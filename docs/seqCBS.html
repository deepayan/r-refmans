<!DOCTYPE html><html><head><title>Help for package seqCBS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {seqCBS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#seqCBS-package'>
<p>Scan Statistics CNV detection using sequencing data</p></a></li>
<li><a href='#BayesCptCI'>
<p>Bayesian Point-wise Confidence Interval for Change-Point Model</p></a></li>
<li><a href='#CombineCaseControlC'>
<p>Combine case and control reads</p></a></li>
<li><a href='#CombineReadsAcrossRuns'>
<p>Combine multiple read lists</p></a></li>
<li><a href='#getAutoGridSize'>
<p>Get Automatic Grid Sizes</p></a></li>
<li><a href='#getCountsInWindow'>
<p>Get number of reads in fixed-width window</p></a></li>
<li><a href='#hppSimulate'>
<p>Simulate a homogeneous Poisson Process</p></a></li>
<li><a href='#JSSim_Meta'><p>Meta File for Simulated Datasets</p></a></li>
<li><a href='#JSSim_NormalSim1'><p>Simulated normal sample dataset 1</p></a></li>
<li><a href='#JSSim_NormalSim2'><p>Simulated normal sample dataset 2</p></a></li>
<li><a href='#JSSim_SpikeMat'><p>True Signal Spike for the Simulated Dataset</p></a></li>
<li><a href='#JSSim_TumorSim1'><p>Simulated Tumor sample dataset 1</p></a></li>
<li><a href='#JSSim_TumorSim2'><p>Simulated Tumor sample dataset 2</p></a></li>
<li><a href='#nhppRateEstimate'>
<p>Estimate the rate of non-homogeneous PP with data</p></a></li>
<li><a href='#nhppSimConstWindowAnalysis'>
<p>Analyze the performance on simulation with constant signal length in each set</p></a></li>
<li><a href='#nhppSimConstWindowGen'>
<p>Simulate a Non-Homogeneous PP with constant window spike</p></a></li>
<li><a href='#nhppSimulate'>
<p>Simulate a non-homogeneous Poisson Process</p></a></li>
<li><a href='#nhppSpike'>
<p>Spike rates of NHPP</p></a></li>
<li><a href='#nhppSpikeConstWindow'>
<p>Spike NHPP rate with constant window width</p></a></li>
<li><a href='#readInput'>
<p>Manage reading and merging of raw datasets. Main file input</p></a></li>
<li><a href='#readListInputFile'>
<p>Read meta file containing list of raw data files</p></a></li>
<li><a href='#readSeq'>
<p>Wrapper for managing the reading of different raw data formats</p></a></li>
<li><a href='#readSeqChiang'>
<p>Read data formatted as in Chiang (2009)</p></a></li>
<li><a href='#readSeqELANDPaired'>
<p>Read raw data formatted as in paired ELAND output</p></a></li>
<li><a href='#relCNComp'>
<p>Compute the Relative Copy Number</p></a></li>
<li><a href='#ScanBIC'>
<p>Compute the modified BIC for change-point models</p></a></li>
<li><a href='#ScanCBS'>
<p>Main CBS Algorithm for Change-Point Detection</p></a></li>
<li><a href='#ScanCBSPlot'>
<p>Main Plotting of the scan statistic segmentation</p></a></li>
<li><a href='#ScanCBSSimPlot'>
<p>Plotting for CBS results of Simulated Data</p></a></li>
<li><a href='#ScanIterateGrid'>
<p>Main Scan with Iterative Grid Search</p></a></li>
<li><a href='#ScanStatNewComp'>
<p>Main new window scan statistics computation</p></a></li>
<li><a href='#ScanStatRefineComp'>
<p>Main refining window scan statistics computation</p></a></li>
<li><a href='#SegSeqResProcess'>
<p>Read and Process result of SegSeq</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Copy Number Profiling using Sequencing and CBS</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-04-12</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeremy J. Shen, Nancy R. Zhang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jeremy J. Shen &lt;jeremyjshen@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This is a method for DNA Copy Number Profiling using
        Next-Generation Sequencing. It has new model and test
        statistics based on non-homogeneous Poisson Processes with
        change point models. It uses an adaptation of Circular Binary
        Segmentation. Also included are methods for point-wise Bayesian
        Confidence Interval and model selection method for the
        change-point model. A case and a control sample reads (normal
        and tumor) are required.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), clue</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-04-13 04:52:17 UTC; jshen</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-04-13 05:22:55 UTC</td>
</tr>
</table>
<hr>
<h2 id='seqCBS-package'>
Scan Statistics CNV detection using sequencing data
</h2><span id='topic+seqCBS-package'></span><span id='topic+seqCBS'></span>

<h3>Description</h3>

<p>CNV detection using matched case-control sequencing read data. It gives a number of scan statistics for the detection of rate differences between two non-homogeneous Poisson Processes, and modified BIC model selection.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> seqCBS</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2011-05-18</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>~~ An overview of how to use the package, including the most important ~~
~~ functions ~~
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen<br />
Nancy R. Zhang
</p>
<p>Maintainer: Jeremy J. Shen &lt;jqshen@stanford.edu&gt;
~~ The author and/or maintainer of the package ~~
</p>

<hr>
<h2 id='BayesCptCI'>
Bayesian Point-wise Confidence Interval for Change-Point Model
</h2><span id='topic+BayesCptCI'></span>

<h3>Description</h3>

<p>This algorithm computes a point-wise Bayesian CI for the p parameter in change-point model on binomial process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesCptCI(cases, controls, CBSRes, stepSize="adaptive", adaptMaxMix=80, 
  alpha=0.05, epsilon=10^-4, epsCDF=10^-4, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BayesCptCI_+3A_cases">cases</code></td>
<td>

<p>A numeric vector of the case/tumor reads
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_controls">controls</code></td>
<td>

<p>A numeric vector of the control/normal reads
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_cbsres">CBSRes</code></td>
<td>

<p>Output from the ScanCBS algorithm on this case/control data
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_stepsize">stepSize</code></td>
<td>

<p>An actual point-wise computation is time-consuming; by using stepSize = n, a Bayesian CI is computed at every n reads. The adaptive option gives good computational speed by choosing stepSize based on the data.
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_adaptmaxmix">adaptMaxMix</code></td>
<td>

<p>An upper bound for the number of unique weights calculated at each change point under the adaptive method. The default is 80 for an average of approximately 5000 mixture components at each point.
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_alpha">alpha</code></td>
<td>

<p>Defaults to 0.05 for the usual CI.
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_epsilon">epsilon</code></td>
<td>

<p>The cutoff for the likelihood ratio of a model with shifted change point compared to the ScanCBS estimated change-point. The likelihood decreases exponentially around the true point or a 'good' estimate of it. Only alternatives with above the cutoff likelihood ratio are considered plausible and integrated in following computations.
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_epscdf">epsCDF</code></td>
<td>

<p>This is an error tolerance value for finding the quantile of the posterior, which is a Beta mixture distribution.
</p>
</td></tr>
<tr><td><code id="BayesCptCI_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, then will print much information on each segmentation. For diagnostics only.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is a Bayesian point-wise CI for our change-point method. It takes model complexity (number of change points) as a given. With the ScanCBS-estimated change points, it evaluates alternatives for the change points around the estimated value and computes the likelihood of the alternative models. Through theoretical derivation, we then have the estimated probability of a case read, p, at a given read index, to have a posterior density given by Beta Mixture. We then compute the quantiles of this distribution using a safe version of Newton-Raphson implemented in C as the CI at this read.
</p>


<h3>Value</h3>

<table>
<tr><td><code>CIRes</code></td>
<td>
<p>A matrix containing the location and its CI of p, each column is a location, or a strech of location if stepSize&gt;1</p>
</td></tr>
<tr><td><code>wkRes</code></td>
<td>
<p>The likelihood ratio for alternatives around each estimated change point</p>
</td></tr>
<tr><td><code>mixStruct</code></td>
<td>
<p>The Beta mixture components for each unique location, containing a collection of two shape parameters and the weight wk</p>
</td></tr>
<tr><td><code>timeCIRes</code></td>
<td>
<p>A list containing the result of the timing of this algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanBIC">ScanBIC</a></code>
</p>

<hr>
<h2 id='CombineCaseControlC'>
Combine case and control reads
</h2><span id='topic+CombineCaseControlC'></span>

<h3>Description</h3>

<p>Combine the case and control reads; finds the unique read positions and count the number of case and control reads.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CombineCaseControlC(cases, controls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CombineCaseControlC_+3A_cases">cases</code></td>
<td>

<p>A vector of numeric read positions from case sample
</p>
</td></tr>
<tr><td><code id="CombineCaseControlC_+3A_controls">controls</code></td>
<td>

<p>A vector of numeric read positions from control sample
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A few C functions are used for efficient implementation
</p>


<h3>Value</h3>

<table>
<tr><td><code>combX</code></td>
<td>
<p>Number of total reads at read position</p>
</td></tr>
<tr><td><code>combZ</code></td>
<td>
<p>Number of case reads at read position</p>
</td></tr>
<tr><td><code>combL</code></td>
<td>
<p>Vector of unique read positions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>

<hr>
<h2 id='CombineReadsAcrossRuns'>
Combine multiple read lists
</h2><span id='topic+CombineReadsAcrossRuns'></span>

<h3>Description</h3>

<p>Combines multiple lists in the same format of the same sample into one list of the said format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CombineReadsAcrossRuns(seqs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CombineReadsAcrossRuns_+3A_seqs">seqs</code></td>
<td>

<p>A list of lists, each containing equal number of numeric vectors that can be concatenated together. Both number of lists and number of variables can be arbitrary.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of the same format as the input lists
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(JSSim_NormalSim1)
data(JSSim_NormalSim2)
write.table(JSSim_NormalSim1, file="JSSim_NormalSim1.txt", 
	sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)
write.table(JSSim_NormalSim2, file="JSSim_NormalSim2.txt", 
	sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)
JSSim_Normal1 = readSeqChiang("JSSim_NormalSim1.txt")
JSSim_Normal2 = readSeqChiang("JSSim_NormalSim2.txt")
file.remove(c("JSSim_NormalSim1.txt", "JSSim_NormalSim2.txt"))
combJSNormal = CombineReadsAcrossRuns(list(JSSim_Normal1, JSSim_Normal2))
print(c(length(JSSim_Normal1$seqF), length(JSSim_Normal2$seqF), 
	length(combJSNormal$seqF)))
</code></pre>

<hr>
<h2 id='getAutoGridSize'>
Get Automatic Grid Sizes
</h2><span id='topic+getAutoGridSize'></span>

<h3>Description</h3>

<p>This produces a default set of grid sizes to be used in Interative Grid Scan
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAutoGridSize(nL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAutoGridSize_+3A_nl">nL</code></td>
<td>

<p>Number of unique read positions
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default grid sizes are powers of 10
</p>


<h3>Value</h3>

<p>numeric vector of grid sizes
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Should produce a vector of power of ten up to 10000
	getAutoGridSize(2*10^5)
</code></pre>

<hr>
<h2 id='getCountsInWindow'>
Get number of reads in fixed-width window
</h2><span id='topic+getCountsInWindow'></span>

<h3>Description</h3>

<p>Computes the number of reads for each fixed-width window between two limits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCountsInWindow(events, startE, endE, windowSize = 10000, sorted = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCountsInWindow_+3A_events">events</code></td>
<td>

<p>A vector of the read positions
</p>
</td></tr>
<tr><td><code id="getCountsInWindow_+3A_starte">startE</code></td>
<td>

<p>Left limit
</p>
</td></tr>
<tr><td><code id="getCountsInWindow_+3A_ende">endE</code></td>
<td>

<p>Right Limit
</p>
</td></tr>
<tr><td><code id="getCountsInWindow_+3A_windowsize">windowSize</code></td>
<td>

<p>Size of the window
</p>
</td></tr>
<tr><td><code id="getCountsInWindow_+3A_sorted">sorted</code></td>
<td>

<p>Whether events is sorted, default F
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses hist() function
</p>


<h3>Value</h3>

<p>A vector of counts for each window
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	getCountsInWindow(sample(1:10000, 3000, replace=TRUE), 0, 10000, 100, FALSE)
</code></pre>

<hr>
<h2 id='hppSimulate'>
Simulate a homogeneous Poisson Process
</h2><span id='topic+hppSimulate'></span>

<h3>Description</h3>

<p>Simulation of a homogeneous poisson process using poisson and uniform distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hppSimulate(lambda, maxVal)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hppSimulate_+3A_lambda">lambda</code></td>
<td>

<p>The rate of the poisson process
</p>
</td></tr>
<tr><td><code id="hppSimulate_+3A_maxval">maxVal</code></td>
<td>

<p>The maximum length of the process to be observed
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a very simple simulation function meant to be used in the NHPP generation.
</p>


<h3>Value</h3>

<p>Returns a vector of point events generated for this process
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimulate">nhppSimulate</a></code>
</p>

<hr>
<h2 id='JSSim_Meta'>Meta File for Simulated Datasets</h2><span id='topic+JSSim_Meta'></span>

<h3>Description</h3>

<p>This data set contains the links and description for the normal and tumor simulated data sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSSim_Meta</code></pre>


<h3>Format</h3>

<p>A matrix with 3 columns and 4 rows, and a header line</p>

<hr>
<h2 id='JSSim_NormalSim1'>Simulated normal sample dataset 1</h2><span id='topic+JSSim_NormalSim1'></span>

<h3>Description</h3>

<p>This data set contains simulated reads of a truncated chromosome from a normal sample
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSSim_NormalSim1</code></pre>


<h3>Format</h3>

<p>A matrix with 3 columns and 15193 rows</p>

<hr>
<h2 id='JSSim_NormalSim2'>Simulated normal sample dataset 2</h2><span id='topic+JSSim_NormalSim2'></span>

<h3>Description</h3>

<p>This data set contains a second set of simulated reads of a truncated chromosome from a normal sample
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSSim_NormalSim2</code></pre>


<h3>Format</h3>

<p>A matrix with 3 columns and 15206 rows</p>

<hr>
<h2 id='JSSim_SpikeMat'>True Signal Spike for the Simulated Dataset</h2><span id='topic+JSSim_SpikeMat'></span>

<h3>Description</h3>

<p>This data set gives the true signal spike location and strength for the simulated datasets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSSim_SpikeMat</code></pre>


<h3>Format</h3>

<p>A matrix with 5 columns and rows</p>

<hr>
<h2 id='JSSim_TumorSim1'>Simulated Tumor sample dataset 1</h2><span id='topic+JSSim_TumorSim1'></span>

<h3>Description</h3>

<p>This data set contains simulated reads of a truncated chromosome from a Tumor sample, with spiked in signals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSSim_TumorSim1</code></pre>


<h3>Format</h3>

<p>A matrix with 3 columns and 16452 rows</p>

<hr>
<h2 id='JSSim_TumorSim2'>Simulated Tumor sample dataset 2</h2><span id='topic+JSSim_TumorSim2'></span>

<h3>Description</h3>

<p>This data set contains a second set of simulated reads of a truncated chromosome from a Tumor sample, with spiked in signals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSSim_TumorSim2</code></pre>


<h3>Format</h3>

<p>A matrix with 3 columns and 16225 rows</p>

<hr>
<h2 id='nhppRateEstimate'>
Estimate the rate of non-homogeneous PP with data
</h2><span id='topic+nhppRateEstimate'></span>

<h3>Description</h3>

<p>Given a vector of point events, give a rough estimate of the rate of underlying non-homogeneous Poisson process by window and smoothing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nhppRateEstimate(controls, length.out = floor(length(controls)/20), 
	lowessF = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nhppRateEstimate_+3A_controls">controls</code></td>
<td>

<p>A vector of point locations (read positions) of a control sample for which the rate is wanted
</p>
</td></tr>
<tr><td><code id="nhppRateEstimate_+3A_length.out">length.out</code></td>
<td>

<p>The number of windows to be used for the rate estimate vector; default to be number of observations/100
</p>
</td></tr>
<tr><td><code id="nhppRateEstimate_+3A_lowessf">lowessF</code></td>
<td>

<p>Smoothing factor for the lowess smoothing of the windowed rates, describes the proportion of windows around a particular window that has influence on its smoothed rate estimate
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is used to give a realistic estimate of the rate nhpp of control samples
</p>


<h3>Value</h3>

<p>Returns a vector of length <code>length.out</code> that contains the smoothed rate estimate of each window
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimulate">nhppSimulate</a></code>
</p>

<hr>
<h2 id='nhppSimConstWindowAnalysis'>
Analyze the performance on simulation with constant signal length in each set
</h2><span id='topic+nhppSimConstWindowAnalysis'></span>

<h3>Description</h3>

<p>Takes the dataset and metafile output of <code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code> and of SegSeq, then evaluates the performance in change-point precision and recall. The dataset must be generated in such format for this function to work.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nhppSimConstWindowAnalysis(filePrefix, chromosomeN, 
  distMetric=c(20,50,100,150,200,300,500,1000), 
  cptLen=c(3,5,8,12,15,20,30,50,100), 
  nPair=2, nRepeat=10, statistic="normal", grid.size="auto", takeN=5, 
  maxNCut=60, minStat=5, verbose=FALSE, timing=TRUE, hasRun=FALSE, 
  width=12, height=6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_fileprefix">filePrefix</code></td>
<td>

<p>The first part of the filename for data and metafile generated by <code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code>
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_chromosomen">chromosomeN</code></td>
<td>

<p>The number indicating the chromosome number the dataset emulates
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_distmetric">distMetric</code></td>
<td>

<p>A set of criterions of determining change points called are true. A call is deemed true if an actual signal change points within x number of reads is matched to it, after a minimum-cost bipartite matching. Larger value is a looser criterion.
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_cptlen">cptLen</code></td>
<td>

<p>The second part of the filename for data and metafile generated by <code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code>, indicating the length of the true signal. Constant width of the signal (CN gain or loss) region to simulate, can be a vector of different values for which to test
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_npair">nPair</code></td>
<td>

<p>A part of the filename for data and metafile generated by <code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code>, indicating the number of normal/tumor pair. Number of tumor samples to generate for each choice of the width of the signal; number of normal samples to generate
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_nrepeat">nRepeat</code></td>
<td>

<p>A part of the filename for data and metafile generated by <code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code>. Number of times to repeat the simulation data generation
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_statistic">statistic</code></td>
<td>

<p>The type of statistic to use for the analysis
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_grid.size">grid.size</code></td>
<td>

<p>Argument to <code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_taken">takeN</code></td>
<td>

<p>Argument to <code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_maxncut">maxNCut</code></td>
<td>

<p>Argument to <code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_minstat">minStat</code></td>
<td>

<p>Argument to <code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, will print run information as the algorithm proceeds
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_timing">timing</code></td>
<td>

<p>Performs timing of the <code><a href="#topic+ScanCBS">ScanCBS</a></code> algorithm
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_hasrun">hasRun</code></td>
<td>

<p>If <code>TRUE</code>, will read the output file of <code><a href="#topic+ScanCBS">ScanCBS</a></code> instead of run it on these datasets again. Only use when the same call to <code><a href="#topic+ScanCBS">ScanCBS</a></code> has been used before in this function call.
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_width">width</code></td>
<td>

<p>Width of the graph output file
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowAnalysis_+3A_height">height</code></td>
<td>

<p>Height of the graph output file
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used in conjunction with <code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code>. It reads in the data and metafile output of the said function, and compares the performance of our algorithm with SegSeq. It is important that SegSeq has been used on the simulation datasets generated before using this.
</p>


<h3>Value</h3>

<table>
<tr><td><code>simCBS</code></td>
<td>
<p>Result of <code><a href="#topic+ScanCBS">ScanCBS</a></code> output structure</p>
</td></tr>
<tr><td><code>CBSMatchDist</code></td>
<td>
<p>The distance among reads after minimum-cost bipartite graph matching for our algorithm</p>
</td></tr>
<tr><td><code>SegMatchDist</code></td>
<td>
<p>The distance among reads after minimum-cost bipartite graph matching for SegSeq</p>
</td></tr>
<tr><td><code>CBSRecall</code>, <code>SegRecall</code></td>
<td>
<p>The recall rates of two algorithms</p>
</td></tr>
<tr><td><code>CBSPrecision</code>, <code>SegPrecision</code></td>
<td>
<p>The precision rates of two algorithms</p>
</td></tr>
<tr><td><code>CBSFMeasure</code>, <code>SegFMeasure</code></td>
<td>
<p>The F-measure of two algorithms</p>
</td></tr>
<tr><td><code>trueTauMeanSigLen</code></td>
<td>
<p>The mean distance between true signal boundaries</p>
</td></tr>
<tr><td><code>nTrueTau</code></td>
<td>
<p>The number of true change points</p>
</td></tr>
<tr><td><code>nCBSCall</code>, <code>nSegCall</code></td>
<td>
<p>Number of change points called by the two algorithms</p>
</td></tr>
<tr><td><code>CBSTime</code></td>
<td>
<p>Mean computational time of <code><a href="#topic+ScanCBS">ScanCBS</a></code> for each signal length</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimConstWindowGen">nhppSimConstWindowGen</a></code>
</p>

<hr>
<h2 id='nhppSimConstWindowGen'>
Simulate a Non-Homogeneous PP with constant window spike
</h2><span id='topic+nhppSimConstWindowGen'></span>

<h3>Description</h3>

<p>Simulate non-homogeneous Poisson processes with a number of constant-widths windows of signal spike, and output the data and meta file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nhppSimConstWindowGen(controlRates, filename, chromosomeN, nSpike=25, 
  cptLen=c(3,5,8,12,20,30,50,75,100), nPair=2, nRepeat=10, minGain=1.5, 
  maxGain=4, minLoss=0.01, maxLoss=0.5, pGain=0.6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nhppSimConstWindowGen_+3A_controlrates">controlRates</code></td>
<td>

<p>The estimated rate of nhpp for the control
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_filename">filename</code></td>
<td>

<p>The prefix of all the output files from this simulation
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_chromosomen">chromosomeN</code></td>
<td>

<p>The chromosome number. Should be the number from which the samples are emulated
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_nspike">nSpike</code></td>
<td>

<p>Number of signal spikes
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_cptlen">cptLen</code></td>
<td>

<p>Constant width of the signal (CN gain or loss) region to simulate, can be a vector of different values for which to test
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_npair">nPair</code></td>
<td>

<p>Number of tumor samples to generate for each choice of the width of the signal; number of normal samples to generate
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_nrepeat">nRepeat</code></td>
<td>

<p>Number of times to repeat the simulation data generation
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_mingain">minGain</code></td>
<td>

<p>Minimal signal gain
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_maxgain">maxGain</code></td>
<td>

<p>Maximal signal gain
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_minloss">minLoss</code></td>
<td>

<p>Minimal signal loss
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_maxloss">maxLoss</code></td>
<td>

<p>Maximal signal loss
</p>
</td></tr>
<tr><td><code id="nhppSimConstWindowGen_+3A_pgain">pGain</code></td>
<td>

<p>Proportion of the signal regions that are CN gain
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used in conjunction with a modified, windowed rate vector to simulate non-homogeneous Poisson processes with a number of constant-widths windows of signal spike.
One should use the <code><a href="#topic+nhppRateEstimate">nhppRateEstimate</a></code> function to estimate the rate of a control sample one wishes to mimic. This function randomly choose windows of a specified constant width, and spike in signals (change points) which can be either gain or loss of copy numbers.
</p>


<h3>Value</h3>

<p>No return value. Generates a number of .txt files, one for each normal/tumor sample as raw data, one input meta file and a file with the true change points for each choice of cptLen.
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimulate">nhppSimulate</a></code>
</p>

<hr>
<h2 id='nhppSimulate'>
Simulate a non-homogeneous Poisson Process
</h2><span id='topic+nhppSimulate'></span>

<h3>Description</h3>

<p>This function simulates an NHPP by blocked thinning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nhppSimulate(smoothRates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nhppSimulate_+3A_smoothrates">smoothRates</code></td>
<td>

<p>A list containing x and y, which are the mid-points of the window and the smoothed number of events in this window
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The list component y of the argument represents the smoothed number of events in the window, namely, they represent the window rate
</p>


<h3>Value</h3>

<p>Returns a vector of events of a realization of the NHPP
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppRateEstimate">nhppRateEstimate</a></code>, <code><a href="#topic+nhppSpike">nhppSpike</a></code>
</p>

<hr>
<h2 id='nhppSpike'>
Spike rates of NHPP
</h2><span id='topic+nhppSpike'></span>

<h3>Description</h3>

<p>Randomly spike the smoothed control rate of an NHPP according to the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nhppSpike(smoothRates, nSpike = 25, cptLenR = 4, cptLenMean = 10, 
  minGain = 1.5, maxGain = 10, minLoss = 0.01, maxLoss = 0.5, pGain = 0.6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nhppSpike_+3A_smoothrates">smoothRates</code></td>
<td>

<p>The smoothed rate estimate of the control process
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_nspike">nSpike</code></td>
<td>

<p>Number of signal spikes
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_cptlenr">cptLenR</code></td>
<td>

<p>Parameter for signal width (parameter R of negative binomial)
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_cptlenmean">cptLenMean</code></td>
<td>

<p>Parameter for signal width (mean width)
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_mingain">minGain</code></td>
<td>

<p>Minimal Gain relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_maxgain">maxGain</code></td>
<td>

<p>Maximal Gain relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_minloss">minLoss</code></td>
<td>

<p>Minimal Loss relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_maxloss">maxLoss</code></td>
<td>

<p>Maximal Loss relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpike_+3A_pgain">pGain</code></td>
<td>

<p>Proportion of signal regions that are CN gain.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The signal width is randomly generated by negative binomial distribution with the two parameters given. The signal strength are uniformly drawn between the two limits.
</p>


<h3>Value</h3>

<table>
<tr><td><code>spikeMat</code></td>
<td>
<p>A matrix containing the actual signal spike information</p>
</td></tr>
<tr><td><code>caseRates</code></td>
<td>
<p>The rate of the case PP to be simulated after signal spike</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimulate">nhppSimulate</a></code>
</p>

<hr>
<h2 id='nhppSpikeConstWindow'>
Spike NHPP rate with constant window width
</h2><span id='topic+nhppSpikeConstWindow'></span>

<h3>Description</h3>

<p>Randomly spike the smoothed control rate of an NHPP according to the parameters, with constant window width.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nhppSpikeConstWindow(smoothRates, nSpike = 25, cptLen = 5, minGain = 1.5, 
  maxGain = 10, minLoss = 0.01, maxLoss = 0.5, pGain = 0.6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nhppSpikeConstWindow_+3A_smoothrates">smoothRates</code></td>
<td>

<p>The smoothed rate estimate of the control process
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_nspike">nSpike</code></td>
<td>

<p>Number of signal spikes
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_cptlen">cptLen</code></td>
<td>

<p>Window width of each signal region
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_mingain">minGain</code></td>
<td>

<p>Minimal Gain relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_maxgain">maxGain</code></td>
<td>

<p>Maximal Gain relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_minloss">minLoss</code></td>
<td>

<p>Minimal Loss relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_maxloss">maxLoss</code></td>
<td>

<p>Maximal Loss relative CN
</p>
</td></tr>
<tr><td><code id="nhppSpikeConstWindow_+3A_pgain">pGain</code></td>
<td>

<p>Proportion of signal regions that are CN gain
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The signal strength are uniformly drawn between the two limits.
</p>


<h3>Value</h3>

<table>
<tr><td><code>spikeMat</code></td>
<td>
<p>A matrix containing the actual signal spike information</p>
</td></tr>
<tr><td><code>caseRates</code></td>
<td>
<p>The rate of the case PP to be simulated after signal spike</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimulate">nhppSimulate</a></code>
</p>

<hr>
<h2 id='readInput'>
Manage reading and merging of raw datasets. Main file input
</h2><span id='topic+readInput'></span>

<h3>Description</h3>

<p>This is used to control the read of a meta file containing names of data files, merge, and give usable output for the main program
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readInput(inputFilename, formatName="Chiang", sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readInput_+3A_inputfilename">inputFilename</code></td>
<td>

<p>The name of file, containing relevant information of all input files
</p>
</td></tr>
<tr><td><code id="readInput_+3A_formatname">formatName</code></td>
<td>

<p>The format in which the data files are written in. We use the simple 'Chiang' as default format of input.
</p>
</td></tr>
<tr><td><code id="readInput_+3A_sep">sep</code></td>
<td>

<p>Delimiter of the meta input file, default is tab-delimited
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The meta input file should be organized in a table format with 2 columns, one of which is 'file' and the other is 'type', indicating the data file names and whether the data is from normal or tumor. We recommend using the 'Chiang' format, as used by the datasets of Chiang (2009). This format requires minimal memory and contains all relevant information for this program. It is a table with two columns, first being the chromosome of the mapped read, and the second being the position of the read in the chromosome. One line for each observation.
</p>


<h3>Value</h3>

<table>
<tr><td><code>normalSeq</code></td>
<td>
<p>A list containing the combined normal/control reads</p>
</td></tr>
<tr><td><code>tumorSeq</code></td>
<td>
<p>A list containing the combined case/tumor reads</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readListInputFile">readListInputFile</a></code>, <code><a href="#topic+readSeq">readSeq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This shows the format of the meta file
data(JSSim_Meta)
print(JSSim_Meta)

# This shows the recommended format, the Chiang data format
data(JSSim_NormalSim1)
print(head(JSSim_NormalSim1))
</code></pre>

<hr>
<h2 id='readListInputFile'>
Read meta file containing list of raw data files
</h2><span id='topic+readListInputFile'></span>

<h3>Description</h3>

<p>Reads a meta file that contains the file names and type of the data files. See details for the format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readListInputFile(inputFilename, sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readListInputFile_+3A_inputfilename">inputFilename</code></td>
<td>

<p>The name of file, containing relevant information of all input files
</p>
</td></tr>
<tr><td><code id="readListInputFile_+3A_sep">sep</code></td>
<td>

<p>Delimiter of the meta input file, default is tab-delimited
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The meta input file should be organized in a table format with 2 columns, one of which is 'file' and the other is 'type', indicating the data file names and whether the data is from 'normal' or 'tumor'.
</p>


<h3>Value</h3>

<table>
<tr><td><code>normalFiles</code></td>
<td>
<p>A character vector containing the names of files with the normal reads</p>
</td></tr>
<tr><td><code>tumorFiles</code></td>
<td>
<p>A character vector containing the names of files with the tumor reads</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readInput">readInput</a></code>, <code><a href="#topic+readSeq">readSeq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This shows the format of the meta file
data(JSSim_Meta)
print(JSSim_Meta)
</code></pre>

<hr>
<h2 id='readSeq'>
Wrapper for managing the reading of different raw data formats
</h2><span id='topic+readSeq'></span>

<h3>Description</h3>

<p>This is a wrapper function. It calls one of the subroutines to reads in a datafile, depending on the format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readSeq(filename, formatName)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readSeq_+3A_filename">filename</code></td>
<td>

<p>The file name of the data file to be read
</p>
</td></tr>
<tr><td><code id="readSeq_+3A_formatname">formatName</code></td>
<td>

<p>The format the file is in. Can be either 'Chiang' or 'ELANDPaired'. We recommend using Chiang since this is the minimal required format.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We recommend using the 'Chiang' format, as used by the datasets of Chiang (2009). This format requires minimal memory and contains all relevant information for this program. It is a table with two columns, first being the chromosome of the mapped read, and the second being the position of the read in the chromosome. One line for each observation. If one has paired read, please use only one of the reads and the mapped location should be the 5'-end.
</p>


<h3>Value</h3>

<table>
<tr><td><code>seqF</code></td>
<td>
<p>Read position for each read</p>
</td></tr>
<tr><td><code>seqChr</code></td>
<td>
<p>Chromosome of each mapped read</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>References</h3>

<p>Chiang et al., Nature Methods, 2009, Vol.6 No.1
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readSeq">readSeq</a></code>, <code><a href="#topic+readSeqChiang">readSeqChiang</a></code>, <code><a href="#topic+readSeqELANDPaired">readSeqELANDPaired</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This shows the recommended format, the Chiang data format
data(JSSim_NormalSim1)
print(head(JSSim_NormalSim1))
</code></pre>

<hr>
<h2 id='readSeqChiang'>
Read data formatted as in Chiang (2009)
</h2><span id='topic+readSeqChiang'></span>

<h3>Description</h3>

<p>Read data formatted as in Chiang (2009), which we recommend using.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readSeqChiang(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readSeqChiang_+3A_filename">filename</code></td>
<td>

<p>The file name of the data set
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This format requires minimal memory and contains all relevant information for this program. It is a table with two columns, first being the chromosome of the mapped read, and the second being the position of the read in the chromosome. One line for each observation. In case of paired read, we only use the front read (whichever has a smaller position label) and ask that you use only that for input.
</p>


<h3>Value</h3>

<table>
<tr><td><code>seqF</code></td>
<td>
<p>Read position for each read</p>
</td></tr>
<tr><td><code>seqChr</code></td>
<td>
<p>Chromosome of each mapped read</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>References</h3>

<p>Chiang et al., Nature Methods, 2009, Vol.6 No.1
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readSeq">readSeq</a></code>, <code><a href="#topic+readSeqChiang">readSeqChiang</a></code>, <code><a href="#topic+readSeqELANDPaired">readSeqELANDPaired</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This shows the format of this type of data
data(JSSim_NormalSim1)
print(head(JSSim_NormalSim1))
</code></pre>

<hr>
<h2 id='readSeqELANDPaired'>
Read raw data formatted as in paired ELAND output
</h2><span id='topic+readSeqELANDPaired'></span>

<h3>Description</h3>

<p>Read datasets with paired-end format, possible output format of ELAND
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readSeqELANDPaired(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readSeqELANDPaired_+3A_filename">filename</code></td>
<td>

<p>The file name of the data set
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This format has two reads per line, each looking like &quot;NACGATGAAACCCCGTCTCTACTAACCATACAAAAA hs_ref_chr17.fa 12091150 R	TGTCGCCCAGGCTGCAATGCAGTGGCGCGATCTCGG hs_ref_chr17.fa 12091018 F&quot;. There are 8 columns, 4 for each of the paired read. The first is the actual read sequence, which we discard; the second is the chromosome of the mapped read; the third is the read position; and the last is indicating whether it is a front- or rear- end read. We only use the reads with the same mapped chromosome and only the front read. This contains more information than needed; the Chiang format is prefered.
</p>


<h3>Value</h3>

<table>
<tr><td><code>seqF</code></td>
<td>
<p>Read position for each read</p>
</td></tr>
<tr><td><code>seqChr</code></td>
<td>
<p>Chromosome of each mapped read</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readSeq">readSeq</a></code>, <code><a href="#topic+readSeqChiang">readSeqChiang</a></code>
</p>

<hr>
<h2 id='relCNComp'>
Compute the Relative Copy Number
</h2><span id='topic+relCNComp'></span>

<h3>Description</h3>

<p>This computes the relative copy number by each of the segment called
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relCNComp(combX, combZ, tauHatInd, p, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="relCNComp_+3A_combx">combX</code></td>
<td>

<p>The number of reads at each unique read position
</p>
</td></tr>
<tr><td><code id="relCNComp_+3A_combz">combZ</code></td>
<td>

<p>The number of case/tumor reads at each unique read position
</p>
</td></tr>
<tr><td><code id="relCNComp_+3A_tauhatind">tauHatInd</code></td>
<td>

<p>The index of change points called
</p>
</td></tr>
<tr><td><code id="relCNComp_+3A_p">p</code></td>
<td>

<p>The overall proportion of case reads
</p>
</td></tr>
<tr><td><code id="relCNComp_+3A_alpha">alpha</code></td>
<td>

<p>Significance level for testing whether each segment is a gain (relative CN &gt; 1) or loss (relative CN &lt; 1). The method internally corrects for multiple testing.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relative CN is defined as the number of case reads divided by the number of control reads in a window, adjusted for overall proportion of case reads (divided by the overall relative CN).
</p>


<h3>Value</h3>

<p>Returns a vector of relative CN for each of the segment between two change points
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>

<hr>
<h2 id='ScanBIC'>
Compute the modified BIC for change-point models
</h2><span id='topic+ScanBIC'></span>

<h3>Description</h3>

<p>This computes mBIC for the current change point model. We then use this to determine the appropriate model complexity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanBIC(combX, combZ, tauHat, lik0, nTotal)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanBIC_+3A_combx">combX</code></td>
<td>

<p>The number of reads at each unique read position
</p>
</td></tr>
<tr><td><code id="ScanBIC_+3A_combz">combZ</code></td>
<td>

<p>The number of case/tumor reads at each unique read position
</p>
</td></tr>
<tr><td><code id="ScanBIC_+3A_tauhat">tauHat</code></td>
<td>

<p>The change points called
</p>
</td></tr>
<tr><td><code id="ScanBIC_+3A_lik0">lik0</code></td>
<td>

<p>The null likelihood. Computed in the main routine.
</p>
</td></tr>
<tr><td><code id="ScanBIC_+3A_ntotal">nTotal</code></td>
<td>

<p>The total number of reads
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is meanted to be called as a subrountine of <code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>


<h3>Value</h3>

<p>Returns a numerical value of mBIC for the current model
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>
</p>

<hr>
<h2 id='ScanCBS'>
Main CBS Algorithm for Change-Point Detection
</h2><span id='topic+ScanCBS'></span>

<h3>Description</h3>

<p>This is the main algorithm. It teratively scans for window of arbitrary size where the case and control read depths are different. It continues until a stopping criterion based on mBIC, maximum number of cut, and the statistic at the current segment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanCBS(cases, controls, statistic = "binomial", grid.size = "auto", takeN = 5, 
  maxNCut = 100, minStat = 0, alpha=0.05, verbose = FALSE, timing = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanCBS_+3A_cases">cases</code></td>
<td>

<p>A numeric vector of the case/tumor reads
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_controls">controls</code></td>
<td>

<p>A numeric vector of the control/normal reads
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_statistic">statistic</code></td>
<td>

<p>The statistic to be used. Can be 'binomial','rabinowitz' or 'normal'.
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_grid.size">grid.size</code></td>
<td>

<p>The set of grid sizes for the iterative search. An automatic default can be computed.
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_taken">takeN</code></td>
<td>

<p>The number of candidate change points to be added to a temporary set at each grid size
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_maxncut">maxNCut</code></td>
<td>

<p>The maximum number of segmentation steps to perform
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_minstat">minStat</code></td>
<td>

<p>The minimum statistic value required to continue the segmentation. Default 0 as this criterion being ignored.
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_alpha">alpha</code></td>
<td>

<p>Significance level for testing whether each segment is a gain (relative CN &gt; 1) or loss (relative CN &lt; 1). The method internally corrects for multiple testing.
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, then will print much information on each segmentation. For diagnostics only.
</p>
</td></tr>
<tr><td><code id="ScanCBS_+3A_timing">timing</code></td>
<td>

<p>If <code>TRUE</code>, perform a timing of this algorithm, include in the output data file.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm is an use of the Circular Binary Segmentation method. It continues to segment the reads and consider the resulting child regions for further segmentation. It keeps track of the most promising cut in each children, and only the child region with the most significant segmentation is further cut, yielding more children. This is repeated until stopping criteria are met. The three types of statistics are by the use of exact binomial likelihood ('binomial'), score statistic ('rabinowitz') or using normal approximation to the binomial ('normal').
</p>


<h3>Value</h3>

<table>
<tr><td><code>tauHat</code></td>
<td>
<p>The change points called</p>
</td></tr>
<tr><td><code>statHat</code></td>
<td>
<p>A matrix containing the statistic and its segmentation for the model called, in the order of the segmentation. The columns are break points in genomic scale (1,2), read index scale (3,4), value of test statistic (5), the parent segment in genomic scale (6,7), and mBIC of the model (8).</p>
</td></tr>
<tr><td><code>relCN</code></td>
<td>
<p>The relative CN computed for each segment between change points</p>
</td></tr>
<tr><td><code>relGainLoss</code></td>
<td>
<p>Test result of whether each segment is a gain, loss, or normal</p>
</td></tr>
<tr><td><code>timingRes</code></td>
<td>
<p>A list containing the result of the timing of this algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>References</h3>

<p>D. Rabinowitz, IMS Lecture Notes - Monograph Series, Vol. 23, 1994
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanIterateGrid">ScanIterateGrid</a></code>, <code><a href="#topic+ScanBIC">ScanBIC</a></code>, <code><a href="#topic+relCNComp">relCNComp</a></code>, <code><a href="#topic+getAutoGridSize">getAutoGridSize</a></code>
</p>

<hr>
<h2 id='ScanCBSPlot'>
Main Plotting of the scan statistic segmentation
</h2><span id='topic+ScanCBSPlot'></span>

<h3>Description</h3>

<p>This is an overall plotting function to display the segmentation for a chromosome
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanCBSPlot(cases, controls, CBSObj, filename, mainTitle, CIObj=NULL, 
  length.out=10000, localWindow=0.5*10^5, localSeparatePlot=TRUE, 
  smoothF=0.025, xlabScale=10^6, width=12, height=18)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanCBSPlot_+3A_cases">cases</code></td>
<td>

<p>The case read positions (should be restricted to a chromosome)
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_controls">controls</code></td>
<td>

<p>The control read positions (should be restricted to a chromosome)
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_cbsobj">CBSObj</code></td>
<td>

<p>The output object of the <code><a href="#topic+ScanCBS">ScanCBS</a></code> function
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_filename">filename</code></td>
<td>

<p>The output file names of the plot
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_maintitle">mainTitle</code></td>
<td>

<p>The title of the plot
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_ciobj">CIObj</code></td>
<td>

<p>Optional; the Bayesian CI computed by <code>BayesCptCI</code> function
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_length.out">length.out</code></td>
<td>

<p>The number of windows to use for the display of smoothed rate estimates
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_localwindow">localWindow</code></td>
<td>

<p>The number of genome locations to show around each of the called change points
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_localseparateplot">localSeparatePlot</code></td>
<td>

<p>Whether to show the local behavior of each change point in a seperate PDF file. Default to TRUE. The output file are the given filename attached with the index and actual location of the change point.
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_smoothf">smoothF</code></td>
<td>

<p>The lowess smoothing factor. The proportion of windows around the current window that affects its smoothed rate estimate
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_xlabscale">xlabScale</code></td>
<td>

<p>The scaling factor of the read positions, often in 10^6, or Mb
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_width">width</code></td>
<td>

<p>The width of the output graph in inches
</p>
</td></tr>
<tr><td><code id="ScanCBSPlot_+3A_height">height</code></td>
<td>

<p>The height of the output graph in inches
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces three sub-graphs, showing the segmentation calls, the smoothed rate estimate, and the inferred relative copy number. It is crucial that one seperates the plot for each chromosome. It also makes a zoom-in plot for a region around each of the called change points.
</p>


<h3>Value</h3>

<p>No return object
</p>


<h3>Author(s)</h3>

<p>Jeremy J. shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>, <code><a href="#topic+ScanCBSSimPlot">ScanCBSSimPlot</a></code>, <code><a href="#topic+relCNComp">relCNComp</a></code>
</p>

<hr>
<h2 id='ScanCBSSimPlot'>
Plotting for CBS results of Simulated Data
</h2><span id='topic+ScanCBSSimPlot'></span>

<h3>Description</h3>

<p>This is an overall plotting function to display the segmentation for a chromosome, for simulation data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanCBSSimPlot(cases, controls, CBSObj, trueTau, SpikeMat, filename, mainTitle, 
  CIObj=NULL, length.out=10000, localWindow=0.5*10^5, localSeparatePlot=TRUE, 
  smoothF=0.025, xlabScale=10^6, width=12, height=18)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanCBSSimPlot_+3A_cases">cases</code></td>
<td>

<p>The case read positions (should be restricted to a chromosome)
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_controls">controls</code></td>
<td>

<p>The control read positions (should be restricted to a chromosome)
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_cbsobj">CBSObj</code></td>
<td>

<p>The output object of the <code><a href="#topic+ScanCBS">ScanCBS</a></code> function
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_truetau">trueTau</code></td>
<td>

<p>The true location of the change points in simulation
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_spikemat">SpikeMat</code></td>
<td>

<p>The matrix of signal spikes as generated by the relevant simulation functions
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_filename">filename</code></td>
<td>

<p>The output file names of the plot
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_maintitle">mainTitle</code></td>
<td>

<p>The title of the plot
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_ciobj">CIObj</code></td>
<td>

<p>Optional; the Bayesian CI computed by <code>BayesCptCI</code> function
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_length.out">length.out</code></td>
<td>

<p>The number of windows to use for the display of smoothed rate estimates
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_localwindow">localWindow</code></td>
<td>

<p>The number of genome locations to show around each of the called change points
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_localseparateplot">localSeparatePlot</code></td>
<td>

<p>Whether to show the local behavior of each change point in a seperate PDF file. Default to TRUE. The output file are the given filename attached with the index and actual location of the change point.
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_smoothf">smoothF</code></td>
<td>

<p>The lowess smoothing factor. The proportion of windows around the current window that affects its smoothed rate estimate
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_xlabscale">xlabScale</code></td>
<td>

<p>The scaling factor of the read positions, often in 10^6, or Mb
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_width">width</code></td>
<td>

<p>The width of the output graph in inches
</p>
</td></tr>
<tr><td><code id="ScanCBSSimPlot_+3A_height">height</code></td>
<td>

<p>The height of the output graph in inches
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is similar to <code><a href="#topic+ScanCBSPlot">ScanCBSPlot</a></code>. This function produces three sub-graphs, showing the segmentation calls, the smoothed rate estimate, and the inferred relative copy number. It is crucial that one seperates the plot for each chromosome. This also has an option of showing each change point details in seperate graphs.
</p>


<h3>Value</h3>

<p>No return object
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>, <code><a href="#topic+ScanCBSPlot">ScanCBSPlot</a></code>, <code><a href="#topic+relCNComp">relCNComp</a></code>
</p>

<hr>
<h2 id='ScanIterateGrid'>
Main Scan with Iterative Grid Search
</h2><span id='topic+ScanIterateGrid'></span>

<h3>Description</h3>

<p>This is a computational speed-up to prevent a quadratic order computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanIterateGrid(combX, combZ, combL, statistic, grid.size, nGridSize, 
  timeIGSBreakDown, takeN, verbose, timing)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanIterateGrid_+3A_combx">combX</code></td>
<td>

<p>The number of reads at the unique read positions
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_combz">combZ</code></td>
<td>

<p>The number of case reads at the unique read positions
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_combl">combL</code></td>
<td>

<p>The set of the labels for the unique read positions
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_statistic">statistic</code></td>
<td>

<p>The type of statistic to be used. Can be 'binomial','rabinowitz', or 'normal'
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_grid.size">grid.size</code></td>
<td>

<p>The set of grid sizes for the iterative search. An automatic default can be given
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_ngridsize">nGridSize</code></td>
<td>

<p>The number of grid sizes
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_timeigsbreakdown">timeIGSBreakDown</code></td>
<td>

<p>Cumulative timing of IGS, in a broken down fashion
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_taken">takeN</code></td>
<td>

<p>The number of candidate change points to be added to a temporary set at each grid size
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, then will print much information on each segmentation. For diagnostics only.
</p>
</td></tr>
<tr><td><code id="ScanIterateGrid_+3A_timing">timing</code></td>
<td>

<p>If <code>TRUE</code>, perform a timing of this algorithm, include in the output data file.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm is a computational speed-up tool. It computes the statistic on coarse grids, and refine to finer grids. Also, at each refinement, it computes all new smaller windows on the finer grid that would not have been captured by the coarse grid. Hence it has a New Scan step and a Refine Scan step, both implemented in C for speed. The three types of statistics are by the use of exact binomial likelihood ('binomial'), score statistic ('rabinowitz') or using normal approximation to the binomial ('normal').
</p>


<h3>Value</h3>

<table>
<tr><td><code>cptsRet</code></td>
<td>
<p>The current set of change points called after the IGS scan of the current region</p>
</td></tr>
<tr><td><code>timeIGSBreakDown</code></td>
<td>
<p>A break-down of the time used at the stages of the IGS</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>, <code><a href="#topic+ScanStatNewComp">ScanStatNewComp</a></code>, <code><a href="#topic+ScanStatRefineComp">ScanStatRefineComp</a></code>
</p>

<hr>
<h2 id='ScanStatNewComp'>
Main new window scan statistics computation
</h2><span id='topic+ScanStatNewComp'></span>

<h3>Description</h3>

<p>This is a wrapper function to call the C routines for the scan statistic new candidate segmentation computing from the IGS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanStatNewComp(combZCumSum, combXCumSum, combZPoint, combXPoint, 
	p, nTotal, grid.cur, max.win, statistic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanStatNewComp_+3A_combzcumsum">combZCumSum</code></td>
<td>

<p>A cumulative sum of the number of case reads
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_combxcumsum">combXCumSum</code></td>
<td>

<p>A cumulative sum of the number of reads
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_combzpoint">combZPoint</code></td>
<td>

<p>The number of case reads at the grid points
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_combxpoint">combXPoint</code></td>
<td>

<p>The number of reads at the grid points
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_p">p</code></td>
<td>

<p>The proportion of case reads in the current region
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_ntotal">nTotal</code></td>
<td>

<p>The total number of reads in the current region
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_grid.cur">grid.cur</code></td>
<td>

<p>The current grid to be computed on
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_max.win">max.win</code></td>
<td>

<p>The maximum inter-window to be considered for new scan
</p>
</td></tr>
<tr><td><code id="ScanStatNewComp_+3A_statistic">statistic</code></td>
<td>

<p>The type of statistic. Can be 'binomial','rabinowitz' or 'normal'
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computations are done in C for speed. The three types of statistics are by the use of exact binomial likelihood ('binomial'), score statistic ('rabinowitz') or using normal approximation to the binomial ('normal').
</p>


<h3>Value</h3>

<p>Returns a matrix containing the candidate change points from the new scan
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>, <code><a href="#topic+ScanIterateGrid">ScanIterateGrid</a></code>
</p>

<hr>
<h2 id='ScanStatRefineComp'>
Main refining window scan statistics computation
</h2><span id='topic+ScanStatRefineComp'></span>

<h3>Description</h3>

<p>This is a wrapper function to call the C routines for the scan statistic to refine current candidate segmentations computing from the IGS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScanStatRefineComp(combZCumSum, combXCumSum, combZPoint, combXPoint, 
  p, nTotal, grid.cur, grid.LR, max.win, statistic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScanStatRefineComp_+3A_combzcumsum">combZCumSum</code></td>
<td>

<p>A cumulative sum of the number of case reads
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_combxcumsum">combXCumSum</code></td>
<td>

<p>A cumulative sum of the number of reads
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_combzpoint">combZPoint</code></td>
<td>

<p>The number of case reads at the grid points
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_combxpoint">combXPoint</code></td>
<td>

<p>The number of reads at the grid points
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_p">p</code></td>
<td>

<p>The proportion of case reads in the current region
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_ntotal">nTotal</code></td>
<td>

<p>The total number of reads in the current region
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_grid.cur">grid.cur</code></td>
<td>

<p>The current grid to be computed on
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_grid.lr">grid.LR</code></td>
<td>

<p>The left and right limits of the existing candidate segmentations that will be refined, indexed by the current grid
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_max.win">max.win</code></td>
<td>

<p>The maximum inter-window to be considered for new scan
</p>
</td></tr>
<tr><td><code id="ScanStatRefineComp_+3A_statistic">statistic</code></td>
<td>

<p>The type of statistic. Can be 'binomial','rabinowitz' or 'normal'.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computations are done in C for speed. The three types of statistics are by the use of exact binomial likelihood ('binomial'), score statistic ('rabinowitz') or using normal approximation to the binomial ('normal').
</p>


<h3>Value</h3>

<p>Returns a matrix containing the refined candidate change points
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScanCBS">ScanCBS</a></code>, <code><a href="#topic+ScanIterateGrid">ScanIterateGrid</a></code>
</p>

<hr>
<h2 id='SegSeqResProcess'>
Read and Process result of SegSeq
</h2><span id='topic+SegSeqResProcess'></span>

<h3>Description</h3>

<p>Read the segmentation results of SegSeq and returns the change points called
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SegSeqResProcess(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SegSeqResProcess_+3A_filename">filename</code></td>
<td>

<p>The filename of the SegSeq output file to be processed
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used to read in the SegSeq results and use for performance evaluation and comparison
</p>


<h3>Value</h3>

<p>Return a list the length of unique chromosomes in the result file. For each entry, the label is the chromosome label; and there is a vector of the change point locations called by SegSeq
</p>


<h3>Author(s)</h3>

<p>Jeremy J. Shen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nhppSimulate">nhppSimulate</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
