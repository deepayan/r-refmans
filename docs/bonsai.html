<!DOCTYPE html><html lang="en"><head><title>Help for package bonsai</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bonsai}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bonsai-package'><p>bonsai: Model Wrappers for Tree-Based Models</p></a></li>
<li><a href='#predict_lightgbm_classification_prob'><p>Internal functions</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#train_lightgbm'><p>Boosted trees with lightgbm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Model Wrappers for Tree-Based Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Bindings for additional tree-based model engines for use with
    the 'parsnip' package. Models include gradient boosted decision trees
    with 'LightGBM' (Ke et al, 2017.), conditional inference trees and
    conditional random forests with 'partykit' (Hothorn and Zeileis, 2015.
    and Hothorn et al, 2006. &lt;<a href="https://doi.org/10.1198%2F106186006X133933">doi:10.1198/106186006X133933</a>&gt;), and
    accelerated oblique random forests with 'aorsf' (Jaeger et al, 2022
    &lt;<a href="https://doi.org/10.5281%2Fzenodo.7116854">doi:10.5281/zenodo.7116854</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bonsai.tidymodels.org/">https://bonsai.tidymodels.org/</a>,
<a href="https://github.com/tidymodels/bonsai">https://github.com/tidymodels/bonsai</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/bonsai/issues">https://github.com/tidymodels/bonsai/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>parsnip (&ge; 1.0.1), R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli, dials, dplyr, glue, purrr, rlang (&ge; 1.1.0), stats,
tibble, utils, withr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>aorsf (&ge; 0.1.5), covr, knitr, lightgbm, Matrix, modeldata,
partykit, rmarkdown, rsample, testthat (&ge; 3.0.0), tune</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-11 22:55:36 UTC; simoncouch</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Falbel [aut],
  Athos Damiani [aut],
  Roel M. Hogervorst
    <a href="https://orcid.org/0000-0001-7509-0328"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Max Kuhn <a href="https://orcid.org/0000-0003-2402-136X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Simon Couch <a href="https://orcid.org/0000-0001-5676-5107"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Posit Software, PBC [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Simon Couch &lt;simon.couch@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-11 23:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='bonsai-package'>bonsai: Model Wrappers for Tree-Based Models</h2><span id='topic+bonsai-package'></span><span id='topic+bonsai'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Bindings for additional tree-based model engines for use with the 'parsnip' package. Models include gradient boosted decision trees with 'LightGBM' (Ke et al, 2017.), conditional inference trees and conditional random forests with 'partykit' (Hothorn and Zeileis, 2015. and Hothorn et al, 2006. <a href="https://doi.org/10.1198/106186006X133933">doi:10.1198/106186006X133933</a>), and accelerated oblique random forests with 'aorsf' (Jaeger et al, 2022 <a href="https://doi.org/10.5281/zenodo.7116854">doi:10.5281/zenodo.7116854</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Simon Couch <a href="mailto:simon.couch@posit.co">simon.couch@posit.co</a> (<a href="https://orcid.org/0000-0001-5676-5107">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Daniel Falbel <a href="mailto:dfalbel@curso-r.com">dfalbel@curso-r.com</a>
</p>
</li>
<li><p> Athos Damiani <a href="mailto:adamiani@curso-r.com">adamiani@curso-r.com</a>
</p>
</li>
<li><p> Roel M. Hogervorst <a href="mailto:hogervorst.rm@gmail.com">hogervorst.rm@gmail.com</a> (<a href="https://orcid.org/0000-0001-7509-0328">ORCID</a>)
</p>
</li>
<li><p> Max Kuhn <a href="mailto:max@posit.co">max@posit.co</a> (<a href="https://orcid.org/0000-0003-2402-136X">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://bonsai.tidymodels.org/">https://bonsai.tidymodels.org/</a>
</p>
</li>
<li> <p><a href="https://github.com/tidymodels/bonsai">https://github.com/tidymodels/bonsai</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/bonsai/issues">https://github.com/tidymodels/bonsai/issues</a>
</p>
</li></ul>


<hr>
<h2 id='predict_lightgbm_classification_prob'>Internal functions</h2><span id='topic+predict_lightgbm_classification_prob'></span><span id='topic+predict_lightgbm_classification_class'></span><span id='topic+predict_lightgbm_classification_raw'></span><span id='topic+predict_lightgbm_regression_numeric'></span><span id='topic+multi_predict._lgb.Booster'></span>

<h3>Description</h3>

<p>Not intended for direct use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_lightgbm_classification_prob(object, new_data, ...)

predict_lightgbm_classification_class(object, new_data, ...)

predict_lightgbm_classification_raw(object, new_data, ...)

predict_lightgbm_regression_numeric(object, new_data, ...)

## S3 method for class ''_lgb.Booster''
multi_predict(object, new_data, type = NULL, trees = NULL, ...)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>parsnip</dt><dd><p><code><a href="parsnip.html#topic+reexports">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='train_lightgbm'>Boosted trees with lightgbm</h2><span id='topic+train_lightgbm'></span>

<h3>Description</h3>

<p><code>train_lightgbm</code> is a wrapper for <code>lightgbm</code> tree-based models
where all of the model arguments are in the main function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_lightgbm(
  x,
  y,
  weights = NULL,
  max_depth = -1,
  num_iterations = 100,
  learning_rate = 0.1,
  feature_fraction_bynode = 1,
  min_data_in_leaf = 20,
  min_gain_to_split = 0,
  bagging_fraction = 1,
  early_stopping_round = NULL,
  validation = 0,
  counts = TRUE,
  quiet = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="train_lightgbm_+3A_x">x</code></td>
<td>
<p>A data frame or matrix of predictors</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_y">y</code></td>
<td>
<p>A vector (factor or numeric) or matrix (numeric) of outcome data.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of sample weights.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_max_depth">max_depth</code></td>
<td>
<p>An integer for the maximum depth of the tree.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_num_iterations">num_iterations</code></td>
<td>
<p>An integer for the number of boosting iterations.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A numeric value between zero and one to control the learning rate.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_feature_fraction_bynode">feature_fraction_bynode</code></td>
<td>
<p>Fraction of predictors that will be randomly sampled
at each split.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_min_data_in_leaf">min_data_in_leaf</code></td>
<td>
<p>A numeric value for the minimum sum of instances needed
in a child to continue to split.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_min_gain_to_split">min_gain_to_split</code></td>
<td>
<p>A number for the minimum loss reduction required to make a
further partition on a leaf node of the tree.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_bagging_fraction">bagging_fraction</code></td>
<td>
<p>Subsampling proportion of rows. Setting this argument
to a non-default value will also set <code>bagging_freq = 1</code>. See the Bagging
section in <code>?details_boost_tree_lightgbm</code> for more details.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_early_stopping_round">early_stopping_round</code></td>
<td>
<p>Number of iterations without an improvement in
the objective function occur before training should be halted.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_validation">validation</code></td>
<td>
<p>The <em>proportion</em> of the training data that are used for
performance assessment and potential early stopping.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_counts">counts</code></td>
<td>
<p>A logical; should <code>feature_fraction_bynode</code> be interpreted as the
<em>number</em> of predictors that will be randomly sampled at each split?
<code>TRUE</code> indicates that <code>mtry</code> will be interpreted in its sense as a <em>count</em>,
<code>FALSE</code> indicates that the argument will be interpreted in its sense as a
<em>proportion</em>.</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_quiet">quiet</code></td>
<td>
<p>A logical; should logging by <code><a href="lightgbm.html#topic+lgb.train">lightgbm::lgb.train()</a></code> be muted?</p>
</td></tr>
<tr><td><code id="train_lightgbm_+3A_...">...</code></td>
<td>
<p>Other options to pass to <code><a href="lightgbm.html#topic+lgb.train">lightgbm::lgb.train()</a></code>. Arguments
will be correctly routed to the <code>param</code> argument, or as a main argument,
depending on their name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an internal function, not meant to be directly called by the user.
</p>


<h3>Value</h3>

<p>A fitted <code>lightgbm.Model</code> object.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
