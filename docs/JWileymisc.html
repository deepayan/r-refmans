<!DOCTYPE html><html><head><title>Help for package JWileymisc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {JWileymisc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.allmissing'><p>Determine which if any variables are all missing in a dataset</p></a></li>
<li><a href='#.fround'><p>Function to round and format a number</p></a></li>
<li><a href='#.quantilePercentiles'><p>Internal Function to Calculate Quantiles</p></a></li>
<li><a href='#aces_daily'><p>Multilevel Daily Data Example</p></a></li>
<li><a href='#APAStyler'><p>A generic function for pretty printing in (semi) APA Style</p></a></li>
<li><a href='#APAStyler.list'><p>APAStyler method for lists</p></a></li>
<li><a href='#APAStyler.lm'><p>APAStyler method for linear models</p></a></li>
<li><a href='#APAStyler.mira'><p>A generic function for pretty printing in (semi) APA Style</p></a></li>
<li><a href='#APAStyler.modelTest.lm'><p>APAStyler method for model tests from a linear model</p></a></li>
<li><a href='#APAStyler.modelTest.vglm'><p>APAStyler method for model tests from a vglm multinomial model</p></a></li>
<li><a href='#APAStyler.SEMSummary'><p>A generic function for pretty printing in (semi) APA Style</p></a></li>
<li><a href='#as.na'><p>Coerces vectors to missing</p></a></li>
<li><a href='#cd'><p>Change directory</p></a></li>
<li><a href='#CheckVals'><p>Score a set of items to create overall scale score</p></a></li>
<li><a href='#compareIVs'><p>Compares the effects of various independent variables on dependent variables</p></a></li>
<li><a href='#compressed RDS'><p>Save and read RDS functions for using multithreaded &ldquo;ZSTD&rdquo; or &ldquo;LZ4&rdquo; compression</p></a></li>
<li><a href='#cor2cov'><p>Convert a correlation matrix and standard deviations to a covariance matrix</p></a></li>
<li><a href='#corOK'><p>Return a non-missing correlation matrix</p></a></li>
<li><a href='#corplot'><p>Heatmap of a Correlation Matrix</p></a></li>
<li><a href='#cramerV'><p>Calculate Phi or Cramer's V effect size</p></a></li>
<li><a href='#diffCircular'><p>Calculate the Circular Difference</p></a></li>
<li><a href='#egltable'><p>Function makes nice tables</p></a></li>
<li><a href='#empirical_pvalue'><p>Calculates an empirical p-value based on the data</p></a></li>
<li><a href='#f.r2'><p>Calculate F and p-value from the R2</p></a></li>
<li><a href='#findSigRegions'><p>Function to find significant regions from an interaction</p></a></li>
<li><a href='#formatHtest'><p>Function to format the reuslts of a hypothesis test as text</p></a></li>
<li><a href='#formatMedIQR'><p>Function to format the median and IQR of a variable</p></a></li>
<li><a href='#formatPval'><p>Function to simplify formatting p-values for easy viewing / publication</p></a></li>
<li><a href='#gglikert'><p>Creates a plot for likert scale</p></a></li>
<li><a href='#hashDataset'><p>Create a character vector or file hash of a dataset and each variable</p></a></li>
<li><a href='#internalcompareIV'><p>Compares the effects of various independent variables</p></a></li>
<li><a href='#internalformulaIt'><p>Internal function to create a formula</p></a></li>
<li><a href='#internalrunIt'><p>Internal function to run a model using gam()</p></a></li>
<li><a href='#intSigRegGraph'><p>Function to find significant regions from an interaction</p></a></li>
<li><a href='#is.naz'><p>Is a variable missing, non finite or zero length character?</p></a></li>
<li><a href='#lagk'><p>Create a lagged variable</p></a></li>
<li><a href='#lm2'><p>Modified lm() to use a specified design matrix</p></a></li>
<li><a href='#meanCircular'><p>Calculate a Circular Mean</p></a></li>
<li><a href='#modelCompare'><p>Compare Two Models</p></a></li>
<li><a href='#modelDiagnostics'><p>Model Diagnostics Functions</p></a></li>
<li><a href='#modelPerformance'><p>Return Indices of Model Performance</p></a></li>
<li><a href='#modelTest'><p>Detailed Tests on Models</p></a></li>
<li><a href='#moments'><p>Estimate the first and second moments</p></a></li>
<li><a href='#naz.omit'><p>Missing and Zero Character Omit</p></a></li>
<li><a href='#param_summary'><p>Calculates summaries for a parameter</p></a></li>
<li><a href='#param_summary_format'><p>Format a data frame of summary statistics</p></a></li>
<li><a href='#plot.modelDiagnostics.lm'><p>Plot Diagnostics for an lm model</p></a></li>
<li><a href='#plot.residualDiagnostics'><p>Plot Residual Diagnostics Default Method</p></a></li>
<li><a href='#plot.SEMSummary'><p>Plots SEMSummary object</p></a></li>
<li><a href='#plot.SEMSummary.list'><p>Plots SEMSummary.list object</p></a></li>
<li><a href='#plot.testDistribution'><p>Plot method for testDistribution objects</p></a></li>
<li><a href='#R2'><p>Calculate R2 Values</p></a></li>
<li><a href='#residualDiagnostics'><p>Residual Diagnostics Functions</p></a></li>
<li><a href='#roundedfivenum'><p>Calculate a rounded five number summary</p></a></li>
<li><a href='#scoring'><p>Score a set of items to create overall scale score - generic</p></a></li>
<li><a href='#SEMSummary'><p>Summary Statistics for a SEM Analysis</p></a></li>
<li><a href='#SEMSummary.fit'><p>Summary Statistics for a SEM Analysis</p></a></li>
<li><a href='#smd'><p>Calculate Standardized Mean Difference (SMD)</p></a></li>
<li><a href='#star'><p>Function to simplify converting p-values to asterisks</p></a></li>
<li><a href='#styledescriptives'><p>Several internal functions to style descriptive statistics</p></a></li>
<li><a href='#styletests'><p>Several internal functions to style inference tests</p></a></li>
<li><a href='#testDistribution'><p>Test the distribution of a variable against a specific distribution</p></a></li>
<li><a href='#timeshift'><p>Shift a time variable to have a new center (zero point)</p></a></li>
<li><a href='#TukeyHSDgg'><p>Tukey HSD Plot</p></a></li>
<li><a href='#VAConverter'><p>Visual Acuity Converter</p></a></li>
<li><a href='#vainternal'><p>Internal Visual Acuity Functions</p></a></li>
<li><a href='#VAObject-class'><p>An S4 class to hold visual acuity data</p></a></li>
<li><a href='#VASummaryObject-class'><p>An S4 class to hold visual acuity summary data</p></a></li>
<li><a href='#winsorizor'><p>Winsorize at specified percentiles</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Miscellaneous Utilities and Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://joshuawiley.com/JWileymisc/">https://joshuawiley.com/JWileymisc/</a>,
<a href="https://github.com/JWiley/JWileymisc">https://github.com/JWiley/JWileymisc</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/JWiley/JWileymisc/issues">https://github.com/JWiley/JWileymisc/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Miscellaneous tools and functions,
    including: generate descriptive statistics tables,
    format output, visualize relations among variables or check
    distributions, and generic functions for residual and
    model diagnostics. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, MASS, multcompView, emmeans, data.table (&ge;
1.14.8), graphics, ggthemes, ggplot2 (&ge; 3.4.3), ggpubr, mgcv,
mice, methods, psych, grid, rms, robustbase, quantreg, lavaan
(&ge; 0.6-16), VGAM (&ge; 1.1-9), lme4, extraoperators (&ge; 0.1.1),
digest, fst, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>scales, foreach, testthat (&ge; 3.1.10), covr, withr, knitr,
rmarkdown, pander, GPArotation</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-05 01:04:58 UTC; jwile</td>
</tr>
<tr>
<td>Author:</td>
<td>Joshua F. Wiley <a href="https://orcid.org/0000-0002-0271-6702"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Joshua F. Wiley &lt;jwiley.psych@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-05 04:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.allmissing'>Determine which if any variables are all missing in a dataset</h2><span id='topic+.allmissing'></span>

<h3>Description</h3>

<p>Internal function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.allmissing(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".allmissing_+3A_data">data</code></td>
<td>
<p>A dataset to check each variable if all missing / non finite / zero character vectors</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>FALSE</code> if no variable(s) all missing, else an informative string message.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>JWileymisc:::.allmissing(mtcars)
cat(JWileymisc:::.allmissing(data.frame(a = NA, b = 1)), fill = TRUE)
</code></pre>

<hr>
<h2 id='.fround'>Function to round and format a number</h2><span id='topic+.fround'></span>

<h3>Description</h3>

<p>Function to round and format a number
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fround(x, digits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".fround_+3A_x">x</code></td>
<td>
<p>the data to round and format</p>
</td></tr>
<tr><td><code id=".fround_+3A_digits">digits</code></td>
<td>
<p>the number of digits to used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector
</p>

<hr>
<h2 id='.quantilePercentiles'>Internal Function to Calculate Quantiles</h2><span id='topic+.quantilePercentiles'></span>

<h3>Description</h3>

<p>Function calculates smoothing spline quantiles
or linear quantiles as a fall back. Not intended for general use.
Expected predicted and residual data.
Exported to support related packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.quantilePercentiles(data, LL = 0.1, UL = 0.9, na.rm = TRUE, cut = 4L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".quantilePercentiles_+3A_data">data</code></td>
<td>
<p>A dataset of predicted and residual values.
Assumed from some sort of (probably parametric) model.</p>
</td></tr>
<tr><td><code id=".quantilePercentiles_+3A_ll">LL</code></td>
<td>
<p>The lower limit for prediction. Defaults to
<code>.1</code> to give the 10th percentile.</p>
</td></tr>
<tr><td><code id=".quantilePercentiles_+3A_ul">UL</code></td>
<td>
<p>The upper limit for prediction. Defaults to
<code>.9</code> to give the 90th percentile.</p>
</td></tr>
<tr><td><code id=".quantilePercentiles_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical whether to remove missing values.
Defaults to <code>TRUE</code></p>
</td></tr>
<tr><td><code id=".quantilePercentiles_+3A_cut">cut</code></td>
<td>
<p>An integer, how many unique predicted values
there have to be at least for it to use quantile regression
or treat the predicted values as discrete.
Defaults to 4.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with the scores and predicted LL and UL,
possibly missing if quantile regression models do not
converge.
</p>

<hr>
<h2 id='aces_daily'>Multilevel Daily Data Example</h2><span id='topic+aces_daily'></span>

<h3>Description</h3>

<p>A data frame drawn from a daily diary study, conducted at
Monash University in 2017 where young adults old completed measures
up to three times per day (morning, afternoon, and evening) for about
12 days.  Thus each participant contributed about 36 observations to
the dataset. To protect participant confidentiality and anonymity, the
data used here were simulated from the original data, but in such a way
as to preserve the relations among variables and most features of the
raw data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aces_daily
</code></pre>


<h3>Format</h3>

<p>A data frame containing 19 variables.
</p>

<dl>
<dt>UserID</dt><dd><p>A unique identifier for each individual</p>
</dd>
<dt>SurveyDay</dt><dd><p>The date each observation occured on</p>
</dd>
<dt>SurveyInteger</dt><dd><p>The survey coded as an integer (1 = morning, 2 = afternoon, 3 = evening)</p>
</dd>
<dt>SurveyStartTimec11</dt><dd><p>Survey start time, centered at time since 11am</p>
</dd>
<dt>Female</dt><dd><p>A 0 or 1 variable, where 1 = female and 0 = male</p>
</dd>
<dt>Age</dt><dd><p>Participant age in years, top coded at 25</p>
</dd>
<dt>BornAUS</dt><dd><p>A 0 or 1 variable where 1 = born in Australia and 0 = born outside of Australia</p>
</dd>
<dt>SES_1</dt><dd><p>Participants subjective SES, bottom coded at 4 and top coded at 8</p>
</dd>
<dt>EDU</dt><dd><p>Participants level of education (1 = university graduate or higher, 0 = less than university graduate</p>
</dd>
<dt>SOLs</dt><dd><p>Self-reported sleep onset latency in minutes, morning survey only</p>
</dd>
<dt>WASONs</dt><dd><p>Self-reported number of wakenings after sleep onset, top coded at 4, morning survey only</p>
</dd>
<dt>STRESS</dt><dd><p>Overall stress ratings on a 0&ndash;10 scale, repeated 3x daily</p>
</dd>
<dt>SUPPORT</dt><dd><p>Overall social support ratings on a 0&ndash;10 scale, repeated 3x daily</p>
</dd>
<dt>PosAff</dt><dd><p>Positive affect ratings on a 1&ndash;5 scale, repeated 3x daily</p>
</dd>
<dt>NegAff</dt><dd><p>Negative affect ratings on a 1&ndash;5 scale, repeated 3x daily</p>
</dd>
<dt>COPEPrb</dt><dd><p>Problem focused coping on a 1&ndash;4 scale, repeated 1x daily at the evening survey</p>
</dd>
<dt>COPEPrc</dt><dd><p>Emotional processing coping on a 1&ndash;4 scale, repeated 1x daily at the evening survey</p>
</dd>
<dt>COPEExp</dt><dd><p>Emotional exprsesion coping on a 1&ndash;4 scale, repeated 1x daily at the evening survey</p>
</dd>
<dt>COPEDis</dt><dd><p>Mental disengagement coping on a 1&ndash;4 scale, repeated 1x daily at the evening survey</p>
</dd>
</dl>


<hr>
<h2 id='APAStyler'>A generic function for pretty printing in (semi) APA Style</h2><span id='topic+APAStyler'></span>

<h3>Description</h3>

<p>A generic function for pretty printing in (semi) APA Style
</p>


<h3>Usage</h3>

<pre><code class='language-R'>APAStyler(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler_+3A_object">object</code></td>
<td>
<p>An object with a class matching one of the methods</p>
</td></tr>
<tr><td><code id="APAStyler_+3A_...">...</code></td>
<td>
<p>Additional argiuments passed on to methods.</p>
</td></tr>
</table>

<hr>
<h2 id='APAStyler.list'>APAStyler method for lists</h2><span id='topic+APAStyler.list'></span>

<h3>Description</h3>

<p>This assumes that all the objects in a list have the same class
and that an <code>APAStyler</code> method exists for that class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'list'
APAStyler(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler.list_+3A_object">object</code></td>
<td>
<p>A list in this case, where each element
is another known class.</p>
</td></tr>
<tr><td><code id="APAStyler.list_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Styled results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
m1 &lt;- lm(mpg ~ qsec * hp, data = mtcars)
m2 &lt;- lm(mpg ~ qsec + hp, data = mtcars)
m3 &lt;- lm(mpg ~ am + vs, data = mtcars)
mt1 &lt;- modelTest(m1)
mt2 &lt;- modelTest(m2)
mt3 &lt;- modelTest(m3)

## styling regression models
APAStyler(list(m1, m2))

## modelTest objects get merged
APAStyler(list(mt1, mt2))

## the models can be named by passing a named list
## including "special" characters using backticks, like spaces
APAStyler(list(Full = mt1, Reduced = mt2))
APAStyler(list(Full = mt1, Reduced = mt2, `Alternate Model` = mt3))

## you can customize the way output is presented
APAStyler(list(mt1, mt2), format = list(
  FixedEffects = "%s, %s\n(%s, %s)",
  EffectSizes = "Cohen's f2 = %s (%s)"))

## clean up
rm(m1, m2, m3, mt1, mt2, mt3)

## End(Not run)
</code></pre>

<hr>
<h2 id='APAStyler.lm'>APAStyler method for linear models</h2><span id='topic+APAStyler.lm'></span>

<h3>Description</h3>

<p>APAStyler method for linear models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm'
APAStyler(object, digits = 2, pdigits, file, print = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler.lm_+3A_object">object</code></td>
<td>
<p>A <code>lm</code> object</p>
</td></tr>
<tr><td><code id="APAStyler.lm_+3A_digits">digits</code></td>
<td>
<p>The number of digits to round results to. Defaults to 2.</p>
</td></tr>
<tr><td><code id="APAStyler.lm_+3A_pdigits">pdigits</code></td>
<td>
<p>The number of digits to use for p values. Defaults to digits + 1 if missing.</p>
</td></tr>
<tr><td><code id="APAStyler.lm_+3A_file">file</code></td>
<td>
<p>An optional argument indicating whether the output should be written to a file.</p>
</td></tr>
<tr><td><code id="APAStyler.lm_+3A_print">print</code></td>
<td>
<p>A logical argument, whether or not to print results to screen.
This is distinct from saving them to a file. Defaults to <code>TRUE</code> for back compatibility.</p>
</td></tr>
<tr><td><code id="APAStyler.lm_+3A_...">...</code></td>
<td>
<p>Additional argiuments passed on to <code>write.table</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='APAStyler.mira'>A generic function for pretty printing in (semi) APA Style</h2><span id='topic+APAStyler.mira'></span>

<h3>Description</h3>

<p>A generic function for pretty printing in (semi) APA Style
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mira'
APAStyler(object, lmobject, digits = 2, pdigits, print = TRUE, file, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler.mira_+3A_object">object</code></td>
<td>
<p><code>mira</code> object</p>
</td></tr>
<tr><td><code id="APAStyler.mira_+3A_lmobject">lmobject</code></td>
<td>
<p>an lm object the degrees of freedom of which can be used for conservative F tests</p>
</td></tr>
<tr><td><code id="APAStyler.mira_+3A_digits">digits</code></td>
<td>
<p>The number of digits to round results to. Defaults to 2.</p>
</td></tr>
<tr><td><code id="APAStyler.mira_+3A_pdigits">pdigits</code></td>
<td>
<p>The number of digits to use for p values. Defaults to digits + 1 if missing.</p>
</td></tr>
<tr><td><code id="APAStyler.mira_+3A_print">print</code></td>
<td>
<p>A logical argument, whether or not to print results to screen.
This is distinct from saving them to a file. Defaults to <code>TRUE</code> for back compatibility.</p>
</td></tr>
<tr><td><code id="APAStyler.mira_+3A_file">file</code></td>
<td>
<p>An optional argument indicating whether the output should be written to a file.</p>
</td></tr>
<tr><td><code id="APAStyler.mira_+3A_...">...</code></td>
<td>
<p>Additional argiuments passed on to <code>write.table</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='APAStyler.modelTest.lm'>APAStyler method for model tests from a linear model</h2><span id='topic+APAStyler.modelTest.lm'></span>

<h3>Description</h3>

<p>APAStyler method for model tests from a linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'modelTest.lm'
APAStyler(
  object,
  format = list(FixedEffects = c("%s%s [%s, %s]"), EffectSizes = c("f2 = %s, %s")),
  digits = 2,
  pcontrol = list(digits = 3, stars = TRUE, includeP = FALSE, includeSign = FALSE,
    dropLeadingZero = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler.modelTest.lm_+3A_object">object</code></td>
<td>
<p>A <code>modelTest.lm</code> class object,
results from running <code>modelTest()</code> function on a
class <code>lm</code> object.</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.lm_+3A_format">format</code></td>
<td>
<p>A list giving the formatting style to be used for
the fixed effecvts and effect sizes.</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.lm_+3A_digits">digits</code></td>
<td>
<p>A numeric value indicating the number of digits to print.
This is still in early implementation stages and currently does not
change all parts of the output (which default to 2 decimals per
APA style).</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.lm_+3A_pcontrol">pcontrol</code></td>
<td>
<p>A list controlling how p values are formatted.</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.lm_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Styled results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- lm(mpg ~ qsec * hp, data = mtcars)
APAStyler(modelTest(m1))

APAStyler(modelTest(m1),
format = list(
  FixedEffects = "%s, %s\n(%s, %s)",
  EffectSizes = "Cohen's f2 = %s (%s)"),
pcontrol = list(digits = 4,
  stars = FALSE, includeP = TRUE,
  includeSign = TRUE,
  dropLeadingZero = TRUE))

## clean up
rm(m1)
</code></pre>

<hr>
<h2 id='APAStyler.modelTest.vglm'>APAStyler method for model tests from a vglm multinomial model</h2><span id='topic+APAStyler.modelTest.vglm'></span>

<h3>Description</h3>

<p>APAStyler method for model tests from a vglm multinomial model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'modelTest.vglm'
APAStyler(
  object,
  format = list(FixedEffects = c("%s%s [%s, %s]"), EffectSizes =
    c("Chi-square (df=%s) = %s, %s")),
  digits = 2,
  pcontrol = list(digits = 3, stars = TRUE, includeP = FALSE, includeSign = FALSE,
    dropLeadingZero = TRUE),
  OR = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler.modelTest.vglm_+3A_object">object</code></td>
<td>
<p>A <code>modelTest.vglm</code> class object,
results from running <code>modelTest()</code> function on a
class <code>vglm</code> object with a multinomial family</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.vglm_+3A_format">format</code></td>
<td>
<p>A list giving the formatting style to be used for
the fixed effects and effect sizes.</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.vglm_+3A_digits">digits</code></td>
<td>
<p>A numeric value indicating the number of digits to print.
This is still in early implementation stages and currently does not
change all parts of the output (which default to 2 decimals per
APA style).</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.vglm_+3A_pcontrol">pcontrol</code></td>
<td>
<p>A list controlling how p values are formatted.</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.vglm_+3A_or">OR</code></td>
<td>
<p>a logical value whether to report odds ratios and
95 percent confidence intervals, if <code>TRUE</code>, or
regression coefficients on the logit scale with standard
errors, if <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="APAStyler.modelTest.vglm_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Styled results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mtcars$cyl &lt;- factor(mtcars$cyl)
m &lt;- VGAM::vglm(cyl ~ qsec,
  family = VGAM::multinomial(), data = mtcars)
mt &lt;- modelTest(m)

APAStyler(mt)

APAStyler(mt, OR = FALSE)

## clean up
rm(m, mt, mtcars)

## Not run: 
mtcars$cyl &lt;- factor(mtcars$cyl)
mtcars$am &lt;- factor(mtcars$am)
m &lt;- VGAM::vglm(cyl ~ qsec,
  family = VGAM::multinomial(), data = mtcars)
APAStyler(modelTest(m))

m &lt;- VGAM::vglm(cyl ~ scale(qsec),
  family = VGAM::multinomial(), data = mtcars)
APAStyler(modelTest(m))

m2 &lt;- VGAM::vglm(cyl ~ factor(vs) * scale(qsec),
  family = VGAM::multinomial(), data = mtcars)
APAStyler(modelTest(m2))

m &lt;- VGAM::vglm(Species ~ Sepal.Length,
  family = VGAM::multinomial(), data = iris)
APAStyler(modelTest(m))

set.seed(1234)
sampdata &lt;- data.frame(
  Outcome = factor(sample(letters[1:3], 20 * 9, TRUE)),
  C1 = rnorm(20 * 9),
  D3 = sample(paste0("L", 1:3), 20 * 9, TRUE))

m &lt;- VGAM::vglm(Outcome ~ factor(D3),
  family = VGAM::multinomial(), data = sampdata)
APAStyler(modelTest(m))

m &lt;- VGAM::vglm(Outcome ~ factor(D3) + C1,
  family = VGAM::multinomial(), data = sampdata)
APAStyler(modelTest(m))

## End(Not run)
</code></pre>

<hr>
<h2 id='APAStyler.SEMSummary'>A generic function for pretty printing in (semi) APA Style</h2><span id='topic+APAStyler.SEMSummary'></span>

<h3>Description</h3>

<p>A generic function for pretty printing in (semi) APA Style
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SEMSummary'
APAStyler(
  object,
  digits = 2,
  type = c("cov", "cor", "both"),
  stars = FALSE,
  file = ifelse(.Platform$OS.type == "windows", "clipboard", FALSE),
  sep = "\t",
  print = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APAStyler.SEMSummary_+3A_object">object</code></td>
<td>
<p><code>SEMSummary</code> object</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_digits">digits</code></td>
<td>
<p>The number of digits to round results to. Defaults to 2.</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_type">type</code></td>
<td>
<p>A character vector giving what to print. Defaults to &lsquo;cov&rsquo;,
the covariances. Other options are &lsquo;cor&rsquo; and &lsquo;both&rsquo;.</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_stars">stars</code></td>
<td>
<p>A logical value whether to include significance values as
stars (*** p &lt; .001, ** p &lt; .01, * p &lt; .05).</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_file">file</code></td>
<td>
<p>An optional argument indicating whether the output should be written to a file.</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_sep">sep</code></td>
<td>
<p>Character what the separator for the table should be. Defaults to tabs.</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_print">print</code></td>
<td>
<p>A logical argument, whether or not to print results to screen.
This is distinct from saving them to a file. Defaults to <code>TRUE</code> for back compatibility.</p>
</td></tr>
<tr><td><code id="APAStyler.SEMSummary_+3A_...">...</code></td>
<td>
<p>Additional argiuments passed on to <code>write.table</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- SEMSummary(~., data = mtcars)
APAStyler(m, type = "cor", stars = FALSE, file = FALSE)
APAStyler(m, type = "cov", stars = FALSE, file = FALSE)
APAStyler(m, type = "both", stars = FALSE, file = FALSE)
APAStyler(m, type = "cor", stars = TRUE, file = FALSE)
APAStyler(m, type = "cov", stars = TRUE, file = FALSE)
APAStyler(m, type = "both", stars = TRUE, file = FALSE)
</code></pre>

<hr>
<h2 id='as.na'>Coerces vectors to missing</h2><span id='topic+as.na'></span>

<h3>Description</h3>

<p>Given a vector, convert it to missing (NA) values,
where the class of the missing matches the input class.
Currently supports character, logical, integer, factor, numeric,
times (from <span class="pkg">chron</span>), Date, POSIXct, POSIXlt, and
zoo (from <span class="pkg">zoo</span>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.na(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.na_+3A_x">x</code></td>
<td>
<p>A vector to convert to missing (NA)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector the same length as the input with missing values of the same class
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(as.na(1L:5L))
str(as.na(rnorm(5)))
str(as.na(c(TRUE, FALSE)))
str(as.na(as.Date("2017-01-01")))
</code></pre>

<hr>
<h2 id='cd'>Change directory</h2><span id='topic+cd'></span>

<h3>Description</h3>

<p>The function takes a path and changes the current working directory
to the path. If the directory specified in the path does not
currently exist, it will be created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cd(base, pre, num)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cd_+3A_base">base</code></td>
<td>
<p>a character string with the base path to the directory. This is required.</p>
</td></tr>
<tr><td><code id="cd_+3A_pre">pre</code></td>
<td>
<p>an optional character string with the prefix to add to
the base path. Non character strings will be coerced to character class.</p>
</td></tr>
<tr><td><code id="cd_+3A_num">num</code></td>
<td>
<p>an optional character string, prefixed by <code>pre</code>.
Non character strings will be coerced to character class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function has been designed to be platform independent,
although it has had limited testing. Path creation is done using
<code>file.path</code>, the existence of the directory is checked using
<code>file.exists</code> and the directory created with <code>dir.create</code>.
Only the first argument, is required.  The other optional arguments
are handy when one wants to create many similar directories with a common base.
</p>


<h3>Value</h3>

<p>NULL, changes the current working directory
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# an example just using the base
cd("~/testdir")

# an example using the optional arguments
base &lt;- "~/testdir"
pre &lt;- "test_"

cd(base, pre, 1)
cd(base, pre, 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='CheckVals'>Score a set of items to create overall scale score</h2><span id='topic+CheckVals'></span>

<h3>Description</h3>

<p>This function creates a single scale score from a data frame, reversing as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckVals(data, okay, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckVals_+3A_data">data</code></td>
<td>
<p>The data to check</p>
</td></tr>
<tr><td><code id="CheckVals_+3A_okay">okay</code></td>
<td>
<p>A vector of okay or acceptable values</p>
</td></tr>
<tr><td><code id="CheckVals_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical whether to remove missing values or not. Defaults to <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> if all values are okay, otherwise an error
</p>

<hr>
<h2 id='compareIVs'>Compares the effects of various independent variables on dependent variables</h2><span id='topic+compareIVs'></span>

<h3>Description</h3>

<p>Utility to estimate the unadjusted, covariate adjusted, and multivariate adjusted
unique contributions of one or more IVs on one or more DVs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareIVs(
  dv,
  type,
  iv,
  covariates = character(),
  data,
  multivariate = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compareIVs_+3A_dv">dv</code></td>
<td>
<p>A character string or vector of the depentent variable(s)</p>
</td></tr>
<tr><td><code id="compareIVs_+3A_type">type</code></td>
<td>
<p>A character string or vector indicating the type of dependent variable(s)</p>
</td></tr>
<tr><td><code id="compareIVs_+3A_iv">iv</code></td>
<td>
<p>A character string or vector giving the IV(s)</p>
</td></tr>
<tr><td><code id="compareIVs_+3A_covariates">covariates</code></td>
<td>
<p>A character string or vector giving the covariate(s)</p>
</td></tr>
<tr><td><code id="compareIVs_+3A_data">data</code></td>
<td>
<p>The data to be used for analysis</p>
</td></tr>
<tr><td><code id="compareIVs_+3A_multivariate">multivariate</code></td>
<td>
<p>A logical value whether to have models with all IVs simultaneously.</p>
</td></tr>
<tr><td><code id="compareIVs_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the internal function, <code>.runIt</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with all the model results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test1 &lt;- compareIVs(
  dv = c("mpg", "disp"),
  type = c("normal", "normal"),
  iv = c("hp", "qsec"),
  covariates = "am",
  data = mtcars, multivariate = TRUE)
test1$OverallSummary
rm(test1)
</code></pre>

<hr>
<h2 id='compressed+20RDS'>Save and read RDS functions for using multithreaded &ldquo;ZSTD&rdquo; or &ldquo;LZ4&rdquo; compression</h2><span id='topic+compressed+20RDS'></span><span id='topic+saveRDSfst'></span><span id='topic+readRDSfst'></span>

<h3>Description</h3>

<p>Save and read RDS functions for using multithreaded &ldquo;ZSTD&rdquo; or &ldquo;LZ4&rdquo; compression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveRDSfst(object, filename = "", compression = 100, algorithm = "ZSTD")

readRDSfst(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compressed+2B20RDS_+3A_object">object</code></td>
<td>
<p>An R object to be saved.</p>
</td></tr>
<tr><td><code id="compressed+2B20RDS_+3A_filename">filename</code></td>
<td>
<p>A character string giving the filename of the object on disk (to save to or read from)</p>
</td></tr>
<tr><td><code id="compressed+2B20RDS_+3A_compression">compression</code></td>
<td>
<p>A numeric value between 0 and 100 indicating the amount of compression.
Defaults to 100, the highest level of compression. 0 gives the lowest compression.</p>
</td></tr>
<tr><td><code id="compressed+2B20RDS_+3A_algorithm">algorithm</code></td>
<td>
<p>A character string of the type of compression to use.
Defaults to &ldquo;ZSTD&rdquo; which is better compression but slower.
The only other option is &ldquo;LZ4&rdquo; which is faster but may provide less compression.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, <code>saveRDS()</code> does not have multithreaded compression
built in. These functions use &ldquo;ZSTD&rdquo; or &ldquo;LZ4&rdquo; compression
via the <code>fst</code> package for multithreaded compression and decompression
with good performance.
To save them, objects are serialized, compressed, and then saved using <code>saveRDS()</code>.
To read them, objects are read in using <code>readRDS()</code>, decompressed, and then unserialized.
Hashing is used to verify the results. <code>saveRDS()</code> is performed using <code>version = 3</code>,
so it will not work on older versions of <code>R</code>.
</p>


<h3>Value</h3>

<p><code>saveRDSfst()</code> is called for its side effect of saving a file to disk.
The original <code>R</code> object if using <code>readRDSfst()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
saveRDSfst(mtcars, filename = file.path(tempdir(), "mtcars.RDS"))

saveRDSfst(mtcars, filename = file.path(tempdir(), "mtcars.RDS"))
readRDSfst(file.path(tempdir(), "mtcars.RDS"))
</code></pre>

<hr>
<h2 id='cor2cov'>Convert a correlation matrix and standard deviations to a covariance matrix</h2><span id='topic+cor2cov'></span>

<h3>Description</h3>

<p>This is a simple function designed to convert a correlation matrix
(standardized covariance matrix) back to a covariance matrix.
It is the opposite of <code>cov2cor</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor2cov(V, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor2cov_+3A_v">V</code></td>
<td>
<p>an n x n correlation matrix.  Should be numeric, square, and symmetric.</p>
</td></tr>
<tr><td><code id="cor2cov_+3A_sigma">sigma</code></td>
<td>
<p>an n length vector of the standard deviations. The length of the
vector must match the number of columns in the correlation matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an n x n covariance matrix
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cov2cor">cov2cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using a built in dataset
cor2cov(cor(longley), sapply(longley, sd))

# should match the above covariance matarix
cov(longley)
all.equal(cov(longley), cor2cov(cor(longley), sapply(longley, sd)))
</code></pre>

<hr>
<h2 id='corOK'>Return a non-missing correlation matrix</h2><span id='topic+corOK'></span>

<h3>Description</h3>

<p>Given a square, symmetric matrix (such as a correlation matrix)
this function tries to drop the fewest possible number of variables
to return a (square, symmetric) matrix with no missing cells.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corOK(x, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corOK_+3A_x">x</code></td>
<td>
<p>a square, symmetric matrix or object coercable to such (such as a data frame).</p>
</td></tr>
<tr><td><code id="corOK_+3A_maxiter">maxiter</code></td>
<td>
<p>a number indicating the maximum number of iterations,
currently as a sanity check. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The assumption that x is square and symmetric comes because it is
assumed that the number of missing cells for a given column are identical
to that of the corresponding row.  <code>corOK</code> finds the column with the
most missing values, and drops that (and its corresponding row), and continues
on in like manner until the matrix has no missing values.  Although this was
intended for a correlation matrix, it could be used on other types of matrices.
Note that because <code>corOK</code> uses an iterative method, it can be slow when many
columns/rows need to be removed. For the intended use (correlation matrices) there
probably should not be many missing.  As a sanity check and to prevent tediously long
computations, the maximum number of iterations can be set.
</p>


<h3>Value</h3>

<p>A list with two elements
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The complete non missing matrix.</p>
</td></tr>
<tr><td><code>keep.indices</code></td>
<td>
<p>A vector of the columns and rows from the
original matrix to be kept (i.e., that are nonmissing).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>cormat &lt;- cor(iris[, -5])
# set missing
cormat[cbind(c(1,2), c(2,1))] &lt;- NA

# print
cormat

# return complete
corOK(cormat)

# using maximum iterations
corOK(cormat, maxiter=0)

# clean up
rm(cormat)
</code></pre>

<hr>
<h2 id='corplot'>Heatmap of a Correlation Matrix</h2><span id='topic+corplot'></span>

<h3>Description</h3>

<p>This function creates a heatmap of a correlation matrix using <span class="pkg">ggplot2</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corplot(
  x,
  coverage,
  pvalues,
  type = c("both", "cor", "p", "coverage"),
  digits = 2,
  order = c("cluster", "asis"),
  ...,
  control.grobs = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corplot_+3A_x">x</code></td>
<td>
<p>A correlation matrix or some other square symmetric matrix.</p>
</td></tr>
<tr><td><code id="corplot_+3A_coverage">coverage</code></td>
<td>
<p>An (optional) matrix with the same dimensions as
<code>x</code> giving the proportion of data present.  Particularly
useful when the correlation matrix is a pairwise present.</p>
</td></tr>
<tr><td><code id="corplot_+3A_pvalues">pvalues</code></td>
<td>
<p>An (optional) matrix with the same dimensions as
<code>x</code> giving the p values for each correlation. To show, use
<code>plot = "p"</code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_type">type</code></td>
<td>
<p>A character string indicating what to show on top of the heatmap. Can be
&lsquo;coverage&rsquo;, in which case bubble points show coverage;
&lsquo;p&rsquo;, in which case p values are shown;
&lsquo;cor&rsquo;, in which case correlations are shown; or
&lsquo;both&rsquo;, in which case both correlations and p-values are shown.
Only has an effect if a coverage (or pvalue) matrix is passed
also. Defaults to <code>cor</code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_digits">digits</code></td>
<td>
<p>The number of digits to round to when printing the
correlations on the heatmap. Text is suppressed when a coverage
matrix is passed and <code>points = TRUE</code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_order">order</code></td>
<td>
<p>A character string indicating how to order the resulting
plot. Defaults to &lsquo;cluster&rsquo; which uses hierarchical clustering
to sensibly order the variables. The other option is &lsquo;asis&rsquo;
in which case the matrix is plotted in the order it is passed.</p>
</td></tr>
<tr><td><code id="corplot_+3A_...">...</code></td>
<td>
<p>Additional arguments currently only passed to
<code>hclust</code> and <code>corOK</code>.</p>
</td></tr>
<tr><td><code id="corplot_+3A_control.grobs">control.grobs</code></td>
<td>
<p>A list of additional <code>quote()</code>d
options to customize the <code>ggplot2</code> output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The actual plot is created using <code>ggplot2</code> and <code>geom_tile</code>.
In addition to creating the plot, the variables are ordered based on a
hierarchical clustering of the correlation matrix.  Specifically, <code>1 - x</code>
is used as the distance matrix. If coverage is passed, will also add a bubble
plot with the area proportional to the proportion of data present for any
given cell.  Defaults for <code>ggplot2</code> are set, but it is possible to use a
named list of quote()d ggplot calls to override all defaults. This is not
expected for typical use.  Particularly main, points, and text as these rely
on internal variable names; however, labels, the gradient color, and area
scaling can be adjusted more safely.
</p>


<h3>Value</h3>

<p>Primarily called for the side effect of creating a plot.
However, the <code>ggplot2</code> plot object is returned,
so it can be saved, replotted, edited, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example plotting the correlation matrix from the
# mtcars dataset
corplot(cor(mtcars))

dat &lt;- as.matrix(iris[, 1:4])

# randomly set 25% of the data to missing
set.seed(10)
dat[sample(length(dat), length(dat) * .25)] &lt;- NA
cor(dat, use = "pair")
cor(dat, use = "complete")

# create a summary of the data (including coverage matrix)
sdat &lt;- SEMSummary(~ ., data = dat, use = "pair")
str(sdat)
# using the plot method for SEMSummary (which basically just calls corplot)
## getting correlations above diagonal and p values below diagonal#'
plot(sdat)

## get correlations only
plot(sdat, type = "cor")

## showing coverage
plot(sdat, type = "coverage")

# use the control.grobs argument to adjust the coverage scaling
# to go from 0 to 1 rather than the range of coverage
corplot(x = sdat$sSigma, coverage = sdat$coverage,
  type = "coverage",
  control.grobs = list(area = quote(scale_size_area(limits = c(0, 1))))
)

# also works with plot() on a SEMSummary
plot(x = sdat, type = "coverage",
  control.grobs = list(area = quote(scale_size_area(limits = c(0, 1))))
)

rm(dat, sdat)
</code></pre>

<hr>
<h2 id='cramerV'>Calculate Phi or Cramer's V effect size</h2><span id='topic+cramerV'></span>

<h3>Description</h3>

<p>Simple function to calculate effect sizes for frequency tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cramerV(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cramerV_+3A_x">x</code></td>
<td>
<p>A frequency table, such as from <code>xtabs()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value with Phi for 2 x 2 tables or Cramer's V
for tables larger than 2 x 2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cramerV(xtabs(~ am + vs, data = mtcars))
cramerV(xtabs(~ cyl + vs, data = mtcars))
cramerV(xtabs(~ cyl + am, data = mtcars))
</code></pre>

<hr>
<h2 id='diffCircular'>Calculate the Circular Difference</h2><span id='topic+diffCircular'></span>

<h3>Description</h3>

<p>Calculate the Circular Difference
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffCircular(x, y, max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffCircular_+3A_x">x</code></td>
<td>
<p>Numeric or integer values</p>
</td></tr>
<tr><td><code id="diffCircular_+3A_y">y</code></td>
<td>
<p>Numeric or integer values</p>
</td></tr>
<tr><td><code id="diffCircular_+3A_max">max</code></td>
<td>
<p>the theoretical maximum (e.g., if degrees, 360; if hours, 24; etc.).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value with the circular difference. This will always be positive if defined.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffCircular(330, 30, max = 360)
diffCircular(22, 1, max = 24)
diffCircular(c(22, 23, 21, 22), c(1, 1, 23, 14), max = 24)
</code></pre>

<hr>
<h2 id='egltable'>Function makes nice tables</h2><span id='topic+egltable'></span>

<h3>Description</h3>

<p>Give a dataset and a list of variables, or just the data
in the vars.  For best results, convert categorical
variables into factors.  Provides a table of estimated descriptive
statistics optionally by group levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>egltable(
  vars,
  g,
  data,
  idvar,
  strict = TRUE,
  parametric = TRUE,
  paired = FALSE,
  simChisq = FALSE,
  sims = 1000000L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="egltable_+3A_vars">vars</code></td>
<td>
<p>Either an index (numeric or character) of
variables to access from the <code>data</code> argument,
or the data to be described itself.</p>
</td></tr>
<tr><td><code id="egltable_+3A_g">g</code></td>
<td>
<p>A variable used tou group/separate the data prior
to calculating descriptive statistics.</p>
</td></tr>
<tr><td><code id="egltable_+3A_data">data</code></td>
<td>
<p>optional argument of the dataset containing
the variables to be described.</p>
</td></tr>
<tr><td><code id="egltable_+3A_idvar">idvar</code></td>
<td>
<p>A character string indicating the variable name
of the ID variable.  Not currently used, but will eventually
support <code>egltable</code> supporting repeated measures data.</p>
</td></tr>
<tr><td><code id="egltable_+3A_strict">strict</code></td>
<td>
<p>Logical, whether to strictly follow the
type of each variable, or to assume categorical if
the number of unique values is less than or equal to 3.</p>
</td></tr>
<tr><td><code id="egltable_+3A_parametric">parametric</code></td>
<td>
<p>Logical whether to use parametric tests in the
case of multiple groups to test for differences.  Only applies to
continuous variables. If <code>TRUE</code>, the default, uses one-way ANOVA,
and a F test. If <code>FALSE</code>, uses the Kruskal-Wallis test.</p>
</td></tr>
<tr><td><code id="egltable_+3A_paired">paired</code></td>
<td>
<p>Logical whether the data are paired or not. Defaults to
<code>FALSE</code>. If <code>TRUE</code>, the grouping variable, <code>g</code>,
must have two levels and <code>idvar</code> must be specified. When used
a paired t-test is used for parametric, continuous data and a
Wilcoxon test for paired  non parametric, continuous data and a McNemar
chi square test is used for categorical data.</p>
</td></tr>
<tr><td><code id="egltable_+3A_simchisq">simChisq</code></td>
<td>
<p>Logical whether to estimate p-values for chi-square test
for categorical data when there are multiple groups, by simulation.
Defaults to <code>FALSE</code>. Useful when there are small cells as will
provide a more accurate test in extreme cases, similar to Fisher Exact
Test but generalizing to large dimension of tables.</p>
</td></tr>
<tr><td><code id="egltable_+3A_sims">sims</code></td>
<td>
<p>Integer for the number of simulations to be used to estimate
p-values for the chi-square tests for categorical variables when
there are multiple groups. Defaults to one million (<code>1e6L</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of the table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>egltable(iris)
egltable(colnames(iris)[1:4], "Species", data = iris)
egltable(iris, parametric = FALSE)
egltable(colnames(iris)[1:4], "Species", iris,
  parametric = FALSE)
egltable(colnames(iris)[1:4], "Species", iris,
  parametric = c(TRUE, TRUE, FALSE, FALSE))
egltable(colnames(iris)[1:4], "Species", iris,
  parametric = c(TRUE, TRUE, FALSE, FALSE), simChisq=TRUE)

diris &lt;- data.table::as.data.table(iris)
egltable("Sepal.Length", g = "Species", data = diris)

tmp &lt;- mtcars
tmp$cyl &lt;- factor(tmp$cyl)
tmp$am &lt;- factor(tmp$am, levels = 0:1)

egltable(c("mpg", "hp"), "vs", tmp)
egltable(c("mpg", "hp"), "am", tmp)
egltable(c("am", "cyl"), "vs", tmp)

tests &lt;- with(sleep,
    wilcox.test(extra[group == 1],
           extra[group == 2], paired = TRUE))
str(tests)

## example with paired data
egltable(c("extra"), g = "group", data = sleep, idvar = "ID", paired = TRUE)

## what happens when ignoring pairing (p-value off)
# egltable(c("extra"), g = "group", data = sleep, idvar = "ID")

## paired categorical data example
## using data on chick weights to create categorical data
tmp &lt;- subset(ChickWeight, Time %in% c(0, 20))
tmp$WeightTertile &lt;- cut(tmp$weight,
  breaks = quantile(tmp$weight, c(0, 1/3, 2/3, 1), na.rm = TRUE),
  include.lowest = TRUE)

egltable(c("weight", "WeightTertile"), g = "Time",
  data = tmp,
  idvar = "Chick", paired = TRUE)

rm(tmp)
</code></pre>

<hr>
<h2 id='empirical_pvalue'>Calculates an empirical p-value based on the data</h2><span id='topic+empirical_pvalue'></span>

<h3>Description</h3>

<p>This function takes a vector of statistics and calculates
the empirical p-value, that is, how many fall on the other
side of zero.  It calculates a two-tailed p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empirical_pvalue(x, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="empirical_pvalue_+3A_x">x</code></td>
<td>
<p>a data vector to operate on</p>
</td></tr>
<tr><td><code id="empirical_pvalue_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical whether to remove NA values. Defaults to <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named vector with the number of values falling at
or below zero, above zero, and the empirical p-value.
</p>


<h3>Author(s)</h3>

<p>Joshua F. Wiley &lt;josh@elkhartgroup.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
empirical_pvalue(rnorm(100))
</code></pre>

<hr>
<h2 id='f.r2'>Calculate F and p-value from the R2</h2><span id='topic+f.r2'></span>

<h3>Description</h3>

<p>Calculate F and p-value from the R2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.r2(r2, numdf, dendf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f.r2_+3A_r2">r2</code></td>
<td>
<p>r squareds</p>
</td></tr>
<tr><td><code id="f.r2_+3A_numdf">numdf</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code id="f.r2_+3A_dendf">dendf</code></td>
<td>
<p>denominator degrees of freedom</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>JWileymisc:::f.r2(.30, 1, 99)
</code></pre>

<hr>
<h2 id='findSigRegions'>Function to find significant regions from an interaction</h2><span id='topic+findSigRegions'></span>

<h3>Description</h3>

<p>This function uses the <code>contrast</code> function from <span class="pkg">rms</span> to
find the threshold for significance from interactions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findSigRegions(
  object,
  l1,
  l2,
  name.vary,
  lower,
  upper,
  alpha = 0.05,
  starts = 50
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findSigRegions_+3A_object">object</code></td>
<td>
<p>A fitted rms object</p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_l1">l1</code></td>
<td>
<p>the first set of values to fix for the contrast function</p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_l2">l2</code></td>
<td>
<p>the second set of values to fix for the contrast function</p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_name.vary">name.vary</code></td>
<td>
<p>the name of the model parameter to vary values for
to find the threshold.  Note that this should not be included in
<code>l1</code> or <code>l2</code> arguments.</p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_lower">lower</code></td>
<td>
<p>The lower bound to search for values for the varying value</p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_upper">upper</code></td>
<td>
<p>The upper bound to search for values for the varying value</p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_alpha">alpha</code></td>
<td>
<p>The significance threshold, defaults to <code>.05</code></p>
</td></tr>
<tr><td><code id="findSigRegions_+3A_starts">starts</code></td>
<td>
<p>Number of starting values to try between the
lower and upper bounds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data table with notes if no convergence or significance
thresholds (if any).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## make me
</code></pre>

<hr>
<h2 id='formatHtest'>Function to format the reuslts of a hypothesis test as text</h2><span id='topic+formatHtest'></span>

<h3>Description</h3>

<p>Function to format the reuslts of a hypothesis test as text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatHtest(
  x,
  type = c("t", "F", "chisq", "kw", "mh", "r_pearson", "r_kendall", "r_spearman"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formatHtest_+3A_x">x</code></td>
<td>
<p>A <code>htest</code> class object</p>
</td></tr>
<tr><td><code id="formatHtest_+3A_type">type</code></td>
<td>
<p>The type of htest. Currently one of: &ldquo;t&rdquo;, &ldquo;F&rdquo;, &ldquo;chisq&rdquo;,
&ldquo;kw&rdquo;, &ldquo;mh&rdquo;, &ldquo;r_pearson&rdquo;, &ldquo;r_kendall&rdquo;, or &ldquo;r_spearman&rdquo;
for t-tests, F-tests, chi-square tests, kruskal-wallis tests,
Mantel-Haenszel tests, pearson correlations, kendall tau correlation,
and spearman rho correlation, respectively.</p>
</td></tr>
<tr><td><code id="formatHtest_+3A_...">...</code></td>
<td>
<p>Arguments passed on to p-value formatting</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string with results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>formatHtest(t.test(extra ~ group, data = sleep), type = "t")
formatHtest(anova(aov(mpg ~ factor(cyl), data = mtcars)), type = "F")
formatHtest(chisq.test(c(A = 20, B = 15, C = 25)), type = "chisq")
formatHtest(kruskal.test(Ozone ~ Month, data = airquality), type = "kw")
formatHtest(mantelhaen.test(UCBAdmissions), type = "mh")
formatHtest(cor.test(~ mpg + hp, data = mtcars, method = "pearson"), type = "r_pearson")
formatHtest(cor.test(~ mpg + hp, data = mtcars, method = "kendall"), type = "r_kendall")
formatHtest(cor.test(~ mpg + hp, data = mtcars, method = "spearman"), type = "r_spearman")
</code></pre>

<hr>
<h2 id='formatMedIQR'>Function to format the median and IQR of a variable</h2><span id='topic+formatMedIQR'></span>

<h3>Description</h3>

<p>Function to format the median and IQR of a variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatMedIQR(x, d = 2, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formatMedIQR_+3A_x">x</code></td>
<td>
<p>the data to have the median and IQR calculated</p>
</td></tr>
<tr><td><code id="formatMedIQR_+3A_d">d</code></td>
<td>
<p>How many digits to display. Defaults to 2.</p>
</td></tr>
<tr><td><code id="formatMedIQR_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical whether to remove missing values. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string with results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>formatMedIQR(mtcars$mpg)
</code></pre>

<hr>
<h2 id='formatPval'>Function to simplify formatting p-values for easy viewing / publication</h2><span id='topic+formatPval'></span>

<h3>Description</h3>

<p>Function to simplify formatting p-values for easy viewing / publication
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatPval(
  x,
  d = 3,
  sd,
  includeP = FALSE,
  includeSign = FALSE,
  dropLeadingZero = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formatPval_+3A_x">x</code></td>
<td>
<p>p values to convert</p>
</td></tr>
<tr><td><code id="formatPval_+3A_d">d</code></td>
<td>
<p>number of digits</p>
</td></tr>
<tr><td><code id="formatPval_+3A_sd">sd</code></td>
<td>
<p>number of scientific digits. Defaults to <code>d</code> if missing.</p>
</td></tr>
<tr><td><code id="formatPval_+3A_includep">includeP</code></td>
<td>
<p>logical value whether to include the character &ldquo;p&rdquo; itself.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="formatPval_+3A_includesign">includeSign</code></td>
<td>
<p>logical value whether to include the character &ldquo;=&rdquo; or &ldquo;&lt;&rdquo;.
Defaults to <code>FALSE</code> and if <code>includeP = TRUE</code> it must be <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="formatPval_+3A_dropleadingzero">dropLeadingZero</code></td>
<td>
<p>logical value whether to drop leading zeros for p-values.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string with stars
</p>


<h3>Examples</h3>

<pre><code class='language-R'>formatPval(c(.00052456, .000000124, .01035, .030489, .534946))
formatPval(c(.00052456, .000000124, .01035, .030489, .534946), 3, 3, FALSE, TRUE)
formatPval(c(.00052456, .000000124, .01035, .030489, .534946), 3, 3, TRUE, TRUE)
formatPval(c(.00052456, .000000124, .01035, .030489, .534946), 5)
formatPval(c(1, .15346, .085463, .05673, .04837, .015353462,
  .0089, .00164, .0006589, .0000000053326), 3, 5)
formatPval(c(1, .15346, .085463, .05673, .04837, .015353462,
  .0089, .00164, .0006589, .0000000053326), 3, 5, dropLeadingZero = FALSE)
</code></pre>

<hr>
<h2 id='gglikert'>Creates a plot for likert scale</h2><span id='topic+gglikert'></span>

<h3>Description</h3>

<p>Creates a plot for likert scale
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gglikert(
  x,
  y,
  leftLab,
  rightLab,
  colour,
  data,
  xlim,
  title,
  shape = 18,
  size = 7
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gglikert_+3A_x">x</code></td>
<td>
<p>Variable to plot on the x axis (the likert scale responses or averages)</p>
</td></tr>
<tr><td><code id="gglikert_+3A_y">y</code></td>
<td>
<p>The variable containing an index of the different items, should be integers</p>
</td></tr>
<tr><td><code id="gglikert_+3A_leftlab">leftLab</code></td>
<td>
<p>The variable with anchors for the low end of the Likert scale</p>
</td></tr>
<tr><td><code id="gglikert_+3A_rightlab">rightLab</code></td>
<td>
<p>The variable with anchors for the high end of the Likert scale</p>
</td></tr>
<tr><td><code id="gglikert_+3A_colour">colour</code></td>
<td>
<p>A character string giving the name of a variable for colouring the data, like a grouping variable. Alternately the colour of points passed to <code><a href="ggplot2.html#topic+geom_point">geom_point</a></code></p>
</td></tr>
<tr><td><code id="gglikert_+3A_data">data</code></td>
<td>
<p>The data to use for plotting</p>
</td></tr>
<tr><td><code id="gglikert_+3A_xlim">xlim</code></td>
<td>
<p>A vector giving the lower an upper limit for the x axis.  This should be the
possible range of the Likert scale, not the actual range.</p>
</td></tr>
<tr><td><code id="gglikert_+3A_title">title</code></td>
<td>
<p>A character vector giving the title for the plot</p>
</td></tr>
<tr><td><code id="gglikert_+3A_shape">shape</code></td>
<td>
<p>A number indicating the point shape, passed to <code><a href="ggplot2.html#topic+geom_point">geom_point</a></code></p>
</td></tr>
<tr><td><code id="gglikert_+3A_size">size</code></td>
<td>
<p>A number indicating the size of points, passed to <code><a href="ggplot2.html#topic+geom_point">geom_point</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(JWileymisc)
library(ggplot2)
library(ggpubr)
testdat &lt;- data.table::data.table(
  Var = 1:4,
  Mean = c(1.5, 3, 2.2, 4.6),
  Low = c("Happy", "Peaceful", "Excited", "Content"),
  High = c("Sad", "Angry", "Hopeless", "Anxious"))

gglikert("Mean", "Var", "Low", "High", data = testdat, xlim = c(1, 5),
  title = "Example Plot of Average Affect Ratings")

testdat &lt;- rbind(
  cbind(testdat, Group = "Young"),
  cbind(testdat, Group = "Old"))
testdat$Mean[5:8] &lt;- c(1.7, 2.6, 2.0, 4.4)

gglikert("Mean", "Var", "Low", "High", colour = "Group",
  data = testdat, xlim = c(1, 5),
  title = "Example Plot of Average Affect Ratings")

gglikert("Mean", "Var", "Low", "High", colour = "Group",
  data = testdat, xlim = c(1, 5),
  title = "Example Plot of Average Affect Ratings") +
ggplot2::scale_colour_manual(values = c("Young" = "grey50", "Old" = "black"))

## clean up
rm(testdat)
</code></pre>

<hr>
<h2 id='hashDataset'>Create a character vector or file hash of a dataset and each variable</h2><span id='topic+hashDataset'></span>

<h3>Description</h3>

<p>Given a <code>data.frame</code> or <code>data.table</code>, create a character vector
MD5 hash of the overall dataset and each variable. The goal of this is to create
a secure vector / text file that can be tracked using version control
(e.g., GitHub) without requiring commiting sensitive datasets.
The tracking will make it possible to evaluate whether two datasets are the
same, such as when sending data or when datasets may change over time
to know which variable(s) changed, if any.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hashDataset(x, file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hashDataset_+3A_x">x</code></td>
<td>
<p>A <code>data.frame</code> or <code>data.table</code> to be hashed.</p>
</td></tr>
<tr><td><code id="hashDataset_+3A_file">file</code></td>
<td>
<p>An optional character string. If given, assumed to be the path/name of a
file to write the character string hash out to, for convenience. When
non missing, the character vector is returned invisibly and a file written.
When missing (default), the character vector is returned directly.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (possibly invisible) character vector. Also (optionally) a text file
written version of the character string.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
hashDataset(mtcars)

## if a file is specified it will write the results to the text file
## nicely formatted, along these lines

cat(hashDataset(cars), sep = "\n")

</code></pre>

<hr>
<h2 id='internalcompareIV'>Compares the effects of various independent variables</h2><span id='topic+internalcompareIV'></span>

<h3>Description</h3>

<p>This is an internal function designed to run many models to compare the
unique predictive effect of different IVs with and without covariates on an
outcome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>internalcompareIV(
  dv,
  type = c("normal", "binary", "count"),
  iv,
  covariates = character(),
  data,
  multivariate = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="internalcompareIV_+3A_dv">dv</code></td>
<td>
<p>A character string of the depentent variable</p>
</td></tr>
<tr><td><code id="internalcompareIV_+3A_type">type</code></td>
<td>
<p>A character string indicating the type of dependent variable</p>
</td></tr>
<tr><td><code id="internalcompareIV_+3A_iv">iv</code></td>
<td>
<p>A character string or vector giving the IV(s)</p>
</td></tr>
<tr><td><code id="internalcompareIV_+3A_covariates">covariates</code></td>
<td>
<p>A character string or vector giving the covariate(s)</p>
</td></tr>
<tr><td><code id="internalcompareIV_+3A_data">data</code></td>
<td>
<p>The data to be used for analysis</p>
</td></tr>
<tr><td><code id="internalcompareIV_+3A_multivariate">multivariate</code></td>
<td>
<p>A logical value whether to have models with all IVs simultaneously.</p>
</td></tr>
<tr><td><code id="internalcompareIV_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the internal function, <code>.runIt</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with all the model results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test1 &lt;- JWileymisc:::internalcompareIV(
  dv = "mpg", type = "normal",
  iv = "hp",
  covariates = "am",
  data = mtcars, multivariate = FALSE)
test1$Summary
rm(test1)
</code></pre>

<hr>
<h2 id='internalformulaIt'>Internal function to create a formula</h2><span id='topic+internalformulaIt'></span>

<h3>Description</h3>

<p>This function is not intended to be called by users.
It creates a formula style character string from its argument.
But note that it does not actually create a formula class object.
If you do not want an argument, use the empty string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>internalformulaIt(dv, iv, covariates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="internalformulaIt_+3A_dv">dv</code></td>
<td>
<p>A character string of the dependent variable.</p>
</td></tr>
<tr><td><code id="internalformulaIt_+3A_iv">iv</code></td>
<td>
<p>A character string or vector of the independent variables</p>
</td></tr>
<tr><td><code id="internalformulaIt_+3A_covariates">covariates</code></td>
<td>
<p>A character string or vector of the dependent variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>JWileymisc:::internalformulaIt("mpg", "hp", "am")
JWileymisc:::internalformulaIt("mpg", "hp", "")
JWileymisc:::internalformulaIt("mpg", "", "am")
</code></pre>

<hr>
<h2 id='internalrunIt'>Internal function to run a model using gam()</h2><span id='topic+internalrunIt'></span>

<h3>Description</h3>

<p>This function is not intended to be called by users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>internalrunIt(formula, type, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="internalrunIt_+3A_formula">formula</code></td>
<td>
<p>A character string containing a formula style object.</p>
</td></tr>
<tr><td><code id="internalrunIt_+3A_type">type</code></td>
<td>
<p>A character string indicating the type of dependent variable.
Currently &ldquo;normal&rdquo;, &ldquo;binary&rdquo;, or &ldquo;count&rdquo;.</p>
</td></tr>
<tr><td><code id="internalrunIt_+3A_data">data</code></td>
<td>
<p>A data frame to be used for analysis.</p>
</td></tr>
<tr><td><code id="internalrunIt_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>gam</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of the gam model.
</p>

<hr>
<h2 id='intSigRegGraph'>Function to find significant regions from an interaction</h2><span id='topic+intSigRegGraph'></span>

<h3>Description</h3>

<p>This function uses the <code>contrast</code> function from <span class="pkg">rms</span> to
find the threshold for significance from interactions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intSigRegGraph(
  object,
  predList,
  contrastList,
  xvar,
  varyvar,
  varyvar.levels,
  xlab = xvar,
  ylab = "Predicted Values",
  ratio = 1,
  xlim,
  ylim,
  xbreaks,
  xlabels = xbreaks,
  scale.x = c(m = 0, s = 1),
  scale.y = c(m = 0, s = 1),
  starts = 50
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intSigRegGraph_+3A_object">object</code></td>
<td>
<p>A fitted rms object</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_predlist">predList</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_contrastlist">contrastList</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_xvar">xvar</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_varyvar">varyvar</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_varyvar.levels">varyvar.levels</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_xlab">xlab</code></td>
<td>
<p>optional</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_ylab">ylab</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_ratio">ratio</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_xlim">xlim</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_ylim">ylim</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_xbreaks">xbreaks</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_xlabels">xlabels</code></td>
<td>
<p>optional</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_scale.x">scale.x</code></td>
<td>
<p>optional</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_scale.y">scale.y</code></td>
<td>
<p>optional</p>
</td></tr>
<tr><td><code id="intSigRegGraph_+3A_starts">starts</code></td>
<td>
<p>Number of starting values to try between the
lower and upper bounds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data table with notes if no convergence or significance
thresholds (if any).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## make me
</code></pre>

<hr>
<h2 id='is.naz'>Is a variable missing, non finite or zero length character?</h2><span id='topic+is.naz'></span>

<h3>Description</h3>

<p>Given a vector, return <code>TRUE</code> or <code>FALSE</code>
if each element is either missing (NA/NaN), non finite (e.g. infinite)
or a zero length character string (only for character vectors).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.naz(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.naz_+3A_x">x</code></td>
<td>
<p>A vector to identify missing / non finite or zero length strings from</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logical vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.naz(c(1, NA, NaN))
is.naz(c(1, NA, NaN, Inf))
is.naz(c("test", "", NA_character_))
</code></pre>

<hr>
<h2 id='lagk'>Create a lagged variable</h2><span id='topic+lagk'></span>

<h3>Description</h3>

<p>Given a variable, create a k lagged version,
optionally do it by a grouping factor, such as an ID.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagk(x, k = 1, by)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lagk_+3A_x">x</code></td>
<td>
<p>the variable to lag</p>
</td></tr>
<tr><td><code id="lagk_+3A_k">k</code></td>
<td>
<p>the length to lag it</p>
</td></tr>
<tr><td><code id="lagk_+3A_by">by</code></td>
<td>
<p>a variable to lag by. Must be sorted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of the lagged values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lagk(1:4, 1)
</code></pre>

<hr>
<h2 id='lm2'>Modified lm() to use a specified design matrix</h2><span id='topic+lm2'></span>

<h3>Description</h3>

<p>This function is a minor modification of the lm() function
to allow the use of a pre-specified design matrix. It is not intended for
public use but only to support <code>modelTest.lm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm2(
  formula,
  data,
  subset,
  weights,
  na.action,
  model = TRUE,
  x = FALSE,
  y = FALSE,
  qr = TRUE,
  singular.ok = TRUE,
  contrasts = NULL,
  offset,
  designMatrix,
  yObserved,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm2_+3A_formula">formula</code></td>
<td>
<p>An object of class &quot;formula&quot; although it is only minimally used</p>
</td></tr>
<tr><td><code id="lm2_+3A_data">data</code></td>
<td>
<p>the dataset</p>
</td></tr>
<tr><td><code id="lm2_+3A_subset">subset</code></td>
<td>
<p>subset</p>
</td></tr>
<tr><td><code id="lm2_+3A_weights">weights</code></td>
<td>
<p>any weights</p>
</td></tr>
<tr><td><code id="lm2_+3A_na.action">na.action</code></td>
<td>
<p>Defaults to <code>na.omit</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_model">model</code></td>
<td>
<p>defaults to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_x">x</code></td>
<td>
<p>defaults to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_y">y</code></td>
<td>
<p>defaults to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_qr">qr</code></td>
<td>
<p>defaults to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_singular.ok">singular.ok</code></td>
<td>
<p>defaults to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_contrasts">contrasts</code></td>
<td>
<p>defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="lm2_+3A_offset">offset</code></td>
<td>
<p>missing by default</p>
</td></tr>
<tr><td><code id="lm2_+3A_designmatrix">designMatrix</code></td>
<td>
<p>a model matrix / design matrix (all numeric, pre coded if applicable for discrete variables)</p>
</td></tr>
<tr><td><code id="lm2_+3A_yobserved">yObserved</code></td>
<td>
<p>the observed y values</p>
</td></tr>
<tr><td><code id="lm2_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an lm class object
</p>


<h3>See Also</h3>

<p><code>lm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mtcars$cyl &lt;- factor(mtcars$cyl)
m &lt;- lm(mpg ~ hp * cyl, data = mtcars)

x &lt;- model.matrix(m)
y &lt;- mtcars$mpg
m2 &lt;- JWileymisc:::lm2(mpg ~ 1 + cyl + hp:cyl, data = mtcars,
  designMatrix = x[, -2, drop = FALSE],
  yObserved = y)

anova(m, m2)

rm(m, m2, x, y)
</code></pre>

<hr>
<h2 id='meanCircular'>Calculate a Circular Mean</h2><span id='topic+meanCircular'></span>

<h3>Description</h3>

<p>Function to calculate circular mean
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanCircular(x, max, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meanCircular_+3A_x">x</code></td>
<td>
<p>Numeric or integer values</p>
</td></tr>
<tr><td><code id="meanCircular_+3A_max">max</code></td>
<td>
<p>The theoretical maximum (e.g., if degrees, 360)</p>
</td></tr>
<tr><td><code id="meanCircular_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether to remove missing values.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value with the circular mean.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meanCircular(c(22:23, 1:2), max = 24)
meanCircular(c(12, 24), max = 24)
meanCircular(c(6, 7, 23), max = 24)
meanCircular(c(6, 7, 21), max = 24)
meanCircular(c(6, 21), max = 24)
meanCircular(c(6, 23), max = 24)
meanCircular(c(.91, .96, .05, .16), max = 1)
meanCircular(c(6, 7, 8, 9), max = 24)
meanCircular(1:3, max = 24)
meanCircular(21:23, max = 24)
meanCircular(c(16, 17, 18, 19), max = 24)
meanCircular(c(355, 5, 15), max = 360)

</code></pre>

<hr>
<h2 id='modelCompare'>Compare Two Models</h2><span id='topic+modelCompare'></span><span id='topic+as.modelCompare'></span><span id='topic+is.modelCompare'></span><span id='topic+modelCompare.lm'></span>

<h3>Description</h3>

<p>Generic function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelCompare(model1, model2, ...)

as.modelCompare(x)

is.modelCompare(x)

## S3 method for class 'lm'
modelCompare(model1, model2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelCompare_+3A_model1">model1</code></td>
<td>
<p>A fitted model object.</p>
</td></tr>
<tr><td><code id="modelCompare_+3A_model2">model2</code></td>
<td>
<p>A fitted model object to compare to <code>model1</code></p>
</td></tr>
<tr><td><code id="modelCompare_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to specific methods.</p>
</td></tr>
<tr><td><code id="modelCompare_+3A_x">x</code></td>
<td>
<p>An object (e.g., list or a modelCompare object) to
test or attempt coercing to a modelCompare object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depends on the method dispatch.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- lm(mpg ~ qsec * hp, data = mtcars)

m2 &lt;- lm(mpg ~ am, data = mtcars)

modelCompare(m1, m2)

## cleanup
rm(m1, m2)

## Not run: 
m3 &lt;- lm(mpg ~ 1, data = mtcars)
m4 &lt;- lm(mpg ~ 0, data = mtcars)
modelCompare(m3, m4)

## cleanup
rm(m3, m4)

## End(Not run)
</code></pre>

<hr>
<h2 id='modelDiagnostics'>Model Diagnostics Functions</h2><span id='topic+modelDiagnostics'></span><span id='topic+as.modelDiagnostics'></span><span id='topic+is.modelDiagnostics'></span><span id='topic+modelDiagnostics.lm'></span>

<h3>Description</h3>

<p>A set of functions to calculate
model diagnostics on models, including constructors,
a generic function, a test of whether an object is of the
<code>modelDiagnostics</code> class, and methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelDiagnostics(object, ...)

as.modelDiagnostics(x)

is.modelDiagnostics(x)

## S3 method for class 'lm'
modelDiagnostics(
  object,
  ev.perc = 0.001,
  robust = FALSE,
  distr = "normal",
  standardized = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelDiagnostics_+3A_object">object</code></td>
<td>
<p>A fitted model object, with methods for
<code>model.frame</code>, <code>resid</code> and <code>fitted</code>.</p>
</td></tr>
<tr><td><code id="modelDiagnostics_+3A_...">...</code></td>
<td>
<p>Additional arguments, passed to <code>residualDiagnostics</code>.</p>
</td></tr>
<tr><td><code id="modelDiagnostics_+3A_x">x</code></td>
<td>
<p>An object to test or a list to coerce to a
<code>modelDiagnostics</code> object.</p>
</td></tr>
<tr><td><code id="modelDiagnostics_+3A_ev.perc">ev.perc</code></td>
<td>
<p>A real number between 0 and 1 indicating the
proportion of the theoretical distribution beyond which
values are considered extreme values (possible outliers).
Defaults to .001.</p>
</td></tr>
<tr><td><code id="modelDiagnostics_+3A_robust">robust</code></td>
<td>
<p>Whether to use robust mean and standard deviation estimates
for normal distribution</p>
</td></tr>
<tr><td><code id="modelDiagnostics_+3A_distr">distr</code></td>
<td>
<p>A character string given the assumed distribution.
Passed on to <code><a href="#topic+testDistribution">testDistribution</a></code>.
Defaults to &ldquo;normal&rdquo;.</p>
</td></tr>
<tr><td><code id="modelDiagnostics_+3A_standardized">standardized</code></td>
<td>
<p>A logical whether to use standardized residuals.
Defaults to <code>TRUE</code> generally where possible but may depend on
method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical (<code>is.modelDiagnostics</code>) or
a modelDiagnostics object (list) for
<code>as.modelDiagnostics</code> and <code>modelDiagnostics</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testm &lt;- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)

md &lt;- modelDiagnostics(testm)
plot(md$residualDiagnostics$testDistribution)
md$extremeValues

plot(md)

md &lt;- modelDiagnostics(testm, ev.perc = .1)
md$extremeValues
plot(md, ncol = 2)

testdat &lt;- data.frame(
  y = c(1, 2, 2, 3, 3, NA, 9000000, 2, 2, 1),
  x = c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2))

modelDiagnostics(
  lm(y ~ x, data = testdat, na.action = "na.omit"),
  ev.perc = .1)$extremeValues

modelDiagnostics(
  lm(y ~ x, data = testdat, na.action = "na.exclude"),
  ev.perc = .1)$extremeValues

## clean up
rm(testm, md, testdat)
</code></pre>

<hr>
<h2 id='modelPerformance'>Return Indices of Model Performance</h2><span id='topic+modelPerformance'></span><span id='topic+as.modelPerformance'></span><span id='topic+is.modelPerformance'></span><span id='topic+modelPerformance.lm'></span>

<h3>Description</h3>

<p>Generic function. Generally returns things like
fit indices, absolute error metrics, tests of
overall model significance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelPerformance(object, ...)

as.modelPerformance(x)

is.modelPerformance(x)

## S3 method for class 'lm'
modelPerformance(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelPerformance_+3A_object">object</code></td>
<td>
<p>A fitted model object. The class of the model
determines which specific method is called.</p>
</td></tr>
<tr><td><code id="modelPerformance_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to specific methods.</p>
</td></tr>
<tr><td><code id="modelPerformance_+3A_x">x</code></td>
<td>
<p>A object (e.g., list or a modelPerformance object) to
test or attempt coercing to a modelPerformance object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>lm</code> class objects, return number of observations,
AIC, BIC, log likelihood, R2, overall model F test, and p-value.
</p>


<h3>Value</h3>

<p>A <code>data.table</code> with results.
</p>
<p>A list with a <code>data.table</code> with the following elements:
</p>

<dl>
<dt>Model</dt><dd><p>A character string indicating the model type, here lm</p>
</dd>
<dt>N_Obs</dt><dd><p>The number of observations</p>
</dd>
<dt>AIC</dt><dd><p>Akaike Information Criterion</p>
</dd>
<dt>BIC</dt><dd><p>Bayesian Information Criterion</p>
</dd>
<dt>LL</dt><dd><p>log likelihood</p>
</dd>
<dt>LLDF</dt><dd><p>log likelihood degrees of freedom</p>
</dd>
<dt>Sigma</dt><dd><p>Residual variability</p>
</dd>
<dt>R2</dt><dd><p>in sample variance explained</p>
</dd>
<dt>F2</dt><dd><p>Cohen's F2 effect size R2 / (1 - R2)</p>
</dd>
<dt>AdjR2</dt><dd><p>adjusted variance explained</p>
</dd>
<dt>F</dt><dd><p>F value for overall model significance test</p>
</dd>
<dt>FNumDF</dt><dd><p>numerator degrees of freedom for F test</p>
</dd>
<dt>FDenDF</dt><dd><p>denominator degrees of freedom for F test</p>
</dd>
<dt>P</dt><dd><p>p-value for overall model F test</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>modelPerformance(lm(mpg ~ qsec * hp, data = mtcars))

modelPerformance(lm(mpg ~ hp, data = mtcars))

## Not run: 
modelPerformance(lm(mpg ~ 0 + hp, data = mtcars))
modelPerformance(lm(mpg ~ 1, data = mtcars))
modelPerformance(lm(mpg ~ 0, data = mtcars))

## End(Not run)
</code></pre>

<hr>
<h2 id='modelTest'>Detailed Tests on Models</h2><span id='topic+modelTest'></span><span id='topic+is.modelTest'></span><span id='topic+as.modelTest'></span><span id='topic+modelTest.vglm'></span><span id='topic+modelTest.lm'></span>

<h3>Description</h3>

<p>TODO: make me!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelTest(object, ...)

is.modelTest(x)

as.modelTest(x)

## S3 method for class 'vglm'
modelTest(object, ...)

## S3 method for class 'lm'
modelTest(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelTest_+3A_object">object</code></td>
<td>
<p>A fitted model object.</p>
</td></tr>
<tr><td><code id="modelTest_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to specific methods.</p>
</td></tr>
<tr><td><code id="modelTest_+3A_x">x</code></td>
<td>
<p>A object (e.g., list or a modelTest object) to
test or attempt coercing to a modelTest object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depends on the method dispatch.
</p>
<p>A list with two elements.
<code>Results</code> contains a data table of the actual estimates.
<code>Table</code> contains a nicely formatted character matrix.
</p>
<p>A list with two elements.
<code>Results</code> contains a data table of the actual estimates.
<code>Table</code> contains a nicely formatted character matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mtcars$cyl &lt;- factor(mtcars$cyl)
m &lt;- VGAM::vglm(cyl ~ qsec,
  family = VGAM::multinomial(), data = mtcars)
modelTest(m)

## clean up
rm(m, mtcars)

## Not run: 
mtcars$cyl &lt;- factor(mtcars$cyl)
mtcars$am &lt;- factor(mtcars$am)
m &lt;- VGAM::vglm(cyl ~ qsec,
  family = VGAM::multinomial(), data = mtcars)
modelTest(m)

m &lt;- VGAM::vglm(cyl ~ scale(qsec),
  family = VGAM::multinomial(), data = mtcars)
modelTest(m)

m2 &lt;- VGAM::vglm(cyl ~ factor(vs) * scale(qsec),
  family = VGAM::multinomial(), data = mtcars)
modelTest(m2)

m &lt;- VGAM::vglm(Species ~ Sepal.Length,
  family = VGAM::multinomial(), data = iris)
modelTest(m)

set.seed(1234)
sampdata &lt;- data.frame(
  Outcome = factor(sample(letters[1:3], 20 * 9, TRUE)),
  C1 = rnorm(20 * 9),
  D3 = sample(paste0("L", 1:3), 20 * 9, TRUE))

m &lt;- VGAM::vglm(Outcome ~ factor(D3),
  family = VGAM::multinomial(), data = sampdata)
modelTest(m)

m &lt;- VGAM::vglm(Outcome ~ factor(D3) + C1,
  family = VGAM::multinomial(), data = sampdata)
modelTest(m)

## End(Not run)
m1 &lt;- lm(mpg ~ qsec * hp, data = mtcars)
modelTest(m1)

mtcars$cyl &lt;- factor(mtcars$cyl)
m2 &lt;- lm(mpg ~ cyl, data = mtcars)
modelTest(m2)

m3 &lt;- lm(mpg ~ hp * cyl, data = mtcars)
modelTest(m3)

m4 &lt;- lm(sqrt(mpg) ~ hp * cyl, data = mtcars)
modelTest(m4)

m5 &lt;- lm(mpg ~ sqrt(hp) * cyl, data = mtcars)
modelTest(m5)

## cleanup
rm(m1, m2, m3, m4, m5, mtcars)
</code></pre>

<hr>
<h2 id='moments'>Estimate the first and second moments</h2><span id='topic+moments'></span>

<h3>Description</h3>

<p>This function relies on the <span class="pkg">lavaan</span> package to use the
Expectation Maximization (EM) algorithm to estimate the first and
second moments (means and [co]variances) when there is missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moments(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="moments_+3A_data">data</code></td>
<td>
<p>A data frame or an object coercable to a data frame.
The means and covariances of all variables are estimated.</p>
</td></tr>
<tr><td><code id="moments_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the <code>estimate.moments.EM</code>
function in <span class="pkg">lavaan</span>. Note this is not an exported function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the esimates from the EM algorithm.
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>A named vector of the means.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The covariance matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suggested by Yves Rosseel author of the lavaan package on which this depends
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SEMSummary">SEMSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sample data
Xmiss &lt;- as.matrix(iris[, -5])
# make 25% missing completely at random
set.seed(10)
Xmiss[sample(length(Xmiss), length(Xmiss) * .25)] &lt;- NA
Xmiss &lt;- as.data.frame(Xmiss)

# true means and covariance
colMeans(iris[, -5])
# covariance with n - 1 divisor
cov(iris[, -5])

# means and covariance matrix using list wise deletion
colMeans(na.omit(Xmiss))
cov(na.omit(Xmiss))

# means and covariance matrix using EM
moments(Xmiss)
# clean up
rm(Xmiss)
</code></pre>

<hr>
<h2 id='naz.omit'>Missing and Zero Character Omit</h2><span id='topic+naz.omit'></span>

<h3>Description</h3>

<p>Given a vector, exclude any missing values,
not a number values, non finite values,
and if a character class, any zero length strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naz.omit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naz.omit_+3A_x">x</code></td>
<td>
<p>A vector to exclude missing, non finite or zero length strings from</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector with missing/non finite/zero length strings omitted
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## stats na.omit
stats::na.omit(c(1, NA, NaN))
stats::na.omit(c("test", "", NA_character_))

naz.omit(c(1, NA, NaN))
naz.omit(c(1L, NA))
naz.omit(c(1L, NA, Inf))
naz.omit(c("test", "", NA_character_))
</code></pre>

<hr>
<h2 id='param_summary'>Calculates summaries for a parameter</h2><span id='topic+param_summary'></span>

<h3>Description</h3>

<p>This function takes a vector of statistics and calculates
several summaries: mean, median, 95
the empirical p-value, that is, how many fall on the other
side of zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>param_summary(x, trans = function(x) x, ..., na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="param_summary_+3A_x">x</code></td>
<td>
<p>a data vector to operate on</p>
</td></tr>
<tr><td><code id="param_summary_+3A_trans">trans</code></td>
<td>
<p>A function to transform the data. Used for summaries,
but not p-values. Defaults to the identity function.</p>
</td></tr>
<tr><td><code id="param_summary_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>formatPval</code>
to control p-value printing.</p>
</td></tr>
<tr><td><code id="param_summary_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical whether to remove NA values. Defaults to <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of summary statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
param_summary(rnorm(100))
</code></pre>

<hr>
<h2 id='param_summary_format'>Format a data frame of summary statistics</h2><span id='topic+param_summary_format'></span>

<h3>Description</h3>

<p>This functions nicely formats a data frame of parameter summary
statistics and is designed to be used with the param_summary()
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>param_summary_format(d, digits = getOption("digits"), pretty = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="param_summary_format_+3A_d">d</code></td>
<td>
<p>A data frame of the parameter summary statistics</p>
</td></tr>
<tr><td><code id="param_summary_format_+3A_digits">digits</code></td>
<td>
<p>Number of digits to round to for printing</p>
</td></tr>
<tr><td><code id="param_summary_format_+3A_pretty">pretty</code></td>
<td>
<p>Logical value whether prettified values should be returned.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A formatted data.table of summary statistics or a formated
vector (if <code>pretty = TRUE</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
xsum &lt;- do.call(rbind, apply(matrix(rnorm(100*10), ncol = 10),
  2, param_summary))
rownames(xsum) &lt;- letters[1:10]
param_summary_format(xsum)
param_summary_format(xsum, pretty = TRUE)

rm(xsum)
</code></pre>

<hr>
<h2 id='plot.modelDiagnostics.lm'>Plot Diagnostics for an lm model</h2><span id='topic+plot.modelDiagnostics.lm'></span>

<h3>Description</h3>

<p>This function creates a number of diagnostic plots
from lm models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'modelDiagnostics.lm'
plot(x, y, plot = TRUE, ask = TRUE, ncol, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.modelDiagnostics.lm_+3A_x">x</code></td>
<td>
<p>A <code>modelDiagnostics</code> class object from lm.</p>
</td></tr>
<tr><td><code id="plot.modelDiagnostics.lm_+3A_y">y</code></td>
<td>
<p>Included to match the generic. Not used.</p>
</td></tr>
<tr><td><code id="plot.modelDiagnostics.lm_+3A_plot">plot</code></td>
<td>
<p>A logical value whether or not to plot the results or
simply return the graaphical  objects.</p>
</td></tr>
<tr><td><code id="plot.modelDiagnostics.lm_+3A_ask">ask</code></td>
<td>
<p>A logical whether to ask before changing plots.
Only applies to interactive environments.</p>
</td></tr>
<tr><td><code id="plot.modelDiagnostics.lm_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns to use for plots.
Missing by default which means individual plots are created.
If specified, plots are put together in a grid.</p>
</td></tr>
<tr><td><code id="plot.modelDiagnostics.lm_+3A_...">...</code></td>
<td>
<p>Included to match the generic. Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list including plots of the residuals,
residuals versus fitted values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testm &lt;- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)

md &lt;- modelDiagnostics(testm, ev.perc = .1)

plot(md)
plot(md, ncol = 2)

## clean up
rm(testm, md)
</code></pre>

<hr>
<h2 id='plot.residualDiagnostics'>Plot Residual Diagnostics Default Method</h2><span id='topic+plot.residualDiagnostics'></span>

<h3>Description</h3>

<p>This function creates a number of diagnostic plots
from residuals. It is a default method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'residualDiagnostics'
plot(x, y, plot = TRUE, ask = TRUE, ncol, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.residualDiagnostics_+3A_x">x</code></td>
<td>
<p>A <code>residualDiagnostics</code> class object.</p>
</td></tr>
<tr><td><code id="plot.residualDiagnostics_+3A_y">y</code></td>
<td>
<p>Included to match the generic. Not used.</p>
</td></tr>
<tr><td><code id="plot.residualDiagnostics_+3A_plot">plot</code></td>
<td>
<p>A logical value whether or not to plot the results or
simply return the graphical objects.</p>
</td></tr>
<tr><td><code id="plot.residualDiagnostics_+3A_ask">ask</code></td>
<td>
<p>A logical whether to ask before changing plots.
Only applies to interactive environments.</p>
</td></tr>
<tr><td><code id="plot.residualDiagnostics_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns to use for plots.
Missing by default which means individual plots are created.
If specified, plots are put together in a grid.</p>
</td></tr>
<tr><td><code id="plot.residualDiagnostics_+3A_...">...</code></td>
<td>
<p>Included to match the generic. Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list including plots of the residuals,
residuals versus fitted values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testm &lt;- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)
testm &lt;- stats::lm(mpg ~ factor(cyl), data = mtcars)

md &lt;- residualDiagnostics(testm, ev.perc = .1)

plot(md, plot = FALSE)$ResFittedPlot
plot(md, ncol = 2)

## clean up
rm(testm, md)
</code></pre>

<hr>
<h2 id='plot.SEMSummary'>Plots SEMSummary object</h2><span id='topic+plot.SEMSummary'></span>

<h3>Description</h3>

<p>Plots SEMSummary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SEMSummary'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SEMSummary_+3A_x">x</code></td>
<td>
<p>An object of class SEMSummary.</p>
</td></tr>
<tr><td><code id="plot.SEMSummary_+3A_y">y</code></td>
<td>
<p>Ignored</p>
</td></tr>
<tr><td><code id="plot.SEMSummary_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the real workhorse, <code>corplot</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+corplot">corplot</a></code>, <code><a href="#topic+SEMSummary">SEMSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># default plot
plot(SEMSummary(~ ., data = mtcars))

# same as default
plot(SEMSummary(~ ., data = mtcars), type = "coverage")

# shows p values
plot(SEMSummary(~ ., data = mtcars), type = "p")

# shows correlations
plot(SEMSummary(~ ., data = mtcars), type = "cor")
</code></pre>

<hr>
<h2 id='plot.SEMSummary.list'>Plots SEMSummary.list object</h2><span id='topic+plot.SEMSummary.list'></span>

<h3>Description</h3>

<p>Plots SEMSummary.list object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SEMSummary.list'
plot(x, y, which, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SEMSummary.list_+3A_x">x</code></td>
<td>
<p>An object of class SEMSummary.list.</p>
</td></tr>
<tr><td><code id="plot.SEMSummary.list_+3A_y">y</code></td>
<td>
<p>Ignored</p>
</td></tr>
<tr><td><code id="plot.SEMSummary.list_+3A_which">which</code></td>
<td>
<p>either a numeric vector based on the positions,
or a character vector giving the names of the levels of the
list to plot.</p>
</td></tr>
<tr><td><code id="plot.SEMSummary.list_+3A_plot">plot</code></td>
<td>
<p>A logical, whether to actually plot the results or not.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.SEMSummary.list_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the real workhorse, <code>corplot</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+corplot">corplot</a></code>, <code><a href="#topic+SEMSummary">SEMSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## correlation matrix by am level
plot(SEMSummary(~ . | am, data = mtcars))
</code></pre>

<hr>
<h2 id='plot.testDistribution'>Plot method for testDistribution objects</h2><span id='topic+plot.testDistribution'></span>

<h3>Description</h3>

<p>Make plots of testDistribution objects, including
density and QQ plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'testDistribution'
plot(
  x,
  y,
  xlim = NULL,
  varlab = "X",
  plot = TRUE,
  rugthreshold = 500,
  seed = 1234,
  factor = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.testDistribution_+3A_x">x</code></td>
<td>
<p>A list of class &ldquo;testDistribution&rdquo;.</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_y">y</code></td>
<td>
<p>Included to match the generic. Not used.</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_xlim">xlim</code></td>
<td>
<p>An optional vector to control the x limits for the theoretical distribution
density line, useful when densities become extreme at boundary values to help keep the
scale of the graph reasonable.  Passed on to <code>stat_function</code>.</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_varlab">varlab</code></td>
<td>
<p>A character vector the label to use for the variable</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_plot">plot</code></td>
<td>
<p>A logical vector whether to plot the graphs. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_rugthreshold">rugthreshold</code></td>
<td>
<p>Integer determining the number of observations beyond
which no rug plot is added. Note that even if this threshold is exceeded,
a rug plot will still be added for any extreme values (if extreme values are
used and present).</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_seed">seed</code></td>
<td>
<p>a random seed used to make the jitter added for Poisson and
Negative Binomial distributions reproducible</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_factor">factor</code></td>
<td>
<p>A scale factor fo the amount of jitter added to the QQ and Deviates
plots for Poisson and Negative Binomial distributions. Defaults to 1.
This results in 1 * smallest distance between points / 5 being used.</p>
</td></tr>
<tr><td><code id="plot.testDistribution_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An invisible list with the ggplot2 objects for graphs,
as well as information about the distribution (parameter estimates,
name, log likelihood (useful for comparing the fit of different distributions
to the data), and a dataset with the sorted data and theoretical quantiles.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+testDistribution">testDistribution</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## evaluate mpg against a normal distribution
plot(testDistribution(mtcars$mpg))

## Not run: 

## example data
set.seed(1234)
d &lt;- data.table::data.table(
  Ynorm = rnorm(200),
  Ybeta = rbeta(200, 1, 4),
  Ychisq = rchisq(200, 8),
  Yf = rf(200, 5, 10),
  Ygamma = rgamma(200, 2, 2),
  Ynbinom = rnbinom(200, mu = 4, size = 9),
  Ypois = rpois(200, 4))

## testing and graphing
plot(testDistribution(d$Ybeta, "beta", starts = list(shape1 = 1, shape2 = 4)))
plot(testDistribution(d$Ychisq, "chisq", starts = list(df = 8)))

## for chi-square distribution, extreme values only on
## the right tail
plot(testDistribution(d$Ychisq, "chisq", starts = list(df = 8),
  extremevalues = "empirical", ev.perc = .1))
plot(testDistribution(d$Ychisq, "chisq", starts = list(df = 8),
  extremevalues = "theoretical", ev.perc = .1))

plot(testDistribution(d$Yf, "f", starts = list(df1 = 5, df2 = 10)))
plot(testDistribution(d$Ygamma, "gamma"))
plot(testDistribution(d$Ynbinom, "poisson"))
plot(testDistribution(d$Ynbinom, "nbinom"))
plot(testDistribution(d$Ypois, "poisson"))

## compare log likelihood of two different distributions
testDistribution(d$Ygamma, "normal")$Distribution$LL
testDistribution(d$Ygamma, "gamma")$Distribution$LL

plot(testDistribution(d$Ynorm, "normal"))
plot(testDistribution(c(d$Ynorm, 10, 1000), "normal",
  extremevalues = "theoretical"))
plot(testDistribution(c(d$Ynorm, 10, 1000), "normal",
  extremevalues = "theoretical", robust = TRUE))

plot(testDistribution(mtcars, "mvnormal"))

## for multivariate normal mahalanobis distance
## which follows a chi-square distribution, extreme values only on
## the right tail
plot(testDistribution(mtcars, "mvnormal", extremevalues = "empirical",
  ev.perc = .1))
plot(testDistribution(mtcars, "mvnormal", extremevalues = "theoretical",
  ev.perc = .1))

rm(d) ## cleanup

## End(Not run)
</code></pre>

<hr>
<h2 id='R2'>Calculate R2 Values</h2><span id='topic+R2'></span><span id='topic+R2.lm'></span>

<h3>Description</h3>

<p>Generic function to return variance explained (R2)
estimates from various models. In some cases these will be true
R2 values, in other cases they may be pseudo-R2 values if
R2 is not strictly defined for a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2(object, ...)

## S3 method for class 'lm'
R2(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2_+3A_object">object</code></td>
<td>
<p>A fitted model object.</p>
</td></tr>
<tr><td><code id="R2_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to specific methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depends on the method dispatch.
</p>
<p>The raw and adjusted r-squared value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>R2(lm(mpg ~ qsec * hp, data = mtcars))
</code></pre>

<hr>
<h2 id='residualDiagnostics'>Residual Diagnostics Functions</h2><span id='topic+residualDiagnostics'></span><span id='topic+as.residualDiagnostics'></span><span id='topic+is.residualDiagnostics'></span><span id='topic+residualDiagnostics.lm'></span>

<h3>Description</h3>

<p>A set of functions to calculate
residual diagnostics on models, including constructors,
a generic function, a test of whether an object is of the
<code>residualDiagnostics</code> class, and methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residualDiagnostics(object, ...)

as.residualDiagnostics(x)

is.residualDiagnostics(x)

## S3 method for class 'lm'
residualDiagnostics(
  object,
  ev.perc = 0.001,
  robust = FALSE,
  distr = "normal",
  standardized = TRUE,
  cut = 4L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residualDiagnostics_+3A_object">object</code></td>
<td>
<p>A fitted model object, with methods for
<code>model.frame</code>, <code>resid</code> and <code>fitted</code>.</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_...">...</code></td>
<td>
<p>Additional arguments, not currently used.</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_x">x</code></td>
<td>
<p>A object (e.g., list or a modelDiagnostics object) to
test or attempt coercing to a residualDiagnostics object.</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_ev.perc">ev.perc</code></td>
<td>
<p>A real number between 0 and 1 indicating the
proportion of the theoretical distribution beyond which
values are considered extreme values (possible outliers).
Defaults to .001.</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_robust">robust</code></td>
<td>
<p>Whether to use robust mean and standard deviation estimates
for normal distribution</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_distr">distr</code></td>
<td>
<p>A character string given the assumed distribution.
Passed on to <code><a href="#topic+testDistribution">testDistribution</a></code>.
Defaults to &ldquo;normal&rdquo;.</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_standardized">standardized</code></td>
<td>
<p>A logical whether to use standardized residuals.
Defaults to <code>TRUE</code> generally where possible but may depend on
method.</p>
</td></tr>
<tr><td><code id="residualDiagnostics_+3A_cut">cut</code></td>
<td>
<p>An integer, how many unique predicted values
there have to be at least for predicted values to be
treated continuously, otherwise they are treated as discrete values.
Defaults to 4.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical (<code>is.residualDiagnostics</code>) or
a residualDiagnostics object (list) for
<code>as.residualDiagnostics</code> and <code>residualDiagnostics</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testm &lt;- stats::lm(mpg ~ hp * factor(cyl), data = mtcars)

resm &lt;- residualDiagnostics(testm)
plot(resm$testDistribution)

resm &lt;- residualDiagnostics(testm, standardized = FALSE)
plot(resm$testDistribution)

## clean up
rm(testm, resm)
## Not run: 

testdat &lt;- data.frame(
  y = c(1, 2, 2, 3, 3, NA, 9000000, 2, 2, 1),
  x = c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2))

residualDiagnostics(
  lm(y ~ x, data = testdat, na.action = "na.omit"),
  ev.perc = .1)$Residuals

residualDiagnostics(
  lm(y ~ x, data = testdat, na.action = "na.exclude"),
  ev.perc = .1)$Residuals

residualDiagnostics(
  lm(sqrt(mpg) ~ hp, data = mtcars, na.action = "na.omit"),
  ev.perc = .1)$Residuals

## End(Not run)
</code></pre>

<hr>
<h2 id='roundedfivenum'>Calculate a rounded five number summary</h2><span id='topic+roundedfivenum'></span>

<h3>Description</h3>

<p>Numbers are the minimum, 25th percentile, median,
75th percentile, and maximum, of the non missing data.
Values returned are either the significant digits or rounded values,
whichever ends up resulting in the fewest total digits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roundedfivenum(x, round = 2, sig = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roundedfivenum_+3A_x">x</code></td>
<td>
<p>The data to have the summary calculated on</p>
</td></tr>
<tr><td><code id="roundedfivenum_+3A_round">round</code></td>
<td>
<p>The number of digits to try rounding</p>
</td></tr>
<tr><td><code id="roundedfivenum_+3A_sig">sig</code></td>
<td>
<p>The number of significant digits to try</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The rounded or significant digit five number summary
</p>


<h3>Examples</h3>

<pre><code class='language-R'>JWileymisc:::roundedfivenum(rnorm(1000))
JWileymisc:::roundedfivenum(mtcars$hp)
</code></pre>

<hr>
<h2 id='scoring'>Score a set of items to create overall scale score - generic</h2><span id='topic+scoring'></span><span id='topic+score'></span><span id='topic+.scoreCESD'></span><span id='topic+.scoreLOTR'></span><span id='topic+.scoreMastery'></span><span id='topic+.scoreMOSSSS'></span><span id='topic+.scorePANAS'></span><span id='topic+.scoreRSES'></span><span id='topic+.scoreMOOD'></span><span id='topic+scaleScore'></span>

<h3>Description</h3>

<p>Score a set of items to create overall scale score - generic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score(
  data,
  reverse = NULL,
  limits = NULL,
  mean = TRUE,
  reliability = TRUE,
  na.rm = TRUE,
  ...
)

.scoreCESD(data, okay = c(0, 1, 2, 3), reverse = c(4, 8, 12, 16), ...)

.scoreLOTR(
  data,
  okay = c(1, 2, 3, 4, 5),
  reverse = c(2, 4, 5),
  indices = list(oindex = c(1, 3, 6), pindex = c(2, 4, 5)),
  ...
)

.scoreMastery(data, okay = c(1, 2, 3, 4), reverse = c(1, 6), ...)

.scoreMOSSSS(
  data,
  okay = c(1, 2, 3, 4, 5),
  indices = list(Structural = 1, Tangible = c(2, 5, 12, 15), Affectionate = c(6, 10, 20),
    PositiveInteraction = c(7, 11, 18), EmotionalInformational = c(3, 9, 16, 19, 4, 8,
    13, 17), Functional = 2:20),
  ...
)

.scorePANAS(
  data,
  okay = c(1, 2, 3, 4, 5),
  indices = list(pos = c(1, 3, 5, 9, 10, 12, 14, 16, 17, 19), neg = c(2, 4, 6, 7, 8, 11,
    13, 15, 18, 20)),
  ...
)

.scoreRSES(data, okay = c(0, 1, 2, 3), reverse = c(3, 5, 8, 9, 10), ...)

.scoreMOOD(
  data,
  indices = list(vision = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19), impact =
    c(13, 14, 15, 16, 17, 20, 21)),
  ...
)

scaleScore(
  data,
  type = c("CESD", "LOTR", "Mastery", "RSES", "MOSSSS", "PANAS"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoring_+3A_data">data</code></td>
<td>
<p>A data frame or an object coercable to a data frame.</p>
</td></tr>
<tr><td><code id="scoring_+3A_reverse">reverse</code></td>
<td>
<p>A vector the same length as the number of columns in the data</p>
</td></tr>
<tr><td><code id="scoring_+3A_limits">limits</code></td>
<td>
<p>An optional vector indicating the lower and upper possible limits (for reversing)</p>
</td></tr>
<tr><td><code id="scoring_+3A_mean">mean</code></td>
<td>
<p>Logical whether to calculate the mean if <code>TRUE</code> or sum if <code>FALSE</code></p>
</td></tr>
<tr><td><code id="scoring_+3A_reliability">reliability</code></td>
<td>
<p>Logical whether or not to calculate reliability information for the scale.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="scoring_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical whether to remove missing values or not. Defaults to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="scoring_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to lower level functions</p>
</td></tr>
<tr><td><code id="scoring_+3A_okay">okay</code></td>
<td>
<p>A vector of okay or acceptable values</p>
</td></tr>
<tr><td><code id="scoring_+3A_indices">indices</code></td>
<td>
<p>Indicates columns for subscales, where applicable</p>
</td></tr>
<tr><td><code id="scoring_+3A_type">type</code></td>
<td>
<p>A character string indicating the scale name, the type of scoring to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results.
</p>
<table>
<tr><td><code>score</code></td>
<td>
<p>The calculated scores.</p>
</td></tr>
<tr><td><code>reliability</code></td>
<td>
<p>Results from the omega function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="psych.html#topic+omega">omega</a></code>
</p>

<hr>
<h2 id='SEMSummary'>Summary Statistics for a SEM Analysis</h2><span id='topic+SEMSummary'></span>

<h3>Description</h3>

<p>This function is designed to calculate the descriptive statistics and
summaries that are often reported on raw data when the main analyses
use structural equation modelling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SEMSummary(
  formula,
  data,
  use = c("fiml", "pairwise.complete.obs", "complete.obs")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SEMSummary_+3A_formula">formula</code></td>
<td>
<p>A formula of the variables to be used in the analysis.
See the &lsquo;details&rsquo; section for more information.</p>
</td></tr>
<tr><td><code id="SEMSummary_+3A_data">data</code></td>
<td>
<p>A data frame, matrix, or list containing the variables
used in the formula.  This is a required argument.</p>
</td></tr>
<tr><td><code id="SEMSummary_+3A_use">use</code></td>
<td>
<p>A character vector of how to handle missing data. Defaults to &ldquo;fiml&rdquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates a variety of relevant statistics on the raw
data used in a SEM analysis.  Because it is meant for SEM style data,
for now it expects all variables to be numeric.  In the future I may
try to expand it to handle factor variables somehow.
</p>
<p>Both the formula and data arguments are required.  The formula should
be the right hand side only.  The most common way to use it would be with
variable names separated by &lsquo;+s&rsquo;.  For convenience, a &lsquo;.&rsquo; is
expanded to mean &ldquo;all variables in the data set&rdquo;.  For a large number
of variables or when whole datasets are being analyzed, this can be considerably
easier to write.  Also it facilitates column indexing by simply passing a subset
of the data (e.g., <code>data[, 1:10]</code>) and using the &lsquo;.&rsquo; expansion to
analyze the first 10 columns.  The examples section demonstrate this use.
</p>
<p>Also noteworthy is that <code>SEMSummary</code> is not really meant to be used
on its own.  It is the computational workhorse, but it is meant to be used
with a styling or printing method to produce simple output.
<code>APAStyler</code> has methods for <code>SEMSummary</code> output.
</p>
<p>There are several new ways to handle missing data now
including listwise deletion, pairwise deletion, and using the EM
algorithm, the default.
</p>


<h3>Value</h3>

<p>A list with S3 class &ldquo;SEMSummary&rdquo;
</p>
<table>
<tr><td><code>names</code></td>
<td>
<p>A character vector containing the variable names.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>An integer vector of the length of each variable used
(this includes available and missing data).</p>
</td></tr>
<tr><td><code>nmissing</code></td>
<td>
<p>An integer vector of the number of missing values in each variable.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A vector of the arithmetic means of each variable (on complete data).</p>
</td></tr>
<tr><td><code>stdev</code></td>
<td>
<p>A numeric vector of the standard deviations of each variable (on complete data).</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>The numeric covariance matrix for all variables.</p>
</td></tr>
<tr><td><code>sSigma</code></td>
<td>
<p>The numeric correlation matrix for all variables.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>A numeric matrix giving the percentage (technically decimal)
of information available for each pairwise covariance/correlation.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>The two-sided p values for the correlation matrix. Pairwise present N
used to calculate degrees of freedom.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+APAStyler">APAStyler</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example using the built in iris dataset
s &lt;- SEMSummary(~ Sepal.Length + Sepal.Width + Petal.Length, data = iris)
s # show output ... not very nice

## Prettier output from SEMSummary
APAStyler(s)

#### Subset the dataset and use the . expansion ####

## summary for all variables in mtcars data set
## with 11 variables, this could be a pain to write out
SEMSummary(~ ., data = mtcars)

## . expansion is also useful when we know column positions
## but not necessarily names
SEMSummary(~ ., data = mtcars[, c(1, 2, 3, 9, 10, 11)])

## clean up
rm(s)

## sample data
Xmiss &lt;- as.matrix(iris[, -5])
# make q0% missing completely at random
set.seed(10)
Xmiss[sample(length(Xmiss), length(Xmiss) * .10)] &lt;- NA
Xmiss &lt;- as.data.frame(Xmiss)

SEMSummary(~ ., data = Xmiss, use = "fiml")


## pairwise
APAStyler(SEMSummary(~ ., data = Xmiss, use = "pair"),
  type = "cor")

## same as cor()
cor(Xmiss, use = "pairwise.complete.obs")

## complete cases only
SEMSummary(~ ., data = Xmiss, use = "comp")

## clean up
rm(Xmiss)
</code></pre>

<hr>
<h2 id='SEMSummary.fit'>Summary Statistics for a SEM Analysis</h2><span id='topic+SEMSummary.fit'></span>

<h3>Description</h3>

<p>This is a low level fitting function, for SEMSummary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SEMSummary.fit(
  formula,
  data,
  use = c("fiml", "pairwise.complete.obs", "complete.obs")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SEMSummary.fit_+3A_formula">formula</code></td>
<td>
<p>A formula of the variables to be used in the analysis.
See the &lsquo;details&rsquo; section for more information.</p>
</td></tr>
<tr><td><code id="SEMSummary.fit_+3A_data">data</code></td>
<td>
<p>A data frame, matrix, or list containing the variables
used in the formula.  This is a required argument.</p>
</td></tr>
<tr><td><code id="SEMSummary.fit_+3A_use">use</code></td>
<td>
<p>A character vector of how to handle missing data. Defaults to &ldquo;fiml&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with S3 class &ldquo;SEMSummary&rdquo;
</p>
<table>
<tr><td><code>names</code></td>
<td>
<p>A character vector containing the variable names.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>An integer vector of the length of each variable used
(this includes available and missing data).</p>
</td></tr>
<tr><td><code>nmissing</code></td>
<td>
<p>An integer vector of the number of missing values in each variable.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A vector of the arithmetic means of each variable (on complete data).</p>
</td></tr>
<tr><td><code>stdev</code></td>
<td>
<p>A numeric vector of the standard deviations of each variable (on complete data).</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>The numeric covariance matrix for all variables.</p>
</td></tr>
<tr><td><code>sSigma</code></td>
<td>
<p>The numeric correlation matrix for all variables.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>A numeric matrix giving the percentage (technically decimal)
of information available for each pairwise covariance/correlation.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>The two-sided p values for the correlation matrix. Pairwise present N
used to calculate degrees of freedom.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+SEMSummary">SEMSummary</a></code>
</p>

<hr>
<h2 id='smd'>Calculate Standardized Mean Difference (SMD)</h2><span id='topic+smd'></span>

<h3>Description</h3>

<p>Simple function to calculate effect sizes for mean differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smd(x, g, index = c("all", "1", "2"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smd_+3A_x">x</code></td>
<td>
<p>A continuous variable</p>
</td></tr>
<tr><td><code id="smd_+3A_g">g</code></td>
<td>
<p>A grouping variable, with two levels</p>
</td></tr>
<tr><td><code id="smd_+3A_index">index</code></td>
<td>
<p>A character string: &ldquo;all&rdquo; uses pooled variance,
&ldquo;1&rdquo; uses the first factor level variance,
&ldquo;2&rdquo; uses the second factor level variance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standardized mean difference.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>smd(mtcars$mpg, mtcars$am)
smd(mtcars$mpg, mtcars$am, "all")
smd(mtcars$mpg, mtcars$am, "1")
smd(mtcars$mpg, mtcars$am, "2")

smd(mtcars$hp, mtcars$vs)

d &lt;- data.table::as.data.table(mtcars)
d[, smd(mpg, vs)]
rm(d)
</code></pre>

<hr>
<h2 id='star'>Function to simplify converting p-values to asterisks</h2><span id='topic+star'></span>

<h3>Description</h3>

<p>Function to simplify converting p-values to asterisks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>star(x, includeMarginal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="star_+3A_x">x</code></td>
<td>
<p>p values to convert to stars</p>
</td></tr>
<tr><td><code id="star_+3A_includemarginal">includeMarginal</code></td>
<td>
<p>logical value whether to include a symbol for
marginally significant &gt;.05 but &lt; .10 p-values. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string with stars
</p>


<h3>Examples</h3>

<pre><code class='language-R'>star(c(.0005, .001, .005, .01, .02, .05, .08, .1, .5, 1))
</code></pre>

<hr>
<h2 id='styledescriptives'>Several internal functions to style descriptive statistics</h2><span id='topic+styledescriptives'></span>

<h3>Description</h3>

<p>Several internal functions to style descriptive statistics
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="styledescriptives_+3A_n">n</code></td>
<td>
<p>A character string giving the variable name (just the name)</p>
</td></tr>
<tr><td><code id="styledescriptives_+3A_x">x</code></td>
<td>
<p>A variable (actual data, not just the name)</p>
</td></tr>
<tr><td><code id="styledescriptives_+3A_digits">digits</code></td>
<td>
<p>An integer indicating the number of significant digits to use.
Defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="styledescriptives_+3A_includelabel">includeLabel</code></td>
<td>
<p>A logical value, whether or not to include the type of
descriptive statistics in the label/name.
Only applies to some functions. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data table with results.
</p>

<hr>
<h2 id='styletests'>Several internal functions to style inference tests</h2><span id='topic+styletests'></span><span id='topic+.styleaov'></span><span id='topic+.style2sttest'></span><span id='topic+.stylepairedttest'></span><span id='topic+.stylepairedwilcox'></span><span id='topic+.stylepairedmcnemar'></span><span id='topic+.stylekruskal'></span><span id='topic+.stylechisq'></span><span id='topic+.stylemsd'></span><span id='topic+.stylemdniqr'></span><span id='topic+.stylefreq'></span>

<h3>Description</h3>

<p>Several internal functions to style inference tests
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.styleaov(dv, g, digits = 2L, pdigits = 3L)

.style2sttest(dv, g, digits = 2, pdigits = 3)

.stylepairedttest(dv, g, ID, digits = 2, pdigits = 3)

.stylepairedwilcox(dv, g, ID, digits = 2, pdigits = 3)

.stylepairedmcnemar(dv, g, ID, digits = 2, pdigits = 3)

.stylekruskal(dv, g, digits = 2, pdigits = 3)

.stylechisq(dv, g, digits = 2, pdigits = 3, simChisq = FALSE, sims = 10000)

.stylemsd(n, x, digits = 2, includeLabel = FALSE)

.stylemdniqr(n, x, digits = 2, includeLabel = FALSE)

.stylefreq(n, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="styletests_+3A_dv">dv</code></td>
<td>
<p>An outcome variable</p>
</td></tr>
<tr><td><code id="styletests_+3A_g">g</code></td>
<td>
<p>A grouping/predictor variable</p>
</td></tr>
<tr><td><code id="styletests_+3A_digits">digits</code></td>
<td>
<p>An integer indicating the number of significant digits to use.
Defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="styletests_+3A_pdigits">pdigits</code></td>
<td>
<p>An integer indicating the number of digits for p values.
Defaults to <code>3</code>.</p>
</td></tr>
<tr><td><code id="styletests_+3A_simchisq">simChisq</code></td>
<td>
<p>A logical value, whether or not to simulate chi-square values.
Only applies to some functions. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="styletests_+3A_sims">sims</code></td>
<td>
<p>An integer indicating the number of simulations to conduct.
Only applies to some functions. Defaults to <code>10000</code>, but this is
arbitrary and should be chosen.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string of the formatted results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
JWileymisc:::.styleaov(mtcars$mpg, mtcars$cyl)

JWileymisc:::.style2sttest(mtcars$mpg, mtcars$am)

JWileymisc:::.stylepairedttest(sleep$extra, sleep$group, sleep$ID)

JWileymisc:::.stylepairedwilcox(sleep$extra, sleep$group, sleep$ID)

## example data
set.seed(1234)
exdata &lt;- data.frame(
  ID = rep(1:10, 2),
  Time = rep(c("base", "post"), each = 10),
  Rating = sample(c("good", "bad"), size = 20, replace = TRUE))
JWileymisc:::.stylepairedmcnemar(exdata$Rating, exdata$Time, exdata$ID)
rm(exdata) ## cleanup

JWileymisc:::.stylekruskal(mtcars$mpg, mtcars$am)
JWileymisc:::.stylekruskal(mtcars$mpg, mtcars$cyl)

JWileymisc:::.stylechisq(mtcars$cyl, mtcars$am)

JWileymisc:::.stylemsd("Miles per Gallon", mtcars$mpg)
JWileymisc:::.stylemsd("Miles per Gallon", mtcars$mpg, includeLabel = TRUE)

JWileymisc:::.stylemdniqr("Miles per Gallon", mtcars$mpg)
JWileymisc:::.stylemdniqr("Miles per Gallon", mtcars$mpg, includeLabel = TRUE)

JWileymisc:::.stylefreq("Transmission", mtcars$am)
JWileymisc:::.stylefreq("Transmission", mtcars$am)
</code></pre>

<hr>
<h2 id='testDistribution'>Test the distribution of a variable against a specific distribution</h2><span id='topic+testDistribution'></span><span id='topic+as.testDistribution'></span><span id='topic+is.testDistribution'></span><span id='topic+testDistribution.default'></span>

<h3>Description</h3>

<p>Function designed to help examine distributions.
It also includes an option for assessing multivariate normality using the
(squared) Mahalanobis distance. A generic function, some methods, and
constructor (<code>as.testDistribution</code>) and function to check class
(<code>is.testDistribution</code>) also are provided.
</p>
<p>Note that for the <code>use</code> argument, several options are possible.
By default it is &ldquo;complete.obs&rdquo;, which uses only cases with complete
data on all variables.
Another option is &ldquo;pairwise.complete.obs&rdquo;, which uses
all available data for each variable indivdiually to estimate the means and
variances, and all pairwise complete observation pairs for each covariance. Because
the same cases are not used for all estimates, it is possible to obtain a covariance
matrix that is not positive definite (e.g., correlations &gt; +1 or &lt; -1).
</p>
<p>Finally, the last option is &ldquo;fiml&rdquo;, which uses full information maximum likelihood
estimates of the means and covariance matrix.  Depending on the number of cases,
missing data patterns, and variables, this may be quite slow and computationally
demanding.
</p>
<p>The <code>robust</code> argument determines whether to use robust estimates or not
when calculating densities, etc.  By default it is <code>FALSE</code>, but if
<code>TRUE</code> and a univariate or multivariate normal distribution is tested,
then robust estimates of the means and covariance matrix (a variance if univariate)
will be used based on <code>covMcd</code> from the <span class="pkg">robustbase</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testDistribution(x, ...)

as.testDistribution(x)

is.testDistribution(x)

## Default S3 method:
testDistribution(
  x,
  distr = c("normal", "beta", "chisq", "f", "gamma", "geometric", "nbinom", "poisson",
    "uniform", "mvnormal"),
  na.rm = TRUE,
  starts,
  extremevalues = c("no", "theoretical", "empirical"),
  ev.perc = 0.005,
  use = c("complete.obs", "pairwise.complete.obs", "fiml"),
  robust = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="testDistribution_+3A_x">x</code></td>
<td>
<p>The data as a single variable or vector to check the distribution unless
the distribution is &ldquo;mvnormal&rdquo; in which case it should be a data frame or
data table.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_...">...</code></td>
<td>
<p>Additional arguments. If these include mu and sigma and the distribution
is multivariate normal, then it will use the passed values instead of calculating
the mean and covariances of the data.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_distr">distr</code></td>
<td>
<p>A character string indicating the distribution to be tested.
Currently one of: &ldquo;normal&rdquo;, &ldquo;beta&rdquo;, &ldquo;chisq&rdquo; (chi-squared),
&ldquo;f&rdquo;, &ldquo;gamma&rdquo;, &ldquo;geometric&rdquo;, &ldquo;nbinom&rdquo; (negative binomial),
&ldquo;poisson&rdquo;, &ldquo;uniform&rdquo;, or &ldquo;mvnormal&rdquo; for multivariate normal where Mahalanobis
distances are calculated and compared against a Chi-squared distribution with
degrees of freedom equal to the number of variables.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value whether to omit missing values. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_starts">starts</code></td>
<td>
<p>A named list of the starting values. Not required for all distributions.
Passed on to <code>fitdistr</code> which fits the maximum likelihood estimates of the
distribution parameters.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_extremevalues">extremevalues</code></td>
<td>
<p>A character vector whether to indicate extreme values.
Should be &ldquo;no&rdquo; to do nothing, &ldquo;empirical&rdquo; to show extreme
values based on the observed data percentiles, or &ldquo;theoretical&rdquo;
to show extreme values based on percentiles of the theoretical distribution.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_ev.perc">ev.perc</code></td>
<td>
<p>Percentile to use for extreme values.  For example if .01,
then the lowest 1 percent and highest 1 percent will be labelled
extreme values.  Defaults to the lowest and highest 0.5 percent.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_use">use</code></td>
<td>
<p>A character vector indicating how the moments
(means and covariance matrix) should be estimated in the presence of
missing data when <code>distr = mvnormal</code>.
The default is to use complete observations, but
full information maximum likelihood based on functions in
<span class="pkg">lavaan</span> is also available.  See details.</p>
</td></tr>
<tr><td><code id="testDistribution_+3A_robust">robust</code></td>
<td>
<p>A logical whether to use robust estimation or not.
Currently only applies to normally distributed data
(univariate or multivariate).  Also, when <code>robust = TRUE</code>,
only complete observations are used (i.e., <code>use = "complete.obs"</code>).
See details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical whether or not an object is of class
<code>testDistribution</code> or an object of the same class.
</p>
<p>A list with information about the distribution (parameter estimates,
name, log likelihood (useful for comparing the fit of different distributions
to the data), and a dataset with the sorted data and theoretical quantiles.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SEMSummary">SEMSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example data
set.seed(1234)
d &lt;- data.table::data.table(
  Ynorm = rnorm(200),
  Ybeta = rbeta(200, 1, 4),
  Ychisq = rchisq(200, 8),
  Yf = rf(200, 5, 10),
  Ygamma = rgamma(200, 2, 2),
  Ynbinom = rnbinom(200, mu = 4, size = 9),
  Ypois = rpois(200, 4))

## testing and graphing
testDistribution(d$Ybeta, "beta", starts = list(shape1 = 1, shape2 = 4))
testDistribution(d$Ychisq, "chisq", starts = list(df = 8))

## for chi-square distribution, extreme values only on
## the right tail
testDistribution(d$Ychisq, "chisq", starts = list(df = 8),
  extremevalues = "empirical", ev.perc = .1)
testDistribution(d$Ychisq, "chisq", starts = list(df = 8),
  extremevalues = "theoretical", ev.perc = .1)

## Not run: 

testDistribution(d$Yf, "uniform")
testDistribution(d$Ypois, "geometric")

testDistribution(d$Yf, "f", starts = list(df1 = 5, df2 = 10))
testDistribution(d$Ygamma, "gamma")
testDistribution(d$Ynbinom, "poisson")
testDistribution(d$Ynbinom, "nbinom")
testDistribution(d$Ypois, "poisson")

## compare log likelihood of two different distributions
testDistribution(d$Ygamma, "normal")$Distribution$LL
testDistribution(d$Ygamma, "gamma")$Distribution$LL

testDistribution(d$Ynorm, "normal")
testDistribution(c(d$Ynorm, 10, 1000), "normal",
  extremevalues = "theoretical")
testDistribution(c(d$Ynorm, 10, 1000), "normal",
  extremevalues = "theoretical", robust = TRUE)

testDistribution(mtcars, "mvnormal")

## for multivariate normal mahalanobis distance
## which follows a chi-square distribution, extreme values only on
## the right tail
testDistribution(mtcars, "mvnormal", extremevalues = "empirical",
  ev.perc = .1)
testDistribution(mtcars, "mvnormal", extremevalues = "theoretical",
  ev.perc = .1)

rm(d) ## cleanup

## End(Not run)
</code></pre>

<hr>
<h2 id='timeshift'>Shift a time variable to have a new center (zero point)</h2><span id='topic+timeshift'></span>

<h3>Description</h3>

<p>Given a vector, shift the values to have a new center, but keeping the same
minimum and maximum.  Designed to work with time values where
the minimum indicates the same time as the maximum (e.g.,
24:00:00 is the same as 00:00:00).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeshift(x, center = 0, min = 0, max = 1, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timeshift_+3A_x">x</code></td>
<td>
<p>the time scores to shift</p>
</td></tr>
<tr><td><code id="timeshift_+3A_center">center</code></td>
<td>
<p>A value (between the minimum and maximum) to center
the time scores. Defaults to 0, which has no effect.</p>
</td></tr>
<tr><td><code id="timeshift_+3A_min">min</code></td>
<td>
<p>The theoretical minimum of the time scores.
Defaults to 0.</p>
</td></tr>
<tr><td><code id="timeshift_+3A_max">max</code></td>
<td>
<p>the theoretical maximum of the time scores.
Defaults to 1.</p>
</td></tr>
<tr><td><code id="timeshift_+3A_inverse">inverse</code></td>
<td>
<p>A logical value, whether to &lsquo;unshift&rsquo;
the time scores.  Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of shifted time scores, recentered as specified.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example showing centering at 11am (i.e., 11am becomes new 0)
plot((1:24)/24, timeshift((1:24)/24, 11/24))

## example showing the inverse, note that 24/24 becomes 0
plot((1:24)/24, timeshift(timeshift((1:24)/24, 11/24), 11/24, inverse = TRUE))
</code></pre>

<hr>
<h2 id='TukeyHSDgg'>Tukey HSD Plot</h2><span id='topic+TukeyHSDgg'></span>

<h3>Description</h3>

<p>This calculates and displays means, confidence intervals
as well as which groups are different based on Tukey's HSD.
Inspired by http://stackoverflow.com/questions/18771516/is-there-a-function-to-add-aov-post-hoc-testing-results-to-ggplot2-boxplot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TukeyHSDgg(x, y, d, ci = 0.95, idvar, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TukeyHSDgg_+3A_x">x</code></td>
<td>
<p>A categorical grouping variable name.</p>
</td></tr>
<tr><td><code id="TukeyHSDgg_+3A_y">y</code></td>
<td>
<p>A continuous outcome variable name.</p>
</td></tr>
<tr><td><code id="TukeyHSDgg_+3A_d">d</code></td>
<td>
<p>A dataset</p>
</td></tr>
<tr><td><code id="TukeyHSDgg_+3A_ci">ci</code></td>
<td>
<p>A numeric value indicating the coverage of the
confidence interval to use.  Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="TukeyHSDgg_+3A_idvar">idvar</code></td>
<td>
<p>An optional ID variable for multilevel data</p>
</td></tr>
<tr><td><code id="TukeyHSDgg_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot graph object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## examples using it with single level data
## differences based on an ANOVA and follow up contrasts
mtcars$cyl &lt;- factor(mtcars$cyl)
TukeyHSDgg("cyl", "mpg", mtcars)
rm(mtcars)

## Not run: 
TukeyHSDgg("Species", "Sepal.Length", iris)

## example based on multilevel data
## differences based on model fit with lmer and follow up contrasts
TukeyHSDgg("treatment", "decrease", OrchardSprays, idvar = "colpos")

## End(Not run)
</code></pre>

<hr>
<h2 id='VAConverter'>Visual Acuity Converter</h2><span id='topic+VAConverter'></span>

<h3>Description</h3>

<p>Converter character (string) input of Snellen fractions,
Counting Fingers (CF), and Hand Motion (HM) to logMAR
values for use in statistical models.  Can handle linear
interpolation if passed an appropriate chart or if the
measures fit with the default chart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VAConverter(
  OS,
  OD,
  chart.values = NULL,
  chart.nletters = NULL,
  datatype = c("snellen", "decimal", "logMAR"),
  zero = 3
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VAConverter_+3A_os">OS</code></td>
<td>
<p>The values to be converted for the left eye
(oculus sinister).</p>
</td></tr>
<tr><td><code id="VAConverter_+3A_od">OD</code></td>
<td>
<p>The values to be converted for the right eye
(oculus dexter)</p>
</td></tr>
<tr><td><code id="VAConverter_+3A_chart.values">chart.values</code></td>
<td>
<p>The Snellen fractions for the chart used (if
interpolation is necessary and it is different from the
default).</p>
</td></tr>
<tr><td><code id="VAConverter_+3A_chart.nletters">chart.nletters</code></td>
<td>
<p>The number of letters on each line of the
chart that was used.  Necessary for proper interpolation.</p>
</td></tr>
<tr><td><code id="VAConverter_+3A_datatype">datatype</code></td>
<td>
<p>The type of data passed to <code>OS</code> and
<code>OD</code>.  One of &quot;Snellen&quot; (the default), &quot;decimal&quot;, or
&quot;logMAR&quot;.  Determines what transformations are needed to convert
to logMAR values.</p>
</td></tr>
<tr><td><code id="VAConverter_+3A_zero">zero</code></td>
<td>
<p>The &ldquo;zero&rdquo; logMAR value.  This is used as the
zero point for visual acuity.  For example, for light perception
(LP), no light perception (NLP), etc.  It defaults to 3 (which
is equivalent to a Snellen value of 20/20000), but may also be
<code>NA</code>.  See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>VAConverter</code> is primarily designed to take raw character
data of various forms and convert them to logMAR values.
Acceptable examples include: &quot;20/20&quot;, &quot;20/80 + 3&quot;, &quot;20/20 - 4&quot;,
&quot;10/20&quot;, &quot;CF 10&quot;, &quot;HM 2&quot;, &quot;CF 4&quot;, &quot;NLP&quot;, &quot;LP&quot;, &quot;&quot;, &quot;CF&quot;, &quot;HM&quot;,
etc.  For Snellen values, both parts should be present, and
there should be a space between components; e.g., between
fraction, +/- and number or between CF and 10.  Although I have
attempted to make it as flexible and general as possible, there
are still fairly rigid requirements so that it can parse a
variety of text formats to numerical values.  Optionally, it can
also handle decimal values (i.e., the results of actually
dividing a Snellen value 20/20 = 1).
</p>
<p><code>chart.values</code> and <code>chart.nletters</code> must be the same
length.  These are used to interpolate values such as &quot;20/20 + 3&quot;
which is interpreted as reading all of the letters on the &quot;20/20&quot;
line and &quot;3&quot; of the letters on the next best line (typically
&quot;20/15&quot; but this can be chart dependent).  The functions goes 3/n
of the distance between the logMAR values for each line.  This is
why it is important to know the values for the chart <em>that
was actually used</em>.
</p>
<p>If datatype = &quot;logMAR&quot;, the values passed to <code>OS</code> and
<code>OD</code> are directly assigned to the <code>logMAROS</code> and
<code>logMAROD</code> slots of a <code>"<a href="#topic+VAObject-class">VAObject</a>"</code> and an
error is returned if that results in the creation of an invalid
object (e.g., they are not numeric or not of equal length).
</p>
<p>The <code>zero</code> argument is primarily included to facilitate
calculating averages.  For example, in some cases it may be nice
to get a sense of an individual's &quot;overall&quot; or &quot;average&quot; logMAR
value.  Because on the logMAR scale, 0 is &quot;20/20&quot;, an alternate
number needs to be used.  3 was chosen as a rough default, but it
is by no means necessarily the best choice.  If you are not
interested in computing an average between the left and right eyes
within individuals, it makes sense to simply use <code>NA</code> rather
than a crude &quot;zero&quot; approximation.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+VAObject-class">VAObject</a></code>.  This
includes the left and right eye logMAR values in slots
<code>@logMAROS</code> and <code>@logMAROD</code> as well as additional
information.  More information can be found in the class
documentation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## sampdat &lt;- c("HM 12", "20/20 + 3", "20/50", "CF", "HM",
##              "20/70 - 2", "LP", NA, "Prosthetic")
## tmp &lt;- VAConverter(OS = sampdat, OD = rev(sampdat), datatype = "snellen")
</code></pre>

<hr>
<h2 id='vainternal'>Internal Visual Acuity Functions</h2><span id='topic+vainternal'></span><span id='topic+logmar'></span><span id='topic+CFHM'></span><span id='topic+snellen'></span>

<h3>Description</h3>

<p>This function is one of several designed to help convert measures of
visual acuity recorded typically recorded as Snellen fractions
(e.g., 20/20 sees at 20 feet what is &quot;typically&quot; seen at 20 feet.
20/40 sees at 20 feet what is &quot;typically&quot; seen at 40 feet, etc.)
into statistically usable data.  It can also parse text data
for Counting Fingers (CF) and Hand Motion (HM)  and convert them to
approximate logMAR values.
This is an internal function and is not  meant to be
called directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logmar(x, snell.numerator = 20, inverse = FALSE)

CFHM(x, zero)

snellen(snellenvalue, chart.values, chart.nletters)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vainternal_+3A_x">x</code></td>
<td>
<p>Character data of the form: &ldquo;CF 10&rdquo;, &ldquo;HM 12&rdquo;,
&ldquo;HM&rdquo;, &ldquo;CF&rdquo;, &ldquo;CF 2&rdquo;, etc. to be converted to
logMAR values.</p>
</td></tr>
<tr><td><code id="vainternal_+3A_snell.numerator">snell.numerator</code></td>
<td>
<p>The numerator of a Snellen fraction.
It defaults to 20 (the most common one).</p>
</td></tr>
<tr><td><code id="vainternal_+3A_inverse">inverse</code></td>
<td>
<p><code>inverse</code> = FALSE by default.  If TRUE,
<code>logmar</code> will assume <code>x</code> is a logMAR value, and
calculate the denominator of a Snellen fraction using the
<code>snell.numerator</code> as the numerator.</p>
</td></tr>
<tr><td><code id="vainternal_+3A_zero">zero</code></td>
<td>
<p>A &ldquo;zero&rdquo; logMAR value to be used for any CF or HM
value missing a number.  May be an actual number or simply <code>NA</code></p>
</td></tr>
<tr><td><code id="vainternal_+3A_snellenvalue">snellenvalue</code></td>
<td>
<p>The observed snellen values</p>
</td></tr>
<tr><td><code id="vainternal_+3A_chart.values">chart.values</code></td>
<td>
<p>The chart snellen values</p>
</td></tr>
<tr><td><code id="vainternal_+3A_chart.nletters">chart.nletters</code></td>
<td>
<p>The number of letters per chart line</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This treats CF as approximately 200 letters (per Holladay), so
CF at 10 feet has Snellen value &quot;equivalent&quot; of 10/200. HM is
approximately 10 times worse, so HM at 10 feet approximately
10/2000.  After conversion, rough equivalents are passed to
<code>logmar</code> to actually be converted.
Other functions are responsible for suitably parsing the text and
passing numbers to <code>logmar</code>. If <code>inverse = FALSE</code> (the default),
<code>logmar</code> calculates <code class="reqn">-log_{10}(\frac{snell.numerator}{x})</code>.
If <code>TRUE</code>, then <code class="reqn">\frac{snell.numerator}{10^{-x}}</code>.
</p>
<p>The <code>zero</code> argument is used to specify a &quot;zero&quot; logMAR value.
In particular, this is used when no distance information is given
(e.g., only &quot;HM&quot; or &quot;CF&quot; as opposed to &quot;CF 6&quot; or &quot;HM 4&quot;).
For the reasioning and rational behind this, see the &quot;Details&quot;
section of <code><a href="#topic+VAConverter">VAConverter</a></code>.
</p>
<p>For the <code>snellen</code> function, the input should be character data
and have a numerator and denominator separated by '/'.  E.g.,
&ldquo;20/20&rdquo;, &ldquo;20/40 + 3&rdquo;.  This handles both simple
and Snellen values that need to be interpolated given the
appropriate chart.
</p>
<p>logMAR calculations including interpolating partial lines.
Given &ldquo;20/25 + 3&rdquo;, calculate the logMAR of 20/25 and
20/20 (the next step up since '+'), and go 3/chart.nletters
of the way between these two values.  Similarly if
&ldquo;20/20 - 3&rdquo;, it will go partway between 20/25 and 20/30.
Note that it depends on the lines and letters per line
<em>on the actual chart used</em>. The <code>chart.values</code> and
<code>chart.nletters</code> should contain all the lines and number
of letters for the chart that was used.
</p>
<p>These functions were written to deal
with a very specific style of recording visual acuity for a study I
worked on.  It may or may not have much use elsewhere.  <code>CFHM</code>
was not intended to typically be called by the user directly.
Generally, a higher level function, (e.g., <code>VAConverter</code>) would
be called.
</p>


<h3>References</h3>

<p>Jack T. Holladay (2004).  Visual acuity measurements.
<em>Journal of Cataract &amp; Refractive Surgery, 30</em>(2),
pp. 287&ndash;290. <a href="https://doi.org/10.1016/j.jcrs.2004.01.014">doi:10.1016/j.jcrs.2004.01.014</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VAConverter">VAConverter</a></code> the overall function typically
called
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## logMAR value for "perfect" 20/20 vision
JWileymisc:::logmar(x = 20)

## Go to and from logMAR value, should return "20"
## there may be slight error due to floating point arithmetic
JWileymisc:::logmar(x = JWileymisc:::logmar(x = 20), inverse = TRUE)

## logMAR value for 20/40 vision
JWileymisc:::logmar(40)
## logMAR approximations, note "HM" is just the zero value
JWileymisc:::CFHM(c("HM 20", "HM", "CF 20", "CF 12", "CF"), zero = 3)
## In cases where there is insufficient data, rather than choose
## an arbitrary value, you can may just use NA
JWileymisc:::CFHM(c("HM 20", "HM", "CF 20", "CF 12", "CF"), zero = NA)
</code></pre>

<hr>
<h2 id='VAObject-class'>An S4 class to hold visual acuity data</h2><span id='topic+VAObject-class'></span><span id='topic++5B+2CVAObject+2CANY+2CANY+2CANY-method'></span><span id='topic++5B+2CVAObject-method'></span><span id='topic+print+2CVAObject-method'></span><span id='topic+show+2CVAObject-method'></span><span id='topic+summary+2CVAObject-method'></span>

<h3>Description</h3>

<p>A class to hold Visual Acuity data for the oculus sinister (OS; left eye)
and oculus dexter (OD; right eye)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VAObject,ANY,ANY,ANY'
x[i, j, ..., drop = TRUE]

## S4 method for signature 'VAObject'
print(x, ...)

## S4 method for signature 'VAObject'
show(object)

## S4 method for signature 'VAObject'
summary(object, weightbest = TRUE, w = c(0.75, 0.25))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VAObject-class_+3A_x">x</code></td>
<td>
<p>the object to subset</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_i">i</code></td>
<td>
<p>the rows to subset (optional)</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_j">j</code></td>
<td>
<p>the columns to subset (optional)</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to lower functions</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_drop">drop</code></td>
<td>
<p>should be missing</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_object">object</code></td>
<td>
<p>A VAObject class object</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_weightbest">weightbest</code></td>
<td>
<p>Logical whether to upweight the best seeing eye.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="VAObject-class_+3A_w">w</code></td>
<td>
<p>A numeric vector of the weights, first for the best seeing
then the worst seeing eye. Defaults to <code>c(.75, .25)</code>.</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>x[i</code>: extract method
</p>
</li>
<li> <p><code>print(VAObject)</code>: print method
</p>
</li>
<li> <p><code>show(VAObject)</code>: show method
</p>
</li>
<li> <p><code>summary(VAObject)</code>: summary method
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>originalOS</code></dt><dd><p>the original visual acuity data for the left (ocular sinister) eye</p>
</dd>
<dt><code>originalOD</code></dt><dd><p>the original visual acuity data for the right (ocular dexter) eye</p>
</dd>
<dt><code>logMAROS</code></dt><dd><p>Logarithm of the minimum angle of resolution data for OS</p>
</dd>
<dt><code>logMAROD</code></dt><dd><p>Logarithm of the minimum angle of resolution data for OD</p>
</dd>
<dt><code>chart.values</code></dt><dd><p>the snellen values for each line of the chart used
to measure visual acuity.  Used for the linear interpolation in the
case of partially correct line readings.</p>
</dd>
<dt><code>chart.nletters</code></dt><dd><p>the number of letters on each line of the chart
used to measure visual acuity.  Used for the linear interpolation
in the case of partially correct line readings (+2 is 2/4 of the
way to the next line if there are four letters, but only 2/6 if
there are six, etc.)</p>
</dd>
<dt><code>zero</code></dt><dd><p>the logMAR value chosen to represent &quot;zero&quot; visual acuity
when creating the combined logMAR values for both eyes or taking
the arithmetic mean.</p>
</dd>
</dl>

<hr>
<h2 id='VASummaryObject-class'>An S4 class to hold visual acuity summary data</h2><span id='topic+VASummaryObject-class'></span><span id='topic+show+2CVASummaryObject-method'></span><span id='topic+plot+2CVASummaryObject+2Cmissing-method'></span>

<h3>Description</h3>

<p>A class designed to hold visual acuity summary data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'VASummaryObject'
show(object)

## S4 method for signature 'VASummaryObject,missing'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VASummaryObject-class_+3A_object">object</code></td>
<td>
<p>The object to be shown</p>
</td></tr>
<tr><td><code id="VASummaryObject-class_+3A_x">x</code></td>
<td>
<p>A VASummaryObject</p>
</td></tr>
<tr><td><code id="VASummaryObject-class_+3A_y">y</code></td>
<td>
<p>Should be missing</p>
</td></tr>
<tr><td><code id="VASummaryObject-class_+3A_...">...</code></td>
<td>
<p>Additional, unused arguments</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>show(VASummaryObject)</code>: show method
</p>
</li>
<li> <p><code>plot(x = VASummaryObject, y = missing)</code>: plot method
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>logMAR.combined</code></dt><dd><p>Numeric values of the combined logarithm of
the minimum angle of resolution data for both eyes</p>
</dd>
<dt><code>snellen.combined</code></dt><dd><p>the snellen values back transformed from the
combined logMAR values</p>
</dd>
<dt><code>mean.logMAR</code></dt><dd><p>average of the logarithm of the minimum angle of resolution data</p>
</dd>
<dt><code>mean.snellen</code></dt><dd><p>average of the combined Snellen data</p>
</dd>
</dl>

<hr>
<h2 id='winsorizor'>Winsorize at specified percentiles</h2><span id='topic+winsorizor'></span>

<h3>Description</h3>

<p>Simple function winsorizes data at the specified percentile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>winsorizor(d, percentile, values, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="winsorizor_+3A_d">d</code></td>
<td>
<p>A vector, matrix, data frame, or data table to be winsorized</p>
</td></tr>
<tr><td><code id="winsorizor_+3A_percentile">percentile</code></td>
<td>
<p>The percentile bounded by [0, 1] to winsorize data at.
If a data frame or matrix is provided for the data, this should have the
same length as the number of columns, or it will be repeated for all.</p>
</td></tr>
<tr><td><code id="winsorizor_+3A_values">values</code></td>
<td>
<p>If values are specified, use these instead of calculating by percentiles.
Should be a data frame with columns named &ldquo;low&rdquo;, and &ldquo;high&rdquo;.
If a data frame or matrix is provided for the data, there should be as many rows
for values to winsorize at as there are columns in the data.</p>
</td></tr>
<tr><td><code id="winsorizor_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical whether to remove NAs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>winsorized data. Attributes are included to list the exact values
(for each variable, if a data frame or matrix) used to winsorize
at the lower and upper ends.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dev.new(width = 10, height = 5)
par(mfrow = c(1, 2))
hist(as.vector(eurodist), main = "Eurodist")
hist(winsorizor(as.vector(eurodist), .05), main = "Eurodist with lower and upper\n5% winsorized")

library(data.table)
dat &lt;- data.table(x = 1:5)
dat[, y := scale(1:5)]
winsorizor(dat$y, .01)

## make a copy of the data table
winsorizor(dat, .01)

winsorizor(mtcars, .01)

winsorizor(matrix(1:9, 3), .01)

rm(dat) # clean up
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
