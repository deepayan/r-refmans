<!DOCTYPE html><html><head><title>Help for package TensorTest2D</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TensorTest2D}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%b%'><p>Computation of two matrices: the column of the output matrix is the</p>
Kronecker product of two columns of each input matrix.</a></li>
<li><a href='#%hp%'><p>Computation of the vector of Hadamard product values of the matrices</p>
<code>X[,,i]</code> and <code>B</code>.</a></li>
<li><a href='#%w%'><p>Computation of the matrix with rows being the linearized matrix products of</p>
<code>X[,,i]</code> and <code>B</code>.</a></li>
<li><a href='#%wt%'><p>Computation of the matrix with rows being the linearized matrix products of</p>
transposed <code>X[,,i]</code> and <code>B</code>.</a></li>
<li><a href='#ALS'><p>The function performing the Alternating Least Square (ALS) Algorithm.</p></a></li>
<li><a href='#Calculate_IC_Dev'><p>The function computing information criterion values and deviances.</p></a></li>
<li><a href='#Check_tidy_input'><p>The function confirming the input variables fit the</p>
requirements of the tensorReg2D function.</a></li>
<li><a href='#draw.coef'><p>Marking Specific Pixels on the Given Image Plot</p></a></li>
<li><a href='#getGLMCoef'><p>getGLMCoef: Computing the regression coefficients of generalized linear model.</p></a></li>
<li><a href='#mnist_mp2c2'><p>Read the pre-processed MNIST dataset</p></a></li>
<li><a href='#omics'><p>Lung-cancer cell lines data in cancer cell line encyclopedia (CCLE) dataset</p></a></li>
<li><a href='#plot.tsglm'><p>Plot Effective Image Pixels for A <kbd>"tsglm"</kbd> Object</p></a></li>
<li><a href='#predict.tsglm'><p>Predict by Second-order Tensor Generalized Regression</p></a></li>
<li><a href='#summary.tsglm'><p>Summarizing Second-order Tensor Generalized Regression Fits</p></a></li>
<li><a href='#tensorReg2D'><p>Fitting Second-order Tensor Generalized Regression</p></a></li>
<li><a href='#TensorTest2D'><p>The TensorTest2D Package</p></a></li>
<li><a href='#VAR_ALS'><p>The function computing the covariance matrices of the tensor regression parameters.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fitting Second-Order Tensor Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, stats, grDevices, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>abind, glmnet, testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of fitting generalized linear models on
    second-order tensor type data. The functions within this package mainly focus on
    parameter estimation, including parameter coefficients and standard deviation.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>bzip2</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>Mark Chen [aut, cre],
  Sheng-Mao Chang [aut],
  Wenbin Lu [aut],
  Jung-Ying Tzeng [aut],
  Ping-Yang Chen [aut]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/yuting1214/TensorTest2D">https://github.com/yuting1214/TensorTest2D</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/yuting1214/TensorTest2D/issues">https://github.com/yuting1214/TensorTest2D/issues</a></td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mark Chen &lt;l501l501l@gmail.com&gt;</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-03 19:10:09 UTC; l501l</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-03 19:20:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25b+25'>Computation of two matrices: the column of the output matrix is the
Kronecker product of two columns of each input matrix.</h2><span id='topic++25b+25'></span>

<h3>Description</h3>

<p>Computation of two matrices: the column of the output matrix is the
Kronecker product of two columns of each input matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>A %b% B
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25b+2B25_+3A_a">A</code></td>
<td>
<p>A numerical matrix.</p>
</td></tr>
<tr><td><code id="+2B25b+2B25_+3A_b">B</code></td>
<td>
<p>A numerical matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numerical matrix.
</p>

<hr>
<h2 id='+25hp+25'>Computation of the vector of Hadamard product values of the matrices
<code>X[,,i]</code> and <code>B</code>.</h2><span id='topic++25hp+25'></span>

<h3>Description</h3>

<p>Computation of the vector of Hadamard product values of the matrices
<code>X[,,i]</code> and <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X %hp% B
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25hp+2B25_+3A_x">X</code></td>
<td>
<p>A numerical 3D array. Each slice is a matrix of size the same as <code>B</code>.</p>
</td></tr>
<tr><td><code id="+2B25hp+2B25_+3A_b">B</code></td>
<td>
<p>A numerical matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numerical vector.
</p>


<h3>Author(s)</h3>

<p>Sheng-Mao Chang
</p>

<hr>
<h2 id='+25w+25'>Computation of the matrix with rows being the linearized matrix products of
<code>X[,,i]</code> and <code>B</code>.</h2><span id='topic++25w+25'></span>

<h3>Description</h3>

<p>Computation of the matrix with rows being the linearized matrix products of
<code>X[,,i]</code> and <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X %w% B
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25w+2B25_+3A_x">X</code></td>
<td>
<p>A numerical 3D array. Each slice is a matrix of column size
the same as the row size of <code>B</code>.</p>
</td></tr>
<tr><td><code id="+2B25w+2B25_+3A_b">B</code></td>
<td>
<p>A numerical matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numerical 3D array.
</p>

<hr>
<h2 id='+25wt+25'>Computation of the matrix with rows being the linearized matrix products of
transposed <code>X[,,i]</code> and <code>B</code>.</h2><span id='topic++25wt+25'></span>

<h3>Description</h3>

<p>Computation of the matrix with rows being the linearized matrix products of
transposed <code>X[,,i]</code> and <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X %wt% B
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25wt+2B25_+3A_x">X</code></td>
<td>
<p>A numerical 3D array. Each slice is a matrix of row size
the same as the row size of <code>B</code>.</p>
</td></tr>
<tr><td><code id="+2B25wt+2B25_+3A_b">B</code></td>
<td>
<p>A numerical matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numerical vector.
</p>

<hr>
<h2 id='ALS'>The function performing the Alternating Least Square (ALS) Algorithm.</h2><span id='topic+ALS'></span>

<h3>Description</h3>

<p>The function performing the Alternating Least Square (ALS) Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ALS(DATA, n_R, family, opt = opt, max_ite = max_ite, tol = tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ALS_+3A_data">DATA</code></td>
<td>
<p>A list. The input data. <code>DATA$y</code> is the dependent variable.
<code>DATA$X</code> is the 3-D tensor independent variables.
<code>DATA$W</code> is other independent variables.</p>
</td></tr>
<tr><td><code id="ALS_+3A_n_r">n_R</code></td>
<td>
<p>A numerical constant. A predefined value determines the rank of
the approximate matrix</p>
</td></tr>
<tr><td><code id="ALS_+3A_family">family</code></td>
<td>
<p>Family of <kbd>generalized linear model</kbd>. Provide three options for model.(see more details in
<strong>Details</strong>)</p>
</td></tr>
<tr><td><code id="ALS_+3A_opt">opt</code></td>
<td>
<p>Optimization options. Provide two options for optimization
stopping criterion. <strong>opt = 1 or 2</strong>. (see more details in
<strong>Details</strong>)</p>
</td></tr>
<tr><td><code id="ALS_+3A_max_ite">max_ite</code></td>
<td>
<p>Maximum iteration. The value of maximum iterations for the
algorithm.</p>
</td></tr>
<tr><td><code id="ALS_+3A_tol">tol</code></td>
<td>
<p>Tolerance. The value of tolerance with respect to optimization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. See <code>tensorReg2D</code>.
</p>

<hr>
<h2 id='Calculate_IC_Dev'>The function computing information criterion values and deviances.</h2><span id='topic+Calculate_IC_Dev'></span>

<h3>Description</h3>

<p>The function computing information criterion values and deviances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Calculate_IC_Dev(y, w_seq, df, family)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Calculate_IC_Dev_+3A_y">y</code></td>
<td>
<p>A numerical vector. Dependent variable.</p>
</td></tr>
<tr><td><code id="Calculate_IC_Dev_+3A_w_seq">w_seq</code></td>
<td>
<p>A numerical vector. Fitted values of the tensor regression model.</p>
</td></tr>
<tr><td><code id="Calculate_IC_Dev_+3A_df">df</code></td>
<td>
<p>integer. Degree of freedom.</p>
</td></tr>
<tr><td><code id="Calculate_IC_Dev_+3A_family">family</code></td>
<td>
<p>Family of <kbd>generalized linear model</kbd>. Provide three options for model.(see more details in
<strong>Details</strong>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list.
</p>
<p><kbd>IC</kbd>: The values of Akaike information criterion (AIC) and
Bayesian information criterion (BIC).
</p>
<p><kbd>DoF</kbd>: The values of the residual degrees of freedom for the null model and
the residual degrees of freedom.
</p>
<p><kbd>Dev_res</kbd>: The deviance values of residuals.
</p>
<p><kbd>Dev</kbd>: The deviance values for the null model and the working model.
</p>

<hr>
<h2 id='Check_tidy_input'>The function confirming the input variables fit the
requirements of the tensorReg2D function.</h2><span id='topic+Check_tidy_input'></span>

<h3>Description</h3>

<p>The function confirming the input variables fit the
requirements of the tensorReg2D function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Check_tidy_input(y, X, W, n_R, family)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Check_tidy_input_+3A_y">y</code></td>
<td>
<p>A numerical vector. Dependent variable.</p>
</td></tr>
<tr><td><code id="Check_tidy_input_+3A_x">X</code></td>
<td>
<p>A numerical 3-D array. Independent variable(3-D tensor).</p>
</td></tr>
<tr><td><code id="Check_tidy_input_+3A_w">W</code></td>
<td>
<p>A numerical matrix. Independent variable.</p>
</td></tr>
<tr><td><code id="Check_tidy_input_+3A_n_r">n_R</code></td>
<td>
<p>A numerical constant. A predefined value determines the rank of
the approximate matrix</p>
</td></tr>
<tr><td><code id="Check_tidy_input_+3A_family">family</code></td>
<td>
<p>Family of <kbd>generalized linear model</kbd>. Provide three options for model.(see more details in
<strong>Details</strong>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list.
<kbd>DATA</kbd>: list of input data.<code>DATA$y</code> is the dependent variable.
<code>DATA$X</code> is the 3-D tensor independent variables.
<code>DATA$W</code> is other independent variables.
</p>
<p><kbd>fm</kbd>: The model expression shown in <code>summary.tsglm</code>.
</p>

<hr>
<h2 id='draw.coef'>Marking Specific Pixels on the Given Image Plot</h2><span id='topic+draw.coef'></span>

<h3>Description</h3>

<p>Marking Specific Pixels on the Given Image Plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw.coef(
  img,
  marks,
  markstyle = c("black", "bi-dir"),
  showlabels = TRUE,
  plot.legend = TRUE,
  grids = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw.coef_+3A_img">img</code></td>
<td>
<p>a matrix of image data.</p>
</td></tr>
<tr><td><code id="draw.coef_+3A_marks">marks</code></td>
<td>
<p>a matrix of the same size as <code>img</code>.
On the image plot, the pixels are marked if the corresponding cells in <code>marks</code> are non-zero.
The user can specify the style of the marks through <code>markstyle</code>.</p>
</td></tr>
<tr><td><code id="draw.coef_+3A_markstyle">markstyle</code></td>
<td>
<p>string. The style of pixels' marks. If <code>markstyle = 'black'</code>, the rectangles
are marked by black edges for non-zero cells in <code>marks</code>.
If <code>markstyle = 'bi-dir'</code>, &quot;red&quot; rectangles are marked on the pixels in which the cells in <code>marks</code> are positive,
and, &quot;blue&quot; rectangles are marked on the pixels in which the cells in <code>marks</code> are negative.</p>
</td></tr>
<tr><td><code id="draw.coef_+3A_showlabels">showlabels</code></td>
<td>
<p>boolean. For <code>showlabels = TRUE</code>, if <code>dimnames(img)</code> exists, the row and column names are
shown on the sides of the image plot; otherwise, the row and column indices are shown.</p>
</td></tr>
<tr><td><code id="draw.coef_+3A_plot.legend">plot.legend</code></td>
<td>
<p>boolean. Set <code>plot.legend = TRUE</code> if the colorbar legend is needed. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="draw.coef_+3A_grids">grids</code></td>
<td>
<p>boolean. If <code>grids = TRUE</code>, grid lines are added for the image plot.</p>
</td></tr>
<tr><td><code id="draw.coef_+3A_...">...</code></td>
<td>
<p>further arguments passed to the <code><a href="graphics.html#topic+image">image</a></code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ping-Yang Chen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.tsglm">plot.tsglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#

</code></pre>

<hr>
<h2 id='getGLMCoef'>getGLMCoef: Computing the regression coefficients of generalized linear model.</h2><span id='topic+getGLMCoef'></span>

<h3>Description</h3>

<p>getGLMCoef: Computing the regression coefficients of generalized linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getGLMCoef(X, y, family, offset_vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getGLMCoef_+3A_x">X</code></td>
<td>
<p>A numerical matrix. Independent variable.</p>
</td></tr>
<tr><td><code id="getGLMCoef_+3A_y">y</code></td>
<td>
<p>A numerical vector. Dependent variable.</p>
</td></tr>
<tr><td><code id="getGLMCoef_+3A_family">family</code></td>
<td>
<p>Family of <kbd>generalized linear model</kbd>. Provide three options for model.(see more details in
<strong>Details</strong>)</p>
</td></tr>
<tr><td><code id="getGLMCoef_+3A_offset_vec">offset_vec</code></td>
<td>
<p>A numerical vector. Prior knowledge to be included in the predictors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list.
</p>

<hr>
<h2 id='mnist_mp2c2'>Read the pre-processed MNIST dataset</h2><span id='topic+mnist_mp2c2'></span>

<h3>Description</h3>

<p>A pre-processed MNIST dataset with each image of 10*10 = 100 pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mnist_mp2c2)
</code></pre>


<h3>Format</h3>

<p>A list of two sublists, <code>mnist_mp2c2$train</code> and <code>mnist_mp2c2$test</code>.
In each sublist, the data is stored as a list of length two, image and label. 
The image is a 3-dimensional array of size (10, 10, n), where n represents the data size.
For i = 1, ..., n the i-th slice of image is an integer matrix with elements in [0, 255]
representing the image of 10*10 = 100 pixels in grey scale.
The label is a vector of length n. The i-th value is the digit of the i-th slice of image.
</p>


<h3>Details</h3>

<p>The original MNIST handwritten digit is the image of 28*28 = 784 pixels.
The pre-processing procedure is as follows.
First, the original 28 by 28 image is separated into 14 by 14 clusters, 
each one is a 2 by 2 block. For each cluster, the maximal value in its cells 
is taken, and therefore, the original MNIST image is reduced into 14 by 14 image. 
Because the surrounding cells of the reduced image are usually zero value, 
we only take the center 10 by 10 sub-image by cutting the edge cells. 
Thus, the pre-processed MNIST dataset has images of 10*10 = 100 pixels.
</p>


<h3>Source</h3>

<p><a href="https://CRAN.R-project.org/package=dslabs">https://CRAN.R-project.org/package=dslabs</a>
</p>


<h3>References</h3>

<p>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.
(<a href="https://ieeexplore.ieee.org/abstract/document/726791">URL</a>)
</p>
<p>Rafael A. Irizarry and Amy Gill (2019). dslabs: Data Science Labs. R package version 0.7.3.
(<a href="https://CRAN.R-project.org/package=dslabs">URL</a>)
</p>
<p>LeCun, Y. http://yann.lecun.com/exdb/mnist/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mnist_mp2c2)
dim(mnist_mp2c2$train$image)
# 10    10 60000
image(mnist_mp2c2$train$image[,,1])
mnist_mp2c2$train$label[1]
</code></pre>

<hr>
<h2 id='omics'>Lung-cancer cell lines data in cancer cell line encyclopedia (CCLE) dataset</h2><span id='topic+omics'></span>

<h3>Description</h3>

<p>The omics data is a subset of the dataset provided by cancer cell line
encyclopedia (CCLE) project (Barretina et al., 2012;
<a href="https://sites.broadinstitute.org/ccle/">https://sites.broadinstitute.org/ccle/</a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(omics)
</code></pre>


<h3>Format</h3>

<p>A list contains two objects:
</p>

<dl>
<dt>omics</dt><dd><p>a 3-dimensional array with size (3, 10, 68)</p>
</dd>
<dt>Y</dt><dd><p>a 68-length vector representing the response variable</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data consists of one response variable and ten genes
evaluated under three different platforms. 
</p>
<p>The response variable measures the log-transformed activity area of taking 
Vandertanib, a drug targeting on EGFR gene for lung cancer. 
</p>
<p>The three platforms are DNA copy number variation (CNV), methylation and mRNA 
expression.
</p>
<p>Among the 10 genes, 7 of them (EGFR, EREG, HRAS, KRAS, PTPN11, STAT3, and
TGFA) are involved in the protein-protein interaction network of EGFR 
(<a href="https://string-db.org">https://string-db.org</a>) and the rest (ACTB, 
GAPDH, and PPIA) are arbitrarily chosen housekeeping genes and play the role
of negative control. 
</p>
<p>Detailed pre-processing procedure is available in Chang et al. (2021).
</p>


<h3>Source</h3>

<p><a href="https://string-db.org">https://string-db.org</a>
</p>


<h3>References</h3>

<p>Barretina, J., Caponigro, G., Stransky, N. et al. 
The Cancer Cell Line Encyclopedia enables predictive modelling of anticancer 
drug sensitivity. Nature 483, 603â€“607 (2012).
(<a href="https://www.nature.com/articles/nature11003">Link</a>)
</p>
<p>Sheng-Mao Chang, Meng Yang, Wenbin Lu, Yu-Jyun Huang, Yueyang Huang, Hung Hung, 
Jeffrey C Miecznikowski, Tzu-Pin Lu, Jung-Ying Tzeng, 
Gene-set integrative analysis of multi-omics data using tensor-based association test, 
Bioinformatics, 2021;, btab125,
(<a href="https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btab125/6154849">Link</a>))
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(omics)
names(omics)
dim(omics$omics)
# 3 10 68
</code></pre>

<hr>
<h2 id='plot.tsglm'>Plot Effective Image Pixels for A <kbd>"tsglm"</kbd> Object</h2><span id='topic+plot.tsglm'></span>

<h3>Description</h3>

<p><kbd>plot</kbd> method for self-defined class <kbd>"tsglm"</kbd>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tsglm'
plot(
  x,
  method = p.adjust.methods,
  alpha = NULL,
  type = c("coef", "tval"),
  background = NULL,
  showlabels = TRUE,
  plot.legend = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.tsglm_+3A_x">x</code></td>
<td>
<p>an object of class <kbd>"tsglm"</kbd>.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_method">method</code></td>
<td>
<p>p-value correction method. See <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.
Its default value is <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_alpha">alpha</code></td>
<td>
<p>double. The value of significance level.
Its default value is <code>NULL</code>. If specify real-valued <code>alpha</code>, for example 0.05,
the image plot marks the pixels with p-values smaller than <code>alpha</code>.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_type">type</code></td>
<td>
<p>string. The type of values shown on the image pixels when <code>background = NULL</code>.
Set <code>type = 'coef'</code> for showing the values of estimated coefficients of the \(B\) matrix.
Set <code>type = 'tval'</code> for showing the t-statistics of the coefficients of the \(B\) matrix.
If <code>background</code> is not <code>NULL</code>, the plot will neglect the choice for
<code>type</code> and show the background image as per user's interest.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_background">background</code></td>
<td>
<p>an image data that used as the background of the effectiveness markers.
If <code>background = NULL</code>, the background color shows the effect size of
the each pixel according to the setting in <code>type</code>.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_showlabels">showlabels</code></td>
<td>
<p>boolean. For <code>showlabels = TRUE</code>, if the row and column names of the image exist, the row and column names are
shown on the sides of the image plot; otherwise, the row and column indices are shown.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_plot.legend">plot.legend</code></td>
<td>
<p>boolean. Set <code>plot.legend = TRUE</code> if the colorbar legend is needed. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.tsglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to the <code><a href="graphics.html#topic+image">image</a></code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ping-Yang Chen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tensorReg2D">tensorReg2D</a>, <a href="#topic+draw.coef">draw.coef</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulation data
n &lt;- 500 # number of observations
n_P &lt;- 3; n_G &lt;- 16 # dimension of 3-D tensor variables.
n_d &lt;- 1 # number of numerical variable, if n_d == 1,  numerical variable equals to intercept.
beta_True &lt;- rep(1, n_d)
B_True &lt;- c(1, 1, 1)%*%t(rnorm(n_G)) + c(0, .5, .5)%*%t(rnorm(n_G))
B_True &lt;- B_True / 10
W &lt;- matrix(rnorm(n*n_d), n, n_d); W[,1] &lt;- 1
X &lt;- array(rnorm(n*n_P*n_G), dim=c(n_P, n_G, n))

# Binomial Responses
p_B &lt;- exp(W%*%beta_True + X%hp%B_True); p_B &lt;- p_B/(1+p_B)
y_B &lt;- rbinom(n, 1, p_B)
DATA_B &lt;- list(y = y_B, W = W, X = X)

# Binomial Model
result_B &lt;- tensorReg2D(y = DATA_B$y, X = DATA_B$X, W=NULL, n_R = 1,
family = "binomial", opt = 1, max_ite = 100, tol = 10^(-7) )

# Plot the effect size of the pixels
plot(result_B, method = "fdr", alpha = 0.05, type = "coef")
# Plot the t-statistics of the coefficients of the pixels
plot(result_B, method = "fdr", alpha = 0.05, type = "tval")

# Plot the effective pixels with data image as the background
x0 &lt;- DATA_B$X[,,which(DATA_B$y == 0)]
x1 &lt;- DATA_B$X[,,which(DATA_B$y == 1)]
m0 &lt;- m1 &lt;- matrix(0, dim(DATA_B$X)[1], dim(DATA_B$X)[2])
for (i in 1:dim(x0)[3]) m0 &lt;- m0 + x0[,,i]/dim(x0)[3]
for (i in 1:dim(x1)[3]) m1 &lt;- m1 + x1[,,i]/dim(x1)[3]
par(mfrow = c(1, 2), mar = c(2, 2, 2, 2))
plot(result_B, method = "fdr", alpha = 0.05,
background = m0, col = gray(seq(0, 1, 0.05)))
title("Category 0")
plot(result_B, method = "fdr", alpha = 0.05,
background = m1, col = gray(seq(0, 1, 0.05)))
title("Category 1")

</code></pre>

<hr>
<h2 id='predict.tsglm'>Predict by Second-order Tensor Generalized Regression</h2><span id='topic+predict.tsglm'></span>

<h3>Description</h3>

<p><kbd>predict</kbd> method for self-defined class <kbd>"tsglm"</kbd>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tsglm'
predict(object, newx, neww = NULL, type = c("link", "response"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.tsglm_+3A_object">object</code></td>
<td>
<p>Fitted <kbd>"tsglm"</kbd> object.</p>
</td></tr>
<tr><td><code id="predict.tsglm_+3A_newx">newx</code></td>
<td>
<p>a 3-dimensional array for <code>x</code> for which the prediction are interested.</p>
</td></tr>
<tr><td><code id="predict.tsglm_+3A_neww">neww</code></td>
<td>
<p>a numerical matrix for <code>W</code> for which the prediction are interested.</p>
</td></tr>
<tr><td><code id="predict.tsglm_+3A_type">type</code></td>
<td>
<p>the type of prediction required. The default is <code>type = "link"</code> that returns
prediction values on the scale of the linear predictors (eta).
Alternatively, set <code>type = "response"</code> for returning predictions on the scale of the response variable.</p>
</td></tr>
<tr><td><code id="predict.tsglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>There are two types of the output of <kbd>predict.tsglm</kbd> function.
By setting <code>type = "link"</code>, it returns the values of the linear predictors;
and by setting <code>type = "response"</code>, it returns the the expected values of response variable.
For example, for a binomial model, the predictions are log-odds (probabilities on logit scale)
if <code>type = "link"</code>, and <code>type = "response"</code> gives the predicted probabilities of Y=1.
</p>


<h3>Author(s)</h3>

<p>Ping-Yang Chen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tensorReg2D">tensorReg2D</a>, <a href="#topic+summary.tsglm">summary.tsglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Predefined function: sum of hadamard product in each array
`%hp%` &lt;- function(X, B) sapply(1:dim(X)[3], function(i) sum(X[,,i]*B))

# Simulation data
n &lt;- 500 # number of observations
n_P &lt;- 3; n_G &lt;- 64 # dimension of 3-D tensor variables.
n_d &lt;- 1 # number of numerical variable, if n_d == 1,  numerical variable equals to intercept.
beta_True &lt;- rep(1, n_d)
B_True &lt;- c(1,1,1)%*%t(rnorm(n_G)) + c(0, .5, .5)%*%t(rnorm(n_G))
B_True &lt;- B_True / 10
W &lt;- matrix(rnorm(n*n_d), n, n_d); W[,1] &lt;- 1
X &lt;- array(rnorm(n*n_P*n_G), dim=c(n_P, n_G, n))
## Regression
y_R&lt;- as.vector(W%*%beta_True + X%hp%B_True + rnorm(n))
DATA_R &lt;- list(y = y_R, X = X, W = W)
## Binomial
p_B &lt;- exp(W%*%beta_True + X%hp%B_True); p_B &lt;- p_B/(1+p_B)
y_B &lt;- rbinom(n, 1, p_B)
DATA_B &lt;- list(y = y_B, W = W, X = X)
## Poisson
p_P &lt;- exp(W%*%beta_True + X%hp%B_True)
y_P &lt;- rpois(n, p_P)
y_P[which(y_P &gt; 170)] &lt;- 170 # If y_P &gt; 170, factorial(y_P) == inf.
DATA_P &lt;- list(y = y_P, W = W, X = X)

# Execution
## Regression
result_R &lt;- tensorReg2D(y = DATA_R$y, X = DATA_R$X, W=NULL, n_R = 1, family = "gaussian",
opt = 1, max_ite = 100, tol = 10^(-7) )
## Prediction
head(predict(result_R, DATA_R$X))

## Binomial
result_B &lt;- tensorReg2D(y = DATA_B$y, X = DATA_B$X, W=NULL, n_R = 1, family = "binomial",
opt = 1, max_ite = 100, tol = 10^(-7) )
## Prediction
head(predict(result_B, DATA_B$X))

## Poisson
result_P &lt;- tensorReg2D(y = DATA_P$y, X = DATA_P$X, W=NULL, n_R = 1, family = "poisson",
opt = 1, max_ite = 100, tol = 10^(-7) )
## Prediction
head(predict(result_P, DATA_P$X))

</code></pre>

<hr>
<h2 id='summary.tsglm'>Summarizing Second-order Tensor Generalized Regression Fits</h2><span id='topic+summary.tsglm'></span>

<h3>Description</h3>

<p><kbd>summary</kbd> method for self-defined class <kbd>"tsglm"</kbd>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tsglm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.tsglm_+3A_object">object</code></td>
<td>
<p>an object of class <kbd>"tsglm"</kbd>.</p>
</td></tr>
<tr><td><code id="summary.tsglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><kbd>summary.tsglm</kbd> is combined with <code><a href="base.html#topic+print">print</a></code> to provide
formatting the coefficients, standard errors, etc. and additionally gives 'significance stars'
</p>


<h3>Value</h3>

<p><kbd>summary.tsglm</kbd> returns a printout similar to <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>.
</p>
<p>The printout contains the following components:
</p>
<p><kbd>Call</kbd>: The formula for fitted model.
</p>
<p><kbd>Deviance Residuals</kbd>: The summary statistics of deviance residuals. Provide for model
except <kbd>family = "gaussian"</kbd>.
</p>
<p><kbd>Residuals</kbd>: The summary statistics of residuals. Provide for <kbd>family = "gaussian"</kbd>.
</p>
<p><kbd>Coefficients</kbd>: The coefficient table includes estimation, standard deviation,
test statistics, and p-value of parameters and significance stars.
</p>
<p><kbd>Deviance</kbd>: The deviance of a fitted model. Provide for model except <kbd>family = "gaussian"</kbd>.
</p>
<p><kbd>AIC</kbd>: Akaike information criterion.
</p>


<h3>Author(s)</h3>

<p>Mark Chen
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a>, <a href="#topic+predict.tsglm">predict.tsglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulation data
n &lt;- 500 # number of observations
n_P &lt;- 3; n_G &lt;- 64 # dimension of 3-D tensor variables.
n_d &lt;- 2 # number of numerical variable, if n_d == 1,  numerical variable equals to intercept.
beta_True &lt;- rep(1, n_d)
B_True &lt;- c(1,1,1)%*%t(rnorm(n_G)) + c(0, .5, .5)%*%t(rnorm(n_G))
B_True &lt;- B_True / 10
W &lt;- matrix(rnorm(n*n_d), n, n_d); W[,1] &lt;- 1
W_named &lt;- W
colnames(W_named) &lt;- paste0("w", 1:ncol(W_named))
X &lt;- array(rnorm(n*n_P*n_G), dim=c(n_P, n_G, n))
X_named &lt;- X
dimnames(X_named) &lt;- list(paste0("R", 1:nrow(X_named)),paste0("C", 1:ncol(X_named)))
## Regression
y_R &lt;- as.vector(W%*%beta_True + X%hp%B_True + rnorm(n))
DATA_R &lt;- list(y = y_R, X = X, W = W)
y_R_named &lt;- as.vector(W_named%*%beta_True + X_named%hp%B_True + rnorm(n))
DATA_R_named &lt;- list(y = y_R_named, X = X_named, W = W_named)
## Binomial
p_B &lt;- exp(W%*%beta_True + X%hp%B_True); p_B &lt;- p_B/(1+p_B)
y_B &lt;- rbinom(n, 1, p_B)
DATA_B &lt;- list(y = y_B, W = W, X = X)
## Poisson
p_P &lt;- exp(W%*%beta_True + X%hp%B_True)
y_P &lt;- rpois(n, p_P)
y_P[which(y_P &gt; 170)] &lt;- 170 # If y_P &gt; 170, factorial(y_P) == inf.
DATA_P &lt;- list(y = y_P, W = W, X = X)

# Execution
## Regression
result_R &lt;- tensorReg2D(y = DATA_R$y, X = DATA_R$X, W=NULL, n_R = 1, family = "gaussian",
opt = 1, max_ite = 100, tol = 10^(-7) )
summary(result_R)
head(predict(result_R, DATA_R$X))

## Regression with specified names
result_R_named &lt;- tensorReg2D(y = DATA_R_named$y, X = DATA_R_named$X, W=DATA_R_named$W,
n_R = 1, family = "gaussian", opt = 1, max_ite = 100, tol = 10^(-7) )
summary(result_R_named)

## Binomial
result_B &lt;- tensorReg2D(y = DATA_B$y, X = DATA_B$X, W=NULL, n_R = 1, family = "binomial",
opt = 1, max_ite = 100, tol = 10^(-7) )
summary(result_B)
head(predict(result_B, DATA_B$X))

## Poisson
result_P &lt;- tensorReg2D(y = DATA_P$y, X = DATA_P$X, W=NULL, n_R = 1, family = "poisson",
opt = 1, max_ite = 100, tol = 10^(-7) )
summary(result_P)
head(predict(result_P, DATA_P$X))

</code></pre>

<hr>
<h2 id='tensorReg2D'>Fitting Second-order Tensor Generalized Regression</h2><span id='topic+tensorReg2D'></span>

<h3>Description</h3>

<p><kbd>tensorReg2D</kbd> is used to fit second-order tensor generalized regression model. It mainly
focus on parameter estimation, including parameter coefficients and standard
deviation. The function is built upon <strong>Alternating Least Square
Algorithm</strong>, so we provide two criterion to determine optimal result (see more
details below in Arguments). Also, we offer model complexity
measurement,including AIC and BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensorReg2D(y, X, W = NULL, n_R, family, opt = 1, max_ite = 100, tol = 10^(-7))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tensorReg2D_+3A_y">y</code></td>
<td>
<p>A numerical vector. Dependent variable.</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_x">X</code></td>
<td>
<p>A numerical 3-D array Independent variable(3-D tensor).</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_w">W</code></td>
<td>
<p>A numerical matrix. Independent variable.</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_n_r">n_R</code></td>
<td>
<p>A numerical constant. A predefined value determines the rank of
the approximate matrix</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_family">family</code></td>
<td>
<p>Family of <kbd>generalized linear model</kbd>. Provide three options for model.(see more details in
<strong>Details</strong>)</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_opt">opt</code></td>
<td>
<p>Optimization options. Provide two options for optimization
stopping criterion. <strong>opt = 1 or 2</strong>. (see more details in
<strong>Details</strong>)</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_max_ite">max_ite</code></td>
<td>
<p>Maximum iteration. The value of maximum iterations for the
algorithm.</p>
</td></tr>
<tr><td><code id="tensorReg2D_+3A_tol">tol</code></td>
<td>
<p>Tolerance. The value of tolerance with respect to optimization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><kbd>tensorReg2D</kbd> focuses on second-order tensor generalized regression problems.
To be more specific, it provides statistical inference for input variables.
Moreover, the function isn't restricted to second-order tensor input <kbd>X</kbd>;
it could combine with other meaningful numerical variables <kbd>W</kbd>.
</p>
<p>Since <kbd>tensorReg2D</kbd> is based on <strong>Alternating Least Square
Algorithm</strong>, we need to pre-define following arguments to meet favorable
optimization result.
</p>
<p><kbd>n_R</kbd>: In the case of regression with the order 2, P-by-G-by-n tensor, we
can break a unknown parameter matrix <strong>B</strong>(P-by-G) into multiplication
of two matrix <strong>B_1</strong>(P-by-R) and <strong>t(B_2)</strong> (R-by-G), which means
that we can estimate the original matrix <strong>B</strong> by iteratively updating
<strong>B_1</strong> and <strong>B_2</strong>. In this scenario, <kbd>n_R</kbd> equals to the rank
of these two approximate matrix <strong>B_1</strong> and <strong>B_2</strong>. Conceivably,
<kbd>1 &lt;= n_R &lt;= min(P,G)</kbd>, and by properly pre-appointing <kbd>n_R</kbd>, we can
estimate a unknown parameter matrix. By default, <kbd>n_R = 1</kbd>.
</p>
<p><kbd>opt</kbd>: In optimization algorithm, we have to determine stopping
criterion. In <kbd>tensorReg2D</kbd>, we offer two criteria. <kbd>If opt = 1</kbd>, the
criterion is that we stop our execution when the maximum difference between
the elements among an estimated parameter matrix <strong>B</strong> with an estimated
parameter vector <strong>b</strong> and preceding ones is less than predefined
tolerance (<kbd>tol</kbd>) . <kbd>If opt = 2</kbd>, the criterion is that we stop our
execution when the maximum difference between the elements among an estimated
approximate parameter matrix <strong>B_1</strong> , <strong>B_2</strong> with an estimated
parameter vector <strong>b</strong> and preceding ones is less than predefined
tolerance (<kbd>tol</kbd>).
</p>
<p><kbd>family</kbd>: In <kbd>tensorReg2D</kbd>, we provide three options for specific generalized regression
problem. First, <kbd>family = "gaussian"</kbd> using <kbd>identity</kbd> link function corresponds to linear regression
model, where dependent variable is real number. Next, <kbd>family = "binomial"</kbd> based on <kbd>logit</kbd> link function
corresponds to logistic regression, where dependent variable is restricted to zero or one binary variable. Finally,
<kbd>family = "poisson"</kbd> built upon <kbd>log</kbd> link function corresponds to poisson regression, where dependent
variable is non-negative integer.
</p>
<p><kbd>max_ite</kbd>: In optimization algorithm, we have to beforehand determine maximum iteration beforehand.
By default, <kbd>max_ite = 100</kbd>.
</p>
<p><kbd>tol</kbd>: In optimization algorithm, we have to beforehand determine maximum tolerance to cooperate with
stopping criterion(<kbd>opt</kbd>).
</p>


<h3>Value</h3>

<p>tensorReg2D returns an object of <kbd>"tsglm"</kbd>.
</p>
<p>The function, <code><a href="#topic+summary.tsglm">summary.tsglm</a></code> a customized method from generic function
<code><a href="base.html#topic+summary">summary</a></code>, can be used to obtain and print a summary and analysis
of variance table of the results.
</p>
<p>An object of class <kbd>tsglm</kbd> is a list containing at least the following components:
</p>
<p><kbd>ite</kbd>: The number of executed times when stopping the function.
</p>
<p><kbd>b_EST</kbd>: The estimated coefficients for numerical variables.
</p>
<p><kbd>b_SD</kbd>: The estimated standard deviation for numerical variables.
</p>
<p><kbd>b_PV</kbd>: The p-value for numerical variables.
</p>
<p><kbd>B_EST</kbd>: The estimated coefficients for 3-D tensor variables.
</p>
<p><kbd>B_SD</kbd>: The estimated standard deviation for 3-D tensor variables.
</p>
<p><kbd>B_PV</kbd>: The p-value for 3-D tensor variables.
</p>
<p><kbd>Residuals</kbd>: The differences between true values and prediction values. Provide for
<kbd>family = "gaussian"</kbd>.
</p>
<p><kbd>Dev_res</kbd>: Deviance residuals for glm. Provide for model except <kbd>family = "gaussian"</kbd>.
</p>
<p><kbd>Dev</kbd>: The value of Null deviances and Residual deviance. Provide for model except
<kbd>family = "gaussian"</kbd>.
</p>
<p><kbd>IC</kbd>: The value of AIC and BIC.
</p>
<p><kbd>DoF</kbd>: Degree of freedom.
</p>
<p><kbd>call</kbd>: The formula of fitted model.
</p>
<p><kbd>family</kbd>: The family for model.
</p>


<h3>Author(s)</h3>

<p>Sheng-Mao Chang
</p>


<h3>References</h3>

<p>Mengyun Wu, Jian Huang, and Shuangge Ma (2017). Identifying gene-gene
interactions using penalized tensor regression.
</p>
<p>Sheng-Mao Chang, Meng Yang, Wenbin Lu, Yu-Jyun Huang, Yueyang Huang, Hung Hung,
Jeffrey C Miecznikowski, Tzu-Pin Lu, Jung-Ying Tzeng,
Gene-set integrative analysis of multi-omics data using tensor-based association test,
Bioinformatics, 2021;, btab125,
(<a href="https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btab125/6154849">Link</a>))
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulation data
n &lt;- 500 # number of observations
n_P &lt;- 3; n_G &lt;- 64 # dimension of 3-D tensor variables.
n_d &lt;- 1 # number of numerical variable, if n_d == 1,  numerical variable equals to intercept.
beta_True &lt;- rep(1, n_d)
B_True &lt;- c(1,1,1)%*%t(rnorm(n_G)) + c(0, .5, .5)%*%t(rnorm(n_G))
B_True &lt;- B_True / 10
W &lt;- matrix(rnorm(n*n_d), n, n_d); W[,1] &lt;- 1
X &lt;- array(rnorm(n*n_P*n_G), dim=c(n_P, n_G, n))
## Regression
y_R&lt;- as.vector(W%*%beta_True + X%hp%B_True + rnorm(n))
DATA_R &lt;- list(y = y_R, X = X, W = W)
## Binomial
p_B &lt;- exp(W%*%beta_True + X%hp%B_True); p_B &lt;- p_B/(1+p_B)
y_B &lt;- rbinom(n, 1, p_B)
DATA_B &lt;- list(y = y_B, W = W, X = X)
## Poisson
p_P &lt;- exp(W%*%beta_True + X%hp%B_True)
y_P &lt;- rpois(n, p_P)
y_P[which(y_P &gt; 170)] &lt;- 170 # If y_P &gt; 170, factorial(y_P) == inf.
DATA_P &lt;- list(y = y_P, W = W, X = X)

# Execution
## Regression
result_R &lt;- tensorReg2D(y = DATA_R$y, X = DATA_R$X, W=NULL, n_R = 1, family = "gaussian",
opt = 1, max_ite = 100, tol = 10^(-7) )
## Visualization
image(B_True);image(result_R$B_EST)
head(predict(result_R, DATA_R$X))

## Binomial
result_B &lt;- tensorReg2D(y = DATA_B$y, X = DATA_B$X, W=NULL, n_R = 1, family = "binomial",
opt = 1, max_ite = 100, tol = 10^(-7) )
## Visualization
image(B_True);image(result_B$B_EST)
head(predict(result_B, DATA_B$X))

## Poisson
result_P &lt;- tensorReg2D(y = DATA_P$y, X = DATA_P$X, W=NULL, n_R = 1, family = "poisson",
opt = 1, max_ite = 100, tol = 10^(-7) )
## Visualization
image(B_True);image(result_P$B_EST)
head(predict(result_P, DATA_P$X))

</code></pre>

<hr>
<h2 id='TensorTest2D'>The TensorTest2D Package</h2><span id='topic+TensorTest2D'></span>

<h3>Description</h3>

<p><kbd>TensorTest2D</kbd> is a tool used to fit second-order tensor type data.
</p>


<h3>Details</h3>

<p>This package contains functions for fitting generalized linear models on second-order tensor type data.
</p>
<p>It mainly focus on parameter estimation, including parameter coefficients and standard deviation.
</p>
<p>Currently, this package includes generalized linear models with <kbd>identity link</kbd> (Regression),
<kbd>logit link</kbd> (Logistic regression), and <kbd>log link</kbd> (Poisson regression).
</p>
<p>For a complete list of functions, use <kbd>help(package = TensorTest2D)</kbd>.
</p>


<h3>Author(s)</h3>

<p>Sheng-Mao Chang <a href="mailto:smchang110@gm.ntpu.edu.tw">smchang110@gm.ntpu.edu.tw</a>
</p>
<p>Wenbin Lu <a href="mailto:wlu4@ncsu.edu">wlu4@ncsu.edu</a>
</p>
<p>Jung-Ying Tzeng <a href="mailto:jytzeng@ncsu.edu">jytzeng@ncsu.edu</a>
</p>
<p>Ping-Yang Chen <a href="mailto:pychen.ping@gmail.com">pychen.ping@gmail.com</a>
</p>
<p>Maintainer: Mark Chen <a href="mailto:l501l501l@gmail.com">l501l501l@gmail.com</a>
</p>

<hr>
<h2 id='VAR_ALS'>The function computing the covariance matrices of the tensor regression parameters.</h2><span id='topic+VAR_ALS'></span>

<h3>Description</h3>

<p>The function computing the covariance matrices of the tensor regression parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VAR_ALS(DATA, n_R, B1, B2, beta, family)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VAR_ALS_+3A_data">DATA</code></td>
<td>
<p>A list. The input data. <code>DATA$y</code> is the dependent variable.
<code>DATA$X</code> is the 3-D tensor independent variables.
<code>DATA$W</code> is other independent variables.</p>
</td></tr>
<tr><td><code id="VAR_ALS_+3A_n_r">n_R</code></td>
<td>
<p>A numerical constant. A predefined value determines the rank of
the approximate matrix</p>
</td></tr>
<tr><td><code id="VAR_ALS_+3A_b1">B1</code></td>
<td>
<p>A numerical matrix. Parameter matrix B1 of the tensor regression.</p>
</td></tr>
<tr><td><code id="VAR_ALS_+3A_b2">B2</code></td>
<td>
<p>A numerical matrix. Parameter matrix B2 of the tensor regression.</p>
</td></tr>
<tr><td><code id="VAR_ALS_+3A_beta">beta</code></td>
<td>
<p>A numerical vector. Parameter vector of the covariates, W.</p>
</td></tr>
<tr><td><code id="VAR_ALS_+3A_family">family</code></td>
<td>
<p>Family of <kbd>generalized linear model</kbd>. Provide three options for model.(see more details in
<strong>Details</strong>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list.
<kbd>V_B</kbd>: A numerical matrix. Covariance matrix of the vectorized tensors' parameters.
</p>
<p><kbd>V_b</kbd>: A numerical matrix. Covariance matrix of the covariates' parameters.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
