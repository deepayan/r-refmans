<!DOCTYPE html><html><head><title>Help for package adaHuber</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {adaHuber}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adaHuber-package'><p>adaHuber: Adaptive Huber Estimation and Regression</p></a></li>
<li><a href='#adaHuber.cov'><p>Adaptive Huber Covariance Estimation</p></a></li>
<li><a href='#adaHuber.cv.lasso'><p>Cross-Validated Regularized Adaptive Huber Regression.</p></a></li>
<li><a href='#adaHuber.lasso'><p>Regularized Adaptive Huber Regression</p></a></li>
<li><a href='#adaHuber.mean'><p>Adaptive Huber Mean Estimation</p></a></li>
<li><a href='#adaHuber.reg'><p>Adaptive Huber Regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Adaptive Huber Estimation and Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-03-04</td>
</tr>
<tr>
<td>Description:</td>
<td>Huber-type estimation for mean, covariance and (regularized) regression. For all the methods, the robustification parameter tau is chosen by a tuning-free principle.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/XiaoouPan/adaHuber">https://github.com/XiaoouPan/adaHuber</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.3)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo (&ge; 0.9.850.1.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-03-05 19:25:32 UTC; xopan</td>
</tr>
<tr>
<td>Author:</td>
<td>Xiaoou Pan [aut, cre],
  Wen-Xin Zhou [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xiaoou Pan &lt;xip024@ucsd.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-03-09 07:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='adaHuber-package'>adaHuber: Adaptive Huber Estimation and Regression</h2><span id='topic+adaHuber-package'></span>

<h3>Description</h3>

<p>Huber-type robust estimation for mean, covariance and (penalized) regression.
</p>


<h3>Author(s)</h3>

<p>Xiaoou Pan &lt;xip024@ucsd.edu&gt; and Wen-Xin Zhou &lt;wez243@ucsd.edu&gt;
</p>


<h3>References</h3>

<p>Ke, Y., Minsker, S., Ren, Z., Sun, Q. and Zhou, W.-X. (2019). User-friendly covariance estimation for heavy-tailed distributions. Statis. Sci., 34, 454-471.
</p>
<p>Pan, X., Sun, Q. and Zhou, W.-X. (2021). Iteratively reweighted l1-penalized robust regression. Electron. J. Stat., 15, 3287-3348.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Stat. Assoc., 115, 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>

<hr>
<h2 id='adaHuber.cov'>Adaptive Huber Covariance Estimation</h2><span id='topic+adaHuber.cov'></span>

<h3>Description</h3>

<p>Adaptive Huber covariance estimator from a data sample, with robustification parameter <code class="reqn">\tau</code> determined by a tuning-free principle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaHuber.cov(X, epsilon = 1e-04, iteMax = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adaHuber.cov_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">p</code> data matrix.</p>
</td></tr>
<tr><td><code id="adaHuber.cov_+3A_epsilon">epsilon</code></td>
<td>
<p>(<strong>optional</strong>) The tolerance level in the iterative estimation procedure. The problem is converted to mean estimation, and the stopping rule is the same as <code>adaHuber.mean</code>. The defalut value is 1e-4.</p>
</td></tr>
<tr><td><code id="adaHuber.cov_+3A_itemax">iteMax</code></td>
<td>
<p>(<strong>optional</strong>) Maximum number of iterations. Default is 500.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed data <code class="reqn">X</code> is an <code class="reqn">n</code> by <code class="reqn">p</code> matrix. The distribution of each entry can be asymmetrix and/or heavy-tailed. The function outputs a robust estimator for the covariance matrix of <code class="reqn">X</code>. For the input matrix <code>X</code>, both low-dimension (<code class="reqn">p &lt; n</code>) and high-dimension (<code class="reqn">p &gt; n</code>) are allowed.
</p>


<h3>Value</h3>

<p>A list including the following terms will be returned:
</p>

<dl>
<dt><code>means</code></dt><dd><p>The Huber estimators for column means. A <code class="reqn">p</code>-dimensional vector.</p>
</dd>
<dt><code>cov</code></dt><dd><p>The Huber estimator for covariance matrix. A <code class="reqn">p</code> by <code class="reqn">p</code> matrix.</p>
</dd>
</dl>



<h3>References</h3>

<p>Huber, P. J. (1964). Robust estimation of a location parameter. Ann. Math. Statist., 35, 73â€“101.
</p>
<p>Ke, Y., Minsker, S., Ren, Z., Sun, Q. and Zhou, W.-X. (2019). User-friendly covariance estimation for heavy-tailed distributions. Statis. Sci., 34, 454-471.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adaHuber.mean">adaHuber.mean</a></code> for adaptive Huber mean estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100
p = 5
X = matrix(rt(n * p, 3), n, p)
fit.cov = adaHuber.cov(X)
fit.cov$means
fit.cov$cov
</code></pre>

<hr>
<h2 id='adaHuber.cv.lasso'>Cross-Validated Regularized Adaptive Huber Regression.</h2><span id='topic+adaHuber.cv.lasso'></span>

<h3>Description</h3>

<p>Sparse regularized adaptive Huber regressionwith &quot;lasso&quot; penalty. The function implements a localized majorize-minimize algorithm with a gradient-based method. The regularization parameter <code class="reqn">\lambda</code> is selected by cross-validation, and the robustification parameter <code class="reqn">\tau</code> is determined by a tuning-free principle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaHuber.cv.lasso(
  X,
  Y,
  lambdaSeq = NULL,
  kfolds = 5,
  numLambda = 50,
  phi0 = 0.01,
  gamma = 1.2,
  epsilon = 0.001,
  iteMax = 500
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adaHuber.cv.lasso_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code> by <code class="reqn">p</code> design matrix. Each row is a vector of observation with <code class="reqn">p</code> covariates.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_y">Y</code></td>
<td>
<p>An <code class="reqn">n</code>-dimensional response vector.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_lambdaseq">lambdaSeq</code></td>
<td>
<p>(<strong>optional</strong>) A sequence of candidate regularization parameters. If unspecified, a reasonable sequence will be generated.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_kfolds">kfolds</code></td>
<td>
<p>(<strong>optional</strong>) Number of folds for cross-validation. Default is 5.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_numlambda">numLambda</code></td>
<td>
<p>(<strong>optional</strong>) Number of <code class="reqn">\lambda</code> values for cross-validation if <code>lambdaSeq</code> is unspeficied. Default is 50.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_phi0">phi0</code></td>
<td>
<p>(<strong>optional</strong>) The initial quadratic coefficient parameter in the local adaptive majorize-minimize algorithm. Default is 0.01.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_gamma">gamma</code></td>
<td>
<p>(<strong>optional</strong>) The adaptive search parameter (greater than 1) in the local adaptive majorize-minimize algorithm. Default is 1.2.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_epsilon">epsilon</code></td>
<td>
<p>(<strong>optional</strong>) A tolerance level for the stopping rule. The iteration will stop when the maximum magnitude of the change of coefficient updates is less than <code>epsilon</code>. Default is 0.001.</p>
</td></tr>
<tr><td><code id="adaHuber.cv.lasso_+3A_itemax">iteMax</code></td>
<td>
<p>(<strong>optional</strong>) Maximum number of iterations. Default is 500.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object containing the following items will be returned:
</p>

<dl>
<dt><code>coef</code></dt><dd><p>A <code class="reqn">(p + 1)</code> vector of estimated sparse regression coefficients, including the intercept.</p>
</dd>
<dt><code>lambdaSeq</code></dt><dd><p>The sequence of candidate regularization parameters.</p>
</dd>
<dt><code>lambda</code></dt><dd><p>Regularization parameter selected by cross-validation.</p>
</dd>
<dt><code>tau</code></dt><dd><p>The robustification parameter calibrated by the tuning-free principle.</p>
</dd>
<dt><code>iteration</code></dt><dd><p>Number of iterations until convergence.</p>
</dd>
<dt><code>phi</code></dt><dd><p>The quadratic coefficient parameter in the local adaptive majorize-minimize algorithm.</p>
</dd>
</dl>



<h3>References</h3>

<p>Pan, X., Sun, Q. and Zhou, W.-X. (2021). Iteratively reweighted l1-penalized robust regression. Electron. J. Stat., 15, 3287-3348.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Statist. Assoc., 115 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+adaHuber.lasso">adaHuber.lasso</a></code> for regularized adaptive Huber regression with a specified <code class="reqn">lambda</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100; p = 200; s = 5
beta = c(rep(1.5, s + 1), rep(0, p - s))
X = matrix(rnorm(n * p), n, p)
err = rt(n, 2)
Y = cbind(rep(1, n), X) %*% beta + err 

fit.lasso = adaHuber.cv.lasso(X, Y)
beta.lasso = fit.lasso$coef
</code></pre>

<hr>
<h2 id='adaHuber.lasso'>Regularized Adaptive Huber Regression</h2><span id='topic+adaHuber.lasso'></span>

<h3>Description</h3>

<p>Sparse regularized Huber regression models in high dimensions with <code class="reqn">\ell_1</code> (lasso) penalty. The function implements a localized majorize-minimize algorithm with a gradient-based method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaHuber.lasso(
  X,
  Y,
  lambda = 0.5,
  tau = 0,
  phi0 = 0.01,
  gamma = 1.2,
  epsilon = 0.001,
  iteMax = 500
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adaHuber.lasso_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code> by <code class="reqn">p</code> design matrix. Each row is a vector of observation with <code class="reqn">p</code> covariates.</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_y">Y</code></td>
<td>
<p>An <code class="reqn">n</code>-dimensional response vector.</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_lambda">lambda</code></td>
<td>
<p>(<strong>optional</strong>) Regularization parameter. Must be positive. Default is 0.5.</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_tau">tau</code></td>
<td>
<p>(<strong>optional</strong>) The robustness parameter. If not specified or the input value is non-positive, a tuning-free principle is applied. Default is 0 (hence, tuning-free).</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_phi0">phi0</code></td>
<td>
<p>(<strong>optional</strong>) The initial quadratic coefficient parameter in the local adaptive majorize-minimize algorithm. Default is 0.01.</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_gamma">gamma</code></td>
<td>
<p>(<strong>optional</strong>) The adaptive search parameter (greater than 1) in the local adaptive majorize-minimize algorithm. Default is 1.2.</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_epsilon">epsilon</code></td>
<td>
<p>(<strong>optional</strong>) Tolerance level of the gradient-based algorithm. The iteration will stop when the maximum magnitude of all the elements of the gradient is less than <code>tol</code>. Default is 1e-03.</p>
</td></tr>
<tr><td><code id="adaHuber.lasso_+3A_itemax">iteMax</code></td>
<td>
<p>(<strong>optional</strong>) Maximum number of iterations. Default is 500.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object containing the following items will be returned:
</p>

<dl>
<dt><code>coef</code></dt><dd><p>A <code class="reqn">(p + 1)</code> vector of estimated sparse regression coefficients, including the intercept.</p>
</dd>
<dt><code>tau</code></dt><dd><p>The robustification parameter calibrated by the tuning-free principle (if the input is non-positive).</p>
</dd>
<dt><code>iteration</code></dt><dd><p>Number of iterations until convergence.</p>
</dd>
<dt><code>phi</code></dt><dd><p>The quadratic coefficient parameter in the local adaptive majorize-minimize algorithm.</p>
</dd>
</dl>



<h3>References</h3>

<p>Pan, X., Sun, Q. and Zhou, W.-X. (2021). Iteratively reweighted l1-penalized robust regression. Electron. J. Stat., 15, 3287-3348.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Statist. Assoc., 115 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+adaHuber.cv.lasso">adaHuber.cv.lasso</a></code> for regularized adaptive Huber regression with cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 200; p = 500; s = 10
beta = c(rep(1.5, s + 1), rep(0, p - s))
X = matrix(rnorm(n * p), n, p)
err = rt(n, 2)
Y = cbind(rep(1, n), X) %*% beta + err 

fit.lasso = adaHuber.lasso(X, Y, lambda = 0.5)
beta.lasso = fit.lasso$coef
</code></pre>

<hr>
<h2 id='adaHuber.mean'>Adaptive Huber Mean Estimation</h2><span id='topic+adaHuber.mean'></span>

<h3>Description</h3>

<p>Adaptive Huber mean estimator from a data sample, with robustification parameter <code class="reqn">\tau</code> determined by a tuning-free principle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaHuber.mean(X, epsilon = 1e-04, iteMax = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adaHuber.mean_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n</code>-dimensional data vector.</p>
</td></tr>
<tr><td><code id="adaHuber.mean_+3A_epsilon">epsilon</code></td>
<td>
<p>(<strong>optional</strong>) The tolerance level in the iterative estimation procedure, iteration will stop when <code class="reqn">|\mu_new - \mu_old| &lt; \epsilon</code>. The defalut value is 1e-4.</p>
</td></tr>
<tr><td><code id="adaHuber.mean_+3A_itemax">iteMax</code></td>
<td>
<p>(<strong>optional</strong>) Maximum number of iterations. Default is 500.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following terms will be returned:
</p>

<dl>
<dt><code>mu</code></dt><dd><p>The Huber mean estimator.</p>
</dd>
<dt><code>tau</code></dt><dd><p>The robustness parameter determined by the tuning-free principle.</p>
</dd>
<dt><code>iteration</code></dt><dd><p>The number of iterations in the estimation procedure.</p>
</dd>
</dl>



<h3>References</h3>

<p>Huber, P. J. (1964). Robust estimation of a location parameter. Ann. Math. Statist., 35, 73â€“101.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1000
mu = 2
X = rt(n, 2) + mu
fit.mean = adaHuber.mean(X)
fit.mean$mu
</code></pre>

<hr>
<h2 id='adaHuber.reg'>Adaptive Huber Regression</h2><span id='topic+adaHuber.reg'></span>

<h3>Description</h3>

<p>Adaptive Huber regression from a data sample, with robustification parameter <code class="reqn">\tau</code> determined by a tuning-free principle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaHuber.reg(
  X,
  Y,
  method = c("standard", "adaptive"),
  epsilon = 1e-04,
  iteMax = 500
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adaHuber.reg_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code> by <code class="reqn">p</code> design matrix. Each row is a vector of observation with <code class="reqn">p</code> covariates. Number of observations <code class="reqn">n</code> must be greater than number of covariates <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="adaHuber.reg_+3A_y">Y</code></td>
<td>
<p>An <code class="reqn">n</code>-dimensional response vector.</p>
</td></tr>
<tr><td><code id="adaHuber.reg_+3A_method">method</code></td>
<td>
<p>(<strong>optional</strong>) A character string specifying the method to calibrate the robustification parameter <code class="reqn">\tau</code>. Two choices are &quot;standard&quot;(default) and &quot;adaptive&quot;. See Wang et al.(2021) for details.</p>
</td></tr>
<tr><td><code id="adaHuber.reg_+3A_epsilon">epsilon</code></td>
<td>
<p>(<strong>optional</strong>) Tolerance level of the gradient descent algorithm. The iteration will stop when the maximum magnitude of all the elements of the gradient is less than <code>tol</code>. Default is 1e-04.</p>
</td></tr>
<tr><td><code id="adaHuber.reg_+3A_itemax">iteMax</code></td>
<td>
<p>(<strong>optional</strong>) Maximum number of iterations. Default is 500.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object containing the following items will be returned:
</p>

<dl>
<dt><code>coef</code></dt><dd><p>A <code class="reqn">(p + 1)</code>-vector of estimated regression coefficients, including the intercept.</p>
</dd>
<dt><code>tau</code></dt><dd><p>The robustification parameter calibrated by the tuning-free principle.</p>
</dd>
<dt><code>iteration</code></dt><dd><p>Number of iterations until convergence.</p>
</dd>
</dl>



<h3>References</h3>

<p>Huber, P. J. (1964). Robust estimation of a location parameter. Ann. Math. Statist., 35, 73â€“101.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Statist. Assoc., 115, 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 200
p = 10
beta = rep(1.5, p + 1)
X = matrix(rnorm(n * p), n, p)
err = rt(n, 2)
Y = cbind(1, X) %*% beta + err

fit.huber = adaHuber.reg(X, Y, method = "standard")
beta.huber = fit.huber$coef

fit.adahuber = adaHuber.reg(X, Y, method = "adaptive")
beta.adahuber = fit.adahuber$coef
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
