<!DOCTYPE html><html><head><title>Help for package tcl</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tcl}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#change_test'><p>Tests in context of measurement of change using LLTM.</p></a></li>
<li><a href='#discr_test'><p>Testing item discriminations</p></a></li>
<li><a href='#invar_test'><p>Test of invariance of item parameters between two groups.</p></a></li>
<li><a href='#LLTM_test'><p>Testing linear restrictions on parameter space of item parameters of RM.</p></a></li>
<li><a href='#post_hocChange'><p>Power analysis of tests in context of measurement of change using LLTM</p></a></li>
<li><a href='#post_hocPCM'><p>Power analysis of tests of invariance of item parameters between two groups of</p>
persons in partial credit model</a></li>
<li><a href='#post_hocRM'><p>Power analysis of tests of invariance of item parameters between two groups of persons in binary Rasch model</p></a></li>
<li><a href='#powerChange'><p>Power analysis of tests in context of measurement of change using LLTM</p></a></li>
<li><a href='#powerPCM'><p>Power analysis of tests of invariance of item parameters between two groups</p>
of persons in partial credit model</a></li>
<li><a href='#powerRM'><p>Power analysis of tests of invariance of item parameters between two groups</p>
of persons in binary Rasch model</a></li>
<li><a href='#sa_sizeChange'><p>Sample size planning for tests in context of measurement of change using LLTM</p></a></li>
<li><a href='#sa_sizePCM'><p>Sample size planning for tests of invariance of item-category parameters between two groups of persons in partial credit model</p></a></li>
<li><a href='#sa_sizeRM'><p>Sample size planning for tests of invariance of item parameters between two groups of persons in binary Rasch model</p></a></li>
<li><a href='#tcl_hessian'><p>Computation of Hessian matrix.</p></a></li>
<li><a href='#tcl_scorefun'><p>Computation of score function.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Testing in Conditional Likelihood Context</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-02</td>
</tr>
<tr>
<td>Author:</td>
<td>Clemens Draxler [aut, cre],
  Andreas Kurz [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Clemens Draxler &lt;clemens.draxler@umit-tirol.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of hypothesis testing in an extended Rasch modeling framework,
    including sample size planning procedures and power computations. Provides 4 statistical tests, 
    i.e., gradient test (GR), likelihood ratio test (LR), Rao score or Lagrange multiplier test (RS), 
    and Wald test, for testing a number of hypotheses referring to the Rasch model (RM), linear 
    logistic test model (LLTM), rating scale model (RSM), and partial credit model (PCM). Three 
    types of functions for power and sample size computations are provided. Firstly, functions to 
    compute the sample size given a user-specified (predetermined) deviation from the hypothesis 
    to be tested, the level alpha, and the power of the test. Secondly, functions to evaluate the 
    power of the tests given a user-specified (predetermined) deviation from the hypothesis to be 
    tested, the level alpha of the test, and the sample size. Thirdly, functions to evaluate the 
    so-called post hoc power of the tests. This is the power of the tests given the observed 
    deviation of the data from the hypothesis to be tested and a user-specified level alpha of the
    test. Power and sample size computations are based on a Monte Carlo simulation approach. It is
    computationally very efficient. The variance of the random error in computing power and sample
    size arising from the simulation approach is analytically derived by using the delta method. 
    Draxler, C., &amp; Alexandrowicz, R. W. (2015), &lt;<a href="https://doi.org/10.1007%2Fs11336-015-9472-y">doi:10.1007/s11336-015-9472-y</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>eRm, psychotools, ltm, numDeriv, graphics, grDevices, stats,
methods, MASS, splines, Matrix, lattice, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-02 12:38:48 UTC; pandabook</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-02 22:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='change_test'>Tests in context of measurement of change using LLTM.</h2><span id='topic+change_test'></span>

<h3>Description</h3>

<p>Computes gradient (GR), likelihood ratio (LR), Rao score (RS) and Wald (W) test statistics
for hypotheses on parameters expressing change between two time points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>change_test(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="change_test_+3A_x">X</code></td>
<td>
<p>Data matrix containing the responses of n persons to 2k binary items.
Columns 1 to k contain the responses to k items at time point 1,
and columns (k+1) to 2k the responses to the same k items at time point 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume all items be presented twice (2 time points) to the same persons.
The data matrix X has n rows (number of persons) and 2k columns considered as virtual items.
Assume a constant shift of item difficulties of each item between the 2 time points represented
by one parameter. The shift parameter is the only parameter of interest.
Of interest is the test of the hypothesis that the shift parameter equals 0 against the two-sided
alternative that it is not equal to zero.
</p>


<h3>Value</h3>

<p>A list of test statistics, degrees of freedom, and p-values.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of gradient (GR), likelihood ratio (LR), Rao score (RS), and Wald test statistics.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>A vector of corresponding p-values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Fischer, G. H. (1995). The Linear Logistic Test Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch models: Foundations, Recent Developments, and Applications (pp. 131-155). New York: Springer.
</p>
<p>Fischer, G. H. (1983). Logistic Latent Trait Models with Linear Constraints. Psychometrika, 48(1), 3-26.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+invar_test">invar_test</a></code>, and <code><a href="#topic+LLTM_test">LLTM_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example with 400 persons and 4 items
# presented twice, thus 8 virtual items

# Data y generated under the assumption that shift parameter equals 0
# (no change from time point 1 to 2)

# design matrix W used only for example data generation
#     (not used for estimating in change_test function)
W &lt;- rbind(c(1,0,0,0,0),
  c(0,1,0,0,0),
  c(0,0,1,0,0),
  c(0,0,0,1,0),
  c(1,0,0,0,1),
  c(0,1,0,0,1),
  c(0,0,1,0,1),
  c(0,0,0,1,1))

# eta Parameter, first 4 are nuisance, i.e. , easiness parameters of the 4 items
# at time point 1, last one is the shift parameter.
eta &lt;- c(-2,-1,1,2,0)

y &lt;- eRm::sim.rasch(persons = rnorm(400), items = colSums(eta * t(W)))

res &lt;- change_test(X = y)

res$test # test statistics
res$df # degrees of freedoms
res$pvalue # p-values


## End(Not run)
</code></pre>

<hr>
<h2 id='discr_test'>Testing item discriminations</h2><span id='topic+discr_test'></span>

<h3>Description</h3>

<p>Computes gradient (GR), likelihood ratio (LR), Rao score (RS) and Wald (W) test of
hypothesis of equal item discriminations against the
alternative that at least one item discriminates differently (only for binary data).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discr_test(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discr_test_+3A_x">X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tests are based on the following model suggested in Draxler, Kurz, GÃ¼rer, and Nolte (2022)
</p>
<p style="text-align: center;"><code class="reqn"> \text{logit} \big( E(Y) \big ) = \tau + \alpha + \delta (r - 1), </code>
</p>

<p>where <code class="reqn">E(Y)</code> ist the expected value of a binary response (of a person to an item),
<code class="reqn">r = 1, \dots, k - 1</code> is the person score, i.e., number of correct responses of that person
when responding to <code class="reqn">k</code> items, <code class="reqn">\tau</code> is the respective person parameter and <code class="reqn">\alpha</code> and
<code class="reqn">\delta</code> are two parameters referring to the respective item. The parameter <code class="reqn">\alpha</code>
represents a baseline, i.e., the easiness or attractiveness of the respective item in person score
group <code class="reqn">r = 1</code>. The parameter <code class="reqn">\delta</code> denotes the constant change of the attractiveness of that
item between successive person score groups. Thus, the model assumes a linear effect of the person
score <code class="reqn">r</code> on the logit of the probability of a correct response.
</p>
<p>The four test statistics are derived from a conditional likelihood function in which the
<code class="reqn">\tau</code> parameters are eliminated by conditioning on the observed person scores.
The hypothesis to be tested is formally given by setting all <code class="reqn">\delta</code> parameters equal to <code class="reqn">0</code>.
The alternative assumes that at least one <code class="reqn">\delta</code> parameter is not equal to <code class="reqn">0</code>.
</p>


<h3>Value</h3>

<p>A list of test statistics, degrees of freedom, and p-values.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of gradient (GR), likelihood ratio (LR), Rao score (RS), and Wald test statistics.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>A numeric vector of corresponding degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>A vector of corresponding p-values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C., Kurz. A., GÃ¼rer, C., &amp; Nolte, J. P. (2022). An improved inferential procedure to evaluate item
discriminations in a conditional maximum likelihood framework. Manuscript submitted for publication.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+invar_test">invar_test</a></code>, <code><a href="#topic+change_test">change_test</a></code>, and <code><a href="#topic+LLTM_test">LLTM_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##### Dataset PISA Mathematics data.pisaMath {sirt} #####

library(sirt)
data(data.pisaMath)
y &lt;- data.pisaMath$data[, grep(names(data.pisaMath$data), pattern = "M" )]

res &lt;- discr_test(X = y)
# $test
# GR     LR     RS      W
# 72.430 73.032 76.725 73.470
#
# $df
# GR LR RS  W
# 10 10 10 10
#
# $pvalue
#       GR        LR        RS         W
# "&lt; 0.001" "&lt; 0.001" "&lt; 0.001" "&lt; 0.001"
#
# $call
# discr_test(X = y)


## End(Not run)
</code></pre>

<hr>
<h2 id='invar_test'>Test of invariance of item parameters between two groups.</h2><span id='topic+invar_test'></span>

<h3>Description</h3>

<p>Computes gradient (GR), likelihood ratio (LR), Rao score (RS) and Wald (W) test statistics
for hypothesis of equality of item parameters between two groups of persons against a two-sided
alternative that at least one item parameter differs between the two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invar_test(X, splitcr = "median", model = "RM")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invar_test_+3A_x">X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code id="invar_test_+3A_splitcr">splitcr</code></td>
<td>
<p>Split criterion which is either &quot;mean&quot;, &quot;median&quot; or a numeric vector x.
</p>

<dl>
<dt>&quot;mean&quot;</dt><dd><p>Corresponds to division of the sample according to the mean of the person score.</p>
</dd>
<dt>&quot;median&quot;</dt><dd><p>Corresponds to division of the sample according to the median of the person score.</p>
</dd>
<dt>x</dt><dd><p>Has length equal to number of persons and contains zeros and ones. It indicates group membership for every person.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="invar_test_+3A_model">model</code></td>
<td>
<p>RM, PCM, RSM</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that items are excluded for the computation of GR,LR, and W due to inappropriate
response patterns within subgroups and for computation of RS due to inappropriate
response patterns in the total data. If the model is identified from the total data but not from one
or both subgroups only RS will be computed. If the model is not identified from the total data,
no test statistic is computable.
</p>


<h3>Value</h3>

<p>A list of test statistics, degrees of freedom, and p-values.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of gradient (GR), likelihood ratio (LR), Rao score (RS), and Wald test statistics.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>A numeric vector of corresponding degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>A vector of corresponding p-values.</p>
</td></tr>
<tr><td><code>deleted_items</code></td>
<td>
<p>A list with numeric vectors of item numbers that were excluded before computing corresponding test statistics.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+change_test">change_test</a></code>, and <code><a href="#topic+LLTM_test">LLTM_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##### Rasch Model #####
y &lt;- eRm::sim.rasch(persons = rnorm(400), c(0,-3,-2,-1,0,1,2,3))
x &lt;- c(rep(1,200),rep(0,200))

res &lt;- invar_test(y, splitcr = x, model = "RM")

res$test # test statistics
res$df # degrees of freedoms
res$pvalue # p-values
res$deleted_items # excluded items

$test
  GR    LR    RS     W
14.492 14.083 13.678 12.972

$df
GR LR RS  W
7  7  7  7

$pvalue
  GR    LR    RS     W
"0.043" "0.050" "0.057" "0.073"

$deleted_items
 $deleted_items$GR
 [1] "none"

 $deleted_items$LR
 [1] "none"

 $deleted_items$RS
 [1] "none"

 $deleted_items$W
 [1] "none"


$call
invar_test(X = y, splitcr = x, model = "RM")


## End(Not run)
</code></pre>

<hr>
<h2 id='LLTM_test'>Testing linear restrictions on parameter space of item parameters of RM.</h2><span id='topic+LLTM_test'></span>

<h3>Description</h3>

<p>Computes gradient (GR), likelihood ratio (LR), Rao score (RS) and Wald (W) test statistics for
hypotheses defined by linear restrictions on parameter space of the item parameters of RM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LLTM_test(X, W)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LLTM_test_+3A_x">X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code id="LLTM_test_+3A_w">W</code></td>
<td>
<p>Design matrix of LLTM.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RM item parameters are assumed to be linear in the LLTM parameters.
The coefficients of the linear functions are specified by a design matrix W. In this context,
the LLTM is considered as a more parsimonious model than the RM. The LLTM parameters can be
interpreted as the difficulties of certain cognitive operations needed to respond correctly
to psychological test items. The item parameters of the RM are assumed to be linear combinations
of these cognitive operations. These linear combinations are defined in the design matrix W.
</p>


<h3>Value</h3>

<p>A list of test statistics, degrees of freedom, and p-values.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of gradient (GR), likelihood ratio (LR), Rao score (RS), and Wald test statistics.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>A vector of corresponding p-values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Fischer, G. H. (1995). The Linear Logistic Test Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch models: Foundations, Recent Developments, and Applications (pp. 131-155). New York: Springer.
</p>
<p>Fischer, G. H. (1983). Logistic Latent Trait Models with Linear Constraints. Psychometrika, 48(1), 3-26.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+change_test">change_test</a></code>, and <code><a href="#topic+invar_test">invar_test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example assuming no deviation from linear restriction

# design matrix W defining linear restriction
W &lt;- rbind(c(1,0), c(0,1), c(1,1), c(2,1))

# assumed eta parameters of LLTM for data generation
eta &lt;- c(-0.5, 1)

# assumed vector of item parameters of RM
b &lt;- colSums(eta * t(W))

y &lt;- eRm::sim.rasch(persons = rnorm(400), items = b - b[1])  # sum0 = FALSE

res &lt;- LLTM_test(X = y, W = W )

res$test # test statistics
res$df # degrees of freedoms
res$pvalue # p-values


## End(Not run)
</code></pre>

<hr>
<h2 id='post_hocChange'>Power analysis of tests in context of measurement of change using LLTM</h2><span id='topic+post_hocChange'></span>

<h3>Description</h3>

<p>Returns post hoc power of Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given data and probability of error of first kind <code class="reqn">\alpha</code>.
The hypothesis to be tested states that the shift parameter quantifying the constant change
for all items between time points 1 and 2 equals 0. The alternative states that the
shift parameter is not equal to 0. It is assumed that the same items are presented at both
time points. See function <code><a href="#topic+change_test">change_test</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_hocChange(alpha = 0.05, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="post_hocChange_+3A_alpha">alpha</code></td>
<td>
<p>Probability of error of first kind.</p>
</td></tr>
<tr><td><code id="post_hocChange_+3A_data">data</code></td>
<td>
<p>Data matrix as required for function <code><a href="#topic+change_test">change_test</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power of the tests (Wald, LR, score, and gradient) is determined from the assumption that the
approximate distributions of the four test statistics are from the family of noncentral <code class="reqn">\chi^2</code>
distributions with <code class="reqn">df = 1</code> and noncentrality parameter <code class="reqn">\lambda</code>. In case of evaluating the post hoc power,
<code class="reqn">\lambda</code> is assumed to be given by the observed value of the test statistic. Given the probability of the
error of the first kind <code class="reqn">\alpha</code> the post hoc power of the tests can be determined from <code class="reqn">\lambda</code>.
More details about the distributions of the test statistics and the relationship between <code class="reqn">\lambda</code>, power, and
sample size can be found in Draxler and Alexandrowicz (2015).
</p>
<p>In particular, let <code class="reqn">q_{\alpha}</code> be the <code class="reqn">1- \alpha</code> quantile of the central <code class="reqn">\chi^2</code> distribution with df = 1. Then,
</p>
<p style="text-align: center;"><code class="reqn">power = 1 - F_{df, \lambda} (q_{\alpha}),</code>
</p>

<p>where <code class="reqn">F_{df, \lambda}</code> is the cumulative distribution function of the noncentral <code class="reqn">\chi^2</code> distribution with
<code class="reqn">df = 1</code> and <code class="reqn">\lambda</code> equal to the observed value of the test statistic.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of Wald (W), likelihood ratio (LR), Rao score (RS), and gradient (GR)  test statistics.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>Posthoc power value for each test.</p>
</td></tr>
<tr><td><code>observed deviation</code></td>
<td>
<p>CML estimate of shift parameter expressing observed deviation from hypothesis to be tested.</p>
</td></tr>
<tr><td><code>person score distribution</code></td>
<td>
<p>Relative frequencies of person scores. Uninformative scores, i.e., minimum and maximum score,
are omitted. Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which power is determined.
It equals observed value of test statistic.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample size determination within the scope of conditional
maximum likelihood estimation with special focus on testing the Rasch model. Psychometrika, 80(4), 897-919.
</p>
<p>Fischer, G. H. (1995). The Linear Logistic Test Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch models: Foundations, Recent Developments, and Applications (pp. 131-155). New York: Springer.
</p>
<p>Fischer, G. H. (1983). Logistic Latent Trait Models with Linear Constraints. Psychometrika, 48(1), 3-26.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+sa_sizeChange">sa_sizeChange</a></code>, and <code><a href="#topic+powerChange">powerChange</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example with 200 persons and 4 items
# presented twice, thus 8 virtual items

# Data y generated under the assumption that shift parameter equals 0.5
# (change from time point 1 to 2)

# design matrix W used only for exmaple data generation
#     (not used for estimating in change_test function)
W &lt;- rbind(c(1,0,0,0,0), c(0,1,0,0,0), c(0,0,1,0,0), c(0,0,0,1,0),
           c(1,0,0,0,1), c(0,1,0,0,1), c(0,0,1,0,1), c(0,0,0,1,1))

# eta parameter vector, first 4 are nuisance, i.e., item parameters at time point 1.
# (easiness parameters of the 4 items at time point 1),
# last one is the shift parameter
eta &lt;- c(-2,-1,1,2,0.5)

y &lt;- eRm::sim.rasch(persons=rnorm(150), items=colSums(-eta*t(W)))

res &lt;- post_hocChange(alpha = 0.05, data = y)

# &gt; res
# $test
#     W     LR     RS     GR
# 9.822 10.021  9.955 10.088
#
# $power
#     W    LR    RS    GR
# 0.880 0.886 0.884 0.888
#
# $`observed deviation (estimate of shift parameter)`
# [1] 0.504
#
# $`person score distribution`
#
#     1     2     3     4     5     6     7
# 0.047 0.047 0.236 0.277 0.236 0.108 0.047
#
# $`degrees of freedom`
# [1] 1
#
# $`noncentrality parameter`
#     W     LR     RS     GR
# 9.822 10.021  9.955 10.088
#
# $call
# post_hocChange(alpha = 0.05, data = y)

## End(Not run)
</code></pre>

<hr>
<h2 id='post_hocPCM'>Power analysis of tests of invariance of item parameters between two groups of
persons in partial credit model</h2><span id='topic+post_hocPCM'></span>

<h3>Description</h3>

<p>Returns post hoc power of Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test  given data and probability of error of first kind <code class="reqn">\alpha</code>.
The hypothesis to be tested assumes equal item-category parameters of the partial
credit model between two predetermined groups of persons. The alternative states that
at least one of the parameters differs between the two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_hocPCM(alpha = 0.05, data, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="post_hocPCM_+3A_alpha">alpha</code></td>
<td>
<p>Probability of error of first kind.</p>
</td></tr>
<tr><td><code id="post_hocPCM_+3A_data">data</code></td>
<td>
<p>Data matrix with item responses (in ordered categories starting from 0).</p>
</td></tr>
<tr><td><code id="post_hocPCM_+3A_x">x</code></td>
<td>
<p>A numeric vector of length equal to number of persons that contains zeros and ones indicating group membership of the persons.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power of the tests (Wald, LR, score, and gradient) is determined from the assumption
that the approximate distributions of the four test statistics are from the family of
noncentral <code class="reqn">\chi^2</code>  distributions with <code class="reqn">df</code> equal to the number of free item-category
parameters in the partial credit model and noncentrality parameter <code class="reqn">\lambda</code>. In case of evaluating
the post hoc power, <code class="reqn">\lambda</code> is assumed to be given by the observed value of the test statistic.
Given the probability of the error of the first kind <code class="reqn">\alpha</code> the post hoc power of the tests
can be determined from <code class="reqn">\lambda</code>. More details about the distributions of the test statistics and the
relationship between <code class="reqn">\lambda</code>, power, and sample size can be found in Draxler and Alexandrowicz (2015).
</p>
<p>In particular, let <code class="reqn">q_{\alpha}</code> be the <code class="reqn">1- \alpha</code> quantile of the central <code class="reqn">\chi^2</code> distribution
with <code class="reqn">df</code> equal to the number of free item-category parameters. Then,
</p>
<p style="text-align: center;"><code class="reqn">power = 1 - F_{df, \lambda} (q_{\alpha}),</code>
</p>

<p>where <code class="reqn">F_{df, \lambda}</code> is the cumulative distribution function of the noncentral <code class="reqn">\chi^2</code>
distribution with <code class="reqn">df</code> equal to the number of free item-category parameters and <code class="reqn">\lambda</code> equal to the
observed value of the test statistic.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of Wald (W), likelihood ratio (LR), Rao score (RS), and gradient (GR)  test statistics.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>Post hoc power value for each test.</p>
</td></tr>
<tr><td><code>observed global deviation</code></td>
<td>
<p>Observed global deviation from hypothesis to be tested represented by a single number.
It is obtained by dividing the test statistic by the informative sample size.
The latter does not include persons with minimum or maximum person score.</p>
</td></tr>
<tr><td><code>observed local deviation</code></td>
<td>
<p>CML estimates of free item-category parameters in both groups of persons representing observed deviation
from hypothesis to be tested locally per item and response category.</p>
</td></tr>
<tr><td><code>person score distribution in group 1</code></td>
<td>
<p>Relative frequencies of person scores in group 1. Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>person score distribution in group 2</code></td>
<td>
<p>Relative frequencies of person scores in group 2. Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which power is determined.
It equals observed value of test statistic.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+sa_sizePCM">sa_sizePCM</a></code>, and <code><a href="#topic+powerPCM">powerPCM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example for post hoc power analysis for PCM

y &lt;- eRm::pcmdat2
n &lt;- nrow(y) # sample size
x &lt;- c( rep(0,n/2), rep(1,n/2) ) # binary covariate

res &lt;- post_hocPCM(alpha = 0.05, data = y, x = x)

# &gt; res
# $test
#      W     LR     RS     GR
# 11.395 11.818 11.628 11.978
#
# $power
#     W    LR    RS    GR
# 0.683 0.702 0.694 0.709
#
# $`observed global deviation`
#     W    LR    RS    GR
# 0.045 0.046 0.045 0.047
#
# $`observed local deviation`
#        I1-C2 I2-C1 I2-C2  I3-C1  I3-C2  I4-C1  I4-C2
# group1 2.556 0.503 2.573 -2.573 -2.160 -1.272 -0.683
# group2 2.246 0.878 3.135 -1.852 -0.824 -0.494  0.941
#
# $`person score distribution in group 1`
#
#     1     2     3     4     5     6     7
# 0.016 0.097 0.137 0.347 0.121 0.169 0.113
#
# $`person score distribution in group 2`
#
#     1     2     3     4     5     6     7
# 0.015 0.083 0.136 0.280 0.152 0.227 0.106
#
# $`degrees of freedom`
# [1] 7
#
# $`noncentrality parameter`
#      W     LR     RS     GR
# 11.395 11.818 11.628 11.978
#
# $call
# post_hocPCM(alpha = 0.05, data = y, x = x)

## End(Not run)
</code></pre>

<hr>
<h2 id='post_hocRM'>Power analysis of tests of invariance of item parameters between two groups of persons in binary Rasch model</h2><span id='topic+post_hocRM'></span>

<h3>Description</h3>

<p>Returns post hoc power of Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given data and probability of error of first kind <code class="reqn">\alpha</code>.
The hypothesis to be tested assumes equal item parameters  between two predetermined groups
of persons. The alternative states that at least one of the parameters differs between the two
groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_hocRM(alpha = 0.05, data, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="post_hocRM_+3A_alpha">alpha</code></td>
<td>
<p>Probability of error of first kind.</p>
</td></tr>
<tr><td><code id="post_hocRM_+3A_data">data</code></td>
<td>
<p>Binary data matrix.</p>
</td></tr>
<tr><td><code id="post_hocRM_+3A_x">x</code></td>
<td>
<p>A numeric vector of length equal to number of persons containing zeros and ones indicating group membership of the persons.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power of the tests (Wald, LR, score, and gradient) is determined from the assumption that the
approximate distributions of the four test statistics are from the family of noncentral <code class="reqn">\chi^2</code>
distributions with <code class="reqn">df</code> equal to the number of items minus 1 and noncentrality parameter <code class="reqn">\lambda</code>. In case
of evaluating the post hoc power, <code class="reqn">\lambda</code> is assumed to be given by the observed value of the test statistic.
Given the probability of the error of the first kind <code class="reqn">\alpha</code> the post hoc power of the tests can be
determined from <code class="reqn">\lambda</code>. More details about the distributions of the test statistics and the relationship
between <code class="reqn">\lambda</code>, power, and sample size can be found in Draxler and Alexandrowicz (2015).
</p>
<p>In particular, let <code class="reqn">q_{\alpha}</code> be the <code class="reqn">1- \alpha</code> quantile of the central <code class="reqn">\chi^2</code> distribution
with df equal to the number of items minus 1. Then,
</p>
<p style="text-align: center;"><code class="reqn">power = 1 - F_{df, \lambda} (q_{\alpha}),</code>
</p>

<p>where <code class="reqn">F_{df, \lambda}</code> is the cumulative distribution function of the noncentral <code class="reqn">\chi^2</code> distribution
with <code class="reqn">df</code> equal to the number of items reduced by 1 and <code class="reqn">\lambda</code> equal to the observed value of the test statistic.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>test</code></td>
<td>
<p>A numeric vector of Wald (W), likelihood ratio (LR), Rao score (RS), and gradient (GR) test statistics.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>Post hoc power value for each test.</p>
</td></tr>
<tr><td><code>global deviation</code></td>
<td>
<p>Observed global deviation from hypothesis to be tested represented by a single number.
It is obtained by dividing the test statistic by the informative sample size. The latter does not include persons
with minimum or maximum person score. </p>
</td></tr>
<tr><td><code>local deviation</code></td>
<td>
<p>CML estimates of free item parameters in both groups of persons (first item parameter set
to 0 in both groups) representing observed deviation from hypothesis to be tested locally per item.</p>
</td></tr>
<tr><td><code>person score distribution in group 1</code></td>
<td>
<p>Relative frequencies of person scores in group 1. Uninformative scores,
i.e., minimum and maximum score, are omitted. Note that the person score distribution does also have an influence on
the power of the tests.</p>
</td></tr>
<tr><td><code>person score distribution in group 2</code></td>
<td>
<p>Relative frequencies of person scores in group 2. Uninformative scores,
i.e., minimum and maximum score, are omitted. Note that the person score distribution does also have an influence on
the power of the tests.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which power is determined.
It equals observed value of test statistic.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+sa_sizeRM">sa_sizeRM</a></code>, and <code><a href="#topic+powerRM">powerRM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example for post hoc power analysis for Rasch Model

y &lt;- eRm::raschdat1
n &lt;- nrow(y) # sample size
x &lt;- c( rep(0,n/2), rep(1,n/2) ) # binary covariate

res &lt;-  post_hocRM(alpha = 0.05, data = y, x = x)

# &gt; res
# $test
#      W     LR     RS     GR
# 29.241 29.981 29.937 30.238
#
# $power
#     W    LR    RS    GR
# 0.890 0.900 0.899 0.903
#
# $`observed global deviation`
#     W    LR    RS    GR
# 0.292 0.300 0.299 0.302
#
# $`observed local deviation`
#           I2    I3    I4    I5    I6    I7    I8    I9   I10   I11
# group1 1.039 0.693 2.790 2.404 1.129 1.039 0.864 1.039 2.790 2.244
# group2 2.006 0.945 2.006 3.157 1.834 0.690 0.822 1.061 2.689 2.260
#          I12   I13   I14   I15   I16   I17   I18   I19   I20   I21
# group1 1.412 3.777 3.038 1.315 2.244 1.039 1.221 2.404 0.608 0.608
# group2 0.945 2.962 4.009 1.171 2.175 1.472 2.091 2.344 1.275 0.690
#          I22   I23   I24   I25   I26   I27   I28   I29   I30
# group1 0.438 0.608 1.617 3.038 0.438 1.617 2.100 2.583 0.864
# group2 0.822 1.275 1.565 2.175 0.207 1.746 1.746 2.260 0.822
#
# $`person score distribution in group 1`
#
#    1    2    3    4    5    6    7    8    9   10   11   12   13
# 0.02 0.02 0.02 0.06 0.02 0.10 0.10 0.06 0.10 0.12 0.08 0.12 0.12
#   14   15   16   17   18   19   20   21   22   23   24   25   26
# 0.06 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
#   27   28   29
# 0.00 0.00 0.00
#
# $`person score distribution in group 2`
#
#    1    2    3    4    5    6    7    8    9   10   11   12   13
# 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
#   14   15   16   17   18   19   20   21   22   23   24   25   26
# 0.08 0.12 0.10 0.16 0.06 0.04 0.10 0.12 0.08 0.02 0.02 0.02 0.08
#   27   28   29
# 0.00 0.00 0.00
#
# $`degrees of freedom`
# [1] 29
#
# $`noncentrality parameter`
#      W     LR     RS     GR
# 29.241 29.981 29.937 30.238
#
# $call
# post_hocRM(alpha = 0.05, data = y, x = x)


## End(Not run)
</code></pre>

<hr>
<h2 id='powerChange'>Power analysis of tests in context of measurement of change using LLTM</h2><span id='topic+powerChange'></span>

<h3>Description</h3>

<p>Returns power of Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given probability of error of first kind <code class="reqn">\alpha</code>, sample size, and
a deviation from the hypothesis to be tested. The latter states that the shift parameter
quantifying the constant change for all items between time points 1 and 2 equals 0.
The alternative states that the shift parameter is not equal to 0.
It is assumed that the same items are presented at both time points. See function <code><a href="#topic+change_test">change_test</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerChange(alpha = 0.05, n_total, eta, persons = rnorm(10^6))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerChange_+3A_alpha">alpha</code></td>
<td>
<p>Probability of the error of first kind.</p>
</td></tr>
<tr><td><code id="powerChange_+3A_n_total">n_total</code></td>
<td>
<p>Total sample size for which power shall be determined.</p>
</td></tr>
<tr><td><code id="powerChange_+3A_eta">eta</code></td>
<td>
<p>A vector of eta parameters of the LLTM. The last element represents the constant change or shift for all items
between time points 1 and 2. The other elements of the vector are the item parameters at time point 1. A choice of the eta
parameters constitutes a scenario of deviation from the hypothesis of no change.</p>
</td></tr>
<tr><td><code id="powerChange_+3A_persons">persons</code></td>
<td>
<p>A vector of person parameters (drawn from a specified distribution). By default <code class="reqn">10^6</code> parameters are drawn at
random from the standard normal distribution. The larger this number the more accurate are the computations. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the power of the tests is determined from the assumption that the approximate distributions of
the four test statistics are from the family of noncentral <code class="reqn">\chi^2</code> distributions with <code class="reqn">df = 1</code> and noncentrality
parameter <code class="reqn">\lambda</code>. The latter depends on a scenario of deviation from the hypothesis to be tested and a specified sample size.
Given the probability of the error of the first kind <code class="reqn">\alpha</code> the power of the tests can be determined from <code class="reqn">\lambda</code>.
More details about the distributions of the test statistics and the relationship between <code class="reqn">\lambda</code>, power, and sample size can be found
in Draxler and Alexandrowicz (2015).
</p>
<p>As regards the concept of sample size a distinction between informative and total sample size has to be made since the power
of the tests depends only on the informative sample size. In the conditional maximum likelihood context, the responses of
persons with minimum or maximum person score are completely uninformative. They do not contribute to the value of the test
statistic. Thus, the informative sample size does not include these persons. The total sample size is composed of all persons.
</p>
<p>In particular, the determination of <code class="reqn">\lambda</code> and the power of the tests, respectively, is based on a simple Monte Carlo approach.
Data (responses of a large number of persons to a number of items presented at two time points) are generated given a
user-specified scenario of a deviation from the hypothesis to be tested. The hypothesis to be tested assumes no change
between time points 1 and 2. A scenario of a deviation is given by a choice of the item parameters at time point 1 and
the shift parameter, i.e., the LLTM eta parameters, as well as the person parameters (to be drawn randomly from a specified
distribution). The shift parameter represents a constant change of all item parameters from time point 1 to time point 2.
A test statistic <code class="reqn">T</code> (Wald, LR, score, or gradient) is computed from the simulated data. The observed value <code class="reqn">t</code> of the test
statistic is then divided by the informative sample size <code class="reqn">n_{infsim}</code> observed in the simulated data. This yields the so-called
global deviation <code class="reqn">e = t / n_{infsim}</code>, i.e., the chosen scenario of a deviation from the hypothesis to be tested being represented
by a single number. The power of the tests can be determined given a user-specified total sample size denoted by <code class="reqn">n_{total}</code>.
The noncentrality parameter <code class="reqn">\lambda</code> can then be expressed by <code class="reqn">\lambda = n_{total}* (n_{infsim} / n_{totalsim}) * e</code>,
where <code class="reqn">n_{totalsim}</code> denotes the total number of persons in the simulated data and <code class="reqn">n_{infsim} / n_{totalsim}</code> is the proportion of
informative persons in the sim. data. Let <code class="reqn">q_{\alpha}</code> be the <code class="reqn">1 - \alpha</code> quantile of the central <code class="reqn">\chi^2</code> distribution with <code class="reqn">df = 1</code>.
Then,
</p>
<p style="text-align: center;"><code class="reqn">power = 1 - F_{df, \lambda} (q_{\alpha}),</code>
</p>

<p>where <code class="reqn">F_{df, \lambda}</code> is the cumulative distribution function of the noncentral <code class="reqn">\chi^2</code> distribution with <code class="reqn">df = 1</code> and
<code class="reqn">\lambda = n_{total} * (n_{infsim} / n_{totalsim}) * e</code>. Thereby, it is assumed that <code class="reqn">n_{total}</code> is composed of a frequency distribution
of person scores that is proportional to the observed distribution of person scores in the simulated data.
</p>
<p>Note that in this approach the data have to be generated only once. There are no replications needed. Thus, the procedure is
computationally not very time-consuming.
</p>
<p>Since <code class="reqn">e</code> is determined from the value of the test statistic observed in the simulated data it has to be treated as a realized
value of a random variable <code class="reqn">E</code>. The same holds true for <code class="reqn">\lambda</code> as well as the power of the tests. Thus, the power is a realized
value of a random variable that shall be denoted by <code class="reqn">P</code>. Consequently, the (realized) value of the power of the tests need
not be equal to the exact power that follows from the user-specified <code class="reqn">n_{total}</code>, <code class="reqn">\alpha</code>, and the chosen item parameters and shift
parameter used for the simulation of the data. If the CML estimates of these parameters computed from the simulated data are
close to the predetermined parameters the power of the tests will be close to the exact value. This will generally be the
case if the number of person parameters used for simulating the data is large, e.g., <code class="reqn">10^5</code> or even <code class="reqn">10^6</code> persons. In such
cases, the possible random error of the computation procedure based on the sim. data may not be of practical relevance
any more. That is why a large number (of persons for the simulation process) is generally recommended.
</p>
<p>For theoretical reasons, the random error involved in computing the power of the tests can be pretty well approximated.
A suitable approach is the well-known delta method. Basically, it is a Taylor polynomial of first order, i.e., a linear
approximation of a function. According to it the variance of a function of a random variable can be linearly approximated
by multiplying the variance of this random variable with the square of the first derivative of the respective function.
In the present problem, the variance of the test statistic <code class="reqn">T</code> is (approximately) given by the variance of a noncentral
<code class="reqn">\chi^2</code> distribution. Thus, <code class="reqn">Var(T) = 2 (df + 2 \lambda)</code>,
with <code class="reqn">df = 1</code> and <code class="reqn">\lambda = t</code>.
Since the global deviation <code class="reqn">e = (1 / n_{infsim})* t</code> it follows for the variance of the corresponding random variable <code class="reqn">E</code>
that <code class="reqn">Var(E) = (1 / n_{infsim})^2 * Var(T)</code>. The power of the tests is a function of <code class="reqn">e</code> which is given by
<code class="reqn">F_{df, \lambda} (q_{\alpha})</code>, where <code class="reqn">\lambda = n_{total} * (n_{infsim} / n_{totalsim}) * e</code> and <code class="reqn">df = 1</code>.
Then, by the delta method one obtains (for the variance of <code class="reqn">P</code>)
</p>
<p style="text-align: center;"><code class="reqn">Var(P) = Var(E) * (F'_{df, \lambda} (q_{\alpha}))^2,</code>
</p>

<p>where <code class="reqn">F'_{df, \lambda}</code> is the derivative of <code class="reqn">F_{df, \lambda}</code> with respect to <code class="reqn">e</code>. This derivative is determined
numerically and evaluated at <code class="reqn">e</code> using the package numDeriv. The square root of <code class="reqn">Var(P)</code> is then used to quantify the random
error of the suggested Monte Carlo computation procedure. It is called Monte Carlo error of power.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>power</code></td>
<td>
<p>Power value for each test.</p>
</td></tr>
<tr><td><code>MC error of power</code></td>
<td>
<p>Monte Carlo error of power computation for each test.</p>
</td></tr>
<tr><td><code>deviation</code></td>
<td>
<p>Shift parameter estimated from the simulated data representing the constant shift of item parameters between time points 1 and 2.</p>
</td></tr>
<tr><td><code>person score distribution</code></td>
<td>
<p>Relative frequencies of person scores observed in simulated data. Uninformative scores,
i.e., minimum and maximum score, are omitted. Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which power is determined.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample size determination within the scope of conditional
maximum likelihood estimation with special focus on testing the Rasch model. Psychometrika, 80(4), 897-919.
</p>
<p>Fischer, G. H. (1995). The Linear Logistic Test Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch models: Foundations, Recent Developments, and Applications (pp. 131-155). New York: Springer.
</p>
<p>Fischer, G. H. (1983). Logistic Latent Trait Models with Linear Constraints. Psychometrika, 48(1), 3-26.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+sa_sizeChange">sa_sizeChange</a></code>, and <code><a href="#topic+post_hocChange">post_hocChange</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Numerical example: 4 items presented twice, thus 8 virtual items

# eta Parameter, first 4 are nuisance
# (easiness parameters of the 4 items at time point 1),
# last one is the shift parameter
eta &lt;- c(-2,-1,1,2,0.5)
res &lt;- powerChange(alpha = 0.05, n_total=150, eta=eta, persons=rnorm(10^6))

# &gt; res
# $power
#     W    LR    RS    GR
# 0.905 0.910 0.908 0.911
#
# $`MC error of power`
#     W    LR    RS    GR
# 0.002 0.002 0.002 0.002
#
# $`deviation (estimate of shift parameter)`
# [1] 0.499
#
# $`person score distribution`
#
#     1     2     3     4     5     6     7
# 0.034 0.093 0.181 0.249 0.228 0.147 0.068
#
# $`degrees of freedom`
# [1] 1
#
# $`noncentrality parameter`
#      W     LR     RS     GR
# 10.692 10.877 10.815 10.939
#
# $call
# powerChange(alpha = 0.05, n_total = 150, eta = eta, persons = rnorm(10^6))
#

## End(Not run)
</code></pre>

<hr>
<h2 id='powerPCM'>Power analysis of tests of invariance of item parameters between two groups
of persons in partial credit model</h2><span id='topic+powerPCM'></span>

<h3>Description</h3>

<p>Returns power of Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given probability of error of first kind
<code class="reqn">\alpha</code>, sample size, and a deviation from the hypothesis to be tested.
The hypothesis to be tested assumes equal item-category parameters of the
partial credit model between two predetermined groups of persons. The alternative
states that at least one of the parameters differs between the two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerPCM(
  alpha = 0.05,
  n_total,
  persons1 = rnorm(10^6),
  persons2 = rnorm(10^6),
  local_dev
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerPCM_+3A_alpha">alpha</code></td>
<td>
<p>Probability of error of first kind.</p>
</td></tr>
<tr><td><code id="powerPCM_+3A_n_total">n_total</code></td>
<td>
<p>Total sample size for which power shall be determined.</p>
</td></tr>
<tr><td><code id="powerPCM_+3A_persons1">persons1</code></td>
<td>
<p>A vector of person parameters in group 1 (drawn from a specified distribution).
By default <code class="reqn">10^6</code> parameters are drawn at random from the standard normal distribution. The larger
this number the more accurate are the computations. See Details.</p>
</td></tr>
<tr><td><code id="powerPCM_+3A_persons2">persons2</code></td>
<td>
<p>A vector of person parameters in group 2 (drawn from a specified distribution).
By default <code class="reqn">10^6</code> parameters are drawn at random from the standard normal distribution. The larger
this number the more accurate are the computations. See Details.</p>
</td></tr>
<tr><td><code id="powerPCM_+3A_local_dev">local_dev</code></td>
<td>
<p>A list consisting of two lists. One list refers to group 1, the other to group 2.
Each of the two lists contains a numeric vector per item, i.e., each list contains as many vectors as items.
Each vector contains the free item-cat. parameters of the respective item. The number of free item-cat.
parameters per item equals the number of categories of the item minus 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the power of the tests is determined from the assumption that the
approximate distributions of the four test statistics are from the family of
noncentral <code class="reqn">\chi^2</code> distributions with <code class="reqn">df</code> equal to the number of
free item-category parameters and noncentrality parameter <code class="reqn">\lambda</code>.
The latter depends on a scenario of deviation from the hypothesis to be tested
and a specified sample size. Given the probability of the error of the first
kind <code class="reqn">\alpha</code> the power of the tests can be determined from <code class="reqn">\lambda</code>.
More details about the distributions of the test statistics and the relationship
between <code class="reqn">\lambda</code>, power, and sample size can be found in Draxler and
Alexandrowicz (2015).
</p>
<p>As regards the concept of sample size a distinction between informative and total
sample size has to be made since the power of the tests depends only on the informative
sample size. In the conditional maximum likelihood context, the responses of persons
with minimum or maximum person score are completely uninformative. They do not contribute
to the value of the test statistic. Thus, the informative sample size does not include
these persons. The total sample size is composed of all persons.
</p>
<p>In particular, the determination of <code class="reqn">\lambda</code> and the power of the tests, respectively,
is based on a simple Monte Carlo approach. Data (responses of a large number of persons
to a number of items) are generated given a user-specified scenario of a deviation from
the hypothesis to be tested. A scenario of a deviation is given by a choice of the
item-cat. parameters and the person parameters (to be drawn randomly from a specified
distribution) for each of the two groups. Such a scenario may be called local deviation
since deviations can be specified locally for each item-category. The relative group
sizes are determined by the choice of the number of person parameters for each of the
two groups. For instance, by default <code class="reqn">10^6</code> person parameters are selected randomly for
each group. In this case, it is implicitly assumed that the two groups of persons are
of equal size. The user can specify the relative group sizes by choosing the length of
the arguments persons1 and persons2 appropriately. Note that the relative group sizes
do have an impact on power and sample size of the tests. The next step is to compute a
test statistic <code class="reqn">T</code> (Wald, LR, score, or gradient) from the simulated data. The observed
value <code class="reqn">t</code> of the test statistic is then divided by the informative sample size
<code class="reqn">n_{infsim}</code> observed in the simulated data. This yields the so-called global deviation
<code class="reqn">e = t / n_{infsim}</code>, i.e., the chosen scenario of a deviation from the hypothesis to
be tested being represented by a single number. The power of the tests can be determined
given a user-specified total sample size denoted by <code>n_total</code>. The noncentrality
parameter <code class="reqn">\lambda</code> can then be expressed by
<code class="reqn">\lambda = n_{total}* (n_{infsim} / n_{totalsim}) * e</code>, where <code class="reqn">n_{totalsim}</code> denotes
the total number of persons in the simulated data and <code class="reqn">n_{infsim} / n_{totalsim}</code> is
the proportion of informative persons in the sim. data. Let <code class="reqn">q_{\alpha}</code> be the
<code class="reqn">1 - \alpha</code> quantile of the central <code class="reqn">\chi^2</code> distribution with df equal to the
number of free item-category parameters. Then,
</p>
<p style="text-align: center;"><code class="reqn">power = 1 - F_{df, \lambda} (q_{\alpha}),</code>
</p>

<p>where <code class="reqn">F_{df, \lambda}</code> is the cumulative distribution function of the noncentral
<code class="reqn">\chi^2</code> distribution with <code class="reqn">df</code> equal to the number of free item-category parameters
and <code class="reqn">\lambda = n_{total}  (n_{infsim} / n_{totalsim}) * e</code>. Thereby, it is assumed that
<code class="reqn">n_{total}</code> is composed of a frequency distribution of person scores that is proportional
to the observed distribution of person scores in the simulated data. The same holds
true in respect of the relative group sizes, i.e., the relative frequencies of the two
person groups in a sample of size <code class="reqn">n_{total}</code> are assumed to be equal to the relative frequencies of the two
groups in the simulated data.
</p>
<p>Note that in this approach the data have to be generated only once. There are no
replications needed. Thus, the procedure is computationally not very time-consuming.
</p>
<p>Since <code class="reqn">e</code> is determined from the value of the test statistic observed in the simulated
data it has to be treated as a realized value of a random variable <code class="reqn">E</code>. The same holds
true for <code class="reqn">\lambda</code> as well as the power of the tests. Thus, the power is a realized
value of a random variable that shall be denoted by <code class="reqn">P</code>. Consequently, the (realized)
value of the power of the tests need not be equal to the exact power that follows from the
user-specified <code class="reqn">n_{total}</code>, <code class="reqn">\alpha</code>, and the chosen item-category parameters used
for the simulation of the data. If the CML estimates of these parameters computed from the
simulated data are close to the predetermined parameters the power of the tests will be
close to the exact value. This will generally be the case if the number of person parameters
used for simulating the data is large, e.g., <code class="reqn">10^5</code> or even <code class="reqn">10^6</code> persons. In such cases,
the possible random error of the computation procedure based on the sim. data may not be of
practical relevance any more. That is why a large number (of persons for the simulation process)
is generally recommended.
</p>
<p>For theoretical reasons, the random error involved in computing the power of the tests can
be pretty well approximated. A suitable approach is the well-known delta method. Basically,
it is a Taylor polynomial of first order, i.e., a linear approximation of a function.
According to it the variance of a function of a random variable can be linearly approximated
by multiplying the variance of this random variable with the square of the first derivative
of the respective function. In the present problem, the variance of the test statistic <code class="reqn">T</code>
is (approximately) given by the variance of a noncentral <code class="reqn">\chi^2</code> distribution with <code class="reqn">df</code>
equal to the number of free item-category parameters and noncentrality parameter <code class="reqn">\lambda</code>.
Thus,  <code class="reqn">Var(T) = 2 (df + 2 \lambda)</code>, with <code class="reqn">\lambda = t</code>. Since the global
deviation <code class="reqn">e = (1 / n_{infsim}) * t</code> it follows for the variance of the corresponding random variable <code class="reqn">E</code>
that <code class="reqn">Var(E) = (1 / n_{infsim})^2 * Var(T)</code>.
The power of the tests is a function of <code class="reqn">e</code> which is given by <code class="reqn">F_{df, \lambda} (q_{\alpha})</code>,
where <code class="reqn">\lambda = n_{total} * (n_{infsim} / n_{totalsim}) * e</code> and <code class="reqn">df</code> equal to the
number of free item-category parameters. Then, by the delta method one obtains (for the variance of P).
</p>
<p style="text-align: center;"><code class="reqn">Var(P) = Var(E) * (F'_{df, \lambda} (q_{\alpha}))^2,</code>
</p>

<p>where <code class="reqn">F'_{df, \lambda}</code> is the derivative of <code class="reqn">F_{df, \lambda}</code> with respect to <code class="reqn">e</code>.
This derivative is determined numerically and evaluated at <code class="reqn">e</code> using the package numDeriv. The square root of
<code class="reqn">Var(P)</code> is then used to quantify the random error of the suggested Monte Carlo computation
procedure. It is called Monte Carlo error of power.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>power</code></td>
<td>
<p>Power value for each test.</p>
</td></tr>
<tr><td><code>MC error of power</code></td>
<td>
<p>Monte Carlo error of power computation for each test.</p>
</td></tr>
<tr><td><code>global deviation</code></td>
<td>
<p>Global deviation computed from simulated data for each test. See Details.</p>
</td></tr>
<tr><td><code>local deviation</code></td>
<td>
<p>CML estimates of free item-category parameters in both groups of persons
obtained from the simulated data expressing a deviation from the hypothesis to be tested locally
per item and response category.</p>
</td></tr>
<tr><td><code>person score distribution in group 1</code></td>
<td>
<p>Relative frequencies of person scores in group 1 observed in
simulated data. Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>person score distribution in group 2</code></td>
<td>
<p>Relative frequencies of person scores in group 2 observed in
simulated data. Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which power is determined.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+sa_sizePCM">sa_sizePCM</a></code>, and <code><a href="#topic+post_hocPCM">post_hocPCM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example

# free item-category parameters for group 1 and 2  with 5 items, with 3 categories each
local_dev &lt;-  list (  list(c( 0, 0), c( -1, 0), c( 0, 0),  c( 1, 0), c( 1, 0.5)) ,
                      list(c( 0, 0), c( -1, 0), c( 0, 0),  c( 1, 0), c( 0, -0.5))  )

res &lt;-  powerPCM(alpha = 0.05, n_total = 200, persons1 = rnorm(10^6),
                  persons2 = rnorm(10^6), local_dev = local_dev)

# &gt; res
# $power
#     W    LR    RS    GR
# 0.863 0.885 0.876 0.892
#
# $`MC error of power`
#     W    LR    RS    GR
# 0.002 0.002 0.002 0.002
#
# $`global deviation`
#     W    LR    RS    GR
# 0.102 0.107 0.105 0.109
#
# $`local deviation`
#         I1-C2  I2-C1  I2-C2  I3-C1  I3-C2 I4-C1 I4-C2  I5-C1  I5-C2
# group1  0.002 -0.997 -0.993  0.006  0.012 1.002 1.007  1.006  1.508
# group2 -0.007 -1.005 -1.007 -0.006 -0.009 0.993 0.984 -0.006 -0.510
#
# $`person score distribution in group 1`
#
#     1     2     3     4     5     6     7     8     9
# 0.112 0.130 0.131 0.129 0.122 0.114 0.101 0.091 0.070
#
# $`person score distribution in group 2`
#
#     1     2     3     4     5     6     7     8     9
# 0.091 0.108 0.117 0.122 0.122 0.121 0.115 0.110 0.093
#
# $`degrees of freedom`
# [1] 9
#
# $`noncentrality parameter`
#      W     LR     RS     GR
# 18.003 19.024 18.596 19.403
#
# $call
# powerPCM(alpha = 0.05, n_total = 200, persons1 = rnorm(10^6),
#          persons2 = rnorm(10^6), local_dev = local_dev)

## End(Not run)
</code></pre>

<hr>
<h2 id='powerRM'>Power analysis of tests of invariance of item parameters between two groups
of persons in binary Rasch model</h2><span id='topic+powerRM'></span>

<h3>Description</h3>

<p>Returns power of Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given probability of error of first kind
<code class="reqn">\alpha</code>, sample size, and a deviation from the hypothesis to be tested.
The latter assumes equality of the item parameters in the Rasch model
between two predetermined groups of persons. The alternative states that at least
one of the parameters differs between the two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerRM(
  alpha = 0.05,
  n_total,
  persons1 = rnorm(10^6),
  persons2 = rnorm(10^6),
  local_dev
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerRM_+3A_alpha">alpha</code></td>
<td>
<p>Probability of error of first kind.</p>
</td></tr>
<tr><td><code id="powerRM_+3A_n_total">n_total</code></td>
<td>
<p>Total sample size for which power shall be determined.</p>
</td></tr>
<tr><td><code id="powerRM_+3A_persons1">persons1</code></td>
<td>
<p>A vector of person parameters in group 1 (drawn from a specified distribution).
By default <code class="reqn">10^6</code> parameters are drawn at random from the standard normal distribution. The larger
this number the more accurate are the computations. See Details.</p>
</td></tr>
<tr><td><code id="powerRM_+3A_persons2">persons2</code></td>
<td>
<p>A vector of person parameters in group 2 (drawn from a specified distribution).
By default <code class="reqn">10^6</code> parameters are drawn at random from the standard normal distribution. The larger
this number the more accurate are the computations. See Details.</p>
</td></tr>
<tr><td><code id="powerRM_+3A_local_dev">local_dev</code></td>
<td>
<p>A list of two vectors containing item parameters for the two person groups representing
a deviation from the hypothesis to be tested locally per item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the power of the tests is determined from the assumption that the
approximate distributions of the four test statistics are from the family of
noncentral <code class="reqn">\chi^2</code> distributions with <code class="reqn">df</code> equal to the number of items
minus 1 and noncentrality parameter <code class="reqn">\lambda</code>.
The latter depends on a scenario of deviation from the hypothesis to be tested
and a specified sample size. Given the probability of the error of the first
kind <code class="reqn">\alpha</code> the power of the tests can be determined from <code class="reqn">\lambda</code>.
More details about the distributions of the test statistics and the relationship
between <code class="reqn">\lambda</code>, power, and sample size can be found in Draxler and
Alexandrowicz (2015).
</p>
<p>As regards the concept of sample size a distinction between informative and total
sample size has to be made since the power of the tests depends only on the informative
sample size. In the conditional maximum likelihood context, the responses of persons
with minimum or maximum person score are completely uninformative. They do not contribute
to the value of the test statistic. Thus, the informative sample size does not include
these persons. The total sample size is composed of all persons.
</p>
<p>In particular, the determination of <code class="reqn">\lambda</code> and the power of the tests, respectively,
is based on a simple Monte Carlo approach. Data (responses of a large number of persons
to a number of items) are generated given a user-specified scenario of a deviation from
the hypothesis to be tested. A scenario of a deviation is given by a choice of the
item parameters and the person parameters (to be drawn randomly from a specified
distribution) for each of the two groups. Such a scenario may be called local deviation
since deviations can be specified locally for each item. The relative group
sizes are determined by the choice of the number of person parameters for each of the
two groups. For instance, by default <code class="reqn">10^6</code> person parameters are selected randomly for
each group. In this case, it is implicitly assumed that the two groups of persons are
of equal size. The user can specify the relative group sizes by choosing the length of
the arguments persons1 and persons2 appropriately. Note that the relative group sizes
do have an impact on power and sample size of the tests. The next step is to compute a
test statistic <code class="reqn">T</code> (Wald, LR, score, or gradient) from the simulated data. The observed
value <code class="reqn">t</code> of the test statistic is then divided by the informative sample size
<code class="reqn">n_{infsim}</code> observed in the simulated data. This yields the so-called global deviation
<code class="reqn">e = t / n_{infsim}</code>, i.e., the chosen scenario of a deviation from the hypothesis to
be tested being represented by a single number. The power of the tests can be determined
given a user-specified total sample size denoted by <code>n_total</code>. The noncentrality
parameter <code class="reqn">\lambda</code> can then be expressed by
<code class="reqn">\lambda = n_{total}* (n_{infsim} / n_{totalsim}) * e</code>, where <code class="reqn">n_{totalsim}</code> denotes
the total number of persons in the simulated data and <code class="reqn">n_{infsim} / n_{totalsim}</code> is
the proportion of informative persons in the sim. data. Let <code class="reqn">q_{\alpha}</code> be the
<code class="reqn">1 - \alpha</code> quantile of the central <code class="reqn">\chi^2</code> distribution with df equal to the
number items minus 1. Then,
</p>
<p style="text-align: center;"><code class="reqn">power = 1 - F_{df, \lambda} (q_{\alpha}),</code>
</p>

<p>where <code class="reqn">F_{df, \lambda}</code> is the cumulative distribution function of the noncentral
<code class="reqn">\chi^2</code> distribution with <code class="reqn">df</code> equal to the number of items minus 1
and <code class="reqn">\lambda = n_{total}  (n_{infsim} / n_{totalsim}) * e</code>. Thereby, it is assumed that
<code class="reqn">n_{total}</code> is composed of a frequency distribution of person scores that is proportional
to the observed distribution of person scores in the simulated data. The same holds
true in respect of the relative group sizes, i.e., the relative frequencies of the two
person groups in a sample of size <code class="reqn">n_{total}</code> are assumed to be equal to the relative
frequencies of the two groups in the simulated data.
</p>
<p>Note that in this approach the data have to be generated only once. There are no
replications needed. Thus, the procedure is computationally not very time-consuming.
</p>
<p>Since <code class="reqn">e</code> is determined from the value of the test statistic observed in the simulated
data it has to be treated as a realized value of a random variable <code class="reqn">E</code>. The same holds
true for <code class="reqn">\lambda</code> as well as the power of the tests. Thus, the power is a realized
value of a random variable that shall be denoted by <code class="reqn">P</code>. Consequently, the (realized)
value of the power of the tests need not be equal to the exact power that follows from the
user-specified <code class="reqn">n_{total}</code>, <code class="reqn">\alpha</code>, and the chosen item parameters used
for the simulation of the data. If the CML estimates of these parameters computed from the
simulated data are close to the predetermined parameters the power of the tests will be
close to the exact value. This will generally be the case if the number of person parameters
used for simulating the data is large, e.g., <code class="reqn">10^5</code> or even <code class="reqn">10^6</code> persons. In such cases,
the possible random error of the computation procedure based on the sim. data may not be of
practical relevance any more. That is why a large number (of persons for the simulation process)
is generally recommended.
</p>
<p>For theoretical reasons, the random error involved in computing the power of the tests can
be pretty well approximated. A suitable approach is the well-known delta method. Basically,
it is a Taylor polynomial of first order, i.e., a linear approximation of a function.
According to it the variance of a function of a random variable can be linearly approximated
by multiplying the variance of this random variable with the square of the first derivative
of the respective function. In the present problem, the variance of the test statistic <code class="reqn">T</code>
is (approximately) given by the variance of a noncentral <code class="reqn">\chi^2</code> distribution with <code class="reqn">df</code>
equal to the number of free item parameters and noncentrality parameter <code class="reqn">\lambda</code>.
Thus,  <code class="reqn">Var(T) = 2 (df + 2 \lambda)</code>, with <code class="reqn">\lambda = t</code>. Since the global
deviation <code class="reqn">e = (1 / n_{infsim}) * t</code> it follows for the variance of the corresponding random
variable <code class="reqn">E</code> that <code class="reqn">Var(E) = (1 / n_{infsim})^2 * Var(T)</code>.
The power of the tests is a function of <code class="reqn">e</code> which is given by <code class="reqn">F_{df, \lambda} (q_{\alpha})</code>,
where <code class="reqn">\lambda = n_{total} * (n_{infsim} / n_{totalsim}) * e</code> and <code class="reqn">df</code> equal to the
number of free item parameters. Then, by the delta method one obtains (for the variance of P).
</p>
<p style="text-align: center;"><code class="reqn">Var(P) = Var(E) * (F'_{df, \lambda} (q_{\alpha}))^2,</code>
</p>

<p>where <code class="reqn">F'_{df, \lambda}</code> is the derivative of <code class="reqn">F_{df, \lambda}</code> with respect to <code class="reqn">e</code>.
This derivative is determined numerically and evaluated at <code class="reqn">e</code> using the package numDeriv.
The square root of <code class="reqn">Var(P)</code> is then used to quantify the random error of the suggested
Monte Carlo computation procedure. It is called Monte Carlo error of power.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>power</code></td>
<td>
<p>Power value for each test.</p>
</td></tr>
<tr><td><code>MC error of power</code></td>
<td>
<p>Monte Carlo error of power computation for each test.</p>
</td></tr>
<tr><td><code>global deviation</code></td>
<td>
<p>Global deviation computed from simulated data for each test. See Details.</p>
</td></tr>
<tr><td><code>local deviation</code></td>
<td>
<p>CML estimates of item parameters in both groups of persons
obtained from the simulated data expressing a deviation from the hypothesis to be tested locally per item.</p>
</td></tr>
<tr><td><code>person score distribution in group 1</code></td>
<td>
<p>Relative frequencies of person scores in group 1 observed in
simulated data. Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>person score distribution in group 2</code></td>
<td>
<p>Relative frequencies of person scores in group 2 observed in
simulated data. Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the power of the tests.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which power is determined.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+sa_sizeRM">sa_sizeRM</a></code>, and <code><a href="#topic+post_hocRM">post_hocRM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example

res &lt;-  powerRM(n_total = 130, local_dev = list( c(0, -0.5, 0, 0.5, 1) , c(0, 0.5, 0, -0.5, 1)))

# &gt; res
# $power
#     W    LR    RS    GR
# 0.824 0.840 0.835 0.845
#
# $`MC error of power`
#     W    LR    RS    GR
# 0.002 0.002 0.002 0.002
#
# $`global deviation`
#     W    LR    RS    GR
# 0.118 0.122 0.121 0.124
#
# $`local deviation`
#         Item2 Item3  Item4 Item5
# group1 -0.499 0.005  0.500 1.001
# group2  0.501 0.003 -0.499 1.003
#
# $`person score distribution in group 1`
#
#     1     2     3     4
# 0.249 0.295 0.269 0.187
#
# $`person score distribution in group 2`
#
#     1     2     3     4
# 0.249 0.295 0.270 0.186
#
# $`degrees of freedom`
# [1] 4
#
# $`noncentrality parameter`
#      W     LR     RS     GR
# 12.619 13.098 12.937 13.264
#
# $call
# powerRM(n_total = 130, local_dev = list(c(0, -0.5, 0, 0.5, 1),
#                                         c(0, 0.5, 0, -0.5, 1)))


## End(Not run)
</code></pre>

<hr>
<h2 id='sa_sizeChange'>Sample size planning for tests in context of measurement of change using LLTM</h2><span id='topic+sa_sizeChange'></span>

<h3>Description</h3>

<p>Returns sample size for Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given probabilities of errors of first and second kinds <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>
as well as a deviation from the hypothesis to be tested. The hypothesis to be tested states that
the shift parameter quantifying the constant change for all items between time points 1 and 2
equals 0. The alternative states that the shift parameter is not equal to 0. It is assumed that the same
items are presented at both time points. See function <code><a href="#topic+change_test">change_test</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sa_sizeChange(alpha = 0.05, beta = 0.05, eta, persons = rnorm(10^6))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sa_sizeChange_+3A_alpha">alpha</code></td>
<td>
<p>Probability of error of first kind.</p>
</td></tr>
<tr><td><code id="sa_sizeChange_+3A_beta">beta</code></td>
<td>
<p>Probability of error of second kind.</p>
</td></tr>
<tr><td><code id="sa_sizeChange_+3A_eta">eta</code></td>
<td>
<p>A vector of eta parameters of the LLTM. The last element represents the constant change or shift for all items
between time points 1 and 2. The other elements of the vector are the item parameters at time point 1. A choice of the eta
parameters constitutes a scenario of deviation from the hypothesis of no change.</p>
</td></tr>
<tr><td><code id="sa_sizeChange_+3A_persons">persons</code></td>
<td>
<p>A vector of person parameters (drawn from a specified distribution). By default <code class="reqn">10^6</code> parameters
are drawn at random from the standard normal distribution. The larger this number the more accurate are the computations.
See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the sample size is determined from the assumption that the approximate distributions
of the four test statistics are from the family of noncentral <code class="reqn">\chi^2</code> distributions with <code class="reqn">df = 1</code>
and noncentrality parameter <code class="reqn">\lambda</code>. The latter is, inter alia, a function of the sample size. Hence,
the sample size can be determined from the condition <code class="reqn">\lambda = \lambda_0</code>, where <code class="reqn">\lambda_0</code> is
a predetermined constant which depends on the probabilities of the errors of the first and second kinds
<code class="reqn">\alpha</code> and  <code class="reqn">\beta</code> (or power). More details about the distributions of the test statistics
and the relationship between <code class="reqn">\lambda</code>, power, and sample size can be found in Draxler and Alexandrowicz (2015).
</p>
<p>In particular, the determination of <code class="reqn">\lambda</code> and the sample size, respectively, is based on a simple Monte
Carlo approach. As regards the concept of sample size a distinction between informative and total
sample size has to be made. In the conditional maximum likelihood context, the responses of
persons with minimum or maximum person score are completely uninformative. They do not contribute
to the value of the test statistic. Thus, the informative sample size does not include these persons.
The total sample size is composed of all persons. The Monte Carlo approach used in the present
problem to determine <code class="reqn">\lambda</code> and informative (and total) sample size can briefly be described as follows.
Data (responses of a large number of persons to a number of items presented at two time points) are
generated given a user-specified scenario of a deviation from the hypothesis to be tested. The
hypothesis to be tested assumes no change between time points 1 and 2. A scenario of a deviation
is given by a choice of the item parameters at time point 1 and the shift parameter, i.e., the
LLTM eta parameters, as well as the person parameters (to be drawn randomly from a specified distribution).
The shift parameter represents a constant change of all item parameters from time point 1 to time point 2.
A test statistic <code class="reqn">T</code> (Wald, LR, score, or gradient) is computed from the simulated data. The observed
value <code class="reqn">t</code> of the test statistic is then divided by the informative sample size <code class="reqn">n_{infsim}</code> observed
in the simulated data. This yields the so-called global deviation <code class="reqn">e = t / n_{infsim}</code>, i.e.,
the chosen scenario of a deviation from the hypothesis to be tested being represented by a
single number. Let the informative sample size sought be denoted by <code class="reqn">n_{inf}</code> (thus, this is not
the informative sample size observed in the sim. data). The noncentrality parameter <code class="reqn">\lambda</code> can
be expressed by the product <code class="reqn">n_{inf} * e</code>. Then, it follows from the condition <code class="reqn">\lambda = \lambda_0</code> that
</p>
<p style="text-align: center;"><code class="reqn">n_{inf} * e = \lambda_0</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">n_{inf} = \lambda_0 / e.</code>
</p>

<p>Note that the sample of size <code class="reqn">n_{inf}</code> is assumed to be composed only of persons with informative person scores, where
the relative frequency distribution of these informative scores is considered to be equal to the
observed relative frequency distribution of the informative scores in the simulated data. The total sample size
<code class="reqn">n_{total}</code> is then obtained from the relation <code class="reqn">n_{inf} = n_{total} * pr</code>, where <code class="reqn">pr</code> is the proportion
or relative frequency of persons observed in the simulated data with a minimum or maximum score. Basing
the tests given a level <code class="reqn">\alpha</code> on an informative sample of size <code class="reqn">n_{inf}</code> the probability of rejecting
the hypothesis to be tested will be at least <code class="reqn">1 - \beta</code> if the true global deviation <code class="reqn">\geq e</code>.
</p>
<p>Note that in this approach the data have to be generated only once. There are no replications
needed. Thus, the procedure is computationally not very time-consuming.
</p>
<p>Since e is determined from the value of the test statistic observed in the simulated data it has
to be treated as a realized value of a random variable <code class="reqn">E</code>. Consequently, <code class="reqn">n_{inf}</code> is also a
realization of a random variable <code class="reqn">N_{inf}</code>. Thus, the (realized) value <code class="reqn">n_{inf}</code> need not be
equal to the exact value of the informative sample size that follows from the user-specified
(predetermined) <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, and scenario of a deviation from the hypothesis to be
tested, i.e., the selected item parameters and shift parameter used for the simulation of the data.
If the CML estimates of these parameters computed from the simulated data are close to the
predetermined parameters <code class="reqn">n_{inf}</code> will be close to the exact value. This will generally be the
case if the number of person parameters used for simulating the data is large, e.g.,
<code class="reqn">10^5</code> or even <code class="reqn">10^6</code> persons. In such cases, the possible random error of the computation procedure
of <code class="reqn">n_{inf}</code> based on the sim. data may not be of practical relevance any more. That is why a
large number (of persons for the simulation process) is generally recommended.
</p>
<p>For theoretical reasons, the random error involved in computing <code class="reqn">n_{inf}</code> can be pretty well approximated.
A suitable approach is the well-known delta method. Basically, it is a Taylor polynomial of first order,
i.e., a linear approximation of a function. According to it the variance of a function of a random
variable can be linearly approximated by multiplying the variance of this random variable with the square
of the first derivative of the respective function. In the present problem, the variance of the test
statistic <code class="reqn">T</code> is (approximately) given by the variance of a noncentral <code class="reqn">\chi^2</code> distribution. Thus, <code class="reqn">Var(T) = 2 (df + 2 \lambda)</code>,
with <code class="reqn">df = 1</code> and <code class="reqn">\lambda = t</code>. Since the global deviation
<code class="reqn">e = (1 / n_{infsim}) * t</code> it follows for the variance of the corresponding random variable <code class="reqn">E</code> that
<code class="reqn">Var(E) = (1 / n_{infsim})^2 * Var(T)</code>. Since <code class="reqn">n_{inf} = f(e) = \lambda_0 / e</code> one obtains by the
delta method (for the variance of the corresponding random variable <code class="reqn">N_{inf}</code>)
</p>
<p style="text-align: center;"><code class="reqn">Var(N_{inf}) = Var(E) * (f'(e))^2,</code>
</p>

<p>where <code class="reqn">f'(e) = - \lambda_0 / e^2</code> is the derivative of <code class="reqn">f(e)</code>. The square root of <code class="reqn">Var(N_{inf})</code>
is then used to quantify the random error of the suggested Monte Carlo computation procedure. It is called
Monte Carlo error of informative sample size.
</p>


<h3>Value</h3>

<p>A list results.
</p>
<table>
<tr><td><code>informative sample size</code></td>
<td>
<p>Informative sample size for each test, omitting persons with min. and max score.</p>
</td></tr>
<tr><td><code>MC error of sample size</code></td>
<td>
<p>Monte Carlo error of sample size computation for each test.</p>
</td></tr>
<tr><td><code>deviation</code></td>
<td>
<p>Shift parameter estimated from the simulated data representing the constant shift of item
parameters between time points 1 and 2.</p>
</td></tr>
<tr><td><code>person score distribution</code></td>
<td>
<p>Relative frequencies of person scores observed in simulated data. Uninformative scores,
i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the sample size.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which sample size is determined.</p>
</td></tr>
<tr><td><code>total sample size</code></td>
<td>
<p>Total sample size for each test. See Details.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample size determination within the scope of conditional
maximum likelihood estimation with special focus on testing the Rasch model. Psychometrika, 80(4), 897-919.
</p>
<p>Fischer, G. H. (1995). The Linear Logistic Test Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch models: Foundations, Recent Developments, and Applications (pp. 131-155). New York: Springer.
</p>
<p>Fischer, G. H. (1983). Logistic Latent Trait Models with Linear Constraints. Psychometrika, 48(1), 3-26.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+powerChange">powerChange</a></code>, and <code><a href="#topic+post_hocChange">post_hocChange</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Numerical example 4 items presented twice, thus 8 virtual items

# eta Parameter, first 4 are nuisance
# (easiness parameters of the 4 items at time point 1),
# last one is the shift parameter
eta &lt;- c(-2,-1,1,2,0.5)

res &lt;- sa_sizeChange(alpha = 0.05, beta = 0.05, eta=eta, persons = rnorm(10^6))

# &gt; res
# $`informative sample size`
#   W  LR  RS  GR
# 177 174 175 173
#
# $`MC error of sample size`
#     W    LR    RS    GR
# 1.321 1.287 1.299 1.276
#
# $`deviation (estimate of shift parameter)`
# [1] 0.501
#
# $`person score distribution`
#
#     1     2     3     4     5     6     7
# 0.034 0.094 0.181 0.249 0.227 0.147 0.068
#
# $`degrees of freedom`
# [1] 1
#
# $`noncentrality parameter`
# [1] 12.995
#
# $`total sample size`
#   W  LR  RS  GR
# 182 179 180 178
#
# $call
# sa_sizeChange(alpha = 0.05, beta = 0.05, eta = eta, persons = rnorm(10^6))

## End(Not run)
</code></pre>

<hr>
<h2 id='sa_sizePCM'>Sample size planning for tests of invariance of item-category parameters between two groups of persons in partial credit model</h2><span id='topic+sa_sizePCM'></span>

<h3>Description</h3>

<p>Returns sample size for Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test  given probabilities of errors of first and second kinds <code class="reqn">\alpha</code> and
<code class="reqn">\beta</code> as well as a deviation from the hypothesis to be tested. The hypothesis to be tested
assumes equal item-category parameters in the partial credit model between two predetermined groups of persons.
The alternative assumes that at least one parameter differs between the two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sa_sizePCM(
  alpha = 0.05,
  beta = 0.05,
  persons1 = rnorm(10^6),
  persons2 = rnorm(10^6),
  local_dev
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sa_sizePCM_+3A_alpha">alpha</code></td>
<td>
<p>Probability of the error of first kind.</p>
</td></tr>
<tr><td><code id="sa_sizePCM_+3A_beta">beta</code></td>
<td>
<p>Probability of the error of second kind.</p>
</td></tr>
<tr><td><code id="sa_sizePCM_+3A_persons1">persons1</code></td>
<td>
<p>A vector of person parameters for group 1 (drawn from a specified distribution). By default <code class="reqn">10^6</code>
parameters are drawn at random from the standard normal distribution. The larger this number the more accurate are
the computations. See Details. .</p>
</td></tr>
<tr><td><code id="sa_sizePCM_+3A_persons2">persons2</code></td>
<td>
<p>A vector of person parameters for group 2 (drawn from a specified distribution). By default <code class="reqn">10^6</code>
parameters are drawn at random from the standard normal distribution. The larger this number the more accurate are
the computations. See Details.</p>
</td></tr>
<tr><td><code id="sa_sizePCM_+3A_local_dev">local_dev</code></td>
<td>
<p>A list consisting of two lists. One list refers to group 1, the other to group 2. Each of the two lists
contains a numerical vector per item, i.e., each list contains as many vectors as items. Each vector contains the free
item-cat. parameters of the respective item. The number of free item-cat. parameters per item equals the number of
categories of the item minus 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the sample size is determined from the assumption that the approximate distributions of
the four test statistics are from the family of noncentral <code class="reqn">\chi^2</code> distributions with <code class="reqn">df = l</code>,
where <code class="reqn">l</code> is the number of free item-category parameters in the partial credit model, and noncentrality
parameter <code class="reqn">\lambda</code>. The latter is, inter alia, a function of the sample size. Hence, the sample size can be
determined from the condition <code class="reqn">\lambda = \lambda_0</code>, where <code class="reqn">\lambda_0</code> is a predetermined constant
which depends on the probabilities of the errors of the first and second kinds <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>
(or power). More details about the distributions of the test statistics and the relationship between <code class="reqn">\lambda</code>,
power, and sample size can be found in Draxler and Alexandrowicz (2015).
</p>
<p>In particular, the determination of <code class="reqn">\lambda</code> and the sample size, respectively, is based on a simple Monte Carlo
approach. As regards the concept of sample size a distinction between informative and total sample size has
to be made. In the conditional maximum likelihood context, the responses of persons with minimum or maximum
person score are completely uninformative. They do not contribute to the value of the test statistic. Thus,
the informative sample size does not include these persons. The total sample size is composed of all persons.
The Monte Carlo approach used in the present problem to determine <code class="reqn">\lambda</code> and informative (and total) sample size
can briefly be described as follows. Data (responses of a large number of persons to a number of items) are
generated given a user-specified scenario of a deviation from the hypothesis to be tested. The hypothesis
to be tested assumes equal item-category parameters between the two groups of persons. A scenario of a
deviation is given by a choice of the item-cat. parameters and the person parameters (to be drawn randomly
from a specified distribution) for each of the two groups. Such a scenario may be called local deviation
since deviations can be specified locally for each item-category. The relative group sizes are determined
by the choice of the number of person parameters for each of the two groups. For instance, by default
<code class="reqn">10^6</code> person parameters are selected randomly for each group. In this case, it is implicitly assumed that
the two groups of persons are of equal size. The user can specify the relative groups sizes by choosing
the length of the arguments <code>persons1</code> and <code>persons2</code> appropriately. Note that the relative group sizes do
have an impact on power and sample size of the tests. The next step is to compute a test statistic <code class="reqn">T</code>
(Wald, LR, score, or gradient) from the simulated data. The observed value <code class="reqn">t</code> of the test statistic is
then divided by the informative sample size <code class="reqn">n_{infsim}</code> observed in the simulated data. This yields the
so-called global deviation <code class="reqn">e = t / n_{infsim}</code>, i.e., the chosen scenario of a deviation from the
hypothesis to be tested being represented by a single number. Let the informative sample size sought
be denoted by <code class="reqn">n_{inf}</code> (thus, this is not the informative sample size observed in the sim. data). The
noncentrality parameter <code class="reqn">\lambda</code> can be expressed by the product <code class="reqn">n_{inf} * e</code>. Then, it follows from the
condition <code class="reqn">\lambda = \lambda_0</code> that
</p>
<p style="text-align: center;"><code class="reqn">n_{inf} * e = \lambda_0</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">n_{inf} = \lambda_0 / e.</code>
</p>

<p>Note that the sample of size <code class="reqn">n_{inf}</code> is assumed to be composed only of persons with informative person scores in both groups,
where the relative frequency distribution of these informative scores in each of both groups is considered to be
equal to the observed relative frequency distribution of informative scores in each of both groups in the simulated
data. Note also that the relative sizes of the two person groups are
assumed to be equal to the relative sizes of the two groups in the simulated data. By default, the two
groups are equal-sized in the simulated data, i.e., one yields <code class="reqn">n_{inf} / 2</code> persons (with informative scores)
in each of the two groups. The total sample size <code class="reqn">n_{total}</code> is obtained from the relation <code class="reqn">n_{inf} = n_{total} * pr</code>,
where <code class="reqn">pr</code> is the proportion or relative frequency of persons observed in the simulated data with a minimum or
maximum score. Basing the tests given a level <code class="reqn">\alpha</code> on an informative sample of size <code class="reqn">n_{inf}</code> the
probability of rejecting the hypothesis to be tested will be at least <code class="reqn">1 - \beta</code> if the true global deviation
<code class="reqn">\ge e</code>.
</p>
<p>Note that in this approach the data have to be generated only once. There are no replications needed.
Thus, the procedure is computationally not very time-consuming.
</p>
<p>Since e is determined from the value of the test statistic observed in the simulated data it has to be
treated as a realization of a random variable <code class="reqn">E</code>. Consequently, <code class="reqn">n_{inf}</code> is also a realization of a random
variable <code class="reqn">N_{inf}</code>. Thus, the (realized) value <code class="reqn">n_{inf}</code> need not be equal to the exact value of the informative
sample size that follows from the user-specified (predetermined) <code class="reqn">\alpha</code>,<code class="reqn">\beta</code>, and scenario of a deviation
from the hypothesis to be tested, i.e., the selected item-category parameters used for the simulation of
the data. If the CML estimates of these parameters computed from the simulated data are close to the
predetermined parameters <code class="reqn">n_{inf}</code> will be close to the exact value. This will generally be the case if
the number of person parameters used for simulating the data, i.e., the lengths of the vectors persons1
and persons2, is large, e.g., <code class="reqn">10^5</code> or even <code class="reqn">10^6</code> persons. In such cases, the possible random error of the
computation procedure of <code class="reqn">n_{inf}</code> based on the sim. data may not be of practical relevance any more. That is
why a large number (of persons for the simulation process) is generally recommended.
</p>
<p>For theoretical reasons, the random error involved in computing n_inf can be pretty well approximated.
A suitable approach is the well-known delta method. Basically, it is a Taylor polynomial of first order,
i.e., a linear approximation of a function. According to it the variance of a function of a random variable
can be linearly approximated by multiplying the variance of this random variable with the square of the first
derivative of the respective function. In the present problem, the variance of the test statistic <code class="reqn">T</code> is
(approximately) given by the variance of a noncentral <code class="reqn">\chi^2</code> distribution. Thus,
<code class="reqn">Var(T) = 2 (df + 2  \lambda)</code>, with <code class="reqn">df = l</code> and
<code class="reqn">\lambda = t</code>. Since the global deviation <code class="reqn">e = (1 / n_{infsim}) * t</code> it follows for the variance of the
corresponding random variable <code class="reqn">E</code> that <code class="reqn">Var(E) = (1 / n_{infsim})^2 * Var(T)</code>. Since
<code class="reqn">n_{inf} = f(e) = \lambda_0 / e</code> one obtains by the delta method (for the variance of the corresponding
random variable <code class="reqn">N_{inf}</code>)
</p>
<p style="text-align: center;"><code class="reqn">Var(N_{inf}) = Var(E) * (f'(e))^2,</code>
</p>

<p>where <code class="reqn">f'(e) = - \lambda_0 / e^2</code> is the derivative of <code class="reqn">f(e)</code>. The square root of <code class="reqn">Var(N_{inf})</code> is then used to
quantify the random error of the suggested Monte Carlo computation procedure. It is called Monte Carlo
error of informative sample size.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>informative sample size</code></td>
<td>
<p>Informative sample size for each test, omitting persons with min. and max score.</p>
</td></tr>
<tr><td><code>MC error of sample size</code></td>
<td>
<p>Monte Carlo error of informative sample size for each test.</p>
</td></tr>
<tr><td><code>global deviation</code></td>
<td>
<p>Global deviation computed from simulated data. See Details.</p>
</td></tr>
<tr><td><code>local deviation</code></td>
<td>
<p>CML estimates of free item-category parameters in both group of persons obtained from the simulated
data expressing a deviation from the hypothesis to be tested locally per item and response category.</p>
</td></tr>
<tr><td><code>person score distribution in group 1</code></td>
<td>
<p>Relative frequencies of person scores in group 1 observed in simulated data.
Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the sample size.</p>
</td></tr>
<tr><td><code>person score distribution in group 2</code></td>
<td>
<p>Relative frequencies of person scores in group 2 observed in simulated data.
Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the sample size.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which sample size is determined.</p>
</td></tr>
<tr><td><code>total sample size in group 1</code></td>
<td>
<p>Total sample size in group 1 for each test. See Details.</p>
</td></tr>
<tr><td><code>total sample size in group 1</code></td>
<td>
<p>Total sample size in group 2 for each test. See Details.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+powerPCM">powerPCM</a></code>, and <code><a href="#topic+post_hocPCM">post_hocPCM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##### Sample size of PCM Model #####

# free item-category parameters for group 1 and 2  with 5 items, with 3 categories each
local_dev &lt;-  list (  list(c( 0, 0), c( -1, 0), c( 0, 0),  c( 1, 0), c( 1, 0.5)) ,
                      list(c( 0, 0), c( -1, 0), c( 0, 0),  c( 1, 0), c( 0, -0.5))  )

res &lt;- sa_sizePCM(alpha = 0.05, beta = 0.05, persons1 = rnorm(10^6),
                  persons2 = rnorm(10^6), local_dev = local_dev)

# &gt; res
# $`informative sample size`
#   W  LR  RS  GR
# 234 222 227 217
#
# $`MC error of sample size`
#     W    LR    RS    GR
# 1.105 1.018 1.053 0.988
#
# $`global deviation`
#     W    LR    RS    GR
# 0.101 0.107 0.104 0.109
#
# $`local deviation`
#          I1-C2  I2-C1  I2-C2  I3-C1  I3-C2 I4-C1 I4-C2 I5-C1  I5-C2
# group1 -0.001 -1.000 -1.001 -0.003 -0.011 0.997 0.998 0.996  1.492
# group2  0.001 -0.998 -0.996 -0.007 -0.007 0.991 1.001 0.004 -0.499
#
# $`person score distribution in group 1`
#
#     1     2     3     4     5     6     7     8     9
# 0.111 0.130 0.133 0.129 0.122 0.114 0.101 0.091 0.070
#
# $`person score distribution in group 2`
#
#     1     2     3     4     5     6     7     8     9
# 0.090 0.109 0.117 0.121 0.121 0.121 0.116 0.111 0.093
#
# $`degrees of freedom`
# [1] 9
#
# $`noncentrality parameter`
# [1] 23.589
#
# $`total sample size in group 1`
#   W  LR  RS  GR
# 132 125 128 123
#
# $`total sample size in group 2`
#   W  LR  RS  GR
# 133 126 129 123
#
# $call
# sa_sizePCM(alpha = 0.05, beta = 0.05, persons1 = rnorm(10^6),
#            persons2 = rnorm(10^6), local_dev = local_dev)

## End(Not run)
</code></pre>

<hr>
<h2 id='sa_sizeRM'>Sample size planning for tests of invariance of item parameters between two groups of persons in binary Rasch model</h2><span id='topic+sa_sizeRM'></span>

<h3>Description</h3>

<p>Returns sample size for Wald (W), likelihood ratio (LR), Rao score (RS)
and gradient (GR) test given probabilities of errors of first and second kinds <code class="reqn">\alpha</code> and
<code class="reqn">\beta</code> as well as a deviation from the hypothesis to be tested. The hypothesis to be
tested assumes equal item parameters between two predetermined groups of persons. The alternative assumes
that at least one parameter differs between the two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sa_sizeRM(
  alpha = 0.05,
  beta = 0.05,
  persons1 = rnorm(10^6),
  persons2 = rnorm(10^6),
  local_dev
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sa_sizeRM_+3A_alpha">alpha</code></td>
<td>
<p>Probability of the error of first kind.</p>
</td></tr>
<tr><td><code id="sa_sizeRM_+3A_beta">beta</code></td>
<td>
<p>Probability of the error of second kind.</p>
</td></tr>
<tr><td><code id="sa_sizeRM_+3A_persons1">persons1</code></td>
<td>
<p>A vector of person parameters for group 1 (drawn from a specified distribution). By default
<code class="reqn">10^6</code> parameters are drawn at random from the standard normal distribution. The larger this
number the more accurate are the computations. See Details.</p>
</td></tr>
<tr><td><code id="sa_sizeRM_+3A_persons2">persons2</code></td>
<td>
<p>A vector of person parameters for group 2 (drawn from a specified distribution). By default
<code class="reqn">10^6</code> parameters are drawn at random from the standard normal distribution. The larger this
number the more accurate are the computations. See Details.</p>
</td></tr>
<tr><td><code id="sa_sizeRM_+3A_local_dev">local_dev</code></td>
<td>
<p>A list consisting of two vectors containing item parameters for the two person groups
representing a deviation from the hypothesis to be tested locally per item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the sample size is determined from the assumption that the approximate distributions of
the four test statistics are from the family of noncentral <code class="reqn">\chi^2</code> distributions with <code class="reqn">df</code>
equal to the number of items minus 1, and noncentrality parameter <code class="reqn">\lambda</code>. The latter is,
inter alia, a function of the sample size. Hence, the sample size can be determined from the condition
<code class="reqn">\lambda = \lambda_0</code>, where <code class="reqn">\lambda_0</code> is a predetermined constant  which depends on the probabilities of
the errors of the first and second kinds <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>
(or power). More details about the distributions of the test statistics and the relationship between <code class="reqn">\lambda</code>,
power, and sample size can be found in Draxler and Alexandrowicz (2015).
</p>
<p>In particular, the determination of <code class="reqn">\lambda</code> and the sample size, respectively, is based on a simple
Monte Carlo approach. As regards the concept of sample size a distinction between informative and total
sample size has to be made. In the conditional maximum likelihood context, the responses of persons
with minimum or maximum person score are completely uninformative. They do not contribute to the value o
f the test statistic. Thus, the informative sample size does not include these persons. The total sample
size is composed of all persons. The Monte Carlo approach used in the present problem to determine <code class="reqn">\lambda</code>
and informative (and total) sample size can briefly be described as follows. Data (responses of a large number
of persons to a number of items) are generated given a user-specified scenario of a deviation from the hypothesis
to be tested. The hypothesis to be tested assumes equal item parameters between the two groups of persons.
A scenario of a deviation is given by a choice of the item parameters and the person parameters (to be drawn
randomly from a specified distribution) for each of the two groups. Such a scenario may be called local
deviation since deviations can be specified locally for each item. The relative group sizes are determined by
the choice of the number of person parameters for each of the two groups. For instance, by default <code class="reqn">10^6</code> person
parameters are selected randomly for each group. In this case, it is implicitly assumed that the two groups of
persons are of equal size. The user can specify the relative groups sizes by choosing the lengths of the
arguments <code>persons1</code> and <code>persons2</code> appropriately. Note that the relative group sizes do have an impact on power
and sample size of the tests. The next step is to compute a test statistic <code class="reqn">T</code> (Wald, LR, score, or gradient)
from the simulated data. The observed value <code class="reqn">t</code> of the test statistic is then divided by the informative
sample size <code class="reqn">n_{infsim}</code> observed in the simulated data. This yields the so-called global deviation
<code class="reqn">e = t / n_{infsim}</code>, i.e., the chosen scenario of a deviation from the hypothesis to be tested being
represented by a single number. Let the informative sample size sought be denoted by <code class="reqn">n_{inf}</code> (thus, this is
not the informative sample size observed in the sim. data). The noncentrality parameter <code class="reqn">\lambda</code> can
be expressed by the product <code class="reqn">n_{inf} * e</code>. Then, it follows from the condition <code class="reqn">\lambda = \lambda_0</code> that
</p>
<p style="text-align: center;"><code class="reqn">n_{inf} * e = \lambda_0</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">n_{inf} = \lambda_0 / e.</code>
</p>

<p>Note that the sample of size <code class="reqn">n_{inf}</code> is assumed to be composed only of persons with informative person scores in both groups,
where the relative frequency distribution of these informative scores in each of both groups is considered to be equal
to the observed relative frequency distribution of informative scores in each of both groups in the simulated data. Note also that the
relative sizes of the two person groups are assumed to be equal to the
relative sizes of the two groups in the simulated data. By default, the two groups are equal-sized in the simulated
data, i.e., one yields <code class="reqn">n_{inf} / 2</code> persons (with informative scores) in each of the two groups. The total
sample size <code class="reqn">n_{total}</code> is obtained from the relation
<code class="reqn">n_{inf} = n_{total} * pr</code>, where <code class="reqn">pr</code> is the proportion or relative frequency of persons observed
in the simulated data with a minimum or maximum score. Basing the tests given a level <code class="reqn">\alpha</code> on an informative
sample of size <code class="reqn">n_{inf}</code> the probability of rejecting the hypothesis to be tested will be at least
<code class="reqn">1 - \beta</code> if the true global deviation <code class="reqn">\ge e</code>.
</p>
<p>Note that in this approach the data have to be generated only once. There are no replications needed. Thus, the
procedure is computationally not very time-consuming.
</p>
<p>Since <code class="reqn">e</code> is determined from the value of the test statistic observed in the simulated data it has to be
treated as a realization of a random variable <code class="reqn">E</code>. Consequently, <code class="reqn">n_{inf}</code> is also a realization of a
random variable <code class="reqn">N_{inf}</code>. Thus, the (realized) value <code class="reqn">n_{inf}</code> need not be equal to the exact value of
the informative sample size that follows from the user-specified (predetermined) <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, and
scenario of a deviation from the hypothesis to be tested, i.e., the selected item parameters used for the
simulation of the data. If the CML estimates of these parameters computed from the simulated data are close
to the predetermined parameters <code class="reqn">n_{inf}</code> will be close to the exact value. This will generally be the case
if the number of person parameters used for simulating the data, i.e., the lengths of the vectors <code>persons1</code>
and <code>persons2</code>, is large, e.g., <code class="reqn">10^5</code> or even <code class="reqn">10^6</code> persons. In such cases, the possible random
error of the computation procedure of <code class="reqn">n_{inf}</code> based on the sim. data may not be of practical relevance any
more. That is why a large number (of persons for the simulation process) is generally recommended.
</p>
<p>For theoretical reasons, the random error involved in computing <code class="reqn">n_{inf}</code> can be pretty well approximated.
A suitable approach is the well-known delta method. Basically, it is a Taylor polynomial of first order, i.e.,
a linear approximation of a function. According to it the variance of a function of a random variable can be
linearly approximated by multiplying the variance of this random variable with the square of the first
derivative of the respective function. In the present problem, the variance of the test statistic <code class="reqn">T</code> is
(approximately) given by the variance of a noncentral <code class="reqn">\chi^2</code> distribution.
Thus, <code class="reqn">Var(T) = 2 (df + 2 \lambda)</code>, with <code class="reqn">df</code> equal to the number of items minus 1 and
<code class="reqn">\lambda = t</code>. Since the global deviation <code class="reqn">e = (1 / n_{infsim}) * t</code> it
follows for the variance of the corresponding random variable <code class="reqn">E</code> that <code class="reqn">Var(E) = (1 / n_{infsim})^2 * Var(T)</code>.
Since <code class="reqn">n_{inf} = f(e) = \lambda_0 / e</code> one obtains by the delta method (for the variance of the
corresponding random variable <code class="reqn">N_{inf}</code>)
</p>
<p style="text-align: center;"><code class="reqn">Var(N_{inf}) = Var(E) * (f'(e))^2,</code>
</p>

<p>where <code class="reqn">f'(e) = - \lambda_0 / e^2</code> is the derivative of <code class="reqn">f(e)</code>. The square root of
<code class="reqn">Var(N_{inf})</code> is then used to quantify the random error of the suggested Monte Carlo
computation procedure. It is called Monte Carlo error of informative sample size.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>informative sample size</code></td>
<td>
<p>Informative sample size for each test omitting persons with min. and max score.</p>
</td></tr>
<tr><td><code>MC error of sample size</code></td>
<td>
<p>Monte Carlo error of informative sample size for each test.</p>
</td></tr>
<tr><td><code>global deviation</code></td>
<td>
<p>Global deviation computed from simulated data. See Details.</p>
</td></tr>
<tr><td><code>local deviation</code></td>
<td>
<p>CML estimates of free item parameters in both groups obtained from the simulated data.
First item parameter set 0 in both groups.</p>
</td></tr>
<tr><td><code>person score distribution in group 1</code></td>
<td>
<p>Relative frequencies of person scores in group 1 observed in simulated data.
Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the sample size.</p>
</td></tr>
<tr><td><code>person score distribution in group 2</code></td>
<td>
<p>Relative frequencies of person scores in group 2 observed in simulated data.
Uninformative scores, i.e., minimum and maximum score, are omitted.
Note that the person score distribution does also have an influence on the sample size.</p>
</td></tr>
<tr><td><code>degrees of freedom</code></td>
<td>
<p>Degrees of freedom <code class="reqn">df</code>.</p>
</td></tr>
<tr><td><code>noncentrality parameter</code></td>
<td>
<p>Noncentrality parameter <code class="reqn">\lambda</code> of <code class="reqn">\chi^2</code> distribution from which sample size is determined.</p>
</td></tr>
<tr><td><code>total sample size in group 1</code></td>
<td>
<p>Total sample size in group 1 for each test. See Details.</p>
</td></tr>
<tr><td><code>total sample size in group 1</code></td>
<td>
<p>Total sample size in group 2 for each test. See Details.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<p>Draxler, C. (2010). Sample Size Determination for Rasch Model Tests. Psychometrika, 75(4), 708â724.
</p>
<p>Draxler, C., &amp; Alexandrowicz, R. W. (2015). Sample Size Determination Within the Scope of Conditional Maximum Likelihood Estimation
with Special Focus on Testing the Rasch Model. Psychometrika, 80(4), 897â919.
</p>
<p>Draxler, C., Kurz, A., &amp; Lemonte, A. J. (2020). The Gradient Test and its Finite Sample Size Properties in a Conditional Maximum Likelihood
and Psychometric Modeling Context. Communications in Statistics-Simulation and Computation, 1-19.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995a). Testing the Rasch Model. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 69â95). New York: Springer.
</p>
<p>Glas, C. A. W., &amp; Verhelst, N. D. (1995b). Tests of Fit for Polytomous Rasch Models. In G. H. Fischer &amp; I. W. Molenaar (Eds.),
Rasch Models: Foundations, Recent Developments, and Applications (pp. 325-352). New York: Springer.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+powerRM">powerRM</a></code>, and <code><a href="#topic+post_hocRM">post_hocRM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##### Sample size of Rasch Model #####

res &lt;-  sa_sizeRM(local_dev = list( c(0, -0.5, 0, 0.5, 1) , c(0, 0.5, 0, -0.5, 1)))

# &gt; res
# $`informative sample size`
#   W  LR  RS  GR
# 159 153 155 151
#
# $`MC error of sample size`
#     W    LR    RS    GR
# 0.721 0.682 0.695 0.670
#
# $`global deviation`
#     W    LR    RS    GR
# 0.117 0.122 0.120 0.123
#
# $`local deviation`
#         Item2  Item3  Item4 Item5
# group1 -0.502 -0.005  0.497 1.001
# group2  0.495 -0.006 -0.501 0.994
#
# $`person score distribution in group 1`
#
#     1     2     3     4
# 0.249 0.295 0.268 0.188
#
# $`person score distribution in group 2`
#
#     1     2     3     4
# 0.249 0.295 0.270 0.187
#
# $`degrees of freedom`
# [1] 4
#
# $`noncentrality parameter`
# [1] 18.572
#
# $`total sample size in group 1`
#  W LR RS GR
# 97 93 94 92
#
# $`total sample size in group 2`
#  W LR RS GR
# 97 93 94 92
#
# $call
# sa_sizeRM(local_dev = list(c(0, -0.5, 0, 0.5, 1),
#                            c(0, 0.5, 0, -0.5, 1)))

## End(Not run)
</code></pre>

<hr>
<h2 id='tcl_hessian'>Computation of Hessian matrix.</h2><span id='topic+tcl_hessian'></span>

<h3>Description</h3>

<p>Uses function <code>hessian()</code> from numDeriv package to compute (approximate numerically) Hessian matrix
evaluated at arbitrary values of item easiness parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tcl_hessian(X, eta, W, model = "RM")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tcl_hessian_+3A_x">X</code></td>
<td>
<p>data matrix.</p>
</td></tr>
<tr><td><code id="tcl_hessian_+3A_eta">eta</code></td>
<td>
<p>numeric vector of item easiness parameters.</p>
</td></tr>
<tr><td><code id="tcl_hessian_+3A_w">W</code></td>
<td>
<p>design matrix.</p>
</td></tr>
<tr><td><code id="tcl_hessian_+3A_model">model</code></td>
<td>
<p>RM, PCM, RSM, LLTM.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Hessian matrix evaluated at eta
</p>


<h3>References</h3>


<p>Gilbert, P., Gilbert, M. P., &amp; Varadhan, R. (2016). numDeriv: Accurate Numerical Derivatives. R package
version 2016.8-1.1. url: https://CRAN.R-project.org/package=numDeriv

</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Rasch model with beta_1 restricted to 0
y &lt;- eRm::raschdat1
res &lt;- eRm::RM(X = y, sum0 = FALSE)
mat &lt;- tcl_hessian(X = y, eta = res$etapar, model = "RM")


## End(Not run)
</code></pre>

<hr>
<h2 id='tcl_scorefun'>Computation of score function.</h2><span id='topic+tcl_scorefun'></span>

<h3>Description</h3>

<p>Uses function <code>jacobian()</code> from numDeriv package to compute (approximate numerically) score function
(first order partial derivatives of conditional log likelihood function)
evaluated at arbitrary values of item easiness parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tcl_scorefun(X, eta, W, model = "RM")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tcl_scorefun_+3A_x">X</code></td>
<td>
<p>data matrix.</p>
</td></tr>
<tr><td><code id="tcl_scorefun_+3A_eta">eta</code></td>
<td>
<p>numeric vector of item easiness parameters.</p>
</td></tr>
<tr><td><code id="tcl_scorefun_+3A_w">W</code></td>
<td>
<p>design matrix.</p>
</td></tr>
<tr><td><code id="tcl_scorefun_+3A_model">model</code></td>
<td>
<p>RM, PCM, RSM, LLTM.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Score function evaluated at eta
</p>


<h3>References</h3>


<p>Gilbert, P., Gilbert, M. P., &amp; Varadhan, R. (2016). numDeriv: Accurate Numerical Derivatives. R package
version 2016.8-1.1. url: https://CRAN.R-project.org/package=numDeriv

</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Rasch model with beta_1 restricted to 0
y &lt;- eRm::raschdat1
res &lt;- eRm::RM(X = y, sum0 = FALSE)
scorefun &lt;- tcl_scorefun(X = y, eta = res$etapar, model = "RM")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
