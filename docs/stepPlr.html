<!DOCTYPE html><html><head><title>Help for package stepPlr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {stepPlr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.step.plr'>
<p>Computes cross-validated deviance or prediction errors for step.plr</p></a></li>
<li><a href='#plr'>
<p>Logistic regression with a quadratic penalization on the coefficients</p></a></li>
<li><a href='#plr-internal'>
<p>Internal plr functions</p></a></li>
<li><a href='#predict.plr'>
<p>prediction function for plr</p></a></li>
<li><a href='#predict.stepplr'>
<p>prediction function for step.plr</p></a></li>
<li><a href='#step.plr'>
<p>Forward stepwise selection procedure for penalized logistic</p>
regression</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.93</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-01-27</td>
</tr>
<tr>
<td>Title:</td>
<td>L2 Penalized Logistic Regression with Stepwise Variable
Selection</td>
</tr>
<tr>
<td>Author:</td>
<td>Mee Young Park, Trevor Hastie</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mee Young Park &lt;meeyoung@google.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>L2 penalized logistic regression for both continuous and discrete predictors, with forward stagewise/forward stepwise variable selection procedure.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-01-28 16:04:11 UTC</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-01-28 04:57:40 UTC; meeyoung</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
</table>
<hr>
<h2 id='cv.step.plr'>
Computes cross-validated deviance or prediction errors for step.plr
</h2><span id='topic+cv.step.plr'></span>

<h3>Description</h3>

  
<p>This function computes cross-validated deviance or prediction errors
for <code>step.plr.</code> The parameters that can be cross-validated are
<code>lambda</code> and <code>cp</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  cv.step.plr(x, y, weights = rep(1, length(y)),
              nfold = 5, folds = NULL, lambda = c(1e-4, 1e-2, 1),
              cp = c("aic", "bic"), cv.type=c("deviance", "class"),
              trace = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.step.plr_+3A_x">x</code></td>
<td>

<p>matrix of features
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_y">y</code></td>
<td>

<p>binary response
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_weights">weights</code></td>
<td>

<p>optional vector of weights for observations
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_nfold">nfold</code></td>
<td>

<p>number of folds to be used in cross-validation. Default is
<code>nfold=5.</code>
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_folds">folds</code></td>
<td>

<p>list of cross-validation folds. Its length must be <code>nfold</code>. If
<code>NULL,</code> the folds are randomly generated.
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_lambda">lambda</code></td>
<td>

<p>vector of the candidate values for <code>lambda</code> in <code>step.plr</code> 
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_cp">cp</code></td>
<td>

<p>vector of the candidate values for <code>cp</code> in <code>step.plr</code> 
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_cv.type">cv.type</code></td>
<td>

<p>If <code>cv.type=deviance,</code> cross-validated deviances are returned. If
<code>cv.type=class,</code> cross-validated prediction errors are returned.
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_trace">trace</code></td>
<td>

<p>If <code>TRUE,</code> the steps are printed out.
</p>
</td></tr>
<tr><td><code id="cv.step.plr_+3A_...">...</code></td>
<td>

<p>other options for <code>step.plr</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes cross-validated deviance or prediction errors
for <code>step.plr.</code> The parameters that can be cross-validated are
<code>lambda</code> and <code>cp</code>. If both are input as vectors (of length
greater than 1), then a two-dimensional cross-validation is done. If
either one is input as a single value, then the cross-validation is
done only on the parameter with multiple inputs.
</p>


<h3>Author(s)</h3>

<p>Mee Young Park and Trevor Hastie</p>


<h3>References</h3>

<p>Mee Young Park and Trevor Hastie (2008) Penalized Logistic Regression
for Detecting Gene Interactions
</p>


<h3>See Also</h3>

<p>step.plr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
x &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
y &lt;- sample(c(0, 1), n, replace=TRUE)
level &lt;- vector("list", length=p)
for (i in 1:p) level[[i]] &lt;- seq(3)
cvfit &lt;- cv.step.plr(x, y, level=level, lambda=c(1e-4, 1e-2, 1), cp="bic")
</code></pre>

<hr>
<h2 id='plr'>
Logistic regression with a quadratic penalization on the coefficients
</h2><span id='topic+plr'></span>

<h3>Description</h3>

<p>This function fits a logistic regression model penalizing the size of
the L2 norm of the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plr(x, y, weights = rep(1,length(y)),
      offset.subset = NULL, offset.coefficients = NULL,
      lambda = 1e-4, cp = "bic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plr_+3A_x">x</code></td>
<td>

<p>matrix of features
</p>
</td></tr>
<tr><td><code id="plr_+3A_y">y</code></td>
<td>

<p>binary response 
</p>
</td></tr>
<tr><td><code id="plr_+3A_weights">weights</code></td>
<td>

<p>optional vector of weights for observations
</p>
</td></tr>
<tr><td><code id="plr_+3A_offset.subset">offset.subset</code></td>
<td>

<p>optional vector of indices for the predictors for which the
coefficients are preset to <code>offset.coefficients</code>. If
<code>offset.coefficients</code> is not <code>NULL</code>, <code>offset.subset</code>
must be provided.
</p>
</td></tr>
<tr><td><code id="plr_+3A_offset.coefficients">offset.coefficients</code></td>
<td>

<p>optional vector of preset coefficient values for the predictors in
<code>offset.subset</code>. If <code>offset.coefficient</code> is not
<code>NULL</code>, <code>offset.coefficients</code> must be provided.
</p>
</td></tr>
<tr><td><code id="plr_+3A_lambda">lambda</code></td>
<td>

<p>regularization parameter for the L2 norm of the coefficients. The
minimizing criterion in <code>plr</code> is
-log-likelihood+<code class="reqn">\lambda*\|\beta\|^2</code>. Default is
<code>lambda=1e-4.</code>
</p>
</td></tr>
<tr><td><code id="plr_+3A_cp">cp</code></td>
<td>

<p>complexity parameter to be used when computing the
score. <code>score=deviance+cp*df.</code> If <code>cp="aic"</code> or
<code>cp="bic",</code> these are converted to <code>cp=2</code> or
<code>cp=log(sample size),</code> respectively. Default is
<code>cp="bic".</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We proposed using logistic regression with a quadratic penalization on
the coefficients for detecting gene interactions as described in
&quot;Penalized Logistic Regression for Detecting Gene Interactions (2008)&quot;
by Park and Hastie. However, this function <code>plr</code> may be used for
a general purpose. 
</p>


<h3>Value</h3>

<p>A <code>plr</code> object is returned. <code>predict, print,</code> and
<code>summary</code> functions can be applied.  
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>

<p>vector of the coefficient estimates
</p>
</td></tr>
<tr><td><code>covariance</code></td>
<td>

<p>sandwich estimate of the covariance matrix for the coefficients
</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>

<p>deviance of the fitted model
</p>
</td></tr>
<tr><td><code>null.deviance</code></td>
<td>

<p>deviance of the null model
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>degrees of freedom of the fitted model
</p>
</td></tr>
<tr><td><code>score</code></td>
<td>

<p>deviance + cp*df
</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>

<p>number of observations
</p>
</td></tr>
<tr><td><code>cp</code></td>
<td>

<p>complexity parameter used when computing the score
</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>

<p>fitted probabilities
</p>
</td></tr>
<tr><td><code>linear.predictors</code></td>
<td>

<p>linear predictors computed with the estimated coefficients
</p>
</td></tr>
<tr><td><code>level</code></td>
<td>

<p>If any categorical factors are input, level - the list of level sets
- is automatically generated and returned. See <code>step.plr</code> for
details of how it is generated.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mee Young Park and Trevor Hastie</p>


<h3>References</h3>

<p>Mee Young Park and Trevor Hastie (2008) Penalized Logistic Regression
for Detecting Gene Interactions
</p>


<h3>See Also</h3>

<p>predict.plr, step.plr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100

p &lt;- 10
x &lt;- matrix(rnorm(n * p), nrow=n)
y &lt;- sample(c(0, 1), n, replace=TRUE)
fit &lt;- plr(x, y, lambda=1)

p &lt;- 3
z &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x &lt;- data.frame(x1=factor(z[, 1]), x2=factor(z[, 2]), x3=factor(z[, 3]))
y &lt;- sample(c(0, 1), n, replace=TRUE)
fit &lt;- plr(x, y, lambda=1)
# 'level' is automatically generated. Check 'fit$level'.
</code></pre>

<hr>
<h2 id='plr-internal'>
Internal plr functions
</h2><span id='topic+anova.stepplr'></span><span id='topic+cross.imat'></span><span id='topic+get.imat'></span><span id='topic+imat'></span><span id='topic+print.plr'></span><span id='topic+print.stepplr'></span><span id='topic+summary.plr'></span><span id='topic+summary.stepplr'></span><span id='topic+term.match'></span>

<h3>Description</h3>

<p>Internal plr functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'stepplr'
anova(object, ...)
  cross.imat(imat1, imat2)
  get.imat(x, level = NULL)
  imat(object, x)
  ## S3 method for class 'plr'
print(x, ...)
  ## S3 method for class 'stepplr'
print(x, ...)
  ## S3 method for class 'plr'
summary(object, ...)
  ## S3 method for class 'stepplr'
summary(object, ...)
  term.match(term1, term2, termlist, len)
</code></pre>


<h3>Author(s)</h3>

<p>Mee Young Park and Trevor Hastie</p>


<h3>References</h3>

<p>Mee Young Park and Trevor Hastie (2008) Penalized Logistic Regression
for Detecting Gene Interactions
</p>

<hr>
<h2 id='predict.plr'>
prediction function for plr
</h2><span id='topic+predict.plr'></span>

<h3>Description</h3>

<p>This function computes the linear predictors, probability estimates,
or the class labels for new data, using a <code>plr</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'plr'
predict(object, newx = NULL,
        type = c("link", "response", "class"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.plr_+3A_object">object</code></td>
<td>

<p><code>plr</code> object
</p>
</td></tr>
<tr><td><code id="predict.plr_+3A_newx">newx</code></td>
<td>

<p>matrix of features at which the predictions are made. If
<code>newx=NULL,</code> predictions for the training data are returned.
</p>
</td></tr>
<tr><td><code id="predict.plr_+3A_type">type</code></td>
<td>

<p>If <code>type=link,</code> the linear predictors are returned; if
<code>type=response,</code> the probability estimates are returned; and if
<code>type=class,</code> the class labels are returned. Default is
<code>type=link.</code>
</p>
</td></tr>
<tr><td><code id="predict.plr_+3A_...">...</code></td>
<td>

<p>other options for prediction
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mee Young Park and Trevor Hastie</p>


<h3>References</h3>

<p>Mee Young Park and Trevor Hastie (2008) Penalized Logistic Regression
for Detecting Gene Interactions
</p>


<h3>See Also</h3>

<p>plr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100

p &lt;- 10
x0 &lt;- matrix(rnorm(n * p), nrow=n)
y &lt;- sample(c(0, 1), n, replace=TRUE)
fit &lt;- plr(x0, y, lambda=1)
x1 &lt;- matrix(rnorm(n * p), nrow=n)
pred1 &lt;- predict(fit, x1, type="link")
pred2 &lt;- predict(fit, x1, type="response")
pred3 &lt;- predict(fit, x1, type="class")

p &lt;- 3
z &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x0 &lt;- data.frame(x1=factor(z[, 1]), x2=factor(z[, 2]), x3=factor(z[, 3]))
y &lt;- sample(c(0, 1), n, replace=TRUE)
fit &lt;- plr(x0, y, lambda=1)
z &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x1 &lt;- data.frame(x1=factor(z[, 1]), x2=factor(z[, 2]), x3=factor(z[, 3]))
pred1 &lt;- predict(fit, x1, type="link")
pred2 &lt;- predict(fit, x1, type="response")
pred3 &lt;- predict(fit, x1, type="class")
</code></pre>

<hr>
<h2 id='predict.stepplr'>
prediction function for step.plr
</h2><span id='topic+predict.stepplr'></span>

<h3>Description</h3>

<p>This function computes the linear predictors, probability estimates,
or the class labels for new data, using a <code>stepplr</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'stepplr'
predict(object, x = NULL, newx = NULL,
        type = c("link", "response", "class"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.stepplr_+3A_object">object</code></td>
<td>

<p><code>stepplr</code> object
</p>
</td></tr>
<tr><td><code id="predict.stepplr_+3A_x">x</code></td>
<td>

<p>matrix of features used for fitting <code>object.</code> If
<code>newx</code> is provided, <code>x</code> must be provided as well.
</p>
</td></tr>
<tr><td><code id="predict.stepplr_+3A_newx">newx</code></td>
<td>

<p>matrix of features at which the predictions are made. If
<code>newx=NULL,</code> predictions for the training data are returned.
</p>
</td></tr>
<tr><td><code id="predict.stepplr_+3A_type">type</code></td>
<td>

<p>If <code>type=link,</code> the linear predictors are returned; if
<code>type=response,</code> the probability estimates are returned; and if
<code>type=class,</code> the class labels are returned. Default is
<code>type=link.</code>
</p>
</td></tr>
<tr><td><code id="predict.stepplr_+3A_...">...</code></td>
<td>

<p>other options for prediction
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mee Young Park and Trevor Hastie</p>


<h3>References</h3>

<p>Mee Young Park and Trevor Hastie (2008) Penalized Logistic Regression
for Detecting Gene Interactions
</p>


<h3>See Also</h3>

<p>stepplr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
x0 &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x0 &lt;- cbind(rnorm(n), x0)
y &lt;- sample(c(0, 1), n, replace=TRUE)
level &lt;- vector("list", length=6)
for (i in 2:6) level[[i]] &lt;- seq(3)
fit &lt;- step.plr(x0, y, level=level)
x1 &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x1 &lt;- cbind(rnorm(n), x1)
pred1 &lt;- predict(fit, x0, x1, type="link")
pred2 &lt;- predict(fit, x0, x1, type="response")
pred3 &lt;- predict(fit, x0, x1, type="class")
</code></pre>

<hr>
<h2 id='step.plr'>
Forward stepwise selection procedure for penalized logistic
regression
</h2><span id='topic+step.plr'></span>

<h3>Description</h3>

<p>This function fits a series of L2 penalized logistic regression models
selecting variables through the forward stepwise selection procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  step.plr(x, y, weights = rep(1,length(y)), fix.subset = NULL,
           level = NULL, lambda = 1e-4, cp = "bic", max.terms = 5,
           type = c("both", "forward", "forward.stagewise"),
           trace = FALSE)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step.plr_+3A_x">x</code></td>
<td>

<p>matrix of features
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_y">y</code></td>
<td>

<p>binary response 
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_weights">weights</code></td>
<td>

<p>optional vector of weights for observations
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_fix.subset">fix.subset</code></td>
<td>

<p>vector of indices for the variables that are forced to be in the
model
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_level">level</code></td>
<td>

<p>list of length <code>ncol(x).</code> The j-th element corresponds to
the j-th column of <code>x.</code> If the j-th column of <code>x</code> is
discrete, <code>level[[j]]</code> is the set of levels for the
categorical factor. If the j-th column of <code>x</code> is continuous,
<code>level[[j]] = NULL.</code> <code>level</code> is automatically
generated in the function; however, if any levels of the
categorical factors are not observed, but still need to be included
in the model, then the user must provide the complete sets of the
levels through <code>level.</code> If a numeric column needs to be
considered discrete, it can be done by manually providing
<code>level</code> as well.
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_lambda">lambda</code></td>
<td>

<p>regularization parameter for the L2 norm of the
coefficients. The minimizing criterion in <code>plr</code> is
-log-likelihood+<code class="reqn">\lambda*\|\beta\|^2</code>. Default is
<code>lambda=1e-4.</code>
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_cp">cp</code></td>
<td>

<p>complexity parameter to be used when computing the
score. <code>score=deviance+cp*df.</code> If <code>cp="aic"</code> or
<code>cp="bic",</code> these are converted to <code>cp=2</code> or
<code>cp=log(sample size),</code> respectively. Default is
<code>cp="bic".</code>
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_max.terms">max.terms</code></td>
<td>

<p>maximum number of terms to be added in the forward selection
procedure. Default is <code>max.terms=5.</code>
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_type">type</code></td>
<td>

<p>If <code>type="both",</code> forward selection is followed by a backward
deletion. If <code>type="forward",</code> only a forward selection is
done. If <code>type="forward.stagewise",</code> variables are added in
the forward-stagewise method. Default is <code>"both".</code>
</p>
</td></tr>
<tr><td><code id="step.plr_+3A_trace">trace</code></td>
<td>

<p>If <code>TRUE,</code> the variable selection procedure prints out its
progress.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements an L2 penalized logistic regression along
with the stepwise variable selection procedure, as described in
&quot;Penalized Logistic Regression for Detecting Gene Interactions (2008)&quot;
by Park and Hastie.
</p>
<p>If <code>type="forward",</code> <code>max.terms</code> terms are sequentially
added to the model, and the model that minimizes <code>score</code> is
selected as the optimal fit. If <code>type="both",</code> a backward
deletion is done in addition, which provides a series of models with a
different combination of the selected terms. The optimal model
minimizing <code>score</code> is chosen from the second list.
</p>


<h3>Value</h3>

<p>A <code>stepplr</code> object is returned. <code>anova, predict, print,</code> and
<code>summary</code> functions can be applied.
</p>
<table>
<tr><td><code>fit</code></td>
<td>

<p><code>plr</code> object for the optimal model selected
</p>
</td></tr>
<tr><td><code>action</code></td>
<td>

<p>list that stores the selection order of the terms in the optimal
model
</p>
</td></tr>
<tr><td><code>action.name</code></td>
<td>

<p>list of the names of the sequentially added terms - in the same
order as in <code>action</code>
</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>

<p>deviance of the fitted model
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>residual degrees of freedom of the fitted model
</p>
</td></tr>
<tr><td><code>score</code></td>
<td>

<p>deviance + cp*df, where df is the model degrees of freedom
</p>
</td></tr>
<tr><td><code>group</code></td>
<td>

<p>vector of the counts for the dummy variables, to be used in
<code>predict.stepplr</code>
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>

<p>response variable used
</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>

<p>weights used
</p>
</td></tr>
<tr><td><code>fix.subset</code></td>
<td>

<p>fix.subset used
</p>
</td></tr>
<tr><td><code>level</code></td>
<td>

<p>level used
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>lambda used
</p>
</td></tr>
<tr><td><code>cp</code></td>
<td>

<p>complexity parameter used when computing the score
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>

<p>type used
</p>
</td></tr>
<tr><td><code>xnames</code></td>
<td>

<p>column names of <code>x</code>
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mee Young Park and Trevor Hastie</p>


<h3>References</h3>

<p>Mee Young Park and Trevor Hastie (2008) Penalized Logistic Regression
for Detecting Gene Interactions
</p>


<h3>See Also</h3>

<p>cv.step.plr, plr, predict.stepplr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100

p &lt;- 3
z &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x &lt;- data.frame(x1=factor(z[, 1]), x2=factor(z[, 2]), x3=factor(z[, 3]))
y &lt;- sample(c(0, 1), n, replace=TRUE)
fit &lt;- step.plr(x, y)
# 'level' is automatically generated. Check 'fit$level'.

p &lt;- 5
x &lt;- matrix(sample(seq(3), n * p, replace=TRUE), nrow=n)
x &lt;- cbind(rnorm(n), x)
y &lt;- sample(c(0, 1), n, replace=TRUE)
level &lt;- vector("list", length=6)
for (i in 2:6) level[[i]] &lt;- seq(3)
fit1 &lt;- step.plr(x, y, level=level, cp="aic")
fit2 &lt;- step.plr(x, y, level=level, cp=4)
fit3 &lt;- step.plr(x, y, level=level, type="forward")
fit4 &lt;- step.plr(x, y, level=level, max.terms=10)
# This is an example in which 'level' was input manually.
# level[[1]] should be either 'NULL' or 'NA' since the first factor is continuous.
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
