<!DOCTYPE html><html><head><title>Help for package SAiVE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SAiVE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aspect'><p>Raster of aspect</p></a></li>
<li><a href='#basin_dem'><p>Raster of elevation for basin delineation testing</p></a></li>
<li><a href='#basin_pts'><p>Points for basin delineation</p></a></li>
<li><a href='#createStreams'><p>Create stream network from DEM</p></a></li>
<li><a href='#drainageBasins'><p>Watershed/basin delineation</p></a></li>
<li><a href='#elev'><p>Raster of elevation</p></a></li>
<li><a href='#hydroProcess'><p>Hydro-process a DEM</p></a></li>
<li><a href='#modelMatch'><p>Find machine learning models for use in caret</p></a></li>
<li><a href='#permafrost'><p>Permafrost data</p></a></li>
<li><a href='#permafrost_polygons'><p>Polygons of permafrost occurrence and type</p></a></li>
<li><a href='#slope'><p>Raster of slope angle</p></a></li>
<li><a href='#solrad'><p>Raster of solar radiation</p></a></li>
<li><a href='#spatPredict'><p>Predict spatial variables using machine learning</p></a></li>
<li><a href='#streams'><p>Lines representing streams</p></a></li>
<li><a href='#thinFeatures'><p>Remove irrelevant predictor variables</p></a></li>
<li><a href='#veg'><p>Raster of vegetation types</p></a></li>
<li><a href='#wbtCheck'><p>Check WhiteboxTools binaries installation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions Used for SAiVE Group Research, Collaborations, and
Publications</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Holds functions developed by the University of Ottawa's SAiVE
    (Spatio-temporal Analysis of isotope Variations in the Environment)
    research group with the intention of facilitating the re-use of code,
    foster good code writing practices, and to allow others to benefit
    from the work done by the SAiVE group. Contributions are welcome via
    the 'GitHub' repository <a href="https://github.com/UO-SAiVE/SAiVE">https://github.com/UO-SAiVE/SAiVE</a> by group members as well as non-members.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/UO-SAiVE/SAiVE">https://github.com/UO-SAiVE/SAiVE</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/UO-SAiVE/SAiVE/issues">https://github.com/UO-SAiVE/SAiVE/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, crayon, doParallel, parallel, proxy, rlang, stats,
terra, utils, VSURF</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ranger, testthat (&ge; 3.0.0), vdiffr, whitebox</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-07 03:58:32 UTC; g_del</td>
</tr>
<tr>
<td>Author:</td>
<td>Ghislain de Laplante
    <a href="https://orcid.org/0000-0002-5093-9185"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre,
    cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ghislain de Laplante &lt;ghislain.delaplante@yukon.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-07 18:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='aspect'>Raster of aspect</h2><span id='topic+aspect'></span>

<h3>Description</h3>

<p>Raster of aspect
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aspect
</code></pre>


<h3>Format</h3>



<h4><code>aspect</code></h4>

<p>A tif file loaded as a terra spatRaster
</p>



<h3>Source</h3>

<p>Derived from the <a href="https://open.canada.ca/data/en/dataset/7f245e4d-76c2-4caa-951a-45d1d2051333">Canadian Digital Elevation Model DEM</a>
</p>

<hr>
<h2 id='basin_dem'>Raster of elevation for basin delineation testing</h2><span id='topic+basin_dem'></span>

<h3>Description</h3>

<p>Raster of elevation for basin delineation testing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basin_dem
</code></pre>


<h3>Format</h3>



<h4><code>basin_dem</code></h4>

<p>A tif file loaded as a terra spatRaster
</p>



<h3>Source</h3>

<p>Small subset of the <a href="https://open.canada.ca/data/en/dataset/7f245e4d-76c2-4caa-951a-45d1d2051333">Canadian Digital Elevation Model DEM</a>
</p>

<hr>
<h2 id='basin_pts'>Points for basin delineation</h2><span id='topic+basin_pts'></span>

<h3>Description</h3>

<p>Points for basin delineation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basin_pts
</code></pre>


<h3>Format</h3>



<h4><code>basin_pts</code></h4>

<p>A geopackage file loaded as a terra spatVector
</p>



<h3>Source</h3>

<p>Created by package developer in ArcGIS Pro
</p>

<hr>
<h2 id='createStreams'>Create stream network from DEM</h2><span id='topic+createStreams'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Creates a stream network from a provided DEM. In most cases it is advisable to first hydro-process the DEM (see <code><a href="#topic+hydroProcess">hydroProcess()</a></code>) to remove depressions which preclude continuous flow from one DEM cell to the next.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createStreams(
  DEM,
  threshold,
  vector = NULL,
  save_path = NULL,
  force_update_wbt = FALSE,
  n.cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createStreams_+3A_dem">DEM</code></td>
<td>
<p>The path to a digital elevation model file with .tif extension, or a terra spatRaster object. It is usually advisable to have already hydro-processed the DEM to remove artificial depressions. See <code><a href="#topic+hydroProcess">hydroProcess()</a></code>.</p>
</td></tr>
<tr><td><code id="createStreams_+3A_threshold">threshold</code></td>
<td>
<p>The accumulation threshold in DEM cells necessary to start defining a stream.</p>
</td></tr>
<tr><td><code id="createStreams_+3A_vector">vector</code></td>
<td>
<p>Output file specifications. NULL for no vector file saved to disk, &quot;gpkg&quot; for a geopackage file, &quot;shp&quot; for a shapefile.</p>
</td></tr>
<tr><td><code id="createStreams_+3A_save_path">save_path</code></td>
<td>
<p>An optional path in which to save the newly created stream network. If left NULL will save it in the same directory as the provided DEM or, if the DEM is a terra object, return only terra objects.</p>
</td></tr>
<tr><td><code id="createStreams_+3A_force_update_wbt">force_update_wbt</code></td>
<td>
<p>Whitebox Tools is by default only downloaded if it cannot be found on the computer, and no check are performed to ensure the local version is current. Set to TRUE if you know that there is a new version and you would like to use it.</p>
</td></tr>
<tr><td><code id="createStreams_+3A_n.cores">n.cores</code></td>
<td>
<p>The maximum number of cores to use. Leave NULL to use all cores minus 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is essentially a convenient wrapper around three WhiteboxTools geospatial tools: <code><a href="whitebox.html#topic+wbt_d8_flow_accumulation">whitebox::wbt_d8_flow_accumulation()</a></code>, <code><a href="whitebox.html#topic+wbt_d8_pointer">whitebox::wbt_d8_pointer()</a></code>, and <code><a href="whitebox.html#topic+wbt_extract_streams">whitebox::wbt_extract_streams()</a></code>
</p>


<h3>Value</h3>

<p>A raster representation of streams and, if requested, a vector representation of streams. Returned as terra objects and saved to disk if <code>save_path</code> is not null.
</p>


<h3>Author(s)</h3>

<p>Ghislain de Laplante (gdela069@uottawa.ca or ghislain.delaplante@yukon.ca)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


hydroDEM &lt;- hydroProcess(elev, 200, streams, n.cores = 2)
res &lt;- createStreams(hydroDEM, 50, n.cores = 2)

terra::plot(res$streams_derived)


</code></pre>

<hr>
<h2 id='drainageBasins'>Watershed/basin delineation</h2><span id='topic+drainageBasins'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Hydro-processes a DEM, creating flow accumulation, direction, and streams rasters, and (optionally) delineates watersheds above one or more points using <a href="https://www.whiteboxgeo.com/">Whitebox Tools</a>. To facilitate this task in areas with poor quality/low resolution DEMs, can &quot;burn-in&quot; a stream network to the DEM to ensure proper stream placement (see details). Many time-consuming raster operations are performed, so the function will attempt to use existing rasters if they are present in the same path as the base DEM and named according to the function's naming conventions. In practice, this means that only the first run of the function needs to be very time consuming. See details for more information.
</p>
<p>NOTE 1: This tool can be slow to execute, and will use a lot of memory. Be patient, it might take several hours with a large DEM.
</p>
<p>NOTE 2: ESRI shapefiles, on which the Whitebox Tools functions depend, truncate column names to 10 characters. You may want to save and re-assign column names to the output terra object after this function has run.
</p>
<p>NOTE 3: If you are have already run this tool and are using a DEM in the same directory as last time, you only need to specify the DEM and the points (and, optionally, a projection for the points output). Operations using the optional streams shapefile and generating flow accumulation direction, and the artificial streams raster do not need to be repeated unless you want to use a different DEM or streams shapefile.
</p>
<p>NOTE 4: This function is very memory (RAM) intensive. You'll want at least 16GB of RAM, and to ensure that most of it is free. If you get an error such as 'cannot allocate xxxxx bytes', you probably don't have the resources to run the tool. All rasters are un-compressed and converted to 64-bit float type before starting work, and there needs to be room to store more than twice that uncompressed raster size in memory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drainageBasins(
  save_path,
  DEM,
  streams = NULL,
  breach_dist = 10000,
  threshold = 500,
  overwrite = FALSE,
  points = NULL,
  points_name_col = NULL,
  projection = NULL,
  snap = "nearest",
  snap_dist = 200,
  force_update_wbt = FALSE,
  n.cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drainageBasins_+3A_save_path">save_path</code></td>
<td>
<p>The directory where you want the output shapefiles saved.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_dem">DEM</code></td>
<td>
<p>The path to a DEM including extension from which to delineate watersheds/catchments. Must be in .tif format. Derived layers such as flow accumulation, flow direction, and streams will inherit the DEM coordinate reference system.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_streams">streams</code></td>
<td>
<p>Optionally, the path to the polylines shapefile/geopackage containing lines, which can be used to improve accuracy when using poor quality DEMs. If this shapefile is the only input parameter being modified from previous runs (i.e. you've found a new/better streams shapefile but the DEM is unchanged) then specify a shapefile or geopackage lines file here and overwrite = TRUE.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_breach_dist">breach_dist</code></td>
<td>
<p>The max radius (in raster cells) for which to search for a path to breach depressions, passed to <code><a href="whitebox.html#topic+wbt_breach_depressions_least_cost">whitebox::wbt_breach_depressions_least_cost()</a></code>. This value should be high to ensure all depressions are breached. Note that the DEM is <em>not</em> breached in order of lowest elevation to greatest, nor is it breached sequentially (order is unknown, but the raster is presumably searched in some grid pattern for depressions). This means that flow paths may need to cross multiple depressions, especially in low relief areas.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_threshold">threshold</code></td>
<td>
<p>The accumulation threshold in DEM cells necessary to start defining a stream. This streams raster is necessary to snap pout points to, so make sure not to make this number too great!</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_overwrite">overwrite</code></td>
<td>
<p>If applicable, should rasters present in the same directory as the DEM be overwritten? This will also force the recalculation of derived layers.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_points">points</code></td>
<td>
<p>The path to the points shapefile (extension .shp) containing the points from which to build watersheds. The attribute of each point will be attached to the newly-created drainage polygons. Leave NULL (along with related parameters) to only process the DEM without defining watersheds.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_points_name_col">points_name_col</code></td>
<td>
<p>The name of the column in the points shapefile containing names to assign to the watersheds. Duplicates <em>are</em> allowed, and are labelled with the suffix _duplicate and a number for duplicates 2+.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_projection">projection</code></td>
<td>
<p>Optionally, a projection string in the form &quot;epsg:3579&quot; (find them <a href="https://epsg.io/">here</a>). The derived watersheds and point output layers will use this projection. If NULL the projection of the points will be used.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_snap">snap</code></td>
<td>
<p>Snap to the &quot;nearest&quot; derived (calculated) stream, or to the &quot;greatest&quot; flow accumulation cell within the snap distance? Beware that &quot;greatest&quot; will move the point downstream by up to the 'snap_dist' specified, while nearest might snap to the wrong stream.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_snap_dist">snap_dist</code></td>
<td>
<p>The search radius within which to snap points to streams. Snapping method depends on 'snap' parameter. Note that distance units will match the projection, so probably best to work on a meter grid.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_force_update_wbt">force_update_wbt</code></td>
<td>
<p>Whitebox Tools is by default only downloaded if it cannot be found on the computer, and no check are performed to ensure the local version is current. Set to TRUE if you know that there is a new version and you would like to use it.</p>
</td></tr>
<tr><td><code id="drainageBasins_+3A_n.cores">n.cores</code></td>
<td>
<p>The maximum number of cores to use. Leave NULL to use all cores minus 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses software from the Whitebox geospatial analysis package, built by Prof. John Lindsay. Refer to <a href="https://www.whiteboxgeo.com/manual/wbt_book/intro.html">this link</a> for more information.
</p>


<h4>Creating derived raster layers without defining watersheds</h4>

<p>This function can be run without having any specific point above which to define a watershed. This can come in handy if you need to know where the synthetic streams raster will end up to ensure that your defined watershed pour points do not end up on the wrong stream branch, or if you simply want to front-load work while you work on defining the watershed pour points. To do this, leave the parameter 'points' and associated parameters as <code>NULL</code>.
</p>



<h4>Explanation of process:</h4>

<p>Starting from a supplied DEM, the function will fill single-cell pits, burn-in a stream network depression if requested (ensuring that flow accumulations happen in the correct location), breach depressions in the digital elevation model using a least-cost algorithm (i.e. using the pathway resulting in minimal changes to the DEM considering distance and elevation) then calculate flow accumulation and direction rasters. Then, a raster of streams is created where flow accumulation is greatest. The points provided by the user are then snapped to the derived streams raster and watersheds are computed using the flow direction rasters. Finally, the watershed/drainage basin polygons are saved to the specified save path along with the provided points and the snapped pour points.
</p>



<h4>Using a streams shapefile to burn-in depressions to the DEM:</h4>

<p>Be aware that this part of the function should ideally be used with a &quot;simplified&quot; streams shapefile. In particular, avoid or pre-process stream shapefiles that represent side-channels, as these will burn-in several parallel tracks to the DEM. ESRI has a tool called &quot;simplify hydrology lines&quot; which is great if you can ever get it to work, and WhiteboxTools has functions <code><a href="whitebox.html#topic+wbt_remove_short_streams">whitebox::wbt_remove_short_streams()</a></code> to trim the streams raster, and <code><a href="whitebox.html#topic+wbt_repair_stream_vector_topology">whitebox::wbt_repair_stream_vector_topology()</a></code> to help in converting a corrected streams vector to raster in the first place.
</p>



<h3>Value</h3>

<p>A list of terra objects. If points are specified: delineated drainages, pour points as provided, snapped pour points, and the derived streams network. If no points: flow accumulation and direction rasters, and the derived streams network. If points specified, also saved to disk: an ESRI shapefile for each drainage basin, plus the associated snapped pour point and the point as provided and a shapefiles for all basins/points together. In all cases the created or discovered rasters will be in the same folder as the DEM.
</p>


<h3>Author(s)</h3>

<p>Ghislain de Laplante (gdela069@uottawa.ca or ghislain.delaplante@yukon.ca)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


# Must be run with file paths as well as a save_path

# Interim raster are created in the same path as the DEM

file.copy(system.file("extdata/basin_rast.tif", package = "SAiVE"),
  paste0(tempdir(), "/basin_rast.tif"))

basins &lt;- drainageBasins(save_path = tempdir(),
  DEM = paste0(tempdir(), "/basin_rast.tif"),
  streams = system.file("extdata/streams.gpkg", package = "SAiVE"),
  points = system.file("extdata/basin_pts.gpkg", package = "SAiVE"),
  points_name_col = "ID",
  breach_dist = 500,
  n.cores = 2)

terra::plot(basins$delineated_basins)


</code></pre>

<hr>
<h2 id='elev'>Raster of elevation</h2><span id='topic+elev'></span>

<h3>Description</h3>

<p>Raster of elevation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elev
</code></pre>


<h3>Format</h3>



<h4><code>elev</code></h4>

<p>A tif file loaded as a terra spatRaster
</p>



<h3>Source</h3>

<p>Small subset of the <a href="https://open.canada.ca/data/en/dataset/7f245e4d-76c2-4caa-951a-45d1d2051333">Canadian Digital Elevation Model DEM</a>
</p>

<hr>
<h2 id='hydroProcess'>Hydro-process a DEM</h2><span id='topic+hydroProcess'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Takes a digital elevation model and prepares it for hydrological analyses, such as basin delineation. Modifies the input DEM by breaching single cell pits/depressions and then breaching remaining depressions using a least cost algorithm (where cost is a function of distance plus elevation change to the DEM).
</p>
<p>If a streams layer is specified, a depression will be &quot;burned-in&quot; to the DEM along the stream path (after converting the vector file to a raster). This is very useful when trying to delineate basins with a poor resolution DEM. You can control the depth of this depression with parameter 'burn_dist'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hydroProcess(
  DEM,
  breach_dist,
  streams = NULL,
  burn_dist = 10,
  save_path = NULL,
  n.cores = NULL,
  force_update_wbt = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hydroProcess_+3A_dem">DEM</code></td>
<td>
<p>The path to a digital elevation raster file with .tif extension, or a terra spatRaster object.</p>
</td></tr>
<tr><td><code id="hydroProcess_+3A_breach_dist">breach_dist</code></td>
<td>
<p>The max radius (in raster cells) in which to search for a path to breach depressions, passed to <code><a href="whitebox.html#topic+wbt_breach_depressions_least_cost">whitebox::wbt_breach_depressions_least_cost()</a></code>. This value should be high to ensure all depressions are breached, keeping in mind that greater distance = greater computing time. Note that the DEM is <em>not</em> breached in order of lowest elevation to greatest, nor is it breached sequentially (order is unknown, but the raster is presumably searched in some grid pattern for depressions). This means that flow paths may need to cross multiple depressions, especially in low relief areas.</p>
</td></tr>
<tr><td><code id="hydroProcess_+3A_streams">streams</code></td>
<td>
<p>Optionally, the path to the polylines shapefile or geopackage file containing streams, which can be used to improve hydrological accuracy when using poor quality DEMs but decent accuracy stream networks.</p>
</td></tr>
<tr><td><code id="hydroProcess_+3A_burn_dist">burn_dist</code></td>
<td>
<p>The number of units (in DEM units) to use for burning-in the stream network.</p>
</td></tr>
<tr><td><code id="hydroProcess_+3A_save_path">save_path</code></td>
<td>
<p>An optional path in which to save the processed DEM. If left NULL will save it in the same directory as the provided DEM or, if the DEM is a terra object, return only terra objects.</p>
</td></tr>
<tr><td><code id="hydroProcess_+3A_n.cores">n.cores</code></td>
<td>
<p>The maximum number of cores to use. Leave NULL to use all cores minus 1.</p>
</td></tr>
<tr><td><code id="hydroProcess_+3A_force_update_wbt">force_update_wbt</code></td>
<td>
<p>Whitebox Tools is by default only downloaded if it cannot be found on the computer, and no check are performed to ensure the local version is current. Set to TRUE if you know that there is a new version and you would like to use it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Relies on two WhiteboxTools functions: <code><a href="whitebox.html#topic+wbt_fill_single_cell_pits">whitebox::wbt_fill_single_cell_pits()</a></code> and <code><a href="whitebox.html#topic+wbt_breach_depressions_least_cost">whitebox::wbt_breach_depressions_least_cost()</a></code>. If the parameter <code>streams</code> is specified, a depression is burned into the DEM after running fill_single_cell_pits and before breaching depressions.
</p>


<h3>Value</h3>

<p>A hydro-processed DEM returned as a terra object and saved to disk if <code>save_path</code> is not null.
</p>


<h3>Author(s)</h3>

<p>Ghislain de Laplante (gdela069@uottawa.ca or ghislain.delaplante@yukon.ca)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


# Running with terra objects:
res &lt;- hydroProcess(DEM = elev,
  breach_dist = 500,
  streams = streams,
  n.cores = 2)

terra::plot(res)

# Running with file paths:
res &lt;- hydroProcess(DEM = system.file("extdata/dem.tif", package = "SAiVE"),
  breach_dist = 500,
  streams = system.file("extdata/streams.gpkg", package = "SAiVE"),
  n.cores = 2)

terra::plot(res)


</code></pre>

<hr>
<h2 id='modelMatch'>Find machine learning models for use in caret</h2><span id='topic+modelMatch'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>As of 2023-06-15, there are 238 different machine learning models which can be used with the CARET package. As evaluating model performance is time consuming, selecting a subset of models to test prior to deciding on which model to use is essential. This function aims to facilitate this process by matching models according to their Jaccard similarity, in a process inspired by <a href="https://topepo.github.io/caret/models-clustered-by-tag-similarity.html">this section</a> in the CARET e-book. Model data is fetched from <a href="https://topepo.github.io/caret/tag_data.csv">here</a>. The result of this function can then be passed to <code><a href="#topic+spatPredict">spatPredict()</a></code> to further refine model selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelMatch(model, type = "match", similarity = 0.7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelMatch_+3A_model">model</code></td>
<td>
<p>The abbreviation or short name of the model you'd like to match, taken from <a href="https://topepo.github.io/caret/available-models.html">here</a>.</p>
</td></tr>
<tr><td><code id="modelMatch_+3A_type">type</code></td>
<td>
<p>The type of model. You can match the input <code>model</code> type with &quot;match&quot;, or select from dual-purpose models (&quot;dual&quot;), regression models only (&quot;regression&quot;), or classification models only (&quot;classification&quot;).</p>
</td></tr>
<tr><td><code id="modelMatch_+3A_similarity">similarity</code></td>
<td>
<p>The similarity threshold to use as a numeric value from 0 to 1. Models with a similarity score greater than this will be returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function requires internet access to get an up-to-date list of models.
</p>


<h3>Value</h3>

<p>A data.frame of models meeting the requested similarity threshold along with the model abbreviations that can be passed to <code><a href="caret.html#topic+train">caret::train()</a></code> or to function <code><a href="#topic+spatPredict">spatPredict()</a></code>.
</p>


<h3>Author(s)</h3>

<p>Ghislain de Laplante (gdela069@uottawa.ca or ghislain.delaplante@yukon.ca)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Find models similar to 'ranger'
modelMatch("ranger")

# Find only models with a similarity &gt; 0.8 to 'ranger'
modelMatch("ranger", similarity = 0.8)

</code></pre>

<hr>
<h2 id='permafrost'>Permafrost data</h2><span id='topic+permafrost'></span>

<h3>Description</h3>

<p>A small data set of permafrost type with correlated terrain attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permafrost
</code></pre>


<h3>Format</h3>



<h4><code>permafrost</code></h4>

<p>A data frame with 400 rows and 8 columns
</p>



<h3>Source</h3>

<p>Permafrost type classification from central Yukon, with corresponding values derived from the Canadian Digital Elevation Model.
</p>

<hr>
<h2 id='permafrost_polygons'>Polygons of permafrost occurrence and type</h2><span id='topic+permafrost_polygons'></span>

<h3>Description</h3>

<p>Polygons of permafrost occurrence and type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permafrost_polygons
</code></pre>


<h3>Format</h3>



<h4><code>permafrost_polygons</code></h4>

<p>A geopackage file loaded as a terra spatVector.
</p>



<h3>Source</h3>

<p>Permafrost classification polygons created from ground observations and geophysics in central Yukon.
</p>

<hr>
<h2 id='slope'>Raster of slope angle</h2><span id='topic+slope'></span>

<h3>Description</h3>

<p>Raster of slope angle
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slope
</code></pre>


<h3>Format</h3>



<h4><code>slope</code></h4>

<p>A tif file loaded as a terra spatRaster
</p>



<h3>Source</h3>

<p>Derived from the <a href="https://open.canada.ca/data/en/dataset/7f245e4d-76c2-4caa-951a-45d1d2051333">Canadian Digital Elevation Model DEM</a>
</p>

<hr>
<h2 id='solrad'>Raster of solar radiation</h2><span id='topic+solrad'></span>

<h3>Description</h3>

<p>Raster of solar radiation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solrad
</code></pre>


<h3>Format</h3>



<h4><code>solrad</code></h4>

<p>A tif file loaded as a terra spatRaster
</p>



<h3>Source</h3>

<p>Derived from the <a href="https://open.canada.ca/data/en/dataset/7f245e4d-76c2-4caa-951a-45d1d2051333">Canadian Digital Elevation Model DEM</a> using the <a href="https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/area-solar-radiation.htm">ArcGIS Area Solar Radiation tool</a>
</p>

<hr>
<h2 id='spatPredict'>Predict spatial variables using machine learning</h2><span id='topic+spatPredict'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>Function to facilitate the prediction of spatial variables using machine learning, including the selection of a particular model and/or model parameters from several user-defined options. Both classification and regression is supported, though please ensure that the models passed to the parameter <code>methods</code> are suitable.
</p>
<p>Note that you may need to acquiesce to installing supplementary packages, depending on the model types chosen and whether or not these have been run before; this function may not be 'set and forget'.
</p>
<p>It is possible to specify multiple model types (the <code>methods</code> argument) as well as model-specific parameters (the <code>trainControl</code> parameter) if you wish to test multiple options and select the best one. To facilitate model type selection, refer to function <code><a href="#topic+modelMatch">modelMatch()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatPredict(
  features,
  outcome,
  poly_sample = 1000,
  trainControl,
  methods,
  fastCompare = TRUE,
  thinFeatures = TRUE,
  predict = FALSE,
  n.cores = NULL,
  save_path = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatPredict_+3A_features">features</code></td>
<td>
<p>Independent variables. Must be either a NAMED list of terra spatRasters or a multi-layer (stacked) spatRaster (c(rast1, rast2). All layers must all have the same cell size, alignment, extent, and crs. These rasters should include the training extent (that covered by the spatVector in <code>outcome</code>) as well as the desired extrapolation extent.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_outcome">outcome</code></td>
<td>
<p>Dependent variable, as a terra spatVector of points or polygons with a single attribute table column (of class integer, numeric or factor). The class of this column dictates whether the problem is approached as a classification or regression problem; see details. If specifying polygons, stratified random sampling will be done with <code>poly_sample</code> number of points per unique polygon value.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_poly_sample">poly_sample</code></td>
<td>
<p>If passing a polygon SpatVector to <code>outcome</code>, the number of points to generate from the polygons for each unique polygon value.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_traincontrol">trainControl</code></td>
<td>
<p>Parameters used to control training of the machine learning model, created with <code><a href="caret.html#topic+trainControl">caret::trainControl()</a></code>. Passed to the <code>trControl</code> parameter of <code><a href="caret.html#topic+train">caret::train()</a></code>. If specifying multiple model types in <code>methods</code> you can use a single <code>trainControl</code> which will apply to all <code>methods</code>, or pass multiple variations to this argument as a list with names matching the names of <code>methods</code> (one element for each model specified in methods).</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_methods">methods</code></td>
<td>
<p>A string specifying one or more classification/regression model(s) to use. Passed to the <code>method</code> parameter of <code><a href="caret.html#topic+train">caret::train()</a></code>. If specifying more than one method they will all be passed to <code><a href="caret.html#topic+resamples">caret::resamples()</a></code> to compare model performance. Then, if <code>predict = TRUE</code>, the model with the highest accuracy will be selected to predict the raster surface across the exent of <code>features</code>. A different <code>trainControl</code> parameter can be used for each model in <code>methods</code>.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_fastcompare">fastCompare</code></td>
<td>
<p>If specifying multiple model types in <code>methods</code> or one model with multiple different <code>trainControl</code> objects, should the points in <code>outcome</code> be sub-sampled for the model comparison step? The selected model will be trained on the full <code>outcome</code> data set after selection. TRUE/FALSE. This only applies if <code>methods</code> is length &gt; 3 and if <code>outcome</code> has more than 4000 rows.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_thinfeatures">thinFeatures</code></td>
<td>
<p>Should random forest selection using <code><a href="VSURF.html#topic+VSURF">VSURF::VSURF()</a></code> be used in an attempt to remove irrelevant variables?</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_predict">predict</code></td>
<td>
<p>TRUE will apply the selected model to the full extent of <code>features</code> and return a raster saved to <code>save_path</code>.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_n.cores">n.cores</code></td>
<td>
<p>The maximum number of cores to use. Leave NULL to use all cores minus 1.</p>
</td></tr>
<tr><td><code id="spatPredict_+3A_save_path">save_path</code></td>
<td>
<p>The path (folder) to which you wish to save the predicted raster. Not used unless <code>predict = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function partly operates as a convenient means of passing various parameters to the <code><a href="caret.html#topic+train">caret::train()</a></code> function, enabling the user to rapidly trial different model types and parameter sets. In addition, pre-processing of data can optionally be done using <code><a href="VSURF.html#topic+VSURF">VSURF::VSURF()</a></code> (parameter <code>thinFeatures</code>) which can decrease the time to run models by removing superfluous parameters.
</p>


<h3>Value</h3>

<p>A list with three to five elements: the outcome of the VSURF variable selection process, details of the fitted model, model performance statistics, model performance comparison (if methods includes more than one model), and the final predicted raster (if predict = TRUE). If applicable, the predicted raster is written to disk.
</p>


<h3>Balancing classes in outcome (dependent) variable</h3>

<p>Models can be biased if they are given significantly more points in one outcome class vs others, and best practice is to even out the number of points in each class. If extracting point values from a vector or raster object, a simple way to do that is by using the &quot;strata&quot; parameter if using <code><a href="terra.html#topic+sample">terra::spatSample()</a></code>. If working directly from points, <code><a href="caret.html#topic+downSample">caret::downSample()</a></code> and <code><a href="caret.html#topic+downSample">caret::upSample()</a></code> can be used. See <a href="https://topepo.github.io/caret/subsampling-for-class-imbalances.html">this link</a> for more information.
</p>


<h3>Classification or regression</h3>

<p>Whether this function treats your inputs as a classification or regression problem depends on the class attached to the outcome variable. A class <code>factor</code> will be treated as a classification problem while all other classes will be treated as regression problems.
</p>


<h3>Method for selecting the best model:</h3>

<p>When specifying multiple model types in<code>methods</code>, each model type and <code>trainControl</code> pair (if <code>trainControl</code> is a list of length equal to <code>methods</code>) is run using <code><a href="caret.html#topic+train">caret::train()</a></code>. To speed things up you can use <code>fastCompare</code> = TRUE. Models are then compared on their 'accuracy' metric as output by <code><a href="caret.html#topic+resamples">caret::resamples()</a></code>, and the highest-performing model is selected. If <code>fastCompare</code> is TRUE, this model is then run on the complete data set provided in <code>outcome</code>. Model statistics are returned upon function completion, which allows the user to select their own 'best performing' model based on other criteria.
</p>


<h3>Author(s)</h3>

<p>Ghislain de Laplante (gdela069@uottawa.ca or ghislain.delaplante@yukon.ca)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# These examples can take a while to run!

# Single model, single trainControl

trainControl &lt;- caret::trainControl(
                method = "repeatedcv",
                number = 2, # 2-fold Cross-validation
                repeats = 2, # repeated 2 times
                verboseIter = FALSE,
                returnResamp = "final",
                savePredictions = "all",
                allowParallel = TRUE)

 outcome &lt;- permafrost_polygons
 outcome$Type &lt;- as.factor(outcome$Type)

result &lt;- spatPredict(features = c(aspect, solrad, slope),
  outcome = outcome,
  poly_sample = 100,
  trainControl = trainControl,
  methods = "ranger",
  n.cores = 2)

terra::plot(result$prediction)


# Multiple models, multiple trainControl

trainControl &lt;- list("ranger" = caret::trainControl(
                                  method = "repeatedcv",
                                  number = 2,
                                  repeats = 2,
                                  verboseIter = FALSE,
                                  returnResamp = "final",
                                  savePredictions = "all",
                                  allowParallel = TRUE),
                     "Rborist" = caret::trainControl(
                                   method = "boot",
                                   number = 2,
                                   repeats = 2,
                                   verboseIter = FALSE,
                                   returnResamp = "final",
                                   savePredictions = "all",
                                   allowParallel = TRUE)
                                   )

result &lt;- spatPredict(features = c(aspect, solrad, slope),
  outcome = outcome,
  poly_sample = 100,
  trainControl = trainControl,
  methods = c("ranger", "Rborist"),
  n.cores = 2)

terra::plot(result$prediction)

</code></pre>

<hr>
<h2 id='streams'>Lines representing streams</h2><span id='topic+streams'></span>

<h3>Description</h3>

<p>Lines representing streams
</p>


<h3>Usage</h3>

<pre><code class='language-R'>streams
</code></pre>


<h3>Format</h3>



<h4><code>streams</code></h4>

<p>A geopackage file loaded as a terra spatVector
</p>



<h3>Source</h3>

<p>A subset of the Yukon CANVEC water flow lines found <a href="https://open.yukon.ca/data/datasets/water-flow-50k-canvec">here</a>
</p>

<hr>
<h2 id='thinFeatures'>Remove irrelevant predictor variables</h2><span id='topic+thinFeatures'></span>

<h3>Description</h3>

<p>Uses <code><a href="VSURF.html#topic+VSURF">VSURF::VSURF()</a></code> to build random forests and remove irrelevant predictor variables from a data.frame containing an outcome variable and 2 or more predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thinFeatures(data, outcome_col, n.cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thinFeatures_+3A_data">data</code></td>
<td>
<p>A data.frame containing a column for the outcome variable and <em>n</em> columns for predictor variables.</p>
</td></tr>
<tr><td><code id="thinFeatures_+3A_outcome_col">outcome_col</code></td>
<td>
<p>The name of the outcome variable column.</p>
</td></tr>
<tr><td><code id="thinFeatures_+3A_n.cores">n.cores</code></td>
<td>
<p>The maximum number of cores to use. Leave NULL to use all cores minus 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two data.frames: the outcome of the VSURF algorithm and the data after applying the VSURF results (rows removed if applicable)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# thinFeatures on 'permafrost' data set

data(permafrost)
res &lt;- thinFeatures(permafrost, "Type", n.cores = 2)

# Results will vary due to inherent randomness of random forests!

</code></pre>

<hr>
<h2 id='veg'>Raster of vegetation types</h2><span id='topic+veg'></span>

<h3>Description</h3>

<p>Raster of vegetation types
</p>


<h3>Usage</h3>

<pre><code class='language-R'>veg
</code></pre>


<h3>Format</h3>



<h4><code>veg</code></h4>

<p>A tif file loaded as a terra spatRaster
</p>



<h3>Source</h3>

<p>A small subset of the North American Land Cover dataset produced by the <a href="http://www.cec.org/north-american-environmental-atlas/land-cover-30m-2020/">Commission for Environmental Cooperation</a>, resampled to match cell size of other rasters in this package.
</p>

<hr>
<h2 id='wbtCheck'>Check WhiteboxTools binaries installation</h2><span id='topic+wbtCheck'></span>

<h3>Description</h3>

<p>Checks for the existence of WhiteboxTools in its default directory and installs it if necessary or if <code>force = TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wbtCheck(force = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wbtCheck_+3A_force">force</code></td>
<td>
<p>Set TRUE to force update of WhiteboxTools binaries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the version number of the installed binaries and (if necessary) installs WhiteboxTools in its default location.
</p>


<h3>Author(s)</h3>

<p>Ghislain de Laplante (gdela069@uottawa.ca or ghislain.delaplante@yukon.ca)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

#Check if WhiteboxTools binaries are installed. If not, install latest version.
wbtCheck()

# Update WhiteboxTools binaries if they are already installed.
wbtCheck(force = TRUE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
