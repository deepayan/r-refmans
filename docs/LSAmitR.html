<!DOCTYPE html><html><head><title>Help for package LSAmitR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LSAmitR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#datenKapitel01'>
<p>Illustrationsdaten zu Kapitel 1, Testkonstruktion</p></a></li>
<li><a href='#datenKapitel02'>
<p>Illustrationsdaten zu Kapitel 2, Stichprobenziehung</p></a></li>
<li><a href='#datenKapitel03'>
<p>Illustrationsdaten zu Kapitel 3, Standard-Setting</p></a></li>
<li><a href='#datenKapitel04'>
<p>Illustrationsdaten zu Kapitel 4, Differenzielles Itemfunktionieren in Subgruppen</p></a></li>
<li><a href='#datenKapitel05'>
<p>Illustrationsdaten zu Kapitel 5, Testdesign</p></a></li>
<li><a href='#datenKapitel06'>
<p>Illustrationsdaten zu Kapitel 6, Skalierung und Linking</p></a></li>
<li><a href='#datenKapitel07'>
<p>Illustrationsdaten zu Kapitel 7, Statistische Analysen produktiver Kompetenzen</p></a></li>
<li><a href='#datenKapitel08'>
<p>Illustrationsdaten zu Kapitel 8, Fehlende Daten und Plausible Values</p></a></li>
<li><a href='#datenKapitel09'>
<p>Illustrationsdaten zu Kapitel 9, Fairer Vergleich in der Rueckmeldung</p></a></li>
<li><a href='#datenKapitel10'>
<p>Illustrationsdaten zu Kapitel 10, Reporting und Analysen</p></a></li>
<li><a href='#Kapitel  0'><p>Kapitel 0: Konzeption der Ueberpruefung der Bildungsstandards in</p>
Oesterreich</a></li>
<li><a href='#Kapitel  1'><p>Kapitel 1: Testkonstruktion</p></a></li>
<li><a href='#Kapitel  2'><p>Kapitel 2: Stichprobenziehung</p></a></li>
<li><a href='#Kapitel  3'><p>Kapitel 3: Standard-Setting</p></a></li>
<li><a href='#Kapitel  4'><p>Kapitel 4: Differenzielles Itemfunktionieren in Subgruppen</p></a></li>
<li><a href='#Kapitel  5'><p>Kapitel 5: Testdesign</p></a></li>
<li><a href='#Kapitel  6'><p>Kapitel 6: Skalierung und Linking</p></a></li>
<li><a href='#Kapitel  7'><p>Kapitel 7: Statistische Analysen produktiver Kompetenzen</p></a></li>
<li><a href='#Kapitel  8'><p>Kapitel 8: Fehlende Daten und Plausible Values</p></a></li>
<li><a href='#Kapitel  9'><p>Kapitel 9: Fairer Vergleich in der Rueckmeldung</p></a></li>
<li><a href='#Kapitel 10'><p>Kapitel 10: Reporting und Analysen</p></a></li>
<li><a href='#Kapitel 11'><p>Kapitel 11: Aspekte der Validierung</p></a></li>
<li><a href='#LSAmitR-Hilfsmethoden'>
<p>Large-Scale Assessment mit R: Hilfsfunktionen aus den Kapiteln</p></a></li>
<li><a href='#LSAmitR-package'>
<p>Daten, Beispiele und Funktionen zu 'Large-Scale Assessment mit R'</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Daten, Beispiele und Funktionen zu 'Large-Scale Assessment mit
R'</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas Kiefer [aut, cre],
  Alexander Robitzsch [aut],
  Matthias Trendtel [aut],
  Robert Fellinger [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Kiefer &lt;thomas.kiefer@iqs.gv.at&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Dieses R-Paket stellt Zusatzmaterial in Form von Daten, Funktionen
             und R-Hilfe-Seiten für den Herausgeberband Breit, S. und Schreiner, 
             C. (Hrsg.). (2016). "Large-Scale Assessment mit R: Methodische Grundlagen 
             der österreichischen Bildungsstandardüberprüfung." Wien: facultas. 
             (ISBN: 978-3-7089-1343-8, <a href="https://www.iqs.gv.at/themen/bildungsforschung/publikationen/veroeffentlichte-publikationen">https://www.iqs.gv.at/themen/bildungsforschung/publikationen/veroeffentlichte-publikationen</a>) zur 
             Verfügung.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lme4, Hmisc</td>
</tr>
<tr>
<td>Suggests:</td>
<td>BIFIEsurvey, TAM, miceadds, sirt, mice, pls, WrightMap, irr,
lavaan, difR, kerdiest, glmnet, mirt, car, mitml, matrixStats,
combinat, xtable, tensor, gtools, plyr, prettyR, gridExtra,
lattice</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.iqs.gv.at/themen/bildungsforschung/publikationen/veroeffentlichte-publikationen">https://www.iqs.gv.at/themen/bildungsforschung/publikationen/veroeffentlichte-publikationen</a></td>
</tr>
<tr>
<td>Language:</td>
<td>de</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-31 18:38:35 UTC; t.kiefer</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-01 07:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='datenKapitel01'>
Illustrationsdaten zu Kapitel 1, Testkonstruktion
</h2><span id='topic+datenKapitel01'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 1, 
<em>Testkonstruktion</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel01)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel01</code> ist eine Liste mit den vier Elementen <code>pilotScored</code>, 
<code>pilotItems</code>, <code>pilotRoh</code> und <code>pilotMM</code>, die einer fiktiven
Pilotierung entstammen.
</p>

<ul>
<li> <p><strong>pilotScored</strong>: Rekodierte Instrumentendaten der Pilotierung (vgl. 
<code>pilotItems</code>).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>sidstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>female</code> </td><td style="text-align: left;"> Geschlecht (<code>"w"</code> = weiblich, <code>"m"</code> = männlich).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>form</code> </td><td style="text-align: left;"> das von der Schülerin/dem Schüler bearbeitete Testheft.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RS*</code> </td><td style="text-align: left;"> dichotom und polytom bewertete Itemantworten auf Items 
<code>E8RS13151</code> bis <code>E8RS7993</code> (<code>0:4</code> = Score der Itemantwort, 
<code>8</code> = Itemantwort "nicht bewertbar", <code>9</code> = "omitted response").
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	2504 obs. of  163 variables:
 $ sidstud  : int  1052 1057 1058 1064 1068 1073 1074 1076 1078 1080 ...
 $ female   : chr  "w" "w" "w" "w" ...
 $ form     : chr  "PR019" "PR020" "PR021" "PR022" ...
 $ E8RS13151: int  NA NA NA NA NA NA NA NA NA NA ...
 $ E8RS13171: int  NA NA 1 NA NA NA NA 1 NA NA ...
 $ E8RS13491: int  NA NA NA NA 0 NA NA NA NA NA ...
 $ E8RS13641: int  0 NA NA NA NA NA 0 NA NA NA ...
 [...] 
 $ E8RS7929: int  NA NA 0 NA NA NA NA NA NA NA ...
 $ E8RS7940: int  NA NA NA NA NA 0 NA NA NA NA ...
 $ E8RS7955: int  NA 0 NA NA NA NA NA NA 2 NA ...
 $ E8RS7993: int  NA NA NA 0 NA NA 2 NA NA NA ...
&#8288;</code>

</p>

</li>
<li> <p><strong>pilotItems</strong>: Itembank der Pilotierung.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>testlet</code> </td><td style="text-align: left;"> Testletname des Items (gleichbedeutend mit zugewiesenem 
Stimulus). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>item</code> </td><td style="text-align: left;"> Itemname. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>format</code> </td><td style="text-align: left;"> Antwortformt. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus</code> </td><td style="text-align: left;"> Fokus des Testitems. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focusLabel</code> </td><td style="text-align: left;"> Bezeichnung des Fokus des Testitems. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>topic</code> </td><td style="text-align: left;"> Thema. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>no.Words</code> </td><td style="text-align: left;"> Anzahl Wörter im Stimulus. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>key</code> </td><td style="text-align: left;"> Indikator der richtigen Antwort (<code>1:3</code> = korrekte 
Antwortoption bei Multiple-Choice Items, <code>A:F</code> = korrekt zuzuordnende 
Antwortoption bei Matching-Items, <code>""</code>= korrekte Antworten für Items im 
Antwortformat "open gap-fill" werden in Form von Coding-Guides ausgebildeten 
Kodiererinnen/Kodierern vorgelegt). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>maxScore</code> </td><td style="text-align: left;"> Maximal zu erreichende Punkte. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>PR*</code> </td><td style="text-align: left;"> Positionen der Items in den Testheften <code>PR001</code> bis 
<code>PR056</code>.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	320 obs. of  65 variables:
 $ testlet   : chr  "E8RS1315" "E8RS1317" "E8RS1340" "E8RS1349" ...
 $ item      : chr  "E8RS13151" "E8RS13171" "E8RS13401" "E8RS13491" ...
 $ format    : chr  "MC3" "MC3" "MC3" "MC3" ...
 $ focus     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ focusLabel: chr  "RFocus1" "RFocus1" "RFocus1" "RFocus1" ...
 $ topic     : chr  "Interkulturelle und landeskundliche Aspekte" "Familie und Freunde" ...
 $ no.Words  : int  24 24 29 32 10 33 22 41 10 37 ...
 $ key       : chr  "1" "3" "2" "2" ...
 $ maxScore  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ PR001     : int  NA NA NA 10 NA NA NA NA NA NA ...
 $ PR002     : int  5 NA 6 NA 7 NA NA 8 NA NA ...
 $ PR003     : int  NA NA NA 6 NA NA NA NA NA NA ...
 $ PR004     : int  NA NA NA 10 NA NA NA NA NA NA ...
 [...] 
 $ PR054     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ PR055     : int  NA 9 NA NA NA NA 10 NA NA 11 ...
 $ PR056     : int  NA NA NA NA NA NA NA NA 6 NA ...
&#8288;</code>

</p>


</li>
<li> <p><strong>pilotRoh</strong>: Instrumentendaten der Pilotierung mit Roh-Antworten 
(vgl. <code>pilotItems</code>).
</p>


<table>
<tr>
 <td style="text-align: left;">
<code>sidstud</code> </td><td style="text-align: left;"> eindeutiger Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>female</code> </td><td style="text-align: left;"> Geschlecht (<code>"w"</code> = weiblich, <code>"m"</code> = männlich).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>form</code> </td><td style="text-align: left;"> das von der Schülerin/dem Schüler bearbeitete Testheft.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RS*</code> </td><td style="text-align: left;"> Rohantworten der Schülerin/des Schülers auf Items 
<code>E8RS13151</code> bis <code>E8RS37281</code> (<code>(8, 9)</code> = für alle Items, wie oben, 
nicht bewertbare bzw. ausgelassene Itemantwort, 
<code>1:3</code> = gewählte Antwortoption bei Multiple-Choice Items, 
<code>A:F</code> = zugeordnete Antwortoption bei Matching-Items, 
<code>0:1</code> = von Kodiererinnen/Kodierern 
bewertete Antworten für Items im Antwortformat "open gap-fill").
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	2504 obs. of  323 variables:
 $ sidstud  : int  1052 1057 1058 1064 1068 1073 1074 1076 1078 1080 ...
 $ female   : chr  "w" "w" "w" "w" ...
 $ form     : chr  "PR019" "PR020" "PR021" "PR022" ...
 $ E8RS13151: int  NA NA NA NA NA NA NA NA NA NA ...
 $ E8RS13171: int  NA NA 3 NA NA NA NA 3 NA NA ...
 $ E8RS13491: int  NA NA NA NA 3 NA NA NA NA NA ...
 $ E8RS13641: int  2 NA NA NA NA NA 2 NA NA NA ...
 [...] 
 $ E8RS37163: chr  "" "" "" "" ...
 $ E8RS37164: chr  "" "" "" "" ...
 $ E8RS37165: chr  "" "" "" "" ...
 $ E8RS37281: chr  "" "" "" "" ...
&#8288;</code>

</p>

</li>
<li> <p><strong>pilotMM</strong>: Multiple-Marking-Datensatz der Pilotierung mit 
gemeinsamen Bewertungen einer itemweisen Auswahl von Schülerantworten durch alle 
Kodiererinnen/Kodierer (<code>0</code> = falsch, <code>1</code> = richtig, <code>(8, 9)</code> = wie 
oben, nicht bewertbare bzw. ausgelassene Itemantwort).
</p>


<table>
<tr>
 <td style="text-align: left;">
<code>sidstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>item</code> </td><td style="text-align: left;"> Itemnummer. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Coder_1</code> </td><td style="text-align: left;"> Bewertung der Schülerantwort von Kodiererin/Kodierer 1. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Coder_2</code> </td><td style="text-align: left;"> Bewertung der Schülerantwort von Kodiererin/Kodierer 2. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Coder_3</code> </td><td style="text-align: left;"> Bewertung der Schülerantwort von Kodiererin/Kodierer 3.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	1200 obs. of  5 variables:
 $ sidstud: int  1185 1269 1311 1522 1658 1665 1854 1889 1921 2067 ...
 $ item   : chr  "E8RS46051" "E8RS46051" "E8RS46051" "E8RS46051" ...
 $ Coder_1: int  1 1 9 0 0 9 9 1 9 0 ...
 $ Coder_2: int  1 1 9 0 0 9 9 1 9 0 ...
 $ Coder_3: int  1 1 9 0 0 9 9 1 9 0 ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Itzlinger-Bruneforth, U., Kuhn, J.-T. &amp; Kiefer, T. (2016). Testkonstruktion. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 21&ndash;50). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+201">Kapitel 1</a></code>.
</p>

<hr>
<h2 id='datenKapitel02'>
Illustrationsdaten zu Kapitel 2, Stichprobenziehung
</h2><span id='topic+datenKapitel02'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 2, 
<em>Stichprobenziehung</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel02)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel02</code> ist eine Liste mit den zwei Elementen <code>schueler</code> und 
<code>schule</code>, die auf Schulen- und Schülerebene alle für eine 
Stichprobenziehung und die Berechnung von Stichprobengewichten relevanten 
Informationen beinhalten.
</p>
<p>Diese 51644 Schülerinnen und Schüler in 1327 Schulen &ndash; verteilt über vier 
Strata &ndash; stellen die Zielpopulation der im Band durchgeführten Analysen dar.
</p>


<ul>
<li> <p><strong>schueler</strong>: Schülerdatensatz.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>SKZ</code> </td><td style="text-align: left;"> Schulenidentifikator ("Schulkennzahl"). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>klnr</code> </td><td style="text-align: left;"> Nummer der Klasse innerhalb der Schule. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idclass</code> </td><td style="text-align: left;"> Klassenidentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>female</code> </td><td style="text-align: left;"> Geschlecht (<code>1</code> = weiblich, <code>0</code> = männlich).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Stratum</code> </td><td style="text-align: left;"> Stratum der Schule. (<code>1:4</code> = Stratum 1 bis Stratum 4; 
für eine genauere Beschreibung der Strata, siehe Buchkapitel).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>teilnahme</code> </td><td style="text-align: left;"> Information über die Teilnahme der Schülerin/ des Schülers 
an der Erhebung (<code>1</code> = nimmt teil, <code>0</code> = nimmt nicht teil). 
Information ist erst zum Zeitpunkt der Erhebung vorhanden (nicht schon bei 
der Stichprobenziehung) und wird zur Berechnung der Stichprobengewichte mit 
Ausfalladjustierung herangezogen (siehe 
Buchkapitel, Unterabschnitt 2.4.4).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	51644 obs. of  7 variables:
 $ SKZ      : int [1:51644] 10001 10001 10001 10001 10001 10001 10001 10001 10001 10001 ...
 $ klnr     : int [1:51644] 1 1 1 1 1 1 1 1 1 1 ...
 $ idclass  : int [1:51644] 1000101 1000101 1000101 1000101 1000101 1000101 1000101 1000101 ...
 $ idstud   : int [1:51644] 100010101 100010102 100010103 100010104 100010105 100010106 100010107 ...
 $ female   : int [1:51644] 1 0 0 0 0 1 0 1 0 1 ...
 $ Stratum  : int [1:51644] 1 1 1 1 1 1 1 1 1 1 ...
 $ teilnahme: int [1:51644] 1 1 1 1 0 1 1 1 1 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>schule</strong>: Schulendatensatz.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>index</code> </td><td style="text-align: left;"> Laufparameter.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SKZ</code> </td><td style="text-align: left;"> Schulenidentifikator ("Schulkennzahl"). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>stratum</code> </td><td style="text-align: left;"> Stratum der Schule. (<code>1:4</code> = Stratum 1 bis Stratum 4; 
für eine genauere Beschreibung der Strata, siehe Buchkapitel).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>NSchueler</code> </td><td style="text-align: left;"> Anzahl Schüler/innen in der 4. Schulstufe der Schule.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>NKlassen</code> </td><td style="text-align: left;"> Anzahl Klassen in der 4. Schulstufe der Schule.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	1327 obs. of  5 variables:
 $ index    : int [1:1327] 1 2 3 4 5 6 7 8 9 10 ...
 $ SKZ      : int [1:1327] 10204 10215 10422 11017 10257 10544 10548 10846 11127 10126 ...
 $ stratum  : int [1:1327] 1 1 1 1 1 1 1 1 1 1 ...
 $ NSchueler: int [1:1327] 8 9 9 9 10 10 10 10 10 11 ...
 $ NKlassen : int [1:1327] 1 1 1 1 1 1 1 2 1 1 ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>George, A. C., Oberwimmer, K. &amp; Itzlinger-Bruneforth, U. (2016). 
Stichprobenziehung. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 51&ndash;81). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+202">Kapitel 2</a></code>.
</p>

<hr>
<h2 id='datenKapitel03'>
Illustrationsdaten zu Kapitel 3, Standard-Setting
</h2><span id='topic+datenKapitel03'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 3, 
<em>Standard-Setting</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel03)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel03</code> ist eine Liste mit den vier Elementen <code>ratings</code>, 
<code>bookmarks</code>, <code>sdat</code> und <code>productive</code>, die Daten zu verschiedenen 
Methoden eines Standard-Settings beinhalten.
</p>
<p>Normierte Personen- und Itemparameter entstammen einer Vorgängerstudie, in der 
die Parameter für das jeweils zu betrachtende Testinstrument auf die 
Berichtsmetrik transformiert wurden (vgl. Kapitel 5, <em>Testdesign</em>, und 
Kapitel 6, <em>Skalierung und Linking</em>, im Band).
</p>


<ul>
<li> <p><strong>ratings</strong>: Daten aus der IDM-Methode (siehe Buchkapitel, 
Unterabschnitt 3.2.2).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>task</code> </td><td style="text-align: left;"> Itemnummer. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Norm_rp23</code> </td><td style="text-align: left;"> Itemparameter auf der Berichtsmetrik. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Seite_OIB</code> </td><td style="text-align: left;"> Seitenzahl im OIB.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>R01...R12</code> </td><td style="text-align: left;"> Von der jeweiligen Expertin/dem jeweiligen Experten 
(Rater/in) zugeordnete Kompetenzstufe des Items.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	60 obs. of  15 variables:
 $ task     : chr [1:60] "E8RS89991" "E8RS14021" "E8RS16031" "E8RS14171" ...
 $ Norm_rp23: num [1:60] 376 396 396 413 420 ...
 $ Seite_OIB: int [1:60] 1 2 3 4 5 6 7 8 9 10 ...
 $ R01      : int [1:60] 1 1 1 1 1 1 1 1 1 1 ...
 $ R02      : int [1:60] 1 1 1 2 1 2 2 1 2 2 ...
 $ R03      : int [1:60] 1 2 1 2 1 2 2 1 1 2 ...
 $ R04      : int [1:60] 1 1 1 1 2 1 1 1 2 1 ...
 $ R05      : int [1:60] 2 2 1 2 1 1 2 1 2 2 ...
 $ R06      : int [1:60] 1 1 1 1 2 1 2 1 2 2 ...
 $ R07      : int [1:60] 1 1 1 1 1 1 1 1 1 2 ...
 $ R08      : int [1:60] 2 2 1 2 2 2 2 1 2 2 ...
 $ R09      : int [1:60] 2 1 1 1 1 1 2 1 2 2 ...
 $ R10      : int [1:60] 1 2 1 1 1 1 1 1 2 1 ...
 $ R11      : int [1:60] 2 2 1 1 2 2 2 1 2 1 ...
 $ R12      : int [1:60] 1 2 1 2 3 2 2 1 1 2 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>bookmarks</strong>: Daten aus der Bookmark-Methode (siehe Buchkapitel, 
Unterabschnitt 3.2.3).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Rater</code> </td><td style="text-align: left;"> Rateridentifikator der Expertin/des Experten im Panel. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Cut1</code> </td><td style="text-align: left;"> Bookmark der Expertin/des Experten in Form einer Seite im OIB, 
wo ein Schüler an der Grenze zwischen der ersten und zweiten Stufe das Item 
nicht mehr sicher lösen könnte (für eine genauere Beschreibung der Stufen, siehe 
Buchkapitel).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Cut2</code> </td><td style="text-align: left;"> Entsprechender Bookmark für die Grenze zwischen zweiter und
dritter Stufe.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	12 obs. of  3 variables:
 $ Rater: chr [1:12] "R01" "R02" "R03" "R04" ...
 $ Cut1 : int [1:12] 6 4 6 2 4 4 4 4 3 6 ...
 $ Cut2 : int [1:12] 45 39 39 45 39 30 39 39 44 45 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>sdat</strong>: Plausible Values zum Berichten von Impact Data (siehe 
Buchkapitel, Unterabschnitt 3.2.4).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>pid</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>studwgt</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers (vgl. Kapitel 
2, <em>Stichprobenziehung</em>, im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TPV1...TPV10</code> </td><td style="text-align: left;"> Plausible Values der Schülerin/des Schülers auf der 
Berichtsmetrik (vgl. Kapitel 8, <em>Fehlende Daten und Plausible Values</em>, im Band).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	3500 obs. of  12 variables:
 $ pid    : int [1:3500] 1 2 3 4 5 6 7 8 9 10 ...
 $ studwgt: num [1:3500] 0.978 0.978 0.978 0.978 0.978 ...
 $ TPV1   : num [1:3500] 635 562 413 475 427 ...
 $ TPV2   : num [1:3500] 601 558 409 452 462 ...
 $ TPV3   : num [1:3500] 512 555 383 444 473 ...
 $ TPV4   : num [1:3500] 675 553 375 473 454 ...
 $ TPV5   : num [1:3500] 595 553 384 471 457 ...
 $ TPV6   : num [1:3500] 593 557 362 490 501 ...
 $ TPV7   : num [1:3500] 638 518 292 460 490 ...
 $ TPV8   : num [1:3500] 581 493 306 467 477 ...
 $ TPV9   : num [1:3500] 609 621 333 448 462 ...
 $ TPV10  : num [1:3500] 573 634 406 537 453 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>productive</strong>: Daten aus der Contrasting-Groups-Methode (siehe 
Buchkapitel, Unterabschnitt 3.3.2).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Script</code> </td><td style="text-align: left;"> Nummer des Schülertexts. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Performance</code> </td><td style="text-align: left;"> Personenparameter der Schülerin/des Schülers auf der 
Berichtsmetrik. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>R01...R10</code> </td><td style="text-align: left;"> Von der jeweiligen Expertin/dem jeweiligen Experten 
(Rater/in) zugeordnete Kompetenzstufe der Performanz (<code>0</code> = untere Stufe, 
<code>1</code> = obere Stufe; für eine genauere Beschreibung der Stufen, siehe 
Buchkapitel).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	45 obs. of  12 variables:
 $ Script     : int [1:45] 1 2 3 4 5 6 7 8 9 10 ...
 $ Performance: num [1:45] 211 260 269 308 321 ...
 $ R01        : int [1:45] 1 0 0 1 0 0 0 0 0 0 ...
 $ R02        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R03        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R04        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R05        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R06        : int [1:45] 1 0 0 0 0 0 1 0 0 0 ...
 $ R07        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R08        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R09        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
 $ R10        : int [1:45] 0 0 0 0 0 0 0 0 0 0 ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Luger-Bazinger, C., Freunberger, R. &amp; Itzlinger-Bruneforth, U. (2016). 
Standard-Setting. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 83&ndash;110). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+203">Kapitel 3</a></code>.
</p>

<hr>
<h2 id='datenKapitel04'>
Illustrationsdaten zu Kapitel 4, Differenzielles Itemfunktionieren in Subgruppen
</h2><span id='topic+datenKapitel04'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 4, 
<em>Differenzielles Itemfunktionieren in Subgruppen</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel04)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel04</code> ist eine Liste mit den drei Elementen <code>dat</code>, 
<code>dat.th1</code> und <code>ibank</code>.
</p>


<ul>
<li> <p><strong>dat</strong>: Dichotome Itemantworten von 9884 Schülerinnen und Schülern 
im Multiple-Matrix-Design mit Gruppierungsmerkmal.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>AHS</code> </td><td style="text-align: left;"> Besuch einer allgemeinbildenden höheren Schulen (<code>AHS</code> = 1), bzw. 
allgemeinbildenden Pflichtschule (<code>AHS</code> = 0).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RS*</code> </td><td style="text-align: left;"> dichotom bewertete Itemantworten zu Items 
<code>E8RS01661</code> bis <code>E8RS79931</code>.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	9884 obs. of  52 variables:
 $ idstud   : int [1:9884] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ AHS      : int [1:9884] 0 0 0 0 0 0 0 0 0 0 ...
 $ E8RS01661: int [1:9884] 0 NA 1 NA 0 0 NA 1 NA 0 ...
 $ E8RS02011: int [1:9884] 0 NA 0 NA 0 0 NA 0 NA 0 ...
 $ E8RS02201: int [1:9884] NA 1 NA 1 NA NA 1 NA 1 NA ...
 [...]
 $ E8RS79641: int [1:9884] NA 0 0 0 0 0 NA NA 0 NA ...
 $ E8RS79931: int [1:9884] 0 NA NA NA NA NA 0 1 NA 0 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>dat.th1</strong>: Teildatensatz mit Itemantworten der Subgruppe von 1636 
Schülerinnen und Schülern, die das erste Testheft (vgl. <code>ibank</code>) bearbeitet 
haben.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>AHS</code> </td><td style="text-align: left;"> Besuch einer allgemeinbildenden höheren Schulen (<code>AHS</code> = 1), bzw. 
allgemeinbildenden Pflichtschule (<code>AHS</code> = 0).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RS*</code> </td><td style="text-align: left;"> dichotom bewertete Itemantworten zu Items 
<code>E8RS01661</code> bis <code>E8RS79931</code>.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	1636 obs. of  27 variables:
 $ idstud   : int [1:1636] 10010109 10010111 10020101 10020113 10020114 10030110 ...
 $ AHS      : int [1:1636] 0 0 0 0 0 0 0 0 0 0 ...
 $ E8RS01661: int [1:1636] 1 0 0 1 0 1 0 0 0 0 ...
 $ E8RS02011: int [1:1636] 0 0 0 1 0 0 1 0 0 1 ...
 $ E8RS02421: int [1:1636] 0 0 0 0 0 1 0 0 0 1 ...
 [...]
 $ E8RS28551: int [1:1636] 1 0 1 0 0 0 1 1 0 0 ...
 $ E8RS79931: int [1:1636] 1 0 0 0 0 0 0 0 0 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>ibank</strong>: Beispielhafte Itembank mit klassifizierenden 
Item-Informationen (vgl. Kapitel 1, <em>Testkonstruktion</em>, im Band).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>task</code> </td><td style="text-align: left;"> Itemname. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>format</code> </td><td style="text-align: left;"> Antwortformat des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus</code> </td><td style="text-align: left;"> Fokuskategorie des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">



<code>itemnr</code> </td><td style="text-align: left;"> Itemidentifikator.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	50 obs. of  4 variables:
 $ task       : chr  "E8RS01661" "E8RS02011" "E8RS02201" "E8RS02231" ...
 $ format     : chr  "MC4" "MC4" "MC4" "MC4" ...
 $ focus      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ itemnr     : int  1661 2011 2201 2231 2251 2421 2461 2891 2931 3131 ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Trendtel, M., Schwabe, F. &amp; Fellinger, R. (2016). Differenzielles 
Itemfunktionieren in Subgruppen. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 111&ndash;147). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+204">Kapitel 4</a></code>.
</p>

<hr>
<h2 id='datenKapitel05'>
Illustrationsdaten zu Kapitel 5, Testdesign
</h2><span id='topic+datenKapitel05'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 5, 
<em>Testdesign</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel05)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel05</code> ist eine Liste mit den sechs Elementen <code>tdItembank</code>, 
<code>tdBib2d</code>, <code>tdBibPaare</code>, <code>tdExItembank</code>, <code>tdExBib2d</code> und 
<code>tdExBibPaare</code>, die sowohl für die Umsetzung im Kapitel als auch für die 
Übungsaufgaben die relevanten Informationen auf Itemebene in Form einer 
Itembank und Zwischenergebnisse aus dem Blockdesign für die Weiterverarbeitung 
beinhalten.
</p>


<ul>
<li> <p><strong>tdItembank</strong>: Itembank für den Testdesignprozess, bestehend aus 
286 dichotomen und polytomen Items.
</p>


<table>
<tr>
 <td style="text-align: left;">
<code>testlet</code> </td><td style="text-align: left;"> Testletname des Items (gleichbedeutend mit zugewiesenem 
Stimulus). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>itemnr</code> </td><td style="text-align: left;"> Itemidentifikator </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>task</code> </td><td style="text-align: left;"> Itemname.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>format</code> </td><td style="text-align: left;"> Antwortformat.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus</code> </td><td style="text-align: left;"> Fokuskategorie des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus.label</code> </td><td style="text-align: left;"> Bezeichnung des Fokus. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>topic</code> </td><td style="text-align: left;"> Themengruppe des Inhalts des zum Item gehörenden Stimulus.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>audiolength</code> </td><td style="text-align: left;"> Länge der Tonaufnahme in Sekunden.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RelFreq</code> </td><td style="text-align: left;"> Item-Schwierigkeit (genauer: aus Pilotierung gewonnener 
Erwartungswert gewichtet mit höchstem erreichbaren Punktewert bei dem Item; 
vgl. Kapitel 1, <em>Testkonstruktion</em>, im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rpb.WLE</code> </td><td style="text-align: left;"> Item-Trennschärfe (genauer: Punktbiseriale Korrelation der 
Itemantworten mit dem Weighted Likelihood Personenschätzer (WLE); vgl. Kapitel 1
und Kapitel 6, <em>Skalierung und Linking</em>, im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>uniformDIF</code> </td><td style="text-align: left;"> Uniformes Differenzielles Itemfunktionieren (vgl. Kapitel 
4, <em>Differenzielles Itemfunktionieren in Subgruppen</em>, im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>DIF.ETS</code> </td><td style="text-align: left;"> Klassifikation des uniform DIF nach ETS (vgl. Kapitel 
4 im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>IIF_380</code> </td><td style="text-align: left;"> Wert der Fisher-Iteminformationsfunktionen am Skalenwert 380 
(vgl. Kapitel 6 im Band). </td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code>IIF_580</code> </td><td style="text-align: left;"> Wert der Fisher-Iteminformationsfunktionen am Skalenwert 
580.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	286 obs. of  14 variables:
 $ testlet    : chr [1:286] "E8LS0127" "E8LS0128" "E8LS0132" "E8LS0135" ...
 $ itemnr     : int [1:286] 127 128 132 135 139 141 142 144 145 147 ...
 $ task       : chr [1:286] "E8LS0127" "E8LS0128" "E8LS0132" "E8LS0135" ...
 $ format     : chr [1:286] "MC4" "MC4" "MC4" "MC4" ...
 $ focus      : int [1:286] 0 2 2 5 2 5 2 4 2 5 ...
 $ focus.label: chr [1:286] "LFocus0" "LFocus2" "LFocus2" "LFocus5" ...
 $ topic      : chr [1:286] "Körper und Gesundheit" "Gedanken, Empfindungen und Gefühle" ...
 $ audiolength: int [1:286] 47 46 39 62 51 30 44 28 50 23 ...
 $ RelFreq    : num [1:286] 0.71 0.314 0.253 0.847 0.244 ...
 $ rpb.WLE    : num [1:286] 0.516 0.469 0.285 0.54 0.352 ...
 $ uniformDIF : num [1:286] 0.115726 0.474025 0.11837 0.083657 -0.000051 ...
 $ DIF.ETS    : chr [1:286] "A+" "B+" "A+" "A+" ...
 $ IIF_380    : num [1:286] 0.4073 0.1542 0.0708 0.4969 0.0611 ...
 $ IIF_580    : num [1:286] 0.157 0.508 0.277 0.26 0.148 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>tdBib2d</strong>: Vollständiges durch den BIB-Design-Algorithmus erzeugtes
Itemblock-Design (vgl. Tabelle 5.3) in tabellarischer Aufstellung mit 30 
Testheften (Zeilen), 6 Positionen (Spalten) und 30 Itemblöcken (Zelleneinträge).
</p>
<p><code style="white-space: pre;">&#8288;'data.frame':	30 obs. of  6 variables:
 $ V1: int [1:30] 12 5 6 7 3 1 17 4 18 13 ...
 $ V2: int [1:30] 2 11 9 4 10 8 15 17 7 26 ...
 $ V3: int [1:30] 7 6 10 12 1 5 20 15 17 8 ...
 $ V4: int [1:30] 11 9 3 2 8 4 13 5 22 7 ...
 $ V5: int [1:30] 10 7 2 9 4 12 6 18 13 1 ...
 $ V6: int [1:30] 3 8 1 5 6 11 16 27 14 24 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>tdBibPaare</strong>: Ergebnis des BIB-Design-Algorithmus als Blockpaare, 
wobei die Zelleneinträge die paarweisen Auftretenshäufigkeiten des Zeilenblocks
mit dem Spaltenblock im Design anzeigen.
</p>
<p><code style="white-space: pre;">&#8288;'data.frame':	30 obs. of  30 variables:
 $ V1 : int [1:30] 6 1 2 2 1 2 1 3 1 2 ...
 $ V2 : int [1:30] 1 6 2 2 1 1 3 0 3 2 ...
 $ V3 : int [1:30] 2 2 6 1 0 3 1 2 2 5 ...
 [...]
 $ V29: int [1:30] 0 0 1 1 0 1 0 0 1 2 ...
 $ V30: int [1:30] 1 1 1 0 0 0 0 1 0 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>tdExItembank</strong>: Beispiel-Itembank für den Testdesignprozess in den 
Übungsaufgaben zum Kapitel.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>task</code> </td><td style="text-align: left;"> Itemname. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>format</code> </td><td style="text-align: left;"> Antwortformat.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus</code> </td><td style="text-align: left;"> Fokuskategorie des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>p</code> </td><td style="text-align: left;"> Item-Leichtigkeit (genauer: in der Pilotierung beobachtete 
relative Lösungshäufigkeit für dichotome Items). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>p_cat</code> </td><td style="text-align: left;"> Dreistufige Kategorisierung der Schwierigkeit. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>itemdiff</code> </td><td style="text-align: left;"> Rasch-kalibrierte Itemparameter. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bearbeitungszeit</code> </td><td style="text-align: left;"> Geschätzte mittlere Bearbeitungszeit des Items.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	250 obs. of  7 variables:
 $ task            : chr [1:250] "M80003" "M80004" "M80006" "M80007" ...
 $ format          : chr [1:250] "ho" "MC4" "MC4" "ho" ...
 $ focus           : int [1:250] 1 4 4 2 3 4 1 2 3 3 ...
 $ p               : num [1:250] 0.84 0.56 0.34 0.45 0.2 0.42 0.77 0.42 0.34 0.71 ...
 $ p_cat           : chr [1:250] "leicht" "mittel" "mittel" "mittel" ...
 $ itemdiff        : int [1:250] 404 570 676 622 761 636 457 636 676 494 ...
 $ bearbeitungszeit: int [1:250] 90 60 90 120 90 150 90 30 120 90 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>tdExBib2d</strong>: Vollständiges Itemblock-Design zur Weiterverarbeitung 
in den Übungsaufgaben zum Kapitel in tabellarischer Aufstellung mit 10 
Testheften (Zeilen), 4 Positionen (Spalten) und 10 Itemblöcken (Zelleneinträge). 
</p>
<p><code style="white-space: pre;">&#8288;'data.frame':	10 obs. of  4 variables:
 $ V1: int [1:10] 1 9 8 2 10 4 7 3 5 6
 $ V2: int [1:10] 10 6 7 8 4 1 9 5 3 2
 $ V3: int [1:10] 6 10 9 1 5 2 3 8 4 7
 $ V4: int [1:10] 7 8 4 3 9 6 1 10 2 5
&#8288;</code>

</p>

</li>
<li> <p><strong>tdExBibPaare</strong>: Itemblock-Design zur Weiterverarbeitung in den 
Übungsaufgaben in der Darstellung als Blockpaare, wobei die Zelleneinträge 
die paarweisen Auftretenshäufigkeiten des Zeilenblocks mit dem Spaltenblock 
im Design anzeigen.
</p>
<p><code style="white-space: pre;">&#8288;'data.frame':	10 obs. of  10 variables:
 $ V1 : int [1:10] 4 2 2 1 0 2 2 1 1 1
 $ V2 : int [1:10] 2 4 2 2 2 2 1 1 0 0
 $ V3 : int [1:10] 2 2 4 1 2 0 1 2 1 1
 $ V4 : int [1:10] 1 2 1 4 2 1 1 1 2 1
 $ V5 : int [1:10] 0 2 2 2 4 1 1 1 1 2
 $ V6 : int [1:10] 2 2 0 1 1 4 2 1 1 2
 $ V7 : int [1:10] 2 1 1 1 1 2 4 1 2 1
 $ V8 : int [1:10] 1 1 2 1 1 1 1 4 2 2
 $ V9 : int [1:10] 1 0 1 2 1 1 2 2 4 2
 $ V10: int [1:10] 1 0 1 1 2 2 1 2 2 4
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Kiefer, T., Kuhn, J.-T. &amp; Fellinger, R. (2016). Testdesign. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 149&ndash;184). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+205">Kapitel 5</a></code>.
</p>

<hr>
<h2 id='datenKapitel06'>
Illustrationsdaten zu Kapitel 6, Skalierung und Linking
</h2><span id='topic+datenKapitel06'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 6, 
<em>Skalierung und Linking</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel06)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel06</code> ist eine Liste mit den fünf Elementen <code>dat</code>, 
<code>itembank</code>, <code>datTH1</code>, <code>itembankTH1</code> und <code>normdat</code>.
</p>


<ul>
<li> <p><strong>dat</strong>: Dichotome und polytome Itemantworten von 9885 Schülerinnen 
und Schülern im Multiple-Matrix-Design mit Stichprobengewichten und 
Testheftinformation.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>index</code> </td><td style="text-align: left;"> Laufindex. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers (vgl. Kapitel 
2, <em>Stichprobenziehung</em>, im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>th</code> </td><td style="text-align: left;"> Bearbeitetes Testheft.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>I1...I50</code> </td><td style="text-align: left;"> Itemantworten.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	9885 obs. of  54 variables:
 $ index  : int [1:9885] 1 2 3 4 5 6 7 8 9 10 ...
 $ idstud : int [1:9885] 10010101 10010102 10010103 10010105 10010106 10010107 10010108 ...
 $ wgtstud: num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
 $ th     : chr [1:9885] "ER04" "ER03" "ER05" "ER02" ...
 $ I1     : int [1:9885] 0 NA 1 NA 0 0 NA 1 NA 0 ...
 $ I2     : int [1:9885] 0 NA 0 NA 0 0 NA 0 NA 0 ...
 $ I3     : int [1:9885] NA 1 NA 1 NA NA 1 NA 1 NA ...
 [...]
 $ I49    : int [1:9885] 0 NA NA 4 NA NA 3 NA 3 NA ...
 $ I50    : int [1:9885] NA 0 0 NA 1 2 NA 0 NA 2 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>itembank</strong>: Den Instrumentendaten zugrundeliegende Itembank mit 
klassifizierenden Item-Informationen (vgl. Kapitel 1, Testkonstruktion, im Band).
</p>

<table>
<tr>
 <td style="text-align: left;">

<code>Item</code> </td><td style="text-align: left;"> Itemname. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>format</code> </td><td style="text-align: left;"> Antwortformat des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus</code> </td><td style="text-align: left;"> Fokuskategorie des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">




<code>itemnr</code> </td><td style="text-align: left;"> Itemidentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>N.subI</code> </td><td style="text-align: left;"> Anzahl Subitems.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	50 obs. of  5 variables:
 $ index      : int [1:50] 1 2 3 4 5 6 7 8 9 10 ...
 $ Item       : chr [1:50] "I1" "I2" "I3" "I4" ...
 $ format     : chr [1:50] "MC4" "MC4" "MC4" "MC4" ...
 $ focus      : int [1:50] 0 0 0 0 0 0 0 0 0 0 ...
 $ itemnr     : int [1:50] 1661 2011 2201 2231 2251 2421 2461 2891 2931 3131 ...
 $ N.subI     : int [1:50] 1 1 1 1 1 1 1 1 1 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>datTH1</strong>: Teildatensatz mit Itemantworten der Subgruppe von 1637 
Schülerinnen und Schülern, die das erste Testheft bearbeitet haben.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>index</code> </td><td style="text-align: left;"> Laufindex. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers (vgl. Kapitel 
2, <em>Stichprobenziehung</em>, im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>th</code> </td><td style="text-align: left;"> Bearbeitetes Testheft.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>I1...I50</code> </td><td style="text-align: left;"> Itemantworten.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	1637 obs. of  29 variables:
 $ index  : int [1:1637] 8 10 12 23 24 34 41 46 54 57 ...
 $ idstud : int [1:1637] 10010109 10010111 10020101 10020113 10020114 10030110 10040103 ...
 $ wgtstud: num [1:1637] 34.5 34.5 29.2 29.2 29.2 ...
 $ th     : chr [1:1637] "ER01" "ER01" "ER01" "ER01" ...
 $ I1     : int [1:1637] 1 0 0 1 0 1 0 0 0 0 ...
 $ I2     : int [1:1637] 0 0 0 1 0 0 1 0 0 1 ...
 $ I6     : int [1:1637] 0 0 0 0 0 1 0 0 0 1 ...
 [...]
 $ I47    : int [1:1637] 0 2 0 2 0 0 2 1 0 1 ...
 $ I50    : int [1:1637] 0 2 0 2 0 0 1 1 0 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>itembankTH1</strong>: Itembank zum Testheft 1.
</p>

<table>
<tr>
 <td style="text-align: left;">

<code>Item</code> </td><td style="text-align: left;"> Itemname. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>format</code> </td><td style="text-align: left;"> Antwortformat des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>focus</code> </td><td style="text-align: left;"> Fokuskategorie des Items. </td>
</tr>
<tr>
 <td style="text-align: left;">




<code>itemnr</code> </td><td style="text-align: left;"> Itemidentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>N.subI</code> </td><td style="text-align: left;"> Anzahl Subitems.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	25 obs. of  5 variables:
 $ Item       : chr [1:25] "I1" "I2" "I6" "I9" ...
 $ format     : chr [1:25] "MC4" "MC4" "MC4" "MC4" ...
 $ focus      : int [1:25] 0 0 0 0 0 1 1 1 1 1 ...
 $ itemnr     : int [1:25] 1661 2011 2421 2931 3131 3641 4491 4681 5621 5761 ...
 $ N.subI     : int [1:25] 1 1 1 1 1 1 1 1 1 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>normdat</strong>: Instrumentendaten einer Normierungsstudie (vgl. 
Kapitel 3, <em>Standard-Setting</em>, und  Kapitel 5, <em>Testdesign</em>, im Band) 
mit Ankeritems für die Illustration von Linkingmethoden.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers in der 
Normierungsstudie (es wird von einer vollständig randomisierten Stichprobe
ausgegangen, weshalb die Gewichte konstant 1 sind). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>th</code> </td><td style="text-align: left;"> Testheft.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>I*</code> </td><td style="text-align: left;"> Itemantworten zu Items, die in der zu linkenden Studie auch 
eingesetzt werden. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>J*</code> </td><td style="text-align: left;"> Itemantworten zu Items, die in der zu linkenden Studie nicht 
verwendet werden.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	3000 obs. of  327 variables:
 $ idstud : int [1:3000] 1000 1005 1011 1014 1021 1024 1025 1026 1027 1028 ...
 $ wgtstud: int [1:3000] 1 1 1 1 1 1 1 1 1 1 ...
 $ th     : chr [1:3000] "E8R01" "E8R02" "E8R03" "E8R04" ...
 $ J1     : int [1:3000] NA NA NA NA NA NA NA NA 0 NA ...
 $ J2     : int [1:3000] NA NA 0 NA NA NA NA NA NA NA ...
 $ J3     : int [1:3000] NA NA NA NA NA NA NA NA 0 NA ...
 [...]
 $ I39    : int [1:3000] NA NA NA NA NA NA NA NA NA NA ...
 $ I40    : int [1:3000] NA NA NA NA NA NA NA NA 0 NA ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Trendtel, M., Pham, G. &amp; Yanagida, T. (2016). Skalierung und Linking.
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 185&ndash;224). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+206">Kapitel 6</a></code>.
</p>

<hr>
<h2 id='datenKapitel07'>
Illustrationsdaten zu Kapitel 7, Statistische Analysen produktiver Kompetenzen
</h2><span id='topic+datenKapitel07'></span><span id='topic+datenKapitel07Ex'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 7, 
<em>Statistische Analysen produktiver Kompetenzen</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel07)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel07</code> ist eine Liste mit den fünf Elementen <code>prodRat</code>, 
<code>prodPRat</code>, <code>prodRatL</code>, <code>prodRatEx</code> und <code>prodRatLEx</code>, 
zu unterschiedlichen Darstellungen von Ratings zu Schreib-Performanzen für 
das Kapitel wie auch die darin gestellten Übungsaufgaben.
</p>


<ul>
<li> <p><strong>prodRat</strong>: Bewertung der Texte von 9736 Schülerinnen und Schülern 
zu einer von 3 &quot;long prompts&quot; durch einen (oder mehrere) der 41 Raters.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>aufgabe</code> </td><td style="text-align: left;"> 3 lange Schreibaufgaben.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rater</code> </td><td style="text-align: left;"> 41 Raters. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TA</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Task 
Achievement</em> anhand einer 8-stufigen Ratingskala.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>CC</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Coherence and
Cohesion</em> anhand einer 8-stufigen Ratingskala.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>GR</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Grammar</em> 
anhand einer 8-stufigen Ratingskala.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>VO</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Vocabulary</em>
anhand einer 8-stufigen Ratingskala.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	10755 obs. of  7 variables:
 $ idstud : int [1:10755] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ aufgabe: chr [1:10755] "E8W014" "E8W014" "E8W014" "E8W014" ...
 $ rater  : chr [1:10755] "R141" "R143" "R191" "R191" ...
 $ TA     : int [1:10755] 0 0 0 3 4 4 0 0 2 4 ...
 $ CC     : int [1:10755] 0 0 0 3 5 2 0 0 1 3 ...
 $ GR     : int [1:10755] 0 0 0 3 5 3 0 0 1 4 ...
 $ VO     : int [1:10755] 0 0 0 3 5 2 0 0 1 3 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>prodPRat</strong>: Bewertung der Schülertexte von 841 Schülerinnen und 
Schülern durch <em>Pseudoraters</em>.<br /> 
Die Mehrfachkodierungen der Schülertexte werden auf zwei zufällige Raters 
reduziert (siehe Unterabschnitt 7.1 für eine Erläuterung).
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>aufgabe</code> </td><td style="text-align: left;"> 3 lange Schreibaufgaben.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TA_R1...VO_R1</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf den Dimension 
<em>Task Achievement</em> (<code>TA_*</code>), <em>Coherence and Cohesion</em> 
(<code>CC_*</code>), <em>Grammar</em> (<code>GR_*</code>) und <em>Vocabulary</em> (<code>VO_*</code>) 
anhand einer 8-stufigen Ratingskala durch Pseudorater/in 1.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TA_R2...VO_R2</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf den Dimension 
<em>Task Achievement</em> (<code>TA_*</code>), <em>Coherence and Cohesion</em> 
(<code>CC_*</code>), <em>Grammar</em> (<code>GR_*</code>) und <em>Vocabulary</em> (<code>VO_*</code>) 
anhand einer 8-stufigen Ratingskala durch Pseudorater/in 2.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	841 obs. of  10 variables:
 $ idstud : int [1:841] 10010108 10010112 10030106 10030110 10030112 10050105 ...
 $ aufgabe: chr [1:841] "E8W006" "E8W006" "E8W010" "E8W006" ...
 $ TA_R1  : int [1:841] 0 1 5 2 4 6 2 4 0 5 ...
 $ CC_R1  : int [1:841] 0 1 5 2 6 5 2 6 0 3 ...
 $ GR_R1  : int [1:841] 0 0 5 1 5 5 2 6 0 1 ...
 $ VO_R1  : int [1:841] 0 2 4 1 5 5 3 6 0 2 ...
 $ TA_R2  : int [1:841] 0 0 3 4 4 6 5 2 0 5 ...
 $ CC_R2  : int [1:841] 0 0 2 2 4 5 2 3 0 2 ...
 $ GR_R2  : int [1:841] 0 0 2 1 5 5 3 4 0 2 ...
 $ VO_R2  : int [1:841] 0 0 3 2 5 6 4 3 0 2 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>prodRatL</strong>: Bewertung der Schülertexte im <em>Long Format</em>.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>aufgabe</code> </td><td style="text-align: left;"> 3 lange Schreibaufgaben.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rater</code> </td><td style="text-align: left;"> 41 Raters. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>item</code> </td><td style="text-align: left;"> Dimension. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>response</code> </td><td style="text-align: left;"> Rating zur Aufgabe in jeweiliger Dimension.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	43020 obs. of  5 variables:
 $ idstud  : int [1:43020] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ aufgabe : chr [1:43020] "E8W014" "E8W014" "E8W014" "E8W014" ...
 $ rater   : chr [1:43020] "R141" "R143" "R191" "R191" ...
 $ item    : Factor w/ 4 levels "TA","CC","GR",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ response: int [1:43020] 0 0 0 3 4 4 0 0 2 4 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>prodRatEx</strong>: Übungsdatensatz: Bewertung der Texte von 9748 
Schülerinnen und Schülern zu einer von 3 &quot;short prompts&quot; durch einen (oder 
mehrere) der 41 Raters.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>aufgabe</code> </td><td style="text-align: left;"> 3 Schreibaufgaben.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rater</code> </td><td style="text-align: left;"> 41 Raters. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TA</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Task 
Achievement</em> anhand einer 8-stufigen Ratingskala.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>CC</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Coherence and
Cohesion</em> anhand einer 8-stufigen Ratingskala.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>GR</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Grammar</em> 
anhand einer 8-stufigen Ratingskala.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>VO</code> </td><td style="text-align: left;"> Bewertung des Schülertexts auf der Dimension <em>Vocabulary</em>
anhand einer 8-stufigen Ratingskala.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	10643 obs. of  7 variables:
 $ idstud : int [1:10643] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ aufgabe: chr [1:10643] "E8W001" "E8W011" "E8W001" "E8W011" ...
 $ rater  : chr [1:10643] "R123" "R132" "R132" "R113" ...
 $ TA     : int [1:10643] 0 3 0 4 3 2 0 1 1 5 ...
 $ CC     : int [1:10643] 0 3 0 4 2 2 0 1 2 3 ...
 $ GR     : int [1:10643] 0 3 0 4 3 1 0 1 3 1 ...
 $ VO     : int [1:10643] 0 3 0 4 3 2 0 1 3 1 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>prodRatLEx</strong>: Übungsdatensatz: Bewertung der Schülertexte im 
<em>Long Format</em>.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>aufgabe</code> </td><td style="text-align: left;"> 3 kurze Schreibaufgaben.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rater</code> </td><td style="text-align: left;"> 41 Raters. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>item</code> </td><td style="text-align: left;"> Dimension. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>response</code> </td><td style="text-align: left;"> Rating zur Aufgabe in jeweiliger Dimension.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	42572 obs. of  5 variables:
 $ idstud  : int [1:42572] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ aufgabe : chr [1:42572] "E8W001" "E8W011" "E8W001" "E8W011" ...
 $ rater   : chr [1:42572] "R123" "R132" "R132" "R113" ...
 $ item    : Factor w/ 4 levels "TA","CC","GR",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ response: int [1:42572] 0 3 0 4 3 2 0 1 1 5 ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Freunberger, R., Robitzsch, A. &amp; Luger-Bazinger, C. (2016). Statistische 
Analysen produktiver Kompetenzen. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 225&ndash;258). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+207">Kapitel 7</a></code>.
</p>

<hr>
<h2 id='datenKapitel08'>
Illustrationsdaten zu Kapitel 8, Fehlende Daten und Plausible Values
</h2><span id='topic+datenKapitel08'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 8, 
<em>Fehlende Daten und Plausible Values</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel08)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel08</code> ist eine Liste mit den vier Elementen <code>data08H</code>, 
<code>data08I</code>, <code>data08J</code> und <code>data08K</code>, die Kontextinformationen mit 
fehlenden Daten zur Imputation sowie Instrumentendaten im Multiple-Matrix-Design
für die Plausible-Value-Ziehung enthalten.
</p>


<ul>
<li> <p><strong>data08H</strong>: Roh-Datensatz mit Leistungsschätzern und 
Kontextinformationen für 2507 Schüler/innen in 74 Schulen.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idschool</code> </td><td style="text-align: left;"> Schulenidentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers (vgl. Kapitel 
2, <em>Stichprobenziehung</em>, im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schule (vgl. Kapitel 
2 im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Stratum</code> </td><td style="text-align: left;"> Stratum der Schule. (<code>1:4</code> = Stratum 1 bis Stratum 4; 
für eine genauere Beschreibung der Strata, siehe Kapitel 
2 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>female</code> </td><td style="text-align: left;"> Geschlecht (<code>1</code> = weiblich, <code>0</code> = männlich).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>migrant</code> </td><td style="text-align: left;"> Migrationsstatus (<code>1</code> = mit Migrationshintergrund, 
<code>0</code> = ohne Migrationshintergrund).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>HISEI</code> </td><td style="text-align: left;"> Sozialstatus (vgl. Kapitel 10, <em>Reporting und Analysen</em>, 
im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>eltausb</code> </td><td style="text-align: left;"> Ausbildung der Eltern.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>buch</code> </td><td style="text-align: left;"> Anzahl der Bücher zu Hause.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SK</code> </td><td style="text-align: left;"> Fragebogenskala "Selbstkonzept".</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>LF</code> </td><td style="text-align: left;"> Fragebogenskala "Lernfreude".</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>NSchueler</code> </td><td style="text-align: left;"> Anzahl Schüler/innen in der 4. Schulstufe (vgl. Kapitel 
2 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>NKlassen</code> </td><td style="text-align: left;"> Anzahl Klassen in der 4. Schulstufe (vgl. Kapitel 
2 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SES_Schule</code> </td><td style="text-align: left;"> Auf Schulebene erfasster Sozialstatus (siehe Buchkapitel).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8WWLE</code> </td><td style="text-align: left;"> WLE der Schreibkompetenz (vgl. Kapitel 7, <em>Statistische 
Analysen produktiver Kompetenzen</em>, im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8LWLE</code> </td><td style="text-align: left;"> WLE der Hörverstehenskompetenz (vgl. Kapitel 6, 
<em>Skalierung und Linking</em>, im Band).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	2507 obs. of  17 variables:
 $ idstud    : int [1:2507] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ idschool  : int [1:2507] 1001 1001 1001 1001 1001 1001 1001 1001 1001 1001 ...
 $ wgtstud   : num [1:2507] 34.5 34.5 34.5 34.5 34.5 ...
 $ wgtschool : num [1:2507] 31.2 31.2 31.2 31.2 31.2 ...
 $ stratum   : int [1:2507] 1 1 1 1 1 1 1 1 1 1 ...
 $ female    : int [1:2507] 0 0 0 0 1 0 1 1 1 1 ...
 $ migrant   : int [1:2507] 0 0 0 0 0 NA 0 0 0 0 ...
 $ HISEI     : int [1:2507] 31 NA 25 27 27 NA NA 57 52 58 ...
 $ eltausb   : int [1:2507] 2 NA 2 2 2 NA 2 1 2 1 ...
 $ buch      : int [1:2507] 1 1 1 1 3 NA 4 2 5 4 ...
 $ SK        : num [1:2507] 2.25 2.25 3 3 2.5 NA 2.5 3.25 3.5 2.5 ...
 $ LF        : num [1:2507] 1.25 1.5 1 1 4 NA 2 3.5 3.75 2.25 ...
 $ NSchueler : int [1:2507] 69 69 69 69 69 69 69 69 69 69 ...
 $ NKlassen  : int [1:2507] 1 1 1 1 1 1 1 1 1 1 ...
 $ SES_Schule: num [1:2507] 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 ...
 $ E8WWLE    : num [1:2507] -3.311 -0.75 -3.311 0.769 1.006 ...
 $ E8LWLE    : num [1:2507] -1.175 -1.731 -1.311 0.284 0.336 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>data08I</strong>: Datensatz zur Illustration der Bedeutung einer 
geeigneten Behandlung fehlender Werte und von Messfehlern.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>index</code> </td><td style="text-align: left;"> Laufindex. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>x</code> </td><td style="text-align: left;"> Vollständig beobachteter Sozialstatus.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>theta</code> </td><td style="text-align: left;"> Kompetenzwert. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>WLE</code> </td><td style="text-align: left;"> WLE-Personenschätzer (vgl. Kapitel 6 im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SEWLE</code> </td><td style="text-align: left;"> Messfehler ("standard error") des WLE-Personenschätzers. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>X</code> </td><td style="text-align: left;"> Sozialstatus mit teilweise fehlenden Werten. 
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	1500 obs. of  6 variables:
 $ index: int [1:1500] 1 2 3 4 5 6 7 8 9 10 ...
 $ x    : num [1:1500] 0.69 0.15 -0.13 -0.02 0.02 0.02 -0.56 0.14 -0.06 -1.41 ...
 $ theta: num [1:1500] 2.08 -1.56 -0.65 -0.62 0.76 -1 1.12 0.08 0 -0.6 ...
 $ WLE  : num [1:1500] 1.22 -2.9 -2.02 0.03 0.8 0.93 0.28 -0.77 -0.31 -1.76 ...
 $ SEWLE: num [1:1500] 0.83 0.82 0.8 0.8 0.8 0.81 0.81 0.8 0.8 0.8 ...
 $ X    : num [1:1500] 0.69 0.15 NA NA 0.02 0.02 -0.56 NA -0.06 -1.41 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>data08J</strong>: Datensatz data08H nach Imputation der fehlenden Werte. 
Für die Beschreibung der Variablen, siehe <code>data08H</code>.
</p>
<p><code style="white-space: pre;">&#8288;'data.frame':	2507 obs. of  14 variables:
 $ idstud    : int [1:2507] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ wgtstud   : num [1:2507] 34.5 34.5 34.5 34.5 34.5 ...
 $ female    : int [1:2507] 0 0 0 0 1 0 1 1 1 1 ...
 $ migrant   : num [1:2507] 0 0 0 0 0 ...
 $ HISEI     : num [1:2507] 31 56.8 25 27 27 ...
 $ eltausb   : num [1:2507] 2 1.04 2 2 2 ...
 $ buch      : num [1:2507] 1 1 1 1 3 ...
 $ SK        : num [1:2507] 2.25 2.25 3 3 2.5 ...
 $ LF        : num [1:2507] 1.25 1.5 1 1 4 ...
 $ E8LWLE    : num [1:2507] -1.175 -1.731 -1.311 0.284 0.336 ...
 $ E8WWLE    : num [1:2507] -3.311 -0.75 -3.311 0.769 1.006 ...
 $ NSchueler : num [1:2507] 69 69 69 69 69 69 69 69 69 69 ...
 $ NKlassen  : int [1:2507] 1 1 1 1 1 1 1 1 1 1 ...
 $ SES_Schule: num [1:2507] 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 ...
&#8288;</code>

</p>

</li>
<li> <p><strong>data08K</strong>: Datensatz mit Itemantworten der Schüler/innen zu den 
Testinstrumenten zu Hörverstehen und Schreiben.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers (vgl. Kapitel 
2 im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8LS*</code> </td><td style="text-align: left;"> Itemantworten für Hörverstehen (vgl. Kapitel 6). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8W*</code> </td><td style="text-align: left;"> Itemantworten für Schreiben (vgl. Kapitel 7).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	2507 obs. of  99 variables:
 $ idstud   : int [1:2507] 10010101 10010102 10010103 10010105 10010106 10010107 ...
 $ wgtstud  : num [1:2507] 34.5 34.5 34.5 34.5 34.5 ...
 $ E8LS0158 : int [1:2507] NA NA NA NA NA NA 0 0 NA NA ...
 $ E8LS0165 : int [1:2507] 0 1 1 0 1 0 NA NA 1 0 ...
 $ E8LS0166 : int [1:2507] 0 0 1 1 0 1 NA NA 1 1 ...
 [...]
 $ E8W014CC : int [1:2507] 0 0 0 3 5 2 NA NA NA NA ...
 $ E8W014GR : int [1:2507] 0 0 0 3 5 3 NA NA NA NA ...
 $ E8W014VOC: int [1:2507] 0 0 0 3 5 2 NA NA NA NA ...
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Robitzsch, A., Pham, G. &amp; Yanagida, T. (2016). Fehlende Daten und Plausible 
Values.
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 259&ndash;293). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+208">Kapitel 8</a></code>.
</p>

<hr>
<h2 id='datenKapitel09'>
Illustrationsdaten zu Kapitel 9, Fairer Vergleich in der Rueckmeldung
</h2><span id='topic+datenKapitel09'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 9, 
<em>Fairer Vergleich in der Rückmeldung</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel09)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel09</code> ist ein singulärer vollständiger Datensatz. 
</p>
<ul>
<li> <p><strong>datenKapitel09</strong>: Datensatz mit sieben 
Kontextinformationen und 43 im Fairen Vergleich daraus abgeleiteten und 
berechneten Kenngrößen zu 244 Schulen (<code><a href="#topic+Kapitel+209">Kapitel 9</a></code>).
</p>


<table>
<tr>
 <td style="text-align: left;">
<code>idschool</code> </td><td style="text-align: left;"> Schulenidentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Stratum</code> </td><td style="text-align: left;"> Stratum der Schule. (<code>1:4</code> = Stratum 1 bis Stratum 4; 
für eine genauere Beschreibung der Strata, siehe Kapitel 
2, <em>Stichprobenziehung</em>, im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>groesse</code> </td><td style="text-align: left;"> Logarithmierte Schulgröße.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TWLE</code> </td><td style="text-align: left;"> Aggregierte Leistungsschätzer der Schüler in der Schule 
(abhängige Variable im Fairen Verlgeich).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>female</code> </td><td style="text-align: left;"> Anteil an Mädchen in der Schule.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mig</code> </td><td style="text-align: left;"> Anteil an Schülerinnen und Schülern mit Migrationshintergrund.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sozstat</code> </td><td style="text-align: left;"> Mittlerer sozioökonomischer Status (SES).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>zgroesse...zsozzsoz</code> </td><td style="text-align: left;"> z-Standardisierte Werte der entsprechenden 
Variablen und Interaktionen.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>expTWLE.*</code> </td><td style="text-align: left;"> Nach den jeweiligen Modellen erwartete (aggregierte) 
Leistungswerte der Schulen unter Berücksichtigung des Schulkontexts.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>*.eb*</code> </td><td style="text-align: left;"> Untere und obere Grenzen der Erwartungsbereiche (EB) der 
Schulen und Indikator der Lage der Schule zum Bereich (<code>-1</code> = unter dem EB,
<code>0</code> = im EB, <code>1</code> = über dem EB).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;'data.frame':	244 obs. of  50 variables:
 $ idschool       : int  1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 ...
 $ stratum        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ groesse        : num  2.48 2.64 2.71 2.83 2.89 ...
 $ TWLE           : num  449 447 495 482 514 ...
 $ female         : num  0.545 0.462 0.571 0.529 0.389 ...
 $ mig            : num  0.0168 0.0769 0 0 0 ...
 $ sozstat        : num  -1.034 -0.298 -0.413 -0.259 -0.197 ...
 $ zgroesse       : num  -2.86 -2.54 -2.4 -2.14 -2.02 ...
 [...]
 $ expTWLE.OLS1   : num  431 475 481 489 485 ...
 $ expTWLE.OLS2   : num  439 463 483 490 471 ...
 $ expTWLE.Lasso1 : num  430 472 475 484 482 ...
 $ expTWLE.Lasso2 : num  434 470 481 486 476 ...
 [...]
 $ expTWLE.np     : num  422 478 479 490 465 ...
 [...]
 $ OLS1.eblow31   : num  415 460 465 474 470 ...
 $ OLS1.ebupp31   : num  446 491 496 505 501 ...
 $ OLS1.pos.eb31  : int  1 -1 0 0 1 -1 -1 -1 0 0 ...
 [...]
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Pham, G., Robitzsch, A., George, A. C. &amp; Freunberger, R. (2016).
Fairer Vergleich in der Rückmeldung. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 295&ndash;332). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+209">Kapitel 9</a></code>.
</p>

<hr>
<h2 id='datenKapitel10'>
Illustrationsdaten zu Kapitel 10, Reporting und Analysen
</h2><span id='topic+datenKapitel10'></span>

<h3>Description</h3>

<p>Hier befindet sich die Dokumentation der in Kapitel 10, 
<em>Reporting und Analysen</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: 
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung, 
verwendeten Daten. Die Komponenten der Datensätze werden knapp erläutert und 
deren Strukturen dargestellt. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(datenKapitel10)
</code></pre>


<h3>Format</h3>

<p><code>datenKapitel10</code> ist eine Liste mit den vier Elementen, 
<code>dat</code>, <code>dat.roh</code>, <code>dat.schule</code> und <code>dat.schule.roh</code>.<br />
Die  Elemente <code>dat</code> und <code>dat.schule</code> enthalten jeweils zehn imputierte 
Datensätze (vgl. Kapitel 8, <em>Fehlende Daten und Plausible Values</em>, im 
Band). Zum Vergleich stehen denen die Rohdatensätze <code>dat.roh</code> bzw. 
<code>dat.schule.roh</code> gegenüber.
</p>


<ul>
<li> <p><strong>dat</strong> und <strong>dat.roh</strong>: Roh-Datensatz bzw. Liste mit zehn 
imputierten Datensätzen für 9885 Schülerinnen und Schüler.
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>idschool</code> </td><td style="text-align: left;"> Schulenidentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idstud</code> </td><td style="text-align: left;"> Schüleridentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>idclass</code> </td><td style="text-align: left;"> Klassenidentifikator.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wgtstud</code> </td><td style="text-align: left;"> Stichprobengewicht der Schülerin/des Schülers (vgl. Kapitel 
2, <em>Stichprobenziehung</em>, im Band). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>female</code> </td><td style="text-align: left;"> Geschlecht (<code>1</code> = weiblich, <code>0</code> = männlich).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>migrant</code> </td><td style="text-align: left;"> Migrationsstatus (<code>1</code> = mit Migrationshintergrund, 
<code>0</code> = ohne Migrationshintergrund).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>HISEI</code> </td><td style="text-align: left;"> Sozialstatus (vgl. Kapitel 10, <em>Reporting und Analysen</em>, 
im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>eltausb</code> </td><td style="text-align: left;"> Ausbildung der Eltern.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>buch</code> </td><td style="text-align: left;"> Anzahl der Bücher zu Hause.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SK</code> </td><td style="text-align: left;"> Fragebogenskala "Selbstkonzept".</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>LF</code> </td><td style="text-align: left;"> Fragebogenskala "Lernfreude".</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RTWLE</code> </td><td style="text-align: left;"> WLE der Lesekompetenz (vgl. Kapitel 1, 
<em>Testkonstruktion</em>, und Kapitel 6, <em>Skalierung und Linking</em>, 
im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RPV</code> </td><td style="text-align: left;"> Plausible Values für die Leistung in Englisch Lesen (vgl. 
Kapitel 8 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>jkzone</code> </td><td style="text-align: left;"> Jackknife-Zone im Jackknife-Repeated-Replication-Design (vgl. 
Kapitel 2).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>jkrep</code> </td><td style="text-align: left;"> Jackknife-Replikationsfaktor im 
Jackknife-Repeated-Replication-Design (vgl. Kapitel 2).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>w_fstr*</code> </td><td style="text-align: left;"> Jackknife-Replikationsgewichte (vgl. Kapitel 2).
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;List of 10
 $ :'data.frame':	9885 obs. of  151 variables:
  ..$ idschool    : int [1:9885] 1001 1001 1001 1001 1001 1001 1001 ...
  ..$ idstud      : int [1:9885] 10010101 10010102 10010103 10010105 ...
  ..$ idclass     : int [1:9885] 100101 100101 100101 100101 100101 ...
  ..$ wgtstud     : num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
  ..$ female      : int [1:9885] 0 0 0 0 1 0 1 1 1 1 ...
  ..$ migrant     : int [1:9885] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ HISEI       : int [1:9885] 31 28 25 27 27 76 23 57 52 58 ...
  ..$ eltausb     : int [1:9885] 2 1 2 2 2 2 2 1 2 1 ...
  ..$ buch        : int [1:9885] 1 1 1 1 3 3 4 2 5 4 ...
  ..$ SK          : num [1:9885] 2.25 2.25 3 3 2.5 3.25 2.5 3.25 3.5 2.5 ...
  ..$ LF          : num [1:9885] 1.25 1.5 1 1 4 3 2 3.5 3.75 2.25 ...
  ..$ E8RTWLE     : num [1:9885] 350 438 383 613 526 ...
  ..$ E8RPV       : num [1:9885] 390 473 380 599 509 ...
  ..$ jkzone      : int [1:9885] 37 37 37 37 37 37 37 37 37 37 ...
  ..$ jkrep       : int [1:9885] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ w_fstr1     : num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
  ..$ w_fstr2     : num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
  ..$ w_fstr3     : num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
    [...]
  ..$ w_fstr83    : num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
  ..$ w_fstr84    : num [1:9885] 34.5 34.5 34.5 34.5 34.5 ...
 $ :'data.frame':	9885 obs. of  151 variables:
 [...]
&#8288;</code>

</p>

</li>
<li> <p><strong>dat.schule</strong> und <strong>dat.schule.roh</strong>: Roh-Datensatz bzw. Liste 
mit zehn imputierten Datensätzen als Liste für 244 Schulen. Es handelt sich 
hierbei &ndash; wie bei allen Datensätzen im Band &ndash; um fiktive (höchstens 
partiell-synthetische) Daten!
</p>


<table>
<tr>
 <td style="text-align: left;">
<code>idschool</code> </td><td style="text-align: left;"> Schulenidentifikator. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Schultyp</code> </td><td style="text-align: left;"> Schultyp (<code>AHS</code> = allgemeinbildende höhere Schule, bzw. 
<code>APS</code> = allgemeinbildende Pflichtschule).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Strata</code> </td><td style="text-align: left;"> Stratum der Schule. (<code>1:4</code> = Stratum 1 bis Stratum 4, 
für eine genauere Beschreibung der Strata; siehe Kapitel 
2 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Strata.label</code> </td><td style="text-align: left;"> Bezeichnung des Stratums.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>NSchueler</code> </td><td style="text-align: left;"> Anzahl Schüler/innen in der 4. Schulstufe (vgl. Kapitel 
2 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>NKlassen</code> </td><td style="text-align: left;"> Anzahl Klassen in der 4. Schulstufe (vgl. Kapitel 
2 im Band).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>gemgroesse</code> </td><td style="text-align: left;"> Gemeindegröße. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SCFRA04x02</code> </td><td style="text-align: left;"> Fragebogenvariable aus Schulleiterfragebogen zur 
Schulgröße (vgl. https://www.bifie.at/node/2119).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>SCFO05a*</code> </td><td style="text-align: left;"> Fragebogenvariable aus Schulleiterfragebogen zur 
"Schwerpunktschule für ..." (<code>*a01</code> = Informatik, <code>*a02</code> = 
Mathematik, <code>*a03</code> = Musik, <code>*a04</code> = Naturwissenschaften, 
<code>*a05</code> = Sport, <code>*a06</code> = Sprachen, <code>*a07</code> = Technik, 
<code>*a081</code> = Anderes; vgl. https://www.bifie.at/node/2119). Es handelt sich 
hierbei um rein fiktive Daten!</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>HISEI</code> </td><td style="text-align: left;"> Auf Schulenebene aggregierte HISEI.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>E8RPV</code> </td><td style="text-align: left;"> Auf Schulenebene aggregierte Plausible Values für die Leistung 
in Englisch Lesen.
</td>
</tr>

</table>


<p><code style="white-space: pre;">&#8288;List of 10
 $ :'data.frame':	244 obs. of  18 variables:
  ..$ idschool    : int [1:244] 1001 1002 1003 1004 1005 1006 1007 1010 ...
  ..$ Schultyp    : chr [1:244] "HS" "HS" "HS" "HS" ...
  ..$ Strata      : int [1:244] 1 1 1 1 1 1 1 1 1 1 ...
  ..$ Strata.label: chr [1:244] "HS/Land" "HS/Land" "HS/Land" "HS/Land" ...
  ..$ NSchueler   : int [1:244] 12 14 15 17 18 19 20 20 21 22 ...
  ..$ NKlassen    : int [1:244] 1 1 1 1 2 1 2 1 2 2 ...
  ..$ gemgroesse  : int [1:244] 5 4 4 5 3 4 5 4 4 5 ...
  ..$ SCFRA04x02  : int [1:244] 45 63 47 81 95 80 66 86 104 126 ...
  ..$ SCFO05a01   : int [1:244] 1 0 0 0 0 0 0 1 1 0 ...
  ..$ SCFO05a02   : int [1:244] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ SCFO05a03   : int [1:244] 1 1 0 0 0 0 0 0 0 0 ...
  ..$ SCFO05a04   : int [1:244] 1 0 0 0 0 1 0 0 0 0 ...
  ..$ SCFO05a05   : int [1:244] 0 0 0 0 1 0 1 0 0 0 ...
  ..$ SCFO05a06   : int [1:244] 0 1 1 0 0 1 0 0 1 0 ...
  ..$ SCFO05a07   : int [1:244] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ SCFO05a081  : int [1:244] 0 0 1 0 0 1 1 0 0 0 ...
  ..$ HISEI       : num [1:244] 33.5 48.6 41.1 43.5 46.9 ...
  ..$ E8RPV       : num [1:244] 471 463 513 494 525 ...
 [...]
&#8288;</code>

</p>
</li></ul>



<h3>References</h3>

<p>Bruneforth, M., Oberwimmer, K. &amp; Robitzsch, A. (2016). Reporting und Analysen. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 333&ndash;362). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Für die Verwendung der Daten, siehe <code><a href="#topic+Kapitel+2010">Kapitel 10</a></code>.
</p>

<hr>
<h2 id='Kapitel+20+200'>Kapitel 0: Konzeption der Ueberpruefung der Bildungsstandards in 
Oesterreich</h2><span id='topic+Kapitel+200'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 0, <em>Konzeption der Überprüfung der 
Bildungsstandards in Österreich</em>, im Herausgeberband Large-Scale Assessment mit 
<span class="rlang"><b>R</b></span>: Methodische Grundlagen der österreichischen
Bildungsstandardüberprüfung. 
Hier werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur Unterstützung für 
Leser/innen kommentiert, dokumentiert und gegebenenfalls erweitert.
</p>


<h3>Details</h3>

<p>Dieses Kapitel enthält keine Beispiele mit <span class="rlang"><b>R</b></span>.
</p>


<h3>Author(s)</h3>

<p>Claudia Schreiner und Simone Breit
</p>


<h3>References</h3>

<p>Schreiner, C. &amp; Breit, S. (2016). Konzeption der Überprüfung 
der Bildungsstandards in Österreich.   
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 1&ndash;20). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Zu <code><a href="#topic+Kapitel+201">Kapitel 1</a></code>, Testkonstruktion.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.

</p>

<hr>
<h2 id='Kapitel+20+201'>Kapitel 1: Testkonstruktion</h2><span id='topic+Kapitel+201'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 1, <em>Testkonstruktion</em>, im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische Grundlagen der 
österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Author(s)</h3>

<p>Ursula Itzlinger-Bruneforth, Jörg-Tobias Kuhn, und Thomas Kiefer
</p>


<h3>References</h3>

<p>Itzlinger-Bruneforth, U., Kuhn, J.-T. &amp; Kiefer, T. (2016). Testkonstruktion. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 21&ndash;50). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel01">datenKapitel01</a></code>, den im Kapitel verwendeten Daten.<br />

Zurück zu <code><a href="#topic+Kapitel+200">Kapitel 0</a></code>, Konzeption.<br />
Zu <code><a href="#topic+Kapitel+202">Kapitel 2</a></code>, Stichprobenziehung.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.


</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(TAM)
library(miceadds)
library(irr)
library(gtools)
library(car)

set.seed(1337)
data(datenKapitel01)
pilotScored &lt;- datenKapitel01$pilotScored
pilotItems &lt;- datenKapitel01$pilotItems
pilotRoh &lt;- datenKapitel01$pilotRoh
pilotMM &lt;- datenKapitel01$pilotMM

## -------------------------------------------------------------
## Abschnitt 1.5.5: Aspekte empirischer Güteüberprüfung 
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 1: Vorbereitung
#

# Rekodierter Datensatz pilotScored
dat &lt;- pilotScored
items &lt;- grep("E8R", colnames(dat), value = TRUE)
dat[items] &lt;- recode(dat[items], "9=0;8=0")
# Itembank im Datensatz pilotItems
dat.ib &lt;- pilotItems
items.dich &lt;- dat.ib$item[dat.ib$maxScore == 1]

# Berechne erreichbare Punkte je TH
# aus Maximalscore je Item in Itembank
ind &lt;- match(items, dat.ib$item)
testlets.ind &lt;- ! items %in% items.dich
ind[testlets.ind] &lt;- match(items[testlets.ind], dat.ib$testlet)
maxscores &lt;- dat.ib$maxScore[ind]
max.form &lt;- 1 * (!is.na(dat[, items])) %*% maxscores

# Erzielter Score ist der Summenscore dividiert durch 
# Maximalscore
sumscore &lt;- rowSums(dat[, items], na.rm = TRUE)
relscore &lt;- sumscore/max.form
mean(relscore)

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 2: Omitted Response
#

library(TAM)
# Bestimme absolute und relative Häufigkeit der Kategorie 9 (OR)
ctt.omit &lt;- tam.ctt2(pilotScored[, items])
ctt.omit &lt;- ctt.omit[ctt.omit$Categ == 9, ]
# Übersicht der am häufigsten ausgelassenen Items
tail(ctt.omit[order(ctt.omit$RelFreq), -(1:4)])

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 3: Not Reached
#

not.reached &lt;- rep(0, length(items))
names(not.reached) &lt;- items

# Führe die Bestimmung in jedem Testheft durch
forms &lt;- sort(unique(dat$form))
for(ff in forms){ 
  # (1) Extrahiere Itempositionen
  order.ff &lt;- order(dat.ib[, ff], na.last = NA, 
                    decreasing = TRUE)
  items.ff &lt;- dat.ib$item[order.ff]
  testlets.ff &lt;- dat.ib$testlet[order.ff]
  
  # (2) Sortiere Items und Testlets nach den Positionen
  testlets.ind &lt;- ! items.ff %in% items.dich
  items.ff[testlets.ind] &lt;- testlets.ff[testlets.ind]
  items.order.ff &lt;- unique(items.ff)
  
  # (3) Bringe Testhefte in Reihenfolge und
  #     zähle von hinten aufeinanderfolgende Missings
  ind.ff &lt;- pilotScored$form == ff
  dat.order.ff &lt;- pilotScored[ind.ff, items.order.ff]  
  dat.order.ff &lt;- dat.order.ff == 9
  dat.order.ff &lt;- apply(dat.order.ff, 1, cumsum)
  
  # (4) Vergleiche letzteres mit theoretisch möglichem 
  #     vollständigen NR
  vergleich &lt;- cumsum(rep(1, length(items.order.ff)))
  dat.order.ff[dat.order.ff != vergleich] &lt;- 0
  
  # (5) Erstes NR kann auch OR sein
  erstes.NR &lt;- apply(dat.order.ff, 2, which.max)
  ind &lt;- cbind(erstes.NR, 1:ncol(dat.order.ff))
  dat.order.ff[ind] &lt;- 0
  
  # (6) Zähle, wie oft für ein Item NR gilt
  not.reached.ff &lt;- rowSums(dat.order.ff &gt; 0)
  not.reached[items.order.ff] &lt;- not.reached.ff[items.order.ff] + 
    not.reached[items.order.ff]
}

tail(not.reached[order(not.reached)])

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 4: Itemschwierigkeit
#

# Statistik der relativen Lösungshäufigkeiten
p &lt;- colMeans(dat[, items], na.rm = TRUE) / maxscores
summary(p)

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 5: Trennschärfe
#

discrim &lt;- sapply(items, FUN = function(ii){ 
  if(var(dat[, ii], na.rm = TRUE) == 0) 0 else
    cor(dat[, ii], relscore, use = "pairwise.complete.obs") 
}) 

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 6: Eindeutigkeit der Lösung
#

dat.roh &lt;- pilotRoh
items &lt;- grep("E8R", colnames(dat.roh), value = TRUE)
vars &lt;- c("item", "Categ", "AbsFreq", "RelFreq", "rpb.WLE")

# Wähle nur geschlossene Items (d. h., nicht Open gap-fill)
items.ogf &lt;- dat.ib$item[dat.ib$format == "Open gap-fill"]
items &lt;- setdiff(items, items.ogf)

# Bestimme absolute und relative Häufigkeit der Antwortoptionen 
# und jeweilige punktbiseriale Korrelationen mit dem Gesamtscore
ctt.roh &lt;- tam.ctt2(dat.roh[, items], wlescore = relscore)

# Indikator der richtigen Antwort
match.item &lt;- match(ctt.roh$item, dat.ib$item)
rohscore &lt;- 1 * (ctt.roh$Categ == dat.ib$key[match.item])

# Klassifikation der Antwortoptionen 
ist.antwort.option &lt;- (!ctt.roh$Categ %in% c(8,9))
ist.distraktor &lt;- rohscore == 0 &amp; ist.antwort.option
ist.pos.korr &lt;- ctt.roh$rpb.WLE &gt; 0.05
ist.bearb &lt;- ctt.roh$AbsFreq &gt;= 10

# Ausgabe
ctt.roh[ist.distraktor &amp; ist.pos.korr &amp; ist.bearb, vars]

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 7: Plausible Distraktoren
#

# Ausgabe
head(ctt.roh[ist.distraktor &amp; ctt.roh$RelFreq &lt; 0.05, vars],4)

# -------------------------------------------------------------
# Abschnitt 1.5.5, Listing 8: Kodierbarkeit
#

library(irr)
dat.mm &lt;- pilotMM

# Bestimme Modus der Berechnung: bei 3 Kodierern
# gibt es 3 paarweise Vergleiche
vars &lt;- grep("Coder", colnames(dat.mm))
n.vergleiche &lt;- choose(length(vars), 2)
ind.vergleiche &lt;- upper.tri(diag(length(vars)))

# Berechne Statistik für jedes Item
coder &lt;- NULL
for(ii in unique(dat.mm$item)){
  dat.mm.ii &lt;- dat.mm[dat.mm$item == ii, vars]
  
  # Relative Häufigkeit der paarweisen Übereinstimmung
  agreed &lt;- apply(dat.mm.ii, 1, function(dd){
    sum(outer(dd, dd, "==")[ind.vergleiche]) / n.vergleiche
  })
  
  # Fleiss Kappa
  kappa &lt;- kappam.fleiss(dat.mm.ii)$value
  
  # Ausgabe
  coderII &lt;- data.frame("item" = ii,
                        "p_agreed" = mean(agreed),
                        "kappa" = round(kappa, 4))
  coder &lt;- rbind(coder, coderII)
}


## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+202'>Kapitel 2: Stichprobenziehung</h2><span id='topic+Kapitel+202'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 2, <em>Stichprobenziehung</em>, im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische Grundlagen der 
österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Details</h3>



<h4>Vorbereitungen</h4>

<p>Zunächst werden die Datensätze <code>schule</code> mit den 1.327 Schulen der 
Population und <code>schueler</code> mit den 51.644 Schüler/innen dieser Schulen 
geladen.
Durch das Setzen eines festen Startwerts für den Zufallszahlengenerator 
(<code>set.seed(20150506)</code>) wird erreicht, dass wiederholte Programmdurchläufe 
immer wieder zur selben Stichprobe führen.
</p>
 


<h4>Abschnitt 4.1: Stratifizierung - Schichtung einer Stichprobe</h4>

<p>Die für die explizite Stratifizierung notwendige Information der Anzahl der 
Schüler/innen pro Stratum wird durch Aggregierung (Summe) aus dem Schuldatensatz 
in das Objekt <code>strata</code> extrahiert. Die entsprechende Spalte wird aus 
Gründen der Eindeutigkeit noch in <code>NSchuelerStratum</code> umbenannt.
</p>
<p><code style="white-space: pre;">&#8288;strata &lt;- aggregate(schule[,"NSchueler", drop = FALSE],
                  by=schule[,"stratum", drop = FALSE], sum)
colnames(strata)[2] &lt;- "NSchuelerStratum" #Ergänzung zum Buch
&#8288;</code>

</p>



<h4>Abschnitt 4.2: Schulenziehung, Listing 1</h4>

<p>Im Schuldatensatz wird eine Dummyvariable <code>Klassenziehung</code> angelegt, die 
indiziert, in welchen Schulen mehr als drei Klassen sind, aus denen in Folge 
gezogen werden muss.
</p>
<p><code style="white-space: pre;">&#8288;schule$Klassenziehung &lt;- 0
schule[which(schule$NKlassen&gt;3), "Klassenziehung"] &lt;- 1
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 2</h4>

<p>Dann wird der unter Beachtung der Klassenziehung erwartete Beitrag der Schulen 
(d. h. die Anzahl ihrer Schülerinnen bzw. Schüler) zur Stichprobe in der Spalte 
<code>NSchueler.erw</code> errechnet.
</p>
<p><code style="white-space: pre;">&#8288;schule$NSchueler.erw &lt;- schule$NSchueler
ind &lt;- which(schule$Klassenziehung == 1)
schule[ind, "NSchueler.erw"] &lt;- 
 schule[ind, "NSchueler"]/schule[ind, "NKlassen"]*3
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 3</h4>

<p>Berechnet man aus der erwarteten Anzahl von Lernenden pro Schule ihren relativen 
Anteil (Spalte <code>AnteilSchueler</code>) an der Gesamtschülerzahl im Stratum, so 
kann per Mittelwertbildung die mittlere Anzahl (Spalte 
<code>NSchueler/Schule.erw</code>) von Lernenden einer Schule pro Stratum bestimmt 
werden. 
Die mittlere Anzahl der Schulen im Stratum wird zusätzlich mit den einfachen 
Ziehungsgewichten der Schulen gewichtet, da große Schulen mit höherer 
Wahrscheinlichkeit für die Stichprobe gezogen werden.
</p>
<p><code style="white-space: pre;">&#8288;temp &lt;- merge(schule[, c("SKZ","stratum","NSchueler")], 
             strata[, c("stratum","NSchuelerStratum")])
schule$AnteilSchueler &lt;- 
 temp$NSchueler/temp$NSchuelerStratum
strata$"NSchueler/Schule.erw" &lt;- 
 rowsum(apply(schule, 1, function(x)
   x["NSchueler.erw"]*x["AnteilSchueler"]), schule$stratum)
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 4</h4>

<p>Schließlich erfolgt die Berechnung der Anzahl an Schulen 
(<code>Schulen.zu.ziehen</code>), die in jedem Stratum gezogen werden müssen, um einen 
Stichprobenumfang von 2500 Schülerinnen bzw. Schülern in etwa einzuhalten.
</p>
<p><code style="white-space: pre;">&#8288;strata$Schulen.zu.ziehen &lt;- 
  round(2500/strata[,"NSchueler/Schule.erw"])
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 5</h4>

<p>Die Schulenliste wird vorab nach expliziten und impliziten Strata sortiert.
</p>
<p><code style="white-space: pre;">&#8288;schule &lt;- schule[order(schule$stratum, schule$NSchueler),]
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 6</h4>

<p>Das Sampling-Intervall pro Stratum wird bestimmt (<code>Samp.Int</code>).
</p>
<p><code style="white-space: pre;">&#8288;strata$Samp.Int &lt;- 
  strata$NSchuelerStratum/strata$Schulen.zu.ziehen
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 7</h4>

<p>Ein zufälliger Startwert aus dem Bereich 1 bis <code>Samp.Int</code> wird für jedes 
Stratum bestimmt (<code>Startwert</code>). Zur Festlegung eines festen Ausgangswertes 
des Zufallszahlengenerators siehe oben unter &quot;Vorbereitungen&quot;.
</p>
<p><code style="white-space: pre;">&#8288;set.seed(20150506)
strata$Startwert &lt;- 
  sapply(ceiling(strata$Samp.Int), sample, size = 1)
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 8</h4>

<p>Die Listenpositionen der Lernenden, deren Schulen gezogen werden, werden vom 
Startwert ausgehend im Sampling-Intervall (pro Stratum) ermittelt. 
Die Positionen werden im Objekt <code>tickets</code> abgelegt.
</p>
<p><code style="white-space: pre;">&#8288;tickets &lt;- sapply(1:4, function(x)
  trunc(0:(strata[strata$stratum==x,"Schulen.zu.ziehen"]-1)
    * strata[strata$stratum==x, "Samp.Int"] +
    strata$Startwert[x]))
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 9</h4>

<p>Um die Auswahl der Schulen (entsprechend den Tickets der Lernenden) direkt auf 
der Schulliste durchführen zu können wird in <code>NSchuelerKum</code> die kumulierte 
Anzahl an Schülerinnen und Schülern nach Sortierung (siehe oben Abschnit 4.2, 
Listing 5) berechnet.
</p>
<p><code style="white-space: pre;">&#8288;schule$NSchuelerKum &lt;- 
  unlist(sapply(1:4, function(x)
    cumsum(schule[schule$stratum==x, "NSchueler"])))
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 10</h4>

<p>Durch die Dummy-Variable <code>SInSamp</code> werden nun jene Schulen als zugehörig 
zur Stichprobe markiert, von denen wenigstens eine Schülerin oder ein Schüler 
in Listing 8 dieses Abschnitts ein Ticket erhalten hat.
</p>
<p><code style="white-space: pre;">&#8288;schule$SInSamp &lt;- 0 
for(s in 1:4) {
  NSchuelerKumStrat &lt;- 
    schule[schule$stratum==s, "NSchuelerKum"]
  inds &lt;- sapply(tickets[[s]], function(x)
    setdiff(which(NSchuelerKumStrat &lt;= x),
            which(NSchuelerKumStrat[-1] &lt;= x)))
  schule[schule$stratum==s, "SInSamp"][inds] &lt;- 1 }
&#8288;</code>

</p>
 


<h4>Abschnitt 4.2: Schulenziehung, Listing 11</h4>

<p>Die Ziehungswahrscheinlichkeiten der Schulen (<code>Z.Wsk.Schule</code>) werden für 
die später folgende Gewichtung berechnet.
</p>
<p><code style="white-space: pre;">&#8288;temp &lt;- merge(schule[, c("stratum", "AnteilSchueler")],
              strata[, c("stratum", "Schulen.zu.ziehen")])
schule$Z.Wsk.Schule &lt;- 
  temp$AnteilSchueler*temp$Schulen.zu.ziehen
&#8288;</code>

</p>
 


<h4>Abschnitt 4.3: Klassenziehung, Listing 1</h4>

<p>Im Objekt <code>schukla</code> werden zunächst notwendige Informationen für die 
Klassenziehung zusammengetragen. Die Dummy-Variable <code>KlInSamp</code> darin 
indiziert schließlich gezogene Klassen (aus bereits gezogenen Schulen), wobei 
aus Schulen mit drei oder weniger Klassen alle Klassen gezogen werden. 
Daher wird der Aufruf von <code>sample.int</code> mit <code>min(3, length(temp))</code> 
parametrisiert.
</p>
<p><code style="white-space: pre;">&#8288;schukla &lt;- unique(merge(
  schule[, c("SKZ","NKlassen", "Klassenziehung", 
    "Z.Wsk.Schule", "SInSamp")],
    schueler[, c("SKZ", "idclass")], by="SKZ"))
schukla$KlInSamp &lt;- 0
for(skz in unique(schukla[schukla$SInSamp==1,"SKZ"])) {
  temp &lt;- schukla[schukla$SKZ==skz, "idclass"]
  schukla[schukla$idclass %in% temp[sample.int
    (min(3, length(temp)))], "KlInSamp"] &lt;- 1 }
&#8288;</code>

</p>
 


<h4>Abschnitt 4.3: Klassenziehung, Listing 2</h4>

<p>Die Ziehungswahrscheinlichkeit einer Klasse (<code>Z.Wsk.Klasse</code>) kann 
entsprechend der Dummy-Variable <code>Klassenziehung</code> (siehe Abschnitt 4.2, 
Listing 1) berechnet werden. Man beachte, dass entweder der erste oder der 
zweite Term der Addition Null ergeben muss, sodass die Fallunterscheidung direkt 
ausgedrückt werden kann.
</p>
<p><code style="white-space: pre;">&#8288;schukla$Z.Wsk.Klasse &lt;- ((1 - schukla$Klassenziehung) * 1 +
    schukla$Klassenziehung * 3 / schukla$NKlassen) 
&#8288;</code>

</p>
 


<h4>Abschnitt 4.4: Gewichtung, Listing 1</h4>

<p>Nachdem das Objekt <code>schueler</code> um die Informationen zur Klassenziehung sowie
den Ziehungswahrscheinlichkeiten von Schule und Klasse ergänzt wird, kann die 
Ziehungswahrscheinlichkeit einer Schülerin bzw. eines Schülers 
(<code>Z.Wsk.Schueler</code>) berechnet werden.
</p>
<p><code style="white-space: pre;">&#8288;schueler &lt;- merge(schueler, schukla[, c("idclass", "KlInSamp", "Z.Wsk.Schule", 
                                        "Z.Wsk.Klasse")],
                  by="idclass", all.x=T)
schueler$Z.Wsk.Schueler &lt;- 
  schueler$Z.Wsk.Schule * schueler$Z.Wsk.Klasse
&#8288;</code>

</p>
 


<h4>Abschnitt 4.4: Gewichtung, Listing 2</h4>

<p>Nach Reduktion des Objekts <code>schueler</code> auf die gezogenen Lernenden, werden 
in <code>temp</code> die nonresponse-Raten (Variable <code>x</code>) bestimmt.
</p>
<p><code style="white-space: pre;">&#8288;schueler &lt;- schueler[schueler$KlInSamp==1,]
temp &lt;- merge(schueler[, c("idclass", 
                           "Z.Wsk.Schueler")],
              aggregate(schueler$teilnahme, 
                        by=list(schueler$idclass),
                        function(x) sum(x)/length(x)), 
              by.x="idclass", by.y="Group.1")
&#8288;</code>

</p>
 


<h4>Abschnitt 4.4: Gewichtung, Listing 3</h4>

<p>Mittels der Ziehungswahrscheinlichkeiten der Schülerinnen und Schüler sowie der 
nonresponse-Raten (siehe vorangegangenes Listing) werden die (nicht normierten) 
Schülergewichte (<code>studwgt</code>) bestimmt.
</p>
<p><code style="white-space: pre;">&#8288;schueler$studwgt &lt;- 1/temp$x/temp$Z.Wsk.Schueler
&#8288;</code>

</p>
 


<h4>Abschnitt 4.4: Gewichtung, Listing 4</h4>

<p>Schließlich werden die Schülergewichte in Bezug auf die Anzahl an Schülerinnen 
und Schülern im jeweiligen Stratum normiert (<code>NormStudwgt</code>), sodass sie in 
Summe dieser Anzahl entsprechen.
</p>
<p><code style="white-space: pre;">&#8288;Normierung &lt;- strata$NSchuelerStratum / 
  rowsum(schueler$studwgt * schueler$teilnahme,
         group = schueler$Stratum)
schueler$NormStudwgt &lt;- 
  schueler$studwgt * Normierung[schueler$Stratum]
&#8288;</code>

</p>
 


<h4>Abschnitt 5.3: Anwendung per Jackknife-Repeated-Replication, 
Listing 1</h4>

<p>Die im Folgenden genutzte Hilfsfunktion <code>zones.within.stratum</code> erzeugt ab einem 
Offset einen Vektor mit jeweils doppelt vorkommenden IDs zur Bildung der 
Jackknife-Zonen.
Nachdem die Schulliste zunächst auf die gezogenen Schulen und nach expliziten 
und impliziten Strata* sortiert wurde, werden die Strata in Pseudo-Strata mit 
zwei (oder bei ungerader Anzahl drei) Schulen unterteilt. 
Dies führt zur Variable <code>jkzone</code>.
Basierend auf <code>jkzone</code> wird für jeweils eine der Schulen im Pseudo-Stratum 
der Indikator <code>jkrep</code> auf Null gesetzt, um diese in der jeweiligen 
Replikation von der Berechnung auszuschließen. 
Ergänzend zum Buch wird hier eine Fallunterscheidung getroffen, ob in einem 
Pseudo-Stratum zwei oder drei Schulen sind (s.o): Bei drei Schulen wird zufällig 
ausgewählt, ob bei ein oder zwei Schulen <code>jkrep=0</code> gesetzt wird.
</p>
<p>* Die Sortierung nach dem impliziten Strata Schulgröße erfolgt hier absteigend, 
nachzulesen im Buch-Kapitel.
</p>
<p><code style="white-space: pre;">&#8288;### Ergänzung zum Buch: Hilfsfunktion zones.within.stratum
zones.within.stratum &lt;- function(offset,n.str) {
  maxzone &lt;- offset-1+floor(n.str/2)
  zones &lt;- sort(rep(offset:maxzone,2))
  if (n.str %% 2 == 1) zones &lt;- c(zones,maxzone)
  return(zones) }
### Ende der Ergänzung

# Sortieren der Schulliste (explizite und implizite Strata)
schule &lt;- schule[schule$SInSamp==1,]
schule &lt;- schule[order(schule$stratum,-schule$NSchueler),]

# Unterteilung in Pseudostrata 
cnt.strata &lt;- length(unique(schule$stratum))
offset &lt;- 1
jkzones.vect &lt;- integer()
for (i in 1:cnt.strata) {
  n.str &lt;- table(schule$stratum)[i]
  jkzones.vect &lt;- 
    c(jkzones.vect,zones.within.stratum(offset,n.str))
  offset &lt;- max(jkzones.vect)+1 }
schule$jkzone &lt;- jkzones.vect

# Zufällige Auswahl von Schulen mit Gewicht 0
schule$jkrep &lt;- 1
cnt.zones &lt;- max(schule$jkzone)
jkrep.rows.null &lt;- integer()
for (i in 1:cnt.zones) {
  rows.zone &lt;- which(schule$jkzone==i)
### Ergänzung zum Buch: Fallunterscheidung je nach Anzahl Schulen in der Zone
  if (length(rows.zone)==2) jkrep.rows.null &lt;- 
    c(jkrep.rows.null,sample(rows.zone,size=1))
  else {
      num.null &lt;- sample(1:2,size=1)
      jkrep.rows.null &lt;- 
        c(jkrep.rows.null,sample(rows.zone,size=num.null)) 
    } }
schule[jkrep.rows.null,]$jkrep &lt;- 0
&#8288;</code>

</p>
 


<h4>Abschnitt 5.3: Anwendung per Jackknife-Repeated-Replication, 
Listing 2</h4>

<p>Die Anwendung von Jackknife-Repeated-Replication zur Abschätzung der 
Stichprobenvarianz wird im folgenden am Schülerdatensatz demonstriert, weswegen 
<code>jkzone</code> und <code>jkrep</code> zunächst auf diese Aggregatsebene übertragen 
werden.
In einer Schleife werden replicate weights mittels <code>jkzone</code> und 
<code>jkrep</code> generiert. 
Diese beziehen sich auf das normierte Schülergewicht <code>NormStudwgt</code>.
Man beachte: Es gilt entweder <code>in.zone==0</code> oder <code>(in.zone-1)==0</code>, 
sodass Formel 5 aus dem Buch-Kapitel direkt in einer Addition ausgedrückt werden 
kann. 
Es entstehen so viele replicate weights (<code>w_fstr1</code> usw.) wie 
Jackknife-Zonen existieren.
</p>
<p><code style="white-space: pre;">&#8288;# Übertragung auf Schülerebene
schueler &lt;- 
  merge(schueler,schule[,c("SKZ","jkzone","jkrep")],all.x=TRUE)
# Schleife zur Generierung von Replicate Weights
for (i in 1:cnt.zones) {
  in.zone &lt;- as.numeric(schueler$jkzone==i)
  schueler[paste0("w_fstr",i)] &lt;-   # vgl. Formel 5
    in.zone * schueler$jkrep * schueler$NormStudwgt * 2 +
    (1-in.zone) * schueler$NormStudwgt }
&#8288;</code>

</p>
 


<h4>Abschnitt 5.3: Anwendung per Jackknife-Repeated-Replication, 
Listing 3</h4>

<p>Als einfaches Beispiel wird der Anteil Mädchen (<code>perc.female</code>) in der 
Population aus der Stichprobe heraus geschätzt. Die Schätzung selbst erfolgt als 
Punktschätzung über das normierte Schülergewicht.
Zur Bestimmung der Stichprobenvarianz <code>var.jrr</code> wird der Anteil wiederholt
mit allen replicate weights berechnet und die quadrierte Differenz zur 
Punktschätzung einfach aufsummiert (Formel 6 aus dem Buch-Kapitel).
</p>
<p><code style="white-space: pre;">&#8288;# Schätzung mittels Gesamtgewicht
n.female &lt;- sum(schueler[schueler$female==1,]$NormStudwgt)
perc.female &lt;- n.female / sum(schueler$NormStudwgt)
# wiederholte Berechnung und Varianz
var.jrr = 0
for (i in 1:cnt.zones) {
  n.female.rep &lt;- 
    sum(schueler[schueler$female==1,paste0("w_fstr",i)])
  perc.female.rep &lt;- 
    n.female.rep / sum(schueler[paste0("w_fstr",i)])
  var.jrr &lt;-   # vgl. Formel 6
    var.jrr + (perc.female.rep - perc.female) ^ 2.0 }
&#8288;</code>

</p>



<h3>Author(s)</h3>

<p>Ann Cathrice George, Konrad Oberwimmer, Ursula Itzlinger-Bruneforth
</p>


<h3>References</h3>

<p>George, A. C., Oberwimmer, K. &amp; Itzlinger-Bruneforth, U. (2016). 
Stichprobenziehung. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 51&ndash;81). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel02">datenKapitel02</a></code>, den im Kapitel verwendeten Daten.<br />

Zurück zu <code><a href="#topic+Kapitel+201">Kapitel 1</a></code>, Testkonstruktion.<br />
Zu <code><a href="#topic+Kapitel+203">Kapitel 3</a></code>, Standard-Setting.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.


</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(datenKapitel02)
schueler &lt;- datenKapitel02$schueler
schule &lt;- datenKapitel02$schule
set.seed(20150506)

## -------------------------------------------------------------
## Abschnitt 4.1: Stratifizierung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 4.1, Listing 1

# Information in Strata
strata &lt;- aggregate(schule[,"NSchueler", drop = FALSE],
                    by=schule[,"stratum", drop = FALSE], sum)
colnames(strata)[2] &lt;- "NSchuelerStratum"

## -------------------------------------------------------------
## Abschnitt 4.2: Schulenziehung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 1

# Dummyvariable Klassenziehung
schule$Klassenziehung &lt;- 0
schule[which(schule$NKlassen&gt;3), "Klassenziehung"] &lt;- 1

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 2

# erwarteter Beitrag zur Stichprobe pro Schule 
schule$NSchueler.erw &lt;- schule$NSchueler
ind &lt;- which(schule$Klassenziehung == 1)
schule[ind, "NSchueler.erw"] &lt;- 
  schule[ind, "NSchueler"]/schule[ind, "NKlassen"]*3

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 3

# relativer Anteil Schüler pro Schule
temp &lt;- merge(schule[, c("SKZ","stratum","NSchueler")], 
              strata[, c("stratum","NSchuelerStratum")])
schule$AnteilSchueler &lt;- 
  temp$NSchueler/temp$NSchuelerStratum
# mittlere Anzahl von Schülern pro Schule
strata$"NSchueler/Schule.erw" &lt;- 
  rowsum(apply(schule, 1, function(x)
    x["NSchueler.erw"]*x["AnteilSchueler"]), schule$stratum)

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 4

# Bestimmung Anzahl zu ziehender Schulen
strata$Schulen.zu.ziehen &lt;- 
  round(2500/strata[,"NSchueler/Schule.erw"])

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 5

# Schulenliste nach Stratum und Groesse ordnen
schule &lt;- 
  schule[order(schule$stratum, schule$NSchueler),]

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 6

# Berechnung Sampling-Intervall
strata$Samp.Int &lt;- 
  strata$NSchuelerStratum/strata$Schulen.zu.ziehen

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 7

# Startwerte bestimmen
strata$Startwert &lt;- 
  sapply(ceiling(strata$Samp.Int), sample, size = 1)

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 8

# Schüler-Tickets
tickets &lt;- sapply(1:4, function(x)
  trunc(0:(strata[strata$stratum==x,"Schulen.zu.ziehen"]-1)
  * strata[strata$stratum==x, "Samp.Int"] +
    strata$Startwert[x]))

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 9

# kummulierte Schüleranzahl pro Stratum berechnen
schule$NSchuelerKum &lt;- 
  unlist(sapply(1:4, function(x)
    cumsum(schule[schule$stratum==x, "NSchueler"])))

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 10

# Schulen ziehen
schule$SInSamp &lt;- 0 
for(s in 1:4) {
  NSchuelerKumStrat &lt;- 
    schule[schule$stratum==s, "NSchuelerKum"]
  inds &lt;- sapply(tickets[[s]], function(x)
    setdiff(which(NSchuelerKumStrat &lt;= x),
            which(NSchuelerKumStrat[-1] &lt;= x)))
  schule[schule$stratum==s, "SInSamp"][inds] &lt;- 1 }

# -------------------------------------------------------------
# Abschnitt 4.2, Listing 11

# Berechnung Ziehungswahrscheinlichkeit Schule
temp &lt;- merge(schule[, c("stratum", "AnteilSchueler")],
  strata[, c("stratum", "Schulen.zu.ziehen")])
schule$Z.Wsk.Schule &lt;- 
  temp$AnteilSchueler*temp$Schulen.zu.ziehen

## -------------------------------------------------------------
## Abschnitt 4.3: Klassenziehung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 4.3, Listing 1

### Klassenziehung (Alternative 2)
schukla &lt;- unique(merge(
  schule[, c("SKZ","NKlassen", "Klassenziehung", 
    "Z.Wsk.Schule", "SInSamp")],
    schueler[, c("SKZ", "idclass")], by="SKZ"))
schukla$KlInSamp &lt;- 0
for(skz in unique(schukla[schukla$SInSamp==1,"SKZ"])) {
  temp &lt;- schukla[schukla$SKZ==skz, "idclass"]
  schukla[schukla$idclass%in%temp[sample.int(
    min(3, length(temp)))], "KlInSamp"] &lt;- 1 }

# -------------------------------------------------------------
# Abschnitt 4.3, Listing 2

# Ziehungswahrscheinlichkeit Klasse 
schukla$Z.Wsk.Klasse &lt;- ((1 - schukla$Klassenziehung) * 1 + 
     schukla$Klassenziehung * 3 / schukla$NKlassen) 

## -------------------------------------------------------------
## Abschnitt 4.4: Gewichtung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 4.4, Listing 1

### Gewichte
schueler &lt;- merge(schueler, schukla[, c("idclass", "KlInSamp", "Z.Wsk.Schule", 
                                        "Z.Wsk.Klasse")],
                  by="idclass", all.x=T)
# Ziehungswahrscheinlichkeiten Schueler 
schueler$Z.Wsk.Schueler &lt;- 
  schueler$Z.Wsk.Schule * schueler$Z.Wsk.Klasse

# -------------------------------------------------------------
# Abschnitt 4.4, Listing 2

schueler &lt;- schueler[schueler$KlInSamp==1,]
# Nonresponse Adjustment 
temp &lt;- merge(schueler[, c("idclass", "Z.Wsk.Schueler")],
  aggregate(schueler$teilnahme, 
    by=list(schueler$idclass),
    function(x) sum(x)/length(x)), 
  by.x="idclass", by.y="Group.1")

# -------------------------------------------------------------
# Abschnitt 4.4, Listing 3

# Schülergewichte
schueler$studwgt &lt;- 1/temp$x/temp$Z.Wsk.Schueler

# -------------------------------------------------------------
# Abschnitt 4.4, Listing 4

# Normierung
Normierung &lt;- strata$NSchuelerStratum / 
  rowsum(schueler$studwgt * schueler$teilnahme,
         group = schueler$Stratum)
schueler$NormStudwgt &lt;- 
  schueler$studwgt * Normierung[schueler$Stratum]

## -------------------------------------------------------------
## Abschnitt 5.3: Jackknife-Repeated-Replication
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 5.3, Listing 1

### Ergänzung zum Buch: Hilfsfunktion zones.within.stratum
zones.within.stratum &lt;- function(offset,n.str) {
  maxzone &lt;- offset-1+floor(n.str/2)
  zones &lt;- sort(rep(offset:maxzone,2))
  if (n.str %% 2 == 1) zones &lt;- c(zones,maxzone)
  return(zones) }
### Ende der Ergänzung

# Sortieren der Schulliste (explizite und implizite Strata)
schule &lt;- schule[schule$SInSamp==1,]
schule &lt;- schule[order(schule$stratum,-schule$NSchueler),]

# Unterteilung in Pseudostrata 
cnt.strata &lt;- length(unique(schule$stratum))
offset &lt;- 1
jkzones.vect &lt;- integer()
for (i in 1:cnt.strata) {
  n.str &lt;- table(schule$stratum)[i]
  jkzones.vect &lt;- 
    c(jkzones.vect,zones.within.stratum(offset,n.str))
  offset &lt;- max(jkzones.vect)+1 }
schule$jkzone &lt;- jkzones.vect

# Zufällige Auswahl von Schulen mit Gewicht 0
schule$jkrep &lt;- 1
cnt.zones &lt;- max(schule$jkzone)
jkrep.rows.null &lt;- integer()
for (i in 1:cnt.zones) {
  rows.zone &lt;- which(schule$jkzone==i)
### Ergänzung zum Buch: Fallunterscheidung je nach Anzahl Schulen in der Zone
  if (length(rows.zone)==2) jkrep.rows.null &lt;- 
    c(jkrep.rows.null,sample(rows.zone,size=1))
  else {
      num.null &lt;- sample(1:2,size=1)
      jkrep.rows.null &lt;- 
        c(jkrep.rows.null,sample(rows.zone,size=num.null)) 
    } }
schule[jkrep.rows.null,]$jkrep &lt;- 0

# -------------------------------------------------------------
# Abschnitt 5.3, Listing 2

# Übertragung auf Schülerebene
schueler &lt;- 
  merge(schueler,schule[,c("SKZ","jkzone","jkrep")],all.x=TRUE)
# Schleife zur Generierung von Replicate Weights
for (i in 1:cnt.zones) {
  in.zone &lt;- as.numeric(schueler$jkzone==i)
  schueler[paste0("w_fstr",i)] &lt;-   # vgl. Formel 5
    in.zone * schueler$jkrep * schueler$NormStudwgt * 2 +
    (1-in.zone) * schueler$NormStudwgt }

# -------------------------------------------------------------
# Abschnitt 5.3, Listing 3

# Schätzung mittels Gesamtgewicht
n.female &lt;- sum(schueler[schueler$female==1,]$NormStudwgt)
perc.female &lt;- n.female / sum(schueler$NormStudwgt)
# wiederholte Berechnung und Varianz
var.jrr = 0
for (i in 1:cnt.zones) {
  n.female.rep &lt;- 
    sum(schueler[schueler$female==1,paste0("w_fstr",i)])
  perc.female.rep &lt;- 
    n.female.rep / sum(schueler[paste0("w_fstr",i)])
  var.jrr &lt;-   # vgl. Formel 6
    var.jrr + (perc.female.rep - perc.female) ^ 2.0 }

## End(Not run) 
</code></pre>

<hr>
<h2 id='Kapitel+20+203'>Kapitel 3: Standard-Setting</h2><span id='topic+Kapitel+203'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 3, <em>Standard-Setting</em>, im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische Grundlagen der 
österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Details</h3>



<h4>Übersicht über die verwendeten Daten</h4>

<p>Für dieses Kapitel werden drei Datensätze verwendet. 
Der Datensatz <code>ratings</code> ist das Ergebnis der IDM-Methode, darin enthalten 
sind für alle Items die Einstufung jedes Raters auf eine der drei 
Kompetenzstufen (1, 2, 3), sowie Item-Nummer und Schwierigkeit. 
Der Datensatz <code>bookmarks</code> ist das Ergebnis der Bookmark-Methode, darin 
enthalten sind pro Rater und pro Cut-Score jeweils die gewählte Bookmark als 
Seitenzahl im OIB (die ein bestimmtes Item repräsentiert). 
In <code>sdat</code> sind Personenparameter von 3500 Schülerinnen und Schülern 
enthalten, diese dienen zur Schätzung von Impact Data. 
Der Datensatz <code>productive</code> ist für die Illustration der 
Contrasting-Groups-Methode gedacht: Dieser enthält die Ratings aus der 
Contrasting-Groups-Methode, pro Rater die Information, ob der entsprechende 
Text auf die Stufe unter- oder oberhalb des Cut-Scores eingeteilt wurde, sowie 
Nummer des Textes und Personenfähigkeit. 
</p>



<h4>Abschnitt 3.2.2: Daten aus der IDM-Methode</h4>



<h5>Listing 1: Feedback</h5>

<p>Hier wird der Datensatz <code>ratings</code> verwendet. Er ist das Ergebnis der 
IDM-Methode, darin enthalten sind für alle Items die Einstufung jedes Raters 
auf eine der drei Kompetenzstufen (1, 2, 3). Zunächst werden die Rater und die 
Items aus dem Datensatz ausgewählt, dann wird pro Item die prozentuelle 
Verteilung der Ratings auf die drei Stufen berechnet. 
</p>
<p><code style="white-space: pre;">&#8288;raterID &lt;- grep("R", colnames(ratings), value = TRUE)
nraters &lt;- length(raterID) 
nitems &lt;- nrow(ratings) 
itemID &lt;- ratings[, 1] 
itemdiff &lt;- ratings[, 2]
stufen &lt;- c(1, 2, 3) # Anzahl der Kompetenzstufen
item.freq &lt;- data.frame() 
# Berechne Prozentuelle Zuteilungen auf Stufen pro Item
tabelle.ii &lt;- data.frame()
for(ii in 1:nitems){   
  tabelle.ii &lt;- round(table(factor(as.numeric(ratings[ii,
    raterID]), levels = stufen)) / nraters * 100, digits = 2)      
  item.freq &lt;- rbind(item.freq, tabelle.ii) }
colnames(item.freq) &lt;- paste0("Level_", stufen)
item.freq &lt;- data.frame(ratings[, 1:2], item.freq)
head(item.freq, 3)
# Anmerkung: Item 3 zu 100% auf Stufe 1, Item 2 aufgeteilt 
# auf Stufe 1 und 2
&#8288;</code>

</p>



<h5>Listing 1a: Ergänzung zum Buch</h5>

<p>Hier wird eine Grafik erzeugt, in der das Rating-Verhalten sichtbar wird: Pro 
Item wird angezeigt, wieviele Prozent der Raters es auf eine der drei Stufen 
eingeteilt haben. 
Zunächst werden drei verschiedene Farben definiert, anschließend werden drei 
Barplots erstellt, die zusammen auf einer Seite dargestellt werden. 
Die Grafik wird zur Orientierung bei Diskussionen verwendet, da so schnell 
ersichtlich ist, bei welchen Items sich das Experten-Panel einig oder uneinig
war. 
Für die Grafik gibt es die Möglichkeit, diese in Schwarz-Weiss zu halten oder 
in Farbe zu gestalten.
</p>
<p><code style="white-space: pre;">&#8288;# Farben für die Grafik definieren - falls eine bunte Grafik gewünscht ist, 
# kann barcol &lt;- c(c1, c2, c3) definiert werden
c1 &lt;- rgb(239/255, 214/255, 67/255)  
c2 &lt;- rgb(207/255, 151/255, 49/255)  
c3 &lt;- rgb(207/255, 109/255, 49/255)

# Aufbereitung Tabelle für Grafik
freq.dat &lt;- t(as.matrix(item.freq[1:nitems,(3:(2+length(stufen)))]))
barcol &lt;- c("black", "gray", "white") 

#Grafik wird erzeugt
par(mfcol=c(3,1), oma=c(0,0,3,0)) # Angeben der Plot-Anzahl      
perplot &lt;- round(nitems/3)    
a &lt;- perplot + 1   
b &lt;- perplot*2  
c &lt;- b + 1     
d &lt;- perplot*3
barplot(freq.dat[,1 : perplot], col = barcol, beside = T, 
        names.arg = seq(1 , perplot), xlab = "Itemnummer (Seitenzahl im OIB)", 
        ylab = "% Zuteilung auf Stufe", horiz = F, ylim = range(1:100))
barplot(freq.dat[, a:b], col = barcol, beside = T, names.arg = seq(a, b), 
        xlab = "Itemnummer (Seitenzahl im OIB)", 
        ylab = "% Zuteilung auf Stufe", 
        horiz = F, ylim = range(1:100))
barplot(freq.dat[, c:d], col = barcol, beside = T, names.arg = seq(c, d), 
        xlab = "Itemnummer (Seitenzahl im OIB)", 
        ylab = "% Zuteilung auf Stufe", 
        horiz = F, ylim = range(1:100))
title("Feedback für das Experten-Panel aus der IDM-Methode", outer = T)
&#8288;</code>

</p>



<h5>Listing 2: Cut-Score Berechnung</h5>

<p>Hier wird der Cut-Score aus den Daten der IDM-Methode mithilfe logistischer 
Regression für den ersten Rater im Experten-Panel berechnet. 
Dafür wird der zweite Cut-Score herangezogen. Zunächst müssen die 
entsprechenden Ratings für die logistische Regression umkodiert werden 
(2 = 0, 3 = 1).
Anschließend wird die logistische Regression berechnet, als unabhängige Variable 
dient die Einstufung durch den jeweiligen Experten (0, 1), als abhängige 
Variable die Itemschwierigkeit. 
Anhand der erhaltenen Koeffizienten kann der Cut-Score berechnet werden.
</p>
<p><code style="white-space: pre;">&#8288;library(car)
# Rekodieren
rate.i &lt;- ratings[which(ratings$R01 %in% c(2, 3)), 
                  c("MB_Norm_rp23", "R01")] 
rate.i$R01 &lt;-  recode(rate.i$R01, "2=0; 3=1")
coef(cut.i &lt;- glm(rate.i$R01  ~ rate.i$MB_Norm_rp23 , 
              family = binomial(link="logit")))
# Berechnung des Cut-Scores laut Formel
cut.R01 &lt;- (-cut.i$coefficients[1])/ cut.i$coefficients[2]
&#8288;</code>

</p>



<h5>Listing 3: Rater-Analysen</h5>

<p>Als ersten Schritt in den Rater-Analysen wird das mittlere Cohen's Kappa eines 
Raters mit allen anderen Raters berechnet. Dafür werden zunächst die Ratings 
ausgewählt und dann für jeden Rater die Übereinstimmung mit jedem anderen Rater 
paarweise berechnet. 
Anschließend werden diese Werte gemittelt und auch die Standard-Abweichung 
berechnet. 
</p>
<p><code style="white-space: pre;">&#8288;library(irr)
# Auswahl der Ratings
rater.dat &lt;- ratings[ ,grep("R", colnames(ratings))]
# Kappa von jeder Person mit allen anderen Personen wird berechnet
kappa.mat &lt;- matrix(NA, nraters, nraters) 
for(ii in 1:nraters){  
  rater.eins &lt;- rater.dat[, ii]      
  for(kk in 1:nraters){    
    rater.zwei &lt;- rater.dat[ ,kk]
    dfr.ii &lt;- cbind(rater.eins, rater.zwei)
    kappa.ik &lt;- kappa2(dfr.ii)       
    kappa.mat[ii, kk] &lt;- kappa.ik$value   
      }} 
diag(kappa.mat) &lt;- NA 
# Berechne Mittleres Kappa für jede Person
MW_Kappa &lt;- round(colMeans(kappa.mat, na.rm=T), digits=2) 
SD_Kappa &lt;- round(apply(kappa.mat, 2, sd, na.rm=T), digits=2) 
(Kappa.Stat &lt;- data.frame("Person"= raterID, MW_Kappa, SD_Kappa))
&#8288;</code>

</p>



<h5>Listing 4: Berechnung Fleiss' Kappa</h5>

<p>Fleiss' Kappa gibt die Übereinstimmung innerhalb des gesamten Experten-Panels 
an. 
Wird das Standard-Setting über mehrere Runden durchgeführt, kann Fleiss' Kappa 
auch für jede Runde berechnet werden. 
</p>
<p><code style="white-space: pre;">&#8288;kappam.fleiss(rater.dat)
&#8288;</code>

</p>



<h5>Listing 5: Modalwerte</h5>

<p>Auch die Korrelation zwischen dem Modalwert jedes Items (d.h., ob es am 
häufigsten auf Stufe 1, 2 oder 3 eingeteilt wurde) und der inviduellen 
Zuordnung durch einen Rater kann zu Rater-Analysen herangezogen werden. 
Zunächst wird der Modal-Wert eines jeden Items berechnet. 
Hat ein Item zwei gleich häufige Werte, gibt es eine Warnmeldung und es wird 
für dieses Item NA anstatt eines Wertes vergeben (für diese Analyse sind aber 
nur Items von Interesse, die einen eindeutigen Modalwert haben). 
Danach wird pro Rater die Korrelation zwischen dem Modalwert eines Items und 
der entsprechenden Einteilung durch den Rater berechnet, und dann in 
aufsteigender Höhe ausgegeben.
</p>
<p><code style="white-space: pre;">&#8288;library(prettyR)
# Berechne Modalwert
mode &lt;- as.numeric(apply(rater.dat, 1, Mode))
# Korrelation für die Ratings jeder Person im Panel mit den 
# Modalwerten der Items
corr &lt;- data.frame()
for(z in raterID){
  rater.ii &lt;- rater.dat[, (grep(z, colnames(rater.dat)))]
  cor.ii &lt;- round(cor(mode, rater.ii, use = "pairwise.complete.obs", 
    method = "spearman"), digits = 2)
  corr &lt;- rbind(corr, cor.ii)
}
corr[, 2] &lt;- raterID
colnames(corr) &lt;- c("Korrelation", "Rater")
# Aufsteigende Reihenfolge 
(corr &lt;- corr[order(corr[, 1]),])
&#8288;</code>

</p>



<h5>Listing 5a: Ergänzung zum Buch</h5>

<p>Die Korrelation zwischen Modalwerten und individueller Zuordnung kann auch zur 
besseren Übersicht graphisch gezeigt werden. 
Dabei werden die Korrelationen der Raters aufsteigend dargestellt.
</p>
<p><code style="white-space: pre;">&#8288;# Grafik
plot(corr$Korrelation, xlab = NA, ylab = "Korrelation",   
     ylim = c(0.5, 1), xaxt = "n", main = "Korrelation zwischen 
     Modalwert und individueller Zuordnung der Items pro Rater/in")
text(seq(1:nraters), corr$Korrelation - 0.02, labels = corr[, 2], 
     offset = 1, cex = 1)
title(xlab = "Raters nach aufsteigender Korrelation gereiht")
&#8288;</code>

</p>



<h5>Listing 6: ICC</h5>

<p>Hier wird der ICC als Ausdruck der Übereinstimmung (d.h., Items werden auf 
dieselbe Stufe eingeteilt) und der Konsistenz (d.h., Items werden in dieselbe 
Reihenfolge gebracht) zwischen Raters berechnet. 
Falls es mehrere Runden gibt, kann der ICC auch wiederholt berechnet und 
verglichen werden.
</p>
<p><code style="white-space: pre;">&#8288;library(irr)
(iccdat.agree &lt;- icc(rater.dat, model = "twoway", type = "agreement", 
                     unit = "single", r0 = 0, conf.level=0.95))
(iccdat.cons &lt;- icc(rater.dat, model = "twoway", type = "consistency", 
                    unit = "single", r0 = 0, conf.level=0.95))
&#8288;</code>

</p>




<h4>Abschnitt 3.2.3: Daten aus der Bookmark-Methode</h4>



<h5>Listing 1: Feedback</h5>

<p>Auch in der Bookmark-Methode wird dem Experten-Panel Feedback angeboten, um die 
Diskussion zu fördern. 
Hier wird pro Cut-Score Median, Mittelwert und Standard-Abweichung der 
Bookmarks (Seitenzahl im OIB) im Experten-Panel berechnet.
</p>
<p><code style="white-space: pre;">&#8288;head(bookmarks)
statbookm &lt;- data.frame("Stats"=c("Md","Mean","SD"), 
                        "Cut1"=0, "Cut2"=0)
statbookm[1,2] &lt;- round(median(bookmarks$Cut1), digits=2)
statbookm[1,3] &lt;- round(median(bookmarks$Cut2), digits=2)
statbookm[2,2] &lt;- round(mean(bookmarks$Cut1), digits=2)
statbookm[2,3] &lt;- round(mean(bookmarks$Cut2), digits=2)
statbookm[3,2] &lt;- round(sd(bookmarks$Cut1), digits=2)
statbookm[3,3] &lt;- round(sd(bookmarks$Cut2), digits=2)
(statbookm)
table(bookmarks$Cut1)
table(bookmarks$Cut2)
&#8288;</code>

</p>



<h5>Listing 2: Cut-Score Berechnung</h5>

<p>Jede Bookmark repräsentiert ein Item, das eine bestimmte Itemschwierigkeit hat. 
Die Cut-Scores lassen sich berechnen, in dem man die unterliegenden 
Itemschwierigkeiten der Bookmarks mittelt.
</p>
<p><code style="white-space: pre;">&#8288;bm.cut &lt;- NULL 
bm.cut$cut1 &lt;- mean(ratings$MB_Norm_rp23[bookmarks$Cut1]) 
bm.cut$cut2 &lt;- mean(ratings$MB_Norm_rp23[bookmarks$Cut2]) 
bm.cut$cut1sd &lt;- sd(ratings$MB_Norm_rp23[bookmarks$Cut1]) 
bm.cut$cut2sd &lt;- sd(ratings$MB_Norm_rp23[bookmarks$Cut2]) 
&#8288;</code>

</p>



<h5>Listing 3: Standardfehler des Cut-Scores</h5>

<p>Der Standardfehler wird berechnet, um eine mögliche Streuung des Cut-Scores 
zu berichten. 
</p>
<p><code style="white-space: pre;">&#8288;se.cut1 &lt;- bm.cut$cut1sd/sqrt(nraters)
se.cut2 &lt;- bm.cut$cut2sd/sqrt(nraters)
&#8288;</code>

</p>



<h5>Listing 4: Impact Data</h5>

<p>Mithilfe von Impact Data wird auf Basis von pilotierten Daten geschätzt, welche 
Auswirkungen die Cut-Scores auf die Schülerpopulation hätten (d.h., wie sich die
Schülerinnen und Schüler auf die Stufen verteilen würden).
Für diese Schätzung werden die Personenparameter herangezogen.
Anschließend wird die Verteilung der Personenparameter entsprechend der 
Cut-Scores unterteilt. 
Die Prozentangaben der Schülerinnen und Schüler, die eine bestimmte Stufe 
erreichen, dienen dem Experten-Panel als Diskussionsgrundlage.
</p>
<p><code style="white-space: pre;">&#8288;Pers.Para &lt;- sdat[, "TPV1"]
cuts &lt;- c(bm.cut$cut1, bm.cut$cut2)
# Definiere Bereiche: Minimaler Personenparameter bis Cut-Score 1, 
#   Cut-Score 1 bis Cut-Score 2, Cut-Score 2 bis maximaler 
#   Personenparameter
Cuts.Vec &lt;- c(min(Pers.Para)-1, cuts, max(Pers.Para)+1)
# Teile Personenparameter in entsprechende Bereiche auf
Kum.Cuts &lt;- cut(Pers.Para, breaks = Cuts.Vec)
# Verteilung auf die einzelnen Bereiche
Freq.Pers.Para &lt;- xtabs(~ Kum.Cuts)
nstud &lt;- nrow(sdat)
# Prozent-Berechnung
prozent &lt;- round(as.numeric(Freq.Pers.Para / nstud * 100), 
  digits = 2) 
(Impact.Data &lt;- data.frame("Stufe" = c("A1", "A2", "B1"), 
  "Prozent" = prozent))
&#8288;</code>

</p>




<h4>Abschnitt 3.3.3: Daten aus der Contrasting-Groups-Methode</h4>



<h5>Listing 1: Cut-Scores</h5>

<p>Hier wird der Cut-Score für den produktiven Bereich Schreiben berechnet, die 
Basis ist dabei die Personenfähigkeeit. 
Dabei wird pro Rater vorgegangen. Für jeden Rater werden dabei zwei Gruppen 
gebildet - Texte, die auf die untere Stufe eingeteilt wurden und Texte, die auf 
die obere Stufe eingeteilt wurden. 
Von beiden Gruppen wird jeweils der Mittelwert der Personenfähigkeit berechnet 
und anschließend der Mittelwert zwischen diesen beiden Gruppen. 
Wurde das für alle Raters durchgeführt, können die individuell gesetzten 
Cut-Scores wiederum gemittelt werden und die Standard-Abweichung sowie der 
Standardfehler berechnet werden.
</p>
<p><code style="white-space: pre;">&#8288;raterID &lt;- grep("R", colnames(productive), value = TRUE) 
nraters &lt;- length(raterID)  
nscripts &lt;- nrow(productive) 
# Berechne Cut-Score für jeden Rater
cutscore &lt;- data.frame("rater"=raterID, "cut1.ges"=NA)
for(ii in 1:length(raterID)){ 
  rater &lt;- raterID[ii]   
  rates.ii &lt;-  productive[ ,grep(rater, colnames(productive))]   
  mean0.ii &lt;- mean(productive$Performance[rates.ii == 0], na.rm = T)   
  mean1.ii &lt;- mean(productive$Performance[rates.ii == 1], na.rm = T)   
  mean.ii &lt;- mean(c(mean1.ii, mean0.ii), na.rm = T)   
  cutscore[ii, "cut1.ges"] &lt;- mean.ii }
# Finaler Cut-Score
cut1 &lt;- mean(cutscore$cut1.ges)
sd.cut1 &lt;- sd(cutscore$cut1.ges)
se.cut1 &lt;- sd.cut1/sqrt(nraters)
&#8288;</code>

</p>




<h4>Appendix: Abbildungen im Buch</h4>

<p>Hier ist der R-Code für die im Buch abgedruckten Grafiken zu finden.
</p>


<h5>Abbildung 3.1</h5>

<p>In einem nächsten Schritt wird anhand des mittleren Kappa und der dazugehörigen 
Standard-Abweichung eine Grafik erstellt, um die Übereinstimmung eines Raters 
mit allen anderen Ratern dazustellen. 
Dafür wird zunächst ein Boxplot des mittleren Kappa pro Rater erzeugt. 
In einem zweiten Schritt werden die mittleren Kappas mit der dazugehörigen 
Standard-Abweichung abgetragen. 
Linien markieren 1.5 Standard-Abweichungen vom Mittelwert. 
Raters, die über oder unter dieser Grenze liegen, werden gekennzeichnet.
</p>
<p><code style="white-space: pre;">&#8288;# GRAFIK
# 1. Grafik
par(fig=c(0, 1, 0, 0.35), oma=c(0,0,3,0), cex = 0.85) 
boxplot(Kappa.Stat$MW_Kappa, horizontal = T, ylim=c(0.42,0.66), 
        axes = F, xlab = "MW Kappa")
# 2. Grafik wird hinzugefügt
par(fig=c(0, 1, 0.2, 1), new=TRUE)
sd.factor &lt;- 1.5 
mmw &lt;- mean(Kappa.Stat$MW_Kappa)
sdmw &lt;- sd(Kappa.Stat$MW_Kappa)
#Grenzwerte für MW und SD werden festgelegt
mwind &lt;- c(mmw-(sd.factor*sdmw), mmw+(sd.factor*sdmw))
plot(Kappa.Stat$MW_Kappa, Kappa.Stat$SD_Kappa, xlab = "",
     ylab = "SD Kappa", type = "n", xlim = c(0.42, 0.66), 
     ylim = c(0, 0.2))
abline(v = mwind, col="grey", lty = 2)
# Rater mit 1.5 SD Abweichung vom MW werden grau markiert 
abw.rater &lt;- which(Kappa.Stat$MW_Kappa &lt; mwind[1] | 
                     Kappa.Stat$MW_Kappa &gt; mwind[2])
points(Kappa.Stat$MW_Kappa[-abw.rater], 
       Kappa.Stat$SD_Kappa[-abw.rater], 
       pch = 19)
points(Kappa.Stat$MW_Kappa[abw.rater], 
       Kappa.Stat$SD_Kappa[abw.rater], 
       pch = 25, bg = "grey")
text(Kappa.Stat$MW_Kappa[abw.rater], 
     Kappa.Stat$SD_Kappa[abw.rater], 
     Kappa.Stat$Person[abw.rater], 
     pos = 3) 
title("Rater-Analysen: MW und SD Kappa aus der IDM-Methode", 
      outer = TRUE)
&#8288;</code>

</p>



<h5>Abbildung 3.2</h5>

<p>Um das Feedback über die Setzung der Bookmarks an das Experten-Panel einfacher 
zu gestalten, wird eine Grafik erstellt. 
Darin sieht man pro Cut-Score, wo die Raters ihre Bookmarks (d.h. Seitenzahl 
im OIB) gesetzt haben, sowie Info über den Mittelwert dieser Bookmarks. 
Diese Grafik soll die Diskussion fördern.
</p>
<p><code style="white-space: pre;">&#8288;nitems &lt;- 60

library(lattice)
library(gridExtra)
#Erster Plot mit Mittelwert
plot.Cut1 &lt;- dotplot(bookmarks$Rater ~ bookmarks$Cut1, col = "black", 
                     panel = function(...){
                       panel.dotplot(...)
                       panel.abline(v = mean(bookmarks$Cut1), lty = 5)
                      }, 
                     xlab = "Bookmarks für Cut-Score 1 (Seite im OIB)",
                     ylab = "Raters", cex = 1.3)
#Zweiter Plot mit Mittelwert
plot.Cut2 &lt;- dotplot(bookmarks$Rater ~ bookmarks$Cut2, col = "black", 
                     panel = function(...){
                       panel.dotplot(...)
                       panel.abline(v = mean(bookmarks$Cut2), lty = 5)
                      }, 
                     xlab = "Bookmarks für Cut-Score 2 (Seite im OIB)", 
                     ylab = "Raters", cex = 1.3)
#Plots nebeneinander anordnen
grid.arrange(plot.Cut1, plot.Cut2, nrow = 1, top = "Bookmarks pro Rater/in")
&#8288;</code>

</p>




<h3>Author(s)</h3>

<p>Claudia Luger-Bazinger, Roman Freunberger, Ursula Itzlinger-Bruneforth
</p>


<h3>References</h3>

<p>Luger-Bazinger, C., Freunberger, R. &amp; Itzlinger-Bruneforth, U. (2016). 
Standard-Setting. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 83&ndash;110). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel03">datenKapitel03</a></code>, den im Kapitel verwendeten Daten.<br />

Zurück zu <code><a href="#topic+Kapitel+202">Kapitel 2</a></code>, Stichprobenziehung.<br />
Zu <code><a href="#topic+Kapitel+204">Kapitel 4</a></code>, Differenzielles Itemfunktionieren in Subgruppen.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(car)
library(irr)
library(prettyR)
library(lattice)
library(gridExtra)

data(datenKapitel03)
ratings &lt;- datenKapitel03$ratings
bookmarks &lt;- datenKapitel03$bookmarks
sdat &lt;- datenKapitel03$sdat
productive &lt;- datenKapitel03$productive

## -------------------------------------------------------------
## Abschnitt 3.2.2: Daten aus der IDM-Methode
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 1: Feedback
#

raterID &lt;- grep("R", colnames(ratings), value = TRUE)
nraters &lt;- length(raterID) 
nitems &lt;- nrow(ratings) 
itemID &lt;- ratings[, 1] 
itemdiff &lt;- ratings[, 2]
stufen &lt;- c(1, 2, 3) # Anzahl der Kompetenzstufen
item.freq &lt;- data.frame() 
# Berechne Prozentuelle Zuteilungen auf Stufen pro Item
tabelle.ii &lt;- data.frame()
for(ii in 1:nitems){   
  tabelle.ii &lt;- round(table(factor(as.numeric(ratings[ii, 
    raterID]), levels = stufen)) / nraters * 100, digits = 2)      
  item.freq &lt;- rbind(item.freq, tabelle.ii) }
colnames(item.freq) &lt;- paste0("Level_", stufen)
item.freq &lt;- data.frame(ratings[, 1:2], item.freq)
head(item.freq, 3)
# Anmerkung: Item 3 zu 100% auf Stufe 1, Item 2 aufgeteilt 
# auf Stufe 1 und 2

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 1a: Ergänzung zum Buch
# GRAFIK-Erzeugung
#

# Farben für die Grafik definieren
c1 &lt;- rgb(239/255, 214/255, 67/255)  
c2 &lt;- rgb(207/255, 151/255, 49/255)  
c3 &lt;- rgb(207/255, 109/255, 49/255)

# Aufbereitung Tabelle für Grafik
freq.dat &lt;- t(as.matrix(item.freq[1:nitems,(3:(2+length(stufen)))]))
barcol &lt;- c("black", "gray", "white") 

#Grafik wird erzeugt
par(mfcol=c(3,1), oma=c(0,0,3,0)) # Angeben der Plot-Anzahl      
perplot &lt;- round(nitems/3)    
a &lt;- perplot + 1   
b &lt;- perplot*2  
c &lt;- b + 1     
d &lt;- perplot*3
barplot(freq.dat[,1 : perplot], col = barcol, beside = T, 
        names.arg = seq(1 , perplot), xlab = "Itemnummer (Seitenzahl im OIB)", 
        ylab = "% Zuteilung auf Stufe", horiz = F, ylim = range(1:100))
barplot(freq.dat[, a:b], col = barcol, beside = T, names.arg = seq(a, b), 
        xlab = "Itemnummer (Seitenzahl im OIB)", 
        ylab = "% Zuteilung auf Stufe", 
        horiz = F, ylim = range(1:100))
barplot(freq.dat[, c:d], col = barcol, beside = T, names.arg = seq(c, d), 
        xlab = "Itemnummer (Seitenzahl im OIB)", 
        ylab = "% Zuteilung auf Stufe", 
        horiz = F, ylim = range(1:100))
title("Feedback für das Experten-Panel aus der IDM-Methode", outer = T)

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 2: Cut-Score Berechnung
#

library(car)
# Rekodieren
rate.i &lt;- ratings[which(ratings$R01 %in% c(2, 3)), 
                  c("Norm_rp23", "R01")] 
rate.i$R01 &lt;-  recode(rate.i$R01, "2=0; 3=1")
coef(cut.i &lt;- glm(rate.i$R01  ~ rate.i$Norm_rp23 , 
                  family = binomial(link="logit")))
# Berechnung des Cut-Scores laut Formel
cut.R01 &lt;- (-cut.i$coefficients[1])/ cut.i$coefficients[2]

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 3: Rater-Analysen
# 

library(irr)
# Auswahl der Ratings
rater.dat &lt;- ratings[ ,grep("R", colnames(ratings))]
# Berechne Kappa von jeder Person mit allen anderen Personen
kappa.mat &lt;- matrix(NA, nraters, nraters) 
for(ii in 1:nraters){  
  rater.eins &lt;- rater.dat[, ii]      
  for(kk in 1:nraters){    
    rater.zwei &lt;- rater.dat[ ,kk]
    dfr.ii &lt;- cbind(rater.eins, rater.zwei)
    kappa.ik &lt;- kappa2(dfr.ii)       
    kappa.mat[ii, kk] &lt;- kappa.ik$value }} 
diag(kappa.mat) &lt;- NA 
# Berechne Mittleres Kappa für jede Person
MW_Kappa &lt;- round(colMeans(kappa.mat, na.rm=T), digits=2) 
SD_Kappa &lt;- round(apply(kappa.mat, 2, sd, na.rm=T), digits=2) 
(Kappa.Stat &lt;- data.frame("Person"= raterID, MW_Kappa, 
  SD_Kappa))

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 4: Berechnung Fleiss' Kappa
# 

kappam.fleiss(rater.dat)

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 5: Modalwerte
# 

library(prettyR)
# Berechne Modalwert
mode &lt;- as.numeric(apply(rater.dat, 1, Mode))
# Korrelation für die Ratings jeder Person im Panel mit den 
# Modalwerten der Items
corr &lt;- data.frame()
for(z in raterID){
  rater.ii &lt;- rater.dat[, (grep(z, colnames(rater.dat)))]
  cor.ii &lt;- round(cor(mode, rater.ii, method = "spearman",
    use = "pairwise.complete.obs"), digits = 2)
  corr &lt;- rbind(corr, cor.ii)
}
corr[, 2] &lt;- raterID
colnames(corr) &lt;- c("Korrelation", "Rater")
# Aufsteigende Reihenfolge 
(corr &lt;- corr[order(corr[, 1]),])

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 5: Ergänzung zum Buch
# GRAFIK-Erzeugung und ICC
#

# Grafik
plot(corr$Korrelation, xlab = NA, ylab = "Korrelation",   
     ylim = c(0.5, 1), xaxt = "n", main = "Korrelation zwischen 
     Modalwert und individueller Zuordnung der Items pro Rater/in")
text(seq(1:nraters), corr$Korrelation - 0.02, labels = corr[, 2], 
     offset = 1, cex = 1)
title(xlab = "Raters nach aufsteigender Korrelation gereiht")

# -------------------------------------------------------------
# Abschnitt 3.2.2, Listing 6: ICC
# 

library(irr)
(iccdat.agree &lt;- icc(rater.dat, model = "twoway", 
  type = "agreement", unit = "single", r0 = 0, conf.level=0.95))
(iccdat.cons &lt;- icc(rater.dat, model = "twoway", 
  type = "consistency", unit = "single", r0 = 0, conf.level=0.95))


## -------------------------------------------------------------
## Abschnitt 3.2.3: Daten aus der Bookmark-Methode
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 3.2.3, Listing 1: Feedback
# 

head(bookmarks)
statbookm &lt;- data.frame("Stats"=c("Md","Mean","SD"), 
                        "Cut1"=0, "Cut2"=0)
statbookm[1,2] &lt;- round(median(bookmarks$Cut1), digits=2)
statbookm[1,3] &lt;- round(median(bookmarks$Cut2), digits=2)
statbookm[2,2] &lt;- round(mean(bookmarks$Cut1), digits=2)
statbookm[2,3] &lt;- round(mean(bookmarks$Cut2), digits=2)
statbookm[3,2] &lt;- round(sd(bookmarks$Cut1), digits=2)
statbookm[3,3] &lt;- round(sd(bookmarks$Cut2), digits=2)
(statbookm)
table(bookmarks$Cut1)
table(bookmarks$Cut2)

# -------------------------------------------------------------
# Abschnitt 3.2.3, Listing 2: Cut-Score Berechnung
# 

bm.cut &lt;- NULL 
bm.cut$cut1 &lt;- mean(ratings$Norm_rp23[bookmarks$Cut1]) 
bm.cut$cut2 &lt;- mean(ratings$Norm_rp23[bookmarks$Cut2]) 
bm.cut$cut1sd &lt;- sd(ratings$Norm_rp23[bookmarks$Cut1]) 
bm.cut$cut2sd &lt;- sd(ratings$Norm_rp23[bookmarks$Cut2]) 

# -------------------------------------------------------------
# Abschnitt 3.2.3, Listing 3: Standardfehler des Cut-Scores
# 

se.cut1 &lt;- bm.cut$cut1sd/sqrt(nraters)
se.cut2 &lt;- bm.cut$cut2sd/sqrt(nraters)

# -------------------------------------------------------------
# Abschnitt 3.2.3, Listing 4: Impact Data
#

Pers.Para &lt;- sdat[, "TPV1"]
cuts &lt;- c(bm.cut$cut1, bm.cut$cut2)
# Definiere Bereiche: Minimaler Personenparameter bis Cut-Score 1, 
#   Cut-Score 1 bis Cut-Score 2, Cut-Score 2 bis maximaler 
#   Personenparameter
Cuts.Vec &lt;- c(min(Pers.Para)-1, cuts, max(Pers.Para)+1)
# Teile Personenparameter in entsprechende Bereiche auf
Kum.Cuts &lt;- cut(Pers.Para, breaks = Cuts.Vec)
# Verteilung auf die einzelnen Bereiche
Freq.Pers.Para &lt;- xtabs(~ Kum.Cuts)
nstud &lt;- nrow(sdat)
# Prozent-Berechnung
prozent &lt;- round(as.numeric(Freq.Pers.Para / nstud * 100), 
                 digits = 2) 
(Impact.Data &lt;- data.frame("Stufe" = c("A1", "A2", "B1"), 
                           "Prozent" = prozent))


## -------------------------------------------------------------
## Abschnitt 3.3.2: Daten aus der Contrasting-Groups-Methode
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 3.3.2, Listing 1: Cut-Scores
#

raterID &lt;- grep("R", colnames(productive), value = TRUE) 
nraters &lt;- length(raterID)  
nscripts &lt;- nrow(productive) 
# Berechne Cut-Score für jeden Rater
cutscore &lt;- data.frame("rater"=raterID, "cut1.ges"=NA)
for(ii in 1:length(raterID)){ 
  rater &lt;- raterID[ii]   
  rates.ii &lt;- productive[ ,grep(rater, colnames(productive))]   
  mean0.ii &lt;- mean(productive$Performance[rates.ii == 0], 
    na.rm = TRUE)   
  mean1.ii &lt;- mean(productive$Performance[rates.ii == 1], 
    na.rm = TRUE)   
  mean.ii &lt;- mean(c(mean1.ii, mean0.ii), na.rm = TRUE)   
  cutscore[ii, "cut1.ges"] &lt;- mean.ii }
# Finaler Cut-Score
cut1 &lt;- mean(cutscore$cut1.ges)
sd.cut1 &lt;- sd(cutscore$cut1.ges)
se.cut1 &lt;- sd.cut1/sqrt(nraters)


## -------------------------------------------------------------
## Appendix: Abbildungen
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abbildung 3.1
#

# 1. Grafik
par(fig=c(0, 1, 0, 0.35), oma=c(0,0,3,0), cex = 0.85) 
boxplot(Kappa.Stat$MW_Kappa, horizontal = T, ylim=c(0.42,0.66), 
        axes = F, xlab = "MW Kappa")
# 2. Grafik wird hinzugefügt
par(fig=c(0, 1, 0.2, 1), new=TRUE)
sd.factor &lt;- 1.5 
mmw &lt;- mean(Kappa.Stat$MW_Kappa)
sdmw &lt;- sd(Kappa.Stat$MW_Kappa)
#Grenzwerte für MW und SD werden festgelegt
mwind &lt;- c(mmw-(sd.factor*sdmw), mmw+(sd.factor*sdmw))
plot(Kappa.Stat$MW_Kappa, Kappa.Stat$SD_Kappa, xlab = "",
     ylab = "SD Kappa", type = "n", xlim = c(0.42, 0.66), 
     ylim = c(0, 0.2))
abline(v = mwind, col="grey", lty = 2)
# Rater mit 1.5 SD Abweichung vom MW werden grau markiert 
abw.rater &lt;- which(Kappa.Stat$MW_Kappa &lt; mwind[1] | 
                     Kappa.Stat$MW_Kappa &gt; mwind[2])
points(Kappa.Stat$MW_Kappa[-abw.rater], 
       Kappa.Stat$SD_Kappa[-abw.rater], 
       pch = 19)
points(Kappa.Stat$MW_Kappa[abw.rater], 
       Kappa.Stat$SD_Kappa[abw.rater], 
       pch = 25, bg = "grey")
text(Kappa.Stat$MW_Kappa[abw.rater], 
     Kappa.Stat$SD_Kappa[abw.rater], 
     Kappa.Stat$Person[abw.rater], 
     pos = 3) 
title("Rater-Analysen: MW und SD Kappa aus der IDM-Methode", 
      outer = TRUE)

# -------------------------------------------------------------
# Abbildung 3.2
#

nitems &lt;- 60

library(lattice)
library(gridExtra)
#Erster Plot mit Mittelwert
plot.Cut1 &lt;- dotplot(bookmarks$Rater ~ bookmarks$Cut1, col = "black", 
                     panel = function(...){
                       panel.dotplot(...)
                       panel.abline(v = mean(bookmarks$Cut1), lty = 5)
                     }, 
                     xlab = "Bookmarks für Cut-Score 1 (Seite im OIB)",
                     ylab = "Raters", cex = 1.3)
#Zweiter Plot mit Mittelwert
plot.Cut2 &lt;- dotplot(bookmarks$Rater ~ bookmarks$Cut2, col = "black", 
                     panel = function(...){
                       panel.dotplot(...)
                       panel.abline(v = mean(bookmarks$Cut2), lty = 5)
                     }, 
                     xlab = "Bookmarks für Cut-Score 2 (Seite im OIB)", 
                     ylab = "Raters", cex = 1.3)
#Plots nebeneinander anordnen
grid.arrange(plot.Cut1, plot.Cut2, nrow = 1, top = "Bookmarks pro Rater/in")


## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+204'>Kapitel 4: Differenzielles Itemfunktionieren in Subgruppen</h2><span id='topic+Kapitel+204'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 4, <em>Differenzielles Itemfunktionieren 
in Subgruppen</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Author(s)</h3>

<p>Matthias Trendtel, Franziska Schwabe, Robert Fellinger
</p>


<h3>References</h3>

<p>Trendtel, M., Schwabe, F. &amp; Fellinger, R. (2016). Differenzielles 
Itemfunktionieren in Subgruppen. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 111&ndash;147). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel04">datenKapitel04</a></code>, den im Kapitel verwendeten Daten.<br />

Zurück zu <code><a href="#topic+Kapitel+203">Kapitel 3</a></code>, Standard-Setting.<br />
Zu <code><a href="#topic+Kapitel+205">Kapitel 5</a></code>, Testdesign.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(difR)
library(mirt)
library(sirt)
library(TAM)
set.seed(12345)

data(datenKapitel04)
dat &lt;- datenKapitel04$dat
dat.th1 &lt;- datenKapitel04$dat.th1
ibank &lt;- datenKapitel04$ibank

## -------------------------------------------------------------
## Abschnitt 4.4.1 DIF-Analysen für vollständige Daten
## -------------------------------------------------------------

items.th1 &lt;- grep("E8R", colnames(dat.th1), value=T)
resp &lt;- dat.th1[, items.th1]
AHS &lt;- dat.th1$AHS

# -------------------------------------------------------------
# Abschnitt 4.4.1, Listing 1: Mantel-Haenszel
#

difMH(Data = resp, group = AHS, correct = F, focal.name = 0)

# -------------------------------------------------------------
# Abschnitt 4.4.1, Listing 2: Standardisierte p-Wert Differenzen
#

difStd(Data = resp, group = AHS, focal.name = 0)

# -------------------------------------------------------------
# Abschnitt 4.4.1, Listing 3: SIBTEST
#

SIBTEST(dat = resp, group = AHS, focal_name = 0, 
        focal_set = grep("E8RS03131", items.th1))
SIBTEST(dat = resp, group = AHS, focal_name=0,
        focal_set = grep("E8RS15621", items.th1))

# -------------------------------------------------------------
# Abschnitt 4.4.1, Listing 4: Methode nach Lord
#

difLord(Data = resp, group = AHS, focal.name = 0,
        model = "1PL")

# -------------------------------------------------------------
# Abschnitt 4.4.1, Listing 5: Zusammenschau
#

dichoDif(Data = resp, group = AHS, correct = F, focal.name = 0, 
         method = c("MH", "Std", "Lord"), model = "1PL")


## -------------------------------------------------------------
## Abschnitt 4.4.2 DIF-Analysen für unvollständige Daten
## -------------------------------------------------------------

items &lt;- grep("E8R", colnames(dat), value = T)
resp &lt;- dat[ ,items]
AHS &lt;- dat$AHS

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 1: Matching-Variable setzen
#

score &lt;- rowSums(resp, na.rm=T)

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 2: Durchführung Logistische Regression
#

difLR &lt;- dif.logistic.regression(resp, group = AHS, score = score)

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 3: Durchführung Logistische Regression
#                             mit angepasster Referenzgruppe
#

difLR &lt;- dif.logistic.regression(resp, AHS==0, score)

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 4: Ausgabe erster Teil
#

cbind(item = difLR$item, round(difLR[, 4:13], 3))

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 5: Ausgabe zweiter Teil
#

cbind(difLR[, c(3,14:16)], sign = difLR[, 17], ETS = difLR[, 18]) 

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 6: DIF-Größen
#

table(difLR[, 17], difLR[, 18])

difLR[c(10, 18), c(3, 14, 17:18)]

# -------------------------------------------------------------
# Abschnitt 4.4.2, Listing 7: Ausgabe dritter Teil
#

cbind(difLR[, c(3, 21:23)], sign=difLR[, 24])


## -------------------------------------------------------------
## Abschnitt 4.4.3 Hypothesenprüfung mit GLMM
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 1: Itemauswahl
#

HO.items &lt;- ibank[ibank$format == "ho", "task"]

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 2: Facettenidentifikation
#

facets &lt;- data.frame(AHS = dat$AHS)
form &lt;- formula( ~ item * AHS)

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 3: Initiierung des Designs
#

design &lt;- designMatrices.mfr(resp = dat[, items], 
                             formulaA = form, facets = facets)

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 4: Übergabe der Designmatrix und des
#                             erweiterten Responsepatterns
#

A &lt;- design$A$A.3d[, , 1:(length(items) + 2)]
dimnames(A)[[3]] &lt;- c(items, "AHS", "HO:AHS")
resp &lt;- design$gresp$gresp.noStep

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 5: Ausgabe der ersten Zeilen des 
#                             Responsepatterns
#

head(resp)

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 6: Identifikation Itemformat X Gruppe
#

HO.AHS0 &lt;- paste0(HO.items, "-AHS0")
HO.AHS1 &lt;- paste0(HO.items, "-AHS1")

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 7: Spezifizierung des Designs
#

A[, , "HO:AHS"] &lt;- 0
A[HO.AHS0, 2, "HO:AHS"] &lt;- -1; A[HO.AHS1, 2, "HO:AHS"] &lt;-  1

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 8: Ausgabe der Designmatrix für 
#                             Itemkategorie 'richtig beantwortet'
#

A[,2,c("AHS", "HO:AHS")]

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 9: Schätzen des Modells
#

mod &lt;- tam.mml(resp = resp, A=A)

# -------------------------------------------------------------
# Abschnitt 4.4.3, Listing 10: Ausgabe der Parameterschätzer
#

summary(mod)

## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+205'>Kapitel 5: Testdesign</h2><span id='topic+Kapitel+205'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 5, <em>Testdesign</em>, im Herausgeberband 
Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Author(s)</h3>

<p>Thomas Kiefer, Jörg-Tobias Kuhn, Robert Fellinger
</p>


<h3>References</h3>

<p>Kiefer, T., Kuhn, J.-T. &amp; Fellinger, R. (2016). Testdesign. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 149&ndash;184). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zurück zu <code><a href="#topic+Kapitel+204">Kapitel 4</a></code>, Differenzielles Itemfunktionieren in 
Subgruppen.<br />
Zu <code><a href="#topic+Kapitel+206">Kapitel 6</a></code>, Skalierung und Linking.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(tensor)
set.seed(1337)

data(datenKapitel05)
dat.ib &lt;- datenKapitel05$tdItembank
dat.bib &lt;- datenKapitel05$tdBib2d
dat.bibPaare &lt;- datenKapitel05$tdBibPaare

## -------------------------------------------------------------
## Abschnitt 5.3.2: ATA Methode für das Blockdesign
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 1: Initialisierung
#

library(tensor)

nTh &lt;- 30
nPos &lt;- 6
nBl &lt;- 30
inc &lt;- array(0, dim = c(nTh, nPos, nBl))

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 2: Startdesign
#

for(tt in 1:nTh){
  inc[tt, , sample(1:nBl, nPos)] &lt;- diag(1, nPos)
}

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 3: Zielfunktion
#
des &lt;- inc
desAllePos &lt;- tensor(des, rep(1, nPos), 2, 1)

blockPaarInd &lt;- upper.tri(diag(nrow = nBl))
blockPaar &lt;- crossprod(desAllePos)[blockPaarInd]

err.bb &lt;- blockPaar
err.bb[blockPaar &gt;= 2] &lt;- blockPaar[blockPaar &gt;= 2] - 2
err.bb[blockPaar &lt;= 1] &lt;- 1 - blockPaar[blockPaar &lt;= 1]

objective &lt;- sum(err.bb) / length(err.bb)
objWgt &lt;- 2^0

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 4: Studienzuweisung
#

blMatching &lt;- seq(6, nBl, 6)

nbStatus &lt;- list(
  (desAllePos[1:6, -(1:12)] &gt; 0) / (6 * 18),      # 1
  (desAllePos[25:30, -(19:30)] &gt; 0) / (6 * 18),   # 2
  (rowSums(desAllePos[, blMatching]) != 1) / nTh  # 3
)
nbStatus &lt;- unlist(lapply(nbStatus, sum))

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 5: Erweiterung Positionsbalancierung
#

# 4
nbPos &lt;- sum((colSums(des) != 1) / (nPos * nBl))
# 5
nbPos.pLSA &lt;- list(
  (colSums(des[1:6, 1:2, 1:12], dims = 2) != 1) / 12,
  (colSums(des[1:6, 3:4, 1:12], dims = 2) != 1) / 12,
  (colSums(des[1:6, 5:6, 1:12], dims = 2) != 1) / 12
)
nbPos.pLSA &lt;- sum(unlist(lapply(nbPos.pLSA, sum)) / 3)
# 6
nbPos.link &lt;- list(
  (colSums(des[25:30, 1:2, 19:30], dims = 2) != 1) / 12,
  (colSums(des[25:30, 3:4, 19:30], dims = 2) != 1) / 12,
  (colSums(des[25:30, 5:6, 19:30], dims = 2) != 1) / 12
)
nbPos.link &lt;- sum(unlist(lapply(nbPos.link, sum)) / 3)

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 6: Zusammenfügen
#

nb &lt;- c(nbStatus, nbPos, nbPos.pLSA, nbPos.link)
nbWgt &lt;- c(
  rep(2^5, length(nbStatus)),
  rep(2^6, length(nbPos)),
  rep(2^4, length(nbPos.pLSA)),
  rep(2^3, length(nbPos.link))
)

nbWgt.norm &lt;- nbWgt / (sum(nbWgt) + objWgt)
objWgt.norm &lt;- objWgt / (sum(nbWgt) + objWgt)
oDes &lt;- objWgt.norm %*% objective + nbWgt.norm %*% nb

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 6a: Ergänzung zum Buch
# 
#

fit &lt;- function(des){
  desAllePos &lt;- tensor(des, rep(1, nPos), 2, 1)
  
  #
  blockPaarInd &lt;- upper.tri(diag(nrow = nBl))
  blockPaar &lt;- crossprod(desAllePos)[blockPaarInd]
  
  err.bb &lt;- blockPaar
  err.bb[blockPaar &gt;= 2] &lt;- blockPaar[blockPaar &gt;= 2] - 2
  err.bb[blockPaar &lt;= 1] &lt;- 1 - blockPaar[blockPaar &lt;= 1]
  
  objective &lt;- sum(err.bb) / length(err.bb)
  objWgt &lt;- 2^0
  
  #
  nbStatus &lt;- list(
    (desAllePos[1:6, -(1:12)] &gt; 0) / (6 * 18),      # 1
    (desAllePos[25:30, -(19:30)] &gt; 0) / (6 * 18),   # 2
    (rowSums(desAllePos[, blMatching]) != 1) / nTh  # 3
  )
  nbStatus &lt;- unlist(lapply(nbStatus, sum))
  
  # 4
  nbPos &lt;- sum((colSums(des) != 1) / (nPos * nBl))
  # 5
  nbPos.pLSA &lt;- list(
    (colSums(des[1:6, 1:2, 1:12], dims = 2) != 1) / 12,
    (colSums(des[1:6, 3:4, 1:12], dims = 2) != 1) / 12,
    (colSums(des[1:6, 5:6, 1:12], dims = 2) != 1) / 12
  )
  nbPos.pLSA &lt;- sum(unlist(lapply(nbPos.pLSA, sum)) / 3)
  # 6
  nbPos.link &lt;- list(
    (colSums(des[25:30, 1:2, 19:30], dims = 2) != 1) / 12,
    (colSums(des[25:30, 3:4, 19:30], dims = 2) != 1) / 12,
    (colSums(des[25:30, 5:6, 19:30], dims = 2) != 1) / 12
  )
  nbPos.link &lt;- sum(unlist(lapply(nbPos.link, sum)) / 3)
  
  #
  nb &lt;- c(nbStatus, nbPos, nbPos.pLSA, nbPos.link)
  nbWgt &lt;- c(
    rep(2^5, length(nbStatus)),
    rep(2^6, length(nbPos)),
    rep(2^4, length(nbPos.pLSA)),
    rep(2^3, length(nbPos.link))
  )
  nbWgt.norm &lt;- nbWgt / (sum(nbWgt) + objWgt)
  objWgt.norm &lt;- objWgt / (sum(nbWgt) + objWgt)
  oDes &lt;- objWgt.norm %*% objective + nbWgt.norm %*% nb
  
  return(oDes)
}

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 7: Initialisierung des Algorithmus
#

# t &lt;- 1; t.min &lt;- 1e-5; c &lt;- 0.7; L &lt;- 10000; l &lt;- 1
t &lt;- 1; tMin &lt;- 1e-5; c &lt;- 0.9; L &lt;- 100000; l &lt;- 1

fitInc &lt;- fit(inc)

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 8: Störung
#

thisTh &lt;- (l - 1) %% nTh + 1
child &lt;- inc

bloeckeTh &lt;- which(colSums(child[thisTh, , ]) == 1)
raus &lt;- sample(bloeckeTh, 1)
rein &lt;- sample(setdiff(1:nBl, bloeckeTh), 1)

child[thisTh, , rein] &lt;- child[thisTh, , raus]
child[thisTh, , raus] &lt;- 0


# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 9: Survival
#

fitChild &lt;- fit(child)

behalte &lt;- fitChild &lt; fitInc
if(!behalte){
  pt &lt;- exp(-(fitChild - fitInc) / t)
  behalte &lt;- runif(1) &lt;= pt
}

if(behalte){
  inc &lt;- child
  fitInc &lt;- fitChild
}

# -------------------------------------------------------------
# Abschnitt 5.3.2, Listing 9a: Ergänzung zum Buch
# 

# Achtung: Algorithmus benötigt einige Zeit.
# Je nach Wahl der Lauf-Parameter in Abschnitt 5.3.2, Listing 7, kann der 
# folgende Prozess bis zu ein paar Stunden dauern.

start &lt;- Sys.time()
best &lt;- list(inc, fitInc)
while(t &gt; tMin){
  while(l &lt; L){
    thisTh &lt;- (l - 1) %% nTh + 1
    child &lt;- inc
    
    # Perturbation 
    bloeckeTh &lt;- which(colSums(child[thisTh, , ]) == 1)
    raus &lt;- sample(bloeckeTh, 1)
    rein &lt;- sample(setdiff(1:nBl, bloeckeTh), 1)
    
    child[thisTh, , rein] &lt;- child[thisTh, , raus]
    child[thisTh, , raus] &lt;- 0
    
    # Fit und Survival
    fitChild &lt;- fit(child)
    
    behalte &lt;- fitChild &lt; fitInc
    if(!behalte){
      pt &lt;- exp(-(fitChild - fitInc) / t)
      behalte &lt;- runif(1) &lt;= pt
    }
    
    if(behalte){
      inc &lt;- child
      fitInc &lt;- fitChild
    }
    
    # Kontroll-Ausgaben
    if(fitInc &lt; best[[2]]){
      best &lt;- list(inc, fitInc)
    }    
    
    if (l %% 500 == 0) {
      cat("\r")
      cat(paste("l=", l), 
          paste("t=", as.integer(log(t) / log(c) + 1)),
          paste("fit=", round(fitInc, 4)), 
          paste("pt=", round(pt, 5)),        
          sep=";   ")
      cat("                     ")
      flush.console()
    }
    l &lt;- l + 1
  }
  l &lt;- 1
  t &lt;- t * c
}
end &lt;- Sys.time()

tdBib2d &lt;- apply(inc, 1, function(bb){
  this &lt;- which(colSums(bb) &gt; 0)
  this[order((1:nrow(bb) %*% bb)[this])] 
})

## -------------------------------------------------------------
## Abschnitt 5.3.3: ATA Methode für die Item-zu-Block-Zuordnung
## -------------------------------------------------------------

set.seed(1338)

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 1: Initialisierung
#

nTh &lt;- nrow(dat.bib)
nPos &lt;- ncol(dat.bib)
nBl &lt;- length(unique(unlist(dat.bib)))
blMatching &lt;- seq(6, nBl, 6)

nI &lt;- nrow(dat.ib)
itemsMatching &lt;- which(dat.ib$format == "Matching")
itemsSonst &lt;- which(dat.ib$format != "Matching")

# -------------------------------------------------------------
# Abschnitt 3.3, Listing 2: Startdesign
#

inc &lt;- array(0, dim = c(nI, nBl))
for(bb in blMatching){
  inc[sample(itemsMatching, 2), bb] &lt;- 1
}
for(bb in setdiff(1:nBl, blMatching)){
  inc[sample(itemsSonst, 7), bb] &lt;- 1
}

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 3: Testheftebene
#

des &lt;- inc
desTh &lt;- des[, dat.bib[, 1]] + des[, dat.bib[, 2]] + 
  des[, dat.bib[, 3]] + des[, dat.bib[, 4]] + 
  des[, dat.bib[, 5]] + des[, dat.bib[, 6]]

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 4: IIF
#

theta &lt;- c(380, 580)
InfoItem &lt;- dat.ib[,grep("IIF", colnames(dat.ib))]
TIF &lt;- (t(InfoItem) %*% desTh) / 37

objective &lt;- - sum(TIF) / prod(dim(TIF))
objWgt &lt;- 2^0

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 5: KEY
#

nbKey &lt;- list(
  (colSums(desTh &gt; 1) &gt; 0) / nTh,              # 7
  ((rowSums(desTh[, 1:6]) &gt; 0) +               # 8
     (rowSums(desTh[, 25:30]) &gt; 0) &gt; 1) / nI  
)
nbKey &lt;- unlist(lapply(nbKey, sum))
nbWgt &lt;- 2^c(7, 6)

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 6: Kategorial
#

# 9
zFocus.block &lt;- c(0, 1, 1, 1, 1, 2, 0)
gFocus.block &lt;- rowsum(des[, -blMatching], dat.ib$focus) - 
  zFocus.block
# 10
zFocus.form &lt;- c(2, 6, 6, 6, 6, 13, 1)
gFocus.form &lt;- rowsum(desTh, dat.ib$focus) - zFocus.form
# 11
gTopic.form &lt;- rowsum(desTh, dat.ib$topic) - 4

nbKonstrukt &lt;- list(
  colSums(gFocus.block &lt; 0) / prod(dim(gFocus.block)), 
  colSums(gFocus.form &gt; 0) / prod(dim(gFocus.form)), 
  colSums(gTopic.form &gt; 0) / 30
)
nbKonstrukt &lt;- unlist(lapply(nbKonstrukt, sum))
nbWgt &lt;- c(nbWgt, 2^c(4, 4, 3))

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 7: Stetig
#

length.form &lt;- ((dat.ib$audiolength + 13) %*% desTh) / 60
nbStetig &lt;- list(
  (length.form &gt; 32) / length(length.form),
  (length.form &lt; 28) / length(length.form)
)
nbStetig &lt;- unlist(lapply(nbStetig, sum))
nbWgt &lt;- c(nbWgt, 2^c(3, 2))

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 8: Perturbation
#

thisBl &lt;- 1
child &lt;- inc

items.raus &lt;- which(child[, thisBl] == 1)
raus &lt;- sample(items.raus, 1)

bibPaar.bl &lt;- dat.bibPaare[thisBl, ] != 0
items.bibPaare &lt;- rowSums(child[, bibPaar.bl]) &gt; 0
rein &lt;- which(!items.bibPaare)

if(thisBl %in% blMatching){
  rein &lt;- sample(intersect(rein, itemsMatching), 1)
}else{
  rein &lt;- sample(intersect(rein, itemsSonst), 1)
}  

child[c(raus, rein), thisBl] &lt;- c(0, 1)

# -------------------------------------------------------------
# Abschnitt 5.3.3, Listing 8a: Ergänzung zum Buch
#                              Vollständige Umsetzung
# 

# Achtung: Algorithmus benötigt einige Zeit.
# Je nach Wahl der Lauf-Parameter im nachfolgenden Abschnitt, kann der 
# Prozess bis zu einigen Stunden dauern.

fit &lt;- function(des, dat.ib, dat.bib){
  desTh &lt;- des[, dat.bib[, 1]] + des[, dat.bib[, 2]] + 
    des[, dat.bib[, 3]] + des[, dat.bib[, 4]] + 
    des[, dat.bib[, 5]] + des[, dat.bib[, 6]]
  
  #
  TIF &lt;- (t(InfoItem) %*% desTh) / 37
  
  objective &lt;- - sum(TIF) / prod(dim(TIF))
  objWgt &lt;- 2^0
  
  #
  nbKey &lt;- list(
    (colSums(desTh &gt; 1) &gt; 0) / nTh,              # 7
    ((rowSums(desTh[, 1:6]) &gt; 0) +               # 8
       (rowSums(desTh[, 25:30]) &gt; 0) &gt; 1) / nI  
  )
  nbKey &lt;- unlist(lapply(nbKey, sum))
  nbWgt &lt;- 2^c(7, 6)
  
  # 9
  zFocus.block &lt;- c(0, 1, 1, 1, 1, 2, 0)
  gFocus.block &lt;- rowsum(des[, -blMatching], dat.ib$focus) - 
    zFocus.block
  # 10
  zFocus.form &lt;- c(2, 6, 6, 6, 6, 13, 1)
  gFocus.form &lt;- rowsum(desTh, dat.ib$focus) - zFocus.form
  # 11
  gTopic.form &lt;- rowsum(desTh, dat.ib$topic) - 4
  
  nbKonstrukt &lt;- list(
    colSums(gFocus.block &lt; 0) / prod(dim(gFocus.block)), 
    colSums(gFocus.form &gt; 0) / prod(dim(gFocus.form)), 
    colSums(gTopic.form &gt; 0) / 30
  )
  nbKonstrukt &lt;- unlist(lapply(nbKonstrukt, sum))
  nbWgt &lt;- c(nbWgt, 2^c(4, 4, 3))
  
  #
  length.form &lt;- ((dat.ib$audiolength + 13) %*% desTh) / 60
  nbStetig &lt;- list(
    (length.form &gt; 32) / length(length.form),
    (length.form &lt; 28) / length(length.form)
  )
  nbStetig &lt;- unlist(lapply(nbStetig, sum))
  nbWgt &lt;- c(nbWgt, 2^c(3, 2))
  
  #
  nb &lt;- c(nbKey, nbKonstrukt, nbStetig)
  
  nbWgt.norm &lt;- nbWgt / (sum(nbWgt) + objWgt)
  objWgt.norm &lt;- objWgt / (sum(nbWgt) + objWgt)
  oDes &lt;- objWgt.norm %*% objective + nbWgt.norm %*% nb
  
  return(oDes)
}

#
# t &lt;- 1; tMin &lt;- 1e-5; c &lt;- 0.7; L &lt;- 10000; l &lt;- 1
# t &lt;- 1; tMin &lt;- 1e-5; c &lt;- 0.8; L &lt;- 25000; l &lt;- 1
# t &lt;- 1; tMin &lt;- 1e-5; c &lt;- 0.9; L &lt;- 50000; l &lt;- 1
t &lt;- 1; tMin &lt;- 1e-7; c &lt;- 0.9; L &lt;- 100000; l &lt;- 1

#
fitInc &lt;- fit(inc, dat.ib, dat.bib)
best &lt;- list(inc, fitInc)
vers &lt;- versBest &lt;- 1
#
start &lt;- Sys.time()
while(t &gt; tMin){
  while(l &lt; L){
    thisBl &lt;- (l - 1) %% nBl + 1
    
    # Perturbation 
    child &lt;- inc
    
    items.raus &lt;- which(child[, thisBl] == 1)
    raus &lt;- sample(items.raus, 1)
    
    bibPaar.bl &lt;- dat.bibPaare[thisBl, ] != 0
    items.bibPaare &lt;- rowSums(child[, bibPaar.bl]) &gt; 0
    rein &lt;- which(!items.bibPaare)
    
    if(thisBl %in% blMatching){
      rein &lt;- sample(intersect(rein, itemsMatching), 1)
    }else{
      rein &lt;- sample(intersect(rein, itemsSonst), 1)
    }  
    
    child[c(raus, rein), thisBl] &lt;- c(0, 1)
    
    # Fit und Survival
    fitChild &lt;- fit(child, dat.ib, dat.bib)
    
    behalte &lt;- fitChild &lt; fitInc
    if(!behalte){
      pt &lt;- exp((fitInc - fitChild) / t)
      behalte &lt;- runif(1) &lt;= pt
    }
    
    if(behalte){
      inc &lt;- child
      fitInc &lt;- fitChild
    }
    
    if(fitInc &lt; best[[2]]){
      best &lt;- list(inc, fitInc)
      versBest &lt;- versBest + 1
    }    
    
    # Kontroll-Ausgaben; ggf. löschen
    if (identical(inc, child)) vers &lt;- vers + 1
    if (l %% 500 == 0) {
      cat("\r")
      cat(paste("l=", l), 
          paste("t=", as.integer(log(t) / log(c) + 1)),
          paste("versionen=", vers), 
          paste("versionenBest=", versBest), 
          paste("fit=", round(fitInc, 4)), 
          paste("fitBest=", round(best[[2]], 4)), 
          paste("pt=", round(pt, 5)),        
          sep=";   ")
      cat("                     ")
      flush.console()
    }
    l &lt;- l + 1
  }
  l &lt;- 1
  t &lt;- t * c
}
end &lt;- Sys.time()

## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+206'>Kapitel 6: Skalierung und Linking</h2><span id='topic+Kapitel+206'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 6, <em>Skalierung und Linking</em>, im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Author(s)</h3>

<p>Matthias Trendtel, Giang Pham, Takuya Yanagida
</p>


<h3>References</h3>

<p>Trendtel, M., Pham, G. &amp; Yanagida, T. (2016). Skalierung und Linking.
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 185&ndash;224). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel06">datenKapitel06</a></code>, den im Kapitel verwendeten Daten.<br />

Zurück zu <code><a href="#topic+Kapitel+205">Kapitel 5</a></code>, Testdesign.<br />
Zu <code><a href="#topic+Kapitel+207">Kapitel 7</a></code>, Statistische Analysen produktiver Kompetenzen.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(TAM)
library(sirt)
library(WrightMap)
library(miceadds)
library(plyr)
set.seed(20150528)

dat &lt;- data(datenKapitel06)
# Hauptstudie
dat &lt;- datenKapitel06$dat
ue &lt;- datenKapitel06$itembank
items &lt;- grep("I", colnames(dat), value=TRUE)

# Nur TH1
datTH1 &lt;- datenKapitel06$datTH1
ueTH1 &lt;- datenKapitel06$itembankTH1
rownames(ueTH1) &lt;- ueTH1$Item
itemsTH1 &lt;- grep("I", colnames(datTH1), value=TRUE)
respTH1 &lt;- datTH1[, -(1:4)]; wTH1 &lt;- datTH1$wgtstud

# Normierungsstudie
normdat &lt;- datenKapitel06$normdat

## -------------------------------------------------------------
## Abschnitt 6.3.4 Das Partial Credit Model (PCM)
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.3.4, Listing 1: Leistungsdaten und Stich-
#                             probengewichte Objekten zuweisen
#

resp &lt;- dat[, grep("I", colnames(dat))]; w &lt;- dat$wgtstud

# -------------------------------------------------------------
# Abschnitt 6.3.4, Listing 2: Anpassen eines PCMs
#

mod.1PL &lt;- tam.mml(resp = resp, irtmodel = "1PL", pweights = w)

# -------------------------------------------------------------
# Abschnitt 6.3.4, Listing 2a: Ergänzung zum Buch
# Runden zur besseren Darstellung im Buch
#

mod.1PL$item$M &lt;- round(mod.1PL$item$M, 2)

# -------------------------------------------------------------
# Abschnitt 6.3.4, Listing 3: Darstellung des letzen Items
#

tail(mod.1PL$item, 1)

# -------------------------------------------------------------
# Abschnitt 6.3.4, Listing 4: Umparametrisierung
#

b_ih &lt;- mod.1PL$item[, grep("AXsi_", colnames(mod.1PL$item))]
delta.tau &lt;- pcm.conversion(b_ih)

# -------------------------------------------------------------
# Abschnitt 6.3.4, Listing 5: Berechnung der Thursonian 
#                             Threshods und Lokations Indizes
#

thurst.thres &lt;- IRT.threshold(mod.1PL)
LI &lt;- IRT.threshold(mod.1PL, type="item")


## -------------------------------------------------------------
## Abschnitt 6.3.5 Itemtrennschärfen polytomer Items und
##                 Rateparameter
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 1: Anpassen eines Generalized
#                             Partial Credit Models
# 

mod.GPCM &lt;- tam.mml.2pl(resp, irtmodel = "GPCM", pweights = w)

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 2: Anpassen eines 
#                             Nominal Item Response Models
# 

mod.NIRM &lt;- tam.mml.2pl(resp, irtmodel="2PL", pweights = w)

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 3: Anpassen eines Generalized 
#                             Partial Credit Models mit festen 
#                             Itemgewichten (Trennschärfen)
# 

tammodel &lt;- "
  LAVAAN MODEL:
  F =~ a1__a50*I1__I50;
  # Trait-Varianz auf 1 fixieren
  F ~~ 1*F
  MODEL CONSTRAINT:
  # Gewichtung für die Items festlegen
  a1__a40 == 1*a # dichotome Items
  a41__a44 == .3333*a # T/F Items mit max. Score von 3
  a45__a50 == .25*a # M56 Items mit max. Score von 4
  " 
mod.GPCMr &lt;- tamaan(tammodel, resp, pweights = w)

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 4: Itemtrennschärfevergleich
# 

## Itemparameter im Vergleich
rbind(GPCM = mod.GPCM$item[50, 9:12], 
      NIRM = mod.NIRM$item[50, 9:12],
      GPCMr = mod.GPCMr$item[50, 10:13]) / rep(c(1:4), each=3)

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 5: Itemtrennschärfen eines 
#                             dichotomen und eines polytomen 
#                             Items

rbind(I40 = mod.GPCMr$item[40, 10:13],
      I50 = mod.GPCMr$item[50, 10:13])

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 6: Anpassen eines 1PL-G Modells
#


## Das 1PL-G Modell
tammodel &lt;- "
  LAVAAN MODEL:
  F =~ 1*I1__I50
  F ~~ F
  # Rateparameter für MC4 Items
  I1__I10 ?= gMC4*g1
  # Rateparameter für MC3 Items
  I11__I20 + I31__I40 ?= gMC3*g1
  "
mod.1PL_G &lt;- tamaan(tammodel, resp, pweights = w, 
                    control = list(Msteps = 15))

# -------------------------------------------------------------
# Abschnitt 6.3.5, Listing 7: Ausgabe geschätzter Rateparameter
#                             für MC3 und MC4 Items
#

mod.1PL_G$item[c(10,11), c(1,4,5)]


## -------------------------------------------------------------
## Abschnitt 6.3.6 Bookleteffekte
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.3.6, Listing 1: Anpassen eines Bookletmodells
# 

mod.1PL_Book &lt;- tam.mml.mfr(resp, facets = cbind(th = dat$th), 
                 formulaA= ~ item + item:step + th, pweights = w)

# -------------------------------------------------------------
# Abschnitt 6.3.6, Listing 2: Ausgabe der Bookleteffekte der einzelnen
#                             Testhefte
# 

rbind((tmp &lt;- mod.1PL_Book$xsi[paste0("thER0", 1:5),]), 
      thER06 = - c(sum(tmp[,1]), NA))


## -------------------------------------------------------------
## Abschnitt 6.3.7 Personenfähigkeitsschätzer
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 1: WLEs
# 

WLE.1PL &lt;- as.data.frame(tam.wle(mod.1PL))
round(head(WLE.1PL, 2), 4)

# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 2: WLE Reliabilität
# 

WLErel(WLE.1PL$theta, WLE.1PL$error, w)

# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 3: EAPs
# 

round(head(mod.1PL$person, 2), 4)

# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 4: EAP Reliabilität
# 

EAPrel(mod.1PL$person$EAP, mod.1PL$person$SD.EAP, w)

# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 4a: Ergänzung zum Buch
# Alternative Berechnung der EAP-Reliabilität
#

1 - weighted.mean(mod.1PL$person$SD.EAP^2, w)/mod.1PL$variance


# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 5: PVs
# 

PV.1PL &lt;- tam.pv(mod.1PL)$pv
round(head(PV.1PL, 2), 4)

# -------------------------------------------------------------
# Abschnitt 6.3.7, Listing 6: Statistische Kennwerte der einzelnen
#                             Personenfähigkeitsschätzer
# 

cbind(WLEs = c(M = weighted.mean(WLE.1PL$theta, w),
               SD = weighted_sd(WLE.1PL$theta, w)),
      EAPs = c(M = weighted.mean(mod.1PL$person$EAP, w),
               SD = weighted_sd(mod.1PL$person$EAP, w)),
      PVs = c(M = mean(apply(PV.1PL[, -1], 2, weighted.mean, w)),
              SD=mean(apply(PV.1PL[, -1], 2, weighted_sd, w))))


## -------------------------------------------------------------
## Abschnitt 6.3.8 Mehrdimensionale Modelle
## -------------------------------------------------------------

# Achtung: Algorithmen benötigen einige Zeit
# Zur schnelleren Konvergenz werden nur Daten aus Testheft 1 verwendet

# -------------------------------------------------------------
# Abschnitt 6.3.8, Listing 1: Verteilung der Items auf Foki 
# 

table(paste("Fokus", ue$focus[ue$Item %in% colnames(datTH1)]))
table(paste("Fokus", ueTH1$focus))

# -------------------------------------------------------------
# Abschnitt 6.3.8, Listing 2: Spezifizierung der Q-Matrix und 
#                             Anpassung des Modells
#                             Achtung: Schätzung benötigt &gt; 300 Iterationen
# 

Q &lt;- array(0, c(25, 5), list(items[items %in% colnames(datTH1)]))
for(i in 1:25) Q[i, ueTH1$focus[i] + 1] &lt;- 1
mod.1PL_multi &lt;- tam(resp = respTH1, pweights = wTH1,
                     Q = Q, control = list(snodes = 1500))

# -------------------------------------------------------------
# Abschnitt 6.3.8, Listing 3: Anpassen eines Bifaktormodells
#                             Achtung: Schätzung benötigt &gt; 350 Iterationen
# 

mod.1PL_bi &lt;- tam.fa(respTH1, irtmodel = "bifactor1", 
                dims = ueTH1$format, pweights = wTH1, 
                control = list(snodes = 1500))

# -------------------------------------------------------------
# Abschnitt 6.3.8, Listing 4: Darstellung der Varianzen des 
#                             Hauptfaktors und der Störfaktoren
# 

nams &lt;- c("I26", "I45", "I12", "I1", "I41")
dfr &lt;- data.frame(mod.1PL_bi$B.stand[nams,],
                  row.names=ueTH1[nams, "format"])
dfr

# -------------------------------------------------------------
# Abschnitt 6.3.8, Listing 5: Darstellung der Reliabilitätsschätzer
# 

mod.1PL_bi$meas


## -------------------------------------------------------------
## Abschnitt 6.3.9 Modellpassung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.3.9, Listing 1: Berechnung und Darstellungen von 
#                             Itemfitstatistiken
# 

itemfit &lt;- tam.fit(mod.1PL)
summary(itemfit)

# -------------------------------------------------------------
# Abschnitt 6.3.9, Listing 2: Berechnung und Darstellungen von 
#                             Modellfitstatistiken
# 

modfit &lt;- tam.modelfit(mod.1PL)
modfit$fitstat

# -------------------------------------------------------------
# Abschnitt 6.3.9, Listing 3: LRT für Modelltestung
# 

anova(mod.1PL, mod.GPCM)


## -------------------------------------------------------------
## Abschnitt 6.4.1 Simultane Kalibrierung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.4.1, Listing 1: Daten vorbereiten
#

vars &lt;- c("idstud", "wgtstud", "th")
# Daten der Hauptstudie
tmp1 &lt;- cbind("Hauptstudie" = 1, dat[,c(vars, items)])
# Daten der Normierungsstudie
n.items &lt;- grep("I|J",names(normdat),value=T)
tmp2 &lt;- cbind("Hauptstudie" = 0, normdat[, c(vars, n.items)])
# Schülergewichte der Normierungsstudie sind konstant 1
# Datensätze zusammenfügen
dat.g &lt;- rbind.fill(tmp1,tmp2)
all.items &lt;- grep("I|J",names(dat.g),value=T)

# -------------------------------------------------------------
# Abschnitt 6.4.1, Listing 2: Simultane Kalibrierung
#                             Achtung: Schätzung benötigt &gt; 450 Iterationen
#

# 2-Gruppenmodell
linkmod1 &lt;-  tam.mml(resp=dat.g[, all.items], pid=dat.g[, 2], 
              group = dat.g$Hauptstudie, pweights=dat.g$wgtstud)
summary(linkmod1)

# -------------------------------------------------------------
# Abschnitt 6.4.1, Listing 2a: Ergänzung zum Buch
# Berechnung von Verteilungsparametern
#

set.seed(20160828)

# PVs
PV_linkmod1 &lt;- tam.pv(linkmod1, nplausible = 20)

# Personendatensatz
dfr_linkmod1 &lt;- linkmod1$person
dfr_linkmod1 &lt;- merge( x = dfr_linkmod1, y = PV_linkmod1$pv, by = "pid" , all=T)
dfr_linkmod1 &lt;- dfr_linkmod1[ order(dfr_linkmod1$case) , ]

# Leistungsskala transformieren
vars.pv &lt;- grep("PV",names(dfr_linkmod1),value=T)
# Mittlere Fähigkeit der Normierungsgruppe
p0 &lt;- which(dat.g$Hauptstudie == 0)
M_PV &lt;- mean(apply(dfr_linkmod1[p0,vars.pv],2,Hmisc::wtd.mean,
                   weights = dfr_linkmod1[p0,"pweight"]))
SD_PV &lt;- mean(sqrt(apply(dfr_linkmod1[p0,vars.pv],2,Hmisc::wtd.var,
                         weights = dfr_linkmod1[p0,"pweight"])))
# Tranformationsparameter
a &lt;- 100/SD_PV; b &lt;- 500 - a*M_PV

# Verteilungsparameter der Hauptstudie
p1 &lt;- which(dat.g$Hauptstudie == 1)
M1_PV &lt;- mean(apply(dfr_linkmod1[p1,vars.pv],2,Hmisc::wtd.mean,
                    weights = dfr_linkmod1[p1,"pweight"]))
SD1_PV &lt;- mean(sqrt(apply(dfr_linkmod1[p1,vars.pv],2,Hmisc::wtd.var,
                          weights = dfr_linkmod1[p1,"pweight"])))
TM_PV &lt;- M1_PV*a + b; TSD_PV &lt;- SD1_PV*a

# Ergebnisse
trafo_linkmod1 &lt;- data.frame(M_Norm = 500, SD_Norm = 100, a = a, b = b,
                             M = TM_PV, SD = TSD_PV)


## -------------------------------------------------------------
## Abschnitt 6.4.2 Separate Kalibrierung mit fixiertem 
##                 Itemparameter
## -------------------------------------------------------------


# Vorgehensweise 1: 
# Daten der Normierungsstudie frei kalibrieren und skalieren
# Skalierung der Hauptstudie-Daten mit fixiertem Itemparameter

# -------------------------------------------------------------
# Abschnitt 6.4.2, Listing 1: Daten der Normierungsstudie frei 
#                             kalibrieren und skalieren
#

normmod &lt;- tam.mml(resp = normdat[, n.items], 
                   pid = normdat[, "idstud"])

# -------------------------------------------------------------
# Abschnitt 6.4.2, Listing 1a: Ergänzung zum Buch
# Berechnung von Verteilungsparametern
#

summary(normmod)

set.seed(20160828)

# Personenfähigkeitsschätzer
PV_normmod &lt;- tam.pv(normmod, nplausible = 20)
# In Personendatensatz kombinieren
dfr_normmod &lt;- normmod$person
dfr_normmod &lt;- merge( x = dfr_normmod, y = PV_normmod$pv, by = "pid" , all=T)
dfr_normmod &lt;- dfr_normmod[ order(dfr_normmod$case) , ]

M_norm &lt;- mean(apply(dfr_normmod[,vars.pv],2,Hmisc::wtd.mean,
                     weights = dfr_normmod[,"pweight"]))
SD_norm &lt;- mean(sqrt(apply(dfr_normmod[,vars.pv],2,Hmisc::wtd.var,
                           weights = dfr_normmod[,"pweight"])))
# Tranformationsparameter
a_norm &lt;- 100/SD_norm; b_norm &lt;- 500 - a_norm*M_norm

TM_norm &lt;- M_norm * a_norm + b_norm
TSD_norm &lt;- SD_norm * a_norm

# -------------------------------------------------------------
# Abschnitt 6.4.2, Listing 2: Parameter aus Normierungsstudie
#                             für die Skalierung der Haupt-
#                             studie bei deren Skalierung 
#                             fixieren
#

# Itemschwierigkeit aus der Normierungsstudie
norm.xsi &lt;- normmod$xsi.fixed.estimated
# Hauptstudie: xsi-Matrix aus mod.1PL
xsi.fixed &lt;- mod.1PL$xsi.fixed.estimated
# nur Parameter von Items in Hauptstudie
norm.xsi &lt;- norm.xsi[ 
  rownames(norm.xsi) %in% rownames(xsi.fixed), ]
# Setzen der Parameter in richtiger Reihenfolge
xsi.fixed &lt;- cbind(match(rownames(norm.xsi), 
                         rownames(xsi.fixed)), norm.xsi[, 2])
# Skalierung der Hauptstudie-Daten mit fixierten Itemparameter
mainmod.fixed &lt;- tam.mml(resp = resp, xsi.fixed = xsi.fixed,
                         pid = dat$MB_idstud, pweights = w)

# -------------------------------------------------------------
# Abschnitt 6.4.2, Listing 2a: Ergänzung zum Buch
# Berechnung von Verteilungsparametern
#

summary(mainmod.fixed)

set.seed(20160828)

# Personenfähigkeitsschätzer
WLE_mainmod.fixed &lt;- tam.wle(mainmod.fixed)
PV_mainmod.fixed &lt;- tam.pv(mainmod.fixed, nplausible = 20)
# In Personendatensatz kombinieren
dfr_mainmod.fixed &lt;- mainmod.fixed$person
dfr_mainmod.fixed &lt;- merge( x = dfr_mainmod.fixed, y = WLE_mainmod.fixed, by = "pid" , all=T)
dfr_mainmod.fixed &lt;- merge( x = dfr_mainmod.fixed, y = PV_mainmod.fixed$pv, by = "pid" , all=T)
dfr_mainmod.fixed &lt;- dfr_mainmod.fixed[ order(dfr_mainmod.fixed$case) , ]

M_main &lt;- mean(apply(dfr_mainmod.fixed[,vars.pv],2,Hmisc::wtd.mean,
                     weights = dfr_mainmod.fixed[,"pweight"]))
SD_main &lt;- mean(sqrt(apply(dfr_mainmod.fixed[,vars.pv],2,Hmisc::wtd.var,
                           weights = dfr_mainmod.fixed[,"pweight"])))

TM_main &lt;- M_main * a_norm + b_norm
TSD_main &lt;- SD_main * a_norm

trafo.fixed1 &lt;- data.frame(M_norm = M_norm, SD_norm = SD_norm,
                           a = a_norm, b = b_norm,
                           TM_norm = TM_norm, TSD_norm = TSD_norm,
                           M_PV = M_main, SD_PV = SD_main,
                           M_TPV = TM_main, SD_TPV = TSD_main)

# Vorgehensweise 2: 
# Daten der Hauptstudie frei kalibrieren und skalieren
# Skalierung der Hauptstudie-Daten mit fixierten Itemparameter

# -------------------------------------------------------------
# Abschnitt 6.4.2, Listing 2b: Ergänzung zum Buch
# Analoges Vorgehen mit fixierten Parametern aus der 
# Hauptstudie für die Skalierung der Normierungsstudie
#

# Daten der Hauptstudie kalibrieren und skalieren
mainmod &lt;- tam.mml(resp=dat[, items], irtmodel="1PL", 
                   pid=dat$MB_idstud, pweights=dat[,"wgtstud"])
summary(mainmod)

set.seed(20160828)

# Personenfähigkeitsschätzer
WLE_mainmod &lt;- tam.wle(mainmod)
PV_mainmod &lt;- tam.pv(mainmod, nplausible = 20)
# In Personendatensatz kombinieren
dfr_mainmod &lt;- mainmod$person
dfr_mainmod &lt;- merge( x = dfr_mainmod, y = WLE_mainmod, by = "pid" , all=T)
dfr_mainmod &lt;- merge( x = dfr_mainmod, y = PV_mainmod$pv, by = "pid" , all=T)
dfr_mainmod &lt;- dfr_mainmod[order(dfr_mainmod$case),]

M_main &lt;- mean(apply(dfr_mainmod[,vars.pv],2,Hmisc::wtd.mean,
                     weights = dfr_mainmod[,"pweight"]))
SD_main &lt;- mean(sqrt(apply(dfr_mainmod[,vars.pv],2,Hmisc::wtd.var,
                           weights = dfr_mainmod[,"pweight"])))


# Itemschwierigkeit aus der Hauptstudie
main.xsi &lt;- mod.1PL$xsi.fixed.estimated
# Hauptstudie: xsi-Matrix aus normmod
xsi.fixed &lt;- normmod$xsi.fixed.estimated
# nur Parameter von Items in Hauptstudie
main.xsi &lt;- main.xsi[ 
  rownames(main.xsi) %in% rownames(xsi.fixed), ]
# Setzen der Parameter in richtiger Reihenfolge
xsi.fixed &lt;- cbind(match(rownames(main.xsi), 
                         rownames(xsi.fixed)), main.xsi[, 2])

# Skalierung der Hauptstudie-Daten mit fixiertem Itemparameter
normmod.fixed &lt;- tam.mml(resp=normdat[, n.items], irtmodel="1PL", 
                         xsi.fixed = xsi.fixed,
                         pid=normdat$MB_idstud, pweights=normdat[,"wgtstud"])
summary(normmod.fixed)

set.seed(20160828)

# Personenfähigkeitsschätzer
PV_normmod.fixed &lt;- tam.pv(normmod.fixed, nplausible = 20)
dfr_normmod.fixed &lt;- normmod.fixed$person
dfr_normmod.fixed &lt;- merge( x = dfr_normmod.fixed, y = PV_normmod.fixed$pv, by = "pid" , all=T)
dfr_normmod.fixed &lt;- dfr_normmod.fixed[ order(dfr_normmod.fixed$case) , ]

M_norm &lt;- mean(apply(dfr_normmod.fixed[,vars.pv],2,Hmisc::wtd.mean,
                     weights = dfr_normmod.fixed[,"pweight"]))
SD_norm &lt;- mean(sqrt(apply(dfr_normmod.fixed[,vars.pv],2,Hmisc::wtd.var,
                           weights = dfr_normmod.fixed[,"pweight"])))

# Tranformationsparameter
a_norm &lt;- 100/SD_norm; b_norm &lt;- 500 - a_norm*M_norm

TM_norm &lt;- M_norm * a_norm + b_norm
TSD_norm &lt;- SD_norm * a_norm

TM_main &lt;- M_main * a_norm + b_norm
TSD_main &lt;- SD_main * a_norm

trafo.fixed2 &lt;- data.frame(M_PV = M_main, SD_PV = SD_main,
                           M_Norm.fixed = M_norm, SD_Norm.fixed = SD_norm,
                           a = a_norm, b = b_norm,
                           TM_norm = TM_norm, TSD_norm = TSD_norm,
                           M_TPV = TM_main, SD_TPV = TSD_main)


## -------------------------------------------------------------
## Abschnitt 6.4.3 Separate Kalibrierung mit Linking durch 
##                 Transformationsfunktion
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.4.3, Listing 1: equating.rasch()
#

# Freigeschätzte Itemparameter der Normierung- und Hauptstudie
norm.pars &lt;- normmod$item[,c("item","xsi.item")]
main.pars &lt;- mainmod$item[,c("item","xsi.item")]
# Linking mit equating.rasch
mod.equate &lt;- equating.rasch(x = norm.pars, y = main.pars)
mod.equate$B.est
#   Mean.Mean    Haebara Stocking.Lord
#  -0.1798861 -0.1788159    -0.1771145
head(mod.equate$anchor,2)

# -------------------------------------------------------------
# Abschnitt 6.4.3, Listing 1a: Ergänzung zum Buch
# Berechnung Linkingfehler                             
#
linkitems &lt;- intersect(n.items, items)

head(mod.equate$transf.par,2)
mod.equate$descriptives

# Linkingfehler: Jackknife unit ist Item
pars &lt;- data.frame(unit = linkitems,
                   study1 = normmod$item$xsi.item[match(linkitems, normmod$item$item)],
                   study2 = mainmod$item$xsi.item[match(linkitems, mainmod$item$item)],
                   item = linkitems)
# pars &lt;- as.matrix(pars)
mod.equate.jk &lt;- equating.rasch.jackknife(pars,se.linkerror = T)
mod.equate.jk$descriptives

# -------------------------------------------------------------
# Abschnitt 6.4.3, Listing 2: Linking nach Haberman
#

# Itemparameter der Normierungsstudie
M1 &lt;- mean( apply(dfr_normmod[,vars.pv], 2, mean ) )
SD1 &lt;- mean( apply(dfr_normmod[,vars.pv], 2, sd ) )
a1 &lt;- 1/SD1; b1 &lt;- 0-a1*M1
A &lt;- normmod$item$B.Cat1.Dim1/a1
B &lt;- (normmod$item$xsi.item + b1/a1)
# Itemparameter der Normierungsstudie fuer haberman.linking
tab.norm &lt;- data.frame(Studie = "1_Normierung",
                       item = normmod$item$item,
                       a = A, b = B/A)
# Itemparameter der Hauptstudie
A &lt;- mainmod$item$B.Cat1.Dim1
B &lt;- mainmod$item$xsi.item
tab.main &lt;- data.frame(Studie = "2_Hauptstudie",
                       item = mainmod$item$item,
                       a = A, b = B/A)
# Itemparameter aller Studien
itempars &lt;- rbind(tab.norm, tab.main)
# Personenparameter
personpars &lt;- list(PV_normmod$pv*a1+b1, PV_mainmod$pv)
# Linking nach Habermans Methode
linkhab &lt;- linking.haberman(itempars = itempars, 
                            personpars = personpars)

# -------------------------------------------------------------
# Abschnitt 6.4.3, Listing 2a: Ergänzung zum Buch
# Ergebnisdarstellung, Transformation und Berechnung
# von Verteilungsparametern
#

# Ergebnisse
# Transformationsparameter der Itemparameter
linkhab$transf.itempars
# Transformationsparameter der Personenparameter
linkhab$transf.personpars

# Itemparameter
dfr.items &lt;- data.frame(linkhab$joint.itempars,
                        linkhab$b.orig, linkhab$b.trans)
names(dfr.items)[-1] &lt;- c("joint_a","joint_b",
                          "orig_b_norm","orig_b_main",
                          "trans_b_norm","trans_b_main")
head(round2(dfr.items[,-1],2),2)

# Transformierte Personenparameter der Hauptstudie
dfr_main_transpv &lt;- linkhab$personpars[[2]]
names(dfr_main_transpv)[-1] &lt;- paste0("linkhab_",vars.pv)
dfr_main_transpv &lt;- cbind(dfr_mainmod,dfr_main_transpv[,-1])
round2(head(dfr_main_transpv[,c("PV1.Dim1","linkhab_PV1.Dim1","PV2.Dim1","linkhab_PV2.Dim1")],2),2)

# Aufgeklärte und Fehlvarianz des Linkings
linkhab$es.invariance

# Transformationsparameter der Normierungsstudie auf Skala 500,100
# trafo.fixed1
a &lt;- 100/mean( apply(dfr_normmod[,vars.pv]*a1+b1, 2, sd ) )
b &lt;- 500 - a*mean( apply(dfr_normmod[,vars.pv]*a1+b1, 2, mean ) )

# trafo.fixed2
M_PV &lt;- mean( apply(linkhab$personpars[[2]][vars.pv], 2, 
                    Hmisc::wtd.mean, weights = dfr_mainmod$pweight ) )
SD_PV &lt;- mean( sqrt(apply(linkhab$personpars[[2]][vars.pv], 2, 
                          Hmisc::wtd.var, weights = dfr_mainmod$pweight )) )
M_TPV &lt;- M_PV*a + b
SD_TPV &lt;- SD_PV * a

trafo.linkhab &lt;- data.frame(trafo.fixed1[,1:2],
                            a1 = a1, b1 = b1,
                            M_norm_trans = 0,
                            SD_norm_trans = 1,
                            a = 100, b = 500,
                            trafo.fixed2[,1:2],
                            linkhab_M_PV = M_PV, 
                            linkhab_SD_PV = SD_PV,
                            linkhab_M_TPV = M_TPV,
                            linkhab_SD_TPV = SD_TPV)


## -------------------------------------------------------------
## Abschnitt 6.4.4 Ergebnisse im Vergleich und Standardfehler
##                 des Linkings
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 6.4.4, Listing 3a: Ergänzung zum Buch
# Berechnung von Standardfehlern Ergebnisvergleiche
#

# Gemeinsame Skalierung mit fixiertem Itemparameter aus Hauptstudie
# Standardfehler bzgl. Itemstichprobenfehler

# Matrix für fixerte Itemparameter vorbereiten
xsi.fixed &lt;- normmod.fixed$xsi.fixed.estimated
npar &lt;- length(xsi.fixed[,"xsi"])
mat.xsi.fixed &lt;- cbind(index=1:npar,par = dimnames(xsi.fixed)[[1]])
sequence &lt;- match(mat.xsi.fixed[,"par"],dimnames(main.xsi)[[1]])
mat.xsi.fixed &lt;- cbind(index=as.numeric(mat.xsi.fixed[,1]), 
                       par = mat.xsi.fixed[,2],
                       xsi.fixed = as.numeric(main.xsi[sequence,"xsi"]))
# Nicht fixierte Itemparameter löschen
del &lt;- which(is.na(mat.xsi.fixed[,"xsi.fixed"]))
mat.xsi.fixed &lt;- mat.xsi.fixed[-del,]
head(mat.xsi.fixed,3)

dfr &lt;- data.frame(elim = "none",growth=trafo.fixed2$M_TPV-500)
# Jedes Mal ein Ankeritem weniger
# Schleife über alle Ankeritems

set.seed(20160828)

for(ii in linkitems){
  # ii &lt;- linkitems[1]
  del &lt;- grep(paste0(ii,"_"), mat.xsi.fixed[,2])
  tmp &lt;- mat.xsi.fixed[-del,c(1,3)]
  tmp &lt;- data.frame(index = as.numeric(tmp[,1]),xsi.fixed = as.numeric(tmp[,2]))
  
  # Skalierung der Hauptstudie-Daten mit fixiertem Itemparameter
  normmod.tmp &lt;- tam.mml(resp=normdat[, n.items], irtmodel="1PL", 
                         xsi.fixed = tmp,
                         pid=normdat$MB_idstud, pweights=normdat[,"wgtstud"])
  
  # Personenfähigkeitsschätzer
  # WLE_normmod.tmp &lt;- tam.wle(normmod.tmp)
  PV_normmod.tmp &lt;- tam.pv(normmod.tmp, nplausible = 20)
  # In Personendatensatz kombinieren
  
  M_norm.tmp &lt;- mean(apply(PV_normmod.tmp$pv[,vars.pv],2,mean))
  SD_norm.tmp &lt;- mean(apply(PV_normmod.tmp$pv[,vars.pv],2,sd))
  
  # Tranformationsparameter
  a_norm.tmp &lt;- 100/SD_norm.tmp 
  b_norm.tmp &lt;- 500 - a_norm.tmp*M_norm.tmp
  
  TM_main.tmp &lt;- M_main * a_norm.tmp + b_norm.tmp
  dfr.tmp &lt;- data.frame(elim = ii,growth=TM_main.tmp-500)
  dfr &lt;- rbind(dfr,dfr.tmp)
  
}

dfr$diff2 &lt;- (dfr$growth-dfr$growth[1])^2
sum &lt;- sum(dfr$diff2)
Var &lt;- sum*28/29
SE &lt;- sqrt(Var)

quant &lt;- 1.96 
low &lt;- trafo.fixed2$M_TPV - quant*SE
upp &lt;- trafo.fixed2$M_TPV + quant*SE

dfr$SE &lt;- SE; dfr$quant &lt;- quant
dfr$low &lt;- low; dfr$upp &lt;- upp


## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+207'>Kapitel 7: Statistische Analysen produktiver Kompetenzen</h2><span id='topic+Kapitel+207'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 7, <em>Statistische Analysen produktiver 
Kompetenzen</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Details</h3>



<h4>Abschnitt 1: Beispieldatensätze</h4>

<p>Der zur Illustration verwendete Datensatz <code>prodRat</code> beinhaltet die 
beurteilten Schreibkompetenzen im Fach Englisch auf der 8. Schulstufe von 9836 
Schüler/innen (<code>idstud</code>) die von insgesamt 41 Ratern (<code>rater</code>) 
beurteilt wurden. 
Die sechs Schreibaufgaben (<code>aufgabe</code>) wurden auf sechs Testhefte 
(<code>th</code>) aufgeteilt, wobei jede Aufgabe in genau zwei Testheften vorkommt.
</p>
<p>Zur weiteren Analyse verwenden wir auch den Datensatz <code>prodPRat</code> mit 
sogenannten Pseudoratern.
</p>
<p>Für die Analyse von Varianzkomponenten mittels Linear Mixed Effects (LME) 
Modellen verwenden wir den ursprünglichen Datensatz im Long Format 
(<code>prodRatL</code>). 
</p>
 


<h4>Abschnitt 2: Beurteilerübereinstimmung</h4>



<h5>Listing 1: Berechnen von Häufigkeitstabellen</h5>

<p>Hier werden die Datensätze <code>prodRat</code> und <code>prodPRat</code> verwendet. 
Die R-Funktion <code>apply()</code> ermöglicht eine Anwendung einer beliebigen 
Funktion z.B. <code>prop.table()</code> über alle Zeilen (1) oder Spalten (2) eines 
<code>data.frame</code>.
</p>
<p><code style="white-space: pre;">&#8288;library(irr)
data(datenKapitel07)
prodRat &lt;- datenKapitel07$prodRat

# Items auswählen
items &lt;- c("TA", "CC", "GR", "VO")
# Tabelle erzeugen
tab &lt;- apply(prodRat[, items], 2,
                     FUN=function(x){
                       prop.table(table(x))*100})
print(tab, digits = 2)

# Mittelwert der Ratings berechnen
round(apply(prodRat[, items], 2, mean), 2)
&#8288;</code>

</p>
 


<h5>Listing 2: Beurteilerübereinstimmung berechnen</h5>

<p>Wir verwenden den Datensatz mit Pseudoratern <code>prodPRat</code>. 
Die Analysen werden mit dem Paket <code>irr</code> durchgeführt. 
</p>
<p><code style="white-space: pre;">&#8288;prodRat &lt;- datenKapitel07$prodRat

items &lt;- c("TA", "CC", "GR", "VO")
dfr &lt;- data.frame(items, agree = NA, 
                  kappa = NA, wkappa = NA, korr = NA)
for(i in 1:length(items)){
  dat.i &lt;- prodPRat[, grep(items[i], colnames(prodPRat))]
  dfr[i, "agree"] &lt;- agree(dat.i, tolerance = 1)["value"]
  dfr[i, "kappa"] &lt;- kappa2(dat.i)["value"]
  dfr[i, "wkappa"] &lt;- kappa2(dat.i, weight = "squared")["value"]
  dfr[i, "korr"] &lt;- cor(dat.i[,1], dat.i[,2])
  dfr[i, "icc"] &lt;- icc(dat.i, model = "twoway")["value"]
}
print(dfr, digits = 3)
&#8288;</code>

</p>
 
 


<h4>Abschnitt 3: Skalierungsmodelle</h4>



<h5>Listing 1: Skalierungsmodell mit TAM</h5>

<p>Der Funktion <code>tam.mm.mfr()</code> muss ein <code>data.frame</code> für die Facetten 
übergeben werden. 
Zusätzlich können Einstellungen in einer Liste für das Argument 
<code>control = list()</code> übergeben werden. 
Hier verwenden wir die Einstellung <code>xsi.start0 = 1</code>, was dazu führt, dass 
alle Startwerte auf 0 gesetzt werden. 
Mit <code>fac.oldxsi = 0.1</code> setzen wir das Gewicht der Parameterwerte aus der 
vorigen Iteration etwas über 0. 
Damit kann der Algorithmus stabilisiert und Konvergenzprobleme (deviance 
increase) verhindert werden. Wir definieren noch <code>increment.factor = 1.05</code> 
etwas über dem default-Wert von 1 um mögliche Konvergenzprobleme abzufangen. 
Dieser Wert definiert das Ausmaß der Abnahme des maximalen Zuwachs der 
Parameter pro Iteration (s. TAM-Hilfe).
</p>
<p>Die Personenparameter werden mit der Funktion <code>tam.wle()</code> geschätzt.
</p>
<p>Gibt man in der Funktion <code>summary()</code> das Argument <code>file</code> an, so wird 
der Output direkt in ein Textfile geschrieben.
</p>
<p><code style="white-space: pre;">&#8288;set.seed(1234)
library(TAM)

prodRat &lt;- datenKapitel07$prodRat

# Rater-Facette definieren
facets &lt;- prodRat[, "rater", drop = FALSE] 

# Response Daten definieren
vars &lt;- c("TA", "CC", "GR", "VO")
resp &lt;- prodRat[, vars] 

# Personen-ID definieren
pid &lt;- prodRat$idstud 

# Formel für Modell
formulaA &lt;- ~item*step+item*rater

# Modell berechnen
mod &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = formulaA,   
                   pid = pid, control=list(xsi.start0 = 1, 
                                           fac.oldxsi = 0.1, 
                                           increment.factor = 1.05))
summary(mod, file="TAM_MFRM")

# Personenparameter und Rohscores
persons.mod &lt;- tam.wle(mod)
persons.mod$raw.score &lt;- persons.mod$PersonScores / (persons.mod$N.items) 
&#8288;</code>

</p>
 


<h5>Listing 1b (Ergänzung zum Buch): Skalierungsmodell mit TAM</h5>

<p>Hier werden alle im Buch besprochenen Modelle berechnet und anschließend ein 
Modellvergleich durchgeführt.
</p>
<p><code style="white-space: pre;">&#8288;f1 &lt;- ~item * rater * step
mod1 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f1,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
f2 &lt;- ~item*step+item*rater
mod2 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f2,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
f3 &lt;- ~item * step + rater
mod3 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f3,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
f4 &lt;- ~item + step + rater
mod4 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f4,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
mod4$xsi.facets
IRT.compareModels(mod1, mod2, mod3, mod4)
&#8288;</code>

</p>



<h5>Listing 1c (Ergänzung zum Buch): Wright-Map</h5>

<p>Mit dem Paket <code>WrightMap</code> können die Ergebnisse für die einzelnen Facetten 
dargestellt werden. Wir machen dies für Items und Rater.
</p>
<p><code style="white-space: pre;">&#8288;library(WrightMap)

item.labs &lt;- vars
rater.labs &lt;- unique(prodRat$rater)
item.labs &lt;- c(item.labs, rep(NA, length(rater.labs) - 
                                length(item.labs)))

pars &lt;- mod$xsi.facets$xsi
facet &lt;- mod$xsi.facets$facet
item.par &lt;- pars[facet == "item"]
rater.par &lt;- pars[facet == "rater"]
item_rat &lt;- pars[facet == "item:rater"]
len &lt;- length(item_rat)
item.long &lt;- c(item.par, rep(NA, len - length(item.par)))
rater.long &lt;- c(rater.par, rep(NA, len - length(rater.par)))

wrightMap(persons.mod$theta, rbind(item.long, rater.long), 
          label.items = c("Items",  "Rater"), 
          thr.lab.text = rbind(item.labs, rater.labs), 
          axis.items = "", min.l=-3, max.l=3,
          axis.persons = "Personen")
&#8288;</code>

</p>



<h5>Listing 2: Fit-Indices berechnen</h5>

<p>Die Fit-Indices werden mit der Funktion <code>msq.itemfitWLE</code> für die 
Raterparameter und Itemparameter gesondert  berechnet. 
Der Funktion muss ein Vektor mit Parameterbezeichnungen übergeben werden so wie 
sie im Modell-Objekt vorkommen. 
Im Paket <code>TAM</code> gibt es noch die Funktion <code>tam.fit()</code>, diese basiert 
auf einer Simulation der individuellen Posterior-Verteilung. 
Die Funktion <code>msq.itemfitWLE</code> wertet dagegen die individuelle 
Posterior-Verteilung direkt aus (s. <code>TAM</code>-Hilfe für weitere Beispiele) und 
führt keine Simulation durch.
</p>
<p><code style="white-space: pre;">&#8288;# Infit/Outfit berechnen
pseudo_items &lt;- colnames(mod$resp)
pss &lt;- strsplit(pseudo_items , split="-")
item_parm &lt;- unlist(lapply(pss, FUN = function(ll){ll[1]}))
rater_parm &lt;- unlist(lapply(pss, FUN = function(ll){ll[2]}))

# Fit Items
res.items &lt;- msq.itemfitWLE(mod, item_parm)
summary(res.items)

# Fit Rater
res.rater &lt;- msq.itemfitWLE(mod, rater_parm)
summary(res.rater)
&#8288;</code>

</p>



<h5>Listing 2a (Ergänzung zum Buch): Abbildung Fit-Indices</h5>

<p><code style="white-space: pre;">&#8288;# Abbildung: Histogramm, Rohscores

par(mfcol=c(1,2))

hist(persons.mod$theta, col="grey", breaks=40, 
     main = "",
     xlab = "Theta (logits)",
     ylab = "Häufigkeit")
with(persons.mod, scatter.smooth(raw.score, theta, 
    pch = 1, cex = .6, xlab = "Roscores",
    ylab = "Theta (logits)", 
    lpars = list(col = "darkgrey", lwd = 2, lty = 1)))

# Abbildung: Fit-Statistik
par(mfcol=c(1,2))
fitdat &lt;- res.rater$fit_data
fitdat$var &lt;- factor(substr(fitdat$item, 1, 2))
boxplot(Outfit~var, data=fitdat, 
        ylim=c(0,2), main="Outfit")
boxplot(Infit~var, data=fitdat, 
        ylim=c(0,2), main="Infit")
&#8288;</code>

</p>



<h5>Listing 2b (Ergänzung zum Buch): Korrelationen</h5>

<p>Pearson und Spearman Korrelationskoeffizient wird zwischen Rohscores und Theta 
berechnet.
</p>
<p><code style="white-space: pre;">&#8288;korr &lt;- c(with(persons.mod, cor(raw.score, theta, 
                                method = "pearson")),
          with(persons.mod, cor(raw.score, theta, 
                                method = "spearman")))
print(korr)
&#8288;</code>

</p>



<h5>Listing 3: Q3-Statistik berechnen</h5>

<p>Die Q3-Statistik für lokale stochastische Unabhängigkeit wird mit der Funktion 
<code>tam.modelfit()</code> berechnet. 
Der Output enthält eine Vielzahl an Fit-Statistiken, für weitere Details sei 
hier auf die <code>TAM</code>-Hilfeseite verwiesen. 
Die adjustierte aQ3-Statistik berechnet sich aus den Q3-Werten abzüglich des 
Gesamtmittelwerts von allen Q3-Werten. 
</p>
<p>Mit <code>tam.modelfit()</code> werden Fit-Statistiken für alle Rater x Item 
Kombinationen berechnet. 
Diese werden im Code unten anschließend aggregiert um eine Übersicht zu 
erhalten. 
Dazu werden zuerst nur Paare gleicher Rater ausgewählt, somit wird die 
aggregierte Q3-Statistik nur Rater-spezifisch berechnet. 
Das Objekt <code>rater.q3</code> beinhaltet eine Zeile pro Rater x Item Kombination. 
Kombinationen ergeben sich nur für einen Rater, nicht zwischen unterschiedlichen 
Ratern.
</p>
<p>Anschließend kann man mit <code>aggregate()</code> separat über Rater und 
Kombinationen mitteln und diese als Dotplot darstellen (Paket <code>lattice</code>).
</p>
<p><code style="white-space: pre;">&#8288;# Q3 Statistik
mfit.q3 &lt;- tam.modelfit(mod)
rater.pairs &lt;- mfit.q3$stat.itempair

# Nur Paare gleicher Rater wählen
unique.rater &lt;- which(substr(rater.pairs$item1, 4,12) == 
                      substr(rater.pairs$item2, 4,12))
rater.q3 &lt;- rater.pairs[unique.rater, ]

# Spalten einfügen: Rater, Kombinationen
rater.q3$rater &lt;- substr(rater.q3$item1, 4, 12)
rater.q3 &lt;- rater.q3[order(rater.q3$rater),]
rater.q3$kombi &lt;- as.factor(paste(substr(rater.q3$item1, 1, 2), 
                                  substr(rater.q3$item2, 1, 2), sep="_"))

# Statistiken aggregieren: Rater, Kombinationen
dfr.raterQ3 &lt;- aggregate(rater.q3$aQ3, by = list(rater.q3$rater), mean)
colnames(dfr.raterQ3) &lt;- c("Rater", "Q3")
dfr.itemsQ3 &lt;- aggregate(rater.q3$aQ3, by = list(rater.q3$kombi), mean)
colnames(dfr.itemsQ3) &lt;- c("Items", "Q3")
dfr.itemsQ3
&#8288;</code>

</p>



<h5>Listing 3 (Ergänzung zum Buch): Lattice Dotplot</h5>

<p><code style="white-space: pre;">&#8288;library(lattice)
library(grid)

# Lattice Dotplot
mean.values &lt;- aggregate(rater.q3$aQ3, list(rater.q3$kombi), mean)[["x"]]
dotplot(aQ3~kombi, data=rater.q3, main="Q3-Statistik", ylab="Q3 (adjustiert)",
        col="darkgrey", 
        panel = function(x,...){
          panel.dotplot(x,...)
          panel.abline(h = 0, col.line = "grey", lty=3)
          grid.points(1:6, mean.values, pch=17)
        })
&#8288;</code>

</p>

 


<h4>Abschnitt 4: Generalisierbarkeitstheorie</h4>



<h5>Listing 1: Varianzkomponenten mit lme4 berechnen</h5>

<p>Mit der Funktion <code>lmer()</code> aus dem Paket <code>lme4</code> schätzen wir die 
Varianzkomponenten. 
In der Formel definieren wir dabei die Facetten als random effects.
</p>
<p><code style="white-space: pre;">&#8288;library(lme4)

prodRatL &lt;- datenKapitel07$prodRatL

# Formel definieren
formula1 &lt;- response ~ (1|idstud) + (1|item) + (1|rater) +
                       (1|rater:item) + (1|idstud:rater) + 
                       (1|idstud:item)
# Modell mit Interaktionen
mod.vk &lt;- lmer(formula1, data=prodRatL)

# Zusammenfassung der Ergebnisse
summary(mod.vk)
&#8288;</code>

</p>



<h5>Listing 1a (Ergänzung zum Buch): Summary-Funktion für 
Varianzkomponenten</h5>

<p>Wir generieren eine Funktion <code>summary.VarComp()</code>, die den Output des 
Modells <code>mod.vk</code> in einen ansprechenden <code>data.frame</code> schreibt. 
Hier werden auch die prozentualen Anteile der Varianzkomponenten berechnet.
</p>
<p><code style="white-space: pre;">&#8288;# Helper-Function um die Varianzkomponenten zu extrahieren
summary.VarComp &lt;- function(mod){ 
  var.c &lt;- VarCorr(mod)
  var.c &lt;- c(unlist(var.c) , attr(var.c , "sc")^2)
  names(var.c)[length(var.c)] &lt;- "Residual"
  dfr1 &lt;- data.frame(var.c)
  colnames(dfr1) &lt;- "Varianz"
  dfr1 &lt;- rbind(dfr1, colSums(dfr1))
  rownames(dfr1)[nrow(dfr1)] &lt;- "Total"
  dfr1$prop.Varianz &lt;- 100 * (dfr1$Varianz / dfr1$Varianz[nrow(dfr1)])
  dfr1 &lt;- round(dfr1,2)
  return(dfr1)
}
summary.VarComp(mod.vk)
&#8288;</code>

</p>



<h5>Listing 2: Berechnung des G-Koeffizienten</h5>

<p>Den G-Koeffizienten berechnen wir nach der Formel im Buch.
</p>
<p><code style="white-space: pre;">&#8288;vk &lt;- summary.VarComp(mod.vk)
n.p &lt;- length(unique(prodRatL$idstud)) # Anzahl Schüler
n.i &lt;- 4  # Anzahl Items
n.r &lt;- c(1,2,5) # Anzahl Rater

# Varianzkomponenten extrahieren
sig2.p &lt;- vk["idstud", "Varianz"]
sig2.i &lt;- vk["item", "Varianz"]
sig2.r &lt;- vk["rater", "Varianz"]
sig2.ri &lt;- vk["rater:item", "Varianz"]
sig2.pr &lt;- vk["idstud:rater", "Varianz"]
sig2.pi &lt;- vk["idstud:item", "Varianz"]
sig2.pir &lt;- vk["Residual", "Varianz"]

# Fehlervarianz berechnen
sig2.delta &lt;- sig2.pi/n.i + sig2.pr/n.r + sig2.pir/(n.i*n.r) 

# G-Koeffizient berechnen
g.koeff &lt;- sig2.p / (sig2.p + sig2.delta)
print(data.frame(n.r, g.koeff), digits = 3)
&#8288;</code>

</p>



<h5>Listing 2a (Ergänzung zum Buch): Phi-Koeffizient berechnen</h5>

<p><code style="white-space: pre;">&#8288;sig2.D &lt;- sig2.r/n.r + sig2.i/n.i + sig2.pi/n.i + sig2.pr/n.r + 
          sig2.ri/(n.i*n.r) + sig2.pir/(n.i*n.r) 
phi.koeff &lt;- sig2.p / (sig2.p + sig2.D)
print(data.frame(n.r, phi.koeff), digits = 3)

# Konfidenzintervalle
1.96*sqrt(sig2.D)
&#8288;</code>

</p>



<h5>Listing 2c (Ergänzung zum Buch): Variable Rateranzahl</h5>

<p>Für eine variable Rateranzahl (hier 1 bis 10 Rater) werden die G-Koeffizienten 
berechnet.
</p>
<p><code style="white-space: pre;">&#8288;n.i &lt;- 4  # Anzahl Items
dn.r &lt;- seq(1,10) # 1 bis 10 mögliche Rater
delta.i &lt;- sig2.pi/n.i + sig2.pr/dn.r + sig2.pir/(n.i*dn.r)
g.koeff &lt;- sig2.p / (sig2.p + delta.i)
names(g.koeff) &lt;- paste("nR", dn.r, sep="_") 
print(g.koeff[1:4])

plot(g.koeff, type = "b", pch = 19, lwd = 2, bty = "n",
     main = "G-Koeffizient: Raters",
     ylab = "G-Koeffizient",
     xlab = "Anzahl Raters",  xlim = c(0,10))
abline(v=2, col="darkgrey")
&#8288;</code>

</p>

 


<h4>Abschnitt 5: Strukturgleichungsmodelle</h4>

<p>In R setzen wir das Struktugleichungsmodell mit dem Paket <code>lavaan</code> um. 
Das Modell wird als Textvariable definiert, welche anschließend der Funktion 
<code>sem()</code> übergeben wird. 
Latente Variablen im Messmodell werden in <code>lavaan</code> mit der Form 
<code>latente Variable =~ manifeste</code> <code>Variable(n)</code> definiert, die Ladungen werden 
dabei auf den Wert 1 fixiert, was mittels der Multiplikation der Variable mit 
dem Wert 1 umgesetzt werden kann (z.B. <code>1*Variable</code>). 
Varianzen und Kovarianzen werden mit <code>Variable ~~ Variable</code> gebildet, 
wobei hier die Multiplikation mit einem Label einerseits den berechneten 
Parameter benennt, andererseits, bei mehrmaligem Auftreten des Labels, 
Parameterschätzungen von verschiedenen Variablen restringiert bzw. gleichstellt 
(z.B. wird für die Within-Varianz von <code>TA</code> über beide Rater nur ein 
Parameter geschätzt, nämlich <code>Vta_R12</code>). 
Die ICC wird für jede Dimension separat direkt im Modell spezifiziert, dies 
geschieht durch abgeleitete Variablen mit der Schreibweise 
<code>Variable := Berechnung</code>. 
Die Modellspezifikation und der Aufruf der Funktion <code>sem()</code> ist wie folgt 
definiert:
</p>


<h5>Listing 1 (mit Ergänzung zum Buch): SEM</h5>

<p><code style="white-space: pre;">&#8288;library(lavaan)

prodPRat &lt;- datenKapitel07$prodPRat

# SEM Modell definieren
lv.mod &lt;- " 
  # Messmodell
  TA =~ 1*TA_R1 + 1*TA_R2
  CC =~ 1*CC_R1 + 1*CC_R2
  GR =~ 1*GR_R1 + 1*GR_R2
  VO =~ 1*VO_R1 + 1*VO_R2
  
  # Varianz Between (Personen)
  TA ~~ Vta * TA
  CC ~~ Vcc * CC
  GR ~~ Vgr * GR
  VO ~~ Vvo * VO
  
  # Varianz Within (Rater X Personen)
  TA_R1 ~~ Vta_R12 * TA_R1
  TA_R2 ~~ Vta_R12 * TA_R2
  CC_R1 ~~ Vcc_R12 * CC_R1
  CC_R2 ~~ Vcc_R12 * CC_R2
  GR_R1 ~~ Vgr_R12 * GR_R1
  GR_R2 ~~ Vgr_R12 * GR_R2
  VO_R1 ~~ Vvo_R12 * VO_R1
  VO_R2 ~~ Vvo_R12 * VO_R2
  
  # Kovarianz Within
  TA_R1 ~~ Kta_cc * CC_R1
  TA_R2 ~~ Kta_cc * CC_R2
  TA_R1 ~~ Kta_gr * GR_R1
  TA_R2 ~~ Kta_gr * GR_R2
  TA_R1 ~~ Kta_vo * VO_R1
  TA_R2 ~~ Kta_vo * VO_R2
  CC_R1 ~~ Kcc_gr * GR_R1
  CC_R2 ~~ Kcc_gr * GR_R2
  CC_R1 ~~ Kcc_vo * VO_R1
  CC_R2 ~~ Kcc_vo * VO_R2
  GR_R1 ~~ Kgr_vo * VO_R1
  GR_R2 ~~ Kgr_vo * VO_R2
  
  # ICC berechnen
  icc_ta := Vta / (Vta + Vta_R12)
  icc_cc := Vcc / (Vcc + Vcc_R12)
  icc_gr := Vgr / (Vgr + Vgr_R12)
  icc_vo := Vvo / (Vvo + Vvo_R12)
"
# Schätzung des Modells
mod1 &lt;- sem(lv.mod, data = prodPRat)
summary(mod1, standardized = TRUE)

# Inspektion der Ergebnisse
show(mod1)
fitted(mod1)
inspect(mod1,"cov.lv")
inspect(mod1, "free")
&#8288;</code>

</p>



<h5>Listing 2: Kompakte Darstellung der Ergebnisse</h5>

<p><code style="white-space: pre;">&#8288;parameterEstimates(mod1, ci = FALSE, 
                   standardized = TRUE)
&#8288;</code>

</p>



<h5>Listing 2a (Ergänzung zum Buch): Schreibe Ergebnisse in 
Latex-Tabelle</h5>

<p><code style="white-space: pre;">&#8288;library(xtable)

xtable(parameterEstimates(mod1, ci = FALSE, 
                          standardized = TRUE), digits = 3)
&#8288;</code>

</p>
 
 


<h4>Abschnitt 7: Übungen</h4>



<h5>Übung 1: MFRM M3 und M4 umsetzen und Vergleichen</h5>

<p>Wir setzen die Modelle separat in TAM um und lassen uns mit <code>summary()</code> 
die Ergebnisse anzeigen.
Einen direkten Zugriff auf die geschätzen Parameter bekommt man mit 
<code>mod$xsi.facets</code>. 
Dabei sieht man, dass im Modell 4 keine generalized items gebildet werden, da 
hier kein Interaktionsterm vorkommt. 
Den Modellvergleich machen wir mit <code>IRT.compareModels(mod3, mod4)</code>. 
Modell 3 weist hier kleinere AIC-Werte auf und scheint etwas besser auf die 
Daten zu passen als Modell 4. 
Dies zeigt auch der Likelihood-Ratio Test, demnach sich durch das Hinzufügen von 
Parametern die Modellpassung verbessert.
</p>
<p><code style="white-space: pre;">&#8288;library(TAM)
prodRatEx &lt;- datenKapitel07$prodRatEx

# Rater-Facette definieren
facets &lt;- prodRatEx[, "rater", drop = FALSE] 

# Response Daten definieren
vars &lt;- c("TA", "CC", "GR", "VO")
resp &lt;- prodRatEx[, vars] 

# Personen-ID definieren
pid &lt;- prodRatEx$idstud 

# Modell 3
f3 &lt;- ~item * step + rater
mod3 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f3,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
# Modell 4
f4 &lt;- ~item + step + rater
mod4 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f4,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
summary(mod3, file = "TAM_MFRM")
summary(mod4, file = "TAM_MFRM")


mod3$xsi.facets
mod4$xsi.facets

IRT.compareModels(mod3, mod4)

$IC
  Model   loglike Deviance Npars Nobs      AIC      BIC     AIC3     AICc     CAIC
1  mod3 -60795.35 121590.7    69 9748 121728.7 122224.5 121797.7 121729.7 122293.5
2  mod4 -61041.47 122082.9    51 9748 122184.9 122551.4 122235.9 122185.5 122602.4

$LRtest
  Model1 Model2     Chi2 df p
1   mod4   mod3 492.2264 18 0
&#8288;</code>

</p>



<h5>Übung 2: Varianzkomponentenmodell</h5>

<p>Das Varianzkomponentenmodell setzen wir für die short prompts nach den Vorgaben 
im Buchkapitel um. 
Dabei verändern wir die Anzahl der möglichen Rater durch 
<code>n.r &lt;- c(2,10,15)</code>. 
Der Phi-Koeffizient kann laut Gleichung 6.9 und 6.10 berechnet werden. 
Die Ergebnisse zeigen einen prozentuellen Anteil der Interaktion Person und 
Rater von ca. 15%, dieser scheint auf Halo-Effekte hinzuweisen.
</p>
<p><code style="white-space: pre;">&#8288;library(lme4)
prodRatLEx &lt;- datenKapitel07$prodRatLEx

# Formel definieren
formula1 &lt;- response ~ (1|idstud) + (1|item) + (1|rater) +
                       (1|rater:item) + (1|idstud:rater) + 
                       (1|idstud:item)
# Modell mit Interaktionen
mod.vk &lt;- lmer(formula1, data=prodRatLEx)

# Zusammenfassung der Ergebnisse
summary(mod.vk)
print(vk &lt;- summary.VarComp(mod.vk))

             Varianz prop.Varianz
idstud:item     0.10         2.45
idstud:rater    0.64        15.21
idstud          2.88        67.94
rater:item      0.01         0.22
rater           0.19         4.39
item            0.00         0.02
Residual        0.41         9.78
Total           4.24       100.00


# Verändern der Rateranzahl
n.p &lt;- length(unique(prodRatLEx$idstud)) # Anzahl Schüler
n.i &lt;- 4  # Anzahl Items
n.r &lt;- c(2,10,15) # Anzahl Rater

# Varianzkomponenten extrahieren
sig2.p &lt;- vk["idstud", "Varianz"]
sig2.i &lt;- vk["item", "Varianz"]
sig2.r &lt;- vk["rater", "Varianz"]
sig2.ri &lt;- vk["rater:item", "Varianz"]
sig2.pr &lt;- vk["idstud:rater", "Varianz"]
sig2.pi &lt;- vk["idstud:item", "Varianz"]
sig2.pir &lt;- vk["Residual", "Varianz"]

# Phi-Koeffizient berechnen
sig2.D &lt;- sig2.r/n.r + sig2.i/n.i + sig2.pi/n.i + sig2.pr/n.r + 
          sig2.ri/(n.i*n.r) + sig2.pir/(n.i*n.r) 
phi.koeff &lt;- sig2.p / (sig2.p + sig2.D)
print(data.frame(n.r, phi.koeff), digits = 3)

# Konfidenzintervalle
1.96*sqrt(sig2.D)
&#8288;</code>

</p>

 


<h3>Author(s)</h3>

<p>Roman Freunberger, Alexander Robitzsch, Claudia Luger-Bazinger
</p>


<h3>References</h3>

<p>Freunberger, R., Robitzsch, A. &amp; Luger-Bazinger, C. (2016). Statistische 
Analysen produktiver Kompetenzen. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 225&ndash;258). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel07">datenKapitel07</a></code>, den im Kapitel verwendeten Daten.<br />

Zurück zu <code><a href="#topic+Kapitel+206">Kapitel 6</a></code>, Skalierung und Linking.<br />
Zu <code><a href="#topic+Kapitel+208">Kapitel 8</a></code>, Fehlende Daten und Plausible Values.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.<br />

Zur Hilfeseite von <code><a href="TAM.html#topic+TAM-package">TAM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(irr)
library(TAM)
library(WrightMap)
library(lattice)
library(grid)
library(lme4)
library(lavaan)
library(xtable)

summary.VarComp &lt;- function(mod){ 
  var.c &lt;- VarCorr(mod)
  var.c &lt;- c(unlist(var.c) , attr(var.c , "sc")^2)
  names(var.c)[length(var.c)] &lt;- "Residual"
  dfr1 &lt;- data.frame(var.c)
  colnames(dfr1) &lt;- "Varianz"
  dfr1 &lt;- rbind(dfr1, colSums(dfr1))
  rownames(dfr1)[nrow(dfr1)] &lt;- "Total"
  dfr1$prop.Varianz &lt;- 100 * (dfr1$Varianz / dfr1$Varianz[nrow(dfr1)])
  dfr1 &lt;- round(dfr1,2)
  return(dfr1)
}

data(datenKapitel07)
prodRat &lt;- datenKapitel07$prodRat
prodRatL &lt;- datenKapitel07$prodRatL
prodPRat &lt;- datenKapitel07$prodPRat 

## -------------------------------------------------------------
## Abschnitt 7.2: Beurteilerübereinstimmung
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 7.2, Listing 1: Berechnen der Häufigkeitstabellen
#

# Items auswählen
items &lt;- c("TA", "CC", "GR", "VO")
# Tabelle erzeugen
tab &lt;- apply(prodRat[, items], 2,
             FUN=function(x){
               prop.table(table(x))*100})
print(tab, digits = 2)

# Mittelwert der Ratings berechnen
round(apply(prodRat[, items], 2, mean), 2)

# -------------------------------------------------------------
# Abschnitt 7.2, Listing 2: Beurteilerübereinstimmung berechnen
#

items &lt;- c("TA", "CC", "GR", "VO")
dfr &lt;- data.frame(items, agree = NA, 
                  kappa = NA, wkappa = NA, korr = NA)
for(i in 1:length(items)){
  dat.i &lt;- prodPRat[, grep(items[i], colnames(prodPRat))]
  dfr[i, "agree"] &lt;- agree(dat.i, tolerance = 1)["value"]
  dfr[i, "kappa"] &lt;- kappa2(dat.i)["value"]
  dfr[i, "wkappa"] &lt;- kappa2(dat.i, weight = "squared")["value"]
  dfr[i, "korr"] &lt;- cor(dat.i[,1], dat.i[,2])
  dfr[i, "icc"] &lt;- icc(dat.i, model = "twoway")["value"]
}
print(dfr, digits = 3)


## -------------------------------------------------------------
## Abschnitt 7.3: Skalierungsmodelle
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 1: Skalierungsmodell mit TAM
#

set.seed(1234)

# Rater-Facette definieren
facets &lt;- prodRat[, "rater", drop = FALSE] 
# Response Daten definieren
vars &lt;- c("TA", "CC", "GR", "VO")
resp &lt;- prodRat[, vars] 
# Personen-ID definieren
pid &lt;- prodRat$idstud 

# Formel für Modell
formulaA &lt;- ~item*step+item*rater
# Modell berechnen
mod &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = formulaA,   
                   pid = pid, control=list(xsi.start0 = 1, 
                                           fac.oldxsi = 0.1, 
                                           increment.factor = 1.05))
summary(mod, file="TAM_MFRM")

# Personenparameter und Rohscores
persons.mod &lt;- tam.wle(mod)
persons.mod$raw.score &lt;- persons.mod$PersonScores / (persons.mod$N.items) 

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 1b: Ergänzung zum Buch
# Modellvergleich aller besprochenen Modelle
#

f1 &lt;- ~item * rater * step
mod1 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f1,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
f2 &lt;- ~item*step+item*rater
mod2 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f2,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
f3 &lt;- ~item * step + rater
mod3 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f3,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
f4 &lt;- ~item + step + rater
mod4 &lt;- tam.mml.mfr(resp = resp, facets = facets, formulaA = f4,   
                    pid = pid, control=list(xsi.start0 = 1, 
                                            fac.oldxsi = 0.1, 
                                            increment.factor = 1.05))
mod4$xsi.facets
IRT.compareModels(mod1, mod2, mod3, mod4)

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 1c: Ergänzung zum Buch
# Wright-Map: Items und Rater
#

item.labs &lt;- vars
rater.labs &lt;- unique(prodRat$rater)
item.labs &lt;- c(item.labs, rep(NA, length(rater.labs) - 
                                length(item.labs)))

pars &lt;- mod$xsi.facets$xsi
facet &lt;- mod$xsi.facets$facet
item.par &lt;- pars[facet == "item"]
rater.par &lt;- pars[facet == "rater"]
item_rat &lt;- pars[facet == "item:rater"]
len &lt;- length(item_rat)
item.long &lt;- c(item.par, rep(NA, len - length(item.par)))
rater.long &lt;- c(rater.par, rep(NA, len - length(rater.par)))

wrightMap(persons.mod$theta, rbind(item.long, rater.long), 
          label.items = c("Items",  "Rater"), 
          thr.lab.text = rbind(item.labs, rater.labs), 
          axis.items = "", min.l=-3, max.l=3,
          axis.persons = "Personen")

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 2: Fit-Indices berechnen
#

# Infit/Outfit berechnen
pseudo_items &lt;- colnames(mod$resp)
pss &lt;- strsplit(pseudo_items , split="-")
item_parm &lt;- unlist(lapply(pss, FUN = function(ll){ll[1]}))
rater_parm &lt;- unlist(lapply(pss, FUN = function(ll){ll[2]}))

# Fit Items
res.items &lt;- msq.itemfitWLE(mod, item_parm)
summary(res.items)

# Fit Rater
res.rater &lt;- msq.itemfitWLE(mod, rater_parm)
summary(res.rater)

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 2a: Ergänzung zum Buch
# Abbildung: Histogramm, Rohscores
#

dev.off()
par(mfcol=c(1,2))

hist(persons.mod$theta, col="grey", breaks=40, 
     main = "",
     xlab = "Theta (logits)",
     ylab = "Häufigkeit")
with(persons.mod, scatter.smooth(raw.score, theta, 
                                 pch = 1, cex = .6, xlab = "Rohscores",
                                 ylab = "Theta (logits)", 
                                 lpars = list(col = "darkgrey", lwd = 2, 
                                              lty = 1)))

# Abbildung: Fit-Statistik
par(mfcol=c(1,2))
fitdat &lt;- res.rater$fit_data
fitdat$var &lt;- factor(substr(fitdat$item, 1, 2))
boxplot(Outfit~var, data=fitdat, 
        ylim=c(0,2), main="Outfit")
boxplot(Infit~var, data=fitdat, 
        ylim=c(0,2), main="Infit")

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 2b: Ergänzung zum Buch
# Korrelationen
#

korr &lt;- c(with(persons.mod, cor(raw.score, theta, 
                                method = "pearson")),
          with(persons.mod, cor(raw.score, theta, 
                                method = "spearman")))
print(korr)

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 3: Q3-Statistik berechnen
#

# Q3 Statistik
mfit.q3 &lt;- tam.modelfit(mod)
rater.pairs &lt;- mfit.q3$stat.itempair

# Nur Paare gleicher Rater wählen
unique.rater &lt;- which(substr(rater.pairs$item1, 4,12) == 
                        substr(rater.pairs$item2, 4,12))
rater.q3 &lt;- rater.pairs[unique.rater, ]

# Spalten einfügen: Rater, Kombinationen
rater.q3$rater &lt;- substr(rater.q3$item1, 4, 12)
rater.q3 &lt;- rater.q3[order(rater.q3$rater),]
rater.q3$kombi &lt;- as.factor(paste(substr(rater.q3$item1, 1, 2), 
                                  substr(rater.q3$item2, 1, 2), sep="_"))

# Statistiken aggregieren: Rater, Kombinationen
dfr.raterQ3 &lt;- aggregate(rater.q3$aQ3, by = list(rater.q3$rater), mean)
colnames(dfr.raterQ3) &lt;- c("Rater", "Q3")
dfr.itemsQ3 &lt;- aggregate(rater.q3$aQ3, by = list(rater.q3$kombi), mean)
colnames(dfr.itemsQ3) &lt;- c("Items", "Q3")
dfr.itemsQ3

# -------------------------------------------------------------
# Abschnitt 7.3, Listing 3a: Ergänzung zum Buch
# Lattice Dotplot
#

# Lattice Dotplot
mean.values &lt;- aggregate(rater.q3$aQ3, list(rater.q3$kombi), mean)[["x"]]
dotplot(aQ3~kombi, data=rater.q3, main="Q3-Statistik", ylab="Q3 (adjustiert)",
        col="darkgrey", 
        panel = function(x,...){
          panel.dotplot(x,...)
          panel.abline(h = 0, col.line = "grey", lty=3)
          grid.points(1:6, mean.values, pch=17)
        })


## -------------------------------------------------------------
## Abschnitt 7.4: Generalisierbarkeitstheorie
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 7.4, Listing 1: Varianzkomponenten mit lme4 berechnen
#

# Formel definieren
formula1 &lt;- response ~ (1|idstud) + (1|item) + (1|rater) +
  (1|rater:item) + (1|idstud:rater) + 
  (1|idstud:item)
# Modell mit Interaktionen
mod.vk &lt;- lmer(formula1, data=prodRatL)

# Zusammenfassung der Ergebnisse
summary(mod.vk)

# -------------------------------------------------------------
# Abschnitt 7.4, Listing 1a: Ergänzung zum Buch
# Helper-Function um die Varianzkomponenten zu extrahieren
#

summary.VarComp &lt;- function(mod){ 
  var.c &lt;- VarCorr(mod)
  var.c &lt;- c(unlist(var.c) , attr(var.c , "sc")^2)
  names(var.c)[length(var.c)] &lt;- "Residual"
  dfr1 &lt;- data.frame(var.c)
  colnames(dfr1) &lt;- "Varianz"
  dfr1 &lt;- rbind(dfr1, colSums(dfr1))
  rownames(dfr1)[nrow(dfr1)] &lt;- "Total"
  dfr1$prop.Varianz &lt;- 100 * (dfr1$Varianz / dfr1$Varianz[nrow(dfr1)])
  dfr1 &lt;- round(dfr1,2)
  return(dfr1)
}
summary.VarComp(mod.vk)

# -------------------------------------------------------------
# Abschnitt 7.4, Listing 2: Berechnung des G-Koeffizienten
#

vk &lt;- summary.VarComp(mod.vk)
n.p &lt;- length(unique(prodRatL$idstud)) # Anzahl Schüler
n.i &lt;- 4  # Anzahl Items
n.r &lt;- c(1,2,5) # Anzahl Rater

# Varianzkomponenten extrahieren
sig2.p &lt;- vk["idstud", "Varianz"]
sig2.i &lt;- vk["item", "Varianz"]
sig2.r &lt;- vk["rater", "Varianz"]
sig2.ri &lt;- vk["rater:item", "Varianz"]
sig2.pr &lt;- vk["idstud:rater", "Varianz"]
sig2.pi &lt;- vk["idstud:item", "Varianz"]
sig2.pir &lt;- vk["Residual", "Varianz"]

# Fehlervarianz berechnen
sig2.delta &lt;- sig2.pi/n.i + sig2.pr/n.r + sig2.pir/(n.i*n.r) 

# G-Koeffizient berechnen
g.koeff &lt;- sig2.p / (sig2.p + sig2.delta)
print(data.frame(n.r, g.koeff), digits = 3)

# -------------------------------------------------------------
# Abschnitt 7.4, Listing 2a: Ergänzung zum Buch
# Phi-Koeffizient berechnen
#

sig2.D &lt;- sig2.r/n.r + sig2.i/n.i + sig2.pi/n.i + sig2.pr/n.r + 
  sig2.ri/(n.i*n.r) + sig2.pir/(n.i*n.r) 
phi.koeff &lt;- sig2.p / (sig2.p + sig2.D)
print(data.frame(n.r, phi.koeff), digits = 3)

# Konfidenzintervalle
1.96*sqrt(sig2.D)

# -------------------------------------------------------------
# Abschnitt 7.4, Listing 2c: Ergänzung zum Buch
# Variable Rateranzahl
#

dev.off()
n.i &lt;- 4  # Anzahl Items
dn.r &lt;- seq(1,10)# 1 bis 10 mögliche Rater
delta.i &lt;- sig2.pi/n.i + sig2.pr/dn.r + sig2.pir/(n.i*dn.r)
g.koeff &lt;- sig2.p / (sig2.p + delta.i)
names(g.koeff) &lt;- paste("nR", dn.r, sep="_") 
print(g.koeff[1:4])

# Abbildung variable Rateranzahl
plot(g.koeff, type = "b", pch = 19, lwd = 2, bty = "n",
     main = "G-Koeffizient: Raters",
     ylab = "G-Koeffizient",
     xlab = "Anzahl Raters",  xlim = c(0,10))
abline(v=2, col="darkgrey")


## -------------------------------------------------------------
## Abschnitt 7.5: Strukturgleichungsmodelle
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 7.5, Listing 1: SEM
#

# SEM Modell definieren
lv.mod &lt;- " 
  # Messmodell
  TA =~ 1*TA_R1 + 1*TA_R2
  CC =~ 1*CC_R1 + 1*CC_R2
  GR =~ 1*GR_R1 + 1*GR_R2
  VO =~ 1*VO_R1 + 1*VO_R2
  
  # Varianz Personen
  TA ~~ Vta * TA
  CC ~~ Vcc * CC
  GR ~~ Vgr * GR
  VO ~~ Vvo * VO
  
  # Varianz Rater X Personen
  TA_R1 ~~ Vta_R12 * TA_R1
  TA_R2 ~~ Vta_R12 * TA_R2
  CC_R1 ~~ Vcc_R12 * CC_R1
  CC_R2 ~~ Vcc_R12 * CC_R2
  GR_R1 ~~ Vgr_R12 * GR_R1
  GR_R2 ~~ Vgr_R12 * GR_R2
  VO_R1 ~~ Vvo_R12 * VO_R1
  VO_R2 ~~ Vvo_R12 * VO_R2
  
  # Kovarianz
  TA_R1 ~~ Kta_cc * CC_R1
  TA_R2 ~~ Kta_cc * CC_R2
  TA_R1 ~~ Kta_gr * GR_R1
  TA_R2 ~~ Kta_gr * GR_R2
  TA_R1 ~~ Kta_vo * VO_R1
  TA_R2 ~~ Kta_vo * VO_R2
  CC_R1 ~~ Kcc_gr * GR_R1
  CC_R2 ~~ Kcc_gr * GR_R2
  CC_R1 ~~ Kcc_vo * VO_R1
  CC_R2 ~~ Kcc_vo * VO_R2
  GR_R1 ~~ Kgr_vo * VO_R1
  GR_R2 ~~ Kgr_vo * VO_R2
  
  # ICC berechnen
  icc_ta := Vta / (Vta + Vta_R12)
  icc_cc := Vcc / (Vcc + Vcc_R12)
  icc_gr := Vgr / (Vgr + Vgr_R12)
  icc_vo := Vvo / (Vvo + Vvo_R12)
  "
# Schätzung des Modells
mod1 &lt;- sem(lv.mod, data = prodPRat)
summary(mod1, standardized = TRUE)

# Inspektion der Ergebnisse
show(mod1)
fitted(mod1)
inspect(mod1,"cov.lv")
inspect(mod1, "free")

# -------------------------------------------------------------
# Abschnitt 7.5, Listing 2: Kompakte Darstellung der Ergebnisse
#

parameterEstimates(mod1, ci = FALSE, 
                   standardized = TRUE)

# -------------------------------------------------------------
# Abschnitt 7.5, Listing 2a: Ergänzung zum Buch
# Schreibe Ergebnisse in Latex-Tabelle:
#

xtable(parameterEstimates(mod1, ci = FALSE, 
                          standardized = TRUE), digits = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+208'>Kapitel 8: Fehlende Daten und Plausible Values</h2><span id='topic+Kapitel+208'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 8, <em>Fehlende Daten und Plausible 
Values</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Details</h3>



<h4>Vorbereitungen</h4>

<p>Zur Illustration der Konsequenzen fehlender Daten und der Messfehlerbehaftetheit 
von Variablen soll zunächst ein Illustrationsdatensatz (<code>data08I</code>) mit 
N=1500 simuliert werden. Dabei sollen zwei Variablen vorliegen: Der 
Sozialstatus <code>X</code> soll teilweise fehlende Werte aufweisen und die zu 
erfassende Kompetenz liegt sowohl als wahrer Wert <code class="reqn">\theta</code>  als auch als 
messfehlerbehaftete Variable <code class="reqn">\hat{\theta}</code> vor. 
Im Datensatz <code>data08I</code> liegt sowohl der vollständig beobachtete 
Sozialstatus (<code>x</code>) als auch derselbe Sozialstatus mit teilweise fehlenden 
Variablen (<code>X</code>) vor.
Neben dem Illustrationsdatensatz werden in diesem Kapitel Datensätze der 
österreichischen Bildungsstandards im Fach Englisch verwendet. 
Der Datensatz <code>data08H</code> enthält Kovariaten (d.h. Variablen aus Fragebögen 
oder administrative Daten) auf Ebene der Schüler (Ebene 1) und auf Ebene der 
Schulen (Ebene 2). 
Variablen beider Ebenen können dabei fehlende Werte besitzen. 
Im Datensatz <code>data08J</code> sind fehlende Werte des Datensatzes <code>data08H</code> 
durch eine Ersetzung von Werten bereits aufgefüllt. 
Außerdem liegen Item Responses der Schüler für den Bereich Hörverstehen 
(Listening, L) im Datensatz <code>data08K</code> vor.
Folgende R-Pakete werden in diesem Kapitel verwendet: <code>mice</code>, 
<code>miceadds</code>, <code>TAM</code>, <code>pls</code>.
</p>
<p><code style="white-space: pre;">&#8288;library(miceadds)
library(mice)
library(TAM)
library(pls)
&#8288;</code>

</p>



<h4>Abschnitt 8.1.1: Konsequenzen fehlender Daten und 
messfehlerbehafteter Variablen</h4>



<h5>Listing 1: Deskriptive Statistiken des Datensatzes</h5>

<p>Mit folgendem R-Code werden deskriptive Statistiken des Datensatzes 
<code>data08I</code> ermittelt, an denen die Bedeutung der geeigneten Behandlung 
fehlender Werte und von Messfehlern herausgearbeitet werden soll.
</p>
<p><code style="white-space: pre;">&#8288;data(datenKapitel08)
dat &lt;- datenKapitel08$data08I[,-1]
#*** Missinganteile
round( colMeans( is.na(dat), na.rm=TRUE) , 2 )     
#*** Mittelwerte
round( apply( dat , 2 , mean , na.rm=TRUE ) , 2 )   
#*** Zusammenhang von Missingindikator und Variablen 
round( miceadds::mi_dstat( dat[,c("WLE","X")] ) , 2 )
#*** Varianzen
round( apply( dat , 2 , var , na.rm=TRUE ) , 2 ) 
#*** Korrelationsmatrix
round( cor( dat , use = "pairwise.complete.obs") , 2 )
&#8288;</code>

</p>




<h4>Abschnitt 8.2.5: Durchführung der multiplen Imputation in R</h4>



<h5>Listing 2: Variablenauswahl und leere Imputation</h5>

<p>In diesem Abschnitt wird die multiple Imputation basierend auf dem MICE-Ansatz im 
Paket <code>mice</code> in R umgesetzt. Als Datensatz soll <code>data08H</code> verwendet 
werden. 
Zur Vereinfachung der Darstellung wählen wir auf der Ebene der Schüler die 
Variablen Sozialstatus (<code>HISEI</code>), Anzahl der Bücher zu Hause (<code>buch</code>) 
und den WLE der Hörverstehenskompetenz (<code>E8LWLE</code>) sowie einen auf der 
Schulebene erfassten Sozialstatus (<code>SES_Schule</code>) aus.
</p>
<p><code style="white-space: pre;">&#8288;set.seed(56) 
dat &lt;- datenKapitel08$data08H
# wähle Variablen aus 
dat1 &lt;- dat[ , c("idschool", "HISEI", "buch", "E8LWLE",
                 "SES_Schule") ]
colMeans(is.na(dat1)) 
# führe leere Imputation durch
imp0 &lt;- mice::mice(dat1, m=0, maxit=0)
&#8288;</code>

</p>



<h5>Listing 3: Spezifikation der Imputationsmethoden</h5>

<p>Die nachfolgende Syntax zeigt die Spezifikation der Imputationsmethoden im 
Vektor <code>impMethod</code> in <code>mice</code> für unser Datenbeispiel.
</p>
<p><code style="white-space: pre;">&#8288;impMethod &lt;- imp0$method 
impMethod["HISEI"] &lt;- "2l.continuous" 
# [...]  weitere Spezifikationen
impMethod["SES_Schule"] &lt;- "2lonly.norm" 
impMethod
&#8288;</code>

</p>



<h5>Listing 4: Definition der Prädiktormatrix für die Imputation in 
mice</h5>

<p>Nachfolgender R-Code zeigt die Definition der Prädiktormatrix (Matrix 
<code>predMatrix</code>) für die Imputation in <code>mice</code>.
</p>
<p><code style="white-space: pre;">&#8288;predMatrix &lt;- imp0$predictorMatrix 
predMatrix[-1,"idschool"] &lt;- -2 
# [...]
predMatrix
&#8288;</code>

</p>



<h5>Listing 5: Datenimputation</h5>

<p>Die Imputation kann nun unter dem Aufruf der Funktion <code>mice</code> unter 
Übergabe der Imputationsmethoden und der Prädiktormatrix erfolgen. 
Für das PMM werden 5 Donoren gewählt. Insgesamt sollen 10 imputierte Datensätze 
generiert werden, wobei der Algorithmus 7 Iterationen durchlaufen soll.
</p>
<p><code style="white-space: pre;">&#8288;imp1 &lt;- mice::mice( dat1, imputationMethod=impMethod, 
                    predictorMatrix=predMatrix, donors=5,
                    m=10, maxit=7 )
&#8288;</code>

</p>




<h4>Abschnitt 8.3.2: Dimensionsreduzierende Verfahren für Kovariaten im 
latenten Regressionsmodell</h4>



<h5>Listing 6: Kovariatenauswahl, Interaktionsbildung und Bestimmung 
PLS-Faktoren</h5>

<p>Die Methode des Partial Least Squares soll für den Datensatz <code>data08J</code> 
illustriert werden. 
Es wird zum Auffüllen der Kovariaten mit fehlenden Werten nur ein imputierter 
Datensatz erstellt. 
Danach wird eine PLS-Regression des WLE der Hörverstehenskompetenz 
<code>E8LWLE</code> auf Kovariaten und deren Interaktionen bestimmt. 
Für die Bestimmung der PLS-Faktoren wird das R-Paket <code>pls</code> verwendet. 
Die nachfolgende R-Syntax zeigt die Kovariatenauswahl, die Bildung der 
Interaktionen und die Bestimmung der PLS-Faktoren. Insgesamt entstehen durch 
Aufnahme der Haupteffekte und Interaktionen 55 Kovariaten.
</p>
<p><code style="white-space: pre;">&#8288;dat &lt;- datenKapitel08$data08J
#*** Kovariatenauswahl
kovariaten &lt;- scan(what="character", nlines=2) 
female migrant HISEI eltausb buch
SK LF NSchueler NKlassen SES_Schule

X &lt;- scale( dat[, kovariaten ] )
V &lt;- ncol(X) 
# bilde alle Zweifachinteraktionen 
c2 &lt;- combinat::combn(V,2) 
X2 &lt;- apply( c2 , 2 , FUN = function(cc){ 
             X[,cc[1]] * X[,cc[2]] } ) 
X0 &lt;- cbind( X , X2 )
mod1 &lt;- pls::plsr( dat$E8LWLE ~ X0 , ncomp=55  ) 
summary(mod1)
&#8288;</code>

</p>




<h4>Abschnitt 8.3.3: Ziehung von Plausible Values in R</h4>

<p>In diesem Abschnitt soll die Ziehung von Plausible Values mit dem R-Paket 
<code>TAM</code> illustriert werden. Dabei beschränken wir uns auf den 
Kompetenzbereich des Hörverstehens. 
</p>


<h5>Listing 7: PLS-Faktoren auswählen</h5>

<p>In Abschnitt 8.3.2 wurden dabei die Kovariaten auf PLS-Faktoren reduziert. 
Für die Ziehung von Plausible Values werden nachfolgend 10 PLS-Faktoren 
verwendet.
</p>
<p><code style="white-space: pre;">&#8288;facs &lt;- mod1$scores[,1:10]
&#8288;</code>

</p>



<h5>Listing 8: Rasch-Skalierung</h5>

<p>Für die Hörverstehenskompetenz im Datensatz <code>data08K</code> wird nachfolgend das 
Messmodell als Rasch-Modell geschätzt. Dabei werden Stichprobengewichte für die 
Bestimmung der Itemparameter verwendet.
</p>
<p><code style="white-space: pre;">&#8288;dat2 &lt;- datenKapitel08$data08K
items &lt;- grep("E8L", colnames(dat2), value=TRUE)
# Schätzung des Rasch-Modells in TAM
mod11 &lt;- TAM::tam.mml( resp= dat2[,items ] , 
                       pid = dat2$idstud,  
                       pweights = dat2$wgtstud )
&#8288;</code>

</p>



<h5>Listing 9: Individuelle Likelihood, latente Regressionsmodell und 
PV-Ziehung</h5>

<p>Bei einer Fixierung von Itemparametern ist die bedingte Verteilung 
<code class="reqn">P(\mathbf{X}|\boldsymbol{\theta})</code> des Messmodells konstant. 
Die Schätzung von Item-Response-Modellen erfolgt in <code>TAM</code> unter Verwendung 
eines diskreten Gitters von <code class="reqn">\boldsymbol{\theta}</code>-Werten. 
Während der Anpassung des Rasch-Modells in <code>mod11</code> liegt daher die auf 
diesem Gitter ausgewertete sog. individuelle Likelihood 
<code class="reqn">P(\mathbf{X}|\boldsymbol{\theta})</code> vor, die mit der Funktion 
<code>IRT.likelihood</code> aus dem Objekt <code>mod11</code> extrahiert werden kann. 
Das latente Regressionsmodell kann unter Rückgriff auf die individuelle 
Likelihood mit der Funktion <code>tam.latreg</code> angepasst werden. 
Die Ziehung der Plausible Values erfolgt anschließend mit der Funktion 
<code>tam.pv</code>.
</p>
<p><code style="white-space: pre;">&#8288;#*** extrahiere individuelle Likelihood
lmod11 &lt;- IRT.likelihood(mod11) 
#*** schätze latentes Regressionsmodell
mod12 &lt;- TAM::tam.latreg( like = lmod11 , Y = facs )
#*** ziehe Plausible Values 
pv12 &lt;- TAM::tam.pv(mod12, normal.approx=TRUE, 
                    samp.regr=TRUE , ntheta=400)
&#8288;</code>

</p>



<h5>Listing 10: Plausible Values extrahieren</h5>

<p>Die imputierten Plausible Values lassen sich im Element <code>$pv</code> des 
Ergebnisobjekts aus <code>tam.pv</code> extrahieren.
</p>
<p><code style="white-space: pre;">&#8288;#*** Plausible Values für drei verschiedene Schüler
round( pv12$pv[c(2,5,9),] , 3 )
&#8288;</code>

</p>




<h3>Author(s)</h3>

<p>Alexander Robitzsch, Giang Pham, Takuya Yanagida
</p>


<h3>References</h3>

<p>Robitzsch, A., Pham, G. &amp; Yanagida, T. (2016). Fehlende Daten und Plausible 
Values.
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 259&ndash;293). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel08">datenKapitel08</a></code>, den im Kapitel verwendeten Daten.<br />
Zurück zu <code><a href="#topic+Kapitel+207">Kapitel 7</a></code>, Statistische Analysen produktiver 
Kompetenzen .<br />
Zu <code><a href="#topic+Kapitel+209">Kapitel 9</a></code>, Fairer Vergleich in der Rückmeldung.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(TAM)
library(mice)
library(miceadds)
library(pls)
library(combinat)
library(mitml)

data(datenKapitel08)
data08H &lt;- datenKapitel08$data08H
data08I &lt;- datenKapitel08$data08I
data08J &lt;- datenKapitel08$data08J
data08K &lt;- datenKapitel08$data08K

## -------------------------------------------------------------
## Abschnitt 8.1.1: Konsequenzen fehlender Daten und 
##                  messfehlerbehafteter Variablen
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 8.1.1, Listing 1: Deskriptive Statistiken des 
#                             Illustrationsdatensatzes
#

data(datenKapitel08)
dat &lt;- datenKapitel08$data08I[,-1]
#*** Missinganteile
round( colMeans( is.na(dat), na.rm=TRUE) , 2 )     
#*** Mittelwerte
round( apply( dat , 2 , mean , na.rm=TRUE ) , 2 )   
#*** Zusammenhang von Missingindikator und Variablen 
round( miceadds::mi_dstat( dat[,c("WLE","X")] ) , 2 )
#*** Varianzen
round( apply( dat , 2 , var , na.rm=TRUE ) , 2 ) 
#*** Korrelationsmatrix
round( cor( dat , use = "pairwise.complete.obs") , 2 )


## -------------------------------------------------------------
## Abschnitt 8.2: Multiple Imputation
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 1: Variablenauswahl und leere 
#                             Imputation
#

set.seed(56) 
data(datenKapitel08)
dat &lt;- datenKapitel08$data08H
# wähle Variablen aus 
dat1 &lt;- dat[ , c("idschool", "HISEI", "buch", "E8LWLE",
                 "SES_Schule") ]
colMeans(is.na(dat1)) 
# führe leere Imputation durch
imp0 &lt;- mice::mice(dat1, m=0, maxit=0)

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 2: Spezifikation der Imputations-
#                             methoden
#

impMethod &lt;- imp0$method 
impMethod["HISEI"] &lt;- "2l.continuous" 
# [...]  weitere Spezifikationen
impMethod["SES_Schule"] &lt;- "2lonly.norm" 
impMethod     

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 2b: Ergänzung zum Buch
#

# [...]  weitere Spezifikationen
impMethod["buch"]  &lt;- "2l.pmm"
impMethod

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 3: Definition der Prädiktormatrix 
#                             für die Imputation in mice
#

predMatrix &lt;- imp0$predictorMatrix 
predMatrix[-1,"idschool"] &lt;- -2 
# [...]
predMatrix    

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 3b: Ergänzung zum Buch
#

# [...]
predMatrix[2:4,2:4] &lt;- 3*predMatrix[2:4,2:4]
predMatrix

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 4: Führe Imputation durch
#

imp1 &lt;- mice::mice( dat1, imputationMethod=impMethod, 
  predictorMatrix=predMatrix, donors=5, m=10, maxit=7)

# -------------------------------------------------------------
# Abschnitt 8.2.5, Listing 4b: Ergänzung zum Buch
#

#-- Mittelwert HISEI
wmod1 &lt;- with( imp1 , lm(HISEI ~ 1))
summary( mice::pool( wmod1 ) )

#-- lineare Regression HISEI auf Büchervariable
wmod2 &lt;- with( imp1 , lm(E8LWLE ~ HISEI) )
summary( mice::pool( wmod2 ))

#-- Inferenz Mehrebenenmodelle mit Paket mitml
imp1b &lt;- mitml::mids2mitml.list(imp1)
wmod3 &lt;- with(imp1b, lme4::lmer( HISEI ~ (1|idschool)) )
mitml::testEstimates(wmod3, var.comp=TRUE)

## ------------------------------------------------------------
## Abschnitt 8.3.2: Dimensionsreduzierende Verfahren für 
## Kovariaten im latenten Regressionsmodell
## ------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 8.3.2, Listing 1: Kovariatenauswahl, Interaktions- 
#                         bildung und Bestimmung PLS-Faktoren
#

set.seed(56)
data(datenKapitel08)
dat &lt;- datenKapitel08$data08J

#*** Kovariatenauswahl
kovariaten &lt;- scan(what="character", nlines=2) 
  female migrant HISEI  eltausb buch  
  SK LF NSchueler NKlassen SES_Schule

X &lt;- scale( dat[, kovariaten ] )
V &lt;- ncol(X) 
# bilde alle Zweifachinteraktionen 
c2 &lt;- combinat::combn(V,2) 
X2 &lt;- apply( c2 , 2 , FUN = function(cc){ 
            X[,cc[1]] * X[,cc[2]] } ) 
X0 &lt;- cbind( X , X2 )
# Partial Least Squares Regression
mod1 &lt;- pls::plsr( dat$E8LWLE ~ X0 , ncomp=55  ) 
summary(mod1)

# -------------------------------------------------------------
# Abschnitt 8.3.2, Listing 1b: Ergänzung zum Buch
# Abbildung: Aufgeklärter Varianzanteil
#

# Principal Component Regression (Extraktion der Hauptkomponenten)
mod2 &lt;- pls::pcr(  dat$E8LWLE ~ X0 , ncomp=55 )
summary(mod2)

#*** extrahierte Varianzen mit PLS-Faktoren und PCA-Faktoren
res &lt;- mod1
R2 &lt;- base::cumsum(res$Xvar) / res$Xtotvar
ncomp &lt;- 55
Y &lt;- dat$E8LWLE
R21 &lt;- base::sapply( 1:ncomp , FUN = function(cc){
  1 - stats::var( Y -  res$fitted.values[,1,cc] ) / stats::var( Y )
} )
dfr &lt;- data.frame("comp" = 1:ncomp , "PLS" = R21 )

res &lt;- mod2
R2 &lt;- base::cumsum(res$Xvar) / res$Xtotvar
ncomp &lt;- 55
Y &lt;- dat$E8LWLE
R21 &lt;- base::sapply( 1:ncomp , FUN = function(cc){
           1 - stats::var( Y -  res$fitted.values[,1,cc] ) / stats::var( Y )
} )
dfr$PCA &lt;- R21


plot( dfr$comp , dfr$PLS , type="l" , xlab="Anzahl Faktoren" , 
      ylab="Aufgeklärter Varianzanteil" ,
      ylim=c(0,.3) )
points( dfr$comp , dfr$PLS , pch=16 )        
points( dfr$comp , dfr$PCA , pch=17 )        
lines( dfr$comp , dfr$PCA , lty=2 )        
legend( 45 , .15 , c("PLS" , "PCA") , pch=c(16,17) , lty=c(1,2))

## ------------------------------------------------------------
## Abschnitt 8.3.3: Ziehung von Plausible Values in R
## ------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 8.3.3, Listing 1: PLS-Faktoren auswählen
#

facs &lt;- mod1$scores[,1:10]

# -------------------------------------------------------------
# Abschnitt 8.3.3, Listing 1b: Ergänzung zum Buch
#
set.seed(98766)

# -------------------------------------------------------------
# Abschnitt 8.3.3, Listing 2: Anpassung kognitive Daten
#

data(datenKapitel08)
dat2 &lt;- datenKapitel08$data08K
items &lt;- grep("E8L", colnames(dat2), value=TRUE)
# Schätzung des Rasch-Modells in TAM
mod11 &lt;- TAM::tam.mml( resp= dat2[,items ] , 
       pid = dat2$idstud, pweights = dat2$wgtstud ) 

# -------------------------------------------------------------
# Abschnitt 8.3.3, Listing 3: Individuelle Likelihood, latentes 
#                             Regressionsmodell und PV-Ziehung
#

#*** extrahiere individuelle Likelihood
lmod11 &lt;- IRT.likelihood(mod11) 
#*** schätze latentes Regressionsmodell
mod12 &lt;- TAM::tam.latreg( like = lmod11 , Y = facs )
#*** ziehe Plausible Values 
pv12 &lt;- TAM::tam.pv(mod12, normal.approx=TRUE, 
               samp.regr=TRUE , ntheta=400)

# -------------------------------------------------------------
# Abschnitt 8.3.3, Listing 4: Plausible Values extrahieren
#

#*** Plausible Values für drei verschiedene Schüler
round( pv12$pv[c(2,5,9),] , 3 )


# -------------------------------------------------------------
# Abschnitt 8.3.3, Listing 4b: Ergänzung zum Buch
#

hist( pv12$pv$PV1.Dim1 )

# Korrelation mit Kovariaten
round( cor( pv12$pv$PV1.Dim1 , dat[,kovariaten] , 
            use="pairwise.complete.obs") , 3 )
round( cor( dat$E8LWLE , dat[,kovariaten] , 
            use="pairwise.complete.obs" ) , 3 )

## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+20+209'>Kapitel 9: Fairer Vergleich in der Rueckmeldung</h2><span id='topic+Kapitel+209'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 9, <em>Fairer Vergleich in der 
Rückmeldung</em>, im Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Details</h3>



<h4>Vorbereitungen</h4>

<p>Der zur Illustration verwendete Datensatz <code>dat</code> beinhaltet (imputierte) 
aggregierte Leistungs- und Hintergrunddaten von 244 Schulen, bestehend aus 74 
ländlichen allgemeinbildenden Pflichtschulen (APS, Stratum 1), 69 städtischen 
APS (Stratum 2), 52 ländlichen allgemeinbildenden höheren Schulen (AHS, Stratum 
3) und 49 städtischen AHS (Stratum 4). 
Im Kapitel wird zur Bildung von Interaktionseffekten und quadratischen Termen 
der Kovariaten eine neue Funktion <code>covainteraction</code> verwendet.
</p>
<p><code style="white-space: pre;">&#8288;data(datenKapitel09)
dat &lt;- datenKapitel09

covainteraction &lt;- function(dat,covas,nchar){
  for(ii in 1:(length(covas))){
    vv1 &lt;- covas[ii]
    # Interaktion von vv1 mit sich selbst
    subname1 &lt;- substr(vv1,1,nchar)
    intvar &lt;- paste0(subname1, subname1)
    if(vv1 == covas[1]){
      dat.int &lt;- dat[,vv1]*dat[,vv1];
      newvars &lt;- intvar } else {
        dat.int &lt;- cbind(dat.int,dat[,vv1]*dat[,vv1]); 
        newvars &lt;- c(newvars,intvar) 
      }
    # Interaktion von vv1 mit restlichen Variablen
    if(ii &lt; length(covas)){
      for(jj in ((ii+1):length(covas))){
        vv2 &lt;- covas[jj]
        subname2 &lt;- substr(vv2,1,nchar)
        intvar &lt;- paste0(subname1, subname2)
        newvars &lt;- c(newvars, intvar)
        dat.int &lt;- cbind(dat.int,dat[,vv1]*dat[,vv2])
      }
    }
    
  }
  dat.int &lt;- data.frame(dat.int)
  names(dat.int) &lt;- newvars
  return(dat.int)
}
&#8288;</code>

</p>



<h4>Abschnitt 9.2.5.1: Kovariaten und Interaktionsterme</h4>



<h5>Listing 1: Kovariatenauswahl und z-Standardisierung</h5>

<p>Als Variablen zur Beschreibung von Kontext und Schülerzusammensetzung in den 
Schulen werden in diesem Beispiel die logarithmierte Schulgröße <code>groesse</code>, 
der Anteil an Mädchen <code>female</code>, der Anteil an Schülerinnen und Schülern mit 
Migrationshintergrund <code>mig</code> und der mittlere sozioökonomische Status (SES) 
<code>sozstat</code> eingeführt. 
Die abhängige Variable ist die aggregierte 
Schülerleistung der Schule <code>TWLE</code>. Alle Kovariaten (<code>vars</code>) werden 
zunächst z-standardisiert (<code>zvars</code>).
</p>
<p><code style="white-space: pre;">&#8288;vars &lt;- c("groesse","female","mig","sozstat")
zvars &lt;- paste0("z",vars)
dat[,zvars] &lt;- scale(dat[,vars],scale = TRUE)
&#8288;</code>

</p>



<h5>Listing 2: Interaktionen bilden, z-standardisieren</h5>

<p>Zur Optimierung der Modellspezifikation werden Interaktionseffekte und 
quadratische Terme der Kovariaten gebildet, dann z-standardisiert und in den 
Gesamtdatensatz hinzugefügt. 
Die neuen Variablennamen sind in der Liste <code>intvars</code> aufgelistet.
</p>
<p><code style="white-space: pre;">&#8288;dat1 &lt;- LSAmitR::covainteraction(dat = dat,covas = zvars,nchar = 4)
intvars &lt;- names(dat1) # Interaktionsvariablen
dat1[,intvars] &lt;- scale(dat1[,intvars],scale = TRUE)
dat &lt;- cbind(dat,dat1)
&#8288;</code>

</p>



<h5>Listing 3: Haupt- und Interaktionseffekte</h5>

<p><code style="white-space: pre;">&#8288;maineff &lt;- zvars # Haupteffekte 
alleff &lt;- c(zvars,intvars) # Haupt- und Interaktionseffekte
&#8288;</code>

</p>




<h4>Abschnitt 9.2.5.2: OLS-Regression</h4>



<h5>Listing 4: OLS-Regression mit Haupteffekten</h5>

<p>Das OLS-Regressionsmodell mit den Haupteffekten als Modellprädiktoren 
(<code>ols.mod1</code>) für Schulen im Stratum (<code>st</code>) 4
</p>
<p><code style="white-space: pre;">&#8288;fm.ols1 &lt;- paste0("TWLE ~ ",paste(maineff,collapse=" + "))
fm.ols1 &lt;- as.formula(fm.ols1) # Modellgleichung
st &lt;- 4
pos &lt;- which(dat$stratum == st) # Schulen im Stratum st
ols.mod1 &lt;- lm(formula = fm.ols1,data = dat[pos,]) # Regression
&#8288;</code>

</p>




<h4>Abschnitt 9.2.5.3: Lasso-Regression</h4>



<h5>Listing 5: Datenaufbereitung</h5>

<p>Für die Durchführung der Lasso-Regression wird das R-Paket glmnet 
(Friedman et al., 2010) eingesetzt. Die Kovariatenmatrix (<code>Z</code>) sowie der 
Vektor der abhängigen Leistungswerte (<code>Y</code>) müssen definiert werden.
</p>
<p><code style="white-space: pre;">&#8288;library(glmnet)
Z &lt;- as.matrix(dat[pos,alleff]) # Kovariatenmatrix
Y &lt;- dat$TWLE[pos] # Abhängige Variable
&#8288;</code>

</p>



<h5>Listing 6: Bestimmung Teilmengen für Kreuzvalidierung, 
Lasso-Regression</h5>

<p>Das Lasso-Verfahren wird mit der Funktion <code>cv.glmnet()</code> durchgeführt. 
Zur Auswahl eines optimalen shrinkage <code class="reqn">\lambda</code> wird das Verfahren der 
K-fachen Kreuzvalidierung verwendet. 
Die Schulstichprobe wird durch ID-Zuweisung (<code>foldid</code>) verschiedenen 
Teilmengen zugewiesen.
</p>
<p><code style="white-space: pre;">&#8288;nid &lt;- floor(length(pos)/3) # Teilmengen definieren 
foldid &lt;- rep(c(1:nid),3,length.out=length(pos)) # Zuweisung
lasso.mod2 &lt;- glmnet::cv.glmnet(x=Z,y=Y,alpha = 1, foldid = foldid)
&#8288;</code>

</p>



<h5>Listing 7: Erwartungswerte der Schulen</h5>

<p>Entsprechend <code>lambda.min</code> werden die Regressionskoeffizienten und die 
entsprechenden Erwartungswerte der Schulen bestimmt.
</p>
<p><code style="white-space: pre;">&#8288;lasso.pred2 &lt;- predict(lasso.mod2,newx = Z,s="lambda.min")
dat$expTWLE.Lasso2[pos] &lt;- as.vector(lasso.pred2)
&#8288;</code>

</p>



<h5>Listing 8: Bestimmung R^2</h5>

<p>Bestimmung des aufgeklärten Varianzanteils der Schulleistung <code>R^2</code>.
</p>
<p><code style="white-space: pre;">&#8288;varY &lt;- var(dat$TWLE[pos])
varY.lasso.mod2 &lt;- var(dat$expTWLE.Lasso2[pos])
R2.lasso.mod2 &lt;- varY.lasso.mod2/varY
&#8288;</code>

</p>




<h4>Abschnitt 9.2.5.4: Nichtparametrische Regression</h4>



<h5>Listing 9: Distanzberechnung</h5>

<p>Der erste Schritt zur Durchführung einer nichtparametrischen Regression ist die 
Erstellung der Distanzmatrix zwischen Schulen. In diesem Beispiel wird die 
euklidische Distanz als Distanzmaß berechnet, alle standardisierten Haupteffekte 
sind eingeschlossen. Außerdem setzen wir die Gewichte von allen Kovariaten 
(<code>gi</code>) auf 1. <code>dfr.i</code> in diesem Beispiel ist die Distanzmatrix für
erste Schule im Stratum.
</p>
<p><code style="white-space: pre;">&#8288;N &lt;- length(pos) # Anzahl Schulen im Stratum
schools &lt;- dat$idschool[pos] # Schulen-ID
i &lt;- 1
# Teildatensatz von Schule i
dat.i &lt;- dat[pos[i],c("idschool","TWLE",maineff)]
names(dat.i) &lt;- paste0(names(dat.i),".i")
# Daten der Vergleichsschulen
dat.vgl &lt;- dat[pos[-i],c("idschool","TWLE",maineff)]
index.vgl &lt;- match(dat.vgl$idschool,schools)
# Daten zusammenfügen
dfr.i &lt;- data.frame("index.i"=i,dat.i,"index.vgl"=index.vgl,
                    dat.vgl, row.names=NULL)
# Distanz zur Schule i
dfr.i$dist &lt;- 0
gi &lt;- c(1,1,1,1)
for(ii in 1:length(maineff)){
  vv &lt;- maineff[ii]
  pair.vv &lt;- grep(vv, names(dfr.i), value=T)
  dist.vv &lt;- gi[ii]*((dfr.i[,pair.vv[1]]-dfr.i[,pair.vv[2]])^2)
  dfr.i$dist &lt;- dfr.i$dist + dist.vv }
&#8288;</code>

</p>



<h5>Listing 10: H initiieren</h5>

 
<p><code class="reqn">p(x) = \frac{\lambda^x e^{-\lambda}}{x!}</code>.
</p>
<p>Die Gewichte <code class="reqn">w_{ik}</code> für jedes Paar (i, k) von Schulen werden mithilfe der 
Distanz, der Gauß’schen Kernfunktion (<code>dnorm</code>) als Transformationsfunktion
sowie einer schulspezifischen Bandweite <code class="reqn">h_i</code> berechnet. Die Auswahl des optimalen
Werts <code class="reqn">\hat{h_i}</code> für jede Schule i erfolgt nach Vieu (1991). Zunächst wird
ein Vektor <code>H</code> so gewählt, dass der optimale Wert <code class="reqn">\hat{h_i}</code> größer 
als der kleinste und kleiner als der größte Wert in <code>H</code> ausfällt. 
Je kleiner das Intervall zwischen den Werten in <code>H</code> ist, desto 
wahrscheinlicher ist, dass ein Listenelement den optimalen Wert erlangt. 
Auf der anderen Seite korrespondiert die Rechenzeit mit der Länge von <code>H</code>. 
Gemäß der Größe der Vergleichsgruppe wählen wir eine Länge von 30 für <code>H</code>, 
zusätzlich wird ein sehr großer Wert (100000) für die Fälle hinzugefügt, bei 
denen alle Gewichte beinahe gleich sind.
</p>
<p><code style="white-space: pre;">&#8288;d.dist &lt;- max(dfr.i$dist)-min(dfr.i$dist)
H &lt;- c(seq(d.dist/100,d.dist,length=30),100000)
V1 &lt;- length(H) 
# Anzahl Vergleichsschulen
n &lt;- nrow(dfr.i) 
&#8288;</code>

</p>



<h5>Listing 11: Leave-One-Out-Schätzer der jeweiligen Vergleichsschule k
nach h in H</h5>

<p>Auf Basis aller Werte in <code>H</code> und dem jeweils entsprechenden Gewicht <code class="reqn">w_{ik}</code>
(<code>wgt.h</code>) werden die Leave-One-Out-Schätzer der jeweiligen Vergleichsschule
(<code>pred.k</code>) berechnet.
</p>
<p><code style="white-space: pre;">&#8288;sumw &lt;- 0*H # Vektor w_{ik} initiieren, h in H
av &lt;- "TWLE"
dfr0.i &lt;- dfr.i[,c("idschool",av)]
# Schleife über alle h-Werte
for (ll in 1:V1 ){
  h &lt;- H[ll]
  # Gewicht w_{ik} bei h
  dfr.i$wgt.h &lt;- dnorm(sqrt(dfr.i$dist), mean=0, sd=sqrt(h))
  # Summe von w_{ik} bei h
  sumw[which(H==h)] &lt;- sum(dfr.i$wgt.h)
  # Leave-one-out-Schätzer von Y_k
  for (k in 1:n){
    # Regressionsformel
    fm &lt;- paste0(av,"~",paste0(maineff,collapse="+"))
    fm &lt;- as.formula(fm)
    # Regressionsanalyse ohne Beitrag von Schule k
    dfr.i0 &lt;- dfr.i[-k,]
    mod.k &lt;- lm(formula=fm,data=dfr.i0,weights=dfr.i0$wgt.h)
    # Erwartungswert anhand Kovariaten der Schule k berechnen
    pred.k &lt;- predict(mod.k, dfr.i)[k]
    dfr0.i[k,paste0( "h_",h) ] &lt;- pred.k
}}
# Erwartungswerte auf Basis verschiedener h-Werte
dfr1 &lt;- data.frame("idschool.i"=dfr.i$idschool.i[1],"h"=H )
&#8288;</code>

</p>



<h5>Listing 12: Kreuzvalidierungskriterium nach h in H</h5>

<p>Zur Berechnung der Kreuzvalidierungskriterien (<code>CVh</code>, je kleiner, desto 
reliabler sind die Schätzwerte) für alle Werte h in <code>H</code> verwenden wir in 
diesem Beispiel die Plug-in-Bandweite nach Altman und Leger (1995) (<code>hAL</code>), 
die mit der Funktion <code>ALbw()</code> des R-Pakets <code>kerdiest</code> aufrufbar ist.
</p>
<p><code style="white-space: pre;">&#8288;library(kerdiest)
hAL &lt;- kerdiest::ALbw("n",dfr.i$dist) # Plug-in Bandweite
dfr.i$cross.h &lt;- hAL
dfr.i$crosswgt &lt;- dnorm( sqrt(dfr.i$dist), mean=0, sd = sqrt(hAL) ) 
# Kreuzvalidierungskriterium CVh
vh &lt;- grep("h_",colnames(dfr0.i),value=TRUE)
for (ll in 1:V1){
  dfr1[ll,"CVh"] &lt;- sum( (dfr0.i[,av] - dfr0.i[,vh[ll]])^2 * 
                           dfr.i$crosswgt) / n}
&#8288;</code>

</p>



<h5>Listing 13: Bestimmung des optimalen Wertes von h</h5>

<p>Der optimale Wert von h in <code>H</code> (<code>h.min</code>) entspricht dem mit dem 
kleinsten resultierenden <code>CVh</code>.
</p>
<p><code style="white-space: pre;">&#8288;dfr1$min.h.index &lt;- 0
ind &lt;-  which.min( dfr1$CVh )
dfr1$min.h.index[ind] &lt;- 1
dfr1$h.min &lt;- dfr1$h[ind]
&#8288;</code>

</p>



<h5>Listing 14: Kleinste Quadratsumme der Schätzfehler</h5>

<p>Kleinste Quadratsumme der Schätzfehler der nichtparametrischen Regression mit
h=<code>h.min</code>.
</p>
<p><code style="white-space: pre;">&#8288;dfr1$CVhmin &lt;- dfr1[ ind , "CVh" ]
&#8288;</code>

</p>



<h5>Listing 15: Effizienzsteigerung</h5>

<p>Die Effizienz (Steigerung der Schätzungsreliabilität) der nichtparametrischen 
Regression gegenüber der linearen Regression (äquivalent zu <code>CVh</code> bei 
h=100000).
</p>
<p><code style="white-space: pre;">&#8288;dfr1$eff_gain &lt;-  100 * ( dfr1[V1,"CVh"] / dfr1$CVhmin[1] - 1 )
&#8288;</code>

</p>



<h5>Listing 16: Durchführung der nichtparametrischen Regression</h5>

<p><code style="white-space: pre;">&#8288;h &lt;- dfr1$h.min[1]  # h.min
dfr.i$wgt.h &lt;- dnorm(sqrt(dfr.i$dist),sd=sqrt(h))/
  dnorm(0,sd= sqrt(h)) # w_{ik} bei h.min      
dfr.i0 &lt;- dfr.i
# Lokale Regression    
mod.ii &lt;- lm(formula=fm,data=dfr.i0,weights=dfr.i0$wgt.h)
# Kovariaten Schule i
predM &lt;- data.frame(dfr.i[1,paste0(maineff,".i")])    
names(predM) &lt;- maineff
pred.ii &lt;- predict(mod.ii, predM) # Schätzwert Schule i
dat$expTWLE.np[match(dfr1$idschool.i[1],dat$idschool)] &lt;- pred.ii
&#8288;</code>

</p>




<h4>Abschnitt 9.2.7, Berücksichtigung der Schätzfehler</h4>

<p>Der Erwartungsbereich wird nach der im Buch beschriebenen Vorgehensweise
bestimmt.
</p>


<h5>Listing 17: Bestimmung des Erwartungsbereichs</h5>

<p>Bestimmung der Breite des Erwartungsbereichs aller Schulen auf Basis der 
Ergebnisse der OLS-Regression mit Haupteffekten.
</p>
<p><code style="white-space: pre;">&#8288;vv &lt;- "expTWLE.OLS1" # Variablenname
mm &lt;- "OLS1" # Kurzname des Modells
dfr &lt;- NULL # Ergebnistabelle
# Schleife über alle möglichen Breite von 10 bis 60
for(w in 10:60){
  # Variablen für Ergebnisse pro w
  var &lt;- paste0(mm,".pos.eb",w) # Position der Schule
  var.low &lt;- paste0(mm,".eblow",w) # Untere Grenze des EBs
  var.upp &lt;- paste0(mm,".ebupp",w) # Obere Grenze des EBs
  # Berechnen
  dat[,var.low] &lt;- dat[,vv]-w/2 # Untere Grenze des EBs
  dat[,var.upp] &lt;- dat[,vv]+w/2 # Obere Grenze des EBs 
  # Position: -1=unterhalb, 0=innerhalb, 1=oberhalb des EBs 
  dat[,var] &lt;- -1*(dat$TWLE &lt; dat[,var.low]) + 1*(dat$TWLE &gt; dat[,var.upp])
  # Verteilung der Schulpositionen
  tmp &lt;- data.frame(t(matrix(prop.table(table(dat[,var])))))
  names(tmp) &lt;- c("unterhalb","innerhalb","oberhalb")
  tmp &lt;- data.frame("ModellxBereich"=var,tmp); dfr &lt;- rbind(dfr,tmp) }

# Abweichung zur Wunschverteilung 25-50-25 
dfr1 &lt;- dfr 
dfr1[,c(2,4)] &lt;- (dfr1[,c(2,4)] - .25)^2 
dfr1[,3] &lt;- (dfr1[,3] - .5)^2 
dfr1$sumquare &lt;- rowSums(dfr1[,-1]) 
# Auswahl markieren 
dfr$Auswahl &lt;- 1*(dfr1$sumquare == min(dfr1$sumquare) )
&#8288;</code>

</p>




<h3>Author(s)</h3>

<p>Giang Pham, Alexander Robitzsch, Ann Cathrice George, Roman Freunberger
</p>


<h3>References</h3>

<p>Pham, G., Robitzsch, A., George, A. C. &amp; Freunberger, R. (2016).
Fairer Vergleich in der Rückmeldung. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 295&ndash;332). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel09">datenKapitel09</a></code>, den im Kapitel verwendeten Daten.<br />
Zurück zu <code><a href="#topic+Kapitel+208">Kapitel 8</a></code>, Fehlende Daten und Plausible Values.<br />
Zu <code><a href="#topic+Kapitel+2010">Kapitel 10</a></code>, Reporting und Analysen.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(miceadds)
library(glmnet)
library(kerdiest)

covainteraction &lt;- function(dat,covas,nchar){
  for(ii in 1:(length(covas))){
    vv1 &lt;- covas[ii]
    # Interaktion von vv1 mit sich selbst
    subname1 &lt;- substr(vv1,1,nchar)
    intvar &lt;- paste0(subname1, subname1)
    if(vv1 == covas[1]){
      dat.int &lt;- dat[,vv1]*dat[,vv1];
      newvars &lt;- intvar } else {
        dat.int &lt;- cbind(dat.int,dat[,vv1]*dat[,vv1]); 
        newvars &lt;- c(newvars,intvar) 
      }
    # Interaktion von vv1 mit restlichen Variablen
    if(ii &lt; length(covas)){
      for(jj in ((ii+1):length(covas))){
        vv2 &lt;- covas[jj]
        subname2 &lt;- substr(vv2,1,nchar)
        intvar &lt;- paste0(subname1, subname2)
        newvars &lt;- c(newvars, intvar)
        dat.int &lt;- cbind(dat.int,dat[,vv1]*dat[,vv2])
      }
    }
    
  }
  dat.int &lt;- data.frame(dat.int)
  names(dat.int) &lt;- newvars
  return(dat.int)
}

data(datenKapitel09)
dat &lt;- datenKapitel09

# Platzhalter für Leistungsschätzwerte aller Modelle
dat$expTWLE.OLS1 &lt;- NA
dat$expTWLE.OLS2 &lt;- NA
dat$expTWLE.Lasso1 &lt;- NA
dat$expTWLE.Lasso2 &lt;- NA
dat$expTWLE.np &lt;- NA

## -------------------------------------------------------------
## Abschnitt 9.2.5, Umsetzung in R
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 9.2.5.1, Listing 1: Kovariatenauswahl und
#                               z-Standardisierung
#

vars &lt;- c("groesse","female","mig","sozstat")
zvars &lt;- paste0("z",vars)
dat[,zvars] &lt;- scale(dat[,vars],scale = TRUE)

# -------------------------------------------------------------
# Abschnitt 9.2.5.1, Listing 2: 
#

# Interaktionen bilden, z-standardisieren  
dat1 &lt;- LSAmitR::covainteraction(dat = dat,covas = zvars,nchar = 4)
intvars &lt;- names(dat1) # Interaktionsvariablen
dat1[,intvars] &lt;- scale(dat1[,intvars],scale = TRUE)
dat &lt;- cbind(dat,dat1)

# -------------------------------------------------------------
# Abschnitt 9.2.5.1, Listing 3: Modellprädiktoren: Haupt- und
#                               Interaktionseffekte
#

maineff &lt;- zvars # Haupteffekte 
alleff &lt;- c(zvars,intvars) # Haupt- und Interaktionseffekte

# -------------------------------------------------------------
# Abschnitt 9.2.5.2, Listing 4: OLS-Regression mit Haupteffekten
# 

fm.ols1 &lt;- paste0("TWLE ~ ",paste(maineff,collapse=" + "))
fm.ols1 &lt;- as.formula(fm.ols1) # Modellgleichung
st &lt;- 4
pos &lt;- which(dat$stratum == st) # Schulen im Stratum st
ols.mod1 &lt;- lm(formula = fm.ols1,data = dat[pos,]) # Regression

# -------------------------------------------------------------
# Abschnitt 9.2.5.3, Listing 5: Lasso-Regression
# Datenaufbereitung
#

library(glmnet)
Z &lt;- as.matrix(dat[pos,alleff]) # Kovariatenmatrix
Y &lt;- dat$TWLE[pos] # Abhängige Variable

# -------------------------------------------------------------
# Abschnitt 9.2.5.3, Listing 6: Lasso-Regression
# Bestimmung Teilmengen für Kreuzvalidierung, Lasso-Regression
#

nid &lt;- floor(length(pos)/3) # Teilmengen definieren 
foldid &lt;- rep(c(1:nid),3,length.out=length(pos)) # Zuweisung
lasso.mod2 &lt;- glmnet::cv.glmnet(x=Z,y=Y,alpha = 1, foldid = foldid)

# -------------------------------------------------------------
# Abschnitt 9.2.5.3, Listing 7: Lasso-Regression
# Erwartungswerte der Schulen
#

lasso.pred2 &lt;- predict(lasso.mod2,newx = Z,s="lambda.min")
dat$expTWLE.Lasso2[pos] &lt;- as.vector(lasso.pred2)

# -------------------------------------------------------------
# Abschnitt 9.2.5.3, Listing 8: Lasso-Regression
# Bestimmung R^2
#

varY &lt;- var(dat$TWLE[pos])
varY.lasso.mod2 &lt;- var(dat$expTWLE.Lasso2[pos])
R2.lasso.mod2 &lt;- varY.lasso.mod2/varY

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 9: Nichtparametrische Regression
# Distanzberechnung zur Schule i (Stratum st)
#

N &lt;- length(pos) # Anzahl Schulen im Stratum
schools &lt;- dat$idschool[pos] # Schulen-ID
i &lt;- 1
# Teildatensatz von Schule i
dat.i &lt;- dat[pos[i],c("idschool","TWLE",maineff)]
names(dat.i) &lt;- paste0(names(dat.i),".i")
# Daten der Vergleichsschulen
dat.vgl &lt;- dat[pos[-i],c("idschool","TWLE",maineff)]
index.vgl &lt;- match(dat.vgl$idschool,schools)
# Daten zusammenfügen
dfr.i &lt;- data.frame("index.i"=i,dat.i,"index.vgl"=index.vgl,
                    dat.vgl, row.names=NULL)
# Distanz zur Schule i
dfr.i$dist &lt;- 0
gi &lt;- c(1,1,1,1)
for(ii in 1:length(maineff)){
  vv &lt;- maineff[ii]
  pair.vv &lt;- grep(vv, names(dfr.i), value=T)
  dist.vv &lt;- gi[ii]*((dfr.i[,pair.vv[1]]-dfr.i[,pair.vv[2]])^2)
  dfr.i$dist &lt;- dfr.i$dist + dist.vv }

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 10: Nichtparametrische Regression
#

# H initiieren
d.dist &lt;- max(dfr.i$dist)-min(dfr.i$dist)
H &lt;- c(seq(d.dist/100,d.dist,length=30),100000)
V1 &lt;- length(H) 
# Anzahl Vergleichsschulen
n &lt;- nrow(dfr.i) 

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 11: Nichtparametrische Regression
# Berechnung der Leave-One-Out-Schätzer der jeweiligen 
# Vergleichsschule k nach h in H
#

sumw &lt;- 0*H # Vektor w_{ik} initiieren, h in H
av &lt;- "TWLE"
dfr0.i &lt;- dfr.i[,c("idschool",av)]
# Schleife über alle h-Werte
for (ll in 1:V1 ){
  h &lt;- H[ll]
  # Gewicht w_{ik} bei h
  dfr.i$wgt.h &lt;- dnorm(sqrt(dfr.i$dist), mean=0, sd=sqrt(h))
  # Summe von w_{ik} bei h
  sumw[which(H==h)] &lt;- sum(dfr.i$wgt.h)
  # Leave-one-out-Schätzer von Y_k
  for (k in 1:n){
    # Regressionsformel
    fm &lt;- paste0(av,"~",paste0(maineff,collapse="+"))
    fm &lt;- as.formula(fm)
    # Regressionsanalyse ohne Beitrag von Schule k
    dfr.i0 &lt;- dfr.i[-k,]
    mod.k &lt;- lm(formula=fm,data=dfr.i0,weights=dfr.i0$wgt.h)
    # Erwartungswert anhand Kovariaten der Schule k berechnen
    pred.k &lt;- predict(mod.k, dfr.i)[k]
    dfr0.i[k,paste0( "h_",h) ] &lt;- pred.k
}}
# Erwartungswerte auf Basis verschiedener h-Werte
dfr1 &lt;- data.frame("idschool.i"=dfr.i$idschool.i[1],"h"=H )

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 12: Nichtparametrische Regression
# Berechnung des Kreuzvalidierungskriteriums nach h in H
#

library(kerdiest)
hAL &lt;- kerdiest::ALbw("n",dfr.i$dist) # Plug-in Bandweite
dfr.i$cross.h &lt;- hAL
dfr.i$crosswgt &lt;- dnorm( sqrt(dfr.i$dist), mean=0, sd = sqrt(hAL) ) 
# Kreuzvalidierungskriterium CVh
vh &lt;- grep("h_",colnames(dfr0.i),value=TRUE)
for (ll in 1:V1){
  dfr1[ll,"CVh"] &lt;- sum( (dfr0.i[,av] - dfr0.i[,vh[ll]])^2 * 
                           dfr.i$crosswgt) / n}

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 13: Nichtparametrische Regression
# Bestimmung optimales Wertes von h (h.min)
#

dfr1$min.h.index &lt;- 0
ind &lt;-  which.min( dfr1$CVh )
dfr1$min.h.index[ind ] &lt;- 1
dfr1$h.min &lt;- dfr1$h[ind]

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 14: Nichtparametrische Regression
# Kleinste Quadratsumme der Schätzfehler
#

dfr1$CVhmin &lt;- dfr1[ ind , "CVh" ]

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 15: Nichtparametrische Regression
# Effizienzsteigerung berechnen
#

dfr1$eff_gain &lt;-  100 * ( dfr1[V1,"CVh"] / dfr1$CVhmin[1] - 1 )

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Listing 16: Nichtparametrische Regression
# Durchführung der nichtparametrischen Regression bei h=h.min
#

h &lt;- dfr1$h.min[1]  # h.min
dfr.i$wgt.h &lt;- dnorm(sqrt(dfr.i$dist),sd=sqrt(h))/
  dnorm(0,sd= sqrt(h)) # w_{ik} bei h.min      
dfr.i0 &lt;- dfr.i
# Lokale Regression    
mod.ii &lt;- lm(formula=fm,data=dfr.i0,weights=dfr.i0$wgt.h)
# Kovariaten Schule i
predM &lt;- data.frame(dfr.i[1,paste0(maineff,".i")])    
names(predM) &lt;- maineff
pred.ii &lt;- predict(mod.ii, predM) # Schätzwert Schule i
dat[match(dfr1$idschool.i[1],dat$idschool), "expTWLE.np"] &lt;- pred.ii   

## -------------------------------------------------------------
## Abschnitt 9.2.5, Umsetzung in R, Ergänzung zum Buch
## -------------------------------------------------------------

# Korrelationen zwischen Haupteffekten
cor(dat[,maineff]) # gesamt
# Pro Stratum
for(s in 1:4) print(cor(dat[which(dat$stratum == s),maineff]))

# -------------------------------------------------------------
# Abschnitt 9.2.5.2, Ergänzung zum Buch
# OLS-Regression
#

# Modellgleichung nur mit Haupteffekten
fm.ols1 &lt;- paste0("TWLE ~ ",paste(maineff,collapse=" + "))
fm.ols1 &lt;- as.formula(fm.ols1)

# Modellgleichung mit Haupteffekten ohne zgroesse
fm.ols1a &lt;- paste0("TWLE ~ ",paste(setdiff(maineff,c("zgroesse")),
                                   collapse=" + "))
fm.ols1a &lt;- as.formula(fm.ols1a)

# Modellgleichung mit Haupt- und Interaktionseffekten
fm.ols2 &lt;- paste0("TWLE ~ ",paste(alleff,collapse=" + "))
fm.ols2 &lt;- as.formula(fm.ols2)

# Ergebnistabelle über 4 Strata hinweg vorbereiten
tab1 &lt;- data.frame("Variable"=c("(Intercept)",maineff))
tab2 &lt;- data.frame("Variable"=c("(Intercept)",alleff))

# Durchführung: Schleife über vier Strata
for(st in 1:4){
  # st &lt;- 4
  # Position Schulen des Stratums st im Datensatz
  pos &lt;- which(dat$stratum == st)
  
  #---------------------------------
  # OLS-Modell 1
  
  # Durchführung
  ols.mod1 &lt;- lm(formula = fm.ols1,data = dat[pos,])
  ols.mod1a &lt;- lm(formula = fm.ols1a,data = dat[pos,])
  
  # Modellergebnisse anzeigen
  summary(ols.mod1)
  summary(ols.mod1a)
  
  # Erwartungswerte der Schulen 
  dat$expTWLE.OLS1[pos] &lt;- fitted(ols.mod1)
  
  # Ergebnisse in Tabelle speichern
  par &lt;- summary(ols.mod1)
  tab.s &lt;- data.frame(par$coef,R2=par$r.squared,R2.adj=par$adj.r.squared)
  names(tab.s) &lt;- paste0("stratum",st,
                         c("_coef","_SE","_t","_p","_R2","_R2.adj"))
  tab1 &lt;- cbind(tab1, tab.s)
  
  # Durchführung OLS-Modell 2
  ols.mod2 &lt;- lm(formula = fm.ols2,data = dat[pos,])
  
  # Modellergebnisse anzeigen
  summary(ols.mod2)
  
  # Erwartungswerte der Schulen
  dat$expTWLE.OLS2[pos] &lt;- fitted(ols.mod2)
  
  # Ergebnisse in Tabelle speichern
  par &lt;- summary(ols.mod2)
  tab.s &lt;- data.frame(par$coef,R2=par$r.squared,R2.adj=par$adj.r.squared)
  names(tab.s) &lt;- paste0("stratum",st,
                         c("_coef","_SE","_t","_p","_R2","_R2.adj"))
  tab2 &lt;- cbind(tab2, tab.s) 
  
}

# Daten Schule 1196 ansehen
dat[which(dat$idschool == 1196),]

# Schätzwerte nach ols.mod1 und ols.mod2 vergleichen
summary(abs(dat$expTWLE.OLS1 - dat$expTWLE.OLS2))
cor.test(dat$expTWLE.OLS1,dat$expTWLE.OLS2)

# Grafische Darstellung des Vergleich (Schule 1196 rot markiert)
plot(dat$expTWLE.OLS1,dat$expTWLE.OLS2,xlim=c(380,650),ylim=c(380,650),
     col=1*(dat$idschool == 1196)+1,pch=15*(dat$idschool == 1196)+1)
abline(a=0,b=1)

# -------------------------------------------------------------
# Abschnitt 9.2.5.3, Ergänzung zum Buch
# Lasso-Regression
#

library(glmnet)

# Variablen für Erwartungswerte
dat$expTWLE.Lasso2 &lt;- dat$expTWLE.Lasso1 &lt;- NA

# Tabelle für Modellergebnisse
tab3 &lt;- data.frame("Variable"=c("(Intercept)",maineff))
tab4 &lt;- data.frame("Variable"=c("(Intercept)",alleff))

for(st in 1:4){
  # st &lt;- 4
  
  # Position Schulen des Stratums st im Datensatz
  pos &lt;- which(dat$stratum == st)
  
  #------------------------------------------------------------#
  # Lasso-Regression mit den Haupteffekten
  
  # Kovariatenmatrix
  Z &lt;- as.matrix(dat[pos,maineff])
  # Abhängige Variable
  Y &lt;- dat$TWLE[pos]
  
  # Kreuzvalidierung: Teilmengen definieren
  nid &lt;- floor(length(pos)/3)
  # Schulen zu Teilmengen zuordnen
  foldid &lt;- rep(c(1:nid),3,length.out=length(pos))
  
  # Regression
  lasso.mod1 &lt;- cv.glmnet(x=Z,y=Y,alpha = 1, foldid = foldid)
  
  # Ergebnisse ansehen
  print(lasso.mod1)
  
  # Lasso-Koeffizienten bei lambda.min
  print(lasso.beta &lt;- coef(lasso.mod1,s="lambda.min"))
  
  # Erwartungswerte der Schulen
  lasso.pred1 &lt;- predict(lasso.mod1,newx = Z,s="lambda.min")
  dat$expTWLE.Lasso1[pos] &lt;- as.vector(lasso.pred1)
  
  # R2 bestimmen
  varY &lt;- var(dat$TWLE[pos])
  varY.lasso.mod1 &lt;- var(dat$expTWLE.Lasso1[pos])
  print(R2.lasso.mod1 &lt;- varY.lasso.mod1/varY)
  
  # Ergebnistabelle
  vv &lt;- paste0("coef.stratum",st); tab3[,vv] &lt;- NA
  tab3[lasso.beta@i+1,vv] &lt;- lasso.beta@x
  vv &lt;- paste0("lambda.stratum",st); tab3[,vv] &lt;- lasso.mod1$lambda.min
  vv &lt;- paste0("R2.stratum",st); tab3[,vv] &lt;- R2.lasso.mod1
  
  #------------------------------------------------------------#
  # Lasso-Regression mit Haupt- und Interaktionseffekten
  
  # Kovariatenmatrix
  Z &lt;- as.matrix(dat[pos,alleff])
  
  # Regression
  lasso.mod2 &lt;- cv.glmnet(x=Z,y=Y,alpha = 1, foldid = foldid)
  
  # Ergebnisausdruck
  print(lasso.mod2)
  
  # Lasso-Koeffizienten bei lambda.min
  print(lasso.beta &lt;- coef(lasso.mod2,s="lambda.min"))
  
  # Erwartungswerte der Schulen
  lasso.pred2 &lt;- predict(lasso.mod2,newx = Z,s="lambda.min")
  dat$expTWLE.Lasso2[pos] &lt;- as.vector(lasso.pred2)
  
  # R2 bestimmen
  varY.lasso.mod2 &lt;- var(dat$expTWLE.Lasso2[pos])
  R2.lasso.mod2 &lt;- varY.lasso.mod2/varY
  R2.lasso.mod2
  
  # Ergebnistabelle
  vv &lt;- paste0("coef.stratum",st); tab4[,vv] &lt;- NA
  tab4[lasso.beta@i+1,vv] &lt;- lasso.beta@x
  vv &lt;- paste0("lambda.stratum",st); tab4[,vv] &lt;- lasso.mod2$lambda.min
  vv &lt;- paste0("R2.stratum",st); tab4[,vv] &lt;- R2.lasso.mod2
  
  
}

# Regressionresiduen = Schätzung von SChul- und Unterrichtseffekt
dat$resTWLE.Lasso1 &lt;- dat$TWLE - dat$expTWLE.Lasso1
dat$resTWLE.Lasso2 &lt;- dat$TWLE - dat$expTWLE.Lasso2

# -------------------------------------------------------------
# Abschnitt 9.2.5.4, Ergänzung zum Buch
# Nichtparametrische Regression
#

#
# Achtung: Der nachfolgende Algorithmus benötigt viel Zeit!
# 

av &lt;- "TWLE" # Abhängige Variable
dfr3 &lt;- NULL # Ergebnistabelle

# Variable für Leistungsschätzwerte

# Schleife über 4 Strata
for(st in 1:4){
  # st &lt;- 1
  pos &lt;- which(dat$stratum == st)
  N &lt;- length(pos)
  schools &lt;- dat$idschool[pos]
  
  ###
  # Distanzmatrix dfr für alle Schulen im Stratum erstellen
  dfr &lt;- NULL
  
  for (i in 1:N){
    # i &lt;- 1
    # Teildatensatz von Schule i
    dat.i &lt;- dat[pos[i],c("idschool","TWLE",maineff)]
    # Daten der Vergleichsgruppe
    dat.vgl &lt;- dat[pos[-i],c("idschool","TWLE",maineff)]
    # Variablennamen von dat.vgl umbenennen
    # names(dat.vgl) &lt;- paste0("vgl.",names(dat.vgl))
    # Variablennamen von dat.i umbenennen
    names(dat.i) &lt;- paste0(names(dat.i),".i")
    
    # Daten zusammenfügen
    index.vgl &lt;- match(dat.vgl$idschool,schools)
    dfr.i &lt;- data.frame("index.i"=i,dat.i,
                        "index.vgl"=index.vgl,dat.vgl,
                        row.names=NULL)
    
    # Distanz zur i
    dfr.i$dist &lt;- 0
    gi &lt;- c(1,1,1,1)
    for(ii in 1:length(maineff)){
      vv &lt;- maineff[ii]
      pair.vv &lt;- grep(vv, names(dfr.i), value=T)
      dist.vv &lt;- gi[ii]*((dfr.i[,pair.vv[1]]-dfr.i[,pair.vv[2]])^2)
      dfr.i$dist &lt;- dfr.i$dist + dist.vv
    }
    
    print(i) ; flush.console()
    dfr &lt;- rbind( dfr , dfr.i )
  }
  
  dfr1 &lt;- index.dataframe( dfr , systime=TRUE )
  
  ###
  # h-Auswahl und Nichtparametrische Regression pro Schule i
  dfr1.list &lt;- list()
  for (i in 1:N){
    # i &lt;- 1
    dfr.i &lt;- dfr[ dfr$index.i == i , ]
    n &lt;- nrow(dfr.i)
    
    # Startwertliste für h initiieren
    d.dist &lt;- max(dfr.i$dist)-min(dfr.i$dist)
    H &lt;- c(seq(d.dist/100,d.dist,length=30),100000)
    V1 &lt;- length(H) # Anzahl der Startwerte in H
    
    # Startwerte: Summe von w_ik
    sumw &lt;- 0*H
    dfr0.i &lt;- dfr.i[,c("idschool",av)]
    # Schleife über alle h-Werte
    for (ll in 1:V1 ){
      h &lt;- H[ll]
      # Gewicht w_ik bei h
      dfr.i$wgt.h &lt;- dnorm(sqrt(dfr.i$dist), mean=0, sd=sqrt(h))
      # Summe von w_ik bei h
      sumw[which(H==h)] &lt;- sum(dfr.i$wgt.h)
      # Leave-one-out-Schätzer von Y_k
      for (k in 1:n){
        # Regressionsformel
        fm &lt;- paste0(av,"~",paste0(maineff,collapse="+"))
        fm &lt;- as.formula(fm)
        # Regressionsanalyse ohne Beitrag von Schule k
        dfr.i0 &lt;- dfr.i[-k,]
        mod.k &lt;- lm(formula=fm,data=dfr.i0,weights=dfr.i0$wgt.h)
        # Erwartungswert anhand Kovariaten der Schule k berechnen
        pred.k &lt;- predict(mod.k, dfr.i)[k]
        dfr0.i[k,paste0( "h_",h) ] &lt;- pred.k
      }
      print(paste0("i=",i,", h_",ll))
    }
    # Erwartungswerte auf Basis verschiedener h-Werte
    dfr1 &lt;- data.frame("idschool.i"=dfr.i$idschool.i[1],"h"=H )
    
    # Berechnung des Kreuzvalidierungskriteriums
    library(kerdiest)
    hAL &lt;- kerdiest::ALbw("n",dfr.i$dist) # Plug-in Bandbreite nach Altman und 
                                          # Leger
    name &lt;- paste0( "bandwidth_choice_school" , dfr.i$idschool.i[1] ,  
                     "_cross.h_" , round2(hAL,1) )
    # Regressionsgewichte auf Basis cross.h
    dfr.i$cross.h &lt;- hAL
    dfr.i$crosswgt &lt;- dnorm( sqrt(dfr.i$dist), mean=0, sd = sqrt(hAL) ) 
    
    dfr.i &lt;- index.dataframe( dfr.i , systime=TRUE )

    # Kreuzvalidierungskriterium CVh
    vh &lt;- grep("h_",colnames(dfr0.i),value=TRUE)
    for (ll in 1:V1){
      # ll &lt;- 5
      dfr1[ll,"CVh"] &lt;- sum( (dfr0.i[,av] - dfr0.i[,vh[ll]])^2 * 
                               dfr.i$crosswgt) / n
      print(ll)
    }
    
    # Bestimmung h.min
    dfr1$min.h.index &lt;- 0
    ind &lt;-  which.min( dfr1$CVh )
    dfr1$min.h.index[ind ] &lt;- 1
    dfr1$h.min &lt;- dfr1$h[ind]
    # Kleinste Quadratsumme der Schätzfehler
    dfr1$CVhmin &lt;- dfr1[ ind , "CVh" ]
    
    # Effizienzsteigerung berechnen
    dfr1$eff_gain &lt;-  100 * ( dfr1[V1,"CVh"] / dfr1$CVhmin[1] - 1 )
    
    # h auswählen
    h &lt;- dfr1$h.min[1]
    
    # Gewichte anhand h berechnen
    dfr.i$wgt.h &lt;- dnorm( sqrt( dfr.i$dist ) , sd = sqrt( h) ) / 
                   dnorm( 0 , sd = sqrt( h) )     
    dfr.i0 &lt;- dfr.i
    mod.ii &lt;- lm(formula = fm,data = dfr.i0,weights = dfr.i0$wgt.h)
    
    # Leistungsschätzwerte berechnen
    predM &lt;- data.frame(dfr.i[1,paste0(maineff,".i")])
    names(predM) &lt;- maineff
    
    pred.ii &lt;- predict( mod.ii ,  predM )
    dfr1$fitted_np &lt;- pred.ii  
    dfr1$h.min_sumwgt &lt;- sum( dfr.i0$wgt.h )
    dfr1$h_sumwgt  &lt;- sumw
    
    # Leistungsschätzwerte zum Datensatz hinzufügen
    dat$expTWLE.np[match(dfr1$idschool.i[1],dat$idschool)] &lt;- pred.ii
    dfr1.list[[i]] &lt;- dfr1
  }
  
  ###
  # Ergebnisse im Stratum st zusammenfassen
  dfr2 &lt;- NULL

  for(i in 1:length(dfr1.list)){
    dat.ff &lt;- dfr1.list[[i]]
    dfr2.ff &lt;- dat.ff[1,c("idschool.i","h.min","fitted_np","h.min_sumwgt",
                          "CVhmin","eff_gain")]
    dfr2.ff$CVlinreg &lt;- dat.ff[V1,"CVh"]
    names(dfr2.ff) &lt;- c("idschool","h.min","fitted_np","h.min_sumwgt",
                        "CVhmin","eff_gain","CVlinreg")
    dfr2 &lt;- rbind(dfr2, dfr2.ff)
    print(i)
  }
  
  #---------------------------------------------------##
  # R2 berechnen
  varY &lt;- var(dat$TWLE[pos])
  varY.np &lt;- var(dat$expTWLE.np[pos])
  dfr2$R2.np &lt;- varY.np/varY
  
  #---------------------------------------------------##
  # Zur Gesamtergebnistabelle
  dfr3 &lt;- rbind(dfr3,cbind("Stratum"=st,dfr2))
  
}

# Effizienz der NP-Regression gegenüber OLS-Regression
summary(dfr3$eff_gain)
table(dfr3$eff_gain &gt; 5)
table(dfr3$eff_gain &gt; 10)
table(dfr3$eff_gain &gt; 20)

# Regressionsresiduen
dat$resTWLE.np &lt;- dat$TWLE - dat$expTWLE.np

## -------------------------------------------------------------
## Abschnitt 9.2.6, Ergänzung zum Buch
## Ergebnisse im Vergleich
## -------------------------------------------------------------

# Output-Variablen
out &lt;- grep("expTWLE",names(dat),value=T)
lt &lt;- length(out)

# Korrelationsmatrix
tab &lt;- tab1 &lt;- as.matrix(round2(cor(dat[,out]),3))

# Varianzmatrix
tab2 &lt;- as.matrix(round2(sqrt(var(dat[,out])),1))

tab3 &lt;- matrix(NA,lt,lt)
# Differenzmatrix
for(ii in 1:(lt-1))
  for(jj in (ii+1):lt) tab3[ii,jj] &lt;- round2(mean(abs(dat[,out[jj]] - 
                                                      dat[,out[ii]])),1)

tab4 &lt;- matrix(NA,lt,lt)
# Differenzmatrix
for(ii in 1:(lt-1))
  for(jj in (ii+1):lt) tab4[ii,jj] &lt;- round2(sd(abs(dat[,out[jj]] - 
                                                    dat[,out[ii]])),1)

# Ergebnistabelle
diag(tab) &lt;- diag(tab2)
tab[upper.tri(tab)] &lt;- tab3[upper.tri(tab3)]

# R2 Gesamt
varY &lt;- var(dat$TWLE)
varexp.OLS1 &lt;- var(dat$expTWLE.OLS1); R2.OLS1 &lt;- varexp.OLS1/varY
varexp.OLS2 &lt;- var(dat$expTWLE.OLS2); R2.OLS2 &lt;- varexp.OLS2/varY
varexp.Lasso1 &lt;- var(dat$expTWLE.Lasso1); R2.Lasso1 &lt;- varexp.Lasso1/varY
varexp.Lasso2 &lt;- var(dat$expTWLE.Lasso2); R2.Lasso2 &lt;- varexp.Lasso2/varY
varexp.np &lt;- var(dat$expTWLE.np); R2.np &lt;- varexp.np/varY
R2 &lt;- c(R2.OLS1,R2.OLS2,R2.Lasso1,R2.Lasso2,R2.np)
tab &lt;- cbind(tab,R2)

# R2 pro Stratum
dat0 &lt;- dat
for(st in 1:4){
  # st &lt;- 1
  dat &lt;- dat0[which(dat0$stratum == st),]
  varY &lt;- var(dat$TWLE)
  varexp.OLS1 &lt;- var(dat$expTWLE.OLS1); R2.OLS1 &lt;- varexp.OLS1/varY
  varexp.OLS2 &lt;- var(dat$expTWLE.OLS2); R2.OLS2 &lt;- varexp.OLS2/varY
  varexp.Lasso1 &lt;- var(dat$expTWLE.Lasso1); R2.Lasso1 &lt;- varexp.Lasso1/varY
  varexp.Lasso2 &lt;- var(dat$expTWLE.Lasso2); R2.Lasso2 &lt;- varexp.Lasso2/varY
  varexp.np &lt;- var(dat$expTWLE.np); R2.np &lt;- varexp.np/varY
  R2 &lt;- c(R2.OLS1,R2.OLS2,R2.Lasso1,R2.Lasso2,R2.np)
  tab &lt;- cbind(tab,R2)
}

colnames(tab)[7:10] &lt;- paste0("R2_stratum",1:4)

## -------------------------------------------------------------
## Abschnitt 9.2.7, Berücksichtigung der Schätzfehler
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 9.2.7, Listing 17: Bestimmung des Erwartungsbereichs
#

vv &lt;- "expTWLE.OLS1" # Variablenname
mm &lt;- "OLS1" # Kurzname des Modells
dfr &lt;- NULL # Ergebnistabelle
# Schleife über alle möglichen Breite von 10 bis 60
for(w in 10:60){
  # Variablen für Ergebnisse pro w
  var &lt;- paste0(mm,".pos.eb",w) # Position der Schule
  var.low &lt;- paste0(mm,".eblow",w) # Untere Grenze des EBs
  var.upp &lt;- paste0(mm,".ebupp",w) # Obere Grenze des EBs
  # Berechnen
  dat[,var.low] &lt;- dat[,vv]-w/2 # Untere Grenze des EBs
  dat[,var.upp] &lt;- dat[,vv]+w/2 # Obere Grenze des EBs 
  # Position: -1=unterhalb, 0=innerhalb, 1=oberhalb des EBs 
  dat[,var] &lt;- -1*(dat$TWLE &lt; dat[,var.low]) + 1*(dat$TWLE &gt; dat[,var.upp])
  # Verteilung der Schulpositionen
  tmp &lt;- data.frame(t(matrix(prop.table(table(dat[,var])))))
  names(tmp) &lt;- c("unterhalb","innerhalb","oberhalb")
  tmp &lt;- data.frame("ModellxBereich"=var,tmp); dfr &lt;- rbind(dfr,tmp) }

# Abweichung zur Wunschverteilung 25-50-25 
dfr1 &lt;- dfr 
dfr1[,c(2,4)] &lt;- (dfr1[,c(2,4)] - .25)^2 
dfr1[,3] &lt;- (dfr1[,3] - .5)^2 
dfr1$sumquare &lt;- rowSums(dfr1[,-1]) 
# Auswahl markieren 
dfr$Auswahl &lt;- 1*(dfr1$sumquare == min(dfr1$sumquare) )

# -------------------------------------------------------------
# Abschnitt 9.2.7, Ergänzung zum Buch
# Bestimmung des Erwartungsbereichs
# 

# Ergebnisse aller Schulen werden aus Ursprungsdatensatz geladen.
dat &lt;- datenKapitel09 

# Liste der Erwartungswerte-Variablen
exp.vars &lt;- grep("expTWLE",names(dat),value=T)
# Modellnamen
m.vars &lt;- gsub("expTWLE.","",exp.vars, fixed = TRUE)

# Liste der Ergebnistabelle
list0 &lt;- list()

# Ergebnisse
tab.erg &lt;- NULL

# Schleife über alle Erwartungswerte aller Modelle
for(ii in 1:length(exp.vars)){
  # ii &lt;- 1
  vv &lt;- exp.vars[ii]
  mm &lt;- m.vars[ii]
  
  # Ergebnistabelle
  dfr &lt;- NULL
  
  # Schleife über alle möglichen Breite von 10 bis 60
  for(w in 10:60){
    # eb &lt;- 10
    var &lt;- paste0(mm,".pos.eb",w) # Position der Schule
    var.low &lt;- paste0(mm,".eblow",w) # Untere Grenze des EBs
    var.upp &lt;- paste0(mm,".ebupp",w) # Obere Grenze des EBs
    # Untere Grenze des EBs = Erwartungswert - w/2
    dat[,var.low] &lt;- dat[,vv]-w/2
    # Obere Grenze des EBs = Erwartungswert + w/2
    dat[,var.upp] &lt;- dat[,vv]+w/2
    # Position der Schule bestimmen
    # -1 = unterhalb, 0 = innterhalb, 1 = oberhalb des EBs
    dat[,var] &lt;- -1*(dat$TWLE &lt; dat[,var.low]) + 1*(dat$TWLE &gt; dat[,var.upp])
    # Verteilung der Positionen
    tmp &lt;- data.frame(t(matrix(prop.table(table(dat[,var])))))
    names(tmp) &lt;- c("unterhalb","innerhalb","oberhalb")
    tmp &lt;- data.frame("ModellxBereich"=var,tmp)
    dfr &lt;- rbind(dfr,tmp)
  }
  
  # Vergleich mit Wunschverteilung 25-50-25
  dfr1 &lt;- dfr
  dfr1[,c(2,4)] &lt;- (dfr1[,c(2,4)] - .25)^2
  dfr1[,3] &lt;- (dfr1[,3] - .5)^2
  dfr1$sumquare &lt;- rowSums(dfr1[,-1])
  # Auswahl markieren
  dfr$Auswahl &lt;- 1*(dfr1$sumquare == min(dfr1$sumquare) )
  
  # Zum Liste hinzufügen
  list0[[ii]] &lt;- dfr
  print(dfr[which(dfr$Auswahl == 1),])
  tab.erg &lt;- rbind(tab.erg, dfr[which(dfr$Auswahl == 1),])
  
}

# Nur gewählte Ergebnisse im Datensatz beibehalten
all.vars &lt;- grep("eb",names(dat),value=T)
# Untere und Obere Grenze mit speichern
eb.vars &lt;- tab.erg[,1]
low.vars &lt;- gsub("pos.eb","eblow",eb.vars)
upp.vars &lt;- gsub("pos.eb","ebupp",eb.vars)
del.vars &lt;- setdiff(all.vars, c(eb.vars,low.vars,upp.vars))
dat &lt;- dat[,-match(del.vars,names(dat))]


## -------------------------------------------------------------
## Appendix: Abbildungen
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abbildung 9.4
#

# Koeffizienten bei der ersten 50 lambdas ausdrucken
# Stratum 4

lambda &lt;- lasso.mod2$lambda[1:50]
a &lt;- round2(lambda,2)
a1 &lt;- a[order(a)]
L &lt;- length(a)

dfr &lt;- NULL

for(ll in 1:L){
  dfr.ll &lt;- as.matrix(coef(lasso.mod2,newx = Z,s=a[ll] ))
  colnames(dfr.ll) &lt;- paste0("a_",ll)
  dfr.ll &lt;- data.frame("coef"=rownames(dfr.ll),dfr.ll)
  rownames(dfr.ll) &lt;- NULL
  if(ll == 1) dfr &lt;- dfr.ll else dfr &lt;- merge(dfr, dfr.ll)
}

# Ohne Intercept
dfr &lt;- dfr[-1,]
rownames(dfr) &lt;- 1:nrow(dfr)

cl &lt;- colors()
cl &lt;- grep("grey",cl,value=T)

# Umgekehrte Reihenfolge
dfr1 &lt;- dfr
for(x in 2:(L+1)) {dfr1[,x] &lt;- dfr[,(L+3)-x]; 
names(dfr1)[x] &lt;- names(dfr)[(L+3)-x]}

###
plot(x = log(a), y = rep(0,L), xlim = rev(range(log(a))), ylim=c(-20,22), 
     type = "l", xaxt ="n", xlab = expression(paste(lambda)), 
     ylab="Geschätzte Regressionskoeffizienten")
axis(1, at=log(a), labels=a,cex=1)

tmp &lt;- nrow(dfr)
for(ll in 1:tmp){
  # ll &lt;- 1
  lines(x=log(a),y=dfr[ll,2:(L+1)],type="l",pch=15-ll,col=cl[15-ll])
  points(x=log(a),y=dfr[ll,2:(L+1)],type="p",pch=15-ll)
  legend(x=2.8-0.7*(ll&gt;tmp/2),y=25-2*(ifelse(ll&gt;7,ll-7,ll)),
         legend =dfr$coef[ll],pch=15-ll,bty="n",cex=0.9)
}

# Kennzeichung der gewählten lambda
v &lt;- log(lasso.mod2$lambda.min)
lab2 &lt;- expression(paste("ausgewähltes ",lambda," = .43"))
text(x=v+0.6,y=-8,labels=lab2)

abline(v = v,lty=2,cex=1.2)

# -------------------------------------------------------------
# Abbildung 9.5
# Auswahl Lambda anhand min(cvm)
#

xlab &lt;- expression(paste(lambda))
plot(lasso.mod2, xlim = rev(range(log(lambda))), 
     ylim=c(550,1300),xlab=xlab,xaxt ="n",
     ylab = "Mittleres Fehlerquadrat der Kreuzvalidierung (cvm)",
     font.main=1,cex.main=1)
axis(1, at=log(a), labels=a,cex=1)

lab1 &lt;- expression(paste(lambda," bei min(cvm)"))
text(x=log(lasso.mod2$lambda.min)+0.5,y=max(lasso.mod2$cvm)-50,
     labels=lab1,cex=1)

lab2 &lt;- expression(paste("(ausgewähltes ",lambda," = .43)"))
text(x=log(lasso.mod2$lambda.min)+0.6,y=max(lasso.mod2$cvm)-100,
     labels=lab2,cex=1)

abline(v = log(lasso.mod2$lambda.min),lty=2)

text(x=log(lasso.mod2$lambda.min)-0.3,y = min(lasso.mod2$cvm)-30,
     labels="min(cvm)",cex=1 )
abline(h = min(lasso.mod2$cvm),lty=2)

text &lt;- expression(paste("Anzahl der Nicht-null-Koeffizienten (",
                         lambda," entsprechend)"))
mtext(text=text,side=3,line=3)


# -------------------------------------------------------------
# Abbildung 9.6
# Rohwert-Schätzwert Schule 1196 &amp; 1217 im Vergleich
#

id &lt;- c(1196, 1217)
par(mai=c(1.2,3,1,.5))
plot(x=rep(NA,2),y=c(1:2),xlim=c(470,610),yaxt ="n",type="l",
     xlab="Erwartungswerte je nach Modell und Schulleistung",ylab="")
legend &lt;- c("Schulleistung (TWLE)",paste0("", c("OLS1","OLS2","Lasso1",
                                                "Lasso2","NP"),
                                          "-Modell"))
axis(2, at=c(seq(1,1.4,0.08),seq(1.6,2,0.08)), las=1,cex=0.7,
     labels=rep(legend,2))
text &lt;- paste0("Schule ",id)
mtext(text=text,side=2,at = c(1.2,1.8),line = 10)

exp.vars &lt;- c("TWLE", 
              paste0("expTWLE.", c("OLS1","OLS2","Lasso1","Lasso2","np")))

pch = c(19, 0,3,2,4,5)
ii &lt;- 1
col = c("grey", rep("lightgrey",5))
for(vv in exp.vars){
  # vv &lt;- "TWLE"
  x &lt;- dat0[which(dat0$idschool %in% id),vv]
  abline(h = c(0.92+ii*0.08,1.52+ii*0.08), lty=1+1*(ii&gt;1),col=col[ii])
  points(x=x,y=c(0.92+ii*0.08,1.52+ii*0.08),type="p",pch=pch[ii])
  ii &lt;- ii + 1
}

## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+2010'>Kapitel 10: Reporting und Analysen</h2><span id='topic+Kapitel+2010'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 10, <em>Reporting und Analysen</em>, im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenefalls erweitert.
</p>


<h3>Author(s)</h3>

<p>Michael Bruneforth, Konrad Oberwimmer, Alexander Robitzsch
</p>


<h3>References</h3>

<p>Bruneforth, M., Oberwimmer, K. &amp; Robitzsch, A. (2016). Reporting und Analysen. 
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 333&ndash;362). Wien: facultas.
</p>


<h3>See Also</h3>


<p>Zu <code><a href="#topic+datenKapitel10">datenKapitel10</a></code>, den im Kapitel verwendeten Daten.<br />
Zurück zu <code><a href="#topic+Kapitel+209">Kapitel 9</a></code>, Fairer Vergleich in der Rückmeldung.<br />
Zu <code><a href="#topic+Kapitel+2011">Kapitel 11</a></code>, Aspekte der Validierung.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.



</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(BIFIEsurvey)
library(matrixStats)

data(datenKapitel10)
dat &lt;- datenKapitel10$dat
dat.roh &lt;- datenKapitel10$dat.roh
dat.schule &lt;- datenKapitel10$dat.schule
dat.schule.roh &lt;- datenKapitel10$dat.schule.roh

## -------------------------------------------------------------
## Abschnitt 10.4.1: Datenbasis
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.4.1 a, Ergänzung zum Buch
# Herunterladen, entpacken und setzen des Arbeitsspeichers
# 

# setwd(dir = ".../DatenKapitel10")

# -------------------------------------------------------------
# Abschnitt 10.4.1, Listing 1: Einlesen der Schülerdaten
#

# Anlegen eines leeren Listenobjektes für Schülerdaten
dat &lt;- list()

# Vektor mit Liste der Dateinamen für Schülerdaten
dateinamen &lt;- paste0("e8pv__schueler_imp_",1:10,".csv")
# Schleife zum Einlesen der Daten, die in die Listenobjekte 
# abgelegt werden
for (ii in 1:10) {
  schueler_dfr&lt;-read.csv2(file = dateinamen[[ii]])
  dat[[ii]] &lt;- schueler_dfr
}
# Überprüfen des Listenobjektes und der eingelesenen Daten
str(dat)

# Rohdaten als Datenmatrix einlesen
dat.roh &lt;- read.csv2(file = "e8pv__schueler_raw.csv")

# -------------------------------------------------------------
# Abschnitt 10.4.1, Listing 1a: Ergänzung zum Buch
# Einlesen der Schulendaten
#

# Anlegen eines leeren Listenobjektes für Schuldaten
dat.schule &lt;- list()

# Vektor mit Liste der Dateinamen für Schuldaten
dateinamen &lt;- paste0("e8pv__schule_imp_",1:10,".csv")
# Schleife zum Einlesen der Daten, die in die Listenobjekte 
# abgelegt werden
for (ii in 1:10) {
  schule_dfr&lt;-read.csv2(file = dateinamen[[ii]])
  dat.schule[[ii]] &lt;- schule_dfr
}
# Überprüfen des Listenobjektes und der eingelesenen Daten
str(dat.schule)

#Rohdaten als Datenmatrix einlesen
dat.schule.roh &lt;- read.csv2(file = "e8pv__schule_raw.csv")

## -------------------------------------------------------------
## Abschnitt 10.4.2: Merging verschiedener Ebenen
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.4.2, Listing 1
#

for (i in 1:10) {
   dat[[i]] &lt;- merge(dat[[i]],dat.schule[[i]],
                      by = "idschool",all.x = TRUE)
}

# -------------------------------------------------------------
# Abschnitt 10.4.2, Listing 2

for (i in 1:10) {
   dat.agg &lt;- aggregate(dat[[i]][,c("HISEI","E8RPV")],
                        by = list(idschool = dat[[i]]$idschool),
                        FUN = mean,na.rm = TRUE)
   dat.schule[[i]] &lt;- merge(dat.schule[[i]],dat.agg,
                            by="idschool",all.x = TRUE)
}

## -------------------------------------------------------------
## Abschnitt 10.4.3: Erzeugen von BIFIEdata-Objekten
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.4.3, a: Ergänzung zum Buch
# Einlesen der Replikationsgewichte
#

# Zwischenspeichern des Schülerdatensatzes
dat.tmp &lt;- dat

# Daten aus Large-Scale Assessments können mit replicate weights 
#  abgespeichert werden (z.B. PISA) oder mit Informationen zu den 
#  Jackknifezonen und -gewichten (z.B. PIRLS). In diesem Beispiel 
#  werden beide Methoden vorgestellt, daher wird die Gewichtungs-
#  information in beiden Formen eingelesen: mit replicate weights
#  im Datensatz dat1; mit Replikationsdesign im Datensatz dat2.

# replicate weights für Schüler/innen als Datenmatrix einlesen 
dat.repwgts &lt;- read.csv2(file = "e8__schueler_repwgts.csv")
# replicate weights an Schülerdaten mergen
for (ii in 1:10) {
  dat[[ii]]&lt;-merge(x = dat[[ii]],y = dat.repwgts,
                    by = c("idschool","idstud"))
}

# Jackknifezonen und -gewichte für Schulen als Datenmatrix einlesen 
dat2 &lt;- list()
dat.schule.jk &lt;- read.csv2(file = "e8__schule_jkzones.csv")
# Jackknifezonen und -gewichte an schülerdaten mergen
for (ii in 1:10) {
  dat2[[ii]]&lt;-merge(x = dat.tmp[[ii]],y = dat.schule.jk,
                    by = "idschool")
}

# -------------------------------------------------------------
# Abschnitt 10.4.3, b: Ergänzung zum Buch
# Kontrolle der Sortierung
#

# Die Observationen in den 10 Imputationen muessen gleich sortiert 
# sein. Dies wir zur Sicherheit getestet. 
for (i in 2:10) {
  if (sum(dat[[1]]$idstud!=dat[[i]]$idstud )&gt;0) 
      stop("Imputationsdatensätze nicht gleich sortiert!")  
}
  
# -------------------------------------------------------------
# Abschnitt 10.4.3, c: Ergänzung zum Buch
# Verwendung des R-Datenobjekts
#

dat &lt;- datenKapitel10$dat
  
# -------------------------------------------------------------
# Abschnitt 10.4.3, Listing 1: Übernahme der Gewichte aus 
# Datenmatrix
#

wgtstud &lt;- dat[[1]]$wgtstud
repwgtsvar &lt;- grep("^w_fstr",colnames(dat[[1]]))
repwgts &lt;- dat[[1]][,repwgtsvar]
dat &lt;- BIFIE.data(data.list = dat,wgt = wgtstud,
                  wgtrep = repwgts,fayfac = 1,
                  cdata = TRUE)
summary(dat)

# -------------------------------------------------------------
# Abschnitt 10.4.3, Listing 2: Erzeugung der Gewichte aus 
# Replikationsdesign
#         

dat2 &lt;- BIFIE.data.jack(data = dat2,wgt = "wgtstud",
                        jktype = "JK_GROUP",
                        jkzone = "jkzone",
                        jkrep = "jkrep",
                        fayfac = 1)
summary(dat2)


# -------------------------------------------------------------
# Abschnitt 10.4.3, Listing 3: Univariate Statistik Reading
#

res.univar &lt;- BIFIE.univar(BIFIEobj = dat,
                          vars = c("E8RPV"),
                          group = "Strata")
summary(res.univar)
res2.univar &lt;- BIFIE.univar(BIFIEobj = dat2,
                          vars = c("E8RPV"),
                          group = "Strata")
summary(res2.univar)

## -------------------------------------------------------------
## Abschnitt 10.4.4: Rekodierung und Transformation von 
##                   Variablen
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.4.4, Listing 1: Neue Variable GERSER mit 
# BIFIE.data.transform
#

transform.formula &lt;- as.formula(
   "~ 0 + I(cut(E8RPV,breaks = c(0,406,575,1000),labels = FALSE))"
   )
dat &lt;- BIFIE.data.transform(dat,transform.formula,
                            varnames.new = "GERSER")
res.freq &lt;- BIFIE.freq(BIFIEobj = dat,vars = c("GERSER"))
summary(res.freq)

# -------------------------------------------------------------
# Abschnitt 10.4.4, Listing 2: Zwei neue Variablen PVERfit und 
# PVERres mit BIFIE.data.transform
#

transform.formula &lt;- as.formula(
   "~ 0 + I(fitted(lm(E8RPV ~ HISEI + female))) +
          I(residuals(lm(E8RPV ~ HISEI + female)))"
   )
dat &lt;- BIFIE.data.transform(dat,transform.formula,
                            varnames.new = c("PVERfit","PVERres"))
res.univar &lt;- BIFIE.univar(BIFIEobj = dat,
                          vars = c("PVERfit","PVERres"))
summary(res.univar)

## -------------------------------------------------------------
## Abschnitt 10.4.5: Berechnung von Kenngroessen und deren 
##                   Standardfehlern
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.4.5, Listing 1: Anwenderfunktion
#
library(matrixStats)

anwenderfct.weightedMad &lt;- function(X,w)
{
  # Die Funktion weightedMad wird auf jede Spalte der 
  # übergebenen Matrix X angewendet.
  Wmad&lt;-apply(X = X, MARGIN = 2,FUN = matrixStats::weightedMad, 
              w = w, na.rm = T)
}

wgt.Mad &lt;- BIFIE.by(BIFIEobj = dat,
                     vars =  c("HISEI", "E8RPV"),
                     userfct = anwenderfct.weightedMad,
                     userparnames = c("wMadHISEI", "wMadE8RPV"))
summary(wgt.Mad)

## -------------------------------------------------------------
## Abschnitt 10.6.1: Datenexploration
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.6.1, Listing 1: Ungewichtete univariate 
# Statistiken
#

# Ungewichtete univariate Statistiken
# Häufigkeitstabelle zu 'eltausb' und 'migrant' (Kreuztabelle)
tab1 &lt;- table(dat.roh[,c("eltausb","migrant")],useNA = "always")
# Ausgabe der Tabelle, ergänzt um Randsummen
addmargins(tab1, FUN = list(Total = sum), quiet = TRUE)

# Ausgabe der Tabelle als Prozentverteilungen 
# (in Prozent, gerundet)
round(addmargins(prop.table(x = tab1), FUN = list(Total = sum), 
  quiet = TRUE)*100,2)

# Ausgabe mit Prozentverteilungen der Spalten bzw. Zeilen 
# (in Prozent, gerundet)
round(prop.table(x = tab1,margin = 2)*100,2)
round(prop.table(x = tab1,margin = 1)*100,2)
# Ausgabe nicht wiedergegeben

# -------------------------------------------------------------
# Abschnitt 10.6.1, Listing 2: Gewichtete univariate 
# Statistiken an imputierten Daten


# Gewichtete univariate Statistiken an imputierten Daten
# Häufigkeitstabelle zu 'eltausb' und 'migrant'
res1 &lt;- BIFIE.freq(BIFIEobj = dat,vars = c("eltausb","migrant"))
summary(res1)
# Häufigkeitstabelle zu 'eltausb' gruppiert nach 'migrant'
res2 &lt;- BIFIE.freq(BIFIEobj = dat,vars = "eltausb",
                   group = "migrant")
summary(res2)
# Kreuztabelle mit zwei Variablen
res3 &lt;- BIFIE.crosstab(BIFIEobj = dat,vars1 = "eltausb",
                      vars2 = "migrant")
summary(res3)

# -------------------------------------------------------------
# Abschnitt 10.6.1, Listing 3: Export der Tabelle
#

res_export &lt;- res1$stat[,c("var","varval","Ncases","Nweight", 
  "perc","perc_SE")]
colnames(res_export) &lt;- c("Variable","Wert","N (ungewichtet)",
 "N gewichtet)","Prozent","Standardfehler")
write.table(x = res_export,file = "res_export.dat", sep = ";",
            dec = ",", row.names = FALSE)

## -------------------------------------------------------------
## Abschnitt 10.6.2: Analyse fehlender Werte
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.6.2, Listing 1: Fehlende Werte
#

res1 &lt;- BIFIE.mva(dat, missvars = c("eltausb","migrant"), 
                  se = TRUE)
summary(res1)

# -------------------------------------------------------------
# Abschnitt 10.6.2, Listing 2: Fehlende Werte unter Kovariaten
#

res2 &lt;- BIFIE.mva(dat,missvars = c("eltausb","migrant"), 
  covariates = c("E8RTWLE","eltausb", "migrant"), se = TRUE)   
summary(res2)

## -------------------------------------------------------------
## Abschnitt 10.6.3: Mittelwerte, Perzentilbaender und Quantile
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.6.3, Listing 1: Hilfsvariable
#

# Hilfsvariable zur Gruppierung anlegen
transform.formula &lt;- as.formula("~ 0 + I(migrant*10+female)")
dat &lt;- BIFIE.data.transform(dat,transform.formula,
                  varnames.new="migrant_female")

# -------------------------------------------------------------
# Abschnitt 10.6.3, Listing 2: Statistiken an Hilfsvariablen
#

# Univariate Statistiken mit Mittelwerten und Standardfehlern
res1 &lt;- BIFIE.univar(BIFIEobj = dat,vars = "E8RPV",
                    group = "migrant_female")
# summary(res1)
mittelwerte&lt;-res1$stat[,c("groupval","M","M_SE")]

# Berechne Quantile
probs&lt;-c(.05,.25,.75,.95)
res2 &lt;- BIFIE.ecdf(BIFIEobj = dat,breaks = probs,
                   quanttype = 1, vars = "E8RPV", 
                   group = "migrant_female")
# summary(res2)
quantile&lt;-data.frame(t(matrix(res2$output$ecdf,nrow = 4)))
colnames(quantile)&lt;-probs
# Führe Ergebnisse zusammen
res3&lt;-cbind(mittelwerte,quantile)
print(res3)

# -------------------------------------------------------------
# Abschnitt 10.6.3, Listing 3: IQA
#

# Berechne Interquartilabstand (IQA)
res3$IQA&lt;-res3$"0.75"-res3$"0.25"
# Berechne Grenzen des Vertrauensintervals
res3$VIunten&lt;-res3$M-2*res3$M_SE
res3$VIoben&lt;-res3$M+2*res3$M_SE
round(res3,1)

## -------------------------------------------------------------
## Abschnitt 10.6.4: Gruppenvergleiche mit Regressionen
## -------------------------------------------------------------

# -------------------------------------------------------------
# Abschnitt 10.6.4, Listing 1: Gruppenvergleich Geschlecht
#

# Gruppenvergleich Geschlecht, gesamte Population
res1 &lt;- BIFIE.linreg(BIFIEobj = dat, formula = E8RPV ~ female)
# Alternativer Aufruf mit identischem Resultat
res1 &lt;- BIFIE.linreg(BIFIEobj = dat,dep = "E8RPV", 
                     pre = c("one","female"))
                     
# Vollständige Ausgabe
summary(res1)

# Reduzierte Ausgabe der Ergebnisse
res1_short &lt;- res1$stat[res1$stat$parameter == "b" &amp;
            res1$stat$var == "female",c("est","SE")]
colnames(res1_short) &lt;- c("Geschlechterunterschied","SE")
res1_short

# Gruppenvergleich Geschlecht getrennt nach 'migrant'
res2 &lt;- BIFIE.linreg(BIFIEobj = dat,
                    formula = E8RPV ~ female,
                    group = "migrant")
# Vollständige Ausgabe
summary(res2)

# Reduzierte Ausgabe der Ergebnisse
res2_short &lt;- res2$stat[res2$stat$parameter == "b" &amp;
                        res2$stat$var == "female",
                      c("groupval","est","SE")]
colnames(res2_short) &lt;- c("Migrant","Geschlechterunterschied",
                          "SE")
res2_short

# -------------------------------------------------------------
# Abschnitt 10.6.4, Listing 2: Wald-Test
#

res3 &lt;- BIFIE.univar(vars = "E8RPV",BIFIEobj = dat, 
                     group = c("migrant","female"))
res3_wald &lt;- BIFIE.univar.test(BIFIE.method = res3)

# summary(res3_wald)
res3_wald$stat.dstat[,c("group","groupval1","groupval2",
                        "M1","M2","d","d_SE","d_t","d_p")]

# -------------------------------------------------------------
# Abschnitt 10.6.4, Listing 3: Kontrolle um soziale Herkunft
#

# Gruppenvergleich ohne Berücksichtigung der sozialen Herkunft
res1 &lt;- BIFIE.linreg(BIFIEobj = dat, formula = E8RPV ~ migrant)
# summary(res1)
res1$stat[res1$stat$parameter == "b" &amp; res1$stat$var == "migrant",
         c("groupval","est","SE")]

# Gruppenvergleich mit Berücksichtigung der sozialen Herkunft
res2 &lt;- BIFIE.linreg(BIFIEobj = dat,
                    formula = E8RPV ~ migrant+HISEI+eltausb+buch)
# summary(res2)
res2$stat[res2$stat$parameter == "b" &amp; res2$stat$var == "migrant",
         c("groupval","est","SE")]


## End(Not run)
</code></pre>

<hr>
<h2 id='Kapitel+2011'>Kapitel 11: Aspekte der Validierung</h2><span id='topic+Kapitel+2011'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zum Kapitel 11, <em>Aspekte der Validierung</em>, im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung. 
Im Abschnitt <strong>Details</strong> werden die im Kapitel verwendeten <span class="rlang"><b>R</b></span>-Syntaxen zur 
Unterstützung für Leser/innen kommentiert und dokumentiert. 
Im Abschnitt <strong>Examples</strong> werden die <span class="rlang"><b>R</b></span>-Syntaxen des Kapitels vollständig 
wiedergegeben und gegebenenfalls erweitert.
</p>


<h3>Details</h3>

<p>Dieses Kapitel enthält keine Beispiele mit <span class="rlang"><b>R</b></span>.
</p>


<h3>Author(s)</h3>

<p>Robert Fellinger, Thomas Kiefer, Alexander Robitzsch, Matthias Trendtel
</p>


<h3>References</h3>

<p>Fellinger, R., Kiefer, T., Robitzsch, A. &amp; Trendtel, M. (2016). Aspekte der
Validierung.
In S. Breit &amp; C. Schreiner (Hrsg.), <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:  
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em> 
(pp. 363&ndash;398). Wien: facultas.
</p>


<h3>See Also</h3>

<p>Zurück zu <code><a href="#topic+Kapitel+2010">Kapitel 10</a></code>, Reporting und Analysen.<br />
Zur <code><a href="#topic+LSAmitR-package">Übersicht</a></code>.


</p>

<hr>
<h2 id='LSAmitR-Hilfsmethoden'>
Large-Scale Assessment mit R: Hilfsfunktionen aus den Kapiteln
</h2><span id='topic+quintfunct'></span><span id='topic+covainteraction'></span><span id='topic+summary.VarComp'></span><span id='topic+zones.within.stratum'></span>

<h3>Description</h3>

<p>Das ist die Nutzerseite zu den Hilfsfunktionen, die in einigen Kapiteln im 
Herausgeberband Large-Scale Assessment mit <span class="rlang"><b>R</b></span>: Methodische 
Grundlagen der österreichischen Bildungsstandardüberprüfung angewendet werden.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zones.within.stratum(offset, n.str)

covainteraction(dat,covas, nchar)

quintfunct(X,w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_offset">offset</code></td>
<td>
<p>siehe <code><a href="#topic+Kapitel+202">Kapitel 2</a></code></p>
</td></tr>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_n.str">n.str</code></td>
<td>
<p>siehe <code><a href="#topic+Kapitel+202">Kapitel 2</a></code></p>
</td></tr>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_dat">dat</code></td>
<td>
<p>siehe <code><a href="#topic+Kapitel+209">Kapitel 9</a></code></p>
</td></tr>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_covas">covas</code></td>
<td>
<p>siehe <code><a href="#topic+Kapitel+209">Kapitel 9</a></code></p>
</td></tr>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_nchar">nchar</code></td>
<td>
<p>siehe <code><a href="#topic+Kapitel+209">Kapitel 9</a></code></p>
</td></tr>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_x">X</code></td>
<td>
<p><code>quintfunct</code> ist eine Hilfsfunktion, die nicht für die weitere 
Verwendung gedacht ist.</p>
</td></tr>
<tr><td><code id="LSAmitR-Hilfsmethoden_+3A_w">w</code></td>
<td>
<p><code>quintfunct</code> ist eine Hilfsfunktion, die nicht für die weitere 
Verwendung gedacht ist.</p>
</td></tr>
</table>

<hr>
<h2 id='LSAmitR-package'>
Daten, Beispiele und Funktionen zu 'Large-Scale Assessment mit R'
</h2><span id='topic+LSAmitR-package'></span><span id='topic+LSAmitR'></span>

<h3>Description</h3>

<p>Das Bundesinstitut für Bildungsforschung, Innovation und Entwicklung des 
österreichischen Schulwesens (BIFIE) führt die Überprüfung der Bildungsstandards 
(BIST-Ü) in Österreich durch. &quot;Large-Scale Assessment mit <span class="rlang"><b>R</b></span>&quot; ist ein Handbuch der 
grundlegenden Methodik, die bei diesen Überprüfungen zum Einsatz kommt. 
Angefangen bei der Testkonstruktion bis zu Aspekten der Rückmeldung werden die 
dabei eingesetzten methodischen Verfahren dargestellt und diskutiert sowie deren 
Anwendung in <span class="rlang"><b>R</b></span> anhand von Beispieldatensätzen, die in diesem <span class="rlang"><b>R</b></span>-Paket zur 
Verfügung gestellt werden, illustriert.<br />
</p>
<p>Beispiele, die sich durch den Band ziehen, lehnen sich an die BIST-Ü in Englisch 
im Jahr 2013 an. Die Daten, die den Ausführungen zugrunde liegen, sind jedoch
keine Echtdaten und erlauben daher auch keine Rekonstruktion der in den
Ergebnisberichten publizierten Kennwerte. Es handelt sich (mindestens) um 
partiell-synthetische Daten, die reale Kovarianzstrukturen zwischen Kovariaten
und den Leistungsdaten abbilden sowie eine Mehrebenenstruktur simulieren, die in 
den LSA-Erhebungen typischerweise auftreten. Die Datenmuster
können weder als Einzelstücke noch als Ganzes auf tatsächliche Testpersonen, auf 
Klassen oder Schulen zurückgeführt werden. Ebenso führen
Ergebnisse, die in den Ausführungen der einzelnen Kapitel erzielt werden,
nicht zu den Datensätzen, die in späteren Kapiteln verwendet werden (z. B.
entspricht die Stichprobe, die in Kapitel 2 gezogen wird, nicht jener, deren
Testwerte in Kapitel 6 oder Kapitel 7 untersucht werden).
</p>


<h3>Author(s)</h3>

<p>Thomas Kiefer [aut, cre], Alexander Robitzsch [aut], Matthias 
        Trendtel [aut], Robert Fellinger [aut]
</p>
<p>Maintainer: Thomas Kiefer &lt;thomas.kiefer@iqs.gv.at&gt;
</p>


<h3>References</h3>

<p>Breit, S. &amp; Schreiner, C. [HG.] (2016). <em>Large-Scale Assessment mit <span class="rlang"><b>R</b></span>:
Methodische Grundlagen der österreichischen Bildungsstandardüberprüfung</em>. 
Wien: facultas.
</p>
<p><a href="https://www.iqs.gv.at/themen/bildungsforschung/publikationen/veroeffentlichte-publikationen">https://www.iqs.gv.at/themen/bildungsforschung/publikationen/veroeffentlichte-publikationen</a>
</p>


<h3>See Also</h3>

<p>Zu <code><a href="#topic+Kapitel+200">Kapitel 0</a></code>, Konzeption der Überprüfung der Bildungsstandards in Österreich.<br />
Zu <code><a href="#topic+Kapitel+201">Kapitel 1</a></code>, Testkonstruktion.<br />
Zu <code><a href="#topic+Kapitel+202">Kapitel 2</a></code>, Stichprobenziehung.<br />
Zu <code><a href="#topic+Kapitel+203">Kapitel 3</a></code>, Standard-Setting.<br />
Zu <code><a href="#topic+Kapitel+204">Kapitel 4</a></code>, Differenzielles Itemfunktionieren in Subgruppen.<br />
Zu <code><a href="#topic+Kapitel+205">Kapitel 5</a></code>, Testdesign.<br />
Zu <code><a href="#topic+Kapitel+206">Kapitel 6</a></code>, Skalierung und Linking.<br />
Zu <code><a href="#topic+Kapitel+207">Kapitel 7</a></code>, Statistische Analysen produktiver Kompetenzen.<br />
Zu <code><a href="#topic+Kapitel+208">Kapitel 8</a></code>, Fehlende Daten und Plausible Values.<br />
Zu <code><a href="#topic+Kapitel+209">Kapitel 9</a></code>, Fairer Vergleich in der Rückmeldung.<br />
Zu <code><a href="#topic+Kapitel+2010">Kapitel 10</a></code>, Reporting und Analysen.<br />
Zu <code><a href="#topic+Kapitel+2011">Kapitel 11</a></code>, Aspekte der Validierung.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
install.packages("LSAmitR", dependencies = TRUE)
library(LSAmitR)
package?LSAmitR
?"Kapitel 7"

data(datenKapitel07)
names(datenKapitel07)
dat &lt;- datenKapitel07$prodRat

## End(Not run)</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
