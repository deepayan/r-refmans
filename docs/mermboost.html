<!DOCTYPE html><html lang="en"><head><title>Help for package mermboost</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mermboost}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#climbers_sub'><p>Himalayan Climber Data</p></a></li>
<li><a href='#estuaries'><p>Effect of pollution on marine microinvertebrates in estuaries</p></a></li>
<li><a href='#find_ccc'>
<p>Find cluster-constant covariates in a data set.</p></a></li>
<li><a href='#glmermboost'>
<p>Component-wise Gradient Boosting for Generalised Mixed Models</p></a></li>
<li><a href='#mer_cvrisk'><p> Cluster-sensitive Cross-Validation</p></a></li>
<li><a href='#mermboost'><p> Gradient Boosting for Additive Mixed Models</p></a></li>
<li><a href='#methods'><p> Methods for Gradient Boosting for Mixed Models Objects</p></a></li>
<li><a href='#Orthodont'><p>Growth curve data on an orthdontic measurement</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Gradient Boosting for Generalized Additive Mixed Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Lars Knieper [aut, cre],
  Torsten Hothorn [aut],
  Elisabeth Bergherr [aut],
  Colin Griesbach [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lars Knieper &lt;lars.knieper@uni-goettingen.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a novel framework to estimate mixed models
    via gradient boosting. The implemented functions are based on 'mboost' and 'lme4'. 
    Hence, the family range is predetermined by 'lme4'. A correction mechanism 
    for cluster-constant covariates is implemented as well as an estimation of random 
    effects' covariance.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), mboost, lme4</td>
</tr>
<tr>
<td>Imports:</td>
<td>stabs, data.table, MASS, Matrix, parallel, stringr, tibble</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-21 13:30:14 UTC; lars</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-24 16:40:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='climbers_sub'>Himalayan Climber Data</h2><span id='topic+climbers_sub'></span>

<h3>Description</h3>

<p>A filtered sub-sample of the Himalayan Database distributed through the R for Data Science TidyTuesday project. This dataset includes information on the results and conditions for various Himalayan climbing expeditions. Each row corresponds to a single member of a climbing expedition team.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("climbers_sub")
</code></pre>


<h3>Format</h3>

<p>A filtered version of the one one from bayesrules. A data frame with 2068 observations (1 per climber) and 19 variables:
</p>

<dl>
<dt>expedition_id</dt><dd><p>unique expedition identifier</p>
</dd>
<dt>member_id</dt><dd><p>unique climber identifier</p>
</dd>
<dt>peak_id</dt><dd><p>unique identifier of the expedition's destination peak</p>
</dd>
<dt>peak_name</dt><dd><p>name of the expedition's destination peak</p>
</dd>
<dt>year</dt><dd><p>year of expedition</p>
</dd>
<dt>season</dt><dd><p>season of expedition (Autumn, Spring, Summer, Winter)</p>
</dd>
<dt>sex</dt><dd><p>climber gender identity which the database oversimplifies to a binary category</p>
</dd>
<dt>age</dt><dd><p>climber age</p>
</dd>
<dt>citizenship</dt><dd><p>climber citizenship</p>
</dd>
<dt>expedition_role</dt><dd><p>climber's role in the expedition (eg: Co-Leader)</p>
</dd>
<dt>hired</dt><dd><p>whether the climber was a hired member of the expedition</p>
</dd>
<dt>success</dt><dd><p>whether the climber successfully reached the destination</p>
</dd>
<dt>solo</dt><dd><p>whether the climber was on a solo expedition</p>
</dd>
<dt>oxygen_used</dt><dd><p>whether the climber utilized supplemental oxygen</p>
</dd>
<dt>died</dt><dd><p>whether the climber died during the expedition</p>
</dd>
<dt>injured</dt><dd><p>whether the climber was injured on the expedition</p>
</dd>
<dt>count</dt><dd><p>number of climbers in the expedition</p>
</dd>
<dt>height_metres</dt><dd><p>height of the peak in meters</p>
</dd>
<dt>first_ascent_year</dt><dd><p>the year of the first recorded summit of the peak (though not necessarily the actual first summit!)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Original source: <a href="https://www.himalayandatabase.com/">https://www.himalayandatabase.com/</a>. Complete dataset distributed by: <a href="https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-09-22/">https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-09-22/</a>.
</p>

<hr>
<h2 id='estuaries'>Effect of pollution on marine microinvertebrates in estuaries</h2><span id='topic+estuaries'></span>

<h3>Description</h3>

<p>Data from an observational study of whether there is a different in microinvertebrate
communities between estuaries that have been heavily modified by human activity and those
that have not, across seven estuaries along the coast of New South Wales, Australia (Clark et al. 2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("estuaries")
</code></pre>


<h3>Format</h3>

<p>A dataframe containing (among other things):</p>

<dl>
<dt>Mod</dt><dd><p>A factor describing whether the sample was taken from a 'Modified' or 'Pristine' estuary.</p>
</dd>
<dt>Zone</dt><dd><p>Whether the sample was taken from Inner (upstream) or Outer (downstream) zone of the estuary.</p>
</dd>
<dt>Estuary</dt><dd><p>A factor with seven levels identifying which estuary the sample was taken from.</p>
</dd>
<dt>Total</dt><dd><p>Total abundance of all invertebrates in the sample</p>
</dd> 
<dt>Richness</dt><dd><p>Richness of taxa in the sample &ndash; the number of responses (of those in columns 8-94) taking a non-zero value</p>
</dd> 
</dl>

<p>Other variables in the dataset give invertebrate counts separately for different taxa.
</p>


<h3>References</h3>

<p>Clark, G. F., Kelaher, B. P., Dafforn, K. A., Coleman, M. A., Knott, N. A., 
Marzinelli, E. M., &amp; Johnston, E. L. (2015). What does impacted look like? high diversity and
abundance of epibiota in modified estuaries. Environmental Pollution 196, 12-20.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("estuaries")
plot(Total~Estuary,data=estuaries,col=c(4,2,2,4,2,4,2))
</code></pre>

<hr>
<h2 id='find_ccc'>
Find cluster-constant covariates in a data set.
</h2><span id='topic+find_ccc'></span>

<h3>Description</h3>

<p>This function gives out logical indicators whether a variable is cluster-constant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_ccc(df, id_char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_ccc_+3A_df">df</code></td>
<td>
<p> some data frame</p>
</td></tr>
<tr><td><code id="find_ccc_+3A_id_char">id_char</code></td>
<td>
<p> a character which is the column name for the cluster identifier. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For uncorrected boosting of a mixed model the estimates for cluster constant covariates
might be biased as part of their effect is held in the random effects.
This bias is corrected by the underlying mermboost package.
</p>


<h3>Value</h3>

<p>Gives a logical vector that indicates which variables of the dataframe have the same
realisation for all observations of one cluster/individual.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmermboost">glmermboost</a></code> and <code><a href="#topic+mermboost">mermboost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Orthodont)
find_ccc(Orthodont, "Subject")
</code></pre>

<hr>
<h2 id='glmermboost'>
Component-wise Gradient Boosting for Generalised Mixed Models
</h2><span id='topic+glmermboost'></span><span id='topic+glmermboost.formula'></span>

<h3>Description</h3>

<p>Gradient boosting for optimizing negative log-likelihoods as loss functions where component-wise
linear models are utilized as base-learners and an estimation of random components is guaranteed
via a maximum likelihood approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmermboost(formula, data = list(), weights = NULL,
          offset = NULL, family = gaussian,
          na.action = na.omit, contrasts.arg = NULL,
          center = TRUE, control = boost_control(), oobweights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glmermboost_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit in the
lme4-format including random effects. </p>
</td></tr>
<tr><td><code id="glmermboost_+3A_data">data</code></td>
<td>
<p> a data frame containing the variables in the model. </p>
</td></tr>
<tr><td><code id="glmermboost_+3A_weights">weights</code></td>
<td>
<p> an optional vector of weights to be used in the fitting
process. </p>
</td></tr>
<tr><td><code id="glmermboost_+3A_offset">offset</code></td>
<td>
<p> a numeric vector to be used as offset (optional).</p>
</td></tr>
<tr><td><code id="glmermboost_+3A_family">family</code></td>
<td>
<p>!! This is in contrast to usual mboost -
&quot;only&quot; a <code><a href="stats.html#topic+family">family</a></code> object is possible - except for <code>NBinomial()</code>.</p>
</td></tr>
<tr><td><code id="glmermboost_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain <code>NA</code>s.</p>
</td></tr>
<tr><td><code id="glmermboost_+3A_contrasts.arg">contrasts.arg</code></td>
<td>
<p>a list, whose entries are contrasts suitable for input
to the <code>contrasts</code> replacement function and whose names are
the names of columns of <code>data</code> containing factors.
See <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.</p>
</td></tr>
<tr><td><code id="glmermboost_+3A_center">center</code></td>
<td>
<p>logical indicating of the predictor variables are centered before fitting.</p>
</td></tr>
<tr><td><code id="glmermboost_+3A_control">control</code></td>
<td>
<p> a list of parameters controlling the algorithm. For
more details see <code><a href="mboost.html#topic+boost_control">boost_control</a></code>. </p>
</td></tr>
<tr><td><code id="glmermboost_+3A_oobweights">oobweights</code></td>
<td>
<p> an additional vector of out-of-bag weights, which is
used for the out-of-bag risk (i.e., if <code>boost_control(risk =
      "oobag")</code>).</p>
</td></tr>
<tr><td><code id="glmermboost_+3A_...">...</code></td>
<td>
<p> additional arguments passed to <code><a href="mboost.html#topic+mboost_fit">mboost_fit</a></code>; currently none.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The warning &quot;model with centered covariates does not contain intercept&quot; is correctly given -
the intercept is estimated via the mixed model.
</p>
<p>A (generalized) linear mixed model is fitted using a boosting algorithm based on component-wise
univariate linear models. Additionally, a mixed model gets estimated in every iteration and added
to the current fit. The fit, i.e., the regression coefficients and random effects, can be
interpreted in the usual way. This particular methodology is described in
Knieper et al. (2025).
</p>


<h3>Value</h3>

<p>The description of <code><a href="mboost.html#topic+glmboost">glmboost</a></code> holds while some methods are newly implemented like <code><a href="#topic+predict.mermboost">predict.mermboost</a></code>, <code><a href="#topic+plot.mer_cv">plot.mer_cv</a></code> and <code><a href="#topic+mstop.mer_cv">mstop.mer_cv</a></code>. Only the former one requires a further argument. Additionally, methods  <code><a href="#topic+VarCorr.mermboost">VarCorr.mermboost</a></code> and <code><a href="#topic+ranef.mermboost">ranef.mermboost</a></code>are implemented specifically.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+mermboost">mermboost</a></code> for the same approach using additive models.
</p>
<p>See <code><a href="#topic+mer_cvrisk">mer_cvrisk</a></code> for a cluster-sensitive cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Orthodont)

# are there cluster-constant covariates?
find_ccc(Orthodont, "Subject")


# fit initial model
mod &lt;- glmermboost(distance ~ age + Sex + (1 |Subject),
                   data = Orthodont, family = gaussian,
                   control = boost_control(mstop = 100))

# let mermboost do the cluster-sensitive cross-validation for you
norm_cv &lt;- mer_cvrisk(mod, no_of_folds = 10)
opt_m &lt;- mstop(norm_cv)

# fit model with optimal stopping iteration
mod_opt &lt;- glmermboost(distance ~ age + Sex + (1 |Subject),
                   data = Orthodont, family = gaussian,
                   control = boost_control(mstop = opt_m))

# use the model as known from mboost
# in additional, there are some methods knwon from lme4
ranef(mod_opt)
VarCorr(mod_opt)


#######################

set.seed(123)

# Parameters
n_groups &lt;- 10        # Number of groups
n_per_group &lt;- 50     # Number of observations per group
beta_fixed &lt;- c(0.5, -0.3, 0.7)  # Fixed effects for intercept, covariate1, covariate2
sigma_random &lt;- 1     # Random effect standard deviation

# Simulate random effects (group-specific)
group_effects &lt;- rnorm(n_groups, mean = 0, sd = sigma_random)

# Simulate covariates
covariate1 &lt;- rnorm(n_groups * n_per_group)
covariate2 &lt;- rnorm(n_groups * n_per_group)

# Simulate data
group &lt;- rep(1:n_groups, each = n_per_group)
random_effect &lt;- group_effects[group]

# Linear predictor including fixed effects and random effects
linear_predictor &lt;- beta_fixed[1] + beta_fixed[2] * covariate1 +
                  beta_fixed[3] * covariate2 + random_effect
prob &lt;- plogis(linear_predictor)  # Convert to probabilities

# Simulate binomial outcomes
y &lt;- rbinom(n_groups * n_per_group, size = 1, prob = prob)

# Combine into a data frame
sim_data &lt;- data.frame(group = group, y = y,
                       covariate1 = covariate1,
                       covariate2 = covariate2)
sim_data$group &lt;- as.factor(sim_data$group)



mod3 &lt;- glmermboost(y ~ covariate1 + covariate2 + (1 | group),
                    data = sim_data, family = binomial())
bin_cv &lt;- mer_cvrisk(mod3, no_of_folds = 10)
mstop(bin_cv)

</code></pre>

<hr>
<h2 id='mer_cvrisk'> Cluster-sensitive Cross-Validation </h2><span id='topic+mer_cvrisk'></span><span id='topic+cvrisk.mermboost'></span>

<h3>Description</h3>

<p>Cross-validated estimation of the empirical risk for hyper-parameter selection.
Folds are created cluster-sensitive, hence splitting data into train and tests sets
considers the cluster-structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mer_cvrisk(object, folds, no_of_folds, cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mer_cvrisk_+3A_object">object</code></td>
<td>
<p> an object of class <code>mermboost</code>.</p>
</td></tr>
<tr><td><code id="mer_cvrisk_+3A_folds">folds</code></td>
<td>
<p> a weight matrix with number of rows equal to the number
of observations. The number of columns corresponds to
the number of cross-validation runs. Can be computed
using function <code>cv</code>.</p>
</td></tr>
<tr><td><code id="mer_cvrisk_+3A_no_of_folds">no_of_folds</code></td>
<td>
<p> creates the folds itself by taking the cluster structure into account. </p>
</td></tr>
<tr><td><code id="mer_cvrisk_+3A_cores">cores</code></td>
<td>

<p>is passed on to <code><a href="parallel.html#topic+mclapply">mclapply</a></code> for parallel computing.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of boosting iterations is a hyper-parameter of the
boosting algorithms implemented in this package. Honest,
i.e., cross-validated, estimates of the empirical risk
for different stopping parameters <code>mstop</code> are computed by
this function which can be utilized to choose an appropriate
number of boosting iterations to be applied.
</p>
<p>This function uses the cluster-identifier held in the <code>mermboost</code> object
to split the data into cluster-sensitive folds if the corresponding argument
<code>no_of_folds</code> is given.
As this might lead to imbalanced splits the 1/0 matrix of folds can be given manually
via the folds argument.
</p>


<h3>Value</h3>

<p>An object of class <code>mer_cv</code>, containing the k-folds as a matrix,
the corresponding estimates of the empirical risks, their average
and the results optimal stopping iteration.
<code>plot</code> and <code>mstop</code> methods are available.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Orthodont)

mod &lt;- mermboost(distance ~ bbs(age, knots = 4) + bols(Sex) + (1 |Subject),
                 data = Orthodont, family = gaussian,
                 control = boost_control(mstop = 100))

# let mermboost do the cluster-sensitive cross-validation for you
norm_cv &lt;- mer_cvrisk(mod, no_of_folds = 10)
opt_m &lt;- mstop(norm_cv)
plot(norm_cv)

</code></pre>

<hr>
<h2 id='mermboost'> Gradient Boosting for Additive Mixed Models </h2><span id='topic+mermboost'></span>

<h3>Description</h3>

<p>Gradient boosting for optimizing negative log-likelihoods as loss functions,
where component-wise arbitrary base-learners, e.g., smoothing procedures,
are utilized as additive  base-learners. In addition, every iteration estimates
random component via a maximum likelihood approach using the current fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mermboost(formula, data = list(), na.action = na.omit, weights = NULL,
       offset = NULL, family = gaussian, control = boost_control(),
       oobweights = NULL, baselearner = c("bbs", "bols", "btree", "bss", "bns"),
       ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mermboost_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit in the
lme4-format including random effects.  </p>
</td></tr>
<tr><td><code id="mermboost_+3A_data">data</code></td>
<td>
<p> a data frame containing the variables in the model. </p>
</td></tr>
<tr><td><code id="mermboost_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.</p>
</td></tr>
<tr><td><code id="mermboost_+3A_weights">weights</code></td>
<td>
<p> (optional) a numeric vector of weights to be used in
the fitting process.</p>
</td></tr>
<tr><td><code id="mermboost_+3A_offset">offset</code></td>
<td>
<p> a numeric vector to be used as offset (optional).</p>
</td></tr>
<tr><td><code id="mermboost_+3A_family">family</code></td>
<td>
<p>!! This is in contrast to usual mboost -
&quot;only&quot; a <code><a href="stats.html#topic+family">family</a></code> object is possible - except for <code>NBinomial()</code>.</p>
</td></tr>
<tr><td><code id="mermboost_+3A_control">control</code></td>
<td>
<p> a list of parameters controlling the algorithm. For
more details see <code><a href="mboost.html#topic+boost_control">boost_control</a></code>. </p>
</td></tr>
<tr><td><code id="mermboost_+3A_oobweights">oobweights</code></td>
<td>
<p> an additional vector of out-of-bag weights, which is
used for the out-of-bag risk (i.e., if <code>boost_control(risk =
      "oobag")</code>). This argument is also used internally by
<code>cvrisk</code>. </p>
</td></tr>
<tr><td><code id="mermboost_+3A_baselearner">baselearner</code></td>
<td>
<p> a character specifying the component-wise base
learner to be used: <code><a href="mboost.html#topic+bbs">bbs</a></code> means P-splines with a
B-spline basis (see Schmid and Hothorn 2008), <code><a href="mboost.html#topic+bols">bols</a></code>
linear models and <code><a href="mboost.html#topic+btree">btree</a></code> boosts stumps.
<code>bss</code> and <code>bns</code> are deprecated.
Component-wise smoothing splines have been considered in Buehlmann
and Yu (2003) and Schmid and Hothorn (2008) investigate P-splines
with a B-spline basis. Kneib, Hothorn and Tutz (2009) also utilize
P-splines with a B-spline basis, supplement them with their
bivariate tensor product version to estimate interaction surfaces
and spatial effects and also consider random effects base
learners.</p>
</td></tr>
<tr><td><code id="mermboost_+3A_...">...</code></td>
<td>
<p> additional arguments passed to <code><a href="mboost.html#topic+mboost_fit">mboost_fit</a></code>; currently none.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A (generalized) additive mixed model is fitted using a boosting algorithm based on
component-wise base-learners. Additionally, a mixed model gets estimated in every
iteration and added to the current fit.
</p>
<p>The base-learners can either be specified via the <code>formula</code> object or via
the <code>baselearner</code> argument. The latter argument is the default base-learner
which is used for all variables in the formula, without explicit base-learner
specification (i.e., if the base-learners are explicitly specified in <code>formula</code>,
the <code>baselearner</code> argument will be ignored for this variable).
</p>
<p>Of note, <code>"bss"</code> and <code>"bns"</code> are deprecated and only in the list for
backward compatibility.
</p>
<p>Note that more base-learners (i.e., in addition to the ones provided
via <code>baselearner</code>) can be specified in <code>formula</code>. See
<code><a href="mboost.html#topic+baselearners">baselearners</a></code> for details.
</p>


<h3>Value</h3>

<p>The description of <code><a href="mboost.html#topic+mboost">mboost</a></code> holds while some methods are newly implemented
like <code><a href="#topic+predict.mermboost">predict.mermboost</a></code>, <code><a href="#topic+plot.mer_cv">plot.mer_cv</a></code> and <code><a href="#topic+mstop.mer_cv">mstop.mer_cv</a></code>. Only the former one requires
an further argument. Additionally, methods  <code><a href="#topic+VarCorr.mermboost">VarCorr.mermboost</a></code> and <code><a href="#topic+ranef.mermboost">ranef.mermboost</a></code> are implemented specifically.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+glmermboost">glmermboost</a></code> for the same approach using additive models.
</p>
<p>See <code><a href="#topic+mer_cvrisk">mer_cvrisk</a></code> for a cluster-sensitive cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Orthodont")

# are there cluster-constant covariates?
find_ccc(Orthodont, "Subject")


mod &lt;- mermboost(distance ~ bbs(age, knots = 4) + bols(Sex) + (1 |Subject),
                 data = Orthodont, family = gaussian,
                 control = boost_control(mstop = 100))

# let mermboost do the cluster-sensitive cross-validation for you
norm_cv &lt;- mer_cvrisk(mod, no_of_folds = 10)
opt_m &lt;- mstop(norm_cv)

# fit model with optimal stopping iteration
mod_opt &lt;- mermboost(distance ~ bbs(age, knots = 4) + bols(Sex) + (1 |Subject),
                 data = Orthodont, family = gaussian,
                 control = boost_control(mstop = opt_m))

# use the model as known from mboost
# in additional, there are some methods knwon from lme4
ranef(mod_opt)
VarCorr(mod_opt)

</code></pre>

<hr>
<h2 id='methods'> Methods for Gradient Boosting for Mixed Models Objects </h2><span id='topic+mermboost_methods'></span><span id='topic+predict.mermboost'></span><span id='topic+predict.glmermboost'></span><span id='topic+ranef.glmermboost'></span><span id='topic+ranef.mermboost'></span><span id='topic+VarCorr.glmermboost'></span><span id='topic+VarCorr.mermboost'></span><span id='topic+mstop.mer_cv'></span><span id='topic+plot.mer_cv'></span>

<h3>Description</h3>

<p> Methods for models fitted by mixed model boosting algorithms. </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mermboost'
predict(object, newdata = NULL, RE = TRUE,
        type = c("link", "response", "class"), which = NULL,
        aggregate = c("sum", "cumsum", "none"), ...)
## S3 method for class 'glmermboost'
predict(object, newdata = NULL, RE = TRUE,
        type = c("link", "response", "class"), which = NULL,
        aggregate = c("sum", "cumsum", "none"), ...)

## S3 method for class 'mermboost'
 ranef(object, iteration = mstop(object), ...)
## S3 method for class 'glmermboost'
 ranef(object, iteration = mstop(object), ...)

## S3 method for class 'mermboost'
VarCorr(x, sigma=1, iteration = mstop(x), ...)
## S3 method for class 'glmermboost'
VarCorr(x, sigma=1, iteration = mstop(x), ...)

## S3 method for class 'mer_cv'
mstop(object, ...)
## S3 method for class 'mer_cv'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="methods_+3A_object">object</code></td>
<td>
<p> objects of class <code>glmermboost</code> or <code>mermboost</code>.
If you are using <code><a href="#topic+mstop.mer_cv">mstop.mer_cv</a></code> it refers to an 
object resulting from  <code><a href="#topic+mer_cvrisk">mer_cvrisk</a></code>. </p>
</td></tr>
<tr><td><code id="methods_+3A_newdata">newdata</code></td>
<td>
<p> optionally, a data frame in which to look for variables with
which to predict. In case the model was fitted using the <code>matrix</code>
interface to <code><a href="#topic+glmermboost">glmermboost</a></code>, <code>newdata</code> must be a <code>matrix</code>
as well (an error is given otherwise).
If <code>RE = TRUE</code> but not the same cluster-identifier is found in the newdata object,
it gets set to FALSE, <code>RE = FALSE</code>. </p>
</td></tr>
<tr><td><code id="methods_+3A_re">RE</code></td>
<td>
<p> a logical values (<code>TRUE/FALSE</code>) indicating whether to include random effects. </p>
</td></tr>
<tr><td><code id="methods_+3A_which">which</code></td>
<td>
<p> a subset of base-learners to take into account for computing
predictions or coefficients. If <code>which</code> is given
(as an integer vector or characters corresponding
to base-learners) a list or matrix is returned.
This ignores the random effects. </p>
</td></tr>
<tr><td><code id="methods_+3A_type">type</code></td>
<td>
<p> the type of prediction required.  The default is on the scale
of the predictors; the alternative <code>"response"</code> is on
the scale of the response variable.  Thus for a
binomial model the default predictions are of log-odds
(probabilities on logit scale) and <code>type = "response"</code> gives
the predicted probabilities.  The <code>"class"</code> option returns
predicted classes for binomial data.</p>
</td></tr>
<tr><td><code id="methods_+3A_aggregate">aggregate</code></td>
<td>
<p> a character specifying how to aggregate predictions
or coefficients of single base-learners. The default
returns the prediction or coefficient for the final number of
boosting iterations. <code>"cumsum"</code> returns a
matrix (one row per base-learner) with the
cumulative coefficients for all iterations
simultaneously (in columns). <code>"none"</code> returns a
list of matrices where the <code class="reqn">j</code>th columns of the
respective matrix contains the predictions
of the base-learner of the <code class="reqn">j</code>th boosting
iteration (and zero if the base-learner is not
selected in this iteration). Therefore, no random effects
are considered.</p>
</td></tr>
<tr><td><code id="methods_+3A_iteration">iteration</code></td>
<td>
<p> an integer input that specifies from which iteration the
random component is to be drawn. </p>
</td></tr>
<tr><td><code id="methods_+3A_sigma">sigma</code></td>
<td>
<p> an argument used in <code>lme4</code>. Exists for technical reasons but finds no application here. </p>
</td></tr>
<tr><td><code id="methods_+3A_x">x</code></td>
<td>
<p> a cross-validation object for <code>plot.mer_cv</code> or an <code>mermboost</code> object for <code>VarCorr.mermboost</code>. </p>
</td></tr>
<tr><td><code id="methods_+3A_...">...</code></td>
<td>
<p> additional arguments passed to callies. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods should correspond to equivalent <code>mboost</code> and <code>lme4</code> functions. However, additional arguments about random effects handling might be of interest.
</p>


<h3>Value</h3>

<p>The <code>predict.mermboost</code>-methods give a vector, matrix or a list depending on the arguments. 
</p>
<p>A matrix with cluster-identifier as rownames and random effects as element results from <code>ranef.mermboost</code>.
</p>
<p>A <code>VarrCorr.merMod</code> is the result of applying <code>VarCorr.mermboost</code> to a <code>mermboost</code> model.
</p>
<p>To deal with cross validtion objects, class <code>mer_cv</code>, <code>mstop.mer_cv</code> gives a numeric value of the optimal stopping iteration while <code>plot.mer_cv</code> plots cross-validation risk-paths.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mstop.mer_cv">mstop.mer_cv</a></code> and <code><a href="#topic+plot.mer_cv">plot.mer_cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Orthodont)

mod &lt;- glmermboost(distance ~ age + Sex + (1 |Subject),
                   data = Orthodont, family = gaussian,
                   control = boost_control(mstop = 50))

any(predict(mod, RE = FALSE) == predict(mod, RE = TRUE))
all(predict(mod, RE = FALSE) ==
    predict.glmboost(mod) + mod$nuisance()[[mstop(mod)]]$ff
    )
ranef(mod)
VarCorr(mod, iteration = 10)
</code></pre>

<hr>
<h2 id='Orthodont'>Growth curve data on an orthdontic measurement</h2><span id='topic+Orthodont'></span>

<h3>Description</h3>

<p>The <code>Orthodont</code> data frame has 108 rows and 4 columns of the
change in an orthdontic measurement over time for several young subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Orthodont")</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>distance</dt><dd>
<p>a numeric vector of distances from the pituitary to the
pterygomaxillary fissure (mm).  These distances are measured
on x-ray images of the skull.
</p>
</dd>
<dt>age</dt><dd>
<p>a numeric vector of ages of the subject (yr).
</p>
</dd>
<dt>Subject</dt><dd>
<p>an ordered factor indicating the subject on which the
measurement was made.  The levels are labeled <code>M01</code>
to <code>M16</code> for the males and <code>F01</code> to <code>F13</code> for
the females.  The ordering is by increasing average distance
within sex.
</p>
</dd>
<dt>Sex</dt><dd>
<p>a factor with levels
<code>Male</code> and
<code>Female</code>
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Investigators at the University of North Carolina Dental School
followed the growth of 27 children (16 males, 11 females) from age 8
until age 14.  Every two years they measured the distance between the
pituitary and the pterygomaxillary fissure, two points that are easily
identified on x-ray exposures of the side of the head.
</p>


<h3>Source</h3>

<p>Pinheiro, J. C. and Bates, D. M. (2000), <em>Mixed-Effects Models in S
and S-PLUS</em>, Springer, New York.  (Appendix A.17)
</p>
<p>Potthoff, R. F. and Roy,  S. N. (1964), &ldquo;A generalized multivariate
analysis of variance model useful especially for growth curve
problems&rdquo;, <em>Biometrika</em>, <b>51</b>, 313&ndash;326.
</p>


<h3>References</h3>

<p>Potthoff, R. F. and Roy,  S. N. (1964), &ldquo;A generalized multivariate
analysis of variance model useful especially for growth curve
problems&rdquo;, <em>Biometrika</em>, <b>51</b>, 313&ndash;326.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
