<!DOCTYPE html><html><head><title>Help for package miWQS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {miWQS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#analyze.individually'><p>Performing Individual Chemical Analysis</p></a></li>
<li><a href='#coef.wqs'><p>Finding WQS Coefficients</p></a></li>
<li><a href='#combine.AIC'><p>Combining AICs</p></a></li>
<li><a href='#do.many.wqs'><p>Performing Many WQS Regressions</p></a></li>
<li><a href='#estimate.wqs'><p>Weighted Quantile Sum (WQS) Regression</p></a></li>
<li><a href='#estimate.wqs.formula'><p>Formula for WQS Regression</p></a></li>
<li><a href='#impute.boot'><p>Bootstrapping Imputation for Many Chemicals</p></a></li>
<li><a href='#impute.Lubin'><p>Lubin et al. 2004: Bootstrapping Imputation for One Chemical</p></a></li>
<li><a href='#impute.multivariate.bayesian'><p>Multivariate Bayesian Imputation</p></a></li>
<li><a href='#impute.sub'><p>Imputing by Substitution</p></a></li>
<li><a href='#impute.univariate.bayesian.mi'><p>Univariate Bayesian Imputation</p></a></li>
<li><a href='#make.quantile.matrix'><p>Making Quantiles of Correlated Index</p></a></li>
<li><a href='#plot.wqs'><p>Histograms of the Weights, Beta1, and WQS using <code>ggplot</code></p></a></li>
<li><a href='#pool.mi'><p>Pooling Multiple Imputation Results</p></a></li>
<li><a href='#print.wqs'><p>Prints the fitted WQS model along with the mean weights.</p></a></li>
<li><a href='#simdata87'><p>Simulated Dataset 87</p></a></li>
<li><a href='#wqs.pool.test'><p>Combining WQS Regression Estimates</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multiple Imputation Using Weighted Quantile Sum Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul M. Hargarten &lt;hargartenp@alumni.vcu.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), methods, parallel, stats, utils</td>
</tr>
<tr>
<td>Imports:</td>
<td>coda (&ge; 0.19-2), condMVNorm (&ge; 2015.2-1), ggplot2 (&ge;
3.1.0), glm2 (&ge; 1.2.1), Hmisc (&ge; 4.1-1), invgamma (&ge; 1.1),
MASS (&ge; 7.3-49), matrixNormal (&ge; 0.0.0), MCMCpack (&ge; 1.4-4),
mvtnorm (&ge; 1.0-10), purrr (&ge; 0.3.2), rlist (&ge; 0.4.6.1),
Rsolnp (&ge; 1.16), survival (&ge; 3.1-12), tidyr (&ge; 1.0.0),
tmvmixnorm (&ge; 1.0.2), tmvtnorm (&ge; 1.4-10), truncnorm (&ge;
1.0-8)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>formatR, GGally (&ge; 1.4.0), knitr (&ge; 1.23), mice (&ge; 3.3.0),
norm, pander (&ge; 0.6.3), rmarkdown (&ge; 1.13), scales (&ge;
1.0.0), sessioninfo (&ge; 1.1.1), spelling (&ge; 2.0), testthat (&ge;
2.0.1), wqs (&ge; 0.0.1)</td>
</tr>
<tr>
<td>Description:</td>
<td>The miWQS package handles the uncertainty due to below the detection limit in a correlated component mixture problem.  Researchers want to determine if a set/mixture of continuous and correlated components/chemicals is associated with an outcome and if so, which components are important in that mixture. These components share a common outcome but are interval-censored between zero and low thresholds, or detection limits, that may be different across the components. This package applies the multiple imputation (MI) procedure to the weighted quantile sum regression (WQS) methodology for continuous, binary, or count outcomes (Hargarten &amp; Wheeler (2020) &lt;<a href="https://doi.org/10.1016%2Fj.envres.2020.109466">doi:10.1016/j.envres.2020.109466</a>&gt;). The imputation models are: bootstrapping imputation (Lubin et.al (2004) &lt;<a href="https://doi.org/10.1289%2Fehp.7199">doi:10.1289/ehp.7199</a>&gt;), univariate Bayesian imputation (Hargarten &amp; Wheeler (2020) &lt;<a href="https://doi.org/10.1016%2Fj.envres.2020.109466">doi:10.1016/j.envres.2020.109466</a>&gt;), and multivariate Bayesian regression imputation.  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/phargarten2/miWQS/issues">https://github.com/phargarten2/miWQS/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-04-02 03:18:18 UTC; pablo</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul M. Hargarten [aut, cre],
  David C. Wheeler [aut, rev, ths]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-02 21:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='analyze.individually'>Performing Individual Chemical Analysis</h2><span id='topic+analyze.individually'></span>

<h3>Description</h3>

<p>An accessory function for <code>estimate.wqs()</code>. Performs individual chemical analyses to determine the constraint for the overall mixture effect on the outcome (<code class="reqn">\beta_1</code>) in WQS regression. After adjusting for any covariates, the outcome regresses on each chemical <em>individually</em>. Returns a data-frame of statistics from these analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyze.individually(
  y,
  X,
  Z = NULL,
  family = c("gaussian", "binomial", "poisson"),
  offset = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyze.individually_+3A_y">y</code></td>
<td>
<p>Outcome: numeric vector or factor. Assumed to be complete, and missing outcomes are ignored. Assumed to follow an exponential family distribution given in <code>family</code>.</p>
</td></tr>
<tr><td><code id="analyze.individually_+3A_x">X</code></td>
<td>
<p>Components/chemicals to be combined into an index; a numeric matrix or data-frame.</p>
</td></tr>
<tr><td><code id="analyze.individually_+3A_z">Z</code></td>
<td>
<p>Any covariates used. Ideally, a numeric matrix, but Z can be a factor, vector or data-frame. Assumed to be complete; observations with missing covariate values are ignored with a warning printed. If none, enter NULL.</p>
</td></tr>
<tr><td><code id="analyze.individually_+3A_family">family</code></td>
<td>
<p>The distribution of outcome y. A character value:
if equal to &quot;gaussian&quot; a linear model is implemented;
if equal to &quot;binomial&quot; a logistic model is implemented;
if equal to &quot;poisson&quot;, a log-link (rate or count) model is implemented.
See <code><a href="stats.html#topic+family">family</a></code> in the <span class="pkg">stats</span> package. Passed to <span class="pkg">glm2</span>. Default: &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="analyze.individually_+3A_offset">offset</code></td>
<td>
<p>The at-risk population used as a numeric vector of length equal to the number of subjects when modeling rates in Poisson regression. Passed to <span class="pkg">glm2</span>.  Default: If there is no offset, enter NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Individual chemical analyses with the outcome can be used to determine whether the mixture of chemicals is positively or negatively related to the outcome. The constraint whether the overall mixture effect,  <code class="reqn">\beta_1</code>, is positive or negative is controlled by b1.pos argument in <code><a href="#topic+estimate.wqs">estimate.wqs</a></code>.  The b1.pos argument is TRUE if the overall chemical mixture effect is positively related to the outcome; otherwise, it is negatively related to the outcome.
For each analysis, the outcome is regressed on the log of the observed values for each chemical and any other covariates Z, if they exist. This was accomplished using <code><a href="glm2.html#topic+glm2">glm2</a></code>.  We summarized the results by recording the chemical name, estimating the log chemical effect and its standard error on the outcome, and using the Akaike Information Criterion (AIC) to indicate model fit.
</p>
<p>By looking at the output, one can decide whether the chemical mixture is positive or negative. Generally, if the sign of estimates is mainly positive, we would decide to make b1.pos in <code><a href="#topic+estimate.wqs">estimate.wqs</a></code> to be TRUE. This is just one approach to determine the direction of this constraint. Alternatively, one can conduct a WQS analysis for the positively related chemicals and another WQS analysis for the negatively related chemicals.
</p>


<h3>Value</h3>

<p>A data-frame from statistics of individual chemical analyses is returned: </p>

<dl>
<dt>chemical.name</dt><dd><p>name of the component</p>
</dd>
<dt>estimate</dt><dd><p>the estimate of log chemical effect</p>
</dd>
<dt>Std.Error</dt><dd><p>the standard error of log chemical effect</p>
</dd>
<dt>AIC</dt><dd><p>Model Fit. See <code>stats::<a href="stats.html#topic+AIC">AIC</a></code>.</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other wqs: 
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Binomial Example
data("simdata87")
analyze.individually(
  y = simdata87$y.scenario, X = simdata87$X.true, Z = simdata87$Z.sim,
  family = "binomial"
)
# The "Estimate" column contains the log_odds of each log of the
# chemical on the outcome. Most are positive, which indicates a possible
# positive relationship between mixture of chemicals and the outcome.
</code></pre>

<hr>
<h2 id='coef.wqs'>Finding WQS Coefficients</h2><span id='topic+coef.wqs'></span>

<h3>Description</h3>

<p>An accessor function that returns the coefficients from the validation WQS model,
a <strong>wqs</strong> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wqs'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.wqs_+3A_object">object</code></td>
<td>
<p>An object of class &quot;wqs&quot;, usually as a result of <code><a href="#topic+estimate.wqs">estimate.wqs</a></code>.</p>
</td></tr>
<tr><td><code id="coef.wqs_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a <strong>wqs</strong> object, the <em>fit</em> element, a <span class="pkg">glm2</span> object, is extracted. See <code>glm2{glm2}</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+coef">coef</a></code>
</p>
<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use simulated dataset and set seed for reproducibility.
data(simdata87)
set.seed(23456)
Wa &lt;- estimate.wqs(
  y = simdata87$y.scenario, X = simdata87$X.true[, 1:3],
  B = 10, family = "binomial"
)
coef(Wa)
</code></pre>

<hr>
<h2 id='combine.AIC'>Combining AICs</h2><span id='topic+combine.AIC'></span>

<h3>Description</h3>

<p>Combines individual AIC estimates of separate  models to get a sense of overall model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine.AIC(AIC)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combine.AIC_+3A_aic">AIC</code></td>
<td>
<p>A vector of AICs to combine with length equal to the number of models completed (i.e. K).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The WQS model fits using different completely observed datasets are combined in Stage 3 of multiple imputation. Similar to combining WQS parameter estimates, the mean of individual AIC estimates is taken as the central tendency estimate of WQS model fit. The standard deviation between individual AIC estimates indicates the difference in WQS model fits due to below the detection limit values.
</p>
<p>A vector of AICs may be generated from <code><a href="#topic+do.many.wqs">do.many.wqs</a></code>().
</p>


<h3>Value</h3>

<p>The overall fit of a model across all imputation models: the mean AIC +/- the standard error. Saved as a 1x1 character vector.
</p>


<h3>Warning</h3>

<p>If AIC is a vector with one element, the AIC is returned as a character rounded to the nearest whole number with a warning printed that AIC cannot be combined.
</p>


<h3>See Also</h3>

<p>pool.mi
</p>


<h3>Examples</h3>

<pre><code class='language-R'># AICs from do.many.wqs() example are as follows.
bayes.AIC &lt;- c(1295.380, 1295.669)
combine.AIC(bayes.AIC)

# One AIC
combine.AIC(1295.380)
</code></pre>

<hr>
<h2 id='do.many.wqs'>Performing Many WQS Regressions</h2><span id='topic+do.many.wqs'></span>

<h3>Description</h3>

<p>Second Stage of Multiple Imputation:  In order to analyze a complete imputed chemical array (<code>X.imputed</code>), _n_ subjects by _C_ chemicals by _K_ imputations) via weighted quantile sum regression, <code>do.many.wqs</code>() repeatedly performs the same WQS analysis on each imputed dataset. It repeatedly executes the <code><a href="#topic+estimate.wqs">estimate.wqs</a></code>() function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.many.wqs(y, X.imputed, Z = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do.many.wqs_+3A_y">y</code></td>
<td>
<p>Outcome: numeric vector or factor. Assumed to be complete, and missing outcomes are ignored. Assumed to follow an exponential family distribution given in <code>family</code>.</p>
</td></tr>
<tr><td><code id="do.many.wqs_+3A_x.imputed">X.imputed</code></td>
<td>
<p>Array of complete components with n subjects and C components and K imputations. Must be complete.</p>
</td></tr>
<tr><td><code id="do.many.wqs_+3A_z">Z</code></td>
<td>
<p>Any covariates used. Ideally, a numeric matrix, but Z can be a factor, vector or data-frame. Assumed to be complete; observations with missing covariate values are ignored with a warning printed. If none, enter NULL.</p>
</td></tr>
<tr><td><code id="do.many.wqs_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>estimate.wqs</code>, but the arguments y, X, Z, and place.bdls.Q1 have no effect.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with elements that consist of matrix and list versions of <code>estimate.wqs()</code> output: </p>

<ul>
<li><p> call: the function call, processed by <span class="pkg">rlist</span>.
</p>
</li>
<li><p> C:  the number of chemicals in mixture, number of columns in X.
</p>
</li>
<li><p> n: the sample size.
</p>
</li>
<li><p> wqs.imputed.estimates: Array with rows = # of parameters, 2 columns = mean and standard deviation, and 3rd dimension = K.
</p>
</li>
<li><p> AIC: The overall fit of WQS models taken as the mean AIC and standard error across all imputation models. Saved as a character element.  Calling wqs.fit allows us to see all models.
</p>
</li>
<li><p> train.index: Observations that are selected to train the data in the last WQS model.
</p>
</li>
<li><p> q.train: Vector of quantiles used in training data from the last WQS model
</p>
</li>
<li><p> train.comparison: A list of data-frames that compares the training and validation dataset for all WQS models.
</p>
</li>
<li><p> initial: Matrix with K columns that contains the initial values used for each WQS analysis.
</p>
</li>
<li><p> wqs.train.estimates: Data-frame with rows = B. Summarizes statistics from nonlinear regression in the training datasets of all analyses: </p>

<dl>
<dt>beta1</dt><dd><p>estimate using solnp</p>
</dd>
<dt>beta1_glm, SE_beta1, test_stat, pvalue</dt><dd><p>estimates of WQS parameter in model using glm2.</p>
</dd>
<dt>convergence</dt><dd><p>whether or not the samples have converged</p>
</dd>
<dt>weight estimates</dt><dd><p>estimates of weight for each bootstrap.</p>
</dd>
<dt>imputed</dt><dd><p>A number indicating the completed dataset used in WQS analysis.</p>
</dd>
</dl>

</li>
<li><p> wqs.fit: A list (length = K) of glm2 objects of the WQS model fit to validation data. These are all the WQS estimates for all analyses. See <code><a href="glm2.html#topic+glm2">glm2</a></code>.
</p>
</li></ul>



<h3>Note</h3>

<p>Note #1: We only impute the missing values of the components, X. Any missing data in the outcome and covariates are removed and ignored.
</p>
<p>Note #2: No seed is set in this function. Because bootstraps and splitting is random,  a seed should be set before every use.
</p>
<p>Note #3: If there is one imputed dataset, use the <code><a href="#topic+estimate.wqs">estimate.wqs</a></code> function as <code>do.many.wqs</code> is not necessary.
</p>


<h3>See Also</h3>

<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("simdata87")
# Create 2 multiple imputed datasets using bootstrapping, but only use first 2 chemicals.
set.seed(23234)
l &lt;- impute.boot(
  X = simdata87$X.bdl[, 1:2], DL = simdata87$DL[1:2],
  Z = simdata87$Z.sim[, 1], K = 2
)
# Perform WQS regression on each imputed dataset
set.seed(50679)
bayes.wqs &lt;- do.many.wqs(
  y = simdata87$y.scenario, X.imputed = l$X.imputed,
  Z = simdata87$Z.sim,
  B = 10, family = "binomial"
)
bayes.wqs$wqs.imputed.estimates



# #' @importFrom scales ordinal
</code></pre>

<hr>
<h2 id='estimate.wqs'>Weighted Quantile Sum (WQS) Regression</h2><span id='topic+estimate.wqs'></span>

<h3>Description</h3>

<p>Performs weighted quantile sum (WQS) regression model for continuous, binary, and count outcomes that was extended from <code><a href="wqs.html#topic+wqs.est">wqs.est</a></code> (author: Czarnota) in the <span class="pkg">wqs</span> package. By default, if there is any missing data, the missing data is assumed to be censored and placed in the first quantile.  Accessory functions (print, coefficient, plot) also accompany each WQS object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.wqs(
  y,
  X,
  Z = NULL,
  proportion.train = 1L,
  n.quantiles = 4L,
  place.bdls.in.Q1 = if (anyNA(X)) TRUE else FALSE,
  B = 100L,
  b1.pos = TRUE,
  signal.fn = c("signal.none", "signal.converge.only", "signal.abs",
    "signal.test.stat"),
  family = c("gaussian", "binomial", "poisson"),
  offset = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate.wqs_+3A_y">y</code></td>
<td>
<p>Outcome: numeric vector or factor. Assumed to be complete, and missing outcomes are ignored. Assumed to follow an exponential family distribution given in <code>family</code>.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_x">X</code></td>
<td>
<p>Components/chemicals to be combined into an index; a numeric matrix or data-frame.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_z">Z</code></td>
<td>
<p>Any covariates used. Ideally, a numeric matrix, but Z can be a factor, vector or data-frame. Assumed to be complete; observations with missing covariate values are ignored with a warning printed. If none, enter NULL.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_proportion.train">proportion.train</code></td>
<td>
<p>The proportion of data between 0 and 1 used to train the model. If proportion.train = 1L, all the data is used to both train and validate the model. Default: 1L.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_n.quantiles">n.quantiles</code></td>
<td>
<p>An integer specifying the number of quantiles in categorizing the columns of X, e.g. in quartiles (q = 4), deciles (q = 10), or percentiles (q = 100). Default: 4L.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_place.bdls.in.q1">place.bdls.in.Q1</code></td>
<td>
<p>Logical; if TRUE or X has any missing values, missing values in X are placed in the first quantile of the weighted sum.  Otherwise, the data is complete (no missing data) and the data is equally split into quantiles.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_b">B</code></td>
<td>
<p>Number of bootstrap samples to be used in estimating the weights in the training dataset. In order to use WQS without bootstrapping, set B = 1. However, Carrico et al 2014 suggests that bootstrap some large number (like 100 or 1000) can increase component selection. In that spirit, we set the default to 100.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_b1.pos">b1.pos</code></td>
<td>
<p>Logical; TRUE if the mixture index is expected to be positively related to the outcome (the default). If mixture index is expected to be inversely related to the outcome, put FALSE.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_signal.fn">signal.fn</code></td>
<td>
<p>A character value indicating which signal function is used in calculating the mean weight. See details.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_family">family</code></td>
<td>
<p>The distribution of outcome y. A character value:
if equal to &quot;gaussian&quot; a linear model is implemented;
if equal to &quot;binomial&quot; a logistic model is implemented;
if equal to &quot;poisson&quot;, a log-link (rate or count) model is implemented.
See <code><a href="stats.html#topic+family">family</a></code> in the <span class="pkg">stats</span> package. Passed to <span class="pkg">glm2</span>. Default: &quot;gaussian&quot;.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_offset">offset</code></td>
<td>
<p>The at-risk population used as a numeric vector of length equal to the number of subjects when modeling rates in Poisson regression. Passed to <span class="pkg">glm2</span>.  Default: If there is no offset, enter NULL.</p>
</td></tr>
<tr><td><code id="estimate.wqs_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <cite><a href="Rsolnp.html#topic+solnp">solnp</a></cite> algorithm, or a nonlinear optimization technique using augmented Lagrange method, is used to estimate the weights in the training set. If the log likelihood evaluated at the current parameters is too large (NaN), the log likelihood is reset to be 1e24.
A data-frame with object name <em>train.estimates</em> that summarizes statistics from the nonlinear regression is returned; it consists of these columns:
</p>

<dl>
<dt>beta1</dt><dd><p>estimate using solnp</p>
</dd>
<dt>beta1_glm, SE_beta1, test_stat, pvalue</dt><dd><p>estimates of WQS parameter in model using glm2.</p>
</dd>
<dt>convergence</dt><dd><p>logical, if TRUE the solnp solver has converged. See <cite><a href="Rsolnp.html#topic+solnp">solnp</a></cite>.</p>
</dd>
<dt>weight estimates</dt><dd><p>estimates of weight for each bootstrap.</p>
</dd>
</dl>

<p>Signal functions allow the user to adjust what bootstraps are used in calculating the mean weight. Looking at a histogram of the overall mixture effect, which is an element after plotting a WQS object, may help you to choose a signal function. The <em>signal.fn</em> argument allows the user to choose between four signal functions:
</p>

<dl>
<dt>signal.none</dt><dd><p>Uses all bootstrap-estimated weights in calculating average weight.</p>
</dd>
<dt>signal.converge.only</dt><dd><p>Uses the estimated weights for the bootstrap samples that converged.</p>
</dd>
<dt>signal.abs</dt><dd><p>Applies more weight to the absolute value of test statistic for beta1, the overall mixture effect in the trained WQS model.</p>
</dd>
<dt>signal.test stat</dt><dd><p>Applies more weight to the absolute value of test statistic for beta1, the overall mixture effect in the trained WQS model.</p>
</dd>
</dl>

<p>This package uses the <cite><a href="glm2.html#topic+glm2">glm2</a></cite> function in the <span class="pkg">glm2</span> package to fit the validation model.
</p>
<p>The object is a member of the <em>&quot;wqs&quot;</em> class; accessory functions include <code>coef</code>(), <code>print</code>(), and <code>plot</code>().
</p>
<p>See example 1 in the vignette for details.
</p>


<h3>Value</h3>

<p><code>estimate.wqs</code> returns an object of class &quot;wqs&quot;. A list with the following items: (** important) </p>

<dl>
<dt>call</dt><dd><p>The function call, processed by <span class="pkg">rlist</span>.</p>
</dd>
<dt>C</dt><dd><p>The number of chemicals in mixture, number of columns in X.</p>
</dd>
<dt>n</dt><dd><p>The sample size.</p>
</dd>
<dt>train.index</dt><dd><p>Vector, The numerical indices selected to form the training dataset. Useful to do side-by-side comparisons.</p>
</dd>
<dt>q.train</dt><dd><p>Matrix of quantiles used in training data. </p>
</dd>
<dt>q.valid</dt><dd><p>Matrix of quantiles used in validation data. </p>
</dd>
<dt>train.comparison</dt><dd><p>Data-frame that compares the training and validation datasets to validate equivalence </p>
</dd>
<dt>initial</dt><dd><p>Vector: Initial values used in WQS.</p>
</dd>
<dt>train.estimates</dt><dd><p>Data-frame with rows = B. Summarizes statistics from nonlinear regression in training dataset. See details.</p>
</dd>
<dt>processed.weights</dt><dd><p>** A C x 2 matrix, mean bootstrapped weights (and their standard errors) after filtering with the signal function (see <code>signal.fn</code>). Used to calculate the WQS index.</p>
</dd>
<dt>WQS</dt><dd><p>Vector of the weighted quantile sum estimate based on the processed weights. </p>
</dd>
<dt>fit</dt><dd><p>** glm2 object of the WQS model fit using the validation data. See <code>glm2{glm2}</code>.</p>
</dd>
<dt>boot.index</dt><dd><p>Matrix of bootstrap indices used in training dataset to estimate the weights. Its dimension is the length of training dataset with number of columns = B.</p>
</dd>
</dl>



<h3>Rate WQS Regression</h3>

<p>Rates can be modelled using the offset. The <em>offset</em> argument of <code>estimate.wqs()</code> function is on the normal scale, so please do not take a logarithm.  The objective function used to model the mean rate of the <em>ith</em> individual <code class="reqn">\lambda_i</code> with the offset is:
</p>
<p style="text-align: center;"><code class="reqn"> \lambda_i = offset * exp(\eta) </code>
</p>

<p>, where <code class="reqn">\eta</code> is the linear term of a regression.
</p>


<h3>Note</h3>

<p>No seed is set in this function.  Because bootstraps and splitting is random, a seed should be set before every use.
</p>


<h3>References</h3>

<p>Carrico, C., Gennings, C., Wheeler, D. C., &amp; Factor-Litvak, P. (2014). Characterization of Weighted Quantile Sum Regression for Highly Correlated Data in a Risk Analysis Setting. Journal of Agricultural, Biological, and Environmental Statistics, 20(1), 100–120. https://doi.org/10.1007/s13253-014-0180-3
</p>
<p>Czarnota, J., Gennings, C., Colt, J. S., De Roos, A. J., Cerhan, J. R., Severson, R. K., … Wheeler, D. C. (2015). Analysis of Environmental Chemical Mixtures and Non-Hodgkin Lymphoma Risk in the NCI-SEER NHL Study. Environmental Health Perspectives, 123(10), 965–970.  https://doi.org/10.1289/ehp.1408630
</p>
<p>Czarnota, J., Gennings, C., &amp; Wheeler, D. C. (2015). Assessment of Weighted Quantile Sum Regression for Modeling Chemical Mixtures and Cancer Risk. Cancer Informatics, 14, 159–171. https://doi.org/10.4137/CIN.S17295
</p>


<h3>See Also</h3>

<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Binary outcome using the example simulated dataset in this package.
data(simdata87)
set.seed(23456)
W.bin4  &lt;- estimate.wqs(
  y = simdata87$y.scenario, X = simdata87$X.true[, 1:9],
  B = 10, family = "binomial",
  verbose = TRUE
)
W.bin4

# Example 2: Continuous outcome. Use WQSdata example from wqs package.
## Not run: 
if (requireNamespace("wqs", quietly = TRUE)) {
  library(wqs)
  data(WQSdata)
  set.seed(23456)
  W &lt;- wqs::wqs.est(WQSdata$y, WQSdata[, 1:9], B = 10)
  Wa &lt;- estimate.wqs (y = WQSdata$y, X = WQSdata[, 1:9], B = 10)
  Wa
} else {
  message("You need to install the package wqs for this example.")
}

## End(Not run)

## More examples are found 02_WQS_Examples.
## Also checked vs. Czarnota code, as well as thesis data, to verify results.

</code></pre>

<hr>
<h2 id='estimate.wqs.formula'>Formula for WQS Regression</h2><span id='topic+estimate.wqs.formula'></span>

<h3>Description</h3>

<p>A wrapper function for <code><a href="#topic+estimate.wqs">estimate.wqs</a></code> to use a formula instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.wqs.formula(formula, data, chem_mix, ..., verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate.wqs.formula_+3A_formula">formula</code></td>
<td>
<p>An object of class &quot;formula&quot; that consists of an outcome, chemical mixture, and covariates, if any. See <code>stats::<a href="stats.html#topic+formula">formula</a></code>.</p>
</td></tr>
<tr><td><code id="estimate.wqs.formula_+3A_data">data</code></td>
<td>
<p>The data in a data-frame format</p>
</td></tr>
<tr><td><code id="estimate.wqs.formula_+3A_chem_mix">chem_mix</code></td>
<td>
<p>Indices or column names of variables to be combined into an index.</p>
</td></tr>
<tr><td><code id="estimate.wqs.formula_+3A_...">...</code></td>
<td>
<p>Additional WQS parameters passed to <code>estimate.wqs</code>. Note: data arguments (y, X, and Z) have no effect.</p>
</td></tr>
<tr><td><code id="estimate.wqs.formula_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1
set.seed(232)
test.data &lt;- data.frame(x1 = rlnorm(100, 3, 1), x2 = rlnorm(100, 5, 1),
  z1 = rlnorm(100, 10, 3), z2 = rbinom(100, 1, 0.7),
  y = rnorm(100, 100, 15)
)
estimate.wqs.formula(y ~ ., data = test.data, chem_mix = c("x1", "x2"))
## Not run: 
# Example 2: No covariates
estimate.wqs.formula(y ~ x1 + x2, data = test.data, chem_mix = 1:2)

# Example 3: NA in Z
test.data$z1[10] &lt;- NA
estimate.wqs.formula(y ~ ., data = test.data, chem_mix = c("x1", "x2"))

# Example 4: NA in Z and y
test.data$y[1] &lt;- NA
estimate.wqs.formula(y ~ ., data = test.data, chem_mix = c("x1", "x2"))


# Example 5: NA in Z, X, and y
test.data$x1[2] &lt;- NA
estimate.wqs.formula(y ~ ., data = test.data, chem_mix = c("x1", "x2"),
  place.bdls.in.Q1 = TRUE
)
# due to time constraints

## End(Not run)

</code></pre>

<hr>
<h2 id='impute.boot'>Bootstrapping Imputation for Many Chemicals</h2><span id='topic+impute.boot'></span>

<h3>Description</h3>

<p>If many chemicals have values below the detection limit, this function creates an imputed dataset using a bootstrap procedure as described in Lubin et al. 2004. It repeatedly invokes <code><a href="#topic+impute.Lubin">impute.Lubin</a></code>().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute.boot(X, DL, Z = NULL, K = 5L, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute.boot_+3A_x">X</code></td>
<td>
<p>A numeric vector, matrix, or data-frame of chemical concentration levels with n subjects and C chemicals to be imputed. Missing values are indicated by NA's.  Ideally, a numeric matrix.</p>
</td></tr>
<tr><td><code id="impute.boot_+3A_dl">DL</code></td>
<td>
<p>The detection limit for each chemical as a numeric vector with length equal to C chemicals. Vector must be complete (no NA's); any chemical that has a missing detection limit is not imputed. If DL is a data-frame or matrix with 1 row or 1 column, it is forced as a numeric vector.</p>
</td></tr>
<tr><td><code id="impute.boot_+3A_z">Z</code></td>
<td>
<p>Any covariates used in imputing the chemical concentrations.  Ideally, a numeric matrix; however, Z can be a factor, vector, or data-frame. Assumed to be complete; observations with missing covariate variables are ignored in the imputation, with a warning printed. If none, enter NULL.</p>
</td></tr>
<tr><td><code id="impute.boot_+3A_k">K</code></td>
<td>
<p>A natural number of imputed datasets to generate. Default: 5L.</p>
</td></tr>
<tr><td><code id="impute.boot_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Lubin et al. (2004) evaluate several imputation approaches and show that a multiple imputation procedure using bootstrapping creates unbiased estimates and nominal confidence intervals unless the proportion of missing data is extreme. The authors coded the multiple imputation procedure in a SAS macro that is currently available. We converted the SAS macro into R code.
</p>
<p>The <code>impute.Lubin</code>() function imputes a single chemical with missing values. The distribution for the interval-censored data <em>chemcol</em> is assumed to be   lognormal and censored between 0 and <em>DL</em>. After bootstrapping, the values BDL are imputed  using the inverse transform method. In other words, generate <code class="reqn">u_i \sim Unif( 0.0001, dlcol)</code> and assign value <code class="reqn">F^{-1}(u)</code> to <code class="reqn">x_{i}</code> for <code class="reqn">i = 1,...n_{0}</code> subjects with chemical values BDL.
</p>
<p>In order to impute a single chemical:
</p>

<ol>
<li><p> Input arguments.
</p>
</li>
<li><p> Obtain bootstrap samples.
</p>
</li>
<li><p> Generate weights vector.
</p>
</li>
<li><p> Use <code><a href="survival.html#topic+Surv">Surv</a></code> function from Survival package to obtain survival object.
</p>
</li>
<li><p> Use <code><a href="survival.html#topic+survreg">survreg</a></code> function from Survival package to obtain survival model.
</p>
</li>
<li><p> Sample from lognormal distribution with beta and variance from survival model as the parameters to obtain upper and lower bounds.
</p>
</li>
<li><p> Randomly generate value from uniform distribution between the previously obtained upper and lower bounds.
</p>
</li>
<li><p> Sample from the lognormal distribution to obtain the imputed data value associated with the above uniform value.
</p>
</li></ol>

<p><code>impute.boot()</code> repeatedly performs this procedure for all chemicals.
</p>


<h3>Value</h3>

<p>A list of: </p>

<dl>
<dt>X.imputed</dt><dd><p>A number of subjects (n) x number of chemicals (c) x K array of imputed X values.</p>
</dd>
<dt>bootstrap_index</dt><dd><p>A n x K matrix of bootstrap indices selected for the imputation.</p>
</dd>
<dt>indicator.miss</dt><dd><p>A check; the sum of imputed  missing values above detection limit,
which should be 0.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Note #1: Code was adapted from Erin E. Donahue's original translation of the SAS macro developed from the paper.
</p>
<p>Note #2: No seed is set. Please set seed so the same bootstraps are selected.
</p>
<p>Note #3: If the length of the DL parameter is greater than the number of components, the smallest value is assumed to be a detection limit. A warning is printed to the screen.
</p>


<h3>References</h3>

<p>Lubin, J. H., Colt, J. S., Camann, D., Davis, S., Cerhan, J. R., Severson, R. K., … Hartge, P. (2004).
Epidemiologic Evaluation of Measurement Data in the Presence of Detection Limits. Environmental Health Perspectives,
112(17), 1691–1696. https://doi.org/10.1289/ehp.7199
</p>


<h3>See Also</h3>

<p>Other imputation: 
<code><a href="#topic+impute.Lubin">impute.Lubin</a>()</code>,
<code><a href="#topic+impute.multivariate.bayesian">impute.multivariate.bayesian</a>()</code>,
<code><a href="#topic+impute.sub">impute.sub</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("simdata87")
# Impute using one covariate.
l &lt;- impute.boot(X = simdata87$X.bdl, DL = simdata87$DL, Z = simdata87$Z.sim[, 1],
  K = 2, verbose = TRUE
)
apply(l$X.imputed, 2:3, summary)
</code></pre>

<hr>
<h2 id='impute.Lubin'>Lubin et al. 2004: Bootstrapping Imputation for One Chemical</h2><span id='topic+impute.Lubin'></span>

<h3>Description</h3>

<p>Softly DEPRECATED. Use  impute.boot instead.
</p>
<p>For one chemical, this function creates an imputed dataset using a bootstrap procedure as
described in Lubin et al. 2004.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute.Lubin(chemcol, dlcol, Z = NULL, K = 5L, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute.Lubin_+3A_chemcol">chemcol</code></td>
<td>
<p>A numeric vector, the chemical concentration levels of length C. Censored values are indicated by  NA. On original scale.</p>
</td></tr>
<tr><td><code id="impute.Lubin_+3A_dlcol">dlcol</code></td>
<td>
<p>The detection limit of the chemical. A value or a numeric vector of length C. Must be complete; a missing detection limit is ignored.</p>
</td></tr>
<tr><td><code id="impute.Lubin_+3A_z">Z</code></td>
<td>
<p>Any covariates used in imputing the chemical concentrations.  Ideally, a numeric matrix; however, Z can be a factor, vector, or data-frame. Assumed to be complete; observations with missing covariate variables are ignored in the imputation, with a warning printed. If none, enter NULL.</p>
</td></tr>
<tr><td><code id="impute.Lubin_+3A_k">K</code></td>
<td>
<p>A natural number of imputed datasets to generate. Default: 5L.</p>
</td></tr>
<tr><td><code id="impute.Lubin_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of: </p>

<dl>
<dt>X.imputed</dt><dd><p>A matrix with n subjects and K imputed datasets is returned.</p>
</dd>
<dt>bootstrap_index</dt><dd><p>A n x K matrix of bootstrap indices selected for the imputation. Each column is saved as a factor.</p>
</dd>
<dt>indicator.miss</dt><dd><p>A check; the sum of imputed  missing values above detection limit,
which should be 0.</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other imputation: 
<code><a href="#topic+impute.boot">impute.boot</a>()</code>,
<code><a href="#topic+impute.multivariate.bayesian">impute.multivariate.bayesian</a>()</code>,
<code><a href="#topic+impute.sub">impute.sub</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#   ###Example 2: Simulation
# Apply to an example simulated dataset.
# A seed of 202 is executed before each run for reproducibility.
data(simdata87)

# No Covariates
set.seed(202)
results_Lubin &lt;- impute.Lubin(chemcol = simdata87$X.bdl[, 1], dlcol = simdata87$DL[1],
  K = 5, verbose = TRUE)
str(results_Lubin)
summary(results_Lubin$imputed_values)

# 1 Covariate
set.seed(202)
sim.z1 &lt;- impute.Lubin(simdata87$X.bdl[, 1], simdata87$DL[1],
  K = 5, Z = simdata87$Z.sim[, 1], verbose = TRUE)
summary(sim.z1$imputed_values)

# 2 Covariates
set.seed(202)
sim.z2 &lt;- impute.Lubin(simdata87$X.bdl[, 1], simdata87$DL[1],
  K = 5, Z = simdata87$Z.sim[, -2])
summary(sim.z2$imputed_values)
summary(sim.z2$bootstrap_index)
</code></pre>

<hr>
<h2 id='impute.multivariate.bayesian'>Multivariate Bayesian Imputation</h2><span id='topic+impute.multivariate.bayesian'></span>

<h3>Description</h3>

<p>Given lognormal interval-censored chemical concentrations between zero and different detection limits <em>DL</em>, the chemical concentrations are modelled using Bayesian multivariate regression. Drawing from the posterior predictive density of the BDL chemical concentrations given the observed ones yields multiple (or K) imputed datasets. These datasets are then used in WQS regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute.multivariate.bayesian(
  X,
  DL,
  Z = NULL,
  K = 5L,
  prior.coeff.mean = NULL,
  prior.cov.mean = NULL,
  T = 250L,
  n.burn = 50L,
  initial = list(NA, NA),
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute.multivariate.bayesian_+3A_x">X</code></td>
<td>
<p>A numeric vector, matrix, or data-frame of chemical concentration levels with n subjects and C chemicals to be imputed. Missing values are indicated by NA's.  Ideally, a numeric matrix.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_dl">DL</code></td>
<td>
<p>The detection limit for each chemical as a numeric vector with length equal to C chemicals. Vector must be complete (no NA's); any chemical that has a missing detection limit is not imputed. If DL is a data-frame or matrix with 1 row or 1 column, it is forced as a numeric vector.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_z">Z</code></td>
<td>
<p>Any covariates used in imputing the chemical concentrations.  Ideally, a numeric matrix; however, Z can be a factor, vector, or data-frame. Assumed to be complete; observations with missing covariate variables are ignored in the imputation, with a warning printed. If none, enter NULL.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_k">K</code></td>
<td>
<p>A natural number of imputed datasets to generate. Default: 5L.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_prior.coeff.mean">prior.coeff.mean</code></td>
<td>
<p>The prior mean of number of covariates (p) x C coefficient matrix. The default, entered as NULL, will be a matrix of 1's, given by <code><a href="matrixNormal.html#topic+special.matrix">special.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_prior.cov.mean">prior.cov.mean</code></td>
<td>
<p>The prior mean of covariance matrix. The default, entered as NULL, is an identity matrix with size equal to the number of chemicals, given by <code><a href="matrixNormal.html#topic+special.matrix">special.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_t">T</code></td>
<td>
<p>Number of total iterations for the Gibbs Sampler. Default: 1000L.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_n.burn">n.burn</code></td>
<td>
<p>The burn-in, which is the number of initial iterations to be discarded. Generally, the burn-in can be quite large as the imputed chemical matrices, X.imputed, are formed from the end of the chain &ndash; the lowest state used is <code class="reqn">T - 10*K</code>. Default: 1L (no burn-in).</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_initial">initial</code></td>
<td>
<p>An optional two-item list that consists of initial values for the log imputed BDL values vectorized by subject in the Gibbs Sampler. The list contains two elements, one for each chain in the Gibbs Sampler. Each element is a vector of length n0C containing the log imputed BDL values vectorized by subject, (n0 is total # of missing values). If unknown for each chain, enter NA, and the initial values are automatically generated.</p>
</td></tr>
<tr><td><code id="impute.multivariate.bayesian_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list that consists of the following elements:
</p>
<dl>
<dt>call</dt><dd><p>A list of arguments used in this function.</p>
</dd></dl>

<p>Section - Imputed Dataset (from accessory draw.multi.imputed.samples())   </p>

<dl>
<dt>X.imputed</dt><dd><p>An array of n subjects x C chemicals x K imputed sets on the normal scale. The main result and purpose of the function.</p>
</dd>
</dl>

<p>Section - Convergence </p>

<dl>
<dt>convgd.table</dt><dd><p>A data-frame summarizing convergence with C rows and columns of the Gelman-Rubin statistic and whether the point estimate is less than 1.2. Also printed to the screen.</p>
</dd>
<dt>auto.corr</dt><dd><p>Summary of autocorrelations of missing data, which are used to justify states taken as imputed datasets. Also printed to screen.</p>
</dd>
<dt>last.states</dt><dd><p>A list of the last (Tth) states of the imputed values saved to be used for initial values with the first element being from chain1 and second element from chain2.</p>
</dd>
</dl>

<p>Section - convgd.surrogates. Surrogates used to check for convergence saved as mcmc.list objects. Returning in case trace plots, autocorrelation plots, etc. wants to be calculated. </p>

<dl>
<dt>eigen.Gamma</dt><dd><p>An mcmc.list object of the eigenvalues from the p x p Gamma *Gamma^T matrix from the two BURNED chains.  The eigenvalues were used as surrogates for the convergence of the coefficient matrix, Gamma.</p>
</dd>
<dt>eigen.Sigma</dt><dd><p>An mcmc.list object of the eigenvalues for covariance matrix Sigma from two BURNED chains. The eigenvalues were used as surrogates for the convergence of Sigma.</p>
</dd>
<dt>vec.log.X.imputed</dt><dd><p>An mcmc.list object of the vectorized log imputed chemical values from the two BURNED chains.</p>
</dd>
</dl>

<p>Section - Checking Imputation Procedure </p>

<dl>
<dt>indicator.miss</dt><dd><p>A check; a sum of indicator variables where the number of imputed missing values &gt; detection limit. Should be 0. Printed to screen.</p>
</dd>
</dl>



<h3>Introduction</h3>

<p>We wish to assess the association of the mixture *X* and an outcome *y* while accounting for other covariates *Z*. However, the components in *X* are interval-censored between zero and different detection limits *DL*. The multivariate Bayesian imputation method in the MI-WQS framework (MBMI) jointly imputes the chemical mixture *K* times by taking full advantage of the chemical mixture data.
</p>
<p>The logarithmic chemical concentrations *X* are assumed to follow a matrix normal distribution, which is an extension of the multivariate normal:
</p>
<p style="text-align: center;"><code class="reqn">  \log(X)|Z \sim MatNorm( \mu_{i} = z'_{i} \Gamma , \Sigma) , i = 1, ... n </code>
</p>

<p>(Iranmanesh et al., 2010).  Like other imputation methods in miWQS, we wish to find the posterior predictive density of log(X_miss)|log(X_obs). In <code>impute.multivariate.bayesian()</code>, the missing chemical concentrations are imputed using estimates from a Bayesian Multivariate regression.
</p>


<h3>Step 1 - Generate a posterior sample</h3>

<p>The accessory <code>sample.mregress.impute()</code> function generate a posterior samples using the data augmentation technique. The conjugate priors for a multivariate regression are multivariate extensions of those in the univariate linear regression case. Given complete data, the conjugate priors for the coefficient matrix is another matrix normal with mean <code>prior.coeff.mean</code>, individual variance matrix <code class="reqn">Z'Z</code>, and chemical variance matrix <code class="reqn">\Sigma</code>.  The prior distribution for the covariance matrix is the inverse-Wishart distribution. In this function, we used a matrix of 1's as the default prior coefficient mean of the matrix normal.  The prior parameters chosen for the covariance matrix are vague with the degree of freedoms equal to the number of components, and the mean matrix, by default, is an identity of ones. Instead of attempting to impute a n x C matrix X, we vectorized the logarithmic concentrations by individual, such as:
&gt; vec(t(X))             <br />
...           ...      <br />
dieldrin.18  NA        <br />
pcb_180.18  -0.2514225 <br />
pcb_180.19  -0.2929334 <br />
dieldrin.20 -4.4849838 <br />
pcb_180.20  -1.0441849 <br />
... <br />
</p>
<p>The initial missing values were a sample taken from log(uniform(0,DL_j )). If the initial values are set by the user, the initial log imputed values, which is vectorized by subject, has to be n0C x T.
</p>
<p>For each step in the data augmentation, </p>

<ol>
<li><p> Calculate the MLE, the sample covariance matrix, and the posterior matrix of inverse-Wishart.
</p>
</li>
<li><p> Simulate the covariance matrix using inverse Wishart (MCMCpack::riwish()). See <code><a href="MCMCpack.html#topic+InvWishart">InvWishart</a></code>.
</p>
</li>
<li><p> Simulate the coefficient matrix using the matrix normal. See <code><a href="matrixNormal.html#topic+matrixNormal_Distribution">matrixNormal_Distribution</a></code>.
</p>
</li>
<li><p> Impute the vectorized missing log concentrations BDL for each individual from a multivariate normal using current parameter estimates truncated between zero and the detection limits using
</p>
</li></ol>

<p>Note: The exact MCMC chains are not returned to save computer space.
</p>


<h3>Step 2 - Assess convergence</h3>

<p>To save space, the eigenvalues of the c x c matrix Gamma^T*Gamma and c x c covariance matrix Sigma are saved as surrogates to check for convergence in a Markov Chain. </p>

<dl>
<dt>eigen.Gamma.post</dt><dd><p>A coda object of eigenvalues taken from a p X C posterior coefficient matrix converted into a square matrix C x C matrix (Gamma^T*Gamma). The  eigenvalues as surrogates to check for convergence.</p>
</dd>
<dt>eigen.Sigma.post</dt><dd><p>A coda object of eigenvalues for covariance matrix (C X C) used as surrogates to check for convergence. The covariance matrix is already square so no conversion is needed.</p>
</dd>
<dt>vec.log.X.imputed</dt><dd><p>A coda object of the n0 missing values. <br />
Example: The following chemicals shown are those that are missing. <br />
[,1]        [,2]  <br />
dieldrin.18 -0.7573897 -0.60540942   ...    <br />
pcb_180.18  -0.2514225 -1.18717066 <br />
pcb_180.19  -0.2929334 -0.01894021 <br />
dieldrin.20 -4.4849838 -0.78641994  <br />
pcb_180.20  -1.0441849 -0.1349498 <br />
... <br />
</p>
</dd>
</dl>

<p>The accessory <code>converge.multi.chain()</code> function assesses convergence on matrices using the Brook-Gelman’s multivariate potential scale reduction factor (MPSRF). The <code><a href="coda.html#topic+gelman.diag">gelman.diag</a></code> function calculates the MPSRF on eigenvalues and the vectorized imputed values chain. If the MPSRF is less than 1.24, the stationary distribution of the Markov chains was assumed to occur. The results in <code>convgd.table</code> element are printed to the screen. If at least one chain fails to converge, a warning is printed to occur; in this case, it is suggested to increase <code>T</code>.
</p>


<h3>Step 3 - Processing MCMC chains</h3>

<p>The MCMC chains have already been burned using argument <code>n.burn</code> when generated.
</p>


<h3>Step 4 - Making imputed value array</h3>

<p>The accessory <code>draw.multi.imputed.samples()</code> function forms X.imputed using the posterior predictive distribution of log.miss|log.obs. Using the first MCMC chain of the vectorized log imputed chemical values (<code>vec.log.X.imputed</code>) with length (<code>T</code>), the following states are selected:
</p>
<p style="text-align: center;"><code class="reqn"> t_k=T-(k-1)*10   for k=1,2,…K imputations </code>
</p>

<p>The &quot;10&quot; may be justified using autocorrelation summaries, which are printed &amp; returned.
</p>


<h3>Note</h3>

<p>No seed is set in this function. Because bootstraps and data augmentation are random, a seed should be set before every use.
</p>


<h3>See Also</h3>

<p>Other imputation: 
<code><a href="#topic+impute.Lubin">impute.Lubin</a>()</code>,
<code><a href="#topic+impute.boot">impute.boot</a>()</code>,
<code><a href="#topic+impute.sub">impute.sub</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Example takes too long.
system.time({
  set.seed(2345)
  l  &lt;- impute.multivariate.bayesian(
    X =  simdata87$X.bdl[, c(1, 14)], DL = simdata87$DL[c(1, 14)],
    Z =  NULL, T = 200, n.burn = 10, K = 2
  )
})

## End(Not run)
</code></pre>

<hr>
<h2 id='impute.sub'>Imputing by Substitution</h2><span id='topic+impute.sub'></span>

<h3>Description</h3>

<p>The values below the detection limit for each chemical are substituted by its detection limit/sqrt(2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute.sub(X, DL, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute.sub_+3A_x">X</code></td>
<td>
<p>A numeric vector, matrix, or data-frame of chemical concentration levels with n subjects and C chemicals to be imputed. Missing values are indicated by NA's.  Ideally, a numeric matrix.</p>
</td></tr>
<tr><td><code id="impute.sub_+3A_dl">DL</code></td>
<td>
<p>The detection limit for each chemical as a numeric vector with length equal to C chemicals. Vector must be complete (no NA's); any chemical that has a missing detection limit is not imputed. If DL is a data-frame or matrix with 1 row or 1 column, it is forced as a numeric vector.</p>
</td></tr>
<tr><td><code id="impute.sub_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A n x C matrix of components <em>X</em> are interval-censored between zero and different detection limits <em>DL</em>. Although <em>X</em> may refer to a variable with no obvious <em>DL</em>, we consider each chemical concentration being partially observed in mixture <em>X</em>.
</p>


<h3>Value</h3>

<p>A n x C matrix where the BDL values of each chemical are substituted by its detection limit/sqrt(2).
</p>


<h3>See Also</h3>

<p>Other imputation: 
<code><a href="#topic+impute.Lubin">impute.Lubin</a>()</code>,
<code><a href="#topic+impute.boot">impute.boot</a>()</code>,
<code><a href="#topic+impute.multivariate.bayesian">impute.multivariate.bayesian</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("simdata87")

X.sub &lt;- impute.sub(X = simdata87$X.bdl, DL = simdata87$DL, verbose = TRUE)

# Compare substituted imputed data against the truth
probs &lt;- c(0.01, 0.05, 0.09, 0.25, 0.5, 0.8, 1)
apply(X.sub, 2, quantile, probs)
round(apply(simdata87$X.true, 2, quantile, probs), 5)
</code></pre>

<hr>
<h2 id='impute.univariate.bayesian.mi'>Univariate Bayesian Imputation</h2><span id='topic+impute.univariate.bayesian.mi'></span>

<h3>Description</h3>

<p>Given interval-censored data between 0 and different detection limits (<em>DL</em>), <code>impute.univariate.bayesian.mi</code> generates K complete datasets using Univariate Bayesian Imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute.univariate.bayesian.mi(
  X,
  DL,
  T = 1000L,
  n.burn = 1L,
  K = 5L,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute.univariate.bayesian.mi_+3A_x">X</code></td>
<td>
<p>A numeric vector, matrix, or data-frame of chemical concentration levels with n subjects and C chemicals to be imputed. Missing values are indicated by NA's.  Ideally, a numeric matrix.</p>
</td></tr>
<tr><td><code id="impute.univariate.bayesian.mi_+3A_dl">DL</code></td>
<td>
<p>The detection limit for each chemical as a numeric vector with length equal to C chemicals. Vector must be complete (no NA's); any chemical that has a missing detection limit is not imputed. If DL is a data-frame or matrix with 1 row or 1 column, it is forced as a numeric vector.</p>
</td></tr>
<tr><td><code id="impute.univariate.bayesian.mi_+3A_t">T</code></td>
<td>
<p>Number of total iterations for the Gibbs Sampler. Default: 1000L.</p>
</td></tr>
<tr><td><code id="impute.univariate.bayesian.mi_+3A_n.burn">n.burn</code></td>
<td>
<p>The burn-in, which is the number of initial iterations to be discarded. Generally, the burn-in can be quite large as the imputed chemical matrices, X.imputed, are formed from the end of the chain &ndash; the lowest state used is <code class="reqn">T - 10*K</code>. Default: 1L (no burn-in).</p>
</td></tr>
<tr><td><code id="impute.univariate.bayesian.mi_+3A_k">K</code></td>
<td>
<p>A natural number of imputed datasets to generate. Default: 5L.</p>
</td></tr>
<tr><td><code id="impute.univariate.bayesian.mi_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In univariate Bayesian Imputation, only one chemical is imputed at a time. Both the observed and missing data are assumed to follow
</p>
<p style="text-align: center;"><code class="reqn"> log( X_{ij} )  \sim^{indep} Norm(\mu_j , \sigma^2_j) ,   i=1,...n ; j=1,...C </code>
</p>

<p>Subjects and chemicals are assumed to be independent. Jeffery's priors are  placed on mean and variance for each chemical. Posterior simulation uses data augmentation approach. Convergence is checked using Gelman-Rubin statistics. Given sample convergence, the K sets of posterior missing values come from the burned Markov chains thinned by K. The imputed values then replaces the missing data, which forms K complete datasets.
</p>
<p>Each of the posterior parameters from MCMC chain, mu.post, sigma.post, and log.x.miss, is saved as a list of mcmc objects (in <span class="pkg">coda</span>) of length # of chemicals. (A list was chosen since the number of missing values n0 might be different among chemicals).
</p>


<h3>Value</h3>

<p>Returns a list that contains: </p>

<dl>
<dt>X.imputed</dt><dd><p>** An array of n subjects x C chemicals x K imputed datasets on the normal scale.</p>
</dd>
<dt>mu.post</dt><dd><p>A list with length equal to the number of chemicals, where each element (or for each chemical) is the posterior MCMC chain of the mean, saved as a T x 1 <span class="pkg">coda</span>::<code><a href="coda.html#topic+mcmc">mcmc</a></code> object.</p>
</dd>
<dt>sigma.post</dt><dd><p>A list with length equal to the number of chemicals, where each element of list (or for each chemical) is the posterior MCMC chain of the standard deviation, sigma, saved as T x 1 <strong>coda::mcmc</strong> object.</p>
</dd>
<dt>log.x.miss</dt><dd><p>A list with length equal to the number of chemicals, where each element of list is a T x <code class="reqn">n_{0j}</code> matrix of the log of the  imputed missing values, saved as <strong>coda::mcmc</strong> object. <code class="reqn">n_{0j}</code> is the total # of missing values for the jth chemical.</p>
</dd>
<dt>convgd.table</dt><dd><p>A data-frame summarizing convergence with C rows and columns of the Gelman-Rubin statistic and whether the point estimate is less than 1.1. A summary is also printed to the screen.</p>
</dd>
<dt>number.no.converged</dt><dd><p>A check and summary of convgd.table. Total number of parameters that fail to indicate convergence of MCMC chains using Gelman-Rubin statistic. Should be 0.</p>
</dd>
<dt>indicator.miss</dt><dd><p>A check. The sum of imputed missing values above detection limit that is printed to the screen. Should be 0.</p>
</dd>
</dl>
<p>** Most important and used.

</p>


<h3>Note</h3>

<p>No seed is set in this function. Because bootstraps and MCMC are random, a seed should be set before every use.
</p>


<h3>References</h3>

<p>Hargarten, P. M., &amp; Wheeler, D. C. (2020). Accounting for the Uncertainty Due to Chemicals Below the Detection Limit in Mixture Analysis. Environmental Research, 186, 109466. https://doi.org/10.1016/j.envres.2020.109466
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: 10% BDLs Example -------------------------
# Sample Dataset 87, using 10% BDL Scenario
data(simdata87)
set.seed(472195)
result.imputed &lt;- impute.univariate.bayesian.mi(
  X = simdata87$X.bdl[, 1:6], DL = simdata87$DL[1:6],
  T = 1000, n.burn = 50,  K = 2, verbose = TRUE)
# Did the MCMC converge? A summary of Gelman Statistics is provided.
summary(result.imputed$convg.table)
# Summary of Impouted Values
apply(result.imputed$X.imputed, 2:3, summary)
# To show examples for the accessory functions, save the dataset.
# save( result.imputed, l.data, file = "./data/result_imputed.RData")
</code></pre>

<hr>
<h2 id='make.quantile.matrix'>Making Quantiles of Correlated Index</h2><span id='topic+make.quantile.matrix'></span>

<h3>Description</h3>

<p>Scores quantiles from a numeric matrix. If the matrix has values missing between zero and some threshold, say the detection limit, all these missing values  (indicated by NA) are placed into the first quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.quantile.matrix(
  X,
  n.quantiles,
  place.bdls.in.Q1 = if (anyNA(X)) TRUE else FALSE,
  ...,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.quantile.matrix_+3A_x">X</code></td>
<td>
<p>A numeric matrix. Any missing values are indicated by NA's.</p>
</td></tr>
<tr><td><code id="make.quantile.matrix_+3A_n.quantiles">n.quantiles</code></td>
<td>
<p>An integer specifying the number of quantiles in categorizing the columns of X, e.g. in quartiles (q = 4), deciles (q = 10), or percentiles (q = 100). Default: 4L.</p>
</td></tr>
<tr><td><code id="make.quantile.matrix_+3A_place.bdls.in.q1">place.bdls.in.Q1</code></td>
<td>
<p>Logical; if TRUE or X has any missing values, missing values in X are placed in the first quantile of the weighted sum.  Otherwise, the data is complete (no missing data) and the data is equally split into quantiles.</p>
</td></tr>
<tr><td><code id="make.quantile.matrix_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="make.quantile.matrix_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces sample quantiles for a matrix <em>X</em> using <code><a href="stats.html#topic+quantile">quantile</a></code>() function. Names are kept and the 7th quantile algorithm is used. As ties between quantiles may exist, <code><a href="base.html#topic+.bincode">.bincode</a></code>() is used.
</p>
<p>When there is missing data (as indicated by NA's), <code>make.quantile.matrix</code> places all of the censored data into the first quantile. The remaining quantiles are evenly spread over the observed data. A printed message is displaced what the function does.
</p>


<h3>Value</h3>

<p>A matrix of quantiles with rows = nrow(X) and with columns = n.quantiles.
</p>


<h3>Note</h3>

<p>Developed as an accessory function for <code>estimate.wqs()</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code>
</p>
<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Make quantiles for first nine chemicals using complete chemical data
data(simdata87)
q &lt;- make.quantile.matrix(simdata87$X.true[, 1:9], 4)
q &lt;- apply(q, 2, as.factor)
summary(q)

# Example 2: Place missing values of first nine chemicals in first quantiles
q2 &lt;- make.quantile.matrix(simdata87$X.bdl[, 1:9], 4, verbose = TRUE)
summary(q2)
</code></pre>

<hr>
<h2 id='plot.wqs'>Histograms of the Weights, Beta1, and WQS using <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code></h2><span id='topic+plot.wqs'></span>

<h3>Description</h3>

<p>Plots a WQS object producing three histograms of the weights, the overall chemical effect, and WQS
across bootstraps. These histograms are returned as <span class="pkg">ggplot2</span> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wqs'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.wqs_+3A_x">x</code></td>
<td>
<p>An object of class &quot;wqs&quot;, usually as a result of <code><a href="#topic+estimate.wqs">estimate.wqs</a></code>.</p>
</td></tr>
<tr><td><code id="plot.wqs_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods. Currently has no effect.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Three histograms are produced using <code><a href="ggplot2.html#topic+geom_histogram">geom_histogram</a></code> with ten bins.
</p>
<p>Once a Weighted Quantile Sum (WQS) regression is run, the <strong>hist.weights</strong> is a panel of histograms. These are distributions of the weight estimates to determine which chemicals are important in the mixture. Each weight is between 0 and 1 and sum to 1. The individual bootstrapped weight estimates were used to construct the overall chemical index, WQS.
</p>
<p>The <strong>hist.beta1</strong> is the distribution of the overall effect of the mixture on the outcome across bootstraps in the training dataset. Due to the constraint in WQS regression, these estimates are either all positive or all negative as dictated by <em>b1.pos()</em> argument in <code>estimate.wqs</code>. The patterns detected here might be helpful in adjusting the signal function, which is controlled by <em>signal.fn()</em> argument in <code>estimate.wqs</code>.
</p>


<h3>Value</h3>

<p>A list of histograms </p>

<dl>
<dt>hist.weights</dt><dd><p>A list of <span class="pkg">ggplot2</span> histogram of weights across the bootstrap. Each component consists of a histogram with a weight estimate.</p>
</dd>
<dt>hist.beta1</dt><dd><p>A histogram of the overall chemical mixture effect. This parameter is constrained to be positive if the b1.pos argument in estimate.wqs() is TRUE.; otherwise, it is FALSE.</p>
</dd>
<dt>hist.WQS</dt><dd><p>A histogram of the overall chemical sum, WQS. Due to constraints, it is always between 0 and <em>n.quantiles-1</em>.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Defunct argument <code>filename</code> has been removed. Plots are no longer saved automatically; please save manually using <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>().
</p>


<h3>See Also</h3>

<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+print.wqs">print.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use simulated dataset and set seed for reproducibility.
data(simdata87)
set.seed(23456)
Wa &lt;- estimate.wqs(y = simdata87$y.scenario, X = simdata87$X.true[, 1:6],
  B = 10, family = "binomial")
plot(Wa)
</code></pre>

<hr>
<h2 id='pool.mi'>Pooling Multiple Imputation Results</h2><span id='topic+pool.mi'></span>

<h3>Description</h3>

<p>Combines multiple parameter estimates (as used in MI) across the K imputed datasets using Rubin 1996 / 1987 formulas, including: calculating a pooled mean, standard error, missing data statistics, confidence intervals, and p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool.mi(
  to.pool,
  n = 999999,
  method = c("smallsample", "rubin"),
  alpha = 0.05,
  prt = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pool.mi_+3A_to.pool">to.pool</code></td>
<td>
<p>An array of p x 2 x K, where p is the number of parameters to be pooled,
2 refers to the parameters of mean and standard deviation, and K imputation draws.
The rownames of to.pool are kept in the results.</p>
</td></tr>
<tr><td><code id="pool.mi_+3A_n">n</code></td>
<td>
<p>A number providing the sample size, which is used in calculating the degrees of freedom. If nothing is specified, a large sample is assumed. Has no effect if <code>K</code> = 1.</p>
</td></tr>
<tr><td><code id="pool.mi_+3A_method">method</code></td>
<td>
<p>A string to indicate the method to calculate the degrees of freedom, df.t.
If method = &quot;smallsample&quot; (the default) then the Barnard-Rubin adjustment for small
degrees of freedom is used. Otherwise, the method from Rubin (1987) is used.</p>
</td></tr>
<tr><td><code id="pool.mi_+3A_alpha">alpha</code></td>
<td>
<p>Type I error used to form the confidence interval. Default: 0.05.</p>
</td></tr>
<tr><td><code id="pool.mi_+3A_prt">prt</code></td>
<td>
<p>Boolean variable for printing out the standard output. If TRUE, selective parts of a pool.mi object are printed to the screen in an understandable fashion.</p>
</td></tr>
<tr><td><code id="pool.mi_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, prints more information. Useful to check for any errors in the code. Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stage 3 of Multiple Imputation: We assume that each complete-data estimate is normally distributed. But, given incomplete data, we assume a t-distribution, which forms the basis for confidence intervals and hypothesis tests.
</p>
<p>The input is an array with p rows referring to the number of parameters to be combined. An estimate and within standard error forms the two columns of the array, which can be easily be taken as the first two columns of the coefficients element of the summary of a glm/lm object. The last dimension is the number of imputations, K. See dataset <code>wqs.pool.test</code> as an example.
</p>
<p>Uses Rubin's rules to calculate the statistics of an imputed dataset including: the pooled mean, total standard error, a relative increase in variance, the fraction of missing information, a (1-alpha)
</p>


<h3>Value</h3>

<p>A data-frame is returned with the following columns: </p>

<dl>
<dt>pooled.mean</dt><dd><p>The pooled univariate estimate, Qbar, formula (3.1.2) Rubin (1987).</p>
</dd>
<dt>pooled.total.se</dt><dd><p>The total standard error of the pooled estimate, formula (3.1.5) Rubin (1987).</p>
</dd>
<dt>pooled.total.var</dt><dd><p>The total variance of the pooled estimate, formula (3.1.5) Rubin (1987).</p>
</dd>
<dt>se.within</dt><dd><p>The standard error of mean of the variances (i.e. the pooled within-imputation variance), formula (3.1.3) Rubin (1987).</p>
</dd>
<dt>se.between</dt><dd><p>The between-imputation standard error, square root of formula (3.1.4) Rubin (1987).</p>
</dd>
<dt>relative.inc.var(r)</dt><dd><p>The relative increase in variance due to nonresponse, formula (3.1.7) Rubin (1987).</p>
</dd>
<dt>proportion.var.missing(lambda)</dt><dd><p>The proportion of variation due to nonresponse, formula (2.24) Van Buuren (2012).</p>
</dd>
<dt>frac.miss.info</dt><dd><p>The fraction missing information due to nonresponse, formula (3.1.10) Rubin (1987).</p>
</dd>
<dt>df.t</dt><dd><p>The degrees of freedom for the reference t-distribution, formula (3.1.6) Rubin (1987) or method of Barnard-Rubin (1999) (if method = &quot;smallsample&quot; (default)).</p>
</dd>
<dt>CI</dt><dd><p>The (1-alpha)% confidence interval (CI) for each pooled estimate.</p>
</dd>
<dt>p.value</dt><dd><p>The p-value used to test significance.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Modified the <code><a href="mice.html#topic+pool.scalar">pool.scalar</a></code> (version R 3.4) in the <span class="pkg">mice</span> package to handle multiple parameters at once in an array and combine them. Similar to <code><a href="norm.html#topic+mi.inference">mi.inference</a></code> in the <span class="pkg">norm</span> package, but the small-sample adjustment is missing.
</p>


<h3>References</h3>

<p>Rubin, D. B. (1987). Multiple Imputation for nonresponse in surveys. New York: Wiley.
</p>
<p>Rubin, D. B. (1996). Multiple Imputation After 18+ Years. Journal of the American Statistical Association, 91(434), 473–489. https://doi.org/10.2307/2291635.
</p>
<p>Barnard, J., &amp; Rubin, D. B. (1999). Small-Sample Degrees of Freedom with Multiple Imputation. Biometrika, 86(4), 948–955.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### Example 1: Sample Dataset 87, using 10% BDL Scenario
data(wqs.pool.test)
# Example of the `to.pool` argument
head(wqs.pool.test)

# Pool WQS results and decrease in order of weights.
wqs.results.pooled &lt;-   pool.mi(wqs.pool.test, n = 1000)
weight.dec &lt;- c(order(wqs.results.pooled$pooled.mean[1:14], decreasing = TRUE), 15:16)
wqs.results.pooled &lt;-  wqs.results.pooled[weight.dec, ]
wqs.results.pooled


# When there is 1 estimate (p = 1)
a &lt;- pool.mi(wqs.pool.test[1, , , drop = FALSE], n = 1000)
a
# wqs.results.pooled["dieldrin", ]

# For single imputation (K = 1):
b &lt;- pool.mi(wqs.pool.test[, , 1, drop = FALSE], n = 1000)
b

# Odds ratio and 95% CI using the CLT.
odds.ratio &lt;- exp(wqs.results.pooled[15:16, c("pooled.mean", "CI.1", "CI.2")])
## makeJournalTables :: format.CI(odds.ratio, trim = TRUE, digits = 2, nsmall = 2)
odds.ratio

#  The mice package is suggested for the examples, but not needed for the function.
</code></pre>

<hr>
<h2 id='print.wqs'>Prints the fitted WQS model along with the mean weights.</h2><span id='topic+print.wqs'></span>

<h3>Description</h3>

<p>Prints the fitted WQS model along with the mean weights. Adjusted from print.lm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wqs'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.wqs_+3A_x">x</code></td>
<td>
<p>An object of class WQS, from <code><a href="#topic+estimate.wqs">estimate.wqs</a></code>.</p>
</td></tr>
<tr><td><code id="print.wqs_+3A_digits">digits</code></td>
<td>
<p>minimal number of <em>significant</em> digits, see
<code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
<tr><td><code id="print.wqs_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods to print(). Currently has no effect.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other wqs: 
<code><a href="#topic+analyze.individually">analyze.individually</a>()</code>,
<code><a href="#topic+coef.wqs">coef.wqs</a>()</code>,
<code><a href="#topic+do.many.wqs">do.many.wqs</a>()</code>,
<code><a href="#topic+estimate.wqs.formula">estimate.wqs.formula</a>()</code>,
<code><a href="#topic+estimate.wqs">estimate.wqs</a>()</code>,
<code><a href="#topic+make.quantile.matrix">make.quantile.matrix</a>()</code>,
<code><a href="#topic+plot.wqs">plot.wqs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See estimate.wqs().

# As base package is always available, there is no need to ever import base
</code></pre>

<hr>
<h2 id='simdata87'>Simulated Dataset 87</h2><span id='topic+simdata87'></span>

<h3>Description</h3>

<p>The 87th dataset from the simulation study with 10 percent of observations were below the detection limit (BDL) based of a real epidemiological dataset. Out of 1000 subjects, fourteen correlated chemicals are completely observed (in X.true). In this simulation design, each chemical was simulated from independent normal distributions.
</p>
<p>BDLs were created using the bottom 10th percentile of the true data. Three covariates are considered:  the child’s age, the child’s sex (Male/Female), and the child’s ethnicity/race (White, Non-Hispanic White, and Other). After creating a model matrix, male white newborns (age = 0) serves as the  reference. The age is simulated from a normal with mean of 3.78 and standard deviation of 1.85 truncated between 0 and 8. The categorical variables are simulated from independent binomial distributions.  The outcome will be simulated using a logistic WQS model with complete data:
</p>
<p style="text-align: center;"><code class="reqn">logit(\mu_{i}) = -1.25 + log(1.75)*WQS_{i} + 0.032*z_{age}+ -0.0285*z_{sex} + 0.540*z_{His} + 0.120*z_{other} </code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn"> WQS_{i}= \Sigma_{j=1}^{c}(w_{j}*q_{ij}) </code>
</p>

<p>with four of the 14 weights <code class="reqn">w_j</code>'s being 0.25 and the rest 0. The <code class="reqn">q_ij</code> refers to the quantile score of the <em>jth</em> chemical in the <em>ith</em> subject.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simdata87)
</code></pre>


<h3>Format</h3>

<p>A list that contains: </p>

<ul>
<li><p> y.scenario: A binary outcome (1 = case, 0 = control)
</p>
</li>
<li><p> X.true: 14 chemicals; complete data.
</p>
</li>
<li><p> X.bdl: 14 chemicals with NA's subbed for the bottom 10th percentile of the true values.
</p>
</li>
<li><p> DL: The detection limit. Here, found to be the 10th percentile of X.true
</p>
</li>
<li><p> n0: A vector of length 14 indicating the number of non-detects.
</p>
</li>
<li><p> delta: A vector of length 14 indicating whether the chemical is observed (1) or not (0)
</p>
</li>
<li><p> Z.sim: A data-frame of covariates consisting of: </p>

<ul>
<li><p> Age: A continuous covariate of child's age , simulated using normal with mean of 3.78 and sd of 1.85, truncated between 0 and 8, the maximum age of the case.
</p>
</li>
<li><p> Female: Binary variable child's sex, simulated using the proportion of females (0.42) by binomial distribution.
</p>
</li>
<li><p> Hispanic, Non-Hispanic_Others: Two indicator variables of child's race/ethnicity, sampled from independent binomial distributions  (proportion of Hispanic: 0.33; proportion of Other: 0.23).
</p>
</li></ul>

</li>
<li><p> time: The time required to simulate the data.
</p>
</li></ul>



<h3>References</h3>

<p>Ward, M. H., Colt, J. S., Metayer, C., Gunier, R. B., Lubin, J., Crouse, V., … Buffler, P. A. (2009). Residential Exposure
to Polychlorinated Biphenyls and Organochlorine Pesticides and Risk of Childhood Leukemia. Environmental Health Perspectives, 117(6), 1007–1013.
https://doi.org/10.1289/ehp.0900583
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata87 &lt;- data(simdata87)
</code></pre>

<hr>
<h2 id='wqs.pool.test'>Combining WQS Regression Estimates</h2><span id='topic+wqs.pool.test'></span>

<h3>Description</h3>

<p><em>wqs.pool.test</em> was produced to demonstrate <code>pool.mi</code>(). First, the univariate Bayesian imputation approach (using <code>impute.univariate.bayesian.mi</code>) imputed the <code>X.bdl</code> element of <code>simdata87</code> multiple times to form an imputed X array. Multiple WQS regressions were run on the imputed X array to produce an array of WQS parameter estimates, <em>wqs.pool.test</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wqs.pool.test)
</code></pre>


<h3>Format</h3>

<p>An array of 16 x 2 x 3, with </p>

<ul>
<li><p> 16 parameters as the rows (The 14 weights, intercept, and WQS estimate of a WQS model),
</p>
</li>
<li><p> 2 refers to the parameters of mean and standard deviation
</p>
</li>
<li><p> K=3 complete imputed datasets.
</p>
</li></ul>



<h3>See Also</h3>

<p><code>pool.mi</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wqs.pool.test &lt;- data(wqs.pool.test)
# stage_3_pool_mi_example
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
