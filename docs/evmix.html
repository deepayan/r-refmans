<!DOCTYPE html><html lang="en"><head><title>Help for package evmix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {evmix}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#evmix-package'><p>Extreme Value Mixture Modelling, Threshold Estimation and Boundary Corrected Kernel Density Estimation</p></a></li>
<li><a href='#bckden'><p>Boundary Corrected Kernel Density Estimation Using a Variety of Approaches</p></a></li>
<li><a href='#bckdengpd'><p>Boundary Corrected Kernel Density Estimate and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#bckdengpdcon'><p>Boundary Corrected Kernel Density Estimate and GPD Tail Extreme Value Mixture Model</p>
With Single Continuity Constraint</a></li>
<li><a href='#betagpd'><p>Beta Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#betagpdcon'><p>Beta Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#checking'><p>Internal functions for checking function input arguments</p></a></li>
<li><a href='#dwm'><p>Dynamically Weighted Mixture Model</p></a></li>
<li><a href='#evmix.diag'><p>Diagnostic Plots for Extreme Value Mixture Models</p></a></li>
<li><a href='#fbckden'><p>Cross-validation MLE Fitting of Boundary Corrected Kernel Density Estimation</p>
Using a Variety of Approaches</a></li>
<li><a href='#fbckdengpd'><p>MLE Fitting of Boundary Corrected Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fbckdengpdcon'><p>MLE Fitting of Boundary Corrected Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</p>
with Single Continuity Constraint</a></li>
<li><a href='#fbetagpd'><p>MLE Fitting of beta Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fbetagpdcon'><p>MLE Fitting of beta Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#fdwm'><p>MLE Fitting of Dynamically Weighted Mixture Model</p></a></li>
<li><a href='#fgammagpd'><p>MLE Fitting of Gamma Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fgammagpdcon'><p>MLE Fitting of Gamma Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#fgkg'><p>MLE Fitting of Kernel Density Estimate for Bulk and GPD for Both Tails</p>
Extreme Value Mixture Model</a></li>
<li><a href='#fgkgcon'><p>MLE Fitting of Kernel Density Estimate for Bulk and GPD for Both Tails with</p>
Single Continuity Constraint at Both Thresholds Extreme Value Mixture Model</a></li>
<li><a href='#fgng'><p>MLE Fitting of Normal Bulk and GPD for Both Tails Extreme Value Mixture Model</p></a></li>
<li><a href='#fgngcon'><p>MLE Fitting of Normal Bulk and GPD for Both Tails with</p>
Single Continuity Constraint at Both Thresholds Extreme Value Mixture Model</a></li>
<li><a href='#fgpd'><p>MLE Fitting of Generalised Pareto Distribution (GPD)</p></a></li>
<li><a href='#fhpd'><p>MLE Fitting of Hybrid Pareto Extreme Value Mixture Model</p></a></li>
<li><a href='#fhpdcon'><p>MLE Fitting of Hybrid Pareto Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#fitmgng'><p>MLE Fitting of Normal Bulk and GPD for Both Tails Interval Transition Mixture Model</p></a></li>
<li><a href='#fitmnormgpd'><p>MLE Fitting of Normal Bulk and GPD Tail Interval Transition Mixture Model</p></a></li>
<li><a href='#fitmweibullgpd'><p>MLE Fitting of Weibull Bulk and GPD Tail Interval Transition Mixture Model</p></a></li>
<li><a href='#fkden'><p>Cross-validation MLE Fitting of Kernel Density Estimator, With Variety of Kernels</p></a></li>
<li><a href='#fkdengpd'><p>MLE Fitting of Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fkdengpdcon'><p>MLE Fitting of Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</p>
with Single Continuity Constraint</a></li>
<li><a href='#flognormgpd'><p>MLE Fitting of log-normal Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#flognormgpdcon'><p>MLE Fitting of log-normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#fmgamma'><p>MLE Fitting of Mixture of Gammas Using EM Algorithm</p></a></li>
<li><a href='#fmgammagpd'><p>MLE Fitting of Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model</p>
using the EM algorithm.</a></li>
<li><a href='#fmgammagpdcon'><p>MLE Fitting of Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model</p>
with Single Continuity Constraint using the EM algorithm.</a></li>
<li><a href='#fnormgpd'><p>MLE Fitting of Normal Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fnormgpdcon'><p>MLE Fitting of Normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#fpsden'><p>MLE Fitting of P-splines Density Estimator</p></a></li>
<li><a href='#fpsdengpd'><p>MLE Fitting of P-splines Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fweibullgpd'><p>MLE Fitting of Weibull Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#fweibullgpdcon'><p>MLE Fitting of Weibull Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#gammagpd'><p>Gamma Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#gammagpdcon'><p>Gamma Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#gkg'><p>Kernel Density Estimate and GPD Both Upper and Lower Tails Extreme Value Mixture Model</p></a></li>
<li><a href='#gkgcon'><p>Kernel Density Estimate and GPD Both Upper and Lower Tails Extreme Value Mixture Model</p>
With Single Continuity Constraint at Both</a></li>
<li><a href='#gng'><p>Normal Bulk with GPD Upper and Lower Tails Extreme Value Mixture Model</p></a></li>
<li><a href='#gngcon'><p>Normal Bulk with GPD Upper and Lower Tails Extreme Value Mixture Model</p>
with Single Continuity Constraint at Thresholds</a></li>
<li><a href='#gpd'><p>Generalised Pareto Distribution (GPD)</p></a></li>
<li><a href='#hillplot'><p>Hill Plot</p></a></li>
<li><a href='#hpd'><p>Hybrid Pareto Extreme Value Mixture Model</p></a></li>
<li><a href='#hpdcon'><p>Hybrid Pareto Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#internal'><p>Internal Functions</p></a></li>
<li><a href='#itmgng'><p>Normal Bulk with GPD Upper and Lower Tails Interval Transition Mixture Model</p></a></li>
<li><a href='#itmnormgpd'><p>Normal Bulk and GPD Tail Interval Transition Mixture Model</p></a></li>
<li><a href='#itmweibullgpd'><p>Weibull Bulk and GPD Tail Interval Transition Mixture Model</p></a></li>
<li><a href='#kden'><p>Kernel Density Estimation, With Variety of Kernels</p></a></li>
<li><a href='#kdengpd'><p>Kernel Density Estimate and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#kdengpdcon'><p>Kernel Density Estimate and GPD Tail Extreme Value Mixture Model With</p>
Single Continuity Constraint</a></li>
<li><a href='#kernels'><p>Kernel functions</p></a></li>
<li><a href='#kfun'><p>Various subsidiary kernel function, conversion of bandwidths and evaluating certain</p>
kernel integrals.</a></li>
<li><a href='#lognormgpd'><p>Log-Normal Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#lognormgpdcon'><p>Log-Normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#mgamma'><p>Mixture of Gammas Distribution</p></a></li>
<li><a href='#mgammagpd'><p>Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#mgammagpdcon'><p>Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#mrlplot'><p>Mean Residual Life Plot</p></a></li>
<li><a href='#normgpd'><p>Normal Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#normgpdcon'><p>Normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
<li><a href='#pickandsplot'><p>Pickands Plot</p></a></li>
<li><a href='#psden'><p>P-Splines probability density function</p></a></li>
<li><a href='#psdengpd'><p>P-Splines Density Estimate and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#tcplot'><p>Parameter Threshold Stability Plots</p></a></li>
<li><a href='#weibullgpd'><p>Weibull Bulk and GPD Tail Extreme Value Mixture Model</p></a></li>
<li><a href='#weibullgpdcon'><p>Weibull Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Extreme Value Mixture Modelling, Threshold Estimation and
Boundary Corrected Kernel Density Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>2.12</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-09-02</td>
</tr>
<tr>
<td>Author:</td>
<td>Carl Scarrott, Yang Hu and Alfadino Akbar, University of Canterbury</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carl Scarrott &lt;carl.scarrott@canterbury.ac.nz&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>stats, graphics, MASS, splines, gsl, SparseM, grDevices</td>
</tr>
<tr>
<td>Description:</td>
<td>The usual distribution functions, maximum likelihood inference and
    model diagnostics for univariate stationary extreme value mixture models
    are provided. Kernel density estimation including various boundary
    corrected kernel density estimation methods and a wide choice of kernels,
    with cross-validation likelihood based bandwidth estimator.
    Reasonable consistency with the base functions in the 'evd' package is
    provided, so that users can safely interchange most code.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-03 00:38:08 UTC; csc51</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-03 13:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='evmix-package'>Extreme Value Mixture Modelling, Threshold Estimation and Boundary Corrected Kernel Density Estimation</h2><span id='topic+evmix-package'></span><span id='topic+evmix'></span>

<h3>Description</h3>

<p>Functions for Extreme Value Mixture Modelling, Threshold Estimation and
Boundary Corrected Kernel Density Estimation
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> evmix</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.12</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2019-09-02</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The usual distribution functions, maximum likelihood inference and model
diagnostics for univariate stationary extreme value mixture models are
provided.
</p>
<p>Kernel density estimation including various boundary corrected kernel density
estimation methods and a wide choice of kernels, with cross-validation
likelihood based bandwidth estimators are included.
</p>
<p>Reasonable consistency with the base functions in the <code>evd</code> package is
provided, so that users can safely interchange most code.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott, Yang Hu and Alfadino Akbar, University of Canterbury, New Zealand <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>
<p>MacDonald, A. (2012). Extreme value mixture modelling with medical and
industrial applications. PhD thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf">http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="evd.html#topic+gpd">evd</a></code>, <code><a href="ismev.html#topic+ismev">ismev</a></code> and condmixt
</p>

<hr>
<h2 id='bckden'>Boundary Corrected Kernel Density Estimation Using a Variety of Approaches</h2><span id='topic+bckden'></span><span id='topic+dbckden'></span><span id='topic+pbckden'></span><span id='topic+qbckden'></span><span id='topic+rbckden'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for boundary corrected kernel density estimators
using a variety of approaches (and different kernels) with a constant
bandwidth <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbckden(x, kerncentres, lambda = NULL, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, log = FALSE)

pbckden(q, kerncentres, lambda = NULL, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, lower.tail = TRUE)

qbckden(p, kerncentres, lambda = NULL, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, lower.tail = TRUE)

rbckden(n = 1, kerncentres, lambda = NULL, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bckden_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="bckden_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="bckden_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckden_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckden_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="bckden_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="bckden_+3A_proper">proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td></tr>
<tr><td><code id="bckden_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="bckden_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckden_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckden_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="bckden_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="bckden_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="bckden_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="bckden_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Boundary corrected kernel density estimation (BCKDE) with improved
bias properties near the boundary compared to standard KDE available in 
<code><a href="#topic+kden">kden</a></code> functions. The user chooses from a wide range
of boundary correction methods designed to cope with a lower bound at zero
and potentially also both upper and lower bounds.
</p>
<p>Some boundary correction methods require a secondary correction for
negative density estimates of which two methods are implemented. Further, some
methods don't necessarily give a density which integrates to one, so an option
is provided to renormalise to be proper.
</p>
<p>It assumes there is a lower bound at zero, so prior transformation of data is
required for a alternative lower bound (possibly including negation to allow
for an upper bound).
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>Certain boundary correction methods use the standard kernels which are defined
in the <code><a href="#topic+kernels">kernels</a></code> help
documentation with the <code>"gaussian"</code> as the default choice.
</p>
<p>The quantile function is rather complicated as there is no closed form solution,
so is obtained by numerical approximation of the inverse cumulative distribution function
<code class="reqn">P(X \le q) = p</code> to find <code class="reqn">q</code>. The quantile function 
<code><a href="#topic+bckden">qbckden</a></code> evaluates the KDE cumulative distribution
function over the range from <code>c(0, max(kerncentre) + lambda)</code>,
or <code>c(0, max(kerncentre) + 5*lambda)</code> for normal kernel. Outside of this
range the quantiles are set to <code>0</code> for lower tail and <code>Inf</code>
(or <code>xmax</code> where appropriate) for upper tail. A sequence of values
of length fifty times the number of kernels (upto a maximum of 1000) is first
calculated. Spline based interpolation using <code><a href="stats.html#topic+splinefun">splinefun</a></code>,
with default <code>monoH.FC</code> method, is then used to approximate the quantile
function. This is a similar approach to that taken
by Matt Wand in the <code><a href="ks.html#topic+kde">qkde</a></code> in the <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all these
estimators, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified and you should
consider using <code><a href="#topic+fbckden">fbckden</a></code> function for cross-validation
MLE for bandwidth.
</p>
<p>Random number generation is slow as inversion sampling using the (numerically evaluated)
quantile function is implemented. Users may want to consider alternative approaches instead,
like rejection sampling.
</p>


<h3>Value</h3>

<p><code><a href="#topic+bckden">dbckden</a></code> gives the density, 
<code><a href="#topic+bckden">pbckden</a></code> gives the cumulative distribution function,
<code><a href="#topic+bckden">qbckden</a></code> gives the quantile function and 
<code><a href="#topic+bckden">rbckden</a></code> gives a random sample.
</p>


<h3>Boundary Correction Methods</h3>

<p>Renormalisation to a proper density is assumed by default <code>proper=TRUE</code>.
This correction is needed for <code>bcmethod="renorm"</code>, <code>"simple"</code>,
<code>"beta1"</code>, <code>"beta2"</code>, <code>"gamma1"</code> and <code>"gamma2"</code> which
all require numerical integration. Renormalisation will not be carried out
for other methods, even when <code>proper=TRUE</code>.
</p>
<p>Non-negativity correction is only relevant for the <code>bcmethod="simple"</code> approach.
The Jones and Foster (1996) method is applied <code>nn="jf96"</code> by default. This method
can occassionally give an extra boundary bias for certain populations (e.g. Gamma(2, 1)),
see paper for details. Non-negative values can simply be zeroed (<code>nn="zero"</code>).
Renormalisation should always be applied after non-negativity correction. Non-negativity
correction will not be carried out for other methods, even when requested by user.
</p>
<p>The non-negative correction is applied before renormalisation, when both requested. 
</p>
<p>The boundary correction methods implemented are listed below. The first set can use
any type of kernel (see <code><a href="#topic+kernels">kernels</a></code> help
documentation):
</p>
<p><code>bcmethod="simple"</code> is the default and applies the simple boundary correction method
in equation (3.4) of Jones (1993) and is equivalent to the kernel weighted local linear
fitting at the boundary. Renormalisation and non-negativity correction may be required.
</p>
<p><code>bcmethod="cutnorm"</code> applies cut and normalisation method of
Gasser and Muller (1979), where the kernels themselves are individually truncated at
the boundary and renormalised to unity.
</p>
<p><code>bcmethod="renorm"</code> applies first order correction method discussed in
Diggle (1985), where the kernel density estimate is locally renormalised near boundary.
Renormalisation may be required.
</p>
<p><code>bcmethod="reflect"</code> applies reflection method of Boneva, Kendall and Stefanov
(1971) which is equivalent to the dataset being supplemented by the same dataset negated. 
This method implicitly assumes f'(0)=0, so can cause extra artefacts at the boundary. 
</p>
<p><code>bcmethod="logtrans"</code> applies KDE on the log-scale and then back-transforms (with
explicit normalisation) following Marron and Ruppert (1992). This is the approach
implemented in the <code><a href="ks.html#topic+kde">ks</a></code> package. As the KDE is applied on
the log scale, the effective bandwidth on the original scale is non-constant. The
<code>offset</code> option is only used for this method and is commonly used to offset
zero kernel centres in log transform to prevent <code>log(0)</code>.
</p>
<p>All the following boundary correction methods do not use kernels in their
usual sense, so ignore the <code>kernel</code> input:
</p>
<p><code>bcmethod="beta1"</code> and <code>"beta2"</code> uses the beta and modified beta kernels
of Chen (1999) respectively. The <code>xmax</code> rescales the beta kernels to be
defined on the support [0, xmax] rather than unscaled [0, 1]. Renormalisation
will be required.
</p>
<p><code>bcmethod="gamma1"</code> and <code>"gamma2"</code> uses the gamma and modified gamma kernels
of Chen (2000) respectively. Renormalisation will be required.
</p>
<p><code>bcmethod="copula"</code> uses the bivariate normal copula based kernesl of 
Jones and Henderson (2007). As with the <code>bcmethod="beta1"</code>  and <code>"beta2"</code>
methods the <code>xmax</code> rescales the copula kernels to be defined on the support [0, xmax]
rather than [0, 1]. In this case the bandwidth is defined as <code class="reqn">lambda=1-\rho^2</code>,
so the bandwidth is limited to <code class="reqn">(0, 1)</code>.
</p>


<h3>Warning</h3>

<p>The <code>"simple"</code>, <code>"renorm"</code>, <code>"beta1"</code>, <code>"beta2"</code>, <code>"gamma1"</code> 
and <code>"gamma2"</code> boundary correction methods may require renormalisation using
numerical integration which can be very slow. In particular, the numerical integration
is extremely slow for the <code>kernel="uniform"</code>, due to the adaptive quadrature in
the <code><a href="stats.html#topic+integrate">integrate</a></code> function
being particularly slow for functions with step-like behaviour.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+bckden">bckden</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>lambda</code>, <code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>.
The default sample size for <code><a href="#topic+bckden">rbckden</a></code> is 1.
</p>
<p>The <code>xmax</code> option is only relevant for the beta and copula methods, so a
warning is produced if this is not <code>NULL</code> for in other methods.
The <code>offset</code> option is only relevant for the <code>"logtrans"</code> method, so a
warning is produced if this is not <code>NULL</code> for in other methods.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Chen, S.X. (1999). Beta kernel estimators for density functions. Computational Statistics
and Data Analysis 31, 1310-45.
</p>
<p>Gasser, T. and Muller, H. (1979). Kernel estimation of regression functions. In &quot;Lecture Notes
in Mathematics 757, edited by Gasser and Rosenblatt, Springer.
</p>
<p>Chen, S.X. (2000). Probability density function estimation using gamma kernels.
Annals of the Institute of Statisical Mathematics 52(3), 471-480.
</p>
<p>Boneva, L.I., Kendall, D.G. and Stefanov, I. (1971). Spline transformations: Three new
diagnostic aids for the statistical data analyst (with discussion). Journal of the Royal
Statistical Society B, 33, 1-70.
</p>
<p>Diggle, P.J. (1985). A kernel method for smoothing point process data. Applied Statistics
34, 138-147.
</p>
<p>Marron, J.S. and Ruppert, D. (1994) Transformations to reduce boundary bias in kernel
density estimation, Journal of the Royal Statistical Society. Series B 56(4), 653-671.
</p>
<p>Jones, M.C. and Henderson, D.A. (2007). Kernel-type density estimation on the unit
interval. Biometrika 94(4), 977-984.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kden: <code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fgkg">fgkg</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fbckden: <code><a href="#topic+fbckden">fbckden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

n=100
x = rgamma(n, shape = 1, scale = 2)
xx = seq(-0.5, 12, 0.01)
plot(xx, dgamma(xx, shape = 1, scale = 2), type = "l")
rug(x)
lines(xx, dbckden(xx, x, lambda = 1), lwd = 2, col = "red")
lines(density(x), lty = 2, lwd = 2, col = "green")
legend("topright", c("True Density", "Simple boundary correction",
"KDE using density function", "Boundary Corrected Kernels"),
lty = c(1, 1, 2, 1), lwd = c(1, 2, 2, 1), col = c("black", "red", "green", "blue"))

n=100
x = rbeta(n, shape1 = 3, shape2 = 2)*5
xx = seq(-0.5, 5.5, 0.01)
plot(xx, dbeta(xx/5, shape1 = 3, shape2 = 2)/5, type = "l", ylim = c(0, 0.8))
rug(x)
lines(xx, dbckden(xx, x, lambda = 0.1, bcmethod = "beta2", proper = TRUE, xmax = 5),
  lwd = 2, col = "red")
lines(density(x), lty = 2, lwd = 2, col = "green")
legend("topright", c("True Density", "Modified Beta KDE Using evmix",
  "KDE using density function"),
lty = c(1, 1, 2), lwd = c(1, 2, 2), col = c("black", "red", "green"))

# Demonstrate renormalisation (usually small difference)
n=1000
x = rgamma(n, shape = 1, scale = 2)
xx = seq(-0.5, 15, 0.01)
plot(xx, dgamma(xx, shape = 1, scale = 2), type = "l")
rug(x)
lines(xx, dbckden(xx, x, lambda = 0.5, bcmethod = "simple", proper = TRUE),
  lwd = 2, col = "purple")
lines(xx, dbckden(xx, x, lambda = 0.5, bcmethod = "simple", proper = FALSE),
  lwd = 2, col = "red", lty = 2)
legend("topright", c("True Density", "Simple BC with renomalisation", 
"Simple BC without renomalisation"),
lty = 1, lwd = c(1, 2, 2), col = c("black", "purple", "red"))

## End(Not run)

</code></pre>

<hr>
<h2 id='bckdengpd'>Boundary Corrected Kernel Density Estimate and GPD Tail Extreme Value Mixture Model</h2><span id='topic+bckdengpd'></span><span id='topic+dbckdengpd'></span><span id='topic+pbckdengpd'></span><span id='topic+qbckdengpd'></span><span id='topic+rbckdengpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with 
boundary corrected kernel density estimate for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the bandwidth <code>lambda</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbckdengpd(x, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, log = FALSE)

pbckdengpd(q, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, lower.tail = TRUE)

qbckdengpd(p, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, lower.tail = TRUE)

rbckdengpd(n = 1, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bckdengpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_proper">proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="bckdengpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining boundary corrected kernel density (BCKDE)
estimate for the bulk below the threshold and GPD for upper tail. The user chooses
from a wide range of boundary correction methods designed to cope with a lower bound
at zero and potentially also both upper and lower bounds.
</p>
<p>Some boundary correction methods require a secondary correction for
negative density estimates of which two methods are implemented. Further, some
methods don't necessarily give a density which integrates to one, so an option
is provided to renormalise to be proper.
</p>
<p>It assumes there is a lower bound at zero, so prior transformation of data is
required for a alternative lower bound (possibly including negation to allow
for an upper bound).
</p>
<p>The user can pre-specify <code>phiu</code> permitting a parameterised value for the
tail fraction <code class="reqn">\phi_u</code>. Alternatively, when <code>phiu=TRUE</code> the tail fraction
is estimated as the tail fraction from the BCKDE bulk model.
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the BCKDE (<code>phiu=TRUE</code>), upto the threshold
<code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the BCKDE and conditional GPD
cumulative distribution functions respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all the
BCKDE, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified and you should
consider using <code><a href="#topic+fbckdengpd">fbckdengpd</a></code> of 
<code><a href="#topic+fbckden">fbckden</a></code> function for cross-validation
MLE for bandwidth.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="#topic+bckden">dbckden</a></code> for details of BCKDE bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+bckdengpd">dbckdengpd</a></code> gives the density, 
<code><a href="#topic+bckdengpd">pbckdengpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+bckdengpd">qbckdengpd</a></code> gives the quantile function and 
<code><a href="#topic+bckdengpd">rbckdengpd</a></code> gives a random sample.
</p>


<h3>Boundary Correction Methods</h3>

<p>See <code><a href="#topic+bckden">dbckden</a></code> for details of BCKDE methods.
</p>


<h3>Warning</h3>

<p>The <code>"simple"</code>, <code>"renorm"</code>, <code>"beta1"</code>, <code>"beta2"</code>, <code>"gamma1"</code> 
and <code>"gamma2"</code> boundary correction methods may require renormalisation using
numerical integration which can be very slow. In particular, the numerical integration
is extremely slow for the <code>kernel="uniform"</code>, due to the adaptive quadrature in
the <code><a href="stats.html#topic+integrate">integrate</a></code> function
being particularly slow for functions with step-like behaviour.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+bckdengpd">bckdengpd</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The <code>kerncentres</code> can also be a scalar or vector.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+bckdengpd">rbckdengpd</a></code> is 1.
</p>
<p>The <code>xmax</code> option is only relevant for the beta and copula methods, so a
warning is produced if this is not <code>NULL</code> for in other methods.
The <code>offset</code> option is only relevant for the <code>"logtrans"</code> method, so a
warning is produced if this is not <code>NULL</code> for in other methods.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters or kernel centres.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>, <code><a href="#topic+kernels">kernels</a></code>, 
<code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kdengpd: <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fgkg">fgkg</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fbckdengpd: <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

kerncentres=rgamma(500, shape = 1, scale = 2)
xx = seq(-0.1, 10, 0.01)
hist(kerncentres, breaks = 100, freq = FALSE)
lines(xx, dbckdengpd(xx, kerncentres, lambda = 0.5, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)")
abline(v = quantile(kerncentres, 0.9))

plot(xx, pbckdengpd(xx, kerncentres, lambda = 0.5, bcmethod = "reflect"),
xlab = "x", ylab = "F(x)", type = "l")
lines(xx, pbckdengpd(xx, kerncentres, lambda = 0.5, xi = 0.3, bcmethod = "reflect"),
xlab = "x", ylab = "F(x)", col = "red")
lines(xx, pbckdengpd(xx, kerncentres, lambda = 0.5, xi = -0.3, bcmethod = "reflect"),
xlab = "x", ylab = "F(x)", col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
      col=c("black", "red", "blue"), lty = 1, cex = 0.5)

kerncentres = rweibull(1000, 2, 1)
x = rbckdengpd(1000, kerncentres, lambda = 0.1, phiu = TRUE, bcmethod = "reflect")
xx = seq(0.01, 3.5, 0.01)
hist(x, breaks = 100, freq = FALSE)         
lines(xx, dbckdengpd(xx, kerncentres, lambda = 0.1, phiu = TRUE, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)")

lines(xx, dbckdengpd(xx, kerncentres, lambda = 0.1, xi=-0.2, phiu = 0.1, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)", col = "red")
lines(xx, dbckdengpd(xx, kerncentres, lambda = 0.1, xi=0.2, phiu = 0.1, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)", col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
      col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='bckdengpdcon'>Boundary Corrected Kernel Density Estimate and GPD Tail Extreme Value Mixture Model
With Single Continuity Constraint</h2><span id='topic+bckdengpdcon'></span><span id='topic+dbckdengpdcon'></span><span id='topic+pbckdengpdcon'></span><span id='topic+qbckdengpdcon'></span><span id='topic+rbckdengpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with 
boundary corrected kernel density estimate for bulk
distribution upto the threshold and conditional GPD above threshold with continuity at
threshold. The parameters are the bandwidth <code>lambda</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbckdengpdcon(x, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  log = FALSE)

pbckdengpdcon(q, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  lower.tail = TRUE)

qbckdengpdcon(p, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  lower.tail = TRUE)

rbckdengpdcon(n = 1, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bckdengpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_proper">proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="bckdengpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining boundary corrected kernel density (BCKDE)
estimate for the bulk below the threshold and GPD for upper tail with continuity at
threshold. The user chooses from a wide range of boundary correction methods
designed to cope with a lower bound at zero and potentially also both upper and
lower bounds.
</p>
<p>Some boundary correction methods require a secondary correction for
negative density estimates of which two methods are implemented. Further, some
methods don't necessarily give a density which integrates to one, so an option
is provided to renormalise to be proper.
</p>
<p>It assumes there is a lower bound at zero, so prior transformation of data is
required for a alternative lower bound (possibly including negation to allow
for an upper bound).
</p>
<p>The user can pre-specify <code>phiu</code> permitting a parameterised value for the
tail fraction <code class="reqn">\phi_u</code>. Alternatively, when <code>phiu=TRUE</code> the tail fraction
is estimated as the tail fraction from the BCKDE bulk model.
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the BCKDE (<code>phiu=TRUE</code>), upto the threshold
<code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the BCKDE and conditional GPD
cumulative distribution functions respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the BCKDE and conditional GPD
density functions respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all the
BCKDE, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified and you should
consider using <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code> of 
<code><a href="#topic+fbckden">fbckden</a></code> function for cross-validation
MLE for bandwidth.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="#topic+bckden">dbckden</a></code> for details of BCKDE bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+bckdengpdcon">dbckdengpdcon</a></code> gives the density, 
<code><a href="#topic+bckdengpdcon">pbckdengpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+bckdengpdcon">qbckdengpdcon</a></code> gives the quantile function and 
<code><a href="#topic+bckdengpdcon">rbckdengpdcon</a></code> gives a random sample.
</p>


<h3>Boundary Correction Methods</h3>

<p>See <code><a href="#topic+bckden">dbckden</a></code> for details of BCKDE methods.
</p>


<h3>Warning</h3>

<p>The <code>"simple"</code>, <code>"renorm"</code>, <code>"beta1"</code>, <code>"beta2"</code>, <code>"gamma1"</code> 
and <code>"gamma2"</code> boundary correction methods may require renormalisation using
numerical integration which can be very slow. In particular, the numerical integration
is extremely slow for the <code>kernel="uniform"</code>, due to the adaptive quadrature in
the <code><a href="stats.html#topic+integrate">integrate</a></code> function
being particularly slow for functions with step-like behaviour.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The <code>kerncentres</code> can also be a scalar or vector.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+bckdengpdcon">rbckdengpdcon</a></code> is 1.
</p>
<p>The <code>xmax</code> option is only relevant for the beta and copula methods, so a
warning is produced if this is not <code>NULL</code> for in other methods.
The <code>offset</code> option is only relevant for the <code>"logtrans"</code> method, so a
warning is produced if this is not <code>NULL</code> for in other methods.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters or kernel centres.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>, <code><a href="#topic+kernels">kernels</a></code>, 
<code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kdengpdcon: <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fbckdengpdcon: <code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

kerncentres=rgamma(500, shape = 1, scale = 2)
xx = seq(-0.1, 10, 0.01)
hist(kerncentres, breaks = 100, freq = FALSE)
lines(xx, dbckdengpdcon(xx, kerncentres, lambda = 0.5, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)")
abline(v = quantile(kerncentres, 0.9))

plot(xx, pbckdengpdcon(xx, kerncentres, lambda = 0.5, bcmethod = "reflect"),
xlab = "x", ylab = "F(x)", type = "l")
lines(xx, pbckdengpdcon(xx, kerncentres, lambda = 0.5, xi = 0.3, bcmethod = "reflect"),
xlab = "x", ylab = "F(x)", col = "red")
lines(xx, pbckdengpdcon(xx, kerncentres, lambda = 0.5, xi = -0.3, bcmethod = "reflect"),
xlab = "x", ylab = "F(x)", col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
      col=c("black", "red", "blue"), lty = 1, cex = 0.5)

kerncentres = rweibull(1000, 2, 1)
x = rbckdengpdcon(1000, kerncentres, lambda = 0.1, phiu = TRUE, bcmethod = "reflect")
xx = seq(0.01, 3.5, 0.01)
hist(x, breaks = 100, freq = FALSE)         
lines(xx, dbckdengpdcon(xx, kerncentres, lambda = 0.1, phiu = TRUE, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)")

lines(xx, dbckdengpdcon(xx, kerncentres, lambda = 0.1, xi=-0.2, phiu = 0.1, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)", col = "red")
lines(xx, dbckdengpdcon(xx, kerncentres, lambda = 0.1, xi=0.2, phiu = 0.1, bcmethod = "reflect"),
xlab = "x", ylab = "f(x)", col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
      col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='betagpd'>Beta Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+betagpd'></span><span id='topic+dbetagpd'></span><span id='topic+pbetagpd'></span><span id='topic+qbetagpd'></span><span id='topic+rbetagpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with beta for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the beta shape 1 <code>bshape1</code> and shape 2 <code>bshape2</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbetagpd(x, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), sigmau = sqrt(bshape1 * bshape2/(bshape1 +
  bshape2)^2/(bshape1 + bshape2 + 1)), xi = 0, phiu = TRUE,
  log = FALSE)

pbetagpd(q, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), sigmau = sqrt(bshape1 * bshape2/(bshape1 +
  bshape2)^2/(bshape1 + bshape2 + 1)), xi = 0, phiu = TRUE,
  lower.tail = TRUE)

qbetagpd(p, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), sigmau = sqrt(bshape1 * bshape2/(bshape1 +
  bshape2)^2/(bshape1 + bshape2 + 1)), xi = 0, phiu = TRUE,
  lower.tail = TRUE)

rbetagpd(n = 1, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), sigmau = sqrt(bshape1 * bshape2/(bshape1 +
  bshape2)^2/(bshape1 + bshape2 + 1)), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betagpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="betagpd_+3A_bshape1">bshape1</code></td>
<td>
<p>beta shape 1 (positive)</p>
</td></tr>
<tr><td><code id="betagpd_+3A_bshape2">bshape2</code></td>
<td>
<p>beta shape 2 (positive)</p>
</td></tr>
<tr><td><code id="betagpd_+3A_u">u</code></td>
<td>
<p>threshold over <code class="reqn">(0, 1)</code></p>
</td></tr>
<tr><td><code id="betagpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="betagpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="betagpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="betagpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="betagpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="betagpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="betagpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="betagpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining beta distribution for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
beta bulk model.
</p>
<p>The usual beta distribution is defined over <code class="reqn">[0, 1]</code>, but this mixture is generally
not limited in the upper tail <code class="reqn">[0,\infty]</code>, except for the usual upper tail 
limits for the GPD when <code>xi&lt;0</code> discussed in <code><a href="#topic+gpd">gpd</a></code>. 
Therefore, the threshold is limited to <code class="reqn">(0, 1)</code>.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the beta bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 \le x \le u &lt; 1</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the beta and conditional GPD
cumulative distribution functions (i.e. <code>pbeta(x, bshape1, bshape2)</code> and
<code>pgpd(x, u, sigmau, xi)</code>).
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 \le x \le u &lt; 1</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Beta">dbeta</a></code> for details of beta bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+betagpd">dbetagpd</a></code> gives the density, 
<code><a href="#topic+betagpd">pbetagpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+betagpd">qbetagpd</a></code> gives the quantile function and 
<code><a href="#topic+betagpd">rbetagpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+betagpd">rbetagpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+betagpd">rbetagpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Beta_distribution">http://en.wikipedia.org/wiki/Beta_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>MacDonald, A. (2012). Extreme value mixture modelling with medical and
industrial applications. PhD thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf">http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Beta">dbeta</a></code>
</p>
<p>Other betagpd: <code><a href="#topic+betagpdcon">betagpdcon</a></code>,
<code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>, <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>
<p>Other betagpdcon: <code><a href="#topic+betagpdcon">betagpdcon</a></code>,
<code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>, <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>
<p>Other fbetagpd: <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rbetagpd(1000, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2)
xx = seq(-0.1, 2, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, dbetagpd(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2))

# three tail behaviours
plot(xx, pbetagpd(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2), type = "l")
lines(xx, pbetagpd(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2, xi = 0.3), col = "red")
lines(xx, pbetagpd(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rbetagpd(1000, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, dbetagpd(xx, bshape1 = 2, bshape2 = 0.6, u = 0.7, phiu = 0.5))

plot(xx, dbetagpd(xx, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5, xi=0), type = "l")
lines(xx, dbetagpd(xx, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5, xi=-0.2), col = "red")
lines(xx, dbetagpd(xx, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5, xi=0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='betagpdcon'>Beta Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+betagpdcon'></span><span id='topic+dbetagpdcon'></span><span id='topic+pbetagpdcon'></span><span id='topic+qbetagpdcon'></span><span id='topic+rbetagpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with beta for bulk
distribution upto the threshold and conditional GPD above threshold with continuity at threshold. The parameters
are the beta shape 1 <code>bshape1</code> and shape 2 <code>bshape2</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbetagpdcon(x, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), xi = 0, phiu = TRUE, log = FALSE)

pbetagpdcon(q, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), xi = 0, phiu = TRUE, lower.tail = TRUE)

qbetagpdcon(p, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), xi = 0, phiu = TRUE, lower.tail = TRUE)

rbetagpdcon(n = 1, bshape1 = 1, bshape2 = 1, u = qbeta(0.9,
  bshape1, bshape2), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betagpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_bshape1">bshape1</code></td>
<td>
<p>beta shape 1 (positive)</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_bshape2">bshape2</code></td>
<td>
<p>beta shape 2 (positive)</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_u">u</code></td>
<td>
<p>threshold over <code class="reqn">(0, 1)</code></p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="betagpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining beta distribution for the bulk
below the threshold and GPD for upper tail with continuity at threshold.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
beta bulk model.
</p>
<p>The usual beta distribution is defined over <code class="reqn">[0, 1]</code>, but this mixture is generally
not limited in the upper tail <code class="reqn">[0,\infty]</code>, except for the usual upper tail 
limits for the GPD when <code>xi&lt;0</code> discussed in <code><a href="#topic+gpd">gpd</a></code>. 
Therefore, the threshold is limited to <code class="reqn">(0, 1)</code>.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the beta bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 \le x \le u &lt; 1</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the beta and conditional GPD
cumulative distribution functions (i.e. <code>pbeta(x, bshape1, bshape2)</code> and
<code>pgpd(x, u, sigmau, xi)</code>).
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 \le x \le u &lt; 1</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the beta and conditional GPD
density functions (i.e. <code>dbeta(x, bshape1, bshape2)</code> and
<code>dgpd(x, u, sigmau, xi)</code>) respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Beta">dbeta</a></code> for details of beta bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+betagpdcon">dbetagpdcon</a></code> gives the density, 
<code><a href="#topic+betagpdcon">pbetagpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+betagpdcon">qbetagpdcon</a></code> gives the quantile function and 
<code><a href="#topic+betagpdcon">rbetagpdcon</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+betagpdcon">rbetagpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+betagpdcon">rbetagpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Beta_distribution">http://en.wikipedia.org/wiki/Beta_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>MacDonald, A. (2012). Extreme value mixture modelling with medical and
industrial applications. PhD thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf">http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Beta">dbeta</a></code>
</p>
<p>Other betagpd: <code><a href="#topic+betagpd">betagpd</a></code>,
<code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>, <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>
<p>Other betagpdcon: <code><a href="#topic+betagpd">betagpd</a></code>,
<code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>, <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>
<p>Other fbetagpdcon: <code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rbetagpdcon(1000, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2)
xx = seq(-0.1, 2, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, dbetagpdcon(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2))

# three tail behaviours
plot(xx, pbetagpdcon(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2), type = "l")
lines(xx, pbetagpdcon(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2, xi = 0.3), col = "red")
lines(xx, pbetagpdcon(xx, bshape1 = 1.5, bshape2 = 2, u = 0.7, phiu = 0.2, xi = -0.3), col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rbetagpdcon(1000, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, dbetagpdcon(xx, bshape1 = 2, bshape2 = 0.6, u = 0.7, phiu = 0.5))

plot(xx, dbetagpdcon(xx, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5, xi=0), type = "l")
lines(xx, dbetagpdcon(xx, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5, xi=-0.2), col = "red")
lines(xx, dbetagpdcon(xx, bshape1 = 2, bshape2 = 0.8, u = 0.7, phiu = 0.5, xi=0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='checking'>Internal functions for checking function input arguments</h2><span id='topic+checking'></span><span id='topic+check.quant'></span><span id='topic+check.prob'></span><span id='topic+check.n'></span><span id='topic+check.param'></span><span id='topic+check.posparam'></span><span id='topic+check.nparam'></span><span id='topic+check.logic'></span><span id='topic+check.text'></span><span id='topic+check.inputn'></span><span id='topic+check.phiu'></span><span id='topic+check.optim'></span><span id='topic+check.control'></span><span id='topic+check.bcmethod'></span><span id='topic+check.nn'></span><span id='topic+check.offset'></span><span id='topic+check.design.knots'></span>

<h3>Description</h3>

<p>Functions for checking the input arguments to functions, so that main functions
are more concise. They will stop when an inappropriate input is found.
</p>
<p>These function are visible and operable by the user. But they should be used with caution, as no
checks on the input validity are carried out.
</p>
<p>For likelihood functions you will often not want to stop on finding a non-positive values for
positive parameters, in such cases use <code><a href="#topic+checking">check.param</a></code> rather than 
<code><a href="#topic+checking">check.posparam</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.param(param, allowvec = FALSE, allownull = FALSE,
  allowmiss = FALSE, allowna = FALSE, allowinf = FALSE)

check.posparam(param, allowvec = FALSE, allownull = FALSE,
  allowmiss = FALSE, allowna = FALSE, allowinf = FALSE,
  allowzero = FALSE)

check.quant(x, allownull = FALSE, allowna = FALSE, allowinf = FALSE)

check.prob(prob, allownull = FALSE, allowna = FALSE)

check.n(n, allowzero = FALSE)

check.logic(logicarg, allowvec = FALSE, allowna = FALSE)

check.nparam(ns, nparam = 1, allownull = FALSE, allowmiss = FALSE)

check.inputn(inputn, allowscalar = FALSE, allowzero = FALSE)

check.text(textarg, allowvec = FALSE, allownull = FALSE)

check.phiu(phiu, allowvec = FALSE, allownull = FALSE,
  allowfalse = FALSE)

check.optim(method)

check.control(control)

check.bcmethod(bcmethod)

check.nn(nn)

check.offset(offset, bcmethod, allowzero = FALSE)

check.design.knots(beta, xrange, nseg, degree, design.knots)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checking_+3A_param">param</code></td>
<td>
<p>scalar or vector of parameters</p>
</td></tr>
<tr><td><code id="checking_+3A_allowvec">allowvec</code></td>
<td>
<p>logical, where TRUE permits vector</p>
</td></tr>
<tr><td><code id="checking_+3A_allownull">allownull</code></td>
<td>
<p>logical, where TRUE permits NULL values</p>
</td></tr>
<tr><td><code id="checking_+3A_allowmiss">allowmiss</code></td>
<td>
<p>logical, where TRUE permits missing input</p>
</td></tr>
<tr><td><code id="checking_+3A_allowna">allowna</code></td>
<td>
<p>logical, where TRUE permits NA and NaN values</p>
</td></tr>
<tr><td><code id="checking_+3A_allowinf">allowinf</code></td>
<td>
<p>logical, where TRUE permits +/-Inf values</p>
</td></tr>
<tr><td><code id="checking_+3A_allowzero">allowzero</code></td>
<td>
<p>logical, where TRUE permits zero values (positive vs non-negative)</p>
</td></tr>
<tr><td><code id="checking_+3A_x">x</code></td>
<td>
<p>scalar or vector of quantiles</p>
</td></tr>
<tr><td><code id="checking_+3A_prob">prob</code></td>
<td>
<p>scalar or vector of probability</p>
</td></tr>
<tr><td><code id="checking_+3A_n">n</code></td>
<td>
<p>scalar sample size</p>
</td></tr>
<tr><td><code id="checking_+3A_logicarg">logicarg</code></td>
<td>
<p>logical input argument</p>
</td></tr>
<tr><td><code id="checking_+3A_ns">ns</code></td>
<td>
<p>vector of lengths of parameter vectors</p>
</td></tr>
<tr><td><code id="checking_+3A_nparam">nparam</code></td>
<td>
<p>acceptable length of (non-scalar) vectors of parameter vectors</p>
</td></tr>
<tr><td><code id="checking_+3A_inputn">inputn</code></td>
<td>
<p>vector of input lengths</p>
</td></tr>
<tr><td><code id="checking_+3A_allowscalar">allowscalar</code></td>
<td>
<p>logical, where TRUE permits scalar (as opposed to vector) values</p>
</td></tr>
<tr><td><code id="checking_+3A_textarg">textarg</code></td>
<td>
<p>character input argument</p>
</td></tr>
<tr><td><code id="checking_+3A_phiu">phiu</code></td>
<td>
<p>scalar or vector of phiu (logical, NULL or 0-1 exclusive)</p>
</td></tr>
<tr><td><code id="checking_+3A_allowfalse">allowfalse</code></td>
<td>
<p>logical, where TRUE permits FALSE (and TRUE) values</p>
</td></tr>
<tr><td><code id="checking_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="checking_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="checking_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="checking_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="checking_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="checking_+3A_beta">beta</code></td>
<td>
<p>vector of B-spline coefficients (required)</p>
</td></tr>
<tr><td><code id="checking_+3A_xrange">xrange</code></td>
<td>
<p>vector of minimum and maximum of B-spline (support of density)</p>
</td></tr>
<tr><td><code id="checking_+3A_nseg">nseg</code></td>
<td>
<p>number of segments between knots</p>
</td></tr>
<tr><td><code id="checking_+3A_degree">degree</code></td>
<td>
<p>degree of B-splines (0 is constant, 1 is linear, etc.)</p>
</td></tr>
<tr><td><code id="checking_+3A_design.knots">design.knots</code></td>
<td>
<p>spline knots for splineDesign function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The checking functions will stop on errors and return no value. The only exception is
the <code><a href="#topic+checking">check.inputn</a></code> which outputs the maximum vector length.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>

<hr>
<h2 id='dwm'>Dynamically Weighted Mixture Model</h2><span id='topic+dwm'></span><span id='topic+ddwm'></span><span id='topic+pdwm'></span><span id='topic+qdwm'></span><span id='topic+rdwm'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the dynamically weighted mixture model. The
parameters are the Weibull shape <code>wshape</code> and scale <code>wscale</code>,
Cauchy location <code>cmu</code>, Cauchy scale <code>ctau</code>, GPD scale
<code>sigmau</code>, shape <code>xi</code> and initial value for the quantile
<code>qinit</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddwm(x, wshape = 1, wscale = 1, cmu = 1, ctau = 1,
  sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), xi = 0, log = FALSE)

pdwm(q, wshape = 1, wscale = 1, cmu = 1, ctau = 1,
  sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), xi = 0, lower.tail = TRUE)

qdwm(p, wshape = 1, wscale = 1, cmu = 1, ctau = 1,
  sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), xi = 0, lower.tail = TRUE, qinit = NULL)

rdwm(n = 1, wshape = 1, wscale = 1, cmu = 1, ctau = 1,
  sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), xi = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dwm_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="dwm_+3A_wshape">wshape</code></td>
<td>
<p>Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="dwm_+3A_wscale">wscale</code></td>
<td>
<p>Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="dwm_+3A_cmu">cmu</code></td>
<td>
<p>Cauchy location</p>
</td></tr>
<tr><td><code id="dwm_+3A_ctau">ctau</code></td>
<td>
<p>Cauchy scale</p>
</td></tr>
<tr><td><code id="dwm_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="dwm_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="dwm_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="dwm_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="dwm_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="dwm_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="dwm_+3A_qinit">qinit</code></td>
<td>
<p>scalar or vector of initial values for the quantile estimate</p>
</td></tr>
<tr><td><code id="dwm_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dynamic weighted mixture model combines a Weibull for the bulk 
model with GPD for the tail model. However, unlike all the other mixture 
models the GPD is defined over the entire range of support rather than as a
conditional model above some threshold. A transition function is used to 
apply weights to transition between the bulk and GPD for the upper tail, 
thus providing the dynamically weighted mixture. They use a Cauchy 
cumulative distribution function for the transition function.
</p>
<p>The density function is then a dynamically weighted mixture given by: 
</p>
<p style="text-align: center;"><code class="reqn">f(x) = {[1 - p(x)] h(x) + p(x) g(x)}/r</code>
</p>
<p> where <code class="reqn">h(x)</code> and
<code class="reqn">g(x)</code> are the Weibull and unscaled GPD density functions respectively
(i.e. <code>dweibull(x, wshape, wscale)</code> and <code>dgpd(x, u, sigmau,
  xi)</code>). The Cauchy cumulative distribution function used to provide the
transition is defined by <code class="reqn">p(x)</code> (i.e. <code>pcauchy(x, cmu, ctau</code>. The
normalisation constant <code class="reqn">r</code> ensures a proper density.
</p>
<p>The quantile function is not available in closed form, so has to be solved 
numerically. The argument <code>qinit</code> is the initial quantile estimate
which is used for numerical optimisation and should be set to a reasonable
guess. When the <code>qinit</code> is <code>NULL</code>, the initial quantile value is
given by the midpoint between the Weibull and GPD quantiles. As with the
other inputs <code>qinit</code> is also vectorised, but <code>R</code> does not permit
vectors combining <code>NULL</code> and numeric entries.
</p>


<h3>Value</h3>

<p><code><a href="#topic+dwm">ddwm</a></code> gives the density, 
<code><a href="#topic+dwm">pdwm</a></code> gives the cumulative distribution function,
<code><a href="#topic+dwm">qdwm</a></code> gives the quantile function and 
<code><a href="#topic+dwm">rdwm</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+dwm">rdwm</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+dwm">rdwm</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cauchy_distribution">http://en.wikipedia.org/wiki/Cauchy_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Frigessi, A., Haug, O. and Rue, H. (2002). A dynamic mixture model for unsupervised tail
estimation without threshold selection. Extremes 5 (3), 219-235
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>, <code><a href="stats.html#topic+Cauchy">dcauchy</a></code>
and <code><a href="stats.html#topic+Weibull">dweibull</a></code>
</p>
<p>Other fdwm: <code><a href="#topic+fdwm">fdwm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

xx = seq(0.001, 5, 0.01)
f = ddwm(xx, wshape = 2, wscale = 1/gamma(1.5), cmu = 1, ctau = 1, sigmau = 1, xi = 0.5)
plot(xx, f, ylim = c(0, 1), xlim = c(0, 5), type = 'l', lwd = 2, 
  ylab = "density", main = "Plot example in Frigessi et al. (2002)")
lines(xx, dgpd(xx, sigmau = 1, xi = 0.5), col = "red", lty = 2, lwd = 2)
lines(xx, dweibull(xx, shape = 2, scale = 1/gamma(1.5)), col = "blue", lty = 2, lwd = 2)
legend('topright', c('DWM', 'Weibull', 'GPD'),
      col = c("black", "blue", "red"), lty = c(1, 2, 2), lwd = 2)

# three tail behaviours
plot(xx, pdwm(xx, xi = 0), type = "l")
lines(xx, pdwm(xx, xi = 0.3), col = "red")
lines(xx, pdwm(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)), col=c("black", "red", "blue"), lty = 1)

x = rdwm(10000, wshape = 2, wscale = 1/gamma(1.5), cmu = 1, ctau = 1, sigmau = 1, xi = 0.1)
xx = seq(0, 15, 0.01)
hist(x, freq = FALSE, breaks = 100)
lines(xx, ddwm(xx, wshape = 2, wscale = 1/gamma(1.5), cmu = 1, ctau = 1, sigmau = 1, xi = 0.1),
  lwd = 2, col = 'black')
  
plot(xx, pdwm(xx, wshape = 2, wscale = 1/gamma(1.5), cmu = 1, ctau = 1, sigmau = 1, xi = 0.1),
 xlim = c(0, 15), type = 'l', lwd = 2, 
  xlab = "x", ylab = "F(x)")
lines(xx, pgpd(xx, sigmau = 1, xi = 0.1), col = "red", lty = 2, lwd = 2)
lines(xx, pweibull(xx, shape = 2, scale = 1/gamma(1.5)), col = "blue", lty = 2, lwd = 2)
legend('bottomright', c('DWM', 'Weibull', 'GPD'),
      col = c("black", "blue", "red"), lty = c(1, 2, 2), lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='evmix.diag'>Diagnostic Plots for Extreme Value Mixture Models</h2><span id='topic+evmix.diag'></span><span id='topic+rlplot'></span><span id='topic+qplot'></span><span id='topic+pplot'></span><span id='topic+densplot'></span>

<h3>Description</h3>

<p>The classic four diagnostic plots for evaluating extreme value mixture models: 
1) return level plot, 2) Q-Q plot, 3) P-P plot and 4) density plot. Each plot is available
individually or as the usual 2x2 collection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evmix.diag(modelfit, upperfocus = TRUE, alpha = 0.05, N = 1000,
  legend = FALSE, ...)

rlplot(modelfit, upperfocus = TRUE, alpha = 0.05, N = 1000,
  legend = TRUE, rplim = NULL, rllim = NULL, ...)

qplot(modelfit, upperfocus = TRUE, alpha = 0.05, N = 1000,
  legend = TRUE, ...)

pplot(modelfit, upperfocus = TRUE, alpha = 0.05, N = 1000,
  legend = TRUE, ...)

densplot(modelfit, upperfocus = TRUE, legend = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evmix.diag_+3A_modelfit">modelfit</code></td>
<td>
<p>fitted extreme value mixture model object</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_upperfocus">upperfocus</code></td>
<td>
<p>logical, should plot focus on upper tail?</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_alpha">alpha</code></td>
<td>
<p>significance level over range (0, 1), or <code>NULL</code> for no CI</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_n">N</code></td>
<td>
<p>number of Monte Carlo simulation for CI (N&gt;=10)</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_legend">legend</code></td>
<td>
<p>logical, should legend be included</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the plotting functions</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_rplim">rplim</code></td>
<td>
<p>return period range</p>
</td></tr>
<tr><td><code id="evmix.diag_+3A_rllim">rllim</code></td>
<td>
<p>return level range</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model diagnostics are available for all the fitted extreme mixture models in the 
<code><a href="#topic+evmix-package">evmix</a></code> package. These <code>modelfit</code> is output by all the fitting 
functions, e.g. <code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+fnormgpd">fnormgpd</a></code>.
</p>
<p>Consistent with <code><a href="evd.html#topic+plot.uvevd">plot</a></code> function in the 
<code><a href="evd.html#topic+gpd">evd</a></code> library the <code><a href="stats.html#topic+ppoints">ppoints</a></code> to 
estimate the empirical cumulative probabilities. The default behaviour of this
function is to use </p>
<p style="text-align: center;"><code class="reqn">(i-0.5)/n</code>
</p>
<p> as the estimate for the <code class="reqn">i</code>th order statistic of
the given sample of size <code class="reqn">n</code>.
</p>
<p>The return level plot has the quantile (<code class="reqn">q</code> where <code class="reqn">P(X \ge q)=p</code> on
the <code class="reqn">y</code>-axis, for a particular survival probability <code class="reqn">p</code>. The return period
<code class="reqn">t=1/p</code> is shown on the <code class="reqn">x</code>-axis. The return level is given by:
</p>
<p style="text-align: center;"><code class="reqn">q = u + \sigma_u [(\phi_u t)^\xi - 1]/\xi</code>
</p>

<p>for <code class="reqn">\xi\ne 0</code>. But in the case of <code class="reqn">\xi = 0</code> this simplifies to 
</p>
<p style="text-align: center;"><code class="reqn">q = u + \sigma_u log(\phi_u t)</code>
</p>

<p>which is linear when plotted against the return period on a logarithmic scale. The special
case of exponential/Type I (<code class="reqn">\xi=0</code>) upper tail behaviour will be linear on
this scale. This is the same tranformation as in the GPD/POT diagnostic plot function
<code><a href="evd.html#topic+plot.uvevd">plot.uvevd</a></code> in the <code><a href="evd.html#topic+plot.uvevd">evd</a></code> package,
from which these functions were derived.
</p>
<p>The crosses are the empirical quantiles/return levels (i.e. the ordered sample data)
against their corresponding transformed empirical return period (from 
<code><a href="stats.html#topic+ppoints">ppoints</a></code>). The solid line is the theoretical return level
(quantile) function using the estimated parameters. The estimated threshold 
<code>u</code> and tail fraction <code>phiu</code> are shown. For the two tailed models both
thresholds <code>ul</code> and <code>ur</code> and corresponding tail fractions 
<code>phiul</code> and <code>phiur</code> are shown. The approximate pointwise confidence intervals
for the quantiles are obtained by Monte Carlo simulation using the estimated parameters.
Notice that these intervals ignore the parameter estimation uncertainty.
</p>
<p>The Q-Q and P-P plots have the empirical values on the <code class="reqn">y</code>-axis and theoretical values
from the fitted model on the <code class="reqn">x</code>-axis.
</p>
<p>The density plot provides a histogram of the sample data overlaid with the fitted density
and a standard kernel density estimate using the <code><a href="stats.html#topic+density">density</a></code>
function. The default settings for the <code><a href="stats.html#topic+density">density</a></code> function are used.
Note that for distributions with bounded support (e.g. GPD) with high density near the
boundary standard kernel density estimators exhibit a negative bias due to leakage past
the boundary. So in this case they should not be taken too seriously.
</p>
<p>For the kernel density estimates (i.e. <code>kden</code> and <code>bckden</code>) there is no threshold, 
so no upper tail focus is carried out.
</p>
<p>See <code><a href="evd.html#topic+plot.uvevd">plot.uvevd</a></code> for more detailed explanations of these
types of plots.
</p>


<h3>Value</h3>

<p><code><a href="#topic+evmix.diag">rlplot</a></code> gives the return level plot, 
<code><a href="#topic+evmix.diag">qplot</a></code> gives the Q-Q plot,
<code><a href="#topic+evmix.diag">pplot</a></code> gives the P-P plot,
<code><a href="#topic+evmix.diag">densplot</a></code> gives density plot and
<code><a href="#topic+evmix.diag">evmix.diag</a></code> gives the collection of all 4.
</p>


<h3>Acknowledgments</h3>

<p>Based on the GPD/POT diagnostic function <code><a href="evd.html#topic+plot.uvevd">plot.uvevd</a></code> in the <code><a href="evd.html#topic+plot.uvevd">evd</a></code> package for which Stuart Coles' and Alec Stephenson's 
contributions are gratefully acknowledged.
They are designed to have similar syntax and functionality to simplify the transition for users of these packages.
</p>


<h3>Note</h3>

<p>For all mixture models the missing values are removed by the fitting functions 
(e.g. <code><a href="#topic+fnormgpd">fnormgpd</a></code> and <code><a href="#topic+fgng">fgng</a></code>).
However, these are retained in the GPD fitting <code><a href="#topic+fgpd">fgpd</a></code>, as they 
are interpreted as values below the threshold.
</p>
<p>By default all the plots focus in on the upper tail, but they can be used to display 
the fit over the entire range of support.
</p>
<p>You cannot pass <code>xlim</code> or <code>ylim</code> to the plotting functions via <code>...</code>
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Q-Q_plot">http://en.wikipedia.org/wiki/Q-Q_plot</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/P-P_plot">http://en.wikipedia.org/wiki/P-P_plot</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Coles S.G. (2004). An Introduction to the Statistical Modelling of Extreme Values.
Springer-Verlag: London.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ppoints">ppoints</a></code>, <code><a href="evd.html#topic+plot.uvevd">plot.uvevd</a></code> and
<code><a href="ismev.html#topic+gpd.diag">gpd.diag</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)

x = sort(rnorm(1000))
fit = fnormgpd(x)
evmix.diag(fit)

# repeat without focussing on upper tail
par(mfrow=c(2,2))
rlplot(fit, upperfocus = FALSE)
qplot(fit, upperfocus = FALSE)
pplot(fit, upperfocus = FALSE)
densplot(fit, upperfocus = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='fbckden'>Cross-validation MLE Fitting of Boundary Corrected Kernel Density Estimation
Using a Variety of Approaches</h2><span id='topic+fbckden'></span><span id='topic+lbckden'></span><span id='topic+nlbckden'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting boundary corrected 
kernel density estimator using a variety of approaches (and many possible kernels),
by treating it as a mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbckden(x, linit = NULL, bwinit = NULL, kernel = "gaussian",
  extracentres = NULL, bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, add.jitter = FALSE,
  factor = 0.1, amount = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lbckden(x, lambda = NULL, bw = NULL, kernel = "gaussian",
  extracentres = NULL, bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, log = TRUE)

nlbckden(lambda, x, bw = NULL, kernel = "gaussian",
  extracentres = NULL, bcmethod = "simple", proper = TRUE,
  nn = "jf96", offset = NULL, xmax = NULL, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbckden_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fbckden_+3A_linit">linit</code></td>
<td>
<p>initial value for bandwidth (as kernel half-width) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_bwinit">bwinit</code></td>
<td>
<p>initial value for bandwidth (as kernel standard deviations) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fbckden_+3A_extracentres">extracentres</code></td>
<td>
<p>extra kernel centres used in KDE, 
but likelihood contribution not evaluated, or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="fbckden_+3A_proper">proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td></tr>
<tr><td><code id="fbckden_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="fbckden_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fbckden_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fbckden_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbckden_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbckden_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fbckden_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckden_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The boundary corrected kernel density estimator using a variety of approaches
(and many possible kernels) is fitted to the entire dataset using
cross-validation maximum likelihood estimation. The estimated bandwidth,
variance and standard error are automatically output. 
</p>
<p>The log-likelihood and negative log-likelihood are also provided for wider
usage, e.g. constructing your own extreme value
mixture models or profile likelihood functions. The parameter
<code>lambda</code> must be specified in the negative log-likelihood
<code><a href="#topic+fbckden">nlbckden</a></code>.
</p>
<p>Log-likelihood calculations are carried out in
<code><a href="#topic+fbckden">lbckden</a></code>, which takes bandwidths as inputs in
the same form as distribution functions. The negative log-likelihood is a
wrapper for <code><a href="#topic+fbckden">lbckden</a></code>, designed towards making
it useable for optimisation (e.g. <code>lambda</code> given as first input).
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> used here but 
<code>bw</code> also output. The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code> help
documentation with the <code>"gaussian"</code> as the default choice.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all these
estimators, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified.
</p>
<p>The <code>simple</code>, <code>renorm</code>, <code>beta1</code>, <code>beta2</code> <code>gamma1</code> and <code>gamma2</code>
density estimates require renormalisation, achieved
by numerical integration, so is very time consuming.
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored.
</p>
<p>Cross-validation likelihood is used for kernel density component, obtained by
leaving each point out in turn and evaluating the KDE at the point left out:
</p>
<p style="text-align: center;"><code class="reqn">L(\lambda)\prod_{i=1}^{n} \hat{f}_{-i}(x_i)</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{-i}(x_i) = \frac{1}{(n-1)\lambda} \sum_{j=1: j\ne i}^{n} K(\frac{x_i - x_j}{\lambda})</code>
</p>

<p>is the KDE obtained when the <code class="reqn">i</code>th datapoint is dropped out and then 
evaluated at that dropped datapoint at <code class="reqn">x_i</code>.
</p>
<p>Normally for likelihood estimation of the bandwidth the kernel centres and
the data where the likelihood is evaluated are the same. However, when using
KDE for extreme value mixture modelling the likelihood only those data in the
bulk of the distribution should contribute to the likelihood, but all the
data (including those beyond the threshold) should contribute to the density
estimate. The <code>extracentres</code> option allows the use to specify extra
kernel centres used in estimating the density, but not evaluated in the
likelihood. The default is to just use the existing data, so
<code>extracentres=NULL</code>.
</p>
<p>The default optimisation algorithm is &quot;BFGS&quot;, which requires a finite negative 
log-likelihood function evaluation <code>finitelik=TRUE</code>. For invalid 
parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>. The &quot;BFGS&quot; 
optimisation algorithms require finite values for likelihood, so any user 
input for <code>finitelik</code> will be overridden and set to <code>finitelik=TRUE</code> 
if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call.
</p>
<p>If the hessian is of reduced rank then the variance (from inverse hessian)
and standard error of bandwidth parameter cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the bandwidth estimate
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fbckden">fbckden</a></code> gives leave one out cross-validation
(log-)likelihood and 
<code><a href="#topic+fbckden">lbckden</a></code> gives the negative log-likelihood. 
<code><a href="#topic+fbckden">nlbckden</a></code> returns a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>call</code>: </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>x</code>: </td><td style="text-align: left;"> (jittered) data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>kerncentres</code>: actual kernel centres used <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>init</code>: </td><td style="text-align: left;"> <code>linit</code> for lambda</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>optim</code>: </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mle</code>: </td><td style="text-align: left;"> vector of MLE of bandwidth</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>cov</code>: </td><td style="text-align: left;"> variance of MLE of bandwidth</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>se</code>: </td><td style="text-align: left;"> standard error of MLE of bandwidth</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nllh</code>: </td><td style="text-align: left;"> minimum negative cross-validation log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>n</code>: </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>lambda</code>: </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bw</code>: </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>kernel</code>: </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bcmethod</code>: </td><td style="text-align: left;"> boundary correction method</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>proper</code>: </td><td style="text-align: left;"> logical, whether renormalisation is requested</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nn</code>: </td><td style="text-align: left;"> non-negative correction method</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>offset</code>: </td><td style="text-align: left;"> offset for log transformation method</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>xmax</code>: </td><td style="text-align: left;"> maximum value of scale beta or copula
</td>
</tr>

</table>

<p>The output list has some duplicate entries and repeats some of the inputs to both 
provide similar items to those from <code><a href="evd.html#topic+fpot">fpot</a></code> and to make it 
as useable as possible.
</p>


<h3>Warning</h3>

<p>Two important practical issues arise with MLE for the kernel bandwidth:
1) Cross-validation likelihood is needed for the KDE bandwidth parameter
as the usual likelihood degenerates, so that the MLE <code class="reqn">\hat{\lambda} \rightarrow 0</code> as
<code class="reqn">n \rightarrow \infty</code>, thus giving a negative bias towards a small bandwidth.
Leave one out cross-validation essentially ensures that some smoothing between the kernel centres
is required (i.e. a non-zero bandwidth), otherwise the resultant density estimates would always
be zero if the bandwidth was zero.
</p>
<p>This problem occassionally rears its ugly head for data which has been heavily rounded,
as even when using cross-validation the density can be non-zero even if the bandwidth is zero.
To overcome this issue an option to add a small jitter should be added to the data
(<code>x</code> only) has been included in the fitting inputs, using the 
<code><a href="base.html#topic+jitter">jitter</a></code> function, to remove the ties. The default options red in the 
<code><a href="base.html#topic+jitter">jitter</a></code> are specified above, but the user can override these.
Notice the default scaling <code>factor=0.1</code>, which is a tenth of the default value in the
<code><a href="base.html#topic+jitter">jitter</a></code>
function itself.
</p>
<p>A warning message is given if the data appear to be rounded
(i.e. more than 5
data rounding is the likely culprit. Only use the jittering when the MLE of
the bandwidth is far too small. 
</p>
<p>2) For heavy tailed populations the bandwidth is positively biased, giving oversmoothing
(see example). The bias is due to the distance between the upper (or lower) order statistics not
necessarily decaying to zero as the sample size tends to infinity. Essentially, as the distance
between the two largest (or smallest) sample datapoints does not decay to zero, some smoothing between
them is required (i.e. bandwidth cannot be zero). One solution to this problem is to splice
the GPD at a suitable threshold to remove the problematic tail from the inference for the bandwidth, 
using the <code><a href="#topic+fbckdengpd">fbckdengpd</a></code> function for a heavy upper tail. See MacDonald et al (2013).
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>An initial bandwidth must be provided, so <code>linit</code> and <code>bwinit</code> 
cannot both be <code>NULL</code>
</p>
<p>The extra kernel centres <code>extracentres</code> can either be a vector of data or <code>NULL</code>.
</p>
<p>Invalid parameter ranges will give <code>0</code> for likelihood, <code>log(0)=-Inf</code> for
log-likelihood and <code>-log(0)=Inf</code> for negative log-likelihood. 
</p>
<p>Infinite and missing sample values are dropped.
</p>
<p>Error checking of the inputs is carried out and will either stop or give warning message
as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="base.html#topic+jitter">jitter</a></code>, <code><a href="stats.html#topic+density">density</a></code> and
<code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fgkg">fgkg</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fbckden: <code><a href="#topic+bckden">bckden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

nk=500
x = rgamma(nk, shape = 1, scale = 2)
xx = seq(-1, 10, 0.01)

# cut and normalize is very quick 
fit = fbckden(x, linit = 0.2, bcmethod = "cutnorm")
hist(x, nk/5, freq = FALSE) 
rug(x)
lines(xx, dgamma(xx, shape = 1, scale = 2), col = "black")
# but cut and normalize does not always work well for boundary correction
lines(xx, dbckden(xx, x, lambda = fit$lambda, bcmethod = "cutnorm"), lwd = 2, col = "red")
# Handily, the bandwidth usually works well for other approaches as well
lines(xx, dbckden(xx, x, lambda = fit$lambda, bcmethod = "simple"), lwd = 2, col = "blue")
lines(density(x), lty = 2, lwd = 2, col = "green")
legend("topright", c("True Density", "BC KDE using cutnorm",
  "BC KDE using simple", "KDE Using density"),
  lty = c(1, 1, 1, 2), lwd = c(1, 2, 2, 2), col = c("black", "red", "blue", "green"))

# By contrast simple boundary correction is very slow
# a crude trick to speed it up is to ignore the normalisation and non-negative correction,
# which generally leads to bandwidth being biased high
fit = fbckden(x, linit = 0.2, bcmethod = "simple", proper = FALSE, nn = "none")
hist(x, nk/5, freq = FALSE) 
rug(x)
lines(xx, dgamma(xx, shape = 1, scale = 2), col = "black")
lines(xx, dbckden(xx, x, lambda = fit$lambda, bcmethod = "simple"), lwd = 2, col = "blue")
lines(density(x), lty = 2, lwd = 2, col = "green")

# but ignoring upper tail in likelihood works a lot better
q75 = qgamma(0.75, shape = 1, scale = 2)
fitnotail = fbckden(x[x &lt;= q75], linit = 0.1, 
   bcmethod = "simple", proper = FALSE, nn = "none", extracentres = x[x &gt; q75])
lines(xx, dbckden(xx, x, lambda = fitnotail$lambda, bcmethod = "simple"), lwd = 2, col = "red")
legend("topright", c("True Density", "BC KDE using simple", "BC KDE (upper tail ignored)",
   "KDE Using density"),
   lty = c(1, 1, 1, 2), lwd = c(1, 2, 2, 2), col = c("black", "blue", "red", "green"))

## End(Not run)

</code></pre>

<hr>
<h2 id='fbckdengpd'>MLE Fitting of Boundary Corrected Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fbckdengpd'></span><span id='topic+lbckdengpd'></span><span id='topic+nlbckdengpd'></span><span id='topic+proflubckdengpd'></span><span id='topic+nlubckdengpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with boundary corrected kernel density estimate for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbckdengpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  add.jitter = FALSE, factor = 0.1, amount = NULL, std.err = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

lbckdengpd(x, lambda = NULL, u = 0, sigmau = 1, xi = 0,
  phiu = TRUE, bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  log = TRUE)

nlbckdengpd(pvector, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, finitelik = FALSE)

proflubckdengpd(u, pvector, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, method = "BFGS", control = list(maxit = 10000),
  finitelik = TRUE, ...)

nlubckdengpd(pvector, u, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbckdengpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_proper">proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with boundary corrected kernel density estimate (BCKDE) for bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>lambda</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>lambda</code>, <code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Negative data are ignored.
</p>
<p>Cross-validation likelihood is used for BCKDE, but standard likelihood is used
for GPD component. See help for <code><a href="#topic+fkden">fkden</a></code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all these
estimators, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified.
</p>
<p>The <code>simple</code>, <code>renorm</code>, <code>beta1</code>, <code>beta2</code> <code>gamma1</code> and <code>gamma2</code>
boundary corrected kernel density estimates require renormalisation, achieved
by numerical integration, so are very time consuming.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fbckdengpd">lbckdengpd</a></code>, <code><a href="#topic+fbckdengpd">nlbckdengpd</a></code>,
and <code><a href="#topic+fbckdengpd">nlubckdengpd</a></code> give the log-likelihood,
negative log-likelihood and profile likelihood for threshold. Profile likelihood
for single threshold is given by <code><a href="#topic+fbckdengpd">proflubckdengpd</a></code>.
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code> returns a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:    </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:        </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:    </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bcmethod</code>:  </td><td style="text-align: left;"> boundary correction method</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>proper</code>:    </td><td style="text-align: left;"> logical, whether renormalisation is requested</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nn</code>:        </td><td style="text-align: left;"> non-negative correction method</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>offset</code>:    </td><td style="text-align: left;"> offset for log transformation method</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xmax</code>:      </td><td style="text-align: left;"> maximum value of scaled beta or copula
</td>
</tr>

</table>



<h3>Boundary Correction Methods</h3>

<p>See <code><a href="#topic+bckden">dbckden</a></code> for details of BCKDE methods.
</p>


<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code><a href="#topic+fkden">fkden</a></code>, type <code>help fkden</code>.
</p>
<p>See important warnings about boundary correction approaches in 
<code><a href="#topic+bckden">dbckden</a></code>, type <code>help bckden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>See notes in <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>.
Only the different features are outlined below for brevity.
</p>
<p>No default initial values for parameter vector are provided, so will stop evaluation if
<code>pvector</code> is left as <code>NULL</code>. Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>The data and kernel centres are both vectors. Infinite, missing and negative sample values
(and kernel centres) are dropped.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>.
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fbckdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rgamma(500, 2, 1)
xx = seq(-0.1, 10, 0.01)
y = dgamma(xx, 2, 1)

# Bulk model based tail fraction
pinit = c(0.1, quantile(x, 0.9), 1, 0.1) # initial values required for BCKDE
fit = fbckdengpd(x, pvector = pinit, bcmethod = "cutnorm")
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10))
lines(xx, y)
with(fit, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, bcmethod = "cutnorm"), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = fbckdengpd(x, phiu = FALSE, pvector = pinit, bcmethod = "cutnorm")
with(fit2, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, phiu, bc = "cutnorm"), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
pinit = c(0.1, 1, 0.1) # notice threshold dropped from initial values
fitu = fbckdengpd(x, useq = seq(1, 6, length = 20), pvector = pinit, bcmethod = "cutnorm")
fitfix = fbckdengpd(x, useq = seq(1, 6, length = 20), fixedu = TRUE, pv = pinit, bc = "cutnorm")

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10))
lines(xx, y)
with(fit, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, bc = "cutnorm"), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, bc = "cutnorm"), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, bc = "cutnorm"), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='fbckdengpdcon'>MLE Fitting of Boundary Corrected Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model
with Single Continuity Constraint</h2><span id='topic+fbckdengpdcon'></span><span id='topic+lbckdengpdcon'></span><span id='topic+nlbckdengpdcon'></span><span id='topic+proflubckdengpdcon'></span><span id='topic+nlubckdengpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with boundary corrected kernel density estimate for bulk distribution upto the threshold and conditional
GPD above thresholdwith continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbckdengpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  add.jitter = FALSE, factor = 0.1, amount = NULL, std.err = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

lbckdengpdcon(x, lambda = NULL, u = 0, xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  log = TRUE)

nlbckdengpdcon(pvector, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, finitelik = FALSE)

proflubckdengpdcon(u, pvector, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, method = "BFGS", control = list(maxit = 10000),
  finitelik = TRUE, ...)

nlubckdengpdcon(pvector, u, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbckdengpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_bcmethod">bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_proper">proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fbckdengpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with boundary corrected kernel density
estimate (BCKDE) for bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+bckdengpdcon">dbckdengpdcon</a></code> for details, type <code>help bckdengpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>lambda</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>lambda</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Negative data are ignored.
</p>
<p>Cross-validation likelihood is used for BCKDE, but standard likelihood is used
for GPD component. See help for <code><a href="#topic+fkden">fkden</a></code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all these
estimators, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified.
</p>
<p>The <code>simple</code>, <code>renorm</code>, <code>beta1</code>, <code>beta2</code> <code>gamma1</code> and <code>gamma2</code>
boundary corrected kernel density estimates require renormalisation, achieved
by numerical integration, so are very time consuming.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fbckdengpdcon">lbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpdcon">nlbckdengpdcon</a></code>,
and <code><a href="#topic+fbckdengpdcon">nlubckdengpdcon</a></code> give the log-likelihood,
negative log-likelihood and profile likelihood for threshold. Profile likelihood
for single threshold is given by <code><a href="#topic+fbckdengpdcon">proflubckdengpdcon</a></code>.
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code> returns a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:    </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale(estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:        </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:    </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bcmethod</code>:  </td><td style="text-align: left;"> boundary correction method</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>proper</code>:    </td><td style="text-align: left;"> logical, whether renormalisation is requested</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nn</code>:        </td><td style="text-align: left;"> non-negative correction method</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>offset</code>:    </td><td style="text-align: left;"> offset for log transformation method</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xmax</code>:      </td><td style="text-align: left;"> maximum value of scaled beta or copula
</td>
</tr>

</table>



<h3>Boundary Correction Methods</h3>

<p>See <code><a href="#topic+bckden">dbckden</a></code> for details of BCKDE methods.
</p>


<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code><a href="#topic+fkden">fkden</a></code>, type <code>help fkden</code>.
</p>
<p>See important warnings about boundary correction approaches in 
<code><a href="#topic+bckden">dbckden</a></code>, type <code>help bckden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>See notes in <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>.
Only the different features are outlined below for brevity.
</p>
<p>No default initial values for parameter vector are provided, so will stop evaluation if
<code>pvector</code> is left as <code>NULL</code>. Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>The data and kernel centres are both vectors. Infinite, missing and negative sample values
(and kernel centres) are dropped.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>.
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fbckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rgamma(500, 2, 1)
xx = seq(-0.1, 10, 0.01)
y = dgamma(xx, 2, 1)

# Continuity constraint
pinit = c(0.1, quantile(x, 0.9), 0.1) # initial values required for BCKDE
fit = fbckdengpdcon(x, pvector = pinit, bcmethod = "cutnorm")
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10))
lines(xx, y)
with(fit, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bcmethod = "cutnorm"), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
pinit = c(0.1, quantile(x, 0.9), 1, 0.1) # initial values required for BCKDE
fit2 = fbckdengpd(x, pvector = pinit, bcmethod = "cutnorm")
with(fit2, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, bc = "cutnorm"), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
pinit = c(0.1, 0.1) # notice threshold dropped from initial values
fitu = fbckdengpdcon(x, useq = seq(1, 6, length = 20), pvector = pinit, bcmethod = "cutnorm")
fitfix = fbckdengpdcon(x, useq = seq(1, 6, length = 20), fixedu = TRUE, pv = pinit, bc = "cutnorm")

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10))
lines(xx, y)
with(fit, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bc = "cutnorm"), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bc = "cutnorm"), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bc = "cutnorm"), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='fbetagpd'>MLE Fitting of beta Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fbetagpd'></span><span id='topic+lbetagpd'></span><span id='topic+nlbetagpd'></span><span id='topic+proflubetagpd'></span><span id='topic+nlubetagpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with beta for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbetagpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lbetagpd(x, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), sigmau = sqrt(bshape1 * bshape2/(bshape1 +
  bshape2)^2/(bshape1 + bshape2 + 1)), xi = 0, phiu = TRUE,
  log = TRUE)

nlbetagpd(pvector, x, phiu = TRUE, finitelik = FALSE)

proflubetagpd(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlubetagpd(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbetagpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_bshape1">bshape1</code></td>
<td>
<p>scalar beta shape 1 (positive)</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_bshape2">bshape2</code></td>
<td>
<p>scalar beta shape 2 (positive)</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_u">u</code></td>
<td>
<p>scalar threshold over <code class="reqn">(0, 1)</code></p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fbetagpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with beta bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>bshape1</code>, <code>bshape2</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>bshape1</code>, <code>bshape2</code>, <code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Negative data are ignored. Values above 1 must come from GPD component, as
threshold <code>u&lt;1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fbetagpd">lbetagpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fbetagpd">nlbetagpd</a></code>
and <code><a href="#topic+fbetagpd">nlubetagpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fbetagpd">proflubetagpd</a></code>. Fitting function
<code><a href="#topic+fbetagpd">fbetagpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bshape1</code>:   </td><td style="text-align: left;"> MLE of beta shape1</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bshape2</code>:   </td><td style="text-align: left;"> MLE of beta shape2</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>Thanks to Vathy Kamulete of the Royal Bank of Canada for reporting a bug in the likelihood function. See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> method of moments estimator of beta parameters assuming entire population is beta; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Beta_distribution">http://en.wikipedia.org/wiki/Beta_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>MacDonald, A. (2012). Extreme value mixture modelling with medical and
industrial applications. PhD thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf">http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Beta">dbeta</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other betagpd: <code><a href="#topic+betagpdcon">betagpdcon</a></code>,
<code><a href="#topic+betagpd">betagpd</a></code>, <code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>
</p>
<p>Other betagpdcon: <code><a href="#topic+betagpdcon">betagpdcon</a></code>,
<code><a href="#topic+betagpd">betagpd</a></code>, <code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code>
</p>
<p>Other fbetagpd: <code><a href="#topic+betagpd">betagpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rbeta(1000, shape1 = 2, shape2 = 4)
xx = seq(-0.1, 2, 0.01)
y = dbeta(xx, shape1 = 2, shape2 = 4)

# Bulk model based tail fraction
fit = fbetagpd(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, y)
with(fit, lines(xx, dbetagpd(xx, bshape1, bshape2, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = fbetagpd(x, phiu = FALSE)
with(fit2, lines(xx, dbetagpd(xx, bshape1, bshape2, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fbetagpd(x, useq = seq(0.3, 0.7, length = 20))
fitfix = fbetagpd(x, useq = seq(0.3, 0.7, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, y)
with(fit, lines(xx, dbetagpd(xx, bshape1, bshape2, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dbetagpd(xx, bshape1, bshape2, u, sigmau, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dbetagpd(xx, bshape1, bshape2, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fbetagpdcon'>MLE Fitting of beta Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+fbetagpdcon'></span><span id='topic+lbetagpdcon'></span><span id='topic+nlbetagpdcon'></span><span id='topic+proflubetagpdcon'></span><span id='topic+nlubetagpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with beta for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbetagpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lbetagpdcon(x, bshape1 = 1, bshape2 = 1, u = qbeta(0.9, bshape1,
  bshape2), xi = 0, phiu = TRUE, log = TRUE)

nlbetagpdcon(pvector, x, phiu = TRUE, finitelik = FALSE)

proflubetagpdcon(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlubetagpdcon(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fbetagpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_bshape1">bshape1</code></td>
<td>
<p>scalar beta shape 1 (positive)</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_bshape2">bshape2</code></td>
<td>
<p>scalar beta shape 2 (positive)</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold over <code class="reqn">(0, 1)</code></p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fbetagpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with beta bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+betagpdcon">dbetagpdcon</a></code> for details, type <code>help betagpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>bshape1</code>, <code>bshape2</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>bshape1</code>, <code>bshape2</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Negative data are ignored. Values above 1 must come from GPD component, as
threshold <code>u&lt;1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fbetagpdcon">lbetagpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fbetagpdcon">nlbetagpdcon</a></code>
and <code><a href="#topic+fbetagpdcon">nlubetagpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fbetagpdcon">proflubetagpdcon</a></code>. Fitting function
<code><a href="#topic+fbetagpdcon">fbetagpdcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bshape1</code>:   </td><td style="text-align: left;"> MLE of beta shape1</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bshape2</code>:   </td><td style="text-align: left;"> MLE of beta shape2</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> method of moments estimator of beta parameters assuming entire population is beta; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Beta_distribution">http://en.wikipedia.org/wiki/Beta_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>MacDonald, A. (2012). Extreme value mixture modelling with medical and
industrial applications. PhD thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf">http://ir.canterbury.ac.nz/bitstream/10092/6679/1/thesis_fulltext.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Beta">dbeta</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other betagpd: <code><a href="#topic+betagpdcon">betagpdcon</a></code>,
<code><a href="#topic+betagpd">betagpd</a></code>, <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>
<p>Other betagpdcon: <code><a href="#topic+betagpdcon">betagpdcon</a></code>,
<code><a href="#topic+betagpd">betagpd</a></code>, <code><a href="#topic+fbetagpd">fbetagpd</a></code>
</p>
<p>Other fbetagpdcon: <code><a href="#topic+betagpdcon">betagpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rbeta(1000, shape1 = 2, shape2 = 4)
xx = seq(-0.1, 2, 0.01)
y = dbeta(xx, shape1 = 2, shape2 = 4)

# Continuity constraint
fit = fbetagpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, y)
with(fit, lines(xx, dbetagpdcon(xx, bshape1, bshape2, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = fbetagpd(x, phiu = FALSE)
with(fit2, lines(xx, dbetagpd(xx, bshape1, bshape2, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fbetagpdcon(x, useq = seq(0.3, 0.7, length = 20))
fitfix = fbetagpdcon(x, useq = seq(0.3, 0.7, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 2))
lines(xx, y)
with(fit, lines(xx, dbetagpdcon(xx, bshape1, bshape2, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dbetagpdcon(xx, bshape1, bshape2, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dbetagpdcon(xx, bshape1, bshape2, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fdwm'>MLE Fitting of Dynamically Weighted Mixture Model</h2><span id='topic+fdwm'></span><span id='topic+ldwm'></span><span id='topic+nldwm'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the dynamically weighted mixture model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdwm(x, pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

ldwm(x, wshape = 1, wscale = 1, cmu = 1, ctau = 1,
  sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), xi = 0, log = TRUE)

nldwm(pvector, x, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdwm_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fdwm_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters
(<code>wshape</code>, <code>wscale</code>, <code>cmu</code>, <code>ctau</code>, <code>sigmau</code>, <code>xi</code>) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fdwm_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fdwm_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fdwm_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fdwm_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fdwm_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fdwm_+3A_wshape">wshape</code></td>
<td>
<p>Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="fdwm_+3A_wscale">wscale</code></td>
<td>
<p>Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="fdwm_+3A_cmu">cmu</code></td>
<td>
<p>Cauchy location</p>
</td></tr>
<tr><td><code id="fdwm_+3A_ctau">ctau</code></td>
<td>
<p>Cauchy scale</p>
</td></tr>
<tr><td><code id="fdwm_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fdwm_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fdwm_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dynamically weighted mixture model is fitted to the entire dataset using maximum 
likelihood estimation. The estimated parameters, variance-covariance matrix and their standard
errors are automatically output.
</p>
<p>The log-likelihood and negative log-likelihood are also provided for wider
usage, e.g. constructing profile likelihood functions. The parameter vector
<code>pvector</code> must be specified in the negative log-likelihood <code><a href="#topic+fdwm">nldwm</a></code>.
</p>
<p>Log-likelihood calculations are carried out in
<code><a href="#topic+fdwm">ldwm</a></code>, which takes parameters as inputs in
the same form as distribution functions. The negative log-likelihood is a
wrapper for <code><a href="#topic+fdwm">ldwm</a></code>, designed towards making
it useable for optimisation (e.g. parameters are given a vector as first
input).
</p>
<p>Non-negative data are ignored.
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored,
which is inconsistent with the <code><a href="evd.html#topic+fpot">evd</a></code> library which assumes the 
missing values are below the threshold.
</p>
<p>The default optimisation algorithm is &quot;BFGS&quot;, which requires a finite negative 
log-likelihood function evaluation <code>finitelik=TRUE</code>. For invalid 
parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>. The &quot;BFGS&quot; 
optimisation algorithms require finite values for likelihood, so any user 
input for <code>finitelik</code> will be overridden and set to <code>finitelik=TRUE</code> 
if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call.
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fdwm">ldwm</a></code> gives (log-)likelihood and 
<code><a href="#topic+fdwm">nldwm</a></code> gives the negative log-likelihood. 
<code><a href="#topic+fdwm">fdwm</a></code> returns a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>call</code>:   </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>x</code>:      </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>init</code>:   </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>optim</code>:  </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mle</code>:    </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>cov</code>:    </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>se</code>:     </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rate</code>:   </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nllh</code>:   </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>n</code>:      </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wshape</code>: </td><td style="text-align: left;"> MLE of Weibull shape</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>wscale</code>: </td><td style="text-align: left;"> MLE of Weibull scale</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mu</code>:     </td><td style="text-align: left;"> MLE of Cauchy location</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>tau</code>:    </td><td style="text-align: left;"> MLE of Cauchy scale</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sigmau</code>: </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>xi</code>:     </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The output list has some duplicate entries and repeats some of the inputs to both 
provide similar items to those from <code><a href="evd.html#topic+fpot">fpot</a></code> and to make it 
as useable as possible.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>Unlike most of the distribution functions for the extreme value mixture models,
the MLE fitting only permits single scalar values for each parameter and 
<code>phiu</code>. Only the data is a vector.
</p>
<p>When <code>pvector=NULL</code> then the initial values are calculated, type 
<code>fdwm</code> to see the default formulae used. The mixture model fitting can be
***extremely*** sensitive to the initial values, so you if you get a poor fit then
try some alternatives. Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>Infinite and missing sample values are dropped.
</p>
<p>Error checking of the inputs is carried out and will either stop or give warning message
as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cauchy_distribution">http://en.wikipedia.org/wiki/Cauchy_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Frigessi, A., O. Haug, and H. Rue (2002). A dynamic mixture model for unsupervised tail
estimation without threshold selection. Extremes 5 (3), 219-235
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other fdwm: <code><a href="#topic+dwm">dwm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rweibull(1000, shape = 2)
xx = seq(-0.1, 4, 0.01)
y = dweibull(xx, shape = 2)

fit = fdwm(x, std.err = FALSE)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 4))
lines(xx, y)
with(fit, lines(xx, ddwm(xx, wshape, wscale, cmu, ctau, sigmau, xi), col="red"))

## End(Not run)

</code></pre>

<hr>
<h2 id='fgammagpd'>MLE Fitting of Gamma Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fgammagpd'></span><span id='topic+lgammagpd'></span><span id='topic+nlgammagpd'></span><span id='topic+proflugammagpd'></span><span id='topic+nlugammagpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with gamma for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgammagpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lgammagpd(x, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), sigmau = sqrt(gshape) * gscale, xi = 0, phiu = TRUE,
  log = TRUE)

nlgammagpd(pvector, x, phiu = TRUE, finitelik = FALSE)

proflugammagpd(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlugammagpd(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgammagpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_gshape">gshape</code></td>
<td>
<p>scalar gamma shape (positive)</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_gscale">gscale</code></td>
<td>
<p>scalar gamma scale (positive)</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fgammagpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with gamma bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>gshape</code>, <code>gscale</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>gshape</code>, <code>gscale</code>, <code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Non-positive data are ignored as likelihood is infinite, except for <code>gshape=1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fgammagpd">lgammagpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fgammagpd">nlgammagpd</a></code>
and <code><a href="#topic+fgammagpd">nlugammagpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fgammagpd">proflugammagpd</a></code>. Fitting function
<code><a href="#topic+fgammagpd">fgammagpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>gshape</code>:    </td><td style="text-align: left;"> MLE of gamma shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>gscale</code>:    </td><td style="text-align: left;"> MLE of gamma scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> approximation of MLE of gamma parameters assuming entire population is gamma; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">dgamma</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other gammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fgammagpd: <code><a href="#topic+gammagpd">gammagpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rgamma(1000, shape = 2)
xx = seq(-0.1, 8, 0.01)
y = dgamma(xx, shape = 2)

# Bulk model based tail fraction
fit = fgammagpd(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 8))
lines(xx, y)
with(fit, lines(xx, dgammagpd(xx, gshape, gscale, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = fgammagpd(x, phiu = FALSE)
with(fit2, lines(xx, dgammagpd(xx, gshape, gscale, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fgammagpd(x, useq = seq(1, 5, length = 20))
fitfix = fgammagpd(x, useq = seq(1, 5, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 8))
lines(xx, y)
with(fit, lines(xx, dgammagpd(xx, gshape, gscale, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dgammagpd(xx, gshape, gscale, u, sigmau, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dgammagpd(xx, gshape, gscale, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fgammagpdcon'>MLE Fitting of Gamma Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+fgammagpdcon'></span><span id='topic+lgammagpdcon'></span><span id='topic+nlgammagpdcon'></span><span id='topic+proflugammagpdcon'></span><span id='topic+nlugammagpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with gamma for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgammagpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lgammagpdcon(x, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), xi = 0, phiu = TRUE, log = TRUE)

nlgammagpdcon(pvector, x, phiu = TRUE, finitelik = FALSE)

proflugammagpdcon(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlugammagpdcon(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgammagpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_gshape">gshape</code></td>
<td>
<p>scalar gamma shape (positive)</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_gscale">gscale</code></td>
<td>
<p>scalar gamma scale (positive)</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fgammagpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with gamma bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+gammagpdcon">dgammagpdcon</a></code> for details, type <code>help gammagpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>gshape</code>, <code>gscale</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>gshape</code>, <code>gscale</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Non-positive data are ignored as likelihood is infinite, except for <code>gshape=1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fgammagpdcon">lgammagpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fgammagpdcon">nlgammagpdcon</a></code>
and <code><a href="#topic+fgammagpdcon">nlugammagpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fgammagpdcon">proflugammagpdcon</a></code>. Fitting function
<code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>gshape</code>:    </td><td style="text-align: left;"> MLE of gamma shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>gscale</code>:    </td><td style="text-align: left;"> MLE of gamma scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> approximation of MLE of gamma parameters assuming entire population is gamma; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">dgamma</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other gammagpdcon: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fgammagpdcon: <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rgamma(1000, shape = 2)
xx = seq(-0.1, 8, 0.01)
y = dgamma(xx, shape = 2)

# Continuity constraint
fit = fgammagpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 8))
lines(xx, y)
with(fit, lines(xx, dgammagpdcon(xx, gshape, gscale, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = fgammagpd(x, phiu = FALSE)
with(fit2, lines(xx, dgammagpd(xx, gshape, gscale, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fgammagpdcon(x, useq = seq(1, 5, length = 20))
fitfix = fgammagpdcon(x, useq = seq(1, 5, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 8))
lines(xx, y)
with(fit, lines(xx, dgammagpdcon(xx, gshape, gscale, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dgammagpdcon(xx, gshape, gscale, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dgammagpdcon(xx, gshape, gscale, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fgkg'>MLE Fitting of Kernel Density Estimate for Bulk and GPD for Both Tails
Extreme Value Mixture Model</h2><span id='topic+fgkg'></span><span id='topic+lgkg'></span><span id='topic+nlgkg'></span><span id='topic+proflugkg'></span><span id='topic+nlugkg'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with kernel density estimate for bulk distribution between thresholds and conditional
GPDs beyond thresholds. With options for profile likelihood estimation for both thresholds and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgkg(x, phiul = TRUE, phiur = TRUE, ulseq = NULL, urseq = NULL,
  fixedu = FALSE, pvector = NULL, kernel = "gaussian",
  add.jitter = FALSE, factor = 0.1, amount = NULL, std.err = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

lgkg(x, lambda = NULL, ul = 0, sigmaul = 1, xil = 0,
  phiul = TRUE, ur = 0, sigmaur = 1, xir = 0, phiur = TRUE,
  bw = NULL, kernel = "gaussian", log = TRUE)

nlgkg(pvector, x, phiul = TRUE, phiur = TRUE, kernel = "gaussian",
  finitelik = FALSE)

proflugkg(ulr, pvector, x, phiul = TRUE, phiur = TRUE,
  kernel = "gaussian", method = "BFGS", control = list(maxit =
  10000), finitelik = TRUE, ...)

nlugkg(pvector, ul, ur, x, phiul = TRUE, phiur = TRUE,
  kernel = "gaussian", finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgkg_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgkg_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgkg_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgkg_+3A_ulseq">ulseq</code></td>
<td>
<p>vector of lower thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgkg_+3A_urseq">urseq</code></td>
<td>
<p>vector of upper thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgkg_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>ulseq</code>/<code>urseq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>ulseq</code>/<code>urseq</code>)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fgkg_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fgkg_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fgkg_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fgkg_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgkg_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgkg_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgkg_+3A_lambda">lambda</code></td>
<td>
<p>scalar bandwidth for kernel (as half-width of kernel)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_ul">ul</code></td>
<td>
<p>scalar lower tail threshold</p>
</td></tr>
<tr><td><code id="fgkg_+3A_sigmaul">sigmaul</code></td>
<td>
<p>scalar lower tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_xil">xil</code></td>
<td>
<p>scalar lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgkg_+3A_ur">ur</code></td>
<td>
<p>scalar upper tail threshold</p>
</td></tr>
<tr><td><code id="fgkg_+3A_sigmaur">sigmaur</code></td>
<td>
<p>scalar upper tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_xir">xir</code></td>
<td>
<p>scalar upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgkg_+3A_bw">bw</code></td>
<td>
<p>scalar bandwidth for kernel (as standard deviations of kernel)</p>
</td></tr>
<tr><td><code id="fgkg_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fgkg_+3A_ulr">ulr</code></td>
<td>
<p>vector of length 2 giving lower and upper tail thresholds or
<code>NULL</code> for default values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with kernel density estimate for bulk and
GPD for both tails is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> and <code><a href="#topic+fgkg">fgkg</a></code> 
for details, type <code>help fnormgpd</code> and <code>help fgkg</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>lambda</code>, <code>ul</code>, <code>sigmaul</code>, <code>xil</code>, <code>ur</code>, <code>sigmaur</code>, <code>xir</code>)
if thresholds are also estimated and
(<code>lambda</code>, <code>sigmaul</code>, <code>xil</code>, <code>sigmaur</code>, <code>xir</code>)
for profile likelihood or fixed threshold approach.
</p>
<p>Cross-validation likelihood is used for KDE, but standard likelihood is used
for GPD components. See help for <code><a href="#topic+fkden">fkden</a></code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>The tail fractions <code>phiul</code> and <code>phiur</code> are treated separately to the other parameters, 
to allow for all their representations. In the fitting functions 
<code><a href="#topic+fgkg">fgkg</a></code> and
<code><a href="#topic+fgkg">proflugkg</a></code> they are logical:
</p>

<ul>
<li><p> default values <code>phiul=TRUE</code> and <code>phiur=TRUE</code> - tail fractions specified by 
KDE distribution and survivior functions respectively and
standard error is output as <code>NA</code>.
</p>
</li>
<li> <p><code>phiul=FALSE</code> and <code>phiur=FALSE</code> - treated as extra parameters estimated using
the MLE which is the sample proportion beyond the thresholds and 
standard error is output.
</p>
</li></ul>

<p>In the likelihood functions <code><a href="#topic+fgkg">lgkg</a></code>,
<code><a href="#topic+fgkg">nlgkg</a></code> and <code><a href="#topic+fgkg">nlugkg</a></code> 
it can be logical or numeric:
</p>

<ul>
<li><p> logical - same as for fitting functions with default values <code>phiul=TRUE</code> and <code>phiur=TRUE</code>.
</p>
</li>
<li><p> numeric - any value over range <code class="reqn">(0, 1)</code>. Notice that the tail
fraction probability cannot be 0 or 1 otherwise there would be no
contribution from either tail or bulk components respectively. Also,
<code>phiul+phiur&lt;1</code> as bulk must contribute.
</p>
</li></ul>

<p>If the profile likelihood approach is used, then a grid search over all combinations of both thresholds
is carried out. The combinations which lead to less than 5 in any datapoints beyond the thresholds are not considered.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fgkg">lgkg</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fgkg">nlgkg</a></code>
and <code><a href="#topic+fgkg">nlugkg</a></code>. Profile likelihood for both
thresholds given by <code><a href="#topic+fgkg">proflugkg</a></code>. Fitting function
<code><a href="#topic+fgkg">fgkg</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed thresholds, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ulseq</code>:     </td><td style="text-align: left;"> lower threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>urseq</code>:     </td><td style="text-align: left;"> upper threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold pair in (ulseq, urseq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:    </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ul</code>:        </td><td style="text-align: left;"> lower threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaul</code>:   </td><td style="text-align: left;"> MLE of lower tail GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xil</code>:       </td><td style="text-align: left;"> MLE of lower tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiul</code>:     </td><td style="text-align: left;"> MLE of lower tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiul</code>:  </td><td style="text-align: left;"> standard error of MLE of lower tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ur</code>:        </td><td style="text-align: left;"> upper threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaur</code>:   </td><td style="text-align: left;"> MLE of upper tail GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xir</code>:       </td><td style="text-align: left;"> MLE of upper tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiur</code>:     </td><td style="text-align: left;"> MLE of upper tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiur</code>:  </td><td style="text-align: left;"> standard error of MLE of upper tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:        </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:    </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code><a href="#topic+fkden">fkden</a></code>, type <code>help fkden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>The data and kernel centres are both vectors. Infinite and missing sample values
(and kernel centres) are dropped.
</p>
<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> normal reference rule for bandwidth, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
</li>
<li><p> lower threshold 10% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> upper threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters beyond thresholds. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other gkgcon: <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fgkg: <code><a href="#topic+gkg">gkg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Bulk model based tail fraction
fit = fgkg(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgkg(xx, x, lambda, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
  
# Parameterised tail fraction
fit2 = fgkg(x, phiul = FALSE, phiur = FALSE)
with(fit2, lines(xx, dgkg(xx, x, lambda, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="blue"))
abline(v = c(fit2$ul, fit2$ur), col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fgkg(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10))
fitfix = fgkg(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgkg(xx, x, lambda, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
with(fitu, lines(xx, dgkg(xx, x, lambda, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="purple"))
abline(v = c(fitu$ul, fitu$ur), col = "purple")
with(fitfix, lines(xx, dgkg(xx, x, lambda, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="darkgreen"))
abline(v = c(fitfix$ul, fitfix$ur), col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fgkgcon'>MLE Fitting of Kernel Density Estimate for Bulk and GPD for Both Tails with 
Single Continuity Constraint at Both Thresholds Extreme Value Mixture Model</h2><span id='topic+fgkgcon'></span><span id='topic+lgkgcon'></span><span id='topic+nlgkgcon'></span><span id='topic+proflugkgcon'></span><span id='topic+nlugkgcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with kernel density estimate for bulk distribution between thresholds and conditional
GPDs for both tails with continuity at thresholds. With options for profile likelihood estimation for both thresholds and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgkgcon(x, phiul = TRUE, phiur = TRUE, ulseq = NULL, urseq = NULL,
  fixedu = FALSE, pvector = NULL, kernel = "gaussian",
  add.jitter = FALSE, factor = 0.1, amount = NULL, std.err = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

lgkgcon(x, lambda = NULL, ul = 0, xil = 0, phiul = TRUE, ur = 0,
  xir = 0, phiur = TRUE, bw = NULL, kernel = "gaussian",
  log = TRUE)

nlgkgcon(pvector, x, phiul = TRUE, phiur = TRUE, kernel = "gaussian",
  finitelik = FALSE)

proflugkgcon(ulr, pvector, x, phiul = TRUE, phiur = TRUE,
  kernel = "gaussian", method = "BFGS", control = list(maxit =
  10000), finitelik = TRUE, ...)

nlugkgcon(pvector, ul, ur, x, phiul = TRUE, phiur = TRUE,
  kernel = "gaussian", finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgkgcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_ulseq">ulseq</code></td>
<td>
<p>vector of lower thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_urseq">urseq</code></td>
<td>
<p>vector of upper thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>ulseq</code>/<code>urseq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>ulseq</code>/<code>urseq</code>)</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_lambda">lambda</code></td>
<td>
<p>scalar bandwidth for kernel (as half-width of kernel)</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_ul">ul</code></td>
<td>
<p>scalar lower tail threshold</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_xil">xil</code></td>
<td>
<p>scalar lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_ur">ur</code></td>
<td>
<p>scalar upper tail threshold</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_xir">xir</code></td>
<td>
<p>scalar upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_bw">bw</code></td>
<td>
<p>scalar bandwidth for kernel (as standard deviations of kernel)</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fgkgcon_+3A_ulr">ulr</code></td>
<td>
<p>vector of length 2 giving lower and upper tail thresholds or
<code>NULL</code> for default values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with kernel density estimate for bulk and
GPD for both tails with continuity at thresholds is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> and <code><a href="#topic+fgkg">fgng</a></code> 
for details, type <code>help fnormgpd</code> and <code>help fgng</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmaul</code> and <code>sigmaur</code> parameters are now specified as function of
other parameters, see 
help for <code><a href="#topic+gkgcon">dgkgcon</a></code> for details, type <code>help gkgcon</code>.
Therefore, <code>sigmaul</code> and <code>sigmaur</code> should not be included in the parameter
vector if initial values are provided, making the full parameter vector 
The full parameter vector is
(<code>lambda</code>, <code>ul</code>, <code>xil</code>, <code>ur</code>, <code>xir</code>)
if thresholds are also estimated and
(<code>lambda</code>, <code>xil</code>, <code>xir</code>)
for profile likelihood or fixed threshold approach.
</p>
<p>Cross-validation likelihood is used for KDE, but standard likelihood is used
for GPD components. See help for <code><a href="#topic+fkden">fkden</a></code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>The tail fractions <code>phiul</code> and <code>phiur</code> are treated separately to the other parameters, 
to allow for all their representations. In the fitting functions 
<code><a href="#topic+fgkgcon">fgkgcon</a></code> and
<code><a href="#topic+fgkgcon">proflugkgcon</a></code> they are logical:
</p>

<ul>
<li><p> default values <code>phiul=TRUE</code> and <code>phiur=TRUE</code> - tail fractions specified by 
KDE distribution and survivior functions respectively and
standard error is output as <code>NA</code>.
</p>
</li>
<li> <p><code>phiul=FALSE</code> and <code>phiur=FALSE</code> - treated as extra parameters estimated using
the MLE which is the sample proportion beyond the thresholds and 
standard error is output.
</p>
</li></ul>

<p>In the likelihood functions <code><a href="#topic+fgkgcon">lgkgcon</a></code>,
<code><a href="#topic+fgkgcon">nlgkgcon</a></code> and <code><a href="#topic+fgkgcon">nlugkgcon</a></code> 
it can be logical or numeric:
</p>

<ul>
<li><p> logical - same as for fitting functions with default values <code>phiul=TRUE</code> and <code>phiur=TRUE</code>.
</p>
</li>
<li><p> numeric - any value over range <code class="reqn">(0, 1)</code>. Notice that the tail
fraction probability cannot be 0 or 1 otherwise there would be no
contribution from either tail or bulk components respectively. Also,
<code>phiul+phiur&lt;1</code> as bulk must contribute.
</p>
</li></ul>

<p>If the profile likelihood approach is used, then a grid search over all combinations of both thresholds
is carried out. The combinations which lead to less than 5 in any datapoints beyond the thresholds are not considered.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fgkgcon">lgkgcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fgkgcon">nlgkgcon</a></code>
and <code><a href="#topic+fgkgcon">nlugkgcon</a></code>. Profile likelihood for both
thresholds given by <code><a href="#topic+fgkgcon">proflugkgcon</a></code>. Fitting function
<code><a href="#topic+fgkgcon">fgkgcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed thresholds, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ulseq</code>:     </td><td style="text-align: left;"> lower threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>urseq</code>:     </td><td style="text-align: left;"> upper threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold pair in (ulseq, urseq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:    </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ul</code>:        </td><td style="text-align: left;"> lower threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaul</code>:   </td><td style="text-align: left;"> MLE of lower tail GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xil</code>:       </td><td style="text-align: left;"> MLE of lower tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiul</code>:     </td><td style="text-align: left;"> MLE of lower tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiul</code>:  </td><td style="text-align: left;"> standard error of MLE of lower tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ur</code>:        </td><td style="text-align: left;"> upper threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaur</code>:   </td><td style="text-align: left;"> MLE of upper tail GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xir</code>:       </td><td style="text-align: left;"> MLE of upper tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiur</code>:     </td><td style="text-align: left;"> MLE of upper tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiur</code>:  </td><td style="text-align: left;"> standard error of MLE of lower tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:        </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:    </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code><a href="#topic+fkden">fkden</a></code>, type <code>help fkden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>The data and kernel centres are both vectors. Infinite and missing sample values
(and kernel centres) are dropped.
</p>
<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> normal reference rule for bandwidth, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
</li>
<li><p> lower threshold 10% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> upper threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameters beyond thresholds. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkg">fgkg</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkg">fgkg</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other gkgcon: <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fgkgcon: <code><a href="#topic+gkgcon">gkgcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Continuity constraint
fit = fgkgcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgkgcon(xx, x, lambda, ul, xil, phiul,
   ur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
  
# No continuity constraint
fit2 = fgkg(x)
with(fit2, lines(xx, dgkg(xx, x, lambda, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="blue"))
abline(v = c(fit2$ul, fit2$ur), col = "blue")
legend("topleft", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fgkgcon(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10))
fitfix = fgkgcon(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgkgcon(xx, x, lambda, ul, xil, phiul,
   ur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
with(fitu, lines(xx, dgkgcon(xx, x, lambda, ul, xil, phiul,
   ur, xir, phiur), col="purple"))
abline(v = c(fitu$ul, fitu$ur), col = "purple")
with(fitfix, lines(xx, dgkgcon(xx, x, lambda, ul, xil, phiul,
   ur, xir, phiur), col="darkgreen"))
abline(v = c(fitfix$ul, fitfix$ur), col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fgng'>MLE Fitting of Normal Bulk and GPD for Both Tails Extreme Value Mixture Model</h2><span id='topic+fgng'></span><span id='topic+lgng'></span><span id='topic+nlgng'></span><span id='topic+proflugng'></span><span id='topic+nlugng'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with normal for bulk distribution between thresholds and conditional
GPDs beyond thresholds. With options for profile likelihood estimation for both thresholds and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgng(x, phiul = TRUE, phiur = TRUE, ulseq = NULL, urseq = NULL,
  fixedu = FALSE, pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lgng(x, nmean = 0, nsd = 1, ul = 0, sigmaul = 1, xil = 0,
  phiul = TRUE, ur = 0, sigmaur = 1, xir = 0, phiur = TRUE,
  log = TRUE)

nlgng(pvector, x, phiul = TRUE, phiur = TRUE, finitelik = FALSE)

proflugng(ulr, pvector, x, phiul = TRUE, phiur = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

nlugng(pvector, ul, ur, x, phiul = TRUE, phiur = TRUE,
  finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgng_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgng_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgng_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgng_+3A_ulseq">ulseq</code></td>
<td>
<p>vector of lower thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgng_+3A_urseq">urseq</code></td>
<td>
<p>vector of upper thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgng_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>ulseq</code>/<code>urseq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>ulseq</code>/<code>urseq</code>)</p>
</td></tr>
<tr><td><code id="fgng_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fgng_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgng_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgng_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgng_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgng_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgng_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fgng_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fgng_+3A_ul">ul</code></td>
<td>
<p>scalar lower tail threshold</p>
</td></tr>
<tr><td><code id="fgng_+3A_sigmaul">sigmaul</code></td>
<td>
<p>scalar lower tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fgng_+3A_xil">xil</code></td>
<td>
<p>scalar lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgng_+3A_ur">ur</code></td>
<td>
<p>scalar upper tail threshold</p>
</td></tr>
<tr><td><code id="fgng_+3A_sigmaur">sigmaur</code></td>
<td>
<p>scalar upper tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fgng_+3A_xir">xir</code></td>
<td>
<p>scalar upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgng_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fgng_+3A_ulr">ulr</code></td>
<td>
<p>vector of length 2 giving lower and upper tail thresholds or
<code>NULL</code> for default values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with normal bulk and GPD for both tails is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>nmean</code>, <code>nsd</code>, <code>ul</code>, <code>sigmaul</code>, <code>xil</code>, <code>ur</code>, <code>sigmaur</code>, <code>xir</code>)
if thresholds are also estimated and
(<code>nmean</code>, <code>nsd</code>, <code>sigmaul</code>, <code>xil</code>, <code>sigmaur</code>, <code>xir</code>)
for profile likelihood or fixed threshold approach.
</p>
<p>The tail fractions <code>phiul</code> and <code>phiur</code> are treated separately to the other parameters, 
to allow for all their representations. In the fitting functions 
<code><a href="#topic+fgng">fgng</a></code> and
<code><a href="#topic+fgng">proflugng</a></code> they are logical:
</p>

<ul>
<li><p> default values <code>phiul=TRUE</code> and <code>phiur=TRUE</code> - tail fractions specified by 
normal distribution <code>pnorm(ul, nmean, nsd)</code> and survivior functions 
<code>1-pnorm(ur, nmean, nsd)</code> respectively and standard error is output as <code>NA</code>.
</p>
</li>
<li> <p><code>phiul=FALSE</code> and <code>phiur=FALSE</code> - treated as extra parameters estimated using
the MLE which is the sample proportion beyond the thresholds and 
standard error is output.
</p>
</li></ul>

<p>In the likelihood functions <code><a href="#topic+fgng">lgng</a></code>,
<code><a href="#topic+fgng">nlgng</a></code> and <code><a href="#topic+fgng">nlugng</a></code> 
it can be logical or numeric:
</p>

<ul>
<li><p> logical - same as for fitting functions with default values <code>phiul=TRUE</code> and <code>phiur=TRUE</code>.
</p>
</li>
<li><p> numeric - any value over range <code class="reqn">(0, 1)</code>. Notice that the tail
fraction probability cannot be 0 or 1 otherwise there would be no
contribution from either tail or bulk components respectively. Also,
<code>phiul+phiur&lt;1</code> as bulk must contribute.
</p>
</li></ul>

<p>If the profile likelihood approach is used, then a grid search over all combinations of both thresholds
is carried out. The combinations which lead to less than 5 in any datapoints beyond the thresholds are not considered.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fgng">lgng</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fgng">nlgng</a></code>
and <code><a href="#topic+fgng">nlugng</a></code>. Profile likelihood for both
thresholds given by <code><a href="#topic+fgng">proflugng</a></code>. Fitting function
<code><a href="#topic+fgng">fgng</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed thresholds, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ulseq</code>:     </td><td style="text-align: left;"> lower threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>urseq</code>:     </td><td style="text-align: left;"> upper threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold pair in (ulseq, urseq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:     </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:       </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ul</code>:        </td><td style="text-align: left;"> lower threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaul</code>:   </td><td style="text-align: left;"> MLE of lower tail GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xil</code>:       </td><td style="text-align: left;"> MLE of lower tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiul</code>:     </td><td style="text-align: left;"> MLE of lower tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiul</code>:  </td><td style="text-align: left;"> standard error of MLE of lower tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ur</code>:        </td><td style="text-align: left;"> upper threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaur</code>:   </td><td style="text-align: left;"> MLE of upper tail GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xir</code>:       </td><td style="text-align: left;"> MLE of upper tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiur</code>:     </td><td style="text-align: left;"> MLE of upper tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiur</code>:  </td><td style="text-align: left;"> standard error of MLE of upper tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Xin Zhao produced for MATLAB.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> lower threshold 10% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> upper threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters beyond threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Zhao, X., Scarrott, C.J. Reale, M. and Oxley, L. (2010). Extreme value modelling
for forecasting the market crisis. Applied Financial Econometrics 20(1), 63-72.
</p>
<p>Mendes, B. and H. F. Lopes (2004). Data driven estimates for mixtures. Computational
Statistics and Data Analysis 47(3), 583-598.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+itmnormgpd">itmnormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>,
<code><a href="#topic+lognormgpd">lognormgpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fitmgng">fitmgng</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gngcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other fgng: <code><a href="#topic+gng">gng</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Bulk model based tail fraction
fit = fgng(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgng(xx, nmean, nsd, ul, sigmaul, xil, phiul, 
   ur, sigmaur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
  
# Parameterised tail fraction
fit2 = fgng(x, phiul = FALSE, phiur = FALSE)
with(fit2, lines(xx, dgng(xx, nmean, nsd, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="blue"))
abline(v = c(fit2$ul, fit2$ur), col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fgng(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10))
fitfix = fgng(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgng(xx, nmean, nsd, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
with(fitu, lines(xx, dgng(xx, nmean, nsd, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="purple"))
abline(v = c(fitu$ul, fitu$ur), col = "purple")
with(fitfix, lines(xx, dgng(xx, nmean, nsd, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="darkgreen"))
abline(v = c(fitfix$ul, fitfix$ur), col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fgngcon'>MLE Fitting of Normal Bulk and GPD for Both Tails with 
Single Continuity Constraint at Both Thresholds Extreme Value Mixture Model</h2><span id='topic+fgngcon'></span><span id='topic+lgngcon'></span><span id='topic+nlgngcon'></span><span id='topic+proflugngcon'></span><span id='topic+nlugngcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with normal for bulk distribution between thresholds and conditional
GPDs for both tails with continuity at thresholds. With options for profile likelihood estimation for both thresholds and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgngcon(x, phiul = TRUE, phiur = TRUE, ulseq = NULL, urseq = NULL,
  fixedu = FALSE, pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lgngcon(x, nmean = 0, nsd = 1, ul = 0, xil = 0, phiul = TRUE,
  ur = 0, xir = 0, phiur = TRUE, log = TRUE)

nlgngcon(pvector, x, phiul = TRUE, phiur = TRUE, finitelik = FALSE)

proflugngcon(ulr, pvector, x, phiul = TRUE, phiur = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

nlugngcon(pvector, ul, ur, x, phiul = TRUE, phiur = TRUE,
  finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgngcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgngcon_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fgng">fgng</a></code></p>
</td></tr>
<tr><td><code id="fgngcon_+3A_ulseq">ulseq</code></td>
<td>
<p>vector of lower thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_urseq">urseq</code></td>
<td>
<p>vector of upper thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>ulseq</code>/<code>urseq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>ulseq</code>/<code>urseq</code>)</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgngcon_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_ul">ul</code></td>
<td>
<p>scalar lower tail threshold</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_xil">xil</code></td>
<td>
<p>scalar lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_ur">ur</code></td>
<td>
<p>scalar upper tail threshold</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_xir">xir</code></td>
<td>
<p>scalar upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fgngcon_+3A_ulr">ulr</code></td>
<td>
<p>vector of length 2 giving lower and upper tail thresholds or
<code>NULL</code> for default values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with normal bulk and GPD for both tails
with continuity at thresholds is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> and 
<code><a href="#topic+fgng">fgng</a></code>for details, type <code>help fnormgpd</code> and <code>help fgng</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmaul</code> and <code>sigmaur</code> parameters are now specified as function of
other parameters, see 
help for <code><a href="#topic+gngcon">dgngcon</a></code> for details, type <code>help gngcon</code>.
Therefore, <code>sigmaul</code> and <code>sigmaur</code> should not be included in the parameter
vector if initial values are provided, making the full parameter vector 
The full parameter vector is
(<code>nmean</code>, <code>nsd</code>, <code>ul</code>, <code>xil</code>, <code>ur</code>, <code>xir</code>)
if thresholds are also estimated and
(<code>nmean</code>, <code>nsd</code>, <code>xil</code>, <code>xir</code>)
for profile likelihood or fixed threshold approach.
</p>
<p>If the profile likelihood approach is used, then a grid search over all combinations of both thresholds
is carried out. The combinations which lead to less than 5 in any datapoints beyond the thresholds are not considered.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fgngcon">lgngcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fgngcon">nlgngcon</a></code>
and <code><a href="#topic+fgngcon">nlugngcon</a></code>. Profile likelihood for both
thresholds given by <code><a href="#topic+fgngcon">proflugngcon</a></code>. Fitting function
<code><a href="#topic+fgngcon">fgngcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed thresholds, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ulseq</code>:     </td><td style="text-align: left;"> lower threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>urseq</code>:     </td><td style="text-align: left;"> upper threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold pair in (ulseq, urseq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:     </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:       </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ul</code>:        </td><td style="text-align: left;"> lower threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaul</code>:   </td><td style="text-align: left;"> MLE of lower tail GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xil</code>:       </td><td style="text-align: left;"> MLE of lower tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiul</code>:     </td><td style="text-align: left;"> MLE of lower tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiul</code>:  </td><td style="text-align: left;"> standard error of MLE of lower tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ur</code>:        </td><td style="text-align: left;"> upper threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaur</code>:   </td><td style="text-align: left;"> MLE of upper tail GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xir</code>:       </td><td style="text-align: left;"> MLE of upper tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiur</code>:     </td><td style="text-align: left;"> MLE of upper tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiur</code>:  </td><td style="text-align: left;"> standard error of MLE of upper tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Xin Zhao produced for MATLAB.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> lower threshold 10% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> upper threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameters beyond threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Zhao, X., Scarrott, C.J. Reale, M. and Oxley, L. (2010). Extreme value modelling
for forecasting the market crisis. Applied Financial Econometrics 20(1), 63-72.
</p>
<p>Mendes, B. and H. F. Lopes (2004). Data driven estimates for mixtures. Computational
Statistics and Data Analysis 47(3), 583-598.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fhpdcon">fhpdcon</a></code>,
<code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>, <code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fitmgng">fitmgng</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gngcon: <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other fgngcon: <code><a href="#topic+gngcon">gngcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Continuity constraint
fit = fgngcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgngcon(xx, nmean, nsd, ul, xil, phiul,
   ur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
  
# No continuity constraint
fit2 = fgng(x)
with(fit2, lines(xx, dgng(xx, nmean, nsd, ul, sigmaul, xil, phiul,
   ur, sigmaur, xir, phiur), col="blue"))
abline(v = c(fit2$ul, fit2$ur), col = "blue")
legend("topleft", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fgngcon(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10))
fitfix = fgngcon(x, ulseq = seq(-2, -0.2, length = 10), 
 urseq = seq(0.2, 2, length = 10), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dgngcon(xx, nmean, nsd, ul, xil, phiul,
   ur, xir, phiur), col="red"))
abline(v = c(fit$ul, fit$ur), col = "red")
with(fitu, lines(xx, dgngcon(xx, nmean, nsd, ul, xil, phiul,
   ur, xir, phiur), col="purple"))
abline(v = c(fitu$ul, fitu$ur), col = "purple")
with(fitfix, lines(xx, dgngcon(xx, nmean, nsd, ul, xil, phiul,
   ur, xir, phiur), col="darkgreen"))
abline(v = c(fitfix$ul, fitfix$ur), col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fgpd'>MLE Fitting of Generalised Pareto Distribution (GPD)</h2><span id='topic+fgpd'></span><span id='topic+lgpd'></span><span id='topic+nlgpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the GPD with
parameters scale <code>sigmau</code> and shape <code>xi</code> to the threshold
exceedances, conditional on being above a threshold <code>u</code>. Unconditional
likelihood fitting also provided when the probability <code>phiu</code> of being
above the threshold <code>u</code> is given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgpd(x, u = 0, phiu = NULL, pvector = NULL, std.err = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

lgpd(x, u = 0, sigmau = 1, xi = 0, phiu = 1, log = TRUE)

nlgpd(pvector, x, u = 0, phiu = 1, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fgpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fgpd_+3A_u">u</code></td>
<td>
<p>scalar threshold</p>
</td></tr>
<tr><td><code id="fgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>NULL</code>, see Details</p>
</td></tr>
<tr><td><code id="fgpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of GPD parameters (<code>sigmau</code>, <code>xi</code>) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fgpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fgpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fgpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fgpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fgpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fgpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GPD is fitted to the exceedances of the threshold <code>u</code> using
maximum likelihood estimation. The estimated parameters, 
variance-covariance matrix and their standard errors are automatically 
output.
</p>
<p>The log-likelihood and negative log-likelihood are also provided for wider 
usage, e.g. constructing your own extreme value mixture model or profile
likelihood functions. The 
parameter vector <code>pvector</code> must be specified in the negative 
log-likelihood <code><a href="#topic+fgpd">nlgpd</a></code>.
</p>
<p>Log-likelihood calculations are carried out in 
<code><a href="#topic+fgpd">lgpd</a></code>, which takes parameters as inputs in the 
same form as distribution functions. The negative log-likelihood is a 
wrapper for <code><a href="#topic+fgpd">lgpd</a></code>, designed towards making it 
useable for optimisation (e.g. parameters are given a vector as first 
input).
</p>
<p>The default value for the tail fraction <code>phiu</code> in the fitting function
<code><a href="#topic+fgpd">fgpd</a></code> is <code>NULL</code>, in which case the MLE is calculated 
using the sample proportion of exceedances. In this case the standard error for <code>phiu</code> is 
estimated and output as <code>se.phiu</code>, otherwise it is set to <code>NA</code>. Consistent with the 
<code><a href="evd.html#topic+fpot">evd</a></code> library the missing values (<code>NA</code> and 
<code>NaN</code>) are assumed to be below the threshold in calculating the tail fraction.
</p>
<p>Otherwise, in the fitting function <code><a href="#topic+fgpd">fgpd</a></code> the tail 
fraction <code>phiu</code> can be specified as any value over <code class="reqn">(0, 1]</code>, i.e.
excludes <code class="reqn">\phi_u=0</code>, leading to the unconditional log-likelihood being
used for estimation. In this case the standard error will be output as <code>NA</code>.
</p>
<p>In the log-likelihood functions <code><a href="#topic+fgpd">lgpd</a></code> and 
<code><a href="#topic+fgpd">nlgpd</a></code> the tail fraction <code>phiu</code> cannot be
<code>NULL</code> but can be over the range <code class="reqn">[0, 1]</code>, i.e. which includes
<code class="reqn">\phi_u=0</code>.
</p>
<p>The value of <code>phiu</code> does not effect the GPD parameter estimates, only
the value of the likelihood, as:
</p>
<p style="text-align: center;"><code class="reqn">L(\sigma_u, \xi; u, \phi_u) = (\phi_u ^ {n_u}) L(\sigma_u, \xi; u,
  \phi_u=1)</code>
</p>

<p>where the GPD has scale <code class="reqn">\sigma_u</code> and shape <code class="reqn">\xi</code>, the threshold
is <code class="reqn">u</code> and <code class="reqn">nu</code> is the number of exceedances. A non-unit value for
<code>phiu</code> simply scales the likelihood and shifts the log-likelihood,
thus the GPD parameter estimates are invariant to <code>phiu</code>.
</p>
<p>The default optimisation algorithm is &quot;BFGS&quot;, which requires a finite
negative log-likelihood function evaluation <code>finitelik=TRUE</code>. For
invalid parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>.
The &quot;BFGS&quot; optimisation algorithms require finite values for likelihood, so
any user input for <code>finitelik</code> will be overridden and set to
<code>finitelik=TRUE</code> if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call.
</p>
<p>If the hessian is of reduced rank then the variance covariance (from
inverse hessian) and standard error of parameters cannot be calculated,
then by default <code>std.err=TRUE</code> and the function will stop. If you want
the parameter estimates even if the hessian is of reduced rank (e.g. in a
simulation study) then set <code>std.err=FALSE</code>.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fgpd">lgpd</a></code> gives (log-)likelihood and 
<code><a href="#topic+fgpd">nlgpd</a></code> gives the negative log-likelihood. 
<code><a href="#topic+fgpd">fgpd</a></code> returns a simple list with the following
elements
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>call</code>:     </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>x</code>:        </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>init</code>:     </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>optim</code>:    </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mle</code>:      </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>cov</code>:      </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>se</code>:       </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rate</code>:     </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nllh</code>:     </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>n</code>:        </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>u</code>:        </td><td style="text-align: left;"> threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sigmau</code>:   </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>xi</code>:       </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>phiu</code>:     </td><td style="text-align: left;"> MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>se.phiu</code>:  </td><td style="text-align: left;"> standard error of MLE of tail fraction (parameterised approach using sample proportion)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The output list has some duplicate entries and repeats some of the inputs to both 
provide similar items to those from <code><a href="evd.html#topic+fpot">fpot</a></code> and increase usability.
</p>


<h3>Acknowledgments</h3>

<p>Based on the <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code> and
<code><a href="evd.html#topic+fpot">fpot</a></code> functions in the 
<code><a href="ismev.html#topic+gpd.fit">ismev</a></code> and
<code><a href="evd.html#topic+fpot">evd</a></code> packages for which their author's contributions are gratefully acknowledged.
They are designed to have similar syntax and functionality to simplify the transition for users of these packages.
</p>


<h3>Note</h3>

<p>Unlike all the distribution functions for the GPD, the MLE fitting only
permits single scalar values for each parameter, <code>phiu</code> and threshold
<code>u</code>.
</p>
<p>When <code>pvector=NULL</code> then the initial values are calculated, type
<code>fgpd</code> to see the default formulae used. The GPD fitting is not very
sensitive to the initial values, so you will rarely have to  give
alternatives. Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>Default values for the threshold <code>u=0</code> and tail fraction
<code>phiu=NULL</code> are given in the fitting <code><a href="#topic+fgpd">fpgd</a></code>,
in which case the MLE assumes that excesses over the threshold are given,
rather than exceedances.
</p>
<p>The usual default of <code>phiu=1</code> is given in the likelihood functions
<code><a href="#topic+fgpd">lpgd</a></code> and <code><a href="#topic+fgpd">nlpgd</a></code>.
</p>
<p>The <code><a href="#topic+fgpd">lgpd</a></code> also has the usual defaults for the
other parameters, but <code><a href="#topic+fgpd">nlgpd</a></code> has no defaults.
</p>
<p>Infinite sample values are dropped in fitting function
<code><a href="#topic+fgpd">fpgd</a></code>, but missing values are used to estimate
<code>phiu</code> as described above. But in likelihood functions
<code><a href="#topic+fgpd">lpgd</a></code> and <code><a href="#topic+fgpd">nlpgd</a></code> both
infinite and missing values are ignored.
</p>
<p>Error checking of the inputs is carried out and will either stop or give
warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>


<h3>See Also</h3>

<p><code><a href="evd.html#topic+gpd">dgpd</a></code>, <code><a href="evd.html#topic+fpot">fpot</a></code> and
<code><a href="MASS.html#topic+fitdistr">fitdistr</a></code>
</p>
<p>Other gpd: <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other fgpd: <code><a href="#topic+gpd">gpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
par(mfrow = c(2, 1))

# GPD is conditional model for threshold exceedances
# so tail fraction phiu not relevant when only have exceedances
x = rgpd(1000, u = 10, sigmau = 5, xi = 0.2)
xx = seq(0, 100, 0.1)
hist(x, breaks = 100, freq = FALSE, xlim = c(0, 100))
lines(xx, dgpd(xx, u = 10, sigmau = 5, xi = 0.2))
fit = fgpd(x, u = 10)
lines(xx, dgpd(xx, u = fit$u, sigmau = fit$sigmau, xi = fit$xi), col="red")

# but tail fraction phiu is needed for conditional modelling of population tail
x = rnorm(10000)
xx = seq(-4, 4, 0.01)
hist(x, breaks = 200, freq = FALSE, xlim = c(0, 4))
lines(xx, dnorm(xx), lwd = 2)
fit = fgpd(x, u = 1)
lines(xx, dgpd(xx, u = fit$u, sigmau = fit$sigmau, xi = fit$xi, phiu = fit$phiu),
  col = "red", lwd = 2)
legend("topright", c("True Density","Fitted Density"), col=c("black", "red"), lty = 1)

</code></pre>

<hr>
<h2 id='fhpd'>MLE Fitting of Hybrid Pareto Extreme Value Mixture Model</h2><span id='topic+fhpd'></span><span id='topic+lhpd'></span><span id='topic+nlhpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the hybrid Pareto extreme
value mixture model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fhpd(x, pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lhpd(x, nmean = 0, nsd = 1, xi = 0, log = TRUE)

nlhpd(pvector, x, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fhpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fhpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters
(<code>nmean</code>, <code>nsd</code>, <code>xi</code>) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fhpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fhpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fhpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fhpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fhpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fhpd_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fhpd_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fhpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fhpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hybrid Pareto model is fitted to the entire dataset using maximum likelihood
estimation. The estimated parameters, variance-covariance matrix and their standard errors
are automatically output.
</p>
<p>The log-likelihood and negative log-likelihood are also provided for wider
usage, e.g. constructing profile likelihood functions. The parameter vector
<code>pvector</code> must be specified in the negative log-likelihood
<code><a href="#topic+fhpd">nlhpd</a></code>.
</p>
<p>Log-likelihood calculations are carried out in
<code><a href="#topic+fhpd">lhpd</a></code>, which takes parameters as inputs in
the same form as distribution functions. The negative log-likelihood is a
wrapper for <code><a href="#topic+fhpd">lhpd</a></code>, designed towards making
it useable for optimisation (e.g. parameters are given a vector as first
input).
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored,
which is inconsistent with the <code><a href="evd.html#topic+fpot">evd</a></code> library which assumes the 
missing values are below the threshold.
</p>
<p>The function <code><a href="#topic+fhpd">lhpd</a></code> carries out the calculations
for the log-likelihood directly, which can be exponentiated to give actual
likelihood using (<code>log=FALSE</code>).
</p>
<p>The default optimisation algorithm is &quot;BFGS&quot;, which requires a finite negative 
log-likelihood function evaluation <code>finitelik=TRUE</code>. For invalid 
parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>. The &quot;BFGS&quot; 
optimisation algorithms require finite values for likelihood, so any user 
input for <code>finitelik</code> will be overridden and set to <code>finitelik=TRUE</code> 
if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call.
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fhpd">lhpd</a></code> gives (log-)likelihood and 
<code><a href="#topic+fhpd">nlhpd</a></code> gives the negative log-likelihood. 
<code><a href="#topic+fhpd">fhpd</a></code> returns a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>call</code>:   </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>x</code>:      </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>init</code>:   </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>optim</code>:  </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mle</code>:    </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>cov</code>:    </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>se</code>:     </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rate</code>:   </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nllh</code>:   </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>n</code>:      </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nmean</code>:  </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nsd</code>:    </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>u</code>:      </td><td style="text-align: left;"> threshold (implicit from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>sigmau</code>: </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>xi</code>:     </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:    </td><td style="text-align: left;"> MLE of tail fraction (implied by <code>1/(1+pnorm(u,nmean,nsd))</code>)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The output list has some duplicate entries and repeats some of the inputs to both 
provide similar items to those from <code><a href="evd.html#topic+fpot">fpot</a></code> and to make it 
as useable as possible.
</p>


<h3>Note</h3>

<p>Unlike most of the distribution functions for the extreme value mixture models,
the MLE fitting only permits single scalar values for each parameter. Only the data is a vector.
</p>
<p>When <code>pvector=NULL</code> then the initial values are calculated, type 
<code>fhpd</code> to see the default formulae used. The mixture model fitting can be
***extremely*** sensitive to the initial values, so you if you get a poor fit then
try some alternatives. Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>A default value for the tail fraction <code>phiu=TRUE</code> is given. 
The <code><a href="#topic+fhpd">lhpd</a></code> also has the usual defaults for
the other parameters, but <code><a href="#topic+fhpd">nlhpd</a></code> has no defaults.
</p>
<p>Invalid parameter ranges will give <code>0</code> for likelihood, <code>log(0)=-Inf</code> for
log-likelihood and <code>-log(0)=Inf</code> for negative log-likelihood. 
</p>
<p>Infinite and missing sample values are dropped.
</p>
<p>Error checking of the inputs is carried out and will either stop or give warning message
as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Carreau, J. and Y. Bengio (2008). A hybrid Pareto model for asymmetric fat-tailed data:
the univariate case. Extremes 12 (1), 53-76.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>The condmixt package written by one of the
original authors of the hybrid Pareto model (Carreau and Bengio, 2008) also has 
similar functions for the likelihood of the hybrid Pareto 
(hpareto.negloglike) and fitting (hpareto.fit).
</p>
<p>Other hpd: <code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>
</p>
<p>Other hpdcon: <code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+itmnormgpd">itmnormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>,
<code><a href="#topic+lognormgpd">lognormgpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other fhpd: <code><a href="#topic+hpd">hpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Hybrid Pareto provides reasonable fit for some asymmetric heavy upper tailed distributions
# but not for cases such as the normal distribution
fit = fhpd(x, std.err = FALSE)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dhpd(xx, nmean, nsd, xi), col="red"))
abline(v = fit$u)

# Notice that if tail fraction is included a better fit is obtained
fit2 = fnormgpdcon(x, std.err = FALSE)
with(fit2, lines(xx, dnormgpdcon(xx, nmean, nsd, u, xi), col="blue"))
abline(v = fit2$u)
legend("topright", c("Standard Normal", "Hybrid Pareto", "Normal+GPD Continuous"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)
 
</code></pre>

<hr>
<h2 id='fhpdcon'>MLE Fitting of Hybrid Pareto Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+fhpdcon'></span><span id='topic+lhpdcon'></span><span id='topic+nlhpdcon'></span><span id='topic+profluhpdcon'></span><span id='topic+nluhpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the Hybrid Pareto extreme
value mixture model, with only continuity at threshold and not necessarily
continuous in first derivative. With options for profile likelihood estimation for
threshold and fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fhpdcon(x, useq = NULL, fixedu = FALSE, pvector = NULL,
  std.err = TRUE, method = "BFGS", control = list(maxit = 10000),
  finitelik = TRUE, ...)

lhpdcon(x, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd), xi = 0,
  log = TRUE)

nlhpdcon(pvector, x, finitelik = FALSE)

profluhpdcon(u, pvector, x, method = "BFGS", control = list(maxit =
  10000), finitelik = TRUE, ...)

nluhpdcon(pvector, u, x, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fhpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fhpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hybrid Pareto model is fitted to the entire dataset using maximum
likelihood estimation, with only continuity at threshold and not necessarily
continuous in first derivative. The estimated parameters, variance-covariance matrix
and their standard errors are automatically output.
</p>
<p>Note that the key difference between this model (<code>hpdcon</code>) and the 
normal with GPD tail and continuity at threshold (<code>normgpdcon</code>) is that the
latter includes the rescaling of the conditional GPD component
by the tail fraction to make it an unconditional tail model. However, for the hybrid
Pareto with single continuity constraint use the GPD in it's conditional form with no
differential scaling compared to the bulk model.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. Only
the different features are outlined below for brevity.
</p>
<p>The profile likelihood and fixed threshold approach functionality are implemented for this
version of the hybrid Pareto as it includes the threshold as a parameter. Whereas the usual
hybrid Pareto does not naturally have a threshold parameter.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+hpdcon">dhpdcon</a></code> for details, type <code>help hpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>nmean</code>, <code>nsd</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>nmean</code>, <code>nsd</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>


<h3>Value</h3>

<p><code><a href="#topic+fhpdcon">lhpdcon</a></code>, <code><a href="#topic+fhpdcon">nlhpdcon</a></code>,
and <code><a href="#topic+fhpdcon">nluhpdcon</a></code> give the log-likelihood,
negative log-likelihood and profile likelihood for threshold. Profile likelihood
for single threshold is given by <code><a href="#topic+fhpdcon">profluhpdcon</a></code>.
<code><a href="#topic+fhpdcon">fhpdcon</a></code> returns a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:    </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:       </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:    </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:  </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:    </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:   </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:     </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:     </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:      </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:    </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:    </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:       </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:   </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:     </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:       </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:  </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:      </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:    </td><td style="text-align: left;"> MLE of tail fraction (implied by <code>1/(1+pnorm(u,nmean,nsd))</code>)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>

<p>Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Carreau, J. and Y. Bengio (2008). A hybrid Pareto model for asymmetric fat-tailed data:
the univariate case. Extremes 12 (1), 53-76.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>The condmixt package written by one of the
original authors of the hybrid Pareto model (Carreau and Bengio, 2008) also has 
similar functions for the likelihood of the hybrid Pareto 
(hpareto.negloglike) and fitting (hpareto.fit).
</p>
<p>Other hpd: <code><a href="#topic+fhpd">fhpd</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>
</p>
<p>Other hpdcon: <code><a href="#topic+fhpd">fhpd</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>, <code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other fhpdcon: <code><a href="#topic+hpdcon">hpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Hybrid Pareto provides reasonable fit for some asymmetric heavy upper tailed distributions
# but not for cases such as the normal distribution

# Continuity constraint
fit = fhpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dhpdcon(xx, nmean, nsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = fhpd(x)
with(fit2, lines(xx, dhpd(xx, nmean, nsd, xi), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topleft", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fhpdcon(x, useq = seq(-2, 2, length = 20))
fitfix = fhpdcon(x, useq = seq(-2, 2, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dhpdcon(xx, nmean, nsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dhpdcon(xx, nmean, nsd, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dhpdcon(xx, nmean, nsd, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topleft", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)
  
# Notice that if tail fraction is included a better fit is obtained
fittailfrac = fnormgpdcon(x)

par(mfrow = c(1, 1))
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dhpdcon(xx, nmean, nsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fittailfrac, lines(xx, dnormgpdcon(xx, nmean, nsd, u, xi), col="blue"))
abline(v = fittailfrac$u)
legend("topright", c("Standard Normal", "Hybrid Pareto Continuous", "Normal+GPD Continuous"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='fitmgng'>MLE Fitting of Normal Bulk and GPD for Both Tails Interval Transition Mixture Model</h2><span id='topic+fitmgng'></span><span id='topic+litmgng'></span><span id='topic+nlitmgng'></span><span id='topic+profluitmgng'></span><span id='topic+nluitmgng'></span><span id='topic+profleuitmgng'></span><span id='topic+nleuitmgng'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with normal for bulk distribution between thresholds, conditional
GPDs beyond thresholds and interval transition. With options for profile likelihood
estimation for both thresholds and interval half-width, which can also be fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitmgng(x, eseq = NULL, ulseq = NULL, urseq = NULL,
  fixedeu = FALSE, pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

litmgng(x, nmean = 0, nsd = 1, epsilon = nsd, ul = 0,
  sigmaul = 1, xil = 0, ur = 0, sigmaur = 1, xir = 0,
  log = TRUE)

nlitmgng(pvector, x, finitelik = FALSE)

profleuitmgng(eulr, pvector, x, method = "BFGS", control = list(maxit =
  10000), finitelik = TRUE, ...)

nleuitmgng(pvector, epsilon, ul, ur, x, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitmgng_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_eseq">eseq</code></td>
<td>
<p>vector of epsilons (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_ulseq">ulseq</code></td>
<td>
<p>vector of lower thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_urseq">urseq</code></td>
<td>
<p>vector of upper thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_fixedeu">fixedeu</code></td>
<td>
<p>logical, should threshold and epsilon be fixed
(at either scalar value in <code>useq</code> and <code>eseq</code>,
or estimated from maximum of profile likelihood evaluated at
grid of thresholds and epsilons in <code>useq</code> and <code>eseq</code>)</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fitmgng_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_sigmaul">sigmaul</code></td>
<td>
<p>lower tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_xil">xil</code></td>
<td>
<p>lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_sigmaur">sigmaur</code></td>
<td>
<p>upper tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_xir">xir</code></td>
<td>
<p>upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fitmgng_+3A_eulr">eulr</code></td>
<td>
<p>vector of epsilon, lower and upper thresholds considered in profile likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with the normal bulk and GPD for both tails interval
transition is fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See <code><a href="#topic+itmgng">ditmgng</a></code> for explanation of GPD-normal-GPD interval
transition model, including mixing functions.
</p>
<p>See also help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>nmean</code>, <code>nsd</code>, <code>epsilon</code>, <code>ul</code>, <code>sigmaul</code>, <code>xil</code>,
<code>ur</code>, <code>sigmaur</code>, <code>xir</code>)
if thresholds and interval half-width are also estimated and
(<code>nmean</code>, <code>nsd</code>, <code>sigmaul</code>, <code>xil</code>, <code>sigmaur</code>, <code>xir</code>)
for profile likelihood or fixed threshold approach.
</p>
<p>If the profile likelihood approach is used, then a grid search over all combinations of epsilons and both thresholds
are carried out. The combinations which lead to less than 5 in any component outside of the
intervals are not considered.
</p>
<p>A fixed pair of thresholds and epsilon approach is acheived by setting a single
scalar value to each in <code>ulseq</code>, <code>urseq</code> and <code>eseq</code> respectively.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fitmgng">litmgng</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fitmgng">nlitmgng</a></code>
and <code><a href="#topic+fitmgng">nluitmgng</a></code>. Profile likelihood for 
thresholds and interval half-width given by <code><a href="#topic+fitmgng">profluitmgng</a></code>.
Fitting function <code><a href="#topic+fitmgng">fitmgng</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedeu</code>:   </td><td style="text-align: left;"> fixed epsilon and threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ulseq</code>:     </td><td style="text-align: left;"> lower threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>urseq</code>:     </td><td style="text-align: left;"> upper threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>eseq</code>:      </td><td style="text-align: left;"> interval half-width vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllheuseq</code>: </td><td style="text-align: left;"> profile negative log-likelihood at each combination in (eseq, ulseq, urseq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:     </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:       </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>epsilon</code>:   </td><td style="text-align: left;"> MLE of transition half-width</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ul</code>:        </td><td style="text-align: left;"> lower threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaul</code>:   </td><td style="text-align: left;"> MLE of lower tail GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xil</code>:       </td><td style="text-align: left;"> MLE of lower tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ur</code>:        </td><td style="text-align: left;"> upper threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmaur</code>:   </td><td style="text-align: left;"> MLE of upper tail GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xir</code>:       </td><td style="text-align: left;"> MLE of upper tail GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Xin Zhao produced for MATLAB.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> lower threshold 10% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> upper threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters beyond threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Holden, L. and Haug, O. (2013). A mixture model for unsupervised tail
estimation. arxiv:0902.4137
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fgng">fgng</a></code>, <code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other itmgng: <code><a href="#topic+itmgng">itmgng</a></code>
</p>
<p>Other itmnormgpd: <code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>,
<code><a href="#topic+itmgng">itmgng</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# MLE for complete parameter set (not recommended!)
fit = fitmgng(x)
hist(x, breaks = seq(-6, 6, 0.1), freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, ditmgng(xx, nmean, nsd, epsilon, ul, sigmaul, xil,
                                                     ur, sigmaur, xir), col="red"))
abline(v = fit$ul + fit$epsilon * seq(-1, 1), col = "red")
abline(v = fit$ur + fit$epsilon * seq(-1, 1), col = "darkred")
  
# Profile likelihood for threshold which is then fixed
fitfix = fitmgng(x, eseq = seq(0, 2, 0.1), ulseq = seq(-2.5, 0, 0.25), 
                                         urseq = seq(0, 2.5, 0.25), fixedeu = TRUE)
with(fitfix, lines(xx, ditmgng(xx, nmean, nsd, epsilon, ul, sigmaul, xil,
                                                      ur, sigmaur, xir), col="blue"))
abline(v = fitfix$ul + fitfix$epsilon * seq(-1, 1), col = "blue")
abline(v = fitfix$ur + fitfix$epsilon * seq(-1, 1), col = "darkblue")
legend("topright", c("True Density", "GPD-normal-GPD ITM", "Profile likelihood"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fitmnormgpd'>MLE Fitting of Normal Bulk and GPD Tail Interval Transition Mixture Model</h2><span id='topic+fitmnormgpd'></span><span id='topic+litmnormgpd'></span><span id='topic+nlitmnormgpd'></span><span id='topic+profluitmnormgpd'></span><span id='topic+nluitmnormgpd'></span><span id='topic+profleuitmnormgpd'></span><span id='topic+nleuitmnormgpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with the normal bulk and GPD tail interval transition mixture model.
With options for profile likelihood estimation for threshold and interval half-width,
which can both be fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitmnormgpd(x, eseq = NULL, useq = NULL, fixedeu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

litmnormgpd(x, nmean = 0, nsd = 1, epsilon = nsd, u = qnorm(0.9,
  nmean, nsd), sigmau = nsd, xi = 0, log = TRUE)

nlitmnormgpd(pvector, x, finitelik = FALSE)

profleuitmnormgpd(eu, pvector, x, method = "BFGS", control = list(maxit
  = 10000), finitelik = TRUE, ...)

nleuitmnormgpd(pvector, epsilon, u, x, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitmnormgpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_eseq">eseq</code></td>
<td>
<p>vector of epsilons (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_fixedeu">fixedeu</code></td>
<td>
<p>logical, should threshold and epsilon be fixed
(at either scalar value in <code>useq</code> and <code>eseq</code>,
or estimated from maximum of profile likelihood evaluated at
grid of thresholds and epsilons in <code>useq</code> and <code>eseq</code>)</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fitmnormgpd_+3A_eu">eu</code></td>
<td>
<p>vector of epsilon and threshold pair considered in profile likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with the normal bulk and GPD tail with interval
transition is fitted to the entire dataset using maximum likelihood estimation.
The estimated parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See <code><a href="#topic+itmnormgpd">ditmnormgpd</a></code> for explanation of normal-GPD interval
transition model, including mixing functions.
</p>
<p>See also help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for mixture model fitting details.
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>nmean</code>, <code>nsd</code>, <code>epsilon</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>)
if threshold and interval half-width are both estimated and
(<code>nmean</code>, <code>nsd</code>, <code>sigmau</code>, <code>xi</code>)
for profile likelihood or fixed threshold and epsilon approach.
</p>
<p>If the profile likelihood approach is used, then it is applied to both the threshold and
epsilon parameters together. A grid search over all combinations of epsilons and thresholds
are considered. The combinations which lead to less than 5 on either side of the interval are 
not considered.
</p>
<p>A fixed threshold and epsilon approach is acheived by setting a single scalar value to each in 
<code>useq</code> and <code>eseq</code> respectively.
</p>
<p>If the profile likelihood approach is used, then a grid search over all combinations of epsilon and threshold
are carried out. The combinations which lead to less than 5 in any any interval are not considered.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fitmnormgpd">litmnormgpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fitmnormgpd">nlitmnormgpd</a></code>
and <code><a href="#topic+fitmnormgpd">nluitmnormgpd</a></code>. Profile likelihood for
threshold and interval half-width given by <code><a href="#topic+fitmnormgpd">profluitmnormgpd</a></code>.
Fitting function <code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code> returns a simple list
with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedeu</code>:   </td><td style="text-align: left;"> fixed epsilon and threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>eseq</code>:      </td><td style="text-align: left;"> epsilon vector for profile likelihood or scalar for fixed epsilon</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllheuseq</code>: </td><td style="text-align: left;"> profile negative log-likelihood at each combination in (eseq, useq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:     </td><td style="text-align: left;"> MLE of normal shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:       </td><td style="text-align: left;"> MLE of normal scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>epsilon</code>:   </td><td style="text-align: left;"> MLE of transition half-width</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> epsilon is MLE of normal standard deviation;
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/normal_distribution">http://en.wikipedia.org/wiki/normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Holden, L. and Haug, O. (2013). A mixture model for unsupervised tail
estimation. arxiv:0902.4137
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+flognormgpd">flognormgpd</a></code>, <code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other itmnormgpd: <code><a href="#topic+fitmgng">fitmgng</a></code>,
<code><a href="#topic+itmgng">itmgng</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# MLE for complete parameter set
fit = fitmnormgpd(x)
hist(x, breaks = seq(-6, 6, 0.1), freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, ditmnormgpd(xx, nmean, nsd, epsilon, u, sigmau, xi), col="red"))
abline(v = fit$u + fit$epsilon * seq(-1, 1), col = "red")
  
# Profile likelihood for threshold which is then fixed
fitfix = fitmnormgpd(x, eseq = seq(0, 2, 0.1), useq = seq(0, 2.5, 0.1), fixedeu = TRUE)
with(fitfix, lines(xx, ditmnormgpd(xx, nmean, nsd, epsilon, u, sigmau, xi), col="blue"))
abline(v = fitfix$u + fitfix$epsilon * seq(-1, 1), col = "blue")
legend("topright", c("True Density", "normal-GPD ITM", "Profile likelihood"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fitmweibullgpd'>MLE Fitting of Weibull Bulk and GPD Tail Interval Transition Mixture Model</h2><span id='topic+fitmweibullgpd'></span><span id='topic+litmweibullgpd'></span><span id='topic+nlitmweibullgpd'></span><span id='topic+profluitmweibullgpd'></span><span id='topic+nluitmweibullgpd'></span><span id='topic+profleuitmweibullgpd'></span><span id='topic+nleuitmweibullgpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme valeu 
mixture model with the Weibull bulk and GPD tail interval transition mixture model.
With options for profile likelihood estimation for threshold and interval half-width,
which can both be fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitmweibullgpd(x, eseq = NULL, useq = NULL, fixedeu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

litmweibullgpd(x, wshape = 1, wscale = 1, epsilon = sqrt(wscale^2 *
  gamma(1 + 2/wshape) - (wscale * gamma(1 + 1/wshape))^2),
  u = qweibull(0.9, wshape, wscale), sigmau = sqrt(wscale^2 * gamma(1 +
  2/wshape) - (wscale * gamma(1 + 1/wshape))^2), xi = 0, log = TRUE)

nlitmweibullgpd(pvector, x, finitelik = FALSE)

profleuitmweibullgpd(eu, pvector, x, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nleuitmweibullgpd(pvector, epsilon, u, x, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitmweibullgpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_eseq">eseq</code></td>
<td>
<p>vector of epsilons (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_fixedeu">fixedeu</code></td>
<td>
<p>logical, should threshold and epsilon be fixed
(at either scalar value in <code>useq</code> and <code>eseq</code>,
or estimated from maximum of profile likelihood evaluated at
grid of thresholds and epsilons in <code>useq</code> and <code>eseq</code>)</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_wshape">wshape</code></td>
<td>
<p>scalar Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_wscale">wscale</code></td>
<td>
<p>scalar Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fitmweibullgpd_+3A_eu">eu</code></td>
<td>
<p>vector of epsilon and threshold pair considered in profile likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with the Weibull bulk and GPD tail with interval
transition is fitted to the entire dataset using maximum likelihood estimation.
The estimated parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See <code><a href="#topic+itmweibullgpd">ditmweibullgpd</a></code> for explanation of Weibull-GPD interval
transition model, including mixing functions.
</p>
<p>See also help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for mixture model fitting details.
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>wshape</code>, <code>wscale</code>, <code>epsilon</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>)
if threshold and interval half-width are both estimated and
(<code>wshape</code>, <code>wscale</code>, <code>sigmau</code>, <code>xi</code>)
for profile likelihood or fixed threshold and epsilon approach.
</p>
<p>If the profile likelihood approach is used, then it is applied to both the threshold and
epsilon parameters together. A grid search over all combinations of epsilons and thresholds
are considered. The combinations which lead to less than 5 on either side of the interval are 
not considered.
</p>
<p>A fixed threshold and epsilon approach is acheived by setting a single scalar value to each in 
<code>useq</code> and <code>eseq</code> respectively.
</p>
<p>If the profile likelihood approach is used, then a grid search over all combinations of epsilon and threshold
are carried out. The combinations which lead to less than 5 in any any interval are not considered.
</p>
<p>Negative data are ignored.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fitmweibullgpd">litmweibullgpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fitmweibullgpd">nlitmweibullgpd</a></code>
and <code><a href="#topic+fitmweibullgpd">nluitmweibullgpd</a></code>. Profile likelihood for
threshold and interval half-width given by <code><a href="#topic+fitmweibullgpd">profluitmweibullgpd</a></code>.
Fitting function <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code> returns a simple list
with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedeu</code>:   </td><td style="text-align: left;"> fixed epsilon and threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>eseq</code>:      </td><td style="text-align: left;"> epsilon vector for profile likelihood or scalar for fixed epsilon</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllheuseq</code>: </td><td style="text-align: left;"> profile negative log-likelihood at each combination in (eseq, useq)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>wshape</code>:    </td><td style="text-align: left;"> MLE of Weibull shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>wscale</code>:    </td><td style="text-align: left;"> MLE of Weibull scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>epsilon</code>:   </td><td style="text-align: left;"> MLE of transition half-width</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of Weibull parameters assuming entire population is Weibull; and
</p>
</li>
<li><p> epsilon is MLE of Weibull standard deviation;
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Holden, L. and Haug, O. (2013). A mixture model for unsupervised tail
estimation. arxiv:0902.4137
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Weibull">dweibull</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other weibullgpd: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other itmweibullgpd: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other fitmweibullgpd: <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rweibull(1000, shape = 1, scale = 2)
xx = seq(-0.2, 10, 0.01)
y = dweibull(xx, shape = 1, scale = 2)

# MLE for complete parameter set
fit = fitmweibullgpd(x)
hist(x, breaks = seq(0, 20, 0.1), freq = FALSE, xlim = c(-0.2, 10))
lines(xx, y)
with(fit, lines(xx, ditmweibullgpd(xx, wshape, wscale, epsilon, u, sigmau, xi), col="red"))
abline(v = fit$u + fit$epsilon * seq(-1, 1), col = "red")
  
# Profile likelihood for threshold which is then fixed
fitfix = fitmweibullgpd(x, eseq = seq(0, 2, 0.1), useq = seq(0.5, 4, 0.1), fixedeu = TRUE)
with(fitfix, lines(xx, ditmweibullgpd(xx, wshape, wscale, epsilon, u, sigmau, xi), col="blue"))
abline(v = fitfix$u + fitfix$epsilon * seq(-1, 1), col = "blue")
legend("topright", c("True Density", "Weibull-GPD ITM", "Profile likelihood"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fkden'>Cross-validation MLE Fitting of Kernel Density Estimator, With Variety of Kernels</h2><span id='topic+fkden'></span><span id='topic+lkden'></span><span id='topic+nlkden'></span>

<h3>Description</h3>

<p>Maximum (cross-validation) likelihood estimation for fitting kernel density estimator
for a variety of possible kernels, by treating it as a mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fkden(x, linit = NULL, bwinit = NULL, kernel = "gaussian",
  extracentres = NULL, add.jitter = FALSE, factor = 0.1,
  amount = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lkden(x, lambda = NULL, bw = NULL, kernel = "gaussian",
  extracentres = NULL, log = TRUE)

nlkden(lambda, x, bw = NULL, kernel = "gaussian",
  extracentres = NULL, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fkden_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fkden_+3A_linit">linit</code></td>
<td>
<p>initial value for bandwidth (as kernel half-width) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fkden_+3A_bwinit">bwinit</code></td>
<td>
<p>initial value for bandwidth (as kernel standard deviations) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fkden_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fkden_+3A_extracentres">extracentres</code></td>
<td>
<p>extra kernel centres used in KDE, 
but likelihood contribution not evaluated, or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fkden_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fkden_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fkden_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fkden_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fkden_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fkden_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fkden_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fkden_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fkden_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fkden_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fkden_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The kernel density estimator (KDE) with one of possible kernels is
fitted to the entire dataset using maximum (cross-validation) likelihood estimation.
The estimated bandwidth, variance and standard error are automatically output. 
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> used here but 
<code>bw</code> also output. The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code> help
documentation with the <code>"gaussian"</code> as the default choice.
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored.
</p>
<p>Cross-validation likelihood is used for kernel density component, obtained by
leaving each point out in turn and evaluating the KDE at the point left out:
</p>
<p style="text-align: center;"><code class="reqn">L(\lambda)\prod_{i=1}^{n} \hat{f}_{-i}(x_i)</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{-i}(x_i) = \frac{1}{(n-1)\lambda} \sum_{j=1: j\ne i}^{n} K(\frac{x_i - x_j}{\lambda})</code>
</p>

<p>is the KDE obtained when the <code class="reqn">i</code>th datapoint is dropped out and then 
evaluated at that dropped datapoint at <code class="reqn">x_i</code>.
</p>
<p>Normally for likelihood estimation of the bandwidth the kernel centres and
the data where the likelihood is evaluated are the same. However, when using
KDE for extreme value mixture modelling the likelihood only those data in the
bulk of the distribution should contribute to the likelihood, but all the
data (including those beyond the threshold) should contribute to the density
estimate. The <code>extracentres</code> option allows the use to specify extra
kernel centres used in estimating the density, but not evaluated in the
likelihood. Suppose the first <code>nb</code> data are below the threshold, followed
by <code>nu</code> exceedances of the threshold, so <code class="reqn">i = 1,\ldots,nb, nb+1, \ldots, nb+nu</code>.
The cross-validation likelihood using the extra kernel centres is then:
</p>
<p style="text-align: center;"><code class="reqn">L(\lambda)\prod_{i=1}^{nb} \hat{f}_{-i}(x_i)</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{-i}(x_i) = \frac{1}{(nb+nu-1)\lambda} \sum_{j=1: j\ne i}^{nb+nu} K(\frac{x_i - x_j}{\lambda})</code>
</p>

<p>which shows that the complete set of data is used in evaluating the KDE, but only those
below the threshold contribute to the cross-validation likelihood. The default is to
use the existing data, so <code>extracentres=NULL</code>.
</p>
<p>The following functions are provided:
</p>

<ul>
<li> <p><code><a href="#topic+fkden">fkden</a></code> - maximum (cross-validation) likelihood fitting with all the above options;
</p>
</li>
<li> <p><code><a href="#topic+fkden">lkden</a></code> - cross-validation log-likelihood;
</p>
</li>
<li> <p><code><a href="#topic+fkden">nlkden</a></code> - negative cross-validation log-likelihood;
</p>
</li></ul>

<p>The log-likelihood functions are provided for wider usage, e.g. constructing
profile likelihood functions.
</p>
<p>The log-likelihood and negative log-likelihood are also provided for wider
usage, e.g. constructing your own extreme value
mixture models or profile likelihood functions. The parameter
<code>lambda</code> must be specified in the negative log-likelihood
<code><a href="#topic+fkden">nlkden</a></code>.
</p>
<p>Log-likelihood calculations are carried out in
<code><a href="#topic+fkden">lkden</a></code>, which takes bandwidths as inputs in
the same form as distribution functions. The negative log-likelihood is a
wrapper for <code><a href="#topic+fkden">lkden</a></code>, designed towards making
it useable for optimisation (e.g. <code>lambda</code> given as first input).
</p>
<p>Defaults values for the bandwidth <code>linit</code> and <code>lambda</code> are given in the fitting 
<code><a href="#topic+fkden">fkden</a></code> and cross-validation likelihood functions
<code><a href="#topic+fkden">lkden</a></code>. The bandwidth <code>linit</code> must be specified in
the negative log-likelihood function <code><a href="#topic+fkden">nlkden</a></code>. 
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored,
which is inconsistent with the <code><a href="evd.html#topic+fpot">evd</a></code> library which assumes the 
missing values are below the threshold.
</p>
<p>The function <code><a href="#topic+fkden">lkden</a></code> carries out the calculations
for the log-likelihood directly, which can be exponentiated to give actual
likelihood using (<code>log=FALSE</code>).
</p>
<p>The default optimisation algorithm is &quot;BFGS&quot;, which requires a finite negative 
log-likelihood function evaluation <code>finitelik=TRUE</code>. For invalid 
parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>. The &quot;BFGS&quot; 
optimisation algorithms require finite values for likelihood, so any user 
input for <code>finitelik</code> will be overridden and set to <code>finitelik=TRUE</code> 
if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call or for common indicators of lack
of convergence (e.g. estimated bandwidth equal to initial value).
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fkden">lkden</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fkden">nlkden</a></code>.
Fitting function <code><a href="#topic+fkden">fkden</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:        </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:           </td><td style="text-align: left;"> (jittered) data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kerncentres</code>: </td><td style="text-align: left;"> actual kernel centres used <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:        </td><td style="text-align: left;"> <code>linit</code> for lambda</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:       </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:         </td><td style="text-align: left;"> vector of MLE of bandwidth</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:         </td><td style="text-align: left;"> variance of MLE of bandwidth</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:          </td><td style="text-align: left;"> standard error of MLE of bandwidth</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:        </td><td style="text-align: left;"> minimum negative cross-validation log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:           </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:      </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:          </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:      </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Warning</h3>

<p>Two important practical issues arise with MLE for the kernel bandwidth:
1) Cross-validation likelihood is needed for the KDE bandwidth parameter
as the usual likelihood degenerates, so that the MLE <code class="reqn">\hat{\lambda} \rightarrow 0</code> as
<code class="reqn">n \rightarrow \infty</code>, thus giving a negative bias towards a small bandwidth.
Leave one out cross-validation essentially ensures that some smoothing between the kernel centres
is required (i.e. a non-zero bandwidth), otherwise the resultant density estimates would always
be zero if the bandwidth was zero.
</p>
<p>This problem occassionally rears its ugly head for data which has been heavily rounded,
as even when using cross-validation the density can be non-zero even if the bandwidth is zero.
To overcome this issue an option to add a small jitter should be added to the data
(<code>x</code> only) has been included in the fitting inputs, using the 
<code><a href="base.html#topic+jitter">jitter</a></code> function, to remove the ties. The default options red in the 
<code><a href="base.html#topic+jitter">jitter</a></code> are specified above, but the user can override these.
Notice the default scaling <code>factor=0.1</code>, which is a tenth of the default value in the
<code><a href="base.html#topic+jitter">jitter</a></code>
function itself.
</p>
<p>A warning message is given if the data appear to be rounded
(i.e. more than 5
data rounding is the likely culprit. Only use the jittering when the MLE of
the bandwidth is far too small. 
</p>
<p>2) For heavy tailed populations the bandwidth is positively biased, giving oversmoothing
(see example). The bias is due to the distance between the upper (or lower) order statistics not
necessarily decaying to zero as the sample size tends to infinity. Essentially, as the distance
between the two largest (or smallest) sample datapoints does not decay to zero, some smoothing between
them is required (i.e. bandwidth cannot be zero). One solution to this problem is to trim
the data at a suitable threshold to remove the problematic tail from the inference for the bandwidth, 
using either the <code><a href="#topic+fkdengpd">fkdengpd</a></code> function for a single heavy tail
or the <code><a href="#topic+fgkg">fgkg</a></code> function
if both tails are heavy. See MacDonald et al (2013).
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>When <code>linit=NULL</code> then the initial value for the <code>lambda</code>
bandwidth is calculated 
using <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function and transformed using 
<code><a href="#topic+kfun">klambda</a></code> function.
</p>
<p>The extra kernel centres <code>extracentres</code> can either be a vector of data or <code>NULL</code>.
</p>
<p>Invalid parameter ranges will give <code>0</code> for likelihood, <code>log(0)=-Inf</code> for
log-likelihood and <code>-log(0)=Inf</code> for negative log-likelihood. 
</p>
<p>Infinite and missing sample values are dropped.
</p>
<p>Error checking of the inputs is carried out and will either stop or give warning message
as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="base.html#topic+jitter">jitter</a></code>, <code><a href="stats.html#topic+density">density</a></code> and
<code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other fkden: <code><a href="#topic+kden">kden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

nk=50
x = rnorm(nk)
xx = seq(-5, 5, 0.01)
fit = fkden(x)
hist(x, nk/5, freq = FALSE, xlim = c(-5, 5), ylim = c(0,0.6)) 
rug(x)
for (i in 1:nk) lines(xx, dnorm(xx, x[i], sd = fit$lambda)*0.05)
lines(xx,dnorm(xx), col = "black")
lines(xx, dkden(xx, x, lambda = fit$lambda), lwd = 2, col = "red")
lines(density(x), lty = 2, lwd = 2, col = "green")
lines(density(x, bw = fit$bw), lwd = 2, lty = 2,  col = "blue")
legend("topright", c("True Density", "KDE fitted evmix",
"KDE Using density, default bandwidth", "KDE Using density, c-v likelihood bandwidth"),
lty = c(1, 1, 2, 2), lwd = c(1, 2, 2, 2), col = c("black", "red", "green", "blue"))

par(mfrow = c(2, 1))

# bandwidth is biased towards oversmoothing for heavy tails
nk=100
x = rt(nk, df = 2)
xx = seq(-8, 8, 0.01)
fit = fkden(x)
hist(x, seq(floor(min(x)), ceiling(max(x)), 0.5), freq = FALSE, xlim = c(-8, 10)) 
rug(x)
for (i in 1:nk) lines(xx, dnorm(xx, x[i], sd = fit$lambda)*0.05)
lines(xx,dt(xx , df = 2), col = "black")
lines(xx, dkden(xx, x, lambda = fit$lambda), lwd = 2, col = "red")
legend("topright", c("True Density", "KDE fitted evmix, c-v likelihood bandwidth"),
lty = c(1, 1), lwd = c(1, 2), col = c("black", "red"))

# remove heavy tails from cv-likelihood evaluation, but still include them in KDE within likelihood
# often gives better bandwidth (see MacDonald et al (2011) for justification)
nk=100
x = rt(nk, df = 2)
xx = seq(-8, 8, 0.01)
fit2 = fkden(x[(x &gt; -4) &amp; (x &lt; 4)], extracentres = x[(x &lt;= -4) | (x &gt;= 4)])
hist(x, seq(floor(min(x)), ceiling(max(x)), 0.5), freq = FALSE, xlim = c(-8, 10)) 
rug(x)
for (i in 1:nk) lines(xx, dnorm(xx, x[i], sd = fit2$lambda)*0.05)
lines(xx,dt(xx , df = 2), col = "black")
lines(xx, dkden(xx, x, lambda = fit2$lambda), lwd = 2, col = "red")
lines(xx, dkden(xx, x, lambda = fit$lambda), lwd = 2, col = "blue")
legend("topright", c("True Density", "KDE fitted evmix, tails removed",
"KDE fitted evmix, tails included"),
lty = c(1, 1, 1), lwd = c(1, 2, 2), col = c("black", "red", "blue"))

## End(Not run)

</code></pre>

<hr>
<h2 id='fkdengpd'>MLE Fitting of Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fkdengpd'></span><span id='topic+lkdengpd'></span><span id='topic+nlkdengpd'></span><span id='topic+proflukdengpd'></span><span id='topic+nlukdengpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with kernel density estimate for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fkdengpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, kernel = "gaussian", add.jitter = FALSE,
  factor = 0.1, amount = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lkdengpd(x, lambda = NULL, u = 0, sigmau = 1, xi = 0,
  phiu = TRUE, bw = NULL, kernel = "gaussian", log = TRUE)

nlkdengpd(pvector, x, phiu = TRUE, kernel = "gaussian",
  finitelik = FALSE)

proflukdengpd(u, pvector, x, phiu = TRUE, kernel = "gaussian",
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

nlukdengpd(pvector, u, x, phiu = TRUE, kernel = "gaussian",
  finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fkdengpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_lambda">lambda</code></td>
<td>
<p>scalar bandwidth for kernel (as half-width of kernel)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_bw">bw</code></td>
<td>
<p>scalar bandwidth for kernel (as standard deviations of kernel)</p>
</td></tr>
<tr><td><code id="fkdengpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with kernel density estimate for bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>lambda</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>lambda</code>, <code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Cross-validation likelihood is used for KDE, but standard likelihood is used
for GPD component. See help for <code><a href="#topic+fkden">fkden</a></code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fkdengpd">lkdengpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fkdengpd">nlkdengpd</a></code>
and <code><a href="#topic+fkdengpd">nlukdengpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fkdengpd">proflukdengpd</a></code>. Fitting function
<code><a href="#topic+fkdengpd">fkdengpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:    </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:        </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:    </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code><a href="#topic+fkden">fkden</a></code>, type <code>help fkden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>The data and kernel centres are both vectors. Infinite and missing sample values
(and kernel centres) are dropped.
</p>
<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> normal reference rule for bandwidth, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other fkdengpd: <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Bulk model based tail fraction
fit = fkdengpd(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dkdengpd(xx, x, lambda, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = fkdengpd(x, phiu = FALSE)
with(fit2, lines(xx, dkdengpd(xx, x, lambda, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fkdengpd(x, useq = seq(0, 2, length = 20))
fitfix = fkdengpd(x, useq = seq(0, 2, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dkdengpd(xx, x, lambda, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dkdengpd(xx, x, lambda, u, sigmau, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dkdengpd(xx, x, lambda, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fkdengpdcon'>MLE Fitting of Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model
with Single Continuity Constraint</h2><span id='topic+fkdengpdcon'></span><span id='topic+lkdengpdcon'></span><span id='topic+nlkdengpdcon'></span><span id='topic+proflukdengpdcon'></span><span id='topic+nlukdengpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with kernel density estimate for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fkdengpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, kernel = "gaussian", add.jitter = FALSE,
  factor = 0.1, amount = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lkdengpdcon(x, lambda = NULL, u = 0, xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", log = TRUE)

nlkdengpdcon(pvector, x, phiu = TRUE, kernel = "gaussian",
  finitelik = FALSE)

proflukdengpdcon(u, pvector, x, phiu = TRUE, kernel = "gaussian",
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

nlukdengpdcon(pvector, u, x, phiu = TRUE, kernel = "gaussian",
  finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fkdengpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_add.jitter">add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_factor">factor</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_amount">amount</code></td>
<td>
<p>see <code><a href="base.html#topic+jitter">jitter</a></code></p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_lambda">lambda</code></td>
<td>
<p>scalar bandwidth for kernel (as half-width of kernel)</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_bw">bw</code></td>
<td>
<p>scalar bandwidth for kernel (as standard deviations of kernel)</p>
</td></tr>
<tr><td><code id="fkdengpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with kernel density estimate for bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+kdengpdcon">dkdengpdcon</a></code> for details, type <code>help kdengpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>lambda</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>lambda</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Cross-validation likelihood is used for KDE, but standard likelihood is used
for GPD component. See help for <code><a href="#topic+fkden">fkden</a></code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fkdengpdcon">lkdengpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fkdengpdcon">nlkdengpdcon</a></code>
and <code><a href="#topic+fkdengpdcon">nlukdengpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fkdengpdcon">proflukdengpdcon</a></code>. Fitting function
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:    </td><td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bw</code>:        </td><td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>kernel</code>:    </td><td style="text-align: left;"> kernel name</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code><a href="#topic+fkden">fkden</a></code>, type <code>help fkden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>The data and kernel centres are both vectors. Infinite and missing sample values
(and kernel centres) are dropped.
</p>
<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> normal reference rule for bandwidth, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+fkden">fkden</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other gkgcon: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fkdengpdcon: <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Continuity constraint
fit = fkdengpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dkdengpdcon(xx, x, lambda, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = fkdengpdcon(x)
with(fit2, lines(xx, dkdengpdcon(xx, x, lambda, u, xi), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topleft", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fkdengpdcon(x, useq = seq(0, 2, length = 20))
fitfix = fkdengpdcon(x, useq = seq(0, 2, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dkdengpdcon(xx, x, lambda, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dkdengpdcon(xx, x, lambda, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dkdengpdcon(xx, x, lambda, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='flognormgpd'>MLE Fitting of log-normal Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+flognormgpd'></span><span id='topic+llognormgpd'></span><span id='topic+nllognormgpd'></span><span id='topic+proflulognormgpd'></span><span id='topic+nlulognormgpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with log-normal for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flognormgpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

llognormgpd(x, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean, lnsd),
  sigmau = sqrt(lnmean) * lnsd, xi = 0, phiu = TRUE, log = TRUE)

nllognormgpd(pvector, x, phiu = TRUE, finitelik = FALSE)

proflulognormgpd(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlulognormgpd(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flognormgpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_lnmean">lnmean</code></td>
<td>
<p>scalar mean on log scale</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_lnsd">lnsd</code></td>
<td>
<p>scalar standard deviation on log scale (positive)</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="flognormgpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with log-normal bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>lnmean</code>, <code>lnsd</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>lnmean</code>, <code>lnsd</code>, <code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Non-positive data are ignored.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+flognormgpd">llognormgpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+flognormgpd">nllognormgpd</a></code>
and <code><a href="#topic+flognormgpd">nlulognormgpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+flognormgpd">proflulognormgpd</a></code>. Fitting function
<code><a href="#topic+flognormgpd">flognormgpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lnmean</code>:    </td><td style="text-align: left;"> MLE of log-normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lnsd</code>:      </td><td style="text-align: left;"> MLE of log-normal shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of log-normal parameters assuming entire population is log-normal; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Lognormal_distribution">http://en.wikipedia.org/wiki/Lognormal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Solari, S. and Losada, M.A. (2004). A unified statistical model for
hydrological variables including the selection of threshold for the peak over
threshold method. Water Resources Research. 48, W10541.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Lognormal">dlnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other lognormgpd: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>
<p>Other lognormgpdcon: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other flognormgpd: <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rlnorm(1000)
xx = seq(-0.1, 10, 0.01)
y = dlnorm(xx)

# Bulk model based tail fraction
fit = flognormgpd(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10), ylim = c(0, 0.8))
lines(xx, y)
with(fit, lines(xx, dlognormgpd(xx, lnmean, lnsd, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = flognormgpd(x, phiu = FALSE)
with(fit2, lines(xx, dlognormgpd(xx, lnmean, lnsd, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = flognormgpd(x, useq = seq(1, 5, length = 20))
fitfix = flognormgpd(x, useq = seq(1, 5, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10), ylim = c(0, 0.8))
lines(xx, y)
with(fit, lines(xx, dlognormgpd(xx, lnmean, lnsd, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dlognormgpd(xx, lnmean, lnsd, u, sigmau, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dlognormgpd(xx, lnmean, lnsd, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='flognormgpdcon'>MLE Fitting of log-normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+flognormgpdcon'></span><span id='topic+llognormgpdcon'></span><span id='topic+nllognormgpdcon'></span><span id='topic+proflulognormgpdcon'></span><span id='topic+nlulognormgpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with log-normal for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flognormgpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

llognormgpdcon(x, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean,
  lnsd), xi = 0, phiu = TRUE, log = TRUE)

nllognormgpdcon(pvector, x, phiu = TRUE, finitelik = FALSE)

proflulognormgpdcon(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlulognormgpdcon(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flognormgpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_lnmean">lnmean</code></td>
<td>
<p>scalar mean on log scale</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_lnsd">lnsd</code></td>
<td>
<p>scalar standard deviation on log scale (positive)</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="flognormgpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with log-normal bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+lognormgpdcon">dlognormgpdcon</a></code> for details, type <code>help lognormgpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>lnmean</code>, <code>lnsd</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>lnmean</code>, <code>lnsd</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Non-positive data are ignored.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+flognormgpdcon">llognormgpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+flognormgpdcon">nllognormgpdcon</a></code>
and <code><a href="#topic+flognormgpdcon">nlulognormgpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+flognormgpdcon">proflulognormgpdcon</a></code>. Fitting function
<code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lnmean</code>:    </td><td style="text-align: left;"> MLE of log-normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lnsd</code>:      </td><td style="text-align: left;"> MLE of log-normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of log-normal parameters assuming entire population is log-normal; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Lognormal_distribution">http://en.wikipedia.org/wiki/Lognormal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Solari, S. and Losada, M.A. (2004). A unified statistical model for
hydrological variables including the selection of threshold for the peak over
threshold method. Water Resources Research. 48, W10541.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Lognormal">dlnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other lognormgpd: <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>
<p>Other lognormgpdcon: <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other flognormgpdcon: <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rlnorm(1000)
xx = seq(-0.1, 10, 0.01)
y = dlnorm(xx)

# Continuity constraint
fit = flognormgpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10), ylim = c(0, 0.8))
lines(xx, y)
with(fit, lines(xx, dlognormgpdcon(xx, lnmean, lnsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = flognormgpd(x, phiu = FALSE)
with(fit2, lines(xx, dlognormgpd(xx, lnmean, lnsd, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = flognormgpdcon(x, useq = seq(1, 5, length = 20))
fitfix = flognormgpdcon(x, useq = seq(1, 5, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10), ylim = c(0, 0.8))
lines(xx, y)
with(fit, lines(xx, dlognormgpdcon(xx, lnmean, lnsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dlognormgpdcon(xx, lnmean, lnsd, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dlognormgpdcon(xx, lnmean, lnsd, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fmgamma'>MLE Fitting of Mixture of Gammas Using EM Algorithm</h2><span id='topic+fmgamma'></span><span id='topic+lmgamma'></span><span id='topic+nlmgamma'></span><span id='topic+nlEMmgamma'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the mixture of gammas distribution
using the EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmgamma(x, M, pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lmgamma(x, mgshape, mgscale, mgweight, log = TRUE)

nlmgamma(pvector, x, M, finitelik = FALSE)

nlEMmgamma(pvector, tau, mgweight, x, M, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fmgamma_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_m">M</code></td>
<td>
<p>number of gamma components in mixture</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of GPD parameters (<code>sigmau</code>, <code>xi</code>) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fmgamma_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fmgamma_+3A_mgshape">mgshape</code></td>
<td>
<p>mgamma shape (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgamma_+3A_mgscale">mgscale</code></td>
<td>
<p>mgamma scale (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgamma_+3A_mgweight">mgweight</code></td>
<td>
<p>mgamma weights (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgamma_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fmgamma_+3A_tau">tau</code></td>
<td>
<p>matrix of posterior probability of being in each component
(<code>nxM</code> where <code>n</code> is <code>length(x)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weighted mixture of gammas distribution is fitted to the entire
dataset by maximum likelihood estimation using the EM algorithm. The estimated parameters,
variance-covariance matrix and their standard errors are automatically output.
</p>
<p>The expectation step estimates the expected probability of being in each component
conditional on gamma component parameters. The maximisation step optimizes the
negative log-likelihood conditional on posterior probabilities of each observation
being in each component.
</p>
<p>The optimisation of the likelihood for these mixture models can be very sensitive to
the initial parameter vector, as often there are numerous local modes. This is an
inherent feature of such models and the EM algorithm. The EM algorithm is guaranteed
to reach the maximum of the local mode. Multiple initial values should be considered
to find the global maximum. If the <code>pvector</code> is input as <code>NULL</code> then 
random component probabilities are simulated as the initial values, so multiple such runs
should be run to check the sensitivity to initial values. Alternatives to black-box
likelihood optimisers (e.g. simulated annealing), or moving to computational Bayesian
inference, are also worth considering.
</p>
<p>The log-likelihood functions are provided for wider usage, e.g. constructing profile
likelihood functions. The parameter vector <code>pvector</code> must be specified in the
negative log-likelihood functions <code><a href="#topic+fmgamma">nlmgamma</a></code> and
<code><a href="#topic+fmgamma">nlEMmgamma</a></code>.
</p>
<p>Log-likelihood calculations are carried out in <code><a href="#topic+fmgamma">lmgamma</a></code>,
which takes parameters as inputs in the same form as the distribution functions. The
negative log-likelihood function <code><a href="#topic+fmgamma">nlmgamma</a></code> is a wrapper
for <code><a href="#topic+fmgamma">lmgamma</a></code> designed towards making it useable for optimisation,
i.e. <code><a href="#topic+fmgamma">nlmgamma</a></code> has complete parameter vector as first input.
Similarly, for the maximisation step negative log-likelihood
<code><a href="#topic+fmgamma">nlEMmgamma</a></code>, which also has the second input as the component
probability vector <code>mgweight</code>.
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored.
</p>
<p>The function <code><a href="#topic+fnormgpd">lnormgpd</a></code> carries out the calculations
for the log-likelihood directly, which can be exponentiated to give actual
likelihood using (<code>log=FALSE</code>).
</p>
<p>The default optimisation algorithm in the &quot;maximisation step&quot; is &quot;BFGS&quot;, which
requires a finite negative 
log-likelihood function evaluation <code>finitelik=TRUE</code>. For invalid 
parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>. The &quot;BFGS&quot; 
optimisation algorithms require finite values for likelihood, so any user 
input for <code>finitelik</code> will be overridden and set to <code>finitelik=TRUE</code> 
if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call or for common indicators of lack
of convergence (e.g. any estimated parameters same as initial values).
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>. 
</p>
<p>Suppose there are <code class="reqn">M</code> gamma components with (scalar) shape and scale parameters and
weight for each component. Only <code class="reqn">M-1</code> are to be provided in the initial parameter
vector, as the <code class="reqn">M</code>th components weight is uniquely determined from the others.
</p>
<p>For the fitting function <code><a href="#topic+fmgamma">fmgamma</a></code> and negative log-likelihood
functions the parameter vector <code>pvector</code> is a <code>3*M-1</code> length vector
containing all <code class="reqn">M</code> gamma component shape parameters first, 
followed by the corresponding <code class="reqn">M</code> gamma scale parameters,
then all the corresponding <code class="reqn">M-1</code> probability weight parameters. The full parameter vector
is then <code>c(mgshape, mgscale, mgweight[1:(M-1)])</code>.
</p>
<p>For the maximisation step negative log-likelihood functions the parameter vector
<code>pvector</code> is a <code>2*M</code> length vector containing all <code class="reqn">M</code> gamma component
shape parameters first followed by the corresponding <code class="reqn">M</code> gamma scale parameters. The
partial parameter vector is then <code>c(mgshape, mgscale)</code>.
</p>
<p>For identifiability purposes the mean of each gamma component must be in ascending in order. 
If the initial parameter vector does not satisfy this constraint then an error is given. 
</p>
<p>Non-positive data are ignored as likelihood is infinite, except for <code>gshape=1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fmgamma">lmgamma</a></code> and it's
wrapper for negative log-likelihood from <code><a href="#topic+fmgamma">nlmgamma</a></code>. 
The conditional negative log-likelihood
using the posterior probabilities is given by <code><a href="#topic+fmgamma">nlEMmgamma</a></code>.
Fitting function <code><a href="#topic+fmgammagpd">fmgammagpd</a></code> using EM algorithm returns
a simple list with the following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>M</code>:         </td><td style="text-align: left;"> number of gamma components</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgshape</code>:   </td><td style="text-align: left;"> MLE of gamma shapes</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgscale</code>:   </td><td style="text-align: left;"> MLE of gamma scales</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgweight</code>:  </td><td style="text-align: left;"> MLE of gamma weights</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>EMresults</code>: </td><td style="text-align: left;"> EM results giving complete negative log-likelihood, estimated parameters
                        and conditional "maximisation step" negative log-likelihood and convergence result</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>posterior</code>: </td><td style="text-align: left;"> posterior probabilites</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>Thanks to Daniela Laas, University of St Gallen, Switzerland for reporting various bugs in these functions.
</p>


<h3>Note</h3>

<p>In the fitting and profile likelihood functions, when <code>pvector=NULL</code> then the default initial values
are obtained under the following scheme:
</p>

<ul>
<li><p> number of sample from each component is simulated from symmetric multinomial distribution;
</p>
</li>
<li><p> sample data is then sorted and split into groups of this size (works well when components
have modes which are well separated);
</p>
</li>
<li><p> for data within each component approximate MLE's for the
gamma shape and scale parameters are estimated.
</p>
</li></ul>

<p>The <code><a href="#topic+fmgamma">lmgamma</a></code>, <code><a href="#topic+fmgamma">nlmgamma</a></code> and
<code><a href="#topic+fmgamma">nlEMmgamma</a></code> have no defaults.
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>. 
</p>
<p>Invalid parameter ranges will give <code>0</code> for likelihood, <code>log(0)=-Inf</code> for
log-likelihood and <code>-log(0)=Inf</code> for negative log-likelihood. 
</p>
<p>Infinite and missing sample values are dropped.
</p>
<p>Error checking of the inputs is carried out and will either stop or give warning message
as appropriate.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Mixture_model">http://en.wikipedia.org/wiki/Mixture_model</a>
</p>
<p>McLachlan, G.J. and Peel, D. (2000). Finite Mixture Models. Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">dgamma</a></code> and <code><a href="mixtools.html#topic+gammamixEM">gammamixEM</a></code>
in <code>mixtools</code> package
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other mgamma: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fmgamma: <code><a href="#topic+mgamma">mgamma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = c(rgamma(1000, shape = 1, scale = 1), rgamma(3000, shape = 6, scale = 2))
xx = seq(-1, 40, 0.01)
y = (dgamma(xx, shape = 1, scale = 1) + 3 * dgamma(xx, shape = 6, scale = 2))/4

# Fit by EM algorithm
fit = fmgamma(x, M = 2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, y)
with(fit, lines(xx, dmgamma(xx, mgshape, mgscale, mgweight), col="red"))

## End(Not run)

</code></pre>

<hr>
<h2 id='fmgammagpd'>MLE Fitting of Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model
using the EM algorithm.</h2><span id='topic+fmgammagpd'></span><span id='topic+lmgammagpd'></span><span id='topic+nlmgammagpd'></span><span id='topic+nlumgammagpd'></span><span id='topic+proflumgammagpd'></span><span id='topic+nlEMmgammagpd'></span><span id='topic+nluEMmgammagpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with mixture of gammas for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmgammagpd(x, M, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lmgammagpd(x, mgshape, mgscale, mgweight, u, sigmau, xi, phiu = TRUE,
  log = TRUE)

nlmgammagpd(pvector, x, M, phiu = TRUE, finitelik = FALSE)

nlumgammagpd(pvector, u, x, M, phiu = TRUE, finitelik = FALSE)

nlEMmgammagpd(pvector, tau, mgweight, x, M, phiu = TRUE,
  finitelik = FALSE)

proflumgammagpd(u, pvector, x, M, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nluEMmgammagpd(pvector, u, tau, mgweight, x, M, phiu = TRUE,
  finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fmgammagpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_m">M</code></td>
<td>
<p>number of gamma components in mixture</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_mgshape">mgshape</code></td>
<td>
<p>mgamma shape (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_mgscale">mgscale</code></td>
<td>
<p>mgamma scale (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_mgweight">mgweight</code></td>
<td>
<p>mgamma weights (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fmgammagpd_+3A_tau">tau</code></td>
<td>
<p>matrix of posterior probability of being in each component
(<code>nxM</code> where <code>n</code> is <code>length(x)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with weighted mixture of gammas bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation using the EM algorithm. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The expectation step estimates the expected probability of being in each component
conditional on gamma component parameters. The maximisation step optimizes the
negative log-likelihood conditional on posterior probabilities of each observation
being in each component.
</p>
<p>The optimisation of the likelihood for these mixture models can be very sensitive to
the initial parameter vector, as often there are numerous local modes. This is an
inherent feature of such models and the EM algorithm. The EM algorithm is guaranteed
to reach the maximum of the local mode. Multiple initial values should be considered
to find the global maximum. If the <code>pvector</code> is input as <code>NULL</code> then 
random component probabilities are simulated as the initial values, so multiple such runs
should be run to check the sensitivity to initial values. Alternatives to black-box
likelihood optimisers (e.g. simulated annealing), or moving to computational Bayesian
inference, are also worth considering.
</p>
<p>The log-likelihood functions are provided for wider usage, e.g. constructing profile
likelihood functions. The parameter vector <code>pvector</code> must be specified in the
negative log-likelihood functions <code><a href="#topic+fmgammagpd">nlmgammagpd</a></code> and
<code><a href="#topic+fmgammagpd">nlEMmgammagpd</a></code>.
</p>
<p>Log-likelihood calculations are carried out in <code><a href="#topic+fmgammagpd">lmgammagpd</a></code>,
which takes parameters as inputs in the same form as the distribution functions. The
negative log-likelihood function <code><a href="#topic+fmgammagpd">nlmgammagpd</a></code> is a wrapper
for <code><a href="#topic+fmgammagpd">lmgammagpd</a></code> designed towards making it useable for optimisation,
i.e. <code><a href="#topic+fmgammagpd">nlmgammagpd</a></code> has complete parameter vector as first input.
Though it is not directly used for optimisation here, as the EM algorithm due to mixture of
gammas for the bulk component of this model
</p>
<p>The EM algorithm for the mixture of gammas utilises the
negative log-likelihood function <code><a href="#topic+fmgammagpd">nlEMmgammagpd</a></code>
which takes the posterior probabilities <code class="reqn">tau</code> and component probabilities
<code>mgweight</code> as secondary inputs.
</p>
<p>The profile likelihood for the threshold <code><a href="#topic+fmgammagpd">proflumgammagpd</a></code>
also implements the EM algorithm for the mixture of gammas, utilising the negative
log-likelihood function <code><a href="#topic+fmgammagpd">nluEMmgammagpd</a></code> which takes
the threshold, posterior probabilities <code class="reqn">tau</code> and component probabilities
<code>mgweight</code> as secondary inputs. 
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored.
</p>
<p>Suppose there are <code class="reqn">M</code> gamma components with (scalar) shape and scale parameters and
weight for each component. Only <code class="reqn">M-1</code> are to be provided in the initial parameter
vector, as the <code class="reqn">M</code>th components weight is uniquely determined from the others.
</p>
<p>The initial parameter vector <code>pvector</code> always has the <code class="reqn">M</code> gamma component
shape parameters followed by the corresponding <code class="reqn">M</code> gamma scale parameters. However,
subsets of the other parameters are needed depending on which function is being used:
</p>

<ul>
<li> <p>fmgammagpd - <code>c(mgshape, mgscale, mgweight[1:(M-1)], u, sigmau, xi)</code>
</p>
</li>
<li> <p>nlmgammagpd - <code>c(mgshape, mgscale, mgweight[1:(M-1)], u, sigmau, xi)</code>
</p>
</li>
<li> <p>nlumgammagpd and proflumgammagpd - <code>c(mgshape, mgscale, mgweight[1:(M-1)], sigmau, xi)</code>
</p>
</li>
<li> <p>nlEMmgammagpd - <code>c(mgshape, mgscale, u, sigmau, xi)</code>
</p>
</li>
<li> <p>nluEMmgammagpd - <code>c(mgshape, mgscale, sigmau, xi)</code>
</p>
</li></ul>

<p>Notice that when the component probability weights are included only the first <code class="reqn">M-1</code> 
are specified, as the remaining one can be uniquely determined from these. Where some
parameters are left out, they are always taken as secondary inputs to the functions.
</p>
<p>For identifiability purposes the mean of each gamma component must be in ascending in order. 
If the initial parameter vector does not satisfy this constraint then an error is given. 
</p>
<p>Non-positive data are ignored as likelihood is infinite, except for <code>gshape=1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fmgammagpd">lmgammagpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fmgammagpd">nlmgammagpd</a></code>
and <code><a href="#topic+fmgammagpd">nlumgammagpd</a></code>. The conditional negative log-likelihoods
using the posterior probabilities are  <code><a href="#topic+fmgammagpd">nlEMmgammagpd</a></code>
and <code><a href="#topic+fmgammagpd">nluEMmgammagpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fmgammagpd">proflumgammagpd</a></code> using EM algorithm. Fitting function
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code> using EM algorithm returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>M</code>:         </td><td style="text-align: left;"> number of gamma components</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgshape</code>:   </td><td style="text-align: left;"> MLE of gamma shapes</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgscale</code>:   </td><td style="text-align: left;"> MLE of gamma scales</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgweight</code>:  </td><td style="text-align: left;"> MLE of gamma weights</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>EMresults</code>: </td><td style="text-align: left;"> EM results giving complete negative log-likelihood, estimated parameters
                        and conditional "maximisation step" negative log-likelihood and convergence result</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>posterior</code>: </td><td style="text-align: left;"> posterior probabilites</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>Thanks to Daniela Laas, University of St Gallen, Switzerland for reporting various bugs in these functions.
</p>
<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>In the fitting and profile likelihood functions, when <code>pvector=NULL</code> then the
default initial values are obtained under the following scheme:
</p>

<ul>
<li><p> number of sample from each component is simulated from symmetric multinomial distribution;
</p>
</li>
<li><p> sample data is then sorted and split into groups of this size (works well when components
have modes which are well separated);
</p>
</li>
<li><p> for data within each component approximate MLE's for the
gamma shape and scale parameters are estimated;
</p>
</li>
<li><p> threshold is specified as sample 90% quantile; and 
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>

<p>The other likelihood functions <code><a href="#topic+fmgammagpd">lmgammagpd</a></code>,
<code><a href="#topic+fmgammagpd">nlmgammagpd</a></code>, <code><a href="#topic+fmgammagpd">nlumgammagpd</a></code> and
<code><a href="#topic+fmgammagpd">nlEMmgammagpd</a></code> and <code><a href="#topic+fmgammagpd">nluEMmgammagpd</a></code>
have no defaults.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Mixture_model">http://en.wikipedia.org/wiki/Mixture_model</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>McLachlan, G.J. and Peel, D. (2000). Finite Mixture Models. Wiley.
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>do Nascimento, F.F., Gamerman, D. and Lopes, H.F. (2011). A semiparametric
Bayesian approach to extreme value estimation. Statistical Computing, 22(2), 661-675.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">dgamma</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other mgamma: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fmgammagpd: <code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

n=1000
x = c(rgamma(n*0.25, shape = 1, scale = 1), rgamma(n*0.75, shape = 6, scale = 2))
xx = seq(-1, 40, 0.01)
y = (0.25*dgamma(xx, shape = 1, scale = 1) + 0.75 * dgamma(xx, shape = 6, scale = 2))

# Bulk model based tail fraction
# very sensitive to initial values, so best to provide sensible ones
fit.noinit = fmgammagpd(x, M = 2)
fit.withinit = fmgammagpd(x, M = 2, pvector = c(1, 6, 1, 2, 0.5, 15, 4, 0.1))
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, y)
with(fit.noinit, lines(xx, dmgammagpd(xx, mgshape, mgscale, mgweight, u, sigmau, xi),
 col="red"))
abline(v = fit.noinit$u, col = "red")
with(fit.withinit, lines(xx, dmgammagpd(xx, mgshape, mgscale, mgweight, u, sigmau, xi),
 col="green"))
abline(v = fit.withinit$u, col = "green")
  
# Parameterised tail fraction
fit2 = fmgammagpd(x, M = 2, phiu = FALSE, pvector = c(1, 6, 1, 2, 0.5, 15, 4, 0.1))
with(fit2, lines(xx, dmgammagpd(xx, mgshape, mgscale, mgweight, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Default pvector", "Sensible pvector", 
 "Parameterised Tail Fraction"), col=c("black", "red", "green", "blue"), lty = 1)
  
# Fixed threshold approach
fitfix = fmgammagpd(x, M = 2, useq = 15, fixedu = TRUE,
   pvector = c(1, 6, 1, 2, 0.5, 4, 0.1))

hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, y)
with(fit.withinit, lines(xx, dmgammagpd(xx, mgshape, mgscale, mgweight, u, sigmau, xi), col="red"))
abline(v = fit.withinit$u, col = "red")
with(fitfix, lines(xx, dmgammagpd(xx,mgshape, mgscale, mgweight, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density", "Default initial value (90% quantile)", 
 "Fixed threshold approach"), col=c("black", "red", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fmgammagpdcon'>MLE Fitting of Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model
with Single Continuity Constraint using the EM algorithm.</h2><span id='topic+fmgammagpdcon'></span><span id='topic+lmgammagpdcon'></span><span id='topic+nlmgammagpdcon'></span><span id='topic+nlumgammagpdcon'></span><span id='topic+proflumgammagpdcon'></span><span id='topic+nlEMmgammagpdcon'></span><span id='topic+nluEMmgammagpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with mixture of gammas for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmgammagpdcon(x, M, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lmgammagpdcon(x, mgshape, mgscale, mgweight, u, xi, phiu = TRUE,
  log = TRUE)

nlmgammagpdcon(pvector, x, M, phiu = TRUE, finitelik = FALSE)

nlumgammagpdcon(pvector, u, x, M, phiu = TRUE, finitelik = FALSE)

nlEMmgammagpdcon(pvector, tau, mgweight, x, M, phiu = TRUE,
  finitelik = FALSE)

proflumgammagpdcon(u, pvector, x, M, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nluEMmgammagpdcon(pvector, u, tau, mgweight, x, M, phiu = TRUE,
  finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fmgammagpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_m">M</code></td>
<td>
<p>number of gamma components in mixture</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_mgshape">mgshape</code></td>
<td>
<p>mgamma shape (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_mgscale">mgscale</code></td>
<td>
<p>mgamma scale (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_mgweight">mgweight</code></td>
<td>
<p>mgamma weights (positive) as vector of length <code>M</code></p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
<tr><td><code id="fmgammagpdcon_+3A_tau">tau</code></td>
<td>
<p>matrix of posterior probability of being in each component
(<code>nxM</code> where <code>n</code> is <code>length(x)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with weighted mixture of gammas bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation using the EM algorithm. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The expectation step estimates the expected probability of being in each component
conditional on gamma component parameters. The maximisation step optimizes the
negative log-likelihood conditional on posterior probabilities of each observation
being in each component.
</p>
<p>The optimisation of the likelihood for these mixture models can be very sensitive to
the initial parameter vector, as often there are numerous local modes. This is an
inherent feature of such models and the EM algorithm. The EM algorithm is guaranteed
to reach the maximum of the local mode. Multiple initial values should be considered
to find the global maximum. If the <code>pvector</code> is input as <code>NULL</code> then 
random component probabilities are simulated as the initial values, so multiple such runs
should be run to check the sensitivity to initial values. Alternatives to black-box
likelihood optimisers (e.g. simulated annealing), or moving to computational Bayesian
inference, are also worth considering.
</p>
<p>The log-likelihood functions are provided for wider usage, e.g. constructing profile
likelihood functions. The parameter vector <code>pvector</code> must be specified in the
negative log-likelihood functions <code><a href="#topic+fmgammagpdcon">nlmgammagpdcon</a></code> and
<code><a href="#topic+fmgammagpdcon">nlEMmgammagpdcon</a></code>.
</p>
<p>Log-likelihood calculations are carried out in <code><a href="#topic+fmgammagpdcon">lmgammagpdcon</a></code>,
which takes parameters as inputs in the same form as the distribution functions. The
negative log-likelihood function <code><a href="#topic+fmgammagpdcon">nlmgammagpdcon</a></code> is a wrapper
for <code><a href="#topic+fmgammagpdcon">lmgammagpdcon</a></code> designed towards making it useable for optimisation,
i.e. <code><a href="#topic+fmgammagpdcon">nlmgammagpdcon</a></code> has complete parameter vector as first input.
Though it is not directly used for optimisation here, as the EM algorithm due to mixture of
gammas for the bulk component of this model
</p>
<p>The EM algorithm for the mixture of gammas utilises the
negative log-likelihood function <code><a href="#topic+fmgammagpdcon">nlEMmgammagpdcon</a></code>
which takes the posterior probabilities <code class="reqn">tau</code> and component probabilities
<code>mgweight</code> as secondary inputs.
</p>
<p>The profile likelihood for the threshold <code><a href="#topic+fmgammagpdcon">proflumgammagpdcon</a></code>
also implements the EM algorithm for the mixture of gammas, utilising the negative
log-likelihood function <code><a href="#topic+fmgammagpdcon">nluEMmgammagpdcon</a></code> which takes
the threshold, posterior probabilities <code class="reqn">tau</code> and component probabilities
<code>mgweight</code> as secondary inputs. 
</p>
<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored.
</p>
<p>Suppose there are <code class="reqn">M</code> gamma components with (scalar) shape and scale parameters and
weight for each component. Only <code class="reqn">M-1</code> are to be provided in the initial parameter
vector, as the <code class="reqn">M</code>th components weight is uniquely determined from the others.
</p>
<p>The initial parameter vector <code>pvector</code> always has the <code class="reqn">M</code> gamma component
shape parameters followed by the corresponding <code class="reqn">M</code> gamma scale parameters. However,
subsets of the other parameters are needed depending on which function is being used:
</p>

<ul>
<li> <p>fmgammagpdcon - <code>c(mgshape, mgscale, mgweight[1:(M-1)], u, xi)</code>
</p>
</li>
<li> <p>nlmgammagpdcon - <code>c(mgshape, mgscale, mgweight[1:(M-1)], u, xi)</code>
</p>
</li>
<li> <p>nlumgammagpdcon and proflumgammagpdcon - <code>c(mgshape, mgscale, mgweight[1:(M-1)], xi)</code>
</p>
</li>
<li> <p>nlEMmgammagpdcon - <code>c(mgshape, mgscale, u, xi)</code>
</p>
</li>
<li> <p>nluEMmgammagpdcon - <code>c(mgshape, mgscale, xi)</code>
</p>
</li></ul>

<p>Notice that when the component probability weights are included only the first <code class="reqn">M-1</code> 
are specified, as the remaining one can be uniquely determined from these. Where some
parameters are left out, they are always taken as secondary inputs to the functions.
</p>
<p>For identifiability purposes the mean of each gamma component must be in ascending in order. 
If the initial parameter vector does not satisfy this constraint then an error is given. 
</p>
<p>Non-positive data are ignored as likelihood is infinite, except for <code>gshape=1</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fmgammagpdcon">lmgammagpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fmgammagpdcon">nlmgammagpdcon</a></code>
and <code><a href="#topic+fmgammagpdcon">nlumgammagpdcon</a></code>. The conditional negative log-likelihoods
using the posterior probabilities are  <code><a href="#topic+fmgammagpdcon">nlEMmgammagpdcon</a></code>
and <code><a href="#topic+fmgammagpdcon">nluEMmgammagpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fmgammagpdcon">proflumgammagpdcon</a></code> using EM algorithm. Fitting function
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code> using EM algorithm returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>M</code>:         </td><td style="text-align: left;"> number of gamma components</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgshape</code>:   </td><td style="text-align: left;"> MLE of gamma shapes</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgscale</code>:   </td><td style="text-align: left;"> MLE of gamma scales</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mgweight</code>:  </td><td style="text-align: left;"> MLE of gamma weights</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>EMresults</code>: </td><td style="text-align: left;"> EM results giving complete negative log-likelihood, estimated parameters
                        and conditional "maximisation step" negative log-likelihood and convergence result</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>posterior</code>: </td><td style="text-align: left;"> posterior probabilites</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>Thanks to Daniela Laas, University of St Gallen, Switzerland for reporting various bugs in these functions.
</p>
<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>In the fitting and profile likelihood functions, when <code>pvector=NULL</code> then the
default initial values are obtained under the following scheme:
</p>

<ul>
<li><p> number of sample from each component is simulated from symmetric multinomial distribution;
</p>
</li>
<li><p> sample data is then sorted and split into groups of this size (works well when components
have modes which are well separated);
</p>
</li>
<li><p> for data within each component approximate MLE's for the
gamma shape and scale parameters are estimated;
</p>
</li>
<li><p> threshold is specified as sample 90% quantile; and 
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>

<p>The other likelihood functions <code><a href="#topic+fmgammagpdcon">lmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">nlmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpdcon">nlumgammagpdcon</a></code> and
<code><a href="#topic+fmgammagpdcon">nlEMmgammagpdcon</a></code> and <code><a href="#topic+fmgammagpdcon">nluEMmgammagpdcon</a></code>
have no defaults.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Mixture_model">http://en.wikipedia.org/wiki/Mixture_model</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>McLachlan, G.J. and Peel, D. (2000). Finite Mixture Models. Wiley.
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>do Nascimento, F.F., Gamerman, D. and Lopes, H.F. (2011). A semiparametric
Bayesian approach to extreme value estimation. Statistical Computing, 22(2), 661-675.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">dgamma</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other gammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>
</p>
<p>Other mgamma: <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fmgammagpdcon: <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

n=1000
x = c(rgamma(n*0.25, shape = 1, scale = 1), rgamma(n*0.75, shape = 6, scale = 2))
xx = seq(-1, 40, 0.01)
y = (0.25*dgamma(xx, shape = 1, scale = 1) + 0.75 * dgamma(xx, shape = 6, scale = 2))

# Bulk model based tail fraction
# very sensitive to initial values, so best to provide sensible ones
fit.noinit = fmgammagpdcon(x, M = 2)
fit.withinit = fmgammagpdcon(x, M = 2, pvector = c(1, 6, 1, 2, 0.5, 15, 0.1))
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, y)
with(fit.noinit, lines(xx, dmgammagpdcon(xx, mgshape, mgscale, mgweight, u, xi), col="red"))
abline(v = fit.noinit$u, col = "red")
with(fit.withinit, lines(xx, dmgammagpdcon(xx, mgshape, mgscale, mgweight, u, xi), col="green"))
abline(v = fit.withinit$u, col = "green")
  
# Parameterised tail fraction
fit2 = fmgammagpdcon(x, M = 2, phiu = FALSE, pvector = c(1, 6, 1, 2, 0.5, 15, 0.1))
with(fit2, lines(xx, dmgammagpdcon(xx, mgshape, mgscale, mgweight, u, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Default pvector", "Sensible pvector",
 "Parameterised Tail Fraction"), col=c("black", "red", "green", "blue"), lty = 1)
  
# Fixed threshold approach
fitfix = fmgammagpdcon(x, M = 2, useq = 15, fixedu = TRUE,
   pvector = c(1, 6, 1, 2, 0.5, 0.1))

hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, y)
with(fit.withinit, lines(xx, dmgammagpdcon(xx, mgshape, mgscale, mgweight, u, xi), col="red"))
abline(v = fit.withinit$u, col = "red")
with(fitfix, lines(xx, dmgammagpdcon(xx,mgshape, mgscale, mgweight, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density", "Default initial value (90% quantile)",
 "Fixed threshold approach"), col=c("black", "red", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fnormgpd'>MLE Fitting of Normal Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fnormgpd'></span><span id='topic+lnormgpd'></span><span id='topic+nlnormgpd'></span><span id='topic+proflunormgpd'></span><span id='topic+nlunormgpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with normal for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnormgpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lnormgpd(x, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  sigmau = nsd, xi = 0, phiu = TRUE, log = TRUE)

nlnormgpd(pvector, x, phiu = TRUE, finitelik = FALSE)

proflunormgpd(u, pvector = NULL, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlunormgpd(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnormgpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fnormgpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with normal bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>The optimisation of the likelihood for these mixture models can be very sensitive to
the initial parameter vector (particularly the threshold), as often there are numerous
local modes where multiple thresholds give similar fits. This is an inherent feature
of such models. Options are provided by the arguments <code>pvector</code>,
<code>useq</code> and <code>fixedu</code> to implement various commonly used likelihood inference
approaches for such models:
</p>

<ol>
<li><p> (default) <code>pvector=NULL</code>, <code>useq=NULL</code> and <code>fixedu=FALSE</code> 
- to set initial value for threshold at 90% quantile along with usual defaults for
other parameters as defined in Notes below. Standard likelihood optimisation is used;
</p>
</li>
<li> <p><code>pvector=c(nmean, nsd, u, sigmau, xi)</code> - where initial values of all
5 parameters are manually set. Standard likelihood optimisation is used;
</p>
</li>
<li> <p><code>useq</code> as vector - to specify a sequence of thresholds at which to evaluate
profile likelihood and extract threshold which gives maximum profile likelihood; or
</p>
</li>
<li> <p><code>useq</code> as scalar - to specify a single value for threshold to be considered.
</p>
</li></ol>

<p>In options (3) and (4) the threshold can be treated as: 
</p>

<ul>
<li><p> initial value for maximum likelihood estimation when <code>fixedu=FALSE</code>, using
either profile likelihood estimate (3) or pre-chosen threshold (4); or
</p>
</li>
<li><p> a fixed threshold with MLE for other parameters when <code>fixedu=TRUE</code>, using
either profile likelihood estimate (3) or pre-chosen threshold (4).
</p>
</li></ul>

<p>The latter approach can be used to implement the traditional fixed threshold modelling
approach with threshold pre-chosen using, for example, graphical diagnostics. Further,
in either such case (3) or (4) the <code>pvector</code> could be:
</p>

<ul>
<li> <p><code>NULL</code> for usual defaults for other four parameters, defined in Notes below; or
</p>
</li>
<li><p> vector of initial values for remaining 4 parameters 
(<code>nmean</code>, <code>nsd</code>, <code>sigmau</code>, <code>xi</code>).
</p>
</li></ul>

<p>If the threshold is treated as fixed, then the likelihood is separable between the bulk
and tail components. However, in practice we have found black-box optimisation of the
combined likelihood works sufficiently well, so is used herein.
</p>
<p>The following functions are provided:
</p>

<ul>
<li> <p><code><a href="#topic+fnormgpd">fnormgpd</a></code> - maximum likelihood fitting with all the above options;
</p>
</li>
<li> <p><code><a href="#topic+fnormgpd">lnormgpd</a></code> - log-likelihood;
</p>
</li>
<li> <p><code><a href="#topic+fnormgpd">nlnormgpd</a></code> - negative log-likelihood;
</p>
</li>
<li> <p><code><a href="#topic+fnormgpd">proflunormgpd</a></code> - profile likelihood for given threshold; and
</p>
</li>
<li> <p><code><a href="#topic+fnormgpd">nlunormgpd</a></code> - negative log-likelihood (threshold specified separately).
</p>
</li></ul>

<p>The log-likelihood functions are provided for wider usage, e.g. constructing
profile likelihood functions.
</p>
<p>Defaults values for the parameter vector <code>pvector</code> are given in the fitting 
<code><a href="#topic+fnormgpd">fnormgpd</a></code> and profile likelihood functions
<code><a href="#topic+fnormgpd">proflunormgpd</a></code>. The parameter vector <code>pvector</code>
must be specified in the negative log-likelihood functions 
<code><a href="#topic+fnormgpd">nlnormgpd</a></code> and <code><a href="#topic+fnormgpd">nlunormgpd</a></code>. 
The threshold <code>u</code> must also be specified in the profile likelihood function
<code><a href="#topic+fnormgpd">proflunormgpd</a></code> and <code><a href="#topic+fnormgpd">nlunormgpd</a></code>.
</p>
<p>Log-likelihood calculations are carried out in <code><a href="#topic+fnormgpd">lnormgpd</a></code>,
which takes parameters as inputs in the same form as distribution functions. The negative
log-likelihood functions <code><a href="#topic+fnormgpd">nlnormgpd</a></code> and
<code><a href="#topic+fnormgpd">nlunormgpd</a></code> are wrappers for likelihood function
<code><a href="#topic+fnormgpd">lnormgpd</a></code> designed towards optimisation, 
i.e. <code><a href="#topic+fnormgpd">nlnormgpd</a></code> has vector of all 5 parameters as
first input and <code><a href="#topic+fnormgpd">nlunormgpd</a></code> has threshold as second input
and vector of remaining 4 parameters as first input. The profile likelihood
function <code><a href="#topic+fnormgpd">proflunormgpd</a></code> has threshold <code>u</code> as the first
input, to permit use of <code><a href="base.html#topic+lapply">sapply</a></code> function to evaluate profile
likelihood over vector of potential thresholds. 
</p>
<p>The tail fraction <code>phiu</code> is treated separately to the other parameters, 
to allow for all it's representations. In the fitting 
<code><a href="#topic+fnormgpd">fnormgpd</a></code> and profile likelihood function
<code><a href="#topic+fnormgpd">proflunormgpd</a></code> it is logical:
</p>

<ul>
<li><p> default value <code>phiu=TRUE</code> - tail fraction specified by 
normal survivor function <code>phiu = 1 - pnorm(u, nmean, nsd)</code> and standard error is
output as <code>NA</code>; and
</p>
</li>
<li> <p><code>phiu=FALSE</code> - treated as extra parameter estimated using the MLE which is
the sample proportion above the threshold and standard error is output.
</p>
</li></ul>

<p>In the likelihood functions <code><a href="#topic+fnormgpd">lnormgpd</a></code>,
<code><a href="#topic+fnormgpd">nlnormgpd</a></code> and <code><a href="#topic+fnormgpd">nlunormgpd</a></code> 
it can be logical or numeric:
</p>

<ul>
<li><p> logical - same as for fitting functions with default value <code>phiu=TRUE</code>.
</p>
</li>
<li><p> numeric - any value over range <code class="reqn">(0, 1)</code>. Notice that the tail
fraction probability cannot be 0 or 1 otherwise there would be no
contribution from either tail or bulk components respectively.
</p>
</li></ul>

<p>Missing values (<code>NA</code> and <code>NaN</code>) are assumed to be invalid data so are ignored,
which is inconsistent with the <code><a href="evd.html#topic+fpot">evd</a></code> library which assumes the 
missing values are below the threshold.
</p>
<p>The function <code><a href="#topic+fnormgpd">lnormgpd</a></code> carries out the calculations
for the log-likelihood directly, which can be exponentiated to give actual
likelihood using (<code>log=FALSE</code>).
</p>
<p>The default optimisation algorithm is &quot;BFGS&quot;, which requires a finite negative 
log-likelihood function evaluation <code>finitelik=TRUE</code>. For invalid 
parameters, a zero likelihood is replaced with <code>exp(-1e6)</code>. The &quot;BFGS&quot; 
optimisation algorithms require finite values for likelihood, so any user 
input for <code>finitelik</code> will be overridden and set to <code>finitelik=TRUE</code> 
if either of these optimisation methods is chosen.
</p>
<p>It will display a warning for non-zero convergence result comes from 
<code><a href="stats.html#topic+optim">optim</a></code> function call or for common indicators of lack
of convergence (e.g. any estimated parameters same as initial values).
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fnormgpd">lnormgpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fnormgpd">nlnormgpd</a></code>
and <code><a href="#topic+fnormgpd">nlunormgpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fnormgpd">proflunormgpd</a></code>. Fitting function
<code><a href="#topic+fnormgpd">fnormgpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:     </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:       </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The output list has some duplicate entries and repeats some of the inputs to both 
provide similar items to those from <code><a href="evd.html#topic+fpot">fpot</a></code> and increase usability.
</p>


<h3>Acknowledgments</h3>

<p>These functions are deliberately similar
in syntax and functionality to the commonly used functions in the
<code><a href="ismev.html#topic+gpd.fit">ismev</a></code> and <code><a href="evd.html#topic+fpot">evd</a></code> packages
for which their author's contributions are gratefully acknowledged.
</p>
<p>Anna MacDonald and Xin Zhao laid some of the groundwork with programs they
wrote for MATLAB.
</p>
<p>Clement Lee and Emma Eastoe suggested providing inbuilt
profile likelihood estimation for threshold and fixed threshold approach.
</p>


<h3>Note</h3>

<p>Unlike most of the distribution functions for the extreme value mixture models,
the MLE fitting only permits single scalar values for each parameter and 
<code>phiu</code>.
</p>
<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>

<p>Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>A default value for the tail fraction <code>phiu=TRUE</code> is given. 
The <code><a href="#topic+fnormgpd">lnormgpd</a></code> also has the usual defaults for
the other parameters, but <code><a href="#topic+fnormgpd">nlnormgpd</a></code> and
<code><a href="#topic+fnormgpd">nlunormgpd</a></code> has no defaults.
</p>
<p>If the hessian is of reduced rank then the variance covariance (from inverse hessian)
and standard error of parameters cannot be calculated, then by default 
<code>std.err=TRUE</code> and the function will stop. If you want the parameter estimates
even if the hessian is of reduced rank (e.g. in a simulation study) then
set <code>std.err=FALSE</code>. 
</p>
<p>Invalid parameter ranges will give <code>0</code> for likelihood, <code>log(0)=-Inf</code> for
log-likelihood and <code>-log(0)=Inf</code> for negative log-likelihood. 
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the data/quantiles.
</p>
<p>Infinite and missing sample values are dropped.
</p>
<p>Error checking of the inputs is carried out and will either stop or give warning message
as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fitmgng">fitmgng</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other fnormgpd: <code><a href="#topic+normgpd">normgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Bulk model based tail fraction
fit = fnormgpd(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dnormgpd(xx, nmean, nsd, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = fnormgpd(x, phiu = FALSE)
with(fit2, lines(xx, dnormgpd(xx, nmean, nsd, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topleft", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fnormgpd(x, useq = seq(0, 3, length = 20))
fitfix = fnormgpd(x, useq = seq(0, 3, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dnormgpd(xx, nmean, nsd, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dnormgpd(xx, nmean, nsd, u, sigmau, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dnormgpd(xx, nmean, nsd, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topleft", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fnormgpdcon'>MLE Fitting of Normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+fnormgpdcon'></span><span id='topic+lnormgpdcon'></span><span id='topic+nlnormgpdcon'></span><span id='topic+proflunormgpdcon'></span><span id='topic+nlunormgpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with normal for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnormgpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lnormgpdcon(x, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  xi = 0, phiu = TRUE, log = TRUE)

nlnormgpdcon(pvector, x, phiu = TRUE, finitelik = FALSE)

proflunormgpdcon(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nlunormgpdcon(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnormgpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_nmean">nmean</code></td>
<td>
<p>scalar normal mean</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_nsd">nsd</code></td>
<td>
<p>scalar normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fnormgpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with normal bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for full details, type <code>help fnormgpd</code>. Only
the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+normgpdcon">dnormgpdcon</a></code> for details, type <code>help normgpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>nmean</code>, <code>nsd</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>nmean</code>, <code>nsd</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fnormgpdcon">lnormgpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fnormgpdcon">nlnormgpdcon</a></code>
and <code><a href="#topic+fnormgpdcon">nlunormgpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fnormgpdcon">proflunormgpdcon</a></code>. Fitting function
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nmean</code>:     </td><td style="text-align: left;"> MLE of normal mean</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nsd</code>:       </td><td style="text-align: left;"> MLE of normal standard deviation</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of normal parameters assuming entire population is normal; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gngcon: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other fnormgpdcon: <code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Continuity constraint
fit = fnormgpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dnormgpdcon(xx, nmean, nsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = fnormgpd(x)
with(fit2, lines(xx, dnormgpd(xx, nmean, nsd, u, sigmau, xi), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topleft", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fnormgpdcon(x, useq = seq(0, 3, length = 20))
fitfix = fnormgpdcon(x, useq = seq(0, 3, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 4))
lines(xx, y)
with(fit, lines(xx, dnormgpdcon(xx, nmean, nsd, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dnormgpdcon(xx, nmean, nsd, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dnormgpdcon(xx, nmean, nsd, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topleft", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fpsden'>MLE Fitting of P-splines Density Estimator</h2><span id='topic+fpsden'></span><span id='topic+lpsden'></span><span id='topic+nlpsden'></span><span id='topic+iwlspsden'></span><span id='topic+cvpsden'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for P-splines density estimation. Histogram binning
produces frequency counts, which are modelled by constrained B-splines in a Poisson regression. A penalty
based on differences in the sequences B-spline coefficients is used to smooth/interpolate the counts.
Iterated weighted least squares (IWLS) for a mixed model representation of the P-splines regression,
conditional on a particular penalty coefficient, is used for estimating the B-spline coefficients.
Leave-one-out cross-validation deviances are available for estimation of the penalty coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpsden(x, lambdaseq = NULL, breaks = NULL, xrange = NULL,
  nseg = 10, degree = 3, design.knots = NULL, ord = 2)

lpsden(x, beta = NULL, bsplines = NULL, nbinwidth = 1, log = TRUE)

nlpsden(pvector, x, bsplines = NULL, nbinwidth = 1,
  finitelik = FALSE)

cvpsden(lambda = 1, counts, bsplines, ord = 2)

iwlspsden(counts, bsplines, ord = 2, lambda = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fpsden_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="fpsden_+3A_lambdaseq">lambdaseq</code></td>
<td>
<p>vector of <code class="reqn">\lambda</code>'s (or scalar) to be considered in profile likelihood. Required.</p>
</td></tr>
<tr><td><code id="fpsden_+3A_breaks">breaks</code></td>
<td>
<p>histogram breaks (as in <code><a href="graphics.html#topic+hist">hist</a></code> function)</p>
</td></tr>
<tr><td><code id="fpsden_+3A_xrange">xrange</code></td>
<td>
<p>vector of minimum and maximum of B-spline (support of density)</p>
</td></tr>
<tr><td><code id="fpsden_+3A_nseg">nseg</code></td>
<td>
<p>number of segments between knots</p>
</td></tr>
<tr><td><code id="fpsden_+3A_degree">degree</code></td>
<td>
<p>degree of B-splines (0 is constant, 1 is linear, etc.)</p>
</td></tr>
<tr><td><code id="fpsden_+3A_design.knots">design.knots</code></td>
<td>
<p>spline knots for splineDesign function</p>
</td></tr>
<tr><td><code id="fpsden_+3A_ord">ord</code></td>
<td>
<p>order of difference used in the penalty term</p>
</td></tr>
<tr><td><code id="fpsden_+3A_beta">beta</code></td>
<td>
<p>vector of B-spline coefficients (required)</p>
</td></tr>
<tr><td><code id="fpsden_+3A_bsplines">bsplines</code></td>
<td>
<p>matrix of B-splines</p>
</td></tr>
<tr><td><code id="fpsden_+3A_nbinwidth">nbinwidth</code></td>
<td>
<p>scaling to convert count frequency into proper density</p>
</td></tr>
<tr><td><code id="fpsden_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="fpsden_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of GPD parameters (<code>sigmau</code>, <code>xi</code>) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="fpsden_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fpsden_+3A_lambda">lambda</code></td>
<td>
<p>penalty coefficient</p>
</td></tr>
<tr><td><code id="fpsden_+3A_counts">counts</code></td>
<td>
<p>counts from histogram binning</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The P-splines density estimator is fitted using maximum likelihood estimation, following
the approach of Eilers and Marx (1996). Histogram binning produces frequency counts, which are
modelled by constrained B-splines in a Poisson regression. A penalty
based on differences in the sequences B-spline coefficients is used to smooth/interpolate the counts.
</p>
<p>The B-splines are defined as in Eiler and Marx (1996), so that those are meet the boundary are simply
shifted and truncated version of the internal B-splines. No renormalisation is carried out. They are not
&quot;natural&quot; B-spline which are also commonly in use. Note that atural B-splines can be obtained by suitable
linear combinations of these B-splines. Hence, in practice there is little difference in the fit obtained
from either B-spline definition, even with the penalty constraining the coefficients. If the user desires
they can force the use of natural B-splines, by prior specification of the <code>design.knots</code>
with appropriate replication of the boundaries, see <code><a href="#topic+psden">dpsden</a></code>.
</p>
<p>Iterated weighted least squares (IWLS) for a mixed model representation of the P-splines regression,
conditional on a particular penalty coefficient, is used for estimating the B-spline coefficients which
is equivalent to maximum likelihood estimation. Leave-one-out cross-validation deviances are available
for estimation of the penalty coefficient.
</p>
<p>The parameter vector is the B-spline coefficients <code>beta</code>, no matter whether the penalty coefficient is
fixed or estimated. The penalty coefficient <code>lambda</code> is treated separately.
</p>
<p>The log-likelihood functions <code><a href="#topic+fpsden">lpsden</a></code> and <code><a href="#topic+fpsden">nlpsden</a></code>
evaluate the likelihood for the original dataset, using the fitted P-splines density estimator. The
log-likelihood is output as <code>nllh</code> from the fitting function <code><a href="#topic+fpsden">fpsden</a></code>.
They do not provide the likelihood for the Poisson regression of the histogram counts, which is usually
evaluated using the deviance. The deviance (via CVMSE for Poisson counts) is also output as <code>cvlambda</code>
from the fitting function <code><a href="#topic+fpsden">fpsden</a></code>.
</p>
<p>The <code><a href="#topic+fpsden">iwlspsden</a></code> function performs the IWLS. The 
<code><a href="#topic+fpsden">cvpsden</a></code> function calculates the leave-one-out cross-validation 
sum of the squared errors. They are not designed to be used directly by users. No checks of the
inputs are carried out.
</p>


<h3>Value</h3>

<p>Log-likelihood for original data is given by <code><a href="#topic+fpsden">lpsden</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fpsden">nlpsden</a></code>. Cross-validation 
sum of square of errors is provided by <code><a href="#topic+fpsden">cvpsden</a></code>. Poisson regression
fitting by IWLS is carried out in <code><a href="#topic+fpsden">iwlspsden</a></code>. Fitting function
<code><a href="#topic+fpsden">fpsden</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:                </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:                   </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xrange</code>:              </td><td style="text-align: left;"> range of support of B-splines</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>degree</code>:              </td><td style="text-align: left;"> degree of B-splines</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nseg</code>:                </td><td style="text-align: left;"> number of internal segments</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>design.knots</code>:        </td><td style="text-align: left;"> knots used in <code><a href="splines.html#topic+splineDesign">splineDesign</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>ord</code>:                 </td><td style="text-align: left;"> order of penalty term</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>binned</code>:              </td><td style="text-align: left;"> histogram results</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>breaks</code>:              </td><td style="text-align: left;"> histogram breaks</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mids</code>:                </td><td style="text-align: left;"> histogram mid-bins</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>counts</code>:              </td><td style="text-align: left;"> histogram counts</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nbinwidth</code>:           </td><td style="text-align: left;"> scaling factor to convert counts to density</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bsplines</code>:            </td><td style="text-align: left;"> B-splines matrix used for binned counts</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>databsplines</code>:        </td><td style="text-align: left;"> B-splines matrix used for data</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>counts</code>:              </td><td style="text-align: left;"> histogram counts</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambdaseq</code>:           </td><td style="text-align: left;"> <code class="reqn">\lambda</code> vector for profile likelihood or scalar for fixed <code class="reqn">\lambda</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cvlambda</code>:            </td><td style="text-align: left;"> CV MSE for each <code class="reqn">\lambda</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code> and <code>beta</code>: </td><td style="text-align: left;"> vector of MLE of coefficients</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:                </td><td style="text-align: left;"> negative log-likelihood for original data</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:                   </td><td style="text-align: left;"> total original sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:              </td><td style="text-align: left;"> Estimated or fixed <code class="reqn">\lambda</code></td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>The Poisson regression and leave-one-out cross-validation functions
are based on the code of Eilers and Marx (1996) available from Brian Marx's website 
<a href="http://statweb.lsu.edu/faculty/marx/">http://statweb.lsu.edu/faculty/marx/</a>, which is gratefully acknowledged.
</p>


<h3>Note</h3>

<p>The data are both vectors. Infinite and missing sample values are dropped.
</p>
<p>No initial values for the coefficients are needed.
</p>
<p>It is advised to specify the range of support <code>xrange</code>, using finite end-points. This is 
especially important when the support is bounded. By default <code>xrange</code> is simply the range of the
input data <code>range(x)</code>.
</p>
<p>Further, it is advised to always set the histogram bin <code>breaks</code>, expecially if the support is bounded.
By default <code>10*ln(n)</code> equi-spaced bins are defined between <code>xrange</code>.
</p>


<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/B-spline">http://en.wikipedia.org/wiki/B-spline</a>
</p>
<p><a href="http://statweb.lsu.edu/faculty/marx/">http://statweb.lsu.edu/faculty/marx/</a>
</p>
<p>Eilers, P.H.C. and Marx, B.D. (1996). Flexible smoothing with B-splines and penalties.
Statistical Science 11(2), 89-121.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kden">kden</a></code>.
</p>
<p>Other psden: <code><a href="#topic+fpsdengpd">fpsdengpd</a></code>,
<code><a href="#topic+psdengpd">psdengpd</a></code>, <code><a href="#topic+psden">psden</a></code>
</p>
<p>Other fpsden: <code><a href="#topic+psden">psden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Plenty of histogram bins (100)
breaks = seq(-4, 4, length.out=101)

# P-spline fitting with cubic B-splines, 2nd order penalty and 10 internal segments
# CV search for penalty coefficient. 
fit = fpsden(x, lambdaseq = 10^seq(-5, 5, 0.25), breaks = breaks,
             xrange = c(-4, 4), nseg = 10, degree = 3, ord = 2)
psdensity = exp(fit$bsplines %*% fit$mle)

hist(x, freq = FALSE, breaks = seq(-4, 4, length.out=101), xlim = c(-6, 6))
lines(xx, y, col = "black") # true density

lines(fit$mids, psdensity/fit$nbinwidth, lwd = 2, col = "blue") # P-splines density

# check density against dpsden function
with(fit, lines(xx, dpsden(xx, beta, nbinwidth, design = design.knots),
                lwd = 2, col = "red", lty = 2))

# vertical lines for all knots
with(fit, abline(v = design.knots, col = "red"))

# internal knots
with(fit, abline(v = design.knots[(degree + 2):(length(design.knots) - degree - 1)], col = "blue"))
  
# boundary knots (support of B-splines)
with(fit, abline(v = design.knots[c(degree + 1, length(design.knots) - degree)], col = "green"))

legend("topright", c("True Density","P-spline density","Using dpsdens function"),
  col=c("black", "blue", "red"), lty = c(1, 1, 2))
legend("topleft", c("Internal Knots", "Boundaries", "Extra Knots"),
  col=c("blue", "green", "red"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fpsdengpd'>MLE Fitting of P-splines Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fpsdengpd'></span><span id='topic+lpsdengpd'></span><span id='topic+nlpsdengpd'></span><span id='topic+proflupsdengpd'></span><span id='topic+nlupsdengpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with P-splines density estimate for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpsdengpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, lambdaseq = NULL, breaks = NULL, xrange = NULL,
  nseg = 10, degree = 3, design.knots = NULL, ord = 2,
  std.err = TRUE, method = "BFGS", control = list(maxit = 10000),
  finitelik = TRUE, ...)

lpsdengpd(x, psdenx, u = NULL, sigmau = NULL, xi = 0, phiu = TRUE,
  bsplinefit = NULL, phib = NULL, log = TRUE)

nlpsdengpd(pvector, x, psdenx, phiu = TRUE, bsplinefit, phib = NULL,
  finitelik = FALSE)

proflupsdengpd(u, pvector, x, psdenx, phiu = TRUE, bsplinefit,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

nlupsdengpd(pvector, u, x, psdenx, phiu = TRUE,
  bsplinefit = bsplinefit, phib = NULL, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fpsdengpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_lambdaseq">lambdaseq</code></td>
<td>
<p>vector of <code class="reqn">\lambda</code>'s (or scalar) to be considered in profile likelihood. Required.</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_breaks">breaks</code></td>
<td>
<p>histogram breaks (as in <code><a href="graphics.html#topic+hist">hist</a></code> function)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_xrange">xrange</code></td>
<td>
<p>vector of minimum and maximum of B-spline (support of density)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_nseg">nseg</code></td>
<td>
<p>number of segments between knots</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_degree">degree</code></td>
<td>
<p>degree of B-splines (0 is constant, 1 is linear, etc.)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_design.knots">design.knots</code></td>
<td>
<p>spline knots for splineDesign function</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_ord">ord</code></td>
<td>
<p>order of difference used in the penalty term</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_psdenx">psdenx</code></td>
<td>
<p>P-splines based density estimate for each datapoint in x</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_bsplinefit">bsplinefit</code></td>
<td>
<p>list output from P-splines density fitting <code><a href="#topic+fpsden">fpsden</a></code> function</p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_phib">phib</code></td>
<td>
<p>renormalisation constant for bulk model density <code class="reqn">(1-\phi_u)/H(u)</code>, to make it integrate to <code>1-phiu</code></p>
</td></tr>
<tr><td><code id="fpsdengpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with P-splines density estimate for bulk and GPD tail is 
fitted to the entire dataset. A two-stage maximum likelihood inference approach is taken. The first
stage consists fitting of the P-spline density estimator, which is acheived by MLE using the 
<code><a href="#topic+fpsden">fpsden</a></code> function. The second stage, conditions on the B-spline coefficients,
using MLE for the extreme value mixture model (GPD parameters and threshold, if requested). The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details of extreme value mixture models,
type <code>help fnormgpd</code>. Only the different features are outlined below for brevity.
</p>
<p>As the second stage conditions on the Bs-pline coefficients, the full parameter vector is
(<code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>(Penalized) MLE estimation of the B-Spline coefficients is carried out using Poisson regression
based on histogram bin counts. See help for <code><a href="#topic+fpsden">fpsden</a></code> for details,
type <code>help fpsden</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fpsdengpd">lpsdengpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fpsdengpd">nlpsdengpd</a></code>
and <code><a href="#topic+fpsdengpd">nlupsdengpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fpsdengpd">proflupsdengpd</a></code>. Fitting function
<code><a href="#topic+fpsdengpd">fpsdengpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:          </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:             </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:          </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:        </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:          </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:      </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>bsplinefit</code>:    </td><td style="text-align: left;"> complete <code><a href="#topic+fpsden">fpsden</a></code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>psdenx</code>:        </td><td style="text-align: left;"> P-splines based density estimate for each datapoint in <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xrange</code>:        </td><td style="text-align: left;"> range of support of B-splines</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>degree</code>:        </td><td style="text-align: left;"> degree of B-splines</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nseg</code>:          </td><td style="text-align: left;"> number of internal segments</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>design.knots</code>:  </td><td style="text-align: left;"> knots used in <code><a href="splines.html#topic+splineDesign">splineDesign</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nbinwidth</code>:     </td><td style="text-align: left;"> scaling factor to convert counts to density</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:         </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>conv</code>:          </td><td style="text-align: left;"> indicator for "possible" convergence</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:           </td><td style="text-align: left;"> vector of MLE of (GPD and threshold, if relevant) parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:           </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:            </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:          </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:          </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:             </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>beta</code>:          </td><td style="text-align: left;"> vector of MLE of B-spline coefficients</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>lambda</code>:        </td><td style="text-align: left;"> Estimated or fixed <code class="reqn">\lambda</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:             </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:        </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:            </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:          </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:       </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>
<p>The Poisson regression and leave-one-out cross-validation functions
are based on the code of Eilers and Marx (1996) available from Brian Marx's website 
<a href="http://statweb.lsu.edu/faculty/marx/">http://statweb.lsu.edu/faculty/marx/</a>, which is gratefully acknowledged.
</p>


<h3>Note</h3>

<p>The data are both vectors. Infinite and missing sample values are dropped.
</p>
<p>No initial values for the coefficients are needed.
</p>
<p>It is advised to specify the range of support <code>xrange</code>, using finite end-points. This is 
especially important when the support is bounded. By default <code>xrange</code> is simply the range of the
input data <code>range(x)</code>.
</p>
<p>Further, it is advised to always set the histogram bin <code>breaks</code>, expecially if the support is bounded.
By default <code>10*ln(n)</code> equi-spaced bins are defined between <code>xrange</code>.
</p>
<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/B-spline">http://en.wikipedia.org/wiki/B-spline</a>
</p>
<p><a href="http://statweb.lsu.edu/faculty/marx/">http://statweb.lsu.edu/faculty/marx/</a>
</p>
<p>Eilers, P.H.C. and Marx, B.D. (1996). Flexible smoothing with B-splines and penalties.
Statistical Science 11(2), 89-121.
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpsden">fpsden</a></code>, <code><a href="#topic+normgpd">fnormgpd</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other psden: <code><a href="#topic+fpsden">fpsden</a></code>, <code><a href="#topic+psdengpd">psdengpd</a></code>,
<code><a href="#topic+psden">psden</a></code>
</p>
<p>Other psdengpd: <code><a href="#topic+psdengpd">psdengpd</a></code>, <code><a href="#topic+psden">psden</a></code>
</p>
<p>Other fpsdengpd: <code><a href="#topic+psdengpd">psdengpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-4, 4, 0.01)
y = dnorm(xx)

# Plenty of histogram bins (100)
breaks = seq(-4, 4, length.out=101)

# P-spline fitting with cubic B-splines, 2nd order penalty and 10 internal segments
# CV search for penalty coefficient. 
fit = fpsdengpd(x, useq = seq(0, 3, 0.1), fixedu = TRUE,
             lambdaseq = 10^seq(-5, 5, 0.25), breaks = breaks,
             xrange = c(-4, 4), nseg = 10, degree = 3, ord = 2)
             
hist(x, freq = FALSE, breaks = breaks, xlim = c(-6, 6))
lines(xx, y, col = "black") # true density

# P-splines+GPD
with(fit, lines(xx, dpsdengpd(xx, beta, nbinwidth, 
                              u = u, sigmau = sigmau, xi = xi, design = design.knots),
                lwd = 2, col = "red"))
abline(v = fit$u, col = "red", lwd = 2, lty = 3)

# P-splines density estimate
with(fit, lines(xx, dpsden(xx, beta, nbinwidth, design = design.knots),
                lwd = 2, col = "blue", lty = 2))

# vertical lines for all knots
with(fit, abline(v = design.knots, col = "red"))

# internal knots
with(fit, abline(v = design.knots[(degree + 2):(length(design.knots) - degree - 1)], col = "blue"))
  
# boundary knots (support of B-splines)
with(fit, abline(v = design.knots[c(degree + 1, length(design.knots) - degree)], col = "green"))

legend("topright", c("True Density","P-spline density","P-spline+GPD"),
  col=c("black", "blue", "red"), lty = c(1, 2, 1))
legend("topleft", c("Internal Knots", "Boundaries", "Extra Knots", "Threshold"),
  col=c("blue", "green", "red", "red"), lty = c(1, 1, 1, 2))

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fweibullgpd'>MLE Fitting of Weibull Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+fweibullgpd'></span><span id='topic+lweibullgpd'></span><span id='topic+nlweibullgpd'></span><span id='topic+profluweibullgpd'></span><span id='topic+nluweibullgpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with Weibull for bulk distribution upto the threshold and conditional
GPD above threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fweibullgpd(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lweibullgpd(x, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale *
  gamma(1 + 1/wshape))^2), xi = 0, phiu = TRUE, log = TRUE)

nlweibullgpd(pvector, x, phiu = TRUE, finitelik = FALSE)

profluweibullgpd(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nluweibullgpd(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fweibullgpd_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_wshape">wshape</code></td>
<td>
<p>scalar Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_wscale">wscale</code></td>
<td>
<p>scalar Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scalar scale parameter (positive)</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fweibullgpd_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with Weibull bulk and GPD tail is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The full parameter vector is
(<code>wshape</code>, <code>wscale</code>, <code>u</code>, <code>sigmau</code>, <code>xi</code>) if threshold is also estimated and
(<code>wshape</code>, <code>wscale</code>, <code>sigmau</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Non-positive data are ignored (f(0) is infinite for wshape&lt;1).
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fweibullgpd">lweibullgpd</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fweibullgpd">nlweibullgpd</a></code>
and <code><a href="#topic+fweibullgpd">nluweibullgpd</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fweibullgpd">profluweibullgpd</a></code>. Fitting function
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>wshape</code>:    </td><td style="text-align: left;"> MLE of Weibull shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>wscale</code>:    </td><td style="text-align: left;"> MLE of Weibull scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of Weibull parameters assuming entire population is Weibull; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD parameters above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Weibull">dweibull</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other weibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>,
<code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other weibullgpdcon: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>,
<code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other itmweibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>,
<code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other fweibullgpd: <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rweibull(1000, shape = 2)
xx = seq(-0.1, 4, 0.01)
y = dweibull(xx, shape = 2)

# Bulk model based tail fraction
fit = fweibullgpd(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 4))
lines(xx, y)
with(fit, lines(xx, dweibullgpd(xx, wshape, wscale, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
  
# Parameterised tail fraction
fit2 = fweibullgpd(x, phiu = FALSE)
with(fit2, lines(xx, dweibullgpd(xx, wshape, wscale, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","Bulk Tail Fraction","Parameterised Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fweibullgpd(x, useq = seq(0.5, 2, length = 20))
fitfix = fweibullgpd(x, useq = seq(0.5, 2, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 4))
lines(xx, y)
with(fit, lines(xx, dweibullgpd(xx, wshape, wscale, u, sigmau, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dweibullgpd(xx, wshape, wscale, u, sigmau, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dweibullgpd(xx, wshape, wscale, u, sigmau, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fweibullgpdcon'>MLE Fitting of Weibull Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+fweibullgpdcon'></span><span id='topic+lweibullgpdcon'></span><span id='topic+nlweibullgpdcon'></span><span id='topic+profluweibullgpdcon'></span><span id='topic+nluweibullgpdcon'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with Weibull for bulk distribution upto the threshold and conditional
GPD above threshold with continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fweibullgpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, std.err = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

lweibullgpdcon(x, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), xi = 0, phiu = TRUE, log = TRUE)

nlweibullgpdcon(pvector, x, phiu = TRUE, finitelik = FALSE)

profluweibullgpdcon(u, pvector, x, phiu = TRUE, method = "BFGS",
  control = list(maxit = 10000), finitelik = TRUE, ...)

nluweibullgpdcon(pvector, u, x, phiu = TRUE, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fweibullgpdcon_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code><a href="#topic+fnormgpd">fnormgpd</a></code></p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_useq">useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_fixedu">fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_pvector">pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_std.err">std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_method">method</code></td>
<td>
<p>optimisation method (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_control">control</code></td>
<td>
<p>optimisation control list (see <code><a href="stats.html#topic+optim">optim</a></code>)</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_finitelik">finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_...">...</code></td>
<td>
<p>optional inputs passed to <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_wshape">wshape</code></td>
<td>
<p>scalar Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_wscale">wscale</code></td>
<td>
<p>scalar Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_u">u</code></td>
<td>
<p>scalar threshold value</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_xi">xi</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="fweibullgpdcon_+3A_log">log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extreme value mixture model with Weibull bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code><a href="#topic+fnormgpd">fnormgpd</a></code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code><a href="#topic+weibullgpdcon">dweibullgpdcon</a></code> for details, type <code>help weibullgpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>wshape</code>, <code>wscale</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>wshape</code>, <code>wscale</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Negative data are ignored.
</p>


<h3>Value</h3>

<p>Log-likelihood is given by <code><a href="#topic+fweibullgpdcon">lweibullgpdcon</a></code> and it's
wrappers for negative log-likelihood from <code><a href="#topic+fweibullgpdcon">nlweibullgpdcon</a></code>
and <code><a href="#topic+fweibullgpdcon">nluweibullgpdcon</a></code>. Profile likelihood for single
threshold given by <code><a href="#topic+fweibullgpdcon">profluweibullgpdcon</a></code>. Fitting function
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code> returns a simple list with the
following elements
</p>

<table>
<tr>
 <td style="text-align: left;">
 <code>call</code>:      </td><td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>x</code>:         </td><td style="text-align: left;"> data vector <code>x</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>init</code>:      </td><td style="text-align: left;"> <code>pvector</code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>fixedu</code>:    </td><td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>useq</code>:      </td><td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllhuseq</code>:  </td><td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>optim</code>:     </td><td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>mle</code>:       </td><td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>cov</code>:       </td><td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se</code>:        </td><td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>rate</code>:      </td><td style="text-align: left;"> <code>phiu</code> to be consistent with <code><a href="evd.html#topic+fpot">evd</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>nllh</code>:      </td><td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>n</code>:         </td><td style="text-align: left;"> total sample size</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>wshape</code>:    </td><td style="text-align: left;"> MLE of Weibull shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>wscale</code>:    </td><td style="text-align: left;"> MLE of Weibull scale</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>u</code>:         </td><td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>sigmau</code>:    </td><td style="text-align: left;"> MLE of GPD scale (estimated from other parameters)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>xi</code>:        </td><td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>phiu</code>:      </td><td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
 <td style="text-align: left;">
 <code>se.phiu</code>:   </td><td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code><a href="#topic+fnormgpd">fnormgpd</a></code>, type <code>help fnormgpd</code>.
</p>


<h3>Note</h3>

<p>When <code>pvector=NULL</code> then the initial values are:
</p>

<ul>
<li><p> MLE of Weibull parameters assuming entire population is Weibull; and
</p>
</li>
<li><p> threshold 90% quantile (not relevant for profile likelihood for threshold or fixed threshold approaches);
</p>
</li>
<li><p> MLE of GPD shape parameter above threshold. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Weibull">dweibull</a></code>,
<code><a href="#topic+fgpd">fgpd</a></code> and <code><a href="#topic+gpd">gpd</a></code>
</p>
<p>Other weibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other weibullgpdcon: <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>,
<code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other itmweibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other fweibullgpdcon: <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rweibull(1000, shape = 2)
xx = seq(-0.1, 4, 0.01)
y = dweibull(xx, shape = 2)

# Continuity constraint
fit = fweibullgpdcon(x)
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 4))
lines(xx, y)
with(fit, lines(xx, dweibullgpdcon(xx, wshape, wscale, u, xi), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
fit2 = fweibullgpd(x, phiu = FALSE)
with(fit2, lines(xx, dweibullgpd(xx, wshape, wscale, u, sigmau, xi, phiu), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
fitu = fweibullgpdcon(x, useq = seq(0.5, 2, length = 20))
fitfix = fweibullgpdcon(x, useq = seq(0.5, 2, length = 20), fixedu = TRUE)

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 4))
lines(xx, y)
with(fit, lines(xx, dweibullgpdcon(xx, wshape, wscale, u, xi), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dweibullgpdcon(xx, wshape, wscale, u, xi), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dweibullgpdcon(xx, wshape, wscale, u, xi), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='gammagpd'>Gamma Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+gammagpd'></span><span id='topic+dgammagpd'></span><span id='topic+pgammagpd'></span><span id='topic+qgammagpd'></span><span id='topic+rgammagpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with gamma for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the gamma shape <code>gshape</code> and scale <code>gscale</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgammagpd(x, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), sigmau = sqrt(gshape) * gscale, xi = 0, phiu = TRUE,
  log = FALSE)

pgammagpd(q, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), sigmau = sqrt(gshape) * gscale, xi = 0, phiu = TRUE,
  lower.tail = TRUE)

qgammagpd(p, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), sigmau = sqrt(gshape) * gscale, xi = 0, phiu = TRUE,
  lower.tail = TRUE)

rgammagpd(n = 1, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), sigmau = sqrt(gshape) * gscale, xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gammagpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_gshape">gshape</code></td>
<td>
<p>gamma shape (positive)</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_gscale">gscale</code></td>
<td>
<p>gamma scale (positive)</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gammagpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gammagpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining gamma distribution for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
gamma bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the gamma bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the gamma and conditional GPD
cumulative distribution functions (i.e. <code>pgamma(x, gshape, 1/gscale)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The gamma is defined on the non-negative reals, so the threshold must be positive. 
Though behaviour at zero depends on the shape (<code class="reqn">\alpha</code>):
</p>

<ul>
<li> <p><code class="reqn">f(0+)=\infty</code> for <code class="reqn">0&lt;\alpha&lt;1</code>;
</p>
</li>
<li> <p><code class="reqn">f(0+)=1/\beta</code> for <code class="reqn">\alpha=1</code> (exponential);
</p>
</li>
<li> <p><code class="reqn">f(0+)=0</code> for <code class="reqn">\alpha&gt;1</code>;
</p>
</li></ul>

<p>where <code class="reqn">\beta</code> is the scale parameter.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+GammaDist">dgamma</a></code> for details of gamma bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gammagpd">dgammagpd</a></code> gives the density, 
<code><a href="#topic+gammagpd">pgammagpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+gammagpd">qgammagpd</a></code> gives the quantile function and 
<code><a href="#topic+gammagpd">rgammagpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+gammagpd">rgammagpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+gammagpd">rgammagpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+GammaDist">dgamma</a></code>
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other gammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rgammagpd(1000, gshape = 2)
xx = seq(-1, 10, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dgammagpd(xx, gshape = 2))

# three tail behaviours
plot(xx, pgammagpd(xx, gshape = 2), type = "l")
lines(xx, pgammagpd(xx, gshape = 2, xi = 0.3), col = "red")
lines(xx, pgammagpd(xx, gshape = 2, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rgammagpd(1000, gshape = 2, u = 3, phiu = 0.2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dgammagpd(xx, gshape = 2, u = 3, phiu = 0.2))

plot(xx, dgammagpd(xx, gshape = 2, u = 3, xi=0, phiu = 0.2), type = "l")
lines(xx, dgammagpd(xx, gshape = 2, u = 3, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dgammagpd(xx, gshape = 2, u = 3, xi=0.2, phiu = 0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gammagpdcon'>Gamma Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+gammagpdcon'></span><span id='topic+dgammagpdcon'></span><span id='topic+pgammagpdcon'></span><span id='topic+qgammagpdcon'></span><span id='topic+rgammagpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with gamma for bulk
distribution upto the threshold and conditional GPD above threshold with continuity
at threshold. The parameters
are the gamma shape <code>gshape</code> and scale <code>gscale</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgammagpdcon(x, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), xi = 0, phiu = TRUE, log = FALSE)

pgammagpdcon(q, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), xi = 0, phiu = TRUE, lower.tail = TRUE)

qgammagpdcon(p, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), xi = 0, phiu = TRUE, lower.tail = TRUE)

rgammagpdcon(n = 1, gshape = 1, gscale = 1, u = qgamma(0.9, gshape,
  1/gscale), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gammagpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_gshape">gshape</code></td>
<td>
<p>gamma shape (positive)</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_gscale">gscale</code></td>
<td>
<p>gamma scale (positive)</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gammagpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining gamma distribution for the bulk
below the threshold and GPD for upper tail with continuity at threshold.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
gamma bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the gamma bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the gamma and conditional GPD
cumulative distribution functions (i.e. <code>pgamma(x, gshape, 1/gscale)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the gamma and conditional GPD
density functions (i.e. <code>dgammma(x, gshape, gscale)</code> and
<code>dgpd(x, u, sigmau, xi)</code>) respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>. 
</p>
<p>The gamma is defined on the non-negative reals, so the threshold must be positive. 
Though behaviour at zero depends on the shape (<code class="reqn">\alpha</code>):
</p>

<ul>
<li> <p><code class="reqn">f(0+)=\infty</code> for <code class="reqn">0&lt;\alpha&lt;1</code>;
</p>
</li>
<li> <p><code class="reqn">f(0+)=1/\beta</code> for <code class="reqn">\alpha=1</code> (exponential);
</p>
</li>
<li> <p><code class="reqn">f(0+)=0</code> for <code class="reqn">\alpha&gt;1</code>;
</p>
</li></ul>

<p>where <code class="reqn">\beta</code> is the scale parameter.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+GammaDist">dgamma</a></code> for details of gamma bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gammagpdcon">dgammagpdcon</a></code> gives the density, 
<code><a href="#topic+gammagpdcon">pgammagpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+gammagpdcon">qgammagpdcon</a></code> gives the quantile function and 
<code><a href="#topic+gammagpdcon">rgammagpdcon</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+gammagpdcon">rgammagpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+gammagpdcon">rgammagpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+GammaDist">dgamma</a></code>
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other gammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rgammagpdcon(1000, gshape = 2)
xx = seq(-1, 10, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dgammagpdcon(xx, gshape = 2))

# three tail behaviours
plot(xx, pgammagpdcon(xx, gshape = 2), type = "l")
lines(xx, pgammagpdcon(xx, gshape = 2, xi = 0.3), col = "red")
lines(xx, pgammagpdcon(xx, gshape = 2, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rgammagpdcon(1000, gshape = 2, u = 3, phiu = 0.2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dgammagpdcon(xx, gshape = 2, u = 3, phiu = 0.2))

plot(xx, dgammagpdcon(xx, gshape = 2, u = 3, xi=0, phiu = 0.2), type = "l")
lines(xx, dgammagpdcon(xx, gshape = 2, u = 3, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dgammagpdcon(xx, gshape = 2, u = 3, xi=0.2, phiu = 0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gkg'>Kernel Density Estimate and GPD Both Upper and Lower Tails Extreme Value Mixture Model</h2><span id='topic+gkg'></span><span id='topic+dgkg'></span><span id='topic+pgkg'></span><span id='topic+qgkg'></span><span id='topic+rgkg'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with kernel density estimate for bulk
distribution between thresholds and conditional GPD beyond thresholds. The parameters are the kernel bandwidth
<code>lambda</code>, lower tail (threshold <code>ul</code>, 
GPD scale <code>sigmaul</code> and shape <code>xil</code> and tail fraction <code>phiul</code>)
and upper tail (threshold <code>ur</code>, GPD scale <code>sigmaur</code> and shape 
<code>xiR</code> and tail fraction <code>phiur</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgkg(x, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), sigmaul = sqrt(6 *
  var(kerncentres))/pi, xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), sigmaur = sqrt(6 *
  var(kerncentres))/pi, xir = 0, phiur = TRUE, bw = NULL,
  kernel = "gaussian", log = FALSE)

pgkg(q, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), sigmaul = sqrt(6 *
  var(kerncentres))/pi, xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), sigmaur = sqrt(6 *
  var(kerncentres))/pi, xir = 0, phiur = TRUE, bw = NULL,
  kernel = "gaussian", lower.tail = TRUE)

qgkg(p, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), sigmaul = sqrt(6 *
  var(kerncentres))/pi, xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), sigmaur = sqrt(6 *
  var(kerncentres))/pi, xir = 0, phiur = TRUE, bw = NULL,
  kernel = "gaussian", lower.tail = TRUE)

rgkg(n = 1, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), sigmaul = sqrt(6 *
  var(kerncentres))/pi, xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), sigmaur = sqrt(6 *
  var(kerncentres))/pi, xir = 0, phiur = TRUE, bw = NULL,
  kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gkg_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gkg_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="gkg_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="gkg_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="gkg_+3A_sigmaul">sigmaul</code></td>
<td>
<p>lower tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="gkg_+3A_xil">xil</code></td>
<td>
<p>lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gkg_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gkg_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="gkg_+3A_sigmaur">sigmaur</code></td>
<td>
<p>upper tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="gkg_+3A_xir">xir</code></td>
<td>
<p>upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gkg_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gkg_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="gkg_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="gkg_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gkg_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gkg_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gkg_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gkg_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining kernel density estimate (KDE) for the bulk
between thresholds and GPD beyond thresholds.
</p>
<p>The user can pre-specify <code>phiul</code> and <code>phiur</code> 
permitting a parameterised value for the tail fractions <code class="reqn">\phi_ul</code> and  <code class="reqn">\phi_ur</code>.
Alternatively, when
<code>phiul=TRUE</code> and <code>phiur=TRUE</code> the tail fractions are estimated as the tail
fractions from the KDE bulk model.
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>Notice that the tail fraction cannot be 0 or 1, and the sum of upper and lower tail
fractions <code>phiul + phiur &lt; 1</code>, so the lower threshold must be less than the upper, 
<code>ul &lt; ur</code>.
</p>
<p>The cumulative distribution function has three components. The lower tail with 
tail fraction <code class="reqn">\phi_{ul}</code> defined by the KDE bulk model (<code>phiul=TRUE</code>)
upto the lower threshold <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_l) [1 - G_l(x)].</code>
</p>

<p>where <code class="reqn">H(x)</code> is the kernel density estimator cumulative distribution function (i.e. 
<code>mean(pnorm(x, kerncentres, bw))</code> and  
<code class="reqn">G_l(X)</code> is the conditional GPD cumulative distribution function with negated
<code class="reqn">x</code> value and threshold, i.e. <code>pgpd(-x, -ul, sigmaul, xil, phiul)</code>. The KDE
bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_r) + [1 - H(u_r)] G_r(x)</code>
</p>

<p>where <code class="reqn">G_r(X)</code> is the GPD cumulative distribution function, 
i.e. <code>pgpd(x, ur, sigmaur, xir, phiur)</code>.
</p>
<p>The cumulative distribution function for the pre-specified tail fractions 
<code class="reqn">\phi_{ul}</code> and <code class="reqn">\phi_{ur}</code> is more complicated.  The unconditional GPD
is used for the lower tail <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul} [1 - G_l(x)].</code>
</p>

<p>The KDE bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul}+ (1-\phi_{ul}-\phi_{ur}) (H(x) - H(u_l)) / (H(u_r) - H(u_l)).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1-\phi_{ur}) + \phi_{ur} G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_{ul} = H(u_l)</code> and
<code class="reqn">\phi_{ur} = 1 - H(u_r)</code>.
</p>
<p>If no bandwidth is provided <code>lambda=NULL</code> and <code>bw=NULL</code> then the normal
reference rule is used, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="#topic+kden">dkden</a></code> for details of KDE bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gkg">dgkg</a></code> gives the density, 
<code><a href="#topic+gkg">pgkg</a></code> gives the cumulative distribution function,
<code><a href="#topic+gkg">qgkg</a></code> gives the quantile function and 
<code><a href="#topic+gkg">rgkg</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+gkg">gkg</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The <code>kerncentres</code> can also be a scalar or vector.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+gkg">rgkg</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters or kernel centres.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other gkgcon: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other fgkg: <code><a href="#topic+fgkg">fgkg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

kerncentres=rnorm(1000,0,1)
x = rgkg(1000, kerncentres, phiul = 0.15, phiur = 0.15)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgkg(xx, kerncentres, phiul = 0.15, phiur = 0.15))

# three tail behaviours
plot(xx, pgkg(xx, kerncentres), type = "l")
lines(xx, pgkg(xx, kerncentres,xil = 0.3, xir = 0.3), col = "red")
lines(xx, pgkg(xx, kerncentres,xil = -0.3, xir = -0.3), col = "blue")
legend("topleft", paste("Symmetric xil=xir=",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

# asymmetric tail behaviours
x = rgkg(1000, kerncentres, xil = -0.3, phiul = 0.1, xir = 0.3, phiur = 0.1)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgkg(xx, kerncentres, xil = -0.3, phiul = 0.1, xir = 0.3, phiur = 0.1))

plot(xx, dgkg(xx, kerncentres, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2),
  type = "l", ylim = c(0, 0.4))
lines(xx, dgkg(xx, kerncentres, xil = -0.3, phiul = 0.3, xir = 0.3, phiur = 0.3),
  col = "red")
lines(xx, dgkg(xx, kerncentres, xil = -0.3, phiul = TRUE, xir = 0.3, phiur = TRUE),
  col = "blue")
legend("topleft", c("phiul = phiur = 0.2", "phiul = phiur = 0.3", "Bulk Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gkgcon'>Kernel Density Estimate and GPD Both Upper and Lower Tails Extreme Value Mixture Model
With Single Continuity Constraint at Both</h2><span id='topic+gkgcon'></span><span id='topic+dgkgcon'></span><span id='topic+pgkgcon'></span><span id='topic+qgkgcon'></span><span id='topic+rgkgcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with
kernel density estimate for bulk distribution between thresholds and
conditional GPD beyond thresholds and continuity at both of them. The parameters are the kernel bandwidth
<code>lambda</code>, lower tail (threshold <code>ul</code>, 
GPD shape <code>xil</code> and tail fraction <code>phiul</code>)
and upper tail (threshold <code>ur</code>, GPD shape 
<code>xiR</code> and tail fraction <code>phiur</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgkgcon(x, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), xir = 0, phiur = TRUE,
  bw = NULL, kernel = "gaussian", log = FALSE)

pgkgcon(q, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), xir = 0, phiur = TRUE,
  bw = NULL, kernel = "gaussian", lower.tail = TRUE)

qgkgcon(p, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), xir = 0, phiur = TRUE,
  bw = NULL, kernel = "gaussian", lower.tail = TRUE)

rgkgcon(n = 1, kerncentres, lambda = NULL,
  ul = as.vector(quantile(kerncentres, 0.1)), xil = 0, phiul = TRUE,
  ur = as.vector(quantile(kerncentres, 0.9)), xir = 0, phiur = TRUE,
  bw = NULL, kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gkgcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="gkgcon_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_xil">xil</code></td>
<td>
<p>lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gkgcon_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_xir">xir</code></td>
<td>
<p>upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gkgcon_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="gkgcon_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gkgcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining kernel density estimate (KDE) for the bulk
between thresholds and GPD beyond thresholds and continuity at both of them.
</p>
<p>The user can pre-specify <code>phiul</code> and <code>phiur</code> 
permitting a parameterised value for the tail fractions <code class="reqn">\phi_ul</code> and  <code class="reqn">\phi_ur</code>.
Alternatively, when
<code>phiul=TRUE</code> and <code>phiur=TRUE</code> the tail fractions are estimated as the tail
fractions from the KDE bulk model.
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>Notice that the tail fraction cannot be 0 or 1, and the sum of upper and lower tail
fractions <code>phiul + phiur &lt; 1</code>, so the lower threshold must be less than the upper, 
<code>ul &lt; ur</code>.
</p>
<p>The cumulative distribution function has three components. The lower tail with 
tail fraction <code class="reqn">\phi_{ul}</code> defined by the KDE bulk model (<code>phiul=TRUE</code>)
upto the lower threshold <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_l) [1 - G_l(x)].</code>
</p>

<p>where <code class="reqn">H(x)</code> is the kernel density estimator cumulative distribution function (i.e. 
<code>mean(pnorm(x, kerncentres, bw))</code> and  
<code class="reqn">G_l(X)</code> is the conditional GPD cumulative distribution function with negated
<code class="reqn">x</code> value and threshold, i.e. <code>pgpd(-x, -ul, sigmaul, xil, phiul)</code>. The KDE
bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_r) + [1 - H(u_r)] G_r(x)</code>
</p>

<p>where <code class="reqn">G_r(X)</code> is the GPD cumulative distribution function, 
i.e. <code>pgpd(x, ur, sigmaur, xir, phiur)</code>.
</p>
<p>The cumulative distribution function for the pre-specified tail fractions 
<code class="reqn">\phi_{ul}</code> and <code class="reqn">\phi_{ur}</code> is more complicated.  The unconditional GPD
is used for the lower tail <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul} [1 - G_l(x)].</code>
</p>

<p>The KDE bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul}+ (1-\phi_{ul}-\phi_{ur}) (H(x) - H(u_l)) / (H(u_r) - H(u_l)).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1-\phi_{ur}) + \phi_{ur} G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_{ul} = H(u_l)</code> and
<code class="reqn">\phi_{ur} = 1 - H(u_r)</code>.
</p>
<p>The continuity constraint at <code>ur</code> means that:
</p>
<p style="text-align: center;"><code class="reqn">\phi_{ur} g_r(x) = (1-\phi_{ul}-\phi_{ur}) h(u_r)/ (H(u_r) - H(u_l)).</code>
</p>

<p>By rearrangement, the GPD scale parameter <code>sigmaur</code> is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ur = \phi_{ur} (H(u_r) - H(u_l))/ h(u_r) (1-\phi_{ul}-\phi_{ur}).</code>
</p>

<p>where <code class="reqn">h(x)</code>, <code class="reqn">g_l(x)</code> and <code class="reqn">g_r(x)</code> are the KDE and conditional GPD
density functions for lower and upper tail respectively. 
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ur = [1-H(u_r)] / h(u_r)</code>
</p>
<p>.
</p>
<p>The continuity constraint at <code>ul</code> means that:
</p>
<p style="text-align: center;"><code class="reqn">\phi_{ul} g_l(x) = (1-\phi_{ul}-\phi_{ur}) h(u_l)/ (H(u_r) - H(u_l)).</code>
</p>

<p>The GPD scale parameter <code>sigmaul</code> is replaced by:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ul = \phi_{ul} (H(u_r) - H(u_l))/ h(u_l) (1-\phi_{ul}-\phi_{ur}).</code>
</p>

<p>In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ul = H(u_l)/ h(u_l)</code>
</p>
<p>. 
</p>
<p>If no bandwidth is provided <code>lambda=NULL</code> and <code>bw=NULL</code> then the normal
reference rule is used, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="#topic+kden">dkden</a></code> for details of KDE bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gkgcon">dgkgcon</a></code> gives the density, 
<code><a href="#topic+gkgcon">pgkgcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+gkgcon">qgkgcon</a></code> gives the quantile function and 
<code><a href="#topic+gkgcon">rgkgcon</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+gkgcon">gkgcon</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The <code>kerncentres</code> can also be a scalar or vector.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+gkgcon">rgkgcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters or kernel centres.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other gkgcon: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other fgkgcon: <code><a href="#topic+fgkgcon">fgkgcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

kerncentres=rnorm(1000,0,1)
x = rgkgcon(1000, kerncentres, phiul = 0.15, phiur = 0.15)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgkgcon(xx, kerncentres, phiul = 0.15, phiur = 0.15))

# three tail behaviours
plot(xx, pgkgcon(xx, kerncentres), type = "l")
lines(xx, pgkgcon(xx, kerncentres,xil = 0.3, xir = 0.3), col = "red")
lines(xx, pgkgcon(xx, kerncentres,xil = -0.3, xir = -0.3), col = "blue")
legend("topleft", paste("Symmetric xil=xir=",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

# asymmetric tail behaviours
x = rgkgcon(1000, kerncentres, xil = -0.3, phiul = 0.1, xir = 0.3, phiur = 0.1)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgkgcon(xx, kerncentres, xil = -0.3, phiul = 0.1, xir = 0.3, phiur = 0.1))

plot(xx, dgkgcon(xx, kerncentres, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2),
  type = "l", ylim = c(0, 0.4))
lines(xx, dgkgcon(xx, kerncentres, xil = -0.3, phiul = 0.3, xir = 0.3, phiur = 0.3),
  col = "red")
lines(xx, dgkgcon(xx, kerncentres, xil = -0.3, phiul = TRUE, xir = 0.3, phiur = TRUE),
  col = "blue")
legend("topleft", c("phiul = phiur = 0.2", "phiul = phiur = 0.3", "Bulk Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gng'>Normal Bulk with GPD Upper and Lower Tails Extreme Value Mixture Model</h2><span id='topic+gng'></span><span id='topic+dgng'></span><span id='topic+pgng'></span><span id='topic+qgng'></span><span id='topic+rgng'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with normal
for bulk distribution between the upper and lower thresholds with
conditional GPD's for the two tails. The parameters are the normal mean
<code>nmean</code> and standard deviation <code>nsd</code>, lower tail (threshold <code>ul</code>, 
GPD scale <code>sigmaul</code> and shape <code>xil</code> and tail fraction <code>phiul</code>)
and upper tail (threshold <code>ur</code>, GPD scale <code>sigmaur</code> and shape 
<code>xiR</code> and tail fraction <code>phiuR</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgng(x, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  sigmaul = nsd, xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean,
  nsd), sigmaur = nsd, xir = 0, phiur = TRUE, log = FALSE)

pgng(q, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  sigmaul = nsd, xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean,
  nsd), sigmaur = nsd, xir = 0, phiur = TRUE, lower.tail = TRUE)

qgng(p, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  sigmaul = nsd, xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean,
  nsd), sigmaur = nsd, xir = 0, phiur = TRUE, lower.tail = TRUE)

rgng(n = 1, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  sigmaul = nsd, xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean,
  nsd), sigmaur = nsd, xir = 0, phiur = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gng_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gng_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="gng_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="gng_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="gng_+3A_sigmaul">sigmaul</code></td>
<td>
<p>lower tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="gng_+3A_xil">xil</code></td>
<td>
<p>lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gng_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gng_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="gng_+3A_sigmaur">sigmaur</code></td>
<td>
<p>upper tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="gng_+3A_xir">xir</code></td>
<td>
<p>upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gng_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gng_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gng_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gng_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gng_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gng_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining normal distribution for the bulk
between the lower and upper thresholds and GPD for upper and lower tails. The
user can pre-specify <code>phiul</code> and <code>phiur</code> permitting a parameterised
value for the lower and upper tail fraction respectively. Alternatively, when
<code>phiul=TRUE</code> or <code>phiur=TRUE</code> the corresponding tail fraction is
estimated as from the normal bulk model.
</p>
<p>Notice that the tail fraction cannot be 0 or 1, and the sum of upper and lower tail
fractions <code>phiul+phiur&lt;1</code>, so the lower threshold must be less than the upper, 
<code>ul&lt;ur</code>.
</p>
<p>The cumulative distribution function now has three components. The lower tail with 
tail fraction <code class="reqn">\phi_{ul}</code> defined by the normal bulk model (<code>phiul=TRUE</code>)
upto the lower threshold <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_l) G_l(x).</code>
</p>

<p>where <code class="reqn">H(x)</code> is the normal cumulative distribution function (i.e. 
<code>pnorm(ur, nmean, nsd)</code>). The 
<code class="reqn">G_l(X)</code> is the conditional GPD cumulative distribution function with negated
data and threshold, i.e. <code>dgpd(-x, -ul, sigmaul, xil, phiul)</code>. The normal
bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_r) + [1 - H(u_r)] G(x)</code>
</p>

<p>where <code class="reqn">G(X)</code>.
</p>
<p>The cumulative distribution function for the pre-specified tail fractions 
<code class="reqn">\phi_{ul}</code> and <code class="reqn">\phi_{ur}</code> is more complicated.  The unconditional GPD
is used for the lower tail <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul} G_l(x).</code>
</p>

<p>The normal bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul}+ (1-\phi_{ul}-\phi_{ur}) (H(x) - H(u_l)) / (H(u_r) - H(u_l)).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1-\phi_{ur}) + \phi_{ur} G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_{ul} = H(u_l)</code> and
<code class="reqn">\phi_{ur} = 1 - H(u_r)</code>.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component, 
<code><a href="stats.html#topic+Normal">dnorm</a></code> for details of normal bulk component and
<code><a href="#topic+normgpd">dnormgpd</a></code> for normal with GPD extreme value
mixture model.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gng">dgng</a></code> gives the density, 
<code><a href="#topic+gng">pgng</a></code> gives the cumulative distribution function,
<code><a href="#topic+gng">qgng</a></code> gives the quantile function and 
<code><a href="#topic+gng">rgng</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main input (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+gng">rgng</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+gng">rgng</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Zhao, X., Scarrott, C.J. Reale, M. and Oxley, L. (2010). Extreme value modelling
for forecasting the market crisis. Applied Financial Econometrics 20(1), 63-72.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fitmgng">fitmgng</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gngcon: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other fgng: <code><a href="#topic+fgng">fgng</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rgng(1000, phiul = 0.15, phiur = 0.15)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgng(xx, phiul = 0.15, phiur = 0.15))

# three tail behaviours
plot(xx, pgng(xx), type = "l")
lines(xx, pgng(xx, xil = 0.3, xir = 0.3), col = "red")
lines(xx, pgng(xx, xil = -0.3, xir = -0.3), col = "blue")
legend("topleft", paste("Symmetric xil=xir=",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rgng(1000, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgng(xx, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2))

plot(xx, dgng(xx, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2), type = "l", ylim = c(0, 0.4))
lines(xx, dgng(xx, xil = -0.3, phiul = 0.3, xir = 0.3, phiur = 0.3), col = "red")
lines(xx, dgng(xx, xil = -0.3, phiul = TRUE, xir = 0.3, phiur = TRUE), col = "blue")
legend("topleft", c("phiul = phiur = 0.2", "phiul = phiur = 0.3", "Bulk Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gngcon'>Normal Bulk with GPD Upper and Lower Tails Extreme Value Mixture Model
with Single Continuity Constraint at Thresholds</h2><span id='topic+gngcon'></span><span id='topic+dgngcon'></span><span id='topic+pgngcon'></span><span id='topic+qgngcon'></span><span id='topic+rgngcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with normal
for bulk distribution between the upper and lower thresholds with
conditional GPD's for the two tails with continuity at the lower and upper thresholds.
The parameters are the normal mean
<code>nmean</code> and standard deviation <code>nsd</code>, lower tail (threshold <code>ul</code>, 
GPD shape <code>xil</code> and tail fraction <code>phiul</code>)
and upper tail (threshold <code>ur</code>, GPD shape 
<code>xiR</code> and tail fraction <code>phiuR</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgngcon(x, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean, nsd), xir = 0,
  phiur = TRUE, log = FALSE)

pgngcon(q, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean, nsd), xir = 0,
  phiur = TRUE, lower.tail = TRUE)

qgngcon(p, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean, nsd), xir = 0,
  phiur = TRUE, lower.tail = TRUE)

rgngcon(n = 1, nmean = 0, nsd = 1, ul = qnorm(0.1, nmean, nsd),
  xil = 0, phiul = TRUE, ur = qnorm(0.9, nmean, nsd), xir = 0,
  phiur = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gngcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gngcon_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="gngcon_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="gngcon_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="gngcon_+3A_xil">xil</code></td>
<td>
<p>lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gngcon_+3A_phiul">phiul</code></td>
<td>
<p>probability of being below lower threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gngcon_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="gngcon_+3A_xir">xir</code></td>
<td>
<p>upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="gngcon_+3A_phiur">phiur</code></td>
<td>
<p>probability of being above upper threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gngcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gngcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gngcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gngcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gngcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining normal distribution for the bulk
between the lower and upper thresholds and GPD for upper and lower tails with Continuity Constraints at the lower and upper threshold. The
user can pre-specify <code>phiul</code> and <code>phiur</code> permitting a parameterised
value for the lower and upper tail fraction respectively. Alternatively, when
<code>phiul=TRUE</code> or <code>phiur=TRUE</code> the corresponding tail fraction is
estimated as from the normal bulk model.
</p>
<p>Notice that the tail fraction cannot be 0 or 1, and the sum of upper and lower tail
fractions <code>phiul+phiur&lt;1</code>, so the lower threshold must be less than the upper, 
<code>ul&lt;ur</code>.
</p>
<p>The cumulative distribution function now has three components. The lower tail with 
tail fraction <code class="reqn">\phi_{ul}</code> defined by the normal bulk model (<code>phiul=TRUE</code>)
upto the lower threshold <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_l) G_l(x).</code>
</p>

<p>where <code class="reqn">H(x)</code> is the normal cumulative distribution function (i.e. 
<code>pnorm(ur, nmean, nsd)</code>). The 
<code class="reqn">G_l(X)</code> is the conditional GPD cumulative distribution function with negated
data and threshold, i.e. <code>dgpd(-x, -ul, sigmaul, xil, phiul)</code>. The normal
bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u_r) + [1 - H(u_r)] G(x)</code>
</p>

<p>where <code class="reqn">G(X)</code>.
</p>
<p>The cumulative distribution function for the pre-specified tail fractions 
<code class="reqn">\phi_{ul}</code> and <code class="reqn">\phi_{ur}</code> is more complicated.  The unconditional GPD
is used for the lower tail <code class="reqn">x &lt; u_l</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul} G_l(x).</code>
</p>

<p>The normal bulk model between the thresholds <code class="reqn">u_l \le x \le u_r</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_{ul}+ (1-\phi_{ul}-\phi_{ur}) (H(x) - H(u_l)) / (H(u_r) - H(u_l)).</code>
</p>

<p>Above the threshold <code class="reqn">x &gt; u_r</code> the usual conditional GPD:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1-\phi_{ur}) + \phi_{ur} G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_{ul} = H(u_l)</code> and
<code class="reqn">\phi_{ur} = 1 - H(u_r)</code>.
</p>
<p>The continuity constraint at <code>ur</code> means that:
</p>
<p style="text-align: center;"><code class="reqn">\phi_{ur} g_r(x) = (1-\phi_{ul}-\phi_{ur}) h(u_r)/ (H(u_r) - H(u_l)).</code>
</p>

<p>By rearrangement, the GPD scale parameter <code>sigmaur</code> is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ur = \phi_{ur} (H(u_r) - H(u_l))/ h(u_r) (1-\phi_{ul}-\phi_{ur}).</code>
</p>

<p>where <code class="reqn">h(x)</code>, <code class="reqn">g_l(x)</code> and <code class="reqn">g_r(x)</code> are the normal and conditional GPD
density functions for lower and upper tail respectively. 
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ur = [1-H(u_r)] / h(u_r)</code>
</p>
<p>.
</p>
<p>The continuity constraint at <code>ul</code> means that:
</p>
<p style="text-align: center;"><code class="reqn">\phi_{ul} g_l(x) = (1-\phi_{ul}-\phi_{ur}) h(u_l)/ (H(u_r) - H(u_l)).</code>
</p>

<p>The GPD scale parameter <code>sigmaul</code> is replaced by:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ul = \phi_{ul} (H(u_r) - H(u_l))/ h(u_l) (1-\phi_{ul}-\phi_{ur}).</code>
</p>

<p>In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_ul = H(u_l)/ h(u_l)</code>
</p>
<p>. 
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component, 
<code><a href="stats.html#topic+Normal">dnorm</a></code> for details of normal bulk component,
<code><a href="#topic+normgpd">dnormgpd</a></code> for normal with GPD extreme value
mixture model and <code><a href="#topic+gng">dgng</a></code> for normal bulk with GPD 
upper and lower tails extreme value mixture model.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gngcon">dgngcon</a></code> gives the density, 
<code><a href="#topic+gngcon">pgngcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+gngcon">qgngcon</a></code> gives the quantile function and 
<code><a href="#topic+gngcon">rgngcon</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+gngcon">rgngcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+gngcon">rgngcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Zhao, X., Scarrott, C.J. Reale, M. and Oxley, L. (2010). Extreme value modelling
for forecasting the market crisis. Applied Financial Econometrics 20(1), 63-72.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+hpdcon">hpdcon</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fitmgng">fitmgng</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gngcon: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other fgngcon: <code><a href="#topic+fgngcon">fgngcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rgngcon(1000, phiul = 0.15, phiur = 0.15)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgngcon(xx, phiul = 0.15, phiur = 0.15))

# three tail behaviours
plot(xx, pgngcon(xx), type = "l")
lines(xx, pgngcon(xx, xil = 0.3, xir = 0.3), col = "red")
lines(xx, pgngcon(xx, xil = -0.3, xir = -0.3), col = "blue")
legend("topleft", paste("Symmetric xil=xir=",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rgngcon(1000, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2)
xx = seq(-6, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-6, 6))
lines(xx, dgngcon(xx, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2))

plot(xx, dgngcon(xx, xil = -0.3, phiul = 0.2, xir = 0.3, phiur = 0.2), type = "l", ylim = c(0, 0.4))
lines(xx, dgngcon(xx, xil = -0.3, phiul = 0.3, xir = 0.3, phiur = 0.3), col = "red")
lines(xx, dgngcon(xx, xil = -0.3, phiul = TRUE, xir = 0.3, phiur = TRUE), col = "blue")
legend("topleft", c("phiul = phiur = 0.2", "phiul = phiur = 0.3", "Bulk Tail Fraction"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gpd'>Generalised Pareto Distribution (GPD)</h2><span id='topic+gpd'></span><span id='topic+dgpd'></span><span id='topic+pgpd'></span><span id='topic+qgpd'></span><span id='topic+rgpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the generalised Pareto distribution, either
as a conditional on being above the threshold <code>u</code> or unconditional.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgpd(x, u = 0, sigmau = 1, xi = 0, phiu = 1, log = FALSE)

pgpd(q, u = 0, sigmau = 1, xi = 0, phiu = 1, lower.tail = TRUE)

qgpd(p, u = 0, sigmau = 1, xi = 0, phiu = 1, lower.tail = TRUE)

rgpd(n = 1, u = 0, sigmau = 1, xi = 0, phiu = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="gpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="gpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="gpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code></p>
</td></tr>
<tr><td><code id="gpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="gpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="gpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="gpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="gpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GPD with parameters scale <code class="reqn">\sigma_u</code> and shape <code class="reqn">\xi</code> has
conditional density of being above the threshold <code>u</code> given by
</p>
<p style="text-align: center;"><code class="reqn">f(x | X &gt; u) = 1/\sigma_u [1 + \xi(x - u)/\sigma_u]^{-1/\xi - 1}</code>
</p>

<p>for non-zero <code class="reqn">\xi</code>, <code class="reqn">x &gt; u</code> and <code class="reqn">\sigma_u &gt; 0</code>. Further, 
<code class="reqn">[1+\xi (x - u) / \sigma_u] &gt; 0</code> which for <code class="reqn">\xi &lt; 0</code> implies 
<code class="reqn">u &lt; x \le u - \sigma_u/\xi</code>. In the special case of <code class="reqn">\xi = 0</code>
considered in the limit <code class="reqn">\xi \rightarrow 0</code>, which is
treated here as <code class="reqn">|\xi| &lt; 1e-6</code>, it reduces to the exponential:
</p>
<p style="text-align: center;"><code class="reqn">f(x | X &gt; u) = 1/\sigma_u exp(-(x - u)/\sigma_u).</code>
</p>

<p>The unconditional density is obtained by mutltiplying this by the
survival probability (or <em>tail fraction</em>) <code class="reqn">\phi_u = P(X &gt; u)</code>
giving <code class="reqn">f(x) = \phi_u f(x | X &gt; u)</code>.
</p>
<p>The syntax of these functions are similar to those of the 
<code><a href="evd.html#topic+gpd">evd</a></code> package, so most code using these functions can
be reused. The key difference is the introduction of <code>phiu</code> to
permit output of unconditional quantities.
</p>


<h3>Value</h3>

<p><code><a href="#topic+gpd">dgpd</a></code> gives the density,
<code><a href="#topic+gpd">pgpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+gpd">qgpd</a></code> gives the quantile function and 
<code><a href="#topic+gpd">rgpd</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Based on the
<code><a href="evd.html#topic+gpd">gpd</a></code> functions in the <code><a href="evd.html#topic+gpd">evd</a></code> package for which their author's contributions are gratefully acknowledged.
They are designed to have similar syntax and functionality to simplify the transition for users of these packages.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+gpd">rgpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default threshold <code>u=0</code> and tail fraction
<code>phiu=1</code> which essentially assumes the user provide excesses above 
<code>u</code> by default, rather than exceedances. The default sample size for 
<code><a href="#topic+gpd">rgpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Some key differences arise for <code>phiu=1</code> and <code>phiu&lt;1</code> (see examples below):
</p>

<ol>
<li><p> For <code>phiu=1</code> the <code><a href="#topic+gpd">dgpd</a></code> evaluates as zero for
quantiles below the threshold <code>u</code> and <code><a href="#topic+gpd">pgpd</a></code>
evaluates over <code class="reqn">[0, 1]</code>.
</p>
</li>
<li><p> For <code>phiu=1</code> then <code><a href="#topic+gpd">pgpd</a></code> evaluates as zero
below the threshold <code>u</code>. For <code>phiu&lt;1</code> it evaluates as <code class="reqn">1-\phi_u</code> at
the threshold and <code>NA</code> below the threshold.
</p>
</li>
<li><p> For <code>phiu=1</code> the quantiles from <code><a href="#topic+gpd">qgpd</a></code> are
above threshold and equal to threshold for <code>phiu=0</code>. For <code>phiu&lt;1</code> then
within upper tail, <code>p &gt; 1 - phiu</code>, it will give conditional quantiles
above threshold, but when below the threshold, <code>p &lt;= 1 - phiu</code>, these
are set to <code>NA</code>.
</p>
</li>
<li><p> When simulating GPD variates using <code><a href="#topic+gpd">rgpd</a></code> if
<code>phiu=1</code> then all values are above the threshold. For <code>phiu&lt;1</code> then
a standard uniform <code class="reqn">U</code> is simulated and the variate will be classified as
above the threshold if <code class="reqn">u&lt;\phi</code>, and below the threshold otherwise. This is
equivalent to a binomial random variable for simulated number of exceedances. Those
above the threshold are then simulated from the conditional GPD and those below
the threshold and set to <code>NA</code>.
</p>
</li></ol>

<p>These conditions are intuitive and consistent with <code><a href="evd.html#topic+gpd">evd</a></code>,
which assumes missing data are below threshold.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>
<p>Coles, S.G. (2001). An Introduction to Statistical Modelling of Extreme Values.
Springer Series in Statistics. Springer-Verlag: London.
</p>


<h3>See Also</h3>

<p><code><a href="evd.html#topic+gpd">evd</a></code> package and <code><a href="evd.html#topic+fpot">fpot</a></code>
</p>
<p>Other gpd: <code><a href="#topic+fgpd">fgpd</a></code>
</p>
<p>Other fgpd: <code><a href="#topic+fgpd">fgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
par(mfrow = c(2, 2))

x = rgpd(1000) # simulate sample from GPD
xx = seq(-1, 10, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dgpd(xx))

# three tail behaviours
plot(xx, pgpd(xx), type = "l")
lines(xx, pgpd(xx, xi = 0.3), col = "red")
lines(xx, pgpd(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

# GPD when xi=0 is exponential, and demonstrating phiu
x = rexp(1000)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dgpd(xx, u = 0, sigmau = 1, xi = 0), lwd = 2)
lines(xx, dgpd(xx, u = 0.5, phiu = 1 - pexp(0.5)), col = "red", lwd = 2)
lines(xx, dgpd(xx, u = 1.5, phiu = 1 - pexp(1.5)), col = "blue", lwd = 2)
legend("topright", paste("u =",c(0, 0.5, 1.5)),
  col=c("black", "red", "blue"), lty = 1, lwd = 2)

# Quantile function and phiu
p = pgpd(xx)
plot(qgpd(p), p, type = "l")
lines(xx, pgpd(xx, u = 2), col = "red")
lines(xx, pgpd(xx, u = 5, phiu = 0.2), col = "blue")
legend("bottomright", c("u = 0 phiu = 1","u = 2 phiu = 1","u = 5 phiu = 0.2"),
  col=c("black", "red", "blue"), lty = 1)
  
</code></pre>

<hr>
<h2 id='hillplot'>Hill Plot</h2><span id='topic+hillplot'></span>

<h3>Description</h3>

<p>Plots the Hill plot and some its variants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hillplot(data, orderlim = NULL, tlim = NULL, hill.type = "Hill",
  r = 2, x.theta = FALSE, y.alpha = FALSE, alpha = 0.05,
  ylim = NULL, legend.loc = "topright",
  try.thresh = quantile(data[data &gt; 0], 0.9, na.rm = TRUE),
  main = paste(ifelse(x.theta, "Alt", ""), hill.type, " Plot", sep = ""),
  xlab = ifelse(x.theta, "theta", "order"),
  ylab = paste(ifelse(x.theta, "Alt", ""), hill.type, ifelse(y.alpha,
  " alpha", " xi"), "&gt;0", sep = ""), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hillplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="hillplot_+3A_orderlim">orderlim</code></td>
<td>
<p>vector of (lower, upper) limits of order statistics
to plot estimator, or <code>NULL</code> to use default values</p>
</td></tr>
<tr><td><code id="hillplot_+3A_tlim">tlim</code></td>
<td>
<p>vector of (lower, upper) limits of range of threshold
to plot estimator, or <code>NULL</code> to use default values</p>
</td></tr>
<tr><td><code id="hillplot_+3A_hill.type">hill.type</code></td>
<td>
<p>&quot;Hill&quot; or &quot;SmooHill&quot;</p>
</td></tr>
<tr><td><code id="hillplot_+3A_r">r</code></td>
<td>
<p>smoothing factor for &quot;SmooHill&quot; (integer &gt; 1)</p>
</td></tr>
<tr><td><code id="hillplot_+3A_x.theta">x.theta</code></td>
<td>
<p>logical, should order (<code>FALSE</code>) or theta (<code>TRUE</code>) be given on x-axis</p>
</td></tr>
<tr><td><code id="hillplot_+3A_y.alpha">y.alpha</code></td>
<td>
<p>logical, should shape xi (<code>FALSE</code>) or tail index alpha (<code>TRUE</code>) be given on y-axis</p>
</td></tr>
<tr><td><code id="hillplot_+3A_alpha">alpha</code></td>
<td>
<p>significance level over range (0, 1), or <code>NULL</code> for no CI</p>
</td></tr>
<tr><td><code id="hillplot_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limits or <code>NULL</code></p>
</td></tr>
<tr><td><code id="hillplot_+3A_legend.loc">legend.loc</code></td>
<td>
<p>location of legend (see <code><a href="graphics.html#topic+legend">legend</a></code>) or <code>NULL</code> for no legend</p>
</td></tr>
<tr><td><code id="hillplot_+3A_try.thresh">try.thresh</code></td>
<td>
<p>vector of thresholds to consider</p>
</td></tr>
<tr><td><code id="hillplot_+3A_main">main</code></td>
<td>
<p>title of plot</p>
</td></tr>
<tr><td><code id="hillplot_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="hillplot_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="hillplot_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the plotting functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces the Hill, AltHill, SmooHill and AltSmooHill plots,
including confidence intervals.
</p>
<p>For an ordered iid sequence <code class="reqn">X_{(1)}\ge X_{(2)}\ge\cdots\ge X_{(n)} &gt; 0</code> 
the Hill (1975) estimator using <code class="reqn">k</code> order statistics is given by 
</p>
<p style="text-align: center;"><code class="reqn">H_{k,n}=\frac{1}{k}\sum_{i=1}^{k} \log(\frac{X_{(i)}}{X_{(k+1)}})</code>
</p>

<p>which is the pseudo-likelihood estimator of reciprocal of the tail index <code class="reqn">\xi=/\alpha&gt;0</code>
for regularly varying tails (e.g. Pareto distribution).  The Hill estimator
is defined on orders <code class="reqn">k&gt;2</code>, as when<code class="reqn">k=1</code> the </p>
<p style="text-align: center;"><code class="reqn">H_{1,n}=0</code>
</p>
<p>. The
function will calculate the Hill estimator for <code class="reqn">k\ge 1</code>.
The simple Hill plot is shown for <code>hill.type="Hill"</code>.
</p>
<p>Once a sufficiently low order statistic is reached the Hill estimator will
be constant, upto sample uncertainty, for regularly varying tails. The Hill
plot is a plot of </p>
<p style="text-align: center;"><code class="reqn">H_{k,n}</code>
</p>
<p> against the <code class="reqn">k</code>. Symmetric asymptotic
normal confidence intervals assuming Pareto tails are provided.
</p>
<p>These so called Hill's horror plots can be difficult to interpret. A smooth
form of the Hill estimator was suggested by Resnick and Starica (1997): 
</p>
<p style="text-align: center;"><code class="reqn">smooH_{k,n}=\frac{1}{(r-1)k}\sum_{j=k+1}^{rk} H_{j,n}</code>
</p>
<p> giving the
smooHill plot which is shown for <code>hill.type="SmooHill"</code>. The smoothing
factor is <code>r=2</code> by default.
</p>
<p>It has also been suggested to plot the order on a log scale, by plotting
the points <code class="reqn">(\theta, H_{\lceil n^\theta\rceil, n})</code> for 
<code class="reqn">0\le \theta \le 1</code>. This gives the so called AltHill and AltSmooHill
plots. The alternative x-axis scale is chosen by <code>x.theta=TRUE</code>.
</p>
<p>The Hill estimator is for the GPD shape <code class="reqn">\xi&gt;0</code>, or the reciprocal of the
tail index <code class="reqn">\alpha=1/\xi&gt;0</code>. The shape is plotted by default using
<code>y.alpha=FALSE</code> and the tail index is plotted when <code>y.alpha=TRUE</code>.
</p>
<p>A pre-chosen threshold (or more than one) can be given in
<code>try.thresh</code>. The estimated parameter (<code class="reqn">\xi</code> or <code class="reqn">\alpha</code>) at
each threshold are plot by a horizontal solid line for all higher thresholds. 
The threshold should be set as low as possible, so a dashed line is shown
below the pre-chosen threshold. If the Hill estimator is similar to the
dashed line then a lower threshold may be chosen.
</p>
<p>If no order statistic (or threshold) limits are provided <code>orderlim =
  tlim = NULL</code> then the lowest order statistic is set to <code class="reqn">X_{(3)}</code> and
highest possible value <code class="reqn">X_{(n-1)}</code>. However, the Hill estimator is always
output for all <code class="reqn">k=1, \ldots, n-1</code> and <code class="reqn">k=1, \ldots, floor(n/k)</code> for
smooHill estimator.
</p>
<p>The missing (<code>NA</code> and <code>NaN</code>) and non-finite values are ignored.
Non-positive data are ignored.
</p>
<p>The lower x-axis is the order <code class="reqn">k</code> or <code class="reqn">\theta</code>, chosen by the option
<code>x.theta=FALSE</code> and <code>x.theta=TRUE</code> respectively. The upper axis
is for the corresponding threshold.
</p>


<h3>Value</h3>

<p><code><a href="#topic+hillplot">hillplot</a></code> gives the Hill plot. It also 
returns a dataframe containing columns of the order statistics, order, Hill
estimator, it's standard devation and <code class="reqn">100(1 - \alpha)\%</code> confidence
interval (when requested). When the SmooHill plot is selected, then the corresponding
SmooHill estimates are appended.
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Younes Mouatasim, Risk Dynamics, Brussels for reporting various bugs in these functions.
</p>


<h3>Note</h3>

<p>Warning: Hill plots are not location invariant.
</p>
<p>Asymptotic Wald type CI's are estimated for non-<code>NULL</code> signficance level <code>alpha</code>
for the shape parameter, assuming exactly Pareto tails. When plotting on the tail index scale,
then a simple  reciprocal transform of the CI is applied which may be sub-optimal.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p>Hill, B.M. (1975). A simple general approach to inference about the tail of a distribution. Annals of Statistics 13, 331-341.
</p>
<p>Resnick, S. and Starica, C. (1997). Smoothing the Hill estimator. Advances in Applied Probability 29, 271-293.
</p>
<p>Resnick, S. (1997). Discussion of the Danish Data of Large Fire Insurance Losses. Astin Bulletin 27, 139-151.
</p>


<h3>See Also</h3>

<p><code><a href="evir.html#topic+hill">hill</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Reproduce graphs from Figure 2.4 of Resnick (1997)
data(danish, package="evir")
par(mfrow = c(2, 2))

# Hill plot
hillplot(danish, y.alpha=TRUE, ylim=c(1.1, 2))

# AltHill plot
hillplot(danish, y.alpha=TRUE, x.theta=TRUE, ylim=c(1.1, 2))

# AltSmooHill plot
hillplot(danish, hill.type="SmooHill", r=3, y.alpha=TRUE, x.theta=TRUE, ylim=c(1.35, 1.85))

# AltHill and AltSmooHill plot (no CI's or legend)
hillout = hillplot(danish, hill.type="SmooHill", r=3, y.alpha=TRUE, 
 x.theta=TRUE, try.thresh = c(), alpha=NULL, ylim=c(1.1, 2), legend.loc=NULL, lty=2)
n = length(danish)
with(hillout[3:n,], lines(log(ks)/log(n), 1/H, type="s"))

## End(Not run)
</code></pre>

<hr>
<h2 id='hpd'>Hybrid Pareto Extreme Value Mixture Model</h2><span id='topic+hpd'></span><span id='topic+dhpd'></span><span id='topic+phpd'></span><span id='topic+qhpd'></span><span id='topic+rhpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the hybrid Pareto extreme value mixture model.
The parameters are the normal mean <code>nmean</code> and standard deviation <code>nsd</code> and 
GPD shape <code>xi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhpd(x, nmean = 0, nsd = 1, xi = 0, log = FALSE)

phpd(q, nmean = 0, nsd = 1, xi = 0, lower.tail = TRUE)

qhpd(p, nmean = 0, nsd = 1, xi = 0, lower.tail = TRUE)

rhpd(n = 1, nmean = 0, nsd = 1, xi = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="hpd_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="hpd_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="hpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="hpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="hpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="hpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="hpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="hpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining normal distribution for the bulk
below the threshold and GPD for upper tail which is continuous in its zeroth and
first derivative at the threshold. 
</p>
<p>But it has one important difference to all the other mixture models. The
hybrid Pareto does not include the usual tail fraction <code>phiu</code> scaling, 
i.e. so the GPD is not treated as a conditional model for the exceedances. 
The unscaled GPD is simply spliced with the normal truncated at the
threshold, with no rescaling to account for the proportion above the
threshold being applied. The parameters have to adjust for the lack of tail 
fraction scaling.
</p>
<p>The cumulative distribution function defined upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x) / r </code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (H(u) +  G(x)) / r </code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the normal and conditional GPD
cumulative distribution functions. The normalisation constant <code class="reqn">r</code> ensures a proper
density and is given by<code>r = 1 + pnorm(u, mean = nmean, sd = nsd)</code>, i.e. the 1 comes from
integration of the unscaled GPD and the second term is from the usual normal component.
</p>
<p>The two continuity constraints leads to the threshold <code>u</code> and GPD scale <code>sigmau</code> being replaced
by a function of the normal mean, standard deviation and GPD shape parameters. 
Determined from setting <code class="reqn">h(u) = g(u)</code> where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the normal and unscaled GPD
density functions (i.e. <code>dnorm(u, nmean, nsd)</code> and
<code>dgpd(u, u, sigmau, xi)</code>). The continuity constraint on its first derivative at the threshold 
means that <code class="reqn">h'(u) = g'(u)</code>. Then the Lambert-W function is used for replacing
the threshold u and GPD scale sigmau in terms of the normal mean, standard deviation
and GPD shape xi.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Normal">dnorm</a></code> for details of normal bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+hpd">dhpd</a></code> gives the density, 
<code><a href="#topic+hpd">phpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+hpd">qhpd</a></code> gives the quantile function and 
<code><a href="#topic+hpd">rhpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+hpd">rhpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+hpd">rhpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Carreau, J. and Y. Bengio (2008). A hybrid Pareto model for asymmetric fat-tailed data:
the univariate case. Extremes 12 (1), 53-76.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>.
</p>
<p>The condmixt package written by one of the
original authors of the hybrid Pareto model (Carreau and Bengio, 2008) also has 
similar functions for the hybrid Pareto (hpareto) and
mixture of hybrid Paretos (hparetomixt), which are
more flexible as they also permit the model to be truncated at zero.
</p>
<p>Other hpd: <code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>
</p>
<p>Other hpdcon: <code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other fhpd: <code><a href="#topic+fhpd">fhpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

xx = seq(-5, 20, 0.01)
f1 = dhpd(xx, nmean = 0, nsd = 1, xi = 0.4)
plot(xx, f1, type = "l")
abline(v = 0.4942921)

# three tail behaviours
plot(xx, phpd(xx), type = "l")
lines(xx, phpd(xx, xi = 0.3), col = "red")
lines(xx, phpd(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)
 
sim = rhpd(10000, nmean = 0, nsd = 1.5, xi = 0.2)
hist(sim, freq = FALSE, 100, xlim = c(-5, 20), ylim = c(0, 0.2))
lines(xx, dhpd(xx, nmean = 0, nsd = 1.5, xi = 0.2), col = "blue")

plot(xx, dhpd(xx, nmean = 0, nsd = 1.5, xi = 0), type = "l")
lines(xx, dhpd(xx, nmean = 0, nsd = 1.5, xi = 0.2), col = "red")
lines(xx, dhpd(xx, nmean = 0, nsd = 1.5, xi = -0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='hpdcon'>Hybrid Pareto Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+hpdcon'></span><span id='topic+dhpdcon'></span><span id='topic+phpdcon'></span><span id='topic+qhpdcon'></span><span id='topic+rhpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the hybrid Pareto extreme value mixture model,
but only continuity at threshold and not necessarily continuous in first derivative.
The parameters are the normal mean <code>nmean</code> and standard deviation <code>nsd</code> and 
GPD shape <code>xi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhpdcon(x, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd), xi = 0,
  log = FALSE)

phpdcon(q, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd), xi = 0,
  lower.tail = TRUE)

qhpdcon(p, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd), xi = 0,
  lower.tail = TRUE)

rhpdcon(n = 1, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  xi = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="hpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining normal distribution for the bulk
below the threshold and GPD for upper tail which is continuous at threshold and
not necessarily continuous in first derivative.
</p>
<p>But it has one important difference to all the other mixture models. The
hybrid Pareto does not include the usual tail fraction <code>phiu</code> scaling, 
i.e. so the GPD is not treated as a conditional model for the exceedances. 
The unscaled GPD is simply spliced with the normal truncated at the
threshold, with no rescaling to account for the proportion above the
threshold being applied. The parameters have to adjust for the lack of tail 
fraction scaling.
</p>
<p>The cumulative distribution function defined upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x) / r </code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (H(u) +  G(x)) / r </code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the normal and conditional GPD
cumulative distribution functions. The normalisation constant <code class="reqn">r</code> ensures a proper
density and is given by<code>r = 1 + pnorm(u, mean = nmean, sd = nsd)</code>, i.e. the 1 comes from
integration of the unscaled GPD and the second term is from the usual normal component.
</p>
<p>The continuity constraint leads to the GPD scale <code>sigmau</code> being replaced
by a function of the normal mean, standard deviation, threshold and GPD shape parameters. 
Determined from setting <code class="reqn">h(u) = g(u)</code> where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the normal and unscaled GPD
density functions (i.e. <code>dnorm(u, nmean, nsd)</code> and
<code>dgpd(u, u, sigmau, xi)</code>).
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Normal">dnorm</a></code> for details of normal bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+hpdcon">dhpdcon</a></code> gives the density, 
<code><a href="#topic+hpdcon">phpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+hpdcon">qhpdcon</a></code> gives the quantile function and 
<code><a href="#topic+hpdcon">rhpdcon</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+hpdcon">rhpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+hpdcon">rhpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Carreau, J. and Y. Bengio (2008). A hybrid Pareto model for asymmetric fat-tailed data:
the univariate case. Extremes 12 (1), 53-76.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>. 
</p>
<p>The condmixt package written by one of the
original authors of the hybrid Pareto model (Carreau and Bengio, 2008) also has 
similar functions for the hybrid Pareto (hpareto) and
mixture of hybrid Paretos (hparetomixt), which are
more flexible as they also permit the model to be truncated at zero.
</p>
<p>Other hpd: <code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+hpd">hpd</a></code>
</p>
<p>Other hpdcon: <code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+hpd">hpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpd">hpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other fhpdcon: <code><a href="#topic+fhpdcon">fhpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

xx = seq(-5, 20, 0.01)
f1 = dhpdcon(xx, nmean = 0, nsd = 1.5, u = 1, xi = 0.4)
plot(xx, f1, type = "l")
abline(v = 4)

# three tail behaviours
plot(xx, phpdcon(xx), type = "l")
lines(xx, phpdcon(xx, xi = 0.3), col = "red")
lines(xx, phpdcon(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)
 
sim = rhpdcon(10000, nmean = 0, nsd = 1.5, u = 1, xi = 0.2)
hist(sim, freq = FALSE, 100, xlim = c(-5, 20), ylim = c(0, 0.2))
lines(xx, dhpdcon(xx, nmean = 0, nsd = 1.5, u = 1, xi = 0.2), col = "blue")

plot(xx, dhpdcon(xx, nmean = 0, nsd = 1.5, u = 1, xi = 0), type = "l")
lines(xx, dhpdcon(xx, nmean = 0, nsd = 1.5, u = 1, xi = 0.2), col = "red")
lines(xx, dhpdcon(xx, nmean = 0, nsd = 1.5, u = 1, xi = -0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "u = 1, xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='internal'>Internal Functions</h2><span id='topic+internal'></span><span id='topic+kdenx'></span><span id='topic+pkdenx'></span><span id='topic+bckdenxsimple'></span><span id='topic+pbckdenxsimple'></span><span id='topic+bckdenxcutnorm'></span><span id='topic+pbckdenxcutnorm'></span><span id='topic+bckdenxrenorm'></span><span id='topic+pbckdenxrenorm'></span><span id='topic+bckdenxreflect'></span><span id='topic+pbckdenxreflect'></span><span id='topic+pxb'></span><span id='topic+bckdenxbeta1'></span><span id='topic+pbckdenxbeta1'></span><span id='topic+bckdenxbeta2'></span><span id='topic+pbckdenxbeta2'></span><span id='topic+bckdenxgamma1'></span><span id='topic+pbckdenxgamma1'></span><span id='topic+bckdenxgamma2'></span><span id='topic+pbckdenxgamma2'></span><span id='topic+bckdenxcopula'></span><span id='topic+pbckdenxcopula'></span><span id='topic+pbckdenxlog'></span><span id='topic+pbckdenxnn'></span><span id='topic+qmix'></span><span id='topic+qmixprime'></span><span id='topic+qgbgmix'></span><span id='topic+qgbgmixprime'></span><span id='topic+pscounts'></span>

<h3>Description</h3>

<p>Internal functions not designed to be used directly, but are all exported
to make them visible to users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdenx(x, kerncentres, lambda, kernel = "gaussian")

pkdenx(x, kerncentres, lambda, kernel = "gaussian")

bckdenxsimple(x, kerncentres, lambda, kernel = "gaussian")

pbckdenxsimple(x, kerncentres, lambda, kernel = "gaussian")

bckdenxcutnorm(x, kerncentres, lambda, kernel = "gaussian")

pbckdenxcutnorm(x, kerncentres, lambda, kernel = "gaussian")

bckdenxrenorm(x, kerncentres, lambda, kernel = "gaussian")

pbckdenxrenorm(x, kerncentres, lambda, kernel = "gaussian")

bckdenxreflect(x, kerncentres, lambda, kernel = "gaussian")

pbckdenxreflect(x, kerncentres, lambda, kernel = "gaussian")

pxb(x, lambda)

bckdenxbeta1(x, kerncentres, lambda, xmax)

pbckdenxbeta1(x, kerncentres, lambda, xmax)

bckdenxbeta2(x, kerncentres, lambda, xmax)

pbckdenxbeta2(x, kerncentres, lambda, xmax)

bckdenxgamma1(x, kerncentres, lambda)

pbckdenxgamma1(x, kerncentres, lambda)

bckdenxgamma2(x, kerncentres, lambda)

pbckdenxgamma2(x, kerncentres, lambda)

bckdenxcopula(x, kerncentres, lambda, xmax)

pbckdenxcopula(x, kerncentres, lambda, xmax)

pbckdenxlog(x, kerncentres, lambda, offset, kernel = "gaussian")

pbckdenxnn(x, kerncentres, lambda, kernel = "gaussian", nn)

qmix(x, u, epsilon)

qmixprime(x, u, epsilon)

qgbgmix(x, ul, ur, epsilon)

qgbgmixprime(x, ul, ur, epsilon)

pscounts(x, beta, design.knots, degree)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="internal_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="internal_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="internal_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="internal_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="internal_+3A_xmax">xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="internal_+3A_offset">offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="internal_+3A_nn">nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td></tr>
<tr><td><code id="internal_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="internal_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="internal_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="internal_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="internal_+3A_beta">beta</code></td>
<td>
<p>vector of B-spline coefficients (required)</p>
</td></tr>
<tr><td><code id="internal_+3A_design.knots">design.knots</code></td>
<td>
<p>spline knots for splineDesign function</p>
</td></tr>
<tr><td><code id="internal_+3A_degree">degree</code></td>
<td>
<p>degree of B-splines (0 is constant, 1 is linear, etc.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal functions not designed to be used directly. No error
checking of the inputs is carried out, so user must be know what they are doing.
They are undocumented, but are made visible to the user.
</p>
<p>Mostly, these are used in the kernel density estimation functions.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+density">density</a></code>, <code><a href="#topic+kden">kden</a></code>
and <code><a href="#topic+bckden">bckden</a></code>.
</p>

<hr>
<h2 id='itmgng'>Normal Bulk with GPD Upper and Lower Tails Interval Transition Mixture Model</h2><span id='topic+itmgng'></span><span id='topic+ditmgng'></span><span id='topic+pitmgng'></span><span id='topic+qitmgng'></span><span id='topic+ritmgng'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with normal
for bulk distribution between the upper and lower thresholds with
conditional GPD's for the two tails and interval transition. The parameters are the normal mean
<code>nmean</code> and standard deviation <code>nsd</code>, interval half-width <code>espilon</code>,
lower tail (threshold <code>ul</code>, GPD scale <code>sigmaul</code> and shape <code>xil</code> and
tail fraction <code>phiul</code>) and upper tail (threshold <code>ur</code>, GPD scale
<code>sigmaur</code> and shape <code>xiR</code> and tail fraction <code>phiuR</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ditmgng(x, nmean = 0, nsd = 1, epsilon = nsd, ul = qnorm(0.1,
  nmean, nsd), sigmaul = nsd, xil = 0, ur = qnorm(0.9, nmean, nsd),
  sigmaur = nsd, xir = 0, log = FALSE)

pitmgng(q, nmean = 0, nsd = 1, epsilon = nsd, ul = qnorm(0.1,
  nmean, nsd), sigmaul = nsd, xil = 0, ur = qnorm(0.9, nmean, nsd),
  sigmaur = nsd, xir = 0, lower.tail = TRUE)

qitmgng(p, nmean = 0, nsd = 1, epsilon, ul = qnorm(0.1, nmean, nsd),
  sigmaul = nsd, xil = 0, ur = qnorm(0.9, nmean, nsd),
  sigmaur = nsd, xir = 0, lower.tail = TRUE)

ritmgng(n = 1, nmean = 0, nsd = 1, epsilon = sd, ul = qnorm(0.1,
  nmean, nsd), sigmaul = nsd, xil = 0, ur = qnorm(0.9, nmean, nsd),
  sigmaur = nsd, xir = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="itmgng_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="itmgng_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="itmgng_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="itmgng_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="itmgng_+3A_ul">ul</code></td>
<td>
<p>lower tail threshold</p>
</td></tr>
<tr><td><code id="itmgng_+3A_sigmaul">sigmaul</code></td>
<td>
<p>lower tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="itmgng_+3A_xil">xil</code></td>
<td>
<p>lower tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="itmgng_+3A_ur">ur</code></td>
<td>
<p>upper tail threshold</p>
</td></tr>
<tr><td><code id="itmgng_+3A_sigmaur">sigmaur</code></td>
<td>
<p>upper tail GPD scale parameter (positive)</p>
</td></tr>
<tr><td><code id="itmgng_+3A_xir">xir</code></td>
<td>
<p>upper tail GPD shape parameter</p>
</td></tr>
<tr><td><code id="itmgng_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="itmgng_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="itmgng_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="itmgng_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="itmgng_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interval transition extreme value mixture model combines a normal
distribution for the bulk between the lower and upper thresholds and GPD for
upper and lower tails, with a smooth transition over the interval 
<code class="reqn">(u-epsilon, u+epsilon)</code> (where <code class="reqn">u</code> can be exchanged for the lower and
upper thresholds). The mixing function warps the normal to map from 
<code class="reqn">(u-epsilon, u)</code> to <code class="reqn">(u-epsilon, u+epsilon)</code> and warps the GPD from 
<code class="reqn">(u, u+epsilon)</code> to <code class="reqn">(u-epsilon, u+epsilon)</code>.
</p>
<p>The cumulative distribution function is defined by 
</p>
<p style="text-align: center;"><code class="reqn">F(x)=\kappa(G_l(q(x)) + H_t(r(x)) + G_u(p(x)))</code>
</p>

<p>where <code class="reqn">H_t(x)</code> is the truncated normal cdf, i.e. <code>pnorm(x, nmean, nsd)</code>.
The conditional GPD for the upper tail has cdf <code class="reqn">G_u(x)</code>, 
i.e. <code>pgpd(x, ur, sigmaur, xir)</code> and lower tail cdf <code class="reqn">G_l(x)</code> is for the 
negated support, i.e. <code>1 - pgpd(-x, -ul, sigmaul, xil)</code>. The truncated 
normal is not renormalised to be proper, so <code class="reqn">H_t(x)</code> contributes
<code>pnorm(ur, nmean, nsd) - pnorm(ul, nmean, nsd)</code> to the cdf
for all <code class="reqn">x\geq (u_r + \epsilon)</code> and zero below <code class="reqn">x\leq (u_l - \epsilon)</code>.
The normalisation constant <code class="reqn">\kappa</code> ensures a proper density, given by 
<code>1/(2 + pnorm(ur, nmean, nsd) - pnorm(ul, nmean, nsd)</code> where the
2 is from two GPD components and latter is contribution from normal component.
</p>
<p>The mixing functions <code class="reqn">q(x)</code>, <code class="reqn">r(x)</code> and <code class="reqn">p(x)</code> are reformulated from the 
<code class="reqn">q_i(x)</code> suggested by Holden and Haug (2013). These are symmetric about each
threshold, which for convenience will be referred to a simply <code class="reqn">u</code>. So for
computational convenience only a single <code class="reqn">q(x;u)</code> has been implemented for the
lower and upper GPD components called
<code><a href="#topic+internal">qmix</a></code> for a given <code class="reqn">u</code>, with the complementary
mixing function then defined as <code class="reqn">p(x;u)=-q(-x;-u)</code>. The bulk model mixing
function <code class="reqn">r(x)</code> utilises the equivalent of the <code class="reqn">q(x)</code> for the lower threshold and
<code class="reqn">p(x)</code> for the upper threshold, so these are reused in the bulk mixing function  
<code><a href="#topic+internal">qgbgmix</a></code>.
</p>
<p>A minor adaptation of the mixing function has been applied following a similar
approach to that explained in <code><a href="#topic+itmnormgpd">ditmnormgpd</a></code>. For the
bulk model mixing function <code class="reqn">r(x)</code>, we need <code class="reqn">r(x)&lt;=ul</code> for all <code class="reqn">x\le ul - epsilon</code> and 
<code class="reqn">r(x)&gt;=ur</code> for all <code class="reqn">x\ge ur+epsilon</code>, as then the bulk model will contribute
zero below the lower interval and the constant <code class="reqn">H_t(ur)=H(ur)-H(ul)</code> for all
<code class="reqn">x</code> above the upper interval. Holden and Haug (2013) define
<code class="reqn">r(x)=x-\epsilon</code> for all <code class="reqn">x\ge ur</code> and <code class="reqn">r(x)=x+\epsilon</code> for all <code class="reqn">x\le ul</code>.
For more straightforward and interpretable 
computational implementation the mixing function has been set to the lower threshold
<code class="reqn">r(x)=u_l</code> for all <code class="reqn">x\le u_l-\epsilon</code> and to the upper threshold
<code class="reqn">r(x)=u_r</code> for all <code class="reqn">x\le u_r+\epsilon</code>, so the cdf/pdf of the normal model can be used
directly. We do not have to define cdf/pdf for the non-proper truncated normal
seperately. As such <code class="reqn">r'(x)=0</code> for all <code class="reqn">x\le u_l-\epsilon</code> and <code class="reqn">x\ge u_r+\epsilon</code> in
<code><a href="#topic+internal">qmixxprime</a></code>, which also makes it clearer that
normal does not contribute to either tails beyond the intervals and vice-versa. 
</p>
<p>The quantile function within the transition interval is not available in
closed form, so has to be solved numerically. Outside of the
interval, the quantile are obtained from the normal and GPD components directly.
</p>


<h3>Value</h3>

<p><code><a href="#topic+itmgng">ditmgng</a></code> gives the density, 
<code><a href="#topic+itmgng">pitmgng</a></code> gives the cumulative distribution function,
<code><a href="#topic+itmgng">qitmgng</a></code> gives the quantile function and 
<code><a href="#topic+itmgng">ritmgng</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main input (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+itmgng">ritmgng</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+itmgng">ritmgng</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Holden, L. and Haug, O. (2013). A mixture model for unsupervised tail
estimation. arxiv:0902.4137
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gng">gng</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>,
<code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>
</p>
<p>Other itmgng: <code><a href="#topic+fitmgng">fitmgng</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fitmgng">fitmgng</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other itmnormgpd: <code><a href="#topic+fitmgng">fitmgng</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+itmnormgpd">itmnormgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

xx = seq(-5, 5, 0.01)
ul = -1.5;ur = 2
epsilon = 0.8
kappa = 1/(2 + pnorm(ur, 0, 1) - pnorm(ul, 0, 1))

f = ditmgng(xx, nmean = 0, nsd = 1, epsilon, ul, sigmaul = 1, xil = 0.5, ur, sigmaur = 1, xir = 0.5)
plot(xx, f, ylim = c(0, 0.5), xlim = c(-5, 5), type = 'l', lwd = 2, xlab = "x", ylab = "density")
lines(xx, kappa * dgpd(-xx, -ul, sigmau = 1, xi = 0.5), col = "blue", lty = 2, lwd = 2)
lines(xx, kappa * dnorm(xx, 0, 1), col = "red", lty = 2, lwd = 2)
lines(xx, kappa * dgpd(xx, ur, sigmau = 1, xi = 0.5), col = "green", lty = 2, lwd = 2)
abline(v = ul + epsilon * seq(-1, 1), lty = c(2, 1, 2), col = "blue")
abline(v = ur + epsilon * seq(-1, 1), lty = c(2, 1, 2), col = "green")
legend('topright', c('Normal-GPD ITM', 'kappa*GPD Lower', 'kappa*Normal', 'kappa*GPD Upper'),
      col = c("black", "blue", "red", "green"), lty = c(1, 2, 2, 2), lwd = 2)

# cdf contributions
F = pitmgng(xx, nmean = 0, nsd = 1, epsilon, ul, sigmaul = 1, xil = 0.5, ur, sigmaur = 1, xir = 0.5)
plot(xx, F, ylim = c(0, 1), xlim = c(-5, 5), type = 'l', lwd = 2, xlab = "x", ylab = "cdf")
lines(xx[xx &lt; ul], kappa * (1 - pgpd(-xx[xx &lt; ul], -ul, 1, 0.5)), col = "blue", lty = 2, lwd = 2)
lines(xx[(xx &gt;= ul) &amp; (xx &lt;= ur)], kappa * (1 + pnorm(xx[(xx &gt;= ul) &amp; (xx &lt;= ur)], 0, 1) -
      pnorm(ul, 0, 1)), col = "red", lty = 2, lwd = 2)
lines(xx[xx &gt; ur], kappa * (1 + (pnorm(ur, 0, 1) - pnorm(ul, 0, 1)) +
      pgpd(xx[xx &gt; ur], ur, sigmau = 1, xi = 0.5)), col = "green", lty = 2, lwd = 2)
abline(v = ul + epsilon * seq(-1, 1), lty = c(2, 1, 2), col = "blue")
abline(v = ur + epsilon * seq(-1, 1), lty = c(2, 1, 2), col = "green")
legend('topleft', c('Normal-GPD ITM', 'kappa*GPD Lower', 'kappa*Normal', 'kappa*GPD Upper'),
      col = c("black", "blue", "red", "green"), lty = c(1, 2, 2, 2), lwd = 2)

# simulated data density histogram and overlay true density 
x = ritmgng(10000, nmean = 0, nsd = 1, epsilon, ul, sigmaul = 1, xil = 0.5,
                                                ur, sigmaur = 1, xir = 0.5)
hist(x, freq = FALSE, breaks = seq(-1000, 1000, 0.1), xlim = c(-5, 5))
lines(xx, ditmgng(xx, nmean = 0, nsd = 1, epsilon, ul, sigmaul = 1, xil = 0.5,
  ur, sigmaur = 1, xir = 0.5), lwd = 2, col = 'black')

## End(Not run)

</code></pre>

<hr>
<h2 id='itmnormgpd'>Normal Bulk and GPD Tail Interval Transition Mixture Model</h2><span id='topic+itmnormgpd'></span><span id='topic+ditmnormgpd'></span><span id='topic+pitmnormgpd'></span><span id='topic+qitmnormgpd'></span><span id='topic+ritmnormgpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the normal bulk and GPD tail 
interval transition mixture model. The
parameters are the normal mean <code>nmean</code> and standard deviation <code>nsd</code>,
threshold <code>u</code>, interval half-width <code>epsilon</code>, GPD scale
<code>sigmau</code> and shape <code>xi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ditmnormgpd(x, nmean = 0, nsd = 1, epsilon = nsd, u = qnorm(0.9,
  nmean, nsd), sigmau = nsd, xi = 0, log = FALSE)

pitmnormgpd(q, nmean = 0, nsd = 1, epsilon = nsd, u = qnorm(0.9,
  nmean, nsd), sigmau = nsd, xi = 0, lower.tail = TRUE)

qitmnormgpd(p, nmean = 0, nsd = 1, epsilon = nsd, u = qnorm(0.9,
  nmean, nsd), sigmau = nsd, xi = 0, lower.tail = TRUE)

ritmnormgpd(n = 1, nmean = 0, nsd = 1, epsilon = nsd,
  u = qnorm(0.9, nmean, nsd), sigmau = nsd, xi = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="itmnormgpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="itmnormgpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interval transition mixture model combines a normal for
the bulk model with GPD for the tail model, with a smooth transition
over the interval <code class="reqn">(u-epsilon, u+epsilon)</code>. The mixing function warps
the normal to map from <code class="reqn">(u-epsilon, u)</code> to <code class="reqn">(u-epsilon, u+epsilon)</code> and
warps the GPD from <code class="reqn">(u, u+epsilon)</code> to <code class="reqn">(u-epsilon, u+epsilon)</code>.
</p>
<p>The cumulative distribution function is defined by 
</p>
<p style="text-align: center;"><code class="reqn">F(x)=\kappa(H_t(q(x)) + G(p(x)))</code>
</p>

<p>where <code class="reqn">H_t(x)</code> and <code class="reqn">G(x)</code> are the truncated normal and
conditional GPD cumulative distribution functions 
(i.e. <code>pnorm(x, nmean, nsd)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively. The truncated 
normal is not renormalised to be proper, so <code class="reqn">H_t(x)</code> contrubutes
<code>pnorm(u, nmean, nsd)</code> to the cdf for all <code class="reqn">x\geq (u + \epsilon)</code>.
The normalisation constant <code class="reqn">\kappa</code> ensures a proper density, given by 
<code>1/(1+pnorm(u, nmean, nsd))</code> where 1 is from GPD component and
latter is contribution from normal component.
</p>
<p>The mixing functions <code class="reqn">q(x)</code> and <code class="reqn">p(x)</code> suggested by Holden and Haug (2013)
have been implemented. These are symmetric about the threshold <code class="reqn">u</code>. So for
computational convenience only <code class="reqn">q(x;u)</code> has been implemented as 
<code><a href="#topic+internal">qmix</a></code>
for a given <code class="reqn">u</code>, with the complementary mixing function is then defined as
<code class="reqn">p(x;u)=-q(-x;-u)</code>.
</p>
<p>A minor adaptation of the mixing function has been applied.  For the mixture model to
function correctly <code class="reqn">q(x)&gt;=u</code> for all <code class="reqn">x\ge u+\epsilon</code>, as then the bulk model will contribute
the constant <code class="reqn">H_t(u)=H(u)</code> for all <code class="reqn">x</code> above the interval. Holden and Haug (2013) define
<code class="reqn">q(x)=x-\epsilon</code> for all <code class="reqn">x\ge u</code>. For more straightforward and interpretable 
computational implementation the mixing function has been set to the threshold
<code class="reqn">q(x)=u</code> for all <code class="reqn">x\ge u</code>, so the cdf/pdf of the normal model can be used
directly. We do not have to define cdf/pdf for the non-proper truncated normal
seperately. As such <code class="reqn">q'(x)=0</code> for all <code class="reqn">x\ge u</code> in
<code><a href="#topic+internal">qmixxprime</a></code>, which also makes it clearer that
normal does not contribute to the tail above the interval and vice-versa. 
</p>
<p>The quantile function within the transition interval is not available in
closed form, so has to be solved numerically. Outside of the
interval, the quantile are obtained from the normal and GPD components directly.
</p>


<h3>Value</h3>

<p><code><a href="#topic+itmnormgpd">ditmnormgpd</a></code> gives the density, 
<code><a href="#topic+itmnormgpd">pitmnormgpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+itmnormgpd">qitmnormgpd</a></code> gives the quantile function and 
<code><a href="#topic+itmnormgpd">ritmnormgpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+itmnormgpd">ritmnormgpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+itmnormgpd">ritmnormgpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Holden, L. and Haug, O. (2013). A mixture model for unsupervised tail
estimation. arxiv:0902.4137
</p>


<h3>See Also</h3>

<p><code><a href="#topic+normgpd">normgpd</a></code>, <code><a href="#topic+gpd">gpd</a></code>
and <code><a href="stats.html#topic+Normal">dnorm</a></code>
</p>
<p>Other itmnormgpd: <code><a href="#topic+fitmgng">fitmgng</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+itmgng">itmgng</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

xx = seq(-4, 5, 0.01)
u = 1.5
epsilon = 0.4
kappa = 1/(1 + pnorm(u, 0, 1))

f = ditmnormgpd(xx, nmean = 0, nsd = 1, epsilon, u, sigmau = 1, xi = 0.5)
plot(xx, f, ylim = c(0, 1), xlim = c(-4, 5), type = 'l', lwd = 2, xlab = "x", ylab = "density")
lines(xx, kappa * dgpd(xx, u, sigmau = 1, xi = 0.5), col = "red", lty = 2, lwd = 2)
lines(xx, kappa * dnorm(xx, 0, 1), col = "blue", lty = 2, lwd = 2)
abline(v = u + epsilon * seq(-1, 1), lty = c(2, 1, 2))
legend('topright', c('Normal-GPD ITM', 'kappa*Normal', 'kappa*GPD'),
      col = c("black", "blue", "red"), lty = c(1, 2, 2), lwd = 2)

# cdf contributions
F = pitmnormgpd(xx, nmean = 0, nsd = 1, epsilon, u, sigmau = 1, xi = 0.5)
plot(xx, F, ylim = c(0, 1), xlim = c(-4, 5), type = 'l', lwd = 2, xlab = "x", ylab = "cdf")
lines(xx[xx &gt; u], kappa * (pnorm(u, 0, 1) + pgpd(xx[xx &gt; u], u, sigmau = 1, xi = 0.5)),
     col = "red", lty = 2, lwd = 2)
lines(xx[xx &lt;= u], kappa * pnorm(xx[xx &lt;= u], 0, 1), col = "blue", lty = 2, lwd = 2)
abline(v = u + epsilon * seq(-1, 1), lty = c(2, 1, 2))
legend('topleft', c('Normal-GPD ITM', 'kappa*Normal', 'kappa*GPD'),
      col = c("black", "blue", "red"), lty = c(1, 2, 2), lwd = 2)

# simulated data density histogram and overlay true density 
x = ritmnormgpd(10000, nmean = 0, nsd = 1, epsilon, u, sigmau = 1, xi = 0.5)
hist(x, freq = FALSE, breaks = seq(-4, 1000, 0.1), xlim = c(-4, 5))
lines(xx, ditmnormgpd(xx, nmean = 0, nsd = 1, epsilon, u, sigmau = 1, xi = 0.5),
  lwd = 2, col = 'black')  

## End(Not run)

</code></pre>

<hr>
<h2 id='itmweibullgpd'>Weibull Bulk and GPD Tail Interval Transition Mixture Model</h2><span id='topic+itmweibullgpd'></span><span id='topic+ditmweibullgpd'></span><span id='topic+pitmweibullgpd'></span><span id='topic+qitmweibullgpd'></span><span id='topic+ritmweibullgpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the Weibull bulk and GPD tail 
interval transition mixture model. The
parameters are the Weibull shape <code>wshape</code> and scale <code>wscale</code>,
threshold <code>u</code>, interval half-width <code>epsilon</code>, GPD scale
<code>sigmau</code> and shape <code>xi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ditmweibullgpd(x, wshape = 1, wscale = 1, epsilon = sqrt(wscale^2 *
  gamma(1 + 2/wshape) - (wscale * gamma(1 + 1/wshape))^2),
  u = qweibull(0.9, wshape, wscale), sigmau = sqrt(wscale^2 * gamma(1 +
  2/wshape) - (wscale * gamma(1 + 1/wshape))^2), xi = 0, log = FALSE)

pitmweibullgpd(q, wshape = 1, wscale = 1, epsilon = sqrt(wscale^2 *
  gamma(1 + 2/wshape) - (wscale * gamma(1 + 1/wshape))^2),
  u = qweibull(0.9, wshape, wscale), sigmau = sqrt(wscale^2 * gamma(1 +
  2/wshape) - (wscale * gamma(1 + 1/wshape))^2), xi = 0,
  lower.tail = TRUE)

qitmweibullgpd(p, wshape = 1, wscale = 1, epsilon = sqrt(wscale^2 *
  gamma(1 + 2/wshape) - (wscale * gamma(1 + 1/wshape))^2),
  u = qweibull(0.9, wshape, wscale), sigmau = sqrt(wscale^2 * gamma(1 +
  2/wshape) - (wscale * gamma(1 + 1/wshape))^2), xi = 0,
  lower.tail = TRUE)

ritmweibullgpd(n = 1, wshape = 1, wscale = 1,
  epsilon = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), u = qweibull(0.9, wshape, wscale),
  sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale * gamma(1 +
  1/wshape))^2), xi = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="itmweibullgpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_wshape">wshape</code></td>
<td>
<p>Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_wscale">wscale</code></td>
<td>
<p>Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_epsilon">epsilon</code></td>
<td>
<p>interval half-width</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="itmweibullgpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interval transition mixture model combines a Weibull for
the bulk model with GPD for the tail model, with a smooth transition
over the interval <code class="reqn">(u-epsilon, u+epsilon)</code>. The mixing function warps
the Weibull to map from <code class="reqn">(u-epsilon, u)</code> to <code class="reqn">(u-epsilon, u+epsilon)</code> and
warps the GPD from <code class="reqn">(u, u+epsilon)</code> to <code class="reqn">(u-epsilon, u+epsilon)</code>.
</p>
<p>The cumulative distribution function is defined by 
</p>
<p style="text-align: center;"><code class="reqn">F(x)=\kappa(H_t(q(x)) + G(p(x)))</code>
</p>

<p>where <code class="reqn">H_t(x)</code> and <code class="reqn">G(X)</code> are the truncated Weibull and
conditional GPD cumulative distribution functions 
(i.e. <code>pweibull(x, wshape, wscale)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively. The truncated 
Weibull is not renormalised to be proper, so <code class="reqn">H_t(x)</code> contrubutes
<code>pweibull(u, wshape, wscale)</code> to the cdf for all <code class="reqn">x\geq (u + \epsilon)</code>.
The normalisation constant <code class="reqn">\kappa</code> ensures a proper density, given by 
<code>1/(1+pweibull(u, wshape, wscale))</code> where 1 is from GPD component and
latter is contribution from Weibull component.
</p>
<p>The mixing functions <code class="reqn">q(x)</code> and <code class="reqn">p(x)</code> suggested by Holden and Haug (2013)
have been implemented. These are symmetric about the threshold <code class="reqn">u</code>. So for
computational convenience only <code class="reqn">q(x;u)</code> has been implemented as 
<code><a href="#topic+internal">qmix</a></code>
for a given <code class="reqn">u</code>, with the complementary mixing function is then defined as
<code class="reqn">p(x;u)=-q(-x;-u)</code>.
</p>
<p>A minor adaptation of the mixing function has been applied.  For the mixture model to
function correctly <code class="reqn">q(x)&gt;=u</code> for all <code class="reqn">x\ge u+\epsilon</code>, as then the bulk model will contribute
the constant <code class="reqn">H_t(u)=H(u)</code> for all <code class="reqn">x</code> above the interval. Holden and Haug (2013) define
<code class="reqn">q(x)=x-\epsilon</code> for all <code class="reqn">x\ge u</code>. For more straightforward and interpretable 
computational implementation the mixing function has been set to the threshold
<code class="reqn">q(x)=u</code> for all <code class="reqn">x\ge u</code>, so the cdf/pdf of the Weibull model can be used
directly. We do not have to define cdf/pdf for the non-proper truncated Weibull
seperately. As such <code class="reqn">q'(x)=0</code> for all <code class="reqn">x\ge u</code> in
<code><a href="#topic+internal">qmixxprime</a></code>, which also it makes clearer that
Weibull does not contribute to the tail above the interval and vice-versa. 
</p>
<p>The quantile function within the transition interval is not available in
closed form, so has to be solved numerically. Outside of the
interval, the quantile are obtained from the Weibull and GPD components directly.
</p>


<h3>Value</h3>

<p><code><a href="#topic+itmweibullgpd">ditmweibullgpd</a></code> gives the density, 
<code><a href="#topic+itmweibullgpd">pitmweibullgpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+itmweibullgpd">qitmweibullgpd</a></code> gives the quantile function and 
<code><a href="#topic+itmweibullgpd">ritmweibullgpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+itmweibullgpd">ritmweibullgpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+itmweibullgpd">ritmweibullgpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Holden, L. and Haug, O. (2013). A mixture model for unsupervised tail
estimation. arxiv:0902.4137
</p>


<h3>See Also</h3>

<p><code><a href="#topic+weibullgpd">weibullgpd</a></code>, <code><a href="#topic+gpd">gpd</a></code>
and <code><a href="stats.html#topic+Weibull">dweibull</a></code>
</p>
<p>Other itmweibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>, <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other weibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>, <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other weibullgpdcon: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>,
<code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other fitmweibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

xx = seq(0.001, 5, 0.01)
u = 1.5
epsilon = 0.4
kappa = 1/(1 + pweibull(u, 2, 1))

f = ditmweibullgpd(xx, wshape = 2, wscale = 1, epsilon, u, sigmau = 1, xi = 0.5)
plot(xx, f, ylim = c(0, 1), xlim = c(0, 5), type = 'l', lwd = 2, xlab = "x", ylab = "density")
lines(xx, kappa * dgpd(xx, u, sigmau = 1, xi = 0.5), col = "red", lty = 2, lwd = 2)
lines(xx, kappa * dweibull(xx, 2, 1), col = "blue", lty = 2, lwd = 2)
abline(v = u + epsilon * seq(-1, 1), lty = c(2, 1, 2))
legend('topright', c('Weibull-GPD ITM', 'kappa*Weibull', 'kappa*GPD'),
      col = c("black", "blue", "red"), lty = c(1, 2, 2), lwd = 2)

# cdf contributions
F = pitmweibullgpd(xx, wshape = 2, wscale = 1, epsilon, u, sigmau = 1, xi = 0.5)
plot(xx, F, ylim = c(0, 1), xlim = c(0, 5), type = 'l', lwd = 2, xlab = "x", ylab = "cdf")
lines(xx[xx &gt; u], kappa * (pweibull(u, 2, 1) + pgpd(xx[xx &gt; u], u, sigmau = 1, xi = 0.5)),
     col = "red", lty = 2, lwd = 2)
lines(xx[xx &lt;= u], kappa * pweibull(xx[xx &lt;= u], 2, 1), col = "blue", lty = 2, lwd = 2)
abline(v = u + epsilon * seq(-1, 1), lty = c(2, 1, 2))
legend('topright', c('Weibull-GPD ITM', 'kappa*Weibull', 'kappa*GPD'),
      col = c("black", "blue", "red"), lty = c(1, 2, 2), lwd = 2)

# simulated data density histogram and overlay true density 
x = ritmweibullgpd(10000, wshape = 2, wscale = 1, epsilon, u, sigmau = 1, xi = 0.5)
hist(x, freq = FALSE, breaks = seq(0, 1000, 0.1), xlim = c(0, 5))
lines(xx, ditmweibullgpd(xx, wshape = 2, wscale = 1, epsilon, u, sigmau = 1, xi = 0.5),
  lwd = 2, col = 'black')  

## End(Not run)

</code></pre>

<hr>
<h2 id='kden'>Kernel Density Estimation, With Variety of Kernels</h2><span id='topic+kden'></span><span id='topic+dkden'></span><span id='topic+pkden'></span><span id='topic+qkden'></span><span id='topic+rkden'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the kernel density estimation using the kernel
specified by <code>kernel</code>, with a constant bandwidth specified by either
<code>lambda</code> or <code>bw</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkden(x, kerncentres, lambda = NULL, bw = NULL, kernel = "gaussian",
  log = FALSE)

pkden(q, kerncentres, lambda = NULL, bw = NULL, kernel = "gaussian",
  lower.tail = TRUE)

qkden(p, kerncentres, lambda = NULL, bw = NULL, kernel = "gaussian",
  lower.tail = TRUE)

rkden(n = 1, kerncentres, lambda = NULL, bw = NULL,
  kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kden_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="kden_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="kden_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kden_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kden_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="kden_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="kden_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="kden_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="kden_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="kden_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kernel density estimation using one of many possible kernels with a
constant bandwidth. 
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code> help
documentation with the <code>"gaussian"</code> as the default choice.
</p>
<p>The density function <code><a href="#topic+kden">dkden</a></code> produces exactly the
same density estimate as <code><a href="stats.html#topic+density">density</a></code> when a sequence
of <code>x</code> values are provided, see examples. The latter function is far
more efficient in this situation as it takes advantage of the computational
savings from doing the kernel smoothing in the spectral domain (using the FFT),
where the convolution becomes a multiplication. So even after accounting for applying
the (Fast) Fourier Transform (FFT) and its inverse it is much more efficient
especially for a large sample size or large number of evaluation points.
</p>
<p>However, this KDE function applies the less efficient convolution using the
standard definition:
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_(x) = \frac{1}{n} \sum_{j=1}^{n} K(\frac{x - x_j}{\lambda})</code>
</p>

<p>where <code class="reqn">K(.)</code> is the density function for the standard
kernel. Thus are no restriction on the values <code>x</code> can take. For example, in the 
<code>"gaussian"</code> kernel case for a particular <code>x</code> the density is evaluated as
<code>mean(dnorm(x, kerncentres, lambda))</code> for the density and
<code>mean(pnorm(x, kerncentres, lambda))</code> for cumulative distribution
function which is slower than the FFT but is more adaptable.
</p>
<p>An inversion sampler is used for random number generation which also rather
inefficient, as it can be carried out more efficiently using a mixture representation.
</p>
<p>The quantile function is rather complicated as there is no closed form solution,
so is obtained by numerical approximation of the inverse cumulative distribution function
<code class="reqn">P(X \le q) = p</code> to find <code class="reqn">q</code>. The quantile function 
<code><a href="#topic+kden">qkden</a></code> evaluates the KDE cumulative distribution
function over the range from <code>c(max(kerncentre) - lambda, max(kerncentre) + lambda)</code>,
or <code>c(max(kerncentre) - 5*lambda, max(kerncentre) + 5*lambda)</code> for normal kernel.
Outside of this range the quantiles are set to <code>-Inf</code> for lower tail and <code>Inf</code>
for upper tail. A sequence of values
of length fifty times the number of kernels (with minimum of 1000) is first
calculated. Spline based interpolation using <code><a href="stats.html#topic+splinefun">splinefun</a></code>,
with default <code>monoH.FC</code> method, is then used to approximate the quantile
function. This is a similar approach to that taken
by Matt Wand in the <code><a href="ks.html#topic+kde">qkde</a></code> in the <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>If no bandwidth is provided <code>lambda=NULL</code> and <code>bw=NULL</code> then the normal
reference rule is used, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>


<h3>Value</h3>

<p><code><a href="#topic+kden">dkden</a></code> gives the density, 
<code><a href="#topic+kden">pkden</a></code> gives the cumulative distribution function,
<code><a href="#topic+kden">qkden</a></code> gives the quantile function and 
<code><a href="#topic+kden">rkden</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+kden">kden</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+kden">rkden</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other bckden: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fkden">fkden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other fkden: <code><a href="#topic+fkden">fkden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

nk=50
x = rnorm(nk)
xx = seq(-5, 5, 0.01)
plot(xx, dnorm(xx))
rug(x)
for (i in 1:nk) lines(xx, dnorm(xx, x[i], sd = bw.nrd0(x))*0.05)
lines(xx, dkden(xx, x), lwd = 2, col = "red")
lines(density(x), lty = 2, lwd = 2, col = "green")
legend("topright", c("True Density", "KDE Using evmix", "KDE Using density function"),
lty = c(1, 1, 2), lwd = c(1, 2, 2), col = c("black", "red", "green"))

# Estimate bandwidth using cross-validation likelihood
x = rnorm(nk)
fit = fkden(x)
hist(x, nk/5, freq = FALSE, xlim = c(-5, 5), ylim = c(0, 0.6)) 
rug(x)
for (i in 1:nk) lines(xx, dnorm(xx, x[i], sd = fit$bw)*0.05)
lines(xx,dnorm(xx), col = "black")
lines(xx, dkden(xx, x, lambda = fit$lambda), lwd = 2, col = "red")
lines(density(x), lty = 2, lwd = 2, col = "green")
lines(density(x, bw = fit$bw), lwd = 2, lty = 2,  col = "blue")
legend("topright", c("True Density", "KDE fitted evmix",
"KDE Using density, default bandwidth", "KDE Using density, c-v likelihood bandwidth"),
lty = c(1, 1, 2, 2), lwd = c(1, 2, 2, 2), col = c("black", "red", "green", "blue"))

plot(xx, pnorm(xx), type = "l")
rug(x)
lines(xx, pkden(xx, x), lwd = 2, col = "red")
lines(xx, pkden(xx, x, lambda = fit$lambda), lwd = 2, col = "green")
# green and blue (quantile) function should be same
p = seq(0, 1, 0.001)
lines(qkden(p, x, lambda = fit$lambda), p, lwd = 2, lty = 2, col = "blue") 
legend("topleft", c("True Density", "KDE using evmix, normal reference rule",
"KDE using evmix, c-v likelihood","KDE quantile function, c-v likelihood"),
lty = c(1, 1, 1, 2), lwd = c(1, 2, 2, 2), col = c("black", "red", "green", "blue"))

xnew = rkden(10000, x, lambda = fit$lambda)
hist(xnew, breaks = 100, freq = FALSE, xlim = c(-5, 5))
rug(xnew)
lines(xx,dnorm(xx), col = "black")
lines(xx, dkden(xx, x), lwd = 2, col = "red")
legend("topright", c("True Density", "KDE Using evmix"),
lty = c(1, 2), lwd = c(1, 2), col = c("black", "red"))

## End(Not run)

</code></pre>

<hr>
<h2 id='kdengpd'>Kernel Density Estimate and GPD Tail Extreme Value Mixture Model</h2><span id='topic+kdengpd'></span><span id='topic+dkdengpd'></span><span id='topic+pkdengpd'></span><span id='topic+qkdengpd'></span><span id='topic+rkdengpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with kernel density estimate for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the bandwidth <code>lambda</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkdengpd(x, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", log = FALSE)

pkdengpd(q, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", lower.tail = TRUE)

qkdengpd(p, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian", lower.tail = TRUE)

rkdengpd(n = 1, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), sigmau = sqrt(6 *
  var(kerncentres))/pi, xi = 0, phiu = TRUE, bw = NULL,
  kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kdengpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kdengpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="kdengpd_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kdengpd_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="kdengpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining kernel density estimate (KDE) for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
KDE bulk model.
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the kernel density estimate (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the KDE and conditional GPD
cumulative distribution functions respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>If no bandwidth is provided <code>lambda=NULL</code> and <code>bw=NULL</code> then the normal
reference rule is used, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="#topic+kden">dkden</a></code> for details of KDE bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+kdengpd">dkdengpd</a></code> gives the density, 
<code><a href="#topic+kdengpd">pkdengpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+kdengpd">qkdengpd</a></code> gives the quantile function and 
<code><a href="#topic+kdengpd">rkdengpd</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+kdengpd">kdengpd</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The <code>kerncentres</code> can also be a scalar or vector.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+kdengpd">rkdengpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters or kernel centres.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>, <code><a href="#topic+kdengpdcon">kdengpdcon</a></code>
</p>
<p>Other gkg: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpd">fkdengpd</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other bckdengpd: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkg">gkg</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other fkdengpd: <code><a href="#topic+fkdengpd">fkdengpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

kerncentres=rnorm(500, 0, 1)
xx = seq(-4, 4, 0.01)
hist(kerncentres, breaks = 100, freq = FALSE)
lines(xx, dkdengpd(xx, kerncentres, u = 1.2, sigmau = 0.56, xi = 0.1))

plot(xx, pkdengpd(xx, kerncentres), type = "l")
lines(xx, pkdengpd(xx, kerncentres, xi = 0.3), col = "red")
lines(xx, pkdengpd(xx, kerncentres, xi = -0.3), col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
      col=c("black", "red", "blue"), lty = 1, cex = 0.5)

x = rkdengpd(1000, kerncentres, phiu = 0.1, u = 1.2, sigmau = 0.56, xi = 0.1)
xx = seq(-4, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 6))
lines(xx, dkdengpd(xx, kerncentres, phiu = 0.1, u = 1.2, sigmau = 0.56, xi = 0.1))

plot(xx, dkdengpd(xx, kerncentres, xi=0, phiu = 0.1), type = "l")
lines(xx, dkdengpd(xx, kerncentres, xi=0.2, phiu = 0.1), col = "red")
lines(xx, dkdengpd(xx, kerncentres, xi=-0.2, phiu = 0.1), col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
      col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='kdengpdcon'>Kernel Density Estimate and GPD Tail Extreme Value Mixture Model With 
Single Continuity Constraint</h2><span id='topic+kdengpdcon'></span><span id='topic+dkdengpdcon'></span><span id='topic+pkdengpdcon'></span><span id='topic+qkdengpdcon'></span><span id='topic+rkdengpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with kernel density
estimate for bulk distribution upto the threshold and conditional GPD above threshold
with continuity at threshold. The parameters
are the bandwidth <code>lambda</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkdengpdcon(x, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", log = FALSE)

pkdengpdcon(q, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", lower.tail = TRUE)

qkdengpdcon(p, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", lower.tail = TRUE)

rkdengpdcon(n = 1, kerncentres, lambda = NULL,
  u = as.vector(quantile(kerncentres, 0.9)), xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kdengpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="kdengpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining kernel density estimate (KDE) for the bulk
below the threshold and GPD for upper tail with continuity at threshold.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
KDE bulk model.
</p>
<p>The alternate bandwidth definitions are discussed in the
<code><a href="#topic+kernels">kernels</a></code>, with the <code>lambda</code> as the default.
The <code>bw</code> specification is the same as used in the
<code><a href="stats.html#topic+density">density</a></code> function.
</p>
<p>The possible kernels are also defined in <code><a href="#topic+kernels">kernels</a></code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the kernel density estimate (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the KDE and conditional GPD
cumulative distribution functions respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the KDE and conditional GPD
density functions respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>.
</p>
<p>If no bandwidth is provided <code>lambda=NULL</code> and <code>bw=NULL</code> then the normal
reference rule is used, using the <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code> function, which is
consistent with the <code><a href="stats.html#topic+density">density</a></code> function. At least two kernel
centres must be provided as the variance needs to be estimated.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="#topic+kden">dkden</a></code> for details of KDE bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+kdengpdcon">dkdengpdcon</a></code> gives the density, 
<code><a href="#topic+kdengpdcon">pkdengpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+kdengpdcon">qkdengpdcon</a></code> gives the quantile function and 
<code><a href="#topic+kdengpdcon">rkdengpdcon</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+kdengpdcon">kdengpdcon</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The <code>kerncentres</code> can also be a scalar or vector.
</p>
<p>The kernel centres <code>kerncentres</code> can either be a single datapoint or a vector
of data. The kernel centres (<code>kerncentres</code>) and locations to evaluate density (<code>x</code>)
and cumulative distribution function (<code>q</code>) would usually be different.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>kerncentres</code>, <code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+kdengpdcon">rkdengpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters or kernel centres.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="#topic+kfun">kfun</a></code>,
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="stats.html#topic+bandwidth">bw.nrd0</a></code>
and <code><a href="ks.html#topic+kde">dkde</a></code> in <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>
<p>Other kden: <code><a href="#topic+bckden">bckden</a></code>, <code><a href="#topic+fbckden">fbckden</a></code>,
<code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>,
<code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpd: <code><a href="#topic+bckdengpd">bckdengpd</a></code>,
<code><a href="#topic+fbckdengpd">fbckdengpd</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+fkden">fkden</a></code>, <code><a href="#topic+gkg">gkg</a></code>,
<code><a href="#topic+kdengpd">kdengpd</a></code>, <code><a href="#topic+kden">kden</a></code>
</p>
<p>Other kdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fgkgcon">fgkgcon</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+fkdengpd">fkdengpd</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>, <code><a href="#topic+kdengpd">kdengpd</a></code>
</p>
<p>Other gkgcon: <code><a href="#topic+fgkgcon">fgkgcon</a></code>, <code><a href="#topic+fgkg">fgkg</a></code>,
<code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>, <code><a href="#topic+gkgcon">gkgcon</a></code>,
<code><a href="#topic+gkg">gkg</a></code>
</p>
<p>Other bckdengpdcon: <code><a href="#topic+bckdengpdcon">bckdengpdcon</a></code>,
<code><a href="#topic+bckdengpd">bckdengpd</a></code>, <code><a href="#topic+bckden">bckden</a></code>,
<code><a href="#topic+fbckdengpdcon">fbckdengpdcon</a></code>, <code><a href="#topic+fbckdengpd">fbckdengpd</a></code>,
<code><a href="#topic+fbckden">fbckden</a></code>, <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>,
<code><a href="#topic+gkgcon">gkgcon</a></code>
</p>
<p>Other fkdengpdcon: <code><a href="#topic+fkdengpdcon">fkdengpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

kerncentres=rnorm(500, 0, 1)
xx = seq(-4, 4, 0.01)
hist(kerncentres, breaks = 100, freq = FALSE)
lines(xx, dkdengpdcon(xx, kerncentres, u = 1.2, xi = 0.1))

plot(xx, pkdengpdcon(xx, kerncentres), type = "l")
lines(xx, pkdengpdcon(xx, kerncentres, xi = 0.3), col = "red")
lines(xx, pkdengpdcon(xx, kerncentres, xi = -0.3), col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
      col=c("black", "red", "blue"), lty = 1, cex = 0.5)

x = rkdengpdcon(1000, kerncentres, phiu = 0.2, u = 1, xi = 0.2)
xx = seq(-4, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 6))
lines(xx, dkdengpdcon(xx, kerncentres, phiu = 0.2, u = 1, xi = -0.1))

plot(xx, dkdengpdcon(xx, kerncentres, xi=0, u = 1, phiu = 0.2), type = "l")
lines(xx, dkdengpdcon(xx, kerncentres, xi=0.2, u = 1, phiu = 0.2), col = "red")
lines(xx, dkdengpdcon(xx, kerncentres, xi=-0.2, u = 1, phiu = 0.2), col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
      col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='kernels'>Kernel functions</h2><span id='topic+kernels'></span><span id='topic+kdz'></span><span id='topic+kpz'></span><span id='topic+kdgaussian'></span><span id='topic+kduniform'></span><span id='topic+kdtriangular'></span><span id='topic+kdepanechnikov'></span><span id='topic+kdbiweight'></span><span id='topic+kdtriweight'></span><span id='topic+kdtricube'></span><span id='topic+kdparzen'></span><span id='topic+kdcosine'></span><span id='topic+kdoptcosine'></span><span id='topic+kpgaussian'></span><span id='topic+kpuniform'></span><span id='topic+kptriangular'></span><span id='topic+kpepanechnikov'></span><span id='topic+kpbiweight'></span><span id='topic+kptriweight'></span><span id='topic+kptricube'></span><span id='topic+kpparzen'></span><span id='topic+kpcosine'></span><span id='topic+kpoptcosine'></span>

<h3>Description</h3>

<p>Functions for commonly used kernels for kernel density estimation. The
density and cumulative distribution functions are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdgaussian(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kduniform(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdtriangular(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdepanechnikov(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdbiweight(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdtriweight(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdtricube(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdparzen(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdcosine(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdoptcosine(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpgaussian(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpuniform(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kptriangular(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpepanechnikov(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpbiweight(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kptriweight(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kptricube(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpparzen(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpcosine(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kpoptcosine(x = 0, lambda = NULL, bw = NULL, kerncentres = 0)

kdz(z, kernel = "gaussian")

kpz(z, kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernels_+3A_x">x</code></td>
<td>
<p>location to evaluate KDE (single scalar or vector)</p>
</td></tr>
<tr><td><code id="kernels_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kernels_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kernels_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="kernels_+3A_z">z</code></td>
<td>
<p>standardised location put into kernel <code>z = (x-kerncentres)/lambda</code></p>
</td></tr>
<tr><td><code id="kernels_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions for the commonly used kernels for kernel density estimation. The
density and cumulative distribution functions are provided. Each function can accept the
bandwidth specified as either:
</p>

<ol>
<li> <p><code>bw</code> - in terms of number of standard deviations of the kernel, consistent
with the defined values in the <code><a href="stats.html#topic+density">density</a></code> function in
the <code>R</code> base libraries
</p>
</li>
<li> <p><code>lambda</code> - in terms of half-width of kernel
</p>
</li></ol>

<p>If both bandwidths are given as <code>NULL</code> then the default bandwidth is <code>lambda=1</code>. If
either one is specified then this will be used. If both are specified then <code>lambda</code>
will be used.
</p>
<p>All the kernels have bounded support <code class="reqn">[-\lambda, \lambda]</code>, except the normal
(<code>"gaussian"</code>) which is unbounded. In the latter, both bandwidths are the same
<code>bw=lambda</code> and equal to the standard deviation.
</p>
<p>Typically,a single location <code>x</code> at which to evaluate kernel is given along with
vector of kernel centres. As such, they are designed to be used with 
<code><a href="base.html#topic+lapply">sapply</a></code> to loop over vector of locations at which to evaluate KDE. 
Alternatively, a vector of locations <code>x</code> can be given with a single scalar kernel centre
<code>kerncentres</code>, which is commonly used when locations are pre-standardised by
<code>(x-kerncentres)/lambda</code> and <code>kerncentre=0</code>. A warnings is given if both the
evaluation locations and kernel centres are vectors as this is not often needed so is
likely to be a user error.
</p>
<p>If no kernel centres are provided then by default it is set to zero (i.e. x is at middle of kernel).
</p>
<p>The following kernels are implemented, with relevant ones having definitions
consistent with those of the <code><a href="stats.html#topic+density">density</a></code> function,
except where specified:
</p>

<ul>
<li> <p><code>gaussian</code> or <code>normal</code>
</p>
</li>
<li> <p><code>uniform</code> or <code>rectangular</code> - same as <code>"rectangular"</code> in 
<code><a href="stats.html#topic+density">density</a></code> function
</p>
</li>
<li> <p><code>triangular</code>
</p>
</li>
<li> <p><code>epanechnikov</code>
</p>
</li>
<li> <p><code>biweight</code>
</p>
</li>
<li> <p><code>triweight</code>
</p>
</li>
<li> <p><code>tricube</code>
</p>
</li>
<li> <p><code>parzen</code>
</p>
</li>
<li> <p><code>cosine</code>
</p>
</li>
<li> <p><code>optcosine</code>
</p>
</li></ul>

<p>The kernel densities are all normalised to unity. See Wikipedia reference below
for their definitions.
</p>
<p>Each kernel's functions can be called individually, or the global functions
<code><a href="#topic+kernels">kdz</a></code> and <code><a href="#topic+kernels">kpz</a></code> for the density and
cumulative distribution function can apply any particular kernel which is specified by the
<code>kernel</code> input. These global functions take the standardised locations
<code>z = (x - kerncentres)/lambda</code>.
</p>


<h3>Value</h3>

<p>code<a href="#topic+kernels">kd*</a>  and <code><a href="#topic+kernels">kp*</a></code> give the
density and cumulative distribution functions for each kernel respectively, where
<code>*</code> is the kernel name. <code><a href="#topic+kernels">kdz</a></code> and
<code><a href="#topic+kernels">kpz</a></code> are the equivalent global functions for all of the 
kernels.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_(statistics)">http://en.wikipedia.org/wiki/Kernel_(statistics)</a>
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+density">density</a></code>, <code><a href="#topic+kden">kden</a></code>
and <code><a href="#topic+bckden">bckden</a></code>.
</p>
<p>Other kernels: <code><a href="#topic+kfun">kfun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx = seq(-2, 2, 0.01)
plot(xx, kdgaussian(xx), type = "l", col = "black",ylim = c(0, 1.2))
lines(xx, kduniform(xx), col = "grey")
lines(xx, kdtriangular(xx), col = "blue")
lines(xx, kdepanechnikov(xx), col = "darkgreen")
lines(xx, kdbiweight(xx), col = "red")
lines(xx, kdtriweight(xx), col = "purple")
lines(xx, kdtricube(xx), col = "orange")
lines(xx, kdparzen(xx), col = "salmon")
lines(xx, kdcosine(xx), col = "cyan")
lines(xx, kdoptcosine(xx), col = "goldenrod")
legend("topright", c("Gaussian", "uniform", "triangular", "Epanechnikov",
"biweight", "triweight", "tricube", "Parzen", "cosine", "optcosine"), lty = 1,
col = c("black", "grey", "blue", "darkgreen", "red", "purple", "orange",
  "salmon", "cyan", "goldenrod"))

</code></pre>

<hr>
<h2 id='kfun'>Various subsidiary kernel function, conversion of bandwidths and evaluating certain
kernel integrals.</h2><span id='topic+kfun'></span><span id='topic+klambda'></span><span id='topic+kbw'></span><span id='topic+check.kinputs'></span><span id='topic+check.kernel'></span><span id='topic+check.kbw'></span><span id='topic+ka0'></span><span id='topic+ka1'></span><span id='topic+ka2'></span>

<h3>Description</h3>

<p>Functions for checking the inputs to the kernel functions, evaluating 
integrals <code class="reqn">\int u^l K*(u) du</code> for <code class="reqn">l = 0, 1, 2</code> and conversion between the two bandwidth
definitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.kinputs(x, lambda, bw, kerncentres, allownull = FALSE)

check.kernel(kernel)

check.kbw(lambda, bw, allownull = FALSE)

klambda(bw = NULL, kernel = "gaussian", lambda = NULL)

kbw(lambda = NULL, kernel = "gaussian", bw = NULL)

ka0(truncpoint, kernel = "gaussian")

ka1(truncpoint, kernel = "gaussian")

ka2(truncpoint, kernel = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfun_+3A_x">x</code></td>
<td>
<p>location to evaluate KDE (single scalar or vector)</p>
</td></tr>
<tr><td><code id="kfun_+3A_lambda">lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kfun_+3A_bw">bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td></tr>
<tr><td><code id="kfun_+3A_kerncentres">kerncentres</code></td>
<td>
<p>kernel centres (typically sample data vector or scalar)</p>
</td></tr>
<tr><td><code id="kfun_+3A_allownull">allownull</code></td>
<td>
<p>logical, where TRUE permits NULL values</p>
</td></tr>
<tr><td><code id="kfun_+3A_kernel">kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td></tr>
<tr><td><code id="kfun_+3A_truncpoint">truncpoint</code></td>
<td>
<p>upper endpoint as standardised location <code>x/lambda</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Various boundary correction methods require integral of (partial moments of)
kernel within the range of support, over the range <code class="reqn">[-1, p]</code> where <code class="reqn">p</code>
is the <code>truncpoint</code> determined by the standardised distance of location <code class="reqn">x</code>
where KDE is being evaluated to the lower bound of zero, i.e. <code>truncpoint = x/lambda</code>.
The exception is the normal kernel which has unbounded support so the <code class="reqn">[-5*\lambda, p]</code> where
<code>lambda</code> is the standard deviation bandwidth. There is a function for each partial moment
of degree (0, 1, 2):
</p>

<ul>
<li> <p><code>ka0</code> - <code class="reqn">\int_{-1}^{p} K*(z) dz</code>
</p>
</li>
<li> <p><code>ka1</code> - <code class="reqn">\int_{-1}^{p} u K*(z) dz</code>
</p>
</li>
<li> <p><code>ka2</code> - <code class="reqn">\int_{-1}^{p} u^2 K*(z) dz</code>
</p>
</li></ul>

<p>Notice that when evaluated at the upper endpoint on the support <code class="reqn">p = 1</code>
(or <code class="reqn">p = \infty</code> for normal) these are the zeroth, first and second moments. In the
normal distribution case the lower bound on the region of integration is <code class="reqn">\infty</code> but
implemented here as <code class="reqn">-5*\lambda</code>. 
These integrals are all specified in closed form, there is no need for numerical integration
(except normal which uses the <code><a href="stats.html#topic+Normal">pnorm</a></code> function). 
</p>
<p>See <code><a href="#topic+kernels">kpu</a></code> for list of kernels and discussion of bandwidth 
definitions (and their default values):
</p>

<ol>
<li> <p><code>bw</code> - in terms of number of standard deviations of the kernel, consistent
with the defined values in the <code><a href="stats.html#topic+density">density</a></code> function in
the <code>R</code> base libraries
</p>
</li>
<li> <p><code>lambda</code> - in terms of half-width of kernel
</p>
</li></ol>

<p>The <code><a href="#topic+kfun">klambda</a></code> function converts the <code>bw</code> to the <code>lambda</code>
equivalent, and <code><a href="#topic+kfun">kbw</a></code> applies converse. These conversions are
kernel specific as they depend on the kernel standard deviations. If both <code>bw</code> and
<code>lambda</code> are provided then the latter is used by default. If neither are provided 
(<code>bw=NULL</code> and <code>lambda=NULL</code>) then default is <code>lambda=1</code>.
</p>
<p><code><a href="#topic+kfun">check.kinputs</a></code> checks all the kernel function inputs,
<code><a href="#topic+kfun">check.klambda</a></code> checks the pair of inputted bandwidths and
<code><a href="#topic+kfun">check.kernel</a></code> checks the kernel names.
</p>


<h3>Value</h3>

<p><code><a href="#topic+kfun">klambda</a></code> and <code><a href="#topic+kfun">kbw</a></code> return the
<code>lambda</code> and <code>bw</code> bandwidths respectively.
</p>
<p>The checking functions <code><a href="#topic+kfun">check.kinputs</a></code>,
<code><a href="#topic+kfun">check.klambda</a></code> and <code><a href="#topic+kfun">check.kernel</a></code>
will stop on errors and return no value.
</p>
<p><code><a href="#topic+kfun">ka0</a></code>, <code><a href="#topic+kfun">ka1</a></code> and <code><a href="#topic+kfun">ka2</a></code>
return the partial moment integrals specified above.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_(statistics)">http://en.wikipedia.org/wiki/Kernel_(statistics)</a>
</p>
<p>Wand and Jones (1995). Kernel Smoothing. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernels">kernels</a></code>, <code><a href="stats.html#topic+density">density</a></code>, 
<code><a href="#topic+kden">kden</a></code> and <code><a href="#topic+bckden">bckden</a></code>.
</p>
<p>Other kernels: <code><a href="#topic+kernels">kernels</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx = seq(-2, 2, 0.01)
plot(xx, kdgaussian(xx), type = "l", col = "black",ylim = c(0, 1.2))
lines(xx, kduniform(xx), col = "grey")
lines(xx, kdtriangular(xx), col = "blue")
lines(xx, kdepanechnikov(xx), col = "darkgreen")
lines(xx, kdbiweight(xx), col = "red")
lines(xx, kdtriweight(xx), col = "purple")
lines(xx, kdtricube(xx), col = "orange")
lines(xx, kdparzen(xx), col = "salmon")
lines(xx, kdcosine(xx), col = "cyan")
lines(xx, kdoptcosine(xx), col = "goldenrod")
legend("topright", c("Gaussian", "uniform", "triangular", "Epanechnikov",
"biweight", "triweight", "tricube", "Parzen", "cosine", "optcosine"), lty = 1,
col = c("black", "grey", "blue", "darkgreen", "red", "purple",
  "salmon", "orange", "cyan", "goldenrod"))

</code></pre>

<hr>
<h2 id='lognormgpd'>Log-Normal Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+lognormgpd'></span><span id='topic+dlognormgpd'></span><span id='topic+plognormgpd'></span><span id='topic+qlognormgpd'></span><span id='topic+rlognormgpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with log-normal for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the log-normal mean <code>lnmean</code> and standard deviation <code>lnsd</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlognormgpd(x, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean, lnsd),
  sigmau = lnsd, xi = 0, phiu = TRUE, log = FALSE)

plognormgpd(q, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean, lnsd),
  sigmau = lnsd, xi = 0, phiu = TRUE, lower.tail = TRUE)

qlognormgpd(p, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean, lnsd),
  sigmau = lnsd, xi = 0, phiu = TRUE, lower.tail = TRUE)

rlognormgpd(n = 1, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean,
  lnsd), sigmau = lnsd, xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lognormgpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_lnmean">lnmean</code></td>
<td>
<p>mean on log scale</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_lnsd">lnsd</code></td>
<td>
<p>standard deviation on log scale (positive)</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="lognormgpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining log-normal distribution for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
log-normal bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the log-normal bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the log-normal and conditional GPD
cumulative distribution functions (i.e. <code>plnorm(x, lnmean, lnsd)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The log-normal is defined on the positive reals, so the threshold must be positive.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Lognormal">dlnorm</a></code> for details of log-normal bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+lognormgpd">dlognormgpd</a></code> gives the density, 
<code><a href="#topic+lognormgpd">plognormgpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+lognormgpd">qlognormgpd</a></code> gives the quantile function and 
<code><a href="#topic+lognormgpd">rlognormgpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+lognormgpd">rlognormgpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+lognormgpd">rlognormgpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Log-normal_distribution">http://en.wikipedia.org/wiki/Log-normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Solari, S. and Losada, M.A. (2004). A unified statistical model for
hydrological variables including the selection of threshold for the peak over
threshold method. Water Resources Research. 48, W10541.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Lognormal">dlnorm</a></code>
</p>
<p>Other lognormgpd: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+flognormgpd">flognormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>
</p>
<p>Other lognormgpdcon: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+flognormgpd">flognormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+itmnormgpd">itmnormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other flognormgpd: <code><a href="#topic+flognormgpd">flognormgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rlognormgpd(1000)
xx = seq(-1, 10, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dlognormgpd(xx))

# three tail behaviours
plot(xx, plognormgpd(xx), type = "l")
lines(xx, plognormgpd(xx, xi = 0.3), col = "red")
lines(xx, plognormgpd(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rlognormgpd(1000, u = 2, phiu = 0.2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dlognormgpd(xx, u = 2, phiu = 0.2))

plot(xx, dlognormgpd(xx, u = 2, xi=0, phiu = 0.2), type = "l")
lines(xx, dlognormgpd(xx, u = 2, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dlognormgpd(xx, u = 2, xi=0.2, phiu = 0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='lognormgpdcon'>Log-Normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+lognormgpdcon'></span><span id='topic+dlognormgpdcon'></span><span id='topic+plognormgpdcon'></span><span id='topic+qlognormgpdcon'></span><span id='topic+rlognormgpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with log-normal for bulk
distribution upto the threshold and conditional GPD above threshold with continuity
at threshold. The parameters
are the log-normal mean <code>lnmean</code> and standard deviation <code>lnsd</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlognormgpdcon(x, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean,
  lnsd), xi = 0, phiu = TRUE, log = FALSE)

plognormgpdcon(q, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean,
  lnsd), xi = 0, phiu = TRUE, lower.tail = TRUE)

qlognormgpdcon(p, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean,
  lnsd), xi = 0, phiu = TRUE, lower.tail = TRUE)

rlognormgpdcon(n = 1, lnmean = 0, lnsd = 1, u = qlnorm(0.9, lnmean,
  lnsd), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lognormgpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_lnmean">lnmean</code></td>
<td>
<p>mean on log scale</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_lnsd">lnsd</code></td>
<td>
<p>standard deviation on log scale (positive)</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="lognormgpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining log-normal distribution for the bulk
below the threshold and GPD for upper tailwith continuity
at threshold.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
log-normal bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the log-normal bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the log-normal and conditional GPD
cumulative distribution functions (i.e. <code>plnorm(x, lnmean, lnsd)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The log-normal is defined on the positive reals, so the threshold must be positive.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the log-normal and conditional GPD
density functions (i.e. <code>dlnorm(x, lnmean, lnsd)</code> and
<code>dgpd(x, u, sigmau, xi)</code>) respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>. 
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Lognormal">dlnorm</a></code> for details of log-normal bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+lognormgpdcon">dlognormgpdcon</a></code> gives the density, 
<code><a href="#topic+lognormgpdcon">plognormgpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+lognormgpdcon">qlognormgpdcon</a></code> gives the quantile function and 
<code><a href="#topic+lognormgpdcon">rlognormgpdcon</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+lognormgpdcon">rlognormgpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+lognormgpdcon">rlognormgpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Log-normal_distribution">http://en.wikipedia.org/wiki/Log-normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Solari, S. and Losada, M.A. (2004). A unified statistical model for
hydrological variables including the selection of threshold for the peak over
threshold method. Water Resources Research. 48, W10541.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Lognormal">dlnorm</a></code>
</p>
<p>Other lognormgpd: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+flognormgpd">flognormgpd</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>
<p>Other lognormgpdcon: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+flognormgpd">flognormgpd</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+itmnormgpd">itmnormgpd</a></code>, <code><a href="#topic+lognormgpd">lognormgpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other flognormgpdcon: <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rlognormgpdcon(1000)
xx = seq(-1, 10, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dlognormgpdcon(xx))

# three tail behaviours
plot(xx, plognormgpdcon(xx), type = "l")
lines(xx, plognormgpdcon(xx, xi = 0.3), col = "red")
lines(xx, plognormgpdcon(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rlognormgpdcon(1000, u = 2, phiu = 0.2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 10))
lines(xx, dlognormgpdcon(xx, u = 2, phiu = 0.2))

plot(xx, dlognormgpdcon(xx, u = 2, xi=0, phiu = 0.2), type = "l")
lines(xx, dlognormgpdcon(xx, u = 2, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dlognormgpdcon(xx, u = 2, xi=0.2, phiu = 0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='mgamma'>Mixture of Gammas Distribution</h2><span id='topic+mgamma'></span><span id='topic+dmgamma'></span><span id='topic+pmgamma'></span><span id='topic+qmgamma'></span><span id='topic+rmgamma'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the mixture of gammas distribution. The parameters
are the multiple gamma shapes <code>mgshape</code> scales <code>mgscale</code> and weights <code>mgweights</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmgamma(x, mgshape = 1, mgscale = 1, mgweight = NULL, log = FALSE)

pmgamma(q, mgshape = 1, mgscale = 1, mgweight = NULL,
  lower.tail = TRUE)

qmgamma(p, mgshape = 1, mgscale = 1, mgweight = NULL,
  lower.tail = TRUE)

rmgamma(n = 1, mgshape = 1, mgscale = 1, mgweight = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mgamma_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="mgamma_+3A_mgshape">mgshape</code></td>
<td>
<p>mgamma shape (positive) as list or vector</p>
</td></tr>
<tr><td><code id="mgamma_+3A_mgscale">mgscale</code></td>
<td>
<p>mgamma scale (positive) as list or vector</p>
</td></tr>
<tr><td><code id="mgamma_+3A_mgweight">mgweight</code></td>
<td>
<p>mgamma weights (positive) as list or vector (<code>NULL</code> for equi-weighted)</p>
</td></tr>
<tr><td><code id="mgamma_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="mgamma_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="mgamma_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="mgamma_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="mgamma_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Distribution functions for weighted mixture of gammas.
</p>
<p>Suppose there are <code class="reqn">M&gt;=1</code> gamma components in the mixture model. If you 
wish to have a single (scalar) value for each parameter within each of the
<code class="reqn">M</code> components then these can be input as a vector of length <code class="reqn">M</code>. If
you wish to input a vector of values for each parameter within each of the
<code class="reqn">M</code> components, then they are input as a list with each entry the
parameter object for each component (which can either be a scalar or
vector as usual). No matter whether they are input as a vector or list there
must be <code class="reqn">M</code> elements in <code>mgshape</code> and <code>mgscale</code>, one for each
gamma mixture component. Further, any vectors in the list of parameters must
of the same length of the <code>x, q, p</code> or equal to the sample size <code>n</code>, where
relevant.
</p>
<p>If <code>mgweight=NULL</code> then equal weights for each component are assumed. Otherwise, 
<code>mgweight</code> must be a list of the same length as <code>mgshape</code> and 
<code>mgscale</code>, filled with positive values. In the latter case, the weights are rescaled
to sum to unity.
</p>
<p>The gamma is defined on the non-negative reals. Though behaviour at zero depends on
the shape (<code class="reqn">\alpha</code>):
</p>

<ul>
<li> <p><code class="reqn">f(0+)=\infty</code> for <code class="reqn">0&lt;\alpha&lt;1</code>;
</p>
</li>
<li> <p><code class="reqn">f(0+)=1/\beta</code> for <code class="reqn">\alpha=1</code> (exponential);
</p>
</li>
<li> <p><code class="reqn">f(0+)=0</code> for <code class="reqn">\alpha&gt;1</code>;
</p>
</li></ul>

<p>where <code class="reqn">\beta</code> is the scale parameter.
</p>


<h3>Value</h3>

<p><code><a href="#topic+mgamma">dmgamma</a></code> gives the density, 
<code><a href="#topic+mgamma">pmgamma</a></code> gives the cumulative distribution function,
<code><a href="#topic+mgamma">qmgamma</a></code> gives the quantile function and 
<code><a href="#topic+mgamma">rmgamma</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Daniela Laas, University of St Gallen, Switzerland for reporting various bugs in these functions.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>, and
the gamma mixture parameters can be vectorised within the list. The main
inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either a
scalar or a vector. If vectors are provided they must all be of the same
length, and the function will be evaluated for each element of vector. In
the case of <code><a href="#topic+mgamma">rmgamma</a></code> any input vector must be of
length <code>n</code>. The only exception is when the parameters are single scalar
values, input as vector of length <code class="reqn">M</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+mgamma">rmgamma</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Mixture_model">http://en.wikipedia.org/wiki/Mixture_model</a>
</p>
<p>McLachlan, G.J. and Peel, D. (2000). Finite Mixture Models. Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gammagpd">gammagpd</a></code>, <code><a href="#topic+gpd">gpd</a></code>
and <code><a href="stats.html#topic+GammaDist">dgamma</a></code>
</p>
<p>Other mgamma: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>, <code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>, <code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>, <code><a href="#topic+mgammagpd">mgammagpd</a></code>
</p>
<p>Other fmgamma: <code><a href="#topic+fmgamma">fmgamma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

n = 1000
x = rmgamma(n, mgshape = c(1, 6), mgscale = c(1,2), mgweight = c(1, 2))
xx = seq(-1, 40, 0.01)

hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, dmgamma(xx, mgshape = c(1, 6), mgscale = c(1, 2), mgweight = c(1, 2)))

# By direct simulation
n1 = rbinom(1, n, 1/3) # sample size from population 1
x = c(rgamma(n1, shape = 1, scale = 1), rgamma(n - n1, shape = 6, scale = 2))

hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, dmgamma(xx, mgshape = c(1, 6), mgscale = c(1, 2), mgweight = c(1, 2)))

## End(Not run)

</code></pre>

<hr>
<h2 id='mgammagpd'>Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+mgammagpd'></span><span id='topic+dmgammagpd'></span><span id='topic+pmgammagpd'></span><span id='topic+qmgammagpd'></span><span id='topic+rmgammagpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with mixture of gammas for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the multiple gamma shapes <code>mgshape</code>, scales <code>mgscale</code> and <code>mgweights</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmgammagpd(x, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]),
  sigmau = sqrt(mgshape[[1]]) * mgscale[[1]], xi = 0, phiu = TRUE,
  log = FALSE)

pmgammagpd(q, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]),
  sigmau = sqrt(mgshape[[1]]) * mgscale[[1]], xi = 0, phiu = TRUE,
  lower.tail = TRUE)

qmgammagpd(p, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]),
  sigmau = sqrt(mgshape[[1]]) * mgscale[[1]], xi = 0, phiu = TRUE,
  lower.tail = TRUE)

rmgammagpd(n = 1, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]),
  sigmau = sqrt(mgshape[[1]]) * mgscale[[1]], xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mgammagpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_mgshape">mgshape</code></td>
<td>
<p>mgamma shape (positive) as list or vector</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_mgscale">mgscale</code></td>
<td>
<p>mgamma scale (positive) as list or vector</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_mgweight">mgweight</code></td>
<td>
<p>mgamma weights (positive) as list or vector (<code>NULL</code> for equi-weighted)</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="mgammagpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining mixture of gammas for the bulk
below the threshold and GPD for upper tail. 
</p>
<p>The user can pre-specify <code>phiu</code> permitting a parameterised value for the tail
fraction <code class="reqn">\phi_u</code>. Alternatively, when <code>phiu=TRUE</code> the tail fraction is
estimated as the tail fraction from the mixture of gammas bulk model.
</p>
<p>Suppose there are <code class="reqn">M&gt;=1</code> gamma components in the mixture model. If you 
wish to have a single (scalar) value for each parameter within each of the
<code class="reqn">M</code> components then these can be input as a vector of length <code class="reqn">M</code>. If
you wish to input a vector of values for each parameter within each of the
<code class="reqn">M</code> components, then they are input as a list with each entry the
parameter object for each component (which can either be a scalar or
vector as usual). No matter whether they are input as a vector or list there
must be <code class="reqn">M</code> elements in <code>mgshape</code> and <code>mgscale</code>, one for each
gamma mixture component. Further, any vectors in the list of parameters must
of the same length of the <code>x, q, p</code> or equal to the sample size <code>n</code>, where
relevant.
</p>
<p>If <code>mgweight=NULL</code> then equal weights for each component are assumed. Otherwise, 
<code>mgweight</code> must be a list of the same length as <code>mgshape</code> and 
<code>mgscale</code>, filled with positive values. In the latter case, the weights are rescaled
to sum to unity.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the mixture of gammas bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the mixture of gammas and conditional GPD
cumulative distribution functions.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The gamma is defined on the non-negative reals, so the threshold must be positive. 
Though behaviour at zero depends on the shape (<code class="reqn">\alpha</code>):
</p>

<ul>
<li> <p><code class="reqn">f(0+)=\infty</code> for <code class="reqn">0&lt;\alpha&lt;1</code>;
</p>
</li>
<li> <p><code class="reqn">f(0+)=1/\beta</code> for <code class="reqn">\alpha=1</code> (exponential);
</p>
</li>
<li> <p><code class="reqn">f(0+)=0</code> for <code class="reqn">\alpha&gt;1</code>;
</p>
</li></ul>

<p>where <code class="reqn">\beta</code> is the scale parameter.
</p>
<p>See <code><a href="#topic+gammagpd">gammagpd</a></code> for details of simpler parametric mixture model
with single gamma for bulk component and GPD for upper tail.
</p>


<h3>Value</h3>

<p><code><a href="#topic+mgammagpd">dmgammagpd</a></code> gives the density, 
<code><a href="#topic+mgammagpd">pmgammagpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+mgammagpd">qmgammagpd</a></code> gives the quantile function and 
<code><a href="#topic+mgammagpd">rmgammagpd</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Daniela Laas, University of St Gallen, Switzerland for reporting various bugs in these functions.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>, and the gamma mixture
parameters can be vectorised within the list. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
and parameters must be either a scalar or a vector. If vectors are provided they must all be
of the same length, and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+mgammagpd">rmgammagpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+mgammagpd">rmgammagpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Mixture_model">http://en.wikipedia.org/wiki/Mixture_model</a>
</p>
<p>McLachlan, G.J. and Peel, D. (2000). Finite Mixture Models. Wiley.
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>do Nascimento, F.F., Gamerman, D. and Lopes, H.F. (2011). A semiparametric
Bayesian approach to extreme value estimation. Statistical Computing, 22(2), 661-675.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+GammaDist">dgamma</a></code>
</p>
<p>Other gammagpd: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+gammagpd">gammagpd</a></code>
</p>
<p>Other mgamma: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+mgammagpdcon">mgammagpdcon</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fmgammagpd: <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rmgammagpd(1000, mgshape = c(1, 6), mgscale = c(1, 2), mgweight = c(1, 2),
  u = 15, sigmau = 4, xi = 0)
xx = seq(-1, 40, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, dmgammagpd(xx, mgshape = c(1, 6), mgscale = c(1, 2), mgweight = c(1, 2),
  u = 15, sigmau = 4, xi = 0))
abline(v = 15)

## End(Not run)

</code></pre>

<hr>
<h2 id='mgammagpdcon'>Mixture of Gammas Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+mgammagpdcon'></span><span id='topic+dmgammagpdcon'></span><span id='topic+pmgammagpdcon'></span><span id='topic+qmgammagpdcon'></span><span id='topic+rmgammagpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with mixture of gammas for bulk
distribution upto the threshold and conditional GPD for upper tail with continuity at threshold. The parameters
are the multiple gamma shapes <code>mgshape</code>, scales <code>mgscale</code> and <code>mgweights</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmgammagpdcon(x, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]), xi = 0, phiu = TRUE,
  log = FALSE)

pmgammagpdcon(q, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]), xi = 0, phiu = TRUE,
  lower.tail = TRUE)

qmgammagpdcon(p, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]), xi = 0, phiu = TRUE,
  lower.tail = TRUE)

rmgammagpdcon(n = 1, mgshape = 1, mgscale = 1, mgweight = NULL,
  u = qgamma(0.9, mgshape[[1]], 1/mgscale[[1]]), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mgammagpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_mgshape">mgshape</code></td>
<td>
<p>mgamma shape (positive) as list or vector</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_mgscale">mgscale</code></td>
<td>
<p>mgamma scale (positive) as list or vector</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_mgweight">mgweight</code></td>
<td>
<p>mgamma weights (positive) as list or vector (<code>NULL</code> for equi-weighted)</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="mgammagpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining mixture of gammas for the bulk
below the threshold and GPD for upper tail with continuity at threshold. 
</p>
<p>The user can pre-specify <code>phiu</code> permitting a parameterised value for the tail
fraction <code class="reqn">\phi_u</code>. Alternatively, when <code>phiu=TRUE</code> the tail fraction is
estimated as the tail fraction from the mixture of gammas bulk model.
</p>
<p>Suppose there are <code class="reqn">M&gt;=1</code> gamma components in the mixture model. If you 
wish to have a single (scalar) value for each parameter within each of the
<code class="reqn">M</code> components then these can be input as a vector of length <code class="reqn">M</code>. If
you wish to input a vector of values for each parameter within each of the
<code class="reqn">M</code> components, then they are input as a list with each entry the
parameter object for each component (which can either be a scalar or
vector as usual). No matter whether they are input as a vector or list there
must be <code class="reqn">M</code> elements in <code>mgshape</code> and <code>mgscale</code>, one for each
gamma mixture component. Further, any vectors in the list of parameters must
of the same length of the <code>x, q, p</code> or equal to the sample size <code>n</code>, where
relevant.
</p>
<p>If <code>mgweight=NULL</code> then equal weights for each component are assumed. Otherwise, 
<code>mgweight</code> must be a list of the same length as <code>mgshape</code> and 
<code>mgscale</code>, filled with positive values. In the latter case, the weights are rescaled
to sum to unity.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the mixture of gammas bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the mixture of gammas and conditional GPD
cumulative distribution functions.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the mixture of gammas and conditional GPD
density functions respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>.
</p>
<p>The gamma is defined on the non-negative reals, so the threshold must be positive. 
Though behaviour at zero depends on the shape (<code class="reqn">\alpha</code>):
</p>

<ul>
<li> <p><code class="reqn">f(0+)=\infty</code> for <code class="reqn">0&lt;\alpha&lt;1</code>;
</p>
</li>
<li> <p><code class="reqn">f(0+)=1/\beta</code> for <code class="reqn">\alpha=1</code> (exponential);
</p>
</li>
<li> <p><code class="reqn">f(0+)=0</code> for <code class="reqn">\alpha&gt;1</code>;
</p>
</li></ul>

<p>where <code class="reqn">\beta</code> is the scale parameter.
</p>
<p>See <code><a href="#topic+gammagpd">gammagpd</a></code> for details of simpler parametric mixture model
with single gamma for bulk component and GPD for upper tail.
</p>


<h3>Value</h3>

<p><code><a href="#topic+mgammagpdcon">dmgammagpdcon</a></code> gives the density, 
<code><a href="#topic+mgammagpdcon">pmgammagpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+mgammagpdcon">qmgammagpdcon</a></code> gives the quantile function and 
<code><a href="#topic+mgammagpdcon">rmgammagpdcon</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Daniela Laas, University of St Gallen, Switzerland for reporting various bugs in these functions.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>, and the gamma mixture
parameters can be vectorised within the list. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
and parameters must be either a scalar or a vector. If vectors are provided they must all be
of the same length, and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+mgammagpdcon">rmgammagpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+mgammagpdcon">rmgammagpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Gamma_distribution">http://en.wikipedia.org/wiki/Gamma_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Mixture_model">http://en.wikipedia.org/wiki/Mixture_model</a>
</p>
<p>McLachlan, G.J. and Peel, D. (2000). Finite Mixture Models. Wiley.
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>do Nascimento, F.F., Gamerman, D. and Lopes, H.F. (2011). A semiparametric
Bayesian approach to extreme value estimation. Statistical Computing, 22(2), 661-675.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+GammaDist">dgamma</a></code>
</p>
<p>Other gammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fgammagpd">fgammagpd</a></code>, <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+gammagpdcon">gammagpdcon</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>
</p>
<p>Other mgamma: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpd">fmgammagpd</a></code>, <code><a href="#topic+fmgamma">fmgamma</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpd: <code><a href="#topic+fgammagpd">fgammagpd</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpd">gammagpd</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other mgammagpdcon: <code><a href="#topic+fgammagpdcon">fgammagpdcon</a></code>,
<code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>, <code><a href="#topic+fmgammagpd">fmgammagpd</a></code>,
<code><a href="#topic+fmgamma">fmgamma</a></code>, <code><a href="#topic+gammagpdcon">gammagpdcon</a></code>,
<code><a href="#topic+mgammagpd">mgammagpd</a></code>, <code><a href="#topic+mgamma">mgamma</a></code>
</p>
<p>Other fmgammagpdcon: <code><a href="#topic+fmgammagpdcon">fmgammagpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rmgammagpdcon(1000, mgshape = c(1, 6), mgscale = c(1, 2), mgweight = c(1, 2), u = 15, xi = 0)
xx = seq(-1, 40, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 40))
lines(xx, dmgammagpdcon(xx, mgshape = c(1, 6), mgscale = c(1, 2), mgweight = c(1, 2),
 u = 15, xi = 0))
abline(v = 15)

## End(Not run)

</code></pre>

<hr>
<h2 id='mrlplot'>Mean Residual Life Plot</h2><span id='topic+mrlplot'></span>

<h3>Description</h3>

<p>Plots the sample mean residual life (MRL) plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrlplot(data, tlim = NULL, nt = min(100, length(data)),
  p.or.n = FALSE, alpha = 0.05, ylim = NULL,
  legend.loc = "bottomleft", try.thresh = quantile(data, 0.9, na.rm =
  TRUE), main = "Mean Residual Life Plot", xlab = "Threshold u",
  ylab = "Mean Excess", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mrlplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_tlim">tlim</code></td>
<td>
<p>vector of (lower, upper) limits of range of threshold
to plot MRL, or <code>NULL</code> to use default values</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_nt">nt</code></td>
<td>
<p>number of thresholds for which to evaluate MRL</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_p.or.n">p.or.n</code></td>
<td>
<p>logical, should tail fraction (<code>FALSE</code>) or number of
exceedances (<code>TRUE</code>) be given on upper x-axis</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_alpha">alpha</code></td>
<td>
<p>significance level over range (0, 1), or <code>NULL</code> for no CI</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limits or <code>NULL</code></p>
</td></tr>
<tr><td><code id="mrlplot_+3A_legend.loc">legend.loc</code></td>
<td>
<p>location of legend (see <code><a href="graphics.html#topic+legend">legend</a></code>) or <code>NULL</code> for no legend</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_try.thresh">try.thresh</code></td>
<td>
<p>vector of thresholds to consider</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_main">main</code></td>
<td>
<p>title of plot</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="mrlplot_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the plotting functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots the sample mean residual life plot, which is also known as the mean
excess plot. 
</p>
<p>If the generalised Pareto distribution (GPD) is an appropriate model for the excesses <code class="reqn">X-u</code>
above <code class="reqn">u</code> then their expected value is:
</p>
<p style="text-align: center;"><code class="reqn">E(X - u | X &gt; u) = \sigma_u / (1 - \xi).</code>
</p>

<p>For any higher threshold <code class="reqn">v &gt; u</code> the expected value is 
</p>
<p style="text-align: center;"><code class="reqn">E(X - v | X &gt; v) = [\sigma_u + \xi * (v - u)] / (1 - \xi)</code>
</p>

<p>which is linear in higher thresholds <code class="reqn">v</code> with intercept given by <code class="reqn">[\sigma_u - \xi *u]/(1 - \xi)</code>
and gradient <code class="reqn">\xi/(1 - \xi)</code>. The estimated mean residual life above a threshold
<code class="reqn">v</code> is given by the sample mean excess <code>mean(x[x &gt; v]) - v</code>. 
</p>
<p>Symmetric CLT based confidence intervals are provided, provided there are at least 5 exceedances.
The sampling density for the MRL is shown by a greyscale image, where lighter greys indicate low density.
</p>
<p>A pre-chosen threshold (or more than one) can be given in <code>try.thresh</code>. The GPD is
fitted to the excesses using maximum likelihood estimation. The estimated parameters are
used to plot the linear function for all higher thresholds using a solid line. The threshold
should set as low as possible, so a dashed line is shown below the pre-chosen threshold.
If the MRL is similar to the dashed line then a lower threshold may be chosen.
</p>
<p>If no threshold limits are provided <code>tlim = NULL</code> then the lowest threshold is set
to be just below the median data point and the maximum threshold is set to the 6th
largest datapoint.
</p>
<p>The range of permitted thresholds is just below the minimum datapoint and the
second largest value. If there are less unique values of data within the threshold
range than the number of threshold evalations requested, then instead of a sequence
of thresholds the MRL will be evaluated at each unique datapoint.
</p>
<p>The missing (<code>NA</code> and <code>NaN</code>) and non-finite values are ignored.
</p>
<p>The lower x-axis is the threshold and an upper axis either gives the number of 
exceedances (<code>p.or.n = FALSE</code>) or proportion of excess (<code>p.or.n = TRUE</code>).
Note that unlike the <code>gpd</code> related functions the missing values are ignored, so
do not add to the lower tail fraction. But ignoring the missing values is consistent
with all the other mixture model functions.
</p>


<h3>Value</h3>

<p><code><a href="#topic+mrlplot">mrlplot</a></code> gives the mean residual life plot. It also
returns a matrix containing columns of the threshold, number of exceedances, mean excess,
standard devation of excesses and <code class="reqn">100(1 - \alpha)\%</code> confidence interval if requested. The standard
deviation and confidence interval are <code>NA</code> for less than 5 exceedances.
</p>


<h3>Acknowledgments</h3>

<p>Based on the 
<code><a href="evd.html#topic+mrlplot">mrlplot</a></code> function in the 
<code><a href="evd.html#topic+mrlplot">evd</a></code> package for which Stuart Coles' and Alec Stephenson's contributions are gratefully acknowledged.
They are designed to have similar syntax and functionality to simplify the transition for users of these packages.
</p>


<h3>Note</h3>

<p>If the user specifies the threshold range, the thresholds above the second
largest are dropped. A warning message is given if any thresholds have at most 5 
exceedances, in which case the confidence interval is not calculated as it is
unreliable due to small sample. If there are less than 10 exceedances of the minimum
threshold then the function will stop.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Coles S.G. (2004). An Introduction to the Statistical Modelling of Extreme Values.
Springer-Verlag: London.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="evd.html#topic+mrlplot">mrlplot</a></code> from 
<code><a href="evd.html#topic+mrlplot">evd</a></code> library
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(1000)
mrlplot(x)
mrlplot(x, tlim = c(0, 2.2))
mrlplot(x, tlim = c(0, 2), try.thresh = c(0.5, 1, 1.5))
mrlplot(x, tlim = c(0, 3), try.thresh = c(0.5, 1, 1.5))

</code></pre>

<hr>
<h2 id='normgpd'>Normal Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+normgpd'></span><span id='topic+dnormgpd'></span><span id='topic+pnormgpd'></span><span id='topic+qnormgpd'></span><span id='topic+rnormgpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with normal for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the normal mean <code>nmean</code> and standard deviation <code>nsd</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnormgpd(x, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  sigmau = nsd, xi = 0, phiu = TRUE, log = FALSE)

pnormgpd(q, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  sigmau = nsd, xi = 0, phiu = TRUE, lower.tail = TRUE)

qnormgpd(p, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  sigmau = nsd, xi = 0, phiu = TRUE, lower.tail = TRUE)

rnormgpd(n = 1, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  sigmau = nsd, xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normgpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="normgpd_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="normgpd_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="normgpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="normgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="normgpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="normgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="normgpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="normgpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="normgpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="normgpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="normgpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining normal distribution for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
normal bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the normal bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the normal and conditional GPD
cumulative distribution functions (i.e. <code>pnorm(x, nmean, nsd)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Normal">dnorm</a></code> for details of normal bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+normgpd">dnormgpd</a></code> gives the density, 
<code><a href="#topic+normgpd">pnormgpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+normgpd">qnormgpd</a></code> gives the quantile function and 
<code><a href="#topic+normgpd">rnormgpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+normgpd">rnormgpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+normgpd">rnormgpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
The normal mean <code>nmean</code> and GPD threshold <code>u</code> will also require negation.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu Y. and Scarrott, C.J. (2018). evmix: An R Package for Extreme Value Mixture Modeling, 
Threshold Estimation and Boundary Corrected Kernel Density Estimation. Journal of
Statistical Software 84(5), 1-27. doi: 10.18637/jss.v084.i05.
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+itmnormgpd">itmnormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>,
<code><a href="#topic+lognormgpd">lognormgpd</a></code>, <code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+normgpdcon">normgpdcon</a></code>
</p>
<p>Other gng: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fitmgng">fitmgng</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+itmgng">itmgng</a></code>
</p>
<p>Other fnormgpd: <code><a href="#topic+fnormgpd">fnormgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rnormgpd(1000)
xx = seq(-4, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 6))
lines(xx, dnormgpd(xx))

# three tail behaviours
plot(xx, pnormgpd(xx), type = "l")
lines(xx, pnormgpd(xx, xi = 0.3), col = "red")
lines(xx, pnormgpd(xx, xi = -0.3), col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rnormgpd(1000, phiu = 0.2)
xx = seq(-4, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 6))
lines(xx, dnormgpd(xx, phiu = 0.2))

plot(xx, dnormgpd(xx, xi=0, phiu = 0.2), type = "l")
lines(xx, dnormgpd(xx, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dnormgpd(xx, xi=0.2, phiu = 0.2), col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='normgpdcon'>Normal Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+normgpdcon'></span><span id='topic+dnormgpdcon'></span><span id='topic+pnormgpdcon'></span><span id='topic+qnormgpdcon'></span><span id='topic+rnormgpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with normal for bulk
distribution upto the threshold and conditional GPD above threshold with continuity
at threshold. The parameters
are the normal mean <code>nmean</code> and standard deviation <code>nsd</code>, threshold <code>u</code>
and GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnormgpdcon(x, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  xi = 0, phiu = TRUE, log = FALSE)

pnormgpdcon(q, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  xi = 0, phiu = TRUE, lower.tail = TRUE)

qnormgpdcon(p, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  xi = 0, phiu = TRUE, lower.tail = TRUE)

rnormgpdcon(n = 1, nmean = 0, nsd = 1, u = qnorm(0.9, nmean, nsd),
  xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normgpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_nmean">nmean</code></td>
<td>
<p>normal mean</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_nsd">nsd</code></td>
<td>
<p>normal standard deviation (positive)</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="normgpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining normal distribution for the bulk
below the threshold and GPD for upper tail with continuity at threshold.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
normal bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the normal bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the normal and conditional GPD
cumulative distribution functions (i.e. <code>pnorm(x, nmean, nsd)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the normal and conditional GPD
density functions (i.e. <code>dnorm(x, nmean, nsd)</code> and
<code>dgpd(x, u, sigmau, xi)</code>) respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>. 
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Normal">dnorm</a></code> for details of normal bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+normgpdcon">dnormgpdcon</a></code> gives the density, 
<code><a href="#topic+normgpdcon">pnormgpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+normgpdcon">qnormgpdcon</a></code> gives the quantile function and 
<code><a href="#topic+normgpdcon">rnormgpdcon</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+normgpdcon">rnormgpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+normgpdcon">rnormgpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
The normal mean <code>nmean</code> and GPD threshold <code>u</code> will also require negation.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Normal">dnorm</a></code>
</p>
<p>Other normgpd: <code><a href="#topic+fgng">fgng</a></code>, <code><a href="#topic+fhpd">fhpd</a></code>,
<code><a href="#topic+fitmnormgpd">fitmnormgpd</a></code>, <code><a href="#topic+flognormgpd">flognormgpd</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+itmnormgpd">itmnormgpd</a></code>, <code><a href="#topic+lognormgpdcon">lognormgpdcon</a></code>,
<code><a href="#topic+lognormgpd">lognormgpd</a></code>, <code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other normgpdcon: <code><a href="#topic+fgngcon">fgngcon</a></code>,
<code><a href="#topic+fhpdcon">fhpdcon</a></code>, <code><a href="#topic+flognormgpdcon">flognormgpdcon</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+fnormgpd">fnormgpd</a></code>,
<code><a href="#topic+gngcon">gngcon</a></code>, <code><a href="#topic+gng">gng</a></code>,
<code><a href="#topic+hpdcon">hpdcon</a></code>, <code><a href="#topic+hpd">hpd</a></code>,
<code><a href="#topic+normgpd">normgpd</a></code>
</p>
<p>Other gngcon: <code><a href="#topic+fgngcon">fgngcon</a></code>, <code><a href="#topic+fgng">fgng</a></code>,
<code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>, <code><a href="#topic+gngcon">gngcon</a></code>,
<code><a href="#topic+gng">gng</a></code>
</p>
<p>Other fnormgpdcon: <code><a href="#topic+fnormgpdcon">fnormgpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rnormgpdcon(1000)
xx = seq(-4, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 6))
lines(xx, dnormgpdcon(xx))

# three tail behaviours
plot(xx, pnormgpdcon(xx), type = "l")
lines(xx, pnormgpdcon(xx, xi = 0.3), col = "red")
lines(xx, pnormgpdcon(xx, xi = -0.3), col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rnormgpdcon(1000, phiu = 0.2)
xx = seq(-4, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-4, 6))
lines(xx, dnormgpdcon(xx, phiu = 0.2))

plot(xx, dnormgpdcon(xx, xi=0, phiu = 0.2), type = "l")
lines(xx, dnormgpdcon(xx, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dnormgpdcon(xx, xi=0.2, phiu = 0.2), col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='pickandsplot'>Pickands Plot</h2><span id='topic+pickandsplot'></span>

<h3>Description</h3>

<p>Produces the Pickand's plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pickandsplot(data, orderlim = NULL, tlim = NULL, y.alpha = FALSE,
  alpha = 0.05, ylim = NULL, legend.loc = "topright",
  try.thresh = quantile(data, 0.9, na.rm = TRUE),
  main = "Pickand's Plot", xlab = "order", ylab = ifelse(y.alpha,
  " tail index - alpha", "shape  - xi"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pickandsplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_orderlim">orderlim</code></td>
<td>
<p>vector of (lower, upper) limits of order statistics
to plot estimator, or <code>NULL</code> to use default values</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_tlim">tlim</code></td>
<td>
<p>vector of (lower, upper) limits of range of threshold
to plot estimator, or <code>NULL</code> to use default values</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_y.alpha">y.alpha</code></td>
<td>
<p>logical, should shape xi (<code>FALSE</code>) or tail index alpha (<code>TRUE</code>) be given on y-axis</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_alpha">alpha</code></td>
<td>
<p>significance level over range (0, 1), or <code>NULL</code> for no CI</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limits or <code>NULL</code></p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_legend.loc">legend.loc</code></td>
<td>
<p>location of legend (see <code><a href="graphics.html#topic+legend">legend</a></code>) or <code>NULL</code> for no legend</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_try.thresh">try.thresh</code></td>
<td>
<p>vector of thresholds to consider</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_main">main</code></td>
<td>
<p>title of plot</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="pickandsplot_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the plotting functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces the Pickand's plot including confidence intervals.
</p>
<p>For an ordered iid sequence <code class="reqn">X_{(1)}\ge X_{(2)}\ge\cdots\ge X_{(n)}</code> 
the Pickand's estimator of the reciprocal of the shape parameter <code class="reqn">\xi</code> 
at the <code class="reqn">k</code>th order statistic is given by 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\xi}_{k,n}=\frac{1}{\log(2)} \log\left(\frac{X_{(k)}-X_{(2k)}}{X_{(2k)}-X_{(4k)}}\right).</code>
</p>

<p>Unlike the Hill estimator it does not assume positive data, is valid for any <code class="reqn">\xi</code> and
is location and scale invariant.
The Pickands estimator is defined on orders <code class="reqn">k=1, \ldots, \lfloor n/4\rfloor</code>. 
</p>
<p>Once a sufficiently low order statistic is reached the Pickand's estimator will
be constant, upto sample uncertainty, for regularly varying tails. Pickand's
plot is a plot of </p>
<p style="text-align: center;"><code class="reqn">\hat{\xi}_{k,n}</code>
</p>
<p> against the <code class="reqn">k</code>. Symmetric asymptotic
normal confidence intervals assuming Pareto tails are provided.
</p>
<p>The Pickand's estimator is for the GPD shape <code class="reqn">\xi</code>, or the reciprocal of the
tail index <code class="reqn">\alpha=1/\xi</code>. The shape is plotted by default using
<code>y.alpha=FALSE</code> and the tail index is plotted when <code>y.alpha=TRUE</code>.
</p>
<p>A pre-chosen threshold (or more than one) can be given in
<code>try.thresh</code>. The estimated parameter (<code class="reqn">\xi</code> or <code class="reqn">\alpha</code>) at
each threshold are plot by a horizontal solid line for all higher thresholds. 
The threshold should be set as low as possible, so a dashed line is shown
below the pre-chosen threshold. If Pickand's estimator is similar to the
dashed line then a lower threshold may be chosen.
</p>
<p>If no order statistic (or threshold) limits are provided 
<code>orderlim = tlim = NULL</code> then the lowest order statistic is set to <code class="reqn">X_{(1)}</code> and
highest possible value <code class="reqn">X_{\lfloor n/4\rfloor}</code>. However, Pickand's estimator is always
output for all <code class="reqn">k=1, \ldots, \lfloor n/4\rfloor</code>.
</p>
<p>The missing (<code>NA</code> and <code>NaN</code>) and non-finite values are ignored.
</p>
<p>The lower x-axis is the order <code class="reqn">k</code>. The upper axis is for the corresponding threshold.
</p>


<h3>Value</h3>

<p><code><a href="#topic+pickandsplot">pickandsplot</a></code> gives Pickand's plot. It also 
returns a dataframe containing columns of the order statistics, order, Pickand's
estimator, it's standard devation and <code class="reqn">100(1 - \alpha)\%</code> confidence
interval (when requested).
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Younes Mouatasim, Risk Dynamics, Brussels for reporting various bugs in these functions.
</p>


<h3>Note</h3>

<p>Asymptotic Wald type CI's are estimated for non-<code>NULL</code> signficance level <code>alpha</code>
for the shape parameter, assuming exactly GPD tails. When plotting on the tail index scale,
then a simple reciprocal transform of the CI is applied which may well be sub-optimal.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p>Pickands III, J.. (1975). Statistical inference using extreme order statistics. Annal of Statistics 3(1), 119-131.
</p>
<p>Dekkers A. and de Haan, S. (1989). On the estimation of the extreme-value index and large quantile estimation.
Annals of Statistics 17(4), 1795-1832.
</p>
<p>Resnick, S. (2007). Heavy-Tail Phenomena - Probabilistic and Statistical Modeling. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="smoothtail.html#topic+pickands">pickands</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
par(mfrow = c(2, 1))

# Reproduce graphs from Figure 4.7 of Resnick (2007)
data(danish, package="evir")

# Pickand's plot
pickandsplot(danish, orderlim=c(1, 150), ylim=c(-0.1, 2.2),
 try.thresh=c(), alpha=NULL, legend.loc=NULL)
 
# Using default settings
pickandsplot(danish)

## End(Not run)
</code></pre>

<hr>
<h2 id='psden'>P-Splines probability density function</h2><span id='topic+psden'></span><span id='topic+dpsden'></span><span id='topic+ppsden'></span><span id='topic+qpsden'></span><span id='topic+rpsden'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the P-splines density estimate. B-spline coefficients
can be result from Poisson regression with log or identity link.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsden(x, beta = NULL, nbinwidth = NULL, xrange = NULL, nseg = 10,
  degree = 3, design.knots = NULL, log = FALSE)

ppsden(q, beta = NULL, nbinwidth = NULL, xrange = NULL, nseg = 10,
  degree = 3, design.knots = NULL, lower.tail = TRUE)

qpsden(p, beta = NULL, nbinwidth = NULL, xrange = NULL, nseg = 10,
  degree = 3, design.knots = NULL, lower.tail = TRUE)

rpsden(n = 1, beta = NULL, nbinwidth = NULL, xrange = NULL,
  nseg = 10, degree = 3, design.knots = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="psden_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="psden_+3A_beta">beta</code></td>
<td>
<p>vector of B-spline coefficients (required)</p>
</td></tr>
<tr><td><code id="psden_+3A_nbinwidth">nbinwidth</code></td>
<td>
<p>scaling to convert count frequency into proper density</p>
</td></tr>
<tr><td><code id="psden_+3A_xrange">xrange</code></td>
<td>
<p>vector of minimum and maximum of B-spline (support of density)</p>
</td></tr>
<tr><td><code id="psden_+3A_nseg">nseg</code></td>
<td>
<p>number of segments between knots</p>
</td></tr>
<tr><td><code id="psden_+3A_degree">degree</code></td>
<td>
<p>degree of B-splines (0 is constant, 1 is linear, etc.)</p>
</td></tr>
<tr><td><code id="psden_+3A_design.knots">design.knots</code></td>
<td>
<p>spline knots for splineDesign function</p>
</td></tr>
<tr><td><code id="psden_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="psden_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="psden_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="psden_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="psden_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>P-spline density estimate using B-splines with given coefficients. B-splines
knots can be specified using <code>design.knots</code> or regularly spaced knots can be specified
using <code>xrange</code>, <code>nseg</code> and <code>deg</code>. No default knots are provided.
</p>
<p>If regularly spaced knots are specified using <code>xrange</code>, <code>nseg</code> and <code>deg</code>,
then B-splines which are shifted/spliced versions of each other are defined (i.e. not natural B-splines)
which is consistent with definition of Eilers and Marx, the masters of P-splines.
</p>
<p>The <code><a href="splines.html#topic+splineDesign">splineDesign</a></code> function is used to calculate the B-splines, which 
intakes knot locations as <code>design.knots</code>. As such the <code>design.knots</code> are not the knots in
their usual sense (e.g. to cover [0, 100] with 10 segments the usual knots would be <code class="reqn">0, 10, \ldots, 100</code>).
The <code>design.knots</code> must be extended by the <code>degree</code>, so for <code>degree = 2</code> the
<code>design.knots = seq(-20, 120, 10)</code>.
</p>
<p>Further, if the user wants natural B-splines then these can be specified using the
<code>design.knots</code>, with replicated knots at each bounday according to the degree. To continue the 
above example, for <code>degree = 2</code> the <code>design.knots = c(rep(0, 2), seq(0, 100, 10), rep(100, 2))</code>. 
</p>
<p>If both the <code>design.knots</code> and other knot specification are provided, then the former are
used by default. Default values for only the <code>degree</code> and <code>nseg</code> are provided, all the other
P-spline inputs must be provided. Notice that the <code>order</code> and <code>lambda</code> penalty are not needed
as these are encapsulated in the inference for the B-spline coefficients.
</p>
<p>Poisson regression is typically used for estimating the B-spline coefficients, using maximum likelihood
estimation (via iterative re-weighted least squares). A log-link function is usually used and as such the 
<code>beta</code> coefficients are on a log-scale, and the density needs to be exponentiated. However, an
identity link may be (carefully) used and then these coefficients are on the usual scale.
</p>
<p>The <code>beta</code> coefficients are estimated using a particular sample (size) and histogram bin-width, using 
Poisson regression. Thus to
convert the predicted counts into a proper density it needs to be rescaled by dividing by <code class="reqn">n * binwidth</code>.
If <code>nbinwidth=NULL</code> is not provided then a crude approximate scaling is used by normalising the density
to be proper. The renormalisation requires numerical integration, which is
computationally intensive and so best avoided wherever possible.
</p>
<p>Checks of the consistency of the <code>xrange</code>, <code>degree</code> and <code>nseg</code> and <code>design.knots</code> are made,
with the values implied by the <code>design.knots</code> used by default to replace any incorrect values. These
replacements are made for notational efficiency for users.
</p>
<p>An inversion sampler is used for random number generation which also rather
inefficient, as it could be carried out more efficiently using a mixture representation.
</p>
<p>The quantile function is rather complicated as there is no closed form solution,
so is obtained by numerical approximation of the inverse cumulative distribution function
<code class="reqn">P(X \le q) = p</code> to find <code class="reqn">q</code>. The quantile function 
<code><a href="#topic+psden">qpsden</a></code> evaluates the P-splines cumulative distribution
function over the <code>xrange</code>. A sequence of values
of length fifty times the number of knots (with a minimum of 1000) is first
calculated. Spline based interpolation using <code><a href="stats.html#topic+splinefun">splinefun</a></code>,
with default <code>monoH.FC</code> method, is then used to approximate the quantile
function. This is a similar approach to that taken
by Matt Wand in the <code><a href="ks.html#topic+kde">qkde</a></code> in the <code><a href="ks.html#topic+kde">ks</a></code> package.
</p>


<h3>Value</h3>

<p><code><a href="#topic+psden">dpsden</a></code> gives the density, 
<code><a href="#topic+psden">ppsden</a></code> gives the cumulative distribution function,
<code><a href="#topic+psden">qpsden</a></code> gives the quantile function and 
<code><a href="#topic+psden">rpsden</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+psden">psden</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
</p>
<p>Default values are provided for P-spline inputs of <code>degree</code> and <code>nseg</code> only, 
but all others must be provided by the user.
The default sample size for <code><a href="#topic+psden">rpsden</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/B-spline">http://en.wikipedia.org/wiki/B-spline</a>
</p>
<p><a href="http://statweb.lsu.edu/faculty/marx/">http://statweb.lsu.edu/faculty/marx/</a>
</p>
<p>Eilers, P.H.C. and Marx, B.D. (1996). Flexible smoothing with B-splines and penalties.
Statistical Science 11(2), 89-121.
</p>


<h3>See Also</h3>

<p><code><a href="splines.html#topic+splineDesign">splineDesign</a></code>.
</p>
<p>Other psden: <code><a href="#topic+fpsdengpd">fpsdengpd</a></code>, <code><a href="#topic+fpsden">fpsden</a></code>,
<code><a href="#topic+psdengpd">psdengpd</a></code>
</p>
<p>Other psdengpd: <code><a href="#topic+fpsdengpd">fpsdengpd</a></code>,
<code><a href="#topic+psdengpd">psdengpd</a></code>
</p>
<p>Other fpsden: <code><a href="#topic+fpsden">fpsden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-6, 6, 0.01)
y = dnorm(xx)

# Plenty of histogram bins (100)
breaks = seq(-4, 4, length.out=101)

# P-spline fitting with cubic B-splines, 2nd order penalty and 8 internal segments
# CV search for penalty coefficient. 
fit = fpsden(x, lambdaseq = 10^seq(-5, 5, 0.25), breaks = breaks,
             xrange = c(-4, 4), nseg = 10, degree = 3, ord = 2)
psdensity = exp(fit$bsplines %*% fit$mle)

hist(x, freq = FALSE, breaks = seq(-4, 4, length.out=101), xlim = c(-6, 6))
lines(xx, y, col = "black") # true density

# P-splines density from dpsden function
with(fit, lines(xx, dpsden(xx, beta, nbinwidth, design = design.knots), lwd = 2, col = "blue"))

legend("topright", c("True Density","P-spline density"), col=c("black", "blue"), lty = 1)

# plot B-splines
par(mfrow = c(2, 1))
with(fit, matplot(mids, as.matrix(bsplines), type = "l", lty = 1))

# Natural B-splines
knots = with(fit, seq(xrange[1], xrange[2], length.out = nseg + 1))
natural.knots = with(fit, c(rep(xrange[1], degree), knots, rep(xrange[2], degree)))
naturalb = splineDesign(natural.knots, fit$mids, ord = fit$degree + 1, outer.ok = TRUE)
with(fit, matplot(mids, naturalb, type = "l", lty = 1))

# Compare knot specifications
rbind(fit$design.knots, natural.knots)

# User can use natural B-splines if design.knots are specified manually
natural.fit = fpsden(x, lambdaseq = 10^seq(-5, 5, 0.25), breaks = breaks,
             design.knots = natural.knots, nseg = 10, degree = 3, ord = 2)
psdensity = with(natural.fit, exp(bsplines %*% mle))

par(mfrow = c(1, 1))
hist(x, freq = FALSE, breaks = seq(-4, 4, length.out=101), xlim = c(-6, 6))
lines(xx, y, col = "black") # true density

# check density against dpsden function
with(fit, lines(xx, dpsden(xx, beta, nbinwidth, design = design.knots), lwd = 2, col = "blue"))
with(natural.fit, lines(xx, dpsden(xx, beta, nbinwidth, design = design.knots),
                        lwd = 2, col = "red", lty = 2))

legend("topright", c("True Density", "Eilers and Marx B-splines", "Natural B-splines"),
   col=c("black", "blue", "red"), lty = c(1, 1, 2))

## End(Not run)

</code></pre>

<hr>
<h2 id='psdengpd'>P-Splines Density Estimate and GPD Tail Extreme Value Mixture Model</h2><span id='topic+psdengpd'></span><span id='topic+dpsdengpd'></span><span id='topic+ppsdengpd'></span><span id='topic+qpsdengpd'></span><span id='topic+rpsdengpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with P-splines density estimate for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the B-spline coefficients <code>beta</code> (and associated features), threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsdengpd(x, beta = NULL, nbinwidth = NULL, xrange = NULL,
  nseg = 10, degree = 3, u = NULL, sigmau = NULL, xi = 0,
  phiu = TRUE, design.knots = NULL, log = FALSE)

ppsdengpd(q, beta = NULL, nbinwidth = NULL, xrange = NULL,
  nseg = 10, degree = 3, u = NULL, sigmau = NULL, xi = 0,
  phiu = TRUE, design.knots = NULL, lower.tail = TRUE)

qpsdengpd(p, beta = NULL, nbinwidth = NULL, xrange = NULL,
  nseg = 10, degree = 3, u = NULL, sigmau = NULL, xi = 0,
  phiu = TRUE, design.knots = NULL, lower.tail = TRUE)

rpsdengpd(n = 1, beta = NULL, nbinwidth = NULL, xrange = NULL,
  nseg = 10, degree = 3, u = NULL, sigmau = NULL, xi = 0,
  phiu = TRUE, design.knots = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="psdengpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_beta">beta</code></td>
<td>
<p>vector of B-spline coefficients (required)</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_nbinwidth">nbinwidth</code></td>
<td>
<p>scaling to convert count frequency into proper density</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_xrange">xrange</code></td>
<td>
<p>vector of minimum and maximum of B-spline (support of density)</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_nseg">nseg</code></td>
<td>
<p>number of segments between knots</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_degree">degree</code></td>
<td>
<p>degree of B-splines (0 is constant, 1 is linear, etc.)</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="psdengpd_+3A_design.knots">design.knots</code></td>
<td>
<p>spline knots for splineDesign function</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="psdengpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining P-splines density estimate for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
KDE bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the P-splines density estimate (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the P-splines density estimate and conditional GPD
cumulative distribution functions respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component. 
The specification of the underlying B-splines and the P-splines density estimator
are discussed in the <code><a href="#topic+psden">psden</a></code> function help.
</p>


<h3>Value</h3>

<p><code><a href="#topic+psdengpd">dpsdengpd</a></code> gives the density, 
<code><a href="#topic+psdengpd">ppsdengpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+psdengpd">qpsdengpd</a></code> gives the quantile function and 
<code><a href="#topic+psdengpd">rpsdengpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>Unlike most of the other extreme value mixture model functions the 
<code><a href="#topic+psdengpd">psdengpd</a></code> functions have not been vectorised as
this is not appropriate. The main inputs (<code>x</code>, <code>p</code> or <code>q</code>)
must be either a scalar or a vector, which also define the output length.
The B-splines coefficients <code>beta</code> and knots <code>design.knots</code> are vectors.
</p>
<p>Default values are provided for P-spline inputs of <code>degree</code> and <code>nseg</code> only, 
but all others must be provided by the user. The default sample size for
<code><a href="#topic+psdengpd">rpsdengpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are permitted for the parameters/B-spline criteria.
</p>
<p>Due to symmetry, the lower tail can be described by GPD by negating the quantiles. 
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Alfadino Akbar and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>.
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/B-spline">http://en.wikipedia.org/wiki/B-spline</a>
</p>
<p><a href="http://statweb.lsu.edu/faculty/marx/">http://statweb.lsu.edu/faculty/marx/</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Eilers, P.H.C. and Marx, B.D. (1996). Flexible smoothing with B-splines and penalties.
Statistical Science 11(2), 89-121.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psden">psden</a></code> and <code><a href="#topic+fpsden">fpsden</a></code>.
</p>
<p>Other psden: <code><a href="#topic+fpsdengpd">fpsdengpd</a></code>, <code><a href="#topic+fpsden">fpsden</a></code>,
<code><a href="#topic+psden">psden</a></code>
</p>
<p>Other psdengpd: <code><a href="#topic+fpsdengpd">fpsdengpd</a></code>,
<code><a href="#topic+psden">psden</a></code>
</p>
<p>Other fpsdengpd: <code><a href="#topic+fpsdengpd">fpsdengpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(1, 1))

x = rnorm(1000)
xx = seq(-6, 6, 0.01)
y = dnorm(xx)

# Plenty of histogram bins (100)
breaks = seq(-4, 4, length.out=101)

# P-spline fitting with cubic B-splines, 2nd order penalty and 8 internal segments
# CV search for penalty coefficient. 
fit = fpsdengpd(x, lambdaseq = 10^seq(-5, 5, 0.25), breaks = breaks,
             xrange = c(-4, 4), nseg = 10, degree = 3, ord = 2)
hist(x, freq = FALSE, breaks = seq(-4, 4, length.out=101), xlim = c(-6, 6))

# P-splines only
with(fit, lines(xx, dpsden(xx, beta, nbinwidth, design = design.knots), lwd = 2, col = "blue"))

# P-splines+GPD
with(fit, lines(xx, dpsdengpd(xx, beta, nbinwidth, design = design.knots, 
   u = u, sigmau = sigmau, xi = xi, phiu = phiu), lwd = 2, col = "red"))
abline(v = fit$u, col = "red")

legend("topleft", c("True Density","P-spline density", "P-spline+GPD"),
 col=c("black", "blue", "red"), lty = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='tcplot'>Parameter Threshold Stability Plots</h2><span id='topic+tcplot'></span><span id='topic+tshapeplot'></span><span id='topic+tscaleplot'></span>

<h3>Description</h3>

<p>Plots the MLE of the GPD parameters against threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tcplot(data, tlim = NULL, nt = min(100, length(data)),
  p.or.n = FALSE, alpha = 0.05, ylim.xi = NULL, ylim.sigmau = NULL,
  legend.loc = "bottomright", try.thresh = quantile(data, 0.9, na.rm =
  TRUE), ...)

tshapeplot(data, tlim = NULL, nt = min(100, length(data)),
  p.or.n = FALSE, alpha = 0.05, ylim = NULL,
  legend.loc = "bottomright", try.thresh = quantile(data, 0.9, na.rm =
  TRUE), main = "Shape Threshold Stability Plot", xlab = "Threshold u",
  ylab = "Shape Parameter", ...)

tscaleplot(data, tlim = NULL, nt = min(100, length(data)),
  p.or.n = FALSE, alpha = 0.05, ylim = NULL,
  legend.loc = "bottomright", try.thresh = quantile(data, 0.9, na.rm =
  TRUE), main = "Modified Scale Threshold Stability Plot",
  xlab = "Threshold u", ylab = "Modified Scale Parameter", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tcplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="tcplot_+3A_tlim">tlim</code></td>
<td>
<p>vector of (lower, upper) limits of range of threshold
to plot MRL, or <code>NULL</code> to use default values</p>
</td></tr>
<tr><td><code id="tcplot_+3A_nt">nt</code></td>
<td>
<p>number of thresholds for which to evaluate MRL</p>
</td></tr>
<tr><td><code id="tcplot_+3A_p.or.n">p.or.n</code></td>
<td>
<p>logical, should tail fraction (<code>FALSE</code>) or number of
exceedances (<code>TRUE</code>) be given on upper x-axis</p>
</td></tr>
<tr><td><code id="tcplot_+3A_alpha">alpha</code></td>
<td>
<p>significance level over range (0, 1), or <code>NULL</code> for no CI</p>
</td></tr>
<tr><td><code id="tcplot_+3A_ylim.xi">ylim.xi</code></td>
<td>
<p>y-axis limits for shape parameter or <code>NULL</code></p>
</td></tr>
<tr><td><code id="tcplot_+3A_ylim.sigmau">ylim.sigmau</code></td>
<td>
<p>y-axis limits for scale parameter or <code>NULL</code></p>
</td></tr>
<tr><td><code id="tcplot_+3A_legend.loc">legend.loc</code></td>
<td>
<p>location of legend (see <code><a href="graphics.html#topic+legend">legend</a></code>) or <code>NULL</code> for no legend</p>
</td></tr>
<tr><td><code id="tcplot_+3A_try.thresh">try.thresh</code></td>
<td>
<p>vector of thresholds to consider</p>
</td></tr>
<tr><td><code id="tcplot_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the plotting functions</p>
</td></tr>
<tr><td><code id="tcplot_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limits or <code>NULL</code></p>
</td></tr>
<tr><td><code id="tcplot_+3A_main">main</code></td>
<td>
<p>title of plot</p>
</td></tr>
<tr><td><code id="tcplot_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="tcplot_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MLE of the (modified) GPD scale and shape (xi) parameters are
plotted against a set of possible thresholds. If the GPD is a suitable
model for a threshold <code class="reqn">u</code> then for all higher thresholds <code class="reqn">v &gt; u</code> it
will also be suitable, with the shape and modified scale being
constant. Known as the threshold stability plots (Coles, 2001). The modified
scale parameter is <code class="reqn">\sigma_u - u\xi</code>.
</p>
<p>In practice there is sample uncertainty in the parameter estimates, which
must be taken into account when choosing a threshold.
</p>
<p>The usual asymptotic Wald confidence intervals are shown based on the
observed information matrix to measure this uncertainty. The sampling density
of the Wald normal approximation is shown by a greyscale image, where lighter
greys indicate low density.
</p>
<p>A pre-chosen threshold (or more than one) can be given in <code>try.thresh</code>.
The GPD is fitted to the excesses using maximum likelihood estimation. The
estimated parameters are shown as a horizontal line which is solid above this
threshold, for which they should be the same if the GPD is a good model (upto sample uncertainty).
The threshold should always be chosen to be as low as possible to reduce sample uncertainty.
Therefore, below the pre-chosen threshold, where the GPD should not be a good model, the line
is dashed and the parameter estimates should now deviate from the dashed line
(otherwise a lower threshold could be used).
If no threshold limits are provided <code>tlim = NULL</code> then the lowest threshold is set
to be just below the median data point and the maximum threshold is set to the 11th
largest datapoint. This is a slightly lower order statistic compared to that used in the MRL plot 
<code><a href="#topic+mrlplot">mrlplot</a></code> function to account for the fact the maximum likelihood
estimation is likely to be unreliable with 10 or fewer datapoints.
</p>
<p>The range of permitted thresholds is just below the minimum datapoint and the
second largest value. If there are less unique values of data within the threshold
range than the number of threshold evalations requested, then instead of a sequence
of thresholds they will be set to each unique datapoint, i.e. MLE will only be applied
where there is data.
</p>
<p>The missing (<code>NA</code> and <code>NaN</code>) and non-finite values are ignored.
</p>
<p>The lower x-axis is the threshold and an upper axis either gives the number of 
exceedances (<code>p.or.n = FALSE</code>) or proportion of excess (<code>p.or.n = TRUE</code>).
Note that unlike the <code>gpd</code> related functions the missing values are ignored, so
do not add to the lower tail fraction. But ignoring the missing values is consistent
with all the other mixture model functions.
</p>


<h3>Value</h3>

<p><code><a href="#topic+tcplot">tshapeplot</a></code> and 
<code><a href="#topic+tcplot">tscaleplot</a></code> produces the threshold stability plot for the
shape and scale parameter respectively. They also returns a matrix containing columns of
the threshold, number of exceedances, MLE shape/scale
and their standard devation and <code class="reqn">100(1 - \alpha)\%</code> Wald confidence interval if requested. Where the
observed information matrix is not obtainable the standard deviation and confidence intervals
are <code>NA</code>. For the <code><a href="#topic+tcplot">tscaleplot</a></code> the modified scale quantities
are also provided. <code><a href="#topic+tcplot">tcplot</a></code> produces both plots on one graph and
outputs a merged dataframe of results.
</p>


<h3>Acknowledgments</h3>

<p>Based on the threshold stability plot function <code><a href="evd.html#topic+tcplot">tcplot</a></code> in the 
<code><a href="evd.html#topic+fpot">evd</a></code> package for which Stuart Coles' and Alec Stephenson's 
contributions are gratefully acknowledged.
They are designed to have similar syntax and functionality to simplify the transition for users of these packages.
</p>


<h3>Note</h3>

<p>If the user specifies the threshold range, the thresholds above the sixth
largest are dropped. A warning message is given if any thresholds have at most 10
exceedances, in which case the maximum likelihood estimation is unreliable. If there
are less than 10 exceedances of the minimum threshold then the function will stop.
</p>
<p>By default, no legend is included when using <code><a href="#topic+tcplot">tcplot</a></code> to get
both threshold stability plots.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Coles S.G. (2004). An Introduction to the Statistical Modelling of Extreme Values.
Springer-Verlag: London.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mrlplot">mrlplot</a></code> and <code><a href="evd.html#topic+tcplot">tcplot</a></code> from 
<code><a href="evd.html#topic+mrlplot">evd</a></code> library
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x = rnorm(1000)
tcplot(x)
tshapeplot(x, tlim = c(0, 2))
tscaleplot(x, tlim = c(0, 2), try.thresh = c(0.5, 1, 1.5))
tcplot(x, tlim = c(0, 2), try.thresh = c(0.5, 1, 1.5))

## End(Not run)
</code></pre>

<hr>
<h2 id='weibullgpd'>Weibull Bulk and GPD Tail Extreme Value Mixture Model</h2><span id='topic+weibullgpd'></span><span id='topic+dweibullgpd'></span><span id='topic+pweibullgpd'></span><span id='topic+qweibullgpd'></span><span id='topic+rweibullgpd'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with Weibull for bulk
distribution upto the threshold and conditional GPD above threshold. The parameters
are the weibull shape <code>wshape</code> and scale <code>wscale</code>, threshold <code>u</code>
GPD scale <code>sigmau</code> and shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dweibullgpd(x, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale *
  gamma(1 + 1/wshape))^2), xi = 0, phiu = TRUE, log = FALSE)

pweibullgpd(q, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale *
  gamma(1 + 1/wshape))^2), xi = 0, phiu = TRUE, lower.tail = TRUE)

qweibullgpd(p, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale *
  gamma(1 + 1/wshape))^2), xi = 0, phiu = TRUE, lower.tail = TRUE)

rweibullgpd(n = 1, wshape = 1, wscale = 1, u = qweibull(0.9,
  wshape, wscale), sigmau = sqrt(wscale^2 * gamma(1 + 2/wshape) - (wscale
  * gamma(1 + 1/wshape))^2), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weibullgpd_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_wshape">wshape</code></td>
<td>
<p>Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_wscale">wscale</code></td>
<td>
<p>Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_sigmau">sigmau</code></td>
<td>
<p>scale parameter (positive)</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="weibullgpd_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining Weibull distribution for the bulk
below the threshold and GPD for upper tail.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
weibull bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the Weibull bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the Weibull and conditional GPD
cumulative distribution functions (i.e. <code>pweibull(x, wshape, wscale)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The Weibull is defined on the non-negative reals, so the threshold must be positive.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Weibull">dweibull</a></code> for details of weibull bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+weibullgpd">dweibullgpd</a></code> gives the density, 
<code><a href="#topic+weibullgpd">pweibullgpd</a></code> gives the cumulative distribution function,
<code><a href="#topic+weibullgpd">qweibullgpd</a></code> gives the quantile function and 
<code><a href="#topic+weibullgpd">rweibullgpd</a></code> gives a random sample.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+weibullgpd">rweibullgpd</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+weibullgpd">rweibullgpd</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Weibull">dweibull</a></code>
</p>
<p>Other weibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>, <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>
</p>
<p>Other weibullgpdcon: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>,
<code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>
</p>
<p>Other itmweibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>, <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpdcon">weibullgpdcon</a></code>
</p>
<p>Other fweibullgpd: <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rweibullgpd(1000)
xx = seq(-1, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 6))
lines(xx, dweibullgpd(xx))

# three tail behaviours
plot(xx, pweibullgpd(xx), type = "l")
lines(xx, pweibullgpd(xx, xi = 0.3), col = "red")
lines(xx, pweibullgpd(xx, xi = -0.3), col = "blue")
legend("topleft", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rweibullgpd(1000, phiu = 0.2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 6))
lines(xx, dweibullgpd(xx, phiu = 0.2))

plot(xx, dweibullgpd(xx, xi=0, phiu = 0.2), type = "l")
lines(xx, dweibullgpd(xx, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dweibullgpd(xx, xi=0.2, phiu = 0.2), col = "blue")
legend("topleft", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='weibullgpdcon'>Weibull Bulk and GPD Tail Extreme Value Mixture Model with Single Continuity Constraint</h2><span id='topic+weibullgpdcon'></span><span id='topic+dweibullgpdcon'></span><span id='topic+pweibullgpdcon'></span><span id='topic+qweibullgpdcon'></span><span id='topic+rweibullgpdcon'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random number generation for the extreme value mixture model with Weibull for bulk
distribution upto the threshold and conditional GPD above threshold with continuity at threshold. The parameters
are the weibull shape <code>wshape</code> and scale <code>wscale</code>, threshold <code>u</code>
GPD shape <code>xi</code> and tail fraction <code>phiu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dweibullgpdcon(x, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), xi = 0, phiu = TRUE, log = FALSE)

pweibullgpdcon(q, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), xi = 0, phiu = TRUE, lower.tail = TRUE)

qweibullgpdcon(p, wshape = 1, wscale = 1, u = qweibull(0.9, wshape,
  wscale), xi = 0, phiu = TRUE, lower.tail = TRUE)

rweibullgpdcon(n = 1, wshape = 1, wscale = 1, u = qweibull(0.9,
  wshape, wscale), xi = 0, phiu = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weibullgpdcon_+3A_x">x</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_wshape">wshape</code></td>
<td>
<p>Weibull shape (positive)</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_wscale">wscale</code></td>
<td>
<p>Weibull scale (positive)</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_phiu">phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">[0, 1]</code> or <code>TRUE</code></p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_log">log</code></td>
<td>
<p>logical, if TRUE then log density</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_q">q</code></td>
<td>
<p>quantiles</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical, if FALSE then upper tail probabilities</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_p">p</code></td>
<td>
<p>cumulative probabilities</p>
</td></tr>
<tr><td><code id="weibullgpdcon_+3A_n">n</code></td>
<td>
<p>sample size (positive integer)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme value mixture model combining Weibull distribution for the bulk
below the threshold and GPD for upper tail with continuity at threshold.
</p>
<p>The user can pre-specify <code>phiu</code> 
permitting a parameterised value for the tail fraction <code class="reqn">\phi_u</code>. Alternatively, when
<code>phiu=TRUE</code> the tail fraction is estimated as the tail fraction from the
weibull bulk model.
</p>
<p>The cumulative distribution function with tail fraction <code class="reqn">\phi_u</code> defined by the
upper tail fraction of the Weibull bulk model (<code>phiu=TRUE</code>), upto the 
threshold <code class="reqn">0 &lt; x \le u</code>, given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(x)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = H(u) + [1 - H(u)] G(x)</code>
</p>

<p>where <code class="reqn">H(x)</code> and <code class="reqn">G(X)</code> are the Weibull and conditional GPD
cumulative distribution functions (i.e. <code>pweibull(x, wshape, wscale)</code> and
<code>pgpd(x, u, sigmau, xi)</code>) respectively.
</p>
<p>The cumulative distribution function for pre-specified <code class="reqn">\phi_u</code>, upto the
threshold <code class="reqn">0 &lt; x \le u</code>, is given by:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = (1 - \phi_u) H(x)/H(u)</code>
</p>

<p>and above the threshold <code class="reqn">x &gt; u</code>:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \phi_u + [1 - \phi_u] G(x)</code>
</p>

<p>Notice that these definitions are equivalent when <code class="reqn">\phi_u = 1 - H(u)</code>.
</p>
<p>The continuity constraint means that <code class="reqn">(1 - \phi_u) h(u)/H(u) = \phi_u g(u)</code>
where <code class="reqn">h(x)</code> and <code class="reqn">g(x)</code> are the Weibull and conditional GPD
density functions (i.e. <code>dweibull(x, wshape, wscale)</code> and
<code>dgpd(x, u, sigmau, xi)</code>) respectively. The resulting GPD scale parameter is then:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = \phi_u H(u) / [1 - \phi_u] h(u)</code>
</p>
<p>.
In the special case of where the tail fraction is defined by the bulk model this reduces to
</p>
<p style="text-align: center;"><code class="reqn">\sigma_u = [1 - H(u)] / h(u)</code>
</p>
<p>.
</p>
<p>The Weibull is defined on the non-negative reals, so the threshold must be positive.
</p>
<p>See <code><a href="#topic+gpd">gpd</a></code> for details of GPD upper tail component and 
<code><a href="stats.html#topic+Weibull">dweibull</a></code> for details of weibull bulk component.
</p>


<h3>Value</h3>

<p><code><a href="#topic+weibullgpdcon">dweibullgpdcon</a></code> gives the density, 
<code><a href="#topic+weibullgpdcon">pweibullgpdcon</a></code> gives the cumulative distribution function,
<code><a href="#topic+weibullgpdcon">qweibullgpdcon</a></code> gives the quantile function and 
<code><a href="#topic+weibullgpdcon">rweibullgpdcon</a></code> gives a random sample.
</p>


<h3>Acknowledgments</h3>

<p>Thanks to Ben Youngman, Exeter University, UK for reporting a bug in the <code><a href="#topic+weibullgpdcon">rweibullgpdcon</a></code> function.
</p>


<h3>Note</h3>

<p>All inputs are vectorised except <code>log</code> and <code>lower.tail</code>.
The main inputs (<code>x</code>, <code>p</code> or <code>q</code>) and parameters must be either
a scalar or a vector. If vectors are provided they must all be of the same length,
and the function will be evaluated for each element of vector. In the case of 
<code><a href="#topic+weibullgpdcon">rweibullgpdcon</a></code> any input vector must be of length <code>n</code>.
</p>
<p>Default values are provided for all inputs, except for the fundamentals 
<code>x</code>, <code>q</code> and <code>p</code>. The default sample size for 
<code><a href="#topic+weibullgpdcon">rweibullgpdcon</a></code> is 1.
</p>
<p>Missing (<code>NA</code>) and Not-a-Number (<code>NaN</code>) values in <code>x</code>,
<code>p</code> and <code>q</code> are passed through as is and infinite values are set to
<code>NA</code>. None of these are not permitted for the parameters.
</p>
<p>Error checking of the inputs (e.g. invalid probabilities) is carried out and
will either stop or give warning message as appropriate.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://en.wikipedia.org/wiki/Weibull_distribution">http://en.wikipedia.org/wiki/Weibull_distribution</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Behrens, C.N., Lopes, H.F. and Gamerman, D. (2004). Bayesian analysis of extreme
events with threshold estimation. Statistical Modelling. 4(3), 227-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code> and <code><a href="stats.html#topic+Weibull">dweibull</a></code>
</p>
<p>Other weibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>, <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other weibullgpdcon: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>,
<code><a href="#topic+fweibullgpd">fweibullgpd</a></code>, <code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>,
<code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other itmweibullgpd: <code><a href="#topic+fitmweibullgpd">fitmweibullgpd</a></code>,
<code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>, <code><a href="#topic+fweibullgpd">fweibullgpd</a></code>,
<code><a href="#topic+itmweibullgpd">itmweibullgpd</a></code>, <code><a href="#topic+weibullgpd">weibullgpd</a></code>
</p>
<p>Other fweibullgpdcon: <code><a href="#topic+fweibullgpdcon">fweibullgpdcon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
par(mfrow = c(2, 2))

x = rweibullgpdcon(1000)
xx = seq(-0.1, 6, 0.01)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 6))
lines(xx, dweibullgpdcon(xx))

# three tail behaviours
plot(xx, pweibullgpdcon(xx), type = "l")
lines(xx, pweibullgpdcon(xx, xi = 0.3), col = "red")
lines(xx, pweibullgpdcon(xx, xi = -0.3), col = "blue")
legend("bottomright", paste("xi =",c(0, 0.3, -0.3)),
  col=c("black", "red", "blue"), lty = 1)

x = rweibullgpdcon(1000, phiu = 0.2)
hist(x, breaks = 100, freq = FALSE, xlim = c(-1, 6))
lines(xx, dweibullgpdcon(xx, phiu = 0.2))

plot(xx, dweibullgpdcon(xx, xi=0, phiu = 0.2), type = "l")
lines(xx, dweibullgpdcon(xx, xi=-0.2, phiu = 0.2), col = "red")
lines(xx, dweibullgpdcon(xx, xi=0.2, phiu = 0.2), col = "blue")
legend("topright", c("xi = 0", "xi = 0.2", "xi = -0.2"),
  col=c("black", "red", "blue"), lty = 1)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
