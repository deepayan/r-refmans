<!DOCTYPE html><html lang="en"><head><title>Help for package cloudfs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cloudfs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cloudfs-package'><p>cloudfs: Streamlined Interface to Interact with Cloud Storage Platforms</p></a></li>
<li><a href='#check_args'><p>Capture Arguments</p></a></li>
<li><a href='#check_bool'><p>Check if Argument is Single TRUE or FALSE</p></a></li>
<li><a href='#check_class'><p>Check Argument's Class</p></a></li>
<li><a href='#check_length'><p>Check if Argument is of Proper Length</p></a></li>
<li><a href='#check_null_cond'><p>Return check_null Value</p></a></li>
<li><a href='#check_path'><p>Validate a path</p></a></li>
<li><a href='#check_scalar'><p>Check if Function Argument is Scalar</p></a></li>
<li><a href='#cli_yeah'><p>User Interface: Ask a Yes/No question</p></a></li>
<li><a href='#cloud_drive_attach'><p>Attach Google Drive folder to project</p></a></li>
<li><a href='#cloud_drive_browse'><p>Browse project's Google Drive folder</p></a></li>
<li><a href='#cloud_drive_download'><p>Download a file from Google Drive to the local project folder</p></a></li>
<li><a href='#cloud_drive_download_bulk'><p>Bulk download contents from Google Drive</p></a></li>
<li><a href='#cloud_drive_find_path'><p>Find Google Drive folder based on a path</p></a></li>
<li><a href='#cloud_drive_ls'><p>List Contents of Project's Google Drive Folder</p></a></li>
<li><a href='#cloud_drive_prep_bulk'><p>Prepare Google Drive content dataframe to be used by bulk</p>
download/read functions</a></li>
<li><a href='#cloud_drive_read'><p>Read a file from Google Drive</p></a></li>
<li><a href='#cloud_drive_read_bulk'><p>Bulk Read Contents from Google Drive</p></a></li>
<li><a href='#cloud_drive_spreadsheet_autofit'><p>Automatically resize all columns in a google spreadsheet</p></a></li>
<li><a href='#cloud_drive_upload'><p>Upload a local file to Google Drive</p></a></li>
<li><a href='#cloud_drive_upload_bulk'><p>Bulk Upload Files to Google Drive</p></a></li>
<li><a href='#cloud_drive_write'><p>Write an object to Google Drive</p></a></li>
<li><a href='#cloud_drive_write_bulk'><p>Write multiple objects to Google Drive in bulk</p></a></li>
<li><a href='#cloud_get_roots'><p>Get cloud roots of a project</p></a></li>
<li><a href='#cloud_guess_read_fun'><p>Guess reading function based on file extensions</p></a></li>
<li><a href='#cloud_guess_write_fun'><p>Guess writing function based on file extensions</p></a></li>
<li><a href='#cloud_local_ls'><p>List Contents of local project folder</p></a></li>
<li><a href='#cloud_object_ls'><p>Prepare a dataframe for bulk writing of objects to cloud</p></a></li>
<li><a href='#cloud_object_prep_bulk'><p>Prepare object content dataframe to be used by bulk download/read</p>
functions</a></li>
<li><a href='#cloud_prep_ls'><p>Prepare ls output</p></a></li>
<li><a href='#cloud_read_excel'><p>Read excel file as a list of dataframes</p></a></li>
<li><a href='#cloud_s3_attach'><p>Attach S3 folder to project</p></a></li>
<li><a href='#cloud_s3_browse'><p>Browse project's S3 folder</p></a></li>
<li><a href='#cloud_s3_download'><p>Download a file from S3 to the local project folder</p></a></li>
<li><a href='#cloud_s3_download_bulk'><p>Bulk Download Contents from S3</p></a></li>
<li><a href='#cloud_s3_ls'><p>List Contents of Project's S3 Folder</p></a></li>
<li><a href='#cloud_s3_prep_bulk'><p>Prepare S3 content dataframe to be used by bulk download/read</p>
functions</a></li>
<li><a href='#cloud_s3_read'><p>Read a file from S3</p></a></li>
<li><a href='#cloud_s3_read_bulk'><p>Bulk Read Contents from S3</p></a></li>
<li><a href='#cloud_s3_upload'><p>Upload a local file to S3</p></a></li>
<li><a href='#cloud_s3_upload_bulk'><p>Bulk Upload Files to S3</p></a></li>
<li><a href='#cloud_s3_write'><p>Write an object to S3</p></a></li>
<li><a href='#cloud_s3_write_bulk'><p>Write multiple objects to S3 in bulk</p></a></li>
<li><a href='#doc_file'><p>Package-wide description of <code>file</code> parameter</p></a></li>
<li><a href='#doc_local'><p>Package-wide description of <code>local</code> parameter</p></a></li>
<li><a href='#proj_desc_get'><p>Extract values from DESCRIPTION file</p></a></li>
<li><a href='#validate_desc'><p>Validate project's DESCRIPTION file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Streamlined Interface to Interact with Cloud Storage Platforms</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Description:</td>
<td>A unified interface for simplifying cloud storage interactions, 
    including uploading, downloading, reading, and writing files, with functions
    for both 'Google Drive' (<a href="https://www.google.com/drive/">https://www.google.com/drive/</a>) and 'Amazon S3' 
    (<a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>aws.s3, googledrive, desc, dplyr, cli, utils, rlang, glue,
httr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>googlesheets4, haven, jsonlite, knitr, readr, readxl,
rmarkdown, testthat (&ge; 3.0.0), withr, writexl, xml2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://g6t.github.io/cloudfs/">https://g6t.github.io/cloudfs/</a>, <a href="https://github.com/g6t/cloudfs">https://github.com/g6t/cloudfs</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/g6t/cloudfs/issues">https://github.com/g6t/cloudfs/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-07 16:24:23 UTC; iaroslav@gradientmetrics.com</td>
</tr>
<tr>
<td>Author:</td>
<td>Iaroslav Domin [aut, cre],
  Stefan Musch [aut],
  Michal Czyz [aut],
  Emmanuel Ugochukwu [aut],
  Gradient Metrics [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Iaroslav Domin &lt;iaroslav@gradientmetrics.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-07 16:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='cloudfs-package'>cloudfs: Streamlined Interface to Interact with Cloud Storage Platforms</h2><span id='topic+cloudfs'></span><span id='topic+cloudfs-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>A unified interface for simplifying cloud storage interactions, including uploading, downloading, reading, and writing files, with functions for both 'Google Drive' (<a href="https://www.google.com/drive/">https://www.google.com/drive/</a>) and 'Amazon S3' (<a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Iaroslav Domin <a href="mailto:iaroslav@gradientmetrics.com">iaroslav@gradientmetrics.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Stefan Musch <a href="mailto:stefan@gradientmetrics.com">stefan@gradientmetrics.com</a>
</p>
</li>
<li><p> Michal Czyz <a href="mailto:michal@gradientmetrics.com">michal@gradientmetrics.com</a>
</p>
</li>
<li><p> Emmanuel Ugochukwu <a href="mailto:emmanuel@gradientmetrics.com">emmanuel@gradientmetrics.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Gradient Metrics [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://g6t.github.io/cloudfs/">https://g6t.github.io/cloudfs/</a>
</p>
</li>
<li> <p><a href="https://github.com/g6t/cloudfs">https://github.com/g6t/cloudfs</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/g6t/cloudfs/issues">https://github.com/g6t/cloudfs/issues</a>
</p>
</li></ul>


<hr>
<h2 id='check_args'>Capture Arguments</h2><span id='topic+check_args'></span>

<h3>Description</h3>

<p>Helper to catch arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_args(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_args_+3A_...">...</code></td>
<td>
<p>unquoted arguments names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of quosures.
</p>

<hr>
<h2 id='check_bool'>Check if Argument is Single TRUE or FALSE</h2><span id='topic+check_bool'></span>

<h3>Description</h3>

<p>Check if an argument is single TRUE or FALSE. As an option it is
possible to allow <code>NULL</code> value when <code>alt_null = TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_bool(x, alt_null = FALSE, add_msg = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_bool_+3A_x">x</code></td>
<td>
<p>Function argument that is being asserted.</p>
</td></tr>
<tr><td><code id="check_bool_+3A_alt_null">alt_null</code></td>
<td>
<p>Logical. Should argument accept <code>NULL</code> value.</p>
</td></tr>
<tr><td><code id="check_bool_+3A_add_msg">add_msg</code></td>
<td>
<p>Is an additional message that can be printed over the standard
function error message. You can:
</p>

<ul>
<li><p> pass the names of the arguments that failed the test by using
<code>{x_name}</code> in the message body (e.g. &quot;What are the {x_name}&quot;);
</p>
</li>
<li><p> pass the class of the arguments that failed the test by using
<code>{wrong_class}</code> in the message body (e.g. &quot;{wrong_class} is wrong&quot;)
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>If argument is single <code>TRUE</code> or <code>FALSE</code> (optionally <code>NULL</code>) it
returns invisible <code>NULL</code>. Otherwise the function throws an error.
</p>

<hr>
<h2 id='check_class'>Check Argument's Class</h2><span id='topic+check_class'></span>

<h3>Description</h3>

<p>Check if argument is of proper class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_class(x, arg_class, alt_null = FALSE, add_msg = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_class_+3A_x">x</code></td>
<td>
<p>Function argument that is being asserted.</p>
</td></tr>
<tr><td><code id="check_class_+3A_arg_class">arg_class</code></td>
<td>
<p>Class name. Usually &quot;character&quot;, &quot;numeric&quot;, &quot;data.frame&quot;,
etc.</p>
</td></tr>
<tr><td><code id="check_class_+3A_alt_null">alt_null</code></td>
<td>
<p>Logical. Should argument accept NULL value.</p>
</td></tr>
<tr><td><code id="check_class_+3A_add_msg">add_msg</code></td>
<td>
<p>Is an additional message that can be printed over the standard
function error message. You can:
</p>

<ul>
<li><p> pass the names of the arguments that failed the test by using
<code>{x_names}</code> in the message body (e.g. &quot;What are the {x_names}&quot;);
</p>
</li>
<li><p> pass the tested class by using <code>{arg_class}</code> in the message body (e.g.
&quot;I want them to be {arg_class})&quot;
</p>
</li>
<li><p> pass the classes of the arguments that failed the test by using
<code>{wrong_class}</code> in the message body (e.g. &quot;{wrong_class} is wrong&quot;)
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>If argument <code>class</code> is same as <code>arg_class</code> it returns invisible
<code>NULL</code>. Otherwise the function throws an error.
</p>

<hr>
<h2 id='check_length'>Check if Argument is of Proper Length</h2><span id='topic+check_length'></span>

<h3>Description</h3>

<p>TODO.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_length(x, arg_length = 1L, alt_null = FALSE, add_msg = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_length_+3A_x">x</code></td>
<td>
<p>Function arguments that are being asserted.</p>
</td></tr>
<tr><td><code id="check_length_+3A_arg_length">arg_length</code></td>
<td>
<p>Integer. Length of argument, for scalars it should take
value <code>1</code> (default).</p>
</td></tr>
<tr><td><code id="check_length_+3A_alt_null">alt_null</code></td>
<td>
<p>Logical. Should argument accept NULL value.</p>
</td></tr>
<tr><td><code id="check_length_+3A_add_msg">add_msg</code></td>
<td>
<p>Is an additional message that can be printed over the standard
function error message. You can:
</p>

<ul>
<li><p> pass the names of the arguments that failed the test by using
<code>{x_name}</code> in the message body (e.g. &quot;What are the {wrong_names}&quot;);
</p>
</li>
<li><p> pass the tested length by using <code>{arg_length}</code> in the message body (e.g.
&quot;I want them to be {arg_length})&quot;
</p>
</li>
<li><p> pass the lengths of the arguments that failed the test by using
<code>{wrong_length}</code> in the message body (e.g. &quot;{wrong_lengths} are wrong&quot;)
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns invisible <code>NULL</code> when argument is of asserted length,
otherwise it will throw an error.
</p>

<hr>
<h2 id='check_null_cond'>Return check_null Value</h2><span id='topic+check_null_cond'></span>

<h3>Description</h3>

<p>Check if <code>alt_null</code> argument is TRUE or FALSE. If it is <code>FALSE</code>
it will return <code>FALSE</code>. If the argument is <code>TRUE</code> it will check if the
x argument is <code>NULL</code> and return logical value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_null_cond(x, alt_null)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_null_cond_+3A_x">x</code></td>
<td>
<p>Argument to check if is NULL.</p>
</td></tr>
<tr><td><code id="check_null_cond_+3A_alt_null">alt_null</code></td>
<td>
<p>Logical. If <code>TRUE</code> it will check if <code>x</code> is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>TRUE</code> or <code>FALSE</code>.
</p>

<hr>
<h2 id='check_path'>Validate a path</h2><span id='topic+check_path'></span>

<h3>Description</h3>

<p>Makes sure that a path passed to a cloud function is in the
right format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_path(path, error = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_path_+3A_path">path</code></td>
<td>
<p>A path relative to the project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="check_path_+3A_error">error</code></td>
<td>
<p>if <code>TRUE</code> (default), throws an error if <code>file</code> is not a valid
file path.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>TRUE</code> or <code>FALSE</code> if <code>error</code> is <code>FALSE</code>. Either <code>TRUE</code> or
an error if <code>error</code> is <code>TRUE</code>.
</p>

<hr>
<h2 id='check_scalar'>Check if Function Argument is Scalar</h2><span id='topic+check_scalar'></span>

<h3>Description</h3>

<p>A function to check that argument is of proper class and of
length 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_scalar(..., arg_class, alt_null = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_scalar_+3A_...">...</code></td>
<td>
<p>Function argument that is being asserted.</p>
</td></tr>
<tr><td><code id="check_scalar_+3A_arg_class">arg_class</code></td>
<td>
<p>Class name. Usually &quot;character&quot;, &quot;numeric&quot;,
&quot;data.frame&quot;, etc.</p>
</td></tr>
<tr><td><code id="check_scalar_+3A_alt_null">alt_null</code></td>
<td>
<p>Logical. Should argument accept NULL value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisible <code>NULL</code> if assertion is <code>TRUE</code>, otherwise an error message.
</p>

<hr>
<h2 id='cli_yeah'>User Interface: Ask a Yes/No question</h2><span id='topic+cli_yeah'></span>

<h3>Description</h3>

<p>This function is inspired by (if not mostly copied from)
<code>usethis::ui_yeah</code> function. It's purpose is to ask user a yes/no question.
The differences are:
</p>

<ol>
<li><p> It is more limited in answer options customization. This is done on
purpose to standardize command line dialogues in our code.
</p>
</li>
<li><p> It uses <code>cli</code> package under the hood, so <code>cli</code> rich text formatting is
possible.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>cli_yeah(x, straight = FALSE, .envir = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cli_yeah_+3A_x">x</code></td>
<td>
<p>Question to display.</p>
</td></tr>
<tr><td><code id="cli_yeah_+3A_straight">straight</code></td>
<td>
<p>(logical) Ask a straight Yes/No question? By default (when
<code>FALSE</code>), two different &quot;no&quot; options and one &quot;yes&quot; option are sampled from
a pool of variants. In other words it behaves just like <code>usethis::ui_yeah</code>
with default parameter setup. When <code>straight = TRUE</code>, it only shows &quot;Yes&quot;
and &quot;No&quot;, literally.</p>
</td></tr>
<tr><td><code id="cli_yeah_+3A_.envir">.envir</code></td>
<td>
<p>Environment to evaluate the glue expressions in.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(logical) Returns <code>TRUE</code> when the user selects a &quot;yes&quot; option and
<code>FALSE</code> otherwise, i.e. when user selects a &quot;no&quot; option or refuses to make
a selection (cancels).
</p>

<hr>
<h2 id='cloud_drive_attach'>Attach Google Drive folder to project</h2><span id='topic+cloud_drive_attach'></span>

<h3>Description</h3>

<p>This function facilitates the association of a specific Google
Drive folder with a project by adding a unique identifier to the project's
DESCRIPTION file. The user is prompted to navigate to the Google Drive
website, select or create the desired folder for the project, and then
provide its URL. The function extracts the necessary information from the
URL and updates the <code>cloudfs.drive</code> field in the DESCRIPTION file
accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_attach(project = ".")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_attach_+3A_project">project</code></td>
<td>
<p>Character. Path to a project. By default it is current working
directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return a meaningful value. Its primary purpose
is the side effect of updating the project's DESCRIPTION file with the
associated Google Drive folder identifier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cloud_drive_attach()

</code></pre>

<hr>
<h2 id='cloud_drive_browse'>Browse project's Google Drive folder</h2><span id='topic+cloud_drive_browse'></span>

<h3>Description</h3>

<p>Opens project's Google Drive folder in browser.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_browse(path = "", root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_browse_+3A_path">path</code></td>
<td>
<p>(optional) Path inside the Google Drive folder to open. Defaults
to the root level (path = &quot;&quot;) of the project's folder.</p>
</td></tr>
<tr><td><code id="cloud_drive_browse_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Google Drive file structure is different from the usual file
structure like e.g. on Linux or Windows. A folder on Google Drive can have
two or more child folders with the same name. Google Drive marks files and
folders with so-called id values to distinguish between them. These values
are always unique. You can see them in browser URL for example. The concept
of &quot;name&quot; is in the first place for convenience of the end user.
</p>
<p>In such a setup a relative file path may correspond to multiple files or
folders. This function however works under assumption that the relative
path you pass to it defines strictly one object. If there's any ambiguity
it throws an error.
</p>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code>. The primary purpose of this function is its
side effect: opening the specified Google Drive folder in a browser.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cloud_drive_browse()
cloud_drive_browse("models/kmeans")

</code></pre>

<hr>
<h2 id='cloud_drive_download'>Download a file from Google Drive to the local project folder</h2><span id='topic+cloud_drive_download'></span>

<h3>Description</h3>

<p>Retrieves a file from the project's Google Drive folder and
saves it to the local project folder, maintaining the original folder
structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_download(file, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_download_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_drive_download_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Google Drive file structure is different from the usual file
structure like e.g. on Linux or Windows. A folder on Google Drive can have
two or more child folders with the same name. Google Drive marks files and
folders with so-called id values to distinguish between them. These values
are always unique. You can see them in browser URL for example. The concept
of &quot;name&quot; is in the first place for convenience of the end user.
</p>
<p>In such a setup a relative file path may correspond to multiple files or
folders. This function however works under assumption that the relative
path you pass to it defines strictly one object. If there's any ambiguity
it throws an error.
</p>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code> after successfully downloading the file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# downloads toy_data/demo.csv from project's Google Drive folder 
# (provided it exists) and saves it to local 'toy_data' folder
cloud_drive_download("toy_data/demo.csv")

# clean up
unlink("toy_data", recursive = TRUE)

</code></pre>

<hr>
<h2 id='cloud_drive_download_bulk'>Bulk download contents from Google Drive</h2><span id='topic+cloud_drive_download_bulk'></span>

<h3>Description</h3>

<p>Downloads multiple files from a Google Drive folder based on
the output dataframe from <a href="#topic+cloud_drive_ls">cloud_drive_ls</a>. This function streamlines
the process of downloading multiple files by allowing you to filter and
select specific files from the Google Drive listing and then download
them in bulk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_download_bulk(content, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_download_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_drive_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_drive_download_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the input <code>content</code> dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# provided there's a folder called "toy_data" in the root of your project's
# Google Drive folder, and this folder contains "csv" files
cloud_drive_ls("toy_data") |&gt; 
  filter(type == "csv") |&gt; 
  cloud_drive_download_bulk()
  
# clean up
unlink("toy_data", recursive = TRUE)
  

</code></pre>

<hr>
<h2 id='cloud_drive_find_path'>Find Google Drive folder based on a path</h2><span id='topic+cloud_drive_find_path'></span>

<h3>Description</h3>

<p>Given a Google Drive id pointing to a folder and a relative path
inside this folder, returns id of the object (file or folder) corresponding
to this path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_find_path(root, path = "", create = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_find_path_+3A_root">root</code></td>
<td>
<p>ID of the folder to start search at.</p>
</td></tr>
<tr><td><code id="cloud_drive_find_path_+3A_path">path</code></td>
<td>
<p>Relative location with respect to the root folder.</p>
</td></tr>
<tr><td><code id="cloud_drive_find_path_+3A_create">create</code></td>
<td>
<p>Create folders describing path if they do not exist? Default is
<code>FALSE</code> so by default the function throws an error if path was not found.
If <code>TRUE</code>, the function will create all missing subdirectories. Note that
the object on the deepest level will always be created as a folder. E.g.
if <code>path = "models/kmeans/model.Rds"</code> and <code>"model.Rds"</code> is missing, this
function will create a folder with such name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Google Drive file structure is different from the usual file
structure like e.g. on Linux or Windows. A folder on Google Drive can have
two or more child folders with the same name. Google Drive marks files and
folders with so-called id values to distinguish between them. These values
are always unique. You can see them in browser URL for example. The concept
of &quot;name&quot; is in the first place for convenience of the end user.
</p>
<p>In such a setup a relative file path may correspond to multiple files or
folders. This function however works under assumption that the relative
path you pass to it defines strictly one object. If there's any ambiguity
it throws an error.
</p>


<h3>Value</h3>

<p>A <a href="googledrive.html#topic+dribble">googledrive::dribble</a> object corresponding to the folder.
</p>

<hr>
<h2 id='cloud_drive_ls'>List Contents of Project's Google Drive Folder</h2><span id='topic+cloud_drive_ls'></span>

<h3>Description</h3>

<p>Returns a tibble with names, timestamps, and sizes of files and
folders inside the specified Google Drive folder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_ls(path = "", recursive = FALSE, full_names = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_ls_+3A_path">path</code></td>
<td>
<p>(optional) Path inside the Google Drive root folder. Specifies
the subfolder whose contents should be listed. By default, when <code>path = ""</code>, lists root-level files and folders.</p>
</td></tr>
<tr><td><code id="cloud_drive_ls_+3A_recursive">recursive</code></td>
<td>
<p>(logical) If <code>TRUE</code>, lists contents recursively in all
nested subfolders. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_ls_+3A_full_names">full_names</code></td>
<td>
<p>(logical) If <code>TRUE</code>, folder path is appended to object
names to give a relative file path.</p>
</td></tr>
<tr><td><code id="cloud_drive_ls_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Google Drive file structure is different from the usual file
structure like e.g. on Linux or Windows. A folder on Google Drive can have
two or more child folders with the same name. Google Drive marks files and
folders with so-called id values to distinguish between them. These values
are always unique. You can see them in browser URL for example. The concept
of &quot;name&quot; is in the first place for convenience of the end user.
</p>
<p>In such a setup a relative file path may correspond to multiple files or
folders. This function however works under assumption that the relative
path you pass to it defines strictly one object. If there's any ambiguity
it throws an error.
</p>


<h3>Value</h3>

<p>A tibble containing the names, last modification timestamps, sizes in
bytes, and Google Drive IDs of files and folders inside the specified
Google Drive folder.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# list only root-level files and folders
cloud_drive_ls() 

# list all files in all nested folders
cloud_drive_ls(recursive = TRUE)

# list contents of "plots/barplots" subfolder
cloud_drive_ls("plots/barplots")

</code></pre>

<hr>
<h2 id='cloud_drive_prep_bulk'>Prepare Google Drive content dataframe to be used by bulk
download/read functions</h2><span id='topic+cloud_drive_prep_bulk'></span>

<h3>Description</h3>

<p><code>cloud_drive_ls</code> returns a dataframe of contents of a Google
Drive folder. This dataframe has <code>name</code>, <code>type</code> and <code>id</code> columns. <code>name</code>
may be either full names or short names (depending on <code>full_names</code>
parameter of <code>cloud_drive_ls</code>), but <code>names(name)</code> will always contain full
names. This function:
</p>

<ol>
<li><p> filters out folders
</p>
</li>
<li><p> extracts <code>names(name)</code> into <code>path</code> column.
</p>
</li>
<li><p> informs about the size of files that are to be downloaded/read and asks
for confirmation
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_prep_bulk(
  content,
  what = c("read", "download"),
  safe_size = 5e+07,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_prep_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_drive_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_drive_prep_bulk_+3A_what">what</code></td>
<td>
<p>What will be done with content, either &quot;read&quot; or &quot;download&quot;.
This affects only how messages will look.</p>
</td></tr>
<tr><td><code id="cloud_drive_prep_bulk_+3A_safe_size">safe_size</code></td>
<td>
<p>What is considered to be safe size in bytes to download in
bulk. To show additional caution message in case if you accidentally run
bulk reading on a folder with gigabytes of data.</p>
</td></tr>
<tr><td><code id="cloud_drive_prep_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transformed <code>content</code> dataframe.
</p>

<hr>
<h2 id='cloud_drive_read'>Read a file from Google Drive</h2><span id='topic+cloud_drive_read'></span>

<h3>Description</h3>

<p>Retrieves and reads a file from the project's Google Drive
folder. By default, the function attempts to determine the appropriate
reading function based on the file's extension. However, you can specify a
custom reading function if necessary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_read(file, fun = NULL, ..., root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_read_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_drive_read_+3A_fun">fun</code></td>
<td>
<p>A custom reading function. If <code>NULL</code> (default), the appropriate
reading function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_drive_read_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the reading function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_read_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The content of the file read from Google Drive, with additional
attributes containing metadata about the file.
</p>


<h3>Default reading functions</h3>

<p>Here's how we identify a reading function based on file extension
</p>

<ul>
<li> <p><code>.csv</code>: <a href="readr.html#topic+read_delim">readr::read_csv</a>
</p>
</li>
<li> <p><code>.json</code>: <a href="jsonlite.html#topic+read_json">jsonlite::read_json</a>
</p>
</li>
<li> <p><code>.rds</code>: <a href="base.html#topic+readRDS">base::readRDS</a>
</p>
</li>
<li> <p><code>.sav</code>: <a href="haven.html#topic+read_spss">haven::read_sav</a>
</p>
</li>
<li> <p><code>.xls</code>: <a href="#topic+cloud_read_excel">cloud_read_excel</a>
</p>
</li>
<li> <p><code>.xlsx</code>: <a href="#topic+cloud_read_excel">cloud_read_excel</a>
</p>
</li>
<li> <p><code>.xml</code>: <a href="xml2.html#topic+read_xml">xml2::read_xml</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# provided there are folders called "data" and "models" in the root of your
# project's main Google Drive folder and they contain the files mentioned
# below
cloud_drive_read("data/mtcars.csv")
cloud_drive_read("models/random_forest.rds")
cloud_drive_read("data/dm.sas7bdat", fun = haven::read_sas)

</code></pre>

<hr>
<h2 id='cloud_drive_read_bulk'>Bulk Read Contents from Google Drive</h2><span id='topic+cloud_drive_read_bulk'></span>

<h3>Description</h3>

<p>This function facilitates the bulk reading of multiple files
from the project's designated Google Drive folder. By using
<a href="#topic+cloud_drive_ls">cloud_drive_ls</a>, you can obtain a dataframe detailing the contents of the
Google Drive folder. Applying <code>cloud_drive_read_bulk</code> to this dataframe
allows you to read all listed files into a named list. The function will,
by default, infer the appropriate reading method based on each file's
extension. However, if a specific reading function is provided via the
<code>fun</code> parameter, it will be applied uniformly to all files, which may not
be suitable for diverse file types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_read_bulk(content, fun = NULL, ..., quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_read_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_drive_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_drive_read_bulk_+3A_fun">fun</code></td>
<td>
<p>A custom reading function. If <code>NULL</code> (default), the appropriate
reading function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_drive_read_bulk_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the reading function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_read_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list where each element corresponds to the content of a file
from Google Drive. The names of the list elements are derived from the file
names.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# provided there's a folder called "data" in the root of the project's main
# Google Drive folder, and it contains csv files
data_lst &lt;- 
  cloud_drive_ls("data") |&gt; 
  filter(type == "csv") |&gt; 
  cloud_drive_read_bulk()
  

</code></pre>

<hr>
<h2 id='cloud_drive_spreadsheet_autofit'>Automatically resize all columns in a google spreadsheet</h2><span id='topic+cloud_drive_spreadsheet_autofit'></span>

<h3>Description</h3>

<p>Finds the spreadsheet by path relative to a project root.
Applies <code><a href="googlesheets4.html#topic+range_autofit">googlesheets4::range_autofit()</a></code> to each sheet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_spreadsheet_autofit(file, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_spreadsheet_autofit_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_drive_spreadsheet_autofit_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The file ID of the resized Google spreadsheet as an invisible result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cloud_drive_write(mtcars, "results/mtcars.xlsx")
cloud_drive_spreadsheet_autofit("results/mtcars.xlsx")

</code></pre>

<hr>
<h2 id='cloud_drive_upload'>Upload a local file to Google Drive</h2><span id='topic+cloud_drive_upload'></span>

<h3>Description</h3>

<p>Uploads a local file from the project's directory to its
corresponding location within the project's Google Drive root folder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_upload(file, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_upload_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_drive_upload_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Google Drive file structure is different from the usual file
structure like e.g. on Linux or Windows. A folder on Google Drive can have
two or more child folders with the same name. Google Drive marks files and
folders with so-called id values to distinguish between them. These values
are always unique. You can see them in browser URL for example. The concept
of &quot;name&quot; is in the first place for convenience of the end user.
</p>
<p>In such a setup a relative file path may correspond to multiple files or
folders. This function however works under assumption that the relative
path you pass to it defines strictly one object. If there's any ambiguity
it throws an error.
</p>


<h3>Value</h3>

<p>Invisibly returns a <a href="googledrive.html#topic+dribble">googledrive::dribble</a> object representing the
uploaded file on Google Drive.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create a toy csv file
dir.create("toy_data")
write.csv(mtcars, "toy_data/mtcars.csv")

# uploads toy_data/mtcars.csv to 'data' subfolder of project's 
# Google Drive folder
cloud_drive_upload("toy_data/mtcars.csv")

# clean up
unlink("toy_data", recursive = TRUE)

</code></pre>

<hr>
<h2 id='cloud_drive_upload_bulk'>Bulk Upload Files to Google Drive</h2><span id='topic+cloud_drive_upload_bulk'></span>

<h3>Description</h3>

<p>This function streamlines the process of uploading multiple
files from the local project folder to the project's designated Google
Drive folder. By using <a href="#topic+cloud_local_ls">cloud_local_ls</a>, you can obtain a dataframe
detailing the contents of the local folder. Applying
<code>cloud_drive_upload_bulk</code> to this dataframe allows you to upload all listed
files to Google Drive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_upload_bulk(content, quiet = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_upload_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_s3_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_drive_upload_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_upload_bulk_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the input <code>content</code> dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create toy plots: 2 png's and 1 jpeg
dir.create("toy_plots")
png("toy_plots/plot1.png"); plot(rnorm(100)); dev.off()
png("toy_plots/plot2.png"); plot(hist(rnorm(100))); dev.off()
png("toy_plots/plot3.jpeg"); plot(hclust(dist(USArrests), "ave")); dev.off()

# upload only the two png's
cloud_local_ls("toy_plots")  |&gt; 
  dplyr::filter(type == "png")  |&gt; 
  cloud_drive_upload_bulk()

# clean up
unlink("toy_plots", recursive = TRUE)
  

</code></pre>

<hr>
<h2 id='cloud_drive_write'>Write an object to Google Drive</h2><span id='topic+cloud_drive_write'></span>

<h3>Description</h3>

<p>Saves an R object to a designated location in the project's
Google Drive folder. If no custom writing function is provided, the
function will infer the appropriate writing method based on the file's
extension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_write(x, file, fun = NULL, ..., local = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_write_+3A_x">x</code></td>
<td>
<p>An R object to be written to Google Drive.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_+3A_fun">fun</code></td>
<td>
<p>A custom writing function. If <code>NULL</code> (default), the appropriate
writing function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the writing function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_+3A_local">local</code></td>
<td>
<p>Logical, defaulting to <code>FALSE</code>. If <code>TRUE</code>, the function will
also create a local copy of the file at the specified path. Note that some
writing functions might not overwrite existing files unless explicitly
allowed. Typically, such functions have a parameter (often named
<code>overwrite</code>) to control this behavior. Check the documentation of the
writing function used to determine the exact parameter name and pass it
through the <code>...</code> argument if necessary. Alternatively, you can define an
anonymous function for <code>fun</code> that calls a writing function with the
overwriting option enabled.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a <a href="googledrive.html#topic+dribble">googledrive::dribble</a> object representing the
written file on Google Drive.
</p>


<h3>Default writing functions</h3>

<p>Here's how we identify a writing function based on file extension
</p>

<ul>
<li> <p><code>.csv</code>: <a href="readr.html#topic+write_delim">readr::write_csv</a>
</p>
</li>
<li> <p><code>.json</code>: <a href="jsonlite.html#topic+read_json">jsonlite::write_json</a>
</p>
</li>
<li> <p><code>.rds</code>: <a href="base.html#topic+readRDS">base::saveRDS</a>
</p>
</li>
<li> <p><code>.xls</code>: <a href="writexl.html#topic+write_xlsx">writexl::write_xlsx</a>
</p>
</li>
<li> <p><code>.xlsx</code>: <a href="writexl.html#topic+write_xlsx">writexl::write_xlsx</a>
</p>
</li>
<li> <p><code>.sav</code>: <a href="haven.html#topic+read_spss">haven::write_sav</a>
</p>
</li>
<li> <p><code>.xml</code>: <a href="xml2.html#topic+write_xml">xml2::write_xml</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# write mtcars dataframe to mtcars.csv in data folder
cloud_drive_write(mtcars, "data/mtcars.csv")
cloud_drive_write(random_forest, "models/random_forest.rds")

# provide custom writing function with parameters 
cloud_drive_write(c("one", "two"), "text/count.txt", writeLines, sep = "\n\n")

</code></pre>

<hr>
<h2 id='cloud_drive_write_bulk'>Write multiple objects to Google Drive in bulk</h2><span id='topic+cloud_drive_write_bulk'></span>

<h3>Description</h3>

<p>This function allows for the bulk writing of multiple R objects
to the project's designated Google Drive folder. To prepare a list of
objects for writing, use <a href="#topic+cloud_object_ls">cloud_object_ls</a>, which generates a dataframe
listing the objects and their intended destinations in a format akin to the
output of <a href="#topic+cloud_drive_ls">cloud_drive_ls</a>. By default, the function determines the
appropriate writing method based on each file's extension. However, if a
specific writing function is provided via the <code>fun</code> parameter, it will be
applied to all files, which may not be ideal if dealing with a variety of
file types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_drive_write_bulk(
  content,
  fun = NULL,
  ...,
  local = FALSE,
  quiet = FALSE,
  root = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_drive_write_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) output of <code>cloud_object_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_drive_write_bulk_+3A_fun">fun</code></td>
<td>
<p>A custom writing function. If <code>NULL</code> (default), the appropriate
writing function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_bulk_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the writing function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_bulk_+3A_local">local</code></td>
<td>
<p>Logical, defaulting to <code>FALSE</code>. If <code>TRUE</code>, the function will
also create a local copy of the file at the specified path. Note that some
writing functions might not overwrite existing files unless explicitly
allowed. Typically, such functions have a parameter (often named
<code>overwrite</code>) to control this behavior. Check the documentation of the
writing function used to determine the exact parameter name and pass it
through the <code>...</code> argument if necessary. Alternatively, you can define an
anonymous function for <code>fun</code> that calls a writing function with the
overwriting option enabled.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_bulk_+3A_quiet">quiet</code></td>
<td>
<p>all caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cloud_drive_write_bulk_+3A_root">root</code></td>
<td>
<p>Google Drive ID or URL of the project root. This serves as the
reference point for all relative paths. When left as <code>NULL</code>, the root is
automatically derived from the <code>cloudfs.drive</code> field of the project's
DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the input <code>content</code> dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# write two csv files: data/df_mtcars.csv and data/df_iris.csv
cloud_object_ls(
  dplyr::lst(mtcars = mtcars, iris = iris),
  path = "data",
  extension = "csv",
  prefix = "df_"
) |&gt; 
cloud_drive_write_bulk()
  

</code></pre>

<hr>
<h2 id='cloud_get_roots'>Get cloud roots of a project</h2><span id='topic+cloud_get_roots'></span>

<h3>Description</h3>

<p>Returns a list with all <code style="white-space: pre;">&#8288;cloudfs.*&#8288;</code> roots defined in a project's
DESCRIPTION.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_get_roots(project = ".")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_get_roots_+3A_project">project</code></td>
<td>
<p>Character. Path to a project. By default it is current working
directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list where each element corresponds to a <code style="white-space: pre;">&#8288;cloudfs.*&#8288;</code> root
defined in the project's DESCRIPTION file. The names of the list elements
are derived from the <code style="white-space: pre;">&#8288;cloudfs.*&#8288;</code> fields by removing the <code>cloudfs.</code> prefix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a temp. folder, and put DESCRIPTION file with cloudfs.* fields into it
tmp_project &lt;- file.path(tempdir(), "cloudfs")
if (!dir.exists(tmp_project)) dir.create(tmp_project)
tmp_project_desc &lt;- file.path(tmp_project, "DESCRIPTION")
desc_content &lt;- c(
  "Package: -",
  "cloudfs.s3: my_bucket/my_project",
  "cloudfs.drive: aaaaaa"
)
writeLines(desc_content, tmp_project_desc)

roots &lt;- cloud_get_roots(tmp_project)
roots

</code></pre>

<hr>
<h2 id='cloud_guess_read_fun'>Guess reading function based on file extensions</h2><span id='topic+cloud_guess_read_fun'></span>

<h3>Description</h3>

<p>Take a look at the switch call. That's basically it. Returns an
appropriate function or throws an error if wasn't able to find one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_guess_read_fun(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_guess_read_fun_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A reading function.
</p>


<h3>Default reading functions</h3>

<p>Here's how we identify a reading function based on file extension
</p>

<ul>
<li> <p><code>.csv</code>: <a href="readr.html#topic+read_delim">readr::read_csv</a>
</p>
</li>
<li> <p><code>.json</code>: <a href="jsonlite.html#topic+read_json">jsonlite::read_json</a>
</p>
</li>
<li> <p><code>.rds</code>: <a href="base.html#topic+readRDS">base::readRDS</a>
</p>
</li>
<li> <p><code>.sav</code>: <a href="haven.html#topic+read_spss">haven::read_sav</a>
</p>
</li>
<li> <p><code>.xls</code>: <a href="#topic+cloud_read_excel">cloud_read_excel</a>
</p>
</li>
<li> <p><code>.xlsx</code>: <a href="#topic+cloud_read_excel">cloud_read_excel</a>
</p>
</li>
<li> <p><code>.xml</code>: <a href="xml2.html#topic+read_xml">xml2::read_xml</a>
</p>
</li></ul>


<hr>
<h2 id='cloud_guess_write_fun'>Guess writing function based on file extensions</h2><span id='topic+cloud_guess_write_fun'></span>

<h3>Description</h3>

<p>Take a look at the switch call. That's basically it. Returns an
appropriate function or throws an error if wasn't able to find one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_guess_write_fun(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_guess_write_fun_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A writing function.
</p>


<h3>Default writing functions</h3>

<p>Here's how we identify a writing function based on file extension
</p>

<ul>
<li> <p><code>.csv</code>: <a href="readr.html#topic+write_delim">readr::write_csv</a>
</p>
</li>
<li> <p><code>.json</code>: <a href="jsonlite.html#topic+read_json">jsonlite::write_json</a>
</p>
</li>
<li> <p><code>.rds</code>: <a href="base.html#topic+readRDS">base::saveRDS</a>
</p>
</li>
<li> <p><code>.xls</code>: <a href="writexl.html#topic+write_xlsx">writexl::write_xlsx</a>
</p>
</li>
<li> <p><code>.xlsx</code>: <a href="writexl.html#topic+write_xlsx">writexl::write_xlsx</a>
</p>
</li>
<li> <p><code>.sav</code>: <a href="haven.html#topic+read_spss">haven::write_sav</a>
</p>
</li>
<li> <p><code>.xml</code>: <a href="xml2.html#topic+write_xml">xml2::write_xml</a>
</p>
</li></ul>


<hr>
<h2 id='cloud_local_ls'>List Contents of local project folder</h2><span id='topic+cloud_local_ls'></span>

<h3>Description</h3>

<p>Retrieves names, timestamps, and sizes of files and folders
inside local project folder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_local_ls(
  path = "",
  root = ".",
  recursive = FALSE,
  full_names = FALSE,
  ignore = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_local_ls_+3A_path">path</code></td>
<td>
<p>(optional) Path, relative to the specified root to list contents
of. By default, when <code>path = ""</code>, lists root-level files and folders.</p>
</td></tr>
<tr><td><code id="cloud_local_ls_+3A_root">root</code></td>
<td>
<p>Local directory path relative to which all other paths are
considered.</p>
</td></tr>
<tr><td><code id="cloud_local_ls_+3A_recursive">recursive</code></td>
<td>
<p>(logical) If <code>TRUE</code>, lists contents recursively in all
nested subfolders. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cloud_local_ls_+3A_full_names">full_names</code></td>
<td>
<p>(logical) If <code>TRUE</code>, folder path is appended to object
names to give a relative file path.</p>
</td></tr>
<tr><td><code id="cloud_local_ls_+3A_ignore">ignore</code></td>
<td>
<p>Logical flag indicating whether to ignore certain directories.
Currently, if set to <code>TRUE</code>, the 'renv' folder is ignored due to its
typically large size. This parameter may be expanded in the future to
support more complex ignore patterns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the names, last modification timestamps, and
sizes in bytes of files and folders inside the specified local folder.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># list only root-level files and folders
cloud_local_ls() 

# list all files in all nested folders
cloud_local_ls(recursive = TRUE)

## Not run: 
# list contents of "plots/barplots" subfolder (if it exists)
cloud_local_ls("plots/barplots")

## End(Not run)

</code></pre>

<hr>
<h2 id='cloud_object_ls'>Prepare a dataframe for bulk writing of objects to cloud</h2><span id='topic+cloud_object_ls'></span>

<h3>Description</h3>

<p><code style="white-space: pre;">&#8288;cloud_*_ls&#8288;</code> functions for cloud locations (e.g.
<code><a href="#topic+cloud_s3_ls">cloud_s3_ls</a></code>) return content dataframes which can then be passed to
<code style="white-space: pre;">&#8288;cloud_*_read_bulk&#8288;</code> and <code style="white-space: pre;">&#8288;cloud_*_download_bulk&#8288;</code> functions to read/download
multiple files at once. In a similar manner, this function accepts a list
of objects as an input and produces a dataframe which can then be passed to
<code style="white-space: pre;">&#8288;cloud_*_write_bulk&#8288;</code> functions to write multiple files at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_object_ls(x, path, extension, prefix = "", suffix = "")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_object_ls_+3A_x">x</code></td>
<td>
<p>A <strong>named</strong> list. Names may contain letters, digits, spaces, '.',
'-', '_' symbols and cannot contain trailing or leading spaces.</p>
</td></tr>
<tr><td><code id="cloud_object_ls_+3A_path">path</code></td>
<td>
<p>A directory relative to the project root to write objects to.</p>
</td></tr>
<tr><td><code id="cloud_object_ls_+3A_extension">extension</code></td>
<td>
<p>File extension (string) without the leading dot.</p>
</td></tr>
<tr><td><code id="cloud_object_ls_+3A_prefix">prefix</code>, <code id="cloud_object_ls_+3A_suffix">suffix</code></td>
<td>
<p>(optional) strings to attach at the beginning or at the
end of file names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble in which each row represents an object from the input list,
comprising the following columns:
</p>

<ul>
<li> <p><code>object</code> - objects you've provided
</p>
</li>
<li> <p><code>name</code> - contains paths where objects are meant to be written.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>cloud_object_ls(
  dplyr::lst(mtcars = mtcars, iris = iris),
  path = "data",
  extension = "csv",
  prefix = "df_"
)

</code></pre>

<hr>
<h2 id='cloud_object_prep_bulk'>Prepare object content dataframe to be used by bulk download/read
functions</h2><span id='topic+cloud_object_prep_bulk'></span>

<h3>Description</h3>

<p><code>cloud_object_ls</code> returns an ls-like dataframe for a named list
of objects. This function is used mainly to inform the user about which
files are going to be written and to ask for confirmation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_object_prep_bulk(content, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_object_prep_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) output of <code>cloud_object_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_object_prep_bulk_+3A_quiet">quiet</code></td>
<td>
<p>all caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified <code>content</code> dataframe.
</p>

<hr>
<h2 id='cloud_prep_ls'>Prepare ls output</h2><span id='topic+cloud_prep_ls'></span>

<h3>Description</h3>

<p>Under the hood all ls functions (s3, drive, local) obtain
information about folder content recursively regardless of <code>recursive</code>
parameter. This is needed to be able to calculate last modified time and
size for folders in case if <code>recursive</code> is set to <code>FALSE</code>. The content is
presented in a form of a dataframe similar to what you'd see if you run an
ls function with <code>recursive = TRUE</code> and <code>full_names = FALSE</code>.
</p>
<p>This function takes such a dataframe from this point and:
</p>

<ol>
<li><p> Summarizes it to non-recursive output if <code>recursive</code> is <code>FALSE</code>.
</p>
</li>
<li><p> Appends <code>path</code> to names if <code>full_names</code> is <code>TRUE</code>.
</p>
</li>
<li><p> Writes full names to names of the <code>name</code> column regardless of the
<code>full_names</code> parameter.
</p>
</li>
<li><p> Evaluates the <code>type</code> column.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>cloud_prep_ls(data, path, recursive, full_names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_prep_ls_+3A_data">data</code></td>
<td>
<p>ls dataframe assembled internally by a cloud_ls_* function</p>
</td></tr>
<tr><td><code id="cloud_prep_ls_+3A_path">path</code></td>
<td>
<p>path that was used in a cloud_ls_* function</p>
</td></tr>
<tr><td><code id="cloud_prep_ls_+3A_recursive">recursive</code></td>
<td>
<p>(logical) If <code>TRUE</code>, lists contents recursively in all
nested subfolders. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cloud_prep_ls_+3A_full_names">full_names</code></td>
<td>
<p>(logical) If <code>TRUE</code>, folder path is appended to object
names to give a relative file path.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transformed <code>data</code>.
</p>

<hr>
<h2 id='cloud_read_excel'>Read excel file as a list of dataframes</h2><span id='topic+cloud_read_excel'></span>

<h3>Description</h3>

<p>Uses <a href="readxl.html#topic+read_excel">readxl::read_excel</a> under the hood, reads all sheets and
returns them as a named list of dataframes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_read_excel(path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_read_excel_+3A_path">path</code></td>
<td>
<p>Path to the xlsx/xls file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of dataframes, where each dataframe corresponds to a
sheet in the Excel file. The names of the list elements are derived from
the sheet names.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>datasets &lt;- readxl::readxl_example("datasets.xlsx")
cloud_read_excel(datasets)

</code></pre>

<hr>
<h2 id='cloud_s3_attach'>Attach S3 folder to project</h2><span id='topic+cloud_s3_attach'></span>

<h3>Description</h3>

<p>This function facilitates the association of a specific S3
folder with a project by adding a unique identifier to the project's
DESCRIPTION file. The user is prompted to navigate to the S3 console,
select or create the desired folder for the project, and then provide its
URL. The function extracts the necessary information from the URL and
updates the <code>cloudfs.s3</code> field in the DESCRIPTION file accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_attach(project = ".")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_attach_+3A_project">project</code></td>
<td>
<p>Character. Path to a project. By default it is current working
directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return a meaningful value but modifies the
DESCRIPTION file of the specified project to include the S3 folder path.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cloud_s3_attach()

</code></pre>

<hr>
<h2 id='cloud_s3_browse'>Browse project's S3 folder</h2><span id='topic+cloud_s3_browse'></span>

<h3>Description</h3>

<p>Opens project's S3 folder in browser.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_browse(path = "", root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_browse_+3A_path">path</code></td>
<td>
<p>(optional) Path inside the S3 folder to open. Defaults to the
root level (path = &quot;&quot;) of the project's S3 folder.</p>
</td></tr>
<tr><td><code id="cloud_s3_browse_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code>. The primary purpose of this function is its
side effect: opening the specified S3 folder in a browser.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cloud_s3_browse()
cloud_s3_browse("data")

</code></pre>

<hr>
<h2 id='cloud_s3_download'>Download a file from S3 to the local project folder</h2><span id='topic+cloud_s3_download'></span>

<h3>Description</h3>

<p>Retrieves a file from the project's S3 root folder and saves it
to the local project folder, maintaining the original folder structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_download(file, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_download_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_s3_download_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code> after successfully downloading the file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# downloads toy_data/demo.csv from project's S3 folder (provided it exists)
# and saves it to local 'toy_data' folder
cloud_s3_download("toy_data/demo.csv")

# clean up
unlink("toy_data", recursive = TRUE)

</code></pre>

<hr>
<h2 id='cloud_s3_download_bulk'>Bulk Download Contents from S3</h2><span id='topic+cloud_s3_download_bulk'></span>

<h3>Description</h3>

<p>Downloads multiple files from an S3 folder based on the output
dataframe from <a href="#topic+cloud_s3_ls">cloud_s3_ls</a>. This function streamlines the process of
downloading multiple files by allowing you to filter and select specific
files from the S3 listing and then download them in bulk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_download_bulk(content, quiet = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_download_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_s3_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_s3_download_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_download_bulk_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the input <code>content</code> dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# provided there's a folder called "toy_data" in the root of your project's
# S3 folder, and this folder contains "csv" files
cloud_s3_ls("toy_data") |&gt; 
  filter(type == "csv") |&gt; 
  cloud_s3_download_bulk()
  
# clean up
unlink("toy_data", recursive = TRUE)
  

</code></pre>

<hr>
<h2 id='cloud_s3_ls'>List Contents of Project's S3 Folder</h2><span id='topic+cloud_s3_ls'></span>

<h3>Description</h3>

<p>Returns a tibble with names, timestamps, and sizes of files and
folders inside the specified S3 folder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_ls(path = "", recursive = FALSE, full_names = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_ls_+3A_path">path</code></td>
<td>
<p>(optional) Path inside the S3 folder. Specifies the subfolder
whose contents should be listed. By default, when <code>path = ""</code>, lists
root-level files and folders.</p>
</td></tr>
<tr><td><code id="cloud_s3_ls_+3A_recursive">recursive</code></td>
<td>
<p>(logical) If <code>TRUE</code>, lists contents recursively in all
nested subfolders. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_ls_+3A_full_names">full_names</code></td>
<td>
<p>(logical) If <code>TRUE</code>, folder path is appended to object
names to give a relative file path.</p>
</td></tr>
<tr><td><code id="cloud_s3_ls_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the names, last modification timestamps, and
sizes in bytes of files and folders inside the specified S3 folder.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# list only root-level files and folders
cloud_s3_ls() 

# list all files in all nested folders
cloud_s3_ls(recursive = TRUE)

# list contents of "plots/barplots" subfolder
cloud_s3_ls("plots/barplots")

</code></pre>

<hr>
<h2 id='cloud_s3_prep_bulk'>Prepare S3 content dataframe to be used by bulk download/read
functions</h2><span id='topic+cloud_s3_prep_bulk'></span>

<h3>Description</h3>

<p><code>cloud_s3_ls</code> returns a dataframe of contents of an S3 folder.
This dataframe has <code>name</code> and <code>type</code> columns. <code>name</code> may be either full
names or short names (depending on <code>full_names</code> parameter of <code>cloud_s3_ls</code>),
but <code>names(name)</code> will always contain full names. This function:
</p>

<ol>
<li><p> filters out folders
</p>
</li>
<li><p> extracts <code>names(name)</code> into <code>path</code> column.
</p>
</li>
<li><p> informs about the size of files that are to be downloaded/read and asks
for confirmation
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_prep_bulk(
  content,
  what = c("read", "upload", "download"),
  safe_size = 5e+07,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_prep_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_s3_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_s3_prep_bulk_+3A_what">what</code></td>
<td>
<p>What will be done with content, either &quot;read&quot; or &quot;download&quot;.
This affects only how messages will look.</p>
</td></tr>
<tr><td><code id="cloud_s3_prep_bulk_+3A_safe_size">safe_size</code></td>
<td>
<p>What is considered to be safe size in bytes to download in
bulk. To show additional caution message in case if you accidentally run
bulk reading on a folder with gigabytes of data.</p>
</td></tr>
<tr><td><code id="cloud_s3_prep_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transformed <code>content</code> dataframe.
</p>

<hr>
<h2 id='cloud_s3_read'>Read a file from S3</h2><span id='topic+cloud_s3_read'></span>

<h3>Description</h3>

<p>Retrieves and reads a file from the project's S3 folder. By
default, the function attempts to determine the appropriate reading
function based on the file's extension. However, you can specify a custom
reading function if necessary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_read(file, fun = NULL, ..., root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_read_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_s3_read_+3A_fun">fun</code></td>
<td>
<p>A custom reading function. If <code>NULL</code> (default), the appropriate
reading function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_s3_read_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the reading function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_read_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The content of the file read from S3, with additional attributes
containing metadata about the file.
</p>


<h3>Default reading functions</h3>

<p>Here's how we identify a reading function based on file extension
</p>

<ul>
<li> <p><code>.csv</code>: <a href="readr.html#topic+read_delim">readr::read_csv</a>
</p>
</li>
<li> <p><code>.json</code>: <a href="jsonlite.html#topic+read_json">jsonlite::read_json</a>
</p>
</li>
<li> <p><code>.rds</code>: <a href="base.html#topic+readRDS">base::readRDS</a>
</p>
</li>
<li> <p><code>.sav</code>: <a href="haven.html#topic+read_spss">haven::read_sav</a>
</p>
</li>
<li> <p><code>.xls</code>: <a href="#topic+cloud_read_excel">cloud_read_excel</a>
</p>
</li>
<li> <p><code>.xlsx</code>: <a href="#topic+cloud_read_excel">cloud_read_excel</a>
</p>
</li>
<li> <p><code>.xml</code>: <a href="xml2.html#topic+read_xml">xml2::read_xml</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# provided there are folders called "data" and "models" in the root of your
# project's main S3 folder and they contain the files mentioned below
cloud_s3_read("data/mtcars.csv")
cloud_s3_read("models/random_forest.rds")
cloud_s3_read("data/dm.sas7bdat", fun = haven::read_sas)

</code></pre>

<hr>
<h2 id='cloud_s3_read_bulk'>Bulk Read Contents from S3</h2><span id='topic+cloud_s3_read_bulk'></span>

<h3>Description</h3>

<p>This function facilitates the bulk reading of multiple files
from the project's designated S3 folder. By using <a href="#topic+cloud_s3_ls">cloud_s3_ls</a>, you can
obtain a dataframe detailing the contents of the S3 folder. Applying
<code>cloud_s3_read_bulk</code> to this dataframe allows you to read all listed files
into a named list. The function will, by default, infer the appropriate
reading method based on each file's extension. However, if a specific
reading function is provided via the <code>fun</code> parameter, it will be applied
uniformly to all files, which may not be suitable for diverse file types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_read_bulk(content, fun = NULL, ..., quiet = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_read_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_s3_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_s3_read_bulk_+3A_fun">fun</code></td>
<td>
<p>A custom reading function. If <code>NULL</code> (default), the appropriate
reading function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_s3_read_bulk_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the reading function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_read_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_read_bulk_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list where each element corresponds to the content of a file
from S3. The names of the list elements are derived from the file names.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# provided there's a folder called "data" in the root of the project's main
# S3 folder, and it contains csv files
data_lst &lt;- 
  cloud_s3_ls("data") |&gt;  
  filter(type == "csv")  |&gt;  
  cloud_s3_read_bulk()
  

</code></pre>

<hr>
<h2 id='cloud_s3_upload'>Upload a local file to S3</h2><span id='topic+cloud_s3_upload'></span>

<h3>Description</h3>

<p>Uploads a local file from the project's directory to its
corresponding location within the project's S3 root folder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_upload(file, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_upload_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_s3_upload_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code> after successfully uploading the file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create a toy csv file
dir.create("toy_data")
write.csv(mtcars, "toy_data/mtcars.csv")

# uploads toy_data/mtcars.csv to 'data' subfolder of project's S3 folder
cloud_s3_upload("toy_data/mtcars.csv")

# clean up
unlink("toy_data", recursive = TRUE)

</code></pre>

<hr>
<h2 id='cloud_s3_upload_bulk'>Bulk Upload Files to S3</h2><span id='topic+cloud_s3_upload_bulk'></span>

<h3>Description</h3>

<p>This function facilitates the bulk uploading of multiple files
from the local project folder to the project's designated S3 folder. By
using <a href="#topic+cloud_local_ls">cloud_local_ls</a>, you can obtain a dataframe detailing the contents
of the local folder. Applying <code>cloud_s3_upload_bulk</code> to this dataframe
allows you to upload all listed files to S3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_upload_bulk(content, quiet = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_upload_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) Output of <code>cloud_s3_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_s3_upload_bulk_+3A_quiet">quiet</code></td>
<td>
<p>All caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_upload_bulk_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the input <code>content</code> dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create toy plots: 2 png's and 1 jpeg
dir.create("toy_plots")
png("toy_plots/plot1.png"); plot(rnorm(100)); dev.off()
png("toy_plots/plot2.png"); plot(hist(rnorm(100))); dev.off()
png("toy_plots/plot3.jpeg"); plot(hclust(dist(USArrests), "ave")); dev.off()

# upload only the two png's
cloud_local_ls("toy_plots")  |&gt; 
  dplyr::filter(type == "png")  |&gt; 
  cloud_s3_upload_bulk()

# clean up
unlink("toy_plots", recursive = TRUE)
  

</code></pre>

<hr>
<h2 id='cloud_s3_write'>Write an object to S3</h2><span id='topic+cloud_s3_write'></span>

<h3>Description</h3>

<p>Saves an R object to a designated location in the project's
S3 storage. If no custom writing function is specified, the function will
infer the appropriate writing method based on the file's extension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_write(x, file, fun = NULL, ..., local = FALSE, root = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_write_+3A_x">x</code></td>
<td>
<p>An R object to be written to S3.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_+3A_fun">fun</code></td>
<td>
<p>A custom writing function. If <code>NULL</code> (default), the appropriate
writing function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the writing function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_+3A_local">local</code></td>
<td>
<p>Logical, defaulting to <code>FALSE</code>. If <code>TRUE</code>, the function will
also create a local copy of the file at the specified path. Note that some
writing functions might not overwrite existing files unless explicitly
allowed. Typically, such functions have a parameter (often named
<code>overwrite</code>) to control this behavior. Check the documentation of the
writing function used to determine the exact parameter name and pass it
through the <code>...</code> argument if necessary. Alternatively, you can define an
anonymous function for <code>fun</code> that calls a writing function with the
overwriting option enabled.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns <code>NULL</code> after successfully writing the object to S3.
</p>


<h3>Default writing functions</h3>

<p>Here's how we identify a writing function based on file extension
</p>

<ul>
<li> <p><code>.csv</code>: <a href="readr.html#topic+write_delim">readr::write_csv</a>
</p>
</li>
<li> <p><code>.json</code>: <a href="jsonlite.html#topic+read_json">jsonlite::write_json</a>
</p>
</li>
<li> <p><code>.rds</code>: <a href="base.html#topic+readRDS">base::saveRDS</a>
</p>
</li>
<li> <p><code>.xls</code>: <a href="writexl.html#topic+write_xlsx">writexl::write_xlsx</a>
</p>
</li>
<li> <p><code>.xlsx</code>: <a href="writexl.html#topic+write_xlsx">writexl::write_xlsx</a>
</p>
</li>
<li> <p><code>.sav</code>: <a href="haven.html#topic+read_spss">haven::write_sav</a>
</p>
</li>
<li> <p><code>.xml</code>: <a href="xml2.html#topic+write_xml">xml2::write_xml</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# write mtcars dataframe to mtcars.csv in data folder
cloud_s3_write(mtcars, "data/mtcars.csv")
cloud_s3_write(random_forest, "models/random_forest.rds")

# provide custom writing function with parameters 
cloud_s3_write(c("one", "two"), "text/count.txt", writeLines, sep = "\n\n")

</code></pre>

<hr>
<h2 id='cloud_s3_write_bulk'>Write multiple objects to S3 in bulk</h2><span id='topic+cloud_s3_write_bulk'></span>

<h3>Description</h3>

<p>This function allows for the bulk writing of multiple R objects
to the project's designated S3 folder. To prepare a list of objects for
writing, use <a href="#topic+cloud_object_ls">cloud_object_ls</a>, which generates a dataframe listing the
objects and their intended destinations in a format akin to the output of
<a href="#topic+cloud_s3_ls">cloud_s3_ls</a>. By default, the function determines the appropriate writing
method based on each file's extension. However, if a specific writing
function is provided via the <code>fun</code> parameter, it will be applied to all
files, which may not be ideal if dealing with a variety of file types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_s3_write_bulk(
  content,
  fun = NULL,
  ...,
  local = FALSE,
  quiet = FALSE,
  root = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloud_s3_write_bulk_+3A_content">content</code></td>
<td>
<p>(data.frame) output of <code>cloud_object_ls()</code></p>
</td></tr>
<tr><td><code id="cloud_s3_write_bulk_+3A_fun">fun</code></td>
<td>
<p>A custom writing function. If <code>NULL</code> (default), the appropriate
writing function will be inferred based on the file's extension.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_bulk_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the writing function <code>fun</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_bulk_+3A_local">local</code></td>
<td>
<p>Logical, defaulting to <code>FALSE</code>. If <code>TRUE</code>, the function will
also create a local copy of the file at the specified path. Note that some
writing functions might not overwrite existing files unless explicitly
allowed. Typically, such functions have a parameter (often named
<code>overwrite</code>) to control this behavior. Check the documentation of the
writing function used to determine the exact parameter name and pass it
through the <code>...</code> argument if necessary. Alternatively, you can define an
anonymous function for <code>fun</code> that calls a writing function with the
overwriting option enabled.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_bulk_+3A_quiet">quiet</code></td>
<td>
<p>all caution messages may be turned off by setting this parameter
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cloud_s3_write_bulk_+3A_root">root</code></td>
<td>
<p>S3 path of the project root. This serves as the reference point
for all relative paths. When left as <code>NULL</code>, the root is automatically
derived from the <code>cloudfs.s3</code> field of the project's DESCRIPTION file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the input <code>content</code> dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# write two csv files: data/df_mtcars.csv and data/df_iris.csv
cloud_object_ls(
  dplyr::lst(mtcars = mtcars, iris = iris),
  path = "data",
  extension = "csv",
  prefix = "df_"
) |&gt;  
cloud_s3_write_bulk()
  

</code></pre>

<hr>
<h2 id='doc_file'>Package-wide description of <code>file</code> parameter</h2><span id='topic+doc_file'></span>

<h3>Description</h3>

<p>A dummy function to be referred by <code style="white-space: pre;">&#8288;@inheritParams&#8288;</code> for a
parameter documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doc_file(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doc_file_+3A_file">file</code></td>
<td>
<p>Path to a file relative to project folder root. Can contain only
letters, digits, '-', '_', '.', spaces and '/' symbols.</p>
</td></tr>
</table>

<hr>
<h2 id='doc_local'>Package-wide description of <code>local</code> parameter</h2><span id='topic+doc_local'></span>

<h3>Description</h3>

<p>A dummy function to be referred by <code style="white-space: pre;">&#8288;@inheritParams&#8288;</code> for a
parameter documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doc_local(local)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doc_local_+3A_local">local</code></td>
<td>
<p>Logical, defaulting to <code>FALSE</code>. If <code>TRUE</code>, the function will
also create a local copy of the file at the specified path. Note that some
writing functions might not overwrite existing files unless explicitly
allowed. Typically, such functions have a parameter (often named
<code>overwrite</code>) to control this behavior. Check the documentation of the
writing function used to determine the exact parameter name and pass it
through the <code>...</code> argument if necessary. Alternatively, you can define an
anonymous function for <code>fun</code> that calls a writing function with the
overwriting option enabled.</p>
</td></tr>
</table>

<hr>
<h2 id='proj_desc_get'>Extract values from DESCRIPTION file</h2><span id='topic+proj_desc_get'></span>

<h3>Description</h3>

<p>Extract values from DESCRIPTION file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proj_desc_get(key, project = ".")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proj_desc_get_+3A_key">key</code></td>
<td>
<p>Character. What field to search for in DESCRIPTION file.</p>
</td></tr>
<tr><td><code id="proj_desc_get_+3A_project">project</code></td>
<td>
<p>Character. Path to a project. By default it is current working
directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string value extracted from the DESCRIPTION field.
</p>

<hr>
<h2 id='validate_desc'>Validate project's DESCRIPTION file</h2><span id='topic+validate_desc'></span>

<h3>Description</h3>

<p>Checks that DESCRIPTION file exists in a project folder. If it's
not the case, proposes to create a DESCRIPTION file from template.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_desc(project = ".")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_desc_+3A_project">project</code></td>
<td>
<p>Character. Path to a project. By default it is current working
directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>TRUE</code> or an error.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
