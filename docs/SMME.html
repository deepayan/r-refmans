<!DOCTYPE html><html lang="en"><head><title>Help for package SMME</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SMME}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#iwt'><p>Inverse discrete wavelet transform</p></a></li>
<li><a href='#predict.SMME'><p>Make Prediction From a SMME Object</p></a></li>
<li><a href='#print.SMME'><p>Print Function for objects of Class SMME</p></a></li>
<li><a href='#RH'><p>The Rotated H-transform of a 3d Array by a Matrix</p></a></li>
<li><a href='#SMME'><p>Soft Maximin Estimation for Large Scale Heterogenous Data</p></a></li>
<li><a href='#wt'><p>Discrete wavelet transform</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Soft Maximin Estimation for Large Scale Heterogeneous Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-01-02</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adam Lund &lt;adam.lund@math.ku.dk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient procedure for solving the soft maximin problem for large scale heterogeneous data, see Lund, Mogensen and Hansen (2022) &lt;<a href="https://doi.org/10.1111%2Fsjos.12580">doi:10.1111/sjos.12580</a>&gt;. Currently Lasso and SCAD penalized estimation is implemented. Note this package subsumes and replaces the SMMA package.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.12)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-02 11:22:09 UTC; adam</td>
</tr>
<tr>
<td>Author:</td>
<td>Adam Lund [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-08 10:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='iwt'>Inverse discrete wavelet transform</h2><span id='topic+iwt'></span>

<h3>Description</h3>

<p>This function performs a level J decomposition of the input
array (1d, 2d, or 3d) using the pyramid algorithm (Mallat 1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iwt(x, wf = "la8", J = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iwt_+3A_x">x</code></td>
<td>
<p>a 1, 2, or 3 dimensional data array. The size of each dimension must
be dyadic.</p>
</td></tr>
<tr><td><code id="iwt_+3A_wf">wf</code></td>
<td>
<p>the type of wavelet family used. See R-package waveslim for options.</p>
</td></tr>
<tr><td><code id="iwt_+3A_j">J</code></td>
<td>
<p>is the level (depth) of the decomposition. For default <code>NULL</code> the max
depth is used  making <code>iwt(x)</code> equal to multiplying <code>x</code> with the
inverse of corresponding wavelet matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a C++/R wrapper function for a C implementation of the
inverse discrete wavelet transform by Brandon Whitcher, Rigorous Analytics Ltd,
licensed under the BSD 3 license
https://cran.r-project.org/web/licenses/BSD_3_clause, see the Waveslim package;
Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001).
</p>
<p>Given a data array (1d, 2d or 3d) with dyadic
sizes this transform is computed efficiently via the pyramid
algorithm see Mallat (1989).
</p>
<p>This functionality is used in the computations underlying <code><a href="#topic+softmaximin">softmaximin</a></code>
to perform multiplications involving the wavelet (design) matrix efficiently.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>...</code></td>
<td>
<p>An array with dimensions equal to those of <code>x</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund, Brandon Whitcher
</p>


<h3>References</h3>

<p>Gencay, R., F. Selcuk and B. Whitcher (2001) An Introduction to Wavelets and
Other Filtering Methods in Finance and Economics, Academic Press.
</p>
<p>Mallat, S. G. (1989) A theory for multiresolution signal decomposition: the
wavelet representation, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 11, No. 7, 674-693.
</p>
<p>Percival, D. B. and A. T. Walden (2000) Wavelet Methods for Time Series
Analysis, Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###1d
x &lt;- as.matrix(rnorm(2^3))
range(x - iwt(wt(x)))

###2d
x &lt;- matrix(rnorm(2^(3 + 4)), 2^3, 2^4)
range(x - iwt(wt(x)))

###3d
x &lt;- array(rnorm(2^(3 + 4 + 5)), c(2^3, 2^4, 2^5))
range(x - iwt(wt(x)))

</code></pre>

<hr>
<h2 id='predict.SMME'>Make Prediction From a SMME Object</h2><span id='topic+predict.SMME'></span><span id='topic+SMME_predict'></span><span id='topic+SMME.predict'></span>

<h3>Description</h3>

<p>Given new covariate data this function computes the linear predictors
based on the estimated model coefficients in an object produced by the function
<code>softmaximin</code>. Note that the data can be supplied in three different
formats: i) for general models as a <code class="reqn">n' \times p</code> matrix (<code class="reqn">p</code> is the
number of model coefficients and <code class="reqn">n'</code> is the number of new data points),
ii) for array models with custom design as a list of one, two or three Kronecker component
matrices each of size <code class="reqn">n_i' \times p_i, i = 1, 2, 3</code>
(<code class="reqn">n_i'</code> is the number of new marginal data points in the <code class="reqn">i</code>th dimension),
iii) for wavelet based models a string indicating the wavelet used to produce
the model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SMME'
predict(object, x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.SMME_+3A_object">object</code></td>
<td>
<p>An object of class SMME, produced with <code>softmaximin</code> with
<code class="reqn">m_\zeta</code> fitted models for each value of <code>zeta</code>.</p>
</td></tr>
<tr><td><code id="predict.SMME_+3A_x">x</code></td>
<td>
<p>An object that should be like the input to the <code>softmaximin</code> call
that produced <code>object</code>. For general  models a matrix with column
dimension equal to that of  the original input.For array models with custom
design a list like the one supplied to <code>softmaximin</code> to produce <code>object</code>
and for a wavelet design the name of the wavelet used to produce <code>object</code>.</p>
</td></tr>
<tr><td><code id="predict.SMME_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length <code>length(zeta)</code>. If <code>x</code> is a <code class="reqn">n' \times p</code>
matrix each list item is a <code class="reqn">n'\times m_\zeta</code> matrix containing the linear
predictors computed for each <code>lambda</code>. If <code>x</code> is a string or a list of
tensor component matrices and <code>fit$dim = d</code>, each list item is a <code class="reqn">d + 1</code>
array  containing predictions computed for each <code>lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Adam Lund
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##size of example
n1 &lt;- 65; n2 &lt;- 26; n3 &lt;- 13; p1 &lt;- 13; p2 &lt;- 5; p3 &lt;- 4

##marginal design matrices (Kronecker components)
X1 &lt;- matrix(rnorm(n1 * p1, 0, 0.5), n1, p1)
X2 &lt;- matrix(rnorm(n2 * p2, 0, 0.5), n2, p2)
X3 &lt;- matrix(rnorm(n3 * p3, 0, 0.5), n3, p3)
X &lt;- list(X1, X2, X3)

component &lt;- rbinom(p1 * p2 * p3, 1, 0.1)
Beta1 &lt;- array(rnorm(p1 * p2 * p3, 0, 0.1) + component, c(p1 , p2, p3))
Beta2 &lt;- array(rnorm(p1 * p2 * p3, 0, 0.1) + component, c(p1 , p2, p3))
mu1 &lt;- RH(X3, RH(X2, RH(X1, Beta1)))
mu2 &lt;- RH(X3, RH(X2, RH(X1, Beta2)))
Y1 &lt;- array(rnorm(n1 * n2 * n3, mu1), dim = c(n1, n2, n3))
Y2 &lt;- array(rnorm(n1 * n2 * n3, mu2), dim = c(n1, n2, n3))

Y &lt;- array(NA, c(dim(Y1), 2))
Y[,,, 1] &lt;- Y1; Y[,,, 2] &lt;- Y2;

fit &lt;- softmaximin(X, Y, zeta = c(1, 10), penalty = "lasso", alg = "npg")

##new data in tensor component form
X1 &lt;- matrix(rnorm(2 * p1), nrow = 2)
X2 &lt;- matrix(rnorm(3 * p2), nrow = 3)
X3 &lt;- matrix(rnorm(4 * p3), nrow = 4)
Yhat &lt;- predict(fit, x = list(X1, X2, X3))

</code></pre>

<hr>
<h2 id='print.SMME'>Print Function for objects of Class SMME</h2><span id='topic+print.SMME'></span>

<h3>Description</h3>

<p>This function will print some information about the SMME object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SMME'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.SMME_+3A_x">x</code></td>
<td>
<p>a SMME object</p>
</td></tr>
<tr><td><code id="print.SMME_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##size of example
n1 &lt;- 65; n2 &lt;- 26; n3 &lt;- 13; p1 &lt;- 13; p2 &lt;- 5; p3 &lt;- 4

##marginal design matrices (Kronecker components)
X1 &lt;- matrix(rnorm(n1 * p1, 0, 0.5), n1, p1)
X2 &lt;- matrix(rnorm(n2 * p2, 0, 0.5), n2, p2)
X3 &lt;- matrix(rnorm(n3 * p3, 0, 0.5), n3, p3)
X &lt;- list(X1, X2, X3)

component &lt;- rbinom(p1 * p2 * p3, 1, 0.1)
Beta1 &lt;- array(rnorm(p1 * p2 * p3, 0, .1) + component, c(p1 , p2, p3))
Beta2 &lt;- array(rnorm(p1 * p2 * p3, 0, .1) + component, c(p1 , p2, p3))
mu1 &lt;- RH(X3, RH(X2, RH(X1, Beta1)))
mu2 &lt;- RH(X3, RH(X2, RH(X1, Beta2)))
Y1 &lt;- array(rnorm(n1 * n2 * n3, mu1), dim = c(n1, n2, n3))
Y2 &lt;- array(rnorm(n1 * n2 * n3, mu2), dim = c(n1, n2, n3))

Y &lt;- array(NA, c(dim(Y1), 2))
Y[,,, 1] &lt;- Y1; Y[,,, 2] &lt;- Y2;

fit &lt;- softmaximin(X, Y, zeta = 10, penalty = "lasso", alg = "npg")
fit
</code></pre>

<hr>
<h2 id='RH'>The Rotated H-transform of a 3d Array by a Matrix</h2><span id='topic+RH'></span><span id='topic+SMME_RH'></span><span id='topic+Rotate'></span><span id='topic+H'></span>

<h3>Description</h3>

<p>This function is an implementation of the <code class="reqn">\rho</code>-operator found in
<cite>Currie et al 2006</cite>. It forms the basis of the GLAM arithmetic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RH(M, A)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RH_+3A_m">M</code></td>
<td>
<p>a <code class="reqn">n \times p_1</code> matrix.</p>
</td></tr>
<tr><td><code id="RH_+3A_a">A</code></td>
<td>
<p>a 3d array of size <code class="reqn">p_1 \times p_2 \times p_3</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details see <cite>Currie et al 2006</cite>. Note that this particular implementation
is not used in the  routines underlying the optimization procedure.
</p>


<h3>Value</h3>

<p>A 3d array of size <code class="reqn">p_2 \times p_3 \times n</code>.
</p>


<h3>Author(s)</h3>

<p>Adam Lund
</p>


<h3>References</h3>

<p>Currie, I. D., M. Durban, and P. H. C. Eilers (2006). Generalized linear
array models with applications to multidimensional smoothing.
<em>Journal of the Royal Statistical Society. Series B</em>. 68, 259-280. url = http://dx.doi.org/10.1111/j.1467-9868.2006.00543.x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n1 &lt;- 65; n2 &lt;- 26; n3 &lt;- 13; p1 &lt;- 13; p2 &lt;- 5; p3 &lt;- 4

##marginal design matrices (Kronecker components)
X1 &lt;- matrix(rnorm(n1 * p1), n1, p1)
X2 &lt;- matrix(rnorm(n2 * p2), n2, p2)
X3 &lt;- matrix(rnorm(n3 * p3), n3, p3)

Beta &lt;- array(rnorm(p1 * p2 * p3, 0, 1), c(p1 , p2, p3))
max(abs(c(RH(X3, RH(X2, RH(X1, Beta)))) - kronecker(X3, kronecker(X2, X1)) %*% c(Beta)))

</code></pre>

<hr>
<h2 id='SMME'>Soft Maximin Estimation for Large Scale Heterogenous Data</h2><span id='topic+SMME'></span><span id='topic+softmaximin'></span><span id='topic+pga'></span>

<h3>Description</h3>

<p>Efficient procedure for solving the Lasso or SCAD penalized soft
maximin problem for large scale_y data. This software implements two proximal
gradient based algorithms (NPG and FISTA) to solve different forms of the soft
maximin problem from <cite>Lund et al., 2022</cite>. 1) For general group specific
design the soft maximin problem is solved using the NPG algorithm.
2) For fixed identical d-array-tensor design across groups, where <code class="reqn">d = 1, 2, 3</code>, the
estimation procedure uses either the FISTA algorithm or the NPG algorithm and
is implemented for the following two cases; i) For a tensor design matrix the
algorithms use array arithmetic to speed up design matrix multiplications
using only the tensor components ii) For a wavelet design matrix the algorithms use
the pyramid algorithm to completely avoid the design matrix and speed up
design matrix multiplications.
Multi-threading is possible when openMP is available for R.
</p>
<p>Note this package SMME replaces the SMMA package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmaximin(x,
            y,
            zeta,
            penalty = c("lasso", "scad"),
            alg = c("npg", "fista"),
            nlambda = 30,
            lambda.min.ratio = 1e-04,
            lambda = NULL,
            scale_y = 1,
            penalty.factor = NULL,
            reltol = 1e-05,
            maxiter = 1000,
            steps = 1,
            btmax = 100,
            c = 0.0001,
            tau = 2,
            M = 4,
            nu = 1,
            Lmin = 0,
            lse = TRUE,
            nthreads = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SMME_+3A_x">x</code></td>
<td>
<p>Either a list containing the G group specific design matrices of sizes
<code class="reqn">n_i \times p_i</code> (general model),  a list containing the <code class="reqn">d</code>
(<code class="reqn">d \in \{ 1, 2, 3\}</code>) tensor components (tensor array model) or a string
indicating which wavelet design to use (wavelet array model), see <a href="#topic+wt">wt</a>
for options.</p>
</td></tr>
<tr><td><code id="SMME_+3A_y">y</code></td>
<td>
<p>list containing the G group specific response vectors of sizes
<code class="reqn">n_i \times 1</code>. Alternatively for a model with identical tensor design
across G groups, <code>y</code>is an array of size <code class="reqn">n_1 \times\cdots\times n_d \times G</code>
(<code class="reqn">d \in \{ 1, 2, 3\}</code>) containing the response values.</p>
</td></tr>
<tr><td><code id="SMME_+3A_zeta">zeta</code></td>
<td>
<p>vector of strictly positive floats controlling  the softmaximin
approximation accuracy. When <code>length(zeta) &gt; 1</code> the procedure will distribute
the computations using the <code>nthreads</code> parameter below when openMP is available.</p>
</td></tr>
<tr><td><code id="SMME_+3A_penalty">penalty</code></td>
<td>
<p>string specifying the penalty type. Possible values are
<code>"lasso", "scad"</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_alg">alg</code></td>
<td>
<p>string specifying the optimization algorithm. Possible values are
<code>"npg", "fista"</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_nlambda">nlambda</code></td>
<td>
<p>positive integer giving the number of <code>lambda</code> values.
Used when lambda is not specified.</p>
</td></tr>
<tr><td><code id="SMME_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>strictly positive float giving the smallest value for
<code>lambda</code>, as a fraction of <code class="reqn">\lambda_{max}</code>; the (data dependent)
smallest value for which all coefficients are zero. Used when lambda is not
specified.</p>
</td></tr>
<tr><td><code id="SMME_+3A_lambda">lambda</code></td>
<td>
<p>A sequence of strictly positive floats used  as penalty parameters.</p>
</td></tr>
<tr><td><code id="SMME_+3A_scale_y">scale_y</code></td>
<td>
<p>strictly positive number that the response <code>y</code> is multiplied with.</p>
</td></tr>
<tr><td><code id="SMME_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>a length <code class="reqn">p</code> vector of positive floats that are
multiplied with each element in <code>lambda</code> to allow differential penalization
on the coefficients. For tensor models an array of size <code class="reqn">p_1 \times \cdots \times p_d</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_reltol">reltol</code></td>
<td>
<p>strictly positive float giving the convergence tolerance.</p>
</td></tr>
<tr><td><code id="SMME_+3A_maxiter">maxiter</code></td>
<td>
<p>positive integer giving the maximum number of  iterations
allowed for each <code>lambda</code> value.</p>
</td></tr>
<tr><td><code id="SMME_+3A_steps">steps</code></td>
<td>
<p>strictly positive integer giving the number of steps used in the
multi-step adaptive lasso algorithm for non-convex penalties. Automatically
set to 1 when <code>penalty = "lasso"</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_btmax">btmax</code></td>
<td>
<p>strictly positive integer giving the maximum number of backtracking
steps allowed in each iteration. Default is <code>btmax = 100</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_c">c</code></td>
<td>
<p>strictly positive float used in the NPG algorithm. Default is
<code>c = 0.0001</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_tau">tau</code></td>
<td>
<p>strictly positive float used to control the stepsize for NPG.
Default is <code>tau = 2</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_m">M</code></td>
<td>
<p>positive integer giving the look back for the NPG. Default is <code>M = 4</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_nu">nu</code></td>
<td>
<p>strictly positive float used to control the stepsize. A  value less
that 1 will decrease the stepsize and a value larger than one will increase it.
Default is <code>nu = 1</code>.</p>
</td></tr>
<tr><td><code id="SMME_+3A_lmin">Lmin</code></td>
<td>
<p>non-negative float used by the NPG algorithm to control the
stepsize. For the default  <code>Lmin = 0</code> the maximum step size is the same
as for the FISTA algorithm.</p>
</td></tr>
<tr><td><code id="SMME_+3A_lse">lse</code></td>
<td>
<p>logical variable indicating whether to use the log-sum-exp-loss.  TRUE is
default and yields the loss below and  FALSE yields the exponential of this.</p>
</td></tr>
<tr><td><code id="SMME_+3A_nthreads">nthreads</code></td>
<td>
<p>integer giving the number of threads to use when  openMP
is available. Default is 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider modeling heterogeneous data <code class="reqn">y_1,\ldots, y_n</code> by dividing
it into <code class="reqn">G</code> groups <code class="reqn">\mathbf{y}_g = (y_1, \ldots, y_{n_g})</code>,
<code class="reqn">g \in \{ 1,\ldots, G\}</code> and then using a linear model
</p>
<p style="text-align: center;"><code class="reqn">
\mathbf{y}_g = \mathbf{X}_gb_g + \epsilon_g, \quad g \in \{1,\ldots, G\},
</code>
</p>

<p>to model the group response. Then <code class="reqn">b_g</code> is a group specific <code class="reqn">p\times 1</code>
coefficient, <code class="reqn">\mathbf{X}_g</code> an <code class="reqn">n_g\times p</code> group design matrix and
<code class="reqn">\epsilon_g</code> an <code class="reqn">n_g\times 1</code> error term. The objective is to estimate
a common coefficient <code class="reqn">\beta</code> such that <code class="reqn">\mathbf{X}_g\beta</code> is a robust
and good approximation to <code class="reqn">\mathbf{X}_gb_g</code> across groups.
</p>
<p>Following <cite>Lund et al., 2022</cite>, this objective may be accomplished by
solving the soft maximin estimation problem
</p>
<p style="text-align: center;"><code class="reqn">
\min_{\beta}\frac{1}{\zeta}\log\bigg(\sum_{g = 1}^G \exp(-\zeta \hat V_g(\beta))\bigg)
 + \lambda  \Vert\beta\Vert_1, \quad \zeta &gt; 0,\lambda \geq 0.
</code>
</p>

<p>Here <code class="reqn">\zeta</code> essentially controls the amount of pooling across groups
(<code class="reqn">\zeta \sim 0</code> effectively ignores grouping and pools observations) and
</p>
<p style="text-align: center;"><code class="reqn">
\hat V_g(\beta):=\frac{1}{n_g}(2\beta^\top \mathbf{X}_g^\top
\mathbf{y}_g-\beta^\top \mathbf{X}_g^\top \mathbf{X}_g\beta),
</code>
</p>

<p>is the empirical explained variance, see <cite>Lund et al., 2022</cite> for more
details and references.
</p>
<p>The function <code>softmaximin</code> solves the soft maximin estimation problem in
large scale settings for a sequence of penalty parameters
<code class="reqn">\lambda_{max}&gt;\ldots &gt;\lambda_{min}&gt;0</code> and a sequence of strictly positive
softmaximin  parameters <code class="reqn">\zeta_1, \zeta_2,\ldots</code>.
</p>
<p>The implementation also solves the
problem above with the penalty given by the SCAD penalty, using the multiple
step adaptive lasso procedure to loop over the inner proximal algorithm.
</p>
<p>Two optimization algorithms  are implemented in the SMME packages;
a non-monotone proximal gradient (NPG) algorithm and a fast iterative soft
thresholding algorithm (FISTA).
</p>
<p>The implementation is particularly efficient for models where the design is
identical across groups i.e. <code class="reqn">\mathbf{X}_g = \mathbf{X}</code>
<code class="reqn">\forall g \in \{1, \ldots, G\}</code> in the following two cases:
i) first if <code class="reqn">\mathbf{X}</code> has tensor structure i.e.
</p>
<p style="text-align: center;"><code class="reqn">
\mathbf{X} = \bigotimes_{i=1}^d \mathbf{M}_i
</code>
</p>

<p>for marginal <code class="reqn">n_i\times p_i</code> design matrices <code class="reqn">\mathbf{M}_1,\ldots, \mathbf{M}_d</code>
, <code class="reqn">d \in \{ 1, 2, 3\}</code>, <code>y</code> is a <code class="reqn">d + 1</code> dimensional response array
and  <code>x</code> is a list containing the <code class="reqn">d</code> marginal matrices
<code class="reqn">\mathbf{M}_1,\ldots, \mathbf{M}_d</code>. In this case <code>softmaximin</code> solves
the soft maximin problem using minimal memory by way of tensor optimized
arithmetic, see also <code><a href="#topic+RH">RH</a></code>.
ii) second, if the design matrix <code class="reqn">\mathbf{X}</code> is the inverse matrix of an
orthogonal wavelet transform <code>softmaximin</code>  solves the soft maximin problem
given the <code class="reqn">d + 1</code> dimensional response array <code>y</code> and
<code>x</code> the name of the wavelet family <code><a href="#topic+wt">wt</a></code>,  using the
pyramid algorithm to compute multiplications
involving <code class="reqn">\mathbf{X}</code>.
</p>
<p>Note that when multiple values for <code class="reqn">\zeta</code> is provided it is  possible to
distribute the computations across CPUs if openMP is available.
</p>


<h3>Value</h3>

<p>An object with S3 Class &quot;SMME&quot;.
</p>
<table role = "presentation">
<tr><td><code>spec</code></td>
<td>
<p>A string indicating the array dimension (1, 2 or 3) and the penalty.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>A  <code>length(zeta)</code>-list of <code class="reqn">p \times</code> <code>nlambda</code>
matrices containing the estimates of the model coefficients (<code class="reqn">\beta</code>) for
each <code>lambda</code>-value for which the procedure converged.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>A <code>length(zeta)</code>-list vectors containing the sequence of
penalty values used in the estimation procedure for which the procedure converged.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>A  <code>length(zeta)</code>-list of vectors indicating the nonzero model
coefficients for each value of <code>lambda</code> for which the procedure converged.</p>
</td></tr>
<tr><td><code>dimcoef</code></td>
<td>
<p>An integer giving the number <code class="reqn">p</code> of model parameters.
For array data a vector giving the dimension of the model coefficient array <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>dimobs</code></td>
<td>
<p>An integer giving the number of observations. For array data a
vector giving the dimension of the observation (response) array <code>Y</code>.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Integer indicating the dimension of of the array model. Equal to 1
for non array.</p>
</td></tr>
<tr><td><code>wf</code></td>
<td>
<p>A string indicating the wavelet name if used.</p>
</td></tr>
<tr><td><code>diagnostics</code></td>
<td>
<p>A list of length 3. Item <code>iter</code> is a <code>length(zeta)</code>-list
of vectors containing  the number of   iterations for each <code>lambda</code> value
for which the algorithm converged. Item <code>bt_iter</code>  is a  <code>length(zeta)</code>
vector with total number of backtracking steps performed across all (converged)
<code>lambda</code> values for given  <code>zeta</code> value. Key <code>bt_enter</code> is a
<code>length(zeta)</code> vector with  total number of times backtracking is initiated
across all (converged)  <code>lambda</code> values for given <code>zeta</code> value.</p>
</td></tr>
<tr><td><code>endmod</code></td>
<td>
<p>Vector of length <code>length(zeta)</code> with the number of
models fitted for each <code>zeta</code>.</p>
</td></tr>
<tr><td><code>Stops</code></td>
<td>
<p>Convergence indicators.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund
</p>
<p>Maintainer: Adam Lund, <a href="mailto:adam.lund@math.ku.dk">adam.lund@math.ku.dk</a>
</p>


<h3>References</h3>

<p>Lund, A., S. W. Mogensen and N. R. Hansen (2022). Soft Maximin Estimation for
Heterogeneous Data. <em>Scandinavian Journal of Statistics</em>, vol. 49, no. 4,
pp. 1761-1790.
url = https://doi.org/10.1111/sjos.12580
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Non-array data

##size of example
set.seed(42)
G &lt;- 10; n &lt;- sample(100:500, G); p &lt;- 60
x &lt;- y &lt;- list()

##group design matrices
for(g in 1:G){x[[g]] &lt;- matrix(rnorm(n[g] * p), n[g], p)}

##common features and effects
common_features &lt;- rbinom(p, 1, 0.1) #sparsity of comm. feat.
common_effects &lt;- rnorm(p) * common_features

##group response
for(g in 1:G){
bg &lt;- rnorm(p, 0, 0.5) * (1 - common_features) + common_effects
mu &lt;- x[[g]] %*% bg
y[[g]] &lt;- rnorm(n[g]) + mu
}

##fit model for range of lambda and zeta
system.time(fit &lt;- softmaximin(x, y, zeta = c(0.1, 1), penalty = "lasso", alg = "npg"))
betahat &lt;- fit$coef

##estimated common effects for specific lambda and zeta
zetano &lt;- 2
modelno &lt;- dim(betahat[[zetano]])[2]
m &lt;- min(betahat[[zetano]][ , modelno], common_effects)
M &lt;- max(betahat[[zetano]][ , modelno], common_effects)
plot(common_effects, type = "p", ylim = c(m, M), col = "red")
lines(betahat[[zetano]][ , modelno], type = "h")

#Array data
##size of example
set.seed(42)
G &lt;- 50; n &lt;- c(30, 20, 10); p &lt;- c(7, 5, 4)

##marginal design matrices (Kronecker components)
x &lt;- list()
for(i in 1:length(n)){x[[i]] &lt;- matrix(rnorm(n[i] * p[i]), n[i], p[i])}

##common features and effects
common_features &lt;- rbinom(prod(p), 1, 0.1) #sparsity of comm. feat.
common_effects &lt;- rnorm(prod(p),0,0.1) * common_features

##group response
 y &lt;- array(NA, c(n, G))
for(g in 1:G){
bg &lt;- rnorm(prod(p), 0, .1) * (1 - common_features) + common_effects
Bg &lt;- array(bg, p)
mu &lt;- RH(x[[3]], RH(x[[2]], RH(x[[1]], Bg)))
y[,,, g] &lt;- array(rnorm(prod(n)), dim = n) + mu
}

##fit model for range of lambda and zeta
system.time(fit &lt;- softmaximin(x, y, zeta = c(1, 10, 100), penalty = "lasso",
            alg = "npg"))
betahat &lt;- fit$coef

##estimated common effects for specific lambda and zeta
zetano &lt;- 1
modelno &lt;- dim(betahat[[zetano]])[2]
m &lt;- min(betahat[[zetano]][, modelno], common_effects)
M &lt;- max(betahat[[zetano]][, modelno], common_effects)
plot(common_effects, type = "p", ylim = c(m, M), col = "red")
lines(betahat[[zetano]][ , modelno], type = "h")

#Array data and wavelets
##size of example
set.seed(42)
G &lt;- 50; p &lt;- n &lt;- c(2^3, 2^4, 2^5);

##common features and effects
common_features &lt;- rbinom(prod(p), 1, 0.1) #sparsity of comm. feat.
common_effects &lt;- rnorm(prod(p), 0, 1) * common_features

##group response
y &lt;- array(NA, c(n, G))
for(g in 1:G){
bg &lt;- rnorm(prod(p), 0, 0.1) * (1 - common_features) + common_effects
Bg &lt;- array(bg, p)
mu &lt;- iwt(Bg)
y[,,, g] &lt;- array(rnorm(prod(n), 0, 0.5), dim = n) + mu
}

##fit model for range of lambda and zeta
system.time(fit &lt;- softmaximin(x = "la8", y, zeta = c(0.1, 1, 10),
                                penalty = "lasso", alg = "fista"))
betahat &lt;- fit$coef

##estimated common effects for specific lambda and zeta
zetano &lt;- 3
modelno &lt;- dim(betahat[[zetano]])[2]
m &lt;- min(betahat[[zetano]][, modelno], common_effects)
M &lt;- max(betahat[[zetano]][, modelno], common_effects)
plot(common_effects, type = "p", ylim = c(m, M), col = "red")
lines(betahat[[zetano]][ , modelno], type = "h")
</code></pre>

<hr>
<h2 id='wt'>Discrete wavelet transform</h2><span id='topic+wt'></span>

<h3>Description</h3>

<p>This function performs a level J wavelet transform of the input
array (1d, 2d, or 3d) using the pyramid algorithm (Mallat 1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wt(x, wf = "la8", J = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wt_+3A_x">x</code></td>
<td>
<p>a 1, 2, or 3 dimensional data array. The size of each dimension must
be dyadic.</p>
</td></tr>
<tr><td><code id="wt_+3A_wf">wf</code></td>
<td>
<p>the type of wavelet family used. See R-package waveslim for options.</p>
</td></tr>
<tr><td><code id="wt_+3A_j">J</code></td>
<td>
<p>is the level (depth) of the decomposition. For default <code>NULL</code> the max
depth is used making  <code>wt(x)</code> equal to multiplying <code>x</code> with the
corresponding wavelet matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a C++/R wrapper function for a C implementation of the
discrete wavelet transform by Brandon Whitcher, Rigorous Analytics Ltd, licensed
under the BSD 3 license https://cran.r-project.org/web/licenses/BSD_3_clause,
see the Waveslim package;
Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001).
</p>
<p>Given a data array (1d, 2d or 3d) with dyadic
sizes this transform is computed efficiently via the pyramid
algorithm see Mallat (1989).
</p>
<p>This functionality is used in the computations underlying <code><a href="#topic+softmaximin">softmaximin</a></code>
to perform multiplications involving the wavelet (design) matrix efficiently.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>...</code></td>
<td>
<p>An array with dimensions equal to those of <code>x</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adam Lund, Brandon Whitcher
</p>


<h3>References</h3>

<p>Gencay, R., F. Selcuk and B. Whitcher (2001) An Introduction to Wavelets and
Other Filtering Methods in Finance and Economics, Academic Press.
</p>
<p>Mallat, S. G. (1989) A theory for multiresolution signal decomposition: the
wavelet representation, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 11, No. 7, 674-693.
</p>
<p>Percival, D. B. and A. T. Walden (2000) Wavelet Methods for Time Series
Analysis, Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###1d
x &lt;- as.matrix(rnorm(2^3))
range(x - iwt(wt(x)))

###2d
x &lt;- matrix(rnorm(2^(3 + 4)), 2^3, 2^4)
range(x - iwt(wt(x)))

###3d
x &lt;- array(rnorm(2^(3 + 4 + 5)), c(2^3, 2^4, 2^5))
range(x - iwt(wt(x)))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
