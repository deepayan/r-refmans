<!DOCTYPE html><html lang="en"><head><title>Help for package tsensembler</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tsensembler}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ADE'><p>Arbitrated Dynamic Ensemble</p></a></li>
<li><a href='#ade_hat'><p>Predictions by an ADE ensemble</p></a></li>
<li><a href='#ade_hat-class'><p>Predictions by an ADE ensemble</p></a></li>
<li><a href='#ADE-class'><p>Arbitrated Dynamic Ensemble</p></a></li>
<li><a href='#ae'><p>Computing the absolute error</p></a></li>
<li><a href='#base_ensemble'><p>base_ensemble</p></a></li>
<li><a href='#base_ensemble-class'><p>base_ensemble-class</p></a></li>
<li><a href='#base_models_loss'><p>Computing the error of base models</p></a></li>
<li><a href='#best_mvr'><p>Get best PLS/PCR model</p></a></li>
<li><a href='#blocked_prequential'><p>Prequential Procedure in Blocks</p></a></li>
<li><a href='#bm_cubist'><p>Fit Cubist models (M5)</p></a></li>
<li><a href='#bm_ffnn'><p>Fit Feedforward Neural Networks models</p></a></li>
<li><a href='#bm_gaussianprocess'><p>Fit Gaussian Process models</p></a></li>
<li><a href='#bm_gbm'><p>Fit Generalized Boosted Regression models</p></a></li>
<li><a href='#bm_glm'><p>Fit Generalized Linear Models</p></a></li>
<li><a href='#bm_mars'><p>Fit Multivariate Adaptive Regression Splines models</p></a></li>
<li><a href='#bm_pls_pcr'><p>Fit PLS/PCR regression models</p></a></li>
<li><a href='#bm_ppr'><p>Fit Projection Pursuit Regression models</p></a></li>
<li><a href='#bm_randomforest'><p>Fit Random Forest models</p></a></li>
<li><a href='#bm_svr'><p>Fit Support Vector Regression models</p></a></li>
<li><a href='#bm_xgb'><p>Base model for XGBoost</p></a></li>
<li><a href='#build_base_ensemble'><p>Wrapper for creating an ensemble</p></a></li>
<li><a href='#build_committee'><p>Building a committee for an ADE model</p></a></li>
<li><a href='#combine_predictions'><p>Combining the predictions of several models</p></a></li>
<li><a href='#compute_predictions'><p>Compute the predictions of base models</p></a></li>
<li><a href='#DETS'><p>Dynamic Ensemble for Time Series</p></a></li>
<li><a href='#dets_hat'><p>Predictions by an DETS ensemble</p></a></li>
<li><a href='#dets_hat-class'><p>Predictions by an DETS ensemble</p></a></li>
<li><a href='#DETS-class'><p>Dynamic Ensemble for Time Series</p></a></li>
<li><a href='#EMASE'><p>Weighting Base Models by their Moving Average Squared Error</p></a></li>
<li><a href='#embed_timeseries'><p>Embedding a Time Series</p></a></li>
<li><a href='#get_target'><p>Get the target from a formula</p></a></li>
<li><a href='#get_top_models'><p>Extract top learners from their weights</p></a></li>
<li><a href='#get_y'><p>Get the response values from a data matrix</p></a></li>
<li><a href='#holdout'><p>Holdout</p></a></li>
<li><a href='#intraining_estimations'><p>Out-of-bag loss estimations</p></a></li>
<li><a href='#intraining_predictions'><p>Out-of-bag predictions</p></a></li>
<li><a href='#l1apply'><p>Applying lapply on the rows</p></a></li>
<li><a href='#learning_base_models'><p>Training the base models of an ensemble</p></a></li>
<li><a href='#loss_meta_learn'><p>Training an arbiter</p></a></li>
<li><a href='#meta_cubist'><p>Training a RBR arbiter</p></a></li>
<li><a href='#meta_cubist_predict'><p>Arbiter predictions via Cubist</p></a></li>
<li><a href='#meta_ffnn'><p>Training a Gaussian prosadacess arbiter</p></a></li>
<li><a href='#meta_ffnn_predict'><p>Arbiter predictions via linear ssmodel</p></a></li>
<li><a href='#meta_gp'><p>Training a Gaussian process arbiter</p></a></li>
<li><a href='#meta_gp_predict'><p>Arbiter predictions via linear model</p></a></li>
<li><a href='#meta_lasso'><p>Training a LASSO arbiter</p></a></li>
<li><a href='#meta_lasso_predict'><p>Arbiter predictions via linear model</p></a></li>
<li><a href='#meta_mars'><p>Training a meta_mars process arbiter</p></a></li>
<li><a href='#meta_mars_predict'><p>Arbiter predictions via mars model</p></a></li>
<li><a href='#meta_pls'><p>Training a pls process arbiter</p></a></li>
<li><a href='#meta_pls_predict'><p>Arbiter predictions via pls model</p></a></li>
<li><a href='#meta_ppr'><p>Training a meta_mars process arbiter</p></a></li>
<li><a href='#meta_ppr_predict'><p>Arbiter predictions via ppr model</p></a></li>
<li><a href='#meta_predict'><p>Predicting loss using arbiter</p></a></li>
<li><a href='#meta_rf'><p>Training a random forest arbiter</p></a></li>
<li><a href='#meta_rf_predict'><p>Arbiter predictions via ranger</p></a></li>
<li><a href='#meta_svr'><p>Training a Gaussian process arbiter</p></a></li>
<li><a href='#meta_svr_predict'><p>Arbiter predictions via linear model</p></a></li>
<li><a href='#meta_xgb'><p>Training a xgb arbiter</p></a></li>
<li><a href='#meta_xgb_predict'><p>Arbiter predictions via xgb</p></a></li>
<li><a href='#model_recent_performance'><p>Recent performance of models using EMASE</p></a></li>
<li><a href='#model_specs'><p>Setup base learning models</p></a></li>
<li><a href='#model_specs-class'><p>Setup base learning models</p></a></li>
<li><a href='#model_weighting'><p>Model weighting</p></a></li>
<li><a href='#mse'><p>Computing the mean squared error</p></a></li>
<li><a href='#normalize'><p>Scale a numeric vector using max-min</p></a></li>
<li><a href='#predict'><p>Predicting new observations using an ensemble</p></a></li>
<li><a href='#predict_pls_pcr'><p>predict method for pls/pcr</p></a></li>
<li><a href='#proportion'><p>Computing the proportions of a numeric vector</p></a></li>
<li><a href='#rbind_l'><p>rbind with do.call syntax</p></a></li>
<li><a href='#recent_lambda_observations'><p>Get most recent lambda observations</p></a></li>
<li><a href='#rmse'><p>Computing the root mean squared error</p></a></li>
<li><a href='#roll_mean_matrix'><p>Computing the rolling mean of the columns of a matrix</p></a></li>
<li><a href='#se'><p>Computing the squared error</p></a></li>
<li><a href='#select_best'><p>Selecting best model according to weights</p></a></li>
<li><a href='#sequential_reweighting'><p>Sequential Re-weighting for controlling predictions' redundancy</p></a></li>
<li><a href='#sliding_similarity'><p>Sliding similarity via Pearson's correlation</p></a></li>
<li><a href='#soft.completion'><p>Soft Imputation</p></a></li>
<li><a href='#softmax'><p>Computing the softmax</p></a></li>
<li><a href='#split_by'><p>Splitting expressions by pattern</p></a></li>
<li><a href='#train_ade'><p>Training procedure of for ADE</p></a></li>
<li><a href='#train_ade_quick'><p>ADE training poor version</p>
Train meta-models in the training data,
as opposed to using a validation dataset</a></li>
<li><a href='#tsensembler'><p>Dynamic Ensembles for Time Series Forecasting</p></a></li>
<li><a href='#update_ade'><p>Updating an ADE model</p></a></li>
<li><a href='#update_ade_meta'><p>Updating the metalearning layer of an ADE model</p></a></li>
<li><a href='#update_base_models'><p>Update the base models of an ensemble</p></a></li>
<li><a href='#update_weights'><p>Updating the weights of base models</p></a></li>
<li><a href='#water_consumption'><p>Water Consumption in Oporto city (Portugal) area.</p></a></li>
<li><a href='#xgb_optimizer'><p>XGB optimizer</p></a></li>
<li><a href='#xgb_predict'><p>XGBoost predict function</p></a></li>
<li><a href='#xgb_predict_'><p>asdasd</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Dynamic Ensembles for Time Series Forecasting</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Vitor Cerqueira [aut, cre],
  Luis Torgo [ctb],
  Carlos Soares [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Vitor Cerqueira &lt;cerqueira.vitormanuel@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A framework for dynamically combining forecasting models for time series forecasting predictive tasks. It leverages machine learning models from other packages to automatically combine expert advice using metalearning and other state-of-the-art forecasting combination approaches. The predictive methods receive a data matrix as input, representing an embedded time series, and return a predictive ensemble model. The ensemble use generic functions 'predict()' and 'forecast()' to forecast future values of the time series. Moreover, an ensemble can be updated using methods, such as 'update_weights()' or 'update_base_models()'. A complete description of the methods can be found in: Cerqueira, V., Torgo, L., Pinto, F., and Soares, C. "Arbitrated Ensemble for Time Series Forecasting." to appear at: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer International Publishing, 2017; and Cerqueira, V., Torgo, L., and Soares, C.: "Arbitrated Ensemble for Solar Radiation Forecasting." International Work-Conference on Artificial Neural Networks. Springer, 2017 &lt;<a href="https://doi.org/10.1007%2F978-3-319-59153-7_62">doi:10.1007/978-3-319-59153-7_62</a>&gt;.</td>
</tr>
<tr>
<td>Imports:</td>
<td>xts, zoo, RcppRoll, methods, ranger, glmnet, earth, kernlab,
Cubist, gbm, pls, monmlp, doParallel, foreach, xgboost,
softImpute</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/vcerqueira/tsensembler">https://github.com/vcerqueira/tsensembler</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-26 09:31:22 UTC; root</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-27 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ADE'>Arbitrated Dynamic Ensemble</h2><span id='topic+ADE'></span><span id='topic+quickADE'></span>

<h3>Description</h3>

<p>Arbitrated Dynamic Ensemble (ADE) is an ensemble approach
for adaptively combining forecasting models. A metalearning
strategy is used that specializes base models
across the time series. Each meta-learner is specifically
designed to model how apt its base counterpart is to make
a prediction for a given test example. This is accomplished
by analysing how the error incurred by a given learning model
relates to the characteristics of the data. At test time,
the base-learners are weighted according to their degree
of competence in the input observation, estimated by the
predictions of the meta-learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ADE(
  form,
  data,
  specs,
  lambda = 50,
  omega = 0.5,
  select_best = FALSE,
  all_models = FALSE,
  aggregation = "linear",
  sequential_reweight = FALSE,
  meta_loss_fun = ae,
  meta_model_type = "randomforest",
  num_cores = 1
)

quickADE(
  form,
  data,
  specs,
  lambda = 50,
  omega = 0.5,
  select_best = FALSE,
  all_models = FALSE,
  aggregation = "linear",
  sequential_reweight = FALSE,
  meta_loss_fun = ae,
  meta_model_type = "randomforest",
  num_cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ADE_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="ADE_+3A_data">data</code></td>
<td>
<p>data to train the base models</p>
</td></tr>
<tr><td><code id="ADE_+3A_specs">specs</code></td>
<td>
<p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains
the parameter setting information for training the
base models;</p>
</td></tr>
<tr><td><code id="ADE_+3A_lambda">lambda</code></td>
<td>
<p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</td></tr>
<tr><td><code id="ADE_+3A_omega">omega</code></td>
<td>
<p>committee ratio size. Essentially, the top <em>omega</em> * 100
percent of models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to .5 according to empirical experiments;</p>
</td></tr>
<tr><td><code id="ADE_+3A_select_best">select_best</code></td>
<td>
<p>Logical. If true, at each prediction time,
a single base model is picked to make a prediction. The picked
model is the one that has the lowest loss prediction from
the meta models. Defaults to FALSE;</p>
</td></tr>
<tr><td><code id="ADE_+3A_all_models">all_models</code></td>
<td>
<p>Logical. If true, at each prediction time,
all base models are picked to make a prediction. The
models are weighted according to their predicted loss
and the <code>aggregation</code> function. Defaults to FALSE;</p>
</td></tr>
<tr><td><code id="ADE_+3A_aggregation">aggregation</code></td>
<td>
<p>Type of aggregation used to combine the
predictions of the base models. The options are:
</p>

<dl>
<dt>softmax</dt><dd><p>default</p>
</dd>
<dt>erfc</dt><dd><p>the complementary Gaussian error function</p>
</dd>
<dt>linear</dt><dd><p>a linear scaling</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="ADE_+3A_sequential_reweight">sequential_reweight</code></td>
<td>
<p>Besides ensemble heterogeneity we encourage diversity
explicitly during the aggregation of the output of experts.
This is achieved by taking into account not only predictions
of performance produced by the arbiters, but also the
correlation among experts in a recent window of observations.</p>
</td></tr>
<tr><td><code id="ADE_+3A_meta_loss_fun">meta_loss_fun</code></td>
<td>
<p>Besides</p>
</td></tr>
<tr><td><code id="ADE_+3A_meta_model_type">meta_model_type</code></td>
<td>
<p>meta model to use &ndash; defaults to random forest</p>
</td></tr>
<tr><td><code id="ADE_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cerqueira, Vitor; Torgo, Luis; Pinto, Fabio;
and Soares, Carlos. &quot;Arbitrated Ensemble for Time Series
Forecasting&quot; to appear at: Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer International
Publishing, 2017.
</p>
<p>V. Cerqueira, L. Torgo, and C. Soares, “Arbitrated ensemble for
solar radiation forecasting,” in International Work-Conference on
Artificial Neural Networks. Springer, Cham, 2017, pp. 720–732
</p>


<h3>See Also</h3>

<p><code><a href="#topic+model_specs-class">model_specs-class</a></code> for setting up the ensemble parameters
for an <strong>ADE</strong> model;
<code><a href="#topic+predict">predict</a></code> for the method that predicts new held out observations;
<code><a href="#topic+update_weights">update_weights</a></code> for the method used to update the
weights of an <strong>ADE</strong> model between successive predict or forecast calls;
<code><a href="#topic+update_ade_meta">update_ade_meta</a></code> for updating (retraining) the meta models
of an <strong>ADE</strong> model; <code><a href="#topic+update_base_models">update_base_models</a></code> for
the updating (retraining) the base models of an <strong>ADE</strong> ensemble (and respective
weights); <code><a href="#topic+ade_hat-class">ade_hat-class</a></code> for the object that results from
predicting with an <strong>ADE</strong> model; and <code><a href="#topic+update_ade">update_ade</a></code> to update an ADE
model, combining functions <strong>update_base_models</strong>, <strong>update_meta_ade</strong>, and
<strong>update_weights</strong>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>specs &lt;- model_specs(
  learner = c("bm_ppr", "bm_glm", "bm_mars"),
  learner_pars = list(
    bm_glm = list(alpha = c(0, .5, 1)),
    bm_svr = list(kernel = c("rbfdot", "polydot"),
                  C = c(1, 3)),
    bm_ppr = list(nterms = 4)
  )
)

data("water_consumption")
train &lt;- embed_timeseries(water_consumption, 5)
train &lt;- train[1:300, ] # toy size for checks

model &lt;- ADE(target ~., train, specs)

</code></pre>

<hr>
<h2 id='ade_hat'>Predictions by an ADE ensemble</h2><span id='topic+ade_hat'></span>

<h3>Description</h3>

<p>Predictions produced by a <code><a href="#topic+ADE-class">ADE-class</a></code> object.
It contains <strong>y_hat</strong>, the combined predictions,
<strong>Y_hat</strong>, the predictions of each base model,
<strong>Y_committee</strong>, the base models used for prediction
at each time point, and <strong>E_hat</strong>, the loss predictions
by each meta-model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ade_hat(y_hat, Y_hat, Y_committee, E_hat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ade_hat_+3A_y_hat">y_hat</code></td>
<td>
<p>combined predictions of the ensemble
<code><a href="#topic+ADE">ADE</a></code>. A numeric vector;</p>
</td></tr>
<tr><td><code id="ade_hat_+3A_y_hat">Y_hat</code></td>
<td>
<p>a matrix containing the predictions made by
individual models;</p>
</td></tr>
<tr><td><code id="ade_hat_+3A_y_committee">Y_committee</code></td>
<td>
<p>a list describing the models selected for
predictions at each time point (according to <strong>lambda</strong>
and <strong>omega</strong>);</p>
</td></tr>
<tr><td><code id="ade_hat_+3A_e_hat">E_hat</code></td>
<td>
<p>predictions of error of each base model, estimated
by their respective meta model associate;</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ADE-class">ADE-class</a></code> for generating an ADE ensemble.
</p>
<p>Other ensemble predictions: 
<code><a href="#topic+ade_hat-class">ade_hat-class</a></code>,
<code><a href="#topic+dets_hat-class">dets_hat-class</a></code>,
<code><a href="#topic+dets_hat">dets_hat</a></code>
</p>

<hr>
<h2 id='ade_hat-class'>Predictions by an ADE ensemble</h2><span id='topic+ade_hat-class'></span>

<h3>Description</h3>

<p>Predictions produced by a <code><a href="#topic+ADE-class">ADE-class</a></code> object.
It contains <strong>y_hat</strong>, the combined predictions,
<strong>Y_hat</strong>, the predictions of each base model,
<strong>Y_committee</strong>, the base models used for prediction
at each time point, and <strong>E_hat</strong>, the loss predictions
by each meta-model.
</p>


<h3>Slots</h3>


<dl>
<dt><code>y_hat</code></dt><dd><p>combined predictions of the ensemble
<code><a href="#topic+ADE-class">ADE-class</a></code>. A numeric vector;</p>
</dd>
<dt><code>Y_hat</code></dt><dd><p>a matrix containing the predictions made by
individual models;</p>
</dd>
<dt><code>Y_committee</code></dt><dd><p>a list describing the models selected for
predictions at each time point (according to <strong>lambda</strong>
and <strong>omega</strong>);</p>
</dd>
<dt><code>E_hat</code></dt><dd><p>predictions of error of each base model, estimated
by their respective meta model associate;</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+ADE">ADE</a></code> for generating an ADE ensemble.
</p>
<p>Other ensemble predictions: 
<code><a href="#topic+ade_hat">ade_hat</a></code>,
<code><a href="#topic+dets_hat-class">dets_hat-class</a></code>,
<code><a href="#topic+dets_hat">dets_hat</a></code>
</p>

<hr>
<h2 id='ADE-class'>Arbitrated Dynamic Ensemble</h2><span id='topic+ADE-class'></span>

<h3>Description</h3>

<p>Arbitrated Dynamic Ensemble (ADE) is an ensemble approach
for adaptively combining forecasting models. A metalearning
strategy is used that specializes base models
across the time series. Each meta-learner is specifically
designed to model how apt its base counterpart is to make
a prediction for a given test example. This is accomplished
by analysing how the error incurred by a given learning model
relates to the characteristics of the data. At test time,
the base-learners are weighted according to their degree
of competence in the input observation, estimated by the
predictions of the meta-learners.
</p>


<h3>Slots</h3>


<dl>
<dt><code>base_ensemble</code></dt><dd><p>object of class <code><a href="#topic+base_ensemble-class">base_ensemble-class</a></code>.
It contains the base models used that can be used for predicting
new data or forecasting future values;</p>
</dd>
<dt><code>meta_model</code></dt><dd><p>a list containing the meta models, one for
each base model. The meta-models are random forests;</p>
</dd>
<dt><code>form</code></dt><dd><p>formula;</p>
</dd>
<dt><code>specs</code></dt><dd><p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains
the parameter setting information for training the
base models;</p>
</dd>
<dt><code>lambda</code></dt><dd><p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</dd>
<dt><code>omega</code></dt><dd><p>committee ratio size. Essentially, the top <em>omega</em> * 100
percent of models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to .5 according to empirical experiments;</p>
</dd>
<dt><code>select_best</code></dt><dd><p>Logical. If true, at each prediction time,
a single base model is picked to make a prediction. The picked
model is the one that has the lowest loss prediction from
the meta models. Defaults to FALSE;</p>
</dd>
<dt><code>all_models</code></dt><dd><p>Logical. If true, at each prediction time,
all base models are picked to make a prediction. The
models are weighted according to their predicted loss
and the <code>aggregation</code> function. Defaults to FALSE;</p>
</dd>
<dt><code>aggregation</code></dt><dd><p>Type of aggregation used to combine the
predictions of the base models. The options are:
</p>

<dl>
<dt>softmax</dt><dd><p>default</p>
</dd>
<dt>erfc</dt><dd><p>the complementary Gaussian error function</p>
</dd>
<dt>linear</dt><dd><p>a linear scaling</p>
</dd>
</dl>
</dd>
<dt><code>sequential_reweight</code></dt><dd><p>Besides ensemble heterogeneity we encourage diversity
explicitly during the aggregation of the output of experts.
This is achieved by taking into account not only predictions
of performance produced by the arbiters, but also the
correlation among experts in a recent window of observations.</p>
</dd>
<dt><code>recent_series</code></dt><dd><p>the most recent <code>lambda</code> observations.</p>
</dd>
<dt><code>out_of_bag</code></dt><dd><p>Out of bag observations used to train arbiters.</p>
</dd>
<dt><code>meta_model_type</code></dt><dd><p>meta model to use &ndash; defaults to random forest</p>
</dd>
</dl>


<h3>References</h3>

<p>Cerqueira, Vitor; Torgo, Luis; Pinto, Fabio;
and Soares, Carlos. &quot;Arbitrated Ensemble for Time Series
Forecasting&quot; to appear at: Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer International
Publishing, 2017.
</p>
<p>V. Cerqueira, L. Torgo, and C. Soares, “Arbitrated ensemble for
solar radiation forecasting,” in International Work-Conference on
Artificial Neural Networks. Springer, Cham, 2017, pp. 720–732
</p>


<h3>See Also</h3>

<p><code><a href="#topic+model_specs-class">model_specs-class</a></code> for setting up the ensemble parameters
for an <strong>ADE</strong> model;
<code><a href="#topic+predict">predict</a></code> for the method that predicts new held out observations;
<code><a href="#topic+update_weights">update_weights</a></code> for the method used to update the
weights of an <strong>ADE</strong> model between successive predict or forecast calls;
<code><a href="#topic+update_ade_meta">update_ade_meta</a></code> for updating (retraining) the meta models
of an <strong>ADE</strong> model; <code><a href="#topic+update_base_models">update_base_models</a></code> for
the updating (retraining) the base models of an <strong>ADE</strong> ensemble (and respective
weights); <code><a href="#topic+ade_hat-class">ade_hat-class</a></code> for the object that results from
predicting with an <strong>ADE</strong> model; and <code><a href="#topic+update_ade">update_ade</a></code> to update an ADE
model, combining functions <strong>update_base_models</strong>, <strong>update_meta_ade</strong>, and
<strong>update_weights</strong>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>specs &lt;- model_specs(
  learner = c("bm_ppr", "bm_glm", "bm_mars"),
  learner_pars = list(
    bm_glm = list(alpha = c(0, .5, 1)),
    bm_svr = list(kernel = c("rbfdot", "polydot"),
                  C = c(1, 3)),
    bm_ppr = list(nterms = 4)
  )
)

data("water_consumption")
train &lt;- embed_timeseries(water_consumption, 5)
train &lt;- train[1:300, ] # toy size for checks

model &lt;- ADE(target ~., train, specs)

</code></pre>

<hr>
<h2 id='ae'>Computing the absolute error</h2><span id='topic+ae'></span>

<h3>Description</h3>

<p>Element-wise computation of the absolute error loss function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ae(y, y_hat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ae_+3A_y">y</code></td>
<td>
<p>A numeric vector representing the actual values.</p>
</td></tr>
<tr><td><code id="ae_+3A_y_hat">y_hat</code></td>
<td>
<p>A numeric vector representing the forecasted values.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other error/performance functions: 
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+se">se</a>()</code>
</p>

<hr>
<h2 id='base_ensemble'>base_ensemble</h2><span id='topic+base_ensemble'></span>

<h3>Description</h3>

<p><strong>base_ensemble</strong> is a S4 class that contains the base models
comprising the ensemble. Besides the base learning algorithms &ndash;
<code>base_models</code> &ndash; base_ensemble class contains information
about other meta-data used to compute predictions for new upcoming data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>base_ensemble(base_models, pre_weights, form, colnames)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="base_ensemble_+3A_base_models">base_models</code></td>
<td>
<p>a list comprising the base models;</p>
</td></tr>
<tr><td><code id="base_ensemble_+3A_pre_weights">pre_weights</code></td>
<td>
<p>normalized relative weights of the base learners according to
their performance on the available data;</p>
</td></tr>
<tr><td><code id="base_ensemble_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="base_ensemble_+3A_colnames">colnames</code></td>
<td>
<p>names of the columns of the data used to train the <strong>base_models</strong>;</p>
</td></tr>
</table>

<hr>
<h2 id='base_ensemble-class'>base_ensemble-class</h2><span id='topic+base_ensemble-class'></span>

<h3>Description</h3>

<p><strong>base_ensemble</strong> is a S4 class that contains the base models
comprising the ensemble. Besides the base learning algorithms &ndash;
<code>base_models</code> &ndash; base_ensemble class contains information
about other meta-data used to compute predictions for new upcoming data.
</p>


<h3>Slots</h3>


<dl>
<dt><code>base_models</code></dt><dd><p>a list comprising the base models;</p>
</dd>
<dt><code>pre_weights</code></dt><dd><p>Normalized relative weights of the base learners according to
their performance on the available data;</p>
</dd>
<dt><code>form</code></dt><dd><p>formula;</p>
</dd>
<dt><code>colnames</code></dt><dd><p>names of the columns of the data used to train the <strong>base_models</strong>;</p>
</dd>
<dt><code>N</code></dt><dd><p>number of base models;</p>
</dd>
<dt><code>model_distribution</code></dt><dd><p>base learner distribution with respect to the type of learner.
That is, the number of Decision Trees, SVMs, etc.</p>
</dd>
</dl>

<hr>
<h2 id='base_models_loss'>Computing the error of base models</h2><span id='topic+base_models_loss'></span>

<h3>Description</h3>

<p>Computing the error of base models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>base_models_loss(Y_hat, Y, lfun = se)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="base_models_loss_+3A_y_hat">Y_hat</code></td>
<td>
<p>predictions of the base models (&quot;@Y_hat&quot; slot)
from <code><a href="#topic+base_ensemble-class">base_ensemble-class</a></code> object;</p>
</td></tr>
<tr><td><code id="base_models_loss_+3A_y">Y</code></td>
<td>
<p>true values from the time series;</p>
</td></tr>
<tr><td><code id="base_models_loss_+3A_lfun">lfun</code></td>
<td>
<p>loss function to compute. Defaults to <code>ae</code>, absolute
error</p>
</td></tr>
</table>

<hr>
<h2 id='best_mvr'>Get best PLS/PCR model</h2><span id='topic+best_mvr'></span>

<h3>Description</h3>

<p>Get best PLS/PCR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>best_mvr(obj, form, validation_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="best_mvr_+3A_obj">obj</code></td>
<td>
<p>PLS/PCR model object</p>
</td></tr>
<tr><td><code id="best_mvr_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="best_mvr_+3A_validation_data">validation_data</code></td>
<td>
<p>validation data used for
predicting performances of the model by number
of principal components</p>
</td></tr>
</table>

<hr>
<h2 id='blocked_prequential'>Prequential Procedure in Blocks</h2><span id='topic+blocked_prequential'></span>

<h3>Description</h3>

<p>Prequential Procedure in Blocks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blocked_prequential(x, nfolds, FUN, .rbind = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blocked_prequential_+3A_x">x</code></td>
<td>
<p>data to split into <code>nfolds</code> blocks;</p>
</td></tr>
<tr><td><code id="blocked_prequential_+3A_nfolds">nfolds</code></td>
<td>
<p>number of blocks to split data into;</p>
</td></tr>
<tr><td><code id="blocked_prequential_+3A_fun">FUN</code></td>
<td>
<p>to apply to train/test;</p>
</td></tr>
<tr><td><code id="blocked_prequential_+3A_.rbind">.rbind</code></td>
<td>
<p>logical. If TRUE, the results from
FUN are <strong>rbind</strong>ed;</p>
</td></tr>
<tr><td><code id="blocked_prequential_+3A_...">...</code></td>
<td>
<p>further parameters to FUN</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+intraining_estimations">intraining_estimations</a></code>
function to use as <strong>FUN</strong> parameter.
</p>

<hr>
<h2 id='bm_cubist'>Fit Cubist models (M5)</h2><span id='topic+bm_cubist'></span>

<h3>Description</h3>

<p>Learning a M5 model from training data
Parameter setting can vary in <strong>committees</strong>
and <strong>neighbors</strong> parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_cubist(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_cubist_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_cubist_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_cubist_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="Cubist.html#topic+cubist">cubist</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>Cubist</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_ffnn'>Fit Feedforward Neural Networks models</h2><span id='topic+bm_ffnn'></span>

<h3>Description</h3>

<p>Learning a Feedforward Neural Network
model from training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_ffnn(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_ffnn_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_ffnn_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_ffnn_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter setting can vary in <strong>size</strong>, <strong>maxit</strong>,
and <strong>decay</strong> parameters.
</p>
<p>See <code><a href="nnet.html#topic+nnet">nnet</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>nnet</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_gaussianprocess'>Fit Gaussian Process models</h2><span id='topic+bm_gaussianprocess'></span>

<h3>Description</h3>

<p>Learning a Gaussian Process model from training
data. Parameter setting can vary in <strong>kernel</strong>
and <strong>tolerance</strong>. See <code><a href="kernlab.html#topic+gausspr">gausspr</a></code>
for a comprehensive description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_gaussianprocess(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_gaussianprocess_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_gaussianprocess_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_gaussianprocess_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Imports learning procedure from <strong>kernlab</strong> package.
</p>


<h3>Value</h3>

<p>A list containing Gaussian Processes models
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_gbm'>Fit Generalized Boosted Regression models</h2><span id='topic+bm_gbm'></span>

<h3>Description</h3>

<p>Learning a Boosted Tree Model
from training data. Parameter setting
can vary in <strong>interaction.depth</strong>,
<strong>n.trees</strong>, and <strong>shrinkage</strong>
parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_gbm(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_gbm_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_gbm_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_gbm_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="gbm.html#topic+gbm">gbm</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>gbm</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_glm'>Fit Generalized Linear Models</h2><span id='topic+bm_glm'></span>

<h3>Description</h3>

<p>Learning a Generalized Linear Model
from training data. Parameter setting
can vary in <strong>alpha</strong>.
See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> for a comprehensive description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_glm(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_glm_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_glm_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_glm_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Imports learning procedure from <strong>glmnet</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_mars'>Fit Multivariate Adaptive Regression Splines models</h2><span id='topic+bm_mars'></span>

<h3>Description</h3>

<p>Learning a Multivariate Adaptive Regression Splines
model from training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_mars(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_mars_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_mars_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_mars_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter setting can vary in <strong>nk</strong>,
<strong>degree</strong>, and <strong>thresh</strong> parameters.
</p>
<p>See <code><a href="earth.html#topic+earth">earth</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>earth</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_pls_pcr'>Fit PLS/PCR regression models</h2><span id='topic+bm_pls_pcr'></span>

<h3>Description</h3>

<p>Learning aPartial Least Squares or
Principal Components Regression from training data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_pls_pcr(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_pls_pcr_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_pls_pcr_+3A_data">data</code></td>
<td>
<p>data to train the model</p>
</td></tr>
<tr><td><code id="bm_pls_pcr_+3A_lpars">lpars</code></td>
<td>
<p>parameter setting: For this multivariate regression
model the main parameter is &quot;method&quot;. The available options are
&quot;kernelpls&quot;, &quot;svdpc&quot;, &quot;cppls&quot;, &quot;widekernelpls&quot;, and &quot;simpls&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter setting can vary in <strong>method</strong>
</p>
<p>See <code><a href="pls.html#topic+mvr">mvr</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>pls</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_ppr'>Fit Projection Pursuit Regression models</h2><span id='topic+bm_ppr'></span>

<h3>Description</h3>

<p>Learning a Projection Pursuit Regression
model from training data. Parameter setting
can vary in <strong>nterms</strong> and <strong>sm.method</strong>
parameters. See <code><a href="stats.html#topic+ppr">ppr</a></code> for a comprehensive description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_ppr(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_ppr_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_ppr_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_ppr_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Imports learning procedure from <strong>stats</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_randomforest'>Fit Random Forest models</h2><span id='topic+bm_randomforest'></span>

<h3>Description</h3>

<p>Learning a Random Forest Model
from training data. Parameter setting
can vary in <strong>num.trees</strong> and <strong>mtry</strong>
parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_randomforest(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_randomforest_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_randomforest_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_randomforest_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="ranger.html#topic+ranger">ranger</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>ranger</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_svr">bm_svr</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_svr">bm_svr</a>()</code>
</p>

<hr>
<h2 id='bm_svr'>Fit Support Vector Regression models</h2><span id='topic+bm_svr'></span>

<h3>Description</h3>

<p>Learning a Support Vector Regression
model from training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_svr(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_svr_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_svr_+3A_data">data</code></td>
<td>
<p>training data for building the predictive
model</p>
</td></tr>
<tr><td><code id="bm_svr_+3A_lpars">lpars</code></td>
<td>
<p>a list containing the learning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter setting can vary in <strong>kernel</strong>,
<strong>C</strong>, and <strong>epsilon</strong> parameters.
</p>
<p>See <code><a href="kernlab.html#topic+ksvm">ksvm</a></code> for a comprehensive description.
</p>
<p>Imports learning procedure from <strong>kernlab</strong> package.
</p>


<h3>See Also</h3>

<p>other learning models: <code><a href="#topic+bm_mars">bm_mars</a></code>;
<code><a href="#topic+bm_ppr">bm_ppr</a></code>; <code><a href="#topic+bm_gbm">bm_gbm</a></code>;
<code><a href="#topic+bm_glm">bm_glm</a></code>; <code><a href="#topic+bm_cubist">bm_cubist</a></code>;
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code>; <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>;
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code>; <code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code>
</p>
<p>Other base learning models: 
<code><a href="#topic+bm_cubist">bm_cubist</a>()</code>,
<code><a href="#topic+bm_ffnn">bm_ffnn</a>()</code>,
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a>()</code>,
<code><a href="#topic+bm_gbm">bm_gbm</a>()</code>,
<code><a href="#topic+bm_glm">bm_glm</a>()</code>,
<code><a href="#topic+bm_mars">bm_mars</a>()</code>,
<code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a>()</code>,
<code><a href="#topic+bm_ppr">bm_ppr</a>()</code>,
<code><a href="#topic+bm_randomforest">bm_randomforest</a>()</code>
</p>

<hr>
<h2 id='bm_xgb'>Base model for XGBoost</h2><span id='topic+bm_xgb'></span>

<h3>Description</h3>

<p>Base model for XGBoost
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bm_xgb(form, data, lpars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bm_xgb_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bm_xgb_+3A_data">data</code></td>
<td>
<p>Training data</p>
</td></tr>
<tr><td><code id="bm_xgb_+3A_lpars">lpars</code></td>
<td>
<p>list of parameters&ndash;deprecated</p>
</td></tr>
</table>

<hr>
<h2 id='build_base_ensemble'>Wrapper for creating an ensemble</h2><span id='topic+build_base_ensemble'></span>

<h3>Description</h3>

<p>Using the parameter specifications from
<code><a href="#topic+model_specs-class">model_specs-class</a></code>, this function trains
a set of regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_base_ensemble(form, data, specs, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build_base_ensemble_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="build_base_ensemble_+3A_data">data</code></td>
<td>
<p>data.frame for training the predictive models;</p>
</td></tr>
<tr><td><code id="build_base_ensemble_+3A_specs">specs</code></td>
<td>
<p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains the information
about the parameter setting of the models to train.</p>
</td></tr>
<tr><td><code id="build_base_ensemble_+3A_num_cores">num_cores</code></td>
<td>
<p>number of cores</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S4 class with the following slots:
<strong>base_models</strong>, a list containing the trained models;
<strong>pre_weights</strong>, a numeric vector describing the weights
of the base models according to their performance in the training
data; and <strong>colnames</strong>, the column names of the data, used for
reference.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
specs &lt;- model_specs(c("bm_ppr","bm_svr"), NULL)
M &lt;- build_base_ensemble(target ~., dataset, specs, 1)

</code></pre>

<hr>
<h2 id='build_committee'>Building a committee for an ADE model</h2><span id='topic+build_committee'></span>

<h3>Description</h3>

<p>Building a committee for an ADE model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_committee(Y_hat, Y, lambda, omega)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build_committee_+3A_y_hat">Y_hat</code></td>
<td>
<p>A data.frame containing the predictions
of base models;</p>
</td></tr>
<tr><td><code id="build_committee_+3A_y">Y</code></td>
<td>
<p>True values of the time interval for
which to compute the committee;</p>
</td></tr>
<tr><td><code id="build_committee_+3A_lambda">lambda</code></td>
<td>
<p>Window size. Number of observations to take into
account to build the committee;</p>
</td></tr>
<tr><td><code id="build_committee_+3A_omega">omega</code></td>
<td>
<p>Committee ratio &ndash; ratio of models to dynamically weight
across the data;</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other weighting base models: 
<code><a href="#topic+EMASE">EMASE</a>()</code>,
<code><a href="#topic+get_top_models">get_top_models</a>()</code>,
<code><a href="#topic+model_recent_performance">model_recent_performance</a>()</code>,
<code><a href="#topic+model_weighting">model_weighting</a>()</code>,
<code><a href="#topic+select_best">select_best</a>()</code>
</p>

<hr>
<h2 id='combine_predictions'>Combining the predictions of several models</h2><span id='topic+combine_predictions'></span>

<h3>Description</h3>

<p>This function simply applies a weighted average,
where the predictions of the base models <strong>Y_hat</strong>
are weighted according to their weights <strong>W</strong>. If
a <strong>committee</strong> is specified, only models in the committee are
weighted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_predictions(Y_hat, W, committee = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combine_predictions_+3A_y_hat">Y_hat</code></td>
<td>
<p>a data.frame with the predictions of the
base models;</p>
</td></tr>
<tr><td><code id="combine_predictions_+3A_w">W</code></td>
<td>
<p>a matrix or data.frame with the weights of the
base models;</p>
</td></tr>
<tr><td><code id="combine_predictions_+3A_committee">committee</code></td>
<td>
<p>A list containing the ids of the models in the
committee.</p>
</td></tr>
</table>

<hr>
<h2 id='compute_predictions'>Compute the predictions of base models</h2><span id='topic+compute_predictions'></span>

<h3>Description</h3>

<p>This function is used to predict new observations
using the predictive models comprising an ensemble.
It calls on the respective method based on the type of
model, and returns the predictions as a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_predictions(M, form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_predictions_+3A_m">M</code></td>
<td>
<p>list of base models;</p>
</td></tr>
<tr><td><code id="compute_predictions_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="compute_predictions_+3A_data">data</code></td>
<td>
<p>new data to predict;</p>
</td></tr>
</table>

<hr>
<h2 id='DETS'>Dynamic Ensemble for Time Series</h2><span id='topic+DETS'></span>

<h3>Description</h3>

<p>A Dynamic Ensemble for Time Series (DETS). The DETS ensemble
method we present settles on individually pre-trained models
which are dynamically combined at run-time to make a prediction.
The combination rule is reactive to changes in the environment,
rendering an online combined model. The main properties of the ensemble
are:
</p>

<dl>
<dt>heterogeneity</dt><dd><p>Heterogeneous ensembles are those
comprised of different types of base learners. By employing
models that follow different learning strategies, use different
features and/or data observations we expect that individual
learners will disagree with each other, introducing a natural
diversity into the ensemble that helps in handling different
dynamic regimes in a time series forecasting setting;</p>
</dd>
<dt>responsiveness</dt><dd><p>We promote greater responsiveness of
heterogeneous ensembles in time series tasks by making the
aggregation of their members' predictions time-dependent.
By tracking the loss of each learner over time, we weigh
the predictions of individual learners according to their
recent performance using a non-linear function. This strategy
may be advantageous for better detecting regime changes and
also to quickly adapt the ensemble to new regimes.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>DETS(
  form,
  data,
  specs,
  lambda = 50,
  omega = 0.5,
  select_best = FALSE,
  num_cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DETS_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="DETS_+3A_data">data</code></td>
<td>
<p>data frame to train the base models;</p>
</td></tr>
<tr><td><code id="DETS_+3A_specs">specs</code></td>
<td>
<p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains
the parameter setting information for training the
base models;</p>
</td></tr>
<tr><td><code id="DETS_+3A_lambda">lambda</code></td>
<td>
<p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</td></tr>
<tr><td><code id="DETS_+3A_omega">omega</code></td>
<td>
<p>committee ratio size. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to .5 according to empirical experiments;</p>
</td></tr>
<tr><td><code id="DETS_+3A_select_best">select_best</code></td>
<td>
<p>Logical. If true, at each prediction time,
a single base model is picked to make a prediction. The picked
model is the one that has the lowest loss prediction from
the meta models. Defaults to FALSE;</p>
</td></tr>
<tr><td><code id="DETS_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cerqueira, Vitor; Torgo, Luis; Oliveira, Mariana,
and Bernhard Pfahringer. &quot;Dynamic and Heterogeneous Ensembles
for Time Series Forecasting.&quot; Data Science and Advanced
Analytics (DSAA), 2017 IEEE International Conference on. IEEE, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+model_specs-class">model_specs-class</a></code> for setting up the ensemble parameters
for an <strong>DETS</strong> model;
<code><a href="#topic+predict">predict</a></code> for the method that predicts new held out observations;
<code><a href="#topic+update_weights">update_weights</a></code> for the method used to update the
weights of an <strong>DETS</strong> model between successive predict or forecast calls;
<code><a href="#topic+update_base_models">update_base_models</a></code> for the updating (retraining)
the base models of an <strong>DETS</strong> ensemble (and respective
weights); and <code><a href="#topic+dets_hat-class">dets_hat-class</a></code> for the object that results from
predicting with an <strong>DETS</strong> model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>specs &lt;- model_specs(
 c("bm_ppr", "bm_svr"),
 list(bm_ppr = list(nterms = c(2, 4)),
      bm_svr = list(kernel = c("vanilladot", "polydot"), C = c(1,5)))
)

data("water_consumption");
train &lt;- embed_timeseries(water_consumption, 5);

model &lt;- DETS(target ~., train, specs, lambda = 30, omega = .2)

</code></pre>

<hr>
<h2 id='dets_hat'>Predictions by an DETS ensemble</h2><span id='topic+dets_hat'></span>

<h3>Description</h3>

<p>Predictions by an DETS ensemble
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dets_hat(y_hat, Y_hat, Y_committee, W)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dets_hat_+3A_y_hat">y_hat</code></td>
<td>
<p>combined predictions of the ensemble
<code><a href="#topic+DETS">DETS</a></code>. A numeric vector;</p>
</td></tr>
<tr><td><code id="dets_hat_+3A_y_hat">Y_hat</code></td>
<td>
<p>a matrix containing the predictions made by
individual models;</p>
</td></tr>
<tr><td><code id="dets_hat_+3A_y_committee">Y_committee</code></td>
<td>
<p>a list describing the models selected for
predictions at each time point (according to <strong>lambda</strong>
and <strong>omega</strong>);</p>
</td></tr>
<tr><td><code id="dets_hat_+3A_w">W</code></td>
<td>
<p>a matrix with the weights of the base models at each prediction
time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of results from predicting with a <code>DETS</code>
ensemble
</p>


<h3>See Also</h3>

<p>Other ensemble predictions: 
<code><a href="#topic+ade_hat-class">ade_hat-class</a></code>,
<code><a href="#topic+ade_hat">ade_hat</a></code>,
<code><a href="#topic+dets_hat-class">dets_hat-class</a></code>
</p>

<hr>
<h2 id='dets_hat-class'>Predictions by an DETS ensemble</h2><span id='topic+dets_hat-class'></span>

<h3>Description</h3>

<p>Predictions by an DETS ensemble
</p>


<h3>Slots</h3>


<dl>
<dt><code>y_hat</code></dt><dd><p>combined predictions of the ensemble
<code><a href="#topic+DETS-class">DETS-class</a></code>. A numeric vector;</p>
</dd>
<dt><code>Y_hat</code></dt><dd><p>a matrix containing the predictions made by
individual models;</p>
</dd>
<dt><code>Y_committee</code></dt><dd><p>a list describing the models selected for
predictions at each time point (according to <strong>lambda</strong>
and <strong>omega</strong>);</p>
</dd>
<dt><code>W</code></dt><dd><p>a matrix with the weights of the base models at each prediction
time.</p>
</dd>
</dl>


<h3>See Also</h3>

<p>Other ensemble predictions: 
<code><a href="#topic+ade_hat-class">ade_hat-class</a></code>,
<code><a href="#topic+ade_hat">ade_hat</a></code>,
<code><a href="#topic+dets_hat">dets_hat</a></code>
</p>

<hr>
<h2 id='DETS-class'>Dynamic Ensemble for Time Series</h2><span id='topic+DETS-class'></span>

<h3>Description</h3>

<p>A Dynamic Ensemble for Time Series (DETS). The DETS ensemble
method we present settles on individually pre-trained models
which are dynamically combined at run-time to make a prediction.
The combination rule is reactive to changes in the environment,
rendering an online combined model. The main properties of the ensemble
are:
</p>

<dl>
<dt>heterogeneity</dt><dd><p>Heterogeneous ensembles are those
comprised of different types of base learners. By employing
models that follow different learning strategies, use different
features and/or data observations we expect that individual
learners will disagree with each other, introducing a natural
diversity into the ensemble that helps in handling different
dynamic regimes in a time series forecasting setting;</p>
</dd>
<dt>responsiveness</dt><dd><p>We promote greater responsiveness of
heterogeneous ensembles in time series tasks by making the
aggregation of their members' predictions time-dependent.
By tracking the loss of each learner over time, we weigh
the predictions of individual learners according to their
recent performance using a non-linear function. This strategy
may be advantageous for better detecting regime changes and
also to quickly adapt the ensemble to new regimes.</p>
</dd>
</dl>



<h3>Slots</h3>


<dl>
<dt><code>base_ensemble</code></dt><dd><p>object of class <code><a href="#topic+base_ensemble-class">base_ensemble-class</a></code>.
It contains the base models used that can be used for predicting
new data or forecasting future values;</p>
</dd>
<dt><code>form</code></dt><dd><p>formula;</p>
</dd>
<dt><code>specs</code></dt><dd><p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains
the parameter setting information for training the
base models;</p>
</dd>
<dt><code>lambda</code></dt><dd><p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</dd>
<dt><code>omega</code></dt><dd><p>committee ratio size. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to .5 according to empirical experiments;</p>
</dd>
<dt><code>select_best</code></dt><dd><p>Logical. If true, at each prediction time,
a single base model is picked to make a prediction. The picked
model is the one that has the lowest loss prediction from
the meta models. Defaults to FALSE;</p>
</dd>
<dt><code>recent_series</code></dt><dd><p>the most recent <code>lambda</code> observations.</p>
</dd>
</dl>


<h3>References</h3>

<p>Cerqueira, Vitor; Torgo, Luis; Oliveira, Mariana,
and Bernhard Pfahringer. &quot;Dynamic and Heterogeneous Ensembles
for Time Series Forecasting.&quot; Data Science and Advanced
Analytics (DSAA), 2017 IEEE International Conference on. IEEE, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+model_specs-class">model_specs-class</a></code> for setting up the ensemble parameters
for an <strong>DETS</strong> model;
<code><a href="#topic+predict">predict</a></code> for the method that predicts new held out observations;
<code><a href="#topic+update_weights">update_weights</a></code> for the method used to update the
weights of an <strong>DETS</strong> model between successive predict or forecast calls;
<code><a href="#topic+update_base_models">update_base_models</a></code> for the updating (retraining)
the base models of an <strong>DETS</strong> ensemble (and respective
weights); and <code><a href="#topic+dets_hat-class">dets_hat-class</a></code> for the object that results from
predicting with an <strong>DETS</strong> model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>specs &lt;- model_specs(
 c("bm_ppr", "bm_svr"),
 list(bm_ppr = list(nterms = c(2, 4)),
      bm_svr = list(kernel = c("vanilladot"), C = c(1,5)))
)

data("water_consumption")
train &lt;- embed_timeseries(water_consumption, 5)[1:500,]

model &lt;- DETS(target ~., train, specs, lambda = 30, omega = .2)

</code></pre>

<hr>
<h2 id='EMASE'>Weighting Base Models by their Moving Average Squared Error</h2><span id='topic+EMASE'></span>

<h3>Description</h3>

<p>This function computes the weights of the learning models
using the Moving Average Squared Error (MASE) function
This method provides a simple way to quantify the recent
performance of each base learner and adapt the combined
model accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMASE(loss, lambda, pre_weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMASE_+3A_loss">loss</code></td>
<td>
<p>Squared error of the models at each test point;</p>
</td></tr>
<tr><td><code id="EMASE_+3A_lambda">lambda</code></td>
<td>
<p>Number of periods to average over when computing MASE;</p>
</td></tr>
<tr><td><code id="EMASE_+3A_pre_weights">pre_weights</code></td>
<td>
<p>pre-weights of the base models computed in the
train set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The weights of the models in test time.
</p>


<h3>See Also</h3>

<p>Other weighting base models: 
<code><a href="#topic+build_committee">build_committee</a>()</code>,
<code><a href="#topic+get_top_models">get_top_models</a>()</code>,
<code><a href="#topic+model_recent_performance">model_recent_performance</a>()</code>,
<code><a href="#topic+model_weighting">model_weighting</a>()</code>,
<code><a href="#topic+select_best">select_best</a>()</code>
</p>

<hr>
<h2 id='embed_timeseries'>Embedding a Time Series</h2><span id='topic+embed_timeseries'></span>

<h3>Description</h3>

<p>This function embeds a time series into an Euclidean space.
This implementation is based on the function <code>embed</code> of
<strong>stats</strong> package and has theoretical backgroung on
reconstruction of attractors (see Takens, 1981).
This shape transformation of the series allows for
the use of any regression tool available to learn
the time series. The assumption is that there are no long-term
dependencies in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_timeseries(timeseries, embedding.dimension)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_timeseries_+3A_timeseries">timeseries</code></td>
<td>
<p>a time series of class \&quot;xts\&quot;.</p>
</td></tr>
<tr><td><code id="embed_timeseries_+3A_embedding.dimension">embedding.dimension</code></td>
<td>
<p>an integer specifying the embedding dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An embedded time series
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+embed">embed</a></code> for the details of the embedding procedure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(xts)
ts &lt;- as.xts(rnorm(100L), order.by = Sys.Date() + rnorm(100L))
embedded.ts &lt;- embed.timeseries(ts, 20L)

## End(Not run)

</code></pre>

<hr>
<h2 id='get_target'>Get the target from a formula</h2><span id='topic+get_target'></span>

<h3>Description</h3>

<p>Get the target from a formula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_target(form)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_target_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the target variable as character
</p>

<hr>
<h2 id='get_top_models'>Extract top learners from their weights</h2><span id='topic+get_top_models'></span>

<h3>Description</h3>

<p>This function extracts the top learners at each test point
from a score matrix, according to the committee ratio <strong>omega</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_top_models(scores, omega)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_top_models_+3A_scores">scores</code></td>
<td>
<p>data frame containing the weights;</p>
</td></tr>
<tr><td><code id="get_top_models_+3A_omega">omega</code></td>
<td>
<p>committee ratio of top base learners</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the top base models
</p>


<h3>See Also</h3>

<p>Other weighting base models: 
<code><a href="#topic+EMASE">EMASE</a>()</code>,
<code><a href="#topic+build_committee">build_committee</a>()</code>,
<code><a href="#topic+model_recent_performance">model_recent_performance</a>()</code>,
<code><a href="#topic+model_weighting">model_weighting</a>()</code>,
<code><a href="#topic+select_best">select_best</a>()</code>
</p>

<hr>
<h2 id='get_y'>Get the response values from a data matrix</h2><span id='topic+get_y'></span>

<h3>Description</h3>

<p>Given a formula and a data set, <code>get_y</code> function retrieves
the response values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_y(data, form)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_y_+3A_data">data</code></td>
<td>
<p>data set with the response values;</p>
</td></tr>
<tr><td><code id="get_y_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
</table>

<hr>
<h2 id='holdout'>Holdout</h2><span id='topic+holdout'></span>

<h3>Description</h3>

<p>Holdout
</p>


<h3>Usage</h3>

<pre><code class='language-R'>holdout(x, beta, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="holdout_+3A_x">x</code></td>
<td>
<p>data to split into <code>nfolds</code> blocks;</p>
</td></tr>
<tr><td><code id="holdout_+3A_beta">beta</code></td>
<td>
<p>ratio of observations for training</p>
</td></tr>
<tr><td><code id="holdout_+3A_fun">FUN</code></td>
<td>
<p>function to apply to train/test split</p>
</td></tr>
<tr><td><code id="holdout_+3A_...">...</code></td>
<td>
<p>further arguments to FUN</p>
</td></tr>
</table>

<hr>
<h2 id='intraining_estimations'>Out-of-bag loss estimations</h2><span id='topic+intraining_estimations'></span>

<h3>Description</h3>

<p>A pipeline for retrieving out-of-bag loss estimations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intraining_estimations(train, test, form, specs, lfun, num_cores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intraining_estimations_+3A_train">train</code></td>
<td>
<p>train set from the training set;</p>
</td></tr>
<tr><td><code id="intraining_estimations_+3A_test">test</code></td>
<td>
<p>test set from the training set;</p>
</td></tr>
<tr><td><code id="intraining_estimations_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="intraining_estimations_+3A_specs">specs</code></td>
<td>
<p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains
the specifications of the base models.</p>
</td></tr>
<tr><td><code id="intraining_estimations_+3A_lfun">lfun</code></td>
<td>
<p>loss function for metalearning. Defaults to ae &ndash; absolute error.</p>
</td></tr>
<tr><td><code id="intraining_estimations_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing two objects:
</p>

<dl>
<dt>mloss</dt><dd><p>loss of base models in <strong>test</strong></p>
</dd>
<dt>oob</dt><dd><p>out-of-bag test samples</p>
</dd>
<dt>Y_hat</dt><dd><p>predictions by base models</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other out-of-bag functions: 
<code><a href="#topic+intraining_predictions">intraining_predictions</a>()</code>
</p>

<hr>
<h2 id='intraining_predictions'>Out-of-bag predictions</h2><span id='topic+intraining_predictions'></span>

<h3>Description</h3>

<p>A pipeline for retrieving out-of-bag predictions
from the base models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intraining_predictions(train, test, form, specs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intraining_predictions_+3A_train">train</code></td>
<td>
<p>train set from the training set;</p>
</td></tr>
<tr><td><code id="intraining_predictions_+3A_test">test</code></td>
<td>
<p>test set from the training set;</p>
</td></tr>
<tr><td><code id="intraining_predictions_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="intraining_predictions_+3A_specs">specs</code></td>
<td>
<p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code>. Contains
the specifications of the base models.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other out-of-bag functions: 
<code><a href="#topic+intraining_estimations">intraining_estimations</a>()</code>
</p>

<hr>
<h2 id='l1apply'>Applying lapply on the rows</h2><span id='topic+l1apply'></span>

<h3>Description</h3>

<p>Wrapper function used to compute lapply on the rows
of a data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l1apply(obj, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="l1apply_+3A_obj">obj</code></td>
<td>
<p>a data.frame object to apply the function.</p>
</td></tr>
<tr><td><code id="l1apply_+3A_fun">FUN</code></td>
<td>
<p>function to apply to each row of <code>obj</code></p>
</td></tr>
<tr><td><code id="l1apply_+3A_...">...</code></td>
<td>
<p>Further parameters to <code>lapply</code></p>
</td></tr>
</table>

<hr>
<h2 id='learning_base_models'>Training the base models of an ensemble</h2><span id='topic+learning_base_models'></span>

<h3>Description</h3>

<p>This function uses <em>train</em> to build a set
of predictive models, according to <em>specs</em>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_base_models(train, form, specs, num_cores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="learning_base_models_+3A_train">train</code></td>
<td>
<p>training set to build the predictive models;</p>
</td></tr>
<tr><td><code id="learning_base_models_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="learning_base_models_+3A_specs">specs</code></td>
<td>
<p>object of class <code><a href="#topic+model_specs-class">model_specs-class</a></code></p>
</td></tr>
<tr><td><code id="learning_base_models_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A series of predictive models (<code>base_model</code>), and
the weights of the models computed in the training
data (<code>preweights</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+build_base_ensemble">build_base_ensemble</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
specs &lt;- model_specs(c("bm_ppr","bm_svr"), NULL)
M &lt;- build_base_ensemble(target ~., dataset, specs, 1)

</code></pre>

<hr>
<h2 id='loss_meta_learn'>Training an arbiter</h2><span id='topic+loss_meta_learn'></span>

<h3>Description</h3>

<p>Training an arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_meta_learn(form, data, meta_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss_meta_learn_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="loss_meta_learn_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="loss_meta_learn_+3A_meta_model">meta_model</code></td>
<td>
<p>learning algorithm &ndash; either a &quot;randomforest&quot;,
a &quot;lasso&quot;, or a &quot;gaussianprocess&quot;.</p>
</td></tr>
</table>

<hr>
<h2 id='meta_cubist'>Training a RBR arbiter</h2><span id='topic+meta_cubist'></span>

<h3>Description</h3>

<p>Training a RBR arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_cubist(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_cubist_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="meta_cubist_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_cubist_predict'>Arbiter predictions via Cubist</h2><span id='topic+meta_cubist_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via Cubist
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_cubist_predict(meta_model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_cubist_predict_+3A_meta_model">meta_model</code></td>
<td>
<p>arbiter &ndash; a ranger object</p>
</td></tr>
<tr><td><code id="meta_cubist_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict</p>
</td></tr>
</table>

<hr>
<h2 id='meta_ffnn'>Training a Gaussian prosadacess arbiter</h2><span id='topic+meta_ffnn'></span>

<h3>Description</h3>

<p>Training a Gaussian prosadacess arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_ffnn(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_ffnn_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_ffnn_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_ffnn_predict'>Arbiter predictions via linear ssmodel</h2><span id='topic+meta_ffnn_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via linear ssmodel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_ffnn_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_ffnn_predict_+3A_model">model</code></td>
<td>
<p>arbiter &ndash; a Gaussian process model</p>
</td></tr>
<tr><td><code id="meta_ffnn_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
</table>

<hr>
<h2 id='meta_gp'>Training a Gaussian process arbiter</h2><span id='topic+meta_gp'></span>

<h3>Description</h3>

<p>Training a Gaussian process arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_gp(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_gp_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_gp_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_gp_predict'>Arbiter predictions via linear model</h2><span id='topic+meta_gp_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_gp_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_gp_predict_+3A_model">model</code></td>
<td>
<p>arbiter &ndash; a Gaussian process model</p>
</td></tr>
<tr><td><code id="meta_gp_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
</table>

<hr>
<h2 id='meta_lasso'>Training a LASSO arbiter</h2><span id='topic+meta_lasso'></span>

<h3>Description</h3>

<p>Training a LASSO arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_lasso(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_lasso_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_lasso_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_lasso_predict'>Arbiter predictions via linear model</h2><span id='topic+meta_lasso_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_lasso_predict(meta_model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_lasso_predict_+3A_meta_model">meta_model</code></td>
<td>
<p>arbiter &ndash; a glmnet object</p>
</td></tr>
<tr><td><code id="meta_lasso_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict</p>
</td></tr>
</table>

<hr>
<h2 id='meta_mars'>Training a meta_mars process arbiter</h2><span id='topic+meta_mars'></span>

<h3>Description</h3>

<p>Training a meta_mars process arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_mars(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_mars_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_mars_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_mars_predict'>Arbiter predictions via mars model</h2><span id='topic+meta_mars_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via mars model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_mars_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_mars_predict_+3A_model">model</code></td>
<td>
<p>arbiter &ndash; a Gaussian process model</p>
</td></tr>
<tr><td><code id="meta_mars_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
</table>

<hr>
<h2 id='meta_pls'>Training a pls process arbiter</h2><span id='topic+meta_pls'></span>

<h3>Description</h3>

<p>Training a pls process arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_pls(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_pls_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_pls_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_pls_predict'>Arbiter predictions via pls model</h2><span id='topic+meta_pls_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via pls model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_pls_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_pls_predict_+3A_model">model</code></td>
<td>
<p>arbiter &ndash; a Gaussian process model</p>
</td></tr>
<tr><td><code id="meta_pls_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
</table>

<hr>
<h2 id='meta_ppr'>Training a meta_mars process arbiter</h2><span id='topic+meta_ppr'></span>

<h3>Description</h3>

<p>Training a meta_mars process arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_ppr(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_ppr_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_ppr_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_ppr_predict'>Arbiter predictions via ppr model</h2><span id='topic+meta_ppr_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via ppr model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_ppr_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_ppr_predict_+3A_model">model</code></td>
<td>
<p>arbiter &ndash; a Gaussian process model</p>
</td></tr>
<tr><td><code id="meta_ppr_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
</table>

<hr>
<h2 id='meta_predict'>Predicting loss using arbiter</h2><span id='topic+meta_predict'></span>

<h3>Description</h3>

<p>Predicting loss using arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_predict(model, newdata, meta_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_predict_+3A_model">model</code></td>
<td>
<p>arbiter model</p>
</td></tr>
<tr><td><code id="meta_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
<tr><td><code id="meta_predict_+3A_meta_model">meta_model</code></td>
<td>
<p>learning algorithm &ndash; either a &quot;randomforest&quot;,
a &quot;lasso&quot;, or a &quot;gaussianprocess&quot;.</p>
</td></tr>
</table>

<hr>
<h2 id='meta_rf'>Training a random forest arbiter</h2><span id='topic+meta_rf'></span>

<h3>Description</h3>

<p>Training a random forest arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_rf(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_rf_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="meta_rf_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_rf_predict'>Arbiter predictions via ranger</h2><span id='topic+meta_rf_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via ranger
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_rf_predict(meta_model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_rf_predict_+3A_meta_model">meta_model</code></td>
<td>
<p>arbiter &ndash; a ranger object</p>
</td></tr>
<tr><td><code id="meta_rf_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict</p>
</td></tr>
</table>

<hr>
<h2 id='meta_svr'>Training a Gaussian process arbiter</h2><span id='topic+meta_svr'></span>

<h3>Description</h3>

<p>Training a Gaussian process arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_svr(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_svr_+3A_form">form</code></td>
<td>
<p>form</p>
</td></tr>
<tr><td><code id="meta_svr_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_svr_predict'>Arbiter predictions via linear model</h2><span id='topic+meta_svr_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via linear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_svr_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_svr_predict_+3A_model">model</code></td>
<td>
<p>arbiter &ndash; a Gaussian process model</p>
</td></tr>
<tr><td><code id="meta_svr_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict loss</p>
</td></tr>
</table>

<hr>
<h2 id='meta_xgb'>Training a xgb arbiter</h2><span id='topic+meta_xgb'></span>

<h3>Description</h3>

<p>Training a xgb arbiter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_xgb(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_xgb_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="meta_xgb_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='meta_xgb_predict'>Arbiter predictions via xgb</h2><span id='topic+meta_xgb_predict'></span>

<h3>Description</h3>

<p>Arbiter predictions via xgb
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_xgb_predict(meta_model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meta_xgb_predict_+3A_meta_model">meta_model</code></td>
<td>
<p>arbiter &ndash; a ranger object</p>
</td></tr>
<tr><td><code id="meta_xgb_predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict</p>
</td></tr>
</table>

<hr>
<h2 id='model_recent_performance'>Recent performance of models using EMASE</h2><span id='topic+model_recent_performance'></span>

<h3>Description</h3>

<p>This function computes <strong>EMASE</strong>, Erfc Moving
Average Squared Error, to quantify the recent
performance of the base models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_recent_performance(Y_hat, Y, lambda, omega, pre_weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_recent_performance_+3A_y_hat">Y_hat</code></td>
<td>
<p>A <code>data.frame</code> containing the predictions of
each base model;</p>
</td></tr>
<tr><td><code id="model_recent_performance_+3A_y">Y</code></td>
<td>
<p>know true values from past data to compare the predictions to;</p>
</td></tr>
<tr><td><code id="model_recent_performance_+3A_lambda">lambda</code></td>
<td>
<p>Window size. Number of periods to average
over when computing <strong>MASE</strong>;</p>
</td></tr>
<tr><td><code id="model_recent_performance_+3A_omega">omega</code></td>
<td>
<p>Ratio of top models in the committee;</p>
</td></tr>
<tr><td><code id="model_recent_performance_+3A_pre_weights">pre_weights</code></td>
<td>
<p>The initial weights of the models, computed in
the available data during the learning phase;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing two objects:
</p>

<dl>
<dt>model_scores</dt><dd><p>The weights of the models in each time point</p>
</dd>
<dt>top_models</dt><dd><p>Models in the committee in each time point</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other weighting base models: 
<code><a href="#topic+EMASE">EMASE</a>()</code>,
<code><a href="#topic+build_committee">build_committee</a>()</code>,
<code><a href="#topic+get_top_models">get_top_models</a>()</code>,
<code><a href="#topic+model_weighting">model_weighting</a>()</code>,
<code><a href="#topic+select_best">select_best</a>()</code>
</p>

<hr>
<h2 id='model_specs'>Setup base learning models</h2><span id='topic+model_specs'></span>

<h3>Description</h3>

<p>This class sets up the base learning models and respective
parameters setting to learn the ensemble.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_specs(learner, learner_pars = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_specs_+3A_learner">learner</code></td>
<td>
<p>character vector with the base learners
to be trained. Currently available models are:
</p>

<dl>
<dt><strong>bm_gaussianprocess</strong></dt><dd><p>Gaussian Process models, from the
<strong>kernlab</strong> package. See <code><a href="kernlab.html#topic+gausspr">gausspr</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_ppr</strong></dt><dd><p>Projection Pursuit Regression models, from the
<strong>stats</strong> package. See <code><a href="stats.html#topic+ppr">ppr</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_ppr">bm_ppr</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_glm</strong></dt><dd><p>Generalized Linear Models, from the
<strong>glmnet</strong> package. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_glm">bm_glm</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_gbm</strong></dt><dd><p>Generalized Boosted Regression models, from the
<strong>gbm</strong> package. See <code><a href="gbm.html#topic+gbm">gbm</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_gbm">bm_gbm</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_randomforest</strong></dt><dd><p>Random Forest models, from the
<strong>ranger</strong> package. See <code><a href="ranger.html#topic+ranger">ranger</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_cubist</strong></dt><dd><p>M5 tree models, from the
<strong>Cubist</strong> package. See <code><a href="Cubist.html#topic+cubist">cubist</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_cubist">bm_cubist</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_mars</strong></dt><dd><p>Multivariate Adaptive Regression Splines models, from the
<strong>earth</strong> package. See <code><a href="earth.html#topic+earth">earth</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_mars">bm_mars</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_svr</strong></dt><dd><p>Support Vector Regression models, from the
<strong>kernlab</strong> package. See <code><a href="kernlab.html#topic+ksvm">ksvm</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_svr">bm_svr</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_ffnn</strong></dt><dd><p>Feedforward Neural Network models, from the
<strong>nnet</strong> package. See <code><a href="nnet.html#topic+nnet">nnet</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_pls_pcr</strong></dt><dd><p>Partial Least Regression and Principal
Component Regression models, from the <strong>pls</strong> package.
See <code><a href="pls.html#topic+mvr">mvr</a></code> for a complete description
and possible parametrization. See <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>
for the function implementation.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="model_specs_+3A_learner_pars">learner_pars</code></td>
<td>
<p>a list with parameter setting for the
<strong>learner</strong>. For each model, a inner list should be created
with the specified parameters.
</p>
<p>Check each implementation to see the possible
variations of parameters (also examplified below).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># A PPR model and a GLM model with default parameters
model_specs(learner = c("bm_ppr", "bm_glm"), learner_pars = NULL)


# A PPR model and a SVR model. The listed parameters are combined
# with a cartesian product.
# With these specifications an ensemble with 6 predictive base
# models will be created. Two PPR models, one with 2 nterms
# and another with 4; and 4 SVR models, combining the kernel
# and C parameters.
specs &lt;- model_specs(
 c("bm_ppr", "bm_svr"),
 list(bm_ppr = list(nterms = c(2, 4)),
      bm_svr = list(kernel = c("vanilladot", "polydot"), C = c(1,5)))
)

# All parameters currently available (parameter values can differ)
model_specs(
 learner = c("bm_ppr", "bm_svr", "bm_randomforest",
             "bm_gaussianprocess", "bm_cubist", "bm_glm",
             "bm_gbm", "bm_pls_pcr", "bm_ffnn", "bm_mars"
         ),
 learner_pars = list(
    bm_ppr = list(
       nterms = c(2,4),
       sm.method = "supsmu"
     ),
    bm_svr = list(
       kernel = "rbfdot",
       C = c(1,5),
       epsilon = .01
     ),
    bm_glm = list(
       alpha = c(1, 0)
     ),
    bm_randomforest = list(
       num.trees = 500
     ),
    bm_gbm = list(
       interaction.depth = 1,
       shrinkage = c(.01, .005),
       n.trees = c(100)
     ),
    bm_mars = list(
       nk = 15,
       degree = 3,
       thresh = .001
     ),
    bm_ffnn = list(
       size = 30,
       decay = .01
     ),
    bm_pls_pcr = list(
       method = c("kernelpls", "simpls", "cppls")
     ),
    bm_gaussianprocess = list(
       kernel = "vanilladot",
       tol = .01
     ),
    bm_cubist = list(
       committees = 50,
       neighbors = 0
     )
  )
)

</code></pre>

<hr>
<h2 id='model_specs-class'>Setup base learning models</h2><span id='topic+model_specs-class'></span>

<h3>Description</h3>

<p>This class sets up the base learning models and respective
parameters setting to learn the ensemble.
</p>


<h3>Slots</h3>


<dl>
<dt><code>learner</code></dt><dd><p>character vector with the base learners
to be trained. Currently available models are:
</p>

<dl>
<dt><strong>bm_gaussianprocess</strong></dt><dd><p>Gaussian Process models, from the
<strong>kernlab</strong> package. See <code><a href="kernlab.html#topic+gausspr">gausspr</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_gaussianprocess">bm_gaussianprocess</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_ppr</strong></dt><dd><p>Projection Pursuit Regression models, from the
<strong>stats</strong> package. See <code><a href="stats.html#topic+ppr">ppr</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_ppr">bm_ppr</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_glm</strong></dt><dd><p>Generalized Linear Models, from the
<strong>glmnet</strong> package. See <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_glm">bm_glm</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_gbm</strong></dt><dd><p>Generalized Boosted Regression models, from the
<strong>gbm</strong> package. See <code><a href="gbm.html#topic+gbm">gbm</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_gbm">bm_gbm</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_randomforest</strong></dt><dd><p>Random Forest models, from the
<strong>ranger</strong> package. See <code><a href="ranger.html#topic+ranger">ranger</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_randomforest">bm_randomforest</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_cubist</strong></dt><dd><p>M5 tree models, from the
<strong>Cubist</strong> package. See <code><a href="Cubist.html#topic+cubist">cubist</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_cubist">bm_cubist</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_mars</strong></dt><dd><p>Multivariate Adaptive Regression Splines models, from the
<strong>earth</strong> package. See <code><a href="earth.html#topic+earth">earth</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_mars">bm_mars</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_svr</strong></dt><dd><p>Support Vector Regression models, from the
<strong>kernlab</strong> package. See <code><a href="kernlab.html#topic+ksvm">ksvm</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_svr">bm_svr</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_ffnn</strong></dt><dd><p>Feedforward Neural Network models, from the
<strong>nnet</strong> package. See <code><a href="nnet.html#topic+nnet">nnet</a></code>
for a complete description and possible parametrization. See
<code><a href="#topic+bm_ffnn">bm_ffnn</a></code> for the function implementation.</p>
</dd>
<dt><strong>bm_pls_pcr</strong></dt><dd><p>Partial Least Regression and Principal
Component Regression models, from the <strong>pls</strong> package.
See <code><a href="pls.html#topic+mvr">mvr</a></code> for a complete description
and possible parametrization. See <code><a href="#topic+bm_pls_pcr">bm_pls_pcr</a></code>
for the function implementation.</p>
</dd>
</dl>
</dd>
<dt><code>learner_pars</code></dt><dd><p>a list with parameter setting for the
<strong>learner</strong>. For each model, a inner list should be created
with the specified parameters.
</p>
<p>Check each implementation to see the possible
variations of parameters (also examplified below).</p>
</dd>
</dl>


<h3>Examples</h3>

<pre><code class='language-R'># A PPR model and a GLM model with default parameters
model_specs(learner = c("bm_ppr", "bm_glm"), learner_pars = NULL)


# A PPR model and a SVR model. The listed parameters are combined
# with a cartesian product.
# With these specifications an ensemble with 6 predictive base
# models will be created. Two PPR models, one with 2 nterms
# and another with 4; and 4 SVR models, combining the kernel
# and C parameters.
specs &lt;- model_specs(
 c("bm_ppr", "bm_svr"),
 list(bm_ppr = list(nterms = c(2, 4)),
      bm_svr = list(kernel = c("vanilladot", "polydot"), C = c(1,5)))
)

# All parameters currently available (parameter values can differ)
model_specs(
 learner = c("bm_ppr", "bm_svr", "bm_randomforest",
             "bm_gaussianprocess", "bm_cubist", "bm_glm",
             "bm_gbm", "bm_pls_pcr", "bm_ffnn", "bm_mars"
         ),
 learner_pars = list(
    bm_ppr = list(
       nterms = c(2,4),
       sm.method = "supsmu"
     ),
    bm_svr = list(
       kernel = "rbfdot",
       C = c(1,5),
       epsilon = .01
     ),
    bm_glm = list(
       alpha = c(1, 0)
     ),
    bm_randomforest = list(
       num.trees = 500
     ),
    bm_gbm = list(
       interaction.depth = 1,
       shrinkage = c(.01, .005),
       n.trees = c(100)
     ),
    bm_mars = list(
       nk = 15,
       degree = 3,
       thresh = .001
     ),
    bm_ffnn = list(
       size = 30,
       decay = .01
     ),
    bm_pls_pcr = list(
       method = c("kernelpls", "simpls", "cppls")
     ),
    bm_gaussianprocess = list(
       kernel = "vanilladot",
       tol = .01
     ),
    bm_cubist = list(
       committees = 50,
       neighbors = 0
     )
  )
)

</code></pre>

<hr>
<h2 id='model_weighting'>Model weighting</h2><span id='topic+model_weighting'></span>

<h3>Description</h3>

<p>This is an utility function that takes the raw error of
models and scales them into a 0-1 range according to one
of three strategies:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_weighting(x, trans = "softmax", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_weighting_+3A_x">x</code></td>
<td>
<p>A object describing the loss of each base model</p>
</td></tr>
<tr><td><code id="model_weighting_+3A_trans">trans</code></td>
<td>
<p>Character value describing the transformation type.
The available options are <strong>softmax</strong>, <strong>linear</strong> and
<strong>erfc</strong>. The softmax and erfc provide a non-linear transformation
where the weights decay exponentially as the relative loss of a given model
increases (with respect to all available models). The linear transformation
is a simple normalization of values using the max-min method.</p>
</td></tr>
<tr><td><code id="model_weighting_+3A_...">...</code></td>
<td>
<p>Further arguments to <code>normalize</code> and
<code>proportion</code> functions \(na.rm = TRUE\)</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>erfc</dt><dd><p>using the complementary Gaussian error function</p>
</dd>
<dt>softmax</dt><dd><p>using a softmax function</p>
</dd>
<dt>linear</dt><dd><p>A simple normalization using max-min method</p>
</dd>
</dl>

<p>These tranformations culminate into the
final weights of the models.
</p>


<h3>Value</h3>

<p>An object describing the weights of models
</p>


<h3>See Also</h3>

<p>Other weighting base models: 
<code><a href="#topic+EMASE">EMASE</a>()</code>,
<code><a href="#topic+build_committee">build_committee</a>()</code>,
<code><a href="#topic+get_top_models">get_top_models</a>()</code>,
<code><a href="#topic+model_recent_performance">model_recent_performance</a>()</code>,
<code><a href="#topic+select_best">select_best</a>()</code>
</p>

<hr>
<h2 id='mse'>Computing the mean squared error</h2><span id='topic+mse'></span>

<h3>Description</h3>

<p>Utility function to compute mean squared error (MSE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(y, y_hat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mse_+3A_y">y</code></td>
<td>
<p>A numeric vector representing the actual values.</p>
</td></tr>
<tr><td><code id="mse_+3A_y_hat">y_hat</code></td>
<td>
<p>A numeric vector representing the forecasted values.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other error/performance functions: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>
</p>

<hr>
<h2 id='normalize'>Scale a numeric vector using max-min</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Utility function used to linearly normalize a numeric vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a linearly normalized vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>normalize(rnorm(4L))
normalize(1:10)

</code></pre>

<hr>
<h2 id='predict'>Predicting new observations using an ensemble</h2><span id='topic+predict'></span><span id='topic+predict.ade'></span><span id='topic+predict.dets'></span><span id='topic+predict.base'></span><span id='topic+predict+2CADE-method'></span><span id='topic+predict+2CDETS-method'></span><span id='topic+predict+2Cbase_ensemble-method'></span>

<h3>Description</h3>

<p>Initially, the predictions of the base models are collected.
Then, the predictions of the loss to be incurred by the base models <strong>E_hat</strong>
(estimated by their associate meta models) are computed. The weights of
the base models are then estimated according to <strong>E_hat</strong> and the committee of
top models. The committee is built according to the <em>lambda</em> and
<em>omega</em> parameters. Finally, the predictions are combined
according to the weights and the committee setup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'ADE'
predict(object, newdata)

## S4 method for signature 'DETS'
predict(object, newdata)

## S4 method for signature 'base_ensemble'
predict(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+ADE-class">ADE-class</a></code>;</p>
</td></tr>
<tr><td><code id="predict_+3A_newdata">newdata</code></td>
<td>
<p>new data to predict</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
###### Predicting with an ADE ensemble

specs &lt;- model_specs(
 learner = c("bm_glm", "bm_mars"),
 learner_pars = NULL
)

data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
train &lt;- dataset[1:1000, ]
test &lt;- dataset[1001:1500, ]

model &lt;- ADE(target ~., train, specs)

preds &lt;- predict(model, test)


## Not run: 

###### Predicting with a DETS ensemble

specs &lt;- model_specs(
 learner = c("bm_svr", "bm_glm", "bm_mars"),
 learner_pars = NULL
)

data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
train &lt;- dataset[1:700, ]
test &lt;- dataset[701:1000, ]

model &lt;- DETS(target ~., train, specs, lambda = 50, omega = .2)

preds &lt;- predict(model, test)

## End(Not run)


## Not run: 
###### Predicting with a base ensemble

model &lt;- ADE(target ~., train, specs)

basepreds &lt;- predict(model@base_ensemble, test)

## End(Not run)


</code></pre>

<hr>
<h2 id='predict_pls_pcr'>predict method for pls/pcr</h2><span id='topic+predict_pls_pcr'></span>

<h3>Description</h3>

<p>predict method for pls/pcr
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_pls_pcr(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_pls_pcr_+3A_model">model</code></td>
<td>
<p>pls/pcr model</p>
</td></tr>
<tr><td><code id="predict_pls_pcr_+3A_newdata">newdata</code></td>
<td>
<p>new data</p>
</td></tr>
</table>

<hr>
<h2 id='proportion'>Computing the proportions of a numeric vector</h2><span id='topic+proportion'></span>

<h3>Description</h3>

<p>Utility function used to compute the proportion of the
values of a vector. The proportion of a value is its ratio relative
to the sum of the vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportion(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proportion_+3A_x">x</code></td>
<td>
<p>a numeric vector;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of proportions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>proportion(rnorm(5L))
proportion(1:10)

</code></pre>

<hr>
<h2 id='rbind_l'>rbind with do.call syntax</h2><span id='topic+rbind_l'></span>

<h3>Description</h3>

<p>rbind with do.call syntax
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbind_l(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbind_l_+3A_x">x</code></td>
<td>
<p>object to call <code>rbind</code> to.</p>
</td></tr>
</table>

<hr>
<h2 id='recent_lambda_observations'>Get most recent lambda observations</h2><span id='topic+recent_lambda_observations'></span>

<h3>Description</h3>

<p>Get most recent lambda observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recent_lambda_observations(data, lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recent_lambda_observations_+3A_data">data</code></td>
<td>
<p>time series data as data.frame</p>
</td></tr>
<tr><td><code id="recent_lambda_observations_+3A_lambda">lambda</code></td>
<td>
<p>number of observations to keep</p>
</td></tr>
</table>

<hr>
<h2 id='rmse'>Computing the root mean squared error</h2><span id='topic+rmse'></span>

<h3>Description</h3>

<p>Utility function to compute Root Mean Squared Error (RMSE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmse(y, y_hat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmse_+3A_y">y</code></td>
<td>
<p>A numeric vector representing the actual values.</p>
</td></tr>
<tr><td><code id="rmse_+3A_y_hat">y_hat</code></td>
<td>
<p>A numeric vector representing the forecasted values.</p>
</td></tr>
</table>

<hr>
<h2 id='roll_mean_matrix'>Computing the rolling mean of the columns of a matrix</h2><span id='topic+roll_mean_matrix'></span>

<h3>Description</h3>

<p>Computing the rolling mean of the columns of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roll_mean_matrix(x, lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="roll_mean_matrix_+3A_x">x</code></td>
<td>
<p>a numeric data.frame;</p>
</td></tr>
<tr><td><code id="roll_mean_matrix_+3A_lambda">lambda</code></td>
<td>
<p>periods to average over when computing the
moving average.</p>
</td></tr>
</table>

<hr>
<h2 id='se'>Computing the squared error</h2><span id='topic+se'></span>

<h3>Description</h3>

<p>Utility function to compute pointwise squared error (SE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>se(y, y_hat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="se_+3A_y">y</code></td>
<td>
<p>A numeric vector representing the actual values.</p>
</td></tr>
<tr><td><code id="se_+3A_y_hat">y_hat</code></td>
<td>
<p>A numeric vector representing the forecasted values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>squared error of forecasted values.
</p>


<h3>See Also</h3>

<p>Other error/performance functions: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>
</p>

<hr>
<h2 id='select_best'>Selecting best model according to weights</h2><span id='topic+select_best'></span>

<h3>Description</h3>

<p>This function select the best model from a matrix of data x models.
For each row (data point), the model with maximum weight is assigned
a weight of 1, while the remaining models are assigned a weight of 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_best(model_scores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_best_+3A_model_scores">model_scores</code></td>
<td>
<p>matrix containing the model weights
across the observations</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other weighting base models: 
<code><a href="#topic+EMASE">EMASE</a>()</code>,
<code><a href="#topic+build_committee">build_committee</a>()</code>,
<code><a href="#topic+get_top_models">get_top_models</a>()</code>,
<code><a href="#topic+model_recent_performance">model_recent_performance</a>()</code>,
<code><a href="#topic+model_weighting">model_weighting</a>()</code>
</p>

<hr>
<h2 id='sequential_reweighting'>Sequential Re-weighting for controlling predictions' redundancy</h2><span id='topic+sequential_reweighting'></span>

<h3>Description</h3>

<p>Besides ensemble heterogeneity we encourage diversity
explicitly during the aggregation of the output of experts.
This is achieved by taking into account not only predictions
of performance produced by the arbiters, but also the
correlation among experts in a recent window of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequential_reweighting(sliding_similarity, W)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sequential_reweighting_+3A_sliding_similarity">sliding_similarity</code></td>
<td>
<p>list of pairwise similarity values. See
<code><a href="#topic+sliding_similarity">sliding_similarity</a></code></p>
</td></tr>
<tr><td><code id="sequential_reweighting_+3A_w">W</code></td>
<td>
<p>weights before re-weighting</p>
</td></tr>
</table>

<hr>
<h2 id='sliding_similarity'>Sliding similarity via Pearson's correlation</h2><span id='topic+sliding_similarity'></span>

<h3>Description</h3>

<p>Sliding similarity via Pearson's correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sliding_similarity(Y_hat_ext, lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sliding_similarity_+3A_y_hat_ext">Y_hat_ext</code></td>
<td>
<p>Predictions from the base-learners
across the examples.</p>
</td></tr>
<tr><td><code id="sliding_similarity_+3A_lambda">lambda</code></td>
<td>
<p>window size for computing correlations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with a correlation matrix
for each prediction point
</p>

<hr>
<h2 id='soft.completion'>Soft Imputation</h2><span id='topic+soft.completion'></span>

<h3>Description</h3>

<p>Soft Imputation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soft.completion(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="soft.completion_+3A_x">x</code></td>
<td>
<p>data</p>
</td></tr>
</table>

<hr>
<h2 id='softmax'>Computing the softmax</h2><span id='topic+softmax'></span>

<h3>Description</h3>

<p>This function computes the softmax function in
a numeric vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmax(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softmax_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>

<hr>
<h2 id='split_by'>Splitting expressions by pattern</h2><span id='topic+split_by'></span><span id='topic+split_by_'></span><span id='topic+split_by.'></span>

<h3>Description</h3>

<p>This is an utility function that can be used to split expressions.
It is based on <code>strsplit</code> function.
split_by is the general purpose <em>splitter</em>
split_by_ splits expressions by \&quot;_\&quot;
split_by. splits expressions by a dot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_by(expr, split, unlist. = TRUE, ...)

split_by_(expr, ...)

split_by.(expr, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="split_by_+3A_expr">expr</code></td>
<td>
<p>character expression to split;</p>
</td></tr>
<tr><td><code id="split_by_+3A_split">split</code></td>
<td>
<p>expression to split <code>expr</code> by;</p>
</td></tr>
<tr><td><code id="split_by_+3A_unlist.">unlist.</code></td>
<td>
<p>Logical. If TRUE, the splitted <code>expr</code> is unlisted;</p>
</td></tr>
<tr><td><code id="split_by_+3A_...">...</code></td>
<td>
<p>Further parameters to pass to <code>strsplit</code>;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list or vector with a splitted expression
</p>


<h3>Examples</h3>

<pre><code class='language-R'>split_by_("time_series")
split_by.("time.series")
split_by("born2bewild", "2")

</code></pre>

<hr>
<h2 id='train_ade'>Training procedure of for ADE</h2><span id='topic+train_ade'></span>

<h3>Description</h3>

<p>Base level models are trained according to <strong>specs</strong>,
and meta level models are trained using a blocked prequential
procedure in out-of-bag samples from the training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_ade(form, train, specs, lambda, lfun, meta_model_type, num_cores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="train_ade_+3A_form">form</code></td>
<td>
<p>formula;</p>
</td></tr>
<tr><td><code id="train_ade_+3A_train">train</code></td>
<td>
<p>training data as a data frame;</p>
</td></tr>
<tr><td><code id="train_ade_+3A_specs">specs</code></td>
<td>
<p>a <code><a href="#topic+model_specs-class">model_specs-class</a></code> object class. It contains
the parameter setting specifications for training the ensemble;</p>
</td></tr>
<tr><td><code id="train_ade_+3A_lambda">lambda</code></td>
<td>
<p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</td></tr>
<tr><td><code id="train_ade_+3A_lfun">lfun</code></td>
<td>
<p>meta loss function - defaults to <strong>ae</strong> (absolute error)</p>
</td></tr>
<tr><td><code id="train_ade_+3A_meta_model_type">meta_model_type</code></td>
<td>
<p>algorithm used to train meta models. Defaults to a
random forest (using ranger package)</p>
</td></tr>
<tr><td><code id="train_ade_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>

<hr>
<h2 id='train_ade_quick'>ADE training poor version
Train meta-models in the training data,
as opposed to using a validation dataset</h2><span id='topic+train_ade_quick'></span>

<h3>Description</h3>

<p>Saves times by not computing oob predictions.
Testing comp costs are the same.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_ade_quick(form, train, specs, lambda, lfun, meta_model_type, num_cores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="train_ade_quick_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="train_ade_quick_+3A_train">train</code></td>
<td>
<p>training data</p>
</td></tr>
<tr><td><code id="train_ade_quick_+3A_specs">specs</code></td>
<td>
<p>a <code><a href="#topic+model_specs-class">model_specs-class</a></code> object class. It contains
the parameter setting specifications for training the ensemble;</p>
</td></tr>
<tr><td><code id="train_ade_quick_+3A_lambda">lambda</code></td>
<td>
<p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</td></tr>
<tr><td><code id="train_ade_quick_+3A_lfun">lfun</code></td>
<td>
<p>meta loss function - defaults to <strong>ae</strong> (absolute error)</p>
</td></tr>
<tr><td><code id="train_ade_quick_+3A_meta_model_type">meta_model_type</code></td>
<td>
<p>algorithm used to train meta models. Defaults to a
random forest (using ranger package)</p>
</td></tr>
<tr><td><code id="train_ade_quick_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>

<hr>
<h2 id='tsensembler'>Dynamic Ensembles for Time Series Forecasting</h2><span id='topic+tsensembler'></span>

<h3>Description</h3>

<p>This package implements ensemble methods for time series
forecasting tasks. Dynamically combining different forecasting models
is a common approach to tackle these problems.
</p>


<h3>Details</h3>

<p>The main methods in <strong>tsensembler</strong> are in <code><a href="#topic+ADE-class">ADE-class</a></code> and
<code><a href="#topic+DETS-class">DETS-class</a></code>:
</p>

<dl>
<dt><strong>ADE</strong></dt><dd><p>Arbitrated Dynamic Ensemble (ADE) is an ensemble
approach for dynamically combining forecasting models using
a metalearning strategy called arbitrating. A meta model is
trained for each base model in the ensemble. Each meta-learner is
specifically designed to model the error of its associate
across the time series. At forecasting time, the base models
are weighted according to their degree of competence in the
input observation, estimated by the predictions of the meta models</p>
</dd>
<dt><strong>DETS</strong></dt><dd><p>Dynamic Ensemble for Time Series (DETS) is
similar to <strong>ADE</strong> in the sense that it adaptively combines
the base models in an ensemble for time series forecasting. DETS
follows a more traditional approach for forecaster combination. It
pre-trains a set of heterogeneous base models, and at run-time
weights them dynamically according to recent performance. Like <strong>ADE</strong>,
the ensemble includes a committee, which dynamically selects a
subset of base models that are weighted with a non-linear function</p>
</dd>
</dl>

<p>The ensemble methods can be used to <code>predict</code> new observations
or <code>forecast</code> future values of a time series. They can also be
updated using generic functions (check see also section).
</p>


<h3>References</h3>

<p>Cerqueira, Vitor; Torgo, Luis; Pinto, Fabio; and
Soares, Carlos. &quot;Arbitrated Ensemble for Time Series Forecasting&quot;
to appear at: Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer International
Publishing, 2017.
</p>
<p>V. Cerqueira, L. Torgo, and C. Soares, “Arbitrated ensemble for
solar radiation forecasting,” in International Work-Conference
on Artificial Neural Networks. Springer, 2017, pp. 720–732
</p>
<p>Cerqueira, Vitor; Torgo, Luis; Oliveira, Mariana, and Bernhard
Pfahringer. &quot;Dynamic and Heterogeneous Ensembles for Time Series
Forecasting.&quot; Data Science and Advanced Analytics (DSAA), 2017
IEEE International Conference on. IEEE, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ADE-class">ADE-class</a></code> for setting up an <strong>ADE</strong> model;
and <code><a href="#topic+DETS-class">DETS-class</a></code> for setting up an <strong>DETS</strong> model;
see also <code><a href="#topic+update_weights">update_weights</a></code> and <code><a href="#topic+update_base_models">update_base_models</a></code>
to check the generic function for updating the predictive models in
an ensemble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

data("water_consumption")
# embedding time series into a matrix
dataset &lt;- embed_timeseries(water_consumption, 5)

# splitting data into train/test
train &lt;- dataset[1:1000,]
test &lt;- dataset[1001:1020, ]

# setting up base model parameters
specs &lt;- model_specs(
  learner = c("bm_ppr","bm_glm","bm_svr","bm_mars"),
  learner_pars = list(
    bm_glm = list(alpha = c(0, .5, 1)),
    bm_svr = list(kernel = c("rbfdot", "polydot"),
                  C = c(1,3)),
    bm_ppr = list(nterms = 4)
  ))

# building the ensemble
model &lt;- ADE(target ~., train, specs)


# forecast next value and update base and meta models
# every three points;
# in the other points, only the weights are updated
predictions &lt;- numeric(nrow(test))
for (i in seq_along(predictions)) {
  predictions[i] &lt;- predict(model, test[i, ])@y_hat
  if (i %% 3 == 0) {
    model &lt;-
      update_base_models(model,
                         rbind.data.frame(train, test[seq_len(i), ]))

    model &lt;- update_ade_meta(model, rbind.data.frame(train, test[seq_len(i), ]))
  }
  else
    model &lt;- update_weights(model, test[i, ])
}

point_forecast &lt;- forecast(model, h = 5)

# setting up an ensemble of support vector machines
specs2 &lt;-
  model_specs(learner = c("bm_svr"),
              learner_pars = list(
                bm_svr = list(kernel = c("vanilladot", "polydot",
                                         "rbfdot"),
                              C = c(1,3,6))
              ))

model &lt;- DETS(target ~., train, specs2)
preds &lt;- predict(model, test)@y_hat


## End(Not run)


</code></pre>

<hr>
<h2 id='update_ade'>Updating an ADE model</h2><span id='topic+update_ade'></span><span id='topic+update_ade+2CADE-method'></span>

<h3>Description</h3>

<p><strong>update_ade</strong> is a generic function that combines
<code><a href="#topic+update_base_models">update_base_models</a></code>, <code><a href="#topic+update_ade_meta">update_ade_meta</a></code>,
and <code><a href="#topic+update_weights">update_weights</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_ade(object, newdata, num_cores = 1)

## S4 method for signature 'ADE'
update_ade(object, newdata, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_ade_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+ADE-class">ADE-class</a></code> object.</p>
</td></tr>
<tr><td><code id="update_ade_+3A_newdata">newdata</code></td>
<td>
<p>data used to update the ADE model. This should be
the data used to initially train the models (training set), together
with new observations (for example, validation set). Each model
is retrained using <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="update_ade_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ADE-class">ADE-class</a></code> for building an ADE model;
<code><a href="#topic+update_weights">update_weights</a></code> for updating the weights of the ensemble (without
retraining the models); <code><a href="#topic+update_base_models">update_base_models</a></code> for updating the
base models of an ensemble; and <code><a href="#topic+update_ade_meta">update_ade_meta</a></code> for
updating the meta-models of an ADE model.
</p>
<p>Other updating models: 
<code><a href="#topic+update_ade_meta">update_ade_meta</a>()</code>,
<code><a href="#topic+update_weights">update_weights</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>specs &lt;- model_specs(
 learner = c("bm_svr", "bm_glm", "bm_mars"),
 learner_pars = NULL
)

data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
# toy size for checks
train &lt;- dataset[1:300, ]
validation &lt;- dataset[301:400, ]
test &lt;- dataset[401:500, ]

model &lt;- ADE(target ~., train, specs)

preds_val &lt;- predict(model, validation)
model &lt;- update_ade(model, rbind.data.frame(train, validation))

preds_test &lt;- predict(model, test)


</code></pre>

<hr>
<h2 id='update_ade_meta'>Updating the metalearning layer of an ADE model</h2><span id='topic+update_ade_meta'></span><span id='topic+update_ade_meta+2CADE-method'></span>

<h3>Description</h3>

<p>The <strong>update_ade_meta</strong> function uses new information to
update the meta models of an <code><a href="#topic+ADE-class">ADE-class</a></code> ensemble. As input
it receives a <code><a href="#topic+ADE-class">ADE-class</a></code> model object class and a new dataset
for updating the weights of the base models in the ensemble.
This new data should have the same structure as the one used to build the
ensemble. Updating the base models of the ensemble is done using the <code><a href="#topic+update_base_models">update_base_models</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_ade_meta(object, newdata, num_cores = 1)

## S4 method for signature 'ADE'
update_ade_meta(object, newdata, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_ade_meta_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+ADE-class">ADE-class</a></code> object.</p>
</td></tr>
<tr><td><code id="update_ade_meta_+3A_newdata">newdata</code></td>
<td>
<p>data used to update the meta models. This should be
the data used to initially train the meta-models (training set), together
with new observations (for example, validation set). Each meta model
is retrained using <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="update_ade_meta_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ADE-class">ADE-class</a></code> for building an ADE model;
<code><a href="#topic+update_weights">update_weights</a></code> for updating the weights of the ensemble (without
retraining the models); and <code><a href="#topic+update_base_models">update_base_models</a></code> for updating the
base models of an ensemble.
</p>
<p>Other updating models: 
<code><a href="#topic+update_ade">update_ade</a>()</code>,
<code><a href="#topic+update_weights">update_weights</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
specs &lt;- model_specs(
 learner = c("bm_svr", "bm_glm", "bm_mars"),
 learner_pars = NULL
)

data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
train &lt;- dataset[1:1000, ]
validation &lt;- dataset[1001:1200, ]
test &lt;- dataset[1201:1500, ]

model &lt;- ADE(target ~., train, specs)

preds_val &lt;- predict(model, validation)
model &lt;- update_ade_meta(model, rbind.data.frame(train, validation))

preds_test &lt;- predict(model, test)

## End(Not run)

</code></pre>

<hr>
<h2 id='update_base_models'>Update the base models of an ensemble</h2><span id='topic+update_base_models'></span><span id='topic+update_base_models+2CADE-method'></span><span id='topic+update_base_models+2CDETS-method'></span>

<h3>Description</h3>

<p>This is a generic function for updating the base models
comprising an ensemble.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_base_models(object, newdata, num_cores = 1)

## S4 method for signature 'ADE'
update_base_models(object, newdata, num_cores = 1)

## S4 method for signature 'DETS'
update_base_models(object, newdata, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_base_models_+3A_object">object</code></td>
<td>
<p>an ensemble object, of class <code><a href="#topic+DETS-class">DETS-class</a></code> or
<code><a href="#topic+ADE-class">ADE-class</a></code>;</p>
</td></tr>
<tr><td><code id="update_base_models_+3A_newdata">newdata</code></td>
<td>
<p>new data used to update the models. Each base model
is retrained, so <code>newdata</code> should be the past data used for initially training
the models along with any further available observations.</p>
</td></tr>
<tr><td><code id="update_base_models_+3A_num_cores">num_cores</code></td>
<td>
<p>A numeric value to specify the number of cores used to
train base and meta models. num_cores = 1
leads to sequential training of models. num_cores &gt; 1
splits the training of the base models across num_cores cores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>update_base_models</strong> function receives a
model object and a new dataset for retraining
the base models. This new data should
have the same structure as the one used to build the
ensemble.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ADE-class">ADE-class</a></code> for the ADE model information, and
<code><a href="#topic+DETS-class">DETS-class</a></code> for the DETS model information;
<code><a href="#topic+update_ade_meta">update_ade_meta</a></code> for updating the meta models of an ADE ensemble.
See <code><a href="#topic+update_weights">update_weights</a></code> for the method used to update
the weights of the ensemble. Updating the weights only changes the information
about the recent observations for computing the weights of the base models,
while updating the model uses that information to retrain the models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)
# toy size for checks execution time
train &lt;- dataset[1:300,]
test &lt;- dataset[301:305, ]

specs &lt;- model_specs(c("bm_ppr","bm_glm","bm_mars"), NULL)

model &lt;- ADE(target ~., train, specs)

predictions &lt;- numeric(nrow(test))
for (i in seq_along(predictions)) {
  predictions[i] &lt;- predict(model, test[i, ])@y_hat
  model &lt;-
    update_base_models(model,
                       rbind.data.frame(train, test[seq_len(i), ]))
}

####

specs2 &lt;- model_specs(c("bm_ppr","bm_randomforest","bm_svr"), NULL)

modeldets &lt;- DETS(target ~., train, specs2)

predictions &lt;- numeric(nrow(test))
# predict new data and update models every three points
# in the remaining points, the only the weights are updated
for (i in seq_along(predictions)) {
  predictions[i] &lt;- predict(modeldets, test[i, ])@y_hat

  if (i %% 3 == 0)
    modeldets &lt;-
      update_base_models(modeldets,
                         rbind.data.frame(train, test[seq_len(i), ]))
  else
    modeldets &lt;- update_weights(modeldets, test[seq_len(i), ])
}


</code></pre>

<hr>
<h2 id='update_weights'>Updating the weights of base models</h2><span id='topic+update_weights'></span><span id='topic+update_weights+2CADE-method'></span><span id='topic+update_weights+2CDETS-method'></span>

<h3>Description</h3>

<p>Update the weights of base models of a <code><a href="#topic+ADE-class">ADE-class</a></code>
or <code><a href="#topic+DETS-class">DETS-class</a></code> ensemble.
This is accomplished by using computing the loss of the base models
in new recent observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_weights(object, newdata)

## S4 method for signature 'ADE'
update_weights(object, newdata)

## S4 method for signature 'DETS'
update_weights(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_weights_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+ADE-class">ADE-class</a></code> or <code><a href="#topic+DETS-class">DETS-class</a></code> model object;</p>
</td></tr>
<tr><td><code id="update_weights_+3A_newdata">newdata</code></td>
<td>
<p>new data used to update the most
recent observations of the time series. At prediction time
these observations are used to compute the weights of the base models</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Updating the weights of an ensemble is only necessary between
different calls of the functions <code>predict</code> or <code>forecast</code>.
Otherwise, if consecutive know observations are predicted
(e.g. a validation/test set) the updating is automatically done internally.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+update_weights">update_weights</a></code> for the weight updating method
for an <code><a href="#topic+ADE">ADE</a></code> model, and <code><a href="#topic+update_weights">update_weights</a></code> for the same method
for a <code><a href="#topic+DETS">DETS</a></code> model
</p>
<p>Other updating models: 
<code><a href="#topic+update_ade_meta">update_ade_meta</a>()</code>,
<code><a href="#topic+update_ade">update_ade</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("water_consumption")
dataset &lt;- embed_timeseries(water_consumption, 5)

# toy size for checks
train &lt;- dataset[1:300,]
test &lt;- dataset[301:305, ]

specs &lt;- model_specs(c("bm_ppr","bm_glm","bm_mars"), NULL)
## same with model &lt;- DETS(target ~., train, specs)
model &lt;- ADE(target ~., train, specs)

# if consecutive know observations are predicted (e.g. a validation/test set)
# the updating is automatically done internally.
predictions1 &lt;- predict(model, test)@y_hat

# otherwise, the models need to be updated
predictions &lt;- numeric(nrow(test))
# predict new data and update the weights of the model
for (i in seq_along(predictions)) {
  predictions[i] &lt;- predict(model, test[i, ])@y_hat

  model &lt;- update_weights(model, test[i, ])
}

#all.equal(predictions1, predictions)


</code></pre>

<hr>
<h2 id='water_consumption'>Water Consumption in Oporto city (Portugal) area.</h2><span id='topic+water_consumption'></span>

<h3>Description</h3>

<p>A time series of classes <code>xts</code> and <code>zoo</code>
containing the water consumption
levels a specific delivery point at Oporto town, in
Portugal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>water_consumption
</code></pre>


<h3>Format</h3>

<p>The time series has 1741 values from Jan, 2012 to Oct,
2016 in a daily granularity.
</p>

<dl>
<dt>consumption</dt><dd><p>consumption of water, raw value from sensor</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.addp.pt/home.php">https://www.addp.pt/home.php</a>
</p>

<hr>
<h2 id='xgb_optimizer'>XGB optimizer</h2><span id='topic+xgb_optimizer'></span>

<h3>Description</h3>

<p>XGB optimizer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xgb_optimizer(X, y, gsearch)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="xgb_optimizer_+3A_x">X</code></td>
<td>
<p>Covariates</p>
</td></tr>
<tr><td><code id="xgb_optimizer_+3A_y">y</code></td>
<td>
<p>Target values</p>
</td></tr>
<tr><td><code id="xgb_optimizer_+3A_gsearch">gsearch</code></td>
<td>
<p>Grid search</p>
</td></tr>
</table>

<hr>
<h2 id='xgb_predict'>XGBoost predict function</h2><span id='topic+xgb_predict'></span>

<h3>Description</h3>

<p>XGBoost predict function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xgb_predict(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="xgb_predict_+3A_model">model</code></td>
<td>
<p>Model from bm_xgb</p>
</td></tr>
<tr><td><code id="xgb_predict_+3A_newdata">newdata</code></td>
<td>
<p>Test data</p>
</td></tr>
</table>

<hr>
<h2 id='xgb_predict_'>asdasd</h2><span id='topic+xgb_predict_'></span>

<h3>Description</h3>

<p>asdasd
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xgb_predict_(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="xgb_predict__+3A_model">model</code></td>
<td>
<p>mode</p>
</td></tr>
<tr><td><code id="xgb_predict__+3A_newdata">newdata</code></td>
<td>
<p>s</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
