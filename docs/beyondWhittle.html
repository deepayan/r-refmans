<!DOCTYPE html><html><head><title>Help for package beyondWhittle</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {beyondWhittle}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acceptanceRate'><p>Computing acceptance rate based on trace</p>
Note: Only use for traces from continous distributions!</a></li>
<li><a href='#acvBlockMatrix'><p>Build an nd times nd Block Toeplitz matrix from the</p>
(d times d) autocovariances gamma(0),...,gamma(n-1)</a></li>
<li><a href='#acvMatrix'><p>Build an n times n Toeplitz matrix from the</p>
autocovariance values gamma(0),...,gamma(n-1)</a></li>
<li><a href='#Adj'><p>adjoint of complex matrix</p></a></li>
<li><a href='#arma_conditional'><p>Negative ARMA(p, q) log likelihood</p></a></li>
<li><a href='#bayes_factor'><p>a generic method for bdp_dw_result class</p></a></li>
<li><a href='#bayes_factor.bdp_dw_result'><p>Extracting the Bayes factor of k1=1 from bdp_dw_result class</p></a></li>
<li><a href='#bdp_dw_bayes_factor_k1'><p>Estimating the Bayes factor of hypothesis &quot;k1 = 1&quot;.</p></a></li>
<li><a href='#bdp_dw_est_post_stats'><p>Calculating the estimated posterior mean, median and credible region (tv-PSD)</p></a></li>
<li><a href='#bdp_dw_mcmc'><p>MH sampler for BDP-DW method</p></a></li>
<li><a href='#bdp_dw_mcmc_params_gen'><p>Generate a list of values for MCMC algorithm</p></a></li>
<li><a href='#bdp_dw_prior_params_gen'><p>Generate a list of parameter values in prior elicitation</p></a></li>
<li><a href='#betaBasis_k'><p>Construct Bernstein polynomial basis of degree k on omega</p></a></li>
<li><a href='#betaBasis_k_dw'><p>Construct Bernstein polynomial basis of degree k on omega</p></a></li>
<li><a href='#beyondWhittle-package'>
<p>Bayesian spectral inference for time series</p></a></li>
<li><a href='#center'><p>mean center a numerical vector</p></a></li>
<li><a href='#coarsened_bernstein'><p>Construct coarsened Bernstein polynomial basis of degree l on omega</p></a></li>
<li><a href='#coarsened_bernstein_i'><p>Helping function for <code>coarsened_bernstein</code></p></a></li>
<li><a href='#complexValuedPsd'><p>Inverse function to realValuedPsd</p></a></li>
<li><a href='#cube_from_NumericVector'><p>I/O: Only used within Rcpp</p>
Note: Same workaround as <code>cx_cube_from_ComplexVector</code></a></li>
<li><a href='#cx_cube_from_ComplexVector'><p>I/O: Only used within Rcpp</p></a></li>
<li><a href='#dbList'><p>Construct Bernstein polynomial basises of degree up to kmax on omega</p></a></li>
<li><a href='#dbList_dw_Bern'><p>Construct Bernstein polynomial bases of degree up to kmax on omega</p></a></li>
<li><a href='#dbList_dw_Bern_for_lambda'><p>Construct Bernstein polynomial bases of degree up to kmax on omega for frequency parameter lambda</p></a></li>
<li><a href='#densityMixture'><p>Construct a density mixture from mixture weights and density functions.</p></a></li>
<li><a href='#epsilon_var'><p>epsilon process (residuals) of VAR model</p></a></li>
<li><a href='#fast_ft'><p>Fast Fourier Transform</p></a></li>
<li><a href='#fast_ift'><p>Fast Inverse Fourier Transform</p></a></li>
<li><a href='#fast_mean'><p>Help function to compute the mean.</p></a></li>
<li><a href='#fourier_freq'><p>Fourier frequencies</p></a></li>
<li><a href='#genEpsARMAC'><p>Get epsilon process (i.e. model residuals) for ARMA(p,q)</p></a></li>
<li><a href='#get_f_matrix'><p>Construct psd mixture</p></a></li>
<li><a href='#get_U_cpp'><p>Get U from phi, vectorized, cpp internal only</p></a></li>
<li><a href='#gibbs_ar'><p>Gibbs sampler for an autoregressive model with PACF parametrization.</p></a></li>
<li><a href='#gibbs_AR_nuisance_intern'><p>Gibbs sampler for Bayesian AR model in PACF parametrization,</p>
including support for TS to be a nuisance parameter</a></li>
<li><a href='#gibbs_bdp_dw'><p>BDP-DW method: performing posterior sampling and calculating statistics based on the posterior samples</p></a></li>
<li><a href='#gibbs_multivariate_nuisance'><p>Gibbs sampler for corrected parametric likelihood + Bernstein-Dirichlet mixture,</p>
including possibility of using time series as mere nuisance parameter
Multivariate case</a></li>
<li><a href='#gibbs_multivariate_nuisance_cpp'><p>Gibbs sampler in Cpp</p></a></li>
<li><a href='#gibbs_np'><p>Gibbs sampler for Bayesian nonparametric inference with Whittle likelihood</p></a></li>
<li><a href='#gibbs_npc'><p>Gibbs sampler for Bayesian semiparametric inference with the corrected AR likelihood</p></a></li>
<li><a href='#gibbs_nuisance'><p>Gibbs sampler for corrected parametric likelihood + Bernstein-Dirichlet mixture,</p>
including possibility of using time series as mere nuisance parameter</a></li>
<li><a href='#gibbs_var'><p>Gibbs sampler for vector autoregressive model.</p></a></li>
<li><a href='#gibbs_VAR_nuisance_intern'><p>Gibbs sampling algorithm for VAR model</p></a></li>
<li><a href='#gibbs_vnp'><p>Gibbs sampler for multivaiate Bayesian nonparametric inference with Whittle likelihood</p></a></li>
<li><a href='#hasEigenValueSmallerZero'><p>Does a matrix have an eigenvalue smaller than 0?</p></a></li>
<li><a href='#is_hpd'><p>Check if a matrix is Hermitian positive definite</p></a></li>
<li><a href='#is_quadratic'><p>Is l quadratic?</p></a></li>
<li><a href='#is_spd'><p>Check if a matrix is symmetric positive definite</p></a></li>
<li><a href='#lik_ar'><p>Likelihood of an autoregressive time series model with i.i.d. normal innovations</p></a></li>
<li><a href='#llike'><p>Log corrected parametric AR likelihood (Gaussian)</p></a></li>
<li><a href='#llike_AR'><p>Time domain AR(p) likelihood for nuisance/noise time series</p></a></li>
<li><a href='#llike_dw'><p>Calculating log likelihood</p></a></li>
<li><a href='#llike_var'><p>VAR(p) likelihood</p></a></li>
<li><a href='#llike_var_full'><p>VAR(p) full likelihood</p></a></li>
<li><a href='#llike_var_partial'><p>VAR(p) partial likelihood (unnormalized)</p>
Note: Fine for fixed p, but not suited for model comparison</a></li>
<li><a href='#local_moving_FT_zigzag'><p>Calculate the moving Fourier transform ordinates</p></a></li>
<li><a href='#logDet_stickBreaking'><p>Log determinant of stick breaking transformation V -&gt; p</p></a></li>
<li><a href='#logfuller'><p>Fuller Logarithm</p></a></li>
<li><a href='#lpost'><p>Log posterior = log prior + log corrected parametric likelihood</p></a></li>
<li><a href='#lpost_AR'><p>Log Posterior = Log Prior + (conditional) Log Likelihood</p></a></li>
<li><a href='#lprior'><p>Log prior of Bernstein-Dirichlet mixture and parametric working model &ndash; all unnormalized</p></a></li>
<li><a href='#lprior_AR'><p>Log prior for PACF (~Beta) and sigma2 (~InverseGamma), unnormalized</p></a></li>
<li><a href='#lprior_dw'><p>Calculation of log prior</p></a></li>
<li><a href='#mdft'><p>Multivariate discrete (fast) Fourier Transform</p></a></li>
<li><a href='#midft'><p>Multivariate inverse discrete (fast) Fourier Transform</p></a></li>
<li><a href='#missingValues_str_help'><p>Get string representation for missing values position from vector index</p></a></li>
<li><a href='#mixtureWeight'><p>Get mixture weights of Bernstein-Dirchlet-Mixtures</p></a></li>
<li><a href='#mpdgrm'><p>Compute Periodgram matrix from (complex-valued) Fourier coefficients</p></a></li>
<li><a href='#my_rdirichlet'><p>Generate a random samples from a Dirichlet distribution</p></a></li>
<li><a href='#nll_norm'><p>Negative log likelihood of iid standard normal observations [unit variance]</p>
Note: deprecated</a></li>
<li><a href='#omegaFreq'><p>Fourier frequencies rescaled on the unit interval</p></a></li>
<li><a href='#pacf_to_ar'><p>Convert partial autocorrelation coefficients to AR coefficients.</p></a></li>
<li><a href='#pacf2AR'><p>C++ function for computing AR coefficients from PACF.</p>
See Section III in Barndorff-Nielsen and Schou (1973)</a></li>
<li><a href='#pFromV'><p>Get  p from v in Stick Breaking DP representation</p></a></li>
<li><a href='#phiFromBeta_normalInverseWishart'><p>Convert vector parametrization (beta) to matrix-parametrization (phi),</p>
the latter as e.g. used in MTS::VAR()$ar</a></li>
<li><a href='#plot.bdp_dw_result'><p>Plot method for bdp_dw_result class</p></a></li>
<li><a href='#plot.bdp_dw_tv_psd'><p>Plot method for bdp_dw_tv_psd class</p></a></li>
<li><a href='#plot.gibbs_psd'><p>Plot method for gibbs_psd class</p></a></li>
<li><a href='#plotMPsd'><p>Visualization of multivariate PSDs</p>
Used in <code>plot.gibbs_psd</code></a></li>
<li><a href='#print_mcmc_state'><p>Help function to print MCMC state</p></a></li>
<li><a href='#print_summary_gibbs_psd_help'><p>Helping function for print and summary (both are quite similar)</p></a></li>
<li><a href='#print_warn'><p>Help function to print debugging messages</p></a></li>
<li><a href='#print.bdp_dw_result'><p>Print method for bdp_dw_result class</p></a></li>
<li><a href='#print.gibbs_psd'><p>Print method for gibbs_psd class</p></a></li>
<li><a href='#psd_arma'><p>ARMA(p,q) spectral density function</p></a></li>
<li><a href='#psd_array'><p>Convert psd vector to array</p>
(compatibility: to use plotMPsd for univariate functions as well)</a></li>
<li><a href='#psd_dummy_model'><p>Time series model X_t=e_t, E[e_t]=0</p></a></li>
<li><a href='#psd_tvarma12'><p>time-varying spectral density function of the tvARMA(1,2) processes for illustrations</p></a></li>
<li><a href='#psd_varma'><p>VARMA(p,q) spectral density function</p></a></li>
<li><a href='#psd_varma_help'><p>helping function for psd_varma</p></a></li>
<li><a href='#PSIwgt'><p>Psi-weight calculation for a VARMA model.</p>
NOTE: This is an exact copy of the MTS::PSIwgt function
(only with the plot functionality removed, as not needed).
This has to be done because the MTS package has been removed
from CRAN in April 2022.</a></li>
<li><a href='#qpsd'><p>Compute normalized PSD in the Bernstein-Dirichlet parametrization.</p></a></li>
<li><a href='#qpsd_dw'><p>Evaluation of normalized time-varying spectral density function (based on posterior samples)</p></a></li>
<li><a href='#qpsd_dw.tilde_zigzag_cpp_expedited'><p>Evaluation of normalized time-varying spectral density function (for MCMC algorithm)</p></a></li>
<li><a href='#realValuedPsd'><p>Store imaginary parts above and real parts below the diagonal</p></a></li>
<li><a href='#rmvnorm'><p>Simulate from a Multivariate Normal Distribution</p></a></li>
<li><a href='#scree_type_ar'><p>Negative log AR likelihood values for scree-type plots</p></a></li>
<li><a href='#sim_tvarma12'><p>simulate from the tvARMA(1,2) process for illustration</p></a></li>
<li><a href='#sim_varma'><p>Simulate from a VARMA model</p></a></li>
<li><a href='#sldmvnorm'><p>sum of multivariate normal log densities</p>
with mean 0 and covariance Sigma, unnormalized</a></li>
<li><a href='#summary.bdp_dw_result'><p>Summary method for bdp_dw_result class</p></a></li>
<li><a href='#summary.gibbs_psd'><p>Summary method for gibbs_psd class</p></a></li>
<li><a href='#transfer_polynomial'><p>VARMA transfer polynomials</p></a></li>
<li><a href='#uci_help'><p>Helping function for <code>uci_matrix</code></p></a></li>
<li><a href='#uci_matrix'><p>Uniform credible intervals in matrix-valued case</p></a></li>
<li><a href='#uniformmax'><p>Uniform maximum, as needed for uniform credible intervals</p></a></li>
<li><a href='#uniformmax_help'><p>Helping function for <code>uci_matrix</code></p></a></li>
<li><a href='#uniformmax_multi'><p>Helping function for <code>uci_matrix</code></p></a></li>
<li><a href='#unit_trace_I_l'><p>Range intervals I_l, see (63) in Mittelbach et al.</p></a></li>
<li><a href='#unit_trace_L_from_x'><p>Get L (lower triangular Cholesky) from x</p>
Called U^* in Mittelbach et al, see (60) there</a></li>
<li><a href='#unit_trace_log_c'><p>Get log(c) vector, see (70) in Mittelbach et al.</p>
Helping function for <code>unit_trace_runif</code></a></li>
<li><a href='#unit_trace_log_d'><p>Get log(d) vector, see (39) in Mittelbach et al, adjusted to complex case</p>
Helping function for <code>unit_trace_runif</code></a></li>
<li><a href='#unit_trace_log_f_l'><p>Get log(f_l), see (66) in Mittelbach et al.</p>
Helping function for <code>unit_trace_runif</code></a></li>
<li><a href='#unit_trace_mu'><p>Get mu vector, see (36) in Mittelbach et al.</p>
Helping function for <code>unit_trace_runif</code></a></li>
<li><a href='#unit_trace_nu'><p>Get log(nu) vector, see (38) in Mittelbach et al.</p>
Helping function for <code>unit_trace_runif</code></a></li>
<li><a href='#unit_trace_p'><p>Get p vector, see (67) in Mittelbach et al.</p></a></li>
<li><a href='#unit_trace_q'><p>Get q vector, see (68) in Mittelbach et al.</p></a></li>
<li><a href='#unit_trace_runif'><p>Draw uniformly from Hpd matrices with unit trace</p></a></li>
<li><a href='#unit_trace_runif_single'><p>Obtain one uniform draw from d times d Hpd matrices with unit trace</p>
See Algorithm 2 in Mittelbach et al. (adjusted to complex case)</a></li>
<li><a href='#unit_trace_sigma2'><p>Get sigma2 vector, see (70) in Mittelbach et al.</p>
Helping function for <code>unit_trace_runif</code></a></li>
<li><a href='#unit_trace_U_from_phi'><p>Get U (Hpd with unit trace) matrix from</p>
phi (hyperspherical coordinates) vector.</a></li>
<li><a href='#unit_trace_x_from_phi'><p>Get x from phi, see (62) in Mittelbach et al.</p></a></li>
<li><a href='#unrollPsd'><p>Redundantly roll out a PSD from length N=floor(n/2) to length n</p></a></li>
<li><a href='#VAR_regressor_matrix'><p>VAR regressor matrix, see Section 2.2.3 in Koop and Korobilis (2010)</p></a></li>
<li><a href='#varma_transfer2psd'><p>Get VARMA PSD from transfer polynomials</p>
Helping function for <code>psd_varma</code></a></li>
<li><a href='#VARMAcov_muted'><p>This is a nearly exact copy of the MTS::VARMAcov function, where</p>
the output commands at the end are removed.
This has to be done because the function is called repeatedly
within the MCMC algorithm.
For future versions of the package, a better solution is intended.</a></li>
<li><a href='#vFromP'><p>Get v from p (DP inverse stick breaking)</p>
Note: p is assumed to have length L, i.e. it does NOT contain p_0</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Spectral Inference for Time Series</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-12</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Renate Meyer &lt;renate.meyer@auckland.ac.nz&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementations of Bayesian parametric, nonparametric and semiparametric procedures for univariate and multivariate time series. The package is based on the methods presented in C. Kirch et al (2018) &lt;<a href="https://doi.org/10.1214%2F18-BA1126">doi:10.1214/18-BA1126</a>&gt;, A. Meier (2018) <a href="https://opendata.uni-halle.de//handle/1981185920/13470">https://opendata.uni-halle.de//handle/1981185920/13470</a> and Y. Tang et al (2023) &lt;<a href="https://arxiv.org/abs/2303.11561">arXiv:2303.11561</a>&gt;. It was supported by DFG grants KI 1443/3-1 and KI 1443/3-2.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>ltsa (&ge; 1.4.6), Rcpp (&ge; 0.12.5), MASS, forecast</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, BH</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-12 05:11:03 UTC; Ptole</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander Meier [aut],
  Claudia Kirch [aut],
  Matthew C. Edwards [aut],
  Renate Meyer [aut, cre],
  Yifu Tang [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-13 19:30:02 UTC</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
</table>
<hr>
<h2 id='acceptanceRate'>Computing acceptance rate based on trace
Note: Only use for traces from continous distributions!</h2><span id='topic+acceptanceRate'></span>

<h3>Description</h3>

<p>Computing acceptance rate based on trace
Note: Only use for traces from continous distributions!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acceptanceRate(trace)
</code></pre>

<hr>
<h2 id='acvBlockMatrix'>Build an nd times nd Block Toeplitz matrix from the
(d times d) autocovariances gamma(0),...,gamma(n-1)</h2><span id='topic+acvBlockMatrix'></span>

<h3>Description</h3>

<p>Build an nd times nd Block Toeplitz matrix from the
(d times d) autocovariances gamma(0),...,gamma(n-1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acvBlockMatrix(acv)
</code></pre>

<hr>
<h2 id='acvMatrix'>Build an n times n Toeplitz matrix from the 
autocovariance values gamma(0),...,gamma(n-1)</h2><span id='topic+acvMatrix'></span>

<h3>Description</h3>

<p>Build an n times n Toeplitz matrix from the 
autocovariance values gamma(0),...,gamma(n-1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acvMatrix(acv)
</code></pre>

<hr>
<h2 id='Adj'>adjoint of complex matrix</h2><span id='topic+Adj'></span>

<h3>Description</h3>

<p>adjoint of complex matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Adj(m)
</code></pre>

<hr>
<h2 id='arma_conditional'>Negative ARMA(p, q) log likelihood</h2><span id='topic+arma_conditional'></span>

<h3>Description</h3>

<p>Negative ARMA(p, q) log likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arma_conditional(zt, ar, ma, nll_fun, full_lik, ...)
</code></pre>

<hr>
<h2 id='bayes_factor'>a generic method for bdp_dw_result class</h2><span id='topic+bayes_factor'></span>

<h3>Description</h3>

<p>a generic method for bdp_dw_result class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_factor(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayes_factor_+3A_obj">obj</code></td>
<td>
<p>object of class bdp_dw_result</p>
</td></tr>
</table>

<hr>
<h2 id='bayes_factor.bdp_dw_result'>Extracting the Bayes factor of k1=1 from bdp_dw_result class</h2><span id='topic+bayes_factor.bdp_dw_result'></span>

<h3>Description</h3>

<p>Extracting the Bayes factor of k1=1 from bdp_dw_result class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bdp_dw_result'
bayes_factor(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayes_factor.bdp_dw_result_+3A_obj">obj</code></td>
<td>
<p>object of class bdp_dw_result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the estimated Bayes factor of k1=1
</p>

<hr>
<h2 id='bdp_dw_bayes_factor_k1'>Estimating the Bayes factor of hypothesis &quot;k1 = 1&quot;.</h2><span id='topic+bdp_dw_bayes_factor_k1'></span>

<h3>Description</h3>

<p>Estimating the Bayes factor of hypothesis &quot;k1 = 1&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdp_dw_bayes_factor_k1(post_sample, precision = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bdp_dw_bayes_factor_k1_+3A_post_sample">post_sample</code></td>
<td>
<p>the posterior sample generated by <a href="#topic+bdp_dw_mcmc">bdp_dw_mcmc</a>.</p>
</td></tr>
<tr><td><code id="bdp_dw_bayes_factor_k1_+3A_precision">precision</code></td>
<td>
<p>a positive integer specifying the number of terms used in approximating
the normalizing constant of the prior probability mass function of k1. Default 1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Savage-Dickey estimate of the Bayes factor and its theoretical upper bound. c.f. section 3.3 of Tang et al. (2023).
</p>


<h3>References</h3>

<p>Tang et al. (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>

<hr>
<h2 id='bdp_dw_est_post_stats'>Calculating the estimated posterior mean, median and credible region (tv-PSD)</h2><span id='topic+bdp_dw_est_post_stats'></span>

<h3>Description</h3>

<p>Calculating the estimated posterior mean, median and credible region (tv-PSD)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdp_dw_est_post_stats(post_sample, rescaled_time, freq, unif_CR = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bdp_dw_est_post_stats_+3A_post_sample">post_sample</code></td>
<td>
<p>the posterior sample generated by <a href="#topic+bdp_dw_mcmc">bdp_dw_mcmc</a>.</p>
</td></tr>
<tr><td><code id="bdp_dw_est_post_stats_+3A_rescaled_time">rescaled_time</code>, <code id="bdp_dw_est_post_stats_+3A_freq">freq</code></td>
<td>
<p>numeric vectors forming a rectangular grid on which the estimated tv-PSD is evaluated.</p>
</td></tr>
<tr><td><code id="bdp_dw_est_post_stats_+3A_unif_cr">unif_CR</code></td>
<td>
<p>a Boolean value (default FALSE) indicating whether to calculate the uniform credible region
rescaled_time must be in <code class="reqn">[0,1]</code> and freq must be in <code class="reqn">[0,\pi]</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>tvpsd.mean</code>, <code>tvpsd.median</code></td>
<td>
<p>posterior mean and pointwise posterior median (matrices of dimension length(rescaled_time) by length(freq))</p>
</td></tr>
<tr><td><code>tvpsd.p05</code>, <code>tvpsd.p95</code></td>
<td>
<p>90 percent pointwise credibility interval</p>
</td></tr>
<tr><td><code>tvpsd.u05</code>, <code>tvpsd.u95</code></td>
<td>
<p>90 percent uniform credibility interval if unif_CR = TRUE. Otherwise NA</p>
</td></tr>
</table>

<hr>
<h2 id='bdp_dw_mcmc'>MH sampler for BDP-DW method</h2><span id='topic+bdp_dw_mcmc'></span>

<h3>Description</h3>

<p>Obtain samples of the posterior of the Whittle likelihood in conjunction with a Bernstein-Dirichlet prior on the spectral density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdp_dw_mcmc(
  data,
  m,
  likelihood_thinning = 1,
  mcmc_params,
  prior_params,
  monitor = FALSE,
  print_interval = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bdp_dw_mcmc_+3A_data">data</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_+3A_m">m</code></td>
<td>
<p>window size needed to calculate moving periodogram.</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_+3A_likelihood_thinning">likelihood_thinning</code></td>
<td>
<p>the thinning factor of the dynamic Whittle likelihood.</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_+3A_mcmc_params">mcmc_params</code></td>
<td>
<p>a list generated by <a href="#topic+bdp_dw_mcmc_params_gen">bdp_dw_mcmc_params_gen</a>.</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_+3A_prior_params">prior_params</code></td>
<td>
<p>a list generated by <a href="#topic+bdp_dw_prior_params_gen">bdp_dw_prior_params_gen</a>.</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_+3A_monitor">monitor</code></td>
<td>
<p>a Boolean value (default FALSE) indicating whether to display the real-time status</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_+3A_print_interval">print_interval</code></td>
<td>
<p>If monitor = TRUE, then this value indicates the number of iterations after which a status is printed to console;
If monitor = FALSE, it does not have any effect</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Further detail can be found in the simulation study section in the references papers.
</p>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>k1</code>, <code>k2</code>, <code>tau</code>, <code>V</code>, <code>W1</code>, <code>W2</code></td>
<td>
<p>posterior traces of PSD parameters</p>
</td></tr>
<tr><td><code>tim</code></td>
<td>
<p>total run time</p>
</td></tr>
<tr><td><code>prior_params</code></td>
<td>
<p>the specifications of the prior</p>
</td></tr>
</table>


<h3>References</h3>

<p>Y. Tang et al. (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>

<hr>
<h2 id='bdp_dw_mcmc_params_gen'>Generate a list of values for MCMC algorithm</h2><span id='topic+bdp_dw_mcmc_params_gen'></span>

<h3>Description</h3>

<p>Generate a list of values for MCMC algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdp_dw_mcmc_params_gen(
  Ntotal = 110000,
  burnin = 60000,
  thin = 10,
  adaptive.batchSize = 50,
  adaptive.targetAcceptanceRate = 0.44
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bdp_dw_mcmc_params_gen_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_params_gen_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_params_gen_+3A_thin">thin</code></td>
<td>
<p>thinning number (for post-processing of the posterior sample)</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_params_gen_+3A_adaptive.batchsize">adaptive.batchSize</code></td>
<td>
<p>the batch size for the adaptive MCMC algorithm for sampling tau</p>
</td></tr>
<tr><td><code id="bdp_dw_mcmc_params_gen_+3A_adaptive.targetacceptancerate">adaptive.targetAcceptanceRate</code></td>
<td>
<p>the target acceptance rate for the adaptive MCMC algorithm for sampling tau</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of MCMC parameter values
</p>

<hr>
<h2 id='bdp_dw_prior_params_gen'>Generate a list of parameter values in prior elicitation</h2><span id='topic+bdp_dw_prior_params_gen'></span>

<h3>Description</h3>

<p>Generate a list of parameter values in prior elicitation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdp_dw_prior_params_gen(
  M = 1,
  g0.alpha = 1,
  g0.beta = 1,
  k1.theta = 0.01,
  k2.theta = 0.01,
  tau.alpha = 0.001,
  tau.beta = 0.001,
  k1max = 100,
  k2max = 100,
  L = 20,
  bernstein1_l = 0.1,
  bernstein1_r = 0.9,
  bernstein2_l = 0.1,
  bernstein2_r = 0.9
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_m">M</code></td>
<td>
<p>DP base measure constant (&gt; 0)</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_g0.alpha">g0.alpha</code>, <code id="bdp_dw_prior_params_gen_+3A_g0.beta">g0.beta</code></td>
<td>
<p>parameters of Beta base measure of DP</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_k1.theta">k1.theta</code></td>
<td>
<p>prior parameter for polynomial corresponding to rescaled time (propto exp(-k1.theta*k1*log(k1)))</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_k2.theta">k2.theta</code></td>
<td>
<p>prior parameter for polynomial corresponding to rescaled frequency (propto exp(-k2.theta*k2*log(k2)))</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_tau.alpha">tau.alpha</code>, <code id="bdp_dw_prior_params_gen_+3A_tau.beta">tau.beta</code></td>
<td>
<p>prior parameters for tau (inverse gamma)</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_k1max">k1max</code></td>
<td>
<p>upper bound of the degrees of Bernstein polynomial
corresponding to rescaled time (for pre-computation of basis functions)</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_k2max">k2max</code></td>
<td>
<p>upper bound of the degrees of Bernstein polynomial
corresponding to rescaled frequency (for pre-computation of basis functions)</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_l">L</code></td>
<td>
<p>truncation parameter of DP in stick breaking representation</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_bernstein1_l">bernstein1_l</code>, <code id="bdp_dw_prior_params_gen_+3A_bernstein1_r">bernstein1_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions
for rescaled time, 0&lt;=bernstein1_l&lt;bernstein1_r&lt;=1</p>
</td></tr>
<tr><td><code id="bdp_dw_prior_params_gen_+3A_bernstein2_l">bernstein2_l</code>, <code id="bdp_dw_prior_params_gen_+3A_bernstein2_r">bernstein2_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions
for rescaled frequency, 0&lt;=bernstein2_l&lt;bernstein2_r&lt;=1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of prior parameter values
</p>

<hr>
<h2 id='betaBasis_k'>Construct Bernstein polynomial basis of degree k on omega</h2><span id='topic+betaBasis_k'></span>

<h3>Description</h3>

<p>Construct Bernstein polynomial basis of degree k on omega
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaBasis_k(omega, k, coarsened)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betaBasis_k_+3A_omega">omega</code></td>
<td>
<p>numeric vector in [0,1] of evaluation points</p>
</td></tr>
<tr><td><code id="betaBasis_k_+3A_k">k</code></td>
<td>
<p>positive integer for the degree</p>
</td></tr>
<tr><td><code id="betaBasis_k_+3A_coarsened">coarsened</code></td>
<td>
<p>bool flag indicating whether coarsened or standard Bernstein polynomials are used</p>
</td></tr>
</table>

<hr>
<h2 id='betaBasis_k_dw'>Construct Bernstein polynomial basis of degree k on omega</h2><span id='topic+betaBasis_k_dw'></span>

<h3>Description</h3>

<p>Construct Bernstein polynomial basis of degree k on omega
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaBasis_k_dw(omega, k, bernstein_l = 0, bernstein_r = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betaBasis_k_dw_+3A_omega">omega</code></td>
<td>
<p>numeric vector in <code class="reqn">[0,1]</code> of evaluation points</p>
</td></tr>
<tr><td><code id="betaBasis_k_dw_+3A_k">k</code></td>
<td>
<p>positive integer for the degree</p>
</td></tr>
<tr><td><code id="betaBasis_k_dw_+3A_bernstein_l">bernstein_l</code></td>
<td>
<p>left boundary of the dilated Bernstein polynomials</p>
</td></tr>
<tr><td><code id="betaBasis_k_dw_+3A_bernstein_r">bernstein_r</code></td>
<td>
<p>right boundary of the dilated Bernstein polynomials</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
omega &lt;- seq(0, 1, by = 0.01)
betaBasis_k_dw(omega, 100, 0.1, 0.9)

## End(Not run)
</code></pre>

<hr>
<h2 id='beyondWhittle-package'>
Bayesian spectral inference for time series
</h2><span id='topic+beyondWhittle-package'></span><span id='topic+beyondWhittle'></span>

<h3>Description</h3>

<p>Bayesian parametric, nonparametric and semiparametric procedures for spectral density inference of univariate (locally) stationary time series and multivariate stationary time series
</p>


<h3>Details</h3>

<p>The package contains several methods (parametric, nonparametric and semiparametric) for Bayesian spectral density inference.
The main algorithms to fit the models for univariate stationary time series are:
</p>

<ul>
<li> <p><a href="#topic+gibbs_ar">gibbs_ar</a>: Parametric, autoregressive (AR) model
</p>
</li>
<li> <p><a href="#topic+gibbs_np">gibbs_np</a>: Nonparametric model with Whittle's likelihood and Bernstein-Dirichlet prior from Choudhuri et al (2007)
</p>
</li>
<li> <p><a href="#topic+gibbs_npc">gibbs_npc</a>: Semiparametric model with corrected AR likelihood and Bernstein-Dirichlet prior from Kirch et al (2018)
</p>
</li></ul>

<p>The package also contains the following models for multivariate stationary time series:
</p>

<ul>
<li> <p><a href="#topic+gibbs_var">gibbs_var</a>: Parametric, vector autoregressive (VAR) model
</p>
</li>
<li> <p><a href="#topic+gibbs_vnp">gibbs_vnp</a>: Nonparametric model with Whittle's likelihood and Bernstein-Hpd-Gamma prior from Meier (2018)
</p>
</li></ul>

<p>The main function for univariate locally stationary time series is:
</p>

<ul>
<li> <p><a href="#topic+gibbs_bdp_dw">gibbs_bdp_dw</a>: Nonparametric model with BDP-DW approach from Tang et al (2023)
</p>
</li></ul>

<p>as well as some useful utility functions.
To get started, it is recommended to consider the examples and documentation of the functions listed above.
The work was supported by DFG grants KI 1443/3-1 and KI 1443/3-2.
</p>


<h3>Author(s)</h3>

<p>Claudia Kirch, Renate Meyer, Matthew C. Edwards, Alexander Meier, Yifu Tang
</p>
<p>Maintainer: Renate Meyer &lt;renate.meyer@auckland.ac.nz&gt;
</p>


<h3>References</h3>

<p>N. Choudhuri, S. Ghosal and A. Roy (2004)
<em>Bayesian estimation of the spectral density of a time series</em>
JASA
&lt;doi:10.1198/016214504000000557&gt;
</p>
<p>C. Kirch, M. C. Edwards, A. Meier and R. Meyer (2018)
<em>Beyond Whittle: Nonparametric Correction of a Parametric Likelihood with a Focus on Bayesian Time Series Analysis</em>
Bayesian Analysis
&lt;doi:10.1214/18-BA1126&gt;
</p>
<p>A. Meier (2018)
<em>A matrix Gamma process and applications to Bayesian analysis of multivariate time series</em>
PhD thesis, OvGU Magdeburg
&lt;doi:10.25673/13407&gt;
</p>
<p>Y. Tang, C. Kirch, J. E. Lee and R. Meyer (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>

<hr>
<h2 id='center'>mean center a numerical vector</h2><span id='topic+center'></span>

<h3>Description</h3>

<p>mean center a numerical vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center(x, ...)
</code></pre>

<hr>
<h2 id='coarsened_bernstein'>Construct coarsened Bernstein polynomial basis of degree l on omega</h2><span id='topic+coarsened_bernstein'></span>

<h3>Description</h3>

<p>Construct coarsened Bernstein polynomial basis of degree l on omega
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coarsened_bernstein(omega, l)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coarsened_bernstein_+3A_omega">omega</code></td>
<td>
<p>numeric vector in [0,1] of evaluation points</p>
</td></tr>
<tr><td><code id="coarsened_bernstein_+3A_l">l</code></td>
<td>
<p>positive integer for the degree</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Appendix E.1 in Ghosal/Van der Vaart, Fundamentals, (2017)
</p>

<hr>
<h2 id='coarsened_bernstein_i'>Helping function for <code>coarsened_bernstein</code></h2><span id='topic+coarsened_bernstein_i'></span>

<h3>Description</h3>

<p>Helping function for <code>coarsened_bernstein</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coarsened_bernstein_i(omega, l, i)
</code></pre>

<hr>
<h2 id='complexValuedPsd'>Inverse function to realValuedPsd</h2><span id='topic+complexValuedPsd'></span>

<h3>Description</h3>

<p>Inverse function to realValuedPsd
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complexValuedPsd(f_)
</code></pre>

<hr>
<h2 id='cube_from_NumericVector'>I/O: Only used within Rcpp
Note: Same workaround as <code>cx_cube_from_ComplexVector</code></h2><span id='topic+cube_from_NumericVector'></span>

<h3>Description</h3>

<p>I/O: Only used within Rcpp
Note: Same workaround as <code>cx_cube_from_ComplexVector</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cube_from_NumericVector(x)
</code></pre>

<hr>
<h2 id='cx_cube_from_ComplexVector'>I/O: Only used within Rcpp</h2><span id='topic+cx_cube_from_ComplexVector'></span>

<h3>Description</h3>

<p>This workaround for parsing cubes was neccessary at development time
because there was a (presumable) bug in RcppArmadillo that sometimes
caused the parsing of arma::cx_cube objects to fail, such that the function
received an un-initialized object instead of the parsed one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cx_cube_from_ComplexVector(x)
</code></pre>


<h3>Details</h3>

<p>The workaround parses an Rcpp vector instead, and manually
copies the data in an arma::cx_cube object.
Besides being redundant, it also makes the code less readable and it is
hoped that this workaround can be removed in future revisions.
</p>

<hr>
<h2 id='dbList'>Construct Bernstein polynomial basises of degree up to kmax on omega</h2><span id='topic+dbList'></span>

<h3>Description</h3>

<p>Construct Bernstein polynomial basises of degree up to kmax on omega
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbList(n, kmax, bernstein_l = 0, bernstein_r = 1, coarsened = F, verbose = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbList_+3A_n">n</code></td>
<td>
<p>positive integer determining the number of the (equidistant) evaluation points in [0,1]</p>
</td></tr>
<tr><td><code id="dbList_+3A_kmax">kmax</code></td>
<td>
<p>positive integer for the largest degree</p>
</td></tr>
<tr><td><code id="dbList_+3A_bernstein_l">bernstein_l</code>, <code id="dbList_+3A_bernstein_r">bernstein_r</code></td>
<td>
<p>left and right truncation</p>
</td></tr>
<tr><td><code id="dbList_+3A_coarsened">coarsened</code></td>
<td>
<p>bool flag indicating whether coarsened or standard Bernstein polynomials are used</p>
</td></tr>
<tr><td><code id="dbList_+3A_verbose">verbose</code></td>
<td>
<p>debugging parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length kmax, where the k-th list element is a matrix containing the polynomial basis of degree k
</p>

<hr>
<h2 id='dbList_dw_Bern'>Construct Bernstein polynomial bases of degree up to kmax on omega</h2><span id='topic+dbList_dw_Bern'></span>

<h3>Description</h3>

<p>Construct Bernstein polynomial bases of degree up to kmax on omega
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbList_dw_Bern(omega, kmax, bernstein_l = 0, bernstein_r = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbList_dw_Bern_+3A_omega">omega</code></td>
<td>
<p>numeric vector in <code class="reqn">[0,1]</code> of evaluation points</p>
</td></tr>
<tr><td><code id="dbList_dw_Bern_+3A_kmax">kmax</code></td>
<td>
<p>positive integer for the largest degree</p>
</td></tr>
<tr><td><code id="dbList_dw_Bern_+3A_bernstein_l">bernstein_l</code>, <code id="dbList_dw_Bern_+3A_bernstein_r">bernstein_r</code></td>
<td>
<p>left and right truncation related to the dilation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length kmax, where the k-th list element is a matrix containing the polynomial basis of degree k
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
omega &lt;- seq(0, 1, by = 0.01)
dbList_dw_Bern(omega, 100, 0.1, 0.9)

## End(Not run)
</code></pre>

<hr>
<h2 id='dbList_dw_Bern_for_lambda'>Construct Bernstein polynomial bases of degree up to kmax on omega for frequency parameter lambda</h2><span id='topic+dbList_dw_Bern_for_lambda'></span>

<h3>Description</h3>

<p>Construct Bernstein polynomial bases of degree up to kmax on omega for frequency parameter lambda
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbList_dw_Bern_for_lambda(
  omega,
  kmax,
  bernstein_l = 0,
  bernstein_r = 1,
  m,
  time_grid
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbList_dw_Bern_for_lambda_+3A_omega">omega</code></td>
<td>
<p>numeric vector in <code class="reqn">[0,1]</code> of evaluation points</p>
</td></tr>
<tr><td><code id="dbList_dw_Bern_for_lambda_+3A_kmax">kmax</code></td>
<td>
<p>positive integer for the largest degree</p>
</td></tr>
<tr><td><code id="dbList_dw_Bern_for_lambda_+3A_bernstein_l">bernstein_l</code>, <code id="dbList_dw_Bern_for_lambda_+3A_bernstein_r">bernstein_r</code></td>
<td>
<p>left and right truncation related to the dilation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length kmax, where the k-th list element is a matrix containing the polynomial basis of degree k
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
omega &lt;- time_grid &lt;- seq(0, 1, by = 0.01)
dbList_dw_Bern_for_lambda(omega, 100, 0.1, 0.9)

## End(Not run)
</code></pre>

<hr>
<h2 id='densityMixture'>Construct a density mixture from mixture weights and density functions.</h2><span id='topic+densityMixture'></span>

<h3>Description</h3>

<p>Construct a density mixture from mixture weights and density functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityMixture(weights, densities)
</code></pre>

<hr>
<h2 id='epsilon_var'>epsilon process (residuals) of VAR model</h2><span id='topic+epsilon_var'></span>

<h3>Description</h3>

<p>epsilon process (residuals) of VAR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epsilon_var(zt, ar)
</code></pre>

<hr>
<h2 id='fast_ft'>Fast Fourier Transform</h2><span id='topic+fast_ft'></span>

<h3>Description</h3>

<p>Fast Fourier Transform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_ft(x, real = T)
</code></pre>


<h3>Details</h3>

<p>If <code>real</code>: computes F_n X_n with the real-valued Fourier 
transformation matrix F_n (see Section 2.1 in Kirch et al (2018)).
If <code>!real</code>: computes the complex-valued Fourier coefficients 
(see (4.5) in Meier (2018)).
</p>

<hr>
<h2 id='fast_ift'>Fast Inverse Fourier Transform</h2><span id='topic+fast_ift'></span>

<h3>Description</h3>

<p>Fast Inverse Fourier Transform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_ift(x, real = T, TOL = 1e-15)
</code></pre>


<h3>Details</h3>

<p>inverse function of <code>fast_ft</code>
</p>

<hr>
<h2 id='fast_mean'>Help function to compute the mean.</h2><span id='topic+fast_mean'></span>

<h3>Description</h3>

<p>Help function to compute the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_mean(x)
</code></pre>

<hr>
<h2 id='fourier_freq'>Fourier frequencies</h2><span id='topic+fourier_freq'></span>

<h3>Description</h3>

<p>Fourier frequencies on [0,pi], as defined by 2*pi*j/n for j=0,...,floor(n/2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fourier_freq(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fourier_freq_+3A_n">n</code></td>
<td>
<p>integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of length floor(n/2)+1
</p>

<hr>
<h2 id='genEpsARMAC'>Get epsilon process (i.e. model residuals) for ARMA(p,q)</h2><span id='topic+genEpsARMAC'></span>

<h3>Description</h3>

<p>Get epsilon process (i.e. model residuals) for ARMA(p,q)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genEpsARMAC(zt, ar, ma)
</code></pre>

<hr>
<h2 id='get_f_matrix'>Construct psd mixture</h2><span id='topic+get_f_matrix'></span>

<h3>Description</h3>

<p>Construct psd mixture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_f_matrix(U_phi, r, Z, k, dbList)
</code></pre>

<hr>
<h2 id='get_U_cpp'>Get U from phi, vectorized, cpp internal only</h2><span id='topic+get_U_cpp'></span>

<h3>Description</h3>

<p>Get U from phi, vectorized, cpp internal only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_U_cpp(u_phi)
</code></pre>

<hr>
<h2 id='gibbs_ar'>Gibbs sampler for an autoregressive model with PACF parametrization.</h2><span id='topic+gibbs_ar'></span>

<h3>Description</h3>

<p>Obtain samples of the posterior of a Bayesian autoregressive model of fixed order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_ar(
  data,
  ar.order,
  Ntotal,
  burnin,
  thin = 1,
  print_interval = 500,
  numerical_thresh = 1e-07,
  adaption.N = burnin,
  adaption.batchSize = 50,
  adaption.tar = 0.44,
  full_lik = F,
  rho.alpha = rep(1, ar.order),
  rho.beta = rep(1, ar.order),
  sigma2.alpha = 0.001,
  sigma2.beta = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_ar_+3A_data">data</code></td>
<td>
<p>numeric vector; NA values are interpreted as missing values and treated as random</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive model (integer &gt;= 0)</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_thin">thin</code></td>
<td>
<p>thinning number (postprocessing)</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_print_interval">print_interval</code></td>
<td>
<p>Number of iterations, after which a status is printed to console</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_numerical_thresh">numerical_thresh</code></td>
<td>
<p>Lower (numerical pointwise) bound for the spectral density</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_adaption.n">adaption.N</code></td>
<td>
<p>total number of iterations, in which the proposal variances (of rho) are adapted</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_adaption.batchsize">adaption.batchSize</code></td>
<td>
<p>batch size of proposal adaption for the rho_i's (PACF)</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_adaption.tar">adaption.tar</code></td>
<td>
<p>target acceptance rate for the rho_i's (PACF)</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_full_lik">full_lik</code></td>
<td>
<p>logical; if TRUE, the full likelihood for all observations is used; if FALSE, the partial likelihood for the last n-p observations</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_rho.alpha">rho.alpha</code>, <code id="gibbs_ar_+3A_rho.beta">rho.beta</code></td>
<td>
<p>prior parameters for the rho_i's: 2*(rho-0.5)~Beta(rho.alpha,rho.beta), default is Uniform(-1,1)</p>
</td></tr>
<tr><td><code id="gibbs_ar_+3A_sigma2.alpha">sigma2.alpha</code>, <code id="gibbs_ar_+3A_sigma2.beta">sigma2.beta</code></td>
<td>
<p>prior parameters for sigma2 (inverse gamma)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Partial Autocorrelation Structure (PACF, uniform prior) and the residual variance sigma2 (inverse gamma prior) is used as model parametrization.
The DIC is computed with two times the posterior variance of the deviance as effective number of parameters, see (7.10) in the referenced book by Gelman et al.
Further details can be found in the simulation study section in the referenced paper by C. Kirch et al.
For more information on the PACF parametrization, see the referenced paper by Barndorff-Nielsen and Schou.
</p>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>rho</code></td>
<td>
<p>matrix containing traces of the PACF parameters (if p&gt;0)</p>
</td></tr>
<tr><td><code>sigma2</code></td>
<td>
<p>trace of sigma2</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>a list containing the numeric value <code>DIC</code> of the Deviance Information Criterion (DIC) and the effective number of parameters <code>ENP</code></p>
</td></tr>
<tr><td><code>psd.median</code>, <code>psd.mean</code></td>
<td>
<p>psd estimates: (pointwise) posterior median and mean</p>
</td></tr>
<tr><td><code>psd.p05</code>, <code>psd.p95</code></td>
<td>
<p>pointwise credibility interval</p>
</td></tr>
<tr><td><code>psd.u05</code>, <code>psd.u95</code></td>
<td>
<p>uniform credibility interval</p>
</td></tr>
<tr><td><code>lpost</code></td>
<td>
<p>trace of log posterior</p>
</td></tr>
</table>


<h3>References</h3>

<p>C. Kirch et al. (2018)
<em>Beyond Whittle: Nonparametric Correction of a Parametric Likelihood With a Focus on Bayesian Time Series Analysis</em>
Bayesian Analysis
&lt;doi:10.1214/18-BA1126&gt;
</p>
<p>A. Gelman et al. (2013)
<em>Bayesian Data Analysis, Third Edition</em>
</p>
<p>O. Barndorff-Nielsen and G. Schou
On the parametrization of autoregressive models by partial autocorrelations
Journal of Multivariate Analysis (3),408-419
&lt;doi:10.1016/0047-259X(73)90030-4&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##
## Example 1: Fit an AR(p) model to sunspot data:
##

# Use this variable to set the AR model order
p &lt;- 2

data &lt;- sqrt(as.numeric(sunspot.year))
data &lt;- data - mean(data)

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_ar(data=data, ar.order=p, Ntotal=10000, burnin=4000, thin=2)

# Plot spectral estimate, credible regions and periodogram on log-scale
plot(mcmc, log=T)


##
## Example 2: Fit an AR(p) model to high-peaked AR(1) data
##

# Use this variable to set the AR model order
p &lt;- 1

n &lt;- 256
data &lt;- arima.sim(n=n, model=list(ar=0.95)) 
data &lt;- data - mean(data)
omega &lt;- fourier_freq(n)
psd_true &lt;- psd_arma(omega, ar=0.95, ma=numeric(0), sigma2=1)

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_ar(data=data, ar.order=p, Ntotal=10000, burnin=4000, thin=2)

# Compare estimate with true function (green)
plot(mcmc, log=F, pdgrm=F, credib="uniform")
lines(x=omega, y=psd_true, col=3, lwd=2)

# Compute the Integrated Absolute Error (IAE) of posterior median
cat("IAE=", mean(abs(mcmc$psd.median-psd_true)[-1]) , sep="")

## End(Not run)
</code></pre>

<hr>
<h2 id='gibbs_AR_nuisance_intern'>Gibbs sampler for Bayesian AR model in PACF parametrization,
including support for TS to be a nuisance parameter</h2><span id='topic+gibbs_AR_nuisance_intern'></span>

<h3>Description</h3>

<p>Gibbs sampler for Bayesian AR model in PACF parametrization,
including support for TS to be a nuisance parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_AR_nuisance_intern(
  data,
  mcmc_params,
  prior_params,
  model_params,
  full_lik = F
)
</code></pre>

<hr>
<h2 id='gibbs_bdp_dw'>BDP-DW method: performing posterior sampling and calculating statistics based on the posterior samples</h2><span id='topic+gibbs_bdp_dw'></span>

<h3>Description</h3>

<p>BDP-DW method: performing posterior sampling and calculating statistics based on the posterior samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_bdp_dw(
  data,
  m,
  likelihood_thinning = 1,
  monitor = TRUE,
  print_interval = 100,
  unif_CR = FALSE,
  res_time,
  freq,
  Ntotal = 110000,
  burnin = 60000,
  thin = 10,
  adaptive.batchSize = 50,
  adaptive.targetAcceptanceRate = 0.44,
  M = 1,
  g0.alpha = 1,
  g0.beta = 1,
  k1.theta = 0.01,
  k2.theta = 0.01,
  tau.alpha = 0.001,
  tau.beta = 0.001,
  k1max = 100,
  k2max = 100,
  L = 20,
  bernstein1_l = 0.1,
  bernstein1_r = 0.9,
  bernstein2_l = 0.1,
  bernstein2_r = 0.9
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_bdp_dw_+3A_data">data</code></td>
<td>
<p>time series that needs to be analyzed</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_m">m</code></td>
<td>
<p>window size needed to calculate moving periodogram.</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_likelihood_thinning">likelihood_thinning</code></td>
<td>
<p>the thinning factor of the dynamic Whittle likelihood.</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_monitor">monitor</code></td>
<td>
<p>a Boolean value (default TRUE) indicating whether to display the real-time status</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_print_interval">print_interval</code></td>
<td>
<p>If monitor = TRUE, then this value indicates number of iterations after which a status is printed to console;
If monitor = FALSE, it does not have any effect</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_unif_cr">unif_CR</code></td>
<td>
<p>a Boolean value (default FALSE) indicating whether to calculate the uniform credible region</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_res_time">res_time</code>, <code id="gibbs_bdp_dw_+3A_freq">freq</code></td>
<td>
<p>a set of grid lines in <code class="reqn">[0,1]</code> and <code class="reqn">[0,\pi]</code>, respectively, specifying where to evaluate the estimated tv-PSD</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_thin">thin</code></td>
<td>
<p>thinning number (for post-processing of the posterior sample)</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_adaptive.batchsize">adaptive.batchSize</code></td>
<td>
<p>the batch size for the adaptive MCMC algorithm for sampling tau</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_adaptive.targetacceptancerate">adaptive.targetAcceptanceRate</code></td>
<td>
<p>the target acceptance rate for the adaptive MCMC algorithm for sampling tau</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_m">M</code></td>
<td>
<p>DP base measure constant (&gt; 0)</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_g0.alpha">g0.alpha</code>, <code id="gibbs_bdp_dw_+3A_g0.beta">g0.beta</code></td>
<td>
<p>parameters of Beta base measure of DP</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_k1.theta">k1.theta</code></td>
<td>
<p>prior parameter for polynomial corresponding to rescaled time (propto exp(-k1.theta*k1*log(k1)))</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_k2.theta">k2.theta</code></td>
<td>
<p>prior parameter for polynomial corresponding to rescaled frequency (propto exp(-k2.theta*k2*log(k2)))</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_tau.alpha">tau.alpha</code>, <code id="gibbs_bdp_dw_+3A_tau.beta">tau.beta</code></td>
<td>
<p>prior parameters for tau (inverse gamma)</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_k1max">k1max</code></td>
<td>
<p>upper bound of the degrees of Bernstein polynomial
corresponding to rescaled time (for pre-computation of basis functions)</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_k2max">k2max</code></td>
<td>
<p>upper bound of the degrees of Bernstein polynomial
corresponding to rescaled frequency (for pre-computation of basis functions)</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_l">L</code></td>
<td>
<p>truncation parameter of DP in stick breaking representation</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_bernstein1_l">bernstein1_l</code>, <code id="gibbs_bdp_dw_+3A_bernstein1_r">bernstein1_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions
for rescaled time, 0&lt;=bernstein1_l&lt;bernstein1_r&lt;=1</p>
</td></tr>
<tr><td><code id="gibbs_bdp_dw_+3A_bernstein2_l">bernstein2_l</code>, <code id="gibbs_bdp_dw_+3A_bernstein2_r">bernstein2_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions
for rescaled frequency, 0&lt;=bernstein2_l&lt;bernstein2_r&lt;=1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>k1</code>, <code>k2</code>, <code>tau</code>, <code>V</code>, <code>W1</code>, <code>W2</code></td>
<td>
<p>posterior traces of PSD parameters</p>
</td></tr>
<tr><td><code>lpost</code></td>
<td>
<p>traces log posterior</p>
</td></tr>
<tr><td><code>tim</code></td>
<td>
<p>total run time</p>
</td></tr>
<tr><td><code>bf_k1</code></td>
<td>
<p>Savage-Dickey estimate of Bayes factor of hypothesis k1=1</p>
</td></tr>
<tr><td><code>tvpsd.mean</code>, <code>tvpsd.median</code></td>
<td>
<p>posterior mean and pointwise posterior median (matrices of dimension length(rescaled_time) by length(freq))</p>
</td></tr>
<tr><td><code>tvpsd.p05</code>, <code>tvpsd.p95</code></td>
<td>
<p>90 percent pointwise credibility interval</p>
</td></tr>
<tr><td><code>tvpsd.u05</code>, <code>tvpsd.u95</code></td>
<td>
<p>90 percent uniform credibility interval if unif_CR = TRUE. Otherwise NA</p>
</td></tr>
</table>


<h3>References</h3>

<p>Tang et al. (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##
## Example: Applying BDP-DW method to a multi-peaked tvMA(1) process
##

# set seed
set.seed(200)
# set the length of time series
len_d &lt;- 1500
# generate data from DGP LS2c defined in Section 4.2.2 of Tang et al. (2023). 
# see also ?sim_tvarma12
sim_data &lt;- sim_tvarma12(len_d = 1500, dgp = "LS2", innov_distribution = "c")
# specify grid-points at which the tv-PSD is evaluated
res_time &lt;- seq(0, 1, by = 0.005); freq &lt;- pi * seq(0, 1, by = 0.01)
# calculate the true tv-PSD of DGP LS2c at the pre-specified grid
true_tvPSD &lt;- psd_tvarma12(rescaled_time = res_time, freq = freq, dgp = "LS2")
# plot the true tv-PSD
# type ?plot.bdp_dw_tv_psd for more info
plot(true_tvPSD)

# If you run the example be aware that this may take several minutes
print("This example may take some time to run")
result &lt;- gibbs_bdp_dw(data = sim_data, 
m = 50, 
likelihood_thinning = 2, 
rescaled_time = res_time,
 freq = freq)

# extract bayes factor and examine posterior summary
bayes_factor(result)
summary(result)

# compare estimate with true function
# type ?plot.bdp_dw_result for more info
par(mfrow = c(1,2))

plot(result, which = 1,
zlim = range(result$tvpsd.mean, true_tvPSD$tv_psd)
)
plot(true_tvPSD,
zlim = range(result$tvpsd.mean, true_tvPSD$tv_psd),
main = "true tv-PSD")

par(mfrow = c(1,1))


## End(Not run)
</code></pre>

<hr>
<h2 id='gibbs_multivariate_nuisance'>Gibbs sampler for corrected parametric likelihood + Bernstein-Dirichlet mixture,
including possibility of using time series as mere nuisance parameter
Multivariate case</h2><span id='topic+gibbs_multivariate_nuisance'></span>

<h3>Description</h3>

<p>Gibbs sampler for corrected parametric likelihood + Bernstein-Dirichlet mixture,
including possibility of using time series as mere nuisance parameter
Multivariate case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_multivariate_nuisance(
  data,
  mcmc_params,
  corrected,
  prior_params,
  model_params
)
</code></pre>

<hr>
<h2 id='gibbs_multivariate_nuisance_cpp'>Gibbs sampler in Cpp</h2><span id='topic+gibbs_multivariate_nuisance_cpp'></span>

<h3>Description</h3>

<p>Gibbs sampler in Cpp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_multivariate_nuisance_cpp(
  data,
  NA_pos,
  FZ,
  eps_r,
  eps_Z,
  eps_U,
  k_0,
  r_0,
  Z_0,
  U_phi_0,
  phi_def,
  eta,
  omega,
  Sigma,
  Ntotal,
  print_interval,
  numerical_thresh,
  verbose,
  L,
  k_theta,
  dbList
)
</code></pre>

<hr>
<h2 id='gibbs_np'>Gibbs sampler for Bayesian nonparametric inference with Whittle likelihood</h2><span id='topic+gibbs_np'></span>

<h3>Description</h3>

<p>Obtain samples of the posterior of the Whittle likelihood in conjunction with a Bernstein-Dirichlet prior on the spectral density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_np(
  data,
  Ntotal,
  burnin,
  thin = 1,
  print_interval = 100,
  numerical_thresh = 1e-07,
  M = 1,
  g0.alpha = 1,
  g0.beta = 1,
  k.theta = 0.01,
  tau.alpha = 0.001,
  tau.beta = 0.001,
  kmax = 100 * coars + 500 * (!coars),
  trunc_l = 0.1,
  trunc_r = 0.9,
  coars = F,
  L = max(20, length(data)^(1/3))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_np_+3A_data">data</code></td>
<td>
<p>numeric vector; NA values are interpreted as missing values and treated as random</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_thin">thin</code></td>
<td>
<p>thinning number (postprocessing)</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_print_interval">print_interval</code></td>
<td>
<p>Number of iterations, after which a status is printed to console</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_numerical_thresh">numerical_thresh</code></td>
<td>
<p>Lower (numerical pointwise) bound for the spectral density</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_m">M</code></td>
<td>
<p>DP base measure constant (&gt; 0)</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_g0.alpha">g0.alpha</code>, <code id="gibbs_np_+3A_g0.beta">g0.beta</code></td>
<td>
<p>parameters of Beta base measure of DP</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_k.theta">k.theta</code></td>
<td>
<p>prior parameter for polynomial degree k (propto exp(-k.theta*k*log(k)))</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_tau.alpha">tau.alpha</code>, <code id="gibbs_np_+3A_tau.beta">tau.beta</code></td>
<td>
<p>prior parameters for tau (inverse gamma)</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_kmax">kmax</code></td>
<td>
<p>upper bound for polynomial degree of Bernstein-Dirichlet mixture (can be set to Inf, algorithm is faster with kmax&lt;Inf due to pre-computation of basis functions, but values 500&lt;kmax&lt;Inf are very memory intensive)</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_trunc_l">trunc_l</code>, <code id="gibbs_np_+3A_trunc_r">trunc_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions, 0&lt;=trunc_l&lt;trunc_r&lt;=1</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_coars">coars</code></td>
<td>
<p>flag indicating whether coarsened or default bernstein polynomials are used (see Appendix E.1 in Ghosal and van der Vaart 2017)</p>
</td></tr>
<tr><td><code id="gibbs_np_+3A_l">L</code></td>
<td>
<p>truncation parameter of DP in stick breaking representation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Further details can be found in the simulation study section in the references papers.
</p>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>psd.median</code>, <code>psd.mean</code></td>
<td>
<p>psd estimates: (pointwise) posterior median and mean</p>
</td></tr>
<tr><td><code>psd.p05</code>, <code>psd.p95</code></td>
<td>
<p>pointwise credibility interval</p>
</td></tr>
<tr><td><code>psd.u05</code>, <code>psd.u95</code></td>
<td>
<p>uniform credibility interval</p>
</td></tr>
<tr><td><code>k</code>, <code>tau</code>, <code>V</code>, <code>W</code></td>
<td>
<p>posterior traces of PSD parameters</p>
</td></tr>
<tr><td><code>lpost</code></td>
<td>
<p>trace of log posterior</p>
</td></tr>
</table>


<h3>References</h3>

<p>C. Kirch et al. (2018)
<em>Beyond Whittle: Nonparametric Correction of a Parametric Likelihood With a Focus on Bayesian Time Series Analysis</em>
Bayesian Analysis
&lt;doi:10.1214/18-BA1126&gt;
</p>
<p>N. Choudhuri et al. (2004)
<em>Bayesian Estimation of the Spectral Density of a Time Series</em>
JASA
&lt;doi:10.1198/016214504000000557&gt;
</p>
<p>S. Ghosal and A. van der Vaart (2017)
<em>Fundamentals of Nonparametric Bayesian Inference</em> &lt;doi:10.1017/9781139029834&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##
## Example 1: Fit the NP model to sunspot data:
##

data &lt;- sqrt(as.numeric(sunspot.year))
data &lt;- data - mean(data)

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_np(data=data, Ntotal=10000, burnin=4000, thin=2)

# Plot spectral estimate, credible regions and periodogram on log-scale
plot(mcmc, log=T)


##
## Example 2: Fit the NP model to high-peaked AR(1) data
##

n &lt;- 256
data &lt;- arima.sim(n=n, model=list(ar=0.95)) 
data &lt;- data - mean(data)
omega &lt;- fourier_freq(n)
psd_true &lt;- psd_arma(omega, ar=0.95, ma=numeric(0), sigma2=1)

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_np(data=data, Ntotal=10000, burnin=4000, thin=2)

# Compare estimate with true function (green)
plot(mcmc, log=F, pdgrm=F, credib="uniform")
lines(x=omega, y=psd_true, col=3, lwd=2)

# Compute the Integrated Absolute Error (IAE) of posterior median
cat("IAE=", mean(abs(mcmc$psd.median-psd_true)[-1]) , sep="")

## End(Not run)
</code></pre>

<hr>
<h2 id='gibbs_npc'>Gibbs sampler for Bayesian semiparametric inference with the corrected AR likelihood</h2><span id='topic+gibbs_npc'></span>

<h3>Description</h3>

<p>Obtain samples of the posterior of the corrected autoregressive likelihood in conjunction with a Bernstein-Dirichlet prior on the correction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_npc(
  data,
  ar.order,
  Ntotal,
  burnin,
  thin = 1,
  print_interval = 100,
  numerical_thresh = 1e-07,
  adaption.N = burnin,
  adaption.batchSize = 50,
  adaption.tar = 0.44,
  full_lik = F,
  rho.alpha = rep(1, ar.order),
  rho.beta = rep(1, ar.order),
  eta = T,
  M = 1,
  g0.alpha = 1,
  g0.beta = 1,
  k.theta = 0.01,
  tau.alpha = 0.001,
  tau.beta = 0.001,
  trunc_l = 0.1,
  trunc_r = 0.9,
  coars = F,
  kmax = 100 * coars + 500 * (!coars),
  L = max(20, length(data)^(1/3))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_npc_+3A_data">data</code></td>
<td>
<p>numeric vector; NA values are interpreted as missing values and treated as random</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive model (integer &gt; 0)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_thin">thin</code></td>
<td>
<p>thinning number (postprocessing)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_print_interval">print_interval</code></td>
<td>
<p>Number of iterations, after which a status is printed to console</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_numerical_thresh">numerical_thresh</code></td>
<td>
<p>Lower (numerical pointwise) bound for the spectral density</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_adaption.n">adaption.N</code></td>
<td>
<p>total number of iterations, in which the proposal variances (of rho) are adapted</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_adaption.batchsize">adaption.batchSize</code></td>
<td>
<p>batch size of proposal adaption for the rho_i's (PACF)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_adaption.tar">adaption.tar</code></td>
<td>
<p>target acceptance rate for the rho_i's (PACF)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_full_lik">full_lik</code></td>
<td>
<p>logical; if TRUE, the full likelihood for all observations is used; if FALSE, the partial likelihood for the last n-p observations</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_rho.alpha">rho.alpha</code>, <code id="gibbs_npc_+3A_rho.beta">rho.beta</code></td>
<td>
<p>prior parameters for the rho_i's: 2*(rho-0.5)~Beta(rho.alpha,rho.beta), default is Uniform(-1,1)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_eta">eta</code></td>
<td>
<p>logical variable indicating whether the model confidence eta 
should be included in the inference (eta=T) or fixed to 1 (eta=F)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_m">M</code></td>
<td>
<p>DP base measure constant (&gt; 0)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_g0.alpha">g0.alpha</code>, <code id="gibbs_npc_+3A_g0.beta">g0.beta</code></td>
<td>
<p>parameters of Beta base measure of DP</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_k.theta">k.theta</code></td>
<td>
<p>prior parameter for polynomial degree k (propto exp(-k.theta*k*log(k)))</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_tau.alpha">tau.alpha</code>, <code id="gibbs_npc_+3A_tau.beta">tau.beta</code></td>
<td>
<p>prior parameters for tau (inverse gamma)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_trunc_l">trunc_l</code>, <code id="gibbs_npc_+3A_trunc_r">trunc_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions, 0&lt;=trunc_l&lt;trunc_r&lt;=1</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_coars">coars</code></td>
<td>
<p>flag indicating whether coarsened or default bernstein polynomials are used (see Appendix E.1 in Ghosal and van der Vaart 2017)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_kmax">kmax</code></td>
<td>
<p>upper bound for polynomial degree of Bernstein-Dirichlet mixture (can be set to Inf, algorithm is faster with kmax&lt;Inf due to pre-computation of basis functions, but values 500&lt;kmax&lt;Inf are very memory intensive)</p>
</td></tr>
<tr><td><code id="gibbs_npc_+3A_l">L</code></td>
<td>
<p>truncation parameter of DP in stick breaking representation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Partial Autocorrelation Structure (PACF, uniform prior) and the residual variance sigma2 (inverse gamma prior) is used as model parametrization.
A Bernstein-Dirichlet prior for c_eta with base measure Beta(g0.alpha, g0.beta) is used.
Further details can be found in the simulation study section in the referenced paper by Kirch et al.
For more information on the PACF parametrization, see the referenced paper by Barndorff-Nielsen and Schou.
</p>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>psd.median</code>, <code>psd.mean</code></td>
<td>
<p>psd estimates: (pointwise) posterior median and mean</p>
</td></tr>
<tr><td><code>psd.p05</code>, <code>psd.p95</code></td>
<td>
<p>pointwise credibility interval</p>
</td></tr>
<tr><td><code>psd.u05</code>, <code>psd.u95</code></td>
<td>
<p>uniform credibility interval</p>
</td></tr>
<tr><td><code>k</code>, <code>tau</code>, <code>V</code>, <code>W</code></td>
<td>
<p>posterior traces of nonparametric correction</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>posterior trace of model AR parameters (PACF parametrization)</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>posterior trace of model confidence eta</p>
</td></tr>
<tr><td><code>lpost</code></td>
<td>
<p>trace of log posterior</p>
</td></tr>
</table>


<h3>References</h3>

<p>C. Kirch et al. (2018)
<em>Beyond Whittle: Nonparametric Correction of a Parametric Likelihood With a Focus on Bayesian Time Series Analysis</em>
Bayesian Analysis
&lt;doi:10.1214/18-BA1126&gt;
</p>
<p>S. Ghosal and A. van der Vaart (2017)
<em>Fundamentals of Nonparametric Bayesian Inference</em> &lt;doi:10.1017/9781139029834&gt;
</p>
<p>O. Barndorff-Nielsen and G. Schou
On the parametrization of autoregressive models by partial autocorrelations
Journal of Multivariate Analysis (3),408-419
&lt;doi:10.1016/0047-259X(73)90030-4&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##
## Example 1: Fit a nonparametrically corrected AR(p) model to sunspot data:
##

# Use this variable to set the AR model order
p &lt;- 2

data &lt;- sqrt(as.numeric(sunspot.year))
data &lt;- data - mean(data)

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_npc(data=data, ar.order=p, Ntotal=10000, burnin=4000, thin=2)

# Plot spectral estimate, credible regions and periodogram on log-scale
plot(mcmc, log=T)


##
## Example 2: Fit a nonparametrically corrected AR(p) model to high-peaked AR(1) data
##

# Use this variable to set the autoregressive model order
p &lt;- 1

n &lt;- 256
data &lt;- arima.sim(n=n, model=list(ar=0.95)) 
data &lt;- data - mean(data)
omega &lt;- fourier_freq(n)
psd_true &lt;- psd_arma(omega, ar=0.95, ma=numeric(0), sigma2=1)

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_npc(data=data, ar.order=p, Ntotal=10000, burnin=4000, thin=2)

# Compare estimate with true function (green)
plot(mcmc, log=F, pdgrm=F, credib="uniform")
lines(x=omega, y=psd_true, col=3, lwd=2)

# Compute the Integrated Absolute Error (IAE) of posterior median
cat("IAE=", mean(abs(mcmc$psd.median-psd_true)[-1]) , sep="")

## End(Not run)
</code></pre>

<hr>
<h2 id='gibbs_nuisance'>Gibbs sampler for corrected parametric likelihood + Bernstein-Dirichlet mixture,
including possibility of using time series as mere nuisance parameter</h2><span id='topic+gibbs_nuisance'></span>

<h3>Description</h3>

<p>Gibbs sampler for corrected parametric likelihood + Bernstein-Dirichlet mixture,
including possibility of using time series as mere nuisance parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_nuisance(
  data,
  mcmc_params,
  corrected,
  prior_params,
  model_params,
  full_lik = NULL
)
</code></pre>

<hr>
<h2 id='gibbs_var'>Gibbs sampler for vector autoregressive model.</h2><span id='topic+gibbs_var'></span>

<h3>Description</h3>

<p>Obtain samples of the posterior of a Bayesian VAR model of fixed order.
An independent Normal-Inverse-Wishart prior is employed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_var(
  data,
  ar.order,
  Ntotal,
  burnin,
  thin = 1,
  print_interval = 500,
  full_lik = F,
  beta.mu = rep(0, ar.order * ncol(data)^2),
  beta.Sigma = 10000 * diag(ar.order * ncol(data)^2),
  Sigma.S = 1e-04 * diag(ncol(data)),
  Sigma.nu = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_var_+3A_data">data</code></td>
<td>
<p>numeric matrix; NA values are interpreted as missing values and treated as random</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_ar.order">ar.order</code></td>
<td>
<p>order of the autoregressive model (integer &gt;= 0)</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_thin">thin</code></td>
<td>
<p>thinning number (postprocessing)</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_print_interval">print_interval</code></td>
<td>
<p>Number of iterations, after which a status is printed to console</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_full_lik">full_lik</code></td>
<td>
<p>logical; if TRUE, the full likelihood for all observations is used; if FALSE, the partial likelihood for the last n-p observations</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_beta.mu">beta.mu</code></td>
<td>
<p>prior mean of beta vector (normal)</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_beta.sigma">beta.Sigma</code></td>
<td>
<p>prior covariance matrix of beta vector</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_sigma.s">Sigma.S</code></td>
<td>
<p>prior parameter for the innovation covariance matrix, symmetric positive definite matrix</p>
</td></tr>
<tr><td><code id="gibbs_var_+3A_sigma.nu">Sigma.nu</code></td>
<td>
<p>prior parameter for the innovation covariance matrix, nonnegative real number</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Section 2.2.3 in Koop and Korobilis (2010) or Section 6.2 in Meier (2018) for further details
</p>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>matrix containing traces of the VAR parameter vector beta</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>trace of innovation covariance Sigma</p>
</td></tr>
<tr><td><code>psd.median</code>, <code>psd.mean</code></td>
<td>
<p>psd estimates: (pointwise, componentwise) posterior median and mean</p>
</td></tr>
<tr><td><code>psd.p05</code>, <code>psd.p95</code></td>
<td>
<p>pointwise credibility interval</p>
</td></tr>
<tr><td><code>psd.u05</code>, <code>psd.u95</code></td>
<td>
<p>uniform credibility interval, see (6.5) in Meier (2018)</p>
</td></tr>
<tr><td><code>lpost</code></td>
<td>
<p>trace of log posterior</p>
</td></tr>
</table>


<h3>References</h3>

<p>G. Koop and D. Korobilis (2010)
<em>Bayesian Multivariate Time Series Methods for Empirical Macroeconomics</em>
Foundations and Trends in Econometrics
&lt;doi:10.1561/0800000013&gt;
</p>
<p>A. Meier (2018)
<em>A Matrix Gamma Process and Applications to Bayesian Analysis of Multivariate Time Series</em>
PhD thesis, OvGU Magdeburg
&lt;https://opendata.uni-halle.de//handle/1981185920/13470&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##
## Example 1: Fit a VAR(p) model to SOI/Recruitment series:
##

# Use this variable to set the VAR model order
p &lt;- 5

data &lt;- cbind(as.numeric(astsa::soi-mean(astsa::soi)), 
              as.numeric(astsa::rec-mean(astsa::rec)) / 50)
data &lt;- apply(data, 2, function(x) x-mean(x))

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_var(data=data, ar.order=p, Ntotal=10000, burnin=4000, thin=2)

# Plot spectral estimate, credible regions and periodogram on log-scale
plot(mcmc, log=T)



##
## Example 2: Fit a VAR(p) model to VMA(1) data
##

# Use this variable to set the VAR model order
p &lt;- 5

n &lt;- 256
ma &lt;- rbind(c(-0.75, 0.5), c(0.5, 0.75))
Sigma &lt;- rbind(c(1, 0.5), c(0.5, 1))
data &lt;- sim_varma(model=list(ma=ma), n=n, d=2)
data &lt;- apply(data, 2, function(x) x-mean(x))

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_var(data=data, ar.order=p, Ntotal=10000, burnin=4000, thin=2)

# Plot spectral estimate, credible regions and periodogram on log-scale
plot(mcmc, log=T)

## End(Not run)
</code></pre>

<hr>
<h2 id='gibbs_VAR_nuisance_intern'>Gibbs sampling algorithm for VAR model</h2><span id='topic+gibbs_VAR_nuisance_intern'></span>

<h3>Description</h3>

<p>Gibbs sampling algorithm for VAR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_VAR_nuisance_intern(
  data,
  mcmc_params,
  prior_params,
  model_params,
  full_lik = F
)
</code></pre>

<hr>
<h2 id='gibbs_vnp'>Gibbs sampler for multivaiate Bayesian nonparametric inference with Whittle likelihood</h2><span id='topic+gibbs_vnp'></span>

<h3>Description</h3>

<p>Obtain samples of the posterior of the multivariate Whittle likelihood in conjunction with an Hpd AGamma process prior on the spectral density matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_vnp(
  data,
  Ntotal,
  burnin,
  thin = 1,
  print_interval = 100,
  numerical_thresh = 1e-07,
  adaption.N = burnin,
  adaption.batchSize = 50,
  adaption.tar = 0.44,
  eta = ncol(data),
  omega = ncol(data),
  Sigma = 10000 * diag(ncol(data)),
  k.theta = 0.01,
  kmax = 100 * coars + 500 * (!coars),
  trunc_l = 0.1,
  trunc_r = 0.9,
  coars = F,
  L = max(20, length(data)^(1/3))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_vnp_+3A_data">data</code></td>
<td>
<p>numeric matrix; NA values are interpreted as missing values and treated as random</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_ntotal">Ntotal</code></td>
<td>
<p>total number of iterations to run the Markov chain</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_burnin">burnin</code></td>
<td>
<p>number of initial iterations to be discarded</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_thin">thin</code></td>
<td>
<p>thinning number (postprocessing)</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_print_interval">print_interval</code></td>
<td>
<p>Number of iterations, after which a status is printed to console</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_numerical_thresh">numerical_thresh</code></td>
<td>
<p>Lower (numerical pointwise) bound for the eigenvalues of the spectral density</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_adaption.n">adaption.N</code></td>
<td>
<p>total number of iterations, in which the proposal variances (of r and U) are adapted</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_adaption.batchsize">adaption.batchSize</code></td>
<td>
<p>batch size of proposal adaption</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_adaption.tar">adaption.tar</code></td>
<td>
<p>target acceptance rate for adapted parameters</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_eta">eta</code></td>
<td>
<p>AGamma process parameter, real number &gt; ncol(data)-1</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_omega">omega</code></td>
<td>
<p>AGamma process parameter, positive constant</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_sigma">Sigma</code></td>
<td>
<p>AGamma process parameter, Hpd matrix</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_k.theta">k.theta</code></td>
<td>
<p>prior parameter for polynomial degree k (propto exp(-k.theta*k*log(k)))</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_kmax">kmax</code></td>
<td>
<p>upper bound for polynomial degree of Bernstein-Dirichlet mixture (can be set to Inf, algorithm is faster with kmax&lt;Inf due to pre-computation of basis functions, but values 500&lt;kmax&lt;Inf are very memory intensive)</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_trunc_l">trunc_l</code>, <code id="gibbs_vnp_+3A_trunc_r">trunc_r</code></td>
<td>
<p>left and right truncation of Bernstein polynomial basis functions, 0&lt;=trunc_l&lt;trunc_r&lt;=1</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_coars">coars</code></td>
<td>
<p>flag indicating whether coarsened or default bernstein polynomials are used (see Appendix E.1 in Ghosal and van der Vaart 2017)</p>
</td></tr>
<tr><td><code id="gibbs_vnp_+3A_l">L</code></td>
<td>
<p>truncation parameter of Gamma process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A detailed description of the method can be found in Section 5 in Meier (2018).
</p>


<h3>Value</h3>

<p>list containing the following fields:
</p>
<table>
<tr><td><code>r</code>, <code>x</code>, <code>U</code></td>
<td>
<p>traces of the AGamma process parameters</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>posterior trace of polynomial degree</p>
</td></tr>
<tr><td><code>psd.median</code>, <code>psd.mean</code></td>
<td>
<p>psd estimates: (pointwise, componentwise) posterior median and mean</p>
</td></tr>
<tr><td><code>psd.p05</code>, <code>psd.p95</code></td>
<td>
<p>pointwise credibility interval</p>
</td></tr>
<tr><td><code>psd.u05</code>, <code>psd.u95</code></td>
<td>
<p>uniform credibility interval, see (6.5) in Meier (2018)</p>
</td></tr>
<tr><td><code>lpost</code></td>
<td>
<p>trace of log posterior</p>
</td></tr>
</table>


<h3>References</h3>

<p>A. Meier (2018)
<em>A Matrix Gamma Process and Applications to Bayesian Analysis of Multivariate Time Series</em>
PhD thesis, OvGU Magdeburg
&lt;https://opendata.uni-halle.de//handle/1981185920/13470&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##
## Example: Fit multivariate NP model to SOI/Recruitment series:
##

data &lt;- cbind(as.numeric(astsa::soi-mean(astsa::soi)), 
              as.numeric(astsa::rec-mean(astsa::rec)) / 50)
data &lt;- apply(data, 2, function(x) x-mean(x))

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_vnp(data=data, Ntotal=10000, burnin=4000, thin=2)

# Visualize results
plot(mcmc, log=T)


##
## Example 2: Fit multivariate NP model to VMA(1) data
##

n &lt;- 256
ma &lt;- rbind(c(-0.75, 0.5), c(0.5, 0.75))
Sigma &lt;- rbind(c(1, 0.5), c(0.5, 1))
data &lt;- sim_varma(model=list(ma=ma), n=n, d=2)
data &lt;- apply(data, 2, function(x) x-mean(x))

# If you run the example be aware that this may take several minutes
print("example may take some time to run")
mcmc &lt;- gibbs_vnp(data=data, Ntotal=10000, burnin=4000, thin=2)

# Plot spectral estimate, credible regions and periodogram on log-scale
plot(mcmc, log=T)

## End(Not run)
</code></pre>

<hr>
<h2 id='hasEigenValueSmallerZero'>Does a matrix have an eigenvalue smaller than 0?</h2><span id='topic+hasEigenValueSmallerZero'></span>

<h3>Description</h3>

<p>Does a matrix have an eigenvalue smaller than 0?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hasEigenValueSmallerZero(A, TOL = 0)
</code></pre>

<hr>
<h2 id='is_hpd'>Check if a matrix is Hermitian positive definite</h2><span id='topic+is_hpd'></span>

<h3>Description</h3>

<p>Check if a matrix is Hermitian positive definite
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_hpd(A, tol = 1e-15)
</code></pre>

<hr>
<h2 id='is_quadratic'>Is l quadratic?</h2><span id='topic+is_quadratic'></span>

<h3>Description</h3>

<p>Is l quadratic?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_quadratic(l, thresh = 1e-15)
</code></pre>

<hr>
<h2 id='is_spd'>Check if a matrix is symmetric positive definite</h2><span id='topic+is_spd'></span>

<h3>Description</h3>

<p>Check if a matrix is symmetric positive definite
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_spd(A, tol = 1e-05)
</code></pre>

<hr>
<h2 id='lik_ar'>Likelihood of an autoregressive time series model with i.i.d. normal innovations</h2><span id='topic+lik_ar'></span>

<h3>Description</h3>

<p>Likelihood of an autoregressive time series model with i.i.d. normal innovations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lik_ar(x, ar, mean = 0, sd = 1, log = F, full = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lik_ar_+3A_x">x</code></td>
<td>
<p>numeric vector of data</p>
</td></tr>
<tr><td><code id="lik_ar_+3A_ar">ar</code></td>
<td>
<p>vector of ar parameters</p>
</td></tr>
<tr><td><code id="lik_ar_+3A_mean">mean</code></td>
<td>
<p>the innovation mean</p>
</td></tr>
<tr><td><code id="lik_ar_+3A_sd">sd</code></td>
<td>
<p>the innovation standard deviation</p>
</td></tr>
<tr><td><code id="lik_ar_+3A_log">log</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p)</p>
</td></tr>
<tr><td><code id="lik_ar_+3A_full">full</code></td>
<td>
<p>logical; if TRUE, the full likelihood for all observations is computed; if FALSE, the partial likelihood for the last n-p observations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric value for the likelihood or log-likelihood
</p>

<hr>
<h2 id='llike'>Log corrected parametric AR likelihood (Gaussian)</h2><span id='topic+llike'></span>

<h3>Description</h3>

<p>Log corrected parametric AR likelihood (Gaussian)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike(
  omega,
  FZ,
  ar,
  ma,
  v,
  w,
  k,
  tau,
  corrected,
  toggle.q,
  pdgrm,
  beta_basis_k,
  nll_fun,
  f.alpha,
  excludeBoundary,
  full_lik
)
</code></pre>


<h3>Details</h3>

<p>See (5) in Kirch et al (2018)
</p>

<hr>
<h2 id='llike_AR'>Time domain AR(p) likelihood for nuisance/noise time series</h2><span id='topic+llike_AR'></span>

<h3>Description</h3>

<p>Time domain AR(p) likelihood for nuisance/noise time series
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike_AR(x_noise, rho, sigma2, full_lik)
</code></pre>

<hr>
<h2 id='llike_dw'>Calculating log likelihood</h2><span id='topic+llike_dw'></span>

<h3>Description</h3>

<p>Calculating log likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike_dw(FZ, norm_psd, tau)
</code></pre>

<hr>
<h2 id='llike_var'>VAR(p) likelihood</h2><span id='topic+llike_var'></span>

<h3>Description</h3>

<p>VAR(p) likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike_var(zt, ar, sigma, full_lik)
</code></pre>

<hr>
<h2 id='llike_var_full'>VAR(p) full likelihood</h2><span id='topic+llike_var_full'></span>

<h3>Description</h3>

<p>VAR(p) full likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike_var_full(zt, ar, sigma)
</code></pre>

<hr>
<h2 id='llike_var_partial'>VAR(p) partial likelihood (unnormalized)
Note: Fine for fixed p, but not suited for model comparison</h2><span id='topic+llike_var_partial'></span>

<h3>Description</h3>

<p>VAR(p) partial likelihood (unnormalized)
Note: Fine for fixed p, but not suited for model comparison
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike_var_partial(zt, ar, sigma)
</code></pre>

<hr>
<h2 id='local_moving_FT_zigzag'>Calculate the moving Fourier transform ordinates</h2><span id='topic+local_moving_FT_zigzag'></span>

<h3>Description</h3>

<p>Calculate the moving Fourier transform ordinates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local_moving_FT_zigzag(x, m, thinning_factor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="local_moving_FT_zigzag_+3A_x">x</code></td>
<td>
<p>A numeric vector containing time series.</p>
</td></tr>
<tr><td><code id="local_moving_FT_zigzag_+3A_m">m</code></td>
<td>
<p>A positive integer indicating the size of window.</p>
</td></tr>
<tr><td><code id="local_moving_FT_zigzag_+3A_thinning_factor">thinning_factor</code></td>
<td>
<p>Selected from &quot;1, 2, 3&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the moving Fourier transform and corresponding time grid.
</p>


<h3>References</h3>

<p>Y. Tang et al. (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1); x &lt;- rnorm(1500)
local_moving_FT_zigzag(x, 50, 1)
</code></pre>

<hr>
<h2 id='logDet_stickBreaking'>Log determinant of stick breaking transformation V -&gt; p</h2><span id='topic+logDet_stickBreaking'></span>

<h3>Description</h3>

<p>Log determinant of stick breaking transformation V -&gt; p
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logDet_stickBreaking(v)
</code></pre>


<h3>Details</h3>

<p>See Section 3 in Choudhuri et al (2004)
</p>

<hr>
<h2 id='logfuller'>Fuller Logarithm</h2><span id='topic+logfuller'></span>

<h3>Description</h3>

<p>Fuller Logarithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logfuller(x, xi = 1e-08)
</code></pre>


<h3>Details</h3>

<p>see Fuller (1996), page 496
</p>


<h3>References</h3>

<p>W. Fuller (1996)
<em>Introduction to Statistical Time Series</em>
Wiley Series in Probability and Statistics
</p>

<hr>
<h2 id='lpost'>Log posterior = log prior + log corrected parametric likelihood</h2><span id='topic+lpost'></span>

<h3>Description</h3>

<p>Log posterior = log prior + log corrected parametric likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpost(
  omega,
  FZ,
  ar,
  ma,
  v,
  w,
  k,
  tau,
  M,
  g0.alpha,
  g0.beta,
  k.theta,
  tau.alpha,
  tau.beta,
  corrected,
  toggle.q,
  pdgrm,
  beta_basis_k,
  nll_fun,
  f.alpha,
  rho,
  rho.alpha,
  rho.beta,
  excludeBoundary,
  full_lik
)
</code></pre>

<hr>
<h2 id='lpost_AR'>Log Posterior = Log Prior + (conditional) Log Likelihood</h2><span id='topic+lpost_AR'></span>

<h3>Description</h3>

<p>Log Posterior = Log Prior + (conditional) Log Likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpost_AR(
  x_noise,
  rho,
  rho.alpha,
  rho.beta,
  sigma2,
  sigma2.alpha,
  sigma2.beta,
  full_lik
)
</code></pre>

<hr>
<h2 id='lprior'>Log prior of Bernstein-Dirichlet mixture and parametric working model &ndash; all unnormalized</h2><span id='topic+lprior'></span>

<h3>Description</h3>

<p>Log prior of Bernstein-Dirichlet mixture and parametric working model &ndash; all unnormalized
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lprior(
  v,
  w,
  k,
  tau,
  M,
  g0.alpha,
  g0.beta,
  k.theta,
  tau.alpha,
  tau.beta,
  f.alpha,
  corrected,
  rho,
  rho.alpha,
  rho.beta
)
</code></pre>


<h3>Details</h3>

<p>See Section 3 in Kirch et al (2018).
Hyperparameters are M, g0.a, g0.b, k.theta, tau.alpha, tau.beta.
Note: Flat prior on f.alpha.
</p>

<hr>
<h2 id='lprior_AR'>Log prior for PACF (~Beta) and sigma2 (~InverseGamma), unnormalized</h2><span id='topic+lprior_AR'></span>

<h3>Description</h3>

<p>Log prior for PACF (~Beta) and sigma2 (~InverseGamma), unnormalized
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lprior_AR(rho, rho.alpha, rho.beta, sigma2, sigma2.alpha, sigma2.beta)
</code></pre>

<hr>
<h2 id='lprior_dw'>Calculation of log prior</h2><span id='topic+lprior_dw'></span>

<h3>Description</h3>

<p>Calculation of log prior
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lprior_dw(
  tilde.v,
  tilde.w1,
  tilde.w2,
  k1,
  k2,
  tau,
  M,
  g0.alpha,
  g0.beta,
  k1.theta,
  k2.theta,
  tau.alpha,
  tau.beta
)
</code></pre>

<hr>
<h2 id='mdft'>Multivariate discrete (fast) Fourier Transform</h2><span id='topic+mdft'></span>

<h3>Description</h3>

<p>Multivariate discrete (fast) Fourier Transform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdft(Z, real = F)
</code></pre>

<hr>
<h2 id='midft'>Multivariate inverse discrete (fast) Fourier Transform</h2><span id='topic+midft'></span>

<h3>Description</h3>

<p>Multivariate inverse discrete (fast) Fourier Transform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>midft(FZ, real = F)
</code></pre>

<hr>
<h2 id='missingValues_str_help'>Get string representation for missing values position from vector index</h2><span id='topic+missingValues_str_help'></span>

<h3>Description</h3>

<p>Get string representation for missing values position from vector index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missingValues_str_help(ind, n)
</code></pre>

<hr>
<h2 id='mixtureWeight'>Get mixture weights of Bernstein-Dirchlet-Mixtures</h2><span id='topic+mixtureWeight'></span>

<h3>Description</h3>

<p>Get mixture weights of Bernstein-Dirchlet-Mixtures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixtureWeight(p, w, k)
</code></pre>

<hr>
<h2 id='mpdgrm'>Compute Periodgram matrix from (complex-valued) Fourier coefficients</h2><span id='topic+mpdgrm'></span>

<h3>Description</h3>

<p>Compute Periodgram matrix from (complex-valued) Fourier coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mpdgrm(FZ)
</code></pre>


<h3>Details</h3>

<p>see (4.7) in Meier (2018)
</p>

<hr>
<h2 id='my_rdirichlet'>Generate a random samples from a Dirichlet distribution</h2><span id='topic+my_rdirichlet'></span>

<h3>Description</h3>

<p>Generate a random samples from a Dirichlet distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>my_rdirichlet(alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="my_rdirichlet_+3A_alpha">alpha</code></td>
<td>
<p>numeric vector of positive concentration parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of the same length as alpha
</p>

<hr>
<h2 id='nll_norm'>Negative log likelihood of iid standard normal observations [unit variance]
Note: deprecated</h2><span id='topic+nll_norm'></span>

<h3>Description</h3>

<p>Negative log likelihood of iid standard normal observations [unit variance]
Note: deprecated
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nll_norm(epsilon_t, ...)
</code></pre>

<hr>
<h2 id='omegaFreq'>Fourier frequencies rescaled on the unit interval</h2><span id='topic+omegaFreq'></span>

<h3>Description</h3>

<p>Fourier frequencies rescaled on the unit interval
</p>


<h3>Usage</h3>

<pre><code class='language-R'>omegaFreq(n)
</code></pre>

<hr>
<h2 id='pacf_to_ar'>Convert partial autocorrelation coefficients to AR coefficients.</h2><span id='topic+pacf_to_ar'></span>

<h3>Description</h3>

<p>Convert partial autocorrelation coefficients to AR coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pacf_to_ar(pacf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pacf_to_ar_+3A_pacf">pacf</code></td>
<td>
<p>numeric vector of partial autocorrelations in (-1,1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Section 2 in Kirch et al (2018) or Section III in Barndorff-Nielsen and Schou (1973) for further details
</p>


<h3>Value</h3>

<p>numeric vector of autoregressive model coefficients
</p>


<h3>References</h3>

<p>C. Kirch et al
Supplemental material of
<em>Beyond Whittle: Nonparametric Correction of a Parametric Likelihood With a Focus on Bayesian Time Series Analysis</em>
Bayesian Analysis
&lt;doi:10.1214/18-BA1126SUPP&gt;
</p>
<p>O. Barndorff-Nielsen and G. Schou
On the parametrization of autoregressive models by partial autocorrelations
Journal of Multivariate Analysis (3),408-419
&lt;doi:10.1016/0047-259X(73)90030-4&gt;
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+acf2AR">acf2AR</a>, <a href="stats.html#topic+ARMAacf">ARMAacf</a>
</p>

<hr>
<h2 id='pacf2AR'>C++ function for computing AR coefficients from PACF.
See Section III in Barndorff-Nielsen and Schou (1973)</h2><span id='topic+pacf2AR'></span>

<h3>Description</h3>

<p>C++ function for computing AR coefficients from PACF.
See Section III in Barndorff-Nielsen and Schou (1973)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pacf2AR(pacf)
</code></pre>


<h3>References</h3>

<p>O. Barndorff-Nielsen and G. Schou (1973)
<em>On the Parametrization of Autoregressive Models by Partial Autocorrelations</em>
Journal of Multivariate Analysis (3),408-419
&lt;doi:10.1016/0047-259X(73)90030-4&gt;
</p>

<hr>
<h2 id='pFromV'>Get  p from v in Stick Breaking DP representation</h2><span id='topic+pFromV'></span>

<h3>Description</h3>

<p>Get  p from v in Stick Breaking DP representation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pFromV(v)
</code></pre>

<hr>
<h2 id='phiFromBeta_normalInverseWishart'>Convert vector parametrization (beta) to matrix-parametrization (phi),
the latter as e.g. used in MTS::VAR()$ar</h2><span id='topic+phiFromBeta_normalInverseWishart'></span>

<h3>Description</h3>

<p>Convert vector parametrization (beta) to matrix-parametrization (phi),
the latter as e.g. used in MTS::VAR()$ar
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phiFromBeta_normalInverseWishart(beta, K, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phiFromBeta_normalInverseWishart_+3A_beta">beta</code></td>
<td>
<p>coefficient vector, of dimension K*d*d</p>
</td></tr>
<tr><td><code id="phiFromBeta_normalInverseWishart_+3A_k">K</code></td>
<td>
<p>positive integer, vector dimensionality</p>
</td></tr>
<tr><td><code id="phiFromBeta_normalInverseWishart_+3A_p">p</code></td>
<td>
<p>nonnegarive integer, VAR order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>K times K*p coefficient matrix
</p>

<hr>
<h2 id='plot.bdp_dw_result'>Plot method for bdp_dw_result class</h2><span id='topic+plot.bdp_dw_result'></span>

<h3>Description</h3>

<p>Plot method for bdp_dw_result class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bdp_dw_result'
plot(
  x,
  which = 1:4,
  ask = prod(par("mfcol")) &lt; length(which) &amp;&amp; dev.interactive(),
  col = hcl.colors(200, "Blue-Red 3"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.bdp_dw_result_+3A_x">x</code></td>
<td>
<p>object of class bdp_dw_result</p>
</td></tr>
<tr><td><code id="plot.bdp_dw_result_+3A_which">which</code></td>
<td>
<p>if a subset of the plots is required, specify a subset of the numbers 1:6. 1 indicates posterior mean,
2 indicates posterior median, 3 for lower bound of pointwise 90 percent credible region, 4 for upper bound of 
pointewise 90 percent credible region, 5 indicates lower bound of uniform 90 percent credible region, 6 indicates
upper bound of uniform 90 percent credible region.</p>
</td></tr>
<tr><td><code id="plot.bdp_dw_result_+3A_ask">ask</code></td>
<td>
<p>logical; if TRUE, the user is asked before each plot.</p>
</td></tr>
<tr><td><code id="plot.bdp_dw_result_+3A_col">col</code></td>
<td>
<p>choice of color, default hcl.colors(200, &quot;Blue-Red 3&quot;).</p>
</td></tr>
<tr><td><code id="plot.bdp_dw_result_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to <code>image.default</code></p>
</td></tr>
</table>

<hr>
<h2 id='plot.bdp_dw_tv_psd'>Plot method for bdp_dw_tv_psd class</h2><span id='topic+plot.bdp_dw_tv_psd'></span>

<h3>Description</h3>

<p>Plot method for bdp_dw_tv_psd class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bdp_dw_tv_psd'
plot(x, col = hcl.colors(200, "Blue-Red 3"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.bdp_dw_tv_psd_+3A_x">x</code></td>
<td>
<p>an object of class bdp_dw_tv_psd</p>
</td></tr>
<tr><td><code id="plot.bdp_dw_tv_psd_+3A_col">col</code></td>
<td>
<p>choice of color, default hcl.colors(200, &quot;Blue-Red 3&quot;).</p>
</td></tr>
<tr><td><code id="plot.bdp_dw_tv_psd_+3A_...">...</code></td>
<td>
<p>further arguments to be parsed to <code>image.default</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Visualizes the spectral density function of time-varying
</p>

<hr>
<h2 id='plot.gibbs_psd'>Plot method for gibbs_psd class</h2><span id='topic+plot.gibbs_psd'></span>

<h3>Description</h3>

<p>Plot method for gibbs_psd class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gibbs_psd'
plot(x, pdgrm = T, credib = "both", log = T, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gibbs_psd_+3A_x">x</code></td>
<td>
<p>an object of class gibbs_psd</p>
</td></tr>
<tr><td><code id="plot.gibbs_psd_+3A_pdgrm">pdgrm</code></td>
<td>
<p>bool flag indicating whether periodogram is visualized or not</p>
</td></tr>
<tr><td><code id="plot.gibbs_psd_+3A_credib">credib</code></td>
<td>
<p>string indicating which credible regions are visualized. Possible values are &quot;pointwise&quot;, &quot;uniform&quot;, &quot;both&quot; and &quot;none&quot;.</p>
</td></tr>
<tr><td><code id="plot.gibbs_psd_+3A_log">log</code></td>
<td>
<p>logical value to determine if the individual spectra are visualized on a log scale</p>
</td></tr>
<tr><td><code id="plot.gibbs_psd_+3A_...">...</code></td>
<td>
<p>further arguments to be parsed to <code>plot.default</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Visualizes the spectral density estimate (pointwise posterior median), along with the periodogram
and credibility regions.
If the data has missing values, the periodogram is computed with a linearly
interpolated version of the data using <a href="forecast.html#topic+na.interp">na.interp</a>.
</p>

<hr>
<h2 id='plotMPsd'>Visualization of multivariate PSDs
Used in <code>plot.gibbs_psd</code></h2><span id='topic+plotMPsd'></span>

<h3>Description</h3>

<p>Visualization of multivariate PSDs
Used in <code>plot.gibbs_psd</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMPsd(
  f,
  g = NULL,
  lty = rep(1, 1 + length(g)),
  col = rep(1, 1 + length(g)),
  type = rep("l", 1 + length(g)),
  pch = rep("0", 1 + length(g)),
  lwd = rep(1, 1 + length(g)),
  log = F,
  ylim.compound = T,
  mar = c(4, 4, 4, 3),
  mfrow = c(dim(f)[1], dim(f)[1]),
  lambda_scaling = pi,
  ylab_prefix = "f",
  xlab = "Frequency",
  excludeBoundary = T,
  ...
)
</code></pre>

<hr>
<h2 id='print_mcmc_state'>Help function to print MCMC state</h2><span id='topic+print_mcmc_state'></span>

<h3>Description</h3>

<p>Help function to print MCMC state
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_mcmc_state(i, Ntotal, tim, tim0)
</code></pre>

<hr>
<h2 id='print_summary_gibbs_psd_help'>Helping function for print and summary (both are quite similar)</h2><span id='topic+print_summary_gibbs_psd_help'></span>

<h3>Description</h3>

<p>Helping function for print and summary (both are quite similar)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_summary_gibbs_psd_help(mcmc, flag = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_summary_gibbs_psd_help_+3A_flag">flag</code></td>
<td>
<p>An indicator. flag=T indicates print, flag=F indicates summary</p>
</td></tr>
</table>

<hr>
<h2 id='print_warn'>Help function to print debugging messages</h2><span id='topic+print_warn'></span>

<h3>Description</h3>

<p>Help function to print debugging messages
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_warn(msg)
</code></pre>

<hr>
<h2 id='print.bdp_dw_result'>Print method for bdp_dw_result class</h2><span id='topic+print.bdp_dw_result'></span>

<h3>Description</h3>

<p>Print method for bdp_dw_result class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bdp_dw_result'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bdp_dw_result_+3A_x">x</code></td>
<td>
<p>object of class bdp_dw_result</p>
</td></tr>
<tr><td><code id="print.bdp_dw_result_+3A_...">...</code></td>
<td>
<p>not in use</p>
</td></tr>
</table>

<hr>
<h2 id='print.gibbs_psd'>Print method for gibbs_psd class</h2><span id='topic+print.gibbs_psd'></span>

<h3>Description</h3>

<p>Print method for gibbs_psd class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gibbs_psd'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gibbs_psd_+3A_x">x</code></td>
<td>
<p>object of class gibbs_psd</p>
</td></tr>
<tr><td><code id="print.gibbs_psd_+3A_...">...</code></td>
<td>
<p>not in use</p>
</td></tr>
</table>

<hr>
<h2 id='psd_arma'>ARMA(p,q) spectral density function</h2><span id='topic+psd_arma'></span>

<h3>Description</h3>

<p>Evaluate the ARMA(p,q) spectral density at some frequencies freq in [0,pi),
Note that no test for model stationarity is performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_arma(freq, ar, ma, sigma2 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psd_arma_+3A_freq">freq</code></td>
<td>
<p>numeric vector of frequencies to evaluate the psd, 0 &lt;= freq &lt; pi</p>
</td></tr>
<tr><td><code id="psd_arma_+3A_ar">ar</code></td>
<td>
<p>autoregressive coefficients of ARMA model (use numeric(0) for empty AR part)</p>
</td></tr>
<tr><td><code id="psd_arma_+3A_ma">ma</code></td>
<td>
<p>moving average coefficients of ARMA model (use numeric(0) for empty MA part)</p>
</td></tr>
<tr><td><code id="psd_arma_+3A_sigma2">sigma2</code></td>
<td>
<p>the model innovation variance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See section 4.4 in the referenced book
</p>


<h3>Value</h3>

<p>numeric vector of the (real-valued) spectral density values
</p>


<h3>References</h3>

<p>P. J. Brockwell and R. Davis (1996)
<em>Time Series: Theory and Methods (Second Edition)</em>
</p>

<hr>
<h2 id='psd_array'>Convert psd vector to array
(compatibility: to use plotMPsd for univariate functions as well)</h2><span id='topic+psd_array'></span>

<h3>Description</h3>

<p>Convert psd vector to array
(compatibility: to use plotMPsd for univariate functions as well)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_array(f)
</code></pre>

<hr>
<h2 id='psd_dummy_model'>Time series model X_t=e_t, E[e_t]=0</h2><span id='topic+psd_dummy_model'></span>

<h3>Description</h3>

<p>Time series model X_t=e_t, E[e_t]=0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_dummy_model()
</code></pre>

<hr>
<h2 id='psd_tvarma12'>time-varying spectral density function of the tvARMA(1,2) processes for illustrations</h2><span id='topic+psd_tvarma12'></span>

<h3>Description</h3>

<p>time-varying spectral density function of the tvARMA(1,2) processes for illustrations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_tvarma12(
  rescaled_time,
  freq,
  dgp = NULL,
  a1 = function(u) {
     rep(0, length(u))
 },
  b1 = function(u) {
     rep(0, length(u))
 },
  b2 = function(u) {
     rep(0, length(u))
 }
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psd_tvarma12_+3A_rescaled_time">rescaled_time</code>, <code id="psd_tvarma12_+3A_freq">freq</code></td>
<td>
<p>numeric vectors forming a rectangular grid on which the tv-PSD is evaluated.</p>
</td></tr>
<tr><td><code id="psd_tvarma12_+3A_dgp">dgp</code></td>
<td>
<p>optional: the tv-ARMA models demonstrated in section 4.2 of Tang et al. (2023). 
Should be chosen from &quot;LS1&quot;, &quot;LS2&quot; and &quot;LS3&quot;. See section Details.</p>
</td></tr>
<tr><td><code id="psd_tvarma12_+3A_a1">a1</code>, <code id="psd_tvarma12_+3A_b1">b1</code>, <code id="psd_tvarma12_+3A_b2">b2</code></td>
<td>
<p>If dgp is not supplied, these arguments can be used to specify customized tv-ARMA
process (up to order(1,2)). See Details.
rescaled_time must be in <code class="reqn">[0,1]</code> and freq must be in <code class="reqn">[0,\pi]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+sim_tvarma12">sim_tvarma12</a> for the precise definition of a tvARMA(1,2) process. The time-varying
spectral density function of this process is defined as
</p>

<math>f(u,&lambda;) = (2&pi;)<sup>-1</sup>(1+b<sub>1</sub><sup>2</sup>(u)+b<sub>2</sub><sup>2</sup>(u)+2b<sub>1</sub>(u)(b<sub>2</sub>(u)+1)cos(&lambda;)+2b<sub>2</sub>(u)cos(2&lambda;))/(1+a<sub>1</sub><sup>2</sup>(u)-2a<sub>1</sub>(u)cos(&lambda;)), (u,&lambda;)&isin;[0,1]&times;[0,&pi;],
</math>

<p>where <code class="reqn">u</code> is called rescaled time and <code class="reqn">\lambda</code> is called frequency.
</p>
<p>For dgp = &quot;LS1&quot;, it is a tvMA(2) process (MA order is 2) with
</p>

<math>a<sub>1</sub>(u)=0, b<sub>1</sub>(u)=1.122(1-1.178sin(&pi;/2 u)), 
b<sub>2</sub>(u)=-0.81. </math>

<p>For dgp = &quot;LS2&quot;, it is a tvMA(1) process (MA order is 1) with
</p>

<math>a<sub>1</sub>(u)=0, b<sub>1</sub>(u)=1.1cos(1.5-cos(4&pi; u)), b<sub>2</sub>(u)=0. 
</math>

<p>For dgp = &quot;LS3&quot;, it is a tvAR(1) process (MA order is 0) with
</p>

<math>a<sub>1</sub>(u)=1.2u-0.6, b<sub>1</sub>(u)=0, b<sub>2</sub>(u)=0. </math>



<h3>Value</h3>

<p>a matrix of dimension length(rescaled_time) by length(freq).
</p>


<h3>References</h3>

<p>Tang et al. (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_time &lt;- seq(0, 1, by = 0.005); freq &lt;- pi*seq(0, 1, by = 0.01)
true_tvPSD &lt;- psd_tvarma12(rescaled_time = res_time, freq = freq, dgp = "LS2")
plot(true_tvPSD)

## End(Not run)
</code></pre>

<hr>
<h2 id='psd_varma'>VARMA(p,q) spectral density function</h2><span id='topic+psd_varma'></span>

<h3>Description</h3>

<p>Evaluate the VARMA(p,q) spectral density at some frequencies freq in [0,pi).
Note that no test for model stationarity is performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_varma(
  freq,
  ar = matrix(nrow = nrow(Sigma), ncol = 0),
  ma = matrix(nrow = nrow(Sigma), ncol = 0),
  Sigma
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psd_varma_+3A_freq">freq</code></td>
<td>
<p>numeric vector of frequencies to evaluate the psd, 0 &lt;= freq &lt; pi</p>
</td></tr>
<tr><td><code id="psd_varma_+3A_ar">ar</code></td>
<td>
<p>autoregressive coeffient matrix (d times p*d) of VARMA model, defaults to empty VAR component</p>
</td></tr>
<tr><td><code id="psd_varma_+3A_ma">ma</code></td>
<td>
<p>moving average coeffient matrix (d times p*d) of VARMA model, defaults to empty VAR component</p>
</td></tr>
<tr><td><code id="psd_varma_+3A_sigma">Sigma</code></td>
<td>
<p>positive definite innovation covariance matrix (d times d)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See section 11.5 in the referenced book
</p>


<h3>Value</h3>

<p>an array containing the values of the varma psd matrix at freq
</p>


<h3>References</h3>

<p>P. J. Brockwell and R. Davis (1996)
<em>Time Series: Theory and Methods (Second Edition)</em>
</p>

<hr>
<h2 id='psd_varma_help'>helping function for psd_varma</h2><span id='topic+psd_varma_help'></span>

<h3>Description</h3>

<p>helping function for psd_varma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_varma_help(
  freq,
  ar = matrix(nrow = nrow(sigma), ncol = 0),
  ma = matrix(nrow = nrow(sigma), ncol = 0),
  sigma
)
</code></pre>

<hr>
<h2 id='PSIwgt'>Psi-weight calculation for a VARMA model.
NOTE: This is an exact copy of the MTS::PSIwgt function
(only with the plot functionality removed, as not needed).
This has to be done because the MTS package has been removed
from CRAN in April 2022.</h2><span id='topic+PSIwgt'></span>

<h3>Description</h3>

<p>Psi-weight calculation for a VARMA model.
NOTE: This is an exact copy of the MTS::PSIwgt function
(only with the plot functionality removed, as not needed).
This has to be done because the MTS package has been removed
from CRAN in April 2022.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PSIwgt(Phi = NULL, Theta = NULL, lag = 12, plot = TRUE, output = FALSE)
</code></pre>

<hr>
<h2 id='qpsd'>Compute normalized PSD in the Bernstein-Dirichlet parametrization.</h2><span id='topic+qpsd'></span>

<h3>Description</h3>

<p>Compute normalized PSD in the Bernstein-Dirichlet parametrization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpsd(omega, v, w, k, beta_basis_k, epsilon = 1e-20)
</code></pre>


<h3>Details</h3>

<p>See (5) in Choudhuri et al (2004)
</p>

<hr>
<h2 id='qpsd_dw'>Evaluation of normalized time-varying spectral density function (based on posterior samples)</h2><span id='topic+qpsd_dw'></span>

<h3>Description</h3>

<p>Evaluation of normalized time-varying spectral density function (based on posterior samples)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpsd_dw(v, w1, w2, k1, k2, beta_basis_1_k, beta_basis_2_k)
</code></pre>

<hr>
<h2 id='qpsd_dw.tilde_zigzag_cpp_expedited'>Evaluation of normalized time-varying spectral density function (for MCMC algorithm)</h2><span id='topic+qpsd_dw.tilde_zigzag_cpp_expedited'></span>

<h3>Description</h3>

<p>Evaluation of normalized time-varying spectral density function (for MCMC algorithm)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpsd_dw.tilde_zigzag_cpp_expedited(
  tilde.v,
  tilde.w1,
  tilde.w2,
  k1,
  k2,
  beta_basis_1_k,
  beta_basis_2_k
)
</code></pre>

<hr>
<h2 id='realValuedPsd'>Store imaginary parts above and real parts below the diagonal</h2><span id='topic+realValuedPsd'></span>

<h3>Description</h3>

<p>Store imaginary parts above and real parts below the diagonal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>realValuedPsd(f_)
</code></pre>

<hr>
<h2 id='rmvnorm'>Simulate from a Multivariate Normal Distribution</h2><span id='topic+rmvnorm'></span>

<h3>Description</h3>

<p>Produces one or more samples from the specified multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnorm(n, d, mu = rep(0, d), Sigma = diag(d), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvnorm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_d">d</code></td>
<td>
<p>dimensionality</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_mu">mu</code></td>
<td>
<p>mean vector</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_...">...</code></td>
<td>
<p>further arguments to be parsed to</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a simple wrapper function based on <a href="MASS.html#topic+mvrnorm">mvrnorm</a>,
to be used within <a href="#topic+sim_varma">sim_varma</a>
</p>


<h3>Value</h3>

<p>If n=1 a vector of length d, otherwise an n by d matrix with one sample in each row.
</p>

<hr>
<h2 id='scree_type_ar'>Negative log AR likelihood values for scree-type plots</h2><span id='topic+scree_type_ar'></span>

<h3>Description</h3>

<p>(Approximate) negative maximum log-likelihood for for different autoregressive orders to produce scree-type plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scree_type_ar(data, order.max, method = "yw")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scree_type_ar_+3A_data">data</code></td>
<td>
<p>numeric vector of data</p>
</td></tr>
<tr><td><code id="scree_type_ar_+3A_order.max">order.max</code></td>
<td>
<p>maximum autoregressive order to consider</p>
</td></tr>
<tr><td><code id="scree_type_ar_+3A_method">method</code></td>
<td>
<p>character string giving the method used to fit the model, to be forwarded to <code>stats::<a href="stats.html#topic+ar">ar</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, the maximum likelihood is approximated by the Yule-Walker method, due to numerical stabililty and computational speed. Further details can be found in the simulation study section in the referenced paper.
</p>


<h3>Value</h3>

<p>a data frame containing the autoregressive orders <code>p</code> and the corresponding negative log likelihood values <code>nll</code>
</p>


<h3>References</h3>

<p>C. Kirch et al. (2018)
<em>Beyond Whittle: Nonparametric Correction of a Parametric Likelihood With a Focus on Bayesian Time Series Analysis</em>
Bayesian Analysis
&lt;doi:10.1214/18-BA1126&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

###
### Interactive visual inspection for the sunspot data
###

data &lt;- sqrt(as.numeric(sunspot.year))
data &lt;- data &lt;- data - mean(data)

screeType &lt;- scree_type_ar(data, order.max=15)

# Determine the autoregressive order by an interactive visual inspection of the scree-type plot
plot(x=screeType$p, y=screeType$nll, type="b")
p_ind &lt;- identify(x=screeType$p, y=screeType$nll, n=1, labels=screeType$p)
print(screeType$p[p_ind])

## End(Not run)
</code></pre>

<hr>
<h2 id='sim_tvarma12'>simulate from the tvARMA(1,2) process for illustration</h2><span id='topic+sim_tvarma12'></span>

<h3>Description</h3>

<p>simulate from the tvARMA(1,2) process for illustration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_tvarma12(
  len_d,
  dgp = NULL,
  ar_order = 1,
  ma_order = 2,
  a1 = NULL,
  b1 = NULL,
  b2 = NULL,
  innov_distribution = NULL,
  wn = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_tvarma12_+3A_len_d">len_d</code></td>
<td>
<p>a positive integer indicating the length of the simulated process.</p>
</td></tr>
<tr><td><code id="sim_tvarma12_+3A_dgp">dgp</code></td>
<td>
<p>optional: the tv-ARMA models demonstrated in section 4.2 of Tang et al. (2023). Should be chosen from &quot;LS1&quot;, &quot;LS2&quot; and &quot;LS3&quot;. See section Details.</p>
</td></tr>
<tr><td><code id="sim_tvarma12_+3A_ar_order">ar_order</code>, <code id="sim_tvarma12_+3A_ma_order">ma_order</code>, <code id="sim_tvarma12_+3A_a1">a1</code>, <code id="sim_tvarma12_+3A_b1">b1</code>, <code id="sim_tvarma12_+3A_b2">b2</code></td>
<td>
<p>If dgp is not supplied, these arguments can be used to specify customized tv-ARMA
process (up to order(1,2)). See details.</p>
</td></tr>
<tr><td><code id="sim_tvarma12_+3A_innov_distribution">innov_distribution</code></td>
<td>
<p>optional: the distributions of innovation used in section 4.2.2 of Tang et al. (2023) . 
Should be chosen from &quot;a&quot;, &quot;b&quot;, &quot;c&quot;. &quot;a&quot; denotes standard normal distribution, 
&quot;b&quot; indicates standardized Student-t distribution with degrees of freedom 4 and
&quot;c&quot; denotes standardized Pareto distribution with scale 1 and shape 4.</p>
</td></tr>
<tr><td><code id="sim_tvarma12_+3A_wn">wn</code></td>
<td>
<p>If innov_distribution is not specified, one may supply its own innovation sequence. Please make sure the length
of wn is at least the sum of len_d and the MA order of the process. If ma_order is specified, then MA order is exactly
ma_order. If dgp is specified, the MA order of &quot;LS1&quot;, &quot;LS2&quot; and &quot;LS3&quot; can be found in section Details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates from the following time-varying Autoregressive Moving Average model with order (1,2):
</p>
<math>X<sub>t,T</sub> = a<sub>1</sub>(<sup>t</sup>&frasl;<sub>T</sub>) X<sub>t-1,T</sub> + w<sub>t</sub> + b<sub>1</sub>(<sup>t</sup>&frasl;<sub>T</sub>) w<sub>t-1</sub> + b<sub>2</sub>(<sup>t</sup>&frasl;<sub>T</sub>) w<sub>t-2</sub>, t=1,2,...,T,</math>

<p>where <code class="reqn">T</code> is the length specified and {w<sub>t</sub>} are 
a sequence of i.i.d. random variables with mean 0 and standard deviation 1.
</p>
<p>For dgp = &quot;LS1&quot;, it is a tvMA(2) process (MA order is 2) with
</p>

<math>a<sub>1</sub>(u)=0, b<sub>1</sub>(u)=1.122(1-1.178sin(&pi;/2 u)), b<sub>2</sub>(u)=-0.81.
</math>

<p>For dgp = &quot;LS2&quot;, it is a tvMA(1) process (MA order is 1) with
</p>

<math>a<sub>1</sub>(u)=0, b<sub>1</sub>(u)=1.1cos(1.5-cos(4&pi; u)), b<sub>2</sub>(u)=0.
</math>

<p>For dgp = &quot;LS3&quot;, it is a tvAR(1) process (MA order is 0) with
</p>

<math>a<sub>1</sub>(u)=1.2u-0.6, b<sub>1</sub>(u)=0, b<sub>2</sub>(u)=0.</math>



<h3>Value</h3>

<p>a numeric vector of length len_d simulated from the given process.
</p>


<h3>References</h3>

<p>Tang et al. (2023)
<em>Bayesian nonparametric spectral analysis of locally stationary processes</em>
ArXiv preprint
&lt;arXiv:2303.11561&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sim_tvarma12(len_d = 1500, 
dgp = "LS2", 
innov_distribution = "a") # generate from LS2a

sim_tvarma12(len_d = 1500, 
dgp = "LS2", 
wn = rnorm(1502)) # again, generate from LS2a

sim_tvarma12(len_d = 1500, 
ar_order = 0, 
ma_order = 1, 
b1 = function(u){1.1*cos(1.5 - cos(4*pi*u))}, 
innov_distribution = "a") # again, generate from LS2a

sim_tvarma12(len_d = 1500, 
ar_order = 0, 
ma_order = 1, 
b1 = function(u){1.1*cos(1.5 - cos(4*pi*u))}, 
wn = rnorm(1502)) # again, generate from LS2a

## End(Not run)
</code></pre>

<hr>
<h2 id='sim_varma'>Simulate from a VARMA model</h2><span id='topic+sim_varma'></span>

<h3>Description</h3>

<p>Simulate from a Vector Autoregressive Moving Average (VARMA) model.
Note that no test for model stationarity is performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_varma(model, n, d, rand.gen = rmvnorm, burnin = 10000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_varma_+3A_model">model</code></td>
<td>
<p>A list with component <code>ar</code> and/or <code>ma</code> giving the VAR and VMA 
coefficients respectively. An empty list gives an VARMA(0, 0) model, that is white noise.</p>
</td></tr>
<tr><td><code id="sim_varma_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="sim_varma_+3A_d">d</code></td>
<td>
<p>positive integer for the dimensionality</p>
</td></tr>
<tr><td><code id="sim_varma_+3A_rand.gen">rand.gen</code></td>
<td>
<p>random vector generator, function of type rand.gen(n, d, ...)</p>
</td></tr>
<tr><td><code id="sim_varma_+3A_burnin">burnin</code></td>
<td>
<p>length of burnin period (initial samples that are discarded)</p>
</td></tr>
<tr><td><code id="sim_varma_+3A_...">...</code></td>
<td>
<p>further arguments to be parsed to <code>rand.gen</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If n=1 a vector of length d, otherwise an n by d matrix with one sample in each row.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+arima.sim">arima.sim</a> to simulate from univariate ARMA models
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example: Draw from bivariate normal VAR(2) model
ar &lt;- rbind(c(.5, 0, 0, 0), c(0, -.3, 0, -.5))
Sigma &lt;- matrix(data=c(1, .9, .9, 1), nrow=2, ncol=2)
x &lt;- sim_varma(n=256, d=2, model=list(ar=ar))
plot.ts(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='sldmvnorm'>sum of multivariate normal log densities
with mean 0 and covariance Sigma, unnormalized</h2><span id='topic+sldmvnorm'></span>

<h3>Description</h3>

<p>sum of multivariate normal log densities
with mean 0 and covariance Sigma, unnormalized
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sldmvnorm(z_t, Sigma)
</code></pre>

<hr>
<h2 id='summary.bdp_dw_result'>Summary method for bdp_dw_result class</h2><span id='topic+summary.bdp_dw_result'></span>

<h3>Description</h3>

<p>Summary method for bdp_dw_result class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bdp_dw_result'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.bdp_dw_result_+3A_object">object</code></td>
<td>
<p>object of class bdp_dw_result</p>
</td></tr>
<tr><td><code id="summary.bdp_dw_result_+3A_...">...</code></td>
<td>
<p>not in use</p>
</td></tr>
</table>

<hr>
<h2 id='summary.gibbs_psd'>Summary method for gibbs_psd class</h2><span id='topic+summary.gibbs_psd'></span>

<h3>Description</h3>

<p>Summary method for gibbs_psd class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gibbs_psd'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.gibbs_psd_+3A_object">object</code></td>
<td>
<p>object of class gibbs_psd</p>
</td></tr>
<tr><td><code id="summary.gibbs_psd_+3A_...">...</code></td>
<td>
<p>not in use</p>
</td></tr>
</table>

<hr>
<h2 id='transfer_polynomial'>VARMA transfer polynomials</h2><span id='topic+transfer_polynomial'></span>

<h3>Description</h3>

<p>VARMA transfer polynomials
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfer_polynomial(lambda, coef)
</code></pre>

<hr>
<h2 id='uci_help'>Helping function for <code>uci_matrix</code></h2><span id='topic+uci_help'></span>

<h3>Description</h3>

<p>Helping function for <code>uci_matrix</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uci_help(fpsd.sample, alpha, log = F)
</code></pre>

<hr>
<h2 id='uci_matrix'>Uniform credible intervals in matrix-valued case</h2><span id='topic+uci_matrix'></span>

<h3>Description</h3>

<p>Uniform credible intervals in matrix-valued case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uci_matrix(fpsd.sample, alpha, uniform_among_components = F)
</code></pre>


<h3>Details</h3>

<p>see (6.5) in Meier (2018)
</p>

<hr>
<h2 id='uniformmax'>Uniform maximum, as needed for uniform credible intervals</h2><span id='topic+uniformmax'></span>

<h3>Description</h3>

<p>Uniform maximum, as needed for uniform credible intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniformmax(sample)
</code></pre>


<h3>Details</h3>

<p>see Section 4.1 in Kirch et al (2018)
</p>

<hr>
<h2 id='uniformmax_help'>Helping function for <code>uci_matrix</code></h2><span id='topic+uniformmax_help'></span>

<h3>Description</h3>

<p>Helping function for <code>uci_matrix</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniformmax_help(sample)
</code></pre>

<hr>
<h2 id='uniformmax_multi'>Helping function for <code>uci_matrix</code></h2><span id='topic+uniformmax_multi'></span>

<h3>Description</h3>

<p>Helping function for <code>uci_matrix</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniformmax_multi(mSample)
</code></pre>

<hr>
<h2 id='unit_trace_I_l'>Range intervals I_l, see (63) in Mittelbach et al.</h2><span id='topic+unit_trace_I_l'></span>

<h3>Description</h3>

<p>Range intervals I_l, see (63) in Mittelbach et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_I_l(l)
</code></pre>

<hr>
<h2 id='unit_trace_L_from_x'>Get L (lower triangular Cholesky) from x
Called U^* in Mittelbach et al, see (60) there</h2><span id='topic+unit_trace_L_from_x'></span>

<h3>Description</h3>

<p>Get L (lower triangular Cholesky) from x
Called U^* in Mittelbach et al, see (60) there
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_L_from_x(x)
</code></pre>

<hr>
<h2 id='unit_trace_log_c'>Get log(c) vector, see (70) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code></h2><span id='topic+unit_trace_log_c'></span>

<h3>Description</h3>

<p>Get log(c) vector, see (70) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_log_c(p, q)
</code></pre>

<hr>
<h2 id='unit_trace_log_d'>Get log(d) vector, see (39) in Mittelbach et al, adjusted to complex case
Helping function for <code>unit_trace_runif</code></h2><span id='topic+unit_trace_log_d'></span>

<h3>Description</h3>

<p>Get log(d) vector, see (39) in Mittelbach et al, adjusted to complex case
Helping function for <code>unit_trace_runif</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_log_d(p, q)
</code></pre>

<hr>
<h2 id='unit_trace_log_f_l'>Get log(f_l), see (66) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code></h2><span id='topic+unit_trace_log_f_l'></span>

<h3>Description</h3>

<p>Get log(f_l), see (66) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_log_f_l(phi, p, q, log_c, l)
</code></pre>

<hr>
<h2 id='unit_trace_mu'>Get mu vector, see (36) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code></h2><span id='topic+unit_trace_mu'></span>

<h3>Description</h3>

<p>Get mu vector, see (36) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_mu(p, q)
</code></pre>

<hr>
<h2 id='unit_trace_nu'>Get log(nu) vector, see (38) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code></h2><span id='topic+unit_trace_nu'></span>

<h3>Description</h3>

<p>Get log(nu) vector, see (38) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_nu(sigma2_vec, log_c_vec, log_d_vec)
</code></pre>

<hr>
<h2 id='unit_trace_p'>Get p vector, see (67) in Mittelbach et al.</h2><span id='topic+unit_trace_p'></span>

<h3>Description</h3>

<p>Get p vector, see (67) in Mittelbach et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_p(d)
</code></pre>

<hr>
<h2 id='unit_trace_q'>Get q vector, see (68) in Mittelbach et al.</h2><span id='topic+unit_trace_q'></span>

<h3>Description</h3>

<p>Get q vector, see (68) in Mittelbach et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_q(d)
</code></pre>

<hr>
<h2 id='unit_trace_runif'>Draw uniformly from Hpd matrices with unit trace</h2><span id='topic+unit_trace_runif'></span>

<h3>Description</h3>

<p>Draw uniformly from Hpd matrices with unit trace
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_runif(n, d, verbose = F)
</code></pre>

<hr>
<h2 id='unit_trace_runif_single'>Obtain one uniform draw from d times d Hpd matrices with unit trace
See Algorithm 2 in Mittelbach et al. (adjusted to complex case)</h2><span id='topic+unit_trace_runif_single'></span>

<h3>Description</h3>

<p>Obtain one uniform draw from d times d Hpd matrices with unit trace
See Algorithm 2 in Mittelbach et al. (adjusted to complex case)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_runif_single(d)
</code></pre>

<hr>
<h2 id='unit_trace_sigma2'>Get sigma2 vector, see (70) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code></h2><span id='topic+unit_trace_sigma2'></span>

<h3>Description</h3>

<p>Get sigma2 vector, see (70) in Mittelbach et al.
Helping function for <code>unit_trace_runif</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_sigma2(p, q)
</code></pre>

<hr>
<h2 id='unit_trace_U_from_phi'>Get U (Hpd with unit trace) matrix from 
phi (hyperspherical coordinates) vector.</h2><span id='topic+unit_trace_U_from_phi'></span>

<h3>Description</h3>

<p>Get U (Hpd with unit trace) matrix from 
phi (hyperspherical coordinates) vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_U_from_phi(phi)
</code></pre>

<hr>
<h2 id='unit_trace_x_from_phi'>Get x from phi, see (62) in Mittelbach et al.</h2><span id='topic+unit_trace_x_from_phi'></span>

<h3>Description</h3>

<p>Get x from phi, see (62) in Mittelbach et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unit_trace_x_from_phi(phi)
</code></pre>

<hr>
<h2 id='unrollPsd'>Redundantly roll out a PSD from length N=floor(n/2) to length n</h2><span id='topic+unrollPsd'></span>

<h3>Description</h3>

<p>Redundantly roll out a PSD from length N=floor(n/2) to length n
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unrollPsd(qPsd, n)
</code></pre>

<hr>
<h2 id='VAR_regressor_matrix'>VAR regressor matrix, see Section 2.2.3 in Koop and Korobilis (2010)</h2><span id='topic+VAR_regressor_matrix'></span>

<h3>Description</h3>

<p>VAR regressor matrix, see Section 2.2.3 in Koop and Korobilis (2010)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VAR_regressor_matrix(data, var.order)
</code></pre>

<hr>
<h2 id='varma_transfer2psd'>Get VARMA PSD from transfer polynomials 
Helping function for <code>psd_varma</code></h2><span id='topic+varma_transfer2psd'></span>

<h3>Description</h3>

<p>Get VARMA PSD from transfer polynomials 
Helping function for <code>psd_varma</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varma_transfer2psd(transfer_ar_, transfer_ma_, sigma)
</code></pre>

<hr>
<h2 id='VARMAcov_muted'>This is a nearly exact copy of the MTS::VARMAcov function, where 
the output commands at the end are removed.
This has to be done because the function is called repeatedly
within the MCMC algorithm.
For future versions of the package, a better solution is intended.</h2><span id='topic+VARMAcov_muted'></span>

<h3>Description</h3>

<p>This is a nearly exact copy of the MTS::VARMAcov function, where 
the output commands at the end are removed.
This has to be done because the function is called repeatedly
within the MCMC algorithm.
For future versions of the package, a better solution is intended.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VARMAcov_muted(Phi = NULL, Theta = NULL, Sigma = NULL, lag = 12, trun = 120)
</code></pre>

<hr>
<h2 id='vFromP'>Get v from p (DP inverse stick breaking)
Note: p is assumed to have length L, i.e. it does NOT contain p_0</h2><span id='topic+vFromP'></span>

<h3>Description</h3>

<p>Get v from p (DP inverse stick breaking)
Note: p is assumed to have length L, i.e. it does NOT contain p_0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vFromP(p, eps = 1e-08)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
