<!DOCTYPE html><html><head><title>Help for package pwrss</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pwrss}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#plot'><p>Type I and Type II Error Plot</p></a></li>
<li><a href='#power.chisq.test'><p>Statistical Power for the Generic Chi-square Test</p></a></li>
<li><a href='#power.f.test'><p>Statistical Power for the Generic F Test</p></a></li>
<li><a href='#power.t.test'><p>Statistical Power for the Generic t Test</p></a></li>
<li><a href='#power.z.test'><p>Statistical Power for the Generic z Test</p></a></li>
<li><a href='#pwrss.chisq.gofit'><p>Goodness-of-Fit or Independence (Chi-square Test)</p></a></li>
<li><a href='#pwrss.f.ancova'><p>Analysis of (Co)Variance (F test)</p></a></li>
<li><a href='#pwrss.f.reg'><p>Linear Regression: R-squared or R-squared Difference (F Test)</p></a></li>
<li><a href='#pwrss.f.rmanova'><p>Repeated Measures Analysis of Variance (F test)</p></a></li>
<li><a href='#pwrss.np.2groups'><p>Difference between Two Groups (Non-parametric Tests for Independent and Paired Samples)</p></a></li>
<li><a href='#pwrss.t.2means'><p>Difference between Two Means (t or z Test for Independent or Paired Samples)</p></a></li>
<li><a href='#pwrss.t.mean'><p>One Mean against a Constant (z or t Test)</p></a></li>
<li><a href='#pwrss.t.reg'><p>Linear Regression: Single Coefficient (t or z Test)</p></a></li>
<li><a href='#pwrss.z.2corrs'><p>Difference between Two Correlations (Independent Samples z Test)</p></a></li>
<li><a href='#pwrss.z.2props'><p>Difference between Two Proportions (z Test)</p></a></li>
<li><a href='#pwrss.z.corr'><p>One Correlation against a Constant (One Sample z Test)</p></a></li>
<li><a href='#pwrss.z.logreg'><p>Logistic Regression: Single Coefficient (Large Sample Approx. Wald's z Test)</p></a></li>
<li><a href='#pwrss.z.med'><p>Indirect Effect in Mediation Analysis (z, Joint, and Monte Carlo Tests)</p></a></li>
<li><a href='#pwrss.z.poisreg'><p>Poisson Regression: Single Coefficient (Large Sample Approx. Wald's z Test)</p></a></li>
<li><a href='#pwrss.z.prop'><p>One Proportion against a Constant (z Test)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.3.1</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Power and Sample Size Calculation Tools</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-10</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical power and minimum required sample size calculations for (1) testing a proportion (one-sample) against a constant,  (2) testing a mean (one-sample) against a constant,  (3) testing difference between two proportions (independent samples),  (4) testing difference between two means or groups (parametric and non-parametric tests for independent and paired samples),  (5) testing a correlation (one-sample) against a constant,  (6) testing difference between two correlations (independent samples), (7) testing a single coefficient in multiple linear regression, logistic regression, and Poisson regression (with standardized or unstandardized coefficients, with no covariates or covariate adjusted), (8) testing an indirect effect (with standardized or unstandardized coefficients, with no covariates or covariate adjusted) in the mediation analysis (Sobel, Joint, and Monte Carlo tests), (9) testing an R-squared against zero in linear regression, (10) testing an R-squared difference against zero in hierarchical regression,  (11) testing an eta-squared or f-squared (for main and interaction effects) against zero in analysis of variance (could be one-way, two-way, and three-way),  (12) testing an eta-squared or f-squared (for main and interaction effects) against zero in analysis of covariance (could be one-way, two-way, and three-way),  (13) testing an eta-squared or f-squared (for between, within, and interaction effects) against zero in one-way repeated measures analysis of variance (with non-sphericity correction and repeated measures correlation), and (14) testing goodness-of-fit or independence for contingency tables. Alternative hypothesis can be formulated as "not equal", "less", "greater", "non-inferior", "superior", or "equivalent" in (1), (2), (3), and (4); as "not equal", "less", or "greater" in (5), (6), (7) and (8); but always as "greater" in (9), (10), (11), (12), (13), and (14). Reference: Bulus and Polat (2023) <a href="https://osf.io/ua5fc">https://osf.io/ua5fc</a>.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Metin Bulus &lt;bulusmetin@gmail.com&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-11 20:42:10 UTC; LENOVO</td>
</tr>
<tr>
<td>Author:</td>
<td>Metin Bulus [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-11 21:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='plot'>Type I and Type II Error Plot</h2><span id='topic+plot.pwrss'></span>

<h3>Description</h3>

<p>Plots Type I (alpha) and Type II (beta) errors for t, z, F, and Chi-square tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pwrss'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>an object of the type &quot;pwrss&quot; returned from one of the <code>pwrss</code> functions</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>for S3 generic/method consistency</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no return value at the moment</p>


<h3>Examples</h3>

<pre><code class='language-R'>design &lt;- pwrss.f.ancova(n.levels = c(3,3),
               n = 50, eta2 = 0.10)
plot(design)
</code></pre>

<hr>
<h2 id='power.chisq.test'>Statistical Power for the Generic Chi-square Test</h2><span id='topic+power.chisq.test'></span>

<h3>Description</h3>

<p>Calculates statistical power for the generic chi-square test with (optional) Type I and Type II error plots.
Unlike other more specific functions <code>power.chisq.test()</code> function allows multiple values for one parameter at a time (only when <code>plot = FALSE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.chisq.test(ncp, df, alpha = 0.05, plot = TRUE,
                 plot.main = NULL, plot.sub = NULL,
                 verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.chisq.test_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter (lambda)</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_df">df</code></td>
<td>
<p>degrees of freedom. For example, for the test of homogeneity or independence df = (nrow - 1)*(ncol - 1)</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> plots Type I and Type II error</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_plot.main">plot.main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_plot.sub">plot.sub</code></td>
<td>
<p>plot subtitle</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console. Useful for simulation, plotting, and whatnot</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># power is defined as the probability of observing Chi-square-statistics
# greater than the critical Chi-square value
power.chisq.test(ncp = 20, df = 100, alpha = 0.05)

# power of multiple Chi-square-statistics
power.chisq.test(ncp = c(5, 10, 15, 20), plot = FALSE,
                 df = 100, alpha = 0.05)

</code></pre>

<hr>
<h2 id='power.f.test'>Statistical Power for the Generic F Test</h2><span id='topic+power.f.test'></span>

<h3>Description</h3>

<p>Calculates statistical power for the generic F test with (optional) Type I and Type II error plots.
Unlike other more specific functions <code>power.f.test()</code> function allows multiple values for one parameter at a time (only when <code>plot = FALSE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.f.test(ncp, df1, df2, alpha = 0.05, plot = TRUE,
             plot.main = NULL, plot.sub = NULL,
             verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.f.test_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter (lambda)</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_df1">df1</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_df2">df2</code></td>
<td>
<p>denominator degrees of freedom</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> plots Type I and Type II error</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_plot.main">plot.main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_plot.sub">plot.sub</code></td>
<td>
<p>plot subtitle</p>
</td></tr>
<tr><td><code id="power.f.test_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console. Useful for simulation, plotting, and whatnot</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># power is defined as the probability of observing F-statistics
# greater than the critical F value
power.f.test(ncp = 1, df1 = 4, df2 = 100, alpha = 0.05)

# power of multiple F-statistics
power.f.test(ncp = c(1.0, 1.5, 2.0, 2.5), plot = FALSE,
             df1 = 4, df2 = 100, alpha = 0.05)

</code></pre>

<hr>
<h2 id='power.t.test'>Statistical Power for the Generic t Test</h2><span id='topic+power.t.test'></span>

<h3>Description</h3>

<p>Calculates statistical power for the generic t test with (optional) Type I and Type II error plots.
Unlike other more specific functions <code>power.t.test()</code> function allows multiple values for one parameter at a time (only when <code>plot = FALSE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.t.test(ncp, df, alpha = 0.05,
             alternative = c("not equal", "greater", "less",
                             "non-inferior", "superior", "equivalent"),
             plot = TRUE, plot.main = NULL, plot.sub = NULL,
             verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.t.test_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter (lambda)</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_df">df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;. The same non-centrality parameters will produce the same power rates for &quot;greater&quot;, &quot;less&quot;, &quot;non-inferior&quot;, and &quot;superior&quot; tests. Different labels have been used merely for consistency. However, it should be noted that the non-centrality parameter should conform to the specific test type</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> plots Type I and Type II error</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_plot.main">plot.main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_plot.sub">plot.sub</code></td>
<td>
<p>plot subtitle</p>
</td></tr>
<tr><td><code id="power.t.test_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console. Useful for simulation, plotting, and whatnot</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># power is defined as the probability of observing t-statistics
# greater than the positive critical t value OR
# less than the negative critical t value
power.t.test(ncp = 1.96, df = 99, alpha = 0.05,
             alternative = "not equal")

# power is defined as the probability of observing t-statistics
# greater than the critical t value
power.t.test(ncp = 1.96, df = 99, alpha = 0.05,
             alternative = "greater")

# power is defined as the probability of observing t-statistics
# greater than the critical t value where the non-centrality parameter
# for the alternative distribution is adjusted for the non-inferiority margin
power.t.test(ncp = 1.98, df = 99, alpha = 0.05,
             alternative = "non-inferior")

# power is defined as the probability of observing t-statistics
# greater than the critical t value where the non-centrality parameter
# for the alternative distribution is adjusted for the superiority margin
power.t.test(ncp = 1.94, df = 99, alpha = 0.05,
             alternative = "superior")

# power is defined as the probability of observing t-statistics
# less than the positive critical t value AND
# greater than the negative critical t value
# the non-centrality parameter is for the null distribution
# and is derived from the equivalence margins (lower and upper)
power.t.test(ncp = 1.96, df = 999, alpha = 0.05,
             alternative = "equivalent")
# or, define lower and upper bound with rbind()
power.t.test(ncp = rbind(-1.96, 1.96),
             df = 999, alpha = 0.05,
             alternative = "equivalent")
</code></pre>

<hr>
<h2 id='power.z.test'>Statistical Power for the Generic z Test</h2><span id='topic+power.z.test'></span>

<h3>Description</h3>

<p>Calculates statistical power for the generic z test with (optional) Type I and Type II error plots.
Unlike other more specific functions <code>power.z.test()</code> function allows multiple values for one parameter at a time (only when <code>plot = FALSE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.z.test(ncp, alpha = 0.05,
             alternative = c("not equal", "greater", "less",
                             "non-inferior", "superior", "equivalent"),
             plot = TRUE, plot.main = NULL, plot.sub = NULL,
             verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.z.test_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter (lambda)</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;. The same non-centrality parameters will produce the same power rates for &quot;greater&quot;, &quot;less&quot;, &quot;non-inferior&quot;, and &quot;superior&quot; tests. Different labels have been used for consistency. However, it should be noted that the non-centrality parameter should conform to the specific test type</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> plots Type I and Type II error</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_plot.main">plot.main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_plot.sub">plot.sub</code></td>
<td>
<p>plot subtitle</p>
</td></tr>
<tr><td><code id="power.z.test_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console. Useful for simulation, plotting, and whatnot</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># power defined as the probability of observing z-statistics
# greater than the positive critical t value OR
# less than the negative critical t value
power.z.test(ncp = 1.96, alpha = 0.05,
             alternative = "not equal")

# power is defined as the probability of observing z-statistics
# greater than the critical t value
power.z.test(ncp = 1.96, alpha = 0.05,
             alternative = "greater")

# power is defined as the probability of observing z-statistics
# greater than the critical t value where the non-centrality parameter
# for the alternative distribution is adjusted for the non-inferiority margin
power.z.test(ncp = 1.98, alpha = 0.05,
             alternative = "non-inferior")

# power is defined as the probability of observing z-statistics
# greater than the critical t value where the non-centrality parameter
# for the alternative distribution is adjusted for the superiority margin
power.z.test(ncp = 1.94, alpha = 0.05,
             alternative = "superior")

# power is defined as the probability of observing z-statistics
# less than the positive critical t value AND
# greater than the negative critical t value
# the non-centrality parameter is for the null distribution
# and is derived from the equivalence margins (lower and upper)
power.z.test(ncp = 1.96, alpha = 0.05,
             alternative = "equivalent")
# or, define lower and upper bound with rbind()
power.z.test(ncp = rbind(-1.96, 1.96), alpha = 0.05,
             alternative = "equivalent")
</code></pre>

<hr>
<h2 id='pwrss.chisq.gofit'>Goodness-of-Fit or Independence (Chi-square Test)</h2><span id='topic+pwrss.chisq.gofit'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) for Chi-square goodness-of-fit or independence test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.chisq.gofit(p1 = c(0.50, 0.50),
                  p0 = .chisq.fun(p1)$p0,
                  w = .chisq.fun(p1)$w,
                  df = .chisq.fun(p1)$df,
                  n = NULL, power = NULL,
                  alpha = 0.05, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.chisq.gofit_+3A_p1">p1</code></td>
<td>
<p>a vector or matrix of cell probabilities under alternative hypothesis</p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_p0">p0</code></td>
<td>
<p>a vector or matrix of cell probabilities under null hypothesis. Calculated automatically when <code>p1</code> is specified. The default can be overwritten by the user via providing a vector of the same size or matrix of the same dimensions as <code>p1</code></p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_w">w</code></td>
<td>
<p>effect size. Computed from <code>p1</code> and <code>p0</code> automatically; however, it can be any of Cohen's W, Phi coefficient, Cramer's V, etc. when specified by the user. Phi coefficient is defined as <code>sqrt(X2/n)</code> and Cramer's V is defined as <code>sqrt(X2/(n*v))</code> where <code>v</code> is <code>min(nrow - 1, ncol - 1)</code> and X2 is the chi-square statistic</p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_df">df</code></td>
<td>
<p>degrees of freedom.  Defined as (ncells - 1) if <code>p1</code> is a vector, and as (nrows - 1) * (ncols - 1) if <code>p1</code> is a matrix</p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.chisq.gofit_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (Chi-square test)</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ---------------------------------------------------------#
# Example 1: Cohen's W                                     #
# goodness-of-fit test for 1 x k or k x 1 table            #
# How many subjects are needed to claim that               #
# girls choose STEM related majors less than males?       #
# ---------------------------------------------------------#

## Option 1: Use cell probabilities
## from https://www.aauw.org/resources/research/the-stem-gap/
## 28 percent of the  workforce in STEM field is women
prob.mat &lt;- c(0.28, 0.72) # null hypothesis states that c(0.50, 0.50)
pwrss.chisq.gofit(p1 = c(0.28, 0.72),
                  alpha = 0.05, power = 0.80)

## Option 2: Use Cohe's W = 0.44
## df is k - 1 for Cohen's W
pwrss.chisq.gofit(w = 0.44, df = 1,
                  alpha = 0.05, power = 0.80)


# ---------------------------------------------------------#
# Example 2: Phi Coefficient (or Cramer's V or Cohen's W)  #
# test of independence for 2 x 2 contingency tables        #
# How many subjects are needed to claim that               #
# girls are underdiagnosed with ADHD?                      #
# ---------------------------------------------------------#

## Option 1: Use cell probabilities
## from https://time.com/growing-up-with-adhd/
## 5.6 percent of girls and 13.2 percent of boys are diagnosed with ADHD
prob.mat &lt;- rbind(c(0.056, 0.132),
                  c(0.944, 0.868))
colnames(prob.mat) &lt;- c("Girl", "Boy")
rownames(prob.mat) &lt;- c("ADHD", "No ADHD")
prob.mat
pwrss.chisq.gofit(p1 = prob.mat,
                  alpha = 0.05, power = 0.80)

## Option 2: Use Phi coefficient = 0.1302134
## df is 1 for Phi coefficient
pwrss.chisq.gofit(w = 0.1302134, df = 1,
                  alpha = 0.05, power = 0.80)


# --------------------------------------------------------#
# Example 3: Cramer's V (or Cohen's W)                    #
# test of independence for j x k contingency tables       #
# How many subjects are needed to detect the relationship #
# between depression severity and gender?                 #
# --------------------------------------------------------#

## Option 1: Use cell probabilities
## from https://doi.org/10.1016/j.jad.2019.11.121
prob.mat &lt;- cbind(c(0.6759, 0.1559, 0.1281, 0.0323, 0.0078),
                  c(0.6771, 0.1519, 0.1368, 0.0241, 0.0101))
rownames(prob.mat) &lt;- c("Normal", "Mild", "Moderate", "Severe", "Extremely Severe")
colnames(prob.mat) &lt;- c("Female", "Male")
prob.mat
pwrss.chisq.gofit(p1 = prob.mat,
                  alpha = 0.05, power = 0.80)

# Option 2: Use Cramer's V = 0.03022008 based on 5 x 2 contingency table
# df is (nrow - 1) * (ncol - 1) for Cramer's V
pwrss.chisq.gofit(w = 0.03022008, df = 4,
                  alpha = 0.05, power = 0.80)

</code></pre>

<hr>
<h2 id='pwrss.f.ancova'>Analysis of (Co)Variance (F test)</h2><span id='topic+pwrss.f.anova'></span><span id='topic+pwrss.f.ancova'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size for one-way, two-way, or three-way ANOVA/ANCOVA. Set <code>n.covariates = 0</code> for ANOVA, and <code>n.covariates &gt; 0</code> for ANCOVA. Note that in each case, the effect size (partial) (<code>eta2</code> or <code>f2</code>) should be obtained from the relevant model.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.f.ancova(eta2 = 0.01, f2 = eta2 / (1 - eta2),
               n.way = length(n.levels),
               n.levels = 2, n.covariates = 0, alpha = 0.05,
               n = NULL, power = NULL, verbose = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.f.ancova_+3A_eta2">eta2</code></td>
<td>
<p>expected Eta-squared</p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_f2">f2</code></td>
<td>
<p>expected Cohen's f2 (an alternative to <code>eta2</code> specification). f2 = eta2 / (1 - eta2)</p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_n.way">n.way</code></td>
<td>
<p>1 for one-way, 2 for two-way, 3 for three-way ANOVA or ANCOVA. The default takes its value from the length of <code>n.levels</code></p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_n.levels">n.levels</code></td>
<td>
<p>number of levels (groups) in each factor. For example, for two factors each having two levels (groups) use e.g. c(2,2), for three factors each having two levels (groups) use e.g. c(2,2,2)</p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_n.covariates">n.covariates</code></td>
<td>
<p>number of covariates in the ANCOVA model</p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.f.ancova_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (F test)</p>
</td></tr>
<tr><td><code>df1</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code>df2</code></td>
<td>
<p>denominator degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################
#              one-way ANOVA                #
#############################################

# a researcher is expecting a difference of
# Cohen's d = 0.50 between treatment and control
# translating into Eta-squared = 0.059

# estimate sample size using ANOVA approach
pwrss.f.ancova(eta2 = 0.059, n.levels = 2,
               alpha = 0.05, power = .80)

# estimate sample size using regression approach(F test)
pwrss.f.reg(r2 = 0.059, k = 1,
            alpha = 0.05, power = 0.80)

# estimate sample size using regression approach (t test)
p &lt;- 0.50 # proportion of sample in treatment
pwrss.t.reg(beta1 = 0.50, r2 = 0,
            k = 1, sdx = sqrt(p*(1-p)),
            alpha = 0.05, power = 0.80)

# estimate sample size using t test approach
pwrss.t.2means(mu1 = 0.50,
               alpha = 0.05, power = 0.80)

#############################################
#              two-way ANOVA                #
#############################################

# a researcher is expecting a partial Eta-squared = 0.03
# for interaction of treatment (Factor A) with
# gender consisting of two levels (Factor B)

pwrss.f.ancova(eta2 = 0.03, n.levels = c(2,2),
               alpha = 0.05, power = 0.80)

# estimate sample size using regression approach (F test)
# one dummy for treatment, one dummy for gender, and their interaction (k = 3)
# partial Eta-squared is equivalent to the increase in R-squared by adding
# only the interaction term (m = 1)
pwrss.f.reg(r2 = 0.03, k = 3, m = 1,
            alpha = 0.05, power = 0.80)

#############################################
#              one-way ANCOVA               #
#############################################

# a researcher is expecting an adjusted difference of
# Cohen's d = 0.45 between treatment and control after
# controllling for the pretest (n.cov = 1)
# translating into Eta-squared = 0.048

pwrss.f.ancova(eta2 = 0.048, n.levels = 2, n.cov = 1,
               alpha = 0.05, power = .80)

#############################################
#              two-way ANCOVA               #
#############################################

# a researcher is expecting an adjusted partial Eta-squared = 0.02
# for interaction of treatment (Factor A) with
# gender consisting of two levels (Factor B)

pwrss.f.ancova(eta2 = 0.02, n.levels = c(2,2), n.cov = 1,
               alpha = 0.05, power = .80)
</code></pre>

<hr>
<h2 id='pwrss.f.reg'>Linear Regression: R-squared or R-squared Difference (F Test)</h2><span id='topic+pwrss.f.reg'></span><span id='topic+pwrss.f.regression'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test R-squared deviation from 0 (zero) in linear regression or to test R-squared difference between two linear regression models. The test of R-squared difference is often used to evaluate incremental contribution of a set of predictors in hierarchical linear regression.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.f.reg(r2 = 0.10, f2 = r2 /(1 - r2),
            k = 1, m = k, alpha = 0.05,
            n = NULL, power = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.f.reg_+3A_r2">r2</code></td>
<td>
<p>expected R-squared (or R-squared change)</p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_f2">f2</code></td>
<td>
<p>expected Cohen's f-squared (an alternative to <code>r2</code> specification). f2 = r2 / (1 - r2)</p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_k">k</code></td>
<td>
<p>(total) number of predictors</p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_m">m</code></td>
<td>
<p>number of predictors in the subset of interest. By default <code>m = k</code>, which implies that one is interested in the contribution of all predictors, and tests whether R-squared value is different from 0 (zero)</p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.f.reg_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (F test)</p>
</td></tr>
<tr><td><code>df1</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code>df2</code></td>
<td>
<p>denominator degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># EXample 1: A researcher is expecting that
# three variables together explain 15 percent of the variance
# in the outcome (R-squared = 0.15).
pwrss.f.reg(r2 = 0.15, k = 3,
            alpha = 0.05, power = 0.80)

# Example 2: A researcher is expecting that
# adding two more variables will increase R-squared
# from 0.15 (with 3 predictors) to 0.20 (with 3 + 2 predictors)
# k = 5 (total number of predictors)
# m = 2 (predictors whose incremental contribution to R-squared change is of interest)
pwrss.f.reg(r2 = 0.05, k = 5, m = 2,
            alpha = 0.05, power = 0.80)
</code></pre>

<hr>
<h2 id='pwrss.f.rmanova'>Repeated Measures Analysis of Variance (F test)</h2><span id='topic+pwrss.f.rmanova'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size for one-way Repeated Measures Analysis of Variance (RM-ANOVA).
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.f.rmanova(eta2 = 0.10, f2 = eta2/(1 - eta2),
                corr.rm = 0.50, n.levels = 2, n.rm = 2,
                epsilon = 1, alpha = 0.05,
                type = c("between","within","interaction"),
                n = NULL, power = NULL, verbose = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.f.rmanova_+3A_eta2">eta2</code></td>
<td>
<p>expected (partial) Eta-squared</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_f2">f2</code></td>
<td>
<p>expected Cohen's f-squared (an alternative to <code>eta2</code> specification). <code>f2 = eta2 / (1 - eta2)</code></p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_corr.rm">corr.rm</code></td>
<td>
<p>expected correlation between repeated measures. For example, for pretest/posttest designs, this is the correlation between pretest and posttest scores regardless of group membership. The default is 0.50</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_n.levels">n.levels</code></td>
<td>
<p>number of levels (groups). For example, for randomized controlled trials with two arms (treatment/control) it takes a value of 2</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_n.rm">n.rm</code></td>
<td>
<p>number of measurements. For example, for pretest/posttest designs it takes a value of 2. When there is a follow-up test it takes a value of 3</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_epsilon">epsilon</code></td>
<td>
<p>non-sperhicity correction factor, default is 1 (means no violation of sphericity). Lower bound for this argument is <code>epsilon</code> = 1 / (<code>n.rm</code> - 1)</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_type">type</code></td>
<td>
<p>the effect to be tested: &quot;between&quot;, &quot;within&quot;, or &quot;interaction&quot;. The type of the effect depends on the hypothesis test. If the interest is in the group effect after controlling for the time effect use &quot;between&quot;; if the interest is the time effect after controlling for the group membership use &quot;within&quot;; if the interest is in the group x time interaction use &quot;interaction&quot;</p>
</td></tr>
<tr><td><code id="pwrss.f.rmanova_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (F test)</p>
</td></tr>
<tr><td><code>df1</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code>df2</code></td>
<td>
<p>denominator degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######################################################
# pretest-posttest design with treatment group only  #
######################################################

# a researcher is expecting a difference of Cohen's d = 0.30
# between posttest and pretest score translating into
# Eta-squared = 0.022
pwrss.f.rmanova(eta2 = 0.022,  n.levels = 1, n.rm = 2,
                corr.rm = 0.50, type = "within",
                alpha = 0.05, power = 0.80)

# paired t-test approach
pwrss.t.2means(mu1 = 0.30, mu2 = 0,
               sd1 = 1, sd2 = 1,
               paired = TRUE, paired.r = 0.50,
               alpha = 0.05, power = 0.80)

##########################################################
# posttest only design with treatment and control groups #
##########################################################

# a researcher is expecting a difference of Cohen's d = 0.50
# on the posttest score between treatment and control groups
# translating into Eta-squared = 0.059
pwrss.f.rmanova(eta2 = 0.059,  n.levels = 2, n.rm = 1,
                type = "between",
                alpha = 0.05, power = 0.80)

# independent t-test approach
pwrss.t.2means(mu1 = 0.50, mu2 = 0,
               sd1 = 1, sd2 = 1,
               alpha = 0.05, power = 0.80)

#############################################################
# pretest-posttest design with treatment and control groups #
#############################################################

# a researcher is expecting a difference of Cohen's d = 0.40
# on the posttest score between treatment and control groups
# after controlling for the pretest translating into
# partial Eta-squared = 0.038
pwrss.f.rmanova(eta2 = 0.038,  n.levels = 2, n.rm = 2,
                corr.rm = 0.50, type = "between",
                alpha = 0.05, power = 0.80)

# regression approach
p &lt;- 0.50 # proportion of subjects in treatment group
pwrss.t.reg(beta1 = 0.40, r2 = 0.25, k = 2,
            sdx = sqrt(p*(1-p)),
            alpha = 0.05, power = 0.80)

# a researcher is expecting an interaction effect
# (between groups and time) of Eta-squared = 0.01
pwrss.f.rmanova(eta2 = 0.01,  n.levels = 2, n.rm = 2,
                corr.rm = 0.50, type = "interaction",
                alpha = 0.05, power = 0.80)
</code></pre>

<hr>
<h2 id='pwrss.np.2groups'>Difference between Two Groups (Non-parametric Tests for Independent and Paired Samples)</h2><span id='topic+pwrss.np.2means'></span><span id='topic+pwrss.np.2groups'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test difference between two groups. Although means and standard deviations are some of the arguments in the function below, what is actually being tested is the difference between mean ranks. First, the mean difference is converted into Cohen's d, and then into probability of superiority, which is the probability of an observation in group 1 being higher than an observation in group 2. Probability of superiority can be extracted as <code>pwrss.np.2groups()$parms$prob1</code>. This parameterization, expressed as means and standard deviations, helps in making comparisons and switching back and forth between parametric and non-parametric tests.
</p>
<p>For standardized mean difference (Cohen's d) set <code>mu1 = d</code> and use defaults for <code>mu2</code>, <code>sd1</code>, and <code>sd2</code>. If pooled standard deviation (psd) is available set <code>sd1 = psd</code>.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.np.2groups(mu1 = 0.20, mu2 = 0,
                sd1 = ifelse(paired, sqrt(1/(2*(1-paired.r))), 1), sd2 = sd1,
                margin = 0, alpha = 0.05, paired = FALSE, paired.r = 0.50,
                kappa = 1, n2 = NULL, power = NULL,
                alternative = c("not equal", "greater", "less",
                                "non-inferior", "superior", "equivalent"),
                distribution = c("normal", "uniform", "double exponential",
                                 "laplace", "logistic"),
                method = c("guenther", "noether"),
                verbose = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.np.2groups_+3A_mu1">mu1</code></td>
<td>
<p>expected mean in the first group</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_mu2">mu2</code></td>
<td>
<p>expected mean in the second group</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_sd1">sd1</code></td>
<td>
<p>expected standard deviation in the first group</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_sd2">sd2</code></td>
<td>
<p>expected standard deviation in the second group</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_paired">paired</code></td>
<td>
<p>if <code>TRUE</code> paired samples</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_paired.r">paired.r</code></td>
<td>
<p>correlation between repeated measures for paired samples (e.g., pretest and posttest)</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_n2">n2</code></td>
<td>
<p>sample size in the second group (or for the single group in paired samples)</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_kappa">kappa</code></td>
<td>
<p><code>n1/n2</code> ratio (applies to independent samples only)</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_margin">margin</code></td>
<td>
<p>non-inferority, superiority, or equivalence margin (margin: boundry of <code>mu1 - mu2</code> that is practically insignificant)</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_distribution">distribution</code></td>
<td>
<p>parent distribution: &quot;normal&quot;, &quot;uniform&quot;, &quot;double exponential&quot;, &quot;laplace&quot;, or &quot;logistic&quot;</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_method">method</code></td>
<td>
<p>non-parametric method: &quot;guenther&quot; (default) or &quot;noether&quot;</p>
</td></tr>
<tr><td><code id="pwrss.np.2groups_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z or t test)</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Al-Sunduqchi, M. S. (1990). Determining the appropriate sample size for inferences based on the Wilcoxon statistics [Unpublished doctoral dissertation]. University of Wyoming - Laramie
</p>
<p>Chow, S. C., Shao, J., Wang, H., and Lokhnygina, Y. (2018). Sample size calculations in clinical research (3rd ed.). Taylor &amp; Francis/CRC.
</p>
<p>Noether, G. E. (1987). Sample size determination for some common nonparametric tests. Journal of the American Statistical Association, 82(1), 645-647.
</p>
<p>Ruscio, J. (2008). A probability-based measure of effect size: Robustness to base rates and other factors. Psychological Methods, 13(1), 19-30.
</p>
<p>Ruscio, J., &amp; Mullen, T. (2012). Confidence intervals for the probability of superiority effect size measure and the area under a receiver operating characteristic curve. Multivariate Behavioral Research, 47(2), 201-223.
</p>
<p>Zhao, Y.D., Rahardja, D., &amp; Qu, Y. (2008). Sample size calculation for the Wilcoxon-Mann-Whitney test adjusting for ties. Statistics in Medicine, 27(3), 462-468.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Mann-Whitney U or Wilcoxon rank-sum test
# (a.k.a Wilcoxon-Mann-Whitney test) for independent samples

## difference between group 1 and group 2 is not equal to zero
## estimated difference is Cohen'd = 0.25
pwrss.np.2means(mu1 = 0.25, mu2 = 0, power = 0.80,
                alternative = "not equal")

## difference between group 1 and group 2 is greater than zero
## estimated difference is Cohen'd = 0.25
pwrss.np.2means(mu1 = 0.25, mu2 = 0, power = 0.80,
                alternative = "greater")

## mean of group 1 is practically not smaller than mean of group 2
## estimated difference is Cohen'd = 0.10 and can be as small as -0.05
pwrss.np.2means(mu1 = 0.25, mu2 = 0.15,
                margin = -0.05, power = 0.80,
                alternative = "non-inferior")

## mean of group 1 is practically greater than mean of group 2
## estimated difference is Cohen'd = 0.10 and can be as small as 0.05
pwrss.np.2means(mu1 = 0.25, mu2 = 0.15,
                margin = 0.05, power = 0.80,
                alternative = "superior")

## mean of group 1 is practically same as mean of group 2
## estimated difference is Cohen'd = 0
## and can be as small as -0.05 and as high as 0.05
pwrss.np.2means(mu1 = 0.25, mu2 = 0.25,
                margin = 0.05, power = 0.80,
                alternative = "equivalent")


# Wilcoxon signed-rank test for matched pairs (dependent samples)

## difference between time 1 and time 2 is not equal to zero
## estimated difference between time 1 and time 2 is Cohen'd = -0.25
pwrss.np.2means(mu1 = 0, mu2 = 0.25, power = 0.80,
                paired = TRUE, paired.r = 0.50,
                alternative = "not equal")

## difference between time 1 and time 2 is greater than zero
## estimated difference between time 1 and time 2 is Cohen'd = -0.25
pwrss.np.2means(mu1 = 0, mu2 = 0.25, power = 0.80,
                paired = TRUE, paired.r = 0.50,
                alternative = "greater")

## mean of time 1 is practically not smaller than mean of time 2
## estimated difference is Cohen'd = -0.10 and can be as small as 0.05
pwrss.np.2means(mu1 = 0.15, mu2 = 0.25, margin = 0.05,
                paired = TRUE, paired.r = 0.50, power = 0.80,
                alternative = "non-inferior")

## mean of time 1 is practically greater than mean of time 2
## estimated difference is Cohen'd = -0.10 and can be as small as -0.05
pwrss.np.2means(mu1 = 0.15, mu2 = 0.25, margin = -0.05,
                paired = TRUE, paired.r = 0.50, power = 0.80,
                alternative = "superior")

## mean of time 1 is practically same as mean of time 2
## estimated difference is Cohen'd = 0
## and can be as small as -0.05 and as high as 0.05
pwrss.np.2means(mu1 = 0.25, mu2 = 0.25, margin = 0.05,
                paired = TRUE, paired.r = 0.50, power = 0.80,
                alternative = "equivalent")
</code></pre>

<hr>
<h2 id='pwrss.t.2means'>Difference between Two Means (t or z Test for Independent or Paired Samples)</h2><span id='topic+pwrss.t.2means'></span><span id='topic+pwrss.z.2means'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test difference between two means.
For standardized mean difference (Cohen's d) set <code>mu1 = d</code> and use defaults for <code>mu2</code>, <code>sd1</code>, and <code>sd2</code>.
If pooled standard deviation (psd) is available set <code>sd1 = psd</code>.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, <a href="http://powerandsamplesize.com/">http://powerandsamplesize.com/</a>, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.t.2means(mu1, mu2 = 0, margin = 0,
               sd1 = ifelse(paired, sqrt(1/(2*(1-paired.r))), 1), sd2 = sd1,
               kappa = 1, paired = FALSE, paired.r = 0.50,
               alpha = 0.05, welch.df = FALSE,
               alternative = c("not equal","greater","less",
                               "equivalent","non-inferior","superior"),
               n2 = NULL, power = NULL, verbose = TRUE)

pwrss.z.2means(mu1, mu2 = 0, sd1 = 1, sd2 = sd1, margin = 0,
               kappa = 1, alpha = 0.05,
               alternative = c("not equal", "greater", "less",
                               "equivalent", "non-inferior", "superior"),
               n2 = NULL, power = NULL, verbose = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.t.2means_+3A_mu1">mu1</code></td>
<td>
<p>expected mean in the first group</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_mu2">mu2</code></td>
<td>
<p>expected mean in the second group</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_sd1">sd1</code></td>
<td>
<p>expected standard deviation in the first group</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_sd2">sd2</code></td>
<td>
<p>expected standard deviation in the second group</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_paired">paired</code></td>
<td>
<p>if <code>TRUE</code> paired samples t test</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_paired.r">paired.r</code></td>
<td>
<p>correlation between repeated measures for paired samples (e.g., pretest and posttest)</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_n2">n2</code></td>
<td>
<p>sample size in the second group (or for the single group in paired samples)</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_kappa">kappa</code></td>
<td>
<p><code>n1/n2</code> ratio (applies to independent samples only)</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_welch.df">welch.df</code></td>
<td>
<p>if <code>TRUE</code> uses Welch's degrees of freedom adjustment when groups sizes or variances are not equal (applies to independent samples t test only)</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_margin">margin</code></td>
<td>
<p>non-inferority, superiority, or equivalence margin (margin: boundry of <code>mu1 - mu2</code> that is practically insignificant)</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;</p>
</td></tr>
<tr><td><code id="pwrss.t.2means_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z or t test)</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Chow, S. C., Shao, J., Wang, H., &amp; Lokhnygina, Y. (2018). Sample size calculations in clinical research (3rd ed.). Taylor &amp; Francis/CRC.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># independent samples t test

## difference between group 1 and group 2 is not equal to zero
## estimated difference is Cohen'd = 0.25
pwrss.t.2means(mu1 = 0.25, mu2 = 0, power = 0.80,
                alternative = "not equal")

## difference between group 1 and group 2 is greater than zero
## estimated difference is Cohen'd = 0.25
pwrss.t.2means(mu1 = 0.25, mu2 = 0, power = 0.80,
                alternative = "greater")

## mean of group 1 is practically not smaller than mean of group 2
## estimated difference is Cohen'd = 0.10 and can be as small as -0.05
pwrss.t.2means(mu1 = 0.25, mu2 = 0.15,
                margin = -0.05, power = 0.80,
                alternative = "non-inferior")

## mean of group 1 is practically greater than mean of group 2
## estimated difference is Cohen'd = 0.10 and can be as small as 0.05
pwrss.t.2means(mu1 = 0.25, mu2 = 0.15,
                margin = 0.05, power = 0.80,
                alternative = "superior")

## mean of group 1 is practically same as mean of group 2
## estimated difference is Cohen'd = 0
## and can be as small as -0.05 and as high as 0.05
pwrss.t.2means(mu1 = 0.25, mu2 = 0.25,
                margin = 0.05, power = 0.80,
                alternative = "equivalent")


#  dependent samples (matched pairs) t test

## difference between time 1 and time 2 is not equal to zero
## estimated difference between time 1 and time 2 is Cohen'd = -0.25
pwrss.t.2means(mu1 = 0, mu2 = 0.25, power = 0.80,
                paired = TRUE, paired.r = 0.50,
                alternative = "not equal")

## difference between time 1 and time 2 is less than zero
## estimated difference between time 1 and time 2 is Cohen'd = -0.25
pwrss.t.2means(mu1 = 0, mu2 = 0.25, power = 0.80,
                paired = TRUE, paired.r = 0.50,
                alternative = "less")

## mean of time 1 is practically not smaller than mean of time 2
## estimated difference is Cohen'd = -0.10 and can be as small as 0.05
pwrss.t.2means(mu1 = 0.15, mu2 = 0.25, margin = 0.05,
                paired = TRUE, paired.r = 0.50, power = 0.80,
                alternative = "non-inferior")

## mean of time 1 is practically greater than mean of time 2
## estimated difference is Cohen'd = -0.10 and can be as small as -0.05
pwrss.t.2means(mu1 = 0.15, mu2 = 0.25, margin = -0.05,
                paired = TRUE, paired.r = 0.50, power = 0.80,
                alternative = "superior")

## mean of time 1 is practically same as mean of time 2
## estimated difference is Cohen'd = 0
## and can be as small as -0.05 and as high as 0.05
pwrss.t.2means(mu1 = 0.25, mu2 = 0.25, margin = 0.05,
                paired = TRUE, paired.r = 0.50, power = 0.80,
                alternative = "equivalent")

</code></pre>

<hr>
<h2 id='pwrss.t.mean'>One Mean against a Constant (z or t Test)</h2><span id='topic+pwrss.z.mean'></span><span id='topic+pwrss.t.mean'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test a mean against a constant.
</p>
<p>Formulas are validated using <a href="http://powerandsamplesize.com/">http://powerandsamplesize.com/</a>, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.t.mean(mu, sd = 1, mu0 = 0, margin = 0, alpha = 0.05,
             alternative = c("not equal","greater","less",
                             "equivalent","non-inferior","superior"),
             n = NULL, power = NULL, verbose = TRUE)

pwrss.z.mean(mu, sd = 1, mu0 = 0, margin = 0, alpha = 0.05,
             alternative = c("not equal","greater","less",
                             "equivalent","non-inferior","superior"),
             n = NULL, power = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.t.mean_+3A_mu">mu</code></td>
<td>
<p>expected mean</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_sd">sd</code></td>
<td>
<p>expected standard devation</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_mu0">mu0</code></td>
<td>
<p>constant to be compared (a mean)</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_margin">margin</code></td>
<td>
<p>non-inferority, superiority, or equivalence margin (margin: boundry of <code>mu - mu0</code> that is practically insignificant)</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;</p>
</td></tr>
<tr><td><code id="pwrss.t.mean_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z or t test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: A researcher is expecting a score of 23
# on Beck depression inventory (BDI) which is
# 0.50 standard devation above the threshold value 20
# (assume standard deviation of BDI scores is 6).

# to find that a score of 23 is greater than the threshold 20
pwrss.t.mean(mu = 23, mu0 = 20, sd = 6,
             alpha = 0.05, power = 0.80,
             alternative = "greater")
# standardized formulation
pwrss.t.mean(mu = 0.50, mu0 = 0, sd = 1,
             alpha = 0.05, power = 0.80,
             alternative = "greater")
</code></pre>

<hr>
<h2 id='pwrss.t.reg'>Linear Regression: Single Coefficient (t or z Test)</h2><span id='topic+pwrss.t.reg'></span><span id='topic+pwrss.z.reg'></span><span id='topic+pwrss.t.regression'></span><span id='topic+pwrss.z.regression'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test a single coefficient in multiple linear regression. The predictor is assumed to be continuous by default. However, one can find statistical power or minimum required sample size for a binary predictor (such as treatment and control groups in an experimental design) by specifying <code>sdx = sqrt(p*(1-p))</code> where <code>p</code> is the proportion of subjects in one of the groups. The sample size in each group would be <code>n*p</code> and <code>n*(1-p)</code>. <code>pwrss.t.regression()</code> and <code>pwrss.t.reg()</code> are the same functions.
</p>
<p>When HIGHER values of an outcome is a good thing, <code>beta1</code> is expected to be greater than <code>beta0 + margin</code> for non-inferiority and superiority tests. In this case, <code>margin</code> is NEGATIVE for the non-inferiority test but it is POSITIVE for the superiority test.
</p>
<p>When LOWER values of an outcome is a good thing, <code>beta1</code> is expected to be less than <code>beta0 + margin</code> for non-inferiority and superiority tests. In this case, <code>margin</code> is POSITIVE for the non-inferiority test but it is NEGATIVE for the superiority test.
</p>
<p>For equivalence tests the value of <code>beta0</code> shifts both to the left and right as <code>beta0 - margin</code> and <code>beta0 + margin</code>. For equivalence tests <code>margin</code> is stated as the absolute value and <code>beta1</code> is expected to fall between <code>beta0 - margin</code> and <code>beta0 + margin</code>.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, tables in PASS documentation, and tables in Bulus (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.t.reg(beta1 = 0.25, beta0 = 0, margin = 0,
            sdx = 1, sdy = 1,
            k = 1, r2 = (beta1 * sdx / sdy)^2,
            alpha = 0.05, n = NULL, power = NULL,
            alternative = c("not equal", "less", "greater",
                            "non-inferior", "superior", "equivalent"),
            verbose = TRUE)

pwrss.z.reg(beta1 = 0.25, beta0 = 0, margin = 0,
            sdx = 1, sdy = 1,
            k = 1, r2 = (beta1 * sdx / sdy)^2,
            alpha = 0.05, n = NULL, power = NULL,
            alternative = c("not equal", "less", "greater",
                            "non-inferior", "superior", "equivalent"),
            verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.t.reg_+3A_beta1">beta1</code></td>
<td>
<p>expected regression coefficient. One can use standardized regression coefficient, but should keep <code>sdx = 1</code> and <code>sdy = 1</code> or leave them out as they are default specifications</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_beta0">beta0</code></td>
<td>
<p>regression coefficient under null hypothesis (usually zero). Not to be confused with the intercept. One can use standardized regression coefficient, but should keep <code>sdx = 1</code> and <code>sdy = 1</code> or leave them out as they are default specifications</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_margin">margin</code></td>
<td>
<p>non-inferiority, superiority, or equivalence margin (margin: boundry of <code>beta1 - beta0</code> that is practically insignificant)</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_sdx">sdx</code></td>
<td>
<p>expected standard deviation of the predictor. For a binary predictor, <code>sdx = sqrt(p*(1-p))</code> where<code>p</code> is the proportion of subjects in one of the groups</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_sdy">sdy</code></td>
<td>
<p>expected standard deviation of the outcome</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_k">k</code></td>
<td>
<p>(total) number of predictors</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_r2">r2</code></td>
<td>
<p>expected model R-squared. The default is <code>r2 = (beta * sdx / sdy)^2</code> assuming a linear regression with one predictor. Thus, an <code>r2</code> below this value will throw a warning. To consider other covariates in the model provide a value greater than the default <code>r2</code> along with the argument <code>k&gt;1</code>.</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;non-inferior&quot;, &quot;superior&quot;, or &quot;equivalent&quot;</p>
</td></tr>
<tr><td><code id="pwrss.t.reg_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z or t test)</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M. (2021). Sample size determination and optimal design of randomized/non-equivalent pretest-posttest control-group designs. Adiyaman Univesity Journal of Educational Sciences, 11(1), 48-69.
</p>
<p>Phillips, K. F. (1990). Power of the two one-Sided tests procedure in bioequivalence. Journal of Pharmacokinetics and Biopharmaceutics, 18(2), 137-144.
</p>
<p>Dupont, W. D., and Plummer, W. D. (1998). Power and sample size calculations for studies involving linear regression. Controlled Clinical Trials, 19(6), 589-601.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># continuous predictor x (and 4 covariates)
pwrss.t.reg(beta1 = 0.20, alpha = 0.05,
            alternative = "not equal",
            k = 5, r2 = 0.30,
            power = 0.80)

pwrss.t.reg(beta1 = 0.20, alpha = 0.05,
            alternative = "not equal",
            k = 5, r2 = 0.30,
            n = 138)

# binary predictor x (and 4 covariates)
p &lt;- 0.50 # proportion of subjects in one group
pwrss.t.reg(beta1 = 0.20, alpha = 0.05,
            alternative = "not equal",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            power = 0.80)

pwrss.t.reg(beta1 = 0.20, alpha = 0.05,
            alternative = "not equal",
            sdx = sqrt(p*(1-p)) ,
            k = 5, r2 = 0.30,
            n = 550)

# non-inferiority test with binary predictor x (and 4 covariates)
p &lt;- 0.50 # proportion of subjects in one group
pwrss.t.reg(beta1 = 0.20, beta0 = 0.10, margin = -0.05,
            alpha = 0.05, alternative = "non-inferior",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            power = 0.80)

pwrss.t.reg(beta1 = 0.20, beta0 = 0.10, margin = -0.05,
            alpha = 0.05, alternative = "non-inferior",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            n = 770)

# superiority test with binary predictor x (and 4 covariates)
p &lt;- 0.50 # proportion of subjects in one group
pwrss.t.reg(beta1 = 0.20, beta0 = 0.10, margin = 0.01,
            alpha = 0.05, alternative = "superior",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            power = 0.80)

pwrss.t.reg(beta1 = 0.20, beta0 = 0.10, margin = 0.01,
            alpha = 0.05, alternative = "superior",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            n = 2138)

# equivalence test with binary predictor x (and 4 covariates)
p &lt;- 0.50 # proportion of subjects in one group
pwrss.t.reg(beta1 = 0.20, beta0 = 0.20, margin = 0.05,
            alpha = 0.05, alternative = "equivalent",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            power = 0.80)

pwrss.t.reg(beta1 = 0.20, beta0 = 0.20, margin = 0.05,
            alpha = 0.05, alternative = "equivalent",
            sdx = sqrt(p*(1-p)),
            k = 5, r2 = 0.30,
            n = 9592)
</code></pre>

<hr>
<h2 id='pwrss.z.2corrs'>Difference between Two Correlations (Independent Samples z Test)</h2><span id='topic+pwrss.z.2corrs'></span><span id='topic+pwrss.z.2cors'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test difference between two independent (Pearson) correlations using Fisher's z transformation.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.2corrs(r1 = 0.50, r2 = 0.30,
               alpha = 0.05, kappa = 1,
               alternative = c("not equal","greater","less"),
               n2 = NULL, power = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.2corrs_+3A_r1">r1</code></td>
<td>
<p>expected correlation in the first group</p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_r2">r2</code></td>
<td>
<p>expected correlation in the second group</p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_n2">n2</code></td>
<td>
<p>sample size in the second group. Sample size in the first group can be calculated as <code>n2*kappa</code>. By default, <code>n1 = n2</code> because <code>kappa = 1</code></p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_kappa">kappa</code></td>
<td>
<p><code>n1/n2</code> ratio</p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, or &quot;less&quot;</p>
</td></tr>
<tr><td><code id="pwrss.z.2corrs_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size for the first and second groups</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Chow, S. C., Shao, J., Wang, H., &amp; Lokhnygina, Y. (2018). Sample size calculations in clinical research (3rd ed.). Taylor &amp; Francis/CRC.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># difference between r1 and r2 is different from zero
# it could be -0.10 as well as 0.10
pwrss.z.2corrs(r1 = .20, r2 = 0.30,
               alpha = 0.05, power = .80,
               alternative = "not equal")

# difference between r1 and r2 is greater than zero
pwrss.z.2corrs(r1 = .30, r2 = 0.20,
               alpha = 0.05, power = .80,
               alternative = "greater")
</code></pre>

<hr>
<h2 id='pwrss.z.2props'>Difference between Two Proportions (z Test)</h2><span id='topic+pwrss.z.2props'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test difference between two proportions.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, <a href="http://powerandsamplesize.com/">http://powerandsamplesize.com/</a> and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.2props(p1, p2, margin = 0, arcsin.trans = FALSE, kappa = 1, alpha = 0.05,
               alternative = c("not equal","greater","less",
                               "equivalent","non-inferior","superior"),
               n2 = NULL, power = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.2props_+3A_p1">p1</code></td>
<td>
<p>expected proportion in the first group</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_p2">p2</code></td>
<td>
<p>expected proportion in the second group</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_arcsin.trans">arcsin.trans</code></td>
<td>
<p>if <code>TRUE</code> uses arcsine transformation, if <code>FALSE</code> uses normal approximation (default)</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_kappa">kappa</code></td>
<td>
<p><code>n1/n2</code> ratio</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_n2">n2</code></td>
<td>
<p>sample size in the second group. Sample size in the first group can be calculated as <code>n2*kappa</code>. By default, <code>n1 = n2</code> because <code>kappa = 1</code></p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error.</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_margin">margin</code></td>
<td>
<p>non-inferority, superiority, or equivalence margin (margin: boundry of <code>p1 - p2</code> that is practically insignificant)</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;</p>
</td></tr>
<tr><td><code id="pwrss.z.2props_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size for the first and second group</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Chow, S. C., Shao, J., Wang, H., &amp; Lokhnygina, Y. (2018). Sample size calculations in clinical research (3rd ed.). Taylor &amp; Francis/CRC.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: expecting p1 - p2 smaller than 0
## one-sided test with normal approximation
pwrss.z.2props(p1 = 0.45, p2 = 0.50,
               alpha = 0.05, power = 0.80,
               alternative = "less",
               arcsin.trans = FALSE)
## one-sided test with arcsine transformation
pwrss.z.2props(p1 = 0.45, p2 = 0.50,
               alpha = 0.05, power = 0.80,
               alternative = "less",
               arcsin.trans = TRUE)

# Example 2: expecting p1 - p2 smaller than 0 or greater than 0
## two-sided test with normal approximation
pwrss.z.2props(p1 = 0.45, p2 = 0.50,
               alpha = 0.05, power = 0.80,
               alternative = "not equal",
               arcsin.trans = FALSE)
## two-sided test with arcsine transformation
pwrss.z.2props(p1 = 0.45, p2 = 0.50,
               alpha = 0.05, power = 0.80,
               alternative = "not equal",
               arcsin.trans = TRUE)

# Example 2: expecting p1 - p2 smaller than 0.01
# when smaller proportion is better
## non-inferiority test with normal approximation
pwrss.z.2props(p1 = 0.45, p2 = 0.50, margin = 0.01,
               alpha = 0.05, power = 0.80,
               alternative = "non-inferior",
               arcsin.trans = FALSE)
## non-inferiority test with arcsine transformation
pwrss.z.2props(p1 = 0.45, p2 = 0.50, margin = 0.01,
               alpha = 0.05, power = 0.80,
               alternative = "non-inferior",
               arcsin.trans = TRUE)

# Example 3: expecting p1 - p2 greater than -0.01
# when bigger proportion is better
## non-inferiority test with normal approximation
pwrss.z.2props(p1 = 0.55, p2 = 0.50, margin = -0.01,
               alpha = 0.05, power = 0.80,
               alternative = "non-inferior",
               arcsin.trans = FALSE)
## non-inferiority test with arcsine transformation
pwrss.z.2props(p1 = 0.55, p2 = 0.50,  margin = -0.01,
               alpha = 0.05, power = 0.80,
               alternative = "non-inferior",
               arcsin.trans = TRUE)

# Example 4: expecting p1 - p2 smaller than -0.01
# when smaller proportion is better
## superiority test with normal approximation
pwrss.z.2props(p1 = 0.45, p2 = 0.50, margin = -0.01,
               alpha = 0.05, power = 0.80,
               alternative = "superior",
               arcsin.trans = FALSE)
## superiority test with arcsine transformation
pwrss.z.2props(p1 = 0.45, p2 = 0.50, margin = -0.01,
               alpha = 0.05, power = 0.80,
               alternative = "superior",
               arcsin.trans = TRUE)

# Example 5: expecting p1 - p2 greater than 0.01
# when bigger proportion is better
## superiority test with normal approximation
pwrss.z.2props(p1 = 0.55, p2 = 0.50, margin = 0.01,
               alpha = 0.05, power = 0.80,
               alternative = "superior",
               arcsin.trans = FALSE)
## superiority test with arcsine transformation
pwrss.z.2props(p1 = 0.55, p2 = 0.50, margin = 0.01,
               alpha = 0.05, power = 0.80,
               alternative = "superior",
               arcsin.trans = TRUE)

# Example 6: expecting p1 - p2 between -0.01 and 0.01
## equivalence test with normal approximation
pwrss.z.2props(p1 = 0.50, p2 = 0.50, margin = 0.01,
               alpha = 0.05, power = 0.80,
               alternative = "equivalent",
               arcsin.trans = FALSE)
# equivalence test with arcsine transformation
pwrss.z.2props(p1 = 0.50, p2 = 0.50, margin = 0.01,
               alpha = 0.05, power = 0.80,
               alternative = "equivalent",
               arcsin.trans = TRUE)
</code></pre>

<hr>
<h2 id='pwrss.z.corr'>One Correlation against a Constant (One Sample z Test)</h2><span id='topic+pwrss.z.corr'></span><span id='topic+pwrss.z.cor'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test a (Pearson) correlation against a constant using Fisher's z transformation.
</p>
<p>Formulas are validated using G*Power and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.corr(r = 0.50, r0 = 0, alpha = 0.05,
             alternative = c("not equal","greater","less"),
             n = NULL, power = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.corr_+3A_r">r</code></td>
<td>
<p>expected correlation</p>
</td></tr>
<tr><td><code id="pwrss.z.corr_+3A_r0">r0</code></td>
<td>
<p>constant to be compared (a correlation)</p>
</td></tr>
<tr><td><code id="pwrss.z.corr_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="pwrss.z.corr_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.corr_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.z.corr_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, or &quot;less&quot;</p>
</td></tr>
<tr><td><code id="pwrss.z.corr_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Chow, S. C., Shao, J., Wang, H., &amp; Lokhnygina, Y. (2018). Sample size calculations in clinical research (3rd ed.). Taylor &amp; Francis/CRC.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># expected correlation is 0.20 and it is different from 0
# it could be 0.20 as well as -0.20
pwrss.z.corr(r = 0.20, r0 = 0,
             alpha = 0.05, power = 0.80,
             alternative = "not equal")

# expected correlation is 0.20 and it is greater than 0.10
pwrss.z.corr(r = 0.20, r0 = 0.10,
             alpha = 0.05, power = 0.80,
             alternative = "greater")
</code></pre>

<hr>
<h2 id='pwrss.z.logreg'>Logistic Regression: Single Coefficient (Large Sample Approx. Wald's z Test)</h2><span id='topic+pwrss.z.logreg'></span><span id='topic+pwrss.z.logistic'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test a single coefficient in logistic regression. <code>pwrss.z.logistic()</code> and <code>pwrss.z.logreg()</code> are the same functions. The distribution of the predictor variable can be one of the following: <code>c("normal", "poisson", "uniform", "exponential", "binomial", "bernouilli", "lognormal")</code> for Demidenko (2007) procedure but only <code>c("normal", "binomial", "bernouilli")</code> for Hsieh et al. (1998) procedure. The default parameters for these distributions are
</p>
<p><code>distribution = list(dist = "normal", mean = 0, sd = 1)</code> <br />
<code>distribution = list(dist = "poisson", lambda = 1)</code> <br />
<code>distribution = list(dist = "uniform", min = 0, max = 1)</code> <br />
<code>distribution = list(dist = "exponential", rate = 1)</code> <br />
<code>distribution = list(dist = "binomial", size = 1, prob = 0.50)</code> <br />
<code>distribution = list(dist = "bernoulli", prob = 0.50)</code> <br />
<code>distribution = list(dist = "lognormal", meanlog = 0, sdlog = 1)</code> <br />
</p>
<p>Parameters defined in <code>list()</code> form can be modified, but the names should be kept the same. It is sufficient to use distribution's name for default parameters (e.g. <code>dist = "normal"</code>).
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.logreg(p1 = 0.10, p0 = 0.15,
               odds.ratio  = (p1/(1-p1))/(p0/(1-p0)),
               beta0 = log(p0/(1-p0)), beta1 = log(odds.ratio),
               n = NULL, power = NULL, r2.other.x = 0, alpha = 0.05,
               alternative = c("not equal", "less", "greater"),
               method = c("demidenko(vc)", "demidenko", "hsieh"),
               distribution = "normal", verbose = TRUE)


pwrss.z.logistic(p1 = 0.10, p0 = 0.15,
                 odds.ratio  = (p1/(1-p1))/(p0/(1-p0)),
                 beta0 = log(p0/(1-p0)), beta1 = log(odds.ratio),
                 n = NULL, power = NULL, r2.other.x = 0, alpha = 0.05,
                 alternative = c("not equal", "less", "greater"),
                 method = c("demidenko(vc)", "demidenko", "hsieh"),
                 distribution = "normal", verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.logreg_+3A_p0">p0</code></td>
<td>
<p>base probability under null hypothesis (probability that an event occurs without the influence of the predictor X - or when the value of the predictor is zero)</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_p1">p1</code></td>
<td>
<p>probability under alternative hypothesis (probability that an event occurs when the value of the predictor X is increased by one unit)</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_beta0">beta0</code></td>
<td>
<p>regression coefficient defined as <br /> <code>beta0 = log( p0/(1-p0) )</code></p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_beta1">beta1</code></td>
<td>
<p>regression coefficient for the predictor X defined as <br /> <code>beta1 = log( (p1/(1-p1)) / (p0/(1-p0)) )</code></p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_odds.ratio">odds.ratio</code></td>
<td>
<p>odds ratio defined as <br /> <code>odds.ratio = exp(beta1) = (p1/(1-p1)) / (p0/(1-p0))</code></p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_r2.other.x">r2.other.x</code></td>
<td>
<p>proportion of variance in the predictor X explained by other covariates. Not to be confused with pseudo R-squared</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_method">method</code></td>
<td>
<p>calculation method. <code>"demidenko(vc)"</code> stands for Demidenko (2007) procedure with variance correction; <code>"demidenko"</code> stands for Demidenko (2007) procedure without variance correction; <code>"hsieh"</code> stands for Hsieh et al. (1998) procedure. <code>"demidenko"</code> and <code>"hsieh"</code> methods produce similiar results but <code>"demidenko(vc)"</code> is more precise</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_distribution">distribution</code></td>
<td>
<p>distribution family. Can be one of the <code>c("noramal", "poisson", "uniform", "exponential", "binomial", "bernouilli", "lognormal")</code> for Demidenko (2007) procedure but only <code>c("normal", "binomial", "bernouilli")</code> for Hsieh et al. (1998) procedure</p>
</td></tr>
<tr><td><code id="pwrss.z.logreg_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Demidenko, E. (2007). Sample size determination for logistic regression revisited. Statistics in Medicine, 26(18), 3385-3397.
</p>
<p>Hsieh, F. Y., Bloch, D. A., &amp; Larsen, M. D. (1998). A simple method of sample size calculation for linear and logistic regression. Statistics in Medicine, 17(4), 1623-1634.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# predictor X follows normal distribution

## probability specification
pwrss.z.logreg(p0 = 0.15, p1 = 0.10,
               alpha = 0.05, power = 0.80,
               dist = "normal")

## odds ratio specification
pwrss.z.logreg(p0 = 0.15, odds.ratio = 0.6296,
               alpha = 0.05, power = 0.80,
               dist = "normal")

## regression coefficient specification
pwrss.z.logreg(p0 = 0.15, beta1 = -0.4626,
               alpha = 0.05, power = 0.80,
               dist = "normal")

## change parameters associated with predictor X
dist.x &lt;- list(dist = "normal", mean = 10, sd = 2)
pwrss.z.logreg(p0 = 0.15, beta1 = -0.4626,
               alpha = 0.05, power = 0.80,
               dist = dist.x)


# predictor X follows Bernoulli distribution (such as treatment/control groups)

## probability specification
pwrss.z.logreg(p0 = 0.15, p1 = 0.10,
               alpha = 0.05, power = 0.80,
               dist = "bernoulli")

## odds ratio specification
pwrss.z.logreg(p0 = 0.15, odds.ratio = 0.6296,
               alpha = 0.05, power = 0.80,
               dist = "bernoulli")

## regression coefficient specification
pwrss.z.logreg(p0 = 0.15, beta1 = -0.4626,
               alpha = 0.05, power = 0.80,
               dist = "bernoulli")

## change parameters associated with predictor X
dist.x &lt;- list(dist = "bernoulli", prob = 0.30)
pwrss.z.logreg(p0 = 0.15, beta1 = -0.4626,
               alpha = 0.05, power = 0.80,
               dist = dist.x)
</code></pre>

<hr>
<h2 id='pwrss.z.med'>Indirect Effect in Mediation Analysis (z, Joint, and Monte Carlo Tests)</h2><span id='topic+pwrss.z.med'></span><span id='topic+pwrss.z.mediation'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test indirect effects in mediation analysis (z test, joint test, and Monte Carlo test). One can consider explanatory power of the covariates in the mediator and outcome model via specifying R-squared values accordingly. <code>pwrss.z.mediation()</code> and <code>pwrss.z.med()</code> are the same functions.
</p>
<p>Formulas are validated using Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.med(a, b, cp = 0,
            sdx = 1, sdm = 1, sdy = 1,
            r2m.x = a^2 * sdx^2 / sdm^2,
            r2y.mx = (b^2 * sdm^2 + cp^2 * sdx^2) / sdy^2,
            n = NULL, power = NULL, alpha = 0.05,
            alternative = c("not equal", "less", "greater"),
            mc = TRUE, nsims = 1000, ndraws = 1000,
            verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.med_+3A_a">a</code></td>
<td>
<p>expected regression coefficient for X -&gt; M path. One can use standardized regression coefficient, but should keep <code>sdx = 1</code> and <code>sdm = 1</code> or leave them out as they are default specifications</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_b">b</code></td>
<td>
<p>expected regression coefficient for M -&gt; Y path. One can use standardized regression coefficient, but should keep <code>sdm = 1</code> and <code>sdy = 1</code> or leave them out as they are default specifications</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_cp">cp</code></td>
<td>
<p>expected regression coefficient for X -&gt; Y path (the direct path). One can use standardized regression coefficient, but should keep <code>sdx = 1</code> and <code>sdy = 1</code> or leave them out as they are default specifications</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_sdx">sdx</code></td>
<td>
<p>expected standard deviation of the predictor (X). For a binary predictor, <code>sdx = sqrt(p*(1-p))</code> where<code>p</code> is the proportion of subjects in one of the groups</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_sdm">sdm</code></td>
<td>
<p>expected standard deviation of the mediator (M)</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_sdy">sdy</code></td>
<td>
<p>expected standard deviation of the outcome (Y)</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_r2m.x">r2m.x</code></td>
<td>
<p>expected R-squared value for the mediator model (M ~ X). The default is <code>r2m.x = a^2 * sdx^2 / sdm^2</code> assuming that X is the only predictor. Thus, an <code>r2m.x</code> below this value will throw a warning. To consider other covariates in the mediator model provide a value greater than the default</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_r2y.mx">r2y.mx</code></td>
<td>
<p>expected R-squared value for the outcome model (Y ~ M + X). The default is <code>r2y.mx = (b^2 * sdm^2 + cp^2 * sdx^2) / sdy^2</code> assuming that M and X are the only predictors. Thus, an <code>r2y.mx</code> below this value will throw a warning. To consider other covariates in the outcome model provide a value greater than the default</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_alternative">alternative</code></td>
<td>
<p>direction of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;. It applies to all tests (for path 'a', 'b', and the indirect effect) and typically specified as &quot;not equal&quot;. If path 'a' and 'b' have the opposite signs there will be a warning for &quot;greater&quot; or &quot;less&quot; tests (it can be ignored)</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_mc">mc</code></td>
<td>
<p>logical; if <code>TRUE</code>, statistical power is based on monte carlo simulation</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_nsims">nsims</code></td>
<td>
<p>number of replications (applies when <code>mc = TRUE</code>)</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_ndraws">ndraws</code></td>
<td>
<p>number of draws from the distribution of the path coefficients for each replication (applies when <code>mc = TRUE</code>)</p>
</td></tr>
<tr><td><code id="pwrss.z.med_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Aroian, L. A. (1947). The probability function of the product of two normally distributed variables. Annals of Mathematical Statistics, 18(2), 265-271.
</p>
<p>Goodman, L. A. (1960). On the exact variance of products. Journal of the American Statistical Association, 55(292), 708-713.
</p>
<p>MacKinnon, D. P., &amp; Dwyer, J. H. (1993). Estimating mediated effects in prevention studies. Evaluation Review, 17(2), 144-158.
</p>
<p>MacKinnon, D. P., Warsi, G., &amp; Dwyer, J. H. (1995). A simulation study of mediated effect measures. Multivariate Behavioral Research, 30(1), 41-62.
</p>
<p>Preacher, K. J., &amp; Hayes, A. F. (2004). SPSS and SAS procedures for estimating indirect effects in simple mediation models. Behavior Research Methods, Instruments, &amp; Computers, 36, 717-731.
</p>
<p>Preacher, K. J., &amp; Hayes, A. F. (2008). Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models. Behavior Research Methods, 40, 879-891.
</p>
<p>Sobel, M. E. (1982). Asymptotic intervals for indirect effects in structural equations models. In S. Leinhart (Ed.), Sociological methodology 1982 (pp. 290-312). Jossey-Bass.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># with standardized coefficients

## statistical power
pwrss.z.med(a = 0.25, b = 0.25, cp = 0.10,
            alpha = 0.05, n = 200, mc = TRUE)

## minimum required sample size
pwrss.z.med(a = 0.25, b = 0.25, cp = 0.10,
            alpha = 0.05, power = 0.80)

## adjust for covariates in the outcome model
pwrss.z.med(a = 0.25, b = 0.25, cp = 0.10,
            r2y.mx = 0.50,
            alpha = 0.05, power = 0.80)

# with binary predictor X such as treatment/control variable
# in this case standardized coefficients for path a and cp would be Cohen's d values

## statistical power
p &lt;- 0.50 # proportion of subjects in one group
pwrss.z.med(a = 0.40, b = 0.25, cp = 0.10,
            sdx = sqrt(p*(1-p)),
            alpha = 0.05, n = 200, mc = TRUE)

## minimum required sample size
pwrss.z.med(a = 0.40, b = 0.25, cp = 0.10,
            sdx = sqrt(p*(1-p)),
            alpha = 0.05, power = 0.80)

## adjust for covariates in outcome model
pwrss.z.med(a = 0.40, b = 0.25, cp = 0.10,
            r2y.mx = 0.50, sdx = sqrt(p*(1-p)),
            alpha = 0.05, power = 0.80)
</code></pre>

<hr>
<h2 id='pwrss.z.poisreg'>Poisson Regression: Single Coefficient (Large Sample Approx. Wald's z Test)</h2><span id='topic+pwrss.z.poisreg'></span><span id='topic+pwrss.z.poisson'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test a single coefficient in poisson regression. <code>pwrss.z.poisson()</code> and <code>pwrss.z.poisreg()</code> are the same functions. The distribution of the predictor variable can be one of the following: <code>c("normal", "poisson", "uniform", "exponential", "binomial", "bernouilli", "lognormal")</code>. The default parameters for these distributions are
</p>
<p><code>distribution = list(dist = "normal", mean = 0, sd = 1)</code> <br />
<code>distribution = list(dist = "poisson", lambda = 1)</code> <br />
<code>distribution = list(dist = "uniform", min = 0, max = 1)</code> <br />
<code>distribution = list(dist = "exponential", rate = 1)</code> <br />
<code>distribution = list(dist = "binomial", size = 1, prob = 0.50)</code> <br />
<code>distribution = list(dist = "bernoulli", prob = 0.50)</code> <br />
<code>distribution = list(dist = "lognormal", meanlog = 0, sdlog = 1)</code> <br />
</p>
<p>Parameters defined in <code>list()</code> form can be modified, but the names should be kept the same. It is sufficient to use distribution's name for default parameters (e.g. <code>dist = "normal"</code>).
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.poisreg(exp.beta0 = 1.10, exp.beta1 = 1.16,
                beta0 = log(exp.beta0), beta1 = log(exp.beta1),
                mean.exposure = 1, n = NULL, power = NULL, r2.other.x = 0,
                alpha = 0.05, alternative = c("not equal", "less", "greater"),
                method = c("demidenko(vc)", "demidenko", "signorini"),
                distribution = "normal", verbose = TRUE)


pwrss.z.poisson(exp.beta0 = 1.10, exp.beta1 = 1.16,
                beta0 = log(exp.beta0), beta1 = log(exp.beta1),
                mean.exposure = 1, n = NULL, power = NULL, r2.other.x = 0,
                alpha = 0.05, alternative = c("not equal", "less", "greater"),
                method = c("demidenko(vc)", "demidenko", "signorini"),
                distribution = "normal", verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.poisreg_+3A_exp.beta0">exp.beta0</code></td>
<td>
<p>the base mean event rate</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_exp.beta1">exp.beta1</code></td>
<td>
<p>event rate ratio: the relative increase in the mean event rate for one unit increase in the predictor X (similiar to odds ratio in logistic regression)</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_beta0">beta0</code></td>
<td>
<p><code>log(exp.beta0)</code> or natural logarithm of the base mean event rate</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_beta1">beta1</code></td>
<td>
<p><code>log(exp.beta1)</code> or natural logarithm of the relative increase in the mean event rate for one unit increase in the predictor X</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_mean.exposure">mean.exposure</code></td>
<td>
<p>the mean exposure time (should be &gt; 0). Usually 1</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_n">n</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_r2.other.x">r2.other.x</code></td>
<td>
<p>proportion of variance in the predictor X explained by other covariates. Not to be confused with the pseudo R-squared</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_method">method</code></td>
<td>
<p>calculation method. <code>"demidenko(vc)"</code> stands for Demidenko (2007) procedure with variance correction; <code>"demidenko"</code> stands for Demidenko (2007) procedure without variance correction; <code>"signorini"</code> stands for Signorini (1991) procedure. <code>"demidenko"</code> and <code>"signorini"</code> methods produce similiar results but <code>"demidenko(vc)"</code> is more precise</p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_distribution">distribution</code></td>
<td>
<p>distribution family. Can be one of the <code>c("normal", "poisson", "uniform", "exponential", "binomial", "bernouilli", "lognormal")</code></p>
</td></tr>
<tr><td><code id="pwrss.z.poisreg_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>total sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Demidenko, E. (2007). Sample size determination for logistic regression revisited. Statistics in Medicine, 26(18), 3385-3397.
</p>
<p>Hsieh, F. Y., Bloch, D. A., &amp; Larsen, M. D. (1998). A simple method of sample size calculation for linear and logistic regression. Statistics in Medicine, 17(4), 1623-1634.
</p>
<p>Signorini, D. F. (1991). Sample size for poisson regression. Biometrika, 78(2), 446-450.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># predictor X follows normal distribution

## regression coefficient specification
pwrss.z.poisreg(beta0 = 0.50, beta1 = -0.10,
                alpha = 0.05, power = 0.80,
                dist = "normal")

## rate ratio specification
pwrss.z.poisreg(exp.beta0 = exp(0.50),
                exp.beta1 = exp(-0.10),
                alpha = 0.05, power = 0.80,
                dist = "normal")

## change parameters associated with predictor X
dist.x &lt;- list(dist = "normal", mean = 10, sd = 2)
pwrss.z.poisreg(exp.beta0 = exp(0.50),
                exp.beta1 = exp(-0.10),
                alpha = 0.05, power = 0.80,
                dist = dist.x)


# predictor X follows Bernoulli distribution (such as treatment/control groups)

## regression coefficient specification
pwrss.z.poisreg(beta0 = 0.50, beta1 = -0.10,
                alpha = 0.05, power = 0.80,
                dist = "bernoulli")

## rate ratio specification
pwrss.z.poisreg(exp.beta0 = exp(0.50),
                exp.beta1 = exp(-0.10),
                alpha = 0.05, power = 0.80,
                dist = "bernoulli")

## change parameters associatied with predictor X
dist.x &lt;- list(dist = "bernoulli", prob = 0.30)
pwrss.z.poisreg(exp.beta0 = exp(0.50),
                exp.beta1 = exp(-0.10),
                alpha = 0.05, power = 0.80,
                dist = dist.x)
</code></pre>

<hr>
<h2 id='pwrss.z.prop'>One Proportion against a Constant (z Test)</h2><span id='topic+pwrss.z.prop'></span>

<h3>Description</h3>

<p>Calculates statistical power or minimum required sample size (only one can be NULL at a time) to test a proportion against a constant.
</p>
<p>Formulas are validated using Monte Carlo simulation, G*Power, <a href="http://powerandsamplesize.com/">http://powerandsamplesize.com/</a> and tables in PASS documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwrss.z.prop(p, p0 = 0, margin = 0, arcsin.trans = FALSE, alpha = 0.05,
             alternative = c("not equal","greater","less",
                             "equivalent","non-inferior","superior"),
             n = NULL, power = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwrss.z.prop_+3A_p">p</code></td>
<td>
<p>expected proportion</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_p0">p0</code></td>
<td>
<p>constant to be compared (a proportion)</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_arcsin.trans">arcsin.trans</code></td>
<td>
<p>if <code>TRUE</code> uses Cohen's arcsine transformation, if <code>FALSE</code> uses normal approximation (default)</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_power">power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_alpha">alpha</code></td>
<td>
<p>probability of type I error.</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_margin">margin</code></td>
<td>
<p>non-inferority, superiority, or equivalence margin (margin: boundry of <code>p - p0</code> that is practically insignificant)</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_alternative">alternative</code></td>
<td>
<p>direction or type of the hypothesis test: &quot;not equal&quot;, &quot;greater&quot;, &quot;less&quot;, &quot;equivalent&quot;, &quot;non-inferior&quot;, or &quot;superior&quot;</p>
</td></tr>
<tr><td><code id="pwrss.z.prop_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code> no output is printed on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parms</code></td>
<td>
<p>list of parameters used in calculation</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>type of the statistical test (z or t test)</p>
</td></tr>
<tr><td><code>ncp</code></td>
<td>
<p>non-centrality parameter</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>statistical power <code class="reqn">(1-\beta)</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bulus, M., &amp; Polat, C. (in press). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis with pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi. <a href="https://osf.io/ua5fc/download/">https://osf.io/ua5fc/download/</a>
</p>
<p>Chow, S. C., Shao, J., Wang, H., &amp; Lokhnygina, Y. (2018). Sample size calculations in clinical research (3rd ed.). Taylor &amp; Francis/CRC.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: expecting p - p0 smaller than 0
## one-sided test with normal approximation
pwrss.z.prop(p = 0.45, p0 = 0.50,
             alpha = 0.05, power = 0.80,
             alternative = "less",
             arcsin.trans = FALSE)
## one-sided test with arcsine transformation
pwrss.z.prop(p = 0.45, p0 = 0.50,
             alpha = 0.05, power = 0.80,
             alternative = "less",
             arcsin.trans = TRUE)

# Example 2: expecting p - p0 smaller than 0 or greater than 0
## two-sided test with normal approximation
pwrss.z.prop(p = 0.45, p0 = 0.50,
             alpha = 0.05, power = 0.80,
             alternative = "not equal",
             arcsin.trans = FALSE)
## two-sided test with arcsine transformation
pwrss.z.prop(p = 0.45, p0 = 0.50,
             alpha = 0.05, power = 0.80,
             alternative = "not equal",
             arcsin.trans = TRUE)

# Example 2: expecting p - p0 smaller than 0.01
# when smaller proportion is better
## non-inferiority test with normal approximation
pwrss.z.prop(p = 0.45, p0 = 0.50, margin = 0.01,
             alpha = 0.05, power = 0.80,
             alternative = "non-inferior",
             arcsin.trans = FALSE)
## non-inferiority test with arcsine transformation
pwrss.z.prop(p = 0.45, p0 = 0.50, margin = 0.01,
             alpha = 0.05, power = 0.80,
             alternative = "non-inferior",
             arcsin.trans = TRUE)

# Example 3: expecting p - p0 greater than -0.01
# when bigger proportion is better
## non-inferiority test with normal approximation
pwrss.z.prop(p = 0.55, p0 = 0.50, margin = -0.01,
             alpha = 0.05, power = 0.80,
             alternative = "non-inferior",
             arcsin.trans = FALSE)
## non-inferiority test with arcsine transformation
pwrss.z.prop(p = 0.55, p0 = 0.50, margin = -0.01,
             alpha = 0.05, power = 0.80,
             alternative = "non-inferior",
             arcsin.trans = TRUE)

# Example 4: expecting p - p0 smaller than -0.01
# when smaller proportion is better
## superiority test with normal approximation
pwrss.z.prop(p = 0.45, p0 = 0.50, margin = -0.01,
             alpha = 0.05, power = 0.80,
             alternative = "superior",
             arcsin.trans = FALSE)
## superiority test with arcsine transformation
pwrss.z.prop(p = 0.45, p0 = 0.50, margin = -0.01,
             alpha = 0.05, power = 0.80,
             alternative = "superior",
             arcsin.trans = TRUE)

# Example 5: expecting p - p0 greater than 0.01
# when bigger proportion is better
## superiority test with normal approximation
pwrss.z.prop(p = 0.55, p0 = 0.50, margin = 0.01,
             alpha = 0.05, power = 0.80,
             alternative = "superior",
             arcsin.trans = FALSE)
## superiority test with arcsine transformation
pwrss.z.prop(p = 0.55, p0 = 0.50, margin = 0.01,
             alpha = 0.05, power = 0.80,
             alternative = "superior",
             arcsin.trans = TRUE)

# Example 6: expecting p - p0 between -0.01 and 0.01
## equivalence test with normal approximation
pwrss.z.prop(p = 0.50, p0 = 0.50, margin = 0.01,
             alpha = 0.05, power = 0.80,
             alternative = "equivalent",
             arcsin.trans = FALSE)
# equivalence test with arcsine transformation
pwrss.z.prop(p = 0.50, p0 = 0.50, margin = 0.01,
             alpha = 0.05, power = 0.80,
             alternative = "equivalent",
             arcsin.trans = TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
