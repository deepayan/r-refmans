<!DOCTYPE html><html><head><title>Help for package CalSim</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CalSim}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calibration_simplex'><p>Calibration Simplex</p></a></li>
<li><a href='#plot.calibration_simplex'><p>Plot Calibration Simplex</p></a></li>
<li><a href='#ternary_forecast_example'><p>Ternary probability forecast and observations.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The Calibration Simplex</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Johannes Resin</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johannes Resin &lt;johannes.resin@h-its.org&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5), spatstat (&ge; 2.0-0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>spatstat.geom, stats, ExactMultinom</td>
</tr>
<tr>
<td>Description:</td>
<td>Generates the calibration simplex (a generalization of the reliability diagram) for three-category probability forecasts, as proposed by Wilks (2013) &lt;<a href="https://doi.org/10.1175%2FWAF-D-13-00027.1">doi:10.1175/WAF-D-13-00027.1</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-03-24 08:29:55 UTC; resinjs</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-03-25 13:20:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='calibration_simplex'>Calibration Simplex</h2><span id='topic+calibration_simplex'></span><span id='topic+CalSim'></span><span id='topic+calibration_simplex.default'></span>

<h3>Description</h3>

<p>Generates an object of class <code>calibration_simplex</code> which can be used to assess the calibration
of ternary probability forecasts. The Calibration Simplex can be seen as generalization of the reliability diagram
for binary probability forecasts. For details on the interpretation of the calibration simplex, see Wilks (2013). Be
aware that some minor changes have been made compared to the calibration simplex as suggested by Wilks (2013) (see note below).
</p>
<p>As a somewhat experimental feature, multinomial p-values can be used for uncertainty quantification, that is, as a tool
to judge whether the observed discrepancies may be merely coincidental or whether the predictions may in fact be miscalibrated, see Resin (2020, Section 4.2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibration_simplex(n, p1, p2, p3, obs, test_stat, percentagewise)

## Default S3 method:
calibration_simplex(
  n = 10,
  p1 = NULL,
  p2 = NULL,
  p3 = NULL,
  obs = NULL,
  test_stat = "LLR",
  percentagewise = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibration_simplex_+3A_n">n</code></td>
<td>
<p>A natural number.</p>
</td></tr>
<tr><td><code id="calibration_simplex_+3A_p1">p1</code></td>
<td>
<p>A vector containing the forecasted probabilities for the first (1) category, e.g. below-normal.</p>
</td></tr>
<tr><td><code id="calibration_simplex_+3A_p2">p2</code></td>
<td>
<p>A vector containing the forecasted probabilities for the second (2) category, e.g. near-normal.</p>
</td></tr>
<tr><td><code id="calibration_simplex_+3A_p3">p3</code></td>
<td>
<p>A vector containing the forecasted probabilities for the third (3) category, e.g. above-normal.</p>
</td></tr>
<tr><td><code id="calibration_simplex_+3A_obs">obs</code></td>
<td>
<p>A vector containing the observed outcomes (Categories are encoded as 1 (e.g. below-normal), 2 (e.g. near-normal) and 3 (e.g. above-normal)).</p>
</td></tr>
<tr><td><code id="calibration_simplex_+3A_test_stat">test_stat</code></td>
<td>
<p>A string indicating which test statistic is to be used for the multinomial test in each bin. 
Options are &quot;LLR&quot; (log-likelihood ratio; default), &quot;Chisq&quot; (Pearson's chi-square) and &quot;Prob&quot; (probability mass statistic). See details</p>
</td></tr>
<tr><td><code id="calibration_simplex_+3A_percentagewise">percentagewise</code></td>
<td>
<p>Logical, specifying whether probabilities are percentagewise (summing to 100) or not (summing to 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only two of the three forecast probability vectors (<code>p1</code>, <code>p2</code> and <code>p3</code>) need to be specified.
</p>
<p>The p-values are based on multinomial tests comparing the observed frequencies within a bin 
with the average forecast probabilities within the bin as outlined in Resin (2020, Section 4.2).
The p-values are exact and do not rely on asymptotics, however, it is assumed that the true 
distribution (under the hypothesis of forecast calibration) within each bin 
is approximated well by the multinomial distribution. If <code>n</code> is small the 
approximation may be poor, resulting in unreliable p-values. p-Values less than 0.0001 are not
exact but merely indicate a value less than 0.0001.
</p>


<h3>Value</h3>

<p>A list with class &quot;calibration_simplex&quot; containing
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>As input by user or default.</p>
</td></tr>
<tr><td><code>n_bins</code></td>
<td>
<p>Computed from <code>n</code>. Number of hexagons.</p>
</td></tr>
<tr><td><code>n_obs</code></td>
<td>
<p>Total number of observations.</p>
</td></tr>
<tr><td><code>freq</code></td>
<td>
<p>Vector of length <code>n_bins</code> containing the number of observations within each bin.</p>
</td></tr>
<tr><td><code>cond_rel_freq</code></td>
<td>
<p>Matrix containing the observed outcome frequencies within each bin.</p>
</td></tr>
<tr><td><code>cond_ave_prob</code></td>
<td>
<p>Matrix containing the average forecast probabilities within each bin.</p>
</td></tr>
<tr><td><code>pvals</code></td>
<td>
<p>Exact multinomial p-values within each bin. See details.</p>
</td></tr>
</table>
<p>Object of class <code>calibration_simplex</code>.
</p>


<h3>Note</h3>

<p>In contrast to the calibration simplex proposed by Daniel S. Wilks, 2013, the simplex has been
mirrored at the diagonal through the left bottom hexagon. The miscalibration error is by default calculated
precisely (in each bin as the difference of the relative frequencies of each class and the
average forecast probabilities) instead of approximately (using Wilks original formula).
Approximate errors can be used by setting <code>true_error = FALSE</code> when using <code><a href="#topic+plot.calibration_simplex">plot.calibration_simplex</a></code>.
</p>


<h3>References</h3>

<p>Daniel S. Wilks, 2013, The Calibration Simplex: A Generalization of the Reliability Diagram for Three-Category Probability Forecasts, <em>Weather and Forecasting</em>, <strong>28</strong>, 1210-1218
</p>
<p>Resin, J. (2020), A Simple Algorithm for Exact Multinomial Tests, <em>Preprint</em> <a href="https://arxiv.org/abs/2008.12682">https://arxiv.org/abs/2008.12682</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.calibration_simplex">plot.calibration_simplex</a></code>
</p>
<p><code><a href="#topic+ternary_forecast_example">ternary_forecast_example</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>attach(ternary_forecast_example)   #see also documentation of sample data
#?ternary_forecast_example

# Calibrated forecast sample
calsim0 = calibration_simplex(p1 = p1, p3 = p3, obs = obs0)
plot(calsim0,use_pvals = TRUE) # with multinomial p-values

# Overconfident forecast sample
calsim1 = calibration_simplex(p1 = p1, p3 = p3, obs = obs1)
plot(calsim1)

# Underconfident forecast sample
calsim2 = calibration_simplex(p1 = p1, p3 = p3, obs = obs2)
plot(calsim2,use_pvals = TRUE) # with multinomial p-values

# Unconditionally biased forecast sample
calsim3 = calibration_simplex(p1 = p1, p3 = p3, obs = obs3)
plot(calsim3)

# Using a different number of bins
calsim = calibration_simplex(n=4, p1 = p1, p3 = p3, obs = obs3)
plot(calsim)

calsim = calibration_simplex(n=13, p1 = p1, p3 = p3, obs = obs3)
plot(calsim,               # using some additional plotting parameters:
     error_scale = 0.5,    # errors are less pronounced (smaller shifts)
     min_bin_freq = 100,   # dots are plotted only for bins,
                           # which contain at least 100 forecast-outcome pairs
     category_labels = c("below-normal","near-normal","above-normal"),
     main = "Sample calibration simplex")

detach(ternary_forecast_example)
</code></pre>

<hr>
<h2 id='plot.calibration_simplex'>Plot Calibration Simplex</h2><span id='topic+plot.calibration_simplex'></span>

<h3>Description</h3>

<p>Plot Calibration Simplex
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'calibration_simplex'
plot(
  x,
  true_error = TRUE,
  error_scale = 0.3,
  min_bin_freq = 10,
  plot_error_scale = TRUE,
  scale_area = NULL,
  indicate_bins = TRUE,
  category_labels = c("1", "2", "3"),
  use_pvals = FALSE,
  alphas = c(0.1, 0.01),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.calibration_simplex_+3A_x">x</code></td>
<td>
<p>Object of class <code>calibration_simplex</code></p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_true_error">true_error</code></td>
<td>
<p>Logical, specifying whether to use true miscalibration errors or approximate miscalibration errors.</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_error_scale">error_scale</code></td>
<td>
<p>A number specifying the magnitude of the miscalibration errors (greater 0, usually should be less than 1,
cf. note below).</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_min_bin_freq">min_bin_freq</code></td>
<td>
<p>A number. Lower bound for (absolute) frequencies, i.e. how many observations have to lie in a bin
for it to be plotted.</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_plot_error_scale">plot_error_scale</code></td>
<td>
<p>Logical, specifying whether to plot a scale showing the magnitude of miscalibration errors.</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_scale_area">scale_area</code></td>
<td>
<p>Optional. A number by which the areas of the points are scaled. Use if points are to small or to big.</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_indicate_bins">indicate_bins</code></td>
<td>
<p>Logical, specifying whether to connect points to their respective bin (center of hexagon).</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_category_labels">category_labels</code></td>
<td>
<p>A vector of length 3 containing the category names, e.g. <code>c("1","2","3")</code> (default)</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_use_pvals">use_pvals</code></td>
<td>
<p>Logical, determines whether multinomial p-values are used for uncertainty quantification, see details.</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_alphas">alphas</code></td>
<td>
<p>Vector of length 2 with values 1 &gt; <code>alphas[1]</code> &gt; <code>alphas[2]</code> &gt;= 0.0001. Only relevant if <code>use_pvals = TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.calibration_simplex_+3A_...">...</code></td>
<td>
<p>Arguments concerning the title (e.g. <code>main</code>, <code>cex.main</code>, <code>col.main</code> and <code>font.main</code>)
and subtitle (e.g. <code>sub</code>, <code>cex.sub</code>, <code>col.sub</code> and <code>font.sub</code>) may be passed here.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If multinomial p-values are used (<code>use_pvals = TRUE</code>), the dots are colored in the following way:
</p>

<ul>
<li><p> Blue: p-value greater <code>alphas[1]</code> (0.1 by default).
</p>
</li>
<li><p> Orange: p-value between <code>alphas[1]</code> and <code>alphas[2]</code> (0.1 and 0.01 by default)
</p>
</li>
<li><p> Red: p-value less than <code>alphas[2]</code> (0.01 by default)
</p>
</li>
<li><p> Black: p-value is exactly 0. This only happens if a category which is assigned 0 probability realizes.
</p>
</li></ul>

<p>Many small p-values (orange and red dots) indicate miscalibrated predictions, whereas many blue dots indicate that the predictions 
may in fact be calibrated. WARNING: The use of the multinomial p-values is more of an experimental feature and may not yield reliable 
p-values, especially if <code>n</code> is small.
For details regarding the calculation of the p-values see also <code><a href="#topic+calibration_simplex">calibration_simplex</a></code>.
</p>


<h3>Note</h3>

<p>For details on the meaning of the error scale, cf. Wilks, 2013, especially Fig. 2. Note that the miscalibration error in
each category is in &quot;probability units&quot; (as it is the average difference in relative frequency and forecast probability
in each bin).
</p>

<hr>
<h2 id='ternary_forecast_example'>Ternary probability forecast and observations.</h2><span id='topic+ternary_forecast_example'></span>

<h3>Description</h3>

<p>10,000 realizations of a ternary probability forecast, which exhibits different characteristics, 
depending on the realizing outcome variable. Idealized forecast example, generated as described in Wilks (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ternary_forecast_example)
</code></pre>


<h3>Format</h3>

<p>A data frame with 10,000 rows and 6 variables.
</p>

<dl>
<dt>p1</dt><dd><p>forecast probability for outcome 1</p>
</dd>
<dt>p3</dt><dd><p>forecast probability for outcome 3</p>
</dd>
<dt>obs0</dt><dd><p>outcomes, such that the forecast is well-calibrated</p>
</dd>
<dt>obs1</dt><dd><p>outcomes, such that the forecast is overconfident</p>
</dd>
<dt>obs2</dt><dd><p>outcomes, such that the forecast is underconfident</p>
</dd>
<dt>obs3</dt><dd><p>outcomes, such that the forecast is unconditionally biased</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data generated by package author.
</p>


<h3>References</h3>

<p>Daniel S. Wilks, 2013, The Calibration Simplex: A Generalization of the Reliability Diagram for Three-Category Probability Forecasts, <em>Weather and Forecasting</em>, <strong>28</strong>, 1210-1218
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
