<!DOCTYPE html><html><head><title>Help for package EBglmnet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EBglmnet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EBglmnet-package'><p>Empirical Bayesian Lasso (EBlasso) and Elastic Net (EBEN) Methods for Generalized Linear Models</p></a></li>
<li><a href='#BASIS'><p>An Example Data</p></a></li>
<li><a href='#cv.EBglmnet'><p>Cross Validation (CV) Function to Determine Hyperparameters of the EBglmnet Algorithms</p></a></li>
<li><a href='#EBglmnet'><p>Main Function for the EBglmnet Algorithms</p></a></li>
<li><a href='#EBglmnet-internal'><p>Internal EBglmnet functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Empirical Bayesian Lasso and Elastic Net Methods for Generalized
Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>6.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-12</td>
</tr>
<tr>
<td>Author:</td>
<td>Anhui Huang, Dianting Liu</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Anhui Huang &lt;anhuihuang@gmail.com&gt;</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, glmnet</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides empirical Bayesian lasso and elastic net algorithms for variable selection and effect estimation. Key features include sparse variable selection and effect estimation via generalized linear regression models, high dimensionality with p&gt;&gt;n, and significance test for nonzero effects. This package outperforms other popular methods such as lasso and elastic net methods in terms of power of detection, false discovery rate, and power of detecting grouping effects. Please reference its use as A Huang and D Liu (2016) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtw143">doi:10.1093/bioinformatics/btw143</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://sites.google.com/site/anhuihng/">https://sites.google.com/site/anhuihng/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-25 02:22:49 UTC; anhui</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-25 03:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='EBglmnet-package'>Empirical Bayesian Lasso (EBlasso) and Elastic Net (EBEN) Methods for Generalized Linear Models</h2><span id='topic+EBglmnet-package'></span>

<h3>Description</h3>

<p> Fast Empirical Bayesian Lasso (EBlasso) and Elastic Net (EBEN) are generalized linear regression methods for variable selections and effect estimations. 
Similar as <code>lasso</code> and <code>elastic net</code> implemented in the package <span class="pkg">glmnet</span>, <span class="pkg">EBglmnet</span> features 
the capabilities of handling <code class="reqn">p&gt;&gt;n</code> data, where <code>p</code> is the number of variables and <code>n</code> is 
the number of samples in the regression model, and inferring a sparse solution such that irrelevant variables 
will have exactly zero value on their regression coefficients. Additionally, there are several unique features in <span class="pkg">EBglmnet</span>: <br /><br />
1) Both <code>EBlasso</code> and <code>EBEN</code> can select more than <code>n</code> nonzero effects. <br />
2) EBglmnet also performs hypothesis testing for the significance of nonzero estimates. <br />
<br />
There are three sets of hierarchical prior distributions implemented in <span class="pkg">EBglmnet</span>: <br /><br />
1) EBlasso-NE is a two-level prior with (normal + exponential) distributions for the regression coefficients.<br />
2) EBlasso-NEG is a three-level hierarchical prior with (normal + exponential + gamma) distributions.<br />
3) EBEN implements a normal and generalized gamma hierarchical prior.<br />
</p>
<p>While those sets of priors are all &quot;peak zero and flat tails&quot;, <code>EBlasso-NE</code> assigns more probability mass to the tails, resulting in more nonzero estimates having large <code class="reqn">p</code>-values. In contrast, <code>EBlasso-NEG</code> has a third level constraint on the <code>lasso</code> prior, which results in higher probability mass around zero, thus more sparse results in the final outcome. Meanwhile, <code>EBEN</code> encourages a grouping effect such that highly correlated variables can be selected as a group.
Similar as the relationship between <code>elastic net</code> and <code>lasso</code>, there are two parameters <code class="reqn">(\alpha, \lambda)</code> required for <code>EBEN</code>, and it is reduced to <code>EBlasso-NE</code> when parameter <code class="reqn">\alpha = 1</code>. We recommend using EBlasso-NEG when there are a large number of candidate effects, using EBlasso-NE when effect sizes are relatively small, and using EBEN when groups of highly correlated variables such as co-regulated gene expressions are of interest.
<br /> <br /> 
Two models are available for both methods: linear regression model and logistic regression model. Other features in this package includes:<br /> 
* 1 *     epistasis (two-way interactions) can be included for all models/priors; <br />
* 2 *     model implemented with memory efficient <code>C</code> code; <br />
* 3 *     LAPACK/BLAS are used for most linear algebra computations. <br /> <br />
</p>
<p>Several simulation and real data analysis in the reference papers demonstrated that <span class="pkg">EBglmnet</span> enjoys better performance than <code>lasso</code> and <code>elastic net</code> methods in terms of power of detection, 
false discover rate, as well as encouraging grouping effect when applicable. <br />
</p>
<p>Key Algorithms are described in the following paper: <br />
1. EBlasso-NEG: (Cai X., Huang A., and Xu S., 2011), (Huang A., Xu S., and Cai X., 2013) <br />
2. EBlasso-NE: (Huang A., Xu S., and Cai X., 2013) <br />
3. group EBlasso: (Huang A., Martin E., et al. 2014) <br />
4. EBEN: (Huang A., Xu S., and Cai X., 2015)<br />
5. Whole-genome QTL mapping: (Huang A., Xu S., and Cai X., 2014) <br />
</p>
<p>EBglmnet version after V5 will not support the following. For those functionalities, please refer to the 'cran' package 'EBEN'. 
- Two way interaction (epistasis) will not be supported;
- Group EBlasso will not be supported.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> EBglmnet</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 6.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2016-01-15</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> gpl</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Anhui Huang, Dianting Liu <br />
Maintainer: Anhui Huang &lt;anhuihuang@gmail.com&gt;
</p>


<h3>References</h3>

<p>Huang, A., Xu, S., and Cai, X. (2015). Empirical Bayesian elastic net for multiple quantitative trait locus mapping. Heredity 114(1): 107-115.<br /><br />	
Huang, A., E. Martin, et al. (2014). &quot;Detecting genetic interactions in pathway-based genome-wide association studies.&quot; Genet Epidemiol 38(4): 300-309.<br /><br />
Huang, A., S. Xu, et al. (2014). &quot;Whole-genome quantitative trait locus mapping reveals major role of epistasis on yield of rice.&quot; PLoS ONE 9(1): e87330.<br /><br />
Huang, A. (2014). &quot;Sparse model learning for inferring genotype and phenotype associations.&quot; Ph.D Dissertation. University of Miami(1186).<br /> <br />	
Huang A, Xu S, Cai X. (2013). Empirical Bayesian LASSO-logistic regression for multiple binary trait locus mapping. BMC genetics  14(1):5. <br /><br />
Cai, X., Huang, A., and Xu, S. (2011). Fast empirical Bayesian LASSO for multiple quantitative trait locus mapping. BMC Bioinformatics 12, 211.<br /><br />
</p>

<hr>
<h2 id='BASIS'>An Example Data</h2><span id='topic+BASIS'></span>

<h3>Description</h3>

<p>This is a 1000x481 sample feature matrix</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BASIS)</code></pre>


<h3>Format</h3>

<p>The format is:
int [1:1000, 1:481] 0 -1 0 0 1 0 1 0 1 0 ...
</p>


<h3>Details</h3>

<p>The data was simulated on a 2400 centimorgan (cM) chromosome of an F2 population from 
a cross of two inbred lines. The three genotype of AA, Aa and aa were coded as
1, 0, -1, respectively. Each column corresponds to an even spaced d= 5cM genetic marker, 
and each row represents a sample. The Haldane map function was assumed in the simulation,
such that correlation between markers having distance d is <code class="reqn">R = exp(-2d)</code>. Example of using this dataset for multiple QTL mapping is available in the EBglmnet Vignette.</p>


<h3>Source</h3>

<p> 	Huang, A., Xu, S., and Cai, X. (2014). Empirical Bayesian elastic net for multiple quantitative trait locus mapping. Heredity 10.1038/hdy.2014.79 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BASIS)
</code></pre>

<hr>
<h2 id='cv.EBglmnet'>Cross Validation (CV) Function to Determine Hyperparameters of the EBglmnet Algorithms</h2><span id='topic+cv.EBglmnet'></span>

<h3>Description</h3>

<p>The degree of shrinkage, or equivalently, the number of non-zero effects selected by EBglmnet are 
controlled by the hyperparameters in the prior distribution, which can be obtained 
via Cross Validation (CV). This function performs k-fold CV for hyperparameter selection, and 
outputs the model fit results using the optimal parameters. Therefore, this function runs
<code>EBglmnet</code> for (<code>k x n_parameters + 1</code>) times. By default, EBlasso-NE tests 20
<code class="reqn">\lambda</code>s , EBEN tests an additional 10 <code class="reqn">\alpha</code>s (thus a total of 200 pair of 
hyperparameters), and EBlasso-NEG tests up to 25 pairs of (a,b).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.EBglmnet(x, y, family=c("gaussian","binomial"),
		prior= c("lassoNEG","lasso","elastic net"), nfolds=5, 
		foldId, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.EBglmnet_+3A_x">x</code></td>
<td>
<p>input matrix of dimension <code>n</code> x <code>p</code>; each row is an
observation vector, and each column is a candidate variable. When epistasis is considered, users do not need
to create a giant matrix including both main and interaction terms. Instead, <code>x</code> should always be
the matrix corresponding to the <code>p</code> main effects, and <code>cv.EBglmnet</code> will generate the interaction terms
dynamically during running time.</p>
</td></tr>
<tr><td><code id="cv.EBglmnet_+3A_y">y</code></td>
<td>
<p>response variable. Continuous for <code>family="gaussian"</code>, and binary for 
<code>family="binomial"</code>. For binary response variable, y can be a Boolean or numeric vector, or factor type
array.</p>
</td></tr>
<tr><td><code id="cv.EBglmnet_+3A_family">family</code></td>
<td>
<p>model type taking values of &quot;gaussian&quot; (default) or &quot;binomial&quot;. </p>
</td></tr> 
<tr><td><code id="cv.EBglmnet_+3A_prior">prior</code></td>
<td>
<p>prior distribution to be used. Taking values of &quot;lassoNEG&quot;(default), &quot;lasso&quot;, and &quot;elastic net&quot;. 
All priors will produce a sparse outcome of the regression coefficients; see Details for choosing priors. </p>
</td></tr>  
<tr><td><code id="cv.EBglmnet_+3A_nfolds">nfolds</code></td>
<td>
<p>number of n-fold CV. <code>nfolds</code> typically &gt;=3. Although <code>nfolds</code>
can be as large as the sample size (leave-one-out CV), it will be computationally intensive for large datasets. Default value is <code>nfolds=5</code>.</p>
</td></tr>
<tr><td><code id="cv.EBglmnet_+3A_foldid">foldId</code></td>
<td>
<p>an optional vector of values between 1 and <code>nfolds</code>
identifying which fold each observation is assigned to. If not supplied, each of the <code>n</code> samples will be 
assigned to the <code>nfolds</code> randomly.</p>
</td></tr> 
<tr><td><code id="cv.EBglmnet_+3A_verbose">verbose</code></td>
<td>
<p>parameter that controls the level of message output from EBglment. It takes values from 0 to 5; larger verbose displays more messages. 0 is recommended for CV to avoid excessive outputs. Default value for <code>verbose</code> is minimum message output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>	The three priors in EBglmnet all contain hyperparameters that control how heavy the tail probabilities are. Different values of the hyperparameters will yield different number of non-zero effects retained in the model. 
Appropriate selection of their values is required to obtain optimal results, and CV is the most 
oftenly used method. For Gaussian model, CV determines the optimal hyperparameter values that yield 
the minimum square error. In Binomial model, CV calculates the mean logLikelihood in each of 
the left out fold, and chooses the values that yield the maximum mean logLikelihood value of the k-folds.
See <code>EBglmnet</code> for the details of hyperparameters in each prior distribution. <br /> <br />
</p>


<h3>Value</h3>

<table>
<tr><td><code>CrossValidation</code></td>
<td>
<p>matrix of CV result with columns of: <br />
column 1: hyperparameter1 <br />
column 2: hyperparameter2 <br />
column 3: prediction metrics/Criteria<br />
column 4: standard error in the k-fold CV. <br />
</p>
<p>Prediction metrics is the mean square error (MSE) for Gaussian model and mean log likelihood (logL) for the binomial model.	</p>
</td></tr>
<tr><td><code>optimal hyperparameter</code></td>
<td>
<p>the hyperparameters that yield the smallest MSE or the largest logL.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>model fit using the optimal parameters computed by CV. See <code>EBglmnet</code> for values in this item. </p>
</td></tr>
<tr><td><code>WaldScore</code></td>
<td>
<p>the Wald Score for the posterior distribution.	See (Huang A., Martin E., et al., 2014b) for using Wald Score to identify significant  effect set.</p>
</td></tr>
<tr><td><code>Intercept</code></td>
<td>
<p>model intercept. This parameter is not shrunk (assumes uniform prior).</p>
</td></tr>
<tr><td><code>residual variance</code></td>
<td>
<p>the residual variance if the Gaussian family is assumed in the GLM</p>
</td></tr>
<tr><td><code>logLikelihood</code></td>
<td>
<p>the log Likelihood if the Binomial family is assumed in the GLM</p>
</td></tr>
<tr><td><code>hyperparameters</code></td>
<td>
<p>the hyperparameter(s) used to fit the model</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the GLM family specified in this function call</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>the prior used in this function call</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td></tr>	
<tr><td><code>nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>	
<tr><td><code>nfolds</code></td>
<td>
<p>number of folds in CV</p>
</td></tr>	
</table>


<h3>Author(s)</h3>

<p>Anhui Huang and Dianting Liu <br /> Dept of Electrical and Computer Engineering, Univ of Miami, Coral Gables, FL</p>


<h3>References</h3>

<p>	Cai, X., Huang, A., and Xu, S. (2011). Fast empirical Bayesian LASSO for multiple quantitative trait locus mapping. BMC Bioinformatics 12, 211.<br /><br />
Huang A, Xu S, Cai X. (2013). Empirical Bayesian LASSO-logistic regression for multiple binary trait locus mapping. BMC genetics  14(1):5. <br /><br />
Huang, A., Xu, S., and Cai, X. (2014a). Empirical Bayesian elastic net for multiple quantitative trait locus mapping. Heredity 10.1038/hdy.2014.79 <br /><br /> 
uang, A., E. Martin, et al. (2014b). Detecting genetic interactions in pathway-based genome-wide association studies. Genet Epidemiol 38(4): 300-309.	
<br />	</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rm(list = ls())
library(EBglmnet)
#Use R built-in data set state.x77
y= state.x77[,"Life Exp"]
xNames = c("Population","Income","Illiteracy", "Murder","HS Grad","Frost","Area")
x = state.x77[,xNames]
#
#Gaussian Model
#lassoNEG prior as default
out = cv.EBglmnet(x,y)
out$fit
#lasso prior
out = cv.EBglmnet(x,y,prior= "lasso")
out$fit
#elastic net prior
out = cv.EBglmnet(x,y,prior= "elastic net")
out$fit
#
#Binomial Model
#create a binary response variable
yy = y&gt;mean(y);
out = cv.EBglmnet(x,yy,family="binomial")
out$fit

</code></pre>

<hr>
<h2 id='EBglmnet'>Main Function for the EBglmnet Algorithms</h2><span id='topic+EBglmnet'></span>

<h3>Description</h3>

<p>EBglmnet is the main function to fit a generalized linear model via the empirical Bayesian methods with lasso and elastic net hierarchical priors.
It features with <code>p&gt;&gt;n</code> capability, produces a sparse outcome for the 
regression coefficients, and performs significance test for nonzero effects 
in both  linear and logistic regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EBglmnet(x, y, family=c("gaussian","binomial"),prior= c("lassoNEG","lasso","elastic net"),
	hyperparameters, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EBglmnet_+3A_x">x</code></td>
<td>
<p>input matrix of dimension <code>n</code> x <code>p</code>; each row is an
observation vector, and each column is a variable. 
</p>
</td></tr>
<tr><td><code id="EBglmnet_+3A_y">y</code></td>
<td>
<p>response variable. Continuous for <code>family="gaussian"</code>, and binary for 
<code>family="binomial"</code>. For binary response variable, y can be a Boolean or numeric vector, or factor type
array.</p>
</td></tr>
<tr><td><code id="EBglmnet_+3A_family">family</code></td>
<td>
<p>model type taking values of &quot;gaussian&quot; (default) or &quot;binomial&quot;. </p>
</td></tr> 
<tr><td><code id="EBglmnet_+3A_prior">prior</code></td>
<td>
<p>prior distribution to be used. It takes values of &quot;lassoNEG&quot;(default), &quot;lasso&quot;, and &quot;elastic net&quot;. 
All priors will produce a sparse outcome of the regression coefficients; see Details for choosing priors. </p>
</td></tr>  
<tr><td><code id="EBglmnet_+3A_hyperparameters">hyperparameters</code></td>
<td>
<p>the optimal hyperparameters in the prior distribution. Similar as <code class="reqn">\lambda</code> in lasso
method, the hyperparameters control the number of nonzero elements in the regression coefficients. Hyperparameters 
are most oftenly determined by CV. See <code>cv.EBglmnet</code> for the method in determining their values. 
While <code>cv.EBglmnet</code> already provides the model fitting results using the hyperparameters determined in CV,
users can use this function to obtain the results under other parameter selection criteria such as Akaike information criterion
(AIC) or Bayesian information criterion (BIC). </p>
</td></tr> 
<tr><td><code id="EBglmnet_+3A_verbose">verbose</code></td>
<td>
<p>parameter that controls the level of message output from EBglment. It takes values from 0 to 5; larger verbose displays more messages. small values are recommended to avoid excessive outputs. Default value for <code>verbose</code> is minimum message output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>EBglmnet implements three set of hierarchical prior distributions for the regression parameters <code class="reqn">\beta</code>: <br /><br />
<b>lasso prior</b>:
</p>
<p style="text-align: center;"><code class="reqn">\beta_j  \sim N(0,\sigma_j^2),</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma_j^2  \sim exp(\lambda), j = 1, \dots, p.</code>
</p>

<p><b>lasso-NEG prior</b>:
</p>
<p style="text-align: center;"><code class="reqn">\beta_j  \sim N(0,\sigma_j^2),</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma_j^2  \sim exp(\lambda),</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda  \sim gamma(a,b), j = 1, \dots, p.</code>
</p>

<p><b>elastic net prior</b>:
</p>
<p style="text-align: center;"><code class="reqn">\beta_j  \sim N[0,(\lambda_1 + \tilde{\sigma_j}^{-2})^{-2}],</code>
</p>

<p style="text-align: center;"><code class="reqn">\tilde{\sigma_j}^{2}  \sim generalized-gamma(\lambda_1, \lambda_2), j = 1, \dots,p.</code>
</p>

<p>The prior distributions are peak zero and flat tail probability distributions that assign a high prior 
probability mass to zero and still allow heavy probability on the two tails, which reflect the prior 
belief that a sparse solution exists: most of the variables will have no effects on the response variable,
and only some of the variables will have non-zero effects in contributing the outcome in <code>y</code>. <br />
</p>
<p>The three priors all contains hyperparameters that control how heavy the tail probability is, 
and different values of them will yield different number of non-zero effects retained in the model. 
Appropriate selection of their values is required for obtaining optimal results, 
and CV is the most oftenly used method. See <code>cv.EBglmnet</code> for details for determining the 
optimal hyperparameters in each priors under different GLM families. <br /> <br />
<em>lassoNEG prior</em><br />
<code>"lassoNEG"</code> prior has two hyperparameters (a,b), with <code class="reqn">a \ge -1</code> and <code>b&gt;0</code>. Although
<code>a</code> is allowed to be greater than -1.5, it is not encouraged to choose values in (-1.5, -1) unless the signal-to-noise 
ratio in the explanatory variables are very small.
</p>
<p><em>lasso prior</em><br />
<code>"lasso"</code> prior has one hyperparameter  <code class="reqn">\lambda</code>, with <code class="reqn">\lambda \ge 0</code>.  <code class="reqn">\lambda</code> is similar as 
the shrinkage parameter in <code>lasso</code> except that even for <code>p&gt;&gt;n</code>, <code class="reqn">\lambda</code> is allowed to be zero, and <code>EBlasso</code>
can still provide a sparse solution thanks to the implicit constraint that <code class="reqn">\sigma^2 \ge 0</code>.
</p>
<p><em>elastic net prior</em><br />
Similar as the elastic net in package <span class="pkg">glmnet</span>, EBglmnet transforms the two hyperparameters <code class="reqn">\lambda_1</code> 
and <code class="reqn">\lambda_2</code> in the <code>"elastic net"</code> prior in terms of other two parameters <code class="reqn">\alpha (0\le \alpha \le 1)</code>
and <code class="reqn">\lambda (\lambda &gt;0)</code>.  Therefore, users are asked to specify <code>hyperparameters=c</code>(<code class="reqn">\alpha, \lambda</code>). 
</p>


<h3>Value</h3>

<table>
<tr><td><code>fit</code></td>
<td>
<p>the model fit using the hyperparameters provided. EBglmnet selects the variables having nonzero regression 
coefficients and estimates their posterior distributions. With the posterior mean and variance, a <code>t-test</code> 
is performed and the <code>p-value</code> is calculated. Result in fit is a matrix with rows corresponding to the 
variables having nonzero effects, and columns having the following values: <br /><br />
column1: (predictor index in X) denoting the column number in the input matrix <code>x</code>. <br /><br />
column2: beta. It is the posterior mean of the nonzero regression coefficients. <br /><br />
column3: posterior variance.  It is the diagonal element of the posterior covariance matrix among the nonzero regression coefficients. <br /><br />
column4: t-value calculated using column 3-4. <br /><br />
column5: p-value from t-test.	
</p>
</td></tr>
<tr><td><code>WaldScore</code></td>
<td>
<p>the Wald Score for the posterior distribution. It is computed as <code class="reqn">\beta^T\Sigma^{-1}\beta</code>. 
See (Huang A, 2014b) for using Wald Score to identify significant effect set.</p>
</td></tr>
<tr><td><code>Intercept</code></td>
<td>
<p>the intercept in the linear regression model. This parameter is not shrunk.</p>
</td></tr>
<tr><td><code>residual variance</code></td>
<td>
<p>the residual variance if the Gaussian family is assumed in the GLM</p>
</td></tr>
<tr><td><code>logLikelihood</code></td>
<td>
<p>the log Likelihood if the Binomial family is assumed in the GLM</p>
</td></tr>
<tr><td><code>hyperparameters</code></td>
<td>
<p>the hyperparameter used to fit the model</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the GLM family specified in this function call</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>the prior used in this function call</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td></tr>	
<tr><td><code>nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>	
</table>


<h3>Author(s)</h3>

<p>Anhui Huang and Dianting Liu <br /> </p>


<h3>References</h3>

<p>	Cai, X., Huang, A., and Xu, S. (2011). Fast empirical Bayesian LASSO for multiple quantitative trait locus mapping. BMC Bioinformatics 12, 211.<br /><br />
Huang A, Xu S, Cai X. (2013). Empirical Bayesian LASSO-logistic regression for multiple binary trait locus mapping. BMC genetics  14(1):5. <br /><br />
Huang, A., Xu, S., and Cai, X. (2014a). Empirical Bayesian elastic net for multiple quantitative trait locus mapping. Heredity 10.1038/hdy.2014.79 <br /> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rm(list = ls())
library(EBglmnet)
#Use R built-in data set state.x77
y= state.x77[,"Life Exp"]
xNames = c("Population","Income","Illiteracy", "Murder","HS Grad","Frost","Area")
x = state.x77[,xNames]
#
#Gaussian Model
#lassoNEG prior as default
out = EBglmnet(x,y,hyperparameters=c(0.5,0.5))
out$fit
#lasso prior
out = EBglmnet(x,y,prior= "lasso",hyperparameters=0.5)
out$fit
#elastic net prior
out = EBglmnet(x,y,prior= "elastic net",hyperparameters=c(0.5,0.5))
out$fit
#residual variance
out$res
#intercept
out$Intercept
#
#Binomial Model
#create a binary response variable
yy = y&gt;mean(y);
out = EBglmnet(x,yy,family="binomial",hyperparameters=c(0.5,0.5))
out$fit

</code></pre>

<hr>
<h2 id='EBglmnet-internal'>Internal EBglmnet functions</h2><span id='topic+EBelasticNet.Binomial'></span><span id='topic+EBelasticNet.Gaussian'></span><span id='topic+EBelasticNet.BinomialCV'></span><span id='topic+EBelasticNet.GaussianCV'></span><span id='topic+EBlassoNE.BinomialCV'></span><span id='topic+EBlassoNE.GaussianCV'></span><span id='topic+EBlassoNEG.Binomial'></span><span id='topic+EBlassoNEG.Gaussian'></span><span id='topic+EBlassoNEG.BinomialCV'></span><span id='topic+EBlassoNEG.GaussianCV'></span><span id='topic+ijIndex'></span><span id='topic+CVonePair'></span><span id='topic+lambdaMax'></span>

<h3>Description</h3>

<p>Internal EBglmnet functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>	EBelasticNet.Binomial(BASIS,Target, lambda, alpha,verbose)
	EBelasticNet.BinomialCV(BASIS,Target, nFolds,foldId, verbose)
	EBelasticNet.Gaussian(BASIS,Target, lambda, alpha,verbose)
	EBelasticNet.GaussianCV(BASIS,Target, nFolds,foldId, verbose)
	EBlassoNE.BinomialCV(BASIS,Target,nFolds,foldId,verbose)
	EBlassoNE.GaussianCV(BASIS,Target, nFolds,foldId,verbose)
	EBlassoNEG.Binomial(BASIS,Target,a_gamma,b_gamma, verbose)
	EBlassoNEG.BinomialCV(BASIS,Target,nFolds,foldId,verbose)
	EBlassoNEG.Gaussian(BASIS,Target,a_gamma, b_gamma,  verbose)
	EBlassoNEG.GaussianCV(BASIS,Target,nFolds,foldId,verbose)
	ijIndex(trueLoc,K)
	CVonePair(X,y,nFolds,foldId,hyperpara,prior,family,verbose)
	lambdaMax(X,y,Epis)
</code></pre>


<h3>Details</h3>

<p>These are not intended for use by users. 
<code>EBelasticNet.Binomial</code> fits sparse logistic regression using elastic net prior distribution. 
<code>EBelasticNet.BinomialCV</code> Cross Validation designed with 20 alpha and 20 lambdas for EBEN binomial model.
<code>EBelasticNet.Gaussian</code> fits sparse linear regression using elastic net prior distribution. 
<code>EBelasticNet.GaussianCV</code>Cross Validation designed with 20 alpha and 20 lambdas for EBEN Gaussian model.
<code>EBlassoNE.BinomialCV</code> Cross Validation designed with 20 lambdas for EBlasso binomial model.
<code>EBlassoNE.GaussianCV</code> Cross Validation designed with 20 lambdas for EBlasso Gaussian model.
<code>EBlassoNEG.Binomial</code> fits sparse logistic regression using lasso-NEG prior distribution. 
<code>EBlassoNEG.BinomialCV</code>Cross Validation designed with 3-step search for EBlasso-NEG binomial model.
<code>EBlassoNEG.Gaussian</code> fits sparse linear regression using lasso-NEG prior distribution. 
<code>EBlassoNEG.GaussianCV</code>Cross Validation designed with 3-step search for EBlasso-NEG Gaussian model.
<code>ijIndex</code>Function for looking at the pair of interaction terms.
<code>CVonePair</code>Function performs nFolds CV for the given one pair of hyperparameter.	
<code>lambdaMax</code>Function calculate the maximum lambda for EBlasso-NE and EBEN in CV.
</p>


<h3>Author(s)</h3>

<p>Anhui Huang and Dianting Liu <br /> Dept of Electrical and Computer Engineering, Univ of Miami, Coral Gables, FL</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
