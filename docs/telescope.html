<!DOCTYPE html><html lang="en"><head><title>Help for package telescope</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {telescope}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#identifyLCAMixture'><p>Solve label switching and identify mixture for a mixture of LCA models.</p></a></li>
<li><a href='#identifyMixture'><p>Solve label switching and identify mixture.</p></a></li>
<li><a href='#plotBubble'><p>Plot multivariate categorical data.</p></a></li>
<li><a href='#plotScatter'><p>Pairwise scatter plots of the data.</p></a></li>
<li><a href='#priorOnAlpha_spec'><p>Specify prior on <code class="reqn">\alpha</code>.</p></a></li>
<li><a href='#priorOnE0_spec'><p>Specify prior on e0.</p></a></li>
<li><a href='#priorOnK_spec'><p>Specify prior on <code class="reqn">K</code>.</p></a></li>
<li><a href='#sampleAlpha'><p>Sample alpha conditional on partition and K using an</p>
Metropolis-Hastings step with log-normal proposal.</a></li>
<li><a href='#sampleE0'><p>Sample e0 conditional on partition and K using an</p>
Metropolis-Hastings step with log-normal proposal.</a></li>
<li><a href='#sampleK_alpha'><p>Sample K conditional on <code class="reqn">\alpha</code> where <code class="reqn">e0 = \alpha/K</code>.</p></a></li>
<li><a href='#sampleK_e0'><p>Sample K conditional on e0 (fixed or random, but not depending on K).</p></a></li>
<li><a href='#sampleLCA'><p>Telescoping sampling of the LCA model where a prior on the number</p>
of components K is specified.</a></li>
<li><a href='#sampleLCAMixture'><p>Telescoping sampling of the mixture of LCA models where a prior on the</p>
number of components K is specified.</a></li>
<li><a href='#sampleMultNormMixture'><p>Telescoping sampling of a Bayesian finite multivariate Gaussian</p>
mixture where a prior on the number of components is specified.</a></li>
<li><a href='#samplePoisMixture'><p>Telescoping sampling of a Bayesian finite Poisson mixture with a</p>
prior on the number of components K.</a></li>
<li><a href='#sampleUniNormMixture'><p>Telescoping sampling of a Bayesian finite univariate Gaussian mixture where a prior</p>
on the number of components K is specified.</a></li>
<li><a href='#SimData'><p>Simulated multivariate binary data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.2-0</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Mixtures with an Unknown Number of Components</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits Bayesian finite mixtures with an unknown number of components using the telescoping sampler and different component distributions. For more details see Frühwirth-Schnatter et al. (2021) &lt;<a href="https://doi.org/10.1214%2F21-BA1294">doi:10.1214/21-BA1294</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, bayesm, DirichletReg, extraDistr, graphics, grDevices,
MCMCpack, methods, mvtnorm, stats</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Suggests:</td>
<td>invgamma, klaR, knitr, mclust, poLCA, rmarkdown</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-23 11:20:22 UTC; gruen</td>
</tr>
<tr>
<td>Author:</td>
<td>Gertraud Malsiner-Walli
    <a href="https://orcid.org/0000-0002-1213-4749"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Bettina Grün <a href="https://orcid.org/0000-0001-7265-4773"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Sylvia Frühwirth-Schnatter
    <a href="https://orcid.org/0000-0003-0516-5552"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gertraud Malsiner-Walli &lt;Gertraud.Malsiner-Walli@wu.ac.at&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-23 13:50:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='identifyLCAMixture'>Solve label switching and identify mixture for a mixture of LCA models.</h2><span id='topic+identifyLCAMixture'></span>

<h3>Description</h3>

<p>Clustering of the draws in the point process representation (PPR) using
<code class="reqn">k</code>-means clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identifyLCAMixture(Func, Mu, Phi, Eta, S, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="identifyLCAMixture_+3A_func">Func</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times d \times K</code>; data for clustering in the PPR.</p>
</td></tr>
<tr><td><code id="identifyLCAMixture_+3A_mu">Mu</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times r \times K</code>; draws of cluster means.</p>
</td></tr>
<tr><td><code id="identifyLCAMixture_+3A_phi">Phi</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times K \times r</code>; draws of precisions.</p>
</td></tr>
<tr><td><code id="identifyLCAMixture_+3A_eta">Eta</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times K</code>; draws of cluster sizes.</p>
</td></tr>
<tr><td><code id="identifyLCAMixture_+3A_s">S</code></td>
<td>
<p>A numeric matrix of dimension <code class="reqn">M \times N</code>; draws of cluster assignments.</p>
</td></tr>
<tr><td><code id="identifyLCAMixture_+3A_centers">centers</code></td>
<td>
<p>An integer or a numeric matrix of dimension <code class="reqn">K \times d</code>; used to initialize <code><a href="stats.html#topic+kmeans">stats::kmeans()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following steps are implemented:
</p>

<ul>
<li><p> A functional of the draws of the component-specific
parameters (<code>Func</code>) is passed to the function.  The functionals
of each component and iteration are stacked on top of each other in
order to obtain a matrix where each row corresponds to the
functional of one component.
</p>
</li>
<li><p> The functionals are clustered into <code class="reqn">K_+</code> clusters using <code class="reqn">k</code>-means
clustering. For each functional a group label is obtained.
</p>
</li>
<li><p> The obtained labels of the functionals are used to construct
a classification for each MCMC iteration.  Those classifications
which are a permutation of <code class="reqn">(1,\ldots,K_+)</code> are used to reorder
the Mu and Eta draws and the assignment matrix S. This results in an
identified mixture model.
</p>
</li>
<li><p> Note that only iterations resulting in permutations
are used for parameter estimation and deriving the final
partition. Those MCMC iterations where the obtained
classifications of the functionals are not a permutation of
<code class="reqn">(1,\ldots,K_+)</code> are discarded as no unique assignment of functionals
to components can be made.  If the non-permutation rate, i.e. the
proportion of MCMC iterations where the obtained classifications
of the functionals are not a permutation, is high, this is an
indication of a poor clustering solution, as the
functionals are not clearly separated.
</p>
</li></ul>



<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"S"</code>: reordered assignments.
</p>
</li>
<li> <p><code>"Mu"</code>: reordered Mu matrix.
</p>
</li>
<li> <p><code>"Phi"</code>: reordered Phi matrix.
</p>
</li>
<li> <p><code>"Eta"</code>: reordered weights.
</p>
</li>
<li> <p><code>"non_perm_rate"</code>: proportion of draws where the clustering did not
result in a permutation and hence no relabeling could be
performed; this is the proportion of draws discarded.
</p>
</li></ul>


<hr>
<h2 id='identifyMixture'>Solve label switching and identify mixture.</h2><span id='topic+identifyMixture'></span>

<h3>Description</h3>

<p>Clustering of the draws in the point process representation (PPR) using
<code class="reqn">k</code>-means clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identifyMixture(Func, Mu, Eta, S, centers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="identifyMixture_+3A_func">Func</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times d \times K</code>; data for clustering in the PPR.</p>
</td></tr>
<tr><td><code id="identifyMixture_+3A_mu">Mu</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times r \times K</code>; draws of cluster means.</p>
</td></tr>
<tr><td><code id="identifyMixture_+3A_eta">Eta</code></td>
<td>
<p>A numeric array of dimension <code class="reqn">M \times K</code>; draws of cluster sizes.</p>
</td></tr>
<tr><td><code id="identifyMixture_+3A_s">S</code></td>
<td>
<p>A numeric matrix of dimension <code class="reqn">M \times N</code>; draws of cluster assignments.</p>
</td></tr>
<tr><td><code id="identifyMixture_+3A_centers">centers</code></td>
<td>
<p>An integer or a numeric matrix of dimension <code class="reqn">K \times d</code>; used to initialize <code><a href="stats.html#topic+kmeans">stats::kmeans()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following steps are implemented:
</p>

<ul>
<li><p> A functional of the draws of the component-specific
parameters (<code>Func</code>) is passed to the function.  The functionals
of each component and iteration are stacked on top of each other in
order to obtain a matrix where each row corresponds to the
functional of one component.
</p>
</li>
<li><p> The functionals are clustered into <code class="reqn">K_+</code> clusters using <code class="reqn">k</code>-means
clustering. For each functional a group label is obtained.
</p>
</li>
<li><p> The obtained labels of the functionals are used to construct
a classification for each MCMC iteration.  Those classifications
which are a permutation of <code class="reqn">(1,\ldots,K_+)</code> are used to reorder
the Mu and Eta draws and the assignment matrix S. This results in an
identified mixture model.
</p>
</li>
<li><p> Note that only iterations resulting in permutations
are used for parameter estimation and deriving the final
partition. Those MCMC iterations where the obtained
classifications of the functionals are not a permutation of
<code class="reqn">(1,\ldots,K_+)</code> are discarded as no unique assignment of functionals
to components can be made.  If the non-permutation rate, i.e. the
proportion of MCMC iterations where the obtained classifications
of the functionals are not a permutation, is high, this is an
indication of a poor clustering solution, as the
functionals are not clearly separated.
</p>
</li></ul>



<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"S"</code>: reordered assignments.
</p>
</li>
<li> <p><code>"Mu"</code>: reordered Mu matrix.
</p>
</li>
<li> <p><code>"Eta"</code>: reordered weights.
</p>
</li>
<li> <p><code>"non_perm_rate"</code>: proportion of draws where the clustering did not
result in a permutation and hence no relabeling could be
performed; this is the proportion of draws discarded.
</p>
</li></ul>


<hr>
<h2 id='plotBubble'>Plot multivariate categorical data.</h2><span id='topic+plotBubble'></span>

<h3>Description</h3>

<p>Plots of the level combinations of pairs of variables
are created where the size of the circle indicating a level
combination is proportional to the frequency of the level
combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBubble(x, bg = "grey")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotBubble_+3A_x">x</code></td>
<td>
<p>A matrix or data.frame; the data consisting of categorical
variables.</p>
</td></tr>
<tr><td><code id="plotBubble_+3A_bg">bg</code></td>
<td>
<p>If specified, the symbols are filled with colour(s), the
vector <code>bg</code> is recycled to the number of observations.  The
default is to fill the symbols with grey color.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(chickwts, plotBubble(data.frame(cut(weight, 100 * 1:5), feed)))
</code></pre>

<hr>
<h2 id='plotScatter'>Pairwise scatter plots of the data.</h2><span id='topic+plotScatter'></span>

<h3>Description</h3>

<p>Scatter plots of the observations are plotted by
selecting pairs of dimensions, potentially colored by a known
classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotScatter(x, z, label = "", trim = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotScatter_+3A_x">x</code></td>
<td>
<p>A matrix or data.frame; the data consisting of metric variables.</p>
</td></tr>
<tr><td><code id="plotScatter_+3A_z">z</code></td>
<td>
<p>A vector; indicating the color to use for the observations.</p>
</td></tr>
<tr><td><code id="plotScatter_+3A_label">label</code></td>
<td>
<p>A character string; the text to include in the axes labels.</p>
</td></tr>
<tr><td><code id="plotScatter_+3A_trim">trim</code></td>
<td>
<p>A scalar numeric in <code class="reqn">[0, 0.5)</code>; trimming to use for quantiles to determine axes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plotScatter(iris[, 1:4], iris$Species, label = "dim")
</code></pre>

<hr>
<h2 id='priorOnAlpha_spec'>Specify prior on <code class="reqn">\alpha</code>.</h2><span id='topic+priorOnAlpha_spec'></span>

<h3>Description</h3>

<p>Obtain a function to evaluate the log prior specified
for <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priorOnAlpha_spec(H = c("alpha_const", "gam_05_05", "gam_1_2", "F_6_3"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="priorOnAlpha_spec_+3A_h">H</code></td>
<td>
<p>A character indicating which specification should be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following prior specifications are supported:
</p>

<ul>
<li> <p><code>"alpha_const"</code>: <code class="reqn">\alpha</code> is fixed at 1.
</p>
</li>
<li> <p><code>"gam_05_05"</code>: <code class="reqn">\alpha \sim</code> gamma(0.5, 0.5), i.e., shape = 0.5, rate = 0.5.
</p>
</li>
<li> <p><code>"gam_1_2"</code>: <code class="reqn">\alpha \sim</code> gamma(1, 2), i.e., shape = 1, rate = 2.
</p>
</li>
<li> <p><code>"F_6_3"</code>: <code class="reqn">\alpha \sim</code> F(6, 3), i.e., an F-distribution with degrees of freedom equal to 6 and 3.
</p>
</li></ul>



<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"log_pAlpha"</code>: a function of the log prior of <code class="reqn">\alpha</code>.
</p>
</li>
<li> <p><code>"param"</code>: a list with the parameters.
</p>
</li></ul>


<hr>
<h2 id='priorOnE0_spec'>Specify prior on e0.</h2><span id='topic+priorOnE0_spec'></span>

<h3>Description</h3>

<p>Obtain a function to evaluate the log prior specified
for <code class="reqn">e_0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priorOnE0_spec(E = c("G_1_20", "e0const"), e0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="priorOnE0_spec_+3A_e">E</code></td>
<td>
<p>A character indicating which specification should be used.</p>
</td></tr>
<tr><td><code id="priorOnE0_spec_+3A_e0">e0</code></td>
<td>
<p>A numeric scalar giving the fixed value of <code class="reqn">e_0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following prior specifications are supported:
</p>

<ul>
<li> <p><code>"G_1_20"</code>: <code class="reqn">e_0 \sim</code> gamma(1, 20), i.e., shape = 1, rate = 20.
</p>
</li>
<li> <p><code>"e0const"</code>: <code class="reqn">e_0</code> is fixed at <code>e0</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"log_p_e0"</code>: a function of the log prior of <code class="reqn">e_0</code>.
</p>
</li>
<li> <p><code>"param"</code>: a list with the parameters.
</p>
</li></ul>


<hr>
<h2 id='priorOnK_spec'>Specify prior on <code class="reqn">K</code>.</h2><span id='topic+priorOnK_spec'></span>

<h3>Description</h3>

<p>Obtain a function to evaluate the log prior
specified for <code class="reqn">K</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priorOnK_spec(
  P = c("fixedK", "Unif", "BNB_111", "BNB_121", "BNB_143", "BNB_443", "BNB_943",
    "Pois_1", "Pois_4", "Pois_9", "Geom_05", "Geom_02", "Geom_01", "NB_11", "NB_41",
    "NB_91"),
  K
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="priorOnK_spec_+3A_p">P</code></td>
<td>
<p>A character indicating which specification should be
used. See Details for suitable values.</p>
</td></tr>
<tr><td><code id="priorOnK_spec_+3A_k">K</code></td>
<td>
<p>A numeric or integer scalar specifying the fixed (if <code>P</code>
equals <code>"fixedK"</code>) or maximum value (if <code>P</code> equals <code>"Unif"</code>) of
<code class="reqn">K</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following prior specifications are supported:
</p>

<ul>
<li> <p><code>"fixedK"</code>: K has the fixed value K (second argument).
</p>
</li>
<li> <p><code>"Unif"</code>: <code class="reqn">K \sim</code> Unif<code class="reqn">[1,K]</code>, where the upper limit is given by K (second argument).
</p>
</li>
<li> <p><code>"BNB_111"</code>: <code class="reqn">K-1 \sim</code> BNB(1,1,1), i.e., <code class="reqn">K-1</code> follows a beta-negative binomial distribution with parameters <code class="reqn">(1,1,1)</code>.
</p>
</li>
<li> <p><code>"BNB_121"</code>: <code class="reqn">K-1 \sim</code> BNB(1,2,1), i.e., <code class="reqn">K-1</code> follows a beta-negative binomial distribution with parameters <code class="reqn">(1,2,1)</code>.
</p>
</li>
<li> <p><code>"BNB_143"</code>: <code class="reqn">K-1 \sim</code> BNB(1,2,1), i.e., <code class="reqn">K-1</code> follows a beta-negative binomial distribution with parameters <code class="reqn">(1,4,3)</code>.
</p>
</li>
<li> <p><code>"BNB_443"</code>: <code class="reqn">K-1 \sim</code> BNB(4,4,3), i.e., <code class="reqn">K-1</code> follows a beta-negative binomial distribution with parameters <code class="reqn">(4,4,3)</code>.
</p>
</li>
<li> <p><code>"BNB_943"</code>: <code class="reqn">K-1 \sim</code> BNB(9,4,3), i.e., <code class="reqn">K-1</code> follows a beta-negative binomial distribution with parameters <code class="reqn">(9,4,3)</code>.
</p>
</li>
<li> <p><code>"Pois_1"</code>: <code class="reqn">K-1 \sim</code> pois(1), i.e., <code class="reqn">K-1</code> follows a Poisson distribution with rate 1.
</p>
</li>
<li> <p><code>"Pois_4"</code>: <code class="reqn">K-1 \sim</code> pois(4), i.e., <code class="reqn">K-1</code> follows a Poisson distribution with rate 4.
</p>
</li>
<li> <p><code>"Pois_9"</code>: <code class="reqn">K-1 \sim</code> pois(9), i.e., <code class="reqn">K-1</code> follows a Poisson distribution with rate 9.
</p>
</li>
<li> <p><code>"Geom_05"</code>: <code class="reqn">K-1 \sim</code> geom(0.5), i.e., <code class="reqn">K-1</code> follows a geometric distribution with success probability <code class="reqn">p=0.5</code> and density <code class="reqn">f(x)=p(1-p)^x</code>.
</p>
</li>
<li> <p><code>"Geom_02"</code>: <code class="reqn">K-1 \sim</code> geom(0.2), i.e., <code class="reqn">K-1</code> follows a geometric distribution with success probability <code class="reqn">p=0.2</code> and density <code class="reqn">f(x)=p(1-p)^x</code>.
</p>
</li>
<li> <p><code>"Geom_01"</code>: <code class="reqn">K-1 \sim</code> geom(0.1), i.e., <code class="reqn">K-1</code> follows a geometric distribution with success probability <code class="reqn">p=0.1</code> and density <code class="reqn">f(x)=p(1-p)^x</code>.
</p>
</li>
<li> <p><code>"NB_11"</code>: <code class="reqn">K-1 \sim</code> nbinom(1,0.5), i.e., <code class="reqn">K-1</code> follows a negative-binomial distribution with <code class="reqn">size=1</code> and <code class="reqn">p=0.5</code>.
</p>
</li>
<li> <p><code>"NB_41"</code>: <code class="reqn">K-1 \sim</code> nbinom(4,0.5), i.e., <code class="reqn">K-1</code> follows a negative-binomial distribution with <code class="reqn">size=4</code> and <code class="reqn">p=0.5</code>.
</p>
</li>
<li> <p><code>"NB_91"</code>: <code class="reqn">K-1 \sim</code> nbinom(9,0.5), i.e., <code class="reqn">K-1</code> follows a negative-binomial distribution with <code class="reqn">size=9</code> and <code class="reqn">p=0.5</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"log_pK"</code>: a function of the log prior of <code class="reqn">K</code>.
</p>
</li>
<li> <p><code>"param"</code>: a list with the parameters.
</p>
</li></ul>


<hr>
<h2 id='sampleAlpha'>Sample alpha conditional on partition and K using an
Metropolis-Hastings step with log-normal proposal.</h2><span id='topic+sampleAlpha'></span>

<h3>Description</h3>

<p>Sample <code class="reqn">\alpha</code> conditional on the current
partition and value of <code class="reqn">K</code> using an Metropolis-Hastings
step with log-normal proposal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleAlpha(N, Nk, K, alpha, s0_proposal, log_pAlpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleAlpha_+3A_n">N</code></td>
<td>
<p>A number; indicating the sample size.</p>
</td></tr>
<tr><td><code id="sampleAlpha_+3A_nk">Nk</code></td>
<td>
<p>An integer vector; indicating the group sizes in the partition.</p>
</td></tr>
<tr><td><code id="sampleAlpha_+3A_k">K</code></td>
<td>
<p>A number; indicating the number of components.</p>
</td></tr>
<tr><td><code id="sampleAlpha_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value; indicating the value for <code class="reqn">\alpha</code>.</p>
</td></tr>
<tr><td><code id="sampleAlpha_+3A_s0_proposal">s0_proposal</code></td>
<td>
<p>A numeric value; indicating the standard deviation of the random walk.</p>
</td></tr>
<tr><td><code id="sampleAlpha_+3A_log_palpha">log_pAlpha</code></td>
<td>
<p>A function; evaluating the log prior of <code class="reqn">\alpha</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"alpha"</code>: a numeric, the new <code class="reqn">\alpha</code> value.
</p>
</li>
<li> <p><code>"acc"</code>: logical indicating acceptance.
</p>
</li></ul>


<hr>
<h2 id='sampleE0'>Sample e0 conditional on partition and K using an
Metropolis-Hastings step with log-normal proposal.</h2><span id='topic+sampleE0'></span>

<h3>Description</h3>

<p>Sample <code class="reqn">e_0</code> conditional on the current partition
and value of <code class="reqn">K</code> using an Metropolis-Hastings step with
log-normal proposal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleE0(K, Kp, N, Nk, s0_proposal, e0, log_p_e0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleE0_+3A_k">K</code></td>
<td>
<p>A number; indicating the number of components.</p>
</td></tr>
<tr><td><code id="sampleE0_+3A_kp">Kp</code></td>
<td>
<p>A number; indicating the number of filled components <code class="reqn">K_+</code>.</p>
</td></tr>
<tr><td><code id="sampleE0_+3A_n">N</code></td>
<td>
<p>A number; indicating the sample size.</p>
</td></tr>
<tr><td><code id="sampleE0_+3A_nk">Nk</code></td>
<td>
<p>An integer vector; indicating the group sizes in the partition.</p>
</td></tr>
<tr><td><code id="sampleE0_+3A_s0_proposal">s0_proposal</code></td>
<td>
<p>A numeric value; indicating the standard deviation of the random walk proposal.</p>
</td></tr>
<tr><td><code id="sampleE0_+3A_e0">e0</code></td>
<td>
<p>A numeric value; indicating the current value of <code class="reqn">e_0</code>.</p>
</td></tr>
<tr><td><code id="sampleE0_+3A_log_p_e0">log_p_e0</code></td>
<td>
<p>A function; evaluating the log prior of <code class="reqn">e_0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"e0"</code>: a numeric, the new <code class="reqn">e_0</code> value.
</p>
</li>
<li> <p><code>"acc"</code>: logical indicating acceptance.
</p>
</li></ul>


<hr>
<h2 id='sampleK_alpha'>Sample K conditional on <code class="reqn">\alpha</code> where <code class="reqn">e0 = \alpha/K</code>.</h2><span id='topic+sampleK_alpha'></span>

<h3>Description</h3>

<p>This sampling step only relies on the current
partition and is independent of the current component-specific
parameters, see Frühwirth-Schnatter et al (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleK_alpha(Kp_j, Kmax, Nk_j, alpha, log_pK)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleK_alpha_+3A_kp_j">Kp_j</code></td>
<td>
<p>A number; indicating the current value of <code class="reqn">K_+</code>.</p>
</td></tr>
<tr><td><code id="sampleK_alpha_+3A_kmax">Kmax</code></td>
<td>
<p>A number; indicating the maximum value of <code class="reqn">K</code> for which the conditional posterior is evaluated.</p>
</td></tr>
<tr><td><code id="sampleK_alpha_+3A_nk_j">Nk_j</code></td>
<td>
<p>A numeric vector; indicating the group sizes in the partition, i.e.,
the current number of observations in the filled components.</p>
</td></tr>
<tr><td><code id="sampleK_alpha_+3A_alpha">alpha</code></td>
<td>
<p>A number; indicating the value of the parameter <code class="reqn">\alpha</code>.</p>
</td></tr>
<tr><td><code id="sampleK_alpha_+3A_log_pk">log_pK</code></td>
<td>
<p>A function; evaluating the log prior of <code class="reqn">K</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number indicating the new value of <code class="reqn">K</code>.
</p>

<hr>
<h2 id='sampleK_e0'>Sample K conditional on e0 (fixed or random, but not depending on K).</h2><span id='topic+sampleK_e0'></span>

<h3>Description</h3>

<p>This sampling step only relies on the current
partition and is independent of the current component-specific
parameters, see Frühwirth-Schnatter et al (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleK_e0(Kp_j, Kmax, log_pK, log_p_e0, e0, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleK_e0_+3A_kp_j">Kp_j</code></td>
<td>
<p>A number; indicating the current value of <code class="reqn">K_+</code>.</p>
</td></tr>
<tr><td><code id="sampleK_e0_+3A_kmax">Kmax</code></td>
<td>
<p>A number; indicating the maximum value of <code class="reqn">K</code>, for which the conditional posterior is evaluated.</p>
</td></tr>
<tr><td><code id="sampleK_e0_+3A_log_pk">log_pK</code></td>
<td>
<p>A function; evaluating the prior of <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code id="sampleK_e0_+3A_log_p_e0">log_p_e0</code></td>
<td>
<p>A function; evaluating the log prior of <code class="reqn">e_0</code>.</p>
</td></tr>
<tr><td><code id="sampleK_e0_+3A_e0">e0</code></td>
<td>
<p>A number; indicating the value of <code class="reqn">e_0</code>.</p>
</td></tr>
<tr><td><code id="sampleK_e0_+3A_n">N</code></td>
<td>
<p>A number; indicating the number of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number indicating the new value of <code class="reqn">K</code>.
</p>

<hr>
<h2 id='sampleLCA'>Telescoping sampling of the LCA model where a prior on the number
of components K is specified.</h2><span id='topic+sampleLCA'></span>

<h3>Description</h3>


<ul>
<li><p> The MCMC scheme is implemented as suggested in Frühwirth-Schnatter et al (2021).
</p>
</li>
<li><p> The priors on the model parameters are specified as in Frühwirth-Schnatter et al (2021),
see the vignette for details and notation.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sampleLCA(
  y,
  S,
  pi,
  eta,
  a0,
  M,
  burnin,
  thin,
  Kmax,
  G = c("MixDynamic", "MixStatic"),
  priorOnK,
  priorOnWeights,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleLCA_+3A_y">y</code></td>
<td>
<p>A numeric matrix; containing the data.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_s">S</code></td>
<td>
<p>A numeric matrix; containing the initial cluster
assignments.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_pi">pi</code></td>
<td>
<p>A numeric vector; containing the initial cluster-specific
success probabilities.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_eta">eta</code></td>
<td>
<p>A numeric vector; containing the initial cluster sizes.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_a0">a0</code></td>
<td>
<p>A numeric vector; containing the parameters of the prior on the
cluster-specific success probabilities.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_m">M</code></td>
<td>
<p>A numeric scalar; specifying the number of recorded
iterations.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_burnin">burnin</code></td>
<td>
<p>A numeric scalar; specifying the number of burn-in
iterations.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_thin">thin</code></td>
<td>
<p>A numeric scalar; specifying the thinning used for the
iterations.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_kmax">Kmax</code></td>
<td>
<p>A numeric scalar; the maximum number of components.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_g">G</code></td>
<td>
<p>A character string; either <code>"MixDynamic"</code> or <code>"MixStatic"</code>.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_prioronk">priorOnK</code></td>
<td>
<p>A named list; providing the prior on the number of components K, see <code><a href="#topic+priorOnK_spec">priorOnK_spec()</a></code>.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_prioronweights">priorOnWeights</code></td>
<td>
<p>A named list; providing the prior on the mixture weights.</p>
</td></tr>
<tr><td><code id="sampleLCA_+3A_verbose">verbose</code></td>
<td>
<p>A logical; indicating if some intermediate clustering
results should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"Pi"</code>: sampled component-specific success probabilities.
</p>
</li>
<li> <p><code>"Eta"</code>: sampled weights.
</p>
</li>
<li> <p><code>"S"</code>: sampled assignments.
</p>
</li>
<li> <p><code>"Nk"</code>: number of observations assigned to the different components, for each iteration.
</p>
</li>
<li> <p><code>"K"</code>: sampled number of components.
</p>
</li>
<li> <p><code>"Kplus"</code>: number of filled, i.e., non-empty components, for each iteration.
</p>
</li>
<li> <p><code>"e0"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">e_0</code> is random).
</p>
</li>
<li> <p><code>"alpha"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">\alpha</code> is random).
</p>
</li>
<li> <p><code>"acc"</code>: logical vector indicating acceptance in the Metropolis-Hastings step when sampling either <code class="reqn">e_0</code> or <code class="reqn">\alpha</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("poLCA", quietly = TRUE)) {
    data("carcinoma", package = "poLCA")
    y &lt;- carcinoma
    N &lt;- nrow(y)
    r &lt;- ncol(y)
    
    M &lt;- 200
    thin &lt;- 1
    burnin &lt;- 100
    Kmax &lt;- 50  
    Kinit &lt;- 10
    
    G &lt;- "MixDynamic"
    priorOnAlpha &lt;- priorOnAlpha_spec("gam_1_2")
    priorOnK &lt;- priorOnK_spec("Pois_1")
    
    cat &lt;- apply(y, 2, max)
    a0 &lt;- rep(1, sum(cat))

    cl_y &lt;- kmeans(y, centers = Kinit, iter.max = 20)
    S_0 &lt;- cl_y$cluster
    eta_0 &lt;- cl_y$size/N

    pi_0 &lt;- do.call("cbind", lapply(1:r, function(j) {
        prop.table(table(S_0, y[, j]), 1)
    }))

    result &lt;- sampleLCA(
        y, S_0, pi_0, eta_0, a0, 
        M, burnin, thin, Kmax, 
        G, priorOnK, priorOnAlpha)

    K &lt;- result$K
    Kplus &lt;- result$Kplus   
    
    plot(K, type = "l", ylim = c(0, max(K)),  
         xlab = "iteration", main = "",
         ylab = expression("K" ~ "/" ~ K["+"]), col = 1)
    lines(Kplus, col = 2)
    legend("topright", legend = c("K", expression(K["+"])),
           col = 1:2, lty = 1, box.lwd = 0)
}

</code></pre>

<hr>
<h2 id='sampleLCAMixture'>Telescoping sampling of the mixture of LCA models where a prior on the
number of components K is specified.</h2><span id='topic+sampleLCAMixture'></span>

<h3>Description</h3>


<ul>
<li><p> The MCMC scheme is implemented as suggested in Malsiner-Walli et al (2024).
</p>
</li>
<li><p> Also the priors on the model parameters are specified as in Malsiner-Walli et al (2024),
see the vignette for details and notation.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sampleLCAMixture(
  y,
  S,
  L,
  pi,
  eta,
  mu,
  phi,
  a_00,
  a_mu,
  a_phi,
  b_phi,
  c_phi,
  d_phi,
  M,
  burnin,
  thin,
  Kmax,
  s_mu,
  s_phi,
  eps,
  G,
  priorOnWeights,
  d0,
  priorOnK,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleLCAMixture_+3A_y">y</code></td>
<td>
<p>A numeric matrix; containing the data where categories are coded with numbers.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_s">S</code></td>
<td>
<p>A numeric matrix; containing the initial cluster assignments.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_l">L</code></td>
<td>
<p>A numeric scalar; specifiying the number of classes within each component.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_pi">pi</code></td>
<td>
<p>A numeric matrix; containing the initial class-specific
occurrence probabilities.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_eta">eta</code></td>
<td>
<p>A numeric vector; containing the initial cluster sizes.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_mu">mu</code></td>
<td>
<p>A numeric matrix; containing the initial central component
occurrence probabilities.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_phi">phi</code></td>
<td>
<p>A numeric matrix; containing the initial component- and variable-specific
precisions.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_a_00">a_00</code></td>
<td>
<p>A numeric scalar; specifying the prior parameter a_00.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_a_mu">a_mu</code></td>
<td>
<p>A numeric vector; containing the prior parameter a_mu.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_a_phi">a_phi</code></td>
<td>
<p>A numeric vector; containing the prior parameter a_phi for each variable.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_b_phi">b_phi</code></td>
<td>
<p>A numeric vector; containing the initial value of b_phi for each variable.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_c_phi">c_phi</code></td>
<td>
<p>A numeric vector; containing the prior parameter c_phi for each variable.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_d_phi">d_phi</code></td>
<td>
<p>A numeric vector; containing the prior parameter d_phi for each variable.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_m">M</code></td>
<td>
<p>A numeric scalar; specifying the number of recorded
iterations.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_burnin">burnin</code></td>
<td>
<p>A numeric scalar; specifying the number of burn-in
iterations.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_thin">thin</code></td>
<td>
<p>A numeric scalar; specifying the thinning used for the
iterations.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_kmax">Kmax</code></td>
<td>
<p>A numeric scalar; the maximum number of components.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_s_mu">s_mu</code></td>
<td>
<p>A numeric scalar; specifying the standard deviation of
the proposal in the Metropolis-Hastings step when sampling mu.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_s_phi">s_phi</code></td>
<td>
<p>A numeric scalar; specifying the standard deviation of
the proposal in the Metropolis-Hastings step when sampling phi.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_eps">eps</code></td>
<td>
<p>A numeric scalar; a regularizing constant to bound the
Dirichlet proposal away from the boundary in the
Metropolis-Hastings step when sampling mu.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_g">G</code></td>
<td>
<p>A character string; either <code>"MixDynamic"</code> or <code>"MixStatic"</code>.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_prioronweights">priorOnWeights</code></td>
<td>
<p>A named list; providing the prior on the mixture weights.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_d0">d0</code></td>
<td>
<p>A numeric scalar; containing the Dirichlet prior parameter on the class weights.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_prioronk">priorOnK</code></td>
<td>
<p>A named list; providing the prior on the number of components K, see <code><a href="#topic+priorOnK_spec">priorOnK_spec()</a></code>.</p>
</td></tr>
<tr><td><code id="sampleLCAMixture_+3A_verbose">verbose</code></td>
<td>
<p>A logical; indicating if some intermediate clustering
results should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"Eta"</code>: sampled weights.
</p>
</li>
<li> <p><code>"S"</code>: sampled assignments.
</p>
</li>
<li> <p><code>"K"</code>: sampled number of components.
</p>
</li>
<li> <p><code>"Kplus"</code>: number of filled, i.e., non-empty components, for each iteration.
</p>
</li>
<li> <p><code>"Nk"</code>: number of observations assigned to the different components, for each iteration.
</p>
</li>
<li> <p><code>"Nl"</code>: number of observations assigned to the different classes within the components, for each iteration.
</p>
</li>
<li> <p><code>"e0"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">e_0</code> is random).
</p>
</li>
<li> <p><code>"alpha"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">\alpha</code> is random).
</p>
</li>
<li> <p><code>"acc"</code>: logical vector indicating acceptance in the Metropolis-Hastings step when sampling either <code class="reqn">e_0</code> or <code class="reqn">\alpha</code>.
</p>
</li>
<li> <p><code>"Mu"</code>: sampled central component occurrence probabilities.
</p>
</li>
<li> <p><code>"Phi"</code>: sampled precisions.
</p>
</li>
<li> <p><code>"acc_mu"</code>: the acceptance rate in the Metropolis-Hastings step when sampling <code class="reqn">\mu_{k,j}</code>.
</p>
</li>
<li> <p><code>"acc_phi"</code>: the acceptance rate in the Metropolis-Hastings step when sampling <code class="reqn">\phi_{k,j}</code>.
</p>
</li>
<li> <p><code>"nonnormpost_mode"</code>: parameter values corresponding to the mode of the nonnormalized posterior.
</p>
</li>
<li> <p><code>"Pi_k"</code>: sampled weighted component occurrence probabilities.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data("SimData", package = "telescope")
y &lt;- as.matrix(SimData[, 1:30])
z &lt;- SimData[, 31]
N &lt;- nrow(y)
r &lt;- ncol(y)
    
M &lt;- 5
thin &lt;- 1
burnin &lt;- 0
Kmax &lt;- 50  
Kinit &lt;- 10
    
G &lt;- "MixDynamic"
priorOnAlpha &lt;- priorOnAlpha_spec("gam_1_2")
priorOnK &lt;- priorOnK_spec("Pois_1")
d0 &lt;- 1  

cat &lt;- apply(y, 2, max)
a_mu &lt;- rep(20, sum(cat))
mu_0 &lt;- matrix(rep(rep(1/cat, cat), Kinit),
  byrow = TRUE, nrow = Kinit)

c_phi &lt;- 30; d_phi &lt;- 1; b_phi &lt;- rep(10, r)
a_phi &lt;- rep(1, r)
phi_0 &lt;- matrix(cat, Kinit, r, byrow = TRUE)

a_00 &lt;- 0.05

s_mu &lt;- 2; s_phi &lt;- 2; eps &lt;- 0.01 

set.seed(1234)
cl_y &lt;- kmeans(y, centers = Kinit, nstart = 100, iter.max = 50)
S_0 &lt;- cl_y$cluster
eta_0 &lt;- cl_y$size/N

I_0 &lt;- rep(1L, N)
L &lt;- 2
for (k in 1:Kinit) {
  cl_size &lt;- sum(S_0 == k)
  I_0[S_0 == k] &lt;- rep(1:L, length.out = cl_size)
}

index &lt;- c(0, cumsum(cat))
low &lt;- (index + 1)[-length(index)]
up &lt;- index[-1]

pi_km &lt;- array(NA_real_, dim = c(Kinit, L, sum(cat)))
rownames(pi_km) &lt;- paste0("k_", 1:Kinit)
for (k in 1:Kinit) {
  for (l in 1:L) {
    index &lt;- (S_0 == k) &amp; (I_0 == l)
    for (j in 1:r) {
      pi_km[k, l, low[j]:up[j]] &lt;- tabulate(y[index, j], cat[j]) / sum(index)
    }
  }
}
pi_0 &lt;- pi_km 

result &lt;- sampleLCAMixture(
    y, S_0, L,
    pi_0, eta_0, mu_0, phi_0,
    a_00, a_mu, a_phi, b_phi, c_phi, d_phi,
    M, burnin, thin, Kmax,
    s_mu, s_phi, eps,
    G, priorOnAlpha, d0, priorOnK)
</code></pre>

<hr>
<h2 id='sampleMultNormMixture'>Telescoping sampling of a Bayesian finite multivariate Gaussian
mixture where a prior on the number of components is specified.</h2><span id='topic+sampleMultNormMixture'></span>

<h3>Description</h3>


<ul>
<li><p> The MCMC scheme is implemented as suggested in Frühwirth-Schnatter et al (2021).
</p>
</li>
<li><p> The priors on the model parameters are specified as in Frühwirth-Schnatter et al (2021),
see the vignette for details and notation.
</p>
</li>
<li><p> The parameterizations of the Wishart and inverse Wishart distribution are used as in
Frühwirth-Schnatter et al (2021), see also the vignette.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sampleMultNormMixture(
  y,
  S,
  mu,
  Sigma,
  eta,
  c0,
  g0,
  G0,
  C0,
  b0,
  B0,
  M,
  burnin,
  thin,
  Kmax,
  G = c("MixDynamic", "MixStatic"),
  priorOnK,
  priorOnWeights,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleMultNormMixture_+3A_y">y</code></td>
<td>
<p>A numeric matrix; containing the data.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_s">S</code></td>
<td>
<p>A numeric matrix; containing the initial cluster
assignments.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_mu">mu</code></td>
<td>
<p>A numeric matrix; containing the initial cluster-specific
mean values.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_sigma">Sigma</code></td>
<td>
<p>A numeric matrix; containing the initial cluster-specific
variance covariance values.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_eta">eta</code></td>
<td>
<p>A numeric vector; containing the initial cluster sizes.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_c0">c0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\Sigma_k</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_g0">g0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">C_0</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_g0">G0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">C_0</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_c0">C0</code></td>
<td>
<p>A numeric vector; initial value of the hyperparameter <code class="reqn">C_0</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_b0">b0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\mu_k</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_b0">B0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\mu_k</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_m">M</code></td>
<td>
<p>A numeric scalar; specifying the number of recorded
iterations.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_burnin">burnin</code></td>
<td>
<p>A numeric scalar; specifying the number of burn-in
iterations.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_thin">thin</code></td>
<td>
<p>A numeric scalar; specifying the thinning used for the
iterations.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_kmax">Kmax</code></td>
<td>
<p>A numeric scalar; the maximum number of components.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_g">G</code></td>
<td>
<p>A character string; either <code>"MixDynamic"</code> or <code>"MixStatic"</code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_prioronk">priorOnK</code></td>
<td>
<p>A named list; providing the prior on the number of components K, see <code><a href="#topic+priorOnK_spec">priorOnK_spec()</a></code>.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_prioronweights">priorOnWeights</code></td>
<td>
<p>A named list; providing the prior on the mixture weights.</p>
</td></tr>
<tr><td><code id="sampleMultNormMixture_+3A_verbose">verbose</code></td>
<td>
<p>A logical; indicating if some intermediate clustering
results should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"Mu"</code>: sampled component means.
</p>
</li>
<li> <p><code>"Eta"</code>: sampled weights.
</p>
</li>
<li> <p><code>"S"</code>: sampled assignments.
</p>
</li>
<li> <p><code>"Nk"</code>: number of observations assigned to the different components, for each iteration.
</p>
</li>
<li> <p><code>"K"</code>: sampled number of components.
</p>
</li>
<li> <p><code>"Kplus"</code>: number of filled, i.e., non-empty components, for each iteration.
</p>
</li>
<li> <p><code>"e0"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">e_0</code> is random).
</p>
</li>
<li> <p><code>"alpha"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">\alpha</code> is random).
</p>
</li>
<li> <p><code>"acc"</code>: logical vector indicating acceptance in the Metropolis-Hastings step when sampling either <code class="reqn">e_0</code> or <code class="reqn">\alpha</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1:4]
z &lt;- iris$Species
r &lt;- ncol(y)

M &lt;- 50
thin &lt;- 1
burnin &lt;- 0
Kmax &lt;- 40  
Kinit &lt;- 10

G &lt;- "MixStatic"      
priorOnE0 &lt;- priorOnE0_spec("G_1_20", 1)
priorOnK &lt;- priorOnK_spec("BNB_143")

R &lt;- apply(y, 2, function(x) diff(range(x)))
b0 &lt;- apply(y, 2, median)
B_0 &lt;- rep(1, r)  
B0 &lt;- diag((R^2) * B_0)
c0 &lt;- 2.5 + (r-1)/2
g0 &lt;- 0.5 + (r-1)/2
G0 &lt;- 100 * g0/c0 * diag((1/R^2), nrow = r)
C0 &lt;- g0 * chol2inv(chol(G0))

cl_y &lt;- kmeans(y, centers = Kinit, nstart = 100)
S_0 &lt;- cl_y$cluster
mu_0 &lt;- t(cl_y$centers)

eta_0 &lt;- rep(1/Kinit, Kinit)
Sigma_0 &lt;- array(0, dim = c(r, r, Kinit))
Sigma_0[, , 1:Kinit] &lt;- 0.5 * C0

result &lt;- sampleMultNormMixture(
  y, S_0, mu_0, Sigma_0, eta_0,
  c0, g0, G0, C0, b0, B0,  
  M, burnin, thin, Kmax, G, priorOnK, priorOnE0)

K &lt;- result$K
Kplus &lt;- result$Kplus   

plot(K, type = "l", ylim = c(0, max(K)),
     xlab = "iteration", main = "",
     ylab = expression("K" ~ "/" ~ K["+"]), col = 1)
lines(Kplus, col = 2)
legend("topright", legend = c("K", expression(K["+"])),
       col = 1:2, lty = 1, box.lwd = 0)

</code></pre>

<hr>
<h2 id='samplePoisMixture'>Telescoping sampling of a Bayesian finite Poisson mixture with a
prior on the number of components K.</h2><span id='topic+samplePoisMixture'></span>

<h3>Description</h3>


<ul>
<li><p> The MCMC scheme is implemented as suggested in Frühwirth-Schnatter et al (2021).
</p>
</li>
<li><p> The priors on the model parameters are specified as in
Frühwirth-Schnatter et al (2021) and Früwirth-Schnatter and
Malsiner-Walli (2019), see the vignette for details and notation.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>samplePoisMixture(
  y,
  S,
  mu,
  eta,
  a0,
  b0,
  h0,
  H0,
  M,
  burnin,
  thin,
  Kmax,
  G = c("MixDynamic", "MixStatic"),
  priorOnK,
  priorOnWeights,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samplePoisMixture_+3A_y">y</code></td>
<td>
<p>A numeric matrix; containing the data.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_s">S</code></td>
<td>
<p>A numeric matrix; containing the initial cluster
assignments.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_mu">mu</code></td>
<td>
<p>A numeric matrix; containing the initial cluster-specific
rate values.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_eta">eta</code></td>
<td>
<p>A numeric vector; containing the initial cluster sizes.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_a0">a0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on the rate <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_b0">b0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on the rate <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_h0">h0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on the rate <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_h0">H0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on the rate <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_m">M</code></td>
<td>
<p>A numeric scalar; specifying the number of recorded
iterations.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_burnin">burnin</code></td>
<td>
<p>A numeric scalar; specifying the number of burn-in
iterations.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_thin">thin</code></td>
<td>
<p>A numeric scalar; specifying the thinning used for the
iterations.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_kmax">Kmax</code></td>
<td>
<p>A numeric scalar; the maximum number of components.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_g">G</code></td>
<td>
<p>A character string; either <code>"MixDynamic"</code> or <code>"MixStatic"</code>.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_prioronk">priorOnK</code></td>
<td>
<p>A named list; providing the prior on the number of components K, see <code><a href="#topic+priorOnK_spec">priorOnK_spec()</a></code>.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_prioronweights">priorOnWeights</code></td>
<td>
<p>A named list; providing the prior on the mixture weights.</p>
</td></tr>
<tr><td><code id="samplePoisMixture_+3A_verbose">verbose</code></td>
<td>
<p>A logical; indicating if some intermediate clustering
results should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"Mu"</code>: sampled rate <code class="reqn">\mu</code>.
</p>
</li>
<li> <p><code>"Eta"</code>: sampled weights.
</p>
</li>
<li> <p><code>"S"</code>: sampled assignments.
</p>
</li>
<li> <p><code>"Nk"</code>: number of observations assigned to the different components, for each iteration.
</p>
</li>
<li> <p><code>"K"</code>: sampled number of components.
</p>
</li>
<li> <p><code>"Kplus"</code>: number of filled, i.e., non-empty components, for each iteration.
</p>
</li>
<li> <p><code>"e0"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">e_0</code> is random).
</p>
</li>
<li> <p><code>"alpha"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">\alpha</code> is random).
</p>
</li>
<li> <p><code>"acc"</code>: logical vector indicating acceptance in the Metropolis-Hastings step when sampling either e0 or <code class="reqn">\alpha</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 200
z &lt;- sample(1:2, N, prob = c(0.5, 0.5), replace = TRUE)
y &lt;- rpois(N, c(1, 6)[z])

M &lt;- 200
thin &lt;- 1
burnin &lt;- 100

Kmax &lt;- 50  
Kinit &lt;- 10

G &lt;- "MixDynamic"
priorOnAlpha &lt;- priorOnAlpha_spec("gam_1_2")
priorOnK &lt;- priorOnK_spec("BNB_143")

a0 &lt;- 0.1 
h0 &lt;- 0.5 
b0 &lt;- a0/mean(y) 
H0 &lt;- h0/b0

cl_y &lt;- kmeans(y, centers = Kinit, nstart = 100)
S_0 &lt;- cl_y$cluster
mu_0 &lt;- t(cl_y$centers)
eta_0 &lt;- rep(1/Kinit, Kinit)

result &lt;- samplePoisMixture(
  y, S_0, mu_0, eta_0, 
  a0, b0, h0, H0,
  M, burnin, thin, Kmax, 
  G, priorOnK, priorOnAlpha)

K &lt;- result$K
Kplus &lt;- result$Kplus

plot(K, type = "l", ylim = c(0, max(K)), 
     xlab = "iteration", main = "",
     ylab = expression("K" ~ "/" ~ K["+"]), col = 1)
lines(Kplus, col = 2)
legend("topright", legend = c("K", expression(K["+"])),
       col = 1:2, lty = 1, box.lwd = 0)

</code></pre>

<hr>
<h2 id='sampleUniNormMixture'>Telescoping sampling of a Bayesian finite univariate Gaussian mixture where a prior
on the number of components K is specified.</h2><span id='topic+sampleUniNormMixture'></span>

<h3>Description</h3>


<ul>
<li><p> The MCMC scheme is implemented as suggested in Frühwirth-Schnatter et al (2021).
</p>
</li>
<li><p> The priors on the model parameters are specified as in Frühwirth-Schnatter et al (2021),
see the vignette for details and notation.
</p>
</li>
<li><p> The parametrizations of the gamma and inverse gamma distribution are used as in
Frühwirth-Schnatter et al (2021), see also the vignette.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sampleUniNormMixture(
  y,
  S,
  mu,
  sigma2,
  eta,
  c0,
  g0,
  G0,
  C0_0,
  b0,
  B0,
  M,
  burnin,
  thin,
  Kmax,
  G = c("MixDynamic", "MixStatic"),
  priorOnK,
  priorOnWeights,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleUniNormMixture_+3A_y">y</code></td>
<td>
<p>A numeric matrix; containing the data.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_s">S</code></td>
<td>
<p>A numeric matrix; containing the initial cluster
assignments.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_mu">mu</code></td>
<td>
<p>A numeric matrix; containing the initial cluster-specific
mean values.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_sigma2">sigma2</code></td>
<td>
<p>A numeric matrix; containing the initial cluster-specific
variance values.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_eta">eta</code></td>
<td>
<p>A numeric vector; containing the initial cluster sizes.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_c0">c0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\sigma^2_k</code>.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_g0">g0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\sigma^2_k</code></p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_g0">G0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\sigma^2_k</code></p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_c0_0">C0_0</code></td>
<td>
<p>A numeric vector; initial value of hyperparameter <code class="reqn">C_0</code>.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_b0">b0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\mu_k</code>.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_b0">B0</code></td>
<td>
<p>A numeric vector; hyperparameter of the prior on <code class="reqn">\mu_k</code>.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_m">M</code></td>
<td>
<p>A numeric scalar; specifying the number of recorded
iterations.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_burnin">burnin</code></td>
<td>
<p>A numeric scalar; specifying the number of burn-in
iterations.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_thin">thin</code></td>
<td>
<p>A numeric scalar; specifying the thinning used for the
iterations.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_kmax">Kmax</code></td>
<td>
<p>A numeric scalar; the maximum number of components.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_g">G</code></td>
<td>
<p>A character string; either <code>"MixDynamic"</code> or <code>"MixStatic"</code>.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_prioronk">priorOnK</code></td>
<td>
<p>A named list; providing the prior on the number of
components K, see <code><a href="#topic+priorOnK_spec">priorOnK_spec()</a></code>.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_prioronweights">priorOnWeights</code></td>
<td>
<p>A named list; providing the prior on the mixture weights.</p>
</td></tr>
<tr><td><code id="sampleUniNormMixture_+3A_verbose">verbose</code></td>
<td>
<p>A logical; indicating if some intermediate clustering
results should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing:
</p>

<ul>
<li> <p><code>"Mu"</code>: sampled component means.
</p>
</li>
<li> <p><code>"Sigma2"</code>: sampled component component variances.
</p>
</li>
<li> <p><code>"Eta"</code>: sampled weights.
</p>
</li>
<li> <p><code>"S"</code>: sampled assignments.
</p>
</li>
<li> <p><code>"Nk"</code>: number of observations assigned to the different components, for each iteration.
</p>
</li>
<li> <p><code>"K"</code>: sampled number of components.
</p>
</li>
<li> <p><code>"Kplus"</code>: number of filled, i.e., non-empty components, for each iteration.
</p>
</li>
<li> <p><code>"e0"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">e_0</code> is random).
</p>
</li>
<li> <p><code>"alpha"</code>: sampled Dirichlet parameter of the prior on the weights (if <code class="reqn">\alpha</code> is random).
</p>
</li>
<li> <p><code>"acc"</code>: logical vector indicating acceptance in the Metropolis-Hastings step when sampling either <code class="reqn">e_0</code> or <code class="reqn">\alpha</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("mclust", quietly = TRUE)) {
    data("acidity", package = "mclust")
    y &lt;- acidity
    
    N &lt;- length(y)
    r &lt;- 1
    
    M &lt;- 200
    thin &lt;- 1
    burnin &lt;- 100
    Kmax &lt;- 50  
    Kinit &lt;- 10
    
    G &lt;- "MixStatic" 
    priorOnE0 &lt;- priorOnE0_spec("e0const", 0.01)
    priorOnK &lt;- priorOnK_spec("Pois_1", 50)
    
    R &lt;- diff(range(y))
    c0 &lt;- 2 + (r-1)/2
    C0 &lt;- diag(c(0.02*(R^2)), nrow = r)
    g0 &lt;- 0.2 + (r-1) / 2
    G0 &lt;- diag(10/(R^2), nrow = r)
    B0 &lt;- diag((R^2), nrow = r)
    b0 &lt;- as.matrix((max(y) + min(y))/2, ncol = 1)  
    
    cl_y &lt;- kmeans(y, centers = Kinit, nstart = 100)
    S_0 &lt;- cl_y$cluster
    mu_0 &lt;- t(cl_y$centers)
    eta_0 &lt;- rep(1/Kinit, Kinit)
    sigma2_0 &lt;- array(0, dim = c(1, 1, Kinit))
    sigma2_0[1, 1, ] &lt;- 0.5 * C0

    result &lt;- sampleUniNormMixture(
        y, S_0, mu_0, sigma2_0, eta_0,
        c0, g0, G0, C0, b0, B0,
        M, burnin, thin, Kmax,
        G, priorOnK, priorOnE0)
    
    K &lt;- result$K
    Kplus &lt;- result$Kplus  
    
    plot(K, type = "l", ylim = c(0, max(K)),
         xlab = "iteration", main = "",
         ylab = expression("K" ~ "/" ~ K["+"]), col = 1)
    lines(Kplus, col = 2)
    legend("topright", legend = c("K", expression(K["+"])),
           col = 1:2, lty = 1, box.lwd = 0)
}

</code></pre>

<hr>
<h2 id='SimData'>Simulated multivariate binary data</h2><span id='topic+SimData'></span>

<h3>Description</h3>

<p>Simulated multivariate binary data with a 3-group
structure where the variables are correlated within the groups.
</p>


<h3>Format</h3>

<p>A data frame with 500 observations and 31 variables:
</p>

<dl>
<dt>y1</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y2</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y3</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y4</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y5</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y6</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y7</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y8</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y9</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y10</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y11</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y12</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y13</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y14</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y15</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y16</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y17</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y18</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y19</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y20</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y21</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y22</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y23</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y24</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y25</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y26</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y27</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y28</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y29</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>y30</dt><dd><p>binary variable coded 1 and 2</p>
</dd>
<dt>z</dt><dd><p>integer variable with values 1, 2, and 3 indicating group membership</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
