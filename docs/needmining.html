<!DOCTYPE html><html><head><title>Help for package needmining</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {needmining}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#needmining-package'><p>Functions for a simple needmining implementation</p></a></li>
<li><a href='#downloadTweets'><p>Downloading Tweets based on a keyword list</p></a></li>
<li><a href='#filterTweetsMachineLearning'><p>Classify needs based on machine learning</p></a></li>
<li><a href='#filterTweetsNeedwords'><p>Filter tweets containing need indicating words</p></a></li>
<li><a href='#NMdataToClassify'><p>Test dataset regarding the user needs for smart speakers</p></a></li>
<li><a href='#NMTrainingData'><p>Training dataset regarding the user needs for smart speakers</p></a></li>
<li><a href='#readNeedminingFile'><p>Read Tweet file</p></a></li>
<li><a href='#removeTweetsStopwords'><p>Remove Tweets containing stopwords</p></a></li>
<li><a href='#saveNeedminingFile'><p>Save Tweet file</p></a></li>
<li><a href='#twitterLogin'><p>Login into Twitter API</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Simple Needmining Implementation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;, Timothy P. Jurka [ctb], Yoshimasa Tsuruoka [ctb], Loren Collingwood [ctb], Amber E. Boydstun [ctb], Emiliano Grossman [ctb], Wouter van Atteveldt [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Showcasing needmining (the semi-automatic extraction of customer needs from
	social media data) with Twitter data. It uses the handling of the Twitter API provided by
	the package 'rtweet' and the textmining algorithms provided by the package 'tm'.
	Niklas Kuehl (2016) &lt;<a href="https://doi.org/10.1007%2F978-3-319-32689-4_14">doi:10.1007/978-3-319-32689-4_14</a>&gt; wrote an introduction to the topic of needmining.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, utils, rtweet, randomForest, stringr, SnowballC,
SparseM, tau, tm</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-08 18:57:05 UTC; dorian.proksch</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-08 19:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='needmining-package'>Functions for a simple needmining implementation</h2><span id='topic+needmining-package'></span><span id='topic+needmining'></span>

<h3>Description</h3>

<p>needmining provides the basic functionality to
download social media data from Twitter and 
semi automatically classify the data regarding
user needs
</p>

<hr>
<h2 id='downloadTweets'>Downloading Tweets based on a keyword list</h2><span id='topic+downloadTweets'></span>

<h3>Description</h3>

<p><code>downloadTweets</code> downloads Tweets containing specified keywords from the Twitter API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downloadTweets(search_terms, n = 100, lang = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downloadTweets_+3A_search_terms">search_terms</code></td>
<td>
<p>a string containing the search terms in Twitter format (use OR and AND to connect multiple search terms in one search)</p>
</td></tr>
<tr><td><code id="downloadTweets_+3A_n">n</code></td>
<td>
<p>The number of Tweets downloaded. Please note that this limit is based on your Twitter account</p>
</td></tr>
<tr><td><code id="downloadTweets_+3A_lang">lang</code></td>
<td>
<p>The language of the Tweets. Default is English. Please refer to the Twitter API documentation for language codes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function downloads Tweets for a specified keyword list, removes line breaks, adds a column isNeed filled with 0
</p>


<h3>Value</h3>

<p>a data frame containing the tweets as well as an additional column isNeed filled with 0
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>searchterm &lt;- '"smart speaker" OR "homepod" OR "google home mini"'
## Not run: 
token &lt;- twitterLogin()
currentTweets &lt;- downloadTweets(searchterm, n = 180)

## End(Not run)
</code></pre>

<hr>
<h2 id='filterTweetsMachineLearning'>Classify needs based on machine learning</h2><span id='topic+filterTweetsMachineLearning'></span>

<h3>Description</h3>

<p><code>filterTweetsMachineLearning</code> classifies a list of Tweets as
needs based on the random forest machine learning algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterTweetsMachineLearning(dataToClassify, trainingData)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filterTweetsMachineLearning_+3A_datatoclassify">dataToClassify</code></td>
<td>
<p>a dataframe containing the Tweet messages to classify</p>
</td></tr>
<tr><td><code id="filterTweetsMachineLearning_+3A_trainingdata">trainingData</code></td>
<td>
<p>a dataframe containing Tweets messages with a given classification (0=not a need, 1=a need)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses a machine learning algorithm (random forest) to
classify needs based on their content. It needs a training data set
with classified needs (indicated by 0=not a need, 1=a need).
This function used code fragments from the archived R packages 
maxent and RTextTools. The authors are Timothy P. Jurka, Yoshimasa Tsuruoka, 
Loren Collingwood, Amber E. Boydstun, Emiliano Grossman, Wouter van Atteveldt
</p>


<h3>Value</h3>

<p>a dataframe with classified data
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NMTrainingData)
data(NMdataToClassify)
smallNMTrainingData &lt;- rbind(NMTrainingData[1:75,], NMTrainingData[101:175,])
smallNMdataToClassify &lt;- rbind(NMdataToClassify[1:10,], NMdataToClassify[101:110,])
results &lt;- filterTweetsMachineLearning(smallNMdataToClassify, smallNMTrainingData)

</code></pre>

<hr>
<h2 id='filterTweetsNeedwords'>Filter tweets containing need indicating words</h2><span id='topic+filterTweetsNeedwords'></span>

<h3>Description</h3>

<p><code>filterTweetsNeedwords</code> filters a list of Tweets regarding
need indicating words
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterTweetsNeedwords(tweetMessages, needWords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filterTweetsNeedwords_+3A_tweetmessages">tweetMessages</code></td>
<td>
<p>a dataframe containing the Tweet messages</p>
</td></tr>
<tr><td><code id="filterTweetsNeedwords_+3A_needwords">needWords</code></td>
<td>
<p>a string containing needwords separately by ';'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function filters Tweets regarding a list of need indicating words
</p>


<h3>Value</h3>

<p>a filtered data frame
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NMTrainingData)
needWordsNeedsOnly &lt;- "need;want;wish;feature;ask;would like;improve;idea;upgrade"
needsSimple &lt;- filterTweetsNeedwords(NMTrainingData, needWordsNeedsOnly)
needWordsExtended &lt;- "need;want;wish;feature;ask;would like;improve;idea;upgrade;
					support;problem;issue;help;fix;complain;fail"
needsSimpleExtended &lt;- filterTweetsNeedwords(NMTrainingData, needWordsExtended)
</code></pre>

<hr>
<h2 id='NMdataToClassify'>Test dataset regarding the user needs for smart speakers</h2><span id='topic+NMdataToClassify'></span>

<h3>Description</h3>

<p>A dataset containing 200 artificially generated messages in
the Twitter format for the topic of smart speakers. These messages 
are inspired by real Tweets (rephrased, anonymized, all brand names
removed). Furthermore, Tweets containing stopwords were removed. 
100 rows contain user needs, 100 rows
contain no user needs. The data is coded (0=no need,1=a need). It can 
be used to test a classification algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NMdataToClassify)
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 rows and 2 variables:
</p>

<dl>
<dt>Tweets</dt><dd><p>Contains the message</p>
</dd>
<dt>isNeed</dt><dd><p>Is a need described within the message? 0=no, 1=yes</p>
</dd>
</dl>

<hr>
<h2 id='NMTrainingData'>Training dataset regarding the user needs for smart speakers</h2><span id='topic+NMTrainingData'></span>

<h3>Description</h3>

<p>A dataset containing 200 artificially generated messages in
the Twitter format for the topic of smart speakers. These messages 
are inspired by real Tweets (rephrased, anonymized, all brand names
removed). 100 rows contain user needs, 100 rows
contain no user needs. The data is coded (0=no need,1=a need).
The data can be used to train a classification algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NMTrainingData)
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 rows and 2 variables:
</p>

<dl>
<dt>Tweets</dt><dd><p>Contains the message</p>
</dd>
<dt>isNeed</dt><dd><p>Is a need described within the message? 0=no, 1=yes</p>
</dd>
</dl>

<hr>
<h2 id='readNeedminingFile'>Read Tweet file</h2><span id='topic+readNeedminingFile'></span>

<h3>Description</h3>

<p><code>readNeedminingFile</code> reads a Needmining file 
created by the needmining package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readNeedminingFile(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readNeedminingFile_+3A_filename">filename</code></td>
<td>
<p>The filename of the file to read</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function reads a Needmining file created by the needmining package
</p>


<h3>Value</h3>

<p>a data frame containing the content of the file
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NMTrainingData)
saveNeedminingFile(filename=file.path(tempdir(), "NMTrainingData.csv"),
NMTrainingData)
currentNeedData &lt;- readNeedminingFile(file.path(tempdir(), "NMTrainingData.csv"))
</code></pre>

<hr>
<h2 id='removeTweetsStopwords'>Remove Tweets containing stopwords</h2><span id='topic+removeTweetsStopwords'></span>

<h3>Description</h3>

<p><code>removeTweetsStopwords</code> removes Tweets containing stopwords
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeTweetsStopwords(tweetMessages, stopWords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="removeTweetsStopwords_+3A_tweetmessages">tweetMessages</code></td>
<td>
<p>a dataframe containing the Tweet messages</p>
</td></tr>
<tr><td><code id="removeTweetsStopwords_+3A_stopwords">stopWords</code></td>
<td>
<p>a string containing stopwords separated by ';'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function removes Tweets containing stopwords from a list of Twitter messages.
</p>


<h3>Value</h3>

<p>a filtered data frame
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stopWords &lt;- "review;giveaway;save;deal;win;won;price;launch;news;gift;announce;
 			 reveal;sale;http;buy;bought;purchase;sell;sold;invest;discount;
			coupon;ship;giving away"
data(NMTrainingData)
filteredTweets &lt;- removeTweetsStopwords(NMTrainingData, stopWords)
</code></pre>

<hr>
<h2 id='saveNeedminingFile'>Save Tweet file</h2><span id='topic+saveNeedminingFile'></span>

<h3>Description</h3>

<p><code>saveNeedminingFile</code> saves a dataframe
created by the needmining package
to a file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveNeedminingFile(filename, tweetMessages)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="saveNeedminingFile_+3A_filename">filename</code></td>
<td>
<p>The filename to save to</p>
</td></tr>
<tr><td><code id="saveNeedminingFile_+3A_tweetmessages">tweetMessages</code></td>
<td>
<p>An object containing the Twitter messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function saves a dataframe created by the needmining package to a file
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NMTrainingData)
saveNeedminingFile(filename=file.path(tempdir(), "NMTrainingData.csv"),
NMTrainingData)
</code></pre>

<hr>
<h2 id='twitterLogin'>Login into Twitter API</h2><span id='topic+twitterLogin'></span>

<h3>Description</h3>

<p><code>twitterLogin</code> creates a token for the
Twitter API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twitterLogin()
</code></pre>


<h3>Details</h3>

<p>This function creates a Twitter token of the Twitter API. This is necessary to use functions of the Twitter API. The login data has to be stored 
in the 'TwitterLoginData.csv' in the current set working directory (please refer to getwd() and setwd()). The file should have the following format:
START
app;consumer_key;consumer_secret;access_token;access_secret LINEBREAK
The name of your app; your consumer_key; your consumer_secret; your access_token; your access_secret
END OF FILE
</p>


<h3>Value</h3>

<p>a Twitter token
</p>


<h3>Author(s)</h3>

<p>Dorian Proksch &lt;dorian.proksch@hhl.de&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
token &lt;- twitterLogin()

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
