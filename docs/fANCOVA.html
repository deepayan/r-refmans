<!DOCTYPE html><html lang="en"><head><title>Help for package fANCOVA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fANCOVA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#loess.ancova'>
<p>Fit a semiparametric ANCOVA model with a local polynomial smoother</p></a></li>
<li><a href='#loess.as'>
<p>Fit a local polynomial regression with automatic smoothing parameter selection</p></a></li>
<li><a href='#plot.fANCOVA'>
<p>Plot a fANCOVA Object</p></a></li>
<li><a href='#T.aov'>
<p>Test the equality of nonparametric curves or surfaces based on an ANOVA-type statistic</p></a></li>
<li><a href='#T.L2'>
<p>Test the equality of nonparametric curves or surfaces based on L2 distance</p></a></li>
<li><a href='#T.var'>
<p>Test the equality of nonparametric curves or surfaces based on variance estimators</p></a></li>
<li><a href='#USpopu'><p>US national population</p></a></li>
<li><a href='#wild.boot'>
<p>Generate one or multiple bootstrap samples of regression residuals using the wild bootstrap method</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Nonparametric Analysis of Covariance</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6-1</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of R functions to perform nonparametric 
    analysis of covariance for regression curves or surfaces. 
    Testing the equality or parallelism of nonparametric curves 
    or surfaces is equivalent to analysis of variance (ANOVA) or 
    analysis of covariance (ANCOVA) for one-sample functional data. 
    Three different testing methods are available in the package, 
    including one based on L-2 distance, one based on an ANOVA 
    statistic, and one based on variance estimators.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-11-12 23:45:18 UTC; jix</td>
</tr>
<tr>
<td>Author:</td>
<td>Xiaofeng Wang [aut, cre],
  Xinge Ji [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xiaofeng Wang &lt;wangx6@ccf.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-11-13 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='loess.ancova'>
Fit a semiparametric ANCOVA model with a local polynomial smoother
</h2><span id='topic+loess.ancova'></span>

<h3>Description</h3>

<p>Fit a semiparametric ANCOVA model with a local polynomial smoother. The specific model considered here is
</p>
<p>y_ij= g_i + m(x_ij) + e_ij,
</p>
<p>where the parametric part of the model, g_i, is a factor variable; the nonparametric part of the model, m(.), is a nonparametric smooth function; e_ij are independent identically distributed errors. The errors e_ij do not have to be independent N(0, sigma^2) errors. The errors can be heteroscedastic, i.e., e_ij = sigma_i(x_ij) * u_ij, where u_ij are independent identically distributed errors with mean 0 and variance 1. The model is fitted by the direct estimation method (Speckman, 1988), or by the backfitting method (Buja, Hastie and Tibshirani, 1989; Hastie and Tibshirani, 1990).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loess.ancova(x, y, group, degree = 2, criterion = c("aicc", "gcv"), 
		family = c("gaussian", "symmetric"), method=c("Speckman", "Backfitting"), 
		iter = 10, tol = 0.01, user.span = NULL, plot = FALSE, 
		data.points = FALSE, legend.position = "topright", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loess.ancova_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_y">y</code></td>
<td>

<p>a vector of response values.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_group">group</code></td>
<td>

<p>a vector of group indicators that has the same length as y.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_degree">degree</code></td>
<td>

<p>the degree of the local polynomials to be used. It can ben 0, 1 or 2.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_criterion">criterion</code></td>
<td>

<p>the criterion for automatic smoothing parameter selection: &ldquo;aicc&rdquo; denotes bias-corrected AIC criterion, &ldquo;gcv&rdquo; denotes generalized cross-validation.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_family">family</code></td>
<td>

<p>if &ldquo;gaussian&rdquo; fitting is by least-squares, and if &ldquo;symmetric&rdquo; a re-descending M estimator is used with Tukey's biweight function.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_method">method</code></td>
<td>

<p>if &ldquo;Speckman&rdquo; the direct estimation method by Speckman (1988) will be used, and if &ldquo;Backfitting&rdquo; The model is fitted by the backfitting method (Buja, Hastie and Tibshirani, 1989; Hastie and Tibshirani, 1990).
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_iter">iter</code></td>
<td>

<p>the number of iterations.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_tol">tol</code></td>
<td>

<p>the number of tolerance in the iterations.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_user.span">user.span</code></td>
<td>

<p>the user-defined parameter which controls the degree of smoothing. If it is not specified, the smoothing parameter will be selected by &ldquo;aicc&rdquo; or &ldquo;gcv&rdquo; criterion.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_plot">plot</code></td>
<td>

<p>if TRUE (when x is one-dimensional), the fitted curves for all groups will be generated; if TRUE (when x is two-dimensional), only the smooth component in the model will be plotted.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_data.points">data.points</code></td>
<td>

<p>if TRUE, the data points will be displayed in the plot.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_legend.position">legend.position</code></td>
<td>

<p>the position of legend in the plot: &ldquo;topright&rdquo;, &ldquo;topleft&rdquo;, &ldquo;bottomright&rdquo;, &ldquo;bottomleft&rdquo;, etc.
</p>
</td></tr>
<tr><td><code id="loess.ancova_+3A_...">...</code></td>
<td>

<p>control parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fit a local polynomial regression with automatic smoothing parameter selection. The predictor x can either one-dimensional or two-dimensional.
</p>


<h3>Value</h3>

<p>a list of a vector of the parametric estimates and an object of class &ldquo;loess&rdquo;.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Speckman, P. (1988). Kernel Smoothing in Partial Linear Models. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 50, 413&ndash;436.
</p>
<p>Buja, A., Hastie, T. J. and Tibshirani, R. J. (1989). Linear smoothers and additive
models (with discussion). <em>Annals of Statistics</em>, 17, 453&ndash;555.
</p>
<p>Hastie, T. J. and Tibshirani, R. J. (1990). <em>Generalized Additive Models</em>. Vol. 43 of
Monographs on Statistics and Applied Probability, Chapman and Hall, London.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+loess">loess</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit semiparametric ANCOVA model
set.seed(555)
n1 &lt;- 80
x1 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.3
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- 3*cos(pi*x1/2)  + 6 + e1

n2 &lt;- 75
x2 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.2
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- 3*cos(pi*x2/2) + 3 + e2

n3 &lt;- 90
x3 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.3
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- 3*cos(pi*x3/2)  + e3

data.bind &lt;- rbind(cbind(x1,y1,1), cbind(x2,y2,2),cbind(x3,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x','y','group') 

x &lt;- data.bind[,1]
y &lt;- data.bind[,2]
group &lt;- data.bind[,3]

loess.ancova(x,y,group, plot=TRUE, data.points=TRUE)

## Fit semiparametric ANCOVA model when the predictor is two-dimensional
n1 &lt;- 100
x11 &lt;- runif(n1,min=0, max=3)
x12 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x11) + sin(2*x12)  + e1

n2 &lt;- 100
x21 &lt;- runif(n2, min=0, max=3)
x22 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x21) + sin(2*x22) + 1 + e2

n3 &lt;- 120
x31 &lt;- runif(n3, min=0, max=3)
x32 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x31) + sin(2*x32) + 3 + e3

data.bind &lt;- rbind(cbind(x11, x12 ,y1,1), cbind(x21, x22, y2,2),cbind(x31, x32,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x1','x2', 'y','group') 

loess.ancova(data.bind[,c(1,2)], data.bind$y, data.bind$group, plot=TRUE)
</code></pre>

<hr>
<h2 id='loess.as'>
Fit a local polynomial regression with automatic smoothing parameter selection
</h2><span id='topic+loess.as'></span>

<h3>Description</h3>

<p>Fit a local polynomial regression with automatic smoothing parameter selection. Two methods are available for the selection of the smoothing parameter: bias-corrected Akaike information criterion (aicc); and generalized cross-validation (gcv).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loess.as(x, y, degree = 1, criterion = c("aicc", "gcv"), 
		family = c("gaussian", "symmetric"), user.span = NULL, 
		plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loess.as_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_y">y</code></td>
<td>

<p>a vector of response values.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_degree">degree</code></td>
<td>

<p>the degree of the local polynomials to be used. It can ben 0, 1 or 2.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_criterion">criterion</code></td>
<td>

<p>the criterion for automatic smoothing parameter selection: &ldquo;aicc&rdquo; denotes bias-corrected AIC criterion, &ldquo;gcv&rdquo; denotes generalized cross-validation.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_family">family</code></td>
<td>

<p>if &ldquo;gaussian&rdquo; fitting is by least-squares, and if &ldquo;symmetric&rdquo; a re-descending M estimator is used with Tukey's biweight function.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_user.span">user.span</code></td>
<td>

<p>the user-defined parameter which controls the degree of smoothing.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_plot">plot</code></td>
<td>

<p>if TRUE, the fitted curve or surface will be generated.
</p>
</td></tr>
<tr><td><code id="loess.as_+3A_...">...</code></td>
<td>

<p>control parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fit a local polynomial regression with automatic smoothing parameter selection. The predictor x can either one-dimensional or two-dimensional.
</p>


<h3>Value</h3>

<p>An object of class &ldquo;loess&rdquo;.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Cleveland, W. S. (1979) Robust locally weighted regression and smoothing scatterplots. <em>Journal of the American Statistical Association</em>. 74, 829&ndash;836.
</p>
<p>Hurvich, C.M., Simonoff, J.S., and Tsai, C.L. (1998), Smoothing Parameter Selection in Nonparametric Regression Using an Improved Akaike Information Criterion. <em>Journal of the Royal Statistical Society B</em>. 60, 271&ndash;293.
</p>
<p>Golub, G., Heath, M. and Wahba, G. (1979). Generalized cross validation as a method for choosing a good ridge parameter. <em>Technometrics</em>. 21, 215&ndash;224.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+loess">loess</a></code>, <code><a href="#topic+loess.ancova">loess.ancova</a></code>, <code><a href="#topic+T.L2">T.L2</a></code>, <code><a href="#topic+T.aov">T.aov</a></code>, <code><a href="#topic+T.var">T.var</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit Local Polynomial Regression with Automatic Smoothing Parameter Selection
n1 &lt;- 100
x1 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x1) + e1

(y1.fit &lt;- loess.as(x1, y1, plot=TRUE))

n2 &lt;- 100
x21 &lt;- runif(n2, min=0, max=3)
x22 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x21) + sin(2*x22) + 1 + e2

(y2.fit &lt;- loess.as(cbind(x21, x22), y2, plot=TRUE))

</code></pre>

<hr>
<h2 id='plot.fANCOVA'>
Plot a fANCOVA Object
</h2><span id='topic+plot'></span><span id='topic+plot.fANCOVA'></span>

<h3>Description</h3>

<p>To plot a fANCOVA object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fANCOVA'
plot(x, test.statistic=TRUE, main="", n=256, legend.position="topright", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fANCOVA_+3A_x">x</code></td>
<td>

<p>a fANCOVA object
</p>
</td></tr>
<tr><td><code id="plot.fANCOVA_+3A_test.statistic">test.statistic</code></td>
<td>

<p>if TRUE, plot the density of the test statistic under null hypothesis;
if FALSE, plot the estimated curves.
</p>
</td></tr>
<tr><td><code id="plot.fANCOVA_+3A_main">main</code></td>
<td>

<p>the title of the plot
</p>
</td></tr>
<tr><td><code id="plot.fANCOVA_+3A_n">n</code></td>
<td>

<p>the number of points that are used to draw the curves or surfaces in the plot.
</p>
</td></tr>
<tr><td><code id="plot.fANCOVA_+3A_legend.position">legend.position</code></td>
<td>

<p>the position of legend in the plot: &ldquo;topright&rdquo;, &ldquo;topleft&rdquo;, &ldquo;bottomright&rdquo;, &ldquo;bottomleft&rdquo;, etc.
</p>
</td></tr>
<tr><td><code id="plot.fANCOVA_+3A_...">...</code></td>
<td>

<p>control parameters of the plot function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is to plot a fANCOVA object. The plot will be generated only if the predictor x is one-dimensional. if &ldquo;test.statistic=TRUE&rdquo;, a density plot of the test statistic under null hypothesis will be generated; if &ldquo;test.statistic=FALSE&rdquo;, the estimated curves for all groups are drawn.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+T.L2">T.L2</a></code>, <code><a href="#topic+T.aov">T.aov</a></code>, <code><a href="#topic+T.var">T.var</a></code>.
</p>

<hr>
<h2 id='T.aov'>
Test the equality of nonparametric curves or surfaces based on an ANOVA-type statistic
</h2><span id='topic+T.aov'></span><span id='topic+T.aov.default'></span>

<h3>Description</h3>

<p>Test the equality of nonparametric curves or surfaces based on an ANOVA-type statistic. The specific model considered here is
</p>
<p>y_ij= m_i(x_ij) + e_ij,
</p>
<p>where m_i(.), are nonparametric smooth functions; e_ij are independent identically distributed errors. The errors e_ij do not have to be independent N(0, sigma^2) errors. The errors can be heteroscedastic, i.e., e_ij = sigma_i(x_ij) * u_ij, where u_ij are independent identically distributed errors with mean 0 and variance 1.
</p>
<p>We are interested in the problem of testing the equality of the regression curves (when x is one-dimensional) or surfaces (when x is two-dimensional),
</p>
<p>H_0: m_1(.) = m_2(.) = ...
v.s.
H_1: otherwise
</p>
<p>The problem can also be viewed as the test of the equality in the one-sample problem for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T.aov(x, ...)
## Default S3 method:
T.aov(x, y, group, B = 200, degree = 1, criterion = c("aicc", "gcv"),
		family = c("gaussian", "symmetric"), tstat = c("DN", "YB"),
		user.span = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="T.aov_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_y">y</code></td>
<td>

<p>a vector of response values.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_group">group</code></td>
<td>

<p>a vector of group indicators that has the same length as y.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_b">B</code></td>
<td>

<p>the number of bootstrap replicates. Usually this will be a single positive integer.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_degree">degree</code></td>
<td>

<p>the degree of the local polynomials to be used. It can ben 0, 1 or 2.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_criterion">criterion</code></td>
<td>

<p>the criterion for automatic smoothing parameter selection: &ldquo;aicc&rdquo; denotes bias-corrected AIC criterion, &ldquo;gcv&rdquo; denotes generalized cross-validation.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_family">family</code></td>
<td>

<p>if &ldquo;gaussian&rdquo; fitting is by least-squares, and if &ldquo;symmetric&rdquo; a re-descending M estimator is used with Tukey's biweight function.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_tstat">tstat</code></td>
<td>

<p>the test statistic used here: if &ldquo;DN&rdquo; Dette, H., Neumeyer, N. (2001)'s statistic is used; if &ldquo;YB&rdquo; Young, S.G. and Bowman, A.W. (1995)'s statistic is used.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_user.span">user.span</code></td>
<td>

<p>The user-defined parameter which controls the degree of smoothing.
</p>
</td></tr>
<tr><td><code id="T.aov_+3A_...">...</code></td>
<td>

<p>some control parameters can also be supplied directly
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A wild bootstrap algorithm is applied to test the equality of nonparametric curves or surfaces based on an ANOVA-type statistic.
</p>


<h3>Value</h3>

<p>An object of class &ldquo;fANCOVA&rdquo;
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Dette, H., Neumeyer, N. (2001). Nonparametric analysis of covariance. <em>Annals of Statistics</em>. 29, 1361&ndash;1400.
</p>
<p>Young, S.G. and Bowman, A.W. (1995). Nonparametric analysis of covariance. <em>Biometrics</em>. 51, 920&ndash;931.
</p>
<p>Wang. X.F. and Ye, D. (2010). On nonparametric comparison of images and regression surfaces. <em>Journal of Statistical Planning and Inference</em>. 140, 2875&ndash;2884.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+T.L2">T.L2</a></code>, <code><a href="#topic+T.var">T.var</a></code>, <code><a href="#topic+loess.as">loess.as</a></code>, <code><a href="#topic+loess.ancova">loess.ancova</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nonparametric test the equality of multiple regression curves
## Simulate data sets

n1 &lt;- 100
x1 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x1) + e1

n2 &lt;- 100
x2 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x2) + 1 + e2

n3 &lt;- 120
x3 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x3)  + e3

data.bind &lt;- rbind(cbind(x1,y1,1), cbind(x2,y2,2),cbind(x3,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x','y','group')


t1 &lt;- T.aov(data.bind$x, data.bind$y, data.bind$group)
t1
plot(t1)
plot(t1, test.statistic=FALSE)

########
## Nonparametric test the equality for regression surfaces
## Simulate data sets

n1 &lt;- 100
x11 &lt;- runif(n1,min=0, max=3)
x12 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x11) + sin(2*x12)  + e1

n2 &lt;- 100
x21 &lt;- runif(n2, min=0, max=3)
x22 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x21) + sin(2*x22) + 1 + e2

n3 &lt;- 120
x31 &lt;- runif(n3, min=0, max=3)
x32 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x31) + sin(2*x32) + e3

data.bind &lt;- rbind(cbind(x11, x12 ,y1,1), cbind(x21, x22, y2,2),cbind(x31, x32,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x1','x2', 'y','group')

T.aov(data.bind[,c(1,2)], data.bind$y, data.bind$group)
</code></pre>

<hr>
<h2 id='T.L2'>
Test the equality of nonparametric curves or surfaces based on L2 distance
</h2><span id='topic+T.L2'></span><span id='topic+T.L2.default'></span>

<h3>Description</h3>

<p>Test the equality of nonparametric curves or surfaces based on L2 distance. The specific model considered here is
</p>
<p>y_ij= m_i(x_ij) + e_ij,
</p>
<p>where m_i(.), are nonparametric smooth functions; e_ij are independent identically distributed errors. The errors e_ij do not have to be independent N(0, sigma^2) errors. The errors can be heteroscedastic, i.e., e_ij = sigma_i(x_ij) * u_ij, where u_ij are independent identically distributed errors with mean 0 and variance 1.
</p>
<p>We are interested in the problem of testing the equality of the regression curves (when x is one-dimensional) or surfaces (when x is two-dimensional),
</p>
<p>H_0: m_1(.) = m_2(.) = ...
v.s.
H_1: otherwise
</p>
<p>The problem can also be viewed as the test of the equality in the one-sample problem for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T.L2(x, ...)
## Default S3 method:
T.L2(x, y, group, B = 200, degree = 1, criterion = c("aicc", "gcv"),
		family = c("gaussian", "symmetric"), m = 225, user.span = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="T.L2_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_y">y</code></td>
<td>

<p>a vector of response values.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_group">group</code></td>
<td>

<p>a vector of group indicators that has the same length as y.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_b">B</code></td>
<td>

<p>the number of bootstrap replicates. Usually this will be a single positive integer.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_degree">degree</code></td>
<td>

<p>the degree of the local polynomials to be used. It can ben 0, 1 or 2.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_criterion">criterion</code></td>
<td>

<p>the criterion for automatic smoothing parameter selection: &ldquo;aicc&rdquo; denotes bias-corrected AIC criterion, &ldquo;gcv&rdquo; denotes generalized cross-validation.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_family">family</code></td>
<td>

<p>if &ldquo;gaussian&rdquo; fitting is by least-squares, and if &ldquo;symmetric&rdquo; a re-descending M estimator is used with Tukey's biweight function.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_m">m</code></td>
<td>

<p>the number of the sampling points for the Monte-Carlo integration.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_user.span">user.span</code></td>
<td>

<p>the user-defined parameter which controls the degree of smoothing.
</p>
</td></tr>
<tr><td><code id="T.L2_+3A_...">...</code></td>
<td>

<p>some control parameters can also be supplied directly.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A wild bootstrap algorithm is applied to test the equality of nonparametric curves or surfaces based on L2 distance.
</p>


<h3>Value</h3>

<p>An object of class &ldquo;fANCOVA&rdquo;.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Dette, H., Neumeyer, N. (2001). Nonparametric analysis of covariance. <em>Annals of Statistics</em>. 29, 1361&ndash;1400.
</p>
<p>Wang. X.F. and Ye, D. (2010). On nonparametric comparison of images and regression surfaces. <em>Journal of Statistical Planning and Inference</em>. 140, 2875&ndash;2884.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+T.aov">T.aov</a></code>, <code><a href="#topic+T.var">T.var</a></code>, <code><a href="#topic+loess.as">loess.as</a></code>, <code><a href="#topic+loess.ancova">loess.ancova</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nonparametric test the equality of multiple regression curves
## Simulate data sets

n1 &lt;- 100
x1 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x1) + e1

n2 &lt;- 100
x2 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x2) + 1 + e2

n3 &lt;- 120
x3 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x3)  + e3

data.bind &lt;- rbind(cbind(x1,y1,1), cbind(x2,y2,2),cbind(x3,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x','y','group')


t1 &lt;- T.L2(data.bind$x, data.bind$y, data.bind$group, degree=2)
t1
plot(t1)
plot(t1, test.statistic=FALSE)

########
## Nonparametric test the equality for regression surfaces
## Simulate data sets

n1 &lt;- 100
x11 &lt;- runif(n1,min=0, max=3)
x12 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x11) + sin(2*x12)  + e1

n2 &lt;- 100
x21 &lt;- runif(n2, min=0, max=3)
x22 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x21) + sin(2*x22) + 1 + e2

n3 &lt;- 120
x31 &lt;- runif(n3, min=0, max=3)
x32 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x31) + sin(2*x32) + e3

data.bind &lt;- rbind(cbind(x11, x12 ,y1,1), cbind(x21, x22, y2,2),cbind(x31, x32,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x1','x2', 'y','group')

T.L2(data.bind[,c(1,2)], data.bind$y, data.bind$group, degree=2)
</code></pre>

<hr>
<h2 id='T.var'>
Test the equality of nonparametric curves or surfaces based on variance estimators
</h2><span id='topic+T.var'></span><span id='topic+T.var.default'></span>

<h3>Description</h3>

<p>Test the equality of nonparametric curves or surfaces based on variance estimators. The specific model considered here is
</p>
<p>y_ij= m_i(x_ij) + e_ij,
</p>
<p>where m_i(.), are nonparametric smooth functions; e_ij are independent identically distributed errors. The errors e_ij do not have to be independent N(0, sigma^2) errors. The errors can be heteroscedastic, i.e., e_ij = sigma_i(x_ij) * u_ij, where u_ij are independent identically distributed errors with mean 0 and variance 1.
</p>
<p>We are interested in the problem of testing the equality of the regression curves (when x is one-dimensional) or surfaces (when x is two-dimensional),
</p>
<p>H_0: m_1(.) = m_2(.) = ...
v.s.
H_1: otherwise
</p>
<p>The problem can also be viewed as the test of the equality in the one-sample problem for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T.var(x, ...)
## Default S3 method:
T.var(x, y, group, B = 200, degree = 1, criterion = c("aicc", "gcv"),
		family = c("gaussian", "symmetric"), user.span = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="T.var_+3A_x">x</code></td>
<td>

<p>a vector or two-column matrix of covariate values.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_y">y</code></td>
<td>

<p>a vector of response values.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_group">group</code></td>
<td>

<p>a vector of group indicators that has the same length as y.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_b">B</code></td>
<td>

<p>the number of bootstrap replicates. Usually this will be a single positive integer.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_degree">degree</code></td>
<td>

<p>the degree of the local polynomials to be used. It can ben 0, 1 or 2.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_criterion">criterion</code></td>
<td>

<p>the criterion for automatic smoothing parameter selection: &ldquo;aicc&rdquo; denotes bias-corrected AIC criterion, &ldquo;gcv&rdquo; denotes generalized cross-validation.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_family">family</code></td>
<td>

<p>if &ldquo;gaussian&rdquo; fitting is by least-squares, and if &ldquo;symmetric&rdquo; a re-descending M estimator is used with Tukey's biweight function.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_user.span">user.span</code></td>
<td>

<p>the user-defined parameter which controls the degree of smoothing.
</p>
</td></tr>
<tr><td><code id="T.var_+3A_...">...</code></td>
<td>

<p>some control parameters can also be supplied directly
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A wild bootstrap algorithm is applied to test the equality of nonparametric curves or surfaces based on variance estimators.
</p>


<h3>Value</h3>

<p>An object of class &ldquo;fANCOVA&rdquo;.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Dette, H., Neumeyer, N. (2001). Nonparametric analysis of covariance. <em>Annals of Statistics</em>. 29, 1361&ndash;1400.
</p>
<p>Wang. X.F. and Ye, D. (2010). On nonparametric comparison of images and regression surfaces. <em>Journal of Statistical Planning and Inference</em>. 140, 2875&ndash;2884.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+T.L2">T.L2</a></code>, <code><a href="#topic+T.aov">T.aov</a></code>, <code><a href="#topic+loess.as">loess.as</a></code>, <code><a href="#topic+loess.ancova">loess.ancova</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nonparametric test the equality of multiple regression curves
## Simulate data sets

n1 &lt;- 100
x1 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x1) + e1

n2 &lt;- 100
x2 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x2) + 1 + e2

n3 &lt;- 120
x3 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x3)  + e3

data.bind &lt;- rbind(cbind(x1,y1,1), cbind(x2,y2,2),cbind(x3,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x','y','group')


t1 &lt;- T.var(data.bind$x, data.bind$y, data.bind$group, degree=2, criterion="gcv")
t1
plot(t1)
plot(t1, test.statistic=FALSE)

########
## Nonparametric test the equality for regression surfaces
## Simulate data sets

n1 &lt;- 100
x11 &lt;- runif(n1,min=0, max=3)
x12 &lt;- runif(n1,min=0, max=3)
sd1 &lt;- 0.2
e1 &lt;- rnorm(n1,sd=sd1)
y1 &lt;- sin(2*x11) + sin(2*x12)  + e1

n2 &lt;- 100
x21 &lt;- runif(n2, min=0, max=3)
x22 &lt;- runif(n2, min=0, max=3)
sd2 &lt;- 0.25
e2 &lt;- rnorm(n2, sd=sd2)
y2 &lt;- sin(2*x21) + sin(2*x22) + 1 + e2

n3 &lt;- 120
x31 &lt;- runif(n3, min=0, max=3)
x32 &lt;- runif(n3, min=0, max=3)
sd3 &lt;- 0.25
e3 &lt;- rnorm(n3, sd=sd3)
y3 &lt;- sin(2*x31) + sin(2*x32) + e3

data.bind &lt;- rbind(cbind(x11, x12 ,y1,1), cbind(x21, x22, y2,2),cbind(x31, x32,y3,3))
data.bind &lt;- data.frame(data.bind)
colnames(data.bind)=c('x1','x2', 'y','group')

T.var(data.bind[,c(1,2)], data.bind$y, data.bind$group)
</code></pre>

<hr>
<h2 id='USpopu'>US national population</h2><span id='topic+USpopu'></span>

<h3>Description</h3>

<p>US national population by four groups from 1900 to 1979. The four groups are: Age 0; Age 20; Age 40; Age 60.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(USpopu)
</code></pre>


<h3>Format</h3>

<p>A data frame with 320 observations on 3 variables.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>age</code>  </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> the group variable of age </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>year</code>   </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> a numeric vector, giving year </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>population</code>  </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> a numeric vector, giving population in millions </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>References</h3>

<p><a href="https://www.census.gov/data/tables/time-series/demo/popest/pre-1980-national.html">https://www.census.gov/data/tables/time-series/demo/popest/pre-1980-national.html</a>, U.S. Census Bureau, National Intercensal Tables: 1900-1990. Last Revised: November 30, 2016
</p>


<h3>See Also</h3>

<p><code><a href="#topic+T.L2">T.L2</a></code>, <code><a href="#topic+T.aov">T.aov</a></code>, <code><a href="#topic+T.var">T.var</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(USpopu)
t1 &lt;- T.L2(USpopu$year, USpopu$population, USpopu$age, degree=2)
t1
plot(t1)
plot(t1, test.statistic=FALSE, legend.position="topleft")
</code></pre>

<hr>
<h2 id='wild.boot'>
Generate one or multiple bootstrap samples of regression residuals using the wild bootstrap method
</h2><span id='topic+wild.boot'></span>

<h3>Description</h3>

<p>Generate bootstrap samples using the wild bootstrap method introduced by Wu (1986). One of the advantages for the wild bootstrap method is that it allows for a heterogeneous variance in the residuals in regression analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wild.boot(x, nboot = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wild.boot_+3A_x">x</code></td>
<td>

<p>a vector of regression residuals.
</p>
</td></tr>
<tr><td><code id="wild.boot_+3A_nboot">nboot</code></td>
<td>

<p>the number of bootstrap replicates. Usually this will be a single positive integer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is to generate bootstrap residuals using the wild bootstrap method.
</p>


<h3>Value</h3>

<p>a vector or a matrix.
</p>


<h3>Author(s)</h3>

<p>X.F. Wang <a href="mailto:wangx6@ccf.org">wangx6@ccf.org</a>
</p>


<h3>References</h3>

<p>Wu, C. (1986) Jackknife, bootstrap and other resampling methods in regression analysis (with discussion). <em>Annals of Statistics</em>. 14, 1261&ndash;1350.
</p>
<p>Mammen, E. (1991). Bootstrap, wild bootstrap, and asymptotic normality. <em>Probability Theory and Related Fields</em>. 93, 439&ndash;455.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+T.L2">T.L2</a></code>, <code><a href="#topic+T.aov">T.aov</a></code>, <code><a href="#topic+T.var">T.var</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
x &lt;- runif(n, min=0, max=1)
## generate heteroscedastic error variances
sig.x &lt;- sqrt(exp(x)/2.5-0.4)
err &lt;- sapply(sig.x, function(x) rnorm(1, sd=x))
x2 &lt;- x^2
y &lt;- 10+3*x+2*x2 +err
plot(x,y)
fit &lt;- lm(y ~ x + x2)
## obtain 12 samples of the wild bootstrap residuals 
res.boot &lt;- wild.boot(fit$res, nboot=12)
## obtain 12 samples of the wild bootstrap responses
y.boot &lt;- matrix(rep(fit$fit,time=12), ncol=12) + res.boot
## plot the 12 wild bootstrap samples
## The wild bootstrap method keeps the patterns of variance heterogeneity 
## in the orginal sample.
par(mfrow=c(4,3))
for (i in 1:12) plot(x, y.boot[,i])

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
