<!DOCTYPE html><html><head><title>Help for package apache.sedona</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {apache.sedona}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#apache.sedona-package'><p>apache.sedona: R Interface for Apache Sedona</p></a></li>
<li><a href='#approx_count'><p>Find the approximate total number of records within a Spatial RDD.</p></a></li>
<li><a href='#crs_transform'><p>Perform a CRS transformation.</p></a></li>
<li><a href='#minimum_bounding_box'><p>Find the minimal bounding box of a geometry.</p></a></li>
<li><a href='#new_bounding_box'><p>Construct a bounding box object.</p></a></li>
<li><a href='#sdf_register.spatial_rdd'><p>Import data from a spatial RDD into a Spark Dataframe.</p></a></li>
<li><a href='#sedona_apply_spatial_partitioner'><p>Apply a spatial partitioner to a Sedona spatial RDD.</p></a></li>
<li><a href='#sedona_build_index'><p>Build an index on a Sedona spatial RDD.</p></a></li>
<li><a href='#sedona_knn_query'><p>Query the k nearest spatial objects.</p></a></li>
<li><a href='#sedona_range_query'><p>Execute a range query.</p></a></li>
<li><a href='#sedona_read_dsv_to_typed_rdd'><p>Create a typed SpatialRDD from a delimiter-separated values data source.</p></a></li>
<li><a href='#sedona_read_geojson'><p>Read geospatial data into a Spatial RDD</p></a></li>
<li><a href='#sedona_read_shapefile_to_typed_rdd'><p>(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source.</p></a></li>
<li><a href='#sedona_render_choropleth_map'><p>Visualize a Sedona spatial RDD using a choropleth map.</p></a></li>
<li><a href='#sedona_render_heatmap'><p>Visualize a Sedona spatial RDD using a heatmap.</p></a></li>
<li><a href='#sedona_render_scatter_plot'><p>Visualize a Sedona spatial RDD using a scatter plot.</p></a></li>
<li><a href='#sedona_save_spatial_rdd'><p>Save a Spark dataframe containing exactly 1 spatial column into a file.</p></a></li>
<li><a href='#sedona_spatial_join'><p>Perform a spatial join operation on two Sedona spatial RDDs.</p></a></li>
<li><a href='#sedona_spatial_join_count_by_key'><p>Perform a spatial count-by-key operation based on two Sedona spatial RDDs.</p></a></li>
<li><a href='#sedona_spatial_rdd_aggregation_routine'><p>Spatial RDD aggregation routine</p></a></li>
<li><a href='#sedona_spatial_rdd_data_source'><p>Create a SpatialRDD from an external data source.</p></a></li>
<li><a href='#sedona_visualization_routines'><p>Visualization routine for Sedona spatial RDD.</p></a></li>
<li><a href='#sedona_write_wkb'><p>Write SpatialRDD into a file.</p></a></li>
<li><a href='#spark_read_shapefile'><p>Read geospatial data into a Spark DataFrame.</p></a></li>
<li><a href='#spark_write_geojson'><p>Write geospatial data from a Spark DataFrame.</p></a></li>
<li><a href='#spatial_join_op'><p>Spatial join operator</p></a></li>
<li><a href='#spatial_query'><p>Execute a spatial query</p></a></li>
<li><a href='#to_spatial_rdd'><p>Export a Spark SQL query with a spatial column into a Sedona spatial RDD.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>R Interface for Apache Sedona</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Apache Sedona &lt;private@sedona.apache.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>R interface for 'Apache Sedona' based on 'sparklyr'
    (<a href="https://sedona.apache.org">https://sedona.apache.org</a>).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/apache/sedona/">https://github.com/apache/sedona/</a>, <a href="https://sedona.apache.org/">https://sedona.apache.org/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/apache/sedona/issues">https://github.com/apache/sedona/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>rlang, sparklyr (&ge; 1.3), dbplyr (&ge; 1.1.0), cli, lifecycle</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dplyr (&ge; 0.7.2), knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>'Apache Spark' 3.x</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-17 18:16:00 UTC; jiayu</td>
</tr>
<tr>
<td>Author:</td>
<td>Apache Sedona [aut, cre],
  Jia Yu [ctb, cph],
  Yitao Li <a href="https://orcid.org/0000-0002-1261-905X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph],
  The Apache Software Foundation [cph],
  RStudio [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-17 18:42:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='apache.sedona-package'>apache.sedona: R Interface for Apache Sedona</h2><span id='topic+apache.sedona'></span><span id='topic+apache.sedona-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>R interface for 'Apache Sedona' based on 'sparklyr' (<a href="https://sedona.apache.org">https://sedona.apache.org</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>:  Apache Sedona <a href="mailto:private@sedona.apache.org">private@sedona.apache.org</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Yitao Li <a href="mailto:yitao@rstudio.com">yitao@rstudio.com</a> (<a href="https://orcid.org/0000-0002-1261-905X">ORCID</a>) [copyright holder]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Jia Yu <a href="mailto:jiayu@apache.org">jiayu@apache.org</a> [contributor, copyright holder]
</p>
</li>
<li><p>  The Apache Software Foundation [copyright holder]
</p>
</li>
<li><p>  RStudio [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/apache/sedona/">https://github.com/apache/sedona/</a>
</p>
</li>
<li> <p><a href="https://sedona.apache.org/">https://sedona.apache.org/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/apache/sedona/issues">https://github.com/apache/sedona/issues</a>
</p>
</li></ul>


<hr>
<h2 id='approx_count'>Find the approximate total number of records within a Spatial RDD.</h2><span id='topic+approx_count'></span>

<h3>Description</h3>

<p>Given a Sedona spatial RDD, find the (possibly approximated) number of total
records within it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>approx_count(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="approx_count_+3A_x">x</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Approximate number of records within the SpatialRDD.
</p>


<h3>See Also</h3>

<p>Other Spatial RDD aggregation routine: 
<code><a href="#topic+minimum_bounding_box">minimum_bounding_box</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_shapefile_to_typed_rdd(
    sc,
    location = input_location, type = "polygon"
  )
  approx_cnt &lt;- approx_count(rdd)
}

</code></pre>

<hr>
<h2 id='crs_transform'>Perform a CRS transformation.</h2><span id='topic+crs_transform'></span>

<h3>Description</h3>

<p>Transform data within a spatial RDD from one coordinate reference system to
another. This uses the lon/lat order since v1.5.0. Before, it used lat/lon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crs_transform(x, src_epsg_crs_code, dst_epsg_crs_code, strict = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crs_transform_+3A_x">x</code></td>
<td>
<p>The spatial RDD to be processed.</p>
</td></tr>
<tr><td><code id="crs_transform_+3A_src_epsg_crs_code">src_epsg_crs_code</code></td>
<td>
<p>Coordinate reference system to transform from
(e.g., &quot;epsg:4326&quot;, &quot;epsg:3857&quot;, etc).</p>
</td></tr>
<tr><td><code id="crs_transform_+3A_dst_epsg_crs_code">dst_epsg_crs_code</code></td>
<td>
<p>Coordinate reference system to transform to.
(e.g., &quot;epsg:4326&quot;, &quot;epsg:3857&quot;, etc).</p>
</td></tr>
<tr><td><code id="crs_transform_+3A_strict">strict</code></td>
<td>
<p>If FALSE (default), then ignore the &quot;Bursa-Wolf Parameters
Required&quot; error.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformed SpatialRDD.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_geojson_to_typed_rdd(
    sc,
    location = input_location, type = "polygon"
  )
  crs_transform(
    rdd,
    src_epsg_crs_code = "epsg:4326", dst_epsg_crs_code = "epsg:3857"
  )
}

</code></pre>

<hr>
<h2 id='minimum_bounding_box'>Find the minimal bounding box of a geometry.</h2><span id='topic+minimum_bounding_box'></span>

<h3>Description</h3>

<p>Given a Sedona spatial RDD, find the axis-aligned minimal bounding box of the
geometry represented by the RDD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minimum_bounding_box(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="minimum_bounding_box_+3A_x">x</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A minimum bounding box object.
</p>


<h3>See Also</h3>

<p>Other Spatial RDD aggregation routine: 
<code><a href="#topic+approx_count">approx_count</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_shapefile_to_typed_rdd(
    sc,
    location = input_location, type = "polygon"
  )
  boundary &lt;- minimum_bounding_box(rdd)
}

</code></pre>

<hr>
<h2 id='new_bounding_box'>Construct a bounding box object.</h2><span id='topic+new_bounding_box'></span>

<h3>Description</h3>

<p>Construct a axis-aligned rectangular bounding box object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_bounding_box(sc, min_x = -Inf, max_x = Inf, min_y = -Inf, max_y = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="new_bounding_box_+3A_sc">sc</code></td>
<td>
<p>The Spark connection.</p>
</td></tr>
<tr><td><code id="new_bounding_box_+3A_min_x">min_x</code></td>
<td>
<p>Minimum x-value of the bounding box, can be +/- Inf.</p>
</td></tr>
<tr><td><code id="new_bounding_box_+3A_max_x">max_x</code></td>
<td>
<p>Maximum x-value of the bounding box, can be +/- Inf.</p>
</td></tr>
<tr><td><code id="new_bounding_box_+3A_min_y">min_y</code></td>
<td>
<p>Minimum y-value of the bounding box, can be +/- Inf.</p>
</td></tr>
<tr><td><code id="new_bounding_box_+3A_max_y">max_y</code></td>
<td>
<p>Maximum y-value of the bounding box, can be +/- Inf.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bounding box object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")
bb &lt;- new_bounding_box(sc, -1, 1, -1, 1)

</code></pre>

<hr>
<h2 id='sdf_register.spatial_rdd'>Import data from a spatial RDD into a Spark Dataframe.</h2><span id='topic+sdf_register.spatial_rdd'></span><span id='topic+as.spark.dataframe'></span>

<h3>Description</h3>

<p>Import data from a spatial RDD (possibly with non-spatial attributes) into a
Spark Dataframe.
</p>

<ul>
<li> <p><code>sdf_register</code>: method for sparklyr's sdf_register to handle Spatial RDD
</p>
</li>
<li> <p><code>as.spark.dataframe</code>: lower level function with more fine-grained control on non-spatial columns
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spatial_rdd'
sdf_register(x, name = NULL)

as.spark.dataframe(x, non_spatial_cols = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdf_register.spatial_rdd_+3A_x">x</code></td>
<td>
<p>A spatial RDD.</p>
</td></tr>
<tr><td><code id="sdf_register.spatial_rdd_+3A_name">name</code></td>
<td>
<p>Name to assign to the resulting Spark temporary view. If
unspecified, then a random name will be assigned.</p>
</td></tr>
<tr><td><code id="sdf_register.spatial_rdd_+3A_non_spatial_cols">non_spatial_cols</code></td>
<td>
<p>Column names for non-spatial attributes in the
resulting Spark Dataframe. By default (NULL) it will import all field names if that property exists, in particular for shapefiles.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark Dataframe containing the imported spatial data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_geojson_to_typed_rdd(
    sc,
    location = input_location,
    type = "polygon"
  )
  sdf &lt;- sdf_register(rdd)
  
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    delimiter = ",",
    type = "point",
    first_spatial_col_index = 1L,
    repartition = 5
  )
  sdf &lt;- as.spark.dataframe(rdd, non_spatial_cols = c("attr1", "attr2"))
}

</code></pre>

<hr>
<h2 id='sedona_apply_spatial_partitioner'>Apply a spatial partitioner to a Sedona spatial RDD.</h2><span id='topic+sedona_apply_spatial_partitioner'></span>

<h3>Description</h3>

<p>Given a Sedona spatial RDD, partition its content using a spatial
partitioner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_apply_spatial_partitioner(
  rdd,
  partitioner = c("quadtree", "kdbtree"),
  max_levels = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_apply_spatial_partitioner_+3A_rdd">rdd</code></td>
<td>
<p>The spatial RDD to be partitioned.</p>
</td></tr>
<tr><td><code id="sedona_apply_spatial_partitioner_+3A_partitioner">partitioner</code></td>
<td>
<p>The name of a grid type to use (currently &quot;quadtree&quot; and
&quot;kdbtree&quot; are supported) or an
<code>org.apache.sedona.core.spatialPartitioning.SpatialPartitioner</code> JVM
object. The latter option is only relevant for advanced use cases involving
a custom spatial partitioner.</p>
</td></tr>
<tr><td><code id="sedona_apply_spatial_partitioner_+3A_max_levels">max_levels</code></td>
<td>
<p>Maximum number of levels in the partitioning tree data
structure. If NULL (default), then use the current number of partitions
within <code>rdd</code> as maximum number of levels.
Specifying <code>max_levels</code> is unsupported for use cases involving a
custom spatial partitioner because in these scenarios the partitioner
object already has its own maximum number of levels set and there is no
well-defined way to override this existing setting in the partitioning
data structure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A spatially partitioned SpatialRDD.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    delimiter = ",",
    type = "point",
    first_spatial_col_index = 1L
  )
  sedona_apply_spatial_partitioner(rdd, partitioner = "kdbtree")
}

</code></pre>

<hr>
<h2 id='sedona_build_index'>Build an index on a Sedona spatial RDD.</h2><span id='topic+sedona_build_index'></span>

<h3>Description</h3>

<p>Given a Sedona spatial RDD, build the type of index specified on each of its
partition(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_build_index(
  rdd,
  type = c("quadtree", "rtree"),
  index_spatial_partitions = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_build_index_+3A_rdd">rdd</code></td>
<td>
<p>The spatial RDD to be indexed.</p>
</td></tr>
<tr><td><code id="sedona_build_index_+3A_type">type</code></td>
<td>
<p>The type of index to build. Currently &quot;quadtree&quot; and &quot;rtree&quot; are
supported.</p>
</td></tr>
<tr><td><code id="sedona_build_index_+3A_index_spatial_partitions">index_spatial_partitions</code></td>
<td>
<p>If the RDD is already partitioned using a
spatial partitioner, then index each spatial partition within the RDD
instead of partitions within the raw RDD associated with the underlying
spatial data source. Default: TRUE.
Notice this option is irrelevant if the input RDD has not been partitioned
using with a spatial partitioner yet.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A spatial index object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_shapefile_to_typed_rdd(
    sc,
    location = input_location,
    type = "polygon"
  )
  sedona_build_index(rdd, type = "rtree")
}

</code></pre>

<hr>
<h2 id='sedona_knn_query'>Query the k nearest spatial objects.</h2><span id='topic+sedona_knn_query'></span>

<h3>Description</h3>

<p>Given a spatial RDD, a query object <code>x</code>, and an integer k, find the k
nearest spatial objects within the RDD from <code>x</code> (distance between
<code>x</code> and another geometrical object will be measured by the minimum
possible length of any line segment connecting those 2 objects).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_knn_query(
  rdd,
  x,
  k,
  index_type = c("quadtree", "rtree"),
  result_type = c("rdd", "sdf", "raw")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_knn_query_+3A_rdd">rdd</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
<tr><td><code id="sedona_knn_query_+3A_x">x</code></td>
<td>
<p>The query object.</p>
</td></tr>
<tr><td><code id="sedona_knn_query_+3A_k">k</code></td>
<td>
<p>Number of nearest spatail objects to return.</p>
</td></tr>
<tr><td><code id="sedona_knn_query_+3A_index_type">index_type</code></td>
<td>
<p>Index to use to facilitate the KNN query. If NULL, then
do not build any additional spatial index on top of <code>x</code>. Supported
index types are &quot;quadtree&quot; and &quot;rtree&quot;.</p>
</td></tr>
<tr><td><code id="sedona_knn_query_+3A_result_type">result_type</code></td>
<td>
<p>Type of result to return.
If &quot;rdd&quot; (default), then the k nearest objects will be returned in a Sedona
spatial RDD.
If &quot;sdf&quot;, then a Spark dataframe containing the k nearest objects will be
returned.
If &quot;raw&quot;, then a list of k nearest objects will be returned. Each element
within this list will be a JVM object of type
<code>org.locationtech.jts.geom.Geometry</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The KNN query result.
</p>


<h3>See Also</h3>

<p>Other Sedona spatial query: 
<code><a href="#topic+sedona_range_query">sedona_range_query</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  knn_query_pt_x &lt;- -84.01
  knn_query_pt_y &lt;- 34.01
  knn_query_pt_tbl &lt;- sdf_sql(
    sc,
    sprintf(
      "SELECT ST_GeomFromText(\"POINT(%f %f)\") AS `pt`",
      knn_query_pt_x,
      knn_query_pt_y
    )
  ) %&gt;%
      collect()
  knn_query_pt &lt;- knn_query_pt_tbl$pt[[1]]
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_geojson_to_typed_rdd(
    sc,
    location = input_location,
    type = "polygon"
  )
  knn_result_sdf &lt;- sedona_knn_query(
    rdd,
    x = knn_query_pt, k = 3, index_type = "rtree", result_type = "sdf"
  )
}

</code></pre>

<hr>
<h2 id='sedona_range_query'>Execute a range query.</h2><span id='topic+sedona_range_query'></span>

<h3>Description</h3>

<p>Given a spatial RDD and a query object <code>x</code>, find all spatial objects
within the RDD that are covered by <code>x</code> or intersect <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_range_query(
  rdd,
  x,
  query_type = c("cover", "intersect"),
  index_type = c("quadtree", "rtree"),
  result_type = c("rdd", "sdf", "raw")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_range_query_+3A_rdd">rdd</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
<tr><td><code id="sedona_range_query_+3A_x">x</code></td>
<td>
<p>The query object.</p>
</td></tr>
<tr><td><code id="sedona_range_query_+3A_query_type">query_type</code></td>
<td>
<p>Type of spatial relationship involved in the query.
Currently &quot;cover&quot; and &quot;intersect&quot; are supported.</p>
</td></tr>
<tr><td><code id="sedona_range_query_+3A_index_type">index_type</code></td>
<td>
<p>Index to use to facilitate the KNN query. If NULL, then
do not build any additional spatial index on top of <code>x</code>. Supported
index types are &quot;quadtree&quot; and &quot;rtree&quot;.</p>
</td></tr>
<tr><td><code id="sedona_range_query_+3A_result_type">result_type</code></td>
<td>
<p>Type of result to return.
If &quot;rdd&quot; (default), then the k nearest objects will be returned in a Sedona
spatial RDD.
If &quot;sdf&quot;, then a Spark dataframe containing the k nearest objects will be
returned.
If &quot;raw&quot;, then a list of k nearest objects will be returned. Each element
within this list will be a JVM object of type
<code>org.locationtech.jts.geom.Geometry</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The range query result.
</p>


<h3>See Also</h3>

<p>Other Sedona spatial query: 
<code><a href="#topic+sedona_knn_query">sedona_knn_query</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  range_query_min_x &lt;- -87
  range_query_max_x &lt;- -50
  range_query_min_y &lt;- 34
  range_query_max_y &lt;- 54
  geom_factory &lt;- invoke_new(
    sc,
    "org.locationtech.jts.geom.GeometryFactory"
  )
  range_query_polygon &lt;- invoke_new(
    sc,
    "org.locationtech.jts.geom.Envelope",
    range_query_min_x,
    range_query_max_x,
    range_query_min_y,
    range_query_max_y
  ) %&gt;%
    invoke(geom_factory, "toGeometry", .)
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_geojson_to_typed_rdd(
    sc,
    location = input_location,
    type = "polygon"
  )
  range_query_result_sdf &lt;- sedona_range_query(
    rdd,
    x = range_query_polygon,
    query_type = "intersect",
    index_type = "rtree",
    result_type = "sdf"
  )
}

</code></pre>

<hr>
<h2 id='sedona_read_dsv_to_typed_rdd'>Create a typed SpatialRDD from a delimiter-separated values data source.</h2><span id='topic+sedona_read_dsv_to_typed_rdd'></span>

<h3>Description</h3>

<p>Create a typed SpatialRDD (namely, a PointRDD, a PolygonRDD, or a
LineStringRDD) from a data source containing delimiter-separated values.
The data source can contain spatial attributes (e.g., longitude and latidude)
and other attributes. Currently only inputs with spatial attributes occupying
a contiguous range of columns (i.e.,
[first_spatial_col_index, last_spatial_col_index]) are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_read_dsv_to_typed_rdd(
  sc,
  location,
  delimiter = c(",", "\t", "?", "'", "\"", "_", "-", "%", "~", "|", ";"),
  type = c("point", "polygon", "linestring"),
  first_spatial_col_index = 0L,
  last_spatial_col_index = NULL,
  has_non_spatial_attrs = TRUE,
  storage_level = "MEMORY_ONLY",
  repartition = 1L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_sc">sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_location">location</code></td>
<td>
<p>Location of the data source.</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_delimiter">delimiter</code></td>
<td>
<p>Delimiter within each record. Must be one of
',', '\t', '?', '\&rdquo;, '&quot;', '_', '-', '%', '~', '|', ';'</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_type">type</code></td>
<td>
<p>Type of the SpatialRDD (must be one of &quot;point&quot;, &quot;polygon&quot;, or
&quot;linestring&quot;.</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_first_spatial_col_index">first_spatial_col_index</code></td>
<td>
<p>Zero-based index of the left-most column
containing spatial attributes (default: 0).</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_last_spatial_col_index">last_spatial_col_index</code></td>
<td>
<p>Zero-based index of the right-most column
containing spatial attributes (default: NULL). Note last_spatial_col_index
does not need to be specified when creating a PointRDD because it will
automatically have the implied value of (first_spatial_col_index + 1).
For all other types of RDDs, if last_spatial_col_index is unspecified, then
it will assume the value of -1 (i.e., the last of all input columns).</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_has_non_spatial_attrs">has_non_spatial_attrs</code></td>
<td>
<p>Whether the input contains non-spatial
attributes.</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_storage_level">storage_level</code></td>
<td>
<p>Storage level of the RDD (default: MEMORY_ONLY).</p>
</td></tr>
<tr><td><code id="sedona_read_dsv_to_typed_rdd_+3A_repartition">repartition</code></td>
<td>
<p>The minimum number of partitions to have in the resulting
RDD (default: 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A typed SpatialRDD.
</p>


<h3>See Also</h3>

<p>Other Sedona RDD data interface functions: 
<code><a href="#topic+sedona_read_geojson">sedona_read_geojson</a>()</code>,
<code><a href="#topic+sedona_read_shapefile_to_typed_rdd">sedona_read_shapefile_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_save_spatial_rdd">sedona_save_spatial_rdd</a>()</code>,
<code><a href="#topic+sedona_write_wkb">sedona_write_wkb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your csv file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    delimiter = ",",
    type = "point",
    first_spatial_col_index = 1L
  )
}

</code></pre>

<hr>
<h2 id='sedona_read_geojson'>Read geospatial data into a Spatial RDD</h2><span id='topic+sedona_read_geojson'></span><span id='topic+sedona_read_wkb'></span><span id='topic+sedona_read_wkt'></span><span id='topic+sedona_read_shapefile'></span>

<h3>Description</h3>

<p>Import spatial object from an external data source into a Sedona SpatialRDD.
</p>

<ul>
<li> <p><code>sedona_read_shapefile</code>: from a shapefile
</p>
</li>
<li> <p><code>sedona_read_geojson</code>: from a geojson file
</p>
</li>
<li> <p><code>sedona_read_wkt</code>: from a geojson file
</p>
</li>
<li> <p><code>sedona_read_wkb</code>: from a geojson file
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sedona_read_geojson(
  sc,
  location,
  allow_invalid_geometries = TRUE,
  skip_syntactically_invalid_geometries = TRUE,
  storage_level = "MEMORY_ONLY",
  repartition = 1L
)

sedona_read_wkb(
  sc,
  location,
  wkb_col_idx = 0L,
  allow_invalid_geometries = TRUE,
  skip_syntactically_invalid_geometries = TRUE,
  storage_level = "MEMORY_ONLY",
  repartition = 1L
)

sedona_read_wkt(
  sc,
  location,
  wkt_col_idx = 0L,
  allow_invalid_geometries = TRUE,
  skip_syntactically_invalid_geometries = TRUE,
  storage_level = "MEMORY_ONLY",
  repartition = 1L
)

sedona_read_shapefile(sc, location, storage_level = "MEMORY_ONLY")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_read_geojson_+3A_sc">sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_location">location</code></td>
<td>
<p>Location of the data source.</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_allow_invalid_geometries">allow_invalid_geometries</code></td>
<td>
<p>Whether to allow topology-invalid
geometries to exist in the resulting RDD.</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_skip_syntactically_invalid_geometries">skip_syntactically_invalid_geometries</code></td>
<td>
<p>Whether to allows Sedona to
automatically skip syntax-invalid geometries, rather than throwing
errorings.</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_storage_level">storage_level</code></td>
<td>
<p>Storage level of the RDD (default: MEMORY_ONLY).</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_repartition">repartition</code></td>
<td>
<p>The minimum number of partitions to have in the resulting
RDD (default: 1).</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_wkb_col_idx">wkb_col_idx</code></td>
<td>
<p>Zero-based index of column containing hex-encoded WKB data
(default: 0).</p>
</td></tr>
<tr><td><code id="sedona_read_geojson_+3A_wkt_col_idx">wkt_col_idx</code></td>
<td>
<p>Zero-based index of column containing hex-encoded WKB data
(default: 0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A SpatialRDD.
</p>


<h3>See Also</h3>

<p>Other Sedona RDD data interface functions: 
<code><a href="#topic+sedona_read_dsv_to_typed_rdd">sedona_read_dsv_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_read_shapefile_to_typed_rdd">sedona_read_shapefile_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_save_spatial_rdd">sedona_save_spatial_rdd</a>()</code>,
<code><a href="#topic+sedona_write_wkb">sedona_write_wkb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_geojson(sc, location = input_location)
}

</code></pre>

<hr>
<h2 id='sedona_read_shapefile_to_typed_rdd'>(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source.</h2><span id='topic+sedona_read_shapefile_to_typed_rdd'></span><span id='topic+sedona_read_geojson_to_typed_rdd'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p>Constructors of typed RDD (PointRDD, PolygonRDD, LineStringRDD) are soft deprecated, use non-types versions
</p>
<p>Create a typed SpatialRDD (namely, a PointRDD, a PolygonRDD, or a
LineStringRDD)
</p>

<ul>
<li> <p><code>sedona_read_shapefile_to_typed_rdd</code>: from a shapefile data source
</p>
</li>
<li> <p><code>sedona_read_geojson_to_typed_rdd</code>: from a GeoJSON data source
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sedona_read_shapefile_to_typed_rdd(
  sc,
  location,
  type = c("point", "polygon", "linestring"),
  storage_level = "MEMORY_ONLY"
)

sedona_read_geojson_to_typed_rdd(
  sc,
  location,
  type = c("point", "polygon", "linestring"),
  has_non_spatial_attrs = TRUE,
  storage_level = "MEMORY_ONLY",
  repartition = 1L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_read_shapefile_to_typed_rdd_+3A_sc">sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td></tr>
<tr><td><code id="sedona_read_shapefile_to_typed_rdd_+3A_location">location</code></td>
<td>
<p>Location of the data source.</p>
</td></tr>
<tr><td><code id="sedona_read_shapefile_to_typed_rdd_+3A_type">type</code></td>
<td>
<p>Type of the SpatialRDD (must be one of &quot;point&quot;, &quot;polygon&quot;, or
&quot;linestring&quot;.</p>
</td></tr>
<tr><td><code id="sedona_read_shapefile_to_typed_rdd_+3A_storage_level">storage_level</code></td>
<td>
<p>Storage level of the RDD (default: MEMORY_ONLY).</p>
</td></tr>
<tr><td><code id="sedona_read_shapefile_to_typed_rdd_+3A_has_non_spatial_attrs">has_non_spatial_attrs</code></td>
<td>
<p>Whether the input contains non-spatial
attributes.</p>
</td></tr>
<tr><td><code id="sedona_read_shapefile_to_typed_rdd_+3A_repartition">repartition</code></td>
<td>
<p>The minimum number of partitions to have in the resulting
RDD (default: 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A typed SpatialRDD.
</p>


<h3>See Also</h3>

<p>Other Sedona RDD data interface functions: 
<code><a href="#topic+sedona_read_dsv_to_typed_rdd">sedona_read_dsv_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_read_geojson">sedona_read_geojson</a>()</code>,
<code><a href="#topic+sedona_save_spatial_rdd">sedona_save_spatial_rdd</a>()</code>,
<code><a href="#topic+sedona_write_wkb">sedona_write_wkb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your shapefile
  rdd &lt;- sedona_read_shapefile_to_typed_rdd(
    sc,
    location = input_location, type = "polygon"
  )
}

</code></pre>

<hr>
<h2 id='sedona_render_choropleth_map'>Visualize a Sedona spatial RDD using a choropleth map.</h2><span id='topic+sedona_render_choropleth_map'></span>

<h3>Description</h3>

<p>Generate a choropleth map of a pair RDD assigning integral values to
polygons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_render_choropleth_map(
  pair_rdd,
  resolution_x,
  resolution_y,
  output_location,
  output_format = c("png", "gif", "svg"),
  boundary = NULL,
  color_of_variation = c("red", "green", "blue"),
  base_color = c(0, 0, 0),
  shade = TRUE,
  reverse_coords = FALSE,
  overlay = NULL,
  browse = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_render_choropleth_map_+3A_pair_rdd">pair_rdd</code></td>
<td>
<p>A pair RDD with Sedona Polygon objects being keys and
java.lang.Long being values.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_resolution_x">resolution_x</code></td>
<td>
<p>Resolution on the x-axis.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_resolution_y">resolution_y</code></td>
<td>
<p>Resolution on the y-axis.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_output_location">output_location</code></td>
<td>
<p>Location of the output image. This should be the
desired path of the image file excluding extension in its file name.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_output_format">output_format</code></td>
<td>
<p>File format of the output image. Currently &quot;png&quot;,
&quot;gif&quot;, and &quot;svg&quot; formats are supported (default: &quot;png&quot;).</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_boundary">boundary</code></td>
<td>
<p>Only render data within the given rectangular boundary.
The <code>boundary</code> parameter can be set to either a numeric vector of
c(min_x, max_y, min_y, max_y) values, or with a bounding box object
e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), or NULL
(the default). If <code>boundary</code> is NULL, then the minimum bounding box of the
input spatial RDD will be computed and used as boundary for rendering.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_color_of_variation">color_of_variation</code></td>
<td>
<p>Which color channel will vary depending on values
of data points. Must be one of &quot;red&quot;, &quot;green&quot;, or &quot;blue&quot;. Default: red.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_base_color">base_color</code></td>
<td>
<p>Color of any data point with value 0. Must be a numeric
vector of length 3 specifying values for red, green, and blue channels.
Default: c(0, 0, 0).</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_shade">shade</code></td>
<td>
<p>Whether data point with larger magnitude will be displayed with
darker color. Default: TRUE.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_reverse_coords">reverse_coords</code></td>
<td>
<p>Whether to reverse spatial coordinates in the plot
(default: FALSE).</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_overlay">overlay</code></td>
<td>
<p>A <code>viz_op</code> object containing a raster image to be
displayed on top of the resulting image.</p>
</td></tr>
<tr><td><code id="sedona_render_choropleth_map_+3A_browse">browse</code></td>
<td>
<p>Whether to open the rendered image in a browser (default:
interactive()).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>See Also</h3>

<p>Other Sedona visualization routines: 
<code><a href="#topic+sedona_render_heatmap">sedona_render_heatmap</a>()</code>,
<code><a href="#topic+sedona_render_scatter_plot">sedona_render_scatter_plot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  pt_input_location &lt;- "/dev/null" # replace it with the path to your input file
  pt_rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = pt_input_location,
    type = "point",
    first_spatial_col_index = 1
  )
  polygon_input_location &lt;- "/dev/null" # replace it with the path to your input file
  polygon_rdd &lt;- sedona_read_geojson_to_typed_rdd(
    sc,
    location = polygon_input_location,
    type = "polygon"
  )
  join_result_rdd &lt;- sedona_spatial_join_count_by_key(
    pt_rdd,
    polygon_rdd,
    join_type = "intersect",
    partitioner = "quadtree"
  )
  sedona_render_choropleth_map(
    join_result_rdd,
    400,
    200,
    output_location = tempfile("choropleth-map-"),
    boundary = c(-86.8, -86.6, 33.4, 33.6),
    base_color = c(255, 255, 255)
  )
}

</code></pre>

<hr>
<h2 id='sedona_render_heatmap'>Visualize a Sedona spatial RDD using a heatmap.</h2><span id='topic+sedona_render_heatmap'></span>

<h3>Description</h3>

<p>Generate a heatmap of geometrical object(s) within a Sedona spatial RDD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_render_heatmap(
  rdd,
  resolution_x,
  resolution_y,
  output_location,
  output_format = c("png", "gif", "svg"),
  boundary = NULL,
  blur_radius = 10L,
  overlay = NULL,
  browse = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_render_heatmap_+3A_rdd">rdd</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_resolution_x">resolution_x</code></td>
<td>
<p>Resolution on the x-axis.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_resolution_y">resolution_y</code></td>
<td>
<p>Resolution on the y-axis.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_output_location">output_location</code></td>
<td>
<p>Location of the output image. This should be the
desired path of the image file excluding extension in its file name.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_output_format">output_format</code></td>
<td>
<p>File format of the output image. Currently &quot;png&quot;,
&quot;gif&quot;, and &quot;svg&quot; formats are supported (default: &quot;png&quot;).</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_boundary">boundary</code></td>
<td>
<p>Only render data within the given rectangular boundary.
The <code>boundary</code> parameter can be set to either a numeric vector of
c(min_x, max_y, min_y, max_y) values, or with a bounding box object
e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), or NULL
(the default). If <code>boundary</code> is NULL, then the minimum bounding box of the
input spatial RDD will be computed and used as boundary for rendering.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_blur_radius">blur_radius</code></td>
<td>
<p>Controls the radius of a Gaussian blur in the resulting
heatmap.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_overlay">overlay</code></td>
<td>
<p>A <code>viz_op</code> object containing a raster image to be
displayed on top of the resulting image.</p>
</td></tr>
<tr><td><code id="sedona_render_heatmap_+3A_browse">browse</code></td>
<td>
<p>Whether to open the rendered image in a browser (default:
interactive()).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>See Also</h3>

<p>Other Sedona visualization routines: 
<code><a href="#topic+sedona_render_choropleth_map">sedona_render_choropleth_map</a>()</code>,
<code><a href="#topic+sedona_render_scatter_plot">sedona_render_scatter_plot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    type = "point"
  )

  sedona_render_heatmap(
    rdd,
    resolution_x = 800,
    resolution_y = 600,
    output_location = tempfile("points-"),
    output_format = "png",
    boundary = c(-91, -84, 30, 35),
    blur_radius = 10
  )
}

</code></pre>

<hr>
<h2 id='sedona_render_scatter_plot'>Visualize a Sedona spatial RDD using a scatter plot.</h2><span id='topic+sedona_render_scatter_plot'></span>

<h3>Description</h3>

<p>Generate a scatter plot of geometrical object(s) within a Sedona spatial RDD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_render_scatter_plot(
  rdd,
  resolution_x,
  resolution_y,
  output_location,
  output_format = c("png", "gif", "svg"),
  boundary = NULL,
  color_of_variation = c("red", "green", "blue"),
  base_color = c(0, 0, 0),
  shade = TRUE,
  reverse_coords = FALSE,
  overlay = NULL,
  browse = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_render_scatter_plot_+3A_rdd">rdd</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_resolution_x">resolution_x</code></td>
<td>
<p>Resolution on the x-axis.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_resolution_y">resolution_y</code></td>
<td>
<p>Resolution on the y-axis.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_output_location">output_location</code></td>
<td>
<p>Location of the output image. This should be the
desired path of the image file excluding extension in its file name.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_output_format">output_format</code></td>
<td>
<p>File format of the output image. Currently &quot;png&quot;,
&quot;gif&quot;, and &quot;svg&quot; formats are supported (default: &quot;png&quot;).</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_boundary">boundary</code></td>
<td>
<p>Only render data within the given rectangular boundary.
The <code>boundary</code> parameter can be set to either a numeric vector of
c(min_x, max_y, min_y, max_y) values, or with a bounding box object
e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), or NULL
(the default). If <code>boundary</code> is NULL, then the minimum bounding box of the
input spatial RDD will be computed and used as boundary for rendering.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_color_of_variation">color_of_variation</code></td>
<td>
<p>Which color channel will vary depending on values
of data points. Must be one of &quot;red&quot;, &quot;green&quot;, or &quot;blue&quot;. Default: red.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_base_color">base_color</code></td>
<td>
<p>Color of any data point with value 0. Must be a numeric
vector of length 3 specifying values for red, green, and blue channels.
Default: c(0, 0, 0).</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_shade">shade</code></td>
<td>
<p>Whether data point with larger magnitude will be displayed with
darker color. Default: TRUE.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_reverse_coords">reverse_coords</code></td>
<td>
<p>Whether to reverse spatial coordinates in the plot
(default: FALSE).</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_overlay">overlay</code></td>
<td>
<p>A <code>viz_op</code> object containing a raster image to be
displayed on top of the resulting image.</p>
</td></tr>
<tr><td><code id="sedona_render_scatter_plot_+3A_browse">browse</code></td>
<td>
<p>Whether to open the rendered image in a browser (default:
interactive()).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>See Also</h3>

<p>Other Sedona visualization routines: 
<code><a href="#topic+sedona_render_choropleth_map">sedona_render_choropleth_map</a>()</code>,
<code><a href="#topic+sedona_render_heatmap">sedona_render_heatmap</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    type = "point"
  )

  sedona_render_scatter_plot(
    rdd,
    resolution_x = 800,
    resolution_y = 600,
    output_location = tempfile("points-"),
    output_format = "png",
    boundary = c(-91, -84, 30, 35)
  )
}

</code></pre>

<hr>
<h2 id='sedona_save_spatial_rdd'>Save a Spark dataframe containing exactly 1 spatial column into a file.</h2><span id='topic+sedona_save_spatial_rdd'></span>

<h3>Description</h3>

<p>Export serialized data from a Spark dataframe containing exactly 1 spatial
column into a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_save_spatial_rdd(
  x,
  spatial_col,
  output_location,
  output_format = c("wkb", "wkt", "geojson")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_save_spatial_rdd_+3A_x">x</code></td>
<td>
<p>A Spark dataframe object in sparklyr or a dplyr expression
representing a Spark SQL query.</p>
</td></tr>
<tr><td><code id="sedona_save_spatial_rdd_+3A_spatial_col">spatial_col</code></td>
<td>
<p>The name of the spatial column.</p>
</td></tr>
<tr><td><code id="sedona_save_spatial_rdd_+3A_output_location">output_location</code></td>
<td>
<p>Location of the output file.</p>
</td></tr>
<tr><td><code id="sedona_save_spatial_rdd_+3A_output_format">output_format</code></td>
<td>
<p>Format of the output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>See Also</h3>

<p>Other Sedona RDD data interface functions: 
<code><a href="#topic+sedona_read_dsv_to_typed_rdd">sedona_read_dsv_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_read_geojson">sedona_read_geojson</a>()</code>,
<code><a href="#topic+sedona_read_shapefile_to_typed_rdd">sedona_read_shapefile_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_write_wkb">sedona_write_wkb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  tbl &lt;- dplyr::tbl(
    sc,
    dplyr::sql("SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`")
  )
  sedona_save_spatial_rdd(
    tbl %&gt;% dplyr::mutate(id = 1),
    spatial_col = "pt",
    output_location = "/tmp/pts.wkb",
    output_format = "wkb"
  )
}

</code></pre>

<hr>
<h2 id='sedona_spatial_join'>Perform a spatial join operation on two Sedona spatial RDDs.</h2><span id='topic+sedona_spatial_join'></span>

<h3>Description</h3>

<p>Given <code>spatial_rdd</code> and <code>query_window_rdd</code>, return a pair RDD containing all
pairs of geometrical elements (p, q) such that p is an element of
<code>spatial_rdd</code>, q is an element of <code>query_window_rdd</code>, and (p, q) satisfies
the spatial relation specified by <code>join_type</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_spatial_join(
  spatial_rdd,
  query_window_rdd,
  join_type = c("contain", "intersect"),
  partitioner = c("quadtree", "kdbtree"),
  index_type = c("quadtree", "rtree")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_spatial_join_+3A_spatial_rdd">spatial_rdd</code></td>
<td>
<p>Spatial RDD containing geometries to be queried.</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_+3A_query_window_rdd">query_window_rdd</code></td>
<td>
<p>Spatial RDD containing the query window(s).</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_+3A_join_type">join_type</code></td>
<td>
<p>Type of the join query (must be either &quot;contain&quot; or
&quot;intersect&quot;).
If <code>join_type</code> is &quot;contain&quot;, then a geometry from <code>spatial_rdd</code> will match
a geometry from the <code>query_window_rdd</code> if and only if the former is fully
contained in the latter.
If <code>join_type</code> is &quot;intersect&quot;, then a geometry from <code>spatial_rdd</code> will
match a geometry from the <code>query_window_rdd</code> if and only if the former
intersects the latter.</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_+3A_partitioner">partitioner</code></td>
<td>
<p>Spatial partitioning to apply to both <code>spatial_rdd</code> and
<code>query_window_rdd</code> to facilitate the join query. Can be either a grid type
(currently &quot;quadtree&quot; and &quot;kdbtree&quot; are supported) or a custom spatial
partitioner object. If <code>partitioner</code> is NULL, then assume the same spatial
partitioner has been applied to both <code>spatial_rdd</code> and <code>query_window_rdd</code>
already and skip the partitioning step.</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_+3A_index_type">index_type</code></td>
<td>
<p>Controls how <code>spatial_rdd</code> and <code>query_window_rdd</code> will be
indexed (unless they are indexed already). If &quot;NONE&quot;, then no index will be
constructed and matching geometries will be identified in a doubly nested-
loop iterating through all possible pairs of elements from <code>spatial_rdd</code>
and <code>query_window_rdd</code>, which will be inefficient for large data sets.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A spatial RDD containing the join result.
</p>


<h3>See Also</h3>

<p>Other Sedona spatial join operator: 
<code><a href="#topic+sedona_spatial_join_count_by_key">sedona_spatial_join_count_by_key</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    delimiter = ",",
    type = "point",
    first_spatial_col_index = 1L
  )
  query_rdd_input_location &lt;- "/dev/null" # replace it with the path to your input file
  query_rdd &lt;- sedona_read_shapefile_to_typed_rdd(
    sc,
    location = query_rdd_input_location,
    type = "polygon"
  )
  join_result_rdd &lt;- sedona_spatial_join(
    rdd,
    query_rdd,
    join_type = "intersect",
    partitioner = "quadtree"
  )
}
</code></pre>

<hr>
<h2 id='sedona_spatial_join_count_by_key'>Perform a spatial count-by-key operation based on two Sedona spatial RDDs.</h2><span id='topic+sedona_spatial_join_count_by_key'></span>

<h3>Description</h3>

<p>For each element p from <code>spatial_rdd</code>, count the number of unique elements q
from <code>query_window_rdd</code> such that (p, q) satisfies the spatial relation
specified by <code>join_type</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sedona_spatial_join_count_by_key(
  spatial_rdd,
  query_window_rdd,
  join_type = c("contain", "intersect"),
  partitioner = c("quadtree", "kdbtree"),
  index_type = c("quadtree", "rtree")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_spatial_join_count_by_key_+3A_spatial_rdd">spatial_rdd</code></td>
<td>
<p>Spatial RDD containing geometries to be queried.</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_count_by_key_+3A_query_window_rdd">query_window_rdd</code></td>
<td>
<p>Spatial RDD containing the query window(s).</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_count_by_key_+3A_join_type">join_type</code></td>
<td>
<p>Type of the join query (must be either &quot;contain&quot; or
&quot;intersect&quot;).
If <code>join_type</code> is &quot;contain&quot;, then a geometry from <code>spatial_rdd</code> will match
a geometry from the <code>query_window_rdd</code> if and only if the former is fully
contained in the latter.
If <code>join_type</code> is &quot;intersect&quot;, then a geometry from <code>spatial_rdd</code> will
match a geometry from the <code>query_window_rdd</code> if and only if the former
intersects the latter.</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_count_by_key_+3A_partitioner">partitioner</code></td>
<td>
<p>Spatial partitioning to apply to both <code>spatial_rdd</code> and
<code>query_window_rdd</code> to facilitate the join query. Can be either a grid type
(currently &quot;quadtree&quot; and &quot;kdbtree&quot; are supported) or a custom spatial
partitioner object. If <code>partitioner</code> is NULL, then assume the same spatial
partitioner has been applied to both <code>spatial_rdd</code> and <code>query_window_rdd</code>
already and skip the partitioning step.</p>
</td></tr>
<tr><td><code id="sedona_spatial_join_count_by_key_+3A_index_type">index_type</code></td>
<td>
<p>Controls how <code>spatial_rdd</code> and <code>query_window_rdd</code> will be
indexed (unless they are indexed already). If &quot;NONE&quot;, then no index will be
constructed and matching geometries will be identified in a doubly nested-
loop iterating through all possible pairs of elements from <code>spatial_rdd</code>
and <code>query_window_rdd</code>, which will be inefficient for large data sets.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A spatial RDD containing the join-count-by-key results.
</p>


<h3>See Also</h3>

<p>Other Sedona spatial join operator: 
<code><a href="#topic+sedona_spatial_join">sedona_spatial_join</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_dsv_to_typed_rdd(
    sc,
    location = input_location,
    delimiter = ",",
    type = "point",
    first_spatial_col_index = 1L
  )
  query_rdd_input_location &lt;- "/dev/null" # replace it with the path to your input file
  query_rdd &lt;- sedona_read_shapefile_to_typed_rdd(
    sc,
    location = query_rdd_input_location,
    type = "polygon"
  )
  join_result_rdd &lt;- sedona_spatial_join_count_by_key(
    rdd,
    query_rdd,
    join_type = "intersect",
    partitioner = "quadtree"
  )
}
</code></pre>

<hr>
<h2 id='sedona_spatial_rdd_aggregation_routine'>Spatial RDD aggregation routine</h2><span id='topic+sedona_spatial_rdd_aggregation_routine'></span>

<h3>Description</h3>

<p>Function extracting aggregate statistics from a Sedona spatial RDD.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_spatial_rdd_aggregation_routine_+3A_x">x</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
</table>

<hr>
<h2 id='sedona_spatial_rdd_data_source'>Create a SpatialRDD from an external data source.</h2><span id='topic+sedona_spatial_rdd_data_source'></span>

<h3>Description</h3>

<p>Import spatial object from an external data source into a Sedona SpatialRDD.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_spatial_rdd_data_source_+3A_sc">sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td></tr>
<tr><td><code id="sedona_spatial_rdd_data_source_+3A_location">location</code></td>
<td>
<p>Location of the data source.</p>
</td></tr>
<tr><td><code id="sedona_spatial_rdd_data_source_+3A_type">type</code></td>
<td>
<p>Type of the SpatialRDD (must be one of &quot;point&quot;, &quot;polygon&quot;, or
&quot;linestring&quot;.</p>
</td></tr>
<tr><td><code id="sedona_spatial_rdd_data_source_+3A_has_non_spatial_attrs">has_non_spatial_attrs</code></td>
<td>
<p>Whether the input contains non-spatial
attributes.</p>
</td></tr>
<tr><td><code id="sedona_spatial_rdd_data_source_+3A_storage_level">storage_level</code></td>
<td>
<p>Storage level of the RDD (default: MEMORY_ONLY).</p>
</td></tr>
<tr><td><code id="sedona_spatial_rdd_data_source_+3A_repartition">repartition</code></td>
<td>
<p>The minimum number of partitions to have in the resulting
RDD (default: 1).</p>
</td></tr>
</table>

<hr>
<h2 id='sedona_visualization_routines'>Visualization routine for Sedona spatial RDD.</h2><span id='topic+sedona_visualization_routines'></span>

<h3>Description</h3>

<p>Generate a visual representation of geometrical object(s) within a Sedona
spatial RDD.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_visualization_routines_+3A_rdd">rdd</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_resolution_x">resolution_x</code></td>
<td>
<p>Resolution on the x-axis.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_resolution_y">resolution_y</code></td>
<td>
<p>Resolution on the y-axis.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_output_location">output_location</code></td>
<td>
<p>Location of the output image. This should be the
desired path of the image file excluding extension in its file name.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_output_format">output_format</code></td>
<td>
<p>File format of the output image. Currently &quot;png&quot;,
&quot;gif&quot;, and &quot;svg&quot; formats are supported (default: &quot;png&quot;).</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_boundary">boundary</code></td>
<td>
<p>Only render data within the given rectangular boundary.
The <code>boundary</code> parameter can be set to either a numeric vector of
c(min_x, max_y, min_y, max_y) values, or with a bounding box object
e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), or NULL
(the default). If <code>boundary</code> is NULL, then the minimum bounding box of the
input spatial RDD will be computed and used as boundary for rendering.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_color_of_variation">color_of_variation</code></td>
<td>
<p>Which color channel will vary depending on values
of data points. Must be one of &quot;red&quot;, &quot;green&quot;, or &quot;blue&quot;. Default: red.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_base_color">base_color</code></td>
<td>
<p>Color of any data point with value 0. Must be a numeric
vector of length 3 specifying values for red, green, and blue channels.
Default: c(0, 0, 0).</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_shade">shade</code></td>
<td>
<p>Whether data point with larger magnitude will be displayed with
darker color. Default: TRUE.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_overlay">overlay</code></td>
<td>
<p>A <code>viz_op</code> object containing a raster image to be
displayed on top of the resulting image.</p>
</td></tr>
<tr><td><code id="sedona_visualization_routines_+3A_browse">browse</code></td>
<td>
<p>Whether to open the rendered image in a browser (default:
interactive()).</p>
</td></tr>
</table>

<hr>
<h2 id='sedona_write_wkb'>Write SpatialRDD into a file.</h2><span id='topic+sedona_write_wkb'></span><span id='topic+sedona_write_wkt'></span><span id='topic+sedona_write_geojson'></span>

<h3>Description</h3>

<p>Export serialized data from a Sedona SpatialRDD into a file.
</p>

<ul>
<li> <p><code>sedona_write_wkb</code>:
</p>
</li>
<li> <p><code>sedona_write_wkt</code>:
</p>
</li>
<li> <p><code>sedona_write_geojson</code>:
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sedona_write_wkb(x, output_location)

sedona_write_wkt(x, output_location)

sedona_write_geojson(x, output_location)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sedona_write_wkb_+3A_x">x</code></td>
<td>
<p>The SpatialRDD object.</p>
</td></tr>
<tr><td><code id="sedona_write_wkb_+3A_output_location">output_location</code></td>
<td>
<p>Location of the output file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>


<h3>See Also</h3>

<p>Other Sedona RDD data interface functions: 
<code><a href="#topic+sedona_read_dsv_to_typed_rdd">sedona_read_dsv_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_read_geojson">sedona_read_geojson</a>()</code>,
<code><a href="#topic+sedona_read_shapefile_to_typed_rdd">sedona_read_shapefile_to_typed_rdd</a>()</code>,
<code><a href="#topic+sedona_save_spatial_rdd">sedona_save_spatial_rdd</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- sedona_read_wkb(
    sc,
    location = input_location,
    wkb_col_idx = 0L
  )
  sedona_write_wkb(rdd, "/tmp/wkb_output.tsv")
}

</code></pre>

<hr>
<h2 id='spark_read_shapefile'>Read geospatial data into a Spark DataFrame.</h2><span id='topic+spark_read_shapefile'></span><span id='topic+spark_read_geojson'></span><span id='topic+spark_read_geoparquet'></span>

<h3>Description</h3>

<p>Functions to read geospatial data from a variety of formats into Spark DataFrames.
</p>

<ul>
<li> <p><code>spark_read_shapefile</code>: from a shapefile
</p>
</li>
<li> <p><code>spark_read_geojson</code>: from a geojson file
</p>
</li>
<li> <p><code>spark_read_geoparquet</code>: from a geoparquet file
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>spark_read_shapefile(sc, name = NULL, path = name, options = list(), ...)

spark_read_geojson(
  sc,
  name = NULL,
  path = name,
  options = list(),
  repartition = 0,
  memory = TRUE,
  overwrite = TRUE
)

spark_read_geoparquet(
  sc,
  name = NULL,
  path = name,
  options = list(),
  repartition = 0,
  memory = TRUE,
  overwrite = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spark_read_shapefile_+3A_sc">sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_name">name</code></td>
<td>
<p>The name to assign to the newly generated table.</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_path">path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the &lsquo;<span class="samp">&#8288;"hdfs://"&#8288;</span>&rsquo;, &lsquo;<span class="samp">&#8288;"s3a://"&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;"file://"&#8288;</span>&rsquo; protocols.</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_options">options</code></td>
<td>
<p>A list of strings with additional options. See <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</a>.</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_...">...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_repartition">repartition</code></td>
<td>
<p>The number of partitions used to distribute the
generated table. Use 0 (the default) to avoid partitioning.</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_memory">memory</code></td>
<td>
<p>Boolean; should the data be loaded eagerly into memory? (That
is, should the table be cached?)</p>
</td></tr>
<tr><td><code id="spark_read_shapefile_+3A_overwrite">overwrite</code></td>
<td>
<p>Boolean; overwrite the table with the given name if it
already exists?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tbl
</p>


<h3>See Also</h3>

<p>Other Sedona DF data interface functions: 
<code><a href="#topic+spark_write_geojson">spark_write_geojson</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  input_location &lt;- "/dev/null" # replace it with the path to your input file
  rdd &lt;- spark_read_shapefile(sc, location = input_location)
}

</code></pre>

<hr>
<h2 id='spark_write_geojson'>Write geospatial data from a Spark DataFrame.</h2><span id='topic+spark_write_geojson'></span><span id='topic+spark_write_geoparquet'></span><span id='topic+spark_write_raster'></span>

<h3>Description</h3>

<p>Functions to write geospatial data into a variety of formats from Spark DataFrames.
</p>

<ul>
<li> <p><code>spark_write_geojson</code>: to GeoJSON
</p>
</li>
<li> <p><code>spark_write_geoparquet</code>: to GeoParquet
</p>
</li>
<li> <p><code>spark_write_raster</code>: to raster tiles after using RS output functions (<code>RS_AsXXX</code>)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>spark_write_geojson(
  x,
  path,
  mode = NULL,
  options = list(),
  partition_by = NULL,
  ...
)

spark_write_geoparquet(
  x,
  path,
  mode = NULL,
  options = list(),
  partition_by = NULL,
  ...
)

spark_write_raster(
  x,
  path,
  mode = NULL,
  options = list(),
  partition_by = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spark_write_geojson_+3A_x">x</code></td>
<td>
<p>A Spark DataFrame or dplyr operation</p>
</td></tr>
<tr><td><code id="spark_write_geojson_+3A_path">path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the &lsquo;<span class="samp">&#8288;"hdfs://"&#8288;</span>&rsquo;, &lsquo;<span class="samp">&#8288;"s3a://"&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;"file://"&#8288;</span>&rsquo; protocols.</p>
</td></tr>
<tr><td><code id="spark_write_geojson_+3A_mode">mode</code></td>
<td>
<p>A <code>character</code> element. Specifies the behavior when data or
table already exists. Supported values include: 'error', 'append', 'overwrite' and
ignore. Notice that 'overwrite' will also change the column structure.
</p>
<p>For more details see also <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</a>
for your version of Spark.</p>
</td></tr>
<tr><td><code id="spark_write_geojson_+3A_options">options</code></td>
<td>
<p>A list of strings with additional options.</p>
</td></tr>
<tr><td><code id="spark_write_geojson_+3A_partition_by">partition_by</code></td>
<td>
<p>A <code>character</code> vector. Partitions the output by the given columns on the file system.</p>
</td></tr>
<tr><td><code id="spark_write_geojson_+3A_...">...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Sedona DF data interface functions: 
<code><a href="#topic+spark_read_shapefile">spark_read_shapefile</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  tbl &lt;- dplyr::tbl(
    sc,
    dplyr::sql("SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`")
  )
  spark_write_geojson(
    tbl %&gt;% dplyr::mutate(id = 1),
    output_location = "/tmp/pts.geojson"
  )
}

</code></pre>

<hr>
<h2 id='spatial_join_op'>Spatial join operator</h2><span id='topic+spatial_join_op'></span>

<h3>Description</h3>

<p>R interface for a Sedona spatial join operator
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatial_join_op_+3A_spatial_rdd">spatial_rdd</code></td>
<td>
<p>Spatial RDD containing geometries to be queried.</p>
</td></tr>
<tr><td><code id="spatial_join_op_+3A_query_window_rdd">query_window_rdd</code></td>
<td>
<p>Spatial RDD containing the query window(s).</p>
</td></tr>
<tr><td><code id="spatial_join_op_+3A_join_type">join_type</code></td>
<td>
<p>Type of the join query (must be either &quot;contain&quot; or
&quot;intersect&quot;).
If <code>join_type</code> is &quot;contain&quot;, then a geometry from <code>spatial_rdd</code> will match
a geometry from the <code>query_window_rdd</code> if and only if the former is fully
contained in the latter.
If <code>join_type</code> is &quot;intersect&quot;, then a geometry from <code>spatial_rdd</code> will
match a geometry from the <code>query_window_rdd</code> if and only if the former
intersects the latter.</p>
</td></tr>
<tr><td><code id="spatial_join_op_+3A_partitioner">partitioner</code></td>
<td>
<p>Spatial partitioning to apply to both <code>spatial_rdd</code> and
<code>query_window_rdd</code> to facilitate the join query. Can be either a grid type
(currently &quot;quadtree&quot; and &quot;kdbtree&quot; are supported) or a custom spatial
partitioner object. If <code>partitioner</code> is NULL, then assume the same spatial
partitioner has been applied to both <code>spatial_rdd</code> and <code>query_window_rdd</code>
already and skip the partitioning step.</p>
</td></tr>
<tr><td><code id="spatial_join_op_+3A_index_type">index_type</code></td>
<td>
<p>Controls how <code>spatial_rdd</code> and <code>query_window_rdd</code> will be
indexed (unless they are indexed already). If &quot;NONE&quot;, then no index will be
constructed and matching geometries will be identified in a doubly nested-
loop iterating through all possible pairs of elements from <code>spatial_rdd</code>
and <code>query_window_rdd</code>, which will be inefficient for large data sets.</p>
</td></tr>
</table>

<hr>
<h2 id='spatial_query'>Execute a spatial query</h2><span id='topic+spatial_query'></span>

<h3>Description</h3>

<p>Given a spatial RDD, run a spatial query parameterized by a spatial object
<code>x</code>.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatial_query_+3A_rdd">rdd</code></td>
<td>
<p>A Sedona spatial RDD.</p>
</td></tr>
<tr><td><code id="spatial_query_+3A_x">x</code></td>
<td>
<p>The query object.</p>
</td></tr>
<tr><td><code id="spatial_query_+3A_index_type">index_type</code></td>
<td>
<p>Index to use to facilitate the KNN query. If NULL, then
do not build any additional spatial index on top of <code>x</code>. Supported
index types are &quot;quadtree&quot; and &quot;rtree&quot;.</p>
</td></tr>
<tr><td><code id="spatial_query_+3A_result_type">result_type</code></td>
<td>
<p>Type of result to return.
If &quot;rdd&quot; (default), then the k nearest objects will be returned in a Sedona
spatial RDD.
If &quot;sdf&quot;, then a Spark dataframe containing the k nearest objects will be
returned.
If &quot;raw&quot;, then a list of k nearest objects will be returned. Each element
within this list will be a JVM object of type
<code>org.locationtech.jts.geom.Geometry</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='to_spatial_rdd'>Export a Spark SQL query with a spatial column into a Sedona spatial RDD.</h2><span id='topic+to_spatial_rdd'></span>

<h3>Description</h3>

<p>Given a Spark dataframe object or a dplyr expression encapsulating a Spark
SQL query, build a Sedona spatial RDD that will encapsulate the same query or
data source. The input should contain exactly one spatial column and all
other non-spatial columns will be treated as custom user-defined attributes
in the resulting spatial RDD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_spatial_rdd(x, spatial_col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_spatial_rdd_+3A_x">x</code></td>
<td>
<p>A Spark dataframe object in sparklyr or a dplyr expression
representing a Spark SQL query.</p>
</td></tr>
<tr><td><code id="to_spatial_rdd_+3A_spatial_col">spatial_col</code></td>
<td>
<p>The name of the spatial column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A SpatialRDD encapsulating the query.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  tbl &lt;- dplyr::tbl(
    sc,
    dplyr::sql("SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`")
  )
  rdd &lt;- to_spatial_rdd(tbl, "pt")
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
