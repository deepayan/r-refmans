<!DOCTYPE html><html><head><title>Help for package igate</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {igate}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#categorical.freqplot'><p>Produces frequency plots (normed to density plots to account for</p>
different category sizes) for sanity check in categorical iGATE.</a></li>
<li><a href='#categorical.igate'><p>igate function for categorical target variables</p></a></li>
<li><a href='#counting.test'><p>Performs the counting test</p></a></li>
<li><a href='#igate'><p>igate function for continuous target variables</p></a></li>
<li><a href='#igate.regressions'><p>Produces the regression plots for sanity check in iGATE</p></a></li>
<li><a href='#report'><p>Generates report about a conducted igate.</p></a></li>
<li><a href='#resultsIris'><p>Example results data file to be used for example report generation.</p></a></li>
<li><a href='#robust.categorical.igate'><p>Robust igate for categorical target variables</p></a></li>
<li><a href='#validate'><p>Validates results after using <code>igate</code> or <code>categorical.igate</code>.</p></a></li>
<li><a href='#validatedObsIris'><p>validatedObsIris data set</p></a></li>
<li><a href='#validationCountsIris'><p>validationCountsIris data set</p></a></li>
<li><a href='#validationSummaryIris'><p>validationSummaryIris data set</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Guided Analytics for Testing Manufacturing Parameters</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.3</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of the initial guided analytics for parameter testing and
    controlband extraction framework. Functions are available for continuous and 
    categorical target variables as well as for generating standardized reports of the
    conducted analysis. See <a href="https://github.com/stefan-stein/igate">https://github.com/stefan-stein/igate</a> for more information
    on the technology.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/stefan-stein/igate">https://github.com/stefan-stein/igate</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/stefan-stein/igate/issues">https://github.com/stefan-stein/igate/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>pandoc (&gt;= 1.12.3) - http://pandoc.org</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, dplyr, grDevices, stringr, graphics, stats, knitr,
xtable, kableExtra, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-10 08:30:57 UTC; stefanstein</td>
</tr>
<tr>
<td>Author:</td>
<td>Stefan Stein [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Stefan Stein &lt;s.stein@warwick.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-10 22:50:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='categorical.freqplot'>Produces frequency plots (normed to density plots to account for
different category sizes) for sanity check in categorical iGATE.</h2><span id='topic+categorical.freqplot'></span>

<h3>Description</h3>

<p>This function takes a data frame, a categorical target variable and a list of ssv and
produces a density plot of each ssv and each category of the target variable. The output is written as
.png file into the current working directory. Also, summary statistics are provided.
The files can be saved into the current working directory. Consider changing the
working directory to a new empty folder before running if you want to save a copy of the plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorical.freqplot(df, target, ssv = NULL,
  outlier_removal_ssv = TRUE, savePlots = FALSE,
  image_directory = tempdir())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categorical.freqplot_+3A_df">df</code></td>
<td>
<p>Data frame to be analysed.</p>
</td></tr>
<tr><td><code id="categorical.freqplot_+3A_target">target</code></td>
<td>
<p>Categorical target varaible to be analysed.</p>
</td></tr>
<tr><td><code id="categorical.freqplot_+3A_ssv">ssv</code></td>
<td>
<p>A vector of suspected sources of variation. These are the variables
in <code>df</code> which we believe might have an influence on the target variable and
will be tested. If no list of ssv is provided, the test will be performed
on all numeric variables.</p>
</td></tr>
<tr><td><code id="categorical.freqplot_+3A_outlier_removal_ssv">outlier_removal_ssv</code></td>
<td>
<p>Logical. Should outlier removal be performed for each ssv (default: <code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="categorical.freqplot_+3A_saveplots">savePlots</code></td>
<td>
<p>Logical. If <code>FALSE</code> (the default) frequency plots will be output to the standard plotting
device. If <code>TRUE</code>, frequency plots will be saved to <code>image_directory</code> as png files.</p>
</td></tr>
<tr><td><code id="categorical.freqplot_+3A_image_directory">image_directory</code></td>
<td>
<p>Directory to which plots should be saved. This is only used if <code>savePlots = TRUE</code> and
defaults to the temporary directory of the current R session, i.e. <code>tempdir()</code>. To save plots to the current
working directory set <code>savePlots = TRUE</code> and <code>image_directory = getwd()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Frequency plots for each <code>ssv</code> against  each category of the <code>target</code> are produced and
svaed to current working directory. Also a data frame with summary statistics is produced,
see <b>Value</b> for details.
</p>


<h3>Value</h3>

<p>The density plots of each category of <code>target</code> against each <code>ssv</code> are written as
.png file into the current working directory. Also, a data frame with the following
columns is output
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Causes</code> </td><td style="text-align: left;"> The <code>ssv</code> that were analysed.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>outliers_removed</code> </td><td style="text-align: left;"> How many outliers (with respect to this <code>ssv</code>)
have been removed before drawing the plot?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>observations_retained</code> </td><td style="text-align: left;"> After outlier removal was performed, how many observations
were left and used to fit the model?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>frequency_plot</code> </td><td style="text-align: left;"> Logical. Was plotting successful? No plot will be
produced if a ssv is constant.
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>categorical.freqplot(mtcars, target = "cyl")

</code></pre>

<hr>
<h2 id='categorical.igate'>igate function for categorical target variables</h2><span id='topic+categorical.igate'></span>

<h3>Description</h3>

<p>This function performs an initial Guided Analysis for parameter testing and controlband extraction (iGATE) for
a categorical target variable on a dataset and returns those parameters found to be influential.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorical.igate(df, versus = 8, target, best.cat, worst.cat,
  test = "w", ssv = NULL, outlier_removal_ssv = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categorical.igate_+3A_df">df</code></td>
<td>
<p>Data frame to be analysed.</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_versus">versus</code></td>
<td>
<p>How many Best of the Best and Worst of the Worst do we collect? By default, we will collect 8 of each.</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_target">target</code></td>
<td>
<p>Target variable to be analysed. Must be categorical.
Use <code><a href="#topic+igate">igate</a></code> for continuous <code>target</code>.</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_best.cat">best.cat</code></td>
<td>
<p>The best category. The <code>versus</code> BOB will be selected randomly from this
category.</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_worst.cat">worst.cat</code></td>
<td>
<p>The worst category. The <code>versus</code> WOW will be selected randomly from this
category.</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_test">test</code></td>
<td>
<p>Statistical hypothesis test to be used to determine influential
process parameters. Choose between Wilcoxon Rank test (<code>"w"</code>, default)
and Student's t-test (<code>"t"</code>).</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_ssv">ssv</code></td>
<td>
<p>A vector of suspected sources of variation. These are the variables
in <code>df</code> which we believe might have an influence on the <code>target</code> variable and
will be tested. If no list of <code>ssv</code> is provided, the test will be performed
on all numeric variables.</p>
</td></tr>
<tr><td><code id="categorical.igate_+3A_outlier_removal_ssv">outlier_removal_ssv</code></td>
<td>
<p>Logical. Should outlier removal be performed for each <code>ssv</code> (default: <code>TRUE</code>)?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We collect the Best of the Best and the Worst of the Worst
dynamically dependent on the current <code>ssv</code>. That means, for each <code>ssv</code> we first
remove all the observations with missing values for that <code>ssv</code> from <code>df</code>.
Then, based on the remaining observations, we randomly select <code>versus</code>
observations from the the best category (“Best of the Best”, short BOB)  and
<code>versus</code> observations from the worst category
(“Worst of the Worst”, short WOW). By default, we select 8 of each.
Next, we compare BOB and WOW using the the counting method and the specified
hypothesis test. If the distributions of the <code>ssv</code> in BOB and WOW are
significantly different, the current <code>ssv</code> has been identified as influential
to the <code>target</code> variable. An <code>ssv</code> is considered influential, if the test returns
a count larger/ equal to 6 and/ or a p-value of less than 0.05.
For the next <code>ssv</code> we again start with the entire dataset <code>df</code>, remove all
the observations with missing values for that new <code>ssv</code> and then select our
new BOB and WOW. In particular, for each <code>ssv</code> we might select different observations.
This dynamic selection is necessary, because in case of an incomplete data set,
if we select the same BOB and WOW for all the <code>ssv</code>, we might end up with many
missing values for particular <code>ssv</code>. In that case the hypothesis test loses
statistical power, because it is used on a smaller sample or worse, might
fail altogether if the sample size gets too small.
</p>
<p>For those <code>ssv</code> determined to be significant, control bands are extracted. The rationale is:
If the value for an <code>ssv</code> is in the interval [<code>good_lower_bound</code>,<code>good_upper_bound</code>]
the <code>target</code> is likely to be good. If it is in the interval
[<code>bad_lower_bound</code>,<code>bad_upper_bound</code>], the <code>target</code> is likely to be bad.
</p>
<p>Furthermore some summary statistics are provided: <code>na_removed</code> tells us
how many observations have been removed for a particular <code>ssv</code>. When
selecting the <code>versus</code> BOB/ WOW, the selection is done randomly from within
the best/ worst category, i.e. the <code>versus</code> BOB/ WOW are not uniquely
determined. The randomness in the selection is quantified by <code>ties_best_cat,
ties_worst_cat</code>, which gives the size of the best/ worst category respectively.
</p>


<h3>Value</h3>

<p>A data frame with the following columns
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Causes</code> </td><td style="text-align: left;"> Those <code>ssv</code> that have been found to be influential to the <code>target</code> variable.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Count</code> </td><td style="text-align: left;"> The value returned by the counting method. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>p.value</code> </td><td style="text-align: left;"> The p-value of the hypothesis test performed, i.e. either of the
Wilcoxon rank test (in case <code>test = "w"</code>) or the t-test (if <code>test = "t"</code>).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>good_lower_bound</code> </td><td style="text-align: left;"> The lower bound for this <code>Cause</code> for good quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>good_upper_bound</code> </td><td style="text-align: left;"> The upper bound for this <code>Cause</code> for good quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bad_lower_bound</code> </td><td style="text-align: left;"> The lower bound for this <code>Cause</code> for bad quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bad_upper_bound</code> </td><td style="text-align: left;"> The upper bound for this <code>Cause</code> for bad quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>na_removed</code> </td><td style="text-align: left;"> How many missing values were in the data set for this <code>Cause</code>?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ties_best_cat</code> </td><td style="text-align: left;"> How many observations fall into the best category? </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ties_worst_cat</code> </td><td style="text-align: left;"> How many observations fall into the worst category?
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- mtcars
df$cyl &lt;- as.factor(df$cyl)
categorical.igate(df, target = "cyl", best.cat = "8", worst.cat = "4")

</code></pre>

<hr>
<h2 id='counting.test'>Performs the counting test</h2><span id='topic+counting.test'></span>

<h3>Description</h3>

<p>This test is based on Tukey's &quot;A Quick, Compact, Two-Sample Test to Duckworth's
Specifications&quot;, Technometrics, Vol. 1, No. 1 (1959), p.31-48. The test is chosen here
because of its easy interpretability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>counting.test(B, W)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counting.test_+3A_b">B</code>, <code id="counting.test_+3A_w">W</code></td>
<td>
<p>Numeric vectors with best observations (<code>B</code>) and worst observations
(<code>W</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We form <code>rbind(B,W)</code> and order it. If <code>B</code> and <code>W</code>
differ significantly, ordering <code>rbind(B,W)</code> will find observations of one
group at the top and observations of the other at the bottom. We then count how
many observations of one group are at the top and how many of the other are at the
bottom. The sum of the two values gives us the <code>count</code> test statistic.
A critical value of <code>count &gt;= 6</code> correponds to a p-value of roughly 0.05
and is independent of sample size and distributional assumptions.
These clustered observations at the top and bottom of the ordered list also
determine the control bands <code>good_band_lower_bound</code>,
<code>good_band_upper_bound</code>,<code>bad_band_lower_bound</code>,
<code>bad_band_upper_bound</code>: We look if observations from group <code>B</code>
are at the top or bottom. The highest/ lowest values for observations of group <code>B</code>
within that cluser are <code>good_band_lower_bound</code> and
<code>good_band_upper_bound</code>. We proceed with group <code>W</code> respectively. If
no such clusters form at the end of the ordered list, the control bands are
set to -1.
</p>


<h3>Value</h3>

<p>A data frame with the following columns
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>count</code> </td><td style="text-align: left;"> The count test statistic described in Tukey's paper, adjusted for tied observations.
The original test statistic as described originally in the paper need not exist in case
of tied observations, this implemantation remedies this.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>good_band_lower_bound</code> </td><td style="text-align: left;"> Lower bound for good observations (<code>B</code>).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>good_band_upper_bound</code> </td><td style="text-align: left;"> Upper bound for good observations (<code>B</code>).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bad_band_lower_bound</code> </td><td style="text-align: left;"> Lower bound for bad observations (<code>W</code>).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bad_band_upper_bound</code> </td><td style="text-align: left;"> Upper bound for bad observations (<code>W</code>).
</td>
</tr>

</table>


<hr>
<h2 id='igate'>igate function for continuous target variables</h2><span id='topic+igate'></span>

<h3>Description</h3>

<p>This function performs an initial Guided Analysis for parameter testing and controlband extraction (iGATE)
on a dataset and returns those parameters found to be influential.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>igate(df, versus = 8, target, test = "w", ssv = NULL,
  outlier_removal_target = TRUE, outlier_removal_ssv = TRUE,
  good_end = "low", savePlots = FALSE, image_directory = tempdir())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igate_+3A_df">df</code></td>
<td>
<p>Data frame to be analysed.</p>
</td></tr>
<tr><td><code id="igate_+3A_versus">versus</code></td>
<td>
<p>How many Best of the Best and Worst of the Worst do we collect? By default, we will collect 8 of each.</p>
</td></tr>
<tr><td><code id="igate_+3A_target">target</code></td>
<td>
<p>Target varaible to be analysed. Must be continuous. Use <code><a href="#topic+categorical.igate">categorical.igate</a></code> for categorical target.</p>
</td></tr>
<tr><td><code id="igate_+3A_test">test</code></td>
<td>
<p>Statistical hypothesis test to be used to determine influential
process parameters. Choose between Wilcoxon Rank test (<code>"w"</code>, default) and Student's t-test (<code>"t"</code>).</p>
</td></tr>
<tr><td><code id="igate_+3A_ssv">ssv</code></td>
<td>
<p>A vector of suspected sources of variation. These are the variables
in <code>df</code> which we believe might have an influence on the target variable and
will be tested. If no list of ssv is provided, the test will be performed
on all numeric variables.</p>
</td></tr>
<tr><td><code id="igate_+3A_outlier_removal_target">outlier_removal_target</code></td>
<td>
<p>Logical. Should outliers (with respect to the target variable)
be removed from df (default: <code>TRUE</code>)? Important: This only makes sense if no
prior outlier removal has been performed on df, i.e. <code>df</code> still contains all
the data. Otherwise calculation for outlier threshold will be falsified.</p>
</td></tr>
<tr><td><code id="igate_+3A_outlier_removal_ssv">outlier_removal_ssv</code></td>
<td>
<p>Logical. Should outlier removal be performed for each ssv (default: <code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="igate_+3A_good_end">good_end</code></td>
<td>
<p>Are low (default) or high values of target variable good? This is needed
to determine the control bands.</p>
</td></tr>
<tr><td><code id="igate_+3A_saveplots">savePlots</code></td>
<td>
<p>Logical, only relevant if <code>outlier_removal_target</code> is TRUE. If  <code>savePlots == FALSE</code>
(the default) the boxplot of the target variable will be output to the standard output device for plots, usually
the console. If <code>TRUE</code>, the boxplot will additionally be saved to <code>image_directory</code> as a png file.</p>
</td></tr>
<tr><td><code id="igate_+3A_image_directory">image_directory</code></td>
<td>
<p>Directory to which plots should be saved. This is only used if <code>savePlots = TRUE</code> and
defaults to the temporary directory of the current R session, i.e. <code>tempdir()</code>. To save plots to the current
working directory set <code>savePlots = TRUE</code> and <code>image_directory = getwd()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We collect the Best of the Best and the Worst of the Worst
dynamically dependent on the current ssv. That means, for each ssv we first
remove all the observations with missing values for that ssv from df.
Then, based on the remaining observations, we select versus observations with
the best values for the target variable (“Best of the Best”, short BOB)  and
versus observations with the worst values for the target variable
(“Worst of the Worst”, short WOW). By default, we select 8 of each.
Next, we compare BOB and WOW using the the counting method and the specified
hypothesis test. If the distributions of the ssv in BOB and WOW are
significantly different, the current ssv has been identified as influential
to the target variable. An ssv is considered influential, if the test returns
a count larger/ equal to 6 and/ or a p-value of less than 0.05.
For the next ssv we again start with the entire dataset df, remove all
the observations with missing values for that new ssv and then select our
new BOB and WOW. In particular, for each ssv we might select different observations.
This dynamic selection is necessary, because in case of an incomplete data set,
if we select the same BOB and WOW for all the ssv, we might end up with many
missing values for particular ssv. In that case the hypothesis test loses
statistical power, because it is used on a smaller sample or worse, might
fail altogether if the sample size gets too small.
</p>
<p>For those ssv determined to be significant, control bands are extracted. The rationale is:
If the value for an ssv is in the interval [<code>good_lower_bound</code>,<code>good_upper_bound</code>]
the target is likely to be good. If it is in the interval
[<code>bad_lower_bound</code>,<code>bad_upper_bound</code>], the target is likely to be bad.
</p>
<p>Furthermore some summary statistics are provided: When selecting the <code>versus</code> BOB/ WOW, tied values for target
can mean that the <code>versus</code> BOB/ WOW are not uniquely determined. In that case we randomly select
from the tied observations to give us exactly <code>versus</code> observations per group.
<code>ties_lower_end, cometition_lower_end, ties_upper_end, competition_upper_end</code>
quantify this randomness. How to interpret these values: <em>lower end</em> refers to
the group whose <code>target</code> values are <em>low</em> and <em>upper end</em> to the one whose
<code>target</code> values are high. For example if a low value for <code>target</code> is good,
<em>lower end</em> refers to the BOB and <em>upper end</em> to the WOW. We determine the <code>versus</code>
BOB/ WOW via
</p>
<p><code>lower_end &lt;- df[min_rank(df$target)&lt;=versus,]</code>
</p>
<p>If there are tied observations, <code>nrow(lower_end)</code> can be larger than <code>versus</code>. In <code>ties_lower_end</code> we
record how many observations in <code>lower_end$target</code> have the <em>highest</em> value and in <code>competition_lower_end</code>
we record for how many places they are competing, i.e.
<code>competing_for_lower &lt;- versus - (nrow(lower_end) - ties_lower_end)</code>.
The values for <code>ties_upper_end</code> and <code>competition_upper_end</code> are determined analogously.
</p>


<h3>Value</h3>

<p>A data frame with the following columns
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Causes</code> </td><td style="text-align: left;"> Those ssv that have been found to be influential to the target variable.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Count</code> </td><td style="text-align: left;"> The value returned by the counting method. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>p.value</code> </td><td style="text-align: left;"> The p-value of the hypothesis test performed, i.e. either of the
Wilcoxon rank test (in case <code>test = "w"</code>) or the t-test (if <code>test = "t"</code>).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>good_lower_bound</code> </td><td style="text-align: left;"> The lower bound for this <code>Cause</code> for good quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>good_upper_bound</code> </td><td style="text-align: left;"> The upper bound for this <code>Cause</code> for good quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bad_lower_bound</code> </td><td style="text-align: left;"> The lower bound for this <code>Cause</code> for bad quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>bad_upper_bound</code> </td><td style="text-align: left;"> The upper bound for this <code>Cause</code> for bad quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>na_removed</code> </td><td style="text-align: left;"> How many missing values were in the data set for this <code>Cause</code>?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ties_lower_end</code> </td><td style="text-align: left;"> Number of tied observations at lower end of <code>target</code> when selecting the
<code>versus</code> BOB/ WOW.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>competition_lower_end</code> </td><td style="text-align: left;"> For how many positions are the <code>tied_obs_lower</code> competing?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ties_upper_end</code> </td><td style="text-align: left;"> Number of tied observations at upper end of <code>target</code> when selecting the
<code>versus</code> BOB/ WOW.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>competition_upper_end</code> </td><td style="text-align: left;"> For how many positions are the <code>tied_obs_upper</code> competing?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>adjusted.p.values</code> </td><td style="text-align: left;"> The <code>p.values</code> adjusted via Bonferroni correction.
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>igate(iris, target = "Sepal.Length")

</code></pre>

<hr>
<h2 id='igate.regressions'>Produces the regression plots for sanity check in iGATE</h2><span id='topic+igate.regressions'></span>

<h3>Description</h3>

<p>This function takes a data frame, a target variable and a list of ssv and
produces a regression plot of each ssv against the target. The output can written as
.png file into the current working directory. Also, summary statistics are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>igate.regressions(df, target, ssv = NULL,
  outlier_removal_target = TRUE, outlier_removal_ssv = TRUE,
  savePlots = FALSE, image_directory = tempdir())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igate.regressions_+3A_df">df</code></td>
<td>
<p>Data frame to be analysed.</p>
</td></tr>
<tr><td><code id="igate.regressions_+3A_target">target</code></td>
<td>
<p>Target varaible to be analysed.</p>
</td></tr>
<tr><td><code id="igate.regressions_+3A_ssv">ssv</code></td>
<td>
<p>A vector of suspected sources of variation. These are the variables
in <code>df</code> which we believe might have an influence on the target variable and
will be tested. If no list of ssv is provided, the test will be performed
on all numeric variables.</p>
</td></tr>
<tr><td><code id="igate.regressions_+3A_outlier_removal_target">outlier_removal_target</code></td>
<td>
<p>Logical. Should outliers (with respect to the target variable)
be removed from df (default: <code>TRUE</code>)? Important: This only makes sense if no
prior outlier removal has been performed on df, i.e. <code>df</code> still contains all
the data. Otherwise calculation for outlier threshold will be falsified.</p>
</td></tr>
<tr><td><code id="igate.regressions_+3A_outlier_removal_ssv">outlier_removal_ssv</code></td>
<td>
<p>Logical. Should outlier removal be performed for each ssv (default: <code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="igate.regressions_+3A_saveplots">savePlots</code></td>
<td>
<p>Logical. If <code>FALSE</code> (the default) regression plots will be output to the standard plotting
device. If <code>TRUE</code>, regression plots will additionally be saved to <code>image_directory</code> as png files.</p>
</td></tr>
<tr><td><code id="igate.regressions_+3A_image_directory">image_directory</code></td>
<td>
<p>Directory to which plots should be saved. This is only used if <code>savePlots = TRUE</code> and
defaults to the temporary directory of the current R session, i.e. <code>tempdir()</code>. To save plots to the current
working directory set <code>savePlots = TRUE</code> and <code>image_directory = getwd()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regression plots for each <code>ssv</code> against <code>target</code> are produced and
svaed to current working directory. Also a data frame with summary statistics is produced,
see <b>Value</b> for details.
</p>


<h3>Value</h3>

<p>The regression plots of <code>target</code> against each <code>ssv</code> are written as
.png file into the current working directory. Also, a data frame with the following
columns is output
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Causes</code> </td><td style="text-align: left;"> The <code>ssv</code> that were analysed.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>outliers_removed</code> </td><td style="text-align: left;"> How many outliers (with respect to this <code>ssv</code>)
have been removed before fitting the linear model?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>observations_retained</code> </td><td style="text-align: left;"> After outlier removal was performed, how many observations
were left and used to fit the model?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>regression_plot</code> </td><td style="text-align: left;"> Logical. Was fitting the model successful? It can fail,
for example, if a ssv is constant.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>r_squared</code> </td><td style="text-align: left;"> r^2 value of model.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>gradient, intercept</code> </td><td style="text-align: left;"> Gradient and intercept of fitted model.
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>igate.regressions(iris, target = "Sepal.Length")

</code></pre>

<hr>
<h2 id='report'>Generates report about a conducted igate.</h2><span id='topic+report'></span>

<h3>Description</h3>

<p>Takes results from a previous igate and automatically generates a html report
for it. Be aware that running this function will create an html document in your current working directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>report(df, versus = 8, target, type = "continuous", test = "w",
  ssv = NULL, outlier_removal_target = TRUE,
  outlier_removal_ssv = TRUE, good_outcome = "low", results_path,
  validation = FALSE, validation_path = NULL,
  validation_counts = NULL, validation_summary = NULL,
  image_directory = tempdir(), output_name = NULL, output_directory)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="report_+3A_df">df</code></td>
<td>
<p>The data frame that was analysed with <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>.</p>
</td></tr>
<tr><td><code id="report_+3A_versus">versus</code></td>
<td>
<p>What value of <code>versus</code> was used?</p>
</td></tr>
<tr><td><code id="report_+3A_target">target</code></td>
<td>
<p>What <code>target</code> was used?</p>
</td></tr>
<tr><td><code id="report_+3A_type">type</code></td>
<td>
<p>Was <code><a href="#topic+igate">igate</a></code> (use <code>type = "continuous"</code>) or <code><a href="#topic+categorical.igate">categorical.igate</a></code> (use <code>type = "categorical"</code>) conducted?</p>
</td></tr>
<tr><td><code id="report_+3A_test">test</code></td>
<td>
<p>Which hypothesis test was used alongside the counting method?</p>
</td></tr>
<tr><td><code id="report_+3A_ssv">ssv</code></td>
<td>
<p>Which <code>ssv</code> have been used in the analysis? If <code>NULL</code>, it
will be assumed that <code>ssv = NULL</code> was passed to <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>
and all numeric variables in <code>df</code> will be used.</p>
</td></tr>
<tr><td><code id="report_+3A_outlier_removal_target">outlier_removal_target</code></td>
<td>
<p>Was outlier removal conducted for <code>target</code>? If <code>type == "categorical"</code>
this is set to <code>FALSE</code> automatically.</p>
</td></tr>
<tr><td><code id="report_+3A_outlier_removal_ssv">outlier_removal_ssv</code></td>
<td>
<p>Was outlier removal conducted for each <code>ssv</code>?</p>
</td></tr>
<tr><td><code id="report_+3A_good_outcome">good_outcome</code></td>
<td>
<p>Are <code>"low"</code> or <code>"high"</code> values of <code>target</code> good? Or, in
case of a categorical <code>target</code> the name of the best category as a string.</p>
</td></tr>
<tr><td><code id="report_+3A_results_path">results_path</code></td>
<td>
<p>Name of R object (as string) containing the results of <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>.</p>
</td></tr>
<tr><td><code id="report_+3A_validation">validation</code></td>
<td>
<p>Logical. Has validation of the results been performed?</p>
</td></tr>
<tr><td><code id="report_+3A_validation_path">validation_path</code></td>
<td>
<p>Name R object (as string) containing the validated observations, i.e. first data frame returned by <code><a href="#topic+validate">validate</a></code>.</p>
</td></tr>
<tr><td><code id="report_+3A_validation_counts">validation_counts</code></td>
<td>
<p>Name of R object (as string) containing the counts from validation, i.e. the second data frame returned by <code><a href="#topic+validate">validate</a></code>.</p>
</td></tr>
<tr><td><code id="report_+3A_validation_summary">validation_summary</code></td>
<td>
<p>Name of R object (as string) containing the summary of <code>validation_path</code>, i.e. the third data frame returned by <code><a href="#topic+validate">validate</a></code>.</p>
</td></tr>
<tr><td><code id="report_+3A_image_directory">image_directory</code></td>
<td>
<p>Directory which contains the plots from <code>igate</code>, <code>igate.regressions</code> etc.</p>
</td></tr>
<tr><td><code id="report_+3A_output_name">output_name</code></td>
<td>
<p>Desired name of the output file. File extension .html will be added automatically if not supplied.
If <code>NULL</code> will be *iGATE_Report.html*.</p>
</td></tr>
<tr><td><code id="report_+3A_output_directory">output_directory</code></td>
<td>
<p>Directory into which the report should be saved. To save to the current working directory,
use <code>output_directory = getwd()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An html file named &quot;iGATE_Report.html&quot; will be output to the current working directory, containing details
about the conducted analysis. This includes a list of the analysed SSV, as well as tables with the results from
<code><a href="#topic+igate">igate</a></code>/ <code><a href="#topic+categorical.igate">categorical.igate</a></code> and plots from <code><a href="#topic+igate.regressions">igate.regressions</a></code>/
<code><a href="#topic+categorical.freqplot">categorical.freqplot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example for categorical target variable
# If you want to conduct an igate analysis from scratch, running report
# is the last step and relies on executing the other functions in this package first.
# Run categorical.igate
df &lt;- mtcars
df$cyl &lt;- as.factor(df$cyl)
results &lt;- categorical.igate(df, target = "cyl", best.cat = "8", worst.cat = "4")
# Produce density plots
# Suppose you only want to analyse further the first three identified ssv
results &lt;- results[1:3,]
categorical.freqplot(mtcars, target = "cyl", ssv = results$Causes , savePlots = TRUE)

report(df = df, target = "cyl", type = "categorical", good_outcome = "8",
results_path = "results",
output_name = "testing_igate", output_directory = tempdir())


</code></pre>

<hr>
<h2 id='resultsIris'>Example results data file to be used for example report generation.</h2><span id='topic+resultsIris'></span>

<h3>Description</h3>

<p>This is the output of
<code>resultsIris &lt;- igate(iris, target = "Sepal.Length")</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resultsIris
</code></pre>


<h3>Format</h3>

<p>A data frame as described in the documentation of <code><a href="#topic+igate">igate</a></code>.</p>

<hr>
<h2 id='robust.categorical.igate'>Robust igate for categorical target variables</h2><span id='topic+robust.categorical.igate'></span>

<h3>Description</h3>

<p>This function performs a robust an initial Guided Analysis for parameter testing and
controlband extraction (iGATE) for a categorical target variable by repeatedly running
<code><a href="#topic+categorical.igate">categorical.igate</a></code> and only returning those parameters that are selected more often than a
certain threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robust.categorical.igate(df, versus = 8, target, best.cat, worst.cat,
  test = "w", ssv = NULL, outlier_removal_ssv = TRUE,
  iterations = 50, threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="robust.categorical.igate_+3A_df">df</code></td>
<td>
<p>Data frame to be analysed.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_versus">versus</code></td>
<td>
<p>How many Best of the Best and Worst of the Worst do we collect? By default, we will collect 8 of each.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_target">target</code></td>
<td>
<p>Target variable to be analysed. Must be categorical.
Use <code><a href="#topic+igate">igate</a></code> for continuous <code>target</code>.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_best.cat">best.cat</code></td>
<td>
<p>The best category. The <code>versus</code> BOB will be selected randomly from this
category.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_worst.cat">worst.cat</code></td>
<td>
<p>The worst category. The <code>versus</code> WOW will be selected randomly from this
category.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_test">test</code></td>
<td>
<p>Statistical hypothesis test to be used to determine influential
process parameters. Choose between Wilcoxon Rank test (<code>"w"</code>, default)
and Student's t-test (<code>"t"</code>).</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_ssv">ssv</code></td>
<td>
<p>A vector of suspected sources of variation. These are the variables
in <code>df</code> which we believe might have an influence on the <code>target</code> variable and
will be tested. If no list of <code>ssv</code> is provided, the test will be performed
on all numeric variables.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_outlier_removal_ssv">outlier_removal_ssv</code></td>
<td>
<p>Logical. Should outlier removal be performed for each <code>ssv</code> (default: <code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_iterations">iterations</code></td>
<td>
<p>Integer. How often should categorical.igate be performed? A message about how many iterations
have been perfermed so far will be printed to the console every <code>0.1*iterations</code> iterations.</p>
</td></tr>
<tr><td><code id="robust.categorical.igate_+3A_threshold">threshold</code></td>
<td>
<p>Between 0 and 1. Only parameters that are selected at least <code>floor(iterations*threshold)</code>
times are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We collect the Best of the Best and the Worst of the Worst
dynamically dependent on the current <code>ssv</code>. That means, for each <code>ssv</code> we first
remove all the observations with missing values for that <code>ssv</code> from <code>df</code>.
Then, based on the remaining observations, we randomly select <code>versus</code>
observations from the the best category (“Best of the Best”, short BOB)  and
<code>versus</code> observations from the worst category
(“Worst of the Worst”, short WOW). By default, we select 8 of each. Since this selection
happens randomly, it is recommended to use <code>robust.categorical.igate</code> over <code><a href="#topic+categorical.igate">categorical.igate</a></code>.
After the selection we compare BOB and WOW using the the counting method and the specified
hypothesis test. If the distributions of the <code>ssv</code> in BOB and WOW are
significantly different, the current <code>ssv</code> has been identified as influential
to the <code>target</code> variable. An <code>ssv</code> is considered influential, if the test returns
a count larger/ equal to 6 and/ or a p-value of less than 0.05.
For the next <code>ssv</code> we again start with the entire dataset <code>df</code>, remove all
the observations with missing values for that new <code>ssv</code> and then select our
new BOB and WOW. In particular, for each <code>ssv</code> we might select different observations.
This dynamic selection is necessary, because in case of an incomplete data set,
if we select the same BOB and WOW for all the <code>ssv</code>, we might end up with many
missing values for particular <code>ssv</code>. In that case the hypothesis test loses
statistical power, because it is used on a smaller sample or worse, might
fail altogether if the sample size gets too small.
</p>
<p>For those <code>ssv</code> determined to be significant, control bands are extracted. The rationale is:
If the value for an <code>ssv</code> is in the interval [<code>good_lower_bound</code>,<code>good_upper_bound</code>]
the <code>target</code> is likely to be good. If it is in the interval
[<code>bad_lower_bound</code>,<code>bad_upper_bound</code>], the <code>target</code> is likely to be bad.
</p>


<h3>Value</h3>

<p>A data frame with the summary statistics for those parameters that were selected
at least <code>floor(iterations*threshold)</code> times:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Causes</code> </td><td style="text-align: left;"> Those <code>ssv</code> that have been found to be influential to the <code>target</code> variable.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>median_count</code> </td><td style="text-align: left;"> The median value returned by the counting method for this parameter. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>median_p_value</code> </td><td style="text-align: left;"> The median p-value of the hypothesis test performed, i.e. either of the
Wilcoxon rank test (in case <code>test = "w"</code>) or the t-test (if <code>test = "t"</code>).</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>median_good_lower_bound</code> </td><td style="text-align: left;"> The median lower bound for this <code>Cause</code> for good quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>median_good_upper_bound</code> </td><td style="text-align: left;"> The median upper bound for this <code>Cause</code> for good quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>median_bad_lower_bound</code> </td><td style="text-align: left;"> The median lower bound for this <code>Cause</code> for bad quality.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>median_bad_upper_bound</code> </td><td style="text-align: left;"> The median upper bound for this <code>Cause</code> for bad quality.
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>robust.categorical.igate(mtcars, target = "cyl",
best.cat = "8", worst.cat = "4", iterations = 50, threshold = 0.5)

</code></pre>

<hr>
<h2 id='validate'>Validates results after using <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>.</h2><span id='topic+validate'></span>

<h3>Description</h3>

<p>Takes a new data frame to be used for validation and the causes and control bands
obtained from <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code> and returns
all those observations that fall within these control bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate(validation_df, target, causes, results_df, type = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_+3A_validation_df">validation_df</code></td>
<td>
<p>Data frame to be used for validation. It is recommended to use
a different data frame from the one used in <code><a href="#topic+igate">igate</a></code>/ <code><a href="#topic+categorical.igate">categorical.igate</a></code>.
The same data frame can be used if just a sanity check of the results is performed. This
data frame must contain the <code>target</code> variable as well as all the causes determined
by <code><a href="#topic+igate">igate</a></code>/ <code><a href="#topic+categorical.igate">categorical.igate</a></code>.</p>
</td></tr>
<tr><td><code id="validate_+3A_target">target</code></td>
<td>
<p>Target variable that was used in <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>.</p>
</td></tr>
<tr><td><code id="validate_+3A_causes">causes</code></td>
<td>
<p>Causes determined by <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>.
If you saved the results of <code><a href="#topic+igate">igate</a></code>/ <code><a href="#topic+categorical.igate">categorical.igate</a></code> in an object
<code>results</code>, simply use <code>results$Causes</code> here.</p>
</td></tr>
<tr><td><code id="validate_+3A_results_df">results_df</code></td>
<td>
<p>The data frame containing the results of <code><a href="#topic+igate">igate</a></code> or <code><a href="#topic+categorical.igate">categorical.igate</a></code>.</p>
</td></tr>
<tr><td><code id="validate_+3A_type">type</code></td>
<td>
<p>The type of igate that was performed: either <code>"continuous"</code> or <code>"categorical"</code>. If not provided
function will try to guess the correct type based on the type of <code>validation_df[[target]]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a value of <code>Good_Count</code> or <code>Bad_count</code> is very low in the second
data frame, it means that this cause is excluding a lot of observations from the
first data frame. Consider re-running <code>validate</code> with this cause removed from
<code>causes</code>.
</p>


<h3>Value</h3>

<p>A list of three data frames is returned. The first data frame contains those observations
in <code>validation_df</code> that fall into *all* the good resp. bad control bands specified in <code>results_df</code>.
The columns are <code>target</code>, then one column for each of the <code>causes</code> and a new column
<code>expected_quality</code> which is <code>"good"</code> if the observation falls into all the good
control bands and <code>"bad"</code> if it falls into all the bad control bands.
</p>
<p>The second data frame has three columns
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Cause</code> </td><td style="text-align: left;"> Each of the <code>causes</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Good_Count</code> </td><td style="text-align: left;"> If we selected all those observations that fall into the good band
of this cause, how many observations would we select?</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Bad_Count</code> </td><td style="text-align: left;"> If we selected all those observations that fall into the bad band
of this cause, how many observations would we select?
</td>
</tr>

</table>

<p>The third data frame summarizes the first data frame: If <code>type = "continuous"</code> it has
three columns:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>expected_quality</code> </td><td style="text-align: left;"> Either <code>"good"</code> or <code>"bad"</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>max_target</code> </td><td style="text-align: left;"> The maximum value for <code>target</code> for the observations with "good"
expected quality resp. "bad" expected quality. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>min_target</code> </td><td style="text-align: left;"> Minimum value of <code>target</code> for good resp. bad expected quality.
</td>
</tr>

</table>

<p>If <code>type = "categorical"</code> it has the following three columns:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>expected_quality</code> </td><td style="text-align: left;"> Either <code>"good"</code> or <code>"bad"</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Category</code> </td><td style="text-align: left;"> A list of categories of the observations with expected quality good resp. bad. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Frequency</code> </td><td style="text-align: left;"> A count how often the respective <code>Category</code> appears amongs the observations with
good/ bad expected quality.
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>validate(iris, target = "Sepal.Length", causes = resultsIris$Causes, results_df = resultsIris)

</code></pre>

<hr>
<h2 id='validatedObsIris'>validatedObsIris data set</h2><span id='topic+validatedObsIris'></span>

<h3>Description</h3>

<p>Example validation data file to be used for example report generation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validatedObsIris
</code></pre>


<h3>Format</h3>

<p>A data frame as described in the documentation of <code><a href="#topic+validate">validate</a></code>.</p>


<h3>Details</h3>

<p>This is the output of
</p>
<p><code>
x &lt;- validate(iris, target = "Sepal.Length",
causes = resultsIris$Causes,
results_df = resultsIris)
</code>
</p>
<p><code>validatedObsIris &lt;- x[[1]]</code>
</p>

<hr>
<h2 id='validationCountsIris'>validationCountsIris data set</h2><span id='topic+validationCountsIris'></span>

<h3>Description</h3>

<p>Example validation data file to be used for example report generation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validationCountsIris
</code></pre>


<h3>Format</h3>

<p>A data frame as described in the documentation of <code><a href="#topic+validate">validate</a></code>.</p>


<h3>Details</h3>

<p>This is the output of
</p>
<p><code>
x &lt;- validate(iris, target = "Sepal.Length",
causes = resultsIris$Causes,
results_df = resultsIris)
</code>
</p>
<p><code>validationCountsIris &lt;- x[[2]]</code>
</p>

<hr>
<h2 id='validationSummaryIris'>validationSummaryIris data set</h2><span id='topic+validationSummaryIris'></span>

<h3>Description</h3>

<p>Example validation data file to be used for example report generation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validationSummaryIris
</code></pre>


<h3>Format</h3>

<p>A data frame as described in the documentation of <code><a href="#topic+validate">validate</a></code>.</p>


<h3>Details</h3>

<p>This is the output of
</p>
<p><code>
x &lt;- validate(iris, target = "Sepal.Length",
causes = resultsIris$Causes,
results_df = resultsIris)
</code>
</p>
<p><code>validationSummaryIris &lt;- x[[3]]</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
