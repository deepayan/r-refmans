<!DOCTYPE html><html><head><title>Help for package tfhub</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tfhub}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#bake.step_pretrained_text_embedding'><p>Bake method for step_pretrained_text_embedding</p></a></li>
<li><a href='#hub_image_embedding_column'><p>Module to construct a dense 1-D representation from the pixels of images.</p></a></li>
<li><a href='#hub_load'><p>Hub Load</p></a></li>
<li><a href='#hub_sparse_text_embedding_column'><p>Module to construct dense representations from sparse text features.</p></a></li>
<li><a href='#hub_text_embedding_column'><p>Module to construct a dense representation from a text feature.</p></a></li>
<li><a href='#install_tfhub'><p>Install TensorFlow Hub</p></a></li>
<li><a href='#layer_hub'><p>Hub Layer</p></a></li>
<li><a href='#prep.step_pretrained_text_embedding'><p>Prep method for step_pretrained_text_embedding</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#step_pretrained_text_embedding'><p>Pretrained text-embeddings</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Interface to 'TensorFlow' Hub</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.1</td>
</tr>
<tr>
<td>Description:</td>
<td>'TensorFlow' Hub is a library for the publication, discovery, and
    consumption of reusable parts of machine learning models. A module is a 
    self-contained piece of a 'TensorFlow' graph, along with its weights and 
    assets, that can be reused across different tasks in a process known as
    transfer learning. Transfer learning train a model with a smaller dataset,
    improve generalization, and speed up training.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/rstudio/tfhub">https://github.com/rstudio/tfhub</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rstudio/tfhub/issues">https://github.com/rstudio/tfhub/issues</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>TensorFlow &gt;= 2.0 (https://www.tensorflow.org/)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate (&ge; 1.9.0.9002), tensorflow (&ge; 1.8.0.9006),
magrittr, rstudioapi (&ge; 0.7), vctrs</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.1.0), knitr, tfestimators, keras, rmarkdown,
callr, recipes, tibble, abind, fs,</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/reticulate:</td>
<td>list( packages = list( list(package =
"tensorflow_hub", pip = TRUE) ) )</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-12-15 14:25:06 UTC; tomasz</td>
</tr>
<tr>
<td>Author:</td>
<td>Tomasz Kalinowski [aut, cre],
  Daniel Falbel [aut],
  JJ Allaire [aut],
  RStudio [cph, fnd],
  Google Inc. [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomasz Kalinowski &lt;tomasz.kalinowski@rstudio.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-12-19 01:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code><a href="magrittr.html#topic++25+3E+25">%&gt;%</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='bake.step_pretrained_text_embedding'>Bake method for step_pretrained_text_embedding</h2><span id='topic+bake.step_pretrained_text_embedding'></span>

<h3>Description</h3>

<p>Bake method for step_pretrained_text_embedding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bake.step_pretrained_text_embedding(object, new_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bake.step_pretrained_text_embedding_+3A_object">object</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="bake.step_pretrained_text_embedding_+3A_new_data">new_data</code></td>
<td>
<p>new data to apply transformations</p>
</td></tr>
<tr><td><code id="bake.step_pretrained_text_embedding_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose variables.</p>
</td></tr>
</table>

<hr>
<h2 id='hub_image_embedding_column'>Module to construct a dense 1-D representation from the pixels of images.</h2><span id='topic+hub_image_embedding_column'></span>

<h3>Description</h3>

<p>Module to construct a dense 1-D representation from the pixels of images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hub_image_embedding_column(key, module_spec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hub_image_embedding_column_+3A_key">key</code></td>
<td>
<p>A string or [feature_column](https://tensorflow.rstudio.com/tfestimators/articles/feature_columns.html)
identifying the text feature.</p>
</td></tr>
<tr><td><code id="hub_image_embedding_column_+3A_module_spec">module_spec</code></td>
<td>
<p>A string handle or a _ModuleSpec identifying the module.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This feature column can be used on images, represented as float32 tensors of RGB pixel
data in the range [0,1].
</p>

<hr>
<h2 id='hub_load'>Hub Load</h2><span id='topic+hub_load'></span>

<h3>Description</h3>

<p>Loads a module from a handle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hub_load(handle, tags = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hub_load_+3A_handle">handle</code></td>
<td>
<p>(string) the Module handle to resolve.</p>
</td></tr>
<tr><td><code id="hub_load_+3A_tags">tags</code></td>
<td>
<p>A set of strings specifying the graph variant to use, if loading
from a v1 module.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently this method is fully supported only with Tensorflow 2.x and with
modules created by calling 'export_savedmodel'. The method works in
both eager and graph modes.
</p>
<p>Depending on the type of handle used, the call may involve downloading a
TensorFlow Hub module to a local cache location specified by the
'TFHUB_CACHE_DIR' environment variable. If a copy of the module is already
present in the TFHUB_CACHE_DIR, the download step is skipped.
</p>
<p>Currently, three types of module handles are supported: 1) Smart URL resolvers
such as tfhub.dev, e.g.: https://tfhub.dev/google/nnlm-en-dim128/1. 2) A directory
on a file system supported by Tensorflow containing module files. This may include
a local directory (e.g. /usr/local/mymodule) or a Google Cloud Storage bucket
(gs://mymodule). 3) A URL pointing to a TGZ archive of a module, e.g.
https://example.com/mymodule.tar.gz.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model &lt;- hub_load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')


## End(Not run)

</code></pre>

<hr>
<h2 id='hub_sparse_text_embedding_column'>Module to construct dense representations from sparse text features.</h2><span id='topic+hub_sparse_text_embedding_column'></span>

<h3>Description</h3>

<p>The input to this feature column is a batch of multiple strings with
arbitrary size, assuming the input is a SparseTensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hub_sparse_text_embedding_column(
  key,
  module_spec,
  combiner,
  default_value,
  trainable = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hub_sparse_text_embedding_column_+3A_key">key</code></td>
<td>
<p>A string or [feature_column](https://tensorflow.rstudio.com/tfestimators/articles/feature_columns.html)
identifying the text feature.</p>
</td></tr>
<tr><td><code id="hub_sparse_text_embedding_column_+3A_module_spec">module_spec</code></td>
<td>
<p>A string handle or a _ModuleSpec identifying the module.</p>
</td></tr>
<tr><td><code id="hub_sparse_text_embedding_column_+3A_combiner">combiner</code></td>
<td>
<p>a string specifying reducing op for embeddings in the same Example.
Currently, 'mean', 'sqrtn', 'sum' are supported. Using 'combiner = NULL' is
undefined.</p>
</td></tr>
<tr><td><code id="hub_sparse_text_embedding_column_+3A_default_value">default_value</code></td>
<td>
<p>default value for Examples where the text feature is empty.
Note, it's recommended to have default_value consistent OOV tokens, in case
there was special handling of OOV in the text module. If 'NULL', the text
feature is assumed be non-empty for each Example.</p>
</td></tr>
<tr><td><code id="hub_sparse_text_embedding_column_+3A_trainable">trainable</code></td>
<td>
<p>Whether or not the Module is trainable. 'FALSE' by default,
meaning the pre-trained weights are frozen. This is different from the ordinary
'tf.feature_column.embedding_column()', but that one is intended for training
from scratch.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This type of feature column is typically suited for modules that operate
on pre-tokenized text to produce token level embeddings which are combined
with the combiner into a text embedding. The combiner always treats the tokens
as a bag of words rather than a sequence.
</p>
<p>The output (i.e., transformed input layer) is a DenseTensor, with
shape [batch_size, num_embedding_dim].
</p>

<hr>
<h2 id='hub_text_embedding_column'>Module to construct a dense representation from a text feature.</h2><span id='topic+hub_text_embedding_column'></span>

<h3>Description</h3>

<p>This feature column can be used on an input feature whose values are strings of
arbitrary size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hub_text_embedding_column(key, module_spec, trainable = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hub_text_embedding_column_+3A_key">key</code></td>
<td>
<p>A string or [feature_column](https://tensorflow.rstudio.com/tfestimators/articles/feature_columns.html)
identifying the text feature.</p>
</td></tr>
<tr><td><code id="hub_text_embedding_column_+3A_module_spec">module_spec</code></td>
<td>
<p>A string handle or a _ModuleSpec identifying the module.</p>
</td></tr>
<tr><td><code id="hub_text_embedding_column_+3A_trainable">trainable</code></td>
<td>
<p>Whether or not the Module is trainable. 'FALSE' by default,
meaning the pre-trained weights are frozen. This is different from the ordinary
'tf.feature_column.embedding_column()', but that one is intended for training
from scratch.</p>
</td></tr>
</table>

<hr>
<h2 id='install_tfhub'>Install TensorFlow Hub</h2><span id='topic+install_tfhub'></span>

<h3>Description</h3>

<p>This function is used to install the TensorFlow Hub python module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_tfhub(version = "release", ..., restart_session = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_tfhub_+3A_version">version</code></td>
<td>
<p>version of TensorFlow Hub to be installed.</p>
</td></tr>
<tr><td><code id="install_tfhub_+3A_...">...</code></td>
<td>
<p>other arguments passed to [reticulate::py_install()].</p>
</td></tr>
<tr><td><code id="install_tfhub_+3A_restart_session">restart_session</code></td>
<td>
<p>Restart R session after installing (note this will
only occur within RStudio).</p>
</td></tr>
</table>

<hr>
<h2 id='layer_hub'>Hub Layer</h2><span id='topic+layer_hub'></span>

<h3>Description</h3>

<p>Wraps a Hub module (or a similar callable) for TF2 as a Keras Layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_hub(object, handle, trainable = FALSE, arguments = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_hub_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_hub_+3A_handle">handle</code></td>
<td>
<p>a callable object (subject to the conventions above), or a string
for which 'hub_load()' returns such a callable. A string is required to save
the Keras config of this Layer.</p>
</td></tr>
<tr><td><code id="layer_hub_+3A_trainable">trainable</code></td>
<td>
<p>Boolean controlling whether this layer is trainable.</p>
</td></tr>
<tr><td><code id="layer_hub_+3A_arguments">arguments</code></td>
<td>
<p>optionally, a list with additional keyword arguments passed to
the callable. These must be JSON-serializable to save the Keras config of
this layer.</p>
</td></tr>
<tr><td><code id="layer_hub_+3A_...">...</code></td>
<td>
<p>Other arguments that are passed to the TensorFlow Hub module.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer wraps a callable object for use as a Keras layer. The callable
object can be passed directly, or be specified by a string with a handle
that gets passed to 'hub_load()'.
</p>
<p>The callable object is expected to follow the conventions detailed below.
(These are met by TF2-compatible modules loaded from TensorFlow Hub.)
</p>
<p>The callable is invoked with a single positional argument set to one tensor or
a list of tensors containing the inputs to the layer. If the callable accepts
a training argument, a boolean is passed for it. It is 'TRUE' if this layer
is marked trainable and called for training.
</p>
<p>If present, the following attributes of callable are understood to have special
meanings: variables: a list of all tf.Variable objects that the callable depends on.
trainable_variables: those elements of variables that are reported as trainable
variables of this Keras Layer when the layer is trainable. regularization_losses:
a list of callables to be added as losses of this Keras Layer when the layer is
trainable. Each one must accept zero arguments and return a scalar tensor.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(keras)

model &lt;- keras_model_sequential() %&gt;%
 layer_hub(
   handle = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4",
   input_shape = c(224, 224, 3)
 ) %&gt;%
 layer_dense(1)


## End(Not run)

</code></pre>

<hr>
<h2 id='prep.step_pretrained_text_embedding'>Prep method for step_pretrained_text_embedding</h2><span id='topic+prep.step_pretrained_text_embedding'></span>

<h3>Description</h3>

<p>Prep method for step_pretrained_text_embedding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep.step_pretrained_text_embedding(x, training, info = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prep.step_pretrained_text_embedding_+3A_x">x</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="prep.step_pretrained_text_embedding_+3A_training">training</code></td>
<td>
<p>wether or not it's training</p>
</td></tr>
<tr><td><code id="prep.step_pretrained_text_embedding_+3A_info">info</code></td>
<td>
<p>variables state</p>
</td></tr>
<tr><td><code id="prep.step_pretrained_text_embedding_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose variables.</p>
</td></tr>
</table>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+install_tensorflow'></span><span id='topic+tf'></span><span id='topic+shape'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+install_tensorflow">install_tensorflow</a></code>, <code><a href="tensorflow.html#topic+shape">shape</a></code>, <code><a href="tensorflow.html#topic+tf">tf</a></code></p>
</dd>
</dl>

<hr>
<h2 id='step_pretrained_text_embedding'>Pretrained text-embeddings</h2><span id='topic+step_pretrained_text_embedding'></span>

<h3>Description</h3>

<p>'step_pretrained_text_embedding' creates a *specification* of a
recipe step that will transform text data into its numerical
transformation based on a pretrained model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_pretrained_text_embedding(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  handle,
  args = NULL,
  skip = FALSE,
  id = recipes::rand_id("pretrained_text_embedding")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_pretrained_text_embedding_+3A_recipe">recipe</code></td>
<td>
<p>A recipe object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose variables.</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_role">role</code></td>
<td>
<p>Role for the created variables</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_handle">handle</code></td>
<td>
<p>the Module handle to resolve.</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_args">args</code></td>
<td>
<p>other arguments passed to [hub_load()].</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by [recipes::bake.recipe()]? While all operations are baked
when [recipes::prep.recipe()] is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using 'skip = TRUE' as it may affect
the computations for subsequent operations</p>
</td></tr>
<tr><td><code id="step_pretrained_text_embedding_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(tibble)
library(recipes)
df &lt;- tibble(text = c('hi', "heello", "goodbye"), y = 0)

rec &lt;- recipe(y ~ text, df)
rec &lt;- rec %&gt;% step_pretrained_text_embedding(
 text,
 handle = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1"
)


## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
