<!DOCTYPE html><html lang="en"><head><title>Help for package deeptrafo</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {deeptrafo}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#atm_init'><p>Initializes the Processed Additive Predictor for ATMs</p></a></li>
<li><a href='#BoxCoxNN'><p>BoxCox-type neural network transformation models</p></a></li>
<li><a href='#coef.deeptrafo'><p>S3 methods for deep conditional transformation models</p></a></li>
<li><a href='#ColrNN'><p>Deep continuous outcome logistic regression</p></a></li>
<li><a href='#cotramNN'><p>Deep distribution-free count regression</p></a></li>
<li><a href='#CoxphNN'><p>Cox proportional hazards type neural network transformation models</p></a></li>
<li><a href='#dctm'><p>Deep conditional transformation models with alternative formula interface</p></a></li>
<li><a href='#deeptrafo'><p>Deep Conditional Transformation Models</p></a></li>
<li><a href='#ensemble.deeptrafo'><p>Deep ensembling for neural network transformation models</p></a></li>
<li><a href='#from_preds_to_trafo'><p>Define Predictor of Transformation Model</p></a></li>
<li><a href='#h1_init'><p>Initializes the Processed Additive Predictor for TM's Interaction</p></a></li>
<li><a href='#LehmanNN'><p>Lehmann-type neural network transformation models</p></a></li>
<li><a href='#LmNN'><p>Deep normal linear regression</p></a></li>
<li><a href='#nll'><p>Generic negative log-likelihood for transformation models</p></a></li>
<li><a href='#ontram'><p>Ordinal neural network transformation models</p></a></li>
<li><a href='#plot.deeptrafo'><p>Plot method for deep conditional transformation models</p></a></li>
<li><a href='#PolrNN'><p>Deep (proportional odds) logistic regression</p></a></li>
<li><a href='#SurvregNN'><p>Deep parametric survival regression</p></a></li>
<li><a href='#trafo_control'><p>Options for transformation models</p></a></li>
<li><a href='#trafoensemble'><p>Transformation ensembles</p></a></li>
<li><a href='#weighted_logLik'><p>Tune and evaluate weighted transformation ensembles</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Fitting Deep Conditional Transformation Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-0</td>
</tr>
<tr>
<td>Description:</td>
<td>Allows for the specification of deep conditional transformation 
    models (DCTMs) and ordinal neural network transformation models, as 
    described in Baumann et al (2021) &lt;<a href="https://doi.org/10.1007%2F978-3-030-86523-8_1">doi:10.1007/978-3-030-86523-8_1</a>&gt; and 
    Kook et al (2022) &lt;<a href="https://doi.org/10.1016%2Fj.patcog.2021.108263">doi:10.1016/j.patcog.2021.108263</a>&gt;. Extensions such as
    autoregressive DCTMs (Ruegamer et al, 2023, &lt;<a href="https://doi.org/10.1007%2Fs11222-023-10212-8">doi:10.1007/s11222-023-10212-8</a>&gt;)
    and transformation ensembles (Kook et al, 2022, &lt;<a href="https://doi.org/10.48550%2FarXiv.2205.12729">doi:10.48550/arXiv.2205.12729</a>&gt;)
    are implemented. The software package is described in Kook et al (2024,
    &lt;<a href="https://doi.org/10.18637%2Fjss.v111.i10">doi:10.18637/jss.v111.i10</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), tensorflow (&ge; 2.2.0), keras (&ge; 2.2.0),
tfprobability (&ge; 0.15), deepregression (&ge; 2.2.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, ordinal, tram, cotram, covr</td>
</tr>
<tr>
<td>Imports:</td>
<td>mlt, data.table, variables, stats, purrr, survival, R6,
Formula, reticulate</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/neural-structured-additive-learning/deeptrafo">https://github.com/neural-structured-additive-learning/deeptrafo</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/neural-structured-additive-learning/deeptrafo/issues">https://github.com/neural-structured-additive-learning/deeptrafo/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-12-03 14:51:24 UTC; lkook</td>
</tr>
<tr>
<td>Author:</td>
<td>Lucas Kook [aut, cre],
  Philipp Baumann [aut],
  David Ruegamer [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lucas Kook &lt;lucasheinrich.kook@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-03 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='atm_init'>Initializes the Processed Additive Predictor for ATMs</h2><span id='topic+atm_init'></span>

<h3>Description</h3>

<p>Initializes the Processed Additive Predictor for ATMs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>atm_init(atmnr, h1nr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="atm_init_+3A_atmnr">atmnr</code>, <code id="atm_init_+3A_h1nr">h1nr</code></td>
<td>
<p>positions of the atm and h1 formula</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a subnetwork_init function with pre-defined arguments
</p>

<hr>
<h2 id='BoxCoxNN'>BoxCox-type neural network transformation models</h2><span id='topic+BoxCoxNN'></span>

<h3>Description</h3>

<p>BoxCox-type neural network transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoxCoxNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "normal",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BoxCoxNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="BoxCoxNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    df &lt;- data.frame(y = rnorm(50), x = rnorm(50))
    m &lt;- BoxCoxNN(y ~ x, data = df)
    coef(m)
}

</code></pre>

<hr>
<h2 id='coef.deeptrafo'>S3 methods for deep conditional transformation models</h2><span id='topic+coef.deeptrafo'></span><span id='topic+predict.deeptrafo'></span><span id='topic+fitted.deeptrafo'></span><span id='topic+logLik.deeptrafo'></span><span id='topic+residuals.deeptrafo'></span><span id='topic+simulate.deeptrafo'></span><span id='topic+print.deeptrafo'></span><span id='topic+summary.deeptrafo'></span>

<h3>Description</h3>

<p>S3 methods for deep conditional transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'deeptrafo'
coef(
  object,
  which_param = c("shifting", "interacting", "autoregressive"),
  type = NULL,
  ...
)

## S3 method for class 'deeptrafo'
predict(
  object,
  newdata = NULL,
  type = c("trafo", "pdf", "cdf", "interaction", "shift", "terms"),
  batch_size = NULL,
  K = 100,
  q = NULL,
  pred_grid = FALSE,
  ...
)

## S3 method for class 'deeptrafo'
fitted(
  object,
  newdata = NULL,
  batch_size = NULL,
  convert_fun = as.matrix,
  call_create_lags = TRUE,
  ...
)

## S3 method for class 'deeptrafo'
logLik(
  object,
  newdata = NULL,
  convert_fun = function(x, ...) -sum(x, ...),
  ...
)

## S3 method for class 'deeptrafo'
residuals(object, newdata = NULL, return_gradients = FALSE, ...)

## S3 method for class 'deeptrafo'
simulate(object, nsim = 1, seed = NULL, newdata = NULL, ...)

## S3 method for class 'deeptrafo'
print(x, print_model = FALSE, print_coefs = TRUE, with_baseline = FALSE, ...)

## S3 method for class 'deeptrafo'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.deeptrafo_+3A_object">object</code></td>
<td>
<p>Object of class <code>"deeptrafo"</code>.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_which_param">which_param</code></td>
<td>
<p>Character; either <code>"shifting"</code>, <code>"interacting"</code>,
or <code>"autoregressive"</code> (only for autoregressive transformation models).</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_type">type</code></td>
<td>
<p>Either NULL (all types of coefficients are returned),
&quot;linear&quot; for linear coefficients or &quot;smooth&quot; for coefficients of;
Note that <code>type</code> is currently not used for <code>"interacting"</code>.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_...">...</code></td>
<td>
<p>Further arguments supplied to <code>print.deeptrafo</code></p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_newdata">newdata</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code>; optional new data.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer; optional, useful if data is too large.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_k">K</code></td>
<td>
<p>Integer; grid length for the response to evaluate predictions at,
if <code>newdata</code> does not contain the response.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_q">q</code></td>
<td>
<p>Numeric or factor; user-supplied grid of response values to evaluate
the predictions. Defaults to <code>NULL</code>. If overwritten, <code>K</code> is
ignored.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_pred_grid">pred_grid</code></td>
<td>
<p>Logical; set TRUE, if user provides a predefined grid for an
atp/atm model through newdata which holds two attributes. The first
attribute, rname, should hold the column name (string) of the response
variable while the second attribute, y, should hold the grid name.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_convert_fun">convert_fun</code></td>
<td>
<p>Function; applied to the log-likelihood values of all
observations.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_call_create_lags">call_create_lags</code></td>
<td>
<p>Logical; lags may already be computed by a different method (e.g. plot)</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_return_gradients">return_gradients</code></td>
<td>
<p>Return individual gradients instead of the summed
gradients; the residuals are <code>0.5 * rowSums(gradients)</code></p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_nsim">nsim</code></td>
<td>
<p>Integer; number of simulations; defaults to 1.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_seed">seed</code></td>
<td>
<p>Seed for generating samples; defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_x">x</code></td>
<td>
<p>Object of class <code>"deeptrafo"</code>.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_print_model">print_model</code></td>
<td>
<p>Logical; print keras model.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_print_coefs">print_coefs</code></td>
<td>
<p>Logical; print coefficients.</p>
</td></tr>
<tr><td><code id="coef.deeptrafo_+3A_with_baseline">with_baseline</code></td>
<td>
<p>Logical; print baseline coefs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no new data is supplied, predictions are computed on the training
data (i.e. in-sample). If new data is supplied without a response,
predictions are evaluated on a grid of length <code>K</code>.
</p>


<h3>Value</h3>

<p>Returns vector or matrix of predictions, depending on the supplied
<code>type</code>.
</p>
<p>Returns matrix of fitted values.
</p>

<hr>
<h2 id='ColrNN'>Deep continuous outcome logistic regression</h2><span id='topic+ColrNN'></span>

<h3>Description</h3>

<p>Deep continuous outcome logistic regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColrNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "logistic",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ColrNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="ColrNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="ColrNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    df &lt;- data.frame(y = rnorm(50), x = rnorm(50))
    m &lt;- ColrNN(y ~ x, data = df)
    coef(m)
}

</code></pre>

<hr>
<h2 id='cotramNN'>Deep distribution-free count regression</h2><span id='topic+cotramNN'></span>

<h3>Description</h3>

<p>Deep distribution-free count regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cotramNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "logistic",
  monitor_metrics = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cotramNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="cotramNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="cotramNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="cotramNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="cotramNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="cotramNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="cotramNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="cotramNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    set.seed(1)
    df &lt;- data.frame(y = as.integer(abs(1 + rnorm(50, sd = 10))), x = rnorm(50))
    m &lt;- cotramNN(y ~ 0 + x, data = df, order = 6)

    optimizer &lt;- optimizer_adam(learning_rate = 0.1, decay = 4e-4)
    m &lt;- cotramNN(y ~ 0 + x, data = df, optimizer = optimizer, order = 6)
    library(cotram)
    fit(m, epochs = 800L, validation_split = 0)
    logLik(mm &lt;- cotram(y ~ x, data = df, method = "logit")); logLik(m)
    coef(mm, with_baseline = TRUE); unlist(c(coef(m, which = "interacting"),
                                             coef(m, which = "shifting")))

}

</code></pre>

<hr>
<h2 id='CoxphNN'>Cox proportional hazards type neural network transformation models</h2><span id='topic+CoxphNN'></span>

<h3>Description</h3>

<p>Cox proportional hazards type neural network transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxphNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "gompertz",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CoxphNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="CoxphNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    df &lt;- data.frame(y = rnorm(50), x = rnorm(50))
    m &lt;- CoxphNN(y ~ x, data = df)
    coef(m)
}

</code></pre>

<hr>
<h2 id='dctm'>Deep conditional transformation models with alternative formula interface</h2><span id='topic+dctm'></span>

<h3>Description</h3>

<p>Deep conditional transformation models with alternative formula interface
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dctm(
  response,
  intercept = NULL,
  shift = NULL,
  shared = NULL,
  data,
  response_type = get_response_type(data[[all.vars(response)[1]]]),
  order = get_order(response_type, data[[all.vars(response)[1]]]),
  addconst_interaction = 0,
  latent_distr = "logistic",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dctm_+3A_response">response</code></td>
<td>
<p>Formula for the response; e.g. <code>~ y</code></p>
</td></tr>
<tr><td><code id="dctm_+3A_intercept">intercept</code></td>
<td>
<p>Formula for the intercept function; e.g., <code>~ x</code>,
for which interacting bases with the response will be set up</p>
</td></tr>
<tr><td><code id="dctm_+3A_shift">shift</code></td>
<td>
<p>Formula for the shift part of the model; e.g., <code>~ s(x)</code></p>
</td></tr>
<tr><td><code id="dctm_+3A_shared">shared</code></td>
<td>
<p>Formula for sharing weights between predictors in the intercept
and shift part of the model</p>
</td></tr>
<tr><td><code id="dctm_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="dctm_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="dctm_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="dctm_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="dctm_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="dctm_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="dctm_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="dctm_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
   df &lt;- data.frame(y = rnorm(50), x = rnorm(50))
   m &lt;- dctm(response = ~ y, shift = ~ 0 + x, data = df)
   coef(m)
}

</code></pre>

<hr>
<h2 id='deeptrafo'>Deep Conditional Transformation Models</h2><span id='topic+deeptrafo'></span>

<h3>Description</h3>

<p>Deep Conditional Transformation Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deeptrafo(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(fml)[1]]]),
  order = get_order(response_type, data[[all.vars(fml)[1]]]),
  addconst_interaction = 0,
  latent_distr = "logistic",
  loss = "nll",
  loss_args = NULL,
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  return_data = FALSE,
  engine = "tf",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deeptrafo_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_loss">loss</code></td>
<td>
<p>Character; specifies the loss function used. The default is
<code>"nll"</code>, an internal function which takes <code>latent_distr</code> as an
argument and returns a function with arguments <code>y_true</code> and
<code>y_pred</code> to be given to the underlying 'keras' model. Custom loss
functions can be supplied with the same structure, either as a character
or function.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_loss_args">loss_args</code></td>
<td>
<p>Further additional arguments to <code>loss</code>.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_return_data">return_data</code></td>
<td>
<p>Include full data in the returned object. Defaults to
<code>FALSE</code>. Set to <code>TRUE</code> if inteded to use
<code><a href="stats.html#topic+simulate">simulate</a></code> afterwards.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_engine">engine</code></td>
<td>
<p>Ignored; for compatibility with package <code>deepregression</code>.</p>
</td></tr>
<tr><td><code id="deeptrafo_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>deeptrafo</code> is the main function for setting up neural network
transformation models and is called by all aliases for the more special
cases (see e.g. <code><a href="#topic+ColrNN">ColrNN</a></code>). The naming convention
of the aliases follow the 'tram' package (see e.g. <code><a href="tram.html#topic+Colr">Colr</a></code>)
and add the suffix &quot;NN&quot; to the function name.
</p>


<h3>Value</h3>

<p>An object of class <code>c("deeptrafo", "deepregression")</code>
</p>


<h3>References</h3>

<p>Kook, L., Baumann, P. F., Dürr, O., Sick, B., &amp; Rügamer, D.
(2024). Estimating conditional distributions with neural networks using R
package deeptrafo. Journal of Statistical Software.
<a href="https://doi.org/10.18637/jss.v111.i10">doi:10.18637/jss.v111.i10</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
  reticulate::py_available() &amp;&amp;
  reticulate::py_module_available("tensorflow") &amp;&amp;
  reticulate::py_module_available("keras") &amp;&amp;
  reticulate::py_module_available("tensorflow_probability")) {
  data("wine", package = "ordinal")
  wine$z &lt;- rnorm(nrow(wine))
  wine$x &lt;- rnorm(nrow(wine))

  nn &lt;- \(x) x |&gt;
    layer_dense(input_shape = 1L, units = 2L, activation = "relu") |&gt;
    layer_dense(1L)

  fml &lt;- rating ~ 0 + temp + contact + s(z, df = 3) + nn(x)

  m &lt;- deeptrafo(fml, wine,
    latent_distr = "logistic", monitor_metric = NULL,
    return_data = TRUE, list_of_deep_models = list(nn = nn)
  )

  print(m)

  m %&gt;% fit(epochs = 10, batch_size = nrow(wine))
  coef(m, which_param = "interacting")
  coef(m, which_param = "shifting")
  fitted(m)
  predict(m, type = "pdf")
  predict(m, type = "pdf", newdata = wine[, -2])
  logLik(m)
  logLik(m, newdata = wine[1:10, ])
  plot(m)
  mcv &lt;- cv(m, cv_folds = 3)
  ens &lt;- ensemble(m, n_ensemble = 3)
  coef(ens)
}

</code></pre>

<hr>
<h2 id='ensemble.deeptrafo'>Deep ensembling for neural network transformation models</h2><span id='topic+ensemble.deeptrafo'></span>

<h3>Description</h3>

<p>Deep ensembling for neural network transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'deeptrafo'
ensemble(
  x,
  n_ensemble = 5,
  reinitialize = TRUE,
  mylapply = lapply,
  verbose = FALSE,
  patience = 20,
  plot = TRUE,
  print_members = TRUE,
  stop_if_nan = TRUE,
  save_weights = TRUE,
  callbacks = list(),
  save_fun = NULL,
  seed = seq_len(n_ensemble),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ensemble.deeptrafo_+3A_x">x</code></td>
<td>
<p>Object of class <code>"deeptrafo"</code>.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_n_ensemble">n_ensemble</code></td>
<td>
<p>Numeric; number of ensemble members to fit.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_reinitialize">reinitialize</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), model weights are
initialized randomly prior to fitting each member. Fixed weights are
not affected.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_mylapply">mylapply</code></td>
<td>
<p>Function; <code>lapply</code> function to be used; defaults to
<code>lapply</code></p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_verbose">verbose</code></td>
<td>
<p>Logical; whether to print training in each fold.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_patience">patience</code></td>
<td>
<p>Integer; number of patience for early stopping.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_plot">plot</code></td>
<td>
<p>Logical; whether to plot the resulting losses in each fold.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_print_members">print_members</code></td>
<td>
<p>Logical; print results for each member.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_stop_if_nan">stop_if_nan</code></td>
<td>
<p>Logical; whether to stop ensembling if <code>NaN</code> values
occur</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_save_weights">save_weights</code></td>
<td>
<p>Logical; whether to save the ensemble weights.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_callbacks">callbacks</code></td>
<td>
<p>List; callbacks used for fitting.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_save_fun">save_fun</code></td>
<td>
<p>Function; function to be applied to each member to be stored
in the final result.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_seed">seed</code></td>
<td>
<p>Numeric vector of length <code>n_ensemble</code>; seeds for model
initialization.</p>
</td></tr>
<tr><td><code id="ensemble.deeptrafo_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>object$fit_fun</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ensemble of <code>"deeptrafo"</code> models with list of training histories
and fitted weights included in <code>ensemble_results</code>. For details see
the return statment in <code><a href="deepregression.html#topic+ensemble">ensemble</a></code>.
</p>

<hr>
<h2 id='from_preds_to_trafo'>Define Predictor of Transformation Model</h2><span id='topic+from_preds_to_trafo'></span>

<h3>Description</h3>

<p>Define Predictor of Transformation Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>from_preds_to_trafo(
  atm_toplayer = function(x) layer_dense(x, units = 1L, name = "atm_toplayer"),
  const_ia = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="from_preds_to_trafo_+3A_atm_toplayer">atm_toplayer</code></td>
<td>
<p>Function to be applied on top of the transformed lags.</p>
</td></tr>
<tr><td><code id="from_preds_to_trafo_+3A_const_ia">const_ia</code></td>
<td>
<p>See <code>addconst_interaction</code> in <code><a href="#topic+deeptrafo">deeptrafo</a></code>
or <code><a href="deepregression.html#topic+deepregression">deepregression</a></code>.</p>
</td></tr>
<tr><td><code id="from_preds_to_trafo_+3A_...">...</code></td>
<td>
<p>For compatibility with 'deepregression'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not intended to be used directly by the end user.
</p>


<h3>Value</h3>

<p>A function of <code>list_pred_param</code> returning a list of output tensors
that is passed to <code>model_fun</code> of <code>deepregression</code>
</p>

<hr>
<h2 id='h1_init'>Initializes the Processed Additive Predictor for TM's Interaction</h2><span id='topic+h1_init'></span>

<h3>Description</h3>

<p>Initializes the Processed Additive Predictor for TM's Interaction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h1_init(yterms, h1pred, add_const_positiv = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="h1_init_+3A_yterms">yterms</code></td>
<td>
<p>Terms for the response</p>
</td></tr>
<tr><td><code id="h1_init_+3A_h1pred">h1pred</code></td>
<td>
<p>Interacting predictor</p>
</td></tr>
<tr><td><code id="h1_init_+3A_add_const_positiv">add_const_positiv</code></td>
<td>
<p>Shift basis for the predictors to be strictly
positive</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a subnetwork_init function with pre-defined arguments
</p>

<hr>
<h2 id='LehmanNN'>Lehmann-type neural network transformation models</h2><span id='topic+LehmanNN'></span>

<h3>Description</h3>

<p>Lehmann-type neural network transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LehmanNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "gumbel",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LehmanNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="LehmanNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    df &lt;- data.frame(y = rnorm(50), x = rnorm(50))
    m &lt;- LehmanNN(y ~ 0 + x, data = df)
    coef(m)
}

</code></pre>

<hr>
<h2 id='LmNN'>Deep normal linear regression</h2><span id='topic+LmNN'></span>

<h3>Description</h3>

<p>Deep normal linear regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LmNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "normal",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = 1L, response_type = response_type,
    y_basis_fun = eval_lin, y_basis_fun_lower = .empty_fun(eval_lin), y_basis_fun_prime =
    eval_lin_prime, basis = "shiftscale"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LmNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="LmNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="LmNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="LmNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="LmNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="LmNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="LmNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="LmNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="LmNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    set.seed(1)
    df &lt;- data.frame(y = 10 + rnorm(50), x = rnorm(50))
    m &lt;- LmNN(y ~ 0 + x, data = df)

    optimizer &lt;- optimizer_adam(learning_rate = 0.01, decay = 4e-4)
    m &lt;- LmNN(y ~ 0 + x, data = df, optimizer = optimizer)
    library(tram)
    fit(m, epochs = 900L, validation_split = 0)
    logLik(mm &lt;- Lm(y ~ x, data = df)); logLik(m)
    coef(mm, with_baseline = TRUE); unlist(c(coef(m, which = "interacting"),
                                             coef(m, which = "shifting")))

}

</code></pre>

<hr>
<h2 id='nll'>Generic negative log-likelihood for transformation models</h2><span id='topic+nll'></span>

<h3>Description</h3>

<p>Generic negative log-likelihood for transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nll(latent_distr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nll_+3A_latent_distr">latent_distr</code></td>
<td>
<p>Target distribution, character or
<code>tfd_distribution</code>. If character, can be either &quot;logistic&quot;,
&quot;normal&quot;, &quot;gumbel&quot;, &quot;gompertz&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function for computing the negative log-likelihood of a
neural network transformation model with generic response.
</p>

<hr>
<h2 id='ontram'>Ordinal neural network transformation models</h2><span id='topic+ontram'></span>

<h3>Description</h3>

<p>Ordinal neural network transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ontram(
  response,
  intercept = NULL,
  shift = NULL,
  shared = NULL,
  data,
  response_type = "ordered",
  order = get_order(response_type, data[[all.vars(response)[1]]]),
  addconst_interaction = 0,
  latent_distr = "logistic",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ontram_+3A_response">response</code></td>
<td>
<p>Formula for the response; e.g., <code>~ y</code></p>
</td></tr>
<tr><td><code id="ontram_+3A_intercept">intercept</code></td>
<td>
<p>Formula for the intercept function; e.g., <code>~ x</code>,
for which interacting bases with the response will be set up</p>
</td></tr>
<tr><td><code id="ontram_+3A_shift">shift</code></td>
<td>
<p>Formula for the shift part of the model; e.g., <code>~ s(x)</code></p>
</td></tr>
<tr><td><code id="ontram_+3A_shared">shared</code></td>
<td>
<p>Formula for sharing weights between predictors in the intercept
and shift part of the model</p>
</td></tr>
<tr><td><code id="ontram_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="ontram_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="ontram_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="ontram_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="ontram_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="ontram_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="ontram_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="ontram_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>References</h3>

<p>Kook, L. &amp; Herzog, L., Hothorn, T., Dürr, O., &amp; Sick, B. (2022).
Deep and interpretable regression models for ordinal outcomes.
Pattern Recognition, 122, 108263. DOI 10.1016/j.patcog.2021.108263
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    df &lt;- data.frame(y = ordered(sample.int(6, 50, TRUE)), x = rnorm(50))
    m &lt;- ontram(response = ~ y, shift = ~ x, data = df)
    coef(m)
}

</code></pre>

<hr>
<h2 id='plot.deeptrafo'>Plot method for deep conditional transformation models</h2><span id='topic+plot.deeptrafo'></span>

<h3>Description</h3>

<p>Plot method for deep conditional transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'deeptrafo'
plot(
  x,
  which = NULL,
  type = c("smooth", "trafo", "pdf", "cdf"),
  newdata = NULL,
  which_param = c("shifting", "interacting"),
  only_data = FALSE,
  K = 40,
  q = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.deeptrafo_+3A_x">x</code></td>
<td>
<p>Object of class <code>"deeptrafo"</code>.</p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_which">which</code></td>
<td>
<p>Which effect to plot, default selects all smooth effects in the
shift term.</p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_type">type</code></td>
<td>
<p>Character; One of &quot;smooth&quot;, &quot;trafo&quot;, &quot;pdf&quot;, or &quot;cdf&quot;.</p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_newdata">newdata</code></td>
<td>
<p>Optional new data (<code>list</code> or <code>data.frame</code>) to
evaluate predictions at. If the response is missing, plots are generated
on a grid of length <code>K</code></p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_which_param">which_param</code></td>
<td>
<p>Character; either <code>"interacting"</code> or <code>"shifting"</code>.</p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_only_data">only_data</code></td>
<td>
<p>Logical, if <code>TRUE</code>, only the data for plotting is returned.</p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_k">K</code></td>
<td>
<p>Integer; If <code>type == "smooth"</code> the length of an equidistant
grid at which a two-dimensional function is evaluated for plotting.
Otherwise, length of the grid to evaluate predictions at,
see <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_q">q</code></td>
<td>
<p>Vector of response values to compute predictions at, see <code>newdata</code></p>
</td></tr>
<tr><td><code id="plot.deeptrafo_+3A_...">...</code></td>
<td>
<p>Further arguments, passed to fit, plot or predict function</p>
</td></tr>
</table>

<hr>
<h2 id='PolrNN'>Deep (proportional odds) logistic regression</h2><span id='topic+PolrNN'></span>

<h3>Description</h3>

<p>Deep (proportional odds) logistic regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PolrNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "logistic",
  monitor_metrics = NULL,
  trafo_options = trafo_control(order_bsp = order, response_type = response_type),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PolrNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="PolrNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="PolrNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    df &lt;- data.frame(y = ordered(sample.int(5, 50, replace = TRUE)),
                     x = rnorm(50))
    m &lt;- PolrNN(y ~ x, data = df)
    coef(m)
}

</code></pre>

<hr>
<h2 id='SurvregNN'>Deep parametric survival regression</h2><span id='topic+SurvregNN'></span>

<h3>Description</h3>

<p>Deep parametric survival regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvregNN(
  formula,
  data,
  response_type = get_response_type(data[[all.vars(formula)[1]]]),
  order = get_order(response_type, data[[all.vars(formula)[1]]]),
  addconst_interaction = 0,
  latent_distr = "gompertz",
  monitor_metrics = NULL,
  trafo_options = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvregNN_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response. One of <code>"continuous"</code>,
<code>"survival"</code>, <code>"count"</code>, or <code>"ordered"</code>. If not supplied
manually it is determined by the first entry in <code>data[[response]]</code>.</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_order">order</code></td>
<td>
<p>Integer; order of the response basis. Default 10 for Bernstein
basis or number of levels minus one for ordinal responses.</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_addconst_interaction">addconst_interaction</code></td>
<td>
<p>Positive constant;
a constant added to the additive predictor of the interaction term.
If <code>NULL</code>, terms are left unchanged. If 0 and predictors have
negative values in their design matrix, the minimum value of all predictors
is added to ensure positivity. If &gt; 0, the minimum value plus the
<code>addconst_interaction</code> is added to each predictor in the interaction
term. This ensures a monotone non-decreasing transformation function in
the response when using (tensor product) spline bases in the interacting
term.</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_latent_distr">latent_distr</code></td>
<td>
<p>A <code>tfd_distribution</code> or character; the base distribution for
transformation models. If character, can be <code>"normal"</code>, <code>"logistic"</code>,
<code>"gumbel"</code> or <code>"gompertz"</code>.</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_monitor_metrics">monitor_metrics</code></td>
<td>
<p>See <code><a href="deepregression.html#topic+deepregression">deepregression</a></code></p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_trafo_options">trafo_options</code></td>
<td>
<p>Options for transformation models such as the basis
function used, see <code><a href="#topic+trafo_control">trafo_control</a></code> for more details.</p>
</td></tr>
<tr><td><code id="SurvregNN_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>deepregression</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>See return statement of <code><a href="#topic+deeptrafo">deeptrafo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (.Platform$OS.type != "windows" &amp;&amp;
    reticulate::py_available() &amp;&amp;
    reticulate::py_module_available("tensorflow") &amp;&amp;
    reticulate::py_module_available("keras") &amp;&amp;
    reticulate::py_module_available("tensorflow_probability")) {
    set.seed(1)
    df &lt;- data.frame(y = abs(1 + rnorm(50)), x = rnorm(50))
    m &lt;- SurvregNN(y ~ 0 + x, data = df)

    optimizer &lt;- optimizer_adam(learning_rate = 0.01, decay = 4e-4)
    m &lt;- SurvregNN(y ~ 0 + x, data = df, optimizer = optimizer)
    library(tram)
    fit(m, epochs = 500L, validation_split = 0)
    logLik(mm &lt;- Survreg(y ~ x, data = df, dist = "loglogistic")); logLik(m)
    coef(mm, with_baseline = TRUE); unlist(c(coef(m, which = "interacting"),
                                             coef(m, which = "shifting")))

}

</code></pre>

<hr>
<h2 id='trafo_control'>Options for transformation models</h2><span id='topic+trafo_control'></span>

<h3>Description</h3>

<p>Options for transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trafo_control(
  order_bsp = 10L,
  support = function(y) range(y),
  y_basis_fun = NULL,
  y_basis_fun_lower = NULL,
  y_basis_fun_prime = NULL,
  penalize_bsp = 0,
  order_bsp_penalty = 2,
  tf_bsps = FALSE,
  response_type = c("continuous", "ordered", "survival", "count"),
  atm_toplayer = function(x) {
     layer_dense(x, units = 1L, name = "atm_toplayer",
    use_bias = FALSE)
 },
  basis = c("bernstein", "ordered", "shiftscale")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trafo_control_+3A_order_bsp">order_bsp</code></td>
<td>
<p>The order of Bernstein polynomials in case <code>y_basis_fun</code>
is a Bernstein polynomial defined by <code>eval_bsp</code> or (one less than)
the number of classes of an ordinal outcome.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_support">support</code></td>
<td>
<p>A function returning a vector with two elements, namely
the support for the basis of y.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_y_basis_fun">y_basis_fun</code></td>
<td>
<p>Function; basis function for Y</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_y_basis_fun_lower">y_basis_fun_lower</code></td>
<td>
<p>Function; basis function for lower bound of interval
censored response</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_y_basis_fun_prime">y_basis_fun_prime</code></td>
<td>
<p>Function; basis function derivative</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_penalize_bsp">penalize_bsp</code></td>
<td>
<p>Scalar value &gt; 0; controls amount of penalization of
Bernstein polynomials.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_order_bsp_penalty">order_bsp_penalty</code></td>
<td>
<p>Integer; order of Bernstein polynomial penalty. 0
results in a penalty based on integrated squared second order derivatives,
values &gt;= 1 in difference penalties.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_tf_bsps">tf_bsps</code></td>
<td>
<p>Logical; whether to use a TensorFlow implementation of the
Bernstein polynomial functions.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_response_type">response_type</code></td>
<td>
<p>Character; type of response can be continuous, ordered,
survival, or count.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_atm_toplayer">atm_toplayer</code></td>
<td>
<p>Function; a function specifying the layer on top of ATM
lags.</p>
</td></tr>
<tr><td><code id="trafo_control_+3A_basis">basis</code></td>
<td>
<p>Character or function; implemented options are
<code>"bernstein"</code> (a Bernstein polynomial basis), <code>"ordered"</code>
(for ordinal responses), or <code>"shiftscale"</code> for (log-) linear bases</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a named <code>list</code> with all options, basis functions,
support, and penalties.
</p>

<hr>
<h2 id='trafoensemble'>Transformation ensembles</h2><span id='topic+trafoensemble'></span>

<h3>Description</h3>

<p>Transformation ensembles
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trafoensemble(
  formula,
  data,
  n_ensemble = 5,
  verbose = FALSE,
  print_members = TRUE,
  stop_if_nan = TRUE,
  save_weights = TRUE,
  callbacks = list(),
  save_fun = NULL,
  seed = seq_len(n_ensemble),
  tf_seeds = seq_len(n_ensemble),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trafoensemble_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the response, interaction, shift terms
as <code>response | interacting ~ shifting</code>.
auto-regressive transformation models (ATMs).</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_data">data</code></td>
<td>
<p>Named <code>list</code> or <code>data.frame</code> which may contain both
structured and unstructured data.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_n_ensemble">n_ensemble</code></td>
<td>
<p>Numeric; number of ensemble members to fit.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_verbose">verbose</code></td>
<td>
<p>Logical; whether to print training in each fold.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_print_members">print_members</code></td>
<td>
<p>Logical; print results for each member.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_stop_if_nan">stop_if_nan</code></td>
<td>
<p>Logical; whether to stop ensembling if <code>NaN</code> values
occur</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_save_weights">save_weights</code></td>
<td>
<p>Logical; whether to save the ensemble weights.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_callbacks">callbacks</code></td>
<td>
<p>List; callbacks used for fitting.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_save_fun">save_fun</code></td>
<td>
<p>Function; function to be applied to each member to be stored
in the final result.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_seed">seed</code></td>
<td>
<p>Numeric vector of length <code>n_ensemble</code>; seeds for model
re-initialization. Changing these seeds does not change the  parameters
of the interacting predictor <code>coef(obj, which_param = "interacting")</code>,
change <code>tf_seeds</code> to adapt those coefficients.</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_tf_seeds">tf_seeds</code></td>
<td>
<p>Numeric vector of length <code>n_ensemble</code>; explicit seed for
changing the parameters of the interacting predictor. Distinct from
<code>seed</code> which is used for weight re-initialization of the rest of the
model (i.e., the shifting predictor and potential neural network components
in the interacting component).</p>
</td></tr>
<tr><td><code id="trafoensemble_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>deeptrafo</code> and <code>fit</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ensemble of <code>"deeptrafo"</code> models with list of training histories
and fitted weights included in <code>ensemble_results</code>. For details see
the return statment in <code><a href="deepregression.html#topic+ensemble">ensemble</a></code>.
</p>

<hr>
<h2 id='weighted_logLik'>Tune and evaluate weighted transformation ensembles</h2><span id='topic+weighted_logLik'></span>

<h3>Description</h3>

<p>Tune and evaluate weighted transformation ensembles
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted_logLik(
  object,
  weights = NULL,
  newdata = NULL,
  convert_fun = function(x, ...) mean(x, ...),
  batch_size = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted_logLik_+3A_object">object</code></td>
<td>
<p>Object of class <code>"dtEnsemble"</code></p>
</td></tr>
<tr><td><code id="weighted_logLik_+3A_weights">weights</code></td>
<td>
<p>Numeric; weight-vector of length <code>n_ensemble</code>, if
<code>NULL</code> the weights are tuned on <code>newdata</code></p>
</td></tr>
<tr><td><code id="weighted_logLik_+3A_newdata">newdata</code></td>
<td>
<p>List or data.frame; new data to evaluate or tune the weights
on</p>
</td></tr>
<tr><td><code id="weighted_logLik_+3A_convert_fun">convert_fun</code></td>
<td>
<p>Function; applied to the log-likelihood values of all
observations.</p>
</td></tr>
<tr><td><code id="weighted_logLik_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer; optional, useful if data is too large.</p>
</td></tr>
<tr><td><code id="weighted_logLik_+3A_...">...</code></td>
<td>
<p>Further arguments supplied to <code>print.deeptrafo</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns list of ensemble members, average, and ensemble
log-likelihood converted by <code>convert_fun</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
