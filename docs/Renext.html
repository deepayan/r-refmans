<!DOCTYPE html><html><head><title>Help for package Renext</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Renext}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Renext-package'>
<p>Renewal Method for Extreme Values Extrapolation</p>
</p></a></li>
<li><a href='#anova.Renouv'>
<p>Compute an analysis of deviance table for two nested Renouv</p>
objects</a></li>
<li><a href='#barplotRenouv'><p>Barplot for Renouv &quot;Over Threshold&quot; counts</p></a></li>
<li><a href='#Brest'><p>Surge heights at Brest</p></a></li>
<li><a href='#Brest.years'><p>Surge heights at Brest partial data</p></a></li>
<li><a href='#Brest.years.missing'><p>Years with missing periods in 'Brest.year' dataset</p></a></li>
<li><a href='#CV2'><p>Squared Coefficient of Variation</p></a></li>
<li><a href='#CV2.test'><p>CV2 test of exponentiality</p></a></li>
<li><a href='#Dunkerque'><p>Surge heights at Dunkerque</p></a></li>
<li><a href='#EM.mixexp'>
<p>Expectation-Maximisation for a mixture of exponential distributions</p>
</p></a></li>
<li><a href='#expplot'>
<p>Classical &quot;exponential distribution&quot; plot</p>
</p></a></li>
<li><a href='#fgamma'><p>ML estimation of the Gamma distribution</p></a></li>
<li><a href='#fGEV.MAX'>
<p>Fit a GEV distribution from block maxima or r largest order statistics</p>
using an aggregated Renewal POT process
</p></a></li>
<li><a href='#fGPD'>
<p>Fit a two-parameters Generalised Pareto Distribution from a sample</p>
</p></a></li>
<li><a href='#flomax'>
<p>ML estimation of the Lomax distribution</p>
</p></a></li>
<li><a href='#fmaxlo'>
<p>ML estimation of a 'maxlo' distribution</p>
</p></a></li>
<li><a href='#fweibull'>
<p>ML estimation of classical Weibull distribution</p>
</p></a></li>
<li><a href='#Garonne'>
<p>Flow of the french river La Garonne</p></a></li>
<li><a href='#gev2Ren'>
<p>Translate a vector of GEV parameters into renewal  model</p></a></li>
<li><a href='#gof.date'><p>Goodness-of-fit for the distribution of dates</p></a></li>
<li><a href='#gofExp.test'><p>Goodness-of-fit test for exponential distribution</p></a></li>
<li><a href='#GPD'><p>Generalised Pareto Distribution</p></a></li>
<li><a href='#gumbel2Ren'>
<p>Translate a vector of Gumbel parameters into a vector of parameters</p>
for a renewal model</a></li>
<li><a href='#Hpoints'><p>Plotting positions for exponential return levels</p></a></li>
<li><a href='#ini.mixexp2'>
<p>Simple  estimation for the mixture of two exponential distributions</p>
</p></a></li>
<li><a href='#interevt'><p>Interevents (or interarrivals) from events dates</p></a></li>
<li><a href='#Jackson'><p>Jackson's statistic</p></a></li>
<li><a href='#Jackson.test'><p>Jackson's test of exponentiality</p></a></li>
<li><a href='#logLik.Renouv'>
<p>Log-likelihood of a &quot;Renouv&quot; object</p></a></li>
<li><a href='#Lomax'><p>Lomax distribution</p></a></li>
<li><a href='#LRExp'><p>Likelihood Ratio statistic for exponential vs. GPD</p></a></li>
<li><a href='#LRExp.test'><p>Likelihood Ratio test of exponentiality vs. GPD</p></a></li>
<li><a href='#LRGumbel'><p>Likelihood Ratio statistic for Gumbel vs. GEV</p></a></li>
<li><a href='#LRGumbel.test'><p>Likelihood Ratio test for the Gumbel distribution</p></a></li>
<li><a href='#Maxlo'><p>'maxlo' distribution</p></a></li>
<li><a href='#MixExp2'><p>Mixture of two exponential distributions</p></a></li>
<li><a href='#mom.mixexp2'>
<p>Moment estimation for the mixture of two exponential distributions</p>
</p></a></li>
<li><a href='#mom2par'><p>Parameters from moments</p></a></li>
<li><a href='#NBlevy'><p>Negative Binomial Levy process</p></a></li>
<li><a href='#OT2MAX'><p>Temporal aggregation of a Marked Process</p></a></li>
<li><a href='#OTjitter'>
<p>Add a small amount of noise to a numeric vector</p></a></li>
<li><a href='#parDeriv'>
<p>Derivation of probability functions with respect to the parameters</p></a></li>
<li><a href='#parIni.MAX'>
<p>Initial estimation of GPD parameters for an aggregated renewal model</p>
</p></a></li>
<li><a href='#pGreenwood1'><p>Probability that the Greenwood's statistic is smaller than one</p></a></li>
<li><a href='#plot.Rendata'><p>Plot a Rendata object</p></a></li>
<li><a href='#plot.Renouv'>
<p>Plot an object of class &quot;Renouv&quot;</p>
</p></a></li>
<li><a href='#PPplot'>
<p>Diagnostic plots for Renouv objects</p></a></li>
<li><a href='#predict.Renouv'>
<p>Compute return levels and confidence limits for a &quot;Renouv&quot; object</p></a></li>
<li><a href='#qStat'><p>Quantiles of a test statistic</p></a></li>
<li><a href='#readXML'><p>Read data using an XML index file</p></a></li>
<li><a href='#Ren2gev'>
<p>Translate a vector of coefficients from a Renewal-POT model with</p>
Pareto excesses into a vector of GEV parameters
</p></a></li>
<li><a href='#Ren2gumbel'>
<p>Translate a vector of coefficients from a Renewal-POT model with</p>
exponential excesses to a vector of Gumbel parameters
</p></a></li>
<li><a href='#Renouv'>
<p>Fit a 'Renouvellement' model</p></a></li>
<li><a href='#RenouvNoEst'>
<p>Define a 'renouvellement' model without estimation</p></a></li>
<li><a href='#RLlegend'>
<p>Legend management for return level plots</p>
</p></a></li>
<li><a href='#RLpar'>
<p>Graphical parameters for Return Level plots</p></a></li>
<li><a href='#RLplot'><p>Return level plot</p></a></li>
<li><a href='#roundPred'>
<p>Round quantiles in a pseudo-prediction table</p></a></li>
<li><a href='#rRendata'>
<p>Simulate a random RenData object</p>
</p></a></li>
<li><a href='#SandT'>
<p>Compute empirical survivals (S) and return periods (T)</p>
</p></a></li>
<li><a href='#skip2noskip'>
<p>Fix non-skipped periods from skipped ones</p>
</p></a></li>
<li><a href='#SLTW'><p>Shifted Left Truncated Weibull (SLTW) distribution</p></a></li>
<li><a href='#spacings'>
<p>Methods computing spacings between Largest Order Statistics</p>
</p></a></li>
<li><a href='#summary.Rendata'>
<p>Summary and  print methods for &quot;Rendata&quot; objects</p></a></li>
<li><a href='#summary.Renouv'><p>Summary and print methods for &quot;Renouv&quot; objects</p></a></li>
<li><a href='#translude'><p>Make translucient colors</p></a></li>
<li><a href='#vcov.Renouv'>
<p>Variance-covariance matrix of the estimates of a &quot;Renouv&quot; object</p>
</p></a></li>
<li><a href='#weibplot'><p>Classical Weibull distribution plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Renewal Method for Extreme Values Extrapolation</td>
</tr>
<tr>
<td>Version:</td>
<td>3.1-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Yves Deville &lt;deville.yves@alpestat.com&gt;, Lise Bardet &lt;lise.bardet@irsn.fr&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yann Richet &lt;yann.richet@irsn.fr&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/IRSN/Renext">https://github.com/IRSN/Renext</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.8.0), stats, graphics, evd</td>
</tr>
<tr>
<td>Imports:</td>
<td>numDeriv, splines, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, ismev, XML</td>
</tr>
<tr>
<td>Description:</td>
<td>Peaks Over Threshold (POT) or 'methode du renouvellement'. The
    distribution for the excesses can be chosen, and heterogeneous data
    (including historical data or block data) can be used in a
    Maximum-Likelihood framework. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-29 15:27:46 UTC; richet</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-29 18:10:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='Renext-package'>
Renewal Method for Extreme Values Extrapolation
</h2><span id='topic+Renext-package'></span><span id='topic+Renext'></span>

<h3>Description</h3>

<p>This package proposes fits and diagnostics for the so-called
<em>méthode du renouvellement</em>, an alternative to other &quot;Peaks Over
Threshold&quot; (POT) methods.  The <em>méthode du renouvellement</em>
generalises the classical POT by allowing the excesses over the
threshold to follow a probability distribution which can differ from
the Generalised Pareto Distribution (GPD). Weibull or gamma
excesses are sometimes preferred to GPD excesses. The special
case of exponential excesses (which falls in the three families:
GPD, Weibull and gamma) has a special interest since it allows exact
inference for the (scalar) parameter and for the quantiles form OT
data (only).
</p>
<p>The package allows the joint use of possibly three kinds of data or
information. The first kind is <em>classical excesses</em>, or
<em>&quot;OT data&quot;</em>. It can be completed with two kinds of data
resulting from a temporal aggregation, as is often the case for
<em>historical data</em>. Both types are optional, and concern periods
or <em>blocks</em> that must not overlap nor cross the OT period.
</p>

<ul>
<li> <p><em>MAX data</em> correspond to the case where one knows the
<code class="reqn">r</code> largest observations over each block. The number
<code class="reqn">r</code> may vary across blocks. This kind of data is often
called '<code class="reqn">r</code> largest', or &quot;<code class="reqn">r</code> Largest Order
Statistics&quot; (<code class="reqn">r</code> LOS).
</p>
</li>
<li> <p><em>OTS data</em> (for OT Supplementary data) correspond to the
case where one knows for each block <code class="reqn">b</code> all the observations
that exceeded a threshold <code class="reqn">u_b</code> which is greater (usually
much greater) than the main threshold <code class="reqn">u</code>. The number
<code class="reqn">r_b</code> of such observations can be zero, in which case we
may say that <code class="reqn">u_b</code> is an <em>unobserved level</em>. A
threshold <code class="reqn">u_b</code> is sometimes called a <em>perception
threshold</em>.
</p>
</li></ul>

<p>Historical data are often available in hydrology (e.g. for river flood
discharges, for sea-levels or sea surges) and can concern large
periods such as past centuries. An unobserved level can typically be
related to a material benchmark.
</p>
<p>Maximum likelihood estimation is made possible in this context of
heterogeneous data. Inference is based on the asymptotic normality of
parameter vector estimate and on linearisation (&quot;delta method&quot;) for
quantiles or parameter functions.
</p>
<p>The package allows the use of &quot;marked-process observations&quot; data
(datetime of event and level) where an interevent analysis can be
useful. It also allows the event dates to be unknown and replaced
by a much broader <em>block</em> indication, e.g. a year number. The
key point is then that the &quot;effective duration&quot; (total duration of
observation periods) is known. Event counts for blocks can be used to
check the assumption of Poisson-distributed events.
</p>
<p>The package development was initiated, directed and financed by the
french <em>Institut de Radioprotection et de Sûreté
Nucléaire</em> (IRSN). The package is a non-academic
tool designed for applied analysis on case studies and investigations
or comparisons on classical probabilistic models.
</p>




<h3>Details</h3>









<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Renext</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Renewal Method for Extreme Values Extrapolation</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 3.1-4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-08-29</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Yves Deville &lt;deville.yves@alpestat.com&gt;, Lise Bardet &lt;lise.bardet@irsn.fr&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Yann Richet &lt;yann.richet@irsn.fr&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> https://github.com/IRSN/Renext</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.8.0), stats, graphics, evd</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> numDeriv, splines, methods</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> MASS, ismev, XML</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Peaks Over Threshold (POT) or 'methode du renouvellement'. The
    distribution for the excesses can be chosen, and heterogeneous data
    (including historical data or block data) can be used in a
    Maximum-Likelihood framework. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyData: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
Brest                   Surge heights at Brest
Brest.years             Surge heights at Brest partial data
Brest.years.missing     Years with missing periods in 'Brest.year'
                        dataset
CV2                     Squared Coefficient of Variation
CV2.test                CV2 test of exponentiality
Dunkerque               Surge heights at Dunkerque
EM.mixexp               Expectation-Maximisation for a mixture of
                        exponential distributions
GPD                     Generalised Pareto Distribution
Garonne                 Flow of the french river La Garonne
Hpoints                 Plotting positions for exponential return
                        levels
Jackson                 Jackson's statistic
Jackson.test            Jackson's test of exponentiality
LRExp                   Likelihood Ratio statistic for exponential vs.
                        GPD
LRExp.test              Likelihood Ratio test of exponentiality vs. GPD
LRGumbel                Likelihood Ratio statistic for Gumbel vs. GEV
LRGumbel.test           Likelihood Ratio test for the Gumbel
                        distribution
Lomax                   Lomax distribution
Maxlo                   'maxlo' distribution
MixExp2                 Mixture of two exponential distributions
NBlevy                  Negative Binomial Levy process
OT2MAX                  Temporal aggregation of a Marked Process
OTjitter                Add a small amount of noise to a numeric vector
PPplot                  Diagnostic plots for Renouv objects
RLlegend                Legend management for return level plots
RLpar                   Graphical parameters for Return Level plots
RLplot                  Return level plot
Ren2gev                 Translate a vector of coefficients from a
                        Renewal-POT model with Pareto excesses into a
                        vector of GEV parameters
Ren2gumbel              Translate a vector of coefficients from a
                        Renewal-POT model with exponential excesses to
                        a vector of Gumbel parameters
Renext-package          Renewal Method for Extreme Values Extrapolation
Renouv                  Fit a 'Renouvellement' model
RenouvNoEst             Define a 'renouvellement' model without
                        estimation
SLTW                    Shifted Left Truncated Weibull (SLTW)
                        distribution
SandT                   Compute empirical survivals (S) and return
                        periods (T)
anova.Renouv            Compute an analysis of deviance table for two
                        nested Renouv objects
barplotRenouv           Barplot for Renouv "Over Threshold" counts
expplot                 Classical "exponential distribution" plot
fGEV.MAX                Fit a GEV distribution from block maxima or r
                        largest order statistics using an aggregated
                        Renewal POT process
fGPD                    Fit a two-parameters Generalised Pareto
                        Distribution from a sample
fgamma                  ML estimation of the Gamma distribution
flomax                  ML estimation of the Lomax distribution
fmaxlo                  ML estimation of a 'maxlo' distribution
fweibull                ML estimation of classical Weibull distribution
gev2Ren                 Translate a vector of GEV parameters into
                        renewal model
gof.date                Goodness-of-fit for the distribution of dates
gofExp.test             Goodness-of-fit test for exponential
                        distribution
gumbel2Ren              Translate a vector of Gumbel parameters into a
                        vector of parameters for a renewal model
ini.mixexp2             Simple estimation for the mixture of two
                        exponential distributions
interevt                Interevents (or interarrivals) from events
                        dates
logLik.Renouv           Log-likelihood of a "Renouv" object
mom.mixexp2             Moment estimation for the mixture of two
                        exponential distributions
mom2par                 Parameters from moments
pGreenwood1             Probability that the Greenwood's statistic is
                        smaller than one
parDeriv                Derivation of probability functions with
                        respect to the parameters
parIni.MAX              Initial estimation of GPD parameters for an
                        aggregated renewal model
plot.Rendata            Plot a Rendata object
plot.Renouv             Plot an object of class "Renouv"
predict.Renouv          Compute return levels and confidence limits for
                        a "Renouv" object
qStat                   Quantiles of a test statistic
rRendata                Simulate a random RenData object
readXML                 Read data using an XML index file
roundPred               Round quantiles in a pseudo-prediction table
skip2noskip             Fix non-skipped periods from skipped ones
spacings                Methods computing spacings between Largest
                        Order Statistics
summary.Rendata         Summary and print methods for "Rendata" objects
summary.Renouv          Summary and print methods for "Renouv" objects
translude               Make translucient colors
vcov.Renouv             Variance-covariance matrix of the estimates of
                        a "Renouv" object
weibplot                Classical Weibull distribution plot
</pre>
<p>This package contains a function <code><a href="#topic+Renouv">Renouv</a></code> to fit
&quot;renouvellement&quot; models.
</p>


<h3>Author(s)</h3>

<p>Yves Deville &lt;deville.yves@alpestat.com&gt;, Lise Bardet &lt;lise.bardet@irsn.fr&gt;

</p>
<p>Maintainer: Yann Richet &lt;yann.richet@irsn.fr&gt;

</p>


<h3>References</h3>


<ul>
<li><p> Miquel J. (1984) <em>Guide pratique d'estimation des
probabilités de crues</em>, Eyrolles (coll. EDF DER).
</p>
</li>
<li><p> Coles S. (2001) <em>Introduction to Statistical Modelling of
Extremes Values</em>, Springer.
</p>
</li>
<li><p> Embrechts P., Klüppelberg C. and Mikosch T. (1997)
<em>Modelling Extremal Events for Insurance and
Finance</em>. Springer.
</p>
</li></ul>



<h3>See Also</h3>

<p>The CRAN packages <a href="https://CRAN.R-project.org/package=evd"><span class="pkg">evd</span></a>, <a href="https://CRAN.R-project.org/package=ismev"><span class="pkg">ismev</span></a>,
<a href="https://CRAN.R-project.org/package=extRemes"><span class="pkg">extRemes</span></a>, <a href="https://CRAN.R-project.org/package=POT"><span class="pkg">POT</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 'Garonne' data set
summary(Garonne)
plot(Garonne)

## Weibull excesses
fG &lt;- Renouv(x = Garonne,
             threshold = 3000,
             distname.y = "weibull",
             main = "Weibull fit for 'Garonne'")

coef(fG)
vcov(fG)
summary(fG)
logLik(fG)
## Re-plot if needed
plot(fG)

## Classical 'predict' method with usual formal args 
predict(fG, newdata = c(100, 150, 200), level = c(0.8, 0.9))
</code></pre>

<hr>
<h2 id='anova.Renouv'>
Compute an analysis of deviance table for two nested Renouv
objects
</h2><span id='topic+anova.Renouv'></span>

<h3>Description</h3>

<p>Compute an analysis of deviance table for two nested Renouv objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   ## S3 method for class 'Renouv'
anova(object, object1, trace = 1L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.Renouv_+3A_object">object</code></td>
<td>

<p>A <code>Renouv</code> model as fitted with <code><a href="#topic+Renouv">Renouv</a></code>.
</p>
</td></tr>
<tr><td><code id="anova.Renouv_+3A_object1">object1</code></td>
<td>

<p>A <code>Renouv</code> object such that <code>object</code> is nested in
<code>object1</code>.
</p>
</td></tr>
<tr><td><code id="anova.Renouv_+3A_trace">trace</code></td>
<td>

<p>Level of verbosity. The value <code>0</code> prints nothing.
</p>
</td></tr>
<tr><td><code id="anova.Renouv_+3A_...">...</code></td>
<td>

<p>Not used yet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Of special interest is the case when the distribution of the excesses
used in <code>object</code> is exponential while <code>object1</code> uses a
two-parameters alternative in the GPD family. We know then that the
convergence to the asymptotic distribution is slow, and a numerical
approximation of the true distribution of the test statistic is used
when possible, i.e. when the objects do not use MAX or OTS data and the
number of exceedances is between 8 and 500.
</p>


<h3>Value</h3>

<p>An object of class <code>"anova"</code> inheriting from class <code>"data.frame"</code>.
</p>


<h3>Note</h3>

<p>The deviance of the models can not be interpreted: only the
difference of the deviance is meaningful.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+anova">anova</a></code>, <code><a href="#topic+LRExp.test">LRExp.test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## test using historical data
fit1Exp &lt;- Renouv(Garonne,  distname.y = "exponential", plot = FALSE)
fit1GPD &lt;- Renouv(Garonne, distname.y = "GPD", plot = FALSE)
anova(fit1Exp, fit1GPD)

## test without using historical data
x &lt;- Garonne$OTdata$Flow
dur &lt;- Garonne$OTinfo$effDuration

fit2Exp &lt;- Renouv(x,  threshold = 2700,  effDuration = dur,
                  distname.y = "exponential", plot = FALSE)
fit2GPD &lt;- Renouv(x, threshold = 2700, effDuration = dur,
                  distname.y = "GPD", plot = FALSE)
anova(fit2Exp, fit2GPD)
</code></pre>

<hr>
<h2 id='barplotRenouv'>Barplot for Renouv &quot;Over Threshold&quot; counts</h2><span id='topic+barplotRenouv'></span>

<h3>Description</h3>

<p>Barplot for &quot;Over Threshold&quot; counts in time blocks (usually years)
</p>


<h3>Usage</h3>

<pre><code class='language-R'> barplotRenouv(data,
               blockname = colnames(data)[1],
               varname = colnames(data)[2],
               threshold = quantile(data[, varname], 0.2),
               na.block = NULL,
               plot = TRUE,
               main = NULL, xlab = NULL, ylab = NULL,
               mono = FALSE,
               prob.theo = 0.999,
               ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="barplotRenouv_+3A_data">data</code></td>
<td>

<p>A dataframe object containing the variables.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_blockname">blockname</code></td>
<td>

<p>Name of the &quot;block&quot; variable (column in <code>data</code>). This variable
should contain integers, or be of class &quot;factor&quot;, but with integer
values such as year numbers.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_varname">varname</code></td>
<td>

<p>Name of the variable (e.g. <code>"Surge"</code>).
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_threshold">threshold</code></td>
<td>

<p>Only obs for which the variable exceeds <code>threshold</code> will be
taken into account.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_na.block">na.block</code></td>
<td>

<p>Values of blocks containing missing values. See the Details section.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_plot">plot</code></td>
<td>

<p>If <code>FALSE</code> tests are computed without producing any plot.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_main">main</code></td>
<td>

<p>Character for main title or <code>NULL</code> in which case a default main
title is used.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_xlab">xlab</code></td>
<td>

<p>Character for x axis label or <code>NULL</code> in which case a default
lab is used.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_ylab">ylab</code></td>
<td>

<p>Character for y axis or <code>NULL</code> in which case a default lab is
used.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_mono">mono</code></td>
<td>

<p>If <code>FALSE</code> barplot will have colors, else greyscale will be
used.
</p>
</td></tr>
<tr><td><code id="barplotRenouv_+3A_prob.theo">prob.theo</code></td>
<td>

<p>The total theoretical probability corresponding to the plotted
(theoretical) bars.</p>
</td></tr>  <tr><td><code id="barplotRenouv_+3A_...">...</code></td>
<td>
<p>Further args to be passed to
<code>barplot</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Blocks described in the <code>na.block</code> are omitted in the
determination of counts. The object given in the <code>na.block</code> is
coerced to character and the same is done for values of <code>block</code>
before comparing them to the <code>na.block</code> values.  If <code>block</code>
variable is of class factor with levels representing years
(e.g. 1980, 1981, etc.) missing blocks can be specified either as
<code>c("1980", "1981")</code> or as numeric <code>c(1980, 1981)</code>.
</p>
<p>For the chi-square test, counts for neighbouring frequency classes are
grouped in order to reach a minimum frequency of <code>5</code> in each
group. E.g. if we expect respectively <code>1.0</code>, <code>3.8</code> and
<code>7.0</code> blocks with frequency <code>0</code>, <code>1</code> and <code>2</code> for
events, the three counts are grouped in one group with frequency
<code>1.0+3.8+7.0=11.8</code>. Note that this strategy of grouping is not
unique and is likely to weaken the power of the test. Before
grouping, the higher class theoretical probability is computed as the
probability to obtain a count equal to or greater than the max value.
</p>


<h3>Value</h3>

<p>A list with the following objects.
</p>
<table>
<tr><td><code>freq</code></td>
<td>

<p>frequency table (matrix) giving observed and theoretical (Poisson)
frequencies as well as a group number for the chi-square test.
</p>
</td></tr>
<tr><td><code>overdispersion</code></td>
<td>

<p>the overdispersion coefficient (variance/mean ratio).
</p>
</td></tr>
<tr><td><code>disp.test</code></td>
<td>

<p>a list giving results of the (over)dispersion
test. See the reference Yagouti and al. in the <b>References</b>
section.
</p>
</td></tr>
<tr><td><code>chisq.test</code></td>
<td>

<p>a list giving results for the chis-square test of goodness-of-fit to
the Poisson distribution.
</p>
</td></tr>
<tr><td><code>tests</code></td>
<td>
<p>a matrix with the two tests displayed in two rows.</p>
</td></tr>
</table>
<p>For both tests, the statistic follows a chi-square distribution under the
null hypothesis . The list of results contains the statistic
<code>statistic</code>, the number of degrees of freedom <code>df</code> and 
the <code class="reqn">p</code>-value <code>p.value</code>.
</p>


<h3>Note</h3>

<p>The two tests: (over-)dispersion and chi-square have <em>one-sided</em> (upper
tail) <code class="reqn">p</code>-value. In other words, we do not intend to reject when
statistics take &quot;abnormally small&quot; values, but only when abnormally
large values are met.
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>References</h3>

<p>See Yagouti A., Abi-Zeid I., Ouarda, T.B.M.J. and
B. Bobée (2001), Revue de processus ponctuels et
synthèse de tests statistiques pour le choix d'un type
de processus <em>Revue des Sciences de l'Eau</em>, <b>1</b>,
pp. 323-361.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.Rendata">plot.Rendata</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## na.block influence for Brest data
opar &lt;- par(mfrow = c(2, 2))

bp1 &lt;- barplotRenouv(data = Brest.years, threshold = 30,
         main = "missing periods ignored")
bp2 &lt;- barplotRenouv(data = Brest.years, threshold = 30,
         na.block = 1992, main = "1992 missing")
bp3 &lt;- barplotRenouv(data = Brest.years, threshold = 30,
         na.block = 1991:1993, main ="1991:1993 missing")
bp4 &lt;- barplotRenouv(data = Brest.years, threshold = 30,
         na.block = Brest.years.missing, main = "all missing periods")

par(opar)

## threshold influence
opar &lt;- par(mfrow = c(2,2))

thresh &lt;- c(30, 35, 40, 50)

for (i in 1:length(thresh)) {
  bp  &lt;- barplotRenouv(data = Brest.years, threshold = thresh[i],
                   na.block = Brest.years.missing,
                   main = paste("threshold =", thresh[i], "cm at Brest"))
}
par(opar)
</code></pre>

<hr>
<h2 id='Brest'>Surge heights at Brest</h2><span id='topic+Brest'></span>

<h3>Description</h3>

<p>Surge heights near high tide at Brest tide gauge station (France),
detailed version
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brest</code></pre>


<h3>Format</h3>

<p>The format is:
List of 5
</p>

<ul>
<li> <p><code>$info</code> : List of 6
</p>

<ul>
<li> <p><code>$name</code>        : chr <code>"Brest"</code> 
</p>
</li>
<li> <p><code>$shortLab</code>    : chr <code>"Surge Heights at Brest (France)"</code> 
</p>
</li>
<li> <p><code>$longLab</code>     : chr <code>"Surge Heights near high tide,  Brest (France)"</code>  
</p>
</li>
<li> <p><code>$varName</code>     : chr <code>"Surge"</code>
</p>
</li>
<li> <p><code>$varShortLab</code> : chr <code>"Surge"</code>
</p>
</li>
<li> <p><code>$varUnit</code> : chr <code>"cm"</code>
</p>
</li></ul>

</li>
<li> <p><code>$describe</code> : chr
&quot;High tide sea surge over 30 cm at Brest (France)...&quot;
</p>
</li>
<li> <p><code>$OTinfo</code> : List of 4
</p>
 
<ul>
<li> <p><code>$start</code>       : chr POSIXct[1:1], format: <code>"1846-01-01"</code>
</p>
</li>
<li> <p><code>$end</code>         : chr POSIXct[1:1], format: <code>"2009-01-01"</code>
</p>
</li>
<li> <p><code>$effDuration</code> : num <code>148</code>
</p>
</li>
<li> <p><code>$threshold</code>   : num <code>30</code>
</p>
</li></ul>

</li>
<li> <p><code>$OTdata</code> : 'data.frame':	1289 obs. of  2 variables:
</p>

<ul>
<li> <p><code>$date</code> : POSIXct[1:1289], format: <code>"1846-01-14" "1846-01-21"</code> ...
</p>
</li>
<li> <p><code>$Surge</code> : num [1:1289] <code>36 60 46 40 33</code> ...
</p>
</li></ul>

</li>
<li> <p><code>$OTmissing</code> : 'data.frame':	43 obs. of  3 variables:
</p>

<ul>
<li> <p><code>$start</code>   : POSIXct[1:43], format: <code>"1846-01-01" "1847-01-01"</code> ...
</p>
</li>
<li> <p><code>$end</code>     : POSIXct[1:43], format: <code>"1846-01-04" "1847-01-21"</code> ...
</p>
</li>
<li> <p><code>$comment</code> : chr [1:43] <code>"" "" "" ""</code> ...
</p>
</li></ul>

<p>- <code>attr(*, "class")= chr "Rendata"</code>
</p>
</li></ul>



<h3>Details</h3>

<p>Data are provided as a list.
</p>

<ul>
<li> <p><code>info</code> gives general information about the data
</p>
</li>
<li> <p><code>OTinfo</code> gives general information about the Over the
Threshold part of data. The effective duration (<code>effDuration</code>
element) is the total duration for the periods with effective
measurements.
</p>
</li>
<li> <p><code>OTdata</code> give OT measurements
</p>
</li>
<li> <p><code>OTmissing</code> gives start and end of the missing periods
for OT measurements.
</p>
</li></ul>

<p>Data come from hourly sea levels measured and predicted by the french
<em>Service Hydrogéographique et
Océanographique de la Marine</em> (SHOM).  Observed
sea levels are available as <em>REFMAR</em> data at the url
<a href="https://data.shom.fr/">https://data.shom.fr/</a>.  Data were processed (declustered) by IRSN
in order to provide a series of independent surge heights at high
tide. Surge height at high tide is defined as the difference between
the observed and the predicted maximal sea levels near high tide.  A
correction was applied to account for trend in the sea-level over the
observation period.
</p>
<p>The effective duration given in years is defined up to a small
fraction of year due to leap years and leap seconds.
</p>


<h3>Source</h3>

<p><a href="https://data.shom.fr/">https://data.shom.fr/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(Brest)
Brest$OTinfo$start
plot(Brest)
</code></pre>

<hr>
<h2 id='Brest.years'>Surge heights at Brest partial data</h2><span id='topic+Brest.years'></span>

<h3>Description</h3>

<p>Surge heights at Brest (France) 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brest.years</code></pre>


<h3>Format</h3>

<p>A data frame with 954 observations on the following 2 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>Year e.g; 1980</p>
</dd>
<dt><code>Surge</code></dt><dd><p>Surge heights above the threshold of 30 cm.</p>
</dd>
</dl>



<h3>Details</h3>

<p>These data are a simplified version of <code><a href="#topic+Brest">Brest</a></code>. For each
surge event only the year is retained as timestamp. Years with
missing periods are available as a vector <code><a href="#topic+Brest.years.missing">Brest.years.missing</a></code>. 
</p>
<p>This dataset is useful for testing since similar data are sometimes
met in the analyses.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>names(Brest.years)
</code></pre>

<hr>
<h2 id='Brest.years.missing'>Years with missing periods in 'Brest.year' dataset</h2><span id='topic+Brest.years.missing'></span>

<h3>Description</h3>

<p>Years with missing periods in the 'Brest.years' dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brest.years.missing</code></pre>


<h3>Format</h3>

<p>The format is:
int [1:49] 1846 1847 1852 1857 1858 1859 1860 1861 1862 1863 ...
</p>


<h3>Details</h3>

<p>Vector of years containing missing periods in the
<code><a href="#topic+Brest.years">Brest.years</a></code> dataset. This years should be ignored when
computing yearly statistics such as event rates, since time records
are lost.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(Brest.years.missing)
</code></pre>

<hr>
<h2 id='CV2'>Squared Coefficient of Variation</h2><span id='topic+CV2'></span>

<h3>Description</h3>

<p>Squared Coefficient of Variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   CV2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV2_+3A_x">x</code></td>
<td>

<p>Numeric vector or matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the squared Coefficient of Variation of one or several samples
provided as a numeric vector or matrix.
</p>


<h3>Value</h3>

<p>Numeric vector of the squared coefficients of variation.
</p>


<h3>Note</h3>

<p>The squared coefficient of variation is the ratio
<code class="reqn">S^2/\bar{X}^2</code> where <code class="reqn">\bar{X}</code> and <code class="reqn">S^2</code>
are the sample mean and the sample variance. The variance is computed
using the sample size <code class="reqn">n</code> as denominator, rather than the usual
<code class="reqn">n-1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 30; nSamp &lt;- 500
X &lt;- matrix(rexp(n * nSamp), nrow= nSamp, ncol = n)
W &lt;- CV2(X)
plot(density(W), main = "CV2 of exponential samples")
</code></pre>

<hr>
<h2 id='CV2.test'>CV2 test of exponentiality</h2><span id='topic+CV2.test'></span>

<h3>Description</h3>

<p>Test of exponentiality based on the squared coefficient of variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   CV2.test(x, method = c("num", "sim", "asymp"), nSamp = 15000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV2.test_+3A_x">x</code></td>
<td>

<p>Numeric vector giving the sample.
</p>
</td></tr>
<tr><td><code id="CV2.test_+3A_method">method</code></td>
<td>

<p>Method used to compute the <code class="reqn">p</code>-value.  Can be <code>"asymp"</code>,
<code>"num"</code> or <code>"sim"</code> as in <code><a href="#topic+LRExp.test">LRExp.test</a></code>.
</p>
</td></tr>
<tr><td><code id="CV2.test_+3A_nsamp">nSamp</code></td>
<td>

<p>Number of samples used to compute the <code class="reqn">p</code>-value when
<code>method</code> is <code>"sim"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distribution of <code class="reqn">\textrm{CV}^2</code> is that of
<em>Greenwood's statistic</em> up to normalising constants.  It
approximately normal with expectation <code class="reqn">1</code> and standard deviation
<code class="reqn">2/\sqrt{n}</code> for a large sample size <code>n</code>. Yet the
convergence to the normal is known to be <em>very slow</em>.
</p>


<h3>Value</h3>

<p>A list of test results.
</p>
<table>
<tr><td><code>statistic</code>, <code>p.value</code></td>
<td>

<p>The test statistic, i.e. the squared coefficient of
variation <code class="reqn">\textrm{CV}^2</code> and the <code class="reqn">p</code>-value.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>Description of the test method.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This test is sometimes referred to as <em>Wilk's exponentiality
test</em> or as <em>WE1 test</em>.  It works quite well for a Lomax
alternative (i.e.  GPD with shape <code class="reqn">\xi &gt;0</code>), and hence can be
compared to Jackson's test and the Likelihood-Ratio (LR) test of
exponentiality.  However, this test has lower power that of the two
others while having a comparable computation cost due to the
evaluation of the Greenwood's statistic distribution.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>S. Ascher (1990) &quot;A Survey of Tests for Exponentiality&quot;
<em>Commun. Statist. Theory Methods</em>, 19(5), pp. 1811-1525. 
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+CV2">CV2</a></code> that computes the statistic and
<code><a href="#topic+LRExp.test">LRExp.test</a></code> or <code><a href="#topic+Jackson.test">Jackson.test</a></code> for functions
implementing comparable tests or exponentiality with the same
arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 30; nSamp &lt;- 500
X &lt;- matrix(rexp(n * nSamp), nrow = nSamp, ncol = n)
pVals &lt;- apply(X, 1, function(x) CV2.test(x)$p.value)
plot(pVals)  ## should be uniform on (0, 1)
</code></pre>

<hr>
<h2 id='Dunkerque'>Surge heights at Dunkerque</h2><span id='topic+Dunkerque'></span>

<h3>Description</h3>

<p>Surge heights near high tide at Dunkerque tide gauge station (France)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dunkerque</code></pre>


<h3>Format</h3>

<p>The format is:
List of 7
</p>

<ul>
<li> <p><code>$info</code> : List of 6
</p>

<ul>
<li> <p><code>$name</code>    : chr <code>"Dunkerque"</code>
</p>
</li>
<li> <p><code>$shortLab</code>   : chr <code>"Surge Heights at Dunkerque (France)"</code>
</p>
</li>
<li> <p><code>$longLab</code>    : chr <code>"Surge Heights near high tide,  Dunkerque (France)"</code>
</p>
</li>
<li> <p><code>$varName</code>    : chr <code>"Surge"</code>
</p>
</li>
<li> <p><code>$varShortLab</code> : chr <code>"Surge"</code>
</p>
</li>
<li> <p><code>$varUnit</code>    : chr <code>"cm"</code>
</p>
</li></ul>

</li>
<li> <p><code>$describe</code> : chr <code>"High tide sea surge over 30 cm at Dunkerque... "</code>
</p>
</li>
<li> <p><code>$OTinfo</code> : List of 4
</p>

<ul>
<li> <p><code>$start</code>     : POSIXct[1:1], format: <code>"1956-01-01"</code>
</p>
</li>
<li> <p><code>$end</code>       : POSIXct[1:1], format: <code>"2009-01-01"</code>
</p>
</li>
<li> <p><code>$effDuration: num 38.8</code>
</p>
</li>
<li> <p><code>$threshold  : num "30"</code>
</p>
</li></ul>

</li>
<li> <p><code>$OTdata</code> : 'data.frame':	740 obs. of 3 variables:
</p>

<ul>
<li> <p><code>$date</code>  : POSIXct[1:740], format: <code>"1956-11-27" "1956-12-03"</code> ...
</p>
</li>
<li> <p><code>$Surge</code> : num [1:740] <code>67.9 30.9 51.8 30.8 39.8</code> ...
</p>
</li>
<li> <p><code>$comment</code> : chr [1:740] <code>"" "" "" ""</code> ...
</p>
</li></ul>

</li>
<li>  <p><code>$OTmissing</code> : 'data.frame':	83 obs. of  3 variables:
</p>

<ul>
<li> <p><code>$start</code>  : POSIXct[1:83], format: <code>"1956-01-01" "1956-08-08"</code> ...
</p>
</li>
<li> <p><code>$end</code>    : POSIXct[1:83], format: <code>"1956-06-07" "1956-11-03"</code> ...
</p>
</li>
<li> <p><code>$comment</code>: chr [1:83] <code>"" "" "" ""</code> ...
</p>
</li></ul>

</li>
<li> <p><code>$MAXinfo</code>  : 'data.frame' : 1 obs. of  3 variables:
</p>

<ul>
<li> <p><code>$start</code>  : POSIXct[1:1], format: <code>"1706-01-01"</code>
</p>
</li>
<li> <p><code>$end</code>    : POSIXct[1:1], format: <code>"1956-01-01"</code>
</p>
</li>
<li> <p><code>$duration</code> : num <code>250</code>
</p>
</li></ul>

</li>
<li> <p><code>$MAXdata</code>  :'data.frame':	1 obs. of  4 variables:
</p>

<ul>
<li> <p><code>$block</code>  : int <code>1</code>
</p>
</li>
<li> <p><code>$date</code>   : POSIXct[1:1], format: <code>"1953-02-01"</code>
</p>
</li>
<li> <p><code>$Surge</code>  : num <code>213</code>
</p>
</li>
<li> <p><code>$comment</code> : chr <code>"1"</code></p>
</li></ul>

<p>- <code>attr(*, "class")= chr "Rendata"</code>
</p>
</li></ul>



<h3>Details</h3>

<p>See <code><a href="#topic+Brest">Brest</a></code> and <code><a href="#topic+Garonne">Garonne</a></code> datasets with the
same list structure.
</p>
<p>An 'historical' surge of 213 cm was observed on 1953-02-01 and is
considered by experts as having a return period of 250 years. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Dunkerque$info
plot(Dunkerque)
</code></pre>

<hr>
<h2 id='EM.mixexp'>
Expectation-Maximisation for a mixture of exponential distributions
</h2><span id='topic+EM.mixexp'></span>

<h3>Description</h3>

<p>Experimental function for Expectation-Maximisation (EM) estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EM.mixexp(x, m = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EM.mixexp_+3A_x">x</code></td>
<td>

<p>Sample vector with values <code>&gt;0</code>.
</p>
</td></tr>
<tr><td><code id="EM.mixexp_+3A_m">m</code></td>
<td>

<p>Number of mixture components.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The EM algorithm is very simple for exponential mixtures (as well as
for many other mixture models).
</p>
<p>According to a general feature of EM, this iterative method leads to
successive estimates with increasing likelihood but which may
converge to a local maximum of the likelihood.
</p>


<h3>Value</h3>

<p>List with
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Estimated values as a named vector.
</p>
</td></tr>
<tr><td><code>logL</code></td>
<td>

<p>Vector giving the log-likelihood for successive iterations.
</p>
</td></tr>
<tr><td><code>Alpha</code></td>
<td>

<p>Matrix with <code>m</code> columns giving probability weights for
successive iterations. Row with number <code>it</code> contains the
<code>m</code> probabilities at iteration <code>it</code>.
</p>
</td></tr>
<tr><td><code>Theta</code></td>
<td>

<p>Matrix with <code>m</code> columns giving the estimates of the
<code>m</code> expectations for the successive iterations
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The estimation is done for expectation (inverse rates) but the
<code>estimate</code> vector in the result contains rates for compatibility
reasons (e.g with exponential).
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mom.mixexp2">mom.mixexp2</a></code> and <code><a href="#topic+ini.mixexp2">ini.mixexp2</a></code> for &quot;cheap&quot;
estimators when <code>m = 2</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- rmixexp2(n = 100, prob1 = 0.5, rate2 = 4)
EM.mixexp(x) -&gt; res
res$estimate
matplot(res$Theta, type = "l", lwd = 2,
        xlab = "iteration", ylab = "theta",
        main = "exponential inverse rates")
</code></pre>

<hr>
<h2 id='expplot'>
Classical &quot;exponential distribution&quot; plot
</h2><span id='topic+expplot'></span>

<h3>Description</h3>

<p>Plot a vector using &quot;exponential distribution&quot; scales
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expplot(x,
        plot.pos = "exp",
        rate = NULL,
        labels = NULL,
        mono = TRUE,
        ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expplot_+3A_x">x</code></td>
<td>

<p>The vector to be plotted.
</p>
</td></tr>
<tr><td><code id="expplot_+3A_plot.pos">plot.pos</code></td>
<td>

<p>Plotting position for points: either &quot;exp&quot; for <em>expected</em> ranks
or &quot;med&quot; for a <em>median</em> rank approximation (see <b>Details</b>
below).
</p>
</td></tr>
<tr><td><code id="expplot_+3A_rate">rate</code></td>
<td>

<p>Rate parameter for one or several &quot;exponential distribution&quot; lines
to be plotted
</p>
</td></tr>
<tr><td><code id="expplot_+3A_labels">labels</code></td>
<td>

<p>Text to display in legend when &quot;exponential distribution&quot; lines
are specified
</p>
</td></tr>
<tr><td><code id="expplot_+3A_mono">mono</code></td>
<td>

<p>Monochrome graph?
</p>
</td></tr>
<tr><td><code id="expplot_+3A_...">...</code></td>
<td>

<p>Arguments to be passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This plot shows <code class="reqn">-\log[1-F(x)]</code> against <code class="reqn">x</code>
where <code class="reqn">F(x)</code> at point <code class="reqn">i</code> is taken as
<code class="reqn">i/(n+1)</code> if <code>plot.pos</code> is <code>"exp"</code>, or as the
&quot;median rank&quot; approximation <code class="reqn">(i-0.3)/(n+0.4)</code> if
<code>plot.pos</code> is <code>"med"</code>.
</p>
<p>If the data in <code>x</code> is a sample from an exponential distribution,
the points should be roughly aligned. However the largest order
statistics have high sampling dispersion.
</p>


<h3>Note</h3>

<p>The log scale for y is emulated via the construction of suitable
graduations. So be careful when adding graphical material (points,
etc) to this graph with functions of the &quot;add to plot&quot; family
(<code>points</code>, <code>lines</code>, ...).
</p>
<p>The ML estimate of the <code>rate</code> parameter is the inverse of the
sample mean.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+weibplot">weibplot</a></code> function for a classical &quot;Weibull&quot; plot.
The <code><a href="#topic+interevt">interevt</a></code> is useful to compute interevents (or
&quot;interarrivals&quot;) that should follow an exponential distribution in the
homogeneous Poisson process context.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> x &lt;- rexp(200)
 expplot(x, rate = 1/mean(x), labels = "fitted")
</code></pre>

<hr>
<h2 id='fgamma'>ML estimation of the Gamma distribution</h2><span id='topic+fgamma'></span>

<h3>Description</h3>

<p>Fast Maximum Likelihood estimation of the Gamma distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgamma(x, check.loglik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fgamma_+3A_x">x</code></td>
<td>

<p>Sample vector to be fitted. Should contain only positive non-NA
values.
</p>
</td></tr>
<tr><td><code id="fgamma_+3A_check.loglik">check.loglik</code></td>
<td>

<p>If <code>TRUE</code>, the log-likelihood is recomputed using <code>dgamma</code>
function with <code>log =</code> <code>TRUE</code>. The result is returned as a
list element.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood is concentrated with respect to the scale
parameter. The concentrated log-likelihood is a strictly concave
function of the shape parameter which can easily maximised
numerically.
</p>


<h3>Value</h3>

<p>A list with the following elements
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Parameter ML estimates.
</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>Vector of (asymptotic) standard deviations for the estimates.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>check.loglik</code></td>
<td>

<p>The checked log-likelihood.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>The (asymptotic) covariance matrix computed from theoretical or
observed information matrix.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>The information matrix.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The distribution is fitted by using the <code>scale</code> parameter rather
than <code>rate</code> (inverse of <code>scale</code>).
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">GammaDist</a></code> in the <span class="pkg">stats</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(9876)
alpha &lt;- 0.06
beta &lt;- rexp(1)
n &lt;- 30
x &lt;- rgamma(n, shape = alpha, scale = beta)
fit &lt;- fgamma(x, check.loglik = TRUE)

## compare with MASS results
if (require(MASS)) {
   fit.MASS &lt;- fitdistr(x, densfun = "gamma")
   rate &lt;- 1 / fit$estimate["scale"]
   est &lt;- c(fit$estimate, rate = rate)
   der &lt;- rate * rate ## derivative of rate w.r.t scale
   sdest &lt;- c(fit$sd, rate = der * fit$sd["scale"])
   tab &lt;- rbind(sprintf(" %10.8f ", est),
                sprintf("(%10.8f)", sdest))
   colnames(tab) &lt;- c("shape", "scale", "rate")
   rownames(tab) &lt;- c("est", "sd")
   noquote(tab)
}

</code></pre>

<hr>
<h2 id='fGEV.MAX'>
Fit a GEV distribution from block maxima or r largest order statistics
using an aggregated Renewal POT process
</h2><span id='topic+fGEV.MAX'></span>

<h3>Description</h3>

<p>Fit a GEV distribution from block maxima or <code class="reqn">r</code> largest order
statistics using an aggregated Renewal POT process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fGEV.MAX(MAX.data, MAX.effDuration,
         MAX = NULL,
         control = list(maxit = 300, fnscale = -1),
         scaleData = TRUE,
         cov = TRUE,
         info.observed = TRUE,
         trace = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fGEV.MAX_+3A_max.data">MAX.data</code></td>
<td>

<p>A list of block maxima or <code class="reqn">r</code> largest statistics as in
<code><a href="#topic+Renouv">Renouv</a></code>.
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_max.effduration">MAX.effDuration</code></td>
<td>

<p>A vector of durations as in <code><a href="#topic+Renouv">Renouv</a></code>. <em>The
durations must be identical</em> in order to have a common GEV
distribution for the maxima.
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_max">MAX</code></td>
<td>

<p>A compact representation of the needed data as a list. This is
typically created by using the (non exported)
<code>Renext:::makeMAXdata</code> function.
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_control">control</code></td>
<td>

<p>List to control the optimisation in <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_scaledata">scaleData</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the data in <code>MAX.data</code> are scaled
before being used in the likelihood. The scaling operation is
carried on the excesses (observations minus threshold). 
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_cov">cov</code></td>
<td>

<p>Logical. If <code>TRUE</code> the standard deviation and the covariance
matrix of the estimates are computed and returned as <code>sd</code> and
<code>cov</code> elements of the list. However if the estimated shape
parameter is <code class="reqn">&lt; - 0.5</code> the two elements are filled with
<code>NA</code> because the regularity conditions can not be thought
of as valid.
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_info.observed">info.observed</code></td>
<td>

<p>Logical. If <code>TRUE</code> the covariance is computed from the
<em>observed</em> information matrix. If <code>FALSE</code>, the
<em>expected</em> information matrix is used instead. This is only
possible for block maxima data, i.e.  when all the blocks contain
only one observation. The computation relies on the formula given by
Prescott and Walden. Note that the default value differs from that
of the functions <code><a href="#topic+fGPD">fGPD</a></code>, <code><a href="#topic+flomax">flomax</a></code> and
<code><a href="#topic+fmaxlo">fmaxlo</a></code>, for historical reasons.
</p>
</td></tr>
<tr><td><code id="fGEV.MAX_+3A_trace">trace</code></td>
<td>

<p>Integer level of verbosity during execution. With the value <code>0</code>,
nothing is printed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data are assumed to provide maxima or <code class="reqn">r</code> largest statistics
arising from an aggregated renewal POT model with unknown event rate
<code class="reqn">\lambda</code> and unknown two-parameter Generalised Pareto
Distribution for the excesses. A threshold <code class="reqn">u</code> is fixed below the
given data and the three unknown parameters <code>lambda</code>,
<code>scale</code> and <code>shape</code> of the POT model are found by maximising
the likelihood.  Then a vector of the three parameters for the GEV
distribution is computed by transformation. The covariance matrix and
standard deviations are computed as well using the jacobian matrix of
the transformation.
</p>
<p>The maximisation is for the log-likelihood with the rate <code>lambda</code>
concentrated out, so it is a two-parameter optimisation.
</p>


<h3>Value</h3>

<p>A list
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Named vector of the estimated parameters for the GEV distribution of
maxima.
</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>

<p>Result of the optimisation.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>Identical to <code>opt$value</code>. This is the maximised log-likelihood
for the renewal POT model.
</p>



</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>Standard deviation of the estimates (approximation based on the ML
theory).
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>Covariance matrix of the estimates (approximation based on the ML
theory).
</p>
</td></tr>
</table>


<h3>Caution</h3>

<p>Whatever be the data, the log-likelihood is infinite (hence maximal)
for any vector of GEV parameters with shape <code class="reqn">&lt; -1</code> and
postive scale. Hence the log-likelihood should be maximised with a
constraint on the shape, while an <em>unconstrained</em> optimisation is
used here. In practice, for numerical reasons, the estimate usually
remains inside the <code>shape &gt; -1</code> region. <em>An estimation
leading to shape <code class="reqn">&lt; -1</code> must be considered as meaningless</em>. An
estimation with shape <code class="reqn">&lt; -0.5</code> should be considered with care.
</p>


<h3>Note</h3>

<p>This function could get more arguments in the future.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>The <em>Renext Computing Details</em> document.
</p>
<p>Prescott P. and Walden A.T. (1980) Maximum Likelihood Estimation of the 
Parameters of the Generalized Extreme-Value Distribution.  
<em>Biometrika</em> <b>67</b>(3), 723-724.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Renouv">Renouv</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##====================================================================
## block maxima: simulated data and comparison with  the 'fgev'
## function from the 'evd' package
##====================================================================
set.seed(1234)
u &lt;- 10
nBlocks &lt;- 30
nSim &lt;- 100   ## number of samples 
Par &lt;- array(NA, dim = c(nSim, 3, 2),
             dimnames = list(NULL, c("loc", "scale", "shape"), c("MAX", "evd")))
LL &lt;- array(NA, dim = c(nSim, 2),
            dimnames = list(NULL, c("MAX", "evd")))

for (i in 1:nSim) {
  rd &lt;- rRendata(threshold = u,
                 effDuration = 1,
                 lambda = 12,
                 MAX.effDuration = rep(1, nBlocks),
                 MAX.r = rep(1, nBlocks),
                 distname.y = "exp", par.y = c(rate = 1 / 100))

  MAX &lt;- Renext:::makeMAXdata(rd)
  fit.MAX &lt;- fGEV.MAX(MAX = MAX)
  fit.evd &lt;- fgev(x = unlist(MAX$data))
  Par[i, , "MAX"] &lt;- fit.MAX$estimate
  Par[i, , "evd"] &lt;- fit.evd$estimate
  LL[i, "MAX"] &lt;- fit.MAX$loglik
  LL[i, "evd"] &lt;- logLik(fit.evd)
}

##====================================================================
## r largest: use 'ismev::rlarg.fit' on the venice data set.
## NB 'venice' is taken from the 'evd' package here.
##====================================================================
## Not run:  
require(ismev);
fit1 &lt;- ismev::rlarg.fit(venice)

## transform data: each row is a block
MAX.data &lt;- as.list(as.data.frame(t(venice)))
## remove the NA imposed by the rectangular matrix format
MAX.data &lt;- lapply(MAX.data, function(x) x[!is.na(x)])
MAX.effDuration &lt;- rep(1, length(MAX.data))

fit2 &lt;- fGEV.MAX(MAX.data = MAX.data,
                 MAX.effDuration = MAX.effDuration)

## estimates
est &lt;- cbind(ismev = fit1$mle, RenextLab = fit2$estimate)
print(est)
# covariance
covs &lt;- array(dim = c(2, 3, 3),
              dimnames = list(c("ismev", "RenextLab"),
                colnames(fit2$cov), colnames(fit2$cov)))
                
covs["ismev", , ] &lt;- fit1$cov
covs["RenextLab", , ] &lt;- fit2$cov
print(covs)

## End(Not run)
</code></pre>

<hr>
<h2 id='fGPD'>
Fit a two-parameters Generalised Pareto Distribution from a sample
</h2><span id='topic+fGPD'></span>

<h3>Description</h3>

<p>Fit a two-parameters Generalised Pareto Distribution from a sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
fGPD(x,
     info.observed = TRUE,
     shapeMin = -0.8,
     dCV = 1e-04,
     cov = TRUE,
     trace = 0)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fGPD_+3A_x">x</code></td>
<td>

<p>The sample data vector.
</p>
</td></tr>
<tr><td><code id="fGPD_+3A_info.observed">info.observed</code></td>
<td>

<p>Logical. The observed information matrix is used when <code>TRUE</code>
and the expected information matrix is used when <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="fGPD_+3A_shapemin">shapeMin</code></td>
<td>

<p>Lower bound on the shape parameter. This must be <code>&gt;= -1.0</code>
since otherwise the ML estimate is obtained with the <code>scale</code>
parameter equal to <code>max(x)</code>.
</p>
</td></tr>
<tr><td><code id="fGPD_+3A_dcv">dCV</code></td>
<td>

<p>Half-length of a small interval centered on 1.0.  When the
Coefficient of Variation (CV) falls in this interval, an exponential
distribution is fitted, see <b>Details</b>.
</p>
</td></tr>
<tr><td><code id="fGPD_+3A_cov">cov</code></td>
<td>

<p>Logical. If <code>FALSE</code>, a minimal estimation is performed with
no covariance matrix or derivative returned. This can be useful
when a large number of ML estimations are required, e.g. to sample
from a likelihood ratio.
</p>
</td></tr>
<tr><td><code id="fGPD_+3A_trace">trace</code></td>
<td>

<p>Integer level of verbosity. The value <code>0</code> prints nothing.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function mainly relies on the <code><a href="#topic+flomax">flomax</a></code> and
<code><a href="#topic+fmaxlo">fmaxlo</a></code> functions. When <code>CV</code> is larger than
<code>1.0 + dCV</code>, a Lomax distribution is fitted by Maximum Likelihood
using a concentrated log-likelihood.  When instead <code>CV</code> is
smaller than <code>1.0 - dCV</code>, a maxlo distribution is
fitted. Finally, when <code>CV -1.0</code> has absolute value <code>&lt;= dCV</code>,
an exponential distribution is fitted.  In all cases, the result is
translated into a parameter vector for the GPD.
</p>
<p>Note that when <code>CV</code> is close to <code>1.0</code>, fitting a Lomax or a
maxlo distribution can lead to problems because the estimated values
of the shape and scale parameter are large, and because the
concentrated log-likelihood is a flat function of the scale parameter.
</p>


<h3>Value</h3>

<p>A list
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Vector containing the estimated values of the unknown parameters.
</p>
</td></tr>
<tr><td><code>CV</code></td>
<td>

<p>The coefficient of variation of <code>x</code> computed using
<code>length(x)</code> as denominator in the variance estimation.
</p>
</td></tr>
<tr><td><code>logLik</code>, <code>dlogLik</code></td>
<td>

<p>The maximised value of the log-likelihood and the vector of its
first order derivatives, which should be close to zero.
</p>
</td></tr>
<tr><td><code>sd</code>, <code>cov</code></td>
<td>

<p>Vector of approximated standard deviations and covariance matrix
for the estimated parameters. These are based on the inversion of
expected information matrix.
</p>
</td></tr>
<tr><td><code>sd</code>, <code>cov</code></td>
<td>

<p>Vector of standard deviations and covariance matrix for the
estimates if the <code>cov</code> formal is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code>cvg</code></td>
<td>

<p>Logical. Was convergence reached? This logical flag is set to
<code>TRUE</code> and remains for compatibility reasons.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>It may happen that the estimated shape parameter is <code>&lt; -0.5</code>, in
which case the expected information matrix can not be computed, nor
does the covariance matrix and standard deviations. In this case, the
<code>cov</code> and <code>sd</code> objects contain <code>NA</code> values.  This
problem can arise also when the shape parameter is greater than but
close to the value <code>-0.5</code>. Even when <code>info.observed</code> is
<code>TRUE</code>, the information matrix, covariance and standard
deviations are set to <code>NA</code>.
</p>
<p>When the true (unknown) value is is <code>&lt; -0.5</code>, the regularity
conditions required in the ML approximated inference do not hold.
</p>
<p>The default value of <code>info.observed</code> was set to <code>TRUE</code> from
version <code>3.0-1</code> because standard deviations obtained with this
choice are usually better.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>See the <em>Renext Computing Details</em> document.
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+fmaxlo">fmaxlo</a></code> and <code><a href="#topic+flomax">flomax</a></code> functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(123456)
n &lt;- 500
ns &lt;- 1000
xi &lt;- runif(ns, min = -0.5, max = 0.5)
X &lt;- matrix(nrow = n, ncol = ns)

for (i in 1:length(xi)) {
  Xi &lt;- rgpd(n, scale = 1, shape = xi[i])
  X[ , i] &lt;- Xi
  res1 &lt;- fGPD(Xi)
  res2 &lt;- try(fpot(Xi, threshold = 0.0))
  if (inherits(res2, "try-error")) {
    cat(res2, "\n")
    break
  }
  logLik1 &lt;- res1$loglik; logLik2 &lt;- logLik(res2)
  if (abs(logLik1 - logLik2) &gt; 0.001) {
    cat(sprintf("i = %d, xi = %7.4f\n", i, xi[i]))
    mat &lt;- rbind(c(res1$estimate[1:2], logLik = logLik1),
                 c(res2$estimate[1:2], logLik = logLik2))
    rownames(mat) &lt;- c("fGPD", "fpot")
    print(mat)
  }
}

## End(Not run)
</code></pre>

<hr>
<h2 id='flomax'>
ML estimation of the Lomax distribution
</h2><span id='topic+flomax'></span>

<h3>Description</h3>

<p>Fast Maximum Likelihood estimation of the Lomax distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flomax(x,
       info.observed = TRUE,
       plot = FALSE,
       scaleData = TRUE,
       cov = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flomax_+3A_x">x</code></td>
<td>

<p>Sample vector to be fitted. Should contain only positive
non-NA values.
</p>
</td></tr>
<tr><td><code id="flomax_+3A_info.observed">info.observed</code></td>
<td>

<p>Should the observed information matrix be used or the expected one
be used?
</p>
</td></tr>
<tr><td><code id="flomax_+3A_plot">plot</code></td>
<td>

<p>Logical. If <code>TRUE</code>, a plot will be produced showing the
derivative of the concentrated log-likelihood, function of the shape
parameter.
</p>
</td></tr>
<tr><td><code id="flomax_+3A_scaledata">scaleData</code></td>
<td>

<p>Logical. If <code>TRUE</code> observations in <code>x</code> (which are
positive) are divided by their mean value.  The results are in
theory not affected by this transformation, but scaling the data
could improve the estimation in some cases.  The log-likelihood
plots are shown using the scaled values so the returned estimate of
the scale parameter is not the the abscissa of the maximum shown on
the plot.
</p>
</td></tr>
<tr><td><code id="flomax_+3A_cov">cov</code></td>
<td>

<p>Logical. If <code>FALSE</code>, a minimal estimation is performed with no
covariance matrix or derivative returned. This can be useful when a
large number of ML estimations are required, e.g. to sample from a
likelihood ratio.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood is concentrated with respect to the shape parameter.
This function is increasing for small values of the scale parameter
<code class="reqn">\beta</code>. For large <code class="reqn">\beta</code>, the derivative of the concentrated
log-likelihood tends to zero, and its sign is that of <code class="reqn">(1 -
  \textrm{CV}^2)</code> where <code class="reqn">\textrm{CV}</code> is the
coefficient of variation, computed using <code class="reqn">n</code> as denominator in the
formula for the standard deviation.
</p>
<p>The ML estimate does not exist when the sample has a coefficient of
variation CV less than 1 and it may fail to be found when CV is
greater than yet close to 1.
</p>


<h3>Value</h3>

<p>A list with the following elements
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Parameter ML estimates.
</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>Vector of (asymptotic) standard deviations for the estimates.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The maximised log likelihood.
</p>
</td></tr>
<tr><td><code>dloglik</code></td>
<td>

<p>Gradient of the log-likelihood at the optimum. Its two
elements should normally be close to zero.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>The (asymptotic) covariance matrix computed from theoretical or
observed information matrix.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>The information matrix.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The estimates are biased for small or medium sized sample. The bias is
positive for the shape parameter, thus the estimated shape tends to be
larger than the true unknown value.
</p>
<p>Fitting a Lomax distribution to an exponential sample might lead to a
divergence since the exponential is the limit of a Lomax distribution
with large shape and large scale with constant ratio shape/scale.
Fitting this distribution to a sample having a coefficient of
variation smaller than 1 is not allowed since it should lead to
divergence of the estimation.
</p>
<p>The default value of <code>info.observed</code> was set to <code>TRUE</code> from
version <code>3.0-1</code> because standard deviations obtained with this
choice are usually better.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>J. del Castillo and J. Daoudi (2009) &quot;Estimation of the Generalized
Pareto Distribution&quot;, <em>Statist. Probab. Lett.</em> 79(5),
pp. 684-688.
</p>
<p>D.E. Giles, H. Feng &amp; R.T. Godwin (2013) &quot;On the Bias of the Maximum
Likelihood Estimator for the Two-Parameter Lomax Distribution&quot;
<em>Comm. Statist. Theory Methods</em>. Vol. 42, n. 11, pp. 1934-1950.
</p>
<p>N. Johnson, S. Kotz and N. Balakrishnan 
<em>Continuous Univariate Distributions</em> vol. 1, Wiley 1994.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lomax">Lomax</a></code> for the Lomax distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate sample
set.seed(1234)
n &lt;- 200
alpha &lt;- 2 + rexp(1)
beta &lt;- 1 + rexp(1)
x &lt;- rlomax(n, scale = beta, shape = alpha)
res &lt;- flomax(x, plot = TRUE)

## compare with a GPD with shape 'xi' and scale 'sigma'
xi &lt;- 1 / alpha; sigma &lt;- beta * xi  
res.evd &lt;- evd::fpot(x, threshold = 0, model = "gpd")
xi.evd &lt;- res.evd$estimate["shape"]
sigma.evd &lt;- res.evd$estimate["scale"]
beta.evd &lt;- sigma.evd / xi.evd 
alpha.evd &lt;- 1 / xi.evd
cbind(Renext = res$estimate, evd = c(alpha = alpha.evd, beta = beta.evd))
  
</code></pre>

<hr>
<h2 id='fmaxlo'>
ML estimation of a 'maxlo' distribution
</h2><span id='topic+fmaxlo'></span>

<h3>Description</h3>

<p>Fast Maximum Likelihood estimation of a 'maxlo' distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmaxlo(x,
       shapeMin = 1.25,
       info.observed = TRUE,
       plot = FALSE,
       scaleData = TRUE,
       cov = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fmaxlo_+3A_x">x</code></td>
<td>

<p>Sample vector to be fitted. Should contain only positive non-NA
values.
</p>
</td></tr>
<tr><td><code id="fmaxlo_+3A_shapemin">shapeMin</code></td>
<td>

<p>Lower bound on the shape parameter. This must be <code>&gt;= 1.0</code>
since otherwise the ML estimate is obtained with the <code>scale</code>
parameter equal to <code>max(x)</code>.
</p>
</td></tr>
<tr><td><code id="fmaxlo_+3A_info.observed">info.observed</code></td>
<td>

<p>Should the observed information matrix be used or the expected one
be used?
</p>
</td></tr>
<tr><td><code id="fmaxlo_+3A_plot">plot</code></td>
<td>

<p>Logical. If <code>TRUE</code>, a plot will be produced showing the
derivative of the concentrated log-likelihood, function of the shape
parameter. The derivative function shown is that of the log-likelihood for
the unconstrained maximisation; it is not used in the estimation.
</p>
</td></tr>
<tr><td><code id="fmaxlo_+3A_scaledata">scaleData</code></td>
<td>

<p>Logical. If <code>TRUE</code> observations in <code>x</code> (which are
positive) are divided by their mean value.  The results are in
theory not affected by this transformation, but scaling the data
could improve the estimation in some cases.  The log-likelihood
plots are shown using the scaled values so the returned estimate of
the scale parameter is not the the abscissa of the maximum shown on
the plot.
</p>
</td></tr>
<tr><td><code id="fmaxlo_+3A_cov">cov</code></td>
<td>

<p>Logical. If <code>FALSE</code>, a minimal estimation is performed with
no covariance matrix or derivative returned. This can be useful
when a large number of ML estimations are required, e.g. to sample
from a likelihood ratio.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 'maxlo' likelihood is concentrated with respect to the shape
parameter, thus the function to be maximised has only one one scalar
argument: the scale parameter <code class="reqn">\beta</code>. For large scale
<code class="reqn">\beta</code>, the derivative of the concentrated log-likelihood tends
to zero, and its sign is that of <code class="reqn">(\textrm{CV}^2-1)</code>
where <code class="reqn">\textrm{CV}</code> is the coefficient of variation, computed
using <code class="reqn">n</code> as denominator in the formula for the standard
deviation.
</p>
<p>The ML estimate does not exist when the sample has a coefficient of
variation <code>CV</code> greater than <code>1.0</code> and it may fail to be
found when <code>CV</code> is smaller than yet close to <code>1.0</code>.
</p>
<p>The expected information matrix can be obtained by noticing that when
the r.v. <code class="reqn">Y</code> follows the 'maxlo' distribution with shape
<code class="reqn">\alpha</code> and scale <code class="reqn">\beta</code> the r.v <code class="reqn">V:= 1/(1-Y/\beta)</code>
follows a Pareto distribution with minimum 1 and and shape parameter
<code class="reqn">\alpha</code>. The information matrix involves the second order
moment of <code class="reqn">V</code>.
</p>
<p>The default value of <code>info.observed</code> was set to <code>TRUE</code> from
version <code>3.0-1</code> because standard deviations obtained with this
choice are usually better.
</p>


<h3>Value</h3>

<p>A list with the following elements
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Parameter ML estimates.
</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>Vector of (asymptotic) standard deviations for the estimates.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>dloglik</code></td>
<td>

<p>Gradient of the log-likelihood at the optimum. Its two elements
should normally be close to zero.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>The (asymptotic) covariance matrix computed from theoretical or
observed information matrix.
</p>
</td></tr>  <tr><td><code>info</code></td>
<td>

<p>The information matrix.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The name of the distribution hence also that of the fitting function
are still experimental and might be changed.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Maxlo">Maxlo</a></code> for the description of the distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate sample
set.seed(1234)
n &lt;- 200
alpha &lt;- 2 + rexp(1)
beta &lt;- 1 + rexp(1)
x &lt;- rmaxlo(n, scale = beta, shape = alpha)
res &lt;- fmaxlo(x, plot = TRUE)

## compare with a GPD with shape 'xi' and scale 'sigma'
xi &lt;- -1 / alpha; sigma &lt;- -beta * xi
res.evd &lt;- evd::fpot(x, threshold = 0, model = "gpd")
xi.evd &lt;- res.evd$estimate["shape"]
sigma.evd &lt;- res.evd$estimate["scale"]
beta.evd &lt;- -sigma.evd / xi.evd 
alpha.evd &lt;- -1 / xi.evd
cbind(Renext = res$estimate, evd = c(alpha = alpha.evd, beta = beta.evd))
  

</code></pre>

<hr>
<h2 id='fweibull'>
ML estimation of classical Weibull distribution
</h2><span id='topic+fweibull'></span>

<h3>Description</h3>

<p>Fast Maximum Likelihood estimation of the classical two parameters
Weibull distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
fweibull(x, info.observed = TRUE, scaleData = TRUE, cov = TRUE,
         check.loglik = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fweibull_+3A_x">x</code></td>
<td>

<p>Sample vector to be fitted. Should contain only positive
non-NA values.
</p>
</td></tr>
<tr><td><code id="fweibull_+3A_info.observed">info.observed</code></td>
<td>

<p>Should the observed information matrix be used or the expected one
be used?
</p>
</td></tr>
<tr><td><code id="fweibull_+3A_scaledata">scaleData</code></td>
<td>

<p>Should the data be scaled before estimation? If <code>TRUE</code>,
the observations in <code>x</code> (which are positive) are divided by their
mean value.  The results are in theory not affected by this
transformation, but scaling the data could improve the estimation in
some cases. 
</p>
</td></tr>
<tr><td><code id="fweibull_+3A_cov">cov</code></td>
<td>

<p>Should the covariance of estimates be computed?
</p>
</td></tr>  
<tr><td><code id="fweibull_+3A_check.loglik">check.loglik</code></td>
<td>

<p>If <code>TRUE</code>, the log-likelihood is recomputed using
<code>dweibull</code> function with <code>log = TRUE</code>. The result is
returned as a list element.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ML estimates are obtained thanks to a reparameterisation with
<code class="reqn">\eta = scale^{1/shape}</code> in place of
<code>shape</code>. This allows the maximisation of a one-dimensional
likelihood <code class="reqn">L</code> since the <code class="reqn">\eta</code> parameter can be
concentrated out of <code class="reqn">L</code>. This also allows the determination of
the <em>expected</em> information matrix for
<code class="reqn">[shape,\,\eta]</code> rather than the usual
<em>observed</em> information.
</p>


<h3>Value</h3>

<p>A list
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Parameter ML estimates.
</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>The (asymptotic) standard deviation for estimate.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>The (asymptotic) covariance matrix computed from theoretical or
observed Information matrix.
</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>

<p>The estimated value for eta.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The default value of <code>info.observed</code> was set to <code>TRUE</code> from
version <code>3.0-1</code> because standard deviations obtained with this
choice are usually better.
</p>







<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+weibplot">weibplot</a></code> for Weibull plots.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 1000
set.seed(1234)
shape &lt;- 2 * runif(1)
x &lt;- 100 * rweibull(n, shape = 0.8, scale = 1)
res &lt;- fweibull(x)

## compare with MASS
if (require(MASS)) {
   res2 &lt;- fitdistr(x , "weibull")
   est &lt;- cbind(res$estimate, res2$estimate)
   colnames(est) &lt;- c("Renext", "MASS")
   loglik &lt;- c(res$loglik, res2$loglik)
   est &lt;- rbind(est, loglik)
   est
}

## Weibull plot
weibplot(x,
         shape = c(res$estimate["shape"], res2$estimate["shape"]),
         scale = c(res$estimate["scale"], res2$estimate["scale"]),
         labels = c("Renext 'fweibull'", "MASS 'fitdistr'"),
         mono = TRUE)
</code></pre>

<hr>
<h2 id='Garonne'>
Flow of the french river La Garonne
</h2><span id='topic+Garonne'></span>

<h3>Description</h3>


<p>Flow of the french river La Garonne at le Mas d'Agenais
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Garonne</code></pre>


<h3>Format</h3>

<p>The format is:
List of 7
</p>

<ul>
<li> <p><code>$info</code> : List of 6
</p>

<ul>
<li> <p><code>$name</code>       : chr <code>"Garonne"</code>
</p>
</li>
<li> <p><code>$shortLab</code>   : chr <code>"La Garonne at Le Mas d'Agenais"</code>
</p>
</li>
<li> <p><code>$longLab</code>    : chr <code>"River flow of La Garonne at Le Mas d'Agenais"</code>
</p>
</li>
<li> <p><code>$varName</code>    : chr <code>"Flow"</code>
</p>
</li>
<li> <p><code>$varShortLab</code> : chr <code>"Flow"</code>
</p>
</li>
<li> <p><code>$varUnit</code>    : chr <code>"m3/s"</code>
</p>
</li></ul>

</li>
<li> <p><code>$describe</code> : chr <code>"Flow of the french river La Garonne ..."</code>
</p>
</li>
<li> <p><code>$OTinfo</code> :List of 4
</p>

<ul>
<li> <p><code>$start</code>       : POSIXct[1:1], format: <code>"1913-01-01"</code>
</p>
</li>
<li> <p><code>$end</code>         : POSIXct[1:1], format: <code>"1978-01-01"</code>
</p>
</li>
<li> <p><code>$effduration</code> : num <code>65</code>
</p>
</li>
<li> <p><code>$threshold</code>   : num <code>2500</code>
</p>
</li></ul>

</li>
<li> <p><code>$OTdata</code> : 'data.frame':	151 obs. of  3 variables:
</p>

<ul>
<li> <p><code>$date</code> : POSIXct[1:151], format: <code>"1913-04-08" "1913-04-25"</code>  ...
</p>
</li>
<li> <p><code>$Flow</code>  : num [1:151] <code>2600 2800 2700 4579 3400</code>
...
</p>
</li>
<li> <p><code>comment</code> : chr [1:151] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ...
</p>
</li></ul>

</li>
<li> <p><code>$OTmissing</code> : <code>NULL</code>
</p>
</li>
<li> <p><code>$MAXinfo</code> :'data.frame':	1 obs. of  3 variables:
</p>

<ul>
<li> <p><code>$start</code>    : POSIXct[1:1], format: <code>"1770-01-01"</code>
</p>
</li>
<li> <p><code>$end</code>      : POSIXct[1:1], format: <code>"1913-01-01"</code>
</p>
</li>
<li> <p><code>$duration</code> : num <code>143</code>
</p>
</li></ul>

</li>
<li> <p><code>$MAXdata</code> :'data.frame':	12 obs. of 4 variables:
</p>

<ul>
<li> <p><code>$block</code>  : num [1:12] <code>1 1 1 1 1 1 1 1 1 1</code> ...
</p>
</li>
<li> <p><code>date</code> : POSIXct[1:12], format: <code>NA NA</code> ...
</p>
</li>
<li> <p><code>$Flow</code>      : num [1:12]
<code>7500 7400 7000 7000 7000 6600 6500 6500 6400 6300</code> ...
</p>
</li>
<li> <p><code>$comment</code> : chr [1:12] &quot;1 (1875)&quot; &quot;2 (1770)&quot; &quot;3 (1783)&quot; &quot;4 (1855)&quot; ...
</p>
</li></ul>

<p>- <code>attr(*, "class")= chr "Rendata"</code>
</p>
</li></ul>



<h3>Details</h3>

<p>The data concern the french river <em>La Garonne</em> at the gauging
station named <em>Le Mas d'Agenais</em> where many floods occurred during 
the past centuries.
</p>
<p>The data consist in OT data and historical data. The variable is
the river flow in cube meter per second <code class="reqn">(\textrm{m}^3/\textrm{s})</code> as estimated from 
the river level using a rating curve. The precision is limited and many ties are present
among the flow values.
</p>
<p>The OT data or &quot;OTdata&quot; contain flows values over the threshold
<code class="reqn">u = 2500\,\mathrm{m}</code> for the <code class="reqn">65</code> years
period 1913-1977.
The historical data or &quot;MAXdata&quot;  is simply the <code class="reqn">r=12</code> largest flows for the period 
of <code class="reqn">143</code> years 1770-1912. The exact dates of these events are not known with
precision but the years are known and given as comments.
</p>


<h3>Source</h3>

<p>The data were taken from the book by Miquel.
</p>


<h3>References</h3>

<p>Miquel J. (1984) <em>Guide pratique d'estimation des
probabilités de crues</em>, Eyrolles (coll. EDF DER).
</p>
<p>Parent E. and Bernier J. (2003) Bayesian POT modeling for Historical
data. <em>Journal of Hydrology</em> vol. 274, pp. 95-108.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(Garonne) 
</code></pre>

<hr>
<h2 id='gev2Ren'>
Translate a vector of GEV parameters into renewal  model
</h2><span id='topic+gev2Ren'></span>

<h3>Description</h3>

<p>Translate a (named) vector of GEV parameters into a renewal
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev2Ren(parGev,
        threshold = NULL,
        lambda = NULL,
        w = 1,
        distname.y = c("gpd", "GPD", "lomax", "maxlo"),
        vcovGev = NULL,
        jacobian = TRUE,
        plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gev2Ren_+3A_pargev">parGev</code></td>
<td>

<p>Named vector of GEV coefficients. This must be
a vector of length 3, with names <code>"loc"</code>, <code>"scale"</code>
and <code>"shape"</code>.
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_threshold">threshold</code></td>
<td>

<p>The threshold of the renewal model.
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_lambda">lambda</code></td>
<td>

<p>The rate of the renewal model.
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_w">w</code></td>
<td>

<p>The duration corresponding to the GEV parameters. Positive numeric
scalar assumed to be in years.
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_distname.y">distname.y</code></td>
<td>

<p>The name of the distributions for the excesses in the
renewal model. 
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_vcovgev">vcovGev</code></td>
<td>

<p>A (co)variance matrix for the parameter. This must be a
symmetric positive matrix with 3 rows and 3 columns,
with rownames in correspondence with the parameter names.
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_jacobian">jacobian</code></td>
<td>

<p>Logical. If <code>TRUE</code> a Jacobian matrix
will be returned as a <code>"jacobian"</code> attribute of the
result.
</p>
</td></tr>
<tr><td><code id="gev2Ren_+3A_plot">plot</code></td>
<td>

<p>If <code>TRUE</code> a rough plot will be produced to check
the accordance of the GEV and the renewal models. It
is a return level plot with the two return level curves
shown.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of parameters similar to the coefficient vector of an object
with class <code>"Renouv"</code>.  This vector has an element named
<code>"lambda"</code> corresponding to the rate of the Homogeneous Poisson
Process. The other elements are the parameters for the distribution
of POT excesses.
</p>
<p>The result has attributes named <code>"distname.y"</code> and
<code>"threshold"</code> which can be used to build a <code>Renouv</code> object
using the <code><a href="#topic+RenouvNoEst">RenouvNoEst</a></code> function.  The result may as well
have attributes <code>"jacobian"</code> and <code>"vcov"</code> according to the
arguments values. These objects should be used with attention to their
element names, since the parameter order may not be the one you
expect.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+Ren2gev">Ren2gev</a></code> function provide a reciprocal
transformation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## GEV parameters and block duration
set.seed(1234)
muGev &lt;- rnorm(1); sigmaGev &lt;- rgamma(1, shape = 5)
xiGev &lt;- runif(1, min = -0.2, max = 0.3)
parGev &lt;- c("loc" = muGev, "scale" = sigmaGev, "shape" = xiGev)
parRen &lt;- gev2Ren(parGev, lambda = 1, jacobian = TRUE, plot = TRUE)
## check by reverse transform
parGevCheck &lt;- Ren2gev(parRen, threshold = attr(parRen, "threshold"))
rbind(parGev, parGevCheck)

##=======================================================================
## slightly positive shape convert to "gpd" and "lomax" distributions
##=======================================================================
x &lt;- rgev(n = 100, loc = 3500, scale = 1000, shape = 0.1)
fit.gev &lt;- fgev(x, start = list("loc" = 3000, "scale" = 1000, "shape" = 0.1))
distNames &lt;- c("gpd", "lomax")
namesRen &lt;- c("lambda", "scale", "shape") # works for the 2 target dists
fitNew &lt;- list()
opar &lt;- par(mfrow = c(3, 1))
for (nm in distNames) {  
  parRen &lt;- gev2Ren(parGev = fit.gev$estimate, threshold = 2800,
                    vcov = fit.gev$var.cov, distname.y = nm)
  namesRen &lt;- c("lambda", "scale", "shape")
  myVcov &lt;- attr(parRen, "vcov")[namesRen, namesRen]
  fitNew[[nm]] &lt;- RenouvNoEst(threshold = attr(parRen, "threshold"),
                              estimate = parRen,
                              distname.y = attr(parRen, "distname.y"),
                              cov = myVcov)
  plot(fitNew[[nm]], Tlim = c(1, 200))
}
plot(fit.gev, which = 4)
par(opar)
##=======================================================================
## slightly negative shape convert to "gpd" and "maxlo" distribution
##=======================================================================
x &lt;- rgev(n = 100, loc = 3500, scale = 1000, shape = -0.2)
fit.gev &lt;- fgev(x, start = list("loc" = 3000, "scale" = 1000, "shape" = 0.1))
distNames &lt;- c("gpd", "maxlo")
namesRen &lt;- c("lambda", "scale", "shape") # works for the 2 target dists
fitNew &lt;- list()
opar &lt;- par(mfrow = c(3, 1))
for (nm in distNames) {
  parRen &lt;- gev2Ren(parGev = fit.gev$estimate, threshold = 2800,
                    vcov = fit.gev$var.cov, distname.y = nm)
  myVcov &lt;- attr(parRen, "vcov")[namesRen, namesRen]
  fitNew[[nm]] &lt;- RenouvNoEst(threshold = attr(parRen, "threshold"),
                              estimate = parRen,
                              distname.y = attr(parRen, "distname.y"),
                              cov = myVcov)
  plot(fitNew[[nm]], Tlim = c(1, 200))
}
plot(fit.gev, which = 4)
par(opar)


</code></pre>

<hr>
<h2 id='gof.date'>Goodness-of-fit for the distribution of dates</h2><span id='topic+gof.date'></span>

<h3>Description</h3>

<p>Goodness-of-fit diagnostics for the distribution of event dates
in a (assumed) Poisson process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    gof.date(date,
             start = NULL,
             end = NULL,
             plot = TRUE,
             main = NULL,
             skip = NULL,
             plot.type = "skip")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gof.date_+3A_date">date</code></td>
<td>

<p>Object of class <code>POSIXct</code> (or that can be coerced to this
class) giving the dates to be tested. Must be in strictly increasing
order.
</p>
</td></tr>
<tr><td><code id="gof.date_+3A_start">start</code></td>
<td>

<p>The beginning of the interval, a <code>POSIXct</code> object. If
<code>NULL</code>, the first event in <code>date</code> is used.
</p>
</td></tr>
<tr><td><code id="gof.date_+3A_end">end</code></td>
<td>

<p>Object of class <code>POSIXct</code> the end of the interval. If
<code>NULL</code>, the last event in <code>date</code> is used.
</p>
</td></tr>
<tr><td><code id="gof.date_+3A_plot">plot</code></td>
<td>

<p>Should a plot be shown?
</p>
</td></tr>
<tr><td><code id="gof.date_+3A_main">main</code></td>
<td>

<p>Character giving the main title of the plot. The default <code>NULL</code>
stands for a default main describing the period.
</p>
</td></tr>
<tr><td><code id="gof.date_+3A_skip">skip</code></td>
<td>

<p>Optional data.frame with columns <code>start</code> and <code>end</code>
indicating start and end of skipped periods. The two columns need to
be coerced to POSIXct objects. They can be POSIXct or character with
POSIX datetime format.
</p>
</td></tr>
<tr><td><code id="gof.date_+3A_plot.type">plot.type</code></td>
<td>

<p>Character indicating the type of plot to produce when a <code>skip</code>
data.frame is given. With <code>plot.type = "skip"</code> the plot shows
missing periods as greyed rectangles and the displays the results of
a Kolmogorov-Smirnov (KS) test performed on the events. For the
<code>"omit"</code> case the missing periods are collapsed into vertical
lines on the plot and the displayed results are for an &quot;effective&quot;
KS test of uniformity performed omitting the missing periods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the homogeneous Poisson process, events occur on a time interval in
a uniform fashion. More precisely, for a given time interval the
distribution of the event dates conditional to their number <code class="reqn">n</code> is the
distribution of the order statistics of a sample of size <code class="reqn">n</code> of
the uniform distribution on this interval.
</p>
<p>When the interval has limits taken at events the uniformity statement
remains true, but for <em>inner</em> events. This behaviour is met when
<code>start</code> and <code>end</code> are not given and taken as the first and
last events in <code>date</code>.
</p>


<h3>Value</h3>

<p>A list
</p>
<table>
<tr><td><code>effKS.statistic</code>, <code>KS.statistic</code></td>
<td>

<p>Kolmogorov-Smirnov global test statistic for uniformity (bilateral
test) omitting slipped periods or not.
</p>
</td></tr>
<tr><td><code>effKS.pvalue</code>, <code>KS.pavalue</code></td>
<td>

<p>Critical probability in the KS test omitting skipped periods or not.
</p>
</td></tr>
<tr><td><code>effnevt</code>, <code>nevt</code></td>
<td>

<p>Number of events omitting skipped periods or not.
</p>
</td></tr>
<tr><td><code>effduration</code>, <code>duration</code></td>
<td>

<p>Effective duration i.e. total duration of non-skipped periods. In
years, omitting skipped periods or not.
</p>
</td></tr>
<tr><td><code>effrate</code>, <code>rate</code></td>
<td>

<p>Occurrence rate in <b>number of events by year</b>, omitting skipped
periods or not.
</p>
</td></tr>
<tr><td><code>effduration</code>, <code>duation</code></td>
<td>

<p>Total duration in <b>years</b>, omitting missing periods or not.
</p>
</td></tr>
<tr><td><code>noskip</code></td>
<td>

<p>Data.frame object giving indications on the periods that are NOT
skipped over (hence usually non-missing periods). These are :
<code>start</code>, <code>end</code> (POSIX), <code>duration</code> (in years)
<code>rate</code> (in number of events by year) and Kolmogorov test
statistic and p-value. This data.frame is only available when a
suitable <code>skip</code> has been given.
</p>
</td></tr>
</table>
<p>When the number of events corresponding to the indications of args is
<code>0</code>, the function returns <code>NULL</code> with a warning. When the
number of events is less than <code>6</code> a warning is shown.
</p>


<h3>Warning</h3>

<p>When skipped periods exist the number of events, duration, rate the
global KS test must be computed by omitting the skipped periods in the
duration and retaining only valid interevents. The indication given in
<code>nevt</code> <code>rate</code> and <code>duration</code> should be used only when no
skipped period exist (<code>skip = NULL</code> on input) and replaced by
<code>effnevt</code>, <code>effrate</code> and <code>effduration</code> otherwise.
</p>


<h3>Note</h3>

<p>In practical contexts missing periods are often met in the
datasets. The diagnostic should therefore be applied on <em>every
period with no missing data</em>. Even if the event dates seem reasonably
uniform, it is a good idea to check that the rates do not differ
significantly over intervals.
</p>
<p>When some events are missing and no suitable information is given via
the <code>skip</code> argument, the global <code>rate</code>, <code>KS.statistic</code>
and <code>KS.pvalue</code> are of little interest. Yet the graph might be
instructive.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+interevt">interevt</a></code> function for the determination of interevents
ans subsequent diagnostics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use "Brest" dataset
## simple plot. Kolmogorov-Smirnov is not useful
gof1 &lt;- gof.date(date = Brest$OTdata$date)

## consider missing periods. Much better!
gof2 &lt;- gof.date(date = Brest$OTdata$date,
         skip = Brest$OTmissing,
         start = Brest$OTinfo$start,
         end = Brest$OTinfo$end)

print(gof2$noskip)

## Second type of graph
gof3 &lt;- gof.date(date = Brest$OTdata$date,
         skip = Brest$OTmissing,
         start = Brest$OTinfo$start,
         end = Brest$OTinfo$end,
         plot.type = "omit")

## non-skipped periods at Brest
ns &lt;- skip2noskip(skip = Brest$OTmissing,
                 start = Brest$OTinfo$start,
                 end = Brest$OTinfo$end)

## say 9 plots/diagnostics
oldpar &lt;- par(mar = c(3, 4, 3, 2), mfcol = c(3, 3))

for (i in 1:9) {
  GOF &lt;- gof.date(date = Brest$OTdata$date,
           start = ns$start[i],
           end = ns$end[i])
}

par(oldpar)

</code></pre>

<hr>
<h2 id='gofExp.test'>Goodness-of-fit test for exponential distribution</h2><span id='topic+gofExp.test'></span>

<h3>Description</h3>

<p>Bartlett's goodness-of-fit test for exponential distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   gofExp.test(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gofExp.test_+3A_x">x</code></td>
<td>

<p>Sample with positive values.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>statistic</code></td>
<td>

<p>Statistic.
</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>

<p>Critical value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>References</h3>

<p>See
</p>
<p>Yagouti A., Abi-Zeid I., Ouarda, T.B.M.J. and B. Bobée
(2001), Revue de processus ponctuels et synthèse de
tests statistiques pour le choix d'un type de processus <em>Revue
des Sciences de l'Eau</em>, <b>1</b>, pp. 323-361.
</p>


<h3>See Also</h3>

<p>Among other goodness-of-fit tests <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the
<code>stats</code> package. See <code><a href="#topic+expplot">expplot</a></code> for a graphical
diagnostic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## a sample of size 30
 x &lt;- rexp(30)
 res &lt;- gofExp.test(x)

 ## ns samples: p.values should look as uniform on (0, 1)
 ns &lt;- 100
 xmat &lt;- matrix(rexp(30*ns), nrow = ns, ncol = 30)
 p.values &lt;- apply(xmat, 1, function(x) gofExp.test(x)$p.value)
 plot(sort(p.values), type = "p", pch = 16)
 
</code></pre>

<hr>
<h2 id='GPD'>Generalised Pareto Distribution</h2><span id='topic+GPD'></span><span id='topic+dGPD'></span><span id='topic+pGPD'></span><span id='topic+qGPD'></span><span id='topic+rGPD'></span><span id='topic+hGPD'></span><span id='topic+HGPD'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function, random
generation, hazard and cumulative hazard functions for the Generalised
Pareto Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   dGPD(x, loc = 0.0, scale = 1.0, shape = 0.0, log = FALSE)
   pGPD(q, loc = 0.0, scale = 1.0, shape = 0.0, lower.tail = TRUE)
   qGPD(p, loc = 0.0, scale = 1.0, shape = 0.0, lower.tail = TRUE)
   rGPD(n, loc = 0.0, scale = 1.0, shape = 0.0)
   hGPD(x, loc = 0.0, scale = 1.0, shape = 0.0)
   HGPD(x, loc = 0.0, scale = 1.0, shape = 0.0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GPD_+3A_x">x</code>, <code id="GPD_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_p">p</code></td>
<td>

<p>Vector of probabilities.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_n">n</code></td>
<td>

<p>Number of observations.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_loc">loc</code></td>
<td>

<p>Location parameter <code class="reqn">\mu</code>.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_scale">scale</code></td>
<td>

<p>Scale parameter <code class="reqn">\sigma</code>.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_shape">shape</code></td>
<td>

<p>Shape parameter <code class="reqn">\xi</code>.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_log">log</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the log density is returned.
</p>
</td></tr>
<tr><td><code id="GPD_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Logical; if <code>TRUE</code> (default), probabilities are
<code class="reqn">\textrm{Pr}[X &lt;= x]</code>, otherwise, <code class="reqn">\textrm{Pr}[X
    &gt; x]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\mu</code>, <code class="reqn">\sigma</code> and <code class="reqn">\xi</code> denote <code>loc</code>,
<code>scale</code> and <code>shape</code>. The distribution values <code class="reqn">y</code>
are <code class="reqn">\mu \leq y &lt; y_{\textrm{max}}</code>.
</p>
<p>When <code class="reqn">\xi \neq 0</code>, the survival function value for
<code class="reqn">y \geq \mu</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">S(y) = \left[1 + \xi(y - \mu)/\sigma\right]^{-1/ \xi} \qquad
    \mu &lt; y &lt; y_{\textrm{max}}</code>
</p>

<p>where the upper end-point is
<code class="reqn">y_{\textrm{max}} = \infty</code> for
<code class="reqn">\xi &gt;0</code> and <code class="reqn">y_{\textrm{max}} = \mu -\sigma/ \xi</code> for <code class="reqn">\xi &lt;0</code>.
</p>
<p>When <code class="reqn">\xi = 0</code>, the distribution is exponential with survival
</p>
<p style="text-align: center;"><code class="reqn">S(y) = \exp\left[- (y - \mu)/\sigma\right] \qquad \mu \leq y. </code>
</p>



<h3>Value</h3>

<p><code>dGPD</code> gives the density function, <code>pGPD</code> gives the
distribution function, <code>qGPD</code> gives the quantile function, and
<code>rGPD</code> generates random deviates. The functions
<code>hGPD</code> and <code>HGPD</code> return the hazard rate and the cumulative
hazard.
</p>


<h3>Note</h3>

<p>The functions are slight adaptations of the <code>[r,d,p,q]gpd</code>
functions in the <span class="pkg">evd</span> package. The main difference is that
these functions return <code>NaN</code> when <code>shape</code> is negative, as
it might be needed in unconstrained optimisation. The quantile function
can be used with <code>p=0</code> and <code>p=1</code>, then returning the lower and
upper end-point.       
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fGPD">fGPD</a></code> to fit such a distribution by Maximum Likelihood.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qGPD(p = c(0, 1), shape = -0.2)
shape &lt;- -0.3
xlim &lt;- qGPD(p = c(0, 1), shape = shape)
x &lt;- seq(from = xlim[1], to = xlim[2], length.out = 100)
h &lt;- hGPD(x, shape = shape)
plot(x, h, type = "o", main = "hazard rate for shape &lt; 0")
shape &lt;- 0.2
xlim &lt;- qGPD(p = c(0, 1 - 1e-5), shape = shape)
x &lt;- seq(from = xlim[1], to = xlim[2], length.out = 100)
h &lt;- hGPD(x, shape = shape)
plot(x, h, type = "o", main = "hazard rate shape &gt; 0 ")
</code></pre>

<hr>
<h2 id='gumbel2Ren'>
Translate a vector of Gumbel parameters into a vector of parameters
for a renewal model
</h2><span id='topic+gumbel2Ren'></span>

<h3>Description</h3>

<p>Translate a (named) vector of Gumbel parameters into a vector of
parameters for a renewal model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gumbel2Ren(parGumbel,
           threshold = NULL,
           lambda = NULL,
           w = 1,
           distname.y = c("exponential"),
           vcovGumbel = NULL,
           jacobian = TRUE,
           plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gumbel2Ren_+3A_pargumbel">parGumbel</code></td>
<td>

<p>Named vector of Gumbel parameters, with name <code>"scale"</code> and
<code>"shape"</code>.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_threshold">threshold</code></td>
<td>

<p>The threshold for the target Renouv parameters.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_lambda">lambda</code></td>
<td>

<p>The rate for the target Renouv parameters.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_w">w</code></td>
<td>

<p>A block duration for the conversion.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_distname.y">distname.y</code></td>
<td>

<p>The distribution of the excesses.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_vcovgumbel">vcovGumbel</code></td>
<td>

<p>A covariance matrix for the Gumbel parameters.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_jacobian">jacobian</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the jacobian is used.
</p>
</td></tr>
<tr><td><code id="gumbel2Ren_+3A_plot">plot</code></td>
<td>

<p>Logical. If <code>TRUE</code>, a rough plot will be drawn.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a vector of Gumbel parameters and a block duration, there exits
an infinity of <code>Renouv</code> models with exponential excesses leading to
the prescribed Gumbel distributions for the maximum of the marks on a
block with duration <code>w</code>.  One of these models may be chosen by
specifying either a threshold or a rate <code>lambda</code>.
</p>


<h3>Value</h3>

<p>A vector of Renouv parameters, which can be used with
<code><a href="#topic+RenouvNoEst">RenouvNoEst</a></code>.
</p>


<h3>Caution</h3>

<p>All Renouv models lead to the same return level curve whatever be the
choice of <code>threshold</code> or <code>lambda</code>. However, when a
covariance matrix is given, the covariance matrix for the Renouv
parameters and consequently the confidence bounds <b>depend on the
threshold or rate</b>. So the computed covariance matrix must in general
be considered as putative.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gev2Ren">gev2Ren</a></code> for a similar translation from the GEV
distribution.
</p>

<hr>
<h2 id='Hpoints'>Plotting positions for exponential return levels</h2><span id='topic+Hpoints'></span>

<h3>Description</h3>

<p>Plotting positions for exponential return level plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Hpoints(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hpoints_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plotting positions are numeric values to use as the abscissae
corresponding to the order statistics in an exponential return level
plot. They range from 1 to about <code class="reqn">\log n</code>. They can be
related to the plotting positions given by <code><a href="stats.html#topic+ppoints">ppoints</a></code>.
</p>
<p>The returned vector <code class="reqn">\mathbf{H}</code> has elements </p>
<p style="text-align: center;"><code class="reqn">H_{i} =
  \frac{1}{n} + \frac{1}{n-1} + \dots + \frac{1}{n + 1 -i}</code>
</p>
<p> for <code class="reqn">1 \leq i \leq n</code>. This is the expectation of the <code class="reqn">i</code>-th order statistic
for a sample of the standard exponential distribution, see
e.g. chap. 4 of Embrechts et al.  </p>


<h3>Value</h3>

<p>Numeric vector of plotting positions with length <code>n</code>.
</p>


<h3>Note</h3>

<p>For <code class="reqn">n</code> large enough, the largest value <code class="reqn">H_n</code> is
approximately <code class="reqn">\gamma + \log n</code> where
<code class="reqn">\gamma</code> is the Euler-Mascheroni constant, and <code class="reqn">\exp
  H_n</code> is about <code class="reqn">1.78 n</code>.  Thus if the Hpoints
are used as plotting positions on a return level plot, the largest
observation has a return period of about <code class="reqn">1.78 n</code> years.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>Embrechts P., Klüppelberg C. and Mikosch T. (1997) <em>Modelling
Extremal Events for Insurance and Finance</em>. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ppoints">ppoints</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 30
set.seed(1234)
x &lt;- rGPD(n, shape = 0.2)
plot(exp(Hpoints(n)), sort(x), log = "x",
     main = "Basic return level plot")

</code></pre>

<hr>
<h2 id='ini.mixexp2'>
Simple  estimation for the mixture of two exponential distributions
</h2><span id='topic+ini.mixexp2'></span>

<h3>Description</h3>

<p>Compute a simple (preliminary) estimation for the tree parameters of
the mixture of two exponential distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   ini.mixexp2(x, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ini.mixexp2_+3A_x">x</code></td>
<td>

<p>Sample: numerical vector with elements <code>&gt;0</code>.
</p>
</td></tr>




<tr><td><code id="ini.mixexp2_+3A_plot">plot</code></td>
<td>

<p>Should a graphic be displayed?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function gives estimators using several methods if necessary. The
goal is to find the rates <code>rate1</code>, <code>rate2</code> and the mixing
probability <code>prob1</code> with the 'feasibility' constraints <code>0 &lt;
  rate1</code> <code>&lt; rate2</code> and <code>0 &lt; prob1 &lt; 1</code>.
</p>
<p>First the method of moments is used. If the estimates are feasible
they are returned with <code>method</code> <code>=</code> <code>"moments"</code>.  If
not, the estimates are derived using two linear regressions. A
regression without constant using only the smallest values gives an
estimator of the mean rate.  A regression using only the largest
values gives <code>rate1</code> and <code>prob1</code>. Yet the constraints must
be fulfilled. If they are, the estimates are returned (together with
<code>method =</code> <code>"Hreg"</code> suggesting a cumulative hazard
regression). If not, a (poor) default estimate is returned with
<code>method =</code> <code>"arbitrary"</code>.
</p>


<h3>Value</h3>

<p>A list 
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>A vector with named elements <code>"prob1"</code>, <code>"rate1"</code> and
<code>"rate2"</code>.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>The method that really produced the estimators.
</p>
</td></tr>
</table>


<h3>Note</h3>

  
<p>The method of moments is implemented in <code>mom.mixexp2</code>.  Further
investigations are needed to compare the estimators (moments or Hreg)
and select the best strategy.
</p>
<p>Note that this function returns the estimate within a list and no
longer as a vector with named elements as was the case before.
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+MixExp2">MixExp2</a></code>, <code><a href="#topic+mom.mixexp2">mom.mixexp2</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- rmixexp2(n = 100, prob1 = 0.5, rate2 = 4)
res &lt;- ini.mixexp2(x, plot = TRUE)

</code></pre>

<hr>
<h2 id='interevt'>Interevents (or interarrivals) from events dates</h2><span id='topic+interevt'></span>

<h3>Description</h3>

<p>Compute intervent durations from events dates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   interevt(date,
            skip = NULL, noskip = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interevt_+3A_date">date</code></td>
<td>

<p>A <code>POSIXct</code> vector containing the date(time) of the events.
</p>
</td></tr>
<tr><td><code id="interevt_+3A_skip">skip</code></td>
<td>

<p>A data.frame containing two <code>POSIXct</code> columns <code>start</code> and
<code>end</code> describing the periods to skip over.
</p>
</td></tr>
<tr><td><code id="interevt_+3A_noskip">noskip</code></td>
<td>

<p>A data.frame like <code>skip</code> but where the periods define the NON
skipped part of the events.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Interevents are the time differences between successive dates. When
the <code>date</code> argument contains occurrence times <code class="reqn">T_i</code>
for successive events of an homogeneous Poisson process, interevents
<code class="reqn">T_i -T_{i-1}</code> are mutually independent with the
same exponential distribution.
</p>
<p>When some time intervals are skipped independently from the event
point process, we may consider the interevents
<code class="reqn">T_i-T_{i-1}</code> between two non-skipped events such
that the time interval <code class="reqn">(T_{i-1},\,T_i)</code> does not
contains any skipped interval.  These interevents still are mutually
independent with the same exponential distribution.  When <code>skip</code>
or <code>noskip</code> is not <code>NULL</code> the computation therefore only
retains couples of two successive datetimes &quot;falling&quot; in the same
non-skipped period, which number can therefore be associated with the
interevent.
</p>


<h3>Value</h3>

<p>A list mainly containing a <code>interevt</code> data.frame.
</p>
<table>
<tr><td><code>interevt</code></td>
<td>

<p>Data.frame. Each row describes a retained interevent through a
<code>period</code> integer giving the &quot;noskip&quot; period, a <code>start</code> and
<code>end</code> <code>POSIXct</code> and a <code>duration</code> in <b>days</b>.
</p>
</td></tr>
<tr><td><code>noskip</code></td>
<td>

<p>Only when <code>skip</code> or <code>noskip</code> args have been given. A
data.frame containing broadly the same information as the
<code>noskip</code> arg is it was given or the information deduced from
the <code>skip</code> arg if given.
</p>
</td></tr>
<tr><td><code>axis</code></td>
<td>

<p>When needed, a list with some material to build an axis with uneven
ticks as in the <code>gof.date</code> with <code>skip.action = "omit"</code>.
</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>Only one of the two arguments <code>skip</code> and <code>noskip</code> should be
given in the call. In each case, the rows of the returned data.frame
objects describe periods in chronological order. That is: <code>start</code>
at row <code>2</code> must be after the <code>end</code> value of row <code>1</code> and
so on.
</p>
<p>Note that there are usually less interevents than dates since two
successive dates will be retained for an interevent only when they are
not separated by missing period. As a limit case, there can be no
interevents if the <code>noskip</code> periods contain only one date from
the <code>date</code> vector.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gof.date">gof.date</a></code> for goodness-of-fit diagnostics for dates of
events <code><a href="#topic+expplot">expplot</a></code> for diagnostics concerning the
exponential distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use Brest data
ie &lt;- interevt(date = Brest$OTdata$date, skip = Brest$OTmissing)

expplot(ie$interevt$duration, rate = 1 / mean(ie$interevt$duration),
  main = "No threshold")

## keep only data over a threshold
ind1 &lt;- Brest$OTdata$Surge &gt;= 35
ie1 &lt;- interevt(Brest$OTdata$date[ind1], skip = Brest$OTmissing)
expplot(ie1$interevt$duration, main = "Threshold = 35")

## increase threshold
ind2 &lt;- Brest$OTdata$Surge &gt;= 55
ie2 &lt;- interevt(date = Brest$OTdata$date[ind2], skip = Brest$OTmissing)
expplot(ie2$interevt$duration, main = "Threshold = 55 cm")
</code></pre>

<hr>
<h2 id='Jackson'>Jackson's statistic</h2><span id='topic+Jackson'></span>

<h3>Description</h3>

<p>Jackson's statistic for the exponentiality test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   Jackson(x, norm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Jackson_+3A_x">x</code></td>
<td>
<p>Numeric vector or matrix. In the second case,
rows are considered as samples.</p>
</td></tr>
<tr><td><code id="Jackson_+3A_norm">norm</code></td>
<td>
<p>Logical: if <code>TRUE</code>, the statistic is
normalized by using the <em>asymptotic</em> mean and
standard deviation, respectively 2 and 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The value(s) of the statistic are the ratio of two weighted
means of the order statistics.
</p>


<h3>Value</h3>

<p>A numeric vector of length <code>1</code> when <code>x</code> is a
vector, or with length <code>nrow(x)</code> when <code>x</code> is a
matrix.
</p>


<h3>References</h3>

<p>J. Beirlant and T. de Weit and Y. Goegebeur(2006) A
Goodness-of-fit Statistic for Pareto-Type Behaviour,
<em>J. Comp. Appl. Math.</em>, 186(1), pp. 99-116
</p>

<hr>
<h2 id='Jackson.test'>Jackson's test of exponentiality</h2><span id='topic+Jackson.test'></span>

<h3>Description</h3>

<p>Jackson's test of exponentiality
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   Jackson.test(x, method = c("num", "sim", "asymp"), nSamp = 15000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Jackson.test_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix.</p>
</td></tr>
<tr><td><code id="Jackson.test_+3A_method">method</code></td>
<td>
<p>Character: choice of the method used to
compute the <code class="reqn">p</code>-value. See the <b>Details</b>
section.</p>
</td></tr>
<tr><td><code id="Jackson.test_+3A_nsamp">nSamp</code></td>
<td>
<p>Number of samples used to compute the
<code class="reqn">p</code>-value if <code>method</code> is <code>"sim"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the Jackson's test of exponentiality.  The test
statistic is the ratio of weighted sums of the order
statistics. Both sums can also be written as weighted sums
of the <em>scalings</em>.
</p>
<p>The Jackson's statistic for a sample of size <code class="reqn">n</code> of the
exponential distribution can be shown to be approximately
normal. More precisely <code class="reqn">\sqrt{n}(J_n -2)</code> has approximately a standard normal distribution.
This distribution is used to compute the <code class="reqn">p</code>-value when
<code>method</code> is <code>"asymp"</code>. When <code>method</code> is
<code>"num"</code>, a numerical approximation of the distribution
is used. Finally, when <code>method</code> is <code>"sim"</code> the
<code class="reqn">p</code>-value is computed by simulating <code>nSamp</code>
samples of size <code>length(x)</code> and estimating the
probability to have a Jackson's statistic larger than that
of the 'observed' <code>x</code>.
</p>


<h3>Value</h3>

<p>A list of results.
</p>
<table>
<tr><td><code>statistic</code>, <code>p.value</code></td>
<td>

<p>The statistic and <code class="reqn">p</code>-value.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>Number <code class="reqn">n</code> of observations.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>Description of the test implemented, regardless of how the
<code class="reqn">p</code>-value has been computed.
</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>Jackson's test of exponentiality works fine for a Lomax alternative
(GPD with heavy tail). It then reaches nearly the same power as a
Likelihood Ratio (LR) test, see Kozubowski et al.  It can be
implemented more easily than the LR test because simulated values of
the test statistic can be obtained quickly enough to compute the
<code class="reqn">p</code>-value by simulation.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>J. Beirlant and T. de Weit and Y. Goegebeur(2006) &quot;A Goodness-of-fit
Statistic for Pareto-Type Behaviour&quot;, <em>J. Comp. Appl. Math.</em>,
186(1), pp. 99-116.
</p>
<p>T.J. Kozubowski, A. K. Panorska, F. Qeadan, A. Gershunov and
D. Rominger (2009)
&quot;Testing Exponentiality Versus Pareto Distribution via Likelihood Ratio&quot;
<em>Comm. Statist. Simulation Comput.</em> 38(1), pp. 118-139.
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+Jackson">Jackson</a></code> function computing the statistic and the
<code><a href="#topic+LRExp.test">LRExp.test</a></code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- rGPD(n = 50, loc = 0, scale = 1, shape = 0.1)
Jackson.test(x, method = "num")$p.value
Jackson.test(x, method = "asymp")$p.value
Jackson.test(x, method = "sim")$p.value
</code></pre>

<hr>
<h2 id='logLik.Renouv'>
Log-likelihood of a &quot;Renouv&quot; object
</h2><span id='topic+AIC.Renouv'></span><span id='topic+BIC.Renouv'></span><span id='topic+logLik.Renouv'></span><span id='topic+nobs.Renouv'></span>

<h3>Description</h3>

<p>Log-likelihood, AIC, BIC and number of observations of an object of class &quot;Renouv&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Renouv'
AIC(object, ..., k = 2)
## S3 method for class 'Renouv'
BIC(object, ...)
## S3 method for class 'Renouv'
logLik(object, ...)
## S3 method for class 'Renouv'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.Renouv_+3A_object">object</code></td>
<td>

<p>Object of class <code>"Renouv"</code>.
</p>
</td></tr>
<tr><td><code id="logLik.Renouv_+3A_k">k</code></td>
<td>

<p>See <code><a href="stats.html#topic+AIC">AIC</a></code>.
</p>
</td></tr>
<tr><td><code id="logLik.Renouv_+3A_...">...</code></td>
<td>

<p>Not used yet.
</p>
</td></tr>
</table>


<h3>Caution</h3>

<p>Comparing log-likelihoods, AIC or BIC for different <code>Renouv</code>
objects makes sense only when these share the same data and the same
threshold.
</p>


<h3>Note</h3>

<p><code>logLik</code>, <code>AIC</code> and <code>BIC</code> can be used with an object of
class <code>"Renouv"</code> which makes use of historical data. In this
case, the number of observations may be misleading since a single
historical observation may concern dozens of years and thus have a
much greater impact on the estimation of the tail than an &quot;ordinary&quot;
observation.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p>The <code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+nobs">nobs</a></code> generic functions.
</p>

<hr>
<h2 id='Lomax'>Lomax distribution</h2><span id='topic+Lomax'></span><span id='topic+dlomax'></span><span id='topic+plomax'></span><span id='topic+qlomax'></span><span id='topic+rlomax'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the Lomax distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   dlomax(x, scale = 1.0, shape = 4.0, log = FALSE)
   plomax(q, scale = 1.0, shape = 4.0, lower.tail = TRUE)
   qlomax(p, scale = 1.0, shape = 4.0)
   rlomax(n, scale = 1.0, shape = 4.0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lomax_+3A_x">x</code>, <code id="Lomax_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="Lomax_+3A_p">p</code></td>
<td>

<p>Vector of probabilities.
</p>
</td></tr>
<tr><td><code id="Lomax_+3A_n">n</code></td>
<td>

<p>Number of observations.
</p>
</td></tr>
<tr><td><code id="Lomax_+3A_scale">scale</code>, <code id="Lomax_+3A_shape">shape</code></td>
<td>

<p>Scale and shape parameters. Vectors of length &gt; 1 are not accepted.
</p>
</td></tr>
<tr><td><code id="Lomax_+3A_log">log</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the log density is returned.
</p>
</td></tr>
<tr><td><code id="Lomax_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Logical; if <code>TRUE</code> (default), probabilities are
<code class="reqn">\textrm{Pr}[X &lt;= x]</code>, otherwise, <code class="reqn">\textrm{Pr}[X
    &gt; x]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lomax distribution function with shape <code class="reqn">\alpha &gt; 0</code> and scale
<code class="reqn">\beta &gt; 0</code> has survival function
</p>
<p style="text-align: center;"><code class="reqn">S(y) = \left[1 + y/\beta \right]^{-\alpha} \qquad (y &gt; 0)</code>
</p>

<p>This distribution has increasing hazard and decreasing mean
residual life (MRL). The coefficient of variation decreases with
<code class="reqn">\alpha</code>, and tends to <code class="reqn">1</code> for large <code class="reqn">\alpha</code>.  The
default value <code class="reqn">\alpha=4</code> corresponds to <code class="reqn">\textrm{CV} =
  \sqrt{2}</code>.
</p>


<h3>Value</h3>

<p><code>dlomax</code> gives the density function, <code>plomax</code> gives the
distribution function, <code>qlomax</code> gives the quantile function, and
<code>rlomax</code> generates random deviates.
</p>


<h3>Note</h3>

<p>This distribution is sometimes called <em>log-exponential</em>. It is a
special case of Generalised Pareto Distribution (GPD) with positive
shape <code class="reqn">\xi &gt; 0</code>, scale <code class="reqn">\sigma</code> and location <code class="reqn">\mu=0</code>.  The
Lomax and GPD parameters are related according to </p>
<p style="text-align: center;"><code class="reqn">\alpha =
  1/\xi, \qquad \beta = \sigma/\xi.</code>
</p>
<p>  The Lomax distribution can be used in POT to describe
excesses following GPD with shape <code class="reqn">\xi&gt;0</code> thus with decreasing
hazard and increasing Mean Residual Life.
</p>
<p>Note that the exponential distribution with rate <code class="reqn">\nu</code> is the
limit of a Lomax distribution having large scale <code class="reqn">\beta</code> and large
shape <code class="reqn">\alpha</code>, with the constraint on the shape/scale ratio
<code class="reqn">\alpha/\beta = \nu</code>.
</p>


<h3>References</h3>

<p>Johnson N. Kotz S. and N. Balakrishnan 
<em>Continuous Univariate Distributions</em> vol. 1, Wiley 1994.
</p>
<p><a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution in Wikipedia</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flomax">flomax</a></code> to fit the Lomax distribution by Maximum
Likelihood. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>shape &lt;- 5; scale &lt;- 10
xl &lt;- qlomax(c(0.00, 0.99), scale = scale, shape = shape)
x &lt;- seq(from = xl[1], to = xl[2], length.out = 200)
f &lt;- dlomax(x, scale = scale, shape = shape)
plot(x, f, type = "l", main = "Lomax density")
F &lt;- plomax(x, scale = scale, shape = shape)
plot(x, F, type ="l", main ="Lomax distribution function")
</code></pre>

<hr>
<h2 id='LRExp'>Likelihood Ratio statistic for exponential vs. GPD</h2><span id='topic+LRExp'></span>

<h3>Description</h3>

<p>Likelihood Ratio statistic for the exponential distribution vs. GPD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   LRExp(x, alternative = c("lomax", "GPD", "gpd", "maxlo"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRExp_+3A_x">x</code></td>
<td>

<p>Numeric vector of positive sample values. For the POT context, this
should be the vector of excesses over the threshold.
</p>
</td></tr>
<tr><td><code id="LRExp_+3A_alternative">alternative</code></td>
<td>

<p>Character string describing the alternative hypothesis
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Likelihood-Ratio statistic is actually <code class="reqn">W:=-2 \log
    \textrm{LR}</code> where LR is the ratio of the likelihoods
<em>exponential</em> to <em>alternative distribution</em>.
</p>


<h3>Value</h3>

<p>The LR statistic value.
</p>


<h3>Note</h3>

<p>When the alternative is <code>"lomax"</code> or <code>"maxlo"</code>, the
statistic has a distribution of <em>mixed type</em> under the null
hypothesis of exponentiality. This is a mixture of a distribution of
continuous type (with positive values) and of a Dirac mass at LR =
0. The probability mass <code class="reqn">\textrm{Pr}\{\textrm{LR} = 0\}</code> can be computed using the <code><a href="#topic+pGreenwood1">pGreenwood1</a></code> function. More
precisely, the probability mass is <code>pGreenwood1(n)</code> for the Lomax
alternative and <code>1.0 - pGreenwood1(n)</code> for the maxlo alternative,
where <code>n</code> is the sample size <code>length(x)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRExp.test">LRExp.test</a></code> for the related LR test of exponentiality.
</p>

<hr>
<h2 id='LRExp.test'>Likelihood Ratio test of exponentiality vs. GPD</h2><span id='topic+LRExp.test'></span>

<h3>Description</h3>

<p>Likelihood Ratio test of exponentiality vs. GPD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   LRExp.test(x,
              alternative = c("lomax", "GPD", "gpd", "maxlo"),
              method = c("num", "sim", "asymp"),
              nSamp = 15000,
              simW = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRExp.test_+3A_x">x</code></td>
<td>

<p>Numeric vector of positive sample values. For the POT context this
should be the vector of excesses over the threshold.
</p>
</td></tr>
<tr><td><code id="LRExp.test_+3A_alternative">alternative</code></td>
<td>

<p>Character string describing the alternative distribution.
</p>
</td></tr>
<tr><td><code id="LRExp.test_+3A_method">method</code></td>
<td>

<p>Method used to compute the <code class="reqn">p</code>-value.
</p>
</td></tr>
<tr><td><code id="LRExp.test_+3A_nsamp">nSamp</code></td>
<td>

<p>Number of samples for a simulation, if <code>method</code> is
<code>"sim"</code>.
</p>
</td></tr>
<tr><td><code id="LRExp.test_+3A_simw">simW</code></td>
<td>

<p>Logical. If this is set to <code>TRUE</code> and <code>method</code>
is <code>"sim"</code>, the simulated values are returned as
an element <code>W</code> in the list.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lomax and maxlo alternatives correspond to a GPD alternative with
positive shape parameter <code class="reqn">\xi &gt; 0</code> (Lomax) and GPD with
<code class="reqn">\xi &lt; 0</code> (maxlo).
</p>
<p>The <em>asymptotic</em> distribution of the Likelihood-ratio statistic
is known. For the GPD alternative, this is a chi-square distribution
with one df.  For the Lomax alternative, this is the distribution of a
product <code class="reqn">BC</code> where <code class="reqn">B</code> and <code class="reqn">C</code> are two independent random
variables following a Bernoulli distribution with probability
parameter <code class="reqn">p = 0.5</code> and a chi-square distribution with one df.
</p>

<ul>
<li><p> When <code>method</code> is <code>"num"</code>, a numerical
approximation of the distribution is used. This method
is not unlike that used by Kozubowski et al., but a different
approximation is used. However, if <code>x</code> has a length
<code class="reqn">n &gt; 500</code>, the method is turned to <code>"asymp"</code>.
</p>
</li>
<li><p> When <code>method</code> is <code>"sim"</code>, <code>nSamp</code> samples of the
exponential distribution with the same size as <code>x</code> are drawn
and the LR statistic is computed for each sample. The <code class="reqn">p</code>-value
is simply the estimated probability that a simulated LR is greater
than the observed LR.
</p>
</li>
<li><p> Finally when <code>method</code> is <code>"asymp"</code>, the asymptotic
distribution is used.
</p>
</li></ul>
 


<h3>Value</h3>

<p>A list of results with elements <code>statistic</code>, <code>p.value</code>
and <code>method</code>. Other elements are
</p>
<table>
<tr><td><code>alternative</code></td>
<td>

<p>Character describing the alternative hypothesis.
</p>
</td></tr>
<tr><td><code>W</code></td>
<td>

<p>If <code>simW</code> is <code>TRUE</code> and <code>method</code> is <code>"sim"</code>
only.  A vector of <code>nSamp</code> simulated values of the statistic
<code class="reqn">W := -2 \log \textrm{LR}</code>.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For the Lomax alternative, the distribution of the test
statistic has <em>mixed type</em>: it can take any positive value as
well as the value <code class="reqn">0</code> with a positive probability mass. The
probability mass is the probability that the ML estimate of the GPD
shape parameter is negative, and a good approximation of it is
provided by the <code><a href="#topic+pGreenwood1">pGreenwood1</a></code> function. Note that this
probability converges to its limit <code class="reqn">0.5</code> <em>very slowly</em>, which
suggests that the asymptotic distribution provides poor results for
medium sample sizes, say <code class="reqn">&lt; 100</code>.
</p>
<p>Similarly for a maxlo alternative, the distribution of the test
statistic has mixed type: it can take any positive value as
well as the value <code class="reqn">0</code> with a positive probability mass
approximately given by <code>1 -pGreenwood1(n)</code> where <code class="reqn">n</code>
is the sample size.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>T.J. Kozubowski, A. K. Panorska, F. Qeadan, A. Gershunov and
D. Rominger (2009)
&quot;Testing Exponentiality Versus Pareto Distribution via Likelihood Ratio&quot;
<em>Comm. Statist. Simulation Comput.</em> 38(1),
pp. 118-139.
</p>
<p>The approximation method used is described in the <em>Renext
Computing Details</em> report.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lomax">Lomax</a></code>, <code><a href="#topic+Maxlo">Maxlo</a></code>, <code><a href="#topic+GPD">GPD</a></code> for the
alternatives used here.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- rGPD(n = 50, loc = 0, scale = 1, shape = 0.1)
LRExp.test(x, method = "num")$p.value
LRExp.test(x, method = "asymp")$p.value
## Not run: 
## requires much time
LRExp.test(x, method = "sim")$p.value

## End(Not run)
</code></pre>

<hr>
<h2 id='LRGumbel'>Likelihood Ratio statistic for Gumbel vs. GEV</h2><span id='topic+LRGumbel'></span>

<h3>Description</h3>

<p>Likelihood Ratio statistic for the Gumbel distribution vs. GEV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
   LRGumbel(x, alternative = c("frechet", "GEV"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRGumbel_+3A_x">x</code></td>
<td>

<p>Numeric vector of sample values.
</p>
</td></tr>
<tr><td><code id="LRGumbel_+3A_alternative">alternative</code></td>
<td>

<p>Character string describing the alternative.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Likelihood-Ratio statistic is actually <code class="reqn">W:=-2 \log
    \textrm{LR}</code> where LR is the ratio of the likelihoods
<em>Gumbel</em> to <em>alternative distribution</em>.
</p>


<h3>Value</h3>

<p>The LR statistic value.
</p>


<h3>Note</h3>

<p>When the alternative is <code>"frechet"</code>, the statistic has a
distribution of mixed type under the null hypothesis of a Gumbel
distribution.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRGumbel.test">LRGumbel.test</a></code> for the related LR test of Gumbelity.
</p>

<hr>
<h2 id='LRGumbel.test'>Likelihood Ratio test for the Gumbel distribution</h2><span id='topic+LRGumbel.test'></span>

<h3>Description</h3>

<p>Likelihood Ratio test of Gumbel vs. GEV
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   LRGumbel.test(x,
                 alternative = c("frechet", "GEV"),
                 method = c("num", "sim", "asymp"),
                 nSamp = 1500,
                 simW = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRGumbel.test_+3A_x">x</code></td>
<td>

<p>Numeric vector of sample values.
</p>
</td></tr>
<tr><td><code id="LRGumbel.test_+3A_alternative">alternative</code></td>
<td>

<p>Character string describing the alternative distribution.
</p>
</td></tr>
<tr><td><code id="LRGumbel.test_+3A_method">method</code></td>
<td>

<p>Method used to compute the <code class="reqn">p</code>-value.
</p>
</td></tr>
<tr><td><code id="LRGumbel.test_+3A_nsamp">nSamp</code></td>
<td>

<p>Number of samples for a simulation, if <code>method</code> is
<code>"sim"</code>.
</p>
</td></tr>
<tr><td><code id="LRGumbel.test_+3A_simw">simW</code></td>
<td>

<p>Logical. If this is set to <code>TRUE</code> and <code>method</code>
is <code>"sim"</code>, the simulated values are returned as
an element <code>W</code> in the list.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The asymptotic distribution of the Likelihood-ratio statistic is
known. For the GEV alternative, this is a chi-square distribution with
one df.  For the Fréchet alternative, this is the distribution of a
product <code class="reqn">XY</code> where <code class="reqn">X</code> and <code class="reqn">Y</code> are two independent random
variables following a Bernoulli distribution with probability
parameter <code class="reqn">p = 0.5</code> and a chi-square distribution with one df.
</p>

<ul>
<li><p> When <code>method</code> is <code>"num"</code>, a numerical approximation
of the distribution is used.
</p>
</li>
<li><p> When <code>method</code> is <code>"sim"</code>, <code>nSamp</code> samples of
the Gumbel distribution with the same size as <code>x</code> are drawn and
the LR statistic is computed for each sample. The <code class="reqn">p</code>-value is
simply the estimated probability that a simulated LR is greater than
the observed LR. This method requires more computation time than
the tow others.
</p>
</li>
<li><p> Finally when <code>method</code> is <code>"asymp"</code>, the asymptotic
distribution is used.
</p>
</li></ul>



<h3>Value</h3>

<p>A list of results with elements <code>statistic</code>, <code>p.value</code>
and <code>method</code>. Other elements are
</p>
<table>
<tr><td><code>alternative</code></td>
<td>

<p>Character describing the alternative hypothesis.
</p>
</td></tr>
<tr><td><code>W</code></td>
<td>

<p>If <code>simW</code> is <code>TRUE</code> and <code>method</code> is <code>"sim"</code>
only.  A vector of <code>nSamp</code> simulated values of the statistic
<code class="reqn">W := -2 \log \textrm{LR}</code>.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For the Fréchet alternative, the distribution of the test statistic
has <em>mixed type</em>: it can take any positive value as well as the
value <code class="reqn">0</code> with a positive probability mass. The probability mass
is the probability that the ML estimate of the GEV shape parameter is
negative.
</p>
<p>When <code>method</code> is <code>"sim"</code>, the computation can be slow
because each of the <code>nSamp</code> simulated values requires two
optimisations. The <code>"asymp"</code> method provides an acceptable
precision for <code class="reqn">n \geq 50</code>, and may even be used for
<code class="reqn">n \geq 30</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- rgumbel(60)
res &lt;- LRGumbel.test(x)
</code></pre>

<hr>
<h2 id='Maxlo'>'maxlo' distribution</h2><span id='topic+Maxlo'></span><span id='topic+dmaxlo'></span><span id='topic+pmaxlo'></span><span id='topic+qmaxlo'></span><span id='topic+rmaxlo'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the 'maxlo' distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   dmaxlo(x, scale = 1.0, shape = 4.0, log = FALSE)
   pmaxlo(q, scale = 1.0, shape = 4.0, lower.tail = TRUE)
   qmaxlo(p, scale = 1.0, shape = 4.0)
   rmaxlo(n, scale = 1.0, shape = 4.0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Maxlo_+3A_x">x</code>, <code id="Maxlo_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="Maxlo_+3A_p">p</code></td>
<td>

<p>Vector of probabilities.
</p>
</td></tr>
<tr><td><code id="Maxlo_+3A_n">n</code></td>
<td>

<p>Number of observations.
</p>
</td></tr>
<tr><td><code id="Maxlo_+3A_scale">scale</code>, <code id="Maxlo_+3A_shape">shape</code></td>
<td>

<p>Shift and shape parameters. Vectors of length
&gt; 1 are not accepted.
</p>
</td></tr>
<tr><td><code id="Maxlo_+3A_log">log</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the log density is returned.
</p>
</td></tr>
<tr><td><code id="Maxlo_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Logical; if <code>TRUE</code> (default), probabilities are
<code class="reqn">\textrm{Pr}[X &lt;= x]</code>, otherwise, <code class="reqn">\textrm{Pr}[X
    &gt; x]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 'maxlo' distribution function with shape <code class="reqn">\alpha&gt;0</code> and scale
<code class="reqn">\beta&gt;0</code> is a special case of Generalised Pareto (GPD) with
<em>negative shape</em> <code class="reqn">\xi &lt; 0</code> and location at zero. This is the
finite upper endpoint case of the GPD. Its name is nonstandard and was
chosen to suggest some form of symmetry with respect to the Lomax
distribution.
</p>
<p>The survival  function is
</p>
<p style="text-align: center;"><code class="reqn">S(y) = \left[1-y/\beta\right]^\alpha \qquad 0 &lt; y &lt; \beta</code>
</p>

<p>This distribution has a coefficient of variation smaller than <code class="reqn">1</code>.
</p>


<h3>Value</h3>

<p><code>dmaxlo</code> gives the density function, <code>pmaxlo</code> gives the
distribution function, <code>qmaxlo</code> gives the quantile function, and
<code>rmaxlo</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The 'maxlo' and GPD parameters are related according to </p>
<p style="text-align: center;"><code class="reqn">\alpha =
  -1/\xi, \qquad \beta = -\sigma/\xi.</code>
</p>
<p>  where <code class="reqn">\sigma</code> is the scale parameter of the
GPD. Since only GPD with <code class="reqn">\xi &gt; -0.5</code> seem to be used in practice,
this distribution should be used with <code class="reqn">\alpha &gt; 2</code>.
</p>
<p>This distribution can be used in POT to describe bounded excesses
following GPD with shape <code class="reqn">\xi &lt; 0</code>. The scale parameter
<code class="reqn">\beta</code> then represents the upper end-point of the excesses,
implying the finite upper end-point <code class="reqn">u + \beta</code> for the levels,
where <code class="reqn">u</code> is the threshold. It can be used in <code><a href="#topic+Renouv">Renouv</a></code>
with a fixed scale parameter, thus allowing a control of the upper
end-point.
</p>
<p>This distribution is simply a rescaled version of a beta distribution
and also a rescaled version of a Kumaraswamy distribution. The name
&quot;maxlo&quot; is used here to suggest a form of symmetry to Lomax
distribution.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fmaxlo">fmaxlo</a></code> to fit such a distribution by Maximum Likelihood.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xs &lt;- rmaxlo(500, shape = 2.2, scale = 1000)
hist(xs, main = "'maxlo' distribution"); rug(xs)

xs &lt;- rmaxlo(500, shape = 4, scale = 1000)
hist(xs, main = "'maxlo' distribution"); rug(xs)

x &lt;- seq(from = -10, to = 1010, by = 2)
plot(x = x, y = dmaxlo(x, shape = 4, scale = 1000),
     type = "l", ylab = "dens",
     col = "orangered", main = "dmaxlo and dgpd")
abline(h = 0)
lines(x = x, y = dgpd(x, shape = -1/4, scale = 250),
     type = "l",
     col = "SpringGreen3", lty = "dashed")



</code></pre>

<hr>
<h2 id='MixExp2'>Mixture of two exponential distributions</h2><span id='topic+MixExp2'></span><span id='topic+dmixexp2'></span><span id='topic+rmixexp2'></span><span id='topic+pmixexp2'></span><span id='topic+qmixexp2'></span><span id='topic+hmixexp2'></span><span id='topic+Hmixexp2'></span>

<h3>Description</h3>

<p>Probability functions associated to the mixture of
two exponential distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   dmixexp2(x, prob1,
            rate1 = 1.0, rate2 = rate1 + delta, delta,
            log = FALSE)
   pmixexp2(q, prob1,
            rate1 = 1.0, rate2 = rate1 + delta, delta,
            log = FALSE)
   qmixexp2(p, prob1,
            rate1 = 1.0, rate2 = rate1 + delta, delta)
   rmixexp2(n, prob1,
            rate1 = 1.0, rate2 = rate1 + delta, delta)
   hmixexp2(x, prob1,
            rate1 = 1.0, rate2 = rate1 + delta, delta)
   Hmixexp2(x, prob1,
            rate1 = 1.0, rate2 = rate1 + delta, delta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MixExp2_+3A_x">x</code>, <code id="MixExp2_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_p">p</code></td>
<td>

<p>Vector of probabilities.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_n">n</code></td>
<td>

<p>Number of observations.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_log">log</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the log density is returned.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_prob1">prob1</code></td>
<td>

<p>Probability weight for the &quot;number 1&quot; exponential density.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_rate1">rate1</code></td>
<td>

<p>Rate (inverse expectation) for the &quot;number 1&quot; exponential density.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_rate2">rate2</code></td>
<td>

<p>Rate (inverse expectation) for the &quot;number 2&quot; exponential
density. Should in most cases be <code>&gt; rate1</code>. See <em>Details</em>.
</p>
</td></tr>
<tr><td><code id="MixExp2_+3A_delta">delta</code></td>
<td>

<p>Alternative parameterisation <code>delta = rate2 - rate1</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function is the mixture of two exponential densities
</p>
<p style="text-align: center;"><code class="reqn">
    f(x) = \alpha_1 \lambda_1 \, e^{-\lambda_1 x} + (1-\alpha_1)
    \lambda_2 \, e^{-\lambda_2x} \qquad x &gt; 0
  </code>
</p>

<p>where <code class="reqn">\alpha_1</code> is the probability given in
<code>prob1</code>
while <code class="reqn">\lambda_1</code> and<code class="reqn">\lambda_2</code> are
the two rates given in <code>rate1</code> and <code>rate2</code>.

</p>
<p>A 'naive' identifiability constraint is </p>
<p style="text-align: center;"><code class="reqn">\lambda_1 &lt; \lambda_2</code>
</p>

<p>i.e.  <code>rate1 &lt; rate2</code>, corresponding to the simple constraint
<code>delta &gt; 0</code>.  The parameter <code>delta</code> can be given instead of
<code>rate2</code>.
</p>
<p>The mixture distribution has a decreasing hazard, increasing Mean
Residual Life (MRL) and has a thicker tail than the usual
exponential. However the hazard, MRL have a finite non zero limit and
the distribution behaves as an exponential for large return
levels/periods.
</p>
<p>The quantile function is not available in closed form and is computed
using a dedicated numerical method.
</p>


<h3>Value</h3>

<p><code>dmiwexp2</code>, <code>pmiwexp2</code>, <code>qmiwexp2</code>, evaluates the
density, the distribution and the quantile functions.  <code>dmixexp2</code>
generates a vector of <code>n</code> random draws from the distribution.
<code>hmixep2</code> gives hazard rate and <code>Hmixexp2</code> gives cumulative
hazard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rate1 &lt;- 1.0
rate2 &lt;- 4.0
prob1 &lt;- 0.8
qs &lt;- qmixexp2(p = c(0.99, 0.999), prob1 = prob1,
               rate1 = rate1, rate2 = rate2) 
x &lt;- seq(from = 0, to = qs[2], length.out = 200)
F &lt;- pmixexp2(x, prob1 = prob1, rate1 = rate1, rate2 = rate2)
plot(x, F, type = "l", col = "orangered", lwd = 2,
     main = "Mixexp2 distribution and quantile for p = 0.99")
abline(v = qs[1])
abline(h = 0.99)

</code></pre>

<hr>
<h2 id='mom.mixexp2'>
Moment estimation for the mixture of two exponential distributions
</h2><span id='topic+mom.mixexp2'></span>

<h3>Description</h3>

<p>Compute the moment estimation for the tree parameters of the mixture of
two exponential distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   mom.mixexp2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mom.mixexp2_+3A_x">x</code></td>
<td>

<p>Sample. Vector containing values <code>&gt;0</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three parameters (probability and the two rates) are computed from
the first three moments (theoretical and sample). It can be shown that
the inverse rates are obtained solving a quadratic equation. However
the roots can be negative or complex and the estimates are not valid
ones.
</p>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>A vector with named elements <code>"prob1"</code>, <code>"rate1"</code> and
<code>"rate2"</code>. When the moment estimators are not valid (negative
or complex rates), a vector of three <code>NA</code> is returned.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>Character <code>"moments"</code>.
</p>
</td></tr>  
</table>


<h3>Note</h3>

<p>The theoretical coefficient of variation (CV) of a mixture of two
exponential distributions always exceeds 100%. When the sample CV is
smallest than 100%, no valid estimates exist since the two first
moments can not be matched.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>Paul R. Rider. The Method of Moments Applied to a Mixture of Two
Exponential Distributions. <em>Ann. Math. Statist.</em> Vol. 32, Number
1 (1961), 143-147.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+ini.mixexp2">ini.mixexp2</a></code> for a more versatile initial estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rmixexp2(n = 100, prob1 = 0.5, rate1 = 1.0, rate2 = 3.0)
est &lt;- mom.mixexp2(x)

</code></pre>

<hr>
<h2 id='mom2par'>Parameters from moments</h2><span id='topic+mom2par'></span>

<h3>Description</h3>

<p>Compute parameters from (theoretical) moments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   mom2par(densfun = "exponential",
           mean,
           sd = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mom2par_+3A_densfun">densfun</code></td>
<td>
<p>Name of the distribution. This can be at present time:
<code>"exponential"</code>, <code>"weibull"</code>, <code>"gpd"</code>,
<code>"gamma"</code>, <code>"negative binomial"</code>.
</p>
</td></tr>
<tr><td><code id="mom2par_+3A_mean">mean</code></td>
<td>
<p>Theoretical mean (expectation) of the distribution. Can be
a vector, in which case the parameters will be vectors.</p>
</td></tr>
<tr><td><code id="mom2par_+3A_sd">sd</code></td>
<td>
<p>Standard deviation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For some distributions like Weibull, it is necessary to find
a numerical solution since the parameters have no closed form
expression involving the moments.
</p>


<h3>Value</h3>

<p>A named list containing the parameters values e.g. with names <code>shape</code>
and <code>scale</code>. When <code>mean</code> or <code>sd</code> is vector the list
contains vectors. 
</p>


<h3>Note</h3>

<p>The name of the formal argument <code>densfun</code> is for compatibility with
<code>fitdistr</code> from the MASS package. However, unlike in
<code>fitdistr</code>  this formal can not be given a density value, i.e. an
object of the class <code>"function"</code> such as <code>dnorm</code>. 
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Weibull
mom2par(densfun = "weibull", mean = 1, sd = 2) 
## Genrealised Pareto
mom2par(densfun = "gpd", mean = 1, sd = 2)
## Gamma
mom2par(densfun = "gamma", mean = 1:10, sd = 1)
</code></pre>

<hr>
<h2 id='NBlevy'>Negative Binomial Levy process</h2><span id='topic+NBlevy'></span>

<h3>Description</h3>

<p>Negative Binomial Lévy process estimation from partial observations (counts)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NBlevy(N,
       gamma = NA,
       prob = NA,
       w = rep(1, length(N)),
       sum.w = sum(w),
       interval = c(0.01, 1000),
       optim = TRUE,
       plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NBlevy_+3A_n">N</code></td>
<td>

<p>Vector of counts, one count by time period.
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_gamma">gamma</code></td>
<td>

<p>The <code>gamma</code> parameter if known (NOT IMPLEMENTED YET).
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_prob">prob</code></td>
<td>

<p>The <code>prob</code> parameter if known (NOT IMPLEMENTED YET).
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_w">w</code></td>
<td>

<p>Vector of time length (durations).
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_sum.w">sum.w</code></td>
<td>

<p>NOT IMPLEMENTED YET. The effective duration. If <code>sum.w</code> is
strictly inferior to <code>sum(w)</code>, it is to be understood that
missing periods occur within the counts period. This can be taken
into account with a suitable algorithm (Expectation Maximisation,
etc.)
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_interval">interval</code></td>
<td>

<p>Interval giving min and max values for <code>gamma</code>.
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_optim">optim</code></td>
<td>

<p>If <code>TRUE</code> a one-dimensional optimisation is used. Else the zero
of the derivative of the (concentrated) log-likelihood is searched
for.
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_plot">plot</code></td>
<td>

<p>Should a plot be drawn? <em>May be removed in the future</em>.
</p>
</td></tr>
<tr><td><code id="NBlevy_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector <code class="reqn">\mathbf{N}</code> contains counts for events occurring on
non-overlapping time periods with lengths given in
<code class="reqn">\mathbf{w}</code>.  Under the NB Lévy process
assumptions, the observed counts (i.e. elements of
<code class="reqn">\mathbf{N}</code>) are independent random variables, each following
a negative binomial distribution.  The size parameter <code class="reqn">r_k</code>
for <code class="reqn">N_k</code> is <code class="reqn">r_k = \gamma w_k</code> and
the probability parameter <code class="reqn">p</code> is <code>prob</code>.  The vector
<code class="reqn">\boldsymbol{\mu}</code> of the expected counts has elements
</p>
<p style="text-align: center;"><code class="reqn">\mu_k=\mathrm{E}(N_k)=\frac{1-p}{p} \,\gamma \,w_k.</code>
</p>

<p>The parameters <code class="reqn">\gamma</code> and <code class="reqn">p \:(\code{prob})</code>
are estimated by Maximum Likelihood using the likelihood concentrated
with respect to the <code>prob</code> parameter.
</p>


<h3>Value</h3>

<p>A list with the results
</p>
<table>
<tr><td><code>estimate</code></td>
<td>

<p>Parameter estimates.
</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>Standard deviation for the estimate.
</p>
</td></tr>
<tr><td><code>score</code></td>
<td>

<p>Score vector at the estimated parameter vector.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>Observed information matrix.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>Covariance matrix (approx.).
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Negative Binomial Lévy process is an alternative to
the Homogeneous Poisson Process when counts are subject to
overdispersion. In the NB process, all counts share the same index of
dispersion (variance/expectation ratio), namely <code>1/prob</code>. When
<code>prob</code> is close to 1, the counts are nearly Poisson-distributed.
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>References</h3>

<p>Kozubowski T.J. and Podgórsky K. (2009)
&quot;Distributional properties of the negative binomial Lévy process&quot;.
<em>Probability and Mathematical Statistics</em> <b>29</b>, pp. 43-71.
Lund University Publications.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code> for the negative binomial distribution,
<code><a href="MASS.html#topic+glm.nb">glm.nb</a></code> from the MASS package for fitting Generalised
Linear Model of the negative binomial family.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## known parameters
nint &lt;- 100
gam &lt;- 6; prob &lt;- 0.20

## draw random w, then the counts N
w &lt;- rgamma(nint, shape = 3, scale = 1/5)
N &lt;- rnbinom(nint, size = w * gam, prob = prob)
mu &lt;- w * gam * (1 - prob) / prob
Res &lt;- NBlevy(N = N, w = w)

## Use example data 'Brest'
## compute the number of event and duration of the non-skipped periods
gof1 &lt;- gof.date(date = Brest$OTdata$date,
                 skip = Brest$OTmissing,
                 start = Brest$OTinfo$start,
                 end = Brest$OTinfo$end,
                 plot.type = "omit")
ns1 &lt;- gof1$noskip
## fit the NBlevy
fit1 &lt;- NBlevy(N = ns1$nevt, w = ns1$duration)

## use a higher threshold
OT2 &lt;- subset(Brest$OTdata, Surge &gt; 50)
gof2 &lt;- gof.date(date = OT2$date,
                 skip = Brest$OTmissing,
                 start = Brest$OTinfo$start,
                 end = Brest$OTinfo$end,
                 plot.type = "omit")
ns2 &lt;- gof2$noskip
## the NBlevy prob is now closer to 1
fit2 &lt;- NBlevy(N = ns2$nevt, w = ns2$duration)

c(fit1$prob, fit2$prob)
</code></pre>

<hr>
<h2 id='OT2MAX'>Temporal aggregation of a Marked Process</h2><span id='topic+OT2MAX'></span>

<h3>Description</h3>

<p>Temporal aggregation of a Marked Process, leading to block maxima or
<code class="reqn">r</code>-largest observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  OT2MAX(OTdata,
         OTmissing = NULL,
         start = NULL,
         end = NULL,
         MAX.r = 1L,
         blockDuration = "year",
         monthGapStat = TRUE,
         maxMissingFrac = 0.05,
         dataFrames = FALSE,
         infMAX = FALSE,
         plot = TRUE,
         plotType = c("max", "gaps"),
         jitterSeed = 123,
         trace = 0L,
         ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OT2MAX_+3A_otdata">OTdata</code></td>
<td>

<p>Data frame containing a <code>POSIXct</code>
column <code>date</code> and the marks variable.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_otmissing">OTmissing</code></td>
<td>

<p>Optional data frame with columns <code>start</code> and <code>end</code>
(coerced to <code>POSIXct</code>) giving the beginning and the end of
gaps.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_start">start</code></td>
<td>

<p>An object coerced to <code>POSIXct</code> indicating the beginning of
reliable/usable information. Unless this is a beginning of block
(1-st of January for years), the 1-st block will begin <em>after</em>
<code>start</code> in order to use only qualified information.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_end">end</code></td>
<td>

<p>An object indicating the end of the reliable/usable
information. Unless this is a end of block (1-st of January for
years), the last block will end <em>before</em> <code>end</code> in order to
use only qualified information.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_max.r">MAX.r</code></td>
<td>

<p><em>Target</em> number of observations in the blocks. Can be of length
one (same number of observations for all blocks) or of length equal
to the number of blocks, the values being then for the blocks in the
same order. In both cases, the target number may be impossible to
reach because of a smaller number of events in the block. If
<code>infMAX</code> is <code>TRUE</code>, the target number of observations will
be reached by filling if needed with <code>-Inf</code> values. The
rationale for this is that a non-existing event is assumed to have
an arbitrarily small mark.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_blockduration">blockDuration</code></td>
<td>

<p>Duration of the blocks. Can only be <code>"year"</code> for now.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_monthgapstat">monthGapStat</code></td>
<td>

<p>Logical. Setting it to <code>TRUE</code> will compute statistics
concerning the gaps and return them or show them on a plot.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_maxmissingfrac">maxMissingFrac</code></td>
<td>

<p>Maximal fraction of a block duration (between 0 and 1) that can be
missing without leading to a <code>NA</code> aggregated value.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_dataframes">dataFrames</code></td>
<td>

<p>If <code>TRUE</code>, the result will contain data frames similar
to those found in an object with class <code>"Rendata"</code>. If
<code>FALSE</code> the result will contain <em>list</em> and <em>vector</em>
objects, similar to those used as inputs in the <code><a href="#topic+Renouv">Renouv</a></code>
function under the names <code>MAX.data</code> and
<code>MAX.effDuration</code>. Note however, that <code>-Inf</code> values can be
found in these objects when <code>infMAX</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_infmax">infMAX</code></td>
<td>

<p>If <code>FALSE</code>, the target number of values the blocks will generally
not be reached, because the total number of events in a block can be
lower than the target number. Then, the target number value is revised
to the number of found values in each block. If <code>TRUE</code>, the
target number of values is reached by filling the values with
<code>-Inf</code> and the datetimes with (<code>POSIXct</code>) <code>NA</code>s.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_plot">plot</code></td>
<td>

<p>If <code>TRUE</code> a simple plot is shown.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_plottype">plotType</code></td>
<td>

<p>Character controlling the plot. With <code>"max"</code>, the block maxima
are shown. With <code>plotType = "gap"</code>, the daily and monthly gap
rates are shown. This is possible when suitable information
concerning gaps is provided in <code>OTmissing</code>. The plot then shows
the probability that a given day of the year falls in a gap, as well
as monthly gap rates. Most often one wants that the gap rate does
not show a seasonal behaviour. Note that gap rates for month-year
combinations are shown as grey segments after jitterizing them since
the values <code>0</code> and <code>1</code> may be observed for several
years. An alternative way to is using the <code>monthGapTS</code>
multivariate time series returned by the function, see
<b>Examples</b>.
</p>
</td></tr> <tr><td><code id="OT2MAX_+3A_jitterseed">jitterSeed</code></td>
<td>

<p>Random seed for jittering. Used only when <code>plot</code> is
<code>TRUE</code>, <code>plotType</code> is <code>"gap"</code> and when suitable
information is provided in <code>OTmissing</code>.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_trace">trace</code></td>
<td>

<p>Integer level of verbosity.
</p>
</td></tr>
<tr><td><code id="OT2MAX_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data frame given in <code>OTdata</code> contains the <em>events</em> (or
<em>arrivals</em>) given by the <code>date</code> column, as well as one mark
column. Depending on the argument <code>MAX.r</code>, the maxima or the
<code class="reqn">r</code>-largest observations of the marks is computed for each time
block. When known gaps exist in the data and when they are given in
<code>OTmissing</code>, a block for which the total duration of gaps is too
large will be omitted.
</p>


<h3>Value</h3>

<p>A list, the content of which depends on the value of
<code>dataFrames</code>. If this value is <code>TRUE</code>, the
following elements are returned.
</p>
<table>
<tr><td><code>MAXdata</code></td>
<td>

<p>A data frame of largest values by block with one row for
each observation. The largest values are given as columns
with names equal to those in the <code>OTdata</code> data
frame.
</p>
</td></tr>
<tr><td><code>MAXinfo</code></td>
<td>

<p>A data frame describing the blocks, with one row by
block. The two (<code>POSIXct</code>) columns <code>"start"</code>
and <code>"end"</code> provide the beginning and the end of the
block.  The numeric column <code>duration</code> gives the
<em>effective duration</em> (in year) within block.
</p>
</td></tr>
<tr><td><code>probMissing</code></td>
<td>

<p>A vector with values corresponding to the days in a block
(year). Each value is a estimation of the probability
that the day falls in a gap.
</p>
<p>If <code>dataFrames</code> is <code>FALSE</code>, the list still
contains <code>probMissing</code> as before, as well as other
lists as used in <code><a href="#topic+Renouv">Renouv</a></code>.
</p>
</td></tr>
<tr><td><code>effDuration</code>, <code>r</code></td>
<td>

<p>Vectors containing the effective duration (<em>in
years</em>) and number of value for the blocks.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>List of maxima or <code class="reqn">r</code>-largest values for the blocks.
</p>
</td></tr>
<tr><td><code>monthGapStat</code>, <code>monthGapTS</code></td>
<td>

<p>Summary information concerning gaps, if <code>monthGapStat</code> is
<code>TRUE</code> and if relevant information is provide via the the
<code>OTmissing</code> formal. The element <code>monthGapTS</code> is a
multivariate time series with yearly observations and one series
(column) for each of the 12 months. Each series contains the missing
fraction of the month for the considered year, ranging from
<code>0.0</code> (no gap) to <code>1.0</code> (full gap). This object can be
dealt with standard methods for time-series, but the <code>plot</code>
method will require to select a reduced number of columns first,
see <b>Examples</b>.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Remind that even when <code>maxMissingFrac</code> is set to its maximum
value 1.0, there can still be blocks with no data. When the result is
intended to be used in the <code><a href="#topic+Renouv">Renouv</a></code> function, the formal
<code>dataFrames</code> should be <code>FALSE</code>; the elements <code>data</code> and
<code>effDuration</code> can then be passed as <code>MAX.data</code> and
<code>MAX.effDuration</code>. At the time <code>infMAX</code> should also then be
set to <code>FALSE</code> since <code>-Inf</code> values are not yet allowed in
the <code class="reqn">r</code>-largest values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use Dunkerque data
OTdata &lt;- Dunkerque$OTdata; OTmissing &lt;- Dunkerque$OTmissing
## allow up to 50\% gap in a block, or only 5\%
MAX1 &lt;- OT2MAX(OTdata = OTdata, OTmissing = OTmissing,
               maxMissingFrac = 0.5,
               main = "impact of the 'maxMissingFrac' formal")
MAX2 &lt;- OT2MAX(OTdata = OTdata, OTmissing = OTmissing, dataFrames = TRUE,
               prefix = "Max", maxMissingFrac = 0.05, plot = FALSE)
lines(MAX2$MAXdata$date, MAX2$MAXdata$Surge, type = "h", col = "red", lwd = 3)
legend("topleft", lw = c(1, 3), col = c("black", "orangered"),
       legend = c("50\% max", " 5\% max"))

## r-largest obs for r = 4
MAX3 &lt;- OT2MAX(OTdata, OTmissing = OTmissing, MAX.r = 4,
               maxMissingFrac = 0.9, 
               dataFrames = FALSE, trace = TRUE,
               main = "r-largest with r = 4")

## restrict the period
MAX4 &lt;- OT2MAX(OTdata, OTmissing = OTmissing, MAX.r = 4,
               start = "1962-01-01",
               end = "1990-01-01",
               maxMissingFrac = 0.9, 
               dataFrames = FALSE, trace = TRUE,
               main = "r-largest with r = 4 with given 'start' and 'end'")
## Not run: 
  ## use in a block maxima analysis, as if there were no gaps.
  fit &lt;- fGEV.MAX(MAX.data = MAX3$data,
                  MAX.effDuration = rep(1, length(MAX3$effDuration)))     

## End(Not run)
## plot the gap rate
MAX5 &lt;- OT2MAX(OTdata = OTdata, OTmissing = OTmissing,
               maxMissingFrac = 0.5,
               main = "probability of being in a  gap",
               plotType = "gap")

## time series plot (only &lt;= 10 months)
plot(MAX5$monthGapTS[ , c(1:4)], main = "gap rate by month")

## much better with lattice.
## Not run: 
    require(lattice)
    xyplot(MAX5$monthGapTS)

## End(Not run)
</code></pre>

<hr>
<h2 id='OTjitter'>
Add a small amount of noise to a numeric vector
</h2><span id='topic+OTjitter'></span>

<h3>Description</h3>

<p>Add a small amount of noise to a numeric vector keeping all the
values above the given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OTjitter(x, threshold = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OTjitter_+3A_x">x</code></td>
<td>
<p>The numeric vector to which <em>jitter</em> should be added.
</p>
</td></tr>
<tr><td><code id="OTjitter_+3A_threshold">threshold</code></td>
<td>
<p>A threshold above which all elements of the
modified vector must stay.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the same length and nearly the same values
as <code>x</code>. As in <code><a href="base.html#topic+jitter">jitter</a></code>, a small amount of noise is
added to each value of <code>x</code>. The noise level is adjusted so that
every noisy value remains above the specified threshold. When the
a value is very close to the threshold, only a very small amount of
negative noise can be added.
</p>


<h3>Note</h3>

<p>The aim of this function is to remove possible ties in experimental OT
data. Ties cause problems or warnings in some goodness-of-fit tests such
as Kolmogorov-Smirnov.
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+jitter">jitter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Garonne data (heavily rounded)
x &lt;- Garonne$OTdata$Flow
min(x) 
xmod &lt;- OTjitter(x, threshold = 2500)
length(x)
nlevels(as.factor(x))
nlevels(as.factor(xmod))
max(abs(x-xmod))
</code></pre>

<hr>
<h2 id='parDeriv'>
Derivation of probability functions with respect to the parameters
</h2><span id='topic+parDeriv'></span>

<h3>Description</h3>

<p>Derivation of probability functions with respect to the parameters
by using closed forms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parDeriv(par, x, distname, sum = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parDeriv_+3A_par">par</code></td>
<td>

<p>Vector of parameter values.
</p>
</td></tr>
<tr><td><code id="parDeriv_+3A_x">x</code></td>
<td>

<p>Observations or data at which the derivatives are to be computed.
</p>
</td></tr>
<tr><td><code id="parDeriv_+3A_distname">distname</code></td>
<td>

<p>Name of the distribution. See <b>Details</b>.
</p>
</td></tr>
<tr><td><code id="parDeriv_+3A_sum">sum</code></td>
<td>

<p>Logical. If <code>TRUE</code>, a summation over the element of <code>x</code> is
carried. Otherwise, the first dimension of the result corresponds to
the elements of <code>x</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only a few distributions are and will be available. For now, these are:
the two-parameter Weibull <code>c("shape", "scale")</code>, the
two-parameter Generalised Pareto, <code>c("scale", "shape")</code> and
the two-parameter Lomax and maxlo distributions.
</p>


<h3>Value</h3>

<p>A list of arrays containing the first and second order derivatives.
</p>
<table>
<tr><td><code>derLogdens</code>, <code>der2Logdens</code></td>
<td>
<p>Derivatives of the log-density
<code class="reqn">\log f(x)</code>.</p>
</td></tr>  <tr><td><code>derSurv</code>, <code>der2Surv</code></td>
<td>
<p>Derivatives of
the survival function <code class="reqn">S(x)</code>.</p>
</td></tr></table>
<p>  When <code>x</code> has length <code class="reqn">n</code>
and the distribution depends on <code class="reqn">p</code> parameters, the arrays of
first and second order derivatives have dimension <code class="reqn">n \times
  p</code> and <code class="reqn">n \times p \times p</code> when <code>sum</code> is
<code>FALSE</code>. If <code>sum</code> is <code>TRUE</code> the summation drops the
first dimension and the arrays are <code class="reqn">p</code> and <code class="reqn">p \times
  p</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>See the <em>Renext Computing Details</em> document.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Maxlo">Maxlo</a></code> and <code><a href="#topic+Lomax">Lomax</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
distname &lt;- "maxlo"
if (distname == "weibull") {
    logL &lt;- function(par) {
        sum(dweibull(x, shape = par["shape"], scale = par["scale"], log = TRUE))
    }
    sumS &lt;- function(par) {
        sum(pweibull(x, shape = par["shape"], scale = par["scale"],
                     lower.tail = FALSE))
    }
    pars &lt;- c("shape" = rexp(1), "scale" = 1000 * rexp(1))
    x &lt;- rweibull(n = 100, shape = pars["shape"], scale = pars["scale"])
    Der &lt;- parDeriv(par = pars, x = x, distname = "weibull") 
} else if (distname == "gpd") {
    require(evd)
    logL &lt;- function(par) {
        sum(dgpd(x, loc = 0, shape = par["shape"], scale = par["scale"],
                 log = TRUE))
    }
    sumS &lt;- function(par) { 
        sum(pgpd(x, loc = 0, shape = par["shape"], scale = par["scale"],
                 lower.tail = FALSE))
    }
    pars &lt;- c("scale" = 1000 * rexp(1),
              "shape" = runif(1, min = -0.4, max = 0.4))
    x &lt;- rgpd(n = 100, loc = 0, shape = pars["shape"], scale = pars["scale"])
    Der &lt;- parDeriv(par = pars, x = x, distname = "gpd")
} else if (distname == "lomax") {
    logL &lt;- function(par) {
        sum(dlomax(x, shape = par["shape"], scale = par["scale"], log = TRUE))
    }
    sumS &lt;- function(par) { 
        sum(plomax(x, shape = par["shape"], scale = par["scale"],
                   lower.tail = FALSE))
    }
    pars &lt;- c( "shape" = 1 + rexp(1), "scale" = 1000 * rexp(1))
    x &lt;- rlomax(n = 100, shape = pars["shape"], scale = pars["scale"])
    Der &lt;- parDeriv(par = pars, x = x, distname = "lomax") 
} else if (distname == "maxlo") {
    logL &lt;- function(par) {
        sum(dmaxlo(x, shape = par["shape"], scale = par["scale"], log = TRUE))
    }
    sumS &lt;- function(par) { 
        sum(pmaxlo(x, shape = par["shape"], scale = par["scale"],
                   lower.tail = FALSE))
    }
    pars &lt;- c( "shape" = 2.5 + runif(1), "scale" = 100 * rexp(1))
    x &lt;- rmaxlo(n = 100, shape = pars["shape"], scale = pars["scale"])
    Der &lt;- parDeriv(par = pars, x = x, distname = "maxlo") 
}

## check logdens
H &lt;- numDeriv::hessian(func = logL, x = pars)
colnames(H) &lt;- names(pars)
Grad &lt;- numDeriv::grad(func = logL, x = pars)

cat("gradient for log density\n")
print(cbind(parDeriv = Der$derLogdens, num = Grad))

cat("hessian for log density\n")
print(cbind(exact = Der$der2Logdens, num = H))

## check survival
HS &lt;- numDeriv::hessian(func = sumS, x = pars)
HS &lt;- (HS + t(HS))/2
colnames(HS) &lt;- names(pars)
GradS &lt;- numDeriv::grad(func = sumS, x = pars)

cat("gradient for Survival\n")
print(cbind(parDeriv = Der$derSurv, num = GradS))

cat("hessian for Survival\n")
print(cbind(exact = Der$der2Surv, num = HS))
</code></pre>

<hr>
<h2 id='parIni.MAX'>
Initial estimation of GPD parameters for an aggregated renewal model
</h2><span id='topic+parIni.MAX'></span><span id='topic+parIni.OTS'></span>

<h3>Description</h3>

<p>Initial estimation for an aggregated renewal model with GPD marks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parIni.MAX(MAX, threshold, distname.y = "exp")
parIni.OTS(OTS, threshold, distname.y = "exp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parIni.MAX_+3A_max">MAX</code></td>
<td>

<p>A list describing partial observations of <code>MAX</code> type. These are
block maxima or block <code class="reqn">r</code>-largest statistics. The list must
contain elements named <code>block</code>, <code>effDuration</code>, <code>r</code>,
and <code>data</code> (a by-block list of <code class="reqn">r</code>-largest statistics).
</p>
</td></tr>
<tr><td><code id="parIni.MAX_+3A_ots">OTS</code></td>
<td>

<p>A list describing partial observations of <code>OTS</code> type. These are
observations above the block thresholds, each being not smaller than
<code>threshold</code>. This list contains <code>block</code>,
<code>effDuration</code>, <code>threshold</code>, <code>r</code> and <code>data</code> (a
by-block list of observations).
</p>
</td></tr>
<tr><td><code id="parIni.MAX_+3A_threshold">threshold</code></td>
<td>

<p>The threshold of the POT-renewal model. This is the location
parameter of the marks from which Largest Order Statistics are
observed.
</p>
</td></tr>
<tr><td><code id="parIni.MAX_+3A_distname.y">distname.y</code></td>
<td>

<p>The name of the distribution. For now this can be <code>"exp"</code> or
<code>"exponential"</code> for exponential excesses implying Gumbel
block maxima, or <code>"gpd"</code> for GPD excesses implying GEV block
maxima. The initialisation is the same in all cases, but the result
is formatted according to the target distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions estimate the Poisson rate <code>lambda</code> along with the
shape parameter say <code>sigma</code> for exponential excesses.  If the
target distribution is GPD, then the initial shape parameter is taken
to be 0.
</p>
<p>In the &quot;MAX&quot; case, the estimates are obtained by regressing the maxima
or <code class="reqn">r</code>-Largest Order Statistics within the blocks on the
log-duration of the blocks. The response for a block is the minimum of
the <code class="reqn">r</code> available Largest Order Statistics as found within the
block, and <code class="reqn">r</code> will generally vary across block.  When some blocks
contain <code class="reqn">r &gt; 1</code> largest order statistics, the corresponding
spacings are used to compute a spacings-based estimation of
<code class="reqn">\sigma</code>. This estimator is independent of the regression
estimator for <code class="reqn">\sigma</code> and the two estimators can be combined in a
weighted mean.
</p>
<p>In the &quot;OTS&quot; case, the estimate of <code>lambda</code> is obtained by a
Poisson regression using the log durations of the blocks as an
offset. The estimate of <code>sigma</code> is simply the mean of all the
available excesses, which by assumption share the same exponential
distribution.
</p>


<h3>Value</h3>

<p>A vector containing the estimate of the Poisson rate <code class="reqn">\lambda</code>,
and the estimates of the parameters for the target distribution of the
excesses. For exponential excesses, these are simply a
<code>rate</code> parameter. For <code>GPD</code> excesses, these are the
<code>scale</code> and <code>shape</code> parameters, the second taken as zero.
</p>


<h3>Note</h3>

<p>In the MAX case, the estimation is possible only when the number of
blocks is greater than <code class="reqn">1</code>, since otherwise no information about
<code class="reqn">\lambda</code> can be gained from the data; recall that the time at
which the events occurred within a block is not known or used.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>See the document <em>Renext Computing Details</em>.
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+spacings">spacings</a></code> methods for the spacings used in the
estimation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
## initialisation for 'MAX' data
u &lt;- 10
nBlocks &lt;- 30
nSim &lt;- 100
ParMAX &lt;- matrix(NA, nrow = nSim, ncol = 2)
colnames(ParMAX) &lt;- c("lambda", "sigma")

for (i in 1:nSim) {
  rd &lt;- rRendata(threshold = u,
                 effDuration = 1,
                 lambda = 12,
                 MAX.effDuration = c(60, rexp(nBlocks)),
                 MAX.r = c(5, 2 + rpois(nBlocks, lambda = 1)),
                 distname.y = "exp", par.y = c(rate = 1 / 100))

  MAX &lt;- Renext:::makeMAXdata(rd)
  pari &lt;- parIni.MAX(MAX = MAX, threshold = u)
  ParMAX[i, ] &lt;- pari   
}
## the same for OTS data
u &lt;- 10
nBlocks &lt;- 10
nSim &lt;- 100
ParOTS &lt;- matrix(NA, nrow = nSim, ncol = 2)
colnames(ParOTS) &lt;- c("lambda", "sigma")
rds &lt;- list()

for (i in 1:nSim) {
  rd &lt;- rRendata(threshold = u,
                 effDuration = 1,
                 lambda = 12,
                 OTS.effDuration = rexp(nBlocks, rate = 1 / 10),
                 OTS.threshold = u + rexp(nBlocks, rate = 1 / 10),
                 distname.y = "exp", par.y = c(rate = 1 / 100))
  rds[[i]] &lt;- rd
  OTS &lt;-  Renext:::makeOTSdata(rd)
  pari &lt;- parIni.OTS(OTS = OTS, threshold = u)
  ParOTS[i, ] &lt;- pari   
}

</code></pre>

<hr>
<h2 id='pGreenwood1'>Probability that the Greenwood's statistic is smaller than one</h2><span id='topic+pGreenwood1'></span>

<h3>Description</h3>

<p>Probability that the Greenwood's statistic is smaller than one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
   pGreenwood1(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pGreenwood1_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability was computed by using the approximation of the
quantile function of the Greenwood's statistic returned by
<code><a href="#topic+qStat">qStat</a></code>. The result is found by interpolating the
distribution function for <code class="reqn">x = 1</code>.
</p>


<h3>Value</h3>

<p>Probability that the Greenwood's statistic is smaller than one. For a
random sample of an exponential distribution with size <code class="reqn">n</code>, this
is the probability that the coefficient of variation is less than one,
or the probability that the ML estimate of the GPD shape parameter
<code class="reqn">\xi</code> is negative.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 8:500
plot(n, pGreenwood1(n), type = "l", col = "orangered", lwd = 2,
     log ="x", ylim =c(0.5, 0.7), main = "slow convergence to 0.5")
grid() ; abline(h = 0.5, col = "SpringGreen")
</code></pre>

<hr>
<h2 id='plot.Rendata'>Plot a Rendata object</h2><span id='topic+plot.Rendata'></span>

<h3>Description</h3>

<p>Plot 'Rendata' datasets with OT and historical data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
    ## S3 method for class 'Rendata'
plot(x,
     textOver = quantile(x$OTdata[, x$info$varName], probs = 0.99),
     showHist = TRUE,
                 ...) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Rendata_+3A_x">x</code></td>
<td>

<p>Rendata object i.e. a list object as read with the <code>readXML</code>
function.
</p>
</td></tr>
<tr><td><code id="plot.Rendata_+3A_textover">textOver</code></td>
<td>

<p>Mark values of the variable in the <code>OTdata</code> part of
<code>x</code>. Values above the <code>textOver</code> value (if any) will be
marked with the character version of the block, typically a year
</p>
</td></tr>
<tr><td><code id="plot.Rendata_+3A_showhist">showHist</code></td>
<td>

<p>If <code>TRUE</code>, the historical periods (is any) are shown on the
plot.
</p>
</td></tr>
<tr><td><code id="plot.Rendata_+3A_...">...</code></td>
<td>

<p>further args to be passed to <code>plot</code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot shows the main data of the object <code>x</code> (the <code>OTdata</code>
part) as well as historical data <code>MAXdata</code> or <code>OTSdata</code> if
any. Different colours are used on the background. This function is
not intended to produce nice plots to be printed.
</p>


<h3>Note</h3>

<p>This function is mainly a companion function of <code>readXML</code>. Its
goal is to check the content of the data read.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readXML">readXML</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require(XML)) {
   ## use 'index.xml' file shipped with Renext
   dir1 &lt;- system.file("Rendata", package = "Renext")
   BrestNew &lt;- readXML(name = "Brest", dir = dir1)
   plot(BrestNew)
   GaronneNew &lt;- readXML(name = "Garonne", dir = dir1)
   plot(GaronneNew)
   test1 &lt;- readXML(name = "test1", dir = dir1)
   plot(test1)
}
</code></pre>

<hr>
<h2 id='plot.Renouv'>
Plot an object of class &quot;Renouv&quot;
</h2><span id='topic+plot.Renouv'></span><span id='topic+lines.Renouv'></span>

<h3>Description</h3>

<p>Plot an object of class &quot;Renouv&quot;. The plot is a return level plot with
some supplementary elements to display historical data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Renouv'
plot(x,
     pct.conf = x$pct.conf,
     show = list(OT = TRUE, quant = TRUE, conf = TRUE,
                 MAX = TRUE, OTS = TRUE),
     mono = TRUE,
     predict = FALSE,
     par = NULL,
     legend = TRUE,
     label = NULL,
     problim = NULL,
     Tlim = NULL,
     main = NULL, xlab = "periods", ylab = "level",
     posOptions = NULL,
     byBlockStyle = NULL,
     ...)
## S3 method for class 'Renouv'
lines(x,
      pct.conf = x$pct.conf,
      show = NULL,
      mono = TRUE,
      predict = FALSE,
      par = NULL,
      legend = FALSE,
      label = NULL,
      posOptions = NULL,
      byBlockStyle = NULL,
      ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Renouv_+3A_x">x</code></td>
<td>

<p>Object of class <code>"Renouv"</code>.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_pct.conf">pct.conf</code></td>
<td>

<p>Percents for confidence limits (lower and
upper). These levels should be found within those computed in the
object <code>x</code>. By default, all computed levels will be used.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_show">show</code></td>
<td>

<p>A <em>list with named elements</em> specifying which parts of the
return level plot must be drawn. Element <code>OT</code> is for the the
sample points (Over the Threshold data), <code>quant</code> is for the
quantile curve (or Return Level curve), <code>conf</code> is for the
confidence limits. These three elements can be set to <code>TRUE</code> or
<code>FALSE</code>.  When the element <code>conf</code> is <code>TRUE</code>, only the
percent levels given in <code>pct.conf</code> are drawn. Moreover, the
levels not already computed in the object given in <code>x</code> will be
drawn only if the predictions are recomputed with <code>predict</code> set
to <code>TRUE</code>.  Finally, the <code>MAX</code> and <code>OTS</code> elements are
for the two possible types of historical data. They can be logical
vectors with length one or with length equal to the corresponding of
blocks if only some blocks are to be shown. These two elements can
also be character vectors indicating the names of the blocks which
are to be shown (by partial matching). These names should match one
or several elements of the character vector named <code>blockNames</code>
within the lists <code>x$history.MAX</code> or <code>x$history.OTS</code>
respectively.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_mono">mono</code></td>
<td>

<p>Logical, <code>TRUE</code> for a monochrome plot.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_predict">predict</code></td>
<td>

<p>Logical. When <code>TRUE</code>, predictions are re-computed from the
model before plotting. One effect is that the points used to draw
the curves are designed to cover the whole range (if specified by
the user). One other effect is that the confidence limits are
recomputed in order to include the percent levels given on entry.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_par">par</code></td>
<td>

<p>A list such as returned by the <code><a href="#topic+RLpar">RLpar</a></code> function.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_legend">legend</code></td>
<td>

<p>Logical. If <code>TRUE</code>, a legend is built and drawn on the graph. 
</p>
</td></tr>








<tr><td><code id="plot.Renouv_+3A_label">label</code></td>
<td>

<p>A character label used to build the labels used in the legend. The
default is to use the name of the <code>x</code> object. Using an empty
string <code>""</code> can be better in some cases.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_problim">problim</code></td>
<td>

<p>Limits for the x-axis in probability scale. Can be used as an
alternative to <code>Tlim</code>.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_tlim">Tlim</code></td>
<td>

<p>Limits for the x-axis in return period scale. The values are given
as a numeric vector of length 2, containing values <code class="reqn">\ge 1</code>.
The first element (minimal return period can be 0 in which case it
will be replaced by a very small positive value.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_xlab">xlab</code></td>
<td>

<p>Label of the x-axis (time periods, with log scale).
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_main">main</code></td>
<td>

<p>Main title (character).
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_ylab">ylab</code></td>
<td>

<p>Label of the y-axis (labels).
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_posoptions">posOptions</code></td>
<td>

<p>A pair list to be passed as list of formals to the <code><a href="#topic+SandT">SandT</a></code>
function computing the plotting positions.
</p>
</td></tr>









<tr><td><code id="plot.Renouv_+3A_byblockstyle">byBlockStyle</code></td>
<td>

<p>Logical list (or named logical vector) with elements <code>MAX</code> and
<code>OTS</code>. The value indicates if each (MAX or OTS) block must be
plotted with a specific style (plotting character and color), or if
instead a common style is used for all blocks of the same type
(MAX or OTS). In the first case, each block will create a line in
the legend with a label taken from the <code>history.MAX</code> element of
the object given in <code>x</code>. These legend lines will not appear if
<code>legend</code> is <code>FALSE</code> but can be shown later using
<code><a href="#topic+RLlegend.show">RLlegend.show</a></code>.  In the second case, only one legend line
will be generated. When the number of blocks is large for one type
and the corresponding value of <code>byBlockStyle</code> is <code>TRUE</code>,
the styles will be recycled and the plot/legend might not be clear.
When <code>byBlockStyle</code> is <code>NULL</code> or does not contain
all needed information, default choices are made.
</p>
</td></tr>
<tr><td><code id="plot.Renouv_+3A_...">...</code></td>
<td>

<p>Other arguments passed to the default <code><a href="graphics.html#topic+plot">plot</a></code> function
e.g., <code>ylim</code> to adjust the y-axis.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Historical data blocks (MAX or OTS) embedded in the <code>x</code> object (if any)
can be plotted or not depending on the value of the corresponding
element in <code>show</code>.
</p>

<ul>
<li>
<p>If the <code>MAX</code> element is <code>TRUE</code> and if <code>x</code>
embeds historical data of type <code>MAX</code>, then these will be
shown with a symbol differing from the one for ordinary points.
</p>

</li>
<li>
<p>If <code>OTS</code> element is <code>TRUE</code> and is <code>x</code> embeds
historical data of type <code>OTS</code>, then these will be shown with
a symbol differing from the one for ordinary points. An exception
is when one or several OTS block have no data. Then each such
block is shown as an horizontal segment; its right end-point shows
the effective duration of the block and the ordinate shows the OTS
threshold for this block. No data exceeded the threshold within
the block.
</p>

</li></ul>

<p>This function acts on a list variable named <code>.RLlegend</code> and
stored in a special environment bound to the package. This variable is
used to build legends for plots produced with multiple commands. See
the <code><a href="#topic+RLlegend">RLlegend</a></code> help page.
Examples of possible combined uses of the argument of the <code>plot</code>
and <code>lines</code> together with the <code>RLlegend*</code> functions
are given in the &quot;Renext Graphics&quot; chapter of the <em>Renext
Guide</em> document shipped with this package.
</p>


<h3>Value</h3>

<p>No value returned.
</p>


<h3>Caution</h3>

<p>Remind that the methods <code>plot</code> and <code>lines</code> may change the
value of the variable <code>.RLlegend</code> in the environment
<code>legendEnvir</code>. This variable describes the material to be used in
the legend at the next call of <code>RLlegend.show</code>.
</p>


<h3>Note</h3>

<p>The return level plot is of exponential type i.e. uses a log-scale for
return periods. This contrasts with the Gumbel plot which is also used
in similar contexts.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+RLlegend">RLlegend</a></code> page for the legend construction and
<code><a href="#topic+RLpar">RLpar</a></code> to specify the graphical parameters (colors, line
types, ...) of the elements.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## two fits for the Garonne data
fit.exp &lt;- Renouv(x = Garonne, plot = FALSE)
fit.gpd &lt;- Renouv(x = Garonne, distname.y = "gpd", plot = FALSE)

## simple plot (legend is TRUE here)
plot(fit.exp,
     main = "Two fits overlapped",
     label = "",
     ## Tlim = c(1, 5000),
     predict = TRUE)

## Now try 'lines' and RLlegend.xxx functions
plot(fit.exp,
     main = "Fancy legend",
     show = list(OT = FALSE, quant = FALSE, conf = FALSE,
                 OTS = FALSE, MAX = FALSE),
     legend = FALSE,
     Tlim = c(1, 5000))
RLlegend.ini(x = "bottomright", bg = "lightyellow") ## initialise legend
lines(fit.exp,
      show = list(quant = FALSE, conf = FALSE, OT = TRUE, MAX = TRUE),
      label = "expon",
      par = RLpar(quant.col = "orange", 
        OT.pch = 21, OT.cex = 1.2, OT.col = "SeaGreen", OT.bg = "yellow",
        MAX.block1.col = "purple", MAX.block1.bg = "mistyrose",
        MAX.block1.lwd = 1.4))
lines(fit.gpd,
      pct.conf = c(95, 70),
      show = list(quant = TRUE, conf = TRUE),
      label = "GPD",
      par = RLpar(quant.col = "darkcyan", conf.conf1.col = "red"))
RLlegend.show() ## now draw legend
</code></pre>

<hr>
<h2 id='PPplot'>
Diagnostic plots for Renouv objects 
</h2><span id='topic+PPplot'></span><span id='topic+QQplot'></span><span id='topic+PPplot.Renouv'></span><span id='topic+QQplot.Renouv'></span>

<h3>Description</h3>

<p>Diagnostic plots for <code>Renouv</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PPplot(x, ...)

QQplot(x, ...)

## S3 method for class 'Renouv'
PPplot(x,
       showHist = FALSE,
       legend = FALSE,
       par = NULL,
       posOptions = NULL,
       ...)

## S3 method for class 'Renouv'
QQplot(x,
       showHist = FALSE,
       legend = FALSE,
       par = NULL,
       posOptions = NULL,
       ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PPplot_+3A_x">x</code></td>
<td>

<p>Object containing a fitted model.
</p>
</td></tr>
<tr><td><code id="PPplot_+3A_legend">legend</code></td>
<td>

<p>Should a legend be shown to identify historical blocks? NOT
IMPLEMENTED YET.
</p>
</td></tr>
<tr><td><code id="PPplot_+3A_par">par</code></td>
<td>

<p>A list of graphical parameters as returned by <code><a href="#topic+RLpar">RLpar</a></code>
and used to control the appearance of points. NOT IMPLEMENTED YET.
</p>
</td></tr>
<tr><td><code id="PPplot_+3A_posoptions">posOptions</code></td>
<td>

<p>A pair list to be passed as list of formals to the <code><a href="#topic+SandT">SandT</a></code>
function computing the plotting positions.
</p>
</td></tr>
<tr><td><code id="PPplot_+3A_showhist">showHist</code></td>
<td>

<p>If <code>TRUE</code>, historical information contained in the object
<code>x</code> (if any) will be shown using special plotting positions
as computed by <code><a href="#topic+SandT">SandT</a></code>. 
</p>
</td></tr>
<tr><td><code id="PPplot_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value returned.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SandT">SandT</a></code> for the computation of the plotting
positions used with historical data.</p>

<hr>
<h2 id='predict.Renouv'>
Compute return levels and confidence limits for a &quot;Renouv&quot; object
</h2><span id='topic+predict.Renouv'></span>

<h3>Description</h3>

<p>Compute return levels and confidence limits for an object of class
&quot;Renouv&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   ## S3 method for class 'Renouv'
predict(object,
        newdata = c(10, 20, 50, 100, 200, 500, 1000),
        cov.rate = TRUE,
        level = c(0.95, 0.7),
        prob = FALSE,
        trace = 1, eps = 1e-06,
        ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Renouv_+3A_object">object</code></td>
<td>

<p>An object of class <code>"Renouv"</code> typically created by using the
<code>Renouv</code> function.
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_newdata">newdata</code></td>
<td>

<p>The return period at which return levels and confidence bounds are
wanted.
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_cov.rate">cov.rate</code></td>
<td>

<p>If <code>FALSE</code>, the delta method will not take into account the
uncertainty on the event rate <code>lambda</code> of the Poisson
process. Note however that when <code>distname.y</code> is
<code>"exponential"</code> and when no <code>MAX</code> or <code>OTS</code> data is
used, the value of <code>cov.rate</code> has no impact for now, because
the delta method is not used then.
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_level">level</code></td>
<td>

<p>Confidence levels as in other 'predict' methods (not percentages).
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_prob">prob</code></td>
<td>

<p>If <code>TRUE</code> a <code>prob</code> column is found in the returned data
frame. This column can be used to find which quantile was used
to compute the return level.
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_trace">trace</code></td>
<td>

<p>Some details are printed when <code>trace</code> is not zero.
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_eps">eps</code></td>
<td>

<p>Level of perturbation used to compute the numerical derivatives in
the delta method.
</p>
</td></tr>
<tr><td><code id="predict.Renouv_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unless in some very special cases, the confidence limits are
approximated ones computed by using the delta method with numerical
derivatives.
</p>


<h3>Value</h3>

<p>A data frame with the expected return levels (col. named
<code>"quant"</code>) at the given return periods, and confidence
limits. The returned object has an <code>infer.method</code> attribute
describing the method used to compute the confidence limits.
</p>


<h3>Note</h3>

<p>Despite of its name, this method does not compute true predictions. A
return period is to be interpreted as an average interevent time
rather than the duration of a specific period of time. For instance,
the expected return level for a given return period with length 100
years is the level that would be on average exceeded once every 100
years (assuming that the model description in <code>object</code> is
correct).
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>Coles S. (2001)  <em>Introduction to Statistical Modelling
of Extremes Values</em>, Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Renouv">Renouv</a></code> to fit <code>Renouv</code> model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use Brest data
fit &lt;- Renouv(Brest)
pred &lt;- predict(fit, newdata = c(100, 125, 150, 175, 200),
                level = c(0.99, 0.95))
</code></pre>

<hr>
<h2 id='qStat'>Quantiles of a test statistic</h2><span id='topic+qStat'></span>

<h3>Description</h3>

<p>Quantile of a test statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   qStat(p, n,
         type = c("Greenwood", "Jackson", "logLRGPD", "logLRLomax",
                  "logLRGEV", "logLRFrechet"),
          outNorm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qStat_+3A_p">p</code></td>
<td>

<p>Numeric vector of probabilities. Very small values (<code>p &lt; 0.01</code>)
or very large ones (<code>p &gt; 0.99</code>) will be truncated as
<code>0.00</code> or <code>1.00</code> to maintain a realistic level of
precision.
</p>
</td></tr>
<tr><td><code id="qStat_+3A_n">n</code></td>
<td>

<p>Sample size.
</p>
</td></tr>
<tr><td><code id="qStat_+3A_type">type</code></td>
<td>

<p>The type of statistic, see <b>Details</b>.
</p>
</td></tr>
<tr><td><code id="qStat_+3A_outnorm">outNorm</code></td>
<td>

<p>Logical. If <code>TRUE</code> the output is normalized in a such fashion
that its distribution is the asymptotic one (i.e. standard normal in
practice). When <code>FALSE</code>, the quantiles are given in the true
scale of the statistic: <code class="reqn">\textrm{CV}^2</code>, Jackson. For LR
statistics this argument has no impact.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function provides an approximation of the distribution for several
statistics.
</p>

<ul>
<li><p> For <code>"Greenwood"</code>, the statistic is <em>Greenwood's
statistic</em>. The distribution is that of the squared coefficient of
variation <code class="reqn">\textrm{CV}^2</code> of a sample of size <code>n</code>
from the exponential distribution as computed by <code><a href="#topic+CV2">CV2</a></code>.
</p>
</li>
<li><p> For <code>"Jackson"</code>, the statistic is Jackson's
statistic, see <code><a href="#topic+Jackson">Jackson</a></code>.
</p>
</li>
<li><p> For <code>"logLRGPD"</code> and <code>"logLRLomax"</code>, the
statistic is the log of the likelihood ratio of a sample
from the exponential distribution. The log-likelihoods are
for an exponential distribution compared to a GPD with
non-zero shape, or to a GPD with <em>positive shape</em>
(equivalently, a Lomax distribution).
</p>
</li>
<li><p> For <code>"logLRGEV"</code> and <code>"logLRFrechet"</code>, the
statistic is the log of the likelihood ratio of a sample
from the Gumbel distribution. The log-likelihoods are for a
Gumbel distribution compared to a GEV with non-zero shape,
or to a GEV with <em>positive shape</em> (equivalently, a
Fréchet distribution).
</p>
</li></ul>

<p>The log of Likelihood Ratios are multiplied by <code>2</code>, so that they
compare to a chi-square statistic with one degree of freedom.
</p>


<h3>Value</h3>

<p>A vector of quantiles.
</p>


<h3>Note</h3>

<p>The precision of the result given is limited, and is about
two-digits. This function is not intended to be used as such and is
only provided for information.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- qStat(n = 40, type = "Greenwood")
plot(res$q, res$p, type = "o")
</code></pre>

<hr>
<h2 id='readXML'>Read data using an XML index file</h2><span id='topic+readXML'></span>

<h3>Description</h3>

<p>Read one or several dataset(s) using an XML index file specifying the
data sets to read and the structure of each
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   readXML(name,
           dir,
           index = "index.xml",
           TZ = "GMT",
           trace = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readXML_+3A_name">name</code></td>
<td>

<p>Name for the dataset that will be matched against the <code>name</code>
attribute of datasets as they are given in the index file.
</p>
</td></tr>
<tr><td><code id="readXML_+3A_dir">dir</code></td>
<td>

<p>Path to the directory where the index file and all data files should
be found.
</p>
</td></tr>
<tr><td><code id="readXML_+3A_index">index</code></td>
<td>

<p>Name (short) of the index file. This file must be in the directory
given by <code>dir</code>.
</p>
</td></tr>
<tr><td><code id="readXML_+3A_tz">TZ</code></td>
<td>

<p>A time zone as in <code><a href="base.html#topic+strptime">strptime</a></code>. The time zone <code>"GMT"</code>
should be preferred, since it should work on all platforms and can
cope with dates in the remote past.
</p>
</td></tr>
<tr><td><code id="readXML_+3A_trace">trace</code></td>
<td>

<p>Level of verbosity (integer). Can be used to trace the successive
steps by short indications.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The XML index file is parsed within R. Then according to the
indications within the index file, other files are read (e.g. csv
files). In this way, data returned as a list can contain
heterogeneous data: Over Threshold (OT) data, missing periods, MAX
data, etc.  Various pieces of information are also stored in list
elements with name containing the <code>"info"</code> string.
</p>
<p>This function requires the CRAN package XML.
</p>


<h3>Value</h3>

<p>A list with the data read.
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>General information about the data: <code>varName</code>,
<code>varShorlLab</code> and <code>varUnit</code> give the variable name unit
and short label.
</p>
</td></tr>
<tr><td><code>OTinfo</code></td>
<td>

<p>Information for the Over the Threshold (OT).
</p>
</td></tr>
<tr><td><code>OTdata</code></td>
<td>

<p>Over the Threshold (OT) data.
</p>
</td></tr>
<tr><td><code>OTmissing</code></td>
<td>

<p>Missing periods within the OTdata period.
</p>
</td></tr>
<tr><td><code>MAXinfo</code></td>
<td>

<p>Information for the MAX (<code class="reqn">r</code>-largest) supplement data.
</p>
</td></tr>
<tr><td><code>MAXdata</code></td>
<td>

<p>MAX supplement data.
</p>
</td></tr>
<tr><td><code>OTSinfo</code></td>
<td>

<p>Information for the Over the Threshold Supplement (OTS) data.
</p>
</td></tr>
<tr><td><code>OTSdata</code></td>
<td>

<p>Over the Threshold (OT) supplement data.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The flat files (usually <code>.csv</code> files) can also be read in a more
conventional way e.g. through <code>read.table</code>. However, conform to
the <code>index.xml</code> examples or to the <code>index.xsd</code> schema to see
how to adjust the reading of parameters such as <code>sep</code>, etc.
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Brest">Brest</a></code> for an example of such a list.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Examples of datasets that can be read
## Browse should work for browsers with xslt support
browseURL(file.path(system.file("Rendata", package = "Renext"), "index.xml"))
if (require(XML)) {
   ## use 'index.xml' file shiped with Renext
   dir1 &lt;- system.file("Rendata", package = "Renext")
   BrestNew1 &lt;- readXML(name = "Brest", dir = dir1)
   test1 &lt;- readXML(name = "test1", dir = dir1)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='Ren2gev'>
Translate a vector of coefficients from a Renewal-POT model with
Pareto excesses into a vector of GEV parameters
</h2><span id='topic+Ren2gev'></span>

<h3>Description</h3>

<p>Translate a vector of coefficients from a Renewal-POT model with
Pareto excesses into a vector of GEV parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ren2gev(object,
        threshold = NULL,
        w = 1,
        distname.y = c("gpd", "GPD", "lomax", "maxlo"),
        jacobian = (length(w) == 1L),
        vcovRen = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ren2gev_+3A_object">object</code></td>
<td>

<p>A named vector of parameters or an object of class <code>"Renouv"</code>.
In the first case, the names of the vector element must conform to
the distribution given in <code>distname.y</code>.
</p>
</td></tr>
<tr><td><code id="Ren2gev_+3A_threshold">threshold</code></td>
<td>

<p>The threshold associated with the renewal-POT model.  This must be
provided and be a non NA finite numeric value. It is the location
parameter of the GPD.
</p>
</td></tr>
<tr><td><code id="Ren2gev_+3A_w">w</code></td>
<td>

<p>The duration of the blocks.
</p>
</td></tr>
<tr><td><code id="Ren2gev_+3A_distname.y">distname.y</code></td>
<td>

<p>The distribution of the excesses in the renewal-POT model.  This
is normally a <code>"gpd"</code> but can be a <code>"lomax"</code> or a
<code>"maxlo"</code> distribution provided that the GEV parameters given
in <code>object</code> specify a positive or a negative shape
respectively.
</p>
</td></tr>
<tr><td><code id="Ren2gev_+3A_jacobian">jacobian</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the jacobian matrix of the transformation
is computed. This is only possible at the time when <code>w</code> has
length 1.
</p>
</td></tr>
<tr><td><code id="Ren2gev_+3A_vcovren">vcovRen</code></td>
<td>

<p>A covariance matrix for the &quot;Ren&quot; vector of parameters.  If
<code>object</code> has class <code>"Renouv"</code>, then the covariance matrix
embedded in the object is used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given Renewal-POT parameters, it is possible to compute the
distribution of block maxima. When the distribution is in the Pareto
family, the marginal distribution of maxima is GEV. The location and
the scale GEV parameters depend on the block duration <code class="reqn">w</code>, while
the GEV shape parameter is identical to that of the GPD input
distribution.
</p>


<h3>Value</h3>

<p>When <code>w</code> has length <code>1</code>, a named vector of GEV parameters as
the one estimated by <code><a href="evd.html#topic+fgev">fgev</a></code>. This vector has an
elements named <code>"loc"</code>, <code>"scale"</code> and <code>"shape"</code>.
</p>
<p>When <code>w</code> has length <code>&gt; 1</code>, a matrix with <code>length(w)</code>
rows, each representing a vector of GEV parameters as before.
</p>
<p>The returned object has attributes named <code>"threshold"</code>.  and
<code>"distname.y"</code> to recall how it was built.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+gev2Ren">gev2Ren</a></code> function provides a reciprocal
transformation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- Renouv(Garonne, distname.y = "maxlo")
Ren2gev(fit1)
fit2 &lt;- Renouv(Garonne, distname.y = "gpd")
Ren2gev(fit2)
</code></pre>

<hr>
<h2 id='Ren2gumbel'>
Translate a vector of coefficients from a Renewal-POT model with
exponential excesses to a vector of Gumbel parameters
</h2><span id='topic+Ren2gumbel'></span>

<h3>Description</h3>

<p>Translate a vector of coefficients from a Renewal-POT model with
exponential excesses to a vector of Gumbel parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ren2gumbel(object,
           threshold = NULL,
           w = 1,
           distname.y = c("exponential", "exp"),
           jacobian = (length(w) == 1L),
           vcovRen = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ren2gumbel_+3A_object">object</code></td>
<td>

<p>A named vector of parameters or an object of class <code>"Renouv"</code>.
In the first case, the names of the vector element must conform to
the exponential distribution so the vector must be of length 2 with
names <code>"lambda"</code> and <code>"rate"</code>.
</p>
</td></tr>
<tr><td><code id="Ren2gumbel_+3A_threshold">threshold</code></td>
<td>

<p>A threshold associated with the parameters. If <code>object</code> is an
object with class <code>"Renouv"</code>, its threshold slot will be used.
</p>
</td></tr>
<tr><td><code id="Ren2gumbel_+3A_w">w</code></td>
<td>

<p>A block duration or a vector of block durations.
</p>
</td></tr>
<tr><td><code id="Ren2gumbel_+3A_distname.y">distname.y</code></td>
<td>

<p>The name of the distribution for the excesses.  Can be either
<code>"exponential"</code> or <code>"exp"</code>. The choice has no impact on
the computations, but this name will be attached to the result as an
attribute and may affect later use.
</p>
</td></tr>
<tr><td><code id="Ren2gumbel_+3A_jacobian">jacobian</code></td>
<td>

<p>Logical. If <code>TRUE</code> the jacobian matrix of the transformation
will be computed and attached to the result as an attribute.
</p>
</td></tr>
<tr><td><code id="Ren2gumbel_+3A_vcovren">vcovRen</code></td>
<td>

<p>A covariance matrix for the Renouv parameters. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of GEV parameters if <code>w</code> has length 1, and a matrix if
<code>w</code> has length <code>&gt; 1</code>. The returned objects has attributes.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Ren2gev">Ren2gev</a></code> for the translation of Renouv parameters
corresponding to GPD excesses.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit a Renouv model with exponential excesses (default)
fit &lt;- Renouv(Garonne)
## Convert to gumbel (usable for one-year block maxima)
parGumbel &lt;- Ren2gumbel(fit)
## Retrieve the 'Renouv' model by giving the right threshold
parRen &lt;- gumbel2Ren(parGumbel,
                     threshold = 2500,
                     vcovGumbel = attr(parGumbel, "vcov"),
                     plot = TRUE)
## Build a compatible model under the assumption of one event by
## year
parRen2 &lt;- gumbel2Ren(parGumbel,
                      lambda = 1.00,
                      vcovGumbel = attr(parGumbel, "vcov"),
                      plot = TRUE)
parRenNames &lt;- c("lambda", "rate")
## Build a 'Renouv' object without estimation
myVcov &lt;- attr(parRen, "vcov")[parRenNames, parRenNames]
fitNew &lt;- RenouvNoEst(threshold = attr(parRen, "threshold"),
                      estimate = parRen,
                      distname.y = "exp",
                      cov = myVcov)
## Compare return levels
cbind(roundPred(fit$pred)[ , -2], roundPred(fitNew$pred)[ , -2])
## idem for the putative 'Renouv' with rate 1
myVcov2 &lt;- attr(parRen2, "vcov")[parRenNames, parRenNames]
fitNew2 &lt;- RenouvNoEst(threshold = attr(parRen2, "threshold"),
                       estimate = parRen2,
                       distname.y = "exp",
                       cov = myVcov2)
cbind(roundPred(fit$pred)[ , -2], roundPred(fitNew2$pred)[ , -2])
</code></pre>

<hr>
<h2 id='Renouv'>
Fit a 'Renouvellement' model
</h2><span id='topic+Renouv'></span>

<h3>Description</h3>

<p>Fit a 'renouvellement' POT model using Over the Threshold data and
possibly historical data of two kinds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Renouv(x,
       threshold = NULL,
       effDuration = NULL,
       distname.y = "exponential",
       MAX.data = NULL,
       MAX.effDuration = NULL,
       OTS.data = NULL,
       OTS.effDuration = NULL,
       OTS.threshold = NULL,
       fixed.par.y = NULL,
       start.par.y = NULL,
       force.start.H = FALSE,
       numDeriv = TRUE,
       trans.y = NULL,
       jitter.KS = TRUE,
       pct.conf = c(95, 70),
       rl.prob = NULL,
       prob.max = 1.0-1e-04 ,
       pred.period = NULL,
       suspend.warnings = TRUE,
       control = list(maxit = 300, fnscale = -1),
       control.H = list(maxit = 300, fnscale = -1),
       trace = 0,
       plot = TRUE,
       label = "",
       ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Renouv_+3A_x">x</code></td>
<td>

<p>Can be a numeric vector, an object of the class <code>"Rendata"</code> or
<code>NULL</code>.  In the first case, <code>x</code> contains all the levels
above the threshold for a variable of interest.  In the second case,
most formal arguments take values in accordance with the object
content, and can be by-passed by giving the formal explicitly.  When
<code>x</code> is <code>NULL</code>, the model is fitted using the data provided
using the <code>OTS</code> and <code>MAX</code> formals.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_threshold">threshold</code></td>
<td>

<p>Value of the threshold for the OT data.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_effduration">effDuration</code></td>
<td>

<p>Effective duration, i.e. duration of the OT period.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_distname.y">distname.y</code></td>
<td>

<p>Name of the distribution for the excesses over the threshold. See
<b>Details</b> below.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_max.data">MAX.data</code></td>
<td>

<p>Either a numeric vector or a list of numeric vectors representing
historical data <code class="reqn">r</code>-max by blocks. When <em>a vector</em> is
given, there is only one block, and the data are the corresponding
<code class="reqn">r</code>-max observed levels where <code class="reqn">r</code> is the vector
length; the block duration is given in <code>MAX.effDuration</code>. When
<em>a list</em> is given, each list element contains the data for one
block, and the effective duration are in <code>MAX.effDuration</code>
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_max.effduration">MAX.effDuration</code></td>
<td>

<p>Vector of (effective) durations, one by block MAX data.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_ots.data">OTS.data</code></td>
<td>

<p>A numeric vector or a list of numeric vectors representing
supplementary Over Threshold data in blocks. When a <em>vector</em> is
given, there is only one block, and the data contain all the
'historical' levels over the corresponding threshold given in
<code>OTS.threshold</code>. The block duration is given in
<code>OTS.effDuration</code>. When a <em>list</em> is given, each list
element contains the data for one block, and the threshold and
effective duration are in <code>OTS.threshold</code> and
<code>OTS.effDuration</code>.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_ots.effduration">OTS.effDuration</code></td>
<td>

<p>A numeric vector giving the (effective) durations for the OTS
blocks.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_ots.threshold">OTS.threshold</code></td>
<td>

<p>A vector giving the thresholds for the different OTS blocks. The
given values must be greater than or equal to the value of
<code>threshold</code>.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_fixed.par.y">fixed.par.y</code></td>
<td>

<p>Named list of known (or fixed) parameter values for the
<code>y</code>-distribution.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_start.par.y">start.par.y</code></td>
<td>

<p>Named list of parameter initial values for the
<code>y</code>-distribution. Only used when the distribution does not
belong to the list of special distributions.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_force.start.h">force.start.H</code></td>
<td>

<p>Logical. When <code>TRUE</code>, the values in <code>start.par.y</code> (which
must then be correct) will be used also as starting values in the
maximisation of the global likelihood : OT data and historical
data. This is useful e.g. when the historical data fall outside of
the support for the distribution fitted without historical data. See
below the <b>Details</b> section.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_numderiv">numDeriv</code></td>
<td>

<p>Logical: should the hessian be computed using the <code>numDeriv</code>
package (value <code>TRUE</code>) or should it be taken from the results
of <code>optim</code>?
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_trans.y">trans.y</code></td>
<td>

<p>Transformation of the levels <em>before thresholding</em> (if not
<code>NULL</code>).  This is only possible with the <code>"exponential"</code>
value <code>distname.y</code>. The two allowed choices are <code>"square"</code>
and <code>"log"</code> meaning that the fitted (exponentially distributed)
values are <code>x.OT^2</code> <code>-threshold^2</code> and <code>log(x.OT)</code>
<code>-log(threshold)</code> respectively.  The corresponding
distributions for <code>x.OT</code> may be called &quot;square-exponential&quot; and
&quot;log-exponential&quot;.
</p>
</td></tr>  
<tr><td><code id="Renouv_+3A_jitter.ks">jitter.KS</code></td>
<td>

<p>Logical. When set to <code>TRUE</code>, a small amount of noise is added
to the &quot;OT&quot; data used in the Kolmogorov-Smirnov test in order to
remove ties. This is done using the <code><a href="#topic+OTjitter">OTjitter</a></code> function.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_pct.conf">pct.conf</code></td>
<td>

<p>Character or numeric vector specifying the percentages for the
confidence (bilateral) limits on quantiles.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_rl.prob">rl.prob</code></td>
<td>

<p>Vector of probabilities for the computation of return levels.  These
are used in plots (hence must be dense enough) and appear on output
in the data.frame <code>ret.lev</code>.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_prob.max">prob.max</code></td>
<td>

<p>Max value of probability for return level and confidence limits
evaluations. This argument 'shortens' the default <code>prob</code>
vector: values <code>&gt; prob.max</code> in the default <code>prob</code> vector
are omitted. Ignored when a <code>prob</code> argument is given.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_pred.period">pred.period</code></td>
<td>

<p>A vector of &quot;pretty&quot; periods at which return level and probability
will be evaluated and returned in the <code>pred</code> data.frame.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_suspend.warnings">suspend.warnings</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the warnings will be suspended during
optimisation steps. This is useful when the parameters are subject
to constraints as is usually the case.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_control">control</code></td>
<td>

<p>A named list used in <code><a href="stats.html#topic+optim">optim</a></code> for the no-history stage
(if any). Note that <code>fnscale = -1</code> says that maximisation is
required (not minimisation) and must not be changed!
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_control.h">control.H</code></td>
<td>

<p>A named list used in <code><a href="stats.html#topic+optim">optim</a></code> for the historical stage
(if any).
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_trace">trace</code></td>
<td>

<p>Level of verbosity. Value <code>0</code> prints nothing.
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_plot">plot</code></td>
<td>

<p>Draw a return level plot?
</p>
</td></tr>
<tr><td><code id="Renouv_+3A_label">label</code></td>
<td>

<p>Label to be used in the legend when <code>plot</code> is <code>TRUE</code>.
</p>
</td></tr>


<tr><td><code id="Renouv_+3A_...">...</code></td>
<td>

<p>Arguments passed to <code><a href="#topic+plot.Renouv">plot.Renouv</a></code>, e.g. <code>main</code>,
<code>ylim</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is fitted using Maximum Likelihood (ML).
</p>
<p>Some distributions listed below and here called &quot;special&quot; are
considered in a special manner.  For these distributions, it is not
necessary to give starting values nor parameter names which are
unambiguous.
</p>

<table>
<tr>
 <td style="text-align: left;">
    distribution </td><td style="text-align: left;"> parameters </td>
</tr>
<tr>
 <td style="text-align: left;"> 
    <code>exponential</code> </td><td style="text-align: left;"> <code>rate</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>weibull</code> </td><td style="text-align: left;"> <code>shape</code>, <code>scale</code></td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>GPD</code> </td><td style="text-align: left;"> <code>scale</code>, <code>shape</code></td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>gpd</code> </td><td style="text-align: left;"> <code>scale</code>, <code>shape</code></td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>lomax</code> </td><td style="text-align: left;"> <code>scale</code>, <code>shape</code></td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>maxlo</code> </td><td style="text-align: left;"> <code>scale</code>, <code>shape</code></td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>log-normal</code> </td><td style="text-align: left;"> <code>meanlog</code>,
    <code>sdlog</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>gamma</code> </td><td style="text-align: left;"> <code>shape</code>, <code>scale</code></td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>mixexp2</code> </td><td style="text-align: left;"> <code>prob1</code>, <code>rate1</code>, <code>delta</code>
  </td>
</tr>

</table>

<p>Other distributions can be used. Because the probability functions are
then used in a &quot;black-box&quot; fashion, these distributions should respect
the following <em>formal requirements</em>:
</p>

<ol>
<li><p> The name for the <em>density</em>, <em>distribution</em> and
<em>quantile</em> functions must obey to the <em>classical
&quot;prefixing convention&quot;</em>. Prefixes must be respectively: <code>"d"</code>,
<code>"p"</code>, <code>"q"</code>.  This rules applies for distribution of the
<code>stats</code> package and those of many other packages such
<code>evd</code>.
</p>
</li>
<li> <p><em>The first (main) argument must be vectorisable</em> in all
three functions, i.e. a vector of <code>x</code>, <code>q</code> or <code>p</code>
must be accepted by the density, the distribution and the quantile
functions.
</p>
</li>
<li> <p><em>The density must have a</em> <code>log</code> <em>formal</em>
argument. When <code>log</code> is <code>TRUE</code>, the log-density is
returned instead of the density.
</p>
</li></ol>

<p>For such a distribution, it is necessary to give arguments names in
<code>start.par.y</code>. The arguments list must have exactly the required
number of parameters for the family (e.g. <code>2</code> for <code>gamma</code>).
Some parameters can be fixed (known); then the parameter set will be
the reunion of those appearing in <code>start.par.y</code> and those in
<code>fixed.par.y</code>. Anyway, in the present version, <em>at least one
parameter must be unknown</em> for the <code>y</code> part of the model.
</p>
<p><em>Mathematical requirements</em> exist for a correct use of ML. They
are referred to as &quot;regularity conditions&quot; in ML theory. Note that the
support of the distribution must be the set of non-negative real
numbers.
</p>
<p>The estimation procedure differs according to the existence of
the different types of data: main sample, MAX and OTS.
</p>

<ol>
<li><p> When no historical data is given, the whole set of parameters
contains orthogonal subsets: a &quot;point process&quot; part
concerning the process of events, and an &quot;observation&quot; part
concerning the excesses over the threshold. The parameters can in this
case be estimated separately. The rate of the Poisson process is estimated
by the empirical rate, i.e. the number of events divided by the total
duration given in <code>effDuration</code>. The  &quot;Over the Threshold&quot;
parameters are estimated from the excesses computed as <code>x.OT</code> 
minus the threshold.
</p>
</li>
<li><p> When historical data is given, the two parameter vectors must be
coped with together in maximising the global likelihood. In this case,
we begin the estimation ignoring the historical data and then use the
estimates as starting values for the maximisation of the global
likelihood. In some circumstances, the estimates obtained in the first
stage can not be used with historical data because some of these fall
outside the support of the distribution fitted. This can happen
e.g. with a <code>distname.y = "gpd"</code> when historical data exceed
<code>threshold</code> - <code>scale</code>/<code>shape</code> for the values of
<code>shape</code> and <code>scale</code> computed in the first stage.
</p>
</li>
<li><p> From version 2.1-1 on, it is possible to use <code>OTS</code> and/or
<code>MAX</code> data with no <code>OT</code> data by specifying <code>x =
      NULL</code>. Yet at the time this is only possible <code>distname.y</code> takes
one of the two values: <code>"exp"</code>, or <code>"gpd"</code>.  The initial
values for the parameter are then obtained by using the
<code><a href="#topic+parIni.OTS">parIni.OTS</a></code>, <code><a href="#topic+parIni.MAX">parIni.MAX</a></code> functions and
possibly by combining the two resulting initial parameter
vectors. This possibility can be used to fit a model from <em>block
maxima</em> or <code class="reqn">r</code>-<em>largest</em> classical data but with more
flexibility since the duration of the blocks may here not be constant.
</p>
</li></ol>

<p>The returned <code>Renouv</code> object contains a <code>MAX</code> element
concerning the distribution of block maxima in the two following
cases.
</p>
 
<ol>
<li><p> When <code>distname.y</code> is <code>"exponential"</code> or <code>"exp"</code>,
the distribution of the maximum is Gumbel. The estimated parameters
can be used with the <code>gumbel</code> function of the <b>evd</b> package.
</p>
</li>
<li><p> When  <code>distname.y</code> is <code>"gpd"</code>, <code>"lomax"</code>,
<code>"maxlo"</code> or <code>"GPD"</code>  the distribution of the maximum
is a Generalised Extreme Values distribution. The estimated parameters
can be used with the <code>gev</code> function of the <b>evd</b> package.
</p>
</li></ol>



<h3>Value</h3>

<p>An object with class <code>"Renouv"</code>. This is mainly a list with the
various results.
</p>
<table>
<tr><td><code>est.N</code></td>
<td>

<p>Estimate(s) for the count <code>"N"</code> part. This estimate
does not use the historical data, even if is available.
</p>
</td></tr>
<tr><td><code>est.y</code></td>
<td>

<p>Estimate(s) for the excess <code>"y"</code> part. This estimate does
not use the historical data, even if available.
</p>
</td></tr>
<tr><td><code>cov.N</code>, <code>cov.y</code></td>
<td>

<p>The (co-)variances for the estimates above.
</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>

<p>Estimate(s) for the whole set of parameters based on OT data
<b>and on historical data</b> if available.
</p>
</td></tr>
<tr><td><code>ks.test</code></td>
<td>

<p>Kolmogorov-Smirnov goodness-of-fit test.
</p>
</td></tr>
<tr><td><code>ret.lev</code></td>
<td>

<p>A data frame containing return levels and confidence limits. The
corresponding probabilities are either provided by user or taken as
default values.
</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>

<p>A data frame similar to <code>ret.lev</code>, but with &quot;pretty&quot; return
periods. These are taken as the provided values <code>pred.period</code>
if any or are chosen as &quot;round&quot; multiples of the time unit (taken
from <code>effDuration</code>). The periods are chosen in order to cover
periods ranging from 1/10 to 10 time units.
</p>
</td></tr>
<tr><td><code>MAX</code></td>
<td>

<p>A list providing the estimated distribution of the maximum of the
marks over a block of unit duration. This list element only exists when
this distribution can be deduced from the fit, which
is the case when <code>distname.y</code> is a GPD in a broad sense,
see <b>Details</b>.
</p>
</td></tr>
</table>
<p>Other results are available. Use <code>names(result)</code> to see their
list.
</p>
<p>Except in the the special case where <code>distname.y</code> is
<code>"exponential"</code> and where no historical data are used, the
inference on quantiles is obtained with the <em>delta method</em> and
using numerical derivatives. Confidence limits are unreliable for
return levels much greater than the observation-historical period.
</p>
<p>Due to the presence of estimated parameters, the Kolmogorov-Smirnov
test is unreliable when less than 30 observations are available.
</p>


<h3>Warning</h3>

<p>With some distributions or in presence of historical data, the
estimation can fail due to some problem during the optimisation. Even
when the optimisation converges, the determination of the (numerical)
hessian can be impossible: This can happen if <em>one or more
parameter is too small</em> to compute a finite difference approximation
of gradient. For instance the 'rate' parameter of the exponential
distribution (= inverse mean) will be small when the mean of
the excesses is large.
</p>
<p>A possible solution is then to <b>rescale the data</b> e.g. dividing
them by 10 or 100. As a rule of thumb, an acceptable scaling leads to
data (excesses) of a few units to a few hundreds, but <b>an
order of magnitude of thousands or more should be avoided and reduced
by scaling</b>. The rescaling is recommended for the square exponential
distribution (obtained with <code>trans =</code> <code>"square"</code>) since the
observations are squared.
</p>
<p>Another possible way to solve the problem is to change the
<code>numDeriv</code> value.
</p>


<h3>Note</h3>

<p>The model only concerns the &quot;Over the Threshold&quot; part of the
distribution of the observations. When historical data is used,
observations should all be larger than the threshold.
</p>
<p>The name of the elements in the returned list is indicative, and is
likely to be changed in future versions. At the time, the effect of
historical data on estimation (when such data exist) can be evaluated
by comparing <code>c(res$est.N, res$est.y)</code> and <code>res$estimate</code>
where <code>res</code> is the results list.
</p>
<p>Some warnings may indicate that missing values are met during the
optimisation process. This is due to the evaluation of the density at tail
values. At the time the ML estimates are computed using an unconstrained
optimisation, so invalid parameter values can be met during the
maximisation or even be returned as (invalid) estimates. 
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>


<ul>
<li><p> Miquel J. (1984) <em>Guide pratique d'estimation des
probabilités de crues</em>, Eyrolles (coll. EDF DER).
</p>
</li>
<li><p> Coles S. (2001) <em>Introduction to Statistical Modelling of Extremes
Values</em>, Springer.
</p>
</li>
<li><p> Embrechts P., Klüppelberg C. and Mikosch T. (1997) <em>Modelling
Extremal Events for Insurance and Finance</em>. Springer.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+RLplot">RLplot</a></code> for the <em>return level plot</em>. See
<code><a href="stats.html#topic+optim">optim</a></code> for the tuning of the optimisation. The
<code><a href="#topic+RenouvNoEst">RenouvNoEst</a></code> can be used to create an object with S3
class <code>"Renouv"</code> from known parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Garonne data. Use a "Rendata" object as 'x'. Historical data are used!
fit &lt;- Renouv(x = Garonne, distname = "weibull", trace = 1,
              main = "'Garonne' data")
summary(fit)

## generates a warning because of the ties
fit2 &lt;- Renouv(x = Garonne, distname = "GPD",
               jitter.KS = FALSE,
               threshold = 2800, trace = 1,
               main = "'Garonne' data with threshold = 2800 and GPD fit")

## use a numeric vector as 'x'
fit3 &lt;-
    Renouv(x = Garonne$OTdata$Flow,
           threshold = 2500,
           effDuration = 100,
           distname = "GPD",
           OTS.data = list(numeric(0), c(6800, 7200)),
           OTS.effDuration = c(100, 150),
           OTS.threshold = c(7000, 6000), 
           trace = 1,
           main = "'Garonne' data with artificial \"OTS\" data")
## Add historical (fictive) data
fit4 &lt;- Renouv(x = Garonne$OTdata$Flow,
               threshold = 2500,
               effDuration = 100,
               distname = "weibull",
               fixed.par.y = list(shape = 1.1),
               OTS.data = list(numeric(0), c(6800, 7200)),
               OTS.effDuration = c(100, 150),
               OTS.threshold = c(7000, 6000),
               trace = 0,
               main = "'Garonne' data with artificial \"OTS\" data")

##============================================================================
## use the 'venice' dataset in a r-largest fit from the 'evd' package
##============================================================================
## transform data: each row is a block
MAX.data &lt;- as.list(as.data.frame(t(venice)))
## remove the NA imposed by the rectangular matrix format
MAX.data &lt;- lapply(MAX.data, function(x) x[!is.na(x)])
MAX.effDuration &lt;- rep(1, length(MAX.data))

## fit a Renouv model with no OT data. The threshold
## must be in the support of the gev distribution
u &lt;- 66
fit.gpd &lt;- Renouv(x = NULL,
                  MAX.data = MAX.data,
                  MAX.effDuration = MAX.effDuration,
                  distname.y = "GPD",
                  threshold = u,
                  numDeriv = FALSE,
                  trace = 0,
                  plot = FALSE)
## Not run: 
  require(ismev)
  ## compare with results from the ismev package 
  fit.gev &lt;- rlarg.fit(venice)
  est.gev &lt;- fit.gev$mle
  names(est.gev) &lt;- c("loc", "scale", "shape")
  
  ## transform the 'gev' fit into a Ren parameter set.
  cov.gev &lt;- fit.gev$cov
  rownames(cov.gev) &lt;- colnames(cov.gev) &lt;-  c("loc", "scale", "shape")
  trans &lt;- gev2Ren(est.gev,
                   threshold = u,
                   vcovGev = cov.gev)
  est &lt;- cbind(ismev = trans, RenextLab = coef(fit.gpd))
  colnames(est) &lt;- c("ismev", "RenextLab")
  print(est)
  
  ## fill a 3d array with the two gpd covariance matrices
  cov2 &lt;- attr(trans, "vcov")[c(1, 3, 4), c(1, 3, 4)]
  
  ## covariance
  covs &lt;-
    array(dim = c(2, 3, 3),
          dimnames = list(c("ismev", "RenextLab"),
            colnames(fit.gpd$cov), colnames(fit.gpd$cov)))
  
  covs["ismev", , ] &lt;- cov2
  covs["RenextLab", , ] &lt;- fit.gpd$cov
  print(covs)

## End(Not run)

</code></pre>

<hr>
<h2 id='RenouvNoEst'>
Define a 'renouvellement' model without estimation
</h2><span id='topic+RenouvNoEst'></span>

<h3>Description</h3>

<p>Build a 'renouvellement' model using parameters
given by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RenouvNoEst(threshold,
            estimate = NULL,
            distname.y = "exponential",
            fixed.par.y = NULL,
            trans.y = NULL,
            pct.conf = c(95, 70),
            rl.prob = NULL,
            prob.max = 1 - 1e-04,
            pred.period = NULL,
            cov = NULL,
            nb.OT = NULL,
            infer.method = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RenouvNoEst_+3A_threshold">threshold</code></td>
<td>

<p>The threshold.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_estimate">estimate</code></td>
<td>

<p>Numeric named vector containing the estimates for the parameters. It
must be compatible with the distribution chosen, and must contain in
first position an element named <code>"lambda"</code> representing an
estimated event rate in <em>events by year</em>.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_distname.y">distname.y</code></td>
<td>

<p>Character giving the name of the distribution.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_fixed.par.y">fixed.par.y</code></td>
<td>

<p>Numeric named vector containing values for vectors which are
considered as fixed (and not estimated).
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_trans.y">trans.y</code></td>
<td>

<p>Transformation as in <code><a href="#topic+Renouv">Renouv</a></code>. Used only when
<code>distname.y</code> is equal to <code>"exponential"</code>.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_pct.conf">pct.conf</code></td>
<td>

<p>Vector of percents for confidence limits.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_rl.prob">rl.prob</code></td>
<td>

<p>Probability used in the return level computations. These values are
used for instance in return level plots produced with the
<code><a href="#topic+plot.Renouv">plot.Renouv</a></code> method. When <code>NULL</code> a default vector
is used.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_prob.max">prob.max</code></td>
<td>

<p>Maximal probability for which computations are done.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_pred.period">pred.period</code></td>
<td>

<p>Vector of periods for which predicted return levels will be computed.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_cov">cov</code></td>
<td>

<p>Covariance matrix for the provided estimated parameters.  Must have
rownames and colnames in accordance with those of
<code>estimate</code>. This covariance matrix is used to build confidence
limits on parameters and on return levels using the <em>delta
method</em>.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_nb.ot">nb.OT</code></td>
<td>

<p>Number of data over the threshold used for estimation.  This will be
used only when <code>distname.y</code> is equal to <code>"exponential"</code>.
</p>
</td></tr>
<tr><td><code id="RenouvNoEst_+3A_infer.method">infer.method</code></td>
<td>

<p>Inference method. Will normally be the <em>delta method</em>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used for plotting or comparing models with known
parameter estimates but with no data available.
</p>
<p>The parameters estimates should be accompanied with a covariance
matrix assuming an approximately normal joint distribution of
these. This matrix is usually obtained by computing the numerical
derivatives of the log-likelihood at the second order at the
estimates. This covariance is used to compute approximate confidence
limits for the return levels of the unknown true distribution that was
estimated.
</p>


<h3>Value</h3>

<p>An object of class <code>"Renouv"</code> representing a 'renouvellement'
model similar to those built with <code><a href="#topic+Renouv">Renouv</a></code>. This is mainly
a list. Note however that some list elements found in <code>Renouv</code>
objects built by <code>Renouv</code> can not be found here.  For instance,
the returned objects embeds no goodness-of-fit results since the
object is created without making use of any data.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Renouv">Renouv</a></code> to estimate such models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##======================================================================
## Example from S. Coles' book, page 86 'rainfall data'.
## Note that the first parameter is here the rate 'lambda', and no the
## probability of exceedance as in Coles' book.
##======================================================================
estimate &lt;- c(lambda = 152 / 48, scale = 7.44, shape = 0.184)          
cov &lt;- matrix(c(4.9e-7 * (17531 / 48)^2,  0.0000,  0.0000,
                0.0000,  0.9180, -0.0655,
                0.0000, -0.0655,  0.0102),
              nrow = 3)
colnames(cov) &lt;- rownames(cov) &lt;- names(estimate)
renNE &lt;- RenouvNoEst(threshold = 30, distname.y = "gpd",
                     pct.conf = c(95, 70),
                     estimate = estimate,
                     nb.OT = 152, cov = cov)
summary(renNE)
plot(renNE, main = "Daily rainfall data SW England", ylim = c(0, 400))


</code></pre>

<hr>
<h2 id='RLlegend'>
Legend management for return level plots
</h2><span id='topic+RLlegend'></span><span id='topic+RLlegend.ini'></span><span id='topic+RLlegend.show'></span>

<h3>Description</h3>

<p>Legend management for return level plots produced with the <code>plot</code>
and <code>lines</code> method of the <code>"Renouv"</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    RLlegend.ini(x = "topleft", bty = "n", ...)
    RLlegend.show()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RLlegend_+3A_x">x</code></td>
<td>

<p>A possible value for the <code>x</code> argument of <code><a href="graphics.html#topic+legend">legend</a></code>.
This will usually be a character giving the position e.g,
<code>"topleft"</code> or <code>"bottomleft"</code>. See the
<code><a href="graphics.html#topic+legend">legend</a></code> function help.
</p>
</td></tr>
<tr><td><code id="RLlegend_+3A_bty">bty</code></td>
<td>

<p>As in <code><a href="graphics.html#topic+legend">legend</a></code>. The default value <code>"n"</code> differs
from the default value of <code>legend</code>.
</p>
</td></tr>
<tr><td><code id="RLlegend_+3A_...">...</code></td>
<td>

<p>Other arguments to be kept in the list and passed later to
<code><a href="graphics.html#topic+legend">legend</a></code>. These arguments should be chosen among those
of <code>legend</code> modifying the global legend appearance (e.g.,
<code>bg</code>) but not among those modifying the legend content
(e.g. <code>col</code> <code>pt.bg</code>, <code>legend</code>, ...) since the content
is here built semi-automatically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is to be used in conjunction with
<code><a href="#topic+plot.Renouv">plot.Renouv</a></code> and <code><a href="#topic+lines.Renouv">lines.Renouv</a></code> methods. It
allows the construction of a legend in a semi-automatic fashion, using
the value of the <code>par</code> argument of the <code>plot</code> and
<code>lines</code> methods to specify the legend construction.
</p>
<p>Each call to the <code><a href="#topic+plot.Renouv">plot.Renouv</a></code> or
<code><a href="#topic+lines.Renouv">lines.Renouv</a></code> changes the content of a list variable
named <code>.RLlegend</code> in a special environment bound to the
package. This list is re-created when <code>RLlegend.ini</code> is called,
and is used later to draw a legend on the active device when
<code>RLlegend.show</code> is called.  Between these two calls, the
<code>plot</code> and <code>lines</code> methods should be used with their arg
<code>legend</code> set to <code>FALSE</code>.
</p>





<h3>Value</h3>

<p><code>RLlegend.ini</code> returns a copy of the variable which is set.
</p>
<p><code>RLlegend.show</code> returns nothing.
</p>


<h3>Note</h3>

<p>The size of symbols (i.e, <em>plotting characters</em>) can be set by
using the <code><a href="#topic+RLpar">RLpar</a></code> function and the <code><a href="graphics.html#topic+par">par</a></code>
argument of the methods <code><a href="#topic+plot.Renouv">plot.Renouv</a></code> and
<code><a href="#topic+lines.Renouv">lines.Renouv</a></code>. However it can not be changed in the
legend.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.Renouv">plot.Renouv</a></code> and <code><a href="#topic+lines.Renouv">lines.Renouv</a></code> for
and the <code><a href="#topic+RLpar">RLpar</a></code> function to change the graphical
parameters of the plot and the legend by using the <code>par</code>
argument.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use Garonne data
xG &lt;- Garonne$OTdata$Flow
## use special "exponential" distribution 
fit1 &lt;- Renouv(x = xG, threshold = 2500, distname.y = "exponential",
               effDuration = 65, plot = FALSE)

## use 'exp' in black box fashion, hence with delta method
fit2 &lt;- Renouv(x = xG, , threshold = 2500, distname.y = "exp",
               effDuration = 65, start.par.y = c(rate = 1), plot = FALSE)
RLlegend.ini() ## initialise legend
## sample points only
plot(fit1, main = "Two types of confidence lims",
     show = list(OT = TRUE, quant = FALSE, conf = FALSE),
     label = "",
     legend = FALSE)
## quant and confidence lims
lines(fit1,
     show = list(OT = FALSE, quant = TRUE, conf = TRUE),
     label = "exact",
     legend = FALSE)
## quant (overplot) and confidence lims
lines(fit2,
      show = list(OT = FALSE, quant = TRUE, conf = TRUE),
      par = RLpar(quant.lty = 2, quant.col = "SpringGreen2",
        conf.conf1.col = "orangered", conf.conf1.lwd = 3,
        conf.conf2.col = "orangered", conf.conf2.lwd = 3),
      label = "delta",
      legend = FALSE)
RLlegend.show() ## now draw legend

</code></pre>

<hr>
<h2 id='RLpar'>
Graphical parameters for Return Level plots
</h2><span id='topic+RLpar'></span>

<h3>Description</h3>

<p>Build a hierarchical list of graphical parameters that can
be used in the methods plot or lines for the class <code>"Renouv"</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RLpar(mono = TRUE,
      trace = 0L,
      ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RLpar_+3A_mono">mono</code></td>
<td>

<p>Logical. The default <code>TRUE</code> is for plots possibly using colors
but that can be printed in grayscale.  With the value <code>FALSE</code>,
curves or symbols will appear distinctly on a color device but not
necessarily when printed in grayscale.
</p>
</td></tr>
<tr><td><code id="RLpar_+3A_trace">trace</code></td>
<td>

<p>Integer level of verbosity. The default value <code>0</code> prints
nothing.
</p>
</td></tr>
<tr><td><code id="RLpar_+3A_...">...</code></td>
<td>

<p>Arguments with names corresponding to the hierarchical structure
and the graphical parameter to be changed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formals are in correspondence with the list hierarchy using a
column <code>"."</code> as separator to define the tree. Thus a
<code>quant.col</code> formal argument can be used to specify the color of
the quantile (or return level) curve, while <code>conf.conf1.col</code> will
be used for the first confidence limits (lower and upper).
</p>


<h3>Value</h3>

<p>A list containing lists in a hierarchical fashion. At the root level,
an element concerns a single curve (e.g. the return level curve), a
single scatterplot (e.g. sample used in POT), a group of curves
(e.g. the confidence limits) or a group of scatterplots (e.g. the
collection of <code>MAX</code> historical blocks). For single elements
(curve or scatterplot) the list contains graphical elements with
values as they would be given in <code>plot</code> or <code>lines</code>
calls. For group elements, each element is a list of such lists.
</p>


<h3>Note</h3>

<p>A list of default parameter values is built first using the model
suitable for the <code>mono</code> value. Then the values provided by the
user overwrite the existing. Thus a curve can be coloured even if
<code>mono = TRUE</code>, if a colour specification is given for the
corresponding element.
</p>
<p>When the same parameter name is used several times in <code>RLpar</code>, a
warning is thrown.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.Renouv">plot.Renouv</a></code> and <code><a href="#topic+lines.Renouv">lines.Renouv</a></code> with which
<code>RLpar</code> is to be used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## change color for quantile curve and type for confidence
## limits #1 (with largest confidence level).
newRLpar &lt;- RLpar(quant.col = "red", conf.conf1.lty = "dashed")
newRLpar$quant

## show the names of all possible editable parameters
names(unlist(RLpar()))



</code></pre>

<hr>
<h2 id='RLplot'>Return level plot</h2><span id='topic+RLplot'></span>

<h3>Description</h3>

<p>Return level plot for &quot;Renouvellement&quot; data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RLplot(data,
       x = NULL,
       duration = 1,
       lambda,
       conf.pct = 95,
       mono = TRUE,
       mark.rl = 100,
       mark.labels = mark.rl,
       mark.col = NULL,
       main = NULL,
       ylim = NULL,
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RLplot_+3A_data">data</code></td>
<td>

<p>A data.frame object with a column named <code>quant</code>.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_x">x</code></td>
<td>

<p>Optional vector of observed levels.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_duration">duration</code></td>
<td>

<p>The (effective) duration corresponding to <code>x</code> if
this argument is used.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_lambda">lambda</code></td>
<td>

<p>Rate, with unit inverse of that used for <code>duration</code>, e.g. in
inverse years when <code>duration</code> is in years.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_conf.pct">conf.pct</code></td>
<td>

<p>Vector (character or integer) giving confidence levels. See
<b>Details</b> below.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_mono">mono</code></td>
<td>

<p>If <code>TRUE</code> colours are replaced by black.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_mark.rl">mark.rl</code></td>
<td>

<p>Return levels to be marked on the plot.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_mark.labels">mark.labels</code></td>
<td>

<p>Labels shown at positions in <code>mark.rl</code>.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_mark.col">mark.col</code></td>
<td>

<p>Colours for marked levels.
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_main">main</code></td>
<td>

<p>Main title for the return level plot (defaults to empty title).
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_ylim">ylim</code></td>
<td>

<p>Limits for the y axis (defaults to values computed from the data).
</p>
</td></tr>
<tr><td><code id="RLplot_+3A_...">...</code></td>
<td>

<p>Further args to be passed to <code>plot</code>. Should be removed in
future versions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Percents should match column names in the data.frame as follows. The
upper and lower limits are expected to be <code>U.95</code> and <code>L.95</code>
respectively. For a <code>70%</code> confidence percentage, columns should
have names <code>"U.70"</code> and <code>"L.70"</code>.
</p>
<p>The plot is comparable to the return level described in Coles'book and
related packages, but the return level is here in log-scale while
Coles uses a loglog-scale. A line corresponds here to a one parameter
exponential distribution, while Coles'plot corresponds to Gumbel,
however the two plots differ only for small return periods.  This plot
is identical to an <code>expplot</code> but with x and y scales changed:
only axis tick-marks differ. The convexity of the scatter plot is
therefore opposed in the two plots.
</p>


<h3>Note</h3>

<p>Confidence limits correspond to <em>two-sided symmetrical
intervals</em>. This means that the (random) confidence interval may be
under or above the true unknown value with the same
probabilities. E.g. the probability that the unknown quantile falls
above <code>U.95</code> is <code>2.5%</code>. The two bounds are yet generally
not symmetrical with respect to <code>quant</code>; such a behaviour follows
from the use of &quot;delta&quot; method for approximate intervals.
</p>
<p>It is possible to add graphical material (points, lines) to this plot
using <code>log(returnlev)</code> and <code>quantile</code> coordinates. See
<b>Examples</b> section.
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>References</h3>

<p>Coles S. (2001)  <em>Introduction to Statistical Modelling
of Extremes Values</em>, Springer.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+expplot">expplot</a></code> for a classical exponential plot.  See Also
as <code><a href="#topic+Renouv">Renouv</a></code> to fit &quot;Renouvellement&quot; models. The
<code>return.level</code> function in the <code>extRemes</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Typical probability vector
prob &lt;- c(0.0001,
  seq(from = 0.01, to = 0.09, by = 0.01),
  seq(from = 0.10, to = 0.80, by = 0.10),
  seq(from = 0.85, to = 0.99, by = 0.01),
  0.995, 0.996, 0.997, 0.998, 0.999, 0.9995)

## Model parameters rate = #evts by year, over nyear
lambda &lt;- 4
nyear &lt;- 30
theta.x &lt;- 4

## draw points
n.x &lt;- rpois(1, lambda = lambda*nyear)
x &lt;- rexp(n.x, rate = 1/theta.x)

## ML estimation (exponential)
lambda.hat &lt;- n.x / nyear
theta.x.hat &lt;- mean(x)
  
## Compute bounds (here exact)
alpha &lt;- 0.05

quant &lt;- qexp(p = prob, rate = 1/theta.x.hat) 

theta.L &lt;- 2*n.x*theta.x.hat / qchisq(1 - alpha/2, df = 2*n.x)
theta.U &lt;- 2*n.x*theta.x.hat / qchisq(alpha/2, df = 2*n.x)

L.95 &lt;- qexp(p = prob, rate = 1/theta.L) 
U.95 &lt;- qexp(p = prob, rate = 1/theta.U) 

## store in data.frame object
data &lt;- data.frame(prob = prob, quant = quant, L.95 = L.95, U.95 = U.95)

RLplot(data = data, x = x, lambda = lambda.hat,
       duration = nyear,
       main = "Poisson-exponential return levels")

RLplot(data = data, x = x, lambda = lambda.hat, duration = nyear,
       mark.rl = 10, mark.labels = "10 ans", mono = FALSE, mark.col = "SeaGreen",
       main = "Poisson-exponential return levels")

points(x = log(50), y = 25, pch = 18, cex = 1.4, col = "purple") 
text(x = log(50), y = 25, col ="purple", pos = 4, labels = "special event") 

</code></pre>

<hr>
<h2 id='roundPred'>
Round quantiles in a pseudo-prediction table
</h2><span id='topic+roundPred'></span>

<h3>Description</h3>

<p>Round the quantiles of a pseudo prediction table such
that computed by <code>predict.Renouv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   roundPred(pred, dig.quant = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roundPred_+3A_pred">pred</code></td>
<td>
<p>The data.frame containing the predicted quantiles and
return levels.
</p>
</td></tr>
<tr><td><code id="roundPred_+3A_dig.quant">dig.quant</code></td>
<td>
<p>Number of digits. Guessed if not provided.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only the columns that can be considered as quantiles are
rounded. These are assumed to have names <code>"quant"</code> for
the expected return level and <code>"L."</code> or <code>"U."</code> followed by a
percentage for lower and upper confidence limits (e.g. <code>"L.95"</code>
and <code>"U.95"</code> for 95% percent confidence limits.
The number of digits guessed is experimental.
</p>


<h3>Value</h3>

<p>A data.frame with the same structure as that given, but with some
columns rounded.
</p>

<hr>
<h2 id='rRendata'>
Simulate a random RenData object
</h2><span id='topic+rRendata'></span>

<h3>Description</h3>

<p>Simulate a random <code>RenData</code> object that can be used within the
<code>Renouv</code> function for tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rRendata(lambda = 1,
         threshold = 0,
         effDuration = 100,
         distname.y = "exp",
         par.y = c(rate = 1),
         start = "1913-01-01",
         name = NULL,
         varName = "X", varUnit = "?",
         simDate = TRUE, roundDate = FALSE,
         MAX.effDuration = NULL,
         MAX.r = rep(1L, length(MAX.effDuration)),
         OTS.effDuration = NULL,
         OTS.threshold = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rRendata_+3A_lambda">lambda</code></td>
<td>

<p>The rate of the Homogeneous Poisson Process.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_threshold">threshold</code></td>
<td>

<p>The threshold for the exceedances.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_effduration">effDuration</code></td>
<td>

<p>The effective duration of the main Over Threshold (OT) period.
This must be a positive value.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_distname.y">distname.y</code></td>
<td>

<p>Name of the distribution for the excesses to be simulated.  See
<b>Details</b>.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_par.y">par.y</code></td>
<td>

<p>A named vector or list giving the parameters values for the
distribution. The name must conform to the chosen distribution.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_start">start</code></td>
<td>

<p>A <code>POSIXct</code> object, or character that can be coerced to
<code>POSIXct</code> (e.g. a date given as a character in the
<code>"YYYY-MM-DD"</code> format) giving the start of the main OT sample.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_name">name</code></td>
<td>

<p>A name for the dataset which will be attached to it and be used by
some methods for <code>"Rendata"</code>.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_varname">varName</code></td>
<td>

<p>Name of the simulated variable.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_varunit">varUnit</code></td>
<td>

<p>Unit for the simulated variable (is used by plot). 
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_simdate">simDate</code></td>
<td>

<p>Logical. If <code>TRUE</code> the dates will be reported for the
historical data (MAX and OTS).
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_rounddate">roundDate</code></td>
<td>

<p>Logical. If <code>TRUE</code> the time part ot the <code>date</code> column will
be rounded. Not implemented yet.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_max.effduration">MAX.effDuration</code></td>
<td>

<p>Vector of the durations for the <code>MAX</code> historical blocks.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_max.r">MAX.r</code></td>
<td>

<p>Vector of the (positive) numbers of observations for <code>MAX</code>
historical blocks. Must have the same length as
<code>MAX.effDuration</code>. See <b>Caution</b> below for the effect of
selection large values.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_ots.effduration">OTS.effDuration</code></td>
<td>

<p>Vector of durations for the <code>OTS</code> historical blocks.
</p>
</td></tr>
<tr><td><code id="rRendata_+3A_ots.threshold">OTS.threshold</code></td>
<td>

<p>Vector of numerical thresholds for the observations in <code>OTS</code>
historical blocks. Must have the same length as
<code>OTS.effDuration</code>. All values must be <code>&gt;= threshold</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distribution of the excesses named in <code>distname.y</code> can be
any known distribution, provided that when prefixed with the usual
<code>"r"</code> letter, the name gives the wanted simulation function. For
example, with <code>distname.y = "exp"</code>, the <code>rexp</code> function is
used and <code>par.y</code> must thus contain an element with name
<code>"rate"</code>.
</p>
<p>When a suitable numeric threshold is given, the simulated marks of the
marked process are the sum of the threshold and of a random excess
drawn from <code>distname.y</code>.  When the threshold is not a finite
numeric value, the observed marks are the simulated values themselves.
</p>
<p>The main OT sample is assumed to begin at <code>start</code>. Historical MAX
blocks (if any) are assumed to be just before <code>start</code>, and OTS
are just before <code>start</code> or just before the beginning of the MAX
blocks when there are some.  The dates are computed without taking
into consideration the problems of leap years or leap seconds.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"Rendata"</code>. This class currently has
<code>plot</code> and <code>summary</code> methods.
</p>


<h3>Caution</h3>

<p>By construction, each <code>MAX</code> block contains at least one
observation, while a random period of the same duration might have
none. The simulated number of events on a MAX block is generated using
a censored Poisson distribution.  Care must be taken when estimations
are made on such data, since creating <code>MAX</code> blocks obviously
create a positive bias on <code>lambda</code>. Such bias then also affects
the other parameters concerning the excesses, because these
parameters are no longer orthogonal to the rate parameter
<code>lambda</code> when historical data are used. The bias can be severe if
<code>MAX</code> blocks with small durations are used, or if large number of
events are chosen in <code>MAX.r</code>.
</p>


<h3>Note</h3>

<p>When <code>effDuration</code> is small relative to the inverse of
<code>lambda</code> the number of simulated marks in the OT sample may be
<code class="reqn">0</code> which can cause problems for some uses of the created data.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.Rendata">plot.Rendata</a></code>, <code><a href="#topic+summary.Rendata">summary.Rendata</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
rd &lt;- rRendata(effDuration = 60,
               MAX.effDuration = rep(3, 6),
               MAX.r = rep(4, 6),
               distname.y = "exp", par.y = c(rate = 1/100))
plot(rd)
summary(rd)
rd2 &lt;- rRendata(effDuration = 10,
                MAX.effDuration = rep(60, 2),
                MAX.r = rep(3, 2),
                simDate = FALSE,
                distname.y = "gpd", par.y = c(scale = 20, shape = 0.16))
plot(rd2)
rd3 &lt;- rRendata(effDuration = 10,
                OTS.effDuration = rep(60, 2),
                OTS.threshold = rep(80, 2),
                simDate = FALSE,
                distname.y = "gpd", par.y = c(scale = 20, shape = 0.16))
plot(rd3)
## Renouv fit with historical data
fit &lt;- Renouv(rd)
summary(fit)
</code></pre>

<hr>
<h2 id='SandT'>
Compute empirical survivals (S) and return periods (T)
</h2><span id='topic+SandT'></span>

<h3>Description</h3>

<p>Compute the empirical survival values and the empirical return periods
at the observations of an object. These are used as plotting positions
in several plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  SandT(object, points = c("p", "H"), a = 0, naive = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SandT_+3A_object">object</code></td>
<td>

<p>The object containing the data, with class <code>"Renouv"</code> or
<code>"Rendata"</code>.
</p>
</td></tr>
<tr><td><code id="SandT_+3A_points">points</code></td>
<td>

<p>Option for the computation of the plotting positions.  When
<code>points</code> is set to <code>"p"</code>, the <code class="reqn">p</code>-points formula is
used with the selected value of <code>a</code>. This formula is used to
compute the survival from which the return period is computed. When
instead <code>points</code> is set to <code>"H"</code>, <em>Nelson's formula</em>
is used to compute the return periods, the survival value still
being given by the <code class="reqn">p</code>-points formula. When the data is
heterogeneous, i.e.  when <code>object</code> contains <code>MAX</code> and/or
<code>OTS</code> data, Nelson's formula is used only to compute the return
periods of the upper slice of levels.
</p>
</td></tr>
<tr><td><code id="SandT_+3A_a">a</code></td>
<td>

<p>Parameter used in the interpolation formula for the inverse return
periods as in Hirsch and Stedinger (1987).
</p>
</td></tr>
<tr><td><code id="SandT_+3A_naive">naive</code></td>
<td>

<p>Logical. When <code>TRUE</code>, naive plotting positions are used to
display <code>MAX</code> or <code>OTS</code> data. These can be defined only
when a main sample exists in <code>object</code> as a <code>x.OT</code> element.
For each <code>MAX</code> or <code>OTS</code> block, the positions use the
number of events predicted using the rate of events as estimated
from the main sample. When the main sample has a small durations,
such predictions are likely to be misleading.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object contains historical information (<code>MAX</code> or
<code>OTS</code>), the computation is an adaptation Hirsch and Stedinger
(1987) for the Marked Process (MP) context. The original method is
devoted to block maxima and interpolates the survival values at the
thresholds which are computed first. For MP, the interpolation is
done for the inverse return periods, and the survival values are
deduced from those of the inverse return periods.
</p>
<p>Nelson's formula provides unbiased estimates for the values of the
cumulative hazard <code class="reqn">H(x)</code> at the order statistics, and thus
can be used to estimate the log-return periods as required on the
return level plot.
</p>


<h3>Value</h3>

<p>A list with the following elements
</p>
<table>
<tr><td><code>x</code></td>
<td>

<p>Numeric vector containing the ordered values from all the available
sources in the object: main sample, historical periods either 'MAX' or
'OTS'.
</p>
</td></tr>
<tr><td><code>group</code>, <code>groupNames</code></td>
<td>

<p>Integer and character vectors giving the source of the values in
<code>x</code>, in the same order of the values. For instance,
<code>group[10]</code> gives the group form which <code>x[10]</code> was
extracted, and the name of this group is <code>groupNames[group[10]]</code>.
</p>
</td></tr>
<tr><td><code>S</code>, <code>T</code></td>
<td>

<p>Numeric vectors of the same length as <code>x</code> and containing the
corresponding estimation of the survival value and of the return
period.
</p>
</td></tr>
<tr><td><code>thresh</code>, <code>lambda.thresh</code>, <code>S.thresh</code>, <code>T.thresh</code></td>
<td>

<p>Vector of thresholds and the corresponding estimation for the event
rate, survival and return period. All the estimations are <em>for
the threshold values</em>. The value of <code>T.thresh[i]</code> for a threshold
<code>thresh[i]</code> results from a simple computation: divide the sum of
the durations for blocks with thresholds <code>&gt;= thresh[i]</code> by the
number of events for these blocks.
</p>
</td></tr>
</table>


<h3>seealso</h3>

<p>The <code><a href="stats.html#topic+ppoints">ppoints</a></code> and <code><a href="#topic+Hpoints">Hpoints</a></code> functions.
</p>


<h3>Warning</h3>

<p>When using <code>points = "H"</code> the estimated values of the survival
returned in <code>S</code> and those for the return period <code>T</code> no
longer verify <code>T=1/S/lambda</code>, where <code>lambda</code> is the
estimated rate. In this case, the values in <code>T</code> should be used in
the return level plot, while the values in <code>S</code> should be used in
the PP-plot.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>The original method for block maxima is described in
</p>

<ul>
<li><p> Hirsch R.M. and Stedinger J.R.(1887) Plotting Positions
for Historical Floods and their precision. <em>Water
Ressources Research</em>, vol. 23, N. 4 pp. 715-727.
</p>
</li>
<li><p> Millard S. and Neerchal N. (2001). <em>Environmental
Statistics with S-Plus</em>. CRC Press
</p>
</li></ul>

<p>The adaptation for the Marked Process context is
described in the <em>Renext Computing Details</em>
document.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use an object with class "Rendata"
ST1 &lt;- SandT(object = Garonne)
## basic return level plot
plot(ST1$T, ST1$x, col = ST1$group, log = "x")
## use an object with class "Renouv"
fit &lt;- Renouv(x = Garonne, plot = FALSE)
ST2 &lt;- SandT(object = fit)
plot(ST2$T, ST2$x, col = ST2$group, log = "x")
</code></pre>

<hr>
<h2 id='skip2noskip'>
Fix non-skipped periods from skipped ones
</h2><span id='topic+skip2noskip'></span>

<h3>Description</h3>

<p>Compute non-skipped periods form start and end of skipped periods.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   skip2noskip(skip = NULL,
               start = NULL,
               end = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skip2noskip_+3A_skip">skip</code></td>
<td>

<p>A data.frame object with <code>start</code> and <code>end</code> columns that
can be coerced to <code>POSIXct</code>. Other columns can be present (and will be
ignored). Each row describes a missing period. Rows must be sorted
in chronological order and periods should not overlap. Validity
checks are at the time very limited.
</p>
</td></tr>
<tr><td><code id="skip2noskip_+3A_start">start</code></td>
<td>

<p>Beginning of the whole period, to be used in <code>as.POSIXct</code>.
</p>
</td></tr>
<tr><td><code id="skip2noskip_+3A_end">end</code></td>
<td>

<p>End of the whole period to be used in <code>as.POSIXct</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a 'normal' use of this function <code>start</code> and <code>end</code> are
given, and are respectively <em>before the beginning</em> of the first
<code>skip</code> period and <em>after the end</em> of the last <code>skip</code>
period.  Thus the returned dataframe will have <code>nrow(skip)+1</code>
rows. However, <code>start</code> and <code>end</code> can be <code>NULL</code> in which
case only the <code>nrows(skip)-1</code> &quot;inner&quot; non-skipped periods will be
returned. If <code>start</code> and <code>end</code> are <code>NULL</code> and
<code>skip</code> has only one row, the returned result is <code>NULL</code>.
</p>


<h3>Value</h3>

<p>A data.frame object with two <code>POSIXct</code> columns named <code>start</code> and
<code>end</code>. Each row corresponds to a non-skipped period
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p><code><a href="#topic+readXML">readXML</a></code> for reading data from XML and csv files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Brest data embeds a description of the gaps

ns &lt;- skip2noskip(skip = Brest$OTmissing)

ns2 &lt;- skip2noskip(skip = Brest$OTmissing,
                   start = Brest$OTinfo$start,
                   end = Brest$OTinfo$end)

## check durations. dur2 should be equal to the effective
## duration (with an error of a fraction of day)
dur &lt;- as.numeric(sum(ns$end-ns$start))/365.25
dur2 &lt;- as.numeric(sum(ns2$end-ns2$start))/365.25


</code></pre>

<hr>
<h2 id='SLTW'>Shifted Left Truncated Weibull (SLTW) distribution</h2><span id='topic+SLTW'></span><span id='topic+dSLTW'></span><span id='topic+pSLTW'></span><span id='topic+qSLTW'></span><span id='topic+rSLTW'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and random
generation for the Shifted Left Truncated Weibull distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   dSLTW(x, delta = 1.0, shape = 1.0, scale = 1.0, log = FALSE)
   pSLTW(q, delta = 1.0, shape = 1.0, scale = 1.0, lower.tail = FALSE)
   qSLTW(p, delta = 1.0, shape = 1.0, scale = 1.0)
   rSLTW(n, delta = 1.0, shape = 1.0, scale = 1.0) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLTW_+3A_x">x</code>, <code id="SLTW_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="SLTW_+3A_p">p</code></td>
<td>

<p>Vector of probabilities.
</p>
</td></tr>
<tr><td><code id="SLTW_+3A_n">n</code></td>
<td>

<p>Number of observations.
</p>
</td></tr>
<tr><td><code id="SLTW_+3A_delta">delta</code>, <code id="SLTW_+3A_shape">shape</code>, <code id="SLTW_+3A_scale">scale</code></td>
<td>

<p>Shift, shape and scale parameters. Vectors of length &gt; 1 are not
accepted.
</p>
</td></tr>
<tr><td><code id="SLTW_+3A_log">log</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the log density is returned.
</p>
</td></tr>
<tr><td><code id="SLTW_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Logical; if <code>TRUE</code> (default), probabilities are
<code class="reqn">\textrm{Pr}[X \le x]</code>, otherwise,
<code class="reqn">\textrm{Pr}[X &gt; x]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SLTW distribution function with shape <code class="reqn">\alpha &gt; 0</code>, scale
<code class="reqn">\beta &gt; 0</code> and shift <code class="reqn">\delta &gt; 0</code> has survival function
</p>
<p style="text-align: center;"><code class="reqn">S(y) = 
    \exp\left\{
       -\left[  \left( \frac{y + \delta}{\beta} \right)^\alpha
       -        \left( \frac{\delta}{\beta}   \right)^\alpha
       \right]
    \right\} \qquad (y &gt; 0)
  </code>
</p>

<p>This distribution is that of <code class="reqn">Y := X - \delta</code> conditional to
<code class="reqn">X &gt; \delta</code> where <code class="reqn">X</code> follows a Weibull distribution with
shape <code class="reqn">\alpha</code> and scale <code class="reqn">\beta</code>.
</p>
<p>The hazard and mean residual life (MRL) are monotonous functions with
the same monotonicity as their Weibull equivalent (with the same shape
and scale). The moments or even expectation do not have simple
expression.
</p>
<p>This distribution is sometimes called <em>power exponential</em>. It is
occasionally used in POT with the shift <code>delta</code> taken as the
threshold as it should be when the distribution for the level <code class="reqn">X</code>
(and not for the exceedance <code class="reqn">Y</code>) is known to be the standard
Weibull distribution.  </p>


<h3>Value</h3>

 <p><code>dSLTW</code> gives the density
function, <code>pSLTW</code> gives the distribution function, <code>qSLTW</code>
gives the quantile function, and <code>rSLTW</code> generates random
deviates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lomax">Lomax</a></code> for the Lomax distribution which is a limit case
of <code>SLTW</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>shape &lt;- rexp(1)+1  
delta = 10

xl &lt;- qSLTW(c(0.001, 0.99), delta = delta, shape = shape)
x &lt;- seq(from = xl[1], to = xl[2], length.out = 200)
f &lt;- dSLTW(x, delta = delta, shape = shape)
plot(x, f, type = "l", main = "SLTW density")

F &lt;- pSLTW(x, delta = delta, shape = shape)
plot(x, F, type = "l", main = "SLTW distribution")

X &lt;- rSLTW(5000, delta = delta, shape = shape)
## Should be close to the uniform repartition
plot(ecdf(pSLTW(X, delta = delta, shape = shape)))

</code></pre>

<hr>
<h2 id='spacings'>
Methods computing spacings between Largest Order Statistics
</h2><span id='topic+spacings'></span><span id='topic+spacings.numeric'></span><span id='topic+spacings.data.frame'></span><span id='topic+spacings.Rendata'></span>

<h3>Description</h3>

<p>Methods computing the random <em>spacings</em> for the Largest Order
Statistics of the marks in a POT renewal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacings(object, ...)

## S3 method for class 'numeric'
spacings(object, wExp = TRUE, ...)

## S3 method for class 'data.frame'
spacings(object, varName, wExp = TRUE, ...)

## S3 method for class 'Rendata'
spacings(object, type = c("MAX", "OTS", "OT"), wExp = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spacings_+3A_object">object</code></td>
<td>

<p>A object containing the marks <code class="reqn">X_i</code>. This is can be a vector or
a data frame for data aggregated by blocks. For an object of class
<code>data.frame</code> one of the three data.frame slots: <code>OTdata</code>,
<code>MAXdata</code> or <code>OTSdata</code> can be used using the suitable
value of <code>type</code>.
</p>
</td></tr>
<tr><td><code id="spacings_+3A_varname">varName</code></td>
<td>

<p>Character vector of length 1 giving the name of the variable when
<code>object</code> is a data.frame.
</p>
</td></tr>
<tr><td><code id="spacings_+3A_wexp">wExp</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the spacings are weighted as explained in
<b>Details</b>.
</p>
</td></tr>
<tr><td><code id="spacings_+3A_type">type</code></td>
<td>

<p>Character specifying the data.frame to be used when object has class
<code>"Rendata"</code>.
</p>
</td></tr>
<tr><td><code id="spacings_+3A_...">...</code></td>
<td>

<p>Not used yet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The spacings are the differences between the Largest Order
Statistics. They are useful for some estimation tasks or diagnostics.
Given random variables <code class="reqn">X_i</code>, the <code class="reqn">i</code>-th spacing <code class="reqn">Y_i</code> is
the difference <code class="reqn">X_{(i)}-X_{(i+1)}</code> between the <code class="reqn">i</code>-th largest
order statistic <code class="reqn">X_{(i)}</code> and the next in the decreasing order
i.e. <code class="reqn">X_{(i+1)}</code>.
</p>
<p>When the r.vs <code class="reqn">X_i</code> form a sample of an exponential or Gumbel
distribution, the spacings associated with the largest order
statistics are or tend to be independent and exponentially
distributed. More precisely, the weighted spacings <code class="reqn">i \times
  Y_i</code> have or tend to have the same exponential
distribution. This can be used to estimate the shape parameter of the
underlying distribution using only the largest order
statistics. Moreover the <code class="reqn">r-1</code> spacings <code class="reqn">Y_i</code> built from the
<code class="reqn">r</code> largest order statistics <code class="reqn">i \le r</code> are or tend to be
independent from the <code class="reqn">r</code>-th largest order statistic <code class="reqn">X_{(r)}</code>.
</p>
<p>When <code>wExp</code> is <code>TRUE</code>, the returned values are the weighted
spacings <code class="reqn">i \times Y_i</code>.
</p>


<h3>Value</h3>

<p>A list or vector containing the spacings. When the data is structured
in blocks as is the <code>MAXdata</code> slot of an object of class
<code>"Rendata"</code>, the spacings are computed form the order statistics
<em>within each block</em>, to maintain independence with the next order
statistic in decreasing order.
</p>


<h3>Caution</h3>

<p>By default, the spacings are scaled as explained above, thus assuming
that the marks are exponentially distributed.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>References</h3>

<p>Embrechts P., Klüppelberg C. and Mikosch T. (1997) <em>Modelling
Extremal Events for Insurance and Finance</em>. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sp &lt;- spacings(rgumbel(200, loc = 0, scale = 1))
expplot(sp)
sp1 &lt;- spacings(rgev(200, loc = 0, scale = 1, shape = 0.3))
expplot(sp1)
## spacings are computed by block
sp2 &lt;- spacings(object = Garonne$MAXdata,
                varName = Garonne$info$varName)
expplot(unlist(sp2))
sp3 &lt;- spacings(object = Garonne, type = "OT")
expplot(sp3)
</code></pre>

<hr>
<h2 id='summary.Rendata'>
Summary and  print methods for &quot;Rendata&quot; objects
</h2><span id='topic+print.Rendata'></span><span id='topic+summary.Rendata'></span><span id='topic+print.summary.Rendata'></span>

<h3>Description</h3>

<p>Summary method for &quot;Rendata&quot; objects representing data
to be used in renouvellement models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
  ## S3 method for class 'Rendata'
print(x, ...)
 
  ## S3 method for class 'Rendata'
summary(object, ...)

  ## S3 method for class 'summary.Rendata'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.Rendata_+3A_object">object</code></td>
<td>

<p>An object with class <code>"Rendata"</code>.
</p>
</td></tr>
<tr><td><code id="summary.Rendata_+3A_x">x</code></td>
<td>

<p>An object of class <code>"summary.Rendata"</code>, i.e.  a result of a
call to <code>summary.Rendata</code>.
</p>
</td></tr>
<tr><td><code id="summary.Rendata_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Brest example: no historical data
summary(Brest)

## Garonne example:  with historical data
summary(Garonne)

</code></pre>

<hr>
<h2 id='summary.Renouv'>Summary and print methods for &quot;Renouv&quot; objects</h2><span id='topic+print.Renouv'></span><span id='topic+summary.Renouv'></span><span id='topic+print.summary.Renouv'></span><span id='topic+format.summary.Renouv'></span>

<h3>Description</h3>

<p>Summary method for &quot;Renouv&quot; objects representing 'Renouvellement' (POT)
fitted models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   ## S3 method for class 'Renouv'
print(x,
        digits = max(3L, getOption("digits") - 3L),
        ...)

   ## S3 method for class 'Renouv'
summary(object,
        correlation = FALSE,
        symbolic.cor = FALSE,
        ...)

   ## S3 method for class 'summary.Renouv'
print(x,
      coef = TRUE,
      pred = TRUE,
      probT = FALSE,
      digits = max(3, getOption("digits") - 3),
      symbolic.cor = x$symbolic.cor,
      signif.stars = getOption("show.signif.stars"),
      ...)

   ## S3 method for class 'summary.Renouv'
format(x,
      ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.Renouv_+3A_object">object</code></td>
<td>

<p>An object with class <code>"Renouv"</code>.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_x">x</code></td>
<td>

<p>An object of class <code>"summary.Renouv"</code>, i.e.  a result of a call
to <code>summary.Renouv</code>.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_correlation">correlation</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the correlation matrix of the estimated
parameters is returned and printed.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_coef">coef</code></td>
<td>

<p>Logical. If <code>FALSE</code>, the table of coefficients and t-ratios'
will not be printed.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_pred">pred</code></td>
<td>

<p>Logical. If <code>FALSE</code>, the table of return periods/levels will
not be printed.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_probt">probT</code></td>
<td>

<p>If <code>FALSE</code>, the <code class="reqn">p</code>-values for the t-tests will not be
printed nor displayed.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_digits">digits</code></td>
<td>

<p>the number of significant digits to use when printing.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_symbolic.cor">symbolic.cor</code></td>
<td>

<p>logical. If <code>TRUE</code>, print the correlations in a symbolic form
(see <code><a href="stats.html#topic+symnum">symnum</a></code>) rather than as numbers.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_signif.stars">signif.stars</code></td>
<td>

<p>logical. If <code>TRUE</code>, &lsquo;significance stars&rsquo; are printed for
each coefficient.
</p>
</td></tr>
<tr><td><code id="summary.Renouv_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.summary.Renouv</code> tries to be smart about formatting the
coefficients, standard errors, return levels, etc.
<code>format.summary.Renouv</code> returns as a limited content as a
character string. It does not embed coefficients values nor
predictions.
</p>


<h3>Value</h3>

<p>The function <code>summary.RenOUV</code> computes and returns a list of
summary statistics concerning the object of class <code>"Rendata"</code>
given in <code>object</code>.  The returned list is an object with class
<code>"summary.Renouv"</code>.
</p>
<p>The function <code>print.summary.Rendata</code> does not returns anything.
</p>


<h3>See Also</h3>

<p>The model fitting function <code><a href="#topic+Renouv">Renouv</a></code> (to build
<code>"Renouv"</code> model objects), <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use Brest data
fit &lt;- Renouv(Brest)
summary(fit)
</code></pre>

<hr>
<h2 id='translude'>Make translucient colors</h2><span id='topic+translude'></span>

<h3>Description</h3>

<p>Make translucient colors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>translude(colors, alpha = 0.6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="translude_+3A_colors">colors</code></td>
<td>

<p>A vector of colors in a format that can be understood by
<code><a href="grDevices.html#topic+col2rgb">col2rgb</a></code>.
</p>
</td></tr>
<tr><td><code id="translude_+3A_alpha">alpha</code></td>
<td>

<p>Vector of level(s) of opacity between <code>0</code> and <code>1</code> (<code>0</code> means fully
transparent and <code>1</code> means opaque). After recycling to reach the
required length, this value or vector is used as <code>alpha</code> in
<code><a href="grDevices.html#topic+rgb">rgb</a></code>.  </p>
</td></tr> </table>


<h3>Value</h3>

<p> A vector of translucient (or
semi-transparent) colors.
</p>


<h3>Note</h3>

<p>Using the <b>RColorBrewer</b> package might be a better option that
transluding chosen colors!
</p>

<hr>
<h2 id='vcov.Renouv'>
Variance-covariance matrix of the estimates of a &quot;Renouv&quot; object
</h2><span id='topic+vcov.Renouv'></span>

<h3>Description</h3>

<p>Variance-covariance matrix of the estimates of a &quot;Renouv&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Renouv'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov.Renouv_+3A_object">object</code></td>
<td>

<p>Object of class <code>"Renouv"</code>.
</p>
</td></tr>
<tr><td><code id="vcov.Renouv_+3A_...">...</code></td>
<td>

<p>Not used at the time.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variance-covariance matrix. The rows an columns correspond to the
parameters of the Renouv object. The are the rate <code>"lambda"</code> for
the Poisson process, and the parameters of the distribution for the
excesses over the threshold, with names depending on the chosen
distribution.
</p>


<h3>Author(s)</h3>

<p>Yves Deville
</p>


<h3>See Also</h3>

<p>The <code><a href="stats.html#topic+vcov">vcov</a></code> generic.
</p>

<hr>
<h2 id='weibplot'>Classical Weibull distribution plot</h2><span id='topic+weibplot'></span>

<h3>Description</h3>

<p>Plots a vector using Weibull distribution scales
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   weibplot(x,
            plot.pos = "exp",
            shape = NULL, scale = NULL,
            labels = NULL,
            mono = TRUE,
            ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weibplot_+3A_x">x</code></td>
<td>
<p>The vector to be plotted.</p>
</td></tr>
<tr><td><code id="weibplot_+3A_plot.pos">plot.pos</code></td>
<td>
<p>plotting position for points: either &quot;exp&quot; for
<em>expected</em> ranks or &quot;med&quot; for a <em>median</em> rank approximation (see <b>Details</b> below).</p>
</td></tr>
<tr><td><code id="weibplot_+3A_shape">shape</code></td>
<td>
<p>Shape parameter for one or several Weibull lines to be plotted.</p>
</td></tr>
<tr><td><code id="weibplot_+3A_scale">scale</code></td>
<td>
<p>Scale parameter for one or several Weibull lines to be plotted.</p>
</td></tr>
<tr><td><code id="weibplot_+3A_labels">labels</code></td>
<td>
<p>Text to display in legend when Weibull lines are
specified.</p>
</td></tr>
<tr><td><code id="weibplot_+3A_mono">mono</code></td>
<td>
<p>Monochrome graph.</p>
</td></tr>
<tr><td><code id="weibplot_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This plot shows <code class="reqn">\log\{-\log[1-F(x)]\}</code> against
<code class="reqn">\log(x)</code> where <code class="reqn">F(x)</code> at point <code class="reqn">i</code>
is taken as <code class="reqn">i/(n+1)</code> if <code>plot.pos</code> is <code>"exp"</code>, or as
the &quot;median rank&quot; approximation <code class="reqn">(i-0.3)/(n+0.4)</code>
if <code>plot.pos</code> is <code>"med"</code>.
</p>


<h3>Note</h3>

<p>The graph displayed uses a log scale for x. The log-log scale for y is
emulated via the construction of suitable graduations. So be careful when
adding graphical material (points, etc) to this graph with functions of
the &quot;add to plot&quot; family (<code>points</code>, <code>lines</code>, ...).
</p>


<h3>Author(s)</h3>

<p>Yves Deville</p>


<h3>See Also</h3>

<p>The <code><a href="#topic+expplot">expplot</a></code> function for an &quot;exponential
distribution&quot; plot (dedicated to the <code>shape = 1</code> case), and 
the <code><a href="#topic+fweibull">fweibull</a></code> function for ML estimation of the
parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rweibull(200, shape = 1.2, scale = 1)
weibplot(x, main = "Classical Weibull plot")
## Weibull lines
weibplot(x, shape = c(0.9, 1.3), scale = 1)
weibplot(x, shape = c(0.9, 1.3), scale = 1,
         labels = c("before", "after"))
weibplot(x, shape = c(0.9, 1.3), scale = 1,
         labels = c("before", "after"),
         mono = TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
