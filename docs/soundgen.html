<!DOCTYPE html><html lang="en"><head><title>Help for package soundgen</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {soundgen}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.addAM'><p>Add AM to a sound</p></a></li>
<li><a href='#.addFormants'><p>Add formants per sound</p></a></li>
<li><a href='#.analyze'><p>Analyze per sound</p></a></li>
<li><a href='#.audSpectrogram'><p>Auditory spectrogram per sound</p></a></li>
<li><a href='#.bandpass'><p>Bandpass filter per sound</p></a></li>
<li><a href='#.detectNLP'><p>Detect NLP per sound</p></a></li>
<li><a href='#.fade'><p>Fade per sound</p></a></li>
<li><a href='#.filterSoundByMS'><p>Filter a single sound by MS</p></a></li>
<li><a href='#.flatEnv'><p>Flat envelope per sound</p></a></li>
<li><a href='#.flatSpectrum'><p>Flat spectrum per sound</p></a></li>
<li><a href='#.getDuration'><p>Get duration per sound</p></a></li>
<li><a href='#.getLoudness'><p>Loudness per sound</p></a></li>
<li><a href='#.getPitchZc'><p>Zero-crossing rate per sound</p></a></li>
<li><a href='#.getRMS'><p>RMS amplitude per sound</p></a></li>
<li><a href='#.getSurprisal'><p>Get surprisal per sound</p></a></li>
<li><a href='#.modulationSpectrum'><p>Modulation spectrum per sound</p></a></li>
<li><a href='#.osc'><p>Oscillogram per sound</p></a></li>
<li><a href='#.phasegram'><p>Phasegram per sound</p></a></li>
<li><a href='#.pitchDescriptives'><p>Pitch descriptives per file</p></a></li>
<li><a href='#.prosody'><p>Prosody per sound</p></a></li>
<li><a href='#.resample'><p>Resample per sound</p></a></li>
<li><a href='#.reverb'><p>Add reverb to a sound</p></a></li>
<li><a href='#.segment'><p>Internal soundgen function</p></a></li>
<li><a href='#.shiftFormants'><p>Shift formants per sound</p></a></li>
<li><a href='#.shiftPitch'><p>Shift pitch per sound</p></a></li>
<li><a href='#.spectrogram'><p>Spectrogram per sound</p></a></li>
<li><a href='#.ssm'><p>SSM per sound</p></a></li>
<li><a href='#.timeStretch'><p>Time stretch per sound</p></a></li>
<li><a href='#addAM'><p>Add amplitude modulation</p></a></li>
<li><a href='#addFormants'><p>Add formants</p></a></li>
<li><a href='#addPitchCands'><p>Plot pitch candidates</p></a></li>
<li><a href='#addPitchJumps'><p>Add pitch jumps</p></a></li>
<li><a href='#addSubh'><p>Subharmonics</p></a></li>
<li><a href='#addSubh_per_epoch'><p>Constant subharmonics</p></a></li>
<li><a href='#addVectors'><p>Add overlapping vectors</p></a></li>
<li><a href='#analyze'><p>Acoustic analysis</p></a></li>
<li><a href='#analyzeFrame'><p>Analyze fft frame</p></a></li>
<li><a href='#annotation_app'><p>Annotation app</p></a></li>
<li><a href='#audSpectrogram'><p>Auditory spectrogram</p></a></li>
<li><a href='#averageMatrices'><p>Average matrices</p></a></li>
<li><a href='#bandpass'><p>Bandpass/stop filters</p></a></li>
<li><a href='#beat'><p>Generate beat</p></a></li>
<li><a href='#checkInputType'><p>Check audio input type</p></a></li>
<li><a href='#clumper'><p>Clump a sequence into large segments</p></a></li>
<li><a href='#compareSounds'><p>Compare two sounds</p></a></li>
<li><a href='#convert_sec_to_hms'><p>Print time</p></a></li>
<li><a href='#convertStringToFormants'><p>Prepare a list of formants</p></a></li>
<li><a href='#costJumps'><p>Cost of jumps</p></a></li>
<li><a href='#costPerPath'><p>Cost per path</p></a></li>
<li><a href='#crossFade'><p>Join two waveforms by cross-fading</p></a></li>
<li><a href='#def_form'><p>Defaults and ranges for formant_app()</p></a></li>
<li><a href='#defaults'><p>Shiny app defaults</p></a></li>
<li><a href='#defaults_analyze'><p>Defaults and ranges for analyze()</p></a></li>
<li><a href='#defaults_analyze_pitchCand'><p>Defaults for plotting with analyze()</p></a></li>
<li><a href='#detectNLP'><p>Detect NLP</p></a></li>
<li><a href='#detectNLP_training_nonv'><p>Nonlinear phenomena: Naive Bayes classifier trained on human nonverbal</p>
vocalizations</a></li>
<li><a href='#detectNLP_training_synth'><p>Nonlinear phenomena: Naive Bayes classifier trained on synthetic sounds</p></a></li>
<li><a href='#divideIntoSyllables'><p>Syllable structure of a bout</p></a></li>
<li><a href='#dPhase'><p>Phase derivatives</p></a></li>
<li><a href='#drawContour'><p>Draw contour</p></a></li>
<li><a href='#drawFreqAxis'><p>Draw frequency axis</p></a></li>
<li><a href='#ERBToHz'><p>Convert Hz to ERB rate</p></a></li>
<li><a href='#estimateVTL'><p>Estimate vocal tract length</p></a></li>
<li><a href='#evaluatePars'><p>Evaluate parameters for optimization</p></a></li>
<li><a href='#fade'><p>Fade</p></a></li>
<li><a href='#fart'><p>Fart</p></a></li>
<li><a href='#filled.contour.mod'><p>Modified filled.contour</p></a></li>
<li><a href='#filterMS'><p>Filter modulation spectrum</p></a></li>
<li><a href='#filterSoundByMS'><p>Filter sound by modulation spectrum</p></a></li>
<li><a href='#findBursts'><p>Find bursts</p></a></li>
<li><a href='#findElbow'><p>Find the elbow of a screeplot or similar</p></a></li>
<li><a href='#findGrad'><p>Find gradient</p></a></li>
<li><a href='#findInflections'><p>Find inflections</p></a></li>
<li><a href='#findJumps'><p>Find frequency jumps</p></a></li>
<li><a href='#findPeaks'><p>Find peaks</p></a></li>
<li><a href='#findSyllables'><p>Find syllables</p></a></li>
<li><a href='#findVoicedSegments'><p>Find voiced segments</p></a></li>
<li><a href='#findZeroCrossing'><p>Find zero crossing</p></a></li>
<li><a href='#flatEnv'><p>Flat envelope / compressor</p></a></li>
<li><a href='#flatSpectrum'><p>Flat spectrum</p></a></li>
<li><a href='#forcePerPath'><p>Force per path</p></a></li>
<li><a href='#formant_app'><p>Interactive formant tracker</p></a></li>
<li><a href='#formatPitchManual'><p>Format pitchManual</p></a></li>
<li><a href='#gaussianSmooth2D'><p>Gaussian smoothing in 2D</p></a></li>
<li><a href='#generateEpoch'><p>Generate an epoch</p></a></li>
<li><a href='#generateGC'><p>Generate glottal cycles</p></a></li>
<li><a href='#generateHarmonics'><p>Generate harmonics</p></a></li>
<li><a href='#generateNoise'><p>Generate noise</p></a></li>
<li><a href='#generatePath'><p>Generate path</p></a></li>
<li><a href='#getAM'><p>Get amplitude modulation</p></a></li>
<li><a href='#getAM_env'><p>Get Amplitude Modulation</p></a></li>
<li><a href='#getBandwidth'><p>Get bandwidth</p></a></li>
<li><a href='#getCheckerboardKernel'><p>Checkerboard kernel</p></a></li>
<li><a href='#getCPP'><p>Get Cepstral Peak Prominence</p></a></li>
<li><a href='#getDiscreteContour'><p>Discrete smooth contour from anchors</p></a></li>
<li><a href='#getDom'><p>Get lowest dominant frequency band</p></a></li>
<li><a href='#getDuration'><p>Get duration</p></a></li>
<li><a href='#getEntropy'><p>Entropy</p></a></li>
<li><a href='#getEnv'><p>Get amplitude envelope</p></a></li>
<li><a href='#getFeatureFlux'><p>Get flux from features</p></a></li>
<li><a href='#getFormantDispersion'><p>Get formant dispersion</p></a></li>
<li><a href='#getFormants'><p>Get formants</p></a></li>
<li><a href='#getFrameBank'><p>Frame bank</p></a></li>
<li><a href='#getGlottalCycles'><p>Divide f0 contour into glottal cycles</p></a></li>
<li><a href='#getHNR'><p>Get HNR</p></a></li>
<li><a href='#getIntegerRandomWalk'><p>Discrete random walk</p></a></li>
<li><a href='#getLoudness'><p>Get loudness</p></a></li>
<li><a href='#getMelSpec'><p>Mel-transformed spectrogram</p></a></li>
<li><a href='#getNovelty'><p>SSM novelty</p></a></li>
<li><a href='#getPeakFreq'><p>Get peak frequency</p></a></li>
<li><a href='#getPitchAutocor'><p>Autocorrelation pitch tracker</p></a></li>
<li><a href='#getPitchCep'><p>Cepstral pitch tracker</p></a></li>
<li><a href='#getPitchHps'><p>Harmonic product spectrum</p></a></li>
<li><a href='#getPitchSpec'><p>BaNa pitch tracker</p></a></li>
<li><a href='#getPitchZc'><p>Zero-crossing rate</p></a></li>
<li><a href='#getPrior'><p>Get prior for pitch candidates</p></a></li>
<li><a href='#getRandomWalk'><p>Random walk</p></a></li>
<li><a href='#getRMS'><p>RMS amplitude</p></a></li>
<li><a href='#getRolloff'><p>Control rolloff of harmonics</p></a></li>
<li><a href='#getRough'><p>Calculate roughness from modulation spectrum</p></a></li>
<li><a href='#getSHR'><p>Subharmonics-to-harmonics ratio</p></a></li>
<li><a href='#getSigmoid'><p>Get sigmoid filter</p></a></li>
<li><a href='#getSmoothContour'><p>Smooth contour from anchors</p></a></li>
<li><a href='#getSmoothSpectrum'><p>Get smooth spectrum</p></a></li>
<li><a href='#getSpectralEnvelope'><p>Spectral envelope</p></a></li>
<li><a href='#getSpectralFlux'><p>Get spectral flux</p></a></li>
<li><a href='#getSurprisal'><p>Get surprisal</p></a></li>
<li><a href='#getSurprisal_matrix'><p>Get surprisal per matrix</p></a></li>
<li><a href='#getSurprisal_vector'><p>Get surprisal per vector</p></a></li>
<li><a href='#guessPhase_GL'><p>Guess phase GL</p></a></li>
<li><a href='#guessPhase_spsi'><p>Guess phase SPSI</p></a></li>
<li><a href='#harmEnergy'><p>Energy in harmonics</p></a></li>
<li><a href='#harmHeight'><p>Height of harmonics</p></a></li>
<li><a href='#harmHeight_dif'><p>Height of harmonics: difference method</p></a></li>
<li><a href='#harmHeight_peaks'><p>Height of harmonics: peaks method</p></a></li>
<li><a href='#hillenbrand'><p>Formants in American vowels</p></a></li>
<li><a href='#htmlPlots'><p>HTML for clickable plots</p></a></li>
<li><a href='#hz2mel'><p>Hz to mel</p></a></li>
<li><a href='#HzToERB'><p>Convert Hz to ERB rate</p></a></li>
<li><a href='#HzToNotes'><p>Convert Hz to notes</p></a></li>
<li><a href='#HzToSemitones'><p>Convert Hz to semitones</p></a></li>
<li><a href='#identifyAndPlay'><p>Identify and play</p></a></li>
<li><a href='#interpolate'><p>Interpolate</p></a></li>
<li><a href='#interpolMatrix'><p>Interpolate matrix</p></a></li>
<li><a href='#intplNA'><p>Interpolate NAs</p></a></li>
<li><a href='#invertSpectrogram'><p>Invert spectrogram</p></a></li>
<li><a href='#isNeighbour_mod'><p>Is neighbor modified</p></a></li>
<li><a href='#iso226'><p>iso226</p></a></li>
<li><a href='#istft_mod'><p>Modified istft</p></a></li>
<li><a href='#jet.col'><p>Matlab colors</p></a></li>
<li><a href='#killDC'><p>Kill DC</p></a></li>
<li><a href='#listDepth'><p>List depth</p></a></li>
<li><a href='#lockToFormants'><p>Lock to formants</p></a></li>
<li><a href='#log01'><p>log01</p></a></li>
<li><a href='#logistic'><p>Logistic</p></a></li>
<li><a href='#logit'><p>Logit</p></a></li>
<li><a href='#logMatrix'><p>Log-warp matrix</p></a></li>
<li><a href='#logWarpMS'><p>Log-warp a modulation spectrum</p></a></li>
<li><a href='#matchColumns'><p>Match number of columns</p></a></li>
<li><a href='#matchLengths'><p>Resize vector to required length</p></a></li>
<li><a href='#matchPars'><p>Match soundgen pars (experimental)</p></a></li>
<li><a href='#medianSmoother'><p>Median smoothing</p></a></li>
<li><a href='#Mode'><p>Modified mode</p></a></li>
<li><a href='#modulationSpectrum'><p>Modulation spectrum</p></a></li>
<li><a href='#modulationSpectrumFragment'><p>Modulation spectrum per fragment</p></a></li>
<li><a href='#morph'><p>Morph sounds</p></a></li>
<li><a href='#morphDF'><p>Morph dataframes</p></a></li>
<li><a href='#morphFormants'><p>Morph formants</p></a></li>
<li><a href='#morphList'><p>Morph lists</p></a></li>
<li><a href='#msToSpec'><p>Modulation spectrum to spectrogram</p></a></li>
<li><a href='#na.trim'><p>Trim leading and trailing NAs</p></a></li>
<li><a href='#naiveBayes'><p>Naive Bayes</p></a></li>
<li><a href='#naiveBayes_dynamicPrior'><p>Naive Bayes dynamic prior</p></a></li>
<li><a href='#naiveBayes_likelihood'><p>Naive Bayes likelihood</p></a></li>
<li><a href='#naiveBayes_train'><p>Train a naive Bayes classifier</p></a></li>
<li><a href='#noiseRemoval'><p>Noise removal</p></a></li>
<li><a href='#nonLinearPrediction_mod'><p>Nonlinear prediction modified</p></a></li>
<li><a href='#nonlinPred'><p>Nonlinear prediction</p></a></li>
<li><a href='#nonlinStats'><p>Nonlinear statistics</p></a></li>
<li><a href='#normalizeFolder'><p>Normalize folder</p></a></li>
<li><a href='#notesDict'><p>Conversion table from Hz to musical notation</p></a></li>
<li><a href='#notesToHz'><p>Convert notes to Hz</p></a></li>
<li><a href='#objectToString'><p>Object to string</p></a></li>
<li><a href='#optimizePars'><p>Optimize parameters for acoustic analysis</p></a></li>
<li><a href='#osc'><p>Oscillogram</p></a></li>
<li><a href='#parabPeakInterpol'><p>Parabolic peak interpolation</p></a></li>
<li><a href='#pathfinder'><p>Pathfinder</p></a></li>
<li><a href='#pathfinding_fast'><p>Path through pitch candidates: fast</p></a></li>
<li><a href='#pathfinding_slow'><p>Path through pitch candidates: slow</p></a></li>
<li><a href='#pDistr'><p>Proportion of total</p></a></li>
<li><a href='#permittedValues'><p>Defaults and ranges for soundgen()</p></a></li>
<li><a href='#phasegram'><p>Phasegram</p></a></li>
<li><a href='#phasePropagate'><p>Propagate phase</p></a></li>
<li><a href='#phon2sone'><p>Convert phon to sone</p></a></li>
<li><a href='#pitch_app'><p>Interactive pitch tracker</p></a></li>
<li><a href='#pitchContour'><p>Manually corrected pitch contours in 260 sounds</p></a></li>
<li><a href='#pitchDescriptives'><p>Pitch descriptives</p></a></li>
<li><a href='#pitchManual'><p>Manual pitch estimation in 260 sounds</p></a></li>
<li><a href='#pitchSmoothPraat'><p>Pitch smoothing as in Praat</p></a></li>
<li><a href='#playme'><p>Play audio</p></a></li>
<li><a href='#plotMS'><p>Plot modulation spectrum</p></a></li>
<li><a href='#plotSpec'><p>Plot spectrogram</p></a></li>
<li><a href='#plotUnrasterized'><p>Plot unrasterized spetrogram</p></a></li>
<li><a href='#presets'><p>Presets</p></a></li>
<li><a href='#princarg'><p>Principal argument</p></a></li>
<li><a href='#processAudio'><p>Process audio</p></a></li>
<li><a href='#prosody'><p>Prosody</p></a></li>
<li><a href='#pseudoLog'><p>Pseudolog</p></a></li>
<li><a href='#pseudoLog_undo'><p>Undo pseudolog</p></a></li>
<li><a href='#rbind_fill'><p>rbind_fill</p></a></li>
<li><a href='#readAudio'><p>Read audio</p></a></li>
<li><a href='#reformatAnchors'><p>Reformat anchors</p></a></li>
<li><a href='#reformatFormants'><p>Reformat formants</p></a></li>
<li><a href='#reportCI'><p>Report CI</p></a></li>
<li><a href='#reportTime'><p>Report time</p></a></li>
<li><a href='#resample'><p>Resample a vector</p></a></li>
<li><a href='#reverb'><p>Reverb &amp; echo</p></a></li>
<li><a href='#rnorm_truncated'><p>Random draw from a truncated normal distribution</p></a></li>
<li><a href='#rnorm_truncated2'><p>Random draw from a truncated normal distribution</p></a></li>
<li><a href='#sampleModif'><p>sampleModif</p></a></li>
<li><a href='#scaleNoiseAnchors'><p>Scale noise anchors</p></a></li>
<li><a href='#scaleSPL'><p>Scale SPL</p></a></li>
<li><a href='#schwa'><p>Schwa-related formant conversion</p></a></li>
<li><a href='#segment'><p>Segment a sound</p></a></li>
<li><a href='#segmentManual'><p>Manual counts of syllables in 260 sounds</p></a></li>
<li><a href='#selfsim'><p>Compute self-similarity</p></a></li>
<li><a href='#semitonesToHz'><p>Convert semitones to Hz</p></a></li>
<li><a href='#shiftFormants'><p>Shift formants</p></a></li>
<li><a href='#shiftPitch'><p>Shift pitch</p></a></li>
<li><a href='#silenceSegments'><p>Silence sound segments</p></a></li>
<li><a href='#sinc'><p>Sinc</p></a></li>
<li><a href='#snake'><p>Snake</p></a></li>
<li><a href='#soundgen'><p>Generate a sound</p></a></li>
<li><a href='#soundgen_app'><p>Interactive sound synthesizer</p></a></li>
<li><a href='#specToMS'><p>Spectrogram to modulation spectrum</p></a></li>
<li><a href='#specToMS_1D'><p>Spectrogram to modulation spectrum 1D</p></a></li>
<li><a href='#spectrogram'><p>Spectrogram</p></a></li>
<li><a href='#splitContour'><p>Split contour</p></a></li>
<li><a href='#splitIntoChunks'><p>Split vector into chunks</p></a></li>
<li><a href='#spreadSpec'><p>Spread spectrum</p></a></li>
<li><a href='#ssm'><p>Self-similarity matrix</p></a></li>
<li><a href='#summarizeAnalyze'><p>Summarize the output of analyze()</p></a></li>
<li><a href='#switchColorTheme'><p>Switch color theme</p></a></li>
<li><a href='#timeSeriesSummary'><p>Time series summary</p></a></li>
<li><a href='#timeStretch'><p>Time stretch</p></a></li>
<li><a href='#to_dB'><p>Convert to dB</p></a></li>
<li><a href='#transplantEnv'><p>Transplant envelope</p></a></li>
<li><a href='#transplantFormants'><p>Transplant formants</p></a></li>
<li><a href='#updateAnalyze'><p>Update analyze</p></a></li>
<li><a href='#upsampleGC'><p>Upsample glottal cycles</p></a></li>
<li><a href='#validatePars'><p>Validate parameters</p></a></li>
<li><a href='#warpMatrix'><p>Warp matrix</p></a></li>
<li><a href='#wiggleAnchors'><p>Randomly modify anchors</p></a></li>
<li><a href='#wiggleGC'><p>Wiggle glottal cycles</p></a></li>
<li><a href='#wigglePars'><p>Wiggle parameters</p></a></li>
<li><a href='#writeAudio'><p>Write audio</p></a></li>
<li><a href='#zeroOne'><p>Normalize 0 to 1</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sound Synthesis and Acoustic Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.7.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-22</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrey Anikin &lt;andrey.anikin@cogsci.se&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://cogsci.se/soundgen.html">http://cogsci.se/soundgen.html</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Performs parametric synthesis of sounds with harmonic and noise 
    components such as animal vocalizations or human voice. Also offers tools 
    for audio manipulation and acoustic analysis, including pitch tracking, 
    spectral analysis, audio segmentation, pitch and formant shifting, etc. 
    Includes four interactive web apps for synthesizing and annotating audio, 
    manually correcting pitch contours, and measuring formant frequencies. 
    Reference: Anikin (2019) &lt;<a href="https://doi.org/10.3758%2Fs13428-018-1095-7">doi:10.3758/s13428-018-1095-7</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats (&ge; 4.0.0), graphics, utils, tuneR, seewave (&ge; 2.1.6),
zoo, mvtnorm, dtw, phonTools, signal, shiny, shinyjs, foreach,
doParallel, nonlinearTseries, data.table</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0), shinyBS</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-22 16:30:01 UTC; allgoodguys</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrey Anikin [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-22 17:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.addAM'>Add AM to a sound</h2><span id='topic+.addAM'></span>

<h3>Description</h3>

<p>Internal soundgen function, see <code><a href="#topic+addAM">addAM</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.addAM(
  audio,
  amDep = 25,
  amFreq = 30,
  amType = c("logistic", "sine")[1],
  amShape = 0,
  invalidArgAction = c("adjust", "abort", "ignore")[1],
  plot = FALSE,
  play = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".addAM_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".addAM_+3A_amdep">amDep</code></td>
<td>
<p>amplitude modulation (AM) depth, %. 0: no change; 100: AM with
amplitude range equal to the dynamic range of the sound (anchor format)</p>
</td></tr>
<tr><td><code id=".addAM_+3A_amfreq">amFreq</code></td>
<td>
<p>AM frequency, Hz (anchor format)</p>
</td></tr>
<tr><td><code id=".addAM_+3A_amtype">amType</code></td>
<td>
<p>&quot;sine&quot; = sinusoidal, &quot;logistic&quot; = logistic (default)</p>
</td></tr>
<tr><td><code id=".addAM_+3A_amshape">amShape</code></td>
<td>
<p>ignore if amType = &quot;sine&quot;, otherwise determines the shape of
non-sinusoidal AM: 0 = ~sine, -1 = notches, +1 = clicks (anchor format)</p>
</td></tr>
<tr><td><code id=".addAM_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>permittedValues</code>: 'adjust' = reset to default value, 'abort'
= stop execution, 'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
<tr><td><code id=".addAM_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the amplitude modulation</p>
</td></tr>
<tr><td><code id=".addAM_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
</table>

<hr>
<h2 id='.addFormants'>Add formants per sound</h2><span id='topic+.addFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+addFormants">addFormants</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.addFormants(
  audio,
  formants = NULL,
  spectralEnvelope = NULL,
  action = c("add", "remove")[1],
  dB = NULL,
  specificity = 1,
  zFun = NULL,
  vocalTract = NA,
  formantDep = 1,
  formantDepStoch = 1,
  formantWidth = 1,
  formantCeiling = 2,
  lipRad = 6,
  noseRad = 4,
  mouthOpenThres = 0,
  mouth = NA,
  temperature = 0.025,
  formDrift = 0.3,
  formDisp = 0.2,
  smoothing = list(),
  windowLength_points = 800,
  overlap = 75,
  dynamicRange = 120,
  normalize = c("max", "orig", "none")[1],
  play = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".addFormants_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".addFormants_+3A_formants">formants</code></td>
<td>
<p>either a character string referring to default presets for
speaker &quot;M1&quot; (implemented: &quot;aoieu0&quot;) or a list of formant times,
frequencies, amplitudes, and bandwidths (see examples). NA or NULL means no
formants, only lip radiation. Time stamps for formants and mouthOpening can
be specified in ms relative to <code>sylLen</code> or on a scale of [0, 1]. See
<code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code> for more details</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_spectralenvelope">spectralEnvelope</code></td>
<td>
<p>(optional): as an alternative to specifying formant
frequencies, we can provide the exact filter - a vector of non-negative
numbers specifying the power in each frequency bin on a linear scale
(interpolated to length equal to windowLength_points/2). A matrix
specifying the filter for each STFT step is also accepted. The easiest way
to create this matrix is to call soundgen:::getSpectralEnvelope or to use
the spectrum of a recorded sound</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_action">action</code></td>
<td>
<p>'add' = add formants to the sound, 'remove' = remove formants
(inverse filtering)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_db">dB</code></td>
<td>
<p>if NULL (default), the spectral envelope is applied on the original
scale; otherwise, it is set to range from 1 to 10 ^ (dB / 20)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_specificity">specificity</code></td>
<td>
<p>a way to sharpen or blur the spectral envelope (spectrum ^
specificity) : 1 = no change, &gt;1 = sharper, &lt;1 = blurred</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_zfun">zFun</code></td>
<td>
<p>(optional) an arbitrary function to apply to the spectrogram
prior to iSTFT, where &quot;z&quot; is the spectrogram - a matrix of complex values
(see examples)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_vocaltract">vocalTract</code></td>
<td>
<p>the length of vocal tract, cm. Used for calculating formant
dispersion (for adding extra formants) and formant transitions as the mouth
opens and closes. If <code>NULL</code> or <code>NA</code>, the length is estimated
based on specified formant frequencies, if any (anchor format)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_formantdep">formantDep</code></td>
<td>
<p>scale factor of formant amplitude (1 = no change relative
to amplitudes in <code>formants</code>)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_formantdepstoch">formantDepStoch</code></td>
<td>
<p>the amplitude of additional stochastic formants added
above the highest specified formant, dB (only if temperature &gt; 0)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_formantwidth">formantWidth</code></td>
<td>
<p>scale factor of formant bandwidth (1 = no change)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_formantceiling">formantCeiling</code></td>
<td>
<p>frequency to which stochastic formants are calculated,
in multiples of the Nyquist frequency; increase up to ~10 for long vocal
tracts to avoid losing energy in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_liprad">lipRad</code></td>
<td>
<p>the effect of lip radiation on source spectrum, dB/oct (the
default of +6 dB/oct produces a high-frequency boost when the mouth is
open)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_noserad">noseRad</code></td>
<td>
<p>the effect of radiation through the nose on source spectrum,
dB/oct (the alternative to <code>lipRad</code> when the mouth is closed)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_mouthopenthres">mouthOpenThres</code></td>
<td>
<p>open the lips (switch from nose radiation to lip
radiation) when the mouth is open <code>&gt;mouthOpenThres</code>, 0 to 1</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_mouth">mouth</code></td>
<td>
<p>mouth opening (0 to 1, 0.5 = neutral, i.e. no
modification) (anchor format)</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_formdrift">formDrift</code>, <code id=".addFormants_+3A_formdisp">formDisp</code></td>
<td>
<p>scaling factors for the effect of temperature on
formant drift and dispersal, respectively</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_smoothing">smoothing</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+getSmoothContour">getSmoothContour</a></code> to control the interpolation and smoothing
of contours: interpol (approx / spline / loess), loessSpan, discontThres,
jumpThres</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>length of FFT window, points</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_overlap">overlap</code></td>
<td>
<p>FFT window overlap, %. For allowed values, see
<code><a href="seewave.html#topic+istft">istft</a></code></p>
</td></tr>
<tr><td><code id=".addFormants_+3A_normalize">normalize</code></td>
<td>
<p>&quot;orig&quot; = same as input (default), &quot;max&quot; = maximum possible
peak amplitude, &quot;none&quot; = no normalization</p>
</td></tr>
<tr><td><code id=".addFormants_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id=".addFormants_+3A_...">...</code></td>
<td>
<p>other plotting parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='.analyze'>Analyze per sound</h2><span id='topic+.analyze'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.analyze(
  audio,
  dynamicRange = 80,
  silence = 0.04,
  windowLength = 50,
  step = windowLength/2,
  overlap = 50,
  specType = c("spectrum", "reassign", "spectralDerivative")[1],
  wn = "gaussian",
  zp = 0,
  cutFreq = NULL,
  nFormants = 3,
  formants = NULL,
  loudness = NULL,
  roughness = NULL,
  novelty = NULL,
  pitchMethods = c("dom", "autocor"),
  pitchManual_list = NULL,
  entropyThres = 0.6,
  pitchFloor = 75,
  pitchCeiling = 3500,
  priorMean = 300,
  priorSD = 6,
  priorAdapt = TRUE,
  nCands = 1,
  minVoicedCands = NULL,
  pitchDom = list(domThres = 0.1, domSmooth = 220),
  pitchAutocor = list(autocorThres = 0.7, autocorSmooth = 7, autocorUpsample = 25,
    autocorBestPeak = 0.975),
  pitchCep = list(cepThres = 0.75, cepZp = 0),
  pitchSpec = list(specThres = 0.05, specPeak = 0.25, specHNRslope = 0.8, specSmooth =
    150, specMerge = 0.1, specSinglePeakCert = 0.4, specRatios = 3),
  pitchHps = list(hpsNum = 5, hpsThres = 0.1, hpsNorm = 2, hpsPenalty = 2),
  pitchZc = list(zcThres = 0.1, zcWin = 5),
  harmHeight = list(harmThres = 3, harmTol = 0.25, harmPerSel = 5),
  subh = list(method = c("cep", "pitchCands", "harm")[1], nSubh = 5, tol = 0.05, nHarm =
    5, harmThres = 12, harmTol = 0.25, amRange = c(10, 200)),
  flux = list(thres = 0.15, smoothWin = 100),
  amRange = c(10, 200),
  fmRange = c(5, 1000/step/2),
  shortestSyl = 20,
  shortestPause = 60,
  interpol = NULL,
  pathfinding = c("none", "fast", "slow")[2],
  annealPars = list(maxit = 5000, temp = 1000),
  certWeight = 0.5,
  snakeStep = 0,
  snakePlot = FALSE,
  smooth = 1,
  smoothVars = c("pitch", "dom"),
  returnPitchCands = FALSE,
  plot = TRUE,
  showLegend = TRUE,
  osc = "linear",
  pitchPlot = list(col = rgb(0, 0, 1, 0.75), lwd = 3, showPrior = TRUE),
  pitchDom_plotPars = list(),
  pitchAutocor_plotPars = list(),
  pitchCep_plotPars = list(),
  pitchSpec_plotPars = list(),
  pitchHps_plotPars = list(),
  pitchZc_plotPars = list(),
  extraContour = NULL,
  ylim = NULL,
  xlab = NULL,
  ylab = NULL,
  main = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".analyze_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".analyze_+3A_silence">silence</code></td>
<td>
<p>(0 to 1 as proportion of max amplitude) frames with RMS
amplitude below <code>silence * max_ampl adjusted by scale</code> are not
analyzed at all.</p>
</td></tr>
<tr><td><code id=".analyze_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".analyze_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".analyze_+3A_spectype">specType</code></td>
<td>
<p>plot the original FFT ('spectrum'), reassigned spectrogram
('reassigned'), or spectral derivative ('spectralDerivative')</p>
</td></tr>
<tr><td><code id=".analyze_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id=".analyze_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id=".analyze_+3A_cutfreq">cutFreq</code></td>
<td>
<p>if specified, spectral descriptives (peakFreq, specCentroid,
specSlope, and quartiles) are calculated only between <code>cutFreq[1]</code> and
<code>cutFreq[2]</code>, Hz. If a single number is given, analyzes frequencies
from 0 to <code>cutFreq</code>. For ex., when analyzing recordings with varying
sampling rates, set to half the lowest sampling rate to make the spectra
more comparable. Note that &quot;entropyThres&quot; applies only to this frequency
range, which also affects which frames will not be analyzed with
pitchAutocor.</p>
</td></tr>
<tr><td><code id=".analyze_+3A_nformants">nFormants</code></td>
<td>
<p>the number of formants to extract per STFT frame (0 = no
formant analysis, NULL = as many as possible)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_formants">formants</code></td>
<td>
<p>a list of arguments passed to
<code><a href="phonTools.html#topic+findformants">findformants</a></code> - an external function called to
perform LPC analysis</p>
</td></tr>
<tr><td><code id=".analyze_+3A_loudness">loudness</code></td>
<td>
<p>a list of parameters passed to <code><a href="#topic+getLoudness">getLoudness</a></code> for
measuring subjective loudness, namely <code>SPL_measured, Pref,
spreadSpectrum</code>. NULL = skip loudness analysis</p>
</td></tr>
<tr><td><code id=".analyze_+3A_roughness">roughness</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code> for measuring roughness. NULL = skip
roughness analysis</p>
</td></tr>
<tr><td><code id=".analyze_+3A_novelty">novelty</code></td>
<td>
<p>a list of parameters passed to <code><a href="#topic+ssm">ssm</a></code> for measuring
spectral novelty. NULL = skip novelty analysis</p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchmethods">pitchMethods</code></td>
<td>
<p>methods of pitch estimation to consider for determining
pitch contour: 'autocor' = autocorrelation (~PRAAT), 'cep' = cepstral,
'spec' = spectral (~BaNa), 'dom' = lowest dominant frequency band, 'hps' =
harmonic product spectrum, NULL = no pitch analysis</p>
</td></tr>
<tr><td><code id=".analyze_+3A_entropythres">entropyThres</code></td>
<td>
<p>pitch tracking is only performed for frames with Weiner
entropy below <code>entropyThres</code>, but other spectral descriptives are
still calculated (NULL = analyze everything)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchfloor">pitchFloor</code>, <code id=".analyze_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_priormean">priorMean</code>, <code id=".analyze_+3A_priorsd">priorSD</code></td>
<td>
<p>specifies the mean (Hz) and standard deviation
(semitones) of gamma distribution describing our prior knowledge about the
most likely pitch values for this file. For ex., <code>priorMean = 300,
priorSD = 6</code> gives a prior with mean = 300 Hz and SD = 6 semitones (half
an octave). To avoid using any priors, set <code>priorMean = NA, priorAdapt
= FALSE</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_prioradapt">priorAdapt</code></td>
<td>
<p>adaptive second-pass prior: if TRUE, optimal pitch contours
are estimated first with a prior determined by <code>priorMean,priorSD</code>, and
then with a new prior adjusted according to this first-pass pitch contour</p>
</td></tr>
<tr><td><code id=".analyze_+3A_ncands">nCands</code></td>
<td>
<p>maximum number of pitch candidates per method, normally 1...4
(except for <code>dom</code>, which returns at most one candidate per frame)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_minvoicedcands">minVoicedCands</code></td>
<td>
<p>minimum number of pitch candidates that have to be
defined to consider a frame voiced (if NULL, defaults to 2 if <code>dom</code> is
among other candidates and 1 otherwise)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchdom">pitchDom</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
lowest dominant frequency band or &quot;dom&quot; method; see details and
<code>?soundgen:::getDom</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchautocor">pitchAutocor</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
autocorrelation or &quot;autocor&quot; method; see details and
<code>?soundgen:::getPitchAutocor</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchcep">pitchCep</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
cepstrum or &quot;cep&quot; method; see details and <code>?soundgen:::getPitchCep</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchspec">pitchSpec</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
BaNa or &quot;spec&quot; method; see details and <code>?soundgen:::getPitchSpec</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchhps">pitchHps</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
harmonic product spectrum or &quot;hps&quot; method; see details and
<code>?soundgen:::getPitchHps</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchzc">pitchZc</code></td>
<td>
<p>a list of control parameters for pitch tracking based on zero
crossings in bandpass-filtered audio or &quot;zc&quot; method; see
<code><a href="#topic+getPitchZc">getPitchZc</a></code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_harmheight">harmHeight</code></td>
<td>
<p>a list of control parameters for estimating how high
harmonics reach in the spectrum; see details and <code>?soundgen:::harmHeight</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_subh">subh</code></td>
<td>
<p>a list of control parameters for estimating the strength of
subharmonics per frame - that is, spectral energy at integer ratios of f0:
see <code>?soundgen:::getSHR</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_flux">flux</code></td>
<td>
<p>a list of control parameters for calculating feature-based flux
(not spectral flux) passed to <code><a href="#topic+getFeatureFlux">getFeatureFlux</a></code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_amrange">amRange</code></td>
<td>
<p>target range of frequencies for amplitude modulation, Hz: a
vector of length 2 (affects both <code>amMsFreq</code> and <code>amEnvFreq</code>)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_fmrange">fmRange</code></td>
<td>
<p>target range of frequencies for analyzing frequency
modulation, Hz (<code>fmFreq</code>): a vector of length 2</p>
</td></tr>
<tr><td><code id=".analyze_+3A_shortestsyl">shortestSyl</code></td>
<td>
<p>the smallest length of a voiced segment (ms) that
constitutes a voiced syllable (shorter segments will be replaced by NA, as
if unvoiced)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_shortestpause">shortestPause</code></td>
<td>
<p>the smallest gap between voiced syllables (ms): large
value = interpolate and merge, small value = treat as separate syllables
separated by an unvoiced gap</p>
</td></tr>
<tr><td><code id=".analyze_+3A_interpol">interpol</code></td>
<td>
<p>a list of parameters (currently <code>win, tol, cert</code>) passed
to <code>soundgen:::pathfinder</code> for interpolating missing pitch candidates
(NULL = no interpolation)</p>
</td></tr>
<tr><td><code id=".analyze_+3A_pathfinding">pathfinding</code></td>
<td>
<p>method of finding the optimal path through pitch
candidates: 'none' = best candidate per frame, 'fast' = simple heuristic,
'slow' = annealing. See <code>soundgen:::pathfinder</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_annealpars">annealPars</code></td>
<td>
<p>a list of control parameters for postprocessing of
pitch contour with SANN algorithm of <code><a href="stats.html#topic+optim">optim</a></code>. This is
only relevant if <code>pathfinding = 'slow'</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id=".analyze_+3A_snakestep">snakeStep</code></td>
<td>
<p>optimized path through pitch candidates is further
processed to minimize the elastic force acting on pitch contour. To
disable, set <code>snakeStep = 0</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_snakeplot">snakePlot</code></td>
<td>
<p>if TRUE, plots the snake</p>
</td></tr>
<tr><td><code id=".analyze_+3A_smooth">smooth</code>, <code id=".analyze_+3A_smoothvars">smoothVars</code></td>
<td>
<p>if <code>smooth</code> is a positive number, outliers of
the variables in <code>smoothVars</code> are adjusted with median smoothing.
<code>smooth</code> of 1 corresponds to a window of ~100 ms and tolerated
deviation of ~4 semitones. To disable, set <code>smooth = 0</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a spectrogram with pitch contour overlaid</p>
</td></tr>
<tr><td><code id=".analyze_+3A_showlegend">showLegend</code></td>
<td>
<p>if TRUE, adds a legend with pitch tracking methods</p>
</td></tr>
<tr><td><code id=".analyze_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id=".analyze_+3A_pitchplot">pitchPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the final
pitch contour. Set to <code>list(type = 'n')</code> to suppress</p>
</td></tr>
<tr><td><code id=".analyze_+3A_extracontour">extraContour</code></td>
<td>
<p>name of an output variable to overlap on the pitch
contour plot, eg 'peakFreq' or 'loudness'; can also be a list with extra
graphical parameters, eg <code>extraContour = list(x = 'harmHeight', col =
'red')</code></p>
</td></tr>
<tr><td><code id=".analyze_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id=".analyze_+3A_xlab">xlab</code>, <code id=".analyze_+3A_ylab">ylab</code>, <code id=".analyze_+3A_main">main</code></td>
<td>
<p>plotting parameters</p>
</td></tr>
<tr><td><code id=".analyze_+3A_width">width</code>, <code id=".analyze_+3A_height">height</code>, <code id=".analyze_+3A_units">units</code>, <code id=".analyze_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
<tr><td><code id=".analyze_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Called by <code><a href="#topic+analyze">analyze</a></code> and <code><a href="#topic+pitch_app">pitch_app</a></code> to analyze a
single sound.
</p>

<hr>
<h2 id='.audSpectrogram'>Auditory spectrogram per sound</h2><span id='topic+.audSpectrogram'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.audSpectrogram(
  audio,
  step = 1,
  dynamicRange = 80,
  filterType = c("butterworth", "chebyshev", "gammatone")[1],
  nFilters = 128,
  nFilters_oct = NULL,
  filterOrder = if (filterType == "gammatone") 4 else 3,
  bandwidth = NULL,
  bandwidthMult = 1,
  minFreq = 20,
  maxFreq = audio$samplingRate/2,
  minBandwidth = 10,
  output = c("audSpec", "audSpec_processed", "filterbank", "filterbank_env", "roughness"),
  plot = TRUE,
  plotFilters = FALSE,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  yScale = "bark",
  contrast = 0.2,
  brightness = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".audSpectrogram_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_step">step</code></td>
<td>
<p>step, ms (determines time resolution of the plot, but not of the
returned envelopes per channel). step = NULL means no downsampling at all
(ncol of output = length of input audio)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_filtertype">filterType</code></td>
<td>
<p>&quot;butterworth&quot; = Butterworth filter
<code><a href="signal.html#topic+butter">butter</a></code>, &quot;chebyshev&quot; = Chebyshev filter
<code><a href="signal.html#topic+butter">butter</a></code>, &quot;gammatone&quot; =
<code><a href="seewave.html#topic+gammatone">gammatone</a></code></p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_nfilters">nFilters</code></td>
<td>
<p>the number of filters between <code>minFreq</code> and
<code>maxFreq</code> (determines frequency resolution, while <code>yScale</code>
determines the location of center frequencies)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_nfilters_oct">nFilters_oct</code></td>
<td>
<p>an alternative way to specify frequency resolution: the
number of filters per octave</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_filterorder">filterOrder</code></td>
<td>
<p>filter order (defaults to 4 for gammatones, 3 otherwise)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_bandwidth">bandwidth</code></td>
<td>
<p>filter bandwidth, octaves. If NULL, defaults to ERB
bandwidths as in <code><a href="seewave.html#topic+gammatone">gammatone</a></code></p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_bandwidthmult">bandwidthMult</code></td>
<td>
<p>a scaling factor for all bandwidths (1 = no effect)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_minfreq">minFreq</code>, <code id=".audSpectrogram_+3A_maxfreq">maxFreq</code></td>
<td>
<p>the range of frequencies to analyze. If the
spectrogram looks empty, try increasing minFreq - the lowest filters are
prone to returning very large values</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_minbandwidth">minBandwidth</code></td>
<td>
<p>minimum filter bandwidth, Hz (otherwise filters may
become too narrow when nFilters is high; has no effect if filterType =
'gammatone')</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_output">output</code></td>
<td>
<p>a list of measures to return. Defaults to everything, but this
takes a lot of RAM, so shorten to what's needed if analyzing many files at
once</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_plotfilters">plotFilters</code></td>
<td>
<p>if TRUE, plots the filters as central frequencies Â±
bandwidth/2</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_yscale">yScale</code></td>
<td>
<p>determines the location of center frequencies of the filters</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_xlab">xlab</code>, <code id=".audSpectrogram_+3A_ylab">ylab</code>, <code id=".audSpectrogram_+3A_main">main</code>, <code id=".audSpectrogram_+3A_mar">mar</code>, <code id=".audSpectrogram_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_width">width</code>, <code id=".audSpectrogram_+3A_height">height</code>, <code id=".audSpectrogram_+3A_units">units</code>, <code id=".audSpectrogram_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".audSpectrogram_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.bandpass'>Bandpass filter per sound</h2><span id='topic+.bandpass'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.bandpass(
  audio,
  lwr = NULL,
  upr = NULL,
  action = c("pass", "stop")[1],
  dB = Inf,
  bw = 0,
  na.rm = TRUE,
  normalize = FALSE,
  plot = FALSE,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".bandpass_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".bandpass_+3A_lwr">lwr</code>, <code id=".bandpass_+3A_upr">upr</code></td>
<td>
<p>cutoff frequencies, Hz. Specifying just lwr gives a high-pass
filter, just upr low-pass filter with action = 'pass' (or vice versa with
action = 'stop'). Specifying both lwr and upr a bandpass/bandstop filter,
depending on 'action'</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_action">action</code></td>
<td>
<p>&quot;pass&quot; = preserve the selected frequency range (bandpass),
&quot;stop&quot; = remove the selected frequency range (bandstop)</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_db">dB</code></td>
<td>
<p>a positive number giving the strength of effect in dB (defaults to
Inf - complete removal of selected frequencies)</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_bw">bw</code></td>
<td>
<p>bandwidth of the filter cutoffs, Hz. Defaults to 0 (abrupt, step
function), a positive number corresponds to the standard deviation of a
Gaussian curve, and two numbers set different bandwidths for the lower and
upper cutoff points</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_na.rm">na.rm</code></td>
<td>
<p>if TRUE, NAs are interpolated, otherwise they are preserved in
the output</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, resets the output to the original scale (otherwise
filtering often reduces the amplitude)</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".bandpass_+3A_width">width</code>, <code id=".bandpass_+3A_height">height</code>, <code id=".bandpass_+3A_units">units</code>, <code id=".bandpass_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".bandpass_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to <code>plot()</code> as well as to
<code><a href="seewave.html#topic+meanspec">meanspec</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='.detectNLP'>Detect NLP per sound</h2><span id='topic+.detectNLP'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+detectNLP">detectNLP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.detectNLP(
  audio,
  predictors = c("nPeaks", "d2", "subDep", "amEnvDep", "entropy", "HNR", "CPP",
    "roughness"),
  thresProb = 0.4,
  unvoicedToNone = FALSE,
  train = soundgen::detectNLP_training_nonv,
  scale = NULL,
  from = NULL,
  to = NULL,
  pitchManual_list = NULL,
  pars_analyze = list(windowLength = 50, roughness = list(windowLength = 15, step = 3),
    plot = FALSE),
  pars_phasegram = list(nonlinStats = "d2"),
  pars_naiveBayes = list(prior = "static", wlClumper = 3),
  jumpThres = 14,
  jumpWindow = 100,
  plot = FALSE,
  savePlots = NULL,
  main = NULL,
  xlab = NULL,
  ylab = NULL,
  type = "b",
  ylim = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".detectNLP_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_from">from</code>, <code id=".detectNLP_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plot a contour of RMS amplitude</p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_xlab">xlab</code>, <code id=".detectNLP_+3A_ylab">ylab</code>, <code id=".detectNLP_+3A_main">main</code></td>
<td>
<p>general graphical parameters</p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_width">width</code>, <code id=".detectNLP_+3A_height">height</code>, <code id=".detectNLP_+3A_units">units</code>, <code id=".detectNLP_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".detectNLP_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.fade'>Fade per sound</h2><span id='topic+.fade'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fade(
  audio,
  fadeIn = 1000,
  fadeOut = 1000,
  fadeIn_points = NULL,
  fadeOut_points = NULL,
  samplingRate = NULL,
  shape = c("lin", "exp", "log", "cos", "logistic", "gaussian")[1],
  steepness = 1,
  plot = FALSE,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".fade_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".fade_+3A_fadein">fadeIn</code>, <code id=".fade_+3A_fadeout">fadeOut</code></td>
<td>
<p>length of segments for fading in and out, ms (0 = no
fade)</p>
</td></tr>
<tr><td><code id=".fade_+3A_fadein_points">fadeIn_points</code>, <code id=".fade_+3A_fadeout_points">fadeOut_points</code></td>
<td>
<p>length of segments for fading in and out,
points (if specified, override <code>fadeIn/fadeOut</code>)</p>
</td></tr>
<tr><td><code id=".fade_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id=".fade_+3A_shape">shape</code></td>
<td>
<p>controls the type of fade function: 'lin' = linear, 'exp' =
exponential, 'log' = logarithmic, 'cos' = cosine, 'logistic' = logistic
S-curve</p>
</td></tr>
<tr><td><code id=".fade_+3A_steepness">steepness</code></td>
<td>
<p>scaling factor regulating the steepness of fading curves
(except for shapes 'lin' and 'cos'): 0 = linear, &gt;1 = steeper than default</p>
</td></tr>
<tr><td><code id=".fade_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces an oscillogram of the waveform after fading</p>
</td></tr>
<tr><td><code id=".fade_+3A_width">width</code>, <code id=".fade_+3A_height">height</code>, <code id=".fade_+3A_units">units</code>, <code id=".fade_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".fade_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.filterSoundByMS'>Filter a single sound by MS</h2><span id='topic+.filterSoundByMS'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.filterSoundByMS(
  audio,
  logSpec = FALSE,
  windowLength = 25,
  step = NULL,
  overlap = 80,
  wn = "hamming",
  zp = 0,
  amCond = NULL,
  fmCond = NULL,
  jointCond = NULL,
  action = c("remove", "preserve")[1],
  initialPhase = c("zero", "random", "spsi")[3],
  nIter = 50,
  play = FALSE,
  plot = TRUE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".filterSoundByMS_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, the spectrogram is log-transformed prior to taking 2D
FFT</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_windowlength">windowLength</code>, <code id=".filterSoundByMS_+3A_step">step</code>, <code id=".filterSoundByMS_+3A_wn">wn</code>, <code id=".filterSoundByMS_+3A_zp">zp</code></td>
<td>
<p>parameters for extracting a spectrogram if
<code>specType = 'STFT'</code>. Window length and step are specified in ms (see
<code><a href="#topic+spectrogram">spectrogram</a></code>). If <code>specType = 'audSpec'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_amcond">amCond</code>, <code id=".filterSoundByMS_+3A_fmcond">fmCond</code></td>
<td>
<p>character strings with valid conditions on amplitude and
frequency modulation (see examples)</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_jointcond">jointCond</code></td>
<td>
<p>character string with a valid joint condition amplitude and
frequency modulation</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_action">action</code></td>
<td>
<p>should the defined AM-FM region be removed ('remove') or
preserved, while everything else is removed ('preserve')?</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_initialphase">initialPhase</code></td>
<td>
<p>initial phase estimate: &quot;zero&quot; = set all phases to zero;
&quot;random&quot; = Gaussian noise; &quot;spsi&quot; (default) = single-pass spectrogram
inversion (Beauregard et al., 2015)</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_niter">nIter</code></td>
<td>
<p>the number of iterations of the GL algorithm (Griffin &amp; Lim,
1984), 0 = don't run</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_play">play</code></td>
<td>
<p>if TRUE, plays back the reconstructed audio</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a triple plot: original MS, filtered MS, and
the MS of the output sound</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_saveplots">savePlots</code></td>
<td>
<p>if a valid path is specified, a plot is saved in this folder
(defaults to NA)</p>
</td></tr>
<tr><td><code id=".filterSoundByMS_+3A_width">width</code>, <code id=".filterSoundByMS_+3A_height">height</code>, <code id=".filterSoundByMS_+3A_units">units</code>, <code id=".filterSoundByMS_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
</table>

<hr>
<h2 id='.flatEnv'>Flat envelope per sound</h2><span id='topic+.flatEnv'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.flatEnv(
  audio,
  compression = 1,
  method = c("hil", "rms", "peak")[1],
  windowLength = 50,
  windowLength_points = NULL,
  killDC = FALSE,
  dynamicRange = 40,
  plot = FALSE,
  col = "blue",
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".flatEnv_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_compression">compression</code></td>
<td>
<p>the amount of compression to apply: 0 = none, 1 = maximum</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_method">method</code></td>
<td>
<p>hil = Hilbert envelope, rms = root mean square amplitude, peak
= peak amplitude per window</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_windowlength">windowLength</code></td>
<td>
<p>the length of smoothing window, ms</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>the length of smoothing window, points. If
specified, overrides <code>windowLength</code></p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_killdc">killDC</code></td>
<td>
<p>if TRUE, dynamically removes DC offset or similar deviations of
average waveform from zero (see examples)</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>parts of sound quieter than <code>-dynamicRange</code> dB will
not be amplified</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original sound, the smoothed envelope, and
the compressed sound</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_col">col</code></td>
<td>
<p>the color of amplitude contours</p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_width">width</code>, <code id=".flatEnv_+3A_height">height</code>, <code id=".flatEnv_+3A_units">units</code>, <code id=".flatEnv_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".flatEnv_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to <code>points()</code> that control
the appearance of amplitude contours, eg <code>lwd, lty</code>, etc.</p>
</td></tr>
</table>

<hr>
<h2 id='.flatSpectrum'>Flat spectrum per sound</h2><span id='topic+.flatSpectrum'></span>

<h3>Description</h3>

<p>Internal soundgen function, see <code><a href="#topic+flatSpectrum">flatSpectrum</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.flatSpectrum(
  audio,
  freqWindow = NULL,
  samplingRate = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = NULL,
  overlap = 90,
  wn = "gaussian",
  zp = 0,
  play = FALSE,
  saveAudio = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".flatSpectrum_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of smoothing window, Hz. Defaults to median
pitch estimated by <code><a href="#topic+analyze">analyze</a></code></p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
<tr><td><code id=".flatSpectrum_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full (!) path to folder for saving the processed audio; NULL
= don't save, &rdquo; = same as input folder (NB: overwrites the originals!)</p>
</td></tr>
</table>

<hr>
<h2 id='.getDuration'>Get duration per sound</h2><span id='topic+.getDuration'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+getDuration">getDuration</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.getDuration(audio, silence = 0.01, rms = list(windowLength = 20, step = 5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".getDuration_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".getDuration_+3A_silence">silence</code></td>
<td>
<p>leading and trailing sections quieter than this proportion of
maximum RMS amplitude are removed when calculating
<code>duration_noSilence</code> (NULL = don't calculate <code>duration_noSilence</code>
to save time)</p>
</td></tr>
<tr><td><code id=".getDuration_+3A_rms">rms</code></td>
<td>
<p>a list of control parameters passed to <code><a href="#topic+getRMS">getRMS</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='.getLoudness'>Loudness per sound</h2><span id='topic+.getLoudness'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.getLoudness(
  audio,
  windowLength = 50,
  step = NULL,
  overlap = 50,
  SPL_measured = 70,
  Pref = 2e-05,
  spreadSpectrum = TRUE,
  plot = TRUE,
  savePlots = NULL,
  main = NULL,
  ylim = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  mar = c(5.1, 4.1, 4.1, 4.1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".getLoudness_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_spl_measured">SPL_measured</code></td>
<td>
<p>sound pressure level at which the sound is presented, dB</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_pref">Pref</code></td>
<td>
<p>reference pressure, Pa (currently has no effect on the estimate)</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_spreadspectrum">spreadSpectrum</code></td>
<td>
<p>if TRUE, applies a spreading function to account for
frequency masking</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_width">width</code>, <code id=".getLoudness_+3A_height">height</code>, <code id=".getLoudness_+3A_units">units</code>, <code id=".getLoudness_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_mar">mar</code></td>
<td>
<p>margins of the spectrogram</p>
</td></tr>
<tr><td><code id=".getLoudness_+3A_...">...</code></td>
<td>
<p>other plotting parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='.getPitchZc'>Zero-crossing rate per sound</h2><span id='topic+.getPitchZc'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+getPitchZc">getPitchZc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.getPitchZc(
  audio,
  pitchFloor,
  pitchCeiling,
  zcThres,
  zcWin = 5,
  silence = 0.04,
  env = NULL,
  envWin = 5,
  certMethod = c("autocor", "variab")[2]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".getPitchZc_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_pitchfloor">pitchFloor</code>, <code id=".getPitchZc_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_zcthres">zcThres</code></td>
<td>
<p>pitch candidates with certainty below this value are treated
as noise and set to NA (0 = anything goes, 1 = pitch must be perfectly
stable over <code>zcWin</code>)</p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_zcwin">zcWin</code></td>
<td>
<p>certainty in pitch candidates depends on how stable pitch is
over <code>zcWin</code> glottal cycles (odd integer &gt; 3)</p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_silence">silence</code></td>
<td>
<p>minimum root mean square (RMS) amplitude, below which pitch
candidates are set to NA (NULL = don't consider RMS amplitude)</p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_env">env</code></td>
<td>
<p>precalculated envelope (when called internally by .analyze())</p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_envwin">envWin</code></td>
<td>
<p>window length for calculating RMS envelope, ms</p>
</td></tr>
<tr><td><code id=".getPitchZc_+3A_certmethod">certMethod</code></td>
<td>
<p>method of calculating pitch certainty: 'autocor' =
autocorrelation of pitch estimates per zc over window (a measure of curve
smoothness), 'variab' = variability of pitch estimates per zc over window</p>
</td></tr>
</table>

<hr>
<h2 id='.getRMS'>RMS amplitude per sound</h2><span id='topic+.getRMS'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+getRMS">getRMS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.getRMS(
  audio,
  windowLength = 50,
  step = NULL,
  overlap = 75,
  stereo = c("left", "right", "average", "both")[1],
  killDC = FALSE,
  normalize = TRUE,
  windowDC = 200,
  plot = TRUE,
  main = NULL,
  xlab = "",
  ylab = "",
  type = "b",
  col = "green",
  lwd = 2,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".getRMS_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".getRMS_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_stereo">stereo</code></td>
<td>
<p>'left' = only left channel, 'right' = only right channel,
'average' = take the mean of the two channels, 'both' = return RMS for both
channels separately</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_killdc">killDC</code></td>
<td>
<p>if TRUE, removed DC offset (see also <code><a href="#topic+flatEnv">flatEnv</a></code>)</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, the RMS amplitude is returned as proportion of
the maximum possible amplitude as given by <code>scale</code></p>
</td></tr>
<tr><td><code id=".getRMS_+3A_windowdc">windowDC</code></td>
<td>
<p>the window for calculating DC offset, ms</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plot a contour of RMS amplitude</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_xlab">xlab</code>, <code id=".getRMS_+3A_ylab">ylab</code>, <code id=".getRMS_+3A_main">main</code></td>
<td>
<p>general graphical parameters</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_type">type</code>, <code id=".getRMS_+3A_col">col</code>, <code id=".getRMS_+3A_lwd">lwd</code></td>
<td>
<p>graphical parameters pertaining to the RMS envelope</p>
</td></tr>
<tr><td><code id=".getRMS_+3A_width">width</code>, <code id=".getRMS_+3A_height">height</code>, <code id=".getRMS_+3A_units">units</code>, <code id=".getRMS_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".getRMS_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.getSurprisal'>Get surprisal per sound</h2><span id='topic+.getSurprisal'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+getSurprisal">getSurprisal</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.getSurprisal(
  audio,
  winSurp,
  audSpec_pars = list(filterType = "butterworth", nFilters = 64, step = 20),
  method = c("acf", "np")[1],
  plot = TRUE,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  contrast = 0.2,
  brightness = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".getSurprisal_+3A_winsurp">winSurp</code></td>
<td>
<p>surprisal analysis window, ms (Inf = from sound onset to each
point)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_audspec_pars">audSpec_pars</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+audSpectrogram">audSpectrogram</a></code></p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_method">method</code></td>
<td>
<p>acf = change in maximum autocorrelation after adding the final
point, np = nonlinear prediction (see <code><a href="#topic+nonlinPred">nonlinPred</a></code>)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the auditory spectrogram and the
<code>suprisalLoudness</code> contour</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_xlab">xlab</code>, <code id=".getSurprisal_+3A_ylab">ylab</code>, <code id=".getSurprisal_+3A_main">main</code>, <code id=".getSurprisal_+3A_mar">mar</code>, <code id=".getSurprisal_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_width">width</code>, <code id=".getSurprisal_+3A_height">height</code>, <code id=".getSurprisal_+3A_units">units</code>, <code id=".getSurprisal_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".getSurprisal_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.modulationSpectrum'>Modulation spectrum per sound</h2><span id='topic+.modulationSpectrum'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.modulationSpectrum(
  audio,
  specSource = c("STFT", "audSpec")[1],
  windowLength = 15,
  step = 1,
  wn = "hanning",
  zp = 0,
  audSpec_pars = list(filterType = "butterworth", nFilters = 32, bandwidth = 1/24, yScale
    = "bark", dynamicRange = 120),
  msType = c("1D", "2D")[2],
  amRes = 5,
  maxDur = 5,
  specMethod = c("spec", "meanspec")[2],
  logSpec = FALSE,
  logMPS = FALSE,
  power = 1,
  normalize = TRUE,
  roughRange = c(30, 150),
  roughMean = NULL,
  roughSD = NULL,
  roughMinFreq = 1,
  amRange = c(10, 200),
  returnMS = TRUE,
  returnComplex = FALSE,
  plot = TRUE,
  savePlots = NULL,
  logWarpX = NULL,
  logWarpY = NULL,
  quantiles = c(0.5, 0.8, 0.9),
  kernelSize = 5,
  kernelSD = 0.5,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  main = NULL,
  xlab = "Hz",
  ylab = "1/kHz",
  xlim = NULL,
  ylim = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".modulationSpectrum_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_specsource">specSource</code></td>
<td>
<p>'STFT' = Short-Time Fourier Transform; 'audSpec' = a bank
of bandpass filters (see <code><a href="#topic+audSpectrogram">audSpectrogram</a></code>)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_windowlength">windowLength</code>, <code id=".modulationSpectrum_+3A_step">step</code>, <code id=".modulationSpectrum_+3A_wn">wn</code>, <code id=".modulationSpectrum_+3A_zp">zp</code></td>
<td>
<p>parameters for extracting a spectrogram if
<code>specType = 'STFT'</code>. Window length and step are specified in ms (see
<code><a href="#topic+spectrogram">spectrogram</a></code>). If <code>specType = 'audSpec'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_audspec_pars">audSpec_pars</code></td>
<td>
<p>parameters for extracting an auditory spectrogram if
<code>specType = 'audSpec'</code>. If <code>specType = 'STFT'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_mstype">msType</code></td>
<td>
<p>'2D' = two-dimensional Fourier transform of a spectrogram; '1D'
= separately calculated spectrum of each frequency band</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_amres">amRes</code></td>
<td>
<p>target resolution of amplitude modulation, Hz. If <code>NULL</code>,
the entire sound is analyzed at once, resulting in a single roughness value
(unless it is longer than <code>maxDur</code>, in which case it is analyzed in
chunks <code>maxDur</code> s long). If <code>amRes</code> is set, roughness is
calculated for windows <code>~1000/amRes</code> ms long (but at least 3 STFT
frames). <code>amRes</code> also affects the amount of smoothing when calculating
<code>amMsFreq</code> and <code>amMsPurity</code></p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_maxdur">maxDur</code></td>
<td>
<p>sounds longer than <code>maxDur</code> s are split into fragments,
and the modulation spectra of all fragments are averaged</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_specmethod">specMethod</code></td>
<td>
<p>the function to call when calculating the spectrum of each
frequency band (only used when <code>msType = '1D'</code>); 'meanspec' is faster
and less noisy, whereas 'spec' produces higher resolution</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, the spectrogram is log-transformed prior to taking 2D
FFT</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_logmps">logMPS</code></td>
<td>
<p>if TRUE, the modulation spectrum is log-transformed prior to
calculating roughness</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_power">power</code></td>
<td>
<p>raise modulation spectrum to this power (eg power = 2 for ^2, or
&quot;power spectrum&quot;)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, the modulation spectrum of each analyzed fragment
<code>maxDur</code> in duration is separately normalized to have max = 1</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_roughrange">roughRange</code></td>
<td>
<p>the range of temporal modulation frequencies that
constitute the &quot;roughness&quot; zone, Hz</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_roughmean">roughMean</code>, <code id=".modulationSpectrum_+3A_roughsd">roughSD</code></td>
<td>
<p>the mean (Hz) and standard deviation (semitones) of
a lognormal distribution used to weight roughness estimates. If either is
null, roughness is calculated simply as the proportion of spectrum within
<code>roughRange</code>. If both <code>roughMean</code> and <code>roughRange</code> are
defined, weights outside <code>roughRange</code> are set to 0; a very large SD (a
flat weighting function) gives the same result as just <code>roughRange</code>
without any weighting (see examples)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_roughminfreq">roughMinFreq</code></td>
<td>
<p>frequencies below roughMinFreq (Hz) are ignored when
calculating roughness (ie the estimated roughness increases if we disregard
very low-frequency modulation, which is often strong)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_amrange">amRange</code></td>
<td>
<p>the range of temporal modulation frequencies that we are
interested in as &quot;amplitude modulation&quot; (AM), Hz</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_returnms">returnMS</code></td>
<td>
<p>if FALSE, only roughness is returned (much faster). Careful
with exporting the modulation spectra of a lot of sounds at once as this
requires a lot of RAM</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_returncomplex">returnComplex</code></td>
<td>
<p>if TRUE, returns a complex modulation spectrum (without
normalization and warping)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the modulation spectrum of each sound (see
<code><a href="#topic+plotMS">plotMS</a></code>)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_saveplots">savePlots</code></td>
<td>
<p>if a valid path is specified, a plot is saved in this folder
(defaults to NA)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_logwarpx">logWarpX</code>, <code id=".modulationSpectrum_+3A_logwarpy">logWarpY</code></td>
<td>
<p>numeric vector of length 2: c(sigma, base) of
pseudolog-warping the modulation spectrum, as in function
pseudo_log_trans() from the &quot;scales&quot; package</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_quantiles">quantiles</code></td>
<td>
<p>labeled contour values, % (e.g., &quot;50&quot; marks regions that
contain 50% of the sum total of the entire modulation spectrum)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_kernelsize">kernelSize</code></td>
<td>
<p>the size of Gaussian kernel used for smoothing (1 = no
smoothing)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_kernelsd">kernelSD</code></td>
<td>
<p>the SD of Gaussian kernel used for smoothing, relative to its
size</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_xlab">xlab</code>, <code id=".modulationSpectrum_+3A_ylab">ylab</code>, <code id=".modulationSpectrum_+3A_main">main</code>, <code id=".modulationSpectrum_+3A_xlim">xlim</code>, <code id=".modulationSpectrum_+3A_ylim">ylim</code></td>
<td>
<p>graphical parameters</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_width">width</code>, <code id=".modulationSpectrum_+3A_height">height</code>, <code id=".modulationSpectrum_+3A_units">units</code>, <code id=".modulationSpectrum_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
<tr><td><code id=".modulationSpectrum_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed on to <code>filled.contour.mod</code>
and <code><a href="graphics.html#topic+contour">contour</a></code> (see <code><a href="#topic+spectrogram">spectrogram</a></code>)</p>
</td></tr>
</table>

<hr>
<h2 id='.osc'>Oscillogram per sound</h2><span id='topic+.osc'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+osc">osc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.osc(
  audio,
  dynamicRange = 80,
  dB = FALSE,
  returnWave = FALSE,
  plot = TRUE,
  main = NULL,
  xlab = NULL,
  ylab = NULL,
  ylim = NULL,
  bty = "n",
  midline = TRUE,
  maxPoints = 10000,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".osc_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".osc_+3A_db">dB</code></td>
<td>
<p>if TRUE, plots on a dB instead of linear scale</p>
</td></tr>
<tr><td><code id=".osc_+3A_returnwave">returnWave</code></td>
<td>
<p>if TRUE, returns a log-transformed waveform as a numeric vector</p>
</td></tr>
<tr><td><code id=".osc_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the oscillogram</p>
</td></tr>
<tr><td><code id=".osc_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id=".osc_+3A_xlab">xlab</code>, <code id=".osc_+3A_ylab">ylab</code></td>
<td>
<p>axis labels</p>
</td></tr>
<tr><td><code id=".osc_+3A_ylim">ylim</code></td>
<td>
<p>override default amplitude scale for non-centered sounds</p>
</td></tr>
<tr><td><code id=".osc_+3A_bty">bty</code></td>
<td>
<p>box type (see '?par')</p>
</td></tr>
<tr><td><code id=".osc_+3A_midline">midline</code></td>
<td>
<p>if TRUE, draws a line at 0 dB</p>
</td></tr>
<tr><td><code id=".osc_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of points to plot (speeds up the plotting
of long audio files, but beware of antialiasing)</p>
</td></tr>
<tr><td><code id=".osc_+3A_width">width</code>, <code id=".osc_+3A_height">height</code>, <code id=".osc_+3A_units">units</code>, <code id=".osc_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".osc_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed on to 'plot()'</p>
</td></tr>
</table>

<hr>
<h2 id='.phasegram'>Phasegram per sound</h2><span id='topic+.phasegram'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+phasegram">phasegram</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.phasegram(
  audio,
  windowLength = 10,
  step = windowLength/2,
  timeLag = NULL,
  theilerWindow = NULL,
  nonlinStats = c("ed", "d2", "ml", "sur"),
  pars_ed = list(max.embedding.dim = 15),
  pars_d2 = list(min.embedding.dim = 2, min.radius = 0.001, n.points.radius = 20),
  pars_ml = list(min.embedding.dim = 2, radius = 0.001),
  pars_sur = list(FUN = nonlinearTseries::timeAsymmetry, K = 1),
  bw = 0.01,
  bins = 5/bw,
  plot = TRUE,
  rasterize = FALSE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  xlab = "Time",
  ylab = "",
  main = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".phasegram_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_windowlength">windowLength</code></td>
<td>
<p>the length of each frame analyzed separately (ms)</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_step">step</code></td>
<td>
<p>time step between consecutive frames (ms)</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_timelag">timeLag</code></td>
<td>
<p>time lag between the original and time-shifted version of each
frame that together represent the phase portrait (ms). Defaults to the
number of steps beyond which the mutual information function reaches its
minimum or, if that fails, the steps until mutual information experiences
the first exponential decay - see <code><a href="nonlinearTseries.html#topic+timeLag">timeLag</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_theilerwindow">theilerWindow</code></td>
<td>
<p>time lag between two points that are considered locally
independent and can be treated as neighbors in the reconstructed phase
space. defaults to the first minimum or, if unavailable, the first zero of
the autocorrelation function (or, failing that, to <code>timeLag * 2</code>)</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_nonlinstats">nonlinStats</code></td>
<td>
<p>nonlinear statistics to report: &quot;ed&quot; = the optimal number
of embedding dimensions, &quot;d2&quot; = correlation dimension D2, &quot;ml&quot; = maximum
Lyapunov exponent, &quot;sur&quot; = the results of surrogate data testing for
stochasticity. These are calculated using the functionality of the package
nonlinearTseries, which is seriously slow, so the default is just to get
the phasegram itself</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_pars_ed">pars_ed</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+estimateEmbeddingDim">estimateEmbeddingDim</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_pars_d2">pars_d2</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+corrDim">corrDim</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_pars_ml">pars_ml</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+maxLyapunov">maxLyapunov</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_pars_sur">pars_sur</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+surrogateTest">surrogateTest</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_bw">bw</code></td>
<td>
<p>standard deviation of the smoothing kernel, as in
<code><a href="stats.html#topic+density">density</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_bins">bins</code></td>
<td>
<p>the number of bins along the Y axis after rasterizing (has no
effect if <code>rasterize = FALSE</code>)</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_rasterize">rasterize</code></td>
<td>
<p>if FALSE, only plots and returns Poincare sections on the
original scale (most graphical parameters will then have no effect); if
TRUE, rasterizes the phasegram matrix and plots it with more graphical
parameters</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_xlab">xlab</code>, <code id=".phasegram_+3A_ylab">ylab</code>, <code id=".phasegram_+3A_main">main</code></td>
<td>
<p>graphical parameters passed to
soundgen:::filled.contour.mod (if <code>rasterize = TRUE</code>) or plot (if
<code>rasterize = FALSE</code>)</p>
</td></tr>
<tr><td><code id=".phasegram_+3A_width">width</code>, <code id=".phasegram_+3A_height">height</code>, <code id=".phasegram_+3A_units">units</code>, <code id=".phasegram_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".phasegram_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to soundgen:::filled.contour.mod
(if <code>rasterize = TRUE</code>)  or plot (if <code>rasterize = FALSE</code>)</p>
</td></tr>
</table>

<hr>
<h2 id='.pitchDescriptives'>Pitch descriptives per file</h2><span id='topic+.pitchDescriptives'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.pitchDescriptives(
  time,
  pitch,
  smoothBW,
  inflThres,
  extraSummaryFun = c(),
  ref = 16.35,
  plot = FALSE,
  main = ""
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".pitchDescriptives_+3A_time">time</code></td>
<td>
<p>a vector of time stamps in s</p>
</td></tr>
<tr><td><code id=".pitchDescriptives_+3A_pitch">pitch</code></td>
<td>
<p>a vector of pitch values in Hz</p>
</td></tr>
<tr><td><code id=".pitchDescriptives_+3A_smoothbw">smoothBW</code></td>
<td>
<p>a vector of bandwidths (Hz) for consecutive smoothing of
input using <code><a href="#topic+pitchSmoothPraat">pitchSmoothPraat</a></code>; NA = no smoothing</p>
</td></tr>
<tr><td><code id=".pitchDescriptives_+3A_inflthres">inflThres</code></td>
<td>
<p>minimum difference (in semitones) between consecutive
extrema to consider them inflections; to apply a different threshold at
each smoothing level, provide <code>inflThres</code> as a vector of the same
length as <code>smoothBW</code>; NA = no threshold</p>
</td></tr>
<tr><td><code id=".pitchDescriptives_+3A_extrasummaryfun">extraSummaryFun</code></td>
<td>
<p>additional summary function(s) that take a numeric
vector with some NAs and return a single number, eg c('myFun1', 'myFun2')</p>
</td></tr>
<tr><td><code id=".pitchDescriptives_+3A_ref">ref</code></td>
<td>
<p>reference value for transforming Hz to semitones, defaults to
C0 (16.35 Hz)</p>
</td></tr>
<tr><td><code id=".pitchDescriptives_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the inflections for manual verification</p>
</td></tr>
</table>

<hr>
<h2 id='.prosody'>Prosody per sound</h2><span id='topic+.prosody'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+prosody">prosody</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.prosody(
  audio,
  multProsody,
  analyze_pars = list(),
  shiftPitch_pars = list(),
  pitchManual_list = NULL,
  play = FALSE,
  plot = FALSE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".prosody_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".prosody_+3A_multprosody">multProsody</code></td>
<td>
<p>multiplier of pitch excursion from median (on a
logarithmic or musical scale): &gt;1 = exaggerate intonation, 1 = no change, &lt;1
= flatten, 0 = completely flat at the original median pitch</p>
</td></tr>
<tr><td><code id=".prosody_+3A_analyze_pars">analyze_pars</code></td>
<td>
<p>a list of parameters to pass to <code><a href="#topic+analyze">analyze</a></code>
(only needed if <code>pitchManual</code> is NULL - that is, if we attempt to
track pitch automatically)</p>
</td></tr>
<tr><td><code id=".prosody_+3A_shiftpitch_pars">shiftPitch_pars</code></td>
<td>
<p>a list of parameters to pass to
<code><a href="#topic+shiftPitch">shiftPitch</a></code> to fine-tune the pitch-shifting algorithm</p>
</td></tr>
<tr><td><code id=".prosody_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
<tr><td><code id=".prosody_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".prosody_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id=".prosody_+3A_width">width</code>, <code id=".prosody_+3A_height">height</code>, <code id=".prosody_+3A_units">units</code>, <code id=".prosody_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".prosody_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.resample'>Resample per sound</h2><span id='topic+.resample'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.resample(
  audio,
  mult = NULL,
  len = NULL,
  samplingRate_new = NULL,
  lowPass = TRUE,
  na.rm = FALSE,
  nPoints = 1,
  plot = FALSE,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".resample_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".resample_+3A_mult">mult</code></td>
<td>
<p>multiplier of sampling rate: new sampling rate = old sampling
rate x mult, so 1 = no effect, &gt;1 = upsample, &lt;1 = downsample</p>
</td></tr>
<tr><td><code id=".resample_+3A_len">len</code></td>
<td>
<p>if specified, overrides mult and samplingRate_new and simply
returns a vector of length <code>len</code></p>
</td></tr>
<tr><td><code id=".resample_+3A_samplingrate_new">samplingRate_new</code></td>
<td>
<p>an alternative to <code>mult</code> provided that the old
<code>samplingRate is know</code> (NB: <code>mult</code> takes precedence)</p>
</td></tr>
<tr><td><code id=".resample_+3A_lowpass">lowPass</code></td>
<td>
<p>if TRUE, applies a low-pass filter before decimating or after
upsampling to avoid aliasing</p>
</td></tr>
<tr><td><code id=".resample_+3A_na.rm">na.rm</code></td>
<td>
<p>if TRUE, NAs are interpolated, otherwise they are preserved in
the output</p>
</td></tr>
<tr><td><code id=".resample_+3A_npoints">nPoints</code></td>
<td>
<p>the number of points to use for interpolating leading and
trailing NAs: 1 = constant interpolation, 2 = use the first two non-NAs at
the beginning and the last two non-NAs at the end, etc.</p>
</td></tr>
<tr><td><code id=".resample_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".resample_+3A_width">width</code>, <code id=".resample_+3A_height">height</code>, <code id=".resample_+3A_units">units</code>, <code id=".resample_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".resample_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.reverb'>Add reverb to a sound</h2><span id='topic+.reverb'></span>

<h3>Description</h3>

<p>Internal soundgen function, see <code><a href="#topic+reverb">reverb</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.reverb(
  audio,
  echoDelay = 200,
  echoLevel = -20,
  reverbDelay = 70,
  reverbSpread = 130,
  reverbLevel = -25,
  reverbDensity = 50,
  reverbType = "gaussian",
  filter = list(),
  dynamicRange = 80,
  output = c("audio", "detailed")[1],
  play = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".reverb_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".reverb_+3A_echodelay">echoDelay</code></td>
<td>
<p>the delay at which the echo appears, ms</p>
</td></tr>
<tr><td><code id=".reverb_+3A_echolevel">echoLevel</code></td>
<td>
<p>the rate at which the echo weakens at each repetition, dB</p>
</td></tr>
<tr><td><code id=".reverb_+3A_reverbdelay">reverbDelay</code></td>
<td>
<p>the time of maximum reverb density, ms</p>
</td></tr>
<tr><td><code id=".reverb_+3A_reverbspread">reverbSpread</code></td>
<td>
<p>standard deviation of reverb spread around time
<code>reverbDelay</code>, ms</p>
</td></tr>
<tr><td><code id=".reverb_+3A_reverblevel">reverbLevel</code></td>
<td>
<p>the maximum amplitude of reverb, dB below input</p>
</td></tr>
<tr><td><code id=".reverb_+3A_reverbdensity">reverbDensity</code></td>
<td>
<p>the number of echos or &quot;voices&quot; added</p>
</td></tr>
<tr><td><code id=".reverb_+3A_reverbtype">reverbType</code></td>
<td>
<p>so far only &quot;gaussian&quot; has been implemented</p>
</td></tr>
<tr><td><code id=".reverb_+3A_filter">filter</code></td>
<td>
<p>(optional) a spectral filter to apply to the created reverb and
echo (see <code>addFormants</code> for acceptable formats)</p>
</td></tr>
<tr><td><code id=".reverb_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>the precision with which the reverb and echo are
calculated, dB</p>
</td></tr>
<tr><td><code id=".reverb_+3A_output">output</code></td>
<td>
<p>&quot;audio&quot; = returns just the processed audio, &quot;detailed&quot; =
returns a list with reverb window, the added reverb/echo, etc.</p>
</td></tr>
<tr><td><code id=".reverb_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
</table>

<hr>
<h2 id='.segment'>Internal soundgen function</h2><span id='topic+.segment'></span>

<h3>Description</h3>

<p>A helper function called internally by segment() for segmenting a single sound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.segment(
  audio,
  shortestSyl = 40,
  shortestPause = 40,
  method = c("env", "spec", "mel")[3],
  propNoise = NULL,
  SNR = NULL,
  noiseLevelStabWeight = c(1, 0.25),
  windowLength = 40,
  step = NULL,
  overlap = 80,
  reverbPars = list(reverbDelay = 70, reverbSpread = 130, reverbLevel = -35,
    reverbDensity = 50),
  interburst = NULL,
  peakToTrough = SNR + 3,
  troughLocation = c("left", "right", "both", "either")[4],
  maxDur = 30,
  saveAudio = NULL,
  addSilence = 50,
  plot = FALSE,
  plotname = "",
  savePlots = NULL,
  main = NULL,
  xlab = "",
  ylab = "Signal, dB",
  showLegend = FALSE,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  maxPoints = c(1e+05, 5e+05),
  specPlot = NULL,
  contourPlot = list(lty = 1, lwd = 2, col = "green"),
  sylPlot = list(lty = 1, lwd = 2, col = "blue"),
  burstPlot = list(pch = 8, cex = 3, col = "red"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".segment_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".segment_+3A_shortestsyl">shortestSyl</code></td>
<td>
<p>minimum acceptable length of syllables, ms</p>
</td></tr>
<tr><td><code id=".segment_+3A_shortestpause">shortestPause</code></td>
<td>
<p>minimum acceptable break between syllables, ms
(syllables separated by shorter pauses are merged)</p>
</td></tr>
<tr><td><code id=".segment_+3A_method">method</code></td>
<td>
<p>the signal used to search for syllables: 'env' =
Hilbert-transformed amplitude envelope, 'spec' = spectrogram, 'mel' =
mel-transformed spectrogram (see tuneR::melfcc)</p>
</td></tr>
<tr><td><code id=".segment_+3A_propnoise">propNoise</code></td>
<td>
<p>the proportion of non-zero sound assumed to represent
background noise, 0 to 1 (note that complete silence is not considered, so
padding with silence won't affect the algorithm)</p>
</td></tr>
<tr><td><code id=".segment_+3A_snr">SNR</code></td>
<td>
<p>expected signal-to-noise ratio (dB above noise), which determines
the threshold for syllable detection. The meaning of &quot;dB&quot; here is
approximate since the &quot;signal&quot; may be different from sound intensity</p>
</td></tr>
<tr><td><code id=".segment_+3A_noiselevelstabweight">noiseLevelStabWeight</code></td>
<td>
<p>a vector of length 2 specifying the relative
weights of the overall signal level vs. stability when attempting to
automatically locate the regions that represent noise. Increasing the
weight of stability tends to accentuate the beginning and end of each
syllable.</p>
</td></tr>
<tr><td><code id=".segment_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".segment_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".segment_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".segment_+3A_reverbpars">reverbPars</code></td>
<td>
<p>parameters passed on to <code><a href="#topic+reverb">reverb</a></code> to attempt to
cancel the effects of reverberation or echo, which otherwise tend to merge
short and loud segments like rapid barks</p>
</td></tr>
<tr><td><code id=".segment_+3A_interburst">interburst</code></td>
<td>
<p>minimum time between two consecutive bursts (ms). Defaults
to the average detected <code>(syllable + pause) / 2</code></p>
</td></tr>
<tr><td><code id=".segment_+3A_peaktotrough">peakToTrough</code></td>
<td>
<p>to qualify as a burst, a local maximum has to be at least
<code>peakToTrough</code> dB above the left and/or right local trough(s)
(controlled by <code>troughLocation</code>) over the analysis window (controlled
by <code>interburst</code>). Defaults to SNR + 3 dB</p>
</td></tr>
<tr><td><code id=".segment_+3A_troughlocation">troughLocation</code></td>
<td>
<p>should local maxima be compared to the trough on the
left and/or right of it? Values: 'left', 'right', 'both', 'either'</p>
</td></tr>
<tr><td><code id=".segment_+3A_maxdur">maxDur</code></td>
<td>
<p>long files are split into chunks <code>maxDur</code> s in duration to
avoid running out of RAM; the outputs for all fragments are glued together,
but plotting is switched off. Note that noise profile is estimated in each
chunk separately, so set it low if the background noise is highly variable</p>
</td></tr>
<tr><td><code id=".segment_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id=".segment_+3A_addsilence">addSilence</code></td>
<td>
<p>if syllables are saved as separate audio files, they can be
padded with some silence (ms)</p>
</td></tr>
<tr><td><code id=".segment_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a segmentation plot</p>
</td></tr>
<tr><td><code id=".segment_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id=".segment_+3A_xlab">xlab</code>, <code id=".segment_+3A_ylab">ylab</code>, <code id=".segment_+3A_main">main</code></td>
<td>
<p>main plotting parameters</p>
</td></tr>
<tr><td><code id=".segment_+3A_showlegend">showLegend</code></td>
<td>
<p>if TRUE, shows a legend for thresholds</p>
</td></tr>
<tr><td><code id=".segment_+3A_width">width</code>, <code id=".segment_+3A_height">height</code>, <code id=".segment_+3A_units">units</code>, <code id=".segment_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
<tr><td><code id=".segment_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id=".segment_+3A_specplot">specPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the spectrogram
(if <code>method = 'spec' or 'mel'</code>); set to NULL to hide the spectrogram</p>
</td></tr>
<tr><td><code id=".segment_+3A_contourplot">contourPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the signal
contour used to detect syllables (see details)</p>
</td></tr>
<tr><td><code id=".segment_+3A_sylplot">sylPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the syllables</p>
</td></tr>
<tr><td><code id=".segment_+3A_burstplot">burstPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the bursts</p>
</td></tr>
<tr><td><code id=".segment_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to graphics::plot</p>
</td></tr>
</table>

<hr>
<h2 id='.shiftFormants'>Shift formants per sound</h2><span id='topic+.shiftFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+shiftFormants">shiftFormants</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.shiftFormants(
  audio,
  multFormants,
  freqWindow = NULL,
  spec = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = NULL,
  overlap = 75,
  wn = "gaussian",
  interpol = c("approx", "spline")[1],
  normalize = c("max", "orig", "none")[2],
  play = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".shiftFormants_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_multformants">multFormants</code></td>
<td>
<p>1 = no change, &gt;1 = raise formants (eg 1.1 = 10% up, 2 =
one octave up), &lt;1 = lower formants. Anchor format accepted (see
<code><a href="#topic+soundgen">soundgen</a></code>)</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of spectral smoothing window, Hz. Defaults to
detected f0</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_spec">spec</code></td>
<td>
<p>precomputed spectrogram</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_interpol">interpol</code></td>
<td>
<p>the method for interpolating scaled spectra</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_normalize">normalize</code></td>
<td>
<p>&quot;orig&quot; = same as input (default), &quot;max&quot; = maximum possible
peak amplitude, &quot;none&quot; = no normalization</p>
</td></tr>
<tr><td><code id=".shiftFormants_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='.shiftPitch'>Shift pitch per sound</h2><span id='topic+.shiftPitch'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+shiftPitch">shiftPitch</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.shiftPitch(
  audio,
  multPitch,
  multFormants,
  timeStretch,
  freqWindow = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = NULL,
  overlap = 75,
  wn = "gaussian",
  interpol = c("approx", "spline")[1],
  propagation = c("time", "adaptive")[1],
  preserveEnv = NULL,
  transplantEnv_pars = list(),
  normalize = c("max", "orig", "none")[2],
  play = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".shiftPitch_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_multpitch">multPitch</code></td>
<td>
<p>1 = no change, &gt;1 = raise pitch (eg 1.1 = 10% up, 2 = one
octave up), &lt;1 = lower pitch. Anchor format accepted for multPitch /
multFormant / timeStretch (see <code><a href="#topic+soundgen">soundgen</a></code>)</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_multformants">multFormants</code></td>
<td>
<p>1 = no change, &gt;1 = raise formants (eg 1.1 = 10% up, 2 =
one octave up), &lt;1 = lower formants</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_timestretch">timeStretch</code></td>
<td>
<p>1 = no change, &gt;1 = longer, &lt;1 = shorter</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of spectral smoothing window, Hz. Defaults to
detected f0 prior to pitch shifting - see <code><a href="#topic+shiftFormants">shiftFormants</a></code> for
discussion and examples</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_interpol">interpol</code></td>
<td>
<p>the method for interpolating scaled spectra and anchors</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_propagation">propagation</code></td>
<td>
<p>the method for propagating phase: &quot;time&quot; = horizontal
propagation (default), &quot;adaptive&quot; = an experimental implementation of
&quot;vocoder done right&quot; (Prusa &amp; Holighaus 2017)</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_preserveenv">preserveEnv</code></td>
<td>
<p>if TRUE, transplants the amplitude envelope from the
original to the modified sound with <code><a href="#topic+transplantEnv">transplantEnv</a></code>. Defaults
to TRUE if no time stretching is performed and FALSE otherwise</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_transplantenv_pars">transplantEnv_pars</code></td>
<td>
<p>a list of parameters passed on to
<code><a href="#topic+transplantEnv">transplantEnv</a></code> if <code>preserveEnv = TRUE</code></p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_normalize">normalize</code></td>
<td>
<p>&quot;orig&quot; = same as input (default), &quot;max&quot; = maximum possible
peak amplitude, &quot;none&quot; = no normalization</p>
</td></tr>
<tr><td><code id=".shiftPitch_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='.spectrogram'>Spectrogram per sound</h2><span id='topic+.spectrogram'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+spectrogram">spectrogram</a></code> and
<code><a href="#topic+analyze">analyze</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.spectrogram(
  audio,
  dynamicRange = 80,
  windowLength = 50,
  step = windowLength/2,
  overlap = NULL,
  specType = c("spectrum", "reassigned", "spectralDerivative")[1],
  logSpec = TRUE,
  rasterize = FALSE,
  wn = "gaussian",
  zp = 0,
  normalize = TRUE,
  smoothFreq = 0,
  smoothTime = 0,
  qTime = 0,
  percentNoise = 10,
  noiseReduction = 0,
  output = c("original", "processed", "complex", "all")[1],
  specManual = NULL,
  plot = TRUE,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  yScale = "linear",
  contrast = 0.2,
  brightness = 0,
  blur = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  internal = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".spectrogram_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_spectype">specType</code></td>
<td>
<p>plot the original FFT ('spectrum'), reassigned spectrogram
('reassigned'), or spectral derivative ('spectralDerivative')</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, log-transforms the spectrogram</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_rasterize">rasterize</code></td>
<td>
<p>(only applies if specType = 'reassigned') if TRUE, the
reassigned spectrogram is plotted after rasterizing it: that is, showing
density per time-frequency bins with the same resolution as an ordinary
spectrogram</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, scales input prior to FFT</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_smoothfreq">smoothFreq</code>, <code id=".spectrogram_+3A_smoothtime">smoothTime</code></td>
<td>
<p>length of the window for median smoothing in
frequency and time domains, respectively, points</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_qtime">qTime</code></td>
<td>
<p>the quantile to be subtracted for each frequency bin. For ex.,
if qTime = 0.5, the median of each frequency bin (over the entire sound
duration) will be calculated and subtracted from each frame (see examples)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_percentnoise">percentNoise</code></td>
<td>
<p>percentage of frames (0 to 100%) used for calculating
noise spectrum</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_noisereduction">noiseReduction</code></td>
<td>
<p>how much noise to remove (non-negative number,
recommended 0 to 2). 0 = no noise reduction, 2 = strong noise reduction:
<code class="reqn">spectrum - (noiseReduction * noiseSpectrum)</code>, where noiseSpectrum is
the average spectrum of frames with entropy exceeding the quantile set by
<code>percentNoise</code></p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_output">output</code></td>
<td>
<p>specifies what to return: nothing ('none'), unmodified
spectrogram ('original'), denoised and/or smoothed spectrogram
('processed'), or unmodified spectrogram with the imaginary part giving
phase ('complex')</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_specmanual">specManual</code></td>
<td>
<p>manually calculated spectrogram-like representation in the
same format as the output of spectrogram(): rows = frequency in kHz,
columns = time in ms</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_yscale">yScale</code></td>
<td>
<p>scale of the frequency axis: 'linear' = linear, 'log' =
logarithmic (musical), 'bark' = bark with <code><a href="tuneR.html#topic+hz2bark">hz2bark</a></code>,
'mel' = mel with <code><a href="tuneR.html#topic+hz2mel">hz2mel</a></code>, 'ERB' = Equivalent
Rectangular Bandwidths with <code><a href="#topic+HzToERB">HzToERB</a></code></p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_blur">blur</code></td>
<td>
<p>apply a Gaussian filter to blur or sharpen the image, two
numbers: frequency (Hz), time (ms). A single number is interpreted as
frequency, and a square filter is applied. NA / NULL / 0 means no blurring
in that dimension. Negative numbers mean un-blurring (sharpening) the image
by dividing instead of multiplying by the filter during convolution</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_xlab">xlab</code>, <code id=".spectrogram_+3A_ylab">ylab</code>, <code id=".spectrogram_+3A_main">main</code>, <code id=".spectrogram_+3A_mar">mar</code>, <code id=".spectrogram_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_width">width</code>, <code id=".spectrogram_+3A_height">height</code>, <code id=".spectrogram_+3A_units">units</code>, <code id=".spectrogram_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_internal">internal</code></td>
<td>
<p>a long list of stuff for plotting pitch contours passed by
analyze()</p>
</td></tr>
<tr><td><code id=".spectrogram_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>

<hr>
<h2 id='.ssm'>SSM per sound</h2><span id='topic+.ssm'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ssm(
  audio,
  windowLength = 25,
  step = 5,
  overlap = NULL,
  win = 1,
  sparse = FALSE,
  maxFreq = NULL,
  nBands = NULL,
  MFCC = 2:13,
  input = c("mfcc", "melspec", "spectrum")[2],
  norm = FALSE,
  simil = c("cosine", "cor")[1],
  kernelLen = 100,
  kernelSD = 0.5,
  padWith = 0,
  plot = TRUE,
  main = NULL,
  heights = c(2, 1),
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  specPars = list(levels = seq(0, 1, length = 30), colorTheme = c("bw", "seewave",
    "heat.colors", "...")[2], xlab = "Time, s", ylab = "kHz"),
  ssmPars = list(levels = seq(0, 1, length = 30), colorTheme = c("bw", "seewave",
    "heat.colors", "...")[2], xlab = "Time, s", ylab = "Time, s"),
  noveltyPars = list(type = "b", pch = 16, col = "black", lwd = 3)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ssm_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".ssm_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id=".ssm_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id=".ssm_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id=".ssm_+3A_sparse">sparse</code></td>
<td>
<p>if TRUE, the entire SSM is not calculated, but only the central
region needed to extract the novelty contour (speeds up the processing)</p>
</td></tr>
<tr><td><code id=".ssm_+3A_maxfreq">maxFreq</code></td>
<td>
<p>highest band edge of mel filters, Hz. Defaults to
<code>samplingRate / 2</code>. See <code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id=".ssm_+3A_nbands">nBands</code></td>
<td>
<p>number of warped spectral bands to use. Defaults to <code>100 *
windowLength / 20</code>. See <code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id=".ssm_+3A_mfcc">MFCC</code></td>
<td>
<p>which mel-frequency cepstral coefficients to use; defaults to
<code>2:13</code></p>
</td></tr>
<tr><td><code id=".ssm_+3A_input">input</code></td>
<td>
<p>the spectral representation used to calculate the SSM</p>
</td></tr>
<tr><td><code id=".ssm_+3A_norm">norm</code></td>
<td>
<p>if TRUE, the spectrum of each STFT frame is normalized</p>
</td></tr>
<tr><td><code id=".ssm_+3A_simil">simil</code></td>
<td>
<p>method for comparing frames: &quot;cosine&quot; = cosine similarity, &quot;cor&quot;
= Pearson's correlation</p>
</td></tr>
<tr><td><code id=".ssm_+3A_kernellen">kernelLen</code></td>
<td>
<p>length of checkerboard kernel for calculating novelty, ms
(larger values favor global, slow vs. local, fast novelty)</p>
</td></tr>
<tr><td><code id=".ssm_+3A_kernelsd">kernelSD</code></td>
<td>
<p>SD of checkerboard kernel for calculating novelty</p>
</td></tr>
<tr><td><code id=".ssm_+3A_padwith">padWith</code></td>
<td>
<p>how to treat edges when calculating novelty: NA = treat sound
before and after the recording as unknown, 0 = treat it as silence</p>
</td></tr>
<tr><td><code id=".ssm_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the SSM</p>
</td></tr>
<tr><td><code id=".ssm_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id=".ssm_+3A_heights">heights</code></td>
<td>
<p>relative sizes of the SSM and spectrogram/novelty plot</p>
</td></tr>
<tr><td><code id=".ssm_+3A_width">width</code>, <code id=".ssm_+3A_height">height</code>, <code id=".ssm_+3A_units">units</code>, <code id=".ssm_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id=".ssm_+3A_specpars">specPars</code></td>
<td>
<p>graphical parameters passed to <code>filled.contour.mod</code> and
affecting the <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
<tr><td><code id=".ssm_+3A_ssmpars">ssmPars</code></td>
<td>
<p>graphical parameters passed to <code>filled.contour.mod</code> and
affecting the plot of SSM</p>
</td></tr>
<tr><td><code id=".ssm_+3A_noveltypars">noveltyPars</code></td>
<td>
<p>graphical parameters passed to
<code><a href="graphics.html#topic+lines">lines</a></code> and affecting the novelty contour</p>
</td></tr>
</table>

<hr>
<h2 id='.timeStretch'>Time stretch per sound</h2><span id='topic+.timeStretch'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+timeStretch">timeStretch</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.timeStretch(audio, stretch, precision, normalize = TRUE, play = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".timeStretch_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id=".timeStretch_+3A_stretch">stretch</code></td>
<td>
<p>1 = no change, &gt;1 = longer, &lt;1 = shorter. Single value, vector,
or anchor format (see <code><a href="#topic+soundgen">soundgen</a></code>)</p>
</td></tr>
<tr><td><code id=".timeStretch_+3A_precision">precision</code></td>
<td>
<p>the number of points used for estimating the duration of
output (more = better, but slower)</p>
</td></tr>
<tr><td><code id=".timeStretch_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='addAM'>Add amplitude modulation</h2><span id='topic+addAM'></span>

<h3>Description</h3>

<p>Adds sinusoidal or logistic amplitude modulation to a sound. This produces
additional harmonics in the spectrum at Â±am_freq around each original
harmonic and makes the sound rough. The optimal frequency for creating a
perception of roughness is ~70 Hz (Fastl &amp; Zwicker &quot;Psychoacoustics&quot;).
Sinusoidal AM creates a single pair of new harmonics, while non-sinusoidal AM
creates more extra harmonics (see examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addAM(
  x,
  samplingRate = NULL,
  amDep = 25,
  amFreq = 30,
  amType = c("logistic", "sine")[1],
  amShape = 0,
  invalidArgAction = c("adjust", "abort", "ignore")[1],
  plot = FALSE,
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addAM_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="addAM_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="addAM_+3A_amdep">amDep</code></td>
<td>
<p>amplitude modulation (AM) depth, %. 0: no change; 100: AM with
amplitude range equal to the dynamic range of the sound (anchor format)</p>
</td></tr>
<tr><td><code id="addAM_+3A_amfreq">amFreq</code></td>
<td>
<p>AM frequency, Hz (anchor format)</p>
</td></tr>
<tr><td><code id="addAM_+3A_amtype">amType</code></td>
<td>
<p>&quot;sine&quot; = sinusoidal, &quot;logistic&quot; = logistic (default)</p>
</td></tr>
<tr><td><code id="addAM_+3A_amshape">amShape</code></td>
<td>
<p>ignore if amType = &quot;sine&quot;, otherwise determines the shape of
non-sinusoidal AM: 0 = ~sine, -1 = notches, +1 = clicks (anchor format)</p>
</td></tr>
<tr><td><code id="addAM_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>permittedValues</code>: 'adjust' = reset to default value, 'abort'
= stop execution, 'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
<tr><td><code id="addAM_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the amplitude modulation</p>
</td></tr>
<tr><td><code id="addAM_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
<tr><td><code id="addAM_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full (!) path to folder for saving the processed audio; NULL
= don't save, &rdquo; = same as input folder (NB: overwrites the originals!)</p>
</td></tr>
<tr><td><code id="addAM_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="addAM_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>sound1 = soundgen(pitch = c(200, 300), addSilence = 0)
s1 = addAM(sound1, 16000, amDep = c(0, 50, 0), amFreq = 75, plot = TRUE)
# playme(s1)
## Not run: 
# Parameters can be specified as in the soundgen() function, eg:
s2 = addAM(sound1, 16000,
         amDep = list(time = c(0, 50, 52, 200, 201, 300),
                      value = c(0, 0, 35, 25, 0, 0)),
         plot = TRUE, play = TRUE)

# Sinusoidal AM produces exactly 2 extra harmonics at Â±am_freq
# around each f0 harmonic:
s3 = addAM(sound1, 16000, amDep = 30, amFreq = c(50, 80),
           amType = 'sine', plot = TRUE, play = TRUE)
spectrogram(s3, 16000, windowLength = 150, ylim = c(0, 2))

# Non-sinusoidal AM produces multiple new harmonics,
# which can resemble subharmonics...
s4 = addAM(sound1, 16000, amDep = 70, amFreq = 50, amShape = -1,
           plot = TRUE, play = TRUE)
spectrogram(s4, 16000, windowLength = 150, ylim = c(0, 2))

# ...but more often look like sidebands
sound3 = soundgen(sylLen = 600, pitch = c(800, 1300, 1100), addSilence = 0)
s5 = addAM(sound3, 16000, amDep = c(0, 30, 100, 40, 0),
           amFreq = 105, amShape = -.3,
           plot = TRUE, play = TRUE)
spectrogram(s5, 16000, ylim = c(0, 5))

# Feel free to add AM stochastically:
s6 = addAM(sound1, 16000,
           amDep = rnorm(10, 40, 20), amFreq = rnorm(20, 70, 20),
           plot = TRUE, play = TRUE)
spectrogram(s6, 16000, windowLength = 150, ylim = c(0, 2))

# If am_freq is locked to an integer ratio of f0, we can get subharmonics
# For ex., here is with pitch 400-600-400 Hz (soundgen interpolates pitch
# on a log scale and am_freq on a linear scale, so we align them by extracting
# a long contour on a log scale for both)
con = getSmoothContour(anchors = c(400, 600, 400),
                       len = 20, thisIsPitch = TRUE)
s = soundgen(sylLen = 1500, pitch = con, amFreq = con/3, amDep = 30,
             plot = TRUE, play = TRUE, ylim = c(0, 3))

# Process all files in a folder and save the modified audio
addAM('~/Downloads/temp', saveAudio = '~/Downloads/temp/AM',
      amFreq = 70, amDep = c(0, 50))

## End(Not run)
</code></pre>

<hr>
<h2 id='addFormants'>Add formants</h2><span id='topic+addFormants'></span>

<h3>Description</h3>

<p>A spectral filter that either adds or removes formants from a sound - that
is, amplifies or dampens certain frequency bands, as in human vowels. See
<code><a href="#topic+soundgen">soundgen</a></code> and <code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code> for more
information. With <code>action = 'remove'</code> this function can perform inverse
filtering to remove formants and obtain raw glottal output, provided that you
can specify the correct formant structure. Instead of formants, any arbitrary
spectral filtering function can be applied using the <code>spectralEnvelope</code>
argument (eg for a low/high/bandpass filter).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addFormants(
  x,
  samplingRate = NULL,
  formants = NULL,
  spectralEnvelope = NULL,
  action = c("add", "remove")[1],
  dB = NULL,
  specificity = 1,
  zFun = NULL,
  vocalTract = NA,
  formantDep = 1,
  formantDepStoch = 1,
  formantWidth = 1,
  formantCeiling = 2,
  lipRad = 6,
  noseRad = 4,
  mouthOpenThres = 0,
  mouth = NA,
  temperature = 0.025,
  formDrift = 0.3,
  formDisp = 0.2,
  smoothing = list(),
  windowLength_points = 800,
  overlap = 75,
  normalize = c("max", "orig", "none")[1],
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addFormants_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="addFormants_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="addFormants_+3A_formants">formants</code></td>
<td>
<p>either a character string referring to default presets for
speaker &quot;M1&quot; (implemented: &quot;aoieu0&quot;) or a list of formant times,
frequencies, amplitudes, and bandwidths (see examples). NA or NULL means no
formants, only lip radiation. Time stamps for formants and mouthOpening can
be specified in ms relative to <code>sylLen</code> or on a scale of [0, 1]. See
<code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code> for more details</p>
</td></tr>
<tr><td><code id="addFormants_+3A_spectralenvelope">spectralEnvelope</code></td>
<td>
<p>(optional): as an alternative to specifying formant
frequencies, we can provide the exact filter - a vector of non-negative
numbers specifying the power in each frequency bin on a linear scale
(interpolated to length equal to windowLength_points/2). A matrix
specifying the filter for each STFT step is also accepted. The easiest way
to create this matrix is to call soundgen:::getSpectralEnvelope or to use
the spectrum of a recorded sound</p>
</td></tr>
<tr><td><code id="addFormants_+3A_action">action</code></td>
<td>
<p>'add' = add formants to the sound, 'remove' = remove formants
(inverse filtering)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_db">dB</code></td>
<td>
<p>if NULL (default), the spectral envelope is applied on the original
scale; otherwise, it is set to range from 1 to 10 ^ (dB / 20)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_specificity">specificity</code></td>
<td>
<p>a way to sharpen or blur the spectral envelope (spectrum ^
specificity) : 1 = no change, &gt;1 = sharper, &lt;1 = blurred</p>
</td></tr>
<tr><td><code id="addFormants_+3A_zfun">zFun</code></td>
<td>
<p>(optional) an arbitrary function to apply to the spectrogram
prior to iSTFT, where &quot;z&quot; is the spectrogram - a matrix of complex values
(see examples)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_vocaltract">vocalTract</code></td>
<td>
<p>the length of vocal tract, cm. Used for calculating formant
dispersion (for adding extra formants) and formant transitions as the mouth
opens and closes. If <code>NULL</code> or <code>NA</code>, the length is estimated
based on specified formant frequencies, if any (anchor format)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_formantdep">formantDep</code></td>
<td>
<p>scale factor of formant amplitude (1 = no change relative
to amplitudes in <code>formants</code>)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_formantdepstoch">formantDepStoch</code></td>
<td>
<p>the amplitude of additional stochastic formants added
above the highest specified formant, dB (only if temperature &gt; 0)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_formantwidth">formantWidth</code></td>
<td>
<p>scale factor of formant bandwidth (1 = no change)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_formantceiling">formantCeiling</code></td>
<td>
<p>frequency to which stochastic formants are calculated,
in multiples of the Nyquist frequency; increase up to ~10 for long vocal
tracts to avoid losing energy in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id="addFormants_+3A_liprad">lipRad</code></td>
<td>
<p>the effect of lip radiation on source spectrum, dB/oct (the
default of +6 dB/oct produces a high-frequency boost when the mouth is
open)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_noserad">noseRad</code></td>
<td>
<p>the effect of radiation through the nose on source spectrum,
dB/oct (the alternative to <code>lipRad</code> when the mouth is closed)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_mouthopenthres">mouthOpenThres</code></td>
<td>
<p>open the lips (switch from nose radiation to lip
radiation) when the mouth is open <code>&gt;mouthOpenThres</code>, 0 to 1</p>
</td></tr>
<tr><td><code id="addFormants_+3A_mouth">mouth</code></td>
<td>
<p>mouth opening (0 to 1, 0.5 = neutral, i.e. no
modification) (anchor format)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id="addFormants_+3A_formdrift">formDrift</code>, <code id="addFormants_+3A_formdisp">formDisp</code></td>
<td>
<p>scaling factors for the effect of temperature on
formant drift and dispersal, respectively</p>
</td></tr>
<tr><td><code id="addFormants_+3A_smoothing">smoothing</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+getSmoothContour">getSmoothContour</a></code> to control the interpolation and smoothing
of contours: interpol (approx / spline / loess), loessSpan, discontThres,
jumpThres</p>
</td></tr>
<tr><td><code id="addFormants_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>length of FFT window, points</p>
</td></tr>
<tr><td><code id="addFormants_+3A_overlap">overlap</code></td>
<td>
<p>FFT window overlap, %. For allowed values, see
<code><a href="seewave.html#topic+istft">istft</a></code></p>
</td></tr>
<tr><td><code id="addFormants_+3A_normalize">normalize</code></td>
<td>
<p>&quot;orig&quot; = same as input (default), &quot;max&quot; = maximum possible
peak amplitude, &quot;none&quot; = no normalization</p>
</td></tr>
<tr><td><code id="addFormants_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="addFormants_+3A_saveaudio">saveAudio</code></td>
<td>
<p>path + filename for saving the output, e.g.
'~/Downloads/temp.wav'. If NULL = doesn't save</p>
</td></tr>
<tr><td><code id="addFormants_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="addFormants_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="addFormants_+3A_...">...</code></td>
<td>
<p>other plotting parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: converts input from a time series (time domain) to a spectrogram
(frequency domain) through short-time Fourier transform (STFT), multiples by
the spectral filter containing the specified formants, and transforms back to
a time series via inverse STFT. This is a subroutine for voice synthesis in
<code><a href="#topic+soundgen">soundgen</a></code>, but it can also be applied to a recording.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code> <code><a href="#topic+transplantFormants">transplantFormants</a></code>
<code><a href="#topic+soundgen">soundgen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound = c(rep(0, 1000), runif(8000) * 2 - 1, rep(0, 1000))  # white noise
# NB: pad with silence to avoid artefacts if removing formants
# playme(sound)
# spectrogram(sound, samplingRate = 16000)

# add F1 = 900, F2 = 1300 Hz
sound_filtered = addFormants(sound, samplingRate = 16000,
                             formants = c(900, 1300))
# playme(sound_filtered)
# spectrogram(sound_filtered, samplingRate = 16000)

# ...and remove them again (assuming we know what the formants are)
sound_inverse_filt = addFormants(sound_filtered,
                                 samplingRate = 16000,
                                 formants = c(900, 1300),
                                 action = 'remove')
# playme(sound_inverse_filt)
# spectrogram(sound_inverse_filt, samplingRate = 16000)

## Not run: 
## Perform some user-defined manipulation of the spectrogram with zFun
# Ex.: noise removal - silence all bins under threshold,
# say -0 dB below the max value
s_noisy = soundgen(sylLen = 200, addSilence = 0,
                   noise = list(time = c(-100, 300), value = -20))
spectrogram(s_noisy, 16000)
# playme(s_noisy)
zFun = function(z, cutoff = -50) {
  az = abs(z)
  thres = max(az) * 10 ^ (cutoff / 20)
  z[which(az &lt; thres)] = 0
  return(z)
}
s_denoised = addFormants(s_noisy, samplingRate = 16000,
                         formants = NA, zFun = zFun, cutoff = -40)
spectrogram(s_denoised, 16000)
# playme(s_denoised)

# If neither formants nor spectralEnvelope are defined, only lipRad has an effect
# For ex., we can boost low frequencies by 6 dB/oct
noise = runif(8000)
noise1 = addFormants(noise, 16000, lipRad = -6)
seewave::meanspec(noise1, f = 16000, dB = 'max0')

# Arbitrary spectra can be defined with spectralEnvelope. For ex., we can
# have a flat spectrum up to 2 kHz (Nyquist / 4) and -3 dB/kHz above:
freqs = seq(0, 16000 / 2, length.out = 100)
n = length(freqs)
idx = (n / 4):n
sp_dB = c(rep(0, n / 4 - 1), (freqs[idx] - freqs[idx[1]]) / 1000 * (-3))
plot(freqs, sp_dB, type = 'b')
noise2 = addFormants(noise, 16000, lipRad = 0, spectralEnvelope = 10 ^ (sp_dB / 20))
seewave::meanspec(noise2, f = 16000, dB = 'max0')

## Use the spectral envelope of an existing recording (bleating of a sheep)
# (see also the same example with noise as source in ?generateNoise)
# (NB: this can also be achieved with a single call to transplantFormants)
data(sheep, package = 'seewave')  # import a recording from seewave
sound_orig = as.numeric(scale(sheep@left))
samplingRate = sheep@samp.rate
sound_orig = sound_orig / max(abs(sound_orig))  # range -1 to +1
# playme(sound_orig, samplingRate)

# get a few pitch anchors to reproduce the original intonation
pitch = analyze(sound_orig, samplingRate = samplingRate,
  pitchMethod = c('autocor', 'dom'))$detailed$pitch
pitch = pitch[!is.na(pitch)]

# extract a frequency-smoothed version of the original spectrogram
# to use as filter
specEnv_bleating = spectrogram(sound_orig, windowLength = 5,
 samplingRate = samplingRate, output = 'original', plot = FALSE)
# image(t(log(specEnv_bleating)))

# Synthesize source only, with flat spectrum
sound_unfilt = soundgen(sylLen = 2500, pitch = pitch,
  rolloff = 0, rolloffOct = 0, rolloffKHz = 0,
  temperature = 0, jitterDep = 0, subDep = 0,
  formants = NULL, lipRad = 0, samplingRate = samplingRate,
  invalidArgAction = 'ignore')  # prevent soundgen from increasing samplingRate
# playme(sound_unfilt, samplingRate)
# seewave::meanspec(sound_unfilt, f = samplingRate, dB = 'max0')  # ~flat

# Force spectral envelope to the shape of target
sound_filt = addFormants(sound_unfilt, formants = NULL,
  spectralEnvelope = specEnv_bleating, samplingRate = samplingRate)
# playme(sound_filt, samplingRate)  # playme(sound_orig, samplingRate)
# spectrogram(sound_filt, samplingRate)  # spectrogram(sound_orig, samplingRate)

# The spectral envelope is now similar to the original recording. Compare:
par(mfrow = c(1, 2))
seewave::meanspec(sound_orig, f = samplingRate, dB = 'max0', alim = c(-50, 20))
seewave::meanspec(sound_filt, f = samplingRate, dB = 'max0', alim = c(-50, 20))
par(mfrow = c(1, 1))
# NB: but the source of excitation in the original is actually a mix of
# harmonics and noise, while the new sound is purely tonal

## End(Not run)
</code></pre>

<hr>
<h2 id='addPitchCands'>Plot pitch candidates</h2><span id='topic+addPitchCands'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addPitchCands(
  pitchCands,
  pitchCert,
  pitchSource,
  pitch,
  timestamps = NULL,
  candPlot = list(),
  pitchPlot = list(),
  extraContour = NULL,
  extraContour_pars = list(),
  priorMean = NULL,
  priorSD = NULL,
  pitchFloor = NULL,
  pitchCeiling = NULL,
  addToExistingPlot = TRUE,
  showLegend = TRUE,
  y_Hz = FALSE,
  yScale = c("orig", "bark", "mel")[1],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addPitchCands_+3A_pitchcands">pitchCands</code>, <code id="addPitchCands_+3A_pitchcert">pitchCert</code>, <code id="addPitchCands_+3A_pitchsource">pitchSource</code></td>
<td>
<p>matrices of pitch candidates, their
certainty, and pitch tracking method used as generated internally by
analyze(); columns = STFT frames, rows = candidates</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_pitch">pitch</code></td>
<td>
<p>best guess at pitch contour; length = ncol(pitchCands)</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_candplot">candPlot</code>, <code id="addPitchCands_+3A_pitchplot">pitchPlot</code></td>
<td>
<p>lists of graphical settings for plotting candidates
and pitch contour, respectively</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_extracontour">extraContour</code></td>
<td>
<p>another contour to add to the plot, such as harmHeight, Hz</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_addtoexistingplot">addToExistingPlot</code></td>
<td>
<p>if TRUE, assumes that a spectrogram is already
plotted; if FALSE, sets up a new plot</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_showlegend">showLegend</code></td>
<td>
<p>if TRUE, shows a legend</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_y_hz">y_Hz</code></td>
<td>
<p>if TRUE, plot in Hz, otherwise in kHz</p>
</td></tr>
<tr><td><code id="addPitchCands_+3A_...">...</code></td>
<td>
<p>other graphical parameters used for creating a new plot if
addToExistingPlot = FALSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots pitch candidates or adds them to a spectrogram.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen()
a = soundgen:::.analyze(soundgen:::readAudio(s, samplingRate = 16000),
 windowLength = 25, step = 25,
 returnPitchCands = TRUE, plot = FALSE)
spectrogram(s, 16000, windowLength = 25, step = 5, ylim = c(0, 1), osc = FALSE)
soundgen:::addPitchCands(
  pitchCands = a$pitchCands$freq,
  pitchCert = a$pitchCands$cert,
  pitchSource = a$pitchCands$source,
  pitch = a$result$pitch,
  timestamps = a$result$time / 1000)
</code></pre>

<hr>
<h2 id='addPitchJumps'>Add pitch jumps</h2><span id='topic+addPitchJumps'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addPitchJumps(pitch, magn, nj = 1, prop = 0.1, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addPitchJumps_+3A_pitch">pitch</code></td>
<td>
<p>numeric vector of f0 values over time (any step is OK)</p>
</td></tr>
<tr><td><code id="addPitchJumps_+3A_magn">magn</code></td>
<td>
<p>magnitude of jump(s) in semitones, a numeric vector of length 1
or nj</p>
</td></tr>
<tr><td><code id="addPitchJumps_+3A_nj">nj</code></td>
<td>
<p>number of jump pairs = affected segments (e.g., a single fragment
is transposed if nj = 1)</p>
</td></tr>
<tr><td><code id="addPitchJumps_+3A_prop">prop</code></td>
<td>
<p>duration of transposed episode(s) a a proportion of the total
voiced duration (length of <code>pitch</code>)</p>
</td></tr>
<tr><td><code id="addPitchJumps_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original and modified contours</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adds random discontinuities (jumps) to a pitch contour in a manner that
shifts a segment of pitch contour up or down. Careful when adding several
jumps: one can land on top of another, and it gets rather weird rather
quickly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch = getSmoothContour(c(100, 350, 320, 110), len = 100, interpol = 'loess')
addPitchJumps(pitch, magn = runif(1, 3, 12), plot = TRUE)
addPitchJumps(pitch, magn = c(6, 1), nj = 2, plot = TRUE)
addPitchJumps(pitch, magn = 3, nj = 5, plot = TRUE)

pitch2 = c(rep(NA, 10), pitch[1:50], rep(NA, 25), pitch[51:100], rep(NA, 17))
addPitchJumps(pitch2, magn = c(6, 1), nj = 2, plot = TRUE)
</code></pre>

<hr>
<h2 id='addSubh'>Subharmonics</h2><span id='topic+addSubh'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addSubh(
  rolloff,
  pitch_per_gc,
  subRatio = 2,
  subFreq = 0,
  subDep = 10,
  subWidth = 10000,
  dynamicRange = 80,
  shortestEpoch = 300
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addSubh_+3A_rolloff">rolloff</code></td>
<td>
<p>matrix of original amplitudes of each harmonic in f0 stack
returned by <code><a href="#topic+getRolloff">getRolloff</a></code> (columns=time, rows=frequency bins)</p>
</td></tr>
<tr><td><code id="addSubh_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>vector of the same length as ncol(rolloff)): f0 in Hz,
one value per glottal cycle</p>
</td></tr>
<tr><td><code id="addSubh_+3A_subratio">subRatio</code></td>
<td>
<p>a positive integer giving the ratio of f0 (the main
fundamental) to g0 (a lower frequency): 1 = no subharmonics, 2 = period
doubling regardless of pitch changes, 3 = period tripling, etc; subRatio
overrides subFreq (anchor format)</p>
</td></tr>
<tr><td><code id="addSubh_+3A_subfreq">subFreq</code></td>
<td>
<p>instead of a specific number of subharmonics (subRatio), we
can specify the approximate g0 frequency (Hz), which is used only if
subRatio = 1 and is adjusted to f0 so f0/g0 is always an integer (anchor
format)</p>
</td></tr>
<tr><td><code id="addSubh_+3A_subdep">subDep</code></td>
<td>
<p>the depth of subharmonics relative to the main frequency
component (f0), %. 0: no subharmonics; 100: g0 harmonics are as strong as
the nearest f0 harmonic (anchor format)</p>
</td></tr>
<tr><td><code id="addSubh_+3A_subwidth">subWidth</code></td>
<td>
<p>Width of subharmonic sidebands - regulates how rapidly
g-harmonics weaken away from f-harmonics: large values like the default
10000 means that all g0 harmonics are equally strong (anchor format)</p>
</td></tr>
<tr><td><code id="addSubh_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. Harmonics and noise more than
dynamicRange under maximum amplitude are discarded to save computational
resources</p>
</td></tr>
<tr><td><code id="addSubh_+3A_shortestepoch">shortestEpoch</code></td>
<td>
<p>minimum duration of each epoch with unchanging
subharmonics regime or formant locking, in ms</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adds subharmonics to the main (f0) harmonic stack, forming sidebands.
</p>


<h3>Value</h3>

<p>Returns a list consisting of a list of rolloff matrices (one matrix
per epoch) and a dataframe of epochs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch_per_gc = c(400, 500, 600, 700)
rolloff = getRolloff(pitch_per_gc, rolloff = -30)
# one epoch, two subharmonics
rolloff_subh = soundgen:::addSubh(rolloff, pitch_per_gc,
  subFreq = 200, subDep = 150, shortestEpoch = 100)
# three epochs with 2/3/4 subharmonics
rolloff_subh = soundgen:::addSubh(rolloff, pitch_per_gc,
  subFreq = 200, subDep = 150, shortestEpoch = 0)
</code></pre>

<hr>
<h2 id='addSubh_per_epoch'>Constant subharmonics</h2><span id='topic+addSubh_per_epoch'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addSubh_per_epoch(
  rolloff,
  pitch_per_gc,
  nSubharm,
  sideband_width_vector,
  subDep_vector,
  throwaway01
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addSubh_per_epoch_+3A_rolloff">rolloff</code></td>
<td>
<p>matrix of original amplitudes of each harmonic in f0 stack
returned by <code><a href="#topic+getRolloff">getRolloff</a></code> (columns=time, rows=frequency bins)</p>
</td></tr>
<tr><td><code id="addSubh_per_epoch_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>vector of the same length as ncol(rolloff)): f0 in Hz,
one value per glottal cycle</p>
</td></tr>
<tr><td><code id="addSubh_per_epoch_+3A_nsubharm">nSubharm</code></td>
<td>
<p>the number of subharmonics to generate (a positive integer).
If nSubharm==1, subFreq = f0 / 2. If nSubharm==2, subFreq = f0 / 3 and 2 * f0 / 3.
Etc</p>
</td></tr>
<tr><td><code id="addSubh_per_epoch_+3A_sideband_width_vector">sideband_width_vector</code></td>
<td>
<p>(either numeric or vector of the same length as
pitch_per_gc): regulates how quickly the strength of subharmonics fades as
they move away from harmonics in f0 stack. Low values produce narrow
sidebands, high values produce uniformly strong subharmonics</p>
</td></tr>
<tr><td><code id="addSubh_per_epoch_+3A_throwaway01">throwaway01</code></td>
<td>
<p>discard harmonics that are weaker than this number (between
0 and 1) to save computational resources</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for adding subharmonics to a single epoch, with unchanging
subharmonic regime (fixed number of subharmonics and sideband width). See
master function <code><a href="#topic+addSubh">addSubh</a></code>.
</p>


<h3>Value</h3>

<p>Returns a modified rolloff matrix with added subharmonics
</p>

<hr>
<h2 id='addVectors'>Add overlapping vectors</h2><span id='topic+addVectors'></span>

<h3>Description</h3>

<p>Adds two partly overlapping vectors, such as two waveforms, to produce a
longer vector. The location at which vector 2 is pasted is defined by
insertionPoint. Algorithm: both vectors are padded with zeros to match in
length and then added. All NA's are converted to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addVectors(v1, v2, insertionPoint = 1L, normalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addVectors_+3A_v1">v1</code>, <code id="addVectors_+3A_v2">v2</code></td>
<td>
<p>numeric vectors</p>
</td></tr>
<tr><td><code id="addVectors_+3A_insertionpoint">insertionPoint</code></td>
<td>
<p>the index of element in vector 1 at which vector 2 will
be inserted (any integer, can also be negative)</p>
</td></tr>
<tr><td><code id="addVectors_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, the output is normalized to range from -1 to +1</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+soundgen">soundgen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v1 = 1:6
v2 = rep(100, 3)
addVectors(v1, v2, insertionPoint = 5, normalize = FALSE)
addVectors(v1, v2, insertionPoint = -4, normalize = FALSE)
addVectors(v1, rep(100, 15), insertionPoint = -4, normalize = FALSE)
# note the asymmetry: insertionPoint refers to the first arg
addVectors(v2, v1, insertionPoint = -4, normalize = FALSE)

v3 = rep(100, 15)
addVectors(v1, v3, insertionPoint = -4, normalize = FALSE)
addVectors(v2, v3, insertionPoint = 7, normalize = FALSE)
addVectors(1:6, 3:6, insertionPoint = 3, normalize = FALSE)
</code></pre>

<hr>
<h2 id='analyze'>Acoustic analysis</h2><span id='topic+analyze'></span>

<h3>Description</h3>

<p>Acoustic analysis of one or more sounds: pitch tracking, basic spectral
characteristics, formants, estimated loudness (see
<code><a href="#topic+getLoudness">getLoudness</a></code>), roughness (see <code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code>),
novelty (see <code><a href="#topic+ssm">ssm</a></code>), etc. The default values of arguments are
optimized for human non-linguistic vocalizations. See
vignette('acoustic_analysis', package = 'soundgen') for details. The defaults
and reasonable ranges of all arguments can be found in
<code><a href="#topic+defaults_analyze">defaults_analyze</a></code>. For high-precision work, first extract and
manually correct pitch contours with <code><a href="#topic+pitch_app">pitch_app</a></code>, PRAAT, or
whatever, and then run <code>analyze(pitchManual = ...)</code> with these manual
contours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyze(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  dynamicRange = 80,
  silence = 0.04,
  windowLength = 50,
  step = windowLength/2,
  overlap = 50,
  specType = c("spectrum", "reassign", "spectralDerivative")[1],
  wn = "gaussian",
  zp = 0,
  cutFreq = NULL,
  nFormants = 3,
  formants = list(),
  loudness = list(SPL_measured = 70),
  roughness = list(msType = "1D", windowLength = 25, step = 2, amRes = 5),
  novelty = list(input = "melspec", kernelLen = 100),
  pitchMethods = c("dom", "autocor"),
  pitchManual = NULL,
  entropyThres = 0.6,
  pitchFloor = 75,
  pitchCeiling = 3500,
  priorMean = 300,
  priorSD = 6,
  priorAdapt = TRUE,
  nCands = 1,
  minVoicedCands = NULL,
  pitchDom = list(domThres = 0.1, domSmooth = 220),
  pitchAutocor = list(autocorThres = 0.7, autocorSmooth = 7, autocorUpsample = 25,
    autocorBestPeak = 0.975, interpol = "sinc"),
  pitchCep = list(cepThres = 0.75, cepZp = 0),
  pitchSpec = list(specThres = 0.05, specPeak = 0.25, specHNRslope = 0.8, specSmooth =
    150, specMerge = 0.1, specSinglePeakCert = 0.4, specRatios = 3),
  pitchHps = list(hpsNum = 5, hpsThres = 0.1, hpsNorm = 2, hpsPenalty = 2),
  pitchZc = list(zcThres = 0.1, zcWin = 5),
  harmHeight = list(harmThres = 3, harmTol = 0.25, harmPerSel = 5),
  subh = list(method = c("cep", "pitchCands", "harm")[1], nSubh = 5, tol = 0.05, nHarm =
    5, harmThres = 12, harmTol = 0.25, amRange = c(10, 200)),
  flux = list(thres = 0.15, smoothWin = 100),
  amRange = c(10, 200),
  fmRange = c(5, 1000/step/2),
  shortestSyl = 20,
  shortestPause = 60,
  interpol = list(win = 75, tol = 0.3, cert = 0.3),
  pathfinding = c("none", "fast", "slow")[2],
  annealPars = list(maxit = 5000, temp = 1000),
  certWeight = 0.5,
  snakeStep = 0,
  snakePlot = FALSE,
  smooth = 1,
  smoothVars = c("pitch", "dom"),
  summaryFun = c("mean", "median", "sd"),
  invalidArgAction = c("adjust", "abort", "ignore")[1],
  reportEvery = NULL,
  cores = 1,
  plot = FALSE,
  osc = "linear",
  showLegend = TRUE,
  savePlots = NULL,
  pitchPlot = list(col = rgb(0, 0, 1, 0.75), lwd = 3, showPrior = TRUE),
  extraContour = NULL,
  ylim = NULL,
  xlab = "Time",
  ylab = NULL,
  main = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="analyze_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="analyze_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="analyze_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="analyze_+3A_from">from</code>, <code id="analyze_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="analyze_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="analyze_+3A_silence">silence</code></td>
<td>
<p>(0 to 1 as proportion of max amplitude) frames with RMS
amplitude below <code>silence * max_ampl adjusted by scale</code> are not
analyzed at all.</p>
</td></tr>
<tr><td><code id="analyze_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="analyze_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="analyze_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="analyze_+3A_spectype">specType</code></td>
<td>
<p>plot the original FFT ('spectrum'), reassigned spectrogram
('reassigned'), or spectral derivative ('spectralDerivative')</p>
</td></tr>
<tr><td><code id="analyze_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="analyze_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id="analyze_+3A_cutfreq">cutFreq</code></td>
<td>
<p>if specified, spectral descriptives (peakFreq, specCentroid,
specSlope, and quartiles) are calculated only between <code>cutFreq[1]</code> and
<code>cutFreq[2]</code>, Hz. If a single number is given, analyzes frequencies
from 0 to <code>cutFreq</code>. For ex., when analyzing recordings with varying
sampling rates, set to half the lowest sampling rate to make the spectra
more comparable. Note that &quot;entropyThres&quot; applies only to this frequency
range, which also affects which frames will not be analyzed with
pitchAutocor.</p>
</td></tr>
<tr><td><code id="analyze_+3A_nformants">nFormants</code></td>
<td>
<p>the number of formants to extract per STFT frame (0 = no
formant analysis, NULL = as many as possible)</p>
</td></tr>
<tr><td><code id="analyze_+3A_formants">formants</code></td>
<td>
<p>a list of arguments passed to
<code><a href="phonTools.html#topic+findformants">findformants</a></code> - an external function called to
perform LPC analysis</p>
</td></tr>
<tr><td><code id="analyze_+3A_loudness">loudness</code></td>
<td>
<p>a list of parameters passed to <code><a href="#topic+getLoudness">getLoudness</a></code> for
measuring subjective loudness, namely <code>SPL_measured, Pref,
spreadSpectrum</code>. NULL = skip loudness analysis</p>
</td></tr>
<tr><td><code id="analyze_+3A_roughness">roughness</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code> for measuring roughness. NULL = skip
roughness analysis</p>
</td></tr>
<tr><td><code id="analyze_+3A_novelty">novelty</code></td>
<td>
<p>a list of parameters passed to <code><a href="#topic+ssm">ssm</a></code> for measuring
spectral novelty. NULL = skip novelty analysis</p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchmethods">pitchMethods</code></td>
<td>
<p>methods of pitch estimation to consider for determining
pitch contour: 'autocor' = autocorrelation (~PRAAT), 'cep' = cepstral,
'spec' = spectral (~BaNa), 'dom' = lowest dominant frequency band, 'hps' =
harmonic product spectrum, NULL = no pitch analysis</p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchmanual">pitchManual</code></td>
<td>
<p>manually corrected pitch contour. For a single sound,
provide a numeric vector of any length. For multiple sounds, provide a
dataframe with columns &quot;file&quot; and &quot;pitch&quot; (or path to a csv file) as
returned by <code><a href="#topic+pitch_app">pitch_app</a></code>, ideally with the same windowLength and
step as in current call to analyze. A named list with pitch vectors per
file is also OK (eg as returned by pitch_app)</p>
</td></tr>
<tr><td><code id="analyze_+3A_entropythres">entropyThres</code></td>
<td>
<p>pitch tracking is only performed for frames with Weiner
entropy below <code>entropyThres</code>, but other spectral descriptives are
still calculated (NULL = analyze everything)</p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchfloor">pitchFloor</code>, <code id="analyze_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id="analyze_+3A_priormean">priorMean</code>, <code id="analyze_+3A_priorsd">priorSD</code></td>
<td>
<p>specifies the mean (Hz) and standard deviation
(semitones) of gamma distribution describing our prior knowledge about the
most likely pitch values for this file. For ex., <code>priorMean = 300,
priorSD = 6</code> gives a prior with mean = 300 Hz and SD = 6 semitones (half
an octave). To avoid using any priors, set <code>priorMean = NA, priorAdapt
= FALSE</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_prioradapt">priorAdapt</code></td>
<td>
<p>adaptive second-pass prior: if TRUE, optimal pitch contours
are estimated first with a prior determined by <code>priorMean,priorSD</code>, and
then with a new prior adjusted according to this first-pass pitch contour</p>
</td></tr>
<tr><td><code id="analyze_+3A_ncands">nCands</code></td>
<td>
<p>maximum number of pitch candidates per method, normally 1...4
(except for <code>dom</code>, which returns at most one candidate per frame)</p>
</td></tr>
<tr><td><code id="analyze_+3A_minvoicedcands">minVoicedCands</code></td>
<td>
<p>minimum number of pitch candidates that have to be
defined to consider a frame voiced (if NULL, defaults to 2 if <code>dom</code> is
among other candidates and 1 otherwise)</p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchdom">pitchDom</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
lowest dominant frequency band or &quot;dom&quot; method; see details and
<code>?soundgen:::getDom</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchautocor">pitchAutocor</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
autocorrelation or &quot;autocor&quot; method; see details and
<code>?soundgen:::getPitchAutocor</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchcep">pitchCep</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
cepstrum or &quot;cep&quot; method; see details and <code>?soundgen:::getPitchCep</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchspec">pitchSpec</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
BaNa or &quot;spec&quot; method; see details and <code>?soundgen:::getPitchSpec</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchhps">pitchHps</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
harmonic product spectrum or &quot;hps&quot; method; see details and
<code>?soundgen:::getPitchHps</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchzc">pitchZc</code></td>
<td>
<p>a list of control parameters for pitch tracking based on zero
crossings in bandpass-filtered audio or &quot;zc&quot; method; see
<code><a href="#topic+getPitchZc">getPitchZc</a></code></p>
</td></tr>
<tr><td><code id="analyze_+3A_harmheight">harmHeight</code></td>
<td>
<p>a list of control parameters for estimating how high
harmonics reach in the spectrum; see details and <code>?soundgen:::harmHeight</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_subh">subh</code></td>
<td>
<p>a list of control parameters for estimating the strength of
subharmonics per frame - that is, spectral energy at integer ratios of f0:
see <code>?soundgen:::getSHR</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_flux">flux</code></td>
<td>
<p>a list of control parameters for calculating feature-based flux
(not spectral flux) passed to <code><a href="#topic+getFeatureFlux">getFeatureFlux</a></code></p>
</td></tr>
<tr><td><code id="analyze_+3A_amrange">amRange</code></td>
<td>
<p>target range of frequencies for amplitude modulation, Hz: a
vector of length 2 (affects both <code>amMsFreq</code> and <code>amEnvFreq</code>)</p>
</td></tr>
<tr><td><code id="analyze_+3A_fmrange">fmRange</code></td>
<td>
<p>target range of frequencies for analyzing frequency
modulation, Hz (<code>fmFreq</code>): a vector of length 2</p>
</td></tr>
<tr><td><code id="analyze_+3A_shortestsyl">shortestSyl</code></td>
<td>
<p>the smallest length of a voiced segment (ms) that
constitutes a voiced syllable (shorter segments will be replaced by NA, as
if unvoiced)</p>
</td></tr>
<tr><td><code id="analyze_+3A_shortestpause">shortestPause</code></td>
<td>
<p>the smallest gap between voiced syllables (ms): large
value = interpolate and merge, small value = treat as separate syllables
separated by an unvoiced gap</p>
</td></tr>
<tr><td><code id="analyze_+3A_interpol">interpol</code></td>
<td>
<p>a list of parameters (currently <code>win, tol, cert</code>) passed
to <code>soundgen:::pathfinder</code> for interpolating missing pitch candidates
(NULL = no interpolation)</p>
</td></tr>
<tr><td><code id="analyze_+3A_pathfinding">pathfinding</code></td>
<td>
<p>method of finding the optimal path through pitch
candidates: 'none' = best candidate per frame, 'fast' = simple heuristic,
'slow' = annealing. See <code>soundgen:::pathfinder</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_annealpars">annealPars</code></td>
<td>
<p>a list of control parameters for postprocessing of
pitch contour with SANN algorithm of <code><a href="stats.html#topic+optim">optim</a></code>. This is
only relevant if <code>pathfinding = 'slow'</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id="analyze_+3A_snakestep">snakeStep</code></td>
<td>
<p>optimized path through pitch candidates is further
processed to minimize the elastic force acting on pitch contour. To
disable, set <code>snakeStep = 0</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_snakeplot">snakePlot</code></td>
<td>
<p>if TRUE, plots the snake</p>
</td></tr>
<tr><td><code id="analyze_+3A_smooth">smooth</code>, <code id="analyze_+3A_smoothvars">smoothVars</code></td>
<td>
<p>if <code>smooth</code> is a positive number, outliers of
the variables in <code>smoothVars</code> are adjusted with median smoothing.
<code>smooth</code> of 1 corresponds to a window of ~100 ms and tolerated
deviation of ~4 semitones. To disable, set <code>smooth = 0</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic,
eg &quot;c('mean', 'sd')&quot;; user-defined functions are fine (see examples); NAs
are omitted automatically for mean/median/sd/min/max/range/sum, otherwise
take care of NAs yourself</p>
</td></tr>
<tr><td><code id="analyze_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>defaults_analyze</code>: 'adjust' = reset to default value,
'abort' = stop execution, 'ignore' = throw a warning and continue (may
crash)</p>
</td></tr>
<tr><td><code id="analyze_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="analyze_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="analyze_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a spectrogram with pitch contour overlaid</p>
</td></tr>
<tr><td><code id="analyze_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id="analyze_+3A_showlegend">showLegend</code></td>
<td>
<p>if TRUE, adds a legend with pitch tracking methods</p>
</td></tr>
<tr><td><code id="analyze_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="analyze_+3A_pitchplot">pitchPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the final
pitch contour. Set to <code>list(type = 'n')</code> to suppress</p>
</td></tr>
<tr><td><code id="analyze_+3A_extracontour">extraContour</code></td>
<td>
<p>name of an output variable to overlap on the pitch
contour plot, eg 'peakFreq' or 'loudness'; can also be a list with extra
graphical parameters, eg <code>extraContour = list(x = 'harmHeight', col =
'red')</code></p>
</td></tr>
<tr><td><code id="analyze_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="analyze_+3A_xlab">xlab</code>, <code id="analyze_+3A_ylab">ylab</code>, <code id="analyze_+3A_main">main</code></td>
<td>
<p>plotting parameters</p>
</td></tr>
<tr><td><code id="analyze_+3A_width">width</code>, <code id="analyze_+3A_height">height</code>, <code id="analyze_+3A_units">units</code>, <code id="analyze_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
<tr><td><code id="analyze_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each pitch tracker is controlled by its own list of settings, as follows:
</p>
<dl>
<dt><code>pitchDom</code> (lowest dominant frequency band)</dt><dd>
<ul>
<li><p><code>domThres</code> (0 to 1) to find the lowest dominant frequency band, we
do short-term FFT and take the lowest frequency with amplitude at least
domThres </p>
</li>
<li><p><code>domSmooth</code> the width of smoothing interval (Hz) for
finding <code>dom</code></p>
</li></ul>
</dd> <dt><code>pitchAutocor</code> (autocorrelation)</dt><dd>
<ul>
<li> <p><code>autocorThres</code> voicing threshold (unitless, ~0 to 1)
</p>
</li>
<li><p><code>autocorSmooth</code> the width of smoothing interval (in bins) for
finding peaks in the autocorrelation function. Defaults to 7 for sampling
rate 44100 and smaller odd numbers for lower values of sampling rate </p>
</li>
<li>
<p><code>autocorUpsample</code> upsamples acf to this resolution (Hz) to improve
accuracy in high frequencies </p>
</li>
<li> <p><code>autocorBestPeak</code> amplitude of the
lowest best candidate relative to the absolute max of the acf </p>
</li></ul>
</dd>
<dt><code>pitchCep</code> (cepstrum)</dt><dd><ul>
<li> <p><code>cepThres</code> voicing
threshold (unitless, ~0 to 1) </p>
</li>
<li> <p><code>cepZp</code> zero-padding of the spectrum
used for cepstral pitch detection (final length of spectrum after
zero-padding in points, e.g. 2 ^ 13)</p>
</li></ul>
</dd> <dt> <code>pitchSpec</code> (ratio of
harmonics - BaNa algorithm)</dt><dd> <ul>
<li> <p><code>specThres</code> voicing
threshold (unitless, ~0 to 1) </p>
</li>
<li> <p><code>specPeak,specHNRslope</code> when looking
for putative harmonics in the spectrum, the threshold for peak detection is
calculated as <code>specPeak * (1 - HNR * specHNRslope)</code> </p>
</li>
<li><p> specSmooth the
width of window for detecting peaks in the spectrum, Hz </p>
</li>
<li>
<p><code>specMerge</code> pitch candidates within <code>specMerge</code> semitones are
merged with boosted certainty </p>
</li>
<li> <p><code>specSinglePeakCert</code> (0 to 1) if F0
is calculated based on a single harmonic ratio (as opposed to several ratios
converging on the same candidate), its certainty is taken to be
<code>specSinglePeakCert</code></p>
</li></ul>
</dd> <dt> pitchHps (harmonic product
spectrum)</dt><dd><ul>
<li> <p><code>hpsNum</code> the number of times to downsample the
spectrum </p>
</li>
<li> <p><code>hpsThres</code> voicing threshold (unitless, ~0 to 1) </p>
</li>
<li>
<p><code>hpsNorm</code> the amount of inflation of hps pitch certainty (0 = none)
</p>
</li>
<li> <p><code>hpsPenalty</code> the amount of penalizing hps candidates in low
frequencies (0 = none) </p>
</li></ul>
</dd> </dl>
<p>  Each of these lists also accepts graphical
parameters that affect how pitch candidates are plotted, eg <code>pitchDom =
list(domThres = .5, col = 'yellow')</code>. Other arguments that are lists of
subroutine-specific settings include: </p>
 <dl>
<dt><code>harmonicHeight</code>
(finding how high harmonics reach in the spectrum)</dt><dd><ul>
<li>
<p><code>harmThres</code> minimum height of spectral peak, dB </p>
</li>
<li> <p><code>harmPerSel</code>
the number of harmonics per sliding selection </p>
</li>
<li> <p><code>harmTol</code> maximum
tolerated deviation of peak frequency from multiples of f0, proportion of f0
</p>
</li></ul>
</dd> </dl>



<h3>Value</h3>

<p>Returns a list with <code>$detailed</code> frame-by-frame descriptives and
a <code>$summary</code> with one row per file, as determined by <code>summaryFun</code>
(e.g., mean / median / SD of each acoustic variable across all STFT
frames). Output measures include: </p>
<dl>
<dt>duration</dt><dd><p>total duration,
s</p>
</dd> <dt>duration_noSilence</dt><dd><p>duration from the beginning of the first
non-silent STFT frame to the end of the last non-silent STFT frame, s (NB:
depends strongly on <code>windowLength</code> and <code>silence</code> settings)</p>
</dd>
<dt>time</dt><dd><p>time of the middle of each frame (ms)</p>
</dd>
<dt>amEnvFreq,amEnvDep</dt><dd><p>frequency (Hz) and
depth (0 to 1) of amplitude modulation estimated from a smoothed amplitude
envelope</p>
</dd> <dt>amMsFreq,amMsPurity</dt><dd><p>frequency and purity of amplitude
modulation estimated via <code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code></p>
</dd>
<dt>ampl</dt><dd><p>root mean square of amplitude per frame, calculated as
sqrt(mean(frame ^ 2))</p>
</dd> <dt>ampl_noSilence</dt><dd><p>same as <code>ampl</code>, but
ignoring silent frames</p>
</dd> <dt>CPP</dt><dd><p>Cepstral Peak Prominence, dB (a measure
of pitch quality, the ratio of the highest peak in the cepstrum to the
regression line drawn through it)</p>
</dd> <dt>dom</dt><dd><p>lowest dominant frequency
band (Hz) (see &quot;Pitch tracking methods / Dominant frequency&quot; in the
vignette)</p>
</dd> <dt>entropy</dt><dd><p>Weiner entropy of the spectrum of the current
frame. Close to 0: pure tone or tonal sound with nearly all energy in
harmonics; close to 1: white noise</p>
</dd> <dt>entropySh</dt><dd><p>Normalized Shannon
entropy of the spectrum of the current frame: 0 = pure tone, 1 = white
noise</p>
</dd> <dt>f1_freq, f1_width, ...</dt><dd><p>the frequency and bandwidth of the
first nFormants formants per STFT frame, as calculated by
phonTools::findformants</p>
</dd> <dt>flux</dt><dd><p>feature-based flux, the rate of change
in acoustic features such as pitch, HNR, etc. (0 = none, 1 = max); &quot;epoch&quot;
is an audio segment between two peaks of flux that exceed a threshold of
<code>flux = list(thres = ...)</code> (listed in output$detailed only)</p>
</dd>
<dt>fmFreq</dt><dd><p>frequency of frequency modulation (FM) such as vibrato or
jitter, Hz</p>
</dd> <dt>fmDep</dt><dd><p>depth of FM, semitones</p>
</dd> <dt>fmPurity</dt><dd><p>purity or
dominance of the main FM frequency (fmFreq), 0 to 1</p>
</dd> <dt>harmEnergy</dt><dd><p>the
amount of energy in upper harmonics, namely the ratio of total spectral
mass above 1.25 x F0 to the total spectral mass below 1.25 x F0 (dB)</p>
</dd>
<dt>harmHeight</dt><dd><p>how high harmonics reach in the spectrum, based on the
best guess at pitch (or the manually provided pitch values)</p>
</dd>
<dt>HNR</dt><dd><p>harmonics-to-noise ratio (dB), a measure of harmonicity returned
by soundgen:::getPitchAutocor (see &quot;Pitch tracking methods /
Autocorrelation&quot;). If HNR = 0 dB, there is as much energy in harmonics as
in noise</p>
</dd> <dt>loudness</dt><dd><p>subjective loudness, in sone, corresponding to
the chosen SPL_measured - see <code><a href="#topic+getLoudness">getLoudness</a></code></p>
</dd>
<dt>novelty</dt><dd><p>spectral novelty - a measure of how variable the spectrum is
on a particular time scale, as estimated by <code><a href="#topic+ssm">ssm</a></code></p>
</dd>
<dt>peakFreq</dt><dd><p>the frequency with maximum spectral power (Hz)</p>
</dd>
<dt>pitch</dt><dd><p>post-processed pitch contour based on all F0 estimates</p>
</dd>
<dt>quartile25, quartile50, quartile75</dt><dd><p>the 25th, 50th, and 75th
quantiles of the spectrum of voiced frames (Hz)</p>
</dd> <dt>roughness</dt><dd><p>the
amount of amplitude modulation, see modulationSpectrum</p>
</dd>
<dt>specCentroid</dt><dd><p>the center of gravity of the frameâs spectrum, first
spectral moment (Hz)</p>
</dd> <dt>specSlope</dt><dd><p>the slope of linear regression fit
to the spectrum below cutFreq (dB/kHz)</p>
</dd> <dt>subDep</dt><dd><p>estimated depth of
subharmonics per frame: 0 = none, 1 = as strong as f0. NB: this depends
critically on accurate pitch tracking</p>
</dd> <dt>subRatio</dt><dd><p>the ratio of f0 to
subharmonics frequency with strength subDep: 2 = period doubling, 3 = f0 /
3, etc.</p>
</dd> <dt>voiced</dt><dd><p>is the current STFT frame voiced? TRUE / FALSE</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+pitch_app">pitch_app</a></code> <code><a href="#topic+getLoudness">getLoudness</a></code>
<code><a href="#topic+segment">segment</a></code> <code><a href="#topic+getRMS">getRMS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound = soundgen(sylLen = 300, pitch = c(500, 400, 600),
  noise = list(time = c(0, 300), value = c(-40, 0)),
  temperature = 0.001,
  addSilence = 50)  # NB: always have some silence before and after!!!
# playme(sound, 16000)
a = analyze(sound, samplingRate = 16000, plot = TRUE)
str(a$detailed)  # frame-by-frame
a$summary        # summary per sound

## Not run: 
# For maximum processing speed (just basic spectral descriptives):
a = analyze(sound, samplingRate = 16000,
  plot = FALSE,         # no plotting
  pitchMethods = NULL,  # no pitch tracking
  loudness = NULL,      # no loudness analysis
  novelty = NULL,       # no novelty analysis
  roughness = NULL,     # no roughness analysis
  nFormants = 0         # no formant analysis
)

# Take a sound hard to analyze b/c of subharmonics and jitter
sound2 = soundgen(sylLen = 900, pitch = list(
  time = c(0, .3, .8, 1), value = c(300, 900, 400, 2300)),
  noise = list(time = c(0, 900), value = c(-40, -20)),
  subDep = 10, jitterDep = 0.5,
  temperature = 0.001, samplingRate = 44100, pitchSamplingRate = 44100)
# playme(sound2, 44100)
a2 = analyze(sound2, samplingRate = 44100, priorSD = 24,
             plot = TRUE, ylim = c(0, 5))

# Compare the available pitch trackers
analyze(sound2, 44100,
  pitchMethods = c('dom', 'autocor', 'spec', 'cep', 'hps', 'zc'),
  # don't use priors to see weird pitch candidates better
  priorMean = NA, priorAdapt = FALSE,
  plot = TRUE, yScale = 'bark')

# Fancy plotting options:
a = analyze(sound2, samplingRate = 44100, plot = TRUE,
  xlab = 'Time, ms', colorTheme = 'seewave',
  contrast = .5, ylim = c(0, 4), main = 'My plot',
  pitchMethods = c('dom', 'autocor', 'spec', 'hps', 'cep'),
  priorMean = NA,  # no prior info at all
  pitchDom = list(col = 'red', domThres = .25),
  pitchPlot = list(col = 'black', pch = 9, lty = 3, lwd = 3),
  extraContour = list(x = 'peakFreq', type = 'b', pch = 4, col = 'brown'),
  osc = 'dB', heights = c(2, 1))

# Analyze an entire folder in one go, saving spectrograms with pitch contours
# plus an html file for easy access
s2 = analyze('~/Downloads/temp',
  savePlots = '',  # save in the same folder as audio
  showLegend = TRUE, yScale = 'bark',
  width = 20, height = 12,
  units = 'cm', res = 300, ylim = c(0, 5),
  cores = 4)  # use multiple cores to speed up processing
s2$summary[, 1:5]

# Different options for summarizing the output
a = analyze(sound2, 44100,
            summaryFun = c('mean', 'range'))
a$summary  # one row per sound
# ...with custom summaryFun, eg time of peak relative to duration (0 to 1)
timePeak = function(x) which.max(x) / length(x)  # without omitting NAs
timeTrough = function(x) which.min(x) / length(x)
a = analyze(sound2, samplingRate = 16000,
            summaryFun = c('mean', 'timePeak', 'timeTrough'))
colnames(a$summary)

# Analyze a selection rather than the whole sound
a = analyze(sound, samplingRate = 16000, from = .1, to = .3, plot = TRUE)

# Use only a range of frequencies when calculating spectral descriptives
# (ignore everything below 100 Hz and above 8000 Hz as irrelevant noise)
a = analyze(sound, samplingRate = 16000, cutFreq = c(100, 8000))

## Amplitude and loudness: analyze() should give the same results as
# dedicated functions getRMS() / getLoudness()
# Create 1 kHz tone
samplingRate = 16000; dur_ms = 50
sound3 = sin(2*pi*1000/samplingRate*(1:(dur_ms/1000*samplingRate)))
a1 = analyze(sound3, samplingRate = samplingRate, scale = 1,
             windowLength = 25, overlap = 50,
             loudness = list(SPL_measured = 40),
             pitchMethods = NULL, plot = FALSE)
a1$detailed$loudness  # loudness per STFT frame (1 sone by definition)
getLoudness(sound3, samplingRate = samplingRate, windowLength = 25,
            overlap = 50, SPL_measured = 40, scale = 1)$loudness
a1$detailed$ampl  # RMS amplitude per STFT frame
getRMS(sound3, samplingRate = samplingRate, windowLength = 25,
       overlap = 50, scale = 1)$detailed
# or even simply: sqrt(mean(sound3 ^ 2))

# The same sound as above, but with half the amplitude
a_half = analyze(sound3 / 2, samplingRate = samplingRate, scale = 1,
                 windowLength = 25, overlap = 50,
                 loudness = list(SPL_measured = 40),
                 pitchMethods = NULL, plot = FALSE)
a1$detailed$ampl / a_half$detailed$ampl  # rms amplitude halved
a1$detailed$loudness/ a_half$detailed$loudness
# loudness is not a linear function of amplitude

# Analyzing ultrasounds (slow but possible, just adjust pitchCeiling)
s = soundgen(sylLen = 100, addSilence = 10,
  pitch = c(25000, 35000, 30000),
  formants = NA, rolloff = -12, rolloffKHz = 0,
  pitchSamplingRate = 350000, samplingRate = 350000, windowLength = 5,
  pitchCeiling = 45000, invalidArgAction = 'ignore',
  plot = TRUE)
# s is a bat-like ultrasound inaudible to humans
a = analyze(
  s, 350000, plot = TRUE,
  pitchFloor = 10000, pitchCeiling = 90000, priorMean = NA,
  pitchMethods = c('autocor', 'spec'),
  # probably shouldn't use pitchMethod = "dom" b/c of likely low-freq noise
  windowLength = 5, step = 2.5,
  shortestSyl = 10, shortestPause = 10,  # again, very short sounds
  interpol = list(win = 10),  # again, very short sounds
  smooth = 0.1,  # might need less smoothing if very rapid f0 changes
  nFormants = 0, loudness = NULL, roughness = NULL, novelty = NULL)
# NB: ignore formants and loudness estimates for such non-human sounds

# download 260 sounds from Anikin &amp; Persson (2017)
# http://cogsci.se/publications/anikin-persson_2017_nonlinguistic-vocs/260sounds_wav.zip
# unzip them into a folder, say '~/Downloads/temp'
myfolder = '~/Downloads/temp'  # 260 .wav files live here
s = analyze(myfolder)  # ~ 10-20 minutes!
# s = write.csv(s, paste0(myfolder, '/temp.csv'))  # save a backup

# Check accuracy: import manually verified pitch values (our "key")
# pitchManual   # "ground truth" of mean pitch per sound
# pitchContour  # "ground truth" of complete pitch contours per sound
files_manual = paste0(names(pitchManual), '.wav')
idx = match(s$file, files_manual)  # in case the order is wrong
s$key = pitchManual[idx]

# Compare manually verified mean pitch with the output of analyze:
cor(s$key, s$summary$pitch_median, use = 'pairwise.complete.obs')
plot(s$key, s$summary$pitch_median, log = 'xy')
abline(a=0, b=1, col='red')

# Re-running analyze with manually corrected contours gives correct
pitch-related descriptives like amplVoiced and harmonics (NB: you get it "for
free" when running pitch_app)
s1 = analyze(myfolder, pitchManual = pitchContour)
plot(s$summary$harmonics_median, s1$summary$harmonics_median)
abline(a=0, b=1, col='red')

## End(Not run)
</code></pre>

<hr>
<h2 id='analyzeFrame'>Analyze fft frame</h2><span id='topic+analyzeFrame'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyzeFrame(
  frame,
  bin,
  freqs,
  autoCorrelation = NULL,
  samplingRate,
  cutFreq,
  trackPitch = TRUE,
  pitchMethods = c("dom", "autocor"),
  nCands,
  pitchDom = list(),
  pitchAutocor = list(),
  pitchCep = list(),
  pitchSpec = list(),
  pitchHps = list(),
  pitchFloor,
  pitchCeiling
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="analyzeFrame_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_autocorrelation">autoCorrelation</code></td>
<td>
<p>pre-calculated autocorrelation of the input frame
(computationally more efficient than to do it here)</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate (Hz)</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_cutfreq">cutFreq</code></td>
<td>
<p>if specified, spectral descriptives (peakFreq, specCentroid,
specSlope, and quartiles) are calculated only between <code>cutFreq[1]</code> and
<code>cutFreq[2]</code>, Hz. If a single number is given, analyzes frequencies
from 0 to <code>cutFreq</code>. For ex., when analyzing recordings with varying
sampling rates, set to half the lowest sampling rate to make the spectra
more comparable. Note that &quot;entropyThres&quot; applies only to this frequency
range, which also affects which frames will not be analyzed with
pitchAutocor.</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_trackpitch">trackPitch</code></td>
<td>
<p>if TRUE, attempt to find F0 in this frame (FALSE if entropy
is above some threshold - specified in <code><a href="#topic+analyze">analyze</a></code>)</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchmethods">pitchMethods</code></td>
<td>
<p>methods of pitch estimation to consider for determining
pitch contour: 'autocor' = autocorrelation (~PRAAT), 'cep' = cepstral,
'spec' = spectral (~BaNa), 'dom' = lowest dominant frequency band, 'hps' =
harmonic product spectrum, NULL = no pitch analysis</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_ncands">nCands</code></td>
<td>
<p>maximum number of pitch candidates per method, normally 1...4
(except for <code>dom</code>, which returns at most one candidate per frame)</p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchdom">pitchDom</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
lowest dominant frequency band or &quot;dom&quot; method; see details and
<code>?soundgen:::getDom</code></p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchautocor">pitchAutocor</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
autocorrelation or &quot;autocor&quot; method; see details and
<code>?soundgen:::getPitchAutocor</code></p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchcep">pitchCep</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
cepstrum or &quot;cep&quot; method; see details and <code>?soundgen:::getPitchCep</code></p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchspec">pitchSpec</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
BaNa or &quot;spec&quot; method; see details and <code>?soundgen:::getPitchSpec</code></p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchhps">pitchHps</code></td>
<td>
<p>a list of control parameters for pitch tracking using the
harmonic product spectrum or &quot;hps&quot; method; see details and
<code>?soundgen:::getPitchHps</code></p>
</td></tr>
<tr><td><code id="analyzeFrame_+3A_pitchfloor">pitchFloor</code>, <code id="analyzeFrame_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs the heavy lifting of pitch tracking and acoustic
analysis in general: it takes the spectrum of a single fft frame as input and
analyzes it.
</p>


<h3>Value</h3>

<p>Returns a list with two components: $pitchCands_frame contains pitch
candidates for the frame, and $summaries contains other acoustic predictors
like HNR, specSlope, etc.
</p>

<hr>
<h2 id='annotation_app'>Annotation app</h2><span id='topic+annotation_app'></span>

<h3>Description</h3>

<p>Starts a shiny app for annotating audio. This is a simplified and faster
version of <code><a href="#topic+formant_app">formant_app</a></code> intended only for making annotations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>annotation_app()
</code></pre>


<h3>Value</h3>

<p>Every time a new annotation is added, the app creates a backup csv
file and creates or updates a global object called &quot;my_annot&quot;, which
contains all the annotations. When the app is terminated, it also returns
the results as a dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ann = annotation_app()  # runs in default browser such as Firefox or Chrome

# To change system default browser, run something like:
options('browser' = '/usr/bin/firefox')  # path to the executable on Linux

## End(Not run)
</code></pre>

<hr>
<h2 id='audSpectrogram'>Auditory spectrogram</h2><span id='topic+audSpectrogram'></span>

<h3>Description</h3>

<p>Produces an auditory spectrogram by convolving the sound with a bank of
bandpass filters. The main difference from STFT is that we don't window the
signal and de facto get variable temporal resolution in different frequency
channels, as with a wavelet transform. The key settings are
<code>filterType</code>, <code>nFilters</code>, and <code>yScale</code>, which determine the
type, number, and spacing of the filters, respectively. Gammatone filters
were designed as a simple approximation of human perception - see
<code><a href="seewave.html#topic+gammatone">gammatone</a></code> and Slaney 1993 &quot;An Efficient Implementation
of the PattersonâHoldsworth Auditory Filter Bank&quot;. Butterworth or Chebyshev
filters are not meant to model perception, but can be useful for quickly
plotting a sound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audSpectrogram(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  step = 1,
  dynamicRange = 80,
  filterType = c("butterworth", "chebyshev", "gammatone")[1],
  nFilters = 128,
  nFilters_oct = NULL,
  filterOrder = if (filterType == "gammatone") 4 else 3,
  bandwidth = NULL,
  bandwidthMult = 1,
  minFreq = 20,
  maxFreq = samplingRate/2,
  minBandwidth = 10,
  output = c("audSpec", "audSpec_processed", "filterbank", "filterbank_env", "roughness"),
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  plotFilters = FALSE,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  yScale = c("bark", "mel", "ERB", "log")[1],
  contrast = 0.2,
  brightness = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="audSpectrogram_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_from">from</code>, <code id="audSpectrogram_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_step">step</code></td>
<td>
<p>step, ms (determines time resolution of the plot, but not of the
returned envelopes per channel). step = NULL means no downsampling at all
(ncol of output = length of input audio)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_filtertype">filterType</code></td>
<td>
<p>&quot;butterworth&quot; = Butterworth filter
<code><a href="signal.html#topic+butter">butter</a></code>, &quot;chebyshev&quot; = Chebyshev filter
<code><a href="signal.html#topic+butter">butter</a></code>, &quot;gammatone&quot; =
<code><a href="seewave.html#topic+gammatone">gammatone</a></code></p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_nfilters">nFilters</code></td>
<td>
<p>the number of filters between <code>minFreq</code> and
<code>maxFreq</code> (determines frequency resolution, while <code>yScale</code>
determines the location of center frequencies)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_nfilters_oct">nFilters_oct</code></td>
<td>
<p>an alternative way to specify frequency resolution: the
number of filters per octave</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_filterorder">filterOrder</code></td>
<td>
<p>filter order (defaults to 4 for gammatones, 3 otherwise)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_bandwidth">bandwidth</code></td>
<td>
<p>filter bandwidth, octaves. If NULL, defaults to ERB
bandwidths as in <code><a href="seewave.html#topic+gammatone">gammatone</a></code></p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_bandwidthmult">bandwidthMult</code></td>
<td>
<p>a scaling factor for all bandwidths (1 = no effect)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_minfreq">minFreq</code>, <code id="audSpectrogram_+3A_maxfreq">maxFreq</code></td>
<td>
<p>the range of frequencies to analyze. If the
spectrogram looks empty, try increasing minFreq - the lowest filters are
prone to returning very large values</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_minbandwidth">minBandwidth</code></td>
<td>
<p>minimum filter bandwidth, Hz (otherwise filters may
become too narrow when nFilters is high; has no effect if filterType =
'gammatone')</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_output">output</code></td>
<td>
<p>a list of measures to return. Defaults to everything, but this
takes a lot of RAM, so shorten to what's needed if analyzing many files at
once</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_plotfilters">plotFilters</code></td>
<td>
<p>if TRUE, plots the filters as central frequencies Â±
bandwidth/2</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_yscale">yScale</code></td>
<td>
<p>determines the location of center frequencies of the filters</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_xlab">xlab</code>, <code id="audSpectrogram_+3A_ylab">ylab</code>, <code id="audSpectrogram_+3A_main">main</code>, <code id="audSpectrogram_+3A_mar">mar</code>, <code id="audSpectrogram_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_width">width</code>, <code id="audSpectrogram_+3A_height">height</code>, <code id="audSpectrogram_+3A_units">units</code>, <code id="audSpectrogram_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="audSpectrogram_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list for each analyzed file, including:
</p>
<dl>
<dt>audSpec</dt><dd><p>auditory spectrogram with frequencies in rows and
time in columns</p>
</dd> <dt>audSpec_processed</dt><dd><p>same but rescaled for plotting</p>
</dd>
<dt>filterbank</dt><dd><p>raw output of the filters</p>
</dd> <dt>roughness</dt><dd><p>roughness per
channel (as many as <code>nFilters</code>)</p>
</dd></dl>



<h3>Examples</h3>

<pre><code class='language-R'># synthesize a sound with gradually increasing hissing noise
sound = soundgen(sylLen = 200, temperature = 0.001,
  noise = list(time = c(0, 350), value = c(-40, 0)),
  formantsNoise = list(f1 = list(freq = 5000, width = 10000)),
  addSilence = 25)
# playme(sound, samplingRate = 16000)

# auditory spectrogram
as = audSpectrogram(sound, samplingRate = 16000, nFilters = 48)
dim(as$audSpec)

# compare to FFT-based spectrogram with similar time and frequency resolution
fs = spectrogram(sound, samplingRate = 16000, yScale = 'bark',
                 windowLength = 5, step = 1)
dim(fs)

## Not run: 
# add bells and whistles
audSpectrogram(sound, samplingRate = 16000,
  filterType = 'butterworth',
  nFilters = 128,
  yScale = 'ERB',
  bandwidth = 1/6,
  dynamicRange = 150,
  osc = 'dB',  # plot oscillogram in dB
  heights = c(2, 1),  # spectro/osc height ratio
  contrast = .4,  # increase contrast
  brightness = -.2,  # reduce brightness
  # colorTheme = 'heat.colors',  # pick color theme...
  col = hcl.colors(100, palette = 'Plasma'),  # ...or specify the colors
  cex.lab = .75, cex.axis = .75,  # text size and other base graphics pars
  grid = 5,  # to customize, add manually with graphics::grid()
  ylim = c(0.05, 8),  # always in kHz
  main = 'My auditory spectrogram' # title
  # + axis labels, etc
)

# NB: frequency resolution is controlled by both nFilters and bandwidth
audSpectrogram(sound, 16000, nFilters = 15, bandwidth = 1/2)
audSpectrogram(sound, 16000, nFilters = 15, bandwidth = 1/10)
audSpectrogram(sound, 16000, nFilters = 100, bandwidth = 1/2)
audSpectrogram(sound, 16000, nFilters = 100, bandwidth = 1/10)
audSpectrogram(sound, 16000, nFilters_oct = 5, bandwidth = 1/10)

# remove the oscillogram
audSpectrogram(sound, samplingRate = 16000, osc = 'none')

# save auditory spectrograms of all audio files in a folder
audSpectrogram('~/Downloads/temp',
  savePlots = '~/Downloads/temp/audSpec', cores = 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='averageMatrices'>Average matrices</h2><span id='topic+averageMatrices'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>averageMatrices(mat_list, rFun = "max", cFun = "median", reduceFun = "+")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="averageMatrices_+3A_mat_list">mat_list</code></td>
<td>
<p>a list of matrices to aggregate (eg spectrograms or
modulation spectra)</p>
</td></tr>
<tr><td><code id="averageMatrices_+3A_rfun">rFun</code></td>
<td>
<p>cFun functions used to determine the number of rows and columns
in the result</p>
</td></tr>
<tr><td><code id="averageMatrices_+3A_reducefun">reduceFun</code></td>
<td>
<p>function used to aggregate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a list of matrices (normally modulation spectra), interpolates them to
have the same size, and then reduces them (eg takes the average).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat_list = list(
  matrix(1:30, nrow = 5),
  matrix(80:17, nrow = 8)
)
soundgen:::averageMatrices(mat_list)
soundgen:::averageMatrices(mat_list, cFun = 'max', reduceFun = '*')
</code></pre>

<hr>
<h2 id='bandpass'>Bandpass/stop filters</h2><span id='topic+bandpass'></span>

<h3>Description</h3>

<p>Filtering in the frequency domain with FFT-iFFT: low-pass, high-pass,
bandpass, and bandstop filters. Similar to <code><a href="seewave.html#topic+ffilter">ffilter</a></code>,
but here we use FFT instead of STFT - that is, the entire sound is processed
at once. This works best for relatively short sounds (seconds), but gives us
maximum precision (e.g., for precise notch filtering) and doesn't affect the
attack and decay. NAs are accepted and can be interpolated or preserved in
the output. Because we don't do STFT, arbitrarily short vectors are also fine
as input - for example, we can apply a low-pass filter prior to decimation
when changing the sampling rate without aliasing. Note that, unlike
<code><a href="#topic+pitchSmoothPraat">pitchSmoothPraat</a></code>, <code>bandpass</code> by default applies an abrupt
cutoff instead of a smooth gaussian filter, but this behavior can be adjusted
with the <code>bw</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bandpass(
  x,
  samplingRate = NULL,
  lwr = NULL,
  upr = NULL,
  action = c("pass", "stop")[1],
  dB = Inf,
  bw = 0,
  na.rm = TRUE,
  from = NULL,
  to = NULL,
  normalize = FALSE,
  reportEvery = NULL,
  cores = 1,
  saveAudio = NULL,
  plot = FALSE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bandpass_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="bandpass_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_lwr">lwr</code>, <code id="bandpass_+3A_upr">upr</code></td>
<td>
<p>cutoff frequencies, Hz. Specifying just lwr gives a high-pass
filter, just upr low-pass filter with action = 'pass' (or vice versa with
action = 'stop'). Specifying both lwr and upr a bandpass/bandstop filter,
depending on 'action'</p>
</td></tr>
<tr><td><code id="bandpass_+3A_action">action</code></td>
<td>
<p>&quot;pass&quot; = preserve the selected frequency range (bandpass),
&quot;stop&quot; = remove the selected frequency range (bandstop)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_db">dB</code></td>
<td>
<p>a positive number giving the strength of effect in dB (defaults to
Inf - complete removal of selected frequencies)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_bw">bw</code></td>
<td>
<p>bandwidth of the filter cutoffs, Hz. Defaults to 0 (abrupt, step
function), a positive number corresponds to the standard deviation of a
Gaussian curve, and two numbers set different bandwidths for the lower and
upper cutoff points</p>
</td></tr>
<tr><td><code id="bandpass_+3A_na.rm">na.rm</code></td>
<td>
<p>if TRUE, NAs are interpolated, otherwise they are preserved in
the output</p>
</td></tr>
<tr><td><code id="bandpass_+3A_from">from</code>, <code id="bandpass_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, resets the output to the original scale (otherwise
filtering often reduces the amplitude)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="bandpass_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save the processed audio</p>
</td></tr>
<tr><td><code id="bandpass_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="bandpass_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="bandpass_+3A_width">width</code>, <code id="bandpass_+3A_height">height</code>, <code id="bandpass_+3A_units">units</code>, <code id="bandpass_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="bandpass_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to <code>plot()</code> as well as to
<code><a href="seewave.html#topic+meanspec">meanspec</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: fill in NAs with constant interpolation at the edges and linear
interpolation in the middle; perform FFT; set the frequency ranges to be
filtered out to 0; perform inverse FFT; set to the original scale; put the
NAs back in.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Filter white noise
s1 = fade(c(rnorm(2000, 0, 1)), samplingRate = 16000)

# low-pass
bandpass(s1, 16000, upr = 2000, plot = TRUE)

# high-pass by 40 dB
bandpass(s1, 16000, lwr = 2000, dB = 40, plot = TRUE, wl = 1024)
# wl is passed to seewave::meanspec for plotting

# bandstop
bandpass(s1, 16000, lwr = 1000, upr = 1800, action = 'stop', plot = TRUE)

# bandpass
s2 = bandpass(s1, 16000, lwr = 2000, upr = 2100, plot = TRUE)
# playme(rep(s2, 5))
# spectrogram(s2, 16000)

# low-pass and interpolate a short vector with some NAs
x = rnorm(150, 10) + 3 * sin((1:50) / 5)
x[sample(seq_along(x), 50)] = NA
plot(x, type = 'l')
x_bandp = bandpass(x, samplingRate = 100, upr = 10)
points(x_bandp, type = 'l', col = 'blue')

## Not run: 
# add 20 dB with a Gaussian-shaped filter instead of step function
s3 = bandpass(s1, 16000, lwr = 1700, upr = 2100, bw = 200,
  dB = 20, plot = TRUE)
spectrogram(s3, 16000)
s4 = bandpass(s1, 16000, lwr = 2000, upr = 4300, bw = c(100, 500),
  dB = 60, action = 'stop', plot = TRUE)
spectrogram(s4, 16000)

# precise notch filtering is possible, even in low frequencies
whiteNoise = runif(16000, -1, 1)
s3 = bandpass(whiteNoise, 16000, lwr = 30, upr = 40, normalize = TRUE,
              plot = TRUE, xlim = c(0, 500))
playme(rep(s3, 5))
spectrogram(s3, 16000, windowLength = 150, yScale = 'log')

# compare the same with STFT
s4 = seewave::ffilter(whiteNoise, f = 16000, from = 30, to = 40)
spectrogram(s4, 16000, windowLength = 150, yScale = 'log')
# (note: works better as wl approaches length(s4))

# high-pass all audio files in a folder
bandpass('~/Downloads/temp', saveAudio = '~/Downloads/temp/hp2000/',
         lwr = 2000, savePlots = '~/Downloads/temp/hp2000/')

## End(Not run)
</code></pre>

<hr>
<h2 id='beat'>Generate beat</h2><span id='topic+beat'></span>

<h3>Description</h3>

<p>Generates percussive sounds from clicks through drum-like beats to sliding
tones. The principle is to create a sine wave with rapid frequency modulation
and to add a fade-out. No extra harmonics or formants are added. For this
specific purpose, this is vastly faster and easier than to tinker with
<code><a href="#topic+soundgen">soundgen</a></code> settings, especially since percussive syllables tend
to be very short.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beat(
  nSyl = 10,
  sylLen = 200,
  pauseLen = 50,
  pitch = c(200, 10),
  samplingRate = 16000,
  fadeOut = TRUE,
  play = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="beat_+3A_nsyl">nSyl</code></td>
<td>
<p>the number of syllables to generate</p>
</td></tr>
<tr><td><code id="beat_+3A_syllen">sylLen</code></td>
<td>
<p>average duration of each syllable, ms</p>
</td></tr>
<tr><td><code id="beat_+3A_pauselen">pauseLen</code></td>
<td>
<p>average duration of pauses between syllables, ms</p>
</td></tr>
<tr><td><code id="beat_+3A_pitch">pitch</code></td>
<td>
<p>fundamental frequency, Hz - a vector or data.frame(time = ...,
value = ...)</p>
</td></tr>
<tr><td><code id="beat_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="beat_+3A_fadeout">fadeOut</code></td>
<td>
<p>if TRUE, a linear fade-out is applied to the entire syllable</p>
</td></tr>
<tr><td><code id="beat_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a non-normalized waveform centered at zero.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+soundgen">soundgen</a></code> <code><a href="#topic+generateNoise">generateNoise</a></code>
<code><a href="#topic+fart">fart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>playback = c(TRUE, FALSE)[2]
# a drum-like sound
s = beat(nSyl = 1, sylLen = 200,
         pitch = c(200, 100), play = playback)
# plot(s, type = 'l')

# a dry, muted drum
s = beat(nSyl = 1, sylLen = 200,
         pitch = c(200, 10), play = playback)

# sci-fi laser guns
s = beat(nSyl = 3, sylLen = 300,
         pitch = c(1000, 50), play = playback)

# machine guns
s = beat(nSyl = 10, sylLen = 10, pauseLen = 50,
         pitch = c(2300, 300), play = playback)
</code></pre>

<hr>
<h2 id='checkInputType'>Check audio input type</h2><span id='topic+checkInputType'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkInputType(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkInputType_+3A_x">x</code></td>
<td>
<p>path to a .wav or .mp3 file, Wave object, or a numeric vector
representing the waveform with specified samplingRate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Checks the types of audio input to another function, which could be a folder
with audio files, a single file, a Wave object, or a numeric vector. The
purposes of this helper function are to ascertain that there are some valid
inputs and to make a list of valid audio files, if any.
</p>

<hr>
<h2 id='clumper'>Clump a sequence into large segments</h2><span id='topic+clumper'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clumper(x, minLength, n = length(x))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clumper_+3A_x">x</code></td>
<td>
<p>a vector: anything that can be converted into an integer to call
diff(): factors, integers, characters, booleans</p>
</td></tr>
<tr><td><code id="clumper_+3A_minlength">minLength</code></td>
<td>
<p>the minimum length of a segment (interger or vector)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>clumper</code> makes sure each homogeneous segment in a sequence is at least
minLength long. Called by getIntegerRandomWalk(), addSubh(), naiveBayes(),
etc. Algorithm: find the epochs shorter than minLength, merge max 1/4 of them
with the largest neighbor, and repeat recursively until all epochs are at
least minLength long. minLength can be a vector, in which case it is assumed
to change over time.
</p>


<h3>Value</h3>

<p>Returns the original sequence x transformed to homogeneous segments
of required length, with the original class (e.g. character or factor).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = c(1,3,2,2,2,0,0,4,4,1,1,1,1,1,3,3)
soundgen:::clumper(s, 2)
soundgen:::clumper(s, 3)
soundgen:::clumper(1:5, 10)
soundgen:::clumper(c('a','a','a','b','b','c','c','c','a','c'), 3)
soundgen:::clumper(x = c(1,2,1,2,1,1,1,1,3,1), minLength = c(1, 1, 1, 3))
soundgen:::clumper(as.factor(c('A','B','B','C')), 2)
</code></pre>

<hr>
<h2 id='compareSounds'>Compare two sounds</h2><span id='topic+compareSounds'></span>

<h3>Description</h3>

<p>Computes similarity between two sounds based on comparing their
spectrogram-like representations. If the input is audio, two methods of
producing spectrograms are available: <code>specType = 'linear'</code> calls
<code><a href="tuneR.html#topic+powspec">powspec</a></code> for an power spectrogram with frequencies in Hz,
and <code>specType = 'mel'</code> calls <code><a href="tuneR.html#topic+melfcc">melfcc</a></code> for an auditory
spectrogram with frequencies in Mel. For more customized options, just
produce your spectrograms or feature matrices (time in column, features like
pitch, peak frequency etc in rows) with your favorite function before calling
<code>compareSounds</code> because it also accepts matrices as input. To be
directly comparable, the two matrices are made into matrices of the same
size. In case of differences in sampling rates, only frequencies below the
lower Nyquist frequency or below <code>maxFreq</code> are kept. In case of
differences in duration, the shorter sound is padded with 0 (silence) or NA,
as controlled by arguments <code>padWith, padDir</code>. Then the matrices are
compared using methods like cross-correlation or Dynamic Time Warp.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareSounds(
  x,
  y,
  samplingRate = NULL,
  windowLength = 40,
  overlap = 50,
  step = NULL,
  dynamicRange = 80,
  method = c("cor", "cosine", "diff", "dtw"),
  specType = c("linear", "mel")[2],
  specPars = list(),
  dtwPars = list(),
  padWith = NA,
  padDir = c("central", "left", "right")[1],
  maxFreq = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareSounds_+3A_x">x</code>, <code id="compareSounds_+3A_y">y</code></td>
<td>
<p>either two matrices (spectrograms or feature matrices) or two
sounds to be compared (numeric vectors, Wave objects, or paths to wav/mp3
files)</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_samplingrate">samplingRate</code></td>
<td>
<p>if one or both inputs are numeric vectors, specify
sampling rate, Hz. A vector of length 2 means the two inputs have different
sampling rates, in which case spectrograms are compared only up to the
lower Nyquist frequency</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>parts of the spectra quieter than <code>-dynamicRange</code> dB
are not compared</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_method">method</code></td>
<td>
<p>method of comparing mel-transformed spectra of two sounds:
&quot;cor&quot; = Pearson's correlation; &quot;cosine&quot; = cosine similarity; &quot;diff&quot; =
absolute difference between each bin in the two spectrograms; &quot;dtw&quot; =
multivariate Dynamic Time Warp with <code><a href="dtw.html#topic+dtw">dtw</a></code></p>
</td></tr>
<tr><td><code id="compareSounds_+3A_spectype">specType</code></td>
<td>
<p>&quot;linear&quot; = power spectrogram with
<code><a href="tuneR.html#topic+powspec">powspec</a></code>, &quot;mel&quot; = mel-frequency spectrogram with
<code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id="compareSounds_+3A_specpars">specPars</code></td>
<td>
<p>a list of parameters passed to <code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id="compareSounds_+3A_dtwpars">dtwPars</code></td>
<td>
<p>a list of parameters passed to <code><a href="dtw.html#topic+dtw">dtw</a></code></p>
</td></tr>
<tr><td><code id="compareSounds_+3A_padwith">padWith</code></td>
<td>
<p>if the duration of x and y is not identical, the compared
spectrograms are padded with either silence (<code>padWith = 0</code>) or with
NA's (<code>padWith = NA</code>) to have the same number of columns. Padding with
NA implies that only the overlapping part is of relevance, whereas padding
with 0 means that the added silent part is also compared with the longer
sound, usually resulting in lower similarity (see examples)</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_paddir">padDir</code></td>
<td>
<p>if padding, specify where to add zeros or NAs: before the sound
('left'), after the sound ('right'), or on both sides ('central')</p>
</td></tr>
<tr><td><code id="compareSounds_+3A_maxfreq">maxFreq</code></td>
<td>
<p>parts of the spectra above <code>maxFreq</code> Hz are not compared</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with two columns: &quot;method&quot; for the method(s)
used, and &quot;sim&quot; for the similarity between the two sounds calculated with
that method. The range of similarity measures is [-1, 1] for &quot;cor&quot;,
[0, 1] for &quot;cosine&quot; and &quot;diff&quot;, and (-Inf, Inf) for &quot;dtw&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(orni, peewit, package = 'seewave')
compareSounds(orni, peewit)
# spectrogram(orni); playme(orni)
# spectrogram(peewit); playme(peewit)

## Not run: 
s1 = soundgen(formants = 'a', play = TRUE)
s2 = soundgen(formants = 'ae', play = TRUE)
s3 = soundgen(formants = 'eae', sylLen = 700, play = TRUE)
s4 = runif(8000, -1, 1)  # white noise
compareSounds(s1, s2, samplingRate = 16000)
compareSounds(s1, s4, samplingRate = 16000)

# the central section of s3 is more similar to s1 than is the beg/eng of s3
compareSounds(s1, s3, samplingRate = 16000, padDir = 'left')
compareSounds(s1, s3, samplingRate = 16000, padDir = 'central')

# padding with 0 penalizes differences in duration, whereas padding with NA
# is like saying we only care about the overlapping part
compareSounds(s1, s3, samplingRate = 16000, padWith = 0)
compareSounds(s1, s3, samplingRate = 16000, padWith = NA)

# comparing linear (Hz) vs mel-spectrograms produces quite different results
compareSounds(s1, s3, samplingRate = 16000, specType = 'linear')
compareSounds(s1, s3, samplingRate = 16000, specType = 'mel')

# pass additional control parameters to dtw and melfcc
compareSounds(s1, s3, samplingRate = 16000,
              specPars = list(nbands = 128),
              dtwPars = list(dist.method = "Manhattan"))

# use feature matrices instead of spectrograms (time in columns, features in rows)
a1 = t(as.matrix(analyze(s1, samplingRate = 16000)$detailed))
a1 = a1[4:nrow(a1), ]; a1[is.na(a1)] = 0
a2 = t(as.matrix(analyze(s2, samplingRate = 16000)$detailed))
a2 = a2[4:nrow(a2), ]; a2[is.na(a2)] = 0
a4 = t(as.matrix(analyze(s4, samplingRate = 16000)$detailed))
a4 = a4[4:nrow(a4), ]; a4[is.na(a4)] = 0
compareSounds(a1, a2, method = c('cosine', 'dtw'))
compareSounds(a1, a4, method = c('cosine', 'dtw'))

# a demo for comparing different similarity metrics
target = soundgen(sylLen = 500, formants = 'a',
                  pitch = data.frame(time = c(0, 0.1, 0.9, 1),
                                     value = c(100, 150, 135, 100)),
                  temperature = 0.001)
spec1 = soundgen:::getMelSpec(target, samplingRate = 16000)

parsToTry = list(
  list(formants = 'i',                                            # wrong
       pitch = data.frame(time = c(0, 1),                         # wrong
                          value = c(200, 300))),
  list(formants = 'i',                                            # wrong
       pitch = data.frame(time = c(0, 0.1, 0.9, 1),               # right
                                 value = c(100, 150, 135, 100))),
  list(formants = 'a',                                            # right
       pitch = data.frame(time = c(0,1),                          # wrong
                                 value = c(200, 300))),
  list(formants = 'a',
       pitch = data.frame(time = c(0, 0.1, 0.9, 1),               # right
                                 value = c(100, 150, 135, 100)))  # right
)

sounds = list()
for (s in seq_along(parsToTry)) {
  sounds[[length(sounds) + 1]] =  do.call(soundgen,
    c(parsToTry[[s]], list(temperature = 0.001, sylLen = 500)))
}
lapply(sounds, playme)

method = c('cor', 'cosine', 'diff', 'dtw')
df = matrix(NA, nrow = length(parsToTry), ncol = length(method))
colnames(df) = method
df = as.data.frame(df)
for (i in 1:nrow(df)) {
  df[i, ] = compareSounds(
    x = spec1,  # faster to calculate spec1 once
    y = sounds[[i]],
    samplingRate = 16000,
    method = method
  )[, 2]
}
df$av = rowMeans(df, na.rm = TRUE)
# row 1 = wrong pitch &amp; formants, ..., row 4 = right pitch &amp; formants
df$formants = c('wrong', 'wrong', 'right', 'right')
df$pitch = c('wrong', 'right', 'wrong', 'right')
df

## End(Not run)
</code></pre>

<hr>
<h2 id='convert_sec_to_hms'>Print time</h2><span id='topic+convert_sec_to_hms'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_sec_to_hms(time_s, digits = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_sec_to_hms_+3A_time_s">time_s</code></td>
<td>
<p>time (s)</p>
</td></tr>
<tr><td><code id="convert_sec_to_hms_+3A_digits">digits</code></td>
<td>
<p>number of digits to preserve for s (1-60 s)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Converts time in seconds to time in y m d h min s for pretty printing.
</p>


<h3>Value</h3>

<p>Returns a character string like &quot;1 h 20 min 3 s&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>time_s = c(.0001, .01, .33, .8, 2.135, 5.4, 12, 250, 3721, 10000,
           150000, 365 * 24 * 3600 + 35 * 24 * 3600 + 3721)
soundgen:::convert_sec_to_hms(time_s)
soundgen:::convert_sec_to_hms(time_s, 2)
</code></pre>

<hr>
<h2 id='convertStringToFormants'>Prepare a list of formants</h2><span id='topic+convertStringToFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertStringToFormants(phonemeString, speaker = "M1")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convertStringToFormants_+3A_phonemestring">phonemeString</code></td>
<td>
<p>a string of characters from the dictionary of phoneme
presets, e.g., uaaaaii (short u - longer a - medium-long i)</p>
</td></tr>
<tr><td><code id="convertStringToFormants_+3A_speaker">speaker</code></td>
<td>
<p>name of the preset dictionary to use</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a string of phonemes entered WITHOUT ANY BREAKS. Recognized phonemes in
the human preset dictionary: vowels &quot;a&quot; &quot;o&quot; &quot;i&quot; &quot;e&quot; &quot;u&quot; &quot;0&quot; (schwa);
consonants &quot;s&quot; &quot;x&quot; &quot;j&quot;.
</p>


<h3>Value</h3>

<p>Returns a list of formant values, which can be fed directly into
<code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::convertStringToFormants(phonemeString = 'a')
soundgen:::convertStringToFormants(
  phonemeString = 'au', speaker = 'M1')
soundgen:::convertStringToFormants(
  phonemeString = 'aeui', speaker = 'F1')
soundgen:::convertStringToFormants(
  phonemeString = 'aaeuiiiii', speaker = 'Chimpanzee')
</code></pre>

<hr>
<h2 id='costJumps'>Cost of jumps</h2><span id='topic+costJumps'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>costJumps(cand1, cand2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="costJumps_+3A_cand1">cand1</code>, <code id="costJumps_+3A_cand2">cand2</code></td>
<td>
<p>two candidate pitch values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for calculating the cost of transitions between
pitch candidates. Needed for postprocessing of pitch contour - finding the
optimal pitch contour.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = seq(-3, 3, by = .01)
b = 1 / (1 + 10 * exp(3 - 7 * abs(a)))
plot(a, b, type = 'l')
</code></pre>

<hr>
<h2 id='costPerPath'>Cost per path</h2><span id='topic+costPerPath'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>costPerPath(
  path,
  pitchCands,
  pitchCert,
  certWeight,
  pitchCenterGravity,
  manual = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="costPerPath_+3A_path">path</code></td>
<td>
<p>evaluated path through pitch candidates (as integers specifying
the rows in pitchCands, not the actual values of pitch)</p>
</td></tr>
<tr><td><code id="costPerPath_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="costPerPath_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="costPerPath_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id="costPerPath_+3A_pitchcentergravity">pitchCenterGravity</code></td>
<td>
<p>numeric vector giving the mean of all pitch
candidates per fft frame weighted by our certainty in each of these
candidates</p>
</td></tr>
<tr><td><code id="costPerPath_+3A_manual">manual</code></td>
<td>
<p>a dataframe of manual pitch candidates from pathfinder()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing of pitch contours called by
<code><a href="#topic+pathfinding_slow">pathfinding_slow</a></code>. Calculates the cost of a particular path
through pitch candidates based on pitch jumps and distance from
high-certainty candidates.
</p>

<hr>
<h2 id='crossFade'>Join two waveforms by cross-fading</h2><span id='topic+crossFade'></span>

<h3>Description</h3>

<p><code>crossFade</code> joins two input vectors (waveforms) by cross-fading. First
it truncates both input vectors, so that <code>ampl1</code> ends with a zero
crossing and <code>ampl2</code> starts with a zero crossing, both on an upward
portion of the soundwave. Then it cross-fades both vectors linearly with an
overlap of crossLen or crossLenPoints. If the input vectors are too short for
the specified length of cross-faded region, the two vectors are concatenated
at zero crossings instead of cross-fading. Soundgen uses <code>crossFade</code> for
gluing together epochs with different regimes of pitch effects (see the
vignette on sound generation), but it can also be useful for joining two
separately generated sounds without audible artifacts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crossFade(
  ampl1,
  ampl2,
  crossLenPoints = 240,
  crossLen = NULL,
  samplingRate = NULL,
  shape = c("lin", "exp", "log", "cos", "logistic", "gaussian")[1],
  steepness = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crossFade_+3A_ampl1">ampl1</code>, <code id="crossFade_+3A_ampl2">ampl2</code></td>
<td>
<p>two numeric vectors (waveforms) to be joined</p>
</td></tr>
<tr><td><code id="crossFade_+3A_crosslenpoints">crossLenPoints</code></td>
<td>
<p>(optional) the length of overlap in points</p>
</td></tr>
<tr><td><code id="crossFade_+3A_crosslen">crossLen</code></td>
<td>
<p>the length of overlap in ms (overrides crossLenPoints)</p>
</td></tr>
<tr><td><code id="crossFade_+3A_samplingrate">samplingRate</code></td>
<td>
<p>the sampling rate of input vectors, Hz (needed only if
crossLen is given in ms rather than points)</p>
</td></tr>
<tr><td><code id="crossFade_+3A_shape">shape</code></td>
<td>
<p>controls the type of fade function: 'lin' = linear, 'exp' =
exponential, 'log' = logarithmic, 'cos' = cosine, 'logistic' = logistic
S-curve</p>
</td></tr>
<tr><td><code id="crossFade_+3A_steepness">steepness</code></td>
<td>
<p>scaling factor regulating the steepness of fading curves
(except for shapes 'lin' and 'cos'): 0 = linear, &gt;1 = steeper than default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fade">fade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound1 = sin(1:100 / 9)
sound2 = sin(7:107 / 3)
plot(c(sound1, sound2), type = 'b')
# an ugly discontinuity at 100 that will make an audible click

sound = crossFade(sound1, sound2, crossLenPoints = 5)
plot(sound, type = 'b') # a nice, smooth transition
length(sound) # but note that cross-fading costs us ~60 points
#  because of trimming to zero crossings and then overlapping

## Not run: 
# Actual sounds, alternative shapes of fade-in/out
sound3 = soundgen(formants = 'a', pitch = 200,
                  addSilence = 0, attackLen = c(50, 0))
sound4 = soundgen(formants = 'u', pitch = 200,
                  addSilence = 0, attackLen = c(0, 50))

# simple concatenation (with a click)
playme(c(sound3, sound4), 16000)

# concatentation from zc to zc (no click, but a rough transition)
playme(crossFade(sound3, sound4, crossLen = 0), 16000)

# linear crossFade over 35 ms - brief, but smooth
playme(crossFade(sound3, sound4, crossLen = 35, samplingRate = 16000), 16000)

# s-shaped cross-fade over 300 ms (shortens the sound by ~300 ms)
playme(crossFade(sound3, sound4, samplingRate = 16000,
                 crossLen = 300, shape = 'cos'), 16000)

## End(Not run)
</code></pre>

<hr>
<h2 id='def_form'>Defaults and ranges for formant_app()</h2><span id='topic+def_form'></span>

<h3>Description</h3>

<p>Internal soundgen list of defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>def_form
</code></pre>


<h3>Format</h3>

<p>A matrix with 4 columns:
</p>

<dl>
<dt>default</dt><dd><p>default value</p>
</dd>
<dt>low</dt><dd><p>lowest permitted value</p>
</dd>
<dt>high</dt><dd><p>highest permitted value</p>
</dd>
<dt>step</dt><dd><p>increment for adjustment</p>
</dd>
</dl>
<p>...

</p>


<h3>Details</h3>

<p>A dataset containing defaults and ranges of key variables for formant_app().
Adjust as needed.
</p>

<hr>
<h2 id='defaults'>Shiny app defaults</h2><span id='topic+defaults'></span>

<h3>Description</h3>

<p>A list of default values for Shiny app soundgen_app() - mostly the same as
the defaults for soundgen(). NB: if defaults change, this has to be
updated!!!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defaults
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 69.
</p>

<hr>
<h2 id='defaults_analyze'>Defaults and ranges for analyze()</h2><span id='topic+defaults_analyze'></span>

<h3>Description</h3>

<p>A dataset containing defaults and ranges of key variables for analyze() and
pitch_app(). Adjust as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defaults_analyze
</code></pre>


<h3>Format</h3>

<p>A matrix with 58 rows and 4 columns:
</p>

<dl>
<dt>default</dt><dd><p>default value</p>
</dd>
<dt>low</dt><dd><p>lowest permitted value</p>
</dd>
<dt>high</dt><dd><p>highest permitted value</p>
</dd>
<dt>step</dt><dd><p>increment for adjustment</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='defaults_analyze_pitchCand'>Defaults for plotting with analyze()</h2><span id='topic+defaults_analyze_pitchCand'></span>

<h3>Description</h3>

<p>Default plotting settings for each pitch tracker in analyze() and
pitch_app(). Adjust as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defaults_analyze_pitchCand
</code></pre>


<h3>Format</h3>

<p>A dataframe with 8 rows and 5 columns:
</p>

<dl>
<dt>method</dt><dd><p>pitch tracking method</p>
</dd>
<dt>col</dt><dd><p>color</p>
</dd>
<dt>pch</dt><dd><p>point character</p>
</dd>
<dt>lwd</dt><dd><p>line width</p>
</dd>
<dt>lty</dt><dd><p>line type</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='detectNLP'>Detect NLP</h2><span id='topic+detectNLP'></span>

<h3>Description</h3>

<p>(Experimental) A function for automatically detecting and annotating
nonlinear vocal phenomena (NLP). Algorithm: analyze the audio using
<code><a href="#topic+analyze">analyze</a></code> and <code><a href="#topic+phasegram">phasegram</a></code>, then use the extracted
frame-by-frame descriptives to classify each frame as having no NLP (&quot;none&quot;),
subharmonics (&quot;sh&quot;), sibebands / amplitude modulation (&quot;sb&quot;), or
deterministic chaos (&quot;chaos&quot;). The classification is performed by a
<code><a href="#topic+naiveBayes">naiveBayes</a></code> algorithm adapted to autocorrelated time series and
pretrained on a manually annotated corpus of vocalizations. Whenever
possible, check and correct pitch tracks prior to running the algorithm. See
<code><a href="#topic+naiveBayes">naiveBayes</a></code> for tips on using adaptive priors and &quot;clumpering&quot;
to account for the fact that NLP typically occur in continuous segments
spanning multiple frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectNLP(
  x,
  samplingRate = NULL,
  predictors = c("d2", "subDep", "amEnvDep", "amMsPurity", "entropy", "HNR", "CPP",
    "roughness"),
  thresProb = 0.4,
  unvoicedToNone = FALSE,
  train = soundgen::detectNLP_training_nonv,
  scale = NULL,
  from = NULL,
  to = NULL,
  pitchManual = NULL,
  pars_analyze = list(windowLength = 50, roughness = list(windowLength = 15, step = 3)),
  pars_phasegram = list(nonlinStats = "d2"),
  pars_naiveBayes = list(prior = "static", wlClumper = 3),
  jumpThres = 14,
  jumpWindow = 100,
  reportEvery = NULL,
  cores = 1,
  plot = FALSE,
  savePlots = NULL,
  main = NULL,
  xlab = NULL,
  ylab = NULL,
  ylim = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detectNLP_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_predictors">predictors</code></td>
<td>
<p>variables to include in NLP classification. The default is
to include all 7 variables in the training corpus. NA values are fine (they
do not cause the entire frame to be dropped as long as at least one
variable is measured).</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_thresprob">thresProb</code></td>
<td>
<p>minimum probability of NLP for the frame to be classified as
non-&quot;none&quot;, which is good for reducing false alarms (&lt;1/nClasses means just
go for the highest probability)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_unvoicedtonone">unvoicedToNone</code></td>
<td>
<p>if TRUE, frames treated as unvoiced are set to &quot;none&quot;
(mostly makes sense with manual pitch tracking)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_train">train</code></td>
<td>
<p>training corpus, namely the result of running
<code><a href="#topic+naiveBayes_train">naiveBayes_train</a></code> on audio with known NLP episodes. Currently
implemented: soundgen::detectNLP_training_nonv = manually annotated human
nonverbal vocalizations, soundgen::detectNLP_training_synth = synthetic,
soundgen()-generated sounds with various NLP. To train your own, run
<code>detectNLP</code> on a collection of recordings, provide ground truth
classification of NLP per frame (normally this would be converted from NLP
annotations), and run <code><a href="#topic+naiveBayes_train">naiveBayes_train</a></code>.</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_from">from</code>, <code id="detectNLP_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_pitchmanual">pitchManual</code></td>
<td>
<p>manually corrected pitch contour. For a single sound,
provide a numeric vector of any length. For multiple sounds, provide a
dataframe with columns &quot;file&quot; and &quot;pitch&quot; (or path to a csv file) as
returned by <code><a href="#topic+pitch_app">pitch_app</a></code>, ideally with the same windowLength and
step as in current call to analyze. A named list with pitch vectors per
file is also OK (eg as returned by pitch_app)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_pars_analyze">pars_analyze</code></td>
<td>
<p>arguments passed to <code><a href="#topic+analyze">analyze</a></code>. NB: drop
everything unnecessary to speed up the process, e.g. nFormants = 0,
loudness = NULL, etc. If you have manual pitch contours, pass them as
<code>pitchManual = ...</code>. Make sure the &quot;silence&quot; threshold is appropriate,
and ideally normalize the audio (silent frames are automatically assigned
to &quot;none&quot;)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_pars_phasegram">pars_phasegram</code></td>
<td>
<p>arguments passed to <code><a href="#topic+phasegram">phasegram</a></code>. NB: only
<code>d2</code> and <code>nPeaks</code> are used for NLP detection because they proved
effective in the training corpus; other nonlinear statistics are not
calculated to save time.</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_pars_naivebayes">pars_naiveBayes</code></td>
<td>
<p>arguments passed to <code><a href="#topic+naiveBayes">naiveBayes</a></code>. It is
strongly recommended to use some clumpering, with <code>wlClumper</code> given as
frames (multiple by <code>step</code> to get the corresponding minumum duration
of an NLP segment in ms), and/or dynamic priors.</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_jumpthres">jumpThres</code></td>
<td>
<p>frames in which pitch changes by <code>jumpThres</code> octaves/s
more than in the surrounding frames are classified as containing &quot;pitch
jumps&quot;. Note that this is the rate of frequency change PER SECOND, not from
one frame to the next</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_jumpwindow">jumpWindow</code></td>
<td>
<p>the window for calculating the median pitch slope around
the analyzed frame, ms</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a spectrogram with annotated NLP regimes</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_main">main</code>, <code id="detectNLP_+3A_xlab">xlab</code>, <code id="detectNLP_+3A_ylab">ylab</code>, <code id="detectNLP_+3A_...">...</code></td>
<td>
<p>graphical parameters passed to
<code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
<tr><td><code id="detectNLP_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="detectNLP_+3A_width">width</code>, <code id="detectNLP_+3A_height">height</code>, <code id="detectNLP_+3A_units">units</code>, <code id="detectNLP_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with frame-by-frame descriptives, posterior
probabilities of each NLP type per frame, and the tentative classification
(the NLP type with the highest posterior probability, possibly corrected by
clumpering). The time step is equal to the larger of the steps passed to
analyze() and phasegram().
</p>
<p>Returns a list of datasets, one per input file, with acoustic
descriptives per frame (returned by <code>analyze</code> and <code>phasegram</code>),
probabilities of each NLP type per frame, and the putative classification
of NLP per frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
target = soundgen(sylLen = 2000, addSilence = 0, temperature = 1e-2,
  pitch = c(380, 550, 500, 220), subDep = c(0, 0, 40, 0, 0, 0, 0, 0),
  amDep = c(0, 0, 0, 0, 80, 0, 0, 0), amFreq = 80,
  noise = c(-10, rep(-40, 5)),
  jitterDep = c(0, 0, 0, 0, 0, 3),
  plot = TRUE, play = TRUE)

# classifier trained on manually annotated recordings of human nonverbal
# vocalizations
nlp = detectNLP(target, 16000,
  predictors = c('subDep', 'amEnvDep', 'amMsPurity', 'HNR', 'CPP'),
  plot = TRUE, ylim = c(0, 4))

# classifier trained on synthetic, soundgen()-generated sounds
nlp = detectNLP(target, 16000,
  train = soundgen::detectNLP_training_synth,
  predictors = c('subDep', 'amEnvDep', 'amMsPurity', 'HNR', 'CPP'),
  plot = TRUE, ylim = c(0, 4))
head(nlp[, c('time', 'pr')])
table(nlp$pr)
plot(nlp$amEnvDep, type = 'l')
plot(nlp$subDep, type = 'l')
plot(nlp$entropy, type = 'l')
plot(nlp$none, type = 'l')
points(nlp$sb, type = 'l', col = 'blue')
points(nlp$sh, type = 'l', col = 'green')
points(nlp$chaos, type = 'l', col = 'red')

# detection of pitch jumps
s1 = soundgen(sylLen = 1200, temperature = .001, pitch = list(
  time = c(0, 350, 351, 890, 891, 1200),
  value = c(140, 230, 460, 330, 220, 200)))
playme(s1, 16000)
nlp1 = detectNLP(s1, 16000, plot = TRUE, ylim = c(0, 3),
  predictors = c('subDep', 'amEnvDep', 'amMsPurity', 'HNR', 'CPP'),
  train = soundgen::detectNLP_training_synth)

# process all files in a folder
nlp = detectNLP('/home/allgoodguys/Downloads/temp260/',
  pitchManual = soundgen::pitchContour, cores = 4, plot = TRUE,
  savePlots = '', ylim = c(0, 3))

## End(Not run)
</code></pre>

<hr>
<h2 id='detectNLP_training_nonv'>Nonlinear phenomena: Naive Bayes classifier trained on human nonverbal
vocalizations</h2><span id='topic+detectNLP_training_nonv'></span>

<h3>Description</h3>

<p>The results of running <code><a href="#topic+naiveBayes_train">naiveBayes_train</a></code> on acoustically
analyzed 969 human nonverbal vocalizations (&gt;83K frames). It is used by
<code><a href="#topic+detectNLP">detectNLP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectNLP_training_nonv
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 9.
</p>

<hr>
<h2 id='detectNLP_training_synth'>Nonlinear phenomena: Naive Bayes classifier trained on synthetic sounds</h2><span id='topic+detectNLP_training_synth'></span>

<h3>Description</h3>

<p>The results of running <code><a href="#topic+naiveBayes_train">naiveBayes_train</a></code> on 5000 synthetic
sounds with or without NLP created with soundgen(). It is used by
<code><a href="#topic+detectNLP">detectNLP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectNLP_training_synth
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 9.
</p>

<hr>
<h2 id='divideIntoSyllables'>Syllable structure of a bout</h2><span id='topic+divideIntoSyllables'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divideIntoSyllables(
  nSyl,
  sylLen,
  pauseLen,
  sylDur_min = 20,
  sylDur_max = 10000,
  pauseDur_min = 20,
  pauseDur_max = 1000,
  temperature = 0.025,
  invalidArgAction = c("adjust", "abort", "ignore")[1],
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="divideIntoSyllables_+3A_nsyl">nSyl</code></td>
<td>
<p>the desired number of syllables</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_syllen">sylLen</code></td>
<td>
<p>the desired mean syllable duration, in ms (vectorized)</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_pauselen">pauseLen</code></td>
<td>
<p>the desired mean pause between syllables, in ms (vectorized)</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_syldur_min">sylDur_min</code>, <code id="divideIntoSyllables_+3A_syldur_max">sylDur_max</code></td>
<td>
<p>the lower and upper bounds on possible syllable
duration, in ms</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_pausedur_min">pauseDur_min</code>, <code id="divideIntoSyllables_+3A_pausedur_max">pauseDur_max</code></td>
<td>
<p>the lower and upper bounds on possible pause
duration, in ms</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_temperature">temperature</code></td>
<td>
<p>a non-negative float regulating the stochasticity of
syllable segmentation; 0 = no stochasticity; 1 = sd of proposals is equal
to sylLen (very strong stochasticity)</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>permittedValues</code>: 'adjust' = reset to default value, 'abort'
= stop execution, 'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
<tr><td><code id="divideIntoSyllables_+3A_plot">plot</code></td>
<td>
<p>produce a plot of syllable structure?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stochastic generation of syllable structure of a bout. Calls
<code><a href="#topic+rnorm_truncated2">rnorm_truncated2</a></code> to vary the duration of each new syllable and of
pauses between syllables. Total bout duration will also vary, unless
temperature is zero. However, the output will always contain exactly
<code>nSyl</code> syllables.
</p>


<h3>Value</h3>

<p>Returns a matrix with a list of start-end points for syllables
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::divideIntoSyllables(nSyl = 1, sylLen = 180)
soundgen:::divideIntoSyllables(nSyl = 5, sylLen = 180,
  pauseLen = 55, temperature = 0.2, plot = TRUE)
soundgen:::divideIntoSyllables(nSyl = 5, sylLen = 180,
  pauseLen = 55, temperature = 0)
soundgen:::divideIntoSyllables(nSyl = 3, sylLen = 100,
  pauseLen = 25, temperature = 0.5)

# sylLen and pauseLen are vectorized:
soundgen:::divideIntoSyllables(nSyl = 15, sylLen = 100:200,
  pauseLen = c(80, 25, 80), temperature = 0.05, plot = TRUE)
</code></pre>

<hr>
<h2 id='dPhase'>Phase derivatives</h2><span id='topic+dPhase'></span>

<h3>Description</h3>

<p>Internal soundgen function called by pitchShift().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dPhase(
  phase,
  magn,
  step_s,
  freqs,
  alpha,
  propagation = c("time", "adaptive")[1],
  tol = 10^(-6),
  nr = nrow(phase),
  nc = ncol(phase)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dPhase_+3A_phase">phase</code>, <code id="dPhase_+3A_magn">magn</code></td>
<td>
<p>phase and magnitude of a spectrogram</p>
</td></tr>
<tr><td><code id="dPhase_+3A_step_s">step_s</code></td>
<td>
<p>step in s</p>
</td></tr>
<tr><td><code id="dPhase_+3A_freqs">freqs</code></td>
<td>
<p>a vector of central frequencies per bin</p>
</td></tr>
<tr><td><code id="dPhase_+3A_alpha">alpha</code></td>
<td>
<p>stretch factor</p>
</td></tr>
<tr><td><code id="dPhase_+3A_propagation">propagation</code></td>
<td>
<p>the method for propagating phase: &quot;time&quot; = horizontal
propagation (default), &quot;adaptive&quot; = an experimental implementation of
&quot;vocoder done right&quot; (Prusa &amp; Holighaus 2017)</p>
</td></tr>
<tr><td><code id="dPhase_+3A_tol">tol</code></td>
<td>
<p>tolerance of &quot;vocoder done right&quot; algorithm</p>
</td></tr>
<tr><td><code id="dPhase_+3A_nr">nr</code>, <code id="dPhase_+3A_nc">nc</code></td>
<td>
<p>dimensions of input spectrogram</p>
</td></tr>
</table>

<hr>
<h2 id='drawContour'>Draw contour</h2><span id='topic+drawContour'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drawContour(
  len,
  anchors,
  interpol,
  valueFloor,
  duration_ms = 500,
  loessSpan = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drawContour_+3A_len">len</code></td>
<td>
<p>the required length of the output contour. If NULL, it will be
calculated based on the maximum time value (in ms) and <code>samplingRate</code></p>
</td></tr>
<tr><td><code id="drawContour_+3A_anchors">anchors</code></td>
<td>
<p>a numeric vector of values or a list/dataframe with one column
(value) or two columns (time and value). <code>achors$time</code> can be in ms
(with len=NULL) or in arbitrary units, eg 0 to 1 (with duration determined
by len, which must then be provided in ms). So anchors$time is assumed to
be in ms if len=NULL and relative if len is specified. <code>anchors$value</code>
can be on any scale.</p>
</td></tr>
<tr><td><code id="drawContour_+3A_interpol">interpol</code></td>
<td>
<p>method of interpolation between anchors: &quot;approx&quot; = linear
with <code><a href="stats.html#topic+approx">approx</a></code>, &quot;spline&quot; = cubic splines with
<code><a href="stats.html#topic+spline">spline</a></code>, &quot;loess&quot; = local polynomial regression with
<code><a href="stats.html#topic+loess">loess</a></code></p>
</td></tr>
<tr><td><code id="drawContour_+3A_duration_ms">duration_ms</code></td>
<td>
<p>contour duration, ms</p>
</td></tr>
<tr><td><code id="drawContour_+3A_loessspan">loessSpan</code></td>
<td>
<p>controls the amount of smoothing when interpolating between
anchors with <code><a href="stats.html#topic+loess">loess</a></code>, so only has an effect if interpol
= 'loess' (1 = strong, 0.5 = weak smoothing)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The core part of getSmoothContour() that actually performs the interpolation
between anchors.
</p>

<hr>
<h2 id='drawFreqAxis'>Draw frequency axis</h2><span id='topic+drawFreqAxis'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drawFreqAxis(y, ylim = range(y), yScale, nLbls = 5, y_Hz = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drawFreqAxis_+3A_y">y</code></td>
<td>
<p>frequency values</p>
</td></tr>
<tr><td><code id="drawFreqAxis_+3A_ylim">ylim</code></td>
<td>
<p>range of frequency values</p>
</td></tr>
<tr><td><code id="drawFreqAxis_+3A_yscale">yScale</code></td>
<td>
<p>scale of frequency representation</p>
</td></tr>
<tr><td><code id="drawFreqAxis_+3A_nlbls">nLbls</code></td>
<td>
<p>number of frequency labels</p>
</td></tr>
<tr><td><code id="drawFreqAxis_+3A_y_hz">y_Hz</code></td>
<td>
<p>show frequency in Hz (TRUE) or kHz (FALSE)</p>
</td></tr>
<tr><td><code id="drawFreqAxis_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to axis()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for adding a customized frequency axis to the spectrogram
</p>

<hr>
<h2 id='ERBToHz'>Convert Hz to ERB rate</h2><span id='topic+ERBToHz'></span>

<h3>Description</h3>

<p>Converts from Hz to the number of Equivalent Rectangular Bandwidths (ERBs)
below input frequency. See https://www2.ling.su.se/staff/hartmut/bark.htm and
https://en.wikipedia.org/wiki/Equivalent_rectangular_bandwidth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ERBToHz(e, method = c("linear", "quadratic")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ERBToHz_+3A_e">e</code></td>
<td>
<p>vector or matrix of frequencies in ERB rate</p>
</td></tr>
<tr><td><code id="ERBToHz_+3A_method">method</code></td>
<td>
<p>approximation to use</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+HzToERB">HzToERB</a></code> <code><a href="#topic+HzToSemitones">HzToSemitones</a></code>
<code><a href="#topic+HzToNotes">HzToNotes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>freqs_Hz = c(-20, 20, 100, 440, 1000, 20000, NA)
e_lin = HzToERB(freqs_Hz, 'linear')
ERBToHz(e_lin, 'linear')

e_quad = HzToERB(freqs_Hz, 'quadratic')
ERBToHz(e_quad, 'quadratic')
</code></pre>

<hr>
<h2 id='estimateVTL'>Estimate vocal tract length</h2><span id='topic+estimateVTL'></span>

<h3>Description</h3>

<p>Estimates the length of vocal tract based on formant frequencies. If
<code>method = 'meanFormant'</code>, vocal tract length (VTL) is calculated
separately for each formant, and then the resulting VTLs are averaged. The
equation used is <code class="reqn">(2 * formant_number - 1) * speedSound / (4 *
formant_frequency)</code> for a closed-open tube (mouth open) and
<code class="reqn">formant_number * speedSound / (2 * formant_frequency)</code> for an open-open
or closed-closed tube (eg closed mouth in mmm or open mouth and open glottis
in whispering). If <code>method = 'meanDispersion'</code>, formant dispersion is
calculated as the mean distance between formants, and then VTL is calculated
as <code class="reqn">speed of sound / 2 / formant dispersion</code>. If <code>method =
'regression'</code>, formant dispersion is estimated using the regression method
described in Reby et al. (2005) &quot;Red deer stags use formants as assessment
cues during intrasexual agonistic interactions&quot;. For a review of these and
other VTL-related summary measures of formant frequencies, refer to Pisanski
et al. (2014) &quot;Vocal indicators of body size in men and women: a
meta-analysis&quot;. See also <code><a href="#topic+schwa">schwa</a></code> for VTL estimation with
additional information on formant frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimateVTL(
  formants,
  method = c("regression", "meanDispersion", "meanFormant")[1],
  interceptZero = TRUE,
  tube = c("closed-open", "open-open")[1],
  speedSound = 35400,
  checkFormat = TRUE,
  output = c("simple", "detailed")[1],
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimateVTL_+3A_formants">formants</code></td>
<td>
<p>formant frequencies in any format recognized by
<code><a href="#topic+soundgen">soundgen</a></code>: a vector of formant frequencies like <code>c(550,
1600, 3200)</code>; a list with multiple values per formant like <code>list(f1 =
c(500, 550), f2 = 1200))</code>; or a character string like <code>aaui</code> referring
to default presets for speaker &quot;M1&quot; in soundgen presets</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_method">method</code></td>
<td>
<p>the method of estimating vocal tract length (see details)</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_interceptzero">interceptZero</code></td>
<td>
<p>if TRUE, forces the regression curve to pass through the
origin. This reduces the influence of highly variable lower formants, but
we have to commit to a particular model of the vocal tract: closed-open or
open-open/closed-closed (method = &quot;regression&quot; only)</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_tube">tube</code></td>
<td>
<p>the vocal tract is assumed to be a cylindrical tube that is
either &quot;closed-open&quot; or &quot;open-open&quot; (same as closed-closed)</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_speedsound">speedSound</code></td>
<td>
<p>speed of sound in warm air, by default 35400 cm/s. Stevens
(2000) &quot;Acoustic phonetics&quot;, p. 138</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_checkformat">checkFormat</code></td>
<td>
<p>if FALSE, only a list of properly formatted formant
frequencies is accepted</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_output">output</code></td>
<td>
<p>&quot;simple&quot; (default) = just the VTL; &quot;detailed&quot; = a list of
additional stats (see Value below)</p>
</td></tr>
<tr><td><code id="estimateVTL_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the regression line whose slope gives formant
dispersion (method = &quot;regression&quot; only). Label sizes show the influence of
each formant, and the blue line corresponds to each formant being an
integer multiple of F1 (as when harmonics are misidentified as formants);
the second plot shows how VTL varies depending on the number of formants
used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>output = 'simple'</code> (default), returns the estimated vocal
tract length in cm. If <code>output = 'detailed'</code> and <code>method =
  'regression'</code>, returns a list with extra stats used for plotting. Namely,
<code>$regressionInfo$infl</code> gives the influence of each observation
calculated as the absolute change in VTL with vs without the observation *
10 + 1 (the size of labels on the first plot). <code>$vtlPerFormant$vtl</code>
gives the VTL as it would be estimated if only the first <code>nFormants</code>
were used.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+schwa">schwa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimateVTL(NA)
estimateVTL(500)
estimateVTL(c(600, 1850, 2800, 3600, 5000), plot = TRUE)
estimateVTL(c(600, 1850, 2800, 3600, 5000), plot = TRUE, output = 'detailed')
estimateVTL(c(1200, 2000, 2800, 3800, 5400, 6400),
  tube = 'open-open', interceptZero = FALSE, plot = TRUE)
estimateVTL(c(1200, 2000, 2800, 3800, 5400, 6400),
  tube = 'open-open', interceptZero = TRUE, plot = TRUE)

# Multiple measurements are OK
estimateVTL(
  formants = list(f1 = c(540, 600, 550),
  f2 = 1650, f3 = c(2400, 2550)),
  plot = TRUE, output = 'detailed')
# NB: this is better than averaging formant values. Cf.:
estimateVTL(
  formants = list(f1 = mean(c(540, 600, 550)),
  f2 = 1650, f3 = mean(c(2400, 2550))),
  plot = TRUE)

# Missing values are OK
estimateVTL(c(600, 1850, 3100, NA, 5000), plot = TRUE)
estimateVTL(list(f1 = 500, f2 = c(1650, NA, 1400), f3 = 2700), plot = TRUE)

# Note that VTL estimates based on the commonly reported 'meanDispersion'
# depend only on the first and last formants
estimateVTL(c(500, 1400, 2800, 4100), method = 'meanDispersion')
estimateVTL(c(500, 1100, 2300, 4100), method = 'meanDispersion') # identical
# ...but this is not the case for 'meanFormant' and 'regression' methods
estimateVTL(c(500, 1400, 2800, 4100), method = 'meanFormant')
estimateVTL(c(500, 1100, 2300, 4100), method = 'meanFormant') # much longer

## Not run: 
# Compare the results produced by the three methods
nIter = 1000
out = data.frame(meanFormant = rep(NA, nIter), meanDispersion = NA, regression = NA)
for (i in 1:nIter) {
  # generate a random formant configuration
  f = runif(1, 300, 900) + (1:6) * rnorm(6, 1000, 200)
  out$meanFormant[i]    = estimateVTL(f, method = 'meanFormant')
  out$meanDispersion[i] = estimateVTL(f, method = 'meanDispersion')
  out$regression[i]     = estimateVTL(f, method = 'regression')
}
pairs(out)
cor(out)
# 'meanDispersion' is pretty different, while 'meanFormant' and 'regression'
# give broadly comparable results

## End(Not run)
</code></pre>

<hr>
<h2 id='evaluatePars'>Evaluate parameters for optimization</h2><span id='topic+evaluatePars'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluatePars(
  p,
  pars,
  myfun,
  bounds = NULL,
  fitnessPar,
  fitnessFun = function(x) 1 - cor(x, key, use = "pairwise.complete.obs"),
  myfolder,
  key,
  otherPars = list(plot = FALSE),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evaluatePars_+3A_p">p</code></td>
<td>
<p>numeric vector of evaluated values of parameters</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_pars">pars</code></td>
<td>
<p>names of arguments to <code>myfun</code> that should be
optimized</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_myfun">myfun</code></td>
<td>
<p>the function being optimized: either 'segment' or
'analyze' (in quotes)</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_bounds">bounds</code></td>
<td>
<p>a list setting the lower and upper boundaries for possible
values of optimized parameters. For ex., if we optimize <code>smooth</code>
and <code>smoothOverlap</code>, reasonable bounds might be list(low = c(5,
0), high = c(500, 95))</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_fitnesspar">fitnessPar</code></td>
<td>
<p>the name of output variable that we are comparing with the
key, e.g. 'nBursts' or 'pitch_median'</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_fitnessfun">fitnessFun</code></td>
<td>
<p>the function used to evaluate how well the output of
<code>myfun</code> fits the key. Defaults to 1 - Pearson's correlation (i.e. 0 is
perfect fit, 1 is awful fit). For pitch, log scale is more meaningful, so a
good fitness criterion is &quot;function(x) 1 - cor(log(x), log(key), use =
'pairwise.complete.obs')&quot;</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_myfolder">myfolder</code></td>
<td>
<p>path to where the .wav files live</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_key">key</code></td>
<td>
<p>a vector containing the &quot;correct&quot; measurement that we are aiming
to reproduce</p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_otherpars">otherPars</code></td>
<td>
<p>a list of additional arguments to <code>myfun</code></p>
</td></tr>
<tr><td><code id="evaluatePars_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, reports the values of parameters evaluated and fitness</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Called by <code><a href="#topic+optimizePars">optimizePars</a></code>.
</p>


<h3>Value</h3>

<p>Returns 1 - Pearson's correlation between fitness measure and the key
(i.e. 0 is perfect fit, 1 is awful fit).
</p>

<hr>
<h2 id='fade'>Fade</h2><span id='topic+fade'></span>

<h3>Description</h3>

<p>Applies fade-in and/or fade-out of variable length, shape, and steepness. The
resulting effect softens the attack and release of a waveform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fade(
  x,
  fadeIn = 50,
  fadeOut = 50,
  fadeIn_points = NULL,
  fadeOut_points = NULL,
  samplingRate = NULL,
  scale = NULL,
  shape = c("lin", "exp", "log", "cos", "logistic", "gaussian")[1],
  steepness = 1,
  reportEvery = NULL,
  cores = 1,
  saveAudio = NULL,
  plot = FALSE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fade_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="fade_+3A_fadein">fadeIn</code>, <code id="fade_+3A_fadeout">fadeOut</code></td>
<td>
<p>length of segments for fading in and out, ms (0 = no
fade)</p>
</td></tr>
<tr><td><code id="fade_+3A_fadein_points">fadeIn_points</code>, <code id="fade_+3A_fadeout_points">fadeOut_points</code></td>
<td>
<p>length of segments for fading in and out,
points (if specified, override <code>fadeIn/fadeOut</code>)</p>
</td></tr>
<tr><td><code id="fade_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="fade_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="fade_+3A_shape">shape</code></td>
<td>
<p>controls the type of fade function: 'lin' = linear, 'exp' =
exponential, 'log' = logarithmic, 'cos' = cosine, 'logistic' = logistic
S-curve</p>
</td></tr>
<tr><td><code id="fade_+3A_steepness">steepness</code></td>
<td>
<p>scaling factor regulating the steepness of fading curves
(except for shapes 'lin' and 'cos'): 0 = linear, &gt;1 = steeper than default</p>
</td></tr>
<tr><td><code id="fade_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="fade_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="fade_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id="fade_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces an oscillogram of the waveform after fading</p>
</td></tr>
<tr><td><code id="fade_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="fade_+3A_width">width</code>, <code id="fade_+3A_height">height</code>, <code id="fade_+3A_units">units</code>, <code id="fade_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="fade_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of the same length as input
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crossFade">crossFade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' # Fading a real sound: say we want fast attack and slow release
s = soundgen(attack = 0, windowLength = 10,
             sylLen = 500, addSilence = 0)
# playme(s)
s1 = fade(s, fadeIn = 40, fadeOut = 350,
          samplingRate = 16000, shape = 'cos', plot = TRUE)
# playme(s1)

# Illustration of fade shapes
x = runif(5000, min = -1, max = 1)  # make sure to zero-center input!!!
# plot(x, type = 'l')
y = fade(x, fadeIn_points = 1000, fadeOut_points = 0, plot = TRUE)
y = fade(x, fadeIn_points = 1000, fadeOut_points = 1500,
         shape = 'exp', steepness = 1, plot = TRUE)
y = fade(x, fadeIn_points = 1500, fadeOut_points = 500,
         shape = 'log', steepness = 1, plot = TRUE)
y = fade(x, fadeIn_points = 1500, fadeOut_points = 500,
         shape = 'log', steepness = 3, plot = TRUE)
y = fade(x, fadeIn_points = 1500, fadeOut_points = 1500,
         shape = 'cos', plot = TRUE)
y = fade(x, fadeIn_points = 1500, fadeOut_points = 1500,
         shape = 'logistic', steepness = 1, plot = TRUE)
y = fade(x, fadeIn_points = 1500, fadeOut_points = 1500,
         shape = 'logistic', steepness = 3, plot = TRUE)
y = fade(x, fadeIn_points = 1500, fadeOut_points = 1500,
         shape = 'gaussian', steepness = 1.5, plot = TRUE)

## Not run: 
  fade('~/Downloads/temp', fadeIn = 500, fadeOut = 500, savePlots = '')

## End(Not run)
</code></pre>

<hr>
<h2 id='fart'>Fart</h2><span id='topic+fart'></span>

<h3>Description</h3>

<p>While the same sounds can be created with soundgen(), this facetious function
produces the same effect more efficiently and with very few control
parameters. With default settings, execution time is ~ 10 ms per second of
audio sampled at 16000 Hz. Principle: creates separate glottal cycles with
harmonics, but no formants. See <code><a href="#topic+soundgen">soundgen</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fart(
  glottis = c(50, 200),
  pitch = 65,
  temperature = 0.25,
  sylLen = 600,
  rolloff = -10,
  samplingRate = 16000,
  play = FALSE,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fart_+3A_glottis">glottis</code></td>
<td>
<p>anchors for specifying the proportion of a
glottal cycle with closed glottis, % (0 = no modification, 100 = closed
phase as long as open phase); numeric vector or dataframe specifying time
and value (anchor format)</p>
</td></tr>
<tr><td><code id="fart_+3A_pitch">pitch</code></td>
<td>
<p>a numeric vector of f0 values in Hz or a dataframe
specifying the time (ms or 0 to 1) and value (Hz) of each anchor, hereafter
&quot;anchor format&quot;. These anchors are used to create a smooth contour of
fundamental frequency f0 (pitch) within one syllable</p>
</td></tr>
<tr><td><code id="fart_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id="fart_+3A_syllen">sylLen</code></td>
<td>
<p>syllable length, ms (not vectorized)</p>
</td></tr>
<tr><td><code id="fart_+3A_rolloff">rolloff</code></td>
<td>
<p>rolloff of harmonics in source spectrum, dB/octave (not
vectorized)</p>
</td></tr>
<tr><td><code id="fart_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="fart_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="fart_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the waveform</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a normalized waveform.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+soundgen">soundgen</a></code> <code><a href="#topic+generateNoise">generateNoise</a></code>
<code><a href="#topic+beat">beat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f = fart()
# playme(f)

## Not run: 
while (TRUE) {
  fart(sylLen = 300, temperature = .5, play = TRUE)
  Sys.sleep(rexp(1, rate = 1))
}

## End(Not run)
</code></pre>

<hr>
<h2 id='filled.contour.mod'>Modified filled.contour</h2><span id='topic+filled.contour.mod'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filled.contour.mod(
  x = seq(0, 1, len = nrow(z)),
  y = seq(0, 1, len = ncol(z)),
  z,
  xlim = range(x, finite = TRUE),
  ylim = range(y, finite = TRUE),
  zlim = range(z, finite = TRUE),
  levels = seq(min(z, na.rm = TRUE), max(z, na.rm = TRUE), length.out = nlevels + 1),
  nlevels = 30,
  color.palette = function(n) grDevices::hcl.colors(n, "YlOrRd", rev = TRUE),
  col = color.palette(nlevels),
  legend = FALSE,
  asp = NA,
  xaxs = "i",
  yaxs = "i",
  las = 1,
  log = "",
  yScale = c("orig", "bark", "mel", "ERB")[1],
  axisX = TRUE,
  axisY = TRUE,
  maxPoints = 5e+05,
  y_Hz = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filled.contour.mod_+3A_x">x</code>, <code id="filled.contour.mod_+3A_y">y</code></td>
<td>
<p>locations of grid lines (NB: x = time, y = frequency in kHz, not Hz!)</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_z">z</code></td>
<td>
<p>numeric matrix of values to plot</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_xlim">xlim</code>, <code id="filled.contour.mod_+3A_ylim">ylim</code>, <code id="filled.contour.mod_+3A_zlim">zlim</code></td>
<td>
<p>limits for the plot</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_levels">levels</code></td>
<td>
<p>levels for partitioning z (modified compared to default
filled.contour to avoid artifacts)</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_nlevels">nlevels</code></td>
<td>
<p>numbers of levels for partitioning z</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_color.palette">color.palette</code></td>
<td>
<p>color palette function</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_col">col</code></td>
<td>
<p>list of colors instead of color.palette</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_asp">asp</code>, <code id="filled.contour.mod_+3A_xaxs">xaxs</code>, <code id="filled.contour.mod_+3A_yaxs">yaxs</code>, <code id="filled.contour.mod_+3A_...">...</code></td>
<td>
<p>graphical parameters passed to plot.window() and
axis()</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_log">log</code></td>
<td>
<p>log = 'y' log-transforms the y axis</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_axisx">axisX</code>, <code id="filled.contour.mod_+3A_axisy">axisY</code></td>
<td>
<p>plot the axis or not (logical)</p>
</td></tr>
<tr><td><code id="filled.contour.mod_+3A_y_hz">y_Hz</code></td>
<td>
<p>Y-labels in Hz or kHz (rescales by *1000 if kHz and max &lt; 1 kHz)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A bare-bones version of <code><a href="graphics.html#topic+filled.contour">filled.contour</a></code> that does not
plot a legend and accepts some additional graphical parameters like tick
marks.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sheep, package = 'seewave')
spec = spectrogram(sheep, from = 0.3, to = 0.6, plot = FALSE)
soundgen:::filled.contour.mod(z = t(spec))
</code></pre>

<hr>
<h2 id='filterMS'>Filter modulation spectrum</h2><span id='topic+filterMS'></span>

<h3>Description</h3>

<p>Filters a modulation spectrum by removing a certain range of amplitude
modulation (AM) and frequency modulation (FM) frequencies. Conditions can be
specified either separately for AM and FM with <code>amCond = ..., fmCond =
...</code>, implying an OR combination of conditions, or jointly on AM and FM with
<code>jointCond</code>. <code>jointCond</code> is more general, but using
<code>amCond/fmCond</code> is ~100 times faster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterMS(
  ms,
  amCond = NULL,
  fmCond = NULL,
  jointCond = NULL,
  action = c("remove", "preserve")[1],
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filterMS_+3A_ms">ms</code></td>
<td>
<p>a modulation spectrum as returned by
<code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code> - a matrix of real or complex values, AM
in columns, FM in rows</p>
</td></tr>
<tr><td><code id="filterMS_+3A_amcond">amCond</code>, <code id="filterMS_+3A_fmcond">fmCond</code></td>
<td>
<p>character strings with valid conditions on amplitude and
frequency modulation (see examples)</p>
</td></tr>
<tr><td><code id="filterMS_+3A_jointcond">jointCond</code></td>
<td>
<p>character string with a valid joint condition amplitude and
frequency modulation</p>
</td></tr>
<tr><td><code id="filterMS_+3A_action">action</code></td>
<td>
<p>should the defined AM-FM region be removed ('remove') or
preserved, while everything else is removed ('preserve')?</p>
</td></tr>
<tr><td><code id="filterMS_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the filtered modulation spectrum</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the filtered modulation spectrum - a matrix of the original
dimensions, real or complex.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ms = modulationSpectrum(soundgen(), samplingRate = 16000,
                        returnComplex = TRUE)$complex
# Remove all AM over 25 Hz
ms_filt = filterMS(ms, amCond = 'abs(am) &gt; 25')

# amCond and fmCond are OR-conditions
filterMS(ms, amCond = 'abs(am) &gt; 15', fmCond = 'abs(fm) &gt; 5', action = 'remove')
filterMS(ms, amCond = 'abs(am) &gt; 15', fmCond = 'abs(fm) &gt; 5', action = 'preserve')
filterMS(ms, amCond = 'abs(am) &gt; 10 &amp; abs(am) &lt; 25', action = 'remove')

# jointCond is an AND-condition
filterMS(ms, jointCond = 'am * fm &lt; 5', action = 'remove')
filterMS(ms, jointCond = 'am^2 + (fm*3)^2 &lt; 200', action = 'preserve')

# So:
filterMS(ms, jointCond = 'abs(am) &gt; 5 | abs(fm) &lt; 5')  # slow but general
# ...is the same as:
filterMS(ms, amCond = 'abs(am) &gt; 5', fmCond = 'abs(fm) &lt; 5')  # fast
</code></pre>

<hr>
<h2 id='filterSoundByMS'>Filter sound by modulation spectrum</h2><span id='topic+filterSoundByMS'></span>

<h3>Description</h3>

<p>Manipulates the modulation spectrum (MS) of a sound so as to remove certain
frequencies of amplitude modulation (AM) and frequency modulation (FM).
Algorithm: produces a modulation spectrum with
<code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code>, modifies it with <code><a href="#topic+filterMS">filterMS</a></code>,
converts the modified MS to a spectrogram with <code><a href="#topic+msToSpec">msToSpec</a></code>, and
finally inverts the spectrogram with <code><a href="#topic+invertSpectrogram">invertSpectrogram</a></code>, thus
producing a sound with (approximately) the desired characteristics of the MS.
Note that the last step of inverting the spectrogram introduces some noise,
so the resulting MS is not precisely the same as the intermediate filtered
version. In practice this means that some residual energy will still be
present in the filtered-out frequency range (see examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterSoundByMS(
  x,
  samplingRate = NULL,
  from = NULL,
  to = NULL,
  logSpec = FALSE,
  windowLength = 25,
  step = NULL,
  overlap = 80,
  wn = "hamming",
  zp = 0,
  amCond = NULL,
  fmCond = NULL,
  jointCond = NULL,
  action = c("remove", "preserve")[1],
  initialPhase = c("zero", "random", "spsi")[3],
  nIter = 50,
  reportEvery = NULL,
  cores = 1,
  play = FALSE,
  saveAudio = NULL,
  plot = TRUE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filterSoundByMS_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_from">from</code>, <code id="filterSoundByMS_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, the spectrogram is log-transformed prior to taking 2D
FFT</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_windowlength">windowLength</code>, <code id="filterSoundByMS_+3A_step">step</code>, <code id="filterSoundByMS_+3A_wn">wn</code>, <code id="filterSoundByMS_+3A_zp">zp</code></td>
<td>
<p>parameters for extracting a spectrogram if
<code>specType = 'STFT'</code>. Window length and step are specified in ms (see
<code><a href="#topic+spectrogram">spectrogram</a></code>). If <code>specType = 'audSpec'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_amcond">amCond</code>, <code id="filterSoundByMS_+3A_fmcond">fmCond</code></td>
<td>
<p>character strings with valid conditions on amplitude and
frequency modulation (see examples)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_jointcond">jointCond</code></td>
<td>
<p>character string with a valid joint condition amplitude and
frequency modulation</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_action">action</code></td>
<td>
<p>should the defined AM-FM region be removed ('remove') or
preserved, while everything else is removed ('preserve')?</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_initialphase">initialPhase</code></td>
<td>
<p>initial phase estimate: &quot;zero&quot; = set all phases to zero;
&quot;random&quot; = Gaussian noise; &quot;spsi&quot; (default) = single-pass spectrogram
inversion (Beauregard et al., 2015)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_niter">nIter</code></td>
<td>
<p>the number of iterations of the GL algorithm (Griffin &amp; Lim,
1984), 0 = don't run</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_play">play</code></td>
<td>
<p>if TRUE, plays back the reconstructed audio</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full (!) path to folder for saving the processed audio; NULL
= don't save, &rdquo; = same as input folder (NB: overwrites the originals!)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a triple plot: original MS, filtered MS, and
the MS of the output sound</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_saveplots">savePlots</code></td>
<td>
<p>if a valid path is specified, a plot is saved in this folder
(defaults to NA)</p>
</td></tr>
<tr><td><code id="filterSoundByMS_+3A_width">width</code>, <code id="filterSoundByMS_+3A_height">height</code>, <code id="filterSoundByMS_+3A_units">units</code>, <code id="filterSoundByMS_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the filtered audio as a numeric vector normalized to [-1, 1]
with the same sampling rate as input.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+invertSpectrogram">invertSpectrogram</a></code> <code><a href="#topic+filterMS">filterMS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a sound to be filtered
s = soundgen(pitch = rnorm(n = 20, mean = 200, sd = 25),
  amFreq = 25, amDep = 50, samplingRate = 16000,
  addSilence = 50, plot = TRUE, osc = TRUE)
# playme(s, 16000)

# Filter
s_filt = filterSoundByMS(s, samplingRate = 16000,
  amCond = 'abs(am) &gt; 15', fmCond = 'abs(fm) &gt; 5',
  nIter = 10,  # increase nIter for best results!
  action = 'remove', plot = TRUE)
# playme(s_filt, samplingRate = 16000)

## Not run: 
# Process all files in a folder, save filtered audio and plots
s_filt = filterSoundByMS('~/Downloads/temp2',
  saveAudio = '~/Downloads/temp2/ms', savePlots = '',
  amCond = 'abs(am) &gt; 15', fmCond = 'abs(fm) &gt; 5',
  action = 'remove', nIter = 10)

# Download an example - a bit of speech (sampled at 16000 Hz)
download.file('http://cogsci.se/soundgen/audio/speechEx.wav',
              destfile = '~/Downloads/speechEx.wav')  # modify as needed
target = '~/Downloads/speechEx.wav'
samplingRate = tuneR::readWave(target)@samp.rate
playme(target)
spectrogram(target, osc = TRUE)

# Remove AM above 3 Hz from a bit of speech (remove most temporal details)
s_filt1 = filterSoundByMS(target, amCond = 'abs(am) &gt; 3',
                          action = 'remove', nIter = 15)
playme(s_filt1, samplingRate)
spectrogram(s_filt1, samplingRate = samplingRate, osc = TRUE)

# Intelligigble when AM in 5-25 Hz is preserved:
s_filt2 = filterSoundByMS(target, amCond = 'abs(am) &gt; 5 &amp; abs(am) &lt; 25',
                          action = 'preserve', nIter = 15)
playme(s_filt2, samplingRate)
spectrogram(s_filt2, samplingRate = samplingRate, osc = TRUE)

# Remove slow AM/FM (prosody) to achieve a "robotic" voice
s_filt3 = filterSoundByMS(target, jointCond = 'am^2 + (fm*3)^2 &lt; 300',
                          nIter = 15)
playme(s_filt3, samplingRate)
spectrogram(s_filt3, samplingRate = samplingRate, osc = TRUE)


## An alternative manual workflow w/o calling filterSoundByMS()
# This way you can modify the MS directly and more flexibly
# than with the filterMS() function called by filterSoundByMS()

# (optional) Check that the target spectrogram can be successfully inverted
spec = spectrogram(s, 16000, windowLength = 50, step = NULL, overlap = 80,
  wn = 'hanning', osc = TRUE, padWithSilence = FALSE)
s_rev = invertSpectrogram(spec, samplingRate = 16000,
  windowLength = 50, overlap = 80, wn = 'hamming', play = FALSE)
# playme(s_rev, 16000)  # should be close to the original
spectrogram(s_rev, 16000, osc = TRUE)

# Get modulation spectrum starting from the sound...
ms = modulationSpectrum(s, samplingRate = 16000, windowLength = 25,
  overlap = 80, wn = 'hanning', amRes = NULL, maxDur = Inf, logSpec = FALSE,
  power = NA, returnComplex = TRUE, plot = FALSE)$complex
# ... or starting from the spectrogram:
# ms = specToMS(spec)
plotMS(abs(ms))  # this is the original MS

# Filter as needed - for ex., remove AM &gt; 10 Hz and FM &gt; 3 cycles/kHz
# (removes f0, preserves formants)
am = as.numeric(colnames(ms))
fm = as.numeric(rownames(ms))
idx_row = which(abs(fm) &gt; 3)
idx_col = which(abs(am) &gt; 10)
ms_filt = ms
ms_filt[idx_row, ] = 0
ms_filt[, idx_col] = 0
plotMS(abs(ms_filt))  # this is the filtered MS

# Convert back to a spectrogram
spec_filt = msToSpec(ms_filt)
image(t(log(abs(spec_filt))))

# Invert the spectrogram
s_filt = invertSpectrogram(abs(spec_filt), samplingRate = 16000,
  windowLength = 25, overlap = 80, wn = 'hanning')
# NB: use the same settings as in "spec = spectrogram(s, ...)" above

# Compare with the original
playme(s, 16000)
spectrogram(s, 16000, osc = TRUE)
playme(s_filt, 16000)
spectrogram(s_filt, 16000, osc = TRUE)

ms_new = modulationSpectrum(s_filt, samplingRate = 16000,
  windowLength = 25, overlap = 80, wn = 'hanning', maxDur = Inf,
  plot = TRUE, returnComplex = TRUE)$complex
image(x = as.numeric(colnames(ms_new)), y = as.numeric(rownames(ms_new)),
  z = t(log(abs(ms_new))))
plot(as.numeric(colnames(ms)), log(abs(ms[nrow(ms) / 2, ])), type = 'l')
points(as.numeric(colnames(ms_new)), log(ms_new[nrow(ms_new) / 2, ]), type = 'l',
  col = 'red', lty = 3)
# AM peaks at 25 Hz are removed, but inverting the spectrogram adds a lot of noise

## End(Not run)
</code></pre>

<hr>
<h2 id='findBursts'>Find bursts</h2><span id='topic+findBursts'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findBursts(
  ampl,
  step,
  windowLength,
  interburst,
  burstThres,
  peakToTrough,
  troughLocation = "either",
  scale = c("dB", "linear")[2]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findBursts_+3A_ampl">ampl</code></td>
<td>
<p>downsampled amplitude envelope</p>
</td></tr>
<tr><td><code id="findBursts_+3A_step">step</code></td>
<td>
<p>time difference between two points in the envelope (ms)</p>
</td></tr>
<tr><td><code id="findBursts_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="findBursts_+3A_interburst">interburst</code></td>
<td>
<p>minimum time between two consecutive bursts (ms). Defaults
to the average detected <code>(syllable + pause) / 2</code></p>
</td></tr>
<tr><td><code id="findBursts_+3A_peaktotrough">peakToTrough</code></td>
<td>
<p>to qualify as a burst, a local maximum has to be at least
<code>peakToTrough</code> dB above the left and/or right local trough(s)
(controlled by <code>troughLocation</code>) over the analysis window (controlled
by <code>interburst</code>). Defaults to SNR + 3 dB</p>
</td></tr>
<tr><td><code id="findBursts_+3A_troughlocation">troughLocation</code></td>
<td>
<p>should local maxima be compared to the trough on the
left and/or right of it? Values: 'left', 'right', 'both', 'either'</p>
</td></tr>
<tr><td><code id="findBursts_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Called by <code><a href="#topic+segment">segment</a></code>.
</p>


<h3>Value</h3>

<p>Returns a dataframe with timing of bursts
</p>

<hr>
<h2 id='findElbow'>Find the elbow of a screeplot or similar</h2><span id='topic+findElbow'></span>

<h3>Description</h3>

<p>Adapted from
https://stackoverflow.com/questions/2018178/finding-the-best-trade-off-point-on-a-curve
Algorithm: draw a straight line between the two endpoints and find the point
furthest from this line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findElbow(d, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findElbow_+3A_d">d</code></td>
<td>
<p>dataframe containing x and y coordinates of the points</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>y = c(10, 11, 8, 4, 2, 1.5, 1, 0.7, .5, .4, .3)
soundgen:::findElbow(data.frame(x = seq_along(y), y = y), plot = TRUE)
</code></pre>

<hr>
<h2 id='findGrad'>Find gradient</h2><span id='topic+findGrad'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findGrad(path, interpol = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findGrad_+3A_path">path</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="findGrad_+3A_interpol">interpol</code></td>
<td>
<p>the number of points to interpolate beyond each end of the path</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing of pitch contour. Returns
the elastic force acting on a snake. See <code><a href="#topic+snake">snake</a></code>.
</p>


<h3>Value</h3>

<p>Returns a vector of the same length as input path giving its 4th derivative.
</p>

<hr>
<h2 id='findInflections'>Find inflections</h2><span id='topic+findInflections'></span>

<h3>Description</h3>

<p>Finds inflections in discrete time series such as pitch contours. When there
are no missing values and no thresholds, this can be accomplished with a fast
one-liner like <code>which(diff(diff(x) &gt; 0) != 0) + 1</code>. Missing values are
interpolated by repeating the first and last non-missing values at the head
and tail, respectively, and by linear interpolation in the middle. Setting a
threshold means that small &quot;wiggling&quot; no longer counts. To use an analogy
with ocean waves, smoothing (low-pass filtering) removes the ripples and only
leaves the slow roll, while thresholding preserves only waves that are
sufficiently high, whatever their period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findInflections(x, thres = NULL, step = NULL, plot = FALSE, main = "")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findInflections_+3A_x">x</code></td>
<td>
<p>numeric vector with or without NAs</p>
</td></tr>
<tr><td><code id="findInflections_+3A_thres">thres</code></td>
<td>
<p>minimum vertical distance between two extrema for them to count
as two independent inflections</p>
</td></tr>
<tr><td><code id="findInflections_+3A_step">step</code></td>
<td>
<p>distance between values in s (only needed for plotting)</p>
</td></tr>
<tr><td><code id="findInflections_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a simple plot</p>
</td></tr>
<tr><td><code id="findInflections_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of indices giving the location of inflections.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findPeaks">findPeaks</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = sin(2 * pi * (1:100) / 15) * seq(1, 5, length.out = 100)
idx_na = c(1:4, 6, 7, 14, 25, 30:36, 39, 40, 42, 45:50,
           57, 59, 62, 66, 71:79, 98)
x[idx_na] = NA
soundgen:::findInflections(x, plot = TRUE)
soundgen:::findInflections(x, thres = 5, plot = TRUE)

for (i in 1:10) {
  temp = soundgen:::getRandomWalk(len = runif(1, 10, 100), rw_range = 10,
                                  rw_smoothing = runif(1, 0, 1))
  soundgen:::findInflections(temp, thres = 1, plot = TRUE)
  invisible(readline(prompt="Press [enter] to continue"))
}
</code></pre>

<hr>
<h2 id='findJumps'>Find frequency jumps</h2><span id='topic+findJumps'></span>

<h3>Description</h3>

<p>This function flags frames with apparent pith jumps (frequency jumps, voice
breaks), defined as relatively large and sudden changes in voice pitch or
some other frequency measure (peak frequency, a formant frequency, etc). It
is called by <code><a href="#topic+detectNLP">detectNLP</a></code>. Algorithm: a frame is considered to
contain a frequency jump if the absolute slope at this frame exceeds the
average slope over Â±<code>jumpWindow</code> around it by more than
<code>jumpThres</code>. Note that the slope is considered per second rather than
per time step - that is, taking into account the sampling rate of the
frequency track. Thus, it's not just the change from frame to frame that
defines what is considered a jump, but a change that differs from the trend
in the surrounding frames (see examples). If several consecutive frames
contain apparent jumps, only the greatest of them is preserved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findJumps(
  pitch,
  step,
  jumpThres = 8,
  jumpWindow = 80,
  plot = FALSE,
  xlab = "Time, ms",
  ylab = "f0, Hz",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findJumps_+3A_pitch">pitch</code></td>
<td>
<p>vector of frequencies per frame, Hz</p>
</td></tr>
<tr><td><code id="findJumps_+3A_step">step</code></td>
<td>
<p>time step between frames, ms</p>
</td></tr>
<tr><td><code id="findJumps_+3A_jumpthres">jumpThres</code></td>
<td>
<p>frames in which pitch changes by <code>jumpThres</code> octaves/s
more than in the surrounding frames are classified as containing &quot;pitch
jumps&quot;. Note that this is the rate of frequency change PER SECOND, not from
one frame to the next</p>
</td></tr>
<tr><td><code id="findJumps_+3A_jumpwindow">jumpWindow</code></td>
<td>
<p>the window for calculating the median pitch slope around
the analyzed frame, ms</p>
</td></tr>
<tr><td><code id="findJumps_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the pitch contour with putative frequency jumps
marked by arrows</p>
</td></tr>
<tr><td><code id="findJumps_+3A_xlab">xlab</code>, <code id="findJumps_+3A_ylab">ylab</code>, <code id="findJumps_+3A_...">...</code></td>
<td>
<p>graphical parameters passed to <code>plot</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a boolean vector of the same length as <code>pitch</code>, where
TRUE values correspond to frames with detected pitch jumps.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch = getSmoothContour(anchors = list(
  time = c(0, 350, 351, 890, 891, 1200),
  value = c(140, 230, 460, 330, 220, 200)), len = 40)
step = 25
pj = findJumps(pitch, step, plot = TRUE)

# convert frame indices to time in ms
step = 25
which(pj) * step
# or consider pj's to occur midway between the two frames
which(pj) * step - step / 2

# even very rapid changes are not considered jumps if they match
# the surrounding trend
pitch = getSmoothContour(anchors = list(
  time = c(0, 350, 351, 700),
  value = c(340, 710, 850, 1200)), len = 20)
findJumps(pitch, step, plot = TRUE)
diff(HzToSemitones(pitch)) * (1000 / step) / 12
# the slope at frame 10 (10.4 oct/s) exceeds the jumpThres (8 oct/s), but not
# 10.4 minus the average slope around frame 10 (~3 oct/s, so 10 - 3 &lt; 8)
</code></pre>

<hr>
<h2 id='findPeaks'>Find peaks</h2><span id='topic+findPeaks'></span>

<h3>Description</h3>

<p>A bare-bones, very fast function to find local maxima (peaks) in a numeric
vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findPeaks(x, wl = 3, thres = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findPeaks_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="findPeaks_+3A_wl">wl</code></td>
<td>
<p>rolling window over which we look for maxima: central value Â±
floor(wl/2), eg Â±1 if wl=3</p>
</td></tr>
<tr><td><code id="findPeaks_+3A_thres">thres</code></td>
<td>
<p>required absolute value of each peak</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with indices of local maxima
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findInflections">findInflections</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(100)
findPeaks(x, wl = 3)
findPeaks(x, wl = 3, thres = 1)
findPeaks(x, wl = 5)
idx = findPeaks(x, wl = 5, thres = 1)
plot(x, type = 'b'); abline(h = 1, lty = 3)
points(idx, x[idx], col = 'blue', pch = 8)
</code></pre>

<hr>
<h2 id='findSyllables'>Find syllables</h2><span id='topic+findSyllables'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findSyllables(ampl, step, windowLength, threshold, shortestSyl, shortestPause)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findSyllables_+3A_ampl">ampl</code></td>
<td>
<p>downsampled amplitude envelope</p>
</td></tr>
<tr><td><code id="findSyllables_+3A_step">step</code></td>
<td>
<p>time difference between two points in the envelope (ms)</p>
</td></tr>
<tr><td><code id="findSyllables_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="findSyllables_+3A_threshold">threshold</code></td>
<td>
<p>all continuous segments above this value are considered to
be syllables</p>
</td></tr>
<tr><td><code id="findSyllables_+3A_shortestsyl">shortestSyl</code></td>
<td>
<p>minimum acceptable length of syllables, ms</p>
</td></tr>
<tr><td><code id="findSyllables_+3A_shortestpause">shortestPause</code></td>
<td>
<p>minimum acceptable break between syllables, ms
(syllables separated by shorter pauses are merged)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Called by <code><a href="#topic+segment">segment</a></code>.
</p>


<h3>Value</h3>

<p>Returns a dataframe with timing of syllables.
</p>

<hr>
<h2 id='findVoicedSegments'>Find voiced segments</h2><span id='topic+findVoicedSegments'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findVoicedSegments(
  pitchCands,
  shortestSyl,
  shortestPause,
  step,
  minVoicedCands,
  pitchMethods,
  manualV = NULL,
  manualTryToV = NULL,
  manualUnv = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findVoicedSegments_+3A_pitchcands">pitchCands</code></td>
<td>
<p>matrix of possible pitch values per column. One column is
one fft frame, one row is one pitch candidate</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_shortestsyl">shortestSyl</code></td>
<td>
<p>the smallest length of a voiced segment (ms) that
constitutes a voiced syllable (shorter segments will be replaced by NA, as
if unvoiced)</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_shortestpause">shortestPause</code></td>
<td>
<p>the smallest gap between voiced syllables (ms): large
value = interpolate and merge, small value = treat as separate syllables
separated by an unvoiced gap</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_minvoicedcands">minVoicedCands</code></td>
<td>
<p>a frame is considered to be voiced if at least this
many pitch candidates are not NA. Defaults to 2: since dom is usually
defined, in practice this means that we also want at least one other pitch
candidate (autocor, cep or BaNa)</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_pitchmethods">pitchMethods</code></td>
<td>
<p>methods of pitch tracking in analyze()</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_manualv">manualV</code></td>
<td>
<p>index of frames that should definitely be voiced (manual
candidates)</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_manualtrytov">manualTryToV</code></td>
<td>
<p>index of frames that should be treated as voiced as long
as they have any candidates at all (even &lt;minVoicedCands)</p>
</td></tr>
<tr><td><code id="findVoicedSegments_+3A_manualunv">manualUnv</code></td>
<td>
<p>index of frames forced to be unvoiced</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing of pitch contours. Merges voiced
segments at least <code>shortestSyl</code> ms long and separated by less than
<code>shortestPause</code> ms. Called by <code><a href="#topic+analyze">analyze</a></code>
</p>


<h3>Value</h3>

<p>Returns a dataframe specifying where each voiced segment starts and
ends (in fft frames, not ms!)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch = c(rep(NA, 5), rnorm(15, 300, 15), rep(NA, 7), rnorm(10, 400, 10), rep(NA, 6))
plot(pitch, type = 'b')
soundgen:::findVoicedSegments(
  pitchCands = matrix(pitch, nr = 1),
  shortestSyl = 20,
  shortestPause = 60,
  step = 10,
  minVoicedCands = 1,
  pitchMethods = 'blabla',
  manualV = NULL,
  manualTryToV = NULL,
  manualUnv = NULL
)
</code></pre>

<hr>
<h2 id='findZeroCrossing'>Find zero crossing</h2><span id='topic+findZeroCrossing'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findZeroCrossing(ampl, location)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findZeroCrossing_+3A_ampl">ampl</code></td>
<td>
<p>a vector of amplitudes oscillating around zero, such as a sound
waveform</p>
</td></tr>
<tr><td><code id="findZeroCrossing_+3A_location">location</code></td>
<td>
<p>the index indicating the desired location of a zero crossing</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>findZeroCrossing</code> looks for the last negative point before a zero
crossing as close as possible to the specified location. Since this is
primarily intended for joining waveforms without a click, this function only
looks at upward segments of a waveform (see example).
</p>


<h3>Value</h3>

<p>Returns the index of the last negative value before zero crossing
closest to specified location.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ampl = sin(1:100/2)
plot(ampl, type = 'b')
lines(1:100, rep(0,100), lty = 2)
zc = vector()
for (i in seq_along(ampl)){
  zc[i] = soundgen:::findZeroCrossing (ampl, i)
  # find zc closest to each of 100 points
}
for (z in unique(zc)){
  points(z, ampl[z], col = 'red', pch = 17)
  # only on upward segments
}
zc # see which zc is closest to each point
</code></pre>

<hr>
<h2 id='flatEnv'>Flat envelope / compressor</h2><span id='topic+flatEnv'></span><span id='topic+compressor'></span>

<h3>Description</h3>

<p>Applies a compressor - that is, flattens the amplitude envelope of a
waveform, reducing the difference in amplitude between loud and quiet
sections. This is achieved by dividing the waveform by some function of its
smoothed amplitude envelope (Hilbert, peak or root mean square).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flatEnv(
  x,
  samplingRate = NULL,
  scale = NULL,
  compression = 1,
  method = c("hil", "rms", "peak")[1],
  windowLength = 50,
  windowLength_points = NULL,
  killDC = FALSE,
  dynamicRange = 40,
  reportEvery = NULL,
  cores = 1,
  saveAudio = NULL,
  plot = FALSE,
  savePlots = NULL,
  col = "blue",
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)

compressor(
  x,
  samplingRate = NULL,
  scale = NULL,
  compression = 1,
  method = c("hil", "rms", "peak")[1],
  windowLength = 50,
  windowLength_points = NULL,
  killDC = FALSE,
  dynamicRange = 40,
  reportEvery = NULL,
  cores = 1,
  saveAudio = NULL,
  plot = FALSE,
  savePlots = NULL,
  col = "blue",
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flatEnv_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_compression">compression</code></td>
<td>
<p>the amount of compression to apply: 0 = none, 1 = maximum</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_method">method</code></td>
<td>
<p>hil = Hilbert envelope, rms = root mean square amplitude, peak
= peak amplitude per window</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_windowlength">windowLength</code></td>
<td>
<p>the length of smoothing window, ms</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>the length of smoothing window, points. If
specified, overrides <code>windowLength</code></p>
</td></tr>
<tr><td><code id="flatEnv_+3A_killdc">killDC</code></td>
<td>
<p>if TRUE, dynamically removes DC offset or similar deviations of
average waveform from zero (see examples)</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>parts of sound quieter than <code>-dynamicRange</code> dB will
not be amplified</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save the compressed
sound(s)</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original sound, the smoothed envelope, and
the compressed sound</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_col">col</code></td>
<td>
<p>the color of amplitude contours</p>
</td></tr>
<tr><td><code id="flatEnv_+3A_width">width</code>, <code id="flatEnv_+3A_height">height</code>, <code id="flatEnv_+3A_units">units</code>, <code id="flatEnv_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="flatEnv_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to <code>points()</code> that control
the appearance of amplitude contours, eg <code>lwd, lty</code>, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the input is a single audio (file, Wave, or numeric vector),
returns the compressed waveform as a numeric vector with the original
sampling rate and scale. If the input is a folder with several audio files,
returns a list of compressed waveforms, one for each file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = rnorm(500) * seq(1, 0, length.out = 500)
b = flatEnv(a, 1000, plot = TRUE, windowLength_points = 5)    # too short
c = flatEnv(a, 1000, plot = TRUE, windowLength_points = 450)  # too long
d = flatEnv(a, 1000, plot = TRUE, windowLength_points = 100)  # about right

## Not run: 
s = soundgen(sylLen = 1000, ampl = c(0, -40, 0), plot = TRUE)
# playme(s)
s_flat1 = flatEnv(s, 16000, dynamicRange = 60, plot = TRUE,
                  windowLength = 50, method = 'hil')
s_flat2 = flatEnv(s, 16000, dynamicRange = 60, plot = TRUE,
                  windowLength = 10, method = 'rms')
s_flat3 = flatEnv(s, 16000, dynamicRange = 60, plot = TRUE,
                  windowLength = 10, method = 'peak')
# playme(s_flat2)

# Remove DC offset
s1 = c(rep(0, 50), runif(1000, -1, 1), rep(0, 50)) +
     seq(.3, 1, length.out = 1100)
s2 = flatEnv(s1, 16000, plot = TRUE, windowLength_points = 50, killDC = FALSE)
s3 = flatEnv(s1, 16000, plot = TRUE, windowLength_points = 50, killDC = TRUE)

# Compress and save all audio files in a folder
s4 = flatEnv('~/Downloads/temp',
             method = 'peak', compression = .5,
             saveAudio = '~/Downloads/temp/compressed',
             savePlots = '~/Downloads/temp/compressed',
             col = 'green', lwd = 5)
osc(s4[[1]])

## End(Not run)
</code></pre>

<hr>
<h2 id='flatSpectrum'>Flat spectrum</h2><span id='topic+flatSpectrum'></span>

<h3>Description</h3>

<p>Flattens the spectrum of a sound by smoothing in the frequency domain. Can be
used for removing formants without modifying pitch contour or voice quality
(the balance of harmonic and noise components), followed by the addition of a
new spectral envelope (cf. <code><a href="#topic+transplantFormants">transplantFormants</a></code>). Algorithm:
makes a spectrogram, flattens the real part of the smoothed spectrum of each
STFT frame, and transforms back into time domain with inverse STFT (see also
<code><a href="#topic+addFormants">addFormants</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flatSpectrum(
  x,
  samplingRate = NULL,
  freqWindow = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = NULL,
  overlap = 90,
  wn = "gaussian",
  zp = 0,
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flatSpectrum_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of smoothing window, Hz. Defaults to median
pitch estimated by <code><a href="#topic+analyze">analyze</a></code></p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full (!) path to folder for saving the processed audio; NULL
= don't save, &rdquo; = same as input folder (NB: overwrites the originals!)</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="flatSpectrum_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector with the same sampling rate as the input.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+addFormants">addFormants</a></code> <code><a href="#topic+transplantFormants">transplantFormants</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound_aii = soundgen(formants = 'aii')
# playme(sound_aii, 16000)
seewave::meanspec(sound_aii, f = 16000, dB = 'max0')

sound_flat = flatSpectrum(sound_aii, freqWindow = 150, samplingRate = 16000)
# playme(sound_flat, 16000)
seewave::meanspec(sound_flat, f = 16000, dB = 'max0')
# harmonics are still there, but formants are gone and can be replaced

## Not run: 
# Now let's make a sheep say "aii"
data(sheep, package = 'seewave')  # import a recording from seewave
playme(sheep)
sheep_flat = flatSpectrum(sheep)
playme(sheep_flat, sheep@samp.rate)
seewave::spec(sheep_flat, f = sheep@samp.rate, dB = 'max0')

# So far we have a sheep bleating with a flat spectrum;
# now let's add new formants
sheep_aii = addFormants(sheep_flat,
  samplingRate = sheep@samp.rate,
  formants = 'aii',
  lipRad = -3)  # negative lipRad to counter unnatural flat source
playme(sheep_aii, sheep@samp.rate)
spectrogram(sheep_aii, sheep@samp.rate)
seewave::spec(sheep_aii, f = sheep@samp.rate, dB = 'max0')

## End(Not run)
</code></pre>

<hr>
<h2 id='forcePerPath'>Force per path</h2><span id='topic+forcePerPath'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forcePerPath(pitch, pitchCands, pitchCert, pitchCenterGravity, certWeight)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forcePerPath_+3A_pitch">pitch</code></td>
<td>
<p>numeric vector representing our best guess at pitch contour,
which we are now attempting to improve by minimizing its elastic tension</p>
</td></tr>
<tr><td><code id="forcePerPath_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="forcePerPath_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="forcePerPath_+3A_pitchcentergravity">pitchCenterGravity</code></td>
<td>
<p>numeric vector giving the mean of all pitch
candidates per fft frame weighted by our certainty in each of these
candidates</p>
</td></tr>
<tr><td><code id="forcePerPath_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing of pitch contour. Returns the
total force acting on a snake (sum of internal and external gradients, i.e.
of the elastic force trying to straighten the snake [internal] and of the
force pushing the snake towards the most certain pitch estimates [external])
</p>


<h3>Value</h3>

<p>Returns a numeric vector of the same length as <code>pitch</code> that
gives the total force acting on the snake at each point.
</p>

<hr>
<h2 id='formant_app'>Interactive formant tracker</h2><span id='topic+formant_app'></span>

<h3>Description</h3>

<p>Starts a shiny app for manually correcting formant measurements. For more
tips, see <code><a href="#topic+pitch_app">pitch_app</a></code> and http://cogsci.se/soundgen.html.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formant_app()
</code></pre>


<h3>Details</h3>

<p>Suggested workflow: load one or several audio files (wav/mp3), preferably not
longer than a minute or so. Select a region of interest in the spectrogram -
for example, a sustained vowel with clear and relatively steady formants.
Double-click within the selection to create a new annotation (you may add a
text label if needed). If you are satisfied with the automatically calculated
formant frequencies, proceed to the next region of interest. If not, there
are 4 ways to adjust them: (1) type in the correct number in one of the
formant boxes in the top right corner; (2) click a spectrogram within
selection (pick the formant number to adjust by clicking the formant boxes);
(3) single-click the spectrum to use the cursor's position, or (4)
double-click the spectrum to use the nearest spectral peak. When done with a
file, move on to the next one in the queue. Use the orange button to download
the results. To continue work, upload the output file from the previous
session together with the audio files (you can rename it, but keep the .csv
extension). Use hotkeys (eg spacebar to play/stop) and avoid working with
very large files.
</p>


<h3>Value</h3>

<p>Every time a new annotation is added, the app creates a backup csv
file and creates or updates a global object called &quot;my_formants&quot;, which
contains all the annotations. When the app is terminated, it also returns
the results as a dataframe.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pitch_app">pitch_app</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
f = formant_app()  # runs in default browser such as Firefox or Chrome

# To change system default browser, run something like:
options('browser' = '/usr/bin/firefox')  # path to the executable on Linux

## End(Not run)
</code></pre>

<hr>
<h2 id='formatPitchManual'>Format pitchManual</h2><span id='topic+formatPitchManual'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatPitchManual(pitchManual)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="formatPitchManual_+3A_pitchmanual">pitchManual</code></td>
<td>
<p>dataframe produced by analyze() or pitch_app(), path to a
.csv file in which this dataframe is stored, a named list with a numeric
vector of pitch values per sound, or a numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of pitch contours.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::formatPitchManual(c(NA, 120, 180, NA))
soundgen:::formatPitchManual('NA, 120, 180, NA')
soundgen:::formatPitchManual(list(
  'myfile.wav' = list(pitch = c(NA, 120, 180, NA))
))
soundgen:::formatPitchManual(data.frame(file = c('file1.wav', 'file2.wav'),
                                        pitch = c('NA, 120', '180, NA')))
soundgen:::formatPitchManual('adja')
</code></pre>

<hr>
<h2 id='gaussianSmooth2D'>Gaussian smoothing in 2D</h2><span id='topic+gaussianSmooth2D'></span>

<h3>Description</h3>

<p>Takes a matrix of numeric values and smoothes it by convolution with a
symmetric Gaussian window function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussianSmooth2D(
  m,
  kernelSize = 5,
  kernelSD = 0.5,
  action = c("blur", "unblur")[1],
  plotKernel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gaussianSmooth2D_+3A_m">m</code></td>
<td>
<p>input matrix (numeric, on any scale, doesn't have to be square)</p>
</td></tr>
<tr><td><code id="gaussianSmooth2D_+3A_kernelsize">kernelSize</code></td>
<td>
<p>the size of the Gaussian kernel, in points</p>
</td></tr>
<tr><td><code id="gaussianSmooth2D_+3A_kernelsd">kernelSD</code></td>
<td>
<p>the SD of the Gaussian kernel relative to its size (.5 = the
edge is two SD's away)</p>
</td></tr>
<tr><td><code id="gaussianSmooth2D_+3A_action">action</code></td>
<td>
<p>'blur' = kernel-weighted average, 'unblur' = subtract
kernel-weighted average</p>
</td></tr>
<tr><td><code id="gaussianSmooth2D_+3A_plotkernel">plotKernel</code></td>
<td>
<p>if TRUE, plots the kernel</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric matrix of the same dimensions as input.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = spectrogram(soundgen(), samplingRate = 16000, windowLength = 10,
  output = 'original', plot = FALSE)
s = log(s + .001)
# image(s)
s1 = gaussianSmooth2D(s, kernelSize = 5, plotKernel = TRUE)
# image(s1)

## Not run: 
# more smoothing in time than in frequency
s2 = gaussianSmooth2D(s, kernelSize = c(5, 15))
image(s2)

# vice versa - more smoothing in frequency
s3 = gaussianSmooth2D(s, kernelSize = c(25, 3))
image(s3)

# sharpen the image by deconvolution with the kernel
s4 = gaussianSmooth2D(s1, kernelSize = 5, action = 'unblur')
image(s4)

s5 = gaussianSmooth2D(s, kernelSize = c(15, 1), action = 'unblur')
image(s5)

## End(Not run)
</code></pre>

<hr>
<h2 id='generateEpoch'>Generate an epoch</h2><span id='topic+generateEpoch'></span>

<h3>Description</h3>

<p>Internal soundgen function.
Takes descriptives of a number of glottal cycles (f0, closed phase, rolloff)
and creates a continuous waveform. The principle is to work with one epoch
with stable regime of subharmonics at a time and create a sine wave for each
harmonic, with amplitudes adjusted by rolloff.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateEpoch(pitch_per_gc, epochs, rolloff_per_epoch, samplingRate)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateEpoch_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>pitch per glottal cycle, Hz</p>
</td></tr>
<tr><td><code id="generateEpoch_+3A_epochs">epochs</code></td>
<td>
<p>a dataframe specifying the beginning and end of each epoch</p>
</td></tr>
<tr><td><code id="generateEpoch_+3A_rolloff_per_epoch">rolloff_per_epoch</code></td>
<td>
<p>a list of matrices with one matrix for each epoch; each
matrix should contain one column for each glottal cycle and one row for
each harmonic (linear multiplier, ie NOT in dB). Rownames specify the ratio
to F0 (eg 1.5 means it's a subharmonic added between f0 and its first
harmonic)</p>
</td></tr>
<tr><td><code id="generateEpoch_+3A_samplingrate">samplingRate</code></td>
<td>
<p>the sampling rate of generated sound, Hz</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a waveform as a non-normalized numeric vector centered at zero.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch_per_gc = seq(100, 150, length.out = 90)
epochs = data.frame (start = c(1, 51),
                     end = c(50, 90))
m1 = matrix(rep(10 ^ (-6 * log2(1:200) / 20), 50), ncol = 50, byrow = FALSE)
m2 = matrix(rep(10 ^ (-12 * log2(1:200) / 20), 40), ncol = 40, byrow = FALSE)
rownames(m1) = 1:nrow(m1)
rownames(m2) = 1:nrow(m2)
rolloff_source = list(m1, m2)
s = soundgen:::generateEpoch(pitch_per_gc, epochs,
                             rolloff_source, samplingRate = 16000)
# plot(s, type = 'l')
# playme(s)
</code></pre>

<hr>
<h2 id='generateGC'>Generate glottal cycles</h2><span id='topic+generateGC'></span>

<h3>Description</h3>

<p>Internal soundgen function. Takes descriptives of a number of glottal cycles
(f0, closed phase, rolloff - note that all three should be vectors of the
same length, namely nGC) and creates a waveform consisting of a string of
these glottal cycles separated by pauses (if there is a closed phase). The
principle is to work with one glottal cycle at a time and create a sine wave
for each harmonic, with amplitudes adjusted by rolloff.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateGC(
  pitch_per_gc,
  glottisClosed_per_gc,
  rolloff_per_gc,
  samplingRate,
  wn = "none",
  interpol = "approx"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateGC_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>pitch per glottal cycle, Hz</p>
</td></tr>
<tr><td><code id="generateGC_+3A_glottisclosed_per_gc">glottisClosed_per_gc</code></td>
<td>
<p>proportion of closed phase per glottal cycle, %</p>
</td></tr>
<tr><td><code id="generateGC_+3A_rolloff_per_gc">rolloff_per_gc</code></td>
<td>
<p>a list of one-column matrices, one for each glottal
cycle, specifying rolloff per harmonic (linear multiplier, ie NOT in dB)
Each matrix has as many rows as there are harmonics, and rownames specify
the ratio to F0 (eg 1.5 means it's a subharmonic added between f0 and its
first harmonic)</p>
</td></tr>
<tr><td><code id="generateGC_+3A_samplingrate">samplingRate</code></td>
<td>
<p>the sampling rate of generated sound, Hz</p>
</td></tr>
<tr><td><code id="generateGC_+3A_wn">wn</code></td>
<td>
<p>windowing function applied to each glottal cycle (see
<code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>)</p>
</td></tr>
<tr><td><code id="generateGC_+3A_interpol">interpol</code></td>
<td>
<p>method used to adjust the number of gc to target duration</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a waveform as a non-normalized numeric vector centered at
zero.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch_per_gc = seq(100, 150, length.out = 25)
glottisClosed_per_gc = seq(0, 300, length.out = 25)
m = matrix(10 ^ (-6 * log2(1:200) / 20))
rownames(m) = 1:nrow(m)
rolloff_per_gc = rep(list(m), 25)
s = soundgen:::generateGC(pitch_per_gc, glottisClosed_per_gc,
                          rolloff_per_gc, samplingRate = 16000)
# plot(s, type = 'l')
# playme(s)
</code></pre>

<hr>
<h2 id='generateHarmonics'>Generate harmonics</h2><span id='topic+generateHarmonics'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateHarmonics(
  pitch,
  glottis = 0,
  attackLen = 50,
  nonlinBalance = 0,
  nonlinDep = 50,
  nonlinRandomWalk = NULL,
  jitterDep = 0,
  jitterLen = 1,
  vibratoFreq = 5,
  vibratoDep = 0,
  shimmerDep = 0,
  shimmerLen = 1,
  rolloff = -9,
  rolloffOct = 0,
  rolloffKHz = 0,
  rolloffParab = 0,
  rolloffParabHarm = 3,
  rolloff_perAmpl = 0,
  rolloffExact = NULL,
  formantLocking = NULL,
  specEnv = NULL,
  formantSummary = NULL,
  temperature = 0.025,
  pitchDriftDep = 0.5,
  pitchDriftFreq = 0.125,
  amplDriftDep = 1,
  subDriftDep = 4,
  rolloffDriftDep = 3,
  randomWalk_trendStrength = 0.1,
  shortestEpoch = 300,
  subRatio = 1,
  subFreq = 100,
  subDep = 0,
  subWidth = 10000,
  ampl = NA,
  normalize = TRUE,
  smoothing = list(),
  overlap = 75,
  samplingRate = 16000,
  pitchFloor = 75,
  pitchCeiling = 3500,
  pitchSamplingRate = 3500,
  dynamicRange = 80
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateHarmonics_+3A_pitch">pitch</code></td>
<td>
<p>a contour of fundamental frequency (numeric vector). NB: for
computational efficiency, provide the pitch contour at a reduced sampling
rate pitchSamplingRate, eg 3500 points/s. The pitch contour will be
upsampled before synthesis.</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_glottis">glottis</code></td>
<td>
<p>anchors for specifying the proportion of a
glottal cycle with closed glottis, % (0 = no modification, 100 = closed
phase as long as open phase); numeric vector or dataframe specifying time
and value (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_attacklen">attackLen</code></td>
<td>
<p>duration of fade-in / fade-out at each end of syllables and
noise (ms): a vector of length 1 (symmetric) or 2 (separately for fade-in
and fade-out)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_nonlinbalance">nonlinBalance</code></td>
<td>
<p>hyperparameter for regulating the (approximate)
proportion of sound with different regimes of pitch effects (none /
subharmonics only / subharmonics and jitter). 0% = no noise; 100% = the
entire sound has jitter + subharmonics. Ignored if temperature = 0</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_nonlinrandomwalk">nonlinRandomWalk</code></td>
<td>
<p>a numeric vector specifying the timing of nonliner
regimes: 0 = none, 1 = subharmonics, 2 = subharmonics + jitter + shimmer</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_jitterdep">jitterDep</code></td>
<td>
<p>cycle-to-cycle random pitch variation, semitones (anchor
format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_jitterlen">jitterLen</code></td>
<td>
<p>duration of stable periods between pitch jumps, ms. Use a
low value for harsh noise, a high value for irregular vibrato or shaky
voice (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_vibratofreq">vibratoFreq</code></td>
<td>
<p>the rate of regular pitch modulation, or vibrato, Hz
(anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_vibratodep">vibratoDep</code></td>
<td>
<p>the depth of vibrato, semitones (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_shimmerdep">shimmerDep</code></td>
<td>
<p>random variation in amplitude between individual glottal
cycles (0 to 100% of original amplitude of each cycle) (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_shimmerlen">shimmerLen</code></td>
<td>
<p>duration of stable periods between amplitude jumps, ms. Use
a low value for harsh noise, a high value for shaky voice (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloff">rolloff</code></td>
<td>
<p>basic rolloff from lower to upper harmonics, db/octave
(exponential decay). All rolloff parameters are in anchor format. See
<code><a href="#topic+getRolloff">getRolloff</a></code> for more details</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloffoct">rolloffOct</code></td>
<td>
<p>basic rolloff changes from lower to upper harmonics
(regardless of f0) by <code>rolloffOct</code> dB/oct. For example, we can get
steeper rolloff in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloffkhz">rolloffKHz</code></td>
<td>
<p>rolloff changes linearly with f0 by <code>rolloffKHz</code>
dB/kHz. For ex., -6 dB/kHz gives a 6 dB steeper basic rolloff as f0 goes up
by 1000 Hz</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloffparab">rolloffParab</code></td>
<td>
<p>an optional quadratic term affecting only the first
<code>rolloffParabHarm</code> harmonics. The middle harmonic of the first
<code>rolloffParabHarm</code> harmonics is amplified or dampened by
<code>rolloffParab</code> dB relative to the basic exponential decay</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloffparabharm">rolloffParabHarm</code></td>
<td>
<p>the number of harmonics affected by
<code>rolloffParab</code></p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloff_perampl">rolloff_perAmpl</code></td>
<td>
<p>as amplitude goes down from max to
<code>-dynamicRange</code>, <code>rolloff</code> increases by <code>rolloff_perAmpl</code>
dB/octave. The effect is to make loud parts brighter by increasing energy
in higher frequencies</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloffexact">rolloffExact</code></td>
<td>
<p>user-specified exact strength of harmonics: a vector or
matrix with one row per harmonic, scale 0 to 1 (overrides all other rolloff
parameters)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_formantlocking">formantLocking</code></td>
<td>
<p>the approximate proportion of sound in which one of the
harmonics is locked to the nearest formant, 0 = none, 1 = the entire sound
(anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_specenv">specEnv</code></td>
<td>
<p>a matrix representing the filter (only needed for formant
locking)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_pitchdriftdep">pitchDriftDep</code></td>
<td>
<p>scale factor regulating the effect of temperature on the
amount of slow random drift of f0 (like jitter, but slower): the higher,
the more f0 &quot;wiggles&quot; at a given temperature</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_pitchdriftfreq">pitchDriftFreq</code></td>
<td>
<p>scale factor regulating the effect of temperature on
the frequency of random drift of f0 (like jitter, but slower): the higher,
the faster f0 &quot;wiggles&quot; at a given temperature</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_ampldriftdep">amplDriftDep</code></td>
<td>
<p>drift of amplitude mirroring pitch drift</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_subdriftdep">subDriftDep</code></td>
<td>
<p>drift of subharmonic frequency and bandwidth mirroring
pitch drift</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_rolloffdriftdep">rolloffDriftDep</code></td>
<td>
<p>drift of rolloff mirroring pitch drift</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_randomwalk_trendstrength">randomWalk_trendStrength</code></td>
<td>
<p>try 0 to 1 - the higher, the more likely rw
is to get high in the middle and low at the beginning and end (i.e. max
effect amplitude in the middle of a sound)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_shortestepoch">shortestEpoch</code></td>
<td>
<p>minimum duration of each epoch with unchanging
subharmonics regime or formant locking, in ms</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_subratio">subRatio</code></td>
<td>
<p>a positive integer giving the ratio of f0 (the main
fundamental) to g0 (a lower frequency): 1 = no subharmonics, 2 = period
doubling regardless of pitch changes, 3 = period tripling, etc; subRatio
overrides subFreq (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_subfreq">subFreq</code></td>
<td>
<p>instead of a specific number of subharmonics (subRatio), we
can specify the approximate g0 frequency (Hz), which is used only if
subRatio = 1 and is adjusted to f0 so f0/g0 is always an integer (anchor
format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_subdep">subDep</code></td>
<td>
<p>the depth of subharmonics relative to the main frequency
component (f0), %. 0: no subharmonics; 100: g0 harmonics are as strong as
the nearest f0 harmonic (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_subwidth">subWidth</code></td>
<td>
<p>Width of subharmonic sidebands - regulates how rapidly
g-harmonics weaken away from f-harmonics: large values like the default
10000 means that all g0 harmonics are equally strong (anchor format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_ampl">ampl</code></td>
<td>
<p>amplitude envelope (dB, 0 = max amplitude) (anchor
format)</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, normalizes to -1...+1 prior to applying attack and
amplitude envelope. W/o this, sounds with stronger harmonics are louder</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_smoothing">smoothing</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+getSmoothContour">getSmoothContour</a></code> to control the interpolation and smoothing
of contours: interpol (approx / spline / loess), loessSpan, discontThres,
jumpThres</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_overlap">overlap</code></td>
<td>
<p>FFT window overlap, %. For allowed values, see
<code><a href="seewave.html#topic+istft">istft</a></code></p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_pitchfloor">pitchFloor</code>, <code id="generateHarmonics_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>lower &amp; upper bounds of f0</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_pitchsamplingrate">pitchSamplingRate</code></td>
<td>
<p>sampling frequency of the pitch contour only, Hz.
Low values reduce processing time. Set to <code>pitchCeiling</code> for optimal
speed or to <code>samplingRate</code> for optimal quality</p>
</td></tr>
<tr><td><code id="generateHarmonics_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. Harmonics and noise more than
dynamicRange under maximum amplitude are discarded to save computational
resources</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns one continuous, unfiltered, voiced syllable consisting of several
sine waves.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rolloffExact1 = c(.2, .2, 1, .2, .2)
s1 = soundgen:::generateHarmonics(pitch = seq(400, 530, length.out = 1500),
                       rolloffExact = rolloffExact1)
spectrogram(s1, 16000, ylim = c(0, 4))
# playme(s1, 16000)

rolloffExact2 = matrix(c(.2, .2, 1, .2, .2,
                         1, .5, .2, .1, .05), ncol = 2)
s2 = soundgen:::generateHarmonics(pitch = seq(400, 530, length.out = 1500),
                       rolloffExact = rolloffExact2)
spectrogram(s2, 16000, ylim = c(0, 4))
# playme(s2, 16000)
</code></pre>

<hr>
<h2 id='generateNoise'>Generate noise</h2><span id='topic+generateNoise'></span>

<h3>Description</h3>

<p>Generates noise of length <code>len</code> and with spectrum defined by rolloff
parameters OR by a specified filter <code>spectralEnvelope</code>. This function is
called internally by <code><a href="#topic+soundgen">soundgen</a></code>, but it may be more convenient to
call it directly when synthesizing non-biological noises defined by specific
spectral and amplitude envelopes rather than formants: the wind, whistles,
impact noises, etc. See <code><a href="#topic+fart">fart</a></code> and <code><a href="#topic+beat">beat</a></code> for
similarly simplified functions for tonal non-biological sounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateNoise(
  len,
  rolloffNoise = 0,
  noiseFlatSpec = 1200,
  rolloffNoiseExp = 0,
  spectralEnvelope = NULL,
  noise = NULL,
  temperature = 0.1,
  attackLen = 10,
  windowLength_points = 1024,
  samplingRate = 16000,
  overlap = 75,
  dynamicRange = 80,
  smoothing = list(),
  invalidArgAction = c("adjust", "abort", "ignore")[1],
  play = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateNoise_+3A_len">len</code></td>
<td>
<p>length of output</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_rolloffnoise">rolloffNoise</code>, <code id="generateNoise_+3A_noiseflatspec">noiseFlatSpec</code></td>
<td>
<p>linear rolloff of the excitation source for
the unvoiced component, <code>rolloffNoise</code> dB/kHz (anchor format) applied
above <code>noiseFlatSpec</code> Hz</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_rolloffnoiseexp">rolloffNoiseExp</code></td>
<td>
<p>exponential rolloff of the excitation source for the
unvoiced component, dB/oct (anchor format) applied above 0 Hz</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_spectralenvelope">spectralEnvelope</code></td>
<td>
<p>(optional): as an alternative to using rolloffNoise,
we can provide the exact filter - a vector of non-negative numbers
specifying the desired spectrum on a linear scale up to Nyquist frequency
(samplingRate / 2). The length doesn't matter as it can be interpolated
internally to windowLength_points/2. A matrix specifying the filter for
each STFT step is also accepted. The easiest way to obtain spectralEnvelope
is to call soundgen:::getSpectralEnvelope or to use the spectrum /
spectrogram of a recorded sound</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_noise">noise</code></td>
<td>
<p>loudness of turbulent noise (0 dB = as loud as
voiced component, negative values = quieter) such as aspiration, hissing,
etc (anchor format)</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_attacklen">attackLen</code></td>
<td>
<p>duration of fade-in / fade-out at each end of syllables and
noise (ms): a vector of length 1 (symmetric) or 2 (separately for fade-in
and fade-out)</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>the length of fft window, points</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_overlap">overlap</code></td>
<td>
<p>FFT window overlap, %. For allowed values, see
<code><a href="seewave.html#topic+istft">istft</a></code></p>
</td></tr>
<tr><td><code id="generateNoise_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. Harmonics and noise more than
dynamicRange under maximum amplitude are discarded to save computational
resources</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_smoothing">smoothing</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+getSmoothContour">getSmoothContour</a></code> to control the interpolation and smoothing
of contours: interpol (approx / spline / loess), loessSpan, discontThres,
jumpThres</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>permittedValues</code>: 'adjust' = reset to default value, 'abort'
= stop execution, 'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
<tr><td><code id="generateNoise_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: paints a spectrogram with desired characteristics, sets phase to
zero, and generates a time sequence via inverse FFT.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+soundgen">soundgen</a></code> <code><a href="#topic+fart">fart</a></code> <code><a href="#topic+beat">beat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># .5 s of white noise
samplingRate = 16000
noise1 = generateNoise(len = samplingRate * .5,
  samplingRate = samplingRate)
# playme(noise1, samplingRate)
# seewave::meanspec(noise1, f = samplingRate)

# Percussion (run a few times to notice stochasticity due to temperature = .25)
noise2 = generateNoise(len = samplingRate * .15, noise = c(0, -80),
  rolloffNoise = c(4, -6), attackLen = 5, temperature = .25)
noise3 = generateNoise(len = samplingRate * .25, noise = c(0, -40),
  rolloffNoise = c(4, -20), attackLen = 5, temperature = .25)
# playme(c(noise2, noise3), samplingRate)

## Not run: 
playback = list(TRUE, FALSE, 'aplay', 'vlc')[[1]]
# 1.2 s of noise with rolloff changing from 0 to -12 dB above 2 kHz
noise = generateNoise(len = samplingRate * 1.2,
  rolloffNoise = c(0, -12), noiseFlatSpec = 2000,
  samplingRate = samplingRate, play = playback)
# spectrogram(noise, samplingRate, osc = TRUE)

# Similar, but using the dataframe format to specify a more complicated
# contour for rolloffNoise:
noise = generateNoise(len = samplingRate * 1.2,
  rolloffNoise = data.frame(time = c(0, .3, 1), value = c(-12, 0, -12)),
  noiseFlatSpec = 2000, samplingRate = samplingRate, play = playback)
# spectrogram(noise, samplingRate, osc = TRUE)

# To create a sibilant [s], specify a single strong, broad formant at ~7 kHz:
windowLength_points = 1024
spectralEnvelope = soundgen:::getSpectralEnvelope(
  nr = windowLength_points / 2, nc = 1, samplingRate = samplingRate,
 formants = list('f1' = data.frame(time = 0, freq = 7000,
                                   amp = 50, width = 2000)))
noise = generateNoise(len = samplingRate,
  samplingRate = samplingRate, spectralEnvelope = as.numeric(spectralEnvelope),
  play = playback)
# plot(spectralEnvelope, type = 'l')

# Low-frequency, wind-like noise
spectralEnvelope = soundgen:::getSpectralEnvelope(
  nr = windowLength_points / 2, nc = 1, lipRad = 0,
  samplingRate = samplingRate, formants = list('f1' = data.frame(
    time = 0, freq = 150, amp = 30, width = 90)))
noise = generateNoise(len = samplingRate,
  samplingRate = samplingRate, spectralEnvelope = as.numeric(spectralEnvelope),
  play = playback)

# Manual filter, e.g. for a kettle-like whistle (narrow-band noise)
spectralEnvelope = c(rep(0, 100), 120, rep(0, 100))  # any length is fine
# plot(spectralEnvelope, type = 'b')  # notch filter at Nyquist / 2, here 4 kHz
noise = generateNoise(len = samplingRate, spectralEnvelope = spectralEnvelope,
  samplingRate = samplingRate, play = playback)

# Compare to a similar sound created with soundgen()
# (unvoiced only, a single formant at 4 kHz)
noise_s = soundgen(pitch = NULL,
  noise = data.frame(time = c(0, 1000), value = c(0, 0)),
  formants = list(f1 = data.frame(freq = 4000, amp = 80, width = 20)),
  play = playback)


# Use the spectral envelope of an existing recording (bleating of a sheep)
# (see also the same example with tonal source in ?addFormants)
data(sheep, package = 'seewave')  # import a recording from seewave
sound_orig = as.numeric(sheep@left)
samplingRate = sheep@samp.rate
# playme(sound_orig, samplingRate)

# extract the original spectrogram
windowLength = c(5, 10, 50, 100)[1]  # try both narrow-band (eg 100 ms)
# to get "harmonics" and wide-band (5 ms) to get only formants
spectralEnvelope = spectrogram(sound_orig, windowLength = windowLength,
  samplingRate = samplingRate, output = 'original', padWithSilence = FALSE)
sound_noise = generateNoise(len = length(sound_orig),
  spectralEnvelope = spectralEnvelope, rolloffNoise = 0,
  samplingRate = samplingRate, play = playback)
# playme(sound_noise, samplingRate)

# The spectral envelope is similar to the original recording. Compare:
par(mfrow = c(1, 2))
seewave::meanspec(sound_orig, f = samplingRate, dB = 'max0')
seewave::meanspec(sound_noise, f = samplingRate, dB = 'max0')
par(mfrow = c(1, 1))
# However, the excitation source is now white noise
# (which sounds like noise if windowLength is ~5-10 ms,
# but becomes more and more like the original at longer window lengths)

## End(Not run)
</code></pre>

<hr>
<h2 id='generatePath'>Generate path</h2><span id='topic+generatePath'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generatePath(path, pitchCands, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generatePath_+3A_path">path</code></td>
<td>
<p>currently evaluated path</p>
</td></tr>
<tr><td><code id="generatePath_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="generatePath_+3A_...">...</code></td>
<td>
<p>nothing really, but otherwise optim() complains</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing of pitch contours called by
<code><a href="#topic+pathfinding_slow">pathfinding_slow</a></code>. Generates proposals for new paths through
pitch candidates. It gives up and returns NA after 100 attempts, which stops
annealing - so the adaptation of pitch contour doesn't happen
</p>

<hr>
<h2 id='getAM'>Get amplitude modulation</h2><span id='topic+getAM'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAM(m, amRange = c(10, 100), amRes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getAM_+3A_m">m</code></td>
<td>
<p>numeric matrix of non-negative values with colnames giving temporal
modulation frequency</p>
</td></tr>
<tr><td><code id="getAM_+3A_amrange">amRange</code></td>
<td>
<p>the range of temporal modulation frequencies that we are
interested in as &quot;amplitude modulation&quot; (AM), Hz</p>
</td></tr>
<tr><td><code id="getAM_+3A_amres">amRes</code></td>
<td>
<p>controls the width of window over which we look for local maxima</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for calculating amplitude modulation based on the modulation
spectrum. Algorithm: averages AM across all FM bins in the positive half of
the modulation spectrum and looks for a peak in the specified AM frequency
range.
</p>


<h3>Value</h3>

<p>Returns a list with the frequency (Hz) and depth of amplitude
modulation (dB relative to global max, normally at 0 Hz).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(pitch = 400, amFreq = 75, amDep = 50)
m = modulationSpectrum(s, 16000)
soundgen:::getAM(m$original)
</code></pre>

<hr>
<h2 id='getAM_env'>Get Amplitude Modulation</h2><span id='topic+getAM_env'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAM_env(
  audio,
  amRange = c(20, 100),
  overlap = 80,
  parab = TRUE,
  plot = FALSE
)
</code></pre>


<h3>Details</h3>

<p>Measures AM
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 1500, pitch = c(300, 550, 320, 220),
             amFreq = c(50, 120, 100), amDep = c(10, 60, 30))
# spectrogram(s)
# playme(s)
am = soundgen:::getAM_env(audio = soundgen:::readAudio(s, samplingRate = 16000),
  amRange = c(20, 200), overlap = 80, plot = TRUE)
plot(am$time, am$freq, cex = am$dep * 2)
# compare to getAM from modulation spectrum:
ms = modulationSpectrum(s, 16000, plot = FALSE)
plot(x = seq(1, 1500, length.out = length(ms$amMsFreq)), y = ms$amMsFreq,
     cex = 10^(ms$amMsPurity/20) * 10, xlab = 'Time, ms', ylab = 'AM frequency, Hz')
</code></pre>

<hr>
<h2 id='getBandwidth'>Get bandwidth</h2><span id='topic+getBandwidth'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBandwidth(f)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getBandwidth_+3A_f">f</code></td>
<td>
<p>a vector of formant frequencies, Hz</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates formant bandwidth as a function of formant frequencies using a
modified version of TMF-63 formula. Namely, above 500 Hz it follows the
original formula from Tappert, Martony, and Fant (TMF)-1963, and below 500 Hz
it applies a correction to allow for energy losses at low frequencies. See
Khodai-Joopari &amp; Clermont (2002), &quot;Comparison of formulae for estimating
formant bandwidths&quot;. Below 250 Hz the bandwidth is forces to drop again to
avoid very large values near zero (just guesswork!)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f = 1:5000
plot(f, soundgen:::getBandwidth(f), type = 'l',
  xlab = 'Formant frequency, Hz', ylab = 'Estimated bandwidth, Hz')
</code></pre>

<hr>
<h2 id='getCheckerboardKernel'>Checkerboard kernel</h2><span id='topic+getCheckerboardKernel'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCheckerboardKernel(
  size,
  kernel_mean = 0,
  kernelSD = 0.5,
  plot = FALSE,
  checker = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCheckerboardKernel_+3A_size">size</code></td>
<td>
<p>kernel size (points), preferably an even number</p>
</td></tr>
<tr><td><code id="getCheckerboardKernel_+3A_kernel_mean">kernel_mean</code>, <code id="getCheckerboardKernel_+3A_kernelsd">kernelSD</code></td>
<td>
<p>mean and SD of the gaussian kernel</p>
</td></tr>
<tr><td><code id="getCheckerboardKernel_+3A_plot">plot</code></td>
<td>
<p>if TRUE, shows a perspective plot of the kernel</p>
</td></tr>
<tr><td><code id="getCheckerboardKernel_+3A_checker">checker</code></td>
<td>
<p>if TRUE, inverts two quadrants</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prepares a square matrix <code>size x size</code> specifying a gaussian kernel for
measuring novelty of self-similarity matrices. Called by
<code><a href="#topic+getNovelty">getNovelty</a></code>
</p>


<h3>Value</h3>

<p>Returns a square matrix with <code>size</code> rows and columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kernel = soundgen:::getCheckerboardKernel(size = 64, kernelSD = 0.1, plot = TRUE)
dim(kernel)
kernel = soundgen:::getCheckerboardKernel(size = 19, kernelSD = .5,
  checker = FALSE, plot = TRUE)
kernel = soundgen:::getCheckerboardKernel(size = c(9, 45), kernelSD = .5,
  checker = FALSE, plot = TRUE)
kernel = soundgen:::getCheckerboardKernel(size = c(9, 45), kernelSD = .5,
  checker = TRUE, plot = TRUE)
</code></pre>

<hr>
<h2 id='getCPP'>Get Cepstral Peak Prominence</h2><span id='topic+getCPP'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCPP(frame, samplingRate, pitch, bin, prox_semitones = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCPP_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="getCPP_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate (Hz)</p>
</td></tr>
<tr><td><code id="getCPP_+3A_pitch">pitch</code></td>
<td>
<p>pitch of this frame, Hz</p>
</td></tr>
<tr><td><code id="getCPP_+3A_bin">bin</code></td>
<td>
<p>spectral frequency bin width, Hz</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates Cepstral Peak Prominence from the spectrum of an STFT frame.
</p>


<h3>Value</h3>

<p>Returns either NA or CPP in dB.
</p>

<hr>
<h2 id='getDiscreteContour'>Discrete smooth contour from anchors</h2><span id='topic+getDiscreteContour'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDiscreteContour(
  len,
  anchors = data.frame(time = c(0, 1), value = c(1, 1)),
  interpol = c("spline", "loess")[2],
  valueFloor = NULL,
  valueCeiling = NULL,
  ylim = NULL,
  plot = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDiscreteContour_+3A_len">len</code></td>
<td>
<p>the number of syllables (equivalently, the length of generated
contour)</p>
</td></tr>
<tr><td><code id="getDiscreteContour_+3A_anchors">anchors</code></td>
<td>
<p>a numeric vector of values or a list/dataframe with one column
(value) or two columns (time and value). <code>achors$time</code> can be in ms
(with len=NULL) or in arbitrary units, eg 0 to 1 (with duration determined
by len, which must then be provided in ms). So anchors$time is assumed to
be in ms if len=NULL and relative if len is specified. <code>anchors$value</code>
can be on any scale.</p>
</td></tr>
<tr><td><code id="getDiscreteContour_+3A_interpol">interpol</code></td>
<td>
<p>method of interpolation between anchors: &quot;approx&quot; = linear
with <code><a href="stats.html#topic+approx">approx</a></code>, &quot;spline&quot; = cubic splines with
<code><a href="stats.html#topic+spline">spline</a></code>, &quot;loess&quot; = local polynomial regression with
<code><a href="stats.html#topic+loess">loess</a></code></p>
</td></tr>
<tr><td><code id="getDiscreteContour_+3A_valuefloor">valueFloor</code>, <code id="getDiscreteContour_+3A_valueceiling">valueCeiling</code></td>
<td>
<p>lowser/upper bounds for the contour</p>
</td></tr>
<tr><td><code id="getDiscreteContour_+3A_ylim">ylim</code></td>
<td>
<p>ylim for plotting</p>
</td></tr>
<tr><td><code id="getDiscreteContour_+3A_plot">plot</code></td>
<td>
<p>(boolean) produce a plot?</p>
</td></tr>
<tr><td><code id="getDiscreteContour_+3A_...">...</code></td>
<td>
<p>other plotting options passed to <code>plot()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>A discrete version of <code><a href="#topic+getSmoothContour">getSmoothContour</a></code> with modified plotting.
Intended for plotting variation in parameters across syllables.
</p>


<h3>Value</h3>

<p>Numeric vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for a bout consisting of 10 syllables
soundgen:::getDiscreteContour(len = 10, interpol = 'spline', plot = TRUE,
  ylab = 'Semitones', anchors = data.frame(time = c(0, .2, .6, 1),
  value = c(0, -3, 1, 0)))
</code></pre>

<hr>
<h2 id='getDom'>Get lowest dominant frequency band</h2><span id='topic+getDom'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDom(frame, bin, freqs, domSmooth, domThres, pitchFloor, pitchCeiling)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDom_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="getDom_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="getDom_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="getDom_+3A_domsmooth">domSmooth</code></td>
<td>
<p>the width of smoothing interval (Hz) for finding
<code>dom</code></p>
</td></tr>
<tr><td><code id="getDom_+3A_domthres">domThres</code></td>
<td>
<p>(0 to 1) to find the lowest dominant frequency band, we
do short-term FFT and take the lowest frequency with amplitude at least
domThres</p>
</td></tr>
<tr><td><code id="getDom_+3A_pitchfloor">pitchFloor</code>, <code id="getDom_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculate the lowest frequency band in the spectrum above pitchFloor whose
amplitude exceeds a certain threshold.
</p>


<h3>Value</h3>

<p>Returns a list of $dom (NA or numeric) and $dom_array
(either NULL or a dataframe of pitch candidates).
</p>

<hr>
<h2 id='getDuration'>Get duration</h2><span id='topic+getDuration'></span>

<h3>Description</h3>

<p>Returns the duration of one or more audio files (mostly useful for running on
an entire folder). If <code>threshold</code> is set, it also removes the leading
and trailing silences or near-silences, thus returning the duration of
relatively loud central fragments of each sound. Silences are located based
on the amplitude of root mean square (RMS) amplitude with
<code><a href="#topic+getRMS">getRMS</a></code>. Note that the threshold is set relative to the observed
maximum RMS, just as in <code><a href="#topic+analyze">analyze</a></code>. This means that even very
quiet sounds are not treated as nothing but silence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDuration(
  x,
  samplingRate = NULL,
  silence = 0.01,
  rms = list(windowLength = 20, step = 5),
  reportEvery = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDuration_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="getDuration_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getDuration_+3A_silence">silence</code></td>
<td>
<p>leading and trailing sections quieter than this proportion of
maximum RMS amplitude are removed when calculating
<code>duration_noSilence</code> (NULL = don't calculate <code>duration_noSilence</code>
to save time)</p>
</td></tr>
<tr><td><code id="getDuration_+3A_rms">rms</code></td>
<td>
<p>a list of control parameters passed to <code><a href="#topic+getRMS">getRMS</a></code></p>
</td></tr>
<tr><td><code id="getDuration_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="getDuration_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>duration</code> (s) and <code>duration_noSilence</code> (duration
without leading and trailing silences).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+analyze">analyze</a></code> <code><a href="#topic+getLoudness">getLoudness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = c(rep(0, 550), runif(400, -1, 1), rep(0, 50))
osc(s, samplingRate = 1000)
# true duration_noSilence is 400 ms
getDuration(s, samplingRate = 1000, silence = .01)
getDuration(s, samplingRate = 1000, silence = .1,
            rms = list(windowLength = 5, step = 1))

## Not run: 
d = getDuration('~/Downloads/temp')
hist(d$duration - d$duration_noSilence)

## End(Not run)
</code></pre>

<hr>
<h2 id='getEntropy'>Entropy</h2><span id='topic+getEntropy'></span>

<h3>Description</h3>

<p>Returns Weiner or Shannon entropy of an input vector such as the spectrum of
a sound. Non-positive input values are converted to a small positive number
(convertNonPositive). If all elements are zero, returns NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEntropy(
  x,
  type = c("weiner", "shannon")[1],
  normalize = FALSE,
  convertNonPositive = 1e-10
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getEntropy_+3A_x">x</code></td>
<td>
<p>vector of positive floats</p>
</td></tr>
<tr><td><code id="getEntropy_+3A_type">type</code></td>
<td>
<p>'shannon' for Shannon (information) entropy, 'weiner' for Weiner
entropy</p>
</td></tr>
<tr><td><code id="getEntropy_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, Shannon entropy is normalized by the length of
input vector to range from 0 to 1. It has no affect on Weiner entropy</p>
</td></tr>
<tr><td><code id="getEntropy_+3A_convertnonpositive">convertNonPositive</code></td>
<td>
<p>all non-positive values are converted to
<code>convertNonPositive</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Here are four simplified power spectra, each with 9 frequency bins:
s = list(
  c(rep(0, 4), 1, rep(0, 4)),       # a single peak in spectrum
  c(0, 0, 1, 0, 0, .75, 0, 0, .5),  # perfectly periodic, with 3 harmonics
  rep(0, 9),                        # a silent frame
  rep(1, 9)                         # white noise
)

# Weiner entropy is ~0 for periodic, NA for silent, 1 for white noise
sapply(s, function(x) round(getEntropy(x), 2))

# Shannon entropy is ~0 for periodic with a single harmonic, moderate for
# periodic with multiple harmonics, NA for silent, highest for white noise
sapply(s, function(x) round(getEntropy(x, type = 'shannon'), 2))

# Normalized Shannon entropy - same but forced to be 0 to 1
sapply(s, function(x) round(getEntropy(x,
  type = 'shannon', normalize = TRUE), 2))
</code></pre>

<hr>
<h2 id='getEnv'>Get amplitude envelope</h2><span id='topic+getEnv'></span>

<h3>Description</h3>

<p>Returns the smoothed amplitude envelope of a waveform on the original scale.
Unlike seewave::env, this function always returns an envelope of the same
length as the original sound, regardless of the amount of smoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEnv(
  sound,
  windowLength_points,
  method = c("rms", "hil", "peak", "raw", "mean")[1]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getEnv_+3A_sound">sound</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="getEnv_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>the length of smoothing window, in points</p>
</td></tr>
<tr><td><code id="getEnv_+3A_method">method</code></td>
<td>
<p>'peak' for peak amplitude per window, 'rms' for root mean
square amplitude, 'mean' for mean (for DC offset removal), 'hil' for
Hilbert, 'raw' for low-pass filtering the actual sound</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>a = rnorm(500) * seq(1, 0, length.out = 500)
windowLength_points = 50
scale = max(abs(a))
plot(a, type = 'l', ylim = c(-scale, scale))
points(soundgen:::getEnv(a, windowLength_points, 'rms'),
       type = 'l', col = 'red')
points(soundgen:::getEnv(a, windowLength_points, 'peak'),
       type = 'l', col = 'green')
points(soundgen:::getEnv(a, windowLength_points, 'hil'),
       type = 'l', col = 'blue')
points(soundgen:::getEnv(a, windowLength_points, 'mean'),
       type = 'l', lty = 3, lwd = 3)
</code></pre>

<hr>
<h2 id='getFeatureFlux'>Get flux from features</h2><span id='topic+getFeatureFlux'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFeatureFlux(an, thres = 0.1, smoothing_ww = 1, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getFeatureFlux_+3A_an">an</code></td>
<td>
<p>dataframe of results from analyze()</p>
</td></tr>
<tr><td><code id="getFeatureFlux_+3A_thres">thres</code></td>
<td>
<p>threshold used for epoch detection (0 - 1)</p>
</td></tr>
<tr><td><code id="getFeatureFlux_+3A_smoothing_ww">smoothing_ww</code></td>
<td>
<p>if &gt; 1, <code><a href="#topic+medianSmoother">medianSmoother</a></code> is called on input dataframe</p>
</td></tr>
<tr><td><code id="getFeatureFlux_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the normalized feature matrix and epochs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the change in acoustic features returned by analyze() from one
STFT frame to the next. Since the features are on different scales, they are
normalized depending on their units (but not scaled). Flux is calculated as
mean absolute change across all normalized features. Whenever flux exceeds
<code>thres</code>, a new epoch begins.
</p>


<h3>Value</h3>

<p>Returns a data frame with flux per frame and epoch numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>an = analyze(soundgen(), 16000)
fl = soundgen:::getFeatureFlux(an$detailed, plot = TRUE)
## Not run: 
# or simply:
an = analyze(soundgen(sylLen = 500), 16000, plot = TRUE, ylim = c(0, 8),
             extraContour = 'flux', flux = list(smoothWin = 100, thres = .15))

## End(Not run)
</code></pre>

<hr>
<h2 id='getFormantDispersion'>Get formant dispersion</h2><span id='topic+getFormantDispersion'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFormantDispersion(
  formants,
  method = c("meanDispersion", "regression")[2],
  tube = c("closed-open", "open-open")[1],
  interceptZero = TRUE,
  speedSound = 35400,
  plot = FALSE,
  checkFormat = TRUE,
  output = c("simple", "detailed")[1]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getFormantDispersion_+3A_formants">formants</code></td>
<td>
<p>formant frequencies in any format recognized by
<code><a href="#topic+soundgen">soundgen</a></code>: a vector of formant frequencies like <code>c(550,
1600, 3200)</code>; a list with multiple values per formant like <code>list(f1 =
c(500, 550), f2 = 1200))</code>; or a character string like <code>aaui</code> referring
to default presets for speaker &quot;M1&quot; in soundgen presets</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_method">method</code></td>
<td>
<p>the method of estimating vocal tract length (see details)</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_tube">tube</code></td>
<td>
<p>the vocal tract is assumed to be a cylindrical tube that is
either &quot;closed-open&quot; or &quot;open-open&quot; (same as closed-closed)</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_interceptzero">interceptZero</code></td>
<td>
<p>if TRUE, forces the regression curve to pass through the
origin. This reduces the influence of highly variable lower formants, but
we have to commit to a particular model of the vocal tract: closed-open or
open-open/closed-closed (method = &quot;regression&quot; only)</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_speedsound">speedSound</code></td>
<td>
<p>speed of sound in warm air, by default 35400 cm/s. Stevens
(2000) &quot;Acoustic phonetics&quot;, p. 138</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the regression line whose slope gives formant
dispersion (method = &quot;regression&quot; only). Label sizes show the influence of
each formant, and the blue line corresponds to each formant being an
integer multiple of F1 (as when harmonics are misidentified as formants);
the second plot shows how VTL varies depending on the number of formants
used</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_checkformat">checkFormat</code></td>
<td>
<p>if FALSE, only a list of properly formatted formant
frequencies is accepted</p>
</td></tr>
<tr><td><code id="getFormantDispersion_+3A_output">output</code></td>
<td>
<p>&quot;simple&quot; (default) = just the VTL; &quot;detailed&quot; = a list of
additional stats (see Value below)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates formant dispersion based on one or more formant frequencies.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::getFormantDispersion(
  list(f1 = c(570, 750), f2 = NA, f3 = c(2400, 2200, NA)))
</code></pre>

<hr>
<h2 id='getFormants'>Get formants</h2><span id='topic+getFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFormants(
  audio,
  windowLength = 50,
  step = 25,
  wn = "gaussian",
  zp = 0,
  dynamicRange = 80,
  silence = 0.04,
  formants = list(),
  nFormants = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getFormants_+3A_audio">audio</code></td>
<td>
<p>input sound as returned by readAudio</p>
</td></tr>
<tr><td><code id="getFormants_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="getFormants_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="getFormants_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="getFormants_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id="getFormants_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="getFormants_+3A_silence">silence</code></td>
<td>
<p>(0 to 1 as proportion of max amplitude) frames with RMS
amplitude below <code>silence * max_ampl adjusted by scale</code> are not
analyzed at all.</p>
</td></tr>
<tr><td><code id="getFormants_+3A_formants">formants</code></td>
<td>
<p>a list of arguments passed to
<code><a href="phonTools.html#topic+findformants">findformants</a></code> - an external function called to
perform LPC analysis</p>
</td></tr>
<tr><td><code id="getFormants_+3A_nformants">nFormants</code></td>
<td>
<p>the number of formants to extract per STFT frame (0 = no
formant analysis, NULL = as many as possible)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A barebones version of analyze() that only measures formants. Called by
formant_app()
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sheep, package = 'seewave')
f = soundgen:::getFormants(soundgen:::readAudio(sheep, from = .1, to = .5))
f[11:15, 1:5]
</code></pre>

<hr>
<h2 id='getFrameBank'>Frame bank</h2><span id='topic+getFrameBank'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFrameBank(
  sound,
  samplingRate,
  windowLength_points,
  wn,
  step,
  zp,
  normalize = TRUE,
  filter = NULL,
  padWithSilence = FALSE,
  timeShift = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getFrameBank_+3A_sound">sound</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>length of fft window (points)</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, scales input prior to FFT</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_filter">filter</code></td>
<td>
<p>fft window filter (defaults to NULL)</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id="getFrameBank_+3A_timeshift">timeShift</code></td>
<td>
<p>time (s) added to timestamps</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A subroutine of <code><a href="stats.html#topic+spec">spec</a></code> that saves windowed (and optionally
zero-padded) frames, i.e. chunks of the sound file of the right size and
spacing. Handy for further processing.
</p>


<h3>Value</h3>

<p>A matrix with <code>nrow = windowLength_points/2</code> and <code>ncol</code>
depending on <code>length(sound)</code> and <code>step</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = soundgen:::getFrameBank(sin(1:1000), 16000, 512, 'gaussian', 15, 0)
str(a)
</code></pre>

<hr>
<h2 id='getGlottalCycles'>Divide f0 contour into glottal cycles</h2><span id='topic+getGlottalCycles'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getGlottalCycles(pitch, samplingRate)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getGlottalCycles_+3A_pitch">pitch</code></td>
<td>
<p>a vector of fundamental frequency values</p>
</td></tr>
<tr><td><code id="getGlottalCycles_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate at which f0 values are provided</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a vector of indices giving the borders between &quot;glottal cycles&quot;,
assuming that we know the true f0 at each time point (as we do in synthesized
sounds). The first index is always 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 100 ms of audio with f0 steadily increasing from 150 to 200 Hz
soundgen:::getGlottalCycles(seq(150, 200, length.out = 350),
  samplingRate = 3500)
</code></pre>

<hr>
<h2 id='getHNR'>Get HNR</h2><span id='topic+getHNR'></span>

<h3>Description</h3>

<p>Calculates the harmonics-to-noise ratio (HNR) - that is, the ratio between
the intensity (root mean square amplitude) of the harmonic component and the
intensity of the noise component. Normally called by <code><a href="#topic+analyze">analyze</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getHNR(
  x = NULL,
  samplingRate = NA,
  acf_x = NULL,
  lag.min = 2,
  lag.max = length(x),
  interpol = c("none", "parab", "spline", "sinc")[4],
  wn = "hanning",
  idx_max = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getHNR_+3A_x">x</code></td>
<td>
<p>time series (a numeric vector)</p>
</td></tr>
<tr><td><code id="getHNR_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate</p>
</td></tr>
<tr><td><code id="getHNR_+3A_acf_x">acf_x</code></td>
<td>
<p>pre-computed autocorrelation function of input <code>x</code>, if
already available</p>
</td></tr>
<tr><td><code id="getHNR_+3A_lag.min">lag.min</code>, <code id="getHNR_+3A_lag.max">lag.max</code></td>
<td>
<p>minimum and maximum lag to consider when looking for
peaks in the ACF; lag.min = samplingRate/pitchCeiling, lag.max =
samplingRate/pitchFloor</p>
</td></tr>
<tr><td><code id="getHNR_+3A_interpol">interpol</code></td>
<td>
<p>method of improving the frequency resolution by interpolating
the ACF: &quot;none&quot; = don't interpolate; &quot;parab&quot; = parabolic interpolation on
three points (local peak and its neighbors); &quot;spline&quot; = spline
interpolation; &quot;sinc&quot; = sin(x)/x interpolation to a continuous function
followed by a search for local peaks using Brent's method</p>
</td></tr>
<tr><td><code id="getHNR_+3A_wn">wn</code></td>
<td>
<p>window applied to <code>x</code> (unless acf_x is provided instead of x)
as well as to the sinc interpolation</p>
</td></tr>
<tr><td><code id="getHNR_+3A_idx_max">idx_max</code></td>
<td>
<p>(internal) the index of the peak to investigate, if already
estimated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of three components: f0 = frequency corresponding to the peak
of the autocorrelation function; max_acf = amplitude of the peak of the
autocorrelation function on a scale of (0, 1); HNR = 10 * log10(x / (1 -
max_acf)).
</p>


<h3>References</h3>

<p>Boersma, P. (1993). Accurate short-term analysis of the
fundamental frequency and the harmonics-to-noise ratio of a sampled sound.
In Proceedings of the institute of phonetic sciences (Vol. 17, No. 1193,
pp. 97-110).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>signal = sin(2 * pi * 150 * (1:16000)/16000)
signal = signal / sqrt(mean(signal^2))
noise = rnorm(16000)
noise = noise / sqrt(mean(noise^2))
SNR = 40
s = signal + noise * 10^(-SNR/20)
soundgen:::getHNR(s, 16000, lag.min = 16000/1000,
lag.max = 16000/75, interpol = 'none')
soundgen:::getHNR(s, 16000, lag.min = 16000/1000,
lag.max = 16000/75, interpol = 'parab')
soundgen:::getHNR(s, 16000, lag.min = 16000/1000,
lag.max = 16000/75, interpol = 'spline')
soundgen:::getHNR(s, 16000, lag.min = 16000/1000,
lag.max = 16000/75, interpol = 'sinc')
</code></pre>

<hr>
<h2 id='getIntegerRandomWalk'>Discrete random walk</h2><span id='topic+getIntegerRandomWalk'></span>

<h3>Description</h3>

<p>Takes a continuous random walk and converts it to continuous epochs of
repeated values 0/1/2, each at least minLength points long. 0/1/2 correspond
to different noise regimes: 0 = no noise, 1 = subharmonics, 2 = subharmonics
and jitter/shimmer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getIntegerRandomWalk(
  rw,
  nonlinBalance = 50,
  minLength = 50,
  q1 = NULL,
  q2 = NULL,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getIntegerRandomWalk_+3A_rw">rw</code></td>
<td>
<p>a random walk generated by <code><a href="#topic+getRandomWalk">getRandomWalk</a></code> (expected
range 0 to 100)</p>
</td></tr>
<tr><td><code id="getIntegerRandomWalk_+3A_nonlinbalance">nonlinBalance</code></td>
<td>
<p>a number between 0 to 100: 0 = returns all zeros;
100 = returns all twos</p>
</td></tr>
<tr><td><code id="getIntegerRandomWalk_+3A_minlength">minLength</code></td>
<td>
<p>the mimimum length of each epoch</p>
</td></tr>
<tr><td><code id="getIntegerRandomWalk_+3A_q1">q1</code>, <code id="getIntegerRandomWalk_+3A_q2">q2</code></td>
<td>
<p>cutoff points for transitioning from regime 0 to 1 (q1) or from
regime 1 to 2 (q2). See noiseThresholdsDict for defaults</p>
</td></tr>
<tr><td><code id="getIntegerRandomWalk_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the random walk underlying nonlinear regimes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of integers (0/1/2) of the same length as rw.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rw = getRandomWalk(len = 100, rw_range = 100, rw_smoothing = .2)
r = getIntegerRandomWalk(rw, nonlinBalance = 75,
                         minLength = 10, plot = TRUE)
r = getIntegerRandomWalk(rw, nonlinBalance = 15,
                         q1 = 30, q2 = 70,
                         minLength = 10, plot = TRUE)
</code></pre>

<hr>
<h2 id='getLoudness'>Get loudness</h2><span id='topic+getLoudness'></span>

<h3>Description</h3>

<p>Estimates subjective loudness per frame, in sone. Based on EMBSD speech
quality measure, particularly the matlab code in Yang (1999) and Timoney et
al. (2004). Note that there are many ways to estimate loudness and many other
factors, ignored by this model, that could influence subjectively experienced
loudness. Please treat the output with a healthy dose of skepticism! Also
note that the absolute value of calculated loudness critically depends on the
chosen &quot;measured&quot; sound pressure level (SPL). <code>getLoudness</code> estimates
how loud a sound will be experienced if it is played back at an SPL of
<code>SPL_measured</code> dB. The most meaningful way to use the output is to
compare the loudness of several sounds analyzed with identical settings or of
different segments within the same recording.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLoudness(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  windowLength = 50,
  step = NULL,
  overlap = 50,
  SPL_measured = 70,
  Pref = 2e-05,
  spreadSpectrum = TRUE,
  summaryFun = c("mean", "median", "sd"),
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  main = NULL,
  ylim = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  mar = c(5.1, 4.1, 4.1, 4.1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getLoudness_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_from">from</code>, <code id="getLoudness_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_spl_measured">SPL_measured</code></td>
<td>
<p>sound pressure level at which the sound is presented, dB</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_pref">Pref</code></td>
<td>
<p>reference pressure, Pa (currently has no effect on the estimate)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_spreadspectrum">spreadSpectrum</code></td>
<td>
<p>if TRUE, applies a spreading function to account for
frequency masking</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic,
eg &quot;c('mean', 'sd')&quot;; user-defined functions are fine (see examples); NAs
are omitted automatically for mean/median/sd/min/max/range/sum, otherwise
take care of NAs yourself</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_width">width</code>, <code id="getLoudness_+3A_height">height</code>, <code id="getLoudness_+3A_units">units</code>, <code id="getLoudness_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="getLoudness_+3A_mar">mar</code></td>
<td>
<p>margins of the spectrogram</p>
</td></tr>
<tr><td><code id="getLoudness_+3A_...">...</code></td>
<td>
<p>other plotting parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: calibrates the sound to the desired SPL (Timoney et al., 2004),
extracts a spectrogram with <code><a href="tuneR.html#topic+powspec">powspec</a></code>, converts to bark
scale with (<code><a href="tuneR.html#topic+audspec">audspec</a></code>), spreads the spectrum to account
for frequency masking across the critical bands (Yang, 1999), converts dB to
phon by using standard equal loudness curves (ISO 226), converts phon to sone
(Timoney et al., 2004), sums across all critical bands, and applies a
correction coefficient to standardize output. Calibrated so as to return a
loudness of 1 sone for a 1 kHz pure tone with SPL of 40 dB.
</p>


<h3>Value</h3>

<p>Returns a list: </p>
 <dl>
<dt>specSone</dt><dd><p>spectrum in bark-sone (one
per file): a matrix of loudness values in sone, with frequency on the bark
scale in rows and time (STFT frames) in columns</p>
</dd> <dt>loudness</dt><dd><p>a vector
of loudness in sone per STFT frame (one per file)</p>
</dd> <dt>summary</dt><dd><p>a
dataframe of summary loudness measures (one row per file)</p>
</dd> </dl>



<h3>References</h3>


<ul>
<li><p> ISO 226 as implemented by Jeff Tackett (2005) on
https://www.mathworks.com/matlabcentral/fileexchange/
7028-iso-226-equal-loudness-level-contour-signal </p>
</li>
<li><p> Timoney, J.,
Lysaght, T., Schoenwiesner, M., &amp; MacManus, L. (2004). Implementing
loudness models in matlab. </p>
</li>
<li><p> Yang, W. (1999). Enhanced Modified Bark
Spectral Distortion (EMBSD): An Objective Speech Quality Measure Based on
Audible Distortion and Cognitive Model. Temple University. </p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+getRMS">getRMS</a></code> <code><a href="#topic+analyze">analyze</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sounds = list(
  white_noise = runif(8000, -1, 1),
  white_noise2 = runif(8000, -1, 1) / 2,  # ~6 dB quieter
  pure_tone_1KHz = sin(2*pi*1000/16000*(1:8000))  # pure tone at 1 kHz
)
l = getLoudness(
    x = sounds, samplingRate = 16000, scale = 1,
    windowLength = 20, step = NULL,
    overlap = 50, SPL_measured = 40,
    Pref = 2e-5, plot = FALSE)
l$summary
# white noise (sound 1) is twice as loud as pure tone at 1 KHz (sound 3),
# and note that the same white noise with lower amplitude has lower loudness
# (provided that "scale" is specified)
# compare: lapply(sounds, range)

## Not run: 
s = soundgen()
# playme(s)
l1 = getLoudness(s, samplingRate = 16000, SPL_measured = 70)
l1$summary
# The estimated loudness in sone depends on target SPL
l2 = getLoudness(s, samplingRate = 16000, SPL_measured = 40)
l2$summary

# ...but not (much) on windowLength and samplingRate
l3 = getLoudness(s, samplingRate = 16000, SPL_measured = 40, windowLength = 50)
l3$summary

# input can be an audio file...
getLoudness('~/Downloads/temp/032_ut_anger_30-m-roar-curse.wav')

...or a folder with multiple audio files
getLoudness('~/Downloads/temp2', plot = FALSE)$summary
# Compare:
analyze('~/Downloads/temp2', pitchMethods = NULL,
        plot = FALSE, silence = 0)$summary$loudness_mean
# (per STFT frame; should be similar if silence = 0, because
# otherwise analyze() discards frames considered silent)

# custom summaryFun
ran = function(x) diff(range(x))
getLoudness('~/Downloads/temp2', plot = FALSE,
            summaryFun = c('mean', 'ran'))$summary

## End(Not run)
</code></pre>

<hr>
<h2 id='getMelSpec'>Mel-transformed spectrogram</h2><span id='topic+getMelSpec'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMelSpec(
  s,
  samplingRate = NULL,
  windowLength = 40,
  overlap = 50,
  step = NULL,
  dynamicRange = 80,
  maxFreq = NULL,
  specPars = list(),
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMelSpec_+3A_s">s</code></td>
<td>
<p>input sound (path to a .wav file or numeric vector)</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_samplingrate">samplingRate</code></td>
<td>
<p>if one or both inputs are numeric vectors, specify
sampling rate, Hz. A vector of length 2 means the two inputs have different
sampling rates, in which case spectrograms are compared only up to the
lower Nyquist frequency</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>parts of the spectra quieter than <code>-dynamicRange</code> dB
are not compared</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_maxfreq">maxFreq</code></td>
<td>
<p>parts of the spectra above <code>maxFreq</code> Hz are not compared</p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_specpars">specPars</code></td>
<td>
<p>a list of parameters passed to <code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id="getMelSpec_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the spectrum</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a .wav file or a waveform as numeric vector + samplingRate and returns
mel-transformed spectrum (auditory spectrum). Calls
<code><a href="tuneR.html#topic+melfcc">melfcc</a></code>. See <code><a href="#topic+compareSounds">compareSounds</a></code>.
</p>

<hr>
<h2 id='getNovelty'>SSM novelty</h2><span id='topic+getNovelty'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNovelty(ssm, kernelSize, kernelSD, padWith = 0, normalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getNovelty_+3A_ssm">ssm</code></td>
<td>
<p>self-similarity matrix, as produced by <code><a href="#topic+selfsim">selfsim</a></code></p>
</td></tr>
<tr><td><code id="getNovelty_+3A_kernelsize">kernelSize</code></td>
<td>
<p>the size of gausisan kernel (points)</p>
</td></tr>
<tr><td><code id="getNovelty_+3A_kernelsd">kernelSD</code></td>
<td>
<p>the SD of gaussian kernel</p>
</td></tr>
<tr><td><code id="getNovelty_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, normalizes so that max = 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates novelty in a self-similarity matrix. Called by <code><a href="#topic+ssm">ssm</a></code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector of length <code>nrow(ssm)</code>
</p>

<hr>
<h2 id='getPeakFreq'>Get peak frequency</h2><span id='topic+getPeakFreq'></span>

<h3>Description</h3>

<p>Internal soundgen function for finding frequency modulation in pitch
contours. Called by analyze().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPeakFreq(x, samplingRate, freqRange = NULL, parab = TRUE, plot = FALSE)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
s = soundgen(sylLen = 1000, pitch = 500,
  vibratoFreq = c(6, 12), vibratoDep = 2,
  temperature = .001, addSilence = 5)
an = analyze(s, 16000, step = 5, windowLength = 25,
  plot = TRUE, yScale = 'bark')
plot(an$detailed$fmFreq, type = 'l')

## End(Not run)
</code></pre>

<hr>
<h2 id='getPitchAutocor'>Autocorrelation pitch tracker</h2><span id='topic+getPitchAutocor'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPitchAutocor(
  autoCorrelation,
  samplingRate,
  nCands,
  autocorThres,
  autocorSmooth = NULL,
  autocorUpsample,
  autocorBestPeak,
  pitchFloor,
  pitchCeiling,
  interpol = "sinc",
  wn = "hanning"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPitchAutocor_+3A_autocorrelation">autoCorrelation</code></td>
<td>
<p>pre-calculated autocorrelation of the input frame
(computationally more efficient than to do it here)</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate (Hz)</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_ncands">nCands</code></td>
<td>
<p>maximum number of pitch candidates per method, normally 1...4
(except for <code>dom</code>, which returns at most one candidate per frame)</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_autocorthres">autocorThres</code></td>
<td>
<p>voicing threshold (unitless, ~0 to 1)</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_autocorsmooth">autocorSmooth</code></td>
<td>
<p>the width of smoothing interval (in bins) for
finding peaks in the autocorrelation function. Defaults to 7 for sampling
rate 44100 and smaller odd numbers for lower values of sampling rate</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_autocorupsample">autocorUpsample</code></td>
<td>
<p>upsamples acf to this resolution (Hz) to improve
accuracy in high frequencies</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_autocorbestpeak">autocorBestPeak</code></td>
<td>
<p>amplitude of the lowest best candidate relative to the
absolute max of the acf</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_pitchfloor">pitchFloor</code>, <code id="getPitchAutocor_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_interpol">interpol</code></td>
<td>
<p>a list of parameters (currently <code>win, tol, cert</code>) passed
to <code>soundgen:::pathfinder</code> for interpolating missing pitch candidates
(NULL = no interpolation)</p>
</td></tr>
<tr><td><code id="getPitchAutocor_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attempts to find F0 of a frame by looking for peaks in the autocorrelation
function (time domain analysis). Modified PRAAT's algorithm. See Boersma, P.
(1993). Accurate short-term analysis of the fundamental frequency and the
harmonics-to-noise ratio of a sampled sound. In Proceedings of the institute
of phonetic sciences (Vol. 17, No. 1193, pp. 97-110).
</p>


<h3>Value</h3>

<p>Returns a list of $HNR (NA or numeric) and $pitchAutocor_array
(either NULL or a dataframe of pitch candidates).
</p>

<hr>
<h2 id='getPitchCep'>Cepstral pitch tracker</h2><span id='topic+getPitchCep'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPitchCep(
  frame,
  samplingRate,
  bin,
  nCands,
  cepThres,
  cepZp,
  pitchFloor,
  pitchCeiling,
  tol = 0.05,
  specMerge = 2/12
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPitchCep_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate (Hz)</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_ncands">nCands</code></td>
<td>
<p>maximum number of pitch candidates per method, normally 1...4
(except for <code>dom</code>, which returns at most one candidate per frame)</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_cepthres">cepThres</code></td>
<td>
<p>voicing threshold (unitless, ~0 to 1)</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_cepzp">cepZp</code></td>
<td>
<p>zero-padding of the spectrum used for cepstral pitch detection
(final length of spectrum after zero-padding in points, e.g. 2 ^ 13)</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_pitchfloor">pitchFloor</code>, <code id="getPitchCep_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_tol">tol</code></td>
<td>
<p>tolerance when removing false subharmonics</p>
</td></tr>
<tr><td><code id="getPitchCep_+3A_specmerge">specMerge</code></td>
<td>
<p>tolerance when removing similar candidates, oct</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attempts to find F0 of a frame by looking for peaks in the cepstrum.
See http://www.phon.ucl.ac.uk/courses/spsci/matlab/lect10.html
</p>


<h3>Value</h3>

<p>Returns either NULL or a dataframe of pitch candidates and CPP.
</p>

<hr>
<h2 id='getPitchHps'>Harmonic product spectrum</h2><span id='topic+getPitchHps'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPitchHps(
  frame,
  freqs,
  bin,
  hpsThres,
  hpsNum,
  hpsNorm,
  hpsPenalty,
  pitchFloor,
  pitchCeiling
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPitchHps_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_hpsthres">hpsThres</code></td>
<td>
<p>voicing threshold (unitless, ~0 to 1)</p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_hpsnum">hpsNum</code></td>
<td>
<p>the number of times the spectrum is downsampled</p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_hpsnorm">hpsNorm</code></td>
<td>
<p>the amount of inflation of hps pitch certainty (0 = none)</p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_hpspenalty">hpsPenalty</code></td>
<td>
<p>the amount of penalizing hps candidates in low frequencies
(0 = none)</p>
</td></tr>
<tr><td><code id="getPitchHps_+3A_pitchfloor">pitchFloor</code>, <code id="getPitchHps_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates pitch per frame using the harmonic product spectrum. Algorithm:
downsample the spectrum repeatedly padding with 0 to the original length,
then multiply the resulting scaled spectra. This has the effect of
emphasizing f0, which should hopefully become the highest spectral peak. See
https://cnx.org/contents/i5AAkZCP@2/Pitch-Detection-Algorithms
</p>


<h3>Value</h3>

<p>Returns either NULL or a dataframe of pitch candidates.
</p>

<hr>
<h2 id='getPitchSpec'>BaNa pitch tracker</h2><span id='topic+getPitchSpec'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPitchSpec(
  frame,
  bin,
  freqs,
  specMethod = c("commonFactor", "BaNa")[1],
  specRatios,
  specSmooth,
  specThres,
  specMerge,
  specPeak,
  specHNRslope,
  HNR = NULL,
  specSinglePeakCert,
  pitchFloor,
  pitchCeiling,
  nCands
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPitchSpec_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_bin">bin</code></td>
<td>
<p>the width of spectral bin in <code>frame</code>, Hz</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specmethod">specMethod</code></td>
<td>
<p>&quot;commonFactor&quot; = highest common factor of putative
harmonics, &quot;BaNa&quot; = ratio of putative harmonics</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specratios">specRatios</code></td>
<td>
<p>for method = &quot;commonFactor&quot;, the number of harmonics AND
integer fractions to consider</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specsmooth">specSmooth</code></td>
<td>
<p>the width of window for detecting peaks in the spectrum, Hz</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specthres">specThres</code></td>
<td>
<p>voicing threshold (unitless, ~0 to 1)</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specmerge">specMerge</code></td>
<td>
<p>pitch candidates within <code>specMerge</code> semitones are
merged with boosted certainty</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specpeak">specPeak</code>, <code id="getPitchSpec_+3A_spechnrslope">specHNRslope</code></td>
<td>
<p>when looking for putative harmonics in
the spectrum, the threshold for peak detection is calculated as
<code>specPeak * (1 - HNR * specHNRslope)</code></p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_hnr">HNR</code></td>
<td>
<p>harmonics-to-noise ratio returned by <code><a href="#topic+getPitchAutocor">getPitchAutocor</a></code></p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_specsinglepeakcert">specSinglePeakCert</code></td>
<td>
<p>(0 to 1) if f0 is calculated based on a single
harmonic ratio (as opposed to several ratios converging on the same
candidate), its certainty is taken to be <code>specSinglePeakCert</code></p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_pitchfloor">pitchFloor</code>, <code id="getPitchSpec_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id="getPitchSpec_+3A_ncands">nCands</code></td>
<td>
<p>number of pitch candidates pre frame (specMethod =
&quot;commonFactor&quot; always returns a single candidate)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attempts to find F0 of a frame by detecting several putative harmonics and
either finding their highest common factor (specMethod = &quot;commonFactor&quot;) or
comparing their ratios (specMethod = &quot;BaNa&quot;). For the highest common factor
method, see Howard &amp; Angus (2017) &quot;Acoustics and psychoacoustics&quot; (section
3.2.1). For BaNa, see Ba et al. (2012) &quot;BaNa: A hybrid approach for noise
resilient pitch detection.&quot; Statistical Signal Processing Workshop (SSP),
2012 IEEE.
</p>


<h3>Value</h3>

<p>Returns either NULL or a dataframe of pitch candidates.
</p>

<hr>
<h2 id='getPitchZc'>Zero-crossing rate</h2><span id='topic+getPitchZc'></span>

<h3>Description</h3>

<p>A less precise, but very quick method of pitch tracking based on measuring
zero-crossing rate in low-pass-filtered audio. Recommended for processing
long recordings with typical pitch values well below the first formant
frequency, such as speech. Calling this function is considerably faster than
using the same pitch-tracking method in <code><a href="#topic+analyze">analyze</a></code>. Note that,
unlike analyze(), it returns the times of individual zero crossings
(hopefully corresponding to glottal cycles) instead of pitch values at fixed
time intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPitchZc(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  pitchFloor = 50,
  pitchCeiling = 400,
  zcThres = 0.1,
  zcWin = 5,
  silence = 0.04,
  envWin = 5,
  summaryFun = c("mean", "sd"),
  reportEvery = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPitchZc_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_from">from</code>, <code id="getPitchZc_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_pitchfloor">pitchFloor</code>, <code id="getPitchZc_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_zcthres">zcThres</code></td>
<td>
<p>pitch candidates with certainty below this value are treated
as noise and set to NA (0 = anything goes, 1 = pitch must be perfectly
stable over <code>zcWin</code>)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_zcwin">zcWin</code></td>
<td>
<p>certainty in pitch candidates depends on how stable pitch is
over <code>zcWin</code> glottal cycles (odd integer &gt; 3)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_silence">silence</code></td>
<td>
<p>minimum root mean square (RMS) amplitude, below which pitch
candidates are set to NA (NULL = don't consider RMS amplitude)</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_envwin">envWin</code></td>
<td>
<p>window length for calculating RMS envelope, ms</p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic;
see <code><a href="#topic+analyze">analyze</a></code></p>
</td></tr>
<tr><td><code id="getPitchZc_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: the audio is bandpass-filtered from <code>pitchFloor</code> to <code>pitchCeiling</code>, and the timing of all zero crossings is saved. This is not enough, however, because unvoiced sounds like white noise also have plenty of zero crossings. Accordingly, an attempt is made to detect voiced segments (or steady musical tones, etc.) by looking for stable regions, with several zero-crossings at relatively regular intervals (see parameters <code>zcThres</code> and <code>zcWin</code>). Very quiet parts of audio are also treated as not having a pitch.
</p>


<h3>Value</h3>

<p>Returns a dataframe containing </p>
<dl>
<dt>time</dt><dd><p>time stamps of
all zero crossings except the last one, after bandpass-filtering</p>
</dd>
<dt>pitch</dt><dd><p>pitch calculated from the time between consecutive zero
crossings</p>
</dd> <dt>cert</dt><dd><p>certainty in each pitch candidate calculated from
local pitch stability, 0 to 1</p>
</dd></dl>



<h3>See Also</h3>

<p><code><a href="#topic+analyze">analyze</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sheep, package = 'seewave')
# spectrogram(sheep)
zc = getPitchZc(sheep, pitchCeiling = 250)
plot(zc$detailed[, c('time', 'pitch')], type = 'b')

# Convert to a standard pitch contour sampled at regular time intervals:
pitch = getSmoothContour(
  anchors = data.frame(time = zc$detailed$time, value = zc$detailed$pitch),
  len = 1000, NA_to_zero = FALSE, discontThres = 0)
spectrogram(sheep, extraContour = pitch, ylim = c(0, 2))

## Not run: 
# process all files in a folder
zc = getPitchZc('~/Downloads/temp')
zc$summary

## End(Not run)
</code></pre>

<hr>
<h2 id='getPrior'>Get prior for pitch candidates</h2><span id='topic+getPrior'></span>

<h3>Description</h3>

<p>Prior for adjusting the estimated pitch certainties in <code><a href="#topic+analyze">analyze</a></code>.
For ex., if primarily working with speech, we could prioritize pitch
candidates in the expected pitch range (100-1000 Hz) and decrease our
confidence in candidates with very high or very low frequency as unlikely but
still remotely possible. You can think of this as a &quot;soft&quot; alternative to
setting absolute pitch floor and ceiling. Algorithm: the multiplier for each
pitch candidate is the density of prior distribution with mean = priorMean
(Hz) and sd = priorSD (semitones) normalized so max = 1 over [pitchFloor,
pitchCeiling]. Useful for previewing the prior given to
<code><a href="#topic+analyze">analyze</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPrior(
  priorMean,
  priorSD,
  distribution = c("normal", "gamma")[1],
  pitchFloor = 75,
  pitchCeiling = 3000,
  len = 100,
  plot = TRUE,
  pitchCands = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPrior_+3A_priormean">priorMean</code>, <code id="getPrior_+3A_priorsd">priorSD</code></td>
<td>
<p>specifies the mean (Hz) and standard deviation
(semitones) of gamma distribution describing our prior knowledge about the
most likely pitch values for this file. For ex., <code>priorMean = 300,
priorSD = 6</code> gives a prior with mean = 300 Hz and SD = 6 semitones (half
an octave). To avoid using any priors, set <code>priorMean = NA, priorAdapt
= FALSE</code></p>
</td></tr>
<tr><td><code id="getPrior_+3A_distribution">distribution</code></td>
<td>
<p>the shape of prior distribution on the musical scale:
'normal' (mode = priorMean) or 'gamma' (skewed to lower frequencies)</p>
</td></tr>
<tr><td><code id="getPrior_+3A_pitchfloor">pitchFloor</code>, <code id="getPrior_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>absolute bounds for pitch candidates (Hz)</p>
</td></tr>
<tr><td><code id="getPrior_+3A_len">len</code></td>
<td>
<p>the required length of output vector (resolution)</p>
</td></tr>
<tr><td><code id="getPrior_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the prior</p>
</td></tr>
<tr><td><code id="getPrior_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of pitch candidate frequencies (for internal
soundgen use)</p>
</td></tr>
<tr><td><code id="getPrior_+3A_...">...</code></td>
<td>
<p>additional graphical parameters passed on to plot()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of certainties of length <code>len</code> if
pitchCands is NULL and a numeric matrix of the same dimensions as
pitchCands otherwise.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+analyze">analyze</a></code> <code><a href="#topic+pitch_app">pitch_app</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::getPrior(priorMean = 150,  # Hz
                    priorSD = 2)      # semitones
soundgen:::getPrior(150, 6)
s = soundgen:::getPrior(450, 24, pitchCeiling = 6000)
plot(s, type = 'l')
</code></pre>

<hr>
<h2 id='getRandomWalk'>Random walk</h2><span id='topic+getRandomWalk'></span>

<h3>Description</h3>

<p>Generates a random walk with flexible control over its range, trend, and
smoothness. It works by calling stats::rnorm at each step and taking a
cumulative sum of the generated values. Smoothness is controlled by initially
generating a shorter random walk and upsampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRandomWalk(
  len,
  rw_range = 1,
  rw_smoothing = 0.2,
  method = c("linear", "spline")[2],
  trend = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRandomWalk_+3A_len">len</code></td>
<td>
<p>an integer specifying the required length of random walk. If len
is 1, returns a single draw from a gamma distribution with mean=1 and
sd=rw_range</p>
</td></tr>
<tr><td><code id="getRandomWalk_+3A_rw_range">rw_range</code></td>
<td>
<p>the upper bound of the generated random walk (the lower bound
is set to 0)</p>
</td></tr>
<tr><td><code id="getRandomWalk_+3A_rw_smoothing">rw_smoothing</code></td>
<td>
<p>specifies the amount of smoothing, basically the number
of points used to construct the rw as a proportion of len, from 0 (no
smoothing) to 1 (maximum smoothing to a straight line)</p>
</td></tr>
<tr><td><code id="getRandomWalk_+3A_method">method</code></td>
<td>
<p>specifies the method of smoothing: either linear interpolation
('linear', see stats::approx) or cubic splines ('spline', see
stats::spline)</p>
</td></tr>
<tr><td><code id="getRandomWalk_+3A_trend">trend</code></td>
<td>
<p>mean of generated normal distribution (vectors are also
acceptable, as long as their length is an integer multiple of len). If
positive, the random walk has an overall upwards trend (good values are
between 0 and 0.5 or -0.5). Trend = c(1,-1) gives a roughly bell-shaped rw
with an upward and a downward curve. Larger absolute values of trend
produce less and less random behavior</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of length len and range from 0 to rw_range.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(getRandomWalk(len = 1000, rw_range = 5, rw_smoothing = 0))
plot(getRandomWalk(len = 1000, rw_range = 5, rw_smoothing = .2))
plot(getRandomWalk(len = 1000, rw_range = 5, rw_smoothing = .95))
plot(getRandomWalk(len = 1000, rw_range = 5, rw_smoothing = .99))
plot(getRandomWalk(len = 1000, rw_range = 5, rw_smoothing = 1))
plot(getRandomWalk(len = 1000, rw_range = 15,
  rw_smoothing = .2, trend = c(.1, -.1)))
plot(getRandomWalk(len = 1000, rw_range = 15,
  rw_smoothing = .2, trend = c(15, -1)))
</code></pre>

<hr>
<h2 id='getRMS'>RMS amplitude</h2><span id='topic+getRMS'></span>

<h3>Description</h3>

<p>Calculates root mean square (RMS) amplitude in overlapping windows, providing
an envelope of RMS amplitude - a measure of sound intensity. Longer windows
provide smoother, more robust estimates; shorter windows and more overlap
improve temporal resolution, but they also increase processing time and make
the contour less smooth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRMS(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  windowLength = 50,
  step = NULL,
  overlap = 70,
  stereo = c("left", "right", "average", "both")[1],
  killDC = FALSE,
  normalize = TRUE,
  windowDC = 200,
  summaryFun = "mean",
  reportEvery = NULL,
  cores = 1,
  plot = FALSE,
  savePlots = NULL,
  main = NULL,
  xlab = "",
  ylab = "",
  type = "b",
  col = "green",
  lwd = 2,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRMS_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="getRMS_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_from">from</code>, <code id="getRMS_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="getRMS_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="getRMS_+3A_stereo">stereo</code></td>
<td>
<p>'left' = only left channel, 'right' = only right channel,
'average' = take the mean of the two channels, 'both' = return RMS for both
channels separately</p>
</td></tr>
<tr><td><code id="getRMS_+3A_killdc">killDC</code></td>
<td>
<p>if TRUE, removed DC offset (see also <code><a href="#topic+flatEnv">flatEnv</a></code>)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, the RMS amplitude is returned as proportion of
the maximum possible amplitude as given by <code>scale</code></p>
</td></tr>
<tr><td><code id="getRMS_+3A_windowdc">windowDC</code></td>
<td>
<p>the window for calculating DC offset, ms</p>
</td></tr>
<tr><td><code id="getRMS_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic;
see <code><a href="#topic+analyze">analyze</a></code></p>
</td></tr>
<tr><td><code id="getRMS_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="getRMS_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plot a contour of RMS amplitude</p>
</td></tr>
<tr><td><code id="getRMS_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="getRMS_+3A_xlab">xlab</code>, <code id="getRMS_+3A_ylab">ylab</code>, <code id="getRMS_+3A_main">main</code></td>
<td>
<p>general graphical parameters</p>
</td></tr>
<tr><td><code id="getRMS_+3A_type">type</code>, <code id="getRMS_+3A_col">col</code>, <code id="getRMS_+3A_lwd">lwd</code></td>
<td>
<p>graphical parameters pertaining to the RMS envelope</p>
</td></tr>
<tr><td><code id="getRMS_+3A_width">width</code>, <code id="getRMS_+3A_height">height</code>, <code id="getRMS_+3A_units">units</code>, <code id="getRMS_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="getRMS_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that you can also get similar estimates per frame from
<code><a href="#topic+analyze">analyze</a></code> on a normalized scale of 0 to 1, but <code>getRMS</code> is
much faster, operates on the original scale, and plots the amplitude contour.
If you need RMS for the entire sound instead of per frame, you can simply
calculate it as <code>sqrt(mean(x^2))</code>, where <code>x</code> is your waveform.
Having RMS estimates per frame gives more flexibility: RMS per sound can be
calculated as the mean / median / max of RMS values per frame.
</p>


<h3>Value</h3>

<p>Returns a list containing: </p>

<dl>
<dt>$detailed: </dt><dd><p>a list of RMS amplitudes per frame for each sound, on the scale of input; names give time stamps for the center of each frame, in ms.</p>
</dd>
<dt>$summary: </dt><dd><p>a dataframe with summary measures, one row per sound</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+analyze">analyze</a></code> <code><a href="#topic+getLoudness">getLoudness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen() + .25  # with added DC offset
# osc(s)
r = getRMS(s, samplingRate = 16000, from = .05,
  windowLength = 40, overlap = 50, killDC = TRUE,
  plot = TRUE, type = 'l', lty = 2, main = 'RMS envelope')
r
# short window = jagged envelope
r = getRMS(s, samplingRate = 16000,
  windowLength = 5, overlap = 0, killDC = TRUE,
  plot = TRUE, col = 'blue', pch = 13, main = 'RMS envelope')

 # stereo
 wave_stereo = tuneR::Wave(
   left = runif(1000, -1, 1) * 16000,
   right = runif(1000, -1, 1) / 3 * 16000,
   bit = 16, samp.rate = 4000)
 getRMS(wave_stereo)$summary
 getRMS(wave_stereo, stereo = 'right')$summary
 getRMS(wave_stereo, stereo = 'average')$summary
 getRMS(wave_stereo, from = .05,
   stereo = 'both', plot = TRUE)$summary

## Not run: 
r = getRMS('~/Downloads/temp', savePlots = '~/Downloads/temp/plots')
r$summary

# Compare:
analyze('~/Downloads/temp', pitchMethods = NULL,
        plot = FALSE)$ampl_mean
# (per STFT frame, but should be very similar)

User-defined summary functions:
ran = function(x) diff(range(x))
meanSD = function(x) {
  paste0('mean = ', round(mean(x), 2), '; sd = ', round(sd(x), 2))
}
getRMS('~/Downloads/temp', summaryFun = c('mean', 'ran', 'meanSD'))$summary

## End(Not run)
</code></pre>

<hr>
<h2 id='getRolloff'>Control rolloff of harmonics</h2><span id='topic+getRolloff'></span>

<h3>Description</h3>

<p>Harmonics are generated as separate sine waves. But we don't want each
harmonic to be equally strong, so we normally specify some rolloff function
that describes the loss of energy in upper harmonics relative to the
fundamental frequency (f0). <code><a href="#topic+getRolloff">getRolloff</a></code> provides flexible
control over this rolloff function, going beyond simple exponential decay
(<code>rolloff</code>). Use quadratic terms to modify the behavior of a few lower
harmonics, <code>rolloffOct</code> to adjust the rate of decay per
octave, and <code>rolloffKHz</code> for rolloff correction depending on
f0. Plot the output with different parameter values and see examples below
and the vignette to get a feel for how to use <code><a href="#topic+getRolloff">getRolloff</a></code>
effectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRolloff(
  pitch_per_gc = c(440),
  nHarmonics = NULL,
  rolloff = -6,
  rolloffOct = 0,
  rolloffParab = 0,
  rolloffParabHarm = 3,
  rolloffParabCeiling = NULL,
  rolloffKHz = 0,
  baseline = 200,
  dynamicRange = 80,
  samplingRate = 16000,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRolloff_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>a vector of f0 per glottal cycle, Hz</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_nharmonics">nHarmonics</code></td>
<td>
<p>maximum number of harmonics to generate (very weak
harmonics with amplitude &lt; <code>-dynamicRange</code> will be discarded)</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_rolloff">rolloff</code></td>
<td>
<p>basic rolloff from lower to upper harmonics, db/octave
(exponential decay). All rolloff parameters are in anchor format. See
<code><a href="#topic+getRolloff">getRolloff</a></code> for more details</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_rolloffoct">rolloffOct</code></td>
<td>
<p>basic rolloff changes from lower to upper harmonics
(regardless of f0) by <code>rolloffOct</code> dB/oct. For example, we can get
steeper rolloff in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_rolloffparab">rolloffParab</code></td>
<td>
<p>an optional quadratic term affecting only the first
<code>rolloffParabHarm</code> harmonics. The middle harmonic of the first
<code>rolloffParabHarm</code> harmonics is amplified or dampened by
<code>rolloffParab</code> dB relative to the basic exponential decay</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_rolloffparabharm">rolloffParabHarm</code></td>
<td>
<p>the number of harmonics affected by
<code>rolloffParab</code></p>
</td></tr>
<tr><td><code id="getRolloff_+3A_rolloffparabceiling">rolloffParabCeiling</code></td>
<td>
<p>quadratic adjustment is applied only up to
<code>rolloffParabCeiling</code>, Hz. If not NULL, it overrides
<code>rolloffParabHarm</code></p>
</td></tr>
<tr><td><code id="getRolloff_+3A_rolloffkhz">rolloffKHz</code></td>
<td>
<p>rolloff changes linearly with f0 by <code>rolloffKHz</code>
dB/kHz. For ex., -6 dB/kHz gives a 6 dB steeper basic rolloff as f0 goes up
by 1000 Hz</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_baseline">baseline</code></td>
<td>
<p>The &quot;neutral&quot; f0, at which no adjustment of rolloff
takes place regardless of <code>rolloffKHz</code></p>
</td></tr>
<tr><td><code id="getRolloff_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. Harmonics and noise more than
dynamicRange under maximum amplitude are discarded to save computational
resources</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate (needed to stop at Nyquist frequency and
for plotting purposes)</p>
</td></tr>
<tr><td><code id="getRolloff_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of amplitude multiplication factors for adjusting
the amplitude of harmonics relative to f0 (1 = no adjustment, 0 = silent).
Each row of output contains one harmonic, and each column contains one
glottal cycle.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+soundgen">soundgen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># steady exponential rolloff of -12 dB per octave
rolloff = getRolloff(pitch_per_gc = 150, rolloff = -12,
  rolloffOct = 0, rolloffKHz = 0, plot = TRUE)
# the rate of rolloff slows down by 1 dB each octave
rolloff = getRolloff(pitch_per_gc = 150, rolloff = -12,
  rolloffOct = 1, rolloffKHz = 0, plot = TRUE)

# rolloff can be made to depend on f0 using rolloffKHz
rolloff = getRolloff(pitch_per_gc = c(150, 400, 800),
  rolloffOct = 0, rolloffKHz = -3, plot = TRUE)
# without the correction for f0 (rolloffKHz),
  # high-pitched sounds have the same rolloff as low-pitched sounds,
  # producing unnaturally strong high-frequency harmonics
rolloff = getRolloff(pitch_per_gc = c(150, 400, 800),
  rolloffOct = 0, rolloffKHz = 0, plot = TRUE)

# parabolic adjustment of lower harmonics
rolloff = getRolloff(pitch_per_gc = 350, rolloffParab = 0,
  rolloffParabHarm = 2, plot = TRUE)
# rolloffParabHarm = 1 affects only f0
rolloff = getRolloff(pitch_per_gc = 150, rolloffParab = 30,
  rolloffParabHarm = 1, plot = TRUE)
# rolloffParabHarm=2 or 3 affects only h1
rolloff = getRolloff(pitch_per_gc = 150, rolloffParab = 30,
  rolloffParabHarm = 2, plot = TRUE)
# rolloffParabHarm = 4 affects h1 and h2, etc
rolloff = getRolloff(pitch_per_gc = 150, rolloffParab = 30,
  rolloffParabHarm = 4, plot = TRUE)
# negative rolloffParab weakens lower harmonics
rolloff = getRolloff(pitch_per_gc = 150, rolloffParab = -20,
  rolloffParabHarm = 7, plot = TRUE)
# only harmonics below 2000 Hz are affected
rolloff = getRolloff(pitch_per_gc = c(150, 600),
  rolloffParab = -20, rolloffParabCeiling = 2000,
  plot = TRUE)

# dynamic rolloff (varies over time)
rolloff = getRolloff(pitch_per_gc = c(150, 250),
                     rolloff = c(-12, -18, -24), plot = TRUE)
rolloff = getRolloff(pitch_per_gc = c(150, 250), rolloffParab = 40,
                    rolloffParabHarm = 1:5, plot = TRUE)

## Not run: 
# Note: getRolloff() is called internally by soundgen()
# using the data.frame format for all vectorized parameters
# Compare:
s1 = soundgen(sylLen = 1000, pitch = 250,
              rolloff = c(-24, -2, -18), plot = TRUE)
s2 = soundgen(sylLen = 1000, pitch = 250,
              rolloff = data.frame(time = c(0, .2, 1),
                                   value = c(-24, -2, -18)),
              plot = TRUE)

# Also works for rolloffOct, rolloffParab, etc:
s3 = soundgen(sylLen = 1000, pitch = 250,
             rolloffParab = 20, rolloffParabHarm = 1:15, plot = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='getRough'>Calculate roughness from modulation spectrum</h2><span id='topic+getRough'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRough(m, roughRange = c(30, 150), roughMean = NULL, roughSD = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRough_+3A_m">m</code></td>
<td>
<p>numeric matrix of non-negative values with colnames giving temporal
modulation frequency</p>
</td></tr>
<tr><td><code id="getRough_+3A_roughrange">roughRange</code></td>
<td>
<p>the range of temporal modulation frequencies that
constitute the &quot;roughness&quot; zone, Hz</p>
</td></tr>
<tr><td><code id="getRough_+3A_roughmean">roughMean</code>, <code id="getRough_+3A_roughsd">roughSD</code></td>
<td>
<p>the mean (Hz) and standard deviation (semitones) of
a lognormal distribution used to weight roughness estimates. If either is
null, roughness is calculated simply as the proportion of spectrum within
<code>roughRange</code>. If both <code>roughMean</code> and <code>roughRange</code> are
defined, weights outside <code>roughRange</code> are set to 0; a very large SD (a
flat weighting function) gives the same result as just <code>roughRange</code>
without any weighting (see examples)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for calculating roughness - the proportion of energy /
amplitude in the roughness range
</p>


<h3>Value</h3>

<p>Returns roughness in percent.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m = modulationSpectrum(soundgen(jitterDep = 2, addSilence = 0),
  samplingRate = 16000)$original
# proportion within roughRange
plot(soundgen:::getRough(m, roughRange = c(30, Inf))[, 1:2])
plot(soundgen:::getRough(m, roughRange = c(30, 150))[, 1:2])

# lognormal weighting function instead of roughRange
plot(soundgen:::getRough(m, roughRange = NULL,
  roughMean = 75, roughSD = 1)[, 1:2])  # narrow
plot(soundgen:::getRough(m, roughRange = NULL,
  roughMean = 75, roughSD = 5000)[, 1:2])  # very broad

# lognormal weighting function truncated at roughRange
plot(soundgen:::getRough(m, roughRange = c(30, 150),
  roughMean = 75, roughSD = 3)[, 1:2])
plot(soundgen:::getRough(m, roughRange = c(30, 150),
  roughMean = 75, roughSD = 5000)[, 1:2])
# approaches proportion in roughRange as SD --&gt; Inf

# a nice plot weighting by amplitude
r2 = soundgen:::getRough(m)
plot(r2$freq, r2$rough, cex = r2$amp ^ 2 + .25)
sum(r2$rough)  # simple sum across all bands
sum(r2$rough * r2$amp / sum(r2$amp))  # amplitude-weighted mean
# log-amplitude-weighted mean
sum(r2$rough * log(r2$amp+1e-6) / sum(log(r2$amp+1e-6)))
</code></pre>

<hr>
<h2 id='getSHR'>Subharmonics-to-harmonics ratio</h2><span id='topic+getSHR'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSHR(
  frame,
  bin,
  freqs,
  pitch,
  pitchCands = NULL,
  samplingRate,
  method = c("cep", "pitchCands", "harm")[1],
  nSubh = 5,
  tol = 0.05,
  nHarm = 5,
  harmThres = 12,
  harmTol = 0.25,
  amRange = c(10, 200)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSHR_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="getSHR_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="getSHR_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="getSHR_+3A_pitch">pitch</code></td>
<td>
<p>pitch per frame, Hz</p>
</td></tr>
<tr><td><code id="getSHR_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a list of pitch candidates and certainties sent from
analyze()</p>
</td></tr>
<tr><td><code id="getSHR_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate (Hz)</p>
</td></tr>
<tr><td><code id="getSHR_+3A_method">method</code></td>
<td>
<p>'cep' = cepstrum, 'pitchCands' = existing pitch candidates
below f0, 'harm' = look for harmonic peaks. Only 'cep' is really working at
the moment.</p>
</td></tr>
<tr><td><code id="getSHR_+3A_nsubh">nSubh</code></td>
<td>
<p>the maximum ratio of f0 / g0 to consider</p>
</td></tr>
<tr><td><code id="getSHR_+3A_tol">tol</code></td>
<td>
<p>target frequency (eg f0 / 2) has to be within <code>tol * target</code>
(eg tol = .05 gives a tolerance of 5%)</p>
</td></tr>
<tr><td><code id="getSHR_+3A_nharm">nHarm</code></td>
<td>
<p>for method 'harm' only</p>
</td></tr>
<tr><td><code id="getSHR_+3A_harmthres">harmThres</code></td>
<td>
<p>minimum height of spectral peak, dB</p>
</td></tr>
<tr><td><code id="getSHR_+3A_harmtol">harmTol</code></td>
<td>
<p>maximum tolerated deviation of peak frequency from multiples
of f0, proportion of f0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Looks for pitch candidates (among the ones already found if method =
'pitchCands', or using some other pitch-tracking-like techniques such as
cepstrum) at integer ratios of f0. If such candidates are found, they are
treated as subharmonics. Note that this depends critically on accurate pitch
tracking.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
s400 = soundgen(
  sylLen = 300, pitch = c(280, 370, 330),
  subDep = list(
    time = c(0, .5, .51, 1),
    value = c(0, 0, 10, 10)
  ), subRatio = 3,
  smoothing = list(interpol = 'approx'), formants = 'a',
  rolloff = -12, addSilence = 50, temperature = .001,
  plot = TRUE, ylim = c(0, 2)
)
s = analyze(s400, samplingRate = 16000,
            windowLength =  50, step = 10,
            pitchMethods = c('dom', 'autocor', 'hps'), priorMean = NA,
            plot = TRUE, ylim = c(0, 3),
            extraContour = list('subDep', type = 'b', col = 'brown'))
s$detailed[, c('subRatio', 'subDep')]

s2 = analyze(s400, samplingRate = 16000,
            windowLength =  50, step = 10,
            pitchMethods = c('dom', 'autocor', 'hps'), priorMean = NA,
            subh = list(method = 'harm'),
            plot = TRUE, ylim = c(0, 3),
            extraContour = list('subDep', type = 'b', col = 'brown'))
s$detailed[, c('subRatio', 'subDep')]

## End(Not run)
</code></pre>

<hr>
<h2 id='getSigmoid'>Get sigmoid filter</h2><span id='topic+getSigmoid'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSigmoid(len, samplingRate = 16000, freq = 5, shape = 0, spikiness = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSigmoid_+3A_len">len</code></td>
<td>
<p>the length of output vector</p>
</td></tr>
<tr><td><code id="getSigmoid_+3A_samplingrate">samplingRate</code></td>
<td>
<p>the sampling rate of the output vector, Hz</p>
</td></tr>
<tr><td><code id="getSigmoid_+3A_freq">freq</code></td>
<td>
<p>the frequency of amplitude modulation, Hz (numeric vector)</p>
</td></tr>
<tr><td><code id="getSigmoid_+3A_shape">shape</code></td>
<td>
<p>0 = ~sine, -1 = clicks, +1 = notches (NB: vice versa in
soundgen!); numeric vector of length 1 or the same length as <code>freq</code></p>
</td></tr>
<tr><td><code id="getSigmoid_+3A_spikiness">spikiness</code></td>
<td>
<p>amplifies the effect of the &quot;shape&quot; parameter;
numeric vector of length 1 or the same length as <code>freq</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a filter for amplitude modulation ranging from clicks to
approximately a sine wave to reversed clicks (small episodes of silence). The
filter is made from concatenated sigmoids and their mirror reflections.
</p>


<h3>Value</h3>

<p>Returns a vector of length <code>len</code> and range from 0 to 1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfrow = c(3, 2))
for (shape in c(0, -.1, .1, .5, -1, 1)) {
  s = soundgen:::getSigmoid(shape = shape, len = 1000, samplingRate = 500, freq = 2)
  plot(s, type = 'l', main = paste('shape =', shape), xlab = '', ylab = '')
}
par(mfrow = c(1, 1))

par(mfrow = c(3, 2))
for (shape in c(0, -.1, .1, .5, -1, 1)) {
  s = soundgen:::getSigmoid(shape = shape, len = 1000, samplingRate = 500, freq = 2,
    spikiness = 3)
  plot(s, type = 'l', main = paste('shape =', shape), xlab = '', ylab = '')
}
par(mfrow = c(1, 1))
</code></pre>

<hr>
<h2 id='getSmoothContour'>Smooth contour from anchors</h2><span id='topic+getSmoothContour'></span>

<h3>Description</h3>

<p>Returns a smooth contour based on an arbitrary number of anchors. Used by
<code><a href="#topic+soundgen">soundgen</a></code> for generating intonation contour, mouth opening, etc.
This function is mostly intended to be used internally by soundgen, more
precisely to construct (upsample) smooth curves from a number of anchors. For
general upsampling or downsampling of audio, use <code><a href="#topic+resample">resample</a></code>. Note
that pitch contours are treated as a special case: values are log-transformed
prior to smoothing, so that with 2 anchors we get a linear transition on a
log scale (as if we were operating with musical notes rather than frequencies
in Hz). Pitch plots have two Y axes: one showing Hz and the other showing
musical notation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSmoothContour(
  anchors = data.frame(time = c(0, 1), value = c(0, 1)),
  len = NULL,
  thisIsPitch = FALSE,
  normalizeTime = TRUE,
  interpol = c("approx", "spline", "loess")[3],
  loessSpan = NULL,
  discontThres = 0.05,
  jumpThres = 0.01,
  valueFloor = NULL,
  valueCeiling = NULL,
  plot = FALSE,
  xlim = NULL,
  ylim = NULL,
  xlab = "Time, ms",
  ylab = ifelse(thisIsPitch, "Frequency, Hz", "Amplitude"),
  main = ifelse(thisIsPitch, "Pitch contour", ""),
  samplingRate = 16000,
  voiced = NULL,
  contourLabel = NULL,
  NA_to_zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSmoothContour_+3A_anchors">anchors</code></td>
<td>
<p>a numeric vector of values or a list/dataframe with one column
(value) or two columns (time and value). <code>achors$time</code> can be in ms
(with len=NULL) or in arbitrary units, eg 0 to 1 (with duration determined
by len, which must then be provided in ms). So anchors$time is assumed to
be in ms if len=NULL and relative if len is specified. <code>anchors$value</code>
can be on any scale.</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_len">len</code></td>
<td>
<p>the required length of the output contour. If NULL, it will be
calculated based on the maximum time value (in ms) and <code>samplingRate</code></p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_thisispitch">thisIsPitch</code></td>
<td>
<p>(boolean) is this a pitch contour? If true, log-transforms
before smoothing and plots in both Hz and musical notation</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_normalizetime">normalizeTime</code></td>
<td>
<p>if TRUE, normalizes anchors$time values to range from 0 to 1</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_interpol">interpol</code></td>
<td>
<p>method of interpolation between anchors: &quot;approx&quot; = linear
with <code><a href="stats.html#topic+approx">approx</a></code>, &quot;spline&quot; = cubic splines with
<code><a href="stats.html#topic+spline">spline</a></code>, &quot;loess&quot; = local polynomial regression with
<code><a href="stats.html#topic+loess">loess</a></code></p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_loessspan">loessSpan</code></td>
<td>
<p>controls the amount of smoothing when interpolating between
anchors with <code><a href="stats.html#topic+loess">loess</a></code>, so only has an effect if interpol
= 'loess' (1 = strong, 0.5 = weak smoothing)</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_discontthres">discontThres</code></td>
<td>
<p>if two anchors are closer in time than
<code>discontThres</code> (on a 0-1 scale, ie specified as proportion of total
length), the contour is broken into segments with a linear transition
between these segments</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_jumpthres">jumpThres</code></td>
<td>
<p>if anchors are closer than <code>jumpThres</code>, a new section
starts with no transition at all (e.g. for adding pitch jumps)</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_valuefloor">valueFloor</code>, <code id="getSmoothContour_+3A_valueceiling">valueCeiling</code></td>
<td>
<p>lowser/upper bounds for the contour</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_plot">plot</code></td>
<td>
<p>(boolean) produce a plot?</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_xlim">xlim</code>, <code id="getSmoothContour_+3A_ylim">ylim</code>, <code id="getSmoothContour_+3A_xlab">xlab</code>, <code id="getSmoothContour_+3A_ylab">ylab</code>, <code id="getSmoothContour_+3A_main">main</code></td>
<td>
<p>plotting options</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate used to convert time values to points (Hz)</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_voiced">voiced</code>, <code id="getSmoothContour_+3A_contourlabel">contourLabel</code></td>
<td>
<p>graphical pars for plotting breathing contours
(see examples below)</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_na_to_zero">NA_to_zero</code></td>
<td>
<p>if TRUE, all NAs are replaced with zero</p>
</td></tr>
<tr><td><code id="getSmoothContour_+3A_...">...</code></td>
<td>
<p>other plotting options passed to <code>plot()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of length <code>len</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># long format: anchors are a dataframe
a = getSmoothContour(anchors = data.frame(
  time = c(50, 137, 300), value = c(0.03, 0.78, 0.5)),
  normalizeTime = FALSE,
  voiced = 200, valueFloor = 0, plot = TRUE, main = '',
  samplingRate = 16000) # breathing

# short format: anchors are a vector (equal time steps assumed)
a = getSmoothContour(anchors = c(350, 800, 600),
  len = 5500, thisIsPitch = TRUE, plot = TRUE,
  samplingRate = 3500) # pitch

# a single anchor gives constant value
a = getSmoothContour(anchors = 800,
  len = 500, thisIsPitch = TRUE, plot = TRUE, samplingRate = 500)

# two pitch anchors give loglinear F0 change
a = getSmoothContour(anchors = c(220, 440),
  len = 500, thisIsPitch = TRUE, plot = TRUE, samplingRate = 500)

## Two closely spaced anchors produce a pitch jump
# one loess for the entire contour
a1 = getSmoothContour(anchors = list(time = c(0, .15, .2, .7, 1),
    value = c(360, 116, 550, 700, 610)), len = 500, thisIsPitch = TRUE,
    plot = TRUE, samplingRate = 500)
# two segments with a linear transition
a2 = getSmoothContour(anchors = list(time = c(0, .15, .17, .7, 1),
    value = c(360, 116, 550, 700, 610)), len = 500, thisIsPitch = TRUE,
    plot = TRUE, samplingRate = 500)
# two segments with an abrupt jump
a3 = getSmoothContour(anchors = list(time = c(0, .15, .155, .7, 1),
    value = c(360, 116, 550, 700, 610)), len = 500, thisIsPitch = TRUE,
    plot = TRUE, samplingRate = 500)
# compare:
plot(a2)
plot(a3)  # NB: the segment before the jump is upsampled to compensate

## Control the amount of smoothing
getSmoothContour(c(1, 3, 9, 10, 9, 9, 2), len = 100, plot = TRUE,
  loessSpan = NULL)  # default amount of smoothing (depends on dur)
getSmoothContour(c(1, 3, 9, 10, 9, 9, 2), len = 100, plot = TRUE,
  loessSpan = .85)   # more smoothing than default
getSmoothContour(c(1, 3, 9, 10, 9, 9, 2), len = 100, plot = TRUE,
  loessSpan = .5)    # less smoothing
getSmoothContour(c(1, 3, 9, 10, 9, 9, 2), len = 100, plot = TRUE,
  interpol = 'approx')  # linear interpolation (no smoothing)

## Upsample preserving leading and trailing NAs
anchors = data.frame(time =  c(1,  4,  5,  7,  10, 20, 23, 25, 30),
                     value = c(NA, NA, 10, 15, 12, NA, 17, 15, NA))
plot(anchors, type = 'b')
anchors_ups = getSmoothContour(
  anchors, len = 200,
  interpol = 'approx',  # only approx can propagate NAs
  NA_to_zero = FALSE,   # preserve NAs
  discontThres = 0)     # don't break into sub-contours
plot(anchors_ups, type = 'b')
</code></pre>

<hr>
<h2 id='getSmoothSpectrum'>Get smooth spectrum</h2><span id='topic+getSmoothSpectrum'></span>

<h3>Description</h3>

<p>Internal soundgen function for getting a smoothed spectrum. Called by
formant_app().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSmoothSpectrum(
  sound,
  samplingRate = NULL,
  spectrum = NULL,
  len,
  loessSpan,
  windowLength = 100,
  overlap = 0,
  plot = FALSE,
  xlab = "Frequency, kHz",
  ylab = "dB",
  type = "l",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSmoothSpectrum_+3A_sound">sound</code></td>
<td>
<p>the audio (numeric, any scale)</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_spectrum">spectrum</code></td>
<td>
<p>pre-extracted spectrum in dB with columns &quot;freq&quot; and &quot;ampl&quot;</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_len">len</code></td>
<td>
<p>the desired resolution of the output</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_loessspan">loessSpan</code></td>
<td>
<p>passed to loess to control the amount of smoothing (.01 =
minimal smoothing, 1 = strong smoothing)</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="getSmoothSpectrum_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 100, pitch = 500, addSilence = FALSE)
soundgen:::getSmoothSpectrum(s, 16000, len = 500, loessSpan = .01, plot = TRUE)
soundgen:::getSmoothSpectrum(s, 16000, len = 500, loessSpan = .1, plot = TRUE)
soundgen:::getSmoothSpectrum(s, 16000, len = 500, loessSpan = .5, plot = TRUE)
soundgen:::getSmoothSpectrum(s, 16000, len = 500, loessSpan = 1, plot = TRUE)

sp = seewave::meanspec(s, f = 16000, dB = 'max0')
colnames(sp) = c('freq', 'ampl')
soundgen:::getSmoothSpectrum(spectrum = sp, len = 500, loessSpan = .1, plot = TRUE)
</code></pre>

<hr>
<h2 id='getSpectralEnvelope'>Spectral envelope</h2><span id='topic+getSpectralEnvelope'></span>

<h3>Description</h3>

<p>Prepares a spectral envelope for filtering a sound to add formants, lip
radiation, and some stochastic component regulated by temperature. Formants
are specified as a list containing time, frequency, amplitude, and width
values for each formant (see examples). See vignette('sound_generation',
package = 'soundgen') for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSpectralEnvelope(
  nr,
  nc,
  formants = NA,
  formantDep = 1,
  formantWidth = 1,
  lipRad = 6,
  noseRad = 4,
  mouth = NA,
  mouthOpenThres = 0.2,
  openMouthBoost = 0,
  vocalTract = NULL,
  temperature = 0.05,
  formDrift = 0.3,
  formDisp = 0.2,
  formantDepStoch = 1,
  smoothLinearFactor = 1,
  formantCeiling = 2,
  samplingRate = 16000,
  speedSound = 35400,
  smoothing = list(),
  output = c("simple", "detailed")[1],
  plot = FALSE,
  duration = NULL,
  colorTheme = c("bw", "seewave", "...")[1],
  col = NULL,
  xlab = "Time",
  ylab = "Frequency, kHz",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSpectralEnvelope_+3A_nr">nr</code></td>
<td>
<p>the number of frequency bins = windowLength_points/2, where
windowLength_points is the size of window for Fourier transform</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_nc">nc</code></td>
<td>
<p>the number of time steps for Fourier transform</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formants">formants</code></td>
<td>
<p>a character string like &quot;aaui&quot; referring to default presets
for speaker &quot;M1&quot;; a vector of formant frequencies; or a list of formant
times, frequencies, amplitudes, and bandwidths, with a single value of each
for static or multiple values of each for moving formants. <code>formants =
NA</code> defaults to schwa. Time stamps for formants and mouthOpening can be
specified in ms or an any other arbitrary scale.</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formantdep">formantDep</code></td>
<td>
<p>scale factor of formant amplitude (1 = no change relative
to amplitudes in <code>formants</code>)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formantwidth">formantWidth</code></td>
<td>
<p>scale factor of formant bandwidth (1 = no change)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_liprad">lipRad</code></td>
<td>
<p>the effect of lip radiation on source spectrum, dB/oct (the
default of +6 dB/oct produces a high-frequency boost when the mouth is
open)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_noserad">noseRad</code></td>
<td>
<p>the effect of radiation through the nose on source spectrum,
dB/oct (the alternative to <code>lipRad</code> when the mouth is closed)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_mouth">mouth</code></td>
<td>
<p>mouth opening (0 to 1, 0.5 = neutral, i.e. no
modification) (anchor format)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_mouthopenthres">mouthOpenThres</code></td>
<td>
<p>open the lips (switch from nose radiation to lip
radiation) when the mouth is open <code>&gt;mouthOpenThres</code>, 0 to 1</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_openmouthboost">openMouthBoost</code></td>
<td>
<p>amplify the voice when the mouth is open by
<code>openMouthBoost</code> dB</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_vocaltract">vocalTract</code></td>
<td>
<p>the length of vocal tract, cm. Used for calculating formant
dispersion (for adding extra formants) and formant transitions as the mouth
opens and closes. If <code>NULL</code> or <code>NA</code>, the length is estimated
based on specified formant frequencies, if any (anchor format)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formdrift">formDrift</code></td>
<td>
<p>scale factor regulating the effect of temperature on the
depth of random drift of all formants (user-defined and stochastic): the
higher, the more formants drift at a given temperature</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formdisp">formDisp</code></td>
<td>
<p>scale factor regulating the effect of temperature on the
irregularity of the dispersion of stochastic formants: the higher, the more
unevenly stochastic formants are spaced at a given temperature</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formantdepstoch">formantDepStoch</code></td>
<td>
<p>multiplication factor for the amplitude of additional
formants added above the highest specified formant (0 = none, 1 = default)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_smoothlinearfactor">smoothLinearFactor</code></td>
<td>
<p>regulates smoothing of formant anchors (0 to +Inf)
as they are upsampled to the number of fft steps <code>nc</code>. This is
necessary because the input <code>formants</code> normally contains fewer
sets of formant values than the number of fft steps.
<code>smoothLinearFactor</code> = 0: close to default spline; &gt;3: approaches
linear extrapolation</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_formantceiling">formantCeiling</code></td>
<td>
<p>frequency to which stochastic formants are calculated,
in multiples of the Nyquist frequency; increase up to ~10 for long vocal
tracts to avoid losing energy in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_speedsound">speedSound</code></td>
<td>
<p>speed of sound in warm air, cm/s. Stevens (2000) &quot;Acoustic
phonetics&quot;, p. 138</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_smoothing">smoothing</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+getSmoothContour">getSmoothContour</a></code> to control the interpolation and smoothing
of contours: interpol (approx / spline / loess), loessSpan, discontThres,
jumpThres</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_output">output</code></td>
<td>
<p>&quot;simple&quot; returns just the spectral filter, while &quot;detailed&quot;
also returns a data.frame of formant frequencies over time (needed for
internal purposes such as formant locking)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a plot of the spectral envelope</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_duration">duration</code></td>
<td>
<p>duration of the sound, ms (for plotting purposes only)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
or another color theme (e.g. 'heat.colors')</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_xlab">xlab</code>, <code id="getSpectralEnvelope_+3A_ylab">ylab</code></td>
<td>
<p>labels of axes</p>
</td></tr>
<tr><td><code id="getSpectralEnvelope_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed on to <code>image()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a spectral filter: a matrix with frequency bins in rows and
time steps in columns. Accordingly, rownames of the output give central
frequency of each bin (in kHz), while colnames give time stamps (in ms if
duration is specified, otherwise 0 to 1).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># [a] with only F1-F3 visible, with no stochasticity
e = getSpectralEnvelope(nr = 512, nc = 50, duration = 300,
  formants = soundgen:::convertStringToFormants('a'),
  temperature = 0, plot = TRUE, col = heat.colors(150))
# image(t(e))  # to plot the output on a linear scale instead of dB

# some "wiggling" of specified formants plus extra formants on top
e = getSpectralEnvelope(nr = 512, nc = 50,
  formants = c(860, 1430, 2900),
  temperature = 0.1, formantDepStoch = 1, plot = TRUE)

# a schwa based on variable length of vocal tract
e = getSpectralEnvelope(nr = 512, nc = 100, formants = NA,
  vocalTract = list(time = c(0, .4, 1), value = c(13, 18, 17)),
  temperature = .1, plot = TRUE)

# no formants at all, only lip radiation
e = getSpectralEnvelope(nr = 512, nc = 50, lipRad = 6,
  formants = NA, temperature = 0, plot = FALSE)
plot(e[, 1], type = 'l')              # linear scale
plot(20 * log10(e[, 1]), type = 'l')  # dB scale - 6 dB/oct

# mouth opening
e = getSpectralEnvelope(nr = 512, nc = 50,
  vocalTract = 16, plot = TRUE, lipRad = 6, noseRad = 4,
  mouth = data.frame(time = c(0, .5, 1), value = c(0, 0, .5)))

# scale formant amplitude and/or bandwidth
e1 = getSpectralEnvelope(nr = 512, nc = 50,
  formants = soundgen:::convertStringToFormants('a'),
  formantWidth = 1, formantDep = 1)  # defaults
e2 = getSpectralEnvelope(nr = 512, nc = 50,
  formants = soundgen:::convertStringToFormants('a'),
  formantWidth = 1.5, formantDep = 1.5)
plot(as.numeric(rownames(e2)), 20 * log10(e2[, 1]),
     type = 'l', xlab = 'KHz', ylab = 'dB', col = 'red', lty = 2)
points(as.numeric(rownames(e1)), 20 * log10(e1[, 1]), type = 'l')

# manual specification of formants
e3 = getSpectralEnvelope(
  nr = 512, nc = 50, samplingRate = 16000, plot = TRUE,
  formants = list(
    f1 = list(freq = c(900, 500), amp = c(30, 35), width = c(80, 50)),
    f2 = list(freq = c(1900, 2500), amp = c(25, 30), width = 100),
    f3 = list(freq = 3400, amp = 30, width = 120)
))

# extra zero-pole pair (doesn't affect estimated VTL and thus the extra
# formants added on top)
e4 = getSpectralEnvelope(
  nr = 512, nc = 50, samplingRate = 16000, plot = TRUE,
  formants = list(
    f1 = list(freq = c(900, 500), amp = c(30, 35), width = c(80, 50)),
    f1.5 = list(freq = 1300, amp = -15),
    f1.7 = list(freq = 1500, amp = 15),
    f2 = list(freq = c(1900, 2500), amp = c(25, 30), width = 100),
    f3 = list(freq = 3400, amp = 30, width = 120)
))
plot(as.numeric(rownames(e4)), 20 * log10(e3[, ncol(e3)]),
     type = 'l', xlab = 'KHz', ylab = 'dB')
points(as.numeric(rownames(e4)), 20 * log10(e4[, ncol(e4)]),
       type = 'l', col = 'red', lty = 2)
</code></pre>

<hr>
<h2 id='getSpectralFlux'>Get spectral flux</h2><span id='topic+getSpectralFlux'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSpectralFlux(s)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSpectralFlux_+3A_s">s</code></td>
<td>
<p>raw spectrogram (not normalized): rows = frequency bins, columns = STFT frames</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates spectral flux: the average change across all spectral bins from
one STFT frame to the next. Spectra are normalized in each frame, so
amplitude changes have no effect on flux.
</p>


<h3>Value</h3>

<p>vector of length ncol(s)
</p>

<hr>
<h2 id='getSurprisal'>Get surprisal</h2><span id='topic+getSurprisal'></span>

<h3>Description</h3>

<p>Tracks the (un)predictability of spectral changes in a sound over time,
returning a continuous contour of &quot;surprisal&quot;. This is an attempt to track
auditory salience over time - that is, to identify parts of a sound that are
likely to involuntarily attract the listeners' attention. The functions
returns surprisal proper ('$surprisal') and its product with increases in
loudness ('$surprisalLoudness'). Because getSurprisal() is slow and
experimental, it is not called by analyze().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSurprisal(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  winSurp = 2000,
  audSpec_pars = list(filterType = "butterworth", nFilters = 64, step = 20, yScale =
    "bark"),
  method = c("acf", "np")[1],
  summaryFun = "mean",
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  contrast = 0.2,
  brightness = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSurprisal_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_from">from</code>, <code id="getSurprisal_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_winsurp">winSurp</code></td>
<td>
<p>surprisal analysis window, ms (Inf = from sound onset to each
point)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_audspec_pars">audSpec_pars</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+audSpectrogram">audSpectrogram</a></code></p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_method">method</code></td>
<td>
<p>acf = change in maximum autocorrelation after adding the final
point, np = nonlinear prediction (see <code><a href="#topic+nonlinPred">nonlinPred</a></code>)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic,
eg &quot;c('mean', 'sd')&quot;; user-defined functions are fine (see examples); NAs
are omitted automatically for mean/median/sd/min/max/range/sum, otherwise
take care of NAs yourself</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the auditory spectrogram and the
<code>suprisalLoudness</code> contour</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_xlab">xlab</code>, <code id="getSurprisal_+3A_ylab">ylab</code>, <code id="getSurprisal_+3A_main">main</code>, <code id="getSurprisal_+3A_mar">mar</code>, <code id="getSurprisal_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_width">width</code>, <code id="getSurprisal_+3A_height">height</code>, <code id="getSurprisal_+3A_units">units</code>, <code id="getSurprisal_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="getSurprisal_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: we start with an auditory spectrogram produced by applying a bank
of bandpass filters to the signal, by default with central frequencies
equally spaced on the bark scale (see <code><a href="#topic+audSpectrogram">audSpectrogram</a></code>). For each
frequency channel, a sliding window is analyzed to compare the actually
observed final value with its expected value. There are many ways to
extrapolate / predict time series and thus perform this comparison such as
autocorrelation (method = 'acf') or nonlinear prediction (method = 'np'). The
resulting per-channel surprisal contours are aggregated by taking their mean
weighted by the average amplitude of each frequency channel across the
analysis window. Because increases in loudness are known to be important
predictors of auditory salience, loudness per frame is also returned, as well
as the square root of the product of its derivative and surprisal.
</p>


<h3>Value</h3>

<p>Returns a list with $detailed per-frame and $summary per-file results
(see <code><a href="#topic+analyze">analyze</a></code> for more information). Three measures are
reported: <code>loudness</code> (in sone, as per <code><a href="#topic+getLoudness">getLoudness</a></code>), the
first derivative of loudness with respect to time (<code>dLoudness</code>),
<code>surprisal</code> (non-negative), and <code>suprisalLoudness</code> (geometric
mean of surprisal and dLoudness, treating negative values of dLoudness as
zero).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A quick example
s = soundgen(nSyl = 2, sylLen = 50, pauseLen = 25, addSilence = 15)
surp = getSurprisal(s, samplingRate = 16000)
surp

## Not run: 
# A more meaningful example
sound = soundgen(nSyl = 5, sylLen = 150,
  pauseLen = c(50, 50, 50, 130), pitch = c(200, 150),
  noise = list(time = c(-300, 200), value = -20), plot = TRUE)
# playme(sound)
surp = getSurprisal(sound, samplingRate = 16000,
  yScale = 'bark', method = 'acf')
surp = getSurprisal(sound, samplingRate = 16000,
  yScale = 'bark', method = 'np')  # very slow
surp = getSurprisal(sound, samplingRate = 16000,
  yScale = 'bark', method = 'acf', audSpec_pars = list(
  nFilters = 128, yScale = 'ERB', bandwidth = 1/12))

# short window = amnesia (every event is equally surprising)
getSurprisal(sound, samplingRate = 16000, winSurp = 250)
# long window - remembers further into the past, Inf = from the beginning
surp = getSurprisal(sound, samplingRate = 16000, winSurp = Inf)

# plot "pure" surprisal, without weighting by loudness
spectrogram(sound, 16000, extraContour = surp$detailed$surprisal /
  max(surp$detailed$surprisal, na.rm = TRUE) * 8000)

# NB: surprisalLoudness contour is also log-transformed if yScale = 'log',
# so zeros become NAs
surp = getSurprisal(sound, samplingRate = 16000, yScale = 'log')

# add bells and whistles
surp = getSurprisal(sound, samplingRate = 16000,
  yScale = 'mel',
  osc = 'dB',  # plot oscillogram in dB
  heights = c(2, 1),  # spectro/osc height ratio
  brightness = -.1,  # reduce brightness
  # colorTheme = 'heat.colors',  # pick color theme...
  col = rev(hcl.colors(30, palette = 'Viridis')),  # ...or specify the colors
  cex.lab = .75, cex.axis = .75,  # text size and other base graphics pars
  ylim = c(0, 5),  # always in kHz
  main = 'Audiogram with surprisal contour', # title
  extraContour = list(col = 'blue', lty = 2, lwd = 2)
  # + axis labels, etc
)

surp = getSurprisal('~/Downloads/temp/', savePlots = '~/Downloads/temp/surp')
surp$summary

## End(Not run)
</code></pre>

<hr>
<h2 id='getSurprisal_matrix'>Get surprisal per matrix</h2><span id='topic+getSurprisal_matrix'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+getSurprisal">getSurprisal</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSurprisal_matrix(x, win, method = c("acf", "np")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSurprisal_matrix_+3A_x">x</code></td>
<td>
<p>input matrix such as a spectrogram (columns = time, rows =
frequency)</p>
</td></tr>
<tr><td><code id="getSurprisal_matrix_+3A_win">win</code></td>
<td>
<p>length of analysis window</p>
</td></tr>
<tr><td><code id="getSurprisal_matrix_+3A_method">method</code></td>
<td>
<p>acf = change in maximum autocorrelation after adding the final
point, np = nonlinear prediction (see <code><a href="#topic+nonlinPred">nonlinPred</a></code>)</p>
</td></tr>
</table>

<hr>
<h2 id='getSurprisal_vector'>Get surprisal per vector</h2><span id='topic+getSurprisal_vector'></span>

<h3>Description</h3>

<p>Internal soundgen function called by <code><a href="#topic+getSurprisal">getSurprisal</a></code>. Estimates
the unexpectedness or &quot;surprisal&quot; of the last element of input vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSurprisal_vector(x, method = c("acf", "np")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSurprisal_vector_+3A_x">x</code></td>
<td>
<p>numeric vector representing the time sequence of interest, eg
amplitudes in a frequency bin over multiple STFT frames</p>
</td></tr>
<tr><td><code id="getSurprisal_vector_+3A_method">method</code></td>
<td>
<p>acf = change in maximum autocorrelation after adding the final
point, np = nonlinear prediction (see <code><a href="#topic+nonlinPred">nonlinPred</a></code>)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x = c(rep(1, 3), rep(0, 4), rep(1, 3), rep(0, 4), rep(1, 3), 0, 0)
soundgen:::getSurprisal_vector(x)
soundgen:::getSurprisal_vector(c(x, 1))
soundgen:::getSurprisal_vector(c(x, 13))

soundgen:::getSurprisal_vector(x, method = 'np')
soundgen:::getSurprisal_vector(c(x, 1), method = 'np')
soundgen:::getSurprisal_vector(c(x, 13), method = 'np')
</code></pre>

<hr>
<h2 id='guessPhase_GL'>Guess phase GL</h2><span id='topic+guessPhase_GL'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>guessPhase_GL(
  spec,
  phase,
  nIter,
  samplingRate,
  overlap,
  wn,
  step_points,
  verbose = TRUE,
  plotError = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="guessPhase_GL_+3A_spec">spec</code></td>
<td>
<p>the spectrogram that is to be transform to a time series: numeric
matrix with frequency bins in rows and time frames in columns</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_phase">phase</code></td>
<td>
<p>an initial guess at the phase: numeric matrix of the same dimensions as spec</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_niter">nIter</code></td>
<td>
<p>the number of iterations of the GL algorithm (Griffin &amp; Lim,
1984), 0 = don't run</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_step_points">step_points</code></td>
<td>
<p>STFT step in points</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, prints estimated time left every 10% of GL
iterations</p>
</td></tr>
<tr><td><code id="guessPhase_GL_+3A_ploterror">plotError</code></td>
<td>
<p>if TRUE, produces a scree plot of squared error over GL
iterations (useful for choosing 'nIter')</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the iterative method proposed by Griffin &amp; Lim (1984) to guess the phase
of a magnitude spectrogram.
</p>


<h3>Value</h3>

<p>Returns a matrix of the same dimensions as 'spec' containing the
guessed phase.
</p>

<hr>
<h2 id='guessPhase_spsi'>Guess phase SPSI</h2><span id='topic+guessPhase_spsi'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>guessPhase_spsi(spec, windowLength_points, step_points)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="guessPhase_spsi_+3A_spec">spec</code></td>
<td>
<p>the spectrogram that is to be transform to a time series: numeric
matrix with frequency bins in rows and time frames in columns</p>
</td></tr>
<tr><td><code id="guessPhase_spsi_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>STFT window length in points</p>
</td></tr>
<tr><td><code id="guessPhase_spsi_+3A_step_points">step_points</code></td>
<td>
<p>STFT step in points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Single-pass spectrogram inversion as described in Beauregard, G. T., Harish,
M., &amp; Wyse, L. (2015, July). Single pass spectrogram inversion. In 2015 IEEE
International Conference on Digital Signal Processing (DSP) (pp. 427-431).
IEEE. See <code><a href="#topic+invertSpectrogram">invertSpectrogram</a></code> for details.
</p>


<h3>Value</h3>

<p>Returns a matrix of the same dimensions as 'spec' containing the
guessed phase.
</p>

<hr>
<h2 id='harmEnergy'>Energy in harmonics</h2><span id='topic+harmEnergy'></span>

<h3>Description</h3>

<p>Internal soundgun function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmEnergy(pitch, s, freqs = NULL, coef = 1.25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="harmEnergy_+3A_pitch">pitch</code></td>
<td>
<p>pitch estimates, Hz (vector)</p>
</td></tr>
<tr><td><code id="harmEnergy_+3A_s">s</code></td>
<td>
<p>spectrogram (ncol = length(pitch))</p>
</td></tr>
<tr><td><code id="harmEnergy_+3A_freqs">freqs</code></td>
<td>
<p>as.numeric(rownames(s)) * 1000</p>
</td></tr>
<tr><td><code id="harmEnergy_+3A_coef">coef</code></td>
<td>
<p>calculate above pitch * coef</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the 
</p>

<hr>
<h2 id='harmHeight'>Height of harmonics</h2><span id='topic+harmHeight'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmHeight(
  frame,
  pitch,
  bin,
  freqs,
  harmThres = 3,
  harmTol = 0.25,
  harmPerSel = 5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="harmHeight_+3A_frame">frame</code></td>
<td>
<p>the abs spectrum of a frame, as returned by
<code><a href="stats.html#topic+fft">fft</a></code></p>
</td></tr>
<tr><td><code id="harmHeight_+3A_pitch">pitch</code></td>
<td>
<p>the final pitch estimate for the current frame</p>
</td></tr>
<tr><td><code id="harmHeight_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="harmHeight_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="harmHeight_+3A_harmthres">harmThres</code></td>
<td>
<p>minimum height of spectral peak, dB</p>
</td></tr>
<tr><td><code id="harmHeight_+3A_harmtol">harmTol</code></td>
<td>
<p>maximum tolerated deviation of peak frequency from multiples
of f0, proportion of f0</p>
</td></tr>
<tr><td><code id="harmHeight_+3A_harmpersel">harmPerSel</code></td>
<td>
<p>the number of harmonics per sliding selection</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attempts to estimate how high harmonics reach in the spectrum - that is, at
what frequency we can still discern peaks at multiples of f0 or, for
low-pitched sounds, regularly spaced peaks separated by ~f0.
</p>


<h3>Value</h3>

<p>Returns the frequency (Hz) up to which we find harmonics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 400, addSilence = 0, pitch = 400, noise = -10,
  rolloff = -15, jitterDep = .1, shimmerDep = 5, temperature = .001)
sp = spectrogram(s, samplingRate = 16000)
hh = soundgen:::harmHeight(sp[, 5], pitch = 400,
  freqs = as.numeric(rownames(sp)) * 1000, bin = 16000 / 2 / nrow(sp))
hh
</code></pre>

<hr>
<h2 id='harmHeight_dif'>Height of harmonics: difference method</h2><span id='topic+harmHeight_dif'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmHeight_dif(
  frame_dB,
  pitch,
  bin,
  freqs,
  harmThres = 3,
  harmTol = 0.25,
  harmPerSel = 5,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="harmHeight_dif_+3A_pitch">pitch</code></td>
<td>
<p>the final pitch estimate for the current frame</p>
</td></tr>
<tr><td><code id="harmHeight_dif_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="harmHeight_dif_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="harmHeight_dif_+3A_harmthres">harmThres</code></td>
<td>
<p>minimum height of spectral peak, dB</p>
</td></tr>
<tr><td><code id="harmHeight_dif_+3A_harmtol">harmTol</code></td>
<td>
<p>maximum tolerated deviation of peak frequency from multiples
of f0, proportion of f0</p>
</td></tr>
<tr><td><code id="harmHeight_dif_+3A_harmpersel">harmPerSel</code></td>
<td>
<p>the number of harmonics per sliding selection</p>
</td></tr>
<tr><td><code id="harmHeight_dif_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a plot of spectral peaks</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates how far harmonics reach in the spectrum by analyzing the typical
distances between spectral peaks in different frequency regions.
</p>

<hr>
<h2 id='harmHeight_peaks'>Height of harmonics: peaks method</h2><span id='topic+harmHeight_peaks'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmHeight_peaks(
  frame_dB,
  pitch,
  bin,
  freqs,
  harmThres = 3,
  harmTol = 0.25,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="harmHeight_peaks_+3A_pitch">pitch</code></td>
<td>
<p>the final pitch estimate for the current frame</p>
</td></tr>
<tr><td><code id="harmHeight_peaks_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width, Hz</p>
</td></tr>
<tr><td><code id="harmHeight_peaks_+3A_freqs">freqs</code></td>
<td>
<p>frequency per bin of spectrogram</p>
</td></tr>
<tr><td><code id="harmHeight_peaks_+3A_harmthres">harmThres</code></td>
<td>
<p>minimum height of spectral peak, dB</p>
</td></tr>
<tr><td><code id="harmHeight_peaks_+3A_harmtol">harmTol</code></td>
<td>
<p>maximum tolerated deviation of peak frequency from multiples
of f0, proportion of f0</p>
</td></tr>
<tr><td><code id="harmHeight_peaks_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a plot of spectral peaks</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates how far harmonics reach in the spectrum by checking how many
spectral peaks we can find close to multiples of f0.
</p>

<hr>
<h2 id='hillenbrand'>Formants in American vowels</h2><span id='topic+hillenbrand'></span>

<h3>Description</h3>

<p>Typical relative frequencies of the first four formants measured in dF units
(average spacing between formants, or formant dispersion) above or below
schwa based on estimated VTL in American English, from Hillenbrand (1995),
who measured F1-F4 in ~1.5K recordings (139 speakers, 12 vowels from each).
Audio and formant measurements are freely available online:
https://homepages.wmich.edu/~hillenbr/voweldata.html. The dataset below is
the result of modeling Hillenbrand's data with brms: mvbind(F1rel, F2rel) ~
vowel + (vowel|speaker). It shows the most credible location of each vowel
centroid in the F1Rel-F2Rel space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hillenbrand
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 12 rows and 5 columns.
</p>


<h3>Details</h3>

<p>A dataframe of 12 observations and 5 columns: &quot;vowel&quot; = vowel (American
English), &quot;F1Rel&quot; to &quot;F4Rel&quot; = formant frequencies in dF relative to their
neutral, equidistant positions in a perfectly cylindrical vocal tract. See
<code><a href="#topic+schwa">schwa</a></code> - this is what schwa() returns as $ff_relative_dF
</p>


<h3>References</h3>

<p>Hillenbrand, J., Getty, L. A., Clark, M. J., &amp; Wheeler, K.
(1995). Acoustic characteristics of American English vowels. The Journal of
the Acoustical society of America, 97(5), 3099-3111.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(hillenbrand$F1Rel, hillenbrand$F2Rel, type = 'n')
text(hillenbrand$F1Rel, hillenbrand$F2Rel, labels = hillenbrand$vowel)
</code></pre>

<hr>
<h2 id='htmlPlots'>HTML for clickable plots</h2><span id='topic+htmlPlots'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htmlPlots(
  x,
  savePlots,
  changesAudio,
  suffix,
  extension = "png",
  width = "900px"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="htmlPlots_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="htmlPlots_+3A_saveplots">savePlots</code></td>
<td>
<p>a list of full names of files (with paths and extensions)</p>
</td></tr>
<tr><td><code id="htmlPlots_+3A_changesaudio">changesAudio</code></td>
<td>
<p>if TRUE, it means we modify the input audio, so the
result shouldn't be saved in the original folder (if savePlots = &rdquo;)</p>
</td></tr>
<tr><td><code id="htmlPlots_+3A_suffix">suffix</code></td>
<td>
<p>an extra string to add before the extension, usually the name
of the function that calls htmlPlots, eg &quot;spectrogram&quot;</p>
</td></tr>
<tr><td><code id="htmlPlots_+3A_extension">extension</code></td>
<td>
<p>file extension for the saved plots</p>
</td></tr>
<tr><td><code id="htmlPlots_+3A_width">width</code></td>
<td>
<p>the default width of flex elements in html</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Writes an html file for displaying clickable plots in a browser.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Functions that modify audio
# relative paths
flatEnv('/home/allgoodguys/Downloads/temp', savePlots = '')
flatEnv('/home/allgoodguys/Downloads/temp',
  savePlots = '/home/allgoodguys/Downloads/temp/compr',
  saveAudio = '/home/allgoodguys/Downloads/temp/compr')

# absolute paths
flatEnv('/home/allgoodguys/Downloads/temp', savePlots = '',
  saveAudio = '/home/allgoodguys/Downloads/temp/compr')
flatEnv('/home/allgoodguys/Downloads/temp',
  savePlots = '~/Downloads/temp/plots_compr')


## Functions that only analyze audio
getRMS('/home/allgoodguys/Downloads/temp', savePlots = '')
getRMS('/home/allgoodguys/Downloads/temp',
  savePlots = '~/Downloads/temp/plots_rms')

## End(Not run)
</code></pre>

<hr>
<h2 id='hz2mel'>Hz to mel</h2><span id='topic+hz2mel'></span>

<h3>Description</h3>

<p>Internal soundgen function: a temporary fix needed because tuneR::hz2mel
doesn't accept NAs or vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hz2mel(f, htk = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hz2mel_+3A_f">f</code></td>
<td>
<p>frequency, Hz</p>
</td></tr>
<tr><td><code id="hz2mel_+3A_htk">htk</code></td>
<td>
<p>algrithm</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::hz2mel(c(440, 220, NA))
freq = 1:10000
plot(freq, soundgen:::hz2mel(freq), type = 'l')
</code></pre>

<hr>
<h2 id='HzToERB'>Convert Hz to ERB rate</h2><span id='topic+HzToERB'></span>

<h3>Description</h3>

<p>Converts from Hz to the number of Equivalent Rectangular Bandwidths (ERBs)
below input frequency. See https://www2.ling.su.se/staff/hartmut/bark.htm and
https://en.wikipedia.org/wiki/Equivalent_rectangular_bandwidth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HzToERB(h, method = c("linear", "quadratic")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HzToERB_+3A_h">h</code></td>
<td>
<p>vector or matrix of frequencies (Hz)</p>
</td></tr>
<tr><td><code id="HzToERB_+3A_method">method</code></td>
<td>
<p>approximation to use</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ERBToHz">ERBToHz</a></code> <code><a href="#topic+HzToSemitones">HzToSemitones</a></code>
<code><a href="#topic+HzToNotes">HzToNotes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HzToERB(c(-20, 20, 100, 440, 1000, NA))

f = 20:20000
erb_lin = HzToERB(f, 'linear')
erb_quadratic = HzToERB(f, 'quadratic')
plot(f, erb_lin, log = 'x', type = 'l')
points(f, erb_quadratic, col = 'blue', type = 'l')

# compare with the bark scale:
barks = tuneR::hz2bark(f)
points(f, barks / max(barks) * max(erb_lin),
  col = 'red', type = 'l', lty = 2)
</code></pre>

<hr>
<h2 id='HzToNotes'>Convert Hz to notes</h2><span id='topic+HzToNotes'></span>

<h3>Description</h3>

<p>Converts from Hz to musical notation like A4 - note A of the fourth octave
above C0 (16.35 Hz).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HzToNotes(h, showCents = FALSE, A4 = 440)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HzToNotes_+3A_h">h</code></td>
<td>
<p>vector or matrix of frequencies (Hz)</p>
</td></tr>
<tr><td><code id="HzToNotes_+3A_showcents">showCents</code></td>
<td>
<p>if TRUE, show cents to the nearest notes (cent = 1/100 of a
semitone)</p>
</td></tr>
<tr><td><code id="HzToNotes_+3A_a4">A4</code></td>
<td>
<p>frequency of note A in the fourth octave (modern standard ISO 16 or
concert pitch = 440 Hz)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+notesToHz">notesToHz</a></code> <code><a href="#topic+HzToSemitones">HzToSemitones</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HzToNotes(c(440, 293, 115, 16.35, 4))

HzToNotes(c(440, 415, 80, 81), showCents = TRUE)
# 80 Hz is almost exactly midway (+49 cents) between D#2 and E2

# Baroque tuning A415, half a semitone flat relative to concert pitch A440
HzToNotes(c(440, 415, 16.35), A4 = 415)
</code></pre>

<hr>
<h2 id='HzToSemitones'>Convert Hz to semitones</h2><span id='topic+HzToSemitones'></span>

<h3>Description</h3>

<p>Converts from Hz to semitones above C-5 (~0.5109875 Hz) or another reference
frequency. This may not seem very useful, but note that this gives us a nice
logarithmic scale for generating natural pitch transitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HzToSemitones(h, ref = 0.5109875)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HzToSemitones_+3A_h">h</code></td>
<td>
<p>vector or matrix of frequencies (Hz)</p>
</td></tr>
<tr><td><code id="HzToSemitones_+3A_ref">ref</code></td>
<td>
<p>frequency of the reference value (defaults to C-5, 0.51 Hz)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+semitonesToHz">semitonesToHz</a></code> <code><a href="#topic+HzToNotes">HzToNotes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = HzToSemitones(c(440, 293, 115))
# to convert to musical notation
notesDict$note[1 + round(s)]
# note the "1 +": semitones ABOVE C-5, i.e. notesDict[1, ] is C-5

# Any reference tone can be specified. For ex., for semitones above C0, use:
HzToSemitones(440, ref = 16.35)
# TIP: see notesDict for a table of Hz frequencies to musical notation
</code></pre>

<hr>
<h2 id='identifyAndPlay'>Identify and play</h2><span id='topic+identifyAndPlay'></span>

<h3>Description</h3>

<p>Internal soundgen function. NB: even built-in examples of identify() not
working in R 4.4.1 (points not identified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identifyAndPlay(
  x,
  y = NULL,
  data = NULL,
  audioFolder,
  to = 5,
  plot = FALSE,
  pch = 19,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="identifyAndPlay_+3A_x">x</code>, <code id="identifyAndPlay_+3A_y">y</code></td>
<td>
<p>plot coordinates</p>
</td></tr>
<tr><td><code id="identifyAndPlay_+3A_data">data</code></td>
<td>
<p>dataframe from which x &amp; y are taken, also containing a column
called &quot;file&quot;</p>
</td></tr>
<tr><td><code id="identifyAndPlay_+3A_audiofolder">audioFolder</code></td>
<td>
<p>path to audio files</p>
</td></tr>
<tr><td><code id="identifyAndPlay_+3A_to">to</code></td>
<td>
<p>play only the first ... s</p>
</td></tr>
<tr><td><code id="identifyAndPlay_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the index of clicked points</p>
</td></tr>
<tr><td><code id="identifyAndPlay_+3A_pch">pch</code></td>
<td>
<p>symbol for marking clicked points</p>
</td></tr>
<tr><td><code id="identifyAndPlay_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code>identify()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>A wrapper around <code>identify()</code> intended to play the sound corresponding
to a clicked point.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
msf = modulationSpectrum('~/Downloads/temp', plot = FALSE)

# Method 1: provide path to folder, leave data = NULL
plot(msf$summary$amMsFreq_median, msf$summary$amMsDep_median)
soundgen:::identifyAndPlay(msf$summary$amFreq_median, msf$summary$amDep_median,
  audioFolder = '~/Downloads/temp',
  to = 2,
 plot = TRUE,
 pch = 19)

# Method 2:
x = msf$summary$amMsFreq_median
y = msf$summary$amMsDep_median
plot(x, y)
soundgen:::identifyAndPlay(x, y, data = msf$summary,
  audioFolder = '~/Downloads/temp',
  to = 2,
  plot = FALSE,
  pch = 8)

## End(Not run)
</code></pre>

<hr>
<h2 id='interpolate'>Interpolate</h2><span id='topic+interpolate'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpolate(
  pitchCands,
  pitchCert,
  pitchSource,
  pitchCenterGravity,
  interpolWin_bin = 3,
  interpolTol = 0.3,
  interpolCert = 0.3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpolate_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="interpolate_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="interpolate_+3A_pitchcentergravity">pitchCenterGravity</code></td>
<td>
<p>numeric vector giving the mean of all pitch
candidates per fft frame weighted by our certainty in each of these
candidates</p>
</td></tr>
<tr><td><code id="interpolate_+3A_interpolwin_bin">interpolWin_bin</code></td>
<td>
<p>when interpolating pitch candidates, the median is
calculated over <code>plus-minus interpolWin_bin</code></p>
</td></tr>
<tr><td><code id="interpolate_+3A_interpoltol">interpolTol</code></td>
<td>
<p>when interpolating pitch candidates, the criterion
for needing to interpolate is the absence of pitch candidates with values
within <code>1 plus-minus interpolTol</code> of the median of pitch center of
gravity over the interpolation window. For ex., if <code>interpolTol</code>
is .05, we look for values from 0.95 to 1.05 time the median value over
interpolation window.</p>
</td></tr>
<tr><td><code id="interpolate_+3A_interpolcert">interpolCert</code></td>
<td>
<p>when interpolating pitch candidates, all generated pitch
candidates are assigned a certainty equal to <code>interpolCert</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Interpolation: if a frame has no pitch candidate at all (NA) or no candidate
between the most likely candidates for the adjacent frames, add such a
candidate with some (low) certainty.
</p>


<h3>Value</h3>

<p>Returns a modified pitchCands matrix.
</p>

<hr>
<h2 id='interpolMatrix'>Interpolate matrix</h2><span id='topic+interpolMatrix'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpolMatrix(m, nr = NULL, nc = NULL, interpol = c("approx", "spline")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interpolMatrix_+3A_m">m</code></td>
<td>
<p>input matrix of numeric values</p>
</td></tr>
<tr><td><code id="interpolMatrix_+3A_nr">nr</code>, <code id="interpolMatrix_+3A_nc">nc</code></td>
<td>
<p>target dimensions</p>
</td></tr>
<tr><td><code id="interpolMatrix_+3A_interpol">interpol</code></td>
<td>
<p>interpolation method ('approx' for linear, 'spline' for
spline)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Performs a chosen type of interpolation (bilinear or spline) across both rows
and columns of a matrix, in effect up- or downsampling a matrix to required
dimensions. Rownames and colnames are also interpolated as needed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m = matrix(1:12 + rnorm(12, 0, .2), nrow = 3)
rownames(m) = 1:3; colnames(m) = 1:4
soundgen:::interpolMatrix(m)  # just returns the original
soundgen:::interpolMatrix(m, nr = 10, nc = 7)
soundgen:::interpolMatrix(m, nr = 10, nc = 7, interpol = 'spline')
soundgen:::interpolMatrix(m, nr = 2, nc = 7)
soundgen:::interpolMatrix(m, nr = 2, nc = 3)

# input matrices can have a single row/column
soundgen:::interpolMatrix(matrix(1:5, nrow = 1), nc = 9)
soundgen:::interpolMatrix(matrix(1:5, ncol = 1), nr = 5, nc = 3)
</code></pre>

<hr>
<h2 id='intplNA'>Interpolate NAs</h2><span id='topic+intplNA'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intplNA(x, idx_na = NULL, nPoints = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intplNA_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="intplNA_+3A_idx_na">idx_na</code></td>
<td>
<p>which(is.na(x))</p>
</td></tr>
<tr><td><code id="intplNA_+3A_npoints">nPoints</code></td>
<td>
<p>the number of points to use for interpolating leading and
trailing NAs: 1 = constant interpolation, 2 = use the first two non-NAs at
the beginning and the last two non-NAs at the end, etc.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a numeric vector and fills in the NAs by linear
interpolation in the middle and constant or linear interpolation at the ends.
</p>


<h3>Value</h3>

<p>Returns the same numeric vector with NAs filled in by interpolation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::intplNA(c(NA, 405, 441, 460, NA, NA, NA, 480, 490, NA, NA))
soundgen:::intplNA(c(NA, 405, 441, 460, NA, NA, NA, 480, 490, NA, NA), nPoints = 3)
</code></pre>

<hr>
<h2 id='invertSpectrogram'>Invert spectrogram</h2><span id='topic+invertSpectrogram'></span>

<h3>Description</h3>

<p>Transforms a spectrogram into a time series with inverse STFT. The problem is
that an ordinary spectrogram preserves only the magnitude (modulus) of the
complex STFT, while the phase is lost, and without phase it is impossible to
reconstruct the original audio accurately. So there are a number of
algorithms for &quot;guessing&quot; the phase that would produce an audio whose
magnitude spectrogram is very similar to the target spectrogram. Useful for
certain filtering operations that modify the magnitude spectrogram followed
by inverse STFT, such as filtering in the spectrotemporal modulation domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invertSpectrogram(
  spec,
  samplingRate,
  windowLength,
  overlap,
  step = NULL,
  wn = "hanning",
  specType = c("abs", "log", "dB")[1],
  initialPhase = c("zero", "random", "spsi")[3],
  nIter = 50,
  normalize = TRUE,
  play = TRUE,
  verbose = FALSE,
  plotError = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="invertSpectrogram_+3A_spec">spec</code></td>
<td>
<p>the spectrogram that is to be transform to a time series: numeric
matrix with frequency bins in rows and time frames in columns</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_spectype">specType</code></td>
<td>
<p>the scale of target spectroram: 'abs' = absolute, 'log' =
log-transformed, 'dB' = in decibels</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_initialphase">initialPhase</code></td>
<td>
<p>initial phase estimate: &quot;zero&quot; = set all phases to zero;
&quot;random&quot; = Gaussian noise; &quot;spsi&quot; (default) = single-pass spectrogram
inversion (Beauregard et al., 2015)</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_niter">nIter</code></td>
<td>
<p>the number of iterations of the GL algorithm (Griffin &amp; Lim,
1984), 0 = don't run</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, normalizes the output to range from -1 to +1</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_play">play</code></td>
<td>
<p>if TRUE, plays back the reconstructed audio</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, prints estimated time left every 10% of GL
iterations</p>
</td></tr>
<tr><td><code id="invertSpectrogram_+3A_ploterror">plotError</code></td>
<td>
<p>if TRUE, produces a scree plot of squared error over GL
iterations (useful for choosing 'nIter')</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: takes the spectrogram, makes an initial guess at the phase (zero,
noise, or a more intelligent estimate by the SPSI algorithm), fine-tunes over
'nIter' iterations with the GL algorithm, reconstructs the complex
spectrogram using the best phase estimate, and performs inverse STFT. The
single-pass spectrogram inversion (SPSI) algorithm is implemented as
described in Beauregard et al. (2015) following the python code at
https://github.com/lonce/SPSI_Python. The Griffin-Lim (GL) algorithm is based
on Griffin &amp; Lim (1984).
</p>


<h3>Value</h3>

<p>Returns the reconstructed audio as a numeric vector.
</p>


<h3>References</h3>


<ul>
<li><p> Griffin, D., &amp; Lim, J. (1984). Signal estimation from modified
short-time Fourier transform. IEEE Transactions on Acoustics, Speech, and
Signal Processing, 32(2), 236-243.
</p>
</li>
<li><p> Beauregard, G. T., Harish, M., &amp; Wyse, L. (2015, July). Single pass
spectrogram inversion. In 2015 IEEE International Conference on Digital
Signal Processing (DSP) (pp. 427-431). IEEE.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spectrogram">spectrogram</a></code> <code><a href="#topic+filterSoundByMS">filterSoundByMS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a spectrogram
samplingRate = 16000
windowLength = 40
overlap = 75
wn = 'gaussian'

s = soundgen(samplingRate = samplingRate, addSilence = 100)
spec = spectrogram(s, samplingRate = samplingRate,
  wn = wn, windowLength = windowLength, step = NULL, overlap = overlap,
  padWithSilence = FALSE, output = 'original')

# Invert the spectrogram, attempting to guess the phase
# Note that samplingRate, wn, windowLength, and overlap must be the same as
# in the original (ie you have to know how the spectrogram was created)
s_new = invertSpectrogram(spec, samplingRate = samplingRate,
  windowLength = windowLength, overlap = overlap, wn = wn,
  initialPhase = 'spsi', nIter = 100, specType = 'abs', play = FALSE)

# Verify the quality of audio reconstruction
# playme(s, samplingRate); playme(s_new, samplingRate)
</code></pre>

<hr>
<h2 id='isNeighbour_mod'>Is neighbor modified</h2><span id='topic+isNeighbour_mod'></span>

<h3>Description</h3>

<p>Just a copy of nonlinearTseries:::isNeighbour to avoid a note in
CMD check when calling an unexported function from another package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isNeighbour_mod(v1, v2, embedding.dim, radius)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isNeighbour_mod_+3A_v1">v1</code>, <code id="isNeighbour_mod_+3A_v2">v2</code>, <code id="isNeighbour_mod_+3A_embedding.dim">embedding.dim</code>, <code id="isNeighbour_mod_+3A_radius">radius</code></td>
<td>
<p>see nonlinearTseries:::isNeighbour</p>
</td></tr>
</table>

<hr>
<h2 id='iso226'>iso226</h2><span id='topic+iso226'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iso226(phon, nBarks = 22)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iso226_+3A_phon">phon</code></td>
<td>
<p>the phon value in dB SPL represented by the loudness curve</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates equal loudness curves according to the ISO226 standard. Expected
range of input values in phon is 0 to 90 (1 phon is 1 dB at 1 kHz). The range
of evaluated frequencies is 20 to 12500 Hz, with a total of 29 values (so
upsample if more resolution is needed, but not that beyond 22 barks it's just
assumed to be flat). Translated from the matlab implementation by Jeff Tackett
(03/01/05) available from
&quot;https://www.mathworks.com/matlabcentral/fileexchange/
7028-iso-226-equal-loudness-level-contour-signal&quot;
</p>


<h3>Value</h3>

<p>A dataframe containing evaluated frequencies and SPL values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>i = soundgen:::iso226(40)
plot(i$curve29, type = 'l')
plot(i$curveBark$freq_Hz, i$curveBark$spl, type = 'l')
</code></pre>

<hr>
<h2 id='istft_mod'>Modified istft</h2><span id='topic+istft_mod'></span>

<h3>Description</h3>

<p>Internal soundgen function. Similar to seewave:::istft(), but adapted to work
with time-variable step sizes in the context of dynamic pitch shifting. Only
call it for dynamic istft because the original seewave function should be a
bit faster for static.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>istft_mod(
  stft,
  f,
  wl,
  ovlp = 75,
  wn = "hanning",
  mult_short = 1,
  mult_long = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="istft_mod_+3A_stft">stft</code>, <code id="istft_mod_+3A_f">f</code>, <code id="istft_mod_+3A_wl">wl</code>, <code id="istft_mod_+3A_ovlp">ovlp</code>, <code id="istft_mod_+3A_wn">wn</code></td>
<td>
<p>see seewave:::istft()</p>
</td></tr>
<tr><td><code id="istft_mod_+3A_mult_short">mult_short</code></td>
<td>
<p>stretch factor of length <code>ncol(stft) - 1</code></p>
</td></tr>
<tr><td><code id="istft_mod_+3A_mult_long">mult_long</code></td>
<td>
<p>stretch factor of length <code>ncol(stft)</code></p>
</td></tr>
</table>

<hr>
<h2 id='jet.col'>Matlab colors</h2><span id='topic+jet.col'></span>

<h3>Description</h3>

<p>Internal soundgen function for generating a Matlab-like palette
(=plot3D::jet.col).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jet.col(n = 100, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jet.col_+3A_n">n</code></td>
<td>
<p>number of colors</p>
</td></tr>
<tr><td><code id="jet.col_+3A_alpha">alpha</code></td>
<td>
<p>transparency</p>
</td></tr>
</table>

<hr>
<h2 id='killDC'>Kill DC</h2><span id='topic+killDC'></span>

<h3>Description</h3>

<p>Removes DC offset or similar disbalance in a waveform dynamically, by
subtracting a smoothed ~moving average. Simplified compared to a true moving
average, but very fast (a few ms per second of 44100 audio).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>killDC(
  sound,
  windowLength = 200,
  samplingRate = 16000,
  windowLength_points = NULL,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="killDC_+3A_windowlength">windowLength</code></td>
<td>
<p>the length of smoothing window, ms</p>
</td></tr>
<tr><td><code id="killDC_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="killDC_+3A_windowlength_points">windowLength_points</code></td>
<td>
<p>the length of smoothing window, points. If
specified, overrides <code>windowLength</code></p>
</td></tr>
<tr><td><code id="killDC_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original sound, smoothed moving average, and
modified sound</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># remove static DC offset
a = rnorm(500) + .3
b = soundgen:::killDC(a, windowLength_points = 500, plot = TRUE)

# remove trend
a = rnorm(500) + seq(0, 1, length.out = 500)
b = soundgen:::killDC(a, windowLength_points = 100, plot = TRUE)

# can also be used as a high-pass filter
a = rnorm(500) + sin(1:500 / 50)
b = soundgen:::killDC(a, windowLength_points = 25, plot = TRUE)
</code></pre>

<hr>
<h2 id='listDepth'>List depth</h2><span id='topic+listDepth'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listDepth(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="listDepth_+3A_x">x</code></td>
<td>
<p>any R object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the depth of list structure. See https://stackoverflow.com/questions/13432863/determine-level-of-nesting-in-r
</p>

<hr>
<h2 id='lockToFormants'>Lock to formants</h2><span id='topic+lockToFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lockToFormants(
  pitch,
  specEnv,
  formantSummary,
  rolloffMatrix = NULL,
  lockProb = 0.1,
  minLength = 3,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lockToFormants_+3A_pitch">pitch</code></td>
<td>
<p>pitch contour, numeric vector (normally pitch_per_gc)</p>
</td></tr>
<tr><td><code id="lockToFormants_+3A_specenv">specEnv</code></td>
<td>
<p>spectral envelope as returned by getSpectralEnvelope</p>
</td></tr>
<tr><td><code id="lockToFormants_+3A_formantsummary">formantSummary</code></td>
<td>
<p>matrix of exact formant frequencies (formants in rows,
time in columns)</p>
</td></tr>
<tr><td><code id="lockToFormants_+3A_rolloffmatrix">rolloffMatrix</code></td>
<td>
<p>rolloff matrix as returned by getRolloff</p>
</td></tr>
<tr><td><code id="lockToFormants_+3A_lockprob">lockProb</code></td>
<td>
<p>the (approximate) proportion of sound affected by formant
locking</p>
</td></tr>
<tr><td><code id="lockToFormants_+3A_minlength">minLength</code></td>
<td>
<p>the minimum number of consecutive pitch values affected
(shorter segments of formant locking are ignored)</p>
</td></tr>
<tr><td><code id="lockToFormants_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original and modified pitch contour</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When f0 or another relatively strong harmonic is close to one of the
formants, the pitch contour is modified so as to &quot;lock&quot; it to this formant.
The relevant metric is energy gain (ratio of amplitudes before and after the
adjustment) penalized by the magnitude of the necessary pitch jump (in
semitones) and the amplitude of the locked harmonic relative to f0.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 50
pitch = getSmoothContour(len = n, anchors = c(600, 2000, 1900, 400),
  thisIsPitch = TRUE, plot = TRUE)
rolloffMatrix = getRolloff(pitch_per_gc = pitch)
specEnv = getSpectralEnvelope(nr = 512, nc = length(pitch),
  formants = list(f1 = c(800, 1200), f2 = 2000, f3 = c(3500, 3200)),
  lipRad = 0, temperature = .00001, plot = TRUE)
formantSummary = t(data.frame(f1 = c(800, 1200), f2 = c(2000, 2000), f3 = c(3500, 3200)))
pitch2 = soundgen:::lockToFormants(pitch = pitch, specEnv = specEnv,
  rolloffMatrix = rolloffMatrix,
  formantSummary = formantSummary,
  lockProb = .5, minLength = 5, plot = TRUE)
pitch3 = soundgen:::lockToFormants(pitch = pitch, specEnv = specEnv,
  rolloffMatrix = rolloffMatrix,
  formantSummary = formantSummary,
  lockProb = list(time = c(0, .7, 1), value = c(0, 1, 0)),
  minLength = 5, plot = TRUE)
</code></pre>

<hr>
<h2 id='log01'>log01</h2><span id='topic+log01'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log01(v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log01_+3A_v">v</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Normalizes, log-transforms, and re-normalizes an input vector, so it ranges
from 0 to 1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::log01(exp(1:10))
</code></pre>

<hr>
<h2 id='logistic'>Logistic</h2><span id='topic+logistic'></span>

<h3>Description</h3>

<p>Logistic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logistic_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>

<hr>
<h2 id='logit'>Logit</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>Logit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logit_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>

<hr>
<h2 id='logMatrix'>Log-warp matrix</h2><span id='topic+logMatrix'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logMatrix(m, base = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logMatrix_+3A_m">m</code></td>
<td>
<p>a matrix of numeric values of any dimensions (not necessarily
square)</p>
</td></tr>
<tr><td><code id="logMatrix_+3A_base">base</code></td>
<td>
<p>the base of logarithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Log-warps a matrix, as if log-transforming plot axes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m = matrix(1:90, nrow = 10)
colnames(m) = 1:9
soundgen:::logMatrix(m, base = 2)
soundgen:::logMatrix(m, base = 10)

soundgen:::logMatrix(m = matrix(1:9, nrow = 1), base = 2)

## Not run: 
s = spectrogram(soundgen(), 16000, output = 'original')
image(log(t(soundgen:::logMatrix(s, base = 2))))

## End(Not run)
</code></pre>

<hr>
<h2 id='logWarpMS'>Log-warp a modulation spectrum</h2><span id='topic+logWarpMS'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logWarpMS(x, logWarp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logWarpMS_+3A_x">x</code></td>
<td>
<p>a modulation spectrum: rows = FM, cols = AM</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Log-warps a modulation spectrum along time dimension
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = matrix(1:44, ncol = 11)
colnames(a) = -5:5
soundgen:::logWarpMS(a, logWarp = 2)
</code></pre>

<hr>
<h2 id='matchColumns'>Match number of columns</h2><span id='topic+matchColumns'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchColumns(
  matrix_short,
  nCol,
  padWith = 0,
  padDir = "central",
  interpol = c("approx", "spline")[1]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matchColumns_+3A_matrix_short">matrix_short</code></td>
<td>
<p>input matrix</p>
</td></tr>
<tr><td><code id="matchColumns_+3A_ncol">nCol</code></td>
<td>
<p>the required number of columns</p>
</td></tr>
<tr><td><code id="matchColumns_+3A_padwith">padWith</code></td>
<td>
<p>the value to pad with, normally <code>0</code> or <code>NA</code></p>
</td></tr>
<tr><td><code id="matchColumns_+3A_paddir">padDir</code></td>
<td>
<p>specifies the affected side. For padding, it is the side on
which new elements will be added. For trimming, this is the side that will
be trimmed. Defaults to 'central'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adds columns of new values (eg zeros or NAs) to a matrix, so that the new
number of columns = <code>len</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = matrix(1:9, nrow = 3)
soundgen:::matchColumns(a, nCol = 6, padWith = NA, padDir = 'central')
soundgen:::matchColumns(a, nCol = 6, padWith = 0, padDir = 'central')
soundgen:::matchColumns(a, nCol = 6, padWith = NA, padDir = 'left')
soundgen:::matchColumns(a, nCol = 6, padWith = 'a', padDir = 'right')
soundgen:::matchColumns(a, nCol = 2)
</code></pre>

<hr>
<h2 id='matchLengths'>Resize vector to required length</h2><span id='topic+matchLengths'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchLengths(
  myseq,
  len,
  padDir = c("left", "right", "central")[3],
  padWith = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matchLengths_+3A_myseq">myseq</code></td>
<td>
<p>input vector</p>
</td></tr>
<tr><td><code id="matchLengths_+3A_len">len</code></td>
<td>
<p>target length</p>
</td></tr>
<tr><td><code id="matchLengths_+3A_paddir">padDir</code></td>
<td>
<p>specifies the affected side. For padding, it is the side on
which new elements will be added. For trimming, this is the side that will
be trimmed. Defaults to 'central'</p>
</td></tr>
<tr><td><code id="matchLengths_+3A_padwith">padWith</code></td>
<td>
<p>if the vector needs to be padded to match the required length,
what should it be padded with? Defaults to 0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adjusts a vector to match the required length by either trimming one or both
ends or padding them with zeros.
</p>


<h3>Value</h3>

<p>Returns the modified vector of the required length.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::matchLengths(1:3, len = 5)
soundgen:::matchLengths(1:3, len = 15, padWith = NA)
soundgen:::matchLengths(3:7, len = 3)
# trimmed on the left
soundgen:::matchLengths(3:7, len = 3, padDir = 'left')
# padded with zeros on the left
soundgen:::matchLengths(3:7, len = 10, padDir = 'left')
#' # trimmed on the right
soundgen:::matchLengths(3:7, len = 3, padDir = 'right')
# padded with zeros on the right
soundgen:::matchLengths(3:7, len = 10, padDir = 'right')
</code></pre>

<hr>
<h2 id='matchPars'>Match soundgen pars (experimental)</h2><span id='topic+matchPars'></span>

<h3>Description</h3>

<p>Attempts to find settings for <code><a href="#topic+soundgen">soundgen</a></code> that will reproduce an
existing sound. The principle is to mutate control parameters, trying to
improve fit to target. The currently implemented optimization algorithm is
simple hill climbing. Disclaimer: this function is experimental and may or
may not work for particular tasks. It is intended as a supplement to - not
replacement of - manual optimization. See vignette('sound_generation',
package = 'soundgen') for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchPars(
  target,
  samplingRate = NULL,
  pars = NULL,
  init = NULL,
  probMutation = 0.25,
  stepVariance = 0.1,
  maxIter = 50,
  minExpectedDelta = 0.001,
  compareSoundsPars = list(),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matchPars_+3A_target">target</code></td>
<td>
<p>the sound we want to reproduce using soundgen: path to a .wav
file or numeric vector</p>
</td></tr>
<tr><td><code id="matchPars_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>target</code> (only needed if target is
a numeric vector, rather than a .wav file)</p>
</td></tr>
<tr><td><code id="matchPars_+3A_pars">pars</code></td>
<td>
<p>arguments to <code><a href="#topic+soundgen">soundgen</a></code> that we are attempting to
optimize</p>
</td></tr>
<tr><td><code id="matchPars_+3A_init">init</code></td>
<td>
<p>a list of initial values for the optimized parameters <code>pars</code>
and the values of other arguments to soundgen that are fixed at non-default
values (if any)</p>
</td></tr>
<tr><td><code id="matchPars_+3A_probmutation">probMutation</code></td>
<td>
<p>the probability of a parameter mutating per iteration</p>
</td></tr>
<tr><td><code id="matchPars_+3A_stepvariance">stepVariance</code></td>
<td>
<p>scale factor for calculating the size of mutations</p>
</td></tr>
<tr><td><code id="matchPars_+3A_maxiter">maxIter</code></td>
<td>
<p>maximum number of mutated sounds produced without improving
the fit to target</p>
</td></tr>
<tr><td><code id="matchPars_+3A_minexpecteddelta">minExpectedDelta</code></td>
<td>
<p>minimum improvement in fit to target required to
accept the new sound candidate</p>
</td></tr>
<tr><td><code id="matchPars_+3A_comparesoundspars">compareSoundsPars</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="#topic+compareSounds">compareSounds</a></code></p>
</td></tr>
<tr><td><code id="matchPars_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, plays back the accepted candidate at each iteration
and reports the outcome</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of length 2: <code>$history</code> contains the tried
parameter values together with their fit to target (<code>$history$sim</code>),
and <code>$pars</code> contains a list of the final - hopefully the best -
parameter settings.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
target = soundgen(sylLen = 600, pitch = c(300, 200),
                  rolloff = -15, play = TRUE, plot = TRUE)
# we hope to reproduce this sound

# Match pars based on acoustic analysis alone, without any optimization.
# This *MAY* match temporal structure, pitch, and stationary formants
m1 = matchPars(target = target,
               samplingRate = 16000,
               maxIter = 0,  # no optimization, only acoustic analysis
               verbose = TRUE)
cand1 = do.call(soundgen, c(m1$pars, list(
  temperature = 0.001, play = TRUE, plot = TRUE)))

# Try to improve the match by optimizing rolloff
# (this may take a few minutes to run, and the results may vary)
m2 = matchPars(target = target,
               samplingRate = 16000,
               pars = 'rolloff',
               maxIter = 100,
               verbose = TRUE)
# rolloff should be moving from default (-9) to target (-15):
sapply(m2$history, function(x) x$pars$rolloff)
cand2 = do.call(soundgen, c(m2$pars, list(play = TRUE, plot = TRUE)))

## End(Not run)
</code></pre>

<hr>
<h2 id='medianSmoother'>Median smoothing</h2><span id='topic+medianSmoother'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medianSmoother(df, smoothing_ww, smoothingThres, inviolable = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="medianSmoother_+3A_df">df</code></td>
<td>
<p>dataframe (each column is processed separately, so multiple
contours can be fed into this function at once to speed things up)</p>
</td></tr>
<tr><td><code id="medianSmoother_+3A_smoothing_ww">smoothing_ww</code></td>
<td>
<p>width of smoothing window (points)</p>
</td></tr>
<tr><td><code id="medianSmoother_+3A_smoothingthres">smoothingThres</code></td>
<td>
<p>tolerated deviance from moving median (semitones)</p>
</td></tr>
<tr><td><code id="medianSmoother_+3A_inviolable">inviolable</code></td>
<td>
<p>a vector of indices of the rows of df that should not be
modified (meant for manual pitch values)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for smoothing pitch contours or other contours. Only
outliers are modified, so it's not like smoothing with a kernel. NB: the
expected input is pitch, so deviance is calculated on a log-scale.
</p>


<h3>Value</h3>

<p>Returns a dataframe of the same dimensions as df.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = data.frame(a = rnorm(40, mean = 100, sd = 20),
                b = rnorm(40, mean = 100, sd = 10))
df1 = soundgen:::medianSmoother(df, smoothing_ww = 5,
      smoothingThres = 1, inviolable = 1:10)
plot(df[, 2], type='b')
lines(df1[, 2], type='b', col='blue', pch=3)
</code></pre>

<hr>
<h2 id='Mode'>Modified mode</h2><span id='topic+Mode'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mode(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Mode_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for spectral (~BaNa) pitch tracker. NOT quite the
same as simply mode(x).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::Mode(c(1, 2, 3))  # if every element is unique, return the smallest
soundgen:::Mode(c(1, 2, 2, 3))
</code></pre>

<hr>
<h2 id='modulationSpectrum'>Modulation spectrum</h2><span id='topic+modulationSpectrum'></span>

<h3>Description</h3>

<p>Produces a modulation spectrum of waveform(s) or audio file(s). It begins
with some spectrogram-like time-frequency representation and analyzes the
modulation of the envelope in each frequency band. if <code>specSource =
'audSpec'</code>, the sound is passed through a bank of bandpass filters with
<code><a href="#topic+audSpectrogram">audSpectrogram</a></code>. If <code>specSource = 'STFT'</code>, we begin with an
ordinary spectrogram produced with a Short-Time Fourier Transform. If
<code>msType = '2D'</code>, the modulation spectrum is a 2D Fourier transform of
the spectrogram-like representation, with temporal modulation along the X
axis and spectral modulation along the Y axis. A good visual analogy is
decomposing the spectrogram into a sum of ripples of various frequencies and
directions. If <code>msType = '1D'</code>, the modulation spectrum is a matrix
containing 1D Fourier transforms of each frequency band in the spectrogram,
so the result again has modulation frequencies along the X axis, but the Y
axis now shows the frequency of each analyzed band. Roughness is calculated
as the proportion of the modulation spectrum within <code>roughRange</code> of
temporal modulation frequencies or some weighted version thereof. The
frequency of amplitude modulation (amMsFreq, Hz) is calculated as the highest
peak in the smoothed AM function, and its purity (amMsPurity, dB) as the
ratio of this peak to the median AM over <code>amRange</code>. For relatively short
and steady sounds, set <code>amRes = NULL</code> and analyze the entire sound. For
longer sounds and when roughness or AM vary over time, set <code>amRes</code> to
get multiple measurements over time (see examples). For multiple inputs, such
as a list of waveforms or path to a folder with audio files, the ensemble of
modulation spectra can be interpolated to the same spectral and temporal
resolution and averaged (if <code>averageMS = TRUE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modulationSpectrum(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  msType = c("1D", "2D")[2],
  specSource = c("STFT", "audSpec")[1],
  windowLength = 15,
  step = 1,
  wn = "hanning",
  zp = 0,
  audSpec_pars = list(filterType = "butterworth", nFilters = 32, bandwidth = 1/24, yScale
    = "bark", dynamicRange = 120),
  amRes = 5,
  maxDur = 5,
  specMethod = c("spec", "meanspec")[2],
  logSpec = FALSE,
  logMPS = FALSE,
  power = 1,
  normalize = TRUE,
  roughRange = c(30, 150),
  roughMean = NULL,
  roughSD = NULL,
  roughMinFreq = 1,
  amRange = c(10, 200),
  returnMS = TRUE,
  returnComplex = FALSE,
  summaryFun = c("mean", "median", "sd"),
  averageMS = FALSE,
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  logWarpX = NULL,
  logWarpY = NULL,
  quantiles = c(0.5, 0.8, 0.9),
  kernelSize = 5,
  kernelSD = 0.5,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  main = NULL,
  xlab = "Hz",
  ylab = NULL,
  xlim = NULL,
  ylim = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modulationSpectrum_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_from">from</code>, <code id="modulationSpectrum_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_mstype">msType</code></td>
<td>
<p>'2D' = two-dimensional Fourier transform of a spectrogram; '1D'
= separately calculated spectrum of each frequency band</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_specsource">specSource</code></td>
<td>
<p>'STFT' = Short-Time Fourier Transform; 'audSpec' = a bank
of bandpass filters (see <code><a href="#topic+audSpectrogram">audSpectrogram</a></code>)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_windowlength">windowLength</code>, <code id="modulationSpectrum_+3A_step">step</code>, <code id="modulationSpectrum_+3A_wn">wn</code>, <code id="modulationSpectrum_+3A_zp">zp</code></td>
<td>
<p>parameters for extracting a spectrogram if
<code>specType = 'STFT'</code>. Window length and step are specified in ms (see
<code><a href="#topic+spectrogram">spectrogram</a></code>). If <code>specType = 'audSpec'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_audspec_pars">audSpec_pars</code></td>
<td>
<p>parameters for extracting an auditory spectrogram if
<code>specType = 'audSpec'</code>. If <code>specType = 'STFT'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_amres">amRes</code></td>
<td>
<p>target resolution of amplitude modulation, Hz. If <code>NULL</code>,
the entire sound is analyzed at once, resulting in a single roughness value
(unless it is longer than <code>maxDur</code>, in which case it is analyzed in
chunks <code>maxDur</code> s long). If <code>amRes</code> is set, roughness is
calculated for windows <code>~1000/amRes</code> ms long (but at least 3 STFT
frames). <code>amRes</code> also affects the amount of smoothing when calculating
<code>amMsFreq</code> and <code>amMsPurity</code></p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_maxdur">maxDur</code></td>
<td>
<p>sounds longer than <code>maxDur</code> s are split into fragments,
and the modulation spectra of all fragments are averaged</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_specmethod">specMethod</code></td>
<td>
<p>the function to call when calculating the spectrum of each
frequency band (only used when <code>msType = '1D'</code>); 'meanspec' is faster
and less noisy, whereas 'spec' produces higher resolution</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, the spectrogram is log-transformed prior to taking 2D
FFT</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_logmps">logMPS</code></td>
<td>
<p>if TRUE, the modulation spectrum is log-transformed prior to
calculating roughness</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_power">power</code></td>
<td>
<p>raise modulation spectrum to this power (eg power = 2 for ^2, or
&quot;power spectrum&quot;)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, the modulation spectrum of each analyzed fragment
<code>maxDur</code> in duration is separately normalized to have max = 1</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_roughrange">roughRange</code></td>
<td>
<p>the range of temporal modulation frequencies that
constitute the &quot;roughness&quot; zone, Hz</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_roughmean">roughMean</code>, <code id="modulationSpectrum_+3A_roughsd">roughSD</code></td>
<td>
<p>the mean (Hz) and standard deviation (semitones) of
a lognormal distribution used to weight roughness estimates. If either is
null, roughness is calculated simply as the proportion of spectrum within
<code>roughRange</code>. If both <code>roughMean</code> and <code>roughRange</code> are
defined, weights outside <code>roughRange</code> are set to 0; a very large SD (a
flat weighting function) gives the same result as just <code>roughRange</code>
without any weighting (see examples)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_roughminfreq">roughMinFreq</code></td>
<td>
<p>frequencies below roughMinFreq (Hz) are ignored when
calculating roughness (ie the estimated roughness increases if we disregard
very low-frequency modulation, which is often strong)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_amrange">amRange</code></td>
<td>
<p>the range of temporal modulation frequencies that we are
interested in as &quot;amplitude modulation&quot; (AM), Hz</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_returnms">returnMS</code></td>
<td>
<p>if FALSE, only roughness is returned (much faster). Careful
with exporting the modulation spectra of a lot of sounds at once as this
requires a lot of RAM</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_returncomplex">returnComplex</code></td>
<td>
<p>if TRUE, returns a complex modulation spectrum (without
normalization and warping)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic,
eg &quot;c('mean', 'sd')&quot;; user-defined functions are fine (see examples); NAs
are omitted automatically for mean/median/sd/min/max/range/sum, otherwise
take care of NAs yourself</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_averagems">averageMS</code></td>
<td>
<p>if TRUE, the modulation spectra of all inputs are averaged
into a single output; if FALSE, a separate MS is returned for each input</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the modulation spectrum of each sound (see
<code><a href="#topic+plotMS">plotMS</a></code>)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_saveplots">savePlots</code></td>
<td>
<p>if a valid path is specified, a plot is saved in this folder
(defaults to NA)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_logwarpx">logWarpX</code>, <code id="modulationSpectrum_+3A_logwarpy">logWarpY</code></td>
<td>
<p>numeric vector of length 2: c(sigma, base) of
pseudolog-warping the modulation spectrum, as in function
pseudo_log_trans() from the &quot;scales&quot; package</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_quantiles">quantiles</code></td>
<td>
<p>labeled contour values, % (e.g., &quot;50&quot; marks regions that
contain 50% of the sum total of the entire modulation spectrum)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_kernelsize">kernelSize</code></td>
<td>
<p>the size of Gaussian kernel used for smoothing (1 = no
smoothing)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_kernelsd">kernelSD</code></td>
<td>
<p>the SD of Gaussian kernel used for smoothing, relative to its
size</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_xlab">xlab</code>, <code id="modulationSpectrum_+3A_ylab">ylab</code>, <code id="modulationSpectrum_+3A_main">main</code>, <code id="modulationSpectrum_+3A_xlim">xlim</code>, <code id="modulationSpectrum_+3A_ylim">ylim</code></td>
<td>
<p>graphical parameters</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_width">width</code>, <code id="modulationSpectrum_+3A_height">height</code>, <code id="modulationSpectrum_+3A_units">units</code>, <code id="modulationSpectrum_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
<tr><td><code id="modulationSpectrum_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed on to <code>filled.contour.mod</code>
and <code><a href="graphics.html#topic+contour">contour</a></code> (see <code><a href="#topic+spectrogram">spectrogram</a></code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the following components:
</p>

<ul>
<li> <p><code>$original</code> modulation spectrum prior to blurring and log-warping,
but after squaring if <code>power = TRUE</code>, a matrix of nonnegative values.
Colnames are temporal modulation frequencies (Hz). Rownames are spectral
modulation frequencies (cycles/kHz) if <code>msType = '2D'</code> and frequencies
of filters or spectrograms bands (kHz) if <code>msType = '1D'</code>.
</p>
</li>
<li> <p><code>$original_list</code> a list of modulation spectra for each analyzed
fragment (is <code>amRes</code> is not NULL)
</p>
</li>
<li> <p><code>$processed</code> modulation spectrum after blurring and log-warping
</p>
</li>
<li> <p><code>$complex</code> untransformed complex modulation spectrum (returned
only if returnComplex = TRUE)
</p>
</li>
<li> <p><code>$roughness</code> proportion of the modulation spectrum within
<code>roughRange</code> of temporal modulation frequencies or a weighted average
thereof if <code>roughMean</code> and <code>roughSD</code> are defined, % - a vector if
amRes is numeric and the sound is long enough, otherwise a single number
</p>
</li>
<li> <p><code>$roughness_list</code> a list containing frequencies, amplitudes, and
roughness values for each analyzed frequency band (1D) or frequency
modulation band (2D)
</p>
</li>
<li> <p><code>$amMsFreq</code> frequency of the highest peak, within <code>amRange</code>, of
the folded AM function (average AM across all FM bins for both negative and
positive AM frequencies), where a peak is a local maximum over <code>amRes</code>
Hz. Like <code>roughness</code>, <code>amMsFreq</code> and <code>amMsPurity</code> can be single
numbers or vectors, depending on whether the sound is analyzed as a whole or
in chunks
</p>
</li>
<li> <p><code>$amMsPurity</code> ratio of the peak at amMsFreq to the median AM over
<code>amRange</code>, dB
</p>
</li>
<li> <p><code>$summary</code> dataframe with summaries of roughness, amMsFreq, and
amMsPurity
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p> Singh, N. C., &amp; Theunissen, F. E. (2003). Modulation spectra of
natural sounds and ethological theories of auditory processing. The Journal
of the Acoustical Society of America, 114(6), 3394-3411.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plotMS">plotMS</a></code> <code><a href="#topic+spectrogram">spectrogram</a></code>
<code><a href="#topic+audSpectrogram">audSpectrogram</a></code> <code><a href="#topic+analyze">analyze</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># White noise
ms = modulationSpectrum(rnorm(16000), samplingRate = 16000,
  logSpec = FALSE, power = TRUE,
  amRes = NULL)  # analyze the entire sound, giving a single roughness value
str(ms)

# Harmonic sound
s = soundgen(pitch = 440, amFreq = 100, amDep = 50)
ms = modulationSpectrum(s, samplingRate = 16000, amRes = NULL)
ms[c('roughness', 'amMsFreq', 'amMsPurity')]  # a single value for each
ms1 = modulationSpectrum(s, samplingRate = 16000, amRes = 5)
ms1[c('roughness', 'amMsFreq', 'amMsPurity')]
# measured over time (low values of amRes mean more precision, so we analyze
# longer segments and get fewer values per sound)

# Embellish
ms = modulationSpectrum(s, samplingRate = 16000, logMPS = TRUE,
  xlab = 'Temporal modulation, Hz', ylab = 'Spectral modulation, 1/kHz',
  colorTheme = 'matlab', main = 'Modulation spectrum', lty = 3)

# 1D instead of 2D
modulationSpectrum(s, 16000, msType = '1D', quantiles = NULL,
  colorTheme = 'matlab')

## Not run: 
# A long sound with varying AM and a bit of chaos at the end
s_long = soundgen(sylLen = 3500, pitch = c(250, 320, 280),
                  amFreq = c(30, 55), amDep = c(20, 60, 40),
                  jitterDep = c(0, 0, 2))
playme(s_long)
ms = modulationSpectrum(s_long, 16000)
# plot AM over time
plot(x = seq(1, 1500, length.out = length(ms$amMsFreq)), y = ms$amMsFreq,
     cex = 10^(ms$amMsPurity/20) * 10, xlab = 'Time, ms', ylab = 'AM frequency, Hz')
# plot roughness over time
spectrogram(s_long, 16000, ylim = c(0, 4),
  extraContour = list(ms$roughness / max(ms$roughness) * 4000, col = 'blue'))

# As with spectrograms, there is a tradeoff in time-frequency resolution
s = soundgen(pitch = 500, amFreq = 50, amDep = 100, sylLen = 500,
             samplingRate = 44100, plot = TRUE)
# playme(s, samplingRate = 44100)
ms = modulationSpectrum(s, samplingRate = 44100,
  windowLength = 50, step = 50, amRes = NULL)  # poor temporal resolution
ms = modulationSpectrum(s, samplingRate = 44100,
  windowLength = 5, step = 1, amRes = NULL)  # poor frequency resolution
ms = modulationSpectrum(s, samplingRate = 44100,
  windowLength = 15, step = 3, amRes = NULL)  # a reasonable compromise

# Start with an auditory spectrogram instead of STFT
modulationSpectrum(s, 44100, specSource = 'audSpec', xlim = c(-100, 100))
modulationSpectrum(s, 44100, specSource = 'audSpec',
  logWarpX = c(10, 2), xlim = c(-500, 500),
  audSpec_pars = list(nFilters = 32, filterType = 'gammatone', bandwidth = NULL))

# customize the plot
ms = modulationSpectrum(s, samplingRate = 44100,
  windowLength = 15, overlap = 80, amRes = NULL,
  kernelSize = 17,  # more smoothing
  xlim = c(-70, 70), ylim = c(0, 4),  # zoom in on the central region
  quantiles = c(.25, .5, .8),  # customize contour lines
  col = rev(rainbow(100)),  # alternative palette
  logWarpX = c(10, 2),  # pseudo-log transform
  power = 2)                   # ^2
# Note the peaks at FM = 2/kHz (from "pitch = 500") and AM = 50 Hz (from
# "amFreq = 50")

# Input can be a wav/mp3 file
ms = modulationSpectrum('~/Downloads/temp/16002_Faking_It_Large_clear.wav')

# Input can be path to folder with audio files. Each file is processed
# separately, and the output can contain an MS per file...
ms1 = modulationSpectrum('~/Downloads/temp', kernelSize = 11,
                         plot = FALSE, averageMS = FALSE)
ms1$summary
names(ms1$original)  # a separate MS per file
# ...or a single MS can be calculated:
ms2 = modulationSpectrum('~/Downloads/temp', kernelSize = 11,
                         plot = FALSE, averageMS = TRUE)
plotMS(ms2$original)
ms2$summary

# Input can also be a list of waveforms (numeric vectors)
ss = vector('list', 10)
for (i in seq_along(ss)) {
  ss[[i]] = soundgen(sylLen = runif(1, 100, 1000), temperature = .4,
    pitch = runif(3, 400, 600))
}
# lapply(ss, playme)
# MS of the first sound
ms1 = modulationSpectrum(ss[[1]], samplingRate = 16000, scale = 1)
# average MS of all 10 sounds
ms2 = modulationSpectrum(ss, samplingRate = 16000, scale = 1, averageMS = TRUE, plot = FALSE)
plotMS(ms2$original)

# A sound with ~3 syllables per second and only downsweeps in F0 contour
s = soundgen(nSyl = 8, sylLen = 200, pauseLen = 100, pitch = c(300, 200))
# playme(s)
ms = modulationSpectrum(s, samplingRate = 16000, maxDur = .5,
  xlim = c(-25, 25), colorTheme = 'seewave',
  power = 2)
# note the asymmetry b/c of downsweeps

# "power = 2" returns squared modulation spectrum - note that this affects
# the roughness measure!
ms$roughness
# compare:
modulationSpectrum(s, samplingRate = 16000, maxDur = .5,
  xlim = c(-25, 25), colorTheme = 'seewave',
  power = 1)$roughness  # much higher roughness

# Plotting with or without log-warping the modulation spectrum:
ms = modulationSpectrum(soundgen(), samplingRate = 16000, plot = TRUE)
ms = modulationSpectrum(soundgen(), samplingRate = 16000,
  logWarpX = c(2, 2), plot = TRUE)

# logWarp and kernelSize have no effect on roughness
# because it is calculated before these transforms:
modulationSpectrum(s, samplingRate = 16000, logWarpX = c(1, 10))$roughness
modulationSpectrum(s, samplingRate = 16000, logWarpX = NA)$roughness
modulationSpectrum(s, samplingRate = 16000, kernelSize = 17)$roughness

# Log-transform the spectrogram prior to 2D FFT (affects roughness):
modulationSpectrum(s, samplingRate = 16000, logSpec = FALSE)$roughness
modulationSpectrum(s, samplingRate = 16000, logSpec = TRUE)$roughness

# Use a lognormal weighting function to calculate roughness
# (instead of just % in roughRange)
modulationSpectrum(s, 16000, roughRange = NULL,
  roughMean = 75, roughSD = 3)$roughness
modulationSpectrum(s, 16000, roughRange = NULL,
  roughMean = 100, roughSD = 12)$roughness
# truncate weights outside roughRange
modulationSpectrum(s, 16000, roughRange = c(30, 150),
  roughMean = 100, roughSD = 1000)$roughness  # very large SD
modulationSpectrum(s, 16000, roughRange = c(30, 150),
  roughMean = NULL)$roughness  # same as above b/c SD --&gt; Inf

# Complex modulation spectrum with phase preserved
ms = modulationSpectrum(soundgen(), samplingRate = 16000,
                        returnComplex = TRUE)
plotMS(abs(ms$complex))  # note the symmetry
# compare:
plotMS(ms$original)

## End(Not run)
</code></pre>

<hr>
<h2 id='modulationSpectrumFragment'>Modulation spectrum per fragment</h2><span id='topic+modulationSpectrumFragment'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modulationSpectrumFragment(
  sound,
  samplingRate,
  specSource = "STFT",
  audSpec_pars = NULL,
  msType = c("2D", "1D")[1],
  windowLength,
  windowLength_points,
  step,
  step_points,
  lowestFreq,
  wn = "hanning",
  zp = 0,
  specMethod = c("spec", "meanspec")[2],
  logSpec = FALSE,
  logMPS = FALSE,
  power = 1,
  normalize = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modulationSpectrumFragment_+3A_sound">sound</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_specsource">specSource</code></td>
<td>
<p>'STFT' = Short-Time Fourier Transform; 'audSpec' = a bank
of bandpass filters (see <code><a href="#topic+audSpectrogram">audSpectrogram</a></code>)</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_audspec_pars">audSpec_pars</code></td>
<td>
<p>parameters for extracting an auditory spectrogram if
<code>specType = 'audSpec'</code>. If <code>specType = 'STFT'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_mstype">msType</code></td>
<td>
<p>'2D' = two-dimensional Fourier transform of a spectrogram; '1D'
= separately calculated spectrum of each frequency band</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_windowlength">windowLength</code>, <code id="modulationSpectrumFragment_+3A_step">step</code>, <code id="modulationSpectrumFragment_+3A_wn">wn</code>, <code id="modulationSpectrumFragment_+3A_zp">zp</code></td>
<td>
<p>parameters for extracting a spectrogram if
<code>specType = 'STFT'</code>. Window length and step are specified in ms (see
<code><a href="#topic+spectrogram">spectrogram</a></code>). If <code>specType = 'audSpec'</code>, these settings
have no effect</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_specmethod">specMethod</code></td>
<td>
<p>the function to call when calculating the spectrum of each
frequency band (only used when <code>msType = '1D'</code>); 'meanspec' is faster
and less noisy, whereas 'spec' produces higher resolution</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, the spectrogram is log-transformed prior to taking 2D
FFT</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_logmps">logMPS</code></td>
<td>
<p>if TRUE, the modulation spectrum is log-transformed prior to
calculating roughness</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_power">power</code></td>
<td>
<p>raise modulation spectrum to this power (eg power = 2 for ^2, or
&quot;power spectrum&quot;)</p>
</td></tr>
<tr><td><code id="modulationSpectrumFragment_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, the modulation spectrum of each analyzed fragment
<code>maxDur</code> in duration is separately normalized to have max = 1</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(amFreq = 25, amDep = 100)
ms = soundgen:::modulationSpectrumFragment(s, 16000,
  windowLength = 50, windowLength_points = .05 * 16000,
  step = 5, step_points = .005 * 16000)
plotMS(ms$ms_half)
image(as.numeric(colnames(ms$ms_half)), as.numeric(rownames(ms$ms_half)),
      t(log(ms$ms_half)))
</code></pre>

<hr>
<h2 id='morph'>Morph sounds</h2><span id='topic+morph'></span>

<h3>Description</h3>

<p>Takes two formulas for synthesizing two target sounds with
<code><a href="#topic+soundgen">soundgen</a></code> and produces a number of intermediate forms (morphs),
attempting to go from one target sound to the other in a specified number of
equal steps. Normally you will want to set <code>temperature</code> very low; the
<code>tempEffects</code> argument is not supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>morph(
  formula1,
  formula2,
  nMorphs,
  playMorphs = TRUE,
  savePath = NA,
  samplingRate = 16000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="morph_+3A_formula1">formula1</code>, <code id="morph_+3A_formula2">formula2</code></td>
<td>
<p>lists of parameters for calling
<code><a href="#topic+soundgen">soundgen</a></code> that produce the two target sounds between which
morphing will occur. Character strings containing the full call to soundgen
are also accepted (see examples)</p>
</td></tr>
<tr><td><code id="morph_+3A_nmorphs">nMorphs</code></td>
<td>
<p>the number of morphs to produce, including target sounds</p>
</td></tr>
<tr><td><code id="morph_+3A_playmorphs">playMorphs</code></td>
<td>
<p>if TRUE, the morphs will be played</p>
</td></tr>
<tr><td><code id="morph_+3A_savepath">savePath</code></td>
<td>
<p>if it is the path to an existing directory, morphs will be
saved there as individual .wav files (defaults to NA)</p>
</td></tr>
<tr><td><code id="morph_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of output, Hz. NB: overrides the values in
<code>formula1</code> and <code>formula2</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two sublists (<code>$formulas</code> and <code>$sounds</code>), each
of length <code>nMorphs</code>. For ex., the formula for the second hybrid is
<code>m$formulas[[2]]</code>, and the waveform is <code>m$sounds[[2]]</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+soundgen">soundgen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# write two formulas or copy-paste them from soundgen_app() or presets:
playback = c(TRUE, FALSE)[1]
# [a] to barking
m = morph(formula1 = list(repeatBout = 2),
          # equivalently: formula1 = 'soundgen(repeatBout = 2)',
          formula2 = presets$Misc$Dog_bark,
          nMorphs = 5, playMorphs = playback)
 # use $formulas to access formulas for each morph, $sounds for waveforms
 # m$formulas[[4]]
 # playme(m$sounds[[3]])

# morph intonation and vowel quality
m = morph(
  'soundgen(pitch = c(300, 250, 400),
            formants = c(350, 2900, 3600, 4700))',
  'soundgen(pitch = c(300, 700, 500, 300),
            formants = c(800, 1250, 3100, 4500))',
  nMorphs = 5, playMorphs = playback
)

# from a grunt of disgust to a moan of pleasure
m = morph(
  formula1 = 'soundgen(sylLen = 180, pitch = c(160, 160, 120), rolloff = -12,
    nonlinBalance = 70, subDep = 15, jitterDep = 2,
    formants = c(550, 1200, 2100, 4300, 4700, 6500, 7300),
    noise = data.frame(time = c(0, 180, 270), value = c(-25, -25, -40)),
    rolloffNoise = 0)',
  formula2 = 'soundgen(sylLen = 320, pitch = c(340, 330, 300),
    rolloff = c(-18, -16, -30), ampl = c(0, -10), formants = c(950, 1700, 3700),
    noise = data.frame(time = c(0, 300, 440), value = c(-35, -25, -65)),
    mouth = c(.4, .5), rolloffNoise = -5, attackLen = 30)',
  nMorphs = 8, playMorphs = playback
)

# from scream_010 to moan_515b
# (see online demos at http://cogsci.se/soundgen/humans/humans.html)
m = morph(
  formula1 = "soundgen(
    sylLen = 490,
    pitch = list(time = c(0, 80, 250, 370, 490),
    value = c(1000, 2900, 3200, 2900, 1000)),
    rolloff = c(-5, 0, -25), rolloffKHz = 0,
    temperature = 0.001,
    jitterDep = c(.5, 1, 0), shimmerDep = c(5, 15, 0),
    formants = c(1100, 2300, 3100, 4000, 5300, 6200),
    mouth = c(.3, .5, .6, .5, .3))",
  formula2 = "soundgen(sylLen = 520,
    pitch = c(300, 310, 300),
    ampl = c(0, -30),
    temperature = 0.001, rolloff = c(-18, -25),
    jitterDep = .05, shimmerDep = 2,
    formants = list(f1 = c(700, 900),
      f2 = c(1600, 1400),
      f3 = c(3600, 3500), f4 = c(4300, 4200)),
    mouth = c(.5, .3),
    noise = data.frame(time = c(0, 400, 660),
    value = c(-20, -10, -60)),
    rolloffNoise = c(-5, -15))",
 nMorphs = 5, playMorphs = playback
)

## End(Not run)
</code></pre>

<hr>
<h2 id='morphDF'>Morph dataframes</h2><span id='topic+morphDF'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>morphDF(
  a,
  b,
  nMorphs = 5,
  method = c("smooth", "perAnchor")[2],
  lenSmooth = 50,
  matchIdx = NULL,
  plot = F,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="morphDF_+3A_a">a</code>, <code id="morphDF_+3A_b">b</code></td>
<td>
<p>dataframes to morph</p>
</td></tr>
<tr><td><code id="morphDF_+3A_nmorphs">nMorphs</code></td>
<td>
<p>length of morphing sequence</p>
</td></tr>
<tr><td><code id="morphDF_+3A_method">method</code></td>
<td>
<p>morphing method. 'smooth' equalizes contour lengths and takes a
weighted mean. 'perAnchor' is a more sophisticated algorithm that attempts
to match individual anchors</p>
</td></tr>
<tr><td><code id="morphDF_+3A_lensmooth">lenSmooth</code></td>
<td>
<p>the length of curves generated from anchors prior to
averaging (only applicable if method is 'smooth')</p>
</td></tr>
<tr><td><code id="morphDF_+3A_matchidx">matchIdx</code></td>
<td>
<p>manual override of anchor matching: if you have a better idea
of which anchors should morph into each other, specify</p>
</td></tr>
<tr><td><code id="morphDF_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the morphing sequence of anchors</p>
</td></tr>
<tr><td><code id="morphDF_+3A_...">...</code></td>
<td>
<p>other graphical pars passed on to <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Morphs two dataframes of anchors, with two columns and at least two rows in
each.
</p>


<h3>Value</h3>

<p>A list of length nMorphs containing anchor dataframes for morphing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = data.frame(time=c(0, .2, .9, 1), value=c(100, 110, 180, 110))
b = data.frame(time=c(0, .3, .5, .8, 1), value=c(300, 220, 190, 400, 350))
plot (a, type = 'b', ylim = c(0, 500))
points (b, type = 'b', col = 'blue')
m = soundgen:::morphDF(a, b, nMorphs = 15, method = 'smooth', plot = TRUE)
m = soundgen:::morphDF(a, b, nMorphs = 15, method = 'perAnchor', plot = TRUE)

m = soundgen:::morphDF(a = data.frame(time = c(0, 1), freq = c(700, 700)),
                       b = data.frame(time = c(0, 1), freq = c(400, 600)),
                       nMorphs = 5, method = 'perAnchor', plot = TRUE)
m = soundgen:::morphDF(a = data.frame(time = c(-30, 120, 350), value = c(-120, 10, -120)),
                       b = data.frame(time = c(50, 500), value = c(0, -30)),
                       nMorphs = 10, method = 'perAnchor', plot = TRUE)
m = soundgen:::morphDF(a = data.frame(time = c(-50, 1214), value = c(-50, -70)),
                       b = data.frame(time = c(0, 49, 256), value = c(-120, 10, -120)),
                       nMorphs = 8, method = 'perAnchor', plot = TRUE)
</code></pre>

<hr>
<h2 id='morphFormants'>Morph formants</h2><span id='topic+morphFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>morphFormants(f1, f2, nMorphs = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="morphFormants_+3A_f1">f1</code>, <code id="morphFormants_+3A_f2">f2</code></td>
<td>
<p>dataframes specifying one formant of the two target sounds
(different numbers of rows are ok)</p>
</td></tr>
<tr><td><code id="morphFormants_+3A_nmorphs">nMorphs</code></td>
<td>
<p>length of morphing sequence</p>
</td></tr>
</table>

<hr>
<h2 id='morphList'>Morph lists</h2><span id='topic+morphList'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>morphList(l1, l2, nMorphs = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="morphList_+3A_l1">l1</code>, <code id="morphList_+3A_l2">l2</code></td>
<td>
<p>lists of formants (various lengths are ok)</p>
</td></tr>
<tr><td><code id="morphList_+3A_nmorphs">nMorphs</code></td>
<td>
<p>length of morphing sequence</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length nMorphs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>l1 = list(f1 = data.frame(time = c(0, .5, 1),
                          freq = c(700, 900, 1200),
                          amp = c(30), width = c(80)),
          f2 = data.frame(time = c(0),
                          freq = c(900),
                          amp = c(30),
                          width = c(120)),
          f3 = data.frame(time = c(0),
                          freq = c(1500),
                          amp = c(20),
                          width = c(150)))
l2 = list(f1 = data.frame(time = c(0),
                          freq = c(400),
                          amp = c(40),
                          width = c(120)),
          f2 = data.frame(time = c(0, 1),
                          freq = c(1500, 2000),
                          amp = c(30),
                          width = c(150)))
ml = soundgen:::morphList(l1, l2, 4)
</code></pre>

<hr>
<h2 id='msToSpec'>Modulation spectrum to spectrogram</h2><span id='topic+msToSpec'></span>

<h3>Description</h3>

<p>Takes a complex MS and transforms it to a complex spectrogram with proper row
(frequency) and column (time) labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msToSpec(ms, windowLength = NULL, step = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="msToSpec_+3A_ms">ms</code></td>
<td>
<p>target modulation spectrum (matrix of complex numbers)</p>
</td></tr>
<tr><td><code id="msToSpec_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="msToSpec_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a spectrogram - a numeric matrix of complex numbers of
the same dimensions as ms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 250, amFreq = 25, amDep = 50,
             pitch = 250, samplingRate = 16000)
spec = spectrogram(s, samplingRate = 16000, windowLength = 25, step = 5)
ms = specToMS(spec)
plotMS(log(Mod(ms)), quantiles = NULL, col = soundgen:::jet.col(100))
spec_new = msToSpec(ms)
spectrogram(s, specManual = Mod(spec_new))
## Not run: 
# or plot manually
image(x = as.numeric(colnames(spec_new)), y = as.numeric(rownames(spec_new)),
      z = t(log(abs(spec_new))), xlab = 'Time, ms',
      ylab = 'Frequency, kHz')

## End(Not run)
</code></pre>

<hr>
<h2 id='na.trim'>Trim leading and trailing NAs</h2><span id='topic+na.trim'></span>

<h3>Description</h3>

<p>Internal soundgen function. Nearly 10 times faster than zoo::na.trim.
Slightly slower solution: a[!cumprod(is.na(a)) &amp;
rev(!cumprod(is.na(rev(a))))]. See
https://stackoverflow.com/questions/42759027/remove-leading-and-trailing-na
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na.trim(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.trim_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::na.trim(c(NA, NA, 1:10, NA, 21:25, NA))
</code></pre>

<hr>
<h2 id='naiveBayes'>Naive Bayes</h2><span id='topic+naiveBayes'></span>

<h3>Description</h3>

<p>An implementation of a Naive Bayes classifier adapted to autocorrelated time
series such as the type of nonlinear vocal phenomena in consecutive audio
frames. All predictors must be continuous, and the outcome must be
categorical. Cases with missing values are not deleted because the posterior
probabilities of each outcome class can be calculated from different
combinations of predictors on a case-by-case basis. Two optional
modifications of a standard Naive Bayes algorithm can be made: (1)
classifications can be &quot;clumped&quot; at the final stage, ensuring that every run
or &quot;epoch&quot; of a particular predicted class is at least <code>minLength</code> steps
long, and (2) priors can be continuously adapted based on the likelihood
function of the preceding <code>wlPrior</code> observations if <code>prior =
'dynamic'</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naiveBayes(
  formula,
  train,
  test = train,
  prior = c("flat", "static", "dynamic")[2],
  wlPrior = 3,
  wlClumper = NULL,
  runBack = TRUE,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="naiveBayes_+3A_formula">formula</code></td>
<td>
<p>model formula of the type outcome ~ predictor1 + predictor2 +
... (no interactions)</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_train">train</code></td>
<td>
<p>either the training dataframe or the output of
<code><a href="#topic+naiveBayes_train">naiveBayes_train</a></code>. This data is used to calculate
class-specific distributions of the predictors and prior class
probabilities</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_test">test</code></td>
<td>
<p>the test dataframe. This data is used to make predictions - that
is, outcome class probabilities given the values of predictors</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_prior">prior</code></td>
<td>
<p>&quot;flat&quot; = all classes are equally likely a prior, &quot;static&quot; = use
class probabilities in the training dataset, &quot;dynamic&quot; = update prior
probabilities from weighted likelihoods of <code>wlPrior</code> preceding
observations</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_wlprior">wlPrior</code></td>
<td>
<p>the length of a Gaussian window used for updating dynamic
priors</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_wlclumper">wlClumper</code></td>
<td>
<p>the minimum expected number of observations of the same
class before the class can change</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_runback">runBack</code></td>
<td>
<p>if TRUE, the dynamic prior is calculated both forward and
backward and averaged (only has an effect f <code>prior = 'dynamic'</code>)</p>
</td></tr>
<tr><td><code id="naiveBayes_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces diagnostic plots</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the <code>test</code> dataframe with new columns: &quot;pr&quot; = the
predicted class membership, &quot;[class]&quot; = posterior probabilities per class,
&quot;like_[class]&quot; = log-likelihoods, &quot;prior_[class]&quot; = log-priors,
&quot;priorF_[class]&quot; / &quot;priorB_[class]&quot; = forward / backward log-priors per
class.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(151)
## create some fake data
df = data.frame(group = rep(c(
    rep('A', 150), rep('B', 50), rep('A', 120),
    rep('A', 100), rep('B', 30), rep('A', 90)
  ), 3))
df$group = as.factor(df$group)
df$x1 = rnorm(nrow(df), mean = ifelse(df$group == 'A', 3, 6), sd = 2)
df$x2 = rnorm(nrow(df), mean = ifelse(df$group == 'A', 2, -1), sd = 2)
boxplot(x1 ~ group, df)
boxplot(x2 ~ group, df)

## train the classifier
mod_train = naiveBayes_train(group ~ x1 + x2, data = df)
mod_train

## test on new data generated by the same process
test = data.frame(group = rep(c(
  rep('A', 90), rep('B', 40), rep('A', 150),
  rep('B', 40), rep('A', 130), rep('B', 30)
), 2))
test$group = as.factor(test$group)
test$x1 = rnorm(nrow(test), mean = ifelse(test$group == 'A', 3, 6), sd = 2)
test$x2 = rnorm(nrow(test), mean = ifelse(test$group == 'A', 2, -1), sd = 2)

# flat priors (same prior probability for each class)
nb_flat = naiveBayes(group ~ x1 + x2, train = mod_train, test = test,
  prior = 'flat', plot = TRUE)
# same as passing 'train' directly to the model, w/o calling naiveBayes_train():
nb_flat = naiveBayes(group ~ x1 + x2, train = df, test = test, prior = 'flat')
table(nb_flat$group, nb_flat$pr)
mean(nb_flat$group == nb_flat$pr) # 84% correct

# static priors (use original class proportions as prior class probabilities)
nb_static = naiveBayes(group ~ x1 + x2, train = mod_train, test = test,
  prior = 'static', wlClumper = NULL, plot = TRUE)
table(nb_static$group, nb_static$pr)
mean(nb_static$group == nb_static$pr) # 87% correct

# specify custom static priors
mod_train2 = mod_train
mod_train$table
mod_train2$table = list(A = .1, B = .9)  # sum to 1
nb_static2 = naiveBayes(group ~ x1 + x2, train = mod_train2, test = test,
  prior = 'static', wlClumper = NULL, plot = TRUE)
mean(nb_static2$group == nb_static2$pr)  # 61% correct

# if we expect autocorrelation, ie class X is more likely a priori if the
# last few observations were also likely to be class X, we can use dynamic
# priors and/or clumper the predicted classes (the latter imposes strong
# constraints on the predictions, but may be worth it if the data is known to
# be strongly "clumpered", ie if we know classes occur in long'ish runs)
nb1 = naiveBayes(group ~ x1 + x2, train = mod_train, test = test,
  prior = 'dynamic', wlPrior = 10, plot = TRUE)
table(nb1$group, nb1$pr)
mean(nb1$group == nb1$pr) # 94% correct

nb2 = naiveBayes(group ~ x1 + x2, train = mod_train, test = test,
  prior = 'static', wlClumper = 10, plot = TRUE)
table(nb2$group, nb2$pr)
mean(nb2$group == nb2$pr) # 89% correct

nb3 = naiveBayes(group ~ x1 + x2, train = mod_train, test = test,
  prior = 'dynamic', wlPrior = 10, wlClumper = 10, plot = TRUE)
table(nb3$group, nb3$pr)
mean(nb3$group == nb3$pr) # 98% correct

# NAs in the data are not a problem
test1 = test
test1$x1[sample(1:nrow(test1), 100)] = NA
test1$x2[sample(1:nrow(test1), 10)] = NA
summary(test1)

nb4 = naiveBayes(group ~ x1 + x2, train = mod_train, test = test,
  prior = 'dynamic', wlPrior = 10, plot = TRUE)
table(nb4$group, nb4$pr)
mean(nb4$group == nb4$pr)  # still 94% correct
</code></pre>

<hr>
<h2 id='naiveBayes_dynamicPrior'>Naive Bayes dynamic prior</h2><span id='topic+naiveBayes_dynamicPrior'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naiveBayes_dynamicPrior(
  d,
  nObs = nrow(d),
  mod_train,
  wl,
  class_names,
  nClasses = length(class_names),
  like_names,
  prior_names,
  predictors,
  nPredictors = length(predictors)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="naiveBayes_dynamicPrior_+3A_d">d</code></td>
<td>
<p>dataframe containing the observations</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_nobs">nObs</code></td>
<td>
<p>the number of observations</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_mod_train">mod_train</code></td>
<td>
<p>the output of naiveBayes_train()</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_wl">wl</code></td>
<td>
<p>window length, points</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_class_names">class_names</code></td>
<td>
<p>names of outcome classes</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_nclasses">nClasses</code></td>
<td>
<p>the number of outcome classes</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_like_names">like_names</code></td>
<td>
<p>the names of variables holding likelihoods</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_prior_names">prior_names</code></td>
<td>
<p>the names of prior variables</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_predictors">predictors</code></td>
<td>
<p>the names of predictor variables</p>
</td></tr>
<tr><td><code id="naiveBayes_dynamicPrior_+3A_npredictors">nPredictors</code></td>
<td>
<p>the number of predicto variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Helper function called by <code><a href="#topic+naiveBayes">naiveBayes</a></code> to calculate dynamic
priors. Algorithm: average the likelihoods of wl preceding observations
weighted by a Gaussian function, so more recent observations have more
weight.
</p>

<hr>
<h2 id='naiveBayes_likelihood'>Naive Bayes likelihood</h2><span id='topic+naiveBayes_likelihood'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naiveBayes_likelihood(
  d,
  nObs = nrow(d),
  mod_train,
  class_names,
  nClasses = length(class_names),
  like_names,
  predictors,
  nPredictors = length(predictors)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="naiveBayes_likelihood_+3A_d">d</code></td>
<td>
<p>dataframe containing the observations</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_nobs">nObs</code></td>
<td>
<p>the number of observations</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_mod_train">mod_train</code></td>
<td>
<p>the output of naiveBayes_train()</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_class_names">class_names</code></td>
<td>
<p>names of outcome classes</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_nclasses">nClasses</code></td>
<td>
<p>the number of outcome classes</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_like_names">like_names</code></td>
<td>
<p>the names of variables holding likelihoods</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_predictors">predictors</code></td>
<td>
<p>the names of predictor variables</p>
</td></tr>
<tr><td><code id="naiveBayes_likelihood_+3A_npredictors">nPredictors</code></td>
<td>
<p>the number of predicto variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Helper function called by <code><a href="#topic+naiveBayes">naiveBayes</a></code> to calculate the
likelihood of each observation. Algorithm: for each predictor and class, the
likelihood is dnorm(observation, mean_per_class, sd_per_class). I tried
non-Gaussian probability distributions (Student's t to accommodate outliers),
but Gaussian actually seems to be more robust.
</p>

<hr>
<h2 id='naiveBayes_train'>Train a naive Bayes classifier</h2><span id='topic+naiveBayes_train'></span>

<h3>Description</h3>

<p>Returns conditional means and standard deviations per class as well as a
table with the global proportions of each class in the dataset. This is
mostly useful because the output can be passed on to <code><a href="#topic+naiveBayes">naiveBayes</a></code>
to save time if naiveBayes() is called in a loop with the same training
dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naiveBayes_train(formula, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="naiveBayes_train_+3A_formula">formula</code></td>
<td>
<p>outcome ~ predictor1 + predictor1 + ...</p>
</td></tr>
<tr><td><code id="naiveBayes_train_+3A_data">data</code></td>
<td>
<p>training dataset</p>
</td></tr>
</table>

<hr>
<h2 id='noiseRemoval'>Noise removal</h2><span id='topic+noiseRemoval'></span>

<h3>Description</h3>

<p>Removes noise by spectral substraction. If a recording is affected by a
steady noise with a relatively stable amplitude and spectrum (e.g.,
microphone hiss, crickets, MRI buzz, etc.), its spectrum can be simply
subtracted from the signal. Algorithm: STFT to produce a spectrogram, divide
by normalized noise spectrum, inverse STFT to reconstitute the signal. Most
of the work is done by <code><a href="#topic+addFormants">addFormants</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>noiseRemoval(
  x,
  samplingRate = NULL,
  scale = NULL,
  noise,
  dB = 6,
  specificity = 1,
  windowLength = 50,
  step = windowLength/2,
  dynamicRange = 120,
  normalize = c("max", "orig", "none")[2],
  reportEvery = NULL,
  cores = 1,
  play = FALSE,
  saveAudio = NULL,
  plot = FALSE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="noiseRemoval_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_noise">noise</code></td>
<td>
<p>a numeric vector of length two specifying the location of pure
noise in input audio (in s); a matrix representing pure noise as a spectrum
with frequency bins in rows; any input accepted by
<code><a href="#topic+spectrogram">spectrogram</a></code> if pure noise is found in a separate recording
(eg path to file, numeric vector, etc.)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_db">dB</code></td>
<td>
<p>if NULL (default), the spectral envelope is applied on the original
scale; otherwise, it is set to range from 1 to 10 ^ (dB / 20)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_specificity">specificity</code></td>
<td>
<p>a way to sharpen or blur the noise spectrum (we take noise
spectrum ^ specificity) : 1 = no change, &gt;1 = sharper (the loudest noise
frequencies are preferentially removed), &lt;1 = blurred (even quiet noise
frequencies are removed)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, scales input prior to FFT</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_saveaudio">saveAudio</code></td>
<td>
<p>path + filename for saving the output, e.g.
'~/Downloads/temp.wav'. If NULL = doesn't save</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_width">width</code>, <code id="noiseRemoval_+3A_height">height</code>, <code id="noiseRemoval_+3A_units">units</code>, <code id="noiseRemoval_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="noiseRemoval_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the denoised audio
</p>


<h3>See Also</h3>

<p><code><a href="#topic+addFormants">addFormants</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(noise = list(time = c(-100, 400), value = -20),
  formantsNoise = list(f1 = list(freq = 3000, width = 25)),
  addSilence = 50, temperature = .001, plot = TRUE)
# Option 1: use part of the recording as noise profile
s1 = noiseRemoval(s, samplingRate = 16000, noise = c(0.05, 0.15),
  dB = 40, plot = TRUE)

# Option 2: use a separate recording as noise profile
noise = soundgen(pitch = NA, noise = 0,
  formantsNoise = list(f1 = list(freq = 3000, width = 25)))
spectrogram(noise, 16000)
s2 = noiseRemoval(s, samplingRate = 16000, noise = noise,
  dB = 40, plot = TRUE)

# Option 3: provide noise spectrum as a matrix
spec_noise = spectrogram(
      noise, samplingRate = 16000,
      output = 'original', plot = FALSE)
s3 = noiseRemoval(s, samplingRate = 16000, noise = spec_noise,
  dB = 40, plot = TRUE)

## Not run: 
# play with gain and sensitivity
noiseRemoval(s, samplingRate = 16000, noise = c(0.05, 0.15),
  dB = 60, specificity = 2, plot = TRUE)

# remove noise only from a section of the audio
noiseRemoval(s, samplingRate = 16000, from = .3, to = .4,
  noise = c(0.05, 0.15), dB = 60, plot = TRUE, play = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='nonLinearPrediction_mod'>Nonlinear prediction modified</h2><span id='topic+nonLinearPrediction_mod'></span>

<h3>Description</h3>

<p>A slightly modified version of
<code><a href="nonlinearTseries.html#topic+nonLinearPrediction">nonLinearPrediction</a></code> that can return multiple
new points in one go, without having to call the function repeatedly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonLinearPrediction_mod(
  time.series,
  embedding.dim,
  time.lag,
  nPoints,
  radius,
  radius.increment
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nonLinearPrediction_mod_+3A_time.series">time.series</code>, <code id="nonLinearPrediction_mod_+3A_embedding.dim">embedding.dim</code>, <code id="nonLinearPrediction_mod_+3A_time.lag">time.lag</code>, <code id="nonLinearPrediction_mod_+3A_radius">radius</code>, <code id="nonLinearPrediction_mod_+3A_radius.increment">radius.increment</code></td>
<td>
<p>see <code><a href="nonlinearTseries.html#topic+nonLinearPrediction">nonLinearPrediction</a></code></p>
</td></tr>
<tr><td><code id="nonLinearPrediction_mod_+3A_npoints">nPoints</code></td>
<td>
<p>number of points to return</p>
</td></tr>
</table>

<hr>
<h2 id='nonlinPred'>Nonlinear prediction</h2><span id='topic+nonlinPred'></span>

<h3>Description</h3>

<p>Predicts new points in a time series. The functionality is provided by
<code><a href="nonlinearTseries.html#topic+nonLinearPrediction">nonLinearPrediction</a></code>. This function is just a
simple wrapper &quot;for dummies&quot; that reconstructs the phase space under the
hood, including the choice of time lag, embedding dimensions, etc. It can
also predict not one but many points in a single step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonlinPred(
  x,
  nPoints = 1,
  time.lag = NULL,
  embedding.dim = NULL,
  max.embedding.dim = 15,
  threshold = 0.95,
  max.relative.change = 0.1,
  radius = NULL,
  radius.increment = NULL,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nonlinPred_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="nonlinPred_+3A_npoints">nPoints</code></td>
<td>
<p>number of points to predict, ideally not more than length(x) /
2 (the function is called recursively to predict longer sequences, but
don't expect miracles)</p>
</td></tr>
<tr><td><code id="nonlinPred_+3A_time.lag">time.lag</code></td>
<td>
<p>time lag for constructing Takens vectors. Defaults to the
time to the first exponential decay of mutual information. See
<code><a href="nonlinearTseries.html#topic+timeLag">timeLag</a></code></p>
</td></tr>
<tr><td><code id="nonlinPred_+3A_embedding.dim">embedding.dim</code></td>
<td>
<p>the number of dimensions of the phase space. Defaults to
an estimate based on
<code><a href="nonlinearTseries.html#topic+estimateEmbeddingDim">estimateEmbeddingDim</a></code></p>
</td></tr>
<tr><td><code id="nonlinPred_+3A_max.embedding.dim">max.embedding.dim</code>, <code id="nonlinPred_+3A_threshold">threshold</code>, <code id="nonlinPred_+3A_max.relative.change">max.relative.change</code></td>
<td>
<p>parameters used to
estimate the optimal number of embedding dimensions - see
<code><a href="nonlinearTseries.html#topic+estimateEmbeddingDim">estimateEmbeddingDim</a></code></p>
</td></tr>
<tr><td><code id="nonlinPred_+3A_radius">radius</code>, <code id="nonlinPred_+3A_radius.increment">radius.increment</code></td>
<td>
<p>the radius used for detecting neighbors in the
phase space and its increment in case no neighbors are found - see
<code><a href="nonlinearTseries.html#topic+nonLinearPrediction">nonLinearPrediction</a></code></p>
</td></tr>
<tr><td><code id="nonlinPred_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original time series and the predictions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector on the same scale as input <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = c(rep(1, 3), rep(0, 4), rep(1, 3), rep(0, 4), rep(1, 3), 0, 0)
nonlinPred(x, 5, plot = TRUE)

nonlinPred(sin(1:25), 22, plot = TRUE)

x = soundgen(sylLen = 50, addSilence = 0)[250:450]
nonlinPred(x, 100, plot = TRUE)

nonlinPred(c(rnorm(5), NA, rnorm(3)))
nonlinPred(1:4)
nonlinPred(1:6)

## Not run: 
s1 = soundgen(sylLen = 500, pitch = rnorm(5, 200, 20),
              addSilence = 0, plot = TRUE)
playme(s1)
length(s1)
# we can predict output that is longer than the original time series by
# predicting a bit at a time and using the output as the new input
s2 = nonlinPred(s1, 16000)
spectrogram(c(s1, s2))
playme(c(s1, s2))

## End(Not run)
</code></pre>

<hr>
<h2 id='nonlinStats'>Nonlinear statistics</h2><span id='topic+nonlinStats'></span>

<h3>Description</h3>

<p>Estimates the optimal number of embedding dimensions (ed), correlation
dimension D2 (d2), maximum Lyapunov exponent (ml), and the results of
surrogate data testing for stochasticity (sur) using the functionality of the
package nonlinearTseries. This is basically just a wrapper that puts all
these functions together - convenient for frame-by-frame analysis, eg by
<code><a href="#topic+phasegram">phasegram</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonlinStats(
  x,
  t = NULL,
  pars_ed = list(time.lag = t, max.embedding.dim = 15),
  pars_d2 = list(time.lag = t, min.embedding.dim = 2, min.radius = 0.001, max.radius =
    max(abs(x)) * 2, n.points.radius = 20, theiler.window = t * 2),
  pars_ml = list(time.lag = t, min.embedding.dim = 2, radius = 0.001, theiler.window = t
    * 2),
  pars_sur = list(FUN = nonlinearTseries::timeAsymmetry, K = 1),
  nonlinStats = c("ed", "d2", "ml", "sur")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nonlinStats_+3A_x">x</code></td>
<td>
<p>numeric vector such as a sound or analysis frame</p>
</td></tr>
<tr><td><code id="nonlinStats_+3A_t">t</code></td>
<td>
<p>time lag in points. Defaults to the number of steps beyond which the
mutual information function reaches its minimum - see
<code><a href="nonlinearTseries.html#topic+timeLag">timeLag</a></code></p>
</td></tr>
<tr><td><code id="nonlinStats_+3A_pars_ed">pars_ed</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+estimateEmbeddingDim">estimateEmbeddingDim</a></code></p>
</td></tr>
<tr><td><code id="nonlinStats_+3A_pars_d2">pars_d2</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+corrDim">corrDim</a></code></p>
</td></tr>
<tr><td><code id="nonlinStats_+3A_pars_ml">pars_ml</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+maxLyapunov">maxLyapunov</a></code></p>
</td></tr>
<tr><td><code id="nonlinStats_+3A_pars_sur">pars_sur</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+surrogateTest">surrogateTest</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x = sin((1:200) / 5) + rnorm(200, 0, .5)
plot(x, type = 'l')
soundgen:::nonlinStats(x)
</code></pre>

<hr>
<h2 id='normalizeFolder'>Normalize folder</h2><span id='topic+normalizeFolder'></span>

<h3>Description</h3>

<p>Normalizes the amplitude of all wav/mp3 files in a folder based on their peak
or RMS amplitude or subjective loudness. This is good for playback
experiments, which require that all sounds should have similar intensity or
loudness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalizeFolder(
  myfolder,
  type = c("peak", "rms", "loudness")[1],
  maxAmp = 0,
  summaryFun = "mean",
  windowLength = 50,
  step = NULL,
  overlap = 70,
  killDC = FALSE,
  windowDC = 200,
  saveAudio = NULL,
  reportEvery = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalizeFolder_+3A_myfolder">myfolder</code></td>
<td>
<p>full path to folder containing input audio files</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_type">type</code></td>
<td>
<p>normalize so the output files has the same peak amplitude
('peak'), root mean square amplitude ('rms'), or subjective loudness in
sone ('loudness')</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_maxamp">maxAmp</code></td>
<td>
<p>maximum amplitude in dB (0 = max possible, -10 = 10 dB below
max possible, etc.)</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_summaryfun">summaryFun</code></td>
<td>
<p>should the output files have the same mean / median / max
etc rms amplitude or loudness? (summaryFun has no effect if type = 'peak')</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_killdc">killDC</code></td>
<td>
<p>if TRUE, removed DC offset (see also <code><a href="#topic+flatEnv">flatEnv</a></code>)</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_windowdc">windowDC</code></td>
<td>
<p>the window for calculating DC offset, ms</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to where the normalized files should be saved
(defaults to 'myfolder/normalized')</p>
</td></tr>
<tr><td><code id="normalizeFolder_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: first all files are rescaled to have the same peak amplitude of
<code>maxAmp</code> dB. If <code>type = 'peak'</code>, the process ends here. If
<code>type = 'rms'</code>, there are two additional steps. First the original RMS
amplitude of all files is calculated per frame by <code><a href="#topic+getRMS">getRMS</a></code>. The
&quot;quietest&quot; sound with the lowest summary RMS value is not modified, so its
peak amplitude remains <code>maxAmp</code> dB. All the remaining sounds are
rescaled linearly, so that their summary RMS values becomes the same as that
of the &quot;quietest&quot; sound, and their peak amplitudes become smaller,
<code>&lt;maxAmp</code>. Finally, if <code>type = 'loudness'</code>, the subjective
loudness of each sound is estimated by <code><a href="#topic+getLoudness">getLoudness</a></code>, which
assumes frequency sensitivity typical of human hearing. The following
normalization procedure is similar to that for <code>type = 'rms'</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getRMS">getRMS</a></code> <code><a href="#topic+analyze">analyze</a></code> <code><a href="#topic+getLoudness">getLoudness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# put a few short audio files in a folder, eg '~/Downloads/temp'
getRMS('~/Downloads/temp', summaryFun = 'mean')$summary  # different
normalizeFolder('~/Downloads/temp', type = 'rms', summaryFun = 'mean',
  saveAudio = '~/Downloads/temp/normalized')
getRMS('~/Downloads/temp/normalized', summaryFun = 'mean')$summary  # same
# If the saved audio files are treated as stereo with one channel missing,
# try reconverting with ffmpeg (saving is handled by tuneR::writeWave)

## End(Not run)
</code></pre>

<hr>
<h2 id='notesDict'>Conversion table from Hz to musical notation</h2><span id='topic+notesDict'></span>

<h3>Description</h3>

<p>A dataframe of 192 rows and 2 columns: &quot;note&quot; and &quot;freq&quot; (Hz). Range: C-5
(0.51 Hz) to B10 (31608.53 Hz)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notesDict
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 192 rows and 2 columns.
</p>

<hr>
<h2 id='notesToHz'>Convert notes to Hz</h2><span id='topic+notesToHz'></span>

<h3>Description</h3>

<p>Converts to Hz from musical notation like A4 - note A of the fourth octave
above C0 (16.35 Hz).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>notesToHz(n, A4 = 440)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="notesToHz_+3A_n">n</code></td>
<td>
<p>vector or matrix of notes</p>
</td></tr>
<tr><td><code id="notesToHz_+3A_a4">A4</code></td>
<td>
<p>frequency of note A in the fourth octave (modern standard ISO 16 or
concert pitch = 440 Hz)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+HzToNotes">HzToNotes</a></code> <code><a href="#topic+HzToSemitones">HzToSemitones</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>notesToHz(c("A4", "D4", "A#2", "C0", "C-2"))

# Baroque tuning A415, half a semitone flat relative to concert pitch A440
notesToHz(c("A4", "D4", "A#2", "C0", "C-2"), A4 = 415)
</code></pre>

<hr>
<h2 id='objectToString'>Object to string</h2><span id='topic+objectToString'></span>

<h3>Description</h3>

<p>Internal soundgen function. Converts any object to a string that preserves all internal structure and names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>objectToString(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="objectToString_+3A_x">x</code></td>
<td>
<p>any R object (unquoted)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::objectToString('adja')
soundgen:::objectToString(500)
soundgen:::objectToString(c(870, 1250, 1900))
soundgen:::objectToString(list(f1 = c(870, 1250), f2 = list(freq = 500, amp = 30)))
soundgen:::objectToString(list(
  pitch = list(time = c(0, 1), value = c(160, 150)),
  noise = list(time = c(-1, 170, 362), value = c(-14, 0, -26)),
  mouth = list(time = c(0, 0.07, 1), value = c(0, 0.48, 0.32))))
# NB: no matter how long, the object is still returned as an unbroken string
</code></pre>

<hr>
<h2 id='optimizePars'>Optimize parameters for acoustic analysis</h2><span id='topic+optimizePars'></span>

<h3>Description</h3>

<p>This customized wrapper for <code><a href="stats.html#topic+optim">optim</a></code> attempts to optimize
the parameters of <code><a href="#topic+segment">segment</a></code> or <code><a href="#topic+analyze">analyze</a></code> by comparing
the results with a manually annotated &quot;key&quot;. This optimization function uses
a single measurement per audio file (e.g., median pitch or the number of
syllables). For other purposes, you may want to adapt the optimization
function so that the key specifies the exact timing of syllables, their
median length, frame-by-frame pitch values, or any other characteristic that
you want to optimize for. The general idea remains the same, however: we want
to tune function parameters to fit our type of audio and research priorities.
The default settings of <code><a href="#topic+segment">segment</a></code> and <code><a href="#topic+analyze">analyze</a></code> have
been optimized for human non-linguistic vocalizations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizePars(
  myfolder,
  key,
  myfun,
  pars,
  bounds = NULL,
  fitnessPar,
  fitnessFun = function(x) 1 - cor(x, key, use = "pairwise.complete.obs"),
  nIter = 10,
  init = NULL,
  initSD = 0.2,
  control = list(maxit = 50, reltol = 0.01, trace = 0),
  otherPars = list(plot = FALSE),
  mygrid = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimizePars_+3A_myfolder">myfolder</code></td>
<td>
<p>path to where the .wav files live</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_key">key</code></td>
<td>
<p>a vector containing the &quot;correct&quot; measurement that we are aiming
to reproduce</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_myfun">myfun</code></td>
<td>
<p>the function being optimized: either 'segment' or
'analyze' (in quotes)</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_pars">pars</code></td>
<td>
<p>names of arguments to <code>myfun</code> that should be
optimized</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_bounds">bounds</code></td>
<td>
<p>a list setting the lower and upper boundaries for possible
values of optimized parameters. For ex., if we optimize <code>smooth</code>
and <code>smoothOverlap</code>, reasonable bounds might be list(low = c(5,
0), high = c(500, 95))</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_fitnesspar">fitnessPar</code></td>
<td>
<p>the name of output variable that we are comparing with the
key, e.g. 'nBursts' or 'pitch_median'</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_fitnessfun">fitnessFun</code></td>
<td>
<p>the function used to evaluate how well the output of
<code>myfun</code> fits the key. Defaults to 1 - Pearson's correlation (i.e. 0 is
perfect fit, 1 is awful fit). For pitch, log scale is more meaningful, so a
good fitness criterion is &quot;function(x) 1 - cor(log(x), log(key), use =
'pairwise.complete.obs')&quot;</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_niter">nIter</code></td>
<td>
<p>repeat the optimization several times to check convergence</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_init">init</code></td>
<td>
<p>initial values of optimized parameters (if NULL, the default
values are taken from the definition of <code>myfun</code>)</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_initsd">initSD</code></td>
<td>
<p>each optimization begins with a random seed, and
<code>initSD</code> specifies the SD of normal distribution used to generate
random deviation of initial values from the defaults</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_control">control</code></td>
<td>
<p>a list of control parameters passed on to
<code><a href="stats.html#topic+optim">optim</a></code>. The method used is &quot;Nelder-Mead&quot;</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_otherpars">otherPars</code></td>
<td>
<p>a list of additional arguments to <code>myfun</code></p>
</td></tr>
<tr><td><code id="optimizePars_+3A_mygrid">mygrid</code></td>
<td>
<p>a dataframe with one column per parameter to optimize, with
each row specifying the values to try. If not NULL, <code>optimizePars</code>
simply evaluates each combination of parameter values, without calling
<code><a href="stats.html#topic+optim">optim</a></code> (see examples)</p>
</td></tr>
<tr><td><code id="optimizePars_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE, reports the values of parameters evaluated and fitness</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If your sounds are very different from human non-linguistic vocalizations,
you may want to change the default values of other arguments to speed up
convergence. Adapt the code to enforce suitable constraints, depending
on your data.
</p>


<h3>Value</h3>

<p>Returns a matrix with one row per iteration with fitness in the first
column and the best values of each of the optimized parameters in the
remaining columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Download 260 sounds from the supplements in Anikin &amp; Persson (2017)
# - see http://cogsci.se/publications.html
# Unzip them into a folder, say '~/Downloads/temp'
myfolder = '~/Downloads/temp260'  # 260 .wav files live here

# Optimization of SEGMENTATION
# Import manual counts of syllables in 260 sounds from
# Anikin &amp; Persson (2017) (our "key")
key = segmentManual  # a vector of 260 integers

# Run optimization loop several times with random initial values
# to check convergence
# NB: with 260 sounds and default settings, this might take ~20 min per iteration!
res = optimizePars(myfolder = myfolder, myfun = 'segment', key = key,
  pars = c('shortestSyl', 'shortestPause'),
  fitnessPar = 'nBursts', otherPars = list(method = 'env'),
  nIter = 3, control = list(maxit = 50, reltol = .01, trace = 0))

# Examine the results
print(res)
for (c in 2:ncol(res)) {
  plot(res[, c], res[, 1], main = colnames(res)[c])
}
pars = as.list(res[1, 2:ncol(res)])  # top candidate (best pars)
s = do.call(segment, c(myfolder, pars))  # segment with best pars
cor(key, as.numeric(s[, fitnessPar]))
boxplot(as.numeric(s[, fitnessPar]) ~ as.integer(key), xlab='key')
abline(a=0, b=1, col='red')

# Try a grid with particular parameter values instead of formal optimization
res = optimizePars(myfolder = myfolder, myfun = 'segment', key = segmentManual,
  pars = c('shortestSyl', 'shortestPause'),
  fitnessPar = 'nBursts', otherPars = list(method = 'env'),
  mygrid = expand.grid(shortestSyl = c(30, 40),
                       shortestPause = c(30, 40, 50)))
1 - res$fit  # correlations with key

# Optimization of PITCH TRACKING (takes several hours!)
key = as.numeric(log(pitchManual))
res = optimizePars(
  myfolder = myfolder,
    myfun = 'analyze',
    key = key,  # log-scale better for pitch
    pars = c('windowLength', 'silence'),
    bounds = list(low = c(5, 0), high = c(200, .2)),
    fitnessPar = 'pitch_median',
    nIter = 2,
    otherPars = list(plot = FALSE, loudness = NULL, novelty = NULL,
                     roughness = NULL, nFormants = 0),
    fitnessFun = function(x) {
      1 - cor(log(x), key, use = 'pairwise.complete.obs') *
      (1 - mean(is.na(x) &amp; is.finite(key))) # penalize failing to detect f0
})

## End(Not run)
</code></pre>

<hr>
<h2 id='osc'>Oscillogram</h2><span id='topic+osc'></span>

<h3>Description</h3>

<p>Plots the oscillogram (waveform) of a sound on a linear or logarithmic scale
(in dB). To get a dB scale, centers and normalizes the sound, then takes a
logarithm of the positive part and a flipped negative part, which is
analogous to &quot;Waveform (dB)&quot; view in Audacity. For more plotting options,
check <code><a href="seewave.html#topic+oscillo">oscillo</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>osc(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  dynamicRange = 80,
  dB = FALSE,
  returnWave = FALSE,
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  main = NULL,
  xlab = NULL,
  ylab = NULL,
  ylim = NULL,
  bty = "n",
  midline = TRUE,
  maxPoints = 10000,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="osc_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="osc_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="osc_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="osc_+3A_from">from</code>, <code id="osc_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="osc_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="osc_+3A_db">dB</code></td>
<td>
<p>if TRUE, plots on a dB instead of linear scale</p>
</td></tr>
<tr><td><code id="osc_+3A_returnwave">returnWave</code></td>
<td>
<p>if TRUE, returns a log-transformed waveform as a numeric vector</p>
</td></tr>
<tr><td><code id="osc_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="osc_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="osc_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the oscillogram</p>
</td></tr>
<tr><td><code id="osc_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="osc_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="osc_+3A_xlab">xlab</code>, <code id="osc_+3A_ylab">ylab</code></td>
<td>
<p>axis labels</p>
</td></tr>
<tr><td><code id="osc_+3A_ylim">ylim</code></td>
<td>
<p>override default amplitude scale for non-centered sounds</p>
</td></tr>
<tr><td><code id="osc_+3A_bty">bty</code></td>
<td>
<p>box type (see '?par')</p>
</td></tr>
<tr><td><code id="osc_+3A_midline">midline</code></td>
<td>
<p>if TRUE, draws a line at 0 dB</p>
</td></tr>
<tr><td><code id="osc_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of points to plot (speeds up the plotting
of long audio files, but beware of antialiasing)</p>
</td></tr>
<tr><td><code id="osc_+3A_width">width</code>, <code id="osc_+3A_height">height</code>, <code id="osc_+3A_units">units</code>, <code id="osc_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="osc_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed on to 'plot()'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>returnWave = TRUE</code>, returns the input waveform on the
original or dB scale: a vector with range from '-dynamicRange' to
'dynamicRange'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound = sin(1:2000/10) *
        getSmoothContour(anchors = c(1, .01, .5), len = 2000)

# Oscillogram on a linear scale without bells and whistles, just base R
plot(sound, type = 'l')

# Oscillogram options with soundgen
osc(sound)             # linear
osc(sound, dB = TRUE)  # dB

# For numeric vectors, indicate samplingRate and scale (max amplitude)
osc(sound, samplingRate = 1000, scale = 100, dB = TRUE)

# Embellish and customize the plot
o = osc(sound, samplingRate = 1000, dB = TRUE, midline = FALSE,
        main = 'My waveform', col = 'blue', returnWave = TRUE)
abline(h = -80, col = 'orange', lty = 3)
o[1:10]  # the waveform in dB

## Not run: 
# Wave object
data(sheep, package = 'seewave')
osc(sheep, dB = TRUE)

# Plot a section
osc(sheep, from = .5, to = 1.2)

# for long files, reduce the resolution to plot quickly (careful: if the
# resolution is too low, antialiasing may cause artifacts)
osc(sheep, dB = TRUE, maxPoints = 2500)
osc(sheep, samplingRate = 5000, maxPoints = 100)

# files several minutes long can be plotted in under a second
osc('~/Downloads/speechEx.wav', maxPoints = 20000)

# saves oscillograms of all audio files in a folder
osc('~/Downloads/temp2', savePlots = '')

## End(Not run)
</code></pre>

<hr>
<h2 id='parabPeakInterpol'>Parabolic peak interpolation</h2><span id='topic+parabPeakInterpol'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parabPeakInterpol(threePoints, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parabPeakInterpol_+3A_threepoints">threePoints</code></td>
<td>
<p>the amplitudes of three adjacent points (beta is the
peak), ideally spectrum on a dB scale, obtained with a Gaussian window</p>
</td></tr>
<tr><td><code id="parabPeakInterpol_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plot the points and the fit parabola</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a spectral peak and two adjacent points, fits a parabola through them,
and thus estimates true peak location relative to the discrete peak. See
https://ccrma.stanford.edu/~jos/sasp/Quadratic_Interpolation_Spectral_Peaks.html
</p>


<h3>Value</h3>

<p>Returns a list: $p = the correction coefficient in bins (idx_beta + p
gives the true peak), $ampl_p = the amplitude of the true peak
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::parabPeakInterpol(c(-1, 0, -4), plot = TRUE)
</code></pre>

<hr>
<h2 id='pathfinder'>Pathfinder</h2><span id='topic+pathfinder'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathfinder(
  pitchCands,
  pitchCert,
  pitchSource,
  step,
  manual = NULL,
  certWeight = 0.5,
  pathfinding = c("none", "fast", "slow")[2],
  annealPars = list(maxit = 5000, temp = 1000),
  interpolWin_bin = 3,
  interpolTol = 0.05,
  interpolCert = 0.3,
  manualCert = 1,
  snakeStep = 0,
  snakePlot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pathfinder_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="pathfinder_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="pathfinder_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="pathfinder_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id="pathfinder_+3A_pathfinding">pathfinding</code></td>
<td>
<p>method of finding the optimal path through pitch
candidates: 'none' = best candidate per frame, 'fast' = simple heuristic,
'slow' = annealing. See <code>soundgen:::pathfinder</code></p>
</td></tr>
<tr><td><code id="pathfinder_+3A_annealpars">annealPars</code></td>
<td>
<p>a list of control parameters for postprocessing of
pitch contour with SANN algorithm of <code><a href="stats.html#topic+optim">optim</a></code>. This is
only relevant if <code>pathfinding = 'slow'</code></p>
</td></tr>
<tr><td><code id="pathfinder_+3A_interpolwin_bin">interpolWin_bin</code></td>
<td>
<p>when interpolating pitch candidates, the median is
calculated over <code>plus-minus interpolWin_bin</code></p>
</td></tr>
<tr><td><code id="pathfinder_+3A_interpoltol">interpolTol</code></td>
<td>
<p>when interpolating pitch candidates, the criterion
for needing to interpolate is the absence of pitch candidates with values
within <code>1 plus-minus interpolTol</code> of the median of pitch center of
gravity over the interpolation window. For ex., if <code>interpolTol</code>
is .05, we look for values from 0.95 to 1.05 time the median value over
interpolation window.</p>
</td></tr>
<tr><td><code id="pathfinder_+3A_interpolcert">interpolCert</code></td>
<td>
<p>when interpolating pitch candidates, all generated pitch
candidates are assigned a certainty equal to <code>interpolCert</code></p>
</td></tr>
<tr><td><code id="pathfinder_+3A_manualcert">manualCert</code></td>
<td>
<p>the certainty in manually added pitch candidates</p>
</td></tr>
<tr><td><code id="pathfinder_+3A_snakestep">snakeStep</code></td>
<td>
<p>optimized path through pitch candidates is further
processed to minimize the elastic force acting on pitch contour. To
disable, set <code>snakeStep = 0</code></p>
</td></tr>
<tr><td><code id="pathfinder_+3A_snakeplot">snakePlot</code></td>
<td>
<p>if TRUE, plots the snake</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing pitch contour. Starts with a
reasonable guess and computes the more-or-less optimal pitch contour (not
quite the very optimal - too computationally expensive).
</p>


<h3>Value</h3>

<p>Returns a numeric vector of pitch values representing the best found
path through pitch candidates.
</p>

<hr>
<h2 id='pathfinding_fast'>Path through pitch candidates: fast</h2><span id='topic+pathfinding_fast'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathfinding_fast(
  pitchCands,
  pitchCert,
  pitchSource,
  step,
  pitchCenterGravity,
  certWeight,
  seed_ms = 250,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pathfinding_fast_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="pathfinding_fast_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="pathfinding_fast_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="pathfinding_fast_+3A_pitchcentergravity">pitchCenterGravity</code></td>
<td>
<p>numeric vector giving the mean of all pitch
candidates per fft frame weighted by our certainty in each of these
candidates</p>
</td></tr>
<tr><td><code id="pathfinding_fast_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id="pathfinding_fast_+3A_seed_ms">seed_ms</code></td>
<td>
<p>start a new seed roughly every ... ms</p>
</td></tr>
<tr><td><code id="pathfinding_fast_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots pitch candidates and explored paths</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses a modified Viterbi algorithm to find a reasonable path though pitch
candidates. The idea is to start at several random &quot;seeds&quot;, each time
exploring as many paths as there are candidates per seed. The path with the
lowest global cost is returned. Transition costs are a weighted mean of two
penalties: based on pitch certainties (corrected for distance from pitch
center of gravity) and on pitch jumps.
</p>

<hr>
<h2 id='pathfinding_slow'>Path through pitch candidates: slow</h2><span id='topic+pathfinding_slow'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pathfinding_slow(
  pitchCands = pitchCands,
  pitchCert = pitchCert,
  certWeight = certWeight,
  pitchCenterGravity = pitchCenterGravity,
  manual = NULL,
  annealPars = list(maxit = 5000, temp = 1000)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pathfinding_slow_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="pathfinding_slow_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="pathfinding_slow_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id="pathfinding_slow_+3A_pitchcentergravity">pitchCenterGravity</code></td>
<td>
<p>numeric vector giving the mean of all pitch
candidates per fft frame weighted by our certainty in each of these
candidates</p>
</td></tr>
<tr><td><code id="pathfinding_slow_+3A_manual">manual</code></td>
<td>
<p>a dataframe of manual pitch candidates from pathfinder()</p>
</td></tr>
<tr><td><code id="pathfinding_slow_+3A_annealpars">annealPars</code></td>
<td>
<p>a list of control parameters for postprocessing of
pitch contour with SANN algorithm of <code><a href="stats.html#topic+optim">optim</a></code>. This is
only relevant if <code>pathfinding = 'slow'</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Optimizes the path through pitch candidates using simulated annealing with
<code><a href="stats.html#topic+optim">optim</a></code>. This can be really slow, depending on control
parameters.
</p>

<hr>
<h2 id='pDistr'>Proportion of total</h2><span id='topic+pDistr'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pDistr(x, quantiles)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pDistr_+3A_x">x</code></td>
<td>
<p>numeric vector of non-negative real numbers</p>
</td></tr>
<tr><td><code id="pDistr_+3A_quantiles">quantiles</code></td>
<td>
<p>quantiles of the cumulative distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the values in the input distribution that contain particular
proportions of the sum of all values in the input distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(100)
x = x - min(x)  # must be non-negative
hist(x)
v = soundgen:::pDistr(x, quantiles = c(.5, .8, .9))
sum(x[x &gt; v['0.5']]) / sum(x)
sum(x[x &gt; v['0.9']]) / sum(x)
</code></pre>

<hr>
<h2 id='permittedValues'>Defaults and ranges for soundgen()</h2><span id='topic+permittedValues'></span>

<h3>Description</h3>

<p>A dataset containing defaults and ranges of key variables for soundgen() and
soundgen_app().
Adjust as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permittedValues
</code></pre>


<h3>Format</h3>

<p>A matrix with 58 rows and 4 columns:
</p>

<dl>
<dt>default</dt><dd><p>default value</p>
</dd>
<dt>low</dt><dd><p>lowest permitted value</p>
</dd>
<dt>high</dt><dd><p>highest permitted value</p>
</dd>
<dt>step</dt><dd><p>increment for adjustment</p>
</dd>
</dl>
<p>...

</p>

<hr>
<h2 id='phasegram'>Phasegram</h2><span id='topic+phasegram'></span>

<h3>Description</h3>

<p>Produces a phasegram of a sound or another time series, which is a collection
of Poincare sections cut through phase portraits of consecutive frames. The x
axis is time, just as in a spectrogram, the y axis is a slice through the
phase portrait, and the color shows the density of trajectories at each point
of the phase portrait.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phasegram(
  x,
  samplingRate = NULL,
  from = NULL,
  to = NULL,
  windowLength = 10,
  step = windowLength/2,
  timeLag = NULL,
  theilerWindow = NULL,
  nonlinStats = c("ed", "d2", "ml", "sur"),
  pars_ed = list(max.embedding.dim = 15),
  pars_d2 = list(min.embedding.dim = 2, min.radius = 0.001, n.points.radius = 20),
  pars_ml = list(min.embedding.dim = 2, radius = 0.001),
  pars_sur = list(FUN = nonlinearTseries::timeAsymmetry, K = 1),
  bw = 0.01,
  bins = 5/bw,
  reportEvery = NULL,
  cores = 1,
  rasterize = FALSE,
  plot = TRUE,
  savePlots = NULL,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  xlab = "Time",
  ylab = "",
  main = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phasegram_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="phasegram_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_from">from</code>, <code id="phasegram_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_windowlength">windowLength</code></td>
<td>
<p>the length of each frame analyzed separately (ms)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_step">step</code></td>
<td>
<p>time step between consecutive frames (ms)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_timelag">timeLag</code></td>
<td>
<p>time lag between the original and time-shifted version of each
frame that together represent the phase portrait (ms). Defaults to the
number of steps beyond which the mutual information function reaches its
minimum or, if that fails, the steps until mutual information experiences
the first exponential decay - see <code><a href="nonlinearTseries.html#topic+timeLag">timeLag</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_theilerwindow">theilerWindow</code></td>
<td>
<p>time lag between two points that are considered locally
independent and can be treated as neighbors in the reconstructed phase
space. defaults to the first minimum or, if unavailable, the first zero of
the autocorrelation function (or, failing that, to <code>timeLag * 2</code>)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_nonlinstats">nonlinStats</code></td>
<td>
<p>nonlinear statistics to report: &quot;ed&quot; = the optimal number
of embedding dimensions, &quot;d2&quot; = correlation dimension D2, &quot;ml&quot; = maximum
Lyapunov exponent, &quot;sur&quot; = the results of surrogate data testing for
stochasticity. These are calculated using the functionality of the package
nonlinearTseries, which is seriously slow, so the default is just to get
the phasegram itself</p>
</td></tr>
<tr><td><code id="phasegram_+3A_pars_ed">pars_ed</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+estimateEmbeddingDim">estimateEmbeddingDim</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_pars_d2">pars_d2</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+corrDim">corrDim</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_pars_ml">pars_ml</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+maxLyapunov">maxLyapunov</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_pars_sur">pars_sur</code></td>
<td>
<p>a list of control parameters passed to
<code><a href="nonlinearTseries.html#topic+surrogateTest">surrogateTest</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_bw">bw</code></td>
<td>
<p>standard deviation of the smoothing kernel, as in
<code><a href="stats.html#topic+density">density</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_bins">bins</code></td>
<td>
<p>the number of bins along the Y axis after rasterizing (has no
effect if <code>rasterize = FALSE</code>)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="phasegram_+3A_rasterize">rasterize</code></td>
<td>
<p>if FALSE, only plots and returns Poincare sections on the
original scale (most graphical parameters will then have no effect); if
TRUE, rasterizes the phasegram matrix and plots it with more graphical
parameters</p>
</td></tr>
<tr><td><code id="phasegram_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="phasegram_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="phasegram_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_xlab">xlab</code>, <code id="phasegram_+3A_ylab">ylab</code>, <code id="phasegram_+3A_main">main</code></td>
<td>
<p>graphical parameters passed to
soundgen:::filled.contour.mod (if <code>rasterize = TRUE</code>) or plot (if
<code>rasterize = FALSE</code>)</p>
</td></tr>
<tr><td><code id="phasegram_+3A_width">width</code>, <code id="phasegram_+3A_height">height</code>, <code id="phasegram_+3A_units">units</code>, <code id="phasegram_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="phasegram_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to soundgen:::filled.contour.mod
(if <code>rasterize = TRUE</code>)  or plot (if <code>rasterize = FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: the input sound is normalized to [-1, 1] and divided into
consecutive frames <code>windowLength</code> ms long without multiplying by any
windowing function (unlike in STFT). For each frame, a phase portrait is
obtained by time-shifting the frame by <code>timeLag</code> ms. A Poincare section
is taken through the phase portrait (currently at a fixed angle, namely the
default in <code><a href="nonlinearTseries.html#topic+poincareMap">poincareMap</a></code>), giving the
intersection points of trajectories with this bisecting line. The density of
intersections is estimated with a smoothing kernel of bandwidth <code>bw</code> (as
an alternative to using histogram bins). The density distributions per frame
are stacked together into a phasegram (output: &quot;orig&quot;). The ranges of phase
portraits depend on the amplitude of signal in each frame. The resulting
phasegram can optionally be rasterized to smooth it for plotting (output:
&quot;rasterized&quot;).
</p>


<h3>Value</h3>

<p>Returns a list of three components: &quot;orig&quot; = the full phasegram;
&quot;rasterized&quot; = a rasterized version. For both, $time is the middle of each
frame (ms), $x is the coordinate along a Poincare section (since the audio
is normalized, the scale is [-1, 1]), and $y is the density of
intersections of system trajectories with the Poincare section. The third
component is $descriptives, which gives the result of nonlinear analysis
per frame. Currently implemented: shannon = Shannon entropy of Poincare
sections, nPeaks = log-number of peaks in the density distribution of
Poincare sections, ml = maximum Lyapunov exponent (positive values suggest
chaos), ed = optimal number of embedding dimensions (shows the complexity
of the reconstructed attractor), d2 = correlation dimension, sur =
probability of stochasticity according to surrogate data testing (0 =
deterministic, 1 = stochastic).
</p>


<h3>References</h3>


<ul>
<li><p> Herbst, C. T., Herzel, H., Å vec, J. G., Wyman, M. T., &amp; Fitch, W.
T. (2013). Visualization of system dynamics using phasegrams. Journal of
the Royal Society Interface, 10(85), 20130288.
</p>
</li>
<li><p> Huffaker, R., Huffaker, R. G., Bittelli, M., &amp; Rosa, R. (2017). Nonlinear time series analysis with R. Oxford University Press.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>target = soundgen(sylLen = 300, pitch = c(350, 420, 420, 410, 340) * 3,
  subDep = c(0, 0, 60, 50, 0, 0) / 2, addSilence = 0, plot = TRUE)
# Nonlinear statistics are also returned (slow - disable by setting
# nonlinStats = NULL if these are not needed)
ph = phasegram(target, 16000, nonlinStats = NULL)

## Not run: 
ph = phasegram(target, 16000, windowLength = 20, step = 20,
  rasterize = TRUE, bw = .01, bins = 150)
ph$descriptives

# Unfortunately, phasegrams are greatly affected by noise. Compare:
target2 = soundgen(sylLen = 300, pitch = c(350, 420, 420, 410, 340) * 3,
  subDep = c(0, 0, 60, 50, 0, 0)/2, noise = -10, addSilence = 0, plot = TRUE)
ph2 = phasegram(target2, 16000)

s2 = soundgen(sylLen = 3000, addSilence = 0, temperature = 1e-6,
  pitch = c(380, 550, 500, 220), subDep = c(0, 0, 40, 0, 0, 0, 0, 0),
  amDep = c(0, 0, 0, 0, 80, 0, 0, 0), amFreq = 80,
  jitterDep = c(0, 0, 0, 0, 0, 3))
spectrogram(s2, 16000, yScale = 'bark')
phasegram(s2, 16000, windowLength = 10, nonlinStats = NULL, bw = .001)
phasegram(s2, 16000, windowLength = 10, nonlinStats = NULL, bw = .02)

## End(Not run)
</code></pre>

<hr>
<h2 id='phasePropagate'>Propagate phase</h2><span id='topic+phasePropagate'></span>

<h3>Description</h3>

<p>Internal soundgen function called by dPhase(). Propagates phase using the
&quot;vocoder done right&quot; algorithm, as in Prusa &amp; Holighaus 2017 &quot;Phase vocoder
done right&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phasePropagate(i, dp_hor, dp_ver, magn, phase_new, tol, bin_width, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phasePropagate_+3A_i">i</code></td>
<td>
<p>analyzed frame</p>
</td></tr>
<tr><td><code id="phasePropagate_+3A_dp_hor">dp_hor</code>, <code id="phasePropagate_+3A_dp_ver">dp_ver</code></td>
<td>
<p>time and frequency partial derivatives of phase</p>
</td></tr>
<tr><td><code id="phasePropagate_+3A_phase_new">phase_new</code></td>
<td>
<p>matrix for storing the new phase</p>
</td></tr>
<tr><td><code id="phasePropagate_+3A_tol">tol</code></td>
<td>
<p>tolerance of &quot;vocoder done right&quot; algorithm</p>
</td></tr>
<tr><td><code id="phasePropagate_+3A_bin_width">bin_width</code></td>
<td>
<p>width of frequency bin, Hz</p>
</td></tr>
<tr><td><code id="phasePropagate_+3A_alpha">alpha</code></td>
<td>
<p>stretch factor</p>
</td></tr>
</table>

<hr>
<h2 id='phon2sone'>Convert phon to sone</h2><span id='topic+phon2sone'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phon2sone(phon)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phon2sone_+3A_phon">phon</code></td>
<td>
<p>loudness level, phon (vectorized)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Source: Timoney, J., Lysaght, T., Schoenwiesner, M., &amp; MacManus, L. (2004).
Implementing loudness models in matlab.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>phon = seq(0, 120, 2)
sone = soundgen:::phon2sone(phon)
plot(phon, sone, type = 'b')
plot(phon, log2(sone), type = 'b')
</code></pre>

<hr>
<h2 id='pitch_app'>Interactive pitch tracker</h2><span id='topic+pitch_app'></span>

<h3>Description</h3>

<p>Starts a shiny app for manually editing pitch contours. The settings in the
panels on the left correspond to arguments to <code><a href="#topic+analyze">analyze</a></code> - see
'?analyze' and the vignette on acoustic analysis for help and examples. You
can verify the pitch contours first, and then feed them back into
<code>analyze</code> (see examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitch_app()
</code></pre>


<h3>Value</h3>

<p>When proceeding to the next file in the cue, two types of backups are
created. (1) A global object called &quot;my_pitch&quot; is created or updated. This
list becomes visible when the app is terminated, and it contains the usual
outputs of analyze() ($detailed and $summary) plus lists of manually
corrected voiced and unvoiced frames. (2) The app saves to disk a .csv file
with one row per audio file. Apart from the usual descriptives from
analyze(), there are two additional columns: &quot;time&quot; with time stamps (the
midpoint of each STFT frame, ms) and &quot;pitch&quot; with the manually corrected
pitch values for each frame (Hz). When the orange &quot;Download results&quot; button
is clicked, a context menu pops up offering to terminate the app - if that
happens, the results are also returned directly into R. To process pitch
contours further in R, work directly with my_pitch[[myfile]]$time and
my_pitch[[myfile]]$pitch or, if loading the csv file, do something like:
</p>
<pre>
a = read.csv('~/Downloads/output.csv', stringsAsFactors = FALSE)
pitch = as.numeric(unlist(strsplit(a$pitch, ',')))
mean(pitch, na.rm = TRUE); sd(pitch, na.rm = TRUE)
</pre>
<p><b>Suggested workflow</b>
</p>
<p>Start by setting the basic analysis settings such as pitchFloor,
pitchCeiling, silence, etc. Then click &quot;Load audio&quot; to upload one or several
audio files (wav/mp3). Long files will be very slow, so please cut your audio
into manageable chunks (ideally &lt;10 s). If Shiny complains that maximum
upload size is exceeded, you can increase it, say to 30 MB, with
'options(shiny.maxRequestSize = 30 * 1024^2)'. Once the audio has been
uploaded to the browser, fine-tune the analysis settings as needed, edit the
pitch contour in the first file to your satisfaction, then click &quot;Next&quot; to
proceed to the next file, etc. Remember that setting a reasonable prior is
often faster than adjusting the contour one anchor at a time. When done,
click &quot;Save results&quot;. If working with many files, you might want to save the
results occasionally in case the app crashes (although you should still be
able to recover your data if it does - see below).
</p>
<p><b>How to edit pitch contours</b>
</p>
<p>Left-click to add a new anchor, double-click to remove it or unvoice the
frame. Each time you make a change, the entire pitch contour is re-fit, so
making a change in one frame can affect the path through candidates in
adjacent frames. You can control this behavior by changing the settings in
Out/Path and Out/Smoothing. If correctly configured, the app corrects the
contour with only a few manual values - you shouldn't need to manually edit
every single frame. For longer files, you can zoom in/out and navigate within
the file. You can also select a region to voice/unvoice or shift it as a
whole or to set a prior based on selected frequency range.
</p>
<p><b>Recovering lost data</b>
</p>
<p>Every time you click &quot;next&quot; or &quot;last&quot; to move in between files in the queue,
the output you've got so far is saved in a backup file called &quot;temp.csv&quot;, and
the &quot;my_pitch&quot; global object is updated. If the app crashes or is closed
without saving the results, this backup file preserves your data. To recover
it, access this file manually on disk or simply restart pitch_app() - a
dialog box will pop up and ask whether you wank to append the old data to the
new one. Path to backup file:
&quot;[R_installation_folder]/soundgen/shiny/pitch_app/www/temp.csv&quot;, for example,
&quot;/home/allgoodguys/R/x86_64-pc-linux-gnu-library/3.6/soundgen/shiny/pitch_app/www/temp.csv&quot;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+formant_app">formant_app</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Recommended workflow for analyzing a lot of short audio files
path_to_audio = '~/Downloads/temp'  # our audio lives here

# STEP 1: extract manually corrected pitch contours
my_pitch = pitch_app()  # runs in default browser such as Firefox or Chrome
# To change system default browser, run something like:
options('browser' = '/usr/bin/firefox')  # path to the executable on Linux

# STEP 2: run analyze() with manually corrected pitch contours to obtain
# accurate descriptives like the proportion of energy in harmonics above f0,
# etc. This also gives you formants and loudness estimates (disabled in
# pitch_app to speed things up)
df2 = analyze(path_to_audio,
  pitchMethods = 'autocor',  # only needed for HNR
  nFormants = 5,        # now we can measure formants as well
  pitchManual = my_pitch
  # or, if loading the output of pitch_app() from the disk:
  # pitchManual = '~/Downloads/output.csv'
  # pitchManual = '~/path_to_some_folder/my_pitch_contours.rds
  # etc
)

# STEP 3: add other acoustic descriptors, for ex.
df3 = segment(path_to_audio)

# STEP 4: merge df2, df3, df4, ... in R or a spreadsheet editor to have all
# acoustic descriptives together

# To verify your pitch contours and/or edit them later, copy output.csv to
# the folder with your audio, run pitch_app(), and load the audio + csv
# together. The saved pitch contours are treated as manual anchors

## End(Not run)
</code></pre>

<hr>
<h2 id='pitchContour'>Manually corrected pitch contours in 260 sounds</h2><span id='topic+pitchContour'></span>

<h3>Description</h3>

<p>A dataframe of 260 rows and two columns: &quot;file&quot; for filename in the corpus
(Anikin &amp; Persson, 2017) and &quot;pitch&quot; for pitch values per frame. The corpus
can be downloaded from http://cogsci.se/publications.html
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitchContour
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 260 rows and 2 columns.
</p>

<hr>
<h2 id='pitchDescriptives'>Pitch descriptives</h2><span id='topic+pitchDescriptives'></span>

<h3>Description</h3>

<p>Provides common descriptives of time series such as pitch contours, including
measures of average / range / variability / slope / inflections etc. Several
degrees of smoothing can be applied consecutively. The summaries are produced
on the original and log-transformed scales, so this is meant to be used on
frequency-related variables in Hz.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitchDescriptives(
  x,
  step = NULL,
  timeUnit,
  smoothBW = c(NA, 10, 1),
  inflThres = 0.2,
  extraSummaryFun = c(),
  ref = 16.35,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pitchDescriptives_+3A_x">x</code></td>
<td>
<p>input: numeric vector, a list of time stamps and values in rows, a
dataframe with one row per file and time/pitch values stored as characters
(as exported by <code><a href="#topic+pitch_app">pitch_app</a></code>), or path to csv file containing
the output of <code><a href="#topic+pitch_app">pitch_app</a></code> or <code><a href="#topic+analyze">analyze</a></code></p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_step">step</code></td>
<td>
<p>distance between values in s (only needed if input is a vector)</p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_timeunit">timeUnit</code></td>
<td>
<p>specify whether the time stamps (if any) are in ms or s</p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_smoothbw">smoothBW</code></td>
<td>
<p>a vector of bandwidths (Hz) for consecutive smoothing of
input using <code><a href="#topic+pitchSmoothPraat">pitchSmoothPraat</a></code>; NA = no smoothing</p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_inflthres">inflThres</code></td>
<td>
<p>minimum difference (in semitones) between consecutive
extrema to consider them inflections; to apply a different threshold at
each smoothing level, provide <code>inflThres</code> as a vector of the same
length as <code>smoothBW</code>; NA = no threshold</p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_extrasummaryfun">extraSummaryFun</code></td>
<td>
<p>additional summary function(s) that take a numeric
vector with some NAs and return a single number, eg c('myFun1', 'myFun2')</p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_ref">ref</code></td>
<td>
<p>reference value for transforming Hz to semitones, defaults to
C0 (16.35 Hz)</p>
</td></tr>
<tr><td><code id="pitchDescriptives_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the inflections for manual verification</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe with columns containing summaries of one or
multiple inputs (one input per row). The descriptives are as follows:
</p>
<dl>
<dt>duration</dt><dd><p>total duration, s</p>
</dd> <dt>durDefined</dt><dd><p>duration
after omitting leading and trailing NAs</p>
</dd> <dt>propDefined</dt><dd><p>proportion of
input with non-NA value, eg proportion of voiced frames if the input is
pitch</p>
</dd> <dt>start, start_oct, end, end_oct</dt><dd><p>the first and last values on
the original scale and in octaves above C0 (16.3516 Hz)</p>
</dd> <dt>mean,
median, max, min</dt><dd><p>average and extreme values on the original scale</p>
</dd>
<dt>mean_oct, median_oct, min_oct, max_oct</dt><dd><p>same in octaves above C0</p>
</dd>
<dt>time_max, time_min</dt><dd><p>the location of minimum and maximum relative to
durDefined, 0 to 1</p>
</dd> <dt>range, range_sem, sd, sd_sem</dt><dd><p>range and standard
deviation on the original scale and in semitones</p>
</dd> <dt>CV</dt><dd><p>coefficient of
variation = sd/mean (provided for historical reasons)</p>
</dd> <dt>meanSlope,
meanSlope_sem</dt><dd><p>mean slope in Hz/s or semitones/s (NB: does not depend on
duration or missing values)</p>
</dd> <dt>meanAbsSlope, meanAbsSlope_sem</dt><dd><p>mean
absolute slope (modulus, ie rising and falling sections no longer cancel
out)</p>
</dd> <dt>maxAbsSlope, maxAbsSlope_sem</dt><dd><p>the steepest slope</p>
</dd></dl>



<h3>Examples</h3>

<pre><code class='language-R'>x = c(NA, NA, 405, 441, 459, 459, 460, 462, 462, 458, 458, 445, 458, 451,
444, 444, 430, 416, 409, 403, 403, 389, 375, NA, NA, NA, NA, NA, NA, NA, NA,
NA, 183, 677, 677, 846, 883, 886, 924, 938, 883, 946, 846, 911, 826, 826,
788, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 307,
307, 368, 377, 383, 383, 383, 380, 377, 377, 377, 374, 374, 375, 375, 375,
375, 368, 371, 374, 375, 361, 375, 389, 375, 375, 375, 375, 375, 314, 169,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 238, 285, 361, 374, 375, 375,
375, 375, 375, 389, 403, 389, 389, 375, 375, 389, 375, 348, 361, 375, 348,
348, 361, 348, 342, 361, 361, 361, 365, 365, 361, 966, 966, 966, 959, 959,
946, 1021, 1021, 1026, 1086, 1131, 1131, 1146, 1130, 1172, 1240, 1172, 1117,
1103, 1026, 1026, 966, 919, 946, 882, 832, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA)
plot(x, type = 'b')
ci95 = function(x) diff(quantile(na.omit(x), probs = c(.025, .975)))
pd = pitchDescriptives(
  x, step = .025, timeUnit = 's',
  smoothBW = c(NA, 10, 1),   # original + smoothed at 10 Hz and 1 Hz
  inflThres = c(NA, .2, .2), # different for each level of smoothing
  extraSummaryFun = 'ci95',  # user-defined, here 95% coverage interval
  plot = TRUE
)
pd

## Not run: 
# a single file
data(sheep, package = 'seewave')
a = analyze(sheep)
pd1 = pitchDescriptives(a$detailed[, c('time', 'pitch')],
                        timeUnit = 'ms', inflThres = NA, plot = TRUE)
pd2 = pitchDescriptives(a$detailed[, c('time', 'pitch')],
                        timeUnit = 'ms', inflThres = c(0.1, 0.1, .5), plot = TRUE)

# multiple files returned by analyze()
an = analyze('~/Downloads/temp')
pd = pitchDescriptives(an$detailed, timeUnit = 'ms')
pd

# multiple files returned by pitch_app()
pd = pitchDescriptives(
  '~/Downloads/pitch_manual_1708.csv',
  timeUnit = 'ms', smoothBW = c(NA, 2), inflThres = .25)

# a single file, exported from Praat
par(mfrow = c(3, 1))
pd = pitchDescriptives(
  '~/Downloads/F-Hin-Om_jana.wav_F0contour.txt',
  timeUnit = 's', smoothBW = c(NA, 25, 2), inflThres = .25, plot = TRUE)
par(mfrow = c(1, 1))

## End(Not run)
</code></pre>

<hr>
<h2 id='pitchManual'>Manual pitch estimation in 260 sounds</h2><span id='topic+pitchManual'></span>

<h3>Description</h3>

<p>A vector of manually verified pitch values per sound in the corpus of 590
human non-linguistic emotional vocalizations from Anikin &amp; Persson (2017).
The corpus can be downloaded from http://cogsci.se/publications.html
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitchManual
</code></pre>


<h3>Format</h3>

<p>An object of class <code>numeric</code> of length 260.
</p>

<hr>
<h2 id='pitchSmoothPraat'>Pitch smoothing as in Praat</h2><span id='topic+pitchSmoothPraat'></span>

<h3>Description</h3>

<p>Smoothes an intonation (pitch) contour with a low-pass filter, as in Praat
(http://www.fon.hum.uva.nl/praat/). Algorithm: interpolates missing values
(unvoiced frames), performs FFT to obtain the spectrum, multiplies by a
Gaussian filter, performs an inverse FFT, and fills the missing values back
in. The <code>bandwidth</code> parameter is about half the cutoff frequency (ie
some frequencies will still be present up to ~2 * bandwidth)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitchSmoothPraat(pitch, bandwidth, samplingRate, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pitchSmoothPraat_+3A_pitch">pitch</code></td>
<td>
<p>numeric vector of pitch values (NA = unvoiced)</p>
</td></tr>
<tr><td><code id="pitchSmoothPraat_+3A_bandwidth">bandwidth</code></td>
<td>
<p>the bandwidth of low-pass filter, Hz (high = less smoothing,
close to zero = more smoothing)</p>
</td></tr>
<tr><td><code id="pitchSmoothPraat_+3A_samplingrate">samplingRate</code></td>
<td>
<p>the number of pitch values per second</p>
</td></tr>
<tr><td><code id="pitchSmoothPraat_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original and smoothed pitch contours</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+analyze">analyze</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pitch = c(NA, NA, 405, 441, 459, 459, 460, 462, 462, 458, 458, 445, 458, 451,
444, 444, 430, 416, 409, 403, 403, 389, 375, NA, NA, NA, NA, NA, NA, NA, NA,
NA, 183, 677, 677, 846, 883, 886, 924, 938, 883, 946, 846, 911, 826, 826,
788, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 307,
307, 368, 377, 383, 383, 383, 380, 377, 377, 377, 374, 374, 375, 375, 375,
375, 368, 371, 374, 375, 361, 375, 389, 375, 375, 375, 375, 375, 314, 169,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 238, 285, 361, 374, 375, 375,
375, 375, 375, 389, 403, 389, 389, 375, 375, 389, 375, 348, 361, 375, 348,
348, 361, 348, 342, 361, 361, 361, 365, 365, 361, 966, 966, 966, 959, 959,
946, 1021, 1021, 1026, 1086, 1131, 1131, 1146, 1130, 1172, 1240, 1172, 1117,
1103, 1026, 1026, 966, 919, 946, 882, 832, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA)
pitchSmoothPraat(pitch, bandwidth = 10, samplingRate = 40, plot = TRUE)
pitchSmoothPraat(pitch, bandwidth = 2, samplingRate = 40, plot = TRUE)
</code></pre>

<hr>
<h2 id='playme'>Play audio</h2><span id='topic+playme'></span>

<h3>Description</h3>

<p>Plays one or more sounds: wav/mp3 file(s), Wave objects, or numeric vectors.
This is a simple wrapper for the functionality provided by
<code><a href="tuneR.html#topic+play">play</a></code>. Recommended players on Linux: &quot;play&quot; from the
&quot;vox&quot; library (default), &quot;aplay&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>playme(x, samplingRate = 16000, player = NULL, from = NULL, to = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="playme_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="playme_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="playme_+3A_player">player</code></td>
<td>
<p>the name of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc.
Defaults to &quot;play&quot; on Linux, &quot;afplay&quot; on MacOS, and tuneR default on
Windows. In case of errors, try setting another default player for
<code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="playme_+3A_from">from</code>, <code id="playme_+3A_to">to</code></td>
<td>
<p>play a selected time range (s)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Play an audio file:
playme('pathToMyAudio/audio.wav')

# Create and play a numeric vector:
f0_Hz = 440
sound = sin(2 * pi * f0_Hz * (1:16000) / 16000)
playme(sound, 16000)
playme(sound, 16000, from = .1, to = .5)  # play from 100 to 500 ms

# In case of errors, look into tuneR::play(). For ex., you might need to
# specify which player to use:
playme(sound, 16000, player = 'aplay')

# To avoid doing it all the time, set the default player:
tuneR::setWavPlayer('aplay')
playme(sound, 16000)  # should now work without specifying the player

## End(Not run)
</code></pre>

<hr>
<h2 id='plotMS'>Plot modulation spectrum</h2><span id='topic+plotMS'></span>

<h3>Description</h3>

<p>Plots a single modulation spectrum returned by
<code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code>. The result is the same as the plot produced
by <code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code>, but calling <code>plotMS</code> is handy for
processed modulation spectra - for instance, for plotting the difference
between the modulation spectra of two sounds or groups of sounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMS(
  ms,
  X = NULL,
  Y = NULL,
  quantiles = c(0.5, 0.8, 0.9),
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  logWarpX = NULL,
  logWarpY = NULL,
  main = NULL,
  xlab = "Hz",
  ylab = "1/kHz",
  xlim = NULL,
  ylim = NULL,
  audio = NULL,
  extraY = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMS_+3A_ms">ms</code></td>
<td>
<p>modulation spectrum - a matrix with temporal modulation in columns
and spectral modulation in rows, as returned by
<code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code></p>
</td></tr>
<tr><td><code id="plotMS_+3A_x">X</code>, <code id="plotMS_+3A_y">Y</code></td>
<td>
<p>rownames and colnames of <code>ms</code>, respectively</p>
</td></tr>
<tr><td><code id="plotMS_+3A_quantiles">quantiles</code></td>
<td>
<p>labeled contour values, % (e.g., &quot;50&quot; marks regions that
contain 50% of the sum total of the entire modulation spectrum)</p>
</td></tr>
<tr><td><code id="plotMS_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="plotMS_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="plotMS_+3A_logwarpx">logWarpX</code>, <code id="plotMS_+3A_logwarpy">logWarpY</code></td>
<td>
<p>numeric vector of length 2: c(sigma, base) of
pseudolog-warping the modulation spectrum, as in function
pseudo_log_trans() from the &quot;scales&quot; package</p>
</td></tr>
<tr><td><code id="plotMS_+3A_xlab">xlab</code>, <code id="plotMS_+3A_ylab">ylab</code>, <code id="plotMS_+3A_main">main</code>, <code id="plotMS_+3A_xlim">xlim</code>, <code id="plotMS_+3A_ylim">ylim</code></td>
<td>
<p>graphical parameters</p>
</td></tr>
<tr><td><code id="plotMS_+3A_audio">audio</code></td>
<td>
<p>(internal) a list of audio attributes</p>
</td></tr>
<tr><td><code id="plotMS_+3A_extray">extraY</code></td>
<td>
<p>if TRUE, another Y-axis is plotted on the right showing 1000/Y</p>
</td></tr>
<tr><td><code id="plotMS_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed on to <code>filled.contour.mod</code>
and <code><a href="graphics.html#topic+contour">contour</a></code> (see <code><a href="#topic+spectrogram">spectrogram</a></code>)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>ms1 = modulationSpectrum(runif(4000), samplingRate = 16000, plot = TRUE)
plotMS(ms1$processed)  # identical to above

# compare two modulation spectra
ms2 = modulationSpectrum(soundgen(sylLen = 100, addSilence = 0),
                         samplingRate = 16000)
# ensure the two matrices have the same dimensions
ms2_resized = soundgen:::interpolMatrix(ms2$original,
  nr = nrow(ms1$original), nc = ncol(ms1$original))
# plot the difference
plotMS(log(ms1$original / ms2_resized), quantile = NULL,
  col = colorRampPalette(c('blue', 'yellow')) (50))
</code></pre>

<hr>
<h2 id='plotSpec'>Plot spectrogram</h2><span id='topic+plotSpec'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSpec(
  X,
  Y,
  Z,
  audio = NULL,
  internal = NULL,
  dynamicRange = 80,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  yScale = "linear",
  contrast = 0.2,
  brightness = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  nlevels = 30,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotSpec_+3A_x">X</code></td>
<td>
<p>time stamps, ms</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_y">Y</code></td>
<td>
<p>frequency stamps, kHz / mel / bark</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_z">Z</code></td>
<td>
<p>time in rows, frequency in columns (NB: this is the transpose of the
exported spectrogram!)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_audio">audio</code></td>
<td>
<p>a list returned by <code>readAudio</code></p>
</td></tr>
<tr><td><code id="plotSpec_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_yscale">yScale</code></td>
<td>
<p>scale of the frequency axis: 'linear' = linear, 'log' =
logarithmic (musical), 'bark' = bark with <code><a href="tuneR.html#topic+hz2bark">hz2bark</a></code>,
'mel' = mel with <code><a href="tuneR.html#topic+hz2mel">hz2mel</a></code>, 'ERB' = Equivalent
Rectangular Bandwidths with <code><a href="#topic+HzToERB">HzToERB</a></code></p>
</td></tr>
<tr><td><code id="plotSpec_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_xlab">xlab</code>, <code id="plotSpec_+3A_ylab">ylab</code>, <code id="plotSpec_+3A_main">main</code>, <code id="plotSpec_+3A_mar">mar</code>, <code id="plotSpec_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id="plotSpec_+3A_width">width</code>, <code id="plotSpec_+3A_height">height</code>, <code id="plotSpec_+3A_units">units</code>, <code id="plotSpec_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="plotSpec_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function called by spectrogram() etc to plot a spectrogram.
</p>

<hr>
<h2 id='plotUnrasterized'>Plot unrasterized spetrogram</h2><span id='topic+plotUnrasterized'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotUnrasterized(
  df,
  xlim = range(df$time, finite = TRUE),
  ylim = range(df$freq, finite = TRUE),
  zlim = range(df$magn, finite = TRUE),
  levels = seq(min(df$magn, na.rm = TRUE), max(df$magn, na.rm = TRUE), length.out =
    nlevels + 1),
  nlevels = 30,
  pch = 16,
  cex = 0.25,
  color.palette = function(n) grDevices::hcl.colors(n, "YlOrRd", rev = TRUE),
  col = color.palette(nlevels),
  legend = FALSE,
  asp = NA,
  xaxs = "i",
  yaxs = "i",
  las = 1,
  log = "",
  yScale = c("orig", "bark", "mel", "ERB")[1],
  axisX = TRUE,
  axisY = TRUE,
  maxPoints = 5e+05,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotUnrasterized_+3A_df">df</code></td>
<td>
<p>data to plot</p>
</td></tr>
<tr><td><code id="plotUnrasterized_+3A_xlim">xlim</code>, <code id="plotUnrasterized_+3A_ylim">ylim</code>, <code id="plotUnrasterized_+3A_zlim">zlim</code></td>
<td>
<p>range of values</p>
</td></tr>
<tr><td><code id="plotUnrasterized_+3A_levels">levels</code>, <code id="plotUnrasterized_+3A_nlevels">nlevels</code>, <code id="plotUnrasterized_+3A_pch">pch</code>, <code id="plotUnrasterized_+3A_cex">cex</code>, <code id="plotUnrasterized_+3A_color.palette">color.palette</code>, <code id="plotUnrasterized_+3A_col">col</code>, <code id="plotUnrasterized_+3A_legend">legend</code>, <code id="plotUnrasterized_+3A_asp">asp</code>, <code id="plotUnrasterized_+3A_xaxs">xaxs</code>, <code id="plotUnrasterized_+3A_yaxs">yaxs</code>, <code id="plotUnrasterized_+3A_las">las</code>, <code id="plotUnrasterized_+3A_log">log</code>, <code id="plotUnrasterized_+3A_axisx">axisX</code>, <code id="plotUnrasterized_+3A_axisy">axisY</code></td>
<td>
<p>graphical parameters passed to plot()</p>
</td></tr>
<tr><td><code id="plotUnrasterized_+3A_yscale">yScale</code></td>
<td>
<p>scale of frequency representation</p>
</td></tr>
<tr><td><code id="plotUnrasterized_+3A_maxpoints">maxPoints</code></td>
<td>
<p>downsample if too big for plotting</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for adding a customized frequency axis to the spectrogram
</p>

<hr>
<h2 id='presets'>Presets</h2><span id='topic+presets'></span>

<h3>Description</h3>

<p>A library of presets for easy generation of a few nice sounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>presets
</code></pre>


<h3>Format</h3>

<p>A list of length 4.
</p>

<hr>
<h2 id='princarg'>Principal argument</h2><span id='topic+princarg'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>princarg(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="princarg_+3A_x">x</code></td>
<td>
<p>real number representing phase angle</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recalculates the phase of complex numbers to be within the interval from -pi to pi.
</p>

<hr>
<h2 id='processAudio'>Process audio</h2><span id='topic+processAudio'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processAudio(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  funToCall,
  myPars = list(),
  var_noSummary = NULL,
  reportEvery = NULL,
  savePlots = NULL,
  saveAudio = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="processAudio_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="processAudio_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="processAudio_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="processAudio_+3A_from">from</code>, <code id="processAudio_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="processAudio_+3A_funtocall">funToCall</code></td>
<td>
<p>function to call (specify what to do with each audio input)</p>
</td></tr>
<tr><td><code id="processAudio_+3A_mypars">myPars</code></td>
<td>
<p>a list of parameters to pass on to 'funToCall'</p>
</td></tr>
<tr><td><code id="processAudio_+3A_var_nosummary">var_noSummary</code></td>
<td>
<p>names of output variables that should not be summarized</p>
</td></tr>
<tr><td><code id="processAudio_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="processAudio_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="processAudio_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# How many cores should I use? Maybe ~4
a1 = analyze('~/Downloads/temp60/', cores = 1)  # 3:55
a2 = analyze('~/Downloads/temp60/', cores = 2, reportEvery = 100)  # 2:30
a3 = analyze('~/Downloads/temp60/', cores = 3, reportEvery = 100)  # 1:50
a4 = analyze('~/Downloads/temp60/', cores = 4, reportEvery = 100)  # 1:33
a7 = analyze('~/Downloads/temp60/', cores = 7, reportEvery = 100)  # 1:29

## End(Not run)
</code></pre>

<hr>
<h2 id='prosody'>Prosody</h2><span id='topic+prosody'></span>

<h3>Description</h3>

<p>Exaggerates or flattens the intonation by performing a dynamic pitch shift,
changing pitch excursion from its original median value without changing the
formants. This is a particular case of pitch shifting, which is performed
with <code><a href="#topic+shiftPitch">shiftPitch</a></code>. The result is likely to be improved if
manually corrected pitch contours are provided. Depending on the nature of
audio, the settings that control pitch shifting may also need to be
fine-tuned with the <code>shiftPitch_pars</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prosody(
  x,
  samplingRate = NULL,
  multProsody,
  analyze_pars = list(),
  shiftPitch_pars = list(),
  pitchManual = NULL,
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1,
  plot = FALSE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prosody_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="prosody_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="prosody_+3A_multprosody">multProsody</code></td>
<td>
<p>multiplier of pitch excursion from median (on a
logarithmic or musical scale): &gt;1 = exaggerate intonation, 1 = no change, &lt;1
= flatten, 0 = completely flat at the original median pitch</p>
</td></tr>
<tr><td><code id="prosody_+3A_analyze_pars">analyze_pars</code></td>
<td>
<p>a list of parameters to pass to <code><a href="#topic+analyze">analyze</a></code>
(only needed if <code>pitchManual</code> is NULL - that is, if we attempt to
track pitch automatically)</p>
</td></tr>
<tr><td><code id="prosody_+3A_shiftpitch_pars">shiftPitch_pars</code></td>
<td>
<p>a list of parameters to pass to
<code><a href="#topic+shiftPitch">shiftPitch</a></code> to fine-tune the pitch-shifting algorithm</p>
</td></tr>
<tr><td><code id="prosody_+3A_pitchmanual">pitchManual</code></td>
<td>
<p>manually corrected pitch contour. For a single sound,
provide a numeric vector of any length. For multiple sounds, provide a
dataframe with columns &quot;file&quot; and &quot;pitch&quot; (or path to a csv file) as
returned by <code><a href="#topic+pitch_app">pitch_app</a></code>, ideally with the same windowLength and
step as in current call to analyze. A named list with pitch vectors per
file is also OK (eg as returned by pitch_app)</p>
</td></tr>
<tr><td><code id="prosody_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
<tr><td><code id="prosody_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full (!) path to folder for saving the processed audio; NULL
= don't save, &rdquo; = same as input folder (NB: overwrites the originals!)</p>
</td></tr>
<tr><td><code id="prosody_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="prosody_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="prosody_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="prosody_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="prosody_+3A_width">width</code>, <code id="prosody_+3A_height">height</code>, <code id="prosody_+3A_units">units</code>, <code id="prosody_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="prosody_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the input is a single audio (file, Wave, or numeric vector),
returns the processed waveform as a numeric vector with the original
sampling rate and scale. If the input is a folder with several audio files,
returns a list of processed waveforms, one for each file.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shiftPitch">shiftPitch</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 200, pitch = c(150, 220), addSilence = 50,
             plot = TRUE, yScale = 'log')
# playme(s)
s1 = prosody(s, 16000, multProsody = 2,
  analyze_pars = list(windowLength = 30, step = 15),
  shiftPitch_pars = list(windowLength = 20, step = 5, freqWindow = 300),
  plot = TRUE)
# playme(s1)
# spectrogram(s1, 16000, yScale = 'log')

## Not run: 
# Flat intonation - remove all frequency modulation
s2 = prosody(s, 16000, multProsody = 0,
  analyze_pars = list(windowLength = 30, step = 15),
  shiftPitch_pars = list(windowLength = 20, step = 1, freqWindow = 500),
  plot = TRUE)
playme(s2)
spectrogram(s2, 16000, yScale = 'log')

# Download an example - a bit of speech (sampled at 16000 Hz)
download.file('http://cogsci.se/soundgen/audio/speechEx.wav',
              destfile = '~/Downloads/temp1/speechEx.wav')
target = '~/Downloads/temp1/speechEx.wav'
samplingRate = tuneR::readWave(target)@samp.rate
spectrogram(target, yScale = 'log')
playme(target)

s3 = prosody(target, multProsody = 1.5,
  analyze_pars = list(windowLength = 30, step = 15),
  shiftPitch_pars = list(freqWindow = 400, propagation = 'adaptive'))
spectrogram(s3, tuneR::readWave(target)@samp.rate, yScale = 'log')
playme(s3)

# process all audio files in a folder
s4 = prosody('~/Downloads/temp', multProsody = 2, savePlots = '',
             saveAudio = '~/Downloads/temp/prosody')
str(s4)  # returns a list with audio (+ saves it to disk)

## End(Not run)
</code></pre>

<hr>
<h2 id='pseudoLog'>Pseudolog</h2><span id='topic+pseudoLog'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseudoLog(x, sigma, base)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pseudoLog_+3A_x">x</code></td>
<td>
<p>numeric vector to transform</p>
</td></tr>
<tr><td><code id="pseudoLog_+3A_sigma">sigma</code></td>
<td>
<p>scaling factor for the linear part</p>
</td></tr>
<tr><td><code id="pseudoLog_+3A_base">base</code></td>
<td>
<p>approximate logarithm base used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From function pseudo_log_trans() in the &quot;scales&quot; package.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pseudoLog_undo">pseudoLog_undo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = -30:30
plot(a, soundgen:::pseudoLog(a, sigma = 1, base = 2))
plot(a, soundgen:::pseudoLog(a, sigma = 5, base = 2))
plot(a, soundgen:::pseudoLog(a, sigma = .1, base = 2))
</code></pre>

<hr>
<h2 id='pseudoLog_undo'>Undo pseudolog</h2><span id='topic+pseudoLog_undo'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseudoLog_undo(x, sigma, base)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pseudoLog_undo_+3A_x">x</code></td>
<td>
<p>numeric vector to transform</p>
</td></tr>
<tr><td><code id="pseudoLog_undo_+3A_sigma">sigma</code></td>
<td>
<p>scaling factor for the linear part</p>
</td></tr>
<tr><td><code id="pseudoLog_undo_+3A_base">base</code></td>
<td>
<p>approximate logarithm base used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From function pseudo_log_trans() in the &quot;scales&quot; package.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pseudoLog">pseudoLog</a></code>
</p>

<hr>
<h2 id='rbind_fill'>rbind_fill</h2><span id='topic+rbind_fill'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbind_fill(df1, df2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbind_fill_+3A_df1">df1</code>, <code id="rbind_fill_+3A_df2">df2</code></td>
<td>
<p>two dataframes with partly matching columns</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fills missing columns with NAs, then rbinds - handy in case one has extra
columns. Used in formant_app(), pitch_app()
</p>

<hr>
<h2 id='readAudio'>Read audio</h2><span id='topic+readAudio'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readAudio(
  x,
  input = checkInputType(x),
  i,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="readAudio_+3A_x">x</code></td>
<td>
<p>audio input (only used for Wave objects or numeric vectors)</p>
</td></tr>
<tr><td><code id="readAudio_+3A_input">input</code></td>
<td>
<p>a list returned by <code><a href="#topic+checkInputType">checkInputType</a></code></p>
</td></tr>
<tr><td><code id="readAudio_+3A_i">i</code></td>
<td>
<p>iteration</p>
</td></tr>
<tr><td><code id="readAudio_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector, rather than an audio file or Wave object)</p>
</td></tr>
<tr><td><code id="readAudio_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector, rather than an
audio file or Wave object)</p>
</td></tr>
<tr><td><code id="readAudio_+3A_from">from</code>, <code id="readAudio_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
</table>

<hr>
<h2 id='reformatAnchors'>Reformat anchors</h2><span id='topic+reformatAnchors'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reformatAnchors(anchors, normalizeTime = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reformatAnchors_+3A_anchors">anchors</code></td>
<td>
<p>a numeric vector of values or a list/dataframe with one column
(value) or two columns (time and value)</p>
</td></tr>
<tr><td><code id="reformatAnchors_+3A_normalizetime">normalizeTime</code></td>
<td>
<p>if TRUE, normalizes anchors$time values to range from 0 to 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Checks that the anchors are formatted in a valid way and expands them to a
standard dataframe with two columns: time and value. NB: works for all
anchors except &quot;noise&quot;, whose anchors have to be scaled by sylLen and are
therefore processed directly in soundgen()
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::reformatAnchors(150)
soundgen:::reformatAnchors(c(150, 200, 220))
soundgen:::reformatAnchors(anchors = list(value=c(150, 200, 220)))
soundgen:::reformatAnchors(anchors = list(time = c(0, 10, 100),
                                          value = c(150, 200, 220)))
# returns NA
soundgen:::reformatAnchors('aha')
## Not run: 
# returns NA with a warning
soundgen:::reformatAnchors(anchors = list(time = c(0, .1, 1),
                                          freq = c(150, 200, 220)))

# throws a warning and rearranges in order of time stamps
soundgen:::reformatAnchors(anchors = list(time = c(0, .8, .7, 1),
                                          value = c(150, 200, 150, 220)))

## End(Not run)
</code></pre>

<hr>
<h2 id='reformatFormants'>Reformat formants</h2><span id='topic+reformatFormants'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reformatFormants(
  formants,
  output = c("all", "freqs")[1],
  keepNonInteger = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reformatFormants_+3A_formants">formants</code></td>
<td>
<p>character string like &quot;aoiu&quot;, numeric vector like &quot;c(500,
1500, 2400)&quot;, or a list with an entry for each formant</p>
</td></tr>
<tr><td><code id="reformatFormants_+3A_output">output</code></td>
<td>
<p>'all' (default) includes times stamps, freqs, amplitudes, and
bandwidths; 'freqs' includes only frequencies</p>
</td></tr>
<tr><td><code id="reformatFormants_+3A_keepnoninteger">keepNonInteger</code></td>
<td>
<p>if FALSE, fractional (anti)formants like 'f1.5' are
removed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Checks that the formants are formatted in a valid way and expands them to a
standard list of dataframes with time, frequency, amplitude, and bandwidth of
each formant specified explicitly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::reformatFormants(NA)
soundgen:::reformatFormants('aau')
soundgen:::reformatFormants(c(500, 1500, 2500))
soundgen:::reformatFormants(list(f1 = 500, f2 = c(1500, 1700)))
soundgen:::reformatFormants(list(
     f1 = list(freq = 800, amp = 30),
     f2 = list(freq = c(1500, 1700, 2200), width = c(100, 150, 175))
))

f = list(f1 = c(550, 600), f2 = c(1100, NA, 1600), f2.5 = 2500, f3 = 3000)
soundgen:::reformatFormants(f)
soundgen:::reformatFormants(f, output = 'freqs')
soundgen:::reformatFormants(f, output = 'freqs', keepNonInteger = FALSE)

soundgen:::reformatFormants(c(500, 1400), output = 'freqs')
soundgen:::reformatFormants(list(f1 = 500, f2 = 1400), output = 'freqs')
soundgen:::reformatFormants(list(f1 = c(570, 750),
  f2 = NA, f3 = c(2400, 2200, NA)), output = 'freqs')
</code></pre>

<hr>
<h2 id='reportCI'>Report CI</h2><span id='topic+reportCI'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reportCI(n, digits = 2, suffix = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reportCI_+3A_n">n</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="reportCI_+3A_digits">digits</code></td>
<td>
<p>number of decimal points to preserve</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a numeric vector or matrix with three elements / columns: fit, lower
quantile from a CI, and upper quantile from a CI. For each row, it prints the
result as fit and CI in square brackets
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = rnorm(100)
soundgen:::reportCI(quantile(n, probs = c(.5, .025, .975)))

a = data.frame(fit = c(3, 5, 7),
               lwr = c(1, 4, 6.5),
               upr = c(5, 6, 7.1))
soundgen:::reportCI(a, 1)
soundgen:::reportCI(a, 1, ' cm')
soundgen:::reportCI(a, 1, '%, 95% CI')
</code></pre>

<hr>
<h2 id='reportTime'>Report time</h2><span id='topic+reportTime'></span>

<h3>Description</h3>

<p>Provides a nicely formatted &quot;estimated time left&quot; in loops plus a summary
upon completion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reportTime(
  i,
  time_start,
  nIter = NULL,
  reportEvery = NULL,
  jobs = NULL,
  prefix = ""
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reportTime_+3A_i">i</code></td>
<td>
<p>current iteration</p>
</td></tr>
<tr><td><code id="reportTime_+3A_time_start">time_start</code></td>
<td>
<p>time when the loop started running</p>
</td></tr>
<tr><td><code id="reportTime_+3A_niter">nIter</code></td>
<td>
<p>total number of iterations</p>
</td></tr>
<tr><td><code id="reportTime_+3A_reportevery">reportEvery</code></td>
<td>
<p>report progress every n iterations</p>
</td></tr>
<tr><td><code id="reportTime_+3A_jobs">jobs</code></td>
<td>
<p>vector of length <code>nIter</code> specifying the relative difficulty
of each iteration. If not NULL, estimated time left takes into account
whether the jobs ahead will take more or less time than the jobs already
completed</p>
</td></tr>
<tr><td><code id="reportTime_+3A_prefix">prefix</code></td>
<td>
<p>a string to print before &quot;Done...&quot;, eg &quot;Chain 1: &quot;</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>time_start = proc.time()
nIter = 100
for (i in 1:nIter) {
  Sys.sleep(i ^ 1.02 / 10000)
  reportTime(i, time_start, nIter,
    jobs = (1:100) ^ 1.02, prefix = 'Chain 1: ')
}
## Not run: 
# Unknown number of iterations:
time_start = proc.time()
for (i in 1:20) {
  Sys.sleep(i ^ 2 / 10000)
  reportTime(i = i, time_start = time_start,
  jobs = (1:20) ^ 2, reportEvery = 5)
}

# when analyzing a bunch of audio files, their size is a good estimate
# of how long each will take to process
time_start = proc.time()
filenames = list.files('~/Downloads/temp', pattern = "*.wav|.mp3",
  full.names = TRUE)
filesizes = file.info(filenames)$size
for (i in seq_along(filenames)) {
  # ...do what you have to do with each file...
  reportTime(i = i, time_start = time_start, nIter = length(filenames),
             jobs = filesizes)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='resample'>Resample a vector</h2><span id='topic+resample'></span>

<h3>Description</h3>

<p>Changes the sampling rate without introducing artefacts like aliasing. Best
for relatively short vectors that require special care (eg pitch contours
that contain NAs, which need to be dropped or preserved) as the algorithm is
too slow for long sounds. Algorithm: to downsample, applies a low-pass
filter, then decimates with <code>approx</code>; to upsample, performs linear
interpolation with <code>approx</code>, then applies a low-pass filter. NAs can be
interpolated or preserved in the output. The length of output is determined,
in order of precedence, by <code>len / mult / samplingRate_new</code>. For simple
vector operations, this is very similar to approx, but the leading and
trailing NAs are also preserved (see examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample(
  x,
  samplingRate = NULL,
  samplingRate_new = NULL,
  mult = NULL,
  len = NULL,
  lowPass = TRUE,
  na.rm = FALSE,
  reportEvery = NULL,
  cores = 1,
  saveAudio = NULL,
  plot = FALSE,
  savePlots = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="resample_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="resample_+3A_samplingrate_new">samplingRate_new</code></td>
<td>
<p>an alternative to <code>mult</code> provided that the old
<code>samplingRate is know</code> (NB: <code>mult</code> takes precedence)</p>
</td></tr>
<tr><td><code id="resample_+3A_mult">mult</code></td>
<td>
<p>multiplier of sampling rate: new sampling rate = old sampling
rate x mult, so 1 = no effect, &gt;1 = upsample, &lt;1 = downsample</p>
</td></tr>
<tr><td><code id="resample_+3A_len">len</code></td>
<td>
<p>if specified, overrides mult and samplingRate_new and simply
returns a vector of length <code>len</code></p>
</td></tr>
<tr><td><code id="resample_+3A_lowpass">lowPass</code></td>
<td>
<p>if TRUE, applies a low-pass filter before decimating or after
upsampling to avoid aliasing</p>
</td></tr>
<tr><td><code id="resample_+3A_na.rm">na.rm</code></td>
<td>
<p>if TRUE, NAs are interpolated, otherwise they are preserved in
the output</p>
</td></tr>
<tr><td><code id="resample_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="resample_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="resample_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id="resample_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="resample_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="resample_+3A_width">width</code>, <code id="resample_+3A_height">height</code>, <code id="resample_+3A_units">units</code>, <code id="resample_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="resample_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1: a short vector with NAs
x = c(NA, 1, 2, 3, NA, NA, 6, 7, 8, NA)

# upsample
resample(x, mult = 3.5, lowPass = FALSE, plot = TRUE)  # just approx
resample(x, mult = 3.5, lowPass = TRUE, plot = TRUE) # low-pass + approx
resample(x, mult = 3.5, lowPass = FALSE, na.rm = TRUE, plot = TRUE)

# downsample
resample(x, mult = 0.5, lowPass = TRUE, plot = TRUE)
resample(x, mult = 0.5, na.rm = TRUE, plot = TRUE)
resample(x, len = 5, na.rm = TRUE, plot = TRUE) # same

# The most important TIP: use resample() for audio files and the internal
# soundgen:::.resample(list(sound = ...)) for simple vector operations because
# it's &gt;1000 times faster. For example:
soundgen:::.resample(list(sound = x), mult = 3.5, lowPass = FALSE)

## Example 2: a sound
silence = rep(0, 10)
samplingRate = 1000
fr = seq(100, 300, length.out = 400)
x = c(silence, sin(cumsum(fr) * 2 * pi / samplingRate), silence)
spectrogram(x, samplingRate)

# downsample
x1 = resample(x, mult = 1 / 2.5)
spectrogram(x1, samplingRate / 2.5)  # no aliasing
# cf:
x1bad = resample(x, mult = 1 / 2.5, lowPass = FALSE)
spectrogram(x1bad, samplingRate / 2.5)  # aliasing

# upsample
x2 = resample(x, mult = 3)
spectrogram(x2, samplingRate * 3)  # nothing above the old Nyquist
# cf:
x2bad = resample(x, mult = 3, lowPass = FALSE)
spectrogram(x2bad, samplingRate * 3)  # high-frequency artefacts

## Not run: 
# Example 3: resample all audio files in a folder to 8000 Hz
resample('~/Downloads/temp', saveAudio = '~/Downloads/temp/sr8000/',
         samplingRate_new = 8000, savePlots = '~/Downloads/temp/sr8000/')

## End(Not run)
</code></pre>

<hr>
<h2 id='reverb'>Reverb &amp; echo</h2><span id='topic+reverb'></span>

<h3>Description</h3>

<p>Adds reverberation and/or echo to a sound. Algorithm for reverb: adds
time-shifted copies of the signal weighted by a decay function, which is
analogous to convoluting the input with a parametric model of some
hypothetical impulse response function. In simple terms: we specify how much
and when the sound rebounds back (as from a wall) and add these time-shifted
copies to the original, optionally with some spectral filtering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reverb(
  x,
  samplingRate = NULL,
  echoDelay = 200,
  echoLevel = -20,
  reverbDelay = 70,
  reverbSpread = 130,
  reverbLevel = -25,
  reverbDensity = 50,
  reverbType = "gaussian",
  filter = list(),
  dynamicRange = 80,
  output = c("audio", "detailed")[1],
  play = FALSE,
  reportEvery = NULL,
  cores = 1,
  saveAudio = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reverb_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="reverb_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="reverb_+3A_echodelay">echoDelay</code></td>
<td>
<p>the delay at which the echo appears, ms</p>
</td></tr>
<tr><td><code id="reverb_+3A_echolevel">echoLevel</code></td>
<td>
<p>the rate at which the echo weakens at each repetition, dB</p>
</td></tr>
<tr><td><code id="reverb_+3A_reverbdelay">reverbDelay</code></td>
<td>
<p>the time of maximum reverb density, ms</p>
</td></tr>
<tr><td><code id="reverb_+3A_reverbspread">reverbSpread</code></td>
<td>
<p>standard deviation of reverb spread around time
<code>reverbDelay</code>, ms</p>
</td></tr>
<tr><td><code id="reverb_+3A_reverblevel">reverbLevel</code></td>
<td>
<p>the maximum amplitude of reverb, dB below input</p>
</td></tr>
<tr><td><code id="reverb_+3A_reverbdensity">reverbDensity</code></td>
<td>
<p>the number of echos or &quot;voices&quot; added</p>
</td></tr>
<tr><td><code id="reverb_+3A_reverbtype">reverbType</code></td>
<td>
<p>so far only &quot;gaussian&quot; has been implemented</p>
</td></tr>
<tr><td><code id="reverb_+3A_filter">filter</code></td>
<td>
<p>(optional) a spectral filter to apply to the created reverb and
echo (see <code>addFormants</code> for acceptable formats)</p>
</td></tr>
<tr><td><code id="reverb_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>the precision with which the reverb and echo are
calculated, dB</p>
</td></tr>
<tr><td><code id="reverb_+3A_output">output</code></td>
<td>
<p>&quot;audio&quot; = returns just the processed audio, &quot;detailed&quot; =
returns a list with reverb window, the added reverb/echo, etc.</p>
</td></tr>
<tr><td><code id="reverb_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the processed audio</p>
</td></tr>
<tr><td><code id="reverb_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="reverb_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="reverb_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full (!) path to folder for saving the processed audio; NULL
= don't save, &rdquo; = same as input folder (NB: overwrites the originals!)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen()
s_rev = reverb(s, 16000)
# playme(s_rev)

## Not run: 
# double echo, no reverb
s1 = reverb(s, samplingRate = 16000, reverbLevel = NULL,
            echoDelay = c(250, 800), echoLevel = c(-15, -25))
# playme(s1)
# spectrogram(s1, 16000, osc = TRUE, ylim = c(0, 4))

# only reverb (indoors)
s2 = reverb(s, samplingRate = 16000, echoDelay = NULL,
            reverbDelay = 70, reverbSpread = 130,
            reverbLevel = -20, reverbDensity = 20)
# playme(s2)
# spectrogram(s2, 16000, osc = TRUE, ylim = c(0, 4))

# reverb (caves)
s3 = reverb(s, samplingRate = 16000, echoDelay = NULL,
            reverbDelay = 600, reverbSpread = 1500,
            reverbLevel = -10, reverbDensity = 100)
# playme(s3)
# spectrogram(s3, 16000, osc = TRUE, ylim = c(0, 4))

# both echo and reverb with high frequencies emphasized
s4 = reverb(s, samplingRate = 16000,
            echoDelay = 250, echoLevel = -20,
            reverbDelay = 70, reverbSpread = 120,
            reverbLevel = -25, reverbDensity = 50,
            filter = list(formants = NULL, lipRad = 3))
# playme(s4)
# spectrogram(s4, 16000, osc = TRUE, ylim = c(0, 4))

# add reverb to a recording
s5 = reverb('~/Downloads/temp260/ut_fear_57-m-tone.wav',
            echoDelay = 850, echoLevel = -40)
# playme(s5, 44100)

# add reverb to all files in a folder, save the result
reverb('~/Downloads/temp2', saveAudio = '~/Downloads/temp2/rvb')

## End(Not run)
</code></pre>

<hr>
<h2 id='rnorm_truncated'>Random draw from a truncated normal distribution</h2><span id='topic+rnorm_truncated'></span>

<h3>Description</h3>

<p><code>rnorm_truncated</code> generates random numbers from a normal distribution
using rnorm(), but forced to remain within the specified low/high bounds. All
proposals outside the boundaries (exclusive) are discarded, and the sampling
is repeated until there are enough values within the specified range. Fully
vectorized. Note: &quot;truncnorm::truncnorm&quot; is much faster, but it only accepts
static low/high boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnorm_truncated(
  n = 1,
  mean = 0,
  sd = 1,
  low = NULL,
  high = NULL,
  roundToInteger = FALSE,
  invalidArgAction = c("adjust", "abort", "ignore")[1]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rnorm_truncated_+3A_n">n</code></td>
<td>
<p>the number of values to return</p>
</td></tr>
<tr><td><code id="rnorm_truncated_+3A_mean">mean</code></td>
<td>
<p>the mean of the normal distribution from which values are
generated (vector of length 1 or n)</p>
</td></tr>
<tr><td><code id="rnorm_truncated_+3A_sd">sd</code></td>
<td>
<p>the standard deviation of the normal distribution from which values
are generated (vector of length 1 or n)</p>
</td></tr>
<tr><td><code id="rnorm_truncated_+3A_low">low</code>, <code id="rnorm_truncated_+3A_high">high</code></td>
<td>
<p>exclusive lower and upper bounds ((vectors of length 1 or n))</p>
</td></tr>
<tr><td><code id="rnorm_truncated_+3A_roundtointeger">roundToInteger</code></td>
<td>
<p>boolean vector of length 1 or n. If TRUE, the
corresponding value is rounded to the nearest integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length n.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::rnorm_truncated(n = 3, mean = 10, sd = 5, low = 7, high = NULL,
  roundToInteger = c(TRUE, FALSE, FALSE))
soundgen:::rnorm_truncated(n = 9, mean = c(10, 50, 100), sd = c(5, 0, 20),
  roundToInteger = TRUE) # vectorized
# in case of conflicts between mean and bounds, either adjust the mean:
soundgen:::rnorm_truncated(n = 3, mean = 10, sd = .1,
  low = c(15, 0, 0), high = c(100, 100, 8), invalidArgAction = 'adjust')
#... or ignore the boundaries
soundgen:::rnorm_truncated(n = 3, mean = 10, sd = .1,
  low = c(15, 0, 0), high = c(100, 100, 8), invalidArgAction = 'ignore')
</code></pre>

<hr>
<h2 id='rnorm_truncated2'>Random draw from a truncated normal distribution</h2><span id='topic+rnorm_truncated2'></span>

<h3>Description</h3>

<p>A simplified version of <code>rnorm_truncated</code>, in which values outside the
bounds are simply reset to the low/high bounds. The shape of the resulting
distribution is no longer Gaussian, but this is obviously much faster. Unlike
in <code>rnorm_truncated</code>, &quot;low&quot; and &quot;high&quot; should be scalars, not vectors
(ie static boundaries).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnorm_truncated2(
  n = 1,
  mean = 0,
  sd = 1,
  low = NULL,
  high = NULL,
  roundToInteger = FALSE,
  invalidArgAction = c("adjust", "abort", "ignore")[1]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rnorm_truncated2_+3A_n">n</code></td>
<td>
<p>the number of values to return</p>
</td></tr>
<tr><td><code id="rnorm_truncated2_+3A_mean">mean</code></td>
<td>
<p>the mean of the normal distribution from which values are
generated (vector of length 1 or n)</p>
</td></tr>
<tr><td><code id="rnorm_truncated2_+3A_sd">sd</code></td>
<td>
<p>the standard deviation of the normal distribution from which values
are generated (vector of length 1 or n)</p>
</td></tr>
<tr><td><code id="rnorm_truncated2_+3A_low">low</code>, <code id="rnorm_truncated2_+3A_high">high</code></td>
<td>
<p>exclusive lower and upper bounds (both of length 1)</p>
</td></tr>
<tr><td><code id="rnorm_truncated2_+3A_roundtointeger">roundToInteger</code></td>
<td>
<p>boolean vector of length 1 or n. If TRUE, the
corresponding value is rounded to the nearest integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length n.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hist(soundgen:::rnorm_truncated2(n = 100, mean = 10, sd = 5, low = 7, high = NULL,
  roundToInteger = c(TRUE, FALSE, FALSE)))
hist(soundgen:::rnorm_truncated2(n = 100, mean = c(10, 50, 100), sd = c(5, 0, 20),
  roundToInteger = TRUE)) # vectorized
# in case of conflicts between mean and bounds, either sample at random
# between the boundaries...
hist(soundgen:::rnorm_truncated2(n = 100, mean = 10, sd = .1,
  low = 10, high = 15, invalidArgAction = 'adjust'))
#... or ignore the boundaries
hist(soundgen:::rnorm_truncated2(n = 100, mean = 10, sd = .1,
  low = 15, high = 100, invalidArgAction = 'ignore'))
soundgen:::rnorm_truncated2(n = 6, mean = c(0, 0, 0, 0, 0, 3),
  sd = .05, low = 0, high = 6)
</code></pre>

<hr>
<h2 id='sampleModif'>sampleModif</h2><span id='topic+sampleModif'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleModif(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleModif_+3A_x">x</code></td>
<td>
<p>vector</p>
</td></tr>
<tr><td><code id="sampleModif_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code>sample</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Same as <code><a href="base.html#topic+sample">sample</a></code>, but without defaulting to x = 1:x if
length(x) = 1. See
https://stackoverflow.com/questions/7547758/using-sample-with-sample-space-size-1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::sampleModif(x = 3, n = 1)
# never returns 1 or 2: cf. sample(x = 3, size = 1)
</code></pre>

<hr>
<h2 id='scaleNoiseAnchors'>Scale noise anchors</h2><span id='topic+scaleNoiseAnchors'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaleNoiseAnchors(noiseTime, sylLen_old, sylLen_new)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scaleNoiseAnchors_+3A_noisetime">noiseTime</code></td>
<td>
<p>vector of time points at which noise anchors are defined</p>
</td></tr>
<tr><td><code id="scaleNoiseAnchors_+3A_syllen_old">sylLen_old</code></td>
<td>
<p>syllable length relative to which the timing of noise anchors is
specified</p>
</td></tr>
<tr><td><code id="scaleNoiseAnchors_+3A_syllen_new">sylLen_new</code></td>
<td>
<p>the new syllable length</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Scales a dataframe containing noise anchors so as to preserve the timing of
positive anchors relative to the new syllable duration. Negative time anchors
are not changed: the pre-aspiration length is constant, regardless of the
actual syllable duration. Time anchors from 0 to sylLen are proportional to
the actual syllable duration re the average expected duration (which the user
sees in the UI when choosing time anchors). Time anchors beyond sylLen are
scaled to preserve post-aspiration duration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>noiseTime = c(-20, 50, 120)
soundgen:::scaleNoiseAnchors(noiseTime, sylLen_old = 100, sylLen_new = 200)
soundgen:::scaleNoiseAnchors(noiseTime, sylLen_old = 100, sylLen_new = 50)
soundgen:::scaleNoiseAnchors(noiseTime, sylLen_old = 200, sylLen_new = 300)
</code></pre>

<hr>
<h2 id='scaleSPL'>Scale SPL</h2><span id='topic+scaleSPL'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaleSPL(x, scale = NULL, SPL_measured = 70, Pref = 2e-05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scaleSPL_+3A_x">x</code></td>
<td>
<p>numeric vector ranging from -1 to +1</p>
</td></tr>
<tr><td><code id="scaleSPL_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="scaleSPL_+3A_spl_measured">SPL_measured</code></td>
<td>
<p>sound pressure level at which the sound is presented, dB</p>
</td></tr>
<tr><td><code id="scaleSPL_+3A_pref">Pref</code></td>
<td>
<p>reference pressure, Pa (currently has no effect on the estimate)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Converts a sound from SPL on any scale to a desired level of dB SPL.
See Timoney et al. (2004) &quot;Implementing loudness models in MATLAB&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound = rnorm(100) * getSmoothContour(c(0, 1, 0), len = 100)
sound = sound / max(abs(sound))
# plot(sound, type = 'l')
sound_scaled = soundgen:::scaleSPL(sound, Pref = 2e-1)
plot(sound_scaled, type = 'l')

sound2 = sound / 3
range(soundgen:::scaleSPL(sound2, scale = NULL))
range(soundgen:::scaleSPL(sound2, scale = 1))
</code></pre>

<hr>
<h2 id='schwa'>Schwa-related formant conversion</h2><span id='topic+schwa'></span>

<h3>Description</h3>

<p>This function performs several conceptually related types of conversion of
formant frequencies in relation to the neutral schwa sound based on the
one-tube model of the vocal tract. This is useful for speaker normalization
because absolute formant frequencies measured in Hz depend strongly on
overall vocal tract length (VTL). For example, adult men vs. children or
grizzly bears vs. dog puppies have very different formant spaces in Hz, but
it is possible to define a VTL-normalized formant space that is applicable to
all species and sizes. Case 1: if we know vocal tract length (VTL) but not
formant frequencies, <code>schwa()</code> estimates formants corresponding to a
neutral schwa sound in this vocal tract, assuming that it is perfectly
cylindrical. Case 2: if we know the frequencies of a few lower formants,
<code>schwa()</code> estimates the deviation of observed formant frequencies from
the neutral values expected in a perfectly cylindrical vocal tract (based on
the VTL as specified or as estimated from formant dispersion). Case 3: if we
want to generate a sound with particular relative formant frequencies (e.g.
high F1 and low F2 relative to the schwa for this vocal tract),
<code>schwa()</code> calculates the corresponding formant frequencies in Hz. See
examples below for an illustration of these three suggested uses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>schwa(
  formants = NULL,
  vocalTract = NULL,
  formants_relative = NULL,
  nForm = 8,
  interceptZero = TRUE,
  tube = c("closed-open", "open-open")[1],
  speedSound = 35400,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="schwa_+3A_formants">formants</code></td>
<td>
<p>a numeric vector of observed (measured) formant frequencies,
Hz</p>
</td></tr>
<tr><td><code id="schwa_+3A_vocaltract">vocalTract</code></td>
<td>
<p>the length of vocal tract, cm</p>
</td></tr>
<tr><td><code id="schwa_+3A_formants_relative">formants_relative</code></td>
<td>
<p>a numeric vector of target relative formant
frequencies, % deviation from schwa (see examples)</p>
</td></tr>
<tr><td><code id="schwa_+3A_nform">nForm</code></td>
<td>
<p>the number of formants to estimate (integer)</p>
</td></tr>
<tr><td><code id="schwa_+3A_interceptzero">interceptZero</code></td>
<td>
<p>if TRUE, forces the regression curve to pass through the
origin. This reduces the influence of highly variable lower formants, but
we have to commit to a particular model of the vocal tract: closed-open or
open-open/closed-closed (method = &quot;regression&quot; only)</p>
</td></tr>
<tr><td><code id="schwa_+3A_tube">tube</code></td>
<td>
<p>the vocal tract is assumed to be a cylindrical tube that is
either &quot;closed-open&quot; or &quot;open-open&quot; (same as closed-closed)</p>
</td></tr>
<tr><td><code id="schwa_+3A_speedsound">speedSound</code></td>
<td>
<p>speed of sound in warm air, cm/s. Stevens (2000) &quot;Acoustic
phonetics&quot;, p. 138</p>
</td></tr>
<tr><td><code id="schwa_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots vowel quality in speaker-normalized F1-F2 space</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: the expected formant dispersion is given by <code class="reqn">(2 *
formant_number - 1) * speedSound / (4 * formant_frequency)</code> for a closed-open
tube (mouth open) and <code class="reqn">formant_number * speedSound / (2 *
formant_frequency)</code> for an open-open or closed-closed tube. F1 is schwa is
expected at half the value of formant dispersion. See e.g. Stevens (2000)
&quot;Acoustic phonetics&quot;, p. 139. Basically, we estimate vocal tract length and
see if each formant is higher or lower than expected for this vocal tract.
For this to work, we have to know either the frequencies of enough formants
(not just the first two) or the true length of the vocal tract. See also
<code><a href="#topic+estimateVTL">estimateVTL</a></code> on the algorithm for estimating formant dispersion
if VTL is not known (note that <code>schwa</code> calls <code><a href="#topic+estimateVTL">estimateVTL</a></code>
with the option <code>method = 'regression'</code>).
</p>


<h3>Value</h3>

<p>Returns a list with the following components: </p>

<dl>
<dt>vtl_measured</dt><dd><p>VTL as provided by the user, cm</p>
</dd>
<dt>vocalTract_apparent</dt><dd><p>VTL estimated based on formants frequencies
provided by the user, cm</p>
</dd>
<dt>formantDispersion</dt><dd><p>average distance between formants, Hz</p>
</dd>
<dt>ff_measured</dt><dd><p>formant frequencies as
provided by the user, Hz</p>
</dd>
<dt>ff_schwa</dt><dd><p>formant frequencies corresponding
to a neutral schwa sound in this vocal tract, Hz</p>
</dd>
<dt>ff_theoretical</dt><dd><p>formant frequencies corresponding to the
user-provided relative formant frequencies, Hz</p>
</dd>
<dt>ff_relative</dt><dd><p>deviation of formant frequencies from those expected for
a schwa, % (e.g. if the first ff_relative is -25, it means that F1 is 25%
lower than expected for a schwa in this vocal tract)</p>
</dd>
<dt>ff_relative_semitones</dt><dd><p>deviation of formant frequencies from those
expected for a schwa, semitones. Like <code>ff_relative</code>, this metric is
invariant to vocal tract length, but the variance tends to be greater for
lower vs. higher formants</p>
</dd>
<dt>ff_relative_dF</dt><dd><p>deviation of formant frequencies from those expected
for a schwa, proportion of formant spacing (dF). Unlike <code>ff_relative</code>
and <code>ff_relative_semitones</code>, this metric has similar variance for
lower and higher formants</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+estimateVTL">estimateVTL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## CASE 1: known VTL
# If vocal tract length is known, we calculate expected formant frequencies
schwa(vocalTract = 17.5)
schwa(vocalTract = 13, nForm = 5)
schwa(vocalTract = 13, nForm = 5, tube = 'open-open')

## CASE 2: known (observed) formant frequencies
# Let's take formant frequencies in four vocalizations, namely
# (/a/, /i/, /mmm/, /roar/) by the same male speaker:
formants_a = c(860, 1430, 2900, NA, 5200)  # NAs are OK - here F4 is unknown
s_a = schwa(formants = formants_a, plot = TRUE)
s_a
# We get an estimate of VTL (s_a$vtl_apparent),
#   same as with estimateVTL(formants_a)
# We also get theoretical schwa formants: s_a$ff_schwa
# And we get the difference (% and semitones) in observed vs expected
#   formant frequencies: s_a[c('ff_relative', 'ff_relative_semitones')]
# [a]: F1 much higher than expected, F2 slightly lower (see plot)

formants_i = c(300, 2700, 3400, 4400, 5300, 6400)
s_i = schwa(formants = formants_i, plot = TRUE)
s_i
# The apparent VTL is slightly smaller (14.5 cm)
# [i]: very low F1, very high F2

formants_mmm = c(1200, 2000, 2800, 3800, 5400, 6400)
schwa(formants_mmm, tube = 'closed-closed', plot = TRUE)
# ~schwa, but with a closed mouth

formants_roar = c(550, 1000, 1460, 2280, 3350,
                  4300, 4900, 5800, 6900, 7900)
s_roar = schwa(formants = formants_roar, plot = TRUE)
s_roar
# Note the enormous apparent VTL (22.5 cm!)
# (lowered larynx and rounded lips exaggerate the apparent size)
# s_roar$ff_relative: high F1 and low F2-F4

schwa(formants = formants_roar[1:4], plot = TRUE)
# based on F1-F4, apparent VTL is almost 28 cm!
# Since the lowest formants are the most salient,
# the apparent size is exaggerated even further

# If you know VTL, a few lower formants are enough to get
#   a good estimate of the relative formant values:
schwa(formants = formants_roar[1:4], vocalTract = 19, plot = TRUE)
# NB: in this case theoretical and relative formants are calculated
#  based on user-provided VTL (vtl_measured) rather than vtl_apparent

## CASE 3: from relative to absolute formant frequencies
# Say we want to generate a vowel sound with F1 20% below schwa
#    and F2 40% above schwa, with VTL = 15 cm
s = schwa(formants_relative = c(-20, 40), vocalTract = 15, plot = TRUE)
# s$ff_schwa gives formant frequencies for a schwa, while
#   s$ff_theoretical gives formant frequencies for a sound with
#   target relative formant values (low F1, high F2)
schwa(formants = s$ff_theoretical)
</code></pre>

<hr>
<h2 id='segment'>Segment a sound</h2><span id='topic+segment'></span>

<h3>Description</h3>

<p>Finds syllables and bursts separated by background noise in long recordings
(up to 1-2 hours of audio per file). Syllables are defined as continuous
segments that seem to be different from noise based on amplitude and/or
spectral similarity thresholds. Bursts are defined as local maxima in signal
envelope that are high enough both in absolute terms (relative to the global
maximum) and with respect to the surrounding region (relative to local
minima). See vignette('acoustic_analysis', package = 'soundgen') for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segment(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  shortestSyl = 40,
  shortestPause = 40,
  method = c("env", "spec", "mel")[3],
  propNoise = NULL,
  SNR = NULL,
  noiseLevelStabWeight = c(1, 0.25),
  windowLength = 40,
  step = NULL,
  overlap = 80,
  reverbPars = list(reverbDelay = 70, reverbSpread = 130, reverbLevel = -35,
    reverbDensity = 50),
  interburst = NULL,
  peakToTrough = SNR + 3,
  troughLocation = c("left", "right", "both", "either")[4],
  summaryFun = c("median", "sd"),
  maxDur = 30,
  reportEvery = NULL,
  cores = 1,
  plot = FALSE,
  savePlots = NULL,
  saveAudio = NULL,
  addSilence = 50,
  main = NULL,
  xlab = "",
  ylab = "Signal, dB",
  showLegend = FALSE,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  maxPoints = c(1e+05, 5e+05),
  specPlot = list(colorTheme = "bw"),
  contourPlot = list(lty = 1, lwd = 2, col = "green"),
  sylPlot = list(lty = 1, lwd = 2, col = "blue"),
  burstPlot = list(pch = 8, cex = 3, col = "red"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="segment_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="segment_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="segment_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="segment_+3A_from">from</code>, <code id="segment_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="segment_+3A_shortestsyl">shortestSyl</code></td>
<td>
<p>minimum acceptable length of syllables, ms</p>
</td></tr>
<tr><td><code id="segment_+3A_shortestpause">shortestPause</code></td>
<td>
<p>minimum acceptable break between syllables, ms
(syllables separated by shorter pauses are merged)</p>
</td></tr>
<tr><td><code id="segment_+3A_method">method</code></td>
<td>
<p>the signal used to search for syllables: 'env' =
Hilbert-transformed amplitude envelope, 'spec' = spectrogram, 'mel' =
mel-transformed spectrogram (see tuneR::melfcc)</p>
</td></tr>
<tr><td><code id="segment_+3A_propnoise">propNoise</code></td>
<td>
<p>the proportion of non-zero sound assumed to represent
background noise, 0 to 1 (note that complete silence is not considered, so
padding with silence won't affect the algorithm)</p>
</td></tr>
<tr><td><code id="segment_+3A_snr">SNR</code></td>
<td>
<p>expected signal-to-noise ratio (dB above noise), which determines
the threshold for syllable detection. The meaning of &quot;dB&quot; here is
approximate since the &quot;signal&quot; may be different from sound intensity</p>
</td></tr>
<tr><td><code id="segment_+3A_noiselevelstabweight">noiseLevelStabWeight</code></td>
<td>
<p>a vector of length 2 specifying the relative
weights of the overall signal level vs. stability when attempting to
automatically locate the regions that represent noise. Increasing the
weight of stability tends to accentuate the beginning and end of each
syllable.</p>
</td></tr>
<tr><td><code id="segment_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="segment_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="segment_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="segment_+3A_reverbpars">reverbPars</code></td>
<td>
<p>parameters passed on to <code><a href="#topic+reverb">reverb</a></code> to attempt to
cancel the effects of reverberation or echo, which otherwise tend to merge
short and loud segments like rapid barks</p>
</td></tr>
<tr><td><code id="segment_+3A_interburst">interburst</code></td>
<td>
<p>minimum time between two consecutive bursts (ms). Defaults
to the average detected <code>(syllable + pause) / 2</code></p>
</td></tr>
<tr><td><code id="segment_+3A_peaktotrough">peakToTrough</code></td>
<td>
<p>to qualify as a burst, a local maximum has to be at least
<code>peakToTrough</code> dB above the left and/or right local trough(s)
(controlled by <code>troughLocation</code>) over the analysis window (controlled
by <code>interburst</code>). Defaults to SNR + 3 dB</p>
</td></tr>
<tr><td><code id="segment_+3A_troughlocation">troughLocation</code></td>
<td>
<p>should local maxima be compared to the trough on the
left and/or right of it? Values: 'left', 'right', 'both', 'either'</p>
</td></tr>
<tr><td><code id="segment_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic;
see <code><a href="#topic+analyze">analyze</a></code></p>
</td></tr>
<tr><td><code id="segment_+3A_maxdur">maxDur</code></td>
<td>
<p>long files are split into chunks <code>maxDur</code> s in duration to
avoid running out of RAM; the outputs for all fragments are glued together,
but plotting is switched off. Note that noise profile is estimated in each
chunk separately, so set it low if the background noise is highly variable</p>
</td></tr>
<tr><td><code id="segment_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="segment_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="segment_+3A_plot">plot</code></td>
<td>
<p>if TRUE, produces a segmentation plot</p>
</td></tr>
<tr><td><code id="segment_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="segment_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id="segment_+3A_addsilence">addSilence</code></td>
<td>
<p>if syllables are saved as separate audio files, they can be
padded with some silence (ms)</p>
</td></tr>
<tr><td><code id="segment_+3A_xlab">xlab</code>, <code id="segment_+3A_ylab">ylab</code>, <code id="segment_+3A_main">main</code></td>
<td>
<p>main plotting parameters</p>
</td></tr>
<tr><td><code id="segment_+3A_showlegend">showLegend</code></td>
<td>
<p>if TRUE, shows a legend for thresholds</p>
</td></tr>
<tr><td><code id="segment_+3A_width">width</code>, <code id="segment_+3A_height">height</code>, <code id="segment_+3A_units">units</code>, <code id="segment_+3A_res">res</code></td>
<td>
<p>parameters passed to
<code><a href="grDevices.html#topic+png">png</a></code> if the plot is saved</p>
</td></tr>
<tr><td><code id="segment_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id="segment_+3A_specplot">specPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the spectrogram
(if <code>method = 'spec' or 'mel'</code>); set to NULL to hide the spectrogram</p>
</td></tr>
<tr><td><code id="segment_+3A_contourplot">contourPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the signal
contour used to detect syllables (see details)</p>
</td></tr>
<tr><td><code id="segment_+3A_sylplot">sylPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the syllables</p>
</td></tr>
<tr><td><code id="segment_+3A_burstplot">burstPlot</code></td>
<td>
<p>a list of graphical parameters for displaying the bursts</p>
</td></tr>
<tr><td><code id="segment_+3A_...">...</code></td>
<td>
<p>other graphical parameters passed to graphics::plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: for each chunk at most <code>maxDur</code> long, first the audio
recording is partitioned into signal and noise regions: the quietest and most
stable regions are located, and noise threshold is defined from a
user-specified proportion of noise in the recording (<code>propNoise</code>) or, if
<code>propNoise = NULL</code>, from the lowest local maximum in the density
function of a weighted product of amplitude and stability (that is, we assume
that quiet and stable regions are likely to represent noise). Once we know
what the noise looks like - in terms of its typical amplitude and/or spectrum
- we derive signal contour as its difference from noise at each time point.
If <code>method = 'env'</code>, this is Hilbert transform minus noise, and if
<code>method = 'spec' or 'mel'</code>, this is the inverse of cosine similarity
between the spectrum of each frame and the estimated spectrum of noise
weighted by amplitude. By default, signal-to-noise ratio (SNR) is estimated
as half-median of above-noise signal, but it is recommended that this
parameter is adjusted by hand to suit the purposes of segmentation, as it is
the key setting that controls the balance between false negatives (missing
faint signals) and false positives (hallucinating signals that are actually
noise). Note also that effects of echo or reverberation can be taken into
account: syllable detection threshold may be raised following powerful
acoustic bursts with the help of the <code>reverbPars</code> argument. At the final
stage, continuous &quot;islands&quot; SNR dB above noise level are detected as
syllables, and &quot;peaks&quot; on the islands are detected as bursts. The algorithm
is very flexible, but the parameters may be hard to optimize by hand. If you
have an annotated sample of the sort of audio you are planning to analyze,
with syllables and/or bursts counted manually, you can use it for automatic
optimization of control parameters (see <code><a href="#topic+optimizePars">optimizePars</a></code>).
</p>


<h3>Value</h3>

<p>If <code>summaryFun = NULL</code>, returns returns a list containing full
stats on each syllable and burst (one row per syllable and per burst),
otherwise returns only a dataframe with one row per file - a summary of the
number and spacing of syllables and vocal bursts.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+analyze">analyze</a></code>  <code><a href="#topic+ssm">ssm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound = soundgen(nSyl = 4, sylLen = 100, pauseLen = 70,
                 attackLen = 20, amplGlobal = c(0, -20),
                 pitch = c(368, 284), temperature = .001)
# add noise so SNR decreases from 20 to 0 dB from syl1 to syl4
sound = sound + runif(length(sound), -10 ^ (-20 / 20), 10 ^ (-20 / 20))
# osc(sound, samplingRate = 16000, dB = TRUE)
# spectrogram(sound, samplingRate = 16000, osc = TRUE)
# playme(sound, samplingRate = 16000)

s = segment(sound, samplingRate = 16000, plot = TRUE)
s

# customizing the plot
segment(sound, samplingRate = 16000, plot = TRUE,
        sylPlot = list(lty = 2, col = 'gray20'),
        burstPlot = list(pch = 16, col = 'blue'),
        specPlot = list(col = rev(heat.colors(50))),
        xlab = 'Some custom label', cex.lab = 1.2,
        showLegend = TRUE,
        main = 'My awesome plot')
## Not run: 
# set SNR manually to control detection threshold
s = segment(sound, samplingRate = 16000, SNR = 1, plot = TRUE)

# Download 260 sounds from the supplements to Anikin &amp; Persson (2017) at
# http://cogsci.se/publications.html
# unzip them into a folder, say '~/Downloads/temp'
myfolder = '~/Downloads/temp260'  # 260 .wav files live here
s = segment(myfolder, propNoise = .05, SNR = 3)

# Check accuracy: import a manual count of syllables (our "key")
key = segmentManual  # a vector of 260 integers
trial = as.numeric(s$summary$nBursts)
cor(key, trial, use = 'pairwise.complete.obs')
boxplot(trial ~ as.integer(key), xlab='key')
abline(a=0, b=1, col='red')

# or look at the detected syllables instead of bursts:
cor(key, s$summary$nSyl, use = 'pairwise.complete.obs')

## End(Not run)
</code></pre>

<hr>
<h2 id='segmentManual'>Manual counts of syllables in 260 sounds</h2><span id='topic+segmentManual'></span>

<h3>Description</h3>

<p>A vector of the number of syllables in the corpus of 260 human non-linguistic
emotional vocalizations from Anikin &amp; Persson (2017). The corpus can be
downloaded from http://cogsci.se/publications.html
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segmentManual
</code></pre>


<h3>Format</h3>

<p>An object of class <code>numeric</code> of length 260.
</p>

<hr>
<h2 id='selfsim'>Compute self-similarity</h2><span id='topic+selfsim'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selfsim(
  m,
  norm = FALSE,
  simil = c("cosine", "cor")[1],
  win = 1,
  sparse = FALSE,
  kernelSize = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selfsim_+3A_m">m</code></td>
<td>
<p>input matrix such as a spectrogram</p>
</td></tr>
<tr><td><code id="selfsim_+3A_norm">norm</code></td>
<td>
<p>if TRUE, the spectrum of each STFT frame is normalized</p>
</td></tr>
<tr><td><code id="selfsim_+3A_simil">simil</code></td>
<td>
<p>method for comparing frames: &quot;cosine&quot; = cosine similarity, &quot;cor&quot;
= Pearson's correlation</p>
</td></tr>
<tr><td><code id="selfsim_+3A_win">win</code></td>
<td>
<p>the length of window for averaging self-similarity, frames</p>
</td></tr>
<tr><td><code id="selfsim_+3A_sparse">sparse</code></td>
<td>
<p>if TRUE, the entire SSM is not calculated, but only the central
region needed to extract the novelty contour (speeds up the processing)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Called by <code><a href="#topic+ssm">ssm</a></code>.
</p>


<h3>Value</h3>

<p>Returns a square self-similarity matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m = matrix(rnorm(40), nrow = 5)
soundgen:::selfsim(m, sparse = TRUE, kernelSize = 2)
</code></pre>

<hr>
<h2 id='semitonesToHz'>Convert semitones to Hz</h2><span id='topic+semitonesToHz'></span>

<h3>Description</h3>

<p>Converts from semitones above C-5 (~0.5109875 Hz) or another reference
frequency to Hz. See <code><a href="#topic+HzToSemitones">HzToSemitones</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semitonesToHz(s, ref = 0.5109875)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="semitonesToHz_+3A_s">s</code></td>
<td>
<p>vector or matrix of frequencies (semitones above C0)</p>
</td></tr>
<tr><td><code id="semitonesToHz_+3A_ref">ref</code></td>
<td>
<p>frequency of the reference value (defaults to C-5, 0.51 Hz)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+HzToSemitones">HzToSemitones</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>semitonesToHz(c(117, 105, 60))
</code></pre>

<hr>
<h2 id='shiftFormants'>Shift formants</h2><span id='topic+shiftFormants'></span>

<h3>Description</h3>

<p>Raises or lowers formants (resonance frequencies), changing the voice quality
or timbre of the sound without changing its pitch, statically or dynamically.
Note that this is only possible when the fundamental frequency f0 is lower
than the formant frequencies. For best results, <code>freqWindow</code> should be
no lower than f0 and no higher than formant bandwidths. Obviously, this is
impossible for many signals, so just try a few reasonable values, like ~200
Hz for speech. If <code>freqWindow</code> is not specified, soundgen sets it to the
average detected f0, which is slow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shiftFormants(
  x,
  multFormants,
  samplingRate = NULL,
  freqWindow = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = NULL,
  overlap = 75,
  wn = "gaussian",
  interpol = c("approx", "spline")[1],
  normalize = c("max", "orig", "none")[2],
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shiftFormants_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_multformants">multFormants</code></td>
<td>
<p>1 = no change, &gt;1 = raise formants (eg 1.1 = 10% up, 2 =
one octave up), &lt;1 = lower formants. Anchor format accepted (see
<code><a href="#topic+soundgen">soundgen</a></code>)</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of spectral smoothing window, Hz. Defaults to
detected f0</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_interpol">interpol</code></td>
<td>
<p>the method for interpolating scaled spectra</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_normalize">normalize</code></td>
<td>
<p>&quot;orig&quot; = same as input (default), &quot;max&quot; = maximum possible
peak amplitude, &quot;none&quot; = no normalization</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="shiftFormants_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: phase vocoder. In the frequency domain, we separate the complex
spectrum of each STFT frame into two parts. The &quot;receiver&quot; is the flattened
or smoothed complex spectrum, where smoothing is achieved by obtaining a
smoothed magnitude envelope (the amount of smoothing is controlled by
<code>freqWindow</code>) and then dividing the complex spectrum by this envelope.
This basically removes the formants from the signal. The second component,
&quot;donor&quot;, is a scaled and interpolated version of the same smoothed magnitude
envelope as above - these are the formants shifted up or down. Warping can be
easily implemented instead of simple scaling if nonlinear spectral
transformations are required. We then multiply the &quot;receiver&quot; and &quot;donor&quot;
spectrograms and reconstruct the audio with iSTFT.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shiftPitch">shiftPitch</a></code> <code><a href="#topic+transplantFormants">transplantFormants</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 200, ampl = c(0,-10),
             pitch = c(250, 350), rolloff = c(-9, -15),
             noise = -40,
             formants = 'aii', addSilence = 50)
# playme(s)
s1 = shiftFormants(s, samplingRate = 16000, multFormants = 1.25,
                   freqWindow = 200)
# playme(s1)

## Not run: 
data(sheep, package = 'seewave')  # import a recording from seewave
playme(sheep)
spectrogram(sheep)

# Lower formants by 4 semitones or ~20% = 2 ^ (-4 / 12)
sheep1 = shiftFormants(sheep, multFormants = 2 ^ (-4 / 12), freqWindow = 150)
playme(sheep1, sheep@samp.rate)
spectrogram(sheep1, sheep@samp.rate)

orig = seewave::meanspec(sheep, wl = 128, plot = FALSE)
shifted = seewave::meanspec(sheep1, wl = 128, f = sheep@samp.rate, plot = FALSE)
plot(orig[, 1], log(orig[, 2]), type = 'l')
points(shifted[, 1], log(shifted[, 2]), type = 'l', col = 'blue')

# dynamic change: raise formants at the beginning, lower at the end
sheep2 = shiftFormants(sheep, multFormants = c(1.3, .7), freqWindow = 150)
playme(sheep2, sheep@samp.rate)
spectrogram(sheep2, sheep@samp.rate)

## End(Not run)
</code></pre>

<hr>
<h2 id='shiftPitch'>Shift pitch</h2><span id='topic+shiftPitch'></span>

<h3>Description</h3>

<p>Raises or lowers pitch with or without also shifting the formants (resonance
frequencies) and performing a time-stretch. The three operations (pitch
shift, formant shift, and time stretch) are independent and can be performed
in any combination, statically or dynamically. <code>shiftPitch</code> can also be
used to shift formants without changing pitch or duration, but the dedicated
<code><a href="#topic+shiftFormants">shiftFormants</a></code> is faster for that task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shiftPitch(
  x,
  multPitch = 1,
  multFormants = multPitch,
  timeStretch = 1,
  samplingRate = NULL,
  freqWindow = NULL,
  dynamicRange = 80,
  windowLength = 40,
  step = 2,
  overlap = NULL,
  wn = "gaussian",
  interpol = c("approx", "spline")[1],
  propagation = c("time", "adaptive")[1],
  preserveEnv = NULL,
  transplantEnv_pars = list(windowLength = 10),
  normalize = c("max", "orig", "none")[2],
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shiftPitch_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_multpitch">multPitch</code></td>
<td>
<p>1 = no change, &gt;1 = raise pitch (eg 1.1 = 10% up, 2 = one
octave up), &lt;1 = lower pitch. Anchor format accepted for multPitch /
multFormant / timeStretch (see <code><a href="#topic+soundgen">soundgen</a></code>)</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_multformants">multFormants</code></td>
<td>
<p>1 = no change, &gt;1 = raise formants (eg 1.1 = 10% up, 2 =
one octave up), &lt;1 = lower formants</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_timestretch">timeStretch</code></td>
<td>
<p>1 = no change, &gt;1 = longer, &lt;1 = shorter</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of spectral smoothing window, Hz. Defaults to
detected f0 prior to pitch shifting - see <code><a href="#topic+shiftFormants">shiftFormants</a></code> for
discussion and examples</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_interpol">interpol</code></td>
<td>
<p>the method for interpolating scaled spectra and anchors</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_propagation">propagation</code></td>
<td>
<p>the method for propagating phase: &quot;time&quot; = horizontal
propagation (default), &quot;adaptive&quot; = an experimental implementation of
&quot;vocoder done right&quot; (Prusa &amp; Holighaus 2017)</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_preserveenv">preserveEnv</code></td>
<td>
<p>if TRUE, transplants the amplitude envelope from the
original to the modified sound with <code><a href="#topic+transplantEnv">transplantEnv</a></code>. Defaults
to TRUE if no time stretching is performed and FALSE otherwise</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_transplantenv_pars">transplantEnv_pars</code></td>
<td>
<p>a list of parameters passed on to
<code><a href="#topic+transplantEnv">transplantEnv</a></code> if <code>preserveEnv = TRUE</code></p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_normalize">normalize</code></td>
<td>
<p>&quot;orig&quot; = same as input (default), &quot;max&quot; = maximum possible
peak amplitude, &quot;none&quot; = no normalization</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="shiftPitch_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: phase vocoder. Pitch shifting is accomplished by performing a time
stretch (at present, with horizontal or adaptive phase propagation) followed
by resampling. This shifts both pitch and formants; to preserve the original
formant frequencies or modify them independently of pitch, a variant of
<code><a href="#topic+transplantFormants">transplantFormants</a></code> is performed to &quot;transplant&quot; the original or
scaled formants onto the time-stretched new sound. See Prusa 2017 &quot;Phase
vocoder done right&quot;, Royer 2019 &quot;Pitch-shifting algorithm design and
applications in music&quot;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shiftFormants">shiftFormants</a></code> <code><a href="#topic+transplantFormants">transplantFormants</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 200, ampl = c(0,-10),
             pitch = c(250, 350), rolloff = c(-9, -15),
             noise = -40,
             formants = 'aii', addSilence = 50)
# playme(s)
s1 = shiftPitch(s, samplingRate = 16000, freqWindow = 400,
                multPitch = 1.25, multFormants = .8)
# playme(s1)

## Not run: 
## Dynamic manipulations
# Add a chevron-shaped pitch contour
s2 = shiftPitch(s, samplingRate = 16000, multPitch = c(1.1, 1.3, .8))
playme(s2)

# Time-stretch only the middle
s3 = shiftPitch(s, samplingRate = 16000, timeStretch = list(
  time = c(0, .25, .31, .5, .55, 1),
  value = c(1, 1, 3, 3, 1, 1))
)
playme(s3)


## Various combinations of 3 manipulations
data(sheep, package = 'seewave')  # import a recording from seewave
playme(sheep)
spectrogram(sheep)

# Raise pitch and formants by 3 semitones, shorten by half
sheep1 = shiftPitch(sheep, multPitch = 2 ^ (3 / 12), timeStretch = 0.5)
playme(sheep1, sheep@samp.rate)
spectrogram(sheep1, sheep@samp.rate)

# Just shorten
shiftPitch(sheep, multPitch = 1, timeStretch = 0.25, play = TRUE)

# Raise pitch preserving formants
sheep2 = shiftPitch(sheep, multPitch = 1.2, multFormants = 1, freqWindow = 150)
playme(sheep2, sheep@samp.rate)
spectrogram(sheep2, sheep@samp.rate)

## End(Not run)
</code></pre>

<hr>
<h2 id='silenceSegments'>Silence sound segments</h2><span id='topic+silenceSegments'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silenceSegments(x, samplingRate, na_seg, attackLen = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="silenceSegments_+3A_x">x</code></td>
<td>
<p>sound as a numeric vector</p>
</td></tr>
<tr><td><code id="silenceSegments_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate, Hz</p>
</td></tr>
<tr><td><code id="silenceSegments_+3A_na_seg">na_seg</code></td>
<td>
<p>dataframe containing columns &quot;start_prop&quot; and &quot;end_prop&quot;</p>
</td></tr>
<tr><td><code id="silenceSegments_+3A_attacklen">attackLen</code></td>
<td>
<p>attack length, ms</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fills specified segments with silence (0) and fades in-out the ends of the
silenced segment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = runif(4000) * 2 - 1
s1 = soundgen:::silenceSegments(s, 16000,
       na_seg = data.frame(prop_start = c(.1, .5), prop_end = c(.2, .85)),
       attackLen = c(5, 15))
osc(s1)
</code></pre>

<hr>
<h2 id='sinc'>Sinc</h2><span id='topic+sinc'></span>

<h3>Description</h3>

<p>Sinc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sinc(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sinc_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x = seq(-5, 5, .01); plot(x, soundgen:::sinc(x))
</code></pre>

<hr>
<h2 id='snake'>Snake</h2><span id='topic+snake'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snake(
  pitch,
  pitchCands,
  pitchCert,
  certWeight,
  pitchCenterGravity,
  snakeStep = 0.05,
  snakePlot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="snake_+3A_pitch">pitch</code></td>
<td>
<p>numeric vector representing our best guess at pitch contour,
which we are now attempting to improve by minimizing its elastic tension</p>
</td></tr>
<tr><td><code id="snake_+3A_pitchcands">pitchCands</code></td>
<td>
<p>a matrix of multiple pitch candidates per fft frame. Each
column is one fft frame, each row is one candidate (the last row is always
&quot;manual&quot;)</p>
</td></tr>
<tr><td><code id="snake_+3A_pitchcert">pitchCert</code></td>
<td>
<p>a matrix of the same dimensionality as pitchCands specifying
our certainty in pitch candidates</p>
</td></tr>
<tr><td><code id="snake_+3A_certweight">certWeight</code></td>
<td>
<p>(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve</p>
</td></tr>
<tr><td><code id="snake_+3A_pitchcentergravity">pitchCenterGravity</code></td>
<td>
<p>numeric vector giving the mean of all pitch
candidates per fft frame weighted by our certainty in each of these
candidates</p>
</td></tr>
<tr><td><code id="snake_+3A_snakestep">snakeStep</code></td>
<td>
<p>optimized path through pitch candidates is further
processed to minimize the elastic force acting on pitch contour. To
disable, set <code>snakeStep = 0</code></p>
</td></tr>
<tr><td><code id="snake_+3A_snakeplot">snakePlot</code></td>
<td>
<p>if TRUE, plots the snake</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Internal helper function for postprocessing of pitch contour. Wiggles a snake
along the gradient of internal + external forces. NB: if the snake is run,
the final contour may deviate from the actually measured pitch candidates!
</p>


<h3>Value</h3>

<p>Returns optimized pitch contour (numeric vector of the same length as
<code>pitch</code>).
</p>

<hr>
<h2 id='soundgen'>Generate a sound</h2><span id='topic+soundgen'></span>

<h3>Description</h3>

<p>Generates a bout of one or more syllables with pauses between them. Two basic
components are synthesized: the harmonic component (the sum of sine waves
with frequencies that are multiples of the fundamental frequency) and the
noise component. Both components can be filtered with independently specified
formants. Intonation and amplitude contours can be applied both within each
syllable and across multiple syllables. Suggested application: synthesis of
animal or human non-linguistic vocalizations. For more information, see
<a href="http://cogsci.se/soundgen.html">http://cogsci.se/soundgen.html</a> and vignette('sound_generation', package
= 'soundgen').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soundgen(
  repeatBout = 1,
  nSyl = 1,
  sylLen = 300,
  pauseLen = 200,
  pitch = list(time = c(0, 0.1, 0.9, 1), value = c(100, 150, 135, 100)),
  pitchGlobal = NA,
  glottis = 0,
  temperature = 0.025,
  tempEffects = list(),
  maleFemale = 0,
  creakyBreathy = 0,
  nonlinBalance = 100,
  nonlinRandomWalk = NULL,
  subRatio = 2,
  subFreq = 0,
  subDep = 0,
  subWidth = 10000,
  shortestEpoch = 300,
  jitterLen = 1,
  jitterDep = 0,
  vibratoFreq = 5,
  vibratoDep = 0,
  shimmerDep = 0,
  shimmerLen = 1,
  attackLen = 50,
  rolloff = -9,
  rolloffOct = 0,
  rolloffKHz = -3,
  rolloffParab = 0,
  rolloffParabHarm = 3,
  rolloffExact = NULL,
  lipRad = 6,
  noseRad = 4,
  mouthOpenThres = 0,
  formants = c(860, 1430, 2900),
  formantDep = 1,
  formantDepStoch = 1,
  formantWidth = 1,
  formantCeiling = 2,
  formantLocking = 0,
  vocalTract = NA,
  amDep = 0,
  amFreq = 30,
  amType = c("logistic", "sine")[1],
  amShape = 0,
  noise = NULL,
  formantsNoise = NA,
  rolloffNoise = -4,
  noiseFlatSpec = 1200,
  rolloffNoiseExp = 0,
  noiseAmpRef = c("f0", "source", "filtered")[3],
  mouth = list(time = c(0, 1), value = c(0.5, 0.5)),
  ampl = NA,
  amplGlobal = NA,
  smoothing = list(interpol = c("approx", "spline", "loess")[3], loessSpan = NULL,
    discontThres = 0.05, jumpThres = 0.01),
  samplingRate = 16000,
  windowLength = 50,
  overlap = 75,
  addSilence = 100,
  pitchFloor = 1,
  pitchCeiling = 3500,
  pitchSamplingRate = 16000,
  dynamicRange = 80,
  invalidArgAction = c("adjust", "abort", "ignore")[1],
  plot = FALSE,
  play = FALSE,
  saveAudio = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="soundgen_+3A_repeatbout">repeatBout</code></td>
<td>
<p>number of times the whole bout should be repeated</p>
</td></tr>
<tr><td><code id="soundgen_+3A_nsyl">nSyl</code></td>
<td>
<p>number of syllables in the bout. 'pitchGlobal', 'amplGlobal', and
'formants' span multiple syllables, but not multiple bouts</p>
</td></tr>
<tr><td><code id="soundgen_+3A_syllen">sylLen</code></td>
<td>
<p>average duration of each syllable, ms (vectorized)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_pauselen">pauseLen</code></td>
<td>
<p>average duration of pauses between syllables, ms (can be
negative between bouts: force with invalidArgAction = 'ignore')
(vectorized)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_pitch">pitch</code></td>
<td>
<p>a numeric vector of f0 values in Hz or a dataframe
specifying the time (ms or 0 to 1) and value (Hz) of each anchor, hereafter
&quot;anchor format&quot;. These anchors are used to create a smooth contour of
fundamental frequency f0 (pitch) within one syllable</p>
</td></tr>
<tr><td><code id="soundgen_+3A_pitchglobal">pitchGlobal</code></td>
<td>
<p>unlike <code>pitch</code>, these anchors are
used to create a smooth contour of average f0 across multiple syllables.
The values are in semitones relative to the existing pitch, i.e. 0 = no
change (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_glottis">glottis</code></td>
<td>
<p>anchors for specifying the proportion of a
glottal cycle with closed glottis, % (0 = no modification, 100 = closed
phase as long as open phase); numeric vector or dataframe specifying time
and value (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_temperature">temperature</code></td>
<td>
<p>hyperparameter for regulating the amount of stochasticity
in sound generation</p>
</td></tr>
<tr><td><code id="soundgen_+3A_tempeffects">tempEffects</code></td>
<td>
<p>a list of scaling coefficients regulating the effect of
temperature on particular parameters. To change, specify just those pars
that you want to modify (1 = default, 0 = no stochastic behavior).
<code>amplDep, pitchDep, noiseDep</code>: random fluctuations of user-specified
amplitude / pitch / noise anchors; <code>amplDriftDep</code>: drift of amplitude
mirroring pitch drift; <code>formDisp</code>: dispersion of stochastic formants;
<code>formDrift</code>: formant frequencies; <code>glottisDep</code>: proportion of
glottal cycle with closed glottis; <code>pitchDriftDep</code>: amount of slow
random drift of f0; <code>pitchDriftFreq</code>: frequency of slow random drift
of f0; <code>rolloffDriftDep</code>: drift of rolloff mirroring pitch drift;
<code>specDep</code>: rolloff, rolloffNoise, nonlinear effects, attack;
<code>subDriftDep</code>: drift of subharmonic frequency and bandwidth mirroring
pitch drift; <code>sylLenDep</code>: duration of syllables and pauses</p>
</td></tr>
<tr><td><code id="soundgen_+3A_malefemale">maleFemale</code></td>
<td>
<p>hyperparameter for shifting f0 contour, formants, and
vocalTract to make the speaker appear more male (-1...0) or more female
(0...+1); 0 = no change</p>
</td></tr>
<tr><td><code id="soundgen_+3A_creakybreathy">creakyBreathy</code></td>
<td>
<p>hyperparameter for a rough adjustment of voice quality
from creaky (-1) to breathy (+1); 0 = no change</p>
</td></tr>
<tr><td><code id="soundgen_+3A_nonlinbalance">nonlinBalance</code></td>
<td>
<p>hyperparameter for regulating the (approximate)
proportion of sound with different regimes of pitch effects (none /
subharmonics only / subharmonics and jitter). 0% = no noise; 100% = the
entire sound has jitter + subharmonics. Ignored if temperature = 0</p>
</td></tr>
<tr><td><code id="soundgen_+3A_nonlinrandomwalk">nonlinRandomWalk</code></td>
<td>
<p>a numeric vector specifying the timing of nonliner
regimes: 0 = none, 1 = subharmonics, 2 = subharmonics + jitter + shimmer</p>
</td></tr>
<tr><td><code id="soundgen_+3A_subratio">subRatio</code></td>
<td>
<p>a positive integer giving the ratio of f0 (the main
fundamental) to g0 (a lower frequency): 1 = no subharmonics, 2 = period
doubling regardless of pitch changes, 3 = period tripling, etc; subRatio
overrides subFreq (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_subfreq">subFreq</code></td>
<td>
<p>instead of a specific number of subharmonics (subRatio), we
can specify the approximate g0 frequency (Hz), which is used only if
subRatio = 1 and is adjusted to f0 so f0/g0 is always an integer (anchor
format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_subdep">subDep</code></td>
<td>
<p>the depth of subharmonics relative to the main frequency
component (f0), %. 0: no subharmonics; 100: g0 harmonics are as strong as
the nearest f0 harmonic (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_subwidth">subWidth</code></td>
<td>
<p>Width of subharmonic sidebands - regulates how rapidly
g-harmonics weaken away from f-harmonics: large values like the default
10000 means that all g0 harmonics are equally strong (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_shortestepoch">shortestEpoch</code></td>
<td>
<p>minimum duration of each epoch with unchanging
subharmonics regime or formant locking, in ms</p>
</td></tr>
<tr><td><code id="soundgen_+3A_jitterlen">jitterLen</code></td>
<td>
<p>duration of stable periods between pitch jumps, ms. Use a
low value for harsh noise, a high value for irregular vibrato or shaky
voice (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_jitterdep">jitterDep</code></td>
<td>
<p>cycle-to-cycle random pitch variation, semitones (anchor
format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_vibratofreq">vibratoFreq</code></td>
<td>
<p>the rate of regular pitch modulation, or vibrato, Hz
(anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_vibratodep">vibratoDep</code></td>
<td>
<p>the depth of vibrato, semitones (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_shimmerdep">shimmerDep</code></td>
<td>
<p>random variation in amplitude between individual glottal
cycles (0 to 100% of original amplitude of each cycle) (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_shimmerlen">shimmerLen</code></td>
<td>
<p>duration of stable periods between amplitude jumps, ms. Use
a low value for harsh noise, a high value for shaky voice (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_attacklen">attackLen</code></td>
<td>
<p>duration of fade-in / fade-out at each end of syllables and
noise (ms): a vector of length 1 (symmetric) or 2 (separately for fade-in
and fade-out)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloff">rolloff</code></td>
<td>
<p>basic rolloff from lower to upper harmonics, db/octave
(exponential decay). All rolloff parameters are in anchor format. See
<code><a href="#topic+getRolloff">getRolloff</a></code> for more details</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffoct">rolloffOct</code></td>
<td>
<p>basic rolloff changes from lower to upper harmonics
(regardless of f0) by <code>rolloffOct</code> dB/oct. For example, we can get
steeper rolloff in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffkhz">rolloffKHz</code></td>
<td>
<p>rolloff changes linearly with f0 by <code>rolloffKHz</code>
dB/kHz. For ex., -6 dB/kHz gives a 6 dB steeper basic rolloff as f0 goes up
by 1000 Hz</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffparab">rolloffParab</code></td>
<td>
<p>an optional quadratic term affecting only the first
<code>rolloffParabHarm</code> harmonics. The middle harmonic of the first
<code>rolloffParabHarm</code> harmonics is amplified or dampened by
<code>rolloffParab</code> dB relative to the basic exponential decay</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffparabharm">rolloffParabHarm</code></td>
<td>
<p>the number of harmonics affected by
<code>rolloffParab</code></p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffexact">rolloffExact</code></td>
<td>
<p>user-specified exact strength of harmonics: a vector or
matrix with one row per harmonic, scale 0 to 1 (overrides all other rolloff
parameters)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_liprad">lipRad</code></td>
<td>
<p>the effect of lip radiation on source spectrum, dB/oct (the
default of +6 dB/oct produces a high-frequency boost when the mouth is
open)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_noserad">noseRad</code></td>
<td>
<p>the effect of radiation through the nose on source spectrum,
dB/oct (the alternative to <code>lipRad</code> when the mouth is closed)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_mouthopenthres">mouthOpenThres</code></td>
<td>
<p>open the lips (switch from nose radiation to lip
radiation) when the mouth is open <code>&gt;mouthOpenThres</code>, 0 to 1</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formants">formants</code></td>
<td>
<p>either a character string referring to default presets for
speaker &quot;M1&quot; (implemented: &quot;aoieu0&quot;) or a list of formant times,
frequencies, amplitudes, and bandwidths (see examples). NA or NULL means no
formants, only lip radiation. Time stamps for formants and mouthOpening can
be specified in ms relative to <code>sylLen</code> or on a scale of [0, 1]. See
<code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code> for more details</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formantdep">formantDep</code></td>
<td>
<p>scale factor of formant amplitude (1 = no change relative
to amplitudes in <code>formants</code>)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formantdepstoch">formantDepStoch</code></td>
<td>
<p>the amplitude of additional stochastic formants added
above the highest specified formant, dB (only if temperature &gt; 0)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formantwidth">formantWidth</code></td>
<td>
<p>scale factor of formant bandwidth (1 = no change)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formantceiling">formantCeiling</code></td>
<td>
<p>frequency to which stochastic formants are calculated,
in multiples of the Nyquist frequency; increase up to ~10 for long vocal
tracts to avoid losing energy in the upper part of the spectrum</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formantlocking">formantLocking</code></td>
<td>
<p>the approximate proportion of sound in which one of the
harmonics is locked to the nearest formant, 0 = none, 1 = the entire sound
(anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_vocaltract">vocalTract</code></td>
<td>
<p>the length of vocal tract, cm. Used for calculating formant
dispersion (for adding extra formants) and formant transitions as the mouth
opens and closes. If <code>NULL</code> or <code>NA</code>, the length is estimated
based on specified formant frequencies, if any (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_amdep">amDep</code></td>
<td>
<p>amplitude modulation (AM) depth, %. 0: no change; 100: AM with
amplitude range equal to the dynamic range of the sound (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_amfreq">amFreq</code></td>
<td>
<p>AM frequency, Hz (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_amtype">amType</code></td>
<td>
<p>&quot;sine&quot; = sinusoidal, &quot;logistic&quot; = logistic (default)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_amshape">amShape</code></td>
<td>
<p>ignore if amType = &quot;sine&quot;, otherwise determines the shape of
non-sinusoidal AM: 0 = ~sine, -1 = notches, +1 = clicks (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_noise">noise</code></td>
<td>
<p>loudness of turbulent noise (0 dB = as loud as
voiced component, negative values = quieter) such as aspiration, hissing,
etc (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_formantsnoise">formantsNoise</code></td>
<td>
<p>the same as <code>formants</code>, but for unvoiced instead of
voiced component. If NA (default), the unvoiced component will be filtered
through the same formants as the voiced component, approximating aspiration
noise [h]</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffnoise">rolloffNoise</code>, <code id="soundgen_+3A_noiseflatspec">noiseFlatSpec</code></td>
<td>
<p>linear rolloff of the excitation source for
the unvoiced component, <code>rolloffNoise</code> dB/kHz (anchor format) applied
above <code>noiseFlatSpec</code> Hz</p>
</td></tr>
<tr><td><code id="soundgen_+3A_rolloffnoiseexp">rolloffNoiseExp</code></td>
<td>
<p>exponential rolloff of the excitation source for the
unvoiced component, dB/oct (anchor format) applied above 0 Hz</p>
</td></tr>
<tr><td><code id="soundgen_+3A_noiseampref">noiseAmpRef</code></td>
<td>
<p>noise amplitude is defined relative to: &quot;f0&quot; = the
amplitude of the first partial (fundamental frequency), &quot;source&quot; = the
amplitude of the harmonic component prior to applying formants, &quot;filtered&quot;
=  the amplitude of the harmonic component after applying formants</p>
</td></tr>
<tr><td><code id="soundgen_+3A_mouth">mouth</code></td>
<td>
<p>mouth opening (0 to 1, 0.5 = neutral, i.e. no
modification) (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_ampl">ampl</code></td>
<td>
<p>amplitude envelope (dB, 0 = max amplitude) (anchor
format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_amplglobal">amplGlobal</code></td>
<td>
<p>global amplitude envelope spanning
multiple syllables (dB, 0 = no change) (anchor format)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_smoothing">smoothing</code></td>
<td>
<p>a list of parameters passed to
<code><a href="#topic+getSmoothContour">getSmoothContour</a></code> to control the interpolation and smoothing
of contours: interpol (approx / spline / loess), loessSpan, discontThres,
jumpThres</p>
</td></tr>
<tr><td><code id="soundgen_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling frequency, Hz</p>
</td></tr>
<tr><td><code id="soundgen_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="soundgen_+3A_overlap">overlap</code></td>
<td>
<p>FFT window overlap, %. For allowed values, see
<code><a href="seewave.html#topic+istft">istft</a></code></p>
</td></tr>
<tr><td><code id="soundgen_+3A_addsilence">addSilence</code></td>
<td>
<p>silence before and after the bout, ms: a vector of length 1
(symmetric) or 2 (different duration of silence before/after the sound)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_pitchfloor">pitchFloor</code>, <code id="soundgen_+3A_pitchceiling">pitchCeiling</code></td>
<td>
<p>lower &amp; upper bounds of f0</p>
</td></tr>
<tr><td><code id="soundgen_+3A_pitchsamplingrate">pitchSamplingRate</code></td>
<td>
<p>sampling frequency of the pitch contour only, Hz.
Low values reduce processing time. Set to <code>pitchCeiling</code> for optimal
speed or to <code>samplingRate</code> for optimal quality</p>
</td></tr>
<tr><td><code id="soundgen_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. Harmonics and noise more than
dynamicRange under maximum amplitude are discarded to save computational
resources</p>
</td></tr>
<tr><td><code id="soundgen_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>permittedValues</code>: 'adjust' = reset to default value, 'abort'
= stop execution, 'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
<tr><td><code id="soundgen_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots a spectrogram</p>
</td></tr>
<tr><td><code id="soundgen_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="soundgen_+3A_saveaudio">saveAudio</code></td>
<td>
<p>path + filename for saving the output, e.g.
'~/Downloads/temp.wav'. If NULL = doesn't save</p>
</td></tr>
<tr><td><code id="soundgen_+3A_...">...</code></td>
<td>
<p>other plotting parameters passed to <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the synthesized waveform as a numeric vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateNoise">generateNoise</a></code> <code><a href="#topic+beat">beat</a></code> <code><a href="#topic+fart">fart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># NB: GUI for soundgen is available as a Shiny app.
# Type "soundgen_app()" to open it in default browser

# Set "playback" to TRUE for default system player or the name of preferred
# player (eg "aplay") to play back the audio from examples
playback = FALSE # or TRUE 'aplay', 'vlc', ...

sound = soundgen(play = playback)
# spectrogram(sound, 16000, osc = TRUE)
# playme(sound)

# Control of intonation, amplitude envelope, formants
s0 = soundgen(
  pitch = c(300, 390, 250),
  ampl = data.frame(time = c(0, 50, 300), value = c(-5, -10, 0)),
  attack = c(10, 50),
  formants = c(600, 900, 2200),
  play = playback
)

# Use the in-built collection of presets:
# names(presets)  # speakers
# names(presets$Chimpanzee)  # calls per speaker
s1 = eval(parse(text = presets$Chimpanzee$Scream_conflict))  # screaming chimp
# playme(s1)
s2 = eval(parse(text = presets$F1$Scream))  # screaming woman
# playme(s2, 18320)

# presets of some vowels and consonants
names(presets$M1$Formants$vowels)
soundgen(sylLen = 500, formants = 'aoieu0', play = playback)

## Not run: 
# unless temperature is 0, the sound is different every time
for (i in 1:3) sound = soundgen(play = playback, temperature = .2)

# Bouts versus syllables. Compare:
sound = soundgen(formants = 'uai', repeatBout = 3, play = playback)
sound = soundgen(formants = 'uai', nSyl = 3, play = playback)

# Intonation contours per syllable and globally:
sound = soundgen(nSyl = 5, sylLen = 200, pauseLen = 140,
  pitch = list(
    time = c(0, 0.65, 1),
    value = c(977, 1540, 826)),
  pitchGlobal = list(time = c(0, .5, 1), value = c(-6, 7, 0)),
  play = playback, plot = TRUE)

# Amplitude modulation
sound = soundgen(amFreq = 75, amDep = runif(10, 0, 60),
  pitch = list(
    time = c(0, .3, .9, 1), value = c(1200, 1547, 1487, 1154)),
  sylLen = 800,
  play = playback, plot = TRUE)

# Jitter and mouth opening (bark, dog-like)
sound = soundgen(repeatBout = 2, sylLen = 160, pauseLen = 100,
  jitterDep = 1,
  pitch = c(559, 785, 557),
  mouth = c(0, 0.5, 0),
  vocalTract = 5, formants = NULL,
  play = playback, plot = TRUE)

# Ultrasound - need to adjust some defaults:
 soundgen(
   sylLen = 10,  # just 10 ms
   attackLen = 1,  # should be very short for short vocalizations
   addSilence = 2,
   pitch = c(45000, 35000, 65000, 60000),  # 35-60 kHz
   rolloff = -12,
   rolloffKHz = 0,  # NB: the default is -3 dB/kHz, which we do NOT want here!
   formants = NA,  # no formants (or set vocal tract length)
   samplingRate = 350000,  # at least ~10 times the max f0
   pitchSamplingRate = 350000,  # the same as samplingRate
   windowLength = .25,  # need very short window lengths for USV
   pitchCeiling = 90000, # max allowed pitch
   invalidArgAction = 'ignore', # override the ranges allowed by default
   temperature = 1e-4,
   plot = TRUE
 )

# See the vignette on sound generation for more examples and in-depth
# explanation of the arguments to soundgen()
# Examples of code for creating human and animal vocalizations are available
# on project's homepage: http://cogsci.se/soundgen.html

## End(Not run)
</code></pre>

<hr>
<h2 id='soundgen_app'>Interactive sound synthesizer</h2><span id='topic+soundgen_app'></span>

<h3>Description</h3>

<p>Starts a shiny app that provides an interactive wrapper to
<code><a href="#topic+soundgen">soundgen</a></code>. Supported browsers: Firefox / Chrome. Note that the
browser has to be able to playback WAV audio files, otherwise there will be
no sound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soundgen_app()
</code></pre>

<hr>
<h2 id='specToMS'>Spectrogram to modulation spectrum</h2><span id='topic+specToMS'></span>

<h3>Description</h3>

<p>Takes a spectrogram (either complex or magnitude) and returns a MS with
proper row and column labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specToMS(spec, windowLength = NULL, step = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="specToMS_+3A_spec">spec</code></td>
<td>
<p>target spectrogram (numeric matrix, frequency in rows, time in
columns)</p>
</td></tr>
<tr><td><code id="specToMS_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="specToMS_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a MS - matrix of complex values of the same dimension as
spec, with AM in rows and FM in columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = soundgen(sylLen = 500, amFreq = 25, amDep = 50,
             pitch = 250, samplingRate = 16000)
spec = spectrogram(s, samplingRate = 16000, windowLength = 25,
  step = 5, plot = FALSE)
ms = specToMS(spec)
plotMS(log(Mod(ms)), quantiles = NULL, col = soundgen:::jet.col(100))
## Not run: 
# or plot manually
image(x = as.numeric(colnames(ms)), y = as.numeric(rownames(ms)),
      z = t(log(abs(ms))), xlab = 'Amplitude modulation, Hz',
      ylab = 'Frequency modulation, cycles/kHz')
abline(h = 0, lty = 3); abline(v = 0, lty = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='specToMS_1D'>Spectrogram to modulation spectrum 1D</h2><span id='topic+specToMS_1D'></span>

<h3>Description</h3>

<p>Takes a spectrogram and returns the spectrum of each channel. The input can
be an ordinary STFT spectrogram or an auditory spectrogram (a signal
convolved with a bank of bandpass filters). The difference from
<code><a href="#topic+specToMS">specToMS</a></code> is that, instead of taking a two-dimensional transform
of the spectrogram, here the spectra are calculated independently for each
frequency bin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specToMS_1D(
  fb,
  samplingRate,
  windowLength = 250,
  step = windowLength/2,
  method = c("spec", "meanspec")[2]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="specToMS_1D_+3A_fb">fb</code></td>
<td>
<p>input spectrogram (numeric matrix with frequency in rows and time
in columns)</p>
</td></tr>
<tr><td><code id="specToMS_1D_+3A_samplingrate">samplingRate</code></td>
<td>
<p>for auditory spectrogram, the sampling rate of input
audio; for STFT spectrograms, the number of STFT frames per second</p>
</td></tr>
<tr><td><code id="specToMS_1D_+3A_windowlength">windowLength</code>, <code id="specToMS_1D_+3A_step">step</code></td>
<td>
<p>determine the resolution of modulation spectra (both
in ms)</p>
</td></tr>
<tr><td><code id="specToMS_1D_+3A_method">method</code></td>
<td>
<p>calls either <code><a href="seewave.html#topic+meanspec">meanspec</a></code> or
<code><a href="seewave.html#topic+spec">spec</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a modulation spectrum - a matrix of real values, with center
frequencies of original filters in rows and modulation frequencies in
columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sheep, package = 'seewave')

# auditory spectrogram
as = audSpectrogram(sheep, filterType = 'butterworth',
  nFilters = 24, plot = FALSE)
fb = t(do.call(cbind, as$filterbank_env))
rownames(fb) = names(as$filterbank_env)
ms = soundgen:::specToMS_1D(fb, sheep@samp.rate)
plotMS(log(ms+.01), logWarpX = c(10, 2), quantile = NULL, ylab = 'kHz')

# ordinary STFT spectrogram
sp = spectrogram(sheep, windowLength = 15, step = 0.5,
  output = 'original', plot = FALSE)
ms2 = soundgen:::specToMS_1D(sp, 1000 / 0.5)  # 1000/0.5 frames per s
plotMS(log(ms2+.01), quantile = NULL, ylab = 'kHz')
## Not run: 
ms_spec = soundgen:::specToMS_1D(fb, sheep@samp.rate, method = 'spec')
plotMS(log(ms_spec+.01), logWarpX = c(10, 2), quantile = NULL, ylab = 'kHz')

## End(Not run)
</code></pre>

<hr>
<h2 id='spectrogram'>Spectrogram</h2><span id='topic+spectrogram'></span>

<h3>Description</h3>

<p>Produces the spectrogram of a sound using short-time Fourier transform.
Inspired by <code><a href="seewave.html#topic+spectro">spectro</a></code>, this function offers added
routines for reassignment, noise reduction, smoothing in time and frequency
domains, manual control of contrast and brightness, plotting the oscillogram
on a dB scale, grid, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectrogram(
  x,
  samplingRate = NULL,
  scale = NULL,
  from = NULL,
  to = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = windowLength/2,
  overlap = NULL,
  specType = c("spectrum", "reassigned", "spectralDerivative")[1],
  logSpec = TRUE,
  rasterize = FALSE,
  wn = "gaussian",
  zp = 0,
  normalize = TRUE,
  smoothFreq = 0,
  smoothTime = 0,
  qTime = 0,
  percentNoise = 10,
  noiseReduction = 0,
  output = c("original", "processed", "complex", "all")[1],
  specManual = NULL,
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  osc = c("none", "linear", "dB")[2],
  heights = c(3, 1),
  ylim = NULL,
  yScale = c("linear", "log", "bark", "mel", "ERB")[1],
  contrast = 0.2,
  brightness = 0,
  blur = 0,
  maxPoints = c(1e+05, 5e+05),
  padWithSilence = TRUE,
  colorTheme = c("bw", "seewave", "heat.colors", "...")[1],
  col = NULL,
  extraContour = NULL,
  xlab = NULL,
  ylab = NULL,
  xaxp = NULL,
  mar = c(5.1, 4.1, 4.1, 2),
  main = NULL,
  grid = NULL,
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spectrogram_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_scale">scale</code></td>
<td>
<p>maximum possible amplitude of input used for normalization of
input vector (only needed if <code>x</code> is a numeric vector)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_from">from</code>, <code id="spectrogram_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_spectype">specType</code></td>
<td>
<p>plot the original FFT ('spectrum'), reassigned spectrogram
('reassigned'), or spectral derivative ('spectralDerivative')</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_logspec">logSpec</code></td>
<td>
<p>if TRUE, log-transforms the spectrogram</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_rasterize">rasterize</code></td>
<td>
<p>(only applies if specType = 'reassigned') if TRUE, the
reassigned spectrogram is plotted after rasterizing it: that is, showing
density per time-frequency bins with the same resolution as an ordinary
spectrogram</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, scales input prior to FFT</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_smoothfreq">smoothFreq</code>, <code id="spectrogram_+3A_smoothtime">smoothTime</code></td>
<td>
<p>length of the window for median smoothing in
frequency and time domains, respectively, points</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_qtime">qTime</code></td>
<td>
<p>the quantile to be subtracted for each frequency bin. For ex.,
if qTime = 0.5, the median of each frequency bin (over the entire sound
duration) will be calculated and subtracted from each frame (see examples)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_percentnoise">percentNoise</code></td>
<td>
<p>percentage of frames (0 to 100%) used for calculating
noise spectrum</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_noisereduction">noiseReduction</code></td>
<td>
<p>how much noise to remove (non-negative number,
recommended 0 to 2). 0 = no noise reduction, 2 = strong noise reduction:
<code class="reqn">spectrum - (noiseReduction * noiseSpectrum)</code>, where noiseSpectrum is
the average spectrum of frames with entropy exceeding the quantile set by
<code>percentNoise</code></p>
</td></tr>
<tr><td><code id="spectrogram_+3A_output">output</code></td>
<td>
<p>specifies what to return: nothing ('none'), unmodified
spectrogram ('original'), denoised and/or smoothed spectrogram
('processed'), or unmodified spectrogram with the imaginary part giving
phase ('complex')</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_specmanual">specManual</code></td>
<td>
<p>manually calculated spectrogram-like representation in the
same format as the output of spectrogram(): rows = frequency in kHz,
columns = time in ms</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_plot">plot</code></td>
<td>
<p>should a spectrogram be plotted? TRUE / FALSE</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_osc">osc</code></td>
<td>
<p>&quot;none&quot; = no oscillogram; &quot;linear&quot; = on the original scale; &quot;dB&quot; =
in decibels</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_heights">heights</code></td>
<td>
<p>a vector of length two specifying the relative height of the
spectrogram and the oscillogram (including time axes labels)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_ylim">ylim</code></td>
<td>
<p>frequency range to plot, kHz (defaults to 0 to Nyquist
frequency). NB: still in kHz, even if yScale = bark, mel, or ERB</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_yscale">yScale</code></td>
<td>
<p>scale of the frequency axis: 'linear' = linear, 'log' =
logarithmic (musical), 'bark' = bark with <code><a href="tuneR.html#topic+hz2bark">hz2bark</a></code>,
'mel' = mel with <code><a href="tuneR.html#topic+hz2mel">hz2mel</a></code>, 'ERB' = Equivalent
Rectangular Bandwidths with <code><a href="#topic+HzToERB">HzToERB</a></code></p>
</td></tr>
<tr><td><code id="spectrogram_+3A_contrast">contrast</code></td>
<td>
<p>a number, recommended range -1 to +1. The spectrogram is
raised to the power of <code>exp(3 * contrast)</code>. Contrast &gt;0 increases
sharpness, &lt;0 decreases sharpness</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_brightness">brightness</code></td>
<td>
<p>how much to &quot;lighten&quot; the image (&gt;0 = lighter, &lt;0 = darker)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_blur">blur</code></td>
<td>
<p>apply a Gaussian filter to blur or sharpen the image, two
numbers: frequency (Hz), time (ms). A single number is interpreted as
frequency, and a square filter is applied. NA / NULL / 0 means no blurring
in that dimension. Negative numbers mean un-blurring (sharpening) the image
by dividing instead of multiplying by the filter during convolution</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_maxpoints">maxPoints</code></td>
<td>
<p>the maximum number of &quot;pixels&quot; in the oscillogram (if any)
and spectrogram; good for quickly plotting long audio files; defaults to
c(1e5, 5e5)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_padwithsilence">padWithSilence</code></td>
<td>
<p>if TRUE, pads the sound with just enough silence to
resolve the edges properly (only the original region is plotted, so the
apparent duration doesn't change)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_colortheme">colorTheme</code></td>
<td>
<p>black and white ('bw'), as in seewave package ('seewave'),
matlab-type palette ('matlab'), or any palette from
<code><a href="grDevices.html#topic+palette">palette</a></code> such as 'heat.colors', 'cm.colors', etc</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_col">col</code></td>
<td>
<p>actual colors, eg rev(rainbow(100)) - see ?hcl.colors for colors
in base R (overrides colorTheme)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_extracontour">extraContour</code></td>
<td>
<p>a vector of arbitrary length scaled in Hz (regardless of
yScale!) that will be plotted over the spectrogram (eg pitch contour); can
also be a list with extra graphical parameters such as lwd, col, etc. (see
examples)</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_xlab">xlab</code>, <code id="spectrogram_+3A_ylab">ylab</code>, <code id="spectrogram_+3A_main">main</code>, <code id="spectrogram_+3A_mar">mar</code>, <code id="spectrogram_+3A_xaxp">xaxp</code></td>
<td>
<p>graphical parameters for plotting</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_grid">grid</code></td>
<td>
<p>if numeric, adds n = <code>grid</code> dotted lines per kHz</p>
</td></tr>
<tr><td><code id="spectrogram_+3A_width">width</code>, <code id="spectrogram_+3A_height">height</code>, <code id="spectrogram_+3A_units">units</code>, <code id="spectrogram_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="spectrogram_+3A_...">...</code></td>
<td>
<p>other graphical parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many soundgen functions call <code>spectrogram</code>, and you can pass along most
of its graphical parameters from functions like <code><a href="#topic+soundgen">soundgen</a></code>,
<code><a href="#topic+analyze">analyze</a></code>, etc. However, in some cases this will not work (eg for
&quot;units&quot;) or may produce unexpected results. If in doubt, omit extra graphical
parameters or save your sound first, then call spectrogram() explicitly.
</p>


<h3>Value</h3>

<p>Returns nothing if output = 'none', spectral magnitudes - not power!
- if output = 'original', denoised and/or smoothed spectrum if output =
'processed', or spectral derivatives if specType = 'spectralDerivative'.
The output is a matrix of real numbers with time in columns (ms) and
frequency in rows (kHz).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+osc">osc</a></code> <code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code> <code><a href="#topic+ssm">ssm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># synthesize a sound 500 ms long, with gradually increasing hissing noise
sound = soundgen(sylLen = 500, temperature = 0.001, noise = list(
  time = c(0, 650), value = c(-40, 0)), formantsNoise = list(
  f1 = list(freq = 5000, width = 10000)))
# playme(sound, samplingRate = 16000)

# basic spectrogram
spectrogram(sound, samplingRate = 16000, yScale = 'bark')

# add bells and whistles
spectrogram(sound, samplingRate = 16000,
  osc = 'dB',  # plot oscillogram in dB
  heights = c(2, 1),  # spectro/osc height ratio
  noiseReduction = 1.1,  # subtract the spectrum of noisy parts
  brightness = -1,  # reduce brightness
  # pick color theme - see ?hcl.colors
  # colorTheme = 'heat.colors',
  # ...or just specify the actual colors
  col = colorRampPalette(c('white', 'yellow', 'red'))(50),
  cex.lab = .75, cex.axis = .75,  # text size and other base graphics pars
  grid = 5,  # lines per kHz; to customize, add manually with graphics::grid()
  ylim = c(0, 5),  # always in kHz
  main = 'My spectrogram' # title
  # + axis labels, etc
)
## Not run: 
# save spectrograms of all sounds in a folder
spectrogram('~/Downloads/temp', savePlots = '', cores = 2)

# change dynamic range
spectrogram(sound, samplingRate = 16000, dynamicRange = 40)
spectrogram(sound, samplingRate = 16000, dynamicRange = 120)

# remove the oscillogram
spectrogram(sound, samplingRate = 16000, osc = 'none')  # or NULL etc

# frequencies on a logarithmic (musical) scale (mel/bark also available)
spectrogram(sound, samplingRate = 16000,
            yScale = 'log', ylim = c(.05, 8))

# broad-band instead of narrow-band
spectrogram(sound, samplingRate = 16000, windowLength = 5)

# reassigned spectrograms can be plotted without rasterizing, as a
# scatterplot instead of a contour plot
s = soundgen(sylLen = 500, pitch = c(100, 1100, 120, 1200, 90, 900, 110, 700),
  samplingRate = 22050, formants = NULL, lipRad = 0, rolloff = -20)
spectrogram(s, 22050, windowLength = 5, step = 1, ylim = c(0, 2))
spectrogram(s, 22050, specType = 'reassigned', windowLength = 5,
  step = 1, ylim = c(0, 2))
# ...or it can be rasterized, but that sacrifices frequency resolution:
sp = spectrogram(s, 22050, specType = 'reassigned', rasterize = TRUE,
                 windowLength = 5, step = 1, ylim = c(0, 2), output = 'all')
# The raw reassigned version is saved if output = 'all' for custom plotting
df = sp$reassigned
df$z1 = soundgen:::zeroOne(log(df$magn))
plot(df$time, df$freq, col = rgb(df$z1, df$z1, 1 - df$z1, 1),
  pch = 16, cex = 0.25, ylim = c(0, 2))

# focus only on values in the upper 5% for each frequency bin
spectrogram(sound, samplingRate = 16000, qTime = 0.95)

# detect 10% of the noisiest frames based on entropy and remove the pattern
# found in those frames (in this cases, breathing)
spectrogram(sound, samplingRate = 16000,  noiseReduction = 1.1,
  brightness = -2)  # white noise attenuated

# increase contrast, reduce brightness
spectrogram(sound, samplingRate = 16000, contrast = .7, brightness = -.5)

# apply median smoothing in both time and frequency domains
spectrogram(sound, samplingRate = 16000, smoothFreq = 5,
  smoothTime = 5)

# Gaussian filter to blur or sharpen ("unblur") the image in time and/or
# frequency domains
spectrogram(sound, samplingRate = 16000, blur = c(100, 500))
# TIP: when unblurring, set the first (frequency) parameter to the
# frequency resolution of interest, eg ~500-1000 Hz for human formants
spectrogram(sound, samplingRate = 16000, windowLength = 10, blur = c(-500, 50))

# specify location of tick marks etc - see ?par() for base graphics
spectrogram(sound, samplingRate = 16000,
            ylim = c(0, 3), yaxp = c(0, 3, 5), xaxp = c(0, .8, 10))

# Plot long audio files with reduced resolution
data(sheep, package = 'seewave')
sp = spectrogram(sheep, overlap = 0,
  maxPoints = c(1e4, 5e3),  # limit the number of pixels in osc/spec
  output = 'original')
nrow(sp) * ncol(sp) / 5e3  # spec downsampled by a factor of ~2

# Plot some arbitrary contour over the spectrogram (simply calling lines()
# will not work if osc = TRUE b/c the plot layout is modified)
s = soundgen(sylLen = 1500, pitch = c(250, 350, 320, 220),
  jitterDep = c(0, 0, 3, 2, 0, 0))
an = analyze(s, 16000, plot = FALSE)
spectrogram(s, 16000, extraContour = an$detailed$dom,
  ylim = c(0, 2), yScale = 'bark')
# For values that are not in Hz, normalize any way you like
spectrogram(s, 16000, ylim = c(0, 2), extraContour = list(
  x = an$detailed$loudness / max(an$detailed$loudness, na.rm = TRUE) * 2000,
  # ylim[2] = 2000 Hz
  type = 'b', pch = 5, lwd = 2, lty = 2, col = 'blue'))

# Plot a spectrogram-like matrix paired with an osc
ms = modulationSpectrum(s, 16000, msType = '1D', amRes = 10)
spectrogram(s, 16000, specManual = ms$modulation_spectrogram,
  colorTheme = 'matlab', ylab = 'Modulation frequency, kHz',
  contrast = .25, blur = c(10, 10))

## End(Not run)
</code></pre>

<hr>
<h2 id='splitContour'>Split contour</h2><span id='topic+splitContour'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitContour(anchors, discontThres = 0.05, jumpThres = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splitContour_+3A_anchors">anchors</code></td>
<td>
<p>a dataframe with two columns: time and value (time on any scale)</p>
</td></tr>
<tr><td><code id="splitContour_+3A_discontthres">discontThres</code></td>
<td>
<p>if two anchors are closer in time than
<code>discontThres</code> (on a 0-1 scale, ie specified as proportion of total
length), the contour is broken into segments with a linear transition
between these segments</p>
</td></tr>
<tr><td><code id="splitContour_+3A_jumpthres">jumpThres</code></td>
<td>
<p>if anchors are closer than <code>jumpThres</code>, a new section
starts with no transition at all (e.g. for adding pitch jumps)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Splits a smooth contour into several segments. A new segments is started if
the time step between two anchors is smaller than discontThres.
</p>


<h3>Value</h3>

<p>Returns a dataframe containing the index of anchor rows for start and
end of each segment and whether we want a transition or a jump between
segments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::splitContour(data.frame(time = c(0, 370, 650, 655, 1050, 1400),
  value = c(360, 316, 345, 550, 610, 590)))
soundgen:::splitContour(data.frame(time = c(0, .2, .205, .8, .81, 1),
  value = c(360, 316, 345, 550, 610, 590)))
soundgen:::splitContour(data.frame(time = c(0, .4, .45, .6, .8, 1),
  value = c(360, 316, 345, 550, 610, 590)))
soundgen:::splitContour(data.frame(time = c(0, .4, .45, .6, .8, 1),
  value = c(360, 316, 345, 550, 610, 590)),
  discontThres = .1)
soundgen:::splitContour(data.frame(time = c(0, 1),
  value = c(360, 590)))
</code></pre>

<hr>
<h2 id='splitIntoChunks'>Split vector into chunks</h2><span id='topic+splitIntoChunks'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitIntoChunks(x, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splitIntoChunks_+3A_x">x</code></td>
<td>
<p>numeric vector to split</p>
</td></tr>
<tr><td><code id="splitIntoChunks_+3A_n">n</code></td>
<td>
<p>number of chunks</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes a numeric vector x and splits it into n chunks. This is the fastest
splitting algorithm from
https://stackoverflow.com/questions/3318333/split-a-vector-into-chunks
</p>


<h3>Value</h3>

<p>Returns a list of length <code>n</code> containing the chunks
</p>


<h3>Examples</h3>

<pre><code class='language-R'># prepare chunks of iterator to run in parallel on several cores
chunks = soundgen:::splitIntoChunks(1:21, 4)
chunks
</code></pre>

<hr>
<h2 id='spreadSpec'>Spread spectrum</h2><span id='topic+spreadSpec'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spreadSpec(barkSpec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spreadSpec_+3A_barkspec">barkSpec</code></td>
<td>
<p>a numeric vector of length equal to the number of critical
bands (eg 1 to 24 barks), giving the power in each band on a linear scale
(not dB)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Spreads spectrum to account for frequency masking across critical bands. See
Wonho (1999) &quot;Enhanced modified bark spectral distortion (EMBSD)&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>barkSpec = c(rep(0, 10), 20000, 2e5, 2e4, 1e4, 2000, rep(0, 8))
plot(soundgen:::spreadSpec(barkSpec), type = 'b', col = 'red')
points(barkSpec, type = 'b', col = 'blue')
</code></pre>

<hr>
<h2 id='ssm'>Self-similarity matrix</h2><span id='topic+ssm'></span>

<h3>Description</h3>

<p>Calculates the self-similarity matrix and novelty vector of a sound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssm(
  x,
  samplingRate = NULL,
  from = NULL,
  to = NULL,
  windowLength = 25,
  step = 5,
  overlap = NULL,
  ssmWin = NULL,
  sparse = FALSE,
  maxFreq = NULL,
  nBands = NULL,
  MFCC = 2:13,
  input = c("mfcc", "melspec", "spectrum")[2],
  norm = FALSE,
  simil = c("cosine", "cor")[1],
  kernelLen = 100,
  kernelSD = 0.5,
  padWith = 0,
  summaryFun = c("mean", "sd"),
  reportEvery = NULL,
  cores = 1,
  plot = TRUE,
  savePlots = NULL,
  main = NULL,
  heights = c(2, 1),
  width = 900,
  height = 500,
  units = "px",
  res = NA,
  specPars = list(levels = seq(0, 1, length = 30), colorTheme = c("bw", "seewave",
    "heat.colors", "...")[2], xlab = "Time, s", ylab = "kHz"),
  ssmPars = list(levels = seq(0, 1, length = 30), colorTheme = c("bw", "seewave",
    "heat.colors", "...")[2], xlab = "Time, s", ylab = "Time, s"),
  noveltyPars = list(type = "b", pch = 16, col = "black", lwd = 3)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ssm_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="ssm_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="ssm_+3A_from">from</code>, <code id="ssm_+3A_to">to</code></td>
<td>
<p>if NULL (default), analyzes the whole sound, otherwise
from...to (s)</p>
</td></tr>
<tr><td><code id="ssm_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="ssm_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="ssm_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="ssm_+3A_ssmwin">ssmWin</code></td>
<td>
<p>window for averaging SSM, ms (has a smoothing effect and speeds
up the processing)</p>
</td></tr>
<tr><td><code id="ssm_+3A_sparse">sparse</code></td>
<td>
<p>if TRUE, the entire SSM is not calculated, but only the central
region needed to extract the novelty contour (speeds up the processing)</p>
</td></tr>
<tr><td><code id="ssm_+3A_maxfreq">maxFreq</code></td>
<td>
<p>highest band edge of mel filters, Hz. Defaults to
<code>samplingRate / 2</code>. See <code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id="ssm_+3A_nbands">nBands</code></td>
<td>
<p>number of warped spectral bands to use. Defaults to <code>100 *
windowLength / 20</code>. See <code><a href="tuneR.html#topic+melfcc">melfcc</a></code></p>
</td></tr>
<tr><td><code id="ssm_+3A_mfcc">MFCC</code></td>
<td>
<p>which mel-frequency cepstral coefficients to use; defaults to
<code>2:13</code></p>
</td></tr>
<tr><td><code id="ssm_+3A_input">input</code></td>
<td>
<p>the spectral representation used to calculate the SSM</p>
</td></tr>
<tr><td><code id="ssm_+3A_norm">norm</code></td>
<td>
<p>if TRUE, the spectrum of each STFT frame is normalized</p>
</td></tr>
<tr><td><code id="ssm_+3A_simil">simil</code></td>
<td>
<p>method for comparing frames: &quot;cosine&quot; = cosine similarity, &quot;cor&quot;
= Pearson's correlation</p>
</td></tr>
<tr><td><code id="ssm_+3A_kernellen">kernelLen</code></td>
<td>
<p>length of checkerboard kernel for calculating novelty, ms
(larger values favor global, slow vs. local, fast novelty)</p>
</td></tr>
<tr><td><code id="ssm_+3A_kernelsd">kernelSD</code></td>
<td>
<p>SD of checkerboard kernel for calculating novelty</p>
</td></tr>
<tr><td><code id="ssm_+3A_padwith">padWith</code></td>
<td>
<p>how to treat edges when calculating novelty: NA = treat sound
before and after the recording as unknown, 0 = treat it as silence</p>
</td></tr>
<tr><td><code id="ssm_+3A_summaryfun">summaryFun</code></td>
<td>
<p>functions used to summarize each acoustic characteristic,
eg &quot;c('mean', 'sd')&quot;; user-defined functions are fine (see examples); NAs
are omitted automatically for mean/median/sd/min/max/range/sum, otherwise
take care of NAs yourself</p>
</td></tr>
<tr><td><code id="ssm_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="ssm_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
<tr><td><code id="ssm_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the SSM</p>
</td></tr>
<tr><td><code id="ssm_+3A_saveplots">savePlots</code></td>
<td>
<p>full path to the folder in which to save the plots (NULL =
don't save, &rdquo; = same folder as audio)</p>
</td></tr>
<tr><td><code id="ssm_+3A_main">main</code></td>
<td>
<p>plot title</p>
</td></tr>
<tr><td><code id="ssm_+3A_heights">heights</code></td>
<td>
<p>relative sizes of the SSM and spectrogram/novelty plot</p>
</td></tr>
<tr><td><code id="ssm_+3A_width">width</code>, <code id="ssm_+3A_height">height</code>, <code id="ssm_+3A_units">units</code>, <code id="ssm_+3A_res">res</code></td>
<td>
<p>graphical parameters for saving plots passed to
<code><a href="grDevices.html#topic+png">png</a></code></p>
</td></tr>
<tr><td><code id="ssm_+3A_specpars">specPars</code></td>
<td>
<p>graphical parameters passed to <code>filled.contour.mod</code> and
affecting the <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
<tr><td><code id="ssm_+3A_ssmpars">ssmPars</code></td>
<td>
<p>graphical parameters passed to <code>filled.contour.mod</code> and
affecting the plot of SSM</p>
</td></tr>
<tr><td><code id="ssm_+3A_noveltypars">noveltyPars</code></td>
<td>
<p>graphical parameters passed to
<code><a href="graphics.html#topic+lines">lines</a></code> and affecting the novelty contour</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of two components: $ssm contains the self-similarity
matrix, and $novelty contains the novelty vector.
</p>


<h3>References</h3>


<ul>
<li><p> El Badawy, D., Marmaroli, P., &amp; Lissek, H. (2013). Audio
Novelty-Based Segmentation of Music Concerts. In Acoustics 2013 (No.
EPFL-CONF-190844)
</p>
</li>
<li><p> Foote, J. (1999, October). Visualizing music and
audio using self-similarity. In Proceedings of the seventh ACM
international conference on Multimedia (Part 1) (pp. 77-80). ACM.
</p>
</li>
<li>
<p>Foote, J. (2000). Automatic audio segmentation using a measure of audio
novelty. In Multimedia and Expo, 2000. ICME 2000. 2000 IEEE International
Conference on (Vol. 1, pp. 452-455). IEEE.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spectrogram">spectrogram</a></code> <code><a href="#topic+modulationSpectrum">modulationSpectrum</a></code>
<code><a href="#topic+segment">segment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sound = c(soundgen(),
          soundgen(nSyl = 4, sylLen = 50, pauseLen = 70,
          formants = NA, pitch = c(500, 330)))
# playme(sound)
# detailed, local features (captures each syllable)
s1 = ssm(sound, samplingRate = 16000, kernelLen = 100,
         sparse = TRUE)  # much faster with 'sparse'
# more global features (captures the transition b/w the two sounds)
s2 = ssm(sound, samplingRate = 16000, kernelLen = 400, sparse = TRUE)

s2$summary
s2$novelty  # novelty contour
## Not run: 
ssm(sound, samplingRate = 16000,
    input = 'mfcc', simil = 'cor', norm = TRUE,
    ssmWin = 25,  # speed up the processing
    kernelLen = 300,  # global features
    specPars = list(colorTheme = 'seewave'),
    ssmPars = list(col = rainbow(100)),
    noveltyPars = list(type = 'l', lty = 3, lwd = 2))

## End(Not run)
</code></pre>

<hr>
<h2 id='summarizeAnalyze'>Summarize the output of analyze()</h2><span id='topic+summarizeAnalyze'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeAnalyze(
  result,
  summaryFun = c("mean", "sd"),
  var_noSummary = c("duration", "duration_noSilence", "voiced", "time", "epoch")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarizeAnalyze_+3A_result">result</code></td>
<td>
<p>dataframe returned by analyze(summary = FALSE)</p>
</td></tr>
<tr><td><code id="summarizeAnalyze_+3A_summaryfun">summaryFun</code></td>
<td>
<p>summary functions</p>
</td></tr>
<tr><td><code id="summarizeAnalyze_+3A_var_nosummary">var_noSummary</code></td>
<td>
<p>variables that should not be summarized</p>
</td></tr>
</table>

<hr>
<h2 id='switchColorTheme'>Switch color theme</h2><span id='topic+switchColorTheme'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>switchColorTheme(colorTheme)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="switchColorTheme_+3A_colortheme">colorTheme</code></td>
<td>
<p>string like 'bw', 'seewave', or function name</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::switchColorTheme('bw')
soundgen:::switchColorTheme('seewave')

cols_matlab = soundgen:::switchColorTheme('matlab') (100)
plot(1:100, seq(0, 1, length.out = 100), type = 'n')
for (i in 1:100) {
  rect(i - 1, 0, i, 1, col = cols_matlab[i], border = NA)
}
</code></pre>

<hr>
<h2 id='timeSeriesSummary'>Time series summary</h2><span id='topic+timeSeriesSummary'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeSeriesSummary(
  x,
  step,
  inflThres = NULL,
  extraSummaryFun = c(),
  ref = 16.35,
  plot = FALSE,
  main = ""
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timeSeriesSummary_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="timeSeriesSummary_+3A_step">step</code></td>
<td>
<p>time step in s</p>
</td></tr>
<tr><td><code id="timeSeriesSummary_+3A_inflthres">inflThres</code></td>
<td>
<p>minimum difference (in semitones) between consecutive
extrema to consider them inflections; to apply a different threshold at
each smoothing level, provide <code>inflThres</code> as a vector of the same
length as <code>smoothBW</code>; NA = no threshold</p>
</td></tr>
<tr><td><code id="timeSeriesSummary_+3A_extrasummaryfun">extraSummaryFun</code></td>
<td>
<p>additional summary function(s) that take a numeric
vector with some NAs and return a single number, eg c('myFun1', 'myFun2')</p>
</td></tr>
<tr><td><code id="timeSeriesSummary_+3A_ref">ref</code></td>
<td>
<p>reference value for transforming Hz to semitones, defaults to
C0 (16.35 Hz)</p>
</td></tr>
<tr><td><code id="timeSeriesSummary_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the inflections for manual verification</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A helper function called by .pitchDescriptives for each smoothing level.
</p>

<hr>
<h2 id='timeStretch'>Time stretch</h2><span id='topic+timeStretch'></span>

<h3>Description</h3>

<p>Dynamically time-stretches a sound without preserving its pitch or formants,
as if gradually changing playback speed. Algorithm: the audio is resampled at
time-varying steps. This is about 100 times faster than time-stretching with a
phase vocoder in <code><a href="#topic+shiftPitch">shiftPitch</a></code>, but pitch and formants cannot be
preserved, and large stretch factors may cause artifacts due to aliasing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeStretch(
  x,
  stretch = 1,
  samplingRate = NULL,
  precision = 1000,
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timeStretch_+3A_x">x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td></tr>
<tr><td><code id="timeStretch_+3A_stretch">stretch</code></td>
<td>
<p>1 = no change, &gt;1 = longer, &lt;1 = shorter. Single value, vector,
or anchor format (see <code><a href="#topic+soundgen">soundgen</a></code>)</p>
</td></tr>
<tr><td><code id="timeStretch_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="timeStretch_+3A_precision">precision</code></td>
<td>
<p>the number of points used for estimating the duration of
output (more = better, but slower)</p>
</td></tr>
<tr><td><code id="timeStretch_+3A_play">play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code><a href="tuneR.html#topic+play">play</a></code> as the name
of player to use, eg &quot;aplay&quot;, &quot;play&quot;, &quot;vlc&quot;, etc. In case of errors, try
setting another default player for <code><a href="tuneR.html#topic+play">play</a></code></p>
</td></tr>
<tr><td><code id="timeStretch_+3A_saveaudio">saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td></tr>
<tr><td><code id="timeStretch_+3A_reportevery">reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td></tr>
<tr><td><code id="timeStretch_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+shiftPitch">shiftPitch</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sheep, package = 'seewave')  # import a recording from seewave
# playme(sheep)
# spectrogram(sheep)
s1 = timeStretch(sheep, stretch = c(1, 3))
# playme(s1, sheep@samp.rate)
# spectrogram(s1, sheep@samp.rate)

# compare to a similar effect achieved with a phase vocoder in pitchShift():
s2 = shiftPitch(
  sheep,
  timeStretch = c(1, 3),  # from 1 (original) to mult
  multPitch = c(1, 1/3),  # also drop pitch
  multFormants = c(1, 1/3)  # also drop formants (by the same proportion)
)
# playme(s2, sheep@samp.rate)
# spectrogram(s2, sheep@samp.rate)
# NB: because the two algorithms calculate transitions between stretch
# factors in different ways, the duration is not identical, even though the
# range of pitch change is the same
</code></pre>

<hr>
<h2 id='to_dB'>Convert to dB</h2><span id='topic+to_dB'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_dB(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="to_dB_+3A_x">x</code></td>
<td>
<p>a vector of floats between 0 and 1 (exclusive, i.e. these are ratios)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::to_dB(c(.1, .5, .75, .9, .95, .99, .999, .9999))
</code></pre>

<hr>
<h2 id='transplantEnv'>Transplant envelope</h2><span id='topic+transplantEnv'></span>

<h3>Description</h3>

<p>Extracts a smoothed amplitude envelope of the <code>donor</code> sound and applies
it to the <code>recipient</code> sound. Both sounds are provided as numeric
vectors; they can differ in length and sampling rate. Note that the result
depends on the amount of smoothing (controlled by <code>windowLength</code>) and
the chosen method of calculating the envelope. Very similar to
<code><a href="seewave.html#topic+setenv">setenv</a></code>, but with a different smoothing algorithm and
with a choice of several types of envelope: hil, rms, or peak.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transplantEnv(
  donor,
  samplingRateD = NULL,
  recipient,
  samplingRateR = samplingRateD,
  windowLength = 50,
  method = c("hil", "rms", "peak")[3],
  killDC = FALSE,
  dynamicRange = 80,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transplantEnv_+3A_donor">donor</code></td>
<td>
<p>the sound that &quot;donates&quot; the amplitude envelope</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_samplingrated">samplingRateD</code>, <code id="transplantEnv_+3A_samplingrater">samplingRateR</code></td>
<td>
<p>sampling rate of the donor and recipient,
respectively (only needed for vectors, not files)</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_recipient">recipient</code></td>
<td>
<p>the sound that needs to have its amplitude envelope adjusted</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_windowlength">windowLength</code></td>
<td>
<p>the length of smoothing window, ms</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_method">method</code></td>
<td>
<p>hil = Hilbert envelope, rms = root mean square amplitude, peak
= peak amplitude per window</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_killdc">killDC</code></td>
<td>
<p>if TRUE, dynamically removes DC offset or similar deviations of
average waveform from zero (see examples)</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>parts of sound quieter than <code>-dynamicRange</code> dB will
not be amplified</p>
</td></tr>
<tr><td><code id="transplantEnv_+3A_plot">plot</code></td>
<td>
<p>if TRUE, plots the original sound, the smoothed envelope, and
the compressed sound</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the recipient sound with the donor's amplitude envelope - a
numeric vector with the same sampling rate as the recipient
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flatEnv">flatEnv</a></code> <code><a href="seewave.html#topic+setenv">setenv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>donor = rnorm(500) * seq(1, 0, length.out = 500)
recipient = soundgen(sylLen = 600, addSilence = 50)
transplantEnv(donor, samplingRateD = 200,
               recipient, samplingRateR = 16000,
               windowLength = 50, method = 'hil', plot = TRUE)
transplantEnv(donor, samplingRateD = 200,
               recipient, samplingRateR = 16000,
               windowLength = 10, method = 'peak', plot = TRUE)
</code></pre>

<hr>
<h2 id='transplantFormants'>Transplant formants</h2><span id='topic+transplantFormants'></span>

<h3>Description</h3>

<p>Takes the general spectral envelope of one sound (<code>donor</code>) and
&quot;transplants&quot; it onto another sound (<code>recipient</code>). For biological sounds
like speech or animal vocalizations, this has the effect of replacing the
formants in the recipient sound while preserving the original intonation and
(to some extent) voice quality. Note that the amount of spectral smoothing
(specified with <code>freqWindow</code> or <code>blur</code>) is a crucial parameter: too
little smoothing, and noise between harmonics will be amplified, creasing
artifacts; too much, and formants may be missed. The default is to set
<code>freqWindow</code> to the estimated median pitch, but this is time-consuming
and error-prone, so set it to a reasonable value manually if possible. Also
ensure that both sounds have the same sampling rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transplantFormants(
  donor,
  recipient,
  samplingRate = NULL,
  freqWindow = NULL,
  blur = NULL,
  dynamicRange = 80,
  windowLength = 50,
  step = NULL,
  overlap = 90,
  wn = "gaussian",
  zp = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transplantFormants_+3A_donor">donor</code></td>
<td>
<p>the sound that provides the formants (vector, Wave, or file) or
the desired spectral filter (matrix) as returned by
<code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code></p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_recipient">recipient</code></td>
<td>
<p>the sound that receives the formants (vector, Wave, or file)</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_samplingrate">samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_freqwindow">freqWindow</code></td>
<td>
<p>the width of smoothing window used to flatten the
recipient's spectrum per frame. Defaults to median pitch of the donor (or
of the recipient if donor is a filter matrix). If <code>blur</code> is NULL,
<code>freqWindow</code> also controls the amount of smoothing applied to the
donor's spectrogram</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_blur">blur</code></td>
<td>
<p>the amount of Gaussian blur applied to the donor's spectrogram as
a faster and more flexible alternative to smoothing it per bin with
<code>freqWindow</code>. Provide two numbers: frequency (Hz, normally
approximately equal to freqWindow), time (ms) (NA / NULL / 0 means no
blurring in that dimension). See examples and <code><a href="#topic+spectrogram">spectrogram</a></code></p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_dynamicrange">dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_windowlength">windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_step">step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_overlap">overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_wn">wn</code></td>
<td>
<p>window type accepted by <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td></tr>
<tr><td><code id="transplantFormants_+3A_zp">zp</code></td>
<td>
<p>window length after zero padding, points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Algorithm: makes spectrograms of both sounds, interpolates and smooths or
blurs the donor spectrogram, flattens the recipient spectrogram, multiplies
the spectrograms, and transforms back into time domain with inverse STFT.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transplantEnv">transplantEnv</a></code> <code><a href="#topic+getSpectralEnvelope">getSpectralEnvelope</a></code>
<code><a href="#topic+addFormants">addFormants</a></code> <code><a href="#topic+spectrogram">spectrogram</a></code> <code><a href="#topic+soundgen">soundgen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Objective: take formants from the bleating of a sheep and apply them to a
# synthetic sound with any arbitrary duration, intonation, nonlinearities etc
data(sheep, package = 'seewave')  # import a recording from seewave
playme(sheep)
spectrogram(sheep, osc = TRUE)

recipient = soundgen(
  sylLen = 1200,
  pitch = c(100, 300, 250, 200),
  vibratoFreq = 9, vibratoDep = 1,
  addSilence = 180,
  samplingRate = sheep@samp.rate,  # same as donor
  invalidArgAction = 'ignore')  # force to keep the low samplingRate
playme(recipient, sheep@samp.rate)
spectrogram(recipient, sheep@samp.rate, osc = TRUE)

s1 = transplantFormants(
  donor = sheep,
  recipient = recipient,
  samplingRate = sheep@samp.rate)
playme(s1, sheep@samp.rate)
spectrogram(s1, sheep@samp.rate, osc = TRUE)

# The spectral envelope of s1 will be similar to sheep's on a frequency scale
# determined by freqWindow. Compare the spectra:
par(mfrow = c(1, 2))
seewave::meanspec(sheep, dB = 'max0', alim = c(-50, 20), main = 'Donor')
seewave::meanspec(s1, f = sheep@samp.rate, dB = 'max0',
                  alim = c(-50, 20), main = 'Processed recipient')
par(mfrow = c(1, 1))

# if needed, transplant amplitude envelopes as well:
s2 = transplantEnv(donor = sheep, samplingRateD = sheep@samp.rate,
                   recipient = s1, windowLength = 10)
playme(s2, sheep@samp.rate)
spectrogram(s2, sheep@samp.rate, osc = TRUE)

# using "blur" to apply Gaussian blur to the donor's spectrogram instead of
# smoothing per frame with "freqWindow" (~2.5 times faster)
spectrogram(sheep, blur = c(150, 0))  # preview to select the amount of blur
s1b = transplantFormants(
  donor = sheep,
  recipient = recipient,
  samplingRate = sheep@samp.rate,
  freqWindow = 150,
  blur = c(150, 0))
  # blur: 150 = SD of 150 Hz along the frequency axis,
  #      0 = no smoothing along the time axis
playme(s1b, sheep@samp.rate)
spectrogram(s1b, sheep@samp.rate, osc = TRUE)

# Now we use human formants on sheep source: the sheep asks "why?"
s3 = transplantFormants(
  donor = getSpectralEnvelope(
            nr = 512, nc = 100,  # fairly arbitrary dimensions
            formants = 'uaaai',
            samplingRate = sheep@samp.rate),
  recipient = sheep,
  samplingRate = sheep@samp.rate)
playme(s3, sheep@samp.rate)
spectrogram(s3, sheep@samp.rate, osc = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='updateAnalyze'>Update analyze</h2><span id='topic+updateAnalyze'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateAnalyze(
  result,
  pitch_true,
  pitchCands_list = NULL,
  spectrogram,
  freqs = NULL,
  bin = NULL,
  samplingRate = NULL,
  windowLength = NULL,
  harmHeight_pars = list(),
  subh_pars = list(),
  flux_pars = list(),
  fmRange = NULL,
  smooth,
  smoothing_ww,
  smoothingThres,
  varsToUnv = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="updateAnalyze_+3A_result">result</code></td>
<td>
<p>the matrix of results returned by analyze()</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_pitch_true">pitch_true</code></td>
<td>
<p>manual pitch contour of length nrow(result), with NAs</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_spectrogram">spectrogram</code></td>
<td>
<p>spectrogram with ncol = nrow(result)</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_freqs">freqs</code></td>
<td>
<p>frequency labels of spectrogram bins</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_bin">bin</code></td>
<td>
<p>spectrogram bin width</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_harmheight_pars">harmHeight_pars</code></td>
<td>
<p>same as argument &quot;harmHeight&quot; to analyze() - a list of
settings passed to soundgen:::harmHeight()</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_smooth">smooth</code>, <code id="updateAnalyze_+3A_smoothing_ww">smoothing_ww</code>, <code id="updateAnalyze_+3A_smoothingthres">smoothingThres</code></td>
<td>
<p>smoothing parameters</p>
</td></tr>
<tr><td><code id="updateAnalyze_+3A_varstounv">varsToUnv</code></td>
<td>
<p>set these variables to NA in unvoiced frames</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Updates the output of analyze using manual pitch. Called by pitch_app().
</p>

<hr>
<h2 id='upsampleGC'>Upsample glottal cycles</h2><span id='topic+upsampleGC'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>upsampleGC(pitch_per_gc, samplingRate = 16000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="upsampleGC_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>a vector of fundamental frequencies per glottal cycle</p>
</td></tr>
<tr><td><code id="upsampleGC_+3A_samplingrate">samplingRate</code></td>
<td>
<p>target sampling rate after upsampling, in Hz</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Upsamples a pitch contour to samplingRate through linear interpolation
between successive glottal cycles.
</p>


<h3>Value</h3>

<p>Returns a list of two vectors: pitch_upsampled (the upsampled version
of the input) and gc_upsampled (new indices of glottal cycles on an
upsampled scale)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::upsampleGC(pitch_per_gc = c(100, 150, 130), samplingRate = 16000)
</code></pre>

<hr>
<h2 id='validatePars'>Validate parameters</h2><span id='topic+validatePars'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validatePars(p, gp, def, invalidArgAction = c("adjust", "abort", "ignore")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validatePars_+3A_p">p</code></td>
<td>
<p>parameter name</p>
</td></tr>
<tr><td><code id="validatePars_+3A_gp">gp</code></td>
<td>
<p>parameter value</p>
</td></tr>
<tr><td><code id="validatePars_+3A_def">def</code></td>
<td>
<p>matrix or dataframe containing reference values (low, high,
default)</p>
</td></tr>
<tr><td><code id="validatePars_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range: 'adjust' = reset to default value, 'abort' = stop execution,
'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Checks whether the value of a numeric parameter falls within the allowed
range. Options: abort, reset to default, throw a warning and continue.
</p>

<hr>
<h2 id='warpMatrix'>Warp matrix</h2><span id='topic+warpMatrix'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>warpMatrix(m, scaleFactor, interpol = c("approx", "spline")[1])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="warpMatrix_+3A_m">m</code></td>
<td>
<p>matrix (rows = frequency bins, columns = time)</p>
</td></tr>
<tr><td><code id="warpMatrix_+3A_scalefactor">scaleFactor</code></td>
<td>
<p>1 = no change, &gt;1 = raise formants</p>
</td></tr>
<tr><td><code id="warpMatrix_+3A_interpol">interpol</code></td>
<td>
<p>interpolation method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Warps or scales each column of a matrix (normally a spectrogram).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = matrix(1:12, nrow = 4)
a
soundgen:::warpMatrix(a, 1.5, 'approx')
soundgen:::warpMatrix(a, 1/1.5, 'spline')
</code></pre>

<hr>
<h2 id='wiggleAnchors'>Randomly modify anchors</h2><span id='topic+wiggleAnchors'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wiggleAnchors(
  df,
  temperature = 0.05,
  temp_coef = 1,
  low = c(0, -Inf),
  high = c(1, Inf),
  wiggleAllRows = FALSE,
  sd_values = NULL,
  roundToInteger = FALSE,
  invalidArgAction = c("adjust", "abort", "ignore")[1]
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wiggleAnchors_+3A_df">df</code></td>
<td>
<p>dataframe of anchors, for ex. <code>data.frame(time = c(0, .1, .8,
1), value = c(100, 230, 180, 90))</code></p>
</td></tr>
<tr><td><code id="wiggleAnchors_+3A_temperature">temperature</code>, <code id="wiggleAnchors_+3A_temp_coef">temp_coef</code></td>
<td>
<p>regulate the amount of stochasticity
(&quot;wiggling&quot;). Since <code>temperature</code> is used in several functions,
<code>temp_coef</code> gives more flexibility by controlling how much temperature
affects this particular aspect, namely random variation in anchors. These
two are multiplied, so <code>temp_coef</code> of 0.5 halves the effect of
temperature.</p>
</td></tr>
<tr><td><code id="wiggleAnchors_+3A_low">low</code>, <code id="wiggleAnchors_+3A_high">high</code></td>
<td>
<p>bounds on possible variation. Both <code>low</code> and <code>high</code>
should be vectors of length 2: the first element specifies the boundary for
<code>df$time</code> and the second for <code>df$value</code>. Ex.: low = c(0,1) - low
bound on &quot;time&quot;=0, low bound on &quot;value&quot;=1</p>
</td></tr>
<tr><td><code id="wiggleAnchors_+3A_wiggleallrows">wiggleAllRows</code></td>
<td>
<p>should the first and last time anchors be wiggled? (TRUE
for breathing, FALSE for other anchors)</p>
</td></tr>
<tr><td><code id="wiggleAnchors_+3A_sd_values">sd_values</code></td>
<td>
<p>(optional) the exact value of sd used by rnorm_truncated2 in
columns 2 and beyond</p>
</td></tr>
<tr><td><code id="wiggleAnchors_+3A_roundtointeger">roundToInteger</code></td>
<td>
<p>if TRUE, rounds the values (not time points)</p>
</td></tr>
<tr><td><code id="wiggleAnchors_+3A_invalidargaction">invalidArgAction</code></td>
<td>
<p>what to do if an argument is invalid or outside the
range in <code>permittedValues</code>: 'adjust' = reset to default value, 'abort'
= stop execution, 'ignore' = throw a warning and continue (may crash)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A helper function for introducing random variation into any anchors (for
pitch / breathing / amplitude / ...). At higher temperatures can also add or
delete an anchor. NB: make sure the lower and upper bounds are reasonable
given the scale of df$value!
</p>


<h3>Value</h3>

<p>Modified original dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::wiggleAnchors(df = data.frame(
  time = c(0, .1, .8, 1), value = c(100, 230, 180, 90)),
  temperature = .2, temp_coef = .1, low = c(0, 50), high = c(1, 1000),
  wiggleAllRows = FALSE) # pitch
soundgen:::wiggleAnchors(df = data.frame(time = 0, value = 240),
  temperature = .2, temp_coef = .1, low = c(0, 50), high = c(1, 1000),
  wiggleAllRows = FALSE) # pitch, single anchor
soundgen:::wiggleAnchors(df = data.frame(
  time = c(-100, 100, 600, 900), value = c(-120, -80, 0, -120)),
  temperature = .4, temp_coef = .5, low = c(-Inf, -120), high = c(+Inf, 30),
  wiggleAllRows = TRUE) # noise
# formants
formants = list(f1 = list(time = 0, freq = 860, amp = 30, width = 120),
                f2 = list(time = c(0,1), freq = 1280,
                amp = c(10,40), width = 120))
for (f in seq_along(formants)) {
  formants[[f]] = soundgen:::wiggleAnchors(
    df = formants[[f]],
    temperature = .4, temp_coef = .5,
    low = c(0, 50, 0, 1),
    high = c(1, 8000, 120, 2000),
    wiggleAllRows = FALSE
  )
}
print(formants)

# manually provided sd (temp only affects prob of adding/dropping anchors)
soundgen:::wiggleAnchors(df = data.frame(
  time = c(0, .1, .8, 1), value = c(100, 230, 180, 90)),
  wiggleAllRows = FALSE, sd_values = 5)
</code></pre>

<hr>
<h2 id='wiggleGC'>Wiggle glottal cycles</h2><span id='topic+wiggleGC'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wiggleGC(dep, len, nGC, pitch_per_gc, rw, effect_on)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wiggleGC_+3A_dep">dep</code></td>
<td>
<p>a vector of any length specifying the strengh of applied effect as
2 ^ rnorm(..., 0, dep))</p>
</td></tr>
<tr><td><code id="wiggleGC_+3A_len">len</code></td>
<td>
<p>a vector of any length specifying the period of applied effect in
ms</p>
</td></tr>
<tr><td><code id="wiggleGC_+3A_ngc">nGC</code></td>
<td>
<p>number of glottal cycles</p>
</td></tr>
<tr><td><code id="wiggleGC_+3A_pitch_per_gc">pitch_per_gc</code></td>
<td>
<p>vector of length nGC specifying pitch per glottal cycle,
Hz</p>
</td></tr>
<tr><td><code id="wiggleGC_+3A_rw">rw</code></td>
<td>
<p>vector of length nGC specifying a random walk around 1 to multiply
the effect with</p>
</td></tr>
<tr><td><code id="wiggleGC_+3A_effect_on">effect_on</code></td>
<td>
<p>vector of length nGC specifying glottal cycles to which the
effect should be applied (0 = off, 1 = on)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for preparing a vector of multiplication factors for adding
jitter and shimmer per glottal cycle. Generates random anchors for each
jitter/shimmer period and draws a smooth contour between them by spline
interpolation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(soundgen:::wiggleGC(dep = 5 / 12, len = c(3, 50), nGC = 100,
              pitch_per_gc = rnorm(100, 150, 10),
              rw = rep(1, 100), effect_on = rep(1, 100)),
     type = 'b')
plot(soundgen:::wiggleGC(dep = 5 / 12, len = c(3, 50), nGC = 100,
              pitch_per_gc = rnorm(100, 150, 10),
              rw = rep(1, 100),
              effect_on = c(rep(1, 30), rep(0, 20), rep(1, 50))),
     type = 'b')
plot(soundgen:::wiggleGC(dep = c(1/12, 10/12), len = c(3, 50), nGC = 100,
              pitch_per_gc = rnorm(100, 150, 10),
              rw = rep(1, 100), effect_on = rep(1, 100)),
     type = 'b')
</code></pre>

<hr>
<h2 id='wigglePars'>Wiggle parameters</h2><span id='topic+wigglePars'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wigglePars(parList, parsToWiggle, probMutation, stepVariance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wigglePars_+3A_parlist">parList</code></td>
<td>
<p>full list of considered parameters</p>
</td></tr>
<tr><td><code id="wigglePars_+3A_parstowiggle">parsToWiggle</code></td>
<td>
<p>a list of the names of pars that might be mutated</p>
</td></tr>
<tr><td><code id="wigglePars_+3A_probmutation">probMutation</code></td>
<td>
<p>the probability of a parameter mutating per iteration</p>
</td></tr>
<tr><td><code id="wigglePars_+3A_stepvariance">stepVariance</code></td>
<td>
<p>scale factor for calculating the size of mutations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Helper function for <code><a href="#topic+matchPars">matchPars</a></code>. Takes a list of control
parameters for <code><a href="#topic+soundgen">soundgen</a></code> and introduces some random variation in
their values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>soundgen:::wigglePars(
  parList = list(
    sylLen = 250,
    pitch = data.frame(time = c(0, 1), value = c(200, 300))
  ),
  parsToWiggle = c('sylLen', 'pitch'),
  probMutation = .75,
  stepVariance = .5
)
</code></pre>

<hr>
<h2 id='writeAudio'>Write audio</h2><span id='topic+writeAudio'></span>

<h3>Description</h3>

<p>Internal soundgen function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>writeAudio(x, audio, filename, scale_used = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="writeAudio_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="writeAudio_+3A_audio">audio</code></td>
<td>
<p>list returned by <code><a href="#topic+readAudio">readAudio</a></code> containing
samplingRate, bit, scale, scale_used</p>
</td></tr>
<tr><td><code id="writeAudio_+3A_filename">filename</code></td>
<td>
<p>full path and filename including .wav</p>
</td></tr>
<tr><td><code id="writeAudio_+3A_scale_used">scale_used</code></td>
<td>
<p>actually used scale (max(abs(x))) - overrides
audio$scale_used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Writes a .wav file to disk based on the bit/scale/samplingRate contained in
the internally generated <code>audio</code> object. The point with using this
function is to package tuneR::Wave + normalize + writeWave in a
soundgen-specific way. Unlike seewave::savewav, writeAudio does NOT normalize
or rescale the input.
</p>

<hr>
<h2 id='zeroOne'>Normalize 0 to 1</h2><span id='topic+zeroOne'></span>

<h3>Description</h3>

<p>Internal soundgen function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeroOne(x, na.rm = FALSE, xmin = NULL, xmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zeroOne_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="zeroOne_+3A_na.rm">na.rm</code></td>
<td>
<p>if TRUE, remove NA's when calculating min/max for normalization</p>
</td></tr>
<tr><td><code id="zeroOne_+3A_xmin">xmin</code>, <code id="zeroOne_+3A_xmax">xmax</code></td>
<td>
<p>min and max (to save time if already known)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Normalized input vector to range from 0 to 1
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
