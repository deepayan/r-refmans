<!DOCTYPE html><html><head><title>Help for package configural</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {configural}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#configural-package'><p><span class="pkg">configural</span>: An R package for profile analysis</p></a></li>
<li><a href='#.fungible_extrema'><p>Locate extrema of fungible OLS regression weights</p></a></li>
<li><a href='#%&amp;%'><p>Quadratic form matrix product</p></a></li>
<li><a href='#adjust_Rsq'><p>Adjust a regression model R-squared for overfitting</p></a></li>
<li><a href='#complete_matrix'><p>Make a matrix symmetric by averaging with its transpose</p></a></li>
<li><a href='#cor_covariance'><p>Calculate the asymptotic sampling covariance matrix for the unique elements of a correlation matrix</p></a></li>
<li><a href='#cor_covariance_meta'><p>Estimate the asymptotic sampling covariance matrix for the unique elements of</p>
a meta-analytic correlation matrix</a></li>
<li><a href='#cor_labels'><p>Generate labels for correlations from a vector of variable names</p></a></li>
<li><a href='#cpa_mat'><p>Conduct criterion profile analysis using a correlation matrix</p></a></li>
<li><a href='#cpa_scores'><p>Compute CPA level and pattern scores for a set of data</p></a></li>
<li><a href='#disorders'><p>Meta-analytic correlations among Big Five personality traits and psychological disorders</p></a></li>
<li><a href='#fungible'><p>Locate extrema of fungible weights for regression and related models</p></a></li>
<li><a href='#fungible.cpa'><p>Locate extrema of fungible criterion profile patterns</p></a></li>
<li><a href='#fungible.lm'><p>Locate extrema of fungible OLS regression weights</p></a></li>
<li><a href='#gre'><p>Meta-analytic correlations of Graduate Record Examination subtests with graduate grade point average</p></a></li>
<li><a href='#harmonic_mean'><p>Find the harmonic mean of a vector, matrix, or columns of a data.frame</p></a></li>
<li><a href='#hrm'><p>Meta-analytic correlations of HRM practices with organizational financial performance</p></a></li>
<li><a href='#jobchar'><p>Meta-analytic correlations of job characteristics with performance and satisfaction</p></a></li>
<li><a href='#mindfulness'><p>Meta-analytic correlations among Big Five personality traits and trait mindfulness</p></a></li>
<li><a href='#n_effective_R2'><p>Effective sample size</p></a></li>
<li><a href='#prejudice'><p>Correlations between study design moderators and effect sizes for prejudice reduction following intergroup contact</p></a></li>
<li><a href='#team'><p>Meta-analytic correlations among team processes and team effectiveness</p></a></li>
<li><a href='#transition'><p>Calculate a transition matrix for a symmetric matrix</p></a></li>
<li><a href='#var_error_cpa'><p>Estimate the sampling error variance for criterion profile analysis parameters</p></a></li>
<li><a href='#vech'><p>Vectorize a matrix</p></a></li>
<li><a href='#vech2full'><p>Inverse vectorize a matrix</p></a></li>
<li><a href='#wt_cov'><p>Compute weighted covariances</p></a></li>
<li><a href='#wt_dist'><p>Weighted descriptive statistics for a vector of numbers</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multivariate Profile Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-11</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bwiernik/configural/issues">https://github.com/bwiernik/configural/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>R functions for criterion profile analysis, Davison and Davenport (2002) &lt;<a href="https://doi.org/10.1037%2F1082-989X.7.4.468">doi:10.1037/1082-989X.7.4.468</a>&gt; and meta-analytic criterion profile analysis, Wiernik, Wilmot, Davison, and Ones (2020) &lt;<a href="https://doi.org/10.1037%2Fmet0000305">doi:10.1037/met0000305</a>&gt;. Sensitivity analyses to aid in interpreting criterion profile analysis results are also included.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>crayon</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1.9000</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-18 17:16:43 UTC; brentonw</td>
</tr>
<tr>
<td>Author:</td>
<td>Brenton M. Wiernik [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brenton M. Wiernik &lt;brenton@wiernik.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-18 17:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='configural-package'><span class="pkg">configural</span>: An R package for profile analysis</h2><span id='topic+configural'></span><span id='topic+configural-package'></span>

<h3>Description</h3>

<p>Overview of the <span class="pkg">configural</span> package.
</p>


<h3>Details</h3>

<p>The <span class="pkg">configural</span> package provides tools for conducting configural and profile analyses. It currently supports criterion profile analysis (Davison &amp; Davenport, 2002) and meta-analytic criterion profile analysis (Wiernik et al., 2019). Functions are provided to calculate criterion patterns and CPA variance decomposition, as well as for computing confidence intervals, shrinkage corrections, and fungible patterns.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Brenton M. Wiernik <a href="mailto:brenton@wiernik.org">brenton@wiernik.org</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li><p> Report bugs at <a href="https://github.com/bwiernik/configural/issues">https://github.com/bwiernik/configural/issues</a>
</p>
</li></ul>


<hr>
<h2 id='.fungible_extrema'>Locate extrema of fungible OLS regression weights</h2><span id='topic+.fungible_extrema'></span>

<h3>Description</h3>

<p>Locate extrema of fungible OLS regression weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fungible_extrema(
  theta,
  Rxx,
  rxy,
  Nstarts = 1000,
  MaxMin = c("min", "max"),
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".fungible_extrema_+3A_theta">theta</code></td>
<td>
<p>The value of the R-squared decrement used to generate a family of fungible coefficients.</p>
</td></tr>
<tr><td><code id=".fungible_extrema_+3A_rxx">Rxx</code></td>
<td>
<p>An intercorrelation matrix among the predictor variables</p>
</td></tr>
<tr><td><code id=".fungible_extrema_+3A_rxy">rxy</code></td>
<td>
<p>A vector of predictor–criterion correlations</p>
</td></tr>
<tr><td><code id=".fungible_extrema_+3A_nstarts">Nstarts</code></td>
<td>
<p>The maximum number</p>
</td></tr>
<tr><td><code id=".fungible_extrema_+3A_maxmin">MaxMin</code></td>
<td>
<p>Should the cosine between the OLS and alternative weights be maximized (&quot;max&quot;) to find the maximally similar coefficients or minimized (&quot;min&quot;) to find the maximally dissimilar coefficients?</p>
</td></tr>
<tr><td><code id=".fungible_extrema_+3A_silent">silent</code></td>
<td>
<p>Should current optimization values be printed to the console (<code>FALSE</code>) or suppressed (<code>TRUE</code>)?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the alternative weights and other fungible weights estimation parameters
</p>


<h3>Author(s)</h3>

<p>Adapted from <code>fungible::fungibleExtrema()</code> by Niels Waller and Jeff Jones
</p>

<hr>
<h2 id='+25+26amp+3B+25'>Quadratic form matrix product</h2><span id='topic++25+26+25'></span>

<h3>Description</h3>

<p>Calculate the quadratic form </p>
<p style="text-align: center;"><code class="reqn">Q=x^{\prime}Ax</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>A %&amp;% x
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26amp+2B3B+2B25_+3A_a">A</code></td>
<td>
<p>A square matrix</p>
</td></tr>
<tr><td><code id="+2B25+2B26amp+2B3B+2B25_+3A_x">x</code></td>
<td>
<p>A vector or matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The quadratic product
</p>


<h3>Examples</h3>

<pre><code class='language-R'>diag(5) %&amp;% 1:5
</code></pre>

<hr>
<h2 id='adjust_Rsq'>Adjust a regression model R-squared for overfitting</h2><span id='topic+adjust_Rsq'></span>

<h3>Description</h3>

<p>Estimate shrinkage for regression models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_Rsq(Rsq, n, p, adjust = c("fisher", "pop", "cv"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust_Rsq_+3A_rsq">Rsq</code></td>
<td>
<p>Observed model R-squared</p>
</td></tr>
<tr><td><code id="adjust_Rsq_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="adjust_Rsq_+3A_p">p</code></td>
<td>
<p>Number of predictors</p>
</td></tr>
<tr><td><code id="adjust_Rsq_+3A_adjust">adjust</code></td>
<td>
<p>Which adjustment to apply. Options are &quot;fisher&quot; for the Adjusted R-squared method used in <code><a href="stats.html#topic+lm">stats::lm()</a></code>, &quot;pop&quot; for the positive-part Pratt estimator of the population R-squared, and &quot;cv&quot; for the Browne/positive-part Pratt estimator of the cross-validity R-squared. Based on Shieh (2008), these are the estimators for the population and cross-validity R-squared values that show the least bias with a minimal increase in computational complexity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An adjusted R-squared value.
</p>


<h3>References</h3>

<p>Shieh, G. (2008).
Improved shrinkage estimation of squared multiple correlation coefficient and squared cross-validity coefficient.
<em>Organizational Research Methods, 11</em>(2), 387–407. <a href="https://doi.org/10.1177/1094428106292901">doi:10.1177/1094428106292901</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adjust_Rsq(.55, 100, 6, adjust = "pop")
</code></pre>

<hr>
<h2 id='complete_matrix'>Make a matrix symmetric by averaging with its transpose</h2><span id='topic+complete_matrix'></span>

<h3>Description</h3>

<p>Makes a matrix symmetric by averaging the elements of the matrix and its
transpose. When This function fills in <code>NA</code> elements of a matrix with the corresponding
value from the matrix transpose, if available
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complete_matrix(m, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="complete_matrix_+3A_m">m</code></td>
<td>
<p>Numeric matrix to complete.</p>
</td></tr>
<tr><td><code id="complete_matrix_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be dropped? (default: <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A completed matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predictors &lt;- c('auto', 'skill_var', 'task_var', 'task_sig', 'task_id',
'fb_job', 'job_comp', 'interdep', 'fb_others', 'soc_support')
m &lt;- jobchar$sevar_r[c('perform', predictors), c('perform', predictors)]
complete_matrix(m)
</code></pre>

<hr>
<h2 id='cor_covariance'>Calculate the asymptotic sampling covariance matrix for the unique elements of a correlation matrix</h2><span id='topic+cor_covariance'></span>

<h3>Description</h3>

<p>Calculate the asymptotic sampling covariance matrix for the unique elements of a correlation matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_covariance(r, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_covariance_+3A_r">r</code></td>
<td>
<p>A correlation matrix</p>
</td></tr>
<tr><td><code id="cor_covariance_+3A_n">n</code></td>
<td>
<p>The sample size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The asymptotic sampling covariance matrix
</p>


<h3>Author(s)</h3>

<p>Based on an internal function from the <span class="pkg">fungible</span> package by Niels Waller
</p>


<h3>References</h3>

<p>Nel, D. G. (1985).
A matrix derivation of the asymptotic covariance matrix of sample correlation coefficients.
<em>Linear Algebra and Its Applications, 67</em>, 137–145. <a href="https://doi.org/10.1016/0024-3795%2885%2990191-0">doi:10.1016/0024-3795(85)90191-0</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor_covariance(matrix(c(1, .2, .3, .2, 1, .3, .3, .3, 1), ncol = 3), 100)
</code></pre>

<hr>
<h2 id='cor_covariance_meta'>Estimate the asymptotic sampling covariance matrix for the unique elements of
a meta-analytic correlation matrix</h2><span id='topic+cor_covariance_meta'></span>

<h3>Description</h3>

<p>Estimate the asymptotic sampling covariance matrix for the unique elements of
a meta-analytic correlation matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_covariance_meta(
  r,
  n,
  sevar,
  source = NULL,
  rho = NULL,
  sevar_rho = NULL,
  n_overlap = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_covariance_meta_+3A_r">r</code></td>
<td>
<p>A meta-analytic matrix of observed correlations (can be full or lower-triangular).</p>
</td></tr>
<tr><td><code id="cor_covariance_meta_+3A_n">n</code></td>
<td>
<p>A matrix of total sample sizes for the meta-analytic correlations in <code>r</code> (can be full or lower-triangular).</p>
</td></tr>
<tr><td><code id="cor_covariance_meta_+3A_sevar">sevar</code></td>
<td>
<p>A matrix of estimated sampling error variances for the meta-analytic correlations in <code>r</code> (can be full or lower-triangular).</p>
</td></tr>
<tr><td><code id="cor_covariance_meta_+3A_source">source</code></td>
<td>
<p>A matrix indicating the sources of the meta-analytic correlations in <code>r</code> (can be full or lower-triangular). Used to estimate overlapping sample size for correlations when <code>n_overlap == NULL</code>.</p>
</td></tr>
<tr><td><code id="cor_covariance_meta_+3A_rho">rho</code></td>
<td>
<p>A meta-analytic matrix of corrected correlations (can be full or lower-triangular).</p>
</td></tr>
<tr><td><code id="cor_covariance_meta_+3A_sevar_rho">sevar_rho</code></td>
<td>
<p>A matrix of estimated sampling error variances for the meta-analytic corrected correlations in <code>rho</code> (can be full or lower-triangular).</p>
</td></tr>
<tr><td><code id="cor_covariance_meta_+3A_n_overlap">n_overlap</code></td>
<td>
<p>A matrix indicating the overlapping sample size for the unique (lower triangular) values in <code>r</code> (can be full or lower-triangular). Values must be arranged in the order returned by <code>cor_labels(colnames(R))</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If both <code>source</code> and <code>n_overlap</code> are <code>NULL</code>, it is assumed that all meta-analytic correlations come from the the same source.
</p>


<h3>Value</h3>

<p>The estimated asymptotic sampling covariance matrix
</p>


<h3>References</h3>

<p>Nel, D. G. (1985).
A matrix derivation of the asymptotic covariance matrix of sample correlation coefficients.
<em>Linear Algebra and Its Applications, 67</em>, 137–145. <a href="https://doi.org/10.1016/0024-3795%2885%2990191-0">doi:10.1016/0024-3795(85)90191-0</a>
</p>
<p>Wiernik, B. M. (2018).
<em>Accounting for dependency in meta-analytic structural equations modeling: A flexible alternative to generalized least squares and two-stage structural equations modeling.</em>
Unpublished manuscript.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor_covariance_meta(r = mindfulness$r, n = mindfulness$n,
                    sevar = mindfulness$sevar_r, source = mindfulness$source)
</code></pre>

<hr>
<h2 id='cor_labels'>Generate labels for correlations from a vector of variable names</h2><span id='topic+cor_labels'></span>

<h3>Description</h3>

<p>This function returns a vector of labels for the unique correlations between pairs of variables from a supplied vector of variable names
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_labels(var_names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_labels_+3A_var_names">var_names</code></td>
<td>
<p>A character vector of variable names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of correlation labels
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor_labels(colnames(mindfulness$r))
</code></pre>

<hr>
<h2 id='cpa_mat'>Conduct criterion profile analysis using a correlation matrix</h2><span id='topic+cpa_mat'></span>

<h3>Description</h3>

<p>Conduct criterion profile analysis using a correlation matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpa_mat(
  formula,
  cov_mat,
  n = NULL,
  se_var_mat = NULL,
  se_beta_method = c("normal", "lm"),
  adjust = c("fisher", "pop", "cv"),
  conf_level = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cpa_mat_+3A_formula">formula</code></td>
<td>
<p>Regression formula with a single outcome variable on the left-hand side and one or more predictor variables on the right-hand side (e.g., Y ~ X1 + X2).</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_cov_mat">cov_mat</code></td>
<td>
<p>Correlation matrix containing the variables to be used in the regression.</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_n">n</code></td>
<td>
<p>Sample size. Used to compute adjusted R-squared and, if <code>se_var_mat</code> is NULL, standard errors. If NULL and <code>se_var_mat</code> is specified, effective sample size is computed based on <code>se_var_mat</code> (cf. Revelle et al., 2017).</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_se_var_mat">se_var_mat</code></td>
<td>
<p>Optional. The sampling error covariance matrix among the unique elements of <code>cov_mat</code>. Used to calculate standard errors. If not supplied, the sampling covariance matrix is calculated using <code>n</code>.</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_se_beta_method">se_beta_method</code></td>
<td>
<p>Method to use to estimate the standard errors of standardized regression (beta) coefficients. Current options include &quot;normal&quot; (use the Jones-Waller, 2015, normal-theory approach) and &quot;lm&quot; (estimate standard errors using conventional regression formulas).</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_adjust">adjust</code></td>
<td>
<p>Method to adjust R-squared for overfitting. See <code><a href="#topic+adjust_Rsq">adjust_Rsq()</a></code> for details.</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_conf_level">conf_level</code></td>
<td>
<p>Confidence level to use for confidence intervals.</p>
</td></tr>
<tr><td><code id="cpa_mat_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;cpa&quot; containing the criterion pattern vector and CPA variance decomposition
</p>


<h3>References</h3>

<p>Jones, J. A., &amp; Waller, N. G. (2015).
The normal-theory and asymptotic distribution-free (ADF) covariance matrix of standardized regression coefficients: Theoretical extensions and finite sample behavior.
<em>Psychometrika, 80</em>(2), 365–378. <a href="https://doi.org/10.1007/s11336-013-9380-y">doi:10.1007/s11336-013-9380-y</a>
</p>
<p>Revelle, W., Condon, D. M., Wilt, J., French, J. A., Brown, A., &amp; Elleman, L. G. (2017).
Web- and phone-based data collection using planned missing designs.
In N. G. Fielding, R. M. Lee, &amp; G. Blank, <em>The SAGE Handbook of Online Research Methods</em> (pp. 578–594).
SAGE Publications. <a href="https://doi.org/10.4135/9781473957992.n33">doi:10.4135/9781473957992.n33</a>
</p>
<p>Wiernik, B. M., Wilmot, M. P., Davison, M. L., &amp; Ones, D. S. (2019).
Meta-analytic criterion profile analysis.
<em>Psychological Methods</em> <a href="https://doi.org/10.1037/met0000305">doi:10.1037/met0000305</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sevar &lt;- cor_covariance_meta(mindfulness$r, mindfulness$n, mindfulness$sevar_r, mindfulness$source)
cpa_mat(mindfulness ~ ES + A + C + Ex + O,
          cov_mat = mindfulness$r,
          n = NULL,
          se_var_mat = sevar,
          adjust = "pop")
</code></pre>

<hr>
<h2 id='cpa_scores'>Compute CPA level and pattern scores for a set of data</h2><span id='topic+cpa_scores'></span>

<h3>Description</h3>

<p>Compute CPA level and pattern scores for a set of data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpa_scores(
  cpa_mod,
  newdata = NULL,
  augment = TRUE,
  cpa_names = c("cpa_lev", "cpa_pat"),
  scale = FALSE,
  scale_center = TRUE,
  scale_scale = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cpa_scores_+3A_cpa_mod">cpa_mod</code></td>
<td>
<p>A model returned from <code><a href="#topic+cpa_mat">cpa_mat()</a></code> (a model of class <code>"cpa"</code>)</p>
</td></tr>
<tr><td><code id="cpa_scores_+3A_newdata">newdata</code></td>
<td>
<p>A data frame or matrix containing columns with the same names as
the predictors in <code>cpa_mod</code>.</p>
</td></tr>
<tr><td><code id="cpa_scores_+3A_augment">augment</code></td>
<td>
<p>Should be CPA score columns be added to <code>newdata</code> (<code>TRUE</code>, default)
or returned alone (<code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="cpa_scores_+3A_cpa_names">cpa_names</code></td>
<td>
<p>Character vector of length 2 giving the variable names to assign
to the CPA score columns.</p>
</td></tr>
<tr><td><code id="cpa_scores_+3A_scale">scale</code></td>
<td>
<p>Logical. Should the variables in <code>newdata</code> be scaled (standardized)?</p>
</td></tr>
<tr><td><code id="cpa_scores_+3A_scale_center">scale_center</code></td>
<td>
<p>If <code>scale</code> is <code>TRUE</code>, passed to the <code>center</code> argument in
<code><a href="base.html#topic+scale">base::scale()</a></code>. Can be <code>TRUE</code> (center columns of <code>newdata</code> around the column
means), <code>FALSE</code> (don't center), or a numeric vector of length equal to the
number of predictors in <code>cpa_mod</code> containing the values to center around.</p>
</td></tr>
<tr><td><code id="cpa_scores_+3A_scale_scale">scale_scale</code></td>
<td>
<p>If <code>scale</code> is <code>TRUE</code>, passed to the <code>scale</code> argument in
<code><a href="base.html#topic+scale">base::scale()</a></code>. Can be <code>TRUE</code> (scale/standardize columns of <code>newdata</code> using
the column standard deviations or root mean squares), <code>FALSE</code> (don't scale),
or a numeric vector of length equal to the number of predictors in <code>cpa_mod</code>
containing the values to scale by. See <code><a href="base.html#topic+scale">base::scale()</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the CPA score variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sevar &lt;- cor_covariance_meta(mindfulness$r, mindfulness$n, mindfulness$sevar_r, mindfulness$source)
cpa_mod &lt;- cpa_mat(mindfulness ~ ES + A + C + Ex + O,
                   cov_mat = mindfulness$r,
                   n = NULL,
                   se_var_mat = sevar,
                   adjust = "pop")

newdata &lt;- data.frame(ES = c(4.2, 3.2, 3.4, 4.2, 3.8, 4.0, 5.6, 2.8, 3.4, 2.8),
                      A  = c(4.0, 4.2, 3.8, 4.6, 4.0, 4.6, 4.6, 2.6, 3.6, 5.4),
                      C  = c(2.8, 4.0, 4.0, 3.0, 4.4, 5.6, 4.4, 3.4, 4.0, 5.6),
                      Ex = c(3.8, 5.0, 4.2, 3.6, 4.8, 5.6, 4.2, 2.4, 3.4, 4.8),
                      O  = c(3.0, 4.0, 4.8, 3.2, 3.6, 5.0, 5.4, 4.2, 5.0, 5.2)
                      )

newdata_cpa &lt;- cpa_scores(cpa_mod, newdata, augment = FALSE)
newdata_augment &lt;- cpa_scores(cpa_mod, newdata, augment = TRUE)
</code></pre>

<hr>
<h2 id='disorders'>Meta-analytic correlations among Big Five personality traits and psychological disorders</h2><span id='topic+disorders'></span>

<h3>Description</h3>

<p>Big Five intercorrelations from Davies et al. (2015). Big Five–psychological
disorder correlations from Kotov et al. (2010). Note that there were several
duplicate or missing values in the reported data table in the published
article. These results are based on corrected data values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(disorders)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (mean observed correlations), <code>rho</code> (mean
corrected correlations), <code>n</code> (sample sizes), <code>sevar_r</code> (sampling error
variances for mean observed correlations), <code>sevar_rho</code> (sampling error
variances for mean corrected correlations), and <code>source</code> (character labels
indicating which meta-analytic correlations came from the same source)
</p>


<h3>References</h3>

<p>Davies, S. E., Connelly, B. L., Ones, D. S., &amp; Birkland, A. S. (2015).
The general factor of personality: The “Big One,” a self-evaluative trait, or a methodological gnat that won’t go away?
<em>Personality and Individual Differences, 81</em>, 13–22. <a href="https://doi.org/10.1016/j.paid.2015.01.006">doi:10.1016/j.paid.2015.01.006</a>
</p>
<p>Kotov, R., Gamez, W., Schmidt, F., &amp; Watson, D. (2010). Linking “big” personality traits to anxiety, depressive, and substance use disorders: A meta-analysis.
<em>Psychological Bulletin, 136</em>(5), 768–821. <a href="https://doi.org/10.1037/a0020327">doi:10.1037/a0020327</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(disorders)
</code></pre>

<hr>
<h2 id='fungible'>Locate extrema of fungible weights for regression and related models</h2><span id='topic+fungible'></span>

<h3>Description</h3>

<p>Generates fungible regression weights (Waller, 2008) and related results using the method by Waller and Jones (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fungible(
  object,
  theta = 0.005,
  Nstarts = 1000,
  MaxMin = c("min", "max"),
  silent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungible_+3A_object">object</code></td>
<td>
<p>A fitted model object. Currently supported classes are: &quot;cpa&quot;</p>
</td></tr>
<tr><td><code id="fungible_+3A_theta">theta</code></td>
<td>
<p>A vector of values to decrement from R-squared to compute families of fungible coefficients.</p>
</td></tr>
<tr><td><code id="fungible_+3A_nstarts">Nstarts</code></td>
<td>
<p>Maximum number of (max) minimizations from random starting configurations.</p>
</td></tr>
<tr><td><code id="fungible_+3A_maxmin">MaxMin</code></td>
<td>
<p>Should the cosine between the observed and alternative weights be maximized (&quot;max&quot;) to find the maximally similar coefficients or minimized (&quot;min&quot;) to find the maximally dissimilar coefficients?</p>
</td></tr>
<tr><td><code id="fungible_+3A_silent">silent</code></td>
<td>
<p>Should current optimization values be printed to the console (<code>FALSE</code>) or suppressed (<code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="fungible_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the alternative weights and other fungible weights estimation parameters
</p>


<h3>Author(s)</h3>

<p>Niels Waller, Jeff Jones, Brenton M. Wiernik. Adapted from <code>fungible::fungibleExtrema()</code>.
</p>


<h3>References</h3>

<p>Waller, N. G. (2008).
Fungible weights in multiple regression.
<em>Psychometrika, 73</em>(4), 691–703. <a href="https://doi.org/10.1007/s11336-008-9066-z">doi:10.1007/s11336-008-9066-z</a>
</p>
<p>Waller, N. G., &amp; Jones, J. A. (2009).
Locating the extrema of fungible regression weights.
<em>Psychometrika, 74</em>(4), 589–602. <a href="https://doi.org/10.1007/s11336-008-9087-7">doi:10.1007/s11336-008-9087-7</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mind &lt;- cpa_mat(mindfulness ~ ES + A + C + Ex + O,
                cov_mat = mindfulness$r,
                n = harmonic_mean(vechs(mindfulness$n)),
                se_var_mat = cor_covariance_meta(mindfulness$r,
                                                 mindfulness$n,
                                                 mindfulness$sevar_r,
                                                 mindfulness$source),
                adjust = "pop")
mind_fung &lt;- fungible(mind, Nstarts = 100)
</code></pre>

<hr>
<h2 id='fungible.cpa'>Locate extrema of fungible criterion profile patterns</h2><span id='topic+fungible.cpa'></span>

<h3>Description</h3>

<p>Identify maximally similar or dissimilar criterion patterns in criterion profile analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cpa'
fungible(
  object,
  theta = 0.005,
  Nstarts = 1000,
  MaxMin = c("min", "max"),
  silent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungible.cpa_+3A_object">object</code></td>
<td>
<p>A fitted model object of class &quot;cpa&quot;.</p>
</td></tr>
<tr><td><code id="fungible.cpa_+3A_theta">theta</code></td>
<td>
<p>A vector of values to decrement from R-squared to compute families of fungible coefficients.</p>
</td></tr>
<tr><td><code id="fungible.cpa_+3A_nstarts">Nstarts</code></td>
<td>
<p>Maximum number of (max) minimizations from random starting configurations.</p>
</td></tr>
<tr><td><code id="fungible.cpa_+3A_maxmin">MaxMin</code></td>
<td>
<p>Should the cosine between the observed and alternative weights be maximized (&quot;max&quot;) to find the maximally similar coefficients or minimized (&quot;min&quot;) to find the maximally dissimilar coefficients?</p>
</td></tr>
<tr><td><code id="fungible.cpa_+3A_silent">silent</code></td>
<td>
<p>Should current optimization values be printed to the console (<code>FALSE</code>) or suppressed (<code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="fungible.cpa_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the alternative weights and other fungible weights estimation parameters
</p>


<h3>References</h3>

<p>Wiernik, B. M., Wilmot, M. P., Davison, M. L., &amp; Ones, D. S. (2020).
Meta-analytic criterion profile analysis.
<em>Psychological Methods</em>. <a href="https://doi.org/10.1037/met0000305">doi:10.1037/met0000305</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mind &lt;- cpa_mat(mindfulness ~ ES + A + C + Ex + O,
                cov_mat = mindfulness$r,
                n = harmonic_mean(vechs(mindfulness$n)),
                se_var_mat = cor_covariance_meta(mindfulness$r,
                                                 mindfulness$n,
                                                 mindfulness$sevar_r,
                                                 mindfulness$source),
                adjust = "pop")
mind_fung &lt;- fungible(mind, Nstarts = 100)
</code></pre>

<hr>
<h2 id='fungible.lm'>Locate extrema of fungible OLS regression weights</h2><span id='topic+fungible.lm'></span>

<h3>Description</h3>

<p>Identify maximally similar or dissimilar sets of fungible standardized regression coefficients from an OLS regression model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm'
fungible(
  object,
  theta = 0.005,
  Nstarts = 1000,
  MaxMin = c("min", "max"),
  silent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fungible.lm_+3A_object">object</code></td>
<td>
<p>A fitted model object of class &quot;lm&quot; or &quot;summary.lm&quot;.</p>
</td></tr>
<tr><td><code id="fungible.lm_+3A_theta">theta</code></td>
<td>
<p>A vector of values to decrement from R-squared to compute families of fungible coefficients.</p>
</td></tr>
<tr><td><code id="fungible.lm_+3A_nstarts">Nstarts</code></td>
<td>
<p>Maximum number of (max) minimizations from random starting configurations.</p>
</td></tr>
<tr><td><code id="fungible.lm_+3A_maxmin">MaxMin</code></td>
<td>
<p>Should the cosine between the observed and alternative weights be maximized (&quot;max&quot;) to find the maximally similar coefficients or minimized (&quot;min&quot;) to find the maximally dissimilar coefficients?</p>
</td></tr>
<tr><td><code id="fungible.lm_+3A_silent">silent</code></td>
<td>
<p>Should current optimization values be printed to the console (<code>FALSE</code>) or suppressed (<code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="fungible.lm_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the alternative weights and other fungible weights estimation parameters
</p>


<h3>References</h3>

<p>Waller, N. G., &amp; Jones, J. A. (2009).
Locating the extrema of fungible regression weights.
<em>Psychometrika, 74</em>(4), 589–602. <a href="https://doi.org/10.1007/s11336-008-9087-7">doi:10.1007/s11336-008-9087-7</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lm_mtcars &lt;- lm(mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb,
                data = mtcars)
lm_mtcars_fung &lt;- fungible(lm_mtcars, Nstarts = 100)
</code></pre>

<hr>
<h2 id='gre'>Meta-analytic correlations of Graduate Record Examination subtests with graduate grade point average</h2><span id='topic+gre'></span>

<h3>Description</h3>

<p>Correlations between GRE subtests and graduate student GPA from Kuncel et al. (2001).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gre)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (mean observed correlations), <code>rho</code> (mean
corrected correlations), <code>n</code> (sample sizes), <code>sevar_r</code> (sampling error
variances for mean observed correlations), <code>sevar_rho</code> (sampling error
variances for mean corrected correlations), and <code>source</code> (character labels
indicating which meta-analytic correlations came from the same source)
</p>


<h3>Details</h3>

<p>GRE–GPA correlations in <code>rho</code> are corrected for direct range restriction on
the GRE and unreliability in GPA. Subtest intercorrelations in <code>rho</code> are
observed correlations computed among applicant norm samples. These values are
also used in <code>r</code>. Due to compensatory selection on GRE scores, these values
will not accurately reflect subtest intercorrelations in selected-student
(range-restricted) samples. <code>sevar_rho</code> and<code>sevar_r</code> for GRE subtest
intercorrelations are computed with an assumed
SD<sub>&rho;</sub> = .02.
</p>


<h3>References</h3>

<p>Kuncel, N. R., Hezlett, S. A., &amp; Ones, D. S. (2001).
A comprehensive meta-analysis of the predictive validity of the graduate record examinations: Implications for graduate student selection and performance.
<em>Psychological Bulletin, 127</em>(1), 162–181. <a href="https://doi.org/10.1037/0033-2909.127.1.162">doi:10.1037/0033-2909.127.1.162</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gre)
</code></pre>

<hr>
<h2 id='harmonic_mean'>Find the harmonic mean of a vector, matrix, or columns of a data.frame</h2><span id='topic+harmonic_mean'></span>

<h3>Description</h3>

<p>The harmonic mean is merely the reciprocal of the arithmetic mean of the reciprocals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmonic_mean(x, na.rm = TRUE, zero = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="harmonic_mean_+3A_x">x</code></td>
<td>
<p>A vector, matrix, or data.frame</p>
</td></tr>
<tr><td><code id="harmonic_mean_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. If <code>TRUE</code>, remove <code>NA</code> values before processing</p>
</td></tr>
<tr><td><code id="harmonic_mean_+3A_zero">zero</code></td>
<td>
<p>Logical, If <code>TRUE</code>, if there are any zeroes, return 0, else, return the harmonic mean of the non-zero elements</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The harmonic mean of x
</p>


<h3>Author(s)</h3>

<p>Adapted from <code>psych::harmonic.mean()</code> by William Revelle
</p>


<h3>Examples</h3>

<pre><code class='language-R'>harmonic_mean(1:10)
</code></pre>

<hr>
<h2 id='hrm'>Meta-analytic correlations of HRM practices with organizational financial performance</h2><span id='topic+hrm'></span>

<h3>Description</h3>

<p>Human resource management practice–organizational financial performance
correlations from Combs et al. (2006). Intercorrelations among HRM practices
from Guest et al. (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hrm)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (mean observed correlations), <code>rho</code> (mean
corrected correlations), <code>n</code> (sample sizes), <code>sevar_r</code> (sampling error
variances for mean observed correlations), <code>sevar_rho</code> (sampling error
variances for mean corrected correlations), and <code>source</code> (character labels
indicating which meta-analytic correlations came from the same source)
</p>


<h3>References</h3>

<p>Combs, J., Liu, Y., Hall, A., &amp; Ketchen, D. (2006).
How much do high-performance work practices matter? A meta-analysis of their effects on organizational performance.
<em>Personnel Psychology, 59</em>(3), 501–528. <a href="https://doi.org/10.1111/j.1744-6570.2006.00045.x">doi:10.1111/j.1744-6570.2006.00045.x</a>
</p>
<p>Guest, D., Conway, N., &amp; Dewe, P. (2004).
Using sequential tree analysis to search for ‘bundles’ of HR practices.
<em>Human Resource Management Journal, 14</em>(1), 79–96. <a href="https://doi.org/10.1111/j.1748-8583.2004.tb00113.x">doi:10.1111/j.1748-8583.2004.tb00113.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hrm)
</code></pre>

<hr>
<h2 id='jobchar'>Meta-analytic correlations of job characteristics with performance and satisfaction</h2><span id='topic+jobchar'></span>

<h3>Description</h3>

<p>Self-rated job characteristics intercorrelations and correlations with
other-rated job performance and self-rated job satisfaction from Humphrey et
al. (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(jobchar)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (mean observed correlations), <code>rho</code> (mean
corrected correlations), <code>n</code> (sample sizes), <code>sevar_r</code> (sampling error
variances for mean observed correlations), <code>sevar_rho</code> (sampling error
variances for mean corrected correlations), and <code>source</code> (character labels
indicating which meta-analytic correlations came from the same source)
</p>


<h3>References</h3>

<p>Humphrey, S. E., Nahrgang, J. D., &amp; Morgeson, F. P. (2007).
Integrating motivational, social, and contextual work design features: A meta-analytic summary and theoretical extension of the work design literature.
<em>Journal of Applied Psychology, 92</em>(5), 1332–1356. <a href="https://doi.org/10.1037/0021-9010.92.5.1332">doi:10.1037/0021-9010.92.5.1332</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(jobchar)
predictors &lt;- c('auto', 'skill_var', 'task_var', 'task_sig', 'task_id',
                'fb_job', 'job_comp', 'interdep', 'fb_others', 'soc_support')
sevar_jobchar_perf &lt;-
  cor_covariance_meta(
    r = jobchar$r[c('perform', predictors), c('perform', predictors)],
                    n = jobchar$n[c('perform', predictors), c('perform', predictors)],
                    sevar = jobchar$sevar_r[c('perform', predictors), c('perform', predictors)],
                    rho = jobchar$rho[c('perform', predictors), c('perform', predictors)],
                    sevar_rho = jobchar$sevar_rho[c('perform', predictors),
                                                  c('perform', predictors)],
                    source = jobchar$source[c('perform', predictors), c('perform', predictors)])
cpa_jobchar_perf &lt;- cpa_mat(perform ~ auto + skill_var + task_var + task_sig +
                              task_id + fb_job + job_comp +
                              interdep + fb_others + soc_support,
                            cov_mat = jobchar$rho,
                            n = harmonic_mean(as.vector(jobchar$n[c('perform', predictors),
                                                                  c('perform', predictors)])),
                            se_var_mat = sevar_jobchar_perf,
                            adjust = "pop", conf_level = .95)
</code></pre>

<hr>
<h2 id='mindfulness'>Meta-analytic correlations among Big Five personality traits and trait mindfulness</h2><span id='topic+mindfulness'></span>

<h3>Description</h3>

<p>Big Five intercorrelations from Davies et al. (2015). Big Five–Mindfulness
correlations from Hanley and Garland (2017). Coefficient alpha for
mindfulness measures taken from Giluk (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mindfulness)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (mean observed correlations), <code>rho</code> (mean
corrected correlations), <code>n</code> (sample sizes), <code>sevar_r</code> (sampling error
variances for mean observed correlations), <code>sevar_rho</code> (sampling error
variances for mean corrected correlations), and <code>source</code> (character labels
indicating which meta-analytic correlations came from the same source)
</p>


<h3>References</h3>

<p>Davies, S. E., Connelly, B. L., Ones, D. S., &amp; Birkland, A. S. (2015).
The general factor of personality: The “Big One,” a self-evaluative trait, or a methodological gnat that won’t go away?
<em>Personality and Individual Differences, 81</em>, 13–22. <a href="https://doi.org/10.1016/j.paid.2015.01.006">doi:10.1016/j.paid.2015.01.006</a>
</p>
<p>Giluk, T. L. (2009).
Mindfulness, Big Five personality, and affect: A meta-analysis.
<em>Personality and Individual Differences, 47</em>(8), 805–811. <a href="https://doi.org/10.1016/j.paid.2009.06.026">doi:10.1016/j.paid.2009.06.026</a>
</p>
<p>Hanley, A. W., &amp; Garland, E. L. (2017).
The mindful personality: A meta-analysis from a cybernetic perspective.
<em>Mindfulness, 8</em>(6), 1456–1470. <a href="https://doi.org/10.1007/s12671-017-0736-8">doi:10.1007/s12671-017-0736-8</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mindfulness)
</code></pre>

<hr>
<h2 id='n_effective_R2'>Effective sample size</h2><span id='topic+n_effective_R2'></span>

<h3>Description</h3>

<p>Estimate an effective sample size for a statistic given the observed statistic
and the estimated sampling error variance (cf. Revelle et al., 2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_effective_R2(R2, var_R2, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_effective_R2_+3A_r2">R2</code></td>
<td>
<p>Observed <em>R</em>^2^ value</p>
</td></tr>
<tr><td><code id="n_effective_R2_+3A_var_r2">var_R2</code></td>
<td>
<p>Estimated sampling error variance for <em>R</em>^2^</p>
</td></tr>
<tr><td><code id="n_effective_R2_+3A_p">p</code></td>
<td>
<p>Number of predictors in the regression model</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>n_effective_R2</code> estimates the effective sample size for the <em>R</em>^2^ value from
an OLS regression model, using the sampling error variance formula from Cohen
et al. (2003).
</p>


<h3>Value</h3>

<p>An effective sample size.
</p>


<h3>References</h3>

<p>Revelle, W., Condon, D. M., Wilt, J., French, J. A., Brown, A., &amp; Elleman, L. G. (2017).
Web- and phone-based data collection using planned missing designs.
In N. G. Fielding, R. M. Lee, &amp; G. Blank, <em>The SAGE Handbook of Online Research Methods</em> (pp. 578–594).
SAGE Publications. <a href="https://doi.org/10.4135/9781473957992.n33">doi:10.4135/9781473957992.n33</a>
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003).
<em>Applied multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.).
Routledge. <a href="https://doi.org/10.4324/9780203774441">doi:10.4324/9780203774441</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n_effective_R2(0.3953882, 0.0005397923, 5)
</code></pre>

<hr>
<h2 id='prejudice'>Correlations between study design moderators and effect sizes for prejudice reduction following intergroup contact</h2><span id='topic+prejudice'></span>

<h3>Description</h3>

<p>Correlations among study design moderators and study design
moderator–observed prejudice reduction effect sizes from Pettigrew and Tropp
(2008). Note that correlations with effect size have been reverse-coded so
that a positive correlation indicates that a higher level of the moderator is
associated with <em>larger</em> prejudice reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prejudice)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (observed correlations among moderators) and
<code>k</code> (number of samples in meta-analysis)
</p>


<h3>References</h3>

<p>Pettigrew, T. F., &amp; Tropp, L. R. (2006).
A meta-analytic test of intergroup contact theory.
<em>Journal of Personality and Social Psychology, 90</em>(5), 751–783. <a href="https://doi.org/10.1037/0022-3514.90.5.751">doi:10.1037/0022-3514.90.5.751</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(prejudice)
</code></pre>

<hr>
<h2 id='team'>Meta-analytic correlations among team processes and team effectiveness</h2><span id='topic+team'></span>

<h3>Description</h3>

<p>Team process intercorrelations and team process–team performance/affect
correlations from LePine et al. (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(team)
</code></pre>


<h3>Format</h3>

<p>list with entries <code>r</code> (mean observed correlations), <code>rho</code> (mean
corrected correlations), <code>n</code> (sample sizes), <code>sevar_r</code> (sampling error
variances for mean observed correlations), <code>sevar_rho</code> (sampling error
variances for mean corrected correlations), and <code>source</code> (character labels
indicating which meta-analytic correlations came from the same source)
</p>


<h3>Details</h3>

<p>Note that LePine et al. (2008) did not report confidence intervals, sampling
error variances, or heterogeneity estimates for correlations among team
processes; included sampling error variances in this list are based on total
sample size only and do not include uncertainty stemming from any effect
size heterogeneity.
</p>


<h3>References</h3>

<p>LePine, J. A., Piccolo, R. F., Jackson, C. L., Mathieu, J. E., &amp; Saul, J. R. (2008).
A meta-analysis of teamwork processes: tests of a multidimensional model and relationships with team effectiveness criteria.
<em>Personnel Psychology, 61</em>(2), 273–307. <a href="https://doi.org/10.1111/j.1744-6570.2008.00114.x">doi:10.1111/j.1744-6570.2008.00114.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(team)
</code></pre>

<hr>
<h2 id='transition'>Calculate a transition matrix for a symmetric matrix</h2><span id='topic+transition'></span>

<h3>Description</h3>

<p>The transition matrix extracts the lower triangular elements from a vectorized symmetric matrix (Nel, 1985).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transition(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transition_+3A_p">p</code></td>
<td>
<p>The number of columns in a matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Based on internal functions from the <span class="pkg">fungible</span> package by Niels Waller
</p>


<h3>References</h3>

<p>Nel, D. G. (1985).
A matrix derivation of the asymptotic covariance matrix of sample correlation coefficients.
<em>Linear Algebra and Its Applications, 67</em>, 137–145. <a href="https://doi.org/10.1016/0024-3795%2885%2990191-0">doi:10.1016/0024-3795(85)90191-0</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>transition(5)
</code></pre>

<hr>
<h2 id='var_error_cpa'>Estimate the sampling error variance for criterion profile analysis parameters</h2><span id='topic+var_error_cpa'></span>

<h3>Description</h3>

<p>Estimate the sampling error variance for criterion profile analysis parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_error_cpa(
  Rxx,
  rxy,
  n = NULL,
  se_var_mat = NULL,
  adjust = c("fisher", "pop", "cv")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_error_cpa_+3A_rxx">Rxx</code></td>
<td>
<p>An intercorrelation matrix among the predictor variables</p>
</td></tr>
<tr><td><code id="var_error_cpa_+3A_rxy">rxy</code></td>
<td>
<p>A vector of predictor–criterion correlations</p>
</td></tr>
<tr><td><code id="var_error_cpa_+3A_n">n</code></td>
<td>
<p>The sample size. If NULL and <code>se_var_mat</code> is provided, <code>n</code> will be estimated as the effective sample size based on <code>se_var_mat</code>. See <code><a href="#topic+n_effective_R2">n_effective_R2()</a></code>.</p>
</td></tr>
<tr><td><code id="var_error_cpa_+3A_se_var_mat">se_var_mat</code></td>
<td>
<p>A matrix of sampling covariance values for the elements of <code>Rxx</code> and <code>rxy</code>. If NULL, generated using the Normal theory covariance matrix based on <code>n</code>.</p>
</td></tr>
<tr><td><code id="var_error_cpa_+3A_adjust">adjust</code></td>
<td>
<p>Method to adjust R-squared for overfitting. See <code><a href="#topic+adjust_Rsq">adjust_Rsq</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing sampling covariance matrices or sampling error variance estimates for CPA parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>var_error_cpa(mindfulness$rho[1:5, 1:5], mindfulness$rho[1:5, 6], n = 17060)
</code></pre>

<hr>
<h2 id='vech'>Vectorize a matrix</h2><span id='topic+vech'></span><span id='topic+vechs'></span><span id='topic+cvec'></span><span id='topic+rvec'></span>

<h3>Description</h3>

<p><code>cvec</code> returns the column-wise vectorization of an input matrix (stacking
the columns on one another). <code>rvec</code> returns the row-wise vectorization of an
input matrix (concatenating the rows after each other). <code>vech</code> returns the
column-wise half-vectorization of an input matrix (stacking the lower
triangular elements of the matrix, including the diagonal). <code>vechs</code> returns
the strict column-wise half-vectorization of an input matrix (stacking the
lower triangular elements of the matrix, excluding the diagonal). All
functions return the output as a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vech(x)

vechs(x)

cvec(x)

rvec(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vech_+3A_x">x</code></td>
<td>
<p>A matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of values
</p>


<h3>Author(s)</h3>

<p>Based on functions from the the <span class="pkg">OpenMx</span> package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cvec(matrix(1:9, 3, 3))
rvec(matrix(1:9, 3, 3))
vech(matrix(1:9, 3, 3))
vechs(matrix(1:9, 3, 3))
vechs(matrix(1:12, 3, 4))
</code></pre>

<hr>
<h2 id='vech2full'>Inverse vectorize a matrix</h2><span id='topic+vech2full'></span><span id='topic+vechs2full'></span>

<h3>Description</h3>

<p>These functions return the symmetric matrix that produces the given
half-vectorization result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vech2full(x)

vechs2full(x, diagonal = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vech2full_+3A_x">x</code></td>
<td>
<p>A vector</p>
</td></tr>
<tr><td><code id="vech2full_+3A_diagonal">diagonal</code></td>
<td>
<p>A value or vector of values to enter on the diagonal for <code>vechs2full</code> (default = 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input consists of a vector of the elements in the lower triangle
of the resulting matrix (for <code>vech2full</code>, including the elements along the diagonal
of the matrix, as a column vector), filled column-wise. For <code>vechs2full</code>,
the diagonal values are filled as 1 by default, alternative values can be
specified using the <code>diag</code> argument. The inverse half-vectorization takes a
vector and reconstructs a symmetric matrix such that vech2full(vech(x)) is
identical to x if x is symmetric.
</p>


<h3>Value</h3>

<p>A symmetric matrix
</p>


<h3>Author(s)</h3>

<p>Based on functions from the the <span class="pkg">OpenMx</span> package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vech2full(c(1, 2, 3, 5, 6, 9))
vechs2full(c(2, 3, 6), diagonal = 0)
</code></pre>

<hr>
<h2 id='wt_cov'>Compute weighted covariances</h2><span id='topic+wt_cov'></span><span id='topic+wt_cor'></span>

<h3>Description</h3>

<p>Compute the weighted covariance among variables in a matrix or between the variables in two separate matrices/vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wt_cov(
  x,
  y = NULL,
  wt = NULL,
  as_cor = FALSE,
  use = c("everything", "listwise", "pairwise"),
  unbiased = TRUE,
  df_type = c("count", "sum_wts")
)

wt_cor(x, y = NULL, wt = NULL, use = "everything")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wt_cov_+3A_x">x</code></td>
<td>
<p>Vector or matrix of x variables.</p>
</td></tr>
<tr><td><code id="wt_cov_+3A_y">y</code></td>
<td>
<p>Vector or matrix of y variables</p>
</td></tr>
<tr><td><code id="wt_cov_+3A_wt">wt</code></td>
<td>
<p>Vector of weights</p>
</td></tr>
<tr><td><code id="wt_cov_+3A_as_cor">as_cor</code></td>
<td>
<p>Logical scalar that determines whether the covariances should be standardized (TRUE) or unstandardized (FALSE).</p>
</td></tr>
<tr><td><code id="wt_cov_+3A_use">use</code></td>
<td>
<p>Method for handling missing values. &quot;everything&quot; uses all values and does not account for missingness, &quot;listwise&quot; uses only complete cases, and &quot;pairwise&quot; uses pairwise deletion.</p>
</td></tr>
<tr><td><code id="wt_cov_+3A_unbiased">unbiased</code></td>
<td>
<p>Logical scalar determining whether variance should be unbiased (TRUE) or maximum-likelihood (FALSE).</p>
</td></tr>
<tr><td><code id="wt_cov_+3A_df_type">df_type</code></td>
<td>
<p>Character scalar determining whether the degrees of freedom for unbiased estimates should be based on numbers of cases (n - 1; &quot;count&quot;; default) or squared sums of weights (1 - sum(w^2); &quot;sum_wts&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Scalar, vector, or matrix of covariances.
</p>


<h3>Author(s)</h3>

<p>Jeffrey A. Dahlke
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wt_cov(x = c(1, 0, 2), y = c(1, 2, 3), wt = c(1, 2, 2), as_cor = FALSE, use = "everything")
wt_cov(x = c(1, 0, 2), y = c(1, 2, 3), wt = c(1, 2, 2), as_cor = TRUE, use = "everything")
wt_cov(x = cbind(c(1, 0, 2), c(1, 2, 3)), wt = c(1, 2, 2), as_cor = FALSE, use = "everything")
wt_cov(x = cbind(c(1, 0, 2), c(1, 2, 3)), wt = c(1, 2, 2), as_cor = TRUE, use = "everything")
wt_cov(x = cbind(c(1, 0, 2, NA), c(1, 2, 3, 3)),
       wt = c(1, 2, 2, 1), as_cor = FALSE, use = "listwise")
wt_cov(x = cbind(c(1, 0, 2, NA), c(1, 2, 3, 3)),
       wt = c(1, 2, 2, 1), as_cor = TRUE, use = "listwise")
</code></pre>

<hr>
<h2 id='wt_dist'>Weighted descriptive statistics for a vector of numbers</h2><span id='topic+wt_dist'></span><span id='topic+wt_mean'></span><span id='topic+wt_var'></span>

<h3>Description</h3>

<p>Compute the weighted mean and variance of a vector of numeric values. If no weights are supplied, defaults to computing the unweighted mean and the unweighted maximum-likelihood variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wt_dist(
  x,
  wt = rep(1, length(x)),
  unbiased = TRUE,
  df_type = c("count", "sum_wts")
)

wt_mean(x, wt = rep(1, length(x)))

wt_var(
  x,
  wt = rep(1, length(x)),
  unbiased = TRUE,
  df_type = c("count", "sum_wts")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wt_dist_+3A_x">x</code></td>
<td>
<p>Vector of values to be analyzed.</p>
</td></tr>
<tr><td><code id="wt_dist_+3A_wt">wt</code></td>
<td>
<p>Weights associated with the values in x.</p>
</td></tr>
<tr><td><code id="wt_dist_+3A_unbiased">unbiased</code></td>
<td>
<p>Logical scalar determining whether variance should be unbiased (TRUE) or maximum-likelihood (FALSE).</p>
</td></tr>
<tr><td><code id="wt_dist_+3A_df_type">df_type</code></td>
<td>
<p>Character scalar determining whether the degrees of freedom for unbiased estimates should be based on numbers of cases (&quot;count&quot;; default) or sums of weights (&quot;sum_wts&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weighted mean is computed as
</p>
<p style="text-align: center;"><code class="reqn">\bar{x}_{w}=\frac{\Sigma_{i=1}^{k}x_{i}w_{i}}{\Sigma_{i=1}^{k}w_{i}}</code>
</p>

<p>where <em>x</em> is a numeric vector and <em>w</em> is a vector of weights.
</p>
<p>The weighted variance is computed as
</p>
<p style="text-align: center;"><code class="reqn">var_{w}(x)=\frac{\Sigma_{i=1}^{k}\left(x_{i}-\bar{x}_{w}\right)^{2}w_{i}}{\Sigma_{i=1}^{k}w_{i}}</code>
</p>

<p>and the unbiased weighted variance is estimated by multiplying <code class="reqn">var_{w}(x)</code> by <code class="reqn">\frac{k}{k-1}</code>.
</p>


<h3>Value</h3>

<p>A weighted mean and variance if weights are supplied or an unweighted mean and variance if weights are not supplied.
</p>


<h3>Author(s)</h3>

<p>Jeffrey A. Dahlke
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wt_dist(x = c(.1, .3, .5), wt = c(100, 200, 300))
wt_mean(x = c(.1, .3, .5), wt = c(100, 200, 300))
wt_var(x = c(.1, .3, .5), wt = c(100, 200, 300))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
