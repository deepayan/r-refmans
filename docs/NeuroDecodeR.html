<!DOCTYPE html><html lang="en"><head><title>Help for package NeuroDecodeR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NeuroDecodeR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregate_CV_split_results'><p>A result metric (RM) method to aggregate results over cross-validation splits</p></a></li>
<li><a href='#aggregate_CV_split_results.rm_confusion_matrix'><p>A result metric (RM) method to aggregate results over cross-validation splits</p></a></li>
<li><a href='#aggregate_CV_split_results.rm_main_results'><p>A result metric (RM) method to aggregate results over cross-validation splits</p></a></li>
<li><a href='#aggregate_resample_run_results'><p>A result metric (RM) method to aggregate results over resample runs</p></a></li>
<li><a href='#aggregate_resample_run_results.rm_confusion_matrix'><p>A result metric (RM) method to aggregate results over resample runs</p></a></li>
<li><a href='#aggregate_resample_run_results.rm_main_results'><p>A result metric (RM) method to aggregate results over resample runs</p></a></li>
<li><a href='#cl_max_correlation'><p>A maximum correlation coefficient classifier (CL)</p></a></li>
<li><a href='#cl_poisson_naive_bayes'><p>A Poisson Naive Bayes classifier (CL)</p></a></li>
<li><a href='#cl_svm'><p>A support vector machine classifier (CL)</p></a></li>
<li><a href='#convert_matlab_raster_data'><p>Convert raster data in MATLAB to R</p></a></li>
<li><a href='#create_binned_data'><p>Convert data from raster format to binned format</p></a></li>
<li><a href='#cv_standard'><p>The standard cross-validator (CV)</p></a></li>
<li><a href='#ds_basic'><p>A basic datasource (DS)</p></a></li>
<li><a href='#ds_generalization'><p>A datasource (DS) that allows training and testing on different but related labels</p></a></li>
<li><a href='#fp_select_k_features'><p>A feature preprocessor (FP) that reduces data to the k most selective features</p></a></li>
<li><a href='#fp_zscore'><p>A feature preprocessor (FP) that z-score normalizes the data</p></a></li>
<li><a href='#get_data'><p>A datasource (DS) method to generate training and test sets</p></a></li>
<li><a href='#get_data.ds_basic'><p>A datasource (DS) method to generate training and test sets</p></a></li>
<li><a href='#get_data.ds_generalization'><p>A datasource (DS) method to generate training and test sets</p></a></li>
<li><a href='#get_num_label_repetitions'><p>Get the number of sites have at least k trials of each label level</p></a></li>
<li><a href='#get_num_label_repetitions_each_site'><p>Get the number of trial repetitions for a given label for each site</p></a></li>
<li><a href='#get_parameters'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.cl_max_correlation'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.cl_poisson_naive_bayes'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.cl_svm'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.cv_standard'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.ds_basic'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.ds_generalization'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.fp_select_k_features'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.fp_zscore'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.rm_confusion_matrix'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_parameters.rm_main_results'><p>Get parameters of an NeuroDecodeR object</p></a></li>
<li><a href='#get_predictions'><p>A classifier (CL) method to train the CL and return predictions</p></a></li>
<li><a href='#get_predictions.cl_max_correlation'><p>A classifier (CL) method to train the CL and return predictions</p></a></li>
<li><a href='#get_predictions.cl_poisson_naive_bayes'><p>A classifier (CL) method to train the CL and return predictions</p></a></li>
<li><a href='#get_predictions.cl_svm'><p>A classifier (CL) method to train the CL and return predictions</p></a></li>
<li><a href='#get_siteIDs_with_k_label_repetitions'><p>Get the sitesIDs that have at least k trials for all label level</p></a></li>
<li><a href='#log_check_results_already_exist'><p>A function that checks if a decoding analysis has already been run</p></a></li>
<li><a href='#log_load_results_from_params'><p>A function that loads DECODING_RESULTS based on decoding_parameters</p></a></li>
<li><a href='#log_load_results_from_result_name'><p>A function that loads DECODING_RESULTS based on the result_name</p></a></li>
<li><a href='#log_save_results'><p>Saves the DECODING_RESULTS and logs the parameters used in the analysis</p></a></li>
<li><a href='#NeuroDecodeR'><p>NeuroDecodeR: A package for neural decoding analyses</p></a></li>
<li><a href='#plot_main_results'><p>A plot function to plot multiple rm_main_results</p></a></li>
<li><a href='#plot.label_repetition'><p>A plot function for label_repetition object</p></a></li>
<li><a href='#plot.raster_data'><p>A plot function for data in raster format</p></a></li>
<li><a href='#plot.rm_confusion_matrix'><p>A plot function for the rm_confusion_matrix object</p></a></li>
<li><a href='#plot.rm_main_results'><p>A plot function for the rm_main_results object</p></a></li>
<li><a href='#preprocess_data'><p>A feature-preprocessor (FP) method to pre-process training and test data</p></a></li>
<li><a href='#preprocess_data.fp_select_k_features'><p>A feature-preprocessor (FP) method to pre-process training and test data</p></a></li>
<li><a href='#preprocess_data.fp_zscore'><p>A feature-preprocessor (FP) method to pre-process training and test data</p></a></li>
<li><a href='#read_matlab_raster_data'><p>Reads MATLAB raster data</p></a></li>
<li><a href='#read_raster_data'><p>Read a csv, rda, rds or mat file in raster format</p></a></li>
<li><a href='#rm_confusion_matrix'><p>A result metric (RM) that calculates confusion matrices</p></a></li>
<li><a href='#rm_main_results'><p>A result metric (RM) that calculates main decoding accuracy measures</p></a></li>
<li><a href='#run_decoding'><p>A cross-validator (CV) method to run a decoding analysis</p></a></li>
<li><a href='#run_decoding.cv_standard'><p>A cross-validator (CV) method to run a decoding analysis</p></a></li>
<li><a href='#test_valid_binned_format'><p>Tests if a data frame is in valid binned format</p></a></li>
<li><a href='#test_valid_ndr_object'><p>Tests if an object is a valid NDR object</p></a></li>
<li><a href='#test_valid_raster_format'><p>Tests if a data frame is in valid raster format</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Decode Information from Neural Activity</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Neural decoding is method of analyzing neural data that  
    uses a pattern classifiers to predict experimental conditions based 
    on neural activity. 'NeuroDecodeR' is a system of objects that 
    makes it easy to run neural decoding analyses. For more information
    on neural decoding see Meyers &amp; Kreiman (2011)
    &lt;<a href="https://doi.org/10.7551%2Fmitpress%2F8404.003.0024">doi:10.7551/mitpress/8404.003.0024</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://emeyers.github.io/NeuroDecodeR/">https://emeyers.github.io/NeuroDecodeR/</a>,
<a href="https://github.com/emeyers/NeuroDecodeR">https://github.com/emeyers/NeuroDecodeR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/emeyers/NeuroDecodeR/issues">https://github.com/emeyers/NeuroDecodeR/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, doSNOW, e1071, forcats, foreach, ggplot2, gridExtra,
magrittr, methods, purrr, R.matlab, scales, stats, stringr,
tibble, tictoc, tidyr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-15 04:47:30 UTC; emeyers</td>
</tr>
<tr>
<td>Author:</td>
<td>Ethan Meyers [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ethan Meyers &lt;ethan.meyers@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-15 11:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregate_CV_split_results'>A result metric (RM) method to aggregate results over cross-validation splits</h2><span id='topic+aggregate_CV_split_results'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all RM objects. This function
is called by the cross-validator results aggregated across all
cross-validation splits. This method should not be called directly but
instead is used internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_CV_split_results(rm_obj, prediction_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_CV_split_results_+3A_rm_obj">rm_obj</code></td>
<td>
<p>The results metric object.</p>
</td></tr>
<tr><td><code id="aggregate_CV_split_results_+3A_prediction_results">prediction_results</code></td>
<td>
<p>A data frame containing the prediction results to
be aggregated over CV splits. The results in this data frame are the
results returned by the CL's <code><a href="#topic+get_predictions">get_predictions()</a></code> method, along with a
column that specifies which cross-validation split the results come from.
Thus the columns in the <code>prediction_results</code> data frame are: * <em>CV</em>: The
cross-validation split number the results come from. * <em>test_time</em>: The
time bin a test point comes from. * <em>actual_labels</em>: The actual labels for
what happened on a trial. * <em>predicted_labels</em>: The predictions that
classifier made. * <em>decision_vals.___</em>: A set of columns with the
decision values for each class returned by the classifier.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A result-metric object that contains the decoding results aggregated
across cross-validation splits, and thus should take up less memory than
the original <code>prediction_results</code> that was passed in to this method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_main_results">rm_main_results()</a></code>, <code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix()</a></code>
</p>

<hr>
<h2 id='aggregate_CV_split_results.rm_confusion_matrix'>A result metric (RM) method to aggregate results over cross-validation splits</h2><span id='topic+aggregate_CV_split_results.rm_confusion_matrix'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all RM objects. This function
is called by the cross-validator results aggregated across all
cross-validation splits. This method should not be called directly but
instead is used internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_confusion_matrix'
aggregate_CV_split_results(rm_obj, prediction_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_CV_split_results.rm_confusion_matrix_+3A_rm_obj">rm_obj</code></td>
<td>
<p>The results metric object.</p>
</td></tr>
<tr><td><code id="aggregate_CV_split_results.rm_confusion_matrix_+3A_prediction_results">prediction_results</code></td>
<td>
<p>A data frame containing the prediction results to
be aggregated over CV splits. The results in this data frame are the
results returned by the CL's <code><a href="#topic+get_predictions">get_predictions()</a></code> method, along with a
column that specifies which cross-validation split the results come from.
Thus the columns in the <code>prediction_results</code> data frame are: * <em>CV</em>: The
cross-validation split number the results come from. * <em>test_time</em>: The
time bin a test point comes from. * <em>actual_labels</em>: The actual labels for
what happened on a trial. * <em>predicted_labels</em>: The predictions that
classifier made. * <em>decision_vals.___</em>: A set of columns with the
decision values for each class returned by the classifier.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A result-metric object that contains the decoding results aggregated
across cross-validation splits, and thus should take up less memory than
the original <code>prediction_results</code> that was passed in to this method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_main_results">rm_main_results()</a></code>, <code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix()</a></code>
</p>

<hr>
<h2 id='aggregate_CV_split_results.rm_main_results'>A result metric (RM) method to aggregate results over cross-validation splits</h2><span id='topic+aggregate_CV_split_results.rm_main_results'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all RM objects. This function
is called by the cross-validator results aggregated across all
cross-validation splits. This method should not be called directly but
instead is used internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_main_results'
aggregate_CV_split_results(rm_obj, prediction_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_CV_split_results.rm_main_results_+3A_rm_obj">rm_obj</code></td>
<td>
<p>The results metric object.</p>
</td></tr>
<tr><td><code id="aggregate_CV_split_results.rm_main_results_+3A_prediction_results">prediction_results</code></td>
<td>
<p>A data frame containing the prediction results to
be aggregated over CV splits. The results in this data frame are the
results returned by the CL's <code><a href="#topic+get_predictions">get_predictions()</a></code> method, along with a
column that specifies which cross-validation split the results come from.
Thus the columns in the <code>prediction_results</code> data frame are: * <em>CV</em>: The
cross-validation split number the results come from. * <em>test_time</em>: The
time bin a test point comes from. * <em>actual_labels</em>: The actual labels for
what happened on a trial. * <em>predicted_labels</em>: The predictions that
classifier made. * <em>decision_vals.___</em>: A set of columns with the
decision values for each class returned by the classifier.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A result-metric object that contains the decoding results aggregated
across cross-validation splits, and thus should take up less memory than
the original <code>prediction_results</code> that was passed in to this method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_main_results">rm_main_results()</a></code>, <code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix()</a></code>
</p>

<hr>
<h2 id='aggregate_resample_run_results'>A result metric (RM) method to aggregate results over resample runs</h2><span id='topic+aggregate_resample_run_results'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all RM objects. This function
is called by the cross-validator to aggregate results across all resample
runs. This method should not be called directly but instead it is used
internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_resample_run_results(resample_run_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_resample_run_results_+3A_resample_run_results">resample_run_results</code></td>
<td>
<p>The decoding results from all resample runs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A result metric object that contains the decoding results aggregated
across resample runs. This compressed final results can be plotted (often
by using the RM plot methods).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_main_results">rm_main_results()</a></code>, <code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix()</a></code>
</p>

<hr>
<h2 id='aggregate_resample_run_results.rm_confusion_matrix'>A result metric (RM) method to aggregate results over resample runs</h2><span id='topic+aggregate_resample_run_results.rm_confusion_matrix'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all RM objects. This function
is called by the cross-validator to aggregate results across all resample
runs. This method should not be called directly but instead it is used
internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_confusion_matrix'
aggregate_resample_run_results(resample_run_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_resample_run_results.rm_confusion_matrix_+3A_resample_run_results">resample_run_results</code></td>
<td>
<p>The decoding results from all resample runs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A result metric object that contains the decoding results aggregated
across resample runs. This compressed final results can be plotted (often
by using the RM plot methods).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_main_results">rm_main_results()</a></code>, <code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix()</a></code>
</p>

<hr>
<h2 id='aggregate_resample_run_results.rm_main_results'>A result metric (RM) method to aggregate results over resample runs</h2><span id='topic+aggregate_resample_run_results.rm_main_results'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all RM objects. This function
is called by the cross-validator to aggregate results across all resample
runs. This method should not be called directly but instead it is used
internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_main_results'
aggregate_resample_run_results(resample_run_results)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_resample_run_results.rm_main_results_+3A_resample_run_results">resample_run_results</code></td>
<td>
<p>The decoding results from all resample runs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A result metric object that contains the decoding results aggregated
across resample runs. This compressed final results can be plotted (often
by using the RM plot methods).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rm_main_results">rm_main_results()</a></code>, <code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix()</a></code>
</p>

<hr>
<h2 id='cl_max_correlation'>A maximum correlation coefficient classifier (CL)</h2><span id='topic+cl_max_correlation'></span>

<h3>Description</h3>

<p>An implementation of a maximum correlation coefficient classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cl_max_correlation(
  ndr_container_or_object = NULL,
  return_decision_values = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cl_max_correlation_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the cl_maximum_correlation classifier work with the pipe
(|&gt;) operator. This argument should almost never be directly set by the
user to anything other than NULL. If this is set to the default value of
NULL, then the constructor will return a cl_max_correlation object. If this
is set to an NDT container, then a cl_max_correlation object will be added
to the container and the container will be returned. If this argument is
set to another NDT object, then both that NDR object as well as a new
cl_maximum_correlation object will be added to a new container and the
container will be returned.</p>
</td></tr>
<tr><td><code id="cl_max_correlation_+3A_return_decision_values">return_decision_values</code></td>
<td>
<p>A Boolean specifying whether the prediction
function should return columns that have the decision values. Setting this
to FALSE will save memory so can be useful when analyzing very large high
temporal resolution data sets. However if this is set to FALSE&lt; metrics
won't be able to compute decoding accuracy measures that are based on the
decision values; e.g., the rm_main_results object won't be able to
calculate normalized rank decision values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This CL object learns a mean population vector (template) for each
class from the training set (by averaging together the all training points
within each class). The classifier is tested by calculated Pearson’s
correlation coefficient between a test point and the templates learned from
the training set, and the class with the highest correlation value is
returned as the predicted label. The decision values returned by the
classifier are the correlation coefficients between all test points and all
templates.
</p>
<p>Like all classifiers (CL) objects, this classifier has a private
get_predictions() method which learns a model based on training data and then
makes predictions on the test data.
</p>


<h3>Value</h3>

<p>This constructor creates an NDR classifier object with the class
<code>cl_max_correlation</code>. Like all NDR classifier objects, this classifier will
be used by a cross-validator to learn the relationship between neural
activity and experimental conditions on a training set of data, and then it
will be used to make predictions on a test set of data.
</p>


<h3>See Also</h3>

<p>Other classifier: 
<code><a href="#topic+cl_poisson_naive_bayes">cl_poisson_naive_bayes</a>()</code>,
<code><a href="#topic+cl_svm">cl_svm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># running a basic decoding analysis using the cl_max_correlation
data_file &lt;- system.file(file.path("extdata", "ZD_150bins_50sampled.Rda"),
                         package = "NeuroDecodeR")
ds &lt;- ds_basic(data_file, "stimulus_ID", 18)
fps &lt;- list(fp_zscore())

cl &lt;- cl_max_correlation()
cv &lt;- cv_standard(datasource = ds, 
                  classifier = cl, 
                  feature_preprocessors = fps,
                  num_resample_runs = 2)  # better to use more resample runs (default is 50)

DECODING_RESULTS &lt;- run_decoding(cv)


</code></pre>

<hr>
<h2 id='cl_poisson_naive_bayes'>A Poisson Naive Bayes classifier (CL)</h2><span id='topic+cl_poisson_naive_bayes'></span>

<h3>Description</h3>

<p>An implementation of a Poisson Naive Bayes classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cl_poisson_naive_bayes(
  ndr_container_or_object = NULL,
  return_decision_values = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cl_poisson_naive_bayes_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the cl_poisson_naive_bayes classifier work with magrittr
pipe (|&gt;) operator. This argument should almost never be directly set by
the user to anything other than NULL. If this is set to the default value
of NULL, then the constructor will return a cl_poisson_naive_bayes object.
If this is set to an ndr container, then a cl_poisson_naive_bayes object
will be added to the container and the container will be returned. If this
argument is set to another ndr object, then both that ndr object as well as
a new cl_poisson_naive_bayes object will be added to a new container and
the container will be returned.</p>
</td></tr>
<tr><td><code id="cl_poisson_naive_bayes_+3A_return_decision_values">return_decision_values</code></td>
<td>
<p>A Boolean specifying whether the prediction
function should return columns that have the decision values. Setting this
to FALSE will save memory so can be useful when analyzing very large high
temporal resolution data sets. However if this is set to FALSE&lt; metrics
won't be able to compute decoding accuracy measures that are based on the
decision values; e.g., the rm_main_results object won't be able to
calculate normalized rank decision values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This classifier object implements a Poisson Naive Bayes classifier. The
classifier works by learning the expected number of occurrences (denoted
lambda) for each feature and each class by taking the average of the training
data over all trials (separately for each feature and each class). To
evaluate whether a given test point belongs to class i, the log of the
likelihood function is calculated using the lambda values as parameters of
Poisson distributions (i.e., there is a separate Poisson distribution for
each feature, that is based on the lambda value for that feature). The
overall likelihood value is calculated by multiplying the probabilities for
each neuron together (i.e,. Naive Bayes classifiers assume that each feature
is independent), or equivalently, adding the log of the probabilities for
each feature together. The class with the highest likelihood value is chosen
as the predicted label, and the decision values are the log likelihood
values.
</p>
<p><strong>Note:</strong> this classifier uses spike counts, so the binned data must be
converted to use this classifier, for example, if you are using the basic_DS
data source, then use_count_data = TRUE should be set in the constructor.
Also, preprocessors that convert the data into values that are not integers
should not be used, for example, the fp_zscore should not be used with this
classifier.
</p>
<p>Like all classifiers, this classifier learning a model based on training data
and then makes predictions on new test data.
</p>


<h3>Value</h3>

<p>This constructor creates an NDR classifier object with the class
<code>cl_poisson_naive_bayes</code>. Like all NDR classifier objects, this classifier
will be used by a cross-validator to learn the relationship between neural
activity and experimental conditions on a training set of data, and then it
will be used to make predictions on a test set of data.
</p>


<h3>See Also</h3>

<p>Other classifier: 
<code><a href="#topic+cl_max_correlation">cl_max_correlation</a>()</code>,
<code><a href="#topic+cl_svm">cl_svm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># running a basic decoding analysis using the cl_max_correlation

data_file &lt;- system.file(file.path("extdata", "ZD_150bins_50sampled.Rda"),
                         package = "NeuroDecodeR")
ds &lt;- ds_basic(data_file, "stimulus_ID", 18, use_count_data = TRUE)
fps &lt;- list()

cl &lt;- cl_poisson_naive_bayes()
cv &lt;- cv_standard(datasource = ds, 
                  classifier = cl, 
                  feature_preprocessors = fps,
                  num_resample_runs = 2)  # better to use more resample runs (default is 50)

DECODING_RESULTS &lt;- run_decoding(cv)


</code></pre>

<hr>
<h2 id='cl_svm'>A support vector machine classifier (CL)</h2><span id='topic+cl_svm'></span>

<h3>Description</h3>

<p>This classifier uses the e1071 package to implement a support vector machine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cl_svm(ndr_container_or_object = NULL, return_decision_values = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cl_svm_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the cl_svm classifier works with the magrittr pipe (|&gt;)
operator. This argument should almost never be directly set by the user to
anything other than NULL. If this is set to the default value of NULL, then
the constructor will return a cl_svm object. If this is set to an ndr
container, then a cl_svm object will be added to the container and the
container will be returned. If this argument is set to another ndr object,
then both that ndr object as well as a new cl_svm object will be added to a
new container and the container will be returned.</p>
</td></tr>
<tr><td><code id="cl_svm_+3A_return_decision_values">return_decision_values</code></td>
<td>
<p>A Boolean specifying whether the prediction
function should return columns that have the decision values. Setting this
to FALSE will save memory so can be useful when analyzing very large high
temporal resolution data sets. However if this is set to FALSE&lt; metrics
won't be able to compute decoding accuracy measures that are based on the
decision values; e.g., the rm_main_results object won't be able to
calculate normalized rank decision values.</p>
</td></tr>
<tr><td><code id="cl_svm_+3A_...">...</code></td>
<td>
<p>All parameters that are available in the e1071 package svm()
object should work with this CL object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A support vector machine (SVM) is a classifier that learns a function <em>f</em> that
minimizes the hinge loss between predictions made on the training data, while
also applying a penalty for more complex <em>f</em> (the penalty is based on the norm
of <em>f</em> in a reproducing kernel Hilbert space). The SVM has a parameter <em>C</em> that
controls the trade off between the empirical loss (i.e., a smaller prediction
error on the training set), and the complexity of the <em>f</em>. SVMs can use
different kernels to create nonlinear decision boundaries.
</p>
<p>SVMs are work on binary classification problems, so to do
multi-class classification, an <em>all-pairs</em> classification scheme (which is
the default for the e1071 package). In the all-pairs scheme,training separate
classifiers for all pairs of labels (i.e., if there are 100 different classes
then nchoosek(100, 2) = 4950 different classifiers are trained). Testing the
classifier in all-pairs involves having all classifiers classify the test
point, and then the class label is given to the class the was chosen most
often by the binary classifiers (in the case of a tie in the number of
classes that won a contest the class label is randomly chosen). The decision
values for all-pairs are the number of contests won by each class (for each
test point).
</p>


<h3>Value</h3>

<p>This constructor creates an NDR classifier object with the class
<code>cl_svm</code>. Like all NDR classifier objects, this classifier will be used by
a cross-validator to learn the relationship between neural activity and
experimental conditions on a training set of data, and then it will be used
to make predictions on a test set of data.
</p>


<h3>See Also</h3>

<p>e1071
</p>
<p>Other classifier: 
<code><a href="#topic+cl_max_correlation">cl_max_correlation</a>()</code>,
<code><a href="#topic+cl_poisson_naive_bayes">cl_poisson_naive_bayes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the default e1071 parameters
cl &lt;- cl_svm()

# using a linear kernel
cl &lt;- cl_svm(kernel = "linear")

</code></pre>

<hr>
<h2 id='convert_matlab_raster_data'>Convert raster data in MATLAB to R</h2><span id='topic+convert_matlab_raster_data'></span>

<h3>Description</h3>

<p>If one already has raster data created in MATLAB (.mat files), this function
can be used to convert it to an R format (.rda files) that can be used with
the NDR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_matlab_raster_data(
  matlab_raster_dir_name,
  r_raster_dir_name = NULL,
  save_file_type = "rda",
  sampling_interval_width = 1,
  zero_time_bin = NULL,
  files_contain = "",
  add_sequential_trial_numbers = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_matlab_raster_data_+3A_matlab_raster_dir_name">matlab_raster_dir_name</code></td>
<td>
<p>A character string specifying the path to a
directory that contains raster data in MATLAB .mat files.</p>
</td></tr>
<tr><td><code id="convert_matlab_raster_data_+3A_r_raster_dir_name">r_raster_dir_name</code></td>
<td>
<p>A character string specifying the path to a
directory where the converted raster data in R files will be saved. If
this is not specified then the saved directory will have the same name as
the matlab directory with _rda appended to the end of the directory name.</p>
</td></tr>
<tr><td><code id="convert_matlab_raster_data_+3A_save_file_type">save_file_type</code></td>
<td>
<p>A character string specifying the format that the
raster data should be saved as. This must be set to a string that is either
&quot;rda&quot;, &quot;rds&quot;, or &quot;csv&quot;, and files will be saved to the corresponding
format.</p>
</td></tr>
<tr><td><code id="convert_matlab_raster_data_+3A_sampling_interval_width">sampling_interval_width</code></td>
<td>
<p>A number specifying how successive time bins
will be labeled The default value of 1 means that points will be labeled as
successive integers; i.e., time.1_2, time.2_3, etc. If this value was set
to a larger number, then time points will be specified at the given
sampling width. From example, if sampling_width is set to 10, then the time
labels would be time.1_10, time.10_20, etc. This is useful if the data is
sampled at a particular rate (e.g., if the data is sampled at 500Hz, one
might want to use sampling_interval_width = 2, so that the times listed on
the raster column names are in milliseconds).</p>
</td></tr>
<tr><td><code id="convert_matlab_raster_data_+3A_zero_time_bin">zero_time_bin</code></td>
<td>
<p>A number specifying the time bin that should be marked
as time 0. The default (NULL value) is to use the first bin as time 1.</p>
</td></tr>
<tr><td><code id="convert_matlab_raster_data_+3A_files_contain">files_contain</code></td>
<td>
<p>A string specifying that only a subset of the MATLAB
raster data should be converted based on .mat files that contain this
string.</p>
</td></tr>
<tr><td><code id="convert_matlab_raster_data_+3A_add_sequential_trial_numbers">add_sequential_trial_numbers</code></td>
<td>
<p>A Boolean specifying one should add a
variable to the data called 'trial_number' that has sequential trial. These
trials numbers are needed for data that was recorded simultaneously so that
trials can be aligned across different sites.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a string with the name of the directory that the .rda raster
files have been saved to.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


matlab_raster_dir_name &lt;- file.path(
  system.file("extdata", package = "NeuroDecodeR"),
  "Zhang_Desimone_7object_raster_data_small_mat"
)

# create temporary directory to hold converted data
r_raster_dir_name &lt;- tempdir()
r_raster_dir_name &lt;- convert_matlab_raster_data(matlab_raster_dir_name,
  r_raster_dir_name,
  files_contain = "bp1001spk"
)



</code></pre>

<hr>
<h2 id='create_binned_data'>Convert data from raster format to binned format</h2><span id='topic+create_binned_data'></span>

<h3>Description</h3>

<p>This function takes the name of a directory that contains files in raster
format and averages the data within a specified bin width at specified
sampling interval increments to create data in binned format used for
decoding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_binned_data(
  raster_dir_name,
  save_prefix_name,
  bin_width,
  sampling_interval,
  start_time = NULL,
  end_time = NULL,
  files_contain = "",
  num_parallel_cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_binned_data_+3A_raster_dir_name">raster_dir_name</code></td>
<td>
<p>A string that contains the path to a directory that
has files in raster format. These files will be combined into binned format
data.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_save_prefix_name">save_prefix_name</code></td>
<td>
<p>A string with a prefix that will be used name of file
that contains the saved binned format data.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_bin_width">bin_width</code></td>
<td>
<p>A number that has the number of data samples that data will
be averaged over.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_sampling_interval">sampling_interval</code></td>
<td>
<p>A number that has the specifies the sampling
interval between successive binned data points.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_start_time">start_time</code></td>
<td>
<p>A number that specifies the time to start binning the data.
This needs to be set to one of the start times in the raster data; i.e., if
data columns are in the format time.XXX_YYY, then the start_time must be
one of the XXX values. By default, the start_time is the first
time in the raster data.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_end_time">end_time</code></td>
<td>
<p>A number that specifies the time to end the binning of the data.
This needs to be set to one of the end times in the raster data; i.e., if
data columns are in the format time.XXX_YYY, then the start_time must be
one of the YYY values. By default, the end_time is the last
time in the raster data.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_files_contain">files_contain</code></td>
<td>
<p>A string that specifies that only raster files that
contain this string should be included in the binned format data.</p>
</td></tr>
<tr><td><code id="create_binned_data_+3A_num_parallel_cores">num_parallel_cores</code></td>
<td>
<p>An integer specifying the number of parallel cores
to use. The default (NULL) value is to use half of the cores detected on
the system. If this value is set to a value of less than 1, then the code
will be run serially.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a string with the name of the file that was created which has
the data in binnned format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create binned data with 150 ms bin sizes sampled at 10 ms intervals
raster_dir_name &lt;- file.path(
  "..", "data-raw", "raster",
  "Zhang_Desimone_7objects_raster_data_rda", ""
)

raster_dir_name &lt;- trimws(file.path(system.file("extdata", package = "NeuroDecodeR"), 
                          "Zhang_Desimone_7object_raster_data_small_rda", " "))


# The code could potentially run faster by using more parallel cores
# (e.g., by not setting the num_parallel_cores argument, half the cores available
#  will be used) 
binned_file_name &lt;- create_binned_data(raster_dir_name, 
                                      file.path(tempdir(), "ZD"), 
                                      150, 50,
                                      num_parallel_cores = 2)


</code></pre>

<hr>
<h2 id='cv_standard'>The standard cross-validator (CV)</h2><span id='topic+cv_standard'></span>

<h3>Description</h3>

<p>This object runs a decoding analysis where a classifier is repeatedly trained
and tested using cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_standard(
  ndr_container = NULL,
  datasource = NULL,
  classifier = NULL,
  feature_preprocessors = NULL,
  result_metrics = NULL,
  num_resample_runs = 50,
  run_TCD = TRUE,
  num_parallel_cores = NULL,
  parallel_outfile = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_standard_+3A_ndr_container">ndr_container</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the cv_standard cross-validator work with the magrittr
pipe (|&gt;) operator. This argument would almost always be set at the
end of a sequence of piping operators that include a datasource and a
classifier. Alternatively, one can keep this set to NULL and directly use
the datasource and classifier arguments (one would almost never use
both types of arguments). See the examples.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_datasource">datasource</code></td>
<td>
<p>A datasource (DS) object that will generate the training
and test data.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_classifier">classifier</code></td>
<td>
<p>A classifier (CS) object that will learn parameters based
on the training data and will generate predictions based on the test data.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_feature_preprocessors">feature_preprocessors</code></td>
<td>
<p>A list of feature preprocessor (FP) objects that
learn preprocessing parameters from the training data and apply
preprocessing of both the training and test data based on these parameters.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_result_metrics">result_metrics</code></td>
<td>
<p>A list of result metric (RM) objects that are used to
evaluate the classification performance. If this is set to NULL then the
rm_main_results(), rm_confusion_matrix() results metrics will be used.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_num_resample_runs">num_resample_runs</code></td>
<td>
<p>The number of times the cross-validation should be
run (i.e., &quot;resample runs&quot;), where on each run, new training and test sets
are generated. If pseudo-populations are used (e.g., with the ds_basic),
then new pseudo-populations will be generated on each resample run as well.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_run_tcd">run_TCD</code></td>
<td>
<p>A Boolean indicating whether a Temporal Cross-Decoding (TCD)
analysis should be run where the the classifier is trained and tested at
all points in time. Setting this to FALSE causes the classifier to only be
tested at same time it is trained on which can speed up the analysis run
time and save memory at the cost of not calculated the temporal cross
decoding results.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_num_parallel_cores">num_parallel_cores</code></td>
<td>
<p>An integers specifying the number of parallel cores
to use when executing the resample runs in the analysis. The default (NULL)
value is to use half of the cores detected on the system. If this value is
set to a value of less than 1, then the code will be run serially and
messages will be printed showing how long each CV split took to run which
is useful for debugging.</p>
</td></tr>
<tr><td><code id="cv_standard_+3A_parallel_outfile">parallel_outfile</code></td>
<td>
<p>A string specifying the name of a file where the
output from running the code in parallel is written (this argument is
ignored if num_parallel_cores &lt; 1). By default the parallel output is
written to dev/null so it is not accessible. If this is changed to an empty
string the output will be written to the screen, otherwise it will be
written to a file name specified. See parallel::makeCluster for more
details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A cross-validator object takes a datasource (DS), a classifier (CL),
feature preprocessors (FP) and result metric (RM) objects, and runs
multiple cross-validation cycles where:
</p>

<ol>
<li><p> A datasource (DS) generates training and test data splits of the data
</p>
</li>
<li><p> Feature preprocessors (FPs) do preprocessing of the data
</p>
</li>
<li><p> A classifier (CL) is trained and predictions are generated on a test set
</p>
</li>
<li><p> Result metrics (RMs) assess the accuracy of the predictions and compile
the results.
</p>
</li></ol>



<h3>Value</h3>

<p>This constructor creates an NDR cross-validator object with the class
<code>cv_standard</code>. Like all NDR cross-validator objects, one should use
<code>run_decoding</code> method to run a decoding analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_file &lt;- system.file("extdata/ZD_150bins_50sampled.Rda",
  package = "NeuroDecodeR")

ds &lt;- ds_basic(data_file, "stimulus_ID", 18)
fps &lt;- list(fp_zscore())
cl &lt;- cl_max_correlation()

cv &lt;- cv_standard(datasource = ds, 
                 classifier = cl, 
                 feature_preprocessors = fps,
                  num_resample_runs = 2)  # better to use more resample runs (default is 50)




# alternatively, one can also use the pipe (|&gt;) to do an analysis
data_file2 &lt;- system.file("extdata/ZD_500bins_500sampled.Rda",
  package = "NeuroDecodeR")
  
DECODING_RESULTS &lt;- data_file2 |&gt;
    ds_basic('stimulus_ID', 18) |&gt;
    cl_max_correlation() |&gt;
    fp_zscore() |&gt;
    rm_main_results() |&gt;
    rm_confusion_matrix() |&gt;
    cv_standard(num_resample_runs = 2) |&gt;
    run_decoding()




</code></pre>

<hr>
<h2 id='ds_basic'>A basic datasource (DS)</h2><span id='topic+ds_basic'></span>

<h3>Description</h3>

<p>The standard datasource used to get training and test splits of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_basic(
  binned_data,
  labels,
  num_cv_splits,
  use_count_data = FALSE,
  num_label_repeats_per_cv_split = 1,
  label_levels = NULL,
  num_resample_sites = NULL,
  site_IDs_to_use = NULL,
  site_IDs_to_exclude = NULL,
  randomly_shuffled_labels = FALSE,
  create_simultaneous_populations = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ds_basic_+3A_binned_data">binned_data</code></td>
<td>
<p>A string that list a path to a file that has data in
binned format, or a data frame of binned_data that is in binned format.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_labels">labels</code></td>
<td>
<p>A string specifying the name of the labels that should
be decoded. This label must be one of the columns in the binned data that
starts with 'label.'. For example, if there was a column name in a binned
data file called labels.stimulus_ID that you wanted to decode, then you
would set this argument to be &quot;stimulus_ID&quot;.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_num_cv_splits">num_cv_splits</code></td>
<td>
<p>A number specifying how many cross-validation splits
should be used.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_use_count_data">use_count_data</code></td>
<td>
<p>If the binned data is neural spike counts, then setting
use_count_data = TRUE will convert the data into spike counts. This is
useful for classifiers that work on spike count data, e.g., the
poisson_naive_bayes_CL.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_num_label_repeats_per_cv_split">num_label_repeats_per_cv_split</code></td>
<td>
<p>A number specifying how many times each
label should be repeated in each cross-validation split.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_label_levels">label_levels</code></td>
<td>
<p>A vector of strings specifying specific label
levels that should be used. If this is set to NULL then all label levels
available will be used.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_num_resample_sites">num_resample_sites</code></td>
<td>
<p>The number of sites that should be randomly
selected when constructing training and test vectors. This number needs to
be less than or equal to the number of sites available that have
num_cv_splits * num_label_repeats_per_cv_split repeats.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_site_ids_to_use">site_IDs_to_use</code></td>
<td>
<p>A vector of integers specifying which sites should be
used. If this is NULL (default value), then all sites that have
num_cv_splits * num_label_repeats_per_cv_split repeats will be used, and
a message about how many sites are used will be displayed.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_site_ids_to_exclude">site_IDs_to_exclude</code></td>
<td>
<p>A vector of integers specifying which sites should
be excluded.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_randomly_shuffled_labels">randomly_shuffled_labels</code></td>
<td>
<p>A Boolean specifying whether the labels
should be shuffled prior to running an analysis (i.e., prior to the first
call to the the get_data() method). This is used when one wants to create a
null distribution for comparing when decoding results are above chance.</p>
</td></tr>
<tr><td><code id="ds_basic_+3A_create_simultaneous_populations">create_simultaneous_populations</code></td>
<td>
<p>If the data from all sites
was recorded simultaneously, then setting this variable to 1 will cause the
get_data() function to return simultaneous populations rather than
pseudo-populations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This 'basic' datasource is the datasource that will most commonly be used for
most analyses. It can generate training and tests sets for data that has been
recorded simultaneously or pseudo-populations for data that was not recorded
simultaneously.
</p>
<p>Like all datasources, this datasource takes binned format data and has a
<code>get_data()</code> method that is never explicitly called by the user of the
package, but rather it is called internally by a cross-validation object to
get training and testing splits of data that can be passed to a classifier.
</p>


<h3>Value</h3>

<p>This constructor creates an NDR datasource object with the class
<code>ds_basic</code>. Like all NDR datasource objects, this datasource will be used
by the cross-validator to generate training and test data sets.
</p>


<h3>See Also</h3>

<p>Other datasource: 
<code><a href="#topic+ds_generalization">ds_generalization</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A typical example of creating a datasource to be passed cross-validation object
data_file &lt;- system.file(file.path("extdata", "ZD_150bins_50sampled.Rda"), package = "NeuroDecodeR")
ds &lt;- ds_basic(data_file, "stimulus_ID", 18)

# If one has many repeats of each label, decoding can be faster if one
# uses fewer CV splits and repeats each label multiple times in each split.
ds &lt;- ds_basic(data_file, "stimulus_ID", 6,
  num_label_repeats_per_cv_split = 3
)

# One can specify a subset of labels levels to be used in decoding. Here
#  we just do a three-way decoding analysis between "car", "hand" and "kiwi".
ds &lt;- ds_basic(data_file, "stimulus_ID", 18,
  label_levels = c("car", "hand", "kiwi")
)

# One never explicitly calls the get_data() function, but rather this is
# called by the cross-validator. However, to illustrate what this function
# does, we can call it explicitly here to get training and test data:
all_cv_data &lt;- get_data(ds)
names(all_cv_data)

</code></pre>

<hr>
<h2 id='ds_generalization'>A datasource (DS) that allows training and testing on different but related labels</h2><span id='topic+ds_generalization'></span>

<h3>Description</h3>

<p>This datasource is useful for assessing whether information is
invariant/abstract to particular conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds_generalization(
  binned_data,
  labels,
  num_cv_splits,
  train_label_levels,
  test_label_levels,
  use_count_data = FALSE,
  num_label_repeats_per_cv_split = 1,
  num_resample_sites = NULL,
  site_IDs_to_use = NULL,
  site_IDs_to_exclude = NULL,
  randomly_shuffled_labels = FALSE,
  create_simultaneous_populations = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ds_generalization_+3A_binned_data">binned_data</code></td>
<td>
<p>A string that list a path to a file that has data in
binned format, or a data frame of binned_data that is in binned format.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_labels">labels</code></td>
<td>
<p>A string specifying the name of the labels that
should be decoded. This label must be one of the columns in the binned
data that starts with 'label.'</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_num_cv_splits">num_cv_splits</code></td>
<td>
<p>A number specifying how many cross-validation splits
should be used.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_train_label_levels">train_label_levels</code></td>
<td>
<p>A list that contains vectors specifying which label
levels belong to which training class. Each element in the list corresponds
to a class that the specified training labels will be mapped to. For
example, values in the vector in the first element in the list will be
mapped onto the first training class, etc.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_test_label_levels">test_label_levels</code></td>
<td>
<p>A list that contains vectors specifying which label
levels belong to which test class. Each element in the list corresponds to
a class that the specified test labels will be mapped to. For example,
values in the vector in the first element in the list will be mapped onto
the first test class, etc. The number of elements in this list must be the
same as the number of elements in <code>train_label_levels</code>.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_use_count_data">use_count_data</code></td>
<td>
<p>If the binned data is neural spike counts, then setting
use_count_data = TRUE will convert the data into spike counts. This is
useful for classifiers that work on spike count data, e.g., the
poisson_naive_bayes_CL.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_num_label_repeats_per_cv_split">num_label_repeats_per_cv_split</code></td>
<td>
<p>A number specifying how many times each
label level should be repeated in each cross-validation split.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_num_resample_sites">num_resample_sites</code></td>
<td>
<p>The number of sites that should be randomly
selected when constructing training and test vectors. This number needs to
be less than or equal to the number of sites available that have
num_cv_splits * num_label_repeats_per_cv_split repeats.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_site_ids_to_use">site_IDs_to_use</code></td>
<td>
<p>A vector of integers specifying which sites should be
used.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_site_ids_to_exclude">site_IDs_to_exclude</code></td>
<td>
<p>A vector of integers specifying which sites should
be excluded.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_randomly_shuffled_labels">randomly_shuffled_labels</code></td>
<td>
<p>A Boolean specifying whether the labels
should be shuffled prior to running an analysis (i.e., prior to the first
call to the the get_data() method). This is used when one wants to create a
null distribution for comparing when decoding results are above chance.</p>
</td></tr>
<tr><td><code id="ds_generalization_+3A_create_simultaneous_populations">create_simultaneous_populations</code></td>
<td>
<p>If the data from all sites
were recorded simultaneously, then setting this variable to 1 will cause the
get_data() function to return simultaneous populations rather than
pseudo-populations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like all datasources, this datasource takes binned format data
and has a get_data() method that is called by a cross-validation object to
get training and testing splits of data that can be passed to a classifier.
</p>


<h3>Value</h3>

<p>This constructor creates an NDR datasource object with the class
<code>ds_generalization</code>. Like all NDR datasource objects, this datasource will
be used by the cross-validator to generate training and test data sets.
</p>


<h3>See Also</h3>

<p>Other datasource: 
<code><a href="#topic+ds_basic">ds_basic</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># One can test if a neural population contains information that is position
# invariant by generating training data for objects presented at 'upper' and 'middle'
# locations, and generating test data at a 'lower' location.

id_levels &lt;- c("hand", "flower", "guitar", "face", "kiwi", "couch", "car")
train_label_levels &lt;- NULL
test_label_levels &lt;- NULL
for (i in seq_along(id_levels)) {
  train_label_levels[[i]] &lt;- c(
    paste(id_levels[i], "upper", sep = "_"),
    paste(id_levels[i], "middle", sep = "_")
  )
  test_label_levels[[i]] &lt;- list(paste(id_levels[i], "lower", sep = "_"))
}


data_file &lt;- system.file("extdata/ZD_150bins_50sampled.Rda", package = "NeuroDecodeR")
ds &lt;- ds_generalization(
  data_file,
  "combined_ID_position", 18,
  train_label_levels,
  test_label_levels
)
</code></pre>

<hr>
<h2 id='fp_select_k_features'>A feature preprocessor (FP) that reduces data to the k most selective features</h2><span id='topic+fp_select_k_features'></span>

<h3>Description</h3>

<p>This feature preprocessor object applies an ANOVA to the training data to
find the p-value of all features. It then either uses the top k features with
the smallest p-values, or it removes the features with the smallest k
p-values. Additionally, this function can be used to remove the top k
p-values and then use only the following j next smallest p-values (for
example, this can be useful if one is interesting in comparing the
performance using the most selective 10 neurons to using the next 10 most
selective neurons, etc.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fp_select_k_features(
  ndr_container_or_object = NULL,
  num_sites_to_use = NA,
  num_sites_to_exclude = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fp_select_k_features_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the fp_select_k_features feature preprocessor work with the
pipe (|&gt;) operator. This argument should almost never be directly
set by the user to anything other than NULL. If this is set to the default
value of NULL, then the constructor will return a fp_select_k_features
object. If this is set to an ndr container, then a fp_select_k_features
object will be added to the container and the container will be returned.
If this argument is set to another ndr object, then both that ndr object as
well as a new fp_select_k_features object will be added to a new container
and the container will be returned.</p>
</td></tr>
<tr><td><code id="fp_select_k_features_+3A_num_sites_to_use">num_sites_to_use</code></td>
<td>
<p>The number of features with the smallest p-values to use.</p>
</td></tr>
<tr><td><code id="fp_select_k_features_+3A_num_sites_to_exclude">num_sites_to_exclude</code></td>
<td>
<p>The number of features with the smallest p-values
that should be excluded.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This constructor creates an NDR feature preprocessor object with the
class <code>fp_select_k_features</code>. Like all NDR feature preprocessor objects,
this feature preprocessor will be used by the cross-validator to
pre-process the training and test data sets.
</p>


<h3>See Also</h3>

<p>Other feature_preprocessor: 
<code><a href="#topic+fp_zscore">fp_zscore</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This will cause the cross-validator use only the 50 most selective sites
fp &lt;- fp_select_k_features(num_sites_to_use = 50)

# This will cause the cross-validator to remove the 20 most selective sites
fp &lt;- fp_select_k_features(num_sites_to_exclude = 20)

# This will cause the cross-validator to remove the 20 most selective sites
# and then use only the 50 most selective sites that remain after the 20 are
# eliminated
fp &lt;- fp_select_k_features(num_sites_to_use = 50, num_sites_to_exclude = 20)
</code></pre>

<hr>
<h2 id='fp_zscore'>A feature preprocessor (FP) that z-score normalizes the data</h2><span id='topic+fp_zscore'></span>

<h3>Description</h3>

<p>This feature preprocessor object finds the mean and standard deviation using
the training data. The preprocessor then z-score transforms the training and
test data using this mean and standard deviation by subtracting the mean and
dividing by the standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fp_zscore(ndr_container_or_object = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fp_zscore_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the fp_zscore feature preprocessor work with the
pipe (|&gt;) operator. This argument should almost never be directly set by
the user to anything other than NULL. If this is set to the default value
of NULL, then the constructor will return a fp_zscore object. If this is
set to an ndr container, then a fp_zscore object will be added to the
container and the container will be returned. If this argument is set to
another ndr object, then both that ndr object as well as a new fp_zscore
object will be added to a new container and the container will be returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This feature preprocessor object applies z-score normalization to
each feature by calculating the mean and the standard deviation for each
feature using the training data, and then subtracting the mean and dividing
by the standard deviation for each feature in the training and test sets.
This function is useful for preventing some classifiers from relying too
heavily on particular features when different features can have very
different ranges of values (for example, it is useful when decoding neural
data because different neurons can have different ranges of firing rates).
</p>


<h3>Value</h3>

<p>This constructor creates an NDR feature preprocessor object with the
class <code>fp_zscore</code>. Like all NDR feature preprocessor objects, this feature
preprocessor will be used by the cross-validator to pre-process the
training and test data sets.
</p>


<h3>See Also</h3>

<p>Other feature_preprocessor: 
<code><a href="#topic+fp_select_k_features">fp_select_k_features</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The fp_zscore() constructor does not take any parameters. This object
# just needs to added to a list and passed to the cross-validator applied
fp &lt;- fp_zscore()
</code></pre>

<hr>
<h2 id='get_data'>A datasource (DS) method to generate training and test sets</h2><span id='topic+get_data'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all DS objects. This method
should not be called directly but instead it is used internally by the
cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_data(ds_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_data_+3A_ds_obj">ds_obj</code></td>
<td>
<p>The datasource object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
data from one time point on a single trial.
</p>

<ul>
<li> <p><em>train_labels</em>: The labels that should be used when training the classifier.
</p>
</li>
<li> <p><em>test_labels</em>: The labels that should be used when the classifier
is tested. Note, this can be different than the training labels when
remapping the data using the <code><a href="#topic+ds_generalization">ds_generalization()</a></code> data source.
</p>
</li>
<li> <p><em>time_bin</em>: The time bin where the data point came from.
</p>
</li>
<li> <p><em>site_XXXX</em>: A set of columns with neural activity from each site.
</p>
</li>
<li> <p><em>CV_XX</em>: A set of columns that indicate for each
cross-validation split whether a data point belongs to the training or test
set.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ds_basic">ds_basic()</a></code>, <code><a href="#topic+ds_generalization">ds_generalization()</a></code>
</p>

<hr>
<h2 id='get_data.ds_basic'>A datasource (DS) method to generate training and test sets</h2><span id='topic+get_data.ds_basic'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all DS objects. This method
should not be called directly but instead it is used internally by the
cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds_basic'
get_data(ds_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_data.ds_basic_+3A_ds_obj">ds_obj</code></td>
<td>
<p>The datasource object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
data from one time point on a single trial.
</p>

<ul>
<li> <p><em>train_labels</em>: The labels that should be used when training the classifier.
</p>
</li>
<li> <p><em>test_labels</em>: The labels that should be used when the classifier
is tested. Note, this can be different than the training labels when
remapping the data using the <code><a href="#topic+ds_generalization">ds_generalization()</a></code> data source.
</p>
</li>
<li> <p><em>time_bin</em>: The time bin where the data point came from.
</p>
</li>
<li> <p><em>site_XXXX</em>: A set of columns with neural activity from each site.
</p>
</li>
<li> <p><em>CV_XX</em>: A set of columns that indicate for each
cross-validation split whether a data point belongs to the training or test
set.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ds_basic">ds_basic()</a></code>, <code><a href="#topic+ds_generalization">ds_generalization()</a></code>
</p>

<hr>
<h2 id='get_data.ds_generalization'>A datasource (DS) method to generate training and test sets</h2><span id='topic+get_data.ds_generalization'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all DS objects. This method
should not be called directly but instead it is used internally by the
cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds_generalization'
get_data(ds_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_data.ds_generalization_+3A_ds_obj">ds_obj</code></td>
<td>
<p>The datasource object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
data from one time point on a single trial.
</p>

<ul>
<li> <p><em>train_labels</em>: The labels that should be used when training the classifier.
</p>
</li>
<li> <p><em>test_labels</em>: The labels that should be used when the classifier
is tested. Note, this can be different than the training labels when
remapping the data using the <code><a href="#topic+ds_generalization">ds_generalization()</a></code> data source.
</p>
</li>
<li> <p><em>time_bin</em>: The time bin where the data point came from.
</p>
</li>
<li> <p><em>site_XXXX</em>: A set of columns with neural activity from each site.
</p>
</li>
<li> <p><em>CV_XX</em>: A set of columns that indicate for each
cross-validation split whether a data point belongs to the training or test
set.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ds_basic">ds_basic()</a></code>, <code><a href="#topic+ds_generalization">ds_generalization()</a></code>
</p>

<hr>
<h2 id='get_num_label_repetitions'>Get the number of sites have at least k trials of each label level</h2><span id='topic+get_num_label_repetitions'></span>

<h3>Description</h3>

<p>Calculates number of sites that have at least k label level
repetitions for all values k. This information is useful for assessing how to
set the number of cross-validation splits (and repeats of labels per
cross-validation split) to use in a datasource. One can also assess the
number of label level repetitions separately conditioned on another site_info
variable. For example, if one has recordings from different brain regions,
and the brain region information is contained in a site_info variable, then
one could calculate how many sites have at least k repetitions for each
stimulus in each brain region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_num_label_repetitions(
  binned_data,
  labels,
  site_info_grouping_name = NULL,
  label_levels = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_num_label_repetitions_+3A_binned_data">binned_data</code></td>
<td>
<p>A string that list a path to a file that has data in
binned format, or a data frame of binned_data that is in binned format.</p>
</td></tr>
<tr><td><code id="get_num_label_repetitions_+3A_labels">labels</code></td>
<td>
<p>A string specifying which label variable should be
used for calculating the minimum number of level repetitions.</p>
</td></tr>
<tr><td><code id="get_num_label_repetitions_+3A_site_info_grouping_name">site_info_grouping_name</code></td>
<td>
<p>A character string that specifies if the
number of sites that have k repetitions should be computed separately
based on the levels of a site_info variable.</p>
</td></tr>
<tr><td><code id="get_num_label_repetitions_+3A_label_levels">label_levels</code></td>
<td>
<p>A character vector specifying which levels to include.
If not set, all levels will be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the class <code>label_repetition</code> which allows the
results to be plotted. The returned data frame has a row for each label
level, and columns with sequential integer values k = 0, 1, ... The values
in the data frame show the number of sites that have at least k repetitions
of a given stimulus.
</p>


<h3>Note</h3>

<p>The returned value is an S3 object that inherits from data.frame that
has an associated plot() method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_file &lt;- system.file("extdata/ZD_150bins_50sampled.Rda", package = "NeuroDecodeR")
label_rep_info &lt;- get_num_label_repetitions(data_file, "stimulus_ID")
plot(label_rep_info)


</code></pre>

<hr>
<h2 id='get_num_label_repetitions_each_site'>Get the number of trial repetitions for a given label for each site</h2><span id='topic+get_num_label_repetitions_each_site'></span>

<h3>Description</h3>

<p>Calculates how many repeated trials there are for each label
level for each site. This can be useful for selecting sites that have a
minimum number of repetitions of each stimulus or other experimental
condition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_num_label_repetitions_each_site(binned_data, labels, label_levels = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_num_label_repetitions_each_site_+3A_binned_data">binned_data</code></td>
<td>
<p>A string that list a path to a file that has data in
binned format, or a data frame of binned_data that is in binned format.</p>
</td></tr>
<tr><td><code id="get_num_label_repetitions_each_site_+3A_labels">labels</code></td>
<td>
<p>A string specifying which label variable should be
used for calculating the minimum number of level repetitions.</p>
</td></tr>
<tr><td><code id="get_num_label_repetitions_each_site_+3A_label_levels">label_levels</code></td>
<td>
<p>A character vector specifying which levels to include.
If not set, all levels will be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame where each row corresponds to a recording site. The columns
in the data frame are:
</p>

<ul>
<li> <p><em>siteID</em>: The siteID each row in the data frame corresponds to
</p>
</li>
<li> <p><em>min_repeats</em>: minimum number of repeats across all label levels
</p>
</li>
<li> <p><em>level_XXX</em>: The number or repeats for a specific label level
</p>
</li>
<li> <p><em>site_info.XXX</em>: The site_info for each site
</p>
</li></ul>


<hr>
<h2 id='get_parameters'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.cl_max_correlation'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.cl_max_correlation'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cl_max_correlation'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.cl_max_correlation_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.cl_poisson_naive_bayes'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.cl_poisson_naive_bayes'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cl_poisson_naive_bayes'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.cl_poisson_naive_bayes_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.cl_svm'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.cl_svm'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cl_svm'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.cl_svm_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.cv_standard'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.cv_standard'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv_standard'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.cv_standard_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.ds_basic'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.ds_basic'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds_basic'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.ds_basic_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.ds_generalization'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.ds_generalization'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds_generalization'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.ds_generalization_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.fp_select_k_features'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.fp_select_k_features'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fp_select_k_features'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.fp_select_k_features_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.fp_zscore'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.fp_zscore'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fp_zscore'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.fp_zscore_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.rm_confusion_matrix'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.rm_confusion_matrix'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_confusion_matrix'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.rm_confusion_matrix_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_parameters.rm_main_results'>Get parameters of an NeuroDecodeR object</h2><span id='topic+get_parameters.rm_main_results'></span>

<h3>Description</h3>

<p>Returns the parameters set in an NDR object to enable reproducible analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_main_results'
get_parameters(ndr_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_parameters.rm_main_results_+3A_ndr_obj">ndr_obj</code></td>
<td>
<p>An object from the NeuroDecodeR package to get the parameters from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function that returns a data frame with the parameters of an
NeuroDecodeR (NDR) object. All NDR objects (i.e., DS, FP, CL, RM and CV) need
to define a method that implements this generic function. The CV object's
<code>get_parameters()</code> method usually will call all the DS, FP, CL, RM and CV
<code>get_parameters()</code> methods and aggregate and return all the parameters
aggregated from these objects. These aggregated parameters can then be used
to save the results of a particular analysis based on the parameters using
the <code><a href="#topic+log_save_results">log_save_results()</a></code> function. This method is most frequently used
privately by other NDR objects to save all the parameters that were used in
an analysis.
</p>


<h3>Value</h3>

<p>Returns a data frame with a single row that contains all the NDR
object's parameter values (e.g., values that were set in the object's
constructor).
</p>

<hr>
<h2 id='get_predictions'>A classifier (CL) method to train the CL and return predictions</h2><span id='topic+get_predictions'></span>

<h3>Description</h3>

<p><code>get_predictions</code> takes a training set and a test set of data. It trains the
CL object on the training set and returns the predictions of the on the test
set. This is a generic function that must be implemented by all CL objects.
This method should not be called directly but instead it is used internally
by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_predictions(cl_obj, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_predictions_+3A_cl_obj">cl_obj</code></td>
<td>
<p>The classifier object.</p>
</td></tr>
<tr><td><code id="get_predictions_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="get_predictions_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code>time_bin</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
prediction for one of the test points. The columns in this data frame are:
</p>

<ul>
<li> <p><em>test_time</em>: The time bin a test point came from.
</p>
</li>
<li> <p><em>actual_labels</em>: The actual labels for what happened on a trial.
</p>
</li>
<li> <p><em>predicted_labels</em>: The predictions that classifier made.
</p>
</li>
<li> <p><em>decision_vals.___</em>: A set of columns with the decision values
for each class.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cl_max_correlation">cl_max_correlation()</a></code>, <code><a href="#topic+cl_poisson_naive_bayes">cl_poisson_naive_bayes()</a></code>, <code><a href="#topic+cl_svm">cl_svm()</a></code>
</p>

<hr>
<h2 id='get_predictions.cl_max_correlation'>A classifier (CL) method to train the CL and return predictions</h2><span id='topic+get_predictions.cl_max_correlation'></span>

<h3>Description</h3>

<p><code>get_predictions</code> takes a training set and a test set of data. It trains the
CL object on the training set and returns the predictions of the on the test
set. This is a generic function that must be implemented by all CL objects.
This method should not be called directly but instead it is used internally
by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cl_max_correlation'
get_predictions(cl_obj, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_predictions.cl_max_correlation_+3A_cl_obj">cl_obj</code></td>
<td>
<p>The classifier object.</p>
</td></tr>
<tr><td><code id="get_predictions.cl_max_correlation_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="get_predictions.cl_max_correlation_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code>time_bin</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
prediction for one of the test points. The columns in this data frame are:
</p>

<ul>
<li> <p><em>test_time</em>: The time bin a test point came from.
</p>
</li>
<li> <p><em>actual_labels</em>: The actual labels for what happened on a trial.
</p>
</li>
<li> <p><em>predicted_labels</em>: The predictions that classifier made.
</p>
</li>
<li> <p><em>decision_vals.___</em>: A set of columns with the decision values
for each class.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cl_max_correlation">cl_max_correlation()</a></code>, <code><a href="#topic+cl_poisson_naive_bayes">cl_poisson_naive_bayes()</a></code>, <code><a href="#topic+cl_svm">cl_svm()</a></code>
</p>

<hr>
<h2 id='get_predictions.cl_poisson_naive_bayes'>A classifier (CL) method to train the CL and return predictions</h2><span id='topic+get_predictions.cl_poisson_naive_bayes'></span>

<h3>Description</h3>

<p><code>get_predictions</code> takes a training set and a test set of data. It trains the
CL object on the training set and returns the predictions of the on the test
set. This is a generic function that must be implemented by all CL objects.
This method should not be called directly but instead it is used internally
by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cl_poisson_naive_bayes'
get_predictions(cl_obj, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_predictions.cl_poisson_naive_bayes_+3A_cl_obj">cl_obj</code></td>
<td>
<p>The classifier object.</p>
</td></tr>
<tr><td><code id="get_predictions.cl_poisson_naive_bayes_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="get_predictions.cl_poisson_naive_bayes_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code>time_bin</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
prediction for one of the test points. The columns in this data frame are:
</p>

<ul>
<li> <p><em>test_time</em>: The time bin a test point came from.
</p>
</li>
<li> <p><em>actual_labels</em>: The actual labels for what happened on a trial.
</p>
</li>
<li> <p><em>predicted_labels</em>: The predictions that classifier made.
</p>
</li>
<li> <p><em>decision_vals.___</em>: A set of columns with the decision values
for each class.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cl_max_correlation">cl_max_correlation()</a></code>, <code><a href="#topic+cl_poisson_naive_bayes">cl_poisson_naive_bayes()</a></code>, <code><a href="#topic+cl_svm">cl_svm()</a></code>
</p>

<hr>
<h2 id='get_predictions.cl_svm'>A classifier (CL) method to train the CL and return predictions</h2><span id='topic+get_predictions.cl_svm'></span>

<h3>Description</h3>

<p><code>get_predictions</code> takes a training set and a test set of data. It trains the
CL object on the training set and returns the predictions of the on the test
set. This is a generic function that must be implemented by all CL objects.
This method should not be called directly but instead it is used internally
by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cl_svm'
get_predictions(cl_obj, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_predictions.cl_svm_+3A_cl_obj">cl_obj</code></td>
<td>
<p>The classifier object.</p>
</td></tr>
<tr><td><code id="get_predictions.cl_svm_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="get_predictions.cl_svm_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code>time_bin</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This method returns a data frame where each row corresponds to a
prediction for one of the test points. The columns in this data frame are:
</p>

<ul>
<li> <p><em>test_time</em>: The time bin a test point came from.
</p>
</li>
<li> <p><em>actual_labels</em>: The actual labels for what happened on a trial.
</p>
</li>
<li> <p><em>predicted_labels</em>: The predictions that classifier made.
</p>
</li>
<li> <p><em>decision_vals.___</em>: A set of columns with the decision values
for each class.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cl_max_correlation">cl_max_correlation()</a></code>, <code><a href="#topic+cl_poisson_naive_bayes">cl_poisson_naive_bayes()</a></code>, <code><a href="#topic+cl_svm">cl_svm()</a></code>
</p>

<hr>
<h2 id='get_siteIDs_with_k_label_repetitions'>Get the sitesIDs that have at least k trials for all label level</h2><span id='topic+get_siteIDs_with_k_label_repetitions'></span>

<h3>Description</h3>

<p>This function gets the siteIDs that have at least k label level
repetitions. These siteIDs can be used in a datasource to only get data
from sites that have enough label repetitions. For example, one could use
these siteIDs in conjunction with the ds_basic's site_IDs_to_use argument
to only get data from sites that have enough repetitions of each stimulus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_siteIDs_with_k_label_repetitions(
  binned_data,
  labels,
  k,
  label_levels = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_siteIDs_with_k_label_repetitions_+3A_binned_data">binned_data</code></td>
<td>
<p>A string that list a path to a file that has data in
binned format, or a data frame of binned_data that is in binned format.</p>
</td></tr>
<tr><td><code id="get_siteIDs_with_k_label_repetitions_+3A_labels">labels</code></td>
<td>
<p>A string specifying which label variable should be
used when calculating the minimum number of level repetitions.</p>
</td></tr>
<tr><td><code id="get_siteIDs_with_k_label_repetitions_+3A_k">k</code></td>
<td>
<p>A number specifying that all sitesIDs returned should have at least k
repetitions of all label levels.</p>
</td></tr>
<tr><td><code id="get_siteIDs_with_k_label_repetitions_+3A_label_levels">label_levels</code></td>
<td>
<p>A character vector specifying which levels to include.
If not set, all levels will be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of integers that specific which siteIDs have at least k
repetitions of each label level (from the label levels that are used).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_file &lt;- system.file("extdata/ZD_150bins_50sampled.Rda", package = "NeuroDecodeR")
get_siteIDs_with_k_label_repetitions(data_file, "stimulus_ID", 5)


</code></pre>

<hr>
<h2 id='log_check_results_already_exist'>A function that checks if a decoding analysis has already been run</h2><span id='topic+log_check_results_already_exist'></span>

<h3>Description</h3>

<p>A function that checks if a decoding analysis has already been run
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_check_results_already_exist(decoding_params, manifest_df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_check_results_already_exist_+3A_decoding_params">decoding_params</code></td>
<td>
<p>A data frame of decoding parameters that can
be created by calling the cross-validator's <code>get_parameters()</code> method.</p>
</td></tr>
<tr><td><code id="log_check_results_already_exist_+3A_manifest_df">manifest_df</code></td>
<td>
<p>A manifest data frame that has the list of parameters for
which decoding analyses have already been run.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a Boolean indicating if results with a given set of
parameters already exist in the manifest data frame.
</p>

<hr>
<h2 id='log_load_results_from_params'>A function that loads DECODING_RESULTS based on decoding_parameters</h2><span id='topic+log_load_results_from_params'></span>

<h3>Description</h3>

<p>A function that loads DECODING_RESULTS based on decoding_parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_load_results_from_params(decoding_params, results_dir_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_load_results_from_params_+3A_decoding_params">decoding_params</code></td>
<td>
<p>A data frame of decoding parameters that can
be created by calling the cross-validator's <code>get_parameters()</code> method.</p>
</td></tr>
<tr><td><code id="log_load_results_from_params_+3A_results_dir_name">results_dir_name</code></td>
<td>
<p>A string containing the path to a directory
that contains all the decoding results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list that has all the DECODING_RESULTS that match the parameters
that were specified. If only a single result matches the parameters
specified, then this DECODING_RESULTS is returned rather than a list of
DECODING_RESULTS.
</p>

<hr>
<h2 id='log_load_results_from_result_name'>A function that loads DECODING_RESULTS based on the result_name</h2><span id='topic+log_load_results_from_result_name'></span>

<h3>Description</h3>

<p>A function that loads DECODING_RESULTS based on the result_name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_load_results_from_result_name(result_name, results_dir_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_load_results_from_result_name_+3A_result_name">result_name</code></td>
<td>
<p>A string a specifying the result that should be loaded
based on the name given. This result_name can be a regular expression in
which all result_name values that match the regular expression will be
returned as a list.</p>
</td></tr>
<tr><td><code id="log_load_results_from_result_name_+3A_results_dir_name">results_dir_name</code></td>
<td>
<p>A string containing the path to a directory
that contains all the decoding results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list that has all the DECODING_RESULTS that match the
<code>result_name</code> argument value in the manifest file's <code>result_name</code> column.
The names on the list that are returned correspond to the result_names for
each result in the manifest file. If <code>result_name</code> argument matches only
one result, then this DECODING_RESULTS is returned rather than a list of
DECODING_RESULTS.
</p>

<hr>
<h2 id='log_save_results'>Saves the DECODING_RESULTS and logs the parameters used in the analysis</h2><span id='topic+log_save_results'></span>

<h3>Description</h3>

<p>This function takes results returned by the cross-validator's <code>run_decoding()</code>
method and uses the cross-validator's <code>get_properties()</code> method to save a log
of the results that be used to reload the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_save_results(
  DECODING_RESULTS,
  save_directory_name,
  result_name = "No result name set"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_save_results_+3A_decoding_results">DECODING_RESULTS</code></td>
<td>
<p>A list of results returned by the cross-validator's
run_decoding method.</p>
</td></tr>
<tr><td><code id="log_save_results_+3A_save_directory_name">save_directory_name</code></td>
<td>
<p>A string specifying the directory name where the
decoding results should be saved.</p>
</td></tr>
<tr><td><code id="log_save_results_+3A_result_name">result_name</code></td>
<td>
<p>A string that gives a human readable name for the results
that are to be saved. This name can be used to load the results later. The
default value is &quot;No result name set&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Does not return a value but instead creates a directory that stores
an .rda file with the decoding results and either creates or updates a
manifest files that has information about the decoding results.
</p>

<hr>
<h2 id='NeuroDecodeR'>NeuroDecodeR: A package for neural decoding analyses</h2><span id='topic+NeuroDecodeR'></span>

<h3>Description</h3>

<p>The NeuroDecodeR makes it easy to do neural decoding analyses in R!
</p>


<h3>Details</h3>

<p>The NeuroDecodeR (NDR) is built around five abstract object types that work
together in a modular way to allow a range of neural decoding analyses. These
five object types are:
</p>

<ol>
<li><p> Datasources (DS): Generate training and test splits of the data.
</p>
</li>
<li><p> Feature preprocessors (FP): Learn parameters on the training set and apply
transformations to the training and test sets.
</p>
</li>
<li><p> Classifiers (CL): Learn the relationship between experimental conditions
(i.e., &quot;labels&quot;) and neural data on a training set, and then predict
experimental conditions from neural data in a test set.
</p>
</li>
<li><p> Result metrics (RM): Aggregate results across validation splits and
over resampled runs and compute and plot final decoding accuracy metrics.
</p>
</li>
<li><p> Cross-validators (CV): Take the DS, FP, CL and RM objects and run a
cross-validation decoding procedure.
</p>
</li></ol>



<h3>Data formats</h3>

<p>Two data formats are used to do decoding analyses which are:
</p>

<ol>
<li> <p><code style="white-space: pre;">&#8288;raster format&#8288;</code> contains high temporal precision data where neural
activity from each site is stored in a separate file.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;binned format&#8288;</code> contains data from multiple sites where the data is more
coarsely binned across time.
</p>
</li></ol>

<p>A user of the NDR will typically store their data in <code style="white-space: pre;">&#8288;raster format&#8288;</code> and
then use the <code><a href="#topic+create_binned_data">create_binned_data()</a></code> to create a <code style="white-space: pre;">&#8288;binned format&#8288;</code> data file
that will be used in the decoding analysis.
</p>

<hr>
<h2 id='plot_main_results'>A plot function to plot multiple rm_main_results</h2><span id='topic+plot_main_results'></span>

<h3>Description</h3>

<p>This function can create a line plot of the results or temporal
cross-decoding results for the the zero-one loss, normalized rank and/or
decision values after the decoding analysis has been run (and all results
have been aggregated).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_main_results(
  results_dir_name,
  results_to_plot,
  results_to_show = "zero_one_loss",
  type = "line",
  errorbar = NULL,
  display_names = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_main_results_+3A_results_dir_name">results_dir_name</code></td>
<td>
<p>A string specifying the directory name that contains
files with DECODING_RESULTS that have rm_main_results as one of the result
metrics.</p>
</td></tr>
<tr><td><code id="plot_main_results_+3A_results_to_plot">results_to_plot</code></td>
<td>
<p>This can be set to a vector of strings specifying
result_names for the results to plot, or a vector of numbers that contain
the rows in the results_manifest file of the results that should be
compared. The results_manifest file should be created from saving results
using the log_save_results() function. Finally, if this is set to a single
string that is a regular expression, all results in the results_manifest
file result_name variable that match the regular expression will be
plotted.</p>
</td></tr>
<tr><td><code id="plot_main_results_+3A_results_to_show">results_to_show</code></td>
<td>
<p>A string specifying the types of results to plot. Options
are: 'zero_one_loss', 'normalized_rank', 'decision_values', or 'all'.</p>
</td></tr>
<tr><td><code id="plot_main_results_+3A_type">type</code></td>
<td>
<p>A string specifying the type of results to plot. Options are
'TCD' to plot a temporal cross decoding matrix or 'line' to create a line
plot of the decoding results as a function of time.</p>
</td></tr>
<tr><td><code id="plot_main_results_+3A_errorbar">errorbar</code></td>
<td>
<p>A string specifying if error bars should be plotted. Options
are: 'sd', 'se', or '2se'. If this is set to NULL, then no error bars will
be plotted. If this is set to 'sd', then the standard deviation of the
results will be plotted. If this is set to 'se', then the standard error of
the results will be plotted. If this is set to '2se', then two times the
standard error of the results will be plotted (which is often used to
represent a 95% confidence interval). Note, these error bars are slight
underestimates of the sd and sderr because when using cross-validation the
test data is not independent of the training data. Also, note that error
bars can only be plotted for line plots and not for TCD plots.</p>
</td></tr>
<tr><td><code id="plot_main_results_+3A_display_names">display_names</code></td>
<td>
<p>A vector of strings specifying what the labels on the
plots should say for each result. If this is NULL, the result names will be
the names from the manifest file's result_name column, or if these are set
to &quot;No result name set&quot; then the analysisID will be the label.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot object that a comparison of main decoding results.
</p>


<h3>See Also</h3>

<p>Other result_metrics: 
<code><a href="#topic+plot.rm_confusion_matrix">plot.rm_confusion_matrix</a>()</code>,
<code><a href="#topic+plot.rm_main_results">plot.rm_main_results</a>()</code>,
<code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix</a>()</code>,
<code><a href="#topic+rm_main_results">rm_main_results</a>()</code>
</p>

<hr>
<h2 id='plot.label_repetition'>A plot function for label_repetition object</h2><span id='topic+plot.label_repetition'></span>

<h3>Description</h3>

<p>This function plots the number of sites have at least k label repetitions.
Creating this plot is useful for assessing how to set the number of
cross-validation splits (and repeats of labels per cross-validation split) to
use in a datasource. This function returns a ggplot2 object which can be
further modified as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'label_repetition'
plot(x, ..., show_legend = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.label_repetition_+3A_x">x</code></td>
<td>
<p>A label_repetition object that was generated from calling the
get_num_label_repetitions() function.</p>
</td></tr>
<tr><td><code id="plot.label_repetition_+3A_...">...</code></td>
<td>
<p>This is needed to conform to the plot generic interface.</p>
</td></tr>
<tr><td><code id="plot.label_repetition_+3A_show_legend">show_legend</code></td>
<td>
<p>A Boolean specifying whether to show a legend
that list which label each color in the plot corresponds to.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>. Returns a ggplot object that plots the number of sites that
that have at least k label repetitions as a function of k.
</p>

<hr>
<h2 id='plot.raster_data'>A plot function for data in raster format</h2><span id='topic+plot.raster_data'></span>

<h3>Description</h3>

<p>This function will plot data that is in raster format. If the data is
a spike train consisting of only 0's and 1's then it will create a plot
of spikes as black tick marks on a white background. If the raster data
contains continuous data, then the plot will be color coded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'raster_data'
plot(x, ..., facet_label = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.raster_data_+3A_x">x</code></td>
<td>
<p>Either data that is in raster format, or a string containing the
name of a file that has data in raster format.</p>
</td></tr>
<tr><td><code id="plot.raster_data_+3A_...">...</code></td>
<td>
<p>This is needed to conform to the plot generic interface.</p>
</td></tr>
<tr><td><code id="plot.raster_data_+3A_facet_label">facet_label</code></td>
<td>
<p>If this is set to a string that is the name of one of the
labels in the raster data, then the raster plots will be faceted by
this label.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot object that plots the raster data.
</p>

<hr>
<h2 id='plot.rm_confusion_matrix'>A plot function for the rm_confusion_matrix object</h2><span id='topic+plot.rm_confusion_matrix'></span>

<h3>Description</h3>

<p>This function plots confusion matrices after the decoding analysis has been
run (and all results have been aggregated). This function can also plot
mutual information calculated from the confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_confusion_matrix'
plot(
  x,
  ...,
  results_to_show = "zero_one_loss",
  plot_TCD_results = FALSE,
  plot_only_one_train_time = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.rm_confusion_matrix_+3A_x">x</code></td>
<td>
<p>A rm_confusion_matrix object that has aggregated runs from a
decoding analysis, e.g., if DECODING_RESULTS are the output from the
run_decoding(cv) then this argument should be
<code>DECODING_RESULTS$rm_confusion_matrix</code>.</p>
</td></tr>
<tr><td><code id="plot.rm_confusion_matrix_+3A_...">...</code></td>
<td>
<p>This is needed to conform to the plot generic interface.</p>
</td></tr>
<tr><td><code id="plot.rm_confusion_matrix_+3A_results_to_show">results_to_show</code></td>
<td>
<p>A string specifying the type of result to plot that can
take the following values:
</p>

<ul>
<li><p> &quot;zero_one_loss&quot;: plot a regular confusion matrix.
</p>
</li>
<li><p> &quot;decision_vals&quot;: plot a confusion matrix with the average decision values.
</p>
</li>
<li><p> &quot;mutual_information&quot;: plot the mutual information calculated from the
zero-one loss confusion matrix.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.rm_confusion_matrix_+3A_plot_tcd_results">plot_TCD_results</code></td>
<td>
<p>A Boolean indicating whether the
a cross-temporal decoding of the confusion matrices should only be plotted.
If the <code>results_to_show == "mutual_information"</code> setting this to TRUE
will plot a TCD plot of the mutual information otherwise it will plot a
line plot of the mutual information for training and testing at the same
time.</p>
</td></tr>
<tr><td><code id="plot.rm_confusion_matrix_+3A_plot_only_one_train_time">plot_only_one_train_time</code></td>
<td>
<p>If this is set to a numeric value the the
confusion matrix will only be plotted for the training time <em>start time</em>
that is specified. If the number passed is not equal to an exact start
training time, then the closest training time will be used and a message
saying that the time specified does not exist will be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot object that plots the confusion matrix results.
</p>


<h3>See Also</h3>

<p>Other result_metrics: 
<code><a href="#topic+plot.rm_main_results">plot.rm_main_results</a>()</code>,
<code><a href="#topic+plot_main_results">plot_main_results</a>()</code>,
<code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix</a>()</code>,
<code><a href="#topic+rm_main_results">rm_main_results</a>()</code>
</p>

<hr>
<h2 id='plot.rm_main_results'>A plot function for the rm_main_results object</h2><span id='topic+plot.rm_main_results'></span>

<h3>Description</h3>

<p>This function can create a line plot of the results or temporal
cross-decoding results for the the zero-one loss, normalized rank and/or
decision values after the decoding analysis has been run (and all results
have been aggregated).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rm_main_results'
plot(x, ..., results_to_show = "zero_one_loss", errorbar = NULL, type = "TCD")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.rm_main_results_+3A_x">x</code></td>
<td>
<p>A rm_main_result object that has aggregated runs from a
decoding analysis, e.g., if DECODING_RESULTS are the out from the
run_decoding(cv) then this argument should be
<code>DECODING_RESULTS$rm_main_results</code>.</p>
</td></tr>
<tr><td><code id="plot.rm_main_results_+3A_...">...</code></td>
<td>
<p>This is needed to conform to the plot generic interface.</p>
</td></tr>
<tr><td><code id="plot.rm_main_results_+3A_results_to_show">results_to_show</code></td>
<td>
<p>A string specifying the types of results to plot. Options
are: 'zero_one_loss', 'normalized_rank', 'decision_values', or 'all'.</p>
</td></tr>
<tr><td><code id="plot.rm_main_results_+3A_errorbar">errorbar</code></td>
<td>
<p>A string specifying if error bars should be plotted. Options
are: 'sd', 'se', or '2se'. If this is set to NULL, then no error bars will
be plotted. If this is set to 'sd', then the standard deviation of the
results will be plotted. If this is set to 'se', then the standard error of
the results will be plotted. If this is set to '2se', then two times the
standard error of the results will be plotted (which is often used to
represent a 95% confidence interval). Note, these error bars are slight
underestimates of the sd and sderr because when using cross-validation the
test data is not independent of the training data. Also, note that error
bars can only be plotted for line plots and not for TCD plots.</p>
</td></tr>
<tr><td><code id="plot.rm_main_results_+3A_type">type</code></td>
<td>
<p>A string specifying the type of results to plot. Options are
'TCD' to plot a temporal cross decoding matrix or 'line' to create a line
plot of the decoding results as a function of time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot object that plots the main results.
</p>


<h3>See Also</h3>

<p>Other result_metrics: 
<code><a href="#topic+plot.rm_confusion_matrix">plot.rm_confusion_matrix</a>()</code>,
<code><a href="#topic+plot_main_results">plot_main_results</a>()</code>,
<code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix</a>()</code>,
<code><a href="#topic+rm_main_results">rm_main_results</a>()</code>
</p>

<hr>
<h2 id='preprocess_data'>A feature-preprocessor (FP) method to pre-process training and test data</h2><span id='topic+preprocess_data'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all FP objects. This object
learns a set of parameters from the training data (i.e., the data generated
from a datasource get_data() method). The <code>preprocess_data()</code> method then
uses these parameters do processing on the training and test data before the
data is sent to the classifier. This method should not be called directly but
instead it is used internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocess_data(fp, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preprocess_data_+3A_fp">fp</code></td>
<td>
<p>The FP object.</p>
</td></tr>
<tr><td><code id="preprocess_data_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="preprocess_data_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code style="white-space: pre;">&#8288;time_ bin&#8288;</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned that contains two data frames called
<code>training_set</code> and <code>test_set</code> which contain data in the same format as the
<code>training_set</code> and <code>test_set</code> arguments passed to this function, however
the data in these data frames has been processed by the FP object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fp_zscore">fp_zscore()</a></code>, <code><a href="#topic+fp_select_k_features">fp_select_k_features()</a></code>
</p>

<hr>
<h2 id='preprocess_data.fp_select_k_features'>A feature-preprocessor (FP) method to pre-process training and test data</h2><span id='topic+preprocess_data.fp_select_k_features'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all FP objects. This object
learns a set of parameters from the training data (i.e., the data generated
from a datasource get_data() method). The <code>preprocess_data()</code> method then
uses these parameters do processing on the training and test data before the
data is sent to the classifier. This method should not be called directly but
instead it is used internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fp_select_k_features'
preprocess_data(fp, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preprocess_data.fp_select_k_features_+3A_fp">fp</code></td>
<td>
<p>The FP object.</p>
</td></tr>
<tr><td><code id="preprocess_data.fp_select_k_features_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="preprocess_data.fp_select_k_features_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code style="white-space: pre;">&#8288;time_ bin&#8288;</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned that contains two data frames called
<code>training_set</code> and <code>test_set</code> which contain data in the same format as the
<code>training_set</code> and <code>test_set</code> arguments passed to this function, however
the data in these data frames has been processed by the FP object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fp_zscore">fp_zscore()</a></code>, <code><a href="#topic+fp_select_k_features">fp_select_k_features()</a></code>
</p>

<hr>
<h2 id='preprocess_data.fp_zscore'>A feature-preprocessor (FP) method to pre-process training and test data</h2><span id='topic+preprocess_data.fp_zscore'></span>

<h3>Description</h3>

<p>This is a function that must be implemented by all FP objects. This object
learns a set of parameters from the training data (i.e., the data generated
from a datasource get_data() method). The <code>preprocess_data()</code> method then
uses these parameters do processing on the training and test data before the
data is sent to the classifier. This method should not be called directly but
instead it is used internally by the cross-validator (CV) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fp_zscore'
preprocess_data(fp, training_set, test_set)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preprocess_data.fp_zscore_+3A_fp">fp</code></td>
<td>
<p>The FP object.</p>
</td></tr>
<tr><td><code id="preprocess_data.fp_zscore_+3A_training_set">training_set</code></td>
<td>
<p>The training set data from one time bin. This is a data
frame where the rows correspond to data from a given trial. There must be a
column called <code>train_labels</code> that has the labels of what occurred on each
trial. The rest of the  columns correspond to the neural activity of a
particular site on each trial (and typically have names like site_0001,
site_0002, etc).</p>
</td></tr>
<tr><td><code id="preprocess_data.fp_zscore_+3A_test_set">test_set</code></td>
<td>
<p>The test set data from all times. This is a data frame where
the rows correspond to data from a given trial. There must be a column
called <code style="white-space: pre;">&#8288;time_ bin&#8288;</code> that contains a label indicating the time point that a
row (test point) came from.  The rest of the  columns correspond to the
neural activity of a particular site on each test trial (and typically have
names like site_0001, site_0002, etc).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list is returned that contains two data frames called
<code>training_set</code> and <code>test_set</code> which contain data in the same format as the
<code>training_set</code> and <code>test_set</code> arguments passed to this function, however
the data in these data frames has been processed by the FP object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fp_zscore">fp_zscore()</a></code>, <code><a href="#topic+fp_select_k_features">fp_select_k_features()</a></code>
</p>

<hr>
<h2 id='read_matlab_raster_data'>Reads MATLAB raster data</h2><span id='topic+read_matlab_raster_data'></span>

<h3>Description</h3>

<p>Reads MATLAB data in raster format into an R raster_data format data frame. This
is similar to the general read_raster_data() function but it contains additional
arguments specific to MALTAB raster data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_matlab_raster_data(
  matlab_raster_file_name,
  sampling_interval_width = 1,
  zero_time_bin = NULL,
  add_sequential_trial_numbers = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_matlab_raster_data_+3A_matlab_raster_file_name">matlab_raster_file_name</code></td>
<td>
<p>A character string specifying the file name,
including the full path to a raster data in MATLAB .mat files.</p>
</td></tr>
<tr><td><code id="read_matlab_raster_data_+3A_sampling_interval_width">sampling_interval_width</code></td>
<td>
<p>A number specifying how successive time bins
will be labeled The default value of 1 means that points will be labeled as
successive integers; i.e., time.1_2, time.2_3, etc. If this value was set
to a larger number, then time points will be specified at the given
sampling width. From example, if sampling_width is set to 10, then the time
labels would be time.1_10, time.10_20, etc. This is useful if the data is
sampled at a particular rate (e.g., if the data is sampled at 500Hz, one
might want to use sampling_interval_width = 2, so that the times listed on
the raster column names are in milliseconds).</p>
</td></tr>
<tr><td><code id="read_matlab_raster_data_+3A_zero_time_bin">zero_time_bin</code></td>
<td>
<p>A number specifying the time bin that should be marked
as time 0. The default (NULL value) is to use the first bin as time 1.</p>
</td></tr>
<tr><td><code id="read_matlab_raster_data_+3A_add_sequential_trial_numbers">add_sequential_trial_numbers</code></td>
<td>
<p>A Boolean specifying one should add a
variable to the data called 'trial_number' that has sequential trial. These
trials numbers are needed for data that was recorded simultaneously so that
trials can be aligned across different sites. If the MATLAB raster data has
a field site_info.trial_number then this will override the trial_number that
would automatically be set to that value (and print a message about it).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame of data in <code style="white-space: pre;">&#8288;raster format&#8288;</code> (i.e., with class
<code>raster_data</code>). Data that is in <code style="white-space: pre;">&#8288;raster format&#8288;</code> as the following variables:
</p>

<ol>
<li> <p><code>labels.XXX</code>  These variables contain labels of which experimental conditions were shown on a given trial.
</p>
</li>
<li> <p><code>time.XXX_YYY</code>  These variables contain the data for a given time, XXX is
the start time of the data in a particular bin and YYY is the end time.
</p>
</li>
<li> <p><code>site_info.XXX</code> These variables contain additional meta data about the site.
</p>
</li>
<li> <p><code>trial_number</code> This variable specifies a unique number for each row
indicating which trial a given row of data came from.
</p>
</li></ol>

<p>For more details on <code style="white-space: pre;">&#8288;raster format&#8288;</code> data see the vignette:
<code>vignette("data_formats", package = "NeuroDecodeR")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

matlab_raster_file_name &lt;- file.path(
  system.file("extdata", package = "NeuroDecodeR"),
  "Zhang_Desimone_7object_raster_data_small_mat",
  "bp1001spk_01A_raster_data.mat")

raster_data &lt;- read_matlab_raster_data(matlab_raster_file_name)


</code></pre>

<hr>
<h2 id='read_raster_data'>Read a csv, rda, rds or mat file in raster format</h2><span id='topic+read_raster_data'></span>

<h3>Description</h3>

<p>Reads a csv, rda, rds or mat file that has the appropriate raster_data
column names (i.e., columns that start with site.info, labels. and time.),
and returns data in raster_data format (i.e., a data frame with the raster.data
class attribute).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_raster_data(raster_file_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_raster_data_+3A_raster_file_name">raster_file_name</code></td>
<td>
<p>A string specifying the name (and path) to a csv,
rda, rds or mat raster data file that has the appropriate raster data
column names (i.e., columns that start with site.info, labels. and time.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame of data in <code style="white-space: pre;">&#8288;raster format&#8288;</code> (i.e., with class
<code>raster_data</code>). Data that is in <code style="white-space: pre;">&#8288;raster format&#8288;</code> as the following variables:
</p>

<ol>
<li> <p><code>labels.XXX</code>  These variables contain labels of which experimental conditions were shown on a given trial.
</p>
</li>
<li> <p><code>time.XXX_YYY</code>  These variables contain the data for a given time, XXX is
the start time of the data in a particular bin and YYY is the end time.
</p>
</li>
<li> <p><code>site_info.XXX</code> These variables contain additional meta data about the site.
</p>
</li>
<li> <p><code>trial_number</code> This variable specifies a unique number for each row
indicating which trial a given row of data came from.
</p>
</li></ol>

<p>For more details on <code style="white-space: pre;">&#8288;raster format&#8288;</code> data see the vignette:
<code>vignette("data_formats", package = "NeuroDecodeR")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># reading in a csv file in raster format
csv_raster_file_name &lt;- file.path(
  system.file("extdata", package = "NeuroDecodeR"),
  "Zhang_Desimone_7object_raster_data_small_csv",
  "bp1001spk_01A_raster_data.csv"
)

# read the csv file into a raster_data data frame
raster_data &lt;- read_raster_data(csv_raster_file_name)


</code></pre>

<hr>
<h2 id='rm_confusion_matrix'>A result metric (RM) that calculates confusion matrices</h2><span id='topic+rm_confusion_matrix'></span>

<h3>Description</h3>

<p>This result metric calculate a confusion matrices from all points in time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm_confusion_matrix(
  ndr_container_or_object = NULL,
  save_TCD_results = FALSE,
  create_decision_vals_confusion_matrix = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rm_confusion_matrix_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the rm_confusion_matrix feature preprocessor work with the
magrittr pipe (|&gt;) operator. This argument should almost never be directly
set by the user to anything other than NULL. If this is set to the default
value of NULL, then the constructor will return a rm_confusion_matrix
object. If this is set to an ndr container, then a rm_confusion_matrix
object will be added to the container and the container will be returned.
If this argument is set to another ndr object, then both that ndr object as
well as a new rm_confusion_matrix object will be added to a new container
and the container will be returned.</p>
</td></tr>
<tr><td><code id="rm_confusion_matrix_+3A_save_tcd_results">save_TCD_results</code></td>
<td>
<p>A Boolean specifying whether one wants
to save results to allow one to create temporal cross decoding confusion
matrices; i.e., confusion matrices when training at one point in time and
testing a different point in time. Setting this to FALSE can save memory.</p>
</td></tr>
<tr><td><code id="rm_confusion_matrix_+3A_create_decision_vals_confusion_matrix">create_decision_vals_confusion_matrix</code></td>
<td>
<p>A boolean specifying whether one
wants to create a confusion matrix of the decision values. In this
confusion matrix, each row corresponds to the correct class (like a regular
confusion matrix) and each column corresponds to the mean decision value of
the predictions for each class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like all result metrics, this result metric has functions to aggregate
results after completing each set of cross-validation classifications, and
also after completing all the resample runs. The results should then be
available in the DECODING_RESULTS object returned by the cross-validator.
</p>


<h3>Value</h3>

<p>This constructor creates an NDR result metric object with the class
<code>rm_confusion_matrix</code>. Like all NDR result metric objects, this result
metric will be used by a cross-validator to create a measure of decoding
accuracy by aggregating the results after all cross-validation splits have
been run, and after all resample runs have completed.
</p>


<h3>See Also</h3>

<p>Other result_metrics: 
<code><a href="#topic+plot.rm_confusion_matrix">plot.rm_confusion_matrix</a>()</code>,
<code><a href="#topic+plot.rm_main_results">plot.rm_main_results</a>()</code>,
<code><a href="#topic+plot_main_results">plot_main_results</a>()</code>,
<code><a href="#topic+rm_main_results">rm_main_results</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># If you only want to use the rm_confusion_matrix(), then you can put it in a
# list by itself and pass it to the cross-validator.
the_rms &lt;- list(rm_confusion_matrix())


</code></pre>

<hr>
<h2 id='rm_main_results'>A result metric (RM) that calculates main decoding accuracy measures</h2><span id='topic+rm_main_results'></span>

<h3>Description</h3>

<p>This result metric calculate the zero-one loss, the normalized rank, and the
mean of the decision values. This is also an S3 object which has an
associated plot function to display the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm_main_results(
  ndr_container_or_object = NULL,
  include_norm_rank_results = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rm_main_results_+3A_ndr_container_or_object">ndr_container_or_object</code></td>
<td>
<p>The purpose of this argument is to make the
constructor of the rm_main_results feature preprocessor work with the
magrittr pipe (%&gt;%) operator. This argument should almost never be directly
set by the user to anything other than NULL. If this is set to the default
value of NULL, then the constructor will return a rm_main_results object.
If this is set to an ndr container, then a rm_main_results object will be
added to the container and the container will be returned. If this argument
is set to another ndr object, then both that ndr object as well as a new
rm_main_results object will be added to a new container and the container
will be returned.</p>
</td></tr>
<tr><td><code id="rm_main_results_+3A_include_norm_rank_results">include_norm_rank_results</code></td>
<td>
<p>An argument specifying if the normalized
rank and decision value results should be saved. If this is a Boolean set
to TRUE, then the normalized rank and decision values for the correct
category will be calculated. If this is a Boolean set to FALSE then the
normalized rank and decision values will not be calculated. If this is a
string set to &quot;only_same_train_test_time&quot;, then the normalized rank and
decision values will only be calculated when for results when training and
testing at the same time. Not returning the full results can speed up the
run-time of the code and will use less memory so this can be useful for
large data sets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like all result metrics, this result metric has functions to aggregate
results after completing each set of cross-validation classifications, and
also after completing all the resample runs. The results should then be
available in the DECODING_RESULTS object returned by the cross-validator.
</p>


<h3>Value</h3>

<p>This constructor creates an NDR result metric object with the class
<code>rm_main_results</code>. Like all NDR result metric objects, this result
metric will be used by a cross-validator to create a measure of decoding
accuracy by aggregating the results after all cross-validation splits have
been run, and after all resample runs have completed.
</p>


<h3>See Also</h3>

<p>Other result_metrics: 
<code><a href="#topic+plot.rm_confusion_matrix">plot.rm_confusion_matrix</a>()</code>,
<code><a href="#topic+plot.rm_main_results">plot.rm_main_results</a>()</code>,
<code><a href="#topic+plot_main_results">plot_main_results</a>()</code>,
<code><a href="#topic+rm_confusion_matrix">rm_confusion_matrix</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># If you only want to use the rm_main_results(), then you can put it in a
# list by itself and pass it to the cross-validator.
the_rms &lt;- list(rm_main_results())


</code></pre>

<hr>
<h2 id='run_decoding'>A cross-validator (CV) method to run a decoding analysis</h2><span id='topic+run_decoding'></span>

<h3>Description</h3>

<p>This method runs a full decoding analysis based on the DS, FP, CL, and RM
objects that are passed to the cross-validator constructor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_decoding(cv_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="run_decoding_+3A_cv_obj">cv_obj</code></td>
<td>
<p>A CV object. Parameters that affect the decoding analyses are
set in the CV's constructor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, usually called <code>DECODING_RESULTS</code>, that contains the results
from the decoding analysis. This <code>DECODING_RESULTS</code> list should contain the
result compiled by the result metric objects, as well as a list in
<code>DECODING_RESULTS$cross_validation_paramaters$parameter_df</code> contains data
on all that DS, FP, CL and RM parameters that were used in the decoding
analysis that can be used to store and retrieve the results. Additionally,
the DS, FP, CL and RM objects used in the analysis can be saved in the
<code>DECODING_RESULTS$cross_validation_paramaters</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv_standard">cv_standard()</a></code>
</p>

<hr>
<h2 id='run_decoding.cv_standard'>A cross-validator (CV) method to run a decoding analysis</h2><span id='topic+run_decoding.cv_standard'></span>

<h3>Description</h3>

<p>This method runs a full decoding analysis based on the DS, FP, CL, and RM
objects that are passed to the cross-validator constructor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv_standard'
run_decoding(cv_obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="run_decoding.cv_standard_+3A_cv_obj">cv_obj</code></td>
<td>
<p>A CV object. Parameters that affect the decoding analyses are
set in the CV's constructor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, usually called <code>DECODING_RESULTS</code>, that contains the results
from the decoding analysis. This <code>DECODING_RESULTS</code> list should contain the
result compiled by the result metric objects, as well as a list in
<code>DECODING_RESULTS$cross_validation_paramaters$parameter_df</code> contains data
on all that DS, FP, CL and RM parameters that were used in the decoding
analysis that can be used to store and retrieve the results. Additionally,
the DS, FP, CL and RM objects used in the analysis can be saved in the
<code>DECODING_RESULTS$cross_validation_paramaters</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv_standard">cv_standard()</a></code>
</p>

<hr>
<h2 id='test_valid_binned_format'>Tests if a data frame is in valid binned format</h2><span id='topic+test_valid_binned_format'></span>

<h3>Description</h3>

<p>This function takes a data frame and tests that the data frame is in valid
binned format by checking that the data frame contains variables with the
appropriate names. If the data frame is not in correct binned format, an
error will be thrown that contains a message why the data is not in valid
binned format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_valid_binned_format(binned_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_valid_binned_format_+3A_binned_data">binned_data</code></td>
<td>
<p>A data frame or string specifying a file that will be
checked to see if it is in valid binned format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL if object is in valid binned format. Otherwise it will
give an error message.
</p>

<hr>
<h2 id='test_valid_ndr_object'>Tests if an object is a valid NDR object</h2><span id='topic+test_valid_ndr_object'></span>

<h3>Description</h3>

<p>This function takes an object and tests whether it is a valid NDR object;
i.e., whether it is an object that is either an DS, FP, CL, RM or CV object.
If it is a valid NDR object, then it returns a string specifying the prefix
of the type of object it is; i.e., 'ds', 'fp', 'cl', 'rm' or 'cv'. If it
is not an NDR object then an error is thrown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_valid_ndr_object(ndr_object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_valid_ndr_object_+3A_ndr_object">ndr_object</code></td>
<td>
<p>An object that should be an NDR object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a string if the <code>ndr_object</code> is a valid NDR object. The
string is either 'ds', 'fp', 'cl', 'rm' or 'cv' which specifies what type
of object it is. If <code>ndr_object</code> is not an NDR object, then an error is
thrown.
</p>

<hr>
<h2 id='test_valid_raster_format'>Tests if a data frame is in valid raster format</h2><span id='topic+test_valid_raster_format'></span>

<h3>Description</h3>

<p>This function takes a data frame and tests that the data frame is in valid
raster format by checking that the data frame contains variables with the
appropriate names. If the data frame is not in correct raster format, an
error will be thrown that contains a message why the data is not in valid
raster format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_valid_raster_format(raster_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_valid_raster_format_+3A_raster_data">raster_data</code></td>
<td>
<p>A data frame or string specifying a file that will be
checked to see if it is in valid raster format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns NULL if object is in valid raster format. Otherwise it will
give an error message.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This is valid raster data so the function will return no error message
raster_dir_name &lt;- file.path(
  system.file("extdata", package = "NeuroDecodeR"),
  "Zhang_Desimone_7object_raster_data_small_rda"
)
file_name &lt;- "bp1001spk_01A_raster_data.rda"
raster_full_path &lt;- file.path(raster_dir_name, file_name)

test_valid_raster_format(raster_full_path)


# Binned data is not in raster format (it has an extra column called siteID) so
# checking if it is in raster format should return an error.

binned_file_name &lt;- system.file(file.path("extdata", "ZD_150bins_50sampled.Rda"), 
                                package = "NeuroDecodeR")
try(test_valid_raster_format(binned_file_name))


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
