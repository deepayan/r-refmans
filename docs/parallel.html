<!DOCTYPE html><html lang="en"><head><title>Help for package parallel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {parallel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#parallel-package'>
<p>Support for Parallel Computation</p></a></li>
<li><a href='#clusterApply'><p>Apply Operations using Clusters</p></a></li>
<li><a href='#detectCores'><p>Detect the Number of CPU Cores</p></a></li>
<li><a href='#makeCluster'>
<p>Create a Parallel Socket Cluster</p></a></li>
<li><a href='#mcaffinity'><p>Get or Set CPU Affinity Mask of the Current Process</p></a></li>
<li><a href='#mcchildren'><p>Low-level Functions for Management of Forked Processes</p></a></li>
<li><a href='#mcfork'><p>Fork a Copy of the Current R Process</p></a></li>
<li><a href='#mclapply'><p>Parallel Versions of <code>lapply</code> and <code>mapply</code> using Forking</p></a></li>
<li><a href='#mcparallel'><p>Evaluate an <span class="rlang"><b>R</b></span> Expression Asynchronously in a Separate Process</p></a></li>
<li><a href='#pvec'><p>Parallelize a Vector Map Function using Forking</p></a></li>
<li><a href='#RNGstreams'><p>Implementation of Pierre L'Ecuyer's RngStreams</p></a></li>
<li><a href='#sendData'><p>Cluster Back-end Interface</p></a></li>
<li><a href='#splitIndices'><p>Divide Tasks for Distribution in a Cluster</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>4.6.0</td>
</tr>
<tr>
<td>Priority:</td>
<td>base</td>
</tr>
<tr>
<td>Title:</td>
<td>Support for Parallel Computation in R</td>
</tr>
<tr>
<td>Author:</td>
<td>R Core Team</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>R Core Team &lt;do-use-Contact-address@r-project.org&gt;</td>
</tr>
<tr>
<td>Contact:</td>
<td>R-help mailing list &lt;r-help@r-project.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Support for parallel computation, including by forking
   (taken from package multicore), by sockets (taken from package snow)
   and random-number generation.</td>
</tr>
<tr>
<td>License:</td>
<td>Part of R 4.6.0</td>
</tr>
<tr>
<td>Imports:</td>
<td>tools, compiler</td>
</tr>
<tr>
<td>Suggests:</td>
<td>methods</td>
</tr>
<tr>
<td>Enhances:</td>
<td>snow, Rmpi, mirai</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.6.0; x86_64-apple-darwin22.2.0; 2025-03-20 15:28:57 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='parallel-package'>
Support for Parallel Computation
</h2><span id='topic+parallel-package'></span><span id='topic+parallel'></span>

<h3>Description</h3>

<p>Support for parallel computation, including random-number generation.
</p>


<h3>Details</h3>

<p>This package was first included with <span class="rlang"><b>R</b></span> 2.14.0 in 2011.
</p>
<p>There is support for multiple RNG streams with the
&lsquo;<span class="samp">&#8288;"L'Ecuyer-CMRG"&#8288;</span>&rsquo; <a href="base.html#topic+RNG">RNG</a>: see <code><a href="#topic+nextRNGStream">nextRNGStream</a></code>.
</p>
<p>It contains functionality derived from and pretty much equivalent to
that contained in packages <span class="pkg">multicore</span> (formerly on
<abbr>CRAN</abbr>, with some low-level functions renamed and not
exported) and <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a> (for socket clusters only, but MPI

clusters generated by <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a> are also supported). There
have been many enhancements and bug fixes since 2011.
</p>
<p>This package also provides <code><a href="#topic+makeForkCluster">makeForkCluster</a></code> to create
socket clusters by forking (not Windows).
</p>
<p>For a complete list of exported functions, use
<code>library(help = "parallel")</code>.
</p>


<h3>Author(s)</h3>

<p>Brian Ripley, Luke Tierney and Simon Urbanek
</p>
<p>Maintainer: R Core Team <a href="mailto:R-core@r-project.org">R-core@r-project.org</a>
</p>


<h3>See Also</h3>

<p>Parallel computation involves launching worker processes: functions
<code><a href="tools.html#topic+psnice">psnice</a></code> and <code><a href="tools.html#topic+pskill">pskill</a></code> in package <span class="pkg">tools</span>
provide means to manage such processes.
</p>

<hr>
<h2 id='clusterApply'>Apply Operations using Clusters</h2><span id='topic+clusterApply'></span><span id='topic+clusterApplyLB'></span><span id='topic+clusterCall'></span><span id='topic+clusterEvalQ'></span><span id='topic+clusterExport'></span><span id='topic+clusterMap'></span><span id='topic+clusterSplit'></span><span id='topic+parApply'></span><span id='topic+parCapply'></span><span id='topic+parLapply'></span><span id='topic+parRapply'></span><span id='topic+parSapply'></span><span id='topic+parLapplyLB'></span><span id='topic+parSapplyLB'></span>

<h3>Description</h3>

<p>These functions provide several ways to parallelize computations using
a cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clusterCall(cl = NULL, fun, ...)
clusterApply(cl = NULL, x, fun, ...)
clusterApplyLB(cl = NULL, x, fun, ...)
clusterEvalQ(cl = NULL, expr)
clusterExport(cl = NULL, varlist, envir = .GlobalEnv)
clusterMap(cl = NULL, fun, ..., MoreArgs = NULL, RECYCLE = TRUE,
           SIMPLIFY = FALSE, USE.NAMES = TRUE,
           .scheduling = c("static", "dynamic"))
clusterSplit(cl = NULL, seq)

parLapply(cl = NULL, X, fun, ..., chunk.size = NULL)
parSapply(cl = NULL, X, FUN, ..., simplify = TRUE,
          USE.NAMES = TRUE, chunk.size = NULL)
parApply(cl = NULL, X, MARGIN, FUN, ..., chunk.size = NULL)
parRapply(cl = NULL, x, FUN, ..., chunk.size = NULL)
parCapply(cl = NULL, x, FUN, ..., chunk.size = NULL)

parLapplyLB(cl = NULL, X, fun, ..., chunk.size = NULL)
parSapplyLB(cl = NULL, X, FUN, ..., simplify = TRUE,
            USE.NAMES = TRUE, chunk.size = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clusterApply_+3A_cl">cl</code></td>
<td>
<p>a cluster object, created by this package or by package
<a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a>.  If <code>NULL</code>, use the registered default cluster.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_fun">fun</code>, <code id="clusterApply_+3A_fun">FUN</code></td>
<td>
<p>function or character string naming a function.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_expr">expr</code></td>
<td>
<p>expression to evaluate.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_seq">seq</code></td>
<td>
<p>vector to split.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_varlist">varlist</code></td>
<td>
<p>character vector of names of objects to export.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_envir">envir</code></td>
<td>
<p>environment from which to export variables</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_x">x</code></td>
<td>
<p>a vector for <code>clusterApply</code> and <code>clusterApplyLB</code>, a
matrix for <code>parRapply</code> and <code>parCapply</code>.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code>fun</code> or <code>FUN</code>:
beware of partial matching to earlier arguments.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_moreargs">MoreArgs</code></td>
<td>
<p>additional arguments for <code>fun</code>.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_recycle">RECYCLE</code></td>
<td>
<p>logical; if true shorter arguments are recycled.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_x">X</code></td>
<td>
<p>A vector (atomic or list) for <code>parLapply</code> and
<code>parSapply</code>, an array for <code>parApply</code>.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_chunk.size">chunk.size</code></td>
<td>
<p>scalar number; number of invocations of <code>fun</code> or
<code>FUN</code> in one chunk; a chunk is a unit for scheduling.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_margin">MARGIN</code></td>
<td>
<p>vector specifying the dimensions to use.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_simplify">simplify</code>, <code id="clusterApply_+3A_use.names">USE.NAMES</code></td>
<td>
<p>logical; see <code><a href="base.html#topic+sapply">sapply</a></code>.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_simplify">SIMPLIFY</code></td>
<td>
<p>logical; see <code><a href="base.html#topic+mapply">mapply</a></code>.</p>
</td></tr>
<tr><td><code id="clusterApply_+3A_.scheduling">.scheduling</code></td>
<td>
<p>should tasks be statically allocated to nodes or
dynamic load-balancing used?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>clusterCall</code> calls a function <code>fun</code> with identical
arguments <code>...</code> on each node.
</p>
<p><code>clusterEvalQ</code> evaluates a literal expression on each cluster
node.  It is a parallel version of <code><a href="base.html#topic+evalq">evalq</a></code>, and is a
convenience function invoking <code>clusterCall</code>.
</p>
<p><code>clusterApply</code> calls <code>fun</code> on the first node with
arguments <code>x[[1]]</code> and <code>...</code>, on the second node with
<code>x[[2]]</code> and <code>...</code>, and so on, recycling nodes as needed.
</p>
<p><code>clusterApplyLB</code> is a load balancing version of
<code>clusterApply</code>.  If the length <code>n</code> of <code>x</code> is not
greater than the number of nodes <code>p</code>, then a job is sent to
<code>n</code> nodes.  Otherwise the first <code>p</code> jobs are placed in order
on the <code>p</code> nodes.  When the first job completes, the next job is
placed on the node that has become free; this continues until all jobs
are complete.  Using <code>clusterApplyLB</code> can result in better
cluster utilization than using <code>clusterApply</code>, but increased
communication can reduce performance.  Furthermore, the node that
executes a particular job is non-deterministic. This means that
simulations that assign RNG streams to nodes will not be reproducible.
</p>
<p><code>clusterMap</code> is a multi-argument version of <code>clusterApply</code>,
analogous to <code><a href="base.html#topic+mapply">mapply</a></code> and <code><a href="base.html#topic+Map">Map</a></code>.  If
<code>RECYCLE</code> is true shorter arguments are recycled (and either none
or all must be of length zero); otherwise, the result length is the
length of the shortest argument.  Nodes are recycled if the length of
the result is greater than the number of nodes.  (<code>mapply</code> always
uses <code>RECYCLE = TRUE</code>, and has argument <code>SIMPLIFY = TRUE</code>.
<code>Map</code> always uses <code>RECYCLE = TRUE</code>.)
</p>
<p><code>clusterExport</code> assigns the values on the master <span class="rlang"><b>R</b></span> process of
the variables named in <code>varlist</code> to variables of the same names
in the global environment (aka &lsquo;workspace&rsquo;) of each node.  The
environment on the master from which variables are exported defaults
to the global environment.
</p>
<p><code>clusterSplit</code> splits <code>seq</code> into a consecutive piece for
each cluster and returns the result as a list with length equal to the
number of nodes.  Currently the pieces are chosen to be close
to equal in length: the computation is done on the master.
</p>
<p><code>parLapply</code>, <code>parSapply</code>, and <code>parApply</code> are parallel
versions of <code>lapply</code>, <code>sapply</code> and <code>apply</code>.  Chunks of
computation are statically allocated to nodes using <code>clusterApply</code>.
By default, the number of chunks is the same as the number of nodes.
<code>parLapplyLB</code>, <code>parSapplyLB</code> are load-balancing versions,
intended for use when applying <code>FUN</code> to different elements of
<code>X</code> takes quite variable amounts of time, and either the function is
deterministic or reproducible results are not required.  Chunks of
computation are allocated dynamically to nodes using
<code>clusterApplyLB</code>.  From <span class="rlang"><b>R</b></span> 3.5.0, the default number of chunks is
twice the number of nodes. Before <span class="rlang"><b>R</b></span> 3.5.0, the (fixed) number of chunks
was the same as the number of nodes.  As for <code>clusterApplyLB</code>,
with load balancing the node that executes a particular job is
non-deterministic and simulations that assign RNG streams to nodes
will not be reproducible.
</p>
<p><code>parRapply</code> and <code>parCapply</code> are parallel row and column
<code>apply</code> functions for a matrix <code>x</code>; they may be slightly
more efficient than <code>parApply</code> but do less post-processing of the
result.
</p>
<p>A chunk size of <code>0</code> with static scheduling uses the default (one
chunk per node).  With dynamic scheduling, chunk size of <code>0</code> has the
same effect as <code>1</code> (one invocation of <code>FUN</code>/<code>fun</code> per
chunk).
</p>


<h3>Value</h3>

<p>For <code>clusterCall</code>, <code>clusterEvalQ</code> and <code>clusterSplit</code>, a
list with one element per node.
</p>
<p>For <code>clusterApply</code> and <code>clusterApplyLB</code>, a list the same
length as <code>x</code>.
</p>
<p><code>clusterMap</code> follows <code><a href="base.html#topic+mapply">mapply</a></code>.
</p>
<p><code>clusterExport</code> returns nothing.
</p>
<p><code>parLapply</code> returns a list the length of <code>X</code>.
</p>
<p><code>parSapply</code> and <code>parApply</code> follow <code><a href="base.html#topic+sapply">sapply</a></code> and
<code><a href="base.html#topic+apply">apply</a></code> respectively.
</p>
<p><code>parRapply</code> and <code>parCapply</code> always return a vector.  If
<code>FUN</code> always returns a scalar result this will be of length the
number of rows or columns: otherwise it will be the concatenation of
the returned values.
</p>
<p>An error is signalled on the master if any of the workers produces an
error.
</p>


<h3>Note</h3>

<p>These functions are almost identical to those in package <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a>.
</p>
<p>Two exceptions: <code>parLapply</code> has argument <code>X</code>
not <code>x</code> for consistency with <code><a href="base.html#topic+lapply">lapply</a></code>, and
<code>parSapply</code> has been updated to match <code><a href="base.html#topic+sapply">sapply</a></code>.
</p>


<h3>Author(s)</h3>

<p>Luke Tierney and R Core.
</p>
<p>Derived from the <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Use option cl.cores to choose an appropriate cluster size.
cl &lt;- makeCluster(getOption("cl.cores", 2))

clusterApply(cl, 1:2, get("+"), 3)
xx &lt;- 1
clusterExport(cl, "xx")
clusterCall(cl, function(y) xx + y, 2)

## Use clusterMap like an mapply example
clusterMap(cl, function(x, y) seq_len(x) + y,
          c(a =  1, b = 2, c = 3), c(A = 10, B = 0, C = -10))


parSapply(cl, 1:20, get("+"), 3)

## A bootstrapping example, which can be done in many ways:
clusterEvalQ(cl, {
  ## set up each worker.  Could also use clusterExport()
  library(boot)
  cd4.rg &lt;- function(data, mle) MASS::mvrnorm(nrow(data), mle$m, mle$v)
  cd4.mle &lt;- list(m = colMeans(cd4), v = var(cd4))
  NULL
})
res &lt;- clusterEvalQ(cl, boot(cd4, corr, R = 100,
                    sim = "parametric", ran.gen = cd4.rg, mle = cd4.mle))
library(boot)
cd4.boot &lt;- do.call(c, res)
boot.ci(cd4.boot,  type = c("norm", "basic", "perc"),
        conf = 0.9, h = atanh, hinv = tanh)
stopCluster(cl)

## or
library(boot)
run1 &lt;- function(...) {
   library(boot)
   cd4.rg &lt;- function(data, mle) MASS::mvrnorm(nrow(data), mle$m, mle$v)
   cd4.mle &lt;- list(m = colMeans(cd4), v = var(cd4))
   boot(cd4, corr, R = 500, sim = "parametric",
        ran.gen = cd4.rg, mle = cd4.mle)
}
cl &lt;- makeCluster(mc &lt;- getOption("cl.cores", 2))
## to make this reproducible
clusterSetRNGStream(cl, 123)
cd4.boot &lt;- do.call(c, parLapply(cl, seq_len(mc), run1))
boot.ci(cd4.boot,  type = c("norm", "basic", "perc"),
        conf = 0.9, h = atanh, hinv = tanh)
stopCluster(cl)
</code></pre>

<hr>
<h2 id='detectCores'>Detect the Number of CPU Cores</h2><span id='topic+detectCores'></span>

<h3>Description</h3>

<p>Attempt to detect the number of CPU cores on the current host.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectCores(all.tests = FALSE, logical = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detectCores_+3A_all.tests">all.tests</code></td>
<td>
<p>Logical: if true apply all known tests.</p>
</td></tr>
<tr><td><code id="detectCores_+3A_logical">logical</code></td>
<td>
<p>Logical: if possible, use the number of physical CPUs/cores
(if <code>FALSE</code>) or logical CPUs (if <code>TRUE</code>).  Currently this
is honoured only on macOS, Solaris and Windows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This attempts to detect the number of available CPU cores.
</p>
<p>It has methods to do so for Linux, macOS, FreeBSD, OpenBSD, Solaris
and Windows.  <code>detectCores(TRUE)</code> could be tried on other
Unix-alike systems.
</p>


<h3>Value</h3>

<p>An integer, <code>NA</code> if the answer is unknown.
</p>
<p>Exactly what this represents is OS-dependent: where possible by
default it counts logical (e.g., hyperthreaded) CPUs and not physical
cores or packages.
</p>
<p>Under macOS there is a further distinction between &lsquo;available in
the current power management mode&rsquo; and &lsquo;could be available
this boot&rsquo;, and this function returns the first.
</p>
<p>On Sparc Solaris <code>logical = FALSE</code> returns the number of physical
cores and <code>logical = TRUE</code> returns the number of available
hardware threads. (Some Sparc CPUs have multiple cores per CPU, others
have multiple threads per core and some have both.)  For example, the
UltraSparc T2 CPU in the former CRAN check server was a single
physical CPU with 8 cores, and each core supports 8 hardware threads.
So <code>detectCores(logical = FALSE)</code> returns 8, and
<code>detectCores(logical = TRUE)</code> returns 64.
</p>
<p>Where virtual machines are in use, one would hope that the result
for <code>logical = TRUE</code> represents the number of CPUs available (or
potentially available) to that particular <abbr>VM</abbr>.
</p>


<h3>Note</h3>

<p>This is not suitable for use directly for the <code>mc.cores</code> argument
of <code>mclapply</code> nor specifying the number of cores in
<code>makeCluster</code>.  First because it may return <code>NA</code>, second
because it does not give the number of <em>allowed</em> cores, and third
because on Sparc Solaris and some Windows boxes it is not reasonable
to try to use all the logical CPUs at once.
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek and Brian Ripley
</p>


<h3>Examples</h3>

<pre><code class='language-R'>detectCores()
detectCores(logical = FALSE)
</code></pre>

<hr>
<h2 id='makeCluster'>
Create a Parallel Socket Cluster
</h2><span id='topic+makeCluster'></span><span id='topic+makePSOCKcluster'></span><span id='topic+makeForkCluster'></span><span id='topic+stopCluster'></span><span id='topic+setDefaultCluster'></span><span id='topic+getDefaultCluster'></span><span id='topic+registerClusterType'></span><span id='topic+R_PARALLEL_PORT'></span>

<h3>Description</h3>

<p>Creates a set of copies of <span class="rlang"><b>R</b></span> running in parallel and communicating
over sockets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCluster(spec, type, ...)
makePSOCKcluster(names, ...)
makeForkCluster(nnodes = getOption("mc.cores", 2L), ...)

stopCluster(cl = NULL)

setDefaultCluster(cl = NULL)
getDefaultCluster()

registerClusterType(type, starter, make.default = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makeCluster_+3A_spec">spec</code></td>
<td>
<p>A specification appropriate to the type of cluster.</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_names">names</code></td>
<td>
<p>Either a character vector of host names on which to run
the worker copies of <span class="rlang"><b>R</b></span>, or a positive integer (in which case
that number of copies is run on &lsquo;<span class="samp">&#8288;localhost&#8288;</span>&rsquo;).</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_nnodes">nnodes</code></td>
<td>
<p>The number of nodes to be forked.</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_type">type</code></td>
<td>
<p>One of the supported types: see &lsquo;Details&rsquo;. For
<code>registerClusterType</code>, a name for the newly-registered type of
cluster.</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_...">...</code></td>
<td>
<p>Options to be passed to the function spawning the workers.
See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_cl">cl</code></td>
<td>
<p>an object of class <code>"cluster"</code>.</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_starter">starter</code></td>
<td>
<p>A function used for creating a cluster of the appropriate
<code>type</code>.</p>
</td></tr>
<tr><td><code id="makeCluster_+3A_make.default">make.default</code></td>
<td>
<p>logical. If <code>TRUE</code>, the newly-registered cluster
type will become the default type of cluster created by
<code>makeCluster</code>. If <code>FALSE</code> (the default), the default cluster
type remains unchanged.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>makeCluster</code> creates a cluster of one of the supported types.
The default type, <code>"PSOCK"</code>, calls <code>makePSOCKcluster</code>.  Type
<code>"FORK"</code> calls <code>makeForkCluster</code>.  Other types are passed to
package <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a>.
</p>
<p><code>makePSOCKcluster</code> is an enhanced version of
<code>makeSOCKcluster</code> in package <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a>.  It runs
<code>Rscript</code> on the specified host(s) to set up a worker process
which listens on a socket for expressions to evaluate, and returns the
results (as serialized objects).
</p>
<p><code>makeForkCluster</code> is merely a stub on Windows.  On Unix-alike
platforms it creates the worker process by forking.
</p>
<p>The workers are most often running on the same host as the master,
when no options need be set.
</p>
<p>Several options are supported (mainly for <code>makePSOCKcluster</code>):
</p>

<dl>
<dt><code>master</code></dt><dd><p>The host name of the master, as known to the
workers.  This may not be the same as it is known to the master,
and on private subnets it may be necessary to specify this as a
numeric IP address.  For example, macOS is likely to detect a
machine as &lsquo;<span class="samp">&#8288;somename.local&#8288;</span>&rsquo;, a name known only to itself.</p>
</dd>
<dt><code>port</code></dt><dd><p>The port number for the socket connection,
default taken from the environment variable <span class="env">R_PARALLEL_PORT</span>,
then a randomly chosen port in the range <code>11000:11999</code>.</p>
</dd>
<dt><code>timeout</code></dt><dd><p>The timeout in seconds for that port.  This is
the maximum time of zero communication between master and worker
before failing.  Default is 30 days (and the POSIX standard only
requires values up to 31 days to be supported).</p>
</dd>
<dt><code>setup_timeout</code></dt><dd><p>The maximum number of seconds a worker
attempts to connect to master before failing.  Default is 2
minutes.  The waiting time before the next attempt starts at
0.1 seconds and is incremented 50% after each retry.</p>
</dd>
<dt><code>outfile</code></dt><dd><p>Where to direct the <code><a href="base.html#topic+stdout">stdout</a></code> and
<code><a href="base.html#topic+stderr">stderr</a></code> connection output from the workers.
<code>""</code> indicates no redirection (which may only be useful for
workers on the local machine).
Defaults to &lsquo;<span class="file">/dev/null</span>&rsquo; (&lsquo;<span class="file">nul:</span>&rsquo; on Windows).  The other
possibility is a file path on the worker's host.
Files will be opened in append mode, as all workers log to the
same file.</p>
</dd>
<dt><code>homogeneous</code></dt><dd><p>Logical, default true.  See &lsquo;Note&rsquo;.</p>
</dd>
<dt><code>rscript</code></dt><dd><p>See &lsquo;Note&rsquo;.</p>
</dd>
<dt><code>rscript_args</code></dt><dd><p>Character vector of additional
arguments for <code>Rscript</code> such as <span class="option">--no-environ</span>.</p>
</dd>
<dt><code>renice</code></dt><dd><p>A numerical &lsquo;niceness&rsquo; to set for the
worker processes, e.g. <code>15</code> for a low priority.
OS-dependent: see <code><a href="tools.html#topic+psnice">psnice</a></code> for details.</p>
</dd>
<dt><code>rshcmd</code></dt><dd><p>The command to be run on the master to launch a
process on another host.  Defaults to <code>ssh</code>.</p>
</dd>
<dt><code>user</code></dt><dd><p>The user name to be used when communicating with
another host.</p>
</dd>
<dt><code>manual</code></dt><dd><p>Logical.  If true the workers will need to be
run manually.</p>
</dd>
<dt><code>methods</code></dt><dd><p>Logical.  If true (default) the workers will
load the <span class="pkg">methods</span> package: not loading it saves ca 30% of the
startup CPU time of the cluster.</p>
</dd>
<dt><code>useXDR</code></dt><dd><p>Logical. If true (default) serialization will
use XDR: where large amounts of data are to be transferred and
all the nodes are little-endian, communication may be
substantially faster if this is set to false.</p>
</dd>
<dt><code>setup_strategy</code></dt><dd><p>Character.  If <code>"parallel"</code> (default)
workers will be started in parallel during cluster setup when this is
possible, which is now for homogeneous <code>"PSOCK"</code> clusters with
all workers started automatically (<code>manual = FALSE</code>) on the local
machine.  Workers will be started sequentially on other clusters, on
all clusters with <code>setup_strategy = "sequential"</code> and on <span class="rlang"><b>R</b></span> 3.6.0
and older.  This option is for expert use only (e.g.  debugging) and
may be removed in future versions of R.</p>
</dd>
</dl>

<p>Function <code>makeForkCluster</code> creates a socket cluster by forking
(and hence is not available on Windows).  It supports options
<code>port</code>, <code>timeout</code> and <code>outfile</code>, and always uses
<code>useXDR = FALSE</code>. It is <em>strongly discouraged</em> to use the
<code>"FORK"</code> cluster with GUI front-ends  or multi-threaded libraries.
See <code><a href="#topic+mcfork">mcfork</a></code> for details.
</p>
<p>It is good practice to shut down the workers by calling
<code>stopCluster</code>: however the workers will terminate
themselves once the socket on which they are listening for commands
becomes unavailable, which it should if the master <span class="rlang"><b>R</b></span> session is
completed (or its process dies).
</p>
<p>Function <code>setDefaultCluster</code> registers a cluster as the default one
for the current session.  Using <code>setDefaultCluster(NULL)</code> removes
the registered cluster, as does stopping that cluster.
</p>
<p>Function <code>registerClusterType</code> registers a new type of parallel cluster
in the current session. When <code>makeCluster</code> is called with the
newly-registered <code>type</code>, a cluster of that type is created using the
<code>starter</code> function.
</p>


<h3>Value</h3>

<p>For the cluster creators, an object of class
<code>c("SOCKcluster", "cluster")</code>.
</p>
<p>For the default cluster setter and getter, the registered default
cluster or <code>NULL</code> if there is no such cluster.
</p>
<p><code>registerClusterType</code> is invoked for its side effect which is to define
a mechanism for creating a parallel socket cluster of a given named
<code>type</code>.
</p>


<h3>Note</h3>

<p>Option <code>homogeneous = TRUE</code> was for years documented as
&lsquo;Are all the hosts running identical setups?&rsquo;, but this was
apparently more restrictive than its author intended and not required
by the code.
</p>
<p>The current interpretation of <code>homogeneous = TRUE</code> is that
<code>Rscript</code> can be launched using the same path on each worker.
That path is given by the option <code>rscript</code> and defaults to the
full path to <code>Rscript</code> on the master.  (The workers are not
required to be running the same version of <span class="rlang"><b>R</b></span> as the master, nor even
as each other.)
</p>
<p>For <code>homogeneous = FALSE</code>, <code>Rscript</code> on the workers is
found on their default shell's path.
</p>
<p>For the very common usage of running both master and worker on a
single multi-core host, the default settings are the appropriate ones.
</p>
<p>A socket <a href="base.html#topic+connection">connection</a> is used to communicate from the master to
each worker so the maximum number of connections (default 128 but some
will be in use) may need to be increased when the master process is
started.
</p>


<h3>Author(s)</h3>

<p>Luke Tierney and R Core.
</p>
<p>Derived from the <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a> package.
</p>

<hr>
<h2 id='mcaffinity'>Get or Set CPU Affinity Mask of the Current Process</h2><span id='topic+mcaffinity'></span>

<h3>Description</h3>

<p><code>mcaffinity</code> retrieves or sets the CPU affinity mask of the
current process, i.e., the set of CPUs the process is allowed to be
run on. (CPU here means logical CPU which can be CPU, core or
hyperthread unit.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcaffinity(affinity = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcaffinity_+3A_affinity">affinity</code></td>
<td>
<p>specification of the CPUs to lock this process to
(numeric vector) or <code>NULL</code> if no change is requested</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mcaffinity</code> can be used to obtain (<code>affinity = NULL</code>)
or set the CPU affinity mask of the current process. The affinity mask
is a list of integer CPU identifiers (starting from 1) that this
process is allowed to run on. Not all systems provide user access to
the process CPU affinity, in cases where no support is present at all
<code>mcaffinity()</code> will return <code>NULL</code>. Some systems may take
into account only the number of CPUs present in the mask.
</p>
<p>Typically, it is legal to specify larger set than the number of
logical CPUs (but at most as many as the OS can handle) and the system
will return back the actually present set.
</p>


<h3>Value</h3>

<p><code>NULL</code> if CPU affinity is not supported by the system or an
integer vector with the set of CPUs in the active affinity mask for
this process (this may be different than <code>affinity</code>).
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcparallel">mcparallel</a></code>
</p>

<hr>
<h2 id='mcchildren'>Low-level Functions for Management of Forked Processes</h2><span id='topic+children'></span><span id='topic+readChild'></span><span id='topic+readChildren'></span><span id='topic+selectChildren'></span><span id='topic+sendChildStdin'></span><span id='topic+sendMaster'></span><span id='topic+mckill'></span>

<h3>Description</h3>

<p>These are low-level support functions for the forking approach.
</p>
<p>They are not available on Windows, and not exported from the namespace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>children(select)
readChild(child)
readChildren(timeout = 0)
selectChildren(children = NULL, timeout = 0)
sendChildStdin(child, what)
sendMaster(what, raw.asis = TRUE)

mckill(process, signal = 2L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcchildren_+3A_select">select</code></td>
<td>
<p>if omitted, all active children are returned, otherwise
<code>select</code> should be a list of processes and only those from the
list that are active will be returned.</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_child">child</code></td>
<td>
<p>child process (object of the class <code>"childProcess"</code>) or a
process ID (<abbr>pid</abbr>).  See also &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_timeout">timeout</code></td>
<td>
<p>timeout (in seconds, fractions supported) to wait
for a response before giving up.</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_children">children</code></td>
<td>
<p>list of child processes or a single child process
object or a vector of process IDs or <code>NULL</code>.  If <code>NULL</code>
behaves as if all currently known children were supplied.</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_what">what</code></td>
<td>
<p>For <code>sendChildStdin</code>:<br />
Character or raw vector.  In the former case elements are
collapsed using the newline character.  (But no trailing newline is
added at the end!)
</p>
<p>For <code>sendMaster</code>:<br />
Data to send to the master process.  If <code>what</code> is not
a raw vector, it will be serialized into a raw vector.  Do NOT
send an empty raw vector &ndash; that is reserved for internal use.</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_raw.asis">raw.asis</code></td>
<td>
<p>logical, if <code>TRUE</code> and <code>what</code> is a raw
vector then it is sent directly as-is to the master (default,
suitable for arbitrary payload passing), otherwise raw vectors
are serialized before sending just as any other objects
(suitable for passing evaluation results).</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_process">process</code></td>
<td>
<p>process (object of the class <code>process</code>) or a
process ID (<abbr>pid</abbr>)</p>
</td></tr>
<tr><td><code id="mcchildren_+3A_signal">signal</code></td>
<td>
<p>integer: signal to send.  Values of 2 (SIGINT), 9
(SIGKILL) and 15 (SIGTERM) are pretty much portable, but for maximal
portability use <code>tools::<a href="tools.html#topic+SIGTERM">SIGTERM</a></code> and so on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>children</code> returns currently active children.
</p>
<p><code>readChild</code> reads data (sent by <code>sendMaster</code>) from a given
child process.
</p>
<p><code>selectChildren</code> checks children for available data.
</p>
<p><code>readChildren</code> checks all children for available data and reads
from the first child that has available data.
</p>
<p><code>sendChildStdin</code> sends a string (or data) to one or more child's
standard input.  Note that if the master session was interactive, it
will also be echoed on the standard output of the master process
(unless disabled).  The function is vector-compatible, so you can
specify <code>child</code> as a list or a vector of process IDs.
</p>
<p><code>sendMaster</code> sends data from the child to the master process.
</p>
<p><code>mckill</code> sends a signal to a child process: it is equivalent to
<code><a href="tools.html#topic+pskill">pskill</a></code> in package <span class="pkg">tools</span>.
</p>


<h3>Value</h3>

<p><code>children</code> returns a (possibly empty) list of objects of class
<code>"process"</code>, the process ID.
</p>
<p><code>readChild</code> and <code>readChildren</code> return a raw vector with a
<code>"pid"</code> attribute if data were available, an integer vector of
length one with the process ID if a child terminated or <code>NULL</code>
if the child no longer exists (no children at all for
<code>readChildren</code>).
</p>
<p><code>selectChildren</code> returns <code>TRUE</code> is the timeout was reached,
<code>FALSE</code> if an error occurred (e.g., if the master process was
interrupted) or an integer vector of process IDs with children that
have data available, or <code>NULL</code> if there are no children.
</p>
<p><code>sendChildStdin</code> returns a vector of <code>TRUE</code> values (one for
each member of <code>child</code>) or throws an error.
</p>
<p><code>sendMaster</code> returns <code>TRUE</code> or throws an error.
</p>
<p><code>mckill</code> returns <code>TRUE</code>.
</p>


<h3>Warning</h3>

<p>This is a very low-level interface for expert use only: it not
regarded as part of the <span class="rlang"><b>R</b></span> API and subject to change without notice.
</p>
<p><code>sendMaster</code>, <code>readChild</code> and <code>sendChildStdin</code> did not
support long vectors prior to <span class="rlang"><b>R</b></span> 3.4.0 and so were limited to
<code class="reqn">2^{31} - 1</code> bytes (and still are on 32-bit platforms).
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek and R Core.
</p>
<p>Derived from the <span class="pkg">multicore</span> package formerly on <abbr>CRAN</abbr>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcfork">mcfork</a></code>, <code><a href="#topic+mcparallel">mcparallel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
p  &lt;- mcparallel(scan(n = 1, quiet = TRUE))
sendChildStdin(p, "17.4\n")
mccollect(p)[[1]]

## End(Not run)</code></pre>

<hr>
<h2 id='mcfork'>Fork a Copy of the Current R Process</h2><span id='topic+mcfork'></span><span id='topic+mcexit'></span>

<h3>Description</h3>

<p>These are low-level functions, not available on Windows, and not
exported from the namespace.
</p>
<p><code>mcfork</code> creates a new child process as a copy of the current <span class="rlang"><b>R</b></span> process.
</p>
<p><code>mcexit</code> closes the current child process, informing the master
process as necessary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcfork(estranged = FALSE)

mcexit(exit.code = 0L, send = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcfork_+3A_estranged">estranged</code></td>
<td>
<p>logical, if <code>TRUE</code> then the new process has
no ties to the parent process, will not show in the list of
children and will not be killed on exit.</p>
</td></tr>
<tr><td><code id="mcfork_+3A_exit.code">exit.code</code></td>
<td>
<p>process exit code.  By convention <code>0L</code> signifies
a clean exit, <code>1L</code> an error.</p>
</td></tr>
<tr><td><code id="mcfork_+3A_send">send</code></td>
<td>
<p>if not <code>NULL</code> send this data before exiting
(equivalent to using <code><a href="#topic+sendMaster">sendMaster</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>mcfork</code> function provides an interface to the <code>fork</code>
system call.  In addition it sets up a pipe between the master and
child process that can be used to send data from the child process
to the master (see <code><a href="#topic+sendMaster">sendMaster</a></code>) and child's &lsquo;<span class="file">stdin</span>&rsquo; is
re-mapped to another pipe held by the master process (see
<code><a href="#topic+sendChildStdin">sendChildStdin</a></code>).
</p>
<p>If you are not familiar with the <code>fork</code> system call, do not use
this function directly as it leads to very complex inter-process
interactions amongst the <span class="rlang"><b>R</b></span> processes involved.
</p>
<p>In a nutshell <code>fork</code> spawns a copy (child) of the current
process, that can work in parallel to the master (parent)
process.  At the point of forking both processes share exactly the
same state including the workspace, global options, loaded packages
etc.  Forking is relatively cheap in modern operating systems and no
real copy of the used memory is created, instead both processes
share the same memory and only modified parts are copied. This makes
<code>mcfork</code> an ideal tool for parallel processing since there is no
need to setup the parallel working environment, data and code is
shared automatically from the start.
</p>
<p><code>mcexit</code> is to be run in the child process.  It sends <code>send</code>
to the master (unless <code>NULL</code>) and then shuts down the child
process.  The child can also be shut down by sending it the signal
<code>SIGUSR1</code>, as is done by the unexported function
<code>parallel:::rmChild</code>.
</p>


<h3>Value</h3>

<p><code>mcfork</code> returns an object of the class <code>"childProcess"</code> to
the master and of class <code>"masterProcess"</code> to the child: both the
classes inherit from class <code>"process"</code>.  If <code>estranged</code> is
set to <code>TRUE</code> then the child process will be of the class
<code>"estrangedProcess"</code> and cannot communicate with the master
process nor will it show up on the list of children. These are lists
with components <code>pid</code> (the process id of the <em>other</em>
process) and a vector <code>fd</code> of the two file descriptor numbers
for ends in the current process of the inter-process pipes.
</p>
<p><code>mcexit</code> never returns.
</p>


<h3>GUI/embedded environments</h3>

<p>It is <em>strongly discouraged</em> to use <code>mcfork</code> and the
higher-level functions which rely on it (e.g., <code>mcparallel</code>,
<code>mclapply</code> and <code>pvec</code>) in GUI or embedded environments,
because it leads to several processes sharing the same GUI which will
likely cause chaos (and possibly crashes).  Child processes should
never use on-screen graphics devices.  Some precautions have been
taken to make this usable in <code>R.app</code> on macOS, but users of
third-party front-ends should consult their documentation.
</p>
<p>This can also apply to other connections (e.g., to an X server) created
before forking, and to files opened by e.g. graphics devices.
</p>
<p>Note that <span class="pkg">tcltk</span> counts as a GUI for these purposes since
<code>Tcl</code> runs an event loop.  That event loop is inhibited in a
child process but there could still be problems with Tk graphical
connections.
</p>
<p>It is <em>strongly discouraged</em> to use <code>mcfork</code> and the
higher-level functions in any multi-threaded R process (with additional
threads created by a third-party library or package).  Such use can lead
to deadlocks or crashes, because the child process created by
<code>mcfork</code> may not be able to access resources locked in the parent or
may see an inconsistent version of global data (<code>mcfork</code> runs system
call <code>fork</code> without <code>exec</code>).
</p>
<p>If in doubt, it is safer to use a non-FORK cluster (see
<code><a href="#topic+makeCluster">makeCluster</a></code>, <code><a href="#topic+clusterApply">clusterApply</a></code>).
</p>


<h3>Warning</h3>

<p>This is a very low-level API for expert use only.
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek and R Core.
</p>
<p>Derived from the <span class="pkg">multicore</span> package formerly on <abbr>CRAN</abbr>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcparallel">mcparallel</a></code>, <code><a href="#topic+sendMaster">sendMaster</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## This will work when run as an example, but not when pasted in.
p &lt;- parallel:::mcfork()
if (inherits(p, "masterProcess")) {
    cat("I'm a child! ", Sys.getpid(), "\n")
    parallel:::mcexit(,"I was a child")
}
cat("I'm the master\n")
unserialize(parallel:::readChildren(1.5))
</code></pre>

<hr>
<h2 id='mclapply'>Parallel Versions of <code>lapply</code> and <code>mapply</code> using Forking</h2><span id='topic+mclapply'></span><span id='topic+mcmapply'></span><span id='topic+mcMap'></span>

<h3>Description</h3>

<p><code>mclapply</code> is a parallelized version of <code><a href="base.html#topic+lapply">lapply</a></code>,
it returns a list of the same length as <code>X</code>, each element of
which is the result of applying <code>FUN</code> to the corresponding
element of <code>X</code>.
</p>
<p>It relies on forking and hence is not available on Windows unless
<code>mc.cores = 1</code>.
</p>
<p><code>mcmapply</code> is a parallelized version of <code><a href="base.html#topic+mapply">mapply</a></code>, and
<code>mcMap</code> corresponds to <code><a href="base.html#topic+Map">Map</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclapply(X, FUN, ...,
         mc.preschedule = TRUE, mc.set.seed = TRUE,
         mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),
         mc.cleanup = TRUE, mc.allow.recursive = TRUE, affinity.list = NULL)

mcmapply(FUN, ...,
         MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE,
         mc.preschedule = TRUE, mc.set.seed = TRUE,
         mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),
         mc.cleanup = TRUE, affinity.list = NULL)

mcMap(f, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mclapply_+3A_x">X</code></td>
<td>
<p>a vector (atomic or list) or an expressions vector.  Other
objects (including classed objects) will be coerced by
<code><a href="base.html#topic+as.list">as.list</a></code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_fun">FUN</code></td>
<td>
<p>the function to be applied to (<code>mclapply</code>) each
element of <code>X</code> or (<code>mcmapply</code>) in parallel to <code>...</code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_f">f</code></td>
<td>
<p>the function to be applied in parallel to <code>...</code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_...">...</code></td>
<td>
<p>For <code>mclapply</code>, optional arguments to <code>FUN</code>.
For <code>mcmapply</code> and <code>mcMap</code>, vector or list inputs: see
<code><a href="base.html#topic+mapply">mapply</a></code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_moreargs">MoreArgs</code>, <code id="mclapply_+3A_simplify">SIMPLIFY</code>, <code id="mclapply_+3A_use.names">USE.NAMES</code></td>
<td>
<p>see <code><a href="base.html#topic+mapply">mapply</a></code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_mc.preschedule">mc.preschedule</code></td>
<td>
<p>if set to <code>TRUE</code> then the computation is
first divided to (at most) as many jobs are there are cores and then
the jobs are started, each job possibly covering more than one
value.  If set to <code>FALSE</code> then one job is forked for each value
of <code>X</code>.  The former is better for short computations or large
number of values in <code>X</code>, the latter is better for jobs that
have high variance of completion time and not too many values of
<code>X</code> compared to <code>mc.cores</code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_mc.set.seed">mc.set.seed</code></td>
<td>
<p>See <code><a href="#topic+mcparallel">mcparallel</a></code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_mc.silent">mc.silent</code></td>
<td>
<p>if set to <code>TRUE</code> then all output on
&lsquo;<span class="file">stdout</span>&rsquo; will be suppressed for all parallel processes forked
(&lsquo;<span class="file">stderr</span>&rsquo; is not affected).</p>
</td></tr>
<tr><td><code id="mclapply_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to use, i.e. at most how many
child processes will be run simultaneously.   The option is
initialized from environment variable <span class="env">MC_CORES</span> if set.  Must
be at least one, and parallelization requires at least two cores.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_mc.cleanup">mc.cleanup</code></td>
<td>
<p>if set to <code>TRUE</code> then all children that have
been forked by this function will be killed (by sending
<code>SIGTERM</code>) before this function returns.  Under normal
circumstances <code>mclapply</code> waits for the children to deliver
results, so this option usually has only effect when <code>mclapply</code>
is interrupted. If set to <code>FALSE</code> then child processes are
collected, but not forcefully terminated.  As a special case this
argument can be set to the number of the signal that should be used
to kill the children instead of <code>SIGTERM</code>.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_mc.allow.recursive">mc.allow.recursive</code></td>
<td>
<p>Unless true, calling <code>mclapply</code> in a
child process will use the child and not fork again.</p>
</td></tr>
<tr><td><code id="mclapply_+3A_affinity.list">affinity.list</code></td>
<td>
<p>a vector (atomic or list) containing the CPU
affinity mask for each element of <code>X</code>.  The CPU affinity mask
describes on which CPU (core or hyperthread unit) a given item is
allowed to run, see <code><a href="#topic+mcaffinity">mcaffinity</a></code>.  To use this parameter
prescheduling has to be deactivated (<code>mc.preschedule = FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mclapply</code> is a parallelized version of <code><a href="base.html#topic+lapply">lapply</a></code>,
provided <code>mc.cores &gt; 1</code>: for <code>mc.cores == 1</code> (and the
<code>affinity.list</code> is <code>NULL</code>) it simply calls <code>lapply</code>.
</p>
<p>By default (<code>mc.preschedule = TRUE</code>) the input <code>X</code> is split
into as many parts as there are cores (currently the values are spread
across the cores sequentially, i.e. first value to core 1,
second to core 2, ... (core + 1)-th value to core 1 etc.) and then
one process is forked to each core and the results are collected.
</p>
<p>Without prescheduling, a separate job is forked for each value of
<code>X</code>.  To ensure that no more than <code>mc.cores</code> jobs are
running at once, once that number has been forked the master process
waits for a child to complete before the next fork.
</p>
<p>Due to the parallel nature of the execution random numbers are not
sequential (in the random number sequence) as they would be when using
<code>lapply</code>.  They are sequential for each forked process, but not
all jobs as a whole.  See <code><a href="#topic+mcparallel">mcparallel</a></code> or the package's
vignette for ways to make the results reproducible with
<code>mc.preschedule = TRUE</code>.
</p>
<p>Note: the number of file descriptors (and processes) is usually
limited by the operating system, so you may have trouble using more
than 100 cores or so (see <code>ulimit -n</code> or similar in your OS
documentation) unless you raise the limit of permissible open file
descriptors (fork will fail with error <code>"unable to create a pipe"</code>).
</p>
<p>Prior to <span class="rlang"><b>R</b></span> 3.4.0 and on a 32-bit platform, the <a href="base.html#topic+serialize">serialize</a>d
result from each forked process is limited to <code class="reqn">2^{31} - 1</code>
bytes.  (Returning very large results via serialization is
inefficient and should be avoided.)
</p>
<p><code>affinity.list</code> can be used to run elements of <code>X</code> on
specific CPUs.  This can be helpful, if elements of <code>X</code> have a
high variance of completion time or if the hardware architecture is
heterogeneous.  It also enables the development of scheduling
strategies for optimizing the overall runtime of parallel jobs.  If
<code>affinity.list</code> is set, the <code>mc.core</code> parameter is replaced
with the number of CPU ids used in the affinity masks.
</p>


<h3>Value</h3>

<p>For <code>mclapply</code>, a list of the same length as <code>X</code> and named
by <code>X</code>.
</p>
<p>For <code>mcmapply</code>, a list, vector or array: see
<code><a href="base.html#topic+mapply">mapply</a></code>.
</p>
<p>For <code>mcMap</code>, a list.
</p>
<p>Each forked process runs its job inside <code>try(..., silent = TRUE)</code>
so if errors occur they will be stored as class <code>"try-error"</code>
objects in the return value and a warning will be given.  Note that
the job will typically involve more than one value of <code>X</code> and
hence a <code>"try-error"</code> object will be returned for all the values
involved in the failure, even if not all of them failed. If any forked
process is killed or fails to deliver a result for any reason, values
involved in the failure will be <code>NULL</code>. To allow detection of such
errors, <code>FUN</code> should not return <code>NULL</code>. As of <span class="rlang"><b>R</b></span> 4.0, the
return value of <code>mcmapply</code> is always a list when it needs to contain
<code>"try-error"</code> objects (<code>SIMPLIFY</code> is overridden to <code>FALSE</code>).
</p>


<h3>Warning</h3>

<p>It is <em>strongly discouraged</em> to use these functions in GUI or
embedded environments, because it leads to several processes sharing
the same GUI which will likely cause chaos (and possibly
crashes).  Child processes should never use on-screen graphics
devices.
</p>
<p>Some precautions have been taken to make this usable in
<code>R.app</code> on macOS, but users of third-party front-ends
should consult their documentation.
</p>
<p>Note that <span class="pkg">tcltk</span> counts as a GUI for these purposes since
<code>Tcl</code> runs an event loop.  That event loop
is inhibited in a child process but there could still be problems with
Tk graphical connections.
</p>
<p>It is <em>strongly discouraged</em> to use these functions with
multi-threaded libraries or packages (see <code><a href="#topic+mcfork">mcfork</a></code> for more
details).  If in doubt, it is safer to use a non-FORK cluster (see
<code><a href="#topic+makeCluster">makeCluster</a></code>, <code><a href="#topic+clusterApply">clusterApply</a></code>).
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek and R Core.
The <code>affinity.list</code> feature by Helena Kotthaus and Andreas Lang,
TU Dortmund.
Derived from the <span class="pkg">multicore</span> package formerly on <abbr>CRAN</abbr>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcparallel">mcparallel</a></code>, <code><a href="#topic+pvec">pvec</a></code>,
<code><a href="#topic+parLapply">parLapply</a></code>, <code><a href="#topic+clusterMap">clusterMap</a></code>.
</p>
<p><code><a href="base.html#topic+simplify2array">simplify2array</a></code> for results like <code><a href="base.html#topic+sapply">sapply</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
simplify2array(mclapply(rep(4, 5), rnorm))
# use the same random numbers for all values
set.seed(1)
simplify2array(mclapply(rep(4, 5), rnorm, mc.preschedule = FALSE,
                        mc.set.seed = FALSE))

## Contrast this with the examples for clusterCall
library(boot)
cd4.rg &lt;- function(data, mle) MASS::mvrnorm(nrow(data), mle$m, mle$v)
cd4.mle &lt;- list(m = colMeans(cd4), v = var(cd4))
mc &lt;- getOption("mc.cores", 2)
run1 &lt;- function(...) boot(cd4, corr, R = 500, sim = "parametric",
                           ran.gen = cd4.rg, mle = cd4.mle)
## To make this reproducible:
set.seed(123, "L'Ecuyer")
res &lt;- mclapply(seq_len(mc), run1)
cd4.boot &lt;- do.call(c, res)
boot.ci(cd4.boot,  type = c("norm", "basic", "perc"),
        conf = 0.9, h = atanh, hinv = tanh)

## Usage of the affinity.list parameter
A &lt;- runif(2500000,0,100)
B &lt;- runif(2500000,0,100)
C &lt;- runif(5000000,0,100)
first &lt;- function(i) head(sort(i), n = 1)

# Restrict all elements of X to run on CPU 1 and 2
affL &lt;- list(c(1,2), c(1,2), c(1,2))
mclapply(list(A, A, A), first, mc.preschedule = FALSE, affinity.list = affL)


# Completion times are assumed to have a high variance
# To optimize the overall execution time elements of X are scheduled to suitable CPUs
# Assuming that the runtime for C is as long as the runtime of A plus B
# mapping: A to 1 , B to 1, C to 2
X &lt;- list(A, B, C)
affL &lt;- c(1, 1, 2)
mclapply(X, first, mc.preschedule = FALSE, affinity.list = affL)

</code></pre>

<hr>
<h2 id='mcparallel'>Evaluate an <span class="rlang"><b>R</b></span> Expression Asynchronously in a Separate Process</h2><span id='topic+mccollect'></span><span id='topic+mcparallel'></span>

<h3>Description</h3>

<p>These functions are based on forking and so are not available on Windows.
</p>
<p><code>mcparallel</code> starts a parallel <span class="rlang"><b>R</b></span> process which evaluates the
given expression.
</p>
<p><code>mccollect</code> collects results from one or more parallel processes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcparallel(expr, name, mc.set.seed = TRUE, silent = FALSE,
           mc.affinity = NULL, mc.interactive = FALSE,
	   detached = FALSE)

mccollect(jobs, wait = TRUE, timeout = 0, intermediate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcparallel_+3A_expr">expr</code></td>
<td>
<p>expression to evaluate (do <em>not</em> use any on-screen
devices or GUI elements in this code, see <code><a href="#topic+mcfork">mcfork</a></code> for
the inadvisability of using <code>mcparallel</code> with GUI front-ends
and multi-threaded libraries).  Raw vectors are reserved for
internal use and cannot be returned, but the expression may evaluate
e.g. to a list holding a raw vector. <code>NULL</code> should not be returned
because it is used by <code>mccollect</code> to signal an error. </p>
</td></tr>
<tr><td><code id="mcparallel_+3A_name">name</code></td>
<td>
<p>an optional name (character vector of length one) that can
be associated with the job.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_mc.set.seed">mc.set.seed</code></td>
<td>
<p>logical: see section &lsquo;Random numbers&rsquo;.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_silent">silent</code></td>
<td>
<p>if set to <code>TRUE</code> then all output on stdout will be
suppressed (stderr is not affected).</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_mc.affinity">mc.affinity</code></td>
<td>
<p>either a numeric vector specifying CPUs to restrict
the child process to (1-based) or <code>NULL</code> to not modify the CPU
affinity</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_mc.interactive">mc.interactive</code></td>
<td>
<p>logical, if <code>TRUE</code> or <code>FALSE</code> then the
child process will be set as interactive or non-interactive
respectively. If <code>NA</code> then the child process will inherit the
interactive flag from the parent.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_detached">detached</code></td>
<td>
<p>logical, if <code>TRUE</code> then the job is detached from
the current session and cannot deliver any results back - it is used
for the code side-effect only.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_jobs">jobs</code></td>
<td>
<p>list of jobs (or a single job) to collect results
for.  Alternatively <code>jobs</code> can also be an integer vector of
process IDs.  If omitted <code>collect</code> will wait for all currently
existing children.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_wait">wait</code></td>
<td>
<p>if set to <code>FALSE</code> it checks for any results that are
available within <code>timeout</code> seconds from now, otherwise it waits
for all specified jobs to finish.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_timeout">timeout</code></td>
<td>
<p>timeout (in seconds) to check for job results &ndash; applies
only if <code>wait</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mcparallel_+3A_intermediate">intermediate</code></td>
<td>
<p><code>FALSE</code> or a function which will be called while
<code>collect</code> waits for results.  The function will be called with one
parameter which is the list of results received so far.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mcparallel</code> evaluates the <code>expr</code> expression in parallel to
the current <span class="rlang"><b>R</b></span> process.  Everything is shared read-only (or in fact
copy-on-write) between the parallel process and the current process,
i.e. no side-effects of the expression affect the main process.  The
result of the parallel execution can be collected using
<code>mccollect</code> function.
</p>
<p><code>mccollect</code> function collects any available results from parallel
jobs (or in fact any child process).  If <code>wait</code> is <code>TRUE</code>
then <code>collect</code> waits for all specified jobs to finish before
returning a list containing the last reported result for each
job.   If <code>wait</code> is <code>FALSE</code> then <code>mccollect</code> merely
checks for any results available at the moment and will not wait for
jobs to finish.   If <code>jobs</code> is specified, jobs not listed there
will not be affected or acted upon.
</p>
<p>Note: If <code>expr</code> uses low-level multicore functions such
as <code><a href="#topic+sendMaster">sendMaster</a></code> a single job can deliver results
multiple times and it is the responsibility of the user to interpret
them correctly.  <code>mccollect</code> will return <code>NULL</code> for a
terminating job that has sent its results already after which the
job is no longer available.
</p>
<p>Jobs are identified by process IDs (even when referred to as job objects),
which are reused by the operating system.  Detached jobs created by
<code>mcparallel</code> can thus never be safely referred to by their process
IDs nor job objects.  Non-detached jobs are guaranteed to exist until
collected by <code>mccollect</code>, even if crashed or terminated by a signal. 
Once collected by <code>mccollect</code>, a job is regarded as detached, and
thus must no longer be referred to by its process ID nor its job object. 
With <code>wait = TRUE</code>, all jobs passed to <code>mccollect</code> are
collected.  With <code>wait = FALSE</code>, the collected jobs are given as
names of the result vector, and thus in subsequent calls to
<code>mccollect</code> these jobs must be excluded. Job objects should be used
in preference of process IDs whenever accepted by the API.
</p>
<p>The <code>mc.affinity</code> parameter can be used to try to restrict
the child process to specific CPUs. The availability and the extent of
this feature is system-dependent (e.g., some systems will only
consider the CPU count, others will ignore it completely).
</p>


<h3>Value</h3>

<p><code>mcparallel</code> returns an object of the class <code>"parallelJob"</code>
which inherits from <code>"childProcess"</code> (see the &lsquo;Value&rsquo;
section of the help for <code><a href="#topic+mcfork">mcfork</a></code>).  If argument
<code>name</code> was supplied this will have an additional component
<code>name</code>.
</p>
<p><code>mccollect</code> returns any results that are available in a list.  The
results will have the same order as the specified jobs.  If there are
multiple jobs and a job has a name it will be used to name the
result, otherwise its process ID will be used.  If none of the
specified children are still running, it returns <code>NULL</code>.
</p>


<h3>Random numbers</h3>

<p>If <code>mc.set.seed = FALSE</code>, the child process has the same initial
random number generator (RNG) state as the current <span class="rlang"><b>R</b></span> session.  If the
RNG has been used (or <code>.Random.seed</code> was restored from a saved
workspace), the child will start drawing random numbers at the same
point as the current session.  If the RNG has not yet been used, the
child will set a seed based on the time and process ID when it first
uses the RNG: this is pretty much guaranteed to give a different
random-number stream from the current session and any other child
process.
</p>
<p>The behaviour with <code>mc.set.seed = TRUE</code> is different only if
<code><a href="base.html#topic+RNGkind">RNGkind</a>("L'Ecuyer-CMRG")</code> has been selected.  Then each
time a child is forked it is given the next stream (see
<code><a href="#topic+nextRNGStream">nextRNGStream</a></code>).  So if you select that generator, set a
seed and call <code><a href="#topic+mc.reset.stream">mc.reset.stream</a></code> just before the first use
of <code>mcparallel</code> the results of simulations will be reproducible
provided the same tasks are given to the first, second, ...
forked process.
</p>


<h3>Note</h3>

<p>Prior to <span class="rlang"><b>R</b></span> 3.4.0 and on a 32-bit platform, the <a href="base.html#topic+serialize">serialize</a>d
result from each forked process is limited to <code class="reqn">2^{31} - 1</code> bytes.  (Returning very large results via serialization is
inefficient and should be avoided.)
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek and R Core.
</p>
<p>Derived from the <span class="pkg">multicore</span> package formerly on
<abbr>CRAN</abbr>. (but with different handling of the RNG stream).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pvec">pvec</a></code>, <code><a href="#topic+mclapply">mclapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- mcparallel(1:10)
q &lt;- mcparallel(1:20)
# wait for both jobs to finish and collect all results
res &lt;- mccollect(list(p, q))


p &lt;- mcparallel(1:10)
mccollect(p, wait = FALSE, 10) # will retrieve the result (since it's fast)
mccollect(p, wait = FALSE)     # will signal the job as terminating
mccollect(p, wait = FALSE)     # there is no longer such a job


# a naive parallel lapply can be created using mcparallel alone:
jobs &lt;- lapply(1:10, function(x) mcparallel(rnorm(x), name = x))
mccollect(jobs)
</code></pre>

<hr>
<h2 id='pvec'>Parallelize a Vector Map Function using Forking</h2><span id='topic+pvec'></span>

<h3>Description</h3>

<p><code>pvec</code> parallelizes the execution of a function on vector elements
by splitting the vector and submitting each part to one core. The
function must be a vectorized map, i.e. it takes a vector input and
creates a vector output of exactly the same length as the input which
doesn't depend on the partition of the vector.
</p>
<p>It relies on forking and hence is not available on Windows unless
<code>mc.cores = 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvec(v, FUN, ..., mc.set.seed = TRUE, mc.silent = FALSE,
     mc.cores = getOption("mc.cores", 2L), mc.cleanup = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pvec_+3A_v">v</code></td>
<td>
<p>vector to operate on</p>
</td></tr>
<tr><td><code id="pvec_+3A_fun">FUN</code></td>
<td>
<p>function to call on each part of the vector</p>
</td></tr>
<tr><td><code id="pvec_+3A_...">...</code></td>
<td>
<p>any further arguments passed to <code>FUN</code> after the vector</p>
</td></tr>
<tr><td><code id="pvec_+3A_mc.set.seed">mc.set.seed</code></td>
<td>
<p>See <code><a href="#topic+mcparallel">mcparallel</a></code>.</p>
</td></tr>
<tr><td><code id="pvec_+3A_mc.silent">mc.silent</code></td>
<td>
<p>if set to <code>TRUE</code> then all output on &lsquo;<span class="file">stdout</span>&rsquo; will
be suppressed for all parallel processes forked (&lsquo;<span class="file">stderr</span>&rsquo; is not
affected).</p>
</td></tr>
<tr><td><code id="pvec_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The number of cores to use, i.e. at most how many
child processes will be run simultaneously.  Must be at least one,
and at least two for parallel operation.  The option is initialized
from environment variable <span class="env">MC_CORES</span> if set.</p>
</td></tr>
<tr><td><code id="pvec_+3A_mc.cleanup">mc.cleanup</code></td>
<td>
<p>See the description of this argument in
<code><a href="#topic+mclapply">mclapply</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pvec</code> parallelizes <code>FUN(x, ...)</code> where <code>FUN</code> is a
function that returns a vector of the same length as
<code>x</code>. <code>FUN</code> must also be pure (i.e., without side-effects)
since side-effects are not collected from the parallel processes. The
vector is split into nearly identically sized subvectors on which
<code>FUN</code> is run.  Although it is in principle possible to use
functions that are not necessarily maps, the interpretation would be
case-specific as the splitting is in theory arbitrary (a warning is
given in such cases).
</p>
<p>The major difference between <code>pvec</code> and <code><a href="#topic+mclapply">mclapply</a></code> is
that <code>mclapply</code> will run <code>FUN</code> on each element separately
whereas <code>pvec</code> assumes that <code>c(FUN(x[1]), FUN(x[2]))</code> is
equivalent to <code>FUN(x[1:2])</code> and thus will split into as many
calls to <code>FUN</code> as there are cores (or elements, if fewer), each
handling a subset vector.  This makes it more efficient than
<code>mclapply</code> but requires the above assumption on <code>FUN</code>.
</p>
<p>If <code>mc.cores == 1</code> this evaluates <code>FUN(v, ...)</code> in the
current process.
</p>


<h3>Value</h3>

<p>The result of the computation &ndash; in a successful case it should be of
the same length as <code>v</code>.  If an error occurred or the function was
not a map the result may be shorter or longer, and a warning is given.
</p>


<h3>Note</h3>

<p>Due to the nature of the parallelization, error handling does not
follow the usual rules since errors will be returned as strings and
results from killed child processes will show up simply as
non-existent data.  Therefore it is the responsibility of the user to
check the length of the result to make sure it is of the correct size.
<code>pvec</code> raises a warning if that is the case since it does not
know whether such an outcome is intentional or not.
</p>
<p>See <code><a href="#topic+mcfork">mcfork</a></code> for the inadvisability of using this with
GUI front-ends and multi-threaded libraries.
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek and R Core.
</p>
<p>Derived from the <span class="pkg">multicore</span> package formerly on <abbr>CRAN</abbr>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcparallel">mcparallel</a></code>, <code><a href="#topic+mclapply">mclapply</a></code>,
<code><a href="#topic+parLapply">parLapply</a></code>, <code><a href="#topic+clusterMap">clusterMap</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- pvec(1:1000, sqrt)
stopifnot(all(x == sqrt(1:1000)))


# One use is to convert date strings to unix time in large datasets
# as that is a relatively slow operation.
# So let's get some random dates first
# (A small test only with 2 cores: set options("mc.cores")
# and increase N for a larger-scale test.)
N &lt;- 1e5
dates &lt;- sprintf('%04d-%02d-%02d', as.integer(2000+rnorm(N)),
                 as.integer(runif(N, 1, 12)), as.integer(runif(N, 1, 28)))

system.time(a &lt;- as.POSIXct(dates))

# But specifying the format is faster
system.time(a &lt;- as.POSIXct(dates, format = "%Y-%m-%d"))

# pvec ought to be faster, but system overhead can be high
system.time(b &lt;- pvec(dates, as.POSIXct, format = "%Y-%m-%d"))
stopifnot(all(a == b))

# using mclapply for this would much slower because each value
# will require a separate call to as.POSIXct()
# as lapply(dates, as.POSIXct) does
system.time(c &lt;- unlist(mclapply(dates, as.POSIXct,  format = "%Y-%m-%d")))
stopifnot(all(a == c))
</code></pre>

<hr>
<h2 id='RNGstreams'>Implementation of Pierre L'Ecuyer's RngStreams</h2><span id='topic+nextRNGStream'></span><span id='topic+nextRNGSubStream'></span><span id='topic+clusterSetRNGStream'></span><span id='topic+mc.reset.stream'></span>

<h3>Description</h3>

<p>This is an <span class="rlang"><b>R</b></span> re-implementation of Pierre L'Ecuyer's
&lsquo;RngStreams&rsquo; multiple streams of pseudo-random numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nextRNGStream(seed)
nextRNGSubStream(seed)

clusterSetRNGStream(cl = NULL, iseed)
mc.reset.stream()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RNGstreams_+3A_seed">seed</code></td>
<td>
<p>An integer vector of length 7 as given by
<code>.Random.seed</code> when the &lsquo;<span class="samp">&#8288;"L'Ecuyer-CMRG"&#8288;</span>&rsquo; RNG is in use.
See <code><a href="base.html#topic+RNG">RNG</a></code> for the valid values.</p>
</td></tr>
<tr><td><code id="RNGstreams_+3A_cl">cl</code></td>
<td>
<p>A cluster from this package or package <a href="https://CRAN.R-project.org/package=snow"><span class="pkg">snow</span></a>, or (if
<code>NULL</code>) the registered cluster.</p>
</td></tr>
<tr><td><code id="RNGstreams_+3A_iseed">iseed</code></td>
<td>
<p>An integer to be supplied to <code><a href="base.html#topic+set.seed">set.seed</a></code>, or
<code>NULL</code> not to set reproducible seeds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &lsquo;RngStreams&rsquo; interface works with (potentially) multiple
streams of pseudo-random numbers: this is particularly suitable for
working with parallel computations since each task can be assigned a
separate RNG stream.
</p>
<p>This uses as its underlying generator <code>RNGkind("L'Ecuyer-CMRG")</code>,
of L'Ecuyer (1999), which has a seed vector of 6 (signed) integers and a
period of around <code class="reqn">2^{191}</code>.  Each &lsquo;stream&rsquo; is a
subsequence of the period of length <code class="reqn">2^{127}</code> which is in
turn divided into &lsquo;substreams&rsquo; of length <code class="reqn">2^{76}</code>.
</p>
<p>The idea of L'Ecuyer <em>et al</em> (2002) is to use a separate stream
for each of the parallel computations (which ensures that the random
numbers generated never get into to sync) and the parallel
computations can themselves use substreams if required.  The original
interface stores the original seed of the first stream, the original
seed of the current stream and the current seed: this could be
implemented in <span class="rlang"><b>R</b></span>, but it is as easy to work by saving the relevant
values of <code>.Random.seed</code>: see the examples.
</p>
<p><code>clusterSetRNGStream</code> selects the <code>"L'Ecuyer-CMRG"</code> RNG and
then distributes streams to the members of a cluster, optionally
setting the seed of the streams by <code>set.seed(iseed)</code> (otherwise
they are set from the current seed of the master process: after
selecting the L'Ecuyer generator).
</p>
<p>When not on Windows, Calling <code>mc.reset.stream()</code> after setting
the L'Ecuyer random number generator and seed makes runs from
</p>
<p><code><a href="#topic+mcparallel">mcparallel</a>(mc.set.seed = TRUE)</code>
reproducible.  This is
done internally in <code><a href="#topic+mclapply">mclapply</a></code> and <code><a href="#topic+pvec">pvec</a></code>.
(Note that it does not set the seed in the master process, so does not
affect the fallback-to-serial versions of these functions.)
</p>


<h3>Value</h3>

<p>For <code>nextRNGStream</code> and <code>nextRNGSubStream</code>,
a value which can be assigned to <code>.Random.seed</code>.
</p>


<h3>Note</h3>

<p>Interfaces to L'Ecuyer's C code are available in CRAN
packages <a href="https://CRAN.R-project.org/package=rlecuyer"><span class="pkg">rlecuyer</span></a> and <a href="https://CRAN.R-project.org/package=rstream"><span class="pkg">rstream</span></a>.
</p>


<h3>Author(s)</h3>

<p>Brian Ripley
</p>


<h3>References</h3>

<p>L'Ecuyer, P. (1999).
Good parameters and implementations for combined multiple recursive
random number generators.
<em>Operations Research</em>, <b>47</b>, 159&ndash;164.
<a href="https://doi.org/10.1287/opre.47.1.159">doi:10.1287/opre.47.1.159</a>.
</p>
<p>L'Ecuyer, P., Simard, R.,  Chen, E. J. and Kelton, W. D. (2002).
An object-oriented random-number package with many long streams
and substreams.
<em>Operations Research</em>, <b>50</b>, 1073&ndash;1075.
<a href="https://doi.org/10.1287/opre.50.6.1073.358">doi:10.1287/opre.50.6.1073.358</a>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+RNG">RNG</a></code> for fuller details of <span class="rlang"><b>R</b></span>'s built-in random number
generators.
</p>
<p>The vignette for package <span class="pkg">parallel</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RNGkind("L'Ecuyer-CMRG")
set.seed(123)
(s &lt;- .Random.seed)
## do some work involving random numbers.
nextRNGStream(s)
nextRNGSubStream(s)
</code></pre>

<hr>
<h2 id='sendData'>Cluster Back-end Interface</h2><span id='topic+closeNode'></span><span id='topic+recvData'></span><span id='topic+recvOneData'></span><span id='topic+sendData'></span>

<h3>Description</h3>

<p>The communication primitives used by the <span class="pkg">parallel</span> package to
handle the state and communicate with nodes in the clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  sendData(node, data)
  recvData(node)
  recvOneData(cl)
  closeNode(node)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sendData_+3A_cl">cl</code></td>
<td>

<p>The cluster object, visible to the user. Should be a list inheriting
from class <code>cluster</code>, containing the node objects.
</p>
</td></tr>
<tr><td><code id="sendData_+3A_node">node</code></td>
<td>

<p>The node object corresponding to one execution unit inside the
cluster.
</p>
</td></tr>
<tr><td><code id="sendData_+3A_data">data</code></td>
<td>

<p>The data structure containing a message to the node.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>`[.cluster`</code> method is provided, which retains the classes of the
cluster when subset. The cluster back-end should either rely on this method or
supply its own method that also invokes this method through <code>NextMethod</code>
or calls <code>.subset</code> directly.
</p>
<p>The <code>data</code> messages sent to the nodes are lists containing the
following elements: </p>

<dl>
<dt>type</dt><dd>
<p>A short string describing the type of packet: </p>

<dl>
<dt>DONE</dt><dd>
<p>Sent by the default <code>stopCluster</code> implementation before
calling <code>closeNode</code>.
</p>
</dd>
<dt>EXEC</dt><dd>
<p>The packet contains a job to execute.
</p>
</dd>
</dl>

</dd>
<dt>value</dt><dd>
<p>For messages of type &ldquo;EXEC&rdquo;, a list with the following
elements: </p>

<dl>
<dt>fun</dt><dd>
<p>The function to execute.
</p>
</dd>
<dt>args</dt><dd>
<p>The arguments for <code>fun</code> above as a list.
</p>
</dd>
<dt>return</dt><dd>
<p>Defaults to <code>TRUE</code>. Not currently used by <span class="pkg">parallel</span>.
</p>
</dd>
<dt>tag</dt><dd>
<p>The same tag must be returned back from the worker. Used to
identify individual elements of a larger job when using
dynamic load balancing.
</p>
</dd>
</dl>

</dd>
</dl>

<p>If the &ldquo;DONE&rdquo; messages are used (for example when calling
<code>stopCluster.default</code>), the node can close the connection upon
receipt.
</p>
<p>The response to an &ldquo;EXEC&rdquo; message that should be returned by
<code>recvData</code> is a list with the following elements: </p>

<dl>
<dt>type</dt><dd><p>A string, <code>"VALUE"</code>.</p>
</dd>
<dt>value</dt><dd>
<p>The value of <code>do.call(fun, args, quote = TRUE)</code>. If the
evaluation raised an error, the value of the error.
</p>
</dd>
<dt>success</dt><dd>
<p>A logical scalar indicating whether the evaluation completed
without raising an error.
</p>
</dd>
<dt>time</dt><dd>
<p>The time it took to complete the job, an object of class
<code>proc_time</code>. Can be obtained using
<code><a href="base.html#topic+system.time">system.time</a></code> or by subtracting outputs of
<code><a href="base.html#topic+proc.time">proc.time</a></code>.
</p>
</dd>
<dt>tag</dt><dd>
<p>The original <code>tag</code> from the &ldquo;EXEC&rdquo; message.
</p>
</dd>
</dl>

<p><code>recvData</code> can block if the job is not yet complete, and
<code>recvOneData</code> should block until at least one node is able to
return a complete job result.
</p>
<p>The default <code>closeNode</code> method does nothing. It is envisaged that
<code>stopCluster</code> is used to shut down the entire cluster, although other
back-ends may use this to implement node-specific logic.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>sendData</code></td>
<td>

<p>Ignored. Called for the side effect of sending the <code>data</code> to the
node.
</p>
</td></tr>
<tr><td><code>recvData</code></td>
<td>

<p>The result of the job previously submitted to the node.
</p>
</td></tr>
<tr><td><code>recvOneData</code></td>
<td>

<p>A list with the following items: </p>

<dl>
<dt>node</dt><dd><p>The index of the node returning the data.</p>
</dd>
<dt>value</dt><dd><p>The result of <code>recvData(cluster[[node]])</code>.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>closeNode</code></td>
<td>

<p>Ignored. Called for the side effect of cleaning up the connection to
the node.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+stopCluster">stopCluster</a></code> should also be implemented, but is a user
interface and documented separately. The default method will post
termination messages to individual nodes and then call
<code>closeNode</code> on them.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # A toy cluster consisting of one connection.
  sendData.mynode &lt;- function(node, data) serialize(data, node)
  recvData.mynode &lt;- function(node) unserialize(node)
  recvOneData.mycluster &lt;- function(cl) list(
    node = 1, value = recvData(cl[[1]])
  )
  closeNode.mynode &lt;- function(node) close(node)

  # Not shown: R starting a serverSocket on the other end, ready to
  # accept connections and evaluate jobs
  cl &lt;- structure(list(
    structure(
      socketConnection(..., blocking = TRUE, open = 'a+b'),
      class = 'mynode'
    )
  ), class = c('mycluster', 'cluster'))
  clusterEvalQ(cl, Sys.getpid())
  stopCluster(cl)
  rm(cl)

## End(Not run)</code></pre>

<hr>
<h2 id='splitIndices'>Divide Tasks for Distribution in a Cluster</h2><span id='topic+splitIndices'></span>

<h3>Description</h3>

<p>This divides up <code>1:nx</code> into <code>ncl</code> lists of approximately
equal size, as a way to allocate tasks to nodes in a cluster.
</p>
<p>It is mainly for internal use, but some package authors have found it useful.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitIndices(nx, ncl)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splitIndices_+3A_nx">nx</code></td>
<td>
<p>Number of tasks.</p>
</td></tr>
<tr><td><code id="splitIndices_+3A_ncl">ncl</code></td>
<td>
<p>Number of cluster nodes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length <code>ncl</code>, each element being an integer vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>splitIndices(20, 3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
