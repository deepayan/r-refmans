<!DOCTYPE html><html><head><title>Help for package ncpen</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ncpen}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef.cv.ncpen'><p>coef.cv.ncpen: extracts the optimal coefficients from <code>cv.ncpen</code>.</p></a></li>
<li><a href='#coef.ncpen'><p>coef.ncpen: extract the coefficients from an <code>ncpen</code> object</p></a></li>
<li><a href='#control.ncpen'><p>control.ncpen: do preliminary works for <code>ncpen</code>.</p></a></li>
<li><a href='#cv.ncpen'><p>cv.ncpen: cross validation for <code>ncpen</code></p></a></li>
<li><a href='#cv.ncpen.reg'><p>cv.ncpen: cross validation for <code>ncpen</code></p></a></li>
<li><a href='#excluded'><p>Check whether a pair should be excluded from interactions.</p></a></li>
<li><a href='#fold.cv.ncpen'><p>fold.cv.ncpen: extracts fold ids for <code>cv.ncpen</code>.</p></a></li>
<li><a href='#gic.ncpen'><p>gic.ncpen: compute the generalized information criterion (GIC) for the selection of lambda</p></a></li>
<li><a href='#interact.data'><p>Construct Interaction Matrix</p></a></li>
<li><a href='#make.ncpen.data'><p>Create ncpen Data Structure Using a Formula</p></a></li>
<li><a href='#native_cpp_ncpen_fun_'><p>Native ncpen function.</p></a></li>
<li><a href='#native_cpp_nr_fun_'><p>N/A.</p></a></li>
<li><a href='#native_cpp_obj_fun_'><p>Native object function.</p></a></li>
<li><a href='#native_cpp_obj_grad_fun_'><p>Native object gradient function.</p></a></li>
<li><a href='#native_cpp_obj_hess_fun_'><p>Native object Hessian function.</p></a></li>
<li><a href='#native_cpp_p_ncpen_fun_'><p>Native point ncpen function.</p></a></li>
<li><a href='#native_cpp_pen_fun_'><p>Native Penalty function.</p></a></li>
<li><a href='#native_cpp_pen_grad_fun_'><p>Native Penalty Gradient function.</p></a></li>
<li><a href='#native_cpp_qlasso_fun_'><p>Native QLASSO function.</p></a></li>
<li><a href='#native_cpp_set_dev_mode_'><p>N/A.</p></a></li>
<li><a href='#ncpen'><p>ncpen: nonconvex penalized estimation</p></a></li>
<li><a href='#ncpen-package'><p>ncpen: A package for non-convex penalized estimation for generalized linear models</p></a></li>
<li><a href='#ncpen.reg'><p>ncpen.reg: nonconvex penalized estimation</p></a></li>
<li><a href='#plot.cv.ncpen'><p>plot.cv.ncpen: plot cross-validation error curve.</p></a></li>
<li><a href='#plot.ncpen'><p>plot.ncpen: plots coefficients from an <code>ncpen</code> object.</p></a></li>
<li><a href='#power.data'><p>Power Data</p></a></li>
<li><a href='#predict.ncpen'><p>predict.ncpen: make predictions from an <code>ncpen</code> object</p></a></li>
<li><a href='#sam.gen.ncpen'><p>sam.gen.ncpen: generate a simulated dataset.</p></a></li>
<li><a href='#same.base'><p>Check whether column names are derivation of a same base.</p></a></li>
<li><a href='#to.indicators'><p>Construct Indicator Matrix</p></a></li>
<li><a href='#to.ncpen.x.mat'><p>Convert a <code>data.frame</code> to a <code>ncpen</code> usable <code>matrix</code>.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Unified Algorithm for Non-convex Penalized Estimation for
Generalized Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-11-16</td>
</tr>
<tr>
<td>Description:</td>
<td>An efficient unified nonconvex penalized estimation algorithm for
    Gaussian (linear), binomial Logit (logistic), Poisson, multinomial Logit,
    and Cox proportional hazard regression models.
    The unified algorithm is implemented based on the convex concave procedure and
    the algorithm can be applied to most of the existing nonconvex penalties.
    The algorithm also supports convex penalty:
    least absolute shrinkage and selection operator (LASSO).
    Supported nonconvex penalties include
    smoothly clipped absolute deviation (SCAD),
    minimax concave penalty (MCP), truncated LASSO penalty (TLP),
    clipped LASSO (CLASSO), sparse ridge (SRIDGE),
    modified bridge (MBRIDGE) and modified log (MLOG).
    For high-dimensional data (data set with many variables),
    the algorithm selects relevant variables producing a parsimonious regression model.
    Kim, D., Lee, S. and Kwon, S. (2018) &lt;<a href="https://arxiv.org/abs/1811.05061">arXiv:1811.05061</a>&gt;,
    Lee, S., Kwon, S. and Kim, Y. (2016) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2015.08.019">doi:10.1016/j.csda.2015.08.019</a>&gt;,
    Kwon, S., Lee, S. and Kim, Y. (2015) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2015.07.001">doi:10.1016/j.csda.2015.07.001</a>&gt;.
    (This research is funded by Julian Virtue Professorship from Center for Applied Research at Pepperdine
    Graziadio Business School and the National Research Foundation of Korea.)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/zeemkr/ncpen">https://github.com/zeemkr/ncpen</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/zeemkr/ncpen/issues">https://github.com/zeemkr/ncpen/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.2)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.4)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-11-17 17:59:55 UTC; dongshin</td>
</tr>
<tr>
<td>Author:</td>
<td>Dongshin Kim [aut, cre, cph],
  Sunghoon Kwon [aut, cph],
  Sangin Lee [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dongshin Kim &lt;dongshin.kim@live.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-11-17 18:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef.cv.ncpen'>coef.cv.ncpen: extracts the optimal coefficients from <code>cv.ncpen</code>.</h2><span id='topic+coef.cv.ncpen'></span>

<h3>Description</h3>

<p>The function returns the optimal vector of coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ncpen'
coef(object, type = c("rmse", "like"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.ncpen_+3A_object">object</code></td>
<td>
<p>(cv.ncpen object) fitted <code>cv.ncpen</code> object.</p>
</td></tr>
<tr><td><code id="coef.cv.ncpen_+3A_type">type</code></td>
<td>
<p>(character) a cross-validated error type which is either <code>rmse</code> or <code>like</code>.</p>
</td></tr>
<tr><td><code id="coef.cv.ncpen_+3A_...">...</code></td>
<td>
<p>other S3 parameters. Not used.
Each error type is defined in <code><a href="#topic+cv.ncpen">cv.ncpen</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the optimal coefficients vector selected by cross-validation.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>error type.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the optimal lambda selected by  CV.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the optimal coefficients selected by CV.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.ncpen">cv.ncpen</a></code>, <code><a href="#topic+plot.cv.ncpen">plot.cv.ncpen</a></code> , <code><a href="#topic+gic.ncpen">gic.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = cv.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10)
coef(fit)
### logistic regression with classo penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="binomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = cv.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,family="binomial",penalty="classo")
coef(fit)
### multinomial regression with sridge penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = cv.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,family="multinomial",penalty="sridge")
coef(fit)
</code></pre>

<hr>
<h2 id='coef.ncpen'>coef.ncpen: extract the coefficients from an <code>ncpen</code> object</h2><span id='topic+coef.ncpen'></span>

<h3>Description</h3>

<p>The function returns the coefficients matrix for all lambda values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncpen'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.ncpen_+3A_object">object</code></td>
<td>
<p>(ncpen object) fitted <code>ncpen</code> object.</p>
</td></tr>
<tr><td><code id="coef.ncpen_+3A_...">...</code></td>
<td>
<p>other S3 parameters. Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>beta</code></td>
<td>
<p>The coefficients matrix or list for <code>multinomial</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncpen">ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat)
coef(fit)
### multinomial regression with classo penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat,family="multinomial",penalty="classo")
coef(fit)
</code></pre>

<hr>
<h2 id='control.ncpen'>control.ncpen: do preliminary works for <code>ncpen</code>.</h2><span id='topic+control.ncpen'></span>

<h3>Description</h3>

<p>The function returns controlled samples and tuning parameters for <code>ncpen</code> by eliminating unnecessary errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>control.ncpen(y.vec, x.mat, family = c("gaussian", "binomial", "poisson",
  "multinomial", "cox"), penalty = c("scad", "mcp", "tlp", "lasso",
  "classo", "ridge", "sridge", "mbridge", "mlog"), x.standardize = TRUE,
  intercept = TRUE, lambda = NULL, n.lambda = NULL,
  r.lambda = NULL, w.lambda = NULL, gamma = NULL, tau = NULL,
  alpha = NULL, aiter.max = 100, b.eps = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="control.ncpen_+3A_y.vec">y.vec</code></td>
<td>
<p>(numeric vector) response vector.
Must be 0,1 for <code>binomial</code> and 1,2,..., for <code>multinomial</code>.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_x.mat">x.mat</code></td>
<td>
<p>(numeric matrix) design matrix without intercept.
The censoring indicator must be included at the last column of the design matrix for <code>cox</code>.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_family">family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code>,
<code>binomial</code>,
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>.
Default is <code>gaussian</code>.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_penalty">penalty</code></td>
<td>
<p>(character) penalty function.
Supported penalties are
<code>scad</code> (smoothly clipped absolute deviation),
<code>mcp</code> (minimax concave penalty),
<code>tlp</code> (truncated LASSO penalty),
<code>lasso</code> (least absolute shrinkage and selection operator),
<code>classo</code> (clipped lasso = mcp + lasso),
<code>ridge</code> (ridge),
<code>sridge</code> (sparse ridge = mcp + ridge),
<code>mbridge</code> (modified bridge) and
<code>mlog</code> (modified log).
Default is <code>scad</code>.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_x.standardize">x.standardize</code></td>
<td>
<p>(logical) whether to standardize <code>x.mat</code> prior to fitting the model (see details).
The estimated coefficients are always restored to the original scale.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_intercept">intercept</code></td>
<td>
<p>(logical) whether to include an intercept in the model.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_lambda">lambda</code></td>
<td>
<p>(numeric vector) user-specified sequence of <code>lambda</code> values.
Default is supplied automatically from samples.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_n.lambda">n.lambda</code></td>
<td>
<p>(numeric) the number of <code>lambda</code> values.
Default is 100.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_r.lambda">r.lambda</code></td>
<td>
<p>(numeric) ratio of the smallest <code>lambda</code> value to largest.
Default is 0.001 when n&gt;p, and 0.01 for other cases.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_w.lambda">w.lambda</code></td>
<td>
<p>(numeric vector) penalty weights for each coefficient (see references).
If a penalty weight is set to 0, the corresponding coefficient is always nonzero.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_gamma">gamma</code></td>
<td>
<p>(numeric) additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).
Default is half of the smallest <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_tau">tau</code></td>
<td>
<p>(numeric) concavity parameter of the penalties (see reference).
Default is 3.7 for <code>scad</code>, 2.1 for <code>mcp</code>, <code>classo</code> and <code>sridge</code>, 0.001 for <code>tlp</code>, <code>mbridge</code> and <code>mlog</code>.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) ridge effect (weight between the penalty and ridge penalty) (see details).
Default value is 1. If penalty is <code>ridge</code> and <code>sridge</code> then <code>alpha</code> is set to 0.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_aiter.max">aiter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CD algorithm.</p>
</td></tr>
<tr><td><code id="control.ncpen_+3A_b.eps">b.eps</code></td>
<td>
<p>(numeric) convergence threshold for coefficients vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is used internal purpose but useful when users want to extract proper tuning parameters for <code>ncpen</code>.
Do not supply the samples from <code>control.ncpen</code> into <code>ncpen</code> or <code>cv.ncpen</code> directly to avoid unexpected errors.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>ncpen</code>.
</p>
<table>
<tr><td><code>y.vec</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code>x.mat</code></td>
<td>
<p>design matrix adjusted to supplied options such as family and intercept.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>regression model.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>penalty.</p>
</td></tr>
<tr><td><code>x.standardize</code></td>
<td>
<p>whether to standardize <code>x.mat</code>.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>whether to include the intercept.</p>
</td></tr>
<tr><td><code>std</code></td>
<td>
<p>scale factor for <code>x.standardize</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>lambda values for the analysis.</p>
</td></tr>
<tr><td><code>n.lambda</code></td>
<td>
<p>the number of <code>lambda</code> values.</p>
</td></tr>
<tr><td><code>r.lambda</code></td>
<td>
<p>ratio of the smallest <code>lambda</code> value to largest.</p>
</td></tr>
<tr><td><code>w.lambda</code></td>
<td>
<p>penalty weights for each coefficient.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>concavity parameter of the penalties (see references).</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>ridge effect (amount of ridge penalty). see details.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties.
<em>Journal of the American statistical Association</em>, 96, 1348-60.
Zhang, C.H. (2010). Nearly unbiased variable selection under minimax concave penalty.
<em>The Annals of statistics</em>, 38(2), 894-942.
Shen, X., Pan, W., Zhu, Y. and Zhou, H. (2013). On constrained and regularized high-dimensional regression.
<em>Annals of the Institute of Statistical Mathematics</em>, 65(5), 807-832.
Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
Kwon, S. Kim, Y. and Choi, H.(2013). Sparse bridge estimation with a diverging number of parameters.
<em>Statistics and Its Interface</em>, 6, 231-242.
Huang, J., Horowitz, J.L. and Ma, S. (2008). Asymptotic properties of bridge estimators in sparse high-dimensional regression models.
<em>The Annals of Statistics</em>, 36(2), 587-613.
Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models.
<em>Annals of statistics</em>, 36(4), 1509.
Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncpen">ncpen</a></code>, <code><a href="#topic+cv.ncpen">cv.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
tun = control.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,tau=1)
tun$tau
### multinomial regression with sridge penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
tun = control.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,
                    family="multinomial",penalty="sridge",gamma=10)
### cox regression with mcp penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,r=0.2,cf.min=0.5,cf.max=1,corr=0.5,family="cox")
x.mat = sam$x.mat; y.vec = sam$y.vec
tun = control.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,family="cox",penalty="scad")
</code></pre>

<hr>
<h2 id='cv.ncpen'>cv.ncpen: cross validation for <code>ncpen</code></h2><span id='topic+cv.ncpen'></span>

<h3>Description</h3>

<p>performs k-fold cross-validation (CV) for nonconvex penalized regression models
over a sequence of the regularization parameter <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.ncpen(y.vec, x.mat, family = c("gaussian", "linear", "binomial",
  "logit", "poisson", "multinomial", "cox"), penalty = c("scad", "mcp",
  "tlp", "lasso", "classo", "ridge", "sridge", "mbridge", "mlog"),
  x.standardize = TRUE, intercept = TRUE, lambda = NULL,
  n.lambda = NULL, r.lambda = NULL, w.lambda = NULL, gamma = NULL,
  tau = NULL, alpha = NULL, df.max = 50, cf.max = 100,
  proj.min = 10, add.max = 10, niter.max = 30, qiter.max = 10,
  aiter.max = 100, b.eps = 1e-06, k.eps = 1e-04, c.eps = 1e-06,
  cut = TRUE, local = FALSE, local.initial = NULL, n.fold = 10,
  fold.id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.ncpen_+3A_y.vec">y.vec</code></td>
<td>
<p>(numeric vector) response vector.
Must be 0,1 for <code>binomial</code> and 1,2,..., for <code>multinomial</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_x.mat">x.mat</code></td>
<td>
<p>(numeric matrix) design matrix without intercept.
The censoring indicator must be included at the last column of the design matrix for <code>cox</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_family">family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code> (or <code>linear</code>),
<code>binomial</code> (or <code>logit</code>),
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>.
Default is <code>gaussian</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_penalty">penalty</code></td>
<td>
<p>(character) penalty function.
Supported penalties are
<code>scad</code> (smoothly clipped absolute deviation),
<code>mcp</code> (minimax concave penalty),
<code>tlp</code> (truncated LASSO penalty),
<code>lasso</code> (least absolute shrinkage and selection operator),
<code>classo</code> (clipped lasso = mcp + lasso),
<code>ridge</code> (ridge),
<code>sridge</code> (sparse ridge = mcp + ridge),
<code>mbridge</code> (modified bridge) and
<code>mlog</code> (modified log).
Default is <code>scad</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_x.standardize">x.standardize</code></td>
<td>
<p>(logical) whether to standardize <code>x.mat</code> prior to fitting the model (see details).
The estimated coefficients are always restored to the original scale.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_intercept">intercept</code></td>
<td>
<p>(logical) whether to include an intercept in the model.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_lambda">lambda</code></td>
<td>
<p>(numeric vector) user-specified sequence of <code>lambda</code> values.
Default is supplied automatically from samples.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_n.lambda">n.lambda</code></td>
<td>
<p>(numeric) the number of <code>lambda</code> values.
Default is 100.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_r.lambda">r.lambda</code></td>
<td>
<p>(numeric) ratio of the smallest <code>lambda</code> value to largest.
Default is 0.001 when n&gt;p, and 0.01 for other cases.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_w.lambda">w.lambda</code></td>
<td>
<p>(numeric vector) penalty weights for each coefficient (see references).
If a penalty weight is set to 0, the corresponding coefficient is always nonzero.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_gamma">gamma</code></td>
<td>
<p>(numeric) additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).
Default is half of the smallest <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_tau">tau</code></td>
<td>
<p>(numeric) concavity parameter of the penalties (see reference).
Default is 3.7 for <code>scad</code>, 2.1 for <code>mcp</code>, <code>classo</code> and <code>sridge</code>, 0.001 for <code>tlp</code>, <code>mbridge</code> and <code>mlog</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) ridge effect (weight between the penalty and ridge penalty) (see details).
Default value is 1. If penalty is <code>ridge</code> and <code>sridge</code> then <code>alpha</code> is set to 0.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_df.max">df.max</code></td>
<td>
<p>(numeric) the maximum number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_cf.max">cf.max</code></td>
<td>
<p>(numeric) the maximum of absolute value of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_proj.min">proj.min</code></td>
<td>
<p>(numeric) the projection cycle inside CD algorithm (largely internal use. See details).</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_add.max">add.max</code></td>
<td>
<p>(numeric) the maximum number of variables added in CCCP iterations (largely internal use. See references).</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_niter.max">niter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CCCP.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_qiter.max">qiter.max</code></td>
<td>
<p>(numeric) maximum number of quadratic approximations in each CCCP iteration.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_aiter.max">aiter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CD algorithm.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_b.eps">b.eps</code></td>
<td>
<p>(numeric) convergence threshold for coefficients vector.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_k.eps">k.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_c.eps">c.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions (largely internal use).</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_cut">cut</code></td>
<td>
<p>(logical) convergence threshold for KKT conditions  (largely internal use).</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_local">local</code></td>
<td>
<p>(logical) whether to use local initial estimator for path construction. It may take a long time.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_local.initial">local.initial</code></td>
<td>
<p>(numeric vector) initial estimator for <code>local=TRUE</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_n.fold">n.fold</code></td>
<td>
<p>(numeric) number of folds for CV.</p>
</td></tr>
<tr><td><code id="cv.ncpen_+3A_fold.id">fold.id</code></td>
<td>
<p>(numeric vector) fold ids from 1 to k that indicate fold configuration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two kinds of CV errors are returned: root mean squared error and negative log likelihood.
The results depends on the random partition made internally.
To choose an optimal coefficients form the cv results, use <code><a href="#topic+coef.cv.ncpen">coef.cv.ncpen</a></code>.
<code>ncpen</code> does not search values of <code>gamma</code>, <code>tau</code> and <code>alpha</code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>cv.ncpen</code>.
</p>
<table>
<tr><td><code>ncpen.fit</code></td>
<td>
<p>ncpen object fitted from the whole samples.</p>
</td></tr>
<tr><td><code>fold.index</code></td>
<td>
<p>fold ids of the samples.</p>
</td></tr>
<tr><td><code>rmse</code></td>
<td>
<p>rood mean squared errors from CV.</p>
</td></tr>
<tr><td><code>like</code></td>
<td>
<p>negative log-likelihoods from CV.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>sequence of <code>lambda</code> used for CV.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties.
<em>Journal of the American statistical Association</em>, 96, 1348-60.
Zhang, C.H. (2010). Nearly unbiased variable selection under minimax concave penalty.
<em>The Annals of statistics</em>, 38(2), 894-942.
Shen, X., Pan, W., Zhu, Y. and Zhou, H. (2013). On constrained and regularized high-dimensional regression.
<em>Annals of the Institute of Statistical Mathematics</em>, 65(5), 807-832.
Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
Kwon, S. Kim, Y. and Choi, H.(2013). Sparse bridge estimation with a diverging number of parameters.
<em>Statistics and Its Interface</em>, 6, 231-242.
Huang, J., Horowitz, J.L. and Ma, S. (2008). Asymptotic properties of bridge estimators in sparse high-dimensional regression models.
<em>The Annals of Statistics</em>, 36(2), 587-613.
Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models.
<em>Annals of statistics</em>, 36(4), 1509.
Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.cv.ncpen">plot.cv.ncpen</a></code>, <code><a href="#topic+coef.cv.ncpen">coef.cv.ncpen</a></code>, <code><a href="#topic+ncpen">ncpen</a></code>, <code><a href="#topic+predict.ncpen">predict.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="gaussian")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = cv.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,family="gaussian", penalty="scad")
coef(fit)

</code></pre>

<hr>
<h2 id='cv.ncpen.reg'>cv.ncpen: cross validation for <code>ncpen</code></h2><span id='topic+cv.ncpen.reg'></span>

<h3>Description</h3>

<p>performs k-fold cross-validation (CV) for nonconvex penalized regression models
over a sequence of the regularization parameter <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.ncpen.reg(formula, data, family = c("gaussian", "linear", "binomial",
  "logit", "multinomial", "cox", "poisson"), penalty = c("scad", "mcp",
  "tlp", "lasso", "classo", "ridge", "sridge", "mbridge", "mlog"),
  x.standardize = TRUE, intercept = TRUE, lambda = NULL,
  n.lambda = NULL, r.lambda = NULL, w.lambda = NULL, gamma = NULL,
  tau = NULL, alpha = NULL, df.max = 50, cf.max = 100,
  proj.min = 10, add.max = 10, niter.max = 30, qiter.max = 10,
  aiter.max = 100, b.eps = 1e-06, k.eps = 1e-04, c.eps = 1e-06,
  cut = TRUE, local = FALSE, local.initial = NULL, n.fold = 10,
  fold.id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.ncpen.reg_+3A_formula">formula</code></td>
<td>
<p>(formula) regression formula. To include/exclude intercept, use <code>intercept</code> option
instead of using the &quot;0 +&quot; option in the formula.
The y value must be 0,1 for <code>binomial</code> and 1,2,..., for <code>multinomial</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_data">data</code></td>
<td>
<p>(numeric matrix or data.frame) contains both y and X. Each row is an observation vector.
The censoring indicator must be included at the last column of the data for <code>cox</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_family">family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code> (or <code>linear</code>),
<code>binomial</code> (or <code>logit</code>),
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>.
Default is <code>gaussian</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_penalty">penalty</code></td>
<td>
<p>(character) penalty function.
Supported penalties are
<code>scad</code> (smoothly clipped absolute deviation),
<code>mcp</code> (minimax concave penalty),
<code>tlp</code> (truncated LASSO penalty),
<code>lasso</code> (least absolute shrinkage and selection operator),
<code>classo</code> (clipped lasso = mcp + lasso),
<code>ridge</code> (ridge),
<code>sridge</code> (sparse ridge = mcp + ridge),
<code>mbridge</code> (modified bridge) and
<code>mlog</code> (modified log).
Default is <code>scad</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_x.standardize">x.standardize</code></td>
<td>
<p>(logical) whether to standardize <code>x.mat</code> prior to fitting the model (see details).
The estimated coefficients are always restored to the original scale.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_intercept">intercept</code></td>
<td>
<p>(logical) whether to include an intercept in the model.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_lambda">lambda</code></td>
<td>
<p>(numeric vector) user-specified sequence of <code>lambda</code> values.
Default is supplied automatically from samples.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_n.lambda">n.lambda</code></td>
<td>
<p>(numeric) the number of <code>lambda</code> values.
Default is 100.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_r.lambda">r.lambda</code></td>
<td>
<p>(numeric) ratio of the smallest <code>lambda</code> value to largest.
Default is 0.001 when n&gt;p, and 0.01 for other cases.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_w.lambda">w.lambda</code></td>
<td>
<p>(numeric vector) penalty weights for each coefficient (see references).
If a penalty weight is set to 0, the corresponding coefficient is always nonzero.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_gamma">gamma</code></td>
<td>
<p>(numeric) additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).
Default is half of the smallest <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_tau">tau</code></td>
<td>
<p>(numeric) concavity parameter of the penalties (see reference).
Default is 3.7 for <code>scad</code>, 2.1 for <code>mcp</code>, <code>classo</code> and <code>sridge</code>, 0.001 for <code>tlp</code>, <code>mbridge</code> and <code>mlog</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) ridge effect (weight between the penalty and ridge penalty) (see details).
Default value is 1. If penalty is <code>ridge</code> and <code>sridge</code> then <code>alpha</code> is set to 0.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_df.max">df.max</code></td>
<td>
<p>(numeric) the maximum number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_cf.max">cf.max</code></td>
<td>
<p>(numeric) the maximum of absolute value of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_proj.min">proj.min</code></td>
<td>
<p>(numeric) the projection cycle inside CD algorithm (largely internal use. See details).</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_add.max">add.max</code></td>
<td>
<p>(numeric) the maximum number of variables added in CCCP iterations (largely internal use. See references).</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_niter.max">niter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CCCP.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_qiter.max">qiter.max</code></td>
<td>
<p>(numeric) maximum number of quadratic approximations in each CCCP iteration.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_aiter.max">aiter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CD algorithm.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_b.eps">b.eps</code></td>
<td>
<p>(numeric) convergence threshold for coefficients vector.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_k.eps">k.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_c.eps">c.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions (largely internal use).</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_cut">cut</code></td>
<td>
<p>(logical) convergence threshold for KKT conditions  (largely internal use).</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_local">local</code></td>
<td>
<p>(logical) whether to use local initial estimator for path construction. It may take a long time.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_local.initial">local.initial</code></td>
<td>
<p>(numeric vector) initial estimator for <code>local=TRUE</code>.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_n.fold">n.fold</code></td>
<td>
<p>(numeric) number of folds for CV.</p>
</td></tr>
<tr><td><code id="cv.ncpen.reg_+3A_fold.id">fold.id</code></td>
<td>
<p>(numeric vector) fold ids from 1 to k that indicate fold configuration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two kinds of CV errors are returned: root mean squared error and negative log likelihood.
The results depends on the random partition made internally.
To choose an optimal coefficients form the cv results, use <code><a href="#topic+coef.cv.ncpen">coef.cv.ncpen</a></code>.
<code>ncpen</code> does not search values of <code>gamma</code>, <code>tau</code> and <code>alpha</code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>cv.ncpen</code>.
</p>
<table>
<tr><td><code>ncpen.fit</code></td>
<td>
<p>ncpen object fitted from the whole samples.</p>
</td></tr>
<tr><td><code>fold.index</code></td>
<td>
<p>fold ids of the samples.</p>
</td></tr>
<tr><td><code>rmse</code></td>
<td>
<p>rood mean squared errors from CV.</p>
</td></tr>
<tr><td><code>like</code></td>
<td>
<p>negative log-likelihoods from CV.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>sequence of <code>lambda</code> used for CV.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties.
<em>Journal of the American statistical Association</em>, 96, 1348-60.
Zhang, C.H. (2010). Nearly unbiased variable selection under minimax concave penalty.
<em>The Annals of statistics</em>, 38(2), 894-942.
Shen, X., Pan, W., Zhu, Y. and Zhou, H. (2013). On constrained and regularized high-dimensional regression.
<em>Annals of the Institute of Statistical Mathematics</em>, 65(5), 807-832.
Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
Kwon, S. Kim, Y. and Choi, H.(2013). Sparse bridge estimation with a diverging number of parameters.
<em>Statistics and Its Interface</em>, 6, 231-242.
Huang, J., Horowitz, J.L. and Ma, S. (2008). Asymptotic properties of bridge estimators in sparse high-dimensional regression models.
<em>The Annals of Statistics</em>, 36(2), 587-613.
Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models.
<em>Annals of statistics</em>, 36(4), 1509.
Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.cv.ncpen">plot.cv.ncpen</a></code>, <code><a href="#topic+coef.cv.ncpen">coef.cv.ncpen</a></code>, <code><a href="#topic+ncpen">ncpen</a></code>, <code><a href="#topic+predict.ncpen">predict.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=5,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="gaussian")
x.mat = sam$x.mat; y.vec = sam$y.vec
data = cbind(y.vec, x.mat)
colnames(data) = c("y", paste("xv", 1:ncol(x.mat), sep = ""))
fit1 = cv.ncpen.reg(formula = y ~ xv1 + xv2 + xv3 + xv4 + xv5, data = data, n.lambda=10,
                    family="gaussian", penalty="scad")
fit2 = cv.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=10,family="gaussian", penalty="scad")
coef(fit1)

</code></pre>

<hr>
<h2 id='excluded'>Check whether a pair should be excluded from interactions.</h2><span id='topic+excluded'></span>

<h3>Description</h3>

<p>This is internal use only function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>excluded(excluded.pair, a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="excluded_+3A_excluded.pair">excluded.pair</code></td>
<td>
<p>a pair.</p>
</td></tr>
<tr><td><code id="excluded_+3A_a">a</code></td>
<td>
<p>first column to be compared.</p>
</td></tr>
<tr><td><code id="excluded_+3A_b">b</code></td>
<td>
<p>second column to be compared.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if excluded, FALSE otherwise.
</p>

<hr>
<h2 id='fold.cv.ncpen'>fold.cv.ncpen: extracts fold ids for <code>cv.ncpen</code>.</h2><span id='topic+fold.cv.ncpen'></span>

<h3>Description</h3>

<p>The function returns fold configuration of the samples for CV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fold.cv.ncpen(c.vec, n.fold = 10, family = c("gaussian", "binomial",
  "multinomial", "cox", "poisson"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fold.cv.ncpen_+3A_c.vec">c.vec</code></td>
<td>
<p>(numeric vector) vector for construction of CV ids:
censoring indicator for <code>cox</code> and response vector for the others.</p>
</td></tr>
<tr><td><code id="fold.cv.ncpen_+3A_n.fold">n.fold</code></td>
<td>
<p>(numeric) number of folds for CV.</p>
</td></tr>
<tr><td><code id="fold.cv.ncpen_+3A_family">family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code>,
<code>binomial</code>,
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>.
Default is <code>gaussian</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fold ids of the samples.
</p>
<table>
<tr><td><code>idx</code></td>
<td>
<p>fold ids.</p>
</td></tr>
<tr><td><code>n.fold</code></td>
<td>
<p>the number of folds.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.ncpen">cv.ncpen</a></code>, <code><a href="#topic+plot.cv.ncpen">plot.cv.ncpen</a></code> , <code><a href="#topic+gic.ncpen">gic.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
fold.id = fold.cv.ncpen(c.vec=y.vec,n.fold=10)
### logistic regression with classo penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="binomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fold.id = fold.cv.ncpen(c.vec=y.vec,n.fold=10,family="binomial")
### poison regression with mlog penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="poisson")
x.mat = sam$x.mat; y.vec = sam$y.vec
fold.id = fold.cv.ncpen(c.vec=y.vec,n.fold=10,family="poisson")
### multinomial regression with sridge penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fold.id = fold.cv.ncpen(c.vec=y.vec,n.fold=10,family="multinomial")
### cox regression with mcp penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,r=0.2,cf.min=0.5,cf.max=1,corr=0.5,family="cox")
x.mat = sam$x.mat; y.vec = sam$y.vec
fold.id = fold.cv.ncpen(c.vec=x.mat[,21],n.fold=10,family="cox")
</code></pre>

<hr>
<h2 id='gic.ncpen'>gic.ncpen: compute the generalized information criterion (GIC) for the selection of lambda</h2><span id='topic+gic.ncpen'></span>

<h3>Description</h3>

<p>The function provides the selection of the regularization parameter lambda based
on the GIC including AIC and BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gic.ncpen(fit, weight = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gic.ncpen_+3A_fit">fit</code></td>
<td>
<p>(ncpen object) fitted <code>ncpen</code> object.</p>
</td></tr>
<tr><td><code id="gic.ncpen_+3A_weight">weight</code></td>
<td>
<p>(numeric) the weight factor for various information criteria.
Default is BIC if <code>n&gt;p</code> and GIC if <code>n&lt;p</code> (see details).</p>
</td></tr>
<tr><td><code id="gic.ncpen_+3A_verbose">verbose</code></td>
<td>
<p>(logical) whether to plot the GIC curve.</p>
</td></tr>
<tr><td><code id="gic.ncpen_+3A_...">...</code></td>
<td>
<p>other graphical parameters to <code><a href="graphics.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>User can supply various <code>weight</code> values (see references). For example,
<code>weight=2</code>,
<code>weight=log(n)</code>,
<code>weight=log(log(p))log(n)</code>,
<code>weight=log(log(n))log(p)</code>,
corresponds to AIC, BIC (fixed dimensional model), modified BIC (diverging dimensional model) and GIC (high dimensional model).
</p>


<h3>Value</h3>

<p>The coefficients <code><a href="base.html#topic+matrix">matrix</a></code>.
</p>
<table>
<tr><td><code>gic</code></td>
<td>
<p>the GIC values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the sequence of lambda values used to calculate GIC.</p>
</td></tr>
<tr><td><code>opt.beta</code></td>
<td>
<p>the optimal coefficients selected by GIC.</p>
</td></tr>
<tr><td><code>opt.lambda</code></td>
<td>
<p>the optimal lambda value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Wang, H., Li, R. and Tsai, C.L. (2007). Tuning parameter selectors for the smoothly clipped absolute deviation method.
<em>Biometrika</em>, 94(3), 553-568.
Wang, H., Li, B. and Leng, C. (2009). Shrinkage tuning parameter selection with a diverging number of parameters.
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 71(3), 671-683.
Kim, Y., Kwon, S. and Choi, H. (2012). Consistent Model Selection Criteria on High Dimensions.
<em>Journal of Machine Learning Research</em>, 13, 1037-1057.
Fan, Y. and Tang, C.Y. (2013). Tuning parameter selection in high dimensional penalized likelihood.
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 75(3), 531-552.
Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncpen">ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat)
gic.ncpen(fit,pch="*",type="b")
### multinomial regression with classo penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat,family="multinomial",penalty="classo")
gic.ncpen(fit,pch="*",type="b")
</code></pre>

<hr>
<h2 id='interact.data'>Construct Interaction Matrix</h2><span id='topic+interact.data'></span>

<h3>Description</h3>

<p><code>interact.data</code> interacts all the data in a <code><a href="base.html#topic+data.frame">data.frame</a></code> or <code><a href="base.html#topic+matrix">matrix</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interact.data(data, base.cols = NULL, exclude.pair = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interact.data_+3A_data">data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> or <code><a href="base.html#topic+matrix">matrix</a></code> to interact.</p>
</td></tr>
<tr><td><code id="interact.data_+3A_base.cols">base.cols</code></td>
<td>
<p>indicates columns from one category.
Interactions among variables from a same base.col will be avoided. For example, if three indicator columns,
&quot;ChannelR&quot;, &quot;ChannelC&quot; and &quot;ChannelB&quot;, are created from a categorical column &quot;Channel&quot;, then the interaction among them
can be excluded by assigning <code>base.cols=c("Channel")</code>. Multiple <code>base.cols</code> are possible.</p>
</td></tr>
<tr><td><code id="interact.data_+3A_exclude.pair">exclude.pair</code></td>
<td>
<p>the pairs will be excluded from interactions. This should be a <code><a href="base.html#topic+list">list</a></code> object of pairs.
For example, <code>list(c("a1", "a2"), c("d1", "d2"))</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This returns an object of <code><a href="base.html#topic+matrix">matrix</a></code> which contains interactions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = data.frame(1:3, 4:6, 7:9, 10:12, 13:15);
colnames(df) = c("aa", "bb", "cc", "dd", "aa2");
df

interact.data(df);
interact.data(df, base.cols = "aa");
interact.data(df, base.cols = "aa", exclude.pair = list(c("bb", "cc")));



</code></pre>

<hr>
<h2 id='make.ncpen.data'>Create ncpen Data Structure Using a Formula</h2><span id='topic+make.ncpen.data'></span>

<h3>Description</h3>

<p>This function creates ncpen y <code>vector</code> and x <code>matrix</code> from data using formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.ncpen.data(formula, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.ncpen.data_+3A_formula">formula</code></td>
<td>
<p>(formula) regression formula. Intercept will not be created.</p>
</td></tr>
<tr><td><code id="make.ncpen.data_+3A_data">data</code></td>
<td>
<p>(numeric matrix or data.frame) contains both y and X.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of y vector and x matrix.
</p>
<table>
<tr><td><code>y.vec</code></td>
<td>
<p>y <code>vector</code></p>
</td></tr>
<tr><td><code>x.mat</code></td>
<td>
<p>x <code>matrix</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = data.frame(y = 1:5, x1 = 6:10, x2 = 11:15);
formula = log(y) ~ log(x1) + x2;
make.ncpen.data(formula, data);

</code></pre>

<hr>
<h2 id='native_cpp_ncpen_fun_'>Native ncpen function.</h2><span id='topic+native_cpp_ncpen_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_ncpen_fun_(y_vec, x_mat0, w_vec0, lam_vec0, gam, tau, alp,
  d_max, iter_max, qiter_max, qiiter_max, b_eps, k_eps, p_eff, cut, c_eps,
  add, family, penalty, loc, ob_vec, div)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_ncpen_fun__+3A_y_vec">y_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_x_mat0">x_mat0</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_w_vec0">w_vec0</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_lam_vec0">lam_vec0</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_gam">gam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_tau">tau</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_alp">alp</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_d_max">d_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_iter_max">iter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_qiter_max">qiter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_qiiter_max">qiiter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_b_eps">b_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_k_eps">k_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_p_eff">p_eff</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_cut">cut</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_c_eps">c_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_add">add</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_family">family</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_penalty">penalty</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_loc">loc</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_ob_vec">ob_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_ncpen_fun__+3A_div">div</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_nr_fun_'>N/A.</h2><span id='topic+native_cpp_nr_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_nr_fun_(fam, y_vec, x_mat, iter_max, b_eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_nr_fun__+3A_fam">fam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_nr_fun__+3A_y_vec">y_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_nr_fun__+3A_x_mat">x_mat</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_nr_fun__+3A_iter_max">iter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_nr_fun__+3A_b_eps">b_eps</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_obj_fun_'>Native object function.</h2><span id='topic+native_cpp_obj_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_obj_fun_(name, y_vec, x_mat, b_vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_obj_fun__+3A_name">name</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_fun__+3A_y_vec">y_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_fun__+3A_x_mat">x_mat</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_fun__+3A_b_vec">b_vec</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_obj_grad_fun_'>Native object gradient function.</h2><span id='topic+native_cpp_obj_grad_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_obj_grad_fun_(name, y_vec, x_mat, b_vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_obj_grad_fun__+3A_name">name</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_grad_fun__+3A_y_vec">y_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_grad_fun__+3A_x_mat">x_mat</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_grad_fun__+3A_b_vec">b_vec</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_obj_hess_fun_'>Native object Hessian function.</h2><span id='topic+native_cpp_obj_hess_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_obj_hess_fun_(name, y_vec, x_mat, b_vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_obj_hess_fun__+3A_name">name</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_hess_fun__+3A_y_vec">y_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_hess_fun__+3A_x_mat">x_mat</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_obj_hess_fun__+3A_b_vec">b_vec</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_p_ncpen_fun_'>Native point ncpen function.</h2><span id='topic+native_cpp_p_ncpen_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_p_ncpen_fun_(y_vec, x_mat, b_vec, w_vec, lam, gam, tau, alp,
  iter_max, qiter_max, qiiter_max, b_eps, k_eps, p_eff, cut, c_eps, family,
  penalty)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_y_vec">y_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_x_mat">x_mat</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_b_vec">b_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_w_vec">w_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_lam">lam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_gam">gam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_tau">tau</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_alp">alp</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_iter_max">iter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_qiter_max">qiter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_qiiter_max">qiiter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_b_eps">b_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_k_eps">k_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_p_eff">p_eff</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_cut">cut</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_c_eps">c_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_family">family</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_p_ncpen_fun__+3A_penalty">penalty</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_pen_fun_'>Native Penalty function.</h2><span id='topic+native_cpp_pen_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_pen_fun_(name, b_vec, lam, gam, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_pen_fun__+3A_name">name</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_fun__+3A_b_vec">b_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_fun__+3A_lam">lam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_fun__+3A_gam">gam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_fun__+3A_tau">tau</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_pen_grad_fun_'>Native Penalty Gradient function.</h2><span id='topic+native_cpp_pen_grad_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_pen_grad_fun_(name, b_vec, lam, gam, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_pen_grad_fun__+3A_name">name</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_grad_fun__+3A_b_vec">b_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_grad_fun__+3A_lam">lam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_grad_fun__+3A_gam">gam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_pen_grad_fun__+3A_tau">tau</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_qlasso_fun_'>Native QLASSO function.</h2><span id='topic+native_cpp_qlasso_fun_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_qlasso_fun_(q_mat, l_vec, b_vec0, w_vec, lam, iter_max,
  iiter_max, b_eps, k_eps, p_eff, q_rank, cut, c_eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_qlasso_fun__+3A_q_mat">q_mat</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_l_vec">l_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_b_vec0">b_vec0</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_w_vec">w_vec</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_lam">lam</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_iter_max">iter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_iiter_max">iiter_max</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_b_eps">b_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_k_eps">k_eps</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_p_eff">p_eff</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_q_rank">q_rank</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_cut">cut</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="native_cpp_qlasso_fun__+3A_c_eps">c_eps</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='native_cpp_set_dev_mode_'>N/A.</h2><span id='topic+native_cpp_set_dev_mode_'></span>

<h3>Description</h3>

<p>This is internal use only function. Manual left blank on purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>native_cpp_set_dev_mode_(dev_mode)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="native_cpp_set_dev_mode__+3A_dev_mode">dev_mode</code></td>
<td>
<p>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.
</p>

<hr>
<h2 id='ncpen'>ncpen: nonconvex penalized estimation</h2><span id='topic+ncpen'></span>

<h3>Description</h3>

<p>Fits generalized linear models by penalized maximum likelihood estimation.
The coefficients path is computed for the regression model over a grid of the regularization parameter <code>lambda</code>.
Fits Gaussian (linear), binomial Logit (logistic), Poisson, multinomial Logit regression models, and
Cox proportional hazard model with various non-convex penalties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncpen(y.vec, x.mat, family = c("gaussian", "linear", "binomial", "logit",
  "poisson", "multinomial", "cox"), penalty = c("scad", "mcp", "tlp",
  "lasso", "classo", "ridge", "sridge", "mbridge", "mlog"),
  x.standardize = TRUE, intercept = TRUE, lambda = NULL,
  n.lambda = NULL, r.lambda = NULL, w.lambda = NULL, gamma = NULL,
  tau = NULL, alpha = NULL, df.max = 50, cf.max = 100,
  proj.min = 10, add.max = 10, niter.max = 30, qiter.max = 10,
  aiter.max = 100, b.eps = 1e-07, k.eps = 1e-04, c.eps = 1e-06,
  cut = TRUE, local = FALSE, local.initial = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ncpen_+3A_y.vec">y.vec</code></td>
<td>
<p>(numeric vector) response vector.
Must be 0,1 for <code>binomial</code> and 1,2,..., for <code>multinomial</code>.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_x.mat">x.mat</code></td>
<td>
<p>(numeric matrix) design matrix without intercept.
The censoring indicator must be included at the last column of the design matrix for <code>cox</code>.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_family">family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code> (or <code>linear</code>),
<code>binomial</code> (or <code>logit</code>),
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>,
Default is <code>gaussian</code>.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_penalty">penalty</code></td>
<td>
<p>(character) penalty function.
Supported penalties are
<code>scad</code> (smoothly clipped absolute deviation),
<code>mcp</code> (minimax concave penalty),
<code>tlp</code> (truncated lasso penalty),
<code>lasso</code> (least absolute shrinkage and selection operator),
<code>classo</code> (clipped lasso = mcp + lasso),
<code>ridge</code> (ridge),
<code>sridge</code> (sparse ridge = mcp + ridge),
<code>mbridge</code> (modified bridge) and
<code>mlog</code> (modified log).
Default is <code>scad</code>.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_x.standardize">x.standardize</code></td>
<td>
<p>(logical) whether to standardize <code>x.mat</code> prior to fitting the model (see details).
The estimated coefficients are always restored to the original scale.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_intercept">intercept</code></td>
<td>
<p>(logical) whether to include an intercept in the model.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_lambda">lambda</code></td>
<td>
<p>(numeric vector) user-specified sequence of <code>lambda</code> values.
Default is supplied automatically from samples.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_n.lambda">n.lambda</code></td>
<td>
<p>(numeric) the number of <code>lambda</code> values.
Default is 100.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_r.lambda">r.lambda</code></td>
<td>
<p>(numeric) ratio of the smallest <code>lambda</code> value to largest.
Default is 0.001 when n&gt;p, and 0.01 for other cases.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_w.lambda">w.lambda</code></td>
<td>
<p>(numeric vector) penalty weights for each coefficient (see references).
If a penalty weight is set to 0, the corresponding coefficient is always nonzero.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_gamma">gamma</code></td>
<td>
<p>(numeric) additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).
Default is half of the smallest <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_tau">tau</code></td>
<td>
<p>(numeric) concavity parameter of the penalties (see reference).
Default is 3.7 for <code>scad</code>, 2.1 for <code>mcp</code>, <code>classo</code> and <code>sridge</code>, 0.001 for <code>tlp</code>, <code>mbridge</code> and <code>mlog</code>.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) ridge effect (weight between the penalty and ridge penalty) (see details).
Default value is 1. If penalty is <code>ridge</code> and <code>sridge</code> then <code>alpha</code> is set to 0.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_df.max">df.max</code></td>
<td>
<p>(numeric) the maximum number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_cf.max">cf.max</code></td>
<td>
<p>(numeric) the maximum of absolute value of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_proj.min">proj.min</code></td>
<td>
<p>(numeric) the projection cycle inside CD algorithm (largely internal use. See details).</p>
</td></tr>
<tr><td><code id="ncpen_+3A_add.max">add.max</code></td>
<td>
<p>(numeric) the maximum number of variables added in CCCP iterations (largely internal use. See references).</p>
</td></tr>
<tr><td><code id="ncpen_+3A_niter.max">niter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CCCP.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_qiter.max">qiter.max</code></td>
<td>
<p>(numeric) maximum number of quadratic approximations in each CCCP iteration.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_aiter.max">aiter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CD algorithm.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_b.eps">b.eps</code></td>
<td>
<p>(numeric) convergence threshold for coefficients vector in CD algorithm</p>
</td></tr>
<tr><td><code id="ncpen_+3A_k.eps">k.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_c.eps">c.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions (largely internal use).</p>
</td></tr>
<tr><td><code id="ncpen_+3A_cut">cut</code></td>
<td>
<p>(logical) convergence threshold for KKT conditions  (largely internal use).</p>
</td></tr>
<tr><td><code id="ncpen_+3A_local">local</code></td>
<td>
<p>(logical) whether to use local initial estimator for path construction. It may take a long time.</p>
</td></tr>
<tr><td><code id="ncpen_+3A_local.initial">local.initial</code></td>
<td>
<p>(numeric vector) initial estimator for <code>local=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by <code>lambda</code> is fit
by using concave convex procedure (CCCP) and coordinate descent (CD) algorithm (see references).
The objective function is </p>
<p style="text-align: center;"><code class="reqn"> (sum of squared residuals)/2n + [alpha*penalty + (1-alpha)*ridge] </code>
</p>
<p> for <code>gaussian</code>
and </p>
<p style="text-align: center;"><code class="reqn"> (log-likelihood)/n - [alpha*penalty + (1-alpha)*ridge] </code>
</p>
<p> for the others,
assuming the canonical link.
The algorithm applies the warm start strategy (see references) and tries projections
after <code>proj.min</code> iterations in CD algorithm, which makes the algorithm fast and stable.
<code>x.standardize</code> makes each column of <code>x.mat</code> to have the same Euclidean length
but the coefficients will be re-scaled into the original.
In <code>multinomial</code> case, the coefficients are expressed in vector form. Use <code><a href="#topic+coef.ncpen">coef.ncpen</a></code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>ncpen</code>.
</p>
<table>
<tr><td><code>y.vec</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code>x.mat</code></td>
<td>
<p>design matrix.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>regression model.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>penalty.</p>
</td></tr>
<tr><td><code>x.standardize</code></td>
<td>
<p>whether to standardize <code>x.mat=TRUE</code>.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>whether to include the intercept.</p>
</td></tr>
<tr><td><code>std</code></td>
<td>
<p>scale factor for <code>x.standardize</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>sequence of <code>lambda</code> values.</p>
</td></tr>
<tr><td><code>w.lambda</code></td>
<td>
<p>penalty weights.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>extra shrinkage parameter for <code>classo</code> and sridge only.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>ridge effect.</p>
</td></tr>
<tr><td><code>local</code></td>
<td>
<p>whether to use local initial estimator.</p>
</td></tr>
<tr><td><code>local.initial</code></td>
<td>
<p>local initial estimator for <code>local=TRUE</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>fitted coefficients. Use <code>coef.ncpen</code> for <code>multinomial</code> since the coefficients are represented as vectors.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the number of non-zero coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Kim, D., Lee, S. and Kwon, S. (2018). A unified algorithm for the non-convex penalized estimation: The <code>ncpen</code> package.
<em>http://arxiv.org/abs/1811.05061</em>.
</p>
<p>Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties.
<em>Journal of the American statistical Association</em>, 96, 1348-60.
</p>
<p>Zhang, C.H. (2010). Nearly unbiased variable selection under minimax concave penalty.
<em>The Annals of statistics</em>, 38(2), 894-942.
</p>
<p>Shen, X., Pan, W., Zhu, Y. and Zhou, H. (2013). On constrained and regularized high-dimensional regression.
<em>Annals of the Institute of Statistical Mathematics</em>, 65(5), 807-832.
</p>
<p>Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
</p>
<p>Kwon, S. Kim, Y. and Choi, H.(2013). Sparse bridge estimation with a diverging number of parameters.
<em>Statistics and Its Interface</em>, 6, 231-242.
</p>
<p>Huang, J., Horowitz, J.L. and Ma, S. (2008). Asymptotic properties of bridge estimators in sparse high-dimensional regression models.
<em>The Annals of Statistics</em>, 36(2), 587-613.
</p>
<p>Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models.
<em>Annals of statistics</em>, 36(4), 1509.
</p>
<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.ncpen">coef.ncpen</a></code>, <code><a href="#topic+plot.ncpen">plot.ncpen</a></code>, <code><a href="#topic+gic.ncpen">gic.ncpen</a></code>, <code><a href="#topic+predict.ncpen">predict.ncpen</a></code>, <code><a href="#topic+cv.ncpen">cv.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="gaussian")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat,family="gaussian", penalty="scad")

</code></pre>

<hr>
<h2 id='ncpen-package'>ncpen: A package for non-convex penalized estimation for generalized linear models</h2><span id='topic+ncpen-package'></span>

<h3>Description</h3>

<p>This package fits the generalized linear models with various non-convex penalties.
Supported regression models are Gaussian (linear), binomial Logit (logistic), multinomial Logit,
Poisson and Cox proportional hazard.
A unified algorithm is implemented in <b>ncpen</b> based on the convex concave procedure
or difference convex algorithm that can be applied to most of existing non-convex penalties.
The available penalties in the package are
the least absolute shrinkage and selection operator(LASSO),
smoothly clipped absolute deviation (SCAD),
minimax concave penalty (MCP),
truncated <code class="reqn">\ell_1</code>-penalty (TLP),
clipped LASSO (CLASSO),
sparse bridge (SRIDGE),
modified bridge (MBRIDGE),
and modified log (MLOG) penalties.
</p>


<h3>Details</h3>

<p>The package accepts a design matrix <code class="reqn">X</code> and vector of responses <code class="reqn">y</code>,
and produces the regularization path over a grid of values for the tuning parameter <code>lambda</code>.
Also provides user-friendly processes for plotting, selecting tuning parameters using cross-validation or generalized information criterion (GIC),
<code class="reqn">\ell_2</code>-regularization, penalty weights, standardization and intercept.
</p>


<h3>Note</h3>

<p>This research is funded by Julian Virtue Professorship from Center for Applied Research at Pepperdine
Graziadio Business School and the National Research Foundation of Korea.
</p>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon and Sangin Lee
</p>


<h3>References</h3>

<p>Kim, D., Lee, S. and Kwon, S. (2018). A unified algorithm for the non-convex penalized estimation: The <code>ncpen</code> package.
<em>http://arxiv.org/abs/1811.05061</em>.
</p>
<p>Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO. <em>Computational Statistics and Data Analysis</em>, <b>92C</b>, 53-67.
</p>
<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems. <em>Computational Statistics and Data Analysis</em>, <b>94</b>, 275-286.
</p>
<p>Choi, H., Kim, Y. and Kwon, S. (2013). Sparse bridge estimation with a diverging number of parameters. <em>Statistics and Its Interface</em>, <b>6</b>, 231-242.
</p>

<hr>
<h2 id='ncpen.reg'>ncpen.reg: nonconvex penalized estimation</h2><span id='topic+ncpen.reg'></span>

<h3>Description</h3>

<p>Fits generalized linear models by penalized maximum likelihood estimation.
The coefficients path is computed for the regression model over a grid of the regularization parameter <code>lambda</code>.
Fits Gaussian (linear), binomial Logit (logistic), Poisson, multinomial Logit regression models, and
Cox proportional hazard model with various non-convex penalties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncpen.reg(formula, data, family = c("gaussian", "linear", "binomial",
  "logit", "multinomial", "cox", "poisson"), penalty = c("scad", "mcp",
  "tlp", "lasso", "classo", "ridge", "sridge", "mbridge", "mlog"),
  x.standardize = TRUE, intercept = TRUE, lambda = NULL,
  n.lambda = NULL, r.lambda = NULL, w.lambda = NULL, gamma = NULL,
  tau = NULL, alpha = NULL, df.max = 50, cf.max = 100,
  proj.min = 10, add.max = 10, niter.max = 30, qiter.max = 10,
  aiter.max = 100, b.eps = 1e-07, k.eps = 1e-04, c.eps = 1e-06,
  cut = TRUE, local = FALSE, local.initial = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ncpen.reg_+3A_formula">formula</code></td>
<td>
<p>(formula) regression formula. To include/exclude intercept, use <code>intercept</code> option
instead of using the &quot;0 +&quot; option in the formula.
The y value must be 0,1 for <code>binomial</code> and 1,2,..., for <code>multinomial</code>.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_data">data</code></td>
<td>
<p>(numeric matrix or data.frame) contains both y and X. Each row is an observation vector.
The censoring indicator must be included at the last column of the data for <code>cox</code>.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_family">family</code></td>
<td>
<p>(character) regression model. Supported models are
<code>gaussian</code> (or <code>linear</code>),
<code>binomial</code> (or <code>logit</code>),
<code>poisson</code>,
<code>multinomial</code>,
and <code>cox</code>.
Default is <code>gaussian</code>.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_penalty">penalty</code></td>
<td>
<p>(character) penalty function.
Supported penalties are
<code>scad</code> (smoothly clipped absolute deviation),
<code>mcp</code> (minimax concave penalty),
<code>tlp</code> (truncated LASSO penalty),
<code>lasso</code> (least absolute shrinkage and selection operator),
<code>classo</code> (clipped lasso = mcp + lasso),
<code>ridge</code> (ridge),
<code>sridge</code> (sparse ridge = mcp + ridge),
<code>mbridge</code> (modified bridge) and
<code>mlog</code> (modified log).
Default is <code>scad</code>.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_x.standardize">x.standardize</code></td>
<td>
<p>(logical) whether to standardize <code>x.mat</code> prior to fitting the model (see details).
The estimated coefficients are always restored to the original scale.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_intercept">intercept</code></td>
<td>
<p>(logical) whether to include an intercept in the model.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_lambda">lambda</code></td>
<td>
<p>(numeric vector) user-specified sequence of <code>lambda</code> values.
Default is supplied automatically from samples.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_n.lambda">n.lambda</code></td>
<td>
<p>(numeric) the number of <code>lambda</code> values.
Default is 100.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_r.lambda">r.lambda</code></td>
<td>
<p>(numeric) ratio of the smallest <code>lambda</code> value to largest.
Default is 0.001 when n&gt;p, and 0.01 for other cases.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_w.lambda">w.lambda</code></td>
<td>
<p>(numeric vector) penalty weights for each coefficient (see references).
If a penalty weight is set to 0, the corresponding coefficient is always nonzero.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_gamma">gamma</code></td>
<td>
<p>(numeric) additional tuning parameter for controlling shrinkage effect of <code>classo</code> and <code>sridge</code> (see references).
Default is half of the smallest <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_tau">tau</code></td>
<td>
<p>(numeric) concavity parameter of the penalties (see reference).
Default is 3.7 for <code>scad</code>, 2.1 for <code>mcp</code>, <code>classo</code> and <code>sridge</code>, 0.001 for <code>tlp</code>, <code>mbridge</code> and <code>mlog</code>.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) ridge effect (weight between the penalty and ridge penalty) (see details).
Default value is 1. If penalty is <code>ridge</code> and <code>sridge</code> then <code>alpha</code> is set to 0.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_df.max">df.max</code></td>
<td>
<p>(numeric) the maximum number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_cf.max">cf.max</code></td>
<td>
<p>(numeric) the maximum of absolute value of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_proj.min">proj.min</code></td>
<td>
<p>(numeric) the projection cycle inside CD algorithm (largely internal use. See details).</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_add.max">add.max</code></td>
<td>
<p>(numeric) the maximum number of variables added in CCCP iterations (largely internal use. See references).</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_niter.max">niter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CCCP.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_qiter.max">qiter.max</code></td>
<td>
<p>(numeric) maximum number of quadratic approximations in each CCCP iteration.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_aiter.max">aiter.max</code></td>
<td>
<p>(numeric) maximum number of iterations in CD algorithm.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_b.eps">b.eps</code></td>
<td>
<p>(numeric) convergence threshold for coefficients vector.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_k.eps">k.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_c.eps">c.eps</code></td>
<td>
<p>(numeric) convergence threshold for KKT conditions (largely internal use).</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_cut">cut</code></td>
<td>
<p>(logical) convergence threshold for KKT conditions  (largely internal use).</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_local">local</code></td>
<td>
<p>(logical) whether to use local initial estimator for path construction. It may take a long time.</p>
</td></tr>
<tr><td><code id="ncpen.reg_+3A_local.initial">local.initial</code></td>
<td>
<p>(numeric vector) initial estimator for <code>local=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by <code>lambda</code> is fit
by using concave convex procedure (CCCP) and coordinate descent (CD) algorithm (see references).
The objective function is </p>
<p style="text-align: center;"><code class="reqn"> (sum of squared residuals)/2n + [alpha*penalty + (1-alpha)*ridge] </code>
</p>
<p> for <code>gaussian</code>
and </p>
<p style="text-align: center;"><code class="reqn"> (log-likelihood)/n - [alpha*penalty + (1-alpha)*ridge] </code>
</p>
<p> for the others,
assuming the canonical link.
The algorithm applies the warm start strategy (see references) and tries projections
after <code>proj.min</code> iterations in CD algorithm, which makes the algorithm fast and stable.
<code>x.standardize</code> makes each column of <code>x.mat</code> to have the same Euclidean length
but the coefficients will be re-scaled into the original.
In <code>multinomial</code> case, the coefficients are expressed in vector form. Use <code><a href="#topic+coef.ncpen">coef.ncpen</a></code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>ncpen</code>.
</p>
<table>
<tr><td><code>y.vec</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code>x.mat</code></td>
<td>
<p>design matrix.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>regression model.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>penalty.</p>
</td></tr>
<tr><td><code>x.standardize</code></td>
<td>
<p>whether to standardize <code>x.mat=TRUE</code>.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>whether to include the intercept.</p>
</td></tr>
<tr><td><code>std</code></td>
<td>
<p>scale factor for <code>x.standardize</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>sequence of <code>lambda</code> values.</p>
</td></tr>
<tr><td><code>w.lambda</code></td>
<td>
<p>penalty weights.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>extra shrinkage parameter for <code>classo</code> and sridge only.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>ridge effect.</p>
</td></tr>
<tr><td><code>local</code></td>
<td>
<p>whether to use local initial estimator.</p>
</td></tr>
<tr><td><code>local.initial</code></td>
<td>
<p>local initial estimator for <code>local=TRUE</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>fitted coefficients. Use <code>coef.ncpen</code> for <code>multinomial</code> since the coefficients are represented as vectors.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the number of non-zero coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties.
<em>Journal of the American statistical Association</em>, 96, 1348-60.
Zhang, C.H. (2010). Nearly unbiased variable selection under minimax concave penalty.
<em>The Annals of statistics</em>, 38(2), 894-942.
Shen, X., Pan, W., Zhu, Y. and Zhou, H. (2013). On constrained and regularized high-dimensional regression.
<em>Annals of the Institute of Statistical Mathematics</em>, 65(5), 807-832.
Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
Kwon, S. Kim, Y. and Choi, H.(2013). Sparse bridge estimation with a diverging number of parameters.
<em>Statistics and Its Interface</em>, 6, 231-242.
Huang, J., Horowitz, J.L. and Ma, S. (2008). Asymptotic properties of bridge estimators in sparse high-dimensional regression models.
<em>The Annals of Statistics</em>, 36(2), 587-613.
Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models.
<em>Annals of statistics</em>, 36(4), 1509.
Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.ncpen">coef.ncpen</a></code>, <code><a href="#topic+plot.ncpen">plot.ncpen</a></code>, <code><a href="#topic+gic.ncpen">gic.ncpen</a></code>, <code><a href="#topic+predict.ncpen">predict.ncpen</a></code>, <code><a href="#topic+cv.ncpen">cv.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=5,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="gaussian")
x.mat = sam$x.mat; y.vec = sam$y.vec
data = cbind(y.vec, x.mat)
colnames(data) = c("y", paste("xv", 1:ncol(x.mat), sep = ""))
fit1 = ncpen.reg(formula = y ~ xv1 + xv2 + xv3 + xv4 + xv5, data = data,
                 family="gaussian", penalty="scad")
fit2 = ncpen(y.vec=y.vec,x.mat=x.mat);

</code></pre>

<hr>
<h2 id='plot.cv.ncpen'>plot.cv.ncpen: plot cross-validation error curve.</h2><span id='topic+plot.cv.ncpen'></span>

<h3>Description</h3>

<p>The function Produces a plot of the cross-validated errors from <code>cv.ncpen</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ncpen'
plot(x, type = c("rmse", "like"), log.scale = FALSE,
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.ncpen_+3A_x">x</code></td>
<td>
<p>fitted <code>cv.ncpen</code> object.</p>
</td></tr>
<tr><td><code id="plot.cv.ncpen_+3A_type">type</code></td>
<td>
<p>(character) a cross-validated error type which is either <code>rmse</code> or <code>like</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.ncpen_+3A_log.scale">log.scale</code></td>
<td>
<p>(logical) whether to use log scale of lambda for horizontal axis.</p>
</td></tr>
<tr><td><code id="plot.cv.ncpen_+3A_...">...</code></td>
<td>
<p>other graphical parameters to <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.ncpen">cv.ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
par(mfrow=c(1,2))
sam =  sam.gen.ncpen(n=500,p=10,q=5,cf.min=0.5,cf.max=1,corr=0.5,family="gaussian")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = cv.ncpen(y.vec=y.vec,x.mat=x.mat,n.lambda=50,family="gaussian", penalty="scad")
plot(fit)
plot(fit,log.scale=F)

</code></pre>

<hr>
<h2 id='plot.ncpen'>plot.ncpen: plots coefficients from an <code>ncpen</code> object.</h2><span id='topic+plot.ncpen'></span>

<h3>Description</h3>

<p>Produces a plot of the coefficients paths for a fitted <code>ncpen</code> object. Class-wise paths can be drawn for <code>multinomial</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncpen'
plot(x, log.scale = FALSE, mult.type = c("mat", "vec"),
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ncpen_+3A_x">x</code></td>
<td>
<p>(ncpen object) Fitted <code>ncpen</code> object.</p>
</td></tr>
<tr><td><code id="plot.ncpen_+3A_log.scale">log.scale</code></td>
<td>
<p>(logical) whether to use log scale of lambda for horizontal axis.</p>
</td></tr>
<tr><td><code id="plot.ncpen_+3A_mult.type">mult.type</code></td>
<td>
<p>(character) additional option for <code>multinomial</code> whether to draw the coefficients class-wise or not.
Default is <code>mat</code> that uses class-wise coefficients.</p>
</td></tr>
<tr><td><code id="plot.ncpen_+3A_...">...</code></td>
<td>
<p>other graphical parameters to <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncpen">ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat)
plot(fit)
### multinomial regression with classo penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec,x.mat=x.mat,family="multinomial",penalty="classo")
plot(fit)
plot(fit,mult.type="vec",log.scale=TRUE)
</code></pre>

<hr>
<h2 id='power.data'>Power Data</h2><span id='topic+power.data'></span>

<h3>Description</h3>

<p><code>power.data</code> power data and return a <code><a href="base.html#topic+data.frame">data.frame</a></code> with column names with tail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.data(data, power, tail = "_pow")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.data_+3A_data">data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> or <code><a href="base.html#topic+matrix">matrix</a></code> object.</p>
</td></tr>
<tr><td><code id="power.data_+3A_power">power</code></td>
<td>
<p>power.</p>
</td></tr>
<tr><td><code id="power.data_+3A_tail">tail</code></td>
<td>
<p>tail text for column names for powered data. For example, if a column &quot;sales&quot; is powered by 4 (=<code>power</code>)
and <code>tail</code> is &quot;_pow&quot;, then the output column name becomes &quot;sales_pow4&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This returns an object of <code><a href="base.html#topic+matrix">matrix</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = data.frame(a = 1:3, b= 4:6);
power.data(df, 2, ".pow");


</code></pre>

<hr>
<h2 id='predict.ncpen'>predict.ncpen: make predictions from an <code>ncpen</code> object</h2><span id='topic+predict.ncpen'></span>

<h3>Description</h3>

<p>The function provides various types of predictions from a fitted <code>ncpen</code> object:
response, regression, probability, root mean squared error (RMSE), negative log-likelihood (LIKE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ncpen'
predict(object, type = c("y", "reg", "prob", "rmse",
  "like"), new.y.vec = NULL, new.x.mat = NULL, prob.cut = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ncpen_+3A_object">object</code></td>
<td>
<p>(ncpen object) fitted <code>ncpen</code> object.</p>
</td></tr>
<tr><td><code id="predict.ncpen_+3A_type">type</code></td>
<td>
<p>(character) type of prediction.
<code>y</code> returns new responses from <code>new.x.mat</code>.
<code>reg</code> returns new linear predictors from <code>new.x.mat</code>.
<code>prob</code> returns new class probabilities from <code>new.x.mat</code> for <code>binomial</code> and <code>multinomial</code>.
<code>rmse</code> returns RMSE from <code>new.y.vec</code> and <code>new.x.mat</code>.
<code>prob</code> returns LIKE from <code>new.y.vec</code> and <code>new.x.mat</code>.</p>
</td></tr>
<tr><td><code id="predict.ncpen_+3A_new.y.vec">new.y.vec</code></td>
<td>
<p>(numeric vector). vector of new response at which predictions are to be made.</p>
</td></tr>
<tr><td><code id="predict.ncpen_+3A_new.x.mat">new.x.mat</code></td>
<td>
<p>(numeric matrix). matrix of new design at which predictions are to be made.</p>
</td></tr>
<tr><td><code id="predict.ncpen_+3A_prob.cut">prob.cut</code></td>
<td>
<p>(numeric) threshold value of probability for <code>binomial</code>.</p>
</td></tr>
<tr><td><code id="predict.ncpen_+3A_...">...</code></td>
<td>
<p>other S3 parameters. Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prediction values depending on <code>type</code> for all lambda values.
</p>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Lee, S., Kwon, S. and Kim, Y. (2016). A modified local quadratic approximation algorithm for penalized optimization problems.
<em>Computational Statistics and Data Analysis</em>, 94, 275-286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncpen">ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression with scad penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec[1:190],x.mat=x.mat[1:190,])
predict(fit,"y",new.x.mat=x.mat[190:200,])
### logistic regression with classo penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="binomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec[1:190],x.mat=x.mat[1:190,],family="binomial",penalty="classo")
predict(fit,"y",new.x.mat=x.mat[190:200,])
predict(fit,"y",new.x.mat=x.mat[190:200,],prob.cut=0.3)
predict(fit,"reg",new.x.mat=x.mat[190:200,])
predict(fit,"prob",new.x.mat=x.mat[190:200,])
### multinomial regression with sridge penalty
sam =  sam.gen.ncpen(n=200,p=20,q=5,k=3,cf.min=0.5,cf.max=1,corr=0.5,family="multinomial")
x.mat = sam$x.mat; y.vec = sam$y.vec
fit = ncpen(y.vec=y.vec[1:190],x.mat=x.mat[1:190,],family="multinomial",penalty="classo")
predict(fit,"y",new.x.mat=x.mat[190:200,])
predict(fit,"reg",new.x.mat=x.mat[190:200,])
predict(fit,"prob",new.x.mat=x.mat[190:200,])
</code></pre>

<hr>
<h2 id='sam.gen.ncpen'>sam.gen.ncpen: generate a simulated dataset.</h2><span id='topic+sam.gen.ncpen'></span>

<h3>Description</h3>

<p>Generate a synthetic dataset based on the correlation structure from generalized linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sam.gen.ncpen(n = 100, p = 50, q = 10, k = 3, r = 0.3,
  cf.min = 0.5, cf.max = 1, corr = 0.5, seed = NULL,
  family = c("gaussian", "binomial", "multinomial", "cox", "poisson"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sam.gen.ncpen_+3A_n">n</code></td>
<td>
<p>(numeric) the number of samples.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_p">p</code></td>
<td>
<p>(numeric) the number of variables.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_q">q</code></td>
<td>
<p>(numeric) the number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_k">k</code></td>
<td>
<p>(numeric) the number of classes for <code>multinomial</code>.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_r">r</code></td>
<td>
<p>(numeric) the ratio of censoring for <code>cox</code>.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_cf.min">cf.min</code></td>
<td>
<p>(numeric) value of the minimum coefficient.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_cf.max">cf.max</code></td>
<td>
<p>(numeric) value of the maximum coefficient.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_corr">corr</code></td>
<td>
<p>(numeric) strength of correlations in the correlation structure.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_seed">seed</code></td>
<td>
<p>(numeric) seed number for random generation. Default does not use seed.</p>
</td></tr>
<tr><td><code id="sam.gen.ncpen_+3A_family">family</code></td>
<td>
<p>(character) model type.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A design matrix for regression models is generated from the multivariate normal distribution with a correlation structure.
Then the response variables are computed with a specific model based on the true coefficients (see references).
Note the censoring indicator locates at the last column of <code>x.mat</code> for <code>cox</code>.
</p>


<h3>Value</h3>

<p>An object with list class containing
</p>
<table>
<tr><td><code>x.mat</code></td>
<td>
<p>design matrix.</p>
</td></tr>
<tr><td><code>y.vec</code></td>
<td>
<p>responses.</p>
</td></tr>
<tr><td><code>b.vec</code></td>
<td>
<p>true coefficients.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongshin Kim, Sunghoon Kwon, Sangin Lee
</p>


<h3>References</h3>

<p>Kwon, S., Lee, S. and Kim, Y. (2016). Moderately clipped LASSO.
<em>Computational Statistics and Data Analysis</em>, 92C, 53-67.
Kwon, S. and Kim, Y. (2012). Large sample properties of the SCAD-penalized maximum likelihood estimation on high dimensions.
<em>Statistica Sinica</em>, 629-653.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ncpen">ncpen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### linear regression
sam =  sam.gen.ncpen(n=200,p=20,q=5,cf.min=0.5,cf.max=1,corr=0.5)
x.mat = sam$x.mat; y.vec = sam$y.vec
head(x.mat); head(y.vec)
</code></pre>

<hr>
<h2 id='same.base'>Check whether column names are derivation of a same base.</h2><span id='topic+same.base'></span>

<h3>Description</h3>

<p>This is internal use only function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>same.base(base.cols, a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="same.base_+3A_base.cols">base.cols</code></td>
<td>
<p>vector of base column names.</p>
</td></tr>
<tr><td><code id="same.base_+3A_a">a</code></td>
<td>
<p>first column to be compared.</p>
</td></tr>
<tr><td><code id="same.base_+3A_b">b</code></td>
<td>
<p>second column to be compared.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if same base, FALSE otherwise.
</p>

<hr>
<h2 id='to.indicators'>Construct Indicator Matrix</h2><span id='topic+to.indicators'></span>

<h3>Description</h3>

<p><code>to.indicators</code> converts a categorical variable into a <code><a href="base.html#topic+data.frame">data.frame</a></code>
with indicator (0 or 1) variables for each category.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to.indicators(vec, exclude.base = TRUE, base = NULL, prefix = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to.indicators_+3A_vec">vec</code></td>
<td>
<p>a categorical vector.</p>
</td></tr>
<tr><td><code id="to.indicators_+3A_exclude.base">exclude.base</code></td>
<td>
<p><code>FALSE</code> means to include all the categories. <code>TRUE</code>
means to exclude one category as a base case.
If <code>base</code> is not specified, a random category will be removed.</p>
</td></tr>
<tr><td><code id="to.indicators_+3A_base">base</code></td>
<td>
<p>a base category removed from the indicator matrix. This option works
only when the <code>type</code> variable is set to <code>"exclude.base"</code>.</p>
</td></tr>
<tr><td><code id="to.indicators_+3A_prefix">prefix</code></td>
<td>
<p>a prefix to be used for column names of the output matrix.
Default is &quot;cat_&quot; if <code>prefix</code> is <code>NULL</code>.
For example, if a category vector has values of c(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;),
column names of the output matrix will be &quot;cat_aa&quot;, &quot;cat_bb&quot; and &quot;cat_cc&quot;.
If <code>vec</code> is a <code><a href="base.html#topic+data.frame">data.frame</a></code> and <code>prefix</code> is <code>NULL</code>,
then the <code>vec</code>'s column name followed by &quot;_&quot; will be used as a prefix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This returns an object of <code><a href="base.html#topic+matrix">matrix</a></code> which contains indicators.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a1 = 4:10;
b1 = c("aa", "bb", "cc");

to.indicators(a1, base = 10);
to.indicators(b1, base = "bb", prefix = "T_");
to.indicators(as.data.frame(b1), base = "bb");



</code></pre>

<hr>
<h2 id='to.ncpen.x.mat'>Convert a <code><a href="base.html#topic+data.frame">data.frame</a></code> to a <code>ncpen</code> usable <code><a href="base.html#topic+matrix">matrix</a></code>.</h2><span id='topic+to.ncpen.x.mat'></span>

<h3>Description</h3>

<p>This automates the processes of <code><a href="#topic+to.indicators">to.indicators</a></code> and <code><a href="#topic+interact.data">interact.data</a></code>.
First, it converts categorical variables to a series of indicators.
All other numerical and logical variables are preserved.
Then, if <code>interact.all == TRUE</code>, all the variables are interacted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to.ncpen.x.mat(df, base = NULL, interact.all = FALSE,
  base.cols = NULL, exclude.pair = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to.ncpen.x.mat_+3A_df">df</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> which includes numerical, logical and categorical columns.</p>
</td></tr>
<tr><td><code id="to.ncpen.x.mat_+3A_base">base</code></td>
<td>
<p>a base category removed from the indicator variables. This <code>base</code> will work as the
base case for all the categorical variables.</p>
</td></tr>
<tr><td><code id="to.ncpen.x.mat_+3A_interact.all">interact.all</code></td>
<td>
<p>indicates whether to interact all the columns (<code>TRUE</code>) or not (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="to.ncpen.x.mat_+3A_base.cols">base.cols</code></td>
<td>
<p>indicates columns derived from a same column. For example, if <code>age_sq</code> is <code>age^2</code>,
then <code>"age"</code> is a base column. Categorical columns will be automatically considered as base columns.</p>
</td></tr>
<tr><td><code id="to.ncpen.x.mat_+3A_exclude.pair">exclude.pair</code></td>
<td>
<p>the pairs will be excluded from interactions. This should be a <code><a href="base.html#topic+list">list</a></code> object of pairs.
For example, <code>list(c("a1", "a2"), c("d1", "d2"))</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This returns an object of <code><a href="base.html#topic+matrix">matrix</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = data.frame(num = c(1, 2, 3, 4, 5),
                ctr = c("K", "O", "R", "R", "K"),
                logi = c(TRUE, TRUE, FALSE, FALSE, TRUE),
                age = c(10, 20, 30, 40, 50),
                age_sq = c(10, 20, 30, 40, 50)^2,
                loc = c("b", "a", "c", "a", "b"),
                FTHB = c(1,0,1,0,1),
                PRM  = c(0,1,0,1,0),
                PMI  = c(1,1,0,0,0));

to.ncpen.x.mat(df, interact.all = TRUE,
   base.cols = c("age"),
   exclude.pair = list(c("FTHB", "PRM")));



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
