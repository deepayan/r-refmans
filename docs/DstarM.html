<!DOCTYPE html><html lang="en"><head><title>Help for package DstarM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DstarM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#chisq'><p>Calculates the distance between two probability densities.</p></a></li>
<li><a href='#chisqFit'><p>Calculate model fit</p></a></li>
<li><a href='#Density'><p>Density function</p></a></li>
<li><a href='#estCdf'><p>Estimate cumulative distribution for D*M models</p></a></li>
<li><a href='#estDstarM'><p>Do a D*M analysis</p></a></li>
<li><a href='#estND'><p>Estimate nondecision density</p></a></li>
<li><a href='#estObserved'><p>Estimate observed data density</p></a></li>
<li><a href='#estQdf'><p>Estimate quantiles of distribution</p></a></li>
<li><a href='#getPdfs'><p>(Re)Calculate model densities with given parameters and time grid</p></a></li>
<li><a href='#getSter'><p>Estimate variance of nondecision density</p></a></li>
<li><a href='#getTer'><p>Calculate Mean of the nondecision distribution.</p></a></li>
<li><a href='#normalize'><p>Normalize two pdfs</p></a></li>
<li><a href='#obsQuantiles'><p>Calculate model fit</p></a></li>
<li><a href='#plotObserved'><p>Plot quantiles of data against model implied quantiles.</p></a></li>
<li><a href='#rtDescriptives'><p>Descriptives of reaction time data</p></a></li>
<li><a href='#rtHist'><p>Make histograms of reaction time data</p></a></li>
<li><a href='#simData'><p>Simulate data from a given density function via multinomial sampling</p></a></li>
<li><a href='#testFun'><p>Test fun.density with lower and upper bounds</p></a></li>
<li><a href='#upgradeDstarM'><p>Upgrade a DstarM object for backwards compatibility</p></a></li>
<li><a href='#Voss.density'><p>Calculate model density for a given set of parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyze Two Choice Reaction Time Data with the D*M Method</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Don van den Bergh, Stijn Verdonck, Francis Tuerlinckx</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Don van den Bergh &lt;donvdbergh@hotmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions to estimate parameters of a diffusion model via a D*M analysis. Build in models are: the Ratcliff diffusion model, the RWiener diffusion model, and Linear Ballistic Accumulator models. Custom models functions can be specified as long as they have a density function.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Imports:</td>
<td>DEoptim, RWiener, rtdists, stats, ggplot2, Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/vandenman/DstarM">https://github.com/vandenman/DstarM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/vandenman/DstarM/issues">https://github.com/vandenman/DstarM/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-08-28 12:57:58 UTC; dvdb</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-08-28 18:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='chisq'>Calculates the distance between two probability densities.</h2><span id='topic+chisq'></span><span id='topic+battacharyya'></span><span id='topic+hellinger'></span>

<h3>Description</h3>

<p>Calculates the distance between two probability densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq(tt, a, b)

battacharyya(tt, a, b)

hellinger(tt, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisq_+3A_tt">tt</code></td>
<td>
<p>the time grid on which the densities are evaluated.</p>
</td></tr>
<tr><td><code id="chisq_+3A_a">a</code></td>
<td>
<p>a vector with values of the first density.</p>
</td></tr>
<tr><td><code id="chisq_+3A_b">b</code></td>
<td>
<p>a vector with values of the second density.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The distance between densities <code>a</code> and <code>b</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Lets simulate a bunch of parameters and compare the three distance measures.

tt = seq(0, 5, .001)
parsMatV = cbind(.8, seq(0, 5, .5), .5, .5, .5) # differ only in drift speed
parsMatA = cbind(seq(.5, 2, .15), 2, .5, .5, .5)# differ only in boundary
# calculate densities for all these parameters
dV = apply(parsMatV, 1, function(x, tt) Voss.density(tt, x, boundary = 'upper'), tt = tt)
dA = apply(parsMatA, 1, function(x, tt) Voss.density(tt, x, boundary = 'upper'), tt = tt)
# make plots of the densities
matplot(tt, dA, xlim = c(0, .6), main = 'Densities with different Boundary',
        col = rainbow(ncol(dA)),type = 'l', lty = 1, las = 1, bty = 'n',
        xlab = 'Time', ylab = 'Density')
legend('topright', lty = 1, bty = 'n', col = rainbow(ncol(dA)),
       legend = paste('a = ', parsMatA[, 1]))
matplot(tt, dV, xlim = c(0, .6), main = 'Densities with different Drift Speed',
        col = rainbow(ncol(dV)), type = 'l', lty = 1, las = 1, bty = 'n',
        xlab = 'Time', ylab = 'Density')
legend('topright', lty = 1, bty = 'n', col = rainbow(ncol(dV)),
       legend = paste('v = ',parsMatV[, 2]))
# empty matrices for data storage
distMatV = matrix(NA, nrow = ncol(dV) - 1, ncol = 3,
                  dimnames = list(NULL, c('Chisq', 'Bhattacharyya', 'Hellinger')))
distMatA = matrix(NA, nrow = ncol(dA) - 1, ncol = 3,
                  dimnames = list(NULL, c('Chisq', 'Bhattacharyya', 'Hellinger')))
# calculate distances between densities in column i and i + 1.
# this is done using three different distance measures
for (i in 1:(ncol(dA) - 1)) {
  distMatV[i, ] = c(chisq(tt, dV[, i], dV[, i + 1]),
                    battacharyya(tt, dV[, i], dV[, i + 1]),
                    hellinger(tt, dV[, i], dV[, i + 1]))
  distMatA[i, ] = c(chisq(tt, dA[, i], dA[, i + 1]),
                    battacharyya(tt, dA[, i], dA[, i + 1]),
                    hellinger(tt, dA[, i], dA[, i + 1]))
}
# The three distance measures correlate highly for differences in Boundary
cor(distMatA)
# The battacharyya distance measures does not correlate with the others
# when calculating differences in drift speed
cor(distMatV)
</code></pre>

<hr>
<h2 id='chisqFit'>Calculate model fit</h2><span id='topic+chisqFit'></span>

<h3>Description</h3>

<p>Calculate model fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisqFit(resObserved, data, DstarM = FALSE, tt = NULL, formula = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisqFit_+3A_resobserved">resObserved</code></td>
<td>
<p>either output from <code><a href="#topic+estObserved">estObserved</a></code> or a matrix containing custom densities to calculate the fitness for.</p>
</td></tr>
<tr><td><code id="chisqFit_+3A_data">data</code></td>
<td>
<p>A dataframe containing data.</p>
</td></tr>
<tr><td><code id="chisqFit_+3A_dstarm">DstarM</code></td>
<td>
<p>Logical. Should the DstarM fit measure be calculated or the traditional fit measure?</p>
</td></tr>
<tr><td><code id="chisqFit_+3A_tt">tt</code></td>
<td>
<p>time grid custom densities where calculated on. Should only be supplied if <code>resOberved</code> is a matrix containing custom densities</p>
</td></tr>
<tr><td><code id="chisqFit_+3A_formula">formula</code></td>
<td>
<p>Optional formula argument, for when columns names in the data are different from those used to obtain the results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows a user to manually calculate a chi-square goodness of fit measure for model densities.
This is useful for comparing a traditional analysis and a D*M analysis. For completion, this function can also calculate a
D*M fit measure. We do not recommend usage of the D*M measure. While the chi-square fit measure is
identical to the value of the optimizer when fitting, the DstarM fit measure is not equal to that of a DstarM analysis.
This is because this function calculates the DstarM fit measure on the complete distribution, not on the
model distributions, as is done during the optimization.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt = seq(0, 5, .1)
pars = c(.8, 2, .5, .5, .5, # condition 1
         .8, 3, .5, .5, .5,  # condition 2
         .8, 4, .5, .5, .5)  # condition 3
pdfND = dbeta(tt, 10, 30)

# simulate data
allDat = simData(n = 3e3, pars = pars, tt = tt, pdfND = pdfND, return.pdf = TRUE)
truePdf = allDat$pdfUnnormalized
dat = allDat$dat
chisqFit(resObserved = truePdf, data = dat, tt = tt)
## Not run: 
# estimate it
define restriction matrix
restr = matrix(1:5, 5, 3)
restr[2, 2:3] = 6:7 # allow drift rates to differ
# fix parameters for speed up
fixed = matrix(c('z1', 'a1 / 2', 'sz1', .5, 'sv1', .5), 2, 3)
resD = estDstarM(data = dat, tt = tt, restr = restr, fixed = fixed,
                 Optim = list(parallelType = 1))
resN = estND(resD, Optim = list(parallelType = 1))

resO = estObserved(resD, resN, data = dat)
resO$fit # proper fit

## End(Not run)
</code></pre>

<hr>
<h2 id='Density'>Density function</h2><span id='topic+Density'></span>

<h3>Description</h3>

<p>Density function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Density(rt, tt)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Density_+3A_rt">rt</code></td>
<td>
<p>vector of reaction times</p>
</td></tr>
<tr><td><code id="Density_+3A_tt">tt</code></td>
<td>
<p>grid to evaluate the density on</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Can be passed to the argument <code>densityMethod</code> of <code><a href="#topic+estDstarM">estDstarM</a></code>. This function is a minimal
example to use as custom smoothing function.
</p>


<h3>Value</h3>

<p>a vector of <code>length(tt)</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgamma(1e5, 1, 1)
tt &lt;- seq(0, 5, .01)
d &lt;- Density(x, tt)
hist(x, freq = FALSE)
lines(tt, DstarM:::Density(x, tt))
</code></pre>

<hr>
<h2 id='estCdf'>Estimate cumulative distribution for D*M models</h2><span id='topic+estCdf'></span>

<h3>Description</h3>

<p>Estimate cumulative distribution for D*M models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estCdf(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estCdf_+3A_x">x</code></td>
<td>
<p>Any density function to calculate a cumulative distribution for.
The code is designed for input of class <code>DstarM</code> but other input is also
accepted. Other input can be either a matrix where columns represent densities
or a single vector representing a density.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cumulative distributions functions are calculated by: <code>cumsum(x) / sum(x)</code>.
This method works well enough for our purposes. The example below shows that the
<code><a href="stats.html#topic+ecdf">ecdf</a></code> functions seems to work slightly better. However, this estimates a
cdf from raw data and does not transform a pdf into a cdf and is therefore not useful
for D*M models.
</p>


<h3>Value</h3>

<p>Cumulative density function(s). If the input was a matrix,
a matrix of cumulative density functions is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(1000)
xx = seq(-5, 5, .1)
approx1 = stats::ecdf(x)(xx)
approx2 = estCdf(dnorm(xx, mean(x), sd(x)))
trueCdf = pnorm(xx)
matplot(xx, cbind(trueCdf, approx1, approx2), type = c('l', 'p', 'p'),
        lty = 1, col = 1:3, pch = 1, bty = 'n', las = 1, ylab = 'Prob')
legend('topleft', legend = c('True Cdf', 'Stats Estatimation', 'DstarM Estimation'),
       col = 1:3, lty = c(1, NA, NA), pch = c(NA, 1, 1), bty = 'n')

</code></pre>

<hr>
<h2 id='estDstarM'>Do a D*M analysis</h2><span id='topic+estDstarM'></span>

<h3>Description</h3>

<p>Do a D*M analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estDstarM(
  formula = NULL,
  data,
  tt,
  restr = NULL,
  fixed = list(),
  lower,
  upper,
  Optim = list(),
  DstarM = TRUE,
  SE = 0,
  oscPdf = TRUE,
  splits = rep(0L, (ncondition)),
  forceRestriction = TRUE,
  mg = NULL,
  h = 1,
  pars,
  fun.density = Voss.density,
  args.density = list(),
  fun.dist = chisq,
  args.dist = list(tt = tt),
  verbose = 1L,
  useRcpp = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estDstarM_+3A_formula">formula</code></td>
<td>
<p>A formula object of the form:
<code>binary response ~ reaction time + condition1 * condition2 * ... conditionN</code>.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_data">data</code></td>
<td>
<p>A dataframe for looking up data specified in formula.
For backwards compatibility this can also be with: a column named <code>rt</code> containing response times in ms,
a column named <code>response</code> containing at most 2 response options, and an
optional column named <code>condition</code> containing a numeric index as to which conditions
observations belong.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_tt">tt</code></td>
<td>
<p>A time grid on which the density function will be evaluated.
Should be larger than the highest observed reaction time.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_restr">restr</code></td>
<td>
<p>A restriction matrix where each column depicts one condition.
The number of rows should match the number of parameters (and be equal to the length of lower).
The contents of <code>restr</code> should be numbers, identical numbers means that these parameters
(either within or between condition) will be constrained. Different numbers means parameters
will not be constrained.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_fixed">fixed</code></td>
<td>
<p>A matrix that allows for fixing parameters to certain values.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_lower">lower</code></td>
<td>
<p>Should be a vector containing lower bounds for each parameter.
Has a default if <code>fun.density == Voss.density</code>.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_upper">upper</code></td>
<td>
<p>Should be a vector containing upper bounds for each parameter.
Has a default if <code>fun.density == Voss.density</code>.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_optim">Optim</code></td>
<td>
<p>a named list with identical arguments to <code>DEoptim.control</code>.
In addition, if <code>verbose</code> == TRUE <code>Optim$steptol</code> can be a vector, i.e.
<code>c(200, 50, 10)</code> means: Do 200 iterations then check for convergence, do 50
iterations then check for convergence, check every 10 iterations for convergence until
itermax is reached. Defaults to <code>Optim = list(reltol = 1e-6, itermax = 1e3,
steptol = 50, CR = .9, trace = 0, parallelType = 0)</code>.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_dstarm">DstarM</code></td>
<td>
<p>If TRUE a D*M analysis is done, otherwise the Chi square distance
between data and model is minimized.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_se">SE</code></td>
<td>
<p>positive value, how many standard error to add to the variance to relax
the variance restriction a bit.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_oscpdf">oscPdf</code></td>
<td>
<p>Logical, if TRUE check for oscillations in calculated densities and
remove densities with oscillations.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_splits">splits</code></td>
<td>
<p>Numeric vector determining which conditions have an equal nondecision density.
Identical values in two positions indicate that the conditions corresponding to the indices
of those values have an identical nondecision distribution.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_forcerestriction">forceRestriction</code></td>
<td>
<p>if TRUE the variance restriction is enforced.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_mg">mg</code></td>
<td>
<p>Supply a data density, useful if a uniform kernel approximation does not suffice.
Take care that densities of response categories within conditions are degenerate and therefore integrate to the proportion a category was observed (and not to 1).</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_h">h</code></td>
<td>
<p>bandwidth of a uniform kernel used to generate data based densities.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_pars">pars</code></td>
<td>
<p>Optional parameter vector to supply if one wishes to evaluate the objective
function in a given parameter vector. Only used if <code>itermax</code> equal zero.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_fun.density">fun.density</code></td>
<td>
<p>Function used to calculate densities. See details.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_args.density">args.density</code></td>
<td>
<p>A names list containing additional arguments to be send to fun.density.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_fun.dist">fun.dist</code></td>
<td>
<p>Function used to calculate distances between densities.
Defaults to a chi-square distance.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_args.dist">args.dist</code></td>
<td>
<p>A named list containing additional arguments to be send to fun.dist.</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_verbose">verbose</code></td>
<td>
<p>Numeric, should intermediate output be printed? Defaults to 1, higher values result in more progress output.
Estimation will speed up if set to 0. If set to TRUE, <code>Optim$trace</code> will be
forced to 0, hereby disabling the build in printing of <code>DEoptim</code>. To enable the
printing of <code>DEoptim</code>, set <code>verbose</code> to 0 and specify <code>Optim$trace</code>.
<code>Optim</code>. If set to 1, ETA refers to the expected maximum time until completion (when the iterations limit is reached).</p>
</td></tr>
<tr><td><code id="estDstarM_+3A_usercpp">useRcpp</code></td>
<td>
<p>Logical, setting this to true will make the objective function use an Rcpp implementation
of <code>Voss.density</code> with the distance function <code>chisq</code>. This gains speed at the cost of flexibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Response options will be alphabetically sorted and the first response option will be
treated as the 'lower' option. This means that if the observed proportion of the first
response options is higher, the drift speed will most likely be negative.
</p>
<p><code>fun.density</code> allows a user to specify a custom density function. This function must (at least) take the following arguments:
<code>t</code>: a vector specifying at which time points to calculate the density
<code>pars</code>: a parameter vector
<code>boundary</code>: character 'upper' or 'lower' specifying for which response option the density will be calculated.
<code>DstarM</code>: Logical, if TRUE the density should not describe the nondecision density, if FALSE it should describe the nondecision density.
Any additional arguments can be passed to <code>fun.density</code> via the argument <code>args.density</code>.
If one intends to use a custom density function it is recommended to test the function first with <code><a href="#topic+testFun">testFun</a></code>.
When specifying a custom density function it is probably also necessary to change the lower and upper bounds of the parameter space.
</p>
<p>For purposes of speed, the function can be run in parallel by providing the argument <code>Optim = list(parallelType = 1)</code>.
See <code>DEoptim.control</code> for details. Also, for Ratcliff models the objective function has been rewritten in Rcpp.
This limits some functionality but does result in a faster estimation. Usage of Rcpp can be enabled via <code>useRcpp = TRUE</code>.
</p>
<p>When verbose is set to 1, the ETA is an estimated of the time it takes to execute ALL iterations.
Convergence can (and is usually) reached before then.
</p>


<h3>Value</h3>

<p>Returns a list of class <code>DstarM.fitD</code> that contains:
</p>
<table role = "presentation">
<tr><td><code>Bestvals</code></td>
<td>
<p>Named numeric vector. Contains the best parameter estimates.</p>
</td></tr>
<tr><td><code>fixed</code></td>
<td>
<p>Numeric vector. Contains the best parameter estimates.</p>
</td></tr>
<tr><td><code>GlobalOptimizer</code></td>
<td>
<p>List. All output from the call to <code>DEoptim</code></p>
</td></tr>
<tr><td><code>Debug</code></td>
<td>
<p>List. contains the number of DEoptim iterations, the number of function evaluation of the objective function, and the maximum number of iterations.</p>
</td></tr>
<tr><td><code>note</code></td>
<td>
<p>String. A possible note that is used for summary purposes</p>
</td></tr>
<tr><td><code>tt</code></td>
<td>
<p>Numeric vector. Contains the time grid used.</p>
</td></tr>
<tr><td><code>g.hat</code></td>
<td>
<p>Numeric matrix. Named columns represent the (possibly smoothed) densities of the data distribution of each condition-response pair.</p>
</td></tr>
<tr><td><code>modelDist</code></td>
<td>
<p>Numeric matrix. Named columns represent the densities of the model evaluated at grid <code>tt</code> with parameters <code>Bestvals</code>.</p>
</td></tr>
<tr><td><code>ncondition</code></td>
<td>
<p>Numeric scalar. The number of conditions</p>
</td></tr>
<tr><td><code>var.data</code></td>
<td>
<p>Numeric vector. The variance of each condition-response pair. There are as many values as hypothesized nondecision densities.</p>
</td></tr>
<tr><td><code>var.m</code></td>
<td>
<p>Numeric vector. The variance of the model distributions. There are as many values as hypothesized nondecision densities.</p>
</td></tr>
<tr><td><code>restr.mat</code></td>
<td>
<p>Numeric matrix. Contains the restrictions used.</p>
</td></tr>
<tr><td><code>splits</code></td>
<td>
<p>Numeric vector. Equal to the input argument with the same name.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Numeric scalar. The total number of observations.</p>
</td></tr>
<tr><td><code>DstarM</code></td>
<td>
<p>Logical. Equal to the input argument with the same name.</p>
</td></tr>
<tr><td><code>fun.density</code></td>
<td>
<p>Function. Equal to the input argument with the same name.</p>
</td></tr>
<tr><td><code>fun.dist</code></td>
<td>
<p>Function. Equal to the input argument with the same name.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>Scalar. Equal to the input argument with the same name.</p>
</td></tr>
<tr><td><code>args.density</code></td>
<td>
<p>Named list. Equal to the input argument with the same name.</p>
</td></tr>
<tr><td><code>args.dist</code></td>
<td>
<p>Named list. Equal to the input argument with the same name.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# simulate data with three stimuli of different difficulty.
# this implies different drift rates across conditions.
# define a time grid. A more reasonable stepsize is .01; this is just for speed.
tt = seq(0, 5, .1)
pars = c(.8, 2, .5, .5, .5, # condition 1
        .8, 3, .5, .5, .5,  # condition 2
        .8, 4, .5, .5, .5)  # condition 3
pdfND = dbeta(tt, 10, 30)
# simulate data
data = simData(n = 3e3, pars = pars, tt = tt, pdfND = pdfND)
# define restriction matrix
restr = matrix(1:5, 5, 3)
restr[2, 2:3] = 6:7 # allow drift rates to differ
# fix variance parameters
fixed = matrix(c('sz1', .5, 'sv1', .5), 2, 2)
## Not run: 
# Run D*M analysis
res = estDstarM(data = data, tt = tt, restr = restr, fixed = fixed)
coef(res)
summary(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='estND'>Estimate nondecision density</h2><span id='topic+estND'></span>

<h3>Description</h3>

<p>Estimate nondecision density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estND(
  res,
  tt = NULL,
  data = NULL,
  h = res$h,
  zp = 5,
  upper.bound = 1,
  lower.bound = 0,
  Optim = list(),
  verbose = TRUE,
  dist = NULL,
  NDindex,
  max = 100,
  useRcpp = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estND_+3A_res">res</code></td>
<td>
<p>an object of class <code>D*M</code>.</p>
</td></tr>
<tr><td><code id="estND_+3A_tt">tt</code></td>
<td>
<p>optional timegrid if the nondecision density is to be estimated at a different grid than the model density.</p>
</td></tr>
<tr><td><code id="estND_+3A_data">data</code></td>
<td>
<p>if <code>tt</code> is specified then the original dataset must be supplied too.</p>
</td></tr>
<tr><td><code id="estND_+3A_h">h</code></td>
<td>
<p>Optional smoothing parameter to be used when estimating the nondecision model on a
different time grid than the decision model. If omitted, the smoothing parameter of the decision model
is used.</p>
</td></tr>
<tr><td><code id="estND_+3A_zp">zp</code></td>
<td>
<p>Zero padding the estimated nondecision density by this amount to avoid numerical artefacts.</p>
</td></tr>
<tr><td><code id="estND_+3A_upper.bound">upper.bound</code></td>
<td>
<p>An upper bound for the nondecision density. Defaults to one.
Lowering this bound can increase estimation speed,
at the cost of assuming that the density of the nondecision distribution is zero past this value.</p>
</td></tr>
<tr><td><code id="estND_+3A_lower.bound">lower.bound</code></td>
<td>
<p>A lower bound for the nondecision density. Defaults to zero.
Increasing this bound can increase estimation speed,
at the cost of assuming that the density of the nondecision distribution is zero past this value.</p>
</td></tr>
<tr><td><code id="estND_+3A_optim">Optim</code></td>
<td>
<p>a named list with identical arguments to <code>DEoptim.control</code>.
In addition, if <code>verbose</code> == TRUE <code>Optim$steptol</code> can be a vector, i.e. <code>c(200, 50, 10)</code> means:
Do 200 iterations then check for convergence, do 50 iterations then check for convergence,
check every 10 iterations for convergence until itermax is reached.
If there are multiple nondecision distributions to estimate, one can supply different estimation
parameters for every nondecision distribution by supplying Optim as a list of lists. Every sublists
then corresponds to parameters for one nondecision distribution and should consist of arguments for
<code>DEoptim.control</code>.
Defaults to <code>Optim = list(reltol = 1e-6, itermax = 1e4, steptol = 200, CR = .9, trace = 0)</code>.</p>
</td></tr>
<tr><td><code id="estND_+3A_verbose">verbose</code></td>
<td>
<p>Numeric, should intermediate output be printed? Defaults to 1, higher values result in more progress output.
Estimation will speed up if set to 0. If nonzero, <code>Optim$trace</code> will be
forced to 0, hereby disabling the build in printing of <code>DEoptim</code>. To enable the
printing of <code>DEoptim</code>, set <code>verbose</code> to 0 and specify <code>Optim$trace</code>.</p>
</td></tr>
<tr><td><code id="estND_+3A_dist">dist</code></td>
<td>
<p>A matrix where columns represent nondecision distributions.
If this argument is supplied then the objective function will be evaluated in these values.</p>
</td></tr>
<tr><td><code id="estND_+3A_ndindex">NDindex</code></td>
<td>
<p>A vector containing indices of which nondecision distributions to estimate.
If omitted, all nondecision distributions that complement the results in <code>res</code> are estimated.</p>
</td></tr>
<tr><td><code id="estND_+3A_max">max</code></td>
<td>
<p>A positive float which indicates the maximum height of the nondecision distribution.
If estimated nondecision distributions appear chopped of or have a lot of values at this <code>max</code>
value it is recommended to re-estimate the nondecision distributions with a higher max value. Increasing
the <code>max</code> value without reason will increase the size of the parameter space and slow the estimation
procedure.</p>
</td></tr>
<tr><td><code id="estND_+3A_usercpp">useRcpp</code></td>
<td>
<p>Logical, setting this to true will make use of an Rcpp implementation of the objective function.
This gains speed at the cost of flexibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When verbose is set to 1, the ETA is an estimated of the time it takes to execute ALL iterations.
Convergence can (and is usually) reached before then.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data with three stimuli of different difficulty.
# this implies different drift rates across conditions.
# define a time grid. A more reasonable stepsize is .01; this is just for speed.
tt = seq(0, 5, .1)
pars = c(.8, 2, .5, .5, .5, # condition 1
        .8, 3, .5, .5, .5, # condition 2
        .8, 4, .5, .5, .5) # condition 3
pdfND = dbeta(tt, 10, 30)
# simulate data
dat = simData(n = 3e5, pars = pars, tt = tt, pdfND = pdfND)
# define restriction matrix
restr = matrix(1:5, 5, 3)
restr[2, 2:3] = 6:7 # allow drift rates to differ
# fix variance parameters
fixed = matrix(c('sz1', .5, 'sv1', .5), 2, 2)
## Not run: 
# Run D*M analysis
res = estDstarM(data = dat, tt = tt, restr = restr, fixed = fixed)
# Estimate nondecision density
resND = estND(res)
plot(resND)
lines(tt, pdfND, type = 'b', col = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='estObserved'>Estimate observed data density</h2><span id='topic+estObserved'></span>

<h3>Description</h3>

<p>Estimates the density of the observed data by convoluting the estimated decision distributions
with the estimated nondecision distributions. If a traditional analysis was run the argument resND can
be omitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estObserved(
  resDecision,
  resND = NULL,
  data = NULL,
  interpolateND = FALSE,
  tt = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estObserved_+3A_resdecision">resDecision</code></td>
<td>
<p>output of <code><a href="#topic+estDstarM">estDstarM</a></code>.</p>
</td></tr>
<tr><td><code id="estObserved_+3A_resnd">resND</code></td>
<td>
<p>output of <code><a href="#topic+estND">estND</a></code>.</p>
</td></tr>
<tr><td><code id="estObserved_+3A_data">data</code></td>
<td>
<p>Optional. If the data used to estimate the decision model is supplied
additional fitmeasures are calculated.</p>
</td></tr>
<tr><td><code id="estObserved_+3A_interpolatend">interpolateND</code></td>
<td>
<p>Logical. If the decision model and nondecision model have been
estimated on different time grids, should the rougher time grid be interpolated to
match the smaller grid? If FALSE (the default) the decision model will be recalculated
on the grid of the nondecision model. This tends to produce better fit values.</p>
</td></tr>
<tr><td><code id="estObserved_+3A_tt">tt</code></td>
<td>
<p>Optional time grid to recalculate the model densities on. Unused in case of a DstarM analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of class <code>DstarM.fitObs</code> that contains:
</p>
<table role = "presentation">
<tr><td><code>obsNorm</code></td>
<td>
<p>A matrix containing normalized densities of each condition response pair.</p>
</td></tr>
<tr><td><code>obs</code></td>
<td>
<p>A matrix containing unnormalized densities of each condition response pair.</p>
</td></tr>
<tr><td><code>tt</code></td>
<td>
<p>The time grid used.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>A list containing the values of the objective function for the total model ($total),
for the decision model ($Decision) and for the nondecision distribution(s) ($ND).</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>The number of parameters used in the decision model.</p>
</td></tr>
<tr><td><code>obsIdx</code></td>
<td>
<p>A numeric vector containing indices of any not observed condition-response pairs.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data with three stimuli of different difficulty.
# this implies different drift rates across conditions.
# define a time grid. A more reasonable stepsize is .01; this is just for speed.
tt = seq(0, 5, .1)
pars = c(.8, 2, .5, .5, .5, # condition 1
        .8, 3, .5, .5, .5, # condition 2
        .8, 4, .5, .5, .5) # condition 3
pdfND = dbeta(tt, 10, 30)
# simulate data
lst = simData(n = 3e5, pars = pars, tt = tt, pdfND = pdfND, return.pdf = TRUE)
dat = lst$dat
# define restriction matrix
restr = matrix(1:5, 5, 3)
restr[2, 2:3] = 6:7 # allow drift rates to differ
# fix variance parameters
fixed = matrix(c('sz1', .5, 'sv1', .5), 2, 2)
## Not run: 
# Run D*M analysis
resD = estDstarM(dat = dat, tt = tt, restr = restr, fixed = fixed)
# Estimate nondecision density
resND = estND(resD)
# Estimate observed density
resObs = estObserved(resD, resND)
# plot histograms with overlayed
# densities per condition-response pair
plotObserved(resObserved = resObs, data = dat,
            xlim = c(0, 1))
# plot estimated and true densities
plot(resObs, col = rep(1:3, each = 2), xlim = 0:1)
matlines(tt, lst$pdfNormalized, col = rep(1:3, each = 2), lty = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='estQdf'>Estimate quantiles of distribution</h2><span id='topic+estQdf'></span>

<h3>Description</h3>

<p>Estimate quantiles of distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estQdf(p, x, cdf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estQdf_+3A_p">p</code></td>
<td>
<p>A vector of probabilities.</p>
</td></tr>
<tr><td><code id="estQdf_+3A_x">x</code></td>
<td>
<p>The x-axis values corresponding to the cumulative distribution function.</p>
</td></tr>
<tr><td><code id="estQdf_+3A_cdf">cdf</code></td>
<td>
<p>A cumulative distributions function, i.e. output of <code><a href="#topic+estCdf">estCdf</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Quantiles are obtained in the following manner. For p = 0 and p = 1,
the minimum and maximum of x is used. For other probabilities the quantiles are obtained
via <code>q[i] = uniroot(x, cdf - p[i])$root</code>. Y values are interpolated via
<code><a href="stats.html#topic+approxfun">approxfun</a></code>.
</p>


<h3>Value</h3>

<p>Quantiles of cumulative distribution function(s). If the input was a matrix
of cumulative distributions functions, a matrix of quantiles is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = seq(-9, 9, .1) # x-grid
d = dnorm(x) # density functions
p = seq(0, 1, .2) # probabilities of interest
cEst = estCdf(d) # estimate cumulative distribution functions
qEst = estQdf(p = p, x = x, cdf = cEst) # estimate quantiles
plot(x, cEst, bty = 'n', las = 1, type = 'l', ylab = 'Probability') # plot cdf
abline(h = p, v = qEst, col = 1:6, lty = 2) # add lines for p and for obtained quantiles
points(x = qEst, y = p, pch = 18, col = 1:6, cex = 1.75) # add points for intersections

</code></pre>

<hr>
<h2 id='getPdfs'>(Re)Calculate model densities with given parameters and time grid</h2><span id='topic+getPdfs'></span>

<h3>Description</h3>

<p>This function is a convenience function for calculating model pdfs for
multiple sets of parameters at a specified timegrid. If <code>resDecision</code> is supplied,
the density function and any additional arguments for the density function will be
extracted from that object. If <code>pars</code> is missing these will also be extracted from
this object. This function is intended to recalculate model densities at a new timegrid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPdfs(
  resDecision,
  tt,
  pars,
  DstarM = TRUE,
  fun.density = Voss.density,
  args.density = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPdfs_+3A_resdecision">resDecision</code></td>
<td>
<p>output of <code><a href="#topic+estDstarM">estDstarM</a></code>.</p>
</td></tr>
<tr><td><code id="getPdfs_+3A_tt">tt</code></td>
<td>
<p>Time grid to calculate the model densities on.</p>
</td></tr>
<tr><td><code id="getPdfs_+3A_pars">pars</code></td>
<td>
<p>Model parameters, can be a matrix where every column is a set of parameters.</p>
</td></tr>
<tr><td><code id="getPdfs_+3A_dstarm">DstarM</code></td>
<td>
<p>Logical. Do the model pdfs also describe the nondecision distribution?</p>
</td></tr>
<tr><td><code id="getPdfs_+3A_fun.density">fun.density</code></td>
<td>
<p>density function to calculate pdfs from.</p>
</td></tr>
<tr><td><code id="getPdfs_+3A_args.density">args.density</code></td>
<td>
<p>Additional arguments for fun.density</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing model pdfs.
</p>

<hr>
<h2 id='getSter'>Estimate variance of nondecision density</h2><span id='topic+getSter'></span>

<h3>Description</h3>

<p>Estimate variance of nondecision density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSter(res)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSter_+3A_res">res</code></td>
<td>
<p>An object of class <code>D*M</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The object <code>res</code> can either be output from <code>estDstarM</code> or output from <code>estND</code>.
if the former is supplied, <code>getSter</code> attempts to calculate the variance of the
nondecision distribution by subtracting the variance of the model distribution from the
variance of the data distribution. If the latter is supplied, the variance is calculated by
integrating the nondecision distribution.
</p>

<hr>
<h2 id='getTer'>Calculate Mean of the nondecision distribution.</h2><span id='topic+getTer'></span>

<h3>Description</h3>

<p>Calculate Mean of the nondecision distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTer(res, data, formula = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTer_+3A_res">res</code></td>
<td>
<p>An object of class D*M.</p>
</td></tr>
<tr><td><code id="getTer_+3A_data">data</code></td>
<td>
<p>The data object used to create <code>res</code>.</p>
</td></tr>
<tr><td><code id="getTer_+3A_formula">formula</code></td>
<td>
<p>Optional formula argument, for when columns names in the data are different from those used to obtain the results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The object <code>res</code> can either be output from <code>estDstarM</code> or output from <code>estND</code>.
If the former is supplied it is also necessary to supply the data used for the estimation.
The mean will then be estimated by subtracting the mean of the model densities from the mean of the data density.
If the latter is supplied than this is not required; the mean will be calculated by
integrating the nondecision distribution.
</p>


<h3>Value</h3>

<p>A vector containing estimates for the mean of the nondecision densities.
</p>

<hr>
<h2 id='normalize'>Normalize two pdfs</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Normalize two pdfs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x, tt, props = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>Probability density function(s) evaluated at grid <code>x</code>.
Input should be either a vector or matrix. If input is a matrix, each column represents a single pdf.</p>
</td></tr>
<tr><td><code id="normalize_+3A_tt">tt</code></td>
<td>
<p>a numeric grid defined in <code>x</code>.</p>
</td></tr>
<tr><td><code id="normalize_+3A_props">props</code></td>
<td>
<p>the value each density should integrate to.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>tt &lt;- seq(0, 9, length.out = 1e4)
# 2 poper densities
x1 &lt;- cbind(dexp(tt, .5), dexp(tt, 2))
# still 2 poper densities
x2 &lt;- normalize(10*x1, tt)
# 2 densities that integrate to .5
x3 &lt;- normalize(x1, tt, props = c(.5, .5))
# plot the results
matplot(tt, cbind(x1, x2, x3), type = "l", ylab = "density",
        col = rep(1:3, each = 2), lty = rep(1:2, 3), las = 1, bty = "n")
legend("topright", legend = rep(paste0("x", 1:3), each = 2),
       col = rep(1:3, each = 2), lty = rep(1:2, 3), bty = "n")
</code></pre>

<hr>
<h2 id='obsQuantiles'>Calculate model fit</h2><span id='topic+obsQuantiles'></span>

<h3>Description</h3>

<p>This function is nothing but a wrapper for <code><a href="stats.html#topic+quantile">quantile</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obsQuantiles(data, probs = seq(0, 1, 0.01), what = "cr")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="obsQuantiles_+3A_data">data</code></td>
<td>
<p>A dataframe with: a column named <code>rt</code> containing response times in ms,
a column named <code>response</code> containing at most 2 response options, and an
optional column named <code>condition</code> containing a numeric index as to which conditions
observations belong.</p>
</td></tr>
<tr><td><code id="obsQuantiles_+3A_probs">probs</code></td>
<td>
<p>vector of probabilities for which the corresponding values should be called</p>
</td></tr>
<tr><td><code id="obsQuantiles_+3A_what">what</code></td>
<td>
<p>Character. <code>'cr'</code> if the quantiles are to be calculated per condition-response
pair, <code>'c'</code> if the quantiles are to be calculated per condition, and
<code>'r'</code> if the quantiles are to be calculated per response.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>tt = seq(0, 5, .01)
pars = c(.8, 2, .5, .5, .5, # condition 1
        .8, 3, .5, .5, .5,  # condition 2
        .8, 4, .5, .5, .5)  # condition 3
pdfND = dbeta(tt, 10, 30)
# simulate data
data = simData(n = 3e3, pars = pars, tt = tt, pdfND = pdfND)
probs = seq(0, 1, .01)
q = obsQuantiles(data, probs = probs)
matplot(probs, q, type = 'l', las = 1, bty = 'n')
</code></pre>

<hr>
<h2 id='plotObserved'>Plot quantiles of data against model implied quantiles.</h2><span id='topic+plotObserved'></span>

<h3>Description</h3>

<p>Plots histograms for each condition-response pair/ condition/ response
with overlayed estimated densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotObserved(
  resObserved,
  data,
  what = c("cr", "c", "r"),
  layout = NULL,
  main = NULL,
  linesArgs = list(),
  ggplot = FALSE,
  prob = seq(0, 1, 0.01),
  probType = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotObserved_+3A_resobserved">resObserved</code></td>
<td>
<p>output of <code><a href="#topic+estObserved">estObserved</a></code>.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_data">data</code></td>
<td>
<p>The dataset used to estimate the model.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_what">what</code></td>
<td>
<p>What to plot. Can be 'cr' for 'condition-response pairs,
'c' for condition, and 'r' for response.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_layout">layout</code></td>
<td>
<p>An optional layout matrix.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_main">main</code></td>
<td>
<p>an optional vector containing names for each plot.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_linesargs">linesArgs</code></td>
<td>
<p>A list containing named arguments to be passed to <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_ggplot">ggplot</code></td>
<td>
<p>Deprecated and ignored.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_prob">prob</code></td>
<td>
<p>Should a qqplot of observed vs model implied quantiles be plotted?
By default, it is <code>seq(0, 1, .01)</code>, the probabilities between 0 and 1 to compare the
model implied quantiles to the observed quantiles. If this argument is NULL,
then a histogram overlayed with model implied densities will be plotted.
Internally, <code><a href="#topic+estQdf">estQdf</a></code> is used for generating quantiles.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_probtype">probType</code></td>
<td>
<p>A numeric value defining several plotting options. 0 does nothing, 1
removes the 0% quantile, 2 removes the 100% quantile and 3 removes both the 0% and 100% quantile.</p>
</td></tr>
<tr><td><code id="plotObserved_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to hist.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Keep in mind when using <code>what = 'c'</code> or <code>what = 'r'</code> pdfs are simply
averaged, not weighted to the number of observed responses.
</p>


<h3>Value</h3>

<p>if ggplot is FALSE <code>invisible()</code>, otherwise a list
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data with three stimuli of different difficulty.
# this implies different drift rates across conditions.
# define a time grid. A more reasonable stepsize is .01; this is just for speed.
tt = seq(0, 5, .1)
pars = c(.8, 2, .5, .5, .5, # condition 1
        .8, 3, .5, .5, .5, # condition 2
        .8, 4, .5, .5, .5) # condition 3
pdfND = dbeta(tt, 10, 30)
# simulate data
lst = simData(n = 3e5, pars = pars, tt = tt, pdfND = pdfND, return.pdf = TRUE)
dat = lst$dat
# define restriction matrix
restr = matrix(1:5, 5, 3)
restr[2, 2:3] = 6:7 # allow drift rates to differ
# fix variance parameters
fixed = matrix(c('sz1', .5, 'sv1', .5), 2, 2)
## Not run: 
# Run D*M analysis
resD = estDstarM(dat = dat, tt = tt, restr = restr, fixed = fixed)
# Estimate nondecision density
resND = estND(resD)
# Estimate observed density
resObs = estObserved(resD, resND)
# plot histograms with overlayed
# densities per condition-response pair
plotObserved(resObserved = resObs, data = dat,
            xlim = c(0, 1))
# plot estimated and true densities
plot(resObs, col = rep(1:3, each = 2), xlim = 0:1)
matlines(tt, lst$pdfNormalized, col = rep(1:3, each = 2), lty = 2)
# other uses of plotObserved
plotObserved(resObserved = resObs, data = dat, what = 'cr', xlim = c(0, 1))
plotObserved(resObserved = resObs, data = dat, what = 'c', xlim = c(0, 1))
plotObserved(resObserved = resObs, data = dat, what = 'r', xlim = c(0, 1))

## End(Not run)
</code></pre>

<hr>
<h2 id='rtDescriptives'>Descriptives of reaction time data</h2><span id='topic+rtDescriptives'></span>

<h3>Description</h3>

<p>Descriptives of reaction time data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtDescriptives(formula = NULL, data, plot = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rtDescriptives_+3A_formula">formula</code></td>
<td>
<p>A formula object of the form: <code>binary response ~ reaction time + condition1 * condition2</code></p>
</td></tr>
<tr><td><code id="rtDescriptives_+3A_data">data</code></td>
<td>
<p>A dataframe for looking up data specified in formula.
For backwards compatibility this can also be with: a column named <code>rt</code> containing response times in ms,
a column named <code>response</code> containing at most 2 response options, and an
optional column named <code>condition</code> containing a numeric index as to which conditions
observations belong.</p>
</td></tr>
<tr><td><code id="rtDescriptives_+3A_plot">plot</code></td>
<td>
<p>Logical, should a density plot of all condition-response pairs be made?</p>
</td></tr>
<tr><td><code id="rtDescriptives_+3A_verbose">verbose</code></td>
<td>
<p>Logical, should a table of counts and proportions be printed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function and <code><a href="#topic+rtHist">rtHist</a></code> are helper functions to inspect raw data.
</p>


<h3>Value</h3>

<p>Invisibly returns an object of class 'D*M'. It's first element is <code>table</code> and contains raw counts and proportions for
condition response pairs, conditions, and responses. It's second element <code>plot</code> contains a ggplot object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt &lt;- seq(0, 5, .01)
pars &lt;- matrix(.5, 5, 2)
pars[1, ] &lt;- 1
pars[2, ] &lt;- c(0, 2)
dat &lt;- simData(n = 3e3, pars = pars, tt = tt, pdfND = dbeta(tt, 10, 30))
x &lt;- rtDescriptives(data = dat)

print(x$table, what = 'cr')
print(x$table, what = 'c')
print(x$table, what = 'r')
</code></pre>

<hr>
<h2 id='rtHist'>Make histograms of reaction time data</h2><span id='topic+rtHist'></span>

<h3>Description</h3>

<p>Make histograms of reaction time data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtHist(data, what = "cr", layout = NULL, nms = NULL, ggplot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rtHist_+3A_data">data</code></td>
<td>
<p>A reaction time dataset. Must be a dataframe with $rt, $condition
and $response.</p>
</td></tr>
<tr><td><code id="rtHist_+3A_what">what</code></td>
<td>
<p>@param what What to plot. Can be 'cr' for 'condition-response pairs,
'c' for condition, and 'r' for response.</p>
</td></tr>
<tr><td><code id="rtHist_+3A_layout">layout</code></td>
<td>
<p>An optional layout.</p>
</td></tr>
<tr><td><code id="rtHist_+3A_nms">nms</code></td>
<td>
<p>An optional vector of names for each plot. If omitted the names
will be based on the contents of <code>data$condition</code> and/or <code>data$response</code>.</p>
</td></tr>
<tr><td><code id="rtHist_+3A_ggplot">ggplot</code></td>
<td>
<p>ggplot Logical, should ggplot2 be used instead of base R graphics? If set to TRUE,
some arguments from <code>linesArgs</code> and <code>...</code> will be ignored (but can be added
to plots manually).</p>
</td></tr>
<tr><td><code id="rtHist_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to <code>hist</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function and <code><a href="#topic+rtDescriptives">rtDescriptives</a></code> are helper functions to inspect raw data.
</p>


<h3>Value</h3>

<p>invisible()
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt = seq(0, 5, .01)
dat = simData(n = 3e4, pars = rep(.5, 5), tt = tt, pdfND = dbeta(tt, 10, 30))
rtHist(dat, breaks = tt, xlim = c(0, 1))
</code></pre>

<hr>
<h2 id='simData'>Simulate data from a given density function via multinomial sampling</h2><span id='topic+simData'></span>

<h3>Description</h3>

<p>Simulate data from a given density function via multinomial sampling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simData(
  n,
  pars,
  tt,
  pdfND,
  fun.density = Voss.density,
  args.density = list(prec = 3),
  npars = 5,
  return.pdf = FALSE,
  normalizePdfs = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simData_+3A_n">n</code></td>
<td>
<p>Number of observations to be sampled</p>
</td></tr>
<tr><td><code id="simData_+3A_pars">pars</code></td>
<td>
<p>Parameter values for the density function to be evaluated with. <code>length(pars)</code> must be a multiple of npars.</p>
</td></tr>
<tr><td><code id="simData_+3A_tt">tt</code></td>
<td>
<p>time grid on which the density function will be evaluated. Responses not in this time grid cannot appear.</p>
</td></tr>
<tr><td><code id="simData_+3A_pdfnd">pdfND</code></td>
<td>
<p>either a vector of length tt specifying the nondecision density for all condition-response pairs,
or a matrix where columns corresponds to the nondecision densities of condition-response pairs. Supplying <code>NULL</code> implies no nondecision distribution.</p>
</td></tr>
<tr><td><code id="simData_+3A_fun.density">fun.density</code></td>
<td>
<p>Density function to use.</p>
</td></tr>
<tr><td><code id="simData_+3A_args.density">args.density</code></td>
<td>
<p>Additional arguments to be passed to <code>fun.density</code>, aside from <code>tt</code>, <code>pars</code>, and a boundary argument ('upper' or 'lower')</p>
</td></tr>
<tr><td><code id="simData_+3A_npars">npars</code></td>
<td>
<p>Number of parameters <code>fun.density</code> must be evaluated with. If <code>length(pars) &gt; npars</code> each <code>npars</code> values in <code>pars</code> will be seen as the parameter values of a condition.</p>
</td></tr>
<tr><td><code id="simData_+3A_return.pdf">return.pdf</code></td>
<td>
<p>Logical, if TRUE <code>genData</code> returns a list containing the probability density function used and the data, if FALSE <code>genData</code> returns a dataframe with simulated data.</p>
</td></tr>
<tr><td><code id="simData_+3A_normalizepdfs">normalizePdfs</code></td>
<td>
<p>Logical, should the pdf of the nondecision distribution be normalized?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulate data via multinomial sampling.
The response options to sample from should be provided in <code>tt</code>.
The number of conditions is defined as <code>length(pars) / npars</code>.
</p>


<h3>Value</h3>

<p>A sorted dataframe where rows represent trials. It contains: a column named rt
containing reaction times in seconds, a column named response containing either
response option lower or upper, and a column named condition indicating which
condition a trials belongs to. If <code>return.pdf</code> is TRUE it returns a list where the
first element is the sorted dataframe, the second through the fifth elements are lists
that contain densities used for simulating data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt = seq(0, 5, .01)
pdfND = dbeta(tt, 10, 30)
n = 100
pars = c(1, 2, .5, .5, .5)
dat = simData(n, pars, tt, pdfND)
head(dat)
</code></pre>

<hr>
<h2 id='testFun'>Test fun.density with lower and upper bounds</h2><span id='topic+testFun'></span>

<h3>Description</h3>

<p>Test fun.density with lower and upper bounds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testFun(fun.density, lower, upper, args = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testFun_+3A_fun.density">fun.density</code></td>
<td>
<p>A density function to be evaluated.</p>
</td></tr>
<tr><td><code id="testFun_+3A_lower">lower</code></td>
<td>
<p>Lower bounds of the parameter space with which <code>fun.density</code> can be evaluated.</p>
</td></tr>
<tr><td><code id="testFun_+3A_upper">upper</code></td>
<td>
<p>Upper bounds of the parameter space with which <code>fun.density</code> can be evaluated.</p>
</td></tr>
<tr><td><code id="testFun_+3A_args">args</code></td>
<td>
<p>Additional arguments for fun.density.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A function that is called whenever a nondefault density function is passed to <code>DstarM</code>. It does some rough error checking.
</p>


<h3>Value</h3>

<p>Returns TRUE if no errors occurred, otherwise returns an error message
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lower = c(.5, -6, .1, 0, 0)
upper = c(2, 6, .99, .99, 10)
args = list(t = seq(0, 5, .01), pars = lower, boundary = 'lower',
DstarM = TRUE)
testFun(fun.density = Voss.density, lower = lower, upper = upper,
args = args)
# TRUE
</code></pre>

<hr>
<h2 id='upgradeDstarM'>Upgrade a DstarM object for backwards compatibility</h2><span id='topic+upgradeDstarM'></span>

<h3>Description</h3>

<p>Upgrade a DstarM object for backwards compatibility
</p>


<h3>Usage</h3>

<pre><code class='language-R'>upgradeDstarM(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="upgradeDstarM_+3A_x">x</code></td>
<td>
<p>an object of class <code>D*M</code> or <code>DstarM</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>DstarM.fitD</code>, <code>DstarM.fitND</code>, or <code>DstarM.fitObs</code>.
</p>

<hr>
<h2 id='Voss.density'>Calculate model density for a given set of parameters</h2><span id='topic+Voss.density'></span><span id='topic+LBA.density'></span><span id='topic+Wiener.density'></span>

<h3>Description</h3>

<p>Calculate model density for a given set of parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Voss.density(t, pars, boundary, DstarM = TRUE, prec = 3)

LBA.density(t, pars, boundary, DstarM = TRUE, ...)

Wiener.density(t, pars, boundary, DstarM)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Voss.density_+3A_t">t</code></td>
<td>
<p>Time grid for density to be calculated on.</p>
</td></tr>
<tr><td><code id="Voss.density_+3A_pars">pars</code></td>
<td>
<p>Parameter vector where (if <code>DstarM == TRUE</code>) the first index contains the boundary parameter, the second contains the drift speed, the third contains the relative starting point, the fourth contains a proportion of the maximum size of the variance on the relative starting point, the fifth contains the standard deviation of the drift speed.
if <code>DstarM == FALSE</code> then third index of <code>pars</code> contains the Ter, the fifth the drift speed, the the sixth contains a proportion of the maximum size of the variance on the relative starting point, the fifth contains the standard deviation of the drift speed, and the seventh contains a proportion of the maximum variance of the Ter.</p>
</td></tr>
<tr><td><code id="Voss.density_+3A_boundary">boundary</code></td>
<td>
<p>For which response option will the density be calculated? Either 'upper' or 'lower'.</p>
</td></tr>
<tr><td><code id="Voss.density_+3A_dstarm">DstarM</code></td>
<td>
<p>Logical, see <code>pars</code>.</p>
</td></tr>
<tr><td><code id="Voss.density_+3A_prec">prec</code></td>
<td>
<p>Precision with which the density is calculated. Corresponds roughly to the number of decimals accurately calculated.</p>
</td></tr>
<tr><td><code id="Voss.density_+3A_...">...</code></td>
<td>
<p>Other arguments, see <code>dLBA</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are examples of what <code>fun.density</code> should look like.
<code>Voss.density</code> is an adaptation of <code>ddiffusion</code>,
<code>LBA.density</code> is an adaptation of <code>dLBA</code>, and
<code>wiener.density</code> is an adaptation of <code>dwiener</code>.
To improve speed one can remove error handling.
Normally error handling is useful, however
because differential evolution can result in an incredible number of
function evaluations (more than 10.000) it is recommended to omit error handling in custom
density functions. <code>estDstarM</code> will apply some internal error checks
(see <code><a href="#topic+testFun">testFun</a></code>) on the density functions before starting differential
evolution. A version of <code>ddifusion</code> without error handling can be found in
the source code (commented out to pass R check). Note that for in <code>Voss.density</code>
if DstarM == FALSE nondecision parameters are implemented manually and might differ
from from how they are implemented in other packages. The parameter <code>t0</code>
specifies the mean of a uniform distribution and <code>st0</code> specifies the relative
size of this uniform distribution. To obtain the lower and upper range of the
uniform distribution calculate a = t0 - t0*st0, and b = t0 + t0*st0.
</p>


<h3>Value</h3>

<p>A numeric vector of length <code>length(t)</code> containing a density.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>t = seq(0, .75, .01)
V.pars = c(1, 2, .5, .5, .5)
L.pars = c(1, .5, 2, 1, 1, 1)
W.pars = V.pars[1:3]
V1 = Voss.density(t = t, pars = V.pars, boundary = 'upper', DstarM = TRUE)
V2 = Voss.density(t = t, pars = V.pars, boundary = 'lower', DstarM = TRUE)
L1 = LBA.density(t = t, pars = L.pars, boundary = 'upper', DstarM = TRUE)
L2 = LBA.density(t = t, pars = L.pars, boundary = 'lower', DstarM = TRUE)
W1 = Wiener.density(t = t, pars = W.pars, boundary = 'upper', DstarM = TRUE)
W2 = Wiener.density(t = t, pars = W.pars, boundary = 'lower', DstarM = TRUE)
densities = cbind(V1, V2, L1, L2, W1, W2)
matplot(t, densities, type = 'b', ylab = 'Density', lty = 1, las = 1, bty = 'n',
        col = rep(1:3, each = 2), pch = c(0, 15, 1, 16, 2, 17), cex = .8,
        main = 'Model densities')
legend('topright', legend = c('Voss', 'LBA', 'RWiener'), lty = 1,
       pch = 15:17, col = 1:3, bty = 'n')



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
