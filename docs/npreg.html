<!DOCTYPE html><html><head><title>Help for package npreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {npreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bin.sample'>
<p>Bin Sample a Vector, Matrix, or Data Frame</p></a></li>
<li><a href='#boot'>
<p>Bootstrap a Fit Smooth</p></a></li>
<li><a href='#coef'>
<p>Extract Smooth Model Coefficients</p></a></li>
<li><a href='#deviance'>
<p>Smooth Model Deviance</p></a></li>
<li><a href='#diagnostic.plots'>
<p>Plot Nonparametric Regression Diagnostics</p></a></li>
<li><a href='#fitted'>
<p>Extract Smooth Model Fitted Values</p></a></li>
<li><a href='#gsm'>
<p>Fit a Generalized Smooth Model</p></a></li>
<li><a href='#model.matrix'>
<p>Construct Design Matrix for Fit Model</p></a></li>
<li><a href='#msqrt'>
<p>Matrix (Inverse?) Square Root</p></a></li>
<li><a href='#NegBin'>
<p>Family Function for Negative Binomial</p></a></li>
<li><a href='#nominal'>
<p>Nominal Smoothing Spline Basis and Penalty</p></a></li>
<li><a href='#npreg-internals'><p>Internal Functions for &quot;npreg&quot;</p></a></li>
<li><a href='#number2color'>
<p>Map Numbers to Colors</p></a></li>
<li><a href='#ordinal'>
<p>Ordinal Smoothing Spline Basis and Penalty</p></a></li>
<li><a href='#plot.ss'>
<p>Plot method for Smoothing Spline Fit and Bootstrap</p></a></li>
<li><a href='#plotci'>
<p>Generic X-Y Plotting with Confidence Intervals</p></a></li>
<li><a href='#polynomial'>
<p>Polynomial Smoothing Spline Basis and Penalty</p></a></li>
<li><a href='#predict.gsm'>
<p>Predict method for Generalized Smooth Model Fits</p></a></li>
<li><a href='#predict.sm'>
<p>Predict method for Smooth Model Fits</p></a></li>
<li><a href='#predict.ss'>
<p>Predict method for Smoothing Spline Fits</p></a></li>
<li><a href='#psolve'>
<p>Pseudo-Solve a System of Equations</p></a></li>
<li><a href='#residuals'>
<p>Extract Model Residuals</p></a></li>
<li><a href='#sm'>
<p>Fit a Smooth Model</p></a></li>
<li><a href='#smooth.influence'>
<p>Nonparametric Regression Diagnostics</p></a></li>
<li><a href='#smooth.influence.measures'>
<p>Nonparametric Regression Deletion Diagnostics</p></a></li>
<li><a href='#spherical'>
<p>Spherical Spline Basis and Penalty</p></a></li>
<li><a href='#ss'>
<p>Fit a Smoothing Spline</p></a></li>
<li><a href='#summary'>
<p>Summary methods for Fit Models</p></a></li>
<li><a href='#theta.mle'>
<p>MLE of Theta for Negative Binomial</p></a></li>
<li><a href='#thinplate'>
<p>Thin Plate Spline Basis and Penalty</p></a></li>
<li><a href='#varimp'>
<p>Variable Importance Indices</p></a></li>
<li><a href='#varinf'>
<p>Variance Inflation Factors</p></a></li>
<li><a href='#vcov'>
<p>Calculate Variance-Covariance Matrix for a Fitted Smooth Model</p></a></li>
<li><a href='#weights'>
<p>Extract Smooth Model Weights</p></a></li>
<li><a href='#wtd.mean'>
<p>Weighted Arithmetic Mean</p></a></li>
<li><a href='#wtd.quantile'>
<p>Weighted Quantiles</p></a></li>
<li><a href='#wtd.var'>
<p>Weighted Variance and Standard Deviation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nonparametric Regression via Smoothing Splines</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-9</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-20</td>
</tr>
<tr>
<td>Author:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Multiple and generalized nonparametric regression using smoothing spline ANOVA models and generalized additive models, as described in Helwig (2020) &lt;<a href="https://doi.org/10.4135%2F9781526421036885885">doi:10.4135/9781526421036885885</a>&gt;. Includes support for Gaussian and non-Gaussian responses, smoothers for multiple types of predictors, interactions between smoothers of mixed types, eight different methods for smoothing parameter selection, and flexible tools for prediction and inference.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel, SuppDists</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-20 14:16:19 UTC; nate</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-20 23:00:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='bin.sample'>
Bin Sample a Vector, Matrix, or Data Frame
</h2><span id='topic+bin.sample'></span>

<h3>Description</h3>

<p>Bin elements of a vector (or rows of a matrix/data frame) and randomly sample a specified number of elements from each bin. Returns sampled data and (optionally) indices of sampled data and/or breaks for defining bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bin.sample(x, nbin = 5, size = 1, equidistant = FALSE, 
           index.return = FALSE, breaks.return = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bin.sample_+3A_x">x</code></td>
<td>

<p>Vector, matrix, or data frame to bin sample. Factors are allowed.
</p>
</td></tr>
<tr><td><code id="bin.sample_+3A_nbin">nbin</code></td>
<td>

<p>Number of bins for each variable (defaults to 5 bins for each dimension of <code>x</code>). If <code>length(bins) != ncol(x)</code>, then <code>nbin[1]</code> is used for each variable. 
</p>
</td></tr>
<tr><td><code id="bin.sample_+3A_size">size</code></td>
<td>

<p>Size of sample to randomly draw from each bin (defaults to 1).
</p>
</td></tr>
<tr><td><code id="bin.sample_+3A_equidistant">equidistant</code></td>
<td>

<p>Should bins be defined equidistantly for each predictor? If <code>FALSE</code> (default), sample quantiles define bins for each predictor. If <code>length(equidistant) != ncol(x)</code>, then <code>equidistant[1]</code> is used for each variable.
</p>
</td></tr>
<tr><td><code id="bin.sample_+3A_index.return">index.return</code></td>
<td>

<p>If <code>TRUE</code>, returns the (row) indices of the bin sampled observations.
</p>
</td></tr>
<tr><td><code id="bin.sample_+3A_breaks.return">breaks.return</code></td>
<td>

<p>If <code>TRUE</code>, returns the (lower bounds of the) breaks for the binning.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a single variable, the unidimensional bins are defined using the <code><a href="base.html#topic+.bincode">.bincode</a></code> function. For multiple variables, the multidimensional bins are defined using the algorithm described in the appendix of Helwig et al. (2015), which combines the unidimensional bins (calculated via <code><a href="base.html#topic+.bincode">.bincode</a></code>) into a multidimensional bin code.
</p>


<h3>Value</h3>

<p>If <code>index.return = FALSE</code> and <code>breaks.return = FALSE</code>, returns the bin sampled <code>x</code> observations.
</p>
<p>If <code>index.return = TRUE</code> and/or <code>breaks.return = TRUE</code>, returns a list with elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>bin sampled <code>x</code> observations.</p>
</td></tr>
<tr><td><code>ix</code></td>
<td>
<p>row indices of bin sampled observations (if <code>index.return = TRUE</code>).</p>
</td></tr>
<tr><td><code>bx</code></td>
<td>
<p>lower bounds of breaks defining bins (if <code>breaks.return = TRUE</code>).</p>
</td></tr>





</table>


<h3>Note</h3>

<p>For factors, the number of bins is automatically defined to be the number of levels.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E., Gao, Y., Wang, S., &amp; Ma, P. (2015). Analyzing spatiotemporal trends in social media data via smoothing spline analysis of variance. <em>Spatial Statistics, 14</em>(C), 491-504. <a href="https://doi.org/10.1016/j.spasta.2015.09.002">doi:10.1016/j.spasta.2015.09.002</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+.bincode">.bincode</a></code> for binning a numeric vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########
### unidimensional binning

# generate data
x &lt;- seq(0, 1, length.out = 101)

# bin sample (default)
set.seed(1)
bin.sample(x)

# bin sample (return indices)
set.seed(1)
xs &lt;- bin.sample(x, index.return = TRUE)
xs$x             # sampled data
x[xs$ix]         # indexing sampled data

# bin sample (return indices and breaks)
set.seed(1)
xs &lt;- bin.sample(x, index.return = TRUE, breaks.return = TRUE)
xs$x             # sampled data
x[xs$ix]         # indexing sampled data
xs$bx            # breaks



##########   EXAMPLE 2   ##########
### bidimensional binning

# generate data
x &lt;- expand.grid(x1 = seq(0, 1, length.out = 101),
                 x2 = seq(0, 1, length.out = 101))

# bin sample (default)
set.seed(1)
bin.sample(x)

# bin sample (return indices)
set.seed(1)
xs &lt;- bin.sample(x, index.return = TRUE)
xs$x             # sampled data
x[xs$ix,]        # indexing sampled data

# bin sample (return indices and breaks)
set.seed(1)
xs &lt;- bin.sample(x, index.return = TRUE, breaks.return = TRUE)
xs$x             # sampled data
x[xs$ix,]        # indexing sampled data
xs$bx            # breaks

# plot breaks and 25 bins
plot(xs$bx, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "x1", ylab = "x2", main = "25 bidimensional bins")
grid()
text(xs$bx + 0.1, labels = 1:25)

</code></pre>

<hr>
<h2 id='boot'>
Bootstrap a Fit Smooth
</h2><span id='topic+boot'></span><span id='topic+boot.ss'></span><span id='topic+boot.sm'></span><span id='topic+boot.gsm'></span>

<h3>Description</h3>

<p>Bootstraps a fit nonparametric regression model to form confidence intervals (BCa or percentile) and standard error estimates. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
boot(object, statistic, ..., R = 9999, level = 0.95, bca = TRUE, 
     method = c("cases", "resid", "param"), fix.lambda = TRUE, cov.mat = FALSE, 
     boot.dist = FALSE, verbose = TRUE, parallel = FALSE, cl = NULL)

## S3 method for class 'sm'
boot(object, statistic, ..., R = 9999, level = 0.95, bca = TRUE, 
     method = c("cases", "resid", "param"), fix.lambda = TRUE, 
     fix.thetas = TRUE, cov.mat = FALSE, boot.dist = FALSE, 
     verbose = TRUE, parallel = FALSE, cl = NULL)
     
## S3 method for class 'gsm'
boot(object, statistic, ..., R = 9999, level = 0.95, bca = TRUE, 
     method = c("cases", "resid", "param"), fix.lambda = TRUE, 
     fix.thetas = TRUE, cov.mat = FALSE, boot.dist = FALSE, 
     verbose = TRUE, parallel = FALSE, cl = NULL)     
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot_+3A_object">object</code></td>
<td>

<p>a fit from <code><a href="#topic+ss">ss</a></code> (smoothing spline), <code><a href="#topic+sm">sm</a></code> (smooth model), or <code><a href="#topic+gsm">gsm</a></code> (generalized smooth model)
</p>
</td></tr>
<tr><td><code id="boot_+3A_statistic">statistic</code></td>
<td>

<p>a function to compute the statistic (see Details)
</p>
</td></tr>
<tr><td><code id="boot_+3A_...">...</code></td>
<td>

<p>additional arguments to <code>statistic</code> function (optional)
</p>
</td></tr>
<tr><td><code id="boot_+3A_r">R</code></td>
<td>

<p>number of bootstrap resamples used to form bootstrap distribution
</p>
</td></tr>
<tr><td><code id="boot_+3A_level">level</code></td>
<td>

<p>confidence level for bootstrap confidence intervals
</p>
</td></tr>
<tr><td><code id="boot_+3A_bca">bca</code></td>
<td>

<p>logical indicating whether to calculate BCa (default) or percentile intervals
</p>
</td></tr>
<tr><td><code id="boot_+3A_method">method</code></td>
<td>

<p>resampling method used to form bootstrap distribution
</p>
</td></tr>
<tr><td><code id="boot_+3A_fix.lambda">fix.lambda</code></td>
<td>

<p>logical indicating whether the smoothing parameter should be fixed (default) or re-estimated for each bootstrap sample
</p>
</td></tr>
<tr><td><code id="boot_+3A_fix.thetas">fix.thetas</code></td>
<td>

<p>logical indicating whether the &quot;extra&quot; smoothing parameters should be fixed (default) or re-estimated for each bootstrap sample. Only applicable to <code><a href="#topic+sm">sm</a></code> and <code><a href="#topic+gsm">gsm</a></code> objects with multiple penalized terms.
</p>
</td></tr>
<tr><td><code id="boot_+3A_cov.mat">cov.mat</code></td>
<td>

<p>logical indicating whether the bootstrap estimate of the covariance matrix should be returned
</p>
</td></tr>
<tr><td><code id="boot_+3A_boot.dist">boot.dist</code></td>
<td>

<p>logical indicating whether the bootstrap distribution should be returned
</p>
</td></tr>
<tr><td><code id="boot_+3A_verbose">verbose</code></td>
<td>

<p>logical indicating whether the bootstrap progress bar should be printed
</p>
</td></tr>
<tr><td><code id="boot_+3A_parallel">parallel</code></td>
<td>

<p>logical indicating if the <code><a href="lattice.html#topic+parallel">parallel</a></code> package should be used for parallel computing (of the bootstrap distribution). Defaults to FALSE, which implements sequential computing.
</p>
</td></tr>
<tr><td><code id="boot_+3A_cl">cl</code></td>
<td>

<p>cluster for parallel computing, which is used when <code>parallel = TRUE</code>. Note that if <code>parallel = TRUE</code> and <code>cl = NULL</code>, then the cluster is defined as <code>makeCluster(detectCores())</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>statistic</code> function must satisfy the following two requirements:
</p>
<p>(1) the first input must be the <code>object</code> of class <code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, or <code><a href="#topic+gsm">gsm</a></code>
</p>
<p>(2) the output must be a scalar or vector calculated from the <code>object</code>
</p>
<p>In most applications, the <code>statistic</code> function will be the model predictions at some user-specified <code>newdata</code>, which can be passed to <code>statistic</code> using the <code>...</code> argument.
</p>
<p>If <code>statistic</code> is not provided, then the function is internally defined to be the model predictions at an equidistance sequence (for <code><a href="#topic+ss">ss</a></code> objects) or the training data predictor scores (for <code><a href="#topic+sm">sm</a></code> and <code><a href="#topic+gsm">gsm</a></code> objects).
</p>


<h3>Value</h3>

<p>Produces an object of class 'boot.ss', 'boot.sm', or 'boot.gsm', with the following elements:
</p>
<table>
<tr><td><code>t0</code></td>
<td>
<p>Observed statistic, computed using <code>statistic(object, ...)</code></p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Bootstrap estimate of the standard error</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>Bootstrap estimate of the bias</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>Bootstrap estimate of the covariance (if <code>cov.mat = TRUE</code>)</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>Bootstrap estimate of the confidence interval</p>
</td></tr>
<tr><td><code>boot.dist</code></td>
<td>
<p>Bootstrap distribution of statistic (if <code>boot.dist = TRUE</code>)</p>
</td></tr>
<tr><td><code>bias.correct</code></td>
<td>
<p>Bias correction factor for BCa confidence interval.</p>
</td></tr>
<tr><td><code>acceleration</code></td>
<td>
<p>Acceleration parameter for BCa confidence interval.</p>
</td></tr>
</table>
<p>The output list also contains the elements <code>object</code>, <code>R</code>, <code>level</code>, <code>bca</code>, <code>method</code>, <code>fix.lambda</code>, and <code>fix.thetas</code>, all of which are the same as the corresponding input arguments.
</p>


<h3>Note</h3>

<p>For <code><a href="#topic+gsm">gsm</a></code> objects, requesting <code>method = "resid"</code> uses a variant of the one-step technique described in Moulton and Zeger (1991), which forms the bootstrap estimates of the coefficients without refitting the model.
</p>
<p>As a result, when bootstrapping <code><a href="#topic+gsm">gsm</a></code> objects with <code>method = "resid"</code>:
</p>
<p>(1) it is necessary to set <code>fix.lambda = TRUE</code> and <code>fix.thetas = TRUE</code>
</p>
<p>(2) any logical <code>statistic</code> must depend on the model <code>coefficients</code>, e.g., through the model predictions.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap Methods and Their Application</em>. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511802843">doi:10.1017/CBO9780511802843</a>
</p>
<p>Efron, B., &amp; Tibshirani, R. J. (1994). <em>An Introduction to the Boostrap</em>. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/9780429246593">doi:10.1201/9780429246593</a>
</p>
<p>Moulton, L. H., &amp; Zeger, S. L. (1991). Bootstrapping generalized linear models. <em>Computational Statistics &amp; Data Analysis, 11</em>(1), 53-63. <a href="https://doi.org/10.1016/0167-9473%2891%2990052-4">doi:10.1016/0167-9473(91)90052-4</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code> for fitting &quot;ss&quot; (smoothing spline) objects
</p>
<p><code><a href="#topic+sm">sm</a></code> for fitting &quot;sm&quot; (smooth model) objects
</p>
<p><code><a href="#topic+gsm">gsm</a></code> for fitting &quot;gsm&quot; (generalized smooth model) objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##########   EXAMPLE 1   ##########
### smoothing spline

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit smoothing spline
ssfit &lt;- ss(x, y, nknots = 10)

# nonparameteric bootstrap cases
set.seed(0)
boot.cases &lt;- boot(ssfit)

# nonparameteric bootstrap residuals
set.seed(0)
boot.resid &lt;- boot(ssfit, method = "resid")

# parameteric bootstrap residuals
set.seed(0)
boot.param &lt;- boot(ssfit, method = "param")

# plot results
par(mfrow = c(1, 3))
plot(boot.cases, main = "Cases")
plot(boot.resid, main = "Residuals")
plot(boot.param, main = "Parametric")



##########   EXAMPLE 2   ##########
### smooth model

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit smoothing spline
smfit &lt;- sm(y ~ x, knots = 10)

# define statistic (to be equivalent to boot.ss default)
newdata &lt;- data.frame(x = seq(0, 1, length.out = 201))
statfun &lt;- function(object, newdata) predict(object, newdata)

# nonparameteric bootstrap cases
set.seed(0)
boot.cases &lt;- boot(smfit, statfun, newdata = newdata)

# nonparameteric bootstrap residuals
set.seed(0)
boot.resid &lt;- boot(smfit, statfun, newdata = newdata, method = "resid")

# parameteric bootstrap residuals (R = 99 for speed)
set.seed(0)
boot.param &lt;- boot(smfit, statfun, newdata = newdata, method = "param")
                   
# plot results
par(mfrow = c(1, 3))
plotci(newdata$x, boot.cases$t0, ci = boot.cases$ci, main = "Cases")
plotci(newdata$x, boot.resid$t0, ci = boot.resid$ci, main = "Residuals")
plotci(newdata$x, boot.param$t0, ci = boot.param$ci, main = "Parametric")



##########   EXAMPLE 3   ##########
### generalized smooth model

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit smoothing spline
gsmfit &lt;- gsm(y ~ x, knots = 10)

# define statistic (to be equivalent to boot.ss default)
newdata &lt;- data.frame(x = seq(0, 1, length.out = 201))
statfun &lt;- function(object, newdata) predict(object, newdata)

# nonparameteric bootstrap cases
set.seed(0)
boot.cases &lt;- boot(gsmfit, statfun, newdata = newdata)

# nonparameteric bootstrap residuals
set.seed(0)
boot.resid &lt;- boot(gsmfit, statfun, newdata = newdata, method = "resid")

# parameteric bootstrap residuals
set.seed(0)
boot.param &lt;- boot(gsmfit, statfun, newdata = newdata,  method = "param")
                   
# plot results
par(mfrow = c(1, 3))
plotci(newdata$x, boot.cases$t0, ci = boot.cases$ci, main = "Cases")
plotci(newdata$x, boot.resid$t0, ci = boot.resid$ci, main = "Residuals")
plotci(newdata$x, boot.param$t0, ci = boot.param$ci, main = "Parametric")

## End(Not run)

</code></pre>

<hr>
<h2 id='coef'>
Extract Smooth Model Coefficients
</h2><span id='topic+coef.ss'></span><span id='topic+coef.sm'></span><span id='topic+coef.gsm'></span>

<h3>Description</h3>

<p>Extracts basis function coefficients from a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gsm'
coef(object, ...)

## S3 method for class 'sm'
coef(object, ...)

## S3 method for class 'ss'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef_+3A_object">object</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="coef_+3A_...">...</code></td>
<td>

<p>other arugments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For &quot;ss&quot; objects, the coefficient vector will be of length <code class="reqn">m + q</code> where <code>m</code> is the dimension of the null space and <code class="reqn">q</code> is the number of knots used for the fit.
</p>
<p>For &quot;sm&quot; and &quot;gsm&quot; objects, the coefficient vector will be of length <code class="reqn">m + q</code> if the <code>tprk = TRUE</code> (default). Otherwise the length will depend on the model formula and marginal knot placements. 
</p>


<h3>Value</h3>

<p>Coefficients extracted from the model <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Chambers, J. M. and Hastie, T. J. (1992) <em>Statistical Models in S</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code>
</p>
<p><code><a href="stats.html#topic+model.matrix">model.matrix</a></code>, <code><a href="stats.html#topic+fitted.values">fitted.values</a></code>, <code><a href="stats.html#topic+residuals">residuals</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# smoothing spline
mod.ss &lt;- ss(x, y, nknots = 10)
fit.ss &lt;- fitted(mod.ss)
coef.ss &lt;- coef(mod.ss)
X.ss &lt;- model.matrix(mod.ss)
mean((fit.ss - X.ss %*% coef.ss)^2)

# smooth model
mod.sm &lt;- sm(y ~ x, knots = 10)
fit.sm &lt;- fitted(mod.sm)
coef.sm &lt;- coef(mod.sm)
X.sm &lt;- model.matrix(mod.sm)
mean((fit.sm - X.sm %*% coef.sm)^2)

# generalized smooth model (family = gaussian)
mod.gsm &lt;- gsm(y ~ x, knots = 10)
fit.gsm &lt;- fitted(mod.gsm)
coef.gsm &lt;- coef(mod.gsm)
X.gsm &lt;- model.matrix(mod.gsm)
mean((fit.gsm - X.gsm %*% coef.gsm)^2)

</code></pre>

<hr>
<h2 id='deviance'>
Smooth Model Deviance
</h2><span id='topic+deviance.gsm'></span><span id='topic+deviance.sm'></span><span id='topic+deviance.ss'></span>

<h3>Description</h3>

<p>Returns the deviance from a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gsm'
deviance(object, ...)

## S3 method for class 'sm'
deviance(object, ...)

## S3 method for class 'ss'
deviance(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deviance_+3A_object">object</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="deviance_+3A_...">...</code></td>
<td>

<p>other arugments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>ss</code> and <code>sm</code> objects, the deviance is caculated assuming iid Gaussian errors. 
</p>
<p>For <code>gsm</code> objects, the deviance is calculated by summing the squared deviance residuals, which are calculated using <code>family(object)$dev.resid</code>
</p>


<h3>Value</h3>

<p>Deviance of the model <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Chambers, J. M. and Hastie, T. J. (1992) <em>Statistical Models in S</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code>
</p>
<p><code><a href="stats.html#topic+fitted.values">fitted.values</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for 'ss' and 'sm' objects, this function is defined as
function(object, ...){
    sum(weighted.residuals(object)^2, na.rm = TRUE)
  }
  
## for 'gsm' objects, this function is defined as
function(object, ...){
    object$deviance
  }
</code></pre>

<hr>
<h2 id='diagnostic.plots'>
Plot Nonparametric Regression Diagnostics
</h2><span id='topic+diagnostic.plots'></span>

<h3>Description</h3>

<p>Six regression diagnostic plots for a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagnostic.plots(x, which = c(1, 2, 3, 5), 
           caption = list("Residuals vs Fitted", 
                          "Normal Q-Q", "Scale-Location", 
                          "Cook's distance", "Residuals vs Leverage", 
                          "Cook's dist vs Variance ratio"), 
           panel = if (add.smooth) function(x, y, ...) 
                      panel.smooth(x, y, iter = iter.smooth, ...) 
                   else points, 
           sub.caption = NULL, main = "", 
           ask = prod(par("mfcol")) &lt; length(which) &amp;&amp; dev.interactive(), 
           ..., id.n = 3, labels.id = names(residuals(x)), cex.id = 0.75, cex.pt = 1,
           qqline = TRUE, cook.levels = c(0.5, 1), add.smooth = getOption("add.smooth"), 
           iter.smooth = if (isGlm) 0 else 3, label.pos = c(4, 2), cex.caption = 1, 
           cex.oma.main = 1.25, cex.lab = 1, line.lab = 3, xlim = NULL, ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagnostic.plots_+3A_x">x</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_which">which</code></td>
<td>
<p>subset of the integers <code>1:6</code> indicating which plots to produce</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_caption">caption</code></td>
<td>
<p>captions to appear above the plots</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_panel">panel</code></td>
<td>
<p>panel function (panel.smooth or points?)</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_sub.caption">sub.caption</code></td>
<td>
<p>common title (for use above multiple figures)</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_main">main</code></td>
<td>
<p>title to each plot (in addition to <code>caption</code>)</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_ask">ask</code></td>
<td>
<p>if <code>TRUE</code>, the user is asked before each plot</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_id.n">id.n</code></td>
<td>
<p>number of points to be labeled in each plot, starting with the most extreme</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_labels.id">labels.id</code></td>
<td>
<p>vector of labels for extreme observations (<code>NULL</code> uses the observation numbers)</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_cex.id">cex.id</code></td>
<td>
<p>magnification of point labels</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_cex.pt">cex.pt</code></td>
<td>
<p>magnification of points</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_qqline">qqline</code></td>
<td>
<p>logical indicating if a <code><a href="stats.html#topic+qqline">qqline</a></code> should be added to the normal Q-Q plot</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_cook.levels">cook.levels</code></td>
<td>
<p>levels of Cook's distance at which to draw contours</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_add.smooth">add.smooth</code></td>
<td>
<p>logical indicating if a smoother should be added to most plots</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_iter.smooth">iter.smooth</code></td>
<td>
<p>the number of robustness iterations, the argument <code>iter</code> in <code><a href="graphics.html#topic+panel.smooth">panel.smooth</a></code></p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_label.pos">label.pos</code></td>
<td>
<p>positioning of the labels, for the left hald and right half of the graph respectively, for plots 1-3, 5, and 6</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_cex.caption">cex.caption</code></td>
<td>
<p>controls the size of the <code>caption</code></p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_cex.oma.main">cex.oma.main</code></td>
<td>
<p>controls the size of the <code>sub.caption</code> only if that is above the figures (when there is more than one figure)</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_cex.lab">cex.lab</code></td>
<td>
<p>character expansion factor for axis labels</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_line.lab">line.lab</code></td>
<td>
<p>on which margin line should the axis labels be drawn?</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_xlim">xlim</code></td>
<td>
<p>Limits for x-axis. If <code>length(which) == 1</code>, a vector of the form <code>c(xmin, xmax)</code>. Otherwise a list the same length as <code>which</code> such that each list entry gives the x-axis limits for the corresponding plot.</p>
</td></tr>
<tr><td><code id="diagnostic.plots_+3A_ylim">ylim</code></td>
<td>
<p>Limits for y-axis. If <code>length(which) == 1</code>, a vector of the form <code>c(ymin, ymax)</code>. Otherwise a list the same length as <code>which</code> such that each list entry gives the y-axis limits for the corresponding plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is modeled after the <code><a href="stats.html#topic+plot.lm">plot.lm</a></code> function. The structure of the arguments, as well as the internal codes, mimics the <code><a href="stats.html#topic+plot.lm">plot.lm</a></code> function whenever possible. By default, only plots 1-3 and 5 are provided, but any subset of plots can be requested using the <code>which</code> argument.
</p>
<p>The six plots include: (1) residuals versus fitted values, (2) normal Q-Q plot, (3) scale-location plot of <code class="reqn">\sqrt{|residuals|}</code> versus fitted values, (4) Cook's distances, (5) residuals versus leverages, and (6) Cook's distance versus variance ratio = leverage/(1-leverage).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Belsley, D. A., Kuh, E. and Welsch, R. E. (1980). Regression Diagnostics. New York: Wiley.
</p>
<p>Cook, R. D. and Weisberg, S. (1982). Residuals and Influence in Regression. London: Chapman and Hall.
</p>
<p>McCullagh, P. and Nelder, J. A. (1989). Generalized Linear Models. London: Chapman and Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code>
</p>
<p><code><a href="#topic+smooth.influence.measures">smooth.influence.measures</a></code> and <code><a href="#topic+smooth.influence">smooth.influence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# smoothing spline
mod.ss &lt;- ss(x, y, nknots = 10)
diagnostic.plots(mod.ss)

# smooth model
mod.sm &lt;- sm(y ~ x, knots = 10)
diagnostic.plots(mod.sm)

# generalized smooth model (family = gaussian)
mod.gsm &lt;- gsm(y ~ x, knots = 10)
diagnostic.plots(mod.gsm)

</code></pre>

<hr>
<h2 id='fitted'>
Extract Smooth Model Fitted Values
</h2><span id='topic+fitted.ss'></span><span id='topic+fitted.sm'></span><span id='topic+fitted.gsm'></span>

<h3>Description</h3>

<p>Extracts the fitted values from a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
fitted(object, ...)

## S3 method for class 'sm'
fitted(object, ...)

## S3 method for class 'gsm'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted_+3A_object">object</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="fitted_+3A_...">...</code></td>
<td>

<p>other arugments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects of class <code><a href="#topic+ss">ss</a></code>, fitted values are predicted via <code>predict(object, object$data$x)$y</code>
</p>
<p>For objects of class <code><a href="#topic+sm">sm</a></code>, fitted values are extracted via <code>object$fitted.values</code>
</p>
<p>For objects of class <code><a href="#topic+gsm">gsm</a></code>, fitted values are computed via <code>ginv(object$linear.predictors)</code> where <code>ginv = object$family$linkinv</code>
</p>


<h3>Value</h3>

<p>Fitted values extracted (or predicted) from <code>object</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Chambers, J. M. and Hastie, T. J. (1992) <em>Statistical Models in S</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# smoothing spline
mod.ss &lt;- ss(x, y, nknots = 10)
fit.ss &lt;- fitted(mod.ss)

# smooth model
mod.sm &lt;- sm(y ~ x, knots = 10)
fit.sm &lt;- fitted(mod.sm)

# generalized smooth model (family = gaussian)
mod.gsm &lt;- gsm(y ~ x, knots = 10)
fit.gsm &lt;- fitted(mod.gsm)

# compare fitted values
mean((fit.ss - fit.sm)^2)
mean((fit.ss - fit.gsm)^2)
mean((fit.sm - fit.gsm)^2)
</code></pre>

<hr>
<h2 id='gsm'>
Fit a Generalized Smooth Model
</h2><span id='topic+gsm'></span><span id='topic+family.gsm'></span>

<h3>Description</h3>

<p>Fits a generalized semi- or nonparametric regression model with the smoothing parameter selected via one of seven methods: GCV, OCV, GACV, ACV, PQL, AIC, or BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsm(formula, family = gaussian, data, weights, types = NULL, tprk = TRUE, 
    knots = NULL, skip.iter = TRUE, spar = NULL, lambda = NULL, control = list(),
    method = c("GCV", "OCV", "GACV", "ACV", "PQL", "AIC", "BIC"),
    xrange = NULL, thetas = NULL, mf = NULL)
    
## S3 method for class 'gsm'
family(object, ...)
</code></pre>


<h3>Arguments</h3>

<p>Arguments for <code>gsm</code>:
</p>
<table>
<tr><td><code id="gsm_+3A_formula">formula</code></td>
<td>

<p>Object of class &quot;formula&quot; (or one that can be coerced to that class): a symbolic description of the model to be fitted. Uses the same syntax as <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_family">family</code></td>
<td>

<p>Description of the error distribution and link function to be used in the model. This can be a character string naming a family function, a family function, or the result of a call to a family function. See the &quot;Family Objects&quot; section for details.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_data">data</code></td>
<td>

<p>Optional data frame, list or environment (or object coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing the variables in the model. If not found in data, the variables are taken from <code>environment(formula)</code>, typically the environment from which <code>sm</code> is called.  
</p>
</td></tr>
<tr><td><code id="gsm_+3A_weights">weights</code></td>
<td>

<p>Optional vector of weights to be used in the fitting process. If provided, weighted (penalized) likelihood estimation is used. Defaults to all 1.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_types">types</code></td>
<td>

<p>Named list giving the type of smooth to use for each predictor. If <code>NULL</code>, the type is inferred from the data. See &quot;Types of Smooths&quot; section for details.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_tprk">tprk</code></td>
<td>

<p>Logical specifying how to parameterize smooth models with multiple predictors. If <code>TRUE</code> (default), a <b>t</b>ensor <b>p</b>roduct <b>r</b>eproducing <b>k</b>ernel function is used to represent the function. If <code>FALSE</code>, a tensor product of marginal kernel functions is used to represent the function. See the &quot;Multiple Smooths&quot; section for details.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_knots">knots</code></td>
<td>

<p>Spline knots for the estimation of the nonparametric effects. For models with multiple predictors, the knot specification will depend on the <code>tprk</code> input. See the &quot;Choosing Knots&quot; section for details
</p>
</td></tr>
<tr><td><code id="gsm_+3A_skip.iter">skip.iter</code></td>
<td>

<p>Set to <code>FALSE</code> for deep tuning of the hyperparameters. Only applicable when multiple smooth terms are included. See the &quot;Parameter Tuning&quot; section for details.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_spar">spar</code></td>
<td>

<p>Smoothing parameter. Typically (but not always) in the range <code class="reqn">(0,1]</code>. If specified <code>lambda = 256^(3*(spar-1))</code>.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_lambda">lambda</code></td>
<td>

<p>Computational smoothing parameter. This value is weighted by <code class="reqn">n</code> to form the penalty coefficient (see Details). Ignored if <code>spar</code> is provided.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_control">control</code></td>
<td>

<p>Optional list with named components that control the optimization specs for the smoothing parameter selection routine.
</p>
<p><b>Note</b> that spar is only searched for in the interval <code class="reqn">[lower, upper]</code>.
</p>

<dl>
<dt>lower:</dt><dd><p>lower bound for spar; defaults to 0.</p>
</dd>
<dt>upper:</dt><dd><p>upper bound for spar; defaults to 1.</p>
</dd>
<dt>tol:</dt><dd><p>the absolute precision (<b>tol</b>erance) used by <code><a href="stats.html#topic+optimize">optimize</a></code>; defaults to 1e-8.</p>
</dd>
<dt>iterlim:</dt><dd><p>the iteration limit used by <code><a href="stats.html#topic+nlm">nlm</a></code>; defaults to 5000.</p>
</dd>
<dt>print.level:</dt><dd><p>the print level used by <code><a href="stats.html#topic+nlm">nlm</a></code>; defaults to 0 (no printing).</p>
</dd>
<dt>epsilon:</dt><dd><p>relative convergence tolerance for IRPLS algorithm; defaults to 1e-8</p>
</dd>
<dt>maxit:</dt><dd><p>maximum number of iterations for IRPLS algorithm; defaults to 25</p>
</dd>
<dt>epsilon.out:</dt><dd><p>relative convergence tolerance for iterative NegBin update; defaults to 1e-6</p>
</dd>
<dt>maxit.out:</dt><dd><p>maximum number of iterations for iterative NegBin update; defaults to 10</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="gsm_+3A_method">method</code></td>
<td>

<p>Method for selecting the smoothing parameter. Ignored if <code>lambda</code> is provided.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_xrange">xrange</code></td>
<td>

<p>Optional named list containing the range of each predictor. If <code>NULL</code>, the ranges are calculated from the input <code>data</code>.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_thetas">thetas</code></td>
<td>

<p>Optional vector of hyperparameters to use for smoothing. If <code>NULL</code>, these are tuned using the requested <code>method</code>.
</p>
</td></tr>
<tr><td><code id="gsm_+3A_mf">mf</code></td>
<td>

<p>Optional model frame constructed from <code>formula</code> and <code>data</code> (and potentially <code>weights</code>).
</p>
</td></tr>
</table>
<p>Note: the last two arguments are not intended to be called by the typical user of this function. These arguments are included primarily for internal usage by the <code><a href="#topic+boot.gsm">boot.gsm</a></code> function.
</p>
<p>Arguments for <code>family.gsm</code>:
</p>
<table>
<tr><td><code id="gsm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;gsm&quot;</p>
</td></tr>
<tr><td><code id="gsm_+3A_...">...</code></td>
<td>
<p>additional arguments (currently ignored)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Letting <code class="reqn">\eta_i = \eta(x_i)</code> with <code class="reqn">x_i = (x_{i1}, \ldots, x_{ip})</code>, the function is represented as </p>
<p style="text-align: center;"><code class="reqn">\eta = X \beta + Z \alpha</code>
</p>
<p> where the basis functions in <code class="reqn">X</code> span the null space (i.e., parametric effects), and <code class="reqn">Z</code> contains the kernel function(s) of the contrast space (i.e., nonparametric effects) evaluated at all combinations of observed data points and knots. The vectors <code class="reqn">\beta</code> and <code class="reqn">\alpha</code> contain unknown basis function coefficients.
</p>
<p>Let <code class="reqn">\mu_i = E(y_i)</code> denote the mean of the <code class="reqn">i</code>-th response. The unknown function is related to the mean <code class="reqn">\mu_i</code> such as </p>
<p style="text-align: center;"><code class="reqn">g(\mu_i) = \eta_i</code>
</p>
<p> where <code class="reqn">g()</code> is a known link function. Note that this implies that <code class="reqn">\mu_i = g^{-1}(\eta_i)</code> given that the link function is assumed to be invertible. 
</p>
<p>The penalized likelihood estimation problem has the form
</p>
<p style="text-align: center;"><code class="reqn">
- \sum_{i = 1}^n [y_i \xi_i - b(\xi_i)] + n \lambda \alpha' Q \alpha
</code>
</p>

<p>where <code class="reqn">\xi_i</code> is the canonical parameter, <code class="reqn">b()</code> is a known function that depends on the chosen family, and <code class="reqn">Q</code> is the penalty matrix. Note that <code class="reqn">\xi_i = g_0(\mu_i)</code> where <code class="reqn">g_0</code> is the canonical link function. This implies that <code class="reqn">\xi_i = \eta_i</code> when the chosen link function is canonical, i.e., when <code class="reqn">g = g_0</code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;gsm&quot; with components:

</p>
<table>
<tr><td><code>linear.predictors</code></td>
<td>
<p>the linear fit on link scale. Use <code><a href="#topic+fitted.gsm">fitted.gsm</a></code> to obtain the fitted values on the response scale.</p>
</td></tr>
<tr><td><code>se.lp</code></td>
<td>
<p>the standard errors of the linear predictors.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>up to a constant, minus twice the maximized log-likelihood. Where sensible, the constant is chosen so that a saturated model has deviance zero.</p>
</td></tr>
<tr><td><code>cv.crit</code></td>
<td>
<p>the cross-validation criterion.</p>
</td></tr>
<tr><td><code>nsdf</code></td>
<td>
<p>the degrees of freedom (Df) for the null space.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the estimated degrees of freedom (Df) for the fit model.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom = <code>nobs - df</code></p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>the squared correlation between response and fitted values.</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>the estimated dispersion parameter.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log-likelihood.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Akaike's Information Criterion.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Bayesian Information Criterion.</p>
</td></tr>
<tr><td><code>spar</code></td>
<td>
<p>the value of <code>spar</code> computed or given, i.e., <code class="reqn">s = 1 + \log_{256}(\lambda)/3</code></p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the value of <code class="reqn">\lambda</code> corresponding to <code>spar</code>, i.e., <code class="reqn">\lambda = 256^{3*(s-1)}</code>.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>the smoothness penalty <code class="reqn">\alpha' Q \alpha</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the basis function coefficients used for the fit model.</p>
</td></tr>
<tr><td><code>cov.sqrt</code></td>
<td>
<p>the square-root of the covariance matrix of <code>coefficients</code>. Note: <code>tcrossprod(cov.sqrt)</code> reconstructs the covariance matrix. </p>
</td></tr>
<tr><td><code>specs</code></td>
<td>
<p>a list with information used for prediction purposes:
</p>

<dl>
<dt>knots</dt><dd><p>the spline knots used for each predictor.</p>
</dd>
<dt>thetas</dt><dd><p>the &quot;extra&quot; tuning parameters used to weight the penalties.</p>
</dd>
<dt>xrng</dt><dd><p>the ranges of the predictor variables.</p>
</dd>
<dt>xlev</dt><dd><p>the factor levels of the predictor variables (if applicable).</p>
</dd>
<dt>tprk</dt><dd><p>logical controlling the formation of tensor product smooths.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the data used to fit the model.</p>
</td></tr>
<tr><td><code>types</code></td>
<td>
<p>the type of smooth used for each predictor.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms included in the fit model.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used for smoothing parameter selection. Will be <code>NULL</code> if <code>lambda</code> was provided.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula specifying the fit model.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used for fitting (if applicable)</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the input family evaluated as a function using .</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations of IRPLS used.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the working (IRPLS) residuals from the fitted model.</p>
</td></tr>
<tr><td><code>null.deviance</code></td>
<td>
<p>the deviance of the null model (i.e., intercept only).</p>
</td></tr>
</table>


<h3>Family Objects </h3>

<p>Supported families and links include:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>family</code> </td><td style="text-align: left;"> </td><td style="text-align: left;"> <code>link</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
binomial </td><td style="text-align: left;"> </td><td style="text-align: left;"> logit, probit, cauchit, log, cloglog </td>
</tr>
<tr>
 <td style="text-align: left;">
gaussian </td><td style="text-align: left;"> </td><td style="text-align: left;"> identity, log, inverse </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: left;"> </td><td style="text-align: left;"> inverse, identity, log </td>
</tr>
<tr>
 <td style="text-align: left;">
inverse.gaussian </td><td style="text-align: left;"> </td><td style="text-align: left;"> 1/mu^2, inverse, identity, log </td>
</tr>
<tr>
 <td style="text-align: left;">
poisson </td><td style="text-align: left;"> </td><td style="text-align: left;"> log, identity, sqrt </td>
</tr>
<tr>
 <td style="text-align: left;">
NegBin </td><td style="text-align: left;"> </td><td style="text-align: left;"> log, identity, sqrt </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>See <code><a href="#topic+NegBin">NegBin</a></code> for information about the Negative Binomial family.
</p>


<h3>Methods </h3>

<p>The smoothing parameter can be selected using one of seven methods: <br />
Generalized Cross-Validation (GCV) <br />
Ordinary Cross-Validation (OCV) <br />
Generalized Approximate Cross-Validation (GACV) <br />
Approximate Cross-Validation (ACV) <br />
Penalized Quasi-Likelihood (PQL) <br />
Akaike's Information Criterion (AIC) <br />
Bayesian Information Criterion (BIC)
</p>


<h3>Types of Smooths </h3>

<p>The following codes specify the spline types:
</p>

<table>
<tr>
 <td style="text-align: left;">
par </td><td style="text-align: left;"> Parametric effect (factor, integer, or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
nom </td><td style="text-align: left;"> Nominal smoothing spline (unordered factor). </td>
</tr>
<tr>
 <td style="text-align: left;">
ord </td><td style="text-align: left;"> Ordinal smoothing spline (ordered factor). </td>
</tr>
<tr>
 <td style="text-align: left;">
lin </td><td style="text-align: left;"> Linear smoothing spline (integer or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
cub </td><td style="text-align: left;"> Cubic smoothing spline (integer or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
qui </td><td style="text-align: left;"> Quintic smoothing spline (integer or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
per </td><td style="text-align: left;"> Periodic smoothing spline (integer or numeric).</td>
</tr>
<tr>
 <td style="text-align: left;">  
sph </td><td style="text-align: left;"> Spherical spline (matrix with <code class="reqn">d = 2</code> columns: lat, long). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps </td><td style="text-align: left;"> Thin plate spline (matrix with <code class="reqn">d \ge 1</code> columns).
</td>
</tr>

</table>

<p>For finer control of some specialized spline types:
</p>

<table>
<tr>
 <td style="text-align: left;">
per.lin </td><td style="text-align: left;"> Linear periodic spline (<code class="reqn">m = 1</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
per.cub </td><td style="text-align: left;"> Cubic periodic spline (<code class="reqn">m = 2</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
per.qui </td><td style="text-align: left;"> Quintic periodic spline (<code class="reqn">m = 3</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
sph.2 </td><td style="text-align: left;"> 2nd order spherical spline (<code class="reqn">m = 2</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
sph.3 </td><td style="text-align: left;"> 3rd order spherical spline (<code class="reqn">m = 3</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
sph.4 </td><td style="text-align: left;"> 4th order spherical spline (<code class="reqn">m = 4</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps.lin </td><td style="text-align: left;"> Linear thin plate spline (<code class="reqn">m = 1</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps.cub </td><td style="text-align: left;"> Cubic thin plate spline (<code class="reqn">m = 2</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps.qui </td><td style="text-align: left;"> Quintic thin plate spline (<code class="reqn">m = 3</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>For details on the spline kernel functions, see <code><a href="#topic+basis.nom">basis.nom</a></code> (nominal), <code><a href="#topic+basis.ord">basis.ord</a></code> (ordinal), <code><a href="#topic+basis.poly">basis.poly</a></code> (polynomial), <code><a href="#topic+basis.sph">basis.sph</a></code> (spherical), and <code><a href="#topic+basis.tps">basis.tps</a></code> (thin plate).
</p>


<h3>Choosing Knots </h3>

<p>If <code>tprk = TRUE</code>, the four options for the <code>knots</code> input include: 
</p>

<table>
<tr>
 <td style="text-align: left;">
1. </td><td style="text-align: left;"> a scalar giving the total number of knots to sample </td>
</tr>
<tr>
 <td style="text-align: left;">
2. </td><td style="text-align: left;"> a vector of integers indexing which rows of data are the knots </td>
</tr>
<tr>
 <td style="text-align: left;">
3. </td><td style="text-align: left;"> a list with named elements giving the marginal knot values for each predictor (to be combined via <code><a href="base.html#topic+expand.grid">expand.grid</a></code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
4. </td><td style="text-align: left;"> a list with named elements giving the knot values for each predictor (requires the same number of knots for each predictor)
</td>
</tr>

</table>

<p>If <code>tprk = FALSE</code>, the three options for the <code>knots</code> input include:
</p>

<table>
<tr>
 <td style="text-align: left;">
1. </td><td style="text-align: left;"> a scalar giving the common number of knots for each continuous predictor </td>
</tr>
<tr>
 <td style="text-align: left;">
2. </td><td style="text-align: left;"> a list with named elements giving the number of marginal knots for each predictor </td>
</tr>
<tr>
 <td style="text-align: left;">
3. </td><td style="text-align: left;"> a list with named elements giving the marginal knot values for each predictor
</td>
</tr>

</table>



<h3>Multiple Smooths </h3>

<p>Suppose <code>formula = y ~ x1 + x2</code> so that the model contains additive effects of two predictor variables. 
</p>
<p>The <code class="reqn">k</code>-th predictor's marginal effect can be denoted as </p>
<p style="text-align: center;"><code class="reqn">f_k = X_k \beta_k + Z_k \alpha_k</code>
</p>
<p> where <code class="reqn">X_k</code> is the <code class="reqn">n</code> by <code class="reqn">m_k</code> null space basis function matrix, and <code class="reqn">Z_k</code> is the <code class="reqn">n</code> by <code class="reqn">r_k</code> contrast space basis function matrix. 
</p>
<p>If <code>tprk = TRUE</code>, the null space basis function matrix has the form <code class="reqn">X = [1, X_1, X_2]</code> and the contrast space basis function matrix has the form </p>
<p style="text-align: center;"><code class="reqn">Z = \theta_1 Z_1 + \theta_2 Z_2</code>
</p>
<p> where the <code class="reqn">\theta_k</code> are the &quot;extra&quot; smoothing parameters. Note that <code class="reqn">Z</code> is of dimension <code class="reqn">n</code> by <code class="reqn">r = r_1 = r_2</code>.
</p>
<p>If <code>tprk = FALSE</code>, the null space basis function matrix has the form <code class="reqn">X = [1, X_1, X_2]</code>, and the contrast space basis function matrix has the form </p>
<p style="text-align: center;"><code class="reqn">Z = [\theta_1 Z_1, \theta_2 Z_2]</code>
</p>
<p> where the <code class="reqn">\theta_k</code> are the &quot;extra&quot; smoothing parameters. Note that <code class="reqn">Z</code> is of dimension <code class="reqn">n</code> by <code class="reqn">r = r_1 + r_2</code>.
</p>


<h3>Parameter Tuning </h3>

<p>When multiple smooth terms are included in the model, there are smoothing (hyper)parameters that weight the contribution of each combination of smooth terms. These hyperparameters are distinct from the overall smoothing parameter <code>lambda</code> that weights the contribution of the penalty. 
</p>
<p><code>skip.iter = TRUE</code> (default) estimates the smoothing hyperparameters using Algorithm 3.2 of Gu and Wahba (1991), which typically provides adequate results when the model form is correctly specified. The <code>lambda</code> parameter is tuned via the specified smoothing parameter selection <code>method</code>.
</p>
<p><code>skip.iter = FALSE</code> uses Algorithm 3.2 as an initialization, and then the <code><a href="stats.html#topic+nlm">nlm</a></code> function is used to tune the hyperparameters via the specified smoothing parameter selection <code>method</code>. Setting <code>skip.iter = FALSE</code> can (substantially) increase the model fitting time, but should produce better results&mdash;particularly if the model <code>formula</code> is misspecified.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Berry, L. N., &amp; Helwig, N. E. (2021). Cross-validation, information theory, or maximum likelihood? A comparison of tuning methods for penalized splines. <em>Stats, 4</em>(3), 701-724. <a href="https://doi.org/10.3390/stats4030042">doi:10.3390/stats4030042</a>
</p>
<p>Craven, P. and Wahba, G. (1979). Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. <em>Numerische Mathematik, 31</em>, 377-403. <a href="https://doi.org/10.1007/BF01404567">doi:10.1007/BF01404567</a>
</p>
<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Gu, C. and Wahba, G. (1991). Minimizing GCV/GML scores with multiple smoothing parameters via the Newton method. <em>SIAM Journal on Scientific and Statistical Computing, 12(2)</em>, 383-398. <a href="https://doi.org/10.1137/0912021">doi:10.1137/0912021</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Helwig, N. E. (2021). Spectrally sparse nonparametric regression via elastic net regularized smoothers. <em>Journal of Computational and Graphical Statistics, 30</em>(1), 182-191. <a href="https://doi.org/10.1080/10618600.2020.1806855">doi:10.1080/10618600.2020.1806855</a>
</p>


<h3>See Also</h3>

<p><b>Related Modeling Functions</b>: 
</p>
<p><code><a href="#topic+ss">ss</a></code> for fitting a smoothing spline with a single predictor (Gaussian response).
</p>
<p><code><a href="#topic+sm">sm</a></code> for fitting smooth models with multiple predictors of mixed types (Gaussian response). <br />
</p>
<p><b>S3 Methods and Related Functions for &quot;gsm&quot; Objects</b>:
</p>
<p><code><a href="#topic+boot.gsm">boot.gsm</a></code> for bootstrapping <code>gsm</code> objects.
</p>
<p><code><a href="#topic+coef.gsm">coef.gsm</a></code> for extracting coefficients from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+cooks.distance.gsm">cooks.distance.gsm</a></code> for calculating Cook's distances from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+cov.ratio">cov.ratio</a></code> for computing covariance ratio from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+deviance.gsm">deviance.gsm</a></code> for extracting deviance from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+dfbeta.gsm">dfbeta.gsm</a></code> for calculating DFBETA from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+dfbetas.gsm">dfbetas.gsm</a></code> for calculating DFBETAS from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+diagnostic.plots">diagnostic.plots</a></code> for plotting regression diagnostics from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+family.gsm">family.gsm</a></code> for extracting <code>family</code> from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+fitted.gsm">fitted.gsm</a></code> for extracting fitted values from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+hatvalues.gsm">hatvalues.gsm</a></code> for extracting leverages from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+model.matrix.gsm">model.matrix.gsm</a></code> for constructing model matrix from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+predict.gsm">predict.gsm</a></code> for predicting from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+residuals.gsm">residuals.gsm</a></code> for extracting residuals from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+rstandard.gsm">rstandard.gsm</a></code> for computing standardized residuals from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+rstudent.gsm">rstudent.gsm</a></code> for computing studentized residuals from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+smooth.influence">smooth.influence</a></code> for calculating basic influence information from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+smooth.influence.measures">smooth.influence.measures</a></code> for convenient display of influential observations from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+summary.gsm">summary.gsm</a></code> for summarizing <code>gsm</code> objects.
</p>
<p><code><a href="#topic+vcov.gsm">vcov.gsm</a></code> for extracting coefficient covariance matrix from <code>gsm</code> objects.
</p>
<p><code><a href="#topic+weights.gsm">weights.gsm</a></code> for extracting prior weights from <code>gsm</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########
### 1 continuous predictor

# generate data
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 3 * x + sin(2 * pi * x) - 1.5

# gaussian (default)
set.seed(1)
y &lt;- fx + rnorm(n, sd = 1/sqrt(2))
mod &lt;- gsm(y ~ x, knots = 10)
mean((mod$linear.predictors - fx)^2)

# compare to result from sm (they are identical)
mod.sm &lt;- sm(y ~ x, knots = 10)
mean((mod$linear.predictors - mod.sm$fitted.values)^2)

# binomial (no weights)
set.seed(1)
y &lt;- rbinom(n = n, size = 1, p = 1 / (1 + exp(-fx)))
mod &lt;- gsm(y ~ x, family = binomial, knots = 10)
mean((mod$linear.predictors - fx)^2)

# binomial (w/ weights)
set.seed(1)
w &lt;- as.integer(rep(c(10,20,30,40,50), length.out = n))
y &lt;- rbinom(n = n, size = w, p = 1 / (1 + exp(-fx))) / w
mod &lt;- gsm(y ~ x, family = binomial, weights = w, knots = 10)
mean((mod$linear.predictors - fx)^2)

# poisson
set.seed(1)
y &lt;- rpois(n = n, lambda = exp(fx))
mod &lt;- gsm(y ~ x, family = poisson, knots = 10)
mean((mod$linear.predictors - fx)^2)

# negative binomial (known theta)
set.seed(1)
y &lt;- rnbinom(n = n, size = 1/2, mu = exp(fx))
mod &lt;- gsm(y ~ x, family = NegBin(theta = 1/2), knots = 10)
mean((mod$linear.predictors - fx)^2)
mod$family$theta    # fixed theta

# negative binomial (unknown theta)
set.seed(1)
y &lt;- rnbinom(n = n, size = 1/2, mu = exp(fx))
mod &lt;- gsm(y ~ x, family = NegBin, knots = 10)
mean((mod$linear.predictors - fx)^2)
mod$family$theta    # estimated theta

# gamma
set.seed(1)
y &lt;- rgamma(n = n, shape = 2, scale = (1 / (2 + fx)) / 2)
mod &lt;- gsm(y ~ x, family = Gamma, knots = 10)
mean((mod$linear.predictors - fx - 2)^2)

# inverse.gaussian (not run; requires statmod)
##set.seed(1)
##y &lt;- statmod::rinvgauss(n = n, mean = sqrt(1 / (2 + fx)), shape = 2)
##mod &lt;- gsm(y ~ x, family = inverse.gaussian, knots = 10)
##mean((mod$linear.predictors - fx - 2)^2)



##########   EXAMPLE 2   ##########
### 1 continuous and 1 nominal predictor
### additive model

# generate data
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x) - 1.5
}
fx &lt;- fun(x, z)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])
              
# gaussian (default)
set.seed(1)
y &lt;- fx + rnorm(n, sd = 1/sqrt(2))
mod &lt;- gsm(y ~ x + z, knots = knots)
mean((mod$linear.predictors - fx)^2)

# compare to result from sm (they are identical)
mod.sm &lt;- sm(y ~ x + z, knots = knots)
mean((mod$linear.predictors - mod.sm$fitted.values)^2)

# binomial (no weights)
set.seed(1)
y &lt;- rbinom(n = n, size = 1, p = 1 / (1 + exp(-fx)))
mod &lt;- gsm(y ~ x + z, family = binomial, knots = knots)
mean((mod$linear.predictors - fx)^2)

# binomial (w/ weights)
set.seed(1)
w &lt;- as.integer(rep(c(10,20,30,40,50), length.out = n))
y &lt;- rbinom(n = n, size = w, p = 1 / (1 + exp(-fx))) / w
mod &lt;- gsm(y ~ x + z, family = binomial, weights = w, knots = knots)
mean((mod$linear.predictors - fx)^2)

# poisson
set.seed(1)
y &lt;- rpois(n = n, lambda = exp(fx))
mod &lt;- gsm(y ~ x + z, family = poisson, knots = knots)
mean((mod$linear.predictors - fx)^2)

# negative binomial (known theta)
set.seed(1)
y &lt;- rnbinom(n = n, size = 1/2, mu = exp(fx))
mod &lt;- gsm(y ~ x + z, family = NegBin(theta = 1/2), knots = knots)
mean((mod$linear.predictors - fx)^2)
mod$family$theta    # fixed theta

# negative binomial (unknown theta)
set.seed(1)
y &lt;- rnbinom(n = n, size = 1/2, mu = exp(fx))
mod &lt;- gsm(y ~ x + z, family = NegBin, knots = knots)
mean((mod$linear.predictors - fx)^2)
mod$family$theta    # estimated theta

# gamma
set.seed(1)
y &lt;- rgamma(n = n, shape = 2, scale = (1 / (4 + fx)) / 2)
mod &lt;- gsm(y ~ x + z, family = Gamma, knots = knots)
mean((mod$linear.predictors - fx - 4)^2)

# inverse.gaussian (not run; requires statmod)
##set.seed(1)
##y &lt;- statmod::rinvgauss(n = n, mean = sqrt(1 / (4 + fx)), shape = 2)
##mod &lt;- gsm(y ~ x + z, family = inverse.gaussian, knots = knots)
##mean((mod$linear.predictors - fx - 4)^2)

</code></pre>

<hr>
<h2 id='model.matrix'>
Construct Design Matrix for Fit Model
</h2><span id='topic+model.matrix.ss'></span><span id='topic+model.matrix.sm'></span><span id='topic+model.matrix.gsm'></span>

<h3>Description</h3>

<p><code>model.matrix</code> returns the design (or model) matrix used by the input <code>object</code> to produce the fitted values (for objects of class <code><a href="#topic+ss">ss</a></code> or <code><a href="#topic+sm">sm</a></code>) or the linear predictors (for objects of class <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
model.matrix(object, ...)

## S3 method for class 'sm'
model.matrix(object, ...)

## S3 method for class 'gsm'
model.matrix(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.matrix_+3A_object">object</code></td>
<td>

<p>an object of class <code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, or <code><a href="#topic+gsm">gsm</a></code>
</p>
</td></tr>
<tr><td><code id="model.matrix_+3A_...">...</code></td>
<td>

<p>additional arguments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code><a href="#topic+ss">ss</a></code> objects, the <code><a href="#topic+basis.poly">basis.poly</a></code> function is used to construct the design matrix. 
</p>
<p>For <code><a href="#topic+sm">sm</a></code> objects, the <code><a href="#topic+predict.sm">predict.sm</a></code> function with option <code>design = TRUE</code> is used to construct the design matrix. 
</p>
<p>For <code><a href="#topic+gsm">gsm</a></code> objects, the <code><a href="#topic+predict.gsm">predict.gsm</a></code> function with option <code>design = TRUE</code> is used to construct the design matrix.
</p>


<h3>Value</h3>

<p>The design matrix that is post-multiplied by the coefficients to produce the fitted values (or linear predictors).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Chambers, J. M. (1992) Data for models. Chapter 3 of <em>Statistical Models in S</em> eds J. M. Chambers and T. J. Hastie, Wadsworth &amp; Brooks/Cole.
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basis.poly">basis.poly</a></code> for the smoothing spline basis
</p>
<p><code><a href="#topic+predict.sm">predict.sm</a></code> for predicting from smooth models
</p>
<p><code><a href="#topic+predict.gsm">predict.gsm</a></code> for predicting from generalized smooth models
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# smoothing spline
mod.ss &lt;- ss(x, y, nknots = 10)
X.ss &lt;- model.matrix(mod.ss)
mean((mod.ss$y - X.ss %*% mod.ss$fit$coef)^2)


# smooth model
mod.sm &lt;- sm(y ~ x, knots = 10)
X.sm &lt;- model.matrix(mod.sm)
mean((mod.sm$fitted.values - X.sm %*% mod.sm$coefficients)^2)

# generalized smooth model (family = gaussian)
mod.gsm &lt;- gsm(y ~ x, knots = 10)
X.gsm &lt;- model.matrix(mod.gsm)
mean((mod.gsm$linear.predictors - X.gsm %*% mod.gsm$coefficients)^2)

</code></pre>

<hr>
<h2 id='msqrt'>
Matrix (Inverse?) Square Root
</h2><span id='topic+msqrt'></span>

<h3>Description</h3>

<p>Stable computation of the square root (or inverse square root) of a positive semi-definite matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msqrt(x, inverse = FALSE, symmetric = FALSE, 
      tol = .Machine$double.eps, checkx = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msqrt_+3A_x">x</code></td>
<td>

<p>positive semi-definite matrix
</p>
</td></tr>
<tr><td><code id="msqrt_+3A_inverse">inverse</code></td>
<td>

<p>compute inverse square root?
</p>
</td></tr>
<tr><td><code id="msqrt_+3A_symmetric">symmetric</code></td>
<td>

<p>does the square root need to be symmetric? See Details.
</p>
</td></tr>
<tr><td><code id="msqrt_+3A_tol">tol</code></td>
<td>

<p>tolerance for detecting linear dependencies in <code>x</code>  
</p>
</td></tr>
<tr><td><code id="msqrt_+3A_checkx">checkx</code></td>
<td>

<p>should <code>x</code> be checked for symmetry using <code><a href="Matrix.html#topic+isSymmetric">isSymmetric</a></code>?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>symmetric = FALSE</code>, this function computes the matrix <code>z</code> such that <code>x = tcrossprod(z)</code>
</p>
<p>If <code>symmetric = TRUE</code>, this function computes the matrix <code>z</code> such that <code>x = crossprod(z) = tcrossprod(z)</code>
</p>
<p>If <code>inverse = TRUE</code>, the matrix <code>x</code> is replaced by the pseudo-inverse of <code>x</code> in these equations (see <code><a href="#topic+psolve">psolve</a></code>)
</p>


<h3>Value</h3>

<p>The matrix <code>z</code> that gives the (inverse?) square root of <code>x</code>. See Details.
</p>


<h3>Note</h3>

<p>The matrix (inverse?) square root is calculated by (inverting and) square rooting the eigenvalues that are greater than the first value multiplied by <code>tol * nrow(x)</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psolve">psolve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate x
set.seed(0)
x &lt;- crossprod(matrix(rnorm(100), 20, 5))

# asymmetric square root (default)
xsqrt &lt;- msqrt(x)
mean(( x - crossprod(xsqrt) )^2)
mean(( x - tcrossprod(xsqrt) )^2)

# symmetric square root
xsqrt &lt;- msqrt(x, symmetric = TRUE)
mean(( x - crossprod(xsqrt) )^2)
mean(( x - tcrossprod(xsqrt) )^2)

# asymmetric inverse square root (default)
xsqrt &lt;- msqrt(x, inverse = TRUE)
mean(( solve(x) - crossprod(xsqrt) )^2)
mean(( solve(x) - tcrossprod(xsqrt) )^2)

# symmetric inverse square root
xsqrt &lt;- msqrt(x, inverse = TRUE, symmetric = TRUE)
mean(( solve(x) - crossprod(xsqrt) )^2)
mean(( solve(x) - tcrossprod(xsqrt) )^2)

</code></pre>

<hr>
<h2 id='NegBin'>
Family Function for Negative Binomial
</h2><span id='topic+NegBin'></span>

<h3>Description</h3>

<p>Creates the functions needed to fit a Negative Binomial generalized smooth model via <code><a href="#topic+gsm">gsm</a></code> with or without a known <code>theta</code> parameter. Adapted from the <code>negative.binomial</code> function in the <strong>MASS</strong> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NegBin(theta = NULL, link = "log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NegBin_+3A_theta">theta</code></td>
<td>

<p>the <code>size</code> parameter for the Negative Binomial distribution. Default of <code>NULL</code> indicates that <code>theta</code> should be estimated from the data.
</p>
</td></tr>
<tr><td><code id="NegBin_+3A_link">link</code></td>
<td>

<p>the link function. Must be <code>log</code>, <code>sqrt</code>, <code>identity</code>, or an object of class <code>link-glm</code> (as generated by <code><a href="stats.html#topic+make.link">make.link</a></code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Negative Binomial distribution has mean <code class="reqn">\mu</code> and variance <code class="reqn">\mu + \mu^2/\theta</code>, where the <code>size</code> parameter <code class="reqn">\theta</code> is the inverse of the dispersion parameter. See <code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code> for details.
</p>


<h3>Value</h3>

<p>An object of class &quot;<code>family</code>&quot; with the functions and expressions needed to fit the <code>gsm</code>. In addition to the standard values (see <code><a href="stats.html#topic+family">family</a></code>), this also produces the following:
</p>
<table>
<tr><td><code>logLik</code></td>
<td>
<p>function to evaluate the log-likelihood</p>
</td></tr>
<tr><td><code>canpar</code></td>
<td>
<p>function to compute the canonical parameter</p>
</td></tr>
<tr><td><code>cumulant</code></td>
<td>
<p>function to compute the cumulant function</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>the specified <code>theta</code> parameter</p>
</td></tr>
<tr><td><code>fixed.theta</code></td>
<td>
<p>logical specifying if <code>theta</code> was provided</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (1999) Modern Applied Statistics with S-PLUS. Third Edition. Springer.
</p>
<p>https://www.rdocumentation.org/packages/MASS/versions/7.3-51.6/topics/negative.binomial
</p>
<p>https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/NegBinomial
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsm">gsm</a></code> for fitting generalized smooth models with Negative Binomial responses
</p>
<p><code><a href="#topic+theta.mle">theta.mle</a></code> for maximum likelihood estimation of theta
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 3 * x + sin(2 * pi * x) - 1.5

# negative binomial (size = 1/2, log link)
set.seed(1)
y &lt;- rnbinom(n = n, size = 1/2, mu = exp(fx))

# fit model (known theta)
mod &lt;- gsm(y ~ x, family = NegBin(theta = 1/2), knots = 10)
mean((mod$linear.predictors - fx)^2)
mod$family$theta   # fixed theta

# fit model (unknown theta)
mod &lt;- gsm(y ~ x, family = NegBin, knots = 10)
mean((mod$linear.predictors - fx)^2)
mod$family$theta   # estimated theta

</code></pre>

<hr>
<h2 id='nominal'>
Nominal Smoothing Spline Basis and Penalty
</h2><span id='topic+nominal'></span><span id='topic+basis.nom'></span><span id='topic+basis_nom'></span><span id='topic+penalty.nom'></span><span id='topic+penalty_nom'></span>

<h3>Description</h3>

<p>Generate the smoothing spline basis and penalty matrix for a nominal spline. This basis and penalty are for an unordered factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis.nom(x, knots, K = NULL, intercept = FALSE, ridge = FALSE)

penalty.nom(x, K = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nominal_+3A_x">x</code></td>
<td>

<p>Predictor variable (basis) or spline knots (penalty). Factor or integer vector of length <code class="reqn">n</code>.
</p>
</td></tr>
<tr><td><code id="nominal_+3A_knots">knots</code></td>
<td>

<p>Spline knots. Factor or integer vector of length <code class="reqn">r</code>.
</p>
</td></tr>
<tr><td><code id="nominal_+3A_k">K</code></td>
<td>

<p>Number of levels of <code>x</code>. If <code>NULL</code>, this argument is defined as <code>K = length(unique(x))</code>.
</p>
</td></tr>
<tr><td><code id="nominal_+3A_intercept">intercept</code></td>
<td>

<p>If <code>TRUE</code>, the first column of the basis will be a column of ones. 
</p>
</td></tr>
<tr><td><code id="nominal_+3A_ridge">ridge</code></td>
<td>

<p>If <code>TRUE</code>, the basis matrix is post-multiplied by the inverse square root of the penalty matrix. See Note and Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates a basis function or penalty matrix used to fit nominal smoothing splines.
</p>
<p>With an intercept included, the basis function matrix has the form 
</p>
<p style="text-align: center;"><code class="reqn">X = [X_0,  X_1]</code>
</p>

<p>where matrix <code>X_0</code> is an <code class="reqn">n</code> by 1 matrix of ones, and <code>X_1</code> is a matrix of dimension <code class="reqn">n</code> by <code class="reqn">r</code>. 
</p>
<p>The <code>X_0</code> matrix contains the &quot;parametric part&quot; of the basis (i.e., the intercept). The matrix <code>X_1</code> contains the &quot;nonparametric part&quot; of the basis, which consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = \delta_{x y} - 1/K </code>
</p>

<p>evaluated at all combinations of <code>x</code> and <code>knots</code>. The notation <code class="reqn">\delta_{x y}</code> denotes Kronecker's delta function.
</p>
<p>The penalty matrix consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = \delta_{x y} - 1/K </code>
</p>

<p>evaluated at all combinations of <code>x</code>. 
</p>


<h3>Value</h3>

<p>Basis: Matrix of dimension <code>c(length(x), df)</code> where <code>df = length(knots) + intercept</code>.
</p>
<p>Penalty: Matrix of dimension <code>c(r, r)</code> where <code>r = length(x)</code> is the number of knots.
</p>


<h3>Note</h3>

<p>If the inputs <code>x</code> and <code>knots</code> are factors, they should have the same levels.
</p>
<p>If the inputs <code>x</code> and <code>knots</code> are integers, the <code>knots</code> should be a subset of the input <code>x</code>.
</p>
<p>If <code>ridge = TRUE</code>, the penalty matrix is the identity matrix.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing Spline ANOVA Models. 2nd Ed. New York, NY: Springer-Verlag.  <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2017). Regression with ordered predictors via ordinal smoothing splines. <em>Frontiers in Applied Mathematics and Statistics, 3</em>(15), 1-13. <a href="https://doi.org/10.3389/fams.2017.00015">doi:10.3389/fams.2017.00015</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Helwig, N. E., &amp; Ma, P. (2015). Fast and stable multiple smoothing parameter selection in smoothing spline analysis of variance models with large samples. <em>Journal of Computational and Graphical Statistics, 24</em>(3), 715-732. <a href="https://doi.org/10.1080/10618600.2014.926819">doi:10.1080/10618600.2014.926819</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+ordinal">ordinal</a></code> for a basis and penalty for ordered factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   standard parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- factor(sort(rep(LETTERS[1:4], length.out = n)))
knots &lt;- LETTERS[1:3]
eta &lt;- 1:4
y &lt;- eta[x] + rnorm(n, sd = 0.5)

# nominal smoothing spline basis
X &lt;- basis.nom(x, knots, intercept = TRUE)

# nominal smoothing spline penalty
Q &lt;- penalty.nom(knots, K = 4)

# pad Q with zeros (for intercept)
Q &lt;- rbind(0, cbind(0, Q))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- solve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta[x] - yhat)^2))



######***######   ridge parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- factor(sort(rep(LETTERS[1:4], length.out = n)))
knots &lt;- LETTERS[1:3]
eta &lt;- 1:4
y &lt;- eta[x] + rnorm(n, sd = 0.5)

# nominal smoothing spline basis
X &lt;- basis.nom(x, knots, intercept = TRUE, ridge = TRUE)

# nominal smoothing spline penalty (ridge)
Q &lt;- diag(rep(c(0, 1), times = c(1, ncol(X) - 1)))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- solve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta[x] - yhat)^2))

</code></pre>

<hr>
<h2 id='npreg-internals'>Internal Functions for &quot;npreg&quot;</h2><span id='topic+npreg-internals'></span><span id='topic+bin_sample'></span><span id='topic+build_depe'></span><span id='topic+build_depe2'></span><span id='topic+build_rkhs'></span><span id='topic+charkro'></span><span id='topic+check_control'></span><span id='topic+check_family'></span><span id='topic+check_knot'></span><span id='topic+check_type'></span><span id='topic+check_type2'></span><span id='topic+df2lambda'></span><span id='topic+fit_gsm'></span><span id='topic+fit_sm'></span><span id='topic+fit_ssi'></span><span id='topic+knot1samp'></span><span id='topic+linkinvd'></span><span id='topic+pred_depe'></span><span id='topic+pred_rkhs'></span><span id='topic+print.gsm'></span><span id='topic+print.boot.gsm'></span><span id='topic+print.sm'></span><span id='topic+print.boot.sm'></span><span id='topic+print.ss'></span><span id='topic+print.boot.ss'></span><span id='topic+rexpfam'></span><span id='topic+rowkro'></span><span id='topic+theta.grad'></span><span id='topic+theta.info'></span><span id='topic+tune.deep.sm'></span><span id='topic+tune.deep.gsm'></span><span id='topic+tune.gsm'></span><span id='topic+tune.acv.ss'></span><span id='topic+tune.aic.ss'></span><span id='topic+tune.gacv.ss'></span><span id='topic+tune.gcv.ss'></span><span id='topic+tune.ocv.ss'></span><span id='topic+tune.mle.ss'></span><span id='topic+ordkern'></span><span id='topic+linkern0'></span><span id='topic+linkern1'></span><span id='topic+cubkern0'></span><span id='topic+cubkern1'></span><span id='topic+cubkern2'></span><span id='topic+quikern0'></span><span id='topic+quikern1'></span><span id='topic+quikern2'></span><span id='topic+.linkern0'></span><span id='topic+.linkern1'></span><span id='topic+.cubkern0'></span><span id='topic+.cubkern1'></span><span id='topic+.cubkern2'></span><span id='topic+.quikern0'></span><span id='topic+.quikern1'></span><span id='topic+.quikern2'></span><span id='topic+q2fun'></span><span id='topic+q4fun'></span><span id='topic+q6fun'></span>

<h3>Description</h3>

<p>Internal functions for &quot;npreg&quot; package.
</p>


<h3>Details</h3>

<p>These functions are not necessarily intended to be called by the user.
</p>

<hr>
<h2 id='number2color'>
Map Numbers to Colors
</h2><span id='topic+number2color'></span>

<h3>Description</h3>

<p>Each of the <code class="reqn">n</code> elements of a numeric vector is mapped onto one of the <code class="reqn">m</code> specified colors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>number2color(x, colors, ncol = 21, equidistant = TRUE, xmin = min(x), xmax = max(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="number2color_+3A_x">x</code></td>
<td>

<p>numeric vector of observations that should be mapped to colors
</p>
</td></tr>
<tr><td><code id="number2color_+3A_colors">colors</code></td>
<td>

<p>an optional vector of colors (see Note for default colors)  
</p>
</td></tr>
<tr><td><code id="number2color_+3A_ncol">ncol</code></td>
<td>

<p>number of colors <code class="reqn">m</code> used for mapping
</p>
</td></tr>
<tr><td><code id="number2color_+3A_equidistant">equidistant</code></td>
<td>

<p>if <code>TRUE</code> (default), the breaks used for binning are an equidistant seqeunce of values spanning the range of <code>x</code>. Otherwise sample quantiles of <code>x</code> are used to define the bin breaks.  
</p>
</td></tr>
<tr><td><code id="number2color_+3A_xmin">xmin</code></td>
<td>

<p>minimum <code>x</code> value to use when defining breaks  
</p>
</td></tr>
<tr><td><code id="number2color_+3A_xmax">xmax</code></td>
<td>

<p>maximum <code>x</code> value to use when defining breaks  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Elements of a numeric vector are binned using either an equidistant sequence (default) or sample quantiles. Each bin is associated with a unique color, so binning the observations is equivalent to mapping the numbers to colors. The <code>colors</code> are input to the <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code> function to create a color palette with length specified by the <code>ncol</code> argument.
</p>


<h3>Value</h3>

<p>Returns of vector of colors the same length as <code>x</code>
</p>


<h3>Note</h3>

<p>If <code>colors</code> is missing, the default color palette is defined as
</p>
<p><code>colors &lt;- c("darkblue", rainbow(12)[c(9, 8, 7, 5, 3, 2, 1)], "darkred")</code>
</p>
<p>which is a modified version of the <code><a href="grDevices.html#topic+rainbow">rainbow</a></code> color palette.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+.bincode">.bincode</a></code> is used to bin the data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:100
xcol &lt;- number2color(x)
plot(x, col = xcol)
</code></pre>

<hr>
<h2 id='ordinal'>
Ordinal Smoothing Spline Basis and Penalty
</h2><span id='topic+ordinal'></span><span id='topic+basis.ord'></span><span id='topic+basis_ord'></span><span id='topic+penalty.ord'></span><span id='topic+penalty_ord'></span>

<h3>Description</h3>

<p>Generate the smoothing spline basis and penalty matrix for an ordinal spline. This basis and penalty are for an ordered factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis.ord(x, knots, K = NULL, intercept = FALSE, ridge = FALSE)

penalty.ord(x, K = NULL, xlev = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordinal_+3A_x">x</code></td>
<td>

<p>Predictor variable (basis) or spline knots (penalty). Ordered factor or integer vector of length <code class="reqn">n</code>.
</p>
</td></tr>
<tr><td><code id="ordinal_+3A_knots">knots</code></td>
<td>

<p>Spline knots. Ordered factor or integer vector of length <code class="reqn">r</code>.
</p>
</td></tr>
<tr><td><code id="ordinal_+3A_k">K</code></td>
<td>

<p>Number of levels of <code>x</code>. If <code>NULL</code>, this argument is defined as <code>K = length(unique(x))</code>.
</p>
</td></tr>
<tr><td><code id="ordinal_+3A_xlev">xlev</code></td>
<td>

<p>Factor levels of <code>x</code> (for penalty). If <code>NULL</code>, the levels are defined as <code>levels(as.ordered(x))</code>.
</p>
</td></tr>
<tr><td><code id="ordinal_+3A_intercept">intercept</code></td>
<td>

<p>If <code>TRUE</code>, the first column of the basis will be a column of ones. 
</p>
</td></tr>
<tr><td><code id="ordinal_+3A_ridge">ridge</code></td>
<td>

<p>If <code>TRUE</code>, the basis matrix is post-multiplied by the inverse square root of the penalty matrix. See Note and Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates a basis function or penalty matrix used to fit ordinal smoothing splines.
</p>
<p>With an intercept included, the basis function matrix has the form 
</p>
<p style="text-align: center;"><code class="reqn">X = [X_0,  X_1]</code>
</p>

<p>where matrix <code>X_0</code> is an <code class="reqn">n</code> by 1 matrix of ones, and <code>X_1</code> is a matrix of dimension <code class="reqn">n</code> by <code class="reqn">r</code>. The <code>X_0</code> matrix contains the &quot;parametric part&quot; of the basis (i.e., the intercept). The matrix <code>X_1</code> contains the &quot;nonparametric part&quot; of the basis, which consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = 1 - (x \vee y) + (1 / 2K) * ( x(x-1) + y(y-1) ) + c </code>
</p>

<p>evaluated at all combinations of <code>x</code> and <code>knots</code>. The notation <code class="reqn">(x \vee y)</code> denotes the maximum of <code class="reqn">x</code> and <code class="reqn">y</code>, and the constant is <code class="reqn">c = (K-1)(2K-1) / (6K)</code>.
</p>
<p>The penalty matrix consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = 1 - (x \vee y) + (1 / 2K) * ( x(x-1) + y(y-1) ) + c </code>
</p>

<p>evaluated at all combinations of <code>x</code>.
</p>


<h3>Value</h3>

<p>Basis: Matrix of dimension <code>c(length(x), df)</code> where <code>df = length(knots) + intercept</code>.
</p>
<p>Penalty: Matrix of dimension <code>c(r, r)</code> where <code>r = length(x)</code> is the number of knots.
</p>


<h3>Note</h3>

<p>If the inputs <code>x</code> and <code>knots</code> are factors, they should have the same levels.
</p>
<p>If the inputs <code>x</code> and <code>knots</code> are integers, the <code>knots</code> should be a subset of the input <code>x</code>.
</p>
<p>If <code>ridge = TRUE</code>, the penalty matrix is the identity matrix.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing Spline ANOVA Models. 2nd Ed. New York, NY: Springer-Verlag. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2017). Regression with ordered predictors via ordinal smoothing splines. <em>Frontiers in Applied Mathematics and Statistics, 3</em>(15), 1-13. <a href="https://doi.org/10.3389/fams.2017.00015">doi:10.3389/fams.2017.00015</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+nominal">nominal</a></code> for a basis and penalty for unordered factors.
</p>
<p>See <code><a href="#topic+polynomial">polynomial</a></code> for a basis and penalty for numeric variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   standard parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- factor(sort(rep(LETTERS[1:4], length.out = n)))
knots &lt;- LETTERS[1:3]
eta &lt;- 1:4
y &lt;- eta[x] + rnorm(n, sd = 0.5)

# ordinal smoothing spline basis
X &lt;- basis.ord(x, knots, intercept = TRUE)

# ordinal smoothing spline penalty
Q &lt;- penalty.ord(knots, K = 4)

# pad Q with zeros (for intercept)
Q &lt;- rbind(0, cbind(0, Q))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- solve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta[x] - yhat)^2))



######***######   ridge parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- factor(sort(rep(LETTERS[1:4], length.out = n)))
knots &lt;- LETTERS[1:3]
eta &lt;- 1:4
y &lt;- eta[x] + rnorm(n, sd = 0.5)

# ordinal smoothing spline basis
X &lt;- basis.ord(x, knots, intercept = TRUE, ridge = TRUE)

# ordinal smoothing spline penalty (ridge)
Q &lt;- diag(rep(c(0, 1), times = c(1, ncol(X) - 1)))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- solve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta[x] - yhat)^2))

</code></pre>

<hr>
<h2 id='plot.ss'>
Plot method for Smoothing Spline Fit and Bootstrap
</h2><span id='topic+plot.ss'></span><span id='topic+plot.boot.ss'></span>

<h3>Description</h3>

<p>Default plotting methods for <code><a href="#topic+ss">ss</a></code> and <code><a href="#topic+boot.ss">boot.ss</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
plot(x, n = 201, ci = TRUE, xseq = NULL, ...)

## S3 method for class 'boot.ss'
plot(x, n = 201, ci = TRUE, xseq = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ss_+3A_x">x</code></td>
<td>

<p>an object of class 'ss' or 'boot.ss'
</p>
</td></tr>
<tr><td><code id="plot.ss_+3A_n">n</code></td>
<td>

<p>number of points used to plot smoothing spline estimate
</p>
</td></tr>
<tr><td><code id="plot.ss_+3A_ci">ci</code></td>
<td>

<p>logical indicating whether to include a confidence interval
</p>
</td></tr>
<tr><td><code id="plot.ss_+3A_xseq">xseq</code></td>
<td>

<p>ordered sequence of points at which to plot smoothing spline estimate
</p>
</td></tr>
<tr><td><code id="plot.ss_+3A_...">...</code></td>
<td>

<p>optional additional argument for the <code><a href="#topic+plotci">plotci</a></code> function, e.g., <code>level</code>, <code>col</code>, etc.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unless a sequence of points is provided via the <code>xseq</code> arugment, the plots are created by evaluating the smoothing spline fit at an equidistant sequence of <code>n</code> values that span the range of the training data.
</p>


<h3>Value</h3>

<p>Plot of the function estimate and confidence interval with the title displaying the effective degrees of freedom.
</p>


<h3>Note</h3>

<p>The <code>plot.ss</code> and <code>plot.boot.ss</code> functions produce plots that only differ in terms of their confidence intervals: <code>plot.ss</code> uses the Bayesian CIs, whereas <code>plot.boot.ss</code> uses the bootstrap CIs.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code> and <code><a href="#topic+boot.ss">boot.ss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit smoothing spline
ssfit &lt;- ss(x, y, nknots = 10)

# plot smoothing spline fit
plot(ssfit)

## Not run: 

# bootstrap smoothing spline
ssfitboot &lt;- boot(ssfit)

# plot smoothing spline bootstrap
plot(ssfitboot)

## End(Not run)

</code></pre>

<hr>
<h2 id='plotci'>
Generic X-Y Plotting with Confidence Intervals
</h2><span id='topic+plotci'></span>

<h3>Description</h3>

<p>Modification to the <code><a href="graphics.html#topic+plot">plot</a></code> function that adds confidence intervals. The CIs can be plotted using polygons (default) or error bars.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotci(x, y, se, level = 0.95, crit.val = NULL, 
       add = FALSE, col = NULL, col.ci = NULL, 
       alpha = NULL, bars = NULL, bw = 0.05, 
       linkinv = NULL, ci = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotci_+3A_x">x</code></td>
<td>

<p>a vector of 'x' values (<code class="reqn">n</code> by 1). If <code>y</code> is missing, the <code>x</code> input can be a list or matrix containing the <code>x</code>, <code>y</code>, and <code>se</code> arguments.
</p>
</td></tr>
<tr><td><code id="plotci_+3A_y">y</code></td>
<td>

<p>a vector of 'y' values (<code class="reqn">n</code> by 1).  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_se">se</code></td>
<td>

<p>a vector of standard error values (<code class="reqn">n</code> by 1).
</p>
</td></tr>
<tr><td><code id="plotci_+3A_level">level</code></td>
<td>

<p>confidence level for the intervals (between 0 and 1).  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_crit.val">crit.val</code></td>
<td>

<p>an optional critical value for the intervals. If provided, the <code>level</code> input is ignored. See Details.  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_add">add</code></td>
<td>

<p>a switch controlling whether a new plot should be created (via a call to <code><a href="graphics.html#topic+plot">plot</a></code>) or if the plot should be added to the current plot (via a call to <code><a href="graphics.html#topic+lines">lines</a></code>).
</p>
</td></tr>
<tr><td><code id="plotci_+3A_col">col</code></td>
<td>

<p>a character specifying the color for plotting the lines/points.  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_col.ci">col.ci</code></td>
<td>

<p>a character specifying the color for plotting the intervals.  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_alpha">alpha</code></td>
<td>

<p>a scalar between 0 and 1 controlling the transparency of the intervals.
</p>
</td></tr>
<tr><td><code id="plotci_+3A_bars">bars</code></td>
<td>

<p>a switch controlling whether the intervals should be plotted as bars or polygons.  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_bw">bw</code></td>
<td>

<p>a positive scalar controlling the bar width. Ignored if <code>bars = FALSE</code>.  
</p>
</td></tr>
<tr><td><code id="plotci_+3A_linkinv">linkinv</code></td>
<td>

<p>an inverse link function for the plotting. If provided, the function plots <code>x</code> versus <code>linkinv(y)</code> and the intervals are similarly transformed. 
</p>
</td></tr>
<tr><td><code id="plotci_+3A_ci">ci</code></td>
<td>

<p>an optional matrix if dimension <code class="reqn">n x 2</code> giving the confidence interval lower and upper bounds: <code>ci = cbind(lwr, upr)</code>
</p>
</td></tr>
<tr><td><code id="plotci_+3A_...">...</code></td>
<td>

<p>extra arguments passed to the <code>plot</code> or <code>lines</code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots <code>x</code> versus <code>y</code> with confidence intervals. Unless <code>ci</code> is provided, the CIs have the form <br /> <code>lwr = y - crit.val * se</code><br /> <code>upr = y + crit.val * se</code><br /> where <code>crit.val</code> is the critical value.
</p>
<p>If <code>crit.val = NULL</code>, the critival value is determined from the <code>level</code> input as<br /> <code>crit.val &lt;- qnorm(1-(1-level)/2)</code><br /> where <code><a href="stats.html#topic+qnorm">qnorm</a></code> is the quantile function for the standard normal distribution.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p>This function is used by <code><a href="#topic+plot.ss">plot.ss</a></code> to plot smoothing spline fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit smooth model
smod &lt;- sm(y ~ x, knots = 10)

# plot fit with 95% CI polygon
plotci(x, smod$fitted.values, smod$se.fit)

# plot fit with 95% CI bars
plotci(x, smod$fitted.values, smod$se.fit, bars = TRUE)

# plot fit +/- 1 SE
plotci(x, smod$fitted.values, smod$se.fit, crit.val = 1, bars = TRUE)

</code></pre>

<hr>
<h2 id='polynomial'>
Polynomial Smoothing Spline Basis and Penalty
</h2><span id='topic+polynomial'></span><span id='topic+basis.poly'></span><span id='topic+basis_poly'></span><span id='topic+penalty.poly'></span><span id='topic+penalty_poly'></span>

<h3>Description</h3>

<p>Generate the smoothing spline basis and penalty matrix for a polynomial spline. Derivatives of the smoothing spline basis matrix are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis.poly(x, knots, m = 2, d = 0, xmin = min(x), xmax = max(x), 
           periodic = FALSE, rescale = FALSE, intercept = FALSE, 
           bernoulli = TRUE, ridge = FALSE)

penalty.poly(x, m = 2, xmin = min(x), xmax = max(x), 
             periodic = FALSE, rescale = FALSE, bernoulli = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polynomial_+3A_x">x</code></td>
<td>

<p>Predictor variable (basis) or spline knots (penalty). Numeric or integer vector of length <code class="reqn">n</code>.
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_knots">knots</code></td>
<td>

<p>Spline knots. Numeric or integer vector of length <code class="reqn">r</code>.
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_m">m</code></td>
<td>

<p>Penalty order. &quot;m=1&quot; for linear smoothing spline, &quot;m=2&quot; for cubic, and &quot;m=3&quot; for quintic.  
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_d">d</code></td>
<td>

<p>Derivative order. &quot;d=0&quot; for smoothing spline basis, &quot;d=1&quot; for 1st derivative of basis, and &quot;d=2&quot; for 2nd derivative of basis.  
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_xmin">xmin</code></td>
<td>

<p>Minimum value of &quot;x&quot;.  
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_xmax">xmax</code></td>
<td>

<p>Maximum value of &quot;x&quot;.  
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_periodic">periodic</code></td>
<td>

<p>If <code>TRUE</code>, the smoothing spline basis is periodic w.r.t. the interval [<code>xmin</code>, <code>xmax</code>].
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_rescale">rescale</code></td>
<td>

<p>If <code>TRUE</code>, the nonparametric part of the basis is divided by the average of the reproducing kernel function evaluated at the <code>knots</code>.
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_intercept">intercept</code></td>
<td>

<p>If <code>TRUE</code>, the first column of the basis will be a column of ones. 
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_bernoulli">bernoulli</code></td>
<td>

<p>If <code>TRUE</code>, scaled Bernoulli polynomials are used for the basis and penalty functions.
</p>
</td></tr>
<tr><td><code id="polynomial_+3A_ridge">ridge</code></td>
<td>

<p>If <code>TRUE</code>, the basis matrix is post-multiplied by the inverse square root of the penalty matrix. See Note and Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates a basis function or penalty matrix used to fit linear, cubic, and quintic smoothing splines (or evaluate their derivatives). 
</p>
<p>For non-periodic smoothing splines, the basis function matrix has the form 
</p>
<p style="text-align: center;"><code class="reqn">X = [X_0,  X_1]</code>
</p>

<p>where the matrix <code>X_0</code> is of dimension <code class="reqn">n</code> by <code class="reqn">m-1</code> (plus 1 if an intercept is included), and <code>X_1</code> is a matrix of dimension <code class="reqn">n</code> by <code class="reqn">r</code>. 
</p>
<p>The <code>X_0</code> matrix contains the &quot;parametric part&quot; of the basis, which includes polynomial functions of <code>x</code> up to degree <code class="reqn">m-1</code>.
</p>
<p>The matrix <code>X_1</code> contains the &quot;nonparametric part&quot; of the basis, which consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = \kappa_m(x) \kappa_m(y) + (-1)^{m-1} \kappa_{2m}(|x-y|)</code>
</p>

<p>evaluated at all combinations of <code>x</code> and <code>knots</code>. The <code class="reqn">\kappa_v</code> functions are scaled Bernoulli polynomials.
</p>
<p>For periodic smoothing splines, the <code class="reqn">X_0</code> matrix only contains the intercept column and the modified reproducing kernel function 
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = (-1)^{m-1} \kappa_{2m}(|x-y|)</code>
</p>

<p>is evaluated for all combinations of <code>x</code> and <code>knots</code>.
</p>
<p>For non-periodic smoothing splines, the penalty matrix consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = \kappa_m(x) \kappa_m(y) + (-1)^{m-1} \kappa_{2m}(|x-y|)</code>
</p>

<p>evaluated at all combinations of <code>x</code>. For periodic smoothing splines, the modified reproducing kernel function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = (-1)^{m-1} \kappa_{2m}(|x-y|)</code>
</p>

<p>is evaluated for all combinations of <code>x</code>.
</p>
<p>If <code>bernoulli = FALSE</code>, the reproducing kernel function is defined as
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = (1/(m-1)!)^2 \int_0^1 (x - u)_+^{m-1} (y - u)_+^{m-1} du </code>
</p>

<p>where <code class="reqn">(.)_+ = \max(., 0)</code>. This produces the &quot;classic&quot; definition of a smoothing spline, where the function estimate is a piecewise polynomial function with pieces of degree <code class="reqn">2m - 1</code>.
</p>


<h3>Value</h3>

<p>Basis: Matrix of dimension <code>c(length(x), df)</code> where <code>df &gt;= length(knots)</code>. If the smoothing spline basis is not periodic (default), then the number of columns is <code>df = length(knots) + m - !intercept</code>. For periodic smoothing splines, the basis has <code>m</code> fewer columns.
</p>
<p>Penalty: Matrix of dimension <code>c(r, r)</code> where <code>r = length(x)</code> is the number of knots.
</p>


<h3>Note</h3>

<p>Inputs <code>x</code> and <code>knots</code> should be within the interval [<code>xmin</code>, <code>xmax</code>].
</p>
<p>If <code>ridge = TRUE</code>, the penalty matrix is the identity matrix.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing Spline ANOVA Models. 2nd Ed. New York, NY: Springer-Verlag.  <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2017). Regression with ordered predictors via ordinal smoothing splines. <em>Frontiers in Applied Mathematics and Statistics, 3</em>(15), 1-13. <a href="https://doi.org/10.3389/fams.2017.00015">doi:10.3389/fams.2017.00015</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Helwig, N. E., &amp; Ma, P. (2015). Fast and stable multiple smoothing parameter selection in smoothing spline analysis of variance models with large samples. <em>Journal of Computational and Graphical Statistics, 24</em>(3), 715-732. <a href="https://doi.org/10.1080/10618600.2014.926819">doi:10.1080/10618600.2014.926819</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+thinplate">thinplate</a></code> for a thin plate spline basis and penalty.
</p>
<p>See <code><a href="#topic+ordinal">ordinal</a></code> for a basis and penalty for ordered factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   standard parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- seq(0, 1, length.out = n)
knots &lt;- seq(0, 0.95, by = 0.05)
eta &lt;- 1 + 2 * x + sin(2 * pi * x)
y &lt;- eta + rnorm(n, sd = 0.5)

# cubic smoothing spline basis
X &lt;- basis.poly(x, knots, intercept = TRUE)

# cubic smoothing spline penalty
Q &lt;- penalty.poly(knots, xmin = min(x), xmax = max(x))

# pad Q with zeros (for intercept and linear effect)
Q &lt;- rbind(0, 0, cbind(0, 0, Q))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- solve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta - yhat)^2))

# plot results
plot(x, y)
lines(x, yhat)



######***######   ridge parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- seq(0, 1, length.out = n)
knots &lt;- seq(0, 0.95, by = 0.05)
eta &lt;- 1 + 2 * x + sin(2 * pi * x)
y &lt;- eta + rnorm(n, sd = 0.5)

# cubic smoothing spline basis
X &lt;- basis.poly(x, knots, intercept = TRUE, ridge = TRUE)

# cubic smoothing spline penalty (ridge)
Q &lt;- diag(rep(c(0, 1), times = c(2, ncol(X) - 2)))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- solve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta - yhat)^2))

# plot results
plot(x, y)
lines(x, yhat)

</code></pre>

<hr>
<h2 id='predict.gsm'>
Predict method for Generalized Smooth Model Fits
</h2><span id='topic+predict.gsm'></span>

<h3>Description</h3>

<p><code>predict</code> method for class &quot;gsm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gsm'
predict(object, newdata = NULL, se.fit = FALSE, 
        type = c("link", "response", "terms"), 
        terms = NULL, na.action = na.pass,
        intercept = NULL, combine = TRUE, design = FALSE, 
        check.newdata = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gsm_+3A_object">object</code></td>
<td>

<p>a fit from <code>gsm</code>. 
</p>
</td></tr> 
<tr><td><code id="predict.gsm_+3A_newdata">newdata</code></td>
<td>

<p>an optional list or data frame in which to look for variables with which to predict. If omitted, the original data are used.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_se.fit">se.fit</code></td>
<td>

<p>a switch indicating if standard errors are required.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_type">type</code></td>
<td>

<p>type of prediction (link, response, or model term). Can be abbreviated.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_terms">terms</code></td>
<td>

<p>which terms to include in the fit. The default of <code>NULL</code> uses all terms. This input <b>is</b> used regardless of the <code>type</code> of prediction.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_na.action">na.action</code></td>
<td>

<p>function determining what should be done with missing values in <code>newdata</code>. The default is to predict <code>NA</code>.  
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_intercept">intercept</code></td>
<td>

<p>a switch indicating if the intercept should be included in the prediction. If <code>NULL</code> (default), the intercept is included in the fit only when <code>type = "r"</code> and <code>terms</code> includes all model terms.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_combine">combine</code></td>
<td>

<p>a switch indicating if the parametric and smooth components of the prediction should be combined (default) or returned separately.  
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_design">design</code></td>
<td>

<p>a switch indicating if the model (design) matrix for the prediction should be returned.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_check.newdata">check.newdata</code></td>
<td>

<p>a switch indicating if the <code>newdata</code> should be checked for consistency (e.g., class and range). Ignored if <code>newdata</code> is not provided.
</p>
</td></tr>
<tr><td><code id="predict.gsm_+3A_...">...</code></td>
<td>

<p>additional arguments affecting the prediction produced (currently ignored).  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by the <code><a href="stats.html#topic+predict.glm">predict.glm</a></code> function in R's <b>stats</b> package.
</p>
<p>Produces predicted values, obtained by evaluating the regression function in the frame <code>newdata</code> (which defaults to <code>model.frame(object)</code>). If the logical <code>se.fit</code> is <code>TRUE</code>, standard errors of the predictions are calculated. 
</p>
<p>If <code>newdata</code> is omitted the predictions are based on the data used for the fit. Regardless of the <code>newdata</code> argument, how cases with missing values are handled is determined by the <code>na.action</code> argument. If <code>na.action = na.omit</code> omitted cases will not appear in the predictions, whereas if <code>na.action = na.exclude</code> they will appear (in predictions and standard errors), with value <code>NA</code>.
</p>
<p>Similar to the <code>glm</code> function, setting <code>type = "terms"</code> returns a matrix giving the predictions for each of the requested model <code>terms</code>. Unlike the <code>glm</code> function, this function allows for predictions using any subset of the model terms. Specifically, the predictions (on both the <code>link</code> and <code>response</code> scale) will only include the requested <code>terms</code>, which makes it possible to obtain estimates (and standard errors) for subsets of model terms. In this case, the <code>newdata</code> only needs to contain data for the subset of variables that are requested in <code>terms</code>.
</p>


<h3>Value</h3>

<p>Default use returns a vector of predictions. Otherwise the form of the output will depend on the combination of argumments: <code>se.fit</code>, <code>type</code>, <code>combine</code>, and <code>design</code>.
</p>
<p><code>type = "link"</code>: <br />
When <code>se.fit = FALSE</code> and <code>design = FALSE</code>, the output will be the predictions on the link scale. When <code>se.fit = TRUE</code> or <code>design = TRUE</code>, the output is a list with components <code>fit</code>, <code>se.fit</code> (if requested), and <code>X</code> (if requested). 
</p>
<p><code>type = "response"</code>: <br />
When <code>se.fit = FALSE</code> and <code>design = FALSE</code>, the output will be the predictions on the data scale. When <code>se.fit = TRUE</code> or <code>design = TRUE</code>, the output is a list with components <code>fit</code>, <code>se.fit</code> (if requested), and <code>X</code> (if requested). 
</p>
<p><code>type = "terms"</code>: <br />
When <code>se.fit = FALSE</code> and <code>design = FALSE</code>, the output will be the predictions for each term on the link scale. When <code>se.fit = TRUE</code> or <code>design = TRUE</code>, the output is a list with components <code>fit</code>, <code>se.fit</code> (if requested), and <code>X</code> (if requested). 
</p>
<p>Regardless of the <code>type</code>, setting <code>combine = FALSE</code> decomposes the requested result(s) into the <b>p</b>arametric and <b>s</b>mooth contributions.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.glm.html
</p>
<p>Craven, P. and Wahba, G. (1979). Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. <em>Numerische Mathematik, 31</em>, 377-403. <a href="https://doi.org/10.1007/BF01404567">doi:10.1007/BF01404567</a>
</p>
<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsm">gsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- rbinom(n = n, size = 1, p = 1 / (1 + exp(-fx)))

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit gsm with specified knots (tprk = TRUE)
gsm.ssa &lt;- gsm(y ~ x * z, family = binomial, knots = knots)
pred &lt;- predict(gsm.ssa)
term &lt;- predict(gsm.ssa, type = "terms")
mean((gsm.ssa$linear.predictors - pred)^2)
mean((gsm.ssa$linear.predictors - rowSums(term) - attr(term, "constant"))^2)

# fit gsm with specified knots (tprk = FALSE)
gsm.gam &lt;- gsm(y ~ x * z, family = binomial, knots = knots, tprk = FALSE)
pred &lt;- predict(gsm.gam)
term &lt;- predict(gsm.gam, type = "terms")
mean((gsm.gam$linear.predictors - pred)^2)
mean((gsm.gam$linear.predictors - rowSums(term) - attr(term, "constant"))^2)

</code></pre>

<hr>
<h2 id='predict.sm'>
Predict method for Smooth Model Fits
</h2><span id='topic+predict.sm'></span>

<h3>Description</h3>

<p><code>predict</code> method for class &quot;sm&quot;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sm'
predict(object, newdata = NULL, se.fit = FALSE, 
        interval = c("none", "confidence", "prediction"),
        level = 0.95, type = c("response", "terms"), 
        terms = NULL, na.action = na.pass,
        intercept = NULL, combine = TRUE, design = FALSE, 
        check.newdata = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sm_+3A_object">object</code></td>
<td>

<p>a fit from <code>sm</code>. 
</p>
</td></tr> 
<tr><td><code id="predict.sm_+3A_newdata">newdata</code></td>
<td>

<p>an optional list or data frame in which to look for variables with which to predict. If omitted, the original data are used.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_se.fit">se.fit</code></td>
<td>

<p>a switch indicating if standard errors are required.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_interval">interval</code></td>
<td>

<p>type of interval calculation. Can be abbreviated.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_level">level</code></td>
<td>

<p>tolerance/confidence level.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_type">type</code></td>
<td>

<p>type of prediction (response or model term). Can be abbreviated.  
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_terms">terms</code></td>
<td>

<p>which terms to include in the fit. The default of <code>NULL</code> uses all terms. This input <b>is</b> used regardless of the <code>type</code> of prediction.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_na.action">na.action</code></td>
<td>

<p>function determining what should be done with missing values in <code>newdata</code>. The default is to predict <code>NA</code>.  
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_intercept">intercept</code></td>
<td>

<p>a switch indicating if the intercept should be included in the prediction. If <code>NULL</code> (default), the intercept is included in the fit only when <code>type = "r"</code> and <code>terms</code> includes all model terms.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_combine">combine</code></td>
<td>

<p>a switch indicating if the parametric and smooth components of the prediction should be combined (default) or returned separately.  
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_design">design</code></td>
<td>

<p>a switch indicating if the model (design) matrix for the prediction should be returned.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_check.newdata">check.newdata</code></td>
<td>

<p>a switch indicating if the <code>newdata</code> should be checked for consistency (e.g., class and range). Ignored if <code>newdata</code> is not provided.
</p>
</td></tr>
<tr><td><code id="predict.sm_+3A_...">...</code></td>
<td>

<p>additional arguments affecting the prediction produced (currently ignored).  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by the <code><a href="stats.html#topic+predict.lm">predict.lm</a></code> function in R's <b>stats</b> package.
</p>
<p>Produces predicted values, obtained by evaluating the regression function in the frame <code>newdata</code> (which defaults to <code>model.frame(object)</code>). If the logical <code>se.fit</code> is <code>TRUE</code>, standard errors of the predictions are calculated. Setting <code>interval</code>s specifies computation of confidence or prediction (tolerance) intervals at the specified level, sometimes referred to as narrow vs. wide intervals. 
</p>
<p>If <code>newdata</code> is omitted the predictions are based on the data used for the fit. Regardless of the <code>newdata</code> argument, how cases with missing values are handled is determined by the <code>na.action</code> argument. If <code>na.action = na.omit</code> omitted cases will not appear in the predictions, whereas if <code>na.action = na.exclude</code> they will appear (in predictions, standard errors or interval limits), with value <code>NA</code>.
</p>
<p>Similar to the <code>lm</code> function, setting <code>type = "terms"</code> returns a matrix giving the predictions for each of the requested model <code>terms</code>. Unlike the <code>lm</code> function, this function allows for predictions using any subset of the model terms. Specifically, when <code>type = "response"</code> the predictions will only include the requested <code>terms</code>, which makes it possible to obtain estimates (and standard errors and intervals) for subsets of model terms. In this case, the <code>newdata</code> only needs to contain data for the subset of variables that are requested in <code>terms</code>.
</p>


<h3>Value</h3>

<p>Default use returns a vector of predictions. Otherwise the form of the output will depend on the combination of argumments: <code>se.fit</code>, <code>interval</code>, <code>type</code>, <code>combine</code>, and <code>design</code>.
</p>
<p><code>type = "response"</code>: <br />
When <code>se.fit = FALSE</code> and <code>design = FALSE</code>, the output will be the predictions (possibly with <code>lwr</code> and <code>upr</code> interval bounds). When <code>se.fit = TRUE</code> or <code>design = TRUE</code>, the output is a list with components <code>fit</code>, <code>se.fit</code> (if requested), and <code>X</code> (if requested). 
</p>
<p><code>type = "terms"</code>: <br />
When <code>se.fit = FALSE</code> and <code>design = FALSE</code>, the output will be the predictions for each term (possibly with <code>lwr</code> and <code>upr</code> interval bounds). When <code>se.fit = TRUE</code> or <code>design = TRUE</code>, the output is a list with components <code>fit</code>, <code>se.fit</code> (if requested), and <code>X</code> (if requested). 
</p>
<p>Regardless of the <code>type</code>, setting <code>combine = FALSE</code> decomposes the requested result(s) into the <b>p</b>arametric and <b>s</b>mooth contributions. 
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html
</p>
<p>Craven, P. and Wahba, G. (1979). Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. <em>Numerische Mathematik, 31</em>, 377-403. <a href="https://doi.org/10.1007/BF01404567">doi:10.1007/BF01404567</a>
</p>
<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm">sm</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- fx + rnorm(n, sd = 0.5)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots
smod &lt;- sm(y ~ x * z, knots = knots)

# get model "response" predictions
fit &lt;- predict(smod)
mean((smod$fitted.values - fit)^2)

# get model "terms" predictions
trm &lt;- predict(smod, type = "terms")
attr(trm, "constant")
head(trm)
mean((smod$fitted.values - rowSums(trm) - attr(trm, "constant"))^2)

# get predictions with "newdata" (= the original data)
fit &lt;- predict(smod, newdata = data.frame(x = x, z = z))
mean((fit - smod$fitted.values)^2)

# get predictions and standard errors
fit &lt;- predict(smod, se.fit = TRUE)
mean((fit$fit - smod$fitted.values)^2)
mean((fit$se.fit - smod$se.fit)^2)

# get 99% confidence interval
fit &lt;- predict(smod, interval = "c", level = 0.99)
head(fit)

# get 99% prediction interval
fit &lt;- predict(smod, interval = "p", level = 0.99)
head(fit)

# get predictions only for x main effect
fit &lt;- predict(smod, newdata = data.frame(x = x), 
               se.fit = TRUE, terms = "x")
plotci(x, fit$fit, fit$se.fit)

# get predictions only for each group
fit.a &lt;- predict(smod, newdata = data.frame(x = x, z = "a"), se.fit = TRUE)
fit.b &lt;- predict(smod, newdata = data.frame(x = x, z = "b"), se.fit = TRUE)
fit.c &lt;- predict(smod, newdata = data.frame(x = x, z = "c"), se.fit = TRUE)

# plot results (truth as dashed line)
plotci(x = x, y = fit.a$fit, se = fit.a$se.fit,
       col = "red", col.ci = "pink", ylim = c(-6, 6))
lines(x, fun(x, rep(1, n)), lty = 2, col = "red")
plotci(x = x, y = fit.b$fit, se = fit.b$se.fit,
       col = "blue", col.ci = "cyan", add = TRUE)
lines(x, fun(x, rep(2, n)), lty = 2, col = "blue")
plotci(x = x, y = fit.c$fit, se = fit.c$se.fit,
       col = "darkgreen", col.ci = "lightgreen", add = TRUE)
lines(x, fun(x, rep(3, n)), lty = 2, col = "darkgreen")

# add legends
legend("bottomleft", legend = c("Truth", "Estimate", "CI"), 
       lty = c(2, 1, NA), lwd = c(1, 2, NA), 
       col = c("black", "black","gray80"),
       pch = c(NA, NA, 15), pt.cex = 2, bty = "n")
legend("bottomright", legend = letters[1:3], 
       lwd = 2, col = c("red", "blue", "darkgreen"), bty = "n")

</code></pre>

<hr>
<h2 id='predict.ss'>
Predict method for Smoothing Spline Fits
</h2><span id='topic+predict.ss'></span>

<h3>Description</h3>

<p><code>predict</code> method for class &quot;ss&quot;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
predict(object, x, deriv = 0, se.fit = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ss_+3A_object">object</code></td>
<td>

<p>a fit from <code><a href="#topic+ss">ss</a></code>. 
</p>
</td></tr> 
<tr><td><code id="predict.ss_+3A_x">x</code></td>
<td>

<p>the new values of x.
</p>
</td></tr>
<tr><td><code id="predict.ss_+3A_deriv">deriv</code></td>
<td>

<p>integer; the order of the derivative required.
</p>
</td></tr>
<tr><td><code id="predict.ss_+3A_se.fit">se.fit</code></td>
<td>

<p>a switch indicating if standard errors are required.
</p>
</td></tr>
<tr><td><code id="predict.ss_+3A_...">...</code></td>
<td>

<p>additional arguments affecting the prediction produced (currently ignored).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by the <code><a href="stats.html#topic+predict.smooth.spline">predict.smooth.spline</a></code> function in R's <b>stats</b> package.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The input <code>x</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The fitted values or derivatives at x.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>The standard errors of the fitted values or derivatives (if requested).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.smooth.spline.html
</p>
<p>Craven, P. and Wahba, G. (1979). Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. <em>Numerische Mathematik, 31</em>, 377-403. <a href="https://doi.org/10.1007/BF01404567">doi:10.1007/BF01404567</a>
</p>
<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# GCV selection (default)
ss.GCV &lt;- ss(x, y, nknots = 10)

# get predictions and SEs (at design points)
fit &lt;- predict(ss.GCV, x = x)
head(fit)

# compare to original fit
mean((fit$y - ss.GCV$y)^2)

# plot result (with default 95% CI)
plotci(fit)

# estimate first derivative
d1 &lt;- 3 + 2 * pi * cos(2 * pi * x)
fit &lt;- predict(ss.GCV, x = x, deriv = 1)
head(fit)

# plot result (with default 95% CI)
plotci(fit)
lines(x, d1, lty = 2)   # truth

</code></pre>

<hr>
<h2 id='psolve'>
Pseudo-Solve a System of Equations
</h2><span id='topic+psolve'></span>

<h3>Description</h3>

<p>This generic function solves the equation <code>a %*% x = b</code> for <code>x</code>, where <code>b</code> can be either a vector or a matrix. This implementation is similar to <code><a href="Matrix.html#topic+solve">solve</a></code>, but uses a pseudo-inverse if the system is computationally singular.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psolve(a, b, tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psolve_+3A_a">a</code></td>
<td>

<p>a rectangular numeric matrix containing the coefficients of the linear system. 
</p>
</td></tr>
<tr><td><code id="psolve_+3A_b">b</code></td>
<td>

<p>a numeric vector or matrix giving the right-hand side(s) of the linear system. If missing, <code>b</code> is taken to be an identity matrix and solve will return the (pseudo-)inverse of <code>a</code>.
</p>
</td></tr>
<tr><td><code id="psolve_+3A_tol">tol</code></td>
<td>

<p>the tolerance for detecting linear dependencies in the columns of a. The default is <code>.Machine$double.eps</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>a</code> is a symmetric matrix, <code><a href="base.html#topic+eigen">eigen</a></code> is used to compute the (pseudo-)inverse. This assumes that <code>a</code> is a positive semi-definite matrix. Otherwise <code>svd</code> is used to compute the (pseudo-)inverse for rectangular matrices.
</p>


<h3>Value</h3>

<p>If <code>b</code> is missing, returns the (pseudo-)inverse of <code>a</code>. Otherwise returns <code>psolve(a) %*% b</code>.
</p>


<h3>Note</h3>

<p>The pseudo-inverse is calculated by inverting the eigen/singular values that are greater than the first value multiplied by <code>tol * min(dim(a))</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Moore, E. H. (1920). On the reciprocal of the general algebraic matrix. <em>Bulletin of the American Mathematical Society, 26</em>, 394-395. <a href="https://doi.org/10.1090/S0002-9904-1920-03322-7">doi:10.1090/S0002-9904-1920-03322-7</a>
</p>
<p>Penrose, R. (1955). A generalized inverse for matrices. <em>Mathematical Proceedings of the Cambridge Philosophical Society, 51(3)</em>, 406-413. <a href="https://doi.org/10.1017/S0305004100030401">doi:10.1017/S0305004100030401</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+msqrt">msqrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate X
set.seed(0)
X &lt;- matrix(rnorm(100), 20, 5)
X &lt;- cbind(X, rowSums(X))

# pseudo-inverse of X  (dim = 6 by 20)
Xinv &lt;- psolve(X)

# pseudo-inverse of crossprod(X)  (dim = 6 by 6)
XtXinv &lt;- psolve(crossprod(X))

</code></pre>

<hr>
<h2 id='residuals'>
Extract Model Residuals
</h2><span id='topic+residuals.ss'></span><span id='topic+residuals.sm'></span><span id='topic+residuals.gsm'></span>

<h3>Description</h3>

<p>Extracts the residuals from a fit smoothing spline (&quot;ss&quot;), smooth model (&quot;sm&quot;), or generalized smooth model (&quot;gsm&quot;) object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
residuals(object, type = c("working", "response", "deviance", 
                           "pearson", "partial"), ...)

## S3 method for class 'sm'
residuals(object, type = c("working", "response", "deviance", 
                           "pearson", "partial"), ...)
                           
## S3 method for class 'gsm'
residuals(object, type = c("deviance", "pearson", "working", 
                           "response", "partial"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals_+3A_object">object</code></td>
<td>

<p>an object of class &quot;ss&quot;, &quot;sm&quot;, or &quot;gsm&quot;
</p>
</td></tr>
<tr><td><code id="residuals_+3A_type">type</code></td>
<td>

<p>type of residuals
</p>
</td></tr>
<tr><td><code id="residuals_+3A_...">...</code></td>
<td>

<p>other arugments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects of class <code><a href="#topic+ss">ss</a></code> and <code><a href="#topic+sm">sm</a></code> <br />
* the working and response residuals are defined as 'observed - fitted' <br />
* the deviance and Pearson residuals multiply the working residuals by <code>sqrt(weights(object))</code>
</p>
<p>For objects of class <code><a href="#topic+gsm">gsm</a></code>, the residual types are the same as those produced by the <code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code> function
</p>


<h3>Value</h3>

<p>Residuals from <code>object</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Chambers, J. M. and Hastie, T. J. (1992) <em>Statistical Models in S</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# smoothing spline
mod.ss &lt;- ss(x, y, nknots = 10)
res.ss &lt;- residuals(mod.ss)

# smooth model
mod.sm &lt;- sm(y ~ x, knots = 10)
res.sm &lt;- residuals(mod.sm)

# generalized smooth model (family = gaussian)
mod.gsm &lt;- gsm(y ~ x, knots = 10)
res.gsm &lt;- residuals(mod.gsm)

# y = fitted + residuals
mean((y - fitted(mod.ss) - res.ss)^2)
mean((y - fitted(mod.sm) - res.sm)^2)
mean((y - fitted(mod.gsm) - res.gsm)^2)
</code></pre>

<hr>
<h2 id='sm'>
Fit a Smooth Model
</h2><span id='topic+sm'></span>

<h3>Description</h3>

<p>Fits a semi- or nonparametric regression model with the smoothing parameter(s) selected via one of eight methods: GCV, OCV, GACV, ACV, REML, ML, AIC, or BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm(formula, data, weights, types = NULL, tprk = TRUE, knots = NULL,
   skip.iter = TRUE, df, spar = NULL, lambda = NULL, control = list(),
   method = c("GCV", "OCV", "GACV", "ACV", "REML", "ML", "AIC", "BIC"),
   xrange = NULL, thetas = NULL, mf = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm_+3A_formula">formula</code></td>
<td>

<p>Object of class &quot;formula&quot; (or one that can be coerced to that class): a symbolic description of the model to be fitted. Uses the same syntax as <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>.
</p>
</td></tr>
<tr><td><code id="sm_+3A_data">data</code></td>
<td>

<p>Optional data frame, list or environment (or object coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing the variables in the model. If not found in data, the variables are taken from <code>environment(formula)</code>, typically the environment from which <code>sm</code> is called.  
</p>
</td></tr>
<tr><td><code id="sm_+3A_weights">weights</code></td>
<td>

<p>Optional vector of weights to be used in the fitting process. If provided, weighted least squares is used. Defaults to all 1.
</p>
</td></tr>
<tr><td><code id="sm_+3A_types">types</code></td>
<td>

<p>Named list giving the type of smooth to use for each predictor. If <code>NULL</code>, the type is inferred from the data. See &quot;Types of Smooths&quot; section for details.
</p>
</td></tr>
<tr><td><code id="sm_+3A_tprk">tprk</code></td>
<td>

<p>Logical specifying how to parameterize smooth models with multiple predictors. If <code>TRUE</code> (default), a <b>t</b>ensor <b>p</b>roduct <b>r</b>eproducing <b>k</b>ernel function is used to represent the function. If <code>FALSE</code>, a tensor product of marginal kernel functions is used to represent the function. See the &quot;Multiple Smooths&quot; section for details.
</p>
</td></tr>
<tr><td><code id="sm_+3A_knots">knots</code></td>
<td>

<p>Spline knots for the estimation of the nonparametric effects. For models with multiple predictors, the knot specification will depend on the <code>tprk</code> input. See the &quot;Choosing Knots&quot; section for details
</p>
</td></tr>
<tr><td><code id="sm_+3A_skip.iter">skip.iter</code></td>
<td>

<p>Set to <code>FALSE</code> for deep tuning of the hyperparameters. Only applicable when multiple smooth terms are included. See the &quot;Parameter Tuning&quot; section for details.
</p>
</td></tr>
<tr><td><code id="sm_+3A_df">df</code></td>
<td>

<p>Equivalent degrees of freedom (trace of the smoother matrix). Must be in <code class="reqn">[m,n]</code> where <code class="reqn">m</code> is the number of columns of the null space basis function matrix <code class="reqn">X</code>, and <code class="reqn">n</code> is the number of observations. Will be approximate if <code>skip.iter = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sm_+3A_spar">spar</code></td>
<td>

<p>Smoothing parameter. Typically (but not always) in the range <code class="reqn">(0,1]</code>. If specified <code>lambda = 256^(3*(spar-1))</code>.
</p>
</td></tr>
<tr><td><code id="sm_+3A_lambda">lambda</code></td>
<td>

<p>Computational smoothing parameter. This value is weighted by <code class="reqn">n</code> to form the penalty coefficient (see Details). Ignored if <code>spar</code> is provided.
</p>
</td></tr>
<tr><td><code id="sm_+3A_control">control</code></td>
<td>

<p>Optional list with named components that control the optimization specs for the smoothing parameter selection routine.
</p>
<p><b>Note</b> that spar is only searched for in the interval <code class="reqn">[lower, upper]</code>.
</p>

<dl>
<dt>lower:</dt><dd><p>lower bound for spar; defaults to -1.5</p>
</dd>
<dt>upper:</dt><dd><p>upper bound for spar; defaults to 1.5</p>
</dd>
<dt>tol:</dt><dd><p>the absolute precision (<b>tol</b>erance) used by <code><a href="stats.html#topic+optimize">optimize</a></code> and <code><a href="stats.html#topic+nlm">nlm</a></code>; defaults to 1e-8.</p>
</dd>
<dt>iterlim:</dt><dd><p>the iteration limit used by <code><a href="stats.html#topic+nlm">nlm</a></code>; defaults to 5000.</p>
</dd>
<dt>print.level:</dt><dd><p>the print level used by <code><a href="stats.html#topic+nlm">nlm</a></code>; defaults to 0 (no printing).</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="sm_+3A_method">method</code></td>
<td>

<p>Method for selecting the smoothing parameter. Ignored if <code>lambda</code> is provided and <code>skip.iter = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="sm_+3A_xrange">xrange</code></td>
<td>

<p>Optional named list containing the range of each predictor. If <code>NULL</code>, the ranges are calculated from the input <code>data</code>.
</p>
</td></tr>
<tr><td><code id="sm_+3A_thetas">thetas</code></td>
<td>

<p>Optional vector of hyperparameters to use for smoothing. If <code>NULL</code>, these are tuned using the requested <code>method</code>.
</p>
</td></tr>
<tr><td><code id="sm_+3A_mf">mf</code></td>
<td>

<p>Optional model frame constructed from <code>formula</code> and <code>data</code> (and potentially <code>weights</code>).
</p>
</td></tr>
</table>
<p>Note: the last two arguments are not intended to be called by the typical user of this function. These arguments are included primarily for internal usage by the <code><a href="#topic+boot.sm">boot.sm</a></code> function.
</p>


<h3>Details</h3>

<p>Letting <code class="reqn">f_i = f(x_i)</code> with <code class="reqn">x_i = (x_{i1}, \ldots, x_{ip})</code>, the function is represented as </p>
<p style="text-align: center;"><code class="reqn">f = X \beta + Z \alpha</code>
</p>
<p> where the basis functions in <code class="reqn">X</code> span the null space (i.e., parametric effects), and <code class="reqn">Z</code> contains the kernel function(s) of the contrast space (i.e., nonparametric effects) evaluated at all combinations of observed data points and knots. The vectors <code class="reqn">\beta</code> and <code class="reqn">\alpha</code> contain unknown basis function coefficients.
</p>
<p>Letting <code class="reqn">M =  (X, Z)</code> and <code class="reqn">\gamma = (\beta', \alpha')'</code>, the penalized least squares problem has the form
</p>
<p style="text-align: center;"><code class="reqn">
(y - M \gamma)' W (y - M \gamma) + n \lambda \alpha' Q \alpha
</code>
</p>

<p>where <code class="reqn">W</code> is a diagonal matrix containg the weights, and <code class="reqn">Q</code> is the penalty matrix. The optimal coefficients are the solution to 
</p>
<p style="text-align: center;"><code class="reqn">
(M' W M + n \lambda P) \gamma = M' W y
</code>
</p>

<p>where <code class="reqn">P</code> is the penalty matrix <code class="reqn">Q</code> augmented with zeros corresponding to the <code class="reqn">\beta</code> in <code class="reqn">\gamma</code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;sm&quot; with components:
</p>
<table>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted values, i.e., predictions.</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>the standard errors of the fitted values.</p>
</td></tr>
<tr><td><code>sse</code></td>
<td>
<p>the sum-of-squared errors.</p>
</td></tr>
<tr><td><code>cv.crit</code></td>
<td>
<p>the cross-validation criterion.</p>
</td></tr>
<tr><td><code>nsdf</code></td>
<td>
<p>the degrees of freedom (Df) for the null space.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the estimated degrees of freedom (Df) for the fit model.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom = <code>nobs - df</code></p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>the observed coefficient of multiple determination.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the estimate of the error standard deviation.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log-likelihood (if <code>method</code> is REML or ML).</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Akaike's Information Criterion (if <code>method</code> is AIC).</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Bayesian Information Criterion (if <code>method</code> is BIC).</p>
</td></tr>
<tr><td><code>spar</code></td>
<td>
<p>the value of <code>spar</code> computed or given, i.e., <code class="reqn">s = 1 + \log_{256}(\lambda)/3</code></p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the value of <code class="reqn">\lambda</code> corresponding to <code>spar</code>, i.e., <code class="reqn">\lambda = 256^{3(s-1)}</code>.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>the smoothness penalty <code class="reqn">\alpha' Q \alpha</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the basis function coefficients used for the fit model.</p>
</td></tr>
<tr><td><code>cov.sqrt</code></td>
<td>
<p>the square-root of the covariance matrix of <code>coefficients</code>. Note: <code>tcrossprod(cov.sqrt)</code> reconstructs the covariance matrix. </p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations used by <code>nlm</code> (if applicable).</p>
</td></tr>
<tr><td><code>specs</code></td>
<td>
<p>a list with information used for prediction purposes:
</p>

<dl>
<dt>knots</dt><dd><p>the spline knots used for each predictor.</p>
</dd>
<dt>thetas</dt><dd><p>the &quot;extra&quot; tuning parameters used to weight the penalties.</p>
</dd>
<dt>xrng</dt><dd><p>the ranges of the predictor variables.</p>
</dd>
<dt>xlev</dt><dd><p>the factor levels of the predictor variables (if applicable).</p>
</dd>
<dt>tprk</dt><dd><p>logical controlling the formation of tensor product smooths.</p>
</dd>
<dt>skip.iter</dt><dd><p>logical controlling the parameter tuning (same as input).</p>
</dd>
<dt>control</dt><dd><p>the <code>control</code> options use for tuning.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the data used to fit the model.</p>
</td></tr>
<tr><td><code>types</code></td>
<td>
<p>the type of smooth used for each predictor.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms included in the fit model.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the <code>method</code> used for smoothing parameter selection. Will be <code>NULL</code> if <code>lambda</code> was provided.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula specifying the fit model.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used for fitting (if applicable)</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Methods </h3>

<p>The smoothing parameter can be selected using one of eight methods: <br />
Generalized Cross-Validation (GCV) <br />
Ordinary Cross-Validation (OCV) <br />
Generalized Approximate Cross-Validation (GACV) <br />
Approximate Cross-Validation (ACV) <br />
Restricted Maximum Likelihood (REML) <br />
Maximum Likelihood (ML) <br />
Akaike's Information Criterion (AIC) <br />
Bayesian Information Criterion (BIC)
</p>


<h3>Types of Smooths </h3>

<p>The following codes specify the spline types:
</p>

<table>
<tr>
 <td style="text-align: left;">
par </td><td style="text-align: left;"> Parametric effect (factor, integer, or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
nom </td><td style="text-align: left;"> Nominal smoothing spline (unordered factor). </td>
</tr>
<tr>
 <td style="text-align: left;">
ord </td><td style="text-align: left;"> Ordinal smoothing spline (ordered factor). </td>
</tr>
<tr>
 <td style="text-align: left;">
lin </td><td style="text-align: left;"> Linear smoothing spline (integer or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
cub </td><td style="text-align: left;"> Cubic smoothing spline (integer or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
qui </td><td style="text-align: left;"> Quintic smoothing spline (integer or numeric). </td>
</tr>
<tr>
 <td style="text-align: left;">
per </td><td style="text-align: left;"> Periodic smoothing spline (integer or numeric).</td>
</tr>
<tr>
 <td style="text-align: left;">  
sph </td><td style="text-align: left;"> Spherical spline (matrix with <code class="reqn">d = 2</code> columns: lat, long). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps </td><td style="text-align: left;"> Thin plate spline (matrix with <code class="reqn">d \ge 1</code> columns).
</td>
</tr>

</table>

<p>For finer control of some specialized spline types:
</p>

<table>
<tr>
 <td style="text-align: left;">
per.lin </td><td style="text-align: left;"> Linear periodic spline (<code class="reqn">m = 1</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
per.cub </td><td style="text-align: left;"> Cubic periodic spline (<code class="reqn">m = 2</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
per.qui </td><td style="text-align: left;"> Quintic periodic spline (<code class="reqn">m = 3</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
sph.2 </td><td style="text-align: left;"> Linear spherical spline (<code class="reqn">m = 2</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
sph.3 </td><td style="text-align: left;"> Cubic spherical spline (<code class="reqn">m = 3</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
sph.4 </td><td style="text-align: left;"> Quintic spherical spline (<code class="reqn">m = 4</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps.lin </td><td style="text-align: left;"> Linear thin plate spline (<code class="reqn">m = 1</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps.cub </td><td style="text-align: left;"> Cubic thin plate spline (<code class="reqn">m = 2</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
tps.qui </td><td style="text-align: left;"> Quintic thin plate spline (<code class="reqn">m = 3</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>For details on the spline kernel functions, see <code><a href="#topic+basis.nom">basis.nom</a></code> (nominal), <code><a href="#topic+basis.ord">basis.ord</a></code> (ordinal), <code><a href="#topic+basis.poly">basis.poly</a></code> (polynomial), <code><a href="#topic+basis.sph">basis.sph</a></code> (spherical), and <code><a href="#topic+basis.tps">basis.tps</a></code> (thin plate).
</p>


<h3>Choosing Knots </h3>

<p>If <code>tprk = TRUE</code>, the four options for the <code>knots</code> input include: 
</p>

<table>
<tr>
 <td style="text-align: left;">
1. </td><td style="text-align: left;"> a scalar giving the total number of knots to sample </td>
</tr>
<tr>
 <td style="text-align: left;">
2. </td><td style="text-align: left;"> a vector of integers indexing which rows of data are the knots </td>
</tr>
<tr>
 <td style="text-align: left;">
3. </td><td style="text-align: left;"> a list with named elements giving the marginal knot values for each predictor (to be combined via <code><a href="base.html#topic+expand.grid">expand.grid</a></code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
4. </td><td style="text-align: left;"> a list with named elements giving the knot values for each predictor (requires the same number of knots for each predictor)
</td>
</tr>

</table>

<p>If <code>tprk = FALSE</code>, the three options for the <code>knots</code> input include:
</p>

<table>
<tr>
 <td style="text-align: left;">
1. </td><td style="text-align: left;"> a scalar giving the common number of knots for each continuous predictor </td>
</tr>
<tr>
 <td style="text-align: left;">
2. </td><td style="text-align: left;"> a list with named elements giving the number of marginal knots for each predictor </td>
</tr>
<tr>
 <td style="text-align: left;">
3. </td><td style="text-align: left;"> a list with named elements giving the marginal knot values for each predictor
</td>
</tr>

</table>



<h3>Multiple Smooths </h3>

<p>Suppose <code>formula = y ~ x1 + x2</code> so that the model contains additive effects of two predictor variables. 
</p>
<p>The <code class="reqn">k</code>-th predictor's marginal effect can be denoted as </p>
<p style="text-align: center;"><code class="reqn">f_k = X_k \beta_k + Z_k \alpha_k</code>
</p>
<p> where <code class="reqn">X_k</code> is the <code class="reqn">n</code> by <code class="reqn">m_k</code> null space basis function matrix, and <code class="reqn">Z_k</code> is the <code class="reqn">n</code> by <code class="reqn">r_k</code> contrast space basis function matrix. 
</p>
<p>If <code>tprk = TRUE</code>, the null space basis function matrix has the form <code class="reqn">X = [1, X_1, X_2]</code> and the contrast space basis function matrix has the form </p>
<p style="text-align: center;"><code class="reqn">Z = \theta_1 Z_1 + \theta_2 Z_2</code>
</p>
<p> where the <code class="reqn">\theta_k</code> are the &quot;extra&quot; smoothing parameters. Note that <code class="reqn">Z</code> is of dimension <code class="reqn">n</code> by <code class="reqn">r = r_1 = r_2</code>.
</p>
<p>If <code>tprk = FALSE</code>, the null space basis function matrix has the form <code class="reqn">X = [1, X_1, X_2]</code>, and the contrast space basis function matrix has the form </p>
<p style="text-align: center;"><code class="reqn">Z = [\theta_1 Z_1, \theta_2 Z_2]</code>
</p>
<p> where the <code class="reqn">\theta_k</code> are the &quot;extra&quot; smoothing parameters. Note that <code class="reqn">Z</code> is of dimension <code class="reqn">n</code> by <code class="reqn">r = r_1 + r_2</code>.
</p>


<h3>Parameter Tuning </h3>

<p>When multiple smooth terms are included in the model, there are smoothing (hyper)parameters that weight the contribution of each combination of smooth terms. These hyperparameters are distinct from the overall smoothing parameter <code>lambda</code> that weights the contribution of the penalty. 
</p>
<p><code>skip.iter = TRUE</code> (default) estimates the smoothing hyperparameters using Algorithm 3.2 of Gu and Wahba (1991), which typically provides adequate results when the model form is correctly specified. The <code>lambda</code> parameter is tuned via the specified smoothing parameter selection <code>method</code>.
</p>
<p><code>skip.iter = FALSE</code> uses Algorithm 3.2 as an initialization, and then the <code><a href="stats.html#topic+nlm">nlm</a></code> function is used to tune the hyperparameters via the specified smoothing parameter selection <code>method</code>. Setting <code>skip.iter = FALSE</code> can (substantially) increase the model fitting time, but should produce better results&mdash;particularly if the model <code>formula</code> is misspecified.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Berry, L. N., &amp; Helwig, N. E. (2021). Cross-validation, information theory, or maximum likelihood? A comparison of tuning methods for penalized splines. <em>Stats, 4</em>(3), 701-724. <a href="https://doi.org/10.3390/stats4030042">doi:10.3390/stats4030042</a>
</p>
<p>Craven, P. and Wahba, G. (1979). Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. <em>Numerische Mathematik, 31</em>, 377-403. <a href="https://doi.org/10.1007/BF01404567">doi:10.1007/BF01404567</a>
</p>
<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Gu, C. and Wahba, G. (1991). Minimizing GCV/GML scores with multiple smoothing parameters via the Newton method. <em>SIAM Journal on Scientific and Statistical Computing, 12(2)</em>, 383-398. <a href="https://doi.org/10.1137/0912021">doi:10.1137/0912021</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Helwig, N. E. (2021). Spectrally sparse nonparametric regression via elastic net regularized smoothers. <em>Journal of Computational and Graphical Statistics, 30</em>(1), 182-191. <a href="https://doi.org/10.1080/10618600.2020.1806855">doi:10.1080/10618600.2020.1806855</a>
</p>



<h3>See Also</h3>

<p><b>Related Modeling Functions</b>: 
</p>
<p><code><a href="#topic+ss">ss</a></code> for fitting a smoothing spline with a single predictor (Gaussian response).
</p>
<p><code><a href="#topic+gsm">gsm</a></code> for fitting generalized smooth models with multiple predictors of mixed types (non-Gaussian response). <br />
</p>
<p><b>S3 Methods and Related Functions for &quot;sm&quot; Objects</b>:
</p>
<p><code><a href="#topic+boot.sm">boot.sm</a></code> for bootstrapping <code>sm</code> objects.
</p>
<p><code><a href="#topic+coef.sm">coef.sm</a></code> for extracting coefficients from <code>sm</code> objects.
</p>
<p><code><a href="#topic+cooks.distance.sm">cooks.distance.sm</a></code> for calculating Cook's distances from <code>sm</code> objects.
</p>
<p><code><a href="#topic+cov.ratio">cov.ratio</a></code> for computing covariance ratio from <code>sm</code> objects.
</p>
<p><code><a href="#topic+deviance.sm">deviance.sm</a></code> for extracting deviance from <code>sm</code> objects.
</p>
<p><code><a href="#topic+dfbeta.sm">dfbeta.sm</a></code> for calculating DFBETA from <code>sm</code> objects.
</p>
<p><code><a href="#topic+dfbetas.sm">dfbetas.sm</a></code> for calculating DFBETAS from <code>sm</code> objects.
</p>
<p><code><a href="#topic+diagnostic.plots">diagnostic.plots</a></code> for plotting regression diagnostics from <code>sm</code> objects.
</p>
<p><code><a href="#topic+fitted.sm">fitted.sm</a></code> for extracting fitted values from <code>sm</code> objects.
</p>
<p><code><a href="#topic+hatvalues.sm">hatvalues.sm</a></code> for extracting leverages from <code>sm</code> objects.
</p>
<p><code><a href="#topic+model.matrix.sm">model.matrix.sm</a></code> for constructing model matrix from <code>sm</code> objects.
</p>
<p><code><a href="#topic+predict.sm">predict.sm</a></code> for predicting from <code>sm</code> objects.
</p>
<p><code><a href="#topic+residuals.sm">residuals.sm</a></code> for extracting residuals from <code>sm</code> objects.
</p>
<p><code><a href="#topic+rstandard.sm">rstandard.sm</a></code> for computing standardized residuals from <code>sm</code> objects.
</p>
<p><code><a href="#topic+rstudent.sm">rstudent.sm</a></code> for computing studentized residuals from <code>sm</code> objects.
</p>
<p><code><a href="#topic+smooth.influence">smooth.influence</a></code> for calculating basic influence information from <code>sm</code> objects.
</p>
<p><code><a href="#topic+smooth.influence.measures">smooth.influence.measures</a></code> for convenient display of influential observations from <code>sm</code> objects.
</p>
<p><code><a href="#topic+summary.sm">summary.sm</a></code> for summarizing <code>sm</code> objects.
</p>
<p><code><a href="#topic+vcov.sm">vcov.sm</a></code> for extracting coefficient covariance matrix from <code>sm</code> objects.
</p>
<p><code><a href="#topic+weights.sm">weights.sm</a></code> for extracting prior weights from <code>sm</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########
### 1 continuous predictor

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit sm with 10 knots (tprk = TRUE)
sm.ssa &lt;- sm(y ~ x, knots = 10)

# fit sm with 10 knots (tprk = FALSE)
sm.gam &lt;- sm(y ~ x, knots = 10, tprk = FALSE)

# print both results (note: they are identical)
sm.ssa
sm.gam

# summarize both results (note: they are identical)
summary(sm.ssa)
summary(sm.gam)

# compare true MSE values (note: they are identical) 
mean( ( fx - sm.ssa$fit )^2 )
mean( ( fx - sm.gam$fit )^2 )



##########   EXAMPLE 2   ##########
### 1 continuous and 1 nominal predictor
### additive model

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x)
}
fx &lt;- fun(x, z)
y &lt;- fx + rnorm(n, sd = 0.5)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots (tprk = TRUE)
sm.ssa &lt;- sm(y ~ x + z, knots = knots)

# fit sm with specified knots (tprk = FALSE)
sm.gam &lt;- sm(y ~ x + z, knots = knots, tprk = FALSE)

# print both results (note: they are identical)
sm.ssa
sm.gam

# summarize both results (note: they are almost identical)
summary(sm.ssa)
summary(sm.gam)

# compare true MSE values (note: they are identical) 
mean( ( fx - sm.ssa$fit )^2 )
mean( ( fx - sm.gam$fit )^2 )



##########   EXAMPLE 3   ##########
### 1 continuous and 1 nominal predictor
### interaction model

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- fx + rnorm(n, sd = 0.5)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots (tprk = TRUE)
sm.ssa &lt;- sm(y ~ x * z, knots = knots)

# fit sm with specified knots (tprk = FALSE)
sm.gam &lt;- sm(y ~ x * z, knots = knots, tprk = FALSE)

# print both results (note: they are slightly different)
sm.ssa
sm.gam

# summarize both results (note: they are slightly different)
summary(sm.ssa)
summary(sm.gam)

# compare true MSE values (note: they are slightly different) 
mean( ( fx - sm.ssa$fit )^2 )
mean( ( fx - sm.gam$fit )^2 )



##########   EXAMPLE 4   ##########
### 4 continuous predictors
### additive model

# generate data
set.seed(1)
n &lt;- 100
fun &lt;- function(x){
  sin(pi*x[,1]) + sin(2*pi*x[,2]) + sin(3*pi*x[,3]) + sin(4*pi*x[,4])
}
data &lt;- as.data.frame(replicate(4, runif(n)))
colnames(data) &lt;- c("x1v", "x2v", "x3v", "x4v")
fx &lt;- fun(data)
y &lt;- fx + rnorm(n)

# define marginal knots
knots &lt;- list(x1v = quantile(data$x1v, probs = seq(0, 1, length.out = 10)),
              x2v = quantile(data$x2v, probs = seq(0, 1, length.out = 10)),
              x3v = quantile(data$x3v, probs = seq(0, 1, length.out = 10)),
              x4v = quantile(data$x4v, probs = seq(0, 1, length.out = 10)))
              
# define ssa knot indices
knots.indx &lt;- c(bin.sample(data$x1v, nbin = 10, index.return = TRUE)$ix,
                bin.sample(data$x2v, nbin = 10, index.return = TRUE)$ix,
                bin.sample(data$x3v, nbin = 10, index.return = TRUE)$ix,
                bin.sample(data$x4v, nbin = 10, index.return = TRUE)$ix)

# fit sm with specified knots (tprk = TRUE)
sm.ssa &lt;- sm(y ~ x1v + x2v + x3v + x4v, data = data, knots = knots.indx)

# fit sm with specified knots (tprk = FALSE)
sm.gam &lt;- sm(y ~ x1v + x2v + x3v + x4v, data = data, knots = knots, tprk = FALSE)

# print both results (note: they are slightly different)
sm.ssa
sm.gam

# summarize both results (note: they are slightly different)
summary(sm.ssa)
summary(sm.gam)

# compare true MSE values (note: they are slightly different) 
mean( ( fx - sm.ssa$fit )^2 )
mean( ( fx - sm.gam$fit )^2 )

</code></pre>

<hr>
<h2 id='smooth.influence'>
Nonparametric Regression Diagnostics
</h2><span id='topic+smooth.influence'></span><span id='topic+influence.ss'></span><span id='topic+influence.sm'></span><span id='topic+influence.gsm'></span>

<h3>Description</h3>

<p>These functions provide the basic quantities that are used to form a variety of diagnostics for checking the quality of a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
influence(model, do.coef = TRUE, ...)
## S3 method for class 'sm'
influence(model, do.coef = TRUE, ...)
## S3 method for class 'gsm'
influence(model, do.coef = TRUE, ...)

smooth.influence(model, do.coef = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.influence_+3A_model">model</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="smooth.influence_+3A_do.coef">do.coef</code></td>
<td>

<p>logical indicating if the changed <code>coefficients</code> are desired (see Details).   
</p>
</td></tr>
<tr><td><code id="smooth.influence_+3A_...">...</code></td>
<td>

<p>additional arguments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by <code><a href="stats.html#topic+influence">influence</a></code> and <code><a href="stats.html#topic+lm.influence">lm.influence</a></code> functions in R's <b>stats</b> package.
</p>
<p>The functions documented in <code><a href="#topic+smooth.influence.measures">smooth.influence.measures</a></code> provide a more user-friendly way of computing a variety of regression diagnostics.
</p>
<p>For non-Gaussian <code>gsm</code> objects, these regression diagnostics are based on one-step approximations, which may be inadequate if a case has high influence. 
</p>
<p>For all models, the diagostics are computed assuming that the smoothing parameters are fixed at the given values. 
</p>


<h3>Value</h3>

<p>A list with the components
</p>
<table>
<tr><td><code>hat</code></td>
<td>
<p>a vector containing the leverages, i.e., the diagonals of the smoothing matrix</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>if <code>do.coef</code> is true, a matrix whose i-th row contains the change in the estimated coefficients which results when the i-th case is excluded from the fitting. </p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p> a vector whose i-th entry contains the deviance which results when the i-th case is excluded from the fitting.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p> a vector whose i-th entry contains the effective degrees-of-freedom which results when the i-th case is excluded from the fitting.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>a vector whose i-th element contains the estimate of the residual standard deviation obtained when the i-th case is excluded from the fitting. </p>
</td></tr>
<tr><td><code>wt.res</code></td>
<td>
<p>a vector of <em>weighted</em> (or for class <code>gsm</code> rather <em>deviance</em>) residuals.</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>The approximations used for <code>gsm</code> objects can result in <code>sigma</code> estimates being <code>NaN</code>.
</p>


<h3>Note</h3>

<p>The <code>coefficients</code> returned by <code><a href="#topic+smooth.influence">smooth.influence</a></code> (and the corresponding functions S3 <code>influence</code> methods) are the <em>change</em> in the coefficients which result from dropping each case, i.e., <code class="reqn">\theta - \theta_i</code>, where <code class="reqn">\theta</code> are the original coefficients obtained from the full sample of <code class="reqn">n</code> observations and <code class="reqn">\theta_i</code> are the coefficients that result from dropping the i-th case.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>See the list in the documentation for <code><a href="stats.html#topic+influence.measures">influence.measures</a></code>
</p>
<p>Chambers, J. M. (1992) <em>Linear models.</em> Chapter 4 of <em>Statistical Models in S</em> eds J. M. Chambers and T. J. Hastie, Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code> for modeling functions
</p>
<p><code><a href="#topic+smooth.influence.measures">smooth.influence.measures</a></code> for convenient summary
</p>
<p><code><a href="#topic+diagnostic.plots">diagnostic.plots</a></code> for regression diagnostic plots
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit models
mod.ss &lt;- ss(x, y, nknots = 10)
mod.sm &lt;- sm(y ~ x, knots = 10)
mod.gsm &lt;- gsm(y ~ x, knots = 10)

# calculate influence
infl.ss &lt;- influence(mod.ss)
infl.sm &lt;- influence(mod.sm)
infl.gsm &lt;- influence(mod.gsm)

# compare hat
mean((infl.ss$hat - infl.sm$hat)^2)
mean((infl.ss$hat - infl.gsm$hat)^2)
mean((infl.sm$hat - infl.gsm$hat)^2)

# compare deviance
mean((infl.ss$deviance - infl.sm$deviance)^2)
mean((infl.ss$deviance - infl.gsm$deviance)^2)
mean((infl.sm$deviance - infl.gsm$deviance)^2)

# compare df
mean((infl.ss$df - infl.sm$df)^2)
mean((infl.ss$df - infl.gsm$df)^2)
mean((infl.sm$df - infl.gsm$df)^2)

# compare sigma
mean((infl.ss$sigma - infl.sm$sigma)^2)
mean((infl.ss$sigma - infl.gsm$sigma)^2)
mean((infl.sm$sigma - infl.gsm$sigma)^2)

# compare residuals
mean((infl.ss$wt.res - infl.sm$wt.res)^2)
mean((infl.ss$wt.res - infl.gsm$dev.res)^2)
mean((infl.sm$wt.res - infl.gsm$dev.res)^2)

# NOTE: ss() coef only comparable to sm() and gsm() after rescaling
scale.sm &lt;- rep(c(1, mod.sm$specs$thetas), times = c(2, 10))
scale.gsm &lt;- rep(c(1, mod.gsm$specs$thetas), times = c(2, 10))
mean((coef(mod.ss) / scale.sm - coef(mod.sm))^2)
mean((coef(mod.ss) / scale.gsm - coef(mod.gsm))^2)
mean((coef(mod.sm) - coef(mod.gsm))^2)

# infl.ss$coefficients are *not* comparable to others
mean((infl.ss$coefficients - infl.sm$coefficients)^2)
mean((infl.ss$coefficients - infl.gsm$coefficients)^2)
mean((infl.sm$coefficients - infl.gsm$coefficients)^2)

</code></pre>

<hr>
<h2 id='smooth.influence.measures'>
Nonparametric Regression Deletion Diagnostics
</h2><span id='topic+smooth.influence.measures'></span><span id='topic+rstandard.ss'></span><span id='topic+rstandard.sm'></span><span id='topic+rstandard.gsm'></span><span id='topic+rstudent.ss'></span><span id='topic+rstudent.sm'></span><span id='topic+rstudent.gsm'></span><span id='topic+dfbeta.ss'></span><span id='topic+dfbeta.sm'></span><span id='topic+dfbeta.gsm'></span><span id='topic+dfbetas.ss'></span><span id='topic+dfbetas.sm'></span><span id='topic+dfbetas.gsm'></span><span id='topic+cov.ratio'></span><span id='topic+cooks.distance.ss'></span><span id='topic+cooks.distance.sm'></span><span id='topic+cooks.distance.gsm'></span><span id='topic+hatvalues.ss'></span><span id='topic+hatvalues.sm'></span><span id='topic+hatvalues.gsm'></span>

<h3>Description</h3>

<p>These functions compute several regression (leave-one-out deletion) diagnostics for a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth.influence.measures(model, infl = smooth.influence(model))

## S3 method for class 'ss'
rstandard(model, infl = NULL, sd = model$sigma, 
          type = c("sd.1", "predictive"), ...)
## S3 method for class 'sm'
rstandard(model, infl = NULL, sd = model$sigma, 
          type = c("sd.1", "predictive"), ...)
## S3 method for class 'gsm'
rstandard(model, infl = NULL, 
          type = c("deviance", "pearson"), ...)

## S3 method for class 'ss'
rstudent(model, infl = influence(model, do.coef = FALSE), 
         res = infl$wt.res, ...)
## S3 method for class 'sm'
rstudent(model, infl = influence(model, do.coef = FALSE), 
         res = infl$wt.res, ...)
## S3 method for class 'gsm'
rstudent(model, infl = influence(model, do.coef = FALSE), ...)

## S3 method for class 'ss'
dfbeta(model, infl = NULL, ...)
## S3 method for class 'sm'
dfbeta(model, infl = NULL, ...)
## S3 method for class 'gsm'
dfbeta(model, infl = NULL, ...)

## S3 method for class 'ss'
dfbetas(model, infl = smooth.influence(model, do.coef = TRUE), ...)
## S3 method for class 'sm'
dfbetas(model, infl = smooth.influence(model, do.coef = TRUE), ...)
## S3 method for class 'gsm'
dfbetas(model, infl = smooth.influence(model, do.coef = TRUE), ...)

cov.ratio(model, infl = smooth.influence(model, do.coef = FALSE),
          res = weighted.residuals(model))

## S3 method for class 'ss'
cooks.distance(model, infl = NULL, res = weighted.residuals(model), 
               sd = model$sigma, hat = hatvalues(model), ...)
## S3 method for class 'sm'
cooks.distance(model, infl = NULL, res = weighted.residuals(model), 
               sd = model$sigma, hat = hatvalues(model), ...)
## S3 method for class 'gsm'
cooks.distance(model, infl = NULL, res = residuals(model, type = "pearson"), 
               dispersion = model$dispersion, hat = hatvalues(model), ...)

## S3 method for class 'ss'
hatvalues(model, ...)
## S3 method for class 'sm'
hatvalues(model, ...)
## S3 method for class 'gsm'
hatvalues(model, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.influence.measures_+3A_model">model</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_infl">infl</code></td>
<td>

<p>influence structure as returned by <code><a href="#topic+smooth.influence">smooth.influence</a></code>  
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_res">res</code></td>
<td>

<p>(possibly weighted) residuals with proper defaults    
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_sd">sd</code></td>
<td>

<p>standard deviation to use, see defaults
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_dispersion">dispersion</code></td>
<td>

<p>dispersion (for <code><a href="#topic+gsm">gsm</a></code> objects) to use, see defaults  
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_hat">hat</code></td>
<td>

<p>hat values <code class="reqn">S_{ii}</code>, see defaults  
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_type">type</code></td>
<td>

<p>type of residuals for <code>rstandard</code>  
</p>
</td></tr>
<tr><td><code id="smooth.influence.measures_+3A_...">...</code></td>
<td>

<p>additional arguments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by <code><a href="stats.html#topic+influence.measures">influence.measures</a></code> and related functions in R's <b>stats</b> package.
</p>
<p>The function <code>smooth.influence.measures</code> produces a class &quot;infl&quot; object, which displays the DFBETAS for each coefficient, DFFITS, covariance ratios, Cook's distance, and the diagonals of the smoothing matrix. Cases which are influential with respect to any of these measures are marked with an asterisk.
</p>
<p>The S3 methods <code>dfbetas</code>, <code>dffits</code>, <code>covratio</code>, and <code>cooks.distance</code> provide direct access to the corresponding diagnostic quantities. The S3 methods <code>rstandard</code> and <code>rstudent</code> give the standardized and Studentized residuals, respectively. (These re-normalize the residuals to have unit variance, using an overall and leave-one-out measure of the error variance, respectively.)
</p>
<p>Values for generalized smoothing models are approximations, as described in Williams (1987) (except that Cook's distances are scaled as <code class="reqn">F</code> rather than chi-square values). THe approximations can be poor when some cases have large influence.
</p>
<p>The optional <code>infl</code>, <code>res</code>, and <code>sd</code> arguments are there to encourage the use of these direct access functions in situations where the underlying basic influence measures, e.g., from <code><a href="#topic+smooth.influence">smooth.influence</a></code>, are already available.
</p>
<p>For <code>ss</code> and <code>sm</code> objects, the code <code>rstandard(*, type = "predictive")</code> returns the leave-one-out (ordinary) cross-validation residuals, and the PRESS (PREdictive Sum of Squares) statistic is defined as
</p>
<p><code>PRESS &lt;- sum(rstandard(model, type = "predictive")^2)</code>
</p>
<p>Note that <code>OCV = PRESS / n</code>, where OCV = ordinary cross-validation criterion
</p>


<h3>Note</h3>

<p>Note: the <code><a href="stats.html#topic+dffits">dffits</a></code> function in R's <b>stats</b> package can be used with the following syntax
</p>
<p><code>dffits(model, infl = smooth.influence(model, do.coef = FALSE),
       res = weighted.residuals(model))</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>See references listed in <code><a href="stats.html#topic+influence.measures">influence.measures</a></code>
</p>
<p>Williams, D. A. (1987). Generalized linear model diagnostics using the deviance and single case deletions. <em>Applied Statistics, 36</em>, 181-191. <a href="https://doi.org/10.2307/2347550">doi:10.2307/2347550</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code> for modeling functions
</p>
<p><code><a href="#topic+smooth.influence">smooth.influence</a></code> for some basic influence information
</p>
<p><code><a href="#topic+diagnostic.plots">diagnostic.plots</a></code> for regression diagnostic plots
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# fit models
mod.ss &lt;- ss(x, y, nknots = 10)
mod.sm &lt;- sm(y ~ x, knots = 10)
mod.gsm &lt;- gsm(y ~ x, knots = 10)

# calculate influence
infl.ss &lt;- smooth.influence.measures(mod.ss)
infl.sm &lt;- smooth.influence.measures(mod.sm)
infl.gsm &lt;- smooth.influence.measures(mod.gsm)

# standardized residuals
rstan.ss &lt;- rstandard(mod.ss)
rstan.sm &lt;- rstandard(mod.sm)
rstan.gsm &lt;- rstandard(mod.gsm)

# studentized residuals
rstud.ss &lt;- rstudent(mod.ss)
rstud.sm &lt;- rstudent(mod.sm)
rstud.gsm &lt;- rstudent(mod.gsm)

</code></pre>

<hr>
<h2 id='spherical'>
Spherical Spline Basis and Penalty
</h2><span id='topic+spherical'></span><span id='topic+basis.sph'></span><span id='topic+basis_sph'></span><span id='topic+penalty.sph'></span><span id='topic+penalty_sph'></span>

<h3>Description</h3>

<p>Generate the smoothing spline basis and penalty matrix for a spherical spline. This basis is designed for predictors where the values are points on a sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis.sph(x, knots, m = 2, intercept = FALSE, ridge = FALSE)

penalty.sph(x, m = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spherical_+3A_x">x</code></td>
<td>

<p>Predictor variables (basis) or spline knots (penalty). Matrix of dimension <code class="reqn">n</code> by <code class="reqn">2</code>. Column 1 is latitude (-90 to 90 deg) and column 2 is longitude (-180 to 180 deg).
</p>
</td></tr>
<tr><td><code id="spherical_+3A_knots">knots</code></td>
<td>

<p>Spline knots. Matrix of dimension <code class="reqn">r</code> by <code class="reqn">2</code>. Column 1 is latitude (-90 to 90 deg) and column 2 is longitude (-180 to 180 deg).
</p>
</td></tr>
<tr><td><code id="spherical_+3A_m">m</code></td>
<td>

<p>Penalty order. &quot;m=2&quot; for 2nd order spherical spline, &quot;m=3&quot; for 3rd order, and &quot;m=4&quot; for 4th order.
</p>
</td></tr>
<tr><td><code id="spherical_+3A_intercept">intercept</code></td>
<td>

<p>If <code>TRUE</code>, the first column of the basis will be a column of ones. 
</p>
</td></tr>
<tr><td><code id="spherical_+3A_ridge">ridge</code></td>
<td>

<p>If <code>TRUE</code>, the basis matrix is post-multiplied by the inverse square root of the penalty matrix. See Note and Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates a basis function or penalty matrix used to fit spherical splines of order 2, 3, or 4.
</p>
<p>With an intercept included, the basis function matrix has the form 
</p>
<p style="text-align: center;"><code class="reqn">X = [X_0,  X_1]</code>
</p>

<p>where matrix <code>X_0</code> is an <code class="reqn">n</code> by 1 matrix of ones, and <code>X_1</code> is a matrix of dimension <code class="reqn">n</code> by <code class="reqn">r</code>. 
</p>
<p>The <code>X_0</code> matrix contains the &quot;parametric part&quot; of the basis (i.e., the intercept). 
</p>
<p>The matrix <code>X_1</code> contains the &quot;nonparametric part&quot; of the basis, which consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = [q_{2m-2}(x.y) - \alpha] / \beta  </code>
</p>

<p>evaluated at all combinations of <code>x</code> and <code>knots</code>. Note that <code class="reqn">\alpha = 1/(2m - 1)</code> and <code class="reqn">\beta = 2\pi(2m-2)!</code> are constants, <code class="reqn">q_{2m-2}(.)</code> is the spherical spline semi-kernel function, and <code class="reqn">x.y</code> denotes the cosine of the angle between <code class="reqn">x</code> and <code class="reqn">y</code> (see References).
</p>
<p>The penalty matrix consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = [q_{2m-2}(x.y) - \alpha] / \beta  </code>
</p>

<p>evaluated at all combinations of <code>x</code>.
</p>


<h3>Value</h3>

<p>Basis: Matrix of dimension <code>c(length(x), df)</code> where <code>df = nrow(knots) + intercept</code>.
</p>
<p>Penalty: Matrix of dimension <code>c(r, r)</code> where <code>r = nrow(x)</code> is the number of knots.
</p>


<h3>Note</h3>

<p>The inputs <code>x</code> and <code>knots</code> must have the same dimension.
</p>
<p>If <code>ridge = TRUE</code>, the penalty matrix is the identity matrix.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing Spline ANOVA Models. 2nd Ed. New York, NY: Springer-Verlag. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Wahba, G (1981). Spline interpolation and smoothing on the sphere. <em>SIAM Journal on Scientific Computing, 2</em>(1), 5-16. <a href="https://doi.org/10.1137/0902002">doi:10.1137/0902002</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+thinplate">thinplate</a></code> for a thin plate spline basis and penalty.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   standard parameterization   ######***######

# function with spherical predictors
set.seed(0)
n &lt;- 1000
myfun &lt;- function(x){
  sin(pi*x[,1]) + cos(2*pi*x[,2]) + cos(pi*x[,3])
  }
x3d &lt;- cbind(runif(n), runif(n), runif(n)) - 0.5
x3d &lt;- t(apply(x3d, 1, function(x) x / sqrt(sum(x^2))))
eta &lt;- myfun(x3d)
y &lt;- eta + rnorm(n, sd = 0.5)

# convert x latitude and longitude
x &lt;- cbind(latitude = acos(x3d[,3]) - pi/2,
           longitude = atan2(x3d[,2], x3d[,1])) * (180 / pi)

# select first 100 points as knots
knots &lt;- x[1:100,]

# cubic spherical spline basis
X &lt;- basis.sph(x, knots, intercept = TRUE)

# cubic spherical spline penalty
Q &lt;- penalty.sph(knots)

# pad Q with zeros (for intercept)
Q &lt;- rbind(0, cbind(0, Q))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- psolve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta - yhat)^2))



######***######   ridge parameterization   ######***######

# function with spherical predictors
set.seed(0)
n &lt;- 1000
myfun &lt;- function(x){
  sin(pi*x[,1]) + cos(2*pi*x[,2]) + cos(pi*x[,3])
  }
x3d &lt;- cbind(runif(n), runif(n), runif(n)) - 0.5
x3d &lt;- t(apply(x3d, 1, function(x) x / sqrt(sum(x^2))))
eta &lt;- myfun(x3d)
y &lt;- eta + rnorm(n, sd = 0.5)

# convert x latitude and longitude
x &lt;- cbind(latitude = acos(x3d[,3]) - pi/2,
           longitude = atan2(x3d[,2], x3d[,1])) * (180 / pi)

# select first 100 points as knots
knots &lt;- x[1:100,]

# cubic spherical spline basis
X &lt;- basis.sph(x, knots, intercept = TRUE, ridge = TRUE)

# cubic spherical spline penalty (ridge)
Q &lt;- diag(rep(c(0, 1), times = c(1, ncol(X) - 1)))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- psolve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta - yhat)^2))

</code></pre>

<hr>
<h2 id='ss'>
Fit a Smoothing Spline
</h2><span id='topic+ss'></span>

<h3>Description</h3>

<p>Fits a smoothing spline with the smoothing parameter selected via one of eight methods: GCV, OCV, GACV, ACV, REML, ML, AIC, or BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss(x, y = NULL, w = NULL, df, spar = NULL, lambda = NULL,
   method = c("GCV", "OCV", "GACV", "ACV", "REML", "ML", "AIC", "BIC"), 
   m = 2L, periodic = FALSE, all.knots = FALSE, nknots = .nknots.smspl, 
   knots = NULL, keep.data = TRUE, df.offset = 0, penalty = 1, 
   control.spar = list(), tol = 1e-6 * IQR(x), bernoulli = TRUE,
   xmin = NULL, xmax = NULL, homosced = TRUE, iter.max = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss_+3A_x">x</code></td>
<td>

<p>Predictor vector of length <code class="reqn">n</code>. Can also input a list or a two-column matrix specifying x and y.
</p>
</td></tr>
<tr><td><code id="ss_+3A_y">y</code></td>
<td>

<p>Response vector of length <code class="reqn">n</code>. If y is missing or NULL, the responses are assumed to be specified by x, with x the index vector.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_w">w</code></td>
<td>

<p>Weights vector of length <code class="reqn">n</code>. Defaults to all 1.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_df">df</code></td>
<td>

<p>Equivalent degrees of freedom (trace of the smoother matrix). Must be in <code class="reqn">[m,nx]</code>, where <code class="reqn">nx</code> is the number of unique x values, see below.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_spar">spar</code></td>
<td>

<p>Smoothing parameter. Typically (but not always) in the range <code class="reqn">(0,1]</code>. If specified <code>lambda = 256^(3*(spar-1))</code>.
</p>
</td></tr>
<tr><td><code id="ss_+3A_lambda">lambda</code></td>
<td>

<p>Computational smoothing parameter. This value is weighted by <code class="reqn">n</code> to form the penalty coefficient (see Details). Ignored if <code>spar</code> is provided.
</p>
</td></tr>
<tr><td><code id="ss_+3A_method">method</code></td>
<td>

<p>Method for selecting the smoothing parameter. Ignored if <code>spar</code> or <code>lambda</code> is provided.
</p>
</td></tr>
<tr><td><code id="ss_+3A_m">m</code></td>
<td>

<p>Penalty order (integer). The penalty functional is the integrated squared <code class="reqn">m</code>-th derivative of the function. Defaults to <code class="reqn">m = 2</code>, which is a cubic smoothing spline. Set <code class="reqn">m = 1</code> for a linear smoothing spline or <code class="reqn">m = 3</code> for a quintic smoothing spline.
</p>
</td></tr>
<tr><td><code id="ss_+3A_periodic">periodic</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the estimated function <code class="reqn">f(x)</code> is constrained to be periodic, i.e., <code class="reqn">f(a) = f(b)</code> where <code class="reqn">a = \min(x)</code> and <code class="reqn">b = \max(x)</code>.
</p>
</td></tr>
<tr><td><code id="ss_+3A_all.knots">all.knots</code></td>
<td>

<p>If <code>TRUE</code>, all distinct points in x are used as knots. If <code>FALSE</code> (default), a sequence knots is placed at the quantiles of the unique x values; in this case, the input <code>nknots</code> specifies the number of knots in the sequence. Ignored if the knot values are input using the <code>knots</code> argument.
</p>
</td></tr>
<tr><td><code id="ss_+3A_nknots">nknots</code></td>
<td>

<p>Positive integer or function specifying the number of knots. Ignored if either <code>all.knots = TRUE</code> or the knot values are input using the <code>knots</code> argument.
</p>
</td></tr>
<tr><td><code id="ss_+3A_knots">knots</code></td>
<td>

<p>Vector of knot values for the spline. Should be unique and within the range of the x values (to avoid a warning). 
</p>
</td></tr>
<tr><td><code id="ss_+3A_keep.data">keep.data</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the original data as a part of the output object.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_df.offset">df.offset</code></td>
<td>

<p>Allows the degrees of freedom to be increased by <code>df.offset</code> in the GCV criterion.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_penalty">penalty</code></td>
<td>

<p>The coefficient of the penalty for degrees of freedom in the GCV criterion.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_control.spar">control.spar</code></td>
<td>

<p>Optional list with named components controlling the root finding when the smoothing parameter spar is computed, i.e., missing or NULL, see below.
</p>
<p><b>Note</b> that spar is only searched for in the interval <code class="reqn">[lower, upper]</code>.
</p>

<dl>
<dt>lower:</dt><dd>
<p>lower bound for spar; defaults to -1.5
</p>
</dd>
<dt>upper:</dt><dd>
<p>upper bound for spar; defaults to 1.5
</p>
</dd>
<dt>tol:</dt><dd>
<p>the absolute precision (<b>tol</b>erance) used by <code><a href="stats.html#topic+optimize">optimize</a></code>; defaults to 1e-8.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="ss_+3A_tol">tol</code></td>
<td>

<p>Tolerance for same-ness or uniqueness of the x values. The values are binned into bins of size tol and values which fall into the same bin are regarded as the same. Must be strictly positive (and finite).
</p>
</td></tr>
<tr><td><code id="ss_+3A_bernoulli">bernoulli</code></td>
<td>

<p>If <code>TRUE</code>, scaled Bernoulli polynomials are used for the basis and penalty functions. If <code>FALSE</code>, produces the &quot;classic&quot; definition of a smoothing spline, where the function estimate is a piecewise polynomial function with pieces of degree <code class="reqn">2m - 1</code>. See <code><a href="#topic+polynomial">polynomial</a></code> for details.  
</p>
</td></tr>
<tr><td><code id="ss_+3A_xmin">xmin</code></td>
<td>

<p>Minimum x value used to transform predictor scores to [0,1]. If NULL,  <code>xmin = min(x)</code>.
</p>
</td></tr>
<tr><td><code id="ss_+3A_xmax">xmax</code></td>
<td>

<p>Maximum x value used to transform predictor scores to [0,1]. If NULL,  <code>xmax = max(x)</code>.
</p>
</td></tr>
<tr><td><code id="ss_+3A_homosced">homosced</code></td>
<td>

<p>Are error variances homoscedastic? If <code>FALSE</code>, variance weights are (iteratively?) estimated from the data.
</p>
</td></tr>
<tr><td><code id="ss_+3A_iter.max">iter.max</code></td>
<td>

<p>Maximum number of iterations for variance weight estimation. Ignored if <code>homosced = TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inspired by the <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code> function in R's <b>stats</b> package.
</p>
<p>Neither <code>x</code> nor <code>y</code> are allowed to containing missing or infinite values.
</p>
<p>The <code>x</code> vector should contain at least <code class="reqn">2m</code> distinct values. 'Distinct' here is controlled by <code>tol</code>: values which are regarded as the same are replaced by the first of their values and the corresponding <code>y</code> and <code>w</code> are pooled accordingly.
</p>
<p>Unless <code>lambda</code> has been specified instead of <code>spar</code>, the computational <code class="reqn">\lambda</code> used (as a function of <code>spar</code>) is <code class="reqn">\lambda = 256^{3(s - 1)}</code>, where <code class="reqn">s = </code> <code>spar</code>.
</p>
<p>If <code>spar</code> and <code>lambda</code> are missing or <code>NULL</code>, the value of <code>df</code> is used to determine the degree of smoothing. If <code>df</code> is missing as well, the specified <code>method</code> is used to determine <code class="reqn">\lambda</code>. 
</p>
<p>Letting <code class="reqn">f_i = f(x_i)</code>, the function is represented as </p>
<p style="text-align: center;"><code class="reqn">f = X \beta + Z \alpha</code>
</p>
<p> where the basis functions in <code class="reqn">X</code> span the null space (i.e., functions with <code class="reqn">m</code>-th derivative of zero), and <code class="reqn">Z</code> contains the reproducing kernel function of the contrast space evaluated at all combinations of observed data points and knots, i.e., <code class="reqn">Z[i,j] = R(x_i, k_j)</code> where <code class="reqn">R</code> is the kernel function and <code class="reqn">k_j</code> is the <code class="reqn">j</code>-th knot. The vectors <code class="reqn">\beta</code> and <code class="reqn">\alpha</code> contain unknown basis function coefficients. 
Letting <code class="reqn">M =  (X, Z)</code> and <code class="reqn">\gamma = (\beta', \alpha')'</code>, the penalized least squares problem has the form
</p>
<p style="text-align: center;"><code class="reqn">
(y - M \gamma)' W (y - M \gamma) + n \lambda \alpha' Q \alpha
</code>
</p>

<p>where <code class="reqn">W</code> is a diagonal matrix containg the weights, and <code class="reqn">Q</code> is the penalty matrix. Note that <code class="reqn">Q[i,j] = R(k_i, k_j)</code> contains the reproducing kernel function evaluated at all combinations of knots. The optimal coefficients are the solution to 
</p>
<p style="text-align: center;"><code class="reqn">
(M' W M + n \lambda P) \gamma = M' W y
</code>
</p>

<p>where <code class="reqn">P</code> is the penalty matrix <code class="reqn">Q</code> augmented with zeros corresponding to the <code class="reqn">\beta</code> in <code class="reqn">\gamma</code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;ss&quot; with components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>the distinct <code>x</code> values in increasing order; see Note.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the fitted values corresponding to <code>x</code>.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>the weights used at the unique values of <code>x</code>.</p>
</td></tr>
<tr><td><code>yin</code></td>
<td>
<p>the <code>y</code> values used at the unique <code>y</code> values.</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>the <code>tol</code> argument (whose default depends on <code>x</code>).</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>only if keep.data = TRUE: itself a list with components <code>x</code>, <code>y</code> and <code>w</code> (if applicable). These are the original <code class="reqn">(x_i,y_i,w_i), i = 1, \ldots, n</code>, values where <code>data$x</code> may have repeated values and hence be longer than the above <code>x</code> component; see details.</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>
<p>leverages, the diagonal values of the smoother matrix.</p>
</td></tr>
<tr><td><code>cv.crit</code></td>
<td>
<p>cross-validation score.</p>
</td></tr>
<tr><td><code>pen.crit</code></td>
<td>
<p>the penalized criterion, a non-negative number; simply the (weighted) residual sum of squares (RSS).</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>
<p>the criterion value minimized in the underlying <code>df2lambda</code> function. When <code>df</code> is provided, the criterion is <code class="reqn">[tr(S_{\lambda}) - df]^2</code>.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>equivalent degrees of freedom used.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom = <code>nobs - df</code></p>
</td></tr>
<tr><td><code>spar</code></td>
<td>
<p>the value of <code>spar</code> computed or given, i.e., <code class="reqn">s = 1 + \log_{256}(\lambda)/3</code></p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the value of <code class="reqn">\lambda</code> corresponding to <code>spar</code>, i.e., <code class="reqn">\lambda = 256^{3(s-1)}</code>.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>list for use by <code><a href="#topic+predict.ss">predict.ss</a></code>, with components
</p>

<dl>
<dt>n:</dt><dd><p>number of observations.</p>
</dd>
<dt>knot:</dt><dd><p>the knot sequence.</p>
</dd>
<dt>nk:</dt><dd><p>number of coefficients (# knots plus <code class="reqn">m</code>).</p>
</dd>
<dt>coef:</dt><dd><p>coefficients for the spline basis used.</p>
</dd>
<dt>min, range:</dt><dd><p>numbers giving the corresponding quantities of <code>x</code></p>
</dd>
<dt>m:</dt><dd><p>spline penalty order (same as input <code>m</code>)</p>
</dd>
<dt>periodic:</dt><dd><p>is spline periodic?</p>
</dd>
<dt>cov.sqrt</dt><dd><p>square root of covariance matrix of <code>coef</code> such that <code>tcrossprod(coef)</code> reconstructs the covariance matrix.</p>
</dd>
<dt>weighted</dt><dd><p>were weights <code>w</code> used in fitting?</p>
</dd>
<dt>df.offset</dt><dd><p>same as input</p>
</dd>
<dt>penalty</dt><dd><p>same as input</p>
</dd>
<dt>control.spar</dt><dd><p>control parameters for smoothing parameter selection</p>
</dd>
<dt>bernoulli</dt><dd><p>were Bernoulli polynomials used in fitting?</p>
</dd>
</dl>

</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated error standard deviation.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>log-likelihood (if <code>method</code> is REML or ML).</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Akaike's Information Criterion (if <code>method</code> is AIC).</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Bayesian Information Criterion (if <code>method</code> is BIC).</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>smoothness penalty <code class="reqn">\alpha' Q \alpha</code>, which is the integrated squared <code class="reqn">m</code>-th derivative of the estimated function <code class="reqn">f(x)</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>smoothing parameter selection method. Will be <code>NULL</code> if <code>df</code>, <code>spar</code>, or <code>lambda</code> is provided.</p>
</td></tr>
</table>


<h3>Methods </h3>

<p>The smoothing parameter can be selected using one of eight methods: <br />
Generalized Cross-Validation (GCV) <br />
Ordinary Cross-Validation (OCV) <br />
Generalized Approximate Cross-Validation (GACV) <br />
Approximate Cross-Validation (ACV) <br />
Restricted Maximum Likelihood (REML) <br />
Maximum Likelihood (ML) <br />
Akaike's Information Criterion (AIC) <br />
Bayesian Information Criterion (BIC)
</p>


<h3>Note</h3>

<p>The number of unique x values, nx, are determined by the tol argument, equivalently to
</p>
<p><code>nx &lt;- sum(!duplicated( round((x - mean(x)) / tol) ))</code>
</p>
<p>In this case where not all unique x values are used as knots, the result is not a smoothing spline in the strict sense, but very close unless a small smoothing parameter (or large <code>df</code>) is used.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>https://stat.ethz.ch/R-manual/R-devel/library/stats/html/smooth.spline.html
</p>
<p>Berry, L. N., &amp; Helwig, N. E. (2021). Cross-validation, information theory, or maximum likelihood? A comparison of tuning methods for penalized splines. <em>Stats, 4</em>(3), 701-724. <a href="https://doi.org/10.3390/stats4030042">doi:10.3390/stats4030042</a>
</p>
<p>Craven, P. and Wahba, G. (1979). Smoothing noisy data with spline functions: Estimating the correct degree of smoothing by the method of generalized cross-validation. <em>Numerische Mathematik, 31</em>, 377-403. <a href="https://doi.org/10.1007/BF01404567">doi:10.1007/BF01404567</a>
</p>
<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Helwig, N. E. (2021). Spectrally sparse nonparametric regression via elastic net regularized smoothers. <em>Journal of Computational and Graphical Statistics, 30</em>(1), 182-191. <a href="https://doi.org/10.1080/10618600.2020.1806855">doi:10.1080/10618600.2020.1806855</a>
</p>
<p>Wahba, G. (1985). A comparison of GCV and GML for choosing the smoothing parameters in the generalized spline smoothing problem. <em>The Annals of Statistics, 4</em>, 1378-1402. <a href="https://doi.org/10.1214/aos/1176349743">doi:10.1214/aos/1176349743</a>
</p>


<h3>See Also</h3>

<p><b>Related Modeling Functions</b>: 
</p>
<p><code><a href="#topic+sm">sm</a></code> for fitting smooth models with multiple predictors of mixed types (Gaussian response). 
</p>
<p><code><a href="#topic+gsm">gsm</a></code> for fitting generalized smooth models with multiple predictors of mixed types (non-Gaussian response). <br />
</p>
<p><b>S3 Methods and Related Functions for &quot;ss&quot; Objects</b>:
</p>
<p><code><a href="#topic+boot.ss">boot.ss</a></code> for bootstrapping <code>ss</code> objects.
</p>
<p><code><a href="#topic+coef.ss">coef.ss</a></code> for extracting coefficients from <code>ss</code> objects.
</p>
<p><code><a href="#topic+cooks.distance.ss">cooks.distance.ss</a></code> for calculating Cook's distances from <code>ss</code> objects.
</p>
<p><code><a href="#topic+cov.ratio">cov.ratio</a></code> for computing covariance ratio from <code>ss</code> objects.
</p>
<p><code><a href="#topic+deviance.ss">deviance.ss</a></code> for extracting deviance from <code>ss</code> objects.
</p>
<p><code><a href="#topic+dfbeta.ss">dfbeta.ss</a></code> for calculating DFBETA from <code>ss</code> objects.
</p>
<p><code><a href="#topic+dfbetas.ss">dfbetas.ss</a></code> for calculating DFBETAS from <code>ss</code> objects.
</p>
<p><code><a href="#topic+diagnostic.plots">diagnostic.plots</a></code> for plotting regression diagnostics from <code>ss</code> objects.
</p>
<p><code><a href="#topic+fitted.ss">fitted.ss</a></code> for extracting fitted values from <code>ss</code> objects.
</p>
<p><code><a href="#topic+hatvalues.ss">hatvalues.ss</a></code> for extracting leverages from <code>ss</code> objects.
</p>
<p><code><a href="#topic+model.matrix.ss">model.matrix.ss</a></code> for constructing model matrix from <code>ss</code> objects.
</p>
<p><code><a href="#topic+plot.ss">plot.ss</a></code> for plotting predictions from <code>ss</code> objects.
</p>
<p><code><a href="#topic+plot.boot.ss">plot.boot.ss</a></code> for plotting <code>boot.ss</code> objects.
</p>
<p><code><a href="#topic+predict.ss">predict.ss</a></code> for predicting from <code>ss</code> objects.
</p>
<p><code><a href="#topic+residuals.ss">residuals.ss</a></code> for extracting residuals from <code>ss</code> objects.
</p>
<p><code><a href="#topic+rstandard.ss">rstandard.ss</a></code> for computing standardized residuals from <code>ss</code> objects.
</p>
<p><code><a href="#topic+rstudent.ss">rstudent.ss</a></code> for computing studentized residuals from <code>ss</code> objects.
</p>
<p><code><a href="#topic+smooth.influence">smooth.influence</a></code> for calculating basic influence information from <code>ss</code> objects.
</p>
<p><code><a href="#topic+smooth.influence.measures">smooth.influence.measures</a></code> for convenient display of influential observations from <code>ss</code> objects.
</p>
<p><code><a href="#topic+summary.ss">summary.ss</a></code> for summarizing <code>ss</code> objects.
</p>
<p><code><a href="#topic+vcov.ss">vcov.ss</a></code> for extracting coefficient covariance matrix from <code>ss</code> objects.
</p>
<p><code><a href="#topic+weights.ss">weights.ss</a></code> for extracting prior weights from <code>ss</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# GCV selection (default)
ss.GCV &lt;- ss(x, y, nknots = 10)
ss.GCV

# OCV selection
ss.OCV &lt;- ss(x, y, method = "OCV", nknots = 10)
ss.OCV

# GACV selection
ss.GACV &lt;- ss(x, y, method = "GACV", nknots = 10)
ss.GACV

# ACV selection
ss.ACV &lt;- ss(x, y, method = "ACV", nknots = 10)
ss.ACV

# ML selection
ss.ML &lt;- ss(x, y, method = "ML", nknots = 10)
ss.ML

# REML selection
ss.REML &lt;- ss(x, y, method = "REML", nknots = 10)
ss.REML

# AIC selection
ss.AIC &lt;- ss(x, y, method = "AIC", nknots = 10)
ss.AIC

# BIC selection
ss.BIC &lt;- ss(x, y, method = "BIC", nknots = 10)
ss.BIC

# compare results
mean( ( fx - ss.GCV$y )^2 )
mean( ( fx - ss.OCV$y )^2 )
mean( ( fx - ss.GACV$y )^2 )
mean( ( fx - ss.ACV$y )^2 )
mean( ( fx - ss.ML$y )^2 )
mean( ( fx - ss.REML$y )^2 )
mean( ( fx - ss.AIC$y )^2 )
mean( ( fx - ss.BIC$y )^2 )

# plot results
plot(x, y)
rlist &lt;- list(ss.GCV, ss.OCV, ss.GACV, ss.ACV,
              ss.REML, ss.ML, ss.AIC, ss.BIC)
for(j in 1:length(rlist)){
   lines(rlist[[j]], lwd = 2, col = j)
}

</code></pre>

<hr>
<h2 id='summary'>
Summary methods for Fit Models
</h2><span id='topic+summary'></span><span id='topic+summary.gsm'></span><span id='topic+summary.sm'></span><span id='topic+summary.ss'></span><span id='topic+print.summary.gsm'></span><span id='topic+print.summary.sm'></span><span id='topic+print.summary.ss'></span>

<h3>Description</h3>

<p><code>summary</code> methods for object classes &quot;gsm&quot;, &quot;sm&quot;, and &quot;ss&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gsm'
summary(object, ...)

## S3 method for class 'sm'
summary(object, ...)

## S3 method for class 'ss'
summary(object, ...)

## S3 method for class 'summary.gsm'
print(x, digits = max(3, getOption("digits") - 3), 
      signif.stars = getOption("show.signif.stars"), ...)

## S3 method for class 'summary.sm'
print(x, digits = max(3, getOption("digits") - 3), 
      signif.stars = getOption("show.signif.stars"), ...)

## S3 method for class 'summary.ss'
print(x, digits = max(3, getOption("digits") - 3), 
      signif.stars = getOption("show.signif.stars"), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="summary_+3A_x">x</code></td>
<td>

<p>an object of class &quot;summary.gsm&quot; output by the <code><a href="#topic+summary.gsm">summary.gsm</a></code> function, &quot;summary.sm&quot; output by the <code><a href="#topic+summary.sm">summary.sm</a></code> function, or &quot;summary.ss&quot; output by the <code><a href="#topic+summary.ss">summary.ss</a></code> function.
</p>
</td></tr>
<tr><td><code id="summary_+3A_digits">digits</code></td>
<td>

<p>the minimum number of significant digits to be printed in values.  
</p>
</td></tr>
<tr><td><code id="summary_+3A_signif.stars">signif.stars</code></td>
<td>

<p>logical. If <code>TRUE</code>, &lsquo;significance stars&rsquo; are printed for each coefficient.  
</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>

<p>additional arguments affecting the summary produced (currently ignored).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Summary includes information for assessing the statistical and practical significance of the model terms. 
</p>
<p>Statistical inference is conducted via (approximate) frequentist chi-square tests using the Bayesian interpretation of a smoothing spline (Nychka, 1988; Wahba, 1983). 
</p>
<p>With multiple smooth terms included in the model, the inferential results may (and likely will) differ slightly depending on the <code>tprk</code> argument (when using the <code><a href="#topic+gsm">gsm</a></code> and <code><a href="#topic+sm">sm</a></code> functions). 
</p>
<p>If significance testing is of interest, the <code>tprk = FALSE</code> option may be desirable, given that this allows for unique basis function coefficients for each model term.
</p>
<p>In all cases, the inferential results are based on a (pseudo) F or chi-square statistic which fails to consider the uncertainty of the smoothing parameter estimation.
</p>


<h3>Value</h3>

<table>
<tr><td><code>residuals</code></td>
<td>
<p>the deviance residuals.</p>
</td></tr>
<tr><td><code>fstatistic</code></td>
<td>
<p>the F statistic for testing all effects (parametric and smooth).</p>
</td></tr>
<tr><td><code>dev.expl</code></td>
<td>
<p>the explained deviance.</p>
</td></tr>
<tr><td><code>p.table</code></td>
<td>
<p>the coefficient table for (approximate) inference on the parametric terms.</p>
</td></tr>
<tr><td><code>s.table</code></td>
<td>
<p>the coefficient table for (approximate) inference on the smooth terms.</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>the estimate of the dispersion parameter.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>the observed coefficient of multiple determination.</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p>the adjusted coefficient of multiple determination.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>the collinearity indices, i.e., square-roots of the variance inflation factors (see <code>varinf</code>). A value of 1 indicates no collinearity, and higher values indicate more collinearity of a given term with other model terms.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>the importance indices. Larger values indicate more importance, and the values satisfy <code>sum(pi) = 1</code>. Note that elements of <code>pi</code> can be negative.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the original function call.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the specified family (for gsm objects).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), <em>SAGE Research Methods Foundations.</em> <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Nychka, D. (1988). Bayesian confience intervals for smoothing splines. <em>Journal of the American Statistical Association, 83(404)</em>, 1134-1143. <a href="https://doi.org/10.2307/2290146">doi:10.2307/2290146</a>
</p>
<p>Wahba, G. (1983). Bayesian &quot;confidence intervals&quot; for the cross-validated smoothing spline. <em>Journal of the Royal Statistical Society. Series B, 45(1)</em>, 133-150. <a href="https://doi.org/10.1111/j.2517-6161.1983.tb01239.x">doi:10.1111/j.2517-6161.1983.tb01239.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsm">gsm</a></code>, <code><a href="#topic+sm">sm</a></code>, and <code><a href="#topic+ss">ss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: gsm

# generate data
set.seed(1)
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- rbinom(n = n, size = 1, p = 1 / (1 + exp(-fx)))

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots (tprk = TRUE)
gsm.ssa &lt;- gsm(y ~ x * z, family = binomial, knots = knots)
summary(gsm.ssa)

# fit sm with specified knots (tprk = FALSE)
gsm.gam &lt;- gsm(y ~ x * z, family = binomial, knots = knots, tprk = FALSE)
summary(gsm.gam)


### Example 2: sm

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x + mu[zi]*pi/4)
}
fx &lt;- fun(x, z)
y &lt;- fx + rnorm(n, sd = 0.5)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit sm with specified knots (tprk = TRUE)
sm.ssa &lt;- sm(y ~ x * z, knots = knots)
summary(sm.ssa)

# fit sm with specified knots (tprk = FALSE)
sm.gam &lt;- sm(y ~ x * z, knots = knots, tprk = FALSE)
summary(sm.gam)


### Example 3: ss

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5)

# regular smoothing spline
ss.reg &lt;- ss(x, y, nknots = 10)
summary(ss.reg)

</code></pre>

<hr>
<h2 id='theta.mle'>
MLE of Theta for Negative Binomial
</h2><span id='topic+theta.mle'></span>

<h3>Description</h3>

<p>Computes the maximum likelihood estimate of the size (theta) parameter for the Negative Binomial distribution via a Newton-Raphson algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theta.mle(y, mu, theta, wt = 1, 
          maxit = 100, maxth = .Machine$double.xmax,
          tol = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theta.mle_+3A_y">y</code></td>
<td>

<p>response vector
</p>
</td></tr>
<tr><td><code id="theta.mle_+3A_mu">mu</code></td>
<td>

<p>mean vector
</p>
</td></tr>
<tr><td><code id="theta.mle_+3A_theta">theta</code></td>
<td>

<p>initial theta (optional)
</p>
</td></tr>
<tr><td><code id="theta.mle_+3A_wt">wt</code></td>
<td>

<p>weight vector
</p>
</td></tr>
<tr><td><code id="theta.mle_+3A_maxit">maxit</code></td>
<td>

<p>max number of iterations  
</p>
</td></tr>
<tr><td><code id="theta.mle_+3A_maxth">maxth</code></td>
<td>

<p>max possible value of <code>theta</code>
</p>
</td></tr>
<tr><td><code id="theta.mle_+3A_tol">tol</code></td>
<td>

<p>convergence tolerance  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on the <code>glm.nb</code> function in the <b>MASS</b> package. If <code>theta</code> is missing, the initial estimate of theta is given by 
</p>
<p><code>theta &lt;- 1 / mean(wt * (y / mu - 1)^2)</code> 
</p>
<p>which is motivated by the method of moments estimator for the dispersion parameter in a quasi-Poisson model.
</p>


<h3>Value</h3>

<p>Returns estimated theta with attributes
</p>
<table>
<tr><td><code>SE</code></td>
<td>
<p>standard error estimate</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (1999) Modern Applied Statistics with S-PLUS. Third Edition. Springer.
</p>
<p>https://www.rdocumentation.org/packages/MASS/versions/7.3-51.6/topics/negative.binomial
</p>
<p>https://www.rdocumentation.org/packages/MASS/versions/7.3-51.6/topics/glm.nb
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NegBin">NegBin</a></code> for details on the Negative Binomial distribution
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data
n &lt;- 1000
x &lt;- seq(0, 1, length.out = n)
fx &lt;- 3 * x + sin(2 * pi * x) - 1.5
mu &lt;- exp(fx)

# simulate negative binomial data
set.seed(1)
y &lt;- rnbinom(n = n, size = 1/2, mu = mu)

# estimate theta
theta.mle(y, mu)
</code></pre>

<hr>
<h2 id='thinplate'>
Thin Plate Spline Basis and Penalty
</h2><span id='topic+thinplate'></span><span id='topic+basis.tps'></span><span id='topic+basis_tps'></span><span id='topic+penalty.tps'></span><span id='topic+penalty_tps'></span>

<h3>Description</h3>

<p>Generate the smoothing spline basis and penalty matrix for a thin plate spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basis.tps(x, knots, m = 2, rk = TRUE, intercept = FALSE, ridge = FALSE)

penalty.tps(x, m = 2, rk = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thinplate_+3A_x">x</code></td>
<td>

<p>Predictor variables (basis) or spline knots (penalty). Numeric or integer vector of length <code class="reqn">n</code>, or matrix of dimension <code class="reqn">n</code> by <code class="reqn">p</code>.
</p>
</td></tr>
<tr><td><code id="thinplate_+3A_knots">knots</code></td>
<td>

<p>Spline knots. Numeric or integer vector of length <code class="reqn">r</code>, or matrix of dimension <code class="reqn">r</code> by <code class="reqn">p</code>.
</p>
</td></tr>
<tr><td><code id="thinplate_+3A_m">m</code></td>
<td>

<p>Penalty order. &quot;m=1&quot; for linear thin plate spline, &quot;m=2&quot; for cubic, and &quot;m=3&quot; for quintic. Must satisfy <code class="reqn">2m &gt; p</code>.
</p>
</td></tr>
<tr><td><code id="thinplate_+3A_rk">rk</code></td>
<td>

<p>If true (default), the reproducing kernel parameterization is used. Otherwise, the classic thin plate basis is returned.  
</p>
</td></tr>
<tr><td><code id="thinplate_+3A_intercept">intercept</code></td>
<td>

<p>If <code>TRUE</code>, the first column of the basis will be a column of ones. 
</p>
</td></tr>
<tr><td><code id="thinplate_+3A_ridge">ridge</code></td>
<td>

<p>If <code>TRUE</code>, the basis matrix is post-multiplied by the inverse square root of the penalty matrix. Only applicable if <code>rk = TRUE</code>. See Note and Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates a basis function or penalty matrix used to fit linear, cubic, and quintic thin plate splines. 
</p>
<p>The basis function matrix has the form 
</p>
<p style="text-align: center;"><code class="reqn">X = [X_0,  X_1]</code>
</p>

<p>where the matrix <code>X_0</code> is of dimension <code class="reqn">n</code> by <code class="reqn">M-1</code> (plus 1 if an intercept is included) where <code class="reqn">M = {p+m-1 \choose p}</code>, and <code>X_1</code> is a matrix of dimension <code class="reqn">n</code> by <code class="reqn">r</code>. 
</p>
<p>The <code>X_0</code> matrix contains the &quot;parametric part&quot; of the basis, which includes polynomial functions of the columns of <code>x</code> up to degree <code class="reqn">m-1</code> (and potentially interactions).
</p>
<p>The matrix <code>X_1</code> contains the &quot;nonparametric part&quot; of the basis.
</p>
<p>If <code>rk = TRUE</code>, the matrix <code>X_1</code> consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = (I - P_x) (I - P_y) E(|x - y|)</code>
</p>

<p>evaluated at all combinations of <code>x</code> and <code>knots</code>. Note that <code class="reqn">P_x</code> and <code class="reqn">P_y</code> are projection operators, <code class="reqn">|.|</code> denotes the Euclidean distance, and the TPS semi-kernel is defined as
</p>
<p style="text-align: center;"><code class="reqn">E(z) = \alpha z^{2m-p} \log(z)</code>
</p>

<p>if <code class="reqn">p</code> is even and
</p>
<p style="text-align: center;"><code class="reqn">E(z) = \beta z^{2m-p}</code>
</p>

<p>otherwise, where <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> are positive constants (see References).
</p>
<p>If <code>rk = FALSE</code>, the matrix <code>X_1</code> contains the TPS semi-kernel <code class="reqn">E(.)</code> evaluated at all combinations of <code>x</code> and <code>knots</code>. Note: the TPS semi-kernel is <em>not</em> positive (semi-)definite, but the projection is.
</p>
<p>If <code>rk = TRUE</code>, the penalty matrix consists of the <em>reproducing kernel</em> function
</p>
<p style="text-align: center;"><code class="reqn">\rho(x, y) = (I - P_x) (I - P_y) E(|x - y|)</code>
</p>

<p>evaluated at all combinations of <code>x</code>. If <code>rk = FALSE</code>, the penalty matrix contains the TPS semi-kernel <code class="reqn">E(.)</code> evaluated at all combinations of <code>x</code>.
</p>


<h3>Value</h3>

<p>Basis: Matrix of dimension <code>c(length(x), df)</code> where <code>df = nrow(as.matrix(knots)) + choose(p + m - 1, p) - !intercept</code> and <code>p = ncol(as.matrix(x))</code>.
</p>
<p>Penalty: Matrix of dimension <code>c(r, r)</code> where <code>r = nrow(as.matrix(x))</code> is the number of knots.
</p>


<h3>Note</h3>

<p>The inputs <code>x</code> and <code>knots</code> must have the same dimension.
</p>
<p>If <code>rk = TRUE</code> and <code>ridge = TRUE</code>, the penalty matrix is the identity matrix.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing Spline ANOVA Models. 2nd Ed. New York, NY: Springer-Verlag.  <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2017). Regression with ordered predictors via ordinal smoothing splines. <em>Frontiers in Applied Mathematics and Statistics, 3</em>(15), 1-13. <a href="https://doi.org/10.3389/fams.2017.00015">doi:10.3389/fams.2017.00015</a>
</p>
<p>Helwig, N. E., &amp; Ma, P. (2015). Fast and stable multiple smoothing parameter selection in smoothing spline analysis of variance models with large samples. <em>Journal of Computational and Graphical Statistics, 24</em>(3), 715-732. <a href="https://doi.org/10.1080/10618600.2014.926819">doi:10.1080/10618600.2014.926819</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+polynomial">polynomial</a></code> for a basis and penalty for numeric variables.
</p>
<p>See <code><a href="#topic+spherical">spherical</a></code> for a basis and penalty for spherical variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   standard parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- seq(0, 1, length.out = n)
knots &lt;- seq(0, 0.95, by = 0.05)
eta &lt;- 1 + 2 * x + sin(2 * pi * x)
y &lt;- eta + rnorm(n, sd = 0.5)

# cubic thin plate spline basis
X &lt;- basis.tps(x, knots, intercept = TRUE)

# cubic thin plate spline penalty
Q &lt;- penalty.tps(knots)

# pad Q with zeros (for intercept and linear effect)
Q &lt;- rbind(0, 0, cbind(0, 0, Q))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- psolve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta - yhat)^2))

# plot results
plot(x, y)
lines(x, yhat)



######***######   ridge parameterization   ######***######

# generate data
set.seed(0)
n &lt;- 101
x &lt;- seq(0, 1, length.out = n)
knots &lt;- seq(0, 0.95, by = 0.05)
eta &lt;- 1 + 2 * x + sin(2 * pi * x)
y &lt;- eta + rnorm(n, sd = 0.5)

# cubic thin plate spline basis
X &lt;- basis.tps(x, knots, intercept = TRUE, ridge = TRUE)

# cubic thin plate spline penalty (ridge)
Q &lt;- diag(rep(c(0, 1), times = c(2, ncol(X) - 2)))

# define smoothing parameter
lambda &lt;- 1e-5

# estimate coefficients
coefs &lt;- psolve(crossprod(X) + n * lambda * Q) %*% crossprod(X, y)

# estimate eta
yhat &lt;- X %*% coefs

# check rmse
sqrt(mean((eta - yhat)^2))

# plot results
plot(x, y)
lines(x, yhat)

</code></pre>

<hr>
<h2 id='varimp'>
Variable Importance Indices
</h2><span id='topic+varimp'></span>

<h3>Description</h3>

<p>Computes variable importance indices for terms of a smooth model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varimp(object, newdata = NULL, combine = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varimp_+3A_object">object</code></td>
<td>

<p>an object of class &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function or an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function.
</p>
</td></tr>
<tr><td><code id="varimp_+3A_newdata">newdata</code></td>
<td>

<p>the data used for variable importance calculation (if <code>NULL</code> training data are used).  
</p>
</td></tr>
<tr><td><code id="varimp_+3A_combine">combine</code></td>
<td>

<p>a switch indicating if the parametric and smooth components of the importance should be combined (default) or returned separately.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose that the function can be written as
</p>
<p style="text-align: center;"><code class="reqn">\eta = \eta_0 + \eta_1 + \eta_2 + ... + \eta_p</code>
</p>

<p>where <code class="reqn">\eta_0</code> is a constant (intercept) term, and <code class="reqn">\eta_j</code> denotes the <code class="reqn">j</code>-th effect function, which is assumed to have mean zero. Note that <code class="reqn">\eta_j</code> could be a main or interaction effect function for all <code class="reqn">j = 1, ..., p</code>.
</p>
<p>The variable importance index for the <code class="reqn">j</code>-th effect term is defined as
</p>
<p style="text-align: center;"><code class="reqn">\pi_j = (\eta_j^\top \eta_*) / (\eta_*^\top \eta_*)</code>
</p>

<p>where <code class="reqn">\eta_* = \eta_1 + \eta_2 + ... + \eta_p</code>. Note that <code class="reqn">\sum_{j = 1}^p \pi_j = 1</code> but there is no guarantee that <code class="reqn">\pi_j &gt; 0</code>. 
</p>
<p>If all <code class="reqn">\pi_j</code> are non-negative, then <code class="reqn">\pi_j</code> gives the proportion of the model's R-squared that can be accounted for by the <code class="reqn">j</code>-th effect term. Thus, values of <code class="reqn">\pi_j</code> closer to 1 indicate that <code class="reqn">\eta_j</code> is more important, whereas values of <code class="reqn">\pi_j</code> closer to 0 (including negative values) indicate that <code class="reqn">\eta_j</code> is less important.
</p>


<h3>Value</h3>

<p>If <code>combine = TRUE</code>, returns a named vector containing the importance indices for each effect function (in <code>object$terms</code>).
</p>
<p>If <code>combine = FALSE</code>, returns a data frame where the first column gives the importance indices for the <code>p</code>arametric components and the second column gives the importance indices for the <code>s</code>mooth (nonparametric) components.
</p>


<h3>Note</h3>

<p>When <code>combine = FALSE</code>, importance indices will be equal to zero for non-existent components of a model term. For example, a <code><a href="#topic+nominal">nominal</a></code> effect does not have a parametric component, so the <code>$p</code> component of the importance index for a nominal effect will be zero.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+summary.sm">summary.sm</a></code> for more thorough summaries of smooth models.
</p>
<p>See <code><a href="#topic+summary.gsm">summary.gsm</a></code> for more thorough summaries of generalized smooth models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##########   EXAMPLE 1   ##########
### 1 continuous and 1 nominal predictor

# generate data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
z &lt;- factor(sample(letters[1:3], size = n, replace = TRUE))
fun &lt;- function(x, z){
  mu &lt;- c(-2, 0, 2)
  zi &lt;- as.integer(z)
  fx &lt;- mu[zi] + 3 * x + sin(2 * pi * x)
}
fx &lt;- fun(x, z)
y &lt;- fx + rnorm(n, sd = 0.5)

# define marginal knots
probs &lt;- seq(0, 0.9, by = 0.1)
knots &lt;- list(x = quantile(x, probs = probs),
              z = letters[1:3])

# fit correct (additive) model
sm.add &lt;- sm(y ~ x + z, knots = knots)

# fit incorrect (interaction) model
sm.int &lt;- sm(y ~ x * z, knots = knots)

# true importance indices
eff &lt;- data.frame(x = 3 * x + sin(2 * pi * x), z = c(-2, 0, 2)[as.integer(z)])
eff &lt;- scale(eff, scale = FALSE)
fstar &lt;- rowSums(eff)
colSums(eff * fstar) / sum(fstar^2)

# estimated importance indices
varimp(sm.add)
varimp(sm.int)



##########   EXAMPLE 2   ##########
### 4 continuous predictors
### additive model

# generate data
set.seed(1)
n &lt;- 100
fun &lt;- function(x){
  sin(pi*x[,1]) + sin(2*pi*x[,2]) + sin(3*pi*x[,3]) + sin(4*pi*x[,4])
}
data &lt;- as.data.frame(replicate(4, runif(n)))
colnames(data) &lt;- c("x1v", "x2v", "x3v", "x4v")
fx &lt;- fun(data)
y &lt;- fx + rnorm(n)

# define ssa knot indices
knots.indx &lt;- c(bin.sample(data$x1v, nbin = 10, index.return = TRUE)$ix,
                bin.sample(data$x2v, nbin = 10, index.return = TRUE)$ix,
                bin.sample(data$x3v, nbin = 10, index.return = TRUE)$ix,
                bin.sample(data$x4v, nbin = 10, index.return = TRUE)$ix)

# fit correct (additive) model
sm.add &lt;- sm(y ~ x1v + x2v + x3v + x4v, data = data, knots = knots.indx)

# fit incorrect (interaction) model
sm.int &lt;- sm(y ~ x1v * x2v + x3v + x4v, data = data, knots = knots.indx)

# true importance indices
eff &lt;- data.frame(x1v = sin(pi*data[,1]), x2v = sin(2*pi*data[,2]),
                  x3v = sin(3*pi*data[,3]), x4v = sin(4*pi*data[,4]))
eff &lt;- scale(eff, scale = FALSE)
fstar &lt;- rowSums(eff)
colSums(eff * fstar) / sum(fstar^2)

# estimated importance indices
varimp(sm.add)
varimp(sm.int)

</code></pre>

<hr>
<h2 id='varinf'>
Variance Inflation Factors
</h2><span id='topic+varinf'></span>

<h3>Description</h3>

<p>Computes variance inflation factors for terms of a smooth model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varinf(object, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varinf_+3A_object">object</code></td>
<td>

<p>an object of class &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function or an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function.
</p>
</td></tr>
<tr><td><code id="varinf_+3A_newdata">newdata</code></td>
<td>

<p>the data used for variance inflation calculation (if <code>NULL</code> training data are used).  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\kappa_j^2</code> denote the VIF for the <code class="reqn">j</code>-th model term. 
</p>
<p>Values of <code class="reqn">\kappa_j^2</code> close to 1 indicate no multicollinearity issues for the <code class="reqn">j</code>-th term. Larger values of <code class="reqn">\kappa_j^2</code> indicate that <code class="reqn">\eta_j</code> has more collinearity with other terms. 
</p>
<p>Thresholds of <code class="reqn">\kappa_j^2 &gt; 5</code> or <code class="reqn">\kappa_j^2 &gt; 10</code> are typically recommended for determining if multicollinearity is too much of an issue.
</p>
<p>To understand these thresholds, note that
</p>
<p style="text-align: center;"><code class="reqn">\kappa_j^2 = \frac{1}{1 - R_j^2}</code>
</p>

<p>where <code class="reqn">R_j^2</code> is the R-squared for the linear model predicting <code class="reqn">\eta_j</code> from the remaining model terms.
</p>


<h3>Value</h3>

<p>a named vector containing the variance inflation factors for each effect function (in <code>object$terms</code>).
</p>


<h3>Note</h3>

<p>Suppose that the function can be written as
</p>
<p style="text-align: center;"><code class="reqn">\eta = \eta_0 + \eta_1 + \eta_2 + ... + \eta_p</code>
</p>

<p>where <code class="reqn">\eta_0</code> is a constant (intercept) term, and <code class="reqn">\eta_j</code> denotes the <code class="reqn">j</code>-th effect function, which is assumed to have mean zero. Note that <code class="reqn">\eta_j</code> could be a main or interaction effect function for all <code class="reqn">j = 1, ..., p</code>.
</p>
<p>Defining the <code class="reqn">p \times p</code> matrix <code class="reqn">C</code> with entries
</p>
<p style="text-align: center;"><code class="reqn">C_{jk} = \cos(\eta_j, \eta_k)</code>
</p>

<p>where the cosine is defined with respect to the training data, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">\cos(\eta_j, \eta_k) = \frac{\sum_{i=1}^n \eta_j(x_i) \eta_k(x_i)}{\sqrt{\sum_{i=1}^n \eta_j^2(x_i)} \sqrt{\sum_{i=1}^n \eta_k^2(x_i)}}</code>
</p>

<p>The variane inflation factors are the diagonal elements of <code class="reqn">C^{-1}</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">\kappa_j^2 = C^{jj}</code>
</p>

<p>where <code class="reqn">\kappa_j^2</code> is the VIF for the <code class="reqn">j</code>-th term, and <code class="reqn">C^{jj}</code> denotes the <code class="reqn">j</code>-th diagonal element of the matrix <code class="reqn">C^{-1}</code>. 
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, C. (2013). Smoothing spline ANOVA models, 2nd edition. New York: Springer. <a href="https://doi.org/10.1007/978-1-4614-5369-7">doi:10.1007/978-1-4614-5369-7</a>
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+summary.sm">summary.sm</a></code> for more thorough summaries of smooth models.
</p>
<p>See <code><a href="#topic+summary.gsm">summary.gsm</a></code> for more thorough summaries of generalized smooth models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########   EXAMPLE 1   ##########
### 4 continuous predictors
### no multicollinearity

# generate data
set.seed(1)
n &lt;- 100
fun &lt;- function(x){
  sin(pi*x[,1]) + sin(2*pi*x[,2]) + sin(3*pi*x[,3]) + sin(4*pi*x[,4])
}
data &lt;- as.data.frame(replicate(4, runif(n)))
colnames(data) &lt;- c("x1v", "x2v", "x3v", "x4v")
fx &lt;- fun(data)
y &lt;- fx + rnorm(n)

# fit model
mod &lt;- sm(y ~ x1v + x2v + x3v + x4v, data = data, tprk = FALSE)

# check vif
varinf(mod)


##########   EXAMPLE 2   ##########
### 4 continuous predictors
### multicollinearity

# generate data
set.seed(1)
n &lt;- 100
fun &lt;- function(x){
  sin(pi*x[,1]) + sin(2*pi*x[,2]) + sin(3*pi*x[,3]) + sin(3*pi*x[,4])
}
data &lt;- as.data.frame(replicate(3, runif(n)))
data &lt;- cbind(data, c(data[1,2], data[2:n,3]))
colnames(data) &lt;- c("x1v", "x2v", "x3v", "x4v")
fx &lt;- fun(data)
y &lt;- fx + rnorm(n)

# check collinearity
cor(data)
cor(sin(3*pi*data[,3]), sin(3*pi*data[,4]))

# fit model
mod &lt;- sm(y ~ x1v + x2v + x3v + x4v, data = data, tprk = FALSE)

# check vif
varinf(mod)

</code></pre>

<hr>
<h2 id='vcov'>
Calculate Variance-Covariance Matrix for a Fitted Smooth Model
</h2><span id='topic+vcov.ss'></span><span id='topic+vcov.sm'></span><span id='topic+vcov.gsm'></span>

<h3>Description</h3>

<p>Returns the variance-covariance matrix for the basis function coefficients from a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
vcov(object, ...)

## S3 method for class 'sm'
vcov(object, ...)

## S3 method for class 'gsm'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov_+3A_object">object</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="vcov_+3A_...">...</code></td>
<td>

<p>other arugments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance-covariance matrix is calculated using the Bayesian interpretation of a smoothing spline. Unlike the classic treatments (e.g., Wahba, 1983; Nychka, 1988), which interpret the smoothing spline as a Bayesian estimate of a Gaussian process, this treatment applies the Bayesian interpretation directly on the coefficient vector. More specifically, the smoothing spline basis function coefficients are interpreted as Bayesian estimates of the basis function coefficients (see Helwig, 2020). 
</p>


<h3>Value</h3>

<p>Returns the (symmetric) matrix such that cell (<code class="reqn">i,j</code>) contains the covariance between the <code class="reqn">i</code>-th and <code class="reqn">j</code>-th elements of the coefficient vector.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>
<p>Nychka, D. (1988). Bayesian confience intervals for smoothing splines. <em>Journal of the American Statistical Association, 83(404)</em>, 1134-1143. <a href="https://doi.org/10.2307/2290146">doi:10.2307/2290146</a>
</p>
<p>Wahba, G. (1983). Bayesian &quot;confidence intervals&quot; for the cross-validated smoothing spline. <em>Journal of the Royal Statistical Society. Series B, 45(1)</em>, 133-150. <a href="https://doi.org/10.1111/j.2517-6161.1983.tb01239.x">doi:10.1111/j.2517-6161.1983.tb01239.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code> for model fitting
</p>
<p><code><a href="#topic+boot.ss">boot.ss</a></code>, <code><a href="#topic+boot.sm">boot.sm</a></code>, <code><a href="#topic+boot.gsm">boot.gsm</a></code> for bootstrapping
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for 'ss' objects this function is defined as
  function(object, ...){
    Sigma &lt;- tcrossprod(object$fit$cov.sqrt)
    rownames(Sigma) &lt;- colnames(Sigma) &lt;- names(object$fit$coef)
    Sigma
  }

## for 'sm' and 'gsm' objects this function is defined as
  function(object, ...){
    Sigma &lt;- tcrossprod(object$cov.sqrt)
    rownames(Sigma) &lt;- colnames(Sigma) &lt;- names(object$coefficients)
    Sigma
  }
</code></pre>

<hr>
<h2 id='weights'>
Extract Smooth Model Weights
</h2><span id='topic+weights.ss'></span><span id='topic+weights.sm'></span><span id='topic+weights.gsm'></span>

<h3>Description</h3>

<p>Extracts prior weights from a fit smoothing spline (fit by <code><a href="#topic+ss">ss</a></code>), smooth model (fit by <code><a href="#topic+sm">sm</a></code>), or generalized smooth model (fit by <code><a href="#topic+gsm">gsm</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ss'
weights(object, ...)

## S3 method for class 'sm'
weights(object, ...)

## S3 method for class 'gsm'
weights(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weights_+3A_object">object</code></td>
<td>

<p>an object of class &quot;gsm&quot; output by the <code><a href="#topic+gsm">gsm</a></code> function, &quot;sm&quot; output by the <code><a href="#topic+sm">sm</a></code> function, or &quot;ss&quot; output by the <code><a href="#topic+ss">ss</a></code> function
</p>
</td></tr>
<tr><td><code id="weights_+3A_...">...</code></td>
<td>

<p>other arugments (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the &quot;prior weights&quot;, which are user-specified via the <code>w</code> argument (of the <code><a href="#topic+ss">ss</a></code> function) or the <code>weights</code> argument (of the <code><a href="#topic+sm">sm</a></code> and <code><a href="#topic+gsm">gsm</a></code> functions). If no prior weights were supplied, returns the (default) unit weights, i.e., <code>rep(1, nobs)</code>.
</p>


<h3>Value</h3>

<p>Prior weights extracted from <code>object</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Chambers, J. M. and Hastie, T. J. (1992) <em>Statistical Models in S</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Helwig, N. E. (2020). Multiple and Generalized Nonparametric Regression. In P. Atkinson, S. Delamont, A. Cernat, J. W. Sakshaug, &amp; R. A. Williams (Eds.), SAGE Research Methods Foundations. <a href="https://doi.org/10.4135/9781526421036885885">doi:10.4135/9781526421036885885</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ss">ss</a></code>, <code><a href="#topic+sm">sm</a></code>, <code><a href="#topic+gsm">gsm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate weighted data
set.seed(1)
n &lt;- 100
x &lt;- seq(0, 1, length.out = n)
w &lt;- rep(5:15, length.out = n)
fx &lt;- 2 + 3 * x + sin(2 * pi * x)
y &lt;- fx + rnorm(n, sd = 0.5 / sqrt(w))

# smoothing spline
mod.ss &lt;- ss(x, y, w, nknots = 10)
w.ss &lt;- weights(mod.ss)

# smooth model
mod.sm &lt;- sm(y ~ x, weights = w, knots = 10)
w.sm &lt;- weights(mod.sm)

# generalized smooth model (family = gaussian)
mod.gsm &lt;- gsm(y ~ x, weights = w, knots = 10)
w.gsm &lt;- weights(mod.gsm)

# note: weights are internally rescaled such as 
w0 &lt;- w / mean(w)
max(abs(w0 - w.ss))
max(abs(w0 - w.sm))
max(abs(w0 - w.gsm))

</code></pre>

<hr>
<h2 id='wtd.mean'>
Weighted Arithmetic Mean
</h2><span id='topic+wtd.mean'></span>

<h3>Description</h3>

<p>Generic function for calculating the weighted (and possibly trimmed) arithmetic mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wtd.mean(x, weights, trim = 0, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wtd.mean_+3A_x">x</code></td>
<td>

<p>Numerical or logical vector.
</p>
</td></tr>
<tr><td><code id="wtd.mean_+3A_weights">weights</code></td>
<td>

<p>Vector of non-negative weights.  
</p>
</td></tr>
<tr><td><code id="wtd.mean_+3A_trim">trim</code></td>
<td>

<p>Fraction [0, 0.5) of observations trimmed from each end before calculating mean.
</p>
</td></tr>
<tr><td><code id="wtd.mean_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical indicating whether <code>NA</code> values should be removed before calculation.
</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>If <code>weights</code> are missing, the weights are defined to be a vector of ones (which is the same as the unweighted arithmetic mean).
</p>
<p>If <code>trim</code> is non-zero, then <code>trim</code> observations are deleted from each end before the (weighted) mean is computed. The quantiles used for trimming are defined using the <code><a href="#topic+wtd.quantile">wtd.quantile</a></code> function.
</p>


<h3>Value</h3>

<p>Returns the weighted and/or trimmed arithmetic mean.
</p>


<h3>Note</h3>

<p>The weighted (and possible trimmed) mean is defined as:
</p>
<p><code>sum(weights * x) / sum(weights)</code>
</p>
<p>where <code>x</code> is the (possibly trimmed version of the) input data.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wtd.var">wtd.var</a></code> for weighted variance calculations
</p>
<p><code><a href="#topic+wtd.quantile">wtd.quantile</a></code> for weighted quantile calculations
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data and weights
set.seed(1)
x &lt;- rnorm(10)
w &lt;- rpois(10, lambda = 10)

# weighted mean
wtd.mean(x, w)
sum(x * w) / sum(w)

# trimmed mean
q &lt;- quantile(x, probs = c(0.1, 0.9), type = 4)
i &lt;- which(x &lt; q[1] | x &gt; q[2])
mean(x[-i])
wtd.mean(x, trim = 0.1)

# weighted and trimmed mean
q &lt;- wtd.quantile(x, w, probs = c(0.1, 0.9))
i &lt;- which(x &lt; q[1] | x &gt; q[2])
wtd.mean(x[-i], w[-i])
wtd.mean(x, w, trim = 0.1)

</code></pre>

<hr>
<h2 id='wtd.quantile'>
Weighted Quantiles
</h2><span id='topic+wtd.quantile'></span>

<h3>Description</h3>

<p>Generic function for calculating weighted quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wtd.quantile(x, weights, probs = seq(0, 1, 0.25), 
             na.rm = FALSE, names = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wtd.quantile_+3A_x">x</code></td>
<td>

<p>Numerical or logical vector.
</p>
</td></tr>
<tr><td><code id="wtd.quantile_+3A_weights">weights</code></td>
<td>

<p>Vector of non-negative weights.  
</p>
</td></tr>
<tr><td><code id="wtd.quantile_+3A_probs">probs</code></td>
<td>

<p>Numeric vector of probabilities with values in [0,1].
</p>
</td></tr>
<tr><td><code id="wtd.quantile_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical indicating whether <code>NA</code> values should be removed before calculation.
</p>
</td></tr>
<tr><td><code id="wtd.quantile_+3A_names">names</code></td>
<td>

<p>Logical indicating if the result should have names corresponding to the probabilities.  
</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>If <code>weights</code> are missing, the weights are defined to be a vector of ones (which is the same as the unweighted quantiles).
</p>
<p>The weighted quantiles are computed by linearly interpolating the empirical cdf via the <code><a href="stats.html#topic+approx">approx</a></code> function. 
</p>


<h3>Value</h3>

<p>Returns the weighted quantiles corresponding to the input probabilities.
</p>


<h3>Note</h3>

<p>If the weights are all equal (or missing), the resulting quantiles are equivalent to those produced by the <code><a href="stats.html#topic+quantile">quantile</a></code> function using the 'type = 4' argument.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wtd.mean">wtd.mean</a></code> for weighted mean calculations
</p>
<p><code><a href="#topic+wtd.var">wtd.var</a></code> for weighted variance calculations
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data and weights
set.seed(1)
x &lt;- rnorm(10)
w &lt;- rpois(10, lambda = 10)

# unweighted quantiles
quantile(x, probs = c(0.1, 0.9), type = 4)
wtd.quantile(x, probs = c(0.1, 0.9))

# weighted quantiles
sx &lt;- sort(x, index.return = TRUE)
sw &lt;- w[sx$ix]
ecdf &lt;- cumsum(sw) / sum(sw)
approx(x = ecdf, y = sx$x, xout = c(0.1, 0.9), rule = 2)$y
wtd.quantile(x, w, probs = c(0.1, 0.9))

</code></pre>

<hr>
<h2 id='wtd.var'>
Weighted Variance and Standard Deviation
</h2><span id='topic+wtd.var'></span><span id='topic+wtd.sd'></span>

<h3>Description</h3>

<p>Generic function for calculating weighted variance or standard deviation of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wtd.var(x, weights, na.rm = FALSE)

wtd.sd(x, weights, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wtd.var_+3A_x">x</code></td>
<td>

<p>Numerical or logical vector.
</p>
</td></tr>
<tr><td><code id="wtd.var_+3A_weights">weights</code></td>
<td>

<p>Vector of non-negative weights.  
</p>
</td></tr>
<tr><td><code id="wtd.var_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical indicating whether <code>NA</code> values should be removed before calculation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weighted variance is defined as
</p>
<p><code>(n / (n - 1)) * sum(weights * (x - xbar)^2) / sum(weights)</code>
</p>
<p>where <code>n</code> is the number of observations with non-zero weights, and <code>xbar</code> is the weighted mean computed via the <code><a href="#topic+wtd.mean">wtd.mean</a></code> function.
</p>
<p>The weighted standard deviation is the square root of the weighted variance.
</p>


<h3>Value</h3>

<p>Returns the weighted variance or standard deviation.
</p>


<h3>Note</h3>

<p>If <code>weights</code> are missing, the weights are defined to be a vector of ones (which is the same as the unweighted variance or standard deviation).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wtd.mean">wtd.mean</a></code> for weighted mean calculations
</p>
<p><code><a href="#topic+wtd.quantile">wtd.quantile</a></code> for weighted quantile calculations
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data and weights
set.seed(1)
x &lt;- rnorm(10)
w &lt;- rpois(10, lambda = 10)

# weighted mean
xbar &lt;- wtd.mean(x, w)

# weighted variance
wtd.var(x, w)
(10 / 9) * sum(w * (x - xbar)^2) / sum(w)

# weighted standard deviation
wtd.sd(x, w)
sqrt((10 / 9) * sum(w * (x - xbar)^2) / sum(w))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
