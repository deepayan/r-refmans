<!DOCTYPE html><html><head><title>Help for package opera</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {opera}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#opera-package'><p>Online Prediction by ExpeRt Aggregation</p></a></li>
<li><a href='#check_loss'><p>Function to check validy of provided loss function</p></a></li>
<li><a href='#check_matrix'><p>Function to check and modify the input class and type</p></a></li>
<li><a href='#electric_load'><p>Electricity forecasting data set</p></a></li>
<li><a href='#FTRL'><p>Implementation of FTRL (Follow The Regularized Leader)</p></a></li>
<li><a href='#loss'><p>Errors suffered by a sequence of predictions</p></a></li>
<li><a href='#mixture'><p>Compute an aggregation rule</p></a></li>
<li><a href='#oracle'><p>Compute oracle predictions</p></a></li>
<li><a href='#plot_ridge_weights'><p>Functions to render dynamic mixture graphs using rAmCharts</p></a></li>
<li><a href='#plot.mixture'><p>Plot an object of class mixture</p></a></li>
<li><a href='#plot.oracle'><p>Plot an aggregation procedure</p></a></li>
<li><a href='#plt_oracle_convex'><p>Functions to render dynamic oracle graphs using rAmCharts</p></a></li>
<li><a href='#predict.mixture'><p>Predict method for Mixture models</p></a></li>
<li><a href='#seriesToBlock'><p>Convert a 1-dimensional series to blocks</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Online Prediction by Expert Aggregation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Pierre Gaillard [cre, aut],
  Yannig Goude [aut],
  Laurent Plagne [ctb],
  Thibaut Dubois [ctb],
  Benoit Thieurmel [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pierre Gaillard &lt;pierre@gaillard.me&gt;</td>
</tr>
<tr>
<td>Copyright:</td>
<td>EDF R&amp;D 2012-2015</td>
</tr>
<tr>
<td>Description:</td>
<td>Misc methods to form online predictions, for regression-oriented 
    time-series, by combining a finite set of forecasts provided by the user. See 
             Cesa-Bianchi and Lugosi (2006) &lt;<a href="https://doi.org/10.1017%2FCBO9780511546921">doi:10.1017/CBO9780511546921</a>&gt; for an overview. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2">LGPL-2</a> | <a href="https://www.r-project.org/Licenses/LGPL-2.1">LGPL-2.1</a> | <a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> [expanded from: LGPL]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://pierre.gaillard.me/opera.html">http://pierre.gaillard.me/opera.html</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/dralliag/opera/issues">https://github.com/dralliag/opera/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, htmltools, rAmCharts, htmlwidgets, pipeR, alabama,
methods, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>quantreg, quadprog, RColorBrewer, testthat, splines, caret,
mgcv, survival, knitr, gbm, rmarkdown, magrittr</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-12-06 17:07:44 UTC; BenoitThieurmel</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-12-06 18:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='opera-package'>Online Prediction by ExpeRt Aggregation</h2><span id='topic+opera-package'></span><span id='topic+opera'></span>

<h3>Description</h3>

<p>The package <code>opera</code> performs, for regression-oriented time-series,
predictions by combining a finite set of forecasts provided by the user.
More formally, it considers a sequence of observations <code>Y</code> (such as
electricity consumption, or any bounded time series) to be predicted step
by step. At each time instance <code>t</code>, a finite set of experts
(basicly some based forecasters) provide predictions <code>x</code> of the next
observation in <code>y</code>. This package proposes several adaptive and robust
methods to combine the expert forecasts based on their past performance.
</p>


<h3>Author(s)</h3>

<p>Pierre Gaillard &lt;pierre@gaillard.me&gt;
</p>


<h3>References</h3>

<p>Prediction, Learning, and Games. N. Cesa-Bianchi and G. Lugosi.
<br />
</p>
<p>Forecasting the electricity consumption by aggregating specialized experts;
a review of sequential aggregation of specialized experts, with an
application to Slovakian an French contry-wide one-day-ahead (half-)hourly
predictions, Machine Learning, in press, 2012. Marie Devaine, Pierre
Gaillard, Yannig Goude, and Gilles Stoltz
<br />
</p>
<p>Contributions to online robust aggregation: work on the approximation error and on 
probabilistic forecasting. Pierre Gaillard. PhD Thesis, University Paris-Sud, 2015.
<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('opera')  # load the package
set.seed(1)

# Example: find the best one week ahead forecasting strategy (weekly data)
# packages
library(mgcv)

# import data
data(electric_load)
idx_data_test &lt;- 620:nrow(electric_load)
data_train &lt;- electric_load[-idx_data_test, ]
data_test &lt;- electric_load[idx_data_test, ]

# Build the expert forecasts 
# ##########################

# 1) A generalized additive model
gam.fit &lt;- gam(Load ~ s(IPI) + s(Temp) + s(Time, k=3) + 
                 s(Load1) + as.factor(NumWeek), data = data_train)
gam.forecast &lt;- predict(gam.fit, newdata = data_test)

# 2) An online autoregressive model on the residuals of a medium term model

# Medium term model to remove trend and seasonality (using generalized additive model)
detrend.fit &lt;- gam(Load ~ s(Time,k=3) + s(NumWeek) + s(Temp) + s(IPI), data = data_train)
electric_load$Trend &lt;- c(predict(detrend.fit), predict(detrend.fit,newdata = data_test))
electric_load$Load.detrend &lt;- electric_load$Load - electric_load$Trend

# Residual analysis
ar.forecast &lt;- numeric(length(idx_data_test))
for (i in seq(idx_data_test)) {
  ar.fit &lt;- ar(electric_load$Load.detrend[1:(idx_data_test[i] - 1)])
  ar.forecast[i] &lt;- as.numeric(predict(ar.fit)$pred) + electric_load$Trend[idx_data_test[i]]
}

# Aggregation of experts
###########################

X &lt;- cbind(gam.forecast, ar.forecast)
colnames(X) &lt;- c('gam', 'ar')
Y &lt;- data_test$Load

matplot(cbind(Y, X), type = 'l', col = 1:6, ylab = 'Weekly load', xlab = 'Week')


# How good are the expert? Look at the oracles
oracle.convex &lt;- oracle(Y = Y, experts = X, loss.type = 'square', model = 'convex')

if(interactive()){
  plot(oracle.convex)
}

oracle.convex

# Is a single expert the best over time ? Are there breaks ?
oracle.shift &lt;- oracle(Y = Y, experts = X, loss.type = 'percentage', model = 'shifting')
if(interactive()){
  plot(oracle.shift)
}
oracle.shift

# Online aggregation of the experts with BOA
#############################################

# Initialize the aggregation rule
m0.BOA &lt;- mixture(model = 'BOA', loss.type = 'square')

# Perform online prediction using BOA There are 3 equivalent possibilities 1)
# start with an empty model and update the model sequentially
m1.BOA &lt;- m0.BOA
for (i in 1:length(Y)) {
  m1.BOA &lt;- predict(m1.BOA, newexperts = X[i, ], newY = Y[i], quiet = TRUE)
}

# 2) perform online prediction directly from the empty model
m2.BOA &lt;- predict(m0.BOA, newexpert = X, newY = Y, online = TRUE, quiet = TRUE)

# 3) perform the online aggregation directly
m3.BOA &lt;- mixture(Y = Y, experts = X, model = 'BOA', loss.type = 'square', quiet = TRUE)

# These predictions are equivalent:
identical(m1.BOA, m2.BOA)  # TRUE
identical(m1.BOA, m3.BOA)  # TRUE

# Display the results
summary(m3.BOA)
if(interactive()){
  plot(m1.BOA)
}

# Using d-dimensional time-series
##################################

# Consider the above exemple of electricity consumption 
#  to be predicted every four weeks
YBlock &lt;- seriesToBlock(X = Y, d = 4)
XBlock &lt;- seriesToBlock(X = X, d = 4)

# The four-week-by-four-week predictions can then be obtained 
# by directly using the `mixture` function as we did earlier. 

MLpolBlock &lt;- mixture(Y = YBlock, experts = XBlock, model = "MLpol", loss.type = "square", 
                      quiet = TRUE)


# The predictions can finally be transformed back to a 
# regular one dimensional time-series by using the function `blockToSeries`.

prediction &lt;- blockToSeries(MLpolBlock$prediction)

#### Using the `online = FALSE` option

# Equivalent solution is to use the `online = FALSE` option in the predict function. 
# The latter ensures that the model coefficients are not 
# updated between the next four weeks to forecast.
MLpolBlock &lt;- mixture(model = "BOA", loss.type = "square")
d = 4
n &lt;- length(Y)/d
for (i in 0:(n-1)) { 
  idx &lt;- 4*i + 1:4 # next four weeks to be predicted
  MLpolBlock &lt;- predict(MLpolBlock, newexperts = X[idx, ], newY = Y[idx], online = FALSE, 
                        quiet = TRUE)
}

print(head(MLpolBlock$weights))

</code></pre>

<hr>
<h2 id='check_loss'>Function to check validy of provided loss function</h2><span id='topic+check_loss'></span>

<h3>Description</h3>

<p>Function to check validy of provided loss function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_loss(
  loss.type,
  loss.gradient,
  Y = NULL,
  model = NULL,
  use_cpp = getOption("opera_use_cpp", default = FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_loss_+3A_loss.type">loss.type</code></td>
<td>
<p><code>character, list or function</code>. 
</p>

<dl>
<dt>character</dt><dd><p> Name of the loss to be applied ('square', 'absolute', 'percentage', or 'pinball');</p>
</dd>
<dt>list</dt><dd><p> When using pinball loss: list with field name equal to 'pinball' and field tau equal to the required quantile in [0,1];</p>
</dd>
<dt>function</dt><dd><p> A custom loss as a function of two parameters.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="check_loss_+3A_loss.gradient">loss.gradient</code></td>
<td>
<p><code>boolean, function</code>. 
</p>

<dl>
<dt>boolean</dt><dd><p> If TRUE, the aggregation rule will not be directly applied to the loss function at hand,
but to a gradient version of it. The aggregation rule is then similar to gradient descent aggregation rule. </p>
</dd>
<dt>function</dt><dd><p> If loss.type is a function, the derivative should be provided to be used (it is not automatically 
computed).</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="check_loss_+3A_y">Y</code></td>
<td>
<p><code>numeric</code> (NULL). (Optional) Target values (to perform some checks).</p>
</td></tr>
<tr><td><code id="check_loss_+3A_model">model</code></td>
<td>
<p><code>character</code> (NULL). (Optional) Model used (to perform some checks).</p>
</td></tr>
<tr><td><code id="check_loss_+3A_use_cpp">use_cpp</code></td>
<td>
<p><code>boolean</code>. Whether or not to use cpp function to increase perf.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>loss.type
</p>

<hr>
<h2 id='check_matrix'>Function to check and modify the input class and type</h2><span id='topic+check_matrix'></span>

<h3>Description</h3>

<p>Function to check and modify the input class and type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_matrix(mat, name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_matrix_+3A_mat">mat</code></td>
<td>
<p><code>data.frame, data.table, tibble</code>. Object to be cast to matrix.</p>
</td></tr>
<tr><td><code id="check_matrix_+3A_name">name</code></td>
<td>
<p><code>character</code>. Name of the object to be cast.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a 3d array if a 3d array is provided, else a matrix.
</p>

<hr>
<h2 id='electric_load'>Electricity forecasting data set</h2><span id='topic+electric_load'></span>

<h3>Description</h3>

<p>Electricity forecasting data set provided by EDF R&amp;D.
It contains weekly measurements of the total electricity consumption in France from 1996 to 2009,
together with several covariates, including temperature, industrial production indices (source: INSEE) and calendar information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(electric_load)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 731 rows and 11 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data(electric_load)
 # a few graphs to display the data
 attach(electric_load)
 plot(Load, type = 'l')
 plot(Temp, Load, pch = 16, cex = 0.5)
 plot(NumWeek, Load, pch = 16, cex = 0.5)
 plot(Load, Load1, pch = 16, cex = 0.5)
 acf(Load, lag.max = 20)
 detach(electric_load)
</code></pre>

<hr>
<h2 id='FTRL'>Implementation of FTRL (Follow The Regularized Leader)</h2><span id='topic+FTRL'></span>

<h3>Description</h3>

<p>FTRL (Shalev-Shwartz and Singer 2007) and Chap. 5 of (Hazan 2019) is the online counterpart of empirical risk minimization. 
It is a family of aggregation rules (including OGD) that uses at any time the empirical risk
minimizer so far with an additional regularization. The online optimization can be performed
on any bounded convex set that can be expressed with equality or inequality constraints. 
Note that this method is still under development and a beta version.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FTRL(
  y,
  experts,
  eta = NULL,
  fun_reg = NULL,
  fun_reg_grad = NULL,
  constr_eq = NULL,
  constr_eq_jac = NULL,
  constr_ineq = NULL,
  constr_ineq_jac = NULL,
  loss.type = list(name = "square"),
  loss.gradient = TRUE,
  w0 = NULL,
  max_iter = 50,
  obj_tol = 0.01,
  training = NULL,
  default = FALSE,
  quiet = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FTRL_+3A_y">y</code></td>
<td>
<p><code>vector</code>. Real observations.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_experts">experts</code></td>
<td>
<p><code>matrix</code>. Matrix of experts previsions.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_eta">eta</code></td>
<td>
<p><code>numeric</code>. Regularization parameter.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_fun_reg">fun_reg</code></td>
<td>
<p><code>function</code> (NULL). Regularization function to be applied during the optimization.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_fun_reg_grad">fun_reg_grad</code></td>
<td>
<p><code>function</code> (NULL). Gradient of the regularization function (to speed up the computations).</p>
</td></tr>
<tr><td><code id="FTRL_+3A_constr_eq">constr_eq</code></td>
<td>
<p><code>function</code> (NULL). Constraints (equalities) to be applied during the optimization.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_constr_eq_jac">constr_eq_jac</code></td>
<td>
<p><code>function</code> (NULL). Jacobian of the equality constraints (to speed up the computations).</p>
</td></tr>
<tr><td><code id="FTRL_+3A_constr_ineq">constr_ineq</code></td>
<td>
<p><code>function</code> (NULL). Constraints (inequalities) to be applied during the optimization (... &gt; 0).</p>
</td></tr>
<tr><td><code id="FTRL_+3A_constr_ineq_jac">constr_ineq_jac</code></td>
<td>
<p><code>function</code> (NULL). Jacobian of the inequality constraints (to speed up the computations).</p>
</td></tr>
<tr><td><code id="FTRL_+3A_loss.type">loss.type</code></td>
<td>
<p><code>character, list or function</code> (&quot;square&quot;).
</p>

<dl>
<dt>character</dt><dd><p> Name of the loss to be applied ('square', 'absolute', 'percentage', or 'pinball');</p>
</dd>
<dt>list</dt><dd><p> List with field <code>name</code> equal to the loss name. If using pinball loss, field <code>tau</code> equal to the required quantile in [0,1];</p>
</dd>
<dt>function</dt><dd><p> A custom loss as a function of two parameters (prediction, label).</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="FTRL_+3A_loss.gradient">loss.gradient</code></td>
<td>
<p><code>boolean, function</code> (TRUE). 
</p>

<dl>
<dt>boolean</dt><dd><p> If TRUE, the aggregation rule will not be directly applied to the loss function at hand,
but to a gradient version of it. The aggregation rule is then similar to gradient descent aggregation rule. </p>
</dd>
<dt>function</dt><dd><p> If loss.type is a function, the derivative of the loss in its first component should be provided to be used (it is not automatically 
computed).</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="FTRL_+3A_w0">w0</code></td>
<td>
<p><code>numeric</code> (NULL). Vector of initialization for the weights.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_max_iter">max_iter</code></td>
<td>
<p><code>integer</code> (50). Maximum number of iterations of the optimization algorithm per round.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_obj_tol">obj_tol</code></td>
<td>
<p><code>numeric</code> (1e-2). Tolerance over objective function between two iterations of the optimization.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_training">training</code></td>
<td>
<p><code>list</code> (NULL). List of previous parameters.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_default">default</code></td>
<td>
<p><code>boolean</code> (FALSE). Whether or not to use default parameters for fun_reg, constr_eq, constr_ineq and their grad/jac, 
which values are ALL ignored when TRUE.</p>
</td></tr>
<tr><td><code id="FTRL_+3A_quiet">quiet</code></td>
<td>
<p><code>boolean</code> (FALSE). Whether or not to display progress bars.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class mixture.
</p>


<h3>References</h3>

<p>Hazan E (2019).
&ldquo;Introduction to online convex optimization.&rdquo;
<em>arXiv preprint arXiv:1909.05207</em>.<br /><br /> Shalev-Shwartz S, Singer Y (2007).
&ldquo;A primal-dual perspective of online learning algorithms.&rdquo;
<em>Machine Learning</em>, <b>69</b>(2), 115&ndash;142.
</p>

<hr>
<h2 id='loss'>Errors suffered by a sequence of predictions</h2><span id='topic+loss'></span>

<h3>Description</h3>

<p>The
function <code>loss</code> computes the sequence of instantaneous losses suffered
by the predictions in <code>x</code> to predict the observation in <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss(
  x,
  y,
  pred = NULL,
  loss.type = list(name = "square"),
  loss.gradient = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_+3A_x">x</code></td>
<td>
<p><code>numeric</code>. A vector of length <code>T</code> containing the sequence of prediction to be evaluated.</p>
</td></tr>
<tr><td><code id="loss_+3A_y">y</code></td>
<td>
<p><code>numeric</code>. A vector of length <code>T</code> that contains the observations to be predicted.</p>
</td></tr>
<tr><td><code id="loss_+3A_pred">pred</code></td>
<td>
<p><code>numeric</code>. A vector of length <code>T</code> containing the sequence of real values.</p>
</td></tr>
<tr><td><code id="loss_+3A_loss.type">loss.type</code></td>
<td>
<p><code>character, list or function</code> (&quot;square&quot;).
</p>

<ul>
<li><p>character Name of the loss to be applied ('square', 'absolute', 'percentage', or 'pinball');
</p>
</li>
<li><p>list List with field <code>name</code> equal to the loss name. If using pinball loss, field <code>tau</code> 
equal to the required quantile in [0,1];
</p>
</li>
<li><p>function A custom loss as a function of two parameters.
</p>
</li></ul>
</td></tr>
<tr><td><code id="loss_+3A_loss.gradient">loss.gradient</code></td>
<td>
<p><code>boolean, function</code> (TRUE). 
</p>

<ul>
<li><p>boolean If TRUE, the aggregation rule will not be directly applied to the loss function at hand,
but to a gradient version of it. The aggregation rule is then similar to gradient descent aggregation rule. 
</p>
</li>
<li><p>function If loss.type is a function, the derivative should be provided to be used (it is not automatically 
computed).
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>T</code> containing the sequence of
instantaneous losses suffered by the expert previsions (x) or the gradient computed on the aggregated previsions (pred).
</p>


<h3>Author(s)</h3>

<p>Pierre Gaillard &lt;pierre@gaillard.me&gt;
</p>

<hr>
<h2 id='mixture'>Compute an aggregation rule</h2><span id='topic+mixture'></span><span id='topic+print.mixture'></span><span id='topic+summary.mixture'></span>

<h3>Description</h3>

<p>The function <code>mixture</code> builds an
aggregation rule chosen by the user. 
It can then be used to predict new observations Y sequentially.
If observations <code>Y</code> and expert advice <code>experts</code> are provided, 
<code>mixture</code> is trained by predicting the observations in <code>Y</code>
sequentially with the help of the expert advice in <code>experts</code>.  
At each time instance <code class="reqn">t=1,2,\dots,T</code>, the mixture forms a prediction of <code>Y[t,]</code> by assigning 
a weight to each expert and by combining the expert advice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixture(
  Y = NULL,
  experts = NULL,
  model = "MLpol",
  loss.type = "square",
  loss.gradient = TRUE,
  coefficients = "Uniform",
  awake = NULL,
  parameters = list(),
  use_cpp = getOption("opera_use_cpp", default = FALSE),
  quiet = TRUE
)

## S3 method for class 'mixture'
print(x, ...)

## S3 method for class 'mixture'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixture_+3A_y">Y</code></td>
<td>
<p>A matrix with T rows and d columns. Each row <code>Y[t,]</code> contains a d-dimensional 
observation to be predicted sequentially.</p>
</td></tr>
<tr><td><code id="mixture_+3A_experts">experts</code></td>
<td>
<p>An array of dimension <code>c(T,d,K)</code>, where <code>T</code> is the length of the data-set, 
<code>d</code> the dimension of the observations, and <code>K</code> is the number of experts. It contains the expert
forecasts. Each vector <code>experts[t,,k]</code> corresponds to the d-dimensional prediction of <code>Y[t,]</code> 
proposed by expert k at time <code class="reqn">t=1,\dots,T</code>.
In the case of real prediction (i.e., <code class="reqn">d = 1</code>), <code>experts</code> is a matrix with <code>T</code> rows and <code>K</code> columns.</p>
</td></tr>
<tr><td><code id="mixture_+3A_model">model</code></td>
<td>
<p>A character string specifying the aggregation rule to use. 
Currently available aggregation rules are:
</p>

<dl>
<dt>'EWA'</dt><dd><p>Exponentially weighted average aggregation rules (Cesa-Bianchi and Lugosi 2006). A positive learning rate <strong>eta</strong> 
can be chosen by the user. The
bigger it is the faster the aggregation rule will learn from observations
and experts performances. However, too high values lead to unstable weight
vectors and thus unstable predictions. If it is not specified, the learning rate is calibrated online. 
A finite grid of potential learning rates to be optimized online can be specified with <strong>grid.eta</strong>.</p>
</dd>
<dt>'FS'</dt><dd><p>Fixed-share aggregation rule (Cesa-Bianchi and Lugosi 2006). As for <code>ewa</code>, a learning rate <strong>eta</strong> 
can be chosen by the user or calibrated online. The main difference with <code>ewa</code> aggregation
rule rely in the mixing rate <strong>alpha</strong><code class="reqn">\in [0,1]</code> which considers at
each instance a small probability <code>alpha</code> to have a rupture in the
sequence and that the best expert may change. Fixed-share aggregation rule
can thus compete with the best sequence of experts that can change a few
times (see <code><a href="#topic+oracle">oracle</a></code>), while <code>ewa</code> can only
compete with the best fixed expert. The mixing rate <strong>alpha</strong> is either chosen by the user either calibrated online.
Finite grids of learning rates and mixing rates to be optimized can be specified with 
parameters <strong>grid.eta</strong> and <strong>grid.alpha</strong>.</p>
</dd>
<dt>'Ridge'</dt><dd><p>Online Ridge regression (Cesa-Bianchi and Lugosi 2006). It minimizes at
each instance a penalized criterion.  It forms at each instance linear
combination of the experts' forecasts and can assign negative weights that
not necessarily sum to one.  It is useful if the experts are biased or
correlated. It cannot be used with specialized experts. A positive regularization coefficient <strong>lambda</strong> 
can either be chosen by the user or calibrated online. 
A finite grid of coefficient to be optimized can be specified with a parameter <strong>grid.lambda</strong>.</p>
</dd>
<dt>'MLpol', 'MLewa', 'MLprod'</dt><dd><p>Aggregation rules with multiple learning rates that are
theoretically calibrated (Gaillard et al. 2014). </p>
</dd>
<dt>'BOA'</dt><dd><p>Bernstein online Aggregation (Wintenberger 2017). 
The learning rates are automatically calibrated.</p>
</dd>
<dt>'OGD'</dt><dd><p>Online Gradient descent (Zinkevich 2003). See also (Hazan 2019). The optimization is performed with a time-varying learning rate. 
At time step <code class="reqn">t \geq 1</code>, the learning rate is chosen to be <code class="reqn">t^{-\alpha}</code>, where <code class="reqn">\alpha</code> is provided by alpha in the parameters argument.
The algorithm may or not perform a projection step into the simplex space (non-negative weights that sum to one) according to
the value of the parameter 'simplex' provided by the user.</p>
</dd>
<dt>'FTRL'</dt><dd><p>Follow The Regularized Leader (Shalev-Shwartz and Singer 2007). 
Note that here, the linearized version of FTRL is implemented  (see Chap. 5 of (Hazan 2019)).
<code><a href="#topic+FTRL">FTRL</a></code> is the online counterpart of empirical risk minimization. It is a family of aggregation rules (including OGD) that uses at any time the empirical risk
minimizer so far with an additional regularization. The online optimization can be performed
on any bounded convex set that can be expressed with equality or inequality constraints.  Note that this method is still under development and a beta version.
</p>
<p>The user must provide (in the <strong>parameters</strong>'s list):
</p>

<ul>
<li><p>'eta' The learning rate.
</p>
</li>
<li><p>'fun_reg' The regularization function to be applied on the weigths. See <code><a href="alabama.html#topic+auglag">auglag</a></code>: fn.
</p>
</li>
<li><p>'constr_eq' The equality constraints (e.g. sum(w) = 1). See <code><a href="alabama.html#topic+auglag">auglag</a></code>: heq.
</p>
</li>
<li><p>'constr_ineq' The inequality constraints (e.g. w &gt; 0). See <code><a href="alabama.html#topic+auglag">auglag</a></code>: hin.
</p>
</li>
<li><p>'fun_reg_grad' (optional) The gradient of the regularization function. See <code><a href="alabama.html#topic+auglag">auglag</a></code>: gr.
</p>
</li>
<li><p>'constr_eq_jac' (optional) The Jacobian of the equality constraints. See <code><a href="alabama.html#topic+auglag">auglag</a></code>: heq.jac
</p>
</li>
<li><p>'constr_ineq_jac' (optional) The Jacobian of the inequality constraints. See <code><a href="alabama.html#topic+auglag">auglag</a></code>: hin.jac
</p>
</li></ul>
<p> or set <strong>default</strong> to TRUE. In the latter, <a href="#topic+FTRL">FTRL</a> is performed with Kullback regularization (<code>fun_reg(x) = sum(x log (x/w0))</code>
on the simplex (<code>constr_eq(w) = sum(w) - 1</code> and <code>constr_ineq(w) = w</code>). 
Parameters <strong>w0</strong> (weight initialization), and <strong>max_iter</strong> can also be provided.
</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mixture_+3A_loss.type">loss.type</code></td>
<td>
<p><code>character, list, or function</code> (&quot;square&quot;).
</p>

<dl>
<dt>character</dt><dd><p> Name of the loss to be applied ('square', 'absolute', 'percentage', or 'pinball');</p>
</dd>
<dt>list</dt><dd><p> List with field <code>name</code> equal to the loss name. If using pinball loss, field <code>tau</code> equal to the required quantile in [0,1];</p>
</dd>
<dt>function</dt><dd><p> A custom loss as a function of two parameters (prediction, observation). 
For example, $f(x,y) = abs(x-y)/y$ for the Mean absolute percentage error or $f(x,y) = (x-y)^2$ for the squared loss.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mixture_+3A_loss.gradient">loss.gradient</code></td>
<td>
<p><code>boolean, function</code> (TRUE). 
</p>

<dl>
<dt>boolean</dt><dd><p> If TRUE, the aggregation rule will not be directly applied to the loss function at hand,
but to a gradient version of it. The aggregation rule is then similar to gradient descent aggregation rule. </p>
</dd>
<dt>function</dt><dd><p>Can be provided if loss.type is a function. It should then be
a sub-derivative of the loss in its first component (i.e., in the prediction).
For instance, $g(x) = (x-y)$ for the squared loss. 
</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mixture_+3A_coefficients">coefficients</code></td>
<td>
<p>A probability vector of length K containing the prior weights of the experts
(not possible for 'MLpol'). The weights must be non-negative and sum to 1.</p>
</td></tr>
<tr><td><code id="mixture_+3A_awake">awake</code></td>
<td>
<p>A matrix specifying the
activation coefficients of the experts. Its entries lie in <code>[0,1]</code>.
Possible if some experts are specialists and do not always form and suggest
prediction. If the expert number <code>k</code> at instance <code>t</code> does not
form any prediction of observation <code>Y_t</code>, we can put
<code>awake[t,k]=0</code> so that the mixture does not consider expert <code>k</code> in
the mixture to predict <code>Y_t</code>.</p>
</td></tr>
<tr><td><code id="mixture_+3A_parameters">parameters</code></td>
<td>
<p>A list that contains optional parameters for the aggregation rule. 
If no parameters are provided, the aggregation rule is fully calibrated
online. Possible parameters are:
</p>

<dl>
<dt>eta</dt><dd><p>A positive number defining the learning rate. 
Possible if model is either 'EWA' or 'FS'</p>
</dd>
<dt>grid.eta</dt><dd><p>A vector of positive numbers defining potential learning rates 
for 'EWA' of 'FS'.
The learning rate is then calibrated by sequentially optimizing the parameter in 
the grid. The grid may be extended online if needed by the aggregation rule.</p>
</dd>
<dt>gamma</dt><dd><p>A positive number defining the exponential step of extension 
of grid.eta when it is needed. The default value is 2.</p>
</dd>
<dt>alpha</dt><dd><p>A number in [0,1]. If the model is 'FS', it defines the mixing rate. 
If the model is 'OGD', it defines the order of the learning rate: <code class="reqn">\eta_t = t^{-\alpha}</code>.</p>
</dd>
<dt>grid.alpha</dt><dd><p>A vector of numbers in [0,1] defining potential mixing rates for 'FS'
to be optimized online. The grid is fixed over time. The default value is <code>[0.0001,0.001,0.01,0.1]</code>.</p>
</dd>
<dt>lambda</dt><dd><p>A positive number defining the smoothing parameter of 'Ridge' aggregation rule.</p>
</dd>
<dt>grid.lambda</dt><dd><p>Similar to <code>grid.eta</code> for the parameter <code>lambda</code>.</p>
</dd>
<dt>simplex</dt><dd><p>A boolean that specifies if 'OGD' does a project on the simplex. In other words,
if TRUE (default) the online gradient descent will be under the constraint that the weights sum to 1
and are non-negative. If FALSE, 'OGD' performs an online gradient descent on K dimensional real space.
without any projection step.</p>
</dd>
<dt>averaged</dt><dd><p>A boolean (default is FALSE). If TRUE the coefficients and the weights 
returned (and used to form the predictions) are averaged over the past. It leads to more stability on the time evolution of the weights but needs
more regularity assumption on the underlying process generating the data (i.i.d. for instance). </p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mixture_+3A_use_cpp">use_cpp</code></td>
<td>
<p><code>boolean</code>. Whether or not to use cpp optimization to fasten the computations. This option is not yet compatible
with the use of custom loss function. Note that cpp implementation corresponds to an earlier version of the code and may be outdated. 
Use <code>options(opera_use_cpp = TRUE)</code> to change the default value.</p>
</td></tr>
<tr><td><code id="mixture_+3A_quiet">quiet</code></td>
<td>
<p><code>boolean</code>. Whether or not to display progress bars.</p>
</td></tr>
<tr><td><code id="mixture_+3A_x">x</code></td>
<td>
<p>An object of class mixture</p>
</td></tr>
<tr><td><code id="mixture_+3A_...">...</code></td>
<td>
<p>Additional parameters</p>
</td></tr>
<tr><td><code id="mixture_+3A_object">object</code></td>
<td>
<p>An object of class mixture</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class mixture that can be used to perform new predictions. 
It contains the parameters <code>model</code>, <code>loss.type</code>, <code>loss.gradient</code>,
<code>experts</code>, <code>Y</code>, <code>awake</code>, and the fields
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>A vector of coefficients 
assigned to each expert to perform the next prediction.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p> A matrix of dimension <code>c(T,K)</code>, with
<code>T</code> the number of instances to be predicted and <code>K</code> the number of
experts.  Each row contains the convex combination to form the predictions </p>
</td></tr>
<tr><td><code>prediction</code></td>
<td>
<p> A matrix with <code>T</code> rows and <code>d</code> columns that contains the
predictions outputted by the aggregation rule.  </p>
</td></tr> 
<tr><td><code>loss</code></td>
<td>
<p> The average loss (as stated by parameter <code>loss.type</code>) suffered
by the aggregation rule.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>The learning parameters chosen by the aggregation rule or by the user.</p>
</td></tr>
<tr><td><code>training</code></td>
<td>
<p>A list that contains useful temporary information of the 
aggregation rule to be updated and to perform predictions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pierre Gaillard &lt;pierre@gaillard.me&gt; Yannig Goude &lt;yannig.goude@edf.fr&gt;
</p>


<h3>References</h3>

<p>Cesa-Bianchi N, Lugosi G (2006).
<em>Prediction, learning, and games</em>.
Cambridge university press.<br /><br /> Gaillard P, Stoltz G, van Erven T (2014).
&ldquo;A Second-order Bound with Excess Losses.&rdquo;
In <em>Proceedings of COLT'14</em>, volume 35, 176&ndash;196.<br /><br /> Hazan E (2019).
&ldquo;Introduction to online convex optimization.&rdquo;
<em>arXiv preprint arXiv:1909.05207</em>.<br /><br /> Shalev-Shwartz S, Singer Y (2007).
&ldquo;A primal-dual perspective of online learning algorithms.&rdquo;
<em>Machine Learning</em>, <b>69</b>(2), 115&ndash;142.<br /><br /> Wintenberger O (2017).
&ldquo;Optimal learning with Bernstein online aggregation.&rdquo;
<em>Machine Learning</em>, <b>106</b>(1), 119&ndash;141.<br /><br /> Zinkevich M (2003).
&ldquo;Online convex programming and generalized infinitesimal gradient ascent.&rdquo;
In <em>Proceedings of the 20th international conference on machine learning (icml-03)</em>, 928&ndash;936.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+opera-package">opera-package</a></code> and opera-vignette for a brief example about how to use the package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('opera')  # load the package
set.seed(1)

# Example: find the best one week ahead forecasting strategy (weekly data)
# packages
library(mgcv)

# import data
data(electric_load)
idx_data_test &lt;- 620:nrow(electric_load)
data_train &lt;- electric_load[-idx_data_test, ]
data_test &lt;- electric_load[idx_data_test, ]

# Build the expert forecasts 
# ##########################

# 1) A generalized additive model
gam.fit &lt;- gam(Load ~ s(IPI) + s(Temp) + s(Time, k=3) + 
                 s(Load1) + as.factor(NumWeek), data = data_train)
gam.forecast &lt;- predict(gam.fit, newdata = data_test)

# 2) An online autoregressive model on the residuals of a medium term model

# Medium term model to remove trend and seasonality (using generalized additive model)
detrend.fit &lt;- gam(Load ~ s(Time,k=3) + s(NumWeek) + s(Temp) + s(IPI), data = data_train)
electric_load$Trend &lt;- c(predict(detrend.fit), predict(detrend.fit,newdata = data_test))
electric_load$Load.detrend &lt;- electric_load$Load - electric_load$Trend

# Residual analysis
ar.forecast &lt;- numeric(length(idx_data_test))
for (i in seq(idx_data_test)) {
  ar.fit &lt;- ar(electric_load$Load.detrend[1:(idx_data_test[i] - 1)])
  ar.forecast[i] &lt;- as.numeric(predict(ar.fit)$pred) + electric_load$Trend[idx_data_test[i]]
}

# Aggregation of experts
###########################

X &lt;- cbind(gam.forecast, ar.forecast)
colnames(X) &lt;- c('gam', 'ar')
Y &lt;- data_test$Load

matplot(cbind(Y, X), type = 'l', col = 1:6, ylab = 'Weekly load', xlab = 'Week')


# How good are the expert? Look at the oracles
oracle.convex &lt;- oracle(Y = Y, experts = X, loss.type = 'square', model = 'convex')

if(interactive()){
  plot(oracle.convex)
}

oracle.convex

# Is a single expert the best over time ? Are there breaks ?
oracle.shift &lt;- oracle(Y = Y, experts = X, loss.type = 'percentage', model = 'shifting')
if(interactive()){
  plot(oracle.shift)
}
oracle.shift

# Online aggregation of the experts with BOA
#############################################

# Initialize the aggregation rule
m0.BOA &lt;- mixture(model = 'BOA', loss.type = 'square')

# Perform online prediction using BOA There are 3 equivalent possibilities 1)
# start with an empty model and update the model sequentially
m1.BOA &lt;- m0.BOA
for (i in 1:length(Y)) {
  m1.BOA &lt;- predict(m1.BOA, newexperts = X[i, ], newY = Y[i], quiet = TRUE)
}

# 2) perform online prediction directly from the empty model
m2.BOA &lt;- predict(m0.BOA, newexpert = X, newY = Y, online = TRUE, quiet = TRUE)

# 3) perform the online aggregation directly
m3.BOA &lt;- mixture(Y = Y, experts = X, model = 'BOA', loss.type = 'square', quiet = TRUE)

# These predictions are equivalent:
identical(m1.BOA, m2.BOA)  # TRUE
identical(m1.BOA, m3.BOA)  # TRUE

# Display the results
summary(m3.BOA)
if(interactive()){
  plot(m1.BOA)
}

# Using d-dimensional time-series
##################################

# Consider the above exemple of electricity consumption 
#  to be predicted every four weeks
YBlock &lt;- seriesToBlock(X = Y, d = 4)
XBlock &lt;- seriesToBlock(X = X, d = 4)

# The four-week-by-four-week predictions can then be obtained 
# by directly using the `mixture` function as we did earlier. 

MLpolBlock &lt;- mixture(Y = YBlock, experts = XBlock, model = "MLpol", loss.type = "square", 
                      quiet = TRUE)


# The predictions can finally be transformed back to a 
# regular one dimensional time-series by using the function `blockToSeries`.

prediction &lt;- blockToSeries(MLpolBlock$prediction)

#### Using the `online = FALSE` option

# Equivalent solution is to use the `online = FALSE` option in the predict function. 
# The latter ensures that the model coefficients are not 
# updated between the next four weeks to forecast.
MLpolBlock &lt;- mixture(model = "BOA", loss.type = "square")
d = 4
n &lt;- length(Y)/d
for (i in 0:(n-1)) { 
  idx &lt;- 4*i + 1:4 # next four weeks to be predicted
  MLpolBlock &lt;- predict(MLpolBlock, newexperts = X[idx, ], newY = Y[idx], online = FALSE, 
                        quiet = TRUE)
}

print(head(MLpolBlock$weights))

</code></pre>

<hr>
<h2 id='oracle'>Compute oracle predictions</h2><span id='topic+oracle'></span>

<h3>Description</h3>

<p>The function <code>oracle</code> performs a strategie that cannot be defined online
(in contrast to <a href="#topic+mixture">mixture</a>). It requires in advance the knowledge of the whole
data set <code>Y</code> and the expert advice to be well defined.
Examples of oracles are the best fixed expert, the best fixed convex
combination rule, the best linear combination rule, or the best expert
that can shift a few times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oracle(
  Y,
  experts,
  model = "convex",
  loss.type = "square",
  awake = NULL,
  lambda = NULL,
  niter = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oracle_+3A_y">Y</code></td>
<td>
<p>A vector containing the observations
to be predicted.</p>
</td></tr>
<tr><td><code id="oracle_+3A_experts">experts</code></td>
<td>
<p>A matrix containing the experts
forecasts. Each column corresponds to the predictions proposed by an expert
to predict <code>Y</code>.  It has as many columns as there are experts.</p>
</td></tr>
<tr><td><code id="oracle_+3A_model">model</code></td>
<td>
<p>A character string specifying the oracle to use or a list with a component <code>name</code> specifying the oracle and any additional parameter needed.
Currently available oracles are:
</p>

<dl>
<dt>'expert'</dt><dd><p>The best fixed (constant over time) expert oracle.</p>
</dd>
<dt>'convex'</dt><dd><p>The best fixed convex combination (vector of non-negative weights that sum to 1)</p>
</dd>
<dt>'linear'</dt><dd><p>The best fixed linear combination of expert</p>
</dd>
<dt>'shifting'</dt><dd><p>It computes for all number $m$ of stwitches the
sequence of experts with at most $m$ shifts that would have performed the
best to predict the sequence of observations in <code>Y</code>.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="oracle_+3A_loss.type">loss.type</code></td>
<td>
<p><code>character, list or function</code>. 
</p>

<dl>
<dt>character</dt><dd><p> Name of the loss to be applied ('square', 'absolute', 'percentage', or 'pinball');</p>
</dd>
<dt>list</dt><dd><p> When using pinball loss: list with field name equal to 'pinball' and field tau equal to the required quantile in [0,1];</p>
</dd>
<dt>function</dt><dd><p> A custom loss as a function of two parameters.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="oracle_+3A_awake">awake</code></td>
<td>
<p>A matrix specifying the
activation coefficients of the experts. Its entries lie in <code>[0,1]</code>.
Possible if some experts are specialists and do not always form and suggest
prediction. If the expert number <code>k</code> at instance <code>t</code> does not
form any prediction of observation <code>Y_t</code>, we can put
<code>awake[t,k]=0</code> so that the mixture does not consider expert <code>k</code> in
the mixture to predict <code>Y_t</code>. Remark that to compute the best expert oracle, 
the performance of unactive (or partially active) experts is computed by using 
the prediction of the uniform average of active experts.</p>
</td></tr>
<tr><td><code id="oracle_+3A_lambda">lambda</code></td>
<td>
<p>A positive number used by the 'linear' oracle only. 
A possible $L_2$ regularization parameter for computing the linear oracle 
(if the design matrix is not identifiable)</p>
</td></tr>
<tr><td><code id="oracle_+3A_niter">niter</code></td>
<td>
<p>A positive integer for 'convex' and 'linear' oracles 
if direct computation of the oracle is not implemented. 
It defines the number of optimization steps to perform in 
order to approximate the oracle (default value is 3).</p>
</td></tr>
<tr><td><code id="oracle_+3A_...">...</code></td>
<td>
<p>Additional parameters
that are passed to <code><a href="stats.html#topic+optim">optim</a></code> function is order to perform convex optimization 
(see parameter <code>niter</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class 'oracle' that contains:
</p>
<table>
<tr><td><code>loss</code></td>
<td>
<p> The average loss suffered by the oracle. For the 'shifting' oracle,
it is a vector of length <code>T</code> where
<code>T</code> is the number of instance to be predicted (i.e., the length of the
sequence <code>Y</code>). The value of $loss(m)$ is the loss
(determined by the parameter <code>loss.type</code>) suffered by the
best sequence of expert with at
most $m-1$ shifts.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p> Not for the 'shifting' oracle. A vector containing the best weight vector corresponding to the oracle. </p>
</td></tr>
<tr><td><code>prediction</code></td>
<td>
<p> Not for the 'shifting' oracle. A vector containing the
predictions of the oracle.  </p>
</td></tr>
<tr><td><code>rmse</code></td>
<td>
<p>If loss.type is the square loss (default) only.
The root mean square error (i.e., it is the square root of <code>loss</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pierre Gaillard &lt;pierre@gaillard.me&gt;
</p>

<hr>
<h2 id='plot_ridge_weights'>Functions to render dynamic mixture graphs using rAmCharts</h2><span id='topic+plot_ridge_weights'></span><span id='topic+plot_weights'></span><span id='topic+boxplot_weights'></span><span id='topic+plot_dyn_avg_loss'></span><span id='topic+plot_cumul_res'></span><span id='topic+plot_avg_loss'></span><span id='topic+plot_contrib'></span>

<h3>Description</h3>

<p>Functions to render dynamic mixture graphs using rAmCharts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_ridge_weights(data, colors = NULL, max_experts = 50, round = 3)

plot_weights(data, colors = NULL, max_experts = 50, round = 3)

boxplot_weights(data, colors = NULL, max_experts = 50)

plot_dyn_avg_loss(data, colors = NULL, max_experts = 50, round = 3)

plot_cumul_res(data, colors = NULL, max_experts = 50, round = 3)

plot_avg_loss(data, colors = NULL, max_experts = 50, round = 3)

plot_contrib(data, colors = NULL, alpha = 0.1, max_experts = 50, round = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_ridge_weights_+3A_data">data</code></td>
<td>
<p><code>mixture object</code>. Displays graphs.</p>
</td></tr>
<tr><td><code id="plot_ridge_weights_+3A_colors">colors</code></td>
<td>
<p><code>character</code>. Colors of the lines and bullets.</p>
</td></tr>
<tr><td><code id="plot_ridge_weights_+3A_max_experts">max_experts</code></td>
<td>
<p><code>integer</code>. Maximum number of experts to be displayed (only the more influencial).</p>
</td></tr>
<tr><td><code id="plot_ridge_weights_+3A_round">round</code></td>
<td>
<p><code>integer</code>. Precision of the displayed values.</p>
</td></tr>
<tr><td><code id="plot_ridge_weights_+3A_alpha">alpha</code></td>
<td>
<p><code>numeric</code>. Smoothing parameter for contribution plot (parameter 'f' of function <code><a href="stats.html#topic+lowess">lowess</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>rAmCharts</code> plot
</p>

<hr>
<h2 id='plot.mixture'>Plot an object of class mixture</h2><span id='topic+plot.mixture'></span>

<h3>Description</h3>

<p>provides different diagnostic plots for an aggregation procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixture'
plot(
  x,
  pause = FALSE,
  col = NULL,
  alpha = 0.01,
  dynamic = T,
  type = "all",
  max_experts = 50,
  col_by_weight = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mixture_+3A_x">x</code></td>
<td>
<p>an object of class mixture. If awake is provided (i.e., some experts are unactive), 
their residuals and cumulative losses are computed by using the predictions of the mixture.</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_pause">pause</code></td>
<td>
<p>if set to TRUE (default) displays the plots separately, otherwise on a single page</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_col">col</code></td>
<td>
<p>the color to use to represent each experts, if set to NULL (default) use R<code>RColorBrewer::brewer.pal(...,"Spectral"</code></p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_alpha">alpha</code></td>
<td>
<p><code>numeric</code>. Smoothing parameter for contribution plot (parameter 'f' of function <code><a href="stats.html#topic+lowess">lowess</a></code>).</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_dynamic">dynamic</code></td>
<td>
<p><code>boolean</code>. If TRUE, graphs are generated with <code>rAmCharts</code>, else with base R.</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_type">type</code></td>
<td>
<p><code>char</code>.
</p>

<ul>
<li><p>'all' Display all the graphs ;
</p>
</li>
<li><p>'plot_weight', 'boxplot_weight', 'dyn_avg_loss', 'cumul_res', 'avg_loss', 'contrib' Display the selected graph alone.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.mixture_+3A_max_experts">max_experts</code></td>
<td>
<p><code>integer</code>. Maximum number of experts to be displayed (only the more influencial).</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_col_by_weight">col_by_weight</code></td>
<td>
<p><code>boolean</code>. If TRUE (default), colors are ordered by weights of each expert, else by column</p>
</td></tr>
<tr><td><code id="plot.mixture_+3A_...">...</code></td>
<td>
<p>additional plotting parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots representing: plot of weights of each expert in function of time, boxplots of these weights,
cumulative loss <code class="reqn">L_T=\sum_{t=1}^T l_{i,t}</code> of each expert in function of time, cumulative residuals <code class="reqn">\sum_{t=1}^T (y_t-f_{i,t})</code> of each 
expert's forecast in function of time, average loss suffered by the experts and the contribution of each expert to the aggregation 
<code class="reqn">p_{i,t}f_{i,t}</code> in function of time.
</p>


<h3>Author(s)</h3>

<p>Pierre Gaillard &lt;pierre@gaillard.me&gt;
</p>
<p>Yannig  Goude &lt;yannig.goude@edf.fr&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+opera-package">opera-package</a></code> and opera-vignette for a brief example about how to use the package.
</p>

<hr>
<h2 id='plot.oracle'>Plot an aggregation procedure</h2><span id='topic+plot.oracle'></span>

<h3>Description</h3>

<p>oracle <code>plot</code>. It has one optional arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oracle'
plot(x, sort = TRUE, col = NULL, dynamic = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.oracle_+3A_x">x</code></td>
<td>
<p>An object of class <code>oracle</code>.</p>
</td></tr>
<tr><td><code id="plot.oracle_+3A_sort">sort</code></td>
<td>
<p>if set to TRUE (default), it sorts the experts by performance before the plots.</p>
</td></tr>
<tr><td><code id="plot.oracle_+3A_col">col</code></td>
<td>
<p>colors</p>
</td></tr>
<tr><td><code id="plot.oracle_+3A_dynamic">dynamic</code></td>
<td>
<p>If TRUE, graphs are generated with <code>rAmCharts</code>, else with base R.</p>
</td></tr>
<tr><td><code id="plot.oracle_+3A_...">...</code></td>
<td>
<p>additional arguments to function plot.</p>
</td></tr>
</table>

<hr>
<h2 id='plt_oracle_convex'>Functions to render dynamic oracle graphs using rAmCharts</h2><span id='topic+plt_oracle_convex'></span>

<h3>Description</h3>

<p>Functions to render dynamic oracle graphs using rAmCharts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plt_oracle_convex(data, colors, round = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plt_oracle_convex_+3A_data">data</code></td>
<td>
<p><code>named vector</code>. Vector of values to be displayed.</p>
</td></tr>
<tr><td><code id="plt_oracle_convex_+3A_colors">colors</code></td>
<td>
<p><code>character</code>. Colors to  be used.</p>
</td></tr>
<tr><td><code id="plt_oracle_convex_+3A_round">round</code></td>
<td>
<p><code>integer</code> (2). Precision of the values in the tooltips..</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a rAmCharts plot
</p>

<hr>
<h2 id='predict.mixture'>Predict method for Mixture models</h2><span id='topic+predict.mixture'></span>

<h3>Description</h3>

<p>Performs sequential predictions and updates
of a mixture object based on new observations 
and expert advice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixture'
predict(
  object,
  newexperts = NULL,
  newY = NULL,
  awake = NULL,
  online = TRUE,
  type = c("model", "response", "weights", "all"),
  use_cpp = getOption("opera_use_cpp", default = FALSE),
  quiet = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.mixture_+3A_object">object</code></td>
<td>
<p>Object of class inheriting from 'mixture'</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_newexperts">newexperts</code></td>
<td>
<p>An optional matrix in which to look for expert advice with which
predict. If omitted, the past predictions of the object are returned and the
object is not updated.</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_newy">newY</code></td>
<td>
<p>An optional matrix with d columns (or vector if <code class="reqn">d=1</code>) of observations to be predicted. If provided, it 
should have the same number of rows as the number of rows of <code>newexperts</code>.
If omitted, the object (i.e, the aggregation rule) is not updated.</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_awake">awake</code></td>
<td>
<p>An optional array specifying the
activation coefficients of the experts. It must have the same dimension as experts. Its entries lie in <code>[0,1]</code>.
Possible if some experts are specialists and do not always form and suggest
prediction. If the expert number <code>k</code> at instance <code>t</code> does not
form any prediction of observation <code>Y_t</code>, we can put
<code>awake[t,k]=0</code> so that the mixture does not consider expert <code>k</code> in
the mixture to predict <code>Y_t</code>.</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_online">online</code></td>
<td>
<p>A boolean determining if the observations in newY are predicted
sequentially (by updating the object step by step) or not. If FALSE, 
the observations are predicting using the object (without using any past 
information in newY). If TRUE, newY and newexperts should not be null.</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_type">type</code></td>
<td>
<p>Type of prediction. It can be 
</p>

<dl>
<dt>model</dt><dd><p>return the updated version of object (using newY and newexperts).</p>
</dd>
<dt>response</dt><dd><p>return the forecasts. If type is 'model', forecasts can also 
be obtained from the last values of object$prediction.</p>
</dd>
<dt>weights</dt><dd><p>return the weights assigned to the expert advice to 
produce the forecasts. If type is 'model', forecasts can also 
be obtained from the last rows of object$weights.</p>
</dd>
<dt>all</dt><dd><p>return a list containing 'model', 'response', and 'weights'.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="predict.mixture_+3A_use_cpp">use_cpp</code></td>
<td>
<p><code>boolean</code>. Whether or not to use cpp optimization to fasten the computations. This option is not yet compatible
with the use of custom loss function.</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_quiet">quiet</code></td>
<td>
<p><code>boolean</code>. Whether or not to display progress bars.</p>
</td></tr>
<tr><td><code id="predict.mixture_+3A_...">...</code></td>
<td>
<p>further arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.mixture</code> produces a matrix of predictions 
(type = 'response'), an updated object (type = 'model'), or a matrix of
weights (type = 'weights').
</p>

<hr>
<h2 id='seriesToBlock'>Convert a 1-dimensional series to blocks</h2><span id='topic+seriesToBlock'></span><span id='topic+blockToSeries'></span>

<h3>Description</h3>

<p>The functions <code>seriesToBlock</code> and <code>blockToSeries</code> convert 1-dimensional series into series of higher dimension.
For instance, suppose you have a time-series that consists of <code class="reqn">T = 100</code> days of <code class="reqn">d = 24</code> hours. 
The function seriesToBlock converts the time-series X of <code class="reqn">Td = 2400</code> observations into a matrix of size <code>c(T=100,d =24)</code>, 
where each line corresponds to a specific day. This function is usefull if you need to perform the prediction day by day, instead of hour by hour.
The function can also be used to convert a matrix of expert prediction of dimension <code>c(dT,K)</code> where K is the number of experts,
into an array of dimension <code>c(T,d,K)</code>. The new arrays of observations and of expert predictions can be
given to the aggregation rule procedure to perform <code>d</code>-dimensional predictions (i.e., day predictions).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seriesToBlock(X, d)

blockToSeries(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seriesToBlock_+3A_x">X</code></td>
<td>
<p>An array or a vector to be converted.</p>
</td></tr>
<tr><td><code id="seriesToBlock_+3A_d">d</code></td>
<td>
<p>A positive integer defining the block size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function blockToSeries performs the inverse operation.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
