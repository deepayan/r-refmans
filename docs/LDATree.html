<!DOCTYPE html><html><head><title>Help for package LDATree</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LDATree}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ldaGSVD'><p>Linear Discriminant Analysis using the Generalized Singular Value</p>
Decomposition</a></li>
<li><a href='#LDATree-package'><p>LDATree: Classification Trees with Linear Discriminant Analysis at Terminal Nodes</p></a></li>
<li><a href='#plot.Treee'><p>Plot a Treee object</p></a></li>
<li><a href='#predict.ldaGSVD'><p>Predictions from a fitted ldaGSVD object</p></a></li>
<li><a href='#predict.Treee'><p>Predictions from a fitted Treee object</p></a></li>
<li><a href='#Treee'><p>Classification trees with Linear Discriminant Analysis terminal nodes</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Classification Trees with Linear Discriminant Analysis at
Terminal Nodes</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Description:</td>
<td>A classification tree method that uses LDA (Linear
    Discriminant Analysis) for variable selection, split determination,
    and model fitting in terminal nodes.  It automatically handles missing
    values and offers visualization tools.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Moran79/LDATree">https://github.com/Moran79/LDATree</a>,
<a href="http://iamwangsiyu.com/LDATree/">http://iamwangsiyu.com/LDATree/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Moran79/LDATree/issues">https://github.com/Moran79/LDATree/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, lifecycle, magrittr, scales, stats, visNetwork</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-25 19:39:05 UTC; moran</td>
</tr>
<tr>
<td>Author:</td>
<td>Siyu Wang <a href="https://orcid.org/0009-0005-2098-7089"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre,
    aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Siyu Wang &lt;swang739@wisc.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-25 22:40:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='ldaGSVD'>Linear Discriminant Analysis using the Generalized Singular Value
Decomposition</h2><span id='topic+ldaGSVD'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Fit an LDA/GSVD model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldaGSVD(formula, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldaGSVD_+3A_formula">formula</code></td>
<td>
<p>an object of class <a href="stats.html#topic+formula">formula</a>, which has the form <code>class ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="ldaGSVD_+3A_data">data</code></td>
<td>
<p>a data frame that contains both predictors and the response.
Missing values are NOT allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Traditional Fisher's Linear Discriminant Analysis (LDA) ceases to work when
the within-class scatter matrix is singular. The Generalized Singular Value
Decomposition (GSVD) is used to address this issue. GSVD simultaneously
diagonalizes both the within-class and between-class scatter matrices without
the need to invert a singular matrix. This method is believed to be more
accurate than PCA-LDA (as in <code>MASS::lda</code>) because it also considers the
information in the between-class scatter matrix.
</p>


<h3>Value</h3>

<p>An object of class <code>ldaGSVD</code> containing the following components:
</p>

<ul>
<li> <p><code>scaling</code>: a matrix which transforms the training data to LD scores, normalized so that the within-group scatter matrix is proportional to the identity matrix.
</p>
</li>
<li> <p><code>formula</code>: the formula passed to the <code><a href="#topic+ldaGSVD">ldaGSVD()</a></code>
</p>
</li>
<li> <p><code>terms</code>: a object of class <code>terms</code> derived using the input <code>formula</code> and the training data
</p>
</li>
<li> <p><code>prior</code>: a <code>table</code> of the estimated prior probabilities.
</p>
</li>
<li> <p><code>groupMeans</code>: a matrix that records the group means of the training data on the transformed LD scores.
</p>
</li>
<li> <p><code>xlevels</code>: a list records the levels of the factor predictors, derived using the input <code>formula</code> and the training data
</p>
</li></ul>



<h3>References</h3>

<p>Ye, J., Janardan, R., Park, C. H., &amp; Park, H. (2004). <em>An
optimization criterion for generalized discriminant analysis on
undersampled problems</em>. IEEE Transactions on Pattern Analysis and Machine
Intelligence
</p>
<p>Howland, P., Jeon, M., &amp; Park, H. (2003). <em>Structure preserving dimension
reduction for clustered text data based on the generalized singular value
decomposition</em>. SIAM Journal on Matrix Analysis and Applications
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- ldaGSVD(Species~., data = iris)
# prediction
predict(fit,iris)
</code></pre>

<hr>
<h2 id='LDATree-package'>LDATree: Classification Trees with Linear Discriminant Analysis at Terminal Nodes</h2><span id='topic+LDATree'></span><span id='topic+LDATree-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>A classification tree method that uses LDA (Linear Discriminant Analysis) for variable selection, split determination, and model fitting in terminal nodes. It automatically handles missing values and offers visualization tools.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Siyu Wang <a href="mailto:swang739@wisc.edu">swang739@wisc.edu</a> (<a href="https://orcid.org/0009-0005-2098-7089">ORCID</a>) [copyright holder]
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/Moran79/LDATree">https://github.com/Moran79/LDATree</a>
</p>
</li>
<li> <p><a href="http://iamwangsiyu.com/LDATree/">http://iamwangsiyu.com/LDATree/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/Moran79/LDATree/issues">https://github.com/Moran79/LDATree/issues</a>
</p>
</li></ul>


<hr>
<h2 id='plot.Treee'>Plot a Treee object</h2><span id='topic+plot.Treee'></span>

<h3>Description</h3>

<p>Provide a diagram of the whole tree structure or a scatter/density plot for a
specific tree node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Treee'
plot(x, data, node = -1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Treee_+3A_x">x</code></td>
<td>
<p>a fitted model object of class <code>Treee</code>, which is assumed to be the
result of the <code><a href="#topic+Treee">Treee()</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.Treee_+3A_data">data</code></td>
<td>
<p>the original data you used to fit the <code>Treee</code> object if you want
the individual plot for each node. Otherwise, you can leave this parameter
blank if you only need the overall tree structure diagram.</p>
</td></tr>
<tr><td><code id="plot.Treee_+3A_node">node</code></td>
<td>
<p>the node index that you are interested in. By default, it is set
to <code>-1</code> and the overall tree structure is drawn.</p>
</td></tr>
<tr><td><code id="plot.Treee_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For overall tree structure (<code>node = -1</code>), A figure of class
<code>visNetwork</code> is drawn. Otherwise, a figure of class <code>ggplot</code> is drawn.
</p>


<h3>Overall tree structure</h3>

<p>A full tree diagram (via the R package visNetwork) is shown if <code>node</code> is
not provided (default is <code>-1</code>). The color shows the most common (plurality)
class inside each node. The size of each terminal node is based on its
relative sample size. Under every node, you see the plurality class, the
fraction of the correctly predicted training sample vs. the node's sample
size, and the node index, respectively. When you click on the node, an
information panel with more details will appear.
</p>


<h3>Individual plot for each node</h3>

<p>The node index and the original training data are required to return a more
detailed plot within a specific node. The density plot will be provided
when only two levels are left for the response variable in a node (like in
a binary classification problem). Samples are projected down to their first
linear discriminant scores (LD1). A scatter plot will be provided if a node
contains more than two classes. Samples are projected down to their first
and second linear discriminant scores.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- Treee(Species~., data = iris)
# plot the overall tree
plot(fit)
# plot a certain node
plot(fit, iris, node = 1)
</code></pre>

<hr>
<h2 id='predict.ldaGSVD'>Predictions from a fitted ldaGSVD object</h2><span id='topic+predict.ldaGSVD'></span>

<h3>Description</h3>

<p>Prediction of test data using a fitted ldaGSVD object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldaGSVD'
predict(object, newdata, type = c("response", "prob"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ldaGSVD_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>ldaGSVD</code>, which is assumed to
be the result of the <code><a href="#topic+ldaGSVD">ldaGSVD()</a></code> function.</p>
</td></tr>
<tr><td><code id="predict.ldaGSVD_+3A_newdata">newdata</code></td>
<td>
<p>data frame containing the values at which predictions are
required. Missing values are NOT allowed.</p>
</td></tr>
<tr><td><code id="predict.ldaGSVD_+3A_type">type</code></td>
<td>
<p>character string denoting the type of predicted value returned.
The default is to return the predicted class (<code>type</code> = 'response'). The
predicted posterior probabilities for each class will be returned if <code>type</code>
= 'prob'.</p>
</td></tr>
<tr><td><code id="predict.ldaGSVD_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike the original paper, which uses the k-nearest neighbor (k-NN) as the
classifier, we use a faster and more straightforward likelihood-based method.
One limitation of the traditional likelihood-based method for LDA is that it
ceases to work when there are Linear Discriminant (LD) directions with zero
variance in the within-class scatter matrix. However, when using LDA/GSVD,
all chosen LD directions possess non-zero variance in the between-class
scatter matrix. This implies that LD directions with zero variance in the
within-class scatter matrix will yield the highest Fisher's ratio. Therefore,
to get these directions higher weights, we manually adjust the zero variance
to <code>1e-15</code> for computational reasons.
</p>


<h3>Value</h3>

<p>The function returns different values based on the <code>type</code>, if
</p>

<ul>
<li> <p><code>type = 'response'</code>: vector of predicted responses.
</p>
</li>
<li> <p><code>type = 'prob'</code>: a data frame of the posterior probabilities. Each class takes a column.
</p>
</li></ul>



<h3>References</h3>

<p>Ye, J., Janardan, R., Park, C. H., &amp; Park, H. (2004). <em>An
optimization criterion for generalized discriminant analysis on
undersampled problems</em>. IEEE Transactions on Pattern Analysis and Machine
Intelligence
</p>
<p>Howland, P., Jeon, M., &amp; Park, H. (2003). <em>Structure preserving dimension
reduction for clustered text data based on the generalized singular value
decomposition</em>. SIAM Journal on Matrix Analysis and Applications
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- ldaGSVD(Species~., data = iris)
predict(fit,iris)
# output prosterior probabilities
predict(fit,iris,type = "prob")
</code></pre>

<hr>
<h2 id='predict.Treee'>Predictions from a fitted Treee object</h2><span id='topic+predict.Treee'></span>

<h3>Description</h3>

<p>Prediction of test data using a fitted Treee object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Treee'
predict(object, newdata, type = c("response", "prob", "all", "grove"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Treee_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>Treee</code>, which is assumed to be
the result of the <code><a href="#topic+Treee">Treee()</a></code> function.</p>
</td></tr>
<tr><td><code id="predict.Treee_+3A_newdata">newdata</code></td>
<td>
<p>data frame containing the values at which predictions are
required. Missing values are allowed.</p>
</td></tr>
<tr><td><code id="predict.Treee_+3A_type">type</code></td>
<td>
<p>character string denoting the type of predicted value returned.
The default is to return the predicted class (<code>type = 'response'</code>). The
predicted posterior probabilities for each class will be returned if <code>type = 'prob'</code>. <code>'all'</code> returns a data frame with predicted classes, posterior
probabilities, and the predicted node indices. If cross-validation is
carried out during the LDATree fitting, <code>'grove'</code> option is available and
will output an ensemble result from <code>k</code> LDATrees where <code>k</code> is the number of
cross-validation.</p>
</td></tr>
<tr><td><code id="predict.Treee_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns different values based on the <code>type</code>, if
</p>

<ul>
<li> <p><code>type = 'response'</code>: vector of predicted responses.
</p>
</li>
<li> <p><code>type = 'prob'</code>: a data frame of the posterior probabilities. Each class takes a column.
</p>
</li>
<li> <p><code>type = 'all'</code>: a data frame contains the predicted responses, posterior probabilities, and the predicted node indices.
</p>
</li>
<li> <p><code>type = 'grove'</code>: vector of predicted responses using
the ensemble method. Only available when cross-validation is carried out
during the tree generating process.
</p>
</li></ul>

<p>Note: for factor predictors, if it contains a level which is not used to
grow the tree, it will be converted to missing and will be imputed according
to the <code>missingMethod</code> in the fitted tree.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- Treee(Species~., data = iris)
predict(fit,iris)
# output prosterior probabilities
predict(fit,iris,type = "prob")
</code></pre>

<hr>
<h2 id='Treee'>Classification trees with Linear Discriminant Analysis terminal nodes</h2><span id='topic+Treee'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a> Fit an LDATree model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Treee(
  formula,
  data,
  missingMethod = c("meanFlag", "newLevel"),
  splitMethod = "LDscores",
  pruneMethod = "none",
  numberOfPruning = 10,
  maxTreeLevel = 4,
  minNodeSize = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Treee_+3A_formula">formula</code></td>
<td>
<p>an object of class <a href="stats.html#topic+formula">formula</a>, which has the form <code>class ~ x1 + x2 + ...</code></p>
</td></tr>
<tr><td><code id="Treee_+3A_data">data</code></td>
<td>
<p>a data frame that contains both predictors and the response.
Missing values are allowed in predictors but not in the response.</p>
</td></tr>
<tr><td><code id="Treee_+3A_missingmethod">missingMethod</code></td>
<td>
<p>Missing value solutions for numerical variables and
factor variables. <code>'mean'</code>, <code>'median'</code>, <code>'meanFlag'</code>, <code>'medianFlag'</code> are
available for numerical variables. <code>'mode'</code>, <code>'modeFlag'</code>, <code>'newLevel'</code> are
available for factor variables. The word <code>'Flag'</code> in the methods indicates
whether a missing flag is added or not. The <code>'newLevel'</code> method means that
all missing values are replaced with a new level rather than imputing them
to another existing value.</p>
</td></tr>
<tr><td><code id="Treee_+3A_splitmethod">splitMethod</code></td>
<td>
<p>the splitting rule in LDATree growing process. For now,
<code>'LDscores'</code> is the only available option.</p>
</td></tr>
<tr><td><code id="Treee_+3A_prunemethod">pruneMethod</code></td>
<td>
<p>the model selection method in the LDATree growing process,
which controls the size of the tree. By default, it's set to <code>'none'</code>,
which applies a direct stopping rule. Alternatively, <code>'CV'</code> uses the
alpha-pruning process from CART. Although <code>'CV'</code> is often more accurate, it
can be slower, especially with large datasets.</p>
</td></tr>
<tr><td><code id="Treee_+3A_numberofpruning">numberOfPruning</code></td>
<td>
<p>controls the number of cross-validation in the
pruning. It is 10 by default.</p>
</td></tr>
<tr><td><code id="Treee_+3A_maxtreelevel">maxTreeLevel</code></td>
<td>
<p>controls the largest tree size possible for either a
direct-stopping tree or a CV-pruned tree. Adding one extra level (depth)
introduces an additional layer of nodes at the bottom of the current tree.
e.g., when the maximum level is 1 (or 2), the maximum tree size is 3 (or
7).</p>
</td></tr>
<tr><td><code id="Treee_+3A_minnodesize">minNodeSize</code></td>
<td>
<p>controls the minimum node size. Think carefully before
changing this value. Setting a large number might result in early stopping
and reduced accuracy. By default, it's set to one plus the number of
classes in the response variable.</p>
</td></tr>
<tr><td><code id="Treee_+3A_verbose">verbose</code></td>
<td>
<p>a logical. If TRUE, the function provides additional
diagnostic messages or detailed output about its progress or internal
workings. Default is FALSE, where the function runs silently without
additional output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike other classification trees, LDATree integrates LDA throughout the
entire tree-growing process. Here is a breakdown of its distinctive features:
</p>

<ul>
<li><p> The tree searches for the best binary split based on sample quantiles of the first linear discriminant score.
</p>
</li>
<li><p> An LDA/GSVD model is fitted for each terminal node (For more details, refer to <code><a href="#topic+ldaGSVD">ldaGSVD()</a></code>).
</p>
</li>
<li><p> Missing values can be imputed using the mean, median, or mode, with optional missing flags available.
</p>
</li>
<li><p> By default, the tree employs a direct-stopping rule. However, cross-validation using the alpha-pruning from CART is also provided.
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>Treee</code> containing the following components:
</p>

<ul>
<li> <p><code>formula</code>: the formula passed to the <code><a href="#topic+Treee">Treee()</a></code>
</p>
</li>
<li> <p><code>treee</code>: a list of all the tree nodes, and each node is an object of class <code>TreeeNode</code>.
</p>
</li>
<li> <p><code>missingMethod</code>: the missingMethod passed to the <code><a href="#topic+Treee">Treee()</a></code>
</p>
<p>An object of class <code>TreeeNode</code> containing the following components:
</p>
</li>
<li> <p><code>currentIndex</code>: the node index of the current node
</p>
</li>
<li> <p><code>currentLevel</code>: the level of the current node in the tree
</p>
</li>
<li> <p><code>idxRow</code>, <code>idxCol</code>: the row and column indices showing which portion of data is used in the current node
</p>
</li>
<li> <p><code>currentLoss</code>: the training error (number of misclassified sample) of the current node
</p>
</li>
<li> <p><code>accuracy</code>: the training accuracy of the current node
</p>
</li>
<li> <p><code>proportions</code>: shows the observed frequency for each class
</p>
</li>
<li> <p><code>parent</code>: the node index of its parent
</p>
</li>
<li> <p><code>children</code>: the node indices of its direct children (not including its children's children)
</p>
</li>
<li> <p><code>misReference</code>: a data frame, serves as the reference for missing value imputation
</p>
</li>
<li> <p><code>splitCut</code>: the cut point of the split
</p>
</li>
<li> <p><code>nodeModel</code>: one of <code>'mode'</code> or <code>'LDA'</code>. It shows the type of predictive model fitted in the current node
</p>
</li>
<li> <p><code>nodePredict</code>: the fitted predictive model in the current node. It is an object of class <code>ldaGSVD</code> if LDA is fitted. If <code>nodeModel = 'mode'</code>, then it is a vector of length one, showing the plurality class.
</p>
</li>
<li> <p><code>offsprings</code>: (available only if <code>pruneMethod = 'CV'</code>) showing all terminal descendant nodes of the current node
</p>
</li>
<li> <p><code>offspringLoss</code>: (available only if <code>pruneMethod = 'CV'</code>) sum of the <code>currentLoss</code> of the <code>offsprings</code> of the current node
</p>
</li>
<li> <p><code>alpha</code>: (available only if <code>pruneMethod = 'CV'</code>) the alpha in alpha-pruning from CART
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- Treee(Species~., data = iris)
# Use cross-validation to prune the tree
fitCV &lt;- Treee(Species~., data = iris, pruneMethod = "CV")
# prediction
predict(fit,iris)
# plot the overall tree
plot(fit)
# plot a certain node
plot(fit, iris, node = 1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
