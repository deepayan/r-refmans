<!DOCTYPE html><html lang="en"><head><title>Help for package qualV</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {qualV}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#qualV-package'><p>Qualitative Validation Methods</p></a></li>
<li><a href='#compareME'><p>Compute Several Deviance Measures for Comparison</p></a></li>
<li><a href='#EF'><p>Efficiency Factor as Suggested by Nash and Sutcliffe</p></a></li>
<li><a href='#features'><p>Qualitative Features of Time Series</p></a></li>
<li><a href='#GRI'><p>Geometric Reliability Index as Suggested by Leggett and Williams (1981)</p></a></li>
<li><a href='#LCS'><p>Algorithm for the Longest Common Subsequence Problem</p></a></li>
<li><a href='#phyto'><p>Observed and Predicted Data of Phytoplankton</p></a></li>
<li><a href='#quantV'><p>Quantitative Validation Methods</p></a></li>
<li><a href='#qvalLCS'><p>Qualitative Validation by Means of Interval Sequences and LCS</p></a></li>
<li><a href='#timetrans'><p>Bijective Transformations of Time</p></a></li>
<li><a href='#timeTransME'><p>Transformation of Time to Match Two Time Series</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Qualitative Validation Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3-5</td>
</tr>
<tr>
<td>Author:</td>
<td>K. Gerald van den Boogaart
    <a href="https://orcid.org/0000-0003-4646-943X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, ths],
  Stefanie Rost [aut],
  Thomas Petzoldt <a href="https://orcid.org/0000-0002-4951-6468"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ths, cre]</td>
</tr>
<tr>
<td>Description:</td>
<td>Qualitative methods for the validation of dynamic models.
    It contains (i) an orthogonal set of deviance measures for absolute,
    relative and ordinal scale and (ii) approaches accounting for time
    shifts. The first approach transforms time to take time delays and speed
    differences into account. The second divides the time series into
    interval units according to their main features and finds the longest
    common subsequence (LCS) using a dynamic programming algorithm.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Petzoldt &lt;thomas.petzoldt@tu-dresden.de&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.0.0), KernSmooth</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, utils</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://qualV.R-Forge.R-Project.org/">http://qualV.R-Forge.R-Project.org/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-02 15:22:20 UTC; thpe</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-02 16:00:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='qualV-package'>Qualitative Validation Methods</h2><span id='topic+qualV-package'></span><span id='topic+qualV'></span>

<h3>Description</h3>

<p>Qualitative methods for model validation.</p>


<h3>Details</h3>

<p>This package contains functions for a qualitative model comparison.
Common quantitative deviance measures underestimate the
similarity of patterns if there are shifts in time between measurement
and simulation. Qualitative validation methods are additional methods
to validate models, especially useful to compare the patterns of observed and
simulated values.
<br /><br />
For a complete list of functions with individual help pages, use
<code>library(help="qualV")</code>.
</p>


<h3>References</h3>

<p>Jachner, S., van den Boogaart, K.G. and Petzoldt, T. (2007) Statistical
methods for the qualitative assessment of dynamic models with time
delay (R package qualV), Journal of Statistical Software, 22(8), 1&ndash;30.
<a href="https://doi.org/10.18637/jss.v022.i08">doi:10.18637/jss.v022.i08</a>.
</p>

<hr>
<h2 id='compareME'>Compute Several Deviance Measures for Comparison</h2><span id='topic+compareME'></span><span id='topic+print.compareME'></span><span id='topic+summary.compareME'></span>

<h3>Description</h3>

<p>Various deviance measures are computed allowing the user to find the
aspects in which two time series differ.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareME(o, p,
          o.t      = seq(0, 1, length.out = length(o)),
          p.t      = seq(0, 1, length.out = length(p)),
          ignore   = c("raw", "centered", "scaled", "ordered"),
          geometry = c("real", "logarithmic", "geometric", "ordinal"),
          measure  = c("mad", "var", "sd"),
          type     = "normalized",
          time     = "fixed", ..., col.vars=c("time", "ignore")
         )
## S3 method for class 'compareME'
print(x, ..., digits = 3)
## S3 method for class 'compareME'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareME_+3A_o">o</code></td>
<td>
<p>vector of observed values,</p>
</td></tr>
<tr><td><code id="compareME_+3A_p">p</code></td>
<td>
<p>vector of predicted values,</p>
</td></tr>
<tr><td><code id="compareME_+3A_o.t">o.t</code></td>
<td>
<p>vector of observation times,</p>
</td></tr>
<tr><td><code id="compareME_+3A_p.t">p.t</code></td>
<td>
<p>vector of times for predicted values,</p>
</td></tr>
<tr><td><code id="compareME_+3A_ignore">ignore</code></td>
<td>
<p>a subset of <code>c("raw", "centered", "scaled",
      "ordered")</code> as defined in <code><a href="#topic+generalME">generalME</a></code> to specify
the aspects of the data to be ignored,</p>
</td></tr>
<tr><td><code id="compareME_+3A_geometry">geometry</code></td>
<td>
<p>a subset of <code>c("real", "logarithmic", "geometric",
      "ordinal")</code> as defined in <code><a href="#topic+generalME">generalME</a></code> to specify the
geometry of the observed data,</p>
</td></tr>
<tr><td><code id="compareME_+3A_measure">measure</code></td>
<td>
<p>a subset of <code>c("mad", "var", "sd")</code> to specify the
type of error to be measured,</p>
</td></tr>
<tr><td><code id="compareME_+3A_type">type</code></td>
<td>
<p>a subset of <code>c("dissimilarity", "normalized",
      "similarity", "reference")</code> as defined in <code><a href="#topic+generalME">generalME</a></code>
to specify the type of deviance measure to be used,</p>
</td></tr>
<tr><td><code id="compareME_+3A_time">time</code></td>
<td>
<p>a subset of <code>c("fixed", "transform")</code>, indicates wether
the time should actually be transformed. If this argument and the
time arguments are missing the comparison is based on values only
without time matching.</p>
</td></tr>
<tr><td><code id="compareME_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+timeTransME">timeTransME</a></code>,</p>
</td></tr>
<tr><td><code id="compareME_+3A_col.vars">col.vars</code></td>
<td>
<p>a subset of <code>c("ignore", "geometry", "measure",
      "time")</code> to be displayed in the columns of the resulting <code>ftable</code>,</p>
</td></tr>
<tr><td><code id="compareME_+3A_digits">digits</code></td>
<td>
<p>number of significant digits displayed,</p>
</td></tr>
<tr><td><code id="compareME_+3A_x">x</code>, <code id="compareME_+3A_object">object</code></td>
<td>
<p>objects of class <code>compareME</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function provides a simple standard interface to get a first idea
on the similarities and dissimilarities of two time series spanning the
same time interval. The <code>print</code> and <code>summary</code> methods extract
the relevant information, rounded to an optional number of significant 
digits.
</p>


<h3>Value</h3>

<p>The result is a list of <code>ftable</code>s containing the deviance
measures of all requested combinations of parameters. The list is done
over the different types of measures requested. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+timeTransME">timeTransME</a></code>,
<code><a href="#topic+generalME">generalME</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># a constructed example
x &lt;- seq(0, 2*pi, 0.1)
y &lt;- 5 + sin(x)             # a process
o &lt;- y + rnorm(x, sd = 0.2) # observation with random error
p &lt;- y + 0.1                # simulation with systematic bias

os &lt;- ksmooth(x, o, kernel = "normal",
  bandwidth = dpill(x, o), x.points = x)$y
plot(x, o); lines(x, p); lines(x, os, col = "red")

compareME(o, p)
compareME(os, p)

# observed and measured data with non-matching time intervals
data(phyto)
compareME(obs$y, sim$y, obs$t, sim$t, time = "fixed")
tt &lt;- timeTransME(obs$y, sim$y, obs$t, sim$t, ME = SMSLE, trials = 5)
compareME(tt$yo, tt$yp)

# show names of deviance measures
compareME(type = "name")
</code></pre>

<hr>
<h2 id='EF'>Efficiency Factor as Suggested by Nash and Sutcliffe</h2><span id='topic+EF'></span>

<h3>Description</h3>

<p>The efficiency factor is a dimensionless statistic which
directly relates predictions to observed data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>EF(o, p)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EF_+3A_o">o</code></td>
<td>
<p>vector of observed values</p>
</td></tr>
<tr><td><code id="EF_+3A_p">p</code></td>
<td>
<p>vector of corresponding predicted values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two time series are compared. <code>'EF'</code> is an overall measure
of similarity between fitted and observed values. Any model giving a
negative value cannot be recommended, whereas values close to one
indicate a 'near-perfect' fit.</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>EF</code></td>
<td>
<p>efficiency factor</p>
</td></tr></table>


<h3>References</h3>

<p>Nash, J. E. and Sutcliffe, J. V. (1970) River flow forecasting through
conceptual models part I - A discussion of principles. Journal of
Hydrology, 10, 282-290.
</p>
<p>Mayer, D. G. and Butler, D. G. (1993) Statistical
Validation. Ecological Modelling, 68, 21-32.</p>


<h3>See Also</h3>

<p><code><a href="#topic+MAE">MAE</a></code>, <code><a href="#topic+MSE">MSE</a></code>, <code><a href="#topic+MAPE">MAPE</a></code>,
<code><a href="#topic+GRI">GRI</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># a constructed example
x &lt;- seq(0, 2*pi, 0.1)
y &lt;- 5 + sin(x)           # a process
o &lt;- y + rnorm(x, sd=0.2) # observation with random error
p &lt;- y + 0.1              # simulation with systematic bias

plot(x, o); lines(x, p)
EF(o, p)

# observed and measured data with non-matching time intervals
data(phyto)
obsb &lt;- na.omit(obs[match(sim$t, obs$t), ])
simb &lt;- sim[na.omit(match(obs$t, sim$t)), ]
EF(obsb$y, simb$y)
</code></pre>

<hr>
<h2 id='features'>Qualitative Features of Time Series</h2><span id='topic+features'></span><span id='topic+f.slope'></span><span id='topic+f.curve'></span><span id='topic+f.steep'></span><span id='topic+f.level'></span>

<h3>Description</h3>

<p>A time series is characterised by a sequence of characters,
indicating features of the time series itself, of its first or second
derivative, steepness or level of values.</p>


<h3>Usage</h3>

<pre><code class='language-R'>f.slope(x, y, f = 0.1, scale = c("mean", "range", "IQR", "sd", "none"))
f.curve(x, y, f = 0.1, scale = c("mean", "range", "IQR", "sd", "none"))
f.steep(x, y, f1 = 1, f2 = 0.1)
f.level(y, high = 0.8, low = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="features_+3A_x">x</code></td>
<td>
<p>vector of time</p>
</td></tr>
<tr><td><code id="features_+3A_y">y</code></td>
<td>
<p>input y values</p>
</td></tr>
<tr><td><code id="features_+3A_f">f</code></td>
<td>
<p>factor defining the limit for constant (<code>f.slope</code>) or linear 
(<code>f.curve</code>) sequences</p>
</td></tr>
<tr><td><code id="features_+3A_f1">f1</code></td>
<td>
<p>factor for the upper bound of steepness</p>
</td></tr>
<tr><td><code id="features_+3A_f2">f2</code></td>
<td>
<p>factor for the lower bound of steepness</p>
</td></tr>
<tr><td><code id="features_+3A_scale">scale</code></td>
<td>
<p>method for internal scaling, <code>f</code> is multiplied with mean
value, range, interquartile range (IQR) or standard deviation of increments 
(<code class="reqn">abs(\Delta y / \Delta x)</code>).</p>
</td></tr>
<tr><td><code id="features_+3A_high">high</code></td>
<td>
<p>lower limit of high values</p>
</td></tr>
<tr><td><code id="features_+3A_low">low</code></td>
<td>
<p>upper limit of low values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the first derivative the segment between two values is
characterised by increasing ('A'), decreasing ('B') or constant ('C') and for
the second by convex ('K'), concave ('I') or linear ('J'). For the property of
the first derivative the segment between two values is characterised
by very steep ('S'), steep ('T') or not steep ('U') or the values are divided
into high ('H'), low ('L') or values in between ('M'). Note that for
the last two cases the original values and the not increments are 
standardised (to <code class="reqn">[0, 1]</code>).</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>v</code></td>
<td>
<p>interval sequence</p>
</td></tr></table>


<h3>See Also</h3>

<p><code><a href="#topic+LCS">LCS</a></code>, <code><a href="#topic+qvalLCS">qvalLCS</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(phyto)
bbobs    &lt;- dpill(obs$t, obs$y)
n        &lt;- tail(obs$t, n = 1) - obs$t[1] + 1
obsdpill &lt;- ksmooth(obs$t, obs$y, kernel = "normal", bandwidth = bbobs,
            n.points = n)
obss     &lt;- data.frame(t = obsdpill$x, y = obsdpill$y)
obss     &lt;- obss[match(sim$t, obss$t), ]
f.slope(obss$t, obss$y)
f.curve(obss$t, obss$y)
f.steep(obss$t, obss$y, f1 = 30, f2 = 10)
f.level(obss$y)
</code></pre>

<hr>
<h2 id='GRI'>Geometric Reliability Index as Suggested by Leggett and Williams (1981)</h2><span id='topic+GRI'></span>

<h3>Description</h3>

<p>Given a set of predictions and a corresponding set of
observations, the geometric validation index is a reliability index for
the predictions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>GRI(o, p)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GRI_+3A_o">o</code></td>
<td>
<p>vector of observed values</p>
</td></tr>
<tr><td><code id="GRI_+3A_p">p</code></td>
<td>
<p>vector of corresponding predicted values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One possible interpretation of 'GRI' is that the
simulation is accurate within a multiplicative factor 'GRI', i.e. the
observed values fall between 1/GRI and GRI times of the corresponding
predicted values. Values close to one indicate a good match.</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>GRI</code></td>
<td>
<p>geometric reliability index</p>
</td></tr></table>


<h3>References</h3>

<p>Leggett, L. R. and Williams, L. R. (1981) A reliability index for
models. Ecological Modelling, 13, 303-312. 
<a href="https://doi.org/10.1016/0304-3800%2881%2990034-X">doi:10.1016/0304-3800(81)90034-X</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+MAE">MAE</a></code>, <code><a href="#topic+MSE">MSE</a></code>, <code><a href="#topic+MAPE">MAPE</a></code>, <code><a href="#topic+EF">EF</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># a constructed example
x &lt;- seq(0, 2*pi, 0.1)
y &lt;- 5 + sin(x)             # a process
o &lt;- y + rnorm(x, sd = 0.2) # observation with random error
p &lt;- y + 0.1                # simulation with systematic bias

plot(x, o); lines(x, p)
GRI(o, p)

# observed and measured data with non-matching time intervals
data(phyto)
obsb &lt;- na.omit(obs[match(sim$t, obs$t), ])
simb &lt;- sim[na.omit(match(obs$t, sim$t)), ]
GRI(obsb$y, simb$y)
</code></pre>

<hr>
<h2 id='LCS'>Algorithm for the Longest Common Subsequence Problem</h2><span id='topic+LCS'></span>

<h3>Description</h3>

<p>Determines the longest common subsequence of two strings.</p>


<h3>Usage</h3>

<pre><code class='language-R'>LCS(a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LCS_+3A_a">a</code></td>
<td>
<p>vector (numeric or character), missing values are not accepted</p>
</td></tr>
<tr><td><code id="LCS_+3A_b">b</code></td>
<td>
<p>vector (numeric or character), missing values are not accepted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A longest common subsequence (<code>LCS</code>) is a common subsequence
of two strings of maximum length. The <code>LCS</code> Problem consists of
finding a <code>LCS</code> of two given strings and its length
(<code>LLCS</code>). A qualitative similarity index <code>QSI</code> is
computed by division of the <code>LLCS</code> over maximum length of
<code>'a'</code> and <code>'b'</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>a</code></td>
<td>
<p>vector <code>'a'</code></p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>vector <code>'b'</code></p>
</td></tr>
<tr><td><code>LLCS</code></td>
<td>
<p>length of <code>LCS</code></p>
</td></tr>
<tr><td><code>LCS</code></td>
<td>
<p>longest common subsequence</p>
</td></tr>
<tr><td><code>QSI</code></td>
<td>
<p>quality similarity index</p>
</td></tr>
<tr><td><code>va</code></td>
<td>
<p>one possible <code>LCS</code> of vector <code>'a'</code></p>
</td></tr>
<tr><td><code>vb</code></td>
<td>
<p>one possible <code>LCS</code> of vector <code>'b'</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>LCS</code> is now using a C version of the algorithm provided by
Dominik Reusser.</p>


<h3>References</h3>

<p>Wagner, R. A. and Fischer, M. J. (1974) The String-to-String
Correction Problem. Journal of the ACM, 21, 168-173.
</p>
<p>Paterson, M. and Dancik, V. (1994) Longest Common
Subsequences. Mathematical Foundations of Computer Science, 841,
127-142.
</p>
<p>Gusfield, D. (1997) Algorithms on Strings, Trees, and Sequences:
Computer Science and Computational Biology. Cambridge University
Press, England, ISBN 0-521-58519-8.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># direct use
a &lt;- c("b", "c", "a", "b", "c", "b")
b &lt;- c("a", "b", "c", "c", "b")
print(LCS(a, b))

# a constructed example
x &lt;- seq(0, 2 * pi, 0.1)  # time
y &lt;- 5 + sin(x)           # a process
o &lt;- y + rnorm(x, sd=0.2) # observation with random error
p &lt;- y + 0.1              # simulation with systematic bias
plot(x, o); lines(x, p)

lcs &lt;- LCS(f.slope(x, o), f.slope(x, p))  # too much noise
lcs$LLCS
lcs$QSI

os &lt;- ksmooth(x, o, kernel = "normal", bandwidth = dpill(x, o), x.points = x)$y
lcs &lt;- LCS(f.slope(x, os), f.slope(x, p))
lcs$LLCS
lcs$QSI


# observed and measured data with non-matching time intervals
data(phyto)
bbobs    &lt;- dpill(obs$t, obs$y)
n        &lt;- tail(obs$t, n = 1) - obs$t[1] + 1
obsdpill &lt;- ksmooth(obs$t, obs$y, kernel = "normal", bandwidth = bbobs,
                    n.points = n)
obss     &lt;- data.frame(t = obsdpill$x, y = obsdpill$y)
obss     &lt;- obss[match(sim$t, obss$t),]
obs_f1   &lt;- f.slope(obss$t, obss$y)
sim_f1   &lt;- f.slope(sim$t, sim$y)
lcs      &lt;- LCS(obs_f1, sim_f1)
lcs$QSI
</code></pre>

<hr>
<h2 id='phyto'>Observed and Predicted Data of Phytoplankton</h2><span id='topic+phyto'></span><span id='topic+obs'></span><span id='topic+sim'></span>

<h3>Description</h3>

<p>The data contain the day since 1.1.1994 and observed/predicted biovolumes
of phytoplankton.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(phyto)
</code></pre>


<h3>Format</h3>

<p>Two data frames of two variables with the following components:
</p>

<dl>
<dt><code>obs:</code></dt><dd><p>A data frame of observed phytoplankton concentration in
Bautzen reservoir 1994 (TU Dresden, Institute of Hydrobiology,
workgroup limnology) with the elements:
</p>

<dl>
<dt><code>t:</code></dt><dd><p>time code</p>
</dd>
<dt><code>y:</code></dt><dd><p>observed biovolume (mg/L)</p>
</dd>
</dl>
</dd>  
<dt><code>sim:</code></dt><dd><p>A data frame of predicted phytoplankton concentration
in Bautzen reservoir 1994 (TU Dresden, Institute of Hydrobiology,
workgroup Limnology) with the elements:
</p>

<dl>
<dt><code>t:</code></dt><dd><p>time code</p>
</dd>
<dt><code>y:</code></dt><dd><p>predicted biovolume (mg/L)</p>
</dd>
</dl>
</dd>
</dl>
 

<hr>
<h2 id='quantV'>Quantitative Validation Methods</h2><span id='topic+generalME'></span><span id='topic+MAE'></span><span id='topic+MAPE'></span><span id='topic+MSE'></span><span id='topic+RMSE'></span><span id='topic+CMAE'></span><span id='topic+CMSE'></span><span id='topic+RCMSE'></span><span id='topic+SMAE'></span><span id='topic+SMSE'></span><span id='topic+RSMSE'></span><span id='topic+MALE'></span><span id='topic+MSLE'></span><span id='topic+MAGE'></span><span id='topic+RMSLE'></span><span id='topic+RMSGE'></span><span id='topic+SMALE'></span><span id='topic+SMAGE'></span><span id='topic+SMSLE'></span><span id='topic+RSMSLE'></span><span id='topic+RSMSGE'></span><span id='topic+MAOE'></span><span id='topic+MSOE'></span><span id='topic+RMSOE'></span>

<h3>Description</h3>

<p>Different methods for calculating the difference between two vectors.</p>


<h3>Usage</h3>

<pre><code class='language-R'>generalME(o, p,
          ignore   = c("raw", "centered", "scaled", "ordered"),
          geometry = c("real", "logarithmic", "geometric", "ordinal"),
          measure  = c("mad", "var", "sd"),
          type     = c("dissimilarity", "normalized", "similarity",
                       "reference", "formula", "name", "function"),
                       method = NULL)
   MAE(o, p, type = "dissimilarity")
  MAPE(o, p, type = "dissimilarity")
   MSE(o, p, type = "dissimilarity")

  RMSE(o, p, type = "dissimilarity")
  CMAE(o, p, type = "dissimilarity")
  CMSE(o, p, type = "dissimilarity")
 RCMSE(o, p, type = "dissimilarity")
  SMAE(o, p, type = "dissimilarity")
  SMSE(o, p, type = "dissimilarity")
 RSMSE(o, p, type = "dissimilarity")
  MALE(o, p, type = "dissimilarity")
  MAGE(o, p, type = "dissimilarity")
 RMSLE(o, p, type = "dissimilarity")
 RMSGE(o, p, type = "dissimilarity")

 SMALE(o, p, type = "dissimilarity")
 SMAGE(o, p, type = "dissimilarity")
 SMSLE(o, p, type = "dissimilarity")

RSMSLE(o, p, type = "dissimilarity")
RSMSGE(o, p, type = "dissimilarity")

  MAOE(o, p, type = "dissimilarity")
  MSOE(o, p, type = "dissimilarity")
 RMSOE(o, p, type = "dissimilarity")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantV_+3A_o">o</code></td>
<td>
<p>vector of observed values</p>
</td></tr>
<tr><td><code id="quantV_+3A_p">p</code></td>
<td>
<p>vector of corresponding predicted values</p>
</td></tr>
<tr><td><code id="quantV_+3A_type">type</code></td>
<td>
<p>one of <code>"dissimilarity"</code>, <code>"normalized"</code>,
<code>"similarity"</code>, <code>"reference"</code>, <code>"formula"</code>, for the dissimilarity
measure, the normalized dissimilarity measure, the similarity
measure, or the formula for the normalized measure. For
<code>generalME</code> it is additionally possible to specify
<code>"function"</code> for getting the corresponding function and
<code>"name"</code> for getting the name of the function.
</p>
</td></tr>
<tr><td><code id="quantV_+3A_ignore">ignore</code></td>
<td>
<p>specifies which aspects should be ignored: <code>"raw"</code>
compares original values, <code>"centered"</code> removes differences in mean,
<code>"scaled"</code> ignores scaling, <code>"ordered"</code> indicates the use of the
ordinal geometry only.</p>
</td></tr>
<tr><td><code id="quantV_+3A_geometry">geometry</code></td>
<td>
<p>indicating the geometry to be used for the data and
the output, <code>"real"</code> corresponds to arithmetic differences and means,
<code>"logarithmic"</code> to handling relative data on a logarithmic scale,
<code>"geometric"</code> to geometric means and differences and <code>"ordinal"</code>
to a pure ordinal treatment.</p>
</td></tr>
<tr><td><code id="quantV_+3A_measure">measure</code></td>
<td>
<p>indicates how distances should be measured: as mean
absolute distances like in MAD, as squared distances like in a
variance, or as the root of mean squared distances like in sd.</p>
</td></tr>
<tr><td><code id="quantV_+3A_method">method</code></td>
<td>
<p>optionally the function to be used can specified
directly as a function or as a string.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These comparison criteria are designed for a semiquantitative
comparison of observed values <code>o</code> with predicted values
<code>p</code> to validate the performance of the prediction.
<br />
The general naming convention follows the grammar scheme
<br />
<code>[R][C|S]M[S|A][L|G|O]E</code>
<br />
corresponding to
<code>[Root] [Centered | Scaled] Mean [Squared | Absolute]</code>
<br />
<code>[Logarithmic, Geometric, Ordinal] Error</code>
</p>

<dl>
<dt>Root</dt><dd><p>is used together with squared errors to indicate, that a
root is applied to the mean.</p>
</dd>
<dt>Centered</dt><dd><p>indicates that an additive constant is allowed.</p>
</dd>
<dt>Scaled</dt><dd><p>indicates that a scaling of the predictive sequence is
allowed. Scaled implies centered for real scale.</p>
</dd>
<dt>Squared</dt><dd><p>indicates that squared error is used.</p>
</dd>
<dt>Absolute</dt><dd><p>indicates that absolute error is used.</p>
</dd>
<dt>Logarithmic</dt><dd><p>indicates that the error is calculated based on the
logarithms of the values. This is useful for data on a relative
scale.</p>
</dd>
<dt>Geometric</dt><dd><p>indicates that the result is to be understood as a
factor, similar to a geometric mean.</p>
</dd>
<dt>Ordinal</dt><dd><p>indicates that only the order of the observations is
taken into account by analyzing the data by ranks scaled to the
interval [0, 1].</p>
</dd>
</dl>

<p>The mean errors for squared error measures are
based on the number of degrees of freedom of the residuals.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>generalME</code></td>
<td>
<p>selects the best deviance measure according to the
description given in the parameters. It has the two additional
possibilities of name and function in the type parameter.</p>
</td></tr>
<tr><td><code>MAE</code></td>
<td>
<p>mean absolute error <code class="reqn">\frac1n</code></p>
</td></tr>
<tr><td><code>MAPE</code></td>
<td>
<p>mean absolute percentage error</p>
</td></tr>
<tr><td><code>MSE</code></td>
<td>
<p>mean squared error</p>
</td></tr>
<tr><td><code>RMSE</code></td>
<td>
<p>root mean squared error</p>
</td></tr>
<tr><td><code>CMAE</code></td>
<td>
<p>centered mean absolute error</p>
</td></tr>
<tr><td><code>CMSE</code></td>
<td>
<p>centered mean squared error</p>
</td></tr>
<tr><td><code>RCMSE</code></td>
<td>
<p>root centered mean squared error</p>
</td></tr>
<tr><td><code>SMAE</code></td>
<td>
<p>scaled mean absolute error</p>
</td></tr>
<tr><td><code>SMSE</code></td>
<td>
<p>scaled mean squared error</p>
</td></tr>
<tr><td><code>RSMSE</code></td>
<td>
<p>root scaled mean squared error</p>
</td></tr>
<tr><td><code>MALE</code></td>
<td>
<p>mean absolute logarithmic error</p>
</td></tr>
<tr><td><code>MAGE</code></td>
<td>
<p>mean absolute geometric error</p>
</td></tr>
<tr><td><code>MSLE</code></td>
<td>
<p>mean squared logarithmic error</p>
</td></tr>
<tr><td><code>MSGE</code></td>
<td>
<p>mean squared geometric error</p>
</td></tr>
<tr><td><code>RMSLE</code></td>
<td>
<p>root mean squared logarithmic error</p>
</td></tr>
<tr><td><code>SMALE</code></td>
<td>
<p>scaled mean absolute logarithmic error</p>
</td></tr>
<tr><td><code>SMAGE</code></td>
<td>
<p>scaled mean absolute relative error</p>
</td></tr>
<tr><td><code>SMSLE</code></td>
<td>
<p>scaled mean squared logarithmic error</p>
</td></tr>
<tr><td><code>RSMSLE</code></td>
<td>
<p>root scaled mean squared logarithmic error</p>
</td></tr>
<tr><td><code>RSMSGE</code></td>
<td>
<p>root scaled mean squared geometric error</p>
</td></tr>
<tr><td><code>MAOE</code></td>
<td>
<p>mean absolute ordinal error </p>
</td></tr>
<tr><td><code>MSOE</code></td>
<td>
<p>mean squared ordinal error</p>
</td></tr>
<tr><td><code>RMSOE</code></td>
<td>
<p>root mean squared ordinal error</p>
</td></tr>
</table>


<h3>References</h3>

<p>Mayer, D. G. and Butler, D. G. (1993) Statistical
Validation. Ecological Modelling, 68, 21-32.
</p>
<p>Jachner, S., van den Boogaart, K.G. and Petzoldt, T. (2007) Statistical
methods for the qualitative assessment of dynamic models with time
delay (R package qualV), Journal of Statistical Software, 22(8), 1&ndash;30.
<a href="https://doi.org/10.18637/jss.v022.i08">doi:10.18637/jss.v022.i08</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EF">EF</a></code>, <code><a href="#topic+GRI">GRI</a></code>, <code><a href="#topic+compareME">compareME</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(phyto)
obsb &lt;- na.omit(obs[match(sim$t, obs$t), ])
simb &lt;- sim[na.omit(match(obs$t, sim$t)), ]
o &lt;- obsb$y
p &lt;- simb$y

generalME(o, p, ignore = "raw", geometry = "real")

   MAE(o, p)
  MAPE(o, p)
   MSE(o, p)
  RMSE(o, p)
  CMAE(o, p)
  CMSE(o, p)
 RCMSE(o, p)
  SMAE(o, p)
  SMSE(o, p)
 RSMSE(o, p)
  MALE(o, p)
  MAGE(o, p)
 RMSLE(o, p)
 RMSGE(o, p)

 SMALE(o, p)
 SMAGE(o, p)
 SMSLE(o, p)

RSMSLE(o, p)
RSMSGE(o, p)

  MAOE(o, p)
  MSOE(o, p)
 RMSOE(o, p)
   MAE(o, p)
  MAPE(o, p)


   MSE(o, p, type = "s")
  RMSE(o, p, type = "s")
  CMAE(o, p, type = "s")
  CMSE(o, p, type = "s")
 RCMSE(o, p, type = "s")
  SMAE(o, p, type = "s")
  SMSE(o, p, type = "s")
 RSMSE(o, p, type = "s")
  MALE(o, p, type = "s")
  MAGE(o, p, type = "s")
 RMSLE(o, p, type = "s")
 RMSGE(o, p, type = "s")

 SMALE(o, p, type = "s")
 SMAGE(o, p, type = "s")
 SMSLE(o, p, type = "s")

RSMSLE(o, p, type = "s")
RSMSGE(o, p, type = "s")

  MAOE(o, p, type = "s")
  MSOE(o, p, type = "s")
 RMSOE(o, p, type = "s")
</code></pre>

<hr>
<h2 id='qvalLCS'>Qualitative Validation by Means of Interval Sequences and LCS</h2><span id='topic+qvalLCS'></span><span id='topic+print.qvalLCS'></span><span id='topic+plot.qvalLCS'></span><span id='topic+summary.qvalLCS'></span>

<h3>Description</h3>

<p>Dividing time series into interval sequences of qualitative
features and determining the similarity of the qualitative behavior by
means of the length of <code>LCS</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>qvalLCS(o, p,
        o.t     = seq(0, 1, length.out = length(o)),
        p.t     = seq(0, 1, length.out = length(p)),
        smooth  = c("none", "both", "obs", "sim"),
        feature = c("f.slope", "f.curve", "f.steep", "f.level"))
## S3 method for class 'qvalLCS'
print(x, ...)
## S3 method for class 'qvalLCS'
plot(x, y = NULL, ..., xlim = range(c(x$obs$x, x$sim$x)),
ylim = range(c(x$obs$y, x$sim$y)), xlab = "time", ylab = " ",
col.obs = "black", col.pred = "red",
plot.title = paste("LLCS =", x$lcs$LLCS, ", QSI =", x$lcs$QSI),
legend = TRUE)
## S3 method for class 'qvalLCS'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qvalLCS_+3A_o">o</code></td>
<td>
<p>vector of observed values</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_p">p</code></td>
<td>
<p>vector of predicted values</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_o.t">o.t</code></td>
<td>
<p>vector of observation times</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_p.t">p.t</code></td>
<td>
<p>vector of times for predicted values</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_smooth">smooth</code></td>
<td>
<p>character string to decide if values should be smoothed
before validation, default no smoothing <code>"none"</code> is set,
<code>"both"</code> observed and predicted values will be smoothed,
<code>"obs"</code> only observed, and <code>"sim"</code> only simulated values will
be smoothed.</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_feature">feature</code></td>
<td>
<p>one of <code>"f.slope"</code>, <code>"f.curve"</code>, <code>"f.steep"</code>,
<code>"f.level"</code> as defined in <code><a href="#topic+features">features</a></code> to divide the
time series into interval sequences of these feature. As default
the first derivative <code>"f.slope"</code> is used.</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_x">x</code></td>
<td>
<p>a result from a call of <code>qvalLCS</code></p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_y">y</code></td>
<td>
<p>y unused</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_...">...</code></td>
<td>
<p>further parameters to be past to
<code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_xlim">xlim</code></td>
<td>
<p>the size of the plot in x-direction</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_ylim">ylim</code></td>
<td>
<p>the size of the plot in y-direction</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_xlab">xlab</code></td>
<td>
<p>the label of the x-axis of the plot</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_ylab">ylab</code></td>
<td>
<p>the label of the y-axis of the plot</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_col.obs">col.obs</code></td>
<td>
<p>color to plot the observations</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_col.pred">col.pred</code></td>
<td>
<p>color to plot the predictions</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_plot.title">plot.title</code></td>
<td>
<p>title for the plot</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_legend">legend</code></td>
<td>
<p>tegend for the plot</p>
</td></tr>
<tr><td><code id="qvalLCS_+3A_object">object</code></td>
<td>
<p>a result from a call of <code>qvalLCS</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Common quantitative deviance measures underestimate the
similarity of patterns if there are shifts in time between measurement
and simulation. These methods also assume compareable values in each
time series of the whole time sequence. To compare values independent
of time the qualitative behavior of the time series could be
analyzed. Here the time series are divided into interval sequences
of their local shape. The comparison occurs on the basis of these
segments and not with the original time series. Here shifts in time
are possible, i.e. missing or additional segments are acceptable
without losing similarity. The dynamic programming algorithm of
the longest common subsequence <code><a href="#topic+LCS">LCS</a></code> is used to determine
<code>QSI</code> as index of similarity of the patterns.
<br />
If selected the data are smoothed using a weighted average and a
Gaussian curve as kernel. The bandwidth is automatically selected
based on the plug-in methodology (<code>dpill</code>, see package
<span class="pkg">KernSmooth</span> for more details).
</p>

<dl>
<dt>print.qvalLCS</dt><dd><p>prints only the requested value, without
additional information.</p>
</dd>
<dt>summary.qvalLCS</dt><dd><p>prints all the additional information.</p>
</dd>
<dt>plot.qvalLCS</dt><dd><p>shows a picture visualizing a <code>LCS</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The result is an object of type <code>qvalLCS</code> with the following entries:
</p>
<table role = "presentation">
<tr><td><code>smooth</code></td>
<td>
<p>smoothing parameter</p>
</td></tr>
<tr><td><code>feature</code></td>
<td>
<p>feature parameter</p>
</td></tr>
<tr><td><code>o</code></td>
<td>
<p>xy-table of observed values</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>xy-table of predicted values</p>
</td></tr>
<tr><td><code>obs</code></td>
<td>
<p>xy-table of (smoothed) observed values</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>
<p>xy-table of (smoothed) simulated values</p>
</td></tr>
<tr><td><code>obsf</code></td>
<td>
<p>interval sequence of observation according to selected <code><a href="#topic+features">features</a></code></p>
</td></tr>
<tr><td><code>simf</code></td>
<td>
<p>interval sequence of simulation according to selected <code><a href="#topic+features">features</a></code></p>
</td></tr>
<tr><td><code>lcs</code></td>
<td>
<p>output of <code><a href="#topic+LCS">LCS</a></code> function</p>
</td></tr> 
<tr><td><code>obs.lcs</code></td>
<td>
<p>one <code>LCS</code> of observation</p>
</td></tr>
<tr><td><code>sim.lcs</code></td>
<td>
<p>one <code>LCS</code> of simulation</p>
</td></tr>
</table>


<h3>References</h3>

<p>Agrawal R., K. Lin., H. Sawhney and K. Shim (1995).
Fast similarity search in the presence of noise, scaling, and
translation in time-series databases. In VLDB '95: Proceedings
of the 21. International Conference on Very Large Data Bases,
pp. 490-501. Morgan Kaufmann Publishers Inc. ISBN 1-55860-379-4.
</p>
<p>Cuberos F., J. Ortega, R. Gasca, M. Toro and J. Torres (2002).
Qualitative comparison of temporal series - QSI. Topics in
Artificial Intelligence. Lecture Notes in Artificial
Intelligence, 2504, 75-87.
</p>
<p>Jachner, S., K.G. v.d. Boogaart, T. Petzoldt (2007) Statistical methods
for the qualitative assessment of dynamic models with time delay (R
package qualV), Journal of Statistical Software, 22(8), 1&ndash;30.
<a href="https://doi.org/10.18637/jss.v022.i08">doi:10.18637/jss.v022.i08</a>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LCS">LCS</a></code>, <code><a href="#topic+features">features</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># a constructed example
x &lt;- seq(0, 2*pi, 0.1)
y &lt;- 5 + sin(x)           # a process
o &lt;- y + rnorm(x, sd=0.2) # observation with random error
p &lt;- y + 0.1              # simulation with systematic bias

qvalLCS(o, p)
qvalLCS(o, p, smooth="both", feature="f.curve")

qv &lt;- qvalLCS(o, p, smooth = "obs")
print(qv)
plot(qv, ylim=c(3, 8))

# observed and measured data with non-matching time steps
data(phyto)
qvlcs &lt;- qvalLCS(obs$y, sim$y, obs$t, sim$t, smooth = "obs")

basedate &lt;- as.Date("1960/1/1")
qvlcs$o$x   &lt;- qvlcs$o$x + basedate
qvlcs$obs$x &lt;- qvlcs$obs$x + basedate
qvlcs$sim$x &lt;- qvlcs$sim$x + basedate
qvlcs$obs.lcs$x &lt;- qvlcs$obs.lcs$x + basedate
qvlcs$sim.lcs$x &lt;- qvlcs$sim.lcs$x + basedate

plot.qvalLCS(qvlcs)
summary(qvlcs)
</code></pre>

<hr>
<h2 id='timetrans'>Bijective Transformations of Time</h2><span id='topic+transBeta'></span><span id='topic+transSimplex'></span><span id='topic+transBezier'></span>

<h3>Description</h3>

<p>Various function models for isoton bijective transformation of
a time interval to itself.</p>


<h3>Usage</h3>

<pre><code class='language-R'>transBeta(x, p, interval = c(0, 1), inv = FALSE,
  pmin = -3, pmax = 3, p0 = c(0, 0))
transSimplex(x, p, interval = c(0, 1), inv = FALSE,
  pmin = -2, pmax = 2, p0 = c(0, 0, 0, 0, 0))
transBezier(x, p, interval = c(0, 1), inv = FALSE,
  pmin = 0, pmax = 1, p0 = c(0.25, 0.25, 0.75, 0.75))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timetrans_+3A_x">x</code></td>
<td>
<p>a vector of values to be transformed,</p>
</td></tr>
<tr><td><code id="timetrans_+3A_p">p</code></td>
<td>
<p>the vector of parameters for the transformation,</p>
</td></tr>
<tr><td><code id="timetrans_+3A_interval">interval</code></td>
<td>
<p>a vector of length 2 giving the minimum and maximum
value in the transformation interval.</p>
</td></tr>
<tr><td><code id="timetrans_+3A_inv">inv</code></td>
<td>
<p>a boolean, if true the inverse transform is computed.</p>
</td></tr>
<tr><td><code id="timetrans_+3A_pmin">pmin</code></td>
<td>
<p>a number or a vector giving the minimal useful value for
the parameters. This information is not used by the function itself,
but rather provides a meta information about the function used in
<code><a href="#topic+timeTransME">timeTransME</a></code>. The chosen values are quite restrictive
to avoid stupid extreme transformation.</p>
</td></tr>
<tr><td><code id="timetrans_+3A_pmax">pmax</code></td>
<td>
<p>provides similar to <code>pmin</code> the upper useful bounds
for the parameters.</p>
</td></tr>
<tr><td><code id="timetrans_+3A_p0">p0</code></td>
<td>
<p>provides similar to <code>pmin</code> and <code>pmax</code> the
parameterization for the identify transform.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>transBeta</code></dt><dd>
<p>The transformation provided is the distribution function of the
Beta-Distribution with parameters <code>exp(p[1])</code> and
<code>exp(p[2])</code> scaled to the given interval. This function is
guaranteed to be strictly isotonic for every choice of p. p has
length 2. The strength of the Beta transformation is the reasonable
behavior for strong time deformations.
</p>
</dd>
<dt><code>transSimplex</code></dt><dd>
<p>The transformation provided a simple linear interpolation. The
interval is separated into equidistant time spans, which are
transformed to non-equidistant length. The length of the new
time spans is the proportional to exp(c(p, 0)). This function is
guaranteed to be strictly isotonic for every choice of p. p can have
any length. The strength of the Simplex transformation is the
possibility to have totally different speeds at different times.
</p>
</dd>
<dt><code>transBezier</code></dt><dd>
<p>The transformation is provided by a Bezier-Curve of order
<code>length(p) / 2 + 1</code>. The first and last control point are given by
<code>c(0, 0)</code> and <code>c(1, 1)</code> and the intermediate control points
are given by <code>p[c(1, 2) + 2 * i - 2]</code>. This function is not guaranteed
to be isotonic for <code>length(p) &gt; 4</code>. However it seams useful. A
major theoretical advantage is that this model is symmetric between
image and coimage. The strength of the Bezier transformation is fine
tuning of transformation.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>The value is a vector of the same length as <code>x</code> providing the
transformed values. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+timeTransME">timeTransME</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>t &lt;- seq(0, 1, length.out = 101)
par(mfrow = c(3, 3))
plot(t, transBeta(t, c(0, 0)), type = "l")
plot(t, transBeta(t, c(0, 1)), type = "l")
plot(t, transBeta(t, c(-1,1)), type = "l")
plot(t, transSimplex(t, c(0)), type = "l")
plot(t, transSimplex(t, c(3, 2, 1)), type = "l")
plot(t, transSimplex(t, c(0, 2)), type = "l")
plot(t, transBezier(t, c(0, 1)), type = "l")
plot(t, transBezier(t, c(0, 1, 1, 0)), type = "l")
plot(t, transBezier(t, c(0.4, 0.6)), type = "l")
</code></pre>

<hr>
<h2 id='timeTransME'>Transformation of Time to Match Two Time Series</h2><span id='topic+timeTransME'></span><span id='topic+timetransme'></span><span id='topic+print.timeTransME'></span><span id='topic+plot.timeTransME'></span><span id='topic+summary.timeTransME'></span>

<h3>Description</h3>

<p>Transforming the time of predicted values by means of a monotonic mapping.</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeTransME(o, p,
            o.t      = seq(0, 1, length.out = length(o)),
            p.t      = seq(0, 1, length.out = length(p)),
            ignore   = "scaled",
            geometry = "real",
            measure  = "mad",
            type     = c("dissimilarity", "normalized",
                         "similarity", "reference"),
            interval = range(c(o.t, p.t)),
            time     = c("transformed", "fixed"),
            trans    = transBeta,
            p0       = eval(formals(trans)$p0),
            pmin     = eval(formals(trans)$pmin, list(p = p0)),
            pmax     = eval(formals(trans)$pmax, list(p = p0)),
            timeMEFactor = 0,
            timeME       = MAE,
            timeMEtype   = "normalized",
            timeScale    = 1,
            ME     = generalME(o, p, ignore, geometry, measure,
                               type = "function"),
            MEtype = c("dissimilarity", "normalized"),
            trials = 100,
            debug  = FALSE)
## S3 method for class 'timeTransME'
print(x, ..., digits = 3)
## S3 method for class 'timeTransME'
summary(object, ...)
## S3 method for class 'timeTransME'
plot(x, y = NULL, ..., col.obs = "black", col.pred = "green",
     col.map = "red", sub = x$call, xlab = "t",
     xlim = range(x$x), ylim = range(c(0, x$yo, x$yp)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timeTransME_+3A_x">x</code></td>
<td>
<p>a result from a call to <code>timeTransME</code></p>
</td></tr>
<tr><td><code id="timeTransME_+3A_object">object</code></td>
<td>
<p>a result from a call to <code>timeTransME</code></p>
</td></tr>
<tr><td><code id="timeTransME_+3A_o">o</code></td>
<td>
<p>vector of observed values</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_p">p</code></td>
<td>
<p>vector of predicted values</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_o.t">o.t</code></td>
<td>
<p>vector of observation times</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_p.t">p.t</code></td>
<td>
<p>vector of times for predicted values</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_ignore">ignore</code></td>
<td>
<p>one of <code>"raw"</code>, <code>"centered"</code>, <code>"scaled"</code> or
<code>"ordered"</code> as defined in <code><a href="#topic+generalME">generalME</a></code> to specify the aspects
of the data to be ignored.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_geometry">geometry</code></td>
<td>
<p>one of <code>"real", "logarithmic", "geometric", "ordinal"</code>
as defined in <code><a href="#topic+generalME">generalME</a></code> to specify the geometry of
the observed data.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_measure">measure</code></td>
<td>
<p>one of <code>"mad", "sd", "var"</code> to specify the type of
error to be measured.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_type">type</code></td>
<td>
<p>one of
<code>"dissimilarity"</code>, <code>"normalized"</code>, <code>"similarity"</code> or
<code>"reference"</code> as defined in <code><a href="#topic+generalME">generalME</a></code> to
specify the type of deviance measure to be used.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_interval">interval</code></td>
<td>
<p>a vector with two entries giving start and end time of
the experiment.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_time">time</code></td>
<td>
<p>indicates wether the time should actually be
transformed. LCS is currently not implemented. Use the LCS method
directly.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_trans">trans</code></td>
<td>
<p>the model function for the time transformation. See
<code><a href="#topic+transBezier">transBezier</a></code> for possible alternatives.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_p0">p0</code></td>
<td>
<p>the identity parameters for the time-transformation. A non
identity value can be given to force specific parameters for the
transformation with <code>time = "fixed"</code>.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_pmin">pmin</code></td>
<td>
<p>number or vector providing the minimal allowed values for
the parameters of the transformation.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_pmax">pmax</code></td>
<td>
<p>number or vector providing the minimal allowed values for
the parameters of the transformation.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_timeme">timeME</code></td>
<td>
<p>The <code>timeTransME</code> minimizes a weighted sum of the
deformation of the time scale and of the data values
according to
<code>totalME =</code> minimum of
</p>
<pre>ME(o(x), p(trans(x, timep)), MEtype) +
  timeMEFactor * timeME(x * timeScale,
  trans(x, timep) * timeScale, timeMEtype)</pre><p> over <code>p</code> for
<code>x = c(ot, trans(pt, timep, inv = TRUE))</code>.
<br />
<code>timeME</code> specifies the function to be used to quantify the temporal deformation.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_timemetype">timeMEtype</code></td>
<td>
<p>the type of deviance measure (&ldquo;dissimilarity&rdquo; or
&ldquo;normalized&rdquo;) to be used for <code>timeME</code>.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_timemefactor">timeMEFactor</code></td>
<td>
<p>a real value specifying the weighting of the time
deformation against the value deformation. A value of 0 avoids penalty
for time deformation.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_timescale">timeScale</code></td>
<td>
<p>a scaling applied to the time values before
<code>timeME</code> is applied. This can be used to change the units of
measurement for the time.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_me">ME</code></td>
<td>
<p>the deviance function to be used for the data. See <code><a href="#topic+MSE">MSE</a></code>
for alternatives.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_metype">MEtype</code></td>
<td>
<p>the type of Mean Error to be used in the
calculations. This is not the type of Measure to be reported.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_trials">trials</code></td>
<td>
<p>The number of random starting values that should be used
during the optimization of the time transformation. The optimization of
the time transformation is a very critical task of this procedure and it
had been shown by practical tests that a single local optimization
typically fails to find the globally best fit. Depending on the number
of parameters a value between 100 and 10000 seems reasonable for this
parameter.</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_debug">debug</code></td>
<td>
<p>a logical. If true some diagnostic information for the
optimization step is printed.
</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_...">...</code></td>
<td>
<p>further parameters to be passed to
<code><a href="base.html#topic+plot">plot</a></code></p>
</td></tr>
<tr><td><code id="timeTransME_+3A_col.obs">col.obs</code></td>
<td>
<p>color to plot the observations</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_col.pred">col.pred</code></td>
<td>
<p>color to plot the predictions</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_col.map">col.map</code></td>
<td>
<p>color to plot the mapped predictions</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_sub">sub</code></td>
<td>
<p>the sub-headline of the plot</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_xlab">xlab</code></td>
<td>
<p>the label of the x-axis of the plot</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_xlim">xlim</code></td>
<td>
<p>the size of the plot in x-direction</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_ylim">ylim</code></td>
<td>
<p>the size of the plot in y-direction</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_y">y</code></td>
<td>
<p>y unused</p>
</td></tr>
<tr><td><code id="timeTransME_+3A_digits">digits</code></td>
<td>
<p>number of significant digits displayed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Common quantitative deviance measures underestimate the
similarity of patterns if there are shifts in time between measurement
and simulation. An alternative to measure model performance
independent of shifts in time is to transform the time of the
simulation, i.e. to run the time faster or slower, and to compare the
performance before and after the transformation. The applied
transformation function must be monotonic. <code>timeTransME</code>
minimizes the joint criterium<br />
<code>ME(o(x), p(trans(x, timep)), MEtype) +</code><br />
<code>timeMEFactor * timeME(x * timeScale, trans(x, timep) * timeScale, timeMEtype)</code>
to find a best fitting time transformation.
</p>

<dl>
<dt><code>print.timeTransME</code></dt><dd><p>prints only the requested value, without
additional information.</p>
</dd>
<dt><code>summary.timeTransME</code></dt><dd><p>prints all the additional information.</p>
</dd>
<dt><code>plot.timeTransME</code></dt><dd><p>shows a picture visualising the fit of the
transformed dataset. This can be used as a diagnostic.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The result is an object of type <code>timeTransME</code> with the following entries:
</p>
<table role = "presentation">
<tr><td><code>totalME</code></td>
<td>
<p>the requested measure with specified type,</p>
</td></tr>
<tr><td><code>criterium</code></td>
<td>
<p>the &quot;dissimilarity&quot; measure, which was calculated as a
minimum of
</p>
<pre>ME(o(x), p(trans(x, timep)), MEtype) + timeMEFactor *
  timeME(x * timeScale, trans(x, timep) * timeScale,
  timeMEtype)</pre><p>.</p>
</td></tr>
<tr><td><code>reference</code></td>
<td>
<p>the reference value of this criterium achieved without
time deformation and full dissimilarity.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used to generate this deviance.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>the times at which the series were compared from the
perspective of the observations.</p>
</td></tr>
<tr><td><code>xp</code></td>
<td>
<p>the transformed times at which the series were compared from
the perspective of the prediction.</p>
</td></tr>
<tr><td><code>yo</code></td>
<td>
<p>the interpolated values of the observations at times <code>x</code>.</p>
</td></tr>
<tr><td><code>yp</code></td>
<td>
<p>the interpolated values of the time transformed predictions
at times <code>x</code>.</p>
</td></tr>
<tr><td><code>timeME</code></td>
<td>
<p>the deviance of the time transformation:
<br />
<code>timeME(x, trans(x, ME), timeMEtype))</code>.</p>
</td></tr>
<tr><td><code>timeMEref</code></td>
<td>
<p>the reference value of timeME</p>
</td></tr>
<tr><td><code>timeMEFactor</code></td>
<td>
<p>the factor to be used for timeME in the weighting
with respect to <code>ME</code>.</p>
</td></tr>
<tr><td><code>timeScale</code></td>
<td>
<p>the scaling to time to account for an other unit.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the parameter of trans minimizing the criterium.</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>
<p>the interval of time under consideration</p>
</td></tr>
<tr><td><code>trans</code></td>
<td>
<p>the transformation function used for the time.</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>contains informations about the convergence of the
optimization procedure and a list of secondary minima found.
This additional list element occurs only if there is actually a minimisation
performed.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The deviance calculated by <code>timeTransME(..., time = "fixed")</code> and the
corresponding deviance measure are different because the timeTransME
does an interpolation and compares time sequences at different spacing,
while a simple deviance measure compares values only.
<br />
The CPU usage of the calculation of the
minimum, when <code>trans = "transform"</code> is very high, because the
optimization is done a hundred times with random starting values for
the parameters. This is necessary since with the given objective the
general purpose optimizers often run into local minima and/or do not
converge. The number of iterations can be controlled with the
parameter <code>trials</code>. Setting <code>debug = TRUE</code> gives an impression
how long it takes to find an improved optimum.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transBeta">transBeta</a></code>,
<code><a href="#topic+transBezier">transBezier</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
## a constructed example
x &lt;- seq(0, 2*pi, length=10)
o &lt;- 5 + sin(x) + rnorm(x, sd=0.2) # observation with random error
p &lt;- 5 + sin(x-1)                  # simulation with time shift

# timeTransME(o, p) # reasonably accurate but takes very long!
# timeTransME(o, p, trials=5, debug=TRUE)

ttbeta &lt;- timeTransME(o, p, trials=5)
plot(ttbeta)
## Not run: 
ttsimplex &lt;- timeTransME(o, p, trans = transSimplex, trials=5)
plot(ttsimplex)

ttbezier &lt;- timeTransME(o, p, trans = transBezier, trials=5)
plot(ttbezier)

## End(Not run)

## observed and measured data with non-matching time intervals
data(phyto)
bbobs    &lt;- dpill(obs$t, obs$y)
n        &lt;- diff(range(obs$t)) + 1
obss     &lt;- ksmooth(obs$t, obs$y, kernel = "normal", bandwidth = bbobs,
            n.points = n)
names(obss) &lt;- c("t", "y")
obss     &lt;- as.data.frame(obss)[match(sim$t, obss$t), ]

tt       &lt;- timeTransME(obss$y, sim$y, obss$t, sim$t, ME = SMSE,
            timeMEFactor = 0, time = "transform", type = "n", trials = 5)
round(tt$totalME, digits = 3)

basedate &lt;- as.Date("1960/1/1")
plot(basedate + sim$t, sim$y, type="l", ylim = c(min(obs$y, sim$y),
  max(obs$y, sim$y)), xlab = "time", ylab = "Phytoplankton (mg/L)",
  col = 2, font = 2, lwd = 2, cex.lab = 1.2, las = 1)
lines(basedate + obss$t, obss$y, lwd = 2)
points(basedate + obs$t, obs$y, lwd = 2)
lines(basedate + tt$x, tt$yp, lwd = 2, col = 2, lty = 2)
legend(basedate + 12600, 50, c("measurement", "smoothed measurement",
"simulation", "transformed simulation"), lty = c(0, 1, 1, 2),
pch = c(1, NA, NA, NA), lwd = 2, col = c(1, 1, 2, 2))

tt1 &lt;- timeTransME(obs$y, sim$y, obs$t, sim$t, ME = SMSLE, type = "n",
  time = "fixed")
tt1
plot(tt1)
summary(tt1)

## Not run: 
tt2 &lt;- timeTransME(obss$y, sim$y, obss$t, sim$t, ME = SMSLE, type = "n",
  time = "trans", debug = TRUE)
tt2
plot(tt2)  # logarithm (SMSLE) is not appropriate for the example
summary(tt2)
tt3 &lt;- timeTransME(obss$y, sim$y, obss$t, sim$t, ME = SMSE, type = "n",
  time = "trans", trans = transBezier, debug = TRUE)
tt3
plot(tt3)
summary(tt3)
tt4 &lt;- timeTransME(obss$y, sim$y, obss$t, sim$t, ME = MSOE, type = "n",
  time = "trans", trans = transBezier, debug = TRUE)
tt4
plot(tt4)
summary(tt4)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
