<!DOCTYPE html><html lang="en"><head><title>Help for package LINselect</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LINselect}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#penalty'><p>penalty</p></a></li>
<li><a href='#simulData'><p>simulData</p></a></li>
<li><a href='#tuneLasso'><p>tuneLasso</p></a></li>
<li><a href='#VARselect'><p>VARselect</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Selection of Linear Estimators</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-06</td>
</tr>
<tr>
<td>Author:</td>
<td>Yannick Baraud, Christophe Giraud, Sylvie Huet</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Benjamin Auder &lt;benjamin.auder@universite-paris-saclay.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimate the mean of a Gaussian vector, by choosing among a large collection of estimators,
  following the method developed by Y. Baraud, C. Giraud and S. Huet (2014) &lt;<a href="https://doi.org/10.1214%2F13-AIHP539">doi:10.1214/13-AIHP539</a>&gt;.
  In particular it solves the problem of variable selection by choosing the best predictor among predictors emanating from different methods as lasso,
  elastic-net, adaptive lasso, pls, randomForest. Moreover, it can be applied for choosing the tuning parameter in a Gauss-lasso procedure.</td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm, elasticnet, MASS, randomForest, pls, gtools, stats</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-06 21:44:31 UTC; ba</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-07 05:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='penalty'>penalty</h2><span id='topic+penalty'></span>

<h3>Description</h3>

<p>Calculate the penalty function for estimators selection.</p>


<h3>Usage</h3>

<pre><code class='language-R'>penalty(Delta, n, p, K)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="penalty_+3A_delta">Delta</code></td>
<td>
<p>vector with <code>Dmax</code>+1 components : weights in the penalty function.</p>
</td></tr>
<tr><td><code id="penalty_+3A_n">n</code></td>
<td>
<p>integer : number of observatons.</p>
</td></tr>
<tr><td><code id="penalty_+3A_p">p</code></td>
<td>
<p>integer : number of variables.</p>
</td></tr>
<tr><td><code id="penalty_+3A_k">K</code></td>
<td>
<p>scalar : constant in the penalty function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the same length as Delta: for each <code>d</code>=0, ..., <code>Dmax</code>, let
<code>N</code>=<code>n</code>-<code>d</code>, <code>D</code>=<code>d+1</code> and <br />
<code>pen(d) = x K N/(N-1)</code> where  <code>x</code> satisfies
<br />
<br />
<code class="reqn">\phi</code><code>(x) = exp(-Delta(d))</code>, when <code>Delta(d)&lt;50</code>, 
<br />
where  <code class="reqn">\phi</code><code>(x)=pf(q=x/(D+2),df1=D+2,df2=N-1,lower.tail=F)-(x/D)pf(q=(N+1)x/D(N-1),df1=D,df2=N+1,lower.tail=F)</code>
<br />
<br />
<code class="reqn">\psi</code><code>(x) = Delta(d)</code>, when
<code>Delta(d)</code><code class="reqn">\ge</code><code>50</code>, <br />
where  <code class="reqn">\psi</code><code>(x)=lbeta(1+D/2,(N-1)/2)-log(2(2x+(N-1)D)/((N-1)(N+2)x))-(N-1)/2log((N-1)/(N-1+x))-(D/2)log(x/(N-1+x))
</code></p>


<h3>Note</h3>

<p>The values of the penalty function greater than
1e+08 are set to 1e+08.
</p>
<p>If for some <code>Delta(d)</code> the
equation <code class="reqn">\phi</code><code>(x) = exp(-Delta(d)/(d+1))</code>  has no
solution, then the execution is stopped.</p>


<h3>Author(s)</h3>

<p>Yannick Baraud, Christophe Giraud, Sylvie Huet</p>

<hr>
<h2 id='simulData'>simulData</h2><span id='topic+simulData'></span>

<h3>Description</h3>

<p>Function to simulate data <code class="reqn">Y = X \beta + \sigma N(0, 1)</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>simulData(p = 100, n = 100, beta = NULL, C = NULL, r = 0.95, 
    rSN = 10)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulData_+3A_p">p</code></td>
<td>
<p>integer : number of variates. Should be &gt;15 if <code>beta=NULL</code></p>
</td></tr>
<tr><td><code id="simulData_+3A_n">n</code></td>
<td>
<p>integer : number of observations</p>
</td></tr>
<tr><td><code id="simulData_+3A_beta">beta</code></td>
<td>
<p>vector with <code>p</code> components. See details.</p>
</td></tr>
<tr><td><code id="simulData_+3A_c">C</code></td>
<td>
<p>matrix <code>p x p</code>. Covariance matrix of X. See details.</p>
</td></tr>
<tr><td><code id="simulData_+3A_r">r</code></td>
<td>
<p>scalar for calculating the covariance of X when <code>C=NULL</code>.</p>
</td></tr>
<tr><td><code id="simulData_+3A_rsn">rSN</code></td>
<td>
<p>scalar : ratio signal/noise</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>beta</code> is <code>NULL</code>, then <code>p</code> should be
greater than 15 and
<code>beta=c(rep(2.5,5),rep(1.5,5),rep(0.5,5),rep(0,p-15))</code>
</p>
<p>When <code>C</code> is <code>NULL</code>, then <code>C</code> is block
diagonal with <br />
<code>C[a,b] = r**abs(a-b)</code> for <code class="reqn">1 \le a, b \le 15</code> <br />
<code>C[a,b] = r**abs(a-b)</code> for <code class="reqn">16 \le a, b \le p</code> <br />
</p>
<p>The lines of <code>X</code> are <code>n</code> i.i.d. gaussian variables with
mean 0 and covariance matrix <code>C</code>.
</p>
<p>The variance <code>sigma**2</code> equals the squared euclidean
norm of <code class="reqn">X \beta</code> divided by <code>rSN*n</code>.</p>


<h3>Value</h3>

<p>A list with components :
</p>
<table role = "presentation">
<tr><td><code>Y</code></td>
<td>
<p>vector <code>n</code> : <code class="reqn">Y = X \beta + \sigma N(0, 1)</code></p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>matrix <code>n x p</code> : values of the covariates. See
details.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>matrix <code>p x p</code>. See details</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>scalar. See details.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>vector with <code>p</code> components. See details.</p>
</td></tr></table>


<h3>Note</h3>

<p>Library <code>mvtnorm</code> is loaded.</p>


<h3>Author(s)</h3>

<p>Yannick Baraud, Christophe Giraud, Sylvie Huet</p>

<hr>
<h2 id='tuneLasso'>tuneLasso</h2><span id='topic+tuneLasso'></span>

<h3>Description</h3>

<p>tune the  lasso parameter in the 
regression model : <code class="reqn">Y= X \beta + \sigma N(0,1)</code>
using the lasso or the gauss-lasso method</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneLasso(Y, X, normalize = TRUE, method = c("lasso", "Glasso"), 
    dmax = NULL, Vfold = TRUE, V = 10, LINselect = TRUE, a = 0.5, 
    K = 1.1, verbose = TRUE, max.steps = NULL)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tuneLasso_+3A_y">Y</code></td>
<td>
<p>vector with n components : response variable.</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_x">X</code></td>
<td>
<p>matrix with n rows and p columns : covariates.</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_normalize">normalize</code></td>
<td>
<p>logical : corresponds to the input <code>normalize</code>
of the functions <code><a href="elasticnet.html#topic+enet">enet</a></code> and <code><a href="elasticnet.html#topic+cv.enet">cv.enet</a></code>. <br /> If TRUE the variates <code>X</code> are
normalized.</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_method">method</code></td>
<td>
<p>vector of characters whose components are subset of
(&ldquo;lasso&rdquo;, &ldquo;Glasso&rdquo;)</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_dmax">dmax</code></td>
<td>
<p>integer : maximum number of variables in the lasso
estimator. <code>dmax</code> <code class="reqn">\le</code> D where <br /> 
D = min (3*p/4 , n-5) if  p<code class="reqn"> \ge </code>n
<br /> D= min(p,n-5) if
p &lt; n. <br /> Default : <code>dmax</code> = D.</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_vfold">Vfold</code></td>
<td>
<p>logical : if TRUE the tuning is done by Vfold-CV</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_v">V</code></td>
<td>
<p>integer. Gives the value of V in the Vfold-CV procedure</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_linselect">LINselect</code></td>
<td>
<p>logical : if TRUE the tuning is done by LINselect</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_a">a</code></td>
<td>
<p>scalar : value of the parameter <code class="reqn">\alpha</code> in the LINselect criteria</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_k">K</code></td>
<td>
<p>scalar : value of the parameter <code class="reqn">K</code> in the LINselect criteria</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_verbose">verbose</code></td>
<td>
<p>logical : if TRUE a trace of the current process is displayed in real time.</p>
</td></tr>
<tr><td><code id="tuneLasso_+3A_max.steps">max.steps</code></td>
<td>
<p>integer : maximum number of steps in the lasso
procedure. <br /> Corresponds to the input <code>max.steps</code> of the function
<code><a href="elasticnet.html#topic+enet">enet</a></code>. <br />
Default :
<code>max.steps</code> = 2*min(p,n)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with one or two components according to 
<code>method</code>. <br />
<code>lasso</code> if <code>method</code> contains &quot;lasso&quot; is a list with  one or two components
according to <code>Vfold</code> and <code>LINselect</code>.
</p>

<ul>
<li><p><code>Ls</code> if <code>LINselect</code>=TRUE. A list with components
</p>

<ul>
<li><p><code>support</code>: vector of integers. Estimated support of the
parameter vector <code class="reqn">\beta</code>.
</p>
</li>
<li><p><code>coef</code>: vector whose first component is the estimated
intercept. <br /> The other components are the estimated non zero
coefficients.
</p>
</li>
<li><p><code>fitted</code>: vector with length n. Fitted value of
the response.
</p>
</li>
<li><p><code>crit</code>: vector containing the values of the criteria for
each value of <code>lambda</code>.
</p>
</li>
<li><p><code>lambda</code>: vector containing the values of the tuning
parameter of the lasso algorithm.
</p>
</li></ul>


</li>
<li><p><code>CV</code> if <code>Vfold</code>=TRUE. A list with components
</p>

<ul>
<li><p><code>support</code>: vector of integers. Estimated support of the
parameter vector <code class="reqn">\beta</code>.
</p>
</li>
<li><p><code>coef</code>: vector whose first component is the estimated
intercept. <br /> The other components are the estimated non zero
coefficients.
</p>
</li>
<li><p><code>fitted</code>: vector with length n. Fitted value of
the response.
</p>
</li>
<li><p><code>crit</code>: vector containing the values of the criteria for
each value of <code>lambda</code>.
</p>
</li>
<li><p><code>crit.err</code>: vector containing the estimated
standard-error of the criteria.
</p>
</li>
<li><p><code>lambda</code>: vector containing the values of the tuning
parameter of the lasso algorithm.
</p>
</li></ul>


</li></ul>

<p><code>Glasso</code> if <code>method</code> contains &quot;Glasso&quot;. The same as <code>lasso</code>.</p>


<h3>Note</h3>

<p>library <code>elasticnet</code> is loaded.</p>


<h3>Author(s)</h3>

<p>Yannick Baraud, Christophe Giraud, Sylvie Huet</p>


<h3>References</h3>

<p>See Baraud et al. 2010 
<a href="http://hal.archives-ouvertes.fr/hal-00502156/fr/">http://hal.archives-ouvertes.fr/hal-00502156/fr/</a> <br />
Giraud et al., 2013,
<a href="https://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.ss/1356098553">https://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.ss/1356098553</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#source("charge.R")
library("LINselect")

# simulate data with
## Not run: ex &lt;- simulData(p=100,n=100,r=0.8,rSN=5)

## Not run: ex1.tuneLasso &lt;- tuneLasso(ex$Y,ex$X)

## Not run: data(diabetes)
## Not run: attach(diabetes)
## Not run: ex.diab &lt;- tuneLasso(y,x2)
## Not run: detach(diabetes)


</code></pre>

<hr>
<h2 id='VARselect'>VARselect</h2><span id='topic+VARselect'></span>

<h3>Description</h3>

<p>Estimation in the regression model : <code class="reqn">Y= X \beta + \sigma N(0,1)</code><br />
Variable selection by choosing the best predictor among
predictors emanating <br /> from different methods as lasso,
elastic-net, adaptive lasso, pls, randomForest.</p>


<h3>Usage</h3>

<pre><code class='language-R'>VARselect(Y, X, dmax = NULL, normalize = TRUE, method = c("lasso", 
    "ridge", "pls", "en", "ALridge", "ALpls", "rF", "exhaustive"), 
    pen.crit = NULL, lasso.dmax = NULL, ridge.dmax = NULL, pls.dmax = NULL, 
    en.dmax = NULL, ALridge.dmax = NULL, ALpls.dmax = NULL, rF.dmax = NULL, 
    exhaustive.maxdim = 5e+05, exhaustive.dmax = NULL, en.lambda = c(0.01, 
        0.1, 0.5, 1, 2, 5), ridge.lambda = c(0.01, 0.1, 0.5, 
        1, 2, 5), rF.lmtry = 2, pls.ncomp = 5, ALridge.lambda = c(0.01, 
        0.1, 0.5, 1, 2, 5), ALpls.ncomp = 5, max.steps = NULL, 
    K = 1.1, verbose = TRUE, long.output = FALSE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VARselect_+3A_y">Y</code></td>
<td>
<p>vector with n components : response variable.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_x">X</code></td>
<td>
<p>matrix with n rows and p columns : covariates.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_dmax">dmax</code></td>
<td>
<p>integer : maximum number of variables in the lasso
estimator. <code>dmax</code> <code class="reqn">\le</code> D where <br /> 
D = min (3*p/4 , n-5) if  p<code class="reqn"> \ge </code>n
<br /> D= min(p,n-5) if
p &lt; n. <br /> Default : <code>dmax</code> = D.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_normalize">normalize</code></td>
<td>
<p>logical : if TRUE the columns of X are scaled</p>
</td></tr>
<tr><td><code id="VARselect_+3A_method">method</code></td>
<td>
<p>vector of characters  whose components are subset of <br />
&ldquo;lasso&rdquo;, &ldquo;ridge&rdquo;, &ldquo;pls&rdquo;, &ldquo;en&rdquo;,
&ldquo;ALridge&rdquo;, &ldquo;ALpls&rdquo;, &ldquo;rF&rdquo;,
&ldquo;exhaustive&rdquo;.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_pen.crit">pen.crit</code></td>
<td>
<p>vector with <code>dmax</code>+1 components : for d=0,
..., <code>dmax</code>, <code>penalty[d+1]</code> gives the value of the
penalty for the dimension d. Default : <code>penalty</code> = NULL. In
that case, the
penalty will be calculated by the function penalty. </p>
</td></tr>
<tr><td><code id="VARselect_+3A_lasso.dmax">lasso.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_ridge.dmax">ridge.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_pls.dmax">pls.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_en.dmax">en.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_alridge.dmax">ALridge.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_alpls.dmax">ALpls.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_rf.dmax">rF.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_exhaustive.maxdim">exhaustive.maxdim</code></td>
<td>
<p>integer : maximum number of subsets of
covariates considered  in the exhaustive method. See details.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_exhaustive.dmax">exhaustive.dmax</code></td>
<td>
<p>integer lower than <code>dmax</code>, default = <code>dmax</code></p>
</td></tr>
<tr><td><code id="VARselect_+3A_en.lambda">en.lambda</code></td>
<td>
<p>vector : tuning parameter of the
ridge. It is the input parameter <code>lambda</code> of function
<code><a href="elasticnet.html#topic+enet">enet</a></code></p>
</td></tr>
<tr><td><code id="VARselect_+3A_ridge.lambda">ridge.lambda</code></td>
<td>
<p>vector : tuning parameter of the
ridge. It is the input parameter lambda of function
<code><a href="MASS.html#topic+lm.ridge">lm.ridge</a></code></p>
</td></tr>
<tr><td><code id="VARselect_+3A_rf.lmtry">rF.lmtry</code></td>
<td>
<p>vector : tuning paramer <code>mtry</code> of function
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, <code>mtry</code> =p/<code>rF.lmtry</code>.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_pls.ncomp">pls.ncomp</code></td>
<td>
<p>integer : tuning parameter of the pls. It is the
input parameter <code>ncomp</code> of the function
<code><a href="pls.html#topic+mvr">plsr</a></code>. See details.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_alridge.lambda">ALridge.lambda</code></td>
<td>
<p>similar to
<code>ridge.lambda</code> in the adaptive lasso procedure.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_alpls.ncomp">ALpls.ncomp</code></td>
<td>
<p>similar to <code>pls.ncomp</code> in the
adaptive lasso procedure. See details.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_max.steps">max.steps</code></td>
<td>
<p>integer. Maximum number of steps in the lasso
procedure. Corresponds to the input <code>max.steps</code> of the function
<code><a href="elasticnet.html#topic+enet">enet</a></code>. <br />
Default :
<code>max.steps</code> = 2*min(p,n)</p>
</td></tr>
<tr><td><code id="VARselect_+3A_k">K</code></td>
<td>
<p>scalar : value of the parameter <code class="reqn">K</code> in the LINselect criteria.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_verbose">verbose</code></td>
<td>
<p>logical : if TRUE a trace of the current process is displayed in real time.</p>
</td></tr>
<tr><td><code id="VARselect_+3A_long.output">long.output</code></td>
<td>
<p>logical : if FALSE only the component summary
will be returned. See Value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When method is <code>pls</code> or <code>ALpls</code>, the
<code>LINselect</code> procedure is carried out considering the number
of components in the <code>pls</code> method as the tuning
parameter. <br /> This tuning parameter varies from 1 to <code>pls.ncomp</code>.
</p>
<p>When method is <code>exhaustive</code>, the maximum
number of variate d is calculated as
follows.<br />
Let q be the largest integer such that <code>choose(p,q)</code> &lt;
<code>exhaustive.maxdim</code>. Then d = <code>min(q, exhaustive.dmax,dmax)</code>.</p>


<h3>Value</h3>

<p>A list with at least <code>length(method)</code>
components. <br /> 
For each procedure in <code>method</code>  a list with components <br />
</p>

<ul>
<li><p><code>support</code>: vector of integers. Estimated support of the
parameters <code class="reqn">\beta</code> for the considered procedure.
</p>
</li>
<li><p><code>crit</code>: scalar equals to the LINselect criteria
calculated in the estimated support.
</p>
</li>
<li><p><code>fitted</code>: vector  with length n. Fitted value of
the response calculated when the support of <code class="reqn"> \beta</code>
equals <code>support</code>.
</p>
</li>
<li><p><code>coef</code>: vector whose first component is the estimated
intercept. <br /> The other components are the estimated non zero
coefficients when the support of <code class="reqn"> \beta</code>
equals <code>support</code>.
</p>
</li></ul>

<p>If <code>length(method)</code> &gt; 1, the additional component <code>summary</code> is a list with three
components:
</p>
 
<ul>
<li><p><code>support</code>: vector of integers. Estimated support of the
parameters <code class="reqn">\beta</code> corresponding to the minimum
of the criteria among all procedures.
</p>
</li>
<li><p><code>crit</code>:  scalar. Minimum value of the
criteria among all procedures. 
</p>
</li>
<li><p><code>method</code>: vector of characters. Names of the
procedures  for
which the minimum is reached
</p>
</li></ul>

<p>If <code>pen.crit = NULL</code>, the component <code>pen.crit</code> gives the
values of the penalty calculated by the function <code>penalty</code>.
If <code>long.output</code> is TRUE the component named
<code>chatty</code> is a list  with <code>length(method)</code>
components. <br /> 
For each procedure in <code>method</code>, a list with components
</p>

<ul>
<li><p><code>support</code> where <code>support[[l]]</code> is a vector of
integers containing an estimator of the support of the
parameters <code class="reqn"> \beta</code>.
</p>
</li>
<li><p><code>crit</code> : vector where <code>crit[l]</code> contains the
value of the LINselect criteria calculated in
<code>support[[l]]</code>.
</p>
</li></ul>


<h3>Note</h3>

<p>When method is <code>lasso</code>, library <code>elasticnet</code> is loaded.
</p>
<p>When method is <code>en</code>, library <code>elasticnet</code> is loaded.
</p>
<p>When method is <code>ridge</code>, library <code>MASS</code> is loaded.
</p>
<p>When method is <code>rF</code>, library <code>randomForest</code> is loaded.
</p>
<p>When method is <code>pls</code>, library <code>pls</code> is loaded.
</p>
<p>When method is <code>ALridge</code>, libraries <code>MASS</code> and <code>elasticnet</code> are loaded.
</p>
<p>When method is <code>ALpls</code>, libraries <code>pls</code> and <code>elasticnet</code> are loaded.
</p>
<p>When method is <code>exhaustive</code>, library <code>gtools</code>
is loaded.</p>


<h3>Author(s)</h3>

<p>Yannick Baraud, Christophe Giraud, Sylvie Huet</p>


<h3>References</h3>

<p>See Baraud  et al. 2010 
<a href="http://hal.archives-ouvertes.fr/hal-00502156/fr/">http://hal.archives-ouvertes.fr/hal-00502156/fr/</a> <br />
Giraud et al., 2013,
<a href="https://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.ss/1356098553">https://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.ss/1356098553</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#source("charge.R")
library("LINselect")

# simulate data with
# beta=c(rep(2.5,5),rep(1.5,5),rep(0.5,5),rep(0,p-15))
ex &lt;- simulData(p=100,n=100,r=0.8,rSN=5)

## Not run: ex1.VARselect &lt;- VARselect(ex$Y,ex$X,exhaustive.dmax=2)

## Not run: data(diabetes)
## Not run: attach(diabetes)
## Not run: ex.diab &lt;- VARselect(y,x2,exhaustive.dmax=5)
## Not run: detach(diabetes)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
