<!DOCTYPE html><html><head><title>Help for package greta</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {greta}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#greta'><p>greta: simple and scalable statistical modelling in R</p></a></li>
<li><a href='#as_data'><p>convert other objects to greta arrays</p></a></li>
<li><a href='#calculate'><p>calculate greta arrays given fixed values</p></a></li>
<li><a href='#chol2symm'><p>Cholesky Factor to Symmetric Matrix</p></a></li>
<li><a href='#distribution'><p>define a distribution over data</p></a></li>
<li><a href='#distributions'><p>probability distributions</p></a></li>
<li><a href='#extract-replace-combine'><p>extract, replace and combine greta arrays</p></a></li>
<li><a href='#functions'><p>functions for greta arrays</p></a></li>
<li><a href='#greta_notes_install_miniconda_output'><p>Retrieve python installation or error details.</p></a></li>
<li><a href='#greta_sitrep'><p>Greta Situation Report</p></a></li>
<li><a href='#inference'><p>Statistical inference on greta models.</p></a></li>
<li><a href='#install_greta_deps'><p>Install Python dependencies for greta</p></a></li>
<li><a href='#internals'><p>internal greta methods</p></a></li>
<li><a href='#joint'><p>define joint distributions</p></a></li>
<li><a href='#mixture'><p>mixtures of probability distributions</p></a></li>
<li><a href='#model'><p>greta model objects</p></a></li>
<li><a href='#operators'><p>arithmetic, logical and relational operators for greta arrays</p></a></li>
<li><a href='#optimisers'><p>optimisation methods</p></a></li>
<li><a href='#overloaded'><p>Functions overloaded by greta</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#reinstallers'><p>Helpers to remove, and reinstall python environments and miniconda</p></a></li>
<li><a href='#samplers'><p>MCMC samplers</p></a></li>
<li><a href='#simulate.greta_model'><p>Simulate Responses From <code>greta_model</code> Object</p></a></li>
<li><a href='#structures'><p>create data greta arrays</p></a></li>
<li><a href='#transforms'><p>transformation functions for greta arrays</p></a></li>
<li><a href='#variable'><p>create greta variables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simple and Scalable Statistical Modelling in R</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Write statistical models in R and fit them by MCMC and
    optimisation on CPUs and GPUs, using Google 'TensorFlow'.  greta lets
    you write your own model like in BUGS, JAGS and Stan, except that you
    write models right in R, it scales well to massive datasets, and itâ€™s
    easy to extend and build on.  See the website for more information,
    including tutorials, examples, package documentation, and the greta
    forum.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://greta-stats.org">https://greta-stats.org</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/greta-dev/greta/issues">https://github.com/greta-dev/greta/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, callr, cli (&ge; 3.0.0), coda, future (&ge; 1.22.1), glue
(&ge; 1.5.1), methods, parallelly (&ge; 1.29.0), progress (&ge;
1.2.0), R6, reticulate (&ge; 1.19.0), tensorflow (&ge; 2.7.0),
yesno</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bayesplot, covr, cramer, DiagrammeR, DiagrammeRsvg,
extraDistr, fields, ggplot2, knitr, lattice, MASS, MCMCpack,
mockery, mvtnorm, rmarkdown, rmutil, rsvg, spelling, testthat
(&ge; 3.1.0), tidyverse, truncdist, withr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 2.7.0) with header files and shared
library; TensorFlow (v1.14; https://www.tensorflow.org/);
TensorFlow Probability (v0.7.0;
https://www.tensorflow.org/probability/)</td>
</tr>
<tr>
<td>Collate:</td>
<td>'package.R' 'utils.R' 'greta_mcmc_list.R' 'tf_functions.R'
'overloaded.R' 'node_class.R' 'node_types.R' 'variable.R'
'probability_distributions.R' 'mixture.R' 'joint.R'
'unknowns_class.R' 'greta_array_class.R' 'as_data.R'
'distribution.R' 'operators.R' 'functions.R' 'transforms.R'
'structures.R' 'extract_replace_combine.R' 'dag_class.R'
'greta_model_class.R' 'progress_bar.R' 'inference_class.R'
'samplers.R' 'optimisers.R' 'inference.R'
'install_tensorflow.R' 'calculate.R' 'callbacks.R' 'simulate.R'
'chol2symm.R' 'install_greta_deps.R' 'conda_greta_env.R'
'greta_stash.R' 'greta_create_conda_env.R'
'greta_install_miniconda.R' 'greta_install_python_deps.R'
'new_install_process.R' 'reinstallers.R' 'checkers.R'
'test_if_forked_cluster.R' 'testthat-helpers.R' 'zzz.R'
'internals.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-11 06:20:23 UTC; nick</td>
</tr>
<tr>
<td>Author:</td>
<td>Nick Golding <a href="https://orcid.org/0000-0001-8916-5570"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Nicholas Tierney <a href="https://orcid.org/0000-0003-1460-8722"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Simon Dirmeier [ctb],
  Adam Fleischhacker [ctb],
  Shirin Glander [ctb],
  Martin Ingram [ctb],
  Lee Hazel [ctb],
  Lionel Hertzog [ctb],
  Tiphaine Martin [ctb],
  Matt Mulvahill [ctb],
  Michael Quinn [ctb],
  David Smith [ctb],
  Paul Teetor [ctb],
  Jian Yen [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicholas Tierney &lt;nicholas.tierney@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-11 08:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='greta'>greta: simple and scalable statistical modelling in R</h2><span id='topic+greta-package'></span><span id='topic+greta'></span>

<h3>Description</h3>

<p>greta lets you write statistical models interactively in native
R code, then sample from them efficiently using Hamiltonian Monte Carlo.
</p>
<p>The computational heavy lifting is done by TensorFlow, Google's automatic
differentiation library. So greta is particularly fast where the model
contains lots of linear algebra, and greta models can be run across CPU
clusters or on GPUs.
</p>
<p>See the simple example below, and take a look at the
<a href="https://greta-stats.org">greta website</a> for more information
including
<a href="https://greta-stats.org/articles/get_started.html">tutorials</a> and
<a href="https://greta-stats.org/articles/example_models.html">examples</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nicholas Tierney <a href="mailto:nicholas.tierney@gmail.com">nicholas.tierney@gmail.com</a> (<a href="https://orcid.org/0000-0003-1460-8722">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Nick Golding <a href="mailto:nick.golding.research@gmail.com">nick.golding.research@gmail.com</a> (<a href="https://orcid.org/0000-0001-8916-5570">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Simon Dirmeier [contributor]
</p>
</li>
<li><p> Adam Fleischhacker [contributor]
</p>
</li>
<li><p> Shirin Glander [contributor]
</p>
</li>
<li><p> Martin Ingram [contributor]
</p>
</li>
<li><p> Lee Hazel [contributor]
</p>
</li>
<li><p> Lionel Hertzog [contributor]
</p>
</li>
<li><p> Tiphaine Martin [contributor]
</p>
</li>
<li><p> Matt Mulvahill [contributor]
</p>
</li>
<li><p> Michael Quinn [contributor]
</p>
</li>
<li><p> David Smith [contributor]
</p>
</li>
<li><p> Paul Teetor [contributor]
</p>
</li>
<li><p> Jian Yen [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://greta-stats.org">https://greta-stats.org</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/greta-dev/greta/issues">https://github.com/greta-dev/greta/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# a simple Bayesian regression model for the iris data

# priors
int &lt;- normal(0, 5)
coef &lt;- normal(0, 3)
sd &lt;- lognormal(0, 3)

# likelihood
mean &lt;- int + coef * iris$Petal.Length
distribution(iris$Sepal.Length) &lt;- normal(mean, sd)

# build and sample
m &lt;- model(int, coef, sd)
draws &lt;- mcmc(m, n_samples = 100)

## End(Not run)
</code></pre>

<hr>
<h2 id='as_data'>convert other objects to greta arrays</h2><span id='topic+as_data'></span>

<h3>Description</h3>

<p>define an object in an R session as a data greta array for use
as data in a greta model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_data(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_data_+3A_x">x</code></td>
<td>
<p>an R object that can be coerced to a greta_array (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>as_data()</code> can currently convert R objects to greta_arrays if
they are numeric or logical vectors, matrices or arrays; or if they are
dataframes with only numeric (including integer) or logical elements.
Logical elements are always converted to numerics. R objects cannot be
converted if they contain missing (<code>NA</code>) or infinite (<code>-Inf</code> or
<code>Inf</code>) values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# numeric/integer/logical vectors, matrices and arrays can all be coerced to
# data greta arrays

vec &lt;- rnorm(10)
mat &lt;- matrix(seq_len(3 * 4), nrow = 3)
arr &lt;- array(sample(c(TRUE, FALSE), 2 * 2 * 2, replace = TRUE),
  dim = c(2, 2, 2)
)
(a &lt;- as_data(vec))
(b &lt;- as_data(mat))
(c &lt;- as_data(arr))

# dataframes can also be coerced, provided all the columns are numeric,
# integer or logical
df &lt;- data.frame(
  x1 = rnorm(10),
  x2 = sample(1L:10L),
  x3 = sample(c(TRUE, FALSE), 10, replace = TRUE)
)
(d &lt;- as_data(df))

## End(Not run)
</code></pre>

<hr>
<h2 id='calculate'>calculate greta arrays given fixed values</h2><span id='topic+calculate'></span>

<h3>Description</h3>

<p>Calculate the values that greta arrays would take, given
temporary, or simulated values for the greta arrays on which they depend.
This can be used to check the behaviour of your model, make predictions to
new data after model fitting, or simulate datasets from either the prior or
posterior of your model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate(
  ...,
  values = list(),
  nsim = NULL,
  seed = NULL,
  precision = c("double", "single"),
  trace_batch_size = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate_+3A_...">...</code></td>
<td>
<p>one or more greta_arrays for which to calculate the value</p>
</td></tr>
<tr><td><code id="calculate_+3A_values">values</code></td>
<td>
<p>a named list giving temporary values of the greta arrays with
which <code>target</code> is connected, or a <code>greta_mcmc_list</code> object
returned by <code><a href="#topic+mcmc">mcmc()</a></code>.</p>
</td></tr>
<tr><td><code id="calculate_+3A_nsim">nsim</code></td>
<td>
<p>an optional positive integer scalar for the number of responses
to simulate if stochastic greta arrays are present in the model - see
Details.</p>
</td></tr>
<tr><td><code id="calculate_+3A_seed">seed</code></td>
<td>
<p>an optional seed to be used in set.seed immediately before the
simulation so as to generate a reproducible sample</p>
</td></tr>
<tr><td><code id="calculate_+3A_precision">precision</code></td>
<td>
<p>the floating point precision to use when calculating values.</p>
</td></tr>
<tr><td><code id="calculate_+3A_trace_batch_size">trace_batch_size</code></td>
<td>
<p>the number of posterior samples to process at a time
when <code>target</code> is a <code>greta_mcmc_list</code> object; reduce this to
reduce memory demands</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The greta arrays named in <code>values</code> need not be variables, they
can also be other operations or even data.
</p>
<p>At present, if <code>values</code> is a named list it must contain values for
<em>all</em> of the variable greta arrays with which <code>target</code> is
connected, even values are given for intermediate operations, or the target
doesn't depend on the variable. That may be relaxed in a future release.
</p>
<p>If the model contains stochastic greta arrays; those with a distribution,
calculate can be used to sample from these distributions (and all greta
arrays that depend on them) by setting the <code>nsim</code> argument to a
positive integer for the required number of samples. If <code>values</code> is
specified (either as a list of fixed values or as draws), those values will
be used, and remaining variables will be sampled conditional on them.
Observed data with distributions (i.e. response variables defined with
<code>distribution()</code> can also be sampled, provided they are defined as
greta arrays. This behaviour can be used for a number of tasks, like
simulating datasets for known parameter sets, simulating parameters and
data from a set of priors, or simulating datasets from a model posterior.
See some examples of these below.
</p>


<h3>Value</h3>

<p>Values of the target greta array(s), given values of the greta arrays
on which they depend (either specified in <code>values</code> or sampled from
their priors). If <code>values</code> is a
<code><a href="#topic+mcmc">greta_mcmc_list()</a></code> and <code>nsim = NULL</code>, this will
be a <code>greta_mcmc_list</code> object of posterior samples for the target
greta arrays. Otherwise, the result will be a named list of numeric R
arrays. If <code>nsim = NULL</code> the dimensions of returned numeric R arrays
will be the same as the corresponding greta arrays, otherwise an additional
dimension with <code>nsim</code> elements will be prepended, to represent
multiple simulations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# define a variable greta array, and another that is calculated from it
# then calculate what value y would take for different values of x
x &lt;- normal(0, 1, dim = 3)
a &lt;- lognormal(0, 1)
y &lt;- sum(x^2) + a
calculate(y, values = list(x = c(0.1, 0.2, 0.3), a = 2))

# by setting nsim, you can also sample values from their priors
calculate(y, nsim = 3)

# you can combine sampling and fixed values
calculate(y, values = list(a = 2), nsim = 3)

# if the greta array only depends on data,
# you can pass an empty list to values (this is the default)
x &lt;- ones(3, 3)
y &lt;- sum(x)
calculate(y)

# define a model
alpha &lt;- normal(0, 1)
beta &lt;- normal(0, 1)
sigma &lt;- lognormal(1, 0.1)
y &lt;- as_data(iris$Petal.Width)
mu &lt;- alpha + iris$Petal.Length * beta
distribution(y) &lt;- normal(mu, sigma)
m &lt;- model(alpha, beta, sigma)

# sample values of the parameters, or different observation data (y), from
# the priors (useful for prior # predictive checking) - see also
# ?simulate.greta_model
calculate(alpha, beta, sigma, nsim = 100)
calculate(y, nsim = 100)

# calculate intermediate greta arrays, given some parameter values (useful
# for debugging models)
calculate(mu[1:5], values = list(alpha = 1, beta = 2, sigma = 0.5))
calculate(mu[1:5], values = list(alpha = -1, beta = 0.2, sigma = 0.5))

# simulate datasets given fixed parameter values
calculate(y, values = list(alpha = -1, beta = 0.2, sigma = 0.5), nsim = 10)

# you can use calculate in conjunction with posterior samples from MCMC, e.g.
# sampling different observation datasets, given a random set of these
# posterior samples - useful for posterior predictive model checks
draws &lt;- mcmc(m, n_samples = 500)
calculate(y, values = draws, nsim = 100)

# you can use calculate on greta arrays created even after the inference on
# the model - e.g. to plot response curves
petal_length_plot &lt;- seq(min(iris$Petal.Length),
  max(iris$Petal.Length),
  length.out = 100
)
mu_plot &lt;- alpha + petal_length_plot * beta
mu_plot_draws &lt;- calculate(mu_plot, values = draws)
mu_est &lt;- colMeans(mu_plot_draws[[1]])
plot(mu_est ~ petal_length_plot,
  type = "n",
  ylim = range(mu_plot_draws[[1]])
)
apply(mu_plot_draws[[1]], 1, lines,
  x = petal_length_plot, col = grey(0.8)
)
lines(mu_est ~ petal_length_plot, lwd = 2)

# trace_batch_size can be changed to trade off speed against memory usage
# when calculating. These all produce the same result, but have increasing
# memory requirements:
mu_plot_draws_1 &lt;- calculate(mu_plot,
  values = draws,
  trace_batch_size = 1
)
mu_plot_draws_10 &lt;- calculate(mu_plot,
  values = draws,
  trace_batch_size = 10
)
mu_plot_draws_inf &lt;- calculate(mu_plot,
  values = draws,
  trace_batch_size = Inf
)

## End(Not run)
</code></pre>

<hr>
<h2 id='chol2symm'>Cholesky Factor to Symmetric Matrix</h2><span id='topic+chol2symm'></span>

<h3>Description</h3>

<p>Evaluate <code style="white-space: pre;">&#8288;t(x) \%*\% x&#8288;</code> efficiently, where <code>x</code> is the
(upper-triangular) Cholesky factor of a symmetric, positive definite square
matrix. I.e. it is the inverse of <code>chol</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chol2symm(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chol2symm_+3A_x">x</code></td>
<td>
<p>a square, upper triangular matrix representing the Cholesky
factor of a symmetric, positive definite square matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># a symmetric, positive definite square matrix
y &lt;- rWishart(1, 4, diag(3))[, , 1]
u &lt;- chol(y)
identical(y, chol2symm(u))
identical(chol2symm(u), t(u) %*% u)
## Not run: 
u_greta &lt;- cholesky_variable(3)
y_greta &lt;- chol2symm(u)

## End(Not run)
</code></pre>

<hr>
<h2 id='distribution'>define a distribution over data</h2><span id='topic+distribution'></span><span id='topic+distribution+3C-'></span>

<h3>Description</h3>

<p><code>distribution</code> defines probability distributions over
observed data, e.g. to set a model likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distribution(greta_array) &lt;- value

distribution(greta_array)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distribution_+3A_greta_array">greta_array</code></td>
<td>
<p>a data greta array. For the assignment method it must not
already have a probability distribution assigned</p>
</td></tr>
<tr><td><code id="distribution_+3A_value">value</code></td>
<td>
<p>a greta array with a distribution (see
<code><a href="#topic+distributions">distributions()</a></code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extract method returns the greta array if it has a distribution,
or <code>NULL</code> if it doesn't. It has no real use-case, but is included for
completeness
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# define a model likelihood

# observed data and mean parameter to be estimated
# (explicitly coerce data to a greta array so we can refer to it later)
y &lt;- as_data(rnorm(5, 0, 3))

mu &lt;- uniform(-3, 3)

# define the distribution over y (the model likelihood)
distribution(y) &lt;- normal(mu, 1)

# get the distribution over y
distribution(y)

## End(Not run)
</code></pre>

<hr>
<h2 id='distributions'>probability distributions</h2><span id='topic+distributions'></span><span id='topic+uniform'></span><span id='topic+normal'></span><span id='topic+lognormal'></span><span id='topic+bernoulli'></span><span id='topic+binomial'></span><span id='topic+beta_binomial'></span><span id='topic+negative_binomial'></span><span id='topic+hypergeometric'></span><span id='topic+poisson'></span><span id='topic+gamma'></span><span id='topic+inverse_gamma'></span><span id='topic+weibull'></span><span id='topic+exponential'></span><span id='topic+pareto'></span><span id='topic+student'></span><span id='topic+laplace'></span><span id='topic+beta'></span><span id='topic+cauchy'></span><span id='topic+chi_squared'></span><span id='topic+logistic'></span><span id='topic+f'></span><span id='topic+multivariate_normal'></span><span id='topic+wishart'></span><span id='topic+lkj_correlation'></span><span id='topic+multinomial'></span><span id='topic+categorical'></span><span id='topic+dirichlet'></span><span id='topic+dirichlet_multinomial'></span>

<h3>Description</h3>

<p>These functions can be used to define random variables in a
greta model. They return a variable greta array that follows the specified
distribution. This variable greta array can be used to represent a
parameter with prior distribution, combined into a mixture distribution
using <code><a href="#topic+mixture">mixture()</a></code>, or used with <code><a href="#topic+distribution">distribution()</a></code> to
define a distribution over a data greta array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniform(min, max, dim = NULL)

normal(mean, sd, dim = NULL, truncation = c(-Inf, Inf))

lognormal(meanlog, sdlog, dim = NULL, truncation = c(0, Inf))

bernoulli(prob, dim = NULL)

binomial(size, prob, dim = NULL)

beta_binomial(size, alpha, beta, dim = NULL)

negative_binomial(size, prob, dim = NULL)

hypergeometric(m, n, k, dim = NULL)

poisson(lambda, dim = NULL)

gamma(shape, rate, dim = NULL, truncation = c(0, Inf))

inverse_gamma(alpha, beta, dim = NULL, truncation = c(0, Inf))

weibull(shape, scale, dim = NULL, truncation = c(0, Inf))

exponential(rate, dim = NULL, truncation = c(0, Inf))

pareto(a, b, dim = NULL, truncation = c(0, Inf))

student(df, mu, sigma, dim = NULL, truncation = c(-Inf, Inf))

laplace(mu, sigma, dim = NULL, truncation = c(-Inf, Inf))

beta(shape1, shape2, dim = NULL, truncation = c(0, 1))

cauchy(location, scale, dim = NULL, truncation = c(-Inf, Inf))

chi_squared(df, dim = NULL, truncation = c(0, Inf))

logistic(location, scale, dim = NULL, truncation = c(-Inf, Inf))

f(df1, df2, dim = NULL, truncation = c(0, Inf))

multivariate_normal(mean, Sigma, n_realisations = NULL, dimension = NULL)

wishart(df, Sigma)

lkj_correlation(eta, dimension = 2)

multinomial(size, prob, n_realisations = NULL, dimension = NULL)

categorical(prob, n_realisations = NULL, dimension = NULL)

dirichlet(alpha, n_realisations = NULL, dimension = NULL)

dirichlet_multinomial(size, alpha, n_realisations = NULL, dimension = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distributions_+3A_min">min</code>, <code id="distributions_+3A_max">max</code></td>
<td>
<p>scalar values giving optional limits to <code>uniform</code>
variables. Like <code>lower</code> and <code>upper</code>, these must be specified as
numerics, they cannot be greta arrays (though see details for a
workaround). Unlike <code>lower</code> and <code>upper</code>, they must be finite.
<code>min</code> must always be less than <code>max</code>.</p>
</td></tr>
<tr><td><code id="distributions_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers. See details.</p>
</td></tr>
<tr><td><code id="distributions_+3A_mean">mean</code>, <code id="distributions_+3A_meanlog">meanlog</code>, <code id="distributions_+3A_location">location</code>, <code id="distributions_+3A_mu">mu</code></td>
<td>
<p>unconstrained parameters</p>
</td></tr>
<tr><td><code id="distributions_+3A_sd">sd</code>, <code id="distributions_+3A_sdlog">sdlog</code>, <code id="distributions_+3A_sigma">sigma</code>, <code id="distributions_+3A_lambda">lambda</code>, <code id="distributions_+3A_shape">shape</code>, <code id="distributions_+3A_rate">rate</code>, <code id="distributions_+3A_df">df</code>, <code id="distributions_+3A_scale">scale</code>, <code id="distributions_+3A_shape1">shape1</code>, <code id="distributions_+3A_shape2">shape2</code>, <code id="distributions_+3A_alpha">alpha</code>, <code id="distributions_+3A_beta">beta</code>, <code id="distributions_+3A_df1">df1</code>, <code id="distributions_+3A_df2">df2</code>, <code id="distributions_+3A_a">a</code>, <code id="distributions_+3A_b">b</code>, <code id="distributions_+3A_eta">eta</code></td>
<td>
<p>positive parameters, <code>alpha</code> must be a vector for <code>dirichlet</code>
and <code>dirichlet_multinomial</code>.</p>
</td></tr>
<tr><td><code id="distributions_+3A_truncation">truncation</code></td>
<td>
<p>a length-two vector giving values between which to truncate
the distribution, similarly to the <code>lower</code> and <code>upper</code> arguments
to <code><a href="#topic+variable">variable()</a></code></p>
</td></tr>
<tr><td><code id="distributions_+3A_prob">prob</code></td>
<td>
<p>probability parameter (<code style="white-space: pre;">&#8288;0 &lt; prob &lt; 1&#8288;</code>), must be a vector for
<code>multinomial</code> and <code>categorical</code></p>
</td></tr>
<tr><td><code id="distributions_+3A_size">size</code>, <code id="distributions_+3A_m">m</code>, <code id="distributions_+3A_n">n</code>, <code id="distributions_+3A_k">k</code></td>
<td>
<p>positive integer parameter</p>
</td></tr>
<tr><td><code id="distributions_+3A_sigma">Sigma</code></td>
<td>
<p>positive definite variance-covariance matrix parameter</p>
</td></tr>
<tr><td><code id="distributions_+3A_n_realisations">n_realisations</code></td>
<td>
<p>the number of independent realisation of a multivariate
distribution</p>
</td></tr>
<tr><td><code id="distributions_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of a multivariate distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete probability distributions (<code>bernoulli</code>,
<code>binomial</code>, <code>negative_binomial</code>, <code>poisson</code>,
<code>multinomial</code>, <code>categorical</code>, <code>dirichlet_multinomial</code>) can
be used when they have fixed values (e.g. defined as a likelihood using
<code><a href="#topic+distribution">distribution()</a></code>, but not as unknown variables.
</p>
<p>For univariate distributions <code>dim</code> gives the dimensions of the greta
array to create. Each element of the greta array will be (independently)
distributed according to the distribution. <code>dim</code> can also be left at
its default of <code>NULL</code>, in which case the dimension will be detected
from the dimensions of the parameters (provided they are compatible with
one another).
</p>
<p>For multivariate distributions (<code>multivariate_normal()</code>,
<code>multinomial()</code>, <code>categorical()</code>, <code>dirichlet()</code>, and
<code>dirichlet_multinomial()</code>) each row of the output and parameters
corresponds to an independent realisation. If a single realisation or
parameter value is specified, it must therefore be a row vector (see
example). <code>n_realisations</code> gives the number of rows/realisations, and
<code>dimension</code> gives the dimension of the distribution. I.e. a bivariate
normal distribution would be produced with <code>multivariate_normal(..., dimension = 2)</code>. The dimension can usually be detected from the parameters.
</p>
<p><code>multinomial()</code> does not check that observed values sum to
<code>size</code>, and <code>categorical()</code> does not check that only one of the
observed entries is 1. It's the user's responsibility to check their data
matches the distribution!
</p>
<p>The parameters of <code>uniform</code> must be fixed, not greta arrays. This
ensures these values can always be transformed to a continuous scale to run
the samplers efficiently. However, a hierarchical <code>uniform</code> parameter
can always be created by defining a <code>uniform</code> variable constrained
between 0 and 1, and then transforming it to the required scale. See below
for an example.
</p>
<p>Wherever possible, the parameterisations and argument names of greta
distributions match commonly used R functions for distributions, such as
those in the <code>stats</code> or <code>extraDistr</code> packages. The following
table states the distribution function to which greta's implementation
corresponds:
</p>

<table>
<tr>
 <td style="text-align: left;"> greta </td><td style="text-align: left;"> reference</td>
</tr>
<tr>
 <td style="text-align: left;"> <code>uniform</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Uniform">stats::dunif</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>normal</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Normal">stats::dnorm</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>lognormal</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Lognormal">stats::dlnorm</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>bernoulli</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+Bernoulli">extraDistr::dbern</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>binomial</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Binomial">stats::dbinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>beta_binomial</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+BetaBinom">extraDistr::dbbinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>negative_binomial</code>
</td><td style="text-align: left;"> <a href="stats.html#topic+NegBinomial">stats::dnbinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>hypergeometric</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Hypergeometric">stats::dhyper</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>poisson</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Poisson">stats::dpois</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>gamma</code> </td><td style="text-align: left;">
<a href="stats.html#topic+GammaDist">stats::dgamma</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>inverse_gamma</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+InvGamma">extraDistr::dinvgamma</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>weibull</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Weibull">stats::dweibull</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>exponential</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Exponential">stats::dexp</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>pareto</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+Pareto">extraDistr::dpareto</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>student</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+LocationScaleT">extraDistr::dlst</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>laplace</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+Laplace">extraDistr::dlaplace</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>beta</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Beta">stats::dbeta</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>cauchy</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Cauchy">stats::dcauchy</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>chi_squared</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Chisquare">stats::dchisq</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>logistic</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Logistic">stats::dlogis</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>f</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Fdist">stats::df</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>multivariate_normal</code> </td><td style="text-align: left;">
<a href="mvtnorm.html#topic+Mvnorm">mvtnorm::dmvnorm</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>multinomial</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Multinom">stats::dmultinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>categorical</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Multinom">stats::dmultinom</a> (size = 1)</td>
</tr>
<tr>
 <td style="text-align: left;"> <code>dirichlet</code>
</td><td style="text-align: left;"> <a href="extraDistr.html#topic+Dirichlet">extraDistr::ddirichlet</a></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>dirichlet_multinomial</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+DirMnom">extraDistr::ddirmnom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>wishart</code> </td><td style="text-align: left;">
<a href="stats.html#topic+rWishart">stats::rWishart</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>lkj_correlation</code> </td><td style="text-align: left;">
<a href="https://rdrr.io/github/rmcelreath/rethinking/man/dlkjcorr.html">rethinking::dlkjcorr</a>
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# a uniform parameter constrained to be between 0 and 1
phi &lt;- uniform(min = 0, max = 1)

# a length-three variable, with each element following a standard normal
# distribution
alpha &lt;- normal(0, 1, dim = 3)

# a length-three variable of lognormals
sigma &lt;- lognormal(0, 3, dim = 3)

# a hierarchical uniform, constrained between alpha and alpha + sigma,
eta &lt;- alpha + uniform(0, 1, dim = 3) * sigma

# a hierarchical distribution
mu &lt;- normal(0, 1)
sigma &lt;- lognormal(0, 1)
theta &lt;- normal(mu, sigma)

# a vector of 3 variables drawn from the same hierarchical distribution
thetas &lt;- normal(mu, sigma, dim = 3)

# a matrix of 12 variables drawn from the same hierarchical distribution
thetas &lt;- normal(mu, sigma, dim = c(3, 4))

# a multivariate normal variable, with correlation between two elements
# note that the parameter must be a row vector
Sig &lt;- diag(4)
Sig[3, 4] &lt;- Sig[4, 3] &lt;- 0.6
theta &lt;- multivariate_normal(t(rep(mu, 4)), Sig)

# 10 independent replicates of that
theta &lt;- multivariate_normal(t(rep(mu, 4)), Sig, n_realisations = 10)

# 10 multivariate normal replicates, each with a different mean vector,
# but the same covariance matrix
means &lt;- matrix(rnorm(40), 10, 4)
theta &lt;- multivariate_normal(means, Sig, n_realisations = 10)
dim(theta)

# a Wishart variable with the same covariance parameter
theta &lt;- wishart(df = 5, Sigma = Sig)

## End(Not run)
</code></pre>

<hr>
<h2 id='extract-replace-combine'>extract, replace and combine greta arrays</h2><span id='topic+extract-replace-combine'></span><span id='topic+extract'></span><span id='topic+replace'></span><span id='topic+cbind'></span><span id='topic+rbind'></span><span id='topic+c'></span><span id='topic+rep'></span>

<h3>Description</h3>

<p>Generic methods to extract and replace elements of greta arrays,
or to combine greta arrays.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract-replace-combine_+3A_x">x</code></td>
<td>
<p>a greta array</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_i">i</code>, <code id="extract-replace-combine_+3A_j">j</code></td>
<td>
<p>indices specifying elements to extract or replace</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_n">n</code></td>
<td>
<p>a single integer, as in <code>utils::head()</code> and
<code>utils::tail()</code></p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_nrow">nrow</code>, <code id="extract-replace-combine_+3A_ncol">ncol</code></td>
<td>
<p>optional dimensions for the resulting greta array when x is
not a matrix.</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_value">value</code></td>
<td>
<p>for <code style="white-space: pre;">&#8288;[&lt;-&#8288;</code> a greta array to replace elements, for
<code style="white-space: pre;">&#8288;dim&lt;-&#8288;</code> either NULL or a numeric vector of dimensions</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_...">...</code></td>
<td>
<p>either further indices specifying elements to extract or replace
(<code>[</code>), or multiple greta arrays to combine (<code>cbind()</code>,
<code>rbind()</code> &amp; <code>c()</code>), or additional arguments (<code>rep()</code>,
<code>head()</code>, <code>tail()</code>)</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_drop">drop</code>, <code id="extract-replace-combine_+3A_recursive">recursive</code></td>
<td>
<p>generic arguments that are ignored for greta arrays</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>diag()</code> can be used to extract or replace the diagonal part of
a square and two-dimensional greta array, but it cannot be used to create a
matrix-like greta array from a scalar or vector-like greta array. A static
diagonal matrix can always be created with e.g. <code>diag(3)</code>, and then
converted into a greta array.
</p>
<p>Also note that since R 4.0.0, <code>head</code> and <code>tail</code> methods for arrays changed
to print a vector rather than maintain the array structure. The <code>greta</code>
package supports both methods, and will do so based on which version of R
you are using.
</p>


<h3>Usage</h3>

<pre>
# extract
x[i]
x[i, j, ..., drop = FALSE]
head(x, n = 6L, ...)
tail(x, n = 6L, ...)
diag(x, nrow, ncol)

# replace
x[i] &lt;- value
x[i, j, ...] &lt;- value
diag(x) &lt;- value

# combine
cbind(...)
rbind(...)
abind(...)
c(..., recursive = FALSE)
rep(x, times, ..., recursive = FALSE)

# get and set dimensions
length(x)
dim(x)
dim(x) &lt;- value
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- as_data(matrix(1:12, 3, 4))

# extract and replace
x[1:3, ]
x[, 2:4] &lt;- 1:9
e &lt;- diag(x)
diag(x) &lt;- e + 1

# combine
cbind(x[, 2], x[, 1])
rbind(x[1, ], x[3, ])
abind(x[1, ], x[3, ], along = 1)
c(x[, 1], x)
rep(x[, 2], times = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='functions'>functions for greta arrays</h2><span id='topic+functions'></span>

<h3>Description</h3>

<p>This is a list of functions (mostly from base R) that are
currently implemented to transform greta arrays. Also see <a href="#topic+operators">operators</a>
and <a href="#topic+transforms">transforms</a>.
</p>


<h3>Details</h3>

<p>TensorFlow only enables rounding to integers, so <code>round()</code> will
error if <code>digits</code> is set to anything other than <code>0</code>.
</p>
<p>Any additional arguments to <code>chol()</code>, <code>chol2inv</code>, and
<code>solve()</code> will be ignored, see the TensorFlow documentation for
details of these routines.
</p>
<p><code>sweep()</code> only works on two-dimensional greta arrays (so <code>MARGIN</code>
can only be either 1 or 2), and only for subtraction, addition, division
and multiplication.
</p>
<p><code>tapply()</code> works on column vectors (2D greta arrays with one column),
and <code>INDEX</code> cannot be a greta array. Currently five functions are
available, and arguments passed to ... are ignored.
</p>
<p><code>cospi()</code>, <code>sinpi()</code>, and <code>tanpi()</code> do not use the
computationally more stable routines to compute <code>cos(x * pi)</code> etc.
that are available in R under some operating systems. Similarly
<code>trigamma()</code> uses TensorFlow's polygamma function, resulting in lower
precision than R's equivalent.
</p>


<h3>Usage</h3>

<pre>

 # logarithms and exponentials
 log(x)
 exp(x)
 log1p(x)
 expm1(x)

 # miscellaneous mathematics
 abs(x)
 mean(x)
 sqrt(x)
 sign(x)

 # rounding of numbers
 ceiling(x)
 floor(x)
 round(x, digits = 0)

 # trigonometry
 cos(x)
 sin(x)
 tan(x)
 acos(x)
 asin(x)
 atan(x)
 cosh(x)
 sinh(x)
 tanh(x)
 acosh(x)
 asinh(x)
 atanh(x)
 cospi(x)
 sinpi(x)
 tanpi(x)

 # special mathematical functions
 lgamma(x)
 digamma(x)
 trigamma(x)
 choose(n, k)
 lchoose(n, k)

 # matrix operations
 t(x)
 chol(x, ...)
 chol2inv(x, ...)
 cov2cor(V)
 solve(a, b, ...)
 kronecker(X, Y, FUN = c('*', '/', '+', '-'))

 # reducing operations
 sum(..., na.rm = TRUE)
 prod(..., na.rm = TRUE)
 min(..., na.rm = TRUE)
 max(..., na.rm = TRUE)

 # cumulative operations
 cumsum(x)
 cumprod(x)
 cummax(x)
 cummin(x)

 # solve an upper or lower triangular system
 backsolve(r, x, k = ncol(r), upper.tri = TRUE,
           transpose = FALSE)
 forwardsolve(l, x, k = ncol(l), upper.tri = FALSE,
              transpose = FALSE)

 # miscellaneous operations
 aperm(x, perm)
 apply(x, MARGIN, FUN = c("sum", "max", "mean", "min",
                          "prod", "cumsum", "cumprod"))
 sweep(x, MARGIN, STATS, FUN = c('-', '+', '/', '*'))
 tapply(X, INDEX, FUN = c("sum", "max", "mean", "min", "prod"), ...)

</pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- as_data(matrix(1:9, nrow = 3, ncol = 3))
a &lt;- log(exp(x))
b &lt;- log1p(expm1(x))
c &lt;- sign(x - 5)
d &lt;- abs(x - 5)

z &lt;- t(a)

y &lt;- sweep(x, 1, e, "-")

## End(Not run)
</code></pre>

<hr>
<h2 id='greta_notes_install_miniconda_output'>Retrieve python installation or error details.</h2><span id='topic+greta_notes_install_miniconda_output'></span><span id='topic+stash-notes'></span><span id='topic+greta_notes_install_miniconda_error'></span><span id='topic+greta_notes_conda_create_output'></span><span id='topic+greta_notes_conda_create_error'></span><span id='topic+greta_notes_conda_install_output'></span><span id='topic+greta_notes_conda_install_error'></span><span id='topic+greta_notes_tf_num_error'></span>

<h3>Description</h3>

<p>These functions retrieve installation or error information output by python
when running <code>install_miniconda()</code>, <code>conda_create()</code>, <code>conda_install()</code>, or
when encountering a TensorFlow numerical problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_notes_install_miniconda_output()

greta_notes_install_miniconda_error()

greta_notes_conda_create_output()

greta_notes_conda_create_error()

greta_notes_conda_install_output()

greta_notes_conda_install_error()

greta_notes_tf_num_error()
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
greta_notes_install_miniconda()
greta_notes_conda_create()
greta_notes_conda_install()
greta_notes_tf_num_error()
greta_notes_tf_error()

## End(Not run)
</code></pre>

<hr>
<h2 id='greta_sitrep'>Greta Situation Report</h2><span id='topic+greta_sitrep'></span>

<h3>Description</h3>

<p>This checks if Python, Tensorflow, Tensorflow Probability, and the greta
conda environment are available, and also loads and initialises python
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_sitrep()
</code></pre>


<h3>Value</h3>

<p>Message if greta is ready to use
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
greta_sitrep()

## End(Not run)
</code></pre>

<hr>
<h2 id='inference'>Statistical inference on greta models.</h2><span id='topic+inference'></span><span id='topic+mcmc'></span><span id='topic+stashed_samples'></span><span id='topic+extra_samples'></span><span id='topic+initials'></span><span id='topic+opt'></span>

<h3>Description</h3>

<p>Carry out statistical inference on greta models by
MCMC or likelihood/posterior optimisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcmc(
  model,
  sampler = hmc(),
  n_samples = 1000,
  thin = 1,
  warmup = 1000,
  chains = 4,
  n_cores = NULL,
  verbose = TRUE,
  pb_update = 50,
  one_by_one = FALSE,
  initial_values = initials(),
  trace_batch_size = 100
)

stashed_samples()

extra_samples(
  draws,
  n_samples = 1000,
  thin = 1,
  n_cores = NULL,
  verbose = TRUE,
  pb_update = 50,
  one_by_one = FALSE,
  trace_batch_size = 100
)

initials(...)

opt(
  model,
  optimiser = bfgs(),
  max_iterations = 100,
  tolerance = 1e-06,
  initial_values = initials(),
  adjust = TRUE,
  hessian = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inference_+3A_model">model</code></td>
<td>
<p>greta_model object</p>
</td></tr>
<tr><td><code id="inference_+3A_sampler">sampler</code></td>
<td>
<p>sampler used to draw values in MCMC. See
<code><a href="#topic+samplers">samplers()</a></code> for options.</p>
</td></tr>
<tr><td><code id="inference_+3A_n_samples">n_samples</code></td>
<td>
<p>number of MCMC samples to draw per chain (after any warm-up,
but before thinning)</p>
</td></tr>
<tr><td><code id="inference_+3A_thin">thin</code></td>
<td>
<p>MCMC thinning rate; every <code>thin</code> samples is retained, the
rest are discarded</p>
</td></tr>
<tr><td><code id="inference_+3A_warmup">warmup</code></td>
<td>
<p>number of samples to spend warming up the mcmc sampler (moving
chains toward the highest density area and tuning sampler hyperparameters).</p>
</td></tr>
<tr><td><code id="inference_+3A_chains">chains</code></td>
<td>
<p>number of MCMC chains to run</p>
</td></tr>
<tr><td><code id="inference_+3A_n_cores">n_cores</code></td>
<td>
<p>the maximum number of CPU cores used by each sampler (see
details).</p>
</td></tr>
<tr><td><code id="inference_+3A_verbose">verbose</code></td>
<td>
<p>whether to print progress information to the console</p>
</td></tr>
<tr><td><code id="inference_+3A_pb_update">pb_update</code></td>
<td>
<p>how regularly to update the progress bar (in iterations).
If <code>pb_update</code> is less than or equal to <code>thin</code>, it will be set
to <code>thin + 1</code> to ensure at least one saved iteration per
<code>pb_update</code> iterations.</p>
</td></tr>
<tr><td><code id="inference_+3A_one_by_one">one_by_one</code></td>
<td>
<p>whether to run TensorFlow MCMC code one iteration at a
time, so that greta can handle numerical errors as 'bad' proposals (see
below).</p>
</td></tr>
<tr><td><code id="inference_+3A_initial_values">initial_values</code></td>
<td>
<p>an optional <code>initials</code> object (or list of
<code>initials</code> objects of length <code>chains</code>) giving initial values for
some or all of the variables in the model. These will be used as the
starting point for sampling/optimisation.</p>
</td></tr>
<tr><td><code id="inference_+3A_trace_batch_size">trace_batch_size</code></td>
<td>
<p>the number of posterior samples to process at a time
when tracing the parameters of interest; reduce this to reduce memory
demands</p>
</td></tr>
<tr><td><code id="inference_+3A_draws">draws</code></td>
<td>
<p>a greta_mcmc_list object returned by <code>mcmc</code> or
<code>stashed_samples</code></p>
</td></tr>
<tr><td><code id="inference_+3A_...">...</code></td>
<td>
<p>named numeric values, giving initial values of some or all of the
variables in the model (unnamed variables will be automatically
initialised)</p>
</td></tr>
<tr><td><code id="inference_+3A_optimiser">optimiser</code></td>
<td>
<p>an <code>optimiser</code> object giving the optimisation algorithm
and parameters See <code><a href="#topic+optimisers">optimisers()</a></code>.</p>
</td></tr>
<tr><td><code id="inference_+3A_max_iterations">max_iterations</code></td>
<td>
<p>the maximum number of iterations before giving up</p>
</td></tr>
<tr><td><code id="inference_+3A_tolerance">tolerance</code></td>
<td>
<p>the numerical tolerance for the solution, the optimiser
stops when the (absolute) difference in the joint density between
successive iterations drops below this level</p>
</td></tr>
<tr><td><code id="inference_+3A_adjust">adjust</code></td>
<td>
<p>whether to account for Jacobian adjustments in the joint
density. Set to <code>FALSE</code> (and do not use priors) for maximum likelihood
estimates, or <code>TRUE</code> for maximum <em>a posteriori</em> estimates.</p>
</td></tr>
<tr><td><code id="inference_+3A_hessian">hessian</code></td>
<td>
<p>whether to return a list of <em>analytically</em> differentiated
Hessian arrays for the parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>mcmc()</code> if <code>verbose = TRUE</code>, the progress bar shows
the number of iterations so far and the expected time to complete the phase
of model fitting (warmup or sampling). Occasionally, a proposed set of
parameters can cause numerical instability (I.e. the log density or its
gradient is <code>NA</code>, <code>Inf</code> or <code>-Inf</code>); normally because the log
joint density is so low that it can't be represented as a floating point
number. When this happens, the progress bar will also display the
proportion of proposals so far that were 'bad' (numerically unstable) and
therefore rejected. Some numerical instability during the warmup phase is
normal, but 'bad' samples during the sampling phase can lead to bias in
your posterior sample. If you only have a few bad samples (&lt;10\%), you can
usually resolve this with a longer warmup period or by manually defining
starting values to move the sampler into a more reasonable part of the
parameter space. If you have more samples than that, it may be that your
model is misspecified. You can often diagnose this by using
<code><a href="#topic+calculate">calculate()</a></code> to evaluate the values of greta arrays, given
fixed values of model parameters, and checking the results are what you
expect.
</p>
<p>greta runs multiple chains simultaneously with a single sampler,
vectorising all operations across the chains. E.g. a scalar addition in
your model is computed as an elementwise vector addition (with vectors
having length <code>chains</code>), a vector addition is computed as a matrix
addition etc. TensorFlow is able to parallelise these operations, and this
approach reduced computational overheads, so this is the most efficient of
computing on multiple chains.
</p>
<p>Multiple mcmc samplers (each of which can simultaneously run multiple
chains) can also be run in parallel by setting the execution plan with the
<code>future</code> package. Only <code>plan(multisession)</code> futures or
<code>plan(cluster)</code> futures that don't use fork clusters are allowed,
since forked processes conflict with TensorFlow's parallelism. Explicitly
parallelising chains on a local machine with <code>plan(multisession)</code> will
probably be slower than running multiple chains simultaneously in a single
sampler (with <code>plan(sequential)</code>, the default) because of the overhead
required to start new sessions. However, <code>plan(cluster)</code> can be used
to run chains on a cluster of machines on a local or remote network. See
<code><a href="future.html#topic+cluster">future::cluster()</a></code> for details, and the
<code>future.batchtools</code> package to set up plans on clusters with job
schedulers.
</p>
<p>If <code>n_cores = NULL</code> and mcmc samplers are being run sequentially, each
sampler will be allowed to use all CPU cores (possibly to compute multiple
chains sequentially). If samplers are being run in parallel with the
<code>future</code> package, <code>n_cores</code> will be set so that <code style="white-space: pre;">&#8288;n_cores * [future::nbrOfWorkers]&#8288;</code> is less than the number
of CPU cores.
</p>
<p>After carrying out mcmc on all the model parameters, <code>mcmc()</code>
calculates the values of (i.e. traces) the parameters of interest for each
of these samples, similarly to <code><a href="#topic+calculate">calculate()</a></code>. Multiple
posterior samples can be traced simultaneously, though this can require
large amounts of memory for large models. As in <code>calculate</code>, the
argument <code>trace_batch_size</code> can be modified to trade-off speed against
memory usage.
</p>
<p>If the sampler is aborted before finishing (and <code>future</code>
parallelism isn't being used), the samples collected so far can be
retrieved with <code>stashed_samples()</code>. Only samples from the sampling
phase will be returned.
</p>
<p>Samples returned by <code>mcmc()</code> and <code>stashed_samples()</code> can
be added to with <code>extra_samples()</code>. This continues the chain from the
last value of the previous chain and uses the same sampler and model as was
used to generate the previous samples. It is not possible to change the
sampler or extend the warmup period.
</p>
<p>Because <code>opt()</code> acts on a list of greta arrays with possibly
varying dimension, the <code>par</code> and <code>hessian</code> objects returned by
<code>opt()</code> are named lists, rather than a vector (<code>par</code>) and a
matrix (<code>hessian</code>), as returned by <code><a href="stats.html#topic+optim">stats::optim()</a></code>.
Because greta arrays may not be vectors, the Hessians may not be matrices,
but could be higher-dimensional arrays. To return a Hessian matrix covering
multiple model parameters, you can construct your model so that all those
parameters are in a vector, then split the vector up to define the model.
The parameter vector can then be passed to model. See example.
</p>


<h3>Value</h3>

<p><code>mcmc</code>, <code>stashed_samples</code> &amp; <code>extra_samples</code> - a
<code>greta_mcmc_list</code> object that can be analysed using functions from the
coda package. This will contain mcmc samples of the greta arrays used to
create <code>model</code>.
</p>
<p><code>opt</code> - a list containing the following named elements:
</p>

<ul>
<li> <p><code>par</code> a named list of the optimal values for the greta arrays
specified in <code>model</code>
</p>
</li>
<li> <p><code>value</code> the (unadjusted) negative log joint density of the
model at the parameters 'par'
</p>
</li>
<li> <p><code>iterations</code> the number of iterations taken by the optimiser
</p>
</li>
<li> <p><code>convergence</code> an integer code, 0 indicates successful
completion, 1 indicates the iteration limit <code>max_iterations</code> had
been reached
</p>
</li>
<li> <p><code>hessian</code> (if <code>hessian = TRUE</code>) a named list of hessian
matrices/arrays for the parameters (w.r.t. <code>value</code>)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# define a simple Bayesian model
x &lt;- rnorm(10)
mu &lt;- normal(0, 5)
sigma &lt;- lognormal(1, 0.1)
distribution(x) &lt;- normal(mu, sigma)
m &lt;- model(mu, sigma)

# carry out mcmc on the model
draws &lt;- mcmc(m, n_samples = 100)

# add some more samples
draws &lt;- extra_samples(draws, 200)

#' # initial values can be passed for some or all model variables
draws &lt;- mcmc(m, chains = 1, initial_values = initials(mu = -1))

# if there are multiple chains, a list of initial values should be passed,
# othewise the same initial values will be used for all chains
inits &lt;- list(initials(sigma = 0.5), initials(sigma = 1))
draws &lt;- mcmc(m, chains = 2, initial_values = inits)

# you can auto-generate a list of initials with something like this:
inits &lt;- replicate(4,
  initials(mu = rnorm(1), sigma = runif(1)),
  simplify = FALSE
)
draws &lt;- mcmc(m, chains = 4, initial_values = inits)

# or find the MAP estimate
opt_res &lt;- opt(m)

# get the MLE of the normal variance
mu &lt;- variable()
variance &lt;- variable(lower = 0)
distribution(x) &lt;- normal(mu, sqrt(variance))
m2 &lt;- model(variance)

# adjust = FALSE skips the jacobian adjustments used in MAP estimation, to
# give the true maximum likelihood estimates
o &lt;- opt(m2, adjust = FALSE)

# the MLE corresponds to the *unadjusted* sample variance, but differs
# from the sample variance
o$par
mean((x - mean(x))^2) # same
var(x) # different

# initial values can also be passed to optimisers:
o &lt;- opt(m2, initial_values = initials(variance = 1))

# and you can return a list of the Hessians for each of these parameters
o &lt;- opt(m2, hessian = TRUE)
o$hessian


# to get a hessian matrix across multiple greta arrays, you must first
# combine them and then split them up for use in the model (so that the
# combined vector is part of the model) and pass that vector to model:
params &lt;- c(variable(), variable(lower = 0))
mu &lt;- params[1]
variance &lt;- params[2]
distribution(x) &lt;- normal(mu, sqrt(variance))
m3 &lt;- model(params)
o &lt;- opt(m3, hessian = TRUE)
o$hessian

## End(Not run)
</code></pre>

<hr>
<h2 id='install_greta_deps'>Install Python dependencies for greta</h2><span id='topic+install_greta_deps'></span><span id='topic+reinstall_greta_deps'></span>

<h3>Description</h3>

<p>This is a helper function to install Python dependencies needed. This
includes Tensorflow version 1.14.0, Tensorflow Probability 0.7.0, and
numpy version 1.16.4. These Python modules will be installed into a
virtual or conda environment, named &quot;greta-env&quot;. Note that &quot;virtualenv&quot; is
not available on Windows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_greta_deps(
  method = c("auto", "virtualenv", "conda"),
  conda = "auto",
  timeout = 5,
  ...
)

reinstall_greta_deps(
  method = c("auto", "virtualenv", "conda"),
  conda = "auto",
  timeout = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_greta_deps_+3A_method">method</code></td>
<td>
<p>Installation method (&quot;virtualenv&quot; or &quot;conda&quot;)</p>
</td></tr>
<tr><td><code id="install_greta_deps_+3A_conda">conda</code></td>
<td>
<p>The path to a <code>conda</code> executable. Use <code>"auto"</code> to allow
<code>reticulate</code> to automatically find an appropriate <code>conda</code> binary. See
<strong>Finding Conda</strong> for more details.</p>
</td></tr>
<tr><td><code id="install_greta_deps_+3A_timeout">timeout</code></td>
<td>
<p>maximum time in minutes until the installation for each
installation component times out and exits. Default is 5 minutes per
installation component.</p>
</td></tr>
<tr><td><code id="install_greta_deps_+3A_...">...</code></td>
<td>
<p>Optional arguments, reserved for future expansion.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This will automatically install Miniconda (a minimal version of the
Anaconda scientific software management system), create a 'conda'
environment for greta named 'greta-env' with required python and python
package versions, and forcibly switch over to using that conda environment.
</p>
<p>If you don't want to use conda or the &quot;greta-env&quot; conda environment, you
can install these specific versions of tensorflow (version 1.14.0), and
tensorflow-probability (version 0.7.0), and ensure that the python
environment that is initialised in this R session has these versions
installed. This is now always straightforward, so we recommend installing
the python packages using <code>install_greta_deps()</code> for most users.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
install_greta_deps()

## End(Not run)
## Not run: 
# to help troubleshoot your greta installation, this can help resolve some
# issues with installing greta dependencies
reinstall_greta_deps()

## End(Not run)
</code></pre>

<hr>
<h2 id='internals'>internal greta methods</h2><span id='topic+internals'></span><span id='topic+.internals'></span>

<h3>Description</h3>

<p>A list of functions and R6 class objects that can be used to
develop extensions to greta. Most users will not need to access these
methods, and it is not recommended to use them directly in model code.
</p>


<h3>Details</h3>

<p>This help file lists the available internals, but they are not fully
documented and are subject to change and deprecation without warning (though
care will be taken not to break dependent packages on CRAN). For an overview
of how greta works internally, see the <em>technical details</em> vignette. See
<a href="https://github.com/greta-dev">https://github.com/greta-dev</a> for examples of R packages extending and
building on greta.
</p>
<p>Please get in contact via GitHub if you want to develop an extension to
greta and need more details of how to use these internal functions.
</p>
<p>You can use <code>attach()</code> to put a sublist in the search path. E.g.
<code>attach(.internals$nodes$constructors)</code> will enable you to call
<code>op()</code>, <code>vble()</code> and <code>distrib()</code> directly.
</p>


<h3>Usage</h3>

<pre>
 .internals$greta_arrays$unknowns        # greta array print methods
 .internals$inference$progress_bar       # progress bar tools
                      samplers           # MCMC samplers
                      stash              # stashing MCMC samples
 .internals$nodes$constructors           # node creation wrappers
                  distribution_classes   # R6 distribution classes
                  mixture_classes        # R6 mixture distribution classes
                  node_classes           # R6 node classes
 .internals$tensors                      # functions on tensors
 .internals$utils$checks                 # checking function inputs
                  colours                # greta colour scheme
                  dummy_arrays           # mocking up extract/replace
                  misc                   # code simplification etc.
                  samplers               # mcmc helpers
 .internals$greta_stash                  # internal information storage
</pre>

<hr>
<h2 id='joint'>define joint distributions</h2><span id='topic+joint'></span>

<h3>Description</h3>

<p><code>joint</code> combines univariate probability distributions
together into a multivariate (and <em>a priori</em> independent between
dimensions) joint distribution, either over a variable, or for fixed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joint(..., dim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="joint_+3A_...">...</code></td>
<td>
<p>scalar variable greta arrays following probability distributions
(see <code><a href="#topic+distributions">distributions()</a></code>); the components of the joint
distribution.</p>
</td></tr>
<tr><td><code id="joint_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers. The final dimension of the greta array
returned will be determined by the number of component distributions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The component probability distributions must all be either
continuous or discrete, and must have the same dimensions.
</p>
<p>This functionality is unlikely to be useful in most models, since the same
result can usually be achieved by combining variables with separate
distributions. It is included for situations where it is more convenient to
consider these as a single distribution, e.g. for use with
<code>distribution</code> or <code>mixture</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# an uncorrelated bivariate normal
x &lt;- joint(normal(-3, 0.5), normal(3, 0.5))
m &lt;- model(x)
plot(mcmc(m, n_samples = 500))

# joint distributions can be used to define densities over data
x &lt;- cbind(rnorm(10, 2, 0.5), rbeta(10, 3, 3))
mu &lt;- normal(0, 10)
sd &lt;- normal(0, 3, truncation = c(0, Inf))
a &lt;- normal(0, 3, truncation = c(0, Inf))
b &lt;- normal(0, 3, truncation = c(0, Inf))
distribution(x) &lt;- joint(normal(mu, sd), beta(a, b),
  dim = 10
)
m &lt;- model(mu, sd, a, b)
plot(mcmc(m))

## End(Not run)
</code></pre>

<hr>
<h2 id='mixture'>mixtures of probability distributions</h2><span id='topic+mixture'></span>

<h3>Description</h3>

<p><code>mixture</code> combines other probability distributions into a
single mixture distribution, either over a variable, or for fixed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixture(..., weights, dim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixture_+3A_...">...</code></td>
<td>
<p>variable greta arrays following probability distributions (see
<code><a href="#topic+distributions">distributions()</a></code>); the component distributions in a mixture
distribution.</p>
</td></tr>
<tr><td><code id="mixture_+3A_weights">weights</code></td>
<td>
<p>a column vector or array of mixture weights, which must be
positive, but need not sum to one. The first dimension must be the number
of distributions, the remaining dimensions must either be 1 or match the
distribution dimension.</p>
</td></tr>
<tr><td><code id="mixture_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>weights</code> are rescaled to sum to one along the first
dimension, and are then used as the mixing weights of the distribution.
I.e. the probability density is calculated as a weighted sum of the
component probability distributions passed in via <code style="white-space: pre;">&#8288;\dots&#8288;</code>
</p>
<p>The component probability distributions must all be either continuous or
discrete, and must have the same dimensions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# a scalar variable following a strange bimodal distibution
weights &lt;- uniform(0, 1, dim = 3)
a &lt;- mixture(normal(-3, 0.5),
  normal(3, 0.5),
  normal(0, 3),
  weights = weights
)
m &lt;- model(a)
plot(mcmc(m, n_samples = 500))

# simulate a mixture of poisson random variables and try to recover the
# parameters with a Bayesian model
x &lt;- c(
  rpois(800, 3),
  rpois(200, 10)
)

weights &lt;- uniform(0, 1, dim = 2)
rates &lt;- normal(0, 10, truncation = c(0, Inf), dim = 2)
distribution(x) &lt;- mixture(poisson(rates[1]),
  poisson(rates[2]),
  weights = weights
)
m &lt;- model(rates)
draws_rates &lt;- mcmc(m, n_samples = 500)

# check the mixing probabilities after fitting using calculate()
# (you could also do this within the model)
normalized_weights &lt;- weights / sum(weights)
draws_weights &lt;- calculate(normalized_weights, draws_rates)

# get the posterior means
summary(draws_rates)$statistics[, "Mean"]
summary(draws_weights)$statistics[, "Mean"]

# weights can also be an array, giving different mixing weights
# for each observation (first dimension must be number of components)
dim &lt;- c(5, 4)
weights &lt;- uniform(0, 1, dim = c(2, dim))
b &lt;- mixture(normal(1, 1, dim = dim),
  normal(-1, 1, dim = dim),
  weights = weights
)

## End(Not run)
</code></pre>

<hr>
<h2 id='model'>greta model objects</h2><span id='topic+model'></span><span id='topic+print.greta_model'></span><span id='topic+plot.greta_model'></span>

<h3>Description</h3>

<p>Create a <code>greta_model</code> object representing a statistical
model (using <code>model</code>), and plot a graphical representation of the
model. Statistical inference can be performed on <code>greta_model</code> objects
with <code><a href="#topic+mcmc">mcmc()</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model(..., precision = c("double", "single"), compile = TRUE)

## S3 method for class 'greta_model'
print(x, ...)

## S3 method for class 'greta_model'
plot(x, y, colour = "#996bc7", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_+3A_...">...</code></td>
<td>
<p>for <code>model</code>: <code>greta_array</code> objects to be tracked by
the model (i.e. those for which samples will be retained during mcmc). If
not provided, all of the non-data <code>greta_array</code> objects defined in the
calling environment will be tracked. For <code>print</code> and
<code>plot</code>:further arguments passed to or from other methods (currently
ignored).</p>
</td></tr>
<tr><td><code id="model_+3A_precision">precision</code></td>
<td>
<p>the floating point precision to use when evaluating this
model. Switching from <code>"double"</code> (the default) to <code>"single"</code> may
decrease the computation time but increase the risk of numerical
instability during sampling.</p>
</td></tr>
<tr><td><code id="model_+3A_compile">compile</code></td>
<td>
<p>whether to apply
<a href="https://openxla.org/xla">XLA JIT compilation</a> to
the TensorFlow graph representing the model. This may slow down model
definition, and speed up model evaluation.</p>
</td></tr>
<tr><td><code id="model_+3A_x">x</code></td>
<td>
<p>a <code>greta_model</code> object</p>
</td></tr>
<tr><td><code id="model_+3A_y">y</code></td>
<td>
<p>unused default argument</p>
</td></tr>
<tr><td><code id="model_+3A_colour">colour</code></td>
<td>
<p>base colour used for plotting. Defaults to <code>greta</code> colours
in violet.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>model()</code> takes greta arrays as arguments, and defines a
statistical model by finding all of the other greta arrays on which they
depend, or which depend on them. Further arguments to <code>model</code> can be
used to configure the TensorFlow graph representing the model, to tweak
performance.
</p>
<p>The plot method produces a visual representation of the defined
model. It uses the <code>DiagrammeR</code> package, which must be installed
first. Here's a key to the plots:
<img src="../help/figures/plotlegend.png" width="100%" alt="plotlegend.png" />

</p>


<h3>Value</h3>

<p><code>model</code> - a <code>greta_model</code> object.
</p>
<p><code>plot</code> - a <code><a href="DiagrammeR.html#topic+grViz">DiagrammeR::grViz()</a></code>
object, with the
<code><a href="DiagrammeR.html#topic+create_graph">DiagrammeR::dgr_graph()</a></code> object used to
create it as an attribute <code>"dgr_graph"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# define a simple model
mu &lt;- variable()
sigma &lt;- normal(0, 3, truncation = c(0, Inf))
x &lt;- rnorm(10)
distribution(x) &lt;- normal(mu, sigma)

m &lt;- model(mu, sigma)

plot(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='operators'>arithmetic, logical and relational operators for greta arrays</h2><span id='topic+operators'></span>

<h3>Description</h3>

<p>This is a list of currently implemented arithmetic, logical and
relational operators to combine greta arrays into probabilistic models.
Also see <a href="#topic+functions">functions</a> and <a href="#topic+transforms">transforms</a>.
</p>


<h3>Details</h3>

<p>greta's operators are used just like R's the standard arithmetic,
logical and relational operators, but they return other greta arrays. Since
the operations are only carried during sampling, the greta array objects
have unknown values.
</p>


<h3>Usage</h3>

<pre>
 # arithmetic operators
 -x
 x + y
 x - y
 x * y
 x / y
 x ^ y
 x %% y
 x %/% y
 x %*% y

 # logical operators
 !x
 x &amp; y
 x | y

 # relational operators
 x &lt; y
 x &gt; y
 x &lt;= y
 x &gt;= y
 x == y
 x != y
 </pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- as_data(-1:12)

# arithmetic
a &lt;- x + 1
b &lt;- 2 * x + 3
c &lt;- x %% 2
d &lt;- x %/% 5

# logical
e &lt;- (x &gt; 1) | (x &lt; 1)
f &lt;- e &amp; (x &lt; 2)
g &lt;- !f

# relational
h &lt;- x &lt; 1
i &lt;- (-x) &gt;= x
j &lt;- h == x

## End(Not run)
</code></pre>

<hr>
<h2 id='optimisers'>optimisation methods</h2><span id='topic+optimisers'></span><span id='topic+nelder_mead'></span><span id='topic+powell'></span><span id='topic+cg'></span><span id='topic+bfgs'></span><span id='topic+newton_cg'></span><span id='topic+l_bfgs_b'></span><span id='topic+tnc'></span><span id='topic+cobyla'></span><span id='topic+slsqp'></span><span id='topic+gradient_descent'></span><span id='topic+adadelta'></span><span id='topic+adagrad'></span><span id='topic+adagrad_da'></span><span id='topic+momentum'></span><span id='topic+adam'></span><span id='topic+ftrl'></span><span id='topic+proximal_gradient_descent'></span><span id='topic+proximal_adagrad'></span><span id='topic+rms_prop'></span>

<h3>Description</h3>

<p>Functions to set up optimisers (which find parameters that
maximise the joint density of a model) and change their tuning parameters,
for use in <code><a href="#topic+opt">opt()</a></code>. For details of the algorithms and how to
tune them, see the
<a href="https://docs.scipy.org/doc/scipy/tutorial/optimize.html?highlight=optimize">SciPy optimiser docs</a> or the
<a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib">TensorFlow optimiser docs</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nelder_mead()

powell()

cg()

bfgs()

newton_cg()

l_bfgs_b(maxcor = 10, maxls = 20)

tnc(max_cg_it = -1, stepmx = 0, rescale = -1)

cobyla(rhobeg = 1)

slsqp()

gradient_descent(learning_rate = 0.01)

adadelta(learning_rate = 0.001, rho = 1, epsilon = 1e-08)

adagrad(learning_rate = 0.8, initial_accumulator_value = 0.1)

adagrad_da(
  learning_rate = 0.8,
  global_step = 1L,
  initial_gradient_squared_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

momentum(learning_rate = 0.001, momentum = 0.9, use_nesterov = TRUE)

adam(learning_rate = 0.1, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-08)

ftrl(
  learning_rate = 1,
  learning_rate_power = -0.5,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

proximal_gradient_descent(
  learning_rate = 0.01,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

proximal_adagrad(
  learning_rate = 1,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

rms_prop(learning_rate = 0.1, decay = 0.9, momentum = 0, epsilon = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimisers_+3A_maxcor">maxcor</code></td>
<td>
<p>maximum number of 'variable metric corrections' used to define
the approximation to the hessian matrix</p>
</td></tr>
<tr><td><code id="optimisers_+3A_maxls">maxls</code></td>
<td>
<p>maximum number of line search steps per iteration</p>
</td></tr>
<tr><td><code id="optimisers_+3A_max_cg_it">max_cg_it</code></td>
<td>
<p>maximum number of hessian * vector evaluations per iteration</p>
</td></tr>
<tr><td><code id="optimisers_+3A_stepmx">stepmx</code></td>
<td>
<p>maximum step for the line search</p>
</td></tr>
<tr><td><code id="optimisers_+3A_rescale">rescale</code></td>
<td>
<p>log10 scaling factor used to trigger rescaling of objective</p>
</td></tr>
<tr><td><code id="optimisers_+3A_rhobeg">rhobeg</code></td>
<td>
<p>reasonable initial changes to the variables</p>
</td></tr>
<tr><td><code id="optimisers_+3A_learning_rate">learning_rate</code></td>
<td>
<p>the size of steps (in parameter space) towards the
optimal value</p>
</td></tr>
<tr><td><code id="optimisers_+3A_rho">rho</code></td>
<td>
<p>the decay rate</p>
</td></tr>
<tr><td><code id="optimisers_+3A_epsilon">epsilon</code></td>
<td>
<p>a small constant used to condition gradient updates</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_accumulator_value">initial_accumulator_value</code></td>
<td>
<p>initial value of the 'accumulator' used to
tune the algorithm</p>
</td></tr>
<tr><td><code id="optimisers_+3A_global_step">global_step</code></td>
<td>
<p>the current training step number</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_gradient_squared_accumulator_value">initial_gradient_squared_accumulator_value</code></td>
<td>
<p>initial value of the
accumulators used to tune the algorithm</p>
</td></tr>
<tr><td><code id="optimisers_+3A_l1_regularization_strength">l1_regularization_strength</code></td>
<td>
<p>L1 regularisation coefficient (must be 0 or
greater)</p>
</td></tr>
<tr><td><code id="optimisers_+3A_l2_regularization_strength">l2_regularization_strength</code></td>
<td>
<p>L2 regularisation coefficient (must be 0 or
greater)</p>
</td></tr>
<tr><td><code id="optimisers_+3A_momentum">momentum</code></td>
<td>
<p>the momentum of the algorithm</p>
</td></tr>
<tr><td><code id="optimisers_+3A_use_nesterov">use_nesterov</code></td>
<td>
<p>whether to use Nesterov momentum</p>
</td></tr>
<tr><td><code id="optimisers_+3A_beta1">beta1</code></td>
<td>
<p>exponential decay rate for the 1st moment estimates</p>
</td></tr>
<tr><td><code id="optimisers_+3A_beta2">beta2</code></td>
<td>
<p>exponential decay rate for the 2nd moment estimates</p>
</td></tr>
<tr><td><code id="optimisers_+3A_learning_rate_power">learning_rate_power</code></td>
<td>
<p>power on the learning rate, must be 0 or less</p>
</td></tr>
<tr><td><code id="optimisers_+3A_decay">decay</code></td>
<td>
<p>discounting factor for the gradient</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimisers <code>powell()</code>, <code>cg()</code>, <code>newton_cg()</code>,
<code>l_bfgs_b()</code>, <code>tnc()</code>, <code>cobyla()</code>, and <code>slsqp()</code> are
deprecated. They will be removed in greta 0.4.0, since they will no longer
be available in TensorFlow 2.0, on which that version of greta will depend.
</p>
<p>The <code>cobyla()</code> does not provide information about the number of
iterations nor convergence, so these elements of the output are set to NA
</p>


<h3>Value</h3>

<p>an <code>optimiser</code> object that can be passed to <code><a href="#topic+opt">opt()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# use optimisation to find the mean and sd of some data
x &lt;- rnorm(100, -2, 1.2)
mu &lt;- variable()
sd &lt;- variable(lower = 0)
distribution(x) &lt;- normal(mu, sd)
m &lt;- model(mu, sd)

# configure optimisers &amp; parameters via 'optimiser' argument to opt
opt_res &lt;- opt(m, optimiser = bfgs())

# compare results with the analytic solution
opt_res$par
c(mean(x), sd(x))

## End(Not run)
</code></pre>

<hr>
<h2 id='overloaded'>Functions overloaded by greta</h2><span id='topic+overloaded'></span><span id='topic++25+2A+25'></span><span id='topic+chol2inv'></span><span id='topic+cov2cor'></span><span id='topic+identity'></span><span id='topic+colMeans'></span><span id='topic+rowMeans'></span><span id='topic+colSums'></span><span id='topic+rowSums'></span><span id='topic+sweep'></span><span id='topic+backsolve'></span><span id='topic+forwardsolve'></span><span id='topic+apply'></span><span id='topic+tapply'></span><span id='topic+eigen'></span><span id='topic+rdist'></span><span id='topic+abind'></span><span id='topic+diag'></span>

<h3>Description</h3>

<p>greta provides a wide range of methods to apply common R
functions and operations to <code>greta_array</code> objects. A few of these
functions and operators are not associated with a class system, so they are
overloaded here. This should not affect normal use of these functions, but
they need to be documented to satisfy CRAN's check.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %*% y

chol2inv(x, size = NCOL(x), LINPACK = FALSE)

cov2cor(V)

identity(x)

colMeans(x, na.rm = FALSE, dims = 1L)

rowMeans(x, na.rm = FALSE, dims = 1L)

colSums(x, na.rm = FALSE, dims = 1L)

rowSums(x, na.rm = FALSE, dims = 1L)

sweep(x, MARGIN, STATS, FUN = "-", check.margin = TRUE, ...)

backsolve(r, x, k = ncol(r), upper.tri = TRUE, transpose = FALSE)

forwardsolve(l, x, k = ncol(l), upper.tri = FALSE, transpose = FALSE)

apply(X, MARGIN, FUN, ...)

tapply(X, INDEX, FUN, ...)

eigen(x, symmetric, only.values, EISPACK)

rdist(x1, x2 = NULL, compact = FALSE)

abind(
  ...,
  along = N,
  rev.along = NULL,
  new.names = NULL,
  force.array = TRUE,
  make.names = use.anon.names,
  use.anon.names = FALSE,
  use.first.dimnames = FALSE,
  hier.names = FALSE,
  use.dnns = FALSE
)

diag(x = 1, nrow, ncol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overloaded_+3A_x">x</code>, <code id="overloaded_+3A_y">y</code>, <code id="overloaded_+3A_size">size</code>, <code id="overloaded_+3A_linpack">LINPACK</code>, <code id="overloaded_+3A_v">V</code>, <code id="overloaded_+3A_na.rm">na.rm</code>, <code id="overloaded_+3A_dims">dims</code>, <code id="overloaded_+3A_margin">MARGIN</code>, <code id="overloaded_+3A_stats">STATS</code>, <code id="overloaded_+3A_fun">FUN</code>, <code id="overloaded_+3A_check.margin">check.margin</code>, <code id="overloaded_+3A_...">...</code>, <code id="overloaded_+3A_r">r</code>, <code id="overloaded_+3A_k">k</code>, <code id="overloaded_+3A_upper.tri">upper.tri</code>, <code id="overloaded_+3A_transpose">transpose</code>, <code id="overloaded_+3A_l">l</code>, <code id="overloaded_+3A_x">X</code>, <code id="overloaded_+3A_index">INDEX</code>, <code id="overloaded_+3A_symmetric">symmetric</code>, <code id="overloaded_+3A_only.values">only.values</code>, <code id="overloaded_+3A_eispack">EISPACK</code>, <code id="overloaded_+3A_x1">x1</code>, <code id="overloaded_+3A_x2">x2</code>, <code id="overloaded_+3A_compact">compact</code>, <code id="overloaded_+3A_along">along</code>, <code id="overloaded_+3A_rev.along">rev.along</code>, <code id="overloaded_+3A_new.names">new.names</code>, <code id="overloaded_+3A_force.array">force.array</code>, <code id="overloaded_+3A_make.names">make.names</code>, <code id="overloaded_+3A_use.anon.names">use.anon.names</code>, <code id="overloaded_+3A_use.first.dimnames">use.first.dimnames</code>, <code id="overloaded_+3A_hier.names">hier.names</code>, <code id="overloaded_+3A_use.dnns">use.dnns</code>, <code id="overloaded_+3A_nrow">nrow</code>, <code id="overloaded_+3A_ncol">ncol</code></td>
<td>
<p>arguments as in original documentation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that, since R 3.1, the LINPACK argument is defunct and silently ignored.
The argument is only included for compatibility with the base functions
that call it.
</p>
<p>To find the original help file for these overloaded functions, search for
the function, e.g., <code>?cov2cor</code> and select the non-greta function.
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+install_tensorflow'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+install_tensorflow">install_tensorflow</a></code></p>
</dd>
</dl>

<hr>
<h2 id='reinstallers'>Helpers to remove, and reinstall python environments and miniconda</h2><span id='topic+reinstallers'></span><span id='topic+remove_greta_env'></span><span id='topic+reinstall_greta_env'></span><span id='topic+remove_miniconda'></span><span id='topic+reinstall_miniconda'></span>

<h3>Description</h3>

<p>This can be useful when debugging greta installation to get to &quot;clean slate&quot;.
There are four functions:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_greta_env()

reinstall_greta_env(timeout = 5)

remove_miniconda()

reinstall_miniconda(timeout = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reinstallers_+3A_timeout">timeout</code></td>
<td>
<p>time in minutes to wait until timeout (default is 5 minutes)</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code>remove_greta_env()</code> removes the 'greta-env' conda environment
</p>
</li>
<li> <p><code>remove_miniconda()</code> removes miniconda installation
</p>
</li>
<li> <p><code>reinstall_greta_env()</code> remove 'greta-env' and reinstall it using <code>greta_create_conda_env()</code> (which is used internally).
</p>
</li>
<li> <p><code>reinstall_miniconda()</code> removes miniconda and reinstalls it using <code>greta_install_miniconda()</code> (which is used internally)
</p>
</li></ul>



<h3>Value</h3>

<p>invisible
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
remove_greta_env()
remove_miniconda()
reinstall_greta_env()
reinstall_miniconda()

## End(Not run)
</code></pre>

<hr>
<h2 id='samplers'>MCMC samplers</h2><span id='topic+samplers'></span><span id='topic+hmc'></span><span id='topic+rwmh'></span><span id='topic+slice'></span>

<h3>Description</h3>

<p>Functions to set up MCMC samplers and change the starting values
of their parameters, for use in <code><a href="#topic+mcmc">mcmc()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hmc(Lmin = 5, Lmax = 10, epsilon = 0.1, diag_sd = 1)

rwmh(proposal = c("normal", "uniform"), epsilon = 0.1, diag_sd = 1)

slice(max_doublings = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="samplers_+3A_lmin">Lmin</code></td>
<td>
<p>minimum number of leapfrog steps (positive integer, Lmin &gt; Lmax)</p>
</td></tr>
<tr><td><code id="samplers_+3A_lmax">Lmax</code></td>
<td>
<p>maximum number of leapfrog steps (positive integer, Lmax &gt; Lmin)</p>
</td></tr>
<tr><td><code id="samplers_+3A_epsilon">epsilon</code></td>
<td>
<p>leapfrog stepsize hyperparameter (positive, will be tuned)</p>
</td></tr>
<tr><td><code id="samplers_+3A_diag_sd">diag_sd</code></td>
<td>
<p>estimate of the posterior marginal standard deviations
(positive, will be tuned).</p>
</td></tr>
<tr><td><code id="samplers_+3A_proposal">proposal</code></td>
<td>
<p>the probability distribution used to generate proposal states</p>
</td></tr>
<tr><td><code id="samplers_+3A_max_doublings">max_doublings</code></td>
<td>
<p>the maximum number of iterations of the 'doubling'
algorithm used to adapt the size of the slice</p>
</td></tr>
</table>


<h3>Details</h3>

<p>During the warmup iterations of <code>mcmc</code>, some of these
sampler parameters will be tuned to improve the efficiency of the sampler,
so the values provided here are used as starting values.
</p>
<p>For <code>hmc()</code>, the number of leapfrog steps at each iteration is
selected uniformly at random from between <code>Lmin</code> and <code>Lmax</code>.
<code>diag_sd</code> is used to rescale the parameter space to make it more
uniform, and make sampling more efficient.
</p>
<p><code>rwmh()</code> creates a random walk Metropolis-Hastings sampler;  a
a gradient-free sampling algorithm. The algorithm involves a proposal
generating step <code>proposal_state = current_state + perturb</code> by a random
perturbation, followed by Metropolis-Hastings accept/reject step. The class
is implemented for uniform and normal proposals.
</p>
<p><code>slice()</code> implements a multivariate slice sampling algorithm.
Currently this algorithm can only be used with single-precision models (set
using the <code>precision</code> argument to <code><a href="#topic+model">model()</a></code>). The parameter
<code>max_doublings</code> is not tuned during warmup.
</p>


<h3>Value</h3>

<p>a <code>sampler</code> object that can be passed to <code><a href="#topic+mcmc">mcmc()</a></code>.
</p>

<hr>
<h2 id='simulate.greta_model'>Simulate Responses From <code>greta_model</code> Object</h2><span id='topic+simulate.greta_model'></span>

<h3>Description</h3>

<p>Simulate values of all named greta arrays associated with a
greta model from the model priors, including the response variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'greta_model'
simulate(object, nsim = 1, seed = NULL, precision = c("double", "single"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.greta_model_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+model">greta_model()</a></code> object</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_nsim">nsim</code></td>
<td>
<p>positive integer scalar - the number of responses to simulate</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_seed">seed</code></td>
<td>
<p>an optional seed to be used in set.seed immediately before the
simulation so as to generate a reproducible sample</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_precision">precision</code></td>
<td>
<p>the floating point precision to use when calculating values.</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_...">...</code></td>
<td>
<p>optional additional arguments, none are used at present</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is essentially a wrapper around <code><a href="#topic+calculate">calculate()</a></code> that
finds all relevant greta arrays. See that function for more functionality,
including simulation conditional on fixed values or posterior samples.
</p>
<p>To simulate values of the response variable, it must be both a named object
(in the calling environment) and be a greta array. If you don't see it
showing up in the output, you may need to use <code>as_data</code> to convert it
to a greta array before defining the model.
</p>


<h3>Value</h3>

<p>A named list of vectors, matrices or arrays containing independent
samples of the greta arrays associated with the model. The number of
samples will be prepended as the first dimension of the greta array, so
that a vector of samples is returned for each scalar greta array, and a
matrix is returned for each vector greta array, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# build a greta model
n &lt;- 10
y &lt;- rnorm(n)
y &lt;- as_data(y)

library(greta)
sd &lt;- lognormal(1, 2)
mu &lt;- normal(0, 1, dim = n)
distribution(y) &lt;- normal(mu, sd)
m &lt;- model(mu, sd)

# simulate one random draw of y, mu and sd from the model prior:
sims &lt;- simulate(m)

# 100 simulations of y, mu and sd
sims &lt;- simulate(m, nsim = 100)

## End(Not run)
# nolint start
</code></pre>

<hr>
<h2 id='structures'>create data greta arrays</h2><span id='topic+structures'></span><span id='topic+zeros'></span><span id='topic+ones'></span><span id='topic+greta_array'></span>

<h3>Description</h3>

<p>These structures can be used to set up more complex models. For
example, scalar parameters can be embedded in a greta array by first
creating a greta array with <code>zeros()</code> or <code>ones()</code>, and then
embedding the parameter value using greta's replacement syntax.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeros(...)

ones(...)

greta_array(data = 0, dim = length(data))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="structures_+3A_...">...</code></td>
<td>
<p>dimensions of the greta arrays to create</p>
</td></tr>
<tr><td><code id="structures_+3A_data">data</code></td>
<td>
<p>a vector giving data to fill the greta array. Other object types
are coerced by <code><a href="base.html#topic+as.vector">as.vector()</a></code>.</p>
</td></tr>
<tr><td><code id="structures_+3A_dim">dim</code></td>
<td>
<p>an integer vector giving the dimensions for the greta array to be
created.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>greta_array</code> is a convenience function to create an R array
with <code><a href="base.html#topic+array">array()</a></code> and then coerce it to a greta array. I.e. when
passed something that can be coerced to a numeric array, it is equivalent
to <code>as_data(array(data, dim))</code>.
</p>
<p>If <code>data</code> is a greta array and
dim is different than <code>dim(data)</code>, a reshaped greta array is returned.
This is equivalent to: <code>dim(data) &lt;- dim</code>.
</p>


<h3>Value</h3>

<p>a greta array object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# a 3 row, 4 column greta array of 0s
z &lt;- zeros(3, 4)

# a 3x3x3 greta array of 1s
z &lt;- ones(3, 3, 3)

# a 2x4 greta array filled with pi
z &lt;- greta_array(pi, dim = c(2, 4))

# a 3x3x3 greta array filled with 1, 2, and 3
z &lt;- greta_array(1:3, dim = c(3, 3, 3))

## End(Not run)

</code></pre>

<hr>
<h2 id='transforms'>transformation functions for greta arrays</h2><span id='topic+transforms'></span><span id='topic+inverse-links'></span><span id='topic+iprobit'></span><span id='topic+ilogit'></span><span id='topic+icloglog'></span><span id='topic+icauchit'></span><span id='topic+log1pe'></span><span id='topic+imultilogit'></span>

<h3>Description</h3>

<p>transformations for greta arrays, which may also be used as
inverse link functions. Also see <a href="#topic+operators">operators</a> and <a href="#topic+functions">functions</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iprobit(x)

ilogit(x)

icloglog(x)

icauchit(x)

log1pe(x)

imultilogit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transforms_+3A_x">x</code></td>
<td>
<p>a real-valued (i.e. values ranging from -Inf to Inf) greta array to
transform to a constrained value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>greta does not allow you to state the transformation/link on the
left hand side of an assignment, as is common in the BUGS and STAN
modelling languages. That's because the same syntax has a very different
meaning in R, and can only be applied to objects that are already in
existence. The inverse forms of the common link functions (prefixed with an
'i') can be used instead.
</p>
<p>The <code>log1pe</code> inverse link function is equivalent to <code>log(1 + exp(x))</code>, yielding a positive transformed parameter. Unlike the log
transformation, this transformation is approximately linear for x &gt; 1. i.e.
when <code class="reqn">x &gt; 1</code>, <code class="reqn">y</code> is approximately <code class="reqn">x</code>
</p>
<p><code>imultilogit</code> expects an n-by-m greta array, and returns an n-by-(m+1)
greta array of positive reals whose rows sum to one. This is equivalent
adding a final column of 0s and then running the softmax function widely
used in machine learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x1 &lt;- normal(1, 3, dim = 10)

# transformation to the unit interval
p1 &lt;- iprobit(x1)
p2 &lt;- ilogit(x1)
p3 &lt;- icloglog(x1)
p4 &lt;- icauchit(x1)

# and to positive reals
y &lt;- log1pe(x1)

# transform from 10x3 to 10x4, where rows are a complete set of
# probabilities
x2 &lt;- normal(1, 3, dim = c(10, 3))
z &lt;- imultilogit(x2)

## End(Not run)
</code></pre>

<hr>
<h2 id='variable'>create greta variables</h2><span id='topic+variable'></span><span id='topic+cholesky_variable'></span><span id='topic+simplex_variable'></span><span id='topic+ordered_variable'></span>

<h3>Description</h3>

<p><code>variable()</code> creates greta arrays representing unknown
parameters, to be learned during model fitting. These parameters are not
associated with a probability distribution. To create a variable greta
array following a specific probability distribution, see
<code><a href="#topic+distributions">distributions()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable(lower = -Inf, upper = Inf, dim = NULL)

cholesky_variable(dim, correlation = FALSE)

simplex_variable(dim)

ordered_variable(dim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable_+3A_lower">lower</code>, <code id="variable_+3A_upper">upper</code></td>
<td>
<p>optional limits to variables. These must be specified as
numerics, they cannot be greta arrays (though see details for a
workaround). They can be set to <code>-Inf</code> (<code>lower</code>) or <code>Inf</code>
(<code>upper</code>), though <code>lower</code> must always be less than <code>upper</code>.</p>
</td></tr>
<tr><td><code id="variable_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers. See details.</p>
</td></tr>
<tr><td><code id="variable_+3A_correlation">correlation</code></td>
<td>
<p>whether to return a cholesky factor corresponding to a
correlation matrix (diagonal elements equalling 1, off-diagonal elements
between -1 and 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lower</code> and <code>upper</code> must be fixed, they cannot be greta
arrays. This ensures these values can always be transformed to a continuous
scale to run the samplers efficiently. However, a variable parameter with
dynamic limits can always be created by first defining a variable
constrained between 0 and 1, and then transforming it to the required
scale. See below for an example.
</p>
<p>The constraints in <code>simplex_variable()</code> and <code>ordered_variable()</code>
operate on the final dimension, which must have more than 1 element.
Passing in a scalar value for <code>dim</code> therefore results in a row-vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# a scalar variable
a &lt;- variable()

# a positive length-three variable
b &lt;- variable(lower = 0, dim = 3)

# a 2x2x2 variable bounded between 0 and 1
c &lt;- variable(lower = 0, upper = 1, dim = c(2, 2, 2))

# create a variable, with lower and upper defined by greta arrays
min &lt;- as_data(iris$Sepal.Length)
max &lt;- min^2
d &lt;- min + variable(0, 1, dim = nrow(iris)) * (max - min)

## End(Not run)
# 4x4 cholesky factor variables for covariance and correlation matrices
e_cov &lt;- cholesky_variable(dim = 4)
e_correl &lt;- cholesky_variable(dim = 4, correlation = TRUE)

# these can be converted to symmetic matrices with chol2symm
# (equivalent to t(e_cov) %*% e_cov, but more efficient)
cov &lt;- chol2symm(e_cov)
correl &lt;- chol2symm(e_correl)
# a 4D simplex (sums to 1, all values positive)
f &lt;- simplex_variable(4)

# a 4D simplex on the final dimension
g &lt;- simplex_variable(dim = c(2, 3, 4))
# a 2D variable with each element higher than the one in the cell to the left
h &lt;- ordered_variable(dim = c(3, 4))

# more constraints can be added with monotonic transformations, e.g. an
# ordered positive variable
i &lt;- exp(ordered_variable(5))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
