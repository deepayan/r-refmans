<!DOCTYPE html><html lang="en-US"><head><title>Help for package greta</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {greta}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#greta'><p>greta: simple and scalable statistical modelling in R</p></a></li>
<li><a href='#are_null'><p>Vectorised is.null</p></a></li>
<li><a href='#as_data'><p>convert other objects to greta arrays</p></a></li>
<li><a href='#as.greta_model'><p>Convert object to a &quot;greta_model&quot; object</p></a></li>
<li><a href='#as.unknowns'><p>Create objects of class 'unknowns' to nicely print ? valued arrays</p></a></li>
<li><a href='#calculate'><p>calculate greta arrays given fixed values</p></a></li>
<li><a href='#chol.greta_array'><p>Compute the Cholesky Factor of a Matrix</p></a></li>
<li><a href='#chol2symm'><p>Cholesky Factor to Symmetric Matrix</p></a></li>
<li><a href='#destroy_greta_deps'><p>Remove greta dependencies and remove miniconda</p></a></li>
<li><a href='#dim.node'><p>generic to grab dimensions of nodes</p></a></li>
<li><a href='#dim+26lt+3B-.unknowns'><p>set dims like on a matrix/array</p></a></li>
<li><a href='#distribution'><p>define a distribution over data</p></a></li>
<li><a href='#distributions'><p>probability distributions</p></a></li>
<li><a href='#extract-replace-combine'><p>extract, replace and combine greta arrays</p></a></li>
<li><a href='#functions'><p>functions for greta arrays</p></a></li>
<li><a href='#gpu_cpu'><p>Set GPU or CPU usage</p></a></li>
<li><a href='#greta_create_conda_env'><p>Create conda environment for greta</p></a></li>
<li><a href='#greta_deps_receipt'><p>Capture greta python dependencies.</p></a></li>
<li><a href='#greta_deps_spec'><p>Specify python dependencies for greta</p></a></li>
<li><a href='#greta_deps_tf_tfp'><p>Suggested valid Python dependencies for greta</p></a></li>
<li><a href='#greta_install_miniconda'><p>Installs miniconda</p></a></li>
<li><a href='#greta_notes_tf_num_error'><p>Retrieve python messages.</p></a></li>
<li><a href='#greta_set_install_logfile'><p>Set logfile path when installing greta</p></a></li>
<li><a href='#greta_sitrep'><p>Greta Situation Report</p></a></li>
<li><a href='#inference'><p>Statistical inference on greta models.</p></a></li>
<li><a href='#install_greta_deps'><p>Install Python dependencies for greta</p></a></li>
<li><a href='#internals'><p>internal greta methods</p></a></li>
<li><a href='#is.greta_array'><p>Is object a greta array?</p></a></li>
<li><a href='#is.greta_mcmc_list'><p>Is object a <code>greta_mcmc_list</code>?</p></a></li>
<li><a href='#joint'><p>define joint distributions</p></a></li>
<li><a href='#mixture'><p>mixtures of probability distributions</p></a></li>
<li><a href='#model'><p>greta model objects</p></a></li>
<li><a href='#open_greta_install_log'><p>Read a greta logfile</p></a></li>
<li><a href='#operators'><p>arithmetic, logical and relational operators for greta arrays</p></a></li>
<li><a href='#optimisers'><p>optimisation methods</p></a></li>
<li><a href='#overloaded'><p>Functions overloaded by greta</p></a></li>
<li><a href='#print.greta_deps_spec'><p>Print method for greta python deps</p></a></li>
<li><a href='#print.greta_mcmc_list'><p>Print method for greta MCMC list</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#reinstallers'><p>Helpers to remove, and reinstall python environments and miniconda</p></a></li>
<li><a href='#run_optimiser'><p>Dispatch optimisation method to right class</p></a></li>
<li><a href='#samplers'><p>MCMC samplers</p></a></li>
<li><a href='#simulate.greta_model'><p>Simulate Responses From <code>greta_model</code> Object</p></a></li>
<li><a href='#structures'><p>create data greta arrays</p></a></li>
<li><a href='#transforms'><p>transformation functions for greta arrays</p></a></li>
<li><a href='#variable'><p>create greta variables</p></a></li>
<li><a href='#write_greta_install_log'><p>Write greta dependency installation log file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simple and Scalable Statistical Modelling in R</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Write statistical models in R and fit them by MCMC and
    optimisation on CPUs and GPUs, using Google 'TensorFlow'.  greta lets
    you write your own model like in BUGS, JAGS and Stan, except that you
    write models right in R, it scales well to massive datasets, and itâ€™s
    easy to extend and build on.  See the website for more information,
    including tutorials, examples, package documentation, and the greta
    forum.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://greta-stats.org">https://greta-stats.org</a>, <a href="https://github.com/greta-dev/greta">https://github.com/greta-dev/greta</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/greta-dev/greta/issues">https://github.com/greta-dev/greta/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, callr, cli (&ge; 3.4.1), coda, future (&ge; 1.22.1), glue
(&ge; 1.5.1), methods, parallelly (&ge; 1.29.0), progress (&ge;
1.2.0), R6, reticulate (&ge; 1.19.0), rlang, tensorflow (==
2.16.0), tools, utils, whisker, yesno</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bayesplot, covr, cramer, DiagrammeR, dplyr, DiagrammeRsvg,
extraDistr, fields, ggplot2, knitr, lattice, MASS, MCMCpack,
mockery, mvtnorm, purrr, rmarkdown, rmutil, rsvg, spelling,
testthat (&ge; 3.1.0), tibble, tidyr, truncdist, withr,
rstudioapi</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 3.7.0) with header files and shared
library; TensorFlow (&gt;= v2.0.0; https://www.tensorflow.org/);
TensorFlow Probability (v0.8.0;
https://www.tensorflow.org/probability/)</td>
</tr>
<tr>
<td>Collate:</td>
<td>'package.R' 'utils.R' 'greta_mcmc_list.R' 'tf_functions.R'
'overloaded.R' 'node_class.R' 'node_types.R' 'variable.R'
'probability_distributions.R' 'mixture.R' 'joint.R'
'unknowns_class.R' 'greta_array_class.R' 'as_data.R'
'distribution.R' 'operators.R' 'functions.R' 'transforms.R'
'structures.R' 'extract_replace_combine.R' 'dag_class.R'
'data-deps-tf-tfp.R' 'greta_model_class.R' 'progress_bar.R'
'inference_class.R' 'samplers.R' 'optimisers.R'
'optimiser_class.R' 'inference.R' 'install_tensorflow.R'
'calculate.R' 'callbacks.R' 'simulate.R' 'chol2symm.R'
'install_greta_deps.R' 'conda_greta_env.R' 'greta_stash.R'
'greta_create_conda_env.R' 'greta_install_miniconda.R'
'greta_install_python_deps.R' 'new_install_process.R'
'reinstallers.R' 'checkers.R' 'test_if_forked_cluster.R'
'testthat-helpers.R' 'write-logfiles.R' 'zzz.R' 'internals.R'</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-10 00:43:40 UTC; nick</td>
</tr>
<tr>
<td>Author:</td>
<td>Nick Golding <a href="https://orcid.org/0000-0001-8916-5570"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Nicholas Tierney <a href="https://orcid.org/0000-0003-1460-8722"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Simon Dirmeier [ctb],
  Adam Fleischhacker [ctb],
  Shirin Glander [ctb],
  Martin Ingram [ctb],
  Lee Hazel [ctb],
  Lionel Hertzog [ctb],
  Tiphaine Martin [ctb],
  Matt Mulvahill [ctb],
  Michael Quinn [ctb],
  David Smith [ctb],
  Paul Teetor [ctb],
  Jian Yen [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicholas Tierney &lt;nicholas.tierney@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-12 06:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='greta'>greta: simple and scalable statistical modelling in R</h2><span id='topic+greta-package'></span><span id='topic+greta'></span>

<h3>Description</h3>

<p>greta lets you write statistical models interactively in native
R code, then sample from them efficiently using Hamiltonian Monte Carlo.
</p>
<p>The computational heavy lifting is done by TensorFlow, Google's automatic
differentiation library. So greta is particularly fast where the model
contains lots of linear algebra, and greta models can be run across CPU
clusters or on GPUs.
</p>
<p>See the simple example below, and take a look at the
<a href="https://greta-stats.org">greta website</a> for more information
including
<a href="https://greta-stats.org/articles/get_started.html">tutorials</a> and
<a href="https://greta-stats.org/articles/example_models.html">examples</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nicholas Tierney <a href="mailto:nicholas.tierney@gmail.com">nicholas.tierney@gmail.com</a> (<a href="https://orcid.org/0000-0003-1460-8722">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Nick Golding <a href="mailto:nick.golding.research@gmail.com">nick.golding.research@gmail.com</a> (<a href="https://orcid.org/0000-0001-8916-5570">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Simon Dirmeier [contributor]
</p>
</li>
<li><p> Adam Fleischhacker [contributor]
</p>
</li>
<li><p> Shirin Glander [contributor]
</p>
</li>
<li><p> Martin Ingram [contributor]
</p>
</li>
<li><p> Lee Hazel [contributor]
</p>
</li>
<li><p> Lionel Hertzog [contributor]
</p>
</li>
<li><p> Tiphaine Martin [contributor]
</p>
</li>
<li><p> Matt Mulvahill [contributor]
</p>
</li>
<li><p> Michael Quinn [contributor]
</p>
</li>
<li><p> David Smith [contributor]
</p>
</li>
<li><p> Paul Teetor [contributor]
</p>
</li>
<li><p> Jian Yen [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://greta-stats.org">https://greta-stats.org</a>
</p>
</li>
<li> <p><a href="https://github.com/greta-dev/greta">https://github.com/greta-dev/greta</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/greta-dev/greta/issues">https://github.com/greta-dev/greta/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# a simple Bayesian regression model for the iris data

# priors
int &lt;- normal(0, 5)
coef &lt;- normal(0, 3)
sd &lt;- lognormal(0, 3)

# likelihood
mean &lt;- int + coef * iris$Petal.Length
distribution(iris$Sepal.Length) &lt;- normal(mean, sd)

# build and sample
m &lt;- model(int, coef, sd)
draws &lt;- mcmc(m, n_samples = 100)

## End(Not run)
</code></pre>

<hr>
<h2 id='are_null'>Vectorised is.null</h2><span id='topic+are_null'></span>

<h3>Description</h3>

<p>Vectorised is.null
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are_null(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="are_null_+3A_x">x</code></td>
<td>
<p>list of things that may contain NULL values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.null(list(NULL, NULL, 1))
are_null(list(NULL, NULL, 1))
are_null(list(NULL, NULL, NULL))
are_null(list(1, 2, 3))
is.null(list(1, 2, 3))
</code></pre>

<hr>
<h2 id='as_data'>convert other objects to greta arrays</h2><span id='topic+as_data'></span>

<h3>Description</h3>

<p>define an object in an R session as a data greta array for use
as data in a greta model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_data(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_data_+3A_x">x</code></td>
<td>
<p>an R object that can be coerced to a greta_array (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>as_data()</code> can currently convert R objects to greta_arrays if
they are numeric or logical vectors, matrices or arrays; or if they are
dataframes with only numeric (including integer) or logical elements.
Logical elements are always converted to numerics. R objects cannot be
converted if they contain missing (<code>NA</code>) or infinite (<code>-Inf</code> or
<code>Inf</code>) values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# numeric/integer/logical vectors, matrices and arrays can all be coerced to
# data greta arrays

vec &lt;- rnorm(10)
mat &lt;- matrix(seq_len(3 * 4), nrow = 3)
arr &lt;- array(sample(c(TRUE, FALSE), 2 * 2 * 2, replace = TRUE),
  dim = c(2, 2, 2)
)
(a &lt;- as_data(vec))
(b &lt;- as_data(mat))
(c &lt;- as_data(arr))

# dataframes can also be coerced, provided all the columns are numeric,
# integer or logical
df &lt;- data.frame(
  x1 = rnorm(10),
  x2 = sample(1L:10L),
  x3 = sample(c(TRUE, FALSE), 10, replace = TRUE)
)
(d &lt;- as_data(df))

## End(Not run)
</code></pre>

<hr>
<h2 id='as.greta_model'>Convert object to a &quot;greta_model&quot; object</h2><span id='topic+as.greta_model'></span>

<h3>Description</h3>

<p>Convert object to a &quot;greta_model&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.greta_model(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.greta_model_+3A_x">x</code></td>
<td>
<p>object to convert to greta model</p>
</td></tr>
<tr><td><code id="as.greta_model_+3A_...">...</code></td>
<td>
<p>extra arguments - not used.</p>
</td></tr>
</table>

<hr>
<h2 id='as.unknowns'>Create objects of class 'unknowns' to nicely print ? valued arrays</h2><span id='topic+as.unknowns'></span>

<h3>Description</h3>

<p>Create objects of class 'unknowns' to nicely print ? valued arrays
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.unknowns(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.unknowns_+3A_x">x</code></td>
<td>
<p>object to convert to &quot;unknowns&quot; class</p>
</td></tr>
</table>

<hr>
<h2 id='calculate'>calculate greta arrays given fixed values</h2><span id='topic+calculate'></span>

<h3>Description</h3>

<p>Calculate the values that greta arrays would take, given
temporary, or simulated values for the greta arrays on which they depend.
This can be used to check the behaviour of your model, make predictions to
new data after model fitting, or simulate datasets from either the prior or
posterior of your model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate(
  ...,
  values = list(),
  nsim = NULL,
  seed = NULL,
  precision = c("double", "single"),
  trace_batch_size = 100,
  compute_options = cpu_only()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate_+3A_...">...</code></td>
<td>
<p>one or more greta_arrays for which to calculate the value</p>
</td></tr>
<tr><td><code id="calculate_+3A_values">values</code></td>
<td>
<p>a named list giving temporary values of the greta arrays with
which <code>target</code> is connected, or a <code>greta_mcmc_list</code> object
returned by <code><a href="#topic+mcmc">mcmc()</a></code>.</p>
</td></tr>
<tr><td><code id="calculate_+3A_nsim">nsim</code></td>
<td>
<p>an optional positive integer scalar for the number of responses
to simulate if stochastic greta arrays are present in the model - see
Details.</p>
</td></tr>
<tr><td><code id="calculate_+3A_seed">seed</code></td>
<td>
<p>an optional seed to be used in set.seed immediately before the
simulation so as to generate a reproducible sample</p>
</td></tr>
<tr><td><code id="calculate_+3A_precision">precision</code></td>
<td>
<p>the floating point precision to use when calculating values.</p>
</td></tr>
<tr><td><code id="calculate_+3A_trace_batch_size">trace_batch_size</code></td>
<td>
<p>the number of posterior samples to process at a time
when <code>target</code> is a <code>greta_mcmc_list</code> object; reduce this to
reduce memory demands</p>
</td></tr>
<tr><td><code id="calculate_+3A_compute_options">compute_options</code></td>
<td>
<p>Default is to use CPU only with <code>cpu_only()</code>. Use
<code>gpu_only()</code> to use only GPU. In the future we will add more options for
specifying CPU and GPU use.  If setting GPU with <code>gpu_only()</code> then we
cannot always guarantee that the random number seed will be respected. This
is due to the way tensorflow interfaces with the GPU. If you must have
reproducibility of all simulations we recommend using <code>cpu_only()</code>, which
is the default. You can turn off the message about setting seed with GPU
usage using <code>options(greta_gpu_message = FALSE)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The greta arrays named in <code>values</code> need not be variables, they
can also be other operations or even data.
</p>
<p>At present, if <code>values</code> is a named list it must contain values for
<em>all</em> of the variable greta arrays with which <code>target</code> is
connected, even values are given for intermediate operations, or the target
doesn't depend on the variable. That may be relaxed in a future release.
</p>
<p>If the model contains stochastic greta arrays; those with a distribution,
calculate can be used to sample from these distributions (and all greta
arrays that depend on them) by setting the <code>nsim</code> argument to a
positive integer for the required number of samples. If <code>values</code> is
specified (either as a list of fixed values or as draws), those values will
be used, and remaining variables will be sampled conditional on them.
Observed data with distributions (i.e. response variables defined with
<code>distribution()</code> can also be sampled, provided they are defined as
greta arrays. This behaviour can be used for a number of tasks, like
simulating datasets for known parameter sets, simulating parameters and
data from a set of priors, or simulating datasets from a model posterior.
See some examples of these below.
</p>


<h3>Value</h3>

<p>Values of the target greta array(s), given values of the greta arrays
on which they depend (either specified in <code>values</code> or sampled from
their priors). If <code>values</code> is a
<code><a href="#topic+mcmc">greta_mcmc_list()</a></code> and <code>nsim = NULL</code>, this will
be a <code>greta_mcmc_list</code> object of posterior samples for the target
greta arrays. Otherwise, the result will be a named list of numeric R
arrays. If <code>nsim = NULL</code> the dimensions of returned numeric R arrays
will be the same as the corresponding greta arrays, otherwise an additional
dimension with <code>nsim</code> elements will be prepended, to represent
multiple simulations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# define a variable greta array, and another that is calculated from it
# then calculate what value y would take for different values of x
x &lt;- normal(0, 1, dim = 3)
a &lt;- lognormal(0, 1)
y &lt;- sum(x^2) + a
calculate(y, values = list(x = c(0.1, 0.2, 0.3), a = 2))

# by setting nsim, you can also sample values from their priors
calculate(y, nsim = 3)

# you can combine sampling and fixed values
calculate(y, values = list(a = 2), nsim = 3)

# if the greta array only depends on data,
# you can pass an empty list to values (this is the default)
x &lt;- ones(3, 3)
y &lt;- sum(x)
calculate(y)

# define a model
alpha &lt;- normal(0, 1)
beta &lt;- normal(0, 1)
sigma &lt;- lognormal(1, 0.1)
y &lt;- as_data(iris$Petal.Width)
mu &lt;- alpha + iris$Petal.Length * beta
distribution(y) &lt;- normal(mu, sigma)
m &lt;- model(alpha, beta, sigma)

# sample values of the parameters, or different observation data (y), from
# the priors (useful for prior # predictive checking) - see also
# ?simulate.greta_model
calculate(alpha, beta, sigma, nsim = 100)
calculate(y, nsim = 100)

# calculate intermediate greta arrays, given some parameter values (useful
# for debugging models)
calculate(mu[1:5], values = list(alpha = 1, beta = 2, sigma = 0.5))
calculate(mu[1:5], values = list(alpha = -1, beta = 0.2, sigma = 0.5))

# simulate datasets given fixed parameter values
calculate(y, values = list(alpha = -1, beta = 0.2, sigma = 0.5), nsim = 10)

# you can use calculate in conjunction with posterior samples from MCMC, e.g.
# sampling different observation datasets, given a random set of these
# posterior samples - useful for posterior predictive model checks
draws &lt;- mcmc(m, n_samples = 500)
calculate(y, values = draws, nsim = 100)

# you can use calculate on greta arrays created even after the inference on
# the model - e.g. to plot response curves
petal_length_plot &lt;- seq(min(iris$Petal.Length),
  max(iris$Petal.Length),
  length.out = 100
)
mu_plot &lt;- alpha + petal_length_plot * beta
mu_plot_draws &lt;- calculate(mu_plot, values = draws)
mu_est &lt;- colMeans(mu_plot_draws[[1]])
plot(mu_est ~ petal_length_plot,
  type = "n",
  ylim = range(mu_plot_draws[[1]])
)
apply(mu_plot_draws[[1]], 1, lines,
  x = petal_length_plot, col = grey(0.8)
)
lines(mu_est ~ petal_length_plot, lwd = 2)

# trace_batch_size can be changed to trade off speed against memory usage
# when calculating. These all produce the same result, but have increasing
# memory requirements:
mu_plot_draws_1 &lt;- calculate(mu_plot,
  values = draws,
  trace_batch_size = 1
)
mu_plot_draws_10 &lt;- calculate(mu_plot,
  values = draws,
  trace_batch_size = 10
)
mu_plot_draws_inf &lt;- calculate(mu_plot,
  values = draws,
  trace_batch_size = Inf
)

## End(Not run)
</code></pre>

<hr>
<h2 id='chol.greta_array'>Compute the Cholesky Factor of a Matrix</h2><span id='topic+chol.greta_array'></span>

<h3>Description</h3>

<p>Compute the Cholesky Factor of a Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'greta_array'
chol(x, ..., force_cholesky = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chol.greta_array_+3A_x">x</code></td>
<td>
<p>an object for which a method exists.  The default method
applies to numeric (or logical) symmetric, positive-definite matrices.</p>
</td></tr>
<tr><td><code id="chol.greta_array_+3A_...">...</code></td>
<td>
<p>further arguments pass to or from methods.</p>
</td></tr>
<tr><td><code id="chol.greta_array_+3A_force_cholesky">force_cholesky</code></td>
<td>
<p>Whether to force cholesky computation. Currently
used as a workaround to ensure cholesky is calculated properly, and may
result in code that uses <code>chol()</code> to be slow. Default is TRUE. Can change
to FALSE, but may encounter issues in
<a href="https://github.com/greta-dev/greta/issues/585">https://github.com/greta-dev/greta/issues/585</a>.</p>
</td></tr>
</table>

<hr>
<h2 id='chol2symm'>Cholesky Factor to Symmetric Matrix</h2><span id='topic+chol2symm'></span>

<h3>Description</h3>

<p>Evaluate <code style="white-space: pre;">&#8288;t(x) \%*\% x&#8288;</code> efficiently, where <code>x</code> is the
(upper-triangular) Cholesky factor of a symmetric, positive definite square
matrix. I.e. it is the inverse of <code>chol</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chol2symm(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chol2symm_+3A_x">x</code></td>
<td>
<p>a square, upper triangular matrix representing the Cholesky
factor of a symmetric, positive definite square matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># a symmetric, positive definite square matrix
y &lt;- rWishart(1, 4, diag(3))[, , 1]
y
u &lt;- chol(y)
u
chol2symm(u)
identical(y, chol2symm(u))
identical(chol2symm(u), t(u) %*% u)
## Not run: 
u_greta &lt;- cholesky_variable(3)
y_greta &lt;- chol2symm(u)

## End(Not run)
</code></pre>

<hr>
<h2 id='destroy_greta_deps'>Remove greta dependencies and remove miniconda</h2><span id='topic+destroy_greta_deps'></span>

<h3>Description</h3>

<p>Sometimes when installing greta you might encounter an error and the best
thing to do is start from a clean slate. This function does two things:
</p>

<ol>
<li><p> Removes the &quot;greta-tf2-env&quot; with <code><a href="#topic+remove_greta_env">remove_greta_env()</a></code>
</p>
</li>
<li><p> Removes the miniconda installation with <code><a href="#topic+remove_miniconda">remove_miniconda()</a></code>
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>destroy_greta_deps()
</code></pre>


<h3>Value</h3>

<p>nothing
</p>

<hr>
<h2 id='dim.node'>generic to grab dimensions of nodes</h2><span id='topic+dim.node'></span>

<h3>Description</h3>

<p>generic to grab dimensions of nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'node'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dim.node_+3A_x">x</code></td>
<td>
<p>greta node class</p>
</td></tr>
</table>

<hr>
<h2 id='dim+26lt+3B-.unknowns'>set dims like on a matrix/array</h2><span id='topic+dim+3C-.unknowns'></span>

<h3>Description</h3>

<p>set dims like on a matrix/array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 replacement method for class 'unknowns'
dim(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dim+2B26lt+2B3B-.unknowns_+3A_x">x</code></td>
<td>
<p>matrix/array to set values to</p>
</td></tr>
<tr><td><code id="dim+2B26lt+2B3B-.unknowns_+3A_value">value</code></td>
<td>
<p>values that are  being set set</p>
</td></tr>
</table>

<hr>
<h2 id='distribution'>define a distribution over data</h2><span id='topic+distribution'></span><span id='topic+distribution+3C-'></span>

<h3>Description</h3>

<p><code>distribution</code> defines probability distributions over
observed data, e.g. to set a model likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distribution(greta_array) &lt;- value

distribution(greta_array)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distribution_+3A_greta_array">greta_array</code></td>
<td>
<p>a data greta array. For the assignment method it must not
already have a probability distribution assigned</p>
</td></tr>
<tr><td><code id="distribution_+3A_value">value</code></td>
<td>
<p>a greta array with a distribution (see
<code><a href="#topic+distributions">distributions()</a></code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extract method returns the greta array if it has a distribution,
or <code>NULL</code> if it doesn't. It has no real use-case, but is included for
completeness
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# define a model likelihood

# observed data and mean parameter to be estimated
# (explicitly coerce data to a greta array so we can refer to it later)
y &lt;- as_data(rnorm(5, 0, 3))

mu &lt;- uniform(-3, 3)

# define the distribution over y (the model likelihood)
distribution(y) &lt;- normal(mu, 1)

# get the distribution over y
distribution(y)

## End(Not run)
</code></pre>

<hr>
<h2 id='distributions'>probability distributions</h2><span id='topic+distributions'></span><span id='topic+uniform'></span><span id='topic+normal'></span><span id='topic+lognormal'></span><span id='topic+bernoulli'></span><span id='topic+binomial'></span><span id='topic+beta_binomial'></span><span id='topic+negative_binomial'></span><span id='topic+hypergeometric'></span><span id='topic+poisson'></span><span id='topic+gamma'></span><span id='topic+inverse_gamma'></span><span id='topic+weibull'></span><span id='topic+exponential'></span><span id='topic+pareto'></span><span id='topic+student'></span><span id='topic+laplace'></span><span id='topic+beta'></span><span id='topic+cauchy'></span><span id='topic+chi_squared'></span><span id='topic+logistic'></span><span id='topic+f'></span><span id='topic+multivariate_normal'></span><span id='topic+wishart'></span><span id='topic+lkj_correlation'></span><span id='topic+multinomial'></span><span id='topic+categorical'></span><span id='topic+dirichlet'></span><span id='topic+dirichlet_multinomial'></span>

<h3>Description</h3>

<p>These functions can be used to define random variables in a
greta model. They return a variable greta array that follows the specified
distribution. This variable greta array can be used to represent a
parameter with prior distribution, combined into a mixture distribution
using <code><a href="#topic+mixture">mixture()</a></code>, or used with <code><a href="#topic+distribution">distribution()</a></code> to
define a distribution over a data greta array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniform(min, max, dim = NULL)

normal(mean, sd, dim = NULL, truncation = c(-Inf, Inf))

lognormal(meanlog, sdlog, dim = NULL, truncation = c(0, Inf))

bernoulli(prob, dim = NULL)

binomial(size, prob, dim = NULL)

beta_binomial(size, alpha, beta, dim = NULL)

negative_binomial(size, prob, dim = NULL)

hypergeometric(m, n, k, dim = NULL)

poisson(lambda, dim = NULL)

gamma(shape, rate, dim = NULL, truncation = c(0, Inf))

inverse_gamma(alpha, beta, dim = NULL, truncation = c(0, Inf))

weibull(shape, scale, dim = NULL, truncation = c(0, Inf))

exponential(rate, dim = NULL, truncation = c(0, Inf))

pareto(a, b, dim = NULL, truncation = c(0, Inf))

student(df, mu, sigma, dim = NULL, truncation = c(-Inf, Inf))

laplace(mu, sigma, dim = NULL, truncation = c(-Inf, Inf))

beta(shape1, shape2, dim = NULL, truncation = c(0, 1))

cauchy(location, scale, dim = NULL, truncation = c(-Inf, Inf))

chi_squared(df, dim = NULL, truncation = c(0, Inf))

logistic(location, scale, dim = NULL, truncation = c(-Inf, Inf))

f(df1, df2, dim = NULL, truncation = c(0, Inf))

multivariate_normal(mean, Sigma, n_realisations = NULL, dimension = NULL)

wishart(df, Sigma)

lkj_correlation(eta, dimension = 2)

multinomial(size, prob, n_realisations = NULL, dimension = NULL)

categorical(prob, n_realisations = NULL, dimension = NULL)

dirichlet(alpha, n_realisations = NULL, dimension = NULL)

dirichlet_multinomial(size, alpha, n_realisations = NULL, dimension = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distributions_+3A_min">min</code>, <code id="distributions_+3A_max">max</code></td>
<td>
<p>scalar values giving optional limits to <code>uniform</code>
variables. Like <code>lower</code> and <code>upper</code>, these must be specified as
numerics, they cannot be greta arrays (though see details for a
workaround). Unlike <code>lower</code> and <code>upper</code>, they must be finite.
<code>min</code> must always be less than <code>max</code>.</p>
</td></tr>
<tr><td><code id="distributions_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers. See details.</p>
</td></tr>
<tr><td><code id="distributions_+3A_mean">mean</code>, <code id="distributions_+3A_meanlog">meanlog</code>, <code id="distributions_+3A_location">location</code>, <code id="distributions_+3A_mu">mu</code></td>
<td>
<p>unconstrained parameters</p>
</td></tr>
<tr><td><code id="distributions_+3A_sd">sd</code>, <code id="distributions_+3A_sdlog">sdlog</code>, <code id="distributions_+3A_sigma">sigma</code>, <code id="distributions_+3A_lambda">lambda</code>, <code id="distributions_+3A_shape">shape</code>, <code id="distributions_+3A_rate">rate</code>, <code id="distributions_+3A_df">df</code>, <code id="distributions_+3A_scale">scale</code>, <code id="distributions_+3A_shape1">shape1</code>, <code id="distributions_+3A_shape2">shape2</code>, <code id="distributions_+3A_alpha">alpha</code>, <code id="distributions_+3A_beta">beta</code>, <code id="distributions_+3A_df1">df1</code>, <code id="distributions_+3A_df2">df2</code>, <code id="distributions_+3A_a">a</code>, <code id="distributions_+3A_b">b</code>, <code id="distributions_+3A_eta">eta</code></td>
<td>
<p>positive parameters, <code>alpha</code> must be a vector for <code>dirichlet</code>
and <code>dirichlet_multinomial</code>.</p>
</td></tr>
<tr><td><code id="distributions_+3A_truncation">truncation</code></td>
<td>
<p>a length-two vector giving values between which to truncate
the distribution, similarly to the <code>lower</code> and <code>upper</code> arguments
to <code><a href="#topic+variable">variable()</a></code></p>
</td></tr>
<tr><td><code id="distributions_+3A_prob">prob</code></td>
<td>
<p>probability parameter (<code style="white-space: pre;">&#8288;0 &lt; prob &lt; 1&#8288;</code>), must be a vector for
<code>multinomial</code> and <code>categorical</code></p>
</td></tr>
<tr><td><code id="distributions_+3A_size">size</code>, <code id="distributions_+3A_m">m</code>, <code id="distributions_+3A_n">n</code>, <code id="distributions_+3A_k">k</code></td>
<td>
<p>positive integer parameter</p>
</td></tr>
<tr><td><code id="distributions_+3A_sigma">Sigma</code></td>
<td>
<p>positive definite variance-covariance matrix parameter</p>
</td></tr>
<tr><td><code id="distributions_+3A_n_realisations">n_realisations</code></td>
<td>
<p>the number of independent realisation of a multivariate
distribution</p>
</td></tr>
<tr><td><code id="distributions_+3A_dimension">dimension</code></td>
<td>
<p>the dimension of a multivariate distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete probability distributions (<code>bernoulli</code>,
<code>binomial</code>, <code>negative_binomial</code>, <code>poisson</code>,
<code>multinomial</code>, <code>categorical</code>, <code>dirichlet_multinomial</code>) can
be used when they have fixed values (e.g. defined as a likelihood using
<code><a href="#topic+distribution">distribution()</a></code>, but not as unknown variables.
</p>
<p>For univariate distributions <code>dim</code> gives the dimensions of the greta
array to create. Each element of the greta array will be (independently)
distributed according to the distribution. <code>dim</code> can also be left at
its default of <code>NULL</code>, in which case the dimension will be detected
from the dimensions of the parameters (provided they are compatible with
one another).
</p>
<p>For multivariate distributions (<code>multivariate_normal()</code>,
<code>multinomial()</code>, <code>categorical()</code>, <code>dirichlet()</code>, and
<code>dirichlet_multinomial()</code>) each row of the output and parameters
corresponds to an independent realisation. If a single realisation or
parameter value is specified, it must therefore be a row vector (see
example). <code>n_realisations</code> gives the number of rows/realisations, and
<code>dimension</code> gives the dimension of the distribution. I.e. a bivariate
normal distribution would be produced with <code>multivariate_normal(..., dimension = 2)</code>. The dimension can usually be detected from the parameters.
</p>
<p><code>multinomial()</code> does not check that observed values sum to
<code>size</code>, and <code>categorical()</code> does not check that only one of the
observed entries is 1. It's the user's responsibility to check their data
matches the distribution!
</p>
<p>The parameters of <code>uniform</code> must be fixed, not greta arrays. This
ensures these values can always be transformed to a continuous scale to run
the samplers efficiently. However, a hierarchical <code>uniform</code> parameter
can always be created by defining a <code>uniform</code> variable constrained
between 0 and 1, and then transforming it to the required scale. See below
for an example.
</p>
<p>Wherever possible, the parameterisations and argument names of greta
distributions match commonly used R functions for distributions, such as
those in the <code>stats</code> or <code>extraDistr</code> packages. The following
table states the distribution function to which greta's implementation
corresponds:
</p>

<table>
<tr>
 <td style="text-align: left;"> greta </td><td style="text-align: left;"> reference</td>
</tr>
<tr>
 <td style="text-align: left;"> <code>uniform</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Uniform">stats::dunif</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>normal</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Normal">stats::dnorm</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>lognormal</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Lognormal">stats::dlnorm</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>bernoulli</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+Bernoulli">extraDistr::dbern</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>binomial</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Binomial">stats::dbinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>beta_binomial</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+BetaBinom">extraDistr::dbbinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>negative_binomial</code>
</td><td style="text-align: left;"> <a href="stats.html#topic+NegBinomial">stats::dnbinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>hypergeometric</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Hypergeometric">stats::dhyper</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>poisson</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Poisson">stats::dpois</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>gamma</code> </td><td style="text-align: left;">
<a href="stats.html#topic+GammaDist">stats::dgamma</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>inverse_gamma</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+InvGamma">extraDistr::dinvgamma</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>weibull</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Weibull">stats::dweibull</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>exponential</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Exponential">stats::dexp</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>pareto</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+Pareto">extraDistr::dpareto</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>student</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+LocationScaleT">extraDistr::dlst</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>laplace</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+Laplace">extraDistr::dlaplace</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>beta</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Beta">stats::dbeta</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>cauchy</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Cauchy">stats::dcauchy</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>chi_squared</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Chisquare">stats::dchisq</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>logistic</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Logistic">stats::dlogis</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>f</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Fdist">stats::df</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>multivariate_normal</code> </td><td style="text-align: left;">
<a href="mvtnorm.html#topic+Mvnorm">mvtnorm::dmvnorm</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>multinomial</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Multinom">stats::dmultinom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>categorical</code> </td><td style="text-align: left;">
<a href="stats.html#topic+Multinom">stats::dmultinom</a> (size = 1)</td>
</tr>
<tr>
 <td style="text-align: left;"> <code>dirichlet</code>
</td><td style="text-align: left;"> <a href="extraDistr.html#topic+Dirichlet">extraDistr::ddirichlet</a></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>dirichlet_multinomial</code> </td><td style="text-align: left;">
<a href="extraDistr.html#topic+DirMnom">extraDistr::ddirmnom</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>wishart</code> </td><td style="text-align: left;">
<a href="stats.html#topic+rWishart">stats::rWishart</a></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>lkj_correlation</code> </td><td style="text-align: left;">
<a href="https://rdrr.io/github/rmcelreath/rethinking/man/dlkjcorr.html">rethinking::dlkjcorr</a>
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# a uniform parameter constrained to be between 0 and 1
phi &lt;- uniform(min = 0, max = 1)

# a length-three variable, with each element following a standard normal
# distribution
alpha &lt;- normal(0, 1, dim = 3)

# a length-three variable of lognormals
sigma &lt;- lognormal(0, 3, dim = 3)

# a hierarchical uniform, constrained between alpha and alpha + sigma,
eta &lt;- alpha + uniform(0, 1, dim = 3) * sigma

# a hierarchical distribution
mu &lt;- normal(0, 1)
sigma &lt;- lognormal(0, 1)
theta &lt;- normal(mu, sigma)

# a vector of 3 variables drawn from the same hierarchical distribution
thetas &lt;- normal(mu, sigma, dim = 3)

# a matrix of 12 variables drawn from the same hierarchical distribution
thetas &lt;- normal(mu, sigma, dim = c(3, 4))

# a multivariate normal variable, with correlation between two elements
# note that the parameter must be a row vector
Sig &lt;- diag(4)
Sig[3, 4] &lt;- Sig[4, 3] &lt;- 0.6
theta &lt;- multivariate_normal(t(rep(mu, 4)), Sig)

# 10 independent replicates of that
theta &lt;- multivariate_normal(t(rep(mu, 4)), Sig, n_realisations = 10)

# 10 multivariate normal replicates, each with a different mean vector,
# but the same covariance matrix
means &lt;- matrix(rnorm(40), 10, 4)
theta &lt;- multivariate_normal(means, Sig, n_realisations = 10)
dim(theta)

# a Wishart variable with the same covariance parameter
theta &lt;- wishart(df = 5, Sigma = Sig)

## End(Not run)
</code></pre>

<hr>
<h2 id='extract-replace-combine'>extract, replace and combine greta arrays</h2><span id='topic+extract-replace-combine'></span><span id='topic+extract'></span><span id='topic+replace'></span><span id='topic+cbind'></span><span id='topic+rbind'></span><span id='topic+c'></span><span id='topic+rep'></span>

<h3>Description</h3>

<p>Generic methods to extract and replace elements of greta arrays,
or to combine greta arrays.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract-replace-combine_+3A_x">x</code></td>
<td>
<p>a greta array</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_i">i</code>, <code id="extract-replace-combine_+3A_j">j</code></td>
<td>
<p>indices specifying elements to extract or replace</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_n">n</code></td>
<td>
<p>a single integer, as in <code>utils::head()</code> and
<code>utils::tail()</code></p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_nrow">nrow</code>, <code id="extract-replace-combine_+3A_ncol">ncol</code></td>
<td>
<p>optional dimensions for the resulting greta array when x is
not a matrix.</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_value">value</code></td>
<td>
<p>for <code style="white-space: pre;">&#8288;[&lt;-&#8288;</code> a greta array to replace elements, for
<code style="white-space: pre;">&#8288;dim&lt;-&#8288;</code> either NULL or a numeric vector of dimensions</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_...">...</code></td>
<td>
<p>either further indices specifying elements to extract or replace
(<code>[</code>), or multiple greta arrays to combine (<code>cbind()</code>,
<code>rbind()</code> &amp; <code>c()</code>), or additional arguments (<code>rep()</code>,
<code>head()</code>, <code>tail()</code>)</p>
</td></tr>
<tr><td><code id="extract-replace-combine_+3A_drop">drop</code>, <code id="extract-replace-combine_+3A_recursive">recursive</code></td>
<td>
<p>generic arguments that are ignored for greta arrays</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>diag()</code> can be used to extract or replace the diagonal part of
a square and two-dimensional greta array, but it cannot be used to create a
matrix-like greta array from a scalar or vector-like greta array. A static
diagonal matrix can always be created with e.g. <code>diag(3)</code>, and then
converted into a greta array.
</p>
<p>Also note that since R 4.0.0, <code>head</code> and <code>tail</code> methods for arrays changed
to print a vector rather than maintain the array structure. The <code>greta</code>
package supports both methods, and will do so based on which version of R
you are using.
</p>


<h3>Usage</h3>

<pre>
# extract
x[i]
x[i, j, ..., drop = FALSE]
head(x, n = 6L, ...)
tail(x, n = 6L, ...)
diag(x, nrow, ncol)

# replace
x[i] &lt;- value
x[i, j, ...] &lt;- value
diag(x) &lt;- value

# combine
cbind(...)
rbind(...)
abind(...)
c(..., recursive = FALSE)
rep(x, times, ..., recursive = FALSE)

# get and set dimensions
length(x)
dim(x)
dim(x) &lt;- value
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- as_data(matrix(1:12, 3, 4))

# extract and replace
x[1:3, ]
x[, 2:4] &lt;- 1:9
e &lt;- diag(x)
diag(x) &lt;- e + 1

# combine
cbind(x[, 2], x[, 1])
rbind(x[1, ], x[3, ])
abind(x[1, ], x[3, ], along = 1)
c(x[, 1], x)
rep(x[, 2], times = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='functions'>functions for greta arrays</h2><span id='topic+functions'></span>

<h3>Description</h3>

<p>This is a list of functions (mostly from base R) that are
currently implemented to transform greta arrays. Also see <a href="#topic+operators">operators</a>
and <a href="#topic+transforms">transforms</a>.
</p>


<h3>Details</h3>

<p>TensorFlow only enables rounding to integers, so <code>round()</code> will
error if <code>digits</code> is set to anything other than <code>0</code>.
</p>
<p>Any additional arguments to <code>chol()</code>, <code>chol2inv</code>, and
<code>solve()</code> will be ignored, see the TensorFlow documentation for
details of these routines.
</p>
<p><code>sweep()</code> only works on two-dimensional greta arrays (so <code>MARGIN</code>
can only be either 1 or 2), and only for subtraction, addition, division
and multiplication.
</p>
<p><code>tapply()</code> works on column vectors (2D greta arrays with one column),
and <code>INDEX</code> cannot be a greta array. Currently five functions are
available, and arguments passed to ... are ignored.
</p>
<p><code>cospi()</code>, <code>sinpi()</code>, and <code>tanpi()</code> do not use the
computationally more stable routines to compute <code>cos(x * pi)</code> etc.
that are available in R under some operating systems. Similarly
<code>trigamma()</code> uses TensorFlow's polygamma function, resulting in lower
precision than R's equivalent.
</p>


<h3>Usage</h3>

<pre>

 # logarithms and exponentials
 log(x)
 exp(x)
 log1p(x)
 expm1(x)

 # miscellaneous mathematics
 abs(x)
 mean(x)
 sqrt(x)
 sign(x)

 # rounding of numbers
 ceiling(x)
 floor(x)
 round(x, digits = 0)

 # trigonometry
 cos(x)
 sin(x)
 tan(x)
 acos(x)
 asin(x)
 atan(x)
 cosh(x)
 sinh(x)
 tanh(x)
 acosh(x)
 asinh(x)
 atanh(x)
 cospi(x)
 sinpi(x)
 tanpi(x)

 # special mathematical functions
 lgamma(x)
 digamma(x)
 trigamma(x)
 choose(n, k)
 lchoose(n, k)

 # matrix operations
 t(x)
 chol(x, ...)
 chol2inv(x, ...)
 cov2cor(V)
 solve(a, b, ...)
 kronecker(X, Y, FUN = c('*', '/', '+', '-'))

 # reducing operations
 sum(..., na.rm = TRUE)
 prod(..., na.rm = TRUE)
 min(..., na.rm = TRUE)
 max(..., na.rm = TRUE)

 # cumulative operations
 cumsum(x)
 cumprod(x)
 cummax(x)
 cummin(x)

 # solve an upper or lower triangular system
 backsolve(r, x, k = ncol(r), upper.tri = TRUE,
           transpose = FALSE)
 forwardsolve(l, x, k = ncol(l), upper.tri = FALSE,
              transpose = FALSE)

 # miscellaneous operations
 aperm(x, perm)
 apply(x, MARGIN, FUN = c("sum", "max", "mean", "min",
                          "prod", "cumsum", "cumprod"))
 sweep(x, MARGIN, STATS, FUN = c('-', '+', '/', '*'))
 tapply(X, INDEX, FUN = c("sum", "max", "mean", "min", "prod"), ...)

</pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- as_data(matrix(1:9, nrow = 3, ncol = 3))
a &lt;- log(exp(x))
b &lt;- log1p(expm1(x))
c &lt;- sign(x - 5)
d &lt;- abs(x - 5)

z &lt;- t(a)

y &lt;- sweep(x, 1, e, "-")

## End(Not run)
</code></pre>

<hr>
<h2 id='gpu_cpu'>Set GPU or CPU usage</h2><span id='topic+gpu_cpu'></span><span id='topic+gpu_only'></span><span id='topic+cpu_only'></span>

<h3>Description</h3>

<p>These functions set the use of CPU or GPU inside of greta. They
simply return either &quot;GPU&quot; or &quot;CPU&quot;, but in the future may handle more
complexity. These functions are passed to <code>compute_options</code> inside of a few
functions: <code><a href="#topic+mcmc">mcmc()</a></code>, <code><a href="#topic+opt">opt()</a></code>, and <code><a href="#topic+calculate">calculate()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpu_only()

cpu_only()
</code></pre>

<hr>
<h2 id='greta_create_conda_env'>Create conda environment for greta</h2><span id='topic+greta_create_conda_env'></span>

<h3>Description</h3>

<p>This function runs <code><a href="reticulate.html#topic+conda-tools">reticulate::conda_create()</a></code> inside
<code><a href="callr.html#topic+r_process_options">callr::r_process_options()</a></code>, to create the conda environment,
&quot;greta-env-tf2&quot;. This is used within <code><a href="#topic+install_greta_deps">install_greta_deps()</a></code> as part of
setting up python dependencies. It uses a version of python that is
compatible with the versions of tensorflow and tensorflow-probability,
which is established with  <code><a href="#topic+greta_deps_spec">greta_deps_spec()</a></code>. We mostly recommend
users use <code><a href="#topic+install_greta_deps">install_greta_deps()</a></code> to manage their python dependency
installation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_create_conda_env(timeout = 5, deps = greta_deps_spec())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="greta_create_conda_env_+3A_timeout">timeout</code></td>
<td>
<p>time (minutes) until installation stops. Default is 5 minutes.</p>
</td></tr>
<tr><td><code id="greta_create_conda_env_+3A_deps">deps</code></td>
<td>
<p>dependency specification, see <code><a href="#topic+greta_deps_spec">greta_deps_spec()</a></code> for
more details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing - creates a conda environment for a specific python version
</p>

<hr>
<h2 id='greta_deps_receipt'>Capture greta python dependencies.</h2><span id='topic+greta_deps_receipt'></span>

<h3>Description</h3>

<p>To assist with capturing and sharing python dependencies, we provide a way
to capture the dependencies currently used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_deps_receipt()
</code></pre>


<h3>Value</h3>

<p><code>greta_deps_spec()</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
my_deps &lt;- greta_deps_receipt()

## End(Not run)
</code></pre>

<hr>
<h2 id='greta_deps_spec'>Specify python dependencies for greta</h2><span id='topic+greta_deps_spec'></span>

<h3>Description</h3>

<p>A helper function for specifying versions of Tensorflow (TF), Tensorflow
Probability (TFP), and Python. Defaulting to 2.15.0, 0.23.0, and 3.10,
respectively. You can specify the version that you want to install, but
it will check if these are compatible. That is, if you specify versions of
TF/TFP/Python which do not work with each other, it will error and give
a suggested version to install. It does this by using a dataset,
<code>greta_deps_tf_tfp</code>, to check if the versions of TF, TFP, and Python
specified are compatible on your operating system. You can inspect
this  dataset with <code>View(greta_deps_tf_tfp)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_deps_spec(
  tf_version = "2.15.0",
  tfp_version = "0.23.0",
  python_version = "3.10"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="greta_deps_spec_+3A_tf_version">tf_version</code></td>
<td>
<p>Character. Tensorflow (TF) version in format
major.minor.patch. Default is &quot;2.15.0&quot;.</p>
</td></tr>
<tr><td><code id="greta_deps_spec_+3A_tfp_version">tfp_version</code></td>
<td>
<p>Character.Tensorflow probability (TFP) version
major.minor.patch. Default is &quot;0.23.0&quot;.</p>
</td></tr>
<tr><td><code id="greta_deps_spec_+3A_python_version">python_version</code></td>
<td>
<p>Character. Python version in format major.minor.patch.
Default is &quot;3.10&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame of valid dependencies
</p>


<h3>Examples</h3>

<pre><code class='language-R'>greta_deps_spec()
greta_deps_spec(tf_version = "2.15.0")
greta_deps_spec(tf_version = "2.15.0", tfp_version = "0.23.0")
greta_deps_spec(tf_version = "2.15.0", python_version = "3.10")
greta_deps_spec(
  tf_version = "2.15.0",
  tfp_version = "0.23.0",
  python_version = "3.10"
  )
# this will fail
## Not run: 
greta_deps_spec(
  tf_version = "2.11.0",
  tfp_version = "0.23.0",
  python_version = "3.10"
  )
  
## End(Not run)
</code></pre>

<hr>
<h2 id='greta_deps_tf_tfp'>Suggested valid Python dependencies for greta</h2><span id='topic+greta_deps_tf_tfp'></span>

<h3>Description</h3>

<p>This is a dataset that contains suggested valid versions of Tensorflow (TF),
Tensorflow Probability (TFP), and Python for linux, mac, and windows
machines. It was constructed from
<a href="https://www.tensorflow.org/install/source">https://www.tensorflow.org/install/source</a> and
<a href="https://www.tensorflow.org/install/source_windows">https://www.tensorflow.org/install/source_windows</a>, and by inspecting
<a href="https://github.com/tensorflow/probability/releases">https://github.com/tensorflow/probability/releases</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_deps_tf_tfp
</code></pre>


<h3>Format</h3>



<h4><code>greta_deps_tf_tfp</code></h4>

<p>A data frame with 63 rows and 5 columns:
</p>

<dl>
<dt>os</dt><dd><p>Operating System</p>
</dd>
<dt>tfp_version, tf_version</dt><dd><p>numeric versions in format major.minor.patch for TFP and TF</p>
</dd>
<dt>python_version_min, python_version_max</dt><dd><p>numeric versions range in format major.minor.patch for Python</p>
</dd>
</dl>




<h3>Details</h3>

<p>We recommend using the default versions provided in <code>greta_deps_spec()</code>.
</p>

<hr>
<h2 id='greta_install_miniconda'>Installs miniconda</h2><span id='topic+greta_install_miniconda'></span>

<h3>Description</h3>

<p>This installs miniconda using <code><a href="reticulate.html#topic+install_miniconda">reticulate::install_miniconda()</a></code> inside
<code><a href="callr.html#topic+r_process_options">callr::r_process_options()</a></code>. Used internally by <code><a href="#topic+install_greta_deps">install_greta_deps()</a></code>.
We mostly recommend users use <code><a href="#topic+install_greta_deps">install_greta_deps()</a></code> to manage their
python dependency installation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_install_miniconda(timeout = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="greta_install_miniconda_+3A_timeout">timeout</code></td>
<td>
<p>time (minutes) until installation stops. Default is 5 minutes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing - installs miniconda.
</p>

<hr>
<h2 id='greta_notes_tf_num_error'>Retrieve python messages.</h2><span id='topic+greta_notes_tf_num_error'></span>

<h3>Description</h3>

<p>These functions retrieve specific python error messages that might
come up during greta use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_notes_tf_num_error()
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
greta_notes_tf_error()

## End(Not run)
</code></pre>

<hr>
<h2 id='greta_set_install_logfile'>Set logfile path when installing greta</h2><span id='topic+greta_set_install_logfile'></span>

<h3>Description</h3>

<p>To help debug greta installation, you can save all installation output
to a single logfile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_set_install_logfile(path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="greta_set_install_logfile_+3A_path">path</code></td>
<td>
<p>valid path to logfile - should end with <code>.html</code> so you
can benefit from the html rendering.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing - sets an environment variable for use with
<code><a href="#topic+install_greta_deps">install_greta_deps()</a></code>.
</p>

<hr>
<h2 id='greta_sitrep'>Greta Situation Report</h2><span id='topic+greta_sitrep'></span>

<h3>Description</h3>

<p>This checks if Python, Tensorflow, Tensorflow Probability, and the greta
conda environment are available, and also loads and initialises python
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greta_sitrep()
</code></pre>


<h3>Value</h3>

<p>Message if greta is ready to use
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
greta_sitrep()

## End(Not run)
</code></pre>

<hr>
<h2 id='inference'>Statistical inference on greta models.</h2><span id='topic+inference'></span><span id='topic+mcmc'></span><span id='topic+stashed_samples'></span><span id='topic+extra_samples'></span><span id='topic+initials'></span><span id='topic+opt'></span>

<h3>Description</h3>

<p>Carry out statistical inference on greta models by
MCMC or likelihood/posterior optimisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcmc(
  model,
  sampler = hmc(),
  n_samples = 1000,
  thin = 1,
  warmup = 1000,
  chains = 4,
  n_cores = NULL,
  verbose = TRUE,
  pb_update = 50,
  one_by_one = FALSE,
  initial_values = initials(),
  trace_batch_size = 100,
  compute_options = cpu_only()
)

stashed_samples()

extra_samples(
  draws,
  n_samples = 1000,
  thin = 1,
  n_cores = NULL,
  verbose = TRUE,
  pb_update = 50,
  one_by_one = FALSE,
  trace_batch_size = 100,
  compute_options = cpu_only()
)

initials(...)

opt(
  model,
  optimiser = bfgs(),
  max_iterations = 100,
  tolerance = 1e-06,
  initial_values = initials(),
  adjust = TRUE,
  hessian = FALSE,
  compute_options = cpu_only()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inference_+3A_model">model</code></td>
<td>
<p>greta_model object</p>
</td></tr>
<tr><td><code id="inference_+3A_sampler">sampler</code></td>
<td>
<p>sampler used to draw values in MCMC. See
<code><a href="#topic+samplers">samplers()</a></code> for options.</p>
</td></tr>
<tr><td><code id="inference_+3A_n_samples">n_samples</code></td>
<td>
<p>number of MCMC samples to draw per chain (after any warm-up,
but before thinning)</p>
</td></tr>
<tr><td><code id="inference_+3A_thin">thin</code></td>
<td>
<p>MCMC thinning rate; every <code>thin</code> samples is retained, the
rest are discarded</p>
</td></tr>
<tr><td><code id="inference_+3A_warmup">warmup</code></td>
<td>
<p>number of samples to spend warming up the mcmc sampler (moving
chains toward the highest density area and tuning sampler hyperparameters).</p>
</td></tr>
<tr><td><code id="inference_+3A_chains">chains</code></td>
<td>
<p>number of MCMC chains to run</p>
</td></tr>
<tr><td><code id="inference_+3A_n_cores">n_cores</code></td>
<td>
<p>the maximum number of CPU cores used by each sampler (see
details).</p>
</td></tr>
<tr><td><code id="inference_+3A_verbose">verbose</code></td>
<td>
<p>whether to print progress information to the console</p>
</td></tr>
<tr><td><code id="inference_+3A_pb_update">pb_update</code></td>
<td>
<p>how regularly to update the progress bar (in iterations).
If <code>pb_update</code> is less than or equal to <code>thin</code>, it will be set
to <code>thin + 1</code> to ensure at least one saved iteration per
<code>pb_update</code> iterations.</p>
</td></tr>
<tr><td><code id="inference_+3A_one_by_one">one_by_one</code></td>
<td>
<p>whether to run TensorFlow MCMC code one iteration at a
time, so that greta can handle numerical errors as 'bad' proposals (see
below).</p>
</td></tr>
<tr><td><code id="inference_+3A_initial_values">initial_values</code></td>
<td>
<p>an optional <code>initials</code> object (or list of
<code>initials</code> objects of length <code>chains</code>) giving initial values for
some or all of the variables in the model. These will be used as the
starting point for sampling/optimisation.</p>
</td></tr>
<tr><td><code id="inference_+3A_trace_batch_size">trace_batch_size</code></td>
<td>
<p>the number of posterior samples to process at a time
when tracing the parameters of interest; reduce this to reduce memory
demands</p>
</td></tr>
<tr><td><code id="inference_+3A_compute_options">compute_options</code></td>
<td>
<p>Default is to use CPU only with <code>cpu_only()</code>. Use
<code>gpu_only()</code> to use only GPU. In the future we will add more options for
specifying CPU and GPU use.</p>
</td></tr>
<tr><td><code id="inference_+3A_draws">draws</code></td>
<td>
<p>a greta_mcmc_list object returned by <code>mcmc</code> or
<code>stashed_samples</code></p>
</td></tr>
<tr><td><code id="inference_+3A_...">...</code></td>
<td>
<p>named numeric values, giving initial values of some or all of the
variables in the model (unnamed variables will be automatically
initialised)</p>
</td></tr>
<tr><td><code id="inference_+3A_optimiser">optimiser</code></td>
<td>
<p>an <code>optimiser</code> object giving the optimisation algorithm
and parameters See <code><a href="#topic+optimisers">optimisers()</a></code>.</p>
</td></tr>
<tr><td><code id="inference_+3A_max_iterations">max_iterations</code></td>
<td>
<p>the maximum number of iterations before giving up</p>
</td></tr>
<tr><td><code id="inference_+3A_tolerance">tolerance</code></td>
<td>
<p>the numerical tolerance for the solution, the optimiser
stops when the (absolute) difference in the joint density between
successive iterations drops below this level</p>
</td></tr>
<tr><td><code id="inference_+3A_adjust">adjust</code></td>
<td>
<p>whether to account for Jacobian adjustments in the joint
density. Set to <code>FALSE</code> (and do not use priors) for maximum likelihood
estimates, or <code>TRUE</code> for maximum <em>a posteriori</em> estimates.</p>
</td></tr>
<tr><td><code id="inference_+3A_hessian">hessian</code></td>
<td>
<p>whether to return a list of <em>analytically</em> differentiated
Hessian arrays for the parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>mcmc()</code> if <code>verbose = TRUE</code>, the progress bar shows
the number of iterations so far and the expected time to complete the phase
of model fitting (warmup or sampling). Occasionally, a proposed set of
parameters can cause numerical instability (I.e. the log density or its
gradient is <code>NA</code>, <code>Inf</code> or <code>-Inf</code>); normally because the log
joint density is so low that it can't be represented as a floating point
number. When this happens, the progress bar will also display the
proportion of proposals so far that were 'bad' (numerically unstable) and
therefore rejected. Some numerical instability during the warmup phase is
normal, but 'bad' samples during the sampling phase can lead to bias in
your posterior sample. If you only have a few bad samples (&lt;10\%), you can
usually resolve this with a longer warmup period or by manually defining
starting values to move the sampler into a more reasonable part of the
parameter space. If you have more samples than that, it may be that your
model is misspecified. You can often diagnose this by using
<code><a href="#topic+calculate">calculate()</a></code> to evaluate the values of greta arrays, given
fixed values of model parameters, and checking the results are what you
expect.
</p>
<p>greta runs multiple chains simultaneously with a single sampler,
vectorising all operations across the chains. E.g. a scalar addition in
your model is computed as an elementwise vector addition (with vectors
having length <code>chains</code>), a vector addition is computed as a matrix
addition etc. TensorFlow is able to parallelise these operations, and this
approach reduced computational overheads, so this is the most efficient of
computing on multiple chains.
</p>
<p>Multiple mcmc samplers (each of which can simultaneously run multiple
chains) can also be run in parallel by setting the execution plan with the
<code>future</code> package. Only <code>plan(multisession)</code> futures or
<code>plan(cluster)</code> futures that don't use fork clusters are allowed,
since forked processes conflict with TensorFlow's parallelism. Explicitly
parallelising chains on a local machine with <code>plan(multisession)</code> will
probably be slower than running multiple chains simultaneously in a single
sampler (with <code>plan(sequential)</code>, the default) because of the overhead
required to start new sessions. However, <code>plan(cluster)</code> can be used
to run chains on a cluster of machines on a local or remote network. See
<code><a href="future.html#topic+cluster">future::cluster()</a></code> for details, and the
<code>future.batchtools</code> package to set up plans on clusters with job
schedulers.
</p>
<p>If <code>n_cores = NULL</code> and mcmc samplers are being run sequentially, each
sampler will be allowed to use all CPU cores (possibly to compute multiple
chains sequentially). If samplers are being run in parallel with the
<code>future</code> package, <code>n_cores</code> will be set so that <code style="white-space: pre;">&#8288;n_cores * [future::nbrOfWorkers]&#8288;</code> is less than the number
of CPU cores.
</p>
<p>After carrying out mcmc on all the model parameters, <code>mcmc()</code>
calculates the values of (i.e. traces) the parameters of interest for each
of these samples, similarly to <code><a href="#topic+calculate">calculate()</a></code>. Multiple
posterior samples can be traced simultaneously, though this can require
large amounts of memory for large models. As in <code>calculate</code>, the
argument <code>trace_batch_size</code> can be modified to trade-off speed against
memory usage.
</p>
<p>If the sampler is aborted before finishing (and <code>future</code>
parallelism isn't being used), the samples collected so far can be
retrieved with <code>stashed_samples()</code>. Only samples from the sampling
phase will be returned.
</p>
<p>Samples returned by <code>mcmc()</code> and <code>stashed_samples()</code> can
be added to with <code>extra_samples()</code>. This continues the chain from the
last value of the previous chain and uses the same sampler and model as was
used to generate the previous samples. It is not possible to change the
sampler or extend the warmup period.
</p>
<p>Because <code>opt()</code> acts on a list of greta arrays with possibly
varying dimension, the <code>par</code> and <code>hessian</code> objects returned by
<code>opt()</code> are named lists, rather than a vector (<code>par</code>) and a
matrix (<code>hessian</code>), as returned by <code><a href="stats.html#topic+optim">stats::optim()</a></code>.
Because greta arrays may not be vectors, the Hessians may not be matrices,
but could be higher-dimensional arrays. To return a Hessian matrix covering
multiple model parameters, you can construct your model so that all those
parameters are in a vector, then split the vector up to define the model.
The parameter vector can then be passed to model. See example.
</p>


<h3>Value</h3>

<p><code>mcmc</code>, <code>stashed_samples</code> &amp; <code>extra_samples</code> - a
<code>greta_mcmc_list</code> object that can be analysed using functions from the
coda package. This will contain mcmc samples of the greta arrays used to
create <code>model</code>.
</p>
<p><code>opt</code> - a list containing the following named elements:
</p>

<ul>
<li> <p><code>par</code> a named list of the optimal values for the greta arrays
specified in <code>model</code>
</p>
</li>
<li> <p><code>value</code> the (unadjusted) negative log joint density of the
model at the parameters 'par'
</p>
</li>
<li> <p><code>iterations</code> the number of iterations taken by the optimiser
</p>
</li>
<li> <p><code>convergence</code> an integer code, 0 indicates successful
completion, 1 indicates the iteration limit <code>max_iterations</code> had
been reached
</p>
</li>
<li> <p><code>hessian</code> (if <code>hessian = TRUE</code>) a named list of hessian
matrices/arrays for the parameters (w.r.t. <code>value</code>)
</p>
</li></ul>



<h3>Note</h3>

<p>to set a seed with MCMC you must use <code><a href="tensorflow.html#topic+set_random_seed">tensorflow::set_random_seed()</a></code>.
This is due to an internal API with tensorflow. See <a href="https://github.com/greta-dev/greta/issues/559">https://github.com/greta-dev/greta/issues/559</a> for a thread exploring this.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# define a simple Bayesian model
x &lt;- rnorm(10)
mu &lt;- normal(0, 5)
sigma &lt;- lognormal(1, 0.1)
distribution(x) &lt;- normal(mu, sigma)
m &lt;- model(mu, sigma)

# carry out mcmc on the model
draws &lt;- mcmc(m, n_samples = 100)

# add some more samples
draws &lt;- extra_samples(draws, 200)

#' # initial values can be passed for some or all model variables
draws &lt;- mcmc(m, chains = 1, initial_values = initials(mu = -1))

# if there are multiple chains, a list of initial values should be passed,
# othewise the same initial values will be used for all chains
inits &lt;- list(initials(sigma = 0.5), initials(sigma = 1))
draws &lt;- mcmc(m, chains = 2, initial_values = inits)

# you can auto-generate a list of initials with something like this:
inits &lt;- replicate(4,
  initials(mu = rnorm(1), sigma = runif(1)),
  simplify = FALSE
)
draws &lt;- mcmc(m, chains = 4, initial_values = inits)

# or find the MAP estimate
opt_res &lt;- opt(m)

# get the MLE of the normal variance
mu &lt;- variable()
variance &lt;- variable(lower = 0)
distribution(x) &lt;- normal(mu, sqrt(variance))
m2 &lt;- model(variance)

# adjust = FALSE skips the jacobian adjustments used in MAP estimation, to
# give the true maximum likelihood estimates
o &lt;- opt(m2, adjust = FALSE)

# the MLE corresponds to the *unadjusted* sample variance, but differs
# from the sample variance
o$par
mean((x - mean(x))^2) # same
var(x) # different

# initial values can also be passed to optimisers:
o &lt;- opt(m2, initial_values = initials(variance = 1))

# and you can return a list of the Hessians for each of these parameters
o &lt;- opt(m2, hessian = TRUE)
o$hessian


# to get a hessian matrix across multiple greta arrays, you must first
# combine them and then split them up for use in the model (so that the
# combined vector is part of the model) and pass that vector to model:
params &lt;- c(variable(), variable(lower = 0))
mu &lt;- params[1]
variance &lt;- params[2]
distribution(x) &lt;- normal(mu, sqrt(variance))
m3 &lt;- model(params)
o &lt;- opt(m3, hessian = TRUE)
o$hessian

## End(Not run)
</code></pre>

<hr>
<h2 id='install_greta_deps'>Install Python dependencies for greta</h2><span id='topic+install_greta_deps'></span><span id='topic+reinstall_greta_deps'></span>

<h3>Description</h3>

<p>This is a helper function to install Python dependencies needed. By default
these are TF 2.15.0, TFP 0.23.0, and Python 3.10. These Python modules
will be installed into a conda environment named &quot;greta-env-tf2&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_greta_deps(
  deps = greta_deps_spec(),
  timeout = 5,
  restart = c("ask", "force", "no"),
  ...
)

reinstall_greta_deps(
  deps = greta_deps_spec(),
  timeout = 5,
  restart = c("ask", "force", "no")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="install_greta_deps_+3A_deps">deps</code></td>
<td>
<p>object created with <code><a href="#topic+greta_deps_spec">greta_deps_spec()</a></code> where you
specify python, TF, and TFP versions. By default these are TF 2.15.0,
TFP 0.23.0, and Python 3.10. These versions must be compatible
with each other. If they are not, <code><a href="#topic+greta_deps_spec">greta_deps_spec()</a></code> will error with
more information and suggestions. See ?<code><a href="#topic+greta_deps_spec">greta_deps_spec()</a></code> for more
information, and see the data object <code>greta_deps_tf_tfp</code>
('?greta_deps_tf_tfp&ldquo;).</p>
</td></tr>
<tr><td><code id="install_greta_deps_+3A_timeout">timeout</code></td>
<td>
<p>maximum time in minutes until the installation for each
installation component times out and exits. Default is 5 minutes per
installation component.</p>
</td></tr>
<tr><td><code id="install_greta_deps_+3A_restart">restart</code></td>
<td>
<p>character. Restart R after installation? Default is &quot;ask&quot;.
Other options are, &quot;force&quot;, and &quot;no&quot;. Using &quot;force&quot; will will force a
restart after installation. Using  &quot;no&quot; will not restart. Note that this
only restarts R during interactive sessions, and only in RStudio.</p>
</td></tr>
<tr><td><code id="install_greta_deps_+3A_...">...</code></td>
<td>
<p>Optional arguments, reserved for future expansion.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can specify an environment variable to write a logfile to a specific
location with <code>GRETA_INSTALLATION_LOG</code> using
<code>Sys.setenv('GRETA_INSTALLATION_LOG'='path/to/logfile.html')</code>. Or use
<code><a href="#topic+greta_set_install_logfile">greta_set_install_logfile()</a></code> to set the path, e.g.,
<code>greta_set_install_logfile('path/to/logfile.html')</code>. By default it uses
<code>tools::R_user_dir("greta")</code> as the directory to save a logfile named
&quot;greta-installation-logfile.html&quot;. To see installation notes or errors,
after installation you can open the logfile with
<code><a href="#topic+open_greta_install_log">open_greta_install_log()</a></code>, or you can navigate to the logfile and open
it in a browser.
</p>
<p>By default, if using RStudio, it will now ask you if you want to restart
the R session. If the session is not interactive, or is not in RStudio,
it will not restart. You can also override this with <code>restart = TRUE</code>.
</p>


<h3>Note</h3>

<p>This will automatically install Miniconda (a minimal version of the
Anaconda scientific software management system), create a 'conda'
environment for greta named 'greta-env-tf2' with required python and python
package versions, and forcibly switch over to using that conda environment.
</p>
<p>If you don't want to use conda or the &quot;greta-env-tf2&quot; conda environment, you
can install versions that you like, e.g., using <code><a href="reticulate.html#topic+py_install">reticulate::py_install()</a></code>.
If you want to see which versions of TF, TFP, and Python work with each
other (at least according to information from tensorflows website), see the
data <code>greta_deps_tf_tfp</code>, which is provided with greta. Managing your own
installation is not always straightforward, so we recommend installing
the python packages using <code>install_greta_deps()</code> for most users.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
install_greta_deps()

## End(Not run)
## Not run: 
# to help troubleshoot your greta installation, this can help resolve some
# issues with installing greta dependencies
reinstall_greta_deps()

## End(Not run)
</code></pre>

<hr>
<h2 id='internals'>internal greta methods</h2><span id='topic+internals'></span><span id='topic+.internals'></span>

<h3>Description</h3>

<p>A list of functions and R6 class objects that can be used to
develop extensions to greta. Most users will not need to access these
methods, and it is not recommended to use them directly in model code.
</p>


<h3>Details</h3>

<p>This help file lists the available internals, but they are not fully
documented and are subject to change and deprecation without warning (though
care will be taken not to break dependent packages on CRAN). For an overview
of how greta works internally, see the <em>technical details</em> vignette. See
<a href="https://github.com/greta-dev">https://github.com/greta-dev</a> for examples of R packages extending and
building on greta.
</p>
<p>Please get in contact via GitHub if you want to develop an extension to
greta and need more details of how to use these internal functions.
</p>
<p>You can use <code>attach()</code> to put a sublist in the search path. E.g.
<code>attach(.internals$nodes$constructors)</code> will enable you to call
<code>op()</code>, <code>vble()</code> and <code>distrib()</code> directly.
</p>


<h3>Usage</h3>

<pre>
 .internals$greta_arrays$unknowns        # greta array print methods
 .internals$inference$progress_bar       # progress bar tools
                      samplers           # MCMC samplers
                      stash              # stashing MCMC samples
 .internals$nodes$constructors           # node creation wrappers
                  distribution_classes   # R6 distribution classes
                  mixture_classes        # R6 mixture distribution classes
                  node_classes           # R6 node classes
 .internals$tensors                      # functions on tensors
 .internals$utils$checks                 # checking function inputs
                  colours                # greta colour scheme
                  dummy_arrays           # mocking up extract/replace
                  misc                   # code simplification etc.
                  samplers               # mcmc helpers
 .internals$greta_stash                  # internal information storage
</pre>

<hr>
<h2 id='is.greta_array'>Is object a greta array?</h2><span id='topic+is.greta_array'></span>

<h3>Description</h3>

<p>Is object a greta array?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.greta_array(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.greta_array_+3A_x">x</code></td>
<td>
<p>object to test if is greta array</p>
</td></tr>
<tr><td><code id="is.greta_array_+3A_...">...</code></td>
<td>
<p>extra args (currently not used)</p>
</td></tr>
</table>

<hr>
<h2 id='is.greta_mcmc_list'>Is object a <code>greta_mcmc_list</code>?</h2><span id='topic+is.greta_mcmc_list'></span>

<h3>Description</h3>

<p>Is object a <code>greta_mcmc_list</code>?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.greta_mcmc_list(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.greta_mcmc_list_+3A_x">x</code></td>
<td>
<p>An object that may be a greta_mcmc_list</p>
</td></tr>
<tr><td><code id="is.greta_mcmc_list_+3A_...">...</code></td>
<td>
<p>extra args (not currently used)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical TRUE/FALSE
</p>

<hr>
<h2 id='joint'>define joint distributions</h2><span id='topic+joint'></span>

<h3>Description</h3>

<p><code>joint</code> combines univariate probability distributions
together into a multivariate (and <em>a priori</em> independent between
dimensions) joint distribution, either over a variable, or for fixed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joint(..., dim = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="joint_+3A_...">...</code></td>
<td>
<p>scalar variable greta arrays following probability distributions
(see <code><a href="#topic+distributions">distributions()</a></code>); the components of the joint
distribution.</p>
</td></tr>
<tr><td><code id="joint_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers. The final dimension of the greta array
returned will be determined by the number of component distributions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The component probability distributions must all be either
continuous or discrete, and must have the same dimensions.
</p>
<p>This functionality is unlikely to be useful in most models, since the same
result can usually be achieved by combining variables with separate
distributions. It is included for situations where it is more convenient to
consider these as a single distribution, e.g. for use with
<code>distribution</code> or <code>mixture</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# an uncorrelated bivariate normal
x &lt;- joint(normal(-3, 0.5), normal(3, 0.5))
m &lt;- model(x)
plot(mcmc(m, n_samples = 500))

# joint distributions can be used to define densities over data
x &lt;- cbind(rnorm(10, 2, 0.5), rbeta(10, 3, 3))
mu &lt;- normal(0, 10)
sd &lt;- normal(0, 3, truncation = c(0, Inf))
a &lt;- normal(0, 3, truncation = c(0, Inf))
b &lt;- normal(0, 3, truncation = c(0, Inf))
distribution(x) &lt;- joint(normal(mu, sd), beta(a, b),
  dim = 10
)
m &lt;- model(mu, sd, a, b)
plot(mcmc(m))

## End(Not run)
</code></pre>

<hr>
<h2 id='mixture'>mixtures of probability distributions</h2><span id='topic+mixture'></span>

<h3>Description</h3>

<p><code>mixture</code> combines other probability distributions into a
single mixture distribution, either over a variable, or for fixed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixture(..., weights, dim = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixture_+3A_...">...</code></td>
<td>
<p>variable greta arrays following probability distributions (see
<code><a href="#topic+distributions">distributions()</a></code>); the component distributions in a mixture
distribution.</p>
</td></tr>
<tr><td><code id="mixture_+3A_weights">weights</code></td>
<td>
<p>a column vector or array of mixture weights, which must be
positive, but need not sum to one. The first dimension must be the number
of distributions, the remaining dimensions must either be 1 or match the
distribution dimension.</p>
</td></tr>
<tr><td><code id="mixture_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>weights</code> are rescaled to sum to one along the first
dimension, and are then used as the mixing weights of the distribution.
I.e. the probability density is calculated as a weighted sum of the
component probability distributions passed in via <code style="white-space: pre;">&#8288;\dots&#8288;</code>
</p>
<p>The component probability distributions must all be either continuous or
discrete, and must have the same dimensions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# a scalar variable following a strange bimodal distibution
weights &lt;- uniform(0, 1, dim = 3)
a &lt;- mixture(normal(-3, 0.5),
  normal(3, 0.5),
  normal(0, 3),
  weights = weights
)
m &lt;- model(a)
plot(mcmc(m, n_samples = 500))

# simulate a mixture of poisson random variables and try to recover the
# parameters with a Bayesian model
x &lt;- c(
  rpois(800, 3),
  rpois(200, 10)
)

weights &lt;- uniform(0, 1, dim = 2)
rates &lt;- normal(0, 10, truncation = c(0, Inf), dim = 2)
distribution(x) &lt;- mixture(poisson(rates[1]),
  poisson(rates[2]),
  weights = weights
)
m &lt;- model(rates)
draws_rates &lt;- mcmc(m, n_samples = 500)

# check the mixing probabilities after fitting using calculate()
# (you could also do this within the model)
normalized_weights &lt;- weights / sum(weights)
draws_weights &lt;- calculate(normalized_weights, draws_rates)

# get the posterior means
summary(draws_rates)$statistics[, "Mean"]
summary(draws_weights)$statistics[, "Mean"]

# weights can also be an array, giving different mixing weights
# for each observation (first dimension must be number of components)
dim &lt;- c(5, 4)
weights &lt;- uniform(0, 1, dim = c(2, dim))
b &lt;- mixture(normal(1, 1, dim = dim),
  normal(-1, 1, dim = dim),
  weights = weights
)

## End(Not run)
</code></pre>

<hr>
<h2 id='model'>greta model objects</h2><span id='topic+model'></span><span id='topic+print.greta_model'></span><span id='topic+plot.greta_model'></span>

<h3>Description</h3>

<p>Create a <code>greta_model</code> object representing a statistical
model (using <code>model</code>), and plot a graphical representation of the
model. Statistical inference can be performed on <code>greta_model</code> objects
with <code><a href="#topic+mcmc">mcmc()</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model(..., precision = c("double", "single"), compile = TRUE)

## S3 method for class 'greta_model'
print(x, ...)

## S3 method for class 'greta_model'
plot(x, y, colour = "#996bc7", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_+3A_...">...</code></td>
<td>
<p>for <code>model</code>: <code>greta_array</code> objects to be tracked by
the model (i.e. those for which samples will be retained during mcmc). If
not provided, all of the non-data <code>greta_array</code> objects defined in the
calling environment will be tracked. For <code>print</code> and
<code>plot</code>:further arguments passed to or from other methods (currently
ignored).</p>
</td></tr>
<tr><td><code id="model_+3A_precision">precision</code></td>
<td>
<p>the floating point precision to use when evaluating this
model. Switching from <code>"double"</code> (the default) to <code>"single"</code> may
decrease the computation time but increase the risk of numerical
instability during sampling.</p>
</td></tr>
<tr><td><code id="model_+3A_compile">compile</code></td>
<td>
<p>whether to apply
<a href="https://openxla.org/xla">XLA JIT compilation</a> to
the TensorFlow graph representing the model. This may slow down model
definition, and speed up model evaluation.</p>
</td></tr>
<tr><td><code id="model_+3A_x">x</code></td>
<td>
<p>a <code>greta_model</code> object</p>
</td></tr>
<tr><td><code id="model_+3A_y">y</code></td>
<td>
<p>unused default argument</p>
</td></tr>
<tr><td><code id="model_+3A_colour">colour</code></td>
<td>
<p>base colour used for plotting. Defaults to <code>greta</code> colours
in violet.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>model()</code> takes greta arrays as arguments, and defines a
statistical model by finding all of the other greta arrays on which they
depend, or which depend on them. Further arguments to <code>model</code> can be
used to configure the TensorFlow graph representing the model, to tweak
performance.
</p>
<p>The plot method produces a visual representation of the defined
model. It uses the <code>DiagrammeR</code> package, which must be installed
first. Here's a key to the plots:
<img src="../help/figures/plotlegend.png" width="100%" alt="plotlegend.png" />

</p>


<h3>Value</h3>

<p><code>model</code> - a <code>greta_model</code> object.
</p>
<p><code>plot</code> - a <code><a href="DiagrammeR.html#topic+grViz">DiagrammeR::grViz()</a></code>
object, with the
<code><a href="DiagrammeR.html#topic+create_graph">DiagrammeR::dgr_graph()</a></code> object used to
create it as an attribute <code>"dgr_graph"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# define a simple model
mu &lt;- variable()
sigma &lt;- normal(0, 3, truncation = c(0, Inf))
x &lt;- rnorm(10)
distribution(x) &lt;- normal(mu, sigma)

m &lt;- model(mu, sigma)

plot(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='open_greta_install_log'>Read a greta logfile</h2><span id='topic+open_greta_install_log'></span>

<h3>Description</h3>

<p>This is a convenience function to facilitate reading logfiles. It opens
a browser using <code><a href="utils.html#topic+browseURL">utils::browseURL()</a></code>. It will search for
the environment variable &quot;GRETA_INSTALLATION_LOG&quot; or default to
<code>tools::R_user_dir("greta")</code>. To set
&quot;GRETA_INSTALLATION_LOG&quot; you can use
<code>Sys.setenv('GRETA_INSTALLATION_LOG'='path/to/logfile.html')</code>. Or use
<code><a href="#topic+greta_set_install_logfile">greta_set_install_logfile()</a></code> to set the path, e.g.,
<code>greta_set_install_logfile('path/to/logfile.html')</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>open_greta_install_log()
</code></pre>


<h3>Value</h3>

<p>opens a URL in your default browser
</p>

<hr>
<h2 id='operators'>arithmetic, logical and relational operators for greta arrays</h2><span id='topic+operators'></span>

<h3>Description</h3>

<p>This is a list of currently implemented arithmetic, logical and
relational operators to combine greta arrays into probabilistic models.
Also see <a href="#topic+functions">functions</a> and <a href="#topic+transforms">transforms</a>.
</p>


<h3>Details</h3>

<p>greta's operators are used just like R's the standard arithmetic,
logical and relational operators, but they return other greta arrays. Since
the operations are only carried during sampling, the greta array objects
have unknown values.
</p>


<h3>Usage</h3>

<pre>
 # arithmetic operators
 -x
 x + y
 x - y
 x * y
 x / y
 x ^ y
 x %% y
 x %/% y
 x %*% y

 # logical operators
 !x
 x &amp; y
 x | y

 # relational operators
 x &lt; y
 x &gt; y
 x &lt;= y
 x &gt;= y
 x == y
 x != y
 </pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- as_data(-1:12)

# arithmetic
a &lt;- x + 1
b &lt;- 2 * x + 3
c &lt;- x %% 2
d &lt;- x %/% 5

# logical
e &lt;- (x &gt; 1) | (x &lt; 1)
f &lt;- e &amp; (x &lt; 2)
g &lt;- !f

# relational
h &lt;- x &lt; 1
i &lt;- (-x) &gt;= x
j &lt;- h == x

## End(Not run)
</code></pre>

<hr>
<h2 id='optimisers'>optimisation methods</h2><span id='topic+optimisers'></span><span id='topic+nelder_mead'></span><span id='topic+bfgs'></span><span id='topic+powell'></span><span id='topic+momentum'></span><span id='topic+cg'></span><span id='topic+newton_cg'></span><span id='topic+l_bfgs_b'></span><span id='topic+tnc'></span><span id='topic+cobyla'></span><span id='topic+slsqp'></span><span id='topic+gradient_descent'></span><span id='topic+adadelta'></span><span id='topic+adagrad'></span><span id='topic+adagrad_da'></span><span id='topic+adam'></span><span id='topic+adamax'></span><span id='topic+ftrl'></span><span id='topic+proximal_gradient_descent'></span><span id='topic+proximal_adagrad'></span><span id='topic+nadam'></span><span id='topic+rms_prop'></span>

<h3>Description</h3>

<p>Functions to set up optimisers (which find parameters that
maximise the joint density of a model) and change their tuning parameters,
for use in <code><a href="#topic+opt">opt()</a></code>. For details of the algorithms and how to
tune them, see the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">TensorFlow optimiser docs</a>, or the <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer">Tensorflow Probability optimiser docs</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nelder_mead(
  objective_function = NULL,
  initial_vertex = NULL,
  step_sizes = NULL,
  func_tolerance = 1e-08,
  position_tolerance = 1e-08,
  reflection = NULL,
  expansion = NULL,
  contraction = NULL,
  shrinkage = NULL
)

bfgs(
  value_and_gradients_function = NULL,
  initial_position = NULL,
  tolerance = 1e-08,
  x_tolerance = 0L,
  f_relative_tolerance = 0L,
  initial_inverse_hessian_estimate = NULL,
  stopping_condition = NULL,
  validate_args = TRUE,
  max_line_search_iterations = 50L,
  f_absolute_tolerance = 0L
)

powell()

momentum()

cg()

newton_cg()

l_bfgs_b()

tnc()

cobyla()

slsqp()

gradient_descent(learning_rate = 0.01, momentum = 0, nesterov = FALSE)

adadelta(learning_rate = 0.001, rho = 1, epsilon = 1e-08)

adagrad(learning_rate = 0.8, initial_accumulator_value = 0.1, epsilon = 1e-08)

adagrad_da(
  learning_rate = 0.8,
  global_step = 1L,
  initial_gradient_squared_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

adam(
  learning_rate = 0.1,
  beta_1 = 0.9,
  beta_2 = 0.999,
  amsgrad = FALSE,
  epsilon = 1e-08
)

adamax(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)

ftrl(
  learning_rate = 1,
  learning_rate_power = -0.5,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0,
  l2_shrinkage_regularization_strength = 0,
  beta = 0
)

proximal_gradient_descent(
  learning_rate = 0.01,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

proximal_adagrad(
  learning_rate = 1,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0
)

nadam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)

rms_prop(
  learning_rate = 0.1,
  rho = 0.9,
  momentum = 0,
  epsilon = 1e-10,
  centered = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimisers_+3A_objective_function">objective_function</code></td>
<td>
<p>A function that accepts a point as a real Tensor
and returns a Tensor of real dtype containing the value of the function at
that point. The function to be minimized. If <code>batch_evaluate_objective</code> is
TRUE, the function may be evaluated on a Tensor of shape <code style="white-space: pre;">&#8288;[n+1] + s&#8288;</code> where
n is the dimension of the problem and s is the shape of a single point in
the domain (so n is the size of a Tensor representing a single point). In
this case, the expected return value is a Tensor of shape <code style="white-space: pre;">&#8288;[n+1]&#8288;</code>. Note
that this method does not support univariate functions so the problem
dimension n must be strictly greater than 1.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_vertex">initial_vertex</code></td>
<td>
<p>Tensor of real dtype and any shape that can be
consumed by the <code>objective_function</code>. A single point in the domain that
will be used to construct an axes aligned initial simplex.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_step_sizes">step_sizes</code></td>
<td>
<p>Tensor of real dtype and shape broadcasting compatible
with <code>initial_vertex</code>. Supplies the simplex scale along each axes.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_func_tolerance">func_tolerance</code></td>
<td>
<p>Single numeric number. The algorithm stops if the
absolute difference between the largest and the smallest function value
on the vertices of the simplex is below this number. Default is 1e-08.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_position_tolerance">position_tolerance</code></td>
<td>
<p>Single numeric number. The algorithm stops if
the largest absolute difference between the coordinates of the vertices
is below this threshold.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_reflection">reflection</code></td>
<td>
<p>(optional) Positive Scalar Tensor of same dtype as
<code>initial_vertex</code>. This parameter controls the scaling of the reflected
vertex. See, <a href="https://numerical.recipes/book.html">Press et al(2007)</a>
for details. If not specified, uses the dimension dependent prescription of
Gao and Han (2012) <a href="https://doi.org/10.1007/s10589-010-9329-3">doi:10.1007/s10589-010-9329-3</a></p>
</td></tr>
<tr><td><code id="optimisers_+3A_expansion">expansion</code></td>
<td>
<p>(optional) Positive Scalar Tensor of same dtype as
<code>initial_vertex</code>. Should be greater than 1 and reflection. This parameter
controls the expanded scaling of a reflected vertex.See,
<a href="https://numerical.recipes/book.html">Press et al(2007)</a> for
details. If not specified, uses the dimension dependent prescription of
Gao and Han (2012) <a href="https://doi.org/10.1007/s10589-010-9329-3">doi:10.1007/s10589-010-9329-3</a></p>
</td></tr>
<tr><td><code id="optimisers_+3A_contraction">contraction</code></td>
<td>
<p>(optional) Positive scalar Tensor of same dtype as
<code>initial_vertex</code>. Must be between 0 and 1. This parameter controls the
contraction of the reflected vertex when the objective function at the
reflected point fails to show sufficient decrease. See,
<a href="https://numerical.recipes/book.html">Press et al(2007)</a> for
details. If not specified, uses the dimension dependent prescription of
Gao and Han (2012) <a href="https://doi.org/10.1007/s10589-010-9329-3">doi:10.1007/s10589-010-9329-3</a></p>
</td></tr>
<tr><td><code id="optimisers_+3A_shrinkage">shrinkage</code></td>
<td>
<p>(Optional) Positive scalar Tensor of same dtype as
<code>initial_vertex</code>. Must be between 0 and 1. This parameter is the scale by
which the simplex is shrunk around the best point when the other steps fail
to produce improvements. See,
<a href="https://numerical.recipes/book.html">Press et al(2007)</a> for
details. If not specified, uses the dimension dependent prescription of
Gao and Han (2012) <a href="https://doi.org/10.1007/s10589-010-9329-3">doi:10.1007/s10589-010-9329-3</a></p>
</td></tr>
<tr><td><code id="optimisers_+3A_value_and_gradients_function">value_and_gradients_function</code></td>
<td>
<p>A function that accepts a point as a
real Tensor and returns a tuple of Tensors of real dtype containing the
value of the function and its gradient at that point. The function to be
minimized. The input should be of shape <code style="white-space: pre;">&#8288;[..., n]&#8288;</code>, where n is the size of
the domain of input points, and all others are batching dimensions. The
first component of the return value should be a real Tensor of matching
shape <code style="white-space: pre;">&#8288;[...]&#8288;</code>. The second component (the gradient) should also be of
shape <code style="white-space: pre;">&#8288;[..., n]&#8288;</code> like the input value to the function.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_position">initial_position</code></td>
<td>
<p>real Tensor of shape <code style="white-space: pre;">&#8288;[..., n]&#8288;</code>. The starting point,
or points when using batching dimensions, of the search procedure. At
these points the function value and the gradient norm should be finite.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_tolerance">tolerance</code></td>
<td>
<p>Scalar Tensor of real dtype. Specifies the gradient
tolerance for the procedure. If the supremum norm of the gradient vector
is below this number, the algorithm is stopped. Default is 1e-08.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_x_tolerance">x_tolerance</code></td>
<td>
<p>Scalar Tensor of real dtype. If the absolute change in
the position between one iteration and the next is smaller than this
number, the algorithm is stopped. Default of 0L.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_f_relative_tolerance">f_relative_tolerance</code></td>
<td>
<p>Scalar Tensor of real dtype. If the relative
change in the objective value between one iteration and the next is
smaller than this value, the algorithm is stopped.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_inverse_hessian_estimate">initial_inverse_hessian_estimate</code></td>
<td>
<p>Optional Tensor of the same dtype
as the components of the output of the value_and_gradients_function. If
specified, the shape should broadcastable to shape <code style="white-space: pre;">&#8288;[..., n, n]&#8288;</code>; e.g. if a
single <code style="white-space: pre;">&#8288;[n, n]&#8288;</code> matrix is provided, it will be automatically broadcasted to
all batches. Alternatively, one can also specify a different hessian
estimate for each batch member. For the correctness of the algorithm, it
is required that this parameter be symmetric and positive definite.
Specifies the starting estimate for the inverse of the Hessian at the
initial point. If not specified, the identity matrix is used as the
starting estimate for the inverse Hessian.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_stopping_condition">stopping_condition</code></td>
<td>
<p>(Optional) A function that takes as input two
Boolean tensors of shape <code style="white-space: pre;">&#8288;[...]&#8288;</code>, and returns a Boolean scalar tensor. The
input tensors are converged and failed, indicating the current status of
each respective batch member; the return value states whether the
algorithm should stop. The default is <code>tfp$optimizer.converged_all</code> which
only stops when all batch members have either converged or failed. An
alternative is <code>tfp$optimizer.converged_any</code> which stops as soon as one
batch member has converged, or when all have failed.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_validate_args">validate_args</code></td>
<td>
<p>Logical, default TRUE. When TRUE, optimizer
parameters are checked for validity despite possibly degrading runtime
performance. When FALSE invalid inputs may silently render incorrect outputs.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_max_line_search_iterations">max_line_search_iterations</code></td>
<td>
<p>Python int. The maximum number of
iterations for the hager_zhang line search algorithm.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_f_absolute_tolerance">f_absolute_tolerance</code></td>
<td>
<p>Scalar Tensor of real dtype. If the absolute
change in the objective value between one iteration and the next is
smaller than this value, the algorithm is stopped.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_learning_rate">learning_rate</code></td>
<td>
<p>the size of steps (in parameter space) towards the
optimal value. Default value 0.01</p>
</td></tr>
<tr><td><code id="optimisers_+3A_momentum">momentum</code></td>
<td>
<p>hyperparameter that accelerates gradient descent in the
relevant direction and dampens oscillations. Defaults to 0, which is
vanilla gradient descent.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_nesterov">nesterov</code></td>
<td>
<p>Whether to apply Nesterov momentum. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_rho">rho</code></td>
<td>
<p>the decay rate</p>
</td></tr>
<tr><td><code id="optimisers_+3A_epsilon">epsilon</code></td>
<td>
<p>a small constant used to condition gradient updates</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_accumulator_value">initial_accumulator_value</code></td>
<td>
<p>initial value of the 'accumulator' used to
tune the algorithm</p>
</td></tr>
<tr><td><code id="optimisers_+3A_global_step">global_step</code></td>
<td>
<p>the current training step number</p>
</td></tr>
<tr><td><code id="optimisers_+3A_initial_gradient_squared_accumulator_value">initial_gradient_squared_accumulator_value</code></td>
<td>
<p>initial value of the
accumulators used to tune the algorithm</p>
</td></tr>
<tr><td><code id="optimisers_+3A_l1_regularization_strength">l1_regularization_strength</code></td>
<td>
<p>L1 regularisation coefficient (must be 0 or
greater)</p>
</td></tr>
<tr><td><code id="optimisers_+3A_l2_regularization_strength">l2_regularization_strength</code></td>
<td>
<p>L2 regularisation coefficient (must be 0 or
greater)</p>
</td></tr>
<tr><td><code id="optimisers_+3A_beta_1">beta_1</code></td>
<td>
<p>exponential decay rate for the 1st moment estimates</p>
</td></tr>
<tr><td><code id="optimisers_+3A_beta_2">beta_2</code></td>
<td>
<p>exponential decay rate for the 2nd moment estimates</p>
</td></tr>
<tr><td><code id="optimisers_+3A_amsgrad">amsgrad</code></td>
<td>
<p>Boolean. Whether to apply AMSGrad variant of this algorithm
from the paper &quot;On the Convergence of Adam and beyond&quot;. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_learning_rate_power">learning_rate_power</code></td>
<td>
<p>power on the learning rate, must be 0 or less</p>
</td></tr>
<tr><td><code id="optimisers_+3A_l2_shrinkage_regularization_strength">l2_shrinkage_regularization_strength</code></td>
<td>
<p>A float value, must be greater
than or equal to zero. This differs from L2 above in that the L2 above is
a stabilization penalty, whereas this L2 shrinkage is a magnitude penalty.
When input is sparse shrinkage will only happen on the active weights.</p>
</td></tr>
<tr><td><code id="optimisers_+3A_beta">beta</code></td>
<td>
<p>A float value, representing the beta value from the paper by
<a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf">McMahan et al 2013</a>. Defaults to 0</p>
</td></tr>
<tr><td><code id="optimisers_+3A_centered">centered</code></td>
<td>
<p>Boolean. If TRUE, gradients are normalized by the estimated
variance of the gradient; if FALSE, by the uncentered second moment.
Setting this to TRUE may help with training, but is slightly more
expensive in terms of computation and memory. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimisers <code>powell()</code>, <code>cg()</code>, <code>newton_cg()</code>,
<code>l_bfgs_b()</code>, <code>tnc()</code>, <code>cobyla()</code>, and <code>slsqp()</code> are
now defunct. They will error when called in greta 0.5.0. This are removed
because they are no longer available in TensorFlow 2.0. Note that
optimiser <code>momentum()</code> has been replaced with <code>gradient_descent()</code>
</p>


<h3>Value</h3>

<p>an <code>optimiser</code> object that can be passed to <code><a href="#topic+opt">opt()</a></code>.
</p>


<h3>Note</h3>

<p>This optimizer isn't supported in TF2, so proceed with caution. See
the <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdagradDAOptimizer">TF docs on AdagradDAOptimiser</a> for more detail.
</p>
<p>This optimizer isn't supported in TF2, so proceed with caution. See
the <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/ProximalGradientDescentOptimizer">TF docs on ProximalGradientDescentOptimizer</a> for more detail.
</p>
<p>This optimizer isn't supported in TF2, so proceed with caution. See
the <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/ProximalAdagradOptimizer">TF docs on ProximalAdagradOptimizer</a> for more detail.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# use optimisation to find the mean and sd of some data
x &lt;- rnorm(100, -2, 1.2)
mu &lt;- variable()
sd &lt;- variable(lower = 0)
distribution(x) &lt;- normal(mu, sd)
m &lt;- model(mu, sd)

# configure optimisers &amp; parameters via 'optimiser' argument to opt
opt_res &lt;- opt(m, optimiser = bfgs())

# compare results with the analytic solution
opt_res$par
c(mean(x), sd(x))

## End(Not run)
</code></pre>

<hr>
<h2 id='overloaded'>Functions overloaded by greta</h2><span id='topic+overloaded'></span><span id='topic++25+2A+25'></span><span id='topic+chol2inv'></span><span id='topic+cov2cor'></span><span id='topic+identity'></span><span id='topic+colMeans'></span><span id='topic+rowMeans'></span><span id='topic+colSums'></span><span id='topic+rowSums'></span><span id='topic+sweep'></span><span id='topic+backsolve'></span><span id='topic+forwardsolve'></span><span id='topic+apply'></span><span id='topic+tapply'></span><span id='topic+eigen'></span><span id='topic+rdist'></span><span id='topic+abind'></span><span id='topic+diag'></span>

<h3>Description</h3>

<p>greta provides a wide range of methods to apply common R
functions and operations to <code>greta_array</code> objects. A few of these
functions and operators are not associated with a class system, so they are
overloaded here. This should not affect normal use of these functions, but
they need to be documented to satisfy CRAN's check.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %*% y

chol2inv(x, size = NCOL(x), LINPACK = FALSE)

cov2cor(V)

identity(x)

colMeans(x, na.rm = FALSE, dims = 1L)

rowMeans(x, na.rm = FALSE, dims = 1L)

colSums(x, na.rm = FALSE, dims = 1L)

rowSums(x, na.rm = FALSE, dims = 1L)

sweep(x, MARGIN, STATS, FUN = "-", check.margin = TRUE, ...)

backsolve(r, x, k = ncol(r), upper.tri = TRUE, transpose = FALSE)

forwardsolve(l, x, k = ncol(l), upper.tri = FALSE, transpose = FALSE)

apply(X, MARGIN, FUN, ...)

tapply(X, INDEX, FUN, ...)

eigen(x, symmetric, only.values, EISPACK)

rdist(x1, x2 = NULL, compact = FALSE)

abind(
  ...,
  along = N,
  rev.along = NULL,
  new.names = NULL,
  force.array = TRUE,
  make.names = use.anon.names,
  use.anon.names = FALSE,
  use.first.dimnames = FALSE,
  hier.names = FALSE,
  use.dnns = FALSE
)

diag(x = 1, nrow, ncol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overloaded_+3A_x">x</code>, <code id="overloaded_+3A_y">y</code>, <code id="overloaded_+3A_size">size</code>, <code id="overloaded_+3A_linpack">LINPACK</code>, <code id="overloaded_+3A_v">V</code>, <code id="overloaded_+3A_na.rm">na.rm</code>, <code id="overloaded_+3A_dims">dims</code>, <code id="overloaded_+3A_margin">MARGIN</code>, <code id="overloaded_+3A_stats">STATS</code>, <code id="overloaded_+3A_fun">FUN</code>, <code id="overloaded_+3A_check.margin">check.margin</code>, <code id="overloaded_+3A_...">...</code>, <code id="overloaded_+3A_r">r</code>, <code id="overloaded_+3A_k">k</code>, <code id="overloaded_+3A_upper.tri">upper.tri</code>, <code id="overloaded_+3A_transpose">transpose</code>, <code id="overloaded_+3A_l">l</code>, <code id="overloaded_+3A_x">X</code>, <code id="overloaded_+3A_index">INDEX</code>, <code id="overloaded_+3A_symmetric">symmetric</code>, <code id="overloaded_+3A_only.values">only.values</code>, <code id="overloaded_+3A_eispack">EISPACK</code>, <code id="overloaded_+3A_x1">x1</code>, <code id="overloaded_+3A_x2">x2</code>, <code id="overloaded_+3A_compact">compact</code>, <code id="overloaded_+3A_along">along</code>, <code id="overloaded_+3A_rev.along">rev.along</code>, <code id="overloaded_+3A_new.names">new.names</code>, <code id="overloaded_+3A_force.array">force.array</code>, <code id="overloaded_+3A_make.names">make.names</code>, <code id="overloaded_+3A_use.anon.names">use.anon.names</code>, <code id="overloaded_+3A_use.first.dimnames">use.first.dimnames</code>, <code id="overloaded_+3A_hier.names">hier.names</code>, <code id="overloaded_+3A_use.dnns">use.dnns</code>, <code id="overloaded_+3A_nrow">nrow</code>, <code id="overloaded_+3A_ncol">ncol</code></td>
<td>
<p>arguments as in original documentation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that, since R 3.1, the LINPACK argument is defunct and silently ignored.
The argument is only included for compatibility with the base functions
that call it.
</p>
<p>To find the original help file for these overloaded functions, search for
the function, e.g., <code>?cov2cor</code> and select the non-greta function.
</p>

<hr>
<h2 id='print.greta_deps_spec'>Print method for greta python deps</h2><span id='topic+print.greta_deps_spec'></span>

<h3>Description</h3>

<p>Print method for greta python deps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'greta_deps_spec'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.greta_deps_spec_+3A_x">x</code></td>
<td>
<p>greta python deps</p>
</td></tr>
<tr><td><code id="print.greta_deps_spec_+3A_...">...</code></td>
<td>
<p>extra args, not used</p>
</td></tr>
</table>

<hr>
<h2 id='print.greta_mcmc_list'>Print method for greta MCMC list</h2><span id='topic+print.greta_mcmc_list'></span>

<h3>Description</h3>

<p>Print method for greta MCMC list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'greta_mcmc_list'
print(x, ..., n = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.greta_mcmc_list_+3A_x">x</code></td>
<td>
<p>greta mcmc list</p>
</td></tr>
<tr><td><code id="print.greta_mcmc_list_+3A_...">...</code></td>
<td>
<p>extra args (currently not used)</p>
</td></tr>
<tr><td><code id="print.greta_mcmc_list_+3A_n">n</code></td>
<td>
<p>number of lines to print</p>
</td></tr>
</table>


<h3>Value</h3>

<p>printed MCMC output
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+install_tensorflow'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+install_tensorflow">install_tensorflow</a></code></p>
</dd>
</dl>

<hr>
<h2 id='reinstallers'>Helpers to remove, and reinstall python environments and miniconda</h2><span id='topic+reinstallers'></span><span id='topic+remove_greta_env'></span><span id='topic+reinstall_greta_env'></span><span id='topic+remove_miniconda'></span><span id='topic+reinstall_miniconda'></span>

<h3>Description</h3>

<p>This can be useful when debugging greta installation to get to &quot;clean slate&quot;.
There are four functions:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_greta_env()

reinstall_greta_env(timeout = 5)

remove_miniconda()

reinstall_miniconda(timeout = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reinstallers_+3A_timeout">timeout</code></td>
<td>
<p>time in minutes to wait until timeout (default is 5 minutes)</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code><a href="#topic+remove_greta_env">remove_greta_env()</a></code> removes the 'greta-env-tf2' conda environment
</p>
</li>
<li> <p><code><a href="#topic+remove_miniconda">remove_miniconda()</a></code> removes miniconda installation
</p>
</li>
<li> <p><code><a href="#topic+reinstall_greta_env">reinstall_greta_env()</a></code> remove 'greta-env-tf2' and reinstall it
using <code><a href="#topic+greta_create_conda_env">greta_create_conda_env()</a></code> (which is used internally).
</p>
</li>
<li> <p><code><a href="#topic+reinstall_miniconda">reinstall_miniconda()</a></code> removes miniconda and reinstalls it using
<code><a href="#topic+greta_install_miniconda">greta_install_miniconda()</a></code> (which is used internally)
</p>
</li></ul>



<h3>Value</h3>

<p>invisible
</p>


<h3>See Also</h3>

<p><code><a href="#topic+destroy_greta_deps">destroy_greta_deps()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
remove_greta_env()
remove_miniconda()
reinstall_greta_env()
reinstall_miniconda()

## End(Not run)
</code></pre>

<hr>
<h2 id='run_optimiser'>Dispatch optimisation method to right class</h2><span id='topic+run_optimiser'></span>

<h3>Description</h3>

<p>Should also allow for building other methods in the future
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_optimiser(self)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="run_optimiser_+3A_self">self</code></td>
<td>
<p>optimiser of class: <code>tf_optimiser</code>, <code>tfp_optimiser</code>, or
<code>tf_compat_optimiser</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='samplers'>MCMC samplers</h2><span id='topic+samplers'></span><span id='topic+hmc'></span><span id='topic+rwmh'></span><span id='topic+slice'></span>

<h3>Description</h3>

<p>Functions to set up MCMC samplers and change the starting values
of their parameters, for use in <code><a href="#topic+mcmc">mcmc()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hmc(Lmin = 5, Lmax = 10, epsilon = 0.1, diag_sd = 1)

rwmh(proposal = c("normal", "uniform"), epsilon = 0.1, diag_sd = 1)

slice(max_doublings = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samplers_+3A_lmin">Lmin</code></td>
<td>
<p>minimum number of leapfrog steps (positive integer, Lmin &gt; Lmax)</p>
</td></tr>
<tr><td><code id="samplers_+3A_lmax">Lmax</code></td>
<td>
<p>maximum number of leapfrog steps (positive integer, Lmax &gt; Lmin)</p>
</td></tr>
<tr><td><code id="samplers_+3A_epsilon">epsilon</code></td>
<td>
<p>leapfrog stepsize hyperparameter (positive, will be tuned)</p>
</td></tr>
<tr><td><code id="samplers_+3A_diag_sd">diag_sd</code></td>
<td>
<p>estimate of the posterior marginal standard deviations
(positive, will be tuned).</p>
</td></tr>
<tr><td><code id="samplers_+3A_proposal">proposal</code></td>
<td>
<p>the probability distribution used to generate proposal states</p>
</td></tr>
<tr><td><code id="samplers_+3A_max_doublings">max_doublings</code></td>
<td>
<p>the maximum number of iterations of the 'doubling'
algorithm used to adapt the size of the slice</p>
</td></tr>
</table>


<h3>Details</h3>

<p>During the warmup iterations of <code>mcmc</code>, some of these
sampler parameters will be tuned to improve the efficiency of the sampler,
so the values provided here are used as starting values.
</p>
<p>For <code>hmc()</code>, the number of leapfrog steps at each iteration is
selected uniformly at random from between <code>Lmin</code> and <code>Lmax</code>.
<code>diag_sd</code> is used to rescale the parameter space to make it more
uniform, and make sampling more efficient.
</p>
<p><code>rwmh()</code> creates a random walk Metropolis-Hastings sampler;  a
a gradient-free sampling algorithm. The algorithm involves a proposal
generating step <code>proposal_state = current_state + perturb</code> by a random
perturbation, followed by Metropolis-Hastings accept/reject step. The class
is implemented for uniform and normal proposals.
</p>
<p><code>slice()</code> implements a multivariate slice sampling algorithm.
The parameter <code>max_doublings</code> is not tuned during warmup.
</p>


<h3>Value</h3>

<p>a <code>sampler</code> object that can be passed to <code><a href="#topic+mcmc">mcmc()</a></code>.
</p>

<hr>
<h2 id='simulate.greta_model'>Simulate Responses From <code>greta_model</code> Object</h2><span id='topic+simulate.greta_model'></span>

<h3>Description</h3>

<p>Simulate values of all named greta arrays associated with a
greta model from the model priors, including the response variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'greta_model'
simulate(object, nsim = 1, seed = NULL, precision = c("double", "single"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate.greta_model_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+model">greta_model()</a></code> object</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_nsim">nsim</code></td>
<td>
<p>positive integer scalar - the number of responses to simulate</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_seed">seed</code></td>
<td>
<p>an optional seed to be used in set.seed immediately before the
simulation so as to generate a reproducible sample</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_precision">precision</code></td>
<td>
<p>the floating point precision to use when calculating values.</p>
</td></tr>
<tr><td><code id="simulate.greta_model_+3A_...">...</code></td>
<td>
<p>optional additional arguments, none are used at present</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is essentially a wrapper around <code><a href="#topic+calculate">calculate()</a></code> that
finds all relevant greta arrays. See that function for more functionality,
including simulation conditional on fixed values or posterior samples.
</p>
<p>To simulate values of the response variable, it must be both a named object
(in the calling environment) and be a greta array. If you don't see it
showing up in the output, you may need to use <code>as_data</code> to convert it
to a greta array before defining the model.
</p>


<h3>Value</h3>

<p>A named list of vectors, matrices or arrays containing independent
samples of the greta arrays associated with the model. The number of
samples will be prepended as the first dimension of the greta array, so
that a vector of samples is returned for each scalar greta array, and a
matrix is returned for each vector greta array, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# build a greta model
n &lt;- 10
y &lt;- rnorm(n)
y &lt;- as_data(y)

library(greta)
sd &lt;- lognormal(1, 2)
mu &lt;- normal(0, 1, dim = n)
distribution(y) &lt;- normal(mu, sd)
m &lt;- model(mu, sd)

# simulate one random draw of y, mu and sd from the model prior:
sims &lt;- simulate(m)

# 100 simulations of y, mu and sd
sims &lt;- simulate(m, nsim = 100)

## End(Not run)
# nolint start
</code></pre>

<hr>
<h2 id='structures'>create data greta arrays</h2><span id='topic+structures'></span><span id='topic+zeros'></span><span id='topic+ones'></span><span id='topic+greta_array'></span>

<h3>Description</h3>

<p>These structures can be used to set up more complex models. For
example, scalar parameters can be embedded in a greta array by first
creating a greta array with <code>zeros()</code> or <code>ones()</code>, and then
embedding the parameter value using greta's replacement syntax.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeros(...)

ones(...)

greta_array(data = 0, dim = length(data))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="structures_+3A_...">...</code></td>
<td>
<p>dimensions of the greta arrays to create</p>
</td></tr>
<tr><td><code id="structures_+3A_data">data</code></td>
<td>
<p>a vector giving data to fill the greta array. Other object types
are coerced by <code><a href="base.html#topic+as.vector">as.vector()</a></code>.</p>
</td></tr>
<tr><td><code id="structures_+3A_dim">dim</code></td>
<td>
<p>an integer vector giving the dimensions for the greta array to be
created.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>greta_array</code> is a convenience function to create an R array
with <code><a href="base.html#topic+array">array()</a></code> and then coerce it to a greta array. I.e. when
passed something that can be coerced to a numeric array, it is equivalent
to <code>as_data(array(data, dim))</code>.
</p>
<p>If <code>data</code> is a greta array and
dim is different than <code>dim(data)</code>, a reshaped greta array is returned.
This is equivalent to: <code>dim(data) &lt;- dim</code>.
</p>


<h3>Value</h3>

<p>a greta array object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# a 3 row, 4 column greta array of 0s
z &lt;- zeros(3, 4)

# a 3x3x3 greta array of 1s
z &lt;- ones(3, 3, 3)

# a 2x4 greta array filled with pi
z &lt;- greta_array(pi, dim = c(2, 4))

# a 3x3x3 greta array filled with 1, 2, and 3
z &lt;- greta_array(1:3, dim = c(3, 3, 3))

## End(Not run)

</code></pre>

<hr>
<h2 id='transforms'>transformation functions for greta arrays</h2><span id='topic+transforms'></span><span id='topic+inverse-links'></span><span id='topic+iprobit'></span><span id='topic+ilogit'></span><span id='topic+icloglog'></span><span id='topic+icauchit'></span><span id='topic+log1pe'></span><span id='topic+imultilogit'></span>

<h3>Description</h3>

<p>transformations for greta arrays, which may also be used as
inverse link functions. Also see <a href="#topic+operators">operators</a> and <a href="#topic+functions">functions</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iprobit(x)

ilogit(x)

icloglog(x)

icauchit(x)

log1pe(x)

imultilogit(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transforms_+3A_x">x</code></td>
<td>
<p>a real-valued (i.e. values ranging from -Inf to Inf) greta array to
transform to a constrained value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>greta does not allow you to state the transformation/link on the
left hand side of an assignment, as is common in the BUGS and STAN
modelling languages. That's because the same syntax has a very different
meaning in R, and can only be applied to objects that are already in
existence. The inverse forms of the common link functions (prefixed with an
'i') can be used instead.
</p>
<p>The <code>log1pe</code> inverse link function is equivalent to <code>log(1 + exp(x))</code>, yielding a positive transformed parameter. Unlike the log
transformation, this transformation is approximately linear for x &gt; 1. i.e.
when <code class="reqn">x &gt; 1</code>, <code class="reqn">y</code> is approximately <code class="reqn">x</code>
</p>
<p><code>imultilogit</code> expects an n-by-m greta array, and returns an n-by-(m+1)
greta array of positive reals whose rows sum to one. This is equivalent
adding a final column of 0s and then running the softmax function widely
used in machine learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x1 &lt;- normal(1, 3, dim = 10)

# transformation to the unit interval
p1 &lt;- iprobit(x1)
p2 &lt;- ilogit(x1)
p3 &lt;- icloglog(x1)
p4 &lt;- icauchit(x1)

# and to positive reals
y &lt;- log1pe(x1)

# transform from 10x3 to 10x4, where rows are a complete set of
# probabilities
x2 &lt;- normal(1, 3, dim = c(10, 3))
z &lt;- imultilogit(x2)

## End(Not run)
</code></pre>

<hr>
<h2 id='variable'>create greta variables</h2><span id='topic+variable'></span><span id='topic+cholesky_variable'></span><span id='topic+simplex_variable'></span><span id='topic+ordered_variable'></span>

<h3>Description</h3>

<p><code>variable()</code> creates greta arrays representing unknown
parameters, to be learned during model fitting. These parameters are not
associated with a probability distribution. To create a variable greta
array following a specific probability distribution, see
<code><a href="#topic+distributions">distributions()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable(lower = -Inf, upper = Inf, dim = NULL)

cholesky_variable(dim, correlation = FALSE)

simplex_variable(dim)

ordered_variable(dim)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variable_+3A_lower">lower</code>, <code id="variable_+3A_upper">upper</code></td>
<td>
<p>optional limits to variables. These must be specified as
numerics, they cannot be greta arrays (though see details for a
workaround). They can be set to <code>-Inf</code> (<code>lower</code>) or <code>Inf</code>
(<code>upper</code>), though <code>lower</code> must always be less than <code>upper</code>.</p>
</td></tr>
<tr><td><code id="variable_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers. See details.</p>
</td></tr>
<tr><td><code id="variable_+3A_correlation">correlation</code></td>
<td>
<p>whether to return a cholesky factor corresponding to a
correlation matrix (diagonal elements equalling 1, off-diagonal elements
between -1 and 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lower</code> and <code>upper</code> must be fixed, they cannot be greta
arrays. This ensures these values can always be transformed to a continuous
scale to run the samplers efficiently. However, a variable parameter with
dynamic limits can always be created by first defining a variable
constrained between 0 and 1, and then transforming it to the required
scale. See below for an example.
</p>
<p>The constraints in <code>simplex_variable()</code> and <code>ordered_variable()</code>
operate on the final dimension, which must have more than 1 element.
Passing in a scalar value for <code>dim</code> therefore results in a row-vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# a scalar variable
a &lt;- variable()

# a positive length-three variable
b &lt;- variable(lower = 0, dim = 3)

# a 2x2x2 variable bounded between 0 and 1
c &lt;- variable(lower = 0, upper = 1, dim = c(2, 2, 2))

# create a variable, with lower and upper defined by greta arrays
min &lt;- as_data(iris$Sepal.Length)
max &lt;- min^2
d &lt;- min + variable(0, 1, dim = nrow(iris)) * (max - min)

## End(Not run)
# 4x4 cholesky factor variables for covariance and correlation matrices
e_cov &lt;- cholesky_variable(dim = 4)
e_correl &lt;- cholesky_variable(dim = 4, correlation = TRUE)

# these can be converted to symmetic matrices with chol2symm
# (equivalent to t(e_cov) %*% e_cov, but more efficient)
cov &lt;- chol2symm(e_cov)
correl &lt;- chol2symm(e_correl)
# a 4D simplex (sums to 1, all values positive)
f &lt;- simplex_variable(4)

# a 4D simplex on the final dimension
g &lt;- simplex_variable(dim = c(2, 3, 4))
# a 2D variable with each element higher than the one in the cell to the left
h &lt;- ordered_variable(dim = c(3, 4))

# more constraints can be added with monotonic transformations, e.g. an
# ordered positive variable
i &lt;- exp(ordered_variable(5))
</code></pre>

<hr>
<h2 id='write_greta_install_log'>Write greta dependency installation log file</h2><span id='topic+write_greta_install_log'></span>

<h3>Description</h3>

<p>This can only be run after installation has happened with
<code><a href="#topic+install_greta_deps">install_greta_deps()</a></code>, and before restarting R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_greta_install_log(path = greta_logfile)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_greta_install_log_+3A_path">path</code></td>
<td>
<p>a path with an HTML (.html) extension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing - writes to file
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
