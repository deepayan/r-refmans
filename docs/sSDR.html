<!DOCTYPE html><html><head><title>Help for package sSDR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sSDR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#center'><p>Center a vector</p></a></li>
<li><a href='#cov.x'><p>Covariance matrix</p></a></li>
<li><a href='#disvm'><p>Subspace distance</p></a></li>
<li><a href='#gen.data'><p>Simulate data</p></a></li>
<li><a href='#gOLS'><p>Groupwise OLS (gOLS)</p></a></li>
<li><a href='#gOLS.comp.d'><p>Groupwise OLS (gOLS) BIC criterion to estimate dimensions with</p>
eigen-decomposition</a></li>
<li><a href='#gSIR'><p>Groupwise SIR (gSIR) for binary response</p></a></li>
<li><a href='#gSIR.comp.d'><p>Groupwise SIR (gSIR) BIC criterion to estimate dimensions with</p>
eigen-decomposition (binary response)</a></li>
<li><a href='#matpower'><p>Power of a matrix</p></a></li>
<li><a href='#norm1'><p>Normalize a vector</p></a></li>
<li><a href='#orthnormal'><p>Gram-Schmidt orthonormalization</p></a></li>
<li><a href='#sOLS.comp.d'><p>Structured OLS (sOLS) outer level BIC criterion to estimate dimension with</p>
eigen-decomposition</a></li>
<li><a href='#standmat'><p>Matrix standardization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools Developed for Structured Sufficient Dimension Reduction
(sSDR)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-03-26</td>
</tr>
<tr>
<td>Author:</td>
<td>Yang Liu &lt;zjubioly@gmail.com&gt;, Francesca Chiaromonte, Bing Li</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yang Liu &lt;zjubioly@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs structured OLS (sOLS) and structured SIR (sSIR).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), MASS, Matrix</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-03-26 18:07:48 UTC; yangliu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-03-26 22:02:24</td>
</tr>
</table>
<hr>
<h2 id='center'>Center a vector</h2><span id='topic+center'></span>

<h3>Description</h3>

<p>Center a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>center(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="center_+3A_v">v</code></td>
<td>
<p>A vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function centers any vector and returns a vector with mean zero.
</p>


<h3>Value</h3>

<p>A vector with mean zero.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
y.centered &lt;- center(data$y)
</code></pre>

<hr>
<h2 id='cov.x'>Covariance matrix</h2><span id='topic+cov.x'></span>

<h3>Description</h3>

<p>Covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov.x(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov.x_+3A_x">X</code></td>
<td>
<p>a n x p matrix of n observations and p predictors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns A p x p covariance matrix for any n x p matrix.
</p>


<h3>Value</h3>

<p>A p x p covariance matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
x.cov &lt;- cov.x(data$X)
</code></pre>

<hr>
<h2 id='disvm'>Subspace distance</h2><span id='topic+disvm'></span>

<h3>Description</h3>

<p>Subspace distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disvm(v1, v2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disvm_+3A_v1">v1</code></td>
<td>
<p>A matrix, each column consists of a p-dimensional vector.</p>
</td></tr>
<tr><td><code id="disvm_+3A_v2">v2</code></td>
<td>
<p>A matrix, each column consists of a p-dimensional vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the distances between two spaces using the formulation
in Li, Zha, Chiaromonte (2005), which is the Frobenius norm of the difference
between the two orthogonal projection matrices defined by v1 and v2.
</p>


<h3>Value</h3>

<p>A scaler represents the distance between the two spaces spanned by
v1 and v2 respectively.
</p>


<h3>References</h3>

<p>Li, B., Zha, H., and Chiaromonte, F. (2005). Contour regression:
a general approach to dimension reduction. Annals of Statistics,
33(4):1580-1616.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v1 &lt;- c(1, 0, 0)
v2 &lt;- c(0, 1, 0)
disvm(v1, v1)
disvm(v1, v2)
</code></pre>

<hr>
<h2 id='gen.data'>Simulate data</h2><span id='topic+gen.data'></span>

<h3>Description</h3>

<p>Simulate data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.data(n, rho = 0.5, theta = 1, binary = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.data_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="gen.data_+3A_rho">rho</code></td>
<td>
<p>Pairwise correlation between covariates.</p>
</td></tr>
<tr><td><code id="gen.data_+3A_theta">theta</code></td>
<td>
<p>Standard deviation of the random error.</p>
</td></tr>
<tr><td><code id="gen.data_+3A_binary">binary</code></td>
<td>
<p>If TRUE, generate binary responses; otherwise, by default,
create continuous responses.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates data as presented in Liu (2015).
</p>


<h3>Value</h3>

<p>gen.data returns a list containning at least the following
components:
&quot;X&quot;, a covariate matrix of n observations and p predictors;
&quot;y&quot;, a univariate response;
&quot;b.true&quot;, the actual coefficients for each predictor group.
</p>


<h3>References</h3>

<p>Liu, Y. (2015). Approaches to reduce and integrate data in
structured and high-dimensional regression problems in Genomics. Ph.D.
Dissertation, The Pennsylvania State University, University Park,
Department of Statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
names(data)
</code></pre>

<hr>
<h2 id='gOLS'>Groupwise OLS (gOLS)</h2><span id='topic+gOLS'></span>

<h3>Description</h3>

<p>Groupwise OLS (gOLS)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gOLS(X, Y, groups, dims)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gOLS_+3A_x">X</code></td>
<td>
<p>A covariate matrix of n observations and p predictors.</p>
</td></tr>
<tr><td><code id="gOLS_+3A_y">Y</code></td>
<td>
<p>A univariate response.</p>
</td></tr>
<tr><td><code id="gOLS_+3A_groups">groups</code></td>
<td>
<p>A vector with the number of predictors in each group.</p>
</td></tr>
<tr><td><code id="gOLS_+3A_dims">dims</code></td>
<td>
<p>A vector with the dimension (at most 1) for each predictor group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates directions for each predictor group using gOLS.
Predictors need to be organized in groups within the &quot;X&quot; matrix, as the
same order saved in &quot;groups&quot;. We only allow continuous covariates
in the &quot;X&quot; matrix; while categorical covariates can be handled outside of
gOLS, e.g. structured OLS.
</p>


<h3>Value</h3>

<p>gOLS returns a list containning at least the following components:
&quot;b_est&quot;, the estimated directions for each group with its own dimension
using gOLS AFTER normalization;
&quot;B&quot;, the estimated directions for each group using gOLS BEFORE normalization.
</p>


<h3>References</h3>

<p>Liu, Y., Chiaromonte, F., and Li, B. (2015). Structured Ordinary
Least Squares: a sufficient dimension reduction approach for regressions with
partitioned predictors and heterogeneous units. Submitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=1000, binary=FALSE) # generate data
dim(data$X) # covariate matrix of 1000 observations and 15 predictors
dim(data$y) # univariate response
groups &lt;- c(5, 10) # two predictor groups and their numbers of predictors
dims &lt;- c(1,1) # dimension of each predictor group
est_gOLS &lt;- gOLS(data$X,data$y,groups,dims)
names(est_gOLS)
</code></pre>

<hr>
<h2 id='gOLS.comp.d'>Groupwise OLS (gOLS) BIC criterion to estimate dimensions with
eigen-decomposition</h2><span id='topic+gOLS.comp.d'></span>

<h3>Description</h3>

<p>Groupwise OLS (gOLS) BIC criterion to estimate dimensions with
eigen-decomposition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gOLS.comp.d(X, y, groups)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gOLS.comp.d_+3A_x">X</code></td>
<td>
<p>A covariate matrix of n observations and p predictors.</p>
</td></tr>
<tr><td><code id="gOLS.comp.d_+3A_y">y</code></td>
<td>
<p>A univariate response.</p>
</td></tr>
<tr><td><code id="gOLS.comp.d_+3A_groups">groups</code></td>
<td>
<p>A vector with the number of predictors in each group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates dimension for each predictor group using
eigen-decomposition. Predictors need to be organized in groups within the
&quot;X&quot; matrix, as the same order saved in &quot;groups&quot;. We only allow continuous
covariates in the &quot;X&quot; matrix; while categorical covariates can be handled
outside of gOLS, e.g. structured OLS.
</p>


<h3>Value</h3>

<p>gOLS.comp.d returns a list containning at least the following
components:
&quot;d&quot;, the estimated dimension (at most 1) for each predictor group;
&quot;crit&quot;, the BIC criterion from each iteration.
</p>


<h3>References</h3>

<p>Liu, Y., Chiaromonte, F., and Li, B. (2015). Structured Ordinary
Least Squares: a sufficient dimension reduction approach for regressions with
partitioned predictors and heterogeneous units. Submitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=1000, binary=FALSE) # generate data
dim(data$X) # covariate matrix of 1000 observations and 15 predictors
dim(data$y) # univariate response
groups &lt;- c(5, 10) # two predictor groups and their numbers of predictors
dim_gOLS&lt;-gOLS.comp.d(data$X,data$y,groups)
names(dim_gOLS)
</code></pre>

<hr>
<h2 id='gSIR'>Groupwise SIR (gSIR) for binary response</h2><span id='topic+gSIR'></span>

<h3>Description</h3>

<p>Groupwise SIR (gSIR) for binary response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gSIR(X, Y, groups, dims)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gSIR_+3A_x">X</code></td>
<td>
<p>A covariate matrix of n observations and p predictors.</p>
</td></tr>
<tr><td><code id="gSIR_+3A_y">Y</code></td>
<td>
<p>A binary response.</p>
</td></tr>
<tr><td><code id="gSIR_+3A_groups">groups</code></td>
<td>
<p>A vector with the number of predictors in each group.</p>
</td></tr>
<tr><td><code id="gSIR_+3A_dims">dims</code></td>
<td>
<p>A vector with the dimension (at most 1) for each predictor group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates directions for each predictor group using gSIR.
Predictors need to be organized in groups within the &quot;X&quot; matrix, as the
same order saved in &quot;groups&quot;. We only allow continuous covariates
in the &quot;X&quot; matrix; while categorical covariates can be handled outside of
gSIR, e.g. structured SIR.
</p>


<h3>Value</h3>

<p>gSIR returns a list containning at least the following components:
&quot;b_est&quot;, the estimated directions for each group with its own dimension
using gSIR AFTER normalization;
&quot;B&quot;, the estimated directions for each group using gSIR BEFORE normalization.
</p>


<h3>References</h3>

<p>Guo, Z., Li, L., Lu, W., and Li, B. (2014). Groupwise dimension
reduction via envelope method. Journal of the American Statistical
Association, accepted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=1000, binary=TRUE) # generate data
dim(data$X) # covariate matrix of 1000 observations and 15 predictors
length(data$y) # binary response
groups &lt;- c(5, 10) # two predictor groups and their numbers of predictors
dims &lt;- c(1,1) # dimension of each predictor group
est_gSIR&lt;-gSIR(data$X,data$y,groups,dims)
names(est_gSIR)
</code></pre>

<hr>
<h2 id='gSIR.comp.d'>Groupwise SIR (gSIR) BIC criterion to estimate dimensions with
eigen-decomposition (binary response)</h2><span id='topic+gSIR.comp.d'></span>

<h3>Description</h3>

<p>Groupwise SIR (gSIR) BIC criterion to estimate dimensions with
eigen-decomposition (binary response)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gSIR.comp.d(X, y, groups)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gSIR.comp.d_+3A_x">X</code></td>
<td>
<p>A covariate matrix of n observations and p predictors.</p>
</td></tr>
<tr><td><code id="gSIR.comp.d_+3A_y">y</code></td>
<td>
<p>A binary response.</p>
</td></tr>
<tr><td><code id="gSIR.comp.d_+3A_groups">groups</code></td>
<td>
<p>A vector with the number of predictors in each group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates dimension for each predictor group using
eigen-decomposition. Predictors need to be organized in groups within the
&quot;X&quot; matrix, as the same order saved in &quot;groups&quot;. We only allow continuous
covariates in the &quot;X&quot; matrix; while categorical covariates can be handled
outside of gSIR, e.g. structured SIR.
</p>


<h3>Value</h3>

<p>gSIR.comp.d returns a list containning at least the following
components:
&quot;d&quot;, the estimated dimension (at most 1) for each predictor group;
&quot;crit&quot;, the BIC criterion from each iteration.
</p>


<h3>References</h3>

<p>Liu, Y. (2015). Approaches to reduce and integrate data in
structured and high-dimensional regression problems in Genomics. Ph.D.
Dissertation, The Pennsylvania State University, University Park,
Department of Statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=1000, binary=TRUE) # generate data
dim(data$X) # covariate matrix of 1000 observations and 15 predictors
length(data$y) # univariate response
groups &lt;- c(5, 10) # two predictor groups and their numbers of predictors
dim_gSIR&lt;-gSIR.comp.d(data$X,data$y,groups)
names(dim_gSIR)
</code></pre>

<hr>
<h2 id='matpower'>Power of a matrix</h2><span id='topic+matpower'></span>

<h3>Description</h3>

<p>Power of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matpower(X, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matpower_+3A_x">X</code></td>
<td>
<p>A p x p square matrix.</p>
</td></tr>
<tr><td><code id="matpower_+3A_alpha">alpha</code></td>
<td>
<p>A scaler determining the order of the power.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the power of a square matrix.
</p>


<h3>Value</h3>

<p>A p x p square matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
cov.squared &lt;- matpower(cov.x(data$X), 2)
</code></pre>

<hr>
<h2 id='norm1'>Normalize a vector</h2><span id='topic+norm1'></span>

<h3>Description</h3>

<p>Normalize a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm1(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm1_+3A_v">v</code></td>
<td>
<p>A vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function normalizes any non-zero vector and returns a vector with
the norm equal to 1.
</p>


<h3>Value</h3>

<p>A vector with norm 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
y.norm1 &lt;- norm1(data$y)
</code></pre>

<hr>
<h2 id='orthnormal'>Gram-Schmidt orthonormalization</h2><span id='topic+orthnormal'></span>

<h3>Description</h3>

<p>Gram-Schmidt orthonormalization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orthnormal(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orthnormal_+3A_x">X</code></td>
<td>
<p>a n x p matrix of n observations and p predictors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function orthonormalizes any n x p matrix.
</p>


<h3>Value</h3>

<p>A n x p matrix of n observations and p predictors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
x.orth &lt;- orthnormal(data$X)
</code></pre>

<hr>
<h2 id='sOLS.comp.d'>Structured OLS (sOLS) outer level BIC criterion to estimate dimension with
eigen-decomposition</h2><span id='topic+sOLS.comp.d'></span>

<h3>Description</h3>

<p>Structured OLS (sOLS) outer level BIC criterion to estimate dimension with
eigen-decomposition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sOLS.comp.d(X, sizes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sOLS.comp.d_+3A_x">X</code></td>
<td>
<p>A matrix containing directions estimated from all subpopulations.</p>
</td></tr>
<tr><td><code id="sOLS.comp.d_+3A_sizes">sizes</code></td>
<td>
<p>A vector with the sample sizes of all subpopulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates dimension across the subpopulations using
eigen-decomposition. The order of the subpopulations in the &quot;sizes&quot; vector
should match the one in the &quot;X&quot; matrix. Also, this function returns the
linearly independent directions among all subpopulations.
</p>


<h3>Value</h3>

<p>sOLS.comp.d returns a list containning at least the following
components:
&quot;d&quot;, the dimension estimated across subpopulations;
&quot;u&quot;, the &quot;d&quot; linearly independent directions among the matrix X.
</p>


<h3>References</h3>

<p>Liu, Y., Chiaromonte, F., and Li, B. (2015). Structured Ordinary
Least Squares: a sufficient dimension reduction approach for regressions with
partitioned predictors and heterogeneous units. Submitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v1 &lt;- c(1, 1, 0, 0)
v2 &lt;- c(0, 1, 1, 0)
v3 &lt;- c(0, 0, 1, 1)
v4 &lt;- c(1, 1, 1, 1)
m1 &lt;- cbind(v1, v2)
sizes1 &lt;- c(100, 200)
sOLS.comp.d(m1, sizes1)
m2 &lt;- cbind(v1, v2, v3)
sizes2 &lt;- c(100, 200, 500)
sOLS.comp.d(m2, sizes2)
m3 &lt;- cbind(v1, v3, v4)
sizes3 &lt;- c(100, 500, 1000)
sOLS.comp.d(m3, sizes3)
</code></pre>

<hr>
<h2 id='standmat'>Matrix standardization</h2><span id='topic+standmat'></span>

<h3>Description</h3>

<p>Matrix standardization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standmat(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standmat_+3A_x">x</code></td>
<td>
<p>A n x p matrix of n observations and p predictors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function standardizes a matrix treating each row as a random vector
in an iid sample. It returns a n x p matrix with column-mean zero
and identity-covariance matrix.
</p>


<h3>Value</h3>

<p>A n x p matrix of n observations and p predictors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- gen.data(n=100)
x.std &lt;- standmat(data$X)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
