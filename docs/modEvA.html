<!DOCTYPE html><html><head><title>Help for package modEvA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {modEvA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#modEvA-package'><p>Model Evaluation and Analysis</p></a></li>
<li><a href='#applyThreshold'><p>Apply threshold(s) to model predictions</p></a></li>
<li><a href='#arrangePlots'>
<p>Arrange plots</p></a></li>
<li><a href='#AUC'>
<p>Area Under the Curve</p></a></li>
<li><a href='#Boyce'>
<p>Boyce Index</p></a></li>
<li><a href='#confusionLabel'>
<p>Label predictions according to their confusion matrix category</p></a></li>
<li><a href='#confusionMatrix'>
<p>Confusion matrix</p></a></li>
<li><a href='#Dsquared'>
<p>Explained deviance</p></a></li>
<li><a href='#evaluate'>
<p>Evaluate a model based on the elements of a confusion matrix.</p></a></li>
<li><a href='#evenness'>
<p>Evenness in a binary vector.</p></a></li>
<li><a href='#getBins'>
<p>Get bins of continuous values.</p></a></li>
<li><a href='#getModEqn'>
<p>Get model equation</p></a></li>
<li><a href='#getThreshold'><p>Prediction threshold for a given criterion</p></a></li>
<li><a href='#HLfit'>
<p>Hosmer-Lemeshow goodness of fit</p></a></li>
<li><a href='#inputMunch'>
<p>Munch inputs into 'obs' and 'pred' vectors</p></a></li>
<li><a href='#logLike'>
<p>Log-likelihood</p></a></li>
<li><a href='#lollipop'><p>Lollipop chart</p></a></li>
<li><a href='#MESS'>
<p>Multivariate Environmental Similarity Surfaces based on a data frame</p></a></li>
<li><a href='#MillerCalib'><p>Miller's calibration satistics for logistic regression models</p></a></li>
<li><a href='#mod2obspred'>
<p>Extract observed and predicted values from a model object.</p></a></li>
<li><a href='#modEvAmethods'>
<p>Methods implemented in modEvA functions</p></a></li>
<li><a href='#multModEv'>
<p>Multiple model evaluation</p></a></li>
<li><a href='#OA'><p>Overlap Analysis</p></a></li>
<li><a href='#optiPair'>
<p>Optimize the classification threshold for a pair of related model evaluation measures.</p></a></li>
<li><a href='#optiThresh'>
<p>Optimize threshold for model evaluation.</p></a></li>
<li><a href='#plotGLM'>
<p>Plot a generalized linear model</p></a></li>
<li><a href='#predDensity'>
<p>Plot the density of predicted values for presences and absences.</p></a></li>
<li><a href='#predPlot'>
<p>Plot predicted values for presences and absences, optionally classified according to a prediction threshold.</p></a></li>
<li><a href='#prevalence'>
<p>Prevalence</p></a></li>
<li><a href='#ptsrast2obspred'>
<p>Observed and predicted values from presence points and a raster map.</p></a></li>
<li><a href='#quantReclass'><p>Reclassify continuous values based on quantiles</p></a></li>
<li><a href='#range01'>
<p>Shrink or stretch a vector to make it range between 0 and 1</p></a></li>
<li><a href='#RMSE'>
<p>Root mean square error</p></a></li>
<li><a href='#rotif.mods'><p>Rotifer distribution models</p></a></li>
<li><a href='#RsqGLM'><p>R-squared measures for GLMs</p></a></li>
<li><a href='#similarity'>
<p>Similarity measures</p></a></li>
<li><a href='#standard01'>
<p>Standardize to 0-1 (or vice-versa)</p></a></li>
<li><a href='#threshMeasures'>
<p>Threshold-based measures of model evaluation</p></a></li>
<li><a href='#varImp'><p>Variable importance.</p></a></li>
<li><a href='#varPart'>
<p>Variation partitioning</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Model Evaluation and Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>3.17</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-06-06</td>
</tr>
<tr>
<td>Author:</td>
<td>Barbosa A.M., Brown J.A., Jimenez-Valverde A., Real R.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>A. Marcia Barbosa &lt;ana.marcia.barbosa@gmail.com&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, methods, terra (&gt; 1.5-50)</td>
</tr>
<tr>
<td>Description:</td>
<td>Analyses species distribution models and evaluates their performance. It includes functions for variation partitioning, extracting variable importance, computing several metrics of model discrimination and calibration performance, optimizing prediction thresholds based on a number of criteria, performing multivariate environmental similarity surface (MESS) analysis, and displaying various analytical plots. Initially described in Barbosa et al. (2013) &lt;<a href="https://doi.org/10.1111%2Fddi.12100">doi:10.1111/ddi.12100</a>&gt;.</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://modeva.r-forge.r-project.org/">http://modeva.r-forge.r-project.org/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-06 10:58:51 UTC; marcia</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-06 11:50:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='modEvA-package'>Model Evaluation and Analysis</h2><span id='topic+modEvA-package'></span><span id='topic+modEvA'></span>

<h3>Description</h3>

<p>The modEvA package can analyse species distribution models and evaluate their performance. It includes functions for performing variation partitioning; calculating several measures of model discrimination, classification, explanatory power, and calibration; optimizing prediction thresholds based on a number of criteria; performing multivariate environmental similarity surface (MESS) analysis; and displaying various analytical plots.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> modEvA</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 3.17</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-06-06</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Barbosa A.M., Brown J.A., Jimenez-Valverde A., Real R.
</p>
<p>A. Marcia Barbosa &lt;ana.marcia.barbosa@gmail.com&gt;
</p>


<h3>References</h3>

<p>Barbosa A.M., Real R., Munoz A.R. &amp; Brown J.A. (2013) New measures for assessing model equilibrium and prediction mismatch in species distribution models. Diversity and Distributions 19: 1333-1338 (DOI: 10.1111/ddi.12100)
</p>


<h3>See Also</h3>

<p><span class="pkg">PresenceAbsence</span>, <span class="pkg">ROCR</span>, <span class="pkg">verification</span>, <span class="pkg">Metrics</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

# plot this model:
plotGLM(model = mod)

# compute the Root Mean Square Error of the model:
RMSE(model = mod)

# extract variable importance from the model:
varImp(model = mod)

# calculate the area under the ROC curve for the model:
AUC(model = mod)

# calculate some threshold-based measures for this model:
threshMeasures(model = mod, thresh = 0.5)
threshMeasures(model = mod, thresh = "preval")

# calculate optimal thresholds based on several criteria:
optiThresh(model = mod, measures = c("CCR", "Sensitivity", "kappa", "TSS"),
ylim = c(0, 1), pch = 20, cex = 0.5)

# calculate the optimal threshold balancing two evaluation measures:
optiPair(model = mod, measures = c("Sensitivity", "Specificity"))

# calculate the Boyce index, explained deviance, Hosmer-Lemeshow goodness-of-fit,
# Miller's calibration stats, and (pseudo) R-squared values for the model:
Boyce(model = mod)
Dsquared(model = mod)
HLfit(model = mod, bin.method = "quantiles")
MillerCalib(model = mod)
RsqGLM(model = mod)

# calculate a bunch of evaluation measures for a set of models:
multModEv(models = rotif.mods$models[1:4], thresh = "preval",
bin.method = "quantiles")
</code></pre>

<hr>
<h2 id='applyThreshold'>Apply threshold(s) to model predictions</h2><span id='topic+applyThreshold'></span>

<h3>Description</h3>

<p>This function applies a threshold value to the continuous predictions of a model, converting them to binary predictions: 1 for values above the threshold, and 0 for values below it. If two thresholds are provided (e.g. to separate high, low and intermediate predictions), the result is 0 below the lowest threshold, 1 above the highest threshold, and 0.5 between them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>applyThreshold(model = NULL, obs = NULL, pred = NULL, thresh, right = FALSE,
interval = 0.01, quant = 0, na.rm = TRUE, verbosity = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="applyThreshold_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_thresh">thresh</code></td>
<td>
<p>numeric vector of length 1 or 2, containing the threshold value(s) with which to reclassify 'pred', or the criteria under which to compute these thresholds &ndash; run modEvAmethods(&quot;getThreshold&quot;) for available options, and see Details in <code><a href="#topic+getThreshold">getThreshold</a></code> for their description.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_right">right</code></td>
<td>
<p>logical value indicating if the interval should be closed on the right (and open on the left) or vice versa, i.e., if predictions equalling the threshold value(s) should be classified as lower rather than higher. The default is FALSE.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_interval">interval</code></td>
<td>
<p>Argument to pass to <code><a href="#topic+optiThresh">optiThresh</a></code> indicating the interval between the thresholds to test, if 'thresh' implies optimizing a threshold-based measure. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_quant">quant</code></td>
<td>
<p>Numeric value indicating the proportion of presences to discard if any of 'thresh' is &quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether NA values should be ignored. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="applyThreshold_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to print. Defaults to 2, for the maximum amount of messages.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several criteria have been proposed for selecting thresholds with which to convert continuous model predictions (of presence probability, habitat suitability or alike) into binary predictions of presence or absence. A threshold is required for computing threshold-based model evaluation metrics, such as those in <code><a href="#topic+threshMeasures">threshMeasures</a></code>. This function reclassifies the predictions of a model given one or two numeric thresholds, or one or two threshold selection criteria implemented in <code><a href="#topic+getThreshold">getThreshold</a></code>.
</p>


<h3>Value</h3>

<p>This function returns an object of the same class as 'pred' with the reclassified values after application of the <code>thresh</code>old.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getThreshold">getThreshold</a></code>, <code><a href="#topic+threshMeasures">threshMeasures</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

applyThreshold(model = mod, thresh = "maxTSS")


# you can also use applyThreshold with vectors of observed and predicted values:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

applyThreshold(pred = prediction, thresh = 0.5)

applyThreshold(pred = prediction, thresh = c(0.2, 0.8))

applyThreshold(pred = prediction, thresh = "meanPred")

applyThreshold(obs = presabs, pred = prediction, thresh = "preval")

applyThreshold(obs = presabs, pred = prediction, thresh = "MTP")

applyThreshold(obs = presabs, pred = prediction, thresh = "MTP",
quant = 0.05)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='arrangePlots'>
Arrange plots
</h2><span id='topic+arrangePlots'></span>

<h3>Description</h3>

<p>Get an appropriate row/column combination (for <code>par(mfrow)</code>) for arranging a given number of plots within a plotting window.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arrangePlots(n.plots, landscape = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arrangePlots_+3A_n.plots">n.plots</code></td>
<td>

<p>number of plots to be placed in the graphics device.
</p>
</td></tr>
<tr><td><code id="arrangePlots_+3A_landscape">landscape</code></td>
<td>

<p>logical, whether the plotting window should be landscape/horizontal (number of columns larger than the number of rows) or not. The value does not make a difference if the number of plots makes for a square plotting window.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used internally by <code>optiThresh</code>, but can also be useful outside it.
</p>


<h3>Value</h3>

<p>An integer vector of the form c(nr, nc) indicating, respectively, the number of rows and of columns of plots to set in the graphics device.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+layout">layout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>arrangePlots(10)

arrangePlots(10, landscape = TRUE)


# a more practical example:

data(iris)

names(iris)

# say you want to plot all columns in a nicely arranged plotting window:

par(mfrow = arrangePlots(ncol(iris)))

for (i in 1:ncol(iris)) {
  plot(1:nrow(iris), iris[, i])
}
</code></pre>

<hr>
<h2 id='AUC'>
Area Under the Curve
</h2><span id='topic+AUC'></span>

<h3>Description</h3>

<p>This function calculates the Area Under the Curve of the receiver operating characteristic (ROC) plot, or alternatively the precision-recall (PR) plot, for either a model object or two matching vectors of observed binary (1 for occurrence vs. 0 for non-occurrence) and predicted continuous (e.g. occurrence probability) values, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC(model = NULL, obs = NULL, pred = NULL, simplif = FALSE,
interval = 0.01, FPR.limits = c(0, 1), curve = "ROC",
method = NULL, plot = TRUE, diag = TRUE, diag.col = "grey",
diag.lty = 1, curve.col = "black", curve.lty = 1, curve.lwd = 2,
plot.values = TRUE, plot.digits = 3, plot.preds = FALSE,
grid = FALSE, grid.lty = 1, xlab = "auto", ylab = "auto",
ticks = FALSE, na.rm = TRUE, rm.dup = FALSE, verbosity = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="AUC_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="AUC_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="AUC_+3A_simplif">simplif</code></td>
<td>
<p>logical, whether to use a faster version that returns only the AUC value (and the plot if 'plot = TRUE').</p>
</td></tr>
<tr><td><code id="AUC_+3A_fpr.limits">FPR.limits</code></td>
<td>
<p>(NOT YET IMPLEMENTED) numerical vector of length 2 indicating the limits of false positive rate between which to calculate a partial AUC. The default is c(0, 1), for considering the whole AUC. Pending implementation. Meanwhile, you can try e.g. the <code>roc</code> function in the <span class="pkg">pROC</span> package.</p>
</td></tr>
<tr><td><code id="AUC_+3A_curve">curve</code></td>
<td>
<p>character indicating whether to compute the &quot;ROC&quot; (receiver operating charateristic) or the &quot;PR&quot; (precision-recall) curve.</p>
</td></tr>
<tr><td><code id="AUC_+3A_interval">interval</code></td>
<td>
<p>interval of threshold values at which to calculate the true and false positive rates. Defaults to 0.01 for relatively quick while still relatively accurate computation. Note that, if method = &quot;rank&quot; (the default if curve = &quot;ROC&quot;), this does not affect the obtained AUC value (although it can affect the size of the plotted curve, especially when prevalence is low), as the AUC is calculated with the Mann-Whitney-Wilcoxon statistic and is therefore threshold-independent. If method != &quot;rank&quot; (or, by extension, if curve = &quot;PR&quot; &ndash; see 'method' argument), setting 'interval' to smaller values will provide more accurate AUC values. The size of the 'interval' also affects the resulting 'meanPrecision', as this is averaged across all threshold values.</p>
</td></tr>
<tr><td><code id="AUC_+3A_method">method</code></td>
<td>
<p>character indicating with which method to calculate the AUC value. Available options are &quot;rank&quot; (the default and most accurate, but implemented only if curve = &quot;ROC&quot;) and &quot;trapezoid&quot; (the default if curve = &quot;PR&quot;). The latter is computed more accurately if 'interval' is decreased (see 'interval' argument).</p>
</td></tr>
<tr><td><code id="AUC_+3A_plot">plot</code></td>
<td>
<p>logical, whether or not to plot the curve. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_diag">diag</code></td>
<td>
<p>logical, whether or not to add the reference diagonal (if plot = TRUE). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_diag.col">diag.col</code></td>
<td>
<p>line colour for the reference diagonal (if diag = TRUE).</p>
</td></tr>
<tr><td><code id="AUC_+3A_diag.lty">diag.lty</code></td>
<td>
<p>line type for the reference diagonal (if diag = TRUE).</p>
</td></tr>
<tr><td><code id="AUC_+3A_curve.col">curve.col</code></td>
<td>
<p>line colour for the curve.</p>
</td></tr>
<tr><td><code id="AUC_+3A_curve.lty">curve.lty</code></td>
<td>
<p>line type for the curve.</p>
</td></tr>
<tr><td><code id="AUC_+3A_curve.lwd">curve.lwd</code></td>
<td>
<p>line width for the curve.</p>
</td></tr>
<tr><td><code id="AUC_+3A_plot.values">plot.values</code></td>
<td>
<p>logical, whether or not to show in the plot the values associated to the curve (e.g., the AUC). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_plot.digits">plot.digits</code></td>
<td>
<p>integer number indicating the number of digits to which the values in the plot should be <code><a href="base.html#topic+round">round</a></code>ed. Defaults to 3. This argument is ignored if 'plot' or 'plot.values' are set to FALSE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_plot.preds">plot.preds</code></td>
<td>
<p>logical value indicating whether the proportions of 'pred' values for each threshold should be plotted as proportionally sized blue circles. Can also be provided as a character vector specifying if the circles should be plotted on the &quot;curve&quot; (the default) and/or at the &quot;bottom&quot; of the plot. The default is FALSE for no circles, but it may be interesting to try it, especially if your curve has long straight lines or does not cover the full length of the plot.</p>
</td></tr>
<tr><td><code id="AUC_+3A_grid">grid</code></td>
<td>
<p>logical, whether or not to add a grid to the plot, marking the analysed thresholds. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_grid.lty">grid.lty</code></td>
<td>
<p>line type for the grid (if grid = TRUE).</p>
</td></tr>
<tr><td><code id="AUC_+3A_xlab">xlab</code></td>
<td>
<p>label for the x axis. By default, a label is automatically generated according to the specified 'curve'.</p>
</td></tr>
<tr><td><code id="AUC_+3A_ylab">ylab</code></td>
<td>
<p>label for the y axis. By default, a label is automatically generated according to the specified 'curve'.</p>
</td></tr>
<tr><td><code id="AUC_+3A_ticks">ticks</code></td>
<td>
<p>logical, whether or not to add blue tick marks at the bottom of the plot to mark the thresholds at which there were values from which to to draw the curve. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating if missing values should be ignored in computations. The default is TRUE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="AUC_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="AUC_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to the <code><a href="base.html#topic+plot">plot</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of the &quot;ROC&quot; curve (the default), the AUC is a measure of the overall discrimination power of the predictions, or the probability that an occurrence site has a higher predicted value than a non-occurrence site. It can thus be calculated with the Wilcoxon rank sum statistic, as is done with the default method=&quot;rank&quot;. There's also an option to compute, instead of the ROC curve, the precision-recall (&quot;PR&quot;) curve, which is more robust to imbalanced data, e.g. species rarity (Sofaer et al. 2019), as it doesn't value true negatives.
</p>
<p>If 'curve' is set to &quot;PR&quot;, or if 'method' is manually set to &quot;trapezoid&quot;, the AUC value will be more accurate if 'interval' is decreased (see 'method' and 'interval' arguments above). The plotted curve will also be more accurate with smaller 'interval' values, especially for imbalanced datasets (which can cause an apparent disagreement between the look of the curve and the actual value of the AUC).
</p>
<p>Mind that the AUC has been widely criticized (e.g. Lobo et al. 2008, Jimenez-Valverde et al. 2013), but is still among the most widely used metrics in model evaluation. It is highly correlated with species prevalence (as are all model discrimination and classification metrics), so prevalence is also output by the AUC function (if <code>simplif = FALSE</code>, the default) for reference.
</p>
<p>Although there are functions to calculate the AUC in other R packages (e.g. <span class="pkg">ROCR</span>, <span class="pkg">PresenceAbsence</span>, <span class="pkg">verification</span>, <span class="pkg">Epi</span>, <span class="pkg">PRROC</span>, <span class="pkg">PerfMeas</span>, <span class="pkg">precrec</span>), the <code>AUC</code> function is more compatible with the remaining functions in <span class="pkg">modEvA</span>, and it can be applied not only to a set of observed vs. predicted values, but also directly to a model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;.
</p>


<h3>Value</h3>

<p>If <code>simplif = TRUE</code>, the function returns only the AUC value (a numeric value between 0 and 1). Otherwise (the default), it returns a <code>list</code> with the following components:
</p>
<table>
<tr><td><code>thresholds</code></td>
<td>
<p>a data frame of the true and false positives, the sensitivity, specificity and recall of the predictions, and the number of predicted values at each analysed threshold.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>the total number of obervations.</p>
</td></tr>
<tr><td><code>prevalence</code></td>
<td>
<p>the proportion of presences (i.e., ones) in the data (which correlates with the AUC of the &quot;ROC&quot; plot).</p>
</td></tr>
<tr><td><code>AUC</code></td>
<td>
<p>the value of the AUC).</p>
</td></tr>
<tr><td><code>AUCratio</code></td>
<td>
<p>the ratio of the obtained AUC value to the null expectation (0.5).</p>
</td></tr>
<tr><td><code>meanPrecision</code></td>
<td>
<p>the arithmetic mean of precision (proportion of predicted presences actually observed as presences) across all threshold values (defined by 'interval'). It is close to the AUC of the precision-recall (PR) curve.</p>
</td></tr>
<tr><td><code>GiniCoefficient</code></td>
<td>
<p>the Gini coefficient, measured as the area between the ROC curve and the diagonal divided by the area of the upper triangle (2*AUC-1).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Lobo, J.M., Jimenez-Valverde, A. &amp; Real, R. (2008). AUC: a misleading measure of the performance of predictive distribution models. Global Ecology and Biogeography 17: 145-151
</p>
<p>Jimenez-Valverde, A., Acevedo, P., Barbosa, A.M., Lobo, J.M. &amp; Real, R. (2013). Discrimination capacity in species distribution models depends on the representativeness of the environmental domain. Global Ecology and Biogeography 22: 508-516
</p>
<p>Sofaer, H.R., Hoeting, J.A. &amp; Jarnevich, C.S. (2019). The area under the precision-recall curve as a performance metric for rare binary events. Methods in Ecology and Evolution, 10: 565-577
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]


# compute the AUC:

AUC(model = mod)

AUC(model = mod, simplif = TRUE)

AUC(model = mod, curve = "PR")

AUC(model = mod, interval = 0.1, grid = TRUE)

AUC(model = mod, plot.preds = TRUE)

AUC(model = mod, ticks = TRUE)

AUC(model = mod, plot.preds = c("curve", "bottom"))


# you can also use vectors of observed and predicted values
# instead of a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

AUC(obs = presabs, pred = prediction)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='Boyce'>
Boyce Index
</h2><span id='topic+Boyce'></span>

<h3>Description</h3>

<p>This function computes the (continuous) Boyce index (Boyce 2002; Hirzel et al. 2006) for either: 1) a model object; or 2) two paired numeric vectors of observed (binary, 1 for occurrence vs. 0 for no occurrence records) and predicted (continuous, e.g. occurrence probability) values; or 3) a set of presence point coordinates and a raster map with the predicted values for the entire model evaluation area. This metric is designed for evaluating model predictions against presence/background data (i.e. presence/available, where &quot;available&quot; includes both presences and absences; Boyce 2002), so the function uses the model predictions for the presence sites (ones) against the predictions for the entire dataset (ones and zeros).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Boyce(model = NULL, obs = NULL, pred = NULL, n.bins = NA,
bin.width = "default", res = 100, method = "spearman", rm.dup.classes = FALSE,
rm.dup.points = FALSE, plot = TRUE, plot.lines = TRUE, plot.values = TRUE,
plot.digits = 3, na.rm = TRUE, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Boyce_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments (e.g. for external test data) instead of 'model'.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_n.bins">n.bins</code></td>
<td>
<p>number of classes or bins (e.g. 10) in which to group the 'pred' values, or a vector with the bin thresholds. If <code>n.bins = NA</code> (the default), a moving window is used (see next parameters), so as to compute the &quot;continuous Boyce index&quot; (Hirzel et al. 2006).</p>
</td></tr>
<tr><td><code id="Boyce_+3A_bin.width">bin.width</code></td>
<td>
<p>width of the moving window (if n.bins = NA), in the units of 'pred' (e.g. 0.1). By default, it is 1/10th of the 'pred' range).</p>
</td></tr>
<tr><td><code id="Boyce_+3A_res">res</code></td>
<td>
<p>resolution of the moving window (if n.bins = NA). By default it is 100 focals, providing 100 moving bins).</p>
</td></tr>
<tr><td><code id="Boyce_+3A_method">method</code></td>
<td>
<p>argument to be passed to <code><a href="stats.html#topic+cor">cor</a></code> indicating which correlation coefficient to use. The default is <code>'spearman'</code> as per Boyce et al. (2002), but <code>'pearson'</code> and <code>'kendall'</code> can also be used.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_rm.dup.classes">rm.dup.classes</code></td>
<td>
<p>if <code>TRUE</code> (as in 'ecospat::ecospat.boyce') and if there are different bins with the same predicted/expected ratio, only one of each is used to compute the correlation. See Examples.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_rm.dup.points">rm.dup.points</code></td>
<td>
<p>if <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_plot">plot</code></td>
<td>
<p>logical, whether or not to plot the predicted/expected ratio against the median prediction of each bin. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_plot.lines">plot.lines</code></td>
<td>
<p>logical, whether or not to add lines connecting the points in the plot (if plot=TRUE). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_plot.values">plot.values</code></td>
<td>
<p>logical, whether or not to show in the plot the value of the Boyce index. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_plot.digits">plot.digits</code></td>
<td>
<p>number of digits to which the value in the plot should be <code><a href="base.html#topic+round">round</a></code>ed (if 'plot' and 'plot.values' are TRUE). Defaults to 3.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating if missing values should be removed from computations. The default is TRUE.</p>
</td></tr>
<tr><td><code id="Boyce_+3A_...">...</code></td>
<td>
<p>some additional arguments can be passed to <code><a href="base.html#topic+plot">plot</a></code>, e.g. 'main' or 'xlim'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Boyce index is the correlation between model predictions and area-adjusted frequencies (i.e., observed vs. expected proportion of occurrences) along different prediction classes (bins). In other words, it measures how model predictions differ from a random distribution of the observed presences across the prediction gradient (Boyce et al. 2002). It can take values between -1 and 1. Positive values indicate that presences are more frequent than expected by chance (given availability) in areas with higher predicted values. Values close to zero mean that predictions are no better than random (i.e. presences are distributed among prediction classes as expected by chance), and negative values indicate counter predictions (i.e., presences are more frequent in areas with lower predicted values).
</p>
<p>The R code is largely based on the 'ecospat.boyce' function in the <span class="pkg">ecospat</span> package (version 3.2.1), but it is modified to match the input types in the remaining functions of 'modEvA', and to return a more complete and informative output.
</p>


<h3>Value</h3>

<p>This function returns a <code>list</code> with the following components:
</p>
<table>
<tr><td><code>bins</code></td>
<td>
<p>a data frame with the number of values in each bin, their median and range of predicted values, and the corresponding predicted/expected ratio of presences.</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>the numeric value of the Boyce index, i.e. the coefficient of correlation between the median predicted value in each bin and the corresponding predicted/expected ratio.</p>
</td></tr>
</table>
<p>If plot=TRUE (the default), the function also plots the predicted/expected ratio for the utilized bins along the prediction range. A good model should yield a monotonically increasing curve (but see Note).
</p>


<h3>Note</h3>

<p>This index is designed for evaluating predictions of habitat suitability, not presence probability (which also depends on the species' presence/absence ratio: rare species do not usually show high proportions of presences, even in highly suitable areas). If your predictions are of presence probability with a prevalence different from 50% presences, you should convert those predictions e.g. with the <code>Fav</code> function of package <span class="pkg">fuzzySim</span>, before evaluating them with the Boyce index.
</p>
<p>In bins with overly small sample sizes, the comparison between median prediction and random expectation may not be meaningful, although these bins will equally contribute to the overall Boyce index. When there are bins with less than 30 values, a warning is emitted and their points are plotted in red, but mind that 30 is a largely arbitrary number. See the $bins$bin.N section of the console output, and use the 'bin.width' argument to enlarge the bins.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa, with significant chunks of code from the 'ecospat::ecospat.boyce' function by Blaise Petitpierre and Frank Breiner (<span class="pkg">ecospat</span> package version 3.2.1).
</p>


<h3>References</h3>

<p>Boyce, M.S., P.R. Vernier, S.E. Nielsen &amp; F.K.A. Schmiegelow (2002) Evaluating resource selection functions. Ecological Modelling 157: 281-300
</p>
<p>Hirzel, A.H., G. Le Lay, V. Helfer, C. Randin &amp; A. Guisan (2006) Evaluating the ability of habitat suitability models to predict species presences. Ecological Modelling 199: 142-152
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

# compute the Boyce index:
Boyce(model = mod, main = "My model Boyce plot")
Boyce(model = mod, main = "My model Boyce plot", rm.dup.classes = TRUE)


# you can also use vectors of observed and predicted values
# instead of a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

Boyce(obs = presabs, pred = prediction)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='confusionLabel'>
Label predictions according to their confusion matrix category
</h2><span id='topic+confusionLabel'></span>

<h3>Description</h3>

<p>This function labels the (typically continuous) predictions of a binary-response model according to their confusion matrix categories, i.e., it classifies each prediction into a false positive, false negative, true positive or true negative, given a user-defined threshold value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusionLabel(model = NULL, obs = NULL, pred = NULL, thresh,
interval = 0.01, quant = 0, verbosity = 2, na.rm = FALSE,
rm.dup = FALSE, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusionLabel_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments (e.g. for external test data) instead of 'model'.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_thresh">thresh</code></td>
<td>
<p>numeric value of the threshold to separate predicted presences from predicted absences; can be &quot;preval&quot;, to use the prevalence of 'obs' (or of the response variable in 'model') as the threshold, or any real number between 0 and 1. See Details in <code><a href="#topic+threshMeasures">threshMeasures</a></code> for an informed choice.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_interval">interval</code></td>
<td>
<p>numeric value, used if 'thresh' is a threshold optimization method such as &quot;maxKappa&quot; or &quot;maxTSS&quot;, indicating the interval between the thresholds to test. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_quant">quant</code></td>
<td>
<p>numeric value indicating the proportion of presences to discard if thresh=&quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_na.rm">na.rm</code></td>
<td>
<p>logical argument indicating whether to remove (with a warning saying how many) rows with NA in any of the 'obs' or 'pred' values. The default is FALSE.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_rm.dup">rm.dup</code></td>
<td>
<p>if <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> (the default) and if 'pred' is a SpatRaster, the output (also a SpatRaster) is automatically plotted. Map categories have a set colour table, built with terra::coltab().</p>
</td></tr>
<tr><td><code id="confusionLabel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to terra::plot() (if 'pred' is a SpatRaster and plot=TRUE), such as 'mar', 'axes' or 'legend'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a character vector (or a categorical SpatRaster, if 'pred' is of that class) of the same length as 'pred', or of the same number of rows as the data in 'model', containing the confusion matrix label for each value.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+confusionMatrix">confusionMatrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

confusionLabel(model = mod, thresh = 0.5)


# you can instead use vectors of observed and predicted values:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

confusionLabel(obs = presabs, pred = prediction, thresh = 0.5)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='confusionMatrix'>
Confusion matrix
</h2><span id='topic+confusionMatrix'></span>

<h3>Description</h3>

<p>This function computes the confusion (or contingency) matrix for a binary-response model, containing the numbers of false positives, false negatives, true positives and true negatives, given a user-defined threshold value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusionMatrix(model = NULL, obs = NULL, pred = NULL, thresh, interval = 0.01,
quant = 0, verbosity = 2, na.rm = TRUE, rm.dup = FALSE, plot = FALSE,
classes = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusionMatrix_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments (e.g. for external test data) instead of 'model'.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_thresh">thresh</code></td>
<td>
<p>numeric value of the threshold to separate predicted presences from predicted absences; can be &quot;preval&quot;, to use the prevalence of 'obs' (or of the response variable in 'model') as the threshold, or any real number between 0 and 1. See Details in <code><a href="#topic+threshMeasures">threshMeasures</a></code> for an informed choice.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_interval">interval</code></td>
<td>
<p>numeric value, used if 'thresh' is a threshold optimization method such as &quot;maxKappa&quot; or &quot;maxTSS&quot;, indicating the interval between the thresholds to test. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_quant">quant</code></td>
<td>
<p>numeric value indicating the proportion of presences to discard if thresh=&quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_na.rm">na.rm</code></td>
<td>
<p>logical argument indicating whether to remove (with a warning saying how many) rows with NA in any of the 'obs' or 'pred' values. The default is FALSE.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_rm.dup">rm.dup</code></td>
<td>
<p>if <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_plot">plot</code></td>
<td>
<p>logical argument indicating whether to also plot the matrix as an image. The default is FALSE (for back-compatibility).</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_classes">classes</code></td>
<td>
<p>logical argument indicating whether the matrix image (if plot=TRUE) should have qualitative colours, matching the output of <code><a href="#topic+confusionLabel">confusionLabel</a></code> for SpatRasters. The default is FALSE, in which case the colours are proportional to the values in each section of the matrix, and the palette can be user-specified with the 'col' argument for 'plot' (see Examples).</p>
</td></tr>
<tr><td><code id="confusionMatrix_+3A_...">...</code></td>
<td>
<p>some additional arguments can be passed to <code><a href="graphics.html#topic+image">image</a></code> (and through to <code><a href="base.html#topic+plot">plot</a></code>) if plot=TRUE, such as 'main', 'font.main' or 'cex.main' (not 'axes', 'xlab' or 'ylab', which are already defined by confusionMatrix).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a data frame containing the four values of the confusion matrix.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+confusionLabel">confusionLabel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

confusionMatrix(model = mod, thresh = 0.5)

confusionMatrix(model = mod, thresh = 0.5, plot = TRUE)

confusionMatrix(model = mod, thresh = 0.5, plot = TRUE,
col = hcl.colors(100, "blues"))

confusionMatrix(model = mod, thresh = 0.5, plot = TRUE, classes = TRUE,
main = "Confusion matrix")


# you can instead use vectors of observed and predicted values:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

confusionMatrix(obs = presabs, pred = prediction, thresh = 0.5, plot = TRUE)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='Dsquared'>
Explained deviance
</h2><span id='topic+Dsquared'></span>

<h3>Description</h3>

<p>This function computes the (adjusted) amount of deviance accounted for by a model, given a model object or a set of observed and predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dsquared(model = NULL, obs = NULL, pred = NULL, family = NULL,
adjust = FALSE, npar = NULL, na.rm = TRUE, rm.dup = FALSE,
dismo.version = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dsquared_+3A_model">model</code></td>
<td>
<p>a model object of class implemented in <code><a href="#topic+mod2obspred">mod2obspred</a></code>. If this argument is provided, 'obs' and 'pred' will be extracted with that function. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed values of the response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of presence points, in which case the 'obs' vector of presences and absences will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values, of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_family">family</code></td>
<td>
<p>a character vector (i.e. in quotes) of length 1 specifying the family of the model that generated the 'pred' values. This argument is ignored if <code>model</code> is provided and is of a class for which <code><a href="stats.html#topic+family">family</a></code> provides a result; otherwise (i.e. if 'obs' and 'pred' are provided rather than a model object), family can be specified by the user, or (if left NULL) will be guessed (with a message) given the values of the response variable.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_adjust">adjust</code></td>
<td>
<p>logical, whether or not to adjust the D-squared value for the number of observations and parameters in the model (see Details). The default is <code>FALSE</code>; <code>TRUE</code> requires either providing the <code>model</code> object of class GLM, or specifying the number of parameters in the model that produced the <code>pred</code> values.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_npar">npar</code></td>
<td>
<p>integer value indicating the number of parameters in the model. This argument is ignored and taken from <code>model</code> if this argument is provided and of class GLM, or if <code>adjust = FALSE</code>.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="Dsquared_+3A_dismo.version">dismo.version</code></td>
<td>
<p>Logical value indicating whether the deviance should be computed with code from the dismo::calc.deviance() function. The default is FALSE, for back-compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Linear models have an R-squared value (commonly provided with the model summary) which measures the proportion of variation that the model accounts for. For generalized linear models (GLMs) and others based on non-continuous response variables, an equivalent is the amount of deviance accounted for (D-squared; Guisan &amp; Zimmermann 2000), though this value is not routinely provided with the model summary. The <code>Dsquared</code> function calculates it as the proportion of the null deviance (i.e. the deviance of a model with no predictor variables) that is accounted for by the model. There is also an option to compute the adjusted D-squared, which takes into account the number of observations and the number of parameters, thus allowing direct comparison among the output for different models (Weisberg 1980, Guisan &amp; Zimmermann 2000).
</p>
<p>The function computes the mean residual deviance (as in the <code>calc.deviance</code> function of package <span class="pkg">dismo</span>) of the observed (response) against the predicted values, and the mean deviance of a null model (with no predictor variables), i.e. of the response against the mean of the response. Finally, it gets the explained deviance as (null-residual)/null.
</p>


<h3>Value</h3>

<p>The function returns a numeric value indicating the (optionally adjusted) proportion of deviance accounted for by the input model predictions.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa, with parts of code from 'dismo::calc.deviance' by John R. Leathwick and Jane Elith
</p>


<h3>References</h3>

<p>Guisan, A. &amp; Zimmermann, N.E. (2000) Predictive habitat distribution models in ecology. Ecological Modelling 135: 147-186
</p>
<p>Weisberg, S. (1980) Applied Linear Regression. Wiley, New York
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotGLM">plotGLM</a></code>, <code><a href="#topic+RsqGLM">RsqGLM</a></code>, <code>dismo::calc.deviance</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

Dsquared(model = mod)

Dsquared(model = mod, adjust = TRUE)


# you can also use Dsquared with vectors of observed and predicted values
# instead of with a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values
parameters &lt;- attributes(logLik(mod))$df

Dsquared(obs = presabs, pred = prediction, family = "binomial")

Dsquared(obs = presabs, pred = prediction, family = "binomial",
adjust = TRUE, npar = parameters)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='evaluate'>
Evaluate a model based on the elements of a confusion matrix.
</h2><span id='topic+evaluate'></span>

<h3>Description</h3>

<p>This function evaluates the classification performance of a model based on the values of a confusion matrix obtained at a particular threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate(a, b, c, d, N = NULL, measure = "CCR")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate_+3A_a">a</code></td>
<td>
<p>number of correctly predicted presences</p>
</td></tr>
<tr><td><code id="evaluate_+3A_b">b</code></td>
<td>
<p>number of absences incorrectly predicted as presences</p>
</td></tr>
<tr><td><code id="evaluate_+3A_c">c</code></td>
<td>
<p>number of presences incorrectly predicted as absences
</p>
</td></tr>
<tr><td><code id="evaluate_+3A_d">d</code></td>
<td>
<p>number of correctly predicted absences</p>
</td></tr>
<tr><td><code id="evaluate_+3A_n">N</code></td>
<td>
<p>total number of cases. If NULL (the default), it is calculated automatically by adding up a, b, c and d.)</p>
</td></tr>
<tr><td><code id="evaluate_+3A_measure">measure</code></td>
<td>
<p>a character vector of length 1 indicating the evaluation measure to use. Type <code>modEvAmethods("threshMeasures")</code> for available options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of measures can be used to evaluate continuous model predictions against observed binary occurrence data (Fielding &amp; Bell 1997; Liu et al. 2011; Barbosa et al. 2013; Leroy et al. 2018). The 'evaluate' function can calculate a few threshold-based classification measures from the values of a confusion matrix obtained at a particular threshold. The 'evaluate' function is used internally by <code><a href="#topic+threshMeasures">threshMeasures</a></code>. It can also be accessed directly by the user, but it is usually more practical to use 'threshMeasures', which calculates the confusion matrix automatically.
</p>


<h3>Value</h3>

<p>The value of the specified evaluation measure.
</p>


<h3>Note</h3>

<p>Some measures (e.g. NMI, odds ratio) don't work with zeros in (some parts of) the confusion matrix. Also, TSS and NMI are not symmetrical, i.e. &quot;obs&quot; vs &quot;pred&quot; is different from &quot;pred&quot; vs &quot;obs&quot;.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Barbosa A.M., Real R., Munoz A.R. &amp; Brown J.A. (2013) New measures for assessing model equilibrium and prediction mismatch in species distribution models. Diversity and Distributions, 19: 1333-1338
</p>
<p>Fielding A.H. &amp; Bell J.F. (1997) A review of methods for the assessment of prediction errors in conservation presence/absence models. Environmental Conservation 24: 38-49
</p>
<p>Leroy B., Delsol R., Hugueny B., Meynard C.M., Barhoumi C., Barbet-Massin M. &amp; Bellard C. (2018) Without quality presence-absence data, discrimination metrics such as TSS can be misleading measures of model performance. Journal of Biogeography 45(9):1994-2002
</p>
<p>Liu C., White M., &amp; Newell G. (2011) Measuring and comparing the accuracy of species distribution models with presence-absence data. Ecography, 34, 232-243.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>evaluate(23, 44, 21, 34)

evaluate(23, 44, 21, 34, measure = "TSS")
</code></pre>

<hr>
<h2 id='evenness'>
Evenness in a binary vector.
</h2><span id='topic+evenness'></span>

<h3>Description</h3>

<p>For building and evaluating species distribution models, the porportion of presences (prevalence) of a species and the balance between the number of presences and absences may be issues to take into account (e.g. Jimenez-Valverde &amp; Lobo 2006, Barbosa et al. 2013). The <code>evenness</code> function calculates the presence-absence balance in a binary (e.g., presence/absence) vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evenness(obs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evenness_+3A_obs">obs</code></td>
<td>
<p>a vector of binary observations (e.g. 1 or 0, male or female, disease or no disease, etc.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number ranging between 0 when all values are the same, and 1 when there are the same number of cases with each value in <code>obs</code>.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Barbosa A.M., Real R., Munoz A.R. &amp; Brown J.A. (2013) New measures for assessing model equilibrium and prediction mismatch in species distribution models. Diversity and Distributions, 19: 1333-1338
</p>
<p>Jimenez-Valverde A. &amp; Lobo J.M. (2006) The ghost of unbalanced species distribution data in geographical model predictions. Diversity and Distributions, 12: 521-524.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prevalence">prevalence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(x &lt;- rep(c(0, 1), each = 5))
(y &lt;- c(rep(0, 3), rep(1, 7)))
(z &lt;- c(rep(0, 7), rep(1, 3)))

prevalence(x)
evenness(x)

prevalence(y)
evenness(y)

prevalence(z)
evenness(z)
</code></pre>

<hr>
<h2 id='getBins'>
Get bins of continuous values.
</h2><span id='topic+getBins'></span>

<h3>Description</h3>

<p>Get continuous predicted values into bins according to specific criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBins(model = NULL, obs = NULL, pred = NULL, id = NULL, 
bin.method, n.bins = 10, fixed.bin.size = FALSE, min.bin.size = 15,
min.prob.interval = 0.1, quantile.type = 7, simplif = FALSE,
verbosity = 2, na.rm = TRUE, rm.dup = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBins_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="getBins_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="getBins_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="getBins_+3A_id">id</code></td>
<td>
<p>optional vector of row identifiers; must be of the same length and in the same order of <code>obs</code> and <code>pred</code> (or of the cases used to build <code>model</code>)</p>
</td></tr>
<tr><td><code id="getBins_+3A_bin.method">bin.method</code></td>
<td>
<p>the method with which to divide the values into bins. Type modEvAmethods(&quot;getBins&quot;) for available options and see Details for more information on these methods.</p>
</td></tr>
<tr><td><code id="getBins_+3A_n.bins">n.bins</code></td>
<td>
<p>the number of bins in which to divide the data.</p>
</td></tr>
<tr><td><code id="getBins_+3A_fixed.bin.size">fixed.bin.size</code></td>
<td>
<p>logical, whether all bins should have (approximally) the same size.</p>
</td></tr>
<tr><td><code id="getBins_+3A_min.bin.size">min.bin.size</code></td>
<td>
<p>integer value defining the minimum number of observations to include in each bin. The default is 15, the minimum required for accurate comparisons within bins (Jovani &amp; Tella 2006, Jimenez-Valverde et al. 2013).</p>
</td></tr>
<tr><td><code id="getBins_+3A_min.prob.interval">min.prob.interval</code></td>
<td>
<p>minimum range of probability values in each bin. The default is 0.1.</p>
</td></tr>
<tr><td><code id="getBins_+3A_quantile.type">quantile.type</code></td>
<td>
<p>argument to pass to <code><a href="stats.html#topic+quantile">quantile</a></code> specifying the algorithm to use if bin.method = &quot;quantiles&quot;. The default is 7 (the <code><a href="stats.html#topic+quantile">quantile</a></code> default in R), but check out other types, e.g. 3 (used by SAS), 6 (used by Minitab and SPSS) or 5 (appropriate for deciles, which correspond to the default n.bins = 10).</p>
</td></tr>
<tr><td><code id="getBins_+3A_simplif">simplif</code></td>
<td>
<p>logical, whether to calculate a faster, simplified version (used internally in other functions). The default is FALSE.</p>
</td></tr>
<tr><td><code id="getBins_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages or warnings to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="getBins_+3A_na.rm">na.rm</code></td>
<td>
<p>logical argument indicating whether to remove (with a warning saying how many) rows with NA in any of the 'obs' or 'pred' values. The default is TRUE, as some 'bin.method' options will fail if there are NAs.</p>
</td></tr>
<tr><td><code id="getBins_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mind that different <code>bin.method</code>s can lead to visibly different results regarding the bins and any operations that depend on them (such as <code><a href="#topic+HLfit">HLfit</a></code>). Currently available <code>bin.method</code>s are:
</p>
<p>- <code>round.prob</code>: probability values are rounded to the number of digits of <code>min.prob.interval</code> - e.g., if min.prob.interval = 0.1 (the default), values under 0.05 get into bin 1 (rounded probability = 0), values between 0.05 and 0.15 get into bin 2  (rounded probability = 0.1), etc. until values with probability over 0.95, which get into bin 11. Arguments n.bins, fixed.bin.size and min.bin.size are ignored by this bin.method.
</p>
<p>- <code>prob.bins</code>: probability values are grouped into bins of the given probability intervals - e.g., if min.prob.interval = 0.1 (the default), bin 1 gets the values between 0 and 0.1, bin 2 gets the values between 0.1 and 0.2, etc. until bin 10 which gets the values between 0.9 and 1. Arguments n.bins, fixed.bin.size and min.bin.size are ignored by this bin.method.
</p>
<p>- <code>size.bins</code>: probability values are grouped into bins of (approximately) equal size, defined by argument min.bin.size. Arguments n.bins and min.prob.interval are ignored by this bin.method.
</p>
<p>- <code>n.bins</code>: probability values are divided into the number of bins given by argument n.bins, and their sizes may or may not be forced to be (approximately) equal, depending on argument fixed.bin.size (which is FALSE by default). Arguments min.bin.size and min.prob.interval are ignored by this bin.method.
</p>
<p>- <code>quantiles</code>: probability values are divided using R function <code><a href="stats.html#topic+quantile">quantile</a></code>, with probability cutpoints defined by the given n.bins (i.e., deciles by default), and with the quantile algorithm defined by argument quantile.type. Arguments fixed.bin.size, min.bin.size and min.prob.interval are ignored by this bin.method.
</p>


<h3>Value</h3>

<p>The output of <code>getBins</code> is a list with the following components:
</p>
<table>
<tr><td><code>prob.bin</code></td>
<td>
<p>the first and last value of each bin</p>
</td></tr>
<tr><td><code>bins.table</code></td>
<td>
<p>a data frame with the sample size, number of presences, number of absences, prevalence, mean and median probability, and the difference between predicted and observed values (mean probability - observed prevalence) in each bin.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>the total number of observations in the analysis.</p>
</td></tr>
<tr><td><code>n.bins</code></td>
<td>
<p>the total number of bins obtained.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is still under development and may fail for some datasets and binning methods (e.g., ties may sometimes preclude binning under some bin.methods). Fixes and further binning methods are in preparation. Feedback is welcome.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Jimenez-Valverde A., Acevedo P., Barbosa A.M., Lobo J.M. &amp; Real R. (2013) Discrimination capacity in species distribution models depends on the representativeness of the environmental domain. Global Ecology and Biogeography 22: 508-516.
</p>
<p>Jovani R. &amp; Tella J.L. (2006) Parasite prevalence and sample size: misconceptions and solutions. Trends in Parasitology 22: 214-218.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HLfit">HLfit</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:

data(rotif.mods)


# choose a particular model to play with:

mod &lt;- rotif.mods$models[[1]]


# try getBins using different binning methods:

getBins(model = mod, bin.method = "quantiles")

getBins(model = mod, bin.method = "n.bins")

getBins(model = mod, bin.method = "n.bins", fixed.bin.size = TRUE)
</code></pre>

<hr>
<h2 id='getModEqn'>
Get model equation
</h2><span id='topic+getModEqn'></span>

<h3>Description</h3>

<p>This function retrieves the equation of a model, to print or apply elsewhere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getModEqn(model, type = "Y", digits = NULL, prefix = NULL, 
suffix = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getModEqn_+3A_model">model</code></td>
<td>

<p>a model object of class 'lm' or glm'.
</p>
</td></tr>
<tr><td><code id="getModEqn_+3A_type">type</code></td>
<td>

<p>the type of equation to get; can be either &quot;Y&quot; (the default, for the linear model equation), &quot;P&quot; (for probabiity) or &quot;F&quot; (for favourability).
</p>
</td></tr>
<tr><td><code id="getModEqn_+3A_digits">digits</code></td>
<td>

<p>the number of significant digits to which to round the coefficient estimates in the equation.
</p>
</td></tr>
<tr><td><code id="getModEqn_+3A_prefix">prefix</code></td>
<td>

<p>the prefix to add to each variable name in the equation.
</p>
</td></tr>
<tr><td><code id="getModEqn_+3A_suffix">suffix</code></td>
<td>

<p>the suffix to add to each variable name in the equation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary of a model in R gives you a table of the coefficient estimates and other parameters. Sometimes it may be useful to have a string of text with the model's equation, so that you can present it in an article (e.g. Real et al. 2005) or apply it in a (raster map) calculation, either in R (although here you can usually use the 'predict' function for this) or in a GIS software (e.g. Barbosa et al. 2010). The <code>getModEqn</code> function gets this equation for linear or generalized linear models.
</p>
<p>By default it prints the <code>"Y"</code> linear equation, but for generalized linear models you can also set <code>type = "P"</code> (for the equation of probability) or <code>type = "F"</code> (for favourability, which modifies the intercept to eliminate the effect of modelled prevalence - see Real et al. 2006).
</p>
<p>If the variables to which you want to apply the model have a prefix or suffix (e.g. something like prefix = &quot;raster.stack$&quot; for the R 'raster' or 'terra' package, or prefix = &quot;mydata$&quot; for a data frame, or suffix = &quot;@1&quot; in QGIS, or suffix = &quot;@mapset&quot; in GRASS), you can get these in the equation too, using the <code>prefix</code> and/or the <code>suffix</code> argument.
</p>


<h3>Value</h3>

<p>A charachter string of the model equation.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Barbosa A.M., Real R. &amp; Vargas J.M. (2010) Use of coarse-resolution models of species' distributions to guide local conservation inferences. Conservation Biology 24: 1378-87
</p>
<p>Real R., Barbosa A.M., Martinez-Solano I. &amp; Garcia-Paris, M. (2005) Distinguishing the distributions of two cryptic frogs (Anura: Discoglossidae) using molecular data and environmental modeling. Canadian Journal of Zoology 83: 536-545
</p>
<p>Real R., Barbosa A.M. &amp; Vargas J.M. (2006) Obtaining environmental favourability functions from logistic regression. Environmental and Ecological Statistics 13: 237-245
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

getModEqn(mod)

getModEqn(mod, type = "P", digits = 3, suffix = "@mapset")

getModEqn(mod, type = "F", digits = 2)
</code></pre>

<hr>
<h2 id='getThreshold'>Prediction threshold for a given criterion</h2><span id='topic+getThreshold'></span>

<h3>Description</h3>

<p>This function computes the prediction threshold under a given criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getThreshold(model = NULL, obs = NULL, pred = NULL, threshMethod,
interval = 0.01, quant = 0, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getThreshold_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="getThreshold_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="getThreshold_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="getThreshold_+3A_threshmethod">threshMethod</code></td>
<td>
<p>Criterion under which to compute the threshold. Run modEvAmethods(&quot;getThreshold&quot;) for available options.</p>
</td></tr>
<tr><td><code id="getThreshold_+3A_interval">interval</code></td>
<td>
<p>Argument to pass to <code><a href="#topic+optiThresh">optiThresh</a></code> indicating the interval between the thresholds to test. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="getThreshold_+3A_quant">quant</code></td>
<td>
<p>Numeric value indicating the proportion of presences to discard if threshMethod=&quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
<tr><td><code id="getThreshold_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether NA values should be ignored. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several criteria have been proposed for selecting a threshold with which to convert continuous model predictions (of presence probability, habitat suitability or alike) into binary predictions of presence or absence. Such threshold is required for computing threshold-based model evaluation metrics, such as those in <code><a href="#topic+threshMeasures">threshMeasures</a></code>. This function implements a few of these threshold selection criteria, including those outlined in Liu et al. (2005, 2013) and a couple more:
</p>
<p>- &quot;preval&quot;, &quot;trainPrev&quot;: prevalence (proportion of presences) in the supplied 'model' or 'obs'
</p>
<p>- &quot;meanPred&quot;: mean predicted value in the supplied 'model' or 'pred'
</p>
<p>- &quot;midPoint&quot;: median predicted value in the supplied 'model' or 'pred'
</p>
<p>- &quot;maxKappa&quot;: threshold that maximizes Cohen's kappa
</p>
<p>- &quot;maxCCR&quot;, &quot;maxOA&quot;, &quot;maxOPS&quot;: threshold that maximizes the Correct Classification Rate, aka Overall Accuracy, aka Overall Prediction Success
</p>
<p>- &quot;maxF&quot;: threshold that maximizes the F value
</p>
<p>- &quot;maxSSS&quot;: threshold that maximizes the sum of sensitivity and specificity
</p>
<p>- &quot;maxTSS&quot;: threshold that maximizes the True Skill Statistic
</p>
<p>- &quot;maxSPR&quot;: threshold that maximizes the sum of precision and recall
</p>
<p>- &quot;minDSS&quot;: threshold that minimizes the difference between sensitivity and specificity
</p>
<p>- &quot;minDPR&quot;: threshold that minimizes the difference between precision and recall
</p>
<p>- &quot;minD01&quot;: threshold that minimizes the distance between the ROC curve and the 0,1 point
</p>
<p>- &quot;minD11&quot;: threshold that minimizes the distance between the PR curve and the 1,1 point
</p>
<p>- &quot;equalPrev&quot;: predicted and observed prevalence equalization
</p>
<p>- &quot;MTP&quot;: minimum training presence, or the lowest predicted value where presence is recorded in 'obs' or 'model'. Optionally, with the 'quant' argument, this threshold leaves out predicted values lower than the value for the lowest specified proportion of presences
</p>


<h3>Value</h3>

<p>This function returns a numeric value indicating the threshold selected under the specified 'threshMethod'.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Liu C., Berry P.M., Dawson T.P. &amp; Pearson R.G. (2005) Selecting thresholds of occurrence in the prediction of species distributions. Ecography 28: 385-393
</p>
<p>Liu C., White M. &amp; Newell G. (2013) Selecting thresholds for the prediction of species occurrence with presence-only data. Journal of Biogeography 40: 778-789
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+optiThresh">optiThresh</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

getThreshold(model = mod, threshMethod = "maxTSS")


# you can also use getThreshold with vectors of observed and predicted values
# instead of with a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

getThreshold(obs = presabs, pred = prediction, threshMethod = "maxTSS")

getThreshold(obs = presabs, pred = prediction, threshMethod = "MTP")

getThreshold(obs = presabs, pred = prediction, threshMethod = "MTP",
quant = 0.05)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='HLfit'>
Hosmer-Lemeshow goodness of fit
</h2><span id='topic+HLfit'></span>

<h3>Description</h3>

<p>This function calculates a model's calibration performance (reliability) with the Hosmer &amp; Lemeshow goodness-of-fit statistic, which compares predicted probability to observed occurrence frequency at each portion of the probability range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLfit(model = NULL, obs = NULL, pred = NULL, bin.method, 
n.bins = 10, fixed.bin.size = FALSE, min.bin.size = 15, 
min.prob.interval = 0.1, quantile.type = 7, simplif = FALSE, 
verbosity = 2, alpha = 0.05, plot = TRUE, plot.values = TRUE, 
plot.bin.size = TRUE, xlab = "Predicted probability", 
ylab = "Observed prevalence", na.rm = TRUE, rm.dup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HLfit_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_bin.method">bin.method</code></td>
<td>
<p>argument to pass to <code><a href="#topic+getBins">getBins</a></code> specifying the method for grouping the records into bins within which to compare predicted probability to observed prevalence; type modEvAmethods(&quot;getBins&quot;) for available options, and see Details for more information.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_n.bins">n.bins</code></td>
<td>
<p>argument to pass to <code><a href="#topic+getBins">getBins</a></code> specifying the number of bins to use if bin.method = n.bins or bin.method = quantiles. The default is 10.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_fixed.bin.size">fixed.bin.size</code></td>
<td>
<p>argument to pass to <code><a href="#topic+getBins">getBins</a></code>, a logical value indicating whether to force bins to have (approximately) the same size. The default is FALSE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_min.bin.size">min.bin.size</code></td>
<td>
<p>argument to pass to <code><a href="#topic+getBins">getBins</a></code> specifying the minimum number of records in each bin. The default is 15, the minimum required for accurate comparisons within bins (Jovani &amp; Tella 2006, Jimenez-Valverde et al. 2013).</p>
</td></tr>
<tr><td><code id="HLfit_+3A_min.prob.interval">min.prob.interval</code></td>
<td>
<p>argument to pass to <code><a href="#topic+getBins">getBins</a></code> specifying the minimum interval (range) of probability values within each bin. The default is 0.1.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_quantile.type">quantile.type</code></td>
<td>
<p>argument to pass to <code><a href="stats.html#topic+quantile">quantile</a></code> specifying the algorithm to use if bin.method = &quot;quantiles&quot;. The default is 7 (the <code><a href="stats.html#topic+quantile">quantile</a></code> default in R), but check out other types, e.g. 3 (used by SAS), 6 (used by Minitab and SPSS) or 5 (appropriate for deciles, which correspond to the default n.bins = 10).</p>
</td></tr>
<tr><td><code id="HLfit_+3A_simplif">simplif</code></td>
<td>
<p>logical, wheter to perform a faster simplified version returning only the basic statistics. The default is FALSE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages or warnings to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_alpha">alpha</code></td>
<td>
<p>alpha value for confidence intervals if <code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_plot">plot</code></td>
<td>
<p>logical, whether to produce a plot of the results. The default is TRUE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_plot.values">plot.values</code></td>
<td>
<p>logical, whether to report measure values in the plot. The default is TRUE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_plot.bin.size">plot.bin.size</code></td>
<td>
<p>logical, whether to report bin sizes in the plot. The default is TRUE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_xlab">xlab</code></td>
<td>
<p>label for the x axis.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_ylab">ylab</code></td>
<td>
<p>label for the y axis.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_...">...</code></td>
<td>
<p>further arguments to pass to the <code><a href="base.html#topic+plot">plot</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the commonly used measures for evaluating model performance focus on the discrimination or the classification capacity, i.e., how well the model is capable of distinguishing or classifying presences and absences (often after the model's continuous predictions of presence probability or alike are converted to binary predictions of presence or absence). However, there is another important facet of model evaluation: calibration or reliability, i.e., the relationship between predicted probability and observed occurrence frequency (Pearce &amp; Ferrier 2000; Jimenez-Valverde et al. 2013). The <code>HLfit</code> function measures model reliability with the Hosmer &amp; Lemeshow goodness-of-fit statistic (Hosmer &amp; Lemeshow 1980).
</p>
<p>Note that this statistic has strong limitations and caveats (see e.g. http://www.statisticalhorizons.com/hosmer-lemeshow, Allison 2014), mainly due to the need to group the values into bins within which to compare probability and prevalence, and the strong influence of the binning method on the results. The 'HLfit' function can use several binning methods, which are implemented and roughly explained in the <code><a href="#topic+getBins">getBins</a></code> function and can be accessed by typing 'modEvAmethods(&quot;getBins&quot;)'. You should try 'HLfit' with different binning methods to see how if the results are robust.
</p>


<h3>Value</h3>

<p><code>HLfit</code> returns a list with the following components:
</p>
<table>
<tr><td><code>bins.table</code></td>
<td>
<p>a data frame of the obtained bins and the values resulting from the hosmer-Lemeshow goodness-of-fit analysis.</p>
</td></tr>
<tr><td><code>chi.sq</code></td>
<td>
<p>the value of the Chi-squared test.</p>
</td></tr>
<tr><td><code>DF</code></td>
<td>
<p>the number of degrees of freedom.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the Hosmer-Lemeshow test. Note that this is one of those tests for which higher p-values are better.</p>
</td></tr>
<tr><td><code>RMSE</code></td>
<td>
<p>the root mean squared error.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The 4 lines of code from &quot;observed&quot; to &quot;p.value&quot; were adapted from the 'hosmerlem' function available at http://www.stat.sc.edu/~hitchcock/diseaseoutbreakRexample704.txt. The plotting code was loosely based on the <code>calibration.plot</code> function in package <span class="pkg">PresenceAbsence</span>. <code>HLfit</code> still needs some code simplification, and may fail for some datasets and binning methods. Fixes are being applied. Feedback is welcome.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Allison P.D. (2014) Measures of Fit for Logistic Regression. SAS Global Forum, Paper 1485
</p>
<p>Hosmer D.W. &amp; Lemeshow S. (1980) A goodness-of-fit test for the multiple logistic regression model. Communications in Statistics, A10: 1043-1069
</p>
<p>Jimenez-Valverde A., Acevedo P., Barbosa A.M., Lobo J.M. &amp; Real R. (2013) Discrimination capacity in species distribution models depends on the representativeness of the environmental domain. Global Ecology and Biogeography 22: 508-516
</p>
<p>Jovani R. &amp; Tella J.L. (2006) Parasite prevalence and sample size: misconceptions and solutions. Trends in Parasitology 22: 214-218
</p>
<p>Pearce J. &amp; Ferrier S. (2000) Evaluating the Predictive Performance of Habitat Models Developed using Logistic Regression. Ecological Modeling, 133: 225-245
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getBins">getBins</a></code>, <code><a href="#topic+MillerCalib">MillerCalib</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:

data(rotif.mods)


# choose a particular model to play with:

mod &lt;- rotif.mods$models[[1]]


# try HLfit using different binning methods:

HLfit(model = mod, bin.method = "round.prob", 
main = "HL GOF with round.prob (n=10)")

HLfit(model = mod, bin.method = "prob.bins", 
main = "HL GOF with prob.bins (n=10)")

HLfit(model = mod, bin.method = "size.bins", 
main = "HL GOF with size.bins (min size=15)")

HLfit(model = mod, bin.method = "size.bins", min.bin.size = 30, 
main = "HL GOF with size.bins min size 30")

HLfit(model = mod, bin.method = "n.bins", 
main = "HL GOF with 10 bins")

HLfit(model = mod, bin.method = "n.bins", fixed.bin.size = TRUE, 
main = "HL GOF with 10 bins of fixed size")

HLfit(model = mod, bin.method = "n.bins", n.bins = 20, 
main = "HL GOF with 20 bins")

HLfit(model = mod, bin.method = "quantiles", 
main = "HL GOF with quantile bins (n=10)")

HLfit(model = mod, bin.method = "quantiles", n.bins = 20,
main = "HL GOF with quantile bins (n=20)")


# you can also use 'predPlot' with vectors of observed and predicted values
# instead of a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

HLfit(obs = presabs, pred = prediction, bin.method = "round.prob")


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='inputMunch'>
Munch inputs into 'obs' and 'pred' vectors
</h2><span id='topic+inputMunch'></span>

<h3>Description</h3>

<p>This function is used internally by many other functions in this package to check and extract the 'obs' and 'pred' vectors from the user inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inputMunch(model = NULL, obs = NULL, pred = NULL, rm.dup = FALSE, na.rm = FALSE,
verbosity = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inputMunch_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments (e.g. for external test data) instead of 'model'.</p>
</td></tr>
<tr><td><code id="inputMunch_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="inputMunch_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="inputMunch_+3A_rm.dup">rm.dup</code></td>
<td>
<p>logical argument to be passed to <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code> indicating whether repeated points within the same pixel should be removed. The default is FALSE.</p>
</td></tr>
<tr><td><code id="inputMunch_+3A_na.rm">na.rm</code></td>
<td>
<p>logical argument indicating whether to remove (with a warning saying how many) rows with NA in any of the resulting 'obs' or 'pred' values. The default is FALSE.</p>
</td></tr>
<tr><td><code id="inputMunch_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. Defaults to 2, for the maximum amount of messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a two-column data frame containing the 'obs' and 'pred' values, or an error message if inputs are not as required.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>

<hr>
<h2 id='logLike'>
Log-likelihood
</h2><span id='topic+logLike'></span>

<h3>Description</h3>

<p>This function computes the log-likelihood of a model, given a model object or a set of observed and predicted values (or presence points and raster predictions).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLike(model = NULL, obs = NULL, pred = NULL, na.rm = TRUE, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLike_+3A_model">model</code></td>
<td>
<p>a model object of class implemented in <code><a href="#topic+mod2obspred">mod2obspred</a></code>. If this argument is provided, 'obs' and 'pred' will be extracted with that function. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="logLike_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed values of the response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of presence points, in which case the 'obs' vector of presences and absences will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="logLike_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values, of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="logLike_+3A_na.rm">na.rm</code></td>
<td>
<p>logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="logLike_+3A_plot">plot</code></td>
<td>
<p>logical value indicating whether to plot the sorted values in log() (see Details). The default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood can be a measure of model calibration (Lawson et al. 2014, Fithian et al. 2015, Fletcher &amp; Fortin 2018). The higher the value, the better the predictions fit the observations.
</p>
<p>The log-likelihood is computed as sum(log(pred*obs+(1-pred)*(1-obs))) (Fletcher &amp; Fortin 2018, p. 234). If plot=TRUE, a plot is shown with the values within sum(), both within and outside log().
</p>
<p>In the first instance of 'pred' in the formula above, a very small constant is added to the 'pred' values of zero, because the logarithm of zero is undefined. This added constant is smaller (i.e. closer to the original value of zero) here than in the R code accompanying Fletcher &amp; Fortin (2018), specifically 2e-16 rather than 0.001, which may justify some differences in the results when there are predictions of exactly zero. In any case, whatever constant is used, it should be the same across the models being compared.
</p>


<h3>Value</h3>

<p>This function returns a numeric value indicating the log-likelihood of the input model predictions given the input observations.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Fithian, W., Elith, J., Hastie, T., Keith, D.A., 2015. Bias correction in species distribution models: pooling survey and collection data for multiple species. Methods in Ecology and Evolution 6:424-438. https://doi.org/10.1111/2041-210X.12242
</p>
<p>Fletcher R. &amp; Fortin M.-J. (2018) Spatial Ecology and Conservation Modeling. Applications with R. Springer Nature Switzerland. Cham: 532 pp. https://www.fletcherlab.com/spatial-ecology-conservation-modeli
</p>
<p>Lawson, C.R., Hodgson, J.A., Wilson, R.J., Richards, S.A., 2013. Prevalence, thresholds and the performance of presence-absence models. Methods in Ecology and Evolution 5, 54-64. https://doi.org/10.1111/2041-210X.12123
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="#topic+MillerCalib">MillerCalib</a></code>, <code><a href="#topic+HLfit">HLfit</a></code>,
<code><a href="#topic+Boyce">Boyce</a></code>, <code><a href="#topic+RMSE">RMSE</a></code>, <code><a href="#topic+Dsquared">Dsquared</a></code>,
<code><a href="#topic+RsqGLM">RsqGLM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

logLike(model = mod)


# you can also use logLike with vectors of observed and predicted values
# instead of with a model object:

obs &lt;- mod$y
pred &lt;- mod$fitted.values

logLike(obs = obs, pred = pred)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='lollipop'>Lollipop chart</h2><span id='topic+lollipop'></span>

<h3>Description</h3>

<p>This function creates a lollipop chart from a (optionally named) numeric vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  lollipop(x, names = NULL, ymin = 0, sticks = TRUE, col = "royalblue",
  grid = TRUE, cex = 1, cex.axis = 1, las = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lollipop_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_names">names</code></td>
<td>
<p>a vector of the same length as 'x' with the names to be plotted below the lollipops. If this argument is left NULL and 'x' has names, then these will be used.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_ymin">ymin</code></td>
<td>
<p>numeric value for the lower limit of the y axis. The default is zero. If set to NA, the minimum of 'x' will be used.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_sticks">sticks</code></td>
<td>
<p>logical value indicating whether the sticks of the lollipops should be drawn. The default is TRUE.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_col">col</code></td>
<td>
<p>colour for the lollipops.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_grid">grid</code></td>
<td>
<p>logical, whether or not to add a grid to the plot. The default is TRUE.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_cex">cex</code></td>
<td>
<p>numeric value indicating the size of the lollipops. Will be passed as 'cex' to 'points' and as 'lwd' to 'arrows' (the lines or lollipop sticks).</p>
</td></tr>
<tr><td><code id="lollipop_+3A_cex.axis">cex.axis</code></td>
<td>
<p>numeric value indicating the size of the x and y axis labels.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_las">las</code></td>
<td>
<p>argument to pass to <code><a href="graphics.html#topic+par">par</a></code> indicating the orientation of the axis labels.</p>
</td></tr>
<tr><td><code id="lollipop_+3A_...">...</code></td>
<td>
<p>additional arguments that can be used for the plot, e.g. 'main'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>According to modern data viz recommendations, lollipop charts are generally a better alternative to bar charts, as they reduce the visual distortion caused by the length of the bars, making it easier to compare the values.
</p>


<h3>Value</h3>

<p>This function produces a lollipop chart of the values in 'x'.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+barplot">barplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lollipop(mtcars[,1], names = rownames(mtcars), las = 2, ylab = names(mtcars)[1],
cex.axis = 0.6, main = "Lollipop chart")

lollipop(mtcars[,1], names = rownames(mtcars), las = 2, ylab = names(mtcars)[1],
cex.axis = 0.6, main = "Lollipop chart", ymin = NA)
</code></pre>

<hr>
<h2 id='MESS'>
Multivariate Environmental Similarity Surfaces based on a data frame
</h2><span id='topic+MESS'></span>

<h3>Description</h3>

<p>This function performs the MESS analysis of Elith et al. (2010) to determine
the extent of the environmental differences between model training and model
projection (extrapolation) data. It is applicable to variables in a matrix
or data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MESS(V, P, id.col = NULL, verbosity = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MESS_+3A_v">V</code></td>
<td>
<p>a matrix or data frame containing the variables (one in each column)
in the training dataset.</p>
</td></tr>
<tr><td><code id="MESS_+3A_p">P</code></td>
<td>
<p>a matrix or data frame containing the same variables in the area to
which the model(s) will be projected. Variables (columns) must be in the same
order as in <code>V</code>, and <code>colnames(P)</code> must exist.</p>
</td></tr>
<tr><td><code id="MESS_+3A_id.col">id.col</code></td>
<td>
<p>optionally, the index number of a column containing the row identifiers in P. If provided, this column will be excluded from MESS calculations but included in the output.</p>
</td></tr>
<tr><td><code id="MESS_+3A_verbosity">verbosity</code></td>
<td>
<p>Integer number indicating the amount of messages to display while computing the results. The default is to display all messages. Set verbosity=0 for no messages.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When model predictions are projected into regions, times or spatial resolutions
not analysed in the training data, it may be important to measure the similarity
between the new environments and those in the training sample (Elith et al.
2010), as models are not so reliable when predicting outside their domain
(Barbosa et al. 2009). The Multivariate Environmental Similarity Surfaces (MESS)
analysis measures the similarity in the analysed variables between any given
locality in the projection dataset and the localities in the reference
(training) dataset (Elith et al. 2010).
</p>
<p>MESS analysis is implemented in the MAXENT software (Phillips et al.
2006) and in the <span class="pkg">dismo</span> R package, but there it requires input
variables in raster format. This implies not only the use of complex spatial
data structures, but also that the units of analysis are rectangular pixels,
whereas we often need to model distribution data recorded on less regular
units (e.g. provinces, river basins), or on equal-area cells that are not
necessarily rectangular (e.g. UTM cells, equal-area hexagons or other geometric
shapes). The MESS function computes this analysis for variables in a data frame,
where localities (in rows) may be of any size or shape.
</p>


<h3>Value</h3>

<p>The function returns a data frame with the same column names as <code>P</code>,
plus a column named <code>TOTAL</code>, quantifying the similarity between each
point in the projection dataset and those in the reference dataset. Negative
values indicate localities that are environmentally dissimilar from the
reference region. The last column, <code>MoD</code>, indicates which of the column
names of P corresponds to the most dissimilar variable, i.e., the limiting
factor or the variable that drives the MESS in that locality (Elith et al. 2010).
</p>


<h3>Note</h3>

<p>Newer and apparently more complete methods for analysing environmental dissimilarities have been developed, such as extrapolation detection (ExDet; Mesgaran et al. 2014) and Mobility-Oriented Parity analysis (MOP; Owens et al. 2013).
</p>


<h3>Author(s)</h3>

<p>Alberto Jimenez-Valverde, A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Barbosa A.M., Real R. &amp; Vargas J.M. (2009) Transferability of environmental favourability models in geographic space: the case of the Iberian desman (Galemys pyrenaicus) in Portugal and Spain. Ecological Modelling 220: 747-754
</p>
<p>Elith J., Kearney M. &amp; Phillips S. (2010) The art of modelling range-shifting
species. Methods in Ecology and Evolution 1: 330-342
</p>
<p>Mesgaran M.B., Cousens R.D. &amp; Webber B.L. (2014) Here be dragons: a tool for quantifying novelty due to covariate range and correlation change when projecting species distribution models. Diversity and Distributions, 20: 1147-1159
</p>
<p>Owens H.L., Campbell L.P., Dornak L.L., Saupe E.E., Barve N., Soberon J., Ingenloff K., Lira-Noriega A., Hensz C.M., Myers C.E. &amp; Peterson A.T. (2013) Constraints on interpretation of ecological niche models by limited environmental ranges on calibration areas. Ecological Modelling, 263: 10-18
</p>
<p>Phillips S.J., Anderson R.P. &amp; Schapire R.E. (2006) Maximum entropy modeling
of species geographic distributions. Ecological Modelling 190: 231-259
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OA">OA</a></code>; <code>mess</code> in packages <span class="pkg">dismo</span> and <span class="pkg">predicts</span>; <code>ecospat.climan</code> in package <span class="pkg">ecospat</span>; <code>kuenm_mop</code> and <code>kuenm_mmop</code> in package <span class="pkg">kuenm</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# load package 'fuzzySim' and its sample data:
require(fuzzySim)
data(rotif.env)


# add a column specifying the hemisphere:

unique(rotif.env$CONTINENT)

rotif.env$HEMISPHERE &lt;- "Eastern"

rotif.env$HEMISPHERE[rotif.env$CONTINENT %in%
c("NORTHERN_AMERICA", "SOUTHERN_AMERICA")] &lt;- "Western"

head(rotif.env)


# perform a MESS analysis
# suppose you'll extrapolate models from the Western hemisphere (Americas)
# to the Eastern hemisphere (rest of the world):

names(rotif.env)  # variables are in columns 5:17

west &lt;- subset(rotif.env, HEMISPHERE == "Western", select = 5:17)
east &lt;- subset(rotif.env, HEMISPHERE == "Eastern", select = 5:17)
east.with.ID &lt;- subset(rotif.env, HEMISPHERE == "Eastern",
select = c(1, 5:17))

head(east)
head(east.with.ID)  # ID is in column 1

mess &lt;- MESS(V = west, P = east)
mess.with.ID &lt;- MESS(V = west, P = east.with.ID, id.col = 1)

head(mess)
head(mess.with.ID)

range(mess[ , "TOTAL"])

## End(Not run)
</code></pre>

<hr>
<h2 id='MillerCalib'>Miller's calibration satistics for logistic regression models</h2><span id='topic+MillerCalib'></span>

<h3>Description</h3>

<p>This function calculates Miller's (1991) calibration statistics for a presence probability model &ndash; namely, the intercept and slope of a logistic regression of the response variable on the logit of predicted probabilities. Optionally and by default, it also plots the corresponding regression line over the reference diagonal (identity line). If the model is well calibrated, the line should lie along (or at least be nearly parallel to) the reference diagonal, i.e. the slope should ideally equal 1 (i.e., 45 degrees).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MillerCalib(model = NULL, obs = NULL, pred = NULL, plot = TRUE,
line.col = "black", diag = TRUE, diag.col = "grey", 
plot.values = TRUE, digits = 2, xlab = "", ylab = "", 
main = "Miller calibration", na.rm = TRUE, rm.dup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MillerCalib_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_plot">plot</code></td>
<td>
<p>logical, whether or not to produce a plot of the Miller regression line. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_line.col">line.col</code></td>
<td>
<p>colour for the Miller regression line (if plot = TRUE).</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_diag">diag</code></td>
<td>
<p>logical, whether or not to add the reference diagonal (if plot = TRUE). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_diag.col">diag.col</code></td>
<td>
<p>line colour for the reference diagonal.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_plot.values">plot.values</code></td>
<td>
<p>logical, whether or not to report the values of the intercept and slope on the plot. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_digits">digits</code></td>
<td>
<p>integer number indicating the number of digits to which the values in the plot should be rounded. Dafaults to 2. This argument is ignored if 'plot' or 'plot.values' are set to FALSE.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_xlab">xlab</code></td>
<td>
<p>label for the x axis.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_ylab">ylab</code></td>
<td>
<p>label for the y axis.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_main">main</code></td>
<td>
<p>title for the plot.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="MillerCalib_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calibration or reliability measures how a model's predicted probabilities relate to observed species prevalence or proportion of presences in the modelled data (Pearce &amp; Ferrier 2000; Wintle et al. 2005; Franklin 2010). If predictions are perfectly calibrated, the slope will equal 1 and the intercept will equal 0, so the model's calibation line will perfectly overlap with the reference diagonal or identity line.
</p>
<p>Note that Miller's statistics assess the model globally: a model is well calibrated if the average of all predicted probabilities equals the proportion of presences in the modelled data. For logistic regression models, perfect calibration is always attained on the same data used for building the model (Miller 1991); Miller's calibration statistics are mainly useful when projecting a model outside those training data.
</p>
<p>Calibration can be separated into two measurable components, bias and spread, and a third component, unexplained error. Bias describes a consistent overestimate or underestimate of presence probability, which is reflected by a Miller intercept above or below 0 (i.e., a model line above or below the reference diagonal). Spread describes a departure of the model line from the 45-degree slope. A slope greater than 1 indicates that predicted values above 0.5 are underestimating, and values below 0.5 are overestimating, the probability of presence. A slope smaller than 1 (while greater than 0) implies that predicted values below 0.5 are underestimating, and values above 0.5 are overestimating, the probability of presence (Pearce &amp; Ferrier 2000). A Miller slope very different from 1 indicates a poorly calibrated model. The unexplained error component can be assessed, though only in part, through residual analysis (Miller 1991; Pearce &amp; Ferrier 2000).
</p>
<p>While Miller's calibration statistics were originally conceived for generalized linear models with binomial distribution and logit link (Miller 1991), they may also apply to other models that also estimate presence probability, including those that use different link functions such as probit or cloglog. Regardless of how they get there, these models attempt to estimate presence probabilities as well calibrated as possible, and the logit is the canonical link for the Bernoulli distribution which is appropriate for a binary response variable. Indeed, the Miller slope is visibly worse when those other link functions are used for computing it.
</p>
<p>Miller's calibration slope (though not the intercept) is also adequate to assess the calibration of other predictions related to presence probability, such as suitability and favourability (see e.g. 'Fav' function in the <span class="pkg">fuzzySim</span> package). Indeed, the slope is the same for presence probability and its corresponding favourability value (see Examples, bottom).
</p>


<h3>Value</h3>

<p>This function returns a list of two integer values:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>
<p>the calibration intercept.</p>
</td></tr>
<tr><td><code>slope</code></td>
<td>
<p>the calibration slope.</p>
</td></tr>
</table>
<p>If <code>plot = TRUE</code>, a plot will be produced with the model calibration line, optionally (if diag = TRUE) over the reference diagonal, and optionally (if plot.values = TRUE) with the intercept and slope values printed on it.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa</p>


<h3>References</h3>

<p>Franklin, J. (2010) Mapping Species Distributions: Spatial Inference and Prediction. Cambridge University Press, Cambridge
</p>
<p>Miller M.E., Hui S.L. &amp; Tierney W.M. (1991) Validation techniques for logistic regression models. Statistics in Medicine, 10: 1213-1226
</p>
<p>Pearce J. &amp; Ferrier S. (2000) Evaluating the predictive performance of habitat models developed using logistic regression. Ecological Modelling, 133: 225-245
</p>
<p>Wintle B.A., Elith J. &amp; Potts J.M. (2005) Fauna habitat modelling and mapping: A review and case study in the Lower Hunter Central Coast region of NSW. Austral Ecology, 30: 719-738
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HLfit">HLfit</a></code>, <code><a href="#topic+Dsquared">Dsquared</a></code>, <code><a href="#topic+RsqGLM">RsqGLM</a></code>, <code><a href="#topic+Boyce">Boyce</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

MillerCalib(model = mod)
MillerCalib(model = mod, plot.values = FALSE)
MillerCalib(model = mod, main = "Model calibration line")


# you can also use MillerCalib with vectors of observed and predicted values
# instead of a model object:

MillerCalib(obs = mod$y, pred = mod$fitted.values)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values


# Miller slope can also apply to predictions other than probability:

## Not run: 
# (the following code requires the 'fuzzySim' pkg installed)

MillerCalib(obs = mod$y, pred = mod$fitted.values)  # probability
fav &lt;- fuzzySim::Fav(model = mod)  # favourability
MillerCalib(obs = mod$y, pred = fav)  # same slope, different intercept

## End(Not run)
</code></pre>

<hr>
<h2 id='mod2obspred'>
Extract observed and predicted values from a model object.
</h2><span id='topic+mod2obspred'></span>

<h3>Description</h3>

<p>This function takes a model object and returns the observed and (optionally) the fitted values in that model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod2obspred(model, obs.only = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod2obspred_+3A_model">model</code></td>
<td>
<p>a model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot; from which the response variable and fitted (predicted) values can be extracted. Note that, for &quot;randomForest&quot; models, only the out-of-bag prediction is available from the model object (see <code>?predict.randomForest</code> if you have that package installed), so here you'll get different results if you provide 'model' or the modelled 'obs' (and corresponding 'pred') values.</p>
</td></tr>
<tr><td><code id="mod2obspred_+3A_obs.only">obs.only</code></td>
<td>
<p>logical value indicating whether only 'obs' should be obtained (saves computing time when 'pred' not needed &ndash; used e.g. by <code><a href="#topic+prevalence">prevalence</a></code>). Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with one column containing the observed and (if obs.only=FALSE, the default) another column containing the predicted values from 'model'.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prevalence">prevalence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rotif.mods)
mod &lt;- rotif.mods$models[[1]]
obspred &lt;- mod2obspred(mod)
head(obspred)
</code></pre>

<hr>
<h2 id='modEvAmethods'>
Methods implemented in modEvA functions
</h2><span id='topic+modEvAmethods'></span>

<h3>Description</h3>

<p>This function allows retrieving the methods available for some of the functions in modEvA, such as <code><a href="#topic+similarity">similarity</a></code>, <code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+optiThresh">optiThresh</a></code>, <code><a href="#topic+multModEv">multModEv</a></code>, <code><a href="#topic+getThreshold">getThreshold</a></code> and <code><a href="#topic+getBins">getBins</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modEvAmethods(fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modEvAmethods_+3A_fun">fun</code></td>
<td>
<p>a character vector of length 1 specifying the name (in quotes) of the function for which to obtain the available methods. Must be one of &quot;threshMeasures&quot;, &quot;optiThresh&quot;, &quot;multModEv&quot;, &quot;getThreshold&quot; or &quot;getBins&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector of the available methods for the specified function.</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+optiThresh">optiThresh</a></code>, <code><a href="#topic+getBins">getBins</a></code>, <code><a href="#topic+multModEv">multModEv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>modEvAmethods("threshMeasures")

modEvAmethods("multModEv")

modEvAmethods("optiThresh")

modEvAmethods("getBins")

modEvAmethods("similarity")
</code></pre>

<hr>
<h2 id='multModEv'>
Multiple model evaluation
</h2><span id='topic+multModEv'></span>

<h3>Description</h3>

<p>If you have a list of GLM model objects (created, e.g., with the <code>multGLM</code> function of the 'fuzzySim' R-Forge package), or a data frame with presence-absence data and the corresponding predicted values for a set of species, you can use the <code>multModEv</code> function to get a set of evaluation measures for all models simultaneously, as long as they all have the same sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multModEv(models = NULL, obs.data = NULL, pred.data = NULL,
measures = modEvAmethods("multModEv"), standardize = FALSE, 
thresh = NULL, bin.method = NULL, verbosity = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multModEv_+3A_models">models</code></td>
<td>
<p>a list of model object(s) of class &quot;glm&quot;, all applied to the same data set. Evaluation is based on the cases included in the models.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_obs.data">obs.data</code></td>
<td>
<p>a data frame with observed (training or test) binary data. This argument is ignored if 'models' is provided.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_pred.data">pred.data</code></td>
<td>
<p>a data frame with the corresponding predicted (training or test) values, with both rows and columns in the same order as in 'obs.data'. This argument is ignored if 'models' is provided. Note that, for calibration measures (based on <code><a href="#topic+HLfit">HLfit</a></code> or <code><a href="#topic+MillerCalib">MillerCalib</a></code>), the results are only valid if the input predictions represent probability.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_measures">measures</code></td>
<td>
<p>character vector of the evaluation measures to calculate. The default is all implemented measures, which you can check by typing 'modEvAmethods(&quot;multModEv&quot;)'. But beware: calibration measures (i.e., HL and Miller) are only valid if your predicted values reflect actual presence probability (not favourability, habitat suitability or others); you should exclude them otherwise.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_standardize">standardize</code></td>
<td>
<p>logical, whether to standardize measures that vary between -1 and 1 to the 0-1 scale (see <code><a href="#topic+standard01">standard01</a></code>). The default is FALSE.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_thresh">thresh</code></td>
<td>
<p>argument to pass to <code><a href="#topic+threshMeasures">threshMeasures</a></code> if any of 'measures' is calculated by that function. The default is NULL, but a valid method must be specified if any of 'measures' is threshold-based - i.e., any of those in 'modEvAmethods(&quot;threshMeasures&quot;)'.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_bin.method">bin.method</code></td>
<td>
<p>the method with which to divide the data into groups or bins, for calibration or reliability measures such as <code><a href="#topic+HLfit">HLfit</a></code>. The default is NULL, but a valid method must be specified if 'measures' includes &quot;HL&quot; or &quot;HL.p&quot;. Type modEvAmethods(&quot;getBins&quot;) for available options), and see <code><a href="#topic+HLfit">HLfit</a></code> and <code><a href="#topic+getBins">getBins</a></code> for more information.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages or warnings to display. Defaults to 0, but can also be 1 or 2 for more messages from the functions within.</p>
</td></tr>
<tr><td><code id="multModEv_+3A_...">...</code></td>
<td>
<p>optional arguments to pass to <code><a href="#topic+HLfit">HLfit</a></code> (if &quot;HL&quot; or &quot;HL.p&quot; are included in 'measures'), namely n.bins, fixed.bin.size, min.bin.size, min.prob.interval or quantile.type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the value of each evaluation measure for each model.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rotif.mods)

eval1 &lt;- multModEv(models = rotif.mods$models[1:6], thresh = 0.5, 
bin.method = "n.bins", fixed.bin.size = TRUE)

head(eval1)


eval2 &lt;- multModEv(models = rotif.mods$models[1:6], 
thresh = "preval", measures = c("AUC", "AUCPR", "CCR", 
"Sensitivity", "TSS"))

head(eval2)


# you can also calculate evaluation measures for a set of 
# observed vs predicted data, rather than from model objects:

obses &lt;- sapply(rotif.mods$models, `[[`, "y")
preds &lt;- sapply(rotif.mods$models, `[[`, "fitted.values")

eval3 &lt;- multModEv(obs.data = obses[ , 1:4], 
pred.data = preds[ , 1:4], thresh = "preval", 
bin.method = "prob.bins")

head(eval3)
</code></pre>

<hr>
<h2 id='OA'>Overlap Analysis</h2><span id='topic+OA'></span>

<h3>Description</h3>

<p>This function analyses the range of values of the given environmental variables at the sites where a species has been recorded present.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OA(data, sp.cols, var.cols)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OA_+3A_data">data</code></td>
<td>
<p>a data frame with your species' occurrence data and the predictor variables.</p>
</td></tr>
<tr><td><code id="OA_+3A_sp.cols">sp.cols</code></td>
<td>
<p>index number of the column containing the occurrence data of the species to be modelled. Currently only one species can be analysed at a time.</p>
</td></tr>
<tr><td><code id="OA_+3A_var.cols">var.cols</code></td>
<td>
<p>index numbers of the columns containing the predictor variables to be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Overlap Analysis is one of the simplest forms of modelling species' distributions. It assesses the ranges of values of the given environmental variables at the sites where a species has been recorded present, and predicts where that species should be able to occur based on those presence data (e.g. Brito et al. 1999, Arntzen &amp; Teixeira 2006).
</p>
<p>OA can also be useful when extrapolating models outside their original scope (geographical area, time period or spatial resolution), as it can identify which localities are within the model's domain - i.e., within the analysed ranges of values of the variables, outside which the model may not be reliable (e.g. Barbosa et al. 2009). In this case, the response is not a species' presence, but rather the sites that have been included in the model. See also the <code><a href="#topic+MESS">MESS</a></code> function for a comparison between modelled and extrapolation environments.
</p>
<p>Input data for the <code>OA</code> function are a vector or column with ones and zeros (presences vs. absences of a species if we want to model its occurrence, or modelled vs. non-modelled sites if we want to know which non-modelled sites are within the modelled range), and a matrix or data frame with the corresponding values of the environmental variables to consider (one variable in each column, values in rows).
</p>


<h3>Value</h3>

<p>A binary vector whith 1 where the values of all predictors lie within the ranges observed for the presence records, and 0 otherwise.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Arntzen J.W, Teixeira J. (2006) History and new developments in the mapping and modelling of the distribution of the golden-striped salamander, Chioglossa lusitanica. Zeitschrift fur Feldherpetologie, Supplement: 1-14.
</p>
<p>Barbosa, A.M., Real, R. &amp; Vargas, J.M. (2009) Transferability of environmental favourability models in geographic space: the case of the Iberian desman (Galemys pyrenaicus) in Portugal and Spain. Ecological Modelling 220: 747-754.
</p>
<p>Brito J.C., Crespo E.G., Paulo O.S. (1999) Modelling wildlife distributions: Logistic Multiple Regression vs Overlap Analysis. Ecography 22: 251-260.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MESS">MESS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# load package 'fuzzySim' and its sample data:
require(fuzzySim)
data(rotif.env)

names(rotif.env)

OA(rotif.env, sp.cols = 18, var.cols = 5:17)

## End(Not run)
</code></pre>

<hr>
<h2 id='optiPair'>
Optimize the classification threshold for a pair of related model evaluation measures.
</h2><span id='topic+optiPair'></span>

<h3>Description</h3>

<p>This function can optimize a model's classification threshold based on a pair of model evaluation measures that balance each other, such as sensitivity-specificity, precision-recall (i.e., positive predictive power vs. sensitivity), or omission-commission, or underprediction-overprediction (Fielding &amp; Bell 1997; Liu et al. 2011; Barbosa et al. 2013). The function plots both measures of the given pair against all thresholds with a given interval, and calculates the optimal sum, difference and mean of the two measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optiPair(model = NULL, obs = NULL, pred = NULL,
measures = c("Sensitivity", "Specificity"), interval = 0.01, 
plot = TRUE, plot.sum = FALSE, plot.diff = FALSE, ylim = NULL, 
na.rm = TRUE, exclude.zeros = TRUE, rm.dup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optiPair_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_measures">measures</code></td>
<td>
<p>a character vector of length 2 indicating the pair of measures whose curves to plot and whose combined threshold to optimize. Available measures can be obtained with 'modEvAmethods(&quot;threshMeasures&quot;)', but note that this function expects you to use two measures that counter-balance one another, such as c(&quot;Sensitivity&quot;, &quot;Specificity&quot;) [the default], c(&quot;Omission&quot;, &quot;Commission&quot;), or c(&quot;Precision&quot;, &quot;Recall&quot;).</p>
</td></tr>
<tr><td><code id="optiPair_+3A_interval">interval</code></td>
<td>
<p>the interval of thresholds at which to calculate the measures. The default is 0.01.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_plot">plot</code></td>
<td>
<p>logical indicating whether or not to plot the pair of measures.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_plot.sum">plot.sum</code></td>
<td>
<p>logical, whether to plot the sum (+) of both measures in the pair. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_plot.diff">plot.diff</code></td>
<td>
<p>logical, whether to plot the difference (-) between both measures in the pair. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_ylim">ylim</code></td>
<td>
<p>a character vector of length 2 indicating the lower and upper limits for the y axis. The default is NULL for an automatic definition of 'ylim' based on the values of the measures and their sum and/or difference if any of these are set to TRUE.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, whether NA values should be removed from the calculation of minimum/maximum/mean values to get the optimized measures. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_exclude.zeros">exclude.zeros</code></td>
<td>
<p>logical, whether non-finite and zero values should be removed from the calculation of minimum/maximum/mean values to get the optimized measures. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="optiPair_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code><a href="base.html#topic+plot">plot</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output is a list with the following components:
</p>
<table>
<tr><td><code>measures.values</code></td>
<td>
<p>a data frame with the values of the chosen pair of measures, as well as their difference, sum and mean, at each threshold.</p>
</td></tr>
<tr><td><code>MinDiff</code></td>
<td>
<p>numeric value, the minimum difference between both measures.</p>
</td></tr>
<tr><td><code>ThreshDiff</code></td>
<td>
<p>numeric value, the threshold that minimizes the difference between both measures.</p>
</td></tr>
<tr><td><code>MaxSum</code></td>
<td>
<p>numeric value, the maximum sum of both measures.</p>
</td></tr>
<tr><td><code>ThreshSum</code></td>
<td>
<p>numeric value, the threshold that maximizes the sum of both measures.</p>
</td></tr>
<tr><td><code>MaxMean</code></td>
<td>
<p>numeric value, the maximum mean of both measures.</p>
</td></tr>
<tr><td><code>ThreshMean</code></td>
<td>
<p>numeric value, the threshold that maximizes the mean of both measures.</p>
</td></tr>
</table>
<p>If plot=TRUE (the default), a plot is also produced with the value of each of 'measures' at each threshold, and horizontal and vertical lines marking, respectively, the threshold and value at which the difference between the two 'measures' is minimal.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Barbosa, A.M., Real, R., Munoz, A.-R. &amp; Brown, J.A. (2013) New measures for assessing model equilibrium and prediction mismatch in species distribution models. Diversity and Distributions 19: 1333-1338
</p>
<p>Fielding A.H. &amp; Bell J.F. (1997) A review of methods for the assessment of prediction errors in conservation presence/absence models. Environmental Conservation 24: 38-49
</p>
<p>Liu C., White M., &amp; Newell G. (2011) Measuring and comparing the accuracy of species distribution models with presence-absence data. Ecography, 34, 232-243.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optiThresh">optiThresh</a></code>, <code><a href="#topic+threshMeasures">threshMeasures</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)


# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

optiPair(model = mod)

optiPair(model = mod, measures = c("Precision", "Recall"))

optiPair(model = mod, measures = c("UPR", "OPR"))

optiPair(model = mod, measures = c("CCR", "F1score"))


# you can also use 'optiPair' with vectors of observed 
# and predicted values, instead of a model object:

optiPair(obs = mod$y, pred = mod$fitted.values)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='optiThresh'>
Optimize threshold for model evaluation.
</h2><span id='topic+optiThresh'></span>

<h3>Description</h3>

<p>The 'optiThresh' function calculates optimal thresholds for a number of model evaluation measures (see <code><a href="#topic+threshMeasures">threshMeasures</a></code>). Optimization is given for each measure, and/or for all measures according to particular criteria (e.g. Jimenez-Valverde &amp; Lobo 2007; Liu et al. 2005; Nenzen &amp; Araujo 2011). Results are given numerically and in plots.</p>


<h3>Usage</h3>

<pre><code class='language-R'>optiThresh(model = NULL, obs = NULL, pred = NULL, interval = 0.01,
measures = c(modEvAmethods("threshMeasures"), modEvAmethods("similarity")),
optimize = modEvAmethods("optiThresh"), simplif = FALSE, plot = TRUE,
sep.plots = FALSE, xlab = "Threshold", na.rm = TRUE, rm.dup = FALSE, verbosity = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optiThresh_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_interval">interval</code></td>
<td>
<p>numeric value between 0 and 1 indicating the interval between the thresholds at which to calculate the evaluation measures. Defaults to 0.01.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_measures">measures</code></td>
<td>
<p>character vector indicating the names of the model evaluation measures for which to calculate optimal thresholds. The default is using all measures available in 'c(modEvAmethods(&quot;threshMeasures&quot;), modEvAmethods(&quot;similarity&quot;))'.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_optimize">optimize</code></td>
<td>
<p>character vector indicating the threshold optimization criteria to use; &quot;each&quot; calculates the optimal threshold for each model evaluation measure, while the remaining options optimize all measures according to the specified criterion. The default is using all criteria available in 'modEvAmethods(&quot;optiThresh&quot;)'.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_simplif">simplif</code></td>
<td>
<p>logical, whether to compute a faster simplified version. Used internally in other functions.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_plot">plot</code></td>
<td>
<p>logical, whether to plot the values of each evaluation measure at all thresholds. Ignored if simplif=TRUE.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_sep.plots">sep.plots</code></td>
<td>
<p>logical. If TRUE, each plot is presented separately (you need to be recording R plot history to be able to browse through them all); if FALSE(the default), all plots are presented together in the same plotting window.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_xlab">xlab</code></td>
<td>
<p>character vector indicating the label of the x axis.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="optiThresh_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a list with the following components:
</p>
<table>
<tr><td><code>all.thresholds</code></td>
<td>
<p>a data frame with the values of all analysed measures at all analysed thresholds.</p>
</td></tr>
<tr><td><code>optimals.each</code></td>
<td>
<p>if &quot;each&quot; is among the threshold criteria specified in 'optimize', optimals.each is output as a data frame with the value of each measure at its optimal threshold, as well as the type of optimal for that measure (which may be the maximum for measures of goodness such as &quot;Sensitivity&quot;, or the minimum for measures of badness such as &quot;Omission&quot;).</p>
</td></tr>
<tr><td><code>optimals.criteria</code></td>
<td>
<p>a data frame with the values of measure at the threshold that maximizes each of the criteria specified in 'optimize' (except for &quot;each&quot;, see above).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>&quot;Sensitivity&quot; is the same as &quot;Recall&quot;, and &quot;PPP&quot; (positive predictive power) is the same as &quot;Precision&quot;. &quot;F1score&quot;&quot; is the harmonic mean of precision and recall.
</p>


<h3>Note</h3>

<p>Some measures cannot be calculated for thresholds at which there are zeros in the confusion matrix, hence the eventual 'NaN' or 'Inf' in results. Also, optimization may be deceiving for some measures; use 'plot = TRUE' and inspect the plot(s).
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Jimenez-Valverde A. &amp; Lobo J.M. (2007) Threshold criteria for conversion of probability of species presence to either-or presence-absence. Acta Oecologica 31: 361-369.
</p>
<p>Liu C., Berry P.M., Dawson T.P. &amp; Pearson R.G. (2005) Selecting thresholds of occurrence in the prediction of species distributions. Ecography 28: 385-393.
</p>
<p>Nenzen H.K. &amp; Araujo M.B. (2011) Choice of threshold alters projections of species range shifts under climate change. Ecological Modelling 222: 3346-3354.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+optiPair">optiPair</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

## Not run: 
optiThresh(model = mod)

## End(Not run)


# change some of the parameters:

optiThresh(model = mod, pch = 20,
measures = c("CCR", "Sensitivity", "kappa", "TSS", "Jaccard", "F1score"),
ylim = c(0, 1))


# you can also use optiThresh with vectors of observed and predicted
# values instead of with a model object:

## Not run: 
optiThresh(obs = mod$y, pred = mod$fitted.values, pch = 20)

## End(Not run)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='plotGLM'>
Plot a generalized linear model
</h2><span id='topic+plotGLM'></span>

<h3>Description</h3>

<p>This function plots the observed (presence/absence) data and the predicted (probability) values of a Generalized Linear Model against the y regression equation (logit) values. Only logistic regression (binomial response, logit link) is currently implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotGLM(model = NULL, obs = NULL, pred = NULL, link = "logit", 
plot.values = TRUE, plot.digits = 3, xlab = "Logit (Y)", 
ylab = "Predicted probability", main = "Model plot", na.rm = TRUE, 
rm.dup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotGLM_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;<code><a href="stats.html#topic+glm">glm</a></code>&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_link">link</code></td>
<td>
<p>the link function of the GLM; only 'logit' (the default) is implemented.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_plot.values">plot.values</code></td>
<td>
<p>logical, whether to include in the plot diagnostic values such as explained deviance (calculated with the <code><a href="#topic+Dsquared">Dsquared</a></code> function) and pseudo-R-squared measures (calculated with the <code><a href="#topic+RsqGLM">RsqGLM</a></code> function). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_plot.digits">plot.digits</code></td>
<td>
<p>integer number indicating the number of digits to which the values in the plot should be <code><a href="base.html#topic+round">round</a></code>ed (if 'plot.values = TRUE'). Defaults to 3.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_xlab">xlab</code></td>
<td>
<p>character string specifying the label for the x axis.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_ylab">ylab</code></td>
<td>
<p>character string specifying the label for the y axis.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_main">main</code></td>
<td>
<p>character string specifying the title for the plot.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="plotGLM_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function outputs a plot of model predictions against observations.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Guisan A. &amp; Zimmermann N.E. (2000) Predictive habitat distribution models in ecology. Ecological Modelling 135: 147-186
</p>
<p>Weisberg S. (1980) Applied Linear Regression. Wiley, New York
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predPlot">predPlot</a></code>, <code><a href="#topic+predDensity">predDensity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

plotGLM(model = mod)

plotGLM(model = mod, plot.values = FALSE)


# you can also use 'plotGLM' with vectors of observed and
# predicted values instead of with a model object:

plotGLM(obs = mod$y, pred = mod$fitted.values)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='predDensity'>
Plot the density of predicted values for presences and absences.
</h2><span id='topic+predDensity'></span>

<h3>Description</h3>

<p>This function produces a histogram and/or a kernel density plot of predicted values for a binary-response model, possibly separately for the observed presences and absences, given a model object or a vector of predicted values and (optionally) a vector of the corresponding observed values. When there are multiple predicted values for each site, it can also plot a confidence interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predDensity(model = NULL, obs = NULL, pred = NULL,
separate = TRUE, type = "both", ci = NA, legend.pos = "topright",
main = "Density of predicted values", na.rm = TRUE, rm.dup = FALSE,
xlim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predDensity_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'pred' (and optionally 'obs') argument(s) instead of 'model'.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', an optional numeric vector (in the same order of 'pred') of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument may be omitted (to show the density plot of all 'pred' values combined), and it is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model', a vector of predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs' (if the latter is provided). Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_separate">separate</code></td>
<td>
<p>logical value indicating whether prediction densities should be computed separately for observed presences (ones) and absences (zeros). Defaults to TRUE, but it is automatically changed to FALSE if either 'model' or 'obs' are not provided, or if 'ci' is not NULL.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_type">type</code></td>
<td>
<p>character vector specifying whether to produce a &quot;histogram&quot;, a &quot;density&quot; plot, or &quot;both&quot; (the default). Partial argument matching is used.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_ci">ci</code></td>
<td>
<p>numeric value for a confidence interval to add to the plot, e.g. 0.95 for 95%. The default is NA.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_legend.pos">legend.pos</code></td>
<td>
<p>character specifying the position for the legend; NA or &quot;n&quot; for no legend. Position can be &quot;topright&quot; (the default), &quot;topleft, &quot;bottomright&quot;&quot;, &quot;bottomleft&quot;, &quot;top&quot;, &quot;bottom&quot;, &quot;left&quot;, &quot;right&quot;, or &quot;center&quot;. Partial argument matching is used.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_main">main</code></td>
<td>
<p>main title for the plot.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_na.rm">na.rm</code></td>
<td>
<p>logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_rm.dup">rm.dup</code></td>
<td>
<p>if <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_xlim">xlim</code></td>
<td>
<p>numeric vector of length 2 setting the limits for the x axis of the plot. The default is NULL, for the range of the <code><a href="stats.html#topic+density">density</a></code> of predicted values.</p>
</td></tr>
<tr><td><code id="predDensity_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="graphics.html#topic+hist">hist</a></code>, e.g. 'breaks' or 'border'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details, please refer to the documentation of the functions mentioned under &quot;See Also&quot;.
</p>


<h3>Value</h3>

<p>This function outputs and plots the object(s) specified in 'type' &ndash; by default, a <code><a href="stats.html#topic+density">density</a></code> object and a <code><a href="graphics.html#topic+hist">hist</a></code>ogram.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>, <code><a href="stats.html#topic+density">density</a></code>, <code><a href="#topic+predPlot">predPlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]


# compute predDensity with different parameters:

predDensity(model = mod)

predDensity(model = mod, breaks = seq(0, 1, by = 0.05))

predDensity(model = mod, type = "histogram")

predDensity(model = mod, type = "density")

predDensity(model = mod, ci = 0.975)


# you can also use 'predDensity' with vectors of
# observed and predicted values, instead of a model object:

obs &lt;- mod$y
pred &lt;- mod$fitted.values

predDensity(obs = obs, pred = pred)

predDensity(pred = pred, ci = 0.95)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='predPlot'>
Plot predicted values for presences and absences, optionally classified according to a prediction threshold.
</h2><span id='topic+predPlot'></span>

<h3>Description</h3>

<p>This function plots predicted values separated into observed presences and absences and (optionally and by default) coloured according to whether they are above or below a given prediction threshold. The plot imitates (with permission from the author) one of the graphical outputs of the 'summary' of models built with the <span class="pkg">embarcadero</span> package (Carlson, 2020), but it can be applied to other types of models or to a set of observed and predicted values, and it allows specifying a user-defined threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predPlot(model = NULL, obs = NULL, pred = NULL, thresh = "preval",
main = "Classified predicted values", legend.pos = "n", pch = 1, cex = 0.5,
col = c("black", "grey"), na.rm = TRUE, rm.dup = FALSE, interval = 0.01,
quant = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predPlot_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_thresh">thresh</code></td>
<td>
<p>threshold value to separate predicted presences from predicted absences in 'pred'; can be &quot;preval&quot; (the default), to use the <code><a href="#topic+prevalence">prevalence</a></code> (i.e. proportion of presences) in 'obs'; or any real number between 0 and 1; or any of the options available on modEvAmethods(&quot;getThreshold&quot;) &ndash; see Details in <code><a href="#topic+getThreshold">getThreshold</a></code> for their description. This value, if not NA or NULL, will be used to draw a vertical line on the plot and to colour the points (predicted values) according to whether they fall above or below the threshold.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_main">main</code></td>
<td>
<p>Main title for the plot.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_legend.pos">legend.pos</code></td>
<td>
<p>character value specifying the position for the legend on the plot. Can be &quot;bottomleft&quot;, &quot;bottom&quot;, &quot;bottomright&quot;, &quot;topleft&quot;, &quot;left&quot;, &quot;top&quot;, &quot;topright&quot;, &quot;right&quot;, &quot;center&quot;, or NA or &quot;n&quot; for no legend (the default). Partial argument matching is used.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_pch">pch</code></td>
<td>
<p>plotting character for the presences and absences (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="predPlot_+3A_cex">cex</code></td>
<td>
<p>relative size of the plotting character (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="predPlot_+3A_col">col</code></td>
<td>
<p>vector of length 2 indicating the colours with which to plot predicted presences and absences (points above and below the threshold), respectively. If 'thresh' is NA or NULL, all points will have the first of the specified colours.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_interval">interval</code></td>
<td>
<p>Argument to pass to <code><a href="#topic+optiThresh">optiThresh</a></code> indicating the interval between the thresholds to test, if 'thresh' implies optimizing a threshold-based measure. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="predPlot_+3A_quant">quant</code></td>
<td>
<p>Numeric value indicating the proportion of presences to discard if thresh=&quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function outputs a plot as per 'Description'.
</p>


<h3>Note</h3>

<p>Points are <code><a href="base.html#topic+jitter">jitter</a></code>ed randomly along the y axis to minimize visual overlap. So, each run of 'predPlot' (unless you use <code><a href="base.html#topic+set.seed">set.seed</a></code> first) will produce a different arrangement of points for the same data, although their x-axis values are faithful.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Carlson C.J. (2020) embarcadero: Species distribution modelling with Bayesian additive regression trees in R. Methods in Ecology and Evolution, 11: 850-858.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predDensity">predDensity</a></code>, <code><a href="#topic+plotGLM">plotGLM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

predPlot(model = mod)

predPlot(model = mod, thresh = 0.5)


# you can first select a threshold optimized according to a particular metric:

## Not run: 
threshold &lt;- optiThresh(mod, measures = "TSS", optimize = "each")
threshold &lt;- threshold$optimals.each[ , "threshold"]
threshold
predPlot(model = mod, thresh = threshold)

## End(Not run)

# you can also use 'predPlot' with vectors of observed and predicted values
# instead of a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

predPlot(obs = presabs, pred = prediction)

predPlot(obs = presabs, pred = prediction, thresh = 0.5)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='prevalence'>
Prevalence
</h2><span id='topic+prevalence'></span>

<h3>Description</h3>

<p>For building and evaluating species distribution models, the porportion of presences of the species may be an issue to take into account (e.g. Jimenez-Valverde &amp; Lobo 2006, Barbosa et al. 2013). The <code>prevalence</code> function calculates this measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prevalence(obs, model = NULL, event = 1, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prevalence_+3A_obs">obs</code></td>
<td>
<p>a vector or a factor of binary observations (e.g. 1 vs. 0, male vs. female, disease vs. no disease, etc.). This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_model">model</code></td>
<td>
<p>alternatively to 'obs', a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_event">event</code></td>
<td>
<p>the value whose prevalence we want to calculate (e.g. 1, &quot;present&quot;, etc.). This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, whether NA values should be excluded from the calculation. The default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value of the prevalence of <code>event</code> in the <code>obs</code> vector.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Barbosa A.M., Real R., Munoz A.R. &amp; Brown J.A. (2013) New measures for assessing model equilibrium and prediction mismatch in species distribution models. Diversity and Distributions, in press
</p>
<p>Jimenez-Valverde A. &amp; Lobo J.M. (2006) The ghost of unbalanced species distribution data in geographical model predictions. Diversity and Distributions, 12: 521-524.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evenness">evenness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# calculate prevalence from binary vectors:

(x &lt;- rep(c(0, 1), each = 5))

(y &lt;- c(rep(0, 3), rep(1, 7)))

(z &lt;- c(rep(0, 7), rep(1, 3)))

prevalence(x)

prevalence(y)

prevalence(z)


(w &lt;- c(rep("yes", 3), rep("nope", 7)))

prevalence(w, event = "yes")


# calculate prevalence from a model object:

data(rotif.mods)

prevalence(mod = rotif.mods$models[[1]])
</code></pre>

<hr>
<h2 id='ptsrast2obspred'>
Observed and predicted values from presence points and a raster map.
</h2><span id='topic+ptsrast2obspred'></span>

<h3>Description</h3>

<p>This function takes presence points or coordinates and a raster map of model predictions, and it returns a data frame with two columns containing, respectively, the observed (presence or no presence) and the predicted value for each pixel. Duplicate points (i.e., points falling in the same pixel, whether or not they have the exact same coordinates) can be kept or removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ptsrast2obspred(pts, rst, rm.dup = FALSE, na.rm = FALSE, verbosity = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ptsrast2obspred_+3A_pts">pts</code></td>
<td>
<p>a 'SpatVector' map of the presence points, or a two-column matrix or data frame containing their x (longitude) and y (latitude) coordinates, respectively.</p>
</td></tr>
<tr><td><code id="ptsrast2obspred_+3A_rst">rst</code></td>
<td>
<p>a one-layer 'SpatRaster' map of the model predictions, in the same CRS as 'pts'. If you have a raster map in another format, you can try to convert it with 'terra::rast()'</p>
</td></tr>
<tr><td><code id="ptsrast2obspred_+3A_rm.dup">rm.dup</code></td>
<td>
<p>logical, whether repeated points within the same pixel should be removed. See Examples. The default is FALSE.</p>
</td></tr>
<tr><td><code id="ptsrast2obspred_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, whether presence points with missing or non-finite values of 'rst' should be excluded from the output. The default is FALSE.</p>
</td></tr>
<tr><td><code id="ptsrast2obspred_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. Defaults to 2, for the maximum amount of messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function outputs a data frame with one column containing the observed (1 for presence, 0 for absence) and another column containing the corresponding predicted values from 'rst'.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# you can run these examples if you have the 'terra' package installed

require(terra)

# get an example raster map:
rst &lt;- terra::rast(system.file("ex/elev.tif", package = "terra"))
rst &lt;- terra::aggregate(rst, 10)

plot(rst)

# generate some random presence points within it:
set.seed(8)
presences &lt;- terra::spatSample(as.polygons(ext(rst)), 10)

plot(presences, add = TRUE)


# use 'ptsrast2obspred' on this points + raster data:

# without removing duplicates (the default):
obspred &lt;- ptsrast2obspred(pts = crds(presences), rst = rst)
obspred
nrow(obspred)  # you get as many 'obs' as pixels + additional points per pixel
sum(obspred$obs)  # as many presences as points that overlay 'pred'

# with removal of duplicates:
obspred_rmdup &lt;- ptsrast2obspred(pts = crds(presences), rst = rst[[1]], 
rm.dup = TRUE)  # you get as many 'obs' as pixels
obspred_rmdup
nrow(obspred_rmdup)  # you get as many 'obs' as pixels
sum(obspred_rmdup$obs)  # as many presences as pixels that contain (one or more) points

## End(Not run)
</code></pre>

<hr>
<h2 id='quantReclass'>Reclassify continuous values based on quantiles</h2><span id='topic+quantReclass'></span>

<h3>Description</h3>

<p>This function takes the continuous predictions of a model of suitability (e.g. the continuous Bioclim envelope model, computed by the <code>bioclim</code> function of the <span class="pkg">dismo</span> package or the <code>envelope</code> function of the <span class="pkg">predicts</span> package), and reclassifies them according to their quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantReclass(pred, by = 0.01, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quantReclass_+3A_pred">pred</code></td>
<td>
<p>a 'numeric' vector or a 'SpatRaster' map of predicted suitability values.</p>
</td></tr>
<tr><td><code id="quantReclass_+3A_by">by</code></td>
<td>
<p>numeric value indicating which <code><a href="stats.html#topic+quantile">quantile</a></code>s to compute, e.g. 0.01 for percentiles (the default), 0.1 for deciles, etc.</p>
</td></tr>
<tr><td><code id="quantReclass_+3A_na.rm">na.rm</code></td>
<td>
<p>logical value indicating whether NA values should be ignored when computing the quantiles. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was created by Formoso-Freire et al. (accepted) to reclassify continuous Bioclim predictions into ranked suitability values, rescaling them into relative suitability. Modern implementations of Bioclim compute a percentile distribution of the values of each environmental variable at species presence localities. Then, the closer to the 50th percentile (the median), the more suitable a location is according to that variable (Hijmans et al. 2020; Hijmans 2023). However, the more variables are included in the model, the less suitable any location becomes, because it is less likely to be close to the median for all variables. The proposed rescaling procedure removes the dependence of Bioclim predictions on the number of variables included, and it has shown to provide more realistic predictions (Formoso-Freire et al., accepted).
</p>


<h3>Value</h3>

<p>This function returns an object of the same class as 'pred' with the reclassified values.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa, Victoria Formoso-Freire, Andres Baselga, Carola Gomez-Rodriguez
</p>


<h3>References</h3>

<p>Formoso-Freire V., Barbosa A.M., Baselga A., Gomez-Rodriguez C. (accepted) Predicting the spatio-temporal pattern of range expansion under lack of equilibrium with climate. Biological Conservation
</p>
<p>Hijmans R.J., Phillips S., Leathwick J. &amp; Elith J. (2020). dismo: Species distribution modelling (1.3.5). https://CRAN.R-project.org/package=dismo
</p>
<p>Hijmans R.J. (2023). predicts: Spatial Prediction Tools. R package version 0.1-11. https://CRAN.R-project.org/package=predicts
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getThreshold">getThreshold</a></code>, <code>bioclim</code> in package <span class="pkg">dismo</span>, <code>envelope</code> in package <span class="pkg">predicts</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some sample data:
set.seed(2023)
bioclim_pred &lt;- runif(n = 10, min = 0, max = 1)
bioclim_pred

quantReclass(pred = bioclim_pred, by = 0.1)
</code></pre>

<hr>
<h2 id='range01'>
Shrink or stretch a vector to make it range between 0 and 1
</h2><span id='topic+range01'></span>

<h3>Description</h3>

<p>This function re-scales a numeric vector so that it ranges between 0 and 1. So, the lowest value becomes 0, the highest becomes 1, and the ones in the middle retain their rank and relative diference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>range01(x, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="range01_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="range01_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, whether to remove <code>NA</code> values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was borrowed from http://stackoverflow.com/questions/5468280/scale-a-series-between-two-points-in-r/5468527#5468527 and adapted to handle also missing values.
</p>


<h3>Value</h3>

<p>A numeric vector of the same length as the input, now with the values ranging from 0 to 1.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="#topic+standard01">standard01</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>range01(0:10)

range01(-12.3 : 21.7)
</code></pre>

<hr>
<h2 id='RMSE'>
Root mean square error
</h2><span id='topic+RMSE'></span>

<h3>Description</h3>

<p>This function computes the root mean square error of a model object or a set of observed and predicted values or maps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE(model = NULL, obs = NULL, pred = NULL, na.rm = TRUE, rm.dup = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSE_+3A_model">model</code></td>
<td>
<p>a model object of class implemented in <code><a href="#topic+mod2obspred">mod2obspred</a></code>. If this argument is provided, 'obs' and 'pred' will be extracted with that function. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed values of the response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of presence points, in which case the 'obs' vector of presences and absences will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values, of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The root mean square error is computed as the square root of the mean of the squared differences between observed and predicted values. It is (approximately) the same as the standard deviation of the model residuals (prediction errors), i.e., a measure of how spread out these residuals are, or how concentrated the observations are around the model prediction line. The smaller the RMSE, the better.
</p>


<h3>Value</h3>

<p>The function returns a numeric value indicating the root mean square error of the model predictions.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Kenney J.F. &amp; Keeping E.S. (1962) Root Mean Square. &quot;Mathematics of Statistics&quot;, 3rd ed. Princeton, NJ: Van Nostrand, pp. 59-60.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotGLM">plotGLM</a></code>, <code><a href="#topic+RsqGLM">RsqGLM</a></code>, <code>Dsquared</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

RMSE(model = mod)


# you can also use RMSE with vectors of observed and predicted values
# instead of with a model object:

presabs &lt;- mod$y
prediction &lt;- mod$fitted.values

RMSE(obs = presabs, pred = prediction)


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='rotif.mods'>Rotifer distribution models</h2><span id='topic+rotif.mods'></span>

<h3>Description</h3>

<p>A set of generalized linear models of rotifer species distributions on TDWG level 4 regions of the world (Fontaneto et al. 2012), together with their predicted values. Mind that these models are provided just as sample data and have limited application, due to limitations in the underlying distribution records. See Details for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rotif.mods)</code></pre>


<h3>Format</h3>

<p>A list of 2 elements:
</p>
<p>$ predictions: a data.frame with  291 observations of 60 variables, namely the presence probability (P) and environmental favourability (F) for each of 30 species of rotifers, obtained from the rotif.env dataset in the 'fuzzySim' R-Forge package
</p>
<p>$ models: a list of the 30 generalized linear model (<code><a href="stats.html#topic+glm">glm</a></code>) objects which generated those predictions.
</p>


<h3>Details</h3>

<p>These models were obtained with the 'multGLM' function and the <code>rotif.env</code> dataset from R-Forge package 'fuzzySim' using the following code:
</p>
<p>require(fuzzySim)
</p>
<p>data(rotif.env)
</p>
<p>rotif.mods &lt;- multGLM(data = rotif.env, sp.cols = 18:47, var.cols = 5:17, step = FALSE, trim = TRUE)
</p>
<p>See package 'fuzzySim' (currently available on R-Forge at <a href="http://fuzzysim.r-forge.r-project.org">http://fuzzysim.r-forge.r-project.org</a>) for more information on the source data that were used to build these models.
</p>


<h3>References</h3>

<p>Fontaneto D., Barbosa A.M., Segers H. &amp; Pautasso M. (2012) The 'rotiferologist' effect and other global correlates of species richness in monogonont rotifers. Ecography, 35: 174-182.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rotif.mods)
head(rotif.mods$predictions)
rotif.mods$models[[1]]
</code></pre>

<hr>
<h2 id='RsqGLM'>R-squared measures for GLMs</h2><span id='topic+RsqGLM'></span>

<h3>Description</h3>

<p>This function calculates some (pseudo) R-squared statistics for binomial Generalized Linear Models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RsqGLM(model = NULL, obs = NULL, pred = NULL, use = "pairwise.complete.obs",
plot = TRUE, plot.type = "lollipop", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RsqGLM_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="RsqGLM_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a vector of observed presences (1) and absences (0) of a binary response variable. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="RsqGLM_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability. Must be of the same length and in the same order as 'obs'. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="RsqGLM_+3A_use">use</code></td>
<td>
<p>argument to be passed to <code><a href="stats.html#topic+cor">cor</a></code> for handling mising values.</p>
</td></tr>
<tr><td><code id="RsqGLM_+3A_plot">plot</code></td>
<td>
<p>logical value indicating whether or not to display a bar chart or (by default) a lollipop chart of the calculated measures.</p>
</td></tr>
<tr><td><code id="RsqGLM_+3A_plot.type">plot.type</code></td>
<td>
<p>character value indicating the type of plot to produce (if plot=TRUE). Can be &quot;<code><a href="#topic+lollipop">lollipop</a></code>&quot; (the default) or &quot;<code><a href="graphics.html#topic+barplot">barplot</a></code>&quot;.</p>
</td></tr>
<tr><td><code id="RsqGLM_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to the <code><a href="base.html#topic+plot">plot</a></code> function (see Examples).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implemented measures include the R-squareds of McFadden (1974), Cox-Snell (1989), Nagelkerke (1991, which corresponds to the corrected Cox-Snell, eliminating its upper bound), and Tjur (2009). See Allison (2014) for a brief review of these measures.
</p>


<h3>Value</h3>

<p>The function returns a named list of the calculated R-squared values.</p>


<h3>Note</h3>

<p>Tjur's R-squared can only be calculated for models with binomial response variable; otherwise, NA will be returned.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa</p>


<h3>References</h3>

<p>Allison P. (2014) Measures of fit for logistic regression. SAS Global Forum, Paper 1485-2014
</p>
<p>Cox, D.R. &amp; Snell E.J. (1989) The Analysis of Binary Data, 2nd ed. Chapman and Hall, London
</p>
<p>McFadden, D. (1974) Conditional logit analysis of qualitative choice behavior. In: Zarembka P. (ed.) Frontiers in Economics. Academic Press, New York
</p>
<p>Nagelkerke, N.J.D. (1991) A note on a general definition of the coefficient of determination. Biometrika, 78: 691-692
</p>
<p>Tjur T. (2009) Coefficients of determination in logistic regression models - a new proposal: the coefficient of discrimination. The American Statistician, 63: 366-372.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Dsquared">Dsquared</a></code>, <code><a href="#topic+AUC">AUC</a></code>, <code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+HLfit">HLfit</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

RsqGLM(model = mod)


# you can also use RsqGLM with vectors of observed and predicted values
# instead of a model object:

RsqGLM(obs = mod$y, pred = mod$fitted.values)


# plotting arguments can be modified:

par(mar = c(6, 3, 2, 1))

RsqGLM(obs = mod$y, pred = mod$fitted.values, col = "seagreen", border = NA,
ylim = c(0, 1), main = "Pseudo-R-squared values")
</code></pre>

<hr>
<h2 id='similarity'>
Similarity measures
</h2><span id='topic+similarity'></span>

<h3>Description</h3>

<p>This function computes similarity indices for evaluating the classification accuracy of a species distribution (or ecological niche, or bioclimatic envelope...) model against observed presence-absence data, upon the choice of a threshold value above which the model is considered to predict that the species is expected to be present rather than absent. These metrics were proposed for model evaluation by Li &amp; Guo (2013) and Leroy et al. (2018) &ndash; see Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>similarity(model = NULL, obs = NULL, pred = NULL, thresh,
measures = modEvAmethods("similarity"), simplif = FALSE,
plot = TRUE, plot.type = "lollipop", plot.ordered = FALSE,
verbosity = 2, interval = 0.01, quant = 0, na.rm = TRUE, rm.dup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="similarity_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="similarity_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="similarity_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="similarity_+3A_thresh">thresh</code></td>
<td>
<p>threshold to separate predicted presences from predicted absences in 'model' or 'pred'; can be a numeric value between 0 and 1, or any of the options provided with <code>modEvAmethods("getThreshold")</code>. See Details in <code><a href="#topic+getThreshold">getThreshold</a></code> for a description of the available options, and also Details below for a more informed choice.</p>
</td></tr>
<tr><td><code id="similarity_+3A_measures">measures</code></td>
<td>
<p>character vector of the similarity indices to use. By default, all metrics available through <code>modEvAmethods("similarity")</code> are included.</p>
</td></tr>
<tr><td><code id="similarity_+3A_simplif">simplif</code></td>
<td>
<p>logical, whether to calculate a faster, simplified version. Used internally by other functions in the package. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="similarity_+3A_plot">plot</code></td>
<td>
<p>logical, whether to produce a bar chart or (by default) a lollipop chart of the calculated measures. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="similarity_+3A_plot.type">plot.type</code></td>
<td>
<p>character value indicating the type of plot to produce (if plot=TRUE). Can be &quot;<code><a href="#topic+lollipop">lollipop</a></code>&quot; (the default) or &quot;<code><a href="graphics.html#topic+barplot">barplot</a></code>&quot;.</p>
</td></tr>
<tr><td><code id="similarity_+3A_plot.ordered">plot.ordered</code></td>
<td>
<p>logical, whether to plot the measures in decreasing order rather than in input order. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="similarity_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="similarity_+3A_interval">interval</code></td>
<td>
<p>Numeric value, used if 'thresh' is a threshold optimization method such as &quot;maxKappa&quot; or &quot;maxTSS&quot;, indicating the interval between the thresholds to test. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="similarity_+3A_quant">quant</code></td>
<td>
<p>Numeric value indicating the proportion of presences to discard if thresh=&quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
<tr><td><code id="similarity_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="similarity_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="similarity_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code><a href="base.html#topic+plot">plot</a></code> function, e.g. ylim=c(0, 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Commonly used threshold-based metrics of model evaluation, such as the True Skill Statistic (TSS) implemented in the <code><a href="#topic+threshMeasures">threshMeasures</a></code> function, are conditioned by species prevalence in the modelled sample. To overcome this, Leroy et al. (2018) propose using the similary indices of Sorensen and Jaccard for model evaluation, which they show to be (unlike the TSS) independent of prevalence. This function implements such indices in a model evaluation context.
</p>
<p>Leroy et al. (2018) point out that Sorensen's index is equivalent to the F-measure (or F1 score, which is also implemented in the <code><a href="#topic+threshMeasures">threshMeasures</a></code> function), and that Jaccard's index is half the proxy of the F-measure previously proposed by Li &amp; Guo (2013) for evaluating presence-background models.
</p>


<h3>Value</h3>

<p>If 'simplif=TRUE', the output is a numeric matrix with the name and value of each measure. If 'simplif=FALSE' (the default), the ouptut is a list with the following components:
</p>
<table>
<tr><td><code>N</code></td>
<td>
<p>the number of observations (records) in the analysis.</p>
</td></tr>
<tr><td><code>Threshold</code></td>
<td>
<p>the threshold value used to calculate the 'measures'.</p>
</td></tr>
<tr><td><code>similarity</code></td>
<td>
<p>a numeric matrix with the name and value of each measure.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Leroy B., Delsol R., Hugueny B., Meynard C.M., Barhoumi C., Barbet-Massin M. &amp; Bellard C. (2018) Without quality presence-absence data, discrimination metrics such as TSS can be misleading measures of model performance. Journal of Biogeography 45(9):1994-2002
</p>
<p>Li W. &amp; Guo Q. (2013) How to assess the prediction accuracy of species presence-absence models without absence data? Ecography 36(7):788-799
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+optiThresh">optiThresh</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

similarity(model = mod, thresh = 0.5)

similarity(model = mod, thresh = 0.5, simplif = TRUE, ylim = c(0, 1))

similarity(model = mod, thresh = "maxJaccard")
# or thresh = "maxTSS", "MTP", etc.

# you can also use similarity with vectors of observed and
# predicted values instead of with a model object:

similarity(obs = mod$y, pred = mod$fitted.values, thresh = "maxJaccard")


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='standard01'>
Standardize to 0-1 (or vice-versa)
</h2><span id='topic+standard01'></span>

<h3>Description</h3>

<p>This function converts the score of a measure that ranges from -1 to 1 (e.g. a kappa or TSS value obtained for a model) into its (linearly) corresponding value in 0-to-1 scale, so that it can be compared directly with measures that range between 0 and 1 (such as CCR or AUC). It can also perform the conversion in the opposite direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standard01(score, direction = c("-1+1to01", "01to-1+1"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standard01_+3A_score">score</code></td>
<td>
<p>numeric value indicating the score of the measure of interest.</p>
</td></tr>
<tr><td><code id="standard01_+3A_direction">direction</code></td>
<td>
<p>character value indicating the direction in which to perform the standardization. The default, &quot;-1+1to01&quot;, can be switched to &quot;01to-1+1&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While most of the threshold-based measures of model evaluation range theoretically from 0 to 1, some of them (such as Cohen's kappa and the true skill statistic, TSS) may range from -1 to 1 (Allouche et al. 2006). Thus, the values of different measures may not be directly comparable (Barbosa 2015). We do not usually get negative values of TSS or kappa (nor values under 0.5 for CCR or AUC, for example) because that only happens when model predictions perform worse than random guesses; still, such values are mathematically possible, and can occur e.g. when extrapolating models to regions where where the species-environment relationships differ. This standardization is included as an option in the <code><a href="#topic+threshMeasures">threshMeasures</a></code> function.
</p>


<h3>Value</h3>

<p>The numeric value of 'score' when re-scaled to the 0-to-1 (or to the -1 to +1) scale.
</p>


<h3>Note</h3>

<p>Note that this is not the same as re-scaling a vector so that it ranges between 0 and 1, which is done by <code><a href="#topic+range01">range01</a></code>.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Allouche O., Tsoar A. &amp; Kadmon R. (2006) Assessing the accuracy of species distribution models: prevalence, kappa and the true skill statistic (TSS). Journal of Applied Ecology 43: 1223-1232
</p>
<p>Barbosa, A.M. (2015) Re-scaling of model evaluation measures to allow direct comparison of their values. The Journal of Brief Ideas, 18 Feb 2015, DOI: 10.5281/zenodo.15487
</p>


<h3>See Also</h3>

<p><code><a href="#topic+threshMeasures">threshMeasures</a></code>, <code><a href="#topic+range01">range01</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>standard01(0.6)

standard01(0.6, direction = "-1+1to01")

standard01(0.6, direction = "01to-1+1")
</code></pre>

<hr>
<h2 id='threshMeasures'>
Threshold-based measures of model evaluation
</h2><span id='topic+threshMeasures'></span>

<h3>Description</h3>

<p>This function calculates a number of measures for evaluating the classification accuracy of a species distribution (or ecological niche, or bioclimatic envelope...) model against observed presence-absence data (Fielding &amp; Bell 1997; Liu et al. 2011; Barbosa et al. 2013; Wunderlich et al. 2019), upon the choice of a threshold value above which the model is considered to predict that the species should be present.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threshMeasures(model = NULL, obs = NULL, pred = NULL, thresh,
measures = modEvAmethods("threshMeasures")
[-grep("OddsRatio", modEvAmethods("threshMeasures"))], simplif = FALSE,
plot = TRUE, plot.type = "lollipop", plot.ordered = FALSE, standardize = TRUE,
verbosity = 2, interval = 0.01, quant = 0, na.rm = TRUE, rm.dup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="threshMeasures_+3A_model">model</code></td>
<td>
<p>a binary-response model object of class &quot;glm&quot;, &quot;gam&quot;, &quot;gbm&quot;, &quot;randomForest&quot; or &quot;bart&quot;. If this argument is provided, 'obs' and 'pred' will be extracted with <code><a href="#topic+mod2obspred">mod2obspred</a></code>. Alternatively, you can input the 'obs' and 'pred' arguments instead of 'model'.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_obs">obs</code></td>
<td>
<p>alternatively to 'model' and together with 'pred', a numeric vector of observed presences (1) and absences (0) of a binary response variable. Alternatively (and if 'pred' is a 'SpatRaster'), a two-column matrix or data frame containing, respectively, the x (longitude) and y (latitude) coordinates of the presence points, in which case the 'obs' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_pred">pred</code></td>
<td>
<p>alternatively to 'model' and together with 'obs', a vector with the corresponding predicted values of presence probability, habitat suitability, environmental favourability or alike. Must be of the same length and in the same order as 'obs'. Alternatively (and if 'obs' is a set of point coordinates), a 'SpatRaster' map of the predicted values for the entire evaluation region, in which case the 'pred' vector will be extracted with <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. This argument is ignored if 'model' is provided.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_thresh">thresh</code></td>
<td>
<p>threshold to separate predicted presences from predicted absences in 'model' or 'pred'; can be a numeric value between 0 and 1, or any of the options provided with <code>modEvAmethods("getThreshold")</code>. See Details in <code><a href="#topic+getThreshold">getThreshold</a></code> for a description of the available options, and also Details below for a more informed choice.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_measures">measures</code></td>
<td>
<p>character vector of the evaluation metrics to use. By default, all metrics available through <code>modEvAmethods("threshMeasures")</code> are included, except for &quot;OddsRatio&quot; which usually yields overly large values that stand out in the plot.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_simplif">simplif</code></td>
<td>
<p>logical, whether to calculate a faster, simplified version. Used internally by other functions in the package. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_plot">plot</code></td>
<td>
<p>logical, whether to produce a bar chart or (by default) a lollipop chart of the calculated measures. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_plot.type">plot.type</code></td>
<td>
<p>character value indicating the type of plot to produce (if plot=TRUE). Can be &quot;<code><a href="#topic+lollipop">lollipop</a></code>&quot; (the default) or &quot;<code><a href="graphics.html#topic+barplot">barplot</a></code>&quot;.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_plot.ordered">plot.ordered</code></td>
<td>
<p>logical, whether to plot the measures in decreasing order rather than in input order. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_standardize">standardize</code></td>
<td>
<p>logical, whether to change measures that may range between -1 and +1 (namely kappa and TSS) to their corresponding value in the 0-to-1 scale (skappa and sTSS), so that they can compare directly to other measures (see <code><a href="#topic+standard01">standard01</a></code>). The default is TRUE, but a message is displayed to inform the user about it.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_interval">interval</code></td>
<td>
<p>Numeric value, used if 'thresh' is a threshold optimization method such as &quot;maxKappa&quot; or &quot;maxTSS&quot;, indicating the interval between the thresholds to test. The default is 0.01. Smaller values may provide more precise results but take longer to compute.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_quant">quant</code></td>
<td>
<p>Numeric value indicating the proportion of presences to discard if thresh=&quot;MTP&quot; (minimum training presence). With the default value 0, MTP will be the threshold at which all observed presences are classified as such; with e.g. quant=0.05, MTP will be the threshold at which 5% presences will be classified as absences.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical value indicating whether missing values should be ignored in computations. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_rm.dup">rm.dup</code></td>
<td>
<p>If <code>TRUE</code> and if 'pred' is a SpatRaster and if there are repeated points within the same pixel, a maximum of one point per pixel is used to compute the presences. See examples in <code><a href="#topic+ptsrast2obspred">ptsrast2obspred</a></code>. The default is FALSE.</p>
</td></tr>
<tr><td><code id="threshMeasures_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code><a href="base.html#topic+plot">plot</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The metrics implemented in this function are based on the confusion (or contingency) matrix, and they are described in dedicated publications (Fielding &amp; Bell 1997; Liu et al. 2011; Barbosa et al. 2013; Wunderlich et al. 2019). All of them require a threshold value to separate continuous into binary predictions.
</p>
<p>The threshold value can be chosen according to a number of criteria (see e.g. Liu et al. 2005, 2013; Jimenez-Valverde &amp; Lobo 2007; Nenzen &amp; Araujo 2011). You can choose a fixed numeric value, or set 'thresh' to &quot;preval&quot; (species' prevalence or proportion of presences <b>in the data input to this function</b>), or calculate optimal threshold values according to different criteria with the <code><a href="#topic+getThreshold">getThreshold</a></code>, <code><a href="#topic+optiThresh">optiThresh</a></code> or <code><a href="#topic+optiPair">optiPair</a></code> function. If you are using &quot;environmental favourability&quot; as input 'pred' data (Real et al. 2006; see 'Fav' function in R package <span class="pkg">fuzzySim</span>), then the 0.5 threshold equates to using training prevalence in logistic regression (GLM with binomial error distribution and logit link function).
</p>
<p>While most of these threshold-based measures range from 0 to 1, some of them (such as kappa and TSS) may range from -1 to 1 (Allouche et al. 2006), so their raw scores are not directly comparable. 'threshMeasures' includes an option (used by default) to standardize these measures to 0-1 (Barbosa 2015) using the <code><a href="#topic+standard01">standard01</a></code> function, so that you obtain the standardized versions skappa and sTSS.
</p>
<p>This function can also be used to calculate the agreement between different presence-absence (or other types of binary) data, as e.g. Barbosa et al. (2012) did for comparing mammal distribution data from atlas and range maps. Notice, however, that some of these measures, such as TSS or NMI, are not symmetrical (obs vs. pred is different from pred vs. obs).
</p>


<h3>Value</h3>

<p>If 'simplif=TRUE', the output is a numeric matrix with the name and value of each measure. If 'simplif=FALSE' (the default), the ouptut is a list with the following components:
</p>
<table>
<tr><td><code>N</code></td>
<td>
<p>the number of observations (records) in the analysis.</p>
</td></tr>
<tr><td><code>Prevalence</code></td>
<td>
<p>the prevalence (proportion of presences) in 'obs'.</p>
</td></tr>
<tr><td><code>Threshold</code></td>
<td>
<p>the threshold value used to calculate the 'measures'.</p>
</td></tr>
<tr><td><code>ConfusionMatrix</code></td>
<td>
<p>the confusion matrix obtained with the used threshold.</p>
</td></tr>
<tr><td><code>ThreshMeasures</code></td>
<td>
<p>a numeric matrix with the name and value of each measure.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>&quot;Sensitivity&quot; is the same as &quot;Recall&quot;, and &quot;PPP&quot; (positive predictive power) is the same as &quot;Precision&quot;. Some of these measures (like NMI, UPR, OPR, PPP, NPP) cannot be calculated for thresholds at which there are zeros in the confusion matrix, so they can yield NaN values.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Allouche O., Tsoar A. &amp; Kadmon R. (2006) Assessing the accuracy of species distribution models: prevalence, kappa and the true skill statistic (TSS). Journal of Applied Ecology 43: 1223-1232.
</p>
<p>Barbosa, A.M. (2015) Re-scaling of model evaluation measures to allow direct comparison of their values. The Journal of Brief Ideas, 18 Feb 2015, DOI: 10.5281/zenodo.15487
</p>
<p>Barbosa A.M., Estrada A., Marquez A.L., Purvis A. &amp; Orme C.D.L. (2012) Atlas versus range maps: robustness of chorological relationships to distribution data types in European mammals. Journal of Biogeography 39: 1391-1400
</p>
<p>Barbosa A.M., Real R., Munoz A.R. &amp; Brown J.A. (2013) New measures for assessing model equilibrium and prediction mismatch in species distribution models. Diversity and Distributions 19: 1333-1338
</p>
<p>Fielding A.H. &amp; Bell J.F. (1997) A review of methods for the assessment of prediction errors in conservation presence/absence models. Environmental Conservation 24: 38-49
</p>
<p>Jimenez-Valverde A. &amp; Lobo J.M. (2007) Threshold criteria for conversion of probability of species presence to either-or presence-absence. Acta Oecologica 31: 361-369
</p>
<p>Liu C., Berry P.M., Dawson T.P. &amp; Pearson R.G. (2005) Selecting thresholds of occurrence in the prediction of species distributions. Ecography 28: 385-393
</p>
<p>Liu C., White M. &amp; Newell G. (2011) Measuring and comparing the accuracy of species distribution models with presence-absence data. Ecography 34: 232-243
</p>
<p>Liu C., White M. &amp; Newell G. (2013) Selecting thresholds for the prediction of species occurrence with presence-only data. Journal of Biogeography, 40: 778-789
</p>
<p>Nenzen H.K. &amp; Araujo M.B. (2011) Choice of threshold alters projections of species range shifts under climate change. Ecological Modelling 222: 3346-3354
</p>
<p>Real R., Barbosa A.M. &amp; Vargas J.M. (2006) Obtaining environmental favourability functions from logistic regression. Environmental and Ecological Statistics 13: 237-245
</p>
<p>Wunderlich R.F., Lin Y.-P., Anthony J., Petway J.R. (2019) Two alternative evaluation metrics to replace the true skill statistic in the assessment of species distribution models. Nature Conservation 35: 97-116
</p>


<h3>See Also</h3>

<p><code><a href="#topic+similarity">similarity</a></code>, <code><a href="#topic+optiThresh">optiThresh</a></code>, <code><a href="#topic+optiPair">optiPair</a></code>, <code><a href="#topic+AUC">AUC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sample models:
data(rotif.mods)

# choose a particular model to play with:
mod &lt;- rotif.mods$models[[1]]

threshMeasures(model = mod, simplif = TRUE, thresh = 0.5)

threshMeasures(model = mod, thresh = "preval")

threshMeasures(model = mod, plot.ordered = TRUE, thresh = "preval")

threshMeasures(model = mod, measures = c("CCR", "TSS", "kappa"),
thresh = "preval")

threshMeasures(model = mod, plot.ordered = TRUE, thresh = "preval")


# you can also use threshMeasures with vectors of observed and
# predicted values instead of with a model object:

threshMeasures(obs = mod$y, pred = mod$fitted.values, thresh = "preval")


# 'obs' can also be a table of presence point coordinates
# and 'pred' a SpatRaster of predicted values
</code></pre>

<hr>
<h2 id='varImp'>Variable importance.</h2><span id='topic+varImp'></span>

<h3>Description</h3>

<p>This function gets, and optionally plots, variable importance for an input model object of an implemented class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  varImp(model, imp.type = "each", relative = TRUE, reorder = TRUE,
  group.cats = FALSE, plot = TRUE, plot.type = "lollipop", error.bars = "sd",
  ylim = "auto", col = c("#4477aa", "#ee6677"), plot.points = TRUE,
  legend = TRUE, grid = TRUE, verbosity = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varImp_+3A_model">model</code></td>
<td>
<p>a (binary-response) model object of class &quot;glm&quot; (of package <span class="pkg">stats</span>), &quot;gbm&quot; (of package <span class="pkg">gbm</span>), &quot;randomForest&quot; (of package <span class="pkg">randomForest</span>), &quot;bart&quot; (of package <span class="pkg">dbarts</span>), &quot;pbart&quot; or &quot;lbart&quot; (of package <span class="pkg">BART</span>), or a list produced by function &quot;flexBART&quot; or &quot;probit_flexBART&quot; of package <span class="pkg">flexBART</span>.</p>
</td></tr>
<tr><td><code id="varImp_+3A_imp.type">imp.type</code></td>
<td>
<p>character value indicating the type of variable importance to output, i.e. the metric with which importance is measured. Currently the only option is &quot;each&quot;, to extract the measure provided within each model object. Note that this is inconsistent across model classes &ndash; see Details.</p>
</td></tr>
<tr><td><code id="varImp_+3A_relative">relative</code></td>
<td>
<p>logical value indicating whether to divide the absolute importance values by their total sum, to get a measure of relative variable importance. The default is TRUE. Applies to GLM and BART models.</p>
</td></tr>
<tr><td><code id="varImp_+3A_reorder">reorder</code></td>
<td>
<p>logical value indicating whether to sort the variables in decreasing order of importance. The default is TRUE. If set to FALSE, the variables retain their input order.</p>
</td></tr>
<tr><td><code id="varImp_+3A_group.cats">group.cats</code></td>
<td>
<p>logical value indicating whether to aggregate all factor levels of each (one-hot encoded) categorical variable into a single variable, by summing up their proportions of branches used. Used if 'model' is of class 'bart', 'pbart' or 'lbart', in whose outputs the contributions of categorical variables are split by their factor levels. The default is FALSE. Note that this may incorrectly group variables that have the same name with a different numeric suffix (e.g. &quot;soil_type_1&quot;, &quot;soil_type_2&quot;), so revise your results if you set this to TRUE.</p>
</td></tr>
<tr><td><code id="varImp_+3A_plot">plot</code></td>
<td>
<p>logical value indicating whether to produce a plot with the results. The default is TRUE.</p>
</td></tr>
<tr><td><code id="varImp_+3A_plot.type">plot.type</code></td>
<td>
<p>character value indicating the type of plot to produce (if plot=TRUE). Can be &quot;<code><a href="#topic+lollipop">lollipop</a></code>&quot; (the default), &quot;<code><a href="graphics.html#topic+barplot">barplot</a></code>&quot;, or &quot;<code><a href="graphics.html#topic+boxplot">boxplot</a></code>&quot;. Note that the latter is only useful when 'model' contains several importance values per variable (i.e. for models of class &quot;bart&quot;).</p>
</td></tr>
<tr><td><code id="varImp_+3A_error.bars">error.bars</code></td>
<td>
<p>character value indicating the type of error metric to compute (and plot, if plot=TRUE) if the input contains the necessary information (i.e., for Bayesian models like BART) and if the 'plot.type' is appropriate (i.e. &quot;lollipop&quot; or &quot;barplot&quot;). Can be &quot;sd&quot; (the default) for the standard deviation; &quot;range&quot; for the minimum and maximum value across the ones available; a numeric value between 0 and 1 for the corresponding confidence interval (e.g. 0.95 for 95%), computed with <code><a href="stats.html#topic+quantile">quantile</a></code>; or NA for no error bars.</p>
</td></tr>
<tr><td><code id="varImp_+3A_ylim">ylim</code></td>
<td>
<p>either a numeric vector of length 2 specifying the limits (minimum, maximum) for the y axis, or &quot;auto&quot; (the default) to fit the axis to the existing values.</p>
</td></tr>
<tr><td><code id="varImp_+3A_col">col</code></td>
<td>
<p>character or integer vector of length 1 or 2 specifying the plotting colours (if plot=TRUE) for the variables with positive and negative effect on the response, when this info is available (e.g. for models of class &quot;glm&quot;).</p>
</td></tr>
<tr><td><code id="varImp_+3A_plot.points">plot.points</code></td>
<td>
<p>logical, whether or not to add to the plot the individual importance points (rather than just the mean importance value, and the error bar if error.bars=TRUE) for each variable. By default it is TRUE (following Weissgerber et al. 2015), but it only holds for model objects that include several possible importance values per variable (i.e. BART models).</p>
</td></tr>
<tr><td><code id="varImp_+3A_legend">legend</code></td>
<td>
<p>logical, whether or not to draw a legend. Used only if plot=TRUE and if the output includes negative values (i.e., if 'model' is of class 'GLM' and has variables with positive and negative coefficients).</p>
</td></tr>
<tr><td><code id="varImp_+3A_grid">grid</code></td>
<td>
<p>logical, whether or not to add a grid to the plot. The default is TRUE.</p>
</td></tr>
<tr><td><code id="varImp_+3A_verbosity">verbosity</code></td>
<td>
<p>integer specifying the amount of messages to display. Defaults to the maximum implemented; lower numbers (down to 0) decrease the number of messages.</p>
</td></tr>
<tr><td><code id="varImp_+3A_...">...</code></td>
<td>
<p>additional arguments that can be used for the plot (depending on 'plot.type'), e.g. 'main', 'cex.axis' (for <code><a href="#topic+lollipop">lollipop</a></code> or <code><a href="graphics.html#topic+boxplot">boxplot</a></code>) or 'cex.names' (for <code><a href="graphics.html#topic+barplot">barplot</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variable importance in a model of class &quot;glm&quot; obtained with the <code><a href="stats.html#topic+glm">glm</a></code> function can be measured by the magnitude of the absolute z-value test statistic, which is provided with <code>summary(model)</code>. The 'varImp' function outputs the absolute z value of each variable (or, if relative=TRUE, the relative z value after dividing by the sum of absolute z values), and in the plot (by default) it uses different colours for variables with positive and negative relationships with the response.
</p>
<p>If the input model is of class &quot;gbm&quot; of the <span class="pkg">gbm</span> package, variable importance is obtained from <code>summary.gbm(model)</code> and divided by 100 to get the result as a proportion rather than a percentage (for consistency).
</p>
<p>If the input model is of class &quot;randomForest&quot; of the <span class="pkg">randomForest</span> package, variable importance is obtained with <code>model$importance</code>.
</p>
<p>If the input model is of class &quot;bart&quot; of the <span class="pkg">dbarts</span> package, or of class &quot;pbart&quot; or &quot;lbart&quot; of the <span class="pkg">BART</span> package, or a list produced by function &quot;probit_flexBART&quot; of the <span class="pkg">flexBART</span> package, variable importance is obtained as the mean (if relative=TRUE, the default) or the total number (if relative=FALSE) of regression tree splits where each variable is used. If 'error.bars' is not NA, the error is also computed according to the specified metric (&quot;sd&quot; or standard deviation by default).
</p>


<h3>Value</h3>

<p>This function outputs, and optionally plots, a named numeric vector of variable importance, as measured by 'imp.type' (see Details). If the model is Bayesian (BART) and 'error.bars' is not NA, the output is a row-named data frame with the mean and the lower and upper bounds of the error bars of variable importance.
</p>
<p>Note that variable names can currently not be provided for 'flexBART' models, as the object does not include them. The names will match <code>c(colnames(X_cont_train), colnames(X_cat_train))</code> in the inputs that were provided to 'flexBART'.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Weissgerber T.L., Milic N.M., Winham S.J. &amp; Garovic V,D, (2015) Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm. PLOS Biol 13:e1002128. https://doi.org/10.1371/JOURNAL.PBIO.1002128
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+summary.glm">summary.glm</a></code>; <code>varImportance</code> in package <span class="pkg">predicts</span>; <code>bm_VariablesImportance</code> in package <span class="pkg">biomod2</span>; <code>var_importance</code> in package <span class="pkg">enmpa</span>; <code>varimp</code> in package <span class="pkg">embarcadero</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # load sample models:
  data(rotif.mods)

  # choose a particular model to play with:
  mod &lt;- rotif.mods$models[[1]]

  # get variable importance for this model:
  varImp(model = mod,
    cex.axis = 0.6)

  # change some parameters:
  par(mar = c(10, 4, 2, 1))
  varImp(model = mod,
    col = c("darkgreen", "orange"),
    plot.type = "barplot",
    cex.names = 0.8,
    ylim = c(0, 5),
    main = "Variable importance in \n my model")
</code></pre>

<hr>
<h2 id='varPart'>
Variation partitioning
</h2><span id='topic+varPart'></span>

<h3>Description</h3>

<p>This function performs variation partitioning (Borcard et al. 1992) among two factors (e.g. Ribas et al. 2006) or three factors (e.g. Real et al. 2003) for either linear regression models (LM) or generalized linear models (GLM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varPart(A, B, C = NA, AB, AC = NA, BC = NA, ABC = NA, model.type = NULL,
A.name = "Factor A", B.name = "Factor B", C.name = "Factor C",
model = NULL, groups = NULL, pred.type = "Y", cor.method = "pearson",
return.models = FALSE, plot = TRUE, plot.digits = 3, cex.names = 1.5,
cex.values = 1.2, main = "", cex.main = 2, plot.unexpl = TRUE, colr = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varPart_+3A_a">A</code></td>
<td>
<p>numeric value of the R-squared of the regression of the response variable on the variables related to factor 'A'. NOTE: INSTEAD of this and the next 10 arguments, you can use arguments 'model' and 'groups' below.</p>
</td></tr>
<tr><td><code id="varPart_+3A_b">B</code></td>
<td>
<p>numeric value of the R-squared of the regression of the response variable on the variables related to factor 'B'</p>
</td></tr>
<tr><td><code id="varPart_+3A_c">C</code></td>
<td>
<p>(optionally, if there are 3 factors) numeric value of the R-squared of the regression of the response on the variables related to factor 'C'</p>
</td></tr>
<tr><td><code id="varPart_+3A_ab">AB</code></td>
<td>
<p>numeric value of the R-squared of the regression of the response on the variables of factors 'A' and 'B' simultaneously</p>
</td></tr>
<tr><td><code id="varPart_+3A_ac">AC</code></td>
<td>
<p>(if there are 3 factors) numeric value of the R-squared of the regression of the response on the variables of factors 'A' and 'C' simultaneously</p>
</td></tr>
<tr><td><code id="varPart_+3A_bc">BC</code></td>
<td>
<p>(if there are 3 factors) numeric value of the R-squared of the regression of the response on the variables of factors 'B' and 'C' simultaneously
</p>
</td></tr>
<tr><td><code id="varPart_+3A_abc">ABC</code></td>
<td>
<p>(if there are 3 factors) numeric value of the R-squared of the regression of the response on the variables of factors 'A', 'B' and 'C' simultaneously</p>
</td></tr>
<tr><td><code id="varPart_+3A_model.type">model.type</code></td>
<td>
<p>deprecated argument, kept here for back-compatibility</p>
</td></tr>
<tr><td><code id="varPart_+3A_a.name">A.name</code></td>
<td>
<p>character string indicating the name of factor 'A'</p>
</td></tr>
<tr><td><code id="varPart_+3A_b.name">B.name</code></td>
<td>
<p>character string indicating the name of factor 'B'
</p>
</td></tr>
<tr><td><code id="varPart_+3A_c.name">C.name</code></td>
<td>
<p>character string indicating the name of factor 'C' (if there are 3 factors)</p>
</td></tr>
<tr><td><code id="varPart_+3A_model">model</code></td>
<td>
<p>a model object of class 'glm' (for linear models, instead of 'lm' you can use use 'glm' with family=gaussian). If this argument is provided, all previous arguments are ignored, as they are computed instead from 'model' and 'groups'.</p>
</td></tr>
<tr><td><code id="varPart_+3A_groups">groups</code></td>
<td>
<p>data frame with 2 columns, the 1st one containing the names of the variables, and the 2nd one containing the names of the factors in which they should be grouped (e.g. climatic, human, topographic) for the variation partitioning. This argument is required (and only used) if 'model' is provided.</p>
</td></tr>
<tr><td><code id="varPart_+3A_pred.type">pred.type</code></td>
<td>
<p>character value specifying the type of predictions among which to calculate the R-squared values, or squared correlations. Can be &quot;Y&quot; (the default) for the 'link' function (in the scale of the predictor variables), &quot;P&quot; for using the 'response' (e.g. in the scale of probability for models of family binomial), or &quot;F&quot; for using favourability (i.e., probability after removing the effect of modelled prevalence, as in the 'Fav' function of package <span class="pkg">fuzzySim</span>); see Details. This argument is only used if 'model' is provided.</p>
</td></tr>
<tr><td><code id="varPart_+3A_cor.method">cor.method</code></td>
<td>
<p>character value to pass to the 'method' argument of <code><a href="stats.html#topic+cor">cor</a></code> specifying the correlation coefficient to use. The default is &quot;pearson&quot;. This argument is only used if 'model' is provided.</p>
</td></tr>
<tr><td><code id="varPart_+3A_return.models">return.models</code></td>
<td>
<p>logical value indicating whether to include in the output the model obtained for each group of variables. The default is FALSE. This argument is only used if 'model' is provided.</p>
</td></tr>
<tr><td><code id="varPart_+3A_plot">plot</code></td>
<td>
<p>logical, whether to plot the variation partitioning diagram. The default is TRUE.</p>
</td></tr>
<tr><td><code id="varPart_+3A_plot.digits">plot.digits</code></td>
<td>
<p>integer value of the number of digits to which to <code><a href="base.html#topic+round">round</a></code> the values in the plot. The default is 3.</p>
</td></tr>
<tr><td><code id="varPart_+3A_cex.names">cex.names</code></td>
<td>
<p>numeric value indicating character expansion factor to define the size of the names of the factors displayed in the plot.</p>
</td></tr>
<tr><td><code id="varPart_+3A_cex.values">cex.values</code></td>
<td>
<p>numeric value indicating character expansion factor to define the size of the values displayed in the plot.</p>
</td></tr>
<tr><td><code id="varPart_+3A_main">main</code></td>
<td>
<p>optional character string indicating the main title for the plot. The default is empty.</p>
</td></tr>
<tr><td><code id="varPart_+3A_cex.main">cex.main</code></td>
<td>
<p>numeric value indicating character expansion factor to define the font size of the plot title (if provided).</p>
</td></tr>
<tr><td><code id="varPart_+3A_plot.unexpl">plot.unexpl</code></td>
<td>
<p>logical value indicating whether the amount of unexplained variation should be included in the plot. The default is TRUE.</p>
</td></tr>
<tr><td><code id="varPart_+3A_colr">colr</code></td>
<td>
<p>logical value indicating whether or not to colour the circles in the plot. The default is FALSE for back-compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you have linear models (i.e. GLMs of family Gaussian), input data for 'varPart' are the coefficients of determination (R-squared values) of the linear regressions of the response variable on all the variables in the model, on the variables related to each particular factor, and (when there are 3 factors) on the variables related to each pair of factors. The outputs are the amounts of variance explained exclusively by each factor, the amounts explained exclusively by the overlapping effects of each pair of factors, and the amount explained by the overlap of the 3 factors if this is the case (e.g. Real et al. 2003). The amount of variation not explained by the complete model is also provided.
</p>
<p>If you have generalized linear models (GLMs) such as logistic regression (see <code><a href="stats.html#topic+glm">glm</a></code>), you have no true R-squared values; inputs can then be the squared coefficients of correlation between the model predictions given by each factor (or pair of factors) and the predictions of the complete model. Predictions can be probability (e.g. Munoz &amp; Real 2006), favourability (Baez et al. 2012, Estrada et al. 2016), or the 'logit' linear predictor (Real et al. 2013); the correltion coefficient can be e.g. Pearson's (Munoz &amp; Real 2006) or Spearman's (Baez et al. 2012). An adjusted R-squared can also be used (De Araujo et al. 2014). In GLMs, the &quot;total variation&quot; (AB or ABC, depending on whether you have two or three factors) is 1 (correlation of the predictions of the complete model with themselves), and output values are not the total amounts of variance (of the response variable) explained by variable groups and their overlaps, but rather their proportional contribution to the total variation explained by the model.
</p>


<h3>Value</h3>

<p>This function returns a data frame indicating the proportion of variance accounted for by each of the factors or groups, and (if 'plot = TRUE') a Venn diagram of the contributions of each factor or overlap. If 'return.models=TRUE', the output includes also the model obtained for each group of variables.
</p>


<h3>Note</h3>

<p>These results derive from arithmetic operations between your input values, and they always sum up to 1; if your input is incorrect, the results will be incorrect as well, even if they sum up to 1.
</p>
<p>This function had a bug up to modEvA version 0.8: a badly placed line break prevented the ABC overlap from being calculated correctly. Thanks to Jurica Levatic for pointing this out and helping to solve it!
</p>
<p>Oswald van Ginkel also suggested a fix to some plotting awkwardness when using only two factors, and a nice option for colouring the plot. Many thanks!
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Baez J.C., Estrada A., Torreblanca D. &amp; Real R (2012) Predicting the distribution of cryptic species: the case of the spur-thighed tortoise in Andalusia (southern Iberian Peninsula). Biodiversity and Conservation 21: 65-78
</p>
<p>Borcard D., Legendre P., Drapeau P. (1992) Partialling out the spatial component of ecological variation. Ecology 73: 1045-1055
</p>
<p>De Araujo C.B., Marcondes-Machado L.O. &amp; Costa G.C. (2014) The importance of biotic interactions in species distribution models: a test of the Eltonian noise hypothesis using parrots. Journal of Biogeography 41: 513-523
</p>
<p>Estrada A., Delgado M.P., Arroyo B., Traba J., Morales M.B. (2016) Forecasting Large-Scale Habitat Suitability of European Bustards under Climate Change: The Role of Environmental and Geographic Variables. PLoS ONE 11(3): e0149810
</p>
<p>Munoz A.-R. &amp; Real R. (2006) Assessing the potential range expansion of the exotic monk parakeet in Spain. Diversity and Distributions 12: 656-665
</p>
<p>Real R., Barbosa A.M., Porras D., Kin M.S., Marquez A.L., Guerrero J.C., Palomo L.J., Justo E.R. &amp; Vargas J.M. (2003) Relative importance of environment, human activity and spatial situation in determining the distribution of terrestrial mammal diversity in Argentina. Journal of Biogeography 30: 939-947
</p>
<p>Real R., Romero D., Olivero J., Estrada A. &amp; Marquez A.L. (2013) Estimating how inflated or obscured effects of climate affect forecasted species distribution. PLoS ONE 8: e53646
</p>
<p>Ribas A., Barbosa A.M., Casanova J.C., Real R., Feliu C. &amp; Vargas J.M. (2006) Geographical patterns of the species richness of helminth parasites of moles (Talpa spp.) in Spain: separating the effect of sampling effort from those of other conditioning factors. Vie et Milieu 56: 1-8
</p>


<h3>Examples</h3>

<pre><code class='language-R'># if you have a linear model (LM), use (non-adjusted) R-squared values
# for each factor and for their combinations as inputs:

# with 2 factors:

varPart(A = 0.456, B = 0.315, AB = 0.852, A.name = "Spatial",
B.name = "Environmental", main = "Small whale")

varPart(A = 0.456, B = 0.315, AB = 0.852, A.name = "Spatial",
B.name = "Environmental", main = "Small whale", colr = TRUE)


# with 3 factors:

varPart(A = 0.456, B = 0.315, C = 0.281, AB = 0.051, BC = 0.444,
AC = 0.569, ABC = 0.624, A.name = "Spatial", B.name = "Human",
C.name = "Environmental", main = "Small whale")

varPart(A = 0.456, B = 0.315, C = 0.281, AB = 0.051, BC = 0.444,
AC = 0.569, ABC = 0.624, A.name = "Spatial", B.name = "Human",
C.name = "Environmental", main = "Small whale", colr = TRUE)


# if you have a generalized linear model (GLM),
# you can use squared Pearson correlation coefficients of the
# predictions of each factor with those of the complete model:

varPart(A = (-0.005)^2, B = 0.698^2, C = 0.922^2, AB = 0.696^2,
BC = 0.994^2, AC = 0.953^2, ABC = 1, A.name = "Topographic",
B.name = "Climatic", C.name = "Geographic", main = "Big bird")

# but "Unexplained variation" can be deceiving in these cases
# (see Details); try also adding 'plot.unexpl = FALSE'


# if you have a model object and a table classifying the variables into groups:

data(rotif.mods)
mod &lt;- rotif.mods$models[[2]]

head(mod$model)
vars &lt;- colnames(mod$model)[-1]
vars
var_groups &lt;- data.frame(vars = vars, groups = c("Spatial", "Spatial",
"Climate", "Climate", "Climate", "Human"))
var_groups

varPart(model = mod, groups = var_groups)
varPart(model = mod, groups = var_groups, pred.type = "P", colr = TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
