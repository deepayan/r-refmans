<!DOCTYPE html><html lang="en"><head><title>Help for package preputils</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {preputils}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#beta2m'><p>Convert proportional data to M-Values</p></a></li>
<li><a href='#coalesce'><p>select 1st existing value of several columns</p></a></li>
<li><a href='#fillmap'><p>Supplement missing values in mapping of data</p></a></li>
<li><a href='#filterpca'><p>Filter data set using PCA</p></a></li>
<li><a href='#fixlimits'><p>Fix extremes for logit transformation</p></a></li>
<li><a href='#incons'><p>Detect inconsistencies in 1:1 mapping</p></a></li>
<li><a href='#m2beta'><p>Convert logit transformed M-Values of proportional data</p>
back to original 0/1 range</a></li>
<li><a href='#normalize'><p>Normalize numeric variable to range(0,1)</p></a></li>
<li><a href='#pcv'><p>PCA on automatically selected attributes in high dimensional data</p></a></li>
<li><a href='#rmbat'><p>batch effect removal by mean centering and shifting</p></a></li>
<li><a href='#vifx'><p>Compute Variance inflation factor</p></a></li>
<li><a href='#write.data'><p>Create text data files using convenient defaults</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Utilities for Preparation of Data Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-05-18</td>
</tr>
<tr>
<td>Author:</td>
<td>Josef Frank</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Josef Frank &lt;josef.frank@gmx.ch&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Miscellaneous small utilities are provided to mitigate issues with messy, inconsistent or high dimensional data and help for preprocessing and preparing analyses.</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-05-18 20:31:09 UTC; josef</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-05-18 22:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='beta2m'>Convert proportional data to M-Values</h2><span id='topic+beta2m'></span>

<h3>Description</h3>

<p>Proportional data are commonly modelled using a glm
approach with logit link function. When performing the logit
transformation in advance separately, simple OLS methods can be
applied.</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta2m(b)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="beta2m_+3A_b">b</code></td>
<td>
<p>vector or matrix holding the original data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data are transformed according to
M=log<sub>2</sub>(<sup>b</sup>&frasl;<sub>1-b</sub>)
.
The input data are assumed to have the range 0&lt;b&lt;1.
Data outside this range will lead to missing values.
Corner cases (data of b=0 or b=1) can be handled by use
of fixlimits().
</p>


<h3>Value</h3>

<p>A named vector/matrix with same dimensions as b and log<sub>2</sub> transformed values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    a &lt;- sapply(c(0.01,0.05,0.5,0.8,0.9),function(x) rbinom(30,100,x)/100)
    matplot(a,pch=20)
    matplot(beta2m(a),pch=20)
    matplot(a,beta2m(a),pch=20)
</code></pre>

<hr>
<h2 id='coalesce'>select 1st existing value of several columns</h2><span id='topic+coalesce'></span>

<h3>Description</h3>

<p>Inspired by the respectively named sql function.
In a list of vectors with equal length the function for each
of the observations selects the first value that is not NA,
in the order provided</p>


<h3>Usage</h3>

<pre><code class='language-R'>coalesce(...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coalesce_+3A_...">...</code></td>
<td>
<p>vectors holding the values, sepearated by &quot;,&quot;
(commonly columns of data.frame)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data are transformed according to </p>
<p style="text-align: center;"><code class="reqn">b=\frac{2^M}{2^M+1}</code>
</p>



<h3>Value</h3>

<p>A named vector holding the supplemented values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    a1 = c(1,NA,NA,NA)
    a2 = c(2,2,NA,NA)
    a3 = c(NA,3,3,NA)
    cbind(a1,a2,a3,suppl=coalesce(a1,a2,a3))
</code></pre>

<hr>
<h2 id='fillmap'>Supplement missing values in mapping of data</h2><span id='topic+fillmap'></span>

<h3>Description</h3>

<p>In properly normalized data bases, 1:1 mapping should be
complete and unique. In real world data however ID mappings or
data base key candidates are repeated over and over across
observations, partly with missing data in case of merged data set.
fillmap supplements NAs in mapping variables as far as possible
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fillmap(x, y, what = "xy", rmdup=FALSE, rmmiss=FALSE,
    printori=FALSE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fillmap_+3A_x">x</code>, <code id="fillmap_+3A_y">y</code></td>
<td>
<p>vectors of equal length, holding the mapping values,
sepearated by &quot;,&quot;</p>
</td></tr>
<tr><td><code id="fillmap_+3A_what">what</code></td>
<td>
<p>data to be returned, either 1st (&quot;x&quot;) or 2nd argument
(&quot;y&quot;) or a data,table, cointaining both (&quot;xy&quot;)</p>
</td></tr>
<tr><td><code id="fillmap_+3A_rmdup">rmdup</code></td>
<td>
<p>remove duplicates from mapping (TRUE) or return all
rows in original order (FALSE)</p>
</td></tr>
<tr><td><code id="fillmap_+3A_rmmiss">rmmiss</code></td>
<td>
<p>remove rows, where not mapping could be found (TRUE)
or return all rows (FALSE)</p>
</td></tr>
<tr><td><code id="fillmap_+3A_printori">printori</code></td>
<td>
<p>print original variables side by side</p>
</td></tr>
</table>


<h3>Details</h3>

<p>incons assumes a 1:1 mapping between provided variables, as is
commonly the case for example in ID translation steps. 
</p>
<p>For all cases where a proper unambiguous 1:1 matching exists. The missings
values are filled in
</p>


<h3>Value</h3>

<p>Vector or data.table with original mapping data, where NAs are
filled in whith supplemented data where possible
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    library(data.table)
    pheno1 &lt;- data.frame(id1=c(1,2,3,4),id2=c(11,22,NA,NA),phenodat=c(NA,NA,NA,"d"))
    pheno2 &lt;- data.frame(id1=c(NA,NA,NA),id2=c(11,22,33),phenodat=c("a","b","c"))
    pheno3 &lt;- data.frame(id1=c(4,3),id2=c(44,33),phenodat=c(NA,NA))
    phenoges &lt;- rbind(rbind(pheno1,pheno2),pheno3)
    with(phenoges,fillmap(id1,phenodat))
    with(phenoges,fillmap(id1,phenodat,rmdup=TRUE))
    with(phenoges,fillmap(id1,phenodat,rmmiss=TRUE))
    with(phenoges,fillmap(id1,phenodat,rmdup=TRUE,rmmiss=TRUE))
    with(phenoges,fillmap(id2,phenodat))
    with(phenoges,fillmap(id2,phenodat,rmdup=TRUE))
    with(phenoges,fillmap(id2,phenodat,rmmiss=TRUE))
    with(phenoges,fillmap(id2,phenodat,rmdup=TRUE,rmmiss=TRUE))
    phenosupp &lt;- with(phenoges,fillmap(id1,id2))
    names(phenosupp) &lt;- c("id1","id2")
    phenosupp$phenodat &lt;- fillmap(phenosupp$id1,phenoges$phenodat,what="y")
    unique(phenosupp)
</code></pre>

<hr>
<h2 id='filterpca'>Filter data set using PCA</h2><span id='topic+filterpca'></span>

<h3>Description</h3>

<p>Noise removal in data set by means of using principal component analysis. Optionally calculate distances (reconstruction error and Mahalanobis distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterpca(x,npc=NULL,pcs=NULL,scale.=F,
	method=c("k","t"),resulttype=c("p","d","b"),lambda=NULL)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filterpca_+3A_x">x</code></td>
<td>
<p>data set</p>
</td></tr>
<tr><td><code id="filterpca_+3A_npc">npc</code></td>
<td>
<p>Number of leading principal components to be used for reconstruction of data set after filtering (positive integer) or number of last components to be skipped (negative integer).</p>
</td></tr>
<tr><td><code id="filterpca_+3A_pcs">pcs</code></td>
<td>
<p>Vector of integers providing column numbers of components to be included for reconstruction (positive numbers) or components to be skipped (negative numbers). In case of mixed signs negative numbers are ignored.</p>
</td></tr>
<tr><td><code id="filterpca_+3A_scale.">scale.</code></td>
<td>
<p>should values be scaled to unit variance before PCA?</p>
</td></tr>
<tr><td><code id="filterpca_+3A_method">method</code></td>
<td>
<p>One of either &quot;k&quot; or &quot;t&quot;, with following meaning: &quot;k&quot;: No further filtering except from ignoring some components when projecting back into original space; &quot;t&quot;: Additionally threshold data by setting all value with absolute value below lambda to 0</p>
</td></tr>
<tr><td><code id="filterpca_+3A_resulttype">resulttype</code></td>
<td>
<p>Type of resulting value, either matrix of projected values (p), distances (d) or a list containing both (b)</p>
</td></tr>
<tr><td><code id="filterpca_+3A_lambda">lambda</code></td>
<td>
<p>cutoff to be used for thresholding data. Lambda = NULL instructs to use a predefined value of 5% of the mean deviation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs PCA on provided data set. Noise is removed by reconstructing original values either on only a subset of extracted PCs, thresholding PC-scores (setting all values with absolute value below provided cutoff to 0) or a combination of both.
</p>


<h3>Value</h3>

<p>Depending on requested resulttype:
</p>
<table role = "presentation">
<tr><td><code>p</code></td>
<td>
<p>Matrix with original observations projected back onto original attribute space after filtering</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Data frame with Mahalanobis distance of observations calculated only on subset of requested PCs and with reconstruction error</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>List containing both values mentioned above</p>
</td></tr>    
</table>


<h3>Examples</h3>

<pre><code class='language-R'>    a = iris[-5]
    b0 = filterpca(a,npc=4,res="b")
    b1 = filterpca(a,npc=3,res="b")
    b2 = filterpca(a,npc=2,res="b")
    pairs(b0,pch=20,col=iris$Species)
    pairs(b1,pch=20,col=iris$Species)
    pairs(b2,pch=20,col=iris$Species)
</code></pre>

<hr>
<h2 id='fixlimits'>Fix extremes for logit transformation</h2><span id='topic+fixlimits'></span>

<h3>Description</h3>

<p>Change extreme values in proprtional data
prior to logit transformation</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixlimits(x)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fixlimits_+3A_x">x</code></td>
<td>
<p>name of vector to adjust</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function assumes a data range of 0&lt;=x&lt;=1. Data outside this
range are regarded as measurement errors and recoded to NA.
In order to avoid generating missings during logit transformation
values &gt;=1 and &lt;=0 respectively are shifted to lie within the
range (0,1) excluding the borders themselves by recoding them to
the mean of the respective border and and the most extreme
nearest neighbour.
</p>


<h3>Value</h3>

<p>vector of same length as x with adjusted values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    fixlimits(0:5/5)
</code></pre>

<hr>
<h2 id='incons'>Detect inconsistencies in 1:1 mapping</h2><span id='topic+incons'></span>

<h3>Description</h3>

<p>In properly normalized data bases, no inconsistencies
should be present. In real world data however ID mappings or
data base key candidates are repeated over and over across
observations, especially in mult centric studies with basic
research data. incons tries to detect and flag these mapping
discrepanices</p>


<h3>Usage</h3>

<pre><code class='language-R'>incons(x, y, printproblems=FALSE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="incons_+3A_x">x</code>, <code id="incons_+3A_y">y</code></td>
<td>
<p>vectors of equal length, holding the mapping values,
sepearated by &quot;,&quot;</p>
</td></tr>
<tr><td><code id="incons_+3A_printproblems">printproblems</code></td>
<td>
<p>Should a table of found problems be printed
in addition to the returned flag?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>incons assumes a 1:1 mapping between provided variables, as is
commonly the case for example in ID translation steps
</p>


<h3>Value</h3>

<p>A named vector indicating whether ambiguous mapping does occur (TRUE) 
or mapping is clean (FALSE)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    id1 = c(1,2,2,3,4)
    id2 = c("a","b","c","d","d")
    ambiguous &lt;- incons(id1,id2,print=TRUE)
    data.frame(id1,id2,ambiguous)
</code></pre>

<hr>
<h2 id='m2beta'>Convert logit transformed M-Values of proportional data
back to original 0/1 range</h2><span id='topic+m2beta'></span>

<h3>Description</h3>

<p>Despite conducting analysis of proportional data in M space,
for publication figures the estimated values are commonly shown
in the original space (range between 0 and 1). This function
provides backscaling of the M values to original space by
inverting the logit transformation done by beta2m()</p>


<h3>Usage</h3>

<pre><code class='language-R'>m2beta(M)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m2beta_+3A_m">M</code></td>
<td>
<p>vector or matrix holding the original data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data are transformed according to </p>
<p style="text-align: center;"><code class="reqn">b=\frac{2^M}{2^M+1}</code>
</p>



<h3>Value</h3>

<p>A named vector/matrix with same dimensions as M and transformed values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    b = 1:99 / 100
    M = beta2m(b)
    plot(b,m2beta(M))
    print(all.equal(b, m2beta(M)))
</code></pre>

<hr>
<h2 id='normalize'>Normalize numeric variable to range(0,1)</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Changes range of numeric variables to have min=0 and max=1</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>name of object to normalize</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function changes the range of the named numeric vector to finally have min(x)=0 and max(x)=1.     
</p>


<h3>Value</h3>

<p>vector of same length as x with normalized values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    normalize(1:5)
</code></pre>

<hr>
<h2 id='pcv'>PCA on automatically selected attributes in high dimensional data</h2><span id='topic+pcv'></span>

<h3>Description</h3>

<p> Conduct PCA on variables with biggest variance
in high dimensional data matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcv(x, cols=5, sites=5000)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcv_+3A_x">x</code></td>
<td>
<p>name of data matrix</p>
</td></tr>
<tr><td><code id="pcv_+3A_cols">cols</code></td>
<td>
<p>number of principal components to extract</p>
</td></tr>
<tr><td><code id="pcv_+3A_sites">sites</code></td>
<td>
<p>number of attributes to consider</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pcv assumes data in a numeric matrix and variable major format,
i.e. every line corresponds to to a variable,
while the columns correspond to the individual observations.
This is commonly the case for data in high throughput experiments
where the number of data points per individuals is high (&gt; 10,000),
while the size of batches is comparably small (dozens to hundreds).
Variables with missing values are disregarded for the selection.
</p>
<p>Use t() to transpose individual major data sets beforehand.
</p>
<p>pcv selects the attributes with the highest variance up to
the numbers provided, but takes considerations to limit these to
the actual size of the present data set. 
</p>
<p>This is often used as first step in high throughput measurements
to detect global effects of known batch variables.
</p>


<h3>Value</h3>

<p>matrix with rows corresponding to observations and columns
to extracted components. Values denote the scores on the extracted
components for the respective observations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    pcs &lt;- pcv(t(iris[1:4]),cols=2)    
    cor(pcs,iris[-5])
</code></pre>

<hr>
<h2 id='rmbat'>batch effect removal by mean centering and shifting</h2><span id='topic+rmbat'></span>

<h3>Description</h3>

<p>Remove known categorical batch effects from high dimensional data sets</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmbat(x,batches)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmbat_+3A_x">x</code></td>
<td>
<p>name of object to be processed. This is a matrix in atribute major format (rows correspond to variables, columns to observations)</p>
</td></tr>
<tr><td><code id="rmbat_+3A_batches">batches</code></td>
<td>
<p>Vector with batch identifiers for each of
the columns in x</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each variable the mean values of all batches are shifted to the grand mean of the total sample. On case of several independent bacth effects being present in th data set, thes can either be combined in one batch variable, or the batches can be removed one at a time by chaining the processing and caling the cuntiong with each of the batch variables in turn
</p>


<h3>Value</h3>

<p>matrix with same dimensions as x and batch effects removed
</p>


<h3>Note</h3>

<p>This function is intended for use with methods that do not inherently allow inclusion of covariates in the analysis itself, e.g. pca or heatmap. If methods are used that allow inclusion of batches in analysis like linear models, that is preferred, as the method above can otherwise greatly reduce power if batches are correlated with the effect variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # create data set
    n_obs = 8
    n_var = 10
    predictor &lt;- rep(0:1,n_obs*0.5)
    pure_effect &lt;- outer(rnorm(n_var),predictor)
    error &lt;- matrix(rnorm(n_var*n_obs),n_var,n_obs)
    batch1 &lt;- rep(1:2,each=n_obs*0.5)
    batch2 &lt;- rep(c(1,2,1,2),each=n_obs*0.25)
    batch_effect1 &lt;- outer(rnorm(n_var)*2,scale(batch1))[,,1]
    batch_effect2 &lt;- outer(rnorm(n_var)*4,scale(batch2))[,,1]
    batch_effect &lt;- batch_effect1 + batch_effect2
    data_measured &lt;- pure_effect + batch_effect + error
    
    zero = outer(rep(0,n_var),rep(0,n_obs))
    b1 &lt;- rmbat(batch_effect1,batch1)
    b2 &lt;- rmbat(batch_effect2,batch2)
    b12a &lt;- rmbat(batch_effect1,paste(batch1,batch2))
    b12b &lt;- batch_effect 
    all.equal(b1,zero)
    all.equal(b2,zero)
    all.equal(b12a,zero)
    all.equal(b12b,zero)
</code></pre>

<hr>
<h2 id='vifx'>Compute Variance inflation factor</h2><span id='topic+vifx'></span>

<h3>Description</h3>

<p>Calculate variance inflation factors (VIF) for all numeric variables contained in data set</p>


<h3>Usage</h3>

<pre><code class='language-R'>vifx(x)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vifx_+3A_x">x</code></td>
<td>
<p>name of data frame for which the VIFs should be computed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function reads in the object named in x, builds a linear model for each of the contained variables in the data set, regressing the selected variable on all other numeric variables contained in the data set. 
</p>
<p>The multiple R-squared is computed and transformed to VIF using following formula:
<code class="reqn">VIF_i=\frac{1}{1-R_i^2}</code>
</p>


<h3>Value</h3>

<p>A named vector with names given by the contained numeric variables and values by the computed respective VIFs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    vifx(iris)
</code></pre>

<hr>
<h2 id='write.data'>Create text data files using convenient defaults</h2><span id='topic+write.tab'></span><span id='topic+write.space'></span>

<h3>Description</h3>

<p>Several presets are provided for creating text data files.
Functions are based on write.table, with some predefined extras
to save time when writing data sets to clear text files</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.tab(data, filename, sep="\t", quote=FALSE, row.names=FALSE, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.data_+3A_data">data</code></td>
<td>
<p>name of object to be saved</p>
</td></tr>
<tr><td><code id="write.data_+3A_filename">filename</code></td>
<td>
<p>File name</p>
</td></tr>
<tr><td><code id="write.data_+3A_sep">sep</code></td>
<td>
<p>Column separator, see details</p>
</td></tr>
<tr><td><code id="write.data_+3A_quote">quote</code></td>
<td>
<p>Should text data be quoted? Default FALSE</p>
</td></tr>
<tr><td><code id="write.data_+3A_row.names">row.names</code></td>
<td>
<p>Whether rownames whould be included in output,
default=FALSE</p>
</td></tr>
<tr><td><code id="write.data_+3A_...">...</code></td>
<td>
<p>Further arguments passed on to write.table()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both of the named functions just use the filename as 2nd positional argument and call write.table(). Difference between both is that write.tab has predefined the column separator as &quot;\t&quot;, while write.space uses the write.table default &quot; &quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Not run: 
        write.tab(iris,"~/iris_tab.txt")
        write.space(iris,"~/iris_space.txt")
    
## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
