<!DOCTYPE html><html><head><title>Help for package pracma</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pracma}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pracma-package'>
<p>Practical Numerical Math Routines</p></a></li>
<li><a href='#abm3pc'>
<p>Adams-Bashford-Moulton</p></a></li>
<li><a href='#accumarray'>
<p>Accumulate Vector Elements</p></a></li>
<li><a href='#agmean'>
<p>Arithmetic-geometric Mean</p></a></li>
<li><a href='#aitken'>
<p>Aitken' Method</p></a></li>
<li><a href='#akimaInterp'>
<p>Univariate Akima Interpolation</p></a></li>
<li><a href='#and, or'>
<p>Logical AND, OR (Matlab Style)</p></a></li>
<li><a href='#andrewsplot'>
<p>Andrews' Curves</p></a></li>
<li><a href='#angle'><p>Basic Complex Functions</p></a></li>
<li><a href='#anms'>
<p>Adaptive Nelder-Mead Minimization</p></a></li>
<li><a href='#approx_entropy'>
<p>Approximate and Sample Entropy</p></a></li>
<li><a href='#arclength'>
<p>Arc Length of a Curve</p></a></li>
<li><a href='#arnoldi'><p>Arnoldi Iteration</p></a></li>
<li><a href='#barylag'><p>Barycentric Lagrange Interpolation</p></a></li>
<li><a href='#barylag2d'><p>2-D Barycentric Lagrange Interpolation</p></a></li>
<li><a href='#bernoulli'>
<p>Bernoulli Numbers and Polynomials</p></a></li>
<li><a href='#bernstein'>
<p>Bernstein Polynomials</p></a></li>
<li><a href='#bisect'>
<p>Rootfinding Through Bisection or Secant Rule</p></a></li>
<li><a href='#bits'><p>Binary Representation</p></a></li>
<li><a href='#blanks'><p>String of Blank Carakters</p></a></li>
<li><a href='#blkdiag'>
<p>Block Diagonal Matrix</p></a></li>
<li><a href='#brentDekker'>
<p>Brent-Dekker Root Finding Algorithm</p></a></li>
<li><a href='#brown72'>
<p>Brownian Motion</p></a></li>
<li><a href='#broyden'><p>Broyden's Method</p></a></li>
<li><a href='#bsxfun'>
<p>Elementwise Function Application (Matlab Style)</p></a></li>
<li><a href='#bulirsch-stoer'>
<p>Bulirsch-Stoer Algorithm</p></a></li>
<li><a href='#bvp'>
<p>Boundary Value Problems</p></a></li>
<li><a href='#cart2sph'>
<p>Coordinate Transformations</p></a></li>
<li><a href='#cd, pwd, what'>
<p>Directory Functions (Matlab style)</p></a></li>
<li><a href='#ceil'><p>Integer Functions (Matlab Style)</p></a></li>
<li><a href='#charpoly'>
<p>Characteristic Polynomial</p></a></li>
<li><a href='#chebApprox'><p>Chebyshev Approximation</p></a></li>
<li><a href='#chebCoeff'><p>Chebyshev Polynomials</p></a></li>
<li><a href='#chebPoly'><p>Chebyshev Polynomials</p></a></li>
<li><a href='#circlefit'><p>Fitting a Circle</p></a></li>
<li><a href='#clear, who(s), ver'>
<p>Clear function (Matlab style)</p></a></li>
<li><a href='#clenshaw_curtis'>
<p>Clenshaw-Curtis Quadrature Formula</p></a></li>
<li><a href='#combs'>
<p>Generate Combinations</p></a></li>
<li><a href='#compan'><p>Companion Matrix</p></a></li>
<li><a href='#complexstep'><p>Complex Step Derivatives</p></a></li>
<li><a href='#cond'>
<p>Matrix Condition</p></a></li>
<li><a href='#conv'><p>Polynomial Convolution</p></a></li>
<li><a href='#cot,csc,sec, etc.'>
<p>More Trigonometric Functions</p></a></li>
<li><a href='#cotes'>
<p>Newton-Cotes Formulas</p></a></li>
<li><a href='#coth,csch,sech, etc.'>
<p>More Hyperbolic Functions</p></a></li>
<li><a href='#cranknic'>
<p>Crank-Nicolson Method</p></a></li>
<li><a href='#cross'><p>Vector Cross Product</p></a></li>
<li><a href='#crossn'><p>n-dimensional Vector Cross Product</p></a></li>
<li><a href='#cubicspline'>
<p>Interpolating Cubic Spline</p></a></li>
<li><a href='#curvefit'>
<p>Parametric Curve Fit</p></a></li>
<li><a href='#cutpoints'>
<p>Find Cutting Points</p></a></li>
<li><a href='#dblquad'>
<p>Double and Triple Integration</p></a></li>
<li><a href='#deconv'><p>Deconvolution</p></a></li>
<li><a href='#deeve'>
<p>Event Detection in ODE solution</p></a></li>
<li><a href='#deg2rad'><p>Degrees to Radians</p></a></li>
<li><a href='#detrend'>
<p>Remove Linear Trends</p></a></li>
<li><a href='#deval'>
<p>Evaluate ODE Solution</p></a></li>
<li><a href='#Diag'><p>Matrix Diagonal</p></a></li>
<li><a href='#disp,beep'>
<p>Utility functions (Matlab style)</p></a></li>
<li><a href='#distmat'><p>Distance Matrix</p></a></li>
<li><a href='#dot'><p>Scalar Product</p></a></li>
<li><a href='#eig'><p>Eigenvalue Function (Matlab Style)</p></a></li>
<li><a href='#eigjacobi'>
<p>Jacobi Eigenvalue Method</p></a></li>
<li><a href='#einsteinF'>
<p>Einstein Functions</p></a></li>
<li><a href='#ellipke,ellipj'>
<p>Elliptic and Jacobi Elliptic Integrals</p></a></li>
<li><a href='#eps'>
<p>Floating Point Relative Accuracy</p></a></li>
<li><a href='#erf'>
<p>Error Functions and Inverses (Matlab Style)</p></a></li>
<li><a href='#errorbar'>
<p>Plot Error Bars</p></a></li>
<li><a href='#eta'>
<p>Dirichlet Eta Function</p></a></li>
<li><a href='#euler_heun'>
<p>Euler-Heun ODE Solver</p></a></li>
<li><a href='#expint'>
<p>Exponential and Logarithmic Integral</p></a></li>
<li><a href='#expm'>
<p>Matrix Exponential</p></a></li>
<li><a href='#eye'><p>Some Basic Matrices</p></a></li>
<li><a href='#ezcontour,ezsurf,ezmesh'>
<p>Contour, Surface, and Mesh Plotter</p></a></li>
<li><a href='#ezplot'>
<p>Easy Function Plot</p></a></li>
<li><a href='#ezpolar'>
<p>Easy Polar Plot</p></a></li>
<li><a href='#fact'>
<p>Factorial Function</p></a></li>
<li><a href='#factors'><p>Prime Factors</p></a></li>
<li><a href='#fderiv'>
<p>Numerical Differentiation</p></a></li>
<li><a href='#fibsearch'>
<p>Fibonacci Search</p></a></li>
<li><a href='#figure'>
<p>Control Plot Devices (Matlab Style)</p></a></li>
<li><a href='#findintervals'>
<p>Find Interval Indices</p></a></li>
<li><a href='#findmins'>
<p>Find All Minima</p></a></li>
<li><a href='#findpeaks'>
<p>Find Peaks</p></a></li>
<li><a href='#finds'><p>find function (Matlab Style)</p></a></li>
<li><a href='#findzeros'>
<p>Find All Roots</p></a></li>
<li><a href='#fletcher_powell'>
<p>Fletcher-Powell Conjugate Gradient Minimization</p></a></li>
<li><a href='#flipdim'><p>Matrix Flipping (Matlab Style)</p></a></li>
<li><a href='#fminbnd'>
<p>Finding Function Minimum</p></a></li>
<li><a href='#fmincon'>
<p>Minimize Nonlinear Constrained Multivariable Function.</p></a></li>
<li><a href='#fminsearch'>
<p>Derivative-free Nonlinear Function Minimization</p></a></li>
<li><a href='#fminunc'>
<p>Minimize Unconstrained Multivariable Function</p></a></li>
<li><a href='#fnorm'>
<p>Function Norm</p></a></li>
<li><a href='#fornberg'>
<p>Fornberg's Finite Difference Approximation</p></a></li>
<li><a href='#fprintf'>
<p>Formatted Printing (Matlab style)</p></a></li>
<li><a href='#fractalcurve'>
<p>Fractal Curves</p></a></li>
<li><a href='#fresnelS/C'>
<p>Fresnel Integrals</p></a></li>
<li><a href='#fsolve'>
<p>Solve System of Nonlinear Equations</p></a></li>
<li><a href='#fzero'>
<p>Root Finding Algorithm</p></a></li>
<li><a href='#fzsolve'>
<p>Complex Root Finding</p></a></li>
<li><a href='#gammainc'>
<p>Incomplete Gamma Function</p></a></li>
<li><a href='#gammaz'>
<p>Complex Gamma Function</p></a></li>
<li><a href='#gauss_kronrod'>
<p>Gauss-Kronrod Quadrature</p></a></li>
<li><a href='#gaussHermite'>
<p>Gauss-Hermite Quadrature Formula</p></a></li>
<li><a href='#gaussLaguerre'>
<p>Gauss-Laguerre Quadrature Formula</p></a></li>
<li><a href='#gaussLegendre'>
<p>Gauss-Legendre Quadrature Formula</p></a></li>
<li><a href='#gaussNewton'><p>Gauss-Newton Function Minimization</p></a></li>
<li><a href='#gcd, lcm'><p>GCD and LCM Integer Functions</p></a></li>
<li><a href='#geo_median'>
<p>Geometric Median</p></a></li>
<li><a href='#geomean, harmmean'>
<p>Geometric and Harmonic Mean (Matlab Style)</p></a></li>
<li><a href='#givens'><p>Givens Rotation</p></a></li>
<li><a href='#gmres'>
<p>Generalized Minimal Residual Method</p></a></li>
<li><a href='#golden_ratio'>
<p>Golden Ratio Search</p></a></li>
<li><a href='#grad'>
<p>Numerical Gradient</p></a></li>
<li><a href='#gradient'>
<p>Discrete Gradient (Matlab Style)</p></a></li>
<li><a href='#gramSchmidt'><p>Gram-Schmidt</p></a></li>
<li><a href='#hadamard'><p>Hadamard Matrix</p></a></li>
<li><a href='#halley'>
<p>Halley's Root Finding Mathod</p></a></li>
<li><a href='#hampel'>
<p>Hampel Filter</p></a></li>
<li><a href='#hankel'><p>Hankel Matrix</p></a></li>
<li><a href='#hausdorff_dist'><p>Hausdorff Distance</p></a></li>
<li><a href='#haversine'>
<p>Haversine Formula</p></a></li>
<li><a href='#hessenberg'>
<p>Hessenberg Matrix</p></a></li>
<li><a href='#hessian'>
<p>Hessian Matrix</p></a></li>
<li><a href='#Hessian utilities'><p>Hessian utilities</p></a></li>
<li><a href='#hilb'><p>Hilbert Matrix</p></a></li>
<li><a href='#histc'>
<p>Histogram Count (Matlab style)</p></a></li>
<li><a href='#histss'>
<p>Histogram Bin-width Optimization</p></a></li>
<li><a href='#hooke_jeeves'>
<p>Hooke-Jeeves Function Minimization Method</p></a></li>
<li><a href='#horner'>
<p>Horner's Rule</p></a></li>
<li><a href='#householder'><p>Householder Reflections</p></a></li>
<li><a href='#humps'>
<p>Matlab Test Functions</p></a></li>
<li><a href='#hurstexp'>
<p>Hurst Exponent</p></a></li>
<li><a href='#hypot'><p>Hypotenuse Function</p></a></li>
<li><a href='#ifft'>
<p>Inverse Fast Fourier Transformation</p></a></li>
<li><a href='#inpolygon'>
<p>Polygon Region</p></a></li>
<li><a href='#integral'>
<p>Adaptive Numerical Integration</p></a></li>
<li><a href='#integral2'>
<p>Numerically Evaluate Double  and Triple Integrals</p></a></li>
<li><a href='#interp1'>
<p>One-dimensional Interpolation</p></a></li>
<li><a href='#interp2'>
<p>Two-dimensional Data Interpolation</p></a></li>
<li><a href='#inv'><p>Matrix Inverse (Matlab Style)</p></a></li>
<li><a href='#invlap'>
<p>Inverse Laplacian</p></a></li>
<li><a href='#isempty'><p>isempty Property</p></a></li>
<li><a href='#isposdef'>
<p>Positive Definiteness</p></a></li>
<li><a href='#isprime'><p>isprime Property</p></a></li>
<li><a href='#itersolve'>
<p>Iterative Methods</p></a></li>
<li><a href='#jacobian'><p>Jacobian Matrix</p></a></li>
<li><a href='#kriging'>
<p>Interpolation by Kriging</p></a></li>
<li><a href='#kron'><p>Kronecker product (Matlab Style)</p></a></li>
<li><a href='#L1linreg'>
<p>L1 Linear Regression</p></a></li>
<li><a href='#laguerre'>
<p>Laguerre's Method</p></a></li>
<li><a href='#lambertWp'>
<p>Lambert's W Function</p></a></li>
<li><a href='#laplacian'>
<p>Laplacian Operator</p></a></li>
<li><a href='#lebesgue'><p>Lebesgue Constant</p></a></li>
<li><a href='#legendre'>
<p>Legendre Functions (Matlab Style)</p></a></li>
<li><a href='#line_integral'>
<p>Line integral (in the complex plane)</p></a></li>
<li><a href='#linearproj, affineproj'>
<p>Linear Projection onto a Subspace</p></a></li>
<li><a href='#linprog'>
<p>Linear Programming Solver</p></a></li>
<li><a href='#linspace'><p>Linearly Spaced Sequences</p></a></li>
<li><a href='#logspace'><p>Log-linearly Spaced Sequences</p></a></li>
<li><a href='#lsqlin'>
<p>Linear Least-Squares Fitting</p></a></li>
<li><a href='#lsqlincon'>
<p>Linear Least-Squares Fitting with linear constraints</p></a></li>
<li><a href='#lsqnonlin'>
<p>Nonlinear Least-Squares Fitting</p></a></li>
<li><a href='#lu'>
<p>LU Matrix Factorization</p></a></li>
<li><a href='#magic'><p>Magic Square</p></a></li>
<li><a href='#matlab'>
<p>Matlab Compatibility</p></a></li>
<li><a href='#meshgrid'>
<p>Generate a Mesh Grid</p></a></li>
<li><a href='#mexpfit'>
<p>Multi-exponential Fitting</p></a></li>
<li><a href='#mldivide'><p>Matlab backslash operator</p></a></li>
<li><a href='#mod, rem'><p>Integer Division</p></a></li>
<li><a href='#Mode'>
<p>Mode function (Matlab style)</p></a></li>
<li><a href='#moler'><p>Moler Matrix</p></a></li>
<li><a href='#movavg'>
<p>Moving Average Filters</p></a></li>
<li><a href='#muller'>
<p>Muller's Method</p></a></li>
<li><a href='#nchoosek'>
<p>Binomial Coefficients</p></a></li>
<li><a href='#ndims'><p>Number of Dimensions</p></a></li>
<li><a href='#nearest_spd'>
<p>Nearest Symmetric Positive-definite Matrix</p></a></li>
<li><a href='#nelder_mead'>
<p>Nelder-Mead Function Minimization Method</p></a></li>
<li><a href='#neville'>
<p>Neville's Method</p></a></li>
<li><a href='#newmark'>
<p>Newmark Method</p></a></li>
<li><a href='#newtonHorner'>
<p>Newton's Root Finding Method for Polynomials.</p></a></li>
<li><a href='#newtonInterp'>
<p>Lagrange and Newtons Interpolation</p></a></li>
<li><a href='#newtonRaphson'>
<p>Rootfinding through Newton-Raphson or Secant.</p></a></li>
<li><a href='#newtonsys'><p>Newton Method for Nonlinear Systems</p></a></li>
<li><a href='#nextpow2'><p>Next Power of 2</p></a></li>
<li><a href='#nnz'><p>Nonzero Elements</p></a></li>
<li><a href='#Norm'>
<p>Vector Norm</p></a></li>
<li><a href='#normest'>
<p>Estimated Matrix Norm</p></a></li>
<li><a href='#nthroot'><p>Real nth Root</p></a></li>
<li><a href='#nullspace'>
<p>Kernel or Nullspace</p></a></li>
<li><a href='#numderiv'>
<p>Richardson's Numerical Derivative</p></a></li>
<li><a href='#numel'><p>Number of Elements</p></a></li>
<li><a href='#ode23'>
<p>Non-stiff (and stiff) ODE solvers</p></a></li>
<li><a href='#odregress'>
<p>Orthogonal Distance Regression</p></a></li>
<li><a href='#orth'>
<p>Range Space</p></a></li>
<li><a href='#pade'>
<p>Pade Approximation</p></a></li>
<li><a href='#pascal'>
<p>Pascal Triangle</p></a></li>
<li><a href='#pchip'><p>Hermitean Interpolation Polynomials</p></a></li>
<li><a href='#peaks'>
<p>Peaks Function (Matlab Style)</p></a></li>
<li><a href='#perms'>
<p>Generate Permutations</p></a></li>
<li><a href='#piecewise'>
<p>Piecewise Linear Function</p></a></li>
<li><a href='#pinv'>
<p>Pseudoinverse or Generalized Inverse</p></a></li>
<li><a href='#plotyy'>
<p>Plotting Two y-Axes</p></a></li>
<li><a href='#poisson2disk'>
<p>Poisson Disk Sampling</p></a></li>
<li><a href='#polar'>
<p>Polar Coordinate Plot (Matlab Style)</p></a></li>
<li><a href='#Poly'><p>Define Polynomial by Roots</p></a></li>
<li><a href='#poly2str'>
<p>Print Polynomial</p></a></li>
<li><a href='#polyadd'><p>Adding Polynomials</p></a></li>
<li><a href='#polyApprox'>
<p>Polynomial Approximation</p></a></li>
<li><a href='#polyarea'><p>Area of a Polygon</p></a></li>
<li><a href='#polyder'><p>Derivative of Polynomial</p></a></li>
<li><a href='#polyfit,polyfix'><p>Fitting by Polynomial</p></a></li>
<li><a href='#polyint'><p>Anti-derivative of Polynomial</p></a></li>
<li><a href='#polylog'>
<p>Polylogarithm Function</p></a></li>
<li><a href='#polymul, polydiv'><p>Multiplying and Dividing Polynomials</p></a></li>
<li><a href='#polypow'><p>Polynomial Powers</p></a></li>
<li><a href='#polytrans, polygcf'><p>Polynomial Transformations</p></a></li>
<li><a href='#polyval, polyvalm'><p>Evaluating a Polynomial</p></a></li>
<li><a href='#pow2'><p>Base 2 Power</p></a></li>
<li><a href='#ppfit'>
<p>Piecewise Polynomial Fit</p></a></li>
<li><a href='#ppval'>
<p>Piecewise Polynomial Structures</p></a></li>
<li><a href='#primes'><p>Prime Numbers</p></a></li>
<li><a href='#procrustes'>
<p>Solving the Procrustes Problem</p></a></li>
<li><a href='#psi'>
<p>Psi (Polygamma) Function</p></a></li>
<li><a href='#qpspecial, qpsolve'>
<p>Special Quadratic Programming Solver</p></a></li>
<li><a href='#qrSolve'><p>LSE Solution</p></a></li>
<li><a href='#quad'>
<p>Adaptive Simpson Quadrature</p></a></li>
<li><a href='#quad2d'>
<p>2-d Gaussian Quadrature</p></a></li>
<li><a href='#quadcc'>
<p>Adaptive Clenshaw-Curtis Quadrature</p></a></li>
<li><a href='#quadgk'>
<p>Adaptive Gauss-Kronrod Quadrature</p></a></li>
<li><a href='#quadgr'>
<p>Gaussian Quadrature with Richardson Extrapolation</p></a></li>
<li><a href='#quadinf'>
<p>Infinite Integrals</p></a></li>
<li><a href='#quadl'>
<p>Adaptive Lobatto Quadrature</p></a></li>
<li><a href='#quadprog'>
<p>Quadratic Programming</p></a></li>
<li><a href='#quadv'>
<p>Vectorized Integration</p></a></li>
<li><a href='#quiver'>
<p>Quiver or Velocity Plot</p></a></li>
<li><a href='#rand'><p>Create Random Matrices</p></a></li>
<li><a href='#randcomb'>
<p>Random Combination</p></a></li>
<li><a href='#randortho'>
<p>Generate Random Orthonormal or Unitary Matrix</p></a></li>
<li><a href='#randperm'>
<p>Random Permutation</p></a></li>
<li><a href='#Rank'>
<p>Matrix Rank</p></a></li>
<li><a href='#rat'>
<p>Continuous Fractions (Matlab Style)</p></a></li>
<li><a href='#ratinterp'>
<p>Rational Interpolation</p></a></li>
<li><a href='#rationalfit'>
<p>Rational Function Approximation</p></a></li>
<li><a href='#rectint'>
<p>Rectangle Intersection Areas</p></a></li>
<li><a href='#refindall'>
<p>Find overlapping regular expression matches.</p></a></li>
<li><a href='#regexp'>
<p>Match regular expression</p></a></li>
<li><a href='#regexprep'>
<p>Replace string using regular expression</p></a></li>
<li><a href='#repmat'><p>Replicate Matrix</p></a></li>
<li><a href='#Reshape'><p>Reshape Matrix</p></a></li>
<li><a href='#ridders'>
<p>Ridders' Root Finding Method</p></a></li>
<li><a href='#rk4, rk4sys'>
<p>Classical Runge-Kutta</p></a></li>
<li><a href='#rkf54'>
<p>Runge-Kutta-Fehlberg</p></a></li>
<li><a href='#rmserr'>
<p>Accuracy Measures</p></a></li>
<li><a href='#romberg'>
<p>Romberg Integration</p></a></li>
<li><a href='#roots, polyroots'><p>Polynomial Roots</p></a></li>
<li><a href='#rosser'><p>Rosser Matrix</p></a></li>
<li><a href='#rot90'><p>Matrix Rotation</p></a></li>
<li><a href='#rref'>
<p>Reduced Row Echelon Form</p></a></li>
<li><a href='#runge'><p>Runge Function</p></a></li>
<li><a href='#savgol'>
<p>Savitzky-Golay Smoothing</p></a></li>
<li><a href='#segm_distance'>
<p>Segment Distance</p></a></li>
<li><a href='#segm_intersect'>
<p>Segment Intersection</p></a></li>
<li><a href='#semilogx,semilogy'>
<p>Semi-logarithmic Plots (Matlab Style)</p></a></li>
<li><a href='#shooting'><p>Shooting Method</p></a></li>
<li><a href='#shubert'>
<p>Shubert-Piyavskii Method</p></a></li>
<li><a href='#Si, Ci'>
<p>Sine and Cosine Integral Functions</p></a></li>
<li><a href='#sigmoid'>
<p>Sigmoid Function</p></a></li>
<li><a href='#simpadpt'>
<p>Adaptive Simpson Quadrature</p></a></li>
<li><a href='#simpson2d'>
<p>Double Simpson Integration</p></a></li>
<li><a href='#sind,cosd,tand, etc.'>
<p>Trigonometric Functions in Degrees</p></a></li>
<li><a href='#size'><p>Size of Matrix</p></a></li>
<li><a href='#softline'>
<p>Soft (Inexact) Line Search</p></a></li>
<li><a href='#sorting'><p>Sorting Routines</p></a></li>
<li><a href='#sortrows'><p>Sort Rows of a Matrix (Matlab Style)</p></a></li>
<li><a href='#spinterp'>
<p>Monotone (Shape-Preserving) Interpolation</p></a></li>
<li><a href='#sqrtm,rootm'>
<p>Matrix Square and p-th Roots</p></a></li>
<li><a href='#squareform'>
<p>Format Distance Matrix (Matlab Style)</p></a></li>
<li><a href='#std'><p>Standard Deviation (Matlab Style)</p></a></li>
<li><a href='#std_err'><p>Standard Error</p></a></li>
<li><a href='#steep_descent'>
<p>Steepest Descent Minimization</p></a></li>
<li><a href='#stereographic'>
<p>Stereographic Projection</p></a></li>
<li><a href='#str2num'>
<p>Converting string to number (Matlab style)</p></a></li>
<li><a href='#strcat'><p>String Concatenation</p></a></li>
<li><a href='#strcmp'><p>String Comparison</p></a></li>
<li><a href='#strfind'><p>Find Substrings</p></a></li>
<li><a href='#strjust'>
<p>Justify character vector</p></a></li>
<li><a href='#strRep'>
<p>Find and replace substring</p></a></li>
<li><a href='#strTrim'>
<p>Remove leading and trailing white space.</p></a></li>
<li><a href='#subspace'>
<p>Angle between two subspaces</p></a></li>
<li><a href='#sumalt'>
<p>Alternating Series Acceleration</p></a></li>
<li><a href='#taylor'>
<p>Taylor Series Approximation</p></a></li>
<li><a href='#tic,toc'><p>MATLAB timer functions</p></a></li>
<li><a href='#titanium'>
<p>Titanium Test Data</p></a></li>
<li><a href='#Toeplitz'><p>Toeplitz Matrix</p></a></li>
<li><a href='#Trace'><p>Matrix trace</p></a></li>
<li><a href='#trapz'><p>Trapezoidal Integration</p></a></li>
<li><a href='#tri'>
<p>Triangular Matrices (Matlab Style)</p></a></li>
<li><a href='#trigApprox'>
<p>Trigonometric Approximation</p></a></li>
<li><a href='#trigPoly'>
<p>Trigonometric Polynomial</p></a></li>
<li><a href='#triquad'>
<p>Gaussian Triangle Quadrature</p></a></li>
<li><a href='#trisolve'>
<p>Tridiagonal Linear System Solver</p></a></li>
<li><a href='#vander'><p>Vandermonde matrix</p></a></li>
<li><a href='#vectorfield'>
<p>Vector Field Plotting</p></a></li>
<li><a href='#whittaker'>
<p>Whittaker Smoothing</p></a></li>
<li><a href='#wilkinson'><p>wilkinson Matrix</p></a></li>
<li><a href='#zeta'>
<p>Riemann Zeta Function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-08</td>
</tr>
<tr>
<td>Title:</td>
<td>Practical Numerical Math Functions</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>NlcOptim, quadprog</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Provides a large number of functions from numerical analysis and
    linear algebra, numerical optimization, differential equations,
    time series, plus some well-known special mathematical functions.
    Uses 'MATLAB' function names where appropriate to simplify porting.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-08 14:09:36 UTC; hwb</td>
</tr>
<tr>
<td>Author:</td>
<td>Hans W. Borchers [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hans W. Borchers &lt;hwborchers@googlemail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-10 00:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='pracma-package'>
Practical Numerical Math Routines
</h2><span id='topic+pracma-package'></span><span id='topic+pracma'></span>

<h3>Description</h3>

<p>This package provides R implementations of more advanced functions in
numerical analysis, with a special view on on optimization and time
series routines. Uses Matlab/Octave function names where appropriate
to simplify porting.
</p>
<p>Some of these implementations are the result of courses on Scientific
Computing (&ldquo;Wissenschaftliches Rechnen&rdquo;) and are mostly intended to
demonstrate how to implement certain algorithms in R/S. Others are
implementations of algorithms found in textbooks.
</p>


<h3>Details</h3>

<p>The package encompasses functions from all areas of numerical analysis,
for example:
</p>

<ul>
<li><p> Root finding and minimization of univariate functions,<br />
e.g. Newton-Raphson, Brent-Dekker, Fibonacci or &lsquo;golden ratio&rsquo; search.
</p>
</li>
<li><p> Handling polynomials, including roots and polynomial fitting,<br />
e.g. Laguerre's and Muller's methods.
</p>
</li>
<li><p> Interpolation and function approximation,<br />
barycentric Lagrange interpolation, Pade and rational interpolation,
Chebyshev or trigonometric approximation.
</p>
</li>
<li><p> Some special functions,<br />
e.g. Fresnel integrals, Riemann's Zeta or the complex Gamma function,
and Lambert's W computed iteratively through Newton's method.
</p>
</li>
<li><p> Special matrices, e.g. Hankel, Rosser, Wilkinson
</p>
</li>
<li><p> Numerical differentiation and integration,<br />
Richardson approach and &ldquo;complex step&rdquo; derivatives, adaptive
Simpson and Lobatto integration and adaptive Gauss-Kronrod quadrature.
</p>
</li>
<li><p> Solvers for ordinary differential equations and systems,<br />
Euler-Heun, classical Runge-Kutta, ode23, or predictor-corrector method 
such as the Adams-Bashford-Moulton.
</p>
</li>
<li><p> Some functions from number theory,<br />
such as primes and prime factorization, extended Euclidean algorithm.
</p>
</li>
<li><p> Sorting routines, e.g. recursive quickstep.
</p>
</li>
<li><p> Several functions for string manipulation and regular search,
all wrapped and named similar to their Matlab analogues.
</p>
</li></ul>

<p>It serves three main goals:
</p>

<ul>
<li><p> Collecting R scripts that can be demonstrated in courses on
&lsquo;Numerical Analysis&rsquo; or &lsquo;Scientific Computing&rsquo; using R/S as the chosen
programming language.
</p>
</li>
<li><p> Wrapping functions with appropriate Matlab names to simplify
porting programs from Matlab or Octave to R.
</p>
</li>
<li><p> Providing an environment in which R can be used as a full-blown
numerical computing system.
</p>
</li></ul>

<p>Besides that, many of these functions could be called in R applications
as they do not have comparable counterparts in other R packages (at least
at this moment, as far as I know). 
</p>
<p>All referenced books have been utilized in one way or another.
Web links have been provided where reasonable.
</p>


<h3>Note</h3>

<p>The following 220 functions are emulations of correspondingly named Matlab 
functions and bear the same signature as their Matlab cousins if possible:
</p>
<p><code>accumarray, acosd, acot, acotd, acoth, acsc, acscd, acsch, and, angle, ans,</code><br />
<code>    arrayfun, asec, asecd, asech, asind, atand, atan2d,</code><br />
<code>beep, bernoulli, blank, blkdiag, bsxfun,</code><br />
<code>cart2pol, cart2sph, cd, ceil, circshift, clear, compan, cond, conv,</code><br />
<code>    cosd, cot, cotd, coth, cross, csc, cscd, csch, cumtrapz,</code><br />
<code>dblquad, deblank, deconv, deg2rad, detrend, deval, disp, dot,</code><br />
<code>eig, eigint, ellipj, ellipke, eps, erf, erfc, erfcinv, erfcx, erfi, erfinv,</code><br />
<code>    errorbar, expint, expm, eye, ezcontour, ezmesh, ezplot, ezpolar, ezsurf,</code><br />
<code>fact, fftshift, figure, findpeaks, findstr, flipdim, fliplr, flipud,</code><br />
<code>    fminbnd, fmincon, fminsearch, fminunc, fplot, fprintf, fsolve, fzero,</code><br />
<code>gammainc, gcd, geomean, gmres, gradient,</code><br />
<code>hadamard, hankel, harmmean, hilb, histc, humps, hypot,</code><br />
<code>idivide, ifft, ifftshift, inpolygon, integral, integral2, integral3,</code><br />
<code>    interp1, interp2, inv, isempty, isprime,</code><br />
<code>kron,</code><br />
<code>legendre, linprog, linspace, loglog, logm, logseq, logspace, lsqcurvefit,</code><br />
<code>    lsqlin, lsqnonlin, lsqnonneg, lu,</code><br />
<code>magic, meshgrid, mkpp, mldivide, mod, mrdivide,</code><br />
<code>nchoosek, ndims, nextpow2, nnz, normest, nthroot, null, num2str, numel,</code><br />
<code>ode23, ode23s, ones, or, orth,</code><br />
<code>pascal, pchip, pdist, pdist2, peaks, perms, piecewise, pinv, plotyy,</code><br />
<code>    pol2cart, polar, polyfit, polyint, polylog, polyval, pow2, ppval,</code><br />
<code>    primes, psi, pwd,</code><br />
<code>quad, quad2d, quadgk, quadl, quadprog, quadv, quiver,</code><br />
<code>rad2deg, randi, randn, randsample, rat, rats, regexp, regexpi,</code><br />
<code>    regexpreg, rem, repmat, roots, rosser, rot90, rref, runge,</code><br />
<code>sec, secd, sech, semilogx, semilogy, sinc, sind, size, sortrows, sph2cart,</code><br />
<code>    sqrtm, squareform, std, str2num, strcat, strcmp, strcmpi,</code><br />
<code>    strfind, strfindi, strjust, subspace,</code><br />
<code>tand, tic, toc, trapz, tril, trimmean, triplequad, triu,</code><br />
<code>vander, vectorfield, ver,</code><br />
<code>what, who, whos, wilkinson,</code><br />
<code>zeros, zeta</code>
</p>
<p>The following Matlab function names have been capitalized in &lsquo;pracma&rsquo; to
avoid shadowing functions from R base or one of its recommended packages
(on request of Bill Venables and because of Brian Ripley's CRAN policies):
</p>
<p><code>Diag, factos, finds, Fix, Imag, Lcm, Mode, Norm, nullspace (&lt;- null)</code>,<br />
<code>Poly, Rank, Real, Reshape, strRep, strTrim, Toeplitz, Trace, uniq (&lt;- unique).</code>
</p>
<p>To use &ldquo;ans&rdquo; instead of &ldquo;ans()&rdquo; &ndash; as is common practice in Matlab &ndash;
type (and similar for other Matlab commands):
</p>
<p><code>makeActiveBinding("ans", function() .Last.value, .GlobalEnv)</code><br />
<code>makeActiveBinding("who", who(), .GlobalEnv)</code>
</p>


<h3>Author(s)</h3>

<p>Hans Werner Borchers
</p>
<p>Maintainer: Hans W Borchers  &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Abramowitz, M., and I. A. Stegun (1972). Handbook of Mathematical Functions
(with Formulas, Graphs, and Mathematical Tables). Dover, New York.  
URL: https://www.math.ubc.ca/~cbm/aands/notes.htm
</p>
<p>Arndt, J. (2010). Matters Computational: Ideas, Algorithms, Source Code.
Springer-Verlag, Berlin Heidelberg Dordrecht.
FXT: a library of algorithms: <a href="https://www.jjj.de/fxt/">https://www.jjj.de/fxt/</a>.
</p>
<p>Cormen, Th. H., Ch. E. Leiserson, and R. L. Rivest (2009). Introduction
to Algorithms. Third Edition, The MIT Press, Cambridge, MA.
</p>
<p>Encyclopedia of Mathematics (2012). Editor-in-Chief: Ulf Rehmann.
<a href="https://encyclopediaofmath.org/wiki/Main_Page">https://encyclopediaofmath.org/wiki/Main_Page</a>.
</p>
<p>Gautschi, W. (1997). Numerical Analysis: An Introduction.
Birkhaeuser, Boston.
</p>
<p>Gentle, J. E. (2009). Computational Statistics.
Springer Science+Business Media LCC, New York.
</p>
<p>MathWorld.com (2011).
Matlab Central: <a href="https://www.mathworks.com/matlabcentral/">https://www.mathworks.com/matlabcentral/</a>.
</p>
<p>NIST: National Institute of Standards and Technology.
Olver, F. W. J., et al. (2010). NIST Handbook of Mathematical Functions.
Cambridge University Press. 
Internet: NIST Digital Library of Mathematical Functions, 
<a href="https://dlmf.nist.gov/">https://dlmf.nist.gov/</a>;
Guide to Available Mathematical Software, <a href="https://gams.nist.gov/">https://gams.nist.gov/</a>.
</p>
<p>Press, W. H., S. A. Teukolsky, W. T Vetterling, and B. P. Flannery (2007).
Numerical Recipes: The Art of Numerical Computing. Third Edition, incl.
Numerical Recipes Software, Cambridge University Press, New York.
URL: numerical.recipes/book/book.html.
</p>
<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>
<p>Skiena, St. S. (2008). The Algorithm Design Manual. Second Edition,
Springer-Verlag, London. The Stony Brook Algorithm Repository:
<a href="https://algorist.com/algorist.html">https://algorist.com/algorist.html</a>.
</p>
<p>Stoer, J., and R. Bulirsch (2002). Introduction to Numerical Analysis.
Third Edition, Springer-Verlag, New York.
</p>
<p>Strang, G. (2007). Computational Science and Engineering.
Wellesley-Cambridge Press.
</p>
<p>Weisstein, E. W. (2003). CRC Concise Encyclopedia of Mathematics.
Second Edition, Chapman &amp; Hall/CRC Press.
Wolfram MathWorld: <a href="https://mathworld.wolfram.com/">https://mathworld.wolfram.com/</a>.  
</p>
<p>Zhang, S., and J. Jin (1996). Computation of Special Functions.
John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p>The R package &lsquo;matlab&rsquo; contains some of the basic routines from Matlab,
but unfortunately not any of the higher math routines.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##  See examples in the help files for all functions.
    
## End(Not run)
</code></pre>

<hr>
<h2 id='abm3pc'>
Adams-Bashford-Moulton
</h2><span id='topic+abm3pc'></span>

<h3>Description</h3>

<p>Third-order Adams-Bashford-Moulton predictor-corrector method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abm3pc(f, a, b, y0, n = 50, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abm3pc_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y' = f(x, y)</code>.</p>
</td></tr>
<tr><td><code id="abm3pc_+3A_a">a</code>, <code id="abm3pc_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="abm3pc_+3A_y0">y0</code></td>
<td>
<p>starting values at point <code>a</code>.</p>
</td></tr>
<tr><td><code id="abm3pc_+3A_n">n</code></td>
<td>
<p>the number of steps from <code>a</code> to <code>b</code>.</p>
</td></tr>
<tr><td><code id="abm3pc_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Combined Adams-Bashford and Adams-Moulton (or: multi-step) method of
third order with corrections according to the predictor-corrector approach.
</p>


<h3>Value</h3>

<p>List with components <code>x</code> for grid points between <code>a</code> and <code>b</code>
and <code>y</code> a vector <code>y</code> the same length as <code>x</code>; additionally
an error estimation <code>est.error</code> that should be looked at with caution.
</p>


<h3>Note</h3>

<p>This function serves demonstration purposes only.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rk4">rk4</a></code>, <code><a href="#topic+ode23">ode23</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Attempt on a non-stiff equation
#   y' = y^2 - y^3, y(0) = d, 0 &lt;= t &lt;= 2/d, d = 0.01
f &lt;- function(t, y) y^2 - y^3
d &lt;- 1/250
abm1 &lt;- abm3pc(f, 0, 2/d, d, n = 1/d)
abm2 &lt;- abm3pc(f, 0, 2/d, d, n = 2/d)
## Not run: 
plot(abm1$x, abm1$y, type = "l", col = "blue")
lines(abm2$x, abm2$y, type = "l", col = "red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='accumarray'>
Accumulate Vector Elements
</h2><span id='topic+accumarray'></span><span id='topic+uniq'></span>

<h3>Description</h3>

<p><code>accumarray</code> groups elements from a data set and applies a function
to each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accumarray(subs, val, sz = NULL, func = sum, fillval = 0)

uniq(a, first = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accumarray_+3A_subs">subs</code></td>
<td>
<p>vector or matrix of positive integers,
used as indices for the result vector.</p>
</td></tr>
<tr><td><code id="accumarray_+3A_val">val</code></td>
<td>
<p>numerical vector.</p>
</td></tr>
<tr><td><code id="accumarray_+3A_sz">sz</code></td>
<td>
<p>size of the resulting array.</p>
</td></tr>
<tr><td><code id="accumarray_+3A_func">func</code></td>
<td>
<p>function to be applied to a vector of numbers.</p>
</td></tr>
<tr><td><code id="accumarray_+3A_fillval">fillval</code></td>
<td>
<p>value used to fill the array when there are no indices
pointing to that component.</p>
</td></tr>
<tr><td><code id="accumarray_+3A_a">a</code></td>
<td>
<p>numerical vector.</p>
</td></tr>
<tr><td><code id="accumarray_+3A_first">first</code></td>
<td>
<p>logical, shall the first or last element encountered be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>A &lt;- accumarray(subs, val)</code> creates an array <code>A</code> by accumulating
elements of the vector <code>val</code> using the lines of <code>subs</code> as indices
and applying <code>func</code> to that accumulated vector. The size of the array
can be predetermined by the size vector <code>sz</code>.
</p>
<p><code>A = uniq(a)</code> returns a vector <code>b</code> identical to <code>unique(a)</code>
and two other vectors of indices <code>m</code> and <code>n</code> such that
<code>b == a[m]</code> and <code>a == b[n]</code>.
</p>


<h3>Value</h3>

<p><code>accumarray</code> returns an array of size the maximum in each column of 
<code>subs</code>, or by <code>sz</code>.
</p>
<p><code>uniq</code> returns a list with components
</p>
<table>
<tr><td><code>b</code></td>
<td>
<p>vector of unique elements of a.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>vector of indices such that <code>b = a[m]</code></p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>vector of indices such that <code>a = b[n]</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Matlab function <code>accumarray</code> can also handle sparse matrices.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+unique">unique</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Examples for accumarray
val = 101:105
subs = as.matrix(c(1, 2, 4, 2, 4))
accumarray(subs, val)
# [101; 206; 0; 208]

val = 101:105
subs &lt;- matrix(c(1,2,2,2,2, 1,1,3,1,3, 1,2,2,2,2), ncol = 3)
accumarray(subs, val)
# , , 1
# [,1] [,2] [,3]
# [1,]  101    0    0
# [2,]    0    0    0
# , , 2
# [,1] [,2] [,3]
# [1,]    0    0    0
# [2,]  206    0  208

val = 101:106
subs &lt;- matrix(c(1, 2, 1, 2, 3, 1, 4, 1, 4, 4, 4, 1), ncol = 2, byrow = TRUE)
accumarray(subs, val, func = function(x) sum(diff(x)))
# [,1] [,2] [,3] [,4]
# [1,]    0    1    0    0
# [2,]    0    0    0    0
# [3,]    0    0    0    0
# [4,]    2    0    0    0

val = 101:105
subs = matrix(c(1, 1, 2, 1, 2, 3, 2, 1, 2, 3), ncol = 2, byrow = TRUE)
accumarray(subs, val, sz = c(3, 3), func = max, fillval = NA)
# [,1] [,2] [,3]
# [1,]  101   NA   NA
# [2,]  104   NA  105
# [3,]   NA   NA   NA

##  Examples for uniq
a &lt;- c(1, 1, 5, 6, 2, 3, 3, 9, 8, 6, 2, 4)
A &lt;- uniq(a); A
# A$b  1  5  6  2  3  9  8  4
# A$m  2  3 10 11  7  8  9 12
# A$n  1  1  2  3  4  5  5  6  7  3  4  8
A &lt;- uniq(a, first = TRUE); A
# A$m  1  3  4  5  6  8  9 12

##  Example: Subset sum problem
# Distribution of unique sums among all combinations of a vectors.
allsums &lt;- function(a) {
    S &lt;- c(); C &lt;- c()
    for (k in 1:length(a)) {
        U &lt;- uniq(c(S, a[k], S + a[k]))
        S &lt;- U$b
        C &lt;- accumarray(U$n, c(C, 1, C))
    }
    o &lt;- order(S); S &lt;- S[o]; C &lt;- C[o]
    return(list(S = S, C = C))
}
A &lt;- allsums(seq(1, 9, by=2)); A
# A$S  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24 25
# A$C  1  1  1  1  1  1  2  2  2  1  2  2  1  2  2  2  1  1  1  1  1  1  1
</code></pre>

<hr>
<h2 id='agmean'>
Arithmetic-geometric Mean
</h2><span id='topic+agmean'></span>

<h3>Description</h3>

<p>The arithmetic-geometric mean of real or complex numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agmean(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="agmean_+3A_a">a</code>, <code id="agmean_+3A_b">b</code></td>
<td>
<p>vectors of real or complex numbers of the same length (or scalars).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arithmetic-geometric mean is defined as the common limit of the two
sequences <code class="reqn">a_{n+1} = (a_n + b_n)/2</code> and <code class="reqn">b_{n+1} = \sqrt(a_n b_n)</code>.
</p>
<p>When used for negative or complex numbers, the complex square root function
is applied.
</p>


<h3>Value</h3>

<p>Returns a list with compoinents: <code>agm</code> a vector of arithmetic-geometric 
means, component-wise, <code>niter</code> the number of iterations, and <code>prec</code>
the overall estimated precision.
</p>


<h3>Note</h3>

<p>Gauss discovered that elliptic integrals can be effectively computed via
the arithmetic-geometric mean (see example below), for example:
</p>
<p style="text-align: center;"><code class="reqn">\int_0^{\pi/2} \frac{dt}{\sqrt{1 - m^2 sin^2(t)}}  = \frac{(a+b) \pi}{4 \cdot agm(a,b)}</code>
</p>

<p>where <code class="reqn">m = (a-b)/(a+b)</code>
</p>


<h3>References</h3>

<p><a href="https://mathworld.wolfram.com/Arithmetic-GeometricMean.html">https://mathworld.wolfram.com/Arithmetic-GeometricMean.html</a>
</p>


<h3>See Also</h3>

<p>Arithmetic, geometric, and harmonic mean.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Accuracy test: Gauss constant
1/agmean(1, sqrt(2))$agm - 0.834626841674073186  # 1.11e-16 &lt; eps = 2.22e-16

## Gauss' AGM-based computation of \pi
a &lt;- 1.0
b &lt;- 1.0/sqrt(2)
s &lt;- 0.5
d &lt;- 1L
while (abs(a-b) &gt; eps()) {
    t &lt;- a
    a &lt;- (a + b)*0.5
    b &lt;- sqrt(t*b)
    c &lt;- (a-t)*(a-t)
    d &lt;- 2L * d
    s &lt;- s - d*c
}
approx_pi &lt;- (a+b)^2 / s / 2.0
abs(approx_pi - pi)             # 8.881784e-16 in 4 iterations

##  Example: Approximate elliptic integral
N &lt;- 20
m &lt;- seq(0, 1, len = N+1)[1:N]
E &lt;- numeric(N)
for (i in 1:N) {
    f &lt;- function(t) 1/sqrt(1 - m[i]^2 * sin(t)^2)
    E[i] &lt;- quad(f, 0, pi/2)
}
A &lt;- numeric(2*N-1)
a &lt;- 1
b &lt;- a * (1-m) / (m+1)

## Not run: 
plot(m, E, main = "Elliptic Integrals vs. arith.-geom. Mean")
lines(m, (a+b)*pi / 4 / agmean(a, b)$agm, col="blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='aitken'>
Aitken' Method
</h2><span id='topic+aitken'></span>

<h3>Description</h3>

<p>Aitken's acceleration method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aitken(f, x0, nmax = 12, tol = 1e-8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aitken_+3A_f">f</code></td>
<td>
<p>Function with a fixpoint.</p>
</td></tr>
<tr><td><code id="aitken_+3A_x0">x0</code></td>
<td>
<p>Starting value.</p>
</td></tr>
<tr><td><code id="aitken_+3A_nmax">nmax</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="aitken_+3A_tol">tol</code></td>
<td>
<p>Relative tolerance.</p>
</td></tr>
<tr><td><code id="aitken_+3A_...">...</code></td>
<td>
<p>Additional variables passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Aitken's acceleration method, or delta-squared process, is used for
accelerating the rate of convergence of a sequence (from linear to
quadratic), here applied to the fixed point iteration scheme of a
function.
</p>


<h3>Value</h3>

<p>The fixpoint (as found so far).
</p>


<h3>Note</h3>

<p>Sometimes used to accerate Newton-Raphson (Steffensen's method).
</p>


<h3>References</h3>

<p>Quarteroni, A., and F. Saleri (2006). Scientific Computing with Matlab
and Octave. Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lambertWp">lambertWp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Find a zero of    f(x) = cos(x) - x*exp(x)
# as fixpoint of  phi(x) = x + (cos(x) - x*exp(x))/2
phi &lt;- function(x) x + (cos(x) - x*exp(x))/2
aitken(phi, 0)  #=&gt; 0.5177574
</code></pre>

<hr>
<h2 id='akimaInterp'>
Univariate Akima Interpolation
</h2><span id='topic+akimaInterp'></span>

<h3>Description</h3>

<p>Interpolate smooth curve through given points on a plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  akimaInterp(x, y, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="akimaInterp_+3A_x">x</code>, <code id="akimaInterp_+3A_y">y</code></td>
<td>
<p>x/y-coordinates of (irregular) grid points defining the curve.</p>
</td></tr>
<tr><td><code id="akimaInterp_+3A_xi">xi</code></td>
<td>
<p>x-coordinates of points where to interpolate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implementation of Akima's univariate interpolation method, built from
piecewise third order polynomials. There is no need to solve large systems
of equations, and the method is therefore computationally very efficient.
</p>


<h3>Value</h3>

<p>Returns the interpolated values at the points <code>xi</code> as a vector.
</p>


<h3>Note</h3>

<p>There is also a 2-dimensional version in package &lsquo;akima&rsquo;.
</p>


<h3>Author(s)</h3>

<p>Matlab code by H. Shamsundar under BSC License; re-implementation in R
by Hans W Borchers.
</p>


<h3>References</h3>

<p>Akima, H. (1970). A New Method of Interpolation and Smooth Curve Fitting
Based on Local Procedures. Journal of the ACM, Vol. 17(4), pp 589-602.
</p>
<p>Hyman, J. (1983). Accurate Monotonicity Preserving Cubic Interpolation.
SIAM J. Sci. Stat. Comput., Vol. 4(4), pp. 645-654.
</p>
<p>Akima, H. (1996). Algorithm 760: Rectangular-Grid-Data Surface Fitting that
Has the Accurancy of a Bicubic Polynomial. ACM TOMS Vol. 22(3), pp. 357-361.
</p>
<p>Akima, H. (1996). Algorithm 761: Scattered-Data Surface Fitting that
Has the Accuracy of a Cubic Polynomial. ACM TOMS, Vol. 22(3), pp. 362-371.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kriging">kriging</a></code>, <code>akima::aspline</code>, <code>akima::interp</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c( 0,  2,  3,  5,  6,  8,  9,   11, 12, 14, 15)
y &lt;- c(10, 10, 10, 10, 10, 10, 10.5, 15, 50, 60, 85)
xs &lt;- seq(12, 14, 0.5)          # 12.0 12.5     13.0     13.5     14.0
ys &lt;- akimaInterp(x, y, xs)     # 50.0 54.57405 54.84360 55.19135 60.0
xs; ys

## Not run: 
plot(x, y, col="blue", main = "Akima Interpolation")
xi &lt;- linspace(0,15,51)
yi &lt;- akimaInterp(x, y, xi)
lines(xi, yi, col = "darkred")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='and+2C+20or'>
Logical AND, OR (Matlab Style)
</h2><span id='topic+and'></span><span id='topic+or'></span>

<h3>Description</h3>

<p><code>and(l, k)</code> resp. <code>or(l, k)</code> the same as <code>(l &amp; k) + 0</code> resp.
<code>(l | k) + 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>and(l, k)
or(l, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="and+2B2C+2B20or_+3A_l">l</code>, <code id="and+2B2C+2B20or_+3A_k">k</code></td>
<td>
<p>Arrays.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Performs a logical operation of arrays <code>l</code> and <code>k</code> and returns an
array containing elements set to either 1 (<code>TRUE</code>) or 0 (<code>FALSE</code>),
that is in Matlab style.
</p>


<h3>Value</h3>

<p>Logical vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(0.5,  0.5,  0,    0.75, 0,
              0.5,  0,    0.75, 0.05, 0.85,
              0.35, 0,    0,    0,    0.01,
              0.5,  0.65, 0.65, 0.05, 0), 4, 5, byrow=TRUE)
B &lt;- matrix(c( 0, 1, 0, 1, 0,
               1, 1, 1, 0, 1,
               0, 1, 1, 1, 0,
               0, 1, 0, 0, 1), 4, 5, byrow=TRUE)

and(A, B)
or(A, B)
</code></pre>

<hr>
<h2 id='andrewsplot'>
Andrews' Curves
</h2><span id='topic+andrewsplot'></span>

<h3>Description</h3>

<p>Plots Andrews' curves in cartesian or polar coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>andrewsplot(A, f, style = "pol", scaled = FALSE, npts = 101)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="andrewsplot_+3A_a">A</code></td>
<td>
<p>numeric matrix with at least two columns.</p>
</td></tr>
<tr><td><code id="andrewsplot_+3A_f">f</code></td>
<td>
<p>factor or integer vector with <code>nrow(A)</code> elements.</p>
</td></tr>
<tr><td><code id="andrewsplot_+3A_style">style</code></td>
<td>
<p>character variable, only possible values &lsquo;cart&rsquo; or &lsquo;pol&rsquo;.</p>
</td></tr>
<tr><td><code id="andrewsplot_+3A_scaled">scaled</code></td>
<td>
<p>logical; if true scales each column to have mean 0 and
standard deviation 1 (not yet implemented).</p>
</td></tr>
<tr><td><code id="andrewsplot_+3A_npts">npts</code></td>
<td>
<p>number of points to plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>andrewsplot</code> creates an Andrews plot of the multivariate data in the
matrix <code>A</code>, assigning different colors according to the factor or
integer vector <code>f</code>.
</p>
<p>Andrews' plot represent each observation (row) by a periodic function over
the interval <code>[0, 2*pi]</code>. This function for the <code>i</code>-th observation
is defined as ...
</p>
<p>The plot can be seen in cartesian or polar coordinates &mdash; the latter seems
appropriate as all these functions are periodic.
</p>


<h3>Value</h3>

<p>Generates a plot, no return value.
</p>


<h3>Note</h3>

<p>Please note that a different ordering of the columns will result in quite
different functions and overall picture.
</p>
<p>There are variants utilizing principal component scores, in order of
decreasing eigenvalues.
</p>


<h3>References</h3>

<p>R. Khattree and D. N. Naik (2002). Andrews PLots for Multivariate Data:
Some New Suggestions and Applications. Journal of Statistical Planning
and Inference, Vol. 100, No. 2, pp. 411&ndash;425.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polar">polar</a></code>, <code>andrews::andrews</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
s &lt;- sample(1:4, 4)
A &lt;- as.matrix(iris[, s])
f &lt;- as.integer(iris[, 5])
andrewsplot(A, f, style = "pol")

## End(Not run)
</code></pre>

<hr>
<h2 id='angle'>Basic Complex Functions</h2><span id='topic+Real'></span><span id='topic+Imag'></span><span id='topic+angle'></span>

<h3>Description</h3>

<p>Basic complex functions (Matlab style)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Real(z)
Imag(z)
angle(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="angle_+3A_z">z</code></td>
<td>
<p>Vector or matrix of real or complex numbers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are just Matlab names for the corresponding functions in R. The
<code>angle</code> function is simply defined as <code>atan2(Im(z), Re(z))</code>.
</p>


<h3>Value</h3>

<p>returning real or complex values; <code>angle</code> returns in radians.
</p>


<h3>Note</h3>

<p>The true Matlab names are <code>real</code>, <code>imag</code>, and <code>conj</code>, but as
<code>real</code> was taken in R, all these beginnings are changed to capitals.
</p>
<p>The function <code>Mod</code> has no special name in Matlab;
use <code>abs()</code> instead.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Mod">Mod</a></code>, <code><a href="base.html#topic+abs">abs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z &lt;- c(0, 1, 1+1i, 1i)
Real(z)   # Re(z)
Imag(z)   # Im(z)
Conj(z)   # Conj(z)
abs(z)    # Mod(z)
angle(z)
</code></pre>

<hr>
<h2 id='anms'>
Adaptive Nelder-Mead Minimization
</h2><span id='topic+anms'></span>

<h3>Description</h3>

<p>An implementation of the Nelder-Mead algorithm for derivative-free
optimization / function minimization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anms(fn, x0, ...,
     tol = 1e-10, maxfeval = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anms_+3A_fn">fn</code></td>
<td>
<p>nonlinear function to be minimized.</p>
</td></tr>
<tr><td><code id="anms_+3A_x0">x0</code></td>
<td>
<p>starting vector.</p>
</td></tr>
<tr><td><code id="anms_+3A_tol">tol</code></td>
<td>
<p>relative tolerance, to be used as stopping rule.</p>
</td></tr>
<tr><td><code id="anms_+3A_maxfeval">maxfeval</code></td>
<td>
<p>maximum number of function calls.</p>
</td></tr>
<tr><td><code id="anms_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also called a &lsquo;simplex&rsquo; method for finding the local minimum of a function
of several variables. The method is a pattern search that compares function
values at the vertices of the simplex. The process generates a sequence of
simplices with ever reducing sizes.
</p>
<p><code>anms</code> can be used up to 20 or 30 dimensions (then &lsquo;tol&rsquo; and &lsquo;maxfeval&rsquo;
need to be increased). It applies adaptive parameters for simplicial search, 
depending on the problem dimension &ndash; see Fuchang and Lixing (2012).
</p>
<p>With upper and/or lower bounds, <code>anms</code> will apply a transformation of
bounded to unbounded regions before utilizing Nelder-Mead. Of course, if the
optimum is near to the boundary, results will not be as accurate as when the
minimum is in the interior.
</p>


<h3>Value</h3>

<p>List with following components:
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>minimum solution found.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>value of <code>f</code> at minimum.</p>
</td></tr>
<tr><td><code>nfeval</code></td>
<td>
<p>number of function calls performed.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Copyright (c) 2012 by F. Gao and L. Han, implemented in Matlab with a
permissive license. Implemented in R by Hans W. Borchers. For another
elaborate implementation of Nelder-Mead see the package &lsquo;dfoptim&rsquo;.
</p>


<h3>References</h3>

<p>Nelder, J., and R. Mead (1965). A simplex method for function minimization.
Computer Journal, Volume 7, pp. 308-313.
</p>
<p>O'Neill, R. (1971). Algorithm AS 47: Function Minimization Using a Simplex 
Procedure. Applied Statistics, Volume 20(3), pp. 338-345.
</p>
<p>J. C. Lagarias et al. (1998). Convergence properties of the Nelder-Mead
simplex method in low dimensions. SIAM Journal for Optimization, Vol. 9,
No. 1, pp 112-147.
</p>
<p>Fuchang Gao and Lixing Han (2012). Implementing the Nelder-Mead simplex
algorithm with adaptive parameters. Computational Optimization and
Applications, Vol. 51, No. 1, pp. 259-277.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Rosenbrock function
rosenbrock &lt;- function(x) {
    n &lt;- length(x)
    x1 &lt;- x[2:n]
    x2 &lt;- x[1:(n-1)]
    sum(100*(x1-x2^2)^2 + (1-x2)^2)
}

anms(rosenbrock, c(0,0,0,0,0))
# $xmin
# [1] 1 1 1 1 1
# $fmin
# [1] 8.268732e-21
# $nfeval
# [1] 1153

# To add constraints to the optimization problem, use a slightly 
# modified objective function. Equality constraints not possible.
# Warning: Avoid a starting value too near to the boundary !

## Not run: 
# Example: 0.0 &lt;= x &lt;= 0.5
fun &lt;- function(x) {
    if (any(x &lt; 0) || any(x &gt; 0.5)) 100
    else rosenbrock(x)
}
x0 &lt;- rep(0.1, 5)

anms(fun, x0)
## $xmin
## [1] 0.500000000 0.263051265 0.079972922 0.016228138 0.000267922
## End(Not run)
</code></pre>

<hr>
<h2 id='approx_entropy'>
Approximate and Sample Entropy
</h2><span id='topic+approx_entropy'></span><span id='topic+sample_entropy'></span>

<h3>Description</h3>

<p>Calculates the approximate or sample entropy of a time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>approx_entropy(ts, edim = 2, r = 0.2*sd(ts), elag = 1)

sample_entropy(ts, edim = 2, r = 0.2*sd(ts), tau = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="approx_entropy_+3A_ts">ts</code></td>
<td>
<p>a time series.</p>
</td></tr>
<tr><td><code id="approx_entropy_+3A_edim">edim</code></td>
<td>
<p>the embedding dimension, as for chaotic time series;
a preferred value is 2.</p>
</td></tr>
<tr><td><code id="approx_entropy_+3A_r">r</code></td>
<td>
<p>filter factor; work on heart rate variability has suggested
setting r to be 0.2 times the standard deviation of the data.</p>
</td></tr>
<tr><td><code id="approx_entropy_+3A_elag">elag</code></td>
<td>
<p>embedding lag; defaults to 1, more appropriately it should be
set to the smallest lag at which the autocorrelation function
of the time series is close to zero.
(At the moment it cannot be changed by the user.)</p>
</td></tr>
<tr><td><code id="approx_entropy_+3A_tau">tau</code></td>
<td>
<p>delay time for subsampling, similar to <code>elag</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximate entropy was introduced to quantify the the amount of
regularity and the unpredictability of fluctuations in a time series.
A low value of the entropy indicates that the time series is deterministic;
a high value indicates randomness.
</p>
<p>Sample entropy is conceptually similar with the following differences:
It does not count self-matching, and it does not depend that much on the
length of the time series.
</p>


<h3>Value</h3>

<p>The approximate, or sample, entropy, a scalar value.
</p>


<h3>Note</h3>

<p>This code here derives from Matlab versions at Mathwork's File Exchange,
&ldquo;Fast Approximate Entropy&rdquo; and &ldquo;Sample Entropy&rdquo; by Kijoon Lee under
BSD license.
</p>


<h3>References</h3>

<p>Pincus, S.M. (1991). Approximate entropy as a measure of system complexity.
Proc. Natl. Acad. Sci. USA, Vol. 88, pp. 2297&ndash;2301.
</p>
<p>Kaplan, D., M. I. Furman, S. M. Pincus, S. M. Ryan, L. A. Lipsitz, and
A. L. Goldberger (1991). Aging and the complexity of cardiovascular
dynamics, Biophysics Journal, Vol. 59, pp. 945&ndash;949.
</p>
<p>Yentes, J.M., N. Hunt, K.K. Schmid, J.P. Kaipust, D. McGrath, N. Stergiou
(2012). The Appropriate use of approximate entropy and sample entropy with
short data sets. Ann. Biomed. Eng.
</p>


<h3>See Also</h3>

<p><code>RHRV::CalculateApEn</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ts &lt;- rep(61:65, 10)
approx_entropy(ts, edim = 2)                      # -0.0004610253
sample_entropy(ts, edim = 2)                      #  0

set.seed(8237)
approx_entropy(rnorm(500), edim = 2)              # 1.351439  high, random
approx_entropy(sin(seq(1,100,by=0.2)), edim = 2)  # 0.171806  low,  deterministic
sample_entropy(sin(seq(1,100,by=0.2)), edim = 2)  # 0.2359326

## Not run: (Careful: This will take several minutes.)
# generate simulated data
N &lt;- 1000; t &lt;- 0.001*(1:N)
sint   &lt;- sin(2*pi*10*t);    sd1 &lt;- sd(sint)    # sine curve
whitet &lt;- rnorm(N);          sd2 &lt;- sd(whitet)  # white noise
chirpt &lt;- sint + 0.1*whitet; sd3 &lt;- sd(chirpt)  # chirp signal

# calculate approximate entropy
rnum &lt;- 30; result &lt;- zeros(3, rnum)
for (i in 1:rnum) {
    r &lt;- 0.02 * i
    result[1, i] &lt;- approx_entropy(sint,   2, r*sd1)
    result[2, i] &lt;- approx_entropy(chirpt, 2, r*sd2)
    result[3, i] &lt;- approx_entropy(whitet, 2, r*sd3)
}

# plot curves
r &lt;- 0.02 * (1:rnum)
plot(c(0, 0.6), c(0, 2), type="n",
     xlab = "", ylab = "", main = "Approximate Entropy")
points(r, result[1, ], col="red");    lines(r, result[1, ], col="red")
points(r, result[2, ], col="green");  lines(r, result[2, ], col="green")
points(r, result[3, ], col="blue");   lines(r, result[3, ], col="blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='arclength'>
Arc Length of a Curve
</h2><span id='topic+arclength'></span>

<h3>Description</h3>

<p>Calculates the arc length of a parametrized curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arclength(f, a, b, nmax = 20, tol = 1e-05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arclength_+3A_f">f</code></td>
<td>
<p>parametrization of a curve in n-dim. space.</p>
</td></tr>
<tr><td><code id="arclength_+3A_a">a</code>, <code id="arclength_+3A_b">b</code></td>
<td>
<p>begin and end of the parameter interval.</p>
</td></tr>
<tr><td><code id="arclength_+3A_nmax">nmax</code></td>
<td>
<p>maximal number of iterations.</p>
</td></tr>
<tr><td><code id="arclength_+3A_tol">tol</code></td>
<td>
<p>relative tolerance requested.</p>
</td></tr>
<tr><td><code id="arclength_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the arc length of a parametrized curve in <code>R^n</code>. It applies
Richardson's extrapolation by refining polygon approximations to the curve.
</p>
<p>The parametrization of the curve must be vectorized:
if <code>t--&gt;F(t)</code> is the parametrization, <code>F(c(t1,t1,...))</code> must
return <code>c(F(t1),F(t2),...)</code>.
</p>
<p>Can be directly applied to determine the arc length of a one-dimensional 
function <code>f:R--&gt;R</code> by defining <code>F</code> (if <code>f</code> is vectorized)
as <code>F:t--&gt;c(t,f(t))</code>.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>length</code> the calculated arc length,
<code>niter</code> the number of iterations, and <code>rel.err</code> the relative
error generated from the extrapolation.
</p>


<h3>Note</h3>

<p>If by chance certain equidistant points of the curve lie on a straight line,
the result may be wrong, then use <code>polylength</code> below.
</p>


<h3>Author(s)</h3>

<p>HwB &lt;hwborchers@googlemail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poly_length">poly_length</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example: parametrized 3D-curve with t in 0..3*pi
f &lt;- function(t) c(sin(2*t), cos(t), t)
arclength(f, 0, 3*pi)
# $length:  17.22203            # true length 17.222032...

##  Example: length of the sine curve
f &lt;- function(t) c(t, sin(t))
arclength(f, 0, pi)             # true length  3.82019...

## Example: Length of an ellipse with axes a = 1 and b = 0.5
# parametrization x = a*cos(t), y = b*sin(t)
a &lt;- 1.0; b &lt;- 0.5
f &lt;- function(t) c(a*cos(t), b*sin(t))
L &lt;- arclength(f, 0, 2*pi, tol = 1e-10)     #=&gt; 4.84422411027
# compare with elliptic integral of the second kind
e &lt;- sqrt(1 - b^2/a^2)                      # ellipticity
L &lt;- 4 * a * ellipke(e^2)$e                 #=&gt; 4.84422411027

## Not run: 
##  Example: oscillating 1-dimensional function (from 0 to 5)
f &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
F &lt;- function(t) c(t, f(t))
L &lt;- arclength(F, 0, 5, tol = 1e-12, nmax = 25)
print(L$length, digits = 16)
# [1] 82.81020372882217         # true length 82.810203728822172...

# Split this computation in 10 steps (run time drops from 2 to 0.2 secs)
L &lt;- 0
for (i in 1:10)
	L &lt;- L + arclength(F, (i-1)*0.5, i*0.5, tol = 1e-10)$length
print(L, digits = 16)
# [1] 82.81020372882216

# Alternative calculation of arc length
f1 &lt;- function(x) sqrt(1 + complexstep(f, x)^2)
L1 &lt;- quadgk(f1, 0, 5, tol = 1e-14)
print(L1, digits = 16)
# [1] 82.81020372882216
  
## End(Not run)

## Not run: 
#-- --------------------------------------------------------------------
#   Arc-length parametrization of Fermat's spiral
#-- --------------------------------------------------------------------
# Fermat's spiral: r = a * sqrt(t) 
f &lt;- function(t) 0.25 * sqrt(t) * c(cos(t), sin(t))

t1 &lt;- 0; t2 &lt;- 6*pi
a  &lt;- 0; b  &lt;- arclength(f, t1, t2)$length
fParam &lt;- function(w) {
    fct &lt;- function(u) arclength(f, a, u)$length - w
    urt &lt;- uniroot(fct, c(a, 6*pi))
    urt$root
}

ts &lt;- linspace(0, 6*pi, 250)
plot(matrix(f(ts), ncol=2), type='l', col="blue", 
     asp=1, xlab="", ylab = "",
     main = "Fermat's Spiral", sub="20 subparts of equal length")

for (i in seq(0.05, 0.95, by=0.05)) {
    v &lt;- fParam(i*b); fv &lt;- f(v)
    points(fv[1], f(v)[2], col="darkred", pch=20)
} 
## End(Not run)
</code></pre>

<hr>
<h2 id='arnoldi'>Arnoldi Iteration</h2><span id='topic+arnoldi'></span>

<h3>Description</h3>

<p>Arnoldi iteration generates an orthonormal basis of the Krylov space
and a Hessenberg matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arnoldi(A, q, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arnoldi_+3A_a">A</code></td>
<td>
<p>a square n-by-n matrix.</p>
</td></tr>
<tr><td><code id="arnoldi_+3A_q">q</code></td>
<td>
<p>a vector of length n.</p>
</td></tr>
<tr><td><code id="arnoldi_+3A_m">m</code></td>
<td>
<p>an integer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>arnoldi(A, q, m)</code> carries out <code>m</code> iterations of the
Arnoldi iteration with n-by-n matrix <code>A</code> and starting vector
<code>q</code> (which need not have unit 2-norm). For <code>m &lt; n</code> it 
produces an n-by-(m+1) matrix <code>Q</code> with orthonormal columns
and an (m+1)-by-m upper Hessenberg matrix <code>H</code> such that
<code>A*Q[,1:m] = Q[,1:m]*H[1:m,1:m] + H[m+1,m]*Q[,m+1]*t(E_m)</code>,
where <code>E_m</code> is the m-th column of the m-by-m identity matrix.
</p>


<h3>Value</h3>

<p>Returns a list with two elements:
</p>
<p><code>Q</code> A matrix of orthonormal columns that generate the Krylov
space <code>(A, A q, A^2 q, ...)</code>.
</p>
<p><code>H</code> A Hessenberg matrix such that <code>A = Q * H * t(Q)</code>.
</p>


<h3>References</h3>

<p>Nicholas J. Higham (2008). Functions of Matrices: Theory and 
Computation, SIAM, Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hessenberg">hessenberg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(-149,   -50,  -154,
               537,   180,   546,
               -27,    -9,   -25), nrow = 3, byrow = TRUE)
a &lt;- arnoldi(A, c(1,0,0))
a
## $Q
##      [,1]       [,2]       [,3]
## [1,]    1  0.0000000  0.0000000
## [2,]    0  0.9987384 -0.0502159
## [3,]    0 -0.0502159 -0.9987384
## 
## $H
##           [,1]         [,2]        [,3]
## [1,] -149.0000 -42.20367124  156.316506
## [2,]  537.6783 152.55114875 -554.927153
## [3,]    0.0000   0.07284727    2.448851

a$Q %*% a$H %*% t(a$Q)
##      [,1] [,2] [,3]
## [1,] -149  -50 -154
## [2,]  537  180  546
## [3,]  -27   -9  -25
</code></pre>

<hr>
<h2 id='barylag'>Barycentric Lagrange Interpolation</h2><span id='topic+barylag'></span>

<h3>Description</h3>

<p>Barycentric Lagrange interpolation in one dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>barylag(xi, yi, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="barylag_+3A_xi">xi</code>, <code id="barylag_+3A_yi">yi</code></td>
<td>
<p>x- and y-coordinates of supporting nodes.</p>
</td></tr>
<tr><td><code id="barylag_+3A_x">x</code></td>
<td>
<p>x-coordinates of interpolation points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>barylag</code> interpolates the given data using the barycentric
Lagrange interpolation formula (vectorized to remove all loops).
</p>


<h3>Value</h3>

<p>Values of interpolated data at points <code>x</code>.
</p>


<h3>Note</h3>

<p>Barycentric interpolation is preferred because of its numerical stability.
</p>


<h3>References</h3>

<p>Berrut, J.-P., and L. Nick Trefethen (2004). &ldquo;Barycentric Lagrange
Interpolation&rdquo;. SIAM Review, Vol. 46(3), pp.501&ndash;517.
</p>


<h3>See Also</h3>

<p>Lagrange or Newton interpolation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Generates an example with plot.
# Input:
#   fun  ---  function that shall be 'approximated'
#   a, b ---  interval [a, b] to be used for the example
#   n    ---  number of supporting nodes
#   m    ---  number of interpolation points
# Output
#   plot of function, interpolation, and nodes
#   return value is NULL (invisible)
## Not run: 
barycentricExample &lt;- function(fun, a, b, n, m)
{
	xi &lt;- seq(a, b, len=n)
	yi &lt;- fun(xi)
	x  &lt;- seq(a, b, len=m)

	y &lt;- barylag(xi, yi, x)
	plot(xi, yi, col="red", xlab="x", ylab="y",
		main="Example of barycentric interpolation")

	lines(x, fun(x), col="yellow", lwd=2)
	lines(x, y, col="darkred")

	grid()
}

barycentricExample(sin, -pi, pi, 11, 101)  # good interpolation
barycentricExample(runge, -1, 1, 21, 101)  # bad interpolation

## End(Not run)
</code></pre>

<hr>
<h2 id='barylag2d'>2-D Barycentric Lagrange Interpolation</h2><span id='topic+barylag2d'></span>

<h3>Description</h3>

<p>Two-dimensional barycentric Lagrange interpolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>barylag2d(F, xn, yn, xf, yf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="barylag2d_+3A_f">F</code></td>
<td>
<p>matrix representing values of a function in two dimensions.</p>
</td></tr>
<tr><td><code id="barylag2d_+3A_xn">xn</code>, <code id="barylag2d_+3A_yn">yn</code></td>
<td>
<p>x- and y-coordinates of supporting nodes.</p>
</td></tr>
<tr><td><code id="barylag2d_+3A_xf">xf</code>, <code id="barylag2d_+3A_yf">yf</code></td>
<td>
<p>x- and y-coordinates of an interpolating grid..</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Well-known Lagrange interpolation using barycentric coordinates, here
extended to two dimensions. The function is completely vectorized.
</p>
<p>x-coordinates run downwards in F, y-coordinates to the right. That conforms
to the usage in image or contour plots, see the example below.
</p>


<h3>Value</h3>

<p>Matrix of size <code>length(xf)</code>-by-<code>length(yf)</code> giving the interpolated
values at al the grid points <code>(xf, yf)</code>.
</p>


<h3>Note</h3>

<p>Copyright (c) 2004 Greg von Winckel of a Matlab function under BSD license;
translation to R by Hans W Borchers with permission.
</p>


<h3>References</h3>

<p>Berrut, J.-P., and L. Nick Trefethen (2004). &ldquo;Barycentric Lagrange
Interpolation&rdquo;. SIAM Review, Vol. 46(3), pp.501&ndash;517.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+interp2">interp2</a></code>, <code><a href="#topic+barylag">barylag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example from R-help
xn &lt;- c(4.05, 4.10, 4.15, 4.20, 4.25, 4.30, 4.35)
yn &lt;- c(60.0, 67.5, 75.0, 82.5, 90.0)
foo &lt;- matrix(c(
        -137.8379, -158.8240, -165.4389, -166.4026, -166.2593,
        -152.1720, -167.3145, -171.1368, -170.9200, -170.4605,
        -162.2264, -172.5862, -174.1460, -172.9923, -172.2861,
        -168.7746, -175.2218, -174.9667, -173.0803, -172.1853,
        -172.4453, -175.7163, -174.0223, -171.5739, -170.5384,
        -173.7736, -174.4891, -171.6713, -168.8025, -167.6662,
        -173.2124, -171.8940, -168.2149, -165.0431, -163.8390),
            nrow = 7, ncol = 5, byrow = TRUE)
xf &lt;- c(4.075, 4.1)
yf &lt;- c(63.75, 67.25)
barylag2d(foo, xn, yn, xf, yf)
#  -156.7964 -163.1753
#  -161.7495 -167.0424

# Find the minimum of the underlying function
bar &lt;- function(xy) barylag2d(foo, xn, yn, xy[1], xy[2])
optim(c(4.25, 67.5), bar)  # "Nelder-Mead"
# $par
# 4.230547 68.522747
# $value
# -175.7959

## Not run: 
# Image and contour plots
image(xn, yn, foo)
contour(xn, yn, foo, col="white", add = TRUE)
xs &lt;- seq(4.05, 4.35, length.out = 51)
ys &lt;- seq(60.0, 90.0, length.out = 51)
zz &lt;- barylag2d(foo, xn, yn, xs, ys)
contour(xs, ys, zz, nlevels = 20, add = TRUE)
contour(xs, ys, zz, levels=c(-175, -175.5), add = TRUE)
points(4.23, 68.52)
## End(Not run)
</code></pre>

<hr>
<h2 id='bernoulli'>
Bernoulli Numbers and Polynomials
</h2><span id='topic+bernoulli'></span>

<h3>Description</h3>

<p>The Bernoulli numbers are a sequence of rational numbers that play an
important role for the series expansion of hyperbolic functions, in the
Euler-MacLaurin formula, or for certain values of Riemann's function at
negative integers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bernoulli(n, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bernoulli_+3A_n">n</code></td>
<td>
<p>the index, a whole number greater or equal to 0.</p>
</td></tr>
<tr><td><code id="bernoulli_+3A_x">x</code></td>
<td>
<p>real number or vector of real numbers; if missing, the
Bernoulli numbers will be given, otherwise the polynomial.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation of the Bernoulli numbers uses the values of the zeta function
at negative integers, i.e. <code class="reqn">B_n = -n \, zeta(1-n)</code>. Bernoulli numbers
<code class="reqn">B_n</code> for odd <code>n</code> are 0 except <code class="reqn">B_1</code> which is set to -0.5 on 
purpose.
</p>
<p>The Bernoulli polynomials can be directly defined as
</p>
<p style="text-align: center;"><code class="reqn"> B_n(x) = \sum_{k=0}^n {n \choose k} b_{n-k}\, x^k </code>
</p>

<p>and it is immediately clear that the Bernoulli numbers are then given as
<code class="reqn">B_n = B_n(0)</code>.
</p>


<h3>Value</h3>

<p>Returns the first <code>n+1</code> Bernoulli numbers, if <code>x</code> is missing, or
the value of the Bernoulli polynomial at point(s) <code>x</code>.
</p>


<h3>Note</h3>

<p>The definition uses <code>B_1 = -1/2</code> in accordance with the definition of
the Bernoulli polynomials.
</p>


<h3>References</h3>

<p>See the entry on Bernoulli numbers in the Wikipedia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zeta">zeta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bernoulli(10)
# 1.00000000 -0.50000000  0.16666667  0.00000000 -0.03333333
# 0.00000000  0.02380952  0.00000000 -0.03333333  0.00000000  0.07575758
                #
## Not run: 
x1 &lt;- linspace(0.3, 0.7, 2)
y1 &lt;- bernoulli(1, x1)
plot(x1, y1, type='l', col='red', lwd=2,
     xlim=c(0.0, 1.0), ylim=c(-0.2, 0.2),
     xlab="", ylab="", main="Bernoulli Polynomials")
grid()
xs &lt;- linspace(0, 1, 51)
lines(xs, bernoulli(2, xs), col="green", lwd=2)
lines(xs, bernoulli(3, xs), col="blue", lwd=2)
lines(xs, bernoulli(4, xs), col="cyan", lwd=2)
lines(xs, bernoulli(5, xs), col="brown", lwd=2)
lines(xs, bernoulli(6, xs), col="magenta", lwd=2)
legend(0.75, 0.2, c("B_1", "B_2", "B_3", "B_4", "B_5", "B_6"),
       col=c("red", "green", "blue", "cyan", "brown", "magenta"),
       lty=1, lwd=2)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='bernstein'>
Bernstein Polynomials
</h2><span id='topic+bernstein'></span><span id='topic+bernsteinb'></span>

<h3>Description</h3>

<p>Bernstein base polynomials and approximations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bernstein(f, n, x)

bernsteinb(k, n, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bernstein_+3A_f">f</code></td>
<td>
<p>function to be approximated by Bernstein polynomials.</p>
</td></tr>
<tr><td><code id="bernstein_+3A_k">k</code></td>
<td>
<p>integer between 0 and n, the k-th Bernstein polynomial
of order n.</p>
</td></tr>
<tr><td><code id="bernstein_+3A_n">n</code></td>
<td>
<p>order of the Bernstein polynomial(s).</p>
</td></tr>
<tr><td><code id="bernstein_+3A_x">x</code></td>
<td>
<p>numeric scalar or vector where the Bernstein polynomials
will be calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bernstein basis polynomials <code class="reqn">B_{k,n}(x)</code> are defined as
</p>
<p style="text-align: center;"><code class="reqn"> B_{k,n}(x) = {{n}\choose{k}} x^k (1-x)^{n-k} </code>
</p>

<p>and form a basis for the vector space of polynomials of degree 
<code class="reqn">n</code> over the interval <code class="reqn">[0,1]</code>.
</p>
<p><code>bernstein(f, n, x)</code> computes the approximation of function
<code>f</code> through Bernstein polynomials of degree <code>n</code>, resp.
computes the value of this approximation at <code>x</code>. The function
is vectorized and applies a brute force calculation.
</p>
<p>But if <code>x</code> is a scalar, the value will be calculated using
De Casteljau's algorithm for higher accuracy. For bigger <code>n</code>
the binomial coefficients may be in for problems.
</p>


<h3>Value</h3>

<p>Returns a scalar or vector of function values.
</p>


<h3>References</h3>

<p>See https://en.wikipedia.org/wiki/Bernstein_polynomial
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example
f &lt;- function(x) sin(2*pi*x)
xs &lt;- linspace(0, 1)
ys &lt;- f(xs)
## Not run: 
plot(xs, ys, type='l', col="blue",
     main="Bernstein Polynomials")
grid()
b10  &lt;- bernstein(f,  10, xs)
b100 &lt;- bernstein(f, 100, xs)
lines(xs, b10,  col="magenta")
lines(xs, b100, col="red") 
## End(Not run)

# Bernstein basis polynomials
## Not run: 
xs &lt;- linspace(0, 1)
plot(c(0,1), c(0,1), type='n',
     main="Bernstein Basis Polynomials")
grid()
n = 10
for (i in 0:n) {
    bs &lt;- bernsteinb(i, n, xs)
    lines(xs, bs, col=i+1)
} 
## End(Not run)
</code></pre>

<hr>
<h2 id='bisect'>
Rootfinding Through Bisection or Secant Rule
</h2><span id='topic+bisect'></span><span id='topic+secant'></span><span id='topic+regulaFalsi'></span>

<h3>Description</h3>

<p>Finding roots of univariate functions in bounded intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bisect(fun, a, b, maxiter = 500, tol = NA, ...)

secant(fun, a, b, maxiter = 500, tol = 1e-08, ...)

regulaFalsi(fun, a, b, maxiter = 500, tol = 1e-08, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bisect_+3A_fun">fun</code></td>
<td>
<p>Function or its name as a string.</p>
</td></tr>
<tr><td><code id="bisect_+3A_a">a</code>, <code id="bisect_+3A_b">b</code></td>
<td>
<p>interval end points.</p>
</td></tr>
<tr><td><code id="bisect_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations; default 100.</p>
</td></tr>
<tr><td><code id="bisect_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance; default <code>eps^(1/2)</code></p>
</td></tr>
<tr><td><code id="bisect_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&ldquo;Bisection&rdquo; is a well known root finding algorithms for real, univariate, 
continuous functions. Bisection works in any case if the function has
opposite signs at the endpoints of the interval.
</p>
<p><code>bisect</code> stops when floating point precision is reached, attaching
a tolerance is no longer needed. This version is trimmed for exactness, 
not speed. Special care is taken when 0.0 is a root of the function.
Argument 'tol' is deprecated and not used anymore.
</p>
<p>The &ldquo;Secant rule&rdquo; uses a succession of roots of secant lines to better 
approximate a root of a function. &ldquo;Regula falsi&rdquo; combines bisection and 
secant methods. The so-called &lsquo;Illinois&rsquo; improvement is used here.
</p>


<h3>Value</h3>

<p>Return a list with components <code>root</code>, <code>f.root</code>, 
the function value at the found root, <code>iter</code>, the number of iterations
done, and <code>root</code>, and the estimated accuracy <code>estim.prec</code>
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ridders">ridders</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bisect(sin, 3.0, 4.0)
# $root             $f.root             $iter   $estim.prec
# 3.1415926536      1.2246467991e-16    52      4.4408920985e-16

bisect(sin, -1.0, 1.0)
# $root             $f.root             $iter   $estim.prec
# 0                 0                   2       0

# Legendre polynomial of degree 5
lp5 &lt;- c(63, 0, -70, 0, 15, 0)/8
f &lt;- function(x) polyval(lp5, x)
bisect(f, 0.6, 1)       # 0.9061798453      correct to 15 decimals
secant(f, 0.6, 1)       # 0.5384693         different root
regulaFalsi(f, 0.6, 1)  # 0.9061798459      correct to 10 decimals
</code></pre>

<hr>
<h2 id='bits'>Binary Representation</h2><span id='topic+bits'></span>

<h3>Description</h3>

<p>Literal bit representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bits(x, k = 54, pos_sign = FALSE, break0 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bits_+3A_x">x</code></td>
<td>
<p>a positive or negative floating point number.</p>
</td></tr>
<tr><td><code id="bits_+3A_k">k</code></td>
<td>
<p>number of binary digits after the decimal point</p>
</td></tr>
<tr><td><code id="bits_+3A_pos_sign">pos_sign</code></td>
<td>
<p>logical; shall the '+' sign be included.</p>
</td></tr>
<tr><td><code id="bits_+3A_break0">break0</code></td>
<td>
<p>logical; shall trailing zeros be included.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The literal bit/binary representation of a floating point number is computed
by subtracting powers of 2.
</p>


<h3>Value</h3>

<p>Returns a string containing the binary representation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nextpow2">nextpow2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bits(2^10)        # "10000000000"
bits(1 + 2^-10)   #  "1.000000000100000000000000000000000000000000000000000000"
bits(pi)          # "11.001001000011111101101010100010001000010110100011000000"
bits(1/3.0)       #  "0.010101010101010101010101010101010101010101010101010101"
bits(1 + eps())   #  "1.000000000000000000000000000000000000000000000000000100"
</code></pre>

<hr>
<h2 id='blanks'>String of Blank Carakters</h2><span id='topic+blanks'></span>

<h3>Description</h3>

<p>Create a string of blank characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blanks(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blanks_+3A_n">n</code></td>
<td>
<p>integer greater or equal to 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>blanks(n)</code> is a string of <code>n</code> blanks.
</p>


<h3>Value</h3>

<p>String of <code>n</code> blanks.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+deblank">deblank</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>blanks(6)
</code></pre>

<hr>
<h2 id='blkdiag'>
Block Diagonal Matrix
</h2><span id='topic+blkdiag'></span>

<h3>Description</h3>

<p>Build a block diagonal matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blkdiag(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blkdiag_+3A_...">...</code></td>
<td>
<p>sequence of non-empty, numeric matrices</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generate a block diagonal matrix from A, B, C, .... 
All the arguments must be numeric and non-empty matrices.
</p>


<h3>Value</h3>

<p>a numeric matrix
</p>


<h3>Note</h3>

<p>Vectors as input have to be converted to matrices before. Note that
<code>as.matrix(v)</code> with <code>v</code> a vector will generate a column vector;
use <code>matrix(v, nrow=1)</code> if a row vector is intended.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Diag">Diag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a1 &lt;- matrix(c(1,2), 1)
a2 &lt;- as.matrix(c(1,2))
blkdiag(a1, diag(1, 2, 2), a2)
</code></pre>

<hr>
<h2 id='brentDekker'>
Brent-Dekker Root Finding Algorithm
</h2><span id='topic+brentDekker'></span><span id='topic+brent'></span>

<h3>Description</h3>

<p>Find root of continuous function of one variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brentDekker(fun, a, b, maxiter = 500, tol = 1e-12, ...)
brent(fun, a, b, maxiter = 500, tol = 1e-12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brentDekker_+3A_fun">fun</code></td>
<td>
<p>function whose root is to be found.</p>
</td></tr>
<tr><td><code id="brentDekker_+3A_a">a</code>, <code id="brentDekker_+3A_b">b</code></td>
<td>
<p>left and right end points of an interval;
function values need to be of different sign at the endpoints.</p>
</td></tr>
<tr><td><code id="brentDekker_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="brentDekker_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="brentDekker_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>brentDekker</code> implements a version of the Brent-Dekker algorithm,
a well known root finding algorithms for real, univariate, continuous
functions. The Brent-Dekker approach is a clever combination of secant
and bisection with quadratic interpolation.
</p>
<p><code>brent</code> is simply an alias for <code>brentDekker</code>.
</p>


<h3>Value</h3>

<p><code>brent</code> returns a list with
</p>
<table>
<tr><td><code>root</code></td>
<td>
<p>location of the root.</p>
</td></tr>
<tr><td><code>f.root</code></td>
<td>
<p>funtion value at the root.</p>
</td></tr>
<tr><td><code>f.calls</code></td>
<td>
<p>number of function calls.</p>
</td></tr>
<tr><td><code>estim.prec</code></td>
<td>
<p>estimated relative precision.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ridders">ridders</a></code>, <code><a href="#topic+newtonRaphson">newtonRaphson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Legendre polynomial of degree 5
lp5 &lt;- c(63, 0, -70, 0, 15, 0)/8
f &lt;- function(x) polyval(lp5, x)
brent(f, 0.6, 1)                # 0.9061798459 correct to 12 places
</code></pre>

<hr>
<h2 id='brown72'>
Brownian Motion
</h2><span id='topic+brown72'></span>

<h3>Description</h3>

<p>The Brown72 data set represents a fractal Brownian motion with
a prescribed Hurst exponent 0f 0.72 .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(brown72)
</code></pre>


<h3>Format</h3>

<p>The format is: one column.
</p>


<h3>Details</h3>

<p>Estimating the Hurst exponent for a data set provides a measure of whether
the data is a pure random walk or has underlying trends. Brownian walks can
be generated from a defined Hurst exponent.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(brown72)
plot(brown72, type = "l", col = "blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='broyden'>Broyden's Method</h2><span id='topic+broyden'></span>

<h3>Description</h3>

<p>Broyden's method for the numerical solution of nonlinear systems of
<code>n</code> equations in <code>n</code> variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>broyden(Ffun, x0, J0 = NULL, ...,
        maxiter = 100, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="broyden_+3A_ffun">Ffun</code></td>
<td>
<p><code>n</code> functions of <code>n</code> variables.</p>
</td></tr>
<tr><td><code id="broyden_+3A_x0">x0</code></td>
<td>
<p>Numeric vector of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="broyden_+3A_j0">J0</code></td>
<td>
<p>Jacobian of the function at <code>x0</code>.</p>
</td></tr>
<tr><td><code id="broyden_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function.</p>
</td></tr>
<tr><td><code id="broyden_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="broyden_+3A_tol">tol</code></td>
<td>
<p>Tolerance, relative accuracy.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>F as a function must return a vector of length <code>n</code>, and accept an
<code>n</code>-dim. vector or column vector as input. F must not be univariate,
that is <code>n</code> must be greater than 1.
</p>
<p>Broyden's method computes the Jacobian and its inverse only at the first
iteration, and does a rank-one update thereafter, applying the so-called
Sherman-Morrison formula that computes the inverse of the sum of an
invertible matrix A and the dyadic product, uv', of a column vector u and
a row vector v'.
</p>


<h3>Value</h3>

<p>List with components: <code>zero</code> the best root found so far, <code>fnorm</code>
the square root of sum of squares of the values of f, and <code>niter</code> the
number of iterations needed.
</p>


<h3>Note</h3>

<p>Applied to a system of <code>n</code> linear equations it will stop in
<code>2n</code> steps
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonsys">newtonsys</a></code>, <code><a href="#topic+fsolve">fsolve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example from Quarteroni &amp; Saleri
F1 &lt;- function(x) c(x[1]^2 + x[2]^2 - 1, sin(pi*x[1]/2) + x[2]^3)
broyden(F1, x0 = c(1, 1))
# zero: 0.4760958 -0.8793934; fnorm: 9.092626e-09; niter: 13

F &lt;- function(x) {
    x1 &lt;- x[1]; x2 &lt;- x[2]; x3 &lt;- x[3]
    as.matrix(c(x1^2 + x2^2 + x3^2 - 1,
                x1^2 + x3^2 - 0.25,
                x1^2 + x2^2 - 4*x3), ncol = 1)
}
x0 &lt;- as.matrix(c(1, 1, 1))
broyden(F, x0)
# zero: 0.4407629 0.8660254 0.2360680; fnorm: 1.34325e-08; niter: 8

##  Find the roots of the complex function sin(z)^2 + sqrt(z) - log(z)
F2 &lt;- function(x) {
    z  &lt;- x[1] + x[2]*1i
    fz &lt;- sin(z)^2 + sqrt(z) - log(z)
    c(Re(fz), Im(fz))
}
broyden(F2, c(1, 1))
# zero   0.2555197 0.8948303 , i.e.  z0 = 0.2555 + 0.8948i
# fnorm  7.284374e-10
# niter  13

##  Two more problematic examples
F3 &lt;- function(x)
        c(2*x[1] - x[2] - exp(-x[1]), -x[1] + 2*x[2] - exp(-x[2]))
broyden(F3, c(0, 0))
# $zero   0.5671433 0.5671433   # x = exp(-x)

F4 &lt;- function(x)   # Dennis Schnabel
        c(x[1]^2 + x[2]^2 - 2, exp(x[1] - 1) + x[2]^3 - 2)
broyden(F4, c(2.0, 0.5), maxiter = 100)
</code></pre>

<hr>
<h2 id='bsxfun'>
Elementwise Function Application (Matlab Style)
</h2><span id='topic+bsxfun'></span><span id='topic+arrayfun'></span>

<h3>Description</h3>

<p>Apply a binary function elementwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  bsxfun(func, x, y)

  arrayfun(func, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bsxfun_+3A_func">func</code></td>
<td>
<p>function with two or more input parameters.</p>
</td></tr>
<tr><td><code id="bsxfun_+3A_x">x</code>, <code id="bsxfun_+3A_y">y</code></td>
<td>
<p>two vectors, matrices, or arrays of the same size.</p>
</td></tr>
<tr><td><code id="bsxfun_+3A_...">...</code></td>
<td>
<p>list of arrays of the same size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>bsxfun</code> applies element-by-element a binary function to two vectors,
matrices, or arrays of the same size. For matrices, <code>sweep</code> is used for
reasons of speed, otherwise <code>mapply</code>. (For arrays of more than two
dimensions this may become very slow.)
</p>
<p><code>arrayfun</code> applies <code>func</code> to each element of the arrays and
returns an array of the same size.
</p>


<h3>Value</h3>

<p>The result will be a vector or matrix of the same size as <code>x, y</code>.
</p>


<h3>Note</h3>

<p>The underlying function <code>mapply</code> can be applied in a more general
setting with many function parameters:
</p>
<p><code>mapply(f, x, y, z, ...)</code>
</p>
<p>but the array structure will not be preserved in this case.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Vectorize">Vectorize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rep(1:10, each = 10), 10, 10)
Y &lt;- t(X)
bsxfun("*", X, Y)  # multiplication table

f &lt;- function(x, y) x[1] * y[1]     # function not vectorized
A &lt;- matrix(c(2, 3, 5, 7), 2, 2)
B &lt;- matrix(c(11, 13, 17, 19), 2, 2)
arrayfun(f, A, B)
</code></pre>

<hr>
<h2 id='bulirsch-stoer'>
Bulirsch-Stoer Algorithm
</h2><span id='topic+bulirsch_stoer'></span><span id='topic+midpoint'></span>

<h3>Description</h3>

<p>Bulirsch-Stoer algorithm for solving Ordinary Differential Equations (ODEs)
very accurately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bulirsch_stoer(f, t, y0, ..., tol = 1e-07)

midpoint(f, t0, tfinal, y0, tol = 1e-07, kmax = 25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bulirsch-stoer_+3A_f">f</code></td>
<td>
<p>function describing the differential equation <code class="reqn">y' = f(t, y)</code>.</p>
</td></tr>
<tr><td><code id="bulirsch-stoer_+3A_t">t</code></td>
<td>
<p>vector of <code>x</code>-values where the values of the ODE function
will be computed; needs to be increasingly sorted.</p>
</td></tr>
<tr><td><code id="bulirsch-stoer_+3A_y0">y0</code></td>
<td>
<p>starting values as column vector.</p>
</td></tr>
<tr><td><code id="bulirsch-stoer_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
<tr><td><code id="bulirsch-stoer_+3A_tol">tol</code></td>
<td>
<p>relative tolerance in the Ricardson extrapolation.</p>
</td></tr>
<tr><td><code id="bulirsch-stoer_+3A_t0">t0</code>, <code id="bulirsch-stoer_+3A_tfinal">tfinal</code></td>
<td>
<p>start and end point of the interval.</p>
</td></tr>
<tr><td><code id="bulirsch-stoer_+3A_kmax">kmax</code></td>
<td>
<p>maximal number of steps in the Richardson extrapolation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bulirsch-Stoer algorithm is a well-known method to obtain high-accuracy
solutions to ordinary differential equations with reasonable computational
efforts. It exploits the midpoint method to get good accuracy in each step.
</p>
<p>The (modified) midpoint method computes the values of the dependent
variable <code>y(t)</code> from <code>t0</code> to <code>tfinal</code> by a sequence of
substeps, applying Richardson extrapolation in each step.
</p>
<p>Bulirsch-Stoer and midpoint shall not be used with non-smooth functions or
singularities inside the interval. The best way to get intermediate points
<code>t = (t[1], ..., t[n])</code> may be to call <code>ode23</code> or <code>ode23s</code>
first and use the <code>x</code>-values returned to start <code>bulirsch_stoer</code>
on.
</p>


<h3>Value</h3>

<p>bulirsch_stoer returns a list with <code>x</code> the grid points input, and
<code>y</code> a vector of function values at the se points.
</p>


<h3>Note</h3>

<p>Will be extended to become a full-blown Bulirsch-Stoer implementation.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 2014 Hans W Borchers
</p>


<h3>References</h3>

<p>J. Stoer and R. Bulirsch (2002). Introduction to Numerical Analysis.
Third Edition, Texts in Applied Mathematics 12, Springer Science +
Business, LCC, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ode23">ode23</a></code>, <code><a href="#topic+ode23s">ode23s</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example: y'' = -y
f1 &lt;- function(t, y) as.matrix(c(y[2], -y[1]))
y0 &lt;- as.matrix(c(0.0, 1.0))
tt &lt;- linspace(0, pi, 13)
yy &lt;- bulirsch_stoer(f1, tt, c(0.0, 1.0))   # 13 equally-spaced grid points
yy[nrow(yy), 1]                             # 1.1e-11

## Not run: 
S  &lt;- ode23(f1, 0, pi, c(0.0, 1.0))
yy &lt;- bulirsch_stoer(f1, S$t, c(0.0, 1.0))  # S$x 13 irregular grid points
yy[nrow(yy), 1]                             #  2.5e-11
S$y[nrow(S$y), 1]                           # -7.1e-04

## Example: y' = -200 x y^2                 # y(x) = 1 / (1 + 100 x^2)
f2 &lt;- function(t, y) -200 * t * y^2
y0 &lt; 1
tic(); S &lt;- ode23(f2, 0, 1, y0); toc()            # 0.002 sec
tic(); yy &lt;- bulirsch_stoer(f2, S$t, y0); toc()   # 0.013 sec
## End(Not run)
</code></pre>

<hr>
<h2 id='bvp'>
Boundary Value Problems
</h2><span id='topic+bvp'></span>

<h3>Description</h3>

<p>Solves boundary value problems of linear second order differential equations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bvp(f, g, h, x, y, n = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bvp_+3A_f">f</code>, <code id="bvp_+3A_g">g</code>, <code id="bvp_+3A_h">h</code></td>
<td>
<p>functions on the right side of the differential equation.
If <code>f, g</code> or <code>h</code> is a scalar instead of a function, it is
assumed to be a constant coefficient in the differential equation.</p>
</td></tr>
<tr><td><code id="bvp_+3A_x">x</code></td>
<td>
<p><code>x[1], x[2]</code> are the interval borders where the solution
shall be computed.</p>
</td></tr>
<tr><td><code id="bvp_+3A_y">y</code></td>
<td>
<p>boundary conditions such that
<code>y(x[1]) = y[1], y(x[2]) = y[2]</code>.</p>
</td></tr>
<tr><td><code id="bvp_+3A_n">n</code></td>
<td>
<p>number of intermediate grid points; default 50.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves the two-point boundary value problem given as a linear differential 
equation of second order in the form:
</p>
<p style="text-align: center;"><code class="reqn">y'' = f(x) y' + g(x) y + h(x)</code>
</p>

<p>with the finite element method. The solution <code class="reqn">y(x)</code> shall exist
on the interval <code class="reqn">[a, b]</code> with boundary conditions <code class="reqn">y(a) = y_a</code> 
and <code class="reqn">y(b) = y_b</code>.
</p>


<h3>Value</h3>

<p>Returns a list <code>list(xs, ys)</code> with the grid points <code>xs</code> and the
values <code>ys</code> of the solution at these points, including the boundary
points.
</p>


<h3>Note</h3>

<p>Uses a tridiagonal equation solver that may be faster then <code>qr.solve</code>
for large values of <code>n</code>.
</p>


<h3>References</h3>

<p>Kutz, J. N. (2005). Practical Scientific Computing. Lecture Notes 
98195-2420, University of Washington, Seattle.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shooting">shooting</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Solve y'' = 2*x/(1+x^2)*y' - 2/(1+x^2) * y + 1
##  with y(0) = 1.25 and y(4) = -0.95 on the interval [0, 4]:
f1 &lt;- function(x) 2*x / (1 + x^2)
f2 &lt;- function(x)  -2 / (1 + x^2)
f3 &lt;- function(x) rep(1, length(x))     # vectorized constant function 1
x &lt;- c(0.0,   4.0)
y &lt;- c(1.25, -0.95)
sol &lt;- bvp(f1, f2, f3, x, y)
## Not run: 
plot(sol$xs, sol$ys, ylim = c(-2, 2),
     xlab = "", ylab = "", main = "Boundary Value Problem")
# The analytic solution is
sfun &lt;- function(x) 1.25 + 0.4860896526*x - 2.25*x^2 + 
                    2*x*atan(x) - 1/2 * log(1+x^2) + 1/2 * x^2 * log(1+x^2)
xx &lt;- linspace(0, 4)
yy &lt;- sfun(xx)
lines(xx, yy, col="red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='cart2sph'>
Coordinate Transformations
</h2><span id='topic+cart2sph'></span><span id='topic+sph2cart'></span><span id='topic+cart2pol'></span><span id='topic+pol2cart'></span>

<h3>Description</h3>

<p>Transforms between cartesian, spherical, polar, and cylindrical coordinate
systems in two and three dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cart2sph(xyz)
sph2cart(tpr)
cart2pol(xyz)
pol2cart(prz)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cart2sph_+3A_xyz">xyz</code></td>
<td>
<p>cartesian coordinates x, y, z as vector or matrix.</p>
</td></tr>
<tr><td><code id="cart2sph_+3A_tpr">tpr</code></td>
<td>
<p>spherical coordinates theta, phi, and r as vector or matrix.</p>
</td></tr>
<tr><td><code id="cart2sph_+3A_prz">prz</code></td>
<td>
<p>polar coordinates phi, r or cylindrical coordinates phi, r, z
as vector or matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The spherical coordinate system used here consists of
</p>
<p>- <code>theta</code>, azimuth angle relative to the positive x-axis
</p>
<p>- <code>phi</code>,   elevation angle measured from the reference plane
</p>
<p>- <code>r</code>,     radial distance. i.e., distance to the origin
</p>
<p>The polar angle, measured with respect from the polar axis, is then 
calculated as <code>pi/2 - phi</code>.
Note that this convention differs slightly from spherical coordinates 
<code>(r, theta, phi)</code> as often used in mathematics, where <code>phi</code> 
is the polar angle.
</p>
<p><code>cart2sph</code> returns spherical coordinates as (theta, phi, r), and
<code>sph2cart</code> expects them in this sequence.
</p>
<p><code>cart2pol</code> returns polar coordinates (phi, r) if <code>length(xyz)==2</code>
and cylindrical coordinates (phi, r, z) else. <code>pol2cart</code> needs them in
this sequence and length.
</p>
<p>To go from cylindrical to cartesian coordinates, transform to cartesian
coordinates first &mdash; or write your own function, see the examples.
</p>
<p>All transformation functions are vectorized.
</p>


<h3>Value</h3>

<p>All functions return a (2- or 3-dimensional) vector representing a point
in the requested coordinate system, or a matrix with 2 or 3 named columns
where is row represents a point. The columns are named accordingly.
</p>


<h3>Note</h3>

<p>In Matlab these functions accept two or three variables and return two or
three values. In R it did not appear appropriate to return coordinates as
a list.
</p>
<p>These functions should be vectorized in the sense that they accept will
accept matrices with number of rows or columns equal to 2 or 3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 0.5*cos(pi/6); y &lt;- 0.5*sin(pi/6); z &lt;- sqrt(1 - x^2 - y^2)
(s &lt;-cart2sph(c(x, y, z)))      # 0.5235988 1.0471976 1.0000000
sph2cart(s)                     # 0.4330127 0.2500000 0.8660254

cart2pol(c(1,1))                # 0.7853982 1.4142136
cart2pol(c(1,1,0))              # 0.7853982 1.4142136 0.0000000
pol2cart(c(pi/2, 1))            # 6.123234e-17 1.000000e+00
pol2cart(c(pi/4, 1, 1))         # 0.7071068 0.7071068 1.0000000

##  Transform spherical to cylindrical coordinates and vice versa
#   sph2cyl &lt;- function(th.ph.r) cart2pol(sph2cart(th.ph.r))
#   cyl2sph &lt;- function(phi.r.z) cart2sph(pol2cart(phi.r.z))
</code></pre>

<hr>
<h2 id='cd+2C+20pwd+2C+20what'>
Directory Functions (Matlab style)
</h2><span id='topic+cd'></span><span id='topic+pwd'></span><span id='topic+what'></span>

<h3>Description</h3>

<p>Displays or changes working directory, or lists files therein.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cd(dname)
pwd()

what(dname = getwd())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cd+2B2C+2B20pwd+2B2C+2B20what_+3A_dname">dname</code></td>
<td>
<p>(relative or absolute) directory path.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pwd()</code> displays the name of the current directory, and is the same
as <code>cd()</code>. <code>cd(dname)</code> changes to directory <code>dname</code> and if
successfull displays the directory name.
</p>
<p><code>what()</code> lists all files in a directory.<br />
</p>


<h3>Value</h3>

<p>Name of the current working directory.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+getwd">getwd</a></code>, <code><a href="base.html#topic+setwd">setwd</a></code>, <code><a href="base.html#topic+list.files">list.files</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># cd()
# pwd()
# what()
</code></pre>

<hr>
<h2 id='ceil'>Integer Functions (Matlab Style)</h2><span id='topic+ceil'></span><span id='topic+Fix'></span>

<h3>Description</h3>

<p>Functions for rounding and truncating numeric values towards near
integer values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ceil(n)
Fix(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ceil_+3A_n">n</code></td>
<td>
<p>a numeric vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ceil()</code> is an alias for <code>ceiling()</code> and rounds to the smallest
integer equal to or above <code>n</code>.
</p>
<p><code>Fix()</code> truncates values towards 0 and is an alias for 
<code>trunc()</code>. Uses <code>ml</code> prefix to indicate Matlab style.
</p>
<p>The corresponding functions <code>floor()</code> (rounding to the largest interger
equal to or smaller than <code>n</code>) and <code>round()</code> (rounding to the
specified number of digits after the decimal point, default being 0) are
already part of R base.
</p>


<h3>Value</h3>

<p>integer values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(-1.2, -0.8, 0, 0.5, 1.1, 2.9)
ceil(x)
Fix(x)
</code></pre>

<hr>
<h2 id='charpoly'>
Characteristic Polynomial
</h2><span id='topic+charpoly'></span>

<h3>Description</h3>

<p>Computes the characteristic polynomial (and the inverse of the matrix, if
requested) using the Faddeew-Leverrier method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>charpoly(a, info = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="charpoly_+3A_a">a</code></td>
<td>
<p>quadratic matrix; size should not be much larger than 100.</p>
</td></tr>
<tr><td><code id="charpoly_+3A_info">info</code></td>
<td>
<p>logical; if true, the inverse matrix will also be reported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the characteristic polynomial recursively. In the last step
the determinant and the inverse matrix can be determined without any
extra cost (if the matrix is not singular).
</p>


<h3>Value</h3>

<p>Either the characteristic polynomial as numeric vector, or a list with
components <code>cp</code>, the characteristic polynomial, <code>det</code>, the
determinant, and <code>inv</code>, the inverse matrix, will be returned.
</p>


<h3>References</h3>

<p>Hou, S.-H. (1998). Classroom Note: A Simple Proof of the Leverrier&ndash;Faddeev
Characteristic Polynomial Algorithm, SIAM Review, 40(3), pp. 706&ndash;709.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- magic(5)
A &lt;- charpoly(a, info = TRUE)
A$cp
roots(A$cp)
A$det
zapsmall(A$inv %*% a)
</code></pre>

<hr>
<h2 id='chebApprox'>Chebyshev Approximation</h2><span id='topic+chebApprox'></span>

<h3>Description</h3>

<p>Function approximation through Chebyshev polynomials (of the first kind).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chebApprox(x, fun, a, b, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chebApprox_+3A_x">x</code></td>
<td>
<p>Numeric vector of points within interval <code>[a, b]</code>.</p>
</td></tr>
<tr><td><code id="chebApprox_+3A_fun">fun</code></td>
<td>
<p>Function to be approximated.</p>
</td></tr>
<tr><td><code id="chebApprox_+3A_a">a</code>, <code id="chebApprox_+3A_b">b</code></td>
<td>
<p>Endpoints of the interval.</p>
</td></tr>
<tr><td><code id="chebApprox_+3A_n">n</code></td>
<td>
<p>An integer <code>&gt;= 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Return approximate y-coordinates of points at x by computing the
Chebyshev approximation of degree n for <code>fun</code> on the interval
<code>[a, b]</code>.
</p>


<h3>Value</h3>

<p>A numeric vector of the same length as <code>x</code>.
</p>


<h3>Note</h3>

<p>TODO: Evaluate the Chebyshev approximative polynomial by using the
Clenshaw recurrence formula.
(Not yet vectorized, that's why we still use the Horner scheme.)
</p>


<h3>References</h3>

<p>Press, W. H., S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery (1992).
Numerical Recipes in C: The Art of Scientific Computing. Second Edition,
Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyApprox">polyApprox</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Approximate sin(x) on [-pi, pi] with a polynomial of degree 9 !
# This polynomial has to be beaten:
# P(x) = x - 1/6*x^3 + 1/120*x^5 - 1/5040*x^7 + 1/362880*x^9

# Compare these polynomials
p1 &lt;- rev(c(0, 1, 0, -1/6, 0, 1/120, 0, -1/5040, 0, 1/362880))
p2 &lt;- chebCoeff(sin, -pi, pi, 9)

# Estimate the maximal distance
x  &lt;- seq(-pi, pi, length.out = 101)
ys &lt;- sin(x)
yp &lt;- polyval(p1, x)
yc &lt;- chebApprox(x, sin, -pi, pi, 9)
max(abs(ys-yp))                       # 0.006925271
max(abs(ys-yc))                       # 1.151207e-05

## Not run: 
# Plot the corresponding curves
plot(x, ys, type = "l", col = "gray", lwd = 5)
lines(x, yp, col = "navy")
lines(x, yc, col = "red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='chebCoeff'>Chebyshev Polynomials</h2><span id='topic+chebCoeff'></span>

<h3>Description</h3>

<p>Chebyshev Coefficients for Chebyshev polynomials of the first kind.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chebCoeff(fun, a, b, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chebCoeff_+3A_fun">fun</code></td>
<td>
<p>function to be approximated.</p>
</td></tr>
<tr><td><code id="chebCoeff_+3A_a">a</code>, <code id="chebCoeff_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="chebCoeff_+3A_n">n</code></td>
<td>
<p>an integer <code>&gt;= 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a function <code>fun</code> on on the interval <code>[a, b]</code> determines the
coefficients of the Chebyshev polynomials up to degree <code>n</code> that will
approximate the function (in L2 norm).
</p>


<h3>Value</h3>

<p>Vector of coefficients for the Chebyshev polynomials, from low to high
degrees (see the example).
</p>


<h3>Note</h3>

<p>See the &ldquo;Chebfun Project&rdquo; &lt;https://www.chebfun.org/&gt; by
Nick Trefethen.
</p>


<h3>References</h3>

<p>Weisstein, Eric W. &ldquo;Chebyshev Polynomial of the First Kind.&quot;
From MathWorld &mdash; A Wolfram Web Resource.
<a href="https://mathworld.wolfram.com/ChebyshevPolynomialoftheFirstKind.html">https://mathworld.wolfram.com/ChebyshevPolynomialoftheFirstKind.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chebPoly">chebPoly</a></code>, <code><a href="#topic+chebApprox">chebApprox</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Chebyshev coefficients for x^2 + 1
n &lt;- 4
f2 &lt;- function(x) x^2 + 1
cC &lt;- chebCoeff(f2, -1, 1, n)  #  3.0   0  0.5   0   0
cC[1] &lt;- cC[1]/2               # correcting the absolute Chebyshev term
                               # i.e.  1.5*T_0 + 0.5*T_2
cP &lt;- chebPoly(n)              # summing up the polynomial coefficients
p &lt;- cC %*% cP                 #  0 0 1 0 1
</code></pre>

<hr>
<h2 id='chebPoly'>Chebyshev Polynomials</h2><span id='topic+chebPoly'></span>

<h3>Description</h3>

<p>Chebyshev polynomials and their values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chebPoly(n, x = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chebPoly_+3A_n">n</code></td>
<td>
<p>an integer <code>&gt;= 0</code>.</p>
</td></tr>
<tr><td><code id="chebPoly_+3A_x">x</code></td>
<td>
<p>a numeric vector, possibly empty; default <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Determines an (n+1)-ny-(n+1)-Matrix of Chebyshev polynomials up to degree n.
</p>
<p>The coefficients of the first <code>n</code> Chebyshev polynomials are computed
using the recursion formula. For computing any values at points the well
known Horner schema is applied.
</p>


<h3>Value</h3>

<p>If <code>x</code> is <code>NULL</code>, returns an <code>(n+1)</code>-by-<code>(n+1)</code> matrix
with the coefficients of the first Chebyshev polynomials from <code>0</code> to
<code>n</code>, one polynomial per row with coefficients from highest to lowest
order.
</p>
<p>If <code>x</code> is a numeric vector, returns the values of the <code>n</code>-th
Chebyshev polynomial at the points of <code>x</code>.
</p>


<h3>Note</h3>

<p>See the &ldquo;Chebfun Project&rdquo; &lt;https://www.chebfun.org/&gt; by
Nick Trefethen.
</p>


<h3>References</h3>

<p>Carothers, N. L. (1998). A Short Course on Approximation Theory.
Bowling Green State University.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chebCoeff">chebCoeff</a></code>, <code><a href="#topic+chebApprox">chebApprox</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>chebPoly(6)

## Not run: 
##  Plot 6 Chebyshev Polynomials
plot(0, 0, type="n", xlim=c(-1, 1), ylim=c(-1.2, 1.2),
    main="Chebyshev Polynomials for n=1..6", xlab="x", ylab="y")
grid()
x &lt;- seq(-1, 1, length.out = 101)
for (i in 1:6) {
    y &lt;- chebPoly(i, x)
    lines(x, y, col=i)
}
legend(x = 0.55, y = 1.2, c("n=1", "n=2", "n=3", "n=4", "n=5", "n=6"),
    col = 1:6, lty = 1, bg="whitesmoke", cex = 0.75)

## End(Not run)
</code></pre>

<hr>
<h2 id='circlefit'>Fitting a Circle</h2><span id='topic+circlefit'></span>

<h3>Description</h3>

<p>Fitting a circle from points in the plane
</p>


<h3>Usage</h3>

<pre><code class='language-R'>circlefit(xp, yp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="circlefit_+3A_xp">xp</code>, <code id="circlefit_+3A_yp">yp</code></td>
<td>
<p>Vectors representing the x and y coordinates of plane points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This routine finds an &lsquo;algebraic&rsquo; solution based on a linear fit.
The value to be minimized is the distance of the given points to
the nearest point on the circle along a radius.
</p>


<h3>Value</h3>

<p>Returns x- and y-coordinates of the center and the radius as a vector
of length 3.
</p>
<p>Writes the RMS error of the (radial) distance of the original points
to the circle directly onto the console.
</p>


<h3>References</h3>

<p>Gander, W., G. H. Golub, and R. Strebel (1994). Fitting of Circles and
Ellipses &mdash; Least Squares Solutions. ETH Zürich, Technical Report 217,
Institut für Wissenschaftliches Rechnen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set.seed(8421)
n  &lt;- 20
w  &lt;- 2*pi*runif(n)
xp &lt;- cos(w) + 1 + 0.25 * (runif(n) - 0.5)
yp &lt;- sin(w) + 1 + 0.25 * (runif(n) - 0.5)

circe &lt;- circlefit(xp, yp)  #=&gt; 0.9899628 1.0044920 1.0256633
                            # RMS error: 0.07631986 
## Not run: 
x0 &lt;- circe[1]; y0 &lt;- circe[2]; r0 &lt;- circe[3]
plot(c(-0.2, 2.2), c(-0.2, 2.2), type="n", asp=1)
grid()
abline(h=0, col="gray"); abline(v=0, col="gray")
points(xp, yp, col="darkred")

w  &lt;- seq(0, 2*pi, len=100)
xx &lt;- r0 * cos(w) + x0
yy &lt;- r0 * sin(w) + y0
lines(xx, yy, col="blue")
## End(Not run)
</code></pre>

<hr>
<h2 id='clear+2C+20who+28s+29+2C+20ver'>
Clear function (Matlab style)
</h2><span id='topic+clear'></span><span id='topic+ver'></span><span id='topic+who'></span><span id='topic+whos'></span>

<h3>Description</h3>

<p>List or remove items from workspace, or display system information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clear(lst)
ver()

who()
whos()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clear+2B2C+2B20who+2B28s+2B29+2B2C+2B20ver_+3A_lst">lst</code></td>
<td>
<p>Character vector of names of variables in the global environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Remove these or all items from the workspace, i.e. the global environment,
and freeing up system memory.
</p>
<p><code>who()</code>  lists all items on the workspace.<br />
<code>whos()</code> lists all items and their class and size.
</p>
<p><code>ver()</code> displays version and license information for R and all the
loaded packages.
</p>


<h3>Value</h3>

<p>Invisibly NULL.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+ls">ls</a></code>, <code><a href="base.html#topic+rm">rm</a></code>, <code><a href="utils.html#topic+sessionInfo">sessionInfo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># clear()  # DON'T
# who()
# whos()
# ver()
</code></pre>

<hr>
<h2 id='clenshaw_curtis'>
Clenshaw-Curtis Quadrature Formula
</h2><span id='topic+clenshaw_curtis'></span>

<h3>Description</h3>

<p>Clenshaw-Curtis Quadrature Formula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clenshaw_curtis(f, a = -1, b = 1, n = 1024, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clenshaw_curtis_+3A_f">f</code></td>
<td>
<p>function, the integrand, without singularities.</p>
</td></tr>
<tr><td><code id="clenshaw_curtis_+3A_a">a</code>, <code id="clenshaw_curtis_+3A_b">b</code></td>
<td>
<p>lower and upper limit of the integral; must be finite.</p>
</td></tr>
<tr><td><code id="clenshaw_curtis_+3A_n">n</code></td>
<td>
<p>Number of Chebyshev nodes to account for.</p>
</td></tr>
<tr><td><code id="clenshaw_curtis_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Clenshaw-Curtis quadrature is based on sampling the integrand on
Chebyshev points, an operation that can be implemented using the
Fast Fourier Transform.
</p>


<h3>Value</h3>

<p>Numerical scalar, the value of the integral.
</p>


<h3>References</h3>

<p>Trefethen, L. N. (2008). Is Gauss Quadrature Better Than Clenshaw-Curtis?
SIAM Review, Vol. 50, No. 1, pp 67&ndash;87.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussLegendre">gaussLegendre</a></code>, <code><a href="#topic+gauss_kronrod">gauss_kronrod</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Quadrature with Chebyshev nodes and weights
f &lt;- function(x) sin(x+cos(10*exp(x))/3)
## Not run: ezplot(f, -1, 1, fill = TRUE)
cc &lt;- clenshaw_curtis(f, n = 64)  #=&gt;  0.0325036517151 , true error &gt; 1.3e-10
</code></pre>

<hr>
<h2 id='combs'>
Generate Combinations
</h2><span id='topic+combs'></span>

<h3>Description</h3>

<p>Generates all combinations of length <code>m</code> of a vector <code>a</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combs(a, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combs_+3A_a">a</code></td>
<td>
<p>numeric vector of some length <code>n</code></p>
</td></tr>
<tr><td><code id="combs_+3A_m">m</code></td>
<td>
<p>integer with <code>0 &lt;= m &lt;= n</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>combs</code> generates combinations of length <code>n</code> of the elements
of the vector <code>a</code>.
</p>


<h3>Value</h3>

<p>matrix representing combinations of the elements of <code>a</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perms">perms</a></code>, <code><a href="#topic+randcomb">randcomb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>combs(seq(2, 10, by=2), m = 3)
</code></pre>

<hr>
<h2 id='compan'>Companion Matrix</h2><span id='topic+compan'></span>

<h3>Description</h3>

<p>Computes the companion matrix of a real or complex vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  compan(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compan_+3A_p">p</code></td>
<td>
<p>vector representing a polynomial</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the companion matrix corresponding to the vector <code>p</code>
with <code>-p[2:length(p)]/p[1]</code> as first row.
</p>
<p>The eigenvalues of this matrix are the roots of the polynomial.
</p>


<h3>Value</h3>

<p>A square matrix of <code>length(p)-1</code> rows and columns
</p>


<h3>See Also</h3>

<p><code><a href="#topic+roots">roots</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  p &lt;- c(1, 0, -7, 6)
  compan(p)
  # 0  7 -6
  # 1  0  0
  # 0  1  0
</code></pre>

<hr>
<h2 id='complexstep'>Complex Step Derivatives</h2><span id='topic+complexstep'></span><span id='topic+grad_csd'></span><span id='topic+jacobian_csd'></span><span id='topic+hessian_csd'></span><span id='topic+laplacian_csd'></span>

<h3>Description</h3>

<p>Complex step derivatives of real-valued functions, including gradients,
Jacobians, and Hessians.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complexstep(f, x0, h = 1e-20, ...)

grad_csd(f, x0, h = 1e-20, ...)
jacobian_csd(f, x0, h = 1e-20, ...)
hessian_csd(f, x0, h = 1e-20, ...)
laplacian_csd(f, x0, h = 1e-20, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="complexstep_+3A_f">f</code></td>
<td>
<p>Function that is to be differentiated.</p>
</td></tr>
<tr><td><code id="complexstep_+3A_x0">x0</code></td>
<td>
<p>Point at which to differentiate the function.</p>
</td></tr>
<tr><td><code id="complexstep_+3A_h">h</code></td>
<td>
<p>Step size to be applied; shall be <em>very</em> small.</p>
</td></tr>
<tr><td><code id="complexstep_+3A_...">...</code></td>
<td>
<p>Additional variables to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Complex step derivation is a fast and highly exact way of numerically
differentiating a function. If the following conditions are satisfied,
there will be no loss of accuracy between computing a function value
and computing the derivative at a certain point.
</p>

<ul>
<li> <p><code>f</code> must have an analytical (i.e., complex differentiable)
continuation into an open neighborhood of <code>x0</code>.
</p>
</li>
<li> <p><code>x0</code> <b>and</b> <code>f(x0)</code> must be real.
</p>
</li>
<li> <p><code>h</code> is real and <em>very</em> small: <code>0 &lt; h &lt;&lt; 1</code>.
</p>
</li></ul>

<p><code>complexstep</code> handles differentiation of univariate functions, while
<code>grad_csd</code> and <code>jacobian_csd</code> compute gradients and Jacobians by
applying the complex step approach iteratively. Please understand that these 
functions are not vectorized, but <code>complexstep</code> is.
</p>
<p>As complex step cannot be applied twice (the first derivative does not
fullfil the conditions), <code>hessian_csd</code> works differently. For the
first derivation, complex step is used, to the one time derived function
Richardson's method is applied. The same applies to <code>lapalacian_csd</code>.
</p>


<h3>Value</h3>

<p><code>complexstep(f, x0)</code> returns the derivative <code class="reqn">f'(x_0)</code> of <code class="reqn">f</code>
at <code class="reqn">x_0</code>. The function is vectorized in <code>x0</code>.  
</p>


<h3>Note</h3>

<p>This surprising approach can be easily deduced from the complex-analytic
Taylor formula.
</p>


<h3>Author(s)</h3>

<p>HwB &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Martins, J. R. R. A., P. Sturdza, and J. J. Alonso (2003).
The Complex-step Derivative Approximation.
ACM Transactions on Mathematical Software, Vol. 29, No. 3, pp. 245&ndash;262.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+numderiv">numderiv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example from Martins et al.
f &lt;- function(x) exp(x)/sqrt(sin(x)^3 + cos(x)^3)  # derivative at x0 = 1.5
# central diff formula    # 4.05342789402801, error 1e-10
# numDeriv::grad(f, 1.5)  # 4.05342789388197, error 1e-12  Richardson
# pracma::numderiv        # 4.05342789389868, error 5e-14  Richardson
complexstep(f, 1.5)       # 4.05342789389862, error 1e-15
# Symbolic calculation:   # 4.05342789389862

jacobian_csd(f, 1.5)

f1 &lt;- function(x) sum(sin(x))
grad_csd(f1, rep(2*pi, 3))
## [1] 1 1 1

laplacian_csd(f1, rep(pi/2, 3))
## [1] -3

f2 &lt;- function(x) c(sin(x[1]) * exp(-x[2]))
hessian_csd(f2, c(0.1, 0.5, 0.9))
##             [,1]        [,2] [,3]
## [1,] -0.06055203 -0.60350053    0
## [2,] -0.60350053  0.06055203    0
## [3,]  0.00000000  0.00000000    0

f3 &lt;- function(u) {
    x &lt;- u[1]; y &lt;- u[2]; z &lt;- u[3]
    matrix(c(exp(x^+y^2), sin(x+y), sin(x)*cos(y), x^2 - y^2), 2, 2)
  }
jacobian_csd(f3, c(1,1,1))
##            [,1]       [,2] [,3]
## [1,]  2.7182818  0.0000000    0
## [2,] -0.4161468 -0.4161468    0
## [3,]  0.2919266 -0.7080734    0
## [4,]  2.0000000 -2.0000000    0
</code></pre>

<hr>
<h2 id='cond'>
Matrix Condition
</h2><span id='topic+cond'></span>

<h3>Description</h3>

<p>Condition number of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cond(M, p = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cond_+3A_m">M</code></td>
<td>
<p>Numeric matrix; vectors will be considered as column vectors.</p>
</td></tr>
<tr><td><code id="cond_+3A_p">p</code></td>
<td>
<p>Indicates the <code>p</code>-norm.
At the moment, norms other than <code>p=2</code> are not implemented.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The condition number of a matrix measures the sensitivity of the solution
of a system of linear equations to small errors in the data. Values of
<code>cond(M)</code> and <code>cond(M, p)</code> near <code>1</code> are indications of a
well-conditioned matrix.
</p>


<h3>Value</h3>

<p><code>cond(M)</code> returns the 2-norm condition number, the ratio of the
largest singular value of <code>M</code> to the smallest.
</p>
<p><code>c = cond(M, p)</code> returns the matrix condition number in <code>p</code>-norm:
</p>
<p><code>norm(X,p) * norm(inv(X),p)</code>.
</p>
<p>(Not yet implemented.)
</p>


<h3>Note</h3>

<p>Not feasible for large or sparse matrices as <code>svd(M)</code> needs to be
computed. The Matlab/Octave function <code>condest</code> for condition
estimation has not been implemented.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Philadelphia.   
</p>


<h3>See Also</h3>

<p><code><a href="#topic+normest">normest</a></code>, <code><a href="base.html#topic+svd">svd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cond(hilb(8))
</code></pre>

<hr>
<h2 id='conv'>Polynomial Convolution</h2><span id='topic+conv'></span>

<h3>Description</h3>

<p>Convolution and polynomial multiplication.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conv(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conv_+3A_x">x</code>, <code id="conv_+3A_y">y</code></td>
<td>
<p>real or complex vectors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>r = conv(p,q)</code> convolves vectors <code>p</code> and <code>q</code>.
Algebraically, convolution is the same operation as multiplying the
polynomials whose coefficients are the elements of <code>p</code> and <code>q</code>.
</p>


<h3>Value</h3>

<p>Another vector.
</p>


<h3>Note</h3>

<p><code>conv</code> utilizes fast Fourier transformation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+deconv">deconv</a></code>, <code><a href="#topic+polyadd">polyadd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>conv(c(1, 1, 1), 1)
conv(c(1, 1, 1), c(0, 0, 1))
conv(c(-0.5, 1, -1), c(0.5, 0, 1))
</code></pre>

<hr>
<h2 id='cot+2Ccsc+2Csec+2C+20etc.'>
More Trigonometric Functions
</h2><span id='topic+cot'></span><span id='topic+csc'></span><span id='topic+sec'></span><span id='topic+acot'></span><span id='topic+acsc'></span><span id='topic+asec'></span>

<h3>Description</h3>

<p>More trigonometric functions not available in R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cot(z)
csc(z)
sec(z)
acot(z)
acsc(z)
asec(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cot+2B2Ccsc+2B2Csec+2B2C+2B20etc._+3A_z">z</code></td>
<td>
<p>numeric or complex scalar or vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The usual trigonometric cotangens, cosecans, and secans functions
and their inverses, computed through the other well known &ndash; in R &ndash;
sine, cosine, and tangens functions.
</p>


<h3>Value</h3>

<p>Result vector of numeric or complex values.
</p>


<h3>Note</h3>

<p>These function names are available in Matlab, that is the reason they have
been added to the &lsquo;pracma&rsquo; package.
</p>


<h3>See Also</h3>

<p>Trigonometric and hyperbolic functions in R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cot(1+1i)       # 0.2176 - 0.8680i
csc(1+1i)       # 0.6215 - 0.3039i
sec(1+1i)       # 0.4983 + 0.5911i
acot(1+1i)      # 0.5536 - 0.4024i
acsc(1+1i)      # 0.4523 - 0.5306i
asec(1+1i)      # 1.1185 + 0.5306i
</code></pre>

<hr>
<h2 id='cotes'>
Newton-Cotes Formulas
</h2><span id='topic+cotes'></span>

<h3>Description</h3>

<p>Closed composite Newton-Cotes formulas of degree 2 to 8.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cotes(f, a, b, n, nodes, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cotes_+3A_f">f</code></td>
<td>
<p>the integrand as function of two variables.</p>
</td></tr>
<tr><td><code id="cotes_+3A_a">a</code>, <code id="cotes_+3A_b">b</code></td>
<td>
<p>lower and upper limit of the integral.</p>
</td></tr>
<tr><td><code id="cotes_+3A_n">n</code></td>
<td>
<p>number of subintervals (grid points).</p>
</td></tr>
<tr><td><code id="cotes_+3A_nodes">nodes</code></td>
<td>
<p>number of nodes in the Newton-Cotes formula.</p>
</td></tr>
<tr><td><code id="cotes_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>2 to 8 point closed and summed Newton-Cotes numerical integration formulas.
</p>
<p>These formulas are called &lsquo;closed&rsquo; as they include the endpoints.
They are called &lsquo;composite&rsquo; insofar as they are combined with a
Lagrange interpolation over subintervals.
</p>


<h3>Value</h3>

<p>The integral as a scalar.
</p>


<h3>Note</h3>

<p>It is generally recommended not to apply Newton-Cotes formula of degrees
higher than 6, instead increase the number <code>n</code> of subintervals used.
</p>


<h3>Author(s)</h3>

<p>Standard Newton-Cotes formulas can be found in every textbook.
Copyright (c) 2005 Greg von Winckel of nicely vectorized Matlab code,
available from MatlabCentral, for 2 to 11 grid points.
R version by Hans W Borchers, with permission.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simpadpt">simpadpt</a></code>, <code><a href="#topic+trapz">trapz</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cotes(sin, 0, pi/2, 20, 2)      # 0.999485905248533
cotes(sin, 0, pi/2, 20, 3)      # 1.000000211546591
cotes(sin, 0, pi/2, 20, 4)      # 1.000000391824184
cotes(sin, 0, pi/2, 20, 5)      # 0.999999999501637
cotes(sin, 0, pi/2, 20, 6)      # 0.999999998927507
cotes(sin, 0, pi/2, 20, 7)      # 1.000000000000363  odd degree is better
cotes(sin, 0, pi/2, 20, 8)      # 1.000000000002231
</code></pre>

<hr>
<h2 id='coth+2Ccsch+2Csech+2C+20etc.'>
More Hyperbolic Functions
</h2><span id='topic+coth'></span><span id='topic+csch'></span><span id='topic+sech'></span><span id='topic+acoth'></span><span id='topic+acsch'></span><span id='topic+asech'></span>

<h3>Description</h3>

<p>More hyperbolic functions not available in R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coth(z)
csch(z)
sech(z)
acoth(z)
acsch(z)
asech(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coth+2B2Ccsch+2B2Csech+2B2C+2B20etc._+3A_z">z</code></td>
<td>
<p>numeric or complex scalar or vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The usual hyperbolic cotangens, cosecans, and secans functions and
their inverses, computed through the other well known &ndash; in R &ndash;
hyperbolic sine, cosine, and tangens functions.
</p>


<h3>Value</h3>

<p>Result vector of numeric or complex values.
</p>


<h3>Note</h3>

<p>These function names are available in Matlab, that is the reason they have
been added to the &lsquo;pracma&rsquo; package.
</p>


<h3>See Also</h3>

<p>Trigonometric and hyperbolic functions in R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>coth(1+1i)      # 0.8680 - 0.2176i
csch(1+1i)      # 0.3039 - 0.6215i
sech(1+1i)      # 0.4983 - 0.5911i
acoth(1+1i)     # 0.4024 - 0.5536i
acsch(1+1i)     # 0.5306 - 0.4523i
asech(1+1i)     # 0.5306 - 1.1185i
</code></pre>

<hr>
<h2 id='cranknic'>
Crank-Nicolson Method
</h2><span id='topic+cranknic'></span>

<h3>Description</h3>

<p>The Crank-Nicolson method for solving ordinary differential equations is a
combination of the generic steps of the forward and backward Euler methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cranknic(f, t0, t1, y0, ..., N = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cranknic_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y' = f(x, y)</code>;<br />
defined as a function <code class="reqn">R \times R^m \rightarrow R^m</code>, where
<code class="reqn">m</code> is the number of equations.</p>
</td></tr>
<tr><td><code id="cranknic_+3A_t0">t0</code>, <code id="cranknic_+3A_t1">t1</code></td>
<td>
<p>start and end points of the interval.</p>
</td></tr>
<tr><td><code id="cranknic_+3A_y0">y0</code></td>
<td>
<p>starting values as row or column vector;
for <code class="reqn">m</code> equations <code>y0</code> needs to be a vector of length <code>m</code>.</p>
</td></tr>
<tr><td><code id="cranknic_+3A_n">N</code></td>
<td>
<p>number of steps.</p>
</td></tr>
<tr><td><code id="cranknic_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adding together forward and backword Euler method in the <code>cranknic</code>
method is by finding the root of the function merging these two formulas.
</p>
<p>No attempt is made to catch any errors in the root finding functions.
</p>


<h3>Value</h3>

<p>List with components <code>t</code> for grid (or &lsquo;time&rsquo;) points between <code>t0</code>
and <code>t1</code>, and <code>y</code> an n-by-m matrix with solution variables in
columns, i.e. each row contains one time stamp.
</p>


<h3>Note</h3>

<p>This is for demonstration purposes only; for real problems or applications
please use <code>ode23</code> or <code>rkf54</code>.
</p>


<h3>References</h3>

<p>Quarteroni, A., and F. Saleri (2006). Scientific Computing With MATLAB and
Octave. Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ode23">ode23</a></code>, <code><a href="#topic+newmark">newmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Newton's example
f &lt;- function(x, y) 1 - 3*x + y + x^2 + x*y
sol100  &lt;- cranknic(f, 0, 1, 0, N = 100)
sol1000 &lt;- cranknic(f, 0, 1, 0, N = 1000)

## Not run: 
# Euler's forward approach
feuler &lt;- function(f, t0, t1, y0, n) {
    h &lt;- (t1 - t0)/n;  x &lt;- seq(t0, t1, by = h)
    y &lt;- numeric(n+1); y[1] &lt;- y0
    for (i in 1:n) y[i+1] &lt;- y[i] + h * f(x[i], y[i])
    return(list(x = x, y = y))
}

solode &lt;- ode23(f, 0, 1, 0)
soleul &lt;- feuler(f, 0, 1, 0, 100)

plot(soleul$x, soleul$y, type = "l", col = "blue", 
     xlab = "", ylab = "", main = "Newton's example")
lines(solode$t, solode$y, col = "gray", lwd = 3)
lines(sol100$t, sol100$y, col = "red")
lines(sol1000$t, sol1000$y, col = "green")
grid()

##  System of differential equations
# "Herr und Hund"
fhh &lt;- function(x, y) {
    y1 &lt;- y[1]; y2 &lt;- y[2]
    s &lt;- sqrt(y1^2 + y2^2)
    dy1 &lt;- 0.5 - 0.5*y1/s
    dy2 &lt;- -0.5*y2/s
    return(c(dy1, dy2))
}

sol &lt;- cranknic(fhh, 0, 60, c(0, 10))
plot(sol$y[, 1], sol$y[, 2], type = "l", col = "blue",
     xlab = "", ylab = "", main = '"Herr und Hund"')
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='cross'>Vector Cross Product</h2><span id='topic+cross'></span>

<h3>Description</h3>

<p>Vector or cross product
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  cross(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cross_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="cross_+3A_y">y</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the cross (or: vector) product of vectors in 3 dimensions.
In case of matrices it takes the first dimension of length 3 and
computes the cross product between corresponding columns or rows.
</p>
<p>The more general cross product of <code>n-1</code> vectors in n-dimensional
space is realized as <code>crossn</code>.
</p>


<h3>Value</h3>

<p>3-dim. vector if <code>x</code> and <code>&lt;</code> are vectors, a matrix of
3-dim. vectors if <code>x</code> and <code>y</code> are matrices themselves.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dot">dot</a></code>, <code><a href="#topic+crossn">crossn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cross(c(1, 2, 3), c(4, 5, 6))  # -3  6 -3
</code></pre>

<hr>
<h2 id='crossn'>n-dimensional Vector Cross Product</h2><span id='topic+crossn'></span>

<h3>Description</h3>

<p>Vector cross product of <code>n-1</code> vectors in n-dimensional space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crossn(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crossn_+3A_a">A</code></td>
<td>
<p>matrix of size <code>(n-1) x n</code> where <code>n &gt;= 2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rows of the matrix <code>A</code> are taken as<code>(n-1)</code> vectors in
<code>n</code>-dimensional space. The cross product generates a vector in this
space that is orthogonal to all these rows in <code>A</code> and its length is
the volume of the geometric hypercube spanned by the vectors.
</p>


<h3>Value</h3>

<p>a vector of length <code>n</code>
</p>


<h3>Note</h3>

<p>The &lsquo;scalar triple product&rsquo; in <code class="reqn">R^3</code> can be defined as
</p>
<p><code>spatproduct &lt;- function(a, b, c) dot(a, crossn(b, c))</code>
</p>
<p>It represents the volume of the parallelepiped spanned by the three vectors.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cross">cross</a></code>, <code><a href="#topic+dot">dot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(1,0,0, 0,1,0), nrow=2, ncol=3, byrow=TRUE)
crossn(A)  #=&gt; 0 0 1

x &lt;- c(1.0, 0.0, 0.0)
y &lt;- c(1.0, 0.5, 0.0)
z &lt;- c(0.0, 0.0, 1.0)
identical(dot(x, crossn(rbind(y, z))), det(rbind(x, y, z)))
</code></pre>

<hr>
<h2 id='cubicspline'>
Interpolating Cubic Spline
</h2><span id='topic+cubicspline'></span>

<h3>Description</h3>

<p>Computes the natural interpolation cubic spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cubicspline(x, y, xi = NULL, endp2nd = FALSE, der = c(0, 0))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cubicspline_+3A_x">x</code>, <code id="cubicspline_+3A_y">y</code></td>
<td>
<p>x- and y-coordinates of points to be interpolated.</p>
</td></tr>
<tr><td><code id="cubicspline_+3A_xi">xi</code></td>
<td>
<p>x-coordinates of points at which the interpolation is to be
performed.</p>
</td></tr>
<tr><td><code id="cubicspline_+3A_endp2nd">endp2nd</code></td>
<td>
<p>logical; if true, the derivatives at the endpoints are
prescribed by <code>der</code>.</p>
</td></tr>
<tr><td><code id="cubicspline_+3A_der">der</code></td>
<td>
<p>a two-components vector prescribing derivatives at endpoints.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cubicspline</code> computes the values at <code>xi</code> of the natural 
interpolating cubic spline that interpolate the values <code>y</code> at the
nodes <code>x</code>. The derivatives at the endpoints can be prescribed.
</p>


<h3>Value</h3>

<p>Returns either the interpolated values at the points <code>xi</code> or, if
<code>is.null(xi)</code>, the piecewise polynomial that represents the spline.
</p>


<h3>Note</h3>

<p>From the piecewise polynomial returned one can easily generate the spline
function, see the examples.
</p>


<h3>References</h3>

<p>Quarteroni, Q., and F. Saleri (2006). Scientific Computing with Matlab
and Octave. Springer-Verlag Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+spline">spline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example: Average temperatures at different latitudes
x &lt;- seq(-55, 65, by = 10)
y &lt;- c(-3.25, -3.37, -3.35, -3.20, -3.12, -3.02, -3.02,
       -3.07, -3.17, -3.32, -3.30, -3.22, -3.10)
xs &lt;- seq(-60, 70, by = 1)

# Generate a function for this
pp &lt;- cubicspline(x, y)
ppfun &lt;- function(xs) ppval(pp, xs)

## Not run: 
# Plot with and without endpoint correction
plot(x, y, col = "darkblue",
           xlim = c(-60, 70), ylim = c(-3.5, -2.8),
           xlab = "Latitude", ylab = "Temp. Difference",
           main = "Earth Temperatures per Latitude")
lines(spline(x, y), col = "darkgray")
grid()

ys &lt;- cubicspline(x, y, xs, endp2nd = TRUE)     # der = 0 at endpoints
lines(xs, ys, col = "red")
ys &lt;- cubicspline(x, y, xs)                     # no endpoint condition
lines(xs, ys, col = "darkred")

## End(Not run)
</code></pre>

<hr>
<h2 id='curvefit'>
Parametric Curve Fit
</h2><span id='topic+curvefit'></span>

<h3>Description</h3>

<p>Polynomial fitting of parametrized points on 2D curves, also
requiring to meet some points exactly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>curvefit(u, x, y, n, U = NULL, V = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="curvefit_+3A_u">u</code></td>
<td>
<p>the parameter vector.</p>
</td></tr>
<tr><td><code id="curvefit_+3A_x">x</code>, <code id="curvefit_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates for each parameter value.</p>
</td></tr>
<tr><td><code id="curvefit_+3A_n">n</code></td>
<td>
<p>order of the polynomials, the same in x- and y-dirction.</p>
</td></tr>
<tr><td><code id="curvefit_+3A_u">U</code></td>
<td>
<p>parameter values where points will be fixed.</p>
</td></tr>
<tr><td><code id="curvefit_+3A_v">V</code></td>
<td>
<p>matrix with two columns and <code>lemgth(U)</code> rows;
first column contains the x-, the second the y-values of those
points kept fixed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will attempt to fit two polynomials to parametrized curve 
points using the linear least squares approach with linear equality 
constraints in <code>lsqlin</code>. The requirement to meet exactly some fixed 
points is interpreted as a linear equality constraint.
</p>


<h3>Value</h3>

<p>Returns a list with 4 components, <code>xp</code> and <code>yp</code> coordinates of 
the fitted points, and <code>px</code> and <code>py</code> the coefficients of the
fitting polynomials in x- and y-direction.
</p>


<h3>Note</h3>

<p>In the same manner, derivatives/directions could be prescribed at certain
points.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+circlefit">circlefit</a></code>, <code><a href="#topic+lsqlin">lsqlin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Approximating half circle arc with small perturbations
N &lt;- 50
u &lt;- linspace(0, pi, N)
x &lt;- cos(u) + 0.05 * randn(1, N)
y &lt;- sin(u) + 0.05 * randn(1, N)
n &lt;- 8
cfit1 &lt;- curvefit(u, x, y, n)
## Not run: 
plot(x, y, col = "darkgray", pch = 19, asp = 1)
xp &lt;- cfit1$xp; yp &lt;- cfit1$yp
lines(xp, yp, col="blue")
grid()
## End(Not run)

##  Fix the end points at t = 0 and t = pi
U &lt;- c(0, pi)
V &lt;- matrix(c(1, 0, -1, 0), 2, 2, byrow = TRUE)
cfit2 &lt;- curvefit(u, x, y, n, U, V)
## Not run: 
xp &lt;- cfit2$xp; yp &lt;- cfit2$yp
lines(xp, yp, col="red")
## End(Not run)

## Not run: 
##  Archimedian spiral
n &lt;- 8
u &lt;- linspace(0, 3*pi, 50)
a &lt;- 1.0
x &lt;- as.matrix(a*u*cos(u))
y &lt;- as.matrix(a*u*sin(u))
plot(x, y, type = "p", pch = 19, col = "darkgray", asp = 1)
lines(x, y, col = "darkgray", lwd = 3)
cfit &lt;- curvefit(u, x, y, n)
px &lt;- c(cfit$px); py &lt;- c(cfit$py)
v &lt;- linspace(0, 3*pi, 200)
xs &lt;- polyval(px, v)
ys &lt;- polyval(py, v)
lines(xs, ys, col = "navy")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='cutpoints'>
Find Cutting Points
</h2><span id='topic+cutpoints'></span>

<h3>Description</h3>

<p>Finds cutting points for vector s of real numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutpoints(x, nmax = 8, quant = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cutpoints_+3A_x">x</code></td>
<td>
<p>vector of real values.</p>
</td></tr>
<tr><td><code id="cutpoints_+3A_nmax">nmax</code></td>
<td>
<p>the maximum number of cutting points to choose</p>
</td></tr>
<tr><td><code id="cutpoints_+3A_quant">quant</code></td>
<td>
<p>quantile of the gaps to consider for cuts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds cutting points for vector s of real numbers, based on the gaps in
the values of the vector. The number of cutting points is derived from a
quantile of gaps in the values. The user can set a lower limit for this
number of gaps.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>cutp</code>, the cutting points selected,
and <code>cutd</code>, the gap between values of <code>x</code> at this cutting point.
</p>


<h3>Note</h3>

<p>Automatically finding cutting points is often requested in Data Mining.
If a target attribute is available, Quinlan's C5.0 does a very good job
here. Unfortunately, the &lsquo;C5.0&rsquo; package (of the R-Forge project &ldquo;Rulebased
Models&rdquo;) is quite cumbersome to use.
</p>


<h3>References</h3>

<p>Witten, I. H., and E. Frank (2005). Data Mining: Practical Machine
Learning Tools and Techniques. Morgan Kaufmann Publishers, San Francisco.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 100; x &lt;- sort(runif(N))
cp &lt;- cutpoints(x, 6, 0.9)
n &lt;- length(cp$cutp)

# Print out
nocp &lt;- rle(findInterval(x, c(-Inf, cp$cutp, Inf)))$lengths
cbind(c(-Inf, cp$cutp), c(cp$cutp, Inf), nocp)

# Define a factor from the cutting points
fx &lt;- cut(x, breaks = c(-Inf, cp$cutp, Inf))

## Not run: 
# Plot points and cutting points
plot(x, rep(0, N), col="gray", ann = FALSE)
points(cp$cutp, rep(0, n), pch="|", col=2)

# Compare with k-means clustering
km &lt;- kmeans(x, n)
points(x, rep(0, N), col = km$cluster, pch = "+")

##  A 2-dimensional example
x &lt;- y &lt;- c()
for (i in 1:9) {
  for (j in 1:9) {
    x &lt;- c(x, i + rnorm(20, 0, 0.2))
    y &lt;- c(y, j + rnorm(20, 0, 0.2))
  }
}
cpx &lt;- cutpoints(x, 8, 0)
cpy &lt;- cutpoints(y, 8, 0)

plot(x, y, pch = 18, col=rgb(0.5,0.5,0.5), axes=FALSE, ann=FALSE)
for (xi in cpx$cutp) abline(v=xi, col=2, lty=2)
for (yi in cpy$cutp) abline(h=yi, col=2, lty=2)

km &lt;- kmeans(cbind(x, y), 81)
points(x, y, col=km$cluster)

## End(Not run)
</code></pre>

<hr>
<h2 id='dblquad'>
Double and Triple Integration
</h2><span id='topic+dblquad'></span><span id='topic+triplequad'></span>

<h3>Description</h3>

<p>Numerically evaluate double integral over rectangle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dblquad(f, xa, xb, ya, yb, dim = 2, ..., 
        subdivs = 300, tol = .Machine$double.eps^0.5)

triplequad(f, xa, xb, ya, yb, za, zb, 
            subdivs = 300, tol = .Machine$double.eps^0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dblquad_+3A_f">f</code></td>
<td>
<p>function of two variables, the integrand.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_xa">xa</code>, <code id="dblquad_+3A_xb">xb</code></td>
<td>
<p>left and right endpoint for first variable.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_ya">ya</code>, <code id="dblquad_+3A_yb">yb</code></td>
<td>
<p>left and right endpoint for second variable.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_za">za</code>, <code id="dblquad_+3A_zb">zb</code></td>
<td>
<p>left and right endpoint for third variable.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_dim">dim</code></td>
<td>
<p>which variable to integrate first.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_subdivs">subdivs</code></td>
<td>
<p>number of subdivisions to use.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_tol">tol</code></td>
<td>
<p>relative tolerance to use in <code>integrate</code>.</p>
</td></tr>
<tr><td><code id="dblquad_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the integrand.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>dblquad</code> applies the internal single variable integration
function <code>integrate</code> two times, once for each variable.
</p>
<p>Function <code>triplequad</code> reduces the problem to <code>dblquad</code> by
first integrating over the innermost variable.
</p>


<h3>Value</h3>

<p>Numerical scalar, the value of the integral.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+quad2d">quad2d</a></code>, <code><a href="#topic+simpson2d">simpson2d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f1 &lt;- function(x, y) x^2 + y^2
dblquad(f1, -1, 1, -1, 1)       #   2.666666667 , i.e. 8/3 . err = 0

f2 &lt;- function(x, y) y*sin(x)+x*cos(y)
dblquad(f2, pi, 2*pi, 0, pi)    #  -9.869604401 , i.e. -pi^2, err = 0

# f3 &lt;- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2 &lt;= 1))
f3 &lt;- function(x, y) sqrt(pmax(0, 1 - (x^2 + y^2)))
dblquad(f3, -1, 1, -1, 1)       #   2.094395124 , i.e. 2/3*pi , err = 2e-8

f4 &lt;- function(x, y, z) y*sin(x)+z*cos(x)
triplequad(f4, 0,pi, 0,1, -1,1) # - 2.0 =&gt; -2.220446e-16
</code></pre>

<hr>
<h2 id='deconv'>Deconvolution</h2><span id='topic+deconv'></span>

<h3>Description</h3>

<p>Deconvolution and polynomial division.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deconv(b, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deconv_+3A_b">b</code>, <code id="deconv_+3A_a">a</code></td>
<td>
<p>real or complex vectors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>deconv(b,a)</code> deconvolves vector <code>a</code> out of vector <code>b</code>.
The quotient is returned in vector <code>q</code> and the remainder in vector
<code>r</code> such that <code>b = conv(a,q)+r</code>.
</p>
<p>If <code>b</code> and <code>a</code> are vectors of polynomial coefficients,
convolving them is equivalent to multiplying the two polynomials,
and deconvolution is polynomial division.
</p>


<h3>Value</h3>

<p>List with elements named <code>q</code> and <code>r</code>.
</p>


<h3>Note</h3>

<p>TODO: Base <code>deconv</code> on some <code>filter1d</code> function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+conv">conv</a></code>, <code><a href="#topic+polymul">polymul</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>b &lt;- c(10, 40, 100, 160, 170, 120)
a &lt;- c(1, 2, 3, 4)

p &lt;- deconv(b, a)
p$q                #=&gt; 10 20 30
p$r                #=&gt;  0  0  0
</code></pre>

<hr>
<h2 id='deeve'>
Event Detection in ODE solution
</h2><span id='topic+deeve'></span>

<h3>Description</h3>

<p>Detect events in solutions of a differential equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deeve(x, y, yv = 0, idx = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deeve_+3A_x">x</code></td>
<td>
<p>vector of (time) points at which the differential equation
has been solved.</p>
</td></tr>
<tr><td><code id="deeve_+3A_y">y</code></td>
<td>
<p>values of the function(s) that have been computed for the
given (time) points.</p>
</td></tr>
<tr><td><code id="deeve_+3A_yv">yv</code></td>
<td>
<p>point or numeric vector at which the solution is wanted.</p>
</td></tr>
<tr><td><code id="deeve_+3A_idx">idx</code></td>
<td>
<p>index of functions whose vales shall be returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Determines when (in <code>x</code> coordinates) the <code>idx</code>-th solution
function will take on the value <code>yv</code>.
</p>
<p>The interpolation is linear for the moment. For points outside the
<code>x</code> interval <code>NA</code> is returned.
</p>


<h3>Value</h3>

<p>A (time) point <code>x0</code> at which the event happens.
</p>


<h3>Note</h3>

<p>The interpolation is linear only for the moment.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+deval">deval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Damped pendulum:  y'' = -0.3 y' - sin(y)
#   y1 = y, y2 = y':  y1' = y2,  y2' = -0.3*y2 - sin(y1)
f &lt;- function(t, y) {
	dy1 &lt;- y[2]
	dy2 &lt;- -0.3*y[2] - sin(y[1])
	return(c(dy1, dy2))
}
sol &lt;- rk4sys(f, 0, 10, c(pi/2, 0), 100)
deeve(sol$x, sol$y[,1])                   # y1 = 0 : elongation in [sec]
# [1] 2.073507 5.414753 8.650250
# matplot(sol$x, sol$y); grid()
</code></pre>

<hr>
<h2 id='deg2rad'>Degrees to Radians</h2><span id='topic+deg2rad'></span><span id='topic+rad2deg'></span>

<h3>Description</h3>

<p>Transforms between angles in degrees and radians.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deg2rad(deg)
rad2deg(rad)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deg2rad_+3A_deg">deg</code></td>
<td>
<p>(array of) angles in degrees.</p>
</td></tr>
<tr><td><code id="deg2rad_+3A_rad">rad</code></td>
<td>
<p>(array of) angles in radians.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a simple calculation back and forth. Note that angles greater than
360 degrees are allowed and will be returned. This may appear incorrect but
follows a corresponding discussion on Matlab Central.
</p>


<h3>Value</h3>

<p>The angle in degrees or radians.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>deg2rad(c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90))
rad2deg(seq(-pi/2, pi/2, length = 19))
</code></pre>

<hr>
<h2 id='detrend'>
Remove Linear Trends
</h2><span id='topic+detrend'></span>

<h3>Description</h3>

<p>Removes the mean value or (piecewise) linear trend from a vector or
from each column of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detrend(x, tt = 'linear', bp = c())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detrend_+3A_x">x</code></td>
<td>
<p>vector or matrix, columns considered as the time series.</p>
</td></tr>
<tr><td><code id="detrend_+3A_tt">tt</code></td>
<td>
<p>trend type, &lsquo;constant&rsquo; or &lsquo;linear&rsquo;, default is &lsquo;linear&rsquo;.</p>
</td></tr>
<tr><td><code id="detrend_+3A_bp">bp</code></td>
<td>
<p>break points, indices between 1 and <code>nrow(x)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>detrend</code> computes the least-squares fit of a straight line (or
composite line for piecewise linear trends) to the data and subtracts the
resulting function from the data.
</p>
<p>To obtain the equation of the straight-line fit, use <code>polyfit</code>.
</p>


<h3>Value</h3>

<p>removes the mean or (piecewise) linear trend from <code>x</code> and returns it
in <code>y=detrend(x)</code>, that is <code>x-y</code> <em>is</em> the linear trend.
</p>


<h3>Note</h3>

<p>Detrending is often used for FFT processing.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyfit">polyfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>t &lt;- 1:9
x &lt;- c(0, 2, 0, 4, 4, 4, 0, 2, 0)
x - detrend(x, 'constant')
x - detrend(x, 'linear')

y &lt;- detrend(x, 'linear', 5)
## Not run: 
plot(t, x, col="blue")
lines(t, x - y, col="red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='deval'>
Evaluate ODE Solution
</h2><span id='topic+deval'></span>

<h3>Description</h3>

<p>Evaluate solution of a differential equation solver.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deval(x, y, xp, idx = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deval_+3A_x">x</code></td>
<td>
<p>vector of (time) points at which the differential equation
has been solved.</p>
</td></tr>
<tr><td><code id="deval_+3A_y">y</code></td>
<td>
<p>values of the function(s) that have been computed for the
given (time) points.</p>
</td></tr>
<tr><td><code id="deval_+3A_xp">xp</code></td>
<td>
<p>point or numeric vector at which the solution is wanted;
must be sorted.</p>
</td></tr>
<tr><td><code id="deval_+3A_idx">idx</code></td>
<td>
<p>index of functions whose vales shall be returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Determines where the points <code>xp</code> lie within the vector <code>x</code>
and interpolates linearly.
</p>


<h3>Value</h3>

<p>An <code>length(xp)</code>-by-<code>length(idx)</code> matrix of values at points
<code>xp</code>.
</p>


<h3>Note</h3>

<p>The interpolation is linear only for the moment.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+deeve">deeve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Free fall:  v' = -g - cw abs(v)^1.1,  cw = 1.6 drag coefficien
f &lt;- function(t, y) -9.81 + 1.6*abs(y)^1.1
sol &lt;- rk4(f, 0, 10, 0, 100)
# speed after 0.5, 1, 1.5, 2 seconds
cbind(c(0.5,1,1.5,2), -deval(sol$x, sol$y, c(0.5, 1, 1.5, 2)))
#  0.5  3.272267  m/s
#  1.0  4.507677
#  1.5  4.953259
#  2.0  5.112068
# plot(sol$x, -sol$y, type="l", col="blue"); grid()
</code></pre>

<hr>
<h2 id='Diag'>Matrix Diagonal</h2><span id='topic+Diag'></span>

<h3>Description</h3>

<p>Generate diagonal matrices or return diagonal of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Diag(x, k = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Diag_+3A_x">x</code></td>
<td>
<p>vector or matrix</p>
</td></tr>
<tr><td><code id="Diag_+3A_k">k</code></td>
<td>
<p>integer indicating a secondary diagonal</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> is a vector, <code>Diag(x, k)</code> generates a matrix with <code>x</code>
as the (k-th secondary) diagonal.
</p>
<p>If <code>x</code> is a matrix, <code>Diag(x, k)</code> returns the (<code>k</code>-th secondary) diagonal of <code>x</code>.
</p>
<p>The <code>k</code>-th secondary diagonal is above the main diagonal for <code>k &gt; 0</code>
and below the main diagonal for <code>k &lt; 0</code>.
</p>


<h3>Value</h3>

<p>matrix or vector
</p>


<h3>Note</h3>

<p>In Matlab/Octave this function is called <code>diag()</code> and has a different
signature than the corresponding function in <span class="rlang"><b>R</b></span>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+diag">diag</a></code>, <code><a href="#topic+Trace">Trace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Diag(matrix(1:12,3,4),  1)
Diag(matrix(1:12,3,4), -1)

Diag(c(1,5,9), 1)
Diag(c(1,5,9), -1)
</code></pre>

<hr>
<h2 id='disp+2Cbeep'>
Utility functions (Matlab style)
</h2><span id='topic+disp'></span><span id='topic+beep'></span>

<h3>Description</h3>

<p>Display text or array, or produce beep sound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disp(...)
beep()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disp+2B2Cbeep_+3A_...">...</code></td>
<td>
<p>any R object that can be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Display text or array, or produces the computer's default beep sound
using &lsquo;cat&rsquo; with closing newline.
</p>


<h3>Value</h3>

<p>beep() returns NULL invisibly, disp() displays with newline.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>disp("Some text, and numbers:", pi, exp(1))
# beep()
</code></pre>

<hr>
<h2 id='distmat'>Distance Matrix</h2><span id='topic+distmat'></span><span id='topic+pdist'></span><span id='topic+pdist2'></span>

<h3>Description</h3>

<p>Computes the Euclidean distance between rows of two matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distmat(X, Y)
pdist(X)
pdist2(X, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distmat_+3A_x">X</code></td>
<td>
<p>matrix of some size <code>m x k</code>; vector will be taken as row matrix.</p>
</td></tr>
<tr><td><code id="distmat_+3A_y">Y</code></td>
<td>
<p>matrix of some size <code>n x k</code>; vector will be taken as row matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes Euclidean distance between two vectors A and B as:
</p>
<p><code>||A-B|| = sqrt ( ||A||^2 + ||B||^2 - 2*A.B )</code>
</p>
<p>and vectorizes to rows of two matrices (or vectors).
</p>
<p><code>pdist2</code> is an alias for <code>distmat</code>, while <code>pdist(X)</code> is the
same as <code>distmat(X, X)</code>.
</p>


<h3>Value</h3>

<p>matrix of size <code>m x n</code> if <code>x</code> is of size <code>m x k</code> and
<code>y</code> is of size <code>n x k</code>.
</p>


<h3>Note</h3>

<p>If <code>a</code> is <code>m x r</code> and <code>b</code> is <code>n x r</code> then 
</p>
<p><code>apply(outer(a,t(b),"-"),c(1,4),function(x)sqrt(sum(diag(x*x))))</code>
</p>
<p>is the <code>m x n</code> matrix of distances between the <code>m</code> rows
of <code>a</code> and <code>n</code> rows of <code>b</code>.
</p>
<p>This can be modified as necessary, if one wants to apply distances other
than the euclidean.
</p>
<p>BUT: The code shown here is 10-100 times faster, utilizing the similarity
between Euclidean distance and matrix operations.
</p>


<h3>References</h3>

<p>Copyright (c) 1999 Roland Bunschoten for a Matlab version on MatlabCentral
under the name <code>distance.m</code>. Translated to R by Hans W Borchers.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- c(0.0, 0.0)
B &lt;- matrix(c(
        0,0, 1,0, 0,1, 1,1), nrow=4, ncol = 2, byrow = TRUE)
distmat(A, B)  #=&gt; 0 1 1 sqrt(2)

X &lt;- matrix(rep(0.5, 5), nrow=1, ncol=5)
Y &lt;- matrix(runif(50), nrow=10, ncol=5)
distmat(X, Y)

# A more vectorized form of distmat:
distmat2 &lt;- function(x, y) {
    sqrt(outer(rowSums(x^2), rowSums(y^2), '+') - tcrossprod(x, 2 * y))
}
</code></pre>

<hr>
<h2 id='dot'>Scalar Product</h2><span id='topic+dot'></span>

<h3>Description</h3>

<p>'dot' or 'scalar' product of vectors or pairwise columns of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  dot(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dot_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="dot_+3A_y">y</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the 'dot' or 'scalar' product of vectors or columns of matrices.
Two vectors must be of same length, two matrices must be of
the same size.
If <code>x</code> and <code>y</code> are column or row vectors, their dot product
will be computed as if they were simple vectors.
</p>


<h3>Value</h3>

<p>A scalar or vector of length the number of columns of <code>x</code> and
<code>y</code>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cross">cross</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  dot(1:5, 1:5)  #=&gt; 55
  # Length of space diagonal in 3-dim- cube:
  sqrt(dot(c(1,1,1), c(1,1,1)))  #=&gt; 1.732051
</code></pre>

<hr>
<h2 id='eig'>Eigenvalue Function (Matlab Style)</h2><span id='topic+eig'></span>

<h3>Description</h3>

<p>Eigenvalues of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  eig(a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eig_+3A_a">a</code></td>
<td>
<p>real or complex square matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the eigenvalues of a square matrix of real or complex numbers,
using the R routine <code>eigen</code> without computing the eigenvectors.
</p>


<h3>Value</h3>

<p>Vector of eigenvalues
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compan">compan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  eig(matrix(c(1,-1,-1,1), 2, 2))   #=&gt; 2 0
  eig(matrix(c(1,1,-1,1), 2, 2))    # complex values
  eig(matrix(c(0,1i,-1i,0), 2, 2))  # real values
</code></pre>

<hr>
<h2 id='eigjacobi'>
Jacobi Eigenvalue Method
</h2><span id='topic+eigjacobi'></span>

<h3>Description</h3>

<p>Jacobi's iteration method for eigenvalues and eigenvectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigjacobi(A, tol = .Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eigjacobi_+3A_a">A</code></td>
<td>
<p>a real symmetric matrix.</p>
</td></tr>
<tr><td><code id="eigjacobi_+3A_tol">tol</code></td>
<td>
<p>requested tolerance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Jacobi eigenvalue method repeatedly performs (Givens) transformations
until the matrix becomes almost diagonal.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>V</code>, a matrix containing the
eigenvectors as columns, and <code>D</code> a vector of the eigenvalues.
</p>


<h3>Note</h3>

<p>This R implementation works well up to 50x50-matrices. 
</p>


<h3>References</h3>

<p>Mathews, J. H., and K. D. Fink (2004). Numerical Methods Using Matlab.
Fourth edition, Pearson education, Inc., New Jersey.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+eig">eig</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c( 1.06, -0.73,  0.77, -0.67,
              -0.73,  2.64,  1.04,  0.72,
               0.77,  1.04,  3.93, -2.14,
              -0.67,  0.72, -2.14,  2.04), 4, 4, byrow = TRUE)
eigjacobi(A)
# $V
#            [,1]       [,2]       [,3]       [,4]
# [1,] 0.87019414 -0.3151209  0.1975473 -0.3231656
# [2,] 0.11138094  0.8661855  0.1178032 -0.4726938
# [3,] 0.07043799  0.1683401  0.8273261  0.5312548
# [4,] 0.47475776  0.3494040 -0.5124734  0.6244140
# 
# $D
# [1] 0.66335457 3.39813189 5.58753257 0.02098098
</code></pre>

<hr>
<h2 id='einsteinF'>
Einstein Functions
</h2><span id='topic+einsteinF'></span>

<h3>Description</h3>

<p>Einstein functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>einsteinF(d, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="einsteinF_+3A_x">x</code></td>
<td>
<p>numeric or complex vector.</p>
</td></tr>
<tr><td><code id="einsteinF_+3A_d">d</code></td>
<td>
<p>parameter to select one of the Einstein functions E1, E2, E3, E4.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Einstein functions are sometimes used for the Planck-Einstein
oscillator in one degree of freedom.
</p>
<p>The functions are defined as:
</p>
<p style="text-align: center;"><code class="reqn">E1(x) = \frac{x^2 e^x}{(e^x - 1)^2}</code>
</p>

<p style="text-align: center;"><code class="reqn">E2(x) = \frac{x}{e^x - 1}</code>
</p>

<p style="text-align: center;"><code class="reqn">E3(x) = ln(1 - e^{-x})</code>
</p>

<p style="text-align: center;"><code class="reqn">E4(x) = \frac{x}{e^x - 1} - ln(1 - e^{-x})</code>
</p>

<p><code>E1</code> has an inflection point as <code>x=2.34694130...</code>.
</p>


<h3>Value</h3>

<p>Numeric/complex scalar or vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x1 &lt;- seq(-4, 4, length.out = 101)
y1 &lt;- einsteinF(1, x1)
plot(x1, y1, type = "l", col = "red",
             xlab = "", ylab = "", main = "Einstein Function E1(x)")
grid()

y2 &lt;- einsteinF(2, x1)
plot(x1, y2, type = "l", col = "red",
             xlab = "", ylab = "", main = "Einstein Function E2(x)")
grid()

x3 &lt;- seq(0, 5, length.out = 101)
y3 &lt;- einsteinF(3, x3)
plot(x3, y3, type = "l", col = "red",
             xlab = "", ylab = "", main = "Einstein Function E3(x)")
grid()

y4 &lt;- einsteinF(4, x3)
plot(x3, y4, type = "l", col = "red",
             xlab = "", ylab = "", main = "Einstein Function E4(x)")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='ellipke+2Cellipj'>
Elliptic and Jacobi Elliptic Integrals
</h2><span id='topic+ellipke'></span><span id='topic+ellipj'></span>

<h3>Description</h3>

<p>Complete elliptic integrals of the first and second kind, and
Jacobi elliptic integrals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ellipke(m, tol = .Machine$double.eps)

ellipj(u, m, tol = .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ellipke+2B2Cellipj_+3A_u">u</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="ellipke+2B2Cellipj_+3A_m">m</code></td>
<td>
<p>input vector, all input elements must satisfy <code>0 &lt;= x &lt;= 1</code>.</p>
</td></tr>
<tr><td><code id="ellipke+2B2Cellipj_+3A_tol">tol</code></td>
<td>
<p>tolerance; default is machine precision.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ellipke</code> computes the complete elliptic integrals to accuracy 
<code>tol</code>, based on the algebraic-geometric mean.
</p>
<p><code>ellipj</code> computes the Jacobi elliptic integrals <code>sn</code>, <code>cn</code>,
and <code>dn</code>. For instance, <code class="reqn">sn</code> is the inverse function for
</p>
<p style="text-align: center;"><code class="reqn">u = \int_0^\phi dt / \sqrt{1 - m \sin^2 t}</code>
</p>

<p>with <code class="reqn">sn(u) = \sin(\phi)</code>.
</p>
<p>Some definitions of the elliptic functions use the modules <code>k</code> instead
of the parameter <code>m</code>. They are related by <code>k^2=m=sin(a)^2</code> where
<code>a</code> is the &lsquo;modular angle&rsquo;.
</p>


<h3>Value</h3>

<p><code>ellipke</code> returns list with two components, <code>k</code> the values for 
the first kind, <code>e</code> the values for the second kind.
</p>
<p><code>ellipj</code> returns a list with components the three Jacobi elliptic
integrals <code>sn</code>, <code>cn</code>, and <code>dn</code>.
</p>


<h3>References</h3>

<p>Abramowitz, M., and I. A. Stegun (1965).
Handbook of Mathematical Functions. Dover Publications, New York.
</p>


<h3>See Also</h3>

<p><code>elliptic::sn,cn,dn</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- linspace(0, 1, 20)
ke &lt;- ellipke(x)

## Not run: 
plot(x, ke$k, type = "l", col ="darkblue", ylim = c(0, 5),
     main = "Elliptic Integrals")
lines(x, ke$e, col = "darkgreen")
legend( 0.01, 4.5,
        legend = c("Elliptic integral of first kind",
                   "Elliptic integral of second kind"),
        col = c("darkblue", "darkgreen"), lty = 1)
grid()
## End(Not run)

## ellipse circumference with axes a, b
ellipse_cf &lt;- function(a, b) {
    return(4*a*ellipke(1 - (b^2/a^2))$e)
}
print(ellipse_cf(1.0, 0.8), digits = 10)
# [1] 5.672333578

## Jacobi elliptic integrals
u &lt;- c(0, 1, 2, 3, 4, 5)
m &lt;- seq(0.0, 1.0, by = 0.2)
je &lt;- ellipj(u, m)
# $sn       0.0000  0.8265  0.9851  0.7433  0.4771  0.9999
# $cn       1.0000  0.5630 -0.1720 -0.6690 -0.8789  0.0135
# $dn       1.0000  0.9292  0.7822  0.8176  0.9044  0.0135
je$sn^2 + je$cn^2       # 1 1 1 1 1 1
je$dn^2 + m * je$sn^2   # 1 1 1 1 1 1
</code></pre>

<hr>
<h2 id='eps'>
Floating Point Relative Accuracy
</h2><span id='topic+eps'></span>

<h3>Description</h3>

<p>Distance from 1.0 to the next largest double-precision number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eps(x = 1.0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eps_+3A_x">x</code></td>
<td>
<p>scalar or numerical vector or matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>d=eps(x)</code> is the positive distance from <code>abs(x)</code> to the next 
larger floating point number in double precision.
</p>
<p>If <code>x</code> is an array, <code>eps(x)</code> will return <code>eps(max(abs(x)))</code>.
</p>


<h3>Value</h3>

<p>Returns a scalar.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>for (i in -5:5) cat(eps(10^i), "\n")
# 1.694066e-21 
# 1.355253e-20 
# 2.168404e-19 
# 1.734723e-18 
# 1.387779e-17 
# 2.220446e-16 
# 1.776357e-15 
# 1.421085e-14 
# 1.136868e-13 
# 1.818989e-12 
# 1.455192e-11 
</code></pre>

<hr>
<h2 id='erf'>
Error Functions and Inverses (Matlab Style)
</h2><span id='topic+erf'></span><span id='topic+erfinv'></span><span id='topic+erfc'></span><span id='topic+erfcinv'></span><span id='topic+erfcx'></span><span id='topic+erfz'></span><span id='topic+erfi'></span>

<h3>Description</h3>

<p>The error or Phi function is a variant of the cumulative normal (or
Gaussian) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erf(x)
erfinv(y)
erfc(x)
erfcinv(y)
erfcx(x)

erfz(z)
erfi(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="erf_+3A_x">x</code>, <code id="erf_+3A_y">y</code></td>
<td>
<p>vector of real numbers.</p>
</td></tr>
<tr><td><code id="erf_+3A_z">z</code></td>
<td>
<p>real or complex number; must be a scalar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>erf</code> and <code>erfinv</code> are the error and inverse error functions.<br />
<code>erfc</code> and <code>erfcinv</code> are the complementary error function and
its inverse.<br />
<code>erfcx</code> is the scaled complementary error function.<br />
<code>erfz</code> is the complex, <code>erfi</code> the imaginary error function.
</p>


<h3>Value</h3>

<p>Real or complex number(s), the value(s) of the function.
</p>


<h3>Note</h3>

<p>For the complex error function we used Fortran code from the book 
S. Zhang &amp; J. Jin &ldquo;Computation of Special Functions&rdquo; (Wiley, 1996).
</p>


<h3>Author(s)</h3>

<p>First version by Hans W Borchers;
vectorized version of <code>erfz</code> by Michael Lachmann.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- 1.0
  erf(x); 2*pnorm(sqrt(2)*x) - 1
# [1] 0.842700792949715
# [1] 0.842700792949715
  erfc(x); 1 - erf(x); 2*pnorm(-sqrt(2)*x)
# [1] 0.157299207050285
# [1] 0.157299207050285
# [1] 0.157299207050285
  erfz(x)
# [1] 0.842700792949715
  erfi(x)
# [1] 1.650425758797543
</code></pre>

<hr>
<h2 id='errorbar'>
Plot Error Bars
</h2><span id='topic+errorbar'></span>

<h3>Description</h3>

<p>Draws symmetric error bars in x- and/or y-direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorbar(x, y, xerr = NULL, yerr = NULL,
         bar.col = "red", bar.len = 0.01,
         grid = TRUE, with = TRUE, add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorbar_+3A_x">x</code>, <code id="errorbar_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates</p>
</td></tr>
<tr><td><code id="errorbar_+3A_xerr">xerr</code>, <code id="errorbar_+3A_yerr">yerr</code></td>
<td>
<p>length of the error bars, relative to the x-, y-values.</p>
</td></tr>
<tr><td><code id="errorbar_+3A_bar.col">bar.col</code></td>
<td>
<p>color of the error bars; default: red</p>
</td></tr>
<tr><td><code id="errorbar_+3A_bar.len">bar.len</code></td>
<td>
<p>length of the cross bars orthogonal to the error bars;
default: 0.01.</p>
</td></tr>
<tr><td><code id="errorbar_+3A_grid">grid</code></td>
<td>
<p>logical; should the grid be plotted?; default: true</p>
</td></tr>
<tr><td><code id="errorbar_+3A_with">with</code></td>
<td>
<p>logical; whether to end the error bars with small cross bars.</p>
</td></tr>
<tr><td><code id="errorbar_+3A_add">add</code></td>
<td>
<p>logical; should the error bars be added to an existing plot?;
default: false.</p>
</td></tr>
<tr><td><code id="errorbar_+3A_...">...</code></td>
<td>
<p>additional plotting parameters that will be passed to the
<code>plot</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>errorbar</code> plots <code>y</code> versus <code>x</code> with symmetric error bars,
with a length determined by <code>xerr</code> resp. <code>yerr</code> in x- and/or
y-direction. If <code>xerr</code> or <code>yerr</code> is <code>NULL</code> error bars in
this direction will not be drawn.
</p>
<p>A future version will allow to draw unsymmetric error bars by specifying
upper and lower limits when <code>xerr</code> or <code>yerr</code> is a matrix of
size <code>(2 x length(x))</code>.
</p>


<h3>Value</h3>

<p>Generates a plot, no return value.
</p>


<h3>See Also</h3>

<p><code>plotrix::plotCI</code>, <code>Hmisc::errbar</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(0, 2*pi, length.out = 20)
y &lt;- sin(x)
xe &lt;- 0.1
ye &lt;- 0.1 * y
errorbar(x, y, xe, ye, type = "l", with = FALSE)

cnt &lt;- round(100*randn(20, 3))
y &lt;- apply(cnt, 1, mean)
e &lt;- apply(cnt, 1, sd)
errorbar(1:20, y, yerr = e, bar.col = "blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='eta'>
Dirichlet Eta Function
</h2><span id='topic+eta'></span>

<h3>Description</h3>

<p>Dirichlet's eta function valid in the entire complex plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eta(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eta_+3A_z">z</code></td>
<td>
<p>Real or complex number or a numeric or complex vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the eta function for complex arguments using a series expansion.
</p>
<p>Accuracy is about 13 significant digits for <code>abs(z)&lt;100</code>,
drops off with higher absolute values.
</p>


<h3>Value</h3>

<p>Returns a complex vector of function values.
</p>


<h3>Note</h3>

<p>Copyright (c) 2001 Paul Godfrey for a Matlab version available on
Mathwork's Matlab Central under BSD license.
</p>


<h3>References</h3>

<p>Zhang, Sh., and J. Jin (1996). Computation of Special Functions.
Wiley-Interscience, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gammaz">gammaz</a></code>, <code><a href="#topic+zeta">zeta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z &lt;- 0.5 + (1:5)*1i
eta(z)
z &lt;- c(0, 0.5+1i, 1, 1i, 2+2i, -1, -2, -1-1i)
eta(z)
</code></pre>

<hr>
<h2 id='euler_heun'>
Euler-Heun ODE Solver
</h2><span id='topic+euler_heun'></span>

<h3>Description</h3>

<p>Euler and Euler-Heun ODE solver.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euler_heun(f, a, b, y0, n = 100, improved = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euler_heun_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y' = f(x, y)</code>.</p>
</td></tr>
<tr><td><code id="euler_heun_+3A_a">a</code>, <code id="euler_heun_+3A_b">b</code></td>
<td>
<p>start and end points of the interval.</p>
</td></tr>
<tr><td><code id="euler_heun_+3A_y0">y0</code></td>
<td>
<p>starting value at a.</p>
</td></tr>
<tr><td><code id="euler_heun_+3A_n">n</code></td>
<td>
<p>number of grid points.</p>
</td></tr>
<tr><td><code id="euler_heun_+3A_improved">improved</code></td>
<td>
<p>logical; shall the Heun method be used; default TRUE.</p>
</td></tr>
<tr><td><code id="euler_heun_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>euler_heun</code> is an integration method for ordinary differential
equations using the simple Euler resp. the improved Euler-Heun Method.
</p>


<h3>Value</h3>

<p>List with components <code>t</code> for grid (or &lsquo;time&rsquo;) points, and <code>y</code> 
the vector of predicted values at those grid points.
</p>


<h3>References</h3>

<p>Quarteroni, A., and F. Saleri (). Scientific Computing with MATLAB
and Octave. Second Edition, Springer-Verlag, Berlin Heidelberg, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cranknic">cranknic</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Flame-up process
f &lt;- function(x, y) y^2 - y^3
s1 &lt;- cranknic(f, 0, 200, 0.01)
s2 &lt;- euler_heun(f, 0, 200, 0.01)
## Not run: 
plot(s1$t, s1$y, type="l", col="blue")
lines(s2$t, s2$y, col="red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='expint'>
Exponential and Logarithmic Integral
</h2><span id='topic+expint'></span><span id='topic+expint_E1'></span><span id='topic+expint_Ei'></span><span id='topic+li'></span>

<h3>Description</h3>

<p>The exponential integral functions E1 and Ei and
the logarithmic integral Li.
</p>
<p>The exponential integral is defined for <code class="reqn">x &gt; 0</code> as
</p>
<p style="text-align: center;"><code class="reqn">\int_x^\infty \frac{e^{-t}}{t} dt</code>
</p>

<p>and by analytic continuation in the complex plane. It can also be defined
as the Cauchy principal value of the integral
</p>
<p style="text-align: center;"><code class="reqn">\int_{-\infty}^x \frac{e^t}{t} dt</code>
</p>

<p>This is denoted as <code class="reqn">Ei(x)</code> and the relationship between <code>Ei</code> and
<code>expint(x)</code> for x real, x &gt; 0 is as follows:
</p>
<p style="text-align: center;"><code class="reqn">Ei(x) = - E1(-x) -i \pi</code>
</p>

<p>The logarithmic integral <code class="reqn">li(x)</code> for real <code class="reqn">x, x &gt; 0</code>, is defined as
</p>
<p style="text-align: center;"><code class="reqn">li(x) = \int_0^x \frac{dt}{log(t)}</code>
</p>

<p>and the Eulerian logarithmic integral as <code class="reqn">Li(x) = li(x) - li(2)</code>.
</p>
<p>The integral <code class="reqn">Li</code> approximates the prime number function <code class="reqn">\pi(n)</code>,
i.e., the number of primes below or equal to n (see the examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expint(x)
expint_E1(x)

expint_Ei(x)
li(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expint_+3A_x">x</code></td>
<td>
<p>vector of real or complex numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>x</code> in <code>[-38, 2]</code> we use a series expansion,
otherwise a continued fraction, see the references below, chapter 5.
</p>


<h3>Value</h3>

<p>Returns a vector of real or complex numbers, the vectorized exponential
integral, resp. the logarithmic integral.
</p>


<h3>Note</h3>

<p>The logarithmic integral <code>li(10^i)-li(2)</code> is an approximation of the
number of primes below <code>10^i</code>, i.e., <code>Pi(10^i)</code>, see &ldquo;?primes&rdquo;.
</p>


<h3>References</h3>

<p>Abramowitz, M., and I.A. Stegun (1965). Handbook of Mathematical Functions.
Dover Publications, New York.
</p>


<h3>See Also</h3>

<p><code>gsl::expint_E1,expint_Ei</code>, <code><a href="#topic+primes">primes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>expint_E1(1:10)
#   0.2193839  0.0489005  0.0130484  0.0037794  0.0011483
#   0.0003601  0.0001155  0.0000377  0.0000124  0.0000042
expint_Ei(1:10)

## Not run: 
estimPi &lt;- function(n) round(Re(li(n) - li(2))) # estimated number of primes
primesPi &lt;- function(n) length(primes(n))       # true number of primes &lt;= n
N &lt;- 1e6
(estimPi(N) - primesPi(N)) / estimPi(N)         # deviation is 0.16 percent!
## End(Not run)
</code></pre>

<hr>
<h2 id='expm'>
Matrix Exponential
</h2><span id='topic+expm'></span><span id='topic+logm'></span>

<h3>Description</h3>

<p>Computes the exponential of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expm(A, np = 128)

logm(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expm_+3A_a">A</code></td>
<td>
<p>numeric square matrix.</p>
</td></tr>
<tr><td><code id="expm_+3A_np">np</code></td>
<td>
<p>number of points to use on the unit circle.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For an analytic function <code class="reqn">f</code> and a matrix <code class="reqn">A</code> the expression
<code class="reqn">f(A)</code> can be computed by the Cauchy integral
</p>
<p style="text-align: center;"><code class="reqn">f(A)  =  (2 \pi i)^{-1} \int_G (zI-A)^{-1} f(z) dz</code>
</p>

<p>where <code class="reqn">G</code>  is a closed contour around the eigenvalues of <code class="reqn">A</code>.
</p>
<p>Here this is achieved by taking G to be a circle and approximating the
integral by the trapezoid rule.
</p>
<p><code>logm</code> is a fake at the moment as it computes the matrix logarithm
through taking the logarithm of its eigenvalues; will be replaced by an
approach using Pade interpolation.
</p>
<p>Another more accurate and more reliable approach for computing these
functions can be found in the R package &lsquo;expm&rsquo;.
</p>


<h3>Value</h3>

<p>Matrix of the same size as <code>A</code>.
</p>


<h3>Note</h3>

<p>This approach could be used for other analytic functions, but a point to
consider is which branch to take (e.g., for the <code>logm</code> function).
</p>


<h3>Author(s)</h3>

<p>Idea and Matlab code for a cubic root by Nick Trefethen in his 
&ldquo;10 digits 1 page&rdquo; project.
</p>


<h3>References</h3>

<p>Moler, C., and Ch. Van Loan (2003). Nineteen Dubious Ways to Compute
the Exponential of a Matrix, Twenty-Five Years Later.
SIAM Review, Vol. 1, No. 1, pp. 1&ndash;46.
</p>
<p>N. J. Higham (2008). Matrix Functions: Theory and Computation. SIAM
Society for Industrial and Applied Mathematics.
</p>


<h3>See Also</h3>

<p><code>expm::expm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  The Ward test cases described in the help for expm::expm agree up to
##  10 digits with the values here and with results from Matlab's expm !
A &lt;- matrix(c(-49, -64, 24, 31), 2, 2)
expm(A)
# -0.7357588 0.5518191
# -1.4715176 1.1036382

A1 &lt;- matrix(c(10,  7,  8,  7,
                7,  5,  6,  5,
                8,  6, 10,  9,
                7,  5,  9, 10), nrow = 4, ncol = 4, byrow = TRUE)
expm(logm(A1))
logm(expm(A1))

##  System of linear differential equations: y' = M y  (y = c(y1, y2, y3))
M &lt;- matrix(c(2,-1,1, 0,3,-1, 2,1,3), 3, 3, byrow=TRUE)
M
C1 &lt;- 0.5; C2 &lt;- 1.0; C3 &lt;- 1.5
t  &lt;- 2.0; Mt &lt;- expm(t * M)
yt &lt;- Mt 
</code></pre>

<hr>
<h2 id='eye'>Some Basic Matrices</h2><span id='topic+eye'></span><span id='topic+ones'></span><span id='topic+zeros'></span>

<h3>Description</h3>

<p>Create basic matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eye(n, m = n)
ones(n, m = n)
zeros(n, m = n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eye_+3A_m">m</code>, <code id="eye_+3A_n">n</code></td>
<td>
<p>numeric scalars specifying size of the matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of size <code>n x m</code>.
Defaults to a square matrix if <code>m</code> is missing.
</p>
<p>No dropping of dimensions; if <code>n = 1</code>, still returns a matrix and
not a vector.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+Diag">Diag</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eye(3)
ones(3, 1)
zeros(1, 3)
</code></pre>

<hr>
<h2 id='ezcontour+2Cezsurf+2Cezmesh'>
Contour, Surface, and Mesh Plotter
</h2><span id='topic+ezcontour'></span><span id='topic+ezsurf'></span><span id='topic+ezmesh'></span>

<h3>Description</h3>

<p>Easy-to-use contour and 3-D surface resp mesh plotter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ezcontour(f, xlim = c(-pi,pi), ylim = c(-pi,pi), 
          n = 60, filled = FALSE, col = NULL)

ezsurf(f, xlim = c(-pi, pi), ylim = c(-pi, pi),
       n = 60, ...)

ezmesh(f, xlim = c(-pi,pi), ylim = c(-pi,pi), 
       n = 60, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_f">f</code></td>
<td>
<p>2-D function to be plotted, must accept <code>(x,y)</code> as a vector.</p>
</td></tr>
<tr><td><code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_xlim">xlim</code>, <code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_ylim">ylim</code></td>
<td>
<p>defines x- and y-ranges as intervals.</p>
</td></tr>
<tr><td><code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_n">n</code></td>
<td>
<p>number of grid points in each direction.</p>
</td></tr>
<tr><td><code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_col">col</code></td>
<td>
<p>colour of isolines lines, resp. the surface color.</p>
</td></tr>
<tr><td><code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_filled">filled</code></td>
<td>
<p>logical; shall the contour plot be </p>
</td></tr>
<tr><td><code id="ezcontour+2B2Cezsurf+2B2Cezmesh_+3A_...">...</code></td>
<td>
<p>parameters to be passed to the <code>persp</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ezcontour</code> generates a contour plot of the function <code>f</code> using 
<code>contour</code> (and <code>image</code> if <code>filled=TRUE</code> is chosen).
If <code>filled=TRUE</code> is chosen, <code>col</code> should be a color scheme,
the default is <code>heat.colors(12)</code>.
</p>
<p><code>ezsurf</code> resp. <code>ezmesh</code> generates a surface/mesh plot of the 
function <code>f</code> using <code>persp</code>.
</p>
<p>The function <code>f</code> needs not be vectorized in any form.
</p>


<h3>Value</h3>

<p>Plots the function graph and invisibly returns <code>NULL</code>.
</p>


<h3>Note</h3>

<p>Mimicks Matlab functions of the same names; Matlab's <code>ezcontourf</code> can 
be generated with <code>filled=TRUE</code>.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+contour">contour</a></code>, <code><a href="Matrix.html#topic+image">image</a></code>, <code><a href="graphics.html#topic+persp">persp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
f &lt;- function(xy) {
    x &lt;- xy[1]; y &lt;- xy[2]
    3*(1-x)^2 * exp(-(x^2) - (y+1)^2) -
        10*(x/5 - x^3 - y^5) * exp(-x^2 - y^2) -
        1/3 * exp(-(x+1)^2 - y^2)
    }
ezcontour(f, col = "navy")
ezcontour(f, filled = TRUE)
ezmesh(f)
ezmesh(f, col="lightblue", theta = -15, phi = 30)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='ezplot'>
Easy Function Plot
</h2><span id='topic+ezplot'></span><span id='topic+fplot'></span>

<h3>Description</h3>

<p>Easy function plot w/o the need to define <code>x, y</code> coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fplot(f, interval, ...)

ezplot( f, a, b, n = 101, col = "blue", add = FALSE,
        lty = 1, lwd = 1, marker = 0, pch = 1,
        grid = TRUE, gridcol = "gray", 
        fill = FALSE, fillcol = "lightgray",
        xlab = "x", ylab = "f (x)", main = "Function Plot", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ezplot_+3A_f">f</code></td>
<td>
<p>Function to be plotted.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_interval">interval</code></td>
<td>
<p>interval [a, b] to plot the function in</p>
</td></tr>
<tr><td><code id="ezplot_+3A_a">a</code>, <code id="ezplot_+3A_b">b</code></td>
<td>
<p>Left and right endpoint for the plot.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_n">n</code></td>
<td>
<p>Number of points to plot.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_col">col</code></td>
<td>
<p>Color of the function graph.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_add">add</code></td>
<td>
<p>logical; shall the polt be added to an existing plot.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_lty">lty</code></td>
<td>
<p>line type; default 1.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_lwd">lwd</code></td>
<td>
<p>line width; default 1.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_marker">marker</code></td>
<td>
<p>no. of markers to be added to the curve; defailt: none.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_pch">pch</code></td>
<td>
<p>poimt character; default circle.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_grid">grid</code></td>
<td>
<p>Logical; shall a grid be plotted?; default <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_gridcol">gridcol</code></td>
<td>
<p>Color of grid points.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_fill">fill</code></td>
<td>
<p>Logical; shall the area between function and axis be filled?;
default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_fillcol">fillcol</code></td>
<td>
<p>Color of fill area.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_xlab">xlab</code></td>
<td>
<p>Label on the <code>x</code>-axis.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_ylab">ylab</code></td>
<td>
<p>Label on the <code>y</code>-axis.</p>
</td></tr>
<tr><td><code id="ezplot_+3A_main">main</code></td>
<td>
<p>Title of the plot</p>
</td></tr>
<tr><td><code id="ezplot_+3A_...">...</code></td>
<td>
<p>More parameters to be passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the <code>x, y</code> coordinates of points to be plotted and
calls the <code>plot</code> function.
</p>
<p>If <code>fill</code> is <code>TRUE</code>, also calls the <code>polygon</code> function
with the <code>x, y</code> coordinates in appropriate order.
</p>
<p>If the no. of <code>markers</code> is greater than 2, this number of markers
will be added to the curve, with equal distances measured along the curve.
</p>


<h3>Value</h3>

<p>Plots the function graph and invisibly returns <code>NULL</code>.
</p>


<h3>Note</h3>

<p><code>fplot</code> is almost an alias for <code>ezplot</code> as all <code>ez...</code> 
will be replaced by MATLAB with function names <code>f...</code> in 2017.
</p>
<p><code>ezplot</code> should mimick the Matlab function of the same name, has
more functionality, misses the possibility to plot several functions.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+curve">curve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fun &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
ezplot(fun, 0, 5, n = 1001, fill = TRUE)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='ezpolar'>
Easy Polar Plot
</h2><span id='topic+ezpolar'></span>

<h3>Description</h3>

<p>Easy function plot w/o the need to define <code>x, y</code> coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ezpolar(fun, interv = c(0, 2*pi))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ezpolar_+3A_fun">fun</code></td>
<td>
<p>function to be plotted.</p>
</td></tr>
<tr><td><code id="ezpolar_+3A_interv">interv</code></td>
<td>
<p>left and right endpoint for the plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the <code>x, y</code> coordinates of points to be plotted and
calls the <code>polar</code> function.
</p>


<h3>Value</h3>

<p>Plots the function graph and invisibly returns <code>NULL</code>.
</p>


<h3>Note</h3>

<p>Mimick the Matlab function of the same name.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ezplot">ezplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fun &lt;- function(x) 1 + cos(x)
ezpolar(fun)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='fact'>
Factorial Function
</h2><span id='topic+fact'></span><span id='topic+factorial2'></span>

<h3>Description</h3>

<p>Factorial for non-negative integers <code>n &lt;= 170</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fact(n)

factorial2(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fact_+3A_n">n</code></td>
<td>
<p>Vector of integers, for <code>fact</code>, resp. a single integer for
<code>factorial2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The factorial is computed by brute force; factorials for <code>n &gt;= 171</code>
are not representable as &lsquo;double&rsquo; anymore.
</p>


<h3>Value</h3>

<p><code>fact</code> returns the factorial of each element in <code>n</code>.
If <code>n &lt; 0</code> the value is <code>NaN</code>, and for <code>n &gt; 170</code>
it is <code>Inf</code>.
Non-integers will be reduced to integers through <code>floor(n)</code>.
</p>
<p><code>factorial2</code> returns the product of all even resp. odd integers,
depending on whether <code>n</code> is even or odd.
</p>


<h3>Note</h3>

<p>The R core function <code>factorial</code> uses the <code>gamma</code> function,
whose implementation is not accurate enough for larger input values.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+factorial">factorial</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fact(c(-1, 0, 1, NA, 171))  #=&gt; NaN   1   1  NA Inf
fact(100)                   #=&gt; 9.332621544394410e+157
factorial(100)              #=&gt; 9.332621544394225e+157
# correct value:                9.332621544394415e+157
# Stirling's approximation:     9.324847625269420e+157
# n! ~ sqrt(2*pi*n) * (n/e)^n

factorial2(8);  factorial2(9);  factorial2(10)  # 384   945  3840
factorial(10) / factorial2(10)                  # =&gt; factorial2(9)
</code></pre>

<hr>
<h2 id='factors'>Prime Factors</h2><span id='topic+factors'></span>

<h3>Description</h3>

<p>Returns a vector containing the prime factors of <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  factors(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factors_+3A_n">n</code></td>
<td>
<p>nonnegative integer</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the prime factors of <code>n</code> in ascending order,
each one as often as its multiplicity requires, such that 
<code>n == prod(factors(n))</code>.
</p>
<p>The corresponding Matlab function is called &lsquo;factor&rsquo;, but because
factors have a special meaning in R and the factor() function in R
could not (or should not) be shadowed, the number theoretic function
has been renamed here.
</p>


<h3>Value</h3>

<p>Vector containing the prime factors of <code>n</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+isprime">isprime</a>, <a href="#topic+primes">primes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  factors(1002001)       # 7  7  11  11  13  13
  factors(65537)         # is prime
  # Euler's calculation
  factors(2^32 + 1)      # 641  6700417
## End(Not run)
</code></pre>

<hr>
<h2 id='fderiv'>
Numerical Differentiation
</h2><span id='topic+fderiv'></span>

<h3>Description</h3>

<p>Numerical function differentiation for orders <code>n=1..4</code> using
finite difference approximations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fderiv(f, x, n = 1, h = 0,
        method = c("central", "forward", "backward"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fderiv_+3A_f">f</code></td>
<td>
<p>function to be differentiated.</p>
</td></tr>
<tr><td><code id="fderiv_+3A_x">x</code></td>
<td>
<p>point(s) where differentiation will take place.</p>
</td></tr>
<tr><td><code id="fderiv_+3A_n">n</code></td>
<td>
<p>order of derivative, should only be between 1 and 8;
for <code>n=0</code> function values will be returned.</p>
</td></tr>
<tr><td><code id="fderiv_+3A_h">h</code></td>
<td>
<p>step size: if <code>h=0</code> step size will be set automatically.</p>
</td></tr>
<tr><td><code id="fderiv_+3A_method">method</code></td>
<td>
<p>one of &ldquo;central&rdquo;, &ldquo;forward&rdquo;, or &ldquo;backward&rdquo;.</p>
</td></tr>
<tr><td><code id="fderiv_+3A_...">...</code></td>
<td>
<p>more variables to be passed to function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Derivatives are computed applying central difference formulas that stem
from the Taylor series approximation. These formulas have a convergence
rate of <code class="reqn">O(h^2)</code>.
</p>
<p>Use the &lsquo;forward&rsquo; (right side) or &lsquo;backward&rsquo; (left side) method if the
function can only be computed or is only defined on one side. Otherwise,
always use the central difference formulas.
</p>
<p>Optimal step sizes depend on the accuracy the function can be computed with.
Assuming internal functions with an accuracy 2.2e-16, appropriate step
sizes might be <code>5e-6, 1e-4, 5e-4, 2.5e-3</code> for <code>n=1,...,4</code> and
precisions of about <code>10^-10, 10^-8, 5*10^-7, 5*10^-6</code> (at best).
</p>
<p>For <code>n&gt;4</code> a recursion (or finite difference) formula will be applied,
cd. the Wikipedia article on &ldquo;finite difference&rdquo;.
</p>


<h3>Value</h3>

<p>Vector of the same length as <code>x</code>.
</p>


<h3>Note</h3>

<p>Numerical differentiation suffers from the conflict between round-off
and truncation errors. 
</p>


<h3>References</h3>

<p>Kiusalaas, J. (2005). Numerical Methods in Engineering with Matlab.
Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+numderiv">numderiv</a></code>, <code><a href="#topic+taylor">taylor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
f &lt;- sin
xs &lt;- seq(-pi, pi, length.out = 100)
ys &lt;- f(xs)
y1 &lt;- fderiv(f, xs, n = 1, method = "backward")
y2 &lt;- fderiv(f, xs, n = 2, method = "backward")
y3 &lt;- fderiv(f, xs, n = 3, method = "backward")
y4 &lt;- fderiv(f, xs, n = 4, method = "backward")
plot(xs, ys, type = "l", col = "gray", lwd = 2,
     xlab = "", ylab = "", main = "Sinus and its Derivatives")
lines(xs, y1, col=1, lty=2)
lines(xs, y2, col=2, lty=3)
lines(xs, y3, col=3, lty=4)
lines(xs, y4, col=4, lty=5)
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='fibsearch'>
Fibonacci Search
</h2><span id='topic+fibsearch'></span>

<h3>Description</h3>

<p>Fibonacci search for function minimum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fibsearch(f, a, b, ..., endp = FALSE, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fibsearch_+3A_f">f</code></td>
<td>
<p>Function or its name as a string.</p>
</td></tr>
<tr><td><code id="fibsearch_+3A_a">a</code>, <code id="fibsearch_+3A_b">b</code></td>
<td>
<p>endpoints of the interval</p>
</td></tr>
<tr><td><code id="fibsearch_+3A_endp">endp</code></td>
<td>
<p>logical; shall the endpoints be considered as possible minima?</p>
</td></tr>
<tr><td><code id="fibsearch_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance; default <code>eps^(1/2)</code>.</p>
</td></tr>
<tr><td><code id="fibsearch_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fibonacci search for a univariate function minimum in a bounded interval.
</p>


<h3>Value</h3>

<p>Return a list with components <code>xmin</code>, <code>fmin</code>, 
the function value at the minimum, <code>niter</code>, the number of iterations
done, and the estimated precision <code>estim.prec</code>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
fibsearch(f, 0, 4, tol=10^-10)   # $xmin    = 3.24848329403424
optimize(f, c(0,4), tol=10^-10)  # $minimum = 3.24848328971188
</code></pre>

<hr>
<h2 id='figure'>
Control Plot Devices (Matlab Style)
</h2><span id='topic+figure'></span>

<h3>Description</h3>

<p>Open, activate, and close grahics devices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>figure(figno, title = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="figure_+3A_figno">figno</code></td>
<td>
<p>(single) number of plot device.</p>
</td></tr>
<tr><td><code id="figure_+3A_title">title</code></td>
<td>
<p>title of the plot device; not yet used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of a graphics device cannot be 0 or 1. The function will work
for the operating systems Mac OS, MS Windows, and most Linux systems.
</p>
<p>If <code>figno</code> is negative and a graphics device with that number does
exist, it will be closed.
</p>


<h3>Value</h3>

<p>No return value, except when a device of that number does not exist,
in which case it returns a list of numbers of open graphics devices.
</p>


<h3>Note</h3>

<p>Does not bring the activated graphics device in front.
</p>


<h3>See Also</h3>

<p><code>dev.set, dev.off, dev.list</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
figure()
figure(-2)

## End(Not run)
</code></pre>

<hr>
<h2 id='findintervals'>
Find Interval Indices
</h2><span id='topic+findintervals'></span>

<h3>Description</h3>

<p>Find indices <code>i</code> in vector <code>xs</code> such that either <code>x=xs[i]</code>
or such that <code>xs[i]&lt;x&lt;xs[i+1]</code> or <code>xs[i]&gt;x&gt;xs[i+1]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findintervals(x, xs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findintervals_+3A_x">x</code></td>
<td>
<p>single number.</p>
</td></tr>
<tr><td><code id="findintervals_+3A_xs">xs</code></td>
<td>
<p>numeric vector, not necessarily sorted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Contrary to <code>findInterval</code>, the vector <code>xs</code> in
<code>findintervals</code> need not be sorted.
</p>


<h3>Value</h3>

<p>Vector of indices in <code>1..length(xs)</code>.
If none is found, returns <code>integer(0)</code>.
</p>


<h3>Note</h3>

<p>If <code>x</code> is equal to the last element in <code>xs</code>, the index
<code>length(xs)</code> will also be returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xs &lt;- zapsmall(sin(seq(0, 10*pi, len=100)))
findintervals(0, xs)
#   1  10  20  30  40  50  60  70  80  90 100
</code></pre>

<hr>
<h2 id='findmins'>
Find All Minima
</h2><span id='topic+findmins'></span>

<h3>Description</h3>

<p>Finding all local(!) minima of a unvariate function in an interval by
splitting the interval in many small subintervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findmins(f, a, b, n = 100, tol = .Machine$double.eps^(2/3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findmins_+3A_f">f</code></td>
<td>
<p>functions whose minima shall be found.</p>
</td></tr>
<tr><td><code id="findmins_+3A_a">a</code>, <code id="findmins_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="findmins_+3A_n">n</code></td>
<td>
<p>number of subintervals to generate and search.</p>
</td></tr>
<tr><td><code id="findmins_+3A_tol">tol</code></td>
<td>
<p>has no effect at this moment.</p>
</td></tr>
<tr><td><code id="findmins_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Local minima are found by looking for one minimum in each subinterval.
It will be found by applying <code>optimize</code> to any two adjacent
subinterval where the first slope is negative and the second one
positive.
</p>
<p>If the function is minimal on a whole subinterval, this will cause
problems. If some minima are apparently not found, increase the number
of subintervals.
</p>
<p>Note that the endpoints of the interval will never be considered to be
local minima. The function need not be vectorized.
</p>


<h3>Value</h3>

<p>Numeric vector with the x-positions of all minima found in the interval.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optimize">optimize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fun &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
## Not run: ezplot(fun, 0, 5, n = 1001)

# If n is smaller, the rightmost minimum will not be found.
findmins(fun, 0, 5, n= 1000)
#  2.537727 3.248481 3.761840 4.023021 4.295831
#  4.455115 4.641481 4.756263 4.897461 4.987802
</code></pre>

<hr>
<h2 id='findpeaks'>
Find Peaks
</h2><span id='topic+findpeaks'></span>

<h3>Description</h3>

<p>Find peaks (maxima) in a time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findpeaks(x, nups = 1, ndowns = nups, zero = "0", peakpat = NULL,
          minpeakheight = -Inf, minpeakdistance = 1,
          threshold = 0, npeaks = 0, sortstr = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findpeaks_+3A_x">x</code></td>
<td>
<p>numerical vector taken as a time series (no NAs allowed)</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_nups">nups</code></td>
<td>
<p>minimum number of increasing steps before a peak is reached</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_ndowns">ndowns</code></td>
<td>
<p>minimum number of decreasing steps after the peak</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_zero">zero</code></td>
<td>
<p>can be &lsquo;+&rsquo;, &lsquo;-&rsquo;, or &lsquo;0&rsquo;; how to interprete succeeding steps
of the same value: increasing, decreasing, or special</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_peakpat">peakpat</code></td>
<td>
<p>define a peak as a regular pattern, such as the default
pattern <code>[+]{1,}[-]{1,}</code>; if a pattern is provided, parameters
<code>nups</code> and <code>ndowns</code> are not taken into account</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_minpeakheight">minpeakheight</code></td>
<td>
<p>the minimum (absolute) height a peak has to have
to be recognized as such</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_minpeakdistance">minpeakdistance</code></td>
<td>
<p>the minimum distance (in indices) peaks have to have
to be counted</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_threshold">threshold</code></td>
<td>
<p>the minimum </p>
</td></tr>
<tr><td><code id="findpeaks_+3A_npeaks">npeaks</code></td>
<td>
<p>the number of peaks to return</p>
</td></tr>
<tr><td><code id="findpeaks_+3A_sortstr">sortstr</code></td>
<td>
<p>logical; should the peaks be returned sorted in decreasing
oreder of their maximum value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is quite general as it relies on regular patterns to determine
where a peak is located, from beginning to end.
</p>


<h3>Value</h3>

<p>Returns a matrix where each row represents one peak found. The first column
gives the height, the second the position/index where the maximum is reached,
the third and forth the indices of where the peak begins and ends &mdash; in the
sense of where the pattern starts and ends.
</p>


<h3>Note</h3>

<p>On Matlab Central there are several realizations for finding peaks, for
example &ldquo;peakfinder&rdquo;, &ldquo;peakseek&rdquo;, or &ldquo;peakdetect&rdquo;. And &ldquo;findpeaks&rdquo;
is also the name of a function in the Matlab &lsquo;signal&rsquo; toolbox.
</p>
<p>The parameter names are taken from the &ldquo;findpeaks&rdquo; function in &lsquo;signal&rsquo;,
but the implementation utilizing regular expressions is unique and fast.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hampel">hampel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0, 1, len = 1024)
pos &lt;- c(0.1, 0.13, 0.15, 0.23, 0.25, 0.40, 0.44, 0.65, 0.76, 0.78, 0.81)
hgt &lt;- c(4, 5, 3, 4, 5, 4.2, 2.1, 4.3, 3.1, 5.1, 4.2)
wdt &lt;- c(0.005, 0.005, 0.006, 0.01, 0.01, 0.03, 0.01, 0.01, 0.005, 0.008, 0.005)

pSignal &lt;- numeric(length(x))
for (i in seq(along=pos)) {
	pSignal &lt;- pSignal + hgt[i]/(1 + abs((x - pos[i])/wdt[i]))^4
}
findpeaks(pSignal, npeaks=3, threshold=4, sortstr=TRUE)

## Not run: 
plot(pSignal, type="l", col="navy")
grid()
x &lt;- findpeaks(pSignal, npeaks=3, threshold=4, sortstr=TRUE)
points(x[, 2], x[, 1], pch=20, col="maroon")
## End(Not run)
</code></pre>

<hr>
<h2 id='finds'>find function (Matlab Style)</h2><span id='topic+finds'></span>

<h3>Description</h3>

<p>Finds indices of nonzero elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>finds(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="finds_+3A_v">v</code></td>
<td>
<p>logical or numeric vector or array</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds indices of true or nonzero elements of argument <code>v</code>;
can be used with a logical expression.
</p>


<h3>Value</h3>

<p>Indices of elements matching the expression <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>finds(-3:3 &gt;= 0)
finds(c(0, 1, 0, 2, 3))
</code></pre>

<hr>
<h2 id='findzeros'>
Find All Roots
</h2><span id='topic+findzeros'></span>

<h3>Description</h3>

<p>Finding all roots of a unvariate function in an interval by splitting
the interval in many small subintervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findzeros(f, a, b, n = 100, tol = .Machine$double.eps^(2/3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findzeros_+3A_f">f</code></td>
<td>
<p>functions whose roots shall be found.</p>
</td></tr>
<tr><td><code id="findzeros_+3A_a">a</code>, <code id="findzeros_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="findzeros_+3A_n">n</code></td>
<td>
<p>number of subintervals to generate and search.</p>
</td></tr>
<tr><td><code id="findzeros_+3A_tol">tol</code></td>
<td>
<p>tolerance for identifying zeros.</p>
</td></tr>
<tr><td><code id="findzeros_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Roots, i.e. zeros in a subinterval will be found by applying <code>uniroot</code>
to any subinterval where the sign of the function changes. The endpoints of
the interval will be tested separately.
</p>
<p>If the function points are both positive or negative and the slope in this
interval is high enough, the minimum or maximum will be determined with
<code>optimize</code> and checked for a possible zero. 
</p>
<p>The function need not be vectorized.
</p>


<h3>Value</h3>

<p>Numeric vector with the x-positions of all roots found in the interval.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findmins">findmins</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f1 &lt;- function(x) sin(pi/x)
findzeros(f1, 1/10, 1)
#  0.1000000  0.1111028  0.1250183  0.1428641  0.1666655
#  0.2000004  0.2499867  0.3333441  0.4999794  1.0000000

f2 &lt;- function(x) 0.5*(1 + sin(10*pi*x))
findzeros(f2, 0, 1)
#  0.15  0.35  0.55  0.75  0.95

f3 &lt;- function(x) sin(pi/x) + 1
findzeros(f3, 0.1, 0.5)
# 0.1052632 0.1333333 0.1818182 0.2857143

f4 &lt;- function(x) sin(pi/x) - 1
findzeros(f4, 0.1, 0.5)
# 0.1176471 0.1538462 0.2222222 0.4000000

## Not run: 
# Dini function
Dini &lt;- function(x) x * besselJ(x, 1) + 3 * besselJ(x, 0)
findzeros(Dini, 0, 100, n = 128)
ezplot(Dini, 0, 100, n = 512)

## End(Not run)
</code></pre>

<hr>
<h2 id='fletcher_powell'>
Fletcher-Powell Conjugate Gradient Minimization
</h2><span id='topic+fletcher_powell'></span>

<h3>Description</h3>

<p>Conjugate Gradient (CG) minimization through the Davidon-Fletcher-Powell 
approach for function minimization.
</p>
<p>The Davidon-Fletcher-Powell (DFP) and the Broyden-Fletcher-Goldfarb-Shanno
(BFGS) methods are the first quasi-Newton minimization methods developed.
These methods differ only in some details; in general, the BFGS approach
is more robust.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fletcher_powell(x0, f, g = NULL,
                maxiter = 1000, tol = .Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fletcher_powell_+3A_x0">x0</code></td>
<td>
<p>start value.</p>
</td></tr>
<tr><td><code id="fletcher_powell_+3A_f">f</code></td>
<td>
<p>function to be minimized.</p>
</td></tr>
<tr><td><code id="fletcher_powell_+3A_g">g</code></td>
<td>
<p>gradient function of <code>f</code>;
if <code>NULL</code>, a numerical gradient will be calculated.</p>
</td></tr>
<tr><td><code id="fletcher_powell_+3A_maxiter">maxiter</code></td>
<td>
<p>max. number of iterations.</p>
</td></tr>
<tr><td><code id="fletcher_powell_+3A_tol">tol</code></td>
<td>
<p>relative tolerance, to be used as stopping rule.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The starting point is Newton's method in the multivariate case, when
the estimate of the minimum is updated by the following equation
</p>
<p style="text-align: center;"><code class="reqn">x_{new} = x - H^{-1}(x) grad(g)(x)</code>
</p>

<p>where <code class="reqn">H</code> is the Hessian and <code class="reqn">grad</code> the gradient.
</p>
<p>The basic idea is to generate a sequence of good approximations to the
inverse Hessian matrix, in such a way that the approximations are again
positive definite.
</p>


<h3>Value</h3>

<p>List with following components:
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>minimum solution found.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>value of <code>f</code> at minimum.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>number of iterations performed.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Used some Matlab code as described in the book &ldquo;Applied Numerical Analysis
Using Matlab&rdquo; by L. V.Fausett.
</p>


<h3>References</h3>

<p>J. F. Bonnans, J. C. Gilbert, C. Lemarechal, and C. A. Sagastizabal.
Numerical Optimization: Theoretical and Practical Aspects. Second Edition,
Springer-Verlag, Berlin Heidelberg, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+steep_descent">steep_descent</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Rosenbrock function
rosenbrock &lt;- function(x) {
    n &lt;- length(x)
    x1 &lt;- x[2:n]
    x2 &lt;- x[1:(n-1)]
    sum(100*(x1-x2^2)^2 + (1-x2)^2)
}
fletcher_powell(c(0, 0), rosenbrock)
# $xmin
# [1] 1 1
# $fmin
# [1] 1.774148e-27
# $niter
# [1] 14
</code></pre>

<hr>
<h2 id='flipdim'>Matrix Flipping (Matlab Style)</h2><span id='topic+flipdim'></span><span id='topic+flipud'></span><span id='topic+fliplr'></span><span id='topic+circshift'></span>

<h3>Description</h3>

<p>Flip matrices up and down or left and right; or circulating indices per
dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flipdim(a, dim)
flipud(a)
fliplr(a)
circshift(a, sz)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flipdim_+3A_a">a</code></td>
<td>
<p>numeric or complex matrix</p>
</td></tr>
<tr><td><code id="flipdim_+3A_dim">dim</code></td>
<td>
<p>flipping dimension; can only be 1 (default) or 2</p>
</td></tr>
<tr><td><code id="flipdim_+3A_sz">sz</code></td>
<td>
<p>integer vector of length 1 or 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>flipdim</code> will flip a matrix along the <code>dim</code> dimension, where
<code>dim=1</code> means flipping rows, and <code>dim=2</code> flipping the columns.
</p>
<p><code>flipud</code> and <code>fliplr</code> are simply shortcuts for <code>flipdim(a, 1)</code>
resp. <code>flipdim(a, 2)</code>.
</p>
<p><code>circshift(a, sz)</code> circulates each dimension
(should be applicable to arrays).
</p>


<h3>Value</h3>

<p>the original matrix somehow flipped or circularly shifted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix(1:12, nrow=3, ncol=4, byrow=TRUE)
flipud(a)
fliplr(a)

circshift(a, c(1, -1))
v &lt;- 1:10
circshift(v, 5)
</code></pre>

<hr>
<h2 id='fminbnd'>
Finding Function Minimum
</h2><span id='topic+fminbnd'></span>

<h3>Description</h3>

<p>Find minimum of single-variable function on fixed interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fminbnd(f, a, b, maxiter = 1000, maximum = FALSE,
        tol = 1e-07, rel.tol = tol, abs.tol = 1e-15, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fminbnd_+3A_f">f</code></td>
<td>
<p>function whose minimum or maximum is to be found.</p>
</td></tr>
<tr><td><code id="fminbnd_+3A_a">a</code>, <code id="fminbnd_+3A_b">b</code></td>
<td>
<p>endpoints of the interval to be searched.</p>
</td></tr>
<tr><td><code id="fminbnd_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iterations.</p>
</td></tr>
<tr><td><code id="fminbnd_+3A_maximum">maximum</code></td>
<td>
<p>logical; shall maximum or minimum be found; default FALSE.</p>
</td></tr>
<tr><td><code id="fminbnd_+3A_tol">tol</code></td>
<td>
<p>relative tolerance; left over for compatibility.</p>
</td></tr>
<tr><td><code id="fminbnd_+3A_rel.tol">rel.tol</code>, <code id="fminbnd_+3A_abs.tol">abs.tol</code></td>
<td>
<p>relative and absolute tolerance.</p>
</td></tr>
<tr><td><code id="fminbnd_+3A_...">...</code></td>
<td>
<p>additional variables to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>fminbnd finds the minimum of a function of one variable within a fixed
interval. It applies Brent's algorithm, based on golden section search and
parabolic interpolation.
</p>
<p><code>fminbnd</code> may only give local solutions.
<code>fminbnd</code> never evaluates <code>f</code> at the endpoints.
</p>


<h3>Value</h3>

<p>List with
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>location of the minimum resp. maximum.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>function value at the optimum.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>number of iterations used.</p>
</td></tr>
<tr><td><code>estim.prec</code></td>
<td>
<p>estimated precision.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>fminbnd</code> mimics the Matlab function of the same name.
</p>


<h3>References</h3>

<p>R. P. Brent (1973). Algorithms for Minimization Without Derivatives.
Dover Publications, reprinted 2002.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fibsearch">fibsearch</a></code>, <code><a href="#topic+golden_ratio">golden_ratio</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  CHEBFUN example by Trefethen
f &lt;- function(x) exp(x)*sin(3*x)*tanh(5*cos(30*x))
fminbnd(f, -1, 1)                   # fourth local minimum (from left)
g &lt;- function(x) complexstep(f, x)  # complex-step derivative
xs &lt;- findzeros(g, -1, 1)           # local minima and maxima
ys &lt;- f(xs); n0 &lt;- which.min(ys)    # index of global minimum
fminbnd(f, xs[n0-1], xs[n0+1])      # xmin:0.7036632, fmin: -1.727377

## Not run: 
ezplot(f, -1, 1, n = 1000, col = "darkblue", lwd = 2)
ezplot(function(x) g(x)/150, -1, 1, n = 1000, col = "darkred", add = TRUE)
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='fmincon'>
Minimize Nonlinear Constrained Multivariable Function.
</h2><span id='topic+fmincon'></span>

<h3>Description</h3>

<p>Find minimum of multivariable functions with nonlinear constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  fmincon(x0, fn, gr = NULL, ..., method = "SQP",
          A = NULL, b = NULL, Aeq = NULL, beq = NULL,
          lb = NULL, ub = NULL, hin = NULL, heq = NULL,
          tol = 1e-06, maxfeval = 10000, maxiter = 5000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fmincon_+3A_x0">x0</code></td>
<td>
<p>starting point.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_fn">fn</code></td>
<td>
<p>objective function to be minimized.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_gr">gr</code></td>
<td>
<p>gradient function of the objective; not used for SQP method.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_method">method</code></td>
<td>
<p>method options 'SQP', 'auglag'; only 'SQP is implemented.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_a">A</code>, <code id="fmincon_+3A_b">b</code></td>
<td>
<p>linear ineqality constraints of the form A x &lt;= b .</p>
</td></tr>
<tr><td><code id="fmincon_+3A_aeq">Aeq</code>, <code id="fmincon_+3A_beq">beq</code></td>
<td>
<p>linear eqality constraints of the form Aeq x = beq .</p>
</td></tr>
<tr><td><code id="fmincon_+3A_lb">lb</code>, <code id="fmincon_+3A_ub">ub</code></td>
<td>
<p>bounds constraints of the form lb &lt;= x &lt;= ub .</p>
</td></tr>
<tr><td><code id="fmincon_+3A_hin">hin</code></td>
<td>
<p>nonlinear inequality constraints of the form hin(x) &lt;= 0 .</p>
</td></tr>
<tr><td><code id="fmincon_+3A_heq">heq</code></td>
<td>
<p>nonlinear equality constraints of the form heq(x) = 0 .</p>
</td></tr>
<tr><td><code id="fmincon_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="fmincon_+3A_maxfeval">maxfeval</code></td>
<td>
<p>maximum number of function evaluations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wraps the function <code>solnl</code> in the 'NlcOptim' package. The
underlying method is a Squential Quadratic Programming (SQP) approach.
</p>
<p>Constraints can be defined in different ways, as linear constraints in
matrix form, as nonlinear functions, or as bounds constraints.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>the best minimum found.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>function value at the minimum.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>integer indicating the terminating situation.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>parameter list describing the final situation.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>fmincon</code> mimics the Matlab function of the same name.
</p>


<h3>Author(s)</h3>

<p>Xianyan Chen for the package NlcOptim.
</p>


<h3>References</h3>

<p>J. Nocedal and S. J. Wright (2006). Numerical Optimization. Second
Edition, Springer Science+Business Media, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fminsearch">fminsearch</a></code>, <code><a href="#topic+fminunc">fminunc</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Classical Rosenbrock function
n &lt;- 10; x0 &lt;- rep(1/n, n)
fn &lt;- function(x) {n &lt;- length(x)
    x1 &lt;- x[2:n]; x2 &lt;- x[1:(n - 1)]
    sum(100 * (x1 - x2^2)^2 + (1 - x2)^2)
}
# Equality and inequality constraints
heq1 &lt;- function(x) sum(x)-1.0
hin1 &lt;- function(x) -1 * x
hin2 &lt;- function(x) x - 0.5
ub &lt;- rep(0.5, n)

# Apply constraint minimization
res &lt;- fmincon(x0, fn, hin = hin1, heq = heq1)
res$par; res$value
</code></pre>

<hr>
<h2 id='fminsearch'>
Derivative-free Nonlinear Function Minimization
</h2><span id='topic+fminsearch'></span>

<h3>Description</h3>

<p>Find minimum of multivariable functions using derivative-free methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fminsearch(fn, x0, ..., lower = NULL, upper = NULL,
           method = c("Nelder-Mead", "Hooke-Jeeves"),
           minimize = TRUE, maxiter = 1000, tol = 1e-08)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fminsearch_+3A_fn">fn</code></td>
<td>
<p>function whose minimum or maximum is to be found.</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_x0">x0</code></td>
<td>
<p>point considered near to the optimum.</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_...">...</code></td>
<td>
<p>additional variables to be passed to the function.</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_lower">lower</code>, <code id="fminsearch_+3A_upper">upper</code></td>
<td>
<p>lower and upper bounds constraints.</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_method">method</code></td>
<td>
<p>&quot;Nelder-Mead&quot; (default) or &quot;Hooke-Jeeves&quot;; can be abbreviated.</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_minimize">minimize</code></td>
<td>
<p>logical; shall a minimum or a maximum be found.</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iterations</p>
</td></tr>
<tr><td><code id="fminsearch_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fminsearch</code> finds the minimum of a nonlinear scalar multivariable
function, starting at an initial estimate and returning a value x that is
a local minimizer of the function. With <code>minimize=FALSE</code> it searches
for a maximum, by default for a (local) minimum.
</p>
<p>As methods/solvers &quot;Nelder-Mead&quot; and &quot;Hooke-Jeeves&quot; are available. Only
Hooke-Jeeves can handle bounds constraints. For nonlinear constraints see
<code>fmincon</code>, and for methods using gradients see <code>fminunc</code>.
</p>
<p>Important: <code>fminsearch</code> may only give local solutions.
</p>


<h3>Value</h3>

<p>List with
</p>
<table>
<tr><td><code>xopt</code></td>
<td>
<p>location of the location of minimum resp. maximum.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>function value at the optimum.</p>
</td></tr>
<tr><td><code>count</code></td>
<td>
<p>number of function calls.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>info about convergence: not used at the moment.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>special information from the solver.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>fminsearch</code> mimics the Matlab function of the same name.
</p>


<h3>References</h3>

<p>Nocedal, J., and S. Wright (2006). Numerical Optimization.
Second Edition, Springer-Verlag, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nelder_mead">nelder_mead</a></code>, <code><a href="#topic+hooke_jeeves">hooke_jeeves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Rosenbrock function
rosena &lt;- function(x, a) 100*(x[2]-x[1]^2)^2 + (a-x[1])^2  # min: (a, a^2)

fminsearch(rosena, c(-1.2, 1), a = sqrt(2), method="Nelder-Mead")
## $xmin                   $fmin
## [1] 1.414292 2.000231   [1] 1.478036e-08

fminsearch(rosena, c(-1.2, 1), a = sqrt(2), method="Hooke-Jeeves")
## $xmin                   $fmin
## [1] 1.414215 2.000004   [1] 1.79078e-12
</code></pre>

<hr>
<h2 id='fminunc'>
Minimize Unconstrained Multivariable Function
</h2><span id='topic+fminunc'></span>

<h3>Description</h3>

<p>Find minimum of unconstrained multivariable functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  fminunc(x0, fn, gr = NULL, ...,
          tol = 1e-08, maxiter = 0, maxfeval = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fminunc_+3A_x0">x0</code></td>
<td>
<p>starting point.</p>
</td></tr>
<tr><td><code id="fminunc_+3A_fn">fn</code></td>
<td>
<p>objective function to be minimized.</p>
</td></tr>
<tr><td><code id="fminunc_+3A_gr">gr</code></td>
<td>
<p>gradient function of the objective.</p>
</td></tr>
<tr><td><code id="fminunc_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
<tr><td><code id="fminunc_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="fminunc_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="fminunc_+3A_maxfeval">maxfeval</code></td>
<td>
<p>maximum number of function evaluations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method used here for unconstrained minimization is a variant of a
&quot;variable metric&quot; resp. quasi-Newton approach.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>the best minimum found.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>function value at the minimum.</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>
<p>number of function and gradient calls.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>integer indicating the terminating situation.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>description of the final situation.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>fminunc</code> mimics the Matlab function of the same name.
</p>


<h3>Author(s)</h3>

<p>The &quot;variable metric&quot; code provided by John Nash (package Rvmmin),
stripped-down version by Hans W. Borchers.
</p>


<h3>References</h3>

<p>J. Nocedal and S. J. Wright (2006). Numerical Optimization. Second
Edition, Springer Science+Business Media, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fminsearch">fminsearch</a></code>, <code><a href="#topic+fmincon">fmincon</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  fun = function(x) 
          x[1]*exp(-(x[1]^2 + x[2]^2)) + (x[1]^2 + x[2]^2)/20
  fminunc(x0 = c(1, 2), fun)
  ## xmin: c(-0.6691, 0.0000); fmin: -0.4052
</code></pre>

<hr>
<h2 id='fnorm'>
Function Norm
</h2><span id='topic+fnorm'></span>

<h3>Description</h3>

<p>The <code>fnorm</code> function calculates several different types of function
norms for depending on the argument <code>p</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnorm(f, g, x1, x2, p = 2, npoints = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fnorm_+3A_f">f</code>, <code id="fnorm_+3A_g">g</code></td>
<td>
<p>functions given by name or string.</p>
</td></tr>
<tr><td><code id="fnorm_+3A_x1">x1</code>, <code id="fnorm_+3A_x2">x2</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="fnorm_+3A_p">p</code></td>
<td>
<p>Numeric scalar or Inf, -Inf; default is 2.</p>
</td></tr>
<tr><td><code id="fnorm_+3A_npoints">npoints</code></td>
<td>
<p>number of points to be considered in the interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fnorm</code> returns a scalar that gives some measure of the distance
of two functions <code>f</code> and <code>g</code> on the interval <code>[x1, x2]</code>.
</p>
<p>It takes <code>npoints</code> equidistant points in the interval, computes the
function values for <code>f</code> and <code>g</code> and applies <code>Norm</code> to
their difference.
</p>
<p>Especially <code>p=Inf</code> returns the maximum norm,
while <code>fnorm(f, g, x1, x2, p = 1, npoints) / npoints</code>
would return some estimate of the mean distance.
</p>


<h3>Value</h3>

<p>Numeric scalar (or <code>Inf</code>), or <code>NA</code> if one of these functions
returns <code>NA</code>.
</p>


<h3>Note</h3>

<p>Another kind of &lsquo;mean&rsquo; distance could be calculated by integrating the
difference <code>f-g</code> and dividing through the length of the interval.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Norm">Norm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xp &lt;- seq(-1, 1, length.out = 6)
yp &lt;- runge(xp)
p5 &lt;- polyfit(xp, yp, 5)
f5 &lt;- function(x) polyval(p5, x)
fnorm(runge, f5, -1, 1, p = Inf)                  #=&gt; 0.4303246
fnorm(runge, f5, -1, 1, p = Inf, npoints = 1000)  #=&gt; 0.4326690

# Compute mean distance using fnorm:
fnorm(runge, f5, -1, 1, p = 1, 1000) / 1000       #=&gt; 0.1094193

# Compute mean distance by integration:
fn &lt;- function(x) abs(runge(x) - f5(x))
integrate(fn, -1, 1)$value / 2                    #=&gt; 0.1095285
</code></pre>

<hr>
<h2 id='fornberg'>
Fornberg's Finite Difference Approximation
</h2><span id='topic+fornberg'></span>

<h3>Description</h3>

<p>Finite difference approximation using Fornberg's method for the derivatives
of order 1 to k based on irregulat grid values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fornberg(x, y, xs, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fornberg_+3A_x">x</code></td>
<td>
<p>grid points on the x-axis, must be distinct.</p>
</td></tr>
<tr><td><code id="fornberg_+3A_y">y</code></td>
<td>
<p>discrete values of the function at the grid points.</p>
</td></tr>
<tr><td><code id="fornberg_+3A_xs">xs</code></td>
<td>
<p>point at which to approximate (not vectorized).</p>
</td></tr>
<tr><td><code id="fornberg_+3A_k">k</code></td>
<td>
<p>order of derivative, <code>k&lt;=length(x)-1</code> required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute coefficients for finite difference approximation for the derivative
of order <code>k</code> at <code>xs</code> based on grid values at points in <code>x</code>.
For <code>k=0</code> this will evaluate the interpolating polynomial itself, but
call it with <code>k=1</code>.
</p>


<h3>Value</h3>

<p>Returns a matrix of size <code>(length(xs))</code>, where the (k+1)-th column
gives the value of the k-th derivative. Especially the first column returns 
the polynomial interpolation of the function.
</p>


<h3>Note</h3>

<p>Fornberg's method is considered to be numerically more stable than applying
Vandermonde's matrix.
</p>


<h3>References</h3>

<p>LeVeque, R. J. (2007). Finite Difference Methods for Ordinary and Partial
Differential Equations. Society for Industrial and Applied Mathematics 
(SIAM), Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+neville">neville</a></code>, <code><a href="#topic+newtonInterp">newtonInterp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 2 * pi * c(0.0, 0.07, 0.13, 0.2, 0.28, 0.34, 0.47, 0.5, 0.71, 0.95, 1.0)
y &lt;- sin(0.9*x)
xs &lt;- linspace(0, 2*pi, 51)
fornb &lt;- fornberg(x, y, xs, 10)
## Not run: 
matplot(xs, fornb, type="l")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='fprintf'>
Formatted Printing (Matlab style)
</h2><span id='topic+fprintf'></span>

<h3>Description</h3>

<p>Formatted printing to stdout or a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fprintf(fmt, ..., file = "", append = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fprintf_+3A_fmt">fmt</code></td>
<td>
<p>a character vector of format strings.</p>
</td></tr>
<tr><td><code id="fprintf_+3A_...">...</code></td>
<td>
<p>values passed to the format string.</p>
</td></tr>
<tr><td><code id="fprintf_+3A_file">file</code></td>
<td>
<p>a connection or a character string naming the file to
print to; default is &quot;&quot; which means standard output.</p>
</td></tr>
<tr><td><code id="fprintf_+3A_append">append</code></td>
<td>
<p>logical; shall the output be appended to the file;
default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fprintf</code> applies the format string <code>fmt</code> to all input
data <code>...</code> and writes the result to standard output or a file.
The usual C-style string formatting commands are used-
</p>


<h3>Value</h3>

<p>Returns invisibly the number of bytes printed (using <code>nchar</code>).
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sprintf">sprintf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Examples:
nbytes &lt;- fprintf("Results are:\n", file = "")
for (i in 1:10) {
    fprintf("%4d  %15.7f\n", i, exp(i), file = "")
}
</code></pre>

<hr>
<h2 id='fractalcurve'>
Fractal Curves
</h2><span id='topic+fractalcurve'></span>

<h3>Description</h3>

<p>Generates the following fractal curves: Dragon Curve, Gosper Flowsnake 
Curve, Hexagon Molecule Curve, Hilbert Curve, Koch Snowflake Curve, 
Sierpinski Arrowhead Curve, Sierpinski (Cross) Curve, Sierpinski Triangle
Curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fractalcurve(n, which = c("hilbert", "sierpinski", "snowflake",
    "dragon", "triangle", "arrowhead", "flowsnake", "molecule"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fractalcurve_+3A_n">n</code></td>
<td>
<p>integer, the &lsquo;order&rsquo; of the curve</p>
</td></tr>
<tr><td><code id="fractalcurve_+3A_which">which</code></td>
<td>
<p>character string, which curve to cumpute.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hilbert curve is a continuous curve in the plane with 4^N points.
</p>
<p>The Sierpinski (cross) curve is a closed curve in the plane with 4^(N+1)+1
points.
</p>
<p>His arrowhead curve is a continuous curve in the plane with 3^N+1 points,
and his triangle curve is a closed curve in the plane with 2*3^N+2 points.
</p>
<p>The Koch snowflake curve is a closed curve in the plane with 3*2^N+1
points.
</p>
<p>The dragon curve is a continuous curve in the plane with 2^(N+1) points.
</p>
<p>The flowsnake curve is a continuous curve in the plane with 7^N+1 points.
</p>
<p>The hexagon molecule curve is a closed curve in the plane with 6*3^N+1
points.
</p>


<h3>Value</h3>

<p>Returns a list with <code>x, y</code> the x- resp. y-coordinates of the
generated points describing the fractal curve.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 2011 Jonas Lundgren for the Matlab toolbox <code>fractal 
  curves</code> available on MatlabCentral under BSD license;
here re-implemented in R with explicit allowance from the author.
</p>


<h3>References</h3>

<p>Peitgen, H.O., H. Juergens, and D. Saupe (1993). Fractals for the
Classroom. Springer-Verlag Berlin Heidelberg.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The Hilbert curve transforms a 2-dim. function into a time series.
z &lt;- fractalcurve(4, which = "hilbert")

## Not run: 
f1 &lt;- function(x, y) x^2 + y^2
plot(f1(z$x, z$y), type = 'l', col = "darkblue", lwd = 2,
     ylim = c(-1, 2), main = "Functions transformed by Hilbert curves")

f2 &lt;- function(x, y) x^2 - y^2
lines(f2(z$x, z$y), col = "darkgreen", lwd = 2)

f3 &lt;- function(x, y) x^2 * y^2
lines(f3(z$x, z$y), col = "darkred", lwd = 2)
grid()
## End(Not run)

## Not run: 
## Show some more fractal surves
n &lt;- 8
opar &lt;- par(mfrow=c(2,2), mar=c(2,2,1,1))

z &lt;- fractalcurve(n, which="dragon")
x &lt;- z$x; y &lt;- z$y
plot(x, y, type='l', col="darkgrey", lwd=2)
title("Dragon Curve")

z &lt;- fractalcurve(n, which="molecule")
x &lt;- z$x; y &lt;- z$y
plot(x, y, type='l', col="darkblue")
title("Molecule Curve")

z &lt;- fractalcurve(n, which="arrowhead")
x &lt;- z$x; y &lt;- z$y
plot(x, y, type='l', col="darkgreen")
title("Arrowhead Curve")

z &lt;- fractalcurve(n, which="snowflake")
x &lt;- z$x; y &lt;- z$y
plot(x, y, type='l', col="darkred", lwd=2)
title("Snowflake Curve")

par(opar)
## End(Not run)
</code></pre>

<hr>
<h2 id='fresnelS+2FC'>
Fresnel Integrals
</h2><span id='topic+fresnelS'></span><span id='topic+fresnelC'></span>

<h3>Description</h3>

<p>(Normalized) Fresnel integrals S(x) and C(x)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fresnelS(x)
fresnelC(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fresnelS+2B2FC_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>normalized</em> Fresnel integrals are defined as
</p>
<p style="text-align: center;"><code class="reqn">S(x) = \int_0^x \sin(\pi/2 \, t^2) dt</code>
</p>

<p style="text-align: center;"><code class="reqn">C(x) = \int_0^x \cos(\pi/2 \, t^2) dt</code>
</p>

<p>This program computes the Fresnel integrals S(x) and C(x) using Fortran
code by Zhang and Jin. The accuracy is almost up to Machine precision.
</p>
<p>The functions are not (yet) truly vectorized, but use a call to &lsquo;apply&rsquo;.
The underlying function <code>.fresnel</code> (not exported) computes single
values of <code>S(x)</code> and <code>C(x)</code> at the same time.
</p>


<h3>Value</h3>

<p>Numeric vector of function values.
</p>


<h3>Note</h3>

<p>Copyright (c) 1996 Zhang and Jin for the Fortran routines, converted to
Matlab using the open source project &lsquo;f2matlab&rsquo; by Ben Barrowes, posted to
MatlabCentral in 2004, and then translated to R by Hans W. Borchers.
</p>


<h3>References</h3>

<p>Zhang, S., and J. Jin (1996). Computation of Special Functions.
Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussLegendre">gaussLegendre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Compute Fresnel integrals through Gauss-Legendre quadrature
f1 &lt;- function(t) sin(0.5 * pi * t^2)
f2 &lt;- function(t) cos(0.5 * pi * t^2)
for (x in seq(0.5, 2.5, by = 0.5)) {
    cgl &lt;- gaussLegendre(51, 0, x)
    fs &lt;- sum(cgl$w * f1(cgl$x))
    fc &lt;- sum(cgl$w * f2(cgl$x))
    cat(formatC(c(x, fresnelS(x), fs, fresnelC(x), fc),
        digits = 8, width = 12, flag = " ----"), "\n")
}

## Not run: 
xs &lt;- seq(0, 7.5, by = 0.025)
ys &lt;- fresnelS(xs)
yc &lt;- fresnelC(xs)

##  Function plot of the Fresnel integrals
plot(xs, ys, type = "l", col = "darkgreen",
    xlim = c(0, 8), ylim = c(0, 1),
    xlab = "", ylab = "", main = "Fresnel Integrals")
lines(xs, yc, col = "blue")
legend(6.25, 0.95, c("S(x)", "C(x)"), col = c("darkgreen", "blue"), lty = 1)
grid()

##  The Cornu (or Euler) spiral
plot(c(-1, 1), c(-1, 1), type = "n",
    xlab = "", ylab = "", main = "Cornu Spiral")
lines(ys, yc, col = "red")
lines(-ys, -yc, col = "red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='fsolve'>
Solve System of Nonlinear Equations
</h2><span id='topic+fsolve'></span>

<h3>Description</h3>

<p>Solve a system of <code>m</code> nonlinear equations of <code>n</code> variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fsolve(f, x0, J = NULL,
       maxiter = 100, tol = .Machine$double.eps^(0.5), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fsolve_+3A_f">f</code></td>
<td>
<p>function describing the system of equations.</p>
</td></tr>
<tr><td><code id="fsolve_+3A_x0">x0</code></td>
<td>
<p>point near to the root.</p>
</td></tr>
<tr><td><code id="fsolve_+3A_j">J</code></td>
<td>
<p>Jacobian function of <code>f</code>, or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="fsolve_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations in <code>gaussNewton</code>.</p>
</td></tr>
<tr><td><code id="fsolve_+3A_tol">tol</code></td>
<td>
<p>tolerance to be used in Gauss-Newton.</p>
</td></tr>
<tr><td><code id="fsolve_+3A_...">...</code></td>
<td>
<p>additional variables to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fsolve</code> tries to solve the components of function <code>f</code>
simultaneously and uses the Gauss-Newton method with numerical gradient
and Jacobian. If <code>m = n</code>, it uses <code>broyden</code>. Not applicable
for univariate root finding.
</p>


<h3>Value</h3>

<p>List with
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>location of the solution.</p>
</td></tr>
<tr><td><code>fval</code></td>
<td>
<p>function value at the solution.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>fsolve</code> mimics the Matlab function of the same name.
</p>


<h3>References</h3>

<p>Antoniou, A., and W.-S. Lu (2007). Practical Optimization: Algorithms and
Engineering Applications. Springer Science+Business Media, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+broyden">broyden</a></code>, <code><a href="#topic+gaussNewton">gaussNewton</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Find a matrix X such that X * X * X = [1, 2; 3, 4]
  F &lt;- function(x) {
    a &lt;- matrix(c(1, 3, 2, 4), nrow = 2, ncol = 2, byrow = TRUE)
    X &lt;- matrix(x,             nrow = 2, ncol = 2, byrow = TRUE)
    return(c(X %*% X %*% X - a))
  }
  x0 &lt;- matrix(1, 2, 2)
  X  &lt;- matrix(fsolve(F, x0)$x, 2, 2)
  X
  # -0.1291489  0.8602157
  #  1.2903236  1.1611747

## End(Not run)
</code></pre>

<hr>
<h2 id='fzero'>
Root Finding Algorithm
</h2><span id='topic+fzero'></span>

<h3>Description</h3>

<p>Find root of continuous function of one variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fzero(fun, x, maxiter = 500, tol = 1e-12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fzero_+3A_fun">fun</code></td>
<td>
<p>function whose root is sought.</p>
</td></tr>
<tr><td><code id="fzero_+3A_x">x</code></td>
<td>
<p>a point near the root or an interval giving end points.</p>
</td></tr>
<tr><td><code id="fzero_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="fzero_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="fzero_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fzero</code> tries to find a zero of <code>f</code> near <code>x</code>, if <code>x</code>
is a scalar. Expands the interval until different signs are found at the
endpoints or the maximum number of iterations is exceeded.
If <code>x</code> is a vector of length two, <code>fzero</code> assumes <code>x</code> is
an interval where the sign of <code>x[1]</code> differs from the sign of
<code>x[1]</code>. An error occurs if this is not the case.
</p>
<p>&ldquo;This is essentially the ACM algorithm 748. The structure of the algorithm
has been transformed non-trivially: it implement here a FSM version using
one interior point determination and one bracketing per iteration, thus
reducing the number of temporary variables and simplifying the structure.&rdquo;
</p>
<p>This approach will not find zeroes of quadratic order.
</p>


<h3>Value</h3>

<p><code>fzero</code> returns a list with
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>location of the root.</p>
</td></tr>
<tr><td><code>fval</code></td>
<td>
<p>function value at the root.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>fzero</code> mimics the Matlab function of the same name, but is translated
from Octave's <code>fzero</code> function, copyrighted (c) 2009 by Jaroslav Hajek.
</p>


<h3>References</h3>

<p>Alefeld, Potra and Shi (1995). Enclosing Zeros of Continuous Functions.
ACM Transactions on Mathematical Software, Vol. 21, No. 3.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code>, <code><a href="#topic+brent">brent</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fzero(sin, 3)                    # 3.141593
fzero(cos,c(1, 2))               # 1.570796
fzero(function(x) x^3-2*x-5, 2)  # 2.094551
</code></pre>

<hr>
<h2 id='fzsolve'>
Complex Root Finding
</h2><span id='topic+fzsolve'></span>

<h3>Description</h3>

<p>Find the root of a complex function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fzsolve(fz, z0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fzsolve_+3A_fz">fz</code></td>
<td>
<p>complex(-analytic) function.</p>
</td></tr>
<tr><td><code id="fzsolve_+3A_z0">z0</code></td>
<td>
<p>complex point near the assumed root.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fzsolve</code> tries to find the root of the complex and relatively
smooth (i.e., analytic) function near a starting point.
</p>
<p>The function is considered as real function <code>R^2 --&gt; R^2</code> and the
<code>newtonsys</code> function is applied.
</p>


<h3>Value</h3>

<p>Complex point with sufficiently small function value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonsys">newtonsys</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fz &lt;- function(z) sin(z)^2 + sqrt(z) - log(z)
fzsolve(fz, 1+1i)
# 0.2555197+0.8948303i
</code></pre>

<hr>
<h2 id='gammainc'>
Incomplete Gamma Function
</h2><span id='topic+gammainc'></span><span id='topic+incgam'></span>

<h3>Description</h3>

<p>Lower and upper incomplete gamma function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammainc(x, a)

incgam(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammainc_+3A_x">x</code></td>
<td>
<p>positive real number.</p>
</td></tr>
<tr><td><code id="gammainc_+3A_a">a</code></td>
<td>
<p>real number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gammainc</code> computes the lower and upper incomplete gamma
function, including the regularized gamma function. The lower and
upper incomplete gamma functions are defined as 
</p>
<p style="text-align: center;"><code class="reqn">\gamma(x, a) = \int_0^x e^{-t} \, t^{a-1} \, dt</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\Gamma(x, a) = \int_x^{\infty} e^{-t} \, t^{a-1} \, dt</code>
</p>

<p>while the regularized incomplete gamma function is
<code class="reqn">\gamma(x, a)/\Gamma(a)</code>.
</p>
<p><code>incgam</code> (a name used in Pari/GP) computes the upper incomplete
gamma function alone, applying the R function <code>pgamma</code>. The
accuracy is thus much higher. It works for <code>a &gt;= -1</code>, for even
smaller values a recursion will give the result.
</p>


<h3>Value</h3>

<p><code>gammainc</code> returns a list with the values of the lower, the
upper, and regularized lower incomplete gamma function.
<code>incgam</code> only returns the value of the incomplete upper gamma
function.
</p>


<h3>Note</h3>

<p>Directly converting Fortran code is often easier than translating
Matlab code generated with f2matlab.
</p>


<h3>References</h3>

<p>Zhang, Sh., and J. Jin (1996). Computation of Special Functions.
Wiley-Interscience, New York.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gamma">gamma</a></code>, <code><a href="stats.html#topic+pgamma">pgamma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gammainc( 1.5, 2)
gammainc(-1.5, 2)

incgam(3, 1.2)
incgam(3, 0.5); incgam(3, -0.5)
</code></pre>

<hr>
<h2 id='gammaz'>
Complex Gamma Function
</h2><span id='topic+gammaz'></span>

<h3>Description</h3>

<p>Gamma function valid in the entire complex plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaz(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammaz_+3A_z">z</code></td>
<td>
<p>Real or complex number or a numeric or complex vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the Gamma function for complex arguments using the Lanczos series
approximation.
</p>
<p>Accuracy is 15 significant digits along the real axis and 13 significant
digits elsewhere.
</p>
<p>To compute the logarithmic Gamma function use <code>log(gammaz(z))</code>.
</p>


<h3>Value</h3>

<p>Returns a complex vector of function values.
</p>


<h3>Note</h3>

<p>Copyright (c) 2001 Paul Godfrey for a Matlab version available on
Mathwork's Matlab Central under BSD license.
</p>
<p>Numerical Recipes used a 7 terms formula for a less effective approximation.
</p>


<h3>References</h3>

<p>Zhang, Sh., and J. Jin (1996). Computation of Special Functions.
Wiley-Interscience, New York.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gamma">gamma</a></code>, <code>gsl::lngamma_complex</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>max(gamma(1:10) - gammaz(1:10))
gammaz(-1)
gammaz(c(-2-2i, -1-1i, 0, 1+1i, 2+2i))

# Euler's reflection formula
z &lt;- 1+1i
gammaz(1-z) * gammaz(z)  # == pi/sin(pi*z)
</code></pre>

<hr>
<h2 id='gauss_kronrod'>
Gauss-Kronrod Quadrature
</h2><span id='topic+gauss_kronrod'></span>

<h3>Description</h3>

<p>Simple Gaussian-Kronrod quadrature formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gauss_kronrod(f, a, b, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gauss_kronrod_+3A_f">f</code></td>
<td>
<p>function to be integrated.</p>
</td></tr>
<tr><td><code id="gauss_kronrod_+3A_a">a</code>, <code id="gauss_kronrod_+3A_b">b</code></td>
<td>
<p>end points of the interval.</p>
</td></tr>
<tr><td><code id="gauss_kronrod_+3A_...">...</code></td>
<td>
<p>variables to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Gaussian quadrature of degree 7 with Gauss-Kronrod of degree 15 for error
estimation, the <code>quadQK15</code> procedure in the QUADPACK library.
</p>


<h3>Value</h3>

<p>List of value and relative error.
</p>


<h3>Note</h3>

<p>The function needs to be vectorized (though this could easily be changed),
but the function does not need to be defined at the end points.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quadgk">quadgk</a></code>, <code><a href="#topic+romberg">romberg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gauss_kronrod(sin, 0, pi)  #  2.000000000000000 , rel.error: 1.14e-12
gauss_kronrod(exp, 0, 1)   #  1.718281828459045 , rel.error: 0
                           #  1.718281828459045 , i.e. exp(1) - 1
</code></pre>

<hr>
<h2 id='gaussHermite'>
Gauss-Hermite Quadrature Formula
</h2><span id='topic+gaussHermite'></span>

<h3>Description</h3>

<p>Nodes and weights for the n-point Gauss-Hermite quadrature formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussHermite(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaussHermite_+3A_n">n</code></td>
<td>
<p>Number of nodes in the interval <code>]-Inf, Inf[</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Gauss-Hermite quadrature is used for integrating functions of the form
</p>
<p style="text-align: center;"><code class="reqn">\int_{-\infty}^{\infty} f(x) e^{-x^2} dx</code>
</p>

<p>over the infinite interval <code class="reqn">]-\infty, \infty[</code>.
</p>
<p><code>x</code> and <code>w</code> are obtained from a tridiagonal eigenvalue problem.
The value of such an integral is then <code>sum(w*f(x))</code>.
</p>


<h3>Value</h3>

<p>List with components <code>x</code>, the nodes or points in<code>]-Inf, Inf[</code>, and
<code>w</code>, the weights applied at these nodes.
</p>


<h3>Note</h3>

<p>The basic quadrature rules are well known and can, e. g., be found in
Gautschi (2004) &mdash; and explicit Matlab realizations in Trefethen (2000).
These procedures have also been implemented in Matlab by Geert Van Damme,
see his entries at MatlabCentral since 2010.
</p>


<h3>References</h3>

<p>Gautschi, W. (2004). Orthogonal Polynomials: Computation and Approximation.
Oxford University Press.
</p>
<p>Trefethen, L. N. (2000). Spectral Methods in Matlab. SIAM, Society for
Industrial and Applied Mathematics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussLegendre">gaussLegendre</a></code>, <code><a href="#topic+gaussLaguerre">gaussLaguerre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cc &lt;- gaussHermite(17)
# Integrate  exp(-x^2)  from -Inf to Inf
sum(cc$w)                        #=&gt; 1.77245385090552 == sqrt(pi)
# Integrate  x^2 exp(-x^2)
sum(cc$w * cc$x^2)               #=&gt; 0.88622692545276 == sqrt(pi) /2
# Integrate  cos(x) * exp(-x^2)
sum(cc$w * cos(cc$x))            #=&gt; 1.38038844704314 == sqrt(pi)/exp(1)^0.25
</code></pre>

<hr>
<h2 id='gaussLaguerre'>
Gauss-Laguerre Quadrature Formula
</h2><span id='topic+gaussLaguerre'></span>

<h3>Description</h3>

<p>Nodes and weights for the n-point Gauss-Laguerre quadrature formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussLaguerre(n, a = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaussLaguerre_+3A_n">n</code></td>
<td>
<p>Number of nodes in the interval <code>[0, Inf[</code>.</p>
</td></tr>
<tr><td><code id="gaussLaguerre_+3A_a">a</code></td>
<td>
<p>exponent of <code>x</code> in the integrand: must be greater or equal
to 0, otherwise the integral would not converge.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Gauss-Laguerre quadrature is used for integrating functions of the form
</p>
<p style="text-align: center;"><code class="reqn">\int_0^{\infty} f(x) x^a e^{-x} dx</code>
</p>

<p>over the infinite interval <code class="reqn">]0, \infty[</code>.
</p>
<p><code>x</code> and <code>w</code> are obtained from a tridiagonal eigenvalue problem.
The value of such an integral is then <code>sum(w*f(x))</code>.
</p>


<h3>Value</h3>

<p>List with components <code>x</code>, the nodes or points in<code>[0, Inf[</code>, and
<code>w</code>, the weights applied at these nodes.
</p>


<h3>Note</h3>

<p>The basic quadrature rules are well known and can, e. g., be found in
Gautschi (2004) &mdash; and explicit Matlab realizations in Trefethen (2000).
These procedures have also been implemented in Matlab by Geert Van Damme,
see his entries at MatlabCentral since 2010.
</p>


<h3>References</h3>

<p>Gautschi, W. (2004). Orthogonal Polynomials: Computation and Approximation.
Oxford University Press.
</p>
<p>Trefethen, L. N. (2000). Spectral Methods in Matlab. SIAM, Society for
Industrial and Applied Mathematics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussLegendre">gaussLegendre</a></code>, <code><a href="#topic+gaussHermite">gaussHermite</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cc &lt;- gaussLaguerre(7)
# integrate exp(-x) from 0 to Inf
sum(cc$w)                     # 1
# integrate x^2 * exp(-x)     # integral x^n * exp(-x) is n!
sum(cc$w * cc$x^2)            # 2
# integrate sin(x) * exp(-x)
cc &lt;- gaussLaguerre(17, 0)    # we need more nodes
sum(cc$w * sin(cc$x))         #=&gt; 0.499999999994907 , should be 0.5
</code></pre>

<hr>
<h2 id='gaussLegendre'>
Gauss-Legendre Quadrature Formula
</h2><span id='topic+gaussLegendre'></span>

<h3>Description</h3>

<p>Nodes and weights for the n-point Gauss-Legendre quadrature formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussLegendre(n, a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaussLegendre_+3A_n">n</code></td>
<td>
<p>Number of nodes in the interval <code>[a,b]</code>.</p>
</td></tr>
<tr><td><code id="gaussLegendre_+3A_a">a</code>, <code id="gaussLegendre_+3A_b">b</code></td>
<td>
<p>lower and upper limit of the integral; must be finite.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>x</code> and <code>w</code> are obtained from a tridiagonal eigenvalue problem.
</p>


<h3>Value</h3>

<p>List with components <code>x</code>, the nodes or points in<code>[a,b]</code>, and
<code>w</code>, the weights applied at these nodes.
</p>


<h3>Note</h3>

<p>Gauss quadrature is not suitable for functions with singularities.
</p>


<h3>References</h3>

<p>Gautschi, W. (2004). Orthogonal Polynomials: Computation and Approximation.
Oxford University Press.
</p>
<p>Trefethen, L. N. (2000). Spectral Methods in Matlab. SIAM, Society for
Industrial and Applied Mathematics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussHermite">gaussHermite</a></code>, <code><a href="#topic+gaussLaguerre">gaussLaguerre</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Quadrature with Gauss-Legendre nodes and weights
f &lt;- function(x) sin(x+cos(10*exp(x))/3)
#\dontrun{ezplot(f, -1, 1, fill = TRUE)}
cc &lt;- gaussLegendre(51, -1, 1)
Q &lt;- sum(cc$w * f(cc$x))  #=&gt; 0.0325036515865218 , true error: &lt; 1e-15

# If f is not vectorized, do an explicit summation:
Q &lt;- 0; x &lt;- cc$x; w &lt;- cc$w
for (i in 1:51) Q &lt;- Q + w[i] * f(x[i])

# If f is infinite at b = 1, set  b &lt;- b - eps  (with, e.g., eps = 1e-15)

# Use Gauss-Kronrod approach for error estimation
cc &lt;- gaussLegendre(103, -1, 1)
abs(Q - sum(cc$w * f(cc$x)))     # rel.error &lt; 1e-10

# Use Gauss-Hermite for vector-valued functions
f &lt;- function(x) c(sin(pi*x), exp(x), log(1+x))
cc &lt;- gaussLegendre(32, 0, 1)
drop(cc$w %*% matrix(f(cc$x), ncol = 3))  # c(2/pi, exp(1) - 1, 2*log(2) - 1)
# absolute error &lt; 1e-15
</code></pre>

<hr>
<h2 id='gaussNewton'>Gauss-Newton Function Minimization</h2><span id='topic+gaussNewton'></span>

<h3>Description</h3>

<p>Gauss-Newton method of minimizing a term <code class="reqn">f_1(x)^2 + \ldots + f_m(x)^2</code>
or <code class="reqn">F' F</code> where <code class="reqn">F = (f_1, \ldots, f_m)</code> is a multivariate function
of <code class="reqn">n</code> variables, not necessarily <code class="reqn">n = m</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussNewton(x0, Ffun, Jfun = NULL,
                        maxiter =100, tol = .Machine$double.eps^(1/2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaussNewton_+3A_ffun">Ffun</code></td>
<td>
<p><code>m</code> functions of <code>n</code> variables.</p>
</td></tr>
<tr><td><code id="gaussNewton_+3A_jfun">Jfun</code></td>
<td>
<p>function returning the Jacobian matrix of <code>Ffun</code>;
if <code>NULL</code>, the default, the Jacobian will be computed
numerically. The gradient of <code>f</code> will be computed
internally from the Jacobian (i.e., cannot be supplied).</p>
</td></tr>
<tr><td><code id="gaussNewton_+3A_x0">x0</code></td>
<td>
<p>Numeric vector of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="gaussNewton_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="gaussNewton_+3A_tol">tol</code></td>
<td>
<p>Tolerance, relative accuracy.</p>
</td></tr>
<tr><td><code id="gaussNewton_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves the system of equations applying the Gauss-Newton's method. It is
especially designed for minimizing a sum-of-squares of functions and can
be used to find a common zero of several function.
</p>
<p>This algorithm is described in detail in the textbook by Antoniou and Lu,
incl. different ways to modify and remedy the Hessian if not being positive
definite. Here, the approach by Goldfeld, Quandt and Trotter is used, and 
the hessian modified by the Matthews and Davies algorithm if still not
invertible.
</p>
<p>To accelerate the iteration, an inexact linesearch is applied.
</p>


<h3>Value</h3>

<p>List with components:<br />
<code>xs</code> the minimum or root found so far,<br />
<code>fs</code> the square root of sum of squares of the values of f,<br />
<code>iter</code> the number of iterations needed, and<br />
<code>relerr</code> the absoulte distance between the last two solutions.
</p>


<h3>Note</h3>

<p>If <code>n=m</code> then directly applying the <code>newtonsys</code> function might
be a better alternative.
</p>


<h3>References</h3>

<p>Antoniou, A., and W.-S. Lu (2007). Practical Optimization: Algorithms and
Engineering Applications. Springer Business+Science, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonsys">newtonsys</a></code>, <code><a href="#topic+softline">softline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f1 &lt;- function(x) c(x[1]^2 + x[2]^2 - 1, x[1] + x[2] - 1)
gaussNewton(c(4, 4), f1)

f2 &lt;- function(x) c( x[1] + 10*x[2], sqrt(5)*(x[] - x[4]),
                    (x[2] - 2*x[3])^2, 10*(x[1] - x[4])^2)
gaussNewton(c(-2, -1, 1, 2), f2)

f3 &lt;- function(x)
        c(2*x[1] - x[2] - exp(-x[1]), -x[1] + 2*x[2] - exp(-x[2]))
gaussNewton(c(0, 0), f3)
# $xs   0.5671433 0.5671433

f4 &lt;- function(x)  # Dennis Schnabel
        c(x[1]^2 + x[2]^2 - 2, exp(x[1] - 1) + x[2]^3 - 2)
gaussNewton(c(2.0, 0.5), f4)
# $xs    1 1

##  Examples (from Matlab)
F1 &lt;- function(x) c(2*x[1]-x[2]-exp(-x[1]), -x[1]+2*x[2]-exp(-x[2]))
gaussNewton(c(-5, -5), F1)

# Find a matrix X such that X %*% X %*% X = [1 2; 3 4]
F2 &lt;- function(x) {
    X &lt;- matrix(x, 2, 2)
    D &lt;- X %*% X %*% X - matrix(c(1,3,2,4), 2, 2)
    return(c(D))
}
sol &lt;- gaussNewton(ones(2,2), F2)
(X  &lt;- matrix(sol$xs, 2, 2))
#            [,1]      [,2]
# [1,] -0.1291489 0.8602157
# [2,]  1.2903236 1.1611747
X %*% X %*% X
</code></pre>

<hr>
<h2 id='gcd+2C+20lcm'>GCD and LCM Integer Functions</h2><span id='topic+gcd'></span><span id='topic+Lcm'></span>

<h3>Description</h3>

<p>Greatest common divisor and least common multiple
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcd(a, b, extended = FALSE)
Lcm(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcd+2B2C+2B20lcm_+3A_a">a</code>, <code id="gcd+2B2C+2B20lcm_+3A_b">b</code></td>
<td>
<p>vectors of integers.</p>
</td></tr>
<tr><td><code id="gcd+2B2C+2B20lcm_+3A_extended">extended</code></td>
<td>
<p>logical; if <code>TRUE</code>
the extended Euclidean algorithm will be applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation based on the extended Euclidean algorithm.
</p>
<p>If both <code>a</code> and <code>b</code> are vectors of the same length, the greatest 
common divisor/lowest common multiple will be computed elementwise.
If one is a vektor, the other a scalar, the scalar will be replicated to
the same length.
</p>


<h3>Value</h3>

<p>A numeric (integer) value or vector of integers. Or a list of three vectors
named <code>c, d, g</code>, g containing the greatest common divisors, such that
</p>
<p><code>g = c * a + d * b</code>.
</p>


<h3>Note</h3>

<p>The following relation is always true:
</p>
<p><code>n * m = gcd(n, m) * lcm(n, m)</code>
</p>


<h3>See Also</h3>

<p><code>numbers::extGCD</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gcd(12, 1:24)
gcd(46368, 75025)  # Fibonacci numbers are relatively prime to each other
Lcm(12, 1:24)
Lcm(46368, 75025)  # = 46368 * 75025
</code></pre>

<hr>
<h2 id='geo_median'>
Geometric Median
</h2><span id='topic+geo_median'></span>

<h3>Description</h3>

<p>Compute the &ldquo;geometric median&rdquo; of points in n-dimensional space, that is
the point with the least sum of (Euclidean) distances to all these points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geo_median(P, tol = 1e-07, maxiter = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geo_median_+3A_p">P</code></td>
<td>
<p>matrix of points, <code>x_i</code>-coordinates in the ith column.</p>
</td></tr>
<tr><td><code id="geo_median_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="geo_median_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The task is solved applying an iterative process, known as Weiszfeld's 
algorithm. The solution is unique whenever the points are not collinear.
</p>
<p>If the dimension is 1 (one column), the median will be returned.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>p</code> the coordinates of the solution 
point, <code>d</code> the sum of distances to all the sample points, <code>reltol</code> 
the relative tolerance of the iterative process, and <code>niter</code> the 
number of iterations.
</p>


<h3>Note</h3>

<p>This is also known as the &ldquo;1-median problem&rdquo; and can be generalized to the 
&ldquo;k-median problem&rdquo; for k cluster centers; 
see <code>kcca</code> in the &lsquo;flexclust&rsquo; package.
</p>


<h3>References</h3>

<p>See Wikipedia's entry on &ldquo;Geometric median&rdquo;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+L1linreg">L1linreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate 100 points on the unit sphere in the 10-dim. space
set.seed(1001)
P &lt;- rands(n=100, N=9)
( sol &lt;- geo_median(P) )
# $p
#  [1] -0.009481361 -0.007643410 -0.001252910  0.006437703 -0.019982885 -0.045337987
#  [7]  0.036249563  0.003232175  0.035040592  0.046713023
# $d
# [1] 99.6638
# $reltol
# [1] 3.069063e-08
# $niter
# [1] 10
</code></pre>

<hr>
<h2 id='geomean+2C+20harmmean'>
Geometric and Harmonic Mean (Matlab Style)
</h2><span id='topic+geomean'></span><span id='topic+harmmean'></span><span id='topic+trimmean'></span>

<h3>Description</h3>

<p>Geometric and harmonic mean along a dimension of a vector, matrix, or
array.<br />
<code>trimmean</code> is almost the same as <code>mean</code> in R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geomean(x, dim = 1)
harmmean(x, dim = 1)

trimmean(x, percent = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geomean+2B2C+2B20harmmean_+3A_x">x</code></td>
<td>
<p>numeric vector, matrix, or array.</p>
</td></tr>
<tr><td><code id="geomean+2B2C+2B20harmmean_+3A_dim">dim</code></td>
<td>
<p>dimension along which to take the mean; <code>dim=1</code> means
along columns, <code>dim=2</code> along rows, the result will still
be a row vector, not a column vector as in Matlab.</p>
</td></tr>
<tr><td><code id="geomean+2B2C+2B20harmmean_+3A_percent">percent</code></td>
<td>
<p>percentage, between 0 and 100, of trimmed values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>trimmean</code> does not call <code>mean</code> with the <code>trim</code> option, but
rather calculates <code>k&lt;-round(n*percent/100/2)</code> and leaves out <code>k</code>
values at the beginning and end of the sorted <code>x</code> vector (or row or
column of a matrix).
</p>


<h3>Value</h3>

<p>Returns a scalar or vector (or array) of geometric or harmonic means:
For <code>dim=1</code> the mean of columns, <code>dim=2</code> the mean of rows, etc.
</p>


<h3>Note</h3>

<p>To have an exact analogue of <code>mean(x)</code> in Matlab,
apply <code>trimmean(x)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(1:12, 3, 4)
geomean(A, dim = 1)
## [1]  1.817121  4.932424  7.958114 10.969613
harmmean(A, dim = 2)
## [1] 2.679426 4.367246 5.760000

x &lt;- c(-0.98, -0.90, -0.68, -0.61, -0.61, -0.38, -0.37, -0.32, -0.20, -0.16,
        0.00,  0.05,  0.12,  0.30,  0.44,  0.77,  1.37,  1.64,  1.72,  2.80)
trimmean(x); trimmean(x, 20)    # 0.2  0.085
mean(x); mean(x, 0.10)          # 0.2  0.085
</code></pre>

<hr>
<h2 id='givens'>Givens Rotation</h2><span id='topic+givens'></span>

<h3>Description</h3>

<p>Givens Rotations and QR decomposition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>givens(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="givens_+3A_a">A</code></td>
<td>
<p>numeric square matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>givens(A)</code> returns a QR decomposition (or factorization) of the
square matrix <code>A</code> by applying unitary 2-by-2 matrices <code>U</code> such
that <code>U * [xk;xl] = [x,0]</code> where <code>x=sqrt(xk^2+xl^2)</code>
</p>


<h3>Value</h3>

<p>List with two matrices <code>Q</code> and <code>R</code>, <code>Q</code> orthonormal and
<code>R</code> upper triangular, such that <code>A=Q%*%R</code>.
</p>


<h3>References</h3>

<p>Golub, G. H., and Ch. F. van Loan (1996). Matrix Computations.
Third edition, John Hopkins University Press, Baltimore.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+householder">householder</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  QR decomposition
A &lt;- matrix(c(0,-4,2, 6,-3,-2, 8,1,-1), 3, 3, byrow=TRUE)
gv &lt;- givens(A)
(Q &lt;- gv$Q); (R &lt;- gv$R)
zapsmall(Q %*% R)

givens(magic(5))
</code></pre>

<hr>
<h2 id='gmres'>
Generalized Minimal Residual Method
</h2><span id='topic+gmres'></span>

<h3>Description</h3>

<p><code>gmres(A,b)</code> attempts to solve the system of linear equations
<code>A*x=b</code> for <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    gmres(A, b, x0 = rep(0, length(b)), 
          errtol = 1e-6, kmax = length(b)+1, reorth = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmres_+3A_a">A</code></td>
<td>
<p>square matrix.</p>
</td></tr>
<tr><td><code id="gmres_+3A_b">b</code></td>
<td>
<p>numerical vector or column vector.</p>
</td></tr>
<tr><td><code id="gmres_+3A_x0">x0</code></td>
<td>
<p>initial iterate.</p>
</td></tr>
<tr><td><code id="gmres_+3A_errtol">errtol</code></td>
<td>
<p>relative residual reduction factor.</p>
</td></tr>
<tr><td><code id="gmres_+3A_kmax">kmax</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="gmres_+3A_reorth">reorth</code></td>
<td>
<p>reorthogonalization method, see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Iterative method for the numerical solution of a system of linear equations. 
The method approximates the solution by the vector in a Krylov subspace with 
minimal residual. The Arnoldi iteration is used to find this vector.
</p>
<p>Reorthogonalization method:<br />
1 &ndash; Brown/Hindmarsh condition (default)<br />
2 &ndash; Never reorthogonalize (not recommended)<br />
3 &ndash; Always reorthogonalize (not cheap!)
</p>


<h3>Value</h3>

<p>Returns a list with components <code>x</code> the solution, <code>error</code> the 
vector of residual norms, and <code>niter</code> the number of iterations.
</p>


<h3>Author(s)</h3>

<p>Based on Matlab code from C. T. Kelley's book, see references.
</p>


<h3>References</h3>

<p>C. T. Kelley (1995). Iterative Methods for Linear and Nonlinear Equations.
SIAM, Society for Industrial and Applied Mathematics, Philadelphia, USA.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+solve">solve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(0.46, 0.60, 0.74, 0.61, 0.85,
              0.56, 0.31, 0.80, 0.94, 0.76,
              0.41, 0.19, 0.15, 0.33, 0.06,
              0.03, 0.92, 0.15, 0.56, 0.08,
              0.09, 0.06, 0.69, 0.42, 0.96), 5, 5)
x &lt;- c(0.1, 0.3, 0.5, 0.7, 0.9)
b &lt;- A %*% x
gmres(A, b)
# $x
#      [,1]
# [1,]  0.1
# [2,]  0.3
# [3,]  0.5
# [4,]  0.7
# [5,]  0.9
# 
# $error
# [1] 2.37446e+00 1.49173e-01 1.22147e-01 1.39901e-02 1.37817e-02 2.81713e-31
# 
# $niter
# [1] 5
</code></pre>

<hr>
<h2 id='golden_ratio'>
Golden Ratio Search
</h2><span id='topic+golden_ratio'></span>

<h3>Description</h3>

<p>Golden Ratio search for a univariate function minimum in a bounded interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>golden_ratio(f, a, b, ..., maxiter = 100, tol = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="golden_ratio_+3A_f">f</code></td>
<td>
<p>Function or its name as a string.</p>
</td></tr>
<tr><td><code id="golden_ratio_+3A_a">a</code>, <code id="golden_ratio_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="golden_ratio_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="golden_ratio_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance; default <code>sqrt(eps)</code>.</p>
</td></tr>
<tr><td><code id="golden_ratio_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&lsquo;Golden ratio&rsquo; search for a univariate function minimum in a bounded interval.
</p>


<h3>Value</h3>

<p>Return a list with components <code>xmin</code>, <code>fmin</code>, 
the function value at the minimum, <code>niter</code>, the number of iterations
done, and the estimated precision <code>estim.prec</code>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
golden_ratio(f, 0, 4, tol=10^-10)  # $xmin    = 3.24848329206212
optimize(f, c(0,4), tol=10^-10)    # $minimum = 3.24848328971188
</code></pre>

<hr>
<h2 id='grad'>
Numerical Gradient
</h2><span id='topic+grad'></span>

<h3>Description</h3>

<p>Numerical function gradient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad(f, x0, heps = .Machine$double.eps^(1/3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grad_+3A_f">f</code></td>
<td>
<p>function of several variables.</p>
</td></tr>
<tr><td><code id="grad_+3A_x0">x0</code></td>
<td>
<p>point where the gradient is to build.</p>
</td></tr>
<tr><td><code id="grad_+3A_heps">heps</code></td>
<td>
<p>step size.</p>
</td></tr>
<tr><td><code id="grad_+3A_...">...</code></td>
<td>
<p>more variables to be passed to function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the gradient
</p>
<p style="text-align: center;"><code class="reqn">(\frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n})</code>
</p>

<p>numerically using the &ldquo;central difference formula&rdquo;.
</p>


<h3>Value</h3>

<p>Vector of the same length as <code>x0</code>.
</p>


<h3>References</h3>

<p>Mathews, J. H., and K. D. Fink (1999). Numerical Methods Using Matlab.
Third Edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fderiv">fderiv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(u) {
    x &lt;- u[1]; y &lt;- u[2]; z &lt;- u[3]
    return(x^3 + y^2 + z^2 +12*x*y + 2*z)
 }
x0 &lt;- c(1,1,1)
grad(f, x0)     # 15 14  4        # direction of steepest descent

sum(grad(f, x0) * c(1, -1, 0))    # 1 , directional derivative

f &lt;- function(x) x[1]^2 + x[2]^2
grad(f, c(0,0))                   # 0 0 , i.e. a local optimum
</code></pre>

<hr>
<h2 id='gradient'>
Discrete Gradient (Matlab Style)
</h2><span id='topic+gradient'></span>

<h3>Description</h3>

<p>Discrete numerical gradient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gradient(F, h1 = 1, h2 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gradient_+3A_f">F</code></td>
<td>
<p>vector of function values, or a matrix of values of a function
of two variables.</p>
</td></tr>
<tr><td><code id="gradient_+3A_h1">h1</code></td>
<td>
<p>x-coordinates of grid points, or one value for the difference
between grid points in x-direction.</p>
</td></tr>
<tr><td><code id="gradient_+3A_h2">h2</code></td>
<td>
<p>y-coordinates of grid points, or one value for the difference
between grid points in y-direction.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the numerical gradient of a vector or matrix as a vector or matrix
of discrete slopes in x- (i.e., the differences in horizontal direction)
and slopes in y-direction (the differences in vertical direction).
</p>
<p>A single spacing value, <code>h</code>, specifies the spacing between points in
every direction, where the points are assumed equally spaced.
</p>


<h3>Value</h3>

<p>If <code>F</code> is a vector, one gradient vector will be returned.
</p>
<p>If <code>F</code> is a matrix, a list with two components will be returned:
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>numerical gradient/slope in x-direction.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>numerical gradient/slope in x-direction.</p>
</td></tr>
</table>
<p>where each matrix is of the same size as <code>F</code>.
</p>


<h3>Note</h3>

<p>TODO: If <code>h2</code> is missing, it will not automatically be adapted.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fderiv">fderiv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0, 1, by=0.2)
y &lt;- c(1, 2, 3)
(M &lt;- meshgrid(x, y))
gradient(M$X^2 + M$Y^2)
gradient(M$X^2 + M$Y^2, x, y)

## Not run: 
# One-dimensional example
x &lt;- seq(0, 2*pi, length.out = 100)
y &lt;- sin(x)
f &lt;- gradient(y, x)
max(f - cos(x))      #=&gt; 0.00067086
plot(x, y, type = "l", col = "blue")
lines(x, cos(x), col = "gray", lwd = 3)
lines(x, f, col = "red")
grid()

# Two-dimensional example
v &lt;- seq(-2, 2, by=0.2)
X &lt;- meshgrid(v, v)$X
Y &lt;- meshgrid(v, v)$Y

Z &lt;- X * exp(-X^2 - Y^2)
image(v, v, t(Z))
contour(v, v, t(Z), col="black", add = TRUE)
grid(col="white")

grX &lt;- gradient(Z, v, v)$X
grY &lt;- gradient(Z, v, v)$Y

quiver(X, Y, grX, grY, scale = 0.2, col="blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='gramSchmidt'>Gram-Schmidt</h2><span id='topic+gramSchmidt'></span>

<h3>Description</h3>

<p>Modified Gram-Schmidt Process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  gramSchmidt(A, tol = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gramSchmidt_+3A_a">A</code></td>
<td>
<p>numeric matrix with <code>nrow(A)&gt;=ncol(A)</code>.</p>
</td></tr>
<tr><td><code id="gramSchmidt_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for being equal to zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The modified Gram-Schmidt process uses the classical orthogonalization
process to generate step by step an orthonoral basis of a vector space.
The modified Gram-Schmidt iteration uses orthogonal projectors in order
ro make the process numerically more stable.
</p>


<h3>Value</h3>

<p>List with two matrices <code>Q</code> and <code>R</code>, <code>Q</code> orthonormal and
<code>R</code> upper triangular, such that <code>A=Q%*%R</code>.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Society for Industrial and Applied Mathematics, Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+householder">householder</a>, <a href="#topic+givens">givens</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  QR decomposition
A &lt;- matrix(c(0,-4,2, 6,-3,-2, 8,1,-1), 3, 3, byrow=TRUE)
gs &lt;- gramSchmidt(A)
(Q &lt;- gs$Q); (R &lt;- gs$R)
Q %*% R  # = A
</code></pre>

<hr>
<h2 id='hadamard'>Hadamard Matrix</h2><span id='topic+hadamard'></span>

<h3>Description</h3>

<p>Generate Hadamard matrix of a certain size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hadamard(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hadamard_+3A_n">n</code></td>
<td>
<p>An integer of the form 2^e, 12*2^e, or 20*2^e</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code>n</code>-by-<code>n</code> Hadamard matrix with <code>n&gt;2</code> exists only if
<code>rem(n,4)=0</code>. This function handles only the cases where <code>n</code>,
<code>n/12</code>, or <code>n/20</code> is a power of 2.
</p>


<h3>Value</h3>

<p>Matrix of size <code>n</code>-by-<code>n</code> of orthogonal columns consisting of
1 and -1 only.
</p>


<h3>Note</h3>

<p>Hadamard matrices have applications in combinatorics, signal processing,
and numerical analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hankel">hankel</a></code>, <code><a href="#topic+Toeplitz">Toeplitz</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hadamard(4)
H &lt;- hadamard(8)
t(H) 
</code></pre>

<hr>
<h2 id='halley'>
Halley's Root Finding Mathod
</h2><span id='topic+halley'></span>

<h3>Description</h3>

<p>Finding roots of univariate functions using the Halley method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>halley(fun, x0, maxiter = 500, tol = 1e-08, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="halley_+3A_fun">fun</code></td>
<td>
<p>function whose root is to be found.</p>
</td></tr>
<tr><td><code id="halley_+3A_x0">x0</code></td>
<td>
<p>starting value for the iteration.</p>
</td></tr>
<tr><td><code id="halley_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="halley_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance; default <code>eps^(1/2)</code></p>
</td></tr>
<tr><td><code id="halley_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Well known root finding algorithms for real, univariate, continuous
functions; the second derivative must be smooth, i.e. continuous.
The first and second derivative are computed numerically.
</p>


<h3>Value</h3>

<p>Return a list with components <code>root</code>, <code>f.root</code>, 
the function value at the found root, <code>iter</code>, the number of iterations
done, and the estimated precision <code>estim.prec</code>
</p>


<h3>References</h3>

<p><a href="https://mathworld.wolfram.com/HalleysMethod.html">https://mathworld.wolfram.com/HalleysMethod.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonRaphson">newtonRaphson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>halley(sin, 3.0)        # 3.14159265358979 in 3 iterations
halley(function(x) x*exp(x) - 1, 1.0)
                        # 0.567143290409784 Gauss' omega constant

# Legendre polynomial of degree 5
lp5 &lt;- c(63, 0, -70, 0, 15, 0)/8
f &lt;- function(x) polyval(lp5, x)
halley(f, 1.0)          # 0.906179845938664
</code></pre>

<hr>
<h2 id='hampel'>
Hampel Filter
</h2><span id='topic+hampel'></span>

<h3>Description</h3>

<p>Median absolute deviation (MAD) outlier in Time Series
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hampel(x, k, t0 = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hampel_+3A_x">x</code></td>
<td>
<p>numeric vector representing a time series</p>
</td></tr>
<tr><td><code id="hampel_+3A_k">k</code></td>
<td>
<p>window length <code>2*k+1</code> in indices</p>
</td></tr>
<tr><td><code id="hampel_+3A_t0">t0</code></td>
<td>
<p>threshold, default is 3 (Pearson's rule), see below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &lsquo;median absolute deviation&rsquo; computation is done in the <code>[-k...k]</code>
vicinity of each point at least <code>k</code> steps away from the end points of
the interval.
At the lower and upper end the time series values are preserved.
</p>
<p>A high threshold makes the filter more forgiving, a low one will declare
more points to be outliers. <code>t0&lt;-3</code> (the default) corresponds to Ron 
Pearson's 3 sigma edit rule, <code>t0&lt;-0</code> to John Tukey's median filter.
</p>


<h3>Value</h3>

<p>Returning a list <code>L</code> with <code>L$y</code> the corrected time series and
<code>L$ind</code> the indices of outliers in the &lsquo;median absolut deviation&rsquo;
sense.
</p>


<h3>Note</h3>

<p>Don't take the expression <em>outlier</em> too serious. It's just a hint to
values in the time series that appear to be unusual in the vicinity of
their neighbors under a normal distribution assumption.
</p>


<h3>References</h3>

<p>Pearson, R. K. (1999). &ldquo;Data cleaning for dynamic modeling and control&rdquo;.
European Control Conference, ETH Zurich, Switzerland.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findpeaks">findpeaks</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8421)
x &lt;- numeric(1024)
z &lt;- rnorm(1024)
x[1] &lt;- z[1]
for (i in 2:1024) {
	x[i] &lt;- 0.4*x[i-1] + 0.8*x[i-1]*z[i-1] + z[i]
}
omad &lt;- hampel(x, k=20)

## Not run: 
plot(1:1024, x, type="l")
points(omad$ind, x[omad$ind], pch=21, col="darkred")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='hankel'>Hankel Matrix</h2><span id='topic+hankel'></span>

<h3>Description</h3>

<p>Generate Hankel matrix from column and row vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  hankel(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hankel_+3A_a">a</code></td>
<td>
<p>vector that will be the first column</p>
</td></tr>
<tr><td><code id="hankel_+3A_b">b</code></td>
<td>
<p>vector that if present will form the last row.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hankel(a)</code> returns the square Hankel matrix whose first column is
<code>a</code> and whose elements are zero below the secondary diagonal. (I.e.:
<code>b</code> may be missing.)
</p>
<p><code>hankel(a, b)</code> returns a Hankel matrix whose first column is <code>a</code>
and whose last row is <code>b</code>. If the first element of <code>b</code> differs
from the last element of <code>a</code> it is overwritten by this one.
</p>


<h3>Value</h3>

<p>matrix of size <code>(length(a), length(b))</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Toeplitz">Toeplitz</a></code>, <code><a href="#topic+hadamard">hadamard</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hankel(1:5, 5:1)
</code></pre>

<hr>
<h2 id='hausdorff_dist'>Hausdorff Distance</h2><span id='topic+hausdorff_dist'></span>

<h3>Description</h3>

<p>Hausdorff distance (aka Hausdorff dimension)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hausdorff_dist(P, Q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hausdorff_dist_+3A_p">P</code>, <code id="hausdorff_dist_+3A_q">Q</code></td>
<td>
<p>numerical matrices, representing points in an m-dim. space.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the Hausdorff Distance between two sets of points, P and Q.
Sets P and Q must be matrices with the same number of columns (dimensions).
</p>
<p>The &lsquo;directional&rsquo; Hausdorff distance (dhd) is defined as:
</p>
<p>dhd(P,Q) = max p in P [ min q in Q [ ||p-q|| ] ]
</p>
<p>Intuitively dhd finds the point p from the set P that is farthest from any
point in Q and measures the distance from p to its nearest neighbor in Q.
The Hausdorff Distance is defined as max(dhd(P,Q),dhd(Q,P)).
</p>


<h3>Value</h3>

<p>A single scalar, the Hausdorff distance (dimension).
</p>


<h3>References</h3>

<p>Barnsley, M. (1993). Fractals Everywhere. Morgan Kaufmann, San Francisco.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+distmat">distmat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- matrix(c(1,1,2,2, 5,4,5,4), 4, 2)
Q &lt;- matrix(c(4,4,5,5, 2,1,2,1), 4, 2)
hausdorff_dist(P, Q)    # 4.242641 = sqrt(sum((c(4,2)-c(1,5))^2))
</code></pre>

<hr>
<h2 id='haversine'>
Haversine Formula
</h2><span id='topic+haversine'></span>

<h3>Description</h3>

<p>Haversine formula to calculate the arc distance between two points
on earth (i.e., along a great circle).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>haversine(loc1, loc2, R = 6371.0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="haversine_+3A_loc1">loc1</code>, <code id="haversine_+3A_loc2">loc2</code></td>
<td>
<p>Locations on earth; for format see Details.</p>
</td></tr>
<tr><td><code id="haversine_+3A_r">R</code></td>
<td>
<p>Average earth radius R = 6371 km, can be changed on input.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Haversine formula is more robust for the calculating the distance 
as with the spherical cosine formula. The user may want to assume a 
slightly different earth radius, so this can be provided as input.
</p>
<p>The location can be input in two different formats, as latitude and
longitude in a character string, e.g. for Frankfurt airport as
'50 02 00N, 08 34 14E', or as a numerical two-vector in degrees
(not radians).
</p>
<p>Here for latitude 'N' and 'S' stand for North and South, and for
longitude 'E' or 'W' stand for East and West. For the degrees format,
South and West must be negative.
</p>
<p>These two formats can be mixed.
</p>


<h3>Value</h3>

<p>Returns the distance in km.
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers
</p>


<h3>References</h3>

<p>Entry 'Great_circle_distance' in Wikipedia.
</p>


<h3>See Also</h3>

<p>Implementations of the Haversine formula can also be found in other
R packages, e.g. 'geoPlot' or 'geosphere'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>FRA = '50 02 00N, 08 34 14E'  # Frankfurt Airport
ORD = '41 58 43N, 87 54 17W'  # Chicago O'Hare Interntl. Airport
fra &lt;- c(50+2/60, 8+34/60+14/3600)
ord &lt;- c(41+58/60+43/3600, -(87+54/60+17/3600))

dis &lt;- haversine(FRA, ORD)    # 6971.059 km
fprintf('Flight distance Frankfurt-Chicago is %8.3f km.\n', dis)

dis &lt;- haversine(fra, ord)
fprintf('Flight distance Frankfurt-Chicago is %8.3f km.\n', dis)
</code></pre>

<hr>
<h2 id='hessenberg'>
Hessenberg Matrix
</h2><span id='topic+hessenberg'></span>

<h3>Description</h3>

<p>Generates the Hessenberg matrix for A.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hessenberg(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hessenberg_+3A_a">A</code></td>
<td>
<p>square matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An (upper) Hessenberg matrix has zero entries below the first
subdiagonal. 
</p>
<p>The function generates a Hessenberg matrix <code>H</code> and a unitary 
matrix <code>P</code> (a similarity transformation) such that
<code>A = P * H * t(P)</code>.
</p>
<p>The Hessenberg matrix has the same eigenvalues. If <code>A</code> is 
symmetric, its Hessenberg form will be a tridiagonal matrix.
</p>


<h3>Value</h3>

<p>Returns a list with two elements,
</p>
<table>
<tr><td><code>H</code></td>
<td>
<p>the upper Hessenberg Form of matrix A.</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>a unitary matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Press, Teukolsky, Vetterling, and Flannery (2007).
Numerical Recipes: The Art of Scientific Computing. 3rd Edition,
Cambridge University Press. (Section 11.6.2)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+householder">householder</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(-149,   -50,  -154,
               537,   180,   546,
               -27,    -9,   -25), nrow = 3, byrow = TRUE)
hb  &lt;- hessenberg(A)
hb
## $H
##           [,1]         [,2]        [,3]
## [1,] -149.0000  42.20367124 -156.316506
## [2,] -537.6783 152.55114875 -554.927153
## [3,]    0.0000   0.07284727    2.448851
## 
## $P
##      [,1]       [,2]      [,3]
## [1,]    1  0.0000000 0.0000000
## [2,]    0 -0.9987384 0.0502159
## [3,]    0  0.0502159 0.9987384

hb$P %*% hb$H %*% t(hb$P)
##      [,1] [,2] [,3]
## [1,] -149  -50 -154
## [2,]  537  180  546
## [3,]  -27   -9  -25
</code></pre>

<hr>
<h2 id='hessian'>
Hessian Matrix
</h2><span id='topic+hessian'></span>

<h3>Description</h3>

<p>Numerically compute the Hessian matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hessian(f, x0, h = .Machine$double.eps^(1/4), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hessian_+3A_f">f</code></td>
<td>
<p>univariate function of several variables.</p>
</td></tr>
<tr><td><code id="hessian_+3A_x0">x0</code></td>
<td>
<p>point in <code class="reqn">R^n</code>.</p>
</td></tr>
<tr><td><code id="hessian_+3A_h">h</code></td>
<td>
<p>step size.</p>
</td></tr>
<tr><td><code id="hessian_+3A_...">...</code></td>
<td>
<p>variables to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the hessian matrix based on the three-point central difference
formula, expanded to two variables.
</p>
<p>Assumes that the function has continuous partial derivatives.
</p>


<h3>Value</h3>

<p>An n-by-n matrix with <code class="reqn">\frac{\partial^2 f}{\partial x_i \partial x_j}</code>
as (i, j) entry.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hessdiag">hessdiag</a></code>, <code><a href="#topic+hessvec">hessvec</a></code>, <code><a href="#topic+laplacian">laplacian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) cos(x[1] + x[2])
x0 &lt;- c(0, 0)
hessian(f, x0)

f &lt;- function(u) {
    x &lt;- u[1]; y &lt;- u[2]; z &lt;- u[3]
    return(x^3 + y^2 + z^2 +12*x*y + 2*z)
}
x0 &lt;- c(1,1,1)
hessian(f, x0)
</code></pre>

<hr>
<h2 id='Hessian+20utilities'>Hessian utilities</h2><span id='topic+hessvec'></span><span id='topic+hessdiag'></span>

<h3>Description</h3>

<p>Fast multiplication of Hessian and vector where computation of the full 
Hessian is not needed. Or determine the diagonal of the Hessian when
non-diagonal entries are not needed or are nearly zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  hessvec(f, x, v, csd = FALSE, ...)

  hessdiag(f, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hessian+2B20utilities_+3A_f">f</code></td>
<td>
<p>function whose hessian is to be computed.</p>
</td></tr>
<tr><td><code id="Hessian+2B20utilities_+3A_x">x</code></td>
<td>
<p>point in <code>R^n</code>.</p>
</td></tr>
<tr><td><code id="Hessian+2B20utilities_+3A_v">v</code></td>
<td>
<p>vector of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="Hessian+2B20utilities_+3A_csd">csd</code></td>
<td>
<p>logocal, shall complex-step be applied.</p>
</td></tr>
<tr><td><code id="Hessian+2B20utilities_+3A_...">...</code></td>
<td>
<p>more arguments to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hessvec</code> computes the product of a Hessian of a function
times a vector without deriving the full Hessian by approximating
the gradient (see the reference). If the function allows for the
complex-step method, the gradient can be calculated much more
accurate (see <code>grad_csd</code>).
</p>
<p><code>hessdiag</code> computes only the diagonal of the Hessian by
applying the central difference formula of second order to
approximate the partial derivatives.
</p>


<h3>Value</h3>

<p><code>hessvec</code> returns the product <code>H(f,x) * v</code> as a vector.
</p>
<p><code>hessdiag</code> returns the diagonal of the Hessian of <code>f</code>.
</p>


<h3>References</h3>

<p>B.A. Pearlmutter, Fast Exact Multiplication by the Hessian, Neural Computation (1994), Vol. 6, Issue 1, pp. 147-160.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hessian">hessian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
    set.seed(1237); n &lt;- 100
    a &lt;- runif(n); b &lt;- rnorm(n)
    fn &lt;- function(x, a, b) sum(exp(-a*x)*sin(b*pi*x))
    x0 &lt;- rep(1, n)
    v0 &lt;- rexp(n, rate=0.1)
    
    # compute with full hessian
    h0 &lt;- hessian(fn, x0, a = a, b = b)             # n=100 runtimes
    v1 &lt;- c(h0 %*% v0)                              # 0.167   sec
    
    v2 &lt;- hessvec(fn, x0, v0, a = a, b = b)         # 0.00209 sec
    v3 &lt;- hessvec(fn, x0, v0, csd=TRUE,a=a, b=b)    # 0.00145 sec
    v4 &lt;- hessdiag(fn, x0, a = a, b = b) * v0       # 0.00204 sec
    
    # compare with exact analytical Hessian
    hex &lt;- diag((a^2-b^2*pi^2)*exp(-a*x0)*sin(b*pi*x0) - 
                 2*a*b*pi*exp(-a*x0)*cos(b*pi*x0))
    vex &lt;- c(hex %*% v0)

    max(abs(vex - v1))          # 2.48e-05
    max(abs(vex - v2))          # 7.15e-05
    max(abs(vex - v3))          # 0.09e-05
    max(abs(vex - v4))          # 2.46e-05 
## End(Not run)
</code></pre>

<hr>
<h2 id='hilb'>Hilbert Matrix</h2><span id='topic+hilb'></span>

<h3>Description</h3>

<p>Generate Hilbert matrix of dimension n
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  hilb(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hilb_+3A_n">n</code></td>
<td>
<p>positive integer specifying the dimension of the Hilbert matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generate the Hilbert matrix <code>H</code> of dimension <code>n</code> with elements
<code>H[i, j] = 1/(i+j-1)</code>.
</p>
<p>(Note: This matrix is ill-conditioned, see e.g. <code>det(hilb(6))</code>.)
</p>


<h3>Value</h3>

<p>matrix of dimension n
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vander">vander</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  hilb(5)
</code></pre>

<hr>
<h2 id='histc'>
Histogram Count (Matlab style)
</h2><span id='topic+histc'></span>

<h3>Description</h3>

<p>Histogram-like counting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  histc(x, edges)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="histc_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix.</p>
</td></tr>
<tr><td><code id="histc_+3A_edges">edges</code></td>
<td>
<p>numeric vector of grid points, must be monotonically
non-decreasing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>n = histc(x,edges)</code> counts the number of values in vector <code>x</code>
that fall between the elements in the <code>edges</code> vector (which must
contain monotonically nondecreasing values).
<code>n</code> is a <code>length(edges)</code> vector containing these counts.
</p>
<p>If <code>x</code> is a matrix then <code>cnt</code> and <code>bin</code> are matrices too, and
</p>
<p><code> for (j in (1:n))  cnt[k,j] &lt;- sum(bin[, j] == k) </code>
</p>


<h3>Value</h3>

<p>returns a list with components <code>cnt</code> and <code>bin</code>.
<code>n(k)</code> counts the number of values in <code>x</code> that lie between
<code>edges(k) &lt;= x(i) &lt; edges(k+1)</code>. The last counts any values of <code>x</code>
that match <code>edges(n)</code>. Values outside the values in edges are not
counted. Use <code>-Inf</code> and <code>Inf</code> in edges to include all values.
</p>
<p><code>bin[i]</code> returns <code>k</code> if <code>edges(k) &lt;= x(i) &lt; edges(k+1)</code>,
and <code>0</code> if <code>x[i]</code> lies outside the grid.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>, <code><a href="#topic+histss">histss</a></code>, <code><a href="base.html#topic+findInterval">findInterval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0.0, 1.0, by = 0.05)
e &lt;- seq(0.1, 0.9, by = 0.10)
histc(x, e)
# $cnt
# [1] 2 2 2 2 2 2 2 2 1
# $bin
# [1] 0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 0 0

## Not run: 
# Compare
findInterval(x, e)
# [1] 0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 9
findInterval(x, e, all.inside = TRUE)
# [1] 1 1 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 8 8 8
# cnt[i] &lt;- sum(findInterval(x, e) == i)
## End(Not run)

x &lt;- matrix( c(0.5029, 0.2375, 0.2243, 0.8495,
               0.0532, 0.1644, 0.4215, 0.4135,
               0.7854, 0.0879, 0.1221, 0.6170), 3, 4, byrow = TRUE)
e &lt;- seq(0.0, 1.0, by = 0.2)
histc(x, e)
# $cnt
#      [,1] [,2] [,3] [,4]
# [1,]    1    2    1    0
# [2,]    0    1    1    0
# [3,]    1    0    1    1
# [4,]    1    0    0    1
# [5,]    0    0    0    1
# [6,]    0    0    0    0
# 
# $bin
#      [,1] [,2] [,3] [,4]
# [1,]    3    2    2    5
# [2,]    1    1    3    3
# [3,]    4    1    1    4
</code></pre>

<hr>
<h2 id='histss'>
Histogram Bin-width Optimization
</h2><span id='topic+histss'></span>

<h3>Description</h3>

<p>Method for selecting the bin size of time histograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>histss(x, n = 100, plotting = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="histss_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix.</p>
</td></tr>
<tr><td><code id="histss_+3A_n">n</code></td>
<td>
<p>maximum number of bins.</p>
</td></tr>
<tr><td><code id="histss_+3A_plotting">plotting</code></td>
<td>
<p>logical; shall a histogram be plotted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bin sizes of histograms are optimized in a way to best displays the
underlying spike rate, for example in neurophysiological studies.
</p>


<h3>Value</h3>

<p>Returns the same list as the <code>hist</code> function; the list is invisible
if the histogram is plotted.
</p>


<h3>References</h3>

<p>Shimazaki H. and S. Shinomoto. A method for selecting the bin size of
a time histogram. Neural Computation (2007) Vol. 19(6), 1503-1527
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>, <code><a href="#topic+histc">histc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sin(seq(0, pi/2, length.out = 200))
H &lt;- histss(x, n = 50, plotting = FALSE)
## Not run: 
plot(H, col = "gainsboro")  # Compare with hist(x), or
hist(x, breaks = H$breaks)  # the same 
## End(Not run)
</code></pre>

<hr>
<h2 id='hooke_jeeves'>
Hooke-Jeeves Function Minimization Method
</h2><span id='topic+hooke_jeeves'></span>

<h3>Description</h3>

<p>An implementation of the Hooke-Jeeves algorithm for derivative-free
optimization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hooke_jeeves(x0, fn, ..., lb = NULL, ub = NULL, tol = 1e-08,
             maxfeval = 10000, target = Inf, info = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hooke_jeeves_+3A_x0">x0</code></td>
<td>
<p>starting vector.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_fn">fn</code></td>
<td>
<p>nonlinear function to be minimized.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_lb">lb</code>, <code id="hooke_jeeves_+3A_ub">ub</code></td>
<td>
<p>lower and upper bounds.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_tol">tol</code></td>
<td>
<p>relative tolerance, to be used as stopping rule.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_maxfeval">maxfeval</code></td>
<td>
<p>maximum number of allowed function evaluations.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_target">target</code></td>
<td>
<p>iteration stops when this value is reached.</p>
</td></tr>
<tr><td><code id="hooke_jeeves_+3A_info">info</code></td>
<td>
<p>logical, whether to print information during the main loop.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method computes a new point using the values of <code>f</code> at suitable
points along the orthogonal coordinate directions around the last point.
</p>


<h3>Value</h3>

<p>List with following components:
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>minimum solution found so far.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>value of <code>f</code> at minimum.</p>
</td></tr>
<tr><td><code>count</code></td>
<td>
<p>number of function evaluations.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>NOT USED at the moment.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>special info from the solver.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Hooke-Jeeves is notorious for its number of function calls.
Memoization is often suggested as a remedy.
</p>
<p>For a similar implementation of Hooke-Jeeves see the &lsquo;dfoptim&rsquo; package.
</p>


<h3>References</h3>

<p>C.T. Kelley (1999), Iterative Methods for Optimization, SIAM.
</p>
<p>Quarteroni, Sacco, and Saleri (2007), Numerical Mathematics,
Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nelder_mead">nelder_mead</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Rosenbrock function
rosenbrock &lt;- function(x) {
    n &lt;- length(x)
    x1 &lt;- x[2:n]
    x2 &lt;- x[1:(n-1)]
    sum(100*(x1-x2^2)^2 + (1-x2)^2)
}

hooke_jeeves(c(0,0,0,0), rosenbrock)
## $xmin
## [1] 1.000002 1.000003 1.000007 1.000013
## $fmin
## [1] 5.849188e-11
## $count
## [1] 1691
## $convergence
## [1] 0
## $info
## $info$solver
## [1] "Hooke-Jeeves"
## $info$iterations
## [1] 26

hooke_jeeves(rep(0,4), lb=rep(-1,4), ub=0.5, rosenbrock)
## $xmin
## [1] 0.50000000 0.26221320 0.07797602 0.00608027
## $fmin
## [1] 1.667875
## $count
## [1] 536
## $convergence
## [1] 0
## $info
## $info$solver
## [1] "Hooke-Jeeves"
## $info$iterations
## [1] 26
</code></pre>

<hr>
<h2 id='horner'>
Horner's Rule
</h2><span id='topic+horner'></span><span id='topic+hornerdefl'></span>

<h3>Description</h3>

<p>Compute the value of a polynomial via Horner's Rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>horner(p, x)
hornerdefl(p, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="horner_+3A_p">p</code></td>
<td>
<p>Numeric vector representing a polynomial.</p>
</td></tr>
<tr><td><code id="horner_+3A_x">x</code></td>
<td>
<p>Numeric scalar, vector or matrix at which to evaluate the polynomial.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>horner</code> utilizes the Horner scheme to evaluate the polynomial and its
first derivative at the same time.
</p>
<p>The polynomial <code>p = p_1*x^n + p_2*x^{n-1} + ... + p_n*x + p_{n+1}</code>
is hereby represented by the vector <code>p_1, p_2, ..., p_n, p_{n+1}</code>,
i.e. from highest to lowest coefficient.
</p>
<p><code>hornerdefl</code> uses a similar approach to return the value of <code>p</code>
at <code>x</code> and a polynomial <code>q</code> that satisfies
</p>
<p><code>p(t) = q(t) * (t - x) + r, r constant</code>
</p>
<p>which implies <code>r=0</code> if <code>x</code> is a root of <code>p</code>. This will allow
for a repeated root finding of polynomials.
</p>


<h3>Value</h3>

<p><code>horner</code> returns a list with two elements, <code>list(y=..., dy=...)</code>
where the first list elements returns the values of the polynomial, the
second the values of its derivative at the point(s) <code>x</code>.
</p>
<p><code>hornerdefl</code> returns a list <code>list(y=..., dy=...)</code> where <code>q</code>
represents a polynomial, see above.
</p>


<h3>Note</h3>

<p>For fast evaluation, there is no error checking for <code>p</code> and <code>x</code>,
which both must be numerical vectors
(<code>x</code> can be a matrix in <code>horner</code>).
</p>


<h3>References</h3>

<p>Quarteroni, A., and Saleri, F. (2006) Scientific Computing with Matlab
and Octave. Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyval">polyval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(-2, -1, 0, 1, 2)
p &lt;- c(1, 0, 1)  # polynomial x^2 + x, derivative 2*x
horner(p, x)$y   #=&gt;  5  2  1  2  5
horner(p, x)$dy  #=&gt; -4 -2  0  2  4

p &lt;- Poly(c(1, 2, 3))  # roots 1, 2, 3
hornerdefl(p, 3)          # q = x^2- 3 x + 2  with roots 1, 2
</code></pre>

<hr>
<h2 id='householder'>Householder Reflections</h2><span id='topic+householder'></span>

<h3>Description</h3>

<p>Householder reflections and QR decomposition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  householder(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="householder_+3A_a">A</code></td>
<td>
<p>numeric matrix with <code>nrow(A)&gt;=ncol(A)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Householder method applies a succession of elementary unitary
matrices to the left of matrix <code>A</code>. These matrices are the so-called
Householder reflections.
</p>


<h3>Value</h3>

<p>List with two matrices <code>Q</code> and <code>R</code>, <code>Q</code> orthonormal and
<code>R</code> upper triangular, such that <code>A=Q%*%R</code>.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Society for Industrial and Applied Mathematics, Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+givens">givens</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  QR decomposition
A &lt;- matrix(c(0,-4,2, 6,-3,-2, 8,1,-1), 3, 3, byrow=TRUE)
S &lt;- householder(A)
(Q &lt;- S$Q); (R &lt;- S$R)
Q %*% R  # = A

##  Solve an overdetermined linear system of equations
A &lt;- matrix(c(1:8,7,4,2,3,4,2,2), ncol=3, byrow=TRUE)
S &lt;- householder(A); Q &lt;- S$Q; R &lt;- S$R
m &lt;- nrow(A); n &lt;- ncol(A)
b &lt;- rep(6, 5)

x &lt;- numeric(n)
b &lt;- t(Q) %*% b
x[n] &lt;- b[n] / R[n, n]
for (k in (n-1):1)
    x[k] &lt;- (b[k] - R[k, (k+1):n] %*% x[(k+1):n]) / R[k, k]
qr.solve(A, rep(6, 5)); x
</code></pre>

<hr>
<h2 id='humps'>
Matlab Test Functions
</h2><span id='topic+humps'></span><span id='topic+sinc'></span><span id='topic+psinc'></span>

<h3>Description</h3>

<p>Matlab test functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>humps(x)
sinc(x)
psinc(x, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="humps_+3A_x">x</code></td>
<td>
<p>numeric scalar or vector.</p>
</td></tr>
<tr><td><code id="humps_+3A_n">n</code></td>
<td>
<p>positive integer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>humps</code> is a test function for finding zeros, for optimization
and integration. Its root is at <code>x = 1.2995</code>, a (local) minimum
at <code>x = 0.6370</code>, and the integral from <code>0.5</code> to <code>1.0</code>
is <code>8.0715</code>.
</p>
<p><code>sinc</code> is defined as <code class="reqn">sinc(t) = \frac{\sin(\pi t)}{\pi t}</code>.
It is the continuous inverse Fourier transform of the rectangular pulse
of width <code class="reqn">2\pi</code> and height <code class="reqn">1</code>.
</p>
<p><code>psinc</code> is the 'periodic sinc function' and is defined as
<code class="reqn">psinc(x,n) = \frac{\sin(x n/2)}{n \sin(x/2)}</code>.
</p>


<h3>Value</h3>

<p>Numeric scalar or vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plot(humps(), type="l"); grid()

x &lt;- seq(0, 10, length=101)
plot(x, sinc(x), type="l"); grid()

## End(Not run)
</code></pre>

<hr>
<h2 id='hurstexp'>
Hurst Exponent
</h2><span id='topic+hurstexp'></span>

<h3>Description</h3>

<p>Calculates the Hurst exponent using R/S analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  hurstexp(x, d = 50, display = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hurstexp_+3A_x">x</code></td>
<td>
<p>a time series.</p>
</td></tr>
<tr><td><code id="hurstexp_+3A_d">d</code></td>
<td>
<p>smallest box size; default 50.</p>
</td></tr>
<tr><td><code id="hurstexp_+3A_display">display</code></td>
<td>
<p>logical; shall the results be printed to the console?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hurstexp(x)</code> calculates the Hurst exponent of a time series <code>x</code>
using R/S analysis, after Hurst, with slightly different approaches, or
corrects it with small sample bias, see for example Weron.
</p>
<p>These approaches are a corrected R/S method, an empirical and corrected
empirical method, and a try at a theoretical Hurst exponent. It should be
mentioned that the results are sometimes very different, so providing error
estimates will be highly questionable.
</p>
<p>Optimal sample sizes are automatically computed with a length that
possesses the most divisors among series shorter than <code>x</code> by no more
than 1 percent.
</p>


<h3>Value</h3>

<p><code>hurstexp(x)</code> returns a list with the following components:
</p>

<ul>
<li> <p><code>Hs</code>  - simplified R over S approach
</p>
</li>
<li> <p><code>Hrs</code> - corrected R over S Hurst exponent
</p>
</li>
<li> <p><code>He</code>  - empirical Hurst exponent
</p>
</li>
<li> <p><code>Hal</code> - corrected empirical Hurst exponent
</p>
</li>
<li> <p><code>Ht</code>  - theoretical Hurst exponent
</p>
</li></ul>



<h3>Note</h3>

<p>Derived from Matlab code of R. Weron, published on Matlab Central.
</p>


<h3>References</h3>

<p>H.E. Hurst (1951) Long-term storage capacity of reservoirs, Transactions
of the American Society of Civil Engineers 116, 770-808.
</p>
<p>R. Weron (2002) Estimating long range dependence: finite sample properties
and confidence intervals, Physica A 312, 285-299.
</p>


<h3>See Also</h3>

<p><code>fractal::hurstSpec, RoverS, hurstBlock</code> and <code>fArma::LrdModelling</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Computing the Hurst exponent
data(brown72)
x72 &lt;- brown72                          #  H = 0.72
xgn &lt;- rnorm(1024)                      #  H = 0.50
xlm &lt;- numeric(1024); xlm[1] &lt;- 0.1     #  H = 0.43
for (i in 2:1024) xlm[i] &lt;- 4 * xlm[i-1] * (1 - xlm[i-1])

hurstexp(brown72, d = 128)           # 0.72
# Simple R/S Hurst estimation:         0.6590931 
# Corrected R over S Hurst exponent:   0.7384611 
# Empirical Hurst exponent:            0.7068613 
# Corrected empirical Hurst exponent:  0.6838251 
# Theoretical Hurst exponent:          0.5294909

hurstexp(xgn)                        # 0.50
# Simple R/S Hurst estimation:         0.5518143 
# Corrected R over S Hurst exponent:   0.5982146 
# Empirical Hurst exponent:            0.6104621 
# Corrected empirical Hurst exponent:  0.5690305 
# Theoretical Hurst exponent:          0.5368124 

hurstexp(xlm)                        # 0.43
# Simple R/S Hurst estimation:         0.4825898 
# Corrected R over S Hurst exponent:   0.5067766 
# Empirical Hurst exponent:            0.4869625 
# Corrected empirical Hurst exponent:  0.4485892 
# Theoretical Hurst exponent:          0.5368124 


##  Compare with other implementations
## Not run: 
library(fractal)

x &lt;- x72
hurstSpec(x)                    # 0.776   # 0.720
RoverS(x)                       # 0.717
hurstBlock(x, method="aggAbs")  # 0.648
hurstBlock(x, method="aggVar")  # 0.613
hurstBlock(x, method="diffvar") # 0.714
hurstBlock(x, method="higuchi") # 1.001

x &lt;- xgn
hurstSpec(x)                    # 0.538   # 0.500
RoverS(x)                       # 0.663
hurstBlock(x, method="aggAbs")  # 0.463
hurstBlock(x, method="aggVar")  # 0.430
hurstBlock(x, method="diffvar") # 0.471
hurstBlock(x, method="higuchi") # 0.574

x &lt;- xlm
hurstSpec(x)                    # 0.478   # 0.430
RoverS(x)                       # 0.622
hurstBlock(x, method="aggAbs")  # 0.316
hurstBlock(x, method="aggVar")  # 0.279
hurstBlock(x, method="diffvar") # 0.547
hurstBlock(x, method="higuchi") # 0.998

## End(Not run)
</code></pre>

<hr>
<h2 id='hypot'>Hypotenuse Function</h2><span id='topic+hypot'></span>

<h3>Description</h3>

<p>Square root of sum of squares
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypot(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hypot_+3A_x">x</code>, <code id="hypot_+3A_y">y</code></td>
<td>
<p>Vectors of real or complex numbers of the same size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Element-by-element computation of the square root of the sum of squares
of vectors resp. matrices <code>x</code> and <code>y</code>.
</p>


<h3>Value</h3>

<p>Returns a vector or matrix of the same size.
</p>


<h3>Note</h3>

<p>Returns <code>c()</code> if <code>x</code> or <code>y</code> is empty and the other one has
length 1. If one input is scalar, the other a vector, the scalar will be
extended to a vector of appropriate length. In all other cases, <code>x</code>
and <code>y</code> have to be of the same size.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hypot(3,4)
hypot(1, c(3, 4, 5))
hypot(c(0, 0), c(3, 4))
</code></pre>

<hr>
<h2 id='ifft'>
Inverse Fast Fourier Transformation
</h2><span id='topic+ifft'></span><span id='topic+ifftshift'></span><span id='topic+fftshift'></span>

<h3>Description</h3>

<p>Performs the inverse Fast Fourier Transform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ifft(x)

ifftshift(x)
fftshift(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ifft_+3A_x">x</code></td>
<td>
<p>a real or complex vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ifft</code> returns the value of the normalized discrete, univariate,
inverse Fast Fourier Transform of the values in <code>x</code>.
</p>
<p><code>ifftshift</code> and <code>fftshift</code> shift the zero-component to the center
of the spectrum, that is swap the left and right half of <code>x</code>.
</p>


<h3>Value</h3>

<p>Real or complex vector of the same length.
</p>


<h3>Note</h3>

<p>Almost an alias for R's <code>fft(x, inverse=TRUE)</code>, but dividing by
<code>length(x)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fft">fft</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1, 2, 3, 4)
(y &lt;- fft(x))
ifft(x)
ifft(y)

##  Compute the derivative: F(df/dt) = (1i*k) * F(f)
#   hyperbolic secans f &lt;- sech
df &lt;- function(x) -sech(x) * tanh(x)
d2f &lt;- function(x) sech(x) - 2*sech(x)^3
L &lt;- 20                                 # domain [-L/2, L/2]
N &lt;- 128                                # number of Fourier nodes
x &lt;- linspace(-L/2, L/2, N+1)           # domain discretization
x &lt;- x[1:N]                             # because of periodicity
dx &lt;- x[2] - x[1]                       # finite difference
u &lt;- sech(x)                            # hyperbolic secans
u1d &lt;- df(x); u2d &lt;- d2f(x)             # first and second derivative
ut &lt;- fft(u)                            # discrete Fourier transform
k &lt;- (2*pi/L)*fftshift((-N/2):(N/2-1))  # shifted frequencies
u1 &lt;- Re(ifft((1i*k) * ut))             # inverse transform
u2 &lt;- Re(ifft(-k^2 * ut))               # first and second derivative
## Not run: 
plot(x, u1d, type = "l", col = "blue")
points(x, u1)
grid()
figure()
plot(x, u2d, type = "l", col = "darkred")
points(x, u2)
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='inpolygon'>
Polygon Region
</h2><span id='topic+inpolygon'></span>

<h3>Description</h3>

<p>Points inside polygon region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inpolygon(x, y, xp, yp, boundary = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inpolygon_+3A_x">x</code>, <code id="inpolygon_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates of points to be tested for being inside
the polygon region.</p>
</td></tr>
<tr><td><code id="inpolygon_+3A_xp">xp</code>, <code id="inpolygon_+3A_yp">yp</code></td>
<td>
<p>coordinates of the vertices specifying the polygon.</p>
</td></tr>
<tr><td><code id="inpolygon_+3A_boundary">boundary</code></td>
<td>
<p>Logical; does the boundary belong to the interior.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a polygon defined by points <code>(xp, yp)</code>, determine if the
points <code>(x, y)</code> are inside or outside the polygon. The boundary
can be included or excluded (default) for the interior.
</p>


<h3>Value</h3>

<p>Logical vector, the same length as <code>x</code>.
</p>


<h3>Note</h3>

<p>Special care taken for points on the boundary.
</p>


<h3>References</h3>

<p>Hormann, K., and A. Agathos (2001). The Point in Polygon Problem for
Arbitrary Polygons. Computational Geometry, Vol. 20, No. 3, pp. 131&ndash;144.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xp &lt;- c(0.5, 0.75, 0.75, 0.5, 0.5)
yp &lt;- c(0.5, 0.5, 0.75, 0.75, 0.5)
x &lt;- c(0.6, 0.75, 0.6, 0.5)
y &lt;- c(0.5, 0.6, 0.75, 0.6)
inpolygon(x, y, xp, yp, boundary = FALSE)  # FALSE
inpolygon(x, y, xp, yp, boundary = TRUE)   # TRUE

## Not run: 
pg &lt;- matrix(c(0.15, 0.75, 0.25, 0.45, 0.70,
               0.80, 0.35, 0.55, 0.20, 0.90), 5, 2)
plot(c(0, 1), c(0, 1), type="n")
polygon(pg[,1], pg[,2])
P &lt;- matrix(runif(20000), 10000, 2)
R &lt;- inpolygon(P[, 1], P[, 2], pg[, 1], pg[,2])
clrs &lt;- ifelse(R, "red", "blue")
points(P[, 1], P[, 2], pch = ".", col = clrs)
## End(Not run)
</code></pre>

<hr>
<h2 id='integral'>
Adaptive Numerical Integration
</h2><span id='topic+integral'></span>

<h3>Description</h3>

<p>Combines several approaches to adaptive numerical integration of 
functions of one variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integral(fun, xmin, xmax,
         method = c("Kronrod", "Clenshaw","Simpson"),
         no_intervals = 8, random = FALSE,
         reltol = 1e-8, abstol = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integral_+3A_fun">fun</code></td>
<td>
<p>integrand, univariate (vectorized) function.</p>
</td></tr>
<tr><td><code id="integral_+3A_xmin">xmin</code>, <code id="integral_+3A_xmax">xmax</code></td>
<td>
<p>endpoints of the integration interval.</p>
</td></tr>
<tr><td><code id="integral_+3A_method">method</code></td>
<td>
<p>integration procedure, see below.</p>
</td></tr>
<tr><td><code id="integral_+3A_no_intervals">no_intervals</code></td>
<td>
<p>number of subdivisions at at start.</p>
</td></tr>
<tr><td><code id="integral_+3A_random">random</code></td>
<td>
<p>logical; shall the length of subdivisions be random.</p>
</td></tr>
<tr><td><code id="integral_+3A_reltol">reltol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="integral_+3A_abstol">abstol</code></td>
<td>
<p>absolute tolerance; not used.</p>
</td></tr>
<tr><td><code id="integral_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>integral</code> combines the following methods for adaptive 
numerical integration (also available as separate functions):
</p>

<ul>
<li><p> Kronrod (Gauss-Kronrod)
</p>
</li>
<li><p> Clenshaw (Clenshaw-Curtis; not yet made adaptive)
</p>
</li>
<li><p> Simpson (adaptive Simpson)
</p>
</li></ul>

<p>Recommended default method is Gauss-Kronrod. Also try Clenshaw-Curtis
that may be faster at times.
</p>
<p>Most methods require that function <code>f</code> is vectorized. This will
be checked and the function vectorized if necessary.
</p>
<p>By default, the integration domain is subdivided into <code>no_intervals</code>
subdomains to avoid 0 results if the support of the integrand function is
small compared to the whole domain. If <code>random</code> is true, nodes will
be picked randomly, otherwise forming a regular division.
</p>
<p>If the interval is infinite, <code>quadinf</code> will be called that 
accepts the same methods as well. [If the function is array-valued, 
<code>quadv</code> is called that applies an adaptive Simpson procedure,
other methods are ignored &ndash; not true anymore.]
</p>


<h3>Value</h3>

<p>Returns the integral, no error terms given.
</p>


<h3>Note</h3>

<p><code>integral</code> does not provide &lsquo;new&rsquo; functionality, everything is 
already contained in the functions called here. Other interesting
alternatives are Gauss-Richardson (<code>quadgr</code>) and Romberg 
(<code>romberg</code>) integration.
</p>


<h3>References</h3>

<p>Davis, Ph. J., and Ph. Rabinowitz (1984). Methods of Numerical 
Integration. Dover Publications, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quadgk">quadgk</a></code>, <code><a href="#topic+quadgr">quadgr</a></code>, <code>quadcc</code>,
<code><a href="#topic+simpadpt">simpadpt</a></code>, <code><a href="#topic+romberg">romberg</a></code>,
<code><a href="#topic+quadv">quadv</a></code>, <code><a href="#topic+quadinf">quadinf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Very smooth function
fun &lt;- function(x) 1/(x^4+x^2+0.9)
val &lt;- 1.582232963729353
for (m in c("Kron", "Clen", "Simp")) {
    Q &lt;- integral(fun, -1, 1, reltol = 1e-12, method = m)
    cat(m, Q, abs(Q-val), "\n")}
# Kron 1.582233 3.197442e-13 
# Rich 1.582233 3.197442e-13  # use quadgr()
# Clen 1.582233 3.199663e-13 
# Simp 1.582233 3.241851e-13 
# Romb 1.582233 2.555733e-13  # use romberg()

##  Highly oscillating function
fun &lt;- function(x) sin(100*pi*x)/(pi*x)
val &lt;- 0.4989868086930458
for (m in c("Kron", "Clen", "Simp")) {
    Q &lt;- integral(fun, 0, 1, reltol = 1e-12, method = m)
    cat(m, Q, abs(Q-val), "\n")}
# Kron 0.4989868 2.775558e-16 
# Rich 0.4989868 4.440892e-16  # use quadgr()
# Clen 0.4989868 2.231548e-14
# Simp 0.4989868 6.328271e-15 
# Romb 0.4989868 1.508793e-13  # use romberg()

## Evaluate improper integral
fun &lt;- function(x) log(x)^2 * exp(-x^2)
val &lt;- 1.9475221803007815976
Q &lt;- integral(fun, 0, Inf, reltol = 1e-12)
# For infinite domains Gauss integration is applied!
cat(m, Q, abs(Q-val), "\n")
# Kron 1.94752218028062 2.01587635473288e-11 

## Example with small function support
fun &lt;- function(x)
            ifelse (x &lt;= 0 | x &gt;= pi, 0, sin(x))
integral(fun, -100, 100, no_intervals = 1)      # 0
integral(fun, -100, 100, no_intervals = 10)     # 1.99999999723
integral(fun, -100, 100, random=FALSE)          # 2
integral(fun, -100, 100, random=TRUE)           # 2 (sometimes 0 !)
integral(fun, -1000, 10000, random=FALSE)       # 0
integral(fun, -1000, 10000, random=TRUE)        # 0 (sometimes 2 !)
</code></pre>

<hr>
<h2 id='integral2'>
Numerically Evaluate Double  and Triple Integrals
</h2><span id='topic+integral2'></span><span id='topic+integral3'></span>

<h3>Description</h3>

<p>Numerically evaluate a double integral, resp. a triple integral by
reducing it to a double integral.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integral2(fun, xmin, xmax, ymin, ymax, sector = FALSE,
            reltol = 1e-6, abstol = 0, maxlist = 5000,
            singular = FALSE, vectorized = TRUE, ...)

integral3(fun, xmin, xmax, ymin, ymax, zmin, zmax,
            reltol = 1e-6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integral2_+3A_fun">fun</code></td>
<td>
<p>function</p>
</td></tr>
<tr><td><code id="integral2_+3A_xmin">xmin</code>, <code id="integral2_+3A_xmax">xmax</code></td>
<td>
<p>lower and upper limits of x.</p>
</td></tr>
<tr><td><code id="integral2_+3A_ymin">ymin</code>, <code id="integral2_+3A_ymax">ymax</code></td>
<td>
<p>lower and upper limits of y.</p>
</td></tr>
<tr><td><code id="integral2_+3A_zmin">zmin</code>, <code id="integral2_+3A_zmax">zmax</code></td>
<td>
<p>lower and upper limits of z.</p>
</td></tr>
<tr><td><code id="integral2_+3A_sector">sector</code></td>
<td>
<p>logical.</p>
</td></tr>
<tr><td><code id="integral2_+3A_reltol">reltol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="integral2_+3A_abstol">abstol</code></td>
<td>
<p>absolute tolerance.</p>
</td></tr>
<tr><td><code id="integral2_+3A_maxlist">maxlist</code></td>
<td>
<p>maximum length of the list of rectangles.</p>
</td></tr>
<tr><td><code id="integral2_+3A_singular">singular</code></td>
<td>
<p>logical; are there singularities at vertices.</p>
</td></tr>
<tr><td><code id="integral2_+3A_vectorized">vectorized</code></td>
<td>
<p>logical; is the function fully vectorized.</p>
</td></tr>
<tr><td><code id="integral2_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>integral2</code> implements the &lsquo;TwoD&rsquo; algorithm, that is Gauss-Kronrod
with (3, 7)-nodes on 2D rectangles.
</p>
<p>The borders of the domain of integration must be finite. The limits of
<code>y</code>, that is <code>ymin</code> and <code>ymax</code>, can be constants or scalar
functions of x that describe the lower and upper boundaries. These
functions must be vectorized.
</p>
<p><code>integral2</code> attempts to satisfy <code>ERRBND &lt;= max(AbsTol,RelTol*|Q|)</code>.
This is absolute error control when <code>|Q|</code> is sufficiently small and
relative error control when <code>|Q|</code> is larger.
</p>
<p>The function <code>fun</code> itself must be fully vectorized:
It must accept arrays <code>X</code> and <code>Y</code> and return an array
<code>Z = f(X,Y)</code> of corresponding values. If option <code>vectorized</code> is
set to <code>FALSE</code> the procedure will enforce this vectorized behavior.
</p>
<p>With <code>sector=TRUE</code> the region is a generalized sector that is described
in polar coordinates (r,theta) by
</p>
<p><code>0 &lt;= a &lt;= theta &lt;= b</code> &ndash; a and b must be constants<br />
<code>c &lt;= r &lt;= d</code> &ndash; c and d can be constants or ...
</p>
<p>... functions of theta that describe the lower and upper boundaries.
Functions must be vectorized.<br />
NOTE Polar coordinates  are used only to describe the region &ndash;
the integrand is <code>f(x,y)</code> for both kinds of regions.
</p>
<p><code>integral2</code> can be applied to functions that are singular on a boundary.
With value <code>singular=TRUE</code>, this option causes <code>integral2</code> to use
transformations to weaken singularities for better performance.
</p>
<p><code>integral3</code> also accepts functions for the inner interval limits.
<code>ymin, ymax</code> must be constants or functions of one variable (<code>x</code>),
<code>zmin, zmax</code> constants or functions of two variables (<code>x, y</code>), all
functions vectorized.
</p>
<p>The triple integral will be first integrated over the second and third 
variable with <code>integral2</code>, and then integrated over a single variable 
with <code>integral</code>.
</p>


<h3>Value</h3>

<p>Returns a list with <code>Q</code> the integral and <code>error</code> the error term.
</p>


<h3>Note</h3>

<p>To avoid recursion, a possibly large matrix will be used and passed between
subprograms. A more efficient implementation may be possible.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 2008 Lawrence F. Shampine for Matlab code and description
of the program; adapted and converted to R by Hans W Borchers.
</p>


<h3>References</h3>

<p>Shampine, L. F. (2008). MATLAB Program for Quadrature in 2D.
Proceedings of Applied Mathematics and Computation, 2008, pp. 266&ndash;274.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+integral">integral</a></code>, <code>cubature:adaptIntegrate</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fun &lt;- function(x, y) cos(x) * cos(y)
integral2(fun, 0, 1, 0, 1, reltol = 1e-10)
# $Q:     0.708073418273571  # 0.70807341827357119350 = sin(1)^2
# $error: 8.618277e-19       # 1.110223e-16

##  Compute the volume of a sphere
f &lt;- function(x, y) sqrt(1 -x^2 - y^2)
xmin &lt;- 0; xmax &lt;- 1
ymin &lt;- 0; ymax &lt;- function(x) sqrt(1 - x^2)
I &lt;- integral2(f, xmin, xmax, ymin, ymax)
I$Q                             # 0.5236076 - pi/6 =&gt; 8.800354e-06

##  Compute the volume over a sector
I &lt;- integral2(f, 0,pi/2, 0,1, sector = TRUE)
I$Q                             # 0.5236308 - pi/6 =&gt; 3.203768e-05

##  Integrate 1/( sqrt(x + y)*(1 + x + y)^2 ) over the triangle
##   0 &lt;= x &lt;= 1, 0 &lt;= y &lt;= 1 - x.  The integrand is infinite at (0,0).
f &lt;- function(x,y) 1/( sqrt(x + y) * (1 + x + y)^2 )
ymax &lt;- function(x) 1 - x
I &lt;- integral2(f, 0,1, 0,ymax)
I$Q + 1/2 - pi/4                # -3.247091e-08

##  Compute this integral as a sector
rmax &lt;- function(theta) 1/(sin(theta) + cos(theta))
I &lt;- integral2(f, 0,pi/2, 0,rmax, sector = TRUE, singular = TRUE)
I$Q + 1/2 - pi/4                # -4.998646e-11

##  Examples of computing triple integrals
f0 &lt;- function(x, y, z) y*sin(x) + z*cos(x)
integral3(f0, 0, pi, 0,1, -1,1) # - 2.0 =&gt; 0.0

f1 &lt;- function(x, y, z) exp(x+y+z)
integral3(f1, 0, 1, 1, 2, 0, 0.5)
## [1] 5.206447                         # 5.20644655

f2 &lt;- function(x, y, z) x^2 + y^2 + z
a &lt;- 2; b &lt;- 4
ymin &lt;- function(x) x - 1
ymax &lt;- function(x) x + 6
zmin &lt;- -2
zmax &lt;- function(x, y) 4 + y^2
integral3(f2, a, b, ymin, ymax, zmin, zmax)
## [1] 47416.75556                      # 47416.7555556

f3 &lt;- function(x, y, z) sqrt(x^2 + y^2)
a &lt;- -2; b &lt;- 2
ymin &lt;- function(x) -sqrt(4-x^2)
ymax &lt;- function(x)  sqrt(4-x^2)
zmin &lt;- function(x, y)  sqrt(x^2 + y^2)
zmax &lt;- 2
integral3(f3, a, b, ymin, ymax, zmin, zmax)
## [1] 8.37758                          # 8.377579076269617
</code></pre>

<hr>
<h2 id='interp1'>
One-dimensional Interpolation
</h2><span id='topic+interp1'></span>

<h3>Description</h3>

<p>One-dimensional interpolation of points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interp1(x, y, xi = x,
        method = c("linear", "constant", "nearest", "spline", "cubic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interp1_+3A_x">x</code></td>
<td>
<p>Numeric vector; points on the x-axis; at least two points require;
will be sorted if necessary.</p>
</td></tr>
<tr><td><code id="interp1_+3A_y">y</code></td>
<td>
<p>Numeric vector; values of the assumed underlying function;
<code>x</code> and <code>y</code> must be of the same length.</p>
</td></tr>
<tr><td><code id="interp1_+3A_xi">xi</code></td>
<td>
<p>Numeric vector; points at which to compute the interpolation;
all points must lie between <code>min(x)</code> and <code>max(x)</code>.</p>
</td></tr>
<tr><td><code id="interp1_+3A_method">method</code></td>
<td>
<p>One of &ldquo;constant&quot;, &ldquo;linear&quot;, &ldquo;nearest&quot;, &ldquo;spline&quot;, or &ldquo;cubic&quot;; default is &ldquo;linear&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Interpolation to find <code>yi</code>, the values of the underlying function
at the points in the vector <code>xi</code>.
</p>
<p>Methods can be:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>linear</code> </td><td style="text-align: left;"> linear interpolation (default) </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>constant</code> </td><td style="text-align: left;"> constant between points </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>nearest</code> </td><td style="text-align: left;"> nearest neighbor interpolation </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>spline</code> </td><td style="text-align: left;"> cubic spline interpolation </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>cubic</code> </td><td style="text-align: left;"> cubic Hermite interpolation </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Value</h3>

<p>Numeric vector representing values at points <code>xi</code>.
</p>


<h3>Note</h3>

<p>Method &lsquo;spline&rsquo; uses the spline approach by Moler et al., and is identical 
with the Matlab option of the same name, but slightly different from R's 
spline function.
</p>
<p>The Matlab option &ldquo;cubic&rdquo; seems to have no direct correspondence in R.
Therefore, we simply use <code>pchip</code> here.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+approx">approx</a></code>, <code><a href="stats.html#topic+spline">spline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0.8, 0.3, 0.1, 0.6, 0.9, 0.5, 0.2, 0.0, 0.7, 1.0, 0.4)
y &lt;- x^2
xi &lt;- seq(0, 1, len = 81)
yl &lt;- interp1(x, y, xi, method = "linear")
yn &lt;- interp1(x, y, xi, method = "nearest")
ys &lt;- interp1(x, y, xi, method = "spline")

## Not run: 
plot(x, y); grid()
lines(xi, yl, col="blue", lwd = 2)
lines(xi, yn, col="black", lty = 2)
lines(xi, ys, col="red")
  
## End(Not run)

## Difference between spline (Matlab) and spline (R).
x &lt;- 1:6
y &lt;- c(16, 18, 21, 17, 15, 12)
xs &lt;- linspace(1, 6, 51)
ys &lt;- interp1(x, y, xs, method = "spline")
sp &lt;- spline(x, y, n = 51, method = "fmm")

## Not run: 
plot(x, y, main = "Matlab and R splines")
grid()
lines(xs, ys, col = "red")
lines(sp$x, sp$y, col = "blue")
legend(4, 20, c("Matlab spline", "R spline"), 
              col = c("red", "blue"), lty = 1)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='interp2'>
Two-dimensional Data Interpolation
</h2><span id='topic+interp2'></span>

<h3>Description</h3>

<p>Two-dimensional data interpolation similar to a table look-up.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    interp2(x, y, Z, xp, yp, method = c("linear", "nearest", "constant"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interp2_+3A_x">x</code>, <code id="interp2_+3A_y">y</code></td>
<td>
<p>vectors with monotonically increasing elements, representing
x- and y-coordinates of the data values in <code>Z</code>.</p>
</td></tr>
<tr><td><code id="interp2_+3A_z">Z</code></td>
<td>
<p>numeric <code>length(y)</code>-by-<code>length(x)</code> matrix.</p>
</td></tr>
<tr><td><code id="interp2_+3A_xp">xp</code>, <code id="interp2_+3A_yp">yp</code></td>
<td>
<p>x-, y-coordinates of points at which interpolated values
will be computed.</p>
</td></tr>
<tr><td><code id="interp2_+3A_method">method</code></td>
<td>
<p>interpolation method, &ldquo;linear&rdquo; the most useful.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes a vector containing elements corresponding to the elements of
<code>xp</code> and <code>yp</code>, determining by interpolation within the
two-dimensional function specified by vectors <code>x</code> and <code>y</code>,
and matrix <code>Z</code>.
</p>
<p><code>x</code> and <code>y</code> must be monotonically increasing. They specify
the points at which the data <code>Z</code> is given.
Therefore, <code>length(x) = nrow(Z)</code> and <code>length(y) = ncol(Z)</code>
must be satisfied.
</p>
<p><code>xp</code> and <code>yp</code> must be of the same length.
</p>
<p>The functions appears vectorized as <code>xp</code>, <code>yp</code> can be
vectors, but internally they are treated in a <code>for</code> loop.
</p>


<h3>Value</h3>

<p>Vector the length of <code>xp</code> of interpolated values.
</p>
<p>For methods &ldquo;constant&rdquo; and &ldquo;nearest&rdquo; the intervals are considered
closed from left and below. Out of range values are returned as NAs.
</p>


<h3>Note</h3>

<p>The corresponding Matlab function has also the methods &ldquo;cubic&rdquo; and
&ldquo;spline&rdquo;. If in need of a nonlinear interpolation, take a look at
<code>barylag2d</code> in this package and the example therein.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+interp1">interp1</a></code>, <code>barylag2d</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    x &lt;- linspace(-1, 1, 11)
    y &lt;- linspace(-1, 1, 11)
    mgrid &lt;- meshgrid(x, y)
    Z &lt;- mgrid$X^2 + mgrid$Y^2
    xp &lt;- yp &lt;- linspace(-1, 1, 101)

    method &lt;- "linear"
    zp &lt;- interp2(x, y, Z, xp, yp, method)
    plot(xp, zp, type = "l", col = "blue")

    method = "nearest"
    zp &lt;- interp2(x, y, Z, xp, yp, method)
    lines(xp, zp, col = "red")
    grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='inv'>Matrix Inverse (Matlab Style)</h2><span id='topic+inv'></span>

<h3>Description</h3>

<p>Invert a numeric or complex matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv(a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv_+3A_a">a</code></td>
<td>
<p>real or complex square matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the matrix inverse by calling <code>solve(a)</code> and catching the error
if the matrix is nearly singular.
</p>


<h3>Value</h3>

<p>square matrix that is the inverse of <code>a</code>.
</p>


<h3>Note</h3>

<p><code>inv()</code> is the function name used in Matlab/Octave.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+solve">solve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- hilb(6)
B &lt;- inv(A)
B
# Compute the inverse matrix through Cramer's rule:
n &lt;- nrow(A)
detA &lt;- det(A) 
b &lt;- matrix(NA, nrow = n, ncol = n)
for (i in 1:n) {
    for (j in 1:n) {
        b[i, j] &lt;- (-1)^(i+j) * det(A[-j, -i]) / detA
    }
}
b
</code></pre>

<hr>
<h2 id='invlap'>
Inverse Laplacian
</h2><span id='topic+invlap'></span>

<h3>Description</h3>

<p>Numerical inversion of Laplace transforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invlap(Fs, t1, t2, nnt, a = 6, ns = 20, nd = 19)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invlap_+3A_fs">Fs</code></td>
<td>
<p>function representing the function to be inverse-transformed.</p>
</td></tr>
<tr><td><code id="invlap_+3A_t1">t1</code>, <code id="invlap_+3A_t2">t2</code></td>
<td>
<p>end points of the interval.</p>
</td></tr>
<tr><td><code id="invlap_+3A_nnt">nnt</code></td>
<td>
<p>number of grid points between t1 and t2.</p>
</td></tr>
<tr><td><code id="invlap_+3A_a">a</code></td>
<td>
<p>shift parameter; it is recommended to preserve value 6.</p>
</td></tr>
<tr><td><code id="invlap_+3A_ns">ns</code>, <code id="invlap_+3A_nd">nd</code></td>
<td>
<p>further parameters, increasing them leads to lower error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The transform Fs may be any reasonable function of a variable s^a, where a 
is a real exponent. Thus, the function <code>invlap</code> can solve fractional 
problems and invert functions Fs containing (ir)rational or transcendental 
expressions.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>x</code> the x-coordinates and <code>y</code>
the y-coordinates representing the original function in the interval
<code>[t1,t2]</code>.
</p>


<h3>Note</h3>

<p>Based on a presentation in the first reference. The function <code>invlap</code> 
on MatlabCentral (by ) served as guide. The Talbot procedure from the 
second reference could be an interesting alternative.
</p>


<h3>References</h3>

<p>J. Valsa and L. Brancik (1998). Approximate Formulae for Numerical Inversion 
of Laplace Transforms. Intern. Journal of Numerical Modelling: Electronic 
Networks, Devices and Fields, Vol. 11, (1998), pp. 153-166.
</p>
<p>L.N.Trefethen, J.A.C.Weideman, and T.Schmelzer (2006). Talbot quadratures 
and rational approximations. BIT. Numerical Mathematics, 46(3):653&ndash;670.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Fs &lt;- function(s) 1/(s^2 + 1)           # sine function
Li &lt;- invlap(Fs, 0, 2*pi, 100)

## Not run: 
plot(Li[[1]], Li[[2]], type = "l", col = "blue"); grid()

Fs &lt;- function(s) tanh(s)/s             # step function
L1 &lt;- invlap(Fs, 0.01, 20, 1000)
plot(L1[[1]], L1[[2]], type = "l", col = "blue")
L2 &lt;- invlap(Fs, 0.01, 20, 2000, 6, 280, 59)
lines(L2[[1]], L2[[2]], col="darkred"); grid()

Fs &lt;- function(s) 1/(sqrt(s)*s)
L1 &lt;- invlap(Fs, 0.01, 5, 200, 6, 40, 20)
plot(L1[[1]], L1[[2]], type = "l", col = "blue"); grid()

Fs &lt;- function(s) 1/(s^2 - 1)           # hyperbolic sine function
Li &lt;- invlap(Fs, 0, 2*pi, 100)
plot(Li[[1]], Li[[2]], type = "l", col = "blue"); grid()

Fs &lt;- function(s) 1/s/(s + 1)           # exponential approach
Li &lt;- invlap(Fs, 0, 2*pi, 100)
plot(Li[[1]], Li[[2]], type = "l", col = "blue"); grid()

gamma &lt;- 0.577215664901532              # Euler-Mascheroni constant
Fs &lt;- function(s) -1/s * (log(s)+gamma) # natural logarithm
Li &lt;- invlap(Fs, 0, 2*pi, 100)
plot(Li[[1]], Li[[2]], type = "l", col = "blue"); grid()

Fs &lt;- function(s) (20.5+3.7343*s^1.15)/(21.5+3.7343*s^1.15+0.8*s^2.2+0.5*s^0.9)/s
L1 &lt;- invlap(Fs, 0.01, 5, 200, 6, 40, 20)
plot(L1[[1]], L1[[2]], type = "l", col = "blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='isempty'>isempty Property</h2><span id='topic+isempty'></span>

<h3>Description</h3>

<p>Determine if an object is empty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isempty(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isempty_+3A_x">x</code></td>
<td>
<p>an R object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An empty object has length zero.
</p>


<h3>Value</h3>

<p><code>TRUE</code> if <code>x</code> has length 0; otherwise, <code>FALSE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>isempty(c(0))            # FALSE
isempty(matrix(0, 1, 0)) # TRUE
</code></pre>

<hr>
<h2 id='isposdef'>
Positive Definiteness
</h2><span id='topic+isposdef'></span>

<h3>Description</h3>

<p>Test for positive definiteness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isposdef(A, psd = FALSE, tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isposdef_+3A_a">A</code></td>
<td>
<p>symmetric matrix</p>
</td></tr>
<tr><td><code id="isposdef_+3A_psd">psd</code></td>
<td>
<p>logical, shall semi-positive definiteness be tested?</p>
</td></tr>
<tr><td><code id="isposdef_+3A_tol">tol</code></td>
<td>
<p>tolerance to check symmetry and Cholesky decomposition.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Whether matrix <code>A</code> is positive definite will be determined by
applying the Cholesky decomposition. The matrix must be symmetric.
</p>
<p>With <code>psd=TRUE</code> the matrix will be tested for being semi-positive
definite. If not positive definite, still a warning will be generated.
</p>


<h3>Value</h3>

<p>Returns <code>TRUE</code> or <code>FALSE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- magic(5)
# isposdef(A)
## [1] FALSE
## Warning message:
## In isposdef(A) : Matrix 'A' is not symmetric.
## FALSE

A &lt;- t(A) %*% A
isposdef(A)
## [1] TRUE

A[5, 5] &lt;- 0
isposdef(A)
## [1] FALSE
</code></pre>

<hr>
<h2 id='isprime'>isprime Property</h2><span id='topic+isprime'></span>

<h3>Description</h3>

<p>Vectorized version, returning for a vector or matrix of positive integers
a vector of the same size containing 1 for the elements that are prime and
0 otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  isprime(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isprime_+3A_x">x</code></td>
<td>
<p>vector or matrix of nonnegative integers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given an array of positive integers returns an array of the same size
of 0 and 1, where the i indicates a prime number in the same position.
</p>


<h3>Value</h3>

<p>array of elements 0, 1 with 1 indicating prime numbers
</p>


<h3>See Also</h3>

<p><code><a href="#topic+factors">factors</a>, <a href="#topic+primes">primes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- matrix(1:10, nrow=10, ncol=10, byrow=TRUE)
  x * isprime(x)

  # Find first prime number octett:
  octett &lt;- c(0, 2, 6, 8, 30, 32, 36, 38) - 19
  while (TRUE) {
      octett &lt;- octett + 210
      if (all(as.logical(isprime(octett)))) {
          cat(octett, "\n", sep="  ")
          break
      }
  }
</code></pre>

<hr>
<h2 id='itersolve'>
Iterative Methods
</h2><span id='topic+itersolve'></span>

<h3>Description</h3>

<p>Iterative solutions of systems of linear equations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itersolve(A, b, x0 = NULL, nmax = 1000, tol = .Machine$double.eps^(0.5),
            method = c("Gauss-Seidel", "Jacobi", "Richardson"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itersolve_+3A_a">A</code></td>
<td>
<p>numerical matrix, square and non-singular.</p>
</td></tr>
<tr><td><code id="itersolve_+3A_b">b</code></td>
<td>
<p>numerical vector or column vector.</p>
</td></tr>
<tr><td><code id="itersolve_+3A_x0">x0</code></td>
<td>
<p>starting solution for iteration; defaults to null vector.</p>
</td></tr>
<tr><td><code id="itersolve_+3A_nmax">nmax</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="itersolve_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="itersolve_+3A_method">method</code></td>
<td>
<p>iterative method, Gauss-Seidel, Jacobi, or Richardson.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Iterative methods are based on splitting the matrix <code>A=(P-A)-A</code>
with a so-called &lsquo;preconditioner&rsquo; matrix P. The methods differ in how
to choose this preconditioner.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>x</code> the solution, <code>iter</code> the
number of iterations, and <code>method</code> the name of the method applied.
</p>


<h3>Note</h3>

<p>Richardson's method allows to specify a &lsquo;preconditioner&rsquo;; this has not
been implemented yet.
</p>


<h3>References</h3>

<p>Quarteroni, A., and F. Saleri (2006). Scientific Computing with MATLAB
and Octave. Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qrSolve">qrSolve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 10
A &lt;- Diag(rep(3,N)) + Diag(rep(-2, N-1), k=-1) + Diag(rep(-1, N-1), k=1)
b &lt;- A %*% rep(1, N)
x0 &lt;- rep(0, N)

itersolve(A, b, tol = 1e-8, method = "Gauss-Seidel")
# [1]  1  1  1  1  1  1  1  1  1  1
# [1]  87
itersolve(A, b, x0 = 1:10, tol = 1e-8, method = "Jacobi")
# [1]  1  1  1  1  1  1  1  1  1  1
# [1]  177
</code></pre>

<hr>
<h2 id='jacobian'>Jacobian Matrix</h2><span id='topic+jacobian'></span>

<h3>Description</h3>

<p>Jacobian matrix of a function R^n &ndash;&gt; R^m .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jacobian(f, x0, heps = .Machine$double.eps^(1/3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jacobian_+3A_f">f</code></td>
<td>
<p><code>m</code> functions of <code>n</code> variables.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_x0">x0</code></td>
<td>
<p>Numeric vector of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_heps">heps</code></td>
<td>
<p>This is <code>h</code> in the derivative formula.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_...">...</code></td>
<td>
<p>parameters to be passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the derivative of each funktion <code class="reqn">f_j</code> by variable <code class="reqn">x_i</code>
separately, taking the discrete step <code class="reqn">h</code>.
</p>


<h3>Value</h3>

<p>Numeric <code>m</code>-by-<code>n</code> matrix <code>J</code> where the entry <code>J[j, i]</code>
is <code class="reqn">\frac{\partial f_j}{\partial x_i}</code>, i.e. the derivatives of function
<code class="reqn">f_j</code> line up in row <code class="reqn">i</code> for <code class="reqn">x_1, \ldots, x_n</code>.
</p>


<h3>Note</h3>

<p>Obviously, this function is <em>not</em> vectorized.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code>gradient</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example function from Quarteroni &amp; Saleri
f &lt;- function(x) c(x[1]^2 + x[2]^2 - 1, sin(pi*x[1]/2) + x[2]^3)
jf &lt;- function(x) 
          matrix( c(2*x[1], pi/2 * cos(pi*x[1]/2), 2*x[2], 3*x[2]^2), 2, 2)
all.equal(jf(c(1,1)), jacobian(f, c(1,1)))
# TRUE
</code></pre>

<hr>
<h2 id='kriging'>
Interpolation by Kriging
</h2><span id='topic+kriging'></span>

<h3>Description</h3>

<p>Simple and ordinary Kriging interpolation and interpolating function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kriging(u, v, u0, type = c("ordinary", "simple"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kriging_+3A_u">u</code></td>
<td>
<p>an <code>nxm</code>-matrix of n points in the m-dimensional space.</p>
</td></tr>
<tr><td><code id="kriging_+3A_v">v</code></td>
<td>
<p>an <code>n</code>-dim. (column) vector of interpolation values.</p>
</td></tr>
<tr><td><code id="kriging_+3A_u0">u0</code></td>
<td>
<p>a <code>kxm</code>-matrix of k points in <code>R^m</code> to be interpolated.</p>
</td></tr>
<tr><td><code id="kriging_+3A_type">type</code></td>
<td>
<p>character; values &lsquo;simple&rsquo; or &lsquo;ordinary&rsquo;; no partial matching.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kriging is a geo-spatial estimation procedure that estimates points based
on the variations of known points in a non-regular grid. It is especially
suited for surfaces.
</p>


<h3>Value</h3>

<p><code>kriging</code> returns a <code>k</code>-dim. vektor of interpolation values.
</p>


<h3>Note</h3>

<p>In the literature, different versions and extensions are discussed.
</p>


<h3>References</h3>

<p>Press, W. H., A. A. Teukolsky, W. T. Vetterling, and B. P. Flannery (2007).
Numerical recipes: The Art of Scientific Computing (3rd Ed.). Cambridge
University Press, New York, Sect. 3.7.4, pp. 144-147.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+akimaInterp">akimaInterp</a></code>, <code><a href="#topic+barylag2d">barylag2d</a></code>, package <code>kriging</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Interpolate the Saddle Point function
f &lt;- function(x) x[1]^2 - x[2]^2       # saddle point function

set.seed(8237)
n &lt;- 36
x &lt;- c(1, 1, -1, -1, runif(n-4, -1, 1)) # add four vertices
y &lt;- c(1, -1, 1, -1, runif(n-4, -1, 1))
u &lt;- cbind(x, y)
v &lt;- numeric(n)
for (i in 1:n) v[i] &lt;- f(c(x[i], y[i]))

kriging(u, v, c(0, 0))                      #=&gt;  0.006177183
kriging(u, v, c(0, 0), type = "simple")     #=&gt;  0.006229557

## Not run: 
xs &lt;- linspace(-1, 1, 101)              # interpolation on a diagonal
u0 &lt;- cbind(xs, xs)

yo &lt;- kriging(u, v, u0, type = "ordinary")  # ordinary kriging
ys &lt;- kriging(u, v, u0, type = "simple")    # simple kriging
plot(xs, ys, type = "l", col = "blue", ylim = c(-0.1, 0.1),
             main = "Kriging interpolation along the diagonal")
lines(xs, yo, col = "red")
legend( -1.0, 0.10, c("simple kriging", "ordinary kriging", "function"),
        lty = c(1, 1, 1), lwd = c(1, 1, 2), col=c("blue", "red", "black"))
grid()
lines(c(-1, 1), c(0, 0), lwd = 2)
## End(Not run)

##  Find minimum of the sphere function
f &lt;- function(x, y) x^2 + y^2 + 100
v &lt;- bsxfun(f, x, y)

ff &lt;- function(w) kriging(u, v, w)
ff(c(0, 0))                                 #=&gt;  100.0317
## Not run: 
optim(c(0.0, 0.0), ff)
# $par:   [1]  0.04490075 0.01970690
# $value: [1]  100.0291
ezcontour(ff, c(-1, 1), c(-1, 1))
points(0.04490075, 0.01970690, col = "red")
## End(Not run)
</code></pre>

<hr>
<h2 id='kron'>Kronecker product (Matlab Style)</h2><span id='topic+kron'></span>

<h3>Description</h3>

<p>Kronecker tensor product of two matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kron(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kron_+3A_a">a</code></td>
<td>
<p>real or complex matrix</p>
</td></tr>
<tr><td><code id="kron_+3A_b">b</code></td>
<td>
<p>real or complex matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kronecker product is a large matrix formed by all products between the
elements of <code>a</code> and those of <code>b</code>. The first left block is a11*b,
etc.
</p>


<h3>Value</h3>

<p>an <code>(n*p x m*q</code>-matrix, if <code>a</code> is <code>(n x m</code> and
<code>b</code> is <code>(p x q)</code>.
</p>


<h3>Note</h3>

<p><code>kron()</code> is an alias for the R function <code>kronecker()</code>, which can
also be executed with the binary operator &lsquo;%x%&rsquo;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- diag(1, 2, 2)
b &lt;- matrix(1:4, 2, 2)
kron(a, b)
kron(b, a)
</code></pre>

<hr>
<h2 id='L1linreg'>
L1 Linear Regression
</h2><span id='topic+L1linreg'></span>

<h3>Description</h3>

<p>Solve the linear system <code>A x = b</code> in an Lp sense, that is minimize the
term <code>sum |b - A x|^p</code>. The case <code>p=1</code> is also called 
&ldquo;least absolute deviation&rdquo; (LAD) regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>L1linreg(A, b, p = 1, tol = 1e-07, maxiter = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="L1linreg_+3A_a">A</code></td>
<td>
<p>matrix of independent variables.</p>
</td></tr>
<tr><td><code id="L1linreg_+3A_b">b</code></td>
<td>
<p>independent variables.</p>
</td></tr>
<tr><td><code id="L1linreg_+3A_p">p</code></td>
<td>
<p>the p in L^p norm, <code>p&lt;=1</code>.</p>
</td></tr>
<tr><td><code id="L1linreg_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="L1linreg_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>L1/Lp regression is here solved  applying the &ldquo;iteratively reweighted least
square&rdquo; (IRLS) method in which each step involves a weighted least squares
problem.
</p>
<p>If an intercept term is required, add a unit column to <code>A</code>.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>x</code> the linear coefficients describing
the solution, <code>reltol</code> the relative tolerance reached, and <code>niter</code>
the number of iterations.
</p>


<h3>Note</h3>

<p>In this case of <code>p=1</code>, the problem would be better approached by use
of linear programming methods.
</p>


<h3>References</h3>

<p>Dasgupta, M., and S.K. Mishra (2004). Least absolute deviation estimation 
of linear econometric models: A literature review. MPRA Paper No. 1781.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+lsqnonlin">lsqnonlin</a></code>, <code>quantreg::rq</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- 101; n &lt;- 10       # no. of data points, degree of polynomial
x &lt;- seq(-1, 1, len=m)
y &lt;- runge(x)           # Runge's function
A &lt;- outer(x, n:0, '^') # Vandermonde matrix
b &lt;- y

( sol &lt;- L1linreg(A, b) )
# $x
# [1] -21.93242   0.00000  62.91092   0.00000 -67.84854   0.00000
# [7]  34.14400   0.00000  -8.11899   0.00000   0.84533
# 
# $reltol
# [1] 6.712355e-10
# 
# $niter
# [1] 81

# minimum value of polynomial L1 regression
sum(abs(polyval(sol$x, x) - y))
# [1] 3.061811
</code></pre>

<hr>
<h2 id='laguerre'>
Laguerre's Method
</h2><span id='topic+laguerre'></span>

<h3>Description</h3>

<p>Laguerre's method for finding roots of complex polynomials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laguerre(p, x0, nmax = 25, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laguerre_+3A_p">p</code></td>
<td>
<p>real or complex vector representing a polynomial.</p>
</td></tr>
<tr><td><code id="laguerre_+3A_x0">x0</code></td>
<td>
<p>real or complex point near the root.</p>
</td></tr>
<tr><td><code id="laguerre_+3A_nmax">nmax</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="laguerre_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses values of the polynomial and its first and second derivative.
</p>


<h3>Value</h3>

<p>The root found, or a warning about the number of iterations.
</p>


<h3>Note</h3>

<p>Computations are caried out in complex arithmetic, and it is possible
to obtain a complex root even if the starting estimate is real.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+roots">roots</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1 x^5 - 5.4 x^4 + 14.45 x^3 - 32.292 x^2 + 47.25 x - 26.46
p &lt;- c(1.0, -5.4, 14.45, -32.292, 47.25, -26.46)
laguerre(p, 1)   #=&gt; 1.2
laguerre(p, 2)   #=&gt; 2.099987     (should be 2.1)
laguerre(p, 2i)  #=&gt; 0+2.236068i  (+- 2.2361i, i.e sqrt(-5))
</code></pre>

<hr>
<h2 id='lambertWp'>
Lambert's W Function
</h2><span id='topic+lambertWp'></span><span id='topic+lambertWn'></span>

<h3>Description</h3>

<p>Principal real branch of the Lambert W function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambertWp(x)
lambertWn(x) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambertWp_+3A_x">x</code></td>
<td>
<p>Numeric vector of real numbers <code>&gt;= -1/e</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lambert W function is the inverse of <code>x --&gt; x e^x</code>, with two
real branches, W0 for <code>x &gt;= -1/e</code> and W-1 for <code>-1/e &lt;= x &lt; 0</code>.
Here the principal branch is called <code>lambertWp</code>, tho other one
<code>lambertWp</code>, computed for real <code>x</code>.
</p>
<p>The value is calculated using an iteration that stems from applying
Halley's method. This iteration is quite fast and accurate.
</p>
<p>The functions is not really vectorized, but at least returns a vector of
values when presented with a numeric vector of length <code>&gt;= 2</code>.
</p>


<h3>Value</h3>

<p>Returns the solution <code>w</code> of <code>w*exp(w) = x</code> for real <code>x</code>
with <code>NaN</code> if <code>x &lt; 1/exp(1)</code> (resp. <code>x &gt;= 0</code> for the
second branch).
</p>


<h3>Note</h3>

<p>See the examples how values for the second branch or the complex
Lambert W function could be calculated by Newton's method.
</p>


<h3>References</h3>

<p>Corless, R. M., G. H.Gonnet, D. E. G Hare, D. J. Jeffrey, and D. E. Knuth
(1996). On the Lambert W Function. Advances in Computational Mathematics,
Vol. 5, pp. 329-359.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+halley">halley</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Examples
lambertWp(0)          #=&gt; 0
lambertWp(1)          #=&gt; 0.5671432904097838...  Omega constant
lambertWp(exp(1))     #=&gt; 1
lambertWp(-log(2)/2)  #=&gt; -log(2)

# The solution of  x * a^x = z  is  W(log(a)*z)/log(a)
# x * 123^(x-1) = 3
lambertWp(3*123*log(123))/log(123)  #=&gt; 1.19183018...

x &lt;- seq(-0.35, 0.0, by=0.05)
w &lt;- lambertWn(x)
w * exp(w)            # max. error &lt; 3e-16
# [1] -0.35 -0.30 -0.25 -0.20 -0.15 -0.10 -0.05   NaN

## Not run: 
xs &lt;- c(-1/exp(1), seq(-0.35, 6, by=0.05))
ys &lt;- lambertWp(xs)
plot(xs, ys, type="l", col="darkred", lwd=2, ylim=c(-2,2),
     main="Lambert W0 Function", xlab="", ylab="")
grid()
points(c(-1/exp(1), 0, 1, exp(1)), c(-1, 0, lambertWp(1), 1))
text(1.8, 0.5, "Omega constant")
  
## End(Not run)

## Analytic derivative of lambertWp (similar for lambertWn)
D_lambertWp &lt;- function(x) {
    xw &lt;- lambertWp(x)
    1 / (1+xw) / exp(xw)
}
D_lambertWp(c(-1/exp(1), 0, 1, exp(1)))
# [1] Inf 1.0000000 0.3618963 0.1839397

## Second branch resp. the complex function lambertWm()
F &lt;- function(xy, z0) {
    z &lt;- xy[1] + xy[2]*1i
    fz &lt;- z * exp(z) - z0
    return(c(Re(fz), Im(fz)))
}
newtonsys(F, c(-1, -1), z0 = -0.1)   #=&gt; -3.5771520639573
newtonsys(F, c(-1, -1), z0 = -pi/2)  #=&gt; -1.5707963267949i = -pi/2 * 1i
</code></pre>

<hr>
<h2 id='laplacian'>
Laplacian Operator
</h2><span id='topic+laplacian'></span>

<h3>Description</h3>

<p>Numerically compute the Laplacian of a function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laplacian(f, x0, h = .Machine$double.eps^(1/4), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laplacian_+3A_f">f</code></td>
<td>
<p>univariate function of several variables.</p>
</td></tr>
<tr><td><code id="laplacian_+3A_x0">x0</code></td>
<td>
<p>point in <code class="reqn">R^n</code>.</p>
</td></tr>
<tr><td><code id="laplacian_+3A_h">h</code></td>
<td>
<p>step size.</p>
</td></tr>
<tr><td><code id="laplacian_+3A_...">...</code></td>
<td>
<p>variables to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the Laplacian operator <code class="reqn">f_{x_1 x_1} + \ldots + f_{x_n x_n}</code>
based on the three-point central difference formula, expanded to this
special case.
</p>
<p>Assumes that the function has continuous partial derivatives.
</p>


<h3>Value</h3>

<p>Real number.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hessian">hessian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x) x[1]^2 + 2*x[1]*x[2] + x[2]^2
laplacian(f, c(1,1))
</code></pre>

<hr>
<h2 id='lebesgue'>Lebesgue Constant</h2><span id='topic+lebesgue'></span>

<h3>Description</h3>

<p>Estimates the Lebesgue constant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lebesgue(x, refine = 4, plotting = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lebesgue_+3A_x">x</code></td>
<td>
<p>numeric vector of grid points</p>
</td></tr>
<tr><td><code id="lebesgue_+3A_refine">refine</code></td>
<td>
<p>refine the grid with <code>2^refine</code> grid points;
can only be an integer between 2 and 10, default 4.</p>
</td></tr>
<tr><td><code id="lebesgue_+3A_plotting">plotting</code></td>
<td>
<p>shall the Lebesgue function be plotted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lebesgue constant gives an estimation <code class="reqn">||P_n f|| \le L ||f||</code>
(in minimax norm) where <code class="reqn">P_n f</code> is the interpolating polynomial of
order <code class="reqn">n</code> for <code class="reqn">f</code> on an interval <code class="reqn">[a, b]</code>.
</p>


<h3>Value</h3>

<p>Lebesgue constant for the given grid points.
</p>


<h3>Note</h3>

<p>The Lebesgue constant plays an important role when estimating the distance
of interpolating polynomials from the minimax solution (see the Remez
algorithm).
</p>


<h3>References</h3>

<p>Berrut, J.-P., and L. Nick Trefethen (2004). &ldquo;Barycentric Lagrange
Interpolation&rdquo;. SIAM Review, Vol. 46(3), pp.501&ndash;517.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+barylag">barylag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lebesgue(seq(0, 1, length.out = 6))  #=&gt; 3.100425
</code></pre>

<hr>
<h2 id='legendre'>
Legendre Functions (Matlab Style)
</h2><span id='topic+legendre'></span>

<h3>Description</h3>

<p>Calculate the values of (associated) Legendre functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>legendre(n, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="legendre_+3A_n">n</code></td>
<td>
<p>degree of the Legendre polynomial involved.</p>
</td></tr>
<tr><td><code id="legendre_+3A_x">x</code></td>
<td>
<p>real points to evaluate Legendre's functions at.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>legendre(n,x)</code> computes the associated Legendre functions of degree
<code>n</code> and order <code>m=0,1,...,n</code>, evaluated for each element of
<code>x</code> where <code>x</code> must contain real values in <code>[-1,1]</code>.
</p>
<p>If <code>x</code> is a vector, then <code>L=legendre(n,x)</code> is an
<code>(n+1)</code>-by-<code>N</code> matrix, where <code>N=length(x)</code>. Each element 
<code>L[m+1,i]</code> corresponds to the associated Legendre function of degree
<code>legendre(n,x)</code> and order <code>m</code> evaluated at <code>x[i]</code>.
</p>
<p>Note that the first row of <code>L</code> is the Legendre polynomial evaluated at
<code>x</code>.
</p>


<h3>Value</h3>

<p>Returns a matrix of size <code>(n+1)</code>-by-<code>N</code> where <code>N=length(x)</code>.
</p>


<h3>Note</h3>

<p>Legendre functions are solutions to Legendre's differential equation (it
occurs when solving Laplace's equation in spherical coordinates).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chebPoly">chebPoly</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0.0, 0.1, 0.2)
legendre(2, x)
#      [,1]       [,2]       [,3]
# [1,] -0.5 -0.4850000 -0.4400000
# [2,]  0.0 -0.2984962 -0.5878775
# [3,]  3.0  2.9700000  2.8800000

## Not run: 
x &lt;- seq(0, 1, len = 50)
L &lt;- legendre(2, x)
plot(x, L[1, ], type = "l", col = 1, ylim = c(-2, 3), ylab = "y",
                main = "Legendre Functions of degree 2")
lines(x, L[2, ], col = 2)
lines(x, L[3, ], col = 3)
grid()
## End(Not run)
## Generate Legendre's Polynomial as function
# legendre_P &lt;- function(n, x) {
#     L &lt;- legendre(n, x)
#     return(L[1, ])
# }
</code></pre>

<hr>
<h2 id='line_integral'>
Line integral (in the complex plane)
</h2><span id='topic+line_integral'></span>

<h3>Description</h3>

<p>Provides complex line integrals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>line_integral(fun, waypoints, method = NULL, reltol = 1e-8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="line_integral_+3A_fun">fun</code></td>
<td>
<p>integrand, complex (vectorized) function.</p>
</td></tr>
<tr><td><code id="line_integral_+3A_method">method</code></td>
<td>
<p>integration procedure, see below.</p>
</td></tr>
<tr><td><code id="line_integral_+3A_waypoints">waypoints</code></td>
<td>
<p>complex integration: points on the integration curve.</p>
</td></tr>
<tr><td><code id="line_integral_+3A_reltol">reltol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="line_integral_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>line_integral</code> realizes complex line integration, in this case straight
lines between the waypoints. By passing discrete points densely along the
curve, arbitrary line integrals can be approximated.
</p>
<p><code>line_integral</code> will accept the same methods as <code>integral</code>;
default is <code>integrate</code> from Base R.
</p>


<h3>Value</h3>

<p>Returns the integral, no error terms given.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+integral">integral</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Complex integration examples
points &lt;- c(0, 1+1i, 1-1i, 0)           # direction mathematically negative
f &lt;- function(z) 1 / (2*z -1)
I &lt;- line_integral(f, points)
abs(I - (0-pi*1i))                      # 0 ; residuum 2 pi 1i * 1/2

f &lt;- function(z) 1/z
points &lt;- c(-1i, 1, 1i, -1, -1i)
I &lt;- line_integral(f, points)           # along a rectangle around 0+0i
abs(I - 2*pi*1i)                        #=&gt; 0 ; residuum: 2 pi i * 1

N &lt;- 100
x &lt;- linspace(0, 2*pi, N)
y &lt;- cos(x) + sin(x)*1i
J &lt;- line_integral(f, waypoints = y)    # along a circle around 0+0i
abs(I - J)                              #=&gt; 5.015201e-17; same residuum
</code></pre>

<hr>
<h2 id='linearproj+2C+20affineproj'>
Linear Projection onto a Subspace
</h2><span id='topic+linearproj'></span><span id='topic+affineproj'></span>

<h3>Description</h3>

<p>Computes the projection of points in the columns of B onto the
linear subspace spaned by the columns of A, resp. the projection
of a point onto an affine subspace and its distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  linearproj(A, B)

  affineproj(x0, C, b, unbound = TRUE, maxniter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linearproj+2B2C+2B20affineproj_+3A_a">A</code></td>
<td>
<p>Matrix whose columns span a subspace of some R^n.</p>
</td></tr>
<tr><td><code id="linearproj+2B2C+2B20affineproj_+3A_b">B</code></td>
<td>
<p>Matrix whose columns are to be projected.</p>
</td></tr>
<tr><td><code id="linearproj+2B2C+2B20affineproj_+3A_x0">x0</code></td>
<td>
<p>Point in R^n to be projected onto C x = b.</p>
</td></tr>
<tr><td><code id="linearproj+2B2C+2B20affineproj_+3A_c">C</code>, <code id="linearproj+2B2C+2B20affineproj_+3A_b">b</code></td>
<td>
<p>Matrix and vector, defining an affine subspace as C x = b</p>
</td></tr>
<tr><td><code id="linearproj+2B2C+2B20affineproj_+3A_unbound">unbound</code></td>
<td>
<p>Logical; require all x &gt;= 0 if unbound is false.</p>
</td></tr>
<tr><td><code id="linearproj+2B2C+2B20affineproj_+3A_maxniter">maxniter</code></td>
<td>
<p>Maximum number of iterations (if  is unbound is false).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>linearproj</code> projects points onto a <em>linear</em> subspace in R^n.
The columns of A are assumed be the basis of a linear subspace, esp.
they are required to be linearly independent. The columns of matrix B
define points in R^n that will be projected onto A, and their resp.
coefficients in terms of the basis in A are computed.
</p>
<p>The columns of A need to be linearly independent; if not, generate an 
orthonormal basis of this subspace with <code>orth(A)</code>. If you want to 
project points onto a subspace that is defined by <code>A x = 0</code>, then 
generate an orthonormal basis of the nullspace of A with <code>null(A)</code>.
</p>
<p>Technically, the orthogonal projection can be determined by a finite 
'Fourier expansion' with coefficients calculated as scalar products,
see the examples.
</p>
<p><code>affineproj</code> projects (single) points onto an affine subspace 
defined by <code>A x = b</code> and calculates the distance of <code>x0</code> from 
this subspace. The calculation is based on the following formula:
</p>
<p style="text-align: center;"><code class="reqn">p = (I - A' (A A')^{-1}) x0 + A' (A A')^{-1} b</code>
</p>

<p>Technically, if <code>a</code> is one solution of <code>C x = b</code>, then the 
projection onto C can be derived from the projection onto
<code>S = {C x = 0}</code> with <code>proj_C(x) = a + proj_S(x - a)</code>,
see the examples.
</p>
<p>In case the user requests the coordinates of the projected point to be 
positive, an iteration procedure is started where negative coordinates 
are set to zero in each iteration.
</p>


<h3>Value</h3>

<p>The functions <code>linearproj</code> returns a list with components P and Q. 
The columns of P contain the coefficients &ndash; in the basis of A &ndash; of the 
corresponding projected points in B, and the columns of Q are the the 
coordinates of these points in the natural coordinate system of R^n.
</p>
<p><code>affineproj</code> returns a list with components <code>proj</code>, <code>dist</code>, 
and <code>niter</code>. <code>proj</code> is the projected point, <code>dist</code> the 
distance from the subspace (and <code>niter</code> the number of iterations 
if positivity of the coordinates was requested.).
</p>


<h3>Note</h3>

<p>Some timings show that these implementations are to a certain extent
competitive with direct applications of quadprog.
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers, partly based on code snippets by Ravi Varadhan.
</p>


<h3>References</h3>

<p>G. Strang (2006). Linear Algebra and Its Applications. Fourth Edition,
Cengage Learning, Boston, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nullspace">nullspace</a></code>, <code><a href="#topic+orth">orth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-- Linear projection --------------------------------------------------

# Projection onto the line (1,1,1) in R^3
A &lt;- matrix(c(1,1,1), 3, 1)
B &lt;- matrix(c(1,0,0, 1,2,3, -1,0,1), 3, 3)
S &lt;- linearproj(A, B)
## S$Q
##           [,1] [,2] [,3]
## [1,] 0.3333333    2    0
## [2,] 0.3333333    2    0
## [3,] 0.3333333    2    0

# Fourier expansion': sum(&lt;x0, a_i&gt; a_i /&lt;a_i, a_i&gt;), a_i = A[ ,i]
dot(c(1,2,3), A) * A / dot(A, A)    # A has only one column

#-- Affine projection --------------------------------------------------

# Projection onto the (hyper-)surface x+y+z = 1 in R^3
A &lt;- t(A); b &lt;- 1
x0 &lt;- c(1,2,3)
affineproj(x0, A, b)            # (-2/3, 1/3, 4/3)

# Linear translation: Let S be the linear subspace and A the parallel
# affine subspace of A x = b, a the solution of the linear system, then
#   proj_A(x) = a + proj_S(x-a)
a &lt;- qr.solve(A, b)
A0 &lt;- nullspace(A)
xp &lt;- c(a + linearproj(A0, x0 - a)$Q)
## [1] -0.6666667  0.3333333  1.3333333

#-- Projection with positivity ----------------------- 24 ms -- 1.3 s --
s &lt;- affineproj(x0, A, b, unbound = FALSE)
zapsmall(s$proj)                 # [1] 0 0 1
## $x     : 0.000000e+00 3.833092e-17 1.000000e+00
## $niter : 35

#-- Extended Example ------------------------------------------ 80 ms --
## Not run: 
set.seed(65537)
n = 1000; m = 100                       # dimension, codimension
x0 &lt;- rep(0, n)                         # project (0, ..., 0)
A &lt;- matrix(runif(m*n), nrow = m)       # 100 x 1000
b &lt;- rep(1, m)                          # A x = b, linear system
a &lt;- qr.solve(A, b)                     # A a = b, LS solution
A0 &lt;- nullspace(A)                      # 1000 x 900, base of &lt;A&gt;
xp &lt;- a+drop(A0 %*% dot(x0-a, A0))      # projection
Norm(xp - x0)                           # [1] 0.06597077

## End(Not run)

#-- Solution with quadprog ------------------------------------ 40 ms --
# D &lt;- diag(1, n)             # quadratic form
# A1 &lt;- rbind(A, diag(1, n))  # A x = b and
# b1 &lt;- c(b, rep(0, n))       #   x &gt;= 0
# n &lt;- nrow(A)
# sol = quadprog::solve.QP(D, x0, t(A1), b1, meq = n)
# xp &lt;- sol$solution

#-- Solution with CVXR ---------------------------------------- 50 ms --
# library(CVXR)
# x = Variable(n)                             # n decision variables
# objective = Minimize(p_norm(x0 - x))        # min! || p0 - x ||
# constraint = list(A %*% x == b, x &gt;= 0)     # A x = b, x &gt;= 0
# problem = Problem(objective, constraint)
# solution = solve(problem)                   # Solver: ECOS
# solution$value                              # 
# xp &lt;- solution$getValue(x)                  # 
</code></pre>

<hr>
<h2 id='linprog'>
Linear Programming Solver
</h2><span id='topic+linprog'></span>

<h3>Description</h3>

<p>Solves simple linear programming problems, allowing for inequality and
equality constraints as well as lower and upper bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linprog(cc, A = NULL, b = NULL, Aeq = NULL, beq = NULL,
        lb = NULL, ub = NULL, x0 = NULL, I0 = NULL,
        bigM = 100, maxiter = 20, maximize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linprog_+3A_cc">cc</code></td>
<td>
<p>defines the linear objective function.</p>
</td></tr>
<tr><td><code id="linprog_+3A_a">A</code></td>
<td>
<p>matrix representing the inequality constraints <code>A x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="linprog_+3A_b">b</code></td>
<td>
<p>vector, right hand side of the inequalities.</p>
</td></tr>
<tr><td><code id="linprog_+3A_aeq">Aeq</code></td>
<td>
<p>matrix representing the equality constraints <code>Aeq x &lt;= beq</code>.</p>
</td></tr>
<tr><td><code id="linprog_+3A_beq">beq</code></td>
<td>
<p>vector, right hand side of the inequalities.</p>
</td></tr>
<tr><td><code id="linprog_+3A_lb">lb</code></td>
<td>
<p>lower bounds, if not <code>NULL</code> must all be greater or equal 0.</p>
</td></tr>
<tr><td><code id="linprog_+3A_ub">ub</code></td>
<td>
<p>upper bounds, if not <code>NULL</code> must all be greater or equal <code>lb</code>.</p>
</td></tr>
<tr><td><code id="linprog_+3A_x0">x0</code></td>
<td>
<p>feasible base vector, will not be used at the moment.</p>
</td></tr>
<tr><td><code id="linprog_+3A_i0">I0</code></td>
<td>
<p>index set of <code>x0</code>, will not be used at the moment.</p>
</td></tr>
<tr><td><code id="linprog_+3A_bigm">bigM</code></td>
<td>
<p>big-M constant, will be used for finding a base vector.</p>
</td></tr>
<tr><td><code id="linprog_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="linprog_+3A_maximize">maximize</code></td>
<td>
<p>logical; shall the objective be minimized or maximized?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves linear programming problems of the form <code class="reqn">min cc' * x</code>
such that
</p>
<p style="text-align: center;"><code class="reqn">A * x \le b</code>
</p>

<p style="text-align: center;"><code class="reqn">A_{eq} * x = b_{eq}</code>
</p>

<p style="text-align: center;"><code class="reqn">lb \le x \le ub</code>
</p>



<h3>Value</h3>

<p>List with
</p>

<ul>
<li><p><code>x</code> the solution vector.
</p>
</li>
<li><p><code>fval</code> the value at the optimal solution.
</p>
</li>
<li><p><code>errno</code>, <code>mesage</code> the error number and message.
</p>
</li></ul>



<h3>Note</h3>

<p>This is a first version that will be unstable at times. For real linear
programming problems use package <code>lpSolve</code>.
</p>


<h3>Author(s)</h3>

<p>HwB &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Vanderbei, R. J. (2001). Linear Programming: Foundations and Extensions.
Princeton University Press.
</p>
<p>Eiselt, H. A., and C.-L. Sandblom (2012). Operations Research: 
A Model-based Approach. Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code>linprog::solveLP</code>, <code>lpSolve::lp</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Examples from the book "Operations research - A Model-based Approach"
#-- production planning
cc &lt;- c(5, 3.5, 4.5)
Ain &lt;- matrix(c(3, 5, 4,
                6, 1, 3), 2, 3, byrow=TRUE)
bin &lt;- c(540, 480)
linprog(cc, A = Ain, b = bin, maximize = TRUE)
# $x     20   0 120
# $fval  640

#-- diet problem
cc &lt;- c(1.59, 2.19, 2.99)
Ain &lt;- matrix(c(-250, -380, -257,
                 250,  380,  257,
                  13,   31,   28), 3, 3, byrow = TRUE)
bin &lt;- c(-1800, 2200, 100)
linprog(cc, A = Ain, b = bin)

#-- employee scheduling
cc &lt;- c(1, 1, 1, 1, 1, 1)
A &lt;- (-1)*matrix(c(1, 0, 0, 0, 0, 1,
                   1, 1, 0, 0, 0, 0,
                   0, 1, 1, 0, 0, 0,
                   0, 0, 1, 1, 0, 0,
                   0, 0, 0, 1, 1, 0,
                   0, 0, 0, 0, 1, 1), 6, 6, byrow = TRUE)
b &lt;- -c(17, 9, 19, 12, 5, 8)
linprog(cc, A, b)

#-- inventory models
cc &lt;- c(1, 1.1, 1.2, 1.25, 0.05, 0.15, 0.15)
Aeq &lt;- matrix(c(1, 0, 0, 0, -1,  0,  0,
                0, 1, 0, 0,  1, -1,  0,
                0, 0, 1, 0,  0,  1, -1,
                0, 0, 0, 1,  0,  0,  1), 4, 7, byrow = TRUE)
beq &lt;- c(60, 70, 130, 150)
ub &lt;- c(120, 140, 150, 140, Inf, Inf, Inf)
linprog(cc, Aeq = Aeq, beq = beq, ub = ub)

#-- allocation problem
cc &lt;- c(1, 1, 1, 1, 1)
A &lt;- matrix(c(-5,    0,    0,    0,    0,
               0, -4.5,    0,    0,    0,
               0,    0, -5.5,    0,    0,
               0,    0,    0, -3.5,    0,
               0,    0,    0,    0, -5.5,
               5,    0,    0,    0,    0,
               0,  4.5,    0,    0,    0,
               0,    0,  5.5,    0,    0,
               0,    0,    0,  3.5,    0,
               0,    0,    0,    0,  5.5,
              -5, -4.5, -5.5, -3.5, -5.5,
              10, 10.0, 10.0, 10.0, 10.0,
              0.2, 0.2,  0.2, -1.0,  0.2), 13, 5, byrow = TRUE)
b &lt;- c(-50, -55, -60, -50, -50, rep(100, 5), -5*64, 700, 0)
# linprog(cc, A = A, b = b)
lb &lt;- b[1:5] / diag(A[1:5, ])
ub &lt;- b[6:10] / diag(A[6:10, ])
A1 &lt;- A[11:13, ]
b1 &lt;- b[11:13]
linprog(cc, A1, b1, lb = lb, ub = ub)

#-- transportation problem
cc &lt;- c(1, 7, 4, 2, 3, 5)
Aeq &lt;- matrix(c(1, 1, 1, 0, 0, 0,
                0, 0, 0, 1, 1, 1,
                1, 0, 0, 1, 0, 0,
                0, 1, 0, 0, 1, 0,
                0, 0, 1, 0, 0, 1), 5, 6, byrow = TRUE)
beq &lt;- c(30, 20, 15, 25, 10)
linprog(cc, Aeq = Aeq, beq = beq)
</code></pre>

<hr>
<h2 id='linspace'>Linearly Spaced Sequences</h2><span id='topic+linspace'></span>

<h3>Description</h3>

<p>Generate linearly spaced sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  linspace(x1, x2, n = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linspace_+3A_x1">x1</code></td>
<td>
<p>numeric scalar specifying starting point</p>
</td></tr>
<tr><td><code id="linspace_+3A_x2">x2</code></td>
<td>
<p>numeric scalar specifying ending point</p>
</td></tr>
<tr><td><code id="linspace_+3A_n">n</code></td>
<td>
<p>numeric scalar specifying number of points to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions will generate <code>n</code> linearly spaced points between
<code>x1</code> and <code>x2</code>.
</p>
<p>If <code class="reqn">n &lt; 2</code>, the result will be the ending point <code>x2</code>.
</p>


<h3>Value</h3>

<p>vector containing <code>n</code> points between <code>x1</code> and <code>x2</code> inclusive.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspace">logspace</a></code>, <code><a href="base.html#topic+seq">seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>linspace(1, 10, 9)
</code></pre>

<hr>
<h2 id='logspace'>Log-linearly Spaced Sequences</h2><span id='topic+logspace'></span><span id='topic+logseq'></span>

<h3>Description</h3>

<p>Generate log-linearly spaced sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  logspace(x1, x2, n = 50)
  logseq(x1, x2, n = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logspace_+3A_x1">x1</code></td>
<td>
<p>numeric scalar specifying starting point</p>
</td></tr>
<tr><td><code id="logspace_+3A_x2">x2</code></td>
<td>
<p>numeric scalar specifying ending point</p>
</td></tr>
<tr><td><code id="logspace_+3A_n">n</code></td>
<td>
<p>numeric scalar specifying number of points to be generated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions will generate logarithmically resp.
exponentially spaced points between <code>x1</code> and <code>x2</code> resp.
<code>10^x1</code> and <code>10^x2</code>.
</p>
<p>If <code class="reqn">n &lt; 2</code>, the result will be the ending point <code>x2</code>. For
<code>logspace()</code>, if <code>x2 = pi</code>, the endpoint will be <code>pi</code>
and not <code>10^pi</code>!
</p>


<h3>Value</h3>

<p>vector containing <code>n</code> points between <code>x1</code> and <code>x2</code> inclusive.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspace">logspace</a></code>, <code><a href="base.html#topic+seq">seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>logspace(1, pi, 36)
logseq(0.05, 1, 20)
</code></pre>

<hr>
<h2 id='lsqlin'>
Linear Least-Squares Fitting
</h2><span id='topic+lsqlin'></span>

<h3>Description</h3>

<p>Solves linearly constrained linear least-squares problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  lsqlin(A, b, C, d, tol = 1e-13)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsqlin_+3A_a">A</code></td>
<td>
<p><code>nxm</code>-matrix defining the least-squares problem.</p>
</td></tr>
<tr><td><code id="lsqlin_+3A_b">b</code></td>
<td>
<p>vector or colum matrix with <code>n</code> rows; when it has more than 
one column it describes several least-squares problems.</p>
</td></tr>
<tr><td><code id="lsqlin_+3A_c">C</code></td>
<td>
<p><code>pxm</code>-matrix for the constraint system.</p>
</td></tr>
<tr><td><code id="lsqlin_+3A_d">d</code></td>
<td>
<p>vector or <code>px1</code>-matrix, right hand side for the constraints.</p>
</td></tr>
<tr><td><code id="lsqlin_+3A_tol">tol</code></td>
<td>
<p>tolerance to be passed to <code>pinv</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lsqlin(A, b, C, d)</code> minimizes <code>||A*x - b||</code> (i.e., in the 
least-squares sense) subject to <code>C*x = d</code>.
</p>


<h3>Value</h3>

<p>Returns a least-squares solution as column vector, or a matrix of solutions 
in the columns if <code>b</code> is a matrix with several columns.
</p>


<h3>Note</h3>

<p>The Matlab function <code>lsqlin</code> solves a more general problem, allowing
additional linear inequalities and bound constraints. In <code>pracma</code> this
task is solved applying function <code>lsqlincon</code>.
</p>


<h3>Author(s)</h3>

<p>HwB  email: &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra.
SIAM, Society for Industrial and Applied Mathematics, Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nullspace">nullspace</a></code>, <code><a href="#topic+pinv">pinv</a></code>, <code><a href="#topic+lsqlincon">lsqlincon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(
    0.8147,    0.1576,    0.6557,
    0.9058,    0.9706,    0.0357,
    0.1270,    0.9572,    0.8491,
    0.9134,    0.4854,    0.9340,
    0.6324,    0.8003,    0.6787,
    0.0975,    0.1419,    0.7577,
    0.2785,    0.4218,    0.7431,
    0.5469,    0.9157,    0.3922,
    0.9575,    0.7922,    0.6555,
    0.9649,    0.9595,    0.1712), 10, 3, byrow = TRUE)
b &lt;- matrix(c(
    0.7060,    0.4387,
    0.0318,    0.3816,
    0.2769,    0.7655,
    0.0462,    0.7952,
    0.0971,    0.1869,
    0.8235,    0.4898,
    0.6948,    0.4456,
    0.3171,    0.6463,
    0.9502,    0.7094,
    0.0344,    0.7547), 10, 2, byrow = TRUE)
C &lt;- matrix(c(
    1.0000,    1.0000,    1.0000,
    1.0000,   -1.0000,    0.5000), 2, 3, byrow = TRUE)
d &lt;- as.matrix(c(1, 0.5))

# With a full rank constraint system
(L &lt;- lsqlin(A, b, C, d))
#  0.10326838 0.3740381
#  0.03442279 0.1246794
#  0.86230882 0.5012825
C %*% L
#  1.0  1.0
#  0.5  0.5

## Not run: 
# With a rank deficient constraint system
C &lt;- str2num('[1 1 1;1 1 1]')
d &lt;- str2num('[1;1]')
(L &lt;- lsqlin(A, b[, 1], C, d))
#  0.2583340
# -0.1464215
#  0.8880875
C %*% L         # 1 1  as column vector

# Where both A and C are rank deficient
A2 &lt;- repmat(A[, 1:2], 1, 2)
C &lt;- ones(2, 4) # d as above
(L &lt;- lsqlin(A2, b[, 2], C, d))
#  0.2244121
#  0.2755879
#  0.2244121
#  0.2755879
C %*% L         # 1 1  as column vector
## End(Not run)
</code></pre>

<hr>
<h2 id='lsqlincon'>
Linear Least-Squares Fitting with linear constraints
</h2><span id='topic+lsqlincon'></span>

<h3>Description</h3>

<p>Solves linearly constrained linear least-squares problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsqlincon(C, d,  A = NULL, b = NULL,
          Aeq = NULL, beq = NULL, lb = NULL,  ub = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsqlincon_+3A_c">C</code></td>
<td>
<p><code>mxn</code>-matrix defining the least-squares problem.</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_d">d</code></td>
<td>
<p>vector or a one colum matrix with <code>m</code> rows</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_a">A</code></td>
<td>
<p><code>pxn</code>-matrix for the linear inequality constraints.</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_b">b</code></td>
<td>
<p>vector or <code>px1</code>-matrix, right hand side for the constraints.</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_aeq">Aeq</code></td>
<td>
<p><code>qxn</code>-matrix for the linear equality constraints.</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_beq">beq</code></td>
<td>
<p>vector or <code>qx1</code>-matrix, right hand side for the constraints.</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_lb">lb</code></td>
<td>
<p>lower bounds, a scalar will be extended to length n.</p>
</td></tr>
<tr><td><code id="lsqlincon_+3A_ub">ub</code></td>
<td>
<p>upper bounds, a scalar will be extended to length n.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lsqlincon(C, d, A, b, Aeq, beq, lb, ub)</code> minimizes <code>||C*x - d||</code>
(i.e., in the least-squares sense) subject to the following constraints:
<code>A*x &lt;= b</code>, <code>Aeq*x = beq</code>, and <code>lb &lt;= x &lt;= ub</code>.
</p>
<p>It applies the quadratic solver in <code>quadprog</code> with an active-set
method for solving quadratic programming problems.
</p>
<p>If some constraints are <code>NULL</code> (the default), they will not be taken
into account. In case no constraints are given at all, it simply uses
<code>qr.solve</code>.
</p>


<h3>Value</h3>

<p>Returns the least-squares solution as a vector.
</p>


<h3>Note</h3>

<p>Function <code>lsqlin</code> in <code>pracma</code> solves this for equality constraints
only, by computing a base for the nullspace of <code>Aeq</code>. But for linear
inequality constraints there is no simple linear algebra &lsquo;trick&rsquo;, thus a real
optimization solver is needed.
</p>


<h3>Author(s)</h3>

<p>HwB  email: &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra.
SIAM, Society for Industrial and Applied Mathematics, Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsqlin">lsqlin</a></code>, <code>quadprog::solve.QP</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  MATLABs lsqlin example
C &lt;- matrix(c(
    0.9501,   0.7620,   0.6153,   0.4057,
    0.2311,   0.4564,   0.7919,   0.9354,
    0.6068,   0.0185,   0.9218,   0.9169,
    0.4859,   0.8214,   0.7382,   0.4102,
    0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
d &lt;- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
A &lt;- matrix(c(
    0.2027,   0.2721,   0.7467,   0.4659,
    0.1987,   0.1988,   0.4450,   0.4186,
    0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
b &lt;- c(0.5251, 0.2026, 0.6721)
Aeq &lt;- matrix(c(3, 5, 7, 9), 1)
beq &lt;- 4
lb &lt;- rep(-0.1, 4)   # lower and upper bounds
ub &lt;- rep( 2.0, 4)

x &lt;- lsqlincon(C, d, A, b, Aeq, beq, lb, ub)
# -0.1000000 -0.1000000  0.1599088  0.4089598
# check A %*% x - b &gt;= 0
# check Aeq %*% x - beq == 0
# check sum((C %*% x - d)^2)    # 0.1695104
</code></pre>

<hr>
<h2 id='lsqnonlin'>
Nonlinear Least-Squares Fitting
</h2><span id='topic+lsqnonlin'></span><span id='topic+lsqnonneg'></span><span id='topic+lsqcurvefit'></span><span id='topic+lsqsep'></span>

<h3>Description</h3>

<p><code>lsqnonlin</code> solves nonlinear least-squares problems, including
nonlinear data-fitting problems, through the Levenberg-Marquardt approach.
</p>
<p><code>lsqnonneg</code> solve nonnegative least-squares constraints problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsqnonlin(fun, x0, options = list(), ...)
lsqnonneg(C, d)

lsqsep(flist, p0, xdata, ydata, const = TRUE)
lsqcurvefit(fun, p0, xdata, ydata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsqnonlin_+3A_fun">fun</code></td>
<td>
<p>User-defined, vector-valued function.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_x0">x0</code></td>
<td>
<p>starting point.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_options">options</code></td>
<td>
<p>list of options, for details see below.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_c">C</code>, <code id="lsqnonlin_+3A_d">d</code></td>
<td>
<p>matrix and vector such that <code>C x - d</code> will be
minimized with <code>x &gt;= 0</code>.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_flist">flist</code></td>
<td>
<p>list of (nonlinear) functions, depending on one extra parameter.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_p0">p0</code></td>
<td>
<p>starting parameters.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_xdata">xdata</code>, <code id="lsqnonlin_+3A_ydata">ydata</code></td>
<td>
<p>data points to be fitted.</p>
</td></tr>
<tr><td><code id="lsqnonlin_+3A_const">const</code></td>
<td>
<p>logical; shall a constant term be included.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lsqnonlin</code> computes the sum-of-squares of the vector-valued function
<code>fun</code>, that is if <code class="reqn">f(x) = (f_1(x), \ldots ,f_n(x))</code> then
</p>
<p style="text-align: center;"><code class="reqn">min || f(x) ||_2^2 = min(f_1(x)^2 + \ldots + f_n(x)^2)</code>
</p>

<p>will be minimized.
</p>
<p><code>x=lsqnonlin(fun,x0)</code> starts at point <code>x0</code> and finds a minimum
of the sum of squares of the functions described in fun. <code>fun</code> shall
return a vector of values and not the sum of squares of the values.
(The algorithm implicitly sums and squares fun(x).)
</p>
<p><code>options</code> is a list with the following components and defaults:
</p>

<ul>
<li> <p><code>tau</code>: used as starting value for Marquardt parameter.
</p>
</li>
<li> <p><code>tolx</code>: stopping parameter for step length.
</p>
</li>
<li> <p><code>tolg</code>: stopping parameter for gradient.
</p>
</li>
<li> <p><code>maxeval</code> the maximum number of function evaluations.
</p>
</li></ul>

<p>Typical values for <code>tau</code> are from <code>1e-6...1e-3...1</code> with small
values for good starting points and larger values for not so good or known
bad starting points.
</p>
<p><code>lsqnonneg</code> solves the linear least-squares problem <code>C x - d</code>,
<code>x</code> nonnegative, treating it through an active-set approach..
</p>
<p><code>lsqsep</code> solves the separable least-squares fitting problem
</p>
<p><code>y = a0 + a1*f1(b1, x) + ... + an*fn(bn, x)</code>
</p>
<p>where <code>fi</code> are nonlinear functions each depending on a single extra
paramater <code>bi</code>, and <code>ai</code> are additional linear parameters that
can be separated out to solve a nonlinear problem in the <code>bi</code> alone.
</p>
<p><code>lsqcurvefit</code> is simply an application of <code>lsqnonlin</code> to fitting
data points. <code>fun(p, x)</code> must be a function of two groups of variables
such that <code>p</code> will be varied to minimize the least squares sum, see
the example below.
</p>


<h3>Value</h3>

<p><code>lsqnonlin</code> returns a list with the following elements:
</p>

<ul>
<li> <p><code>x</code>: the point with least sum of squares value.
</p>
</li>
<li> <p><code>ssq</code>: the sum of squares.
</p>
</li>
<li> <p><code>ng</code>: norm of last gradient.
</p>
</li>
<li> <p><code>nh</code>: norm of last step used.
</p>
</li>
<li> <p><code>mu</code>: damping parameter of Levenberg-Marquardt.
</p>
</li>
<li> <p><code>neval</code>: number of function evaluations.
</p>
</li>
<li> <p><code>errno</code>: error number, corresponds to error message.
</p>
</li>
<li> <p><code>errmess</code>: error message, i.e. reason for stopping.
</p>
</li></ul>

<p><code>lsqnonneg</code> returns a list of <code>x</code> the non-negative solition, and
<code>resid.norm</code> the norm of the residual.
</p>
<p><code>lsqsep</code> will return the coefficients sparately, <code>a0</code> for the
constant term (being 0 if <code>const=FALSE</code>) and the vectors <code>a</code> and
<code>b</code> for the linear and nonlinear terms, respectively.
</p>


<h3>Note</h3>

<p>The refined approach, Fletcher's version of the Levenberg-Marquardt
algorithm, may be added at a later time; see the references.
</p>


<h3>References</h3>

<p>Madsen, K., and H. B.Nielsen (2010). Introduction to Optimization and
Data Fitting. Technical University of Denmark, Intitute of Computer
Science and Mathematical Modelling.
</p>
<p>Lawson, C.L., and R.J. Hanson (1974). Solving Least-Squares Problems.
Prentice-Hall, Chapter 23, p. 161.
</p>
<p>Fletcher, R., (1971). A Modified Marquardt Subroutine for Nonlinear Least
Squares. Report AERE-R 6799, Harwell.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nlm">nlm</a></code>, <code><a href="stats.html#topic+nls">nls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Rosenberg function as least-squares problem
x0  &lt;- c(0, 0)
fun &lt;- function(x) c(10*(x[2]-x[1]^2), 1-x[1])
lsqnonlin(fun, x0)

##  Example from R-help
y &lt;- c(5.5199668,  1.5234525,  3.3557000,  6.7211704,  7.4237955,  1.9703127,
       4.3939336, -1.4380091,  3.2650180,  3.5760906,  0.2947972,  1.0569417)
x &lt;- c(1,   0,   0,   4,   3,   5,  12,  10,  12, 100, 100, 100)
# Define target function as difference
f &lt;- function(b)
     b[1] * (exp((b[2] - x)/b[3]) * (1/b[3]))/(1 + exp((b[2] - x)/b[3]))^2 - y
x0 &lt;- c(21.16322, 8.83669, 2.957765)
lsqnonlin(f, x0)        # ssq 50.50144 at c(36.133144, 2.572373, 1.079811)

# nls() will break down
# nls(Y ~ a*(exp((b-X)/c)*(1/c))/(1 + exp((b-X)/c))^2,
#     start=list(a=21.16322, b=8.83669, c=2.957765), algorithm = "plinear")
# Error: step factor 0.000488281 reduced below 'minFactor' of 0.000976563

##  Example: Hougon function
x1 &lt;- c(470, 285, 470, 470, 470, 100, 100, 470, 100, 100, 100, 285, 285)
x2 &lt;- c(300,  80, 300,  80,  80, 190,  80, 190, 300, 300,  80, 300, 190)
x3 &lt;- c( 10,  10, 120, 120,  10,  10,  65,  65,  54, 120, 120,  10, 120)
rate &lt;- c(8.55,  3.79, 4.82, 0.02,  2.75, 14.39, 2.54,
          4.35, 13.00, 8.50, 0.05, 11.32,  3.13)
fun &lt;- function(b)
        (b[1]*x2 - x3/b[5])/(1 + b[2]*x1 + b[3]*x2 + b[4]*x3) - rate
lsqnonlin(fun, rep(1, 5))
# $x    [1.25258502 0.06277577 0.04004772 0.11241472 1.19137819]
# $ssq  0.298901

##  Example for lsqnonneg()
C1 &lt;- matrix( c(0.1210, 0.2319, 0.4398, 0.9342, 0.1370,
                0.4508, 0.2393, 0.3400, 0.2644, 0.8188,
                0.7159, 0.0498, 0.3142, 0.1603, 0.4302,
                0.8928, 0.0784, 0.3651, 0.8729, 0.8903,
                0.2731, 0.6408, 0.3932, 0.2379, 0.7349,
                0.2548, 0.1909, 0.5915, 0.6458, 0.6873,
                0.8656, 0.8439, 0.1197, 0.9669, 0.3461,
                0.2324, 0.1739, 0.0381, 0.6649, 0.1660,
                0.8049, 0.1708, 0.4586, 0.8704, 0.1556,
                0.9084, 0.9943, 0.8699, 0.0099, 0.1911), ncol = 5, byrow = TRUE)
C2 &lt;- C1 - 0.5
d &lt;- c(0.4225, 0.8560, 0.4902, 0.8159, 0.4608,
       0.4574, 0.4507, 0.4122, 0.9016, 0.0056)
( sol &lt;- lsqnonneg(C1, d) )     #-&gt; resid.norm   0.3694372
( sol &lt;- lsqnonneg(C2, d) )     #-&gt; $resid.norm  2.863979

##  Example for lsqcurvefit()
#   Lanczos1 data (artificial data)
#   f(x) = 0.0951*exp(-x) + 0.8607*exp(-3*x) + 1.5576*exp(-5*x)
x &lt;- linspace(0, 1.15, 24)
y &lt;- c(2.51340000, 2.04433337, 1.66840444, 1.36641802, 1.12323249, 0.92688972,
       0.76793386, 0.63887755, 0.53378353, 0.44793636, 0.37758479, 0.31973932,
       0.27201308, 0.23249655, 0.19965895, 0.17227041, 0.14934057, 0.13007002,
       0.11381193, 0.10004156, 0.08833209, 0.07833544, 0.06976694, 0.06239313)

p0 &lt;- c(1.2, 0.3, 5.6, 5.5, 6.5, 7.6)
fp &lt;- function(p, x) p[1]*exp(-p[2]*x) + p[3]*exp(-p[4]*x) + p[5]*exp(-p[6]*x)
lsqcurvefit(fp, p0, x, y)

##  Example for lsqsep()
f &lt;- function(x) 0.5 + x^-0.5 + exp(-0.5*x)
set.seed(8237); n &lt;- 15
x &lt;- sort(0.5 + 9*runif(n))
y &lt;- f(x)                       #y &lt;- f(x) + 0.01*rnorm(n)

m &lt;- 2
f1 &lt;- function(b, x) x^b
f2 &lt;- function(b, x) exp(b*x)
flist &lt;- list(f1, f2)
start &lt;- c(-0.25, -0.75)

sol &lt;- lsqsep(flist, start, x, y, const = TRUE)
a0 &lt;- sol$a0; a &lt;- sol$a; b &lt;- sol$b
fsol &lt;- function(x) a0 + a[1]*f1(b[1], x) + a[2]*f2(b[2], x)

## Not run: 
    ezplot(f, 0.5, 9.5, col = "gray")
    points(x, y, col = "blue")
    xs &lt;- linspace(0.5, 9.5, 51)
    ys &lt;- fsol(xs)
    lines(xs, ys, col = "red")

## End(Not run)
</code></pre>

<hr>
<h2 id='lu'>
LU Matrix Factorization
</h2><span id='topic+lu'></span><span id='topic+lu_crout'></span><span id='topic+lufact'></span><span id='topic+lusys'></span>

<h3>Description</h3>

<p>LU decomposition of a positive definite matrix as Gaussian factorization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lu(A, scheme = c("kji", "jki", "ijk"))
lu_crout(A)

lufact(A)
lusys(A, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lu_+3A_a">A</code></td>
<td>
<p>square positive definite numeric matrix (will not be checked).</p>
</td></tr>
<tr><td><code id="lu_+3A_scheme">scheme</code></td>
<td>
<p>order of row and column operations.</p>
</td></tr>
<tr><td><code id="lu_+3A_b">b</code></td>
<td>
<p>right hand side of a linear system of equations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a given matrix <code>A</code>, the LU decomposition exists and is unique iff
its principal submatrices of order <code>i=1,...,n-1</code> are nonsingular. The
procedure here is a simple Gauss elimination with or without pivoting.
</p>
<p>The scheme abbreviations refer to the order in which the cycles of row- and
column-oriented operations are processed. The &ldquo;ijk&rdquo; scheme is one of the
two compact forms, here the Doolite factorization (the Crout factorization
would be similar).
</p>
<p><code>lu_crout</code> implements the Crout algorithm. For the Doolite algorithm,
the <code>L</code> matrix has ones on its diagonal, for the Crout algorithm, the 
diagonal of the <code>U</code> matrix only has ones.
</p>
<p><code>lufact</code> applies partial pivoting (along the rows).
<code>lusys</code> uses LU factorization to solve the linear system <code>A*x=b</code>.
</p>
<p>These function are not meant to process huge matrices or linear systems of
equations.
Without pivoting they may also be harmed by considerable inaccuracies.
</p>


<h3>Value</h3>

<p><code>lu</code> and <code>lu_crout</code> return a list with components <code>L</code>
and <code>U</code>, the lower and upper triangular matrices such that
<code>A=L%*%U</code>. 
</p>
<p><code>lufact</code> returns a list with <code>L</code> and <code>U</code> combined into one
matrix <code>LU</code>, the <code>rows</code> used in partial pivoting, and <code>det</code>
representing the determinant of <code>A</code>. See the examples how to extract
matrices <code>L</code> and <code>U</code> from <code>LU</code>.
</p>
<p><code>lusys</code> returns the solution of the system as a column vector.
</p>


<h3>Note</h3>

<p>To get the Crout decomposition of a matrix <code>A</code> do
<code>Z &lt;- lu(t(A)); L &lt;- t(Z$U); U &lt;- t(Z$L)</code>.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second edition, Springer-Verlag, Berlin Heidelberg.
</p>
<p>J.H. Mathews and K.D. Fink (2003). Numerical Methods Using MATLAB.
Fourth Edition, Pearson (Prentice-Hall), updated 2006.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+qr">qr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- magic(5)
D &lt;- lu(A, scheme = "ijk")     # Doolittle scheme
D$L %*% D$U
##      [,1] [,2] [,3] [,4] [,5]
## [1,]   17   24    1    8   15
## [2,]   23    5    7   14   16
## [3,]    4    6   13   20   22
## [4,]   10   12   19   21    3
## [5,]   11   18   25    2    9

H4 &lt;- hilb(4)
lufact(H4)$det
## [1] 0.0000001653439

x0 &lt;- c(1.0, 4/3, 5/3, 2.0)
b  &lt;- H4 %*% x0
lusys(H4, b)
##          [,1]
## [1,] 1.000000
## [2,] 1.333333
## [3,] 1.666667
## [4,] 2.000000
</code></pre>

<hr>
<h2 id='magic'>Magic Square</h2><span id='topic+magic'></span>

<h3>Description</h3>

<p>Create a magic square.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>magic(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="magic_+3A_n">n</code></td>
<td>
<p>numeric scalar specifying dimensions for the result;
<code>n</code> must be a scalar greater than or equal to 3.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A magic square is a square matrix where all row and column sums and also
the diagonal sums all have the same value.
</p>
<p>This value or the characteristic sum for a magic square of order <code class="reqn">n</code>
is <code class="reqn">sum(1:n^2)/n</code>.
</p>


<h3>Value</h3>

<p>Returns an <code>n</code>-by-<code>n</code> matrix constructed from
the integers <code>1</code> through <code>N^2</code> with equal row and column sums.
</p>


<h3>Note</h3>

<p>A magic square, scaled by its magic sum, is doubly stochastic.
</p>


<h3>Author(s)</h3>

<p>P. Roebuck <a href="mailto:roebuck@mdanderson.org">roebuck@mdanderson.org</a> for the first R version in the
package &lsquo;matlab&rsquo;. The version here is more R-like.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>magic(3)
</code></pre>

<hr>
<h2 id='matlab'>
Matlab Compatibility
</h2><span id='topic+matlab'></span>

<h3>Description</h3>

<p>Matlab compatibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matlab()
</code></pre>


<h3>Details</h3>

<p>Lists all the functions and function names that emulate Matlab functions.
</p>


<h3>Value</h3>

<p>Invisible NULL value.
</p>

<hr>
<h2 id='meshgrid'>
Generate a Mesh Grid
</h2><span id='topic+meshgrid'></span>

<h3>Description</h3>

<p>Generate two matrices for use in three-dimensional plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meshgrid(x, y = x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meshgrid_+3A_x">x</code></td>
<td>
<p>numerical vector, represents points along the x-axis.</p>
</td></tr>
<tr><td><code id="meshgrid_+3A_y">y</code></td>
<td>
<p>numerical vector, represents points along the y-axis.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rows of the output array X are copies of the vector x;
columns of the output array Y are copies of the vector y.
</p>


<h3>Value</h3>

<p>Returns two matrices as a list with <code>X</code> and <code>Y</code> components.
</p>


<h3>Note</h3>

<p>The three-dimensional variant <code>meshgrid(x, y, z)</code> is not yet implemented.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+outer">outer</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meshgrid(1:5)$X
meshgrid(c(1, 2, 3), c(11, 12))
</code></pre>

<hr>
<h2 id='mexpfit'>
Multi-exponential Fitting
</h2><span id='topic+mexpfit'></span>

<h3>Description</h3>

<p>Multi-exponential fitting means fitting of data points by a sum of
(decaying) exponential functions, with or without a constant term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mexpfit(x, y, p0, w = NULL, const = TRUE, options = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mexpfit_+3A_x">x</code>, <code id="mexpfit_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates of data points to be fitted.</p>
</td></tr>
<tr><td><code id="mexpfit_+3A_p0">p0</code></td>
<td>
<p>starting values for the exponentials alone; can be positive
or negative, but not zero.</p>
</td></tr>
<tr><td><code id="mexpfit_+3A_w">w</code></td>
<td>
<p>weight vector; not used in this version.</p>
</td></tr>
<tr><td><code id="mexpfit_+3A_const">const</code></td>
<td>
<p>logical; shall an absolute term be included.</p>
</td></tr>
<tr><td><code id="mexpfit_+3A_options">options</code></td>
<td>
<p>list of options for <code>lsqnonlin</code>, see there.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multi-exponential fitting problem is solved here with with a separable
nonlinear least-squares approach. If the following function is to be fitted,
</p>
<p style="text-align: center;"><code class="reqn">y = a_0 + a_1 e^{b_1 x} + \ldots + a_n e^{b_n x}</code>
</p>

<p>it will be looked at as a nonlinear optimization problem of the coefficients
<code class="reqn">b_i</code> alone. Given the <code class="reqn">b_i</code>, coefficients <code class="reqn">a_i</code> are uniquely
determined as solution of an (overdetermined) system of linear equations.
</p>
<p>This approach reduces the dimension of the search space by half and improves
numerical stability and accuracy. As a convex problem, the solution is unique
and global.
</p>
<p>To solve the nonlinear part, the function <code>lsqnonlin</code> that uses the
Levenberg-Marquard algorithm will be applied.
</p>


<h3>Value</h3>

<p><code>mexpfit</code> returns a list with the following elements:
</p>

<ul>
<li> <p><code>a0</code>: the absolute term, 0 if <code>const</code> is false.
</p>
</li>
<li> <p><code>a</code>: linear coefficients.
</p>
</li>
<li> <p><code>b</code>: coefficient in the exponential functions.
</p>
</li>
<li> <p><code>ssq</code>: the sum of squares for the final fitting.
</p>
</li>
<li> <p><code>iter</code>: number of iterations resp. function calls.
</p>
</li>
<li> <p><code>errmess</code>: an error or info message.
</p>
</li></ul>



<h3>Note</h3>

<p>As the Jacobian for this expression is known, a more specialized approch
would be possible, without using <code>lsqnonlin</code>;
see the <code>immoptibox</code> of H. B. Nielsen, Techn. University of Denmark.
</p>


<h3>Author(s)</h3>

<p>HwB  email: &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Madsen, K., and H. B. Nielsen (2010). Introduction to Optimization and
Data Fitting. Technical University of Denmark, Intitute of Computer
Science and Mathematical Modelling.
</p>
<p>Nielsen, H. B. (2000). Separable Nonlinear Least Squares. IMM, DTU,
Report IMM-REP-2000-01.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsqsep">lsqsep</a></code>, <code><a href="#topic+lsqnonlin">lsqnonlin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#   Lanczos1 data (artificial data)
#   f(x) = 0.0951*exp(-x) + 0.8607*exp(-3*x) + 1.5576*exp(-5*x)
x &lt;- linspace(0, 1.15, 24)
y &lt;- c(2.51340000, 2.04433337, 1.66840444, 1.36641802, 1.12323249, 0.92688972,
       0.76793386, 0.63887755, 0.53378353, 0.44793636, 0.37758479, 0.31973932,
       0.27201308, 0.23249655, 0.19965895, 0.17227041, 0.14934057, 0.13007002,
       0.11381193, 0.10004156, 0.08833209, 0.07833544, 0.06976694, 0.06239313)
p0 &lt;- c(-0.3, -5.5, -7.6)
mexpfit(x, y, p0, const = FALSE)
## $a0
## [1] 0
## $a
## [1] 0.09510431 0.86071171 1.55758398
## $b
## [1] -1.000022 -3.000028 -5.000009
## $ssq
## [1] 1.936163e-16
## $iter
## [1] 26
## $errmess
## [1] "Stopped by small gradient."
</code></pre>

<hr>
<h2 id='mldivide'>Matlab backslash operator</h2><span id='topic+mldivide'></span><span id='topic+mrdivide'></span>

<h3>Description</h3>

<p>Emulate the Matlab backslash operator &ldquo;\&rdquo; through QR decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mldivide(A, B, pinv = TRUE)
mrdivide(A, B, pinv = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mldivide_+3A_a">A</code>, <code id="mldivide_+3A_b">B</code></td>
<td>

<p>Numerical or complex matrices; <code>A</code> and <code>B</code> must have the same 
number of rows (for <code>mldivide</code>) or the same number of columns
(for <code>mrdivide</code>)
</p>
</td></tr>
<tr><td><code id="mldivide_+3A_pinv">pinv</code></td>
<td>
<p>logical; shall SVD decomposition be used; default true.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mldivide</code> performs matrix left division (and <code>mrdivide</code> matrix
right division). If <code>A</code> is scalar it performs element-wise division.
</p>
<p>If <code>A</code> is square, <code>mldivide</code> is roughly the same as
<code>inv(A) %*% B</code> except it is computed in a different way &mdash;
using QR decomposition.
</p>
<p>If <code>pinv = TRUE</code>, the default, the SVD will be used as
<code>pinv(t(A)%*%A)%*%t(A)%*%B</code> to generate results similar
to Matlab. Otherwise, <code>qr.solve</code> will be used.
</p>
<p>If <code>A</code> is not square, <code>x &lt;- mldivide(A, b)</code> returnes a
least-squares solution that minimizes the length of the vector
<code>A %*% x - b</code>
(which is equivalent to <code>norm(A %*% x - b, "F")</code>.
</p>


<h3>Value</h3>

<p>If <code>A</code> is an n-by-p matrix and <code>B</code> n-by-q, then the result of
<code>mldivide(A, B)</code> is a p-by-q matrix (<code>mldivide</code>).
</p>


<h3>Note</h3>

<p><code>mldivide(A, B)</code> corresponds to <code>A\B</code> in Matlab notation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Solve a system of linear equations
A &lt;- matrix(c(8,1,6, 3,5,7, 4,9,2), nrow = 3, ncol = 3, byrow = TRUE)
b &lt;- c(1, 1, 1)
mldivide(A, b)  # 0.06666667 0.06666667 0.06666667

A &lt;- rbind(1:3, 4:6)
mldivide(A, c(1,1))                 # -0.5  0  0.5 ,i.e. Matlab/Octave result
mldivide(A, c(1,1), pinv = FALSE)   # -1    1  0         R    qr.solve result
</code></pre>

<hr>
<h2 id='mod+2C+20rem'>Integer Division</h2><span id='topic+mod'></span><span id='topic+rem'></span><span id='topic+idivide'></span>

<h3>Description</h3>

<p>Integer division functions and remainders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod(n, m)
rem(n, m)

idivide(n, m, rounding = c("fix", "floor", "ceil", "round"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod+2B2C+2B20rem_+3A_n">n</code></td>
<td>
<p>numeric vector (preferably of integers)</p>
</td></tr>
<tr><td><code id="mod+2B2C+2B20rem_+3A_m">m</code></td>
<td>
<p>must be a scalar integer (positive, zero, or negative)</p>
</td></tr>
<tr><td><code id="mod+2B2C+2B20rem_+3A_rounding">rounding</code></td>
<td>
<p>rounding mode.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mod(n, m)</code> is the modulo operator and returns <code class="reqn">n\,mod\,m</code>.
<code>mod(n, 0)</code> is <code>n</code>, and the result always has the same sign
as <code>m</code>.
</p>
<p><code>rem(n, m)</code> is the same modulo operator and returns <code class="reqn">n\,mod\,m</code>.
<code>mod(n, 0)</code> is <code>NaN</code>, and the result always has the same sign
as <code>n</code>.
</p>
<p><code>idivide(n, m)</code> is integer division, with the same effect as
<code>n %/% m</code> or using an optional rounding mode.
</p>


<h3>Value</h3>

<p>a numeric (integer) value or vector/matrix.
</p>


<h3>Note</h3>

<p>The following relation is fulfilled (for <code>m != 0</code>):
</p>
<p><code>mod(n, m) = n - m * floor(n/m)</code>
</p>


<h3>See Also</h3>

<p>Binary R operators <code>%/%</code> and <code>%%</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod(c(-5:5), 5)
rem(c(-5:5), 5)

idivide(c(-2, 2), 3, "fix")     #  0 0
idivide(c(-2, 2), 3, "floor")   # -1 0
idivide(c(-2, 2), 3, "ceil")    #  0 1
idivide(c(-2, 2), 3, "round")   # -1 1
</code></pre>

<hr>
<h2 id='Mode'>
Mode function (Matlab style)
</h2><span id='topic+Mode'></span>

<h3>Description</h3>

<p>Most frequent value in vector or matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mode(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mode_+3A_x">x</code></td>
<td>
<p>Real or complex vector or of factor levels.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the &lsquo;sample mode&rsquo;, i.e. the most frequently occurring value in x.
</p>
<p>Among values occurring equally frequently, <code>Mode()</code> chooses the
smallest one (for a numeric vector), one with a smallest absolute value
(for complex ones) or the first occurring value (for factor levels).
</p>
<p>A matrix will be changed to a vector.
</p>


<h3>Value</h3>

<p>One element from x and of the same type. The number of occurrences will 
not be returned.
</p>


<h3>Note</h3>

<p>In Matlab/Octave an array dimension can be selected along which to find
the mode value; this has not been realized here.
</p>
<p>Shadows the R function <code>mode</code> that returns essentially the type
of an object.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+median">median</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- round(rnorm(1000), 2)
Mode(x)
</code></pre>

<hr>
<h2 id='moler'>Moler Matrix</h2><span id='topic+moler'></span>

<h3>Description</h3>

<p>Generate the Moler matrix of size <code>n x n</code>. The Moler matrix is for
testing eigenvalue computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moler(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="moler_+3A_n">n</code></td>
<td>
<p>integer</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Moler matrix for testing eigenvalue computations is a symmetric
matrix with exactly one small eigenvalue. 
</p>


<h3>Value</h3>

<p>matrix of size <code>n x n</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wilkinson">wilkinson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(a &lt;- moler(10))
min(eig(a))
</code></pre>

<hr>
<h2 id='movavg'>
Moving Average Filters
</h2><span id='topic+movavg'></span>

<h3>Description</h3>

<p>Different types of moving average of a time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movavg(x, n, type=c("s", "t", "w", "m", "e", "r"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="movavg_+3A_x">x</code></td>
<td>
<p>time series as numeric vector.</p>
</td></tr>
<tr><td><code id="movavg_+3A_n">n</code></td>
<td>
<p>backward window length.</p>
</td></tr>
<tr><td><code id="movavg_+3A_type">type</code></td>
<td>
<p>one of 's', 't', 'w', 'm', 'e', or 'r'; default is 's'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Types of available moving averages are:
</p>

<ul>
<li> <p><code>s</code> for &ldquo;simple&rdquo;, it computes the simple moving average.
<code>n</code> indicates the number of previous data points used with the 
current data point when calculating the moving average.
</p>
</li>
<li> <p><code>t</code> for &ldquo;triangular&rdquo;, it computes the triangular moving average 
by calculating the first simple moving average with window width of 
<code>ceil(n+1)/2</code>; then it calculates a second simple moving average 
on the first moving average with the same window size.
</p>
</li>
<li> <p><code>w</code> for &ldquo;weighted&quot;, it calculates the weighted moving average 
by supplying weights for each element in the moving window. Here the 
reduction of weights follows a linear trend.
</p>
</li>
<li> <p><code>m</code> for &ldquo;modified&quot;, it calculates the modified moving average. 
The first modified moving average is calculated like a simple moving 
average. Subsequent values are calculated by adding the new value and 
subtracting the last average from the resulting sum.
</p>
</li>
<li> <p><code>e</code> for&ldquo;exponential&quot;, it computes the exponentially weighted 
moving average. The exponential moving average is a weighted moving 
average that reduces influences by applying more weight to recent 
data points () reduction factor <code>2/(n+1)</code>; or
</p>
</li>
<li> <p><code>r</code> for&ldquo;running&quot;, this is an exponential moving average with a 
reduction factor of <code>1/n</code> [same as the modified average?].
</p>
</li></ul>



<h3>Value</h3>

<p>Vector the same length as time series <code>x</code>.
</p>


<h3>References</h3>

<p>Matlab Techdoc
</p>


<h3>See Also</h3>

<p><code>filter</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
abbshares &lt;- scan(file="")
25.69 25.89 25.86 26.08 26.41 26.90 26.27 26.45 26.49 26.08 26.11 25.57 26.02
25.53 25.27 25.95 25.19 24.78 24.96 24.63 25.68 25.24 24.87 24.71 25.01 25.06
25.62 25.95 26.08 26.25 25.91 26.61 26.34 25.55 25.36 26.10 25.63 25.52 24.74
25.00 25.38 25.01 24.57 24.95 24.89 24.13 23.83 23.94 23.74 23.12 23.13 21.05
21.59 19.59 21.88 20.59 21.59 21.86 22.04 21.48 21.37 19.94 19.49 19.46 20.34
20.59 19.96 20.18 20.74 20.83 21.27 21.19 20.27 18.83 19.46 18.90 18.09 17.99
18.03 18.50 19.11 18.94 18.21 18.06 17.66 16.77 16.77 17.10 17.62 17.22 17.95
17.08 16.42 16.71 17.06 17.75 17.65 18.90 18.80 19.54 19.23 19.48 18.98 19.28
18.49 18.49 19.08 19.63 19.40 19.59 20.37 19.95 18.81 18.10 18.32 19.02 18.78
18.68 19.12 17.79 18.10 18.64 18.28 18.61 18.20 17.82 17.76 17.26 17.08 16.70
16.68 17.68 17.70 18.97 18.68 18.63 18.80 18.81 19.03 18.26 18.78 18.33 17.97
17.60 17.72 17.79 17.74 18.37 18.24 18.47 18.75 18.66 18.51 18.71 18.83 19.82
19.71 19.64 19.24 19.60 19.77 19.86 20.23 19.93 20.33 20.98 21.40 21.14 21.38
20.89 21.08 21.30 21.24 20.55 20.83 21.57 21.67 21.91 21.66 21.53 21.63 21.83
21.48 21.71 21.44 21.67 21.10 21.03 20.83 20.76 20.90 20.92 20.80 20.89 20.49
20.70 20.60 20.39 19.45 19.82 20.28 20.24 20.30 20.66 20.66 21.00 20.88 20.99
20.61 20.45 20.09 20.34 20.61 20.29 20.20 20.00 20.41 20.70 20.43 19.98 19.92
19.77 19.23 19.55 19.93 19.35 19.66 20.27 20.10 20.09 20.48 19.86 20.22 19.35
19.08 18.81 18.87 18.26 18.27 17.91 17.68 17.73 17.56 17.20 17.14 16.84 16.47
16.45 16.25 16.07

plot(abbshares, type = "l", col = 1, ylim = c(15, 30),
                main = "Types of moving averages", sub = "Mid 2011--Mid 2012",
                xlab = "Days", ylab = "ABB Shares Price (in USD)")
y &lt;- movavg(abbshares, 50, "s"); lines(y, col = 2)
y &lt;- movavg(abbshares, 50, "t"); lines(y, col = 3)
y &lt;- movavg(abbshares, 50, "w"); lines(y, col = 4)
y &lt;- movavg(abbshares, 50, "m"); lines(y, col = 5)
y &lt;- movavg(abbshares, 50, "e"); lines(y, col = 6)
y &lt;- movavg(abbshares, 50, "r"); lines(y, col = 7)
grid()
legend(120, 29, c("original data", "simple", "triangular", "weighted",
                                   "modified", "exponential", "running"),
                col = 1:7, lty = 1, lwd = 1, box.col = "gray", bg = "white")

## End(Not run)
</code></pre>

<hr>
<h2 id='muller'>
Muller's Method
</h2><span id='topic+muller'></span>

<h3>Description</h3>

<p>Muller's root finding method, similar to the secant method, using a 
parabola through three points for approximating the curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>muller(f, p0, p1, p2 = NULL, maxiter = 100, tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="muller_+3A_f">f</code></td>
<td>
<p>function whose root is to be found; function needs to be defined
on the complex plain.</p>
</td></tr>
<tr><td><code id="muller_+3A_p0">p0</code>, <code id="muller_+3A_p1">p1</code>, <code id="muller_+3A_p2">p2</code></td>
<td>
<p>three starting points, should enclose the assumed root.</p>
</td></tr>
<tr><td><code id="muller_+3A_tol">tol</code></td>
<td>
<p>relative tolerance, change in successive iterates.</p>
</td></tr>
<tr><td><code id="muller_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generalizes the secant method by using parabolic interpolation between
three points. This technique can be used for any root-finding problem, 
but is particularly useful for approximating the roots of polynomials,
and for finding zeros of analytic functions in the complex plane.
</p>


<h3>Value</h3>

<p>List of <code>root</code>, <code>fval</code>, <code>niter</code>, and <code>reltol</code>.
</p>


<h3>Note</h3>

<p>Muller's method is considered to be (a bit) more robust than Newton's.
</p>


<h3>References</h3>

<p>Pseudo- and C code available from the &lsquo;Numerical Recipes&rsquo;;
pseudocode in the book &lsquo;Numerical Analysis&rsquo; by Burden and Faires (2011).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+secant">secant</a></code>, <code><a href="#topic+newtonRaphson">newtonRaphson</a></code>, <code><a href="#topic+newtonsys">newtonsys</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>muller(function(x) x^10 - 0.5, 0, 1)  # root: 0.9330329915368074

f &lt;- function(x) x^4 - 3*x^3 + x^2 + x + 1
p0 &lt;- 0.5; p1 &lt;- -0.5; p2 &lt;- 0.0
muller(f, p0, p1, p2)
## $root
## [1] -0.3390928-0.4466301i
## ...

##  Roots of complex functions:
fz &lt;- function(z) sin(z)^2 + sqrt(z) - log(z)
muller(fz, 1, 1i, 1+1i)
## $root
## [1] 0.2555197+0.8948303i
## $fval
## [1] -4.440892e-16+0i
## $niter
## [1] 8
## $reltol
## [1] 3.656219e-13
</code></pre>

<hr>
<h2 id='nchoosek'>
Binomial Coefficients
</h2><span id='topic+nchoosek'></span>

<h3>Description</h3>

<p>Compute the Binomial coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nchoosek(n, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nchoosek_+3A_n">n</code>, <code id="nchoosek_+3A_k">k</code></td>
<td>
<p>integers with <code>k</code> between 0 and <code>n</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Alias for the corresponding R function <code>choose</code>.
</p>


<h3>Value</h3>

<p>integer, the Binomial coefficient <code class="reqn">({n \over k})</code>.
</p>


<h3>Note</h3>

<p>In Matlab/Octave, if <code>n</code> is a vector all combinations of <code>k</code>
elements from vector <code>n</code> will be generated. Here, use the function
<code>combs</code> instead.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+choose">choose</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- sapply(0:6, function(k) nchoosek(6, k))  # 1  6 15 20 15  6  1

# Catalan numbers
catalan &lt;- function(n) choose(2*n, n)/(n+1)
catalan(0:10)
# 1  1  2  5  14  42  132  429  1430  4862  16796

# Relations
n &lt;- 10
sum((-1)^c(0:n) * sapply(0:n, function(k) nchoosek(n, k)))  # 0
</code></pre>

<hr>
<h2 id='ndims'>Number of Dimensions</h2><span id='topic+ndims'></span>

<h3>Description</h3>

<p>Number of matrix or array dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ndims(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ndims_+3A_x">x</code></td>
<td>
<p>a vector, matrix, array, or list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the number of dimensions as <code>length(x)</code>.
</p>
<p>For an empty object its dimension is 0, for vectors it is 1
(deviating from MATLAB), for matrices it is 2, and for arrays
it is the number of dimensions, as usual.
Lists are considered to be (one-dimensional) vectors.
</p>


<h3>Value</h3>

<p>the number of dimensions in a vector, matrix, or array <code>x</code>.
</p>


<h3>Note</h3>

<p>The result will differ from Matlab when <code>x</code> is a vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+size">size</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ndims(c())                      # 0
ndims(as.numeric(1:8))          # 1
ndims(list(a=1, b=2, c=3))      # 1
ndims(matrix(1:12, 3, 4))       # 2
ndims(array(1:8, c(2,2,2)))     # 3
</code></pre>

<hr>
<h2 id='nearest_spd'>
Nearest Symmetric Positive-definite Matrix
</h2><span id='topic+nearest_spd'></span>

<h3>Description</h3>

<p>Find nearest (in Frobenius norm) symmetric positive-definite matrix to A.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearest_spd(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nearest_spd_+3A_a">A</code></td>
<td>
<p>square numeric matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;The nearest symmetric positive semidefinite matrix in the
Frobenius norm to an arbitrary real matrix A is shown to be (B + H)/2,
where H is the symmetric polar factor of B=(A + A')/2.&quot;<br />
N. J. Highham
</p>


<h3>Value</h3>

<p>Returns a matrix of the same size.
</p>


<h3>References</h3>

<p>Nicholas J. Higham (1988). Computing a nearest symmetric positive 
semidefinite matrix. 
Linear Algebra and its Applications. Vol. 103, pp.103-118.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+randortho">randortho</a></code>, <code><a href="#topic+procrustes">procrustes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(1:9, 3, 3)
B &lt;- nearest_spd(A); B
#          [,1]     [,2]     [,3]
# [1,] 2.034900 3.202344 4.369788
# [2,] 3.202344 5.039562 6.876781
# [3,] 4.369788 6.876781 9.383774
norm(B - A, type = 'F')
# [1] 3.758517
</code></pre>

<hr>
<h2 id='nelder_mead'>
Nelder-Mead Function Minimization Method
</h2><span id='topic+nelder_mead'></span>

<h3>Description</h3>

<p>An implementation of the Nelder-Mead algorithm for derivative-free
optimization / function minimization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nelder_mead(fn, x0, ..., adapt = TRUE,
            tol = 1e-08, maxfeval = 5000, 
			step = rep(1.0, length(x0)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nelder_mead_+3A_fn">fn</code></td>
<td>
<p>nonlinear function to be minimized.</p>
</td></tr>
<tr><td><code id="nelder_mead_+3A_x0">x0</code></td>
<td>
<p>starting point for the iteration.</p>
</td></tr>
<tr><td><code id="nelder_mead_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function.</p>
</td></tr>
<tr><td><code id="nelder_mead_+3A_adapt">adapt</code></td>
<td>
<p>logical; adapt to parameter dimension.</p>
</td></tr>
<tr><td><code id="nelder_mead_+3A_tol">tol</code></td>
<td>
<p>terminating limit for the variance of function values;
can be made *very* small, like <code>tol=1e-50</code>.</p>
</td></tr>
<tr><td><code id="nelder_mead_+3A_maxfeval">maxfeval</code></td>
<td>
<p>maximum number of function evaluations.</p>
</td></tr>
<tr><td><code id="nelder_mead_+3A_step">step</code></td>
<td>
<p>size and shape of initial simplex; relative magnitudes of
its elements should reflect the units of the variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also called a &lsquo;simplex&rsquo; method for finding the local minimum of a function
of several variables. The method is a pattern search that compares function
values at the vertices of the simplex. The process generates a sequence of
simplices with ever reducing sizes.
</p>
<p>The simplex function minimisation procedure due to Nelder and Mead (1965),
as implemented by O'Neill (1971), with subsequent comments by Chambers and 
Ertel 1974, Benyon 1976, and Hill 1978. For another elaborate implementation 
of Nelder-Mead in R based on Matlab code by Kelley see package &lsquo;dfoptim&rsquo;.
</p>
<p><code>nelder_mead</code> can be used up to 20 dimensions (then &lsquo;tol&rsquo; and &lsquo;maxfeval&rsquo;
need to be increased). With <code>adapt=TRUE</code> it applies adaptive
coefficients for the simplicial search, depending on the problem dimension
&ndash; see Fuchang and Lixing (2012). This approach especially reduces the
number of function calls.
</p>


<h3>Value</h3>

<p>List with following components:
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>minimum solution found.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>value of <code>f</code> at minimum.</p>
</td></tr>
<tr><td><code>count</code></td>
<td>
<p>number of iterations performed.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>list with solver name and no. of restarts.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Original FORTRAN77 version by R O'Neill; MATLAB version by John Burkardt
under LGPL license. Re-implemented in R by Hans W. Borchers.
</p>


<h3>References</h3>

<p>Nelder, J., and R. Mead (1965). A simplex method for function minimization.
Computer Journal, Volume 7, pp. 308-313.
</p>
<p>O'Neill, R. (1971). Algorithm AS 47: Function Minimization Using a Simplex 
Procedure. Applied Statistics, Volume 20(3), pp. 338-345.
</p>
<p>J. C. Lagarias et al. (1998). Convergence properties of the Nelder-Mead
simplex method in low dimensions. SIAM Journal for Optimization, Vol. 9,
No. 1, pp 112-147.
</p>
<p>Fuchang Gao and Lixing Han (2012). Implementing the Nelder-Mead simplex
algorithm with adaptive parameters. Computational Optimization and
Applications, Vol. 51, No. 1, pp. 259-277.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hooke_jeeves">hooke_jeeves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Classical tests as in the article by Nelder and Mead
# Rosenbrock's parabolic valley
rpv &lt;- function(x) 100*(x[2] - x[1]^2)^2 + (1 - x[1])^2
x0 &lt;- c(-2, 1)
nelder_mead(rpv, x0)                     #  1 1

# Fletcher and Powell's helic valley
fphv &lt;- function(x)
    100*(x[3] - 10*atan2(x[2], x[1])/(2*pi))^2 + 
        (sqrt(x[1]^2 + x[2]^2) - 1)^2 +x[3]^2
x0 &lt;- c(-1, 0, 0)
nelder_mead(fphv, x0)                    #  1 0 0

# Powell's Singular Function (PSF)
psf &lt;- function(x)  (x[1] + 10*x[2])^2 + 5*(x[3] - x[4])^2 + 
                    (x[2] - 2*x[3])^4 + 10*(x[1] - x[4])^4
x0 &lt;- c(3, -1, 0, 1)
# needs maximum number of function calls
nelder_mead(psf, x0, maxfeval=30000)         #  0 0 0 0

## Not run: 
# Can run Rosenbrock's function in 30 dimensions in one and a half minutes:
nelder_mead(fnRosenbrock, rep(0, 30), tol=1e-20, maxfeval=10^7)
# $xmin
#  [1]  0.9999998 1.0000004 1.0000000 1.0000001 1.0000000 1.0000001
#  [7]  1.0000002 1.0000001 0.9999997 0.9999999 0.9999997 1.0000000
# [13]  0.9999999 0.9999994 0.9999998 0.9999999 0.9999999 0.9999999
# [19]  0.9999999 1.0000001 0.9999998 1.0000000 1.0000003 0.9999999
# [25]  1.0000000 0.9999996 0.9999995 0.9999990 0.9999973 0.9999947
# $fmin
# [1] 5.617352e-10
# $fcount
# [1] 1426085
# elapsed time is 96.008000 seconds 
## End(Not run)
</code></pre>

<hr>
<h2 id='neville'>
Neville's Method
</h2><span id='topic+neville'></span>

<h3>Description</h3>

<p>Neville's's method of polynomial interpolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neville(x, y, xs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neville_+3A_x">x</code>, <code id="neville_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates of data points defining the polynomial.</p>
</td></tr>
<tr><td><code id="neville_+3A_xs">xs</code></td>
<td>
<p>single point to be interpolated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Straightforward implementation of Neville's method; not yet vectorized.
</p>


<h3>Value</h3>

<p>Interpolated value at <code>xs</code> of the polynomial defined by <code>x,y</code>.
</p>


<h3>References</h3>

<p>Each textbook on numerical analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonInterp">newtonInterp</a></code>, <code><a href="#topic+barylag">barylag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- Poly(c(1, 2, 3))
fp &lt;- function(x) polyval(p, x)

x &lt;- 0:4; y &lt;- fp(x)
xx &lt;- linspace(0, 4, 51)
yy &lt;- numeric(51)
for (i in 1:51) yy[i] &lt;- neville(x, y, xx[i])

## Not run: 
ezplot(fp, 0, 4)
points(xx, yy)
## End(Not run)
</code></pre>

<hr>
<h2 id='newmark'>
Newmark Method
</h2><span id='topic+newmark'></span>

<h3>Description</h3>

<p>Newmark's is a method to solve higher-order differential equations
without passing through the equivalent first-order system.
It generalizes the so-called &lsquo;leap-frog&rsquo; method.
Here it is restricted to second-order equations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newmark(f, t0, t1, y0, ..., N = 100, zeta = 0.25, theta = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newmark_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y'' = f(x, y, y')</code>;<br />
defined as a function <code class="reqn">R \times R^2 \rightarrow R</code>.</p>
</td></tr>
<tr><td><code id="newmark_+3A_t0">t0</code>, <code id="newmark_+3A_t1">t1</code></td>
<td>
<p>start and end points of the interval.</p>
</td></tr>
<tr><td><code id="newmark_+3A_y0">y0</code></td>
<td>
<p>starting values as row or column vector;
<code>y0</code> needs to be a vector of length 2, the first component
representing <code>y(t0)</code>, the second <code>dy/dt(t0)</code>.</p>
</td></tr>
<tr><td><code id="newmark_+3A_n">N</code></td>
<td>
<p>number of steps.</p>
</td></tr>
<tr><td><code id="newmark_+3A_zeta">zeta</code>, <code id="newmark_+3A_theta">theta</code></td>
<td>
<p>two non-negative real numbers.</p>
</td></tr>
<tr><td><code id="newmark_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves second order differential equations using the Newmark method
on an equispaced grid of <code>N</code> steps.
</p>
<p>Function <code>f</code> must return a vector, whose elements hold the evaluation
of <code>f(t,y)</code>, of the same dimension as <code>y0</code>. Each row in the
solution array Y corresponds to a time returned in <code>t</code>.
</p>
<p>The method is &lsquo;implicit&rsquo; unless <code>zeta=theta=0</code>, second order if
<code>theta=1/2</code> and first order accurate if <code>theta!=1/2</code>.
<code>theta&gt;=1/2</code> ensures stability.
The condition set <code>theta=1/2; zeta=1/4</code> (the defaults) is a popular
approach that is unconditionally stable, but introduces oscillatory
spurious solutions on long time intervals.
(For these simulations it is preferable to use <code>theta&gt;1/2</code> and
<code>zeta&gt;(theta+1/2)^(1/2)</code>.)
</p>
<p>No attempt is made to catch any errors in the root finding functions.
</p>


<h3>Value</h3>

<p>List with components <code>t</code> for grid (or &lsquo;time&rsquo;) points between <code>t0</code>
and <code>t1</code>, and <code>y</code> an n-by-2 matrix with solution variables in
columns, i.e. each row contains one time stamp.
</p>


<h3>Note</h3>

<p>This is for demonstration purposes only; for real problems or applications
please use <code>ode23</code> or <code>rk4sys</code>.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ode23">ode23</a></code>, <code><a href="#topic+cranknic">cranknic</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mathematical pendulum  m l y'' + m g sin(y) = 0
pendel &lt;- function(t, y)  -sin(y[1])
sol &lt;- newmark(pendel, 0, 4*pi, c(pi/4, 0))

## Not run: 
plot(sol$t, sol$y[, 1], type="l", col="blue",
     xlab="Time", ylab="Elongation/Speed", main="Mathematical Pendulum")
lines(sol$t, sol$y[, 2], col="darkgreen")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='newtonHorner'>
Newton's Root Finding Method for Polynomials.
</h2><span id='topic+newtonHorner'></span>

<h3>Description</h3>

<p>Finding roots of univariate polynomials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newtonHorner(p, x0, maxiter = 50, tol = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newtonHorner_+3A_p">p</code></td>
<td>
<p>Numeric vector representing a polynomial.</p>
</td></tr>
<tr><td><code id="newtonHorner_+3A_x0">x0</code></td>
<td>
<p>starting value for newtonHorner().</p>
</td></tr>
<tr><td><code id="newtonHorner_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations; default 100.</p>
</td></tr>
<tr><td><code id="newtonHorner_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance; default <code>eps^(1/2)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to <code>newtonRahson</code>, except that the computation of the
derivative is done through the Horner scheme in parallel with computing
the value of the polynomial. This makes the algorithm significantly
faster. 
</p>


<h3>Value</h3>

<p>Return a list with components <code>root</code>, <code>f.root</code>, 
the function value at the found root, <code>iter</code>, the number of iterations
done, and <code>root</code>, and the estimated precision <code>estim.prec</code>
</p>
<p>The estimated precision is given as the difference to the last solution
before stop.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonRaphson">newtonRaphson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example: x^3 - 6 x^2 + 11 x - 6  with roots 1, 2, 3
p &lt;- c(1, -6, 11, -6)
x0 &lt;- 0
while (length(p) &gt; 1) {
    N &lt;- newtonHorner(p, x0)
    if (!is.null(N$root)) {
        cat("x0 =", N$root, "\n")
        p &lt;- N$deflate
    } else {
        break
    }
}
##  Try: p &lt;- Poly(c(1:20))
</code></pre>

<hr>
<h2 id='newtonInterp'>
Lagrange and Newtons Interpolation
</h2><span id='topic+newtonInterp'></span><span id='topic+lagrangeInterp'></span>

<h3>Description</h3>

<p>Lagrange's and Newton's method of polynomial interpolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newtonInterp(x, y, xs = c())

lagrangeInterp(x, y, xs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newtonInterp_+3A_x">x</code>, <code id="newtonInterp_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates of data points defining the polynomial.</p>
</td></tr>
<tr><td><code id="newtonInterp_+3A_xs">xs</code></td>
<td>
<p>either empty, or a vector of points to be interpolated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Straightforward implementation of Lagrange's Newton's method
(vectorized in <code>xs</code>).
</p>


<h3>Value</h3>

<p>A vector of values at <code>xs</code> of the polynomial defined by <code>x,y</code>.
</p>


<h3>References</h3>

<p>Each textbook on numerical analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+neville">neville</a></code>, <code><a href="#topic+barylag">barylag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- Poly(c(1, 2, 3))
fp &lt;- function(x) polyval(p, x)

x &lt;- 0:4; y &lt;- fp(x)
xx &lt;- linspace(0, 4, 51)
yy &lt;- lagrangeInterp(x, y, xx)
yy &lt;- newtonInterp(x, y, xx)
## Not run: 
ezplot(fp, 0, 4)
points(xx, yy)
## End(Not run)
</code></pre>

<hr>
<h2 id='newtonRaphson'>
Rootfinding through Newton-Raphson or Secant.
</h2><span id='topic+newtonRaphson'></span><span id='topic+newton'></span>

<h3>Description</h3>

<p>Finding roots of univariate functions. (Newton never invented or used
this method; it should be called more appropriately Simpson's method!)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newtonRaphson(fun, x0, dfun = NULL, maxiter = 500, tol = 1e-08, ...)
newton(fun, x0, dfun = NULL, maxiter = 500, tol = 1e-08, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newtonRaphson_+3A_fun">fun</code></td>
<td>
<p>Function or its name as a string.</p>
</td></tr>
<tr><td><code id="newtonRaphson_+3A_x0">x0</code></td>
<td>
<p>starting value for newtonRaphson().</p>
</td></tr>
<tr><td><code id="newtonRaphson_+3A_dfun">dfun</code></td>
<td>
<p>A function to compute the derivative of <code>f</code>.
If <code>NULL</code>, a numeric derivative will be computed.</p>
</td></tr>
<tr><td><code id="newtonRaphson_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations; default 100.</p>
</td></tr>
<tr><td><code id="newtonRaphson_+3A_tol">tol</code></td>
<td>
<p>absolute tolerance; default <code>eps^(1/2)</code></p>
</td></tr>
<tr><td><code id="newtonRaphson_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Well known root finding algorithms for real, univariate, continuous
functions. 
</p>


<h3>Value</h3>

<p>Return a list with components <code>root</code>, <code>f.root</code>, 
the function value at the found root, <code>iter</code>, the number of iterations
done, and <code>root</code>, and the estimated precision <code>estim.prec</code>
</p>
<p>The estimated precision is given as the difference to the last solution 
before stop; this may be misleading.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonHorner">newtonHorner</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Legendre polynomial of degree 5
lp5 &lt;- c(63, 0, -70, 0, 15, 0)/8
f &lt;- function(x) polyval(lp5, x)
newton(f, 1.0)         # 0.9061798459 correct to 10 decimals in 5 iterations
</code></pre>

<hr>
<h2 id='newtonsys'>Newton Method for Nonlinear Systems</h2><span id='topic+newtonsys'></span>

<h3>Description</h3>

<p>Newton's method applied to multivariate nonlinear functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newtonsys(Ffun, x0, Jfun = NULL, ...,
    	  maxiter = 100, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newtonsys_+3A_ffun">Ffun</code></td>
<td>
<p><code>m</code> functions of <code>n</code> variables.</p>
</td></tr>
<tr><td><code id="newtonsys_+3A_jfun">Jfun</code></td>
<td>
<p>Function returning a square <code>n</code>-by-<code>n</code> matrix
(of partial derivatives) or <code>NULL</code>, the default.</p>
</td></tr>
<tr><td><code id="newtonsys_+3A_x0">x0</code></td>
<td>
<p>Numeric vector of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="newtonsys_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="newtonsys_+3A_tol">tol</code></td>
<td>
<p>Tolerance, relative accuracy.</p>
</td></tr>
<tr><td><code id="newtonsys_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves the system of equations applying Newton's method with the univariate
derivative replaced by the Jacobian.
</p>


<h3>Value</h3>

<p>List with components: <code>zero</code> the root found so far, <code>fnorm</code> the
square root of sum of squares of the values of f, and <code>iter</code> the
number of iterations needed.
</p>


<h3>Note</h3>

<p>TODO: better error checking, e.g. when the Jacobian is not invertible.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonRaphson">newtonRaphson</a></code>, <code><a href="#topic+broyden">broyden</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example from Quarteroni &amp; Saleri
F1 &lt;- function(x) c(x[1]^2 + x[2]^2 - 1, sin(pi*x[1]/2) + x[2]^3)
newtonsys(F1, x0 = c(1, 1))  # zero: 0.4760958 -0.8793934

##  Find the roots of the complex function sin(z)^2 + sqrt(z) - log(z)
F2 &lt;- function(x) {
    z  &lt;- x[1] + x[2]*1i
    fz &lt;- sin(z)^2 + sqrt(z) - log(z)
    c(Re(fz), Im(fz))
}
newtonsys(F2, c(1, 1))
# $zero   0.2555197 0.8948303 , i.e.  z0 = 0.2555 + 0.8948i
# $fnorm  2.220446e-16
# $niter  8

##  Two more problematic examples
F3 &lt;- function(x)
        c(2*x[1] - x[2] - exp(-x[1]), -x[1] + 2*x[2] - exp(-x[2]))
newtonsys(F3, c(0, 0))
# $zero   0.5671433 0.5671433
# $fnorm  0
# $niter  4

## Not run: 
F4 &lt;- function(x)  # Dennis Schnabel
        c(x[1]^2 + x[2]^2 - 2, exp(x[1] - 1) + x[2]^3 - 2)
newtonsys(F4, c(2.0, 0.5))
# will result in an error ``missing value in  ... err&lt;tol &amp;&amp; niter&lt;maxiter''
## End(Not run)
</code></pre>

<hr>
<h2 id='nextpow2'>Next Power of 2</h2><span id='topic+nextpow2'></span>

<h3>Description</h3>

<p>Smallest power of 2 greater than the argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  nextpow2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nextpow2_+3A_x">x</code></td>
<td>
<p>numeric scalar, vector, or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the smalest integer <code>n</code> such that <code class="reqn">abs(x) \le 2^n</code>.
IF <code>x</code> is a vector or matrix, returns the result component-wise.
For negative or complex values, the absolute value will be taken.
</p>


<h3>Value</h3>

<p>an integer <code>n</code> such that <code class="reqn">x \le 2^n</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pow2">pow2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  nextpow2(10)                   #=&gt; 4
  nextpow2(1:10)                 #=&gt; 0 1 2 2 3 3 3 3 4 4
  nextpow2(-2^10)                #=&gt; 10
  nextpow2(.Machine$double.eps)  #=&gt; -52
</code></pre>

<hr>
<h2 id='nnz'>Nonzero Elements</h2><span id='topic+nnz'></span>

<h3>Description</h3>

<p>Number of non-zero elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nnz(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnz_+3A_x">x</code></td>
<td>
<p>a numeric or complex vector or matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the number of non-zero elements of <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+find">find</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nnz(diag(10))
</code></pre>

<hr>
<h2 id='Norm'>
Vector Norm
</h2><span id='topic+Norm'></span>

<h3>Description</h3>

<p>The <code>Norm</code> function calculates several different types of vector
norms for <code>x</code>, depending on the argument <code>p</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Norm(x, p = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Norm_+3A_x">x</code></td>
<td>
<p>Numeric vector; matrices not allowed.</p>
</td></tr>
<tr><td><code id="Norm_+3A_p">p</code></td>
<td>
<p>Numeric scalar or Inf, -Inf; default is 2</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Norm</code> returns a scalar that gives some measure of the magnitude
of the elements of <code>x</code>. It is called the <code class="reqn">p</code>-norm for values
<code class="reqn">-Inf \le p \le Inf</code>, defining Hilbert spaces on <code class="reqn">R^n</code>.
</p>
<p><code>Norm(x)</code> is the Euclidean length of a vecor <code>x</code>; same as
<code>Norm(x, 2)</code>.<br />
<code>Norm(x, p)</code> for finite p is defined as <code>sum(abs(A)^p)^(1/p)</code>.<br />
<code>Norm(x, Inf)</code> returns <code>max(abs(x))</code>,
while <code>Norm(x, -Inf)</code> returns <code>min(abs(x))</code>.
</p>


<h3>Value</h3>

<p>Numeric scalar (or <code>Inf</code>), or <code>NA</code> if an element of <code>x</code>
is <code>NA</code>.
</p>


<h3>Note</h3>

<p>In Matlab/Octave this is called <code>norm</code>; R's <code>norm</code> function
<code>norm(x, "F")</code> (&lsquo;Frobenius Norm&rsquo;) is the same as <code>Norm(x)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+norm">norm</a></code> of a matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Norm(c(3, 4))          #=&gt; 5  Pythagoras triple
Norm(c(1, 1, 1), p=2)  #   sqrt(3)
Norm(1:10, p = 1)      #   sum(1:10)
Norm(1:10, p = 0)      #   Inf
Norm(1:10, p = Inf)    #   max(1:10)
Norm(1:10, p = -Inf)   #   min(1:10)
</code></pre>

<hr>
<h2 id='normest'>
Estimated Matrix Norm
</h2><span id='topic+normest'></span>

<h3>Description</h3>

<p>Estimate the 2-norm of a real (or complex-valued) matrix.
2-norm is also the maximum absolute eigenvalue of M, computed here
using the power method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normest(M, maxiter = 100, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normest_+3A_m">M</code></td>
<td>
<p>Numeric matrix; vectors will be considered as column vectors.</p>
</td></tr>
<tr><td><code id="normest_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations allowed; default: 100.</p>
</td></tr>
<tr><td><code id="normest_+3A_tol">tol</code></td>
<td>
<p>Tolerance used for stopping the iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate the 2-norm of the matrix <code>M</code>, typically used for large or
sparse matrices, where the cost of calculating the <code>norm (A)</code> is
prohibitive and an approximation to the 2-norm is acceptable.
</p>
<p>Theoretically, the 2-norm of a matrix <code class="reqn">M</code> is defined as
</p>
<p><code class="reqn">||M||_2 = max \frac{||M*x||_2}{||x||_2}</code> for all <code class="reqn">x \neq 0</code>
</p>
<p>where <code class="reqn">||.||_2</code> is the Euclidean/Frobenius norm.
</p>


<h3>Value</h3>

<p>2-norm of the matrix as a positive real number.
</p>


<h3>Note</h3>

<p>If feasible, an accurate value of the 2-norm would simply be calculated
as the maximum of the singular values (which are all positive):
</p>
<p><code>max(svd(M)\$d)</code>
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Philadelphia.   
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cond">cond</a></code>, <code><a href="base.html#topic+svd">svd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>normest(magic(5)) == max(svd(magic(5))$d)  # TRUE
normest(magic(100))                        # 500050
</code></pre>

<hr>
<h2 id='nthroot'>Real nth Root</h2><span id='topic+nthroot'></span>

<h3>Description</h3>

<p>Compute the real n-th root of real numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  nthroot(x, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nthroot_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="nthroot_+3A_n">n</code></td>
<td>
<p>positive integer specifying the exponent <code class="reqn">1/n</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the n-th root real numbers of a numeric vector <code>x</code>,
while <code>x^(1/n)</code> will return <code>NaN</code> for negative numbers,
even in case <code>n</code> is odd. If some numbers in <code>x</code> are negative,
<code>n</code> must be odd. (This is different in <em>Octave</em>)
</p>


<h3>Value</h3>

<p>Returns a numeric vector of solutions to <code class="reqn">x^{1/n}</code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sqrt">sqrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  nthroot(c(1, -2, 3), 3)  #=&gt; 1.000000 -1.259921  1.442250
  (-2)^(1/3)               #=&gt; NaN
</code></pre>

<hr>
<h2 id='nullspace'>
Kernel or Nullspace
</h2><span id='topic+nullspace'></span><span id='topic+null'></span>

<h3>Description</h3>

<p>Kernel of the linear map defined by matrix <code>M</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nullspace(M)
null(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nullspace_+3A_m">M</code></td>
<td>
<p>Numeric matrix; vectors will be considered as column vectors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The kernel (aka null space/nullspace) of a matrix <code>M</code> is the set of
all vectors <code>x</code> for which <code>Ax=0</code>. It is computed from the
QR-decomposition of the matrix.
</p>
<p><code>null</code> is simply an alias for <code>nullspace</code> &ndash; and the Matlab name.
</p>


<h3>Value</h3>

<p>If <code>M</code> is an <code>n</code>-by-<code>m</code> (operating from left on
<code>m</code>-dimensional column vectors), then <code>N=nullspace(M)</code> is a
<code>m</code>-by-<code>k</code> matrix whose columns define a (linearly independent)
basis of the <code>k</code>-dimensional kernel in <code>R^m</code>.
</p>
<p>If the kernel is only the null vector <code>(0 0 ... 0)</code>, then NULL will
be returned.
</p>
<p>As the rank of a matrix is also the dimension of its image, the following
relation is true:
</p>
<p><code>m = dim(nullspace(M)) + rank(M)</code>
</p>


<h3>Note</h3>

<p>The image of <code>M</code> can be retrieved from <code>orth()</code>.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Philadelphia. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rank">Rank</a></code>, <code><a href="#topic+orth">orth</a></code>, <code>MASS::Null</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>M &lt;- matrix(1:12, 3, 4)
Rank(M)                 #=&gt; 2
N &lt;- nullspace(M)
#           [,1]       [,2]      [,3]
# [1,] 0.4082483 -0.8164966 0.4082483
M 

M1 &lt;- matrix(1:6, 2, 3)  # of rank 2
M2 &lt;- t(M1)
nullspace(M1)            # corresponds to 1 -2  1
nullspace(M2)            # NULL, i.e. 0 0

M &lt;- magic(5)
Rank(M)                 #=&gt; 5
nullspace(M)             #=&gt; NULL, i.e. 0 0 0 0 0
</code></pre>

<hr>
<h2 id='numderiv'>
Richardson's Numerical Derivative
</h2><span id='topic+numderiv'></span><span id='topic+numdiff'></span>

<h3>Description</h3>

<p>Richardson's method applied to the computation of the numerical derivative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numderiv(f, x0, maxiter = 16, h = 1/2, ..., tol = .Machine$double.eps)

numdiff(f, x, maxiter = 16, h = 1/2, ..., tol = .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numderiv_+3A_f">f</code></td>
<td>
<p>function to be differentiated.</p>
</td></tr>
<tr><td><code id="numderiv_+3A_x0">x0</code>, <code id="numderiv_+3A_x">x</code></td>
<td>
<p>point(s) at which the derivative is to be computed.</p>
</td></tr>
<tr><td><code id="numderiv_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="numderiv_+3A_h">h</code></td>
<td>
<p>starting step size, should be the default <code>h=0.5</code>.</p>
</td></tr>
<tr><td><code id="numderiv_+3A_tol">tol</code></td>
<td>
<p>relative tolerance.</p>
</td></tr>
<tr><td><code id="numderiv_+3A_...">...</code></td>
<td>
<p>variables to be passed to function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>numderiv</code> returns the derivative of <code>f</code> at <code>x0</code>, where
<code>x0</code> must be a single scalar in the domain of the function.
</p>
<p><code>numdiff</code> is a vectorized form of <code>numderiv</code> such that the
derivatives will be returned at all points of the vector <code>x</code>.
</p>


<h3>Value</h3>

<p>Numeric scalar or vector of approximated derivatives.
</p>


<h3>Note</h3>

<p>See <code>grad</code> in the &lsquo;numDeriv&rsquo; package for another implementation of
Richardson's method in the context of numerical differentiation.
</p>


<h3>References</h3>

<p>Mathews, J. H., and K. D. Fink (1999). Numerical Methods Using Matlab.
Third Edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fderiv">fderiv</a></code>, <code><a href="#topic+complexstep">complexstep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Differentiate an anti-derivative function
f &lt;- function(x) sin(x)*sqrt(1+sin(x))
F &lt;- function(x)
        integrate(f, 0, x, rel.tol = 1e-12)$value
x0 &lt;- 1
dF0 &lt;- numderiv(F, x0, tol = 6.5e-15)   #=&gt; 1.141882942715462
f(x0)                                   #   1.141882942715464 true value
# fderiv(F, x0)                         #   1.141882942704476
# numDeriv::grad(F, x0)                 #   1.141882942705797

# Compare over a whole period
x &lt;- seq(0, 2*pi, length.out = 11)
max(abs(numdiff(sin, x) - cos(x)))          #=&gt; 3.44e-15
# max(abs(numDeriv::grad(sin, x) - cos(x))) #   7.70e-12

# Example from complex step
f &lt;- function(x) exp(x) / sqrt(sin(x)^3 + cos(x)^3)
x0 &lt;- 1.5
numderiv(f, x0)                          #   4.05342789389876, error 0.5e-12
                                         #   4.053427893898621... true value
</code></pre>

<hr>
<h2 id='numel'>Number of Elements</h2><span id='topic+numel'></span>

<h3>Description</h3>

<p>Number of elements in a vector, matrix, or array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numel(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numel_+3A_x">x</code></td>
<td>
<p>a vector, matrix, array or list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the number of elements of <code>a</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+size">size</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>numel(c(1:12))
numel(matrix(1:12, 3, 4))
</code></pre>

<hr>
<h2 id='ode23'>
Non-stiff (and stiff) ODE solvers
</h2><span id='topic+ode23'></span><span id='topic+ode23s'></span><span id='topic+ode45'></span><span id='topic+ode78'></span>

<h3>Description</h3>

<p>Runge-Kutta (2, 3)-method with variable step size, resp. (4,5)-method
with Dormand-Price coefficients, or (7,8)-pairs with Fehlberg coefficients.
The function <code>f(t, y)</code> has to return the derivative as a column vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ode23(f, t0, tfinal, y0, ..., rtol = 1e-3, atol = 1e-6)

ode23s(f, t0, tfinal, y0, jac = NULL, ...,
            rtol = 1e-03, atol = 1e-06, hmax = 0.0)

ode45(f, t0, tfinal, y0, ..., atol = 1e-6, hmax = 0.0)
ode78(f, t0, tfinal, y0, ..., atol = 1e-6, hmax = 0.0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ode23_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y' = f(x, y)</code>;<br />
defined as a function <code class="reqn">R \times R^m \rightarrow R^m</code>, where
<code class="reqn">m</code> is the number of equations.</p>
</td></tr>
<tr><td><code id="ode23_+3A_t0">t0</code>, <code id="ode23_+3A_tfinal">tfinal</code></td>
<td>
<p>start and end points of the interval.</p>
</td></tr>
<tr><td><code id="ode23_+3A_y0">y0</code></td>
<td>
<p>starting values as column vector;
for <code class="reqn">m</code> equations <code>u0</code> needs to be a vector of length <code>m</code>.</p>
</td></tr>
<tr><td><code id="ode23_+3A_jac">jac</code></td>
<td>
<p>jacobian of <code>f</code> as a function of <code>x</code> alone;
if not specified, a finite difference approximation will be used.</p>
</td></tr>
<tr><td><code id="ode23_+3A_rtol">rtol</code>, <code id="ode23_+3A_atol">atol</code></td>
<td>
<p>relative and absolute tolerance.</p>
</td></tr>
<tr><td><code id="ode23_+3A_hmax">hmax</code></td>
<td>
<p>maximal step size, default is <code>(tfinal - t0)/10.</code></p>
</td></tr>
<tr><td><code id="ode23_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ode23</code> is an integration method for systems of ordinary differential
equations using second and third order Runge-Kutta-Fehlberg formulas with
automatic step-size.
</p>
<p><code>ode23s</code> can be used to solve a stiff system of ordinary differential
equations, based on a modified Rosenbrock triple method of order (2,3);
See section 4.1 in [Shampine and Reichelt].
</p>
<p><code>ode45</code> implements Dormand-Prince (4,5) pair that minimizes the local
truncation error in the 5th-order estimate which is what is used to step
forward (local extrapolation). Generally it produces more accurate results
and costs roughly the same computationally.
</p>
<p><code>ode78</code> implements Fehlberg's (7,8) pair and is a 7th-order accurate
integrator therefore the local error normally expected is O(h^8).  However,
because this particular implementation uses the 8th-order estimate for xout
(i.e. local extrapolation) moving forward with the 8th-order estimate will
yield errors on the order of O(h^9). It requires 13 function evaluations per
integration step.
</p>


<h3>Value</h3>

<p>List with components <code>t</code> for grid (or &lsquo;time&rsquo;) points between <code>t0</code>
and <code>tfinal</code>, and <code>y</code> an n-by-m matrix with solution variables in
columns, i.e. each row contains one time stamp.
</p>


<h3>Note</h3>

<p>Copyright (c) 2004 C. Moler for the Matlab textbook version <code>ode23tx</code>.
</p>


<h3>References</h3>

<p>Ascher, U. M., and L. R. Petzold (1998). Computer Methods for Ordinary
Differential Equations and Differential-Algebraic Equations. SIAM.
</p>
<p>L.F. Shampine and M.W. Reichelt (1997). The MATLAB ODE Suite.
SIAM Journal on Scientific Computing, Vol. 18, pp. 1-22.
</p>
<p>Moler, C. (2004). Numerical Computing with Matlab. Revised Reprint, SIAM.
<a href="https://www.mathworks.com/moler/chapters.html">https://www.mathworks.com/moler/chapters.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rk4sys">rk4sys</a></code>, <code><a href="#topic+deval">deval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example1: Three-body problem
f &lt;- function(t, y)
		as.matrix(c(y[2]*y[3], -y[1]*y[3], 0.51*y[1]*y[2]))
y0 &lt;- as.matrix(c(0, 1, 1))
t0 &lt;- 0; tf &lt;- 20
sol &lt;- ode23(f, t0, tf, y0, rtol=1e-5, atol=1e-10)
## Not run: 
matplot(sol$t, sol$y, type = "l", lty = 1, lwd = c(2, 1, 1),
        col = c("darkred", "darkblue", "darkgreen"),
        xlab = "Time [min]", ylab= "",
        main = "Three-body Problem")
grid()
## End(Not run)

##  Example2: Van der Pol Equation
#   x'' + (x^2 - 1) x' + x = 0
f &lt;- function(t, x)
        as.matrix(c(x[1] * (1 - x[2]^2) -x[2], x[1]))
t0 &lt;- 0; tf &lt;- 20
x0 &lt;- as.matrix(c(0, 0.25))
sol &lt;- ode23(f, t0, tf, x0)
## Not run: 
plot(c(0, 20), c(-3, 3), type = "n",
     xlab = "Time", ylab = "", main = "Van der Pol Equation")
lines(sol$t, sol$y[, 1], col = "blue")
lines(sol$t, sol$y[, 2], col = "darkgreen")
grid()
## End(Not run)

##  Example3: Van der Pol as stiff equation
vdP  &lt;- function(t,y) as.matrix(c(y[2], 10*(1-y[1]^2)*y[2]-y[1]))
ajax &lt;- function(t, y)
            matrix(c(0, 1, -20*y[1]*y[2]-1, 10*(1-y[1]^2)), 2,2, byrow = TRUE)
sol &lt;- ode23s(vdP, t0, tf, c(2, 0), jac = ajax, hmax = 1.0)
## Not run: 
plot(sol$t, sol$y[, 1], col = "blue")
lines(sol$t, sol$y[, 1], col = "blue")
lines(sol$t, sol$y[, 2]/8, col = "red", lwd = 2)
grid()
## End(Not run)

##  Example4: pendulum
m = 1.0;  l = 1.0   # [kg] resp. [m]
g = 9.81; b = 0.7   # [m/s^2] resp. [N s/m]
fp = function(t, x)
        c( x[2] , 1/(1/3*m*l^2)*(-b*x[2]-m*g*l/2*sin(x[1])) )
t0 &lt;- 0.0; tf &lt;- 5.0; hmax = 0.1
y0 = c(30*pi/180, 0.0)
sol = ode45(fp, t0, tf, y0, hmax = 0.1)
## Not run: 
matplot(sol$t, sol$y, type = "l", lty = 1)
grid()
## End(Not run)

##  Example: enforced pendulum
g &lt;- 9.81
L &lt;- 1.0; Y &lt;- 0.25; w &lt;- 2.5
f &lt;- function(t, y) {
    as.matrix(c(y[2], -g/L * sin(y[1]) + w^2/L * Y * cos(y[1]) * sin(w*t)))
}
y0 &lt;- as.matrix(c(0, 0))
sol &lt;- ode78(f, 0.0, 60.0, y0, hmax = 0.05)
## Not run: 
plot(sol$t, sol$y[, 1], type="l", col="blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='odregress'>
Orthogonal Distance Regression
</h2><span id='topic+odregress'></span>

<h3>Description</h3>

<p>Orthogonal Distance Regression (ODR, a.k.a. total least squares) 
is a regression technique in which observational errors on both dependent 
and independent variables are taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>odregress(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="odregress_+3A_x">x</code></td>
<td>
<p>matrix of independent variables.</p>
</td></tr>
<tr><td><code id="odregress_+3A_y">y</code></td>
<td>
<p>vector representing dependent variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation used here is applying PCA resp. the singular value 
decomposition on the matrix of independent and dependent variables.
</p>


<h3>Value</h3>

<p>Returns list with components <code>coeff</code> linear coefficients and intercept 
term, <code>ssq</code> sum of squares of orthogonal distances to the linear line 
or hyperplane, <code>err</code> the orthogonal distances, <code>fitted</code> the 
fitted values,  <code>resid</code> the residuals, and <code>normal</code> the normal 
vector to the hyperplane.
</p>


<h3>Note</h3>

<p>The &ldquo;geometric mean&quot; regression not implemented because questionable.
</p>


<h3>References</h3>

<p>Golub, G.H., and C.F. Van Loan (1980). An analysis of the total least 
squares problem.<br />
Numerical Analysis, Vol. 17, pp. 883-893.
</p>
<p>See ODRPACK or ODRPACK95 (TOMS Algorithm 676).<br />
URL: https://docs.scipy.org/doc/external/odr_ams.pdf
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example in one dimension
x &lt;- c(1.0, 0.6, 1.2, 1.4, 0.2)
y &lt;- c(0.5, 0.3, 0.7, 1.0, 0.2)
odr &lt;- odregress(x, y)
( cc &lt;- odr$coeff )
# [1]  0.65145762 -0.03328271
lm(y ~ x)
# Coefficients:
# (Intercept)            x 
#    -0.01379      0.62931 

# Prediction
xnew &lt;- seq(0, 1.5, by = 0.25)
( ynew &lt;- cbind(xnew, 1) %*% cc )

## Not run: 
plot(x, y, xlim=c(0, 1.5), ylim=c(0, 1.2), main="Orthogonal Regression")
abline(lm(y ~ x), col="blue")
lines(c(0, 1.5), cc[1]*c(0, 1.5) + cc[2], col="red")
points(xnew, ynew, col = "red")
grid()
## End(Not run)

# Example in two dimensions
x &lt;- cbind(c(0.92, 0.89, 0.85, 0.05, 0.62, 0.55, 0.02, 0.73, 0.77, 0.57),
           c(0.66, 0.47, 0.40, 0.23, 0.17, 0.09, 0.92, 0.06, 0.09, 0.60))
y &lt;- x %*% c(0.5, 1.5) + 1
odr &lt;- odregress(x, y); odr
# $coeff
# [1] 0.5 1.5 1.0
# $ssq
# [1] 1.473336e-31

y &lt;- y + rep(c(0.1, -0.1), 5)
odr &lt;- odregress(x, y); odr
# $coeff
# [1] 0.5921823 1.6750269 0.8803822
# $ssq
# [1] 0.02168174

lm(y ~ x)
# Coefficients:
# (Intercept)           x1           x2  
#      0.9153       0.5671       1.6209  
</code></pre>

<hr>
<h2 id='orth'>
Range Space
</h2><span id='topic+orth'></span>

<h3>Description</h3>

<p>Range space or image of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orth(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orth_+3A_m">M</code></td>
<td>
<p>Numeric matrix; vectors will be considered as column vectors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>B=orth(A)</code> returns an orthonormal basis for the range of <code>A</code>.
The columns of <code>B</code> span the same space as the columns of <code>A</code>,
and the columns of <code>B</code> are orthogonal to each other.
</p>
<p>The number of columns of <code>B</code> is the rank of <code>A</code>.
</p>


<h3>Value</h3>

<p>Matrix of orthogonal columns, spanning the image of <code>M</code>.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Philadelphia. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nullspace">nullspace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>M &lt;- matrix(1:12, 3, 4)
Rank(M)                 #=&gt; 2
orth(M)
</code></pre>

<hr>
<h2 id='pade'>
Pade Approximation
</h2><span id='topic+pade'></span>

<h3>Description</h3>

<p>A Pade approximation is a rational function (of a specified order) whose
power series expansion agrees with a given function and its derivatives
to the highest possible order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pade(p1, p2 = c(1), d1 = 5, d2 = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pade_+3A_p1">p1</code></td>
<td>
<p>polynomial representing or approximating the function,
preferably the Taylor series of the function around some point.</p>
</td></tr>
<tr><td><code id="pade_+3A_p2">p2</code></td>
<td>
<p>if present, the function is given as <code>p1/p2</code>.</p>
</td></tr>
<tr><td><code id="pade_+3A_d1">d1</code></td>
<td>
<p>the degree of the numerator of the rational function.</p>
</td></tr>
<tr><td><code id="pade_+3A_d2">d2</code></td>
<td>
<p>the degree of the denominator of the rational function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relationship between the coefficients of <code>p1</code> (and <code>p2</code>)
and <code>r1</code> and <code>r2</code> is determined by a system of linear equations.
The system is then solved by applying the pseudo-inverse <code>pinv</code> for
for the left-hand matrix.
</p>


<h3>Value</h3>

<p>List with components <code>r1</code> and <code>r2</code> for the numerator and 
denominator polynomials, i.e. <code>r1/r2</code> is the rational approximation
sought.
</p>


<h3>Note</h3>

<p>In general, errors for Pade approximations are smallest when the degrees
of numerator and denominator are the same or when the degree of the
numerator is one larger than that of the denominator.
</p>


<h3>References</h3>

<p>Press, W. H., S. A. Teukolsky, W. T Vetterling, and B. P. Flannery (2007).
Numerical Recipes: The Art of Numerical Computing. Third Edition,
Cambridge University Press, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+taylor">taylor</a></code>, <code>ratInterp</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Exponential function
p1 &lt;- c(1/24, 1/6, 1/2, 1.0, 1.0)  # Taylor series of exp(x) at x=0
R  &lt;- pade(p1); r1 &lt;- R$r1; r2 &lt;- R$r2
f1 &lt;- function(x) polyval(r1, x) / polyval(r2, x)
## Not run: 
xs &lt;- seq(-1, 1, length.out=51); ys1 &lt;- exp(xs); ys2 &lt;- f1(xs)
plot(xs, ys1, type = "l", col="blue")
lines(xs, ys2, col = "red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='pascal'>
Pascal Triangle
</h2><span id='topic+pascal'></span>

<h3>Description</h3>

<p>Pascal triangle in matrix format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pascal(n, k = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pascal_+3A_n">n</code></td>
<td>
<p>natural number</p>
</td></tr>
<tr><td><code id="pascal_+3A_k">k</code></td>
<td>
<p>natural number, <code>k &lt;= n</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pascal triangle with <code>k</code> variations.
</p>


<h3>Value</h3>

<p>matrix representing the Pascal triangle
</p>


<h3>See Also</h3>

<p><code>nchoosek</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pascal(5)
pascal(5, 1)
pascal(5, 2)
</code></pre>

<hr>
<h2 id='pchip'>Hermitean Interpolation Polynomials</h2><span id='topic+pchip'></span><span id='topic+pchipfun'></span>

<h3>Description</h3>

<p>Piecewise Cubic Hermitean Interpolation Polynomials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pchip(xi, yi, x)

pchipfun(xi, yi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pchip_+3A_xi">xi</code>, <code id="pchip_+3A_yi">yi</code></td>
<td>
<p>x- and y-coordinates of supporting nodes.</p>
</td></tr>
<tr><td><code id="pchip_+3A_x">x</code></td>
<td>
<p>x-coordinates of interpolation points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pchip</code> is a &lsquo;shape-preserving&rsquo; piecewise cubic Hermite polynomial
approach that apptempts to determine slopes such that function values do
not overshoot data values.
<code>pchipfun</code> is a wrapper around <code>pchip</code> and returns a function.
Both <code>pchip</code> and the function returned by <code>pchipfun</code> are vectorized.
</p>
<p><code>xi</code> and <code>yi</code> must be vectors of the same length greater or equal 3
(for cubic interpolation to be possible), and <code>xi</code> must be sorted.
<code>pchip</code> can be applied to points outside <code>[min(xi), max(xi)]</code>, but
the result does not make much sense outside this interval.
</p>


<h3>Value</h3>

<p>Values of interpolated data at points <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Copyright of the Matlab version from Cleve Moler in his book &ldquo;Numerical
Computing with Matlab&rdquo;, Chapter 3 on Interpolation.
R Version by Hans W. Borchers, 2011.
</p>


<h3>References</h3>

<p>Moler, C. (2004). Numerical Computing with Matlab. Revised Reprint, SIAM.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+interp1">interp1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1, 2, 3, 4, 5, 6)
y &lt;- c(16, 18, 21, 17, 15, 12)
pchip(x, y, seq(1, 6, by = 0.5))
fp &lt;- pchipfun(x, y)
fp(seq(1, 6, by = 0.5))

## Not run: 
plot(x, y, col="red", xlim=c(0,7), ylim=c(10,22),
     main = "Spline and 'pchip' Interpolation")
grid()

xs &lt;- seq(1, 6, len=51)
ys &lt;- interp1(x, y, xs, "spline")
lines(xs, ys, col="cyan")
yp &lt;- pchip(x, y, xs)
lines(xs, yp, col = "magenta")
## End(Not run)
</code></pre>

<hr>
<h2 id='peaks'>
Peaks Function (Matlab Style)
</h2><span id='topic+peaks'></span>

<h3>Description</h3>

<p>An example functions in two variables, with peaks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>peaks(v = 49, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="peaks_+3A_v">v</code></td>
<td>
<p>vector, whose length will be used, or a natural number.</p>
</td></tr>
<tr><td><code id="peaks_+3A_w">w</code></td>
<td>
<p>another vector, will be used in <code>meshgrid(x,y)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>peaks</code> is a function of two variables, obtained by translating
and scaling Gaussian distributions, which is useful for demonstrating
three-dimensional plots.
</p>


<h3>Value</h3>

<p>Returns three matrices as a list with <code>X</code>, <code>Y</code>, and <code>Z</code>
components, the first two being the result of the <code>meshgrid</code> function,
and <code>Z</code> the application of the following function at the points of
<code>X</code> and <code>Y</code>:
</p>
<p><code>z &lt;-  3 * (1-x)^2 * exp(-(x^2) - (y+1)^2) -
             10 * (x/5 - x^3 - y^5) * exp(-x^2 - y^2) -
            1/3 * exp(-(x+1)^2 - y^2)</code>
</p>


<h3>Note</h3>

<p>The variant that <code>peaks()</code> will display the 3-dim. graph as in Matlab
is not yet implemented.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meshgrid">meshgrid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>peaks(3)
## Not run: 
P &lt;- peaks()
x &lt;- P$X[1,]; y &lt;- P$Y[, 1]
persp(x, y, P$Z)

## End(Not run)
</code></pre>

<hr>
<h2 id='perms'>
Generate Permutations
</h2><span id='topic+perms'></span>

<h3>Description</h3>

<p>Generates all permutations of a vector <code>a</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perms(a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perms_+3A_a">a</code></td>
<td>
<p>numeric vector of some length <code>n</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>a</code> is a vector of length <code>n</code>, generate all permutations
of the elements in <code>a</code> as a matrix of size <code>n! x n</code> where
each row represents one permutation.
</p>
<p>A matrix will be expanded as vector.
</p>


<h3>Value</h3>

<p>matrix of permutations of the elements of <code>a</code>
</p>


<h3>Note</h3>

<p>Not feasible for <code>length(a) &gt; 10</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+randperm">randperm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>perms(6)
perms(1:6)
perms(c(1, exp(1), pi))
</code></pre>

<hr>
<h2 id='piecewise'>
Piecewise Linear Function
</h2><span id='topic+piecewise'></span>

<h3>Description</h3>

<p>Compute zeros and area of a piecewise linear function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>piecewise(x, y, abs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="piecewise_+3A_x">x</code>, <code id="piecewise_+3A_y">y</code></td>
<td>
<p>x- and y-coordinates of points defining the piecewise linear function</p>
</td></tr>
<tr><td><code id="piecewise_+3A_abs">abs</code></td>
<td>
<p>logical; shall the integral or the total area between the
x-axis and the function be calculated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute zeros and integral resp. area of a piecewise linear function
given by points with x and y as coordinates.
</p>


<h3>Value</h3>

<p>Returns a list with the integral or area as first element and the vector
as all zeroes as second.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trapz">trapz</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0,  2, 3,  4, 5)
y &lt;- c(2, -2, 0, -2, 0)
piecewise(x, y)
piecewise(x, y, abs=TRUE)
</code></pre>

<hr>
<h2 id='pinv'>
Pseudoinverse or Generalized Inverse
</h2><span id='topic+pinv'></span>

<h3>Description</h3>

<p>Computes the Moore-Penrose generalized inverse of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pinv(A, tol=.Machine$double.eps^(2/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pinv_+3A_a">A</code></td>
<td>
<p>real or complex matrix</p>
</td></tr>
<tr><td><code id="pinv_+3A_tol">tol</code></td>
<td>
<p>tolerance used for assuming an eigenvalue is zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the generalized inverse <code>B</code> of a matrix <code>A</code> using the
singular value decomposition <code>svd()</code>. This generalized invers is
characterized by this equation: <code>A %*% B %*% A == A</code>
</p>
<p>The pseudoinverse <code class="reqn">B</code> solves the problem to minimize
<code class="reqn">|A x - b|</code> by setting <code class="reqn">x = B b</code>
</p>
<p><code>s &lt;- svd(A)</code><br />
<code>D &lt;- diag(s\$d)</code><br />
<code>Dinv &lt;- diag(1/s\$d)</code><br />
<code>U &lt;- s\$u; V &lt;- s\$v</code><br />
<code>X = V Dinv t(U)</code>
</p>
<p>Thus <code>B</code> is computed as <code>s$v %*% diag(1/s$d) %*% t(s$u)</code>.
</p>


<h3>Value</h3>

<p>The pseudoinverse of matrix <code>A</code>.
</p>


<h3>Note</h3>

<p>The pseudoinverse or &lsquo;generalized inverse&rsquo; is also provided by the function
<code>ginv()</code> in package &lsquo;MASS&rsquo;. It is included in a somewhat simplified
way to be independent of that package.
</p>


<h3>References</h3>

<p>Ben-Israel, A., and Th. N. E. Greville (2003). Generalized Inverses - 
Theory and Applications. Springer-Verlag, New York.
</p>


<h3>See Also</h3>

<p><code>MASS::ginv</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(7,6,4,8,10,11,12,9,3,5,1,2), 3, 4)
b &lt;- apply(A, 1, sum)  # 32 16 20  row sum
x &lt;- pinv(A) %*% b
A %*% x              #=&gt; 32 16 20  as column vector
</code></pre>

<hr>
<h2 id='plotyy'>
Plotting Two y-Axes
</h2><span id='topic+plotyy'></span>

<h3>Description</h3>

<p>Line plot with y-axes on both left and right side.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotyy(x1, y1, x2, y2, gridp = TRUE, box.col = "grey",
                       type = "l", lwd = 1, lty = 1,
                       xlab = "x", ylab = "y", main = "",
                       col.y1 = "navy", col.y2 = "maroon", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotyy_+3A_x1">x1</code>, <code id="plotyy_+3A_x2">x2</code></td>
<td>
<p>x-coordinates for the curves</p>
</td></tr>
<tr><td><code id="plotyy_+3A_y1">y1</code>, <code id="plotyy_+3A_y2">y2</code></td>
<td>
<p>the y-values, with ordinates y1 left, y2 right.</p>
</td></tr>
<tr><td><code id="plotyy_+3A_gridp">gridp</code></td>
<td>
<p>logical; shall a grid be plotted.</p>
</td></tr>
<tr><td><code id="plotyy_+3A_box.col">box.col</code></td>
<td>
<p>color of surrounding box.</p>
</td></tr>
<tr><td><code id="plotyy_+3A_type">type</code></td>
<td>
<p>type of the curves, line or points (for both data).</p>
</td></tr>
<tr><td><code id="plotyy_+3A_lwd">lwd</code></td>
<td>
<p>line width (for both data).</p>
</td></tr>
<tr><td><code id="plotyy_+3A_lty">lty</code></td>
<td>
<p>line type (for both data).</p>
</td></tr>
<tr><td><code id="plotyy_+3A_xlab">xlab</code>, <code id="plotyy_+3A_ylab">ylab</code></td>
<td>
<p>text below and on the left.</p>
</td></tr>
<tr><td><code id="plotyy_+3A_main">main</code></td>
<td>
<p>main title of the plot.</p>
</td></tr>
<tr><td><code id="plotyy_+3A_col.y1">col.y1</code>, <code id="plotyy_+3A_col.y2">col.y2</code></td>
<td>
<p>colors to be used for the lines or points.</p>
</td></tr>
<tr><td><code id="plotyy_+3A_...">...</code></td>
<td>
<p>additional plotting parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots <code>y1</code> versus <code>x1</code> with y-axis labeling on the left and plots
<code>y2</code> versus <code>x2</code> with y-axis labeling on the right.
</p>
<p>The x-values should not be too far appart. To exclude certain points, use
<code>NA</code> values. Both curves will be line or point plots, and have the
same line type and width.
</p>


<h3>Value</h3>

<p>Generates a graph, no return values.
</p>


<h3>See Also</h3>

<p><code>plotrix::twoord.plot</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x  &lt;- seq(0, 20, by = 0.01)
y1 &lt;- 200*exp(-0.05*x)*sin(x)
y2 &lt;- 0.8*exp(-0.5*x)*sin(10*x)

plotyy(x, y1, x, y2, main = "Two-ordinates Plot")

## End(Not run)
</code></pre>

<hr>
<h2 id='poisson2disk'>
Poisson Disk Sampling
</h2><span id='topic+poisson2disk'></span>

<h3>Description</h3>

<p>Approximate Poisson disk distribution of points in a rectangle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisson2disk(n, a = 1, b = 1, m = 10, info = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poisson2disk_+3A_n">n</code></td>
<td>
<p>number of points to generate in a rectangle.</p>
</td></tr>
<tr><td><code id="poisson2disk_+3A_a">a</code>, <code id="poisson2disk_+3A_b">b</code></td>
<td>
<p>width and height of the rectangle</p>
</td></tr>
<tr><td><code id="poisson2disk_+3A_m">m</code></td>
<td>
<p>number of points to try in each step.</p>
</td></tr>
<tr><td><code id="poisson2disk_+3A_info">info</code></td>
<td>
<p>shall additional info be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Realizes Mitchell's best-candidate algorithm for creating a Poisson disk
distribution on a rectangle. Can be used for sampling, and will be more 
appropriate in some sampling applications than uniform sampling or 
grid-like sampling.
</p>
<p>With m = 1 uniform sampling will be generated.
</p>


<h3>Value</h3>

<p>Returns the points as a matrix with two columns for x- and
y-coordinates. Prints the minimal distance between points generated.
</p>


<h3>Note</h3>

<p>Bridson's algorithm for Poisson disk sampling may be added later as an
alternative. Also a variant that generates points in a circle.
</p>


<h3>References</h3>

<p>A. Lagae and Ph. Dutre. A Comparison of Methods for Generating Poisson
Disk Distributions. Computer Graphics Forum, Vol. 27(1), pp. 114-129,
2008. URL: citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.192.5862
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1111)
P &lt;- poisson2disk(n = 20, m = 10)
head(P)
##            [,1]       [,2]
## [1,] 0.46550264 0.41292487
## [2,] 0.13710541 0.98737065
## [3,] 0.96028255 0.83222920
## [4,] 0.06044078 0.09325431
## [5,] 0.78579426 0.09267546
## [6,] 0.49670274 0.99852771

# Plotting points
# plot(P, pch = 'x', col = "blue")
</code></pre>

<hr>
<h2 id='polar'>
Polar Coordinate Plot (Matlab Style)
</h2><span id='topic+polar'></span>

<h3>Description</h3>

<p>The polar function accepts polar coordinates, plots them in a Cartesian
plane, and draws the polar grid on the plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polar(t, r, type="l", 
      col = "blue", grcol = "darkgrey", bxcol = "black",
      main = "Polar Plot", add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polar_+3A_t">t</code>, <code id="polar_+3A_r">r</code></td>
<td>
<p>vectors specifying angle and radius.</p>
</td></tr>
<tr><td><code id="polar_+3A_type">type</code></td>
<td>
<p>type of the plot, lines, points, or no plotting.</p>
</td></tr>
<tr><td><code id="polar_+3A_col">col</code></td>
<td>
<p>color of the graph.</p>
</td></tr>
<tr><td><code id="polar_+3A_grcol">grcol</code>, <code id="polar_+3A_bxcol">bxcol</code></td>
<td>
<p>color of grid anf box around the plot.</p>
</td></tr>
<tr><td><code id="polar_+3A_main">main</code></td>
<td>
<p>plot title.</p>
</td></tr>
<tr><td><code id="polar_+3A_add">add</code></td>
<td>
<p>logical; if true, the graph will be plotted into the
coordinate system of an existing plot.</p>
</td></tr>
<tr><td><code id="polar_+3A_...">...</code></td>
<td>
<p>plotting parameters to be passed to the <code>points</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>polar(theta,rho)</code> creates a polar coordinate plot of the angle
<code>theta</code> versus the radius <code>rho</code>. <code>theta</code> is the angle
from the x-axis to the radius vector specified in radians; <code>rho</code>
is the length of the radius vector.
</p>


<h3>Value</h3>

<p>Generates a plot; no returns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
t &lt;- deg2rad(seq(0, 360, by = 2))
polar(t, cos(2*t), bxcol = "white", main = "Sine and Cosine")
polar(t, sin(2*t), col = "red", add = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='Poly'>Define Polynomial by Roots</h2><span id='topic+Poly'></span>

<h3>Description</h3>

<p>Define a polynomial by its roots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Poly(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Poly_+3A_x">x</code></td>
<td>
<p>vector or square matrix, real or complex</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the characteristic polynomial of an (n x n)-Matrix.
</p>
<p>If <code>x</code> is a vector, <code>Poly(x)</code> is the vector of coefficients
of the polynomial whose roots are the elements of <code>x</code>.
</p>


<h3>Value</h3>

<p>Vector representing a polynomial.
</p>


<h3>Note</h3>

<p>In Matlab/Octave this function is called <code>poly()</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyval">polyval</a></code>, <code><a href="#topic+roots">roots</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  Poly(c(1, -1, 1i, -1i))  # Solves x^4 -1 = 0
  # Wilkinson's example:
  roots(Poly(1:20))
</code></pre>

<hr>
<h2 id='poly2str'>
Print Polynomial
</h2><span id='topic+poly2str'></span>

<h3>Description</h3>

<p>Print polynomial as a character string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poly2str(p, svar = "x", smul = "*", d = options("digits")$digits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poly2str_+3A_p">p</code></td>
<td>
<p>numeric vector representing a polynomial</p>
</td></tr>
<tr><td><code id="poly2str_+3A_svar">svar</code></td>
<td>
<p>character representing the unknown, default <code>x</code>.</p>
</td></tr>
<tr><td><code id="poly2str_+3A_smul">smul</code></td>
<td>
<p>multiplication symbol, default <code>*</code>.</p>
</td></tr>
<tr><td><code id="poly2str_+3A_d">d</code></td>
<td>
<p>significant digits, default <code>options("digits")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simple string manipulation.
</p>


<h3>Value</h3>

<p>Returns the usual string representing a polynomial in mathematics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>poly2str(c(0))
poly2str(c(1, -1, 1, -1, 1))
poly2str(c(0, 1e-6, 1e6), d = 2)
</code></pre>

<hr>
<h2 id='polyadd'>Adding Polynomials</h2><span id='topic+polyadd'></span>

<h3>Description</h3>

<p>Add two polynomials given as vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  polyadd(p, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyadd_+3A_p">p</code>, <code id="polyadd_+3A_q">q</code></td>
<td>
<p>Vectors representing two polynomials.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Polynomial addition realized simply by multiplying and summing up
all the coefficients after extending vectors to the same length.
</p>


<h3>Value</h3>

<p>Vector representing a polynomial.
</p>


<h3>Note</h3>

<p>There is no such function in Matlab or Octave.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+conv">conv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>polyadd(c(1, 1, 1), 1)
polyadd(c(1, 1, 1), c(0, 0, 1))
polyadd(c(-0.5, 1, -1), c(0.5, 0, 1))
</code></pre>

<hr>
<h2 id='polyApprox'>
Polynomial Approximation
</h2><span id='topic+polyApprox'></span>

<h3>Description</h3>

<p>Generate a polynomial approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polyApprox(f, a, b, n, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyApprox_+3A_f">f</code></td>
<td>
<p>function to be approximated.</p>
</td></tr>
<tr><td><code id="polyApprox_+3A_a">a</code>, <code id="polyApprox_+3A_b">b</code></td>
<td>
<p>end points of the interval.</p>
</td></tr>
<tr><td><code id="polyApprox_+3A_n">n</code></td>
<td>
<p>degree of the polynomial.</p>
</td></tr>
<tr><td><code id="polyApprox_+3A_...">...</code></td>
<td>
<p>further variables for function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the Chebyshev coefficients to derive polynomial coefficients.
</p>


<h3>Value</h3>

<p>List with four components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>the approximating polynomial.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>a function evaluating this polynomial.</p>
</td></tr>
<tr><td><code>cheb.coeff</code></td>
<td>
<p>the Chebyshev coefficients.</p>
</td></tr> 
<tr><td><code>estim.prec</code></td>
<td>
<p>the estimated precision over the given interval.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Chebyshev approximation is optimal in the sense of the <code class="reqn">L^1</code> norm,
but not as a solution of the <em>minimax</em> problem; for this, an
application of the Remez algorithm is needed.
</p>


<h3>References</h3>

<p>Carothers, N. L. (1998). A Short Course on Approximation Theory.
Bowling Green State University.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chebApprox">chebApprox</a></code>, <code><a href="#topic+polyfit">polyfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example
#   Polynomial approximation for sin
polyApprox(sin, -pi, pi, 9)
# $p
#  [1]  2.197296e-06  0.000000e+00 -1.937495e-04  0.000000e+00  8.317144e-03
#  [6]  0.000000e+00 -1.666468e-01  0.000000e+00  9.999961e-01  0.000000e+00
#
# $f
# function (x) 
# polyval(p, x)
#
# $cheb.coeff
#  [1]  0.06549943  0.00000000 -0.58518036  0.00000000  2.54520983  0.00000000
#  [7] -5.16709776  0.00000000  3.14158037  0.00000000
#
# $estim.prec
# [1] 1.151207e-05

## Not run: 
f &lt;- polyApprox(sin, -pi, pi, 9)$f
x &lt;- seq(-pi, pi, length.out = 100)
y &lt;- sin(x) - f(x)
plot(x, y, type = "l", col = "blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='polyarea'>Area of a Polygon</h2><span id='topic+polyarea'></span><span id='topic+poly_center'></span><span id='topic+poly_length'></span><span id='topic+poly_crossings'></span>

<h3>Description</h3>

<p>Calculates the area and length of a polygon given by the vertices in the 
vectors <code>x</code> and <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  polyarea(x, y)

  poly_length(x, y)
  poly_center(x, y)

  poly_crossings(L1, L2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyarea_+3A_x">x</code></td>
<td>
<p>x-coordinates of the vertices defining the polygon</p>
</td></tr>
<tr><td><code id="polyarea_+3A_y">y</code></td>
<td>
<p>y-coordinates of the vertices</p>
</td></tr>
<tr><td><code id="polyarea_+3A_l1">L1</code>, <code id="polyarea_+3A_l2">L2</code></td>
<td>
<p>matrices of type <code>2xn</code> with x- and y-coordinates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>polyarea</code> calculates the area of a polygon defined by the vertices
with coordinates <code>x</code> and <code>y</code>. Areas to the left of the vertices
are positive, those to the right are counted negative.
</p>
<p>The computation is based on the Gauss polygon area formula. The polygon
automatically be closed, that is the last point need not be / should not
be the same as the first.
</p>
<p>If some points of self-intersection of the polygon line are not in the
vertex set, the calculation will be inexact. The sum of all areas will be
returned, parts that are circulated in the mathematically negative sense
will be counted as negative in this sum.
</p>
<p>If <code>x</code>, <code>y</code> are matrices of the same size, the areas of all
polygons defined by corresponding columns are computed.
</p>
<p><code>poly_center</code> calculates the center (of mass) of the figure defined by
the polygon. Self-intersections should be avoided in this case.
The mathematical orientation of the polygon does not have influence on the
center coordinates.
</p>
<p><code>poly_length</code> calculates the length of the polygon
</p>
<p><code>poly_crossings</code> calculates the crossing points of two polygons given
as matrices with x- and y-coordinates in the first and second row. Can be 
used for finding the crossing points of parametrizised curves.
</p>


<h3>Value</h3>

<p>Area or length of the polygon resp. sum of the enclosed areas; or the
coordinates of the center of gravity.
</p>
<p><code>poly_crossings</code> returns a matrix with column names <code>x</code> and
<code>y</code> representing the crossing points.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trapz">trapz</a></code>, <code><a href="#topic+arclength">arclength</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Zu Chongzhi's calculation of pi (China, about 480 A.D.),
  # approximating the circle from inside by a regular 12288-polygon(!):
  phi &lt;- seq(0, 2*pi, len=3*2^12+1)
  x &lt;- cos(phi)
  y &lt;- sin(phi)
  pi_approx &lt;- polyarea(x, y)
  print(pi_approx, digits=8)    #=&gt; 3.1415925 or 355/113

  poly_length(x, y)              #=&gt; 6.2831852 where 2*pi is 6.2831853

  x1 &lt;- x + 0.5; y1 &lt;- y + 0.5
  x2 &lt;- rev(x1); y2 &lt;- rev(y1)
  poly_center(x1, y1)            #=&gt; 0.5 0.5
  poly_center(x2, y2)            #=&gt; 0.5 0.5

  # A simple example
  L1 &lt;- matrix(c(0, 0.5, 1, 1,   2,
                0, 1,   1, 0.5, 0), nrow = 2, byrow = TRUE)
  L2 &lt;- matrix(c(0.5, 0.75, 1.25, 1.25,
                0,   0.75, 0.75, 0   ), nrow = 2, byrow = TRUE)
  P &lt;- poly_crossings(L1, L2)
  P
  ##         x     y
  ## [1,] 1.00 0.750
  ## [2,] 1.25 0.375

## Not run: 
  # Crossings of Logarithmic and Archimedian spirals
  # Logarithmic spiral
  a &lt;- 1; b &lt;- 0.1
  t &lt;- seq(0, 5*pi, length.out = 200)
  xl &lt;- a*exp(b*t)*cos(t) - 1
  yl &lt;- a*exp(b*t)*sin(t)
  plot(xl, yl, type = "l", lwd = 2, col = "blue",
       xlim = c(-6, 3), ylim = c(-3, 4), xlab = "", ylab = "",
       main = "Intersecting Logarithmic and Archimedian spirals")
  grid()

  # Archimedian spiral
  a &lt;- 0; b &lt;- 0.25
  r &lt;- a + b*t
  xa &lt;- r * cos(t)
  ya &lt;- r*sin(t)
  lines(xa, ya, type = "l", lwd = 2, col = "red")
  legend(-6.2, -1.0, c("Logarithmic", "Archimedian"),
         lwd = 2, col = c("blue", "red"), bg = "whitesmoke")

  L1 &lt;- rbind(xl, yl)
  L2 &lt;- rbind(xa, ya)
  P &lt;- poly_crossings(L1, L2)
  points(P)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='polyder'>Derivative of Polynomial</h2><span id='topic+polyder'></span>

<h3>Description</h3>

<p>Differentiate polynomials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  polyder(p, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyder_+3A_p">p</code></td>
<td>
<p>polynomial <code>p</code> given as a vector</p>
</td></tr>
<tr><td><code id="polyder_+3A_q">q</code></td>
<td>
<p>polynomial <code>p</code> given as a vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the derivative of polynomials and polynomial products.
</p>
<p><code>polyder(p)</code> returns the derivative of <code>p</code> while
<code>polyder(p, q)</code> returns the derivative of the product of the
polynomials <code>p</code> and <code>q</code>.
</p>


<h3>Value</h3>

<p>a vector representing a polynomial
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyval">polyval</a></code>, <code><a href="#topic+polyint">polyint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  polyder(c(3, 6, 9), c(1, 2, 0))  # 12 36 42 18
</code></pre>

<hr>
<h2 id='polyfit+2Cpolyfix'>Fitting by Polynomial</h2><span id='topic+polyfit'></span><span id='topic+polyfix'></span>

<h3>Description</h3>

<p>Polynomial curve fitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polyfit(x, y, n)

polyfix(x, y, n, xfix, yfix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyfit+2B2Cpolyfix_+3A_x">x</code></td>
<td>
<p>x-coordinates of points</p>
</td></tr>
<tr><td><code id="polyfit+2B2Cpolyfix_+3A_y">y</code></td>
<td>
<p>y-coordinates of points</p>
</td></tr>
<tr><td><code id="polyfit+2B2Cpolyfix_+3A_n">n</code></td>
<td>
<p>degree of the fitting polynomial</p>
</td></tr>
<tr><td><code id="polyfit+2B2Cpolyfix_+3A_xfix">xfix</code>, <code id="polyfit+2B2Cpolyfix_+3A_yfix">yfix</code></td>
<td>
<p>x- and y-coordinates of points to be fixed</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>polyfit</code> finds the coefficients of a polynomial of degree <code>n</code>
fitting the points given by their <code>x</code>, <code>y</code> coordinates in a
least-squares sense. In <code>polyfit</code>, if <code>x</code>, <code>y</code> are matrices
of the same size, the coordinates are taken elementwise. Complex values are 
not allowed.
</p>
<p><code>polyfix</code> finds a polynomial that fits the data in a least-squares
sense, but also passes exactly through all the points with coordinates
<code>xfix</code> and <code>yfix</code>. Degree <code>n</code> should be greater or equal
to the number of fixed points, but not too big to avoid &lsquo;singular matrix&rsquo;
or similar error messages
</p>


<h3>Value</h3>

<p>vector representing a polynomial.
</p>


<h3>Note</h3>

<p>Please not that <code>polyfit2</code> is has been removed since 1.9.3; please use
<code>polyfix</code> instead.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+poly">poly</a></code>, <code><a href="#topic+polyval">polyval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Fitting the sine function by a polynomial
  x &lt;- seq(0, pi, length.out=25)
  y &lt;- sin(x)
  p &lt;- polyfit(x, y, 6)
  
## Not run: 
  # Plot sin and fitted polynomial
  plot(x, y, type="b")
  yf &lt;- polyval(p, x)
  lines(x, yf, col="red")
  grid()
## End(Not run)

## Not run: 
  n &lt;- 3
  N &lt;- 100
  x &lt;- linspace(0, 2*pi, N); y = sin(x) + 0.1*rnorm(N)
  xfix &lt;- c(0, 2*pi); yfix = c(0, 0)

  xs &lt;- linspace(0, 2*pi); ys &lt;- sin(xs)
  plot(xs, ys, type = 'l', col = "gray",
	   main = "Polynom Approximation of Degree 3")
  grid()
  points(x, y, pch='o', cex=0.5)
  points(xfix, yfix, col = "darkred")

  p0 &lt;- polyfit(x, y, n)
  lines(xs, polyval(p0, xs), col = "blue")

  p1 &lt;- polyfix(x, y, n, xfix, yfix)
  lines(xs, polyval(p1, xs), col = "red")

  legend(4, 1, c("sin", "polyfit", "polyfix"),
         col=c("gray", "blue", "red"), lty=c(1,1,1))
## End(Not run)
</code></pre>

<hr>
<h2 id='polyint'>Anti-derivative of Polynomial</h2><span id='topic+polyint'></span>

<h3>Description</h3>

<p>Integrate polynomials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  polyint(p, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyint_+3A_p">p</code></td>
<td>
<p>polynomial <code>p</code> given as a vector</p>
</td></tr>
<tr><td><code id="polyint_+3A_k">k</code></td>
<td>
<p>an integration constant</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the integral, i.e. the antiderivative, of a polynomial
and adds a constant of integration <code>k</code> if given, else 0.
</p>


<h3>Value</h3>

<p>a vector representing a polynomial
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyval">polyval</a></code>, <code><a href="#topic+polyder">polyder</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  polyint(c(1, 1, 1, 1, 1), 1)
</code></pre>

<hr>
<h2 id='polylog'>
Polylogarithm Function
</h2><span id='topic+polylog'></span>

<h3>Description</h3>

<p>Computes the <code>n</code>-based polylogarithm of <code>z</code>: <code>Li_n(z)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polylog(z, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polylog_+3A_z">z</code></td>
<td>
<p>real number or vector, all entries satisfying <code>abs(z)&lt;1</code>.</p>
</td></tr>
<tr><td><code id="polylog_+3A_n">n</code></td>
<td>
<p>base of polylogarithm, integer greater or equal -4.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Polylogarithm is also known as Jonquiere's function. It is defined as
</p>
<p style="text-align: center;"><code class="reqn">\sum_{k=1}^{\infty}{z^k / k^n} = z + z^2/2^n + ...</code>
</p>

<p>The polylogarithm function arises, e.g., in Feynman diagram integrals. It
also arises in the closed form of the integral of the Fermi-Dirac and the
Bose-Einstein distributions.
</p>
<p>The special cases <code>n=2</code> and <code>n=3</code> are called the dilogarithm and 
trilogarithm, respectively.
</p>
<p>Approximation should be correct up to at least 5 digits for <code class="reqn">|z| &gt; 0.55</code>
and on the order of 10 digits for <code class="reqn">|z| &lt;= 0.55</code>.
</p>


<h3>Value</h3>

<p>Returns the function value (not vectorized).
</p>


<h3>Note</h3>

<p>Based on some equations, see references.
A Matlab implementation is available in the Matlab File Exchange.
</p>


<h3>References</h3>

<p>V. Bhagat, et al. (2003). On the evaluation of generalized BoseEinstein and 
FermiDirac integrals. Computer Physics Communications, Vol. 155, p.7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>polylog(0.5,  1)    # polylog(z, 1) = -log(1-z)
polylog(0.5,  2)    # (p1^2 - 6*log(2)^2) / 12
polylog(0.5,  3)    # (4*log(2)^3 - 2*pi^2*log(2) + 21*zeta(3)) / 24
polylog(0.5,  0)    # polylog(z,  0) = z/(1-z)
polylog(0.5, -1)    # polylog(z, -1) = z/(1-z)^2
</code></pre>

<hr>
<h2 id='polymul+2C+20polydiv'>Multiplying and Dividing Polynomials</h2><span id='topic+polymul'></span><span id='topic+polydiv'></span>

<h3>Description</h3>

<p>Multiply or divide two polynomials given as vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  polymul(p, q)

  polydiv(p, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polymul+2B2C+2B20polydiv_+3A_p">p</code>, <code id="polymul+2B2C+2B20polydiv_+3A_q">q</code></td>
<td>
<p>Vectors representing two polynomials.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Polynomial multiplication realized simply by multiplying and summing up
all the coefficients. Division is an alias for <code>deconv</code>.
Polynomials are defined from highest to lowest coefficient.
</p>


<h3>Value</h3>

<p>Vector representing a polynomial. For division, it returns a list with
'd' the result of the division and 'r' the rest.
</p>


<h3>Note</h3>

<p><code>conv</code> also realizes polynomial multiplication, through Fast Fourier
Transformation, with the drawback that small imaginary parts may evolve.
<code>deconv</code> can also be used for polynomial division.
</p>


<h3>See Also</h3>

<p><code>conv</code>, <code>deconv</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multiply x^2 + x + 1 with itself
polymul(c(1, 1, 1), c(0, 1, 1, 1))  #=&gt; 1 2 3 2 1

polydiv(c(1, 2, 3, 2, 1), c(1, 1, 1))
#=&gt; d = c(1,1,1); #=&gt; r = c(0.000000e+00 -1.110223e-16)
</code></pre>

<hr>
<h2 id='polypow'>Polynomial Powers</h2><span id='topic+polypow'></span>

<h3>Description</h3>

<p>Power of a polynomial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polypow(p, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polypow_+3A_p">p</code></td>
<td>
<p>vector representing a polynomial.</p>
</td></tr>
<tr><td><code id="polypow_+3A_n">n</code></td>
<td>
<p>positive integer, the exponent.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses <code>polymul</code> to multiply the polynomial <code>p</code> <code>n</code> times
with itself.
</p>


<h3>Value</h3>

<p>Vector representing a polynomial.
</p>


<h3>Note</h3>

<p>There is no such function in Matlab or Octave.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polymul">polymul</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>polypow(c(1, -1), 6)             #=&gt; (x - 1)^6 = (1  -6  15 -20  15  -6   1)
polypow(c(1, 1, 1, 1, 1, 1), 2)  # 1 2 3 4 5 6 5 4 3 2 1
</code></pre>

<hr>
<h2 id='polytrans+2C+20polygcf'>Polynomial Transformations</h2><span id='topic+polytrans'></span><span id='topic+polygcf'></span>

<h3>Description</h3>

<p>Transform a polynomial, find a greatest common factor, or determine the
multiplicity of a root.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polytrans(p, q)

polygcf(p, q, tol = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polytrans+2B2C+2B20polygcf_+3A_p">p</code>, <code id="polytrans+2B2C+2B20polygcf_+3A_q">q</code></td>
<td>
<p>vectors representing two polynomials.</p>
</td></tr>
<tr><td><code id="polytrans+2B2C+2B20polygcf_+3A_tol">tol</code></td>
<td>
<p>tolerance for coefficients to tolerate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Transforms polynomial <code>p</code> replacing occurences of <code>x</code> with
another polynomial <code>q</code> in <code>x</code>.
</p>
<p>Finds a greatest common divisor (or factor) of two polynomials.
Determines the multiplicity of a possible root; returns 0 if not a root.
This is in general only true to a certain tolerance.
</p>


<h3>Value</h3>

<p><code>polytrans</code> and <code>polygcf</code> return vectors representing polynomials.
<code>rootsmult</code> returns a natural number (or 0).
</p>


<h3>Note</h3>

<p>There are no such functions in Matlab or Octave.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyval">polyval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (x+1)^2 + (x+1) + 1
polytrans(c(1, 1, 1), c(1, 1))    #=&gt; 1 3 3
polytrans(c(1, 1, 1), c(-1, -1))  #=&gt; 1 1 1

p &lt;- c(1,-1,1,-1,1)         #=&gt;  x^4 - x^3 + x^2 - x + 1
q &lt;- c(1,1,1)               #=&gt;  x^2 + x + 1
polygcf(polymul(p, q), q)   #=&gt;  [1] 1 1 1

p = polypow(c(1, -1), 6)    #=&gt;  [1] 1  -6  15 -20  15  -6   1
rootsmult(p, 1)             #=&gt;  [1] 6
</code></pre>

<hr>
<h2 id='polyval+2C+20polyvalm'>Evaluating a Polynomial</h2><span id='topic+polyval'></span><span id='topic+polyvalm'></span>

<h3>Description</h3>

<p>Evaluate polynomial on vector or matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  polyval(p, x)

  polyvalm(p, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyval+2B2C+2B20polyvalm_+3A_p">p</code></td>
<td>
<p>vector representing a polynomial.</p>
</td></tr>
<tr><td><code id="polyval+2B2C+2B20polyvalm_+3A_x">x</code></td>
<td>
<p>vector of values where to evaluate the polynomial.</p>
</td></tr>
<tr><td><code id="polyval+2B2C+2B20polyvalm_+3A_a">A</code></td>
<td>
<p>matrix; needs to be square.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>polyval</code> valuates the polynomial given by <code>p</code> at the 
values specified by the elements of <code>x</code>. If <code>x</code> is 
a matrix, the polynomial will be evaluated at each element and  
a matrix returned.
</p>
<p><code>polyvalm</code> will evaluate the polynomial in the matrix sense,
i.e., matrix multiplication is used instead of element by element
multiplication as used in 'polyval'. The argument matrix <code>A</code>
must be a square matrix.
</p>


<h3>Value</h3>

<p>Vector of values, resp. a matrix.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+poly">poly</a></code>, <code><a href="#topic+roots">roots</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Evaluate 3 x^2 + 2 x + 1 at x = 5, 7, and 9
  p = c(3, 2, 1);
  polyval(p, c(5, 7, 9))    # 86  162  262

  # Apply the characteristic polynomial to its matrix
  A &lt;- pascal(4)
  p &lt;- pracma::Poly(A)      # characteristic polynomial of A
  polyvalm(p, A)            # almost zero 4x4-matrix
</code></pre>

<hr>
<h2 id='pow2'>Base 2 Power</h2><span id='topic+pow2'></span>

<h3>Description</h3>

<p>Power with base 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  pow2(f, e)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pow2_+3A_f">f</code></td>
<td>
<p>numeric vector of factors</p>
</td></tr>
<tr><td><code id="pow2_+3A_e">e</code></td>
<td>
<p>numeric vector of exponents for base 2</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the expression <code>f * 2^e</code>, setting <code>e</code> to <code>f</code>
and <code>f</code> to 1 in case <code>e</code> is missing.
Complex values are only processed if <code>e</code> is missing.
</p>


<h3>Value</h3>

<p>Returns a numeric vector computing <code class="reqn">f\,2^e</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nextpow2">nextpow2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  pow2(c(0, 1, 2, 3))                   #=&gt; 1 2 4 8
  pow2(c(0, -1, 2, 3), c(0,1,-2,3))     #=&gt; 0.0 -2.0  0.5 24.0
  pow2(1i)                              #=&gt; 0.7692389+0.6389613i
</code></pre>

<hr>
<h2 id='ppfit'>
Piecewise Polynomial Fit
</h2><span id='topic+ppfit'></span>

<h3>Description</h3>

<p>Piecewise linear or cubic fitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppfit(x, y, xi, method = c("linear", "cubic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppfit_+3A_x">x</code>, <code id="ppfit_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates of given points.</p>
</td></tr>
<tr><td><code id="ppfit_+3A_xi">xi</code></td>
<td>
<p>x-coordinates of the choosen support nodes.</p>
</td></tr>
<tr><td><code id="ppfit_+3A_method">method</code></td>
<td>
<p>interpolation method,
can be &lsquo;constant&rsquo;, &lsquo;linear&rsquo;, or &lsquo;cubic&rsquo; (i.e., &lsquo;spline&rsquo;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ppfit</code> fits a piece-wise polynomial to the input independent and 
dependent variables,<code>x</code> and <code>y</code>, respectively. A weighted linear 
least squares solution is provided. The weighting vector <code>w</code> must be 
of the same size as the input variables.
</p>


<h3>Value</h3>

<p>Returns a <code>pp</code> (i.e., piecewise polynomial) structure.
</p>


<h3>Note</h3>

<p>Following an idea of Copyright (c) 2012 Ben Abbott, Martin Helm for Octave.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mkpp">mkpp</a></code>, <code><a href="#topic+ppval">ppval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 0:39
y &lt;- c(  8.8500,  32.0775,  74.7375, 107.6775, 132.0975, 156.6675,
       169.0650, 187.5375, 202.2575, 198.0750, 225.9600, 204.3550,
       233.8125, 204.5925, 232.3625, 204.7550, 220.1925, 199.5875,
       197.3025, 175.3050, 218.6325, 163.0775, 170.6625, 148.2850,
       154.5950, 135.4050, 138.8600, 125.6750, 118.8450,  99.2675,
       129.1675,  91.1925,  89.7000,  76.8825,  83.6625,  74.1950,
        73.9125,  55.8750,  59.8675,  48.1900)

xi &lt;- linspace(0, 39, 8)
pplin &lt;- ppfit(x, y, xi)  # method = "linear"
ppcub &lt;- ppfit(x, y, xi, method = "cubic")

## Not run: 
plot(x, y, type = "b", main = "Piecewise polynomial approximation")
xs &lt;- linspace(0, 39, 100)
yslin &lt;- ppval(pplin, xs)
yscub &lt;- ppval(ppcub, xs)
lines(xs, yscub, col="red",lwd = 2)
lines(xs, yslin, col="blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='ppval'>
Piecewise Polynomial Structures
</h2><span id='topic+mkpp'></span><span id='topic+ppval'></span>

<h3>Description</h3>

<p>Make or evaluate a piecewise polynomial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mkpp(x, P)

ppval(pp, xx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppval_+3A_x">x</code></td>
<td>
<p>increasing vector of real numbers.</p>
</td></tr>
<tr><td><code id="ppval_+3A_p">P</code></td>
<td>
<p>matrix containing the coefficients of polynomials in each row.</p>
</td></tr>
<tr><td><code id="ppval_+3A_pp">pp</code></td>
<td>
<p>a piecewise polynomial structure, generated by <code>mkpp</code>.</p>
</td></tr>
<tr><td><code id="ppval_+3A_xx">xx</code></td>
<td>
<p>numerical vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pp&lt;-mkpp(x,P)</code> builds a piecewise polynomial from its breaks
<code>x</code> and coefficients <code>P</code>. <code>x</code> is a monotonically increasing
vector of length <code>L+1</code>, and <code>P</code> is an <code>L-by-k</code> matrix where 
each row contains the coefficients of the polynomial of order <code>k</code>, from 
highest to lowest exponent, on the interval <code>[x[i],x[i+1])</code>.
</p>
<p><code>ppval(pp,xx)</code> returns the values of the piecewise polynomial
<code>pp</code> at the entries of the vector <code>xx</code>. The first and last
polynomial will be extended to the left resp. right of the interval
<code>[x[1],x[L+1])</code>.
</p>


<h3>Value</h3>

<p><code>mkpp</code> will return a piecewise polynomial structure, that is a list
with components <code>breaks=x</code>, <code>pieces=P</code>, <code>order=k</code> and
<code>dim=1</code> for scalar-valued functions.
</p>


<h3>Note</h3>

<p>Matlab allows to generate vector-valued piecewise polynomials. This may be
included in later versions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cubicspline">cubicspline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example: Linear interpolation of the sine function
xs &lt;- linspace(0, pi, 10)
ys &lt;- sin(xs)
P &lt;- matrix(NA, nrow = 9, ncol = 2)
for (i in 1:9) {
    P[i, ] &lt;- c((ys[i+1]-ys[i])/(xs[i+1]-xs[i]), ys[i])
}
ppsin &lt;- mkpp(xs, P)

## Not run: 
plot(xs, ys); grid()
x100 &lt;- linspace(0, pi, 100)
lines(x100, sin(x100), col="darkgray")
ypp &lt;- ppval(ppsin, x100)
lines(x100, ypp, col="red")

## End(Not run)
</code></pre>

<hr>
<h2 id='primes'>Prime Numbers</h2><span id='topic+primes'></span>

<h3>Description</h3>

<p>Generate a list of prime numbers less or equal <code>n</code>, resp. between
<code>n1</code> and <code>n2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  primes(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="primes_+3A_n">n</code></td>
<td>
<p>nonnegative integer greater than 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The list of prime numbers up to <code>n</code> is generated using the &quot;sieve of
Erasthostenes&quot;. This approach is reasonably fast, but may require a lot of
main memory when <code>n</code> is large.
</p>
<p>In double precision arithmetic integers are represented exactly only up to
2^53 - 1, therefore this is the maximal allowed value.
</p>


<h3>Value</h3>

<p>vector of integers representing prime numbers
</p>


<h3>See Also</h3>

<p><code><a href="#topic+isprime">isprime</a>, <a href="#topic+factors">factors</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>primes(1000)
## Not run: 
##  Appendix:  Logarithmic Integrals and Prime Numbers (C.F.Gauss, 1846)

library('gsl')
# 'European' form of the logarithmic integral
Li &lt;- function(x) expint_Ei(log(x)) - expint_Ei(log(2))

# No. of primes and logarithmic integral for 10^i, i=1..12
i &lt;- 1:12;  N &lt;- 10^i
# piN &lt;- numeric(12)
# for (i in 1:12) piN[i] &lt;- length(primes(10^i))
piN &lt;- c(4, 25, 168, 1229, 9592, 78498, 664579,
         5761455, 50847534, 455052511, 4118054813, 37607912018)
cbind(i, piN, round(Li(N)), round((Li(N)-piN)/piN, 6))

#  i     pi(10^i)      Li(10^i)  rel.err  
# --------------------------------------      
#  1            4            5  0.280109
#  2           25           29  0.163239
#  3          168          177  0.050979
#  4         1229         1245  0.013094
#  5         9592         9629  0.003833
#  6        78498        78627  0.001637
#  7       664579       664917  0.000509
#  8      5761455      5762208  0.000131
#  9     50847534     50849234  0.000033
# 10    455052511    455055614  0.000007
# 11   4118054813   4118066400  0.000003
# 12  37607912018  37607950280  0.000001
# --------------------------------------
## End(Not run)
</code></pre>

<hr>
<h2 id='procrustes'>
Solving the Procrustes Problem
</h2><span id='topic+procrustes'></span><span id='topic+kabsch'></span>

<h3>Description</h3>

<p><code>procrustes</code> solves for two matrices <code>A</code> and <code>B</code> the 
&lsquo;Procrustes Problem&rsquo; of finding an orthogonal matrix <code>Q</code> such that
<code>A-B*Q</code> has the minimal Frobenius norm.
</p>
<p><code>kabsch</code> determines a best rotation of a given vector set into a
second vector set by minimizing the weighted sum of squared deviations.
The order of vectors is assumed fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>procrustes(A, B)

kabsch(A, B, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="procrustes_+3A_a">A</code>, <code id="procrustes_+3A_b">B</code></td>
<td>
<p>two numeric matrices of the same size.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_w">w</code></td>
<td>
<p>weights , influence the distance of points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>procrustes(A,B)</code> uses the <code>svd</code> decomposition 
to find an orthogonal matrix <code>Q</code> such that <code>A-B*Q</code> has a 
minimal Frobenius norm, where this norm for a matrix <code>C</code> is defined
as <code>sqrt(Trace(t(C)*C))</code>, or <code>norm(C,'F')</code> in R.
</p>
<p>Solving it with <code>B=I</code> means finding a nearest orthogonal matrix.
</p>
<p><code>kabsch</code> solves a similar problem and uses the Procrustes procedure
for its purpose. Given two sets of points, represented as columns of the
matrices <code>A</code> and <code>B</code>, it determines an orthogonal matrix
<code>U</code> and a translation vector <code>R</code> such that <code>U*A+R-B</code> 
is minimal.
</p>


<h3>Value</h3>

<p><code>procrustes</code> returns a list with components <code>P</code>, which is 
<code>B*Q</code>, then <code>Q</code>, the orthogonal matrix, and <code>d</code>, the
Frobenius norm of <code>A-B*Q</code>.
</p>
<p><code>kabsch</code> returns a list with <code>U</code> the orthogonal matrix applied, 
<code>R</code> the translation vector, and <code>d</code> the least root mean square
between <code>U*A+R</code> and <code>B</code>.
</p>


<h3>Note</h3>

<p>The <code>kabsch</code> function does not take into account scaling of the sets,
but this could easily be integrated.
</p>


<h3>References</h3>

<p>Golub, G. H., and Ch. F. van Loan (1996). Matrix Computations. 3rd Edition,
The John Hopkins University Press, Baltimore London. [Sect. 12.4, p. 601]
</p>
<p>Kabsch, W. (1976). A solution for the best rotation to relate two sets 
of vectors. Acta Cryst A, Vol. 32, p. 9223.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Procrustes
U &lt;- randortho(5)               # random orthogonal matrix
P &lt;- procrustes(U, eye(5))

##  Kabsch
P &lt;- matrix(c(0, 1, 0, 0, 1, 1, 0, 1,
              0, 0, 1, 0, 1, 0, 1, 1,
              0, 0, 0, 1, 0, 1, 1, 1), nrow = 3, ncol = 8, byrow = TRUE)
R &lt;- c(1, 1, 1)
phi &lt;- pi/4
U &lt;- matrix(c(1, 0, 0,
              0, cos(phi), -sin(phi),
              0, sin(phi),  cos(phi)), nrow = 3, ncol = 3, byrow = TRUE)

Q &lt;- U %*% P + R
K &lt;- kabsch(P, Q)
# K$R == R  and  K$U %*% P + c(K$R) == Q
</code></pre>

<hr>
<h2 id='psi'>
Psi (Polygamma) Function
</h2><span id='topic+psi'></span>

<h3>Description</h3>

<p>Arbitrary order Polygamma function valid in the entire complex plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi(k, z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi_+3A_k">k</code></td>
<td>
<p>order of the polygamma function, whole number greater or equal 0.</p>
</td></tr>
<tr><td><code id="psi_+3A_z">z</code></td>
<td>
<p>numeric complex number or vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the Polygamma function of arbitrary order, and valid in the entire
complex plane. The polygamma function is defined as
</p>
<p style="text-align: center;"><code class="reqn">\psi(n, z) = \frac{d^{n+1}}{dz^{n+1}} \log(\Gamma(z))</code>
</p>

<p>If <code>n</code> is 0 or absent then <code>psi</code> will be the Digamma function.
If <code>n=1,2,3,4,5</code> etc. then <code>psi</code> will be the
tri-, tetra-, penta-, hexa-, hepta- etc. gamma function.
</p>


<h3>Value</h3>

<p>Returns a complex number or a vector of complex numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>psi(2) - psi(1)         # 1
-psi(1)                 # Eulers constant: 0.57721566490153  [or, -psi(0, 1)]
psi(1, 2)               # pi^2/6 - 1     : 0.64493406684823
psi(10, -11.5-0.577007813568142i)
                        # is near a root of the decagamma function
</code></pre>

<hr>
<h2 id='qpspecial+2C+20qpsolve'>
Special Quadratic Programming Solver
</h2><span id='topic+qpspecial'></span><span id='topic+qpsolve'></span>

<h3>Description</h3>

<p>Solves a special Quadratic Programming problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpspecial(G, x, maxit = 100)

qpsolve(d, A, b, meq = 0, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_g">G</code></td>
<td>
<p><code>m x n</code>-matrix.</p>
</td></tr>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_x">x</code></td>
<td>
<p>column vector of length <code>n</code>, the initial (feasible) iterate; 
if not present (or requirements on x0 not met), x0 will be found.</p>
</td></tr>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterates allowed; default 100.</p>
</td></tr>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_d">d</code></td>
<td>
<p>Linear term of the quadratic form.</p>
</td></tr>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_a">A</code>, <code id="qpspecial+2B2C+2B20qpsolve_+3A_b">b</code></td>
<td>
<p>Linear equality and inequality constraints.</p>
</td></tr>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_meq">meq</code></td>
<td>
<p>First meq rows are used as equality constraints.</p>
</td></tr>
<tr><td><code id="qpspecial+2B2C+2B20qpsolve_+3A_tol">tol</code></td>
<td>
<p>Tolerance used for stopping the iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>qpspecial</code> solves the special QP problem:
</p>
<p><code>min     q(x)  = || G*x ||_2^2 = x'*(G'*G)*x</code><br />
<code>s.t.  sum(x)  = 1</code><br />
<code>and   x  &gt;= 0</code>
</p>
<p>The problem corresponds to finding the smallest vector (2-norm) in the 
convex hull of the columns of <code>G</code>.
</p>
<p><code>qpsolve</code> solves the more general QP problem:
</p>
<p><code>min  q(x) = 0.5 t(x)*x - d x</code><br />
<code>s.t. A x &gt;= b</code>
</p>
<p>with <code>A x = b</code> for the first <code>meq</code> rows.
</p>


<h3>Value</h3>

<p>Returns a list with the following components:
</p>

<ul>
<li> <p><code>x</code> &ndash; optimal point attaining optimal value;
</p>
</li>
<li> <p><code>d = G*x</code> &ndash; smallest vector in the convex hull;
</p>
</li>
<li> <p><code>q</code> &ndash; optimal value found, <code>= t(d) %*% d</code>;
</p>
</li>
<li> <p><code>niter</code> &ndash; number of iterations used;
</p>
</li>
<li> <p><code>info</code> &ndash; error number:<br />
<code>= 0</code>: everything went well, q is optimal,<br />
<code>= 1</code>:  maxit reached and final x is feasible,<br />
<code>= 2</code>:  something went wrong.
</p>
</li></ul>



<h3>Note</h3>

<p><code>x</code> may be missing, same as if requirements are not met; may stop with 
an error if <code>x</code> is not feasible.
</p>


<h3>Author(s)</h3>

<p>Matlab code by Anders Skajaa, 2010, under GPL license (HANSO toolbox);
converted to R by Abhirup Mallik and Hans W. Borchers, with permission.
</p>


<h3>References</h3>

<p>[Has to be found.]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>G &lt;- matrix(c(0.31, 0.99, 0.54, 0.20,
              0.56, 0.97, 0.40, 0.38,
              0.81, 0.06, 0.44, 0.80), 3, 4, byrow =TRUE)
qpspecial(G)
# $x
#              [,1]
# [1,] 1.383697e-07
# [2,] 5.221698e-09
# [3,] 8.648168e-01
# [4,] 1.351831e-01
# $d
#           [,1]
# [1,] 0.4940377
# [2,] 0.3972964
# [3,] 0.4886660
# $q
# [1] 0.6407121
# $niter
# [1] 6
# $info
# [1] 0

# Example from quadprog::solve.QP
d &lt;- c(0,5,0)
A &lt;- matrix(c(-4,-3,0,2,1,0,0,-2,1),3,3)
b &lt;- c(-8,2,0)
qpsolve(d, A, b)
## $sol
## [1] 0.4761905 1.0476190 2.0952381
## $val
## [1] -2.380952
## $niter
## [1] 3
</code></pre>

<hr>
<h2 id='qrSolve'>LSE Solution</h2><span id='topic+qrSolve'></span>

<h3>Description</h3>

<p>Systems of linear equations via QR decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  qrSolve(A, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qrSolve_+3A_a">A</code></td>
<td>
<p>numerical matrix with <code>nrow(A)&gt;=ncol(A)</code>.</p>
</td></tr>
<tr><td><code id="qrSolve_+3A_b">b</code></td>
<td>
<p>numerical vector with <code>length(b) == nrow(A)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves (overdetermined) systems of linear equations via QR decomposition. 
</p>


<h3>Value</h3>

<p>The solution of the system as vector.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Society for Industrial and Applied Mathematics, Philadelphia.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+householder">householder</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(0,-4,2, 6,-3,-2, 8,1,-1), 3, 3, byrow=TRUE)
b &lt;- c(-2, -6, 7)
qrSolve(A, b)

##  Solve an overdetermined linear system of equations
A &lt;- matrix(c(1:8,7,4,2,3,4,2,2), ncol=3, byrow=TRUE)
b &lt;- rep(6, 5)
x &lt;- qrSolve(A, b)
qr.solve(A, rep(6, 5)); x
</code></pre>

<hr>
<h2 id='quad'>
Adaptive Simpson Quadrature
</h2><span id='topic+quad'></span>

<h3>Description</h3>

<p>Adaptive quadrature of functions of one variable over a finite interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quad(f, xa, xb, tol = .Machine$double.eps^0.5, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quad_+3A_f">f</code></td>
<td>
<p>a one-dimensional function; needs to be vectorized.</p>
</td></tr>
<tr><td><code id="quad_+3A_xa">xa</code></td>
<td>
<p>lower limit of integration; must be finite</p>
</td></tr>
<tr><td><code id="quad_+3A_xb">xb</code></td>
<td>
<p>upper limit of integration; must be finite</p>
</td></tr>
<tr><td><code id="quad_+3A_tol">tol</code></td>
<td>
<p>accuracy requested.</p>
</td></tr>
<tr><td><code id="quad_+3A_trace">trace</code></td>
<td>
<p>logical; shall a trace be printed?</p>
</td></tr>
<tr><td><code id="quad_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Realizes adaptive Simpson quadrature in R through recursive calls.
</p>
<p>The function <code>f</code> needs to be vectorized though this could be changed
easily. <code>quad</code> is not suitable for functions with singularities in the
interval or at end points.
</p>


<h3>Value</h3>

<p>A single numeric value, the computed integral.
</p>


<h3>Note</h3>

<p>More modern adaptive methods based on Gauss-Kronrod or Clenshaw-Curtis
quadrature are now generally preferred.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 1998 Walter Gautschi for the Matlab version published as
part of the referenced article. R implementation by Hans W Borchers 2011.
</p>


<h3>References</h3>

<p>Gander, W. and W. Gautschi (2000). &ldquo;Adaptive Quadrature &mdash; Revisited&rdquo;.
BIT, Vol. 40, 2000, pp. 84-101.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+quadl">quadl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># options(digits=15)
f &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
quad(f, 0, 4)              # 1.2821290747821
quad(f, 0, 4, tol=10^-15)  # 1.2821290743501
integrate(f, 0, 4)
# 1.28212907435010 with absolute error &lt; 4.1e-06

## Not run: 
xx &lt;- seq(0, 4, length.out = 200)
yy &lt;- f(xx)
plot(xx, yy, type = 'l')
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='quad2d'>
2-d Gaussian Quadrature
</h2><span id='topic+quad2d'></span>

<h3>Description</h3>

<p>Two-dimensional Gaussian Quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quad2d(f, xa, xb, ya, yb, n = 32, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quad2d_+3A_f">f</code></td>
<td>
<p>function of two variables; needs to be vectorized.</p>
</td></tr>
<tr><td><code id="quad2d_+3A_xa">xa</code>, <code id="quad2d_+3A_ya">ya</code></td>
<td>
<p>lower limits of integration; must be finite.</p>
</td></tr>
<tr><td><code id="quad2d_+3A_xb">xb</code>, <code id="quad2d_+3A_yb">yb</code></td>
<td>
<p>upper limits of integration; must be finite.</p>
</td></tr>
<tr><td><code id="quad2d_+3A_n">n</code></td>
<td>
<p>number of nodes used per direction.</p>
</td></tr>
<tr><td><code id="quad2d_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extends the Gaussian quadrature to two dimensions by computing two sets
of nodes and weights (in x- and y-direction), evaluating the function
on this grid and multiplying weights appropriately.
</p>
<p>The function <code>f</code> needs to be vectorized in both variables such that
<code>f(X, Y)</code> returns a matrix when <code>X</code> an <code>Y</code> are matrices
(of the same size).
</p>
<p><code>quad</code> is not suitable for functions with singularities.
</p>


<h3>Value</h3>

<p>A single numerical value, the computed integral.
</p>


<h3>Note</h3>

<p>The extension of Gaussian quadrature to two dimensions is obvious, but
see also the example &lsquo;integral2d.m&rsquo; at Nick Trefethens &ldquo;10 digits 1 page&rdquo;.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quad">quad</a></code>, <code>cubature::adaptIntegrate</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example:  f(x, y) = (y+1)*exp(x)*sin(16*y-4*(x+1)^2)
f &lt;- function(x, y)
        (y+1) * exp(x) * sin(16*y-4*(x+1)^2)
# this is even faster than cubature::adaptIntegral():
quad2d(f, -1, 1, -1, 1)
# 0.0179515583236958  # true value 0.01795155832370

##  Volume of the sphere: use polar coordinates
f0 &lt;- function(x, y) sqrt(1 - x^2 - y^2)  # for x^2 + y^2 &lt;= 1
fp &lt;- function(x, y) y * f0(y*cos(x), y*sin(x))
quad2d(fp, 0, 2*pi, 0, 1, n = 101)  # 2.09439597740074
2/3 * pi                            # 2.0943951023932
</code></pre>

<hr>
<h2 id='quadcc'>
Adaptive Clenshaw-Curtis Quadrature
</h2><span id='topic+quadcc'></span>

<h3>Description</h3>

<p>Adaptive Clenshaw-Curtis Quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadcc(f, a, b, tol = .Machine$double.eps^0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadcc_+3A_f">f</code></td>
<td>
<p>integrand as function, may have singularities at the endpoints.</p>
</td></tr>
<tr><td><code id="quadcc_+3A_a">a</code>, <code id="quadcc_+3A_b">b</code></td>
<td>
<p>endpoints of the integration interval.</p>
</td></tr>
<tr><td><code id="quadcc_+3A_tol">tol</code></td>
<td>
<p>relative tolerence.</p>
</td></tr>
<tr><td><code id="quadcc_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adaptive version of the Clenshaw-Curtis quadrature formula with an
(4, 8)-point erroe term.
</p>


<h3>Value</h3>

<p>List with two components, <code>value</code> the value of the integral and
the relative error <code>error</code>.
</p>


<h3>See Also</h3>

<p><code>clenshaw_curtis</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##  Dilogarithm function
flog &lt;- function(t) log(1-t)/t
quadcc(flog, 1, 0, tol = 1e-12)
# 1.644934066848128 - pi^2/6 &lt; 1e-13

## End(Not run)
</code></pre>

<hr>
<h2 id='quadgk'>
Adaptive Gauss-Kronrod Quadrature
</h2><span id='topic+quadgk'></span>

<h3>Description</h3>

<p>Adaptive Gauss-Kronrod Quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadgk(f, a, b, tol = .Machine$double.eps^0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadgk_+3A_f">f</code></td>
<td>
<p>integrand as function; needs to be vectorized,
but may have singularities at the endpoints.</p>
</td></tr>
<tr><td><code id="quadgk_+3A_a">a</code>, <code id="quadgk_+3A_b">b</code></td>
<td>
<p>endpoints of the integration interval.</p>
</td></tr>
<tr><td><code id="quadgk_+3A_tol">tol</code></td>
<td>
<p>relative tolerence.</p>
</td></tr>
<tr><td><code id="quadgk_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function f.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adaptive version of the (7, 15)-point Gauss-Kronrod quadrature formula,
where in each recursion the error is taken as the difference between these
two estimated integrals.
</p>
<p>The function <code>f</code> must be vectorized, though this will not be checked
and may lead to strange errors. If it is not, use <code>F = Vectorize(f)</code>.
</p>


<h3>Value</h3>

<p>Value of the integration. The relative error should be of the same
order of magnitude as the relative tolerance (or much smaller).
</p>


<h3>Note</h3>

<p>Uses the same nodes and weights as the <code>quadQK15</code> procedure in the
QUADPACK library.
</p>


<h3>See Also</h3>

<p><code>gauss_kronrod</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Dilogarithm function
flog &lt;- function(t) log(1-t)/t
quadgk(flog, 1, 0, tol = 1e-12)
# 1.644934066848128 - pi^2/6 &lt; 1e-13
</code></pre>

<hr>
<h2 id='quadgr'>
Gaussian Quadrature with Richardson Extrapolation
</h2><span id='topic+quadgr'></span>

<h3>Description</h3>

<p>Gaussian 12-point quadrature with Richardson extrapolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadgr(f, a, b, tol = .Machine$double.eps^(1/2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadgr_+3A_f">f</code></td>
<td>
<p>integrand as function, may have singularities at the endpoints.</p>
</td></tr>
<tr><td><code id="quadgr_+3A_a">a</code>, <code id="quadgr_+3A_b">b</code></td>
<td>
<p>endpoints of the integration interval.</p>
</td></tr>
<tr><td><code id="quadgr_+3A_tol">tol</code></td>
<td>
<p>relative tolerence.</p>
</td></tr>
<tr><td><code id="quadgr_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to the function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>quadgr</code> uses a 12-point Gauss-Legendre quadrature.
The error estimate is based on successive interval bisection. Richardson
extrapolation accelerates the convergence for some integrals, especially
integrals with endpoint singularities.
</p>
<p>Through some preprocessing infinite intervals can also be handled.
</p>


<h3>Value</h3>

<p>List with <code>value</code> and <code>rel.err</code>.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 2009 Jonas Lundgren for the Matlab function <code>quadgr</code>
available on MatlabCentral under the BSD license.
</p>
<p>R re-implementation by HwB, email: &lt;hwborchers@googlemail.com&gt;, in 2011.
</p>


<h3>See Also</h3>

<p><code>gaussLegendre</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Dilogarithm function
flog &lt;- function(t) log(1-t)/t
quadgr(flog, 1, 0, tol = 1e-12)
# value
# 1.6449340668482 , is pi^2/6 = 1.64493406684823
# rel.err
# 2.07167616395054e-13
</code></pre>

<hr>
<h2 id='quadinf'>
Infinite Integrals
</h2><span id='topic+quadinf'></span>

<h3>Description</h3>

<p>Iterative quadrature of functions over finite, semifinite, or
infinite intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadinf(f, xa, xb, tol = 1e-12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadinf_+3A_f">f</code></td>
<td>
<p>univariate function; needs not be vectorized.</p>
</td></tr>
<tr><td><code id="quadinf_+3A_xa">xa</code></td>
<td>
<p>lower limit of integration; can be infinite</p>
</td></tr>
<tr><td><code id="quadinf_+3A_xb">xb</code></td>
<td>
<p>upper limit of integration; can be infinite</p>
</td></tr>
<tr><td><code id="quadinf_+3A_tol">tol</code></td>
<td>
<p>accuracy requested.</p>
</td></tr>
<tr><td><code id="quadinf_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>quadinf</code> implements the &lsquo;double exponential method&rsquo; for fast 
numerical integration of smooth real functions on finite intervals.
For infinite intervals, the tanh-sinh quadrature scheme is applied,
that is the transformation <code>g(t)=tanh(pi/2*sinh(t))</code>.
</p>
<p>Please note that this algorithm does work very accurately for
&lsquo;normal&rsquo; function, but should not be applied to (heavily)
oscillating functions. The maximal number of iterations is 7, so
if this is returned the iteration may not have converged.
</p>
<p>The integrand function needs <em>not</em> be vectorized.
</p>


<h3>Value</h3>

<p>A list with components <code>Q</code> the integral value, <code>relerr</code>
the relative error, and <code>niter</code> the number of iterations.
</p>


<h3>Note</h3>

<p>See also my remarks on R-help in September 2010 in the thread
&ldquo;bivariate vector numerical integration with infinite range&rdquo;.
</p>


<h3>References</h3>

<p>D. H. Bayley. Tanh-Sinh High-precision Quadrature. 2006.<br />
URL: https://www.davidhbailey.com//dhbpapers/dhb-tanh-sinh.pdf
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+quadgk">quadgk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  We will look at the error function exp(-x^2)
f &lt;- function(x) exp(-x^2)          # sqrt(pi)/2         theory
quadinf(f, 0, Inf)                  # 0.8862269254527413
quadinf(f, -Inf, 0)                 # 0.8862269254527413

f = function(x) sqrt(x) * exp(-x)   # 0.8862269254527579 exact
quadinf(f, 0, Inf)                  # 0.8862269254527579

f = function(x) x * exp(-x^2)       # 1/2
quadinf(f, 0, Inf)                  # 0.5

f = function(x) 1 / (1+x^2)         # 3.141592653589793 = pi
quadinf(f, -Inf, Inf)               # 3.141592653589784
</code></pre>

<hr>
<h2 id='quadl'>
Adaptive Lobatto Quadrature
</h2><span id='topic+quadl'></span>

<h3>Description</h3>

<p>Adaptive quadrature of functions of one variable over a finite interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadl(f, xa, xb, tol = .Machine$double.eps^0.5, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadl_+3A_f">f</code></td>
<td>
<p>a one-dimensional function; needs to be vectorized.</p>
</td></tr>
<tr><td><code id="quadl_+3A_xa">xa</code></td>
<td>
<p>lower limit of integration; must be finite</p>
</td></tr>
<tr><td><code id="quadl_+3A_xb">xb</code></td>
<td>
<p>upper limit of integration; must be finite</p>
</td></tr>
<tr><td><code id="quadl_+3A_tol">tol</code></td>
<td>
<p>accuracy requested.</p>
</td></tr>
<tr><td><code id="quadl_+3A_trace">trace</code></td>
<td>
<p>logical; shall a trace be printed?</p>
</td></tr>
<tr><td><code id="quadl_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Realizes adaptive Lobatto quadrature in R through recursive calls.
</p>
<p>The function <code>f</code> needs to be vectorized though this could be changed
easily.
</p>


<h3>Value</h3>

<p>A single numeric value, the computed integral.
</p>


<h3>Note</h3>

<p>Compared to Gaussian quadrature, Lobatto integration include the end points
of the integration interval. It is accurate for polynomials up to degree
2n-3, where n is the number of integration points.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 1998 Walter Gautschi for the Matlab version published as
part of the referenced article. R implementation by Hans W Borchers 2011.
</p>


<h3>References</h3>

<p>Gander, W. and W. Gautschi (2000). &ldquo;Adaptive Quadrature &mdash; Revisited&rdquo;.
BIT, Vol. 40, 2000, pp. 84-101.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quad">quad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># options(digits=15)
f &lt;- function(x) x * cos(0.1*exp(x)) * sin(0.1*pi*exp(x))
quadl(f, 0, 4)              # 1.2821290743501
integrate(f, 0, 4)
# 1.28212907435010 with absolute error &lt; 4.1e-06

## Not run: 
xx &lt;- seq(0, 4, length.out = 200)
yy &lt;- f(xx)
plot(xx, yy, type = 'l')
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='quadprog'>
Quadratic Programming
</h2><span id='topic+quadprog'></span>

<h3>Description</h3>

<p>Solves quadratic programming problems with linear and box constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadprog(C, d, A = NULL, b = NULL,
         Aeq = NULL, beq = NULL, lb = NULL, ub = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadprog_+3A_c">C</code></td>
<td>
<p>symmetric matrix, representing the quadratic term.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_d">d</code></td>
<td>
<p>vector, representing the linear term.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_a">A</code></td>
<td>
<p>matrix, represents the linear constraint coefficients.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_b">b</code></td>
<td>
<p>vector, constant vector in the constraints.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_aeq">Aeq</code></td>
<td>
<p>matrix, linear equality constraint coefficients.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_beq">beq</code></td>
<td>
<p>vector, constant equality constraint vector.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_lb">lb</code></td>
<td>
<p>elementwise lower bounds.</p>
</td></tr>
<tr><td><code id="quadprog_+3A_ub">ub</code></td>
<td>
<p>elementwise upper bounds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds a minimum for the quadratic programming problem specified as:
</p>
<p style="text-align: center;"><code class="reqn">min 1/2 x'Cx + d'x</code>
</p>

<p>such that the following constraints are satisfied:
</p>
<p style="text-align: center;"><code class="reqn">A x &lt;= b</code>
</p>

<p style="text-align: center;"><code class="reqn">Aeq x = beq</code>
</p>

<p style="text-align: center;"><code class="reqn">lb &lt;= x &lt;= ub</code>
</p>

<p>The matrix should be symmetric and positive definite, in which case
the solution is unique, indicated when the exit flag is 1.
</p>
<p>For more information, see <code>?solve.QP</code>.
</p>


<h3>Value</h3>

<p>Returns a list with components
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>minimum solution, subject to all bounds and constraints.</p>
</td></tr>
<tr><td><code>fval</code></td>
<td>
<p>value of the target expression at the arg minimum.</p>
</td></tr>
<tr><td><code>eflag</code></td>
<td>
<p>exit flag.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is wrapping the active set quadratic solver in the 
<code>quadprog</code> package: <code>quadprog::solve.QP</code>, combined with
a more MATLAB-like API interface.
</p>


<h3>References</h3>

<p>Nocedal, J., and St. J. Wright (2006). Numerical Optimization.
Second Edition, Springer Series in Operations Research, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsqlincon">lsqlincon</a></code>, <code>quadprog::solve.QP</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example in ?solve.QP
# Assume we want to minimize: 1/2 x^T x - (0 5 0) %*% x
# under the constraints:      A x &lt;= b
# with b = (8,-2, 0)
# and      ( 4  3  0) 
#      A = (-2 -1  0)
#          ( 0  2,-1)
# and possibly equality constraint  3x1 + 2x2 + x3 = 1
# or upper bound c(1.5, 1.5, 1.5).

C &lt;- diag(1, 3); d &lt;- -c(0, 5, 0)
A &lt;- matrix(c(4,3,0, -2,-1,0, 0,2,-1), 3, 3, byrow=TRUE)
b &lt;- c(8, -2, 0)

quadprog(C, d, A, b)
# $xmin
# [1] 0.4761905 1.0476190 2.0952381
# $fval
# [1] -2.380952
# $eflag
# [1] 1

Aeq &lt;- c(3, 2, 1);  beq &lt;- 1
quadprog(C, d, A, b, Aeq, beq)
# $xmin
# [1]  1.4 -0.8 -1.6
# $fval
# [1] 6.58
# $eflag
# [1] 1

quadprog(C, d, A, b, lb = 0, ub = 1.5)
# $xmin
# [1] 0.625 0.750 1.500
# $fval
# [1] -2.148438
# $eflag
# [1] 1

## Example help(quadprog)
C &lt;- matrix(c(1, -1, -1, 2), 2, 2)
d &lt;- c(-2, -6)
A &lt;- matrix(c(1,1, -1,2, 2,1), 3, 2, byrow=TRUE)
b &lt;- c(2, 2, 3)
lb &lt;- c(0, 0)

quadprog(C, d, A, b, lb=lb)
# $xmin
# [1] 0.6666667 1.3333333
# $fval
# [1] -8.222222
# $eflag
# [1] 1
</code></pre>

<hr>
<h2 id='quadv'>
Vectorized Integration
</h2><span id='topic+quadv'></span>

<h3>Description</h3>

<p>Vectorized adaptive Simpson integration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadv(f, a, b, tol = .Machine$double.eps^(1/2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadv_+3A_f">f</code></td>
<td>
<p>univariate, vector-valued function; need not be vectorized.</p>
</td></tr>
<tr><td><code id="quadv_+3A_a">a</code>, <code id="quadv_+3A_b">b</code></td>
<td>
<p>endpoints of the integration interval.</p>
</td></tr>
<tr><td><code id="quadv_+3A_tol">tol</code></td>
<td>
<p>acuracy required for the recursion step.</p>
</td></tr>
<tr><td><code id="quadv_+3A_...">...</code></td>
<td>
<p>further parameters to be passed to the function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recursive version of the adaptive Simpson quadrature, recursion is based
on the maximum of all components of the function calls.
</p>
<p><code>quad</code> is not suitable for functions with singularities in the
interval or at end points.
</p>


<h3>Value</h3>

<p>Returns a list with components <code>Q</code> the integral value, <code>fcnt</code>
the number of function calls, and <code>estim.prec</code> the estimated precision
that normally will be much too high.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quad">quad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Examples
f1 &lt;- function(x) c(sin(x), cos(x))
quadv(f1, 0, pi)
# $Q
#  [1] 2.000000e+00 1.110223e-16
# $fcnt
#  [1] 65
# $estim.prec
#  [1] 4.321337e-07

f2 &lt;- function(x) x^c(1:10)
quadv(f2, 0, 1, tol = 1e-12)
# $Q
#  [1] 0.50000000 0.33333333 0.25000000 0.20000000 0.16666667
#  [6] 0.14285714 0.12500000 0.11111111 0.10000000 0.09090909
# $fcnt
#  [1] 505
# $estim.prec
#  [1] 2.49e-10
</code></pre>

<hr>
<h2 id='quiver'>
Quiver or Velocity Plot
</h2><span id='topic+quiver'></span>

<h3>Description</h3>

<p>A quiver plot displays velocity vectors as arrows with components
<code>(u,v)</code> at the points <code>(x,y)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    quiver(x, y, u, v,
           scale = 0.05, angle = 10, length = 0.1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quiver_+3A_x">x</code>, <code id="quiver_+3A_y">y</code></td>
<td>
<p>x,y-coordinates of start points of the arrows.</p>
</td></tr>
<tr><td><code id="quiver_+3A_u">u</code>, <code id="quiver_+3A_v">v</code></td>
<td>
<p>x,y-coordinates of start points.</p>
</td></tr>
<tr><td><code id="quiver_+3A_scale">scale</code></td>
<td>
<p>scales the length of the arrows.</p>
</td></tr>
<tr><td><code id="quiver_+3A_angle">angle</code></td>
<td>
<p>angle between shaft and edge of the arrows.</p>
</td></tr>
<tr><td><code id="quiver_+3A_length">length</code></td>
<td>
<p>length of the arrow edges.</p>
</td></tr>
<tr><td><code id="quiver_+3A_...">...</code></td>
<td>
<p>more options presented to the <code>arrows</code> primitive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The matrices <code>x, y, u, v</code> must all be the same size and contain
corresponding position and velocity components.
However, x and y can also be vectors.
</p>


<h3>Value</h3>

<p>Opens a graph window and plots the velocity vectors.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vectorfield">vectorfield</a></code>, <code><a href="graphics.html#topic+arrows">arrows</a></code>
</p>

<hr>
<h2 id='rand'>Create Random Matrices</h2><span id='topic+rand'></span><span id='topic+randn'></span><span id='topic+randi'></span><span id='topic+randsample'></span><span id='topic+rands'></span><span id='topic+randp'></span>

<h3>Description</h3>

<p>Create random matrices or random points in a unit circle (Matlab style).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rand(n = 1, m = n)
randn(n = 1, m = n)
randi(imax, n = 1, m = n)
randsample(n, k, w = NULL, replacement = FALSE)

rands(n = 1, N = 1, r = 1)
randp(n = 1, r = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rand_+3A_n">n</code>, <code id="rand_+3A_m">m</code></td>
<td>
<p>integers specifying the size of the matrix</p>
</td></tr>
<tr><td><code id="rand_+3A_imax">imax</code></td>
<td>
<p>integer or pair of integers</p>
</td></tr>
<tr><td><code id="rand_+3A_k">k</code></td>
<td>
<p>number of elements to return.</p>
</td></tr>
<tr><td><code id="rand_+3A_w">w</code></td>
<td>
<p>weight vector, used for discrete probabilities.</p>
</td></tr>
<tr><td><code id="rand_+3A_replacement">replacement</code></td>
<td>
<p>logical; sampling with or without replacement.</p>
</td></tr>
<tr><td><code id="rand_+3A_n">N</code></td>
<td>
<p>dimension of a shere, N=1 for the unit circle</p>
</td></tr>
<tr><td><code id="rand_+3A_r">r</code></td>
<td>
<p>radius of circle, default 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rand()</code>, <code>randn()</code>, <code>randi()</code> create random matrices of
size <code>n x m</code>, where the default is square matrices if <code>m</code> is
missing.
</p>
<p><code>rand()</code> uses the uniform distribution on <code>]0, 1[</code>, while 
<code>randn()</code> uses the normal distribution with mean 0 and standard
deviation 1.
</p>
<p><code>randi()</code> generates integers between <code>imax[1]</code> and <code>imax[2]</code>
resp. 1 and <code>imax</code>, if <code>imax</code> is a scalar.
</p>
<p><code>randsample()</code> samples <code>k</code> elements from <code>1:n</code>, with or 
without replacement, or returns a weighted sample (with replacement),
using the weight vector <code>w</code> for probabilities.
</p>
<p><code>rands()</code> generates uniformly random points on an <code>N</code>-sphere in 
the <code>N+1</code>-dimensional space. To generate uniformly random points in the 
<code>N</code>-dim. unit cube, take points in <code>S^{N-1}</code> und multiply with
<code>unif(n)^(1/(N-1))</code>.
</p>
<p><code>randp()</code> generates uniformly random points in the unit circle (or in
a circle of radius r).
</p>


<h3>Value</h3>

<p>Matrices of size <code>nxm</code> resp. a vector of length <code>n</code>.
</p>
<p><code>randp()</code> returns a pair of values representing a point in the circle,
or a matrix of size <code>(n,2)</code>. <code>rands()</code> returns a matrix of size
<code>(n, N+1)</code> with all rows being vectors of length <code>1</code>.
</p>


<h3>Note</h3>

<p>The Matlab style of setting a seed is not available; use R style
<code>set.seed(...)</code>.
</p>


<h3>References</h3>

<p>Knuth, D. (1981). The Art of Computer programming; Vol. 2: Seminumerical
Algorithms; Chapt. 3: Random Numbers. Addison-Wesley, Reading.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+set.seed">set.seed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rand(3)
randn(1, 5)
randi(c(1,6), 1, 10)
randsample(10, 5, replacement = TRUE, w = c(0,0,0, 1, 1, 1, 1, 0,0,0))

P &lt;- rands(1000, N = 1, r = 2)
U &lt;- randp(1000, 2)
## Not run: 
plot(U[, 1], U[, 2], pch = "+", asp = 1)
points(P, pch = ".")
## End(Not run)

#-- v is 2 independent normally distributed elements
# u &lt;- randp(1); r &lt;- t(u) %*% u
# v &lt;- sqrt(-2 * log(r)/r) * u

n &lt;- 5000; U &lt;- randp(n)
R &lt;- apply(U*U, 1, sum)
P &lt;- sqrt(-2 * log(R)/R) * U  # rnorm(2*n)
## Not run: 
hist(c(P))
## End(Not run)
</code></pre>

<hr>
<h2 id='randcomb'>
Random Combination
</h2><span id='topic+randcomb'></span>

<h3>Description</h3>

<p>Generates a random combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randcomb(a, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randcomb_+3A_a">a</code></td>
<td>
<p>numeric vector of some length <code>n</code></p>
</td></tr>
<tr><td><code id="randcomb_+3A_m">m</code></td>
<td>
<p>integer with <code>0 &lt;= m &lt;= n</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates one random combination of the elements <code>a</code> of length
<code>m</code>.
</p>


<h3>Value</h3>

<p>vector of combined elements of <code>a</code>
</p>


<h3>Note</h3>

<p>This behavior is different from Matlab/Octave, but does better correspond
with the behavior of the perms() function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+combs">combs</a></code>, <code><a href="#topic+randperm">randperm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>randcomb(seq(2, 10, by=2), m = 3)
</code></pre>

<hr>
<h2 id='randortho'>
Generate Random Orthonormal or Unitary Matrix
</h2><span id='topic+randortho'></span>

<h3>Description</h3>

<p>Generates random orthonormal or unitary matrix of size <code>n</code>.
</p>
<p>Will be needed in applications that explore high-dimensional data spaces,
for example optimization procedures or Monte Carlo methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randortho(n, type = c("orthonormal", "unitary"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randortho_+3A_n">n</code></td>
<td>
<p>positive integer.</p>
</td></tr>
<tr><td><code id="randortho_+3A_type">type</code></td>
<td>
<p>orthonormal (i.e., real) or unitary (i.e., complex) matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates orthonormal or unitary matrices <code>Q</code>, that is
<code>t(Q)</code> resp <code>t(Conj(Q))</code> is inverse to <code>Q</code>. The randomness
is meant with respect to the (additively invariant) Haar measure on
<code class="reqn">O(n)</code> resp. <code class="reqn">U(n)</code>.
</p>
<p>Stewart (1980) describes a way to generate such matrices by applying
Householder transformation. Here a simpler approach is taken based on the
QR decomposition, see Mezzadri (2006),
</p>


<h3>Value</h3>

<p>Orthogonal (or unitary) matrix <code>Q</code> of size <code>n</code>, that is
<code>Q %*% t(Q)</code> resp. <code>Q %*% t(Conj(Q))</code> is the unit matrix
of size <code>n</code>.
</p>


<h3>Note</h3>

<p><code>rortho</code> was deprecated and eventually removed in version 2.1.7.
</p>


<h3>References</h3>

<p>G. W. Stewart (1980). &ldquo;The Efficient Generation of Random Orthogonal Matrices
with an Application to Condition Estimators&rdquo;.
SIAM Journal on Numerical Analysis, Vol. 17, No. 3, pp. 403-409.
</p>
<p>F. Mezzadri (2006). &ldquo;How to generate random matrices from the classical
compact groups&rdquo;. NOTICES of the AMS, Vol. 54 (2007), 592-604.
(arxiv.org/abs/math-ph/0609050v2)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Q &lt;- randortho(5)
zapsmall(Q %*% t(Q))
zapsmall(t(Q) %*% Q)
</code></pre>

<hr>
<h2 id='randperm'>
Random Permutation
</h2><span id='topic+randperm'></span>

<h3>Description</h3>

<p>Generates a random permutation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randperm(a, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randperm_+3A_a">a</code></td>
<td>
<p>integer or numeric vector of some length <code>n</code>.</p>
</td></tr>
<tr><td><code id="randperm_+3A_k">k</code></td>
<td>
<p>integer, smaller as <code>a</code> or <code>length(a)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates one random permutation of <code>k</code> of the elements <code>a</code>, if
<code>a</code> is a vector, or of <code>1:a</code> if <code>a</code> is a single integer.
</p>


<h3>Value</h3>

<p>Vector of permuted elements of <code>a</code> or <code>1:a</code>.
</p>


<h3>Note</h3>

<p>This behavior is different from Matlab/Octave, but does better correspond
with the behavior of the perms() function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perms">perms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>randperm(1:6, 3)
randperm(6, 6)
randperm(11:20, 5)
randperm(seq(2, 10, by=2))
</code></pre>

<hr>
<h2 id='Rank'>
Matrix Rank
</h2><span id='topic+Rank'></span>

<h3>Description</h3>

<p>Provides an estimate of the rank of a matrix <code>M</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rank(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rank_+3A_m">M</code></td>
<td>
<p>Numeric matrix; vectors will be considered as column vectors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides an estimate of the number of linearly independent rows or columns
of a matrix <code>M</code>. Compares an approach using QR-decomposition with one
counting singular values larger than a certain tolerance (Matlab).
</p>


<h3>Value</h3>

<p>Matrix rank as integer between <code>0</code> and <code>min(ncol(M), nrow(M))</code>.
</p>


<h3>Note</h3>

<p>The corresponding function in Matlab is called <code>rank</code>, but that term
has a different meaning in R.
</p>


<h3>References</h3>

<p>Trefethen, L. N., and D. Bau III. (1997). Numerical Linear Algebra. SIAM,
Philadelphia. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nullspace">nullspace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Rank(magic(10))   #=&gt; 7
Rank(magic(100))  #=&gt; 3 (!)
Rank(hilb(8))     #=&gt; 8 , but qr(hilb(8))$rank says, rank is 7.
# Warning message:
# In Rank(hilb(8)) : Rank calculation may be problematic.
</code></pre>

<hr>
<h2 id='rat'>
Continuous Fractions (Matlab Style)
</h2><span id='topic+rat'></span><span id='topic+rats'></span>

<h3>Description</h3>

<p>Generate continuous fractions for numeric values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rat(x, tol = 1e-06)
rats(x, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rat_+3A_x">x</code></td>
<td>
<p>a numeric scalar or vector.</p>
</td></tr>
<tr><td><code id="rat_+3A_tol">tol</code></td>
<td>
<p>tolerance; default <code>1e-6</code> to make a nicer appearance for
<code>pi</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rat</code> generates continuous fractions, while <code>rats</code> prints the
the corresponding rational representation and returns the numeric values.
</p>


<h3>Value</h3>

<p><code>rat</code> returns a character vector of string representations of
continuous fractions in the format <code>[b0; b1, ..., b_{n-1}]</code>.
</p>
<p><code>rats</code> prints the rational number and returns a numeric vector.
</p>


<h3>Note</h3>

<p>Essentially, these functions apply <code>contfrac</code>.
</p>


<h3>See Also</h3>

<p><code>numbers::contfrac</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rat(pi)
rats(pi)
rat(sqrt(c(2, 3, 5)),  tol = 1e-15)
rats(sqrt(c(2, 3, 5)), tol = 1e-15)
</code></pre>

<hr>
<h2 id='ratinterp'>
Rational Interpolation
</h2><span id='topic+ratinterp'></span>

<h3>Description</h3>

<p>Burlisch-Stoer rational interpolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratinterp(x, y, xs = x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ratinterp_+3A_x">x</code></td>
<td>
<p>numeric vector; points on the x-axis; needs to be sorted;
at least three points required.</p>
</td></tr>
<tr><td><code id="ratinterp_+3A_y">y</code></td>
<td>
<p>numeric vector; values of the assumed underlying function;
<code>x</code> and <code>y</code> must be of the same length.</p>
</td></tr>
<tr><td><code id="ratinterp_+3A_xs">xs</code></td>
<td>
<p>numeric vector; points at which to compute the interpolation;
all points must lie between <code>min(x)</code> and <code>max(x)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Burlisch-Stoer approach to rational interpolation is a recursive
procedure (similar to the Newton form of polynomial interpolation) that
produces a &ldquo;diagonal&rdquo; rational function, that is the degree of the
numerator is either the same or one less than the degree of the denominator.
</p>
<p>Polynomial interpolation will have difficulties if some kind of singularity
exists in the neighborhood, even if the pole occurs in the complex plane.
For instance, Runge's function has a pole at <code class="reqn">z = 0.2 i</code>, quite close
to the interval <code class="reqn">[-1, 1]</code>.
</p>


<h3>Value</h3>

<p>Numeric vector representing values at points <code>xs</code>.
</p>


<h3>Note</h3>

<p>The algorithm does not yield a simple algebraic expression for the
rational function found.
</p>


<h3>References</h3>

<p>Stoer, J., and R. Bulirsch (2002). Introduction to Numerical Analysis.
Third Edition, Springer-Verlag, New York.
</p>
<p>Fausett, L. V. (2008). Applied Numerical Analysis Using Matlab.
Second Edition, Pearson Education.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rationalfit">rationalfit</a></code>, <code><a href="#topic+pade">pade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Rational interpolation of Runge's function
x &lt;- c(-1, -0.5, 0, 0.5, 1.0)
y &lt;- runge(x)
xs &lt;- linspace(-1, 1)
ys &lt;- runge(xs)
yy &lt;- ratinterp(x, y, xs)  # returns exactly the Runge function

## Not run: 
plot(xs, ys, type="l", col="blue", lty = 2, lwd = 3)
points(x, y)
yy &lt;- ratinterp(x, y, xs)
lines(xs, yy, col="red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='rationalfit'>
Rational Function Approximation
</h2><span id='topic+rationalfit'></span>

<h3>Description</h3>

<p>Fitting a rational function to data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rationalfit(x, y, d1 = 5, d2 = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rationalfit_+3A_x">x</code></td>
<td>
<p>numeric vector; points on the x-axis; needs to be sorted;
at least three points required.</p>
</td></tr>
<tr><td><code id="rationalfit_+3A_y">y</code></td>
<td>
<p>numeric vector; values of the assumed underlying function;
<code>x</code> and <code>y</code> must be of the same length.</p>
</td></tr>
<tr><td><code id="rationalfit_+3A_d1">d1</code>, <code id="rationalfit_+3A_d2">d2</code></td>
<td>
<p>maximal degrees of numerator (<code>d1</code>) and denominator
(<code>d1</code>) of the requested rational function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A rational fit is a rational function of two polynomials <code>p1</code> and
<code>p2</code> (of user specified degrees <code>d1</code> and <code>d2</code>) such that
<code>p1(x)/p2(x)</code> approximates <code>y</code> in a least squares sense.
</p>
<p><code>d1</code> and <code>d2</code> must be large enough to get a good fit and usually
<code>d1=d2</code> gives good results
</p>


<h3>Value</h3>

<p>List with components <code>p1</code> and <code>p2</code> for the polynomials in
numerator and denominator of the rational function.
</p>


<h3>Note</h3>

<p>This implementation will later be replaced by a 'barycentric rational
interpolation'.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 2006 by Paul Godfrey for a Matlab version available from the
MatlabCentral under BSD license. R re-implementation by Hans W Borchers.
</p>


<h3>References</h3>

<p>Press, W. H., S. A. Teukolsky, W. T Vetterling, and B. P. Flannery (2007).
Numerical Recipes: The Art of Numerical Computing. Third Edition,
Cambridge University Press, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ratinterp">ratinterp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- linspace(0, 15, 151); y &lt;- sin(x)/x
rA &lt;- rationalfit(x, y, 10, 10); p1 &lt;- rA$p1; p2 &lt;- rA$p2
ys &lt;- polyval(p1,x) / polyval(p2,x)
plot(x, y, type="l", col="blue", ylim=c(-0.5, 1.0))
points(x, Re(ys), col="red")  # max(abs(y-ys), na.rm=TRUE) &lt; 1e-6
grid()

# Rational approximation of the Zeta function
x &lt;- seq(-5, 5, by = 1/16)
y &lt;- zeta(x)
rA &lt;- rationalfit(x, y, 10, 10); p1 &lt;- rA$p1; p2 &lt;- rA$p2
ys &lt;- polyval(p1,x) / polyval(p2,x)
plot(x, y, type="l", col="blue", ylim=c(-5, 5))
points(x, Re(ys), col="red")
grid()

# Rational approximation to the Gamma function
x &lt;- seq(-5, 5, by = 1/32); y &lt;- gamma(x)
rA &lt;- rationalfit(x, y, 10, 10); p1 &lt;- rA$p1; p2 &lt;- rA$p2
ys &lt;- polyval(p1,x) / polyval(p2,x)
plot(x, y, type="l", col = "blue")
points(x, Re(ys), col="red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='rectint'>
Rectangle Intersection Areas
</h2><span id='topic+rectint'></span>

<h3>Description</h3>

<p>Calculates the area of intersection of rectangles, specified by position
vectors <code>x</code> and <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rectint(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rectint_+3A_x">x</code>, <code id="rectint_+3A_y">y</code></td>
<td>
<p>both vectors of length 4, or both matrices with 4 columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rectangles are specified as position vectors, that is <code>c(x[1],x[2])</code>
is the lower left corner, <code>x[3]</code> and <code>x[4]</code> are width and height
of the rectangle. When <code>x</code> and <code>y</code> are matrices, each row is
assumed to be a position vector specifying a rectangle.
</p>


<h3>Value</h3>

<p>Returns a scalar if <code>x</code> and <code>y</code> are vectors. If <code>x</code> is
a <code>n-by-4</code> and <code>y</code> a <code>m-by-4</code> matrix, then it returns
a <code>n-by-m</code> matrix <code>R</code> with entry <code>(i,j)</code> being the area
<code>rectint(x[i,], y[j,])</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyarea">polyarea</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0.5, 0.5, 0.25, 1.00)
y &lt;- c(0.3, 0.3, 0.35, 0.75)
rectint(x, y)
# [1] 0.0825
</code></pre>

<hr>
<h2 id='refindall'>
Find overlapping regular expression matches.
</h2><span id='topic+refindall'></span>

<h3>Description</h3>

<p>Find overlapping matches for a regular expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>refindall(s, pat, over = 1, ignorecase = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="refindall_+3A_s">s</code></td>
<td>
<p>Single character string.</p>
</td></tr>
<tr><td><code id="refindall_+3A_pat">pat</code></td>
<td>
<p>Regular expression.</p>
</td></tr>
<tr><td><code id="refindall_+3A_over">over</code></td>
<td>
<p>Natural number, indication how many steps to go forward
after a match; defaults to 1.</p>
</td></tr>
<tr><td><code id="refindall_+3A_ignorecase">ignorecase</code></td>
<td>
<p>logical, whether to ignore case.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the starting position of all &mdash; even overlapping &mdash; matches
of the regular expression <code>pat</code> in the character string <code>s</code>.
</p>
<p>The syntax for pattern matching has to be PERL-like.
</p>


<h3>Value</h3>

<p>A numeric vector with the indices of starting positions of all matches.
</p>


<h3>Note</h3>

<p>This effect can also be reached with the R function gregexpr(), see the
example below.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regexp">regexp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>refindall("ababababa", 'aba')
gregexpr('a(?=ba)', "ababababa", perl=TRUE)

refindall("AbababaBa", 'aba')
refindall("AbababaBa", 'aba', ignorecase = TRUE)
</code></pre>

<hr>
<h2 id='regexp'>
Match regular expression
</h2><span id='topic+regexp'></span><span id='topic+regexpi'></span>

<h3>Description</h3>

<p>Returns the positions of substrings that match the regular expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regexp(s, pat, ignorecase = FALSE, once = FALSE, split = FALSE)

regexpi(s, pat, once = FALSE, split = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regexp_+3A_s">s</code></td>
<td>
<p>Character string, i.e. of length 1.</p>
</td></tr>
<tr><td><code id="regexp_+3A_pat">pat</code></td>
<td>
<p>Matching pattern as character string.</p>
</td></tr>
<tr><td><code id="regexp_+3A_ignorecase">ignorecase</code></td>
<td>
<p>Logical: whether case should be ignored;
default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="regexp_+3A_once">once</code></td>
<td>
<p>Logical: whether the first are all occurrences should be found;
default: all.</p>
</td></tr>
<tr><td><code id="regexp_+3A_split">split</code></td>
<td>
<p>Logical: should the string be splitted at the occurrences of
the pattern?; default: no.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the start and end positions and the exact value of substrings
that match the regular expression. If <code>split</code> is choosen, the
splitted strings will also be returned.
</p>


<h3>Value</h3>

<p>A list with components <code>start</code> and <code>end</code> as numeric vectors
indicating the start and end positions of the matches.
</p>
<p><code>match</code> contains each exact match, and <code>split</code> contains the
character vector of splitted strings.
</p>
<p>If no match is found all components will be <code>NULL</code>, except
<code>split</code> that will contain the whole string if <code>split = TRUE</code>.
</p>


<h3>Note</h3>

<p>This is the behavior of the corresponding Matlab function, though the
signature, options and return values do not match exactly.
Notice the transposed parameters <code>s</code> and <code>pat</code> compared to the
corresponding R function <code>regexpr</code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+regexpr">regexpr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- "bat cat can car COAT court cut ct CAT-scan"
pat &lt;-  'c[aeiou]+t'
regexp(s, pat)
regexpi(s, pat)
</code></pre>

<hr>
<h2 id='regexprep'>
Replace string using regular expression
</h2><span id='topic+regexprep'></span>

<h3>Description</h3>

<p>Replace string using regular expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regexprep(s, expr, repstr, ignorecase = FALSE, once = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regexprep_+3A_s">s</code></td>
<td>
<p>Single character string.</p>
</td></tr>
<tr><td><code id="regexprep_+3A_expr">expr</code></td>
<td>
<p>Regular expression to be matched.</p>
</td></tr>
<tr><td><code id="regexprep_+3A_repstr">repstr</code></td>
<td>
<p>String that replaces the matched substring(s).</p>
</td></tr>
<tr><td><code id="regexprep_+3A_ignorecase">ignorecase</code></td>
<td>
<p>logical, whether to ignore case.</p>
</td></tr>
<tr><td><code id="regexprep_+3A_once">once</code></td>
<td>
<p>logical, shall only the first or all occurences be replaced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Matches the regular expression against the string and replaces the first
or all non-overlapping occurrences with the replacement string.
</p>
<p>The syntax for regular expression has to be PERL-like.
</p>


<h3>Value</h3>

<p>String with substrings replaced.
</p>


<h3>Note</h3>

<p>The Matlab/Octave variant allows a character vector. This is not possible
here as it would make the return value quite complicated.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gsub">gsub</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- "bat cat can car COAT court cut ct CAT-scan"
pat &lt;-  'c[aeiou]+t'
regexprep(s, pat, '---')
regexprep(s, pat, '---', once = TRUE)
regexprep(s, pat, '---', ignorecase = TRUE)
</code></pre>

<hr>
<h2 id='repmat'>Replicate Matrix</h2><span id='topic+repmat'></span>

<h3>Description</h3>

<p>Replicate and tile matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repmat(a, n, m = n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repmat_+3A_a">a</code></td>
<td>
<p>vector or matrix to be replicated.</p>
</td></tr>
<tr><td><code id="repmat_+3A_n">n</code>, <code id="repmat_+3A_m">m</code></td>
<td>
<p>number of times to replicate in each dimension.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>repmat(a,m,n)</code> creates a large matrix consisting of an m-by-n tiling
of copies of <code>a</code>. 
</p>


<h3>Value</h3>

<p>Returns matrix with value <code>a</code> replicated to the number of times
in each dimension specified.
Defaults to square if dimension argument resolves to a single value.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+Reshape">Reshape</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>repmat(1, 3)                  # same as ones(3)
repmat(1, 3, 3)
repmat(matrix(1:4, 2, 2), 3)
</code></pre>

<hr>
<h2 id='Reshape'>Reshape Matrix</h2><span id='topic+Reshape'></span>

<h3>Description</h3>

<p>Reshape matrix or vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Reshape(a, n, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Reshape_+3A_a">a</code></td>
<td>
<p>matrix or vector</p>
</td></tr>
<tr><td><code id="Reshape_+3A_n">n</code>, <code id="Reshape_+3A_m">m</code></td>
<td>
<p>size of the result</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Reshape(a, n, m)</code> returns the n-by-m matrix whose elements are taken
column-wise from <code>a</code>.
</p>
<p>An error results if <code>a</code> does not have <code>n*m</code> elements.
If <code>m</code> is missing, it will be calculated from <code>n</code> and the
size of <code>a</code>.
</p>


<h3>Value</h3>

<p>Returns matrix (or array) of the requested size containing the elements
of <code>a</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix(1:12, nrow=4, ncol=3)
Reshape(a, 6, 2)
Reshape(a, 6)     # the same
Reshape(a, 3, 4)
</code></pre>

<hr>
<h2 id='ridders'>
Ridders' Root Finding Method
</h2><span id='topic+ridders'></span>

<h3>Description</h3>

<p>Ridders' root finding method is a powerful variant of &lsquo;regula falsi&rsquo; (and
&lsquo;false position&rsquo;). In reliability and speed, this method is competitive
with Brent-Dekker and similar approaches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridders(fun, a, b, maxiter = 500, tol = 1e-12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ridders_+3A_fun">fun</code></td>
<td>
<p>function whose root is to be found.</p>
</td></tr>
<tr><td><code id="ridders_+3A_a">a</code>, <code id="ridders_+3A_b">b</code></td>
<td>
<p>left and right interval bounds.</p>
</td></tr>
<tr><td><code id="ridders_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations (function calls).</p>
</td></tr>
<tr><td><code id="ridders_+3A_tol">tol</code></td>
<td>
<p>tolerance, length of the last interval.</p>
</td></tr>
<tr><td><code id="ridders_+3A_...">...</code></td>
<td>
<p>additional parameters passed on to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a bracketing interval $[x_1, x_2]$, the method first calculates the
midpoint <code class="reqn">x_3 = (x_1 + x_2)/2</code> and the uses an updating formula
</p>
<p style="text-align: center;"><code class="reqn">x_4 = x_3 + (x_3 - x_1) \frac{sgn(f(x_1) - f(x_2)) f(x_3)}{\sqrt{f(x_3)^2 - f(x_1) f(x_2)}}</code>
</p>
 


<h3>Value</h3>

<p>Returns a list with components
</p>
<table>
<tr><td><code>root</code></td>
<td>
<p>root of the function.</p>
</td></tr>
<tr><td><code>f.root</code></td>
<td>
<p>value of the function at the found root.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>number of iterations,or more specifically: number of function calls.</p>
</td></tr>
<tr><td><code>estim.prec</code></td>
<td>
<p>the estimated precision, coming from the last brackett.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See function <code>f12</code> whose zero at <code class="reqn">\sqrt{e}</code> is difficult to find
exactly for all root finders.
</p>


<h3>Author(s)</h3>

<p>HwB  email: &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Press, Teukolsky, Vetterling, and Flannery (1992). Numerical Recipes in C.
Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+brent">brent</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Test functions
f1  &lt;- function(x)                          # [0, 1.2],     0.399 422 2917
            x^2 * (x^2/3 + sqrt(2)*sin(x)) - sqrt(3)/18
f2  &lt;- function(x) 11*x^11 - 1              # [0.4, 1.6],   0.804 133 0975
f3  &lt;- function(x) 35*x^35 - 1              # [-0.5, 1.9],  0.903 407 6632
f4  &lt;- function(x)                          # [-0.5, 0.7],  0.077 014 24135
            2*(x*exp(-9) - exp(-9*x)) + 1 
f5  &lt;- function(x) x^2 - (1 - x)^9          # [-1.4, 1],    0.259 204 4937
f6  &lt;- function(x) (x-1)*exp(-9*x) + x^9    # [-0.8, 1.6],  0.536 741 6626
f7  &lt;- function(x) x^2 + sin(x/9) - 1/4     # [-0.5, 1.9],  0.4475417621
f8  &lt;- function(x) 1/8 * (9 - 1/x)        # [0.001, 1.201], 0.111 111 1111 
f9  &lt;- function(x) tan(x) - x - 0.0463025   # [-0.9, 1.5],  0.500 000 0340
f10 &lt;- function(x)                          # [0.4, 1],     0.679 808 9215
            x^2 + x*sin(sqrt(75)*x) - 0.2
f11 &lt;- function(x) x^9 + 0.0001             # [-1.2, 0],   -0.359 381 3664 
f12 &lt;- function(x)                          # [1, 3.4],     1.648 721 27070
            log(x) + x^2/(2*exp(1)) - 2 * x/sqrt(exp(1)) + 1

r &lt;- ridders(f1 , 0, 1.2);       r$root; r$niter # 18
r &lt;- ridders(f2 , 0.4, 1.6);     r$root; r$niter # 14
r &lt;- ridders(f3 ,-0.5, 1.9);     r$root; r$niter # 20
r &lt;- ridders(f4 ,-0.5, 0.7);     r$root; r$niter # 12
r &lt;- ridders(f5 ,-1.4, 1);       r$root; r$niter # 16
r &lt;- ridders(f6 ,-0.8, 1.6);     r$root; r$niter # 20
r &lt;- ridders(f7 ,-0.5, 1.9);     r$root; r$niter # 16
r &lt;- ridders(f8 ,0.001, 1.201);  r$root; r$niter # 18
r &lt;- ridders(f9 ,-0.9, 1.5);     r$root; r$niter # 20
r &lt;- ridders(f10,0.4, 1);        r$root; r$niter # 14
r &lt;- ridders(f11,-1.2, 0);       r$root; r$niter # 12
r &lt;- ridders(f12,1, 3.4);        r$root; r$niter # 30, err = 1e-5

## Not run: 
##  Use ridders() with Rmpfr
options(digits=16)
library("Rmpfr") # unirootR
prec &lt;- 256
.N &lt;- function(.) mpfr(., precBits = prec)

f12 &lt;- function(x) {
    e1 &lt;- exp(.N(1))
    log(x) + x^2/(2*e1) - 2*x/sqrt(e1) + 1
}
sqrte &lt;- sqrt(exp(.N(1)))  # 1.648721270700128...
f12(sqrte)                 # 0

unirootR(f12, interval=mpfr(c(1, 3.4), prec), tol=1e-20)
# $root
# 1 'mpfr' number of precision  200   bits 
# [1] 1.648721270700128...

ridders(f12, .N(1), .N(3.4), maxiter=200, tol=1e-20)
# $root
# 1 'mpfr' number of precision  200   bits 
# [1] 1.648721270700128...

## End(Not run)
</code></pre>

<hr>
<h2 id='rk4+2C+20rk4sys'>
Classical Runge-Kutta
</h2><span id='topic+rk4'></span><span id='topic+rk4sys'></span>

<h3>Description</h3>

<p>Classical Runge-Kutta of order 4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rk4(f, a, b, y0, n)

rk4sys(f, a, b, y0, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rk4+2B2C+2B20rk4sys_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y' = f(x, y)</code>;<br />
defined as a function <code class="reqn">R \times R^m \rightarrow R^m</code>, where <code class="reqn">m</code>
is the number of equations.</p>
</td></tr>
<tr><td><code id="rk4+2B2C+2B20rk4sys_+3A_a">a</code>, <code id="rk4+2B2C+2B20rk4sys_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="rk4+2B2C+2B20rk4sys_+3A_y0">y0</code></td>
<td>
<p>starting values; for <code class="reqn">m</code> equations <code>y0</code> needs to be
a vector of length <code>m</code>.</p>
</td></tr>
<tr><td><code id="rk4+2B2C+2B20rk4sys_+3A_n">n</code></td>
<td>
<p>the number of steps from <code>a</code> to <code>b</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Classical Runge-Kutta of order 4 for (systems of) ordinary differential
equations with fixed step size.
</p>


<h3>Value</h3>

<p>List with components <code>x</code> for grid points between <code>a</code> and <code>b</code>
and <code>y</code> an n-by-m matrix with solutions for variables in columns, i.e.
each row contains one time stamp.
</p>


<h3>Note</h3>

<p>This function serves demonstration purposes only.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ode23">ode23</a></code>, <code><a href="#topic+deval">deval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Example1: ODE
# y' = y*(-2*x + 1/x) for x != 0, 1 if x = 0
# solution is x*exp(-x^2)
f &lt;- function(x, y) {
	if (x != 0) dy &lt;- y * (- 2*x + 1/x)
	else        dy &lt;- rep(1, length(y))
	return(dy)
}
sol &lt;- rk4(f, 0, 2, 0, 50)
## Not run: 
x &lt;- seq(0, 2, length.out = 51)
plot(x, x*exp(-x^2), type = "l", col = "red")
points(sol$x, sol$y, pch = "*")
grid()
## End(Not run)

##  Example2: Chemical process
  f &lt;- function(t, u) {
    u1 &lt;- u[3] - 0.1 * (t+1) * u[1]
    u2 &lt;- 0.1 * (t+1) * u[1] - 2 * u[2]
    u3 &lt;- 2 * u[2] - u[3]
    return(c(u1, u2, u3))
  }
u0 &lt;- c(0.8696, 0.0435, 0.0870)
a &lt;- 0; b &lt;- 40
n &lt;- 40
sol &lt;- rk4sys(f, a, b, u0, n)
## Not run: 
matplot(sol$x, sol$y, type = "l", lty = 1, lwd = c(2, 1, 1),
        col = c("darkred", "darkblue", "darkgreen"),
        xlab = "Time [min]", ylab= "Concentration [Prozent]",
        main = "Chemical composition")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='rkf54'>
Runge-Kutta-Fehlberg
</h2><span id='topic+rkf54'></span>

<h3>Description</h3>

<p>Runge-Kutta-Fehlberg with adaptive step size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rkf54(f, a, b, y0, tol = .Machine$double.eps^0.5,
                   control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rkf54_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y' = f(x, y)</code>.</p>
</td></tr>
<tr><td><code id="rkf54_+3A_a">a</code>, <code id="rkf54_+3A_b">b</code></td>
<td>
<p>endpoints of the interval.</p>
</td></tr>
<tr><td><code id="rkf54_+3A_y0">y0</code></td>
<td>
<p>starting values at <code>a</code>.</p>
</td></tr>
<tr><td><code id="rkf54_+3A_tol">tol</code></td>
<td>
<p>relative tolerance, used for determining the step size.</p>
</td></tr>
<tr><td><code id="rkf54_+3A_control">control</code></td>
<td>
<p>list for influencing the step size with components<br />
<code>hmin, hmax</code>, the minimal, maximal step size<br />
<code>jmax</code>, the maximally allowed number of steps.</p>
</td></tr>
<tr><td><code id="rkf54_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Runge-Kutta-Fehlberg is a kind of Runge-Kutta method of solving ordinary
differential equations of order (5, 4) with variable step size.
</p>
<p>&ldquo;At each step, two different approximations for the solution are made and
compared.  If the two answers are in close agreement, the approximation is
accepted. If the two answers do not agree to a specified accuracy, the step
size is reduced.  If the answers agree to more significant digits than
required, the step size is increased.&rdquo;
</p>
<p>Some textbooks promote the idea to use the five-order formula as the
accepted value instead of using it for error estimation. This approach
is taken here, that is why the function is called <code>rkf54</code>. The idea
is still debated as the accuracy determinations appears to be diminished.
</p>


<h3>Value</h3>

<p>List with components <code>x</code> for grid points between <code>a</code> and <code>b</code>
and <code>y</code> the function values of the numerical solution.
</p>


<h3>Note</h3>

<p>This function serves demonstration purposes only.
</p>


<h3>References</h3>

<p>Stoer, J., and R. Bulirsch (2002). Introduction to Numerical Analysis.
Third Edition, Springer-Verlag, New York.
</p>
<p>Mathematica code associated with the book:<br />
Mathews, J. H., and K. D. Fink (2004). Numerical Methods Using Matlab.
Fourth Edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rk4">rk4</a></code>, <code><a href="#topic+ode23">ode23</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: y' = 1 + y^2
f1 &lt;- function(x, y)  1 + y^2
sol11 &lt;- rkf54(f1, 0, 1.1, 0.5, control = list(hmin = 0.01))
sol12 &lt;- rkf54(f1, 0, 1.1, 0.5, control = list(jmax =  250))

# Riccati equation: y' = x^2 + y^2
f2 &lt;- function(x, y)  x^2 + y^2
sol21 &lt;- rkf54(f2, 0, 1.5, 0.5, control = list(hmin = 0.01))
sol22 &lt;- rkf54(f2, 0, 1.5, 0.5, control = list(jmax =  250))

## Not run: 
plot(0, 0, type = "n", xlim = c(0, 1.5), ylim = c(0, 20),
     main = "Riccati", xlab = "", ylab = "")
points(sol11$x, sol11$y, pch = "*", col = "darkgreen")
lines(sol12$x, sol12$y)
points(sol21$x, sol21$y, pch = "*", col = "blue")
lines(sol22$x, sol22$y)
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='rmserr'>
Accuracy Measures
</h2><span id='topic+rmserr'></span>

<h3>Description</h3>

<p>Calculates different accuracy measures, most prominently RMSE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmserr(x, y, summary = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmserr_+3A_x">x</code>, <code id="rmserr_+3A_y">y</code></td>
<td>
<p>two vectors of real numbers</p>
</td></tr>
<tr><td><code id="rmserr_+3A_summary">summary</code></td>
<td>
<p>logical; should a summary be printed to the screen?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates six different measures of accuracy for two given vectors or
sequences of real numbers:
</p>

<table>
<tr>
 <td style="text-align: left;">
  MAE  </td><td style="text-align: left;"> Mean Absolute Error</td>
</tr>
<tr>
 <td style="text-align: left;">
  MSE  </td><td style="text-align: left;"> Mean Squared Error</td>
</tr>
<tr>
 <td style="text-align: left;">
  RMSE </td><td style="text-align: left;"> Root Mean Squared Error</td>
</tr>
<tr>
 <td style="text-align: left;">
  MAPE </td><td style="text-align: left;"> Mean Absolute Percentage Error</td>
</tr>
<tr>
 <td style="text-align: left;">
  LMSE </td><td style="text-align: left;"> Normalized Mean Squared Error</td>
</tr>
<tr>
 <td style="text-align: left;">
  rSTD </td><td style="text-align: left;"> relative Standard Deviation
  </td>
</tr>

</table>



<h3>Value</h3>

<p>Returns a list with different accuracy measures.
</p>


<h3>Note</h3>

<p>Often used in Data Mining for <em>predicting</em> the accuracy of predictions.
</p>


<h3>References</h3>

<p>Gentle, J. E. (2009). Computational Statistics, section 10.3.
Springer Science+Business Media LCC, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rep(1, 10)
y &lt;- rnorm(10, 1, 0.1)
rmserr(x, y, summary = TRUE)
</code></pre>

<hr>
<h2 id='romberg'>
Romberg Integration
</h2><span id='topic+romberg'></span>

<h3>Description</h3>

<p>Romberg Integration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>romberg(f, a, b, maxit = 25, tol = 1e-12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="romberg_+3A_f">f</code></td>
<td>
<p>function to be integrated.</p>
</td></tr>
<tr><td><code id="romberg_+3A_a">a</code>, <code id="romberg_+3A_b">b</code></td>
<td>
<p>end points of the interval.</p>
</td></tr>
<tr><td><code id="romberg_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="romberg_+3A_tol">tol</code></td>
<td>
<p>requested tolerance.</p>
</td></tr>
<tr><td><code id="romberg_+3A_...">...</code></td>
<td>
<p>variables to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simple Romberg integration with an explicit Richardson method applied
to a series of trapezoidal integrals. This scheme works best with smooth
and non-oscillatory functions and needs the least number of function calls
among all integration routines.
</p>
<p>The function does <em>not</em> need to be vectorized.
</p>


<h3>Value</h3>

<p>List of value, number or iterations, and relative error.
</p>


<h3>Note</h3>

<p>Using a trapezoid formula Romberg integration will use
<code>2*(2^iter-1)+iter</code> function calls. By remembering function values
this could be reduced to <code>2^iter+1</code> calls.
</p>


<h3>References</h3>

<p>Chapra, S. C., and R. P. Canale (2006). Numerical Methods for Engineers.
Fifth Edition, McGraw-Hill, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+quadgr">quadgr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>romberg(sin, 0, pi, tol = 1e-15)    #  2                 , rel.error 1e-15
romberg(exp, 0, 1,  tol = 1e-15)    #  1.718281828459044 , rel error 1e-15
                                    #  1.718281828459045 , i.e. exp(1) - 1

f &lt;- function(x, p) sin(x) * cos(p*x)
romberg(f, 0, pi, p = 2)            #  2/3               , abs.err 1.5e-14
# value: -0.6666667, iter: 7, rel.error: 1e-12
</code></pre>

<hr>
<h2 id='roots+2C+20polyroots'>Polynomial Roots</h2><span id='topic+roots'></span><span id='topic+rootsmult'></span><span id='topic+polyroots'></span>

<h3>Description</h3>

<p>Computes the roots (and multiplicities) of a polynomial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  roots(p)
  polyroots(p, ntol = 1e-04, ztol = 1e-08)

  rootsmult(p, r, tol=1e-12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roots+2B2C+2B20polyroots_+3A_p">p</code></td>
<td>
<p>vector of real or complex numbers representing the polynomial.</p>
</td></tr>
<tr><td><code id="roots+2B2C+2B20polyroots_+3A_r">r</code></td>
<td>
<p>a possible root of the polynomial.</p>
</td></tr>
<tr><td><code id="roots+2B2C+2B20polyroots_+3A_tol">tol</code>, <code id="roots+2B2C+2B20polyroots_+3A_ntol">ntol</code>, <code id="roots+2B2C+2B20polyroots_+3A_ztol">ztol</code></td>
<td>
<p>norm tolerance and accuracy for polyroots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>roots</code> computes roots of a polynomial as eigenvalues 
of the companion matrix. 
</p>
<p><code>polyroots</code> attempts to refine the results of <code>roots</code> with special 
attention to multiple roots. For a reference of this implementation see 
F. C. Chang, &quot;Solving multiple-root polynomials&quot;, 
IEEE Antennas and Propagation Magazine Vol. 51, No. 6 (2010), pp. 151-155.
</p>
<p><code>rootsmult</code> determines te order of a possible root <code>r</code>. As this 
computation is problematic in double precision, the result should be taken 
with a grain of salt.
</p>


<h3>Value</h3>

<p><code>roots</code> returns a vector holding the roots of the polynomial, 
<code>rootsmult</code> the multiplicity of a root as an integer. And 
<code>polyroots</code> returns a data frame witha column 'root' and a column 
'mult' giving the multiplicity of that root.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+polyroot">polyroot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  roots(c(1, 0, 1, 0, 0))                     # 0 0 1i -1i
  p &lt;- Poly(c(-2, -1, 0, 1, 2))               # 1*x^5 - 5*x^3 + 4*x
  roots(p)                                    # 0 -2  2 -1  1

  p &lt;- Poly(c(rep(1, 4), rep(-1, 4), 0, 0))   # 1  0 -4  0  6  0 -4  0  1
  rootsmult(p, 1.0); rootsmult(p, -1.0)       # 4  4
  polyroots(p)
  ##   root mult
  ## 1    0    2
  ## 2    1    4
  ## 3   -1    4
</code></pre>

<hr>
<h2 id='rosser'>Rosser Matrix</h2><span id='topic+rosser'></span>

<h3>Description</h3>

<p>Generate the Rosser matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rosser()
</code></pre>


<h3>Details</h3>

<p>This is a classic symmetric eigenvalue test problem.
It has a double eigenvalue, three nearly equal eigenvalues, dominant
eigenvalues of opposite sign, a zero eigenvalue, and a small, nonzero
eigenvalue.
</p>


<h3>Value</h3>

<p>matrix of size 8 x 8
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wilkinson">wilkinson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rosser()
</code></pre>

<hr>
<h2 id='rot90'>Matrix Rotation</h2><span id='topic+rot90'></span>

<h3>Description</h3>

<p>Rotate matrices for 90, 180, or 270 degrees..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rot90(a, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rot90_+3A_a">a</code></td>
<td>
<p>numeric or complex matrix</p>
</td></tr>
<tr><td><code id="rot90_+3A_k">k</code></td>
<td>
<p>scalar integer number of times the matrix will be rotated for
90 degrees; may be negative.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rotates a numeric or complex matrix for 90 (k = 1), 180 (k = 2) or
270 (k = 3 or k = -1) degrees.
</p>
<p>Value of k is taken mod 4.
</p>


<h3>Value</h3>

<p>the original matrix rotated
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix(1:12, nrow=3, ncol=4, byrow=TRUE)
rot90(a)
rot90(a, 2)
rot90(a, -1)
</code></pre>

<hr>
<h2 id='rref'>
Reduced Row Echelon Form
</h2><span id='topic+rref'></span>

<h3>Description</h3>

<p>Produces the reduced row echelon form of <code>A</code> using
Gauss Jordan elimination with partial pivoting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rref(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rref_+3A_a">A</code></td>
<td>
<p>numeric matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A matrix of &ldquo;row-reduced echelon form&quot; has the following characteristics:
</p>
<p>1. All zero rows are at the bottom of the matrix
</p>
<p>2. The leading entry of each nonzero row after the first occurs
to the right of the leading entry of the previous row.
</p>
<p>3. The leading entry in any nonzero row is 1.
</p>
<p>4. All entries in the column above and below a leading 1 are zero.
</p>
<p>Roundoff errors may cause this algorithm to compute a different value
for the rank than <code>rank</code>, <code>orth</code> or <code>null</code>.
</p>


<h3>Value</h3>

<p>A matrix the same size as <code>m</code>.
</p>


<h3>Note</h3>

<p>This serves demonstration purposes only; don't use for large matrices.
</p>


<h3>References</h3>

<p>Weisstein, Eric W. &ldquo;Echelon Form.&quot; From MathWorld &ndash; A Wolfram Web Resource.<br />
<a href="https://mathworld.wolfram.com/EchelonForm.html">https://mathworld.wolfram.com/EchelonForm.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+qr.solve">qr.solve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(1, 2, 3, 1, 3, 2, 3, 2, 1), 3, 3, byrow = TRUE)
rref(A)       
#      [,1] [,2] [,3]
# [1,]    1    0    0
# [2,]    0    1    0
# [3,]    0    0    1

A &lt;- matrix(data=c(1, 2, 3, 2, 5, 9, 5, 7, 8,20, 100, 200),
            nrow=3, ncol=4, byrow=FALSE)  
rref(A)
#   1    0    0  120
#   0    1    0    0
#   0    0    1  -20

# Use rref on a rank-deficient magic square:
A = magic(4)
R = rref(A)
zapsmall(R)
#   1    0    0    1
#   0    1    0    3
#   0    0    1   -3
#   0    0    0    0
</code></pre>

<hr>
<h2 id='runge'>Runge Function</h2><span id='topic+runge'></span>

<h3>Description</h3>

<p>Runge's test function for interpolation techniques.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runge(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runge_+3A_x">x</code></td>
<td>
<p>numeric scalar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Runge's function is a classical test function for interpolation and 
and approximation techniques, especially for equidistant nodes.
</p>
<p>For example, when approximating the Runge function on the interval
<code>[-1, 1]</code>, the error at the endpoints will diverge when the number
of nodes is increasing.
</p>


<h3>Value</h3>

<p>Numerical value of the function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fnorm">fnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(-1, 1, length.out = 101)
y &lt;- runge(x)
plot(x, y, type = "l", lwd = 2, col = "navy", ylim = c(-0.2, 1.2))
grid()

n &lt;- c(6, 11, 16)
for (i in seq(along=n)) {
    xp &lt;- seq(-1, 1, length.out = n[i])
    yp &lt;- runge(xp)
    p  &lt;- polyfit(xp, yp, n[i]-1)
    y  &lt;- polyval(p, x)
    lines(x, y, lty=i) }

## End(Not run)
</code></pre>

<hr>
<h2 id='savgol'>
Savitzky-Golay Smoothing
</h2><span id='topic+savgol'></span>

<h3>Description</h3>

<p>Polynomial filtering method of Savitzky and Golay.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>savgol(T, fl, forder = 4, dorder = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="savgol_+3A_t">T</code></td>
<td>
<p>Vector of signals to be filtered.</p>
</td></tr>
<tr><td><code id="savgol_+3A_fl">fl</code></td>
<td>
<p>Filter length (for instance fl = 51..151), has to be odd.</p>
</td></tr>
<tr><td><code id="savgol_+3A_forder">forder</code></td>
<td>
<p>Filter order (2 = quadratic filter, 4 = quartic).</p>
</td></tr>
<tr><td><code id="savgol_+3A_dorder">dorder</code></td>
<td>
<p>Derivative order (0 = smoothing, 1 = first derivative, etc.).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Savitzky-Golay smoothing performs a local polynomial regression on a
series of values which are treated as being equally spaced to determine
the smoothed value for each point.
Methods are also provided for calculating derivatives.
</p>


<h3>Value</h3>

<p>Vector representing the smoothed time series.
</p>


<h3>Note</h3>

<p>For derivatives T2 has to be divided by the step size to the order<br />
(and to be multiplied by k! &mdash; the sign appears to be wrong).
</p>


<h3>Author(s)</h3>

<p>Peter Riegler implemented a Matlab version in 2001. Based on this,
Hans W. Borchers published an R version in 2003.
</p>


<h3>References</h3>

<p>See Numerical Recipes, 1992, Chapter 14.8, for details.
</p>


<h3>See Also</h3>

<p><code>RTisean::sav_gol</code>, <code>signal::sgolayfilt</code>, <code><a href="#topic+whittaker">whittaker</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># *** Sinosoid test function ***
ts &lt;- sin(2*pi*(1:1000)/200)
t1 &lt;- ts + rnorm(1000)/10
t2 &lt;- savgol(t1, 51)
## Not run: 
plot( 1:1000, t1, col = "grey")
lines(1:1000, ts, col = "blue")
lines(1:1000, t2, col = "red")
## End(Not run)
</code></pre>

<hr>
<h2 id='segm_distance'>
Segment Distance
</h2><span id='topic+segm_distance'></span>

<h3>Description</h3>

<p>The minimum distance between a point and a segment, or the
minimum distance between points of two segments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segm_distance(p1, p2, p3, p4 = c())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segm_distance_+3A_p1">p1</code>, <code id="segm_distance_+3A_p2">p2</code></td>
<td>
<p>end points of the first segment.</p>
</td></tr>
<tr><td><code id="segm_distance_+3A_p3">p3</code>, <code id="segm_distance_+3A_p4">p4</code></td>
<td>
<p>end points of the second segment, or the point <code>p3</code>
alone if <code>p4</code> is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>p4=c()</code>, determines the orthogonal line to the segment through
the single point and computes the distance to the intersection point.
</p>
<p>Otherwise, it computes the distances of all four end points to the
other segment and takes the minimum of those.
</p>


<h3>Value</h3>

<p>Returns a list with component <code>l</code> the minimum distance and components
<code>p, q</code> the two nearest points.
</p>
<p>If <code>p4=c()</code> then point <code>p</code> lies on the segment and <code>q</code> is
<code>p4</code>.
</p>


<h3>Note</h3>

<p>The interfaces of <code>segm_intersect</code> and <code>segm_distance</code> should be
brought into line.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+segm_intersect">segm_intersect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plot(c(0, 1), c(0, 1), type = "n", asp=1, 
     xlab = "", ylab = "", main = "Segment Distances")
grid()
for (i in 1:20) {
    s1 &lt;- matrix(runif(4), 2, 2)
    s2 &lt;- matrix(runif(4), 2, 2)
    lines(s1[, 1], s1[, 2], col = "red")
    lines(s2[, 1], s2[, 2], col = "darkred")
    S &lt;- segm_distance(s1[1,], s1[2,], s2[1,], s2[2,])
    S$d
    points(c(S$p[1], S$q[1]), c(S$p[2], S$q[2]), pch=20, col="navy")
    lines(c(S$p[1], S$q[1]), c(S$p[2], S$q[2]), col="gray")
}
## End(Not run)
</code></pre>

<hr>
<h2 id='segm_intersect'>
Segment Intersection
</h2><span id='topic+segm_intersect'></span>

<h3>Description</h3>

<p>Do two segments have at least one point in common?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segm_intersect(s1, s2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segm_intersect_+3A_s1">s1</code>, <code id="segm_intersect_+3A_s2">s2</code></td>
<td>
<p>Two segments, represented by their end points; i.e.,
<code>s &lt;- rbind(p1, p2)</code> when <code>p1, p2</code> are the end points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First compares the &lsquo;bounding boxes&rsquo;, and if those intersect looks at
whether the other end points lie on different sides of each segment.
</p>


<h3>Value</h3>

<p>Logical, <code>TRUE</code> if these segments intersect.
</p>


<h3>Note</h3>

<p>Should be written without reference to the <code>cross</code> function.
Should also return the intersection point, see the example.
</p>


<h3>References</h3>

<p>Cormen, Th. H., Ch. E. Leiserson, and R. L. Rivest (2009). Introduction
to Algorithms. Third Edition, The MIT Press, Cambridge, MA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+segm_distance">segm_distance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plot(c(0, 1), c(0, 1), type="n",
     xlab = "", ylab = "", main = "Segment Intersection")
grid()
for (i in 1:20) {
s1 &lt;- matrix(runif(4), 2, 2)
s2 &lt;- matrix(runif(4), 2, 2)
if (segm_intersect(s1, s2)) {
    clr &lt;- "red"
    p1 &lt;- s1[1, ]; p2 &lt;- s1[2, ]; p3 &lt;- s2[1, ]; p4 &lt;- s2[2, ]
    A &lt;- cbind(p2 - p1, p4 - p3)
    b &lt;- (p3 - p1)
    a &lt;- solve(A, b)
    points((p1 + a[1]*(p2-p1))[1], (p1 + a[1]*(p2-p1))[2], pch = 19, col = "blue")
} else
    clr &lt;- "darkred"
lines(s1[,1], s1[, 2], col = clr)
lines(s2[,1], s2[, 2], col = clr)
}
## End(Not run)
</code></pre>

<hr>
<h2 id='semilogx+2Csemilogy'>
Semi-logarithmic Plots (Matlab Style)
</h2><span id='topic+semilogx'></span><span id='topic+semilogy'></span><span id='topic+loglog'></span>

<h3>Description</h3>

<p>Generates semi- and double-logarithmic plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semilogx(x, y, ...)
semilogy(x, y, ...)

loglog(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semilogx+2B2Csemilogy_+3A_x">x</code>, <code id="semilogx+2B2Csemilogy_+3A_y">y</code></td>
<td>
<p>x-, y-coordinates.</p>
</td></tr>
<tr><td><code id="semilogx+2B2Csemilogy_+3A_...">...</code></td>
<td>
<p>additional graphical parameters passed to the plot function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots data in logarithmic scales for the x-axis or y-axis, or uses
logarithmic scales in both axes, and adds grid lines.
</p>


<h3>Value</h3>

<p>Generates a plot, returns nothing.
</p>


<h3>Note</h3>

<p>Matlab's logarithmic plots find a more appropriate grid.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+plot">plot</a></code> with <code>log= </code> option.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- logspace(-1, 2)
loglog(x, exp(x), type = 'b')
## End(Not run)
</code></pre>

<hr>
<h2 id='shooting'>Shooting Method</h2><span id='topic+shooting'></span>

<h3>Description</h3>

<p>The shooting method solves the boundary value problem for 
second-order differential equations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shooting(f, t0, tfinal, y0, h, a, b,
         itermax = 20, tol = 1e-6, hmax = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shooting_+3A_f">f</code></td>
<td>
<p>function in the differential equation <code class="reqn">y'' = f(x, y, y')</code>.</p>
</td></tr>
<tr><td><code id="shooting_+3A_t0">t0</code>, <code id="shooting_+3A_tfinal">tfinal</code></td>
<td>
<p>start and end points of the interval.</p>
</td></tr>
<tr><td><code id="shooting_+3A_y0">y0</code></td>
<td>
<p>starting value of the solution.</p>
</td></tr>
<tr><td><code id="shooting_+3A_h">h</code></td>
<td>
<p>function defining the boundary condition as a function at the
end point of the interval.</p>
</td></tr>
<tr><td><code id="shooting_+3A_a">a</code>, <code id="shooting_+3A_b">b</code></td>
<td>
<p>two guesses of the derivative at the start point.</p>
</td></tr>
<tr><td><code id="shooting_+3A_itermax">itermax</code></td>
<td>
<p>maximum number of iterations for the secant method.</p>
</td></tr>
<tr><td><code id="shooting_+3A_tol">tol</code></td>
<td>
<p>tolerance to be used for stopping and in the <code>ode45</code>
solver.</p>
</td></tr>
<tr><td><code id="shooting_+3A_hmax">hmax</code></td>
<td>
<p>maximal step size, to be passed to the solver.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A second-order differential equation is solved with boundary conditions
<code>y(t0) = y0</code> at the start point of the interval, and
<code>h(y(tfinal), dy/dt(tfinal)) = 0</code> at the end. The zero of
<code>h</code> is found by a simple secant approach.
</p>


<h3>Value</h3>

<p>Returns a list with two components, <code>t</code> for grid (or &lsquo;time&rsquo;)
points between <code>t0</code> and <code>tfinal</code>, and <code>y</code> the solution
of the differential equation evaluated at these points.
</p>


<h3>Note</h3>

<p>Replacing secant with Newton's method would be an easy exercise.
The same for replacing <code>ode45</code> with some other solver.
</p>


<h3>References</h3>

<p>L. V. Fausett (2008). Applied Numerical Analysis Using MATLAB.
Second Edition, Pearson Education Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bvp">bvp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-- Example 1
f &lt;- function(t, y1, y2) -2*y1*y2
h &lt;- function(u, v) u + v - 0.25

t0 &lt;- 0; tfinal &lt;- 1
y0 &lt;- 1
sol &lt;- shooting(f, t0, tfinal, y0, h, 0, 1)
## Not run: 
plot(sol$t, sol$y[, 1], type='l', ylim=c(-1, 1))
xs &lt;- linspace(0, 1); ys &lt;- 1/(xs+1)
lines(xs, ys, col="red")
lines(sol$t, sol$y[, 2], col="gray")
grid()
## End(Not run)

#-- Example 2
f &lt;- function(t, y1, y2) -y2^2 / y1
h &lt;- function(u, v) u - 2
t0 &lt;- 0; tfinal &lt;- 1
y0 &lt;- 1
sol &lt;- shooting(f, t0, tfinal, y0, h, 0, 1)
</code></pre>

<hr>
<h2 id='shubert'>
Shubert-Piyavskii Method
</h2><span id='topic+shubert'></span>

<h3>Description</h3>

<p>Shubert-Piyavskii Univariate Function Maximization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shubert(f, a, b, L, crit = 1e-04, nmax = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shubert_+3A_f">f</code></td>
<td>
<p>function to be optimized.</p>
</td></tr>
<tr><td><code id="shubert_+3A_a">a</code>, <code id="shubert_+3A_b">b</code></td>
<td>
<p>search between a and b for a maximum.</p>
</td></tr>
<tr><td><code id="shubert_+3A_l">L</code></td>
<td>
<p>a Lipschitz constant for the function.</p>
</td></tr>
<tr><td><code id="shubert_+3A_crit">crit</code></td>
<td>
<p>critical value</p>
</td></tr>
<tr><td><code id="shubert_+3A_nmax">nmax</code></td>
<td>
<p>maximum number of steps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Shubert-Piyavskii method, often called the Sawtooth Method, finds 
the global maximum of a univariate function on a known interval. It is 
guaranteed to find the global maximum on the interval under certain
conditions:
</p>
<p>The function f is Lipschitz-continuous, that is there is a constant L
such that </p>
<p style="text-align: center;"><code class="reqn">|f(x) - f(y)| \le L |x - y|</code>
</p>

<p>for all <code class="reqn">x, y</code> in <code class="reqn">[a, b]</code>.
</p>
<p>The process is stopped when the improvement in the last step is smaller 
than the input argument <code>crit</code>.
</p>


<h3>Value</h3>

<p>Returns a list with the following components:
</p>
<table>
<tr><td><code>xopt</code></td>
<td>
<p>the x-coordinate of the minimum found.</p>
</td></tr>
<tr><td><code>fopt</code></td>
<td>
<p>the function value at the minimum.</p>
</td></tr>
<tr><td><code>nopt</code></td>
<td>
<p>number of steps.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Y. K. Yeo. Chemical Engineering Computation with MATLAB.
CRC Press, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findmins">findmins</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Determine the global minimum of sin(1.2*x)+sin(3.5*x) in [-3, 8].
f &lt;- function(x) sin(1.2*x) + sin(3.5*x)
shubert(function(x) -f(x), -3, 8, 5, 1e-04, 1000)
## $xopt
## [1] 3.216231     # 3.216209
## $fopt
## [1] 1.623964
## $nopt
## [1] 481
</code></pre>

<hr>
<h2 id='Si+2C+20Ci'>
Sine and Cosine Integral Functions
</h2><span id='topic+Si'></span><span id='topic+Ci'></span>

<h3>Description</h3>

<p>Computes the sine and cosine integrals through approximations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Si(x)
Ci(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Si+2B2C+2B20Ci_+3A_x">x</code></td>
<td>
<p>Scalar or vector of real numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sine and cosine integrals are defined as
</p>
<p style="text-align: center;"><code class="reqn">Si(x) = \int_0^x \frac{\sin(t)}{t} dt</code>
</p>

<p style="text-align: center;"><code class="reqn">Ci(x) = - \int_x^\infty \frac{\cos(t)}{t} dt = \gamma + \log(x) + \int_0^x \frac{\cos(t)-1}{t} dt</code>
</p>

<p>where <code class="reqn">\gamma</code> is the Euler-Mascheroni constant.
</p>


<h3>Value</h3>

<p>Returns a scalar of sine resp. cosine integrals applied to each
element of the scalar/vector. The value <code>Ci(x)</code> is not correct, 
it should be <code>Ci(x)+pi*i</code>, only the real part is returned!
</p>
<p>The function is not truely vectorized, for vectors the values are
calculated in a for-loop. The accuracy is about <code>10^-13</code> and better
in a reasonable range of input values.
</p>


<h3>References</h3>

<p>Zhang, S., and J. Jin (1996). Computation of Special Functions. Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sinc">sinc</a></code>, <code><a href="#topic+expint">expint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(-3:3) * pi
Si(x); Ci(x)

## Not run: 
xs &lt;- linspace(0, 10*pi, 200)
ysi &lt;- Si(xs); yci &lt;- Ci(xs)
plot(c(0, 35), c(-1.5, 2.0), type = 'n', xlab = '', ylab = '',
     main = "Sine and cosine integral functions")
lines(xs, ysi, col = "darkred",  lwd = 2)
lines(xs, yci, col = "darkblue", lwd = 2)
lines(c(0, 10*pi), c(pi/2, pi/2), col = "gray")
lines(xs, cos(xs), col = "gray")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='sigmoid'>
Sigmoid Function
</h2><span id='topic+sigmoid'></span><span id='topic+logit'></span>

<h3>Description</h3>

<p>Sigmoid function (aka sigmoidal curve or logistic function).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoid(x, a = 1, b = 0)
logit(x, a = 1, b = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigmoid_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="sigmoid_+3A_a">a</code>, <code id="sigmoid_+3A_b">b</code></td>
<td>
<p>parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>sigmoidal</code> function with parameters <code>a,b</code> is the function
</p>
<p style="text-align: center;"><code class="reqn">y = 1/(1 + e^{-a (x-b)})</code>
</p>

<p>The <code>sigmoid</code> function is also the solution of the ordinary 
differentialequation
</p>
<p style="text-align: center;"><code class="reqn">y' = y (1-y)</code>
</p>

<p>with <code class="reqn">y(0) = 1/2</code> and has an indefinite integral <code class="reqn">\ln(1 + e^x)</code>.
</p>
<p>The <code>logit</code> function is the inverse of the sigmoid function and is
(therefore) omly defined between 0 and 1. Its definition is
</p>
<p style="text-align: center;"><code class="reqn">y = b + 1/a log(x/(1-x))</code>
</p>

<p>The parameters must be scalars; if they are vectors, only the first
component will be taken.
</p>


<h3>Value</h3>

<p>Numeric/complex scalar or vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-6, 6, length.out = 101)
y1 &lt;- sigmoid(x)
y2 &lt;- sigmoid(x, a = 2)
## Not run: 
plot(x, y1, type = "l", col = "darkblue", 
        xlab = "", ylab = "", main = "Sigmoid Function(s)")
lines(x, y2, col = "darkgreen")
grid()
## End(Not run)

# The slope in 0 (in x = b) is a/4
# sigmf with slope 1 and range [-1, 1].
sigmf &lt;- function(x) 2 * sigmoid(x, a = 2) - 1

# logit is the inverse of the sigmoid function
x &lt;- c(-0.75, -0.25, 0.25, 0.75)
y &lt;- sigmoid(x)
logit(y)        #=&gt; -0.75 -0.25  0.25  0.75
</code></pre>

<hr>
<h2 id='simpadpt'>
Adaptive Simpson Quadrature
</h2><span id='topic+simpadpt'></span>

<h3>Description</h3>

<p>Numerically evaluate an integral using adaptive Simpson's rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpadpt(f, a, b, tol = 1e-6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simpadpt_+3A_f">f</code></td>
<td>
<p>univariate function, the integrand.</p>
</td></tr>
<tr><td><code id="simpadpt_+3A_a">a</code>, <code id="simpadpt_+3A_b">b</code></td>
<td>
<p>lower limits of integration; must be finite.</p>
</td></tr>
<tr><td><code id="simpadpt_+3A_tol">tol</code></td>
<td>
<p>relative tolerance</p>
</td></tr>
<tr><td><code id="simpadpt_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximates the integral of the function <code>f</code> from a to b to within
an error of <code>tol</code> using recursive adaptive Simpson quadrature.
</p>


<h3>Value</h3>

<p>A numerical value or vector, the computed integral.
</p>


<h3>Note</h3>

<p>Based on code from the book by Quarteroni et al.,
with some tricks borrowed from Matlab and Octave.
</p>


<h3>References</h3>

<p>Quarteroni, A., R. Sacco, and F. Saleri (2007). Numerical Mathematics.
Second Edition, Springer-Verlag, Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quad">quad</a></code>, <code><a href="#topic+simpson2d">simpson2d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myf &lt;- function(x, n) 1/(x+n)  # 0.0953101798043249 , log((n+1)/n) for n=10
simpadpt(myf, 0, 1, n = 10)    # 0.095310179804535

##  Dilogarithm function
flog  &lt;- function(t) log(1-t) / t  # singularity at t=1, almost at t=0
dilog &lt;- function(x) simpadpt(flog, x, 0, tol = 1e-12)
dilog(1)  # 1.64493406685615
          # 1.64493406684823 = pi^2/6

## Not run: 
N &lt;- 51
xs &lt;- seq(-5, 1, length.out = N)
ys &lt;- numeric(N)
for (i in 1:N) ys[i] &lt;- dilog(xs[i])
plot(xs, ys, type = "l", col = "blue",
             main = "Dilogarithm function")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='simpson2d'>
Double Simpson Integration
</h2><span id='topic+simpson2d'></span>

<h3>Description</h3>

<p>Numerically evaluate double integral by 2-dimensional Simpson method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpson2d(f, xa, xb, ya, yb, nx = 128, ny = 128, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simpson2d_+3A_f">f</code></td>
<td>
<p>function of two variables, the integrand.</p>
</td></tr>
<tr><td><code id="simpson2d_+3A_xa">xa</code>, <code id="simpson2d_+3A_xb">xb</code></td>
<td>
<p>left and right endpoint for first variable.</p>
</td></tr>
<tr><td><code id="simpson2d_+3A_ya">ya</code>, <code id="simpson2d_+3A_yb">yb</code></td>
<td>
<p>left and right endpoint for second variable.</p>
</td></tr>
<tr><td><code id="simpson2d_+3A_nx">nx</code>, <code id="simpson2d_+3A_ny">ny</code></td>
<td>
<p>number of intervals in x- and y-direction.</p>
</td></tr>
<tr><td><code id="simpson2d_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the integrand.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 2D Simpson integrator has weights that are most easily determined 
by taking the outer product of the vector of weights for the 1D Simpson
rule.
</p>


<h3>Value</h3>

<p>Numerical scalar, the value of the integral.
</p>


<h3>Note</h3>

<p>Copyright (c) 2008 W. Padden and Ch. Macaskill for Matlab code published
under BSD License on MatlabCentral.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dblquad">dblquad</a></code>, <code><a href="#topic+quad2d">quad2d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f1 &lt;- function(x, y) x^2 + y^2
simpson2d(f1, -1, 1, -1, 1)     #   2.666666667 , i.e. 8/3 . err = 0

f2 &lt;- function(x, y) y*sin(x)+x*cos(y)
simpson2d(f2, pi, 2*pi, 0, pi)  #  -9.869604401 , i.e. -pi^2, err = 2e-8

f3 &lt;- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2 &lt;= 1))
simpson2d(f3, -1, 1, -1, 1)     #   2.094393912 , i.e. 2/3*pi , err = 1e-6
</code></pre>

<hr>
<h2 id='sind+2Ccosd+2Ctand+2C+20etc.'>
Trigonometric Functions in Degrees
</h2><span id='topic+sind'></span><span id='topic+cosd'></span><span id='topic+tand'></span><span id='topic+cotd'></span><span id='topic+asind'></span><span id='topic+acosd'></span><span id='topic+atand'></span><span id='topic+acotd'></span><span id='topic+secd'></span><span id='topic+cscd'></span><span id='topic+asecd'></span><span id='topic+acscd'></span><span id='topic+atan2d'></span>

<h3>Description</h3>

<p>Trigonometric functions expecting input in degrees, not radians.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sind(x)
cosd(x)
tand(x)
cotd(x)
asind(x)
acosd(x)
atand(x)
acotd(x)
secd(x)
cscd(x)
asecd(x)
acscd(x)
atan2d(x1, x2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sind+2B2Ccosd+2B2Ctand+2B2C+2B20etc._+3A_x">x</code>, <code id="sind+2B2Ccosd+2B2Ctand+2B2C+2B20etc._+3A_x1">x1</code>, <code id="sind+2B2Ccosd+2B2Ctand+2B2C+2B20etc._+3A_x2">x2</code></td>
<td>
<p>numeric or complex scalars or vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The usual trigonometric functions with input values as scalar or vector
in degrees. Note that <code>tan(x)</code> with fractional part does not return
<code>NaN</code> as <code>tanpi(x)</code>, but is computed as <code>sind(x)/cosd(x)</code>.
</p>
<p>For <code>atan2d</code> the inputs <code>x1,x2</code> can be both degrees or radians,
but don't mix! The result is in degrees, of course.
</p>


<h3>Value</h3>

<p>Returns a scalar or vector of numeric values.
</p>


<h3>Note</h3>

<p>These function names are available in Matlab, that is the reason
they have been added to the &lsquo;pracma&rsquo; package.
</p>


<h3>See Also</h3>

<p>Other trigonometric functions in R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sind(x) and cosd(x) are accurate for x which are multiples
# of 90 and 180 degrees, while tand(x) is problematic.

x &lt;- seq(0, 720, by = 90)
sind(x)                     # 0  1  0 -1  0  1  0 -1  0
cosd(x)                     # 1  0 -1  0  1  0 -1  0  1
tand(x)                     # 0  Inf  0  -Inf  0  Inf  0  -Inf  0
cotd(x)                     # Inf  0  -Inf  0  Inf  0  -Inf  0  Inf

x &lt;- seq(5, 85, by = 20)
asind(sind(x))              # 5 25 45 65 85
asecd(sec(x))
tand(x)                     # 0.08748866  0.46630766  1.00000000  ...
atan2d(1, 1)                # 45
</code></pre>

<hr>
<h2 id='size'>Size of Matrix</h2><span id='topic+size'></span>

<h3>Description</h3>

<p>Provides the dimensions of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="size_+3A_x">x</code></td>
<td>
<p>vector, matrix, or array</p>
</td></tr>
<tr><td><code id="size_+3A_k">k</code></td>
<td>
<p>integer specifying a particular dimension</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the number of dimensions as <code>length(x)</code>.
</p>
<p>Vector will be treated as a single row matrix.
</p>


<h3>Value</h3>

<p>vector containing the dimensions of <code>x</code>, or the <code>k</code>-th dimension
if <code>k</code> is not missing.
</p>


<h3>Note</h3>

<p>The result will differ from Matlab when <code>x</code> is a character vector.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+dim">dim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>size(1:8)
size(matrix(1:8, 2, 4))		# 2 4
size(matrix(1:8, 2, 4), 2)	# 4
size(matrix(1:8, 2, 4), 3)	# 1
</code></pre>

<hr>
<h2 id='softline'>
Soft (Inexact) Line Search
</h2><span id='topic+softline'></span>

<h3>Description</h3>

<p>Fletcher's inexact line search algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softline(x0, d0, f, g = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="softline_+3A_x0">x0</code></td>
<td>
<p>initial point for linesearch.</p>
</td></tr>
<tr><td><code id="softline_+3A_d0">d0</code></td>
<td>
<p>search direction from <code>x0</code>.</p>
</td></tr>
<tr><td><code id="softline_+3A_f">f</code></td>
<td>
<p>real function of several variables that is to be minimized.</p>
</td></tr>
<tr><td><code id="softline_+3A_g">g</code></td>
<td>
<p>gradient of objective function <code>f</code>; computed numerically
if not provided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many optimization methods have been found to be quite tolerant to line
search imprecision, therefore inexact line searches are often used in
these methods.
</p>


<h3>Value</h3>

<p>Returns the suggested inexact optimization paramater as a real number
<code>a0</code> such that <code>x0+a0*d0</code> should be a reasonable approximation.
</p>


<h3>Note</h3>

<p>Matlab version of an inexact linesearch algorithm by A. Antoniou and
W.-S. Lu in their textbook &ldquo;Practical Optimization&rdquo;. Translated to R
by Hans W Borchers.
</p>


<h3>References</h3>

<p>Fletcher, R. (1980). Practical Methods of Optimization, Volume 1.,
Section 2.6. Wiley, New York.
</p>
<p>Antoniou, A., and W.-S. Lu (2007). Practical Optimization: Algorithms and
Engineering Applications. Springer Science+Business Media, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaussNewton">gaussNewton</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Himmelblau function
  f_himm &lt;- function(x) (x[1]^2 + x[2] - 11)^2 + (x[1] + x[2]^2 - 7)^2
  g_himm &lt;- function(x) {
    w1 &lt;- (x[1]^2 + x[2] - 11); w2 &lt;- (x[1] + x[2]^2 - 7)
    g1 &lt;- 4*w1*x[1] + 2*w2;     g2 &lt;- 2*w1 + 4*w2*x[2]
    c(g1, g2)
  }
  # Find inexact minimum from [6, 6] in the direction [-1, -1] !
  softline(c(6, 6), c(-1, -1), f_himm, g_himm)
  # [1] 3.458463

  # Find the same minimum by using the numerical gradient
  softline(c(6, 6), c(-1, -1), f_himm)
  # [1] 3.458463
</code></pre>

<hr>
<h2 id='sorting'>Sorting Routines</h2><span id='topic+bubbleSort'></span><span id='topic+insertionSort'></span><span id='topic+selectionSort'></span><span id='topic+shellSort'></span><span id='topic+heapSort'></span><span id='topic+mergeSort'></span><span id='topic+mergeOrdered'></span><span id='topic+quickSort'></span><span id='topic+quickSortx'></span><span id='topic+is.sorted'></span><span id='topic+testSort'></span>

<h3>Description</h3>

<p>R implementations of several sorting routines. These implementations are
meant for demonstration and lecturing purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.sorted(a)
testSort(n = 1000)

bubbleSort(a)
insertionSort(a)
selectionSort(a)
shellSort(a, f = 2.3)
heapSort(a)
mergeSort(a, m = 10)
mergeOrdered(a, b)
quickSort(a, m = 3)
quickSortx(a, m = 25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sorting_+3A_a">a</code>, <code id="sorting_+3A_b">b</code></td>
<td>
<p>Numeric vectors to be sorted or merged.</p>
</td></tr>
<tr><td><code id="sorting_+3A_f">f</code></td>
<td>
<p>Retracting factor for <code>shellSort</code>.</p>
</td></tr>
<tr><td><code id="sorting_+3A_m">m</code></td>
<td>
<p>Size of subsets that are sorted by <code>insertionSort</code> when the
sorting procedure is called recursively.</p>
</td></tr>
<tr><td><code id="sorting_+3A_n">n</code></td>
<td>
<p>Only in <code>testSort</code>: the length of a vector of random numbers
to be sorted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>bubbleSort(a)</code> is the well-known &ldquo;bubble sort&rdquo; routine; it is
forbiddingly slow.
</p>
<p><code>insertionSort(a)</code> sorts the array one entry at a time; it is slow,
but quite efficient for small data sets.
</p>
<p><code>selectionSort(a)</code> is an in-place sorting routine that is inefficient,
but noted for its simplicity.
</p>
<p><code>shellSort(a, f = 2.3)</code> exploits the fact that insertion sort works
efficiently on input that is already almost sorted. It reduces the gaps
by the factor <code>f</code>; <code>f=2.3</code> is said to be a reasonable choice.
</p>
<p><code>heapSort(a)</code> is not yet implemented.
</p>
<p><code>mergeSort(a, m = 10)</code> works recursively, merging already sorted parts
with <code>mergeOrdered</code>. <code>m</code> should be between<code>3</code> and 1/1000 of
the size of <code>a</code>.
</p>
<p><code>mergeOrdered(a, b)</code> works only correctly if <code>a</code> and <code>a</code>
are already sorted.
</p>
<p><code>quickSort(a, m = 3)</code> realizes the celebrated &ldquo;quicksort algorithm&rdquo;
and is the fastest of all implementations here. To avoid too deeply nested
recursion with R, <code>insertionSort</code> is called when the size of a subset
is smaller than <code>m</code>.
</p>
<p>Values between <code>3..30</code> seem reasonable and smaller values are better,
with the risk of running into a too deeply nested recursion.
</p>
<p><code>quickSort(a, m = 25)</code> is an extended version where the split is
calculated more carefully, but in general this approach takes too much
time.
</p>
<p>Values for <code>m</code> are <code>20..40</code> with <code>m=25</code> favoured.
</p>
<p><code>testSort(n = 1000)</code> is a test routine, e.g. for testing your
computer power. On an iMac, <code>quickSort</code> will sort an array of
size 1,000,000 in less than 15 secs.
</p>


<h3>Value</h3>

<p>All routines return the vector sorted.
</p>
<p><code>is.sorted</code> indicates logically whether the vector is sorted.
</p>


<h3>Note</h3>

<p>At the moment, only increasingly sorting is possible
(if needed apply <code>rev</code> afterwards).
</p>


<h3>Author(s)</h3>

<p>HwB &lt;hwborchers@googlemail.com&gt;
</p>


<h3>References</h3>

<p>Knuth, D. E. (1973). The Art of Computer Programming, Volume 3: Sorting
and Searching, Chapter 5: Sorting. Addison-Wesley Publishing Company.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sort">sort</a></code>, the internal C-based sorting routine.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
testSort(100)

a &lt;- sort(runif(1000)); b &lt;- sort(runif(1000))
system.time(y &lt;- mergeSort(c(a, b)))
system.time(y &lt;- mergeOrdered(a, b))
is.sorted(y)
## End(Not run)
</code></pre>

<hr>
<h2 id='sortrows'>Sort Rows of a Matrix (Matlab Style)</h2><span id='topic+sortrows'></span>

<h3>Description</h3>

<p>Sort rows of a matrix according to values in a column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sortrows(A, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sortrows_+3A_a">A</code></td>
<td>
<p>numeric matrix.</p>
</td></tr>
<tr><td><code id="sortrows_+3A_k">k</code></td>
<td>
<p>number of column to sort the matrix accordingly.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sortrows(A, k)</code> sorts the rows of the matrix <code>A</code> such that
column <code>k</code> is increasingly sorted.
</p>


<h3>Value</h3>

<p>Returns the sorted matrix.
</p>


<h3>See Also</h3>

 
<p><code><a href="base.html#topic+sort">sort</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- magic(5)
sortrows(A)
sortrows(A, k = 2)
</code></pre>

<hr>
<h2 id='spinterp'>
Monotone (Shape-Preserving) Interpolation
</h2><span id='topic+spinterp'></span>

<h3>Description</h3>

<p>Monotone interpolation preserves the monotonicity of the data being
interpolated, and when the data points are also monotonic, the slopes 
of the interpolant should also be monotonic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spinterp(x, y, xp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spinterp_+3A_x">x</code>, <code id="spinterp_+3A_y">y</code></td>
<td>
<p>x- and y-coordinates of the points that shall be interpolated.</p>
</td></tr>
<tr><td><code id="spinterp_+3A_xp">xp</code></td>
<td>
<p>points that should be interpolated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation follows a cubic version of the method of Delbourgo and
Gregory. It yields &lsquo;shaplier&rsquo; curves than the Stineman method.
</p>
<p>The calculation of the slopes is according to recommended practice:
</p>
<p>- monotonic and convex &ndash;&gt; harmonic<br />
- monotonic and nonconvex &ndash;&gt; geometric<br />
- nonmonotonic and convex &ndash;&gt; arithmetic<br />
- nonmonotonic and nonconvex &ndash;&gt; circles (Stineman) [not implemented]
</p>
<p>The choice of supplementary coefficients <code>r[i]</code> depends on whether
the data are montonic or convex or both:
</p>
<p>- monotonic, but not convex<br />
- otherwise
</p>
<p>and that can be detected from the data. The choice <code>r[i]=3</code> for all
<code>i</code> results in the standard cubic Hermitean rational interpolation.
</p>


<h3>Value</h3>

<p>The interpolated values at all the points of <code>xp</code>.
</p>


<h3>Note</h3>

<p>At the moment, the data need to be monotonic and the case of convexity
is not considered.
</p>


<h3>References</h3>

<p>Stan Wagon (2010). Mathematica in Action. Third Edition, Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code>stinepack::stinterp</code>, <code>demography::cm.interp</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data1 &lt;- list(x = c(1,2,3,5,6,8,9,11,12,14,15),
              y = c(rep(10,6), 10.5,15,50,60,95))
data2 &lt;- list(x = c(0,1,4,6.5,9,10),
              y = c(10,4,2,1,3,10))
data3 &lt;- list(x = c(7.99,8.09,8.19,8.7,9.2,10,12,15,20),
              y = c(0,0.000027629,0.00437498,0.169183,0.469428,
                    0.94374,0.998636,0.999919,0.999994))
data4 &lt;- list(x = c(22,22.5,22.6,22.7,22.8,22.9,
                    23,23.1,23.2,23.3,23.4,23.5,24),
              y = c(523,543,550,557,565,575,
                    590,620,860,915,944,958,986))
data5 &lt;- list(x = c(0,1.1,1.31,2.5,3.9,4.4,5.5,6,8,10.1),
              y = c(10.1,8,4.7,4.0,3.48,3.3,5.8,7,7.7,8.6))

data6 &lt;- list(x = c(-0.8, -0.75, -0.3, 0.2, 0.5),
              y = c(-0.9,  0.3,   0.4, 0.5, 0.6))
data7 &lt;- list(x = c(-1, -0.96, -0.88, -0.62, 0.13, 1),
              y = c(-1, -0.4,   0.3,   0.78, 0.91, 1))

data8 &lt;- list(x = c(-1, -2/3, -1/3, 0.0, 1/3, 2/3, 1),
              y = c(-1, -(2/3)^3, -(1/3)^3, -(1/3)^3, (1/3)^3, (1/3)^3, 1))

## Not run: 
opr &lt;- par(mfrow=c(2,2))

# These are well-known test cases:
D &lt;- data1
plot(D, ylim=c(0, 100)); grid()
xp &lt;- seq(1, 15, len=51); yp &lt;- spinterp(D$x, D$y, xp)
lines(spline(D), col="blue")
lines(xp, yp, col="red")

D &lt;- data3
plot(D, ylim=c(0, 1.2)); grid()
xp &lt;- seq(8, 20, len=51); yp &lt;- spinterp(D$x, D$y, xp)
lines(spline(D), col="blue")
lines(xp, yp, col="red")

D &lt;- data4
plot(D); grid()
xp &lt;- seq(22, 24, len=51); yp &lt;- spinterp(D$x, D$y, xp)
lines(spline(D), col="blue")
lines(xp, yp, col="red")

# Fix a horizontal slope at the end points
D &lt;- data8
x &lt;- c(-1.05, D$x, 1.05); y &lt;- c(-1, D$y, 1)
plot(D); grid()
xp &lt;- seq(-1, 1, len=101); yp &lt;- spinterp(x, y, xp)
lines(spline(D, n=101), col="blue")
lines(xp, yp, col="red")

par(opr)
## End(Not run)
</code></pre>

<hr>
<h2 id='sqrtm+2Crootm'>
Matrix Square and p-th Roots
</h2><span id='topic+sqrtm'></span><span id='topic+signm'></span><span id='topic+rootm'></span>

<h3>Description</h3>

<p>Computes the matrix square root and matrix p-th root of a nonsingular
real matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sqrtm(A, kmax = 20, tol = .Machine$double.eps^(1/2))
signm(A, kmax = 20, tol = .Machine$double.eps^(1/2))

rootm(A, p, kmax = 20, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sqrtm+2B2Crootm_+3A_a">A</code></td>
<td>
<p>numeric, i.e. real, matrix.</p>
</td></tr>
<tr><td><code id="sqrtm+2B2Crootm_+3A_p">p</code></td>
<td>
<p>p-th root to be taken.</p>
</td></tr>
<tr><td><code id="sqrtm+2B2Crootm_+3A_kmax">kmax</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="sqrtm+2B2Crootm_+3A_tol">tol</code></td>
<td>
<p>absolut tolerance, norm distance of <code>A</code> and <code>B^p</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A real matrix may or may not have a real square root; if it has no real
negative eigenvalues. The number of square roots can vary from two to
infinity. A positive definite matric has one distinguished square root,
called the principal one, with the property that the eigenvalues lie in
the segment
<code>{z | -pi/p &lt; arg(z) &lt; pi/p}</code> (for the p-th root).
</p>
<p>The matrix square root <code>sqrtm(A)</code> is computed here through the
Denman-Beavers iteration (see the references) with quadratic rate of
convergence, a refinement of the common Newton iteration determining
roots of a quadratic equation.
</p>
<p>The matrix p-th root <code>rootm(A)</code> is computed as a complex integral
</p>
<p style="text-align: center;"><code class="reqn"> A^{1/p} = \frac{p \sin(\pi/p)}{\pi} A \int_0^{\infty} (x^p I + A)^{-1} dx</code>
</p>

<p>applying the trapezoidal rule along the unit circle.
</p>
<p>One application is the computation of the matrix logarithm as
</p>
<p style="text-align: center;"><code class="reqn">\log A = 2^k log A^{1/2^k}</code>
</p>

<p>such that the argument to the logarithm is close to the identity matrix
and the Pade approximation can be applied to <code class="reqn">\log(I + X)</code>.
</p>
<p>The matrix sector function is defined as <code>sectm(A,m)=(A^m)^(-1/p)%*%A</code>;
for <code>p=2</code> this is the matrix sign function.
</p>
<p><code>S=signm(A)</code> is real if A is and has the following properties:<br />
<code>S^2=Id; S A = A S</code><br />
<code>singm([0 A; B 0])=[0 C; C^-1 0]</code> where <code>C=A(BA)^-1</code>
</p>
<p>These functions arise in control theory.
</p>


<h3>Value</h3>

<p><code>sqrtm(A)</code> returns a list with components
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>square root matrix of <code>A</code>.</p>
</td></tr>
<tr><td><code>Binv</code></td>
<td>
<p>inverse of the square root matrix.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of iterations.</p>
</td></tr>
<tr><td><code>acc</code></td>
<td>
<p>accuracy or absolute error.</p>
</td></tr>
</table>
<p><code>rootm(A)</code> returns a list with components
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>square root matrix of <code>A</code>.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of iterations.</p>
</td></tr>
<tr><td><code>acc</code></td>
<td>
<p>accuracy or absolute error.</p>
</td></tr>
</table>
<p>If <code>k</code> is negative the iteration has <em>not</em> converged.
</p>
<p><code>signm</code> just returns one matrix, even when there was no convergence.
</p>


<h3>Note</h3>

<p>The p-th root of a positive definite matrix can also be computed from
its eigenvalues as
</p>
<p><code>E &lt;- eigen(A)</code><br />
<code>V &lt;- E\$vectors; U &lt;- solve(V)</code><br />
<code>D &lt;- diag(E\$values)</code><br />
<code>B &lt;- V %*% D^(1/p) %*% U</code>
</p>
<p>or by applying the functions <code>expm</code>, <code>logm</code> in package &lsquo;expm&rsquo;:
</p>
<p><code>B &lt;- expm(1/p * logm(A))</code>
</p>
<p>As these approaches all calculate the principal branch, the results are
identical (but will numerically slightly differ).
</p>


<h3>References</h3>

<p>N. J. Higham (1997). Stable Iterations for the Matrix Square Root.
Numerical Algorithms, Vol. 15, pp. 227&ndash;242.
</p>
<p>D. A. Bini, N. J. Higham, and B. Meini (2005). Algorithms for the
matrix pth root. Numerical Algorithms, Vol. 39, pp. 349&ndash;378.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expm">expm</a></code>, <code>expm::sqrtm</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A1 &lt;- matrix(c(10,  7,  8,  7,
                7,  5,  6,  5,
                8,  6, 10,  9,
                7,  5,  9, 10), nrow = 4, ncol = 4, byrow = TRUE)

X &lt;- sqrtm(A1)$B    # accuracy: 2.352583e-13
X 

A2 &lt;- matrix(c(90.81, 8.33, 0.68, 0.06, 0.08, 0.02, 0.01, 0.01,
                0.70, 90.65, 7.79, 0.64, 0.06, 0.13, 0.02, 0.01,
                0.09, 2.27, 91.05, 5.52, 0.74, 0.26, 0.01, 0.06,
                0.02, 0.33, 5.95, 85.93, 5.30, 1.17, 1.12, 0.18,
                0.03, 0.14, 0.67, 7.73, 80.53, 8.84, 1.00, 1.06,
                0.01, 0.11, 0.24, 0.43, 6.48, 83.46, 4.07, 5.20,
                0.21, 0, 0.22, 1.30, 2.38, 11.24, 64.86, 19.79,
                0, 0, 0, 0, 0, 0, 0, 100
              ) / 100, nrow = 8, ncol = 8, byrow = TRUE)

X &lt;- rootm(A2, 12)  # k = 6, accuracy: 2.208596e-14

##  Matrix sign function
signm(A1)                               # 4x4 identity matrix
B &lt;- rbind(cbind(zeros(4,4), A1),
           cbind(eye(4), zeros(4,4)))
signm(B)                                # [0, signm(A1)$B; signm(A1)$Binv 0]
</code></pre>

<hr>
<h2 id='squareform'>
Format Distance Matrix (Matlab Style)
</h2><span id='topic+squareform'></span>

<h3>Description</h3>

<p>Format or generate a distance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>squareform(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="squareform_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> is a vector as created by the <code>dist</code> function, it converts
it into a fulll square, symmetric matrix.
And if <code>x</code> is a distance matrix, i.e. square, symmetric amd with zero
diagonal elements, it returns the flattened lower triangular submatrix.
</p>


<h3>Value</h3>

<p>Returns a matrix if <code>x</code> is a vector,
and a vextor if <code>x</code> is a matrix.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:6
y &lt;- squareform(x)
#  0  1  2  3
#  1  0  4  5
#  2  4  0  6
#  3  5  6  0
all(squareform(y) == x)
# TRUE
</code></pre>

<hr>
<h2 id='std'>Standard Deviation (Matlab Style)</h2><span id='topic+std'></span>

<h3>Description</h3>

<p>Standard deviation of the values of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std(x, flag=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="std_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="std_+3A_flag">flag</code></td>
<td>
<p>numeric scalar. If <code>0</code>, selects unbiased algorithm; and
if <code>1</code>, selects the biased version.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>flag = 0</code> the result is the square root of an unbiased estimator of 
the variance. <code>std(X,1)</code> returns the standard deviation producing the
second moment of the set of values about their mean.
</p>


<h3>Value</h3>

<p>Return value depends on argument <code>x</code>. If vector, returns the
standard deviation. If matrix, returns vector containing the standard
deviation of each column.
</p>


<h3>Note</h3>

<p><code>flag = 0</code> produces the same result as R's sd().
</p>


<h3>Examples</h3>

<pre><code class='language-R'>std(1:10)          # 3.027650
std(1:10, flag=1)  # 2.872281
</code></pre>

<hr>
<h2 id='std_err'>Standard Error</h2><span id='topic+std_err'></span>

<h3>Description</h3>

<p>Standard error of the values of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std_err(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="std_err_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard error is computed as <code>var(x)/length(x)</code>.
</p>


<h3>Value</h3>

<p>Returns the standard error of all elements of the vector or matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>std_err(1:10)  #=&gt; 0.9574271
</code></pre>

<hr>
<h2 id='steep_descent'>
Steepest Descent Minimization
</h2><span id='topic+steep_descent'></span>

<h3>Description</h3>

<p>Function minimization by steepest descent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steep_descent(x0, f, g = NULL, info = FALSE,
              maxiter = 100, tol = .Machine$double.eps^(1/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="steep_descent_+3A_x0">x0</code></td>
<td>
<p>start value.</p>
</td></tr>
<tr><td><code id="steep_descent_+3A_f">f</code></td>
<td>
<p>function to be minimized.</p>
</td></tr>
<tr><td><code id="steep_descent_+3A_g">g</code></td>
<td>
<p>gradient function of <code>f</code>;
if <code>NULL</code>, a numerical gradient will be calculated.</p>
</td></tr>
<tr><td><code id="steep_descent_+3A_info">info</code></td>
<td>
<p>logical; shall information be printed on every iteration?</p>
</td></tr>
<tr><td><code id="steep_descent_+3A_maxiter">maxiter</code></td>
<td>
<p>max. number of iterations.</p>
</td></tr>
<tr><td><code id="steep_descent_+3A_tol">tol</code></td>
<td>
<p>relative tolerance, to be used as stopping rule.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Steepest descent is a line search method that moves along the downhill
direction.
</p>


<h3>Value</h3>

<p>List with following components:
</p>
<table>
<tr><td><code>xmin</code></td>
<td>
<p>minimum solution found.</p>
</td></tr>
<tr><td><code>fmin</code></td>
<td>
<p>value of <code>f</code> at minimum.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>number of iterations performed.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Used some Matlab code as described in the book &ldquo;Applied Numerical Analysis
Using Matlab&rdquo; by L. V.Fausett.
</p>


<h3>References</h3>

<p>Nocedal, J., and S. J. Wright (2006). Numerical Optimization.
Second Edition, Springer-Verlag, New York, pp. 22 ff.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fletcher_powell">fletcher_powell</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  Rosenbrock function: The flat valley of the Rosenbruck function makes
##  it infeasible for a steepest descent approach.
# rosenbrock &lt;- function(x) {
#     n &lt;- length(x)
#     x1 &lt;- x[2:n]
#     x2 &lt;- x[1:(n-1)]
#     sum(100*(x1-x2^2)^2 + (1-x2)^2)
# }
# steep_descent(c(1, 1), rosenbrock)
# Warning message:
# In steep_descent(c(0, 0), rosenbrock) :
#   Maximum number of iterations reached -- not converged.

## Sphere function
sph &lt;- function(x) sum(x^2)
steep_descent(rep(1, 10), sph)
# $xmin   0 0 0 0 0 0 0 0 0 0
# $fmin   0
# $niter  2
</code></pre>

<hr>
<h2 id='stereographic'>
Stereographic Projection
</h2><span id='topic+stereographic'></span><span id='topic+stereographic_inv'></span>

<h3>Description</h3>

<p>The stereographic projection is a function that maps the n-dimensional
sphere from the South pole (0,...,-1) to the tangent plane of the sphere
at the north pole (0,...,+1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stereographic(p)

stereographic_inv(q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stereographic_+3A_p">p</code></td>
<td>
<p>point on the n-spere ; can also be a set of points,
each point represented as a column of a matrix.</p>
</td></tr>
<tr><td><code id="stereographic_+3A_q">q</code></td>
<td>
<p>point on the tangent plane at the north pole
(last coordinate = 1); can also be a set of such points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The stereographic projection is a smooth function from <code class="reqn">S^n - (0,\dots,-1)</code>
to the tangent hyperplane at the north pole. The south pole is mapped to
infinity, that is why one speaks of <code class="reqn">S^n</code> as a 'one-point compactification'
of <code class="reqn">R^{n-1}</code>.
</p>
<p>All mapped points will have a last coordinate 1.0 (lying on the tangent
plane.) Points mapped by 'stereographic_inv' are assumed to have a last
coordinate 1.0 (this will not be checked), otherwise the result will be
different from what is expected &ndash; though the result is still correct in
itself.
</p>
<p>All points are column vectors: <code>stereographic</code> will transform a row
vector to column; <code>stereographic_inv</code> will return a single vector
as column.
</p>


<h3>Value</h3>

<p>Returns a point (or a set of point) of (n-1) dimensions on the tangent plane
resp. an n-dimensional point on the n-sphere, i.e., <code>sum(x^2) = 1</code>.
</p>


<h3>Note</h3>

<p>To map a region around the south pole, a similar function would be possible.
Instead it is simpler to change the sign of the last coordinate.
</p>


<h3>Author(s)</h3>

<p>Original MATLAB code by J.Burkardt under LGPL license; rewritten in R
by Hans W Borchers.
</p>


<h3>References</h3>

<p>See the &quot;Stereographic projection&quot; article on Wikipedia.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># points in the xy-plane (i.e., z = 0)
A &lt;- matrix(c(1,0,0, -1,0,0, 0,1,0, 0,-1,0), nrow = 3)
B &lt;- stereographic(A); B
##      [,1] [,2] [,3] [,4]
## [1,]    2   -2    0    0
## [2,]    0    0    2   -2
## [3,]    1    1    1    1

stereographic_inv(B)
##      [,1] [,2] [,3] [,4]
## [1,]    1   -1    0    0
## [2,]    0    0    1   -1
## [3,]    0    0    0    0

stereographic_inv(c(2,0,2))     # not correct: z = 2
##      [,1]
## [1,]  1.0
## [2,]  0.0
## [3,]  0.5

## Not run: 
# Can be used for optimization with sum(x^2) == 1
# Imagine to maximize the product x*y*z for x^2 + y^2 + z^2 == 1 !
  fnObj &lt;- function(x) {                # length(x) = 2
    x1 &lt;- stereographic_inv(c(x, 1))    # on S^2
    return( -prod(x1) )                 # Maximize
  }
  sol &lt;- optim(c(1, 1), fnObj)
  -sol$value                            # the maximal product
  ## [1] 0.1924501                      #   1/3 * sqrt(1/3)
  stereographic_inv(c(sol$par, 1))      # the solution coordinates
               [,1]                     #   on S^2
  ## [1,] 0.5773374                     # by symmetry must be
  ## [2,] 0.5773756                     # sqrt(1/3) = 0.5773503...
  ## [3,] 0.5773378
## End(Not run)
</code></pre>

<hr>
<h2 id='str2num'>
Converting string to number (Matlab style)
</h2><span id='topic+str2num'></span><span id='topic+num2str'></span>

<h3>Description</h3>

<p>Functions for converting strings to numbers and numbers to strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>str2num(S)
num2str(A, fmt = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="str2num_+3A_s">S</code></td>
<td>
<p>string containing numbers (in Matlab format).</p>
</td></tr>
<tr><td><code id="str2num_+3A_a">A</code></td>
<td>
<p>numerical vector or matrix.</p>
</td></tr>
<tr><td><code id="str2num_+3A_fmt">fmt</code></td>
<td>
<p>format string, or integer indicating number of decimals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>str2num</code> converts a string containing numbers into a numerical object.
The string can begin and end with '[' and ']', numbers can be separated with
blanks or commas; a semicolon within the brackets indicates a new row for
matrix input. When a semicolon appears behind the braces, no output is shown
on the command line.
</p>
<p><code>num2str</code> converts a numerical object, vector or matrix, into a 
character object of the same size. <code>fmt</code> will be a format string for
use in <code>sprintf</code>, or an integer <code>n</code> being used in <code>'%.nf'</code>.
</p>


<h3>Value</h3>

<p>Returns a vector or matrix of the same size, converted to strings,
respectively numbers.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sprintf">sprintf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str1 &lt;- " [1 2 3; 4, 5, 6; 7,8,9]  "
str2num(str1)
# matrix(1:9, nrow = 3, ncol = 3, byrow = TRUE)

# str2 &lt;- " [1 2 3; 45, 6; 7,8,9]  "
# str2num(str2)
# Error in str2num(str2) : 
#   All rows in Argument 's' must have the same length.

A &lt;- matrix(c(pi, 0, exp(1), 1), 2, 2)
B &lt;- num2str(A, 2); b &lt;- dim(B)
B &lt;- as.numeric(B); dim(B) &lt;- b
B
#      [,1] [,2]
# [1,] 3.14 2.72
# [2,] 0.00 1.00
</code></pre>

<hr>
<h2 id='strcat'>String Concatenation</h2><span id='topic+strcat'></span>

<h3>Description</h3>

<p>Concatenate all strings  in a character vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strcat(s1, s2 = NULL, collapse = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strcat_+3A_s1">s1</code></td>
<td>
<p>character string or vectors</p>
</td></tr>
<tr><td><code id="strcat_+3A_s2">s2</code></td>
<td>
<p>character string or vector, or NULL (default)</p>
</td></tr>
<tr><td><code id="strcat_+3A_collapse">collapse</code></td>
<td>
<p>character vector of length 1 (at best a single character)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Concatenate all strings  in character vector <code>s1</code>, if <code>s2</code> is
<code>NULL</code>, or cross-concatenate all string elements in <code>s1</code> and
<code>s2</code> using <code>collapse</code> as &lsquo;glue&rsquo;.
</p>


<h3>Value</h3>

<p>a character string or character vector
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+paste">paste</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>strcat(c("a", "b", "c"))                        #=&gt; "abc"
strcat(c("a", "b"), c("1", "2"), collapse="x")  #=&gt; "ax1" "ax2" "bx1" "bx2"
</code></pre>

<hr>
<h2 id='strcmp'>String Comparison</h2><span id='topic+strcmp'></span><span id='topic+strcmpi'></span>

<h3>Description</h3>

<p>Compare two strings or character vectors for equality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strcmp(s1, s2)
strcmpi(s1, s2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strcmp_+3A_s1">s1</code>, <code id="strcmp_+3A_s2">s2</code></td>
<td>
<p>character strings or vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>strcmp</code> comparisons are case-sensitive, while for <code>strcmpi</code>
the are case-insensitive. Leading and trailing blanks do count.
</p>


<h3>Value</h3>

<p>logical, i.e. <code>TRUE</code> if <code>s1</code> and <code>s2</code> have the same length
as character vectors and all elements are equal as character strings, else
<code>FALSE</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+strcat">strcat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>strcmp(c("yes", "no"), c("yes", "no"))
strcmpi(c("yes", "no"), c("Yes", "No"))
</code></pre>

<hr>
<h2 id='strfind'>Find Substrings</h2><span id='topic+strfind'></span><span id='topic+strfindi'></span><span id='topic+findstr'></span>

<h3>Description</h3>

<p>Find substrings within strings of a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strfind(s1, s2, overlap = TRUE)
strfindi(s1, s2, overlap = TRUE)

findstr(s1, s2, overlap = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strfind_+3A_s1">s1</code></td>
<td>
<p>character string or character vector</p>
</td></tr>
<tr><td><code id="strfind_+3A_s2">s2</code></td>
<td>
<p>character string (character vector of length 1)</p>
</td></tr>
<tr><td><code id="strfind_+3A_overlap">overlap</code></td>
<td>
<p>logical (are overlapping substrings allowed)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>strfind</code> finds positions of substrings within <code>s1</code> that
match exactly with <code>s2</code>, and is case sensitive; no regular patterns.
</p>
<p><code>strfindi</code> does not distinguish between lower and upper case.
</p>
<p><code>findstr</code> should only be used as internal function, in Matlab it is
deprecated. It searches for the shorter string within the longer one.
</p>


<h3>Value</h3>

<p>Returns a vector of indices, or a list of such index vectors if
<code>s2</code> is a character vector of length greater than 1.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+strcmp">strcmp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- c("", "ab", "aba", "aba aba", "abababa")
s &lt;- "aba"
strfind(S, s)
strfindi(toupper(S), s)
strfind(S, s, overlap = FALSE)
</code></pre>

<hr>
<h2 id='strjust'>
Justify character vector
</h2><span id='topic+strjust'></span>

<h3>Description</h3>

<p>Justify the strings in a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strjust(s, justify = c("left", "right", "center"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strjust_+3A_s">s</code></td>
<td>
<p>Character vector.</p>
</td></tr>
<tr><td><code id="strjust_+3A_justify">justify</code></td>
<td>
<p>Whether to justify left, right, or centered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>strjust(s)</code> or <code>strjust(s, justify = ``right'')</code> returns
a right-justified character vector. All strings have the same length,
the length of the longest string in <code>s</code> &mdash; but the strings in
<code>s</code> have been trimmed before.
</p>
<p><code>strjust(s, justify = ``left'')</code> does the same, with all strings
left-justified.
</p>
<p><code>strjust(s, justify = ``centered'')</code> returns all string in <code>s</code>
centered. If an odd number of blanks has to be added, one blank more is
added to the left than to the right.
</p>


<h3>Value</h3>

<p>A character vector of the same length.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+strTrim">strTrim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- c("abc", "letters", "1", "2  2")
strjust(S, "left")
</code></pre>

<hr>
<h2 id='strRep'>
Find and replace substring
</h2><span id='topic+strRep'></span>

<h3>Description</h3>

<p>Find and replace all occurrences of a substring with another one
in all strings of a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strRep(s, old, new)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strRep_+3A_s">s</code></td>
<td>
<p>Character vector.</p>
</td></tr>
<tr><td><code id="strRep_+3A_old">old</code></td>
<td>
<p>String to be replaced.</p>
</td></tr>
<tr><td><code id="strRep_+3A_new">new</code></td>
<td>
<p>String that replaces another one.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Replaces all occurrences of <code>old</code> with <code>new</code> in all strings
of character vector <code>s</code>. The matching is case sensitive.
</p>


<h3>Value</h3>

<p>A character vector of the same length.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gsub">gsub</a></code>, <code>regexprep</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- c('This is a good example.', "He has a good character.",
       'This is good, good food.', "How goodgood this is!")
strRep(S, 'good', 'great')
</code></pre>

<hr>
<h2 id='strTrim'>
Remove leading and trailing white space.
</h2><span id='topic+strTrim'></span><span id='topic+deblank'></span>

<h3>Description</h3>

<p>Removes leading and trailing white space from a string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strTrim(s)
deblank(s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strTrim_+3A_s">s</code></td>
<td>
<p>character string or character vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>strTrim</code> removes leading and trailing white space from a string or
from all strings in a character vector.
</p>
<p><code>deblank</code> removes trailing white space only from a string or
from all strings in a character vector.  
</p>


<h3>Value</h3>

<p>A character string or character vector with (leading and) trailing
white space.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+strjust">strjust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- c("  abc", "abc   ", " abc ", " a b c ", "abc", "a b c")
strTrim(s)
deblank(s)
</code></pre>

<hr>
<h2 id='subspace'>
Angle between two subspaces
</h2><span id='topic+subspace'></span>

<h3>Description</h3>

<p>Finds the angle between two subspaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subspace(A, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subspace_+3A_a">A</code>, <code id="subspace_+3A_b">B</code></td>
<td>
<p>Numeric matrices; vectors will be considered as column vectors.
These matrices must have the same number or rows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds the angle between two subspaces specified by the columns of A and B.
</p>


<h3>Value</h3>

<p>An angle in radians.
</p>


<h3>Note</h3>

<p>It is not necessary that two subspaces be the same size in order to find
the angle between them. Geometrically, this is the angle between two
hyperplanes embedded in a higher dimensional space.
</p>


<h3>References</h3>

<p>Strang, G. (1998). Introduction to Linear Algebra. Wellesley-Cambridge Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+orth">orth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>180 * subspace(c(1, 2), c(2, 1)) / pi  #=&gt; 36.87
180 * subspace(c(0, 1), c(1, 2)) / pi  #=&gt; 26.565

H &lt;- hadamard(8)
A &lt;- H[, 2:4]
B &lt;- H[, 5:8]
subspace(A, B)    #=&gt; 1.5708 or pi/2, i.e. A and B are orthogonal
</code></pre>

<hr>
<h2 id='sumalt'>
Alternating Series Acceleration
</h2><span id='topic+sumalt'></span>

<h3>Description</h3>

<p>Computes the value of an (infinite) alternating sum applying an
acceleration method found by Cohen et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sumalt(f_alt, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sumalt_+3A_f_alt">f_alt</code></td>
<td>
<p>a funktion of <code>k=0..Inf</code> that returns element
<code>a_k</code> of the infinite alternating series.</p>
</td></tr>
<tr><td><code id="sumalt_+3A_n">n</code></td>
<td>
<p>number of elements of the series used for calculating.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the sum of an alternating series (whose entries are strictly
decreasing), applying the acceleration method developped by H. Cohen,
F. Rodriguez Villegas, and Don Zagier.
</p>
<p>For example, to compute the Leibniz series (see below) to 15 digits 
exactly, <code>10^15</code> summands of the series will be needed. This
accelleration approach here will only need about 20 of them!
</p>


<h3>Value</h3>

<p>Returns an approximation of the series value.
</p>


<h3>Author(s)</h3>

<p>Implemented by Hans W Borchers.
</p>


<h3>References</h3>

<p>Henri Cohen, F. Rodriguez Villegas, and Don Zagier.
Convergence Acceleration of Alternating Series.
Experimental Mathematics, Vol. 9 (2000).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aitken">aitken</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Beispiel: Leibniz-Reihe 1 - 1/3 + 1/5 - 1/7 +- ...
a_pi4 &lt;- function(k) (-1)^k / (2*k + 1)
sumalt(a_pi4, 20)  # 0.7853981633974484 = pi/4 + eps()

# Beispiel: Van Wijngaarden transform needs 60 terms
n &lt;- 60; N &lt;- 0:n
a &lt;- cumsum((-1)^N / (2*N+1))
for (i in 1:n) {
    a &lt;- (a[1:(n-i+1)] + a[2:(n-i+2)]) / 2
}
a - pi/4  # 0.7853981633974483

# Beispiel: 1 - 1/2^2 + 1/3^2 - 1/4^2 +- ...
b_alt &lt;- function(k) (-1)^k / (k+1)^2
sumalt(b_alt, 20)  # 0.8224670334241133 = pi^2/12 + eps()

## Not run: 
# Dirichlet eta() function: eta(s) = 1/1^s - 1/2^s + 1/3^s -+ ...
  eta_ &lt;- function(s) {
    eta_alt &lt;- function(k) (-1)^k / (k+1)^s
    sumalt(eta_alt, 30)
  }
  eta_(1)                       # 0.6931471805599453 = log(2)
  abs(eta_(1+1i) - eta(1+1i))   # 1.24e-16

## End(Not run)
</code></pre>

<hr>
<h2 id='taylor'>
Taylor Series Approximation
</h2><span id='topic+taylor'></span>

<h3>Description</h3>

<p>Local polynomial approximation through Taylor series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taylor(f, x0, n = 4, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="taylor_+3A_f">f</code></td>
<td>
<p>differentiable function.</p>
</td></tr>
<tr><td><code id="taylor_+3A_x0">x0</code></td>
<td>
<p>point where the series expansion will take place.</p>
</td></tr>
<tr><td><code id="taylor_+3A_n">n</code></td>
<td>
<p>Taylor series order to be used; should be <code>n &lt;= 8</code>.</p>
</td></tr>
<tr><td><code id="taylor_+3A_...">...</code></td>
<td>
<p>more variables to be passed to function <code>f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the first four coefficients of the Taylor series through
numerical differentiation and uses some polynomial &lsquo;yoga&rsquo;.
</p>


<h3>Value</h3>

<p>Vector of length <code>n+1</code> representing a polynomial of degree <code>n</code>.
</p>


<h3>Note</h3>

<p>TODO: Pade approximation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fderiv">fderiv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>taylor(sin, 0, 4)  #=&gt; -0.1666666  0.0000000  1.0000000  0.0000000
taylor(exp, 1, 4)  #=&gt;  0.04166657 0.16666673 0.50000000 1.00000000 1.00000000

f &lt;- function(x) log(1+x)
p &lt;- taylor(f, 0, 4)
p                     # log(1+x) = 0 + x - 1/2 x^2 + 1/3 x^3 - 1/4 x^4 +- ...
                      # [1] -0.250004  0.333334 -0.500000  1.000000  0.000000

## Not run: 
x &lt;- seq(-1.0, 1.0, length.out=100)
yf &lt;- f(x)
yp &lt;- polyval(p, x)
plot(x, yf, type = "l", col = "gray", lwd = 3)
lines(x, yp, col = "red")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='tic+2Ctoc'>MATLAB timer functions</h2><span id='topic+tic'></span><span id='topic+toc'></span>

<h3>Description</h3>

<p>Provides stopwatch timer. Function <code>tic</code> starts the timer and <code>toc</code>
updates the elapsed time since the timer was started. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tic(gcFirst=FALSE)
toc(echo=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tic+2B2Ctoc_+3A_gcfirst">gcFirst</code></td>
<td>
<p>logical scalar. If <code>TRUE</code>, perform garbage collection
prior to starting stopwatch</p>
</td></tr>
<tr><td><code id="tic+2B2Ctoc_+3A_echo">echo</code></td>
<td>
<p>logical scalar. If <code>TRUE</code>, print elapsed time to screen</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides analog to <code><a href="base.html#topic+system.time">system.time</a></code>.
Function <code>toc</code> can be invoked multiple times in a row.
</p>


<h3>Value</h3>

<p><code>toc</code> invisibly returns the elapsed time as a named scalar (vector).
</p>


<h3>Author(s)</h3>

<p>P. Roebuck <a href="mailto:proebuck@mdanderson.org">proebuck@mdanderson.org</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tic()
for(i in 1:100) mad(runif(1000))	# kill time
toc()
</code></pre>

<hr>
<h2 id='titanium'>
Titanium Test Data
</h2><span id='topic+titanium'></span>

<h3>Description</h3>

<p>The Titanium data set describes measurements of a certain property of 
titanium as a function of temperature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(titanium)
</code></pre>


<h3>Format</h3>

<p>The format is:<br />
Two columns called &lsquo;x&rsquo; and &lsquo;y&rsquo;, the first being the temperature.
</p>


<h3>Details</h3>

<p>These data have become a standard test for data fitting since they are hard
to fit by classical techniques and have a significant amount of noise.
</p>


<h3>Source</h3>

<p>Boor, C. de, and J. R. Rice (1968). Least squares cubic spline
approximation II &ndash; Variable knots, CSD TR 21, Comp.Sci., Purdue Univ.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(titanium)
plot(titanium)
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='Toeplitz'>Toeplitz Matrix</h2><span id='topic+Toeplitz'></span>

<h3>Description</h3>

<p>Generate Toeplitz matrix from column and row vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Toeplitz(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Toeplitz_+3A_a">a</code></td>
<td>
<p>vector that will be the first column</p>
</td></tr>
<tr><td><code id="Toeplitz_+3A_b">b</code></td>
<td>
<p>vector that if present will form the first row.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Toeplitz(a, b)</code> returns a (non-symmetric) Toeplitz matrix whose
first column is <code>a</code> and whose first row is <code>b</code>. The following
rows are shifted to the left.
</p>
<p>If the first element of <code>b</code> differs from the last element of <code>a</code>
it is overwritten by this one (and a warning sent).
</p>


<h3>Value</h3>

<p>Matrix of size <code>(length(a), length(b))</code>.
</p>


<h3>Note</h3>

<p><code>stats::Toeplitz</code> does not allow to specify the row vector, that is
returns only the <em>symmetric</em> Toeplitz matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hankel">hankel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Toeplitz(c(1, 2, 3, 4, 5))
Toeplitz(c(1, 2, 3, 4, 5), c(1.5, 2.5, 3.5, 4.5, 5.5))
</code></pre>

<hr>
<h2 id='Trace'>Matrix trace</h2><span id='topic+Trace'></span>

<h3>Description</h3>

<p>Sum of the main diagonal elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Trace(a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Trace_+3A_a">a</code></td>
<td>
<p>a square matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sums the elements of the main diagonal of areal or complrx square matrix.
</p>


<h3>Value</h3>

<p>scalar value
</p>


<h3>Note</h3>

<p>The corresponding function in Matlab/Octave is called trace(), but this in <span class="rlang"><b>R</b></span>
has a different meaning.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Diag">Diag</a></code>, <code><a href="base.html#topic+diag">diag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Trace(matrix(1:16, nrow=4, ncol=4))
</code></pre>

<hr>
<h2 id='trapz'>Trapezoidal Integration</h2><span id='topic+trapz'></span><span id='topic+cumtrapz'></span><span id='topic+trapzfun'></span>

<h3>Description</h3>

<p>Compute the area of a function with values <code>y</code> at the points
<code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  trapz(x, y)
  cumtrapz(x, y)

  trapzfun(f, a, b, maxit = 25, tol = 1e-07, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trapz_+3A_x">x</code></td>
<td>
<p>x-coordinates of points on the x-axis</p>
</td></tr>
<tr><td><code id="trapz_+3A_y">y</code></td>
<td>
<p>y-coordinates of function values</p>
</td></tr>
<tr><td><code id="trapz_+3A_f">f</code></td>
<td>
<p>function to be integrated.</p>
</td></tr>
<tr><td><code id="trapz_+3A_a">a</code>, <code id="trapz_+3A_b">b</code></td>
<td>
<p>lower and upper border of the integration domain.</p>
</td></tr>
<tr><td><code id="trapz_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of steps.</p>
</td></tr>
<tr><td><code id="trapz_+3A_tol">tol</code></td>
<td>
<p>tolerance; stops when improvements are smaller.</p>
</td></tr>
<tr><td><code id="trapz_+3A_...">...</code></td>
<td>
<p>arguments passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The points <code>(x, 0)</code> and <code>(x, y)</code> are taken as vertices of a
polygon and the area is computed using <code>polyarea</code>. This approach
matches exactly the approximation for integrating the function using the
trapezoidal rule with basepoints <code>x</code>.
</p>
<p><code>cumtrapz</code> computes the cumulative integral of <code>y</code> with respect 
to <code>x</code> using trapezoidal integration. <code>x</code> and <code>y</code> must be
vectors of the same length, or <code>x</code> must be a vector and <code>y</code> a
matrix whose first dimension is <code>length(x)</code>.
</p>
<p>Inputs <code>x</code> and <code>y</code> can be complex.
</p>
<p><code>trapzfun</code> realizes trapezoidal integration and stops when the
differencefrom one step to the next is smaller than tolerance (or the
of iterations get too big). The function will only be evaluated once
on each node.
</p>


<h3>Value</h3>

<p>Approximated integral of the function, discretized through the points
<code>x, y</code>, from <code>min(x)</code> to <code>max(x)</code>.
Or a matrix of the same size as <code>y</code>.
</p>
<p><code>trapzfun</code> returns a lst with components <code>value</code> the value of
the integral, <code>iter</code> the number of iterations, and <code>rel.err</code>
the relative error.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyarea">polyarea</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Calculate the area under the sine curve from 0 to pi:
  n &lt;- 101
  x &lt;- seq(0, pi, len = n)
  y &lt;- sin(x)
  trapz(x, y)                       #=&gt; 1.999835504

  # Use a correction term at the boundary: -h^2/12*(f'(b)-f'(a))
  h  &lt;- x[2] - x[1]
  ca &lt;- (y[2]-y[1]) / h
  cb &lt;- (y[n]-y[n-1]) / h
  trapz(x, y) - h^2/12 * (cb - ca)  #=&gt; 1.999999969

  # Use two complex inputs
  z  &lt;- exp(1i*pi*(0:100)/100)
  ct &lt;- cumtrapz(z, 1/z)
  ct[101]                           #=&gt; 0+3.14107591i

  f &lt;- function(x) x^(3/2)          # 
  trapzfun(f, 0, 1)                 #=&gt; 0.4 with 11 iterations
</code></pre>

<hr>
<h2 id='tri'>
Triangular Matrices (Matlab Style)
</h2><span id='topic+tril'></span><span id='topic+triu'></span>

<h3>Description</h3>

<p>Extract lower or upper triangular part of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tril(M, k = 0)
triu(M, k = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tri_+3A_m">M</code></td>
<td>
<p>numeric matrix.</p>
</td></tr>
<tr><td><code id="tri_+3A_k">k</code></td>
<td>
<p>integer, indicating a secondary diagonal.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>tril</code><br />
Returns the elements on and below the kth diagonal of X, where k = 0 is
the main diagonal, k &gt; 0 is above the main diagonal, and k &lt; 0 is below
the main diagonal.
</p>
<p><code>triu</code><br />
Returns the elements on and above the kth diagonal of X, where k = 0 is
the main diagonal, k &gt; 0 is above the main diagonal, and k &lt; 0 is below
the main diagonal.
</p>


<h3>Value</h3>

<p>Matrix the same size as the input matrix.
</p>


<h3>Note</h3>

<p>For <code>k==0</code> it is simply an application of the R functions
<code>lower.tri</code> resp. <code>upper.tri</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Diag">Diag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tril(ones(4,4), +1)
#    1  1  0  0
#    1  1  1  0
#    1  1  1  1
#    1  1  1  1

triu(ones(4,4), -1)
#    1  1  1  1
#    1  1  1  1
#    0  1  1  1
#    0  0  1  1
</code></pre>

<hr>
<h2 id='trigApprox'>
Trigonometric Approximation
</h2><span id='topic+trigApprox'></span>

<h3>Description</h3>

<p>Computes the trigonometric series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trigApprox(t, x, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trigApprox_+3A_t">t</code></td>
<td>
<p>vector of points at which to compute the values of the
trigonometric approximation.</p>
</td></tr>
<tr><td><code id="trigApprox_+3A_x">x</code></td>
<td>
<p>data from <code>t=0</code> to <code>t=2*(n-1)*pi/n</code>.</p>
</td></tr>
<tr><td><code id="trigApprox_+3A_m">m</code></td>
<td>
<p>degree of trigonometric regression.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calls <code>trigPoly</code> to get the trigonometric coefficients and then
sums the finite series.
</p>


<h3>Value</h3>

<p>Vector of values the same length as <code>t</code>.
</p>


<h3>Note</h3>

<p>TODO: Return an approximating function instead.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trigPoly">trigPoly</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##  Example: Gauss' Pallas data (1801)
asc &lt;- seq(0, 330, by = 30)
dec &lt;- c(408, 89, -66, 10, 338, 807, 1238, 1511, 1583, 1462, 1183, 804)
plot(2*pi*asc/360, dec, pch = "+", col = "red", xlim = c(0, 2*pi), ylim = c(-500, 2000),
     xlab = "Ascension [radians]", ylab = "Declination [minutes]",
     main = "Gauss' Pallas Data")
grid()
points(2*pi*asc/360, dec, pch = "o", col = "red")
ts &lt;- seq(0, 2*pi, len = 100)
xs &lt;- trigApprox(ts ,dec, 1)
lines(ts, xs, col = "black")
xs &lt;- trigApprox(ts ,dec, 2)
lines(ts, xs, col = "blue")
legend(3, 0, c("Trig. Regression of degree 1", "Trig. Regression of degree 2",
                  "Astronomical position"), col = c("black", "blue", "red"),
                lty = c(1,1,0), pch = c("", "", "+"))
## End(Not run)
</code></pre>

<hr>
<h2 id='trigPoly'>
Trigonometric Polynomial
</h2><span id='topic+trigPoly'></span>

<h3>Description</h3>

<p>Computes the trigonometric coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trigPoly(x, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trigPoly_+3A_x">x</code></td>
<td>
<p>data from <code>t=0</code> to <code>t=2*(n-1)*pi/n</code>.</p>
</td></tr>
<tr><td><code id="trigPoly_+3A_m">m</code></td>
<td>
<p>degree of trigonometric regression.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the coefficients of the trigonometric series of degree <code>m</code>,
</p>
<p style="text-align: center;"><code class="reqn">a_0 + \sum_k(a_k \cos(k t) + b_k \sin(k t))</code>
</p>

<p>by applying orthogonality relations.
</p>


<h3>Value</h3>

<p>Coefficients as a list with components <code>a0</code>, <code>a</code>, and <code>b</code>. 
</p>


<h3>Note</h3>

<p>For irregular spaced data or data not covering the whole period, use
standard regression techniques, see examples.
</p>


<h3>References</h3>

<p>Fausett, L. V. (2007). Applied Numerical Analysis Using Matlab.
Second edition, Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trigApprox">trigApprox</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data available only from 0 to pi/2
t &lt;- seq(0, pi, len=7)
x &lt;- 0.5 + 0.25*sin(t) + 1/3*cos(t) - 1/3*sin(2*t) - 0.25*cos(2*t)

# use standard regression techniques
A &lt;- cbind(1, cos(t), sin(t), cos(2*t), sin(2*t))
ab &lt;- qr.solve(A, x)
ab
# [1]  0.5000000  0.3333333  0.2500000 -0.2500000 -0.3333333
ts &lt;- seq(0, 2*pi, length.out = 100)
xs &lt;- ab[1] + ab[2]*cos(ts) +
      ab[3]*sin(ts) + ab[4]*cos(2*ts) +ab[5]*sin(2*ts)

## Not run: 
# plot to make sure
plot(t, x, col = "red", xlim=c(0, 2*pi), ylim=c(-2,2),
           main = "Trigonometric Regression")
lines(ts, xs, col="blue")
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='triquad'>
Gaussian Triangle Quadrature
</h2><span id='topic+triquad'></span>

<h3>Description</h3>

<p>Numerically integrates a function over an arbitrary triangular domain by
computing the Gauss nodes and weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triquad(f, x, y, n = 10, tol = 1e-10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="triquad_+3A_f">f</code></td>
<td>
<p>the integrand as function of two variables.</p>
</td></tr>
<tr><td><code id="triquad_+3A_x">x</code></td>
<td>
<p>x-coordinates of the three vertices of the triangle.</p>
</td></tr>
<tr><td><code id="triquad_+3A_y">y</code></td>
<td>
<p>y-coordinates of the three vertices of the triangle.</p>
</td></tr>
<tr><td><code id="triquad_+3A_n">n</code></td>
<td>
<p>number of nodes.</p>
</td></tr>
<tr><td><code id="triquad_+3A_tol">tol</code></td>
<td>
<p>relative tolerance to be achieved.</p>
</td></tr>
<tr><td><code id="triquad_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the <code>N^2</code> nodes and weights for a triangle with vertices
given by 3x2 vector. The nodes are produced by collapsing the square
to a triangle.
</p>
<p>Then <code>f</code> will be applied to the nodes and the result multiplied
left and right with the weights (i.e., Gaussian quadrature).
</p>
<p>By default, the function applies Gaussian quadrature with number of
nodes <code>n=10,21,43,87,175</code> until the relative error is smaller than
the tolerance.
</p>


<h3>Value</h3>

<p>The integral as a scalar.
</p>


<h3>Note</h3>

<p>A small relative tolerance is <em>not</em> really indicating a small
absolute tolerance.
</p>


<h3>Author(s)</h3>

<p>Copyright (c) 2005 Greg von Winckel Matlab code based on the publication
mentioned and available from MatlabCentral (calculates nodes and weights).
Translated to R (with permission) by Hans W Borchers.
</p>


<h3>References</h3>

<p>Lyness, J. N., and R. Cools (1994). A Survey of Numerical Cubature
over Triangles. Proceedings of the AMS Conference &ldquo;Mathematics of
Computation 1943&ndash;1993&rdquo;, Vancouver, CA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quad2d">quad2d</a></code>, <code><a href="#topic+simpson2d">simpson2d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(-1, 1, 0); y &lt;- c(0, 0, 1)
f1 &lt;- function(x, y) x^2 + y^2
(I &lt;- triquad(f1, x, y))                        # 0.3333333333333333

# split the unit square
x1 &lt;- c(0, 1, 1); y1 &lt;- c(0, 0, 1)
x2 &lt;- c(0, 1, 0); y2 &lt;- c(0, 1, 1)
f2 &lt;- function(x, y) exp(x + y)
I &lt;- triquad(f2, x1, y1) + triquad(f2, x2, y2)  # 2.952492442012557
quad2d(f2, 0, 1, 0, 1)                          # 2.952492442012561
simpson2d(f2, 0, 1, 0, 1)                       # 2.952492442134769
dblquad(f2,  0, 1, 0, 1)                        # 2.95249244201256
</code></pre>

<hr>
<h2 id='trisolve'>
Tridiagonal Linear System Solver
</h2><span id='topic+trisolve'></span>

<h3>Description</h3>

<p>Solves tridiagonal linear systems <code>A*x=rhs</code> efficiently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trisolve(a, b, d, rhs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trisolve_+3A_a">a</code></td>
<td>
<p>diagonal of the tridiagonal matrix <code>A</code>.</p>
</td></tr>
<tr><td><code id="trisolve_+3A_b">b</code>, <code id="trisolve_+3A_d">d</code></td>
<td>
<p>upper and lower secondary diagonal of <code>A</code>.</p>
</td></tr>
<tr><td><code id="trisolve_+3A_rhs">rhs</code></td>
<td>
<p>right hand side of the linear system <code>A*x=rhs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves tridiagonal linear systems <code>A*x=rhs</code> by applying Givens
transformations.
</p>
<p>By only storing the three diagonals, <code>trisolve</code> has memory requirements 
of <code>3*n</code> instead of <code>n^2</code> and
is faster than the standard <code>solve</code> function for larger matrices.
</p>


<h3>Value</h3>

<p>Returns the solution of the tridiagonal linear system as vector.
</p>


<h3>Note</h3>

<p>Has applications for spline approximations and for solving boundary value
problems (ordinary differential equations).
</p>


<h3>References</h3>

<p>Gander, W. (1992). Computermathematik. Birkhaeuser Verlag, Basel.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qrSolve">qrSolve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8237)
a &lt;- rep(1, 100)
e &lt;- runif(99); f &lt;- rnorm(99)
x &lt;- rep(seq(0.1, 0.9, by = 0.2), times = 20)
A &lt;- diag(100) + Diag(e, 1) + Diag(f, -1)
rhs &lt;- A %*% x
s &lt;- trisolve(a, e, f, rhs)
s[1:10]                         #=&gt; 0.1 0.3 0.5 0.7 0.9 0.1 0.3 0.5 0.7 0.9
s[91:100]                       #=&gt; 0.1 0.3 0.5 0.7 0.9 0.1 0.3 0.5 0.7 0.9
</code></pre>

<hr>
<h2 id='vander'>Vandermonde matrix</h2><span id='topic+vander'></span>

<h3>Description</h3>

<p>Generate Vandermonde matrix from a numeric vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  vander(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vander_+3A_x">x</code></td>
<td>
<p>Numeric vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates the usual Vandermonde matrix from a numeric vector, e.g.
applied when fitting a polynomial to given points.
Complex values are allowed.
</p>


<h3>Value</h3>

<p>Vandermonde matrix of dimension n where <code>n = length(x)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  vander(c(1:10))
</code></pre>

<hr>
<h2 id='vectorfield'>
Vector Field Plotting
</h2><span id='topic+vectorfield'></span>

<h3>Description</h3>

<p>Plotting a vector field
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vectorfield(fun, xlim, ylim, n = 16,
            scale = 0.05, col = "green", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vectorfield_+3A_fun">fun</code></td>
<td>
<p>function of two variables &mdash; must be vectorized.</p>
</td></tr>
<tr><td><code id="vectorfield_+3A_xlim">xlim</code></td>
<td>
<p>range of <code>x</code> values.</p>
</td></tr>
<tr><td><code id="vectorfield_+3A_ylim">ylim</code></td>
<td>
<p>range of <code>y</code> values.</p>
</td></tr>
<tr><td><code id="vectorfield_+3A_n">n</code></td>
<td>
<p>grid size, proposed 16 in each direction.</p>
</td></tr>
<tr><td><code id="vectorfield_+3A_scale">scale</code></td>
<td>
<p>scales the length of the arrows.</p>
</td></tr>
<tr><td><code id="vectorfield_+3A_col">col</code></td>
<td>
<p>arrow color, proposed &lsquo;green&rsquo;.</p>
</td></tr>
<tr><td><code id="vectorfield_+3A_...">...</code></td>
<td>
<p>more options presented to the <code>arrows</code> primitive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots a vector field for a function <code>f</code>. Main usage could be to plot
the solution of a differential equation into the same graph.
</p>


<h3>Value</h3>

<p>Opens a graph window and plots the vector field.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quiver">quiver</a></code>, <code><a href="graphics.html#topic+arrows">arrows</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x, y) x^2 - y^2
xx &lt;- c(-1, 1); yy &lt;- c(-1, 1)
## Not run: 
vectorfield(f, xx, yy, scale = 0.1)
for (xs in seq(-1, 1, by = 0.25)) {
    sol &lt;- rk4(f, -1, 1, xs, 100)
    lines(sol$x, sol$y, col="darkgreen")
}
grid()
## End(Not run)
</code></pre>

<hr>
<h2 id='whittaker'>
Whittaker Smoothing
</h2><span id='topic+whittaker'></span>

<h3>Description</h3>

<p>Smoothing of time series using the Whittaker-Henderson approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whittaker(y, lambda = 1600, d = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="whittaker_+3A_y">y</code></td>
<td>
<p>signal to be smoothed.</p>
</td></tr>
<tr><td><code id="whittaker_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter (rough 50..1e4 smooth); the default
value of 1600 has been recommended in the literature.</p>
</td></tr>
<tr><td><code id="whittaker_+3A_d">d</code></td>
<td>
<p>order of differences in penalty (generally 2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Whittaker smoother family was first presented by Whittaker in 
1923 for life tables, based on penalized least squares. These ideas 
were revived by Paul Eilers, Leiden University, in 2003. This
approach is also known as Whittaker-Henderson smoothing.
</p>
<p>The smoother attempts to both fit a curve that represents the raw 
data, but is penalized if subsequent points vary too much.
Mathematically it is a large, but sparse optimization problem that 
can be expressed in a few lines of Matlab or R code.
</p>


<h3>Value</h3>

<p>A smoothed time series.
</p>


<h3>Note</h3>

<p>This is a version that avoids package 'SparseM'.
</p>


<h3>Author(s)</h3>

<p>An R version, based on Matlab code by P. Eilers in 2002, has been 
published by Nicholas Lewin-Koh on the R-help mailing list in Feb. 
2004, and in private communication to the author of this package.
</p>


<h3>References</h3>

<p>P. H. C. Eilers (2003). A Perfect Smoother. Analytical Chemistry,
Vol. 75, No. 14, pp. 3631&ndash;3636.
</p>
<p>Wilson, D. I. (2006). The Black Art of Smoothing. Electrical and 
Automation Technology, June/July issue.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+supsmu">supsmu</a></code>, <code><a href="#topic+savgol">savgol</a></code>, <code>ptw::whit2</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># **Sinosoid test function**
ts &lt;- sin(2*pi*(1:1000)/200)
t1 &lt;- ts + rnorm(1000)/10
t3 &lt;- whittaker(t1, lambda = 1600)
## Not run: 
plot(1:1000, t1, col = "grey")
lines(1:1000, ts, col="blue")
lines(1:1000, t3, col="red")
## End(Not run)
</code></pre>

<hr>
<h2 id='wilkinson'>wilkinson Matrix</h2><span id='topic+wilkinson'></span>

<h3>Description</h3>

<p>Generate the Wilkinson matrix of size <code>n x n</code>.The Wilkinson matrix for
testing eigenvalue computations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wilkinson(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wilkinson_+3A_n">n</code></td>
<td>
<p>integer</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wilkinson matrix for testing eigenvalue computations is a symmetric
matrix with three non-zero diagonals and with several pairs of nearly equal
eigenvalues. 
</p>


<h3>Value</h3>

<p>matrix of size <code>n x n</code>
</p>


<h3>Note</h3>

<p>The two largest eigenvalues of <code>wilkinson(21)</code> agree to 14, but not 15
decimal places.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Toeplitz">Toeplitz</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(a &lt;- wilkinson(7))
eig(a)
</code></pre>

<hr>
<h2 id='zeta'>
Riemann Zeta Function
</h2><span id='topic+zeta'></span>

<h3>Description</h3>

<p>Riemann's zeta function valid in the entire complex plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeta(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zeta_+3A_z">z</code></td>
<td>
<p>Real or complex number or a numeric or complex vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the zeta function for complex arguments using a series expansion
for Dirichlet's eta function.
</p>
<p>Accuracy is about 7 significant digits for <code>abs(z)&lt;50</code>,
drops off with higher absolute values.
</p>


<h3>Value</h3>

<p>Returns a complex vector of function values.
</p>


<h3>Note</h3>

<p>Copyright (c) 2001 Paul Godfrey for a Matlab version available on
Mathwork's Matlab Central under BSD license.
</p>


<h3>References</h3>

<p>Zhang, Sh., and J. Jin (1996). Computation of Special Functions.
Wiley-Interscience, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gammaz">gammaz</a></code>, <code><a href="#topic+eta">eta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##  First zero on the critical line s = 0.5 + i t
## Not run: 
x &lt;- seq(0, 20, len=1001)
z &lt;- 0.5 + x*1i
fr &lt;- Re(zeta(z))
fi &lt;- Im(zeta(z))
fa &lt;- abs(zeta(z))
plot(x, fa, type="n", xlim = c(0, 20), ylim = c(-1.5, 2.5),
     xlab = "Imaginary part (on critical line)", ylab = "Function value",
     main = "Riemann's Zeta Function along the critical line")
lines(x, fr, col="blue")
lines(x, fi, col="darkgreen")
lines(x, fa, col = "red", lwd = 2)
points(14.1347, 0, col = "darkred")
legend(0, 2.4, c("real part", "imaginary part", "absolute value"),
       lty = 1, lwd = c(1, 1, 2), col = c("blue", "darkgreen", "red"))
grid()
## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
