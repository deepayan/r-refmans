<!DOCTYPE html><html lang="en-GB"><head><title>Help for package Distance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Distance}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Distance-package'><p>Distance sampling</p></a></li>
<li><a href='#add_df_covar_line'><p>Add covariate levels detection function plots</p></a></li>
<li><a href='#AIC.dsmodel'><p>Akaike's An Information Criterion for detection functions</p></a></li>
<li><a href='#amakihi'><p>Hawaiian amakihi point transect data</p></a></li>
<li><a href='#bootdht'><p>Bootstrap uncertainty estimation for distance sampling models</p></a></li>
<li><a href='#bootdht_Dhat_summarize'><p>Simple summary of density results for bootstrap model</p></a></li>
<li><a href='#bootdht_Nhat_summarize'><p>Simple summary of abundance results for bootstrap model</p></a></li>
<li><a href='#capercaillie'><p>Capercaillie in Monaughty Forest</p></a></li>
<li><a href='#checkdata'><p>Check that the data supplied to <code>ds</code> is correct</p></a></li>
<li><a href='#ClusterExercise'><p>Simulated minke whale data with cluster size</p></a></li>
<li><a href='#convert_units'><p>Convert units for abundance estimation</p></a></li>
<li><a href='#create_bins'><p>Create bins from a set of binned distances and a set of cutpoints.</p></a></li>
<li><a href='#create.bins'><p>Create bins from a set of binned distances and a set of cutpoints.</p></a></li>
<li><a href='#CueCountingExample'><p>Cue counts of whale blows</p></a></li>
<li><a href='#dht2'><p>Abundance estimation for distance sampling models</p></a></li>
<li><a href='#ds'><p>Fit detection functions and calculate abundance from line or point transect</p>
data</a></li>
<li><a href='#ds.gof'><p>Goodness of fit tests for distance sampling models</p></a></li>
<li><a href='#ducknest'><p>Ducknest line transect survey data</p></a></li>
<li><a href='#DuikerCameraTraps'><p>Duiker camera trap survey</p></a></li>
<li><a href='#dummy_ddf'><p>Detection function objects when detection is certain</p></a></li>
<li><a href='#ETP_Dolphin'><p>Eastern Tropical Pacific spotted dolphin survey</p></a></li>
<li><a href='#flatfile'><p>The flatfile data format</p></a></li>
<li><a href='#gof_ds'><p>Goodness of fit testing and quantile-quantile plots</p></a></li>
<li><a href='#golftees'><p>Golf tee data</p></a></li>
<li><a href='#logLik.dsmodel'><p>log-likelihood value for a fitted detection function</p></a></li>
<li><a href='#LTExercise'><p>Simulated line transect survey data</p></a></li>
<li><a href='#make_activity_fn'><p>Multiplier bootstrap helper functions</p></a></li>
<li><a href='#minke'><p>Simulated minke whale data</p></a></li>
<li><a href='#p_dist_table'><p>Distribution of probabilities of detection</p></a></li>
<li><a href='#plot.dsmodel'><p>Plot a fitted detection function</p></a></li>
<li><a href='#predict.dsmodel'><p>Predictions from a fitted detection function</p></a></li>
<li><a href='#predict.fake_ddf'><p>Prediction for fake detection functions</p></a></li>
<li><a href='#print.dht_result'><p>Print abundance estimates</p></a></li>
<li><a href='#print.dsmodel'><p>Simple pretty printer for distance sampling analyses</p></a></li>
<li><a href='#print.summary.dsmodel'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#PTExercise'><p>Simulated point transect survey data</p></a></li>
<li><a href='#QAIC'><p>Tools for model selection when distance sampling data are overdispersed</p></a></li>
<li><a href='#Savannah_sparrow_1980'><p>Savanna sparrow point transects</p></a></li>
<li><a href='#sikadeer'><p>Sika deer pellet data from southern Scotland</p></a></li>
<li><a href='#Stratify_example'><p>Simulated minke whale data</p></a></li>
<li><a href='#summarize_ds_models'><p>Make a table of summary statistics for detection function models</p></a></li>
<li><a href='#summary.dht_bootstrap'><p>Summarize bootstrap abundance uncertainty estimate output</p></a></li>
<li><a href='#summary.dsmodel'><p>Summary of distance sampling analysis</p></a></li>
<li><a href='#Systematic_variance_1'><p>Simulation of encounter rate variance</p></a></li>
<li><a href='#unflatten'><p>Unflatten flatfile data.frames</p></a></li>
<li><a href='#unimak'><p>Simulated line transect survey data with covariates</p></a></li>
<li><a href='#units_table'><p>Generate table of unit conversions</p></a></li>
<li><a href='#wren'><p>Steve Buckland's winter wren surveys</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Maintainer:</td>
<td>Laura Marshall &lt;lhm@st-andrews.ac.uk&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Title:</td>
<td>Distance Sampling Detection Function and Abundance Estimation</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Description:</td>
<td>A simple way of fitting detection functions to distance sampling
    data for both line and point transects. Adjustment term selection, left and
    right truncation as well as monotonicity constraints and binning are
    supported. Abundance and density estimates can also be calculated (via a
    Horvitz-Thompson-like estimator) if survey area information is provided. See
    Miller et al. (2019) &lt;<a href="https://doi.org/10.18637%2Fjss.v089.i01">doi:10.18637/jss.v089.i01</a>&gt; for more information on
    methods and <a href="https://examples.distancesampling.org/">https://examples.distancesampling.org/</a> for example analyses.</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/DistanceDevelopment/Distance/">https://github.com/DistanceDevelopment/Distance/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/DistanceDevelopment/Distance/issues">https://github.com/DistanceDevelopment/Distance/issues</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), mrds (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, methods, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, progress, parallel, doParallel, doRNG, foreach,
activity, testthat, optimx, readxl</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-24 12:38:02 UTC; lhm</td>
</tr>
<tr>
<td>Author:</td>
<td>Laura Marshall [cre],
  David Miller [aut],
  T.J. Clark-Wolf [aut],
  Len Thomas [ctb],
  Jeff Laake [ctb],
  Eric Rexstad [rev]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-24 15:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='Distance-package'>Distance sampling</h2><span id='topic+Distance-package'></span><span id='topic+Distance'></span>

<h3>Description</h3>

<p><code>Distance</code> is a simple way to fit detection functions and estimate
abundance using distance sampling methodology.
</p>


<h3>Details</h3>

<p>Underlying <code>Distance</code> is the package <code>mrds</code>, for more advanced
analyses (such as those involving double observer surveys) one may find it
necessary to use <code>mrds</code>.
</p>
<p>Examples of distance sampling analyses are available at
<a href="http://examples.distancesampling.org/">http://examples.distancesampling.org/</a>.
</p>
<p>For help with distance sampling and this package, there is a Google Group
<a href="https://groups.google.com/forum/#!forum/distance-sampling">https://groups.google.com/forum/#!forum/distance-sampling</a>.
</p>
<p>Bugs can be reported at <a href="https://github.com/DistanceDevelopment/Distance/issues">https://github.com/DistanceDevelopment/Distance/issues</a>.
</p>


<h3>Author(s)</h3>

<p>David L. Miller <a href="mailto:dave@ninepointeightone.net">dave@ninepointeightone.net</a>
</p>


<h3>References</h3>

<p>&quot;_PACKAGE&quot;
</p>
<p>Key References:
</p>
<p>Miller D.L., E. Rexstad, L. Thomas, L. Marshall and J.L. Laake. 2019.
Distance Sampling in R. Journal of Statistical Software, 89(1), 1-28.
<a href="https://doi.org/10.18637/jss.v089.i01">doi:10.18637/jss.v089.i01</a>
</p>
<p>Background References:
</p>
<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>
<p>Marques, F.F.C. and S.T. Buckland. 2004. Covariate models for the detection
function. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>

<hr>
<h2 id='add_df_covar_line'>Add covariate levels detection function plots</h2><span id='topic+add_df_covar_line'></span>

<h3>Description</h3>

<p>Add a line or lines to a plot of the detection function which correspond to
a a given covariate combination. These can be particularly useful when there
is a small number of factor levels or if quantiles of a continuous covariate
are specified.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_df_covar_line_+3A_ddf">ddf</code></td>
<td>
<p>a fitted detection function object.</p>
</td></tr>
<tr><td><code id="add_df_covar_line_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> with the covariate combination you want to plot.</p>
</td></tr>
<tr><td><code id="add_df_covar_line_+3A_...">...</code></td>
<td>
<p>extra arguments to give to <code><a href="graphics.html#topic+lines">lines</a></code> (e.g.,
<code>lty</code>, <code>lwd</code>, <code>col</code>).</p>
</td></tr>
<tr><td><code id="add_df_covar_line_+3A_ndist">ndist</code></td>
<td>
<p>number of distances at which to evaluate the detection function.</p>
</td></tr>
<tr><td><code id="add_df_covar_line_+3A_pdf">pdf</code></td>
<td>
<p>should the line be drawn on the probability density scale;
ignored for line transects</p>
</td></tr>
<tr><td><code id="add_df_covar_line_+3A_breaks">breaks</code></td>
<td>
<p>required to ensure that PDF lines are the right size, should
match what is supplied to original <code>plot</code> command. Defaults to
&quot;Sturges&quot; breaks, as in <code><a href="graphics.html#topic+hist">hist</a></code>. Only used if <code>pdf=TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>All covariates must be specified in <code>data</code>. Plots can become quite busy
when this approach is used. It may be useful to fix some covariates at their
median level and plot set values of a covariate of interest. For example
setting weather (e.g., Beaufort) to its median and plotting levels of
observer, then creating a second plot for a fixed observer with levels of
weather.
</p>
<p>Arguments to <code><a href="graphics.html#topic+lines">lines</a></code> are supplied in ... and aesthetics like
line type (<code>lty</code>), line width (<code>lwd</code>) and colour (<code>col</code>) are
recycled. By default <code>lty</code> is used to distinguish between the lines. It
may be useful to add a <code><a href="graphics.html#topic+legend">legend</a></code> to the plot (lines are plotted
in the order of <code>data</code>).
</p>


<h3>Value</h3>

<p>invisibly, the values of detectability over the truncation range.
</p>


<h3>Note</h3>

<p>This function is located in the <code>mrds</code> package but the
documentation is provided here for easy access.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# example using a model for the minke data
data(minke)
# fit a model
result &lt;- ds(minke, formula=~Region.Label)

# make a base plot, showpoints=FALSE makes the plot less busy
plot(result, showpoints=FALSE)

# add lines for sex one at a time
add_df_covar_line(result, data.frame(Region.Label="South"), lty=2)
add_df_covar_line(result, data.frame(Region.Label="North"), lty=3)

# add a legend
legend(1.5, 1, c("Average", "South", "North"), lty=1:3)

# point transect example
data(amakihi)
result &lt;- ds(amakihi, truncation=150, transect="point", formula=~OBs)
plot(result, showpoints=FALSE, pdf=TRUE)
add_df_covar_line(result,
                  data.frame(OBs=na.omit(unique(amakihi$OBs))), pdf=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='AIC.dsmodel'>Akaike's An Information Criterion for detection functions</h2><span id='topic+AIC.dsmodel'></span>

<h3>Description</h3>

<p>Extract the AIC from a fitted detection function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dsmodel'
AIC(object, ..., k = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AIC.dsmodel_+3A_object">object</code></td>
<td>
<p>a fitted detection function object</p>
</td></tr>
<tr><td><code id="AIC.dsmodel_+3A_...">...</code></td>
<td>
<p>optionally more fitted model objects.</p>
</td></tr>
<tr><td><code id="AIC.dsmodel_+3A_k">k</code></td>
<td>
<p>penalty per parameter to be used; the default <code>k = 2</code> is the
&quot;classical&quot; AIC</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Distance)
data(minke)
model &lt;- ds(minke, truncation=4)
model_hr &lt;- ds(minke, truncation=4, key="hr")
# extract the AIC for 2 models
AIC(model, model_hr)

## End(Not run)
</code></pre>

<hr>
<h2 id='amakihi'>Hawaiian amakihi point transect data</h2><span id='topic+amakihi'></span><span id='topic+amakihi_units'></span>

<h3>Description</h3>

<p>Also known as the Common 'Amakihi, a type of Hawaiian honeycreeper
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 1487 rows and 12 variables
</p>

<ul>
<li> <p><code>Region.Label</code> strata names (seven strata)
</p>
</li>
<li> <p><code>Area</code> size of study area (set to 0)
</p>
</li>
<li> <p><code>Sample.Label</code> transect ID
</p>
</li>
<li> <p><code>Effort</code> number of visits to point
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> radial distance (m)
</p>
</li>
<li> <p><code>Month</code> month survey conducted (not used)
</p>
</li>
<li> <p><code>OBs</code> observer ID (note capitalisation of variable name)
</p>
</li>
<li> <p><code>Sp</code> species code (COAM) for all detections
</p>
</li>
<li> <p><code>MAS</code> Time after sunrise (min)
</p>
</li>
<li> <p><code>HAS</code> Time after sunrise (hours)
</p>
</li>
<li> <p><code>Study.Area</code> name of study area
</p>
</li></ul>



<h3>Note</h3>

<p>Example for investigating covariates in the detection function.  Note
high colinearity between two measures of time since sunrise.  Convergence
problems can result from models with several factor covariates.
</p>


<h3>References</h3>

<p>Marques, T.A., L. Thomas, S.G. Fancy and S.T. Buckland. (2007)
Improving estimates of bird density using multiple-covariate distance
sampling.  The Auk 124 (4): 1229–1243.
<a href="https://doi.org/10.1642/0004-8038%282007%29124%5B1229%3AIEOBDU%5D2.0.CO%3B2">doi:10.1642/0004-8038(2007)124[1229:IEOBDU]2.0.CO;2</a>
</p>

<hr>
<h2 id='bootdht'>Bootstrap uncertainty estimation for distance sampling models</h2><span id='topic+bootdht'></span>

<h3>Description</h3>

<p>Performs a bootstrap for simple distance sampling models using the same data
structures as <code><a href="mrds.html#topic+dht">dht</a></code>. Note that only geographical stratification
as supported in <code>dht</code> is allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootdht(
  model,
  flatfile,
  resample_strata = FALSE,
  resample_obs = FALSE,
  resample_transects = TRUE,
  nboot = 100,
  summary_fun = bootdht_Nhat_summarize,
  convert_units = 1,
  select_adjustments = FALSE,
  sample_fraction = 1,
  multipliers = NULL,
  progress_bar = "base",
  cores = 1,
  convert.units = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootdht_+3A_model">model</code></td>
<td>
<p>a model fitted by <code><a href="#topic+ds">ds</a></code> or a list of models</p>
</td></tr>
<tr><td><code id="bootdht_+3A_flatfile">flatfile</code></td>
<td>
<p>Data provided in the flatfile format. See <code><a href="#topic+flatfile">flatfile</a></code> for
details. Please note, it is a current limitation of bootdht that all
Sample.Label identifiers must be unique across all strata, i.e.transect
ids must not be re-used from one strata to another. An easy way to achieve
this is to paste together the stratum names and transect ids.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_resample_strata">resample_strata</code></td>
<td>
<p>should resampling happen at the stratum
(<code>Region.Label</code>) level? (Default <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bootdht_+3A_resample_obs">resample_obs</code></td>
<td>
<p>should resampling happen at the observation (<code>object</code>)
level? (Default <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="bootdht_+3A_resample_transects">resample_transects</code></td>
<td>
<p>should resampling happen at the transect
(<code>Sample.Label</code>) level? (Default <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="bootdht_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap replicates</p>
</td></tr>
<tr><td><code id="bootdht_+3A_summary_fun">summary_fun</code></td>
<td>
<p>function that is used to obtain summary statistics from
the bootstrap, see Summary Functions below. By default
<code><a href="#topic+bootdht_Nhat_summarize">bootdht_Nhat_summarize</a></code> is used, which just extracts abundance estimates.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_convert_units">convert_units</code></td>
<td>
<p>conversion between units for abundance estimation, see
&quot;Units&quot;, below. (Defaults to 1, implying all of the units are &quot;correct&quot;
already.) This takes precedence over any unit conversion stored in <code>model</code>.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_select_adjustments">select_adjustments</code></td>
<td>
<p>select the number of adjustments in each
bootstrap, when <code>FALSE</code> the exact detection function specified in <code>model</code> is
fitted to each replicate. Setting this option to <code>TRUE</code> can significantly
increase the runtime for the bootstrap. Note that for this to work <code>model</code>
must have been fitted with <code>adjustment!=NULL</code>.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_sample_fraction">sample_fraction</code></td>
<td>
<p>what proportion of the transects was covered (e.g.,
0.5 for one-sided line transects).</p>
</td></tr>
<tr><td><code id="bootdht_+3A_multipliers">multipliers</code></td>
<td>
<p><code>list</code> of multipliers. See &quot;Multipliers&quot; below.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_progress_bar">progress_bar</code></td>
<td>
<p>which progress bar should be used? Default &quot;base&quot; uses
<code>txtProgressBar</code>, &quot;none&quot; suppresses output, &quot;progress&quot; uses the
<code>progress</code> package, if installed.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_cores">cores</code></td>
<td>
<p>number of CPU cores to use to compute the estimates. See &quot;Parallelization&quot; below.</p>
</td></tr>
<tr><td><code id="bootdht_+3A_convert.units">convert.units</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
</table>


<h3>Summary Functions</h3>

<p>The function <code>summary_fun</code> allows the user to specify what summary
statistics should be recorded from each bootstrap. The function should take
two arguments, <code>ests</code> and <code>fit</code>. The former is the output from
<code>dht2</code>, giving tables of estimates. The latter is the fitted detection
function object. The function is called once fitting and estimation has been
performed and should return a <code>data.frame</code>. Those <code>data.frame</code>s
are then concatenated using <code>rbind</code>. One can make these functions
return any information within those objects, for example abundance or
density estimates or the AIC for each model. See Examples below.
</p>


<h3>Multipliers</h3>

<p>It is often the case that we cannot measure distances to individuals or
groups directly, but instead need to estimate distances to something they
produce (e.g., for whales, their blows; for elephants their dung) &ndash; this is
referred to as indirect sampling. We may need to use estimates of production
rate and decay rate for these estimates (in the case of dung or nests) or
just production rates (in the case of songbird calls or whale blows). We
refer to these conversions between &quot;number of cues&quot; and &quot;number of animals&quot;
as &quot;multipliers&quot;.
</p>
<p>The <code>multipliers</code> argument is a <code>list</code>, with 3 possible elements (<code>creation</code>
and <code>decay</code>). Each element of which is either:
</p>

<ul>
<li> <p><code>data.frame</code> and must have at least a column named <code>rate</code>, which abundance
estimates will be divided by (the term &quot;multiplier&quot; is a misnomer, but
kept for compatibility with Distance for Windows). Additional columns can
be added to give the standard error and degrees of freedom for the rate
if known as <code>SE</code> and <code>df</code>, respectively. You can use a multirow
<code>data.frame</code> to have different rates for different geographical areas
(for example). In this case the rows need to have a column (or columns)
to <code>merge</code> with the data (for example <code>Region.Label</code>).
</p>
</li>
<li><p> a <code>function</code> which will return a single estimate of the relevant
multiplier. See <code><a href="#topic+make_activity_fn">make_activity_fn</a></code> for a helper function for use with the
<code>activity</code> package.
</p>
</li></ul>



<h3>Model selection</h3>

<p>Model selection can be performed on a per-replicate basis within the
bootstrap. This has three variations:
</p>

<ol>
<li><p> when <code>select_adjustments</code> is <code>TRUE</code> then adjustment terms are selected
by AIC within each bootstrap replicate (provided that <code>model</code> had the
<code>order</code> and <code>adjustment</code> options set to non-<code>NULL</code>.
</p>
</li>
<li><p> if <code>model</code> is a list of fitted detection functions, each of these is
fitted to each replicate and results generated from the one with the
lowest AIC.
</p>
</li>
<li><p> when <code>select_adjustments</code> is <code>TRUE</code> and <code>model</code> is a list of fitted
detection functions, each model fitted to each replicate and number of
adjustments is selected via AIC.
This last option can be extremely time consuming.
</p>
</li></ol>



<h3>Parallelization</h3>

<p>If <code>cores</code>&gt;1 then the <code>parallel</code>/<code>doParallel</code>/<code>foreach</code>/<code>doRNG</code> packages
will be used to run the computation over multiple cores of the computer. To
use this component you need to install those packages using:
<code>install.packages(c("foreach", "doParallel", "doRNG"))</code> It is advised that
you do not set <code>cores</code> to be greater than one less than the number of cores
on your machine. The <code>doRNG</code> package is required to make analyses
reproducible (<code><a href="base.html#topic+set.seed">set.seed</a></code> can be used to ensure the same answers).
</p>
<p>It is also hard to debug any issues in <code>summary_fun</code> so it is best to run a
small number of bootstraps first in parallel to check that things work. On
Windows systems <code>summary_fun</code> does not have access to the global environment
when running in parallel, so all computations must be made using only its
<code>ests</code> and <code>fit</code> arguments (i.e., you can not use R objects from elsewhere
in that function, even if they are available to you from the console).
</p>
<p>Another consequence of the global environment being unavailable inside
parallel bootstraps is that any starting values in the model object passed
in to <code>bootdht</code> must be hard coded (otherwise you get back 0 successful
bootstraps). For a worked example showing this, see the camera trap distance
sampling online example at
<a href="https://examples.distancesampling.org/Distance-cameratraps/camera-distill.html">https://examples.distancesampling.org/Distance-cameratraps/camera-distill.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.dht_bootstrap">summary.dht_bootstrap</a></code> for how to summarize the results,
<code><a href="#topic+bootdht_Nhat_summarize">bootdht_Nhat_summarize</a></code> and <code><a href="#topic+bootdht_Dhat_summarize">bootdht_Dhat_summarize</a></code> for an examples of
summary functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# fit a model to the minke data
data(minke)
mod1 &lt;- ds(minke)

# summary function to save the abundance estimate
Nhat_summarize &lt;- function(ests, fit) {
  return(data.frame(Nhat=ests$individuals$N$Estimate))
}

# perform 5 bootstraps
bootout &lt;- bootdht(mod1, flatfile=minke, summary_fun=Nhat_summarize, nboot=5)

# obtain basic summary information
summary(bootout)

## End(Not run)
</code></pre>

<hr>
<h2 id='bootdht_Dhat_summarize'>Simple summary of density results for bootstrap model</h2><span id='topic+bootdht_Dhat_summarize'></span>

<h3>Description</h3>

<p>When using <code><a href="#topic+bootdht">bootdht</a></code> one needs to use a summary function to
extract results from the resulting models per replicate. This function is
the simplest possible example of such a function, that just extracts the
estimated density (with stratum labels).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootdht_Dhat_summarize(ests, fit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootdht_Dhat_summarize_+3A_ests">ests</code></td>
<td>
<p>output from <code><a href="#topic+dht2">dht2</a></code>.</p>
</td></tr>
<tr><td><code id="bootdht_Dhat_summarize_+3A_fit">fit</code></td>
<td>
<p>fitted detection function object (unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Further examples of such functions can be found at
<a href="http://examples.distancesampling.org">http://examples.distancesampling.org</a>.
</p>


<h3>Value</h3>

<p><code>data.frame</code> with two columns (&quot;<code>Dhat</code>&quot; and &quot;<code>Label</code>&quot;), giving the
estimate(s) of density of individuals per stratum from each bootstrap
replicate. This <code>data.frame</code> can be examined for example, with
<code><a href="stats.html#topic+quantile">quantile</a></code> to compute confidence intervals.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootdht">bootdht</a></code> which this function is to be used with and
<code><a href="#topic+bootdht_Nhat_summarize">bootdht_Nhat_summarize</a></code> which does the same job
but returns abundance results.
</p>

<hr>
<h2 id='bootdht_Nhat_summarize'>Simple summary of abundance results for bootstrap model</h2><span id='topic+bootdht_Nhat_summarize'></span>

<h3>Description</h3>

<p>When using <code><a href="#topic+bootdht">bootdht</a></code> one needs to use a summary function to
extract results from the resulting models per replicate. This function is
the simplest possible example of such a function, that just extracts the
estimated abundance (with stratum labels).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootdht_Nhat_summarize(ests, fit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootdht_Nhat_summarize_+3A_ests">ests</code></td>
<td>
<p>output from <code><a href="#topic+dht2">dht2</a></code>.</p>
</td></tr>
<tr><td><code id="bootdht_Nhat_summarize_+3A_fit">fit</code></td>
<td>
<p>fitted detection function object (unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Further examples of such functions can be found at
<a href="http://examples.distancesampling.org">http://examples.distancesampling.org</a>.
</p>


<h3>Value</h3>

<p><code>data.frame</code> with two columns (&quot;<code>Nhat</code>&quot; and &quot;<code>Label</code>&quot;), giving the
estimate(s) of abundance of individuals per stratum from each bootstrap
replicate. This <code>data.frame</code> can be examined for example, with
<code><a href="stats.html#topic+quantile">quantile</a></code> to compute confidence intervals.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootdht">bootdht</a></code> which this function is to be used with and
<code><a href="#topic+bootdht_Dhat_summarize">bootdht_Dhat_summarize</a></code> which does the same job
but for abundance results.
</p>

<hr>
<h2 id='capercaillie'>Capercaillie in Monaughty Forest</h2><span id='topic+capercaillie'></span><span id='topic+capercaillie_units'></span>

<h3>Description</h3>

<p>Data from a line transect survey of capercaillie in Monaughty Forest, Moray,
Scotland.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 112 observations on the following 9 variables.
</p>

<ul>
<li> <p><code>Sample.Label</code> name of single transect
</p>
</li>
<li> <p><code>Effort</code> transect length (km)
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (m)
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>size</code> only individual birds detected
</p>
</li>
<li> <p><code>detected</code> whether detected
</p>
</li>
<li> <p><code>observer</code> single observer data
</p>
</li>
<li> <p><code>Region.Label</code> stratum name
</p>
</li>
<li> <p><code>Area</code> size of Monaughty Forest (ha)
</p>
</li></ul>


<hr>
<h2 id='checkdata'>Check that the data supplied to <code>ds</code> is correct</h2><span id='topic+checkdata'></span>

<h3>Description</h3>

<p>This is an internal function that checks the <code>data.frame</code>s supplied
to <code>ds</code> are &quot;correct&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkdata(
  data,
  region.table = NULL,
  sample.table = NULL,
  obs.table = NULL,
  formula = ~1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkdata_+3A_data">data</code></td>
<td>
<p>as in <code>ds</code></p>
</td></tr>
<tr><td><code id="checkdata_+3A_region.table">region.table</code></td>
<td>
<p>as in <code>ds</code></p>
</td></tr>
<tr><td><code id="checkdata_+3A_sample.table">sample.table</code></td>
<td>
<p>as in <code>ds</code></p>
</td></tr>
<tr><td><code id="checkdata_+3A_obs.table">obs.table</code></td>
<td>
<p>as in <code>ds</code></p>
</td></tr>
<tr><td><code id="checkdata_+3A_formula">formula</code></td>
<td>
<p>formula for the covariates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Throws an error if something goes wrong, otherwise returns a
<code>data.frame</code>.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='ClusterExercise'>Simulated minke whale data with cluster size</h2><span id='topic+ClusterExercise'></span><span id='topic+ClusterExercise_units'></span>

<h3>Description</h3>

<p>Data simulated from models fitted to 1992/1993 Southern Hemisphere minke
whale data collected by the International Whaling Commission. See Branch and
Butterworth (2001) for survey details (survey design is shown in figure
1(e)). Data simulated by David Borchers.
</p>


<h3>Format</h3>

<p><code>data.frame</code> with 99 observations of 9 variables:
</p>

<ul>
<li> <p><code>Region.Label</code> stratum label (<code>"North"</code> or <code>"South"</code>)
</p>
</li>
<li> <p><code>Area</code> stratum area  (square nautical mile)
</p>
</li>
<li> <p><code>Sample.Label</code> transect identifier
</p>
</li>
<li> <p><code>Effort</code> transect length  (nautical mile)
</p>
</li>
<li> <p><code>object</code> unique object ID
</p>
</li>
<li> <p><code>distance</code> observed distance  (nautical mile)
</p>
</li>
<li> <p><code>Cluster.strat</code> strata based on cluster size: 1, 2 and 3+
</p>
</li>
<li> <p><code>size</code> cluster size
</p>
</li>
<li> <p><code>Study.Area</code> name of study area
</p>
</li></ul>



<h3>References</h3>

<p>Branch, T.A. and D.S. Butterworth. (2001) Southern Hemisphere
minke whales: standardised abundance estimates from the 1978/79 to 1997/98
IDCR-SOWER surveys. Journal of Cetacean Research and Management 3(2):
143-174
</p>
<p>Hedley, S.L., and S.T. Buckland. (2004) Spatial models for line transect
sampling. Journal of Agricultural, Biological, and Environmental Statistics
9: 181-199. <a href="https://doi.org/10.1198/1085711043578">doi:10.1198/1085711043578</a>.
</p>

<hr>
<h2 id='convert_units'>Convert units for abundance estimation</h2><span id='topic+convert_units'></span>

<h3>Description</h3>

<p>It is often the case that effort, distances and prediction area are
collected in different units in the field. Functions in <code>Distance</code>
allow for an argument to convert between these and provide an answer that
makes sense. This function calculates that conversion factor, given
knowledge of the units of the quantities used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_units(distance_units, effort_units, area_units)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_units_+3A_distance_units">distance_units</code></td>
<td>
<p>units distances were measured in.</p>
</td></tr>
<tr><td><code id="convert_units_+3A_effort_units">effort_units</code></td>
<td>
<p>units that effort were measured in. Set as <code>NULL</code> for
point transects.</p>
</td></tr>
<tr><td><code id="convert_units_+3A_area_units">area_units</code></td>
<td>
<p>units for the prediction area.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>convert_units</code> expects particular names for its inputs &ndash; these should
be singular names of the unit (e.g., &quot;metre&quot; rather than &quot;metres&quot;). You can
view possible options with <code><a href="#topic+units_table">units_table</a></code>. Both UK and US
spellings are acceptable, case does not matter. For density estimation, area
must still be provided (&quot;objects per square ???&quot;). Note that for cue counts
(or other multiplier-based methods) one will still have to ensure that the
rates are in the correct units for the survey.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'># distances measured in metres, effort in kilometres and
# abundance over an area measured in hectares:
convert_units("Metre", "Kilometre", "Hectare")

# all SI units, so the result is 1
convert_units("Metre", "metre", "square metre")

# for points ignore effort
convert_units("Metre", NULL, "Hectare")
</code></pre>

<hr>
<h2 id='create_bins'>Create bins from a set of binned distances and a set of cutpoints.</h2><span id='topic+create_bins'></span>

<h3>Description</h3>

<p>This is an internal routine and shouldn't be necessary in normal analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_bins(data, cutpoints)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_bins_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with at least the column <code>distance</code>.</p>
</td></tr>
<tr><td><code id="create_bins_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector of cutpoints for the bins</p>
</td></tr>
</table>


<h3>Value</h3>

<p>argument <code>data</code> with two extra columns <code>distbegin</code> and
<code>distend</code>.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Distance)
data(minke)

# put the minke data into bins 0-1, 1-2, 2-3 km
minke_cuts &lt;- create_bins(minke[!is.na(minke$distance),], c(0,1,2,3))

## End(Not run)
</code></pre>

<hr>
<h2 id='create.bins'>Create bins from a set of binned distances and a set of cutpoints.</h2><span id='topic+create.bins'></span>

<h3>Description</h3>

<p><code>create.bins</code> is now deprecated, please use <code><a href="#topic+create_bins">create_bins</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.bins(data, cutpoints)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create.bins_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with at least the column <code>distance</code>.</p>
</td></tr>
<tr><td><code id="create.bins_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector of cutpoints for the bins</p>
</td></tr>
</table>


<h3>Value</h3>

<p>argument <code>data</code> with two extra columns <code>distbegin</code> and
<code>distend</code>.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='CueCountingExample'>Cue counts of whale blows</h2><span id='topic+CueCountingExample'></span><span id='topic+CueCountingExample_units'></span>

<h3>Description</h3>

<p>Cues are treated as an indirect count, requiring the use of multipliers.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 109 rows and 15 variables.
</p>

<ul>
<li><p> 'Region.Label stratum labels
</p>
</li>
<li> <p><code>Area</code> size (km^2) of each stratum
</p>
</li>
<li> <p><code>Sample.Label</code> transect labels
</p>
</li>
<li> <p><code>Cue.rate</code> rate of blows per animal per hour
</p>
</li>
<li> <p><code>Cue.rate.SE</code> variability in cue rate
</p>
</li>
<li> <p><code>Cue.rate.df</code> degrees of freedom (number of animals sampled for cues)
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (km)
</p>
</li>
<li> <p><code>Sample.Fraction</code> proportion of full circle scanned (radians)
</p>
</li>
<li> <p><code>Sample.Fraction.SE</code> variability in sampling fraction (0)
</p>
</li>
<li> <p><code>Search.time</code> Duration of scanning effort (hr)
</p>
</li>
<li> <p><code>bss</code> Beaufort sea state
</p>
</li>
<li> <p><code>sp</code> Species detected (all observations W in these data)
</p>
</li>
<li> <p><code>size</code> Number of animals in group (all 1 in these data)
</p>
</li>
<li> <p><code>Study.Area</code> study area name
</p>
</li></ul>



<h3>Details</h3>

<p>Because whale blows disappear instantaneously, there is no need to measure a
decay rate. However a cue production rate (blows per individual per unit
time) is required, as is a measure of variability of that rate.
</p>


<h3>Note</h3>

<p>There are two other nuances in this survey.  Even though the survey
is taking place on a moving ship, effort is measured as amount of time
scanning for blows.  In some instances, it is not possible for the observer
to scan the sea all around them as view may be restricted by the ship's
superstructure.  Here a <code style="white-space: pre;">&#8288;sampling fraction&#8288;</code> multiplier is employed to deal
with restricted vision.  Units of measure of <code>cue.rate</code> and <code>Search.time</code>
must be equal.
</p>

<hr>
<h2 id='dht2'>Abundance estimation for distance sampling models</h2><span id='topic+dht2'></span>

<h3>Description</h3>

<p>Once a detection function is fitted to data, this function can be used to
compute abundance estimates over required areas. The function also allows
for stratification and variance estimation via various schemes (see below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dht2(
  ddf,
  observations = NULL,
  transects = NULL,
  geo_strat = NULL,
  flatfile = NULL,
  strat_formula,
  convert_units = 1,
  er_est = c("R2", "P2"),
  multipliers = NULL,
  sample_fraction = 1,
  ci_width = 0.95,
  innes = FALSE,
  stratification = "geographical",
  total_area = NULL,
  binomial_var = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dht2_+3A_ddf">ddf</code></td>
<td>
<p>model fitted by <code><a href="#topic+ds">ds</a></code> or <code><a href="mrds.html#topic+ddf">ddf</a></code>.
Multiple detection functions can be supplied as a <code>list</code>.</p>
</td></tr>
<tr><td><code id="dht2_+3A_observations">observations</code></td>
<td>
<p><code>data.frame</code> to link detection function data (indexed by
<code>object</code> column IDs) to the transects (indexed by <code>Sample.Label</code> column
IDs). See &quot;Data&quot; below.</p>
</td></tr>
<tr><td><code id="dht2_+3A_transects">transects</code></td>
<td>
<p><code>data.frame</code> with information about samples (points or
line transects). See &quot;Data&quot; below.</p>
</td></tr>
<tr><td><code id="dht2_+3A_geo_strat">geo_strat</code></td>
<td>
<p><code>data.frame</code> with information about any geographical
stratification. See &quot;Data&quot; below.</p>
</td></tr>
<tr><td><code id="dht2_+3A_flatfile">flatfile</code></td>
<td>
<p>data in the flatfile format, see <code><a href="#topic+flatfile">flatfile</a></code>. Note
that the <code>object</code> column (uniquely identifying the observations) is required.</p>
</td></tr>
<tr><td><code id="dht2_+3A_strat_formula">strat_formula</code></td>
<td>
<p>a formula giving the stratification structure (see
&quot;Stratification&quot; below). Currently only one level of stratification is
supported.</p>
</td></tr>
<tr><td><code id="dht2_+3A_convert_units">convert_units</code></td>
<td>
<p>conversion factor between units for the distances,
effort and area. See &quot;Units&quot; below. Can supply one per detection function in
<code>ddf</code>.</p>
</td></tr>
<tr><td><code id="dht2_+3A_er_est">er_est</code></td>
<td>
<p>encounter rate variance estimator to be used. See &quot;Variance&quot;
below and <code><a href="mrds.html#topic+varn">varn</a></code>. Can supply one per detection function in
<code>ddf</code>.</p>
</td></tr>
<tr><td><code id="dht2_+3A_multipliers">multipliers</code></td>
<td>
<p><code>list</code> of <code>data.frame</code>s. See &quot;Multipliers&quot; below.</p>
</td></tr>
<tr><td><code id="dht2_+3A_sample_fraction">sample_fraction</code></td>
<td>
<p>proportion of the transect covered (e.g., 0.5 for
one-sided line transects). May be specified as either a single number or a
<code>data.frame</code> with 2 columns <code>Sample.Label</code> and <code>fraction</code> (if fractions are
different for each transect).</p>
</td></tr>
<tr><td><code id="dht2_+3A_ci_width">ci_width</code></td>
<td>
<p>for use with confidence interval calculation (defined as
1-alpha, so the default 95 will give a 95% confidence interval).</p>
</td></tr>
<tr><td><code id="dht2_+3A_innes">innes</code></td>
<td>
<p>logical flag for computing encounter rate variance using either
the method of Innes et al (2002) where estimated abundance per transect
divided by effort is used as the encounter rate, vs. (when <code>innes=FALSE</code>)
using the number of observations divided by the effort (as in Buckland et
al., 2001)</p>
</td></tr>
<tr><td><code id="dht2_+3A_stratification">stratification</code></td>
<td>
<p>what do strata represent, see &quot;Stratification&quot; below.</p>
</td></tr>
<tr><td><code id="dht2_+3A_total_area">total_area</code></td>
<td>
<p>for options <code>stratification="effort_sum"</code> and
<code>stratification="replicate"</code> the area to use as the total for combined,
weighted final estimates.</p>
</td></tr>
<tr><td><code id="dht2_+3A_binomial_var">binomial_var</code></td>
<td>
<p>if we wish to estimate abundance for the covered area
only (i.e., study area = surveyed area) then this must be set to be
<code>TRUE</code> and use the binomial variance estimator of Borchers et al.
(1998). This is only valid when objects are not clustered. (This situation
is rare.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> (of class <code>dht_result</code> for pretty printing) with
estimates and attributes containing additional information, see &quot;Outputs&quot;
for information on column names.
</p>


<h3>Data</h3>

<p>The data format allows for complex stratification schemes to be set-up. Three
objects are always required:
</p>

<ul>
<li> <p><code>ddf</code> the detection function (see <code><a href="#topic+ds">ds</a></code> or
<code><a href="mrds.html#topic+ddf">ddf</a></code> for information on the format of their inputs).
</p>
</li>
<li> <p><code>observations</code> has one row per observation and links the observations to
the transects. Required columns:
</p>

<ul>
<li> <p><code>object</code> (unique ID for the observation, which must match with the
data in the detection function)
</p>
</li>
<li> <p><code>Sample.Label</code> (unique ID for the transect).
</p>
</li>
<li><p> Additional columns for strata which are not included in the detection
function are required (stratification covariates that are included in
the detection function do not need to be included here). The important
case here is group size, which must have column name <code>size</code> (but does
not need to be in the detection function).
</p>
</li></ul>

</li>
<li> <p><code>transects</code> has one row per sample (point or line transect). At least
one row is required. Required columns: <code>Sample.Label</code> (unique ID for the
transect), <code>Effort</code> (line length for line transects, number of visits for
point transects), if there is more than one geographical stratum.
</p>
</li></ul>

<p>With only these three arguments, abundance can only be calculated for the
covered area. Including additional information on the area we wish to
extrapolate to (i.e., the study area), we can obtain abundance estimates:
</p>

<ul>
<li> <p><code>geo_strat</code> has one row for each stratum that we wish to estimate
abundance for. For abundance in the study area, at least one row is
required. Required columns: <code>Area</code> (the area of that stratum). If there
is &gt;1 row, then additional columns, named in <code>strat_formula</code>.'
</p>
</li></ul>

<p>Note that if the <code>Area</code> column is set to all 0, then only density estimates
will be returned.
</p>


<h3>Multipliers</h3>

<p>It is often the case that we cannot measure distances to individuals or
groups directly, but instead need to estimate distances to something they
produce (e.g., for whales, their blows; for elephants their dung) &ndash; this is
referred to as indirect sampling. We may need to use estimates of production
rate and decay rate for these estimates (in the case of dung or nests) or
just production rates (in the case of songbird calls or whale blows). We
refer to these conversions between &quot;number of cues&quot; and &quot;number of animals&quot;
as &quot;multipliers&quot;.
</p>
<p>The <code>multipliers</code> argument is a <code>list</code>, with 2 possible elements (<code>creation</code>
and <code>decay</code>). Each element of which is a <code>data.frame</code> and must have at least
a column named <code>rate</code>, which abundance estimates will be divided by (the
term &quot;multiplier&quot; is a misnomer, but kept for compatibility with Distance
for Windows). Additional columns can be added to give the standard error and
degrees of freedom for the rate if known as <code>SE</code> and <code>df</code>, respectively. You
can use a multirow <code>data.frame</code> to have different rates for different
geographical areas (for example). In this case the rows need to have a
column (or columns) to <code>merge</code> with the data (for example <code>Region.Label</code>).
</p>


<h3>Stratification</h3>

<p>The <code>strat_formula</code> argument is used to specify a column to use to stratify
the results, using the form <code>~column.name</code> where <code>column.name</code> is the column
name you wish to use.
</p>
<p>The <code>stratification</code> argument is used to specify which of four types of
stratification are intended:
</p>

<ul>
<li> <p><code>"geographical"</code> if each stratum represents a different geographical
areas and you want the total over all the areas
</p>
</li>
<li> <p><code>"effort_sum"</code> if your strata are in fact from replicate
surveys (perhaps using different designs) but you don't have many
replicates and/or want an estimate of &quot;average variance&quot;
</p>
</li>
<li> <p><code>"replicate"</code> if you have replicate surveys but have many of them, this
calculates the average abundance and the variance between those many
surveys (think of a population of surveys)
</p>
</li>
<li> <p><code>"object"</code> if the stratification is really about the type of object
observed, for example sex, species or life stage and what you want is the
total number of individuals across all the classes of objects. For example,
if you have stratified by sex and have males and females, but also want a
total number of animals, you should use this option.
</p>
</li></ul>

<p>A simple example of using <code>stratification="geographical"</code> is given below.
Further examples can be found at <a href="http://examples.distancesampling.org/">http://examples.distancesampling.org/</a>
(see, e.g., the deer pellet survey).
</p>


<h3>Variance</h3>

<p>Variance in the estimated abundance comes from multiple sources. Depending
on the data used to fit the model and estimate abundance, different
components will be included in the estimated variances. In the simplest
case, the detection function and encounter rate variance need to be
combined. If group size varies, then this too must be included. Finally, if
multipliers are used and have corresponding standard errors given, this are
also included. Variances are combined by assuming independence between the
measures and adding variances. A brief summary of how each component is
calculated is given here, though see references for more details.
</p>

<ul>
<li> <p><em>detection function</em>: variance from the detection function parameters is
transformed to variance about the abundance via a sandwich estimator (see
e.g., Appendix C of Borchers et al (2002)).
</p>
</li>
<li> <p><em>encounter rate</em>: for strata with &gt;1 transect in them, the encounter
rate estimators given in Fewster et al (2009) can be specified via the
<code>er_est</code> argument. If the argument <code>innes=TRUE</code> then calculations use the
estimated number of individuals in the transect (rather than the
observed), which was give by Innes et al (2002) as a superior estimator.
When there is only one transect in a stratum, Poisson variance is assumed.
Information on the Fewster encounter rate variance estimators are given in
<code><a href="mrds.html#topic+varn">varn</a></code>
</p>
</li>
<li> <p><em>group size</em>: if objects occur in groups (sometimes &quot;clusters&quot;), then
the empirical variance of the group sizes is added to the total variance.
</p>
</li>
<li> <p><em>multipliers</em>: if multipliers with standard errors are given, their
corresponding variances are added. If no standard errors are supplied,
then their contribution to variance is assumed to be 0.
</p>
</li></ul>



<h3>Units</h3>

<p>It is often the case that distances are recorded in one convenient set of
units, whereas the study area and effort are recorded in some other units.
To ensure that the results from this function are in the expected units, we
use the <code>convert_units</code> argument to supply a single number to convert the
units of the covered area to those of the study/stratification area (results
are always returned in the units of the study area). For line transects, the
covered area is calculated as <code>2 * width * length</code> where <code>width</code> is the
effective (half)width of the transect (often referred to as w in the
literature) and <code>length</code> is the line length (referred to as L). If <code>width</code>
and <code>length</code> are measured in kilometres and the study area in square
kilometres, then all is fine and <code>convert_units</code> is 1 (and can be ignored).
If, for example, line length and distances were measured in metres, we
instead need to convert this to be kilometres, by dividing by 1000 for each
of distance and length, hence <code>convert_units=1e-6</code>. For point transects,
this is slightly easier as we only have the radius and study area to
consider, so the conversion is just such that the units of the truncation
radius are the square root of the study area units.
</p>


<h3>Output</h3>

<p>On printing the output from call to <code>dht2</code>, three tables are produced. Below is a guide to the output columns names, per table.
</p>

<ul>
<li><p> Summary statistics table
</p>

<ul>
<li> <p><code>Region.Label</code> Stratum name (this first column name depends on the <code>formula</code> supplied)
</p>
</li>
<li> <p><code>Area</code> Size of stratum
</p>
</li>
<li> <p><code>CoveredArea</code> Surveyed area in stratum (2 x w x L)
</p>
</li>
<li> <p><code>Effort</code> Transect length or number of point visits per stratum
</p>
</li>
<li> <p><code>n</code> Number of detections
</p>
</li>
<li> <p><code>k</code> Number of replicate transects
</p>
</li>
<li> <p><code>ER</code> Encounter rate
</p>
</li>
<li> <p><code>se.ER</code> Standard error of encounter rate
</p>
</li>
<li> <p><code>cv.ER</code> Coefficient of variation of encounter rate
</p>
</li></ul>

</li>
<li><p> Abundance or density estimates table:
</p>

<ul>
<li> <p><code>Region.Label</code> As above
</p>
</li>
<li> <p><code>Estimate</code> Point estimate of abundance or density
</p>
</li>
<li> <p><code>se</code> Standard error
</p>
</li>
<li> <p><code>cv</code> Coefficient of variation
</p>
</li>
<li> <p><code>LCI</code> Lower confidence bound
</p>
</li>
<li> <p><code>UCI</code> Upper confidence bound
</p>
</li>
<li> <p><code>df</code> Degrees of freedom used for confidence interval computation
</p>
</li></ul>

</li>
<li><p> Components percentage of variance:
</p>

<ul>
<li> <p><code>Region.Label</code> As above
</p>
</li>
<li> <p><code>Detection</code> Percent of variance in abundance/density associated with
detection function uncertainty
</p>
</li>
<li> <p><code>ER</code> Percent of variance in abundance/density associated with
variability in encounter rate
</p>
</li>
<li> <p><code>Multipliers</code> Percent of variance in abundance/density associated with
uncertainty in multipliers
</p>
</li></ul>

</li></ul>



<h3>References</h3>

<p>Borchers, D.L., S.T. Buckland, P.W. Goedhart, E.D. Clarke, and S.L. Hedley.
1998. Horvitz-Thompson estimators for double-platform line transect surveys.
<em>Biometrics</em> 54: 1221-1237.
</p>
<p>Borchers, D.L., S.T. Buckland, and W. Zucchini. 2002 <em>Estimating Animal
Abundance: Closed Populations</em>. Statistics for Biology and Health. Springer
London.
</p>
<p>Buckland, S.T., E.A. Rexstad, T.A. Marques, and C.S. Oedekoven. 2015
<em>Distance Sampling: Methods and Applications</em>. Methods in Statistical
Ecology. Springer International Publishing.
</p>
<p>Buckland, S.T., D.R. Anderson, K. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. 2001 <em>Introduction to Distance Sampling: Estimating Abundance of
Biological Populations</em>. Oxford University Press.
</p>
<p>Innes, S., M. P. Heide-Jorgensen, J.L. Laake, K.L. Laidre, H.J. Cleator, P.
Richard, and R.E.A. Stewart. 2002 Surveys of belugas and narwhals in the
Canadian high arctic in 1996. <em>NAMMCO Scientific Publications</em> 4, 169-190.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# example of simple geographical stratification
# minke whale data, with 2 strata: North and South
data(minke)
# first fitting the detection function
minke_df &lt;- ds(minke, truncation=1.5, adjustment=NULL)
# now estimate abundance using dht2
# stratum labels are in the Region.Label column
minke_dht2 &lt;- dht2(minke_df, flatfile=minke, stratification="geographical",
                   strat_formula=~Region.Label)
# could compare this to minke_df$dht and see the same results
minke_dht2
# can alternatively report density
print(minke_dht2, report="density")

## End(Not run)
</code></pre>

<hr>
<h2 id='ds'>Fit detection functions and calculate abundance from line or point transect
data</h2><span id='topic+ds'></span>

<h3>Description</h3>

<p>This function fits detection functions to line or point transect data and
then (provided that survey information is supplied) calculates abundance and
density estimates. The examples below illustrate some basic types of
analysis using <code>ds()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds(
  data,
  truncation = ifelse(is.null(cutpoints), ifelse(is.null(data$distend),
    max(data$distance), max(data$distend)), max(cutpoints)),
  transect = "line",
  formula = ~1,
  key = c("hn", "hr", "unif"),
  adjustment = c("cos", "herm", "poly"),
  nadj = NULL,
  order = NULL,
  scale = c("width", "scale"),
  cutpoints = NULL,
  dht_group = FALSE,
  monotonicity = ifelse(formula == ~1, "strict", "none"),
  region_table = NULL,
  sample_table = NULL,
  obs_table = NULL,
  convert_units = 1,
  er_var = ifelse(transect == "line", "R2", "P2"),
  method = "nlminb",
  mono_method = "slsqp",
  quiet = FALSE,
  debug_level = 0,
  initial_values = NULL,
  max_adjustments = 5,
  er_method = 2,
  dht_se = TRUE,
  optimizer = "both",
  winebin = NULL,
  dht.group,
  region.table,
  sample.table,
  obs.table,
  convert.units,
  er.var,
  debug.level,
  initial.values,
  max.adjustments
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ds_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> containing at least a column called <code>distance</code> or
a numeric vector containing the distances.  NOTE!  If there is a column
called <code>size</code> in the data then it will be interpreted as group/cluster size,
see the section &quot;Clusters/groups&quot;, below. One can supply data as a &quot;flat
file&quot; and not supply <code>region_table</code>, <code>sample_table</code> and <code>obs_table</code>, see
&quot;Data format&quot;, below and <code><a href="#topic+flatfile">flatfile</a></code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_truncation">truncation</code></td>
<td>
<p>either truncation distance (numeric, e.g. 5) or percentage
(as a string, e.g. &quot;15%&quot;). Can be supplied as a <code>list</code> with elements <code>left</code>
and <code>right</code> if left truncation is required (e.g.  <code>list(left=1,right=20)</code> or
<code>list(left="1%",right="15%")</code> or even <code>list(left="1",right="15%")</code>).  By
default for exact distances the maximum observed distance is used as the
right truncation. When the data is binned, the right truncation is the
largest bin end point. Default left truncation is set to zero.</p>
</td></tr>
<tr><td><code id="ds_+3A_transect">transect</code></td>
<td>
<p>indicates transect type &quot;line&quot; (default) or &quot;point&quot;.</p>
</td></tr>
<tr><td><code id="ds_+3A_formula">formula</code></td>
<td>
<p>formula for the scale parameter. For a CDS analysis leave
this as its default <code>~1</code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_key">key</code></td>
<td>
<p>key function to use; <code>"hn"</code> gives half-normal (default), <code>"hr"</code>
gives hazard-rate and <code>"unif"</code> gives uniform. Note that if uniform key is
used, covariates cannot be included in the model.</p>
</td></tr>
<tr><td><code id="ds_+3A_adjustment">adjustment</code></td>
<td>
<p>adjustment terms to use; <code>"cos"</code> gives cosine (default),
<code>"herm"</code> gives Hermite polynomial and <code>"poly"</code> gives simple polynomial. A
value of <code>NULL</code> indicates that no adjustments are to be fitted.</p>
</td></tr>
<tr><td><code id="ds_+3A_nadj">nadj</code></td>
<td>
<p>the number of adjustment terms to fit. In the absence of
covariates in the formula, the default value (<code>NULL</code>) will select via AIC
(using a sequential forward selection algorithm) up to <code>max.adjustment</code>
adjustments (unless <code>order</code> is specified). When covariates are present
in the model formula, the default value of <code>NULL</code> results in no adjustment
terms being fitted in the model. A non-negative integer value will cause
the specified number of adjustments to be fitted. Supplying an integer
value will allow the use of adjustment terms in addition to specifying
covariates in the model. The order of adjustment terms used will depend
on the <code>key</code>and <code>adjustment</code>. For <code>key="unif"</code>, adjustments of order
1, 2, 3, ... are fitted when <code>adjustment = "cos"</code> and order 2, 4, 6, ...
otherwise. For <code>key="hn"</code> or <code>"hr"</code> adjustments of order 2, 3, 4, ... are
fitted when <code>adjustment = "cos"</code> and order 4, 6, 8, ... otherwise. See
Buckland et al. (2001, p. 47) for details.</p>
</td></tr>
<tr><td><code id="ds_+3A_order">order</code></td>
<td>
<p>order of adjustment terms to fit. The default value (<code>NULL</code>)
results in <code>ds</code> choosing the orders to use - see <code>nadj</code>. Otherwise a scalar
positive integer value can be used to fit a single adjustment term of the
specified order, and a vector of positive integers to fit multiple
adjustment terms of the specified orders. For simple and Hermite polynomial
adjustments, only even orders are allowed. The number of adjustment terms
specified here must match <code>nadj</code> (or <code>nadj</code> can be the default <code>NULL</code> value).</p>
</td></tr>
<tr><td><code id="ds_+3A_scale">scale</code></td>
<td>
<p>the scale by which the distances in the adjustment terms are
divided. Defaults to <code>"width"</code>, scaling by the truncation distance. If the
key is uniform only <code>"width"</code> will be used. The other option is <code>"scale"</code>:
the scale parameter of the detection</p>
</td></tr>
<tr><td><code id="ds_+3A_cutpoints">cutpoints</code></td>
<td>
<p>if the data are binned, this vector gives the cutpoints of
the bins. Supplying a distance column in your data and specifying cutpoints
is the recommended approach for all standard binned analyses.
Ensure that the first element is 0 (or the left truncation
distance) and the last is the distance to the end of the furthest bin.
(Default <code>NULL</code>, no binning.) If you have provided <code>distbegin</code> and <code>distend</code>
columns in your data (note this should only be used when your cutpoints
are not constant across all your data, e.g. planes flying at differing
altitudes) then do not specify the cutpoints argument as this will cause
the <code>distbegin</code> and <code>distend</code> columns in your data to be overwritten.</p>
</td></tr>
<tr><td><code id="ds_+3A_dht_group">dht_group</code></td>
<td>
<p>should density abundance estimates consider all groups to
be size 1 (abundance of groups) <code>dht_group=TRUE</code> or should the abundance of
individuals (group size is taken into account), <code>dht_group=FALSE</code>. Default
is <code>FALSE</code> (abundance of individuals is calculated).</p>
</td></tr>
<tr><td><code id="ds_+3A_monotonicity">monotonicity</code></td>
<td>
<p>should the detection function be constrained for
monotonicity weakly (<code>"weak"</code>), strictly (<code>"strict"</code>) or not at all
(<code>"none"</code> or <code>FALSE</code>). See Monotonicity, below. (Default <code>"strict"</code>). By
default it is on for models without covariates in the detection function,
off when covariates are present.</p>
</td></tr>
<tr><td><code id="ds_+3A_region_table">region_table</code></td>
<td>
<p><code>data_frame</code> with two columns:
</p>

<ul>
<li> <p><code>Region.Label</code> label for the region
</p>
</li>
<li> <p><code>Area</code> area of the region
</p>
</li>
<li> <p><code>region_table</code> has one row for each stratum. If there is no
stratification then <code>region_table</code> has one entry with <code>Area</code> corresponding
to the total survey area. If <code>Area</code> is omitted density estimates only are
produced.
</p>
</li></ul>
</td></tr>
<tr><td><code id="ds_+3A_sample_table">sample_table</code></td>
<td>
<p><code>data.frame</code> mapping the regions to the samples
(i.e. transects). There are three columns:
</p>

<ul>
<li> <p><code>Sample.Label</code> label for the sample
</p>
</li>
<li> <p><code>Region.Label</code> label for the region that the sample belongs to.
</p>
</li>
<li> <p><code>Effort</code> the effort expended in that sample (e.g. transect length).
</p>
</li></ul>
</td></tr>
<tr><td><code id="ds_+3A_obs_table">obs_table</code></td>
<td>
<p><code>data.frame</code> mapping the individual observations
(objects) to regions and samples. There should be three columns:
</p>

<ul>
<li> <p><code>object</code> unique numeric identifier for the observation
</p>
</li>
<li> <p><code>Region.Label</code> label for the region that the sample belongs to
</p>
</li>
<li> <p><code>Sample.Label</code> label for the sample
</p>
</li></ul>
</td></tr>
<tr><td><code id="ds_+3A_convert_units">convert_units</code></td>
<td>
<p>conversion between units for abundance estimation, see
&quot;Units&quot;, below. (Defaults to 1, implying all of the units are &quot;correct&quot;
already.)</p>
</td></tr>
<tr><td><code id="ds_+3A_er_var">er_var</code></td>
<td>
<p>encounter rate variance estimator to use when abundance
estimates are required. Defaults to &quot;R2&quot; for line transects and &quot;P2&quot; for
point transects (&gt;= 1.0.9, earlier versions &lt;= 1.0.8 used the &quot;P3&quot; estimator
by default for points). See <code><a href="#topic+dht2">dht2</a></code> for more information and if more
complex options are required.</p>
</td></tr>
<tr><td><code id="ds_+3A_method">method</code></td>
<td>
<p>optimization method to use (any method usable by
<code><a href="stats.html#topic+optim">optim</a></code> or <code><a href="optimx.html#topic+optimx">optimx</a></code>). Defaults to
<code>"nlminb"</code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_mono_method">mono_method</code></td>
<td>
<p>optimization method to use when monotonicity is enforced.
Can be either <code>slsqp</code> or <code>solnp</code>. Defaults to <code>slsqp</code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_quiet">quiet</code></td>
<td>
<p>suppress non-essential messages (useful for bootstraps etc).
Default value <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_debug_level">debug_level</code></td>
<td>
<p>print debugging output. <code>0</code>=none, <code>1-3</code> increasing levels
of debugging output.</p>
</td></tr>
<tr><td><code id="ds_+3A_initial_values">initial_values</code></td>
<td>
<p>a <code>list</code> of named starting values, see
<code><a href="mrds.html#topic+mrds_opt">mrds_opt</a></code>. Only allowed when AIC term selection is not
used.</p>
</td></tr>
<tr><td><code id="ds_+3A_max_adjustments">max_adjustments</code></td>
<td>
<p>maximum number of adjustments to try (default 5) only
used when <code>order=NULL</code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_er_method">er_method</code></td>
<td>
<p>encounter rate variance calculation: default = 2 gives the
method of Innes et al, using expected counts in the encounter rate. Setting
to 1 gives observed counts (which matches Distance for Windows) and 0 uses
binomial variance (only useful in the rare situation where study area =
surveyed area). See <code><a href="mrds.html#topic+dht.se">dht.se</a></code> for more details.</p>
</td></tr>
<tr><td><code id="ds_+3A_dht_se">dht_se</code></td>
<td>
<p>should uncertainty be calculated when using <code>dht</code>? Safe to
leave as <code>TRUE</code>, used in <code>bootdht</code>.</p>
</td></tr>
<tr><td><code id="ds_+3A_optimizer">optimizer</code></td>
<td>
<p>By default this is set to 'both'. In this case
the R optimizer will be used and if present the MCDS optimizer will also
be used. The result with the best likelihood value will be selected. To
run only a specified optimizer set this value to either 'R' or 'MCDS'.
See <code><a href="mrds.html#topic+mcds_dot_exe">mcds_dot_exe</a></code> for setup instructions.</p>
</td></tr>
<tr><td><code id="ds_+3A_winebin">winebin</code></td>
<td>
<p>If you are trying to use our MCDS.exe optimizer on a
non-windows system then you may need to specify the winebin. Please
see <code><a href="mrds.html#topic+mcds_dot_exe">mcds_dot_exe</a></code> for more details.</p>
</td></tr>
<tr><td><code id="ds_+3A_dht.group">dht.group</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_region.table">region.table</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_sample.table">sample.table</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_obs.table">obs.table</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_convert.units">convert.units</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_er.var">er.var</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_debug.level">debug.level</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_initial.values">initial.values</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
<tr><td><code id="ds_+3A_max.adjustments">max.adjustments</code></td>
<td>
<p>deprecated, see same argument with underscore, above.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements:
</p>

<ul>
<li> <p><code>ddf</code> a detection function model object.
</p>
</li>
<li> <p><code>dht</code> abundance/density information (if survey region data was supplied,
else <code>NULL</code>)
</p>
</li></ul>



<h3>Details</h3>

<p>If abundance estimates are required then the <code>data.frame</code>s <code>region_table</code>
and <code>sample_table</code> must be supplied. If <code>data</code> does not contain the columns
<code>Region.Label</code> and <code>Sample.Label</code> then the <code>data.frame</code> <code>obs_table</code> must
also be supplied. Note that stratification only applies to abundance
estimates and not at the detection function level. Density and abundance
estimates, and corresponding estimates of variance and confidence intervals,
are calculated using the methods described in Buckland et al. (2001)
sections 3.6.1 and 3.7.1 (further details can be found in the documentation
for <code><a href="mrds.html#topic+dht">dht</a></code>).
</p>
<p>For more advanced abundance/density estimation please see the
<code><a href="mrds.html#topic+dht">dht</a></code> and <code><a href="#topic+dht2">dht2</a></code> functions.
</p>
<p>Examples of distance sampling analyses are available at
<a href="http://examples.distancesampling.org/">http://examples.distancesampling.org/</a>.
</p>
<p>Hints and tips on fitting (particularly optimisation issues) are on the
<code><a href="mrds.html#topic+mrds_opt">mrds_opt</a></code> manual page.
</p>


<h3>Clusters/groups</h3>

<p>Note that if the data contains a column named <code>size</code>, cluster size will be
estimated and density/abundance will be based on a clustered analysis of
the data. Setting this column to be <code>NULL</code> will perform a non-clustered
analysis (for example if &quot;<code>size</code>&quot; means something else in your dataset).
</p>


<h3>Truncation</h3>

<p>The right truncation point is by default set to be largest observed distance
or bin end point. This is a default will not be appropriate for all data and
can often be the cause of model convergence failures. It is recommended that
one plots a histogram of the observed distances prior to model fitting so as
to get a feel for an appropriate truncation distance. (Similar arguments go
for left truncation, if appropriate). Buckland et al (2001) provide
guidelines on truncation.
</p>
<p>When specified as a percentage, the largest <code>right</code> and smallest <code>left</code>
percent distances are discarded. Percentages cannot be supplied when using
binned data.
</p>
<p>For left truncation, there are two options: (1) fit a detection function to
the truncated data as is (this is what happens when you set <code>left</code>).  This
does not assume that g(x)=1 at the truncation point. (2) manually remove
data with distances less than the left truncation distance &ndash; effectively
move the centre line out to be the truncation distance (this needs to be
done before calling <code>ds</code>). This then assumes that detection is certain at
the left truncation distance. The former strategy has a weaker assumption,
but will give higher variance as the detection function close to the line
has no data to tell it where to fit &ndash; it will be relying on the data from
after the left truncation point and the assumed shape of the detection
function. The latter is most appropriate in the case of aerial surveys,
where some area under the plane is not visible to the observers, but their
probability of detection is certain at the smallest distance.
</p>


<h3>Binning</h3>

<p>Note that binning is performed such that bin 1 is all distances greater or
equal to cutpoint 1 (&gt;=0 or left truncation distance) and less than cutpoint
2. Bin 2 is then distances greater or equal to cutpoint 2 and less than
cutpoint 3 and so on.
</p>


<h3>Monotonicity</h3>

<p>When adjustment terms are used, it is possible for the detection function to
not always decrease with increasing distance. This is unrealistic and can
lead to bias. To avoid this, the detection function can be constrained for
monotonicity (and is by default for detection functions without covariates).
</p>
<p>Monotonicity constraints are supported in a similar way to that described
in Buckland et al (2001). 20 equally spaced points over the range of the
detection function (left to right truncation) are evaluated at each round
of the optimisation and the function is constrained to be either always
less than it's value at zero (<code>"weak"</code>) or such that each value is
less than or equal to the previous point (monotonically decreasing;
<code>"strict"</code>). See also <code><a href="mrds.html#topic+check.mono">check.mono</a></code>.
</p>
<p>Even with no monotonicity constraints, checks are still made that the
detection function is monotonic, see <code><a href="mrds.html#topic+check.mono">check.mono</a></code>.
</p>


<h3>Units</h3>

<p>In extrapolating to the entire survey region it is important that the unit
measurements be consistent or converted for consistency. A conversion
factor can be specified with the <code>convert_units</code> argument. The values of
<code>Area</code> in <code>region_table</code>, must be made consistent with the units for
<code>Effort</code> in <code>sample_table</code> and the units of <code>distance</code> in the <code>data.frame</code>
that was analyzed. It is easiest if the units of <code>Area</code> are the square of
the units of <code>Effort</code> and then it is only necessary to convert the units of
<code>distance</code> to the units of <code>Effort</code>. For example, if <code>Effort</code> was entered
in kilometres and <code>Area</code> in square kilometres and <code>distance</code> in metres then
using <code>convert_units=0.001</code> would convert metres to kilometres, density
would be expressed in square kilometres which would then be consistent with
units for <code>Area</code>. However, they can all be in different units as long as
the appropriate composite value for <code>convert_units</code> is chosen. Abundance
for a survey region can be expressed as: <code>A*N/a</code> where <code>A</code> is <code>Area</code> for
the survey region, <code>N</code> is the abundance in the covered (sampled) region,
and <code>a</code> is the area of the sampled region and is in units of <code>Effort * distance</code>. The sampled region <code>a</code> is multiplied by <code>convert_units</code>, so it
should be chosen such that the result is in the same units as <code>Area</code>.  For
example, if <code>Effort</code> was entered in kilometres, <code>Area</code> in hectares (100m x
100m) and <code>distance</code> in metres, then using <code>convert_units=10</code> will convert
<code>a</code> to units of hectares (100 to convert metres to 100 metres for distance
and .1 to convert km to 100m units).
</p>


<h3>Data format</h3>

<p>One can supply <code>data</code> only to simply fit a detection function. However, if
abundance/density estimates are necessary further information is required.
Either the <code>region_table</code>, <code>sample_table</code> and <code>obs_table</code> <code>data.frame</code>s can
be supplied or all data can be supplied as a &quot;flat file&quot; in the <code>data</code>
argument. In this format each row in data has additional information that
would ordinarily be in the other tables. This usually means that there are
additional columns named: <code>Sample.Label</code>, <code>Region.Label</code>, <code>Effort</code> and
<code>Area</code> for each observation. See <code><a href="#topic+flatfile">flatfile</a></code> for an example.
</p>


<h3>Density estimation</h3>

<p>If column <code>Area</code> is omitted, a density estimate is generated but note that
the degrees of freedom/standard errors/confidence intervals will not match
density estimates made with the <code>Area</code> column present.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>


<h3>References</h3>

<p>Buckland, S.T., Anderson, D.R., Burnham, K.P., Laake, J.L., Borchers, D.L.,
and Thomas, L. (2001). Distance Sampling. Oxford University Press. Oxford,
UK.
</p>
<p>Buckland, S.T., Anderson, D.R., Burnham, K.P., Laake, J.L., Borchers, D.L.,
and Thomas, L. (2004). Advanced Distance Sampling. Oxford University Press.
Oxford, UK.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flatfile">flatfile</a></code>, <code><a href="mrds.html#topic+AIC.ds">AIC.ds</a></code>,
<code><a href="#topic+ds.gof">ds.gof</a></code>, <code><a href="#topic+p_dist_table">p_dist_table</a></code>,
<code><a href="mrds.html#topic+plot.ds">plot.ds</a></code>, <code><a href="#topic+add_df_covar_line">add_df_covar_line</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# An example from mrds, the golf tee data.
library(Distance)
data(book.tee.data)
tee.data &lt;- subset(book.tee.data$book.tee.dataframe, observer==1)
ds.model &lt;- ds(tee.data, 4)
summary(ds.model)
plot(ds.model)

## Not run: 
# same model, but calculating abundance
# need to supply the region, sample and observation tables
region &lt;- book.tee.data$book.tee.region
samples &lt;- book.tee.data$book.tee.samples
obs &lt;- book.tee.data$book.tee.obs

ds.dht.model &lt;- ds(tee.data, 4, region_table=region,
                   sample_table=samples, obs_table=obs)
summary(ds.dht.model)

# specify order 2 cosine adjustments
ds.model.cos2 &lt;- ds(tee.data, 4, adjustment="cos", order=2)
summary(ds.model.cos2)

# specify order 2 and 3 cosine adjustments, turning monotonicity
# constraints off
ds.model.cos23 &lt;- ds(tee.data, 4, adjustment="cos", order=c(2, 3),
                   monotonicity=FALSE)
# check for non-monotonicity -- actually no problems
check.mono(ds.model.cos23$ddf, plot=TRUE, n.pts=100)

# include both a covariate and adjustment terms in the model
ds.model.cos2.sex &lt;- ds(tee.data, 4, adjustment="cos", order=2,
                        monotonicity=FALSE, formula=~as.factor(sex))
# check for non-monotonicity -- actually no problems
check.mono(ds.model.cos2.sex$ddf, plot=TRUE, n.pts=100)

# truncate the largest 10% of the data and fit only a hazard-rate
# detection function
ds.model.hr.trunc &lt;- ds(tee.data, truncation="10%", key="hr",
                        adjustment=NULL)
summary(ds.model.hr.trunc)

# compare AICs between these models:
AIC(ds.model)
AIC(ds.model.cos2)
AIC(ds.model.cos23)

## End(Not run)
</code></pre>

<hr>
<h2 id='ds.gof'>Goodness of fit tests for distance sampling models</h2><span id='topic+ds.gof'></span>

<h3>Description</h3>

<p>This function is deprecated, please see <code><a href="#topic+gof_ds">gof_ds</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds.gof(model, breaks = NULL, nc = NULL, qq = TRUE, ks = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ds.gof_+3A_model">model</code></td>
<td>
<p>deprecated.</p>
</td></tr>
<tr><td><code id="ds.gof_+3A_breaks">breaks</code></td>
<td>
<p>deprecated.</p>
</td></tr>
<tr><td><code id="ds.gof_+3A_nc">nc</code></td>
<td>
<p>deprecated.</p>
</td></tr>
<tr><td><code id="ds.gof_+3A_qq">qq</code></td>
<td>
<p>deprecated.</p>
</td></tr>
<tr><td><code id="ds.gof_+3A_ks">ks</code></td>
<td>
<p>deprecated.</p>
</td></tr>
<tr><td><code id="ds.gof_+3A_...">...</code></td>
<td>
<p>deprecated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, deprecated.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>See Also</h3>

<p><code><a href="mrds.html#topic+qqplot.ddf">qqplot.ddf</a></code> <code><a href="mrds.html#topic+ddf.gof">ddf.gof</a></code>
</p>

<hr>
<h2 id='ducknest'>Ducknest line transect survey data</h2><span id='topic+ducknest'></span><span id='topic+ducknest_units'></span><span id='topic+ducknests_units'></span>

<h3>Description</h3>

<p>Simulated line transect survey of duck nests, designed to reproduce the data
of Figure 2 in Anderson and Pospahala (1970).
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 534 rows and 7 variables
</p>

<ul>
<li> <p><code>Region.Label</code> strata names (single stratum in this instance)
</p>
</li>
<li> <p><code>Area</code> size of refuge (0 in this case, actual size 60km^2)
</p>
</li>
<li> <p><code>Sample.Label</code> transect ID
</p>
</li>
<li> <p><code>Effort</code> length of transects (km)
</p>
</li>
<li> <p><code>object</code> nest ID
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (m)
</p>
</li>
<li> <p><code>Study.Area</code> name of wildlife refuge
</p>
</li></ul>



<h3>Details</h3>

<p>The Monte Vista National Wildlife Refuge is in southern Colorado in the USA
at an altitude of roughly 2400m.
</p>


<h3>Source</h3>

<p>Simulated data, from the distance sampling introductory course,
Centre for Research into Ecological &amp; Environmental Modelling, University of
St Andrews.
</p>


<h3>References</h3>

<p>Anderson, D. R., and R. S. Pospahala. 1970. Correction of bias
in belt transect studies of immotile objects. The Journal of Wildlife
Management 34 (1): 141–146. <a href="https://doi.org/10.2307/3799501">doi:10.2307/3799501</a>
</p>

<hr>
<h2 id='DuikerCameraTraps'>Duiker camera trap survey</h2><span id='topic+DuikerCameraTraps'></span><span id='topic+DuikerCameraTraps_units'></span>

<h3>Description</h3>

<p>Study took place in Tai National Park Cote d'Ivoire in 2014.  Filmed
Maxwell's duikers (Philantomba maxwellii) were assigned to distance
intervals; recorded distances are the midpoints of the intervals. This data
includes only observations recorded at times of peak activity.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 6277 rows and 6 variables
</p>

<ul>
<li> <p><code>Region.Label</code>  strata names (single stratum)
</p>
</li>
<li> <p><code>Area</code>  size of study area (40.37 km^2)
</p>
</li>
<li> <p><code>multiplier</code>  spatial effort, as the proportion of a circle covered by
the angle of view of the camera (42 degrees for these cameras)
</p>
</li>
<li> <p><code>Sample.Label</code>  camera station identifier (21 functioning cameras in
this data set)
</p>
</li>
<li> <p><code>Effort</code>  temporal effort, i.e. the number of 2-second time-steps over
which the camera operated
</p>
</li>
<li> <p><code>object</code> unique object ID
</p>
</li>
<li> <p><code>distance</code>  radial distance (m) to interval midpoint
</p>
</li></ul>



<h3>Source</h3>

<p>Howe, E.J., Buckland, S.T., Després-Einspenner, M.-L. and Kühl, H.S.
(2017), Distance sampling with camera traps. Methods Ecol Evol, 8:
1558-1565. <a href="https://doi.org/10.1111/2041-210X.12790">doi:10.1111/2041-210X.12790</a>
</p>
<p>Howe, Eric J. et al. (2018), Data from: Distance sampling with camera traps,
Dryad, Dataset, <a href="https://doi.org/10.5061/dryad.b4c70">doi:10.5061/dryad.b4c70</a>
</p>

<hr>
<h2 id='dummy_ddf'>Detection function objects when detection is certain</h2><span id='topic+dummy_ddf'></span>

<h3>Description</h3>

<p>Create a detection function object for strip/plot surveys for use with
<code>dht2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dummy_ddf(data, width, left = 0, transect = "line")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dummy_ddf_+3A_data">data</code></td>
<td>
<p>as specified for <code>ds</code> and <code>ddf</code> (including a <code>size</code> column)</p>
</td></tr>
<tr><td><code id="dummy_ddf_+3A_width">width</code></td>
<td>
<p>right truncation</p>
</td></tr>
<tr><td><code id="dummy_ddf_+3A_left">left</code></td>
<td>
<p>left truncation (default 0, no left truncation)</p>
</td></tr>
<tr><td><code id="dummy_ddf_+3A_transect">transect</code></td>
<td>
<p><code>"line"</code> or <code>"point"</code> transect</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='ETP_Dolphin'>Eastern Tropical Pacific spotted dolphin survey</h2><span id='topic+ETP_Dolphin'></span><span id='topic+ETP_Dolphin_units'></span>

<h3>Description</h3>

<p>Observers aboard tuna vessels detecting dolphin schools along with a number
of possibly useful covariates for modelling the detection function.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 1090 rows and 13 variables:
</p>

<ul>
<li> <p><code>Region.Label</code> stratum labels (only one)
</p>
</li>
<li> <p><code>Area</code> size (nmi) of each stratum
</p>
</li>
<li> <p><code>Sample.Label</code> transect labels
</p>
</li>
<li> <p><code>Effort</code> transect length (nmi)
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (nmi)
</p>
</li>
<li> <p><code>LnCluster</code> natural log of cluster size
</p>
</li>
<li> <p><code>Month</code> month of detection
</p>
</li>
<li> <p><code>Beauf.class</code> Beaufort sea state
</p>
</li>
<li> <p><code>Cue.type</code> initial cue triggering detection
</p>
</li>
<li> <p><code>Search.method</code> observer method making the detection
</p>
</li>
<li> <p><code>size</code> cluster size
</p>
</li>
<li> <p><code>Study.Area</code> study area name
</p>
</li></ul>



<h3>Details</h3>

<p>Several different search methods included in these data
</p>

<ul>
<li> <p><code>0</code> binoculars from crows nest
</p>
</li>
<li> <p><code>2</code> binoculars from elsewhere on ship
</p>
</li>
<li> <p><code>3</code> helicopter searching ahead of ship
</p>
</li>
<li> <p><code>5</code> radar detects of seabirds above dolphin schools
</p>
</li></ul>

<p>Several cue types were also recorded by observers.
</p>

<ul>
<li> <p><code>1</code> seabirds above the school
</p>
</li>
<li> <p><code>2</code> water splashes
</p>
</li>
<li> <p><code>3</code> unspecified
</p>
</li>
<li> <p><code>4</code> floating objects such as logs
</p>
</li></ul>



<h3>Source</h3>

<p>Inter-American Tropical Tuna Commission
</p>

<hr>
<h2 id='flatfile'>The flatfile data format</h2><span id='topic+flatfile'></span>

<h3>Description</h3>

<p><code>Distance</code> allows loading data as a &quot;flat file&quot; and analyse data (and
obtain abundance estimates) straight away, provided that the format of the
flat file is correct. One can provide the file as, for example, an Excel
spreadsheet using <code><a href="readxl.html#topic+read_excel">readxl::read_xls</a></code> in or CSV using
<code><a href="utils.html#topic+read.table">read.csv</a></code>.
</p>


<h3>Details</h3>

<p>Each row of the data table corresponds to either: (1) an observation or (2)
a sample (transect) without observations. In either case the following
columns must be present:
</p>

<ul>
<li> <p><code>distance</code> observed distance to object
</p>
</li>
<li> <p><code>object</code> a unique identifier for each observation (only required when
using <code><a href="#topic+dht2">dht2</a></code>)
</p>
</li>
<li> <p><code>Sample.Label</code> identifier for the sample (transect id)
</p>
</li>
<li> <p><code>Effort</code> effort for this transect (e.g. line transect length or number
of times point transect was visited)
</p>
</li>
<li> <p><code>Region.Label</code> label for a given stratum (see below)
</p>
</li>
<li> <p><code>Area</code> area of the strata<code style="white-space: pre;">&#8288;When the row represents a transect without observations,&#8288;</code>distance<code style="white-space: pre;">&#8288;and any other observation-specific covariates (including&#8288;</code>size<code style="white-space: pre;">&#8288;and detection function covariates) take the value&#8288;</code>NA'.
</p>
</li></ul>

<p>Note that in the simplest case (one area surveyed only once) there is only
one <code>Region.Label</code> and a single corresponding <code>Area</code> duplicated for each
observation.
</p>
<p>The example given below was provided by Eric Rexstad. Additional examples
can be found at  <a href="http://examples.distancesampling.org/">http://examples.distancesampling.org/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Distance)
# Need to have the readxl package installed from CRAN
require(readxl)

# Need to get the file path first
minke.filepath &lt;- system.file("minke.xlsx", package="Distance")

# Load the Excel file, note that col_names=FALSE and we add column names after
minke &lt;- read_xlsx(minke.filepath, col_names=FALSE)
names(minke) &lt;- c("Region.Label", "Area", "Sample.Label", "Effort",
                  "distance")
# One may want to call edit(minke) or head(minke) at this point
# to examine the data format

## perform an analysis using the exact distances
pooled.exact &lt;- ds(minke, truncation=1.5, key="hr", order=0)
summary(pooled.exact)


## Try a binned analysis
# first define the bins
dist.bins &lt;- c(0,.214, .428,.643,.857,1.071,1.286,1.5)
pooled.binned &lt;- ds(minke, truncation=1.5, cutpoints=dist.bins, key="hr",
                    order=0)

# binned with stratum as a covariate
minke$stratum &lt;- ifelse(minke$Region.Label=="North", "N", "S")
strat.covar.binned &lt;- ds(minke, truncation=1.5, key="hr",
                         formula=~as.factor(stratum), cutpoints=dist.bins)

# Stratified by North/South
full.strat.binned.North &lt;- ds(minke[minke$Region.Label=="North",],
                  truncation=1.5, key="hr", order=0, cutpoints=dist.bins)
full.strat.binned.South &lt;- ds(minke[minke$Region.Label=="South",],
                     truncation=1.5, key="hr", order=0, cutpoints=dist.bins)

## model summaries
model.sel.bin &lt;- data.frame(name=c("Pooled f(0)", "Stratum covariate",
                                   "Full stratification"),
                            aic=c(pooled.binned$ddf$criterion,
                                  strat.covar.binned$ddf$criterion,
                                  full.strat.binned.North$ddf$criterion+
                                  full.strat.binned.South$ddf$criterion))

# Note model with stratum as covariate is most parsimonious
print(model.sel.bin)

## End(Not run)
</code></pre>

<hr>
<h2 id='gof_ds'>Goodness of fit testing and quantile-quantile plots</h2><span id='topic+gof_ds'></span>

<h3>Description</h3>

<p>Goodness of fit testing for detection function models. For continuous
distances Kolmogorov-Smirnov and Cramer-von Mises tests can be used, when
binned or continuous distances are used a <code class="reqn">\chi^2</code> test can be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gof_ds(
  model,
  plot = TRUE,
  chisq = FALSE,
  nboot = 100,
  ks = FALSE,
  nc = NULL,
  breaks = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gof_ds_+3A_model">model</code></td>
<td>
<p>a fitted detection function.</p>
</td></tr>
<tr><td><code id="gof_ds_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> the Q-Q plot is plotted</p>
</td></tr>
<tr><td><code id="gof_ds_+3A_chisq">chisq</code></td>
<td>
<p>if <code>TRUE</code> then chi-squared statistic is calculated even
for models that use exact distances. Ignored for models that use binned
distances</p>
</td></tr>
<tr><td><code id="gof_ds_+3A_nboot">nboot</code></td>
<td>
<p>number of replicates to use to calculate p-values for the
Kolmogorov-Smirnov goodness of fit test statistics</p>
</td></tr>
<tr><td><code id="gof_ds_+3A_ks">ks</code></td>
<td>
<p>perform the Kolmogorov-Smirnov test (this involves many bootstraps
so can take a while)</p>
</td></tr>
<tr><td><code id="gof_ds_+3A_nc">nc</code></td>
<td>
<p>number of evenly-spaced distance classes for chi-squared test, if
<code>chisq=TRUE</code></p>
</td></tr>
<tr><td><code id="gof_ds_+3A_breaks">breaks</code></td>
<td>
<p>vector of cutpoints to use for binning, if <code>chisq=TRUE</code></p>
</td></tr>
<tr><td><code id="gof_ds_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code><a href="mrds.html#topic+ddf.gof">ddf.gof</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kolmogorov-Smirnov and Cramer-von Mises tests are based on looking at the
quantile-quantile plot produced by <code><a href="mrds.html#topic+qqplot.ddf">qqplot.ddf</a></code> and
deviations from the line <code class="reqn">x=y</code>.
</p>
<p>The Kolmogorov-Smirnov test asks the question &quot;what's the largest vertical
distance between a point and the <code class="reqn">y=x</code> line?&quot; It uses this distance as a
statistic to test the null hypothesis that the samples (EDF and CDF in our
case) are from the same distribution (and hence our model fits well). If the
deviation between the <code class="reqn">y=x</code> line and the points is too large we reject
the null hypothesis and say the model doesn't have a good fit.
</p>
<p>Rather than looking at the single biggest difference between the y=x line
and the points in the Q-Q plot, we might prefer to think about all the
differences between line and points, since there may be many smaller
differences that we want to take into account rather than looking for one
large deviation. Its null hypothesis is the same, but the statistic it uses
is the sum of the deviations from each of the point to the line.
</p>
<p>A chi-squared test is also run if <code>chisq=TRUE</code>. In this case binning of
distances is required if distance data are continuous. This can be specified
as a number of equally-spaced bins (using the argument <code style="white-space: pre;">&#8288;nc=&#8288;</code>) or the
cutpoints of bins (using <code style="white-space: pre;">&#8288;breaks=&#8288;</code>). The test compares the number of
observations in a given bin to the number predicted under the fitted
detection function.
</p>


<h3>Details</h3>

<p>Note that a bootstrap procedure is required for the Kolmogorov-Smirnov test
to ensure that the p-values from the procedure are correct as the we are
comparing the cumulative distribution function (CDF) and empirical
distribution function (EDF) and we have estimated the parameters of the
detection function. The <code>nboot</code> parameter controls the number of bootstraps
to use. Set to <code>0</code> to avoid computing bootstraps (much faster but with no
Kolmogorov-Smirnov results, of course).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# fit and test a simple model for the golf tee data
library(Distance)
data(book.tee.data)
tee.data &lt;- subset(book.tee.data$book.tee.dataframe, observer==1)
ds.model &lt;- ds(tee.data,4)
# don't make plot
gof_ds(ds.model, plot=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='golftees'>Golf tee data</h2><span id='topic+golftees'></span><span id='topic+golftees_units'></span>

<h3>Description</h3>

<p>The data are from independent surveys by eight observers of a population of
250 groups (760 individuals) of golf tees.  The tees, of two colours, were
placed in groups of between 1 and 8 in a survey region of 1680 m^2, either
exposed above the surrounding grass, or at least partially hidden by it.
They were surveyed by the 1999 statistics honours class at the University of
St Andrews.
</p>


<h3>Format</h3>

<p>Data is a <code>list</code> with 4 elements each of which is a <code>data.frame</code>:
</p>

<ul>
<li> <p><code>book.tee.dataframe</code>
</p>

<ul>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>observer</code> observer ID
</p>
</li>
<li> <p><code>detected</code> detected or not detected
</p>
</li>
<li> <p><code>distance</code> perpendicular distance
</p>
</li>
<li> <p><code>size</code> group size
</p>
</li>
<li> <p><code>sex</code> number of tees in group
</p>
</li>
<li> <p><code>exposure</code> tee height above ground
</p>
</li></ul>

</li>
<li> <p><code>book.tee.region</code>
</p>

<ul>
<li> <p><code>Region.Label</code> stratum name
</p>
</li>
<li> <p><code>Area</code> stratum size
</p>
</li></ul>

</li>
<li> <p><code>book.tee.samples</code>
</p>

<ul>
<li> <p><code>Sample.Label</code> transect label
</p>
</li>
<li> <p><code>Region.Label</code> stratum name
</p>
</li>
<li> <p><code>Effort</code> transect length
</p>
</li></ul>

</li>
<li> <p><code>book.tee.obs</code>
</p>

<ul>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>Region.Label</code> stratum in which it was detected
</p>
</li>
<li> <p><code>Sample.Label</code> transect on which it was detected
</p>
</li></ul>

</li></ul>



<h3>Details</h3>

<p>We treat each group of golf tees as a single animal with size equal to the
number of tees in the group; yellow tees are male, green are female; tees
exposed above the surrounding grass are classified as exposed, others as
unexposed.  We are grateful to Miguel Bernal for making these data
available; they were collected by him as part of a masters project.
</p>


<h3>References</h3>

<p>Borchers, D. L., S.T. Buckland, and W. Zucchini. 2002. Estimating Animal
Abundance: Closed Populations. Statistics for Biology and Health. London:
Springer-Verlag. <a href="https://link.springer.com/book/10.1007/978-1-4471-3708-5">https://link.springer.com/book/10.1007/978-1-4471-3708-5</a>
</p>
<p>Buckland, S.T., D.R. Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and
L. Thomas. Advanced Distance Sampling: Estimating Abundance of Biological
Populations. Oxford University Press. Oxford, 2004.
</p>

<hr>
<h2 id='logLik.dsmodel'>log-likelihood value for a fitted detection function</h2><span id='topic+logLik.dsmodel'></span>

<h3>Description</h3>

<p>Extract the log-likelihood from a fitted detection function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dsmodel'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLik.dsmodel_+3A_object">object</code></td>
<td>
<p>a fitted detection function model object</p>
</td></tr>
<tr><td><code id="logLik.dsmodel_+3A_...">...</code></td>
<td>
<p>included for S3 completeness, but ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value giving the log-likelihood with two attributes:
<code>"df"</code> the &quot;degrees of freedom for the model (number of parameters) and
<code>"nobs"</code> the number of observations used to fit the model
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Distance)
data(minke)
model &lt;- ds(minke, truncation=4)
# extract the log likelihood
logLik(model)

## End(Not run)
</code></pre>

<hr>
<h2 id='LTExercise'>Simulated line transect survey data</h2><span id='topic+LTExercise'></span><span id='topic+LTExercise_units'></span>

<h3>Description</h3>

<p>Simulated line transect survey. Twelve transects, detection function is
half-normal.  True object density is 79.8 animals per km^2.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 106 rows and 7 variables
</p>

<ul>
<li> <p><code>Region.Label</code> strata names (single stratum)
</p>
</li>
<li> <p><code>Area</code> size of study area (1 in this case, making abundance and density
equal)
</p>
</li>
<li> <p><code>Sample.Label</code> transect ID
</p>
</li>
<li> <p><code>Effort</code> length of transects (km)
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (m)
</p>
</li>
<li> <p><code>Study.Area</code> name of study area
</p>
</li></ul>



<h3>Note</h3>

<p>There is no unit object associated with this dataset
</p>


<h3>Source</h3>

<p>Simulated data, from the distance sampling introductory course,
Centre for Research into Ecological &amp; Environmental Modelling, University of
St Andrews.
</p>

<hr>
<h2 id='make_activity_fn'>Multiplier bootstrap helper functions</h2><span id='topic+make_activity_fn'></span>

<h3>Description</h3>

<p>Helper to use a models specified using <code><a href="activity.html#topic+fitact">activity::fitact</a></code> to fit an
activity model and generate single realisations for bootstrapping with
<code><a href="#topic+bootdht">bootdht</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_activity_fn(..., detector_daily_duration = 24)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_activity_fn_+3A_...">...</code></td>
<td>
<p>parameters specified by activity::fitact</p>
</td></tr>
<tr><td><code id="make_activity_fn_+3A_detector_daily_duration">detector_daily_duration</code></td>
<td>
<p>by default we assume that detectors were able to detect animals for 24 hours, if they were only able to do this for some proportion of the day (say daylight hours), then adjust this argument accordingly</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses <code><a href="activity.html#topic+fitact">activity::fitact</a></code> to generate single possible availability estimates
based on bootstraps. The function returns another function, which can be
passed to <code>bootdht</code>. It is recommended that you try out the function before
passing it to <code><a href="#topic+bootdht">bootdht</a></code>. See examples for a template for use.
</p>


<h3>Value</h3>

<p>a function which generates a single bootstrap estimate of
availability
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='minke'>Simulated minke whale data</h2><span id='topic+minke'></span>

<h3>Description</h3>

<p>Data simulated from models fitted to 1992/1993 Southern Hemisphere minke
whale data collected by the International Whaling Commission. See Branch and
Butterworth (2001) for survey details (survey design is shown in figure
1(e)). Data simulated by David Borchers.
</p>


<h3>Format</h3>

<p><code>data.frame</code> with 99 observations of 5 variables:
</p>

<ul>
<li> <p><code>Region.Label</code> stratum label (<code>"North"</code> or <code>"South"</code>)
</p>
</li>
<li> <p><code>Area</code> stratum area
</p>
</li>
<li> <p><code>Sample.Label</code> transect identifier
</p>
</li>
<li> <p><code>Effort</code> transect length
</p>
</li>
<li> <p><code>distance</code> observed distance
</p>
</li>
<li> <p><code>object</code> unique object ID
</p>
</li></ul>



<h3>Details</h3>

<p>Data are included here as both R data and as an Excel spreadsheet to
illustrate the &quot;flat file&quot; input method. See <code><a href="#topic+flatfile">flatfile</a></code> for how
to load this data and an example analysis.
</p>


<h3>Source</h3>

<p>Shipped with the Distance for Windows.
</p>


<h3>References</h3>

<p>Branch, T.A. and D.S. Butterworth (2001) Southern Hemisphere
minke whales: standardised abundance estimates from the 1978/79 to 1997/98
IDCR-SOWER surveys. Journal of Cetacean Research and Management 3(2):
143-174
</p>
<p>Hedley, S.L., and S.T. Buckland. Spatial Models for Line Transect Sampling.
Journal of Agricultural, Biological, and Environmental Statistics 9, no. 2
(2004): 181-199. <a href="https://doi.org/10.1198/1085711043578">doi:10.1198/1085711043578</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(minke)
head(minke)
</code></pre>

<hr>
<h2 id='p_dist_table'>Distribution of probabilities of detection</h2><span id='topic+p_dist_table'></span>

<h3>Description</h3>

<p>Generate a table of frequencies of probability of detection from a detection
function model. This is particularly useful when employing covariates, as it
can indicate if there are detections with very small detection probabilities
that can be unduly influential when calculating abundance estimates.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p_dist_table_+3A_object">object</code></td>
<td>
<p>fitted detection function</p>
</td></tr>
<tr><td><code id="p_dist_table_+3A_bins">bins</code></td>
<td>
<p>how the results should be binned</p>
</td></tr>
<tr><td><code id="p_dist_table_+3A_proportion">proportion</code></td>
<td>
<p>should proportions be returned as well as counts?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because <code><a href="mrds.html#topic+dht">dht</a></code> uses a Horvitz-Thompson-like estimator, abundance
estimates can be sensitive to errors in the estimated probabilities. The
estimator is based on <code class="reqn">\sum 1/ \hat{P}_a(z_i)</code>, which means that the
sensitivity is greater for smaller detection probabilities. As a rough
guide, we recommend that the method be not used if more than say 5% of the
<code class="reqn">\hat{P}_a(z_i)</code> are less than 0.2, or if any are less than 0.1. If
these conditions are violated, the truncation distance w can be reduced.
This causes some loss of precision relative to standard distance sampling
without covariates.
</p>


<h3>Value</h3>

<p>a <code>data.frame</code> with probability bins, counts and (optionally)
proportions. The object has an attribute <code>p_range</code> which contains the
range of estimated detection probabilities
</p>


<h3>Note</h3>

<p>This function is located in the <code>mrds</code> package but the documentation
is provided here for easy access.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>References</h3>

<p>Marques, F.F.C. and S.T. Buckland. 2004. Covariate models for
the detection function.
In: Advanced Distance Sampling, eds. S.T. Buckland, D.R. Anderson, K.P.
Burnham, J.L. Laake, D.L. Borchers, and L. Thomas. Oxford University
Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# example using a model for the minke data
data(minke)
# fit a model
result &lt;- ds(minke, formula=~Region.Label)
# print table
p_dist_table(result)
# with proportions
p_dist_table(result, proportion=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.dsmodel'>Plot a fitted detection function</h2><span id='topic+plot.dsmodel'></span>

<h3>Description</h3>

<p>This is just a simple wrapper around <code><a href="mrds.html#topic+plot.ds">plot.ds</a></code>. See the
manual page for that function for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dsmodel'
plot(x, pl.den = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.dsmodel_+3A_x">x</code></td>
<td>
<p>an object of class <code>dsmodel</code>.</p>
</td></tr>
<tr><td><code id="plot.dsmodel_+3A_pl.den">pl.den</code></td>
<td>
<p>shading density for histogram (default <code>0</code>, no shading)</p>
</td></tr>
<tr><td><code id="plot.dsmodel_+3A_...">...</code></td>
<td>
<p>extra arguments to be passed to <code><a href="mrds.html#topic+plot.ds">plot.ds</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>, just produces a plot.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_df_covar_line">add_df_covar_line</a></code>
</p>

<hr>
<h2 id='predict.dsmodel'>Predictions from a fitted detection function</h2><span id='topic+predict.dsmodel'></span>

<h3>Description</h3>

<p>Predict detection probabilities (or effective strip widths/effective areas
of detection) from a fitted distance sampling model using either the
original data (i.e., &quot;fitted&quot; values) or using new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dsmodel'
predict(
  object,
  newdata = NULL,
  compute = FALSE,
  esw = FALSE,
  se.fit = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.dsmodel_+3A_object">object</code></td>
<td>
<p><code>ds</code> model object.</p>
</td></tr>
<tr><td><code id="predict.dsmodel_+3A_newdata">newdata</code></td>
<td>
<p>new <code>data.frame</code> for prediction, this must include a column
called &quot;<code>distance</code>&quot;.</p>
</td></tr>
<tr><td><code id="predict.dsmodel_+3A_compute">compute</code></td>
<td>
<p>if <code>TRUE</code> compute values and don't use the fitted values
stored in the model object.</p>
</td></tr>
<tr><td><code id="predict.dsmodel_+3A_esw">esw</code></td>
<td>
<p>if <code>TRUE</code>, returns effective strip half-width (or effective area
of detection for point transect models) integral from 0 to the truncation
distance (<code>width</code>) of <code class="reqn">p(y)dy</code>; otherwise it returns the integral from 0
to truncation width of <code class="reqn">p(y)\pi(y)</code> where <code class="reqn">\pi(y)=1/w</code> for lines and
<code class="reqn">\pi(y)=2r/w^2</code> for points.</p>
</td></tr>
<tr><td><code id="predict.dsmodel_+3A_se.fit">se.fit</code></td>
<td>
<p>should standard errors on the predicted probabilities of
detection (or ESW if <code>esw=TRUE</code>) estimated? Stored in the <code>se.fit</code> element</p>
</td></tr>
<tr><td><code id="predict.dsmodel_+3A_...">...</code></td>
<td>
<p>for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For line transects, the effective strip half-width (<code>esw=TRUE</code>) is the
integral of the fitted detection function over either 0 to W or the
specified <code>int.range</code>.  The predicted detection probability is the
average probability which is simply the integral divided by the distance
range. For point transect models, <code>esw=TRUE</code> calculates the effective
area of detection (commonly referred to as &quot;nu&quot;, this is the integral of
<code>2/width^2 * r * g(r)</code>.
</p>
<p>Fitted detection probabilities are stored in the <code>model</code> object and
these are returned unless <code>compute=TRUE</code> or <code>newdata</code> is
specified. <code>compute=TRUE</code> is used to estimate numerical derivatives for
use in delta method approximations to the variance.
</p>
<p>Note that the ordering of the returned results when no new data is supplied
(the &quot;fitted&quot; values) will not necessarily be the same as the data supplied
to <code><a href="mrds.html#topic+ddf">ddf</a></code>, the data (and hence results from <code>predict</code>) will
be sorted by object ID (<code>object</code>).
</p>


<h3>Value</h3>

<p>a list with a single element: <code>fitted</code>, a vector of average
detection probabilities or esw values for each observation in the original
data or<code>newdata</code>. If <code>se.fit=TRUE</code> there is an additional element <code style="white-space: pre;">&#8288;$se.fit&#8288;</code>,
which contains the standard errors of the probabilities of detection or ESW.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='predict.fake_ddf'>Prediction for fake detection functions</h2><span id='topic+predict.fake_ddf'></span>

<h3>Description</h3>

<p>Prediction function for dummy detection functions. The function returns as
many 1s as there are rows in <code>newdata</code>. If <code>esw=TRUE</code> then the
strip width is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fake_ddf'
predict(
  object,
  newdata = NULL,
  compute = FALSE,
  int.range = NULL,
  esw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fake_ddf_+3A_object">object</code></td>
<td>
<p>model object</p>
</td></tr>
<tr><td><code id="predict.fake_ddf_+3A_newdata">newdata</code></td>
<td>
<p>how many 1s should we return?</p>
</td></tr>
<tr><td><code id="predict.fake_ddf_+3A_compute">compute</code></td>
<td>
<p>unused, compatibility with <code><a href="mrds.html#topic+predict.ds">mrds::predict</a></code></p>
</td></tr>
<tr><td><code id="predict.fake_ddf_+3A_int.range">int.range</code></td>
<td>
<p>unused, compatibility with <code><a href="mrds.html#topic+predict.ds">mrds::predict</a></code></p>
</td></tr>
<tr><td><code id="predict.fake_ddf_+3A_esw">esw</code></td>
<td>
<p>should the strip width be returned?</p>
</td></tr>
<tr><td><code id="predict.fake_ddf_+3A_...">...</code></td>
<td>
<p>for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='print.dht_result'>Print abundance estimates</h2><span id='topic+print.dht_result'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+dht2">dht2</a></code> for information on printed column names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dht_result'
print(x, report = "abundance", groups = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.dht_result_+3A_x">x</code></td>
<td>
<p>object of class <code>dht_result</code></p>
</td></tr>
<tr><td><code id="print.dht_result_+3A_report">report</code></td>
<td>
<p>should <code>"abundance"</code>, <code>"density"</code> or <code>"both"</code> be reported?</p>
</td></tr>
<tr><td><code id="print.dht_result_+3A_groups">groups</code></td>
<td>
<p>should abundance/density of groups be produced?</p>
</td></tr>
<tr><td><code id="print.dht_result_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>

<hr>
<h2 id='print.dsmodel'>Simple pretty printer for distance sampling analyses</h2><span id='topic+print.dsmodel'></span>

<h3>Description</h3>

<p>Simply prints out a brief description of the model which was fitted. For more
detailed information use <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dsmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.dsmodel_+3A_x">x</code></td>
<td>
<p>a distance sampling analysis (result from calling <code><a href="#topic+ds">ds</a></code>).</p>
</td></tr>
<tr><td><code id="print.dsmodel_+3A_...">...</code></td>
<td>
<p>not passed through, just for S3 compatibility.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='print.summary.dsmodel'>Print summary of distance detection function model object</h2><span id='topic+print.summary.dsmodel'></span>

<h3>Description</h3>

<p>Provides a brief summary of a distance sampling analysis. Including:
detection function parameters, model selection criterion, and optionally
abundance in the covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.dsmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.dsmodel_+3A_x">x</code></td>
<td>
<p>a summary of distance sampling analysis</p>
</td></tr>
<tr><td><code id="print.summary.dsmodel_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, just prints the summary.
</p>


<h3>Author(s)</h3>

<p>David L. Miller and Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="mrds.html#topic+summary.ds">summary.ds</a></code>
</p>

<hr>
<h2 id='PTExercise'>Simulated point transect survey data</h2><span id='topic+PTExercise'></span><span id='topic+PTExercise_units'></span>

<h3>Description</h3>

<p>Simulated point transect survey. Thirty point transects, detection function
is half-normal.  True object density is 79.6 animals per hectare.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 144 rows and 7 variables
</p>

<ul>
<li> <p><code>Region.Label</code> strata names (single stratum)
</p>
</li>
<li> <p><code>Area</code> size of study area (0 in this case)
</p>
</li>
<li> <p><code>Sample.Label</code> transect ID
</p>
</li>
<li> <p><code>Effort</code> number of visits to point
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> radial distance (m)
</p>
</li>
<li> <p><code>Study.Area</code> name of study area
</p>
</li></ul>



<h3>Source</h3>

<p>Simulated data, from the distance sampling introductory course,
Centre for Research into Ecological &amp; Environmental Modelling, University of
St Andrews.
</p>

<hr>
<h2 id='QAIC'>Tools for model selection when distance sampling data are overdispersed</h2><span id='topic+QAIC'></span><span id='topic+chi2_select'></span>

<h3>Description</h3>

<p>Overdispersion causes AIC to select overly-complex models, so analysts
should specify the number/order of adjustment terms manually when fitting
distance sampling models to data from camera traps, rather than allowing
automated selection using AIC. Howe et al (2019) described a two-step method
for selecting among models of the detection function in the face of
overdispersion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QAIC(object, ..., chat = NULL, k = 2)

chi2_select(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QAIC_+3A_object">object</code></td>
<td>
<p>a fitted detection function object</p>
</td></tr>
<tr><td><code id="QAIC_+3A_...">...</code></td>
<td>
<p>additional fitted model objects.</p>
</td></tr>
<tr><td><code id="QAIC_+3A_chat">chat</code></td>
<td>
<p>a value of <code class="reqn">\hat{c}</code> to be used in QAIC calculation</p>
</td></tr>
<tr><td><code id="QAIC_+3A_k">k</code></td>
<td>
<p>penalty per parameter to be used; default 2</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In step 1, and overdispersion factor (<code class="reqn">\hat{c}</code>) is computed
either (1) for each key function family, from the most complex model in each
family, as the chi-square goodness of fit test statistic divided by its
degrees of freedom (<code class="reqn">\hat{c}_1</code>), or (2) for all models in the
candidate set, from the raw data (<code class="reqn">\hat{c}_1</code>). In camera trap
surveys of solitary animals, <code class="reqn">\hat{c}_1</code> would be the mean number
of distance observations recorded during a single pass by an animal in front
of a trap. In surveys of social animals employing human observers,
<code class="reqn">\hat{c}_1</code> would be the mean number of detected animals per
detected group, and in camera trap surveys of social animals
<code class="reqn">\hat{c}_1</code> the mean number of distance observations recorded
during an encounter between a group of animals and a CT.  In step two, the
chi-square goodness of fit statistic divided by its degrees of freedom is
calculated for the QAIC-minimizing model within each key function, and the
model with the lowest value is selected for estimation.
</p>
<p>The <code>QAIC()</code> function should only be used select among models with the same
key function (step 1). <code>QAIC()</code> uses <code class="reqn">\hat{c}_1</code> by default,
computing it from the model with the most parameters. Alternatively,
<code class="reqn">\hat{c}_1</code> can be calculated from the raw data and included in
the call to <code>QAIC()</code>. Users must identify the QAIC-minimizing model within
key functions from the resulting <code>data.frame</code>, and provide these models as
arguments in <code>ch2_select()</code>. <code>chi2_select()</code> then computes and reports the
chi-square goodness of fit statistic divided by its degrees of freedom for
each of those models. The model with the lowest value is recommended for
estimation.
</p>


<h3>Value</h3>

<p>a <code>data.frame</code> with one row per model supplied, in the same order as
given
</p>


<h3>Author(s)</h3>

<p>David L Miller, based on code from Eric Rexstad and explanation from
Eric Howe.
</p>


<h3>References</h3>

<p>Howe, E. J., Buckland, S. T., Després-Einspenner, M.-L., &amp; Kühl, H. S. (2019). Model selection with overdispersed distance sampling data. Methods in Ecology and Evolution, 10(1), 38–47. <a href="https://doi.org/10.1111/2041-210X.13082">doi:10.1111/2041-210X.13082</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Distance)
data("wren_cuecount")

# fit hazard-rate key models
w3.hr0 &lt;- ds(wren_cuecount, transect="point", key="hr", adjustment=NULL,
             truncation=92.5)
w3.hr1 &lt;- ds(wren_cuecount, transect="point", key="hr", adjustment="cos",
             order=2, truncation=92.5)
w3.hr2 &lt;- ds(wren_cuecount, transect="point", key="hr", adjustment="cos",
             order=c(2, 4), truncation=92.5)

# fit unform key models
w3.u1 &lt;- ds(wren_cuecount, transect="point", key="unif", adjustment="cos",
            order=1, truncation=92.5)
w3.u2 &lt;- ds(wren_cuecount, transect="point", key="unif", adjustment="cos",
            order=c(1,2), monotonicity="none",  truncation=92.5)
w3.u3 &lt;- ds(wren_cuecount, transect="point", key="unif", adjustment="cos",
            order=c(1,2,3), monotonicity="none", truncation=92.5)

# fit half-normal key functions
w3.hn0 &lt;- ds(wren_cuecount, transect="point", key="hn", adjustment=NULL,
             truncation=92.5)
w3.hn1 &lt;- ds(wren_cuecount, transect="point", key="hn", adjustment="herm",
             order=2, truncation=92.5)

# stage 1: calculate QAIC per model set
QAIC(w3.hr0, w3.hr1, w3.hr2)  # no adjustments smallest
QAIC(w3.u1, w3.u2, w3.u3)     # 2 adjustment terms (by 0.07)
QAIC(w3.hn0, w3.hn1)  # no adjustments smallest

# stage 2: select using chi^2/degrees of freedom between sets
chi2_select(w3.hr0, w3.u2, w3.hn0)

# example using a pre-calculated chat
chat &lt;- attr(QAIC(w3.hr0, w3.hr1, w3.hr2), "chat")
QAIC(w3.hr0, chat=chat)

## End(Not run)
</code></pre>

<hr>
<h2 id='Savannah_sparrow_1980'>Savanna sparrow point transects</h2><span id='topic+Savannah_sparrow_1980'></span><span id='topic+Savannah_sparrow_1981'></span><span id='topic+Savannah_sparrow_1980_units'></span><span id='topic+Savannah_sparrow_1981_units'></span>

<h3>Description</h3>

<p>Point transect data collected in Colorado 1980/81 to examine effect of
agricultural practices upon avian community.
</p>


<h3>Format</h3>

<p><code>data.frame</code> with 468 observations (1980) and 448 observations
(1981) of 7 variables:
</p>

<ul>
<li> <p><code>Region.Label</code> stratum label (pasture ID)
</p>
</li>
<li> <p><code>Area</code> stratum area (set to 1 so density is reported)
</p>
</li>
<li> <p><code>Sample.Label</code> transect identifier
</p>
</li>
<li> <p><code>Effort</code> number of visits
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> radial distance (m)
</p>
</li>
<li> <p><code>Study.Area</code> name of study area
</p>
</li></ul>



<h3>Details</h3>

<p>Design consisted of point transects placed in multiple pastures (3 in 1980
and 4 in 1981). While many species were observed, only data for Savannah
sparrows (<em>Passerculus sandwichensis</em>) are included here.
</p>
<p>Data given here are different from the Distance for Windows example project.
Here each individual sighting is treated as an independent observation. This
corresponds to the analysis in Buckland et al. (2001) Section 8.7.  In the
Distance for Windows project objects are clusters of individuals. This
should not affect the results too greatly as most clusters were of size 1,
and so the results obtained should not be too far out.
</p>


<h3>References</h3>

<p>Knopf, F.L., J.A. Sedgwick, and R.W. Cannon. (1988) Guild structure of a
riparian avifauna relative to seasonal cattle grazing.  The Journal of
Wildlife Management 52 (2): 280–290.  <a href="https://doi.org/10.2307/3801235">doi:10.2307/3801235</a>
</p>

<hr>
<h2 id='sikadeer'>Sika deer pellet data from southern Scotland</h2><span id='topic+sikadeer'></span><span id='topic+sikadeer_units'></span>

<h3>Description</h3>

<p>Because sika deer spend most of their time in woodland areas, abundance
estimates are based on pellet group counts.  Line transect methods were
applied to estimate deer pellet group density by geographic block.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 1923 rows and 11 variables.
</p>

<ul>
<li> <p><code>Region.Label</code> stratum labels
</p>
</li>
<li> <p><code>Area</code> size (ha) of each stratum
</p>
</li>
<li> <p><code>Sample.Label</code> transect labels
</p>
</li>
<li> <p><code>Defecation.rate</code> rate of dung production per individual per day
</p>
</li>
<li> <p><code>Defecation.rate.SE</code> variability in defecation rate
</p>
</li>
<li> <p><code>Decay.rate</code> time (days) for dung to become undetectable
</p>
</li>
<li> <p><code>Decay.rate.SE</code> variability in decay rate
</p>
</li>
<li> <p><code>Effort</code> transect length (km)
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (cm)
</p>
</li>
<li> <p><code>Study.Area</code> study area name
</p>
</li></ul>



<h3>Details</h3>

<p>Data presented here are from the Peebleshire portion of the study described
by Marques et al. (2001).
</p>


<h3>References</h3>

<p>Marques, F.F.C., S.T. Buckland, D. Goffin, C.E. Dixon, D.L.  Borchers, B.A.
Mayle, and A.J. Peace. (2001). Estimating deer abundance from line transect
surveys of dung: sika deer in southern Scotland. Journal of Applied Ecology
38 (2): 349–363.  <a href="https://doi.org/10.1046/j.1365-2664.2001.00584.x">doi:10.1046/j.1365-2664.2001.00584.x</a>
</p>

<hr>
<h2 id='Stratify_example'>Simulated minke whale data</h2><span id='topic+Stratify_example'></span><span id='topic+Stratify_example_units'></span>

<h3>Description</h3>

<p>Data simulated from models fitted to 1992/1993 Southern Hemisphere minke
whale data collected by the International Whaling Commission. See Branch and
Butterworth (2001) for survey details (survey design is shown in figure
1(e)). Data simulated by David Borchers.
</p>


<h3>Format</h3>

<p><code>data.frame</code> with 99 observations of 7 variables:
<code>Region.Label</code> stratum label (<code>"North"</code> or <code>"South"</code>)
<code>Area</code> stratum area  (square nautical mile)
<code>Sample.Label</code> transect identifier
<code>Effort</code> transect length  (nautical mile)
<code>object</code> object ID
<code>distance</code> observed distance (nautical mile)
<code>Study.Area</code> name of study area
</p>


<h3>References</h3>

<p>Branch, T.A. and D.S. Butterworth. (2001) Southern Hemisphere
minke whales: standardised abundance estimates from the 1978/79 to 1997/98
IDCR-SOWER surveys. Journal of Cetacean Research and Management 3(2):
143-174
</p>
<p>Hedley, S.L., and S.T. Buckland. (2004) Spatial models for line transect
sampling. Journal of Agricultural, Biological, and Environmental Statistics
9: 181-199. <a href="https://doi.org/10.1198/1085711043578">doi:10.1198/1085711043578</a>.
</p>

<hr>
<h2 id='summarize_ds_models'>Make a table of summary statistics for detection function models</h2><span id='topic+summarize_ds_models'></span>

<h3>Description</h3>

<p>Provide a summary table of useful information about fitted detection
functions. This can be useful when paired with <code>knitr</code>'s <code>kable</code> function. By
default models are sorted by AIC and will therefore not allow models with
different truncations and distance binning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_ds_models(..., sort = "AIC", output = "latex", delta_only = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarize_ds_models_+3A_...">...</code></td>
<td>
<p>models to be summarised</p>
</td></tr>
<tr><td><code id="summarize_ds_models_+3A_sort">sort</code></td>
<td>
<p>column to sort by (default <code>"AIC"</code>)</p>
</td></tr>
<tr><td><code id="summarize_ds_models_+3A_output">output</code></td>
<td>
<p>should the output be given in <code>"latex"</code> compatible format
or as <code>"plain"</code> text?</p>
</td></tr>
<tr><td><code id="summarize_ds_models_+3A_delta_only">delta_only</code></td>
<td>
<p>only output AIC differences (default <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the column names are in LaTeX format, so if you plan to manipulate
the resulting <code>data.frame</code> in R, you may wish to rename the columns for
ease of access.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# fit some models to the golf tee data
library(Distance)
data(book.tee.data)
tee.data &lt;- subset(book.tee.data$book.tee.dataframe, observer==1)
model_hn &lt;- ds(tee.data,4)
model_hr &lt;- ds(tee.data,4, key="hr")
summarize_ds_models(model_hr, model_hn, output="plain")

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.dht_bootstrap'>Summarize bootstrap abundance uncertainty estimate output</h2><span id='topic+summary.dht_bootstrap'></span>

<h3>Description</h3>

<p>A simple function to calculate summaries of bootstrap output generated by
<code><a href="#topic+bootdht">bootdht</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dht_bootstrap'
summary(object, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.dht_bootstrap_+3A_object">object</code></td>
<td>
<p>output from <code>bootdht</code></p>
</td></tr>
<tr><td><code id="summary.dht_bootstrap_+3A_alpha">alpha</code></td>
<td>
<p>value to use in confidence interval calculation (to obtain
<code>alpha</code>/2 and 1-<code>alpha</code>/2 intervals</p>
</td></tr>
<tr><td><code id="summary.dht_bootstrap_+3A_...">...</code></td>
<td>
<p>for S3 compatibility, unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Summaries are only made for numeric outputs. Both median and mean are
reported to allow assessment of bias. The coefficient of variation reported
(in column <code>cv</code>) is based on the median calculated from the bootstraps.
</p>


<h3>Value</h3>

<p>a <code>data.frame</code> of summary statistics
</p>

<hr>
<h2 id='summary.dsmodel'>Summary of distance sampling analysis</h2><span id='topic+summary.dsmodel'></span>

<h3>Description</h3>

<p>Provides a brief summary of a distance sampling analysis. This includes
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dsmodel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.dsmodel_+3A_object">object</code></td>
<td>
<p>a distance analysis</p>
</td></tr>
<tr><td><code id="summary.dsmodel_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function just calls <code><a href="mrds.html#topic+summary.ds">summary.ds</a></code> and <code><a href="mrds.html#topic+dht">dht</a></code>,
collates and prints the results in a nice way.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='Systematic_variance_1'>Simulation of encounter rate variance</h2><span id='topic+Systematic_variance_1'></span><span id='topic+Systematic_variance_2'></span><span id='topic+Systematic_variance_1_units'></span><span id='topic+Systematic_variance_2_units'></span>

<h3>Description</h3>

<p><code>systematic_var_1</code> consists of simulated line transect data with large
differences in transect length. In <code>systematic_var_2</code> that transect length
gradient is coupled with a strong animal gradient; exaggerating encounter
rate variance between transects.
</p>


<h3>Format</h3>

<p><code>data.frame</code> with 253 observations (<code>systematic_var_1</code>) or 256
observations (<code>systematic_var_2</code>) of 7 variables:
<code>Region.Label</code> stratum label (default)
<code>Area</code> stratum area (0.5 km^2)
<code>Sample.Label</code> transect identifier
<code>Effort</code> transect length (km)
<code>object</code> object ID
<code>distance</code> perpendicular distance (m)
<code>Study.Area</code> name of study area
</p>


<h3>Details</h3>

<p>True population size is 1000 objects in the study area of size 0.5 km^2;
such that true density is 2000 objects per km.
</p>


<h3>References</h3>

<p>Fewster, R.M., S.T. Buckland, K.P. Burnham, D.L. Borchers, P.E.
Jupp, J.L. Laake and L. Thomas. (2009) Estimating the encounter rate
variance in distance sampling. Biometrics 65 (1): 225–236.
<a href="https://doi.org/10.1111/j.1541-0420.2008.01018.x">doi:10.1111/j.1541-0420.2008.01018.x</a>
</p>

<hr>
<h2 id='unflatten'>Unflatten flatfile data.frames</h2><span id='topic+unflatten'></span>

<h3>Description</h3>

<p>Sometimes data is provided in the <code><a href="#topic+flatfile">flatfile</a></code> format, but we
really want it in <code>mrds</code> format (that is, as distance data, observation
table, sample table and region table format). This function undoes the
flattening, assuming that the data have the correct columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unflatten(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unflatten_+3A_data">data</code></td>
<td>
<p>data in flatfile format (a <code>data.frame</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> of four <code>data.frame</code>s: distance data, observation table,
sample table, region table.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='unimak'>Simulated line transect survey data with covariates</h2><span id='topic+unimak'></span><span id='topic+unimak_units'></span>

<h3>Description</h3>

<p>Simulated line transect survey. Only eight line transects, detection
function is half-normal.
</p>


<h3>Format</h3>

<p>A <code>data.frame</code> with 60 rows and 9 variables
</p>

<ul>
<li> <p><code>Region.Label</code> strata names (single stratum)
</p>
</li>
<li> <p><code>Area</code> size of study area (mi^2)
</p>
</li>
<li> <p><code>Sample.Label</code> transect ID
</p>
</li>
<li> <p><code>Effort</code> transect length (mi)
</p>
</li>
<li> <p><code>object</code> object ID
</p>
</li>
<li> <p><code>distance</code> perpendicular distance (km)
</p>
</li>
<li> <p><code>MSTDO</code> time since medication taken by observer (min)
</p>
</li>
<li> <p><code>Hour</code> time of day of sighting (hour)
</p>
</li>
<li> <p><code>Study.Area</code> name of study area
</p>
</li></ul>



<h3>Note</h3>

<p><code>Hour</code> is covariate that has no effect on detection function,
while <code>MSTDO</code> does affect the detection function.  Examine the ability
of model selection to choose the correct model.
</p>


<h3>Source</h3>

<p>Simulated data, from the distance sampling introductory course,
Centre for Research into Ecological &amp; Environmental Modelling, University of
St Andrews.
</p>

<hr>
<h2 id='units_table'>Generate table of unit conversions</h2><span id='topic+units_table'></span>

<h3>Description</h3>

<p>Returns a table of conversions between the units used in Distance for
Windows. This is extracted from the <code>DistIni.mdb</code> default database.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>units_table()
</code></pre>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='wren'>Steve Buckland's winter wren surveys</h2><span id='topic+wren'></span><span id='topic+wren_5min'></span><span id='topic+wren_snapshot'></span><span id='topic+wren_cuecount'></span><span id='topic+wren_lt'></span><span id='topic+wren_5min_units'></span><span id='topic+wren_snapshot_units'></span><span id='topic+wren_cuecount_units'></span><span id='topic+wren_lt_units'></span>

<h3>Description</h3>

<p>Observations of winter wren (<em>Troglodytes troglodytes L.</em>) collected by Steve
Buckland in woodland/parkland at Montrave Estate near Leven, Fife, Scotland.
</p>


<h3>Details</h3>

<p>Four different surveys were carried out:
</p>

<ul>
<li> <p><code>wren_5min</code> 5-minute point count
</p>
</li>
<li> <p><code>wren_snapshot</code> snapshot method
</p>
</li>
<li> <p><code>wren_cuecount</code> cue count
</p>
</li>
<li> <p><code>wren_lt</code> line transect survey
</p>
</li></ul>



<h3>Note</h3>

<p><code>wren_5min</code>: 134 observations of 8 variables
</p>

<ul>
<li> <p><code>Region.Label</code>  stratum name (single stratum)
</p>
</li>
<li> <p><code>Area</code>  size (ha) of Montrave study area
</p>
</li>
<li> <p><code>Sample.Label</code>  point label
</p>
</li>
<li> <p><code>Effort</code>  Number of visits to point
</p>
</li>
<li> <p><code>object</code>  Object ID
</p>
</li>
<li> <p><code>distance</code>  radial distance (m)
</p>
</li>
<li> <p><code>direction</code>  direction of detection from point
</p>
</li>
<li> <p><code>Study.Area</code>  Montrave Estate
</p>
</li></ul>

<p><code>wren_snapshot</code>: 119 observations of 7 variables
</p>

<ul>
<li> <p><code>Region.Label</code>  stratum name (single stratum)
</p>
</li>
<li> <p><code>Area</code>  size (ha) of Montrave study area
</p>
</li>
<li> <p><code>Sample.Label</code>  point label
</p>
</li>
<li> <p><code>Effort</code>  Number of visits to point
</p>
</li>
<li> <p><code>object</code>  Object ID
</p>
</li>
<li> <p><code>distance</code>  radial distance (m)
</p>
</li>
<li> <p><code>Study.Area</code>  Montrave Estate
</p>
</li></ul>

<p><code>wren_cuecount</code>: 774 observations of 9 variables
</p>

<ul>
<li> <p><code>Region.Label</code>  stratum name (single stratum)
</p>
</li>
<li> <p><code>Area</code>  size (ha) of Montrave study area
</p>
</li>
<li> <p><code>Sample.Label</code>  point label
</p>
</li>
<li> <p><code>Cue.rate</code>  Production rate (per min) of cues
</p>
</li>
<li> <p><code>Cue.rate.SE</code>   SE of cue production rate
</p>
</li>
<li> <p><code>object</code>  Object ID
</p>
</li>
<li> <p><code>distance</code>  radial distance (m)
</p>
</li>
<li> <p><code>Search.time</code>  Time (min) listening for cues
</p>
</li>
<li> <p><code>Study.Area</code>  Montrave Estate
</p>
</li></ul>

<p><code>wren_lt</code>: 156 observations of 8 variables
</p>

<ul>
<li> <p><code>Region.Label</code>  stratum name (single stratum)
</p>
</li>
<li> <p><code>Area</code>  size (ha) of Montrave study area
</p>
</li>
<li> <p><code>Sample.Label</code>  transect label
</p>
</li>
<li> <p><code>Effort</code>   transect length (km)
</p>
</li>
<li> <p><code>object</code>  Object ID
</p>
</li>
<li> <p><code>distance</code>  perpendicular distance (m)
</p>
</li>
<li> <p><code>Study.Area</code>  Montrave Estate
</p>
</li></ul>



<h3>Source</h3>

<p>Steve Buckland
</p>


<h3>References</h3>

<p>Buckland, S. T. (2006) Point-transect surveys for songbirds:
robust methodologies. The Auk 123 (2): 345–357.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
