<!DOCTYPE html><html lang="en"><head><title>Help for package BalancedSampling</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BalancedSampling}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BalancedSampling'><p>BalancedSampling: Balanced and Spatially Balanced Sampling</p></a></li>
<li><a href='#cube'><p>The Cube method</p></a></li>
<li><a href='#genpopUniform'><p>Generate populations</p></a></li>
<li><a href='#getPips'><p>Inclusion probabilities proportional-to-size</p></a></li>
<li><a href='#hlpm2'><p>Hierarchical Local Pivotal Method 2</p></a></li>
<li><a href='#lcube'><p>The Local Cube method</p></a></li>
<li><a href='#lpm'><p>The (Local) Pivotal Methods</p></a></li>
<li><a href='#sb'><p>Spatial balance</p></a></li>
<li><a href='#scps'><p>Spatially Correlated Poisson Sampling</p></a></li>
<li><a href='#vsb'><p>Variance estimator for spatially balanced samples</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Balanced and Spatially Balanced Sampling</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-11-15</td>
</tr>
<tr>
<td>Author:</td>
<td>Anton Grafström <a href="https://orcid.org/0000-0002-4345-4024"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Wilmer Prentius <a href="https://orcid.org/0000-0002-3561-290X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Jonathan Lisic [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Anton Grafström &lt;anton.grafstrom@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Select balanced and spatially balanced probability samples in multi-dimensional spaces
    with any prescribed inclusion probabilities. It contains fast (C++ via Rcpp) implementations of
    the included sampling methods. The local pivotal method by Grafström, Lundström and Schelin (2012)
    &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2011.01699.x">doi:10.1111/j.1541-0420.2011.01699.x</a>&gt; and spatially correlated Poisson sampling by Grafström (2012)
    &lt;<a href="https://doi.org/10.1016%2Fj.jspi.2011.07.003">doi:10.1016/j.jspi.2011.07.003</a>&gt; are included. Also the cube method (for balanced sampling) and
    the local cube method (for doubly balanced sampling) are included, see Grafström and Tillé (2013)
    &lt;<a href="https://doi.org/10.1002%2Fenv.2194">doi:10.1002/env.2194</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.13)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.envisim.se/">https://www.envisim.se/</a>,
<a href="https://github.com/envisim/BalancedSampling/">https://github.com/envisim/BalancedSampling/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-18 13:47:48 UTC; ang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-18 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BalancedSampling'>BalancedSampling: Balanced and Spatially Balanced Sampling</h2><span id='topic+BalancedSampling-package'></span><span id='topic+BalancedSampling'></span>

<h3>Description</h3>

<p>Select balanced and spatially balanced probability samples in multi-dimensional
spaces with any prescribed inclusion probabilities.
It contains fast (C++ via Rcpp) implementations of the included sampling methods.
</p>
<p>You can access the project website at
<a href="https://envisim.se">https://envisim.se</a>.
</p>


<h3>Author(s)</h3>

<p>Anton Grafström <a href="mailto:anton.grafstrom@gmail.com">anton.grafstrom@gmail.com</a>, Jonathan Lisic, Wilmer Prentius.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://www.envisim.se/">https://www.envisim.se/</a>
</p>
</li>
<li> <p><a href="https://github.com/envisim/BalancedSampling/">https://github.com/envisim/BalancedSampling/</a>
</p>
</li></ul>


<hr>
<h2 id='cube'>The Cube method</h2><span id='topic+cube'></span><span id='topic+cubestratified'></span>

<h3>Description</h3>

<p>Selects balanced samples with prescribed inclusion probabilities
from a finite population using the fast flight Cube Method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cube(prob, x, eps = 1e-12)

cubestratified(prob, x, integerStrata, eps = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cube_+3A_prob">prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities.</p>
</td></tr>
<tr><td><code id="cube_+3A_x">x</code></td>
<td>
<p>An N by q matrix of balancing auxiliary variables.</p>
</td></tr>
<tr><td><code id="cube_+3A_eps">eps</code></td>
<td>
<p>A small value used to determine when an updated probability is
close enough to 0.0 or 1.0.</p>
</td></tr>
<tr><td><code id="cube_+3A_integerstrata">integerStrata</code></td>
<td>
<p>An integer vector of length N with stratum numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>prob</code> sum to an integer n, and <code>prob</code> is included as the first
balancing variable, a fixed sized sample (n) will be produced.
</p>


<h4>Stratified cube</h4>

<p>For <code>cubestratified</code>, <code>prob</code> is automatically inserted as a balancing variable.
</p>
<p>The stratified version uses the fast flight Cube method and pooling of
landing phases.
</p>



<h3>Value</h3>

<p>A vector of selected indices in 1,2,...,N.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>cubestratified()</code>: 
</p>
</li></ul>


<h3>References</h3>

<p>Deville, J. C. and Tillé, Y. (2004).
Efficient balanced sampling: the cube method.
Biometrika, 91(4), 893-912.
</p>
<p>Chauvet, G. and Tillé, Y. (2006).
A fast algorithm for balanced sampling.
Computational Statistics, 21(1), 53-62.
</p>
<p>Chauvet, G. (2009).
Stratified balanced sampling.
Survey Methodology, 35, 115-119.
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+hlpm2">hlpm2</a>()</code>,
<code><a href="#topic+lcube">lcube</a>()</code>,
<code><a href="#topic+lpm">lpm</a>()</code>,
<code><a href="#topic+scps">scps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
s = cube(prob, x);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
strata = c(rep(1L, 100), rep(2L, 200), rep(3L, 300), rep(4L, 400));
s = cubestratified(prob, x, strata);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
prob = c(0.2, 0.25, 0.35, 0.4, 0.5, 0.5, 0.55, 0.65, 0.7, 0.9);
N = length(prob);
x = matrix(runif(N * 2), ncol = 2);
ep = rep(0L, N);
r = 10000L;
for (i in seq_len(r)) {
  s = cube(prob, cbind(prob, x));
  ep[s] = ep[s] + 1L;
}
print(ep / r);

## End(Not run)

</code></pre>

<hr>
<h2 id='genpopUniform'>Generate populations</h2><span id='topic+genpopUniform'></span><span id='topic+genpopPoisson'></span>

<h3>Description</h3>

<p>Generate uniform and poisson cluster process populations
</p>
<p>If <code>from</code> and <code>to</code> is used with <code>genpopPoisson</code> together with <code>mirror</code>, the
population will be bounded within these values.
For the <code>genpopUniform</code>, these numbers represent the minimum and maximum
values of the uniform distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genpopUniform(size, dims = 2L, from = 0, to = 1)

genpopPoisson(
  parents,
  children,
  dims = 2L,
  from = 0,
  to = 1,
  distribution = function(n) rnorm(n, 0, 0.02),
  mirror = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genpopUniform_+3A_size">size</code></td>
<td>
<p>The size of the population</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_dims">dims</code></td>
<td>
<p>The number of auxiliary variables</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_from">from</code></td>
<td>
<p>A number or a vector of size <code>dims</code> with the minimum values</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_to">to</code></td>
<td>
<p>A number or a vector of size <code>dims</code> with the maximum values</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_parents">parents</code></td>
<td>
<p>The number of parent locations</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_children">children</code></td>
<td>
<p>A number or a vector of size <code>parents</code> with the mean number of
children to be spawned.</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_distribution">distribution</code></td>
<td>
<p>A function taking a number as a variable, returning the
offset from the parent location.</p>
</td></tr>
<tr><td><code id="genpopUniform_+3A_mirror">mirror</code></td>
<td>
<p>If <code>TRUE</code>, the population is mirrored to be inside <code>from</code> and <code>to</code>.</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>genpopPoisson()</code>: Poisson cluster process
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
x = genpopUniform(120, 2L);
N = nrow(x);
n = 60;
prob = rep(n / N, N);
s = lpm2(prob, x);
b = sb(prob, x, s);

## End(Not run)

## Not run: 
set.seed(12345);
x = genpopPoisson(70, 50, 2L);
N = nrow(x);
n = 60;
prob = rep(n / N, N);
s = lpm2(prob, x);
b = sb(prob, x, s);

## End(Not run)

</code></pre>

<hr>
<h2 id='getPips'>Inclusion probabilities proportional-to-size</h2><span id='topic+getPips'></span>

<h3>Description</h3>

<p>Computes the first-order inclusion probabilties from a vector of positive numbers,
for a probabilitiy proportional-to-size design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPips(x, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPips_+3A_x">x</code></td>
<td>
<p>A vector of positive numbers</p>
</td></tr>
<tr><td><code id="getPips_+3A_n">n</code></td>
<td>
<p>The wanted sample size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of inclusion probabilities proportional-to-size
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
x = matrix(runif(N * 2), ncol = 2);
prob = getPips(x[, 1], n);
s = lpm2(prob, x);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

## End(Not run)

</code></pre>

<hr>
<h2 id='hlpm2'>Hierarchical Local Pivotal Method 2</h2><span id='topic+hlpm2'></span>

<h3>Description</h3>

<p>Selects an initial sample using the <code><a href="#topic+lpm2">lpm2()</a></code>, and then splits this sample into
subsamples of given <code>sizes</code> using successive, hierarchical selection with
the <code><a href="#topic+lpm2">lpm2()</a></code>.
The method is used to select several subsamples, such that each subsample, and
the combination (i.e. the union of all subsamples), is spatially balanced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hlpm2(prob, x, sizes, type = "kdtree2", bucketSize = 50, eps = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hlpm2_+3A_prob">prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities.</p>
</td></tr>
<tr><td><code id="hlpm2_+3A_x">x</code></td>
<td>
<p>An N by p matrix of (standardized) auxiliary variables. Squared euclidean distance is used in the <code>x</code> space.</p>
</td></tr>
<tr><td><code id="hlpm2_+3A_sizes">sizes</code></td>
<td>
<p>A vector of integers containing the sizes of the subsamples.
<code>sum(sizes) = sum(prob)</code> must hold.</p>
</td></tr>
<tr><td><code id="hlpm2_+3A_type">type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td></tr>
<tr><td><code id="hlpm2_+3A_bucketsize">bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td></tr>
<tr><td><code id="hlpm2_+3A_eps">eps</code></td>
<td>
<p>A small value used to determine when an updated probability is
close enough to 0.0 or 1.0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inclusion probabilities <code>prob</code> <em>must</em> sum to an integer n.
The sizes of the subsamples <code>sum(sizes)</code> <em>must</em> sum to the same integer n.
</p>


<h3>Value</h3>

<p>A vector of selected indices in 1,2,...,N.
</p>
<p>A matrix with the population indices of the combined sample in the
first column, and the associated subsample in the second column.
</p>


<h3>k-d-trees</h3>

<p>The <code>type</code>s &quot;kdtree&quot; creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li><p>&quot;kdtree0&quot; creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li><p>&quot;kdtree1&quot; creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li><p>&quot;kdtree2&quot; creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li><p>&quot;notree&quot; does a naive search for the nearest neighbour.
</p>
</li></ul>



<h3>References</h3>

<p>Friedman, J. H., Bentley, J. L., &amp; Finkel, R. A. (1977).
An algorithm for finding best matches in logarithmic expected time.
ACM Transactions on Mathematical Software (TOMS), 3(3), 209-226.
</p>
<p>Maneewongvatana, S., &amp; Mount, D. M. (1999, December).
It’s okay to be skinny, if your friends are fat.
In Center for geometric computing 4th annual workshop on computational geometry (Vol. 2, pp. 1-8).
</p>
<p>Grafström, A., Lundström, N.L.P. &amp; Schelin, L. (2012).
Spatially balanced sampling through the Pivotal method.
Biometrics 68(2), 514-520.
</p>
<p>Lisic, J. J., &amp; Cruze, N. B. (2016, June).
Local pivotal methods for large surveys.
In Proceedings of the Fifth International Conference on Establishment Surveys.
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+cube">cube</a>()</code>,
<code><a href="#topic+lcube">lcube</a>()</code>,
<code><a href="#topic+lpm">lpm</a>()</code>,
<code><a href="#topic+scps">scps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
sizes = c(10, 20, 30, 40);
s = hlpm2(prob, x, sizes);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

## End(Not run)

</code></pre>

<hr>
<h2 id='lcube'>The Local Cube method</h2><span id='topic+lcube'></span><span id='topic+lcubestratified'></span>

<h3>Description</h3>

<p>Selects doubly balanced samples with prescribed inclusion probabilities
from a finite population using the Local Cube method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcube(prob, Xspread, Xbal, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lcubestratified(
  prob,
  Xspread,
  Xbal,
  integerStrata,
  type = "kdtree2",
  bucketSize = 50,
  eps = 1e-12
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lcube_+3A_prob">prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities.</p>
</td></tr>
<tr><td><code id="lcube_+3A_xspread">Xspread</code></td>
<td>
<p>An N by p matrix of (standardized) auxiliary variables. Squared euclidean distance is used in the <code>Xspread</code> space.</p>
</td></tr>
<tr><td><code id="lcube_+3A_xbal">Xbal</code></td>
<td>
<p>An N by q matrix of balancing auxiliary variables.</p>
</td></tr>
<tr><td><code id="lcube_+3A_type">type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td></tr>
<tr><td><code id="lcube_+3A_bucketsize">bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td></tr>
<tr><td><code id="lcube_+3A_eps">eps</code></td>
<td>
<p>A small value used to determine when an updated probability is
close enough to 0.0 or 1.0.</p>
</td></tr>
<tr><td><code id="lcube_+3A_integerstrata">integerStrata</code></td>
<td>
<p>An integer vector of length N with stratum numbers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>prob</code> sum to an integer n, and <code>prob</code> is included as the first
balancing variable, a fixed sized sample (n) will be produced.
</p>


<h4>Stratified lcube</h4>

<p>For <code>lcubestratified</code>, <code>prob</code> is automatically inserted as a balancing variable.
</p>
<p>The stratified version uses the fast flight Cube method and pooling of
landing phases.
</p>



<h3>Value</h3>

<p>A vector of selected indices in 1,2,...,N.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>lcubestratified()</code>: 
</p>
</li></ul>


<h3>k-d-trees</h3>

<p>The <code>type</code>s &quot;kdtree&quot; creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li><p>&quot;kdtree0&quot; creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li><p>&quot;kdtree1&quot; creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li><p>&quot;kdtree2&quot; creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li><p>&quot;notree&quot; does a naive search for the nearest neighbour.
</p>
</li></ul>



<h3>References</h3>

<p>Deville, J. C. and Tillé, Y. (2004).
Efficient balanced sampling: the cube method.
Biometrika, 91(4), 893-912.
</p>
<p>Chauvet, G. and Tillé, Y. (2006).
A fast algorithm for balanced sampling.
Computational Statistics, 21(1), 53-62.
</p>
<p>Chauvet, G. (2009).
Stratified balanced sampling.
Survey Methodology, 35, 115-119.
</p>
<p>Grafström, A. and Tillé, Y. (2013).
Doubly balanced spatial sampling with spreading and restitution of auxiliary totals.
Environmetrics, 24(2), 120-131
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+cube">cube</a>()</code>,
<code><a href="#topic+hlpm2">hlpm2</a>()</code>,
<code><a href="#topic+lpm">lpm</a>()</code>,
<code><a href="#topic+scps">scps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
xspr = matrix(runif(N * 2), ncol = 2);
s = lcube(prob, xspr, cbind(prob, x));
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
xspr = matrix(runif(N * 2), ncol = 2);
strata = c(rep(1L, 100), rep(2L, 200), rep(3L, 300), rep(4L, 400));
s = lcubestratified(prob, xspr, x, strata);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
prob = c(0.2, 0.25, 0.35, 0.4, 0.5, 0.5, 0.55, 0.65, 0.7, 0.9);
N = length(prob);
x = matrix(runif(N * 2), ncol = 2);
xspr = matrix(runif(N * 2), ncol = 2);
ep = rep(0L, N);
r = 10000L;
for (i in seq_len(r)) {
  s = lcube(prob, xspr, cbind(prob, x));
  ep[s] = ep[s] + 1L;
}
print(ep / r);

## End(Not run)

</code></pre>

<hr>
<h2 id='lpm'>The (Local) Pivotal Methods</h2><span id='topic+lpm'></span><span id='topic+lpm1'></span><span id='topic+lpm2'></span><span id='topic+lpm1s'></span><span id='topic+spm'></span><span id='topic+rpm'></span>

<h3>Description</h3>

<p>Selects spatially balanced samples with prescribed inclusion probabilities
from a finite population using the Local Pivotal Method 1 (LPM1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpm(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lpm1(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lpm2(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lpm1s(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

spm(prob, eps = 1e-12)

rpm(prob, eps = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lpm_+3A_prob">prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities, or an integer &gt; 1. If an integer n, then the sample will be drawn with equal probabilities n / N.</p>
</td></tr>
<tr><td><code id="lpm_+3A_x">x</code></td>
<td>
<p>An N by p matrix of (standardized) auxiliary variables. Squared euclidean distance is used in the <code>x</code> space.</p>
</td></tr>
<tr><td><code id="lpm_+3A_type">type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td></tr>
<tr><td><code id="lpm_+3A_bucketsize">bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td></tr>
<tr><td><code id="lpm_+3A_eps">eps</code></td>
<td>
<p>A small value used to determine when an updated probability is
close enough to 0.0 or 1.0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>prob</code> sum to an integer n, a fixed sized sample (n) will be produced.
For <code>spm</code> and <code>rpm</code>, <code>prob</code> must be a vector of inclusion probabilities.
If equal inclusion probabilities is wanted, this can be produced by
<code>rep(n / N, N)</code>.
</p>
<p>The available pivotal methods are:
</p>

<ul>
<li> <p><code>lpm1</code>: The Local Pivotal Mehtod 1 (Grafström et al., 2012).
Updates only units which are mutual nearest neighbours.
Selects such a pair at random.
</p>
</li>
<li> <p><code>lpm2</code>, <code>lpm</code>: The Local Pivotal Method 2 (Grafström et al., 2012).
Selects a unit at random, which competes with this units nearest neighbour.
</p>
</li>
<li> <p><code>lpm1s</code>: The Local Pivotal Method 1 search: (Prentius, 2023).
Updates only units which are mutual nearest neighbours.
Selects such a pair by branching the remaining units, giving higher
probabilities to update a pair with a long branch.
This changes the algorithm of lpm1, but makes it faster.
</p>
</li>
<li> <p><code>spm</code>: The Sequential Pivotal Method.
Selects the two units with smallest indices to compete against each other.
If the list is ordered, the algorithm is similar to systematic sampling.
</p>
</li>
<li> <p><code>rpm</code>: The Random Pivotal Method.
Selects two units at random to compete against each other.
Produces a design with high entropy.
</p>
</li></ul>



<h3>Value</h3>

<p>A vector of selected indices in 1,2,...,N.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>lpm1()</code>: 
</p>
</li>
<li> <p><code>lpm2()</code>: 
</p>
</li>
<li> <p><code>lpm1s()</code>: 
</p>
</li>
<li> <p><code>spm()</code>: 
</p>
</li>
<li> <p><code>rpm()</code>: 
</p>
</li></ul>


<h3>k-d-trees</h3>

<p>The <code>type</code>s &quot;kdtree&quot; creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li><p>&quot;kdtree0&quot; creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li><p>&quot;kdtree1&quot; creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li><p>&quot;kdtree2&quot; creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li><p>&quot;notree&quot; does a naive search for the nearest neighbour.
</p>
</li></ul>



<h3>References</h3>

<p>Friedman, J. H., Bentley, J. L., &amp; Finkel, R. A. (1977).
An algorithm for finding best matches in logarithmic expected time.
ACM Transactions on Mathematical Software (TOMS), 3(3), 209-226.
</p>
<p>Deville, J.-C., &amp;  Tillé, Y. (1998).
Unequal probability sampling without replacement through a splitting method.
Biometrika 85, 89-101.
</p>
<p>Maneewongvatana, S., &amp; Mount, D. M. (1999, December).
It’s okay to be skinny, if your friends are fat.
In Center for geometric computing 4th annual workshop on computational geometry (Vol. 2, pp. 1-8).
</p>
<p>Chauvet, G. (2012).
On a characterization of ordered pivotal sampling.
Bernoulli, 18(4), 1320-1340.
</p>
<p>Grafström, A., Lundström, N.L.P. &amp; Schelin, L. (2012).
Spatially balanced sampling through the Pivotal method.
Biometrics 68(2), 514-520.
</p>
<p>Lisic, J. J., &amp; Cruze, N. B. (2016, June).
Local pivotal methods for large surveys.
In Proceedings of the Fifth International Conference on Establishment Surveys.
</p>
<p>Prentius, W. (2023)
Manuscript.
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+cube">cube</a>()</code>,
<code><a href="#topic+hlpm2">hlpm2</a>()</code>,
<code><a href="#topic+lcube">lcube</a>()</code>,
<code><a href="#topic+scps">scps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
s = lpm2(prob, x);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
prob = c(0.2, 0.25, 0.35, 0.4, 0.5, 0.5, 0.55, 0.65, 0.7, 0.9);
N = length(prob);
x = matrix(runif(N * 2), ncol = 2);
ep = rep(0L, N);
r = 10000L;
for (i in seq_len(r)) {
  s = lpm2(prob, x);
  ep[s] = ep[s] + 1L;
}
print(ep / r);

set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
lpm1(prob, x);
lpm2(prob, x);
lpm1s(prob, x);
spm(prob);
rpm(prob);

## End(Not run)
</code></pre>

<hr>
<h2 id='sb'>Spatial balance</h2><span id='topic+sb'></span><span id='topic+sblb'></span>

<h3>Description</h3>

<p>Calculates the spatial balance of a sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sb(prob, x, sample, type = "kdtree2", bucketSize = 10)

sblb(prob, x, sample, type = "kdtree2", bucketSize = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sb_+3A_prob">prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities, or an integer &gt; 1. If an integer n, then the sample will be drawn with equal probabilities n / N.</p>
</td></tr>
<tr><td><code id="sb_+3A_x">x</code></td>
<td>
<p>An N by p matrix of (standardized) auxiliary variables. Squared euclidean distance is used in the <code>x</code> space.</p>
</td></tr>
<tr><td><code id="sb_+3A_sample">sample</code></td>
<td>
<p>A vector of sample indices.</p>
</td></tr>
<tr><td><code id="sb_+3A_type">type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td></tr>
<tr><td><code id="sb_+3A_bucketsize">bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>About voronoi and sumofsquares
</p>


<h3>Value</h3>

<p>The balance measure of the provided sample.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>sblb()</code>: Spatial balance using local balance
</p>
</li></ul>


<h3>k-d-trees</h3>

<p>The <code>type</code>s &quot;kdtree&quot; creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li><p>&quot;kdtree0&quot; creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li><p>&quot;kdtree1&quot; creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li><p>&quot;kdtree2&quot; creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li><p>&quot;notree&quot; does a naive search for the nearest neighbour.
</p>
</li></ul>



<h3>References</h3>

<p>Friedman, J. H., Bentley, J. L., &amp; Finkel, R. A. (1977).
An algorithm for finding best matches in logarithmic expected time.
ACM Transactions on Mathematical Software (TOMS), 3(3), 209-226.
</p>
<p>Maneewongvatana, S., &amp; Mount, D. M. (1999, December).
It’s okay to be skinny, if your friends are fat.
In Center for geometric computing 4th annual workshop on computational geometry (Vol. 2, pp. 1-8).
</p>
<p>Stevens Jr, D. L., &amp; Olsen, A. R. (2004).
Spatially balanced sampling of natural resources.
Journal of the American statistical Association, 99(465), 262-278.
</p>
<p>Grafström, A., Lundström, N.L.P. &amp; Schelin, L. (2012).
Spatially balanced sampling through the Pivotal method.
Biometrics 68(2), 514-520.
</p>
<p>Prentius, W, &amp; Grafström A. (2023).
Manuscript.
</p>


<h3>See Also</h3>

<p>Other measure: 
<code><a href="#topic+vsb">vsb</a>()</code>
</p>
<p>Other measure: 
<code><a href="#topic+vsb">vsb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 500;
n = 70;
prob = rep(n / N, N);
x = matrix(runif(N * 2), ncol = 2);
s = lpm2(prob, x);
b = sb(prob, x, s);

## End(Not run)
</code></pre>

<hr>
<h2 id='scps'>Spatially Correlated Poisson Sampling</h2><span id='topic+scps'></span><span id='topic+lcps'></span>

<h3>Description</h3>

<p>Selects spatially balanced samples with prescribed inclusion probabilities
from a finite population using Spatially Correlated Poisson Sampling (SCPS).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scps(prob, x, rand = NULL, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lcps(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scps_+3A_prob">prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities, or an integer &gt; 1. If an integer n, then the sample will be drawn with equal probabilities n / N.</p>
</td></tr>
<tr><td><code id="scps_+3A_x">x</code></td>
<td>
<p>An N by p matrix of (standardized) auxiliary variables. Squared euclidean distance is used in the <code>x</code> space.</p>
</td></tr>
<tr><td><code id="scps_+3A_rand">rand</code></td>
<td>
<p>A vector of length N with random numbers.
If this is supplied, the decision of each unit is taken with the corresponding
random number. This makes it possible to coordinate the samples.</p>
</td></tr>
<tr><td><code id="scps_+3A_type">type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td></tr>
<tr><td><code id="scps_+3A_bucketsize">bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td></tr>
<tr><td><code id="scps_+3A_eps">eps</code></td>
<td>
<p>A small value used to determine when an updated probability is
close enough to 0.0 or 1.0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>prob</code> sum to an integer n, a fixed sized sample (n) will be produced.
The implementation uses the maximal weight strategy, as specified in
Grafström (2012).
</p>


<h4>Coordinated SCPS</h4>

<p>If <code>rand</code> is supplied, coordinated SCPS will be performed.
The algorithm for coordinated SCPS differs from the SCPS algorithm, as
uncoordinated SCPS chooses a unit to update randomly, whereas coordinated SCPS
traverses the units in the supplied order.
This has a small impact on the efficiency of the algorithm for coordinated SCPS.
</p>



<h4>Locally Correlated Poisson Sampling (LCPS)</h4>

<p>The method differs from SCPS as LPM1 differs from LPM2. In each step of the
algorithm, the unit with the smallest updating distance is chosen as the
deciding unit.
</p>



<h3>Value</h3>

<p>A vector of selected indices in 1,2,...,N.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>lcps()</code>: 
</p>
</li></ul>


<h3>k-d-trees</h3>

<p>The <code>type</code>s &quot;kdtree&quot; creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li><p>&quot;kdtree0&quot; creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li><p>&quot;kdtree1&quot; creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li><p>&quot;kdtree2&quot; creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li><p>&quot;notree&quot; does a naive search for the nearest neighbour.
</p>
</li></ul>



<h3>References</h3>

<p>Friedman, J. H., Bentley, J. L., &amp; Finkel, R. A. (1977).
An algorithm for finding best matches in logarithmic expected time.
ACM Transactions on Mathematical Software (TOMS), 3(3), 209-226.
</p>
<p>Maneewongvatana, S., &amp; Mount, D. M. (1999, December).
It’s okay to be skinny, if your friends are fat.
In Center for geometric computing 4th annual workshop on computational geometry (Vol. 2, pp. 1-8).
</p>
<p>Grafström, A. (2012).
Spatially correlated Poisson sampling.
Journal of Statistical Planning and Inference, 142(1), 139-147.
</p>
<p>Prentius, W. (2023).
Locally correlated Poisson sampling.
Environmetrics, e2832.
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+cube">cube</a>()</code>,
<code><a href="#topic+hlpm2">hlpm2</a>()</code>,
<code><a href="#topic+lcube">lcube</a>()</code>,
<code><a href="#topic+lpm">lpm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
s = scps(prob, x);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
prob = c(0.2, 0.25, 0.35, 0.4, 0.5, 0.5, 0.55, 0.65, 0.7, 0.9);
N = length(prob);
x = matrix(runif(N * 2), ncol = 2);
ep = rep(0L, N);
r = 10000L;
for (i in seq_len(r)) {
  s = scps(prob, x);
  ep[s] = ep[s] + 1L;
}
print(ep / r);

set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
scps(prob, x);
lcps(prob, x);

## End(Not run)

</code></pre>

<hr>
<h2 id='vsb'>Variance estimator for spatially balanced samples</h2><span id='topic+vsb'></span>

<h3>Description</h3>

<p>Variance estimator of HT estimator of population total.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vsb(probs, ys, xs, k = 3L, type = "kdtree2", bucketSize = 40)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vsb_+3A_probs">probs</code></td>
<td>
<p>A vector of length n with inclusion probabilities.</p>
</td></tr>
<tr><td><code id="vsb_+3A_ys">ys</code></td>
<td>
<p>A vector of length n containing the target variable.</p>
</td></tr>
<tr><td><code id="vsb_+3A_xs">xs</code></td>
<td>
<p>An n by p matrix of (standardized) auxiliary variables.</p>
</td></tr>
<tr><td><code id="vsb_+3A_k">k</code></td>
<td>
<p>The number of neighbours to construct the means around.</p>
</td></tr>
<tr><td><code id="vsb_+3A_type">type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td></tr>
<tr><td><code id="vsb_+3A_bucketsize">bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>k = 0L</code>, the variance estimate is constructed by using all units that
have the minimum distance.
</p>
<p>If <code>k &gt; 0L</code>, the variance estimate is constructed by using the <code>k</code> closest
units. If multiple units are located on the border, all are used.
</p>


<h3>Value</h3>

<p>The variance estimate.
</p>


<h3>k-d-trees</h3>

<p>The <code>type</code>s &quot;kdtree&quot; creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li><p>&quot;kdtree0&quot; creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li><p>&quot;kdtree1&quot; creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li><p>&quot;kdtree2&quot; creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li><p>&quot;notree&quot; does a naive search for the nearest neighbour.
</p>
</li></ul>



<h3>References</h3>

<p>Grafström, A., &amp; Schelin, L. (2014).
How to select representative samples.
Scandinavian Journal of Statistics, 41(2), 277-290.
</p>


<h3>See Also</h3>

<p>Other measure: 
<code><a href="#topic+sb">sb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
y = runif(N);
s = lpm2(prob, x);
vsb(prob[s], y[s], x[s, ]);
vsb(prob[s], y[s], x[s, ], 0L);

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
