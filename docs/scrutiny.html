<!DOCTYPE html><html><head><title>Help for package scrutiny</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scrutiny}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#scrutiny-package'><p>scrutiny: Error Detection in Science</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#audit'><p>Summarize scrutiny objects</p></a></li>
<li><a href='#audit_cols_minimal'><p>Compute minimal <code>audit()</code> summaries</p></a></li>
<li><a href='#audit_list'><p>Summaries in list form</p></a></li>
<li><a href='#audit-special'><p>Summarize output of sequence mappers and total-n mappers</p></a></li>
<li><a href='#check_audit_special'><p>Alert user if more specific <code style="white-space: pre;">&#8288;audit_*()&#8288;</code> summaries are available</p></a></li>
<li><a href='#check_mapper_input_colnames'><p>Check that a mapper's input has correct column names</p></a></li>
<li><a href='#data-frame-predicates'><p>Is an object a consistency test output tibble?</p></a></li>
<li><a href='#debit'><p>The DEBIT (descriptive binary) test</p></a></li>
<li><a href='#debit_map'><p>Apply DEBIT to many cases</p></a></li>
<li><a href='#debit_map_seq'><p>Using DEBIT with dispersed inputs</p></a></li>
<li><a href='#debit_map_total_n'><p>Use DEBIT with hypothetical group sizes</p></a></li>
<li><a href='#debit_plot'><p>Visualize DEBIT results</p></a></li>
<li><a href='#decimal_places'><p>Count decimal places</p></a></li>
<li><a href='#decimal_places_df'><p>Count decimal places in a data frame</p></a></li>
<li><a href='#disperse'><p>Vary hypothetical group sizes</p></a></li>
<li><a href='#duplicate_count'><p>Count duplicate values</p></a></li>
<li><a href='#duplicate_count_colpair'><p>Count duplicate values by column</p></a></li>
<li><a href='#duplicate_detect'><p>Detect duplicate values</p></a></li>
<li><a href='#duplicate_tally'><p>Count duplicates at each observation</p></a></li>
<li><a href='#fractional-rounding'><p>Generalized rounding to the nearest fraction of a specified denominator</p></a></li>
<li><a href='#function_map'><p>Create new <code style="white-space: pre;">&#8288;*_map()&#8288;</code> functions</p></a></li>
<li><a href='#function_map_seq'><p>Create new <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> functions</p></a></li>
<li><a href='#function_map_total_n'><p>Create new <code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> functions</p></a></li>
<li><a href='#grim'><p>The GRIM test (granularity-related inconsistency of means)</p></a></li>
<li><a href='#grim_granularity'><p>Granularity of non-continuous scales</p></a></li>
<li><a href='#grim_map'><p>GRIM-test many cases at once</p></a></li>
<li><a href='#grim_map_seq'><p>GRIM-testing with dispersed inputs</p></a></li>
<li><a href='#grim_map_total_n'><p>GRIM-testing with hypothetical group sizes</p></a></li>
<li><a href='#grim_plot'><p>Visualize GRIM test results</p></a></li>
<li><a href='#grim-stats'><p>Possible GRIM inconsistencies</p></a></li>
<li><a href='#grimmer'><p>The GRIMMER test (granularity-related inconsistency of means mapped to error</p>
repeats)</a></li>
<li><a href='#grimmer_map'><p>GRIMMER-test many cases at once</p></a></li>
<li><a href='#grimmer_map_seq'><p>GRIMMER-testing with dispersed inputs</p></a></li>
<li><a href='#grimmer_map_total_n'><p>GRIMMER-testing with hypothetical group sizes</p></a></li>
<li><a href='#is_numeric_like'><p>Test whether a vector is numeric or coercible to numeric</p></a></li>
<li><a href='#manage_helper_col'><p>Helper column operations</p></a></li>
<li><a href='#manage_key_colnames'><p>Enable name-independent key column identification</p></a></li>
<li><a href='#parens-extractors'><p>Extract substrings from before and inside parentheses</p></a></li>
<li><a href='#pigs1'><p>Means and sample sizes for GRIM-testing</p></a></li>
<li><a href='#pigs2'><p>Percentages and sample sizes for GRIM-testing</p></a></li>
<li><a href='#pigs3'><p>Binary means and standard deviations for using DEBIT</p></a></li>
<li><a href='#pigs4'><p>Data with duplications</p></a></li>
<li><a href='#pigs5'><p>Means, SDs, and sample sizes for GRIMMER-testing</p></a></li>
<li><a href='#reround'><p>General interface to reconstructing rounded numbers</p></a></li>
<li><a href='#restore_zeros'><p>Restore trailing zeros</p></a></li>
<li><a href='#reverse_map_seq'><p>Reverse the <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> process</p></a></li>
<li><a href='#reverse_map_total_n'><p>Reverse the <code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> process</p></a></li>
<li><a href='#rounding_bias'><p>Compute rounding bias</p></a></li>
<li><a href='#rounding-common'><p>Common rounding procedures</p></a></li>
<li><a href='#rounding-uncommon'><p>Uncommon rounding procedures</p></a></li>
<li><a href='#row_to_colnames'><p>Turn row values into column names</p></a></li>
<li><a href='#sd-binary'><p>Standard deviation of binary data</p></a></li>
<li><a href='#seq_disperse'><p>Sequence generation with dispersion at decimal level</p></a></li>
<li><a href='#seq_length'><p>Set sequence length</p></a></li>
<li><a href='#seq_test_ranking'><p>Rank sequence test results</p></a></li>
<li><a href='#seq-decimal'><p>Sequence generation at decimal level</p></a></li>
<li><a href='#seq-predicates'><p>Is a vector a certain kind of sequence?</p></a></li>
<li><a href='#split_by_parens'><p>Split columns by parentheses, brackets, braces, or similar</p></a></li>
<li><a href='#subset-superset'><p>Test for subsets, supersets, and equal sets</p></a></li>
<li><a href='#tidyeval'><p>Tidy eval helpers</p></a></li>
<li><a href='#unnest_consistency_cols'><p>Unnest a test result column</p></a></li>
<li><a href='#unround'><p>Reconstruct rounding bounds</p></a></li>
<li><a href='#write_doc_audit'><p>Documentation template for <code>audit()</code></p></a></li>
<li><a href='#write_doc_audit_seq'><p>Documentation template for <code>audit_seq()</code></p></a></li>
<li><a href='#write_doc_audit_total_n'><p>Documentation template for <code>audit_total_n()</code></p></a></li>
<li><a href='#write_doc_factory_map_conventions'><p>Documentation template for function factory conventions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Error Detection in Science</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lukas Jung &lt;jung-lukas@gmx.net&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Test published summary statistics for consistency
    (Brown and Heathers, 2017, &lt;<a href="https://doi.org/10.1177%2F1948550616673876">doi:10.1177/1948550616673876</a>&gt;;
    Allard, 2018, <a href="https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/">https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/</a>;
    Heathers and Brown, 2019, <a href="https://osf.io/5vb3u/">https://osf.io/5vb3u/</a>).
    The package also provides infrastructure for implementing new
    error detection techniques.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli, corrr, dplyr, ggplot2, ggrepel, glue, lifecycle,
magrittr, methods, purrr, rlang (&ge; 1.0.2), stats, stringr,
tibble, tidyr, tidyselect</td>
</tr>
<tr>
<td>Collate:</td>
<td>'is-numeric-like.R' 'import-reexport.R' 'utils.R'
'mapper-function-helpers.R' 'audit-cols-minimal.R' 'audit.R'
'baseline-consistency-tests.R' 'before-inside-parens.R'
'function-factory-helpers.R' 'round-ceil-floor.R' 'round.R'
'reround.R' 'unround.R' 'sd-binary.R' 'decimal-places.R'
'debit-table.R' 'debit.R' 'grim.R' 'function-map.R' 'grimmer.R'
'grimmer-map.R' 'duplicate-detect.R' 'debit-map.R'
'restore-zeros.R' 'seq-decimal.R' 'manage-extra-cols.R'
'grim-map.R' 'data-doc.R' 'data-frame-predicates.R'
'seq-predicates.R' 'function-map-seq.R' 'debit-map-seq.R'
'disperse.R' 'function-map-total-n.R' 'debit-map-total-n.R'
'debit-plot.R' 'duplicate-count-colpair.R' 'duplicate-count.R'
'grim-granularity.R' 'grim-map-debug.R' 'grim-map-seq.R'
'grim-map-total-n.R' 'grim-plot.R' 'grim-stats.R'
'grimmer-map-seq.R' 'grimmer-map-total-n.R' 'metadata.R'
'method-audit-seq.R' 'method-audit-total-n.R'
'method-debit-map.R' 'method-detect.R'
'method-dup-count-colpair.R' 'method-dup-count.R'
'method-grim-map.R' 'method-grim-sequence.R'
'method-grimmer-map.R' 'method-tally.R' 'reround-to-fraction.R'
'reverse-map-seq.R' 'reverse-map-total-n.R'
'rivets-perfect-mean-sd.R' 'rivets-plot-cols.R'
'rivets-plot-lines.R' 'rivets-t-test.R' 'rivets_new.R'
'rounding-bias.R' 'row-to-colnames.R' 'scrutiny-package.R'
'seq-disperse.R' 'seq-length.R' 'split-by-parens.R'
'subset-superset.R' 'utils-pipe.R' 'utils-tidy-eval.R'
'write-doc-audit.R'</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, pkgload, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://lhdjung.github.io/scrutiny/">https://lhdjung.github.io/scrutiny/</a>,
<a href="https://github.com/lhdjung/scrutiny/">https://github.com/lhdjung/scrutiny/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lhdjung/scrutiny/issues">https://github.com/lhdjung/scrutiny/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-23 20:14:43 UTC; lukasjung</td>
</tr>
<tr>
<td>Author:</td>
<td>Lukas Jung [aut, cre],
  Aurélien Allard [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-23 23:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='scrutiny-package'>scrutiny: Error Detection in Science</h2><span id='topic+scrutiny'></span><span id='topic+scrutiny-package'></span>

<h3>Description</h3>

<p>Test published summary statistics for consistency (Brown and Heathers, 2017, <a href="https://doi.org/10.1177/1948550616673876">doi:10.1177/1948550616673876</a>; Allard, 2018, <a href="https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/">https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/</a>; Heathers and Brown, 2019, <a href="https://osf.io/5vb3u/">https://osf.io/5vb3u/</a>). The package also provides infrastructure for implementing new error detection techniques.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Lukas Jung <a href="mailto:jung-lukas@gmx.net">jung-lukas@gmx.net</a>
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Aurélien Allard [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://lhdjung.github.io/scrutiny/">https://lhdjung.github.io/scrutiny/</a>
</p>
</li>
<li> <p><a href="https://github.com/lhdjung/scrutiny/">https://github.com/lhdjung/scrutiny/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/lhdjung/scrutiny/issues">https://github.com/lhdjung/scrutiny/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>The pipe, <code style="white-space: pre;">&#8288;%&gt;%&#8288;</code>, is imported from magrittr and reexported for scrutiny users.
See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='audit'>Summarize scrutiny objects</h2><span id='topic+audit'></span>

<h3>Description</h3>

<p><code>audit()</code> summarizes the results of scrutiny functions like
<code><a href="#topic+grim_map">grim_map()</a></code> that perform tests on data frames.
</p>
<p>See below for a record of such functions. Go to the documentation of any of
them to learn about its <code>audit()</code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audit(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="audit_+3A_data">data</code></td>
<td>
<p>A data frame that inherits one of the classes named below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>audit()</code> is an S3 generic. It looks up the (invisible) scrutiny
class of a tibble returned by any function named below. You don't need to
deal with the classes directly. Behind the scenes, they mediate between
these functions and their associated summary statistics.
</p>


<h3>Value</h3>

<p>A tibble (data frame) with test summary statistics.
</p>


<h3>Run before <code>audit()</code></h3>


<table>
<tr>
 <td style="text-align: left;">
   <strong>Function</strong> </td><td style="text-align: left;"> <strong>Class</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+grim_map">grim_map()</a></code> </td><td style="text-align: left;"> <code>"scr_grim_map"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+grimmer_map">grimmer_map()</a></code> </td><td style="text-align: left;"> <code>"scr_grimmer_map"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+debit_map">debit_map()</a></code> </td><td style="text-align: left;"> <code>"scr_debit_map"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+duplicate_count">duplicate_count()</a></code> </td><td style="text-align: left;"> <code>"scr_dup_count"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+duplicate_count_colpair">duplicate_count_colpair()</a></code> </td><td style="text-align: left;"> <code>"scr_dup_count_colpair"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+duplicate_tally">duplicate_tally()</a></code> </td><td style="text-align: left;"> <code>"scr_dup_tally"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+duplicate_detect">duplicate_detect()</a></code> </td><td style="text-align: left;"> <code>"scr_dup_detect"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+audit_seq">audit_seq()</a></code> </td><td style="text-align: left;"> <code>"scr_audit_seq"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+audit_total_n">audit_total_n()</a></code> </td><td style="text-align: left;"> <code>"scr_audit_total_n"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'># For basic GRIM-testing:
pigs1 %&gt;%
  grim_map() %&gt;%
  audit()

# For duplicate detection:
pigs4 %&gt;%
  duplicate_count() %&gt;%
  audit()
</code></pre>

<hr>
<h2 id='audit_cols_minimal'>Compute minimal <code>audit()</code> summaries</h2><span id='topic+audit_cols_minimal'></span>

<h3>Description</h3>

<p>Call <code>audit_cols_minimal()</code> within your <code><a href="#topic+audit">audit()</a></code> methods for
the output of consistency test mapper functions such as <code><a href="#topic+grim_map">grim_map()</a></code>. It
will create a tibble with the three minimal, required columns:
</p>

<ol>
<li> <p><code>incons_cases</code> counts the inconsistent cases, i.e., the number of rows
in the mapper's output where <code>"consistency"</code> is <code>FALSE</code>.
</p>
</li>
<li> <p><code>all_cases</code> is the total number of rows in the mapper's output.
</p>
</li>
<li> <p><code>incons_rate</code> is the ratio of <code>incons_cases</code> to <code>all_cases</code>.
</p>
</li></ol>

<p>You can still add other columns to this tibble. Either way, make sure to
name your method correctly. See examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audit_cols_minimal(data, name_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="audit_cols_minimal_+3A_data">data</code></td>
<td>
<p>Data frame returned by a mapper function, such as <code><a href="#topic+grim_map">grim_map()</a></code>.</p>
</td></tr>
<tr><td><code id="audit_cols_minimal_+3A_name_test">name_test</code></td>
<td>
<p>String (length 1). Short, plain-text name of the consistency
test, such as <code>"GRIM"</code>. Only needed for a potential alert.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble (data frame) with the columns listed above.
</p>


<h3>See Also</h3>

<p>For context, see <code>vignette("consistency-tests-in-depth")</code>. In case
you don't call <code>audit_cols_minimal()</code>, you should call
<code><a href="#topic+check_audit_special">check_audit_special()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a mapper function called `schlim_map()`
# that applies a test called SCHLIM and returns
# a data frame with the `"scr_schlim_map"` class:
audit.scr_schlim_map &lt;- function(data) {
  audit_cols_minimal(data, name_test = "SCHLIM")
}

# If you like, add other summary columns
# with `dplyr::mutate()` or similar.
</code></pre>

<hr>
<h2 id='audit_list'>Summaries in list form</h2><span id='topic+audit_list'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>audit_list()</code> is deprecated. Use <code>audit()</code> instead.
</p>
<p>It was meant to be used when <code>audit()</code> would have returned tibbles that
were too wide to be read. However, the output format for <code>audit()</code> has now
been overhauled, there is no longer a need for <code>audit_list()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audit_list(data)
</code></pre>


<h3>Value</h3>

<p>Named list of <code>audit()</code>'s results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Only use `audit()` instead:
pigs1 %&gt;%
  grim_map() %&gt;%
  audit()
</code></pre>

<hr>
<h2 id='audit-special'>Summarize output of sequence mappers and total-n mappers</h2><span id='topic+audit-special'></span><span id='topic+audit_seq'></span><span id='topic+audit_total_n'></span>

<h3>Description</h3>

<p><code>audit_seq()</code> and <code>audit_total_n()</code> summarize the results of
functions that end on <code style="white-space: pre;">&#8288;_seq&#8288;</code> and <code style="white-space: pre;">&#8288;_total_n&#8288;</code>, respectively.
</p>
<p>See below for a record of such functions. Go to the documentation of any of
them to learn about the way its output is processed by <code>audit_seq()</code> or
<code>audit_total_n()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audit_seq(data)

audit_total_n(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="audit-special_+3A_data">data</code></td>
<td>
<p>A data frame that inherits one of the classes named below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functions named below that end on <code style="white-space: pre;">&#8288;_seq&#8288;</code> were made by
<code>function_map_seq()</code>. All that end on <code style="white-space: pre;">&#8288;_total_n&#8288;</code> were made by
<code>function_map_total_n()</code>.
</p>


<h3>Value</h3>

<p>A tibble (data frame) with test summary statistics.
</p>


<h3>Before <code>audit_seq()</code></h3>


<table>
<tr>
 <td style="text-align: left;">
   <strong>Function</strong> </td><td style="text-align: left;"> <strong>Class</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>grim_map_seq()</code> </td><td style="text-align: left;"> <code>"scr_grim_map_seq"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>grimmer_map_seq()</code> </td><td style="text-align: left;"> <code>"scr_grimmer_map_seq"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>debit_map_seq()</code> </td><td style="text-align: left;"> <code>"scr_debit_map_seq"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Before <code>audit_total_n()</code></h3>


<table>
<tr>
 <td style="text-align: left;">
   <strong>Function</strong> </td><td style="text-align: left;"> <strong>Class</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>grim_map_total_n()</code> </td><td style="text-align: left;"> <code>"scr_grim_map_total_n"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>grimmer_map_total_n()</code> </td><td style="text-align: left;"> <code>"scr_grimmer_map_total_n"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>debit_map_total_n()</code> </td><td style="text-align: left;"> <code>"scr_debit_map_total_n"</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'># For GRIM-testing with dispersed inputs:
out &lt;- pigs1 %&gt;%
  grim_map_seq() %&gt;%
  audit_seq()
out

# Follow up on `audit_seq()` or
# `audit_total_n()` with `audit()`:
audit(out)
</code></pre>

<hr>
<h2 id='check_audit_special'>Alert user if more specific <code style="white-space: pre;">&#8288;audit_*()&#8288;</code> summaries are available</h2><span id='topic+check_audit_special'></span>

<h3>Description</h3>

<p>(Note: Ignore this function if your <code>audit()</code> method calls
<code>audit_cols_minimal()</code>.)
</p>
<p>Call <code>check_audit_special()</code> within an <code>audit()</code> method for a consistency
test mapper function, such as <code>audit.scr_grim_map()</code>. It checks if the
input data frame was the product of a function produced by
<code>function_map_seq()</code> or <code>function_map_total_n()</code>.
</p>
<p>If so, the function issues a gentle alert to the user that points to
<code>audit_seq()</code> or <code>audit_total_n()</code>, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_audit_special(data, name_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_audit_special_+3A_data">data</code></td>
<td>
<p>The <code>audit()</code> method's input data frame.</p>
</td></tr>
<tr><td><code id="check_audit_special_+3A_name_test">name_test</code></td>
<td>
<p>String (length 1). Short, plain-text name of the consistency
test, such as <code>"GRIM"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value. Might print an alert.
</p>


<h3>See Also</h3>

<p><code>vignette("consistency-tests-in-depth")</code>, for context.
</p>

<hr>
<h2 id='check_mapper_input_colnames'>Check that a mapper's input has correct column names</h2><span id='topic+check_mapper_input_colnames'></span>

<h3>Description</h3>

<p>When called within a consistency test mapper function,
<code>check_mapper_input_colnames()</code> makes sure that the input data frame has
correct column names:
</p>

<ul>
<li><p> They include all the key columns corresponding to the test applied by the
mapper.
</p>
</li>
<li><p> They don't already include <code>"consistency"</code>.
</p>
</li></ul>

<p>If either check fails, the function throws an informative error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_mapper_input_colnames(data, reported, name_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_mapper_input_colnames_+3A_data">data</code></td>
<td>
<p>Data frame. Input to the mapper function.</p>
</td></tr>
<tr><td><code id="check_mapper_input_colnames_+3A_reported">reported</code></td>
<td>
<p>String vector of the &quot;key&quot; column names that <code>data</code> must
have, such as <code>c("x", "n")</code> for <code>grim_map()</code>.</p>
</td></tr>
<tr><td><code id="check_mapper_input_colnames_+3A_name_test">name_test</code></td>
<td>
<p>String (length 1). Short, plain-text name of the consistency
test that the mapper function applies, such as <code>"GRIM"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value. Might throw an error.
</p>


<h3>See Also</h3>

<p><code>vignette("consistency-tests-in-depth")</code>, for context and the &quot;key
columns&quot; terminology.
</p>

<hr>
<h2 id='data-frame-predicates'>Is an object a consistency test output tibble?</h2><span id='topic+data-frame-predicates'></span><span id='topic+is_map_df'></span><span id='topic+is_map_basic_df'></span><span id='topic+is_map_seq_df'></span><span id='topic+is_map_total_n_df'></span>

<h3>Description</h3>


<ul>
<li> <p><code>is_map_df()</code> tests whether an object is the output of a scrutiny-style
mapper function for consistency tests, like <code><a href="#topic+grim_map">grim_map()</a></code>. These mapper
functions also include those produced by <code><a href="#topic+function_map">function_map()</a></code>,
<code><a href="#topic+function_map_seq">function_map_seq()</a></code>, and <code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>.
</p>
</li>
<li> <p><code>is_map_basic_df()</code> is a variant of <code>is_map_df()</code> that tests whether an
object is the output of a &quot;basic&quot; mapper function. This includes functions
like <code>grim_map()</code> and those produced by <code><a href="#topic+function_map">function_map()</a></code>, but not those
produced by <code><a href="#topic+function_map_seq">function_map_seq()</a></code> or <code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>.
</p>
</li>
<li> <p><code>is_map_seq_df()</code> tests whether an object is the output of a function that
was produced by <code><a href="#topic+function_map_seq">function_map_seq()</a></code>.
</p>
</li>
<li> <p><code>is_map_total_n_df()</code> tests whether an object is the output of a function
that was produced by <code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>is_map_df(x)

is_map_basic_df(x)

is_map_seq_df(x)

is_map_total_n_df(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data-frame-predicates_+3A_x">x</code></td>
<td>
<p>Object to be tested.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sections 3, 6, and 7 of <code>vignette("consistency-tests-in-depth")</code>
discuss which function factories produce which functions, and which of
these new, factory-made functions return which kinds of tibbles.
</p>
<p>These tibbles are what the <code style="white-space: pre;">&#8288;is_map_*()&#8288;</code> functions test for. As an example,
<code><a href="#topic+function_map_seq">function_map_seq()</a></code> produces <code>grim_map_seq()</code>, and this new function
returns a tibble. <code>is_map_df()</code> and <code>is_map_seq_df()</code> return <code>TRUE</code> for
this tibble, but <code>is_map_basic_df()</code> and <code>is_map_total_n_df()</code> return
<code>FALSE</code>.
</p>
<p>For an overview, see the table at the end of
<code>vignette("consistency-tests-in-depth")</code>.
</p>


<h3>Value</h3>

<p>Logical (length 1).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example test output:
df1 &lt;- grim_map(pigs1)
df2 &lt;- grim_map_seq(pigs1)
df3 &lt;- grim_map_total_n(tibble::tribble(
  ~x1,    ~x2,   ~n,
  "3.43", "5.28", 90,
  "2.97", "4.42", 103
))

# All three tibbles are mapper output:
is_map_df(df1)
is_map_df(df2)
is_map_df(df3)

# However, only `df1` is the output of a
# basic mapper...
is_map_basic_df(df1)
is_map_basic_df(df2)
is_map_basic_df(df3)

# ...only `df2` is the output of a
# sequence mapper...
is_map_seq_df(df1)
is_map_seq_df(df2)
is_map_seq_df(df3)

# ...and only `df3` is the output of a
# total-n mapper:
is_map_total_n_df(df1)
is_map_total_n_df(df2)
is_map_total_n_df(df3)
</code></pre>

<hr>
<h2 id='debit'>The DEBIT (descriptive binary) test</h2><span id='topic+debit'></span>

<h3>Description</h3>

<p><code>debit()</code> tests summaries of binary data for consistency: If the
mean and the standard deviation of binary data are given, are they
consistent with the reported sample size?
</p>
<p>The function is vectorized, but it is recommended to use <code><a href="#topic+debit_map">debit_map()</a></code>
for testing multiple cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debit(
  x,
  sd,
  n,
  formula = "mean_n",
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="debit_+3A_x">x</code></td>
<td>
<p>String. Mean of a binary distribution.</p>
</td></tr>
<tr><td><code id="debit_+3A_sd">sd</code></td>
<td>
<p>String. Sample standard deviation of a binary distribution.</p>
</td></tr>
<tr><td><code id="debit_+3A_n">n</code></td>
<td>
<p>Integer. Total sample size.</p>
</td></tr>
<tr><td><code id="debit_+3A_formula">formula</code></td>
<td>
<p>String. Formula used to compute the SD of the binary
distribution. Currently, only the default, <code>"mean_n"</code>, is supported.</p>
</td></tr>
<tr><td><code id="debit_+3A_rounding">rounding</code></td>
<td>
<p>String. Rounding method or methods to be used for
reconstructing the SD values to which <code>sd</code> will be compared. Default is
<code>"up_or_down"</code> (from 5). See <code>vignette("rounding-options")</code>.</p>
</td></tr>
<tr><td><code id="debit_+3A_threshold">threshold</code></td>
<td>
<p>Integer. If <code>rounding</code> is set to <code>"up_from"</code>, <code>"down_from"</code>,
or <code>"up_from_or_down_from"</code>, set <code>threshold</code> to the number from which the
reconstructed values should then be rounded up or down. Otherwise
irrelevant. Default is <code>5</code>.</p>
</td></tr>
<tr><td><code id="debit_+3A_symmetric">symmetric</code></td>
<td>
<p>Logical. Set <code>symmetric</code> to <code>TRUE</code> if the rounding of
negative numbers with <code>"up"</code>, <code>"down"</code>, <code>"up_from"</code>, or <code>"down_from"</code>
should mirror that of positive numbers so that their absolute values are
always equal. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Logical. <code>TRUE</code> if <code>x</code>, <code>sd</code>, and <code>n</code> are mutually consistent,
<code>FALSE</code> if not.
</p>


<h3>References</h3>

<p>Heathers, James A. J., and Brown, Nicholas J. L. 2019. DEBIT: A
Simple Consistency Test For Binary Data. https://osf.io/5vb3u/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+debit_map">debit_map()</a></code> applies <code>debit()</code> to any number of cases at once.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Check single cases of binary
# summary data:
debit(x = "0.36", sd = "0.11", n = 20)
</code></pre>

<hr>
<h2 id='debit_map'>Apply DEBIT to many cases</h2><span id='topic+debit_map'></span>

<h3>Description</h3>

<p>Call <code>debit_map()</code> to use DEBIT on multiple combinations of
mean, standard deviation, and sample size of binary distributions. Mapping
function for <code><a href="#topic+debit">debit()</a></code>.
</p>
<p>For summary statistics, call <code><a href="#topic+audit">audit()</a></code> on the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debit_map(
  data,
  x = NULL,
  sd = NULL,
  n = NULL,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE,
  show_rec = TRUE,
  extra = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="debit_map_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="debit_map_+3A_x">x</code>, <code id="debit_map_+3A_sd">sd</code>, <code id="debit_map_+3A_n">n</code></td>
<td>
<p>Optionally, specify these arguments as column names in <code>data</code>.</p>
</td></tr>
<tr><td><code id="debit_map_+3A_rounding">rounding</code>, <code id="debit_map_+3A_threshold">threshold</code>, <code id="debit_map_+3A_symmetric">symmetric</code></td>
<td>
<p>Arguments passed on to <code><a href="#topic+debit">debit()</a></code>, with
the same defaults.</p>
</td></tr>
<tr><td><code id="debit_map_+3A_show_rec">show_rec</code></td>
<td>
<p>If set to <code>FALSE</code>, the resulting tibble only includes the
columns <code>x</code>, <code>sd</code>, <code>n</code>, and <code>consistency</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="debit_map_+3A_extra">extra</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with (at least) these columns &ndash;
</p>

<ul>
<li> <p><code>x</code>, <code>sd</code>, <code>n</code>: the inputs.
</p>
</li>
<li> <p><code>consistency</code>: DEBIT consistency of <code>x</code>, <code>sd</code>, and <code>n</code>.
</p>
<p>By default, the tibble also includes the rounding method, boundary values,
and information about the boundary values being inclusive or not. The
tibble has the <code>scr_debit_map</code> class, which is recognized by the <code>audit()</code>
generic.
</p>
</li></ul>



<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for the
<code><a href="#topic+audit">audit()</a></code> generic, so you can call <code><a href="#topic+audit">audit()</a></code> following <code>debit_map()</code>.
It returns a tibble with these columns &mdash;
</p>

<ol>
<li> <p><code>incons_cases</code>: the number of DEBIT-inconsistent cases.
</p>
</li>
<li> <p><code>all_cases</code>: the total number of cases.
</p>
</li>
<li> <p><code>incons_rate</code>: the rate of inconsistent cases.
</p>
</li>
<li> <p><code>mean_x</code>: the mean <code>x</code> (mean) value.
</p>
</li>
<li> <p><code>mean_sd</code>: the mean <code>sd</code> value.
</p>
</li>
<li> <p><code>distinct_n</code>: the number of distinct <code>n</code> values.
</p>
</li></ol>



<h3>References</h3>

<p>Heathers, James A. J., and Brown, Nicholas J. L. 2019. DEBIT: A
Simple Consistency Test For Binary Data. https://osf.io/5vb3u/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Call `debit_map()` on binary summary
# data such as these:
pigs3

# The `consistency` column shows
# whether the values to its left
# are DEBIT-consistent:
pigs3 %&gt;%
  debit_map()

# Get test summaries with `audit()`:
pigs3 %&gt;%
  debit_map() %&gt;%
  audit()
</code></pre>

<hr>
<h2 id='debit_map_seq'>Using DEBIT with dispersed inputs</h2><span id='topic+debit_map_seq'></span>

<h3>Description</h3>

<p><code>debit_map_seq()</code> applies DEBIT with values surrounding the input values.
This provides an easy and powerful way to assess whether small errors in
computing or reporting may be responsible for DEBIT inconsistencies in
published statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debit_map_seq(
  data,
  x = NULL,
  sd = NULL,
  n = NULL,
  var = Inf,
  dispersion = 1:5,
  out_min = "auto",
  out_max = NULL,
  include_reported = FALSE,
  include_consistent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="debit_map_seq_+3A_data">data</code></td>
<td>
<p>A data frame that <code>debit_map()</code> could take.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_x">x</code>, <code id="debit_map_seq_+3A_sd">sd</code>, <code id="debit_map_seq_+3A_n">n</code></td>
<td>
<p>Optionally, specify column names in <code>data</code> as these arguments.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_var">var</code></td>
<td>
<p>String. Names of the columns that will be dispersed. Default is
<code>c("x", "sd", "n")</code>.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Sequence with steps up and down from the <code>var</code>
inputs. It will be adjusted to these values' decimal levels. For example,
with a reported <code>8.34</code>, the step size is <code>0.01</code>. Default is <code>1:5</code>, for five
steps up and down.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_out_min">out_min</code>, <code id="debit_map_seq_+3A_out_max">out_max</code></td>
<td>
<p>If specified, output will be restricted so that it's
not below <code>out_min</code> or above <code>out_max</code>. Defaults are <code>"auto"</code> for
<code>out_min</code>, i.e., a minimum of one decimal unit above zero; and <code>NULL</code> for
<code>out_max</code>, i.e., no maximum.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_include_reported">include_reported</code></td>
<td>
<p>Logical. Should the reported values themselves be
included in the sequences originating from them? Default is <code>FALSE</code> because
this might be redundant and bias the results.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_include_consistent">include_consistent</code></td>
<td>
<p>Logical. Should the function also process
consistent cases (from among those reported), not just inconsistent ones?
Default is <code>FALSE</code> because the focus should be on clarifying
inconsistencies.</p>
</td></tr>
<tr><td><code id="debit_map_seq_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code>debit_map()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble (data frame) with detailed test results.
</p>


<h3>Summaries with <code><a href="#topic+audit_seq">audit_seq()</a></code></h3>

<p>You can call <code><a href="#topic+audit_seq">audit_seq()</a></code>
following <code>debit_map_seq()</code>. It will return a data frame with these
columns:
</p>

<ul>
<li> <p><code>x</code>, <code>sd</code>, and <code>n</code> are the original inputs,
tested for <code>consistency</code> here.
</p>
</li>
<li> <p><code>hits_total</code> is the total number of DEBIT-consistent value sets
found within the specified <code>dispersion</code> range.
</p>
</li>
<li> <p><code>hits_x</code> is the number of DEBIT-consistent value sets
found by varying <code>x</code>.
</p>
</li>
<li><p> Accordingly with <code>sd</code> and <code>hits_sd</code> as well as <code>n</code> and <code>hits_n</code>.
</p>
</li>
<li><p> (Note that any consistent reported cases will be counted by the
<code style="white-space: pre;">&#8288;hits_*&#8288;</code> columns if both <code>include_reported</code> and <code>include_consistent</code> are
set to <code>TRUE</code>.)
</p>
</li>
<li> <p><code>diff_x</code> reports the absolute difference between <code>x</code> and the next
consistent dispersed value (in dispersion steps, not the actual numeric
difference). <code>diff_x_up</code> and <code>diff_x_down</code> report the difference to the
next higher or lower consistent value, respectively.
</p>
</li>
<li> <p><code>diff_sd</code>, <code>diff_sd_up</code>, and <code>diff_sd_down</code> do the same for <code>sd</code>.
</p>
</li>
<li><p> Likewise with <code>diff_n</code>, <code>diff_n_up</code>, and <code>diff_n_down</code>.
</p>
</li></ul>

<p>Call <code><a href="#topic+audit">audit()</a></code> following <code>audit_seq()</code> to summarize results even further.
It's mostly self-explaining, but <code>na_count</code> and <code>na_rate</code> are the number
and rate of times that a difference could not be computed because of a lack
of corresponding hits within the <code>dispersion</code> range.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># `debit_map_seq()` can take any input
# that `debit_map()` can take:
pigs3

# Results from testing some few rows:
out &lt;- pigs3 %&gt;%
  dplyr::slice(3:4) %&gt;%
  debit_map_seq()

out

# Case-wise summaries with `audit_seq()`
# can be more important than the raw results:
out %&gt;%
  audit_seq()
</code></pre>

<hr>
<h2 id='debit_map_total_n'>Use DEBIT with hypothetical group sizes</h2><span id='topic+debit_map_total_n'></span>

<h3>Description</h3>

<p><code>debit_map_total_n()</code> extends DEBIT to cases where only group
means and standard deviations (SDs) were reported, not group sizes.
</p>
<p>The function is analogous to <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code> and
<code><a href="#topic+grimmer_map_total_n">grimmer_map_total_n()</a></code>, relying on the same infrastructure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debit_map_total_n(
  data,
  x1 = NULL,
  x2 = NULL,
  sd1 = NULL,
  sd2 = NULL,
  dispersion = 0:5,
  n_min = 1L,
  n_max = NULL,
  constant = NULL,
  constant_index = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="debit_map_total_n_+3A_data">data</code></td>
<td>
<p>Data frame with string columns <code>x1</code>, <code>x2</code>, <code>sd1</code>, and <code>sd2</code>, as
well as numeric column <code>n</code>. The first two are reported group means. <code>sd1</code>
and <code>sd2</code> are reported group SDs. <code>n</code> is the reported total sample size. It
is not very important whether a value is in <code>x1</code> or in <code>x2</code> because, after
the first round of tests, the function switches roles between <code>x1</code> and
<code>x2</code>, and reports the outcomes both ways. The same applies to <code>sd1</code> and
<code>sd2</code>. However, do make sure the <code style="white-space: pre;">&#8288;x*&#8288;</code> and <code style="white-space: pre;">&#8288;sd*&#8288;</code> values are paired
accurately, as reported.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_x1">x1</code>, <code id="debit_map_total_n_+3A_x2">x2</code>, <code id="debit_map_total_n_+3A_sd1">sd1</code>, <code id="debit_map_total_n_+3A_sd2">sd2</code></td>
<td>
<p>Optionally, specify these arguments as column names in
<code>data</code>.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Steps up and down from half the <code>n</code> values.
Default is <code>0:5</code>, i.e., half <code>n</code> itself followed by five steps up and down.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_n_min">n_min</code></td>
<td>
<p>Numeric. Minimal group size. Default is 1.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_n_max">n_max</code></td>
<td>
<p>Numeric. Maximal group size. Default is <code>NULL</code>, i.e., no
maximum.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_constant">constant</code></td>
<td>
<p>Optionally, add a length-2 vector or a list of length-2
vectors (such as a data frame with exactly two rows) to accompany the pairs
of dispersed values. Default is <code>NULL</code>, i.e., no constant values.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_constant_index">constant_index</code></td>
<td>
<p>Integer (length 1). Index of <code>constant</code> or the first
<code>constant</code> column in the output tibble. If <code>NULL</code> (the default), <code>constant</code>
will go to the right of <code>n_change</code>.</p>
</td></tr>
<tr><td><code id="debit_map_total_n_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code><a href="#topic+debit_map">debit_map()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with these columns:
</p>

<ul>
<li> <p><code>x</code> and <code>sd</code>, the group-wise reported input statistics, are repeated in
row pairs.
</p>
</li>
<li> <p><code>n</code> is dispersed from half the input <code>n</code>, with <code>n_change</code> tracking the
differences.
</p>
</li>
<li> <p><code>both_consistent</code> flags scenarios where both reported <code>x</code> and <code>sd</code> values
are consistent with the hypothetical <code>n</code> values.
</p>
</li>
<li> <p><code>case</code> corresponds to the row numbers of the input data frame.
</p>
</li>
<li> <p><code>dir</code> is <code>"forth"</code> in the first half of rows and <code>"back"</code> in the second
half. <code>"forth"</code> means that <code>x2</code> and <code>sd2</code> from the input are paired with the
larger dispersed <code>n</code>, whereas <code>"back"</code> means that <code>x1</code> and <code>sd1</code> are paired
with the larger dispersed <code>n</code>.
</p>
</li>
<li><p> Other columns from <code>debit_map()</code> are preserved.
</p>
</li></ul>



<h3>Summaries with <code><a href="#topic+audit_total_n">audit_total_n()</a></code></h3>

<p>You can call
<code><a href="#topic+audit_total_n">audit_total_n()</a></code> following up on <code>debit_map_total_n()</code>
to get a tibble with summary statistics. It will have these columns:
</p>

<ul>
<li> <p><code>x1</code>, <code>x2</code>, <code>sd1</code>, <code>sd2</code>, and <code>n</code> are the original inputs.
</p>
</li>
<li> <p><code>hits_total</code> is the number of scenarios in which all of
<code>x1</code>, <code>x2</code>, <code>sd1</code>, and <code>sd2</code> are DEBIT-consistent. It is the sum
of <code>hits_forth</code> and <code>hits_back</code> below.
</p>
</li>
<li> <p><code>hits_forth</code> is the number of both-consistent cases that result
from pairing <code>x2</code> and <code>sd2</code> with the larger dispersed <code>n</code> value.
</p>
</li>
<li> <p><code>hits_back</code> is the same, except <code>x1</code> and <code>sd1</code> are
paired with the larger dispersed <code>n</code> value.
</p>
</li>
<li> <p><code>scenarios_total</code> is the total number of test scenarios,
whether or not both <code>x1</code> and <code>sd1</code> as well as <code>x2</code> and <code>sd2</code>
are DEBIT-consistent.
</p>
</li>
<li> <p><code>hit_rate</code> is the ratio of <code>hits_total</code> to <code>scenarios_total</code>.
</p>
</li></ul>

<p>Call <code><a href="#topic+audit">audit()</a></code> following <code><a href="#topic+audit_total_n">audit_total_n()</a></code> to summarize results
even further.
</p>


<h3>References</h3>

<p>Bauer, P. J., &amp; Francis, G. (2021). Expression of Concern: Is It
Light or Dark? Recalling Moral Behavior Changes Perception of Brightness.
<em>Psychological Science</em>, 32(12), 2042–2043.
https://journals.sagepub.com/doi/10.1177/09567976211058727
</p>
<p>Heathers, J. A. J., &amp; Brown, N. J. L. (2019). DEBIT: A Simple Consistency
Test For Binary Data. https://osf.io/5vb3u/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>, which created the present function using
<code><a href="#topic+debit_map">debit_map()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run `debit_map_total_n()` on data like these:
df &lt;- tibble::tribble(
  ~x1,  ~x2,  ~sd1,  ~sd2,  ~n,
  "0.30", "0.28", "0.17", "0.10", 70,
  "0.41", "0.39", "0.09", "0.15", 65
)
df

debit_map_total_n(df)
</code></pre>

<hr>
<h2 id='debit_plot'>Visualize DEBIT results</h2><span id='topic+debit_plot'></span>

<h3>Description</h3>

<p>Plot a distribution of binary data and their mutual DEBIT
consistency. Call this function only on a data frame that resulted from a
call to <code><a href="#topic+debit_map">debit_map()</a></code>.
</p>
<p>Various parameters of the individual geoms can be controlled via arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debit_plot(
  data,
  show_outer_boxes = TRUE,
  show_labels = TRUE,
  show_full_scale = TRUE,
  show_theme_other = TRUE,
  color_cons = "royalblue1",
  color_incons = "red",
  line_alpha = 1,
  line_color = "black",
  line_linetype = 1,
  line_width = 0.5,
  line_size = 0.5,
  rect_alpha = 1,
  tile_alpha = 0.15,
  tile_height_offset = 0.025,
  tile_width_offset = 0.025,
  tile_height_min = 0.0375,
  tile_width_min = 0.0385,
  label_alpha = 0.5,
  label_linetype = 3,
  label_size = 3.5,
  label_linesize = 0.75,
  label_force = 175,
  label_force_pull = 0.75,
  label_padding = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="debit_plot_+3A_data">data</code></td>
<td>
<p>Data frame. Result of a call to <code><a href="#topic+debit_map">debit_map()</a></code>.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_show_outer_boxes">show_outer_boxes</code></td>
<td>
<p>Logical. Should outer tiles surround the actual data
points, making it easier to spot them and to assess their overlap? Default
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_show_labels">show_labels</code></td>
<td>
<p>Logical. Should the data points have labels (of the form
&quot;mean; SD&quot;)? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_show_full_scale">show_full_scale</code></td>
<td>
<p>Logical. Should the plot be fixed to full scale,
showing the entire consistency line independently of the data? Default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_show_theme_other">show_theme_other</code></td>
<td>
<p>Logical. Should the theme be modified in a way
fitting the plot structure? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_color_cons">color_cons</code>, <code id="debit_plot_+3A_color_incons">color_incons</code></td>
<td>
<p>Strings. Colors of the geoms representing
consistent and inconsistent values, respectively.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_line_alpha">line_alpha</code>, <code id="debit_plot_+3A_line_color">line_color</code>, <code id="debit_plot_+3A_line_linetype">line_linetype</code>, <code id="debit_plot_+3A_line_width">line_width</code>, <code id="debit_plot_+3A_line_size">line_size</code></td>
<td>
<p>Parameters of
the curved DEBIT line.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_rect_alpha">rect_alpha</code></td>
<td>
<p>Parameter of the DEBIT rectangles. (Due to the nature of
the data mapping, there can be no leeway regarding the shape or size of
this particular geom.)</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_tile_alpha">tile_alpha</code>, <code id="debit_plot_+3A_tile_height_offset">tile_height_offset</code>, <code id="debit_plot_+3A_tile_width_offset">tile_width_offset</code>, <code id="debit_plot_+3A_tile_height_min">tile_height_min</code>, <code id="debit_plot_+3A_tile_width_min">tile_width_min</code></td>
<td>
<p>Parameters of the outer tiles surrounding the DEBIT rectangles. Offset refers
to the distance from the rectangles within.</p>
</td></tr>
<tr><td><code id="debit_plot_+3A_label_alpha">label_alpha</code>, <code id="debit_plot_+3A_label_linetype">label_linetype</code>, <code id="debit_plot_+3A_label_size">label_size</code>, <code id="debit_plot_+3A_label_linesize">label_linesize</code>, <code id="debit_plot_+3A_label_force">label_force</code>, <code id="debit_plot_+3A_label_force_pull">label_force_pull</code>, <code id="debit_plot_+3A_label_padding">label_padding</code></td>
<td>
<p>Parameters of the labels showing mean and SD values. Passed on to
<code><a href="ggrepel.html#topic+geom_text_repel">ggrepel::geom_text_repel()</a></code>; see there for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The labels are created via <code><a href="ggrepel.html#topic+geom_text_repel">ggrepel::geom_text_repel()</a></code>, so the
algorithm is designed to minimize overlap with the tiles and other labels.
Yet, they don't take the DEBIT line into account, and their locations are
ultimately random. You might therefore have to resize the plot or run the
function a few times until the labels are localized in a satisfactory way.
</p>
<p>An alternative to the present function would be an S3 method for
<code><a href="ggplot2.html#topic+autoplot">ggplot2::autoplot()</a></code>. However, a standalone function such as this allows
for customizing geom parameters and might perhaps provide better
accessibility overall.
</p>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>References</h3>

<p>Heathers, James A. J., and Brown, Nicholas J. L. 2019. DEBIT: A
Simple Consistency Test For Binary Data. https://osf.io/5vb3u/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run `debit_plot()` on the output
# of `debit_map()`:
pigs3 %&gt;%
  debit_map() %&gt;%
  debit_plot()
</code></pre>

<hr>
<h2 id='decimal_places'>Count decimal places</h2><span id='topic+decimal_places'></span><span id='topic+decimal_places_scalar'></span>

<h3>Description</h3>

<p><code>decimal_places()</code> counts the decimal places in a numeric
vector, or in a string vector that can be coerced to numeric.
</p>
<p><code>decimal_places_scalar()</code> is much faster but only takes a single input. It
is useful as a helper within other single-case functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decimal_places(x, sep = "\\.")

decimal_places_scalar(x, sep = "\\.")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decimal_places_+3A_x">x</code></td>
<td>
<p>Numeric (or string that can be coerced to numeric). Object with
decimal places to count.</p>
</td></tr>
<tr><td><code id="decimal_places_+3A_sep">sep</code></td>
<td>
<p>Substring that separates the mantissa from the integer part.
Default is <code>"\\."</code>, which renders a decimal point.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Decimal places in numeric values can't be counted accurately if the
number has 15 or more characters in total, including the integer part and
the decimal point. A possible solutions is to enter the number as a string
to count all digits. (Converting to string is not sufficient &ndash; those
numbers need to be <em>entered</em> in quotes.)
</p>
<p>The functions ignore any whitespace at the end of a string, so they won't
mistake spaces for decimal places.
</p>


<h3>Value</h3>

<p>Integer. Number of decimal places in <code>x</code>.
</p>


<h3>Trailing zeros</h3>

<p>If trailing zeros matter, don't convert numeric
values to strings: In numeric values, any trailing zeros have already been
dropped, and any information about them was lost (e.g., <code>3.70</code> returns
<code>3.7</code>). Enter those values as strings instead, such as <code>"3.70"</code> instead of
<code>3.70</code>. However, you can restore lost trailing zeros with
<code><a href="#topic+restore_zeros">restore_zeros()</a></code> if the original number of decimal places is known.
</p>
<p>If you need to enter many such values as strings, consider using
<code><a href="tibble.html#topic+tribble">tibble::tribble()</a></code> and drawing quotation marks around all values in a
<code>tribble()</code> column at once via RStudio's multiple cursors.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+decimal_places_df">decimal_places_df()</a></code>, which applies <code>decimal_places()</code> to all
numeric-like columns in a data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># `decimal_places()` works on both numeric values
# and strings...
decimal_places(x = 2.851)
decimal_places(x = "2.851")

# ... but trailing zeros are only counted within
# strings:
decimal_places(x = c(7.3900, "7.3900"))

# This doesn't apply to non-trailing zeros; these
# behave just like any other digit would:
decimal_places(x = c(4.08, "4.08"))

# Whitespace at the end of a string is not counted:
decimal_places(x = "6.0     ")

# `decimal_places_scalar()` is much faster,
# but only works with a single number or string:
decimal_places_scalar(x = 8.13)
decimal_places_scalar(x = "5.024")
</code></pre>

<hr>
<h2 id='decimal_places_df'>Count decimal places in a data frame</h2><span id='topic+decimal_places_df'></span>

<h3>Description</h3>

<p>For every value in a column, <code>decimal_places_df()</code> counts its decimal places.
By default, it operates on all columns that are coercible to numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decimal_places_df(
  data,
  cols = everything(),
  check_numeric_like = TRUE,
  sep = "\\."
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decimal_places_df_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="decimal_places_df_+3A_cols">cols</code></td>
<td>
<p>Select columns from <code>data</code> using
<a href="https://tidyselect.r-lib.org/reference/language.html">tidyselect</a>.
Default is <code>everything()</code>, but restricted by <code>check_numeric_like</code>.</p>
</td></tr>
<tr><td><code id="decimal_places_df_+3A_check_numeric_like">check_numeric_like</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), the function only
operates on numeric columns and other columns coercible to numeric, as
determined by <code><a href="#topic+is_numeric_like">is_numeric_like()</a></code>.</p>
</td></tr>
<tr><td><code id="decimal_places_df_+3A_sep">sep</code></td>
<td>
<p>Substring that separates the mantissa from the integer part.
Default is <code>"\\."</code>, which renders a decimal point.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame. The values of the selected columns are replaced by the
numbers of their decimal places.
</p>


<h3>See Also</h3>

<p>Wrapped functions: <code><a href="#topic+decimal_places">decimal_places()</a></code>, <code><a href="dplyr.html#topic+across">dplyr::across()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Coerce all columns to string:
iris &lt;- iris %&gt;%
  tibble::as_tibble() %&gt;%
  dplyr::mutate(across(everything(), as.character))

# The function will operate on all
# numeric-like columns but not on `"Species"`:
iris %&gt;%
  decimal_places_df()

# Operate on some select columns only
# (from among the numeric-like columns):
iris %&gt;%
  decimal_places_df(cols = starts_with("Sepal"))
</code></pre>

<hr>
<h2 id='disperse'>Vary hypothetical group sizes</h2><span id='topic+disperse'></span><span id='topic+disperse2'></span><span id='topic+disperse_total'></span>

<h3>Description</h3>

<p>Some published studies only report a total sample size but no
group sizes. However, group sizes are crucial for consistency tests such as
GRIM. Call <code>disperse()</code> to generate possible group sizes that all add up to
the total sample size, if that total is even.
</p>
<p><code>disperse2()</code> is a variant for odd totals. It takes two consecutive numbers
and generates decreasing values from the lower as well as increasing values
from the upper. In this way, all combinations still add up to the total.
</p>
<p><code>disperse_total()</code> directly takes the total sample size, checks if it's
even or odd, splits it up accordingly, and applies <code>disperse()</code> or
<code>disperse2()</code>, respectively.
</p>
<p>These functions are primarily intended as helpers. They form the backbone
of <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code> and all other functions created with
<code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disperse(
  n,
  dispersion = 0:5,
  n_min = 1L,
  n_max = NULL,
  constant = NULL,
  constant_index = NULL
)

disperse2(
  n,
  dispersion = 0:5,
  n_min = 1L,
  n_max = NULL,
  constant = NULL,
  constant_index = NULL
)

disperse_total(
  n,
  dispersion = 0:5,
  n_min = 1L,
  n_max = NULL,
  constant = NULL,
  constant_index = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disperse_+3A_n">n</code></td>
<td>
<p>Numeric:
</p>

<ul>
<li><p> In <code>disperse()</code>, single number from which to go up and down. This should be
half of an even total sample size.
</p>
</li>
<li><p> In <code>disperse2()</code>, the two consecutive numbers closest to half of an odd
total sample size (e.g., <code>c(25, 26)</code> for a total of 51).
</p>
</li>
<li><p> In <code>disperse_total()</code>, the total sample size.
</p>
</li></ul>
</td></tr>
<tr><td><code id="disperse_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Vector that determines the steps up and down from
<code>n</code> (or, in <code>disperse_total()</code>, from half <code>n</code>). Default is <code>0:5</code>.</p>
</td></tr>
<tr><td><code id="disperse_+3A_n_min">n_min</code></td>
<td>
<p>Numeric. Minimal group size. Default is <code>1L</code>.</p>
</td></tr>
<tr><td><code id="disperse_+3A_n_max">n_max</code></td>
<td>
<p>Numeric. Maximal group size. Default is <code>NULL</code>, i.e., no
maximum.</p>
</td></tr>
<tr><td><code id="disperse_+3A_constant">constant</code></td>
<td>
<p>Optionally, add a length-2 vector or a list of length-2
vectors (such as a data frame with exactly two rows) to accompany the pairs
of dispersed values. Default is <code>NULL</code>, i.e., no constant values.</p>
</td></tr>
<tr><td><code id="disperse_+3A_constant_index">constant_index</code></td>
<td>
<p>Integer (length 1). Index of <code>constant</code> or the first
<code>constant</code> column in the output tibble. If <code>NULL</code> (the default), <code>constant</code>
will go to the right of <code>n_change</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If any group size is less than <code>n_min</code> or greater than <code>n_max</code>, it
is removed. The complementary size of the other group is also removed.
</p>
<p><code>constant</code> values are pairwise repeated. That is why <code>constant</code> must be
a length-2 atomic vector or a list of such vectors. If <code>constant</code> is a data
frame or some other named list, the resulting columns will have the same
names as the list-element names. If the list is not named, the new column
names will be <code>"constant1"</code>, <code>"constant2"</code>, etc; or just <code>"constant"</code>, for
a single pair.
</p>


<h3>Value</h3>

<p>A tibble (data frame) with these columns:
</p>

<ul>
<li> <p><code>n</code> includes the dispersed <code>n</code> values. Every pair of consecutive rows has
<code>n</code> values that each add up to the total.
</p>
</li>
<li> <p><code>n_change</code> records how the input <code>n</code> was transformed to the output <code>n</code>. In
<code>disperse2()</code>, the <code>n_change</code> strings label the lower of the input <code>n</code>
values <code>n1</code> and the higher one <code>n2</code>.
</p>
</li></ul>



<h3>References</h3>

<p>Bauer, P. J., &amp; Francis, G. (2021). Expression of Concern: Is It
Light or Dark? Recalling Moral Behavior Changes Perception of Brightness.
<em>Psychological Science</em>, 32(12), 2042–2043.
https://journals.sagepub.com/doi/10.1177/09567976211058727
</p>


<h3>See Also</h3>

<p><code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>, <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code>, and
<code><a href="#topic+seq_distance_df">seq_distance_df()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a total sample size of 40,
# set `n` to `20`:
disperse(n = 20)

# Specify `dispersion` to control
# the steps up and down from `n`:
disperse(n = 20, dispersion = c(3, 6, 10))

# In `disperse2()`, specify `n` as two
# consecutive numbers -- i.e., group sizes:
disperse2(n = c(25, 26))

# Use the total sample size directly
# with `disperse_total()`. An even total
# internally triggers `disperse()`...
disperse_total(n = 40)

# ...whereas an odd total triggers `disperse2()`:
disperse_total(n = 51)

# You may add values that repeat along with the
# dispersed ones but remain constant themselves.
# Such values can be stored in a length-2 vector
# for a single column...
disperse_total(37, constant = c("5.24", "3.80"))

# ... or a list of length-2 vectors for multiple
# columns. This includes data frames with 2 rows:
df_constant &lt;- tibble::tibble(
  name = c("Paul", "Mathilda"), age = 27:28,
  registered = c(TRUE, FALSE)
)
disperse_total(37, constant = df_constant)
</code></pre>

<hr>
<h2 id='duplicate_count'>Count duplicate values</h2><span id='topic+duplicate_count'></span>

<h3>Description</h3>

<p><code>duplicate_count()</code> returns a frequency table. When searching a
data frame, it includes values from all columns for each frequency count.
</p>
<p>This function is a blunt tool designed for initial data checking. It is not
too informative if many values have few characters each.
</p>
<p>For summary statistics, call <code><a href="#topic+audit">audit()</a></code> on the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicate_count(
  x,
  ignore = NULL,
  locations_type = c("character", "list"),
  numeric_only = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicate_count_+3A_x">x</code></td>
<td>
<p>Vector or data frame.</p>
</td></tr>
<tr><td><code id="duplicate_count_+3A_ignore">ignore</code></td>
<td>
<p>Optionally, a vector of values that should not be counted.</p>
</td></tr>
<tr><td><code id="duplicate_count_+3A_locations_type">locations_type</code></td>
<td>
<p>String. One of <code>"character"</code> or <code>"list"</code>. With
<code>"list"</code>, each <code>locations</code> value is a vector of column names, which is
better for further programming. By default (<code>"character"</code>), the column
names are pasted into a string, which is more readable.</p>
</td></tr>
<tr><td><code id="duplicate_count_+3A_numeric_only">numeric_only</code></td>
<td>
<p>[<a href="base.html#topic+Deprecated">Deprecated</a>] No longer used: All values are coerced to
character.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Don't use <code>numeric_only</code>. It no longer has any effect and will be
removed in the future. The only reason for this argument was the risk of
errors introduced by coercing values to numeric. This is no longer an issue
because all values are now coerced to character, which is more appropriate
for checking reported statistics.
</p>


<h3>Value</h3>

<p>If <code>x</code> is a data frame or another named vector, a tibble with four
columns. If <code>x</code> isn't named, only the first two columns appear:
</p>

<ul>
<li> <p><code>value</code>: All the values from <code>x</code>.
</p>
</li>
<li> <p><code>frequency</code>: Absolute frequency of each value in <code>x</code>, in descending order.
</p>
</li>
<li> <p><code>locations</code>: Names of all columns from <code>x</code> in which <code>value</code> appears.
</p>
</li>
<li> <p><code>locations_n</code>: Number of columns named in <code>locations</code>.
</p>
</li></ul>

<p>The tibble has the <code>scr_dup_count</code> class, which is recognized by the
<code><a href="#topic+audit">audit()</a></code> generic.
</p>


<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for the
<code><a href="#topic+audit">audit()</a></code> generic, so you can call <code><a href="#topic+audit">audit()</a></code> following
<code>duplicate_count()</code>. It returns a tibble with summary statistics for the
two numeric columns, <code>frequency</code> and <code>locations_n</code> (or, if <code>x</code> isn't named,
only for <code>frequency</code>).
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+duplicate_count_colpair">duplicate_count_colpair()</a></code> to check each combination of columns for
duplicates.
</p>
</li>
<li> <p><code><a href="#topic+duplicate_tally">duplicate_tally()</a></code> to show instances of a value next to each instance.
</p>
</li>
<li> <p><code><a href="janitor.html#topic+get_dupes">janitor::get_dupes()</a></code> to search for duplicate rows.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Count duplicate values...
iris %&gt;%
  duplicate_count()

# ...and compute summaries:
iris %&gt;%
  duplicate_count() %&gt;%
  audit()

# Any values can be ignored:
iris %&gt;%
  duplicate_count(ignore = c("setosa", "versicolor", "virginica"))
</code></pre>

<hr>
<h2 id='duplicate_count_colpair'>Count duplicate values by column</h2><span id='topic+duplicate_count_colpair'></span>

<h3>Description</h3>

<p><code>duplicate_count_colpair()</code> takes a data frame and checks each combination of
columns for duplicates. Results are presented in a tibble, ordered by the
number of duplicates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicate_count_colpair(
  data,
  ignore = NULL,
  show_rates = TRUE,
  na.rm = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicate_count_colpair_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="duplicate_count_colpair_+3A_ignore">ignore</code></td>
<td>
<p>Optionally, a vector of values that should not be checked for
duplicates.</p>
</td></tr>
<tr><td><code id="duplicate_count_colpair_+3A_show_rates">show_rates</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), adds columns <code>rate_x</code> and
<code>rate_y</code>. See value section. Set <code>show_rates</code> to <code>FALSE</code> for higher
performance.</p>
</td></tr>
<tr><td><code id="duplicate_count_colpair_+3A_na.rm">na.rm</code></td>
<td>
<p>[<a href="base.html#topic+Deprecated">Deprecated</a>] Missing values are never counted in any case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble (data frame) with these columns –
</p>

<ul>
<li> <p><code>x</code> and <code>y</code>: Each line contains a unique combination of <code>data</code>'s columns,
stored in the <code>x</code> and <code>y</code> output columns.
</p>
</li>
<li> <p><code>count</code>: Number of &quot;duplicates&quot;, i.e., values that are present in both <code>x</code>
and <code>y</code>.
</p>
</li>
<li> <p><code>total_x</code>, <code>total_y</code>, <code>rate_x</code>, and <code>rate_y</code> (added by default): <code>total_x</code>
is the number of non-missing values in the column named under <code>x</code>. Also,
<code>rate_x</code> is the proportion of <code>x</code> values that are duplicated in <code>y</code>, i.e.,
<code>count / total_x</code>. Likewise with <code>total_y</code> and <code>rate_y</code>. The two <code style="white-space: pre;">&#8288;rate_*&#8288;</code>
columns will be equal unless <code>NA</code> values are present.
</p>
</li></ul>



<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for <code><a href="#topic+audit">audit()</a></code>,
so you can call <code><a href="#topic+audit">audit()</a></code> following <code>duplicate_count_colpair()</code>. It
returns a tibble with summary statistics.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+duplicate_count">duplicate_count()</a></code> for a frequency table.
</p>
</li>
<li> <p><code><a href="#topic+duplicate_tally">duplicate_tally()</a></code> to show instances of a value next to each instance.
</p>
</li>
<li> <p><code><a href="janitor.html#topic+get_dupes">janitor::get_dupes()</a></code> to search for duplicate rows.
</p>
</li>
<li> <p><code><a href="corrr.html#topic+colpair_map">corrr::colpair_map()</a></code>, a versatile tool for pairwise column analysis which
the present function wraps.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Basic usage:
mtcars %&gt;%
  duplicate_count_colpair()

# Summaries with `audit()`:
mtcars %&gt;%
  duplicate_count_colpair() %&gt;%
  audit()
</code></pre>

<hr>
<h2 id='duplicate_detect'>Detect duplicate values</h2><span id='topic+duplicate_detect'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#superseded"><img src="../help/figures/lifecycle-superseded.svg" alt='[Superseded]' /></a>
</p>
<p><code>duplicate_detect()</code> is superseded because it's less informative than
<code><a href="#topic+duplicate_tally">duplicate_tally()</a></code> and <code><a href="#topic+duplicate_count">duplicate_count()</a></code>. Use these functions
instead.
</p>
<p>For every value in a vector or data frame, <code>duplicate_detect()</code> tests
whether there is at least one identical value. Test results are presented
next to every value.
</p>
<p>This function is a blunt tool designed for initial data checking. Don't put
too much weight on its results.
</p>
<p>For summary statistics, call <code><a href="#topic+audit">audit()</a></code> on the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicate_detect(x, ignore = NULL, colname_end = "dup", numeric_only)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicate_detect_+3A_x">x</code></td>
<td>
<p>Vector or data frame.</p>
</td></tr>
<tr><td><code id="duplicate_detect_+3A_ignore">ignore</code></td>
<td>
<p>Optionally, a vector of values that should not be checked. In
the test result columns, they will be marked <code>NA</code>.</p>
</td></tr>
<tr><td><code id="duplicate_detect_+3A_colname_end">colname_end</code></td>
<td>
<p>String. Name ending of the logical test result columns.
Default is <code>"dup"</code>.</p>
</td></tr>
<tr><td><code id="duplicate_detect_+3A_numeric_only">numeric_only</code></td>
<td>
<p>[<a href="base.html#topic+Deprecated">Deprecated</a>] No longer used: All values are coerced to
character.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is not very informative with many input values that
only have a few characters each. Many of them may have duplicates just by
chance. For example, in R's built-in <code>iris</code> data set, 99% of values have
duplicates.
</p>
<p>In general, the fewer values and the more characters per value, the more
significant the results.
</p>


<h3>Value</h3>

<p>A tibble (data frame). It has all the columns from <code>x</code>, and to each
of these columns' right, the corresponding test result column.
</p>
<p>The tibble has the <code>scr_dup_detect</code> class, which is recognized by the
<code>audit()</code> generic.
</p>


<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for the
<code><a href="#topic+audit">audit()</a></code> generic, so you can call <code><a href="#topic+audit">audit()</a></code> following
<code>duplicate_detect()</code>. It returns a tibble with these columns &mdash;
</p>

<ul>
<li> <p><code>term</code>: The original data frame's variables.
</p>
</li>
<li> <p><code>dup_count</code>: Number of &quot;duplicated&quot; values of that <code>term</code> variable: those
which have at least one duplicate anywhere in the data frame.
</p>
</li>
<li> <p><code>total</code>: Number of all non-<code>NA</code> values of that <code>term</code> variable.
</p>
</li>
<li> <p><code>dup_rate</code>: Rate of &quot;duplicated&quot; values of that <code>term</code> variable.
</p>
</li></ul>

<p>The final row, <code>.total</code>, summarizes across all other rows: It adds up the
<code>dup_count</code> and <code>total_count</code> columns, and calculates the mean of the
<code>dup_rate</code> column.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+duplicate_tally">duplicate_tally()</a></code> to count instances of a value instead of just
stating whether it is duplicated.
</p>
</li>
<li> <p><code><a href="#topic+duplicate_count">duplicate_count()</a></code> for a frequency table.
</p>
</li>
<li> <p><code><a href="#topic+duplicate_count_colpair">duplicate_count_colpair()</a></code> to check each combination of columns for
duplicates.
</p>
</li>
<li> <p><code><a href="janitor.html#topic+get_dupes">janitor::get_dupes()</a></code> to search for duplicate rows.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Find duplicate values in a data frame...
duplicate_detect(x = pigs4)

# ...or in a single vector:
duplicate_detect(x = pigs4$snout)

# Summary statistics with `audit()`:
pigs4 %&gt;%
  duplicate_detect() %&gt;%
  audit()

# Any values can be ignored:
pigs4 %&gt;%
  duplicate_detect(ignore = c(8.131, 7.574))
</code></pre>

<hr>
<h2 id='duplicate_tally'>Count duplicates at each observation</h2><span id='topic+duplicate_tally'></span>

<h3>Description</h3>

<p>For every value in a vector or data frame, <code>duplicate_tally()</code>
counts how often it appears in total. Tallies are presented next to each
value.
</p>
<p>For summary statistics, call <code><a href="#topic+audit">audit()</a></code> on the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplicate_tally(x, ignore = NULL, colname_end = "n")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplicate_tally_+3A_x">x</code></td>
<td>
<p>Vector or data frame.</p>
</td></tr>
<tr><td><code id="duplicate_tally_+3A_ignore">ignore</code></td>
<td>
<p>Optionally, a vector of values that should not be checked. In
the test result columns, they will be marked <code>NA</code>.</p>
</td></tr>
<tr><td><code id="duplicate_tally_+3A_colname_end">colname_end</code></td>
<td>
<p>String. Name ending of the logical test result columns.
Default is <code>"n"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is not very informative with many input values that
only have a few characters each. Many of them may have duplicates just by
chance. For example, in R's built-in <code>iris</code> data set, 99% of values have
duplicates.
</p>
<p>In general, the fewer values and the more characters per value, the more
significant the results.
</p>


<h3>Value</h3>

<p>A tibble (data frame). It has all the columns from <code>x</code>, and to each
of these columns' right, the corresponding tally column.
</p>
<p>The tibble has the <code>scr_dup_detect</code> class, which is recognized by the
<code>audit()</code> generic.
</p>


<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for the <code><a href="#topic+audit">audit()</a></code>
generic, so you can call <code><a href="#topic+audit">audit()</a></code> following <code>duplicate_tally()</code>. It
returns a tibble with summary statistics.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+duplicate_count">duplicate_count()</a></code> for a frequency table.
</p>
</li>
<li> <p><code><a href="#topic+duplicate_count_colpair">duplicate_count_colpair()</a></code> to check each combination of columns for
duplicates.
</p>
</li>
<li> <p><code><a href="janitor.html#topic+get_dupes">janitor::get_dupes()</a></code> to search for duplicate rows.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Tally duplicate values in a data frame...
duplicate_tally(x = pigs4)

# ...or in a single vector:
duplicate_tally(x = pigs4$snout)

# Summary statistics with `audit()`:
pigs4 %&gt;%
  duplicate_tally() %&gt;%
  audit()

# Any values can be ignored:
pigs4 %&gt;%
  duplicate_tally(ignore = c(8.131, 7.574))
</code></pre>

<hr>
<h2 id='fractional-rounding'>Generalized rounding to the nearest fraction of a specified denominator</h2><span id='topic+fractional-rounding'></span><span id='topic+reround_to_fraction'></span><span id='topic+reround_to_fraction_level'></span>

<h3>Description</h3>

<p>Two functions that round numbers to specific fractions, not just
to the next higher decimal level. They are inspired by
<code><a href="janitor.html#topic+round_to_fraction">janitor::round_to_fraction()</a></code> but feature all the options of
<code><a href="#topic+reround">reround()</a></code>:
</p>

<ul>
<li> <p><code>reround_to_fraction()</code> closely follows <code><a href="janitor.html#topic+round_to_fraction">janitor::round_to_fraction()</a></code>
by first rounding to fractions of a whole number, then optionally rounding
the result to a specific number of digits in the usual way.
</p>
</li>
<li> <p><code>reround_to_fraction_level()</code> rounds to the nearest fraction of a number
at the specific decimal level (i.e., number of digits), without subsequent
rounding. This is closer to conventional rounding functions.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>reround_to_fraction(
  x = NULL,
  denominator = 1,
  digits = Inf,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE
)

reround_to_fraction_level(
  x = NULL,
  denominator = 1,
  digits = 0L,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fractional-rounding_+3A_x">x</code></td>
<td>
<p>Numeric. Vector of numbers to be rounded.</p>
</td></tr>
<tr><td><code id="fractional-rounding_+3A_denominator">denominator</code></td>
<td>
<p>Numeric (&gt;= 1) . <code>x</code> will be rounded to the nearest
fraction of <code>denominator</code>. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="fractional-rounding_+3A_digits">digits</code></td>
<td>
<p>Numeric (whole numbers).
</p>

<ul>
<li><p> In <code>reround_to_fraction()</code>: If <code>digits</code> is specified, the values
resulting from fractional rounding will subsequently be rounded to that
many decimal places. If set to <code>"auto"</code>, it internally becomes
<code>ceiling(log10(denominator)) + 1</code>, as in <code><a href="janitor.html#topic+round_to_fraction">janitor::round_to_fraction()</a></code>.
Default is <code>Inf</code>, in which case there is no subsequent rounding.
</p>
</li>
<li><p> In <code>reround_to_fraction_level()</code>: This function will round to a fraction
of the number at the decimal level specified by <code>digits</code>. Default is <code>0</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fractional-rounding_+3A_rounding">rounding</code>, <code id="fractional-rounding_+3A_threshold">threshold</code>, <code id="fractional-rounding_+3A_symmetric">symmetric</code></td>
<td>
<p>More arguments passed down to
<code><a href="#topic+reround">reround()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector of the same length as <code>x</code> unless <code>rounding</code> is either
of <code>"up_or_down"</code>, <code>"up_from_or_down_from"</code>, and <code>"ceiling_or_floor"</code>. In
these cases, it will always have length 2.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reround">reround()</a></code>, which the functions wrap, and
<code><a href="janitor.html#topic+round_to_fraction">janitor::round_to_fraction()</a></code>, part of which they copy.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#`reround_to_fraction()` rounds `0.4`
# to `0` if `denominator` is `1`, which
# is the usual integer rounding...
reround_to_fraction(0.4, denominator = 1, rounding = "even")

# ...but if `denominator` is `2`, it rounds to the nearest
# fraction of 2, which is `0.5`:
reround_to_fraction(0.4, denominator = 2, rounding = "even")

# Likewise with fractions of 3:
reround_to_fraction(0.25, denominator = 3, rounding = "even")

# The default for `rounding` is to round
# both up and down, as in `reround()`:
reround_to_fraction(0.4, denominator = 2)

# These two rounding procedures differ
# at the tie points:
reround_to_fraction(0.25, denominator = 2)

# `reround_to_fraction_level()`, in contrast,
# uses `digits` to determine some decimal level,
# and then rounds to the closest fraction at
# that level:
reround_to_fraction_level(0.12345, denominator = 2, digits = 0)
reround_to_fraction_level(0.12345, denominator = 2, digits = 1)
reround_to_fraction_level(0.12345, denominator = 2, digits = 2)
</code></pre>

<hr>
<h2 id='function_map'>Create new <code style="white-space: pre;">&#8288;*_map()&#8288;</code> functions</h2><span id='topic+function_map'></span>

<h3>Description</h3>

<p><code>function_map()</code> creates new basic mapper functions for
consistency tests, such as <code><a href="#topic+grim_map">grim_map()</a></code> or <code><a href="#topic+debit_map">debit_map()</a></code>.
</p>
<p>For context, see <a href="https://lhdjung.github.io/scrutiny/articles/consistency-tests.html#creating-basic-mappers-with-function_map"><em>Creating basic mappers with <code>function_map()</code></em></a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>function_map(
  .fun,
  .reported,
  .name_test,
  .name_key_result = "consistency",
  .name_class = NULL,
  .args_disabled = NULL,
  .col_names = NULL,
  .col_control = NULL,
  .col_filler = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="function_map_+3A_.fun">.fun</code></td>
<td>
<p>Single-case consistency testing function that will be applied to
each row in a data frame. The function must return a single logical value,
i.e., <code>TRUE</code>, <code>FALSE</code>, or <code>NA</code>.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.reported">.reported</code></td>
<td>
<p>String. Names of the columns to be tested.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.name_test">.name_test</code></td>
<td>
<p>String (length 1). Plain-text name of the consistency test,
such as <code>"GRIM"</code>.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.name_key_result">.name_key_result</code></td>
<td>
<p>(Experimental) Optionally, a single string that will
be the name of the key result column in the output. Default is
<code>"consistency"</code>.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.name_class">.name_class</code></td>
<td>
<p>String. Optionally, one or more classes to be added to the
output data frame. Default is <code>NULL</code>, i.e., no extra class (but see
<em>Details</em>).</p>
</td></tr>
<tr><td><code id="function_map_+3A_.args_disabled">.args_disabled</code></td>
<td>
<p>Optionally, a string vector with names of arguments of
the <code style="white-space: pre;">&#8288;*_scalar()&#8288;</code> function that don't work with the factory-made function.
If the user  tries to specify these arguments, an informative error will be
thrown.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.col_names">.col_names</code></td>
<td>
<p>(Experimental) Optionally, a string vector with the names
of additional columns that are derived from the <code style="white-space: pre;">&#8288;*_scalar()&#8288;</code> function.
Requires <code>.col_control</code> and <code>.col_filler</code> specifications.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.col_control">.col_control</code></td>
<td>
<p>(Experimental) Optionally, a single string with the name
of the <code style="white-space: pre;">&#8288;*_scalar()&#8288;</code> function's logical argument that controls if the
columns named in <code>.col_names</code> will be displayed.</p>
</td></tr>
<tr><td><code id="function_map_+3A_.col_filler">.col_filler</code></td>
<td>
<p>(Experimental) Optionally, a vector specifying the values
of <code>.col_names</code> columns in rows where the <code style="white-space: pre;">&#8288;*_scalar()&#8288;</code> function only
returned the <code>consistency</code> value.</p>
</td></tr>
<tr><td><code id="function_map_+3A_...">...</code></td>
<td>
<p>These dots must be empty.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output tibble returned by the factory-made function will inherit
one or two classes independently of the <code>.name_class</code> argument:
</p>

<ul>
<li><p> It will inherit a class named <code>"scr_{tolower(.name_test)}_map"</code>; for
example, the class is <code>"scr_grim_map"</code> if <code>.name_test</code> is <code>"GRIM"</code>.
</p>
</li>
<li><p> If a <code>rounding</code> argument is specified via <code>...</code>, or else if <code>.fun</code> has a
<code>rounding</code> argument with a default, the output tibble will inherit a class
named <code>"scr_rounding_{rounding}"</code>; for example,
<code>"scr_rounding_up_or_down"</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A factory-made function with these arguments:
</p>

<ul>
<li> <p><code>data</code>: Data frame with all the columns named in <code>.reported</code>. It must
have columns named after the key arguments in <code>.fun</code>. Other columns are
permitted.
</p>
</li>
<li><p> Arguments named after the <code>.reported</code> values. They can be specified as the
names of <code>data</code> columns so that the function will rename that column using
the <code>.reported</code> name.
</p>
</li>
<li> <p><code>reported</code>, <code>fun</code>, <code>name_class</code>: Same as when calling <code>function_map()</code> but
spelled without dots. You can override these defaults when calling the
factory-made function.
</p>
</li>
<li> <p><code>...</code>: Arguments passed down to <code>.fun</code>. This does not include the
column-identifying arguments derived from <code>.reported</code>.
</p>
</li></ul>



<h3>Value returned by the factory-made function</h3>

<p>A tibble that includes
<code>"consistency"</code>: a logical column showing whether the values to its left
are mutually consistent (<code>TRUE</code>) or not (<code>FALSE</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Basic test implementation for "SCHLIM",
# a mock test with no real significance:
schlim_scalar &lt;- function(y, n) {
  (y / 3) &gt; n
}

# Let the function factory produce
# a mapper function for SCHLIM:
schlim_map &lt;- function_map(
  .fun = schlim_scalar,
  .reported = c("y", "n"),
  .name_test = "SCHLIM"
)

# Example data:
df1 &lt;- tibble::tibble(y = 16:25, n = 3:12)

# Call the "factory-made" function:
schlim_map(df1)
</code></pre>

<hr>
<h2 id='function_map_seq'>Create new <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> functions</h2><span id='topic+function_map_seq'></span>

<h3>Description</h3>

<p><code>function_map_seq()</code> is the engine that powers functions such as
<code><a href="#topic+grim_map_seq">grim_map_seq()</a></code>. It creates new, &quot;factory-made&quot; functions that apply
consistency tests such as GRIM or GRIMMER to sequences of specified
variables. The sequences are centered around the reported values of those
variables.
</p>
<p>By default, only inconsistent values are dispersed from and tested. This
provides an easy and powerful way to assess whether small errors in
computing or reporting may be responsible for inconsistencies in published
statistics.
</p>
<p>For background and more examples, see the
<a href="https://lhdjung.github.io/scrutiny/articles/consistency-tests.html#sequence-mapper">sequence
mapper section</a> of <em>Consistency tests in depth</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>function_map_seq(
  .fun,
  .var = Inf,
  .reported,
  .name_test,
  .name_key_result = "consistency",
  .name_class = NULL,
  .args_disabled = NULL,
  .dispersion = 1:5,
  .out_min = "auto",
  .out_max = NULL,
  .include_reported = FALSE,
  .include_consistent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="function_map_seq_+3A_.fun">.fun</code></td>
<td>
<p>Function such as <code>grim_map()</code>, or one made by <code><a href="#topic+function_map">function_map()</a></code>:
It will be used to test columns in a data frame for consistency. Test
results are logical and need to be contained in a column called
<code>"consistency"</code> that is added to the input data frame. This modified data
frame is then returned by <code>.fun</code>.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.var">.var</code></td>
<td>
<p>String. Variables that will be dispersed by the manufactured
function. Defaults to <code>.reported</code>.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.reported">.reported</code></td>
<td>
<p>String. All variables the manufactured function can disperse
in principle.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.name_test">.name_test</code></td>
<td>
<p>String (length 1). The name of the consistency test, such
as <code>"GRIM"</code>, to be optionally shown in a message when using the
manufactured function.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.name_key_result">.name_key_result</code></td>
<td>
<p>(Experimental) Optionally, a single string that will
be the name of the key result column in the output. Default is
<code>"consistency"</code>.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.name_class">.name_class</code></td>
<td>
<p>String. If specified, the tibbles returned by the
manufactured function will inherit this string as an S3 class. Default is
<code>NULL</code>, i.e., no extra class.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.args_disabled">.args_disabled</code></td>
<td>
<p>String. Optionally, names of the basic <code style="white-space: pre;">&#8288;*_map()&#8288;</code>
function's arguments. These arguments will throw an error if specified when
calling the factory-made function.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.dispersion">.dispersion</code></td>
<td>
<p>Numeric. Sequence with steps up and down from the reported
values. It will be adjusted to these values' decimal level. For example,
with a reported <code>8.34</code>, the step size is <code>0.01</code>. Default is <code>1:5</code>, for five
steps up and down.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.out_min">.out_min</code>, <code id="function_map_seq_+3A_.out_max">.out_max</code></td>
<td>
<p>If specified when calling a factory-made function,
output will be restricted so that it's not below <code>.out_min</code> or above
<code>.out_max</code>. Defaults are <code>"auto"</code> for <code>.out_min</code>, i.e., a minimum of one
decimal unit above zero; and <code>NULL</code> for <code>.out_max</code>, i.e., no maximum.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.include_reported">.include_reported</code></td>
<td>
<p>Logical. Should the reported values themselves be
included in the sequences originating from them? Default is <code>FALSE</code> because
this might be redundant and bias the results.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_.include_consistent">.include_consistent</code></td>
<td>
<p>Logical. Should the function also process
consistent cases (from among those reported), not just inconsistent ones?
Default is <code>FALSE</code> because the focus should be on clarifying
inconsistencies.</p>
</td></tr>
<tr><td><code id="function_map_seq_+3A_...">...</code></td>
<td>
<p>These dots must be empty.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All arguments of <code>function_map_seq()</code> set the defaults for the
arguments in the manufactured function. They can still be specified
differently when calling the latter.
</p>
<p>If functions created this way are exported from other packages, they should
be written as if they were created with
<a href="https://purrr.tidyverse.org/reference/faq-adverbs-export.html">purrr
adverbs</a>; see explanations there, and examples in the
<a href="https://lhdjung.github.io/scrutiny/articles/consistency-tests.html#context-and-export">export
section</a> of <em>Consistency tests in depth</em>.
</p>
<p>This function is a so-called function factory: It produces other functions,
such as <code><a href="#topic+grim_map_seq">grim_map_seq()</a></code>. More specifically, it is a function operator
because it also takes functions as inputs, such as <code><a href="#topic+grim_map">grim_map()</a></code>. See
Wickham (2019, ch. 10-11).
</p>


<h3>Value</h3>

<p>A function such as those below. (&quot;Testable statistics&quot; are variables
that can be selected via <code>var</code>, and are then varied. All variables except
for those in parentheses are selected by default.)</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Manufactured function</strong> </td><td style="text-align: left;"> <strong>Testable statistics</strong> </td><td style="text-align: left;"> <strong>Test vignette</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+grim_map_seq">grim_map_seq()</a></code> </td><td style="text-align: left;"> <code>"x"</code>, <code>"n"</code>, (<code>"items"</code>) </td><td style="text-align: left;"> <code>vignette("grim")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+grimmer_map_seq">grimmer_map_seq()</a></code> </td><td style="text-align: left;"> <code>"x"</code>, <code>"sd"</code>, <code>"n"</code>, (<code>"items"</code>) </td><td style="text-align: left;"> <code>vignette("grimmer")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+debit_map_seq">debit_map_seq()</a></code> </td><td style="text-align: left;"> <code>"x"</code>, <code>"sd"</code>, <code>"n"</code> </td><td style="text-align: left;"> <code>vignette("debit")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The factory-made function will also have dots, <code>...</code>, to pass arguments
down to <code>.fun</code>, i.e., the basic mapper function such as <code>grim_map()</code>.
</p>


<h3>Conventions</h3>

<p>The name of a function returned by
<code>function_map_seq()</code> should mechanically follow from that of
the input function. For example, <code><a href="#topic+grim_map_seq">grim_map_seq()</a></code> derives
from <code><a href="#topic+grim_map">grim_map()</a></code>. This pattern fits best if the input function itself
is named after the test it performs on a data frame, followed by <code style="white-space: pre;">&#8288;_map&#8288;</code>:
<code><a href="#topic+grim_map">grim_map()</a></code> applies GRIM, <code><a href="#topic+grimmer_map">grimmer_map()</a></code> applies GRIMMER, etc.
</p>
<p>Much the same is true for the classes of data frames returned by the
manufactured function via the <code>.name_class</code> argument of
<code>function_map_seq()</code>. It should be the function's own name preceded
by the name of the package that contains it, or by an acronym of that
package's name. Therefore, some existing classes are
<code>scr_grim_map_seq</code> and <code>scr_grimmer_map_seq</code>.
</p>


<h3>References</h3>

<p>Wickham, H. (2019). <em>Advanced R</em> (Second Edition). CRC
Press/Taylor and Francis Group. https://adv-r.hadley.nz/index.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Function definition of `grim_map_seq()`:
grim_map_seq &lt;- function_map_seq(
  .fun = grim_map,
  .reported = c("x", "n"),
  .name_test = "GRIM",
)
</code></pre>

<hr>
<h2 id='function_map_total_n'>Create new <code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> functions</h2><span id='topic+function_map_total_n'></span>

<h3>Description</h3>

<p><code>function_map_total_n()</code> is the engine that powers functions
such as <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code>. It creates new, &quot;factory-made&quot; functions
for consistency tests such as GRIM or GRIMMER. The new functions take
reported summary statistics (e.g., means) and apply those tests in cases
where only a total sample size is known, not group sizes.
</p>
<p>This works by making <code><a href="#topic+disperse_total">disperse_total()</a></code> create multiple pairs of
hypothetical group sizes, all of which add up to the reported total. There
need to be exactly two groups.
</p>
<p>For background and more examples, see the
<a href="https://lhdjung.github.io/scrutiny/articles/consistency-tests.html#total-n-mapper">total-n
mapper section</a> of <em>Consistency tests in depth</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>function_map_total_n(
  .fun,
  .reported,
  .name_test,
  .name_key_result = "consistency",
  .name_class = NULL,
  .dispersion = 0:5,
  .n_min = 1L,
  .n_max = NULL,
  .constant = NULL,
  .constant_index = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="function_map_total_n_+3A_.fun">.fun</code></td>
<td>
<p>Function such as <code><a href="#topic+grim_map">grim_map()</a></code>, or one made by
<code><a href="#topic+function_map">function_map()</a></code>: It will be used to test columns in a data frame for
consistency. Test results are logical and need to be contained in a column
called <code>consistency</code> that is added to the input data frame. This modified
data frame is then returned by <code>.fun</code>.</p>
</td></tr>
<tr><td><code id="function_map_total_n_+3A_.reported">.reported</code></td>
<td>
<p>String. Names of the columns containing group-specific
statistics that were reported alongside the total sample size(s). They will
be tested for consistency with the hypothetical group sizes. Examples are
<code>"x"</code> for GRIM and <code>c("x", "sd")</code> for DEBIT. In the data frame with
reported group statistics that the manufactured function takes as an input,
each will need to fan out like <code>"x1"</code>, <code>"x2"</code>, <code>"sd1"</code>, and <code>"sd2"</code>.</p>
</td></tr>
<tr><td><code id="function_map_total_n_+3A_.name_test">.name_test</code></td>
<td>
<p>String (length 1). The name of the consistency test, such
as <code>"GRIM"</code>, to be optionally shown in a message when using the
manufactured function.</p>
</td></tr>
<tr><td><code id="function_map_total_n_+3A_.name_key_result">.name_key_result</code></td>
<td>
<p>(Experimental) Optionally, a single string that will
be the name of the key result column in the output. Default is
<code>"consistency"</code>.</p>
</td></tr>
<tr><td><code id="function_map_total_n_+3A_.name_class">.name_class</code></td>
<td>
<p>String. If specified, the tibbles returned by the
manufactured function will inherit this string as an S3 class. Default is
<code>NULL</code>, i.e., no extra class.</p>
</td></tr>
<tr><td><code id="function_map_total_n_+3A_.dispersion">.dispersion</code>, <code id="function_map_total_n_+3A_.n_min">.n_min</code>, <code id="function_map_total_n_+3A_.n_max">.n_max</code>, <code id="function_map_total_n_+3A_.constant">.constant</code>, <code id="function_map_total_n_+3A_.constant_index">.constant_index</code></td>
<td>
<p>Arguments passed
down to <code><a href="#topic+disperse_total">disperse_total()</a></code>, using defaults from there.</p>
</td></tr>
<tr><td><code id="function_map_total_n_+3A_...">...</code></td>
<td>
<p>These dots must be empty.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If functions created by <code>function_map_total_n()</code> are exported from
other packages, they should be written as if they were created with
<a href="https://purrr.tidyverse.org/reference/faq-adverbs-export.html">purrr
adverbs</a>; see explanations there, and examples in the
<a href="https://lhdjung.github.io/scrutiny/articles/consistency-tests.html#context-and-export">export
section</a> of <em>Consistency tests in depth</em>.
</p>
<p>This function is a so-called function factory: It produces other functions,
such as <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code>. More specifically, it is a function
operator because it also takes functions as inputs, such as <code><a href="#topic+grim_map">grim_map()</a></code>.
See Wickham (2019), ch. 10-11.
</p>


<h3>Value</h3>

<p>A function such as these:</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Manufactured function</strong> </td><td style="text-align: left;"> <strong>Reported statistics</strong> </td><td style="text-align: left;"> <strong>Test vignette</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code> </td><td style="text-align: left;"> <code>"x"</code> </td><td style="text-align: left;"> <code>vignette("grim")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+grimmer_map_total_n">grimmer_map_total_n()</a></code> </td><td style="text-align: left;"> <code>"x"</code>, <code>"sd"</code> </td><td style="text-align: left;"> <code>vignette("grimmer")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code><a href="#topic+debit_map_total_n">debit_map_total_n()</a></code> </td><td style="text-align: left;"> <code>"x"</code>, <code>"sd"</code> </td><td style="text-align: left;"> <code>vignette("debit")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The factory-made function will also have dots, <code>...</code>, to pass arguments
down to <code>.fun</code>, i.e., the basic mapper function.
</p>


<h3>Conventions</h3>

<p>The name of a function returned by
<code>function_map_total_n()</code> should mechanically follow from that of
the input function. For example, <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code> derives
from <code><a href="#topic+grim_map">grim_map()</a></code>. This pattern fits best if the input function itself
is named after the test it performs on a data frame, followed by <code style="white-space: pre;">&#8288;_map&#8288;</code>:
<code><a href="#topic+grim_map">grim_map()</a></code> applies GRIM, <code><a href="#topic+grimmer_map">grimmer_map()</a></code> applies GRIMMER, etc.
</p>
<p>Much the same is true for the classes of data frames returned by the
manufactured function via the <code>.name_class</code> argument of
<code>function_map_total_n()</code>. It should be the function's own name preceded
by the name of the package that contains it, or by an acronym of that
package's name. Therefore, some existing classes are
<code>scr_grim_map_total_n</code> and <code>scr_grimmer_map_total_n</code>.
</p>


<h3>References</h3>

<p>Bauer, P. J., &amp; Francis, G. (2021). Expression of Concern: Is It
Light or Dark? Recalling Moral Behavior Changes Perception of Brightness.
<em>Psychological Science</em>, 32(12), 2042–2043.
https://journals.sagepub.com/doi/10.1177/09567976211058727
</p>
<p>Wickham, H. (2019). <em>Advanced R</em> (Second Edition). CRC Press/Taylor and
Francis Group. https://adv-r.hadley.nz/index.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+function_map_seq">function_map_seq()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Function definition of `grim_map_total_n()`:
grim_map_total_n &lt;- function_map_total_n(
  .fun = grim_map,
  .reported = "x",
  .name_test = "GRIM"
)
</code></pre>

<hr>
<h2 id='grim'>The GRIM test (granularity-related inconsistency of means)</h2><span id='topic+grim'></span>

<h3>Description</h3>

<p><code>grim()</code> checks if a reported mean value of integer data is
mathematically consistent with the reported sample size and the number of
items that compose the mean value.
</p>
<p>Set <code>percent</code> to <code>TRUE</code> if <code>x</code> is a percentage. This will convert <code>x</code> to a
decimal number and adjust the decimal count accordingly.
</p>
<p>The function is vectorized, but it is recommended to use <code><a href="#topic+grim_map">grim_map()</a></code> for
testing multiple cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim(
  x,
  n,
  items = 1,
  percent = FALSE,
  show_rec = FALSE,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE,
  tolerance = .Machine$double.eps^0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim_+3A_x">x</code></td>
<td>
<p>String. The reported mean or percentage value.</p>
</td></tr>
<tr><td><code id="grim_+3A_n">n</code></td>
<td>
<p>Integer. The reported sample size.</p>
</td></tr>
<tr><td><code id="grim_+3A_items">items</code></td>
<td>
<p>Numeric. The number of items composing <code>x</code>. Default is 1, the
most common case.</p>
</td></tr>
<tr><td><code id="grim_+3A_percent">percent</code></td>
<td>
<p>Logical. Set <code>percent</code> to <code>TRUE</code> if <code>x</code> is a percentage. This
will convert it to a decimal number and adjust the decimal count (i.e.,
increase it by 2). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_+3A_show_rec">show_rec</code></td>
<td>
<p>Logical. For internal use only. If set to <code>TRUE</code>, the output
is a matrix that also contains intermediary values from GRIM-testing. Don't
specify this manually; instead, use <code>show_rec</code> in <code><a href="#topic+grim_map">grim_map()</a></code>. Default
is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_+3A_rounding">rounding</code></td>
<td>
<p>String. Rounding method or methods to be used for
reconstructing the values to which <code>x</code> will be compared. Default is
<code>"up_or_down"</code> (from 5).</p>
</td></tr>
<tr><td><code id="grim_+3A_threshold">threshold</code></td>
<td>
<p>Numeric. If <code>rounding</code> is set to <code>"up_from"</code>, <code>"down_from"</code>,
or <code>"up_from_or_down_from"</code>, set <code>threshold</code> to the number from which the
reconstructed values should then be rounded up or down. Otherwise, this
argument plays no role. Default is <code>5</code>.</p>
</td></tr>
<tr><td><code id="grim_+3A_symmetric">symmetric</code></td>
<td>
<p>Logical. Set <code>symmetric</code> to <code>TRUE</code> if the rounding of
negative numbers with <code>"up"</code>, <code>"down"</code>, <code>"up_from"</code>, or <code>"down_from"</code>
should mirror that of positive numbers so that their absolute values are
always equal. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_+3A_tolerance">tolerance</code></td>
<td>
<p>Numeric. Tolerance of comparison between <code>x</code> and the
possible mean or percentage values. Default is circa 0.000000015
(1.490116e-08), as in <code><a href="dplyr.html#topic+near">dplyr::near()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>x</code> values need to be strings because only strings retain
trailing zeros, which are as important for the GRIM test as any other
decimal digits.
</p>
<p>Use <code><a href="#topic+restore_zeros">restore_zeros()</a></code> on numeric values (or values that were numeric
values at some point) to easily supply the trailing zeros they might once
have had. See documentation there.
</p>
<p>Browse the source code in the grim.R file. <code>grim()</code> is a vectorized version
of the internal <code>grim_scalar()</code> function found there.
</p>


<h3>Value</h3>

<p>Logical. <code>TRUE</code> if <code>x</code>, <code>n</code>, and <code>items</code> are mutually consistent,
<code>FALSE</code> if not.
</p>


<h3>References</h3>

<p>Brown, N. J. L., &amp; Heathers, J. A. J. (2017). The GRIM Test: A
Simple Technique Detects Numerous Anomalies in the Reporting of Results in
Psychology. <em>Social Psychological and Personality Science</em>, 8(4), 363–369.
https://journals.sagepub.com/doi/10.1177/1948550616673876
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grim_map">grim_map()</a></code> applies <code>grim()</code> to any number of cases at once.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A mean of 5.19 is not consistent with a sample size of 28:
grim(x = "5.19", n = 28)    # `x` in quotes!

# However, it is consistent with a sample size of 32:
grim(x = "5.19", n = 32)

# For a scale composed of two items:
grim(x = "2.84", n = 16, items = 2)

# With percentages instead of means -- here, 71%:
grim(x = "71", n = 43, percent = TRUE)
</code></pre>

<hr>
<h2 id='grim_granularity'>Granularity of non-continuous scales</h2><span id='topic+grim_granularity'></span><span id='topic+grim_items'></span>

<h3>Description</h3>

<p><code>grim_granularity()</code> computes the minimal difference between two
means or proportions of ordinal or interval data.
</p>
<p><code>grim_items()</code> is the reverse: It converts granularity values to the number
of scale items, which might then be used for consistency testing functions
such as <code>grim()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim_granularity(n, items = 1)

grim_items(n, gran, tolerance = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim_granularity_+3A_n">n</code></td>
<td>
<p>Numeric. Sample size.</p>
</td></tr>
<tr><td><code id="grim_granularity_+3A_items">items</code></td>
<td>
<p>Numeric. Number of items composing the scale. Default is 1,
which will hold for most non-Likert scales.</p>
</td></tr>
<tr><td><code id="grim_granularity_+3A_gran">gran</code></td>
<td>
<p>Numeric. Granularity.</p>
</td></tr>
<tr><td><code id="grim_granularity_+3A_tolerance">tolerance</code></td>
<td>
<p>Numeric. In <code>grim_items()</code>, <code>tolerance</code> is the maximal
amount by which results may differ from being whole numbers. If they exceed
that amount, a warning will be shown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These two functions differ only in the names of their arguments &mdash;
the underlying formula is the same (and it's very simple). However, for
clarity, they are presented as distinct.
</p>
<p>The output of <code>grim_items()</code> should be whole numbers, because scale items
have a granularity of 1. If they differ from the next whole number by more
than a numeric <code>tolerance</code> (which is determined by the argument by that
name), a warning will be shown.
</p>
<p>It would be wrong to determine a scale's granularity from the minimal
distance between two values in a given distribution. This would only
signify how those values actually do differ, not how they <em>can</em> differ <em>a
priori</em> based on scale design. Also, keep in mind that continuous scales
have no granularity at all.
</p>


<h3>Value</h3>

<p>Numeric. Granularity or number of items.
</p>


<h3>References</h3>

<p>Brown, N. J. L., &amp; Heathers, J. A. J. (2017). The GRIM Test: A
Simple Technique Detects Numerous Anomalies in the Reporting of Results in
Psychology. <em>Social Psychological and Personality Science</em>, 8(4), 363–369.
https://journals.sagepub.com/doi/10.1177/1948550616673876
</p>


<h3>Examples</h3>

<pre><code class='language-R'># If a non-Likert scale ranges from 0 to 3
# and measures 16 cases:
grim_granularity(n = 16)   # `items = 1` by default

# Same but Likert scale with 2 items:
grim_granularity(n = 16, items = 2)

# If a scale is applied to a single case
# and has a granularity of 0.5:
grim_items(n = 1, gran = 0.5)

# With more cases, a warning appears
# because items can only be whole numbers:
grim_items(n = c(10, 15, 20), gran = 0.5)
</code></pre>

<hr>
<h2 id='grim_map'>GRIM-test many cases at once</h2><span id='topic+grim_map'></span>

<h3>Description</h3>

<p>Call <code>grim_map()</code> to GRIM-test any number of combinations of
mean/proportion, sample size, and number of items. Mapping function for
GRIM-testing.
</p>
<p>Set <code>percent</code> to <code>TRUE</code> if the <code>x</code> values are percentages. This will
convert <code>x</code> values to decimals and adjust the decimal count accordingly.
</p>
<p>Display intermediary numbers from GRIM-testing in columns by setting
<code>show_rec</code> to <code>TRUE</code>.
</p>
<p>For summary statistics, call <code style="white-space: pre;">&#8288;[audit()&#8288;</code>] on the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim_map(
  data,
  items = 1,
  merge_items = TRUE,
  percent = FALSE,
  x = NULL,
  n = NULL,
  show_rec = FALSE,
  show_prob = FALSE,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE,
  tolerance = .Machine$double.eps^0.5,
  testables_only = FALSE,
  extra = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim_map_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>x</code>, <code>n</code>, and optionally <code>items</code> (see
documentation for <code><a href="#topic+grim">grim()</a></code>. By default, any other columns in <code>data</code> will
be returned alongside GRIM test results (see <code>extra</code> below).</p>
</td></tr>
<tr><td><code id="grim_map_+3A_items">items</code></td>
<td>
<p>Integer. If there is no <code>items</code> column in <code>data</code>, this specifies
the number of items composing the <code>x</code> values. Default is 1, the most common
case.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_merge_items">merge_items</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), there will be no <code>items</code>
column in the output. Instead, values from an <code>items</code> column or argument
will be multiplied with values in the <code>n</code> column. This does not affect
GRIM-testing.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_percent">percent</code></td>
<td>
<p>Logical. Set <code>percent</code> to <code>TRUE</code> if the <code>x</code> values are
percentages. This will convert them to decimal numbers and adjust the
decimal count (i.e., increase it by 2). It also affects the <code>ratio</code> column.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_x">x</code>, <code id="grim_map_+3A_n">n</code></td>
<td>
<p>Optionally, specify these arguments as column names in <code>data</code>.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_show_rec">show_rec</code></td>
<td>
<p>Logical. If set to <code>TRUE</code>, the reconstructed numbers from
GRIM-testing are shown as columns. See section <em>Reconstructed numbers</em>
below. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_show_prob">show_prob</code></td>
<td>
<p>Logical. If set to <code>TRUE</code>, adds a <code>prob</code> column that
contains the probability of GRIM inconsistency. This is simply the <code>ratio</code>
column censored to range between 0 and 1. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_rounding">rounding</code>, <code id="grim_map_+3A_threshold">threshold</code>, <code id="grim_map_+3A_symmetric">symmetric</code>, <code id="grim_map_+3A_tolerance">tolerance</code></td>
<td>
<p>Further parameters of
GRIM-testing; see documentation for <code><a href="#topic+grim">grim()</a></code>.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_testables_only">testables_only</code></td>
<td>
<p>Logical. If <code>testables_only</code> is set to <code>TRUE</code>, only
GRIM-testable cases (i.e., those with a positive GRIM ratio) are included.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grim_map_+3A_extra">extra</code></td>
<td>
<p>String or integer. The other column(s) from <code>data</code> to be
returned in the output tibble alongside test results, referenced by their
name(s) or number(s). Default is <code>Inf</code>, which returns all columns. To
return none of them, set <code>extra</code> to 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with these columns &ndash;
</p>

<ul>
<li> <p><code>x</code>, <code>n</code>: the inputs.
</p>
</li>
<li> <p><code>consistency</code>: GRIM consistency of <code>x</code>, <code>n</code>, and <code>items</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;extra&gt;&#8288;</code>: any columns from <code>data</code> other than <code>x</code>, <code>n</code>, and <code>items</code>.
</p>
</li>
<li> <p><code>ratio</code>: the GRIM ratio; see <code><a href="#topic+grim_ratio">grim_ratio()</a></code>.
</p>
<p>The tibble has the <code>scr_grim_map</code> class, which is recognized by the
<code><a href="#topic+audit">audit()</a></code> generic.
</p>
</li></ul>



<h3>Reconstructed numbers</h3>

<p>If <code>show_rec</code> is set to <code>TRUE</code>, the output
includes the following additional columns:
</p>

<ul>
<li> <p><code>rec_sum</code>: the sum total from which the mean or proportion was ostensibly
derived.
</p>
</li>
<li> <p><code>rec_x_upper</code>: the upper reconstructed <code>x</code> value.
</p>
</li>
<li> <p><code>rec_x_lower</code>: the lower reconstructed <code>x</code> value.
</p>
</li>
<li> <p><code>rec_x_upper_rounded</code>: the rounded <code>rec_x_upper</code> value.
</p>
</li>
<li> <p><code>rec_x_lower_rounded</code>: the rounded <code>rec_x_lower</code> value.
</p>
</li></ul>

<p>With the default for <code>rounding</code>, <code>"up_or_down"</code>, each of the last two columns
is replaced by two columns that specify the rounding procedures (i.e.,
<code>"_up"</code> and <code>"_down"</code>).
</p>


<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for <code><a href="#topic+audit">audit()</a></code>,
so you can call <code><a href="#topic+audit">audit()</a></code> following <code>grim_map()</code> to get a summary of
<code>grim_map()</code>'s results. It is a tibble with one row and these columns &ndash;
</p>

<ol>
<li> <p><code>incons_cases</code>: number of GRIM-inconsistent value sets.
</p>
</li>
<li> <p><code>all_cases</code>: total number of value sets.
</p>
</li>
<li> <p><code>incons_rate</code>: proportion of GRIM-inconsistent value sets.
</p>
</li>
<li> <p><code>mean_grim_ratio</code>: average of GRIM ratios.
</p>
</li>
<li> <p><code>incons_to_ratio</code>: ratio of <code>incons_rate</code> to <code>mean_grim_ratio</code>.
</p>
</li>
<li> <p><code>testable_cases</code>: number of GRIM-testable value sets (i.e., those with a
positive ratio).
</p>
</li>
<li> <p><code>testable_rate</code>: proportion of GRIM-testable value sets.
</p>
</li></ol>



<h3>References</h3>

<p>Brown, N. J. L., &amp; Heathers, J. A. J. (2017). The GRIM Test: A
Simple Technique Detects Numerous Anomalies in the Reporting of Results in
Psychology. <em>Social Psychological and Personality Science</em>, 8(4), 363–369.
https://journals.sagepub.com/doi/10.1177/1948550616673876
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use `grim_map()` on data like these:
pigs1

# The `consistency` column shows
# whether the values to its left
# are GRIM-consistent:
pigs1 %&gt;%
  grim_map()

# Display intermediary numbers from
# GRIM-testing with `show_rec = TRUE`:
pigs1 %&gt;%
  grim_map(show_rec = TRUE)

# Get summaries with `audit()`:
pigs1 %&gt;%
  grim_map() %&gt;%
  audit()
</code></pre>

<hr>
<h2 id='grim_map_seq'>GRIM-testing with dispersed inputs</h2><span id='topic+grim_map_seq'></span>

<h3>Description</h3>

<p><code>grim_map_seq()</code> performs GRIM-testing with values surrounding
the input values. This provides an easy and powerful way to assess whether
small errors in computing or reporting may be responsible for GRIM
inconsistencies in published statistics.
</p>
<p>Call <code><a href="#topic+audit_seq">audit_seq()</a></code> on the results for summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim_map_seq(
  data,
  x = NULL,
  n = NULL,
  var = Inf,
  dispersion = 1:5,
  out_min = "auto",
  out_max = NULL,
  include_reported = FALSE,
  include_consistent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim_map_seq_+3A_data">data</code></td>
<td>
<p>A data frame that <code>grim_map()</code> could take.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_x">x</code>, <code id="grim_map_seq_+3A_n">n</code></td>
<td>
<p>Optionally, specify these arguments as column names in <code>data</code>.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_var">var</code></td>
<td>
<p>String. Names of the columns that will be dispersed. Default is
<code>c("x", "n")</code>.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Sequence with steps up and down from the <code>var</code>
inputs. It will be adjusted to these values' decimal levels. For example,
with a reported <code>8.34</code>, the step size is <code>0.01</code>. Default is <code>1:5</code>, for five
steps up and down.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_out_min">out_min</code>, <code id="grim_map_seq_+3A_out_max">out_max</code></td>
<td>
<p>If specified, output will be restricted so that it's
not below <code>out_min</code> or above <code>out_max</code>. Defaults are <code>"auto"</code> for
<code>out_min</code>, i.e., a minimum of one decimal unit above zero; and <code>NULL</code> for
<code>out_max</code>, i.e., no maximum.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_include_reported">include_reported</code></td>
<td>
<p>Logical. Should the reported values themselves be
included in the sequences originating from them? Default is <code>FALSE</code> because
this might be redundant and bias the results.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_include_consistent">include_consistent</code></td>
<td>
<p>Logical. Should the function also process
consistent cases (from among those reported), not just inconsistent ones?
Default is <code>FALSE</code> because the focus should be on clarifying
inconsistencies.</p>
</td></tr>
<tr><td><code id="grim_map_seq_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code>grim_map()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble (data frame) with detailed test results.
</p>


<h3>Summaries with <code>audit_seq()</code></h3>

<p>You can call <code>audit_seq()</code> following
<code>grim_map_seq()</code>. It will return a data frame with these columns:
</p>

<ul>
<li> <p><code>x</code> and <code>n</code> are the original inputs,
tested for <code>consistency</code> here.
</p>
</li>
<li> <p><code>hits_total</code> is the total number of GRIM-consistent value sets
found within the specified <code>dispersion</code> range.
</p>
</li>
<li> <p><code>hits_x</code> is the number of GRIM-consistent value sets
found by varying <code>x</code>.
</p>
</li>
<li><p> Accordingly with <code>n</code> and <code>hits_n</code>.
</p>
</li>
<li><p> (Note that any consistent reported cases will be counted by the
<code style="white-space: pre;">&#8288;hits_*&#8288;</code> columns if both <code>include_reported</code> and <code>include_consistent</code>
are set to <code>TRUE</code>.)
</p>
</li>
<li> <p><code>diff_x</code> reports the absolute difference between <code>x</code> and the next
consistent dispersed value (in dispersion steps, not the actual numeric
difference). <code>diff_x_up</code> and <code>diff_x_down</code> report the difference to the
next higher or lower consistent value, respectively.
</p>
</li>
<li> <p><code>diff_n</code>, <code>diff_n_up</code>, and <code>diff_n_down</code> do the same for <code>n</code>.
</p>
</li></ul>

<p>Call <code>audit()</code> following <code>audit_seq()</code> to summarize results even further.
It's mostly self-explaining, but <code>na_count</code> and <code>na_rate</code> are the number
and rate of times that a difference could not be computed because of a lack
of corresponding hits within the <code>dispersion</code> range.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># `grim_map_seq()` can take any input
# that `grim_map()` can take:
pigs1

# All the results:
out &lt;- grim_map_seq(pigs1, include_consistent = TRUE)
out

# Case-wise summaries with `audit_seq()`
# can be more important than the raw results:
out %&gt;%
  audit_seq()
</code></pre>

<hr>
<h2 id='grim_map_total_n'>GRIM-testing with hypothetical group sizes</h2><span id='topic+grim_map_total_n'></span>

<h3>Description</h3>

<p>When reporting group means, some published studies only report
the total sample size but no group sizes corresponding to each mean.
However, group sizes are crucial for GRIM-testing.
</p>
<p>In the two-groups case, <code>grim_map_total_n()</code> helps in these ways:
</p>

<ul>
<li><p> It creates hypothetical group sizes. With an even total sample size, it
incrementally moves up and down from half the total sample size. For example,
with a total sample size of 40, it starts at 20, goes on to 19 and 21, then
to 18 and 22, etc. With odd sample sizes, it starts from the two integers
around half.
</p>
</li>
<li><p> It GRIM-tests all of these values together with the group means.
</p>
</li>
<li><p> It reports all the scenarios in which both &quot;dispersed&quot; hypothetical group
sizes are GRIM-consistent with the group means.
</p>
</li></ul>

<p>All of this works with one or more total sample sizes at a time. Call
<code><a href="#topic+audit_total_n">audit_total_n()</a></code> for summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim_map_total_n(
  data,
  x1 = NULL,
  x2 = NULL,
  dispersion = 0:5,
  n_min = 1L,
  n_max = NULL,
  constant = NULL,
  constant_index = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim_map_total_n_+3A_data">data</code></td>
<td>
<p>Data frame with string columns <code>x1</code> and <code>x2</code>, and numeric column
<code>n</code>. The first two are group mean or percentage values with unknown group
sizes, and <code>n</code> is the total sample size. It is not very important whether a
value is in <code>x1</code> or in <code>x2</code> because, after the first round of tests, the
function switches roles between <code>x1</code> and <code>x2</code>, and reports the outcomes
both ways.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_x1">x1</code>, <code id="grim_map_total_n_+3A_x2">x2</code></td>
<td>
<p>Optionally, specify these arguments as column names in <code>data</code>.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Steps up and down from half the <code>n</code> values.
Default is <code>0:5</code>, i.e., half <code>n</code> itself followed by five steps up and down.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_n_min">n_min</code></td>
<td>
<p>Numeric. Minimal group size. Default is 1.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_n_max">n_max</code></td>
<td>
<p>Numeric. Maximal group size. Default is <code>NULL</code>, i.e., no
maximum.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_constant">constant</code></td>
<td>
<p>Optionally, add a length-2 vector or a list of length-2
vectors (such as a data frame with exactly two rows) to accompany the pairs
of dispersed values. Default is <code>NULL</code>, i.e., no constant values.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_constant_index">constant_index</code></td>
<td>
<p>Integer (length 1). Index of <code>constant</code> or the first
<code>constant</code> column in the output tibble. If <code>NULL</code> (the default), <code>constant</code>
will go to the right of <code>n_change</code>.</p>
</td></tr>
<tr><td><code id="grim_map_total_n_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code><a href="#topic+grim_map">grim_map()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with these columns:
</p>

<ul>
<li> <p><code>x</code>, the group-wise reported input statistic, is repeated in row pairs.
</p>
</li>
<li> <p><code>n</code> is dispersed from half the input <code>n</code>, with <code>n_change</code> tracking the
differences.
</p>
</li>
<li> <p><code>both_consistent</code> flags scenarios where both reported <code>x</code> values are
consistent with the hypothetical <code>n</code> values.
</p>
</li>
<li> <p><code>case</code> corresponds to the row numbers of the input data frame.
</p>
</li>
<li> <p><code>dir</code> is <code>"forth"</code> in the first half of rows and <code>"back"</code> in the second
half. <code>"forth"</code> means that <code>x2</code> from the input is paired with the larger
dispersed <code>n</code>, whereas <code>"back"</code> means that <code>x1</code> is paired with the larger
dispersed <code>n</code>.
</p>
</li>
<li><p> Other columns from <code><a href="#topic+grim_map">grim_map()</a></code> are preserved.
</p>
</li></ul>



<h3>Summaries with <code><a href="#topic+audit_total_n">audit_total_n()</a></code></h3>

<p>You can call
<code><a href="#topic+audit_total_n">audit_total_n()</a></code> following up on <code><a href="#topic+grim_map_total_n">grim_map_total_n()</a></code>
to get a tibble with summary statistics. It will have these columns:
</p>

<ul>
<li> <p><code>x1</code>, <code>x2</code>, and <code>n</code> are the original inputs.
</p>
</li>
<li> <p><code>hits_total</code> is the number of scenarios in which both
<code>x1</code> and <code>x2</code> are GRIM-consistent. It is the sum
of <code>hits_forth</code> and <code>hits_back</code> below.
</p>
</li>
<li> <p><code>hits_forth</code> is the number of both-consistent cases that result
from pairing <code>x2</code> with the larger dispersed <code>n</code> value.
</p>
</li>
<li> <p><code>hits_back</code> is the same, except <code>x1</code> is
paired with the larger dispersed <code>n</code> value.
</p>
</li>
<li> <p><code>scenarios_total</code> is the total number of test scenarios,
whether or not both <code>x1</code> and <code>x2</code>
are GRIM-consistent.
</p>
</li>
<li> <p><code>hit_rate</code> is the ratio of <code>hits_total</code> to <code>scenarios_total</code>.
</p>
</li></ul>

<p>Call <code><a href="#topic+audit">audit()</a></code> following <code><a href="#topic+audit_total_n">audit_total_n()</a></code> to summarize results
even further.
</p>


<h3>References</h3>

<p>Bauer, P. J., &amp; Francis, G. (2021). Expression of Concern: Is It
Light or Dark? Recalling Moral Behavior Changes Perception of Brightness.
<em>Psychological Science</em>, 32(12), 2042–2043.
https://journals.sagepub.com/doi/10.1177/09567976211058727
</p>
<p>Brown, N. J. L., &amp; Heathers, J. A. J. (2017). The GRIM Test: A Simple
Technique Detects Numerous Anomalies in the Reporting of Results in
Psychology. <em>Social Psychological and Personality Science</em>, 8(4), 363–369.
https://journals.sagepub.com/doi/10.1177/1948550616673876
</p>


<h3>See Also</h3>

<p><code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>, which created the present function using
<code><a href="#topic+grim_map">grim_map()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run `grim_map_total_n()` on data like these:
df &lt;- tibble::tribble(
  ~x1,    ~x2,   ~n,
  "3.43", "5.28", 90,
  "2.97", "4.42", 103
)
df

grim_map_total_n(df)

# `audit_total_n()` summaries can be more important than
# the detailed results themselves.
# The `hits_total` column shows all scenarios in
# which both divergent `n` values are GRIM-consistent
# with the `x*` values when paired with them both ways:
df %&gt;%
  grim_map_total_n() %&gt;%
  audit_total_n()

# By default (`dispersion = 0:5`), the function goes
# five steps up and down from `n`. If this sequence
# gets longer, the number of hits tends to increase:
df %&gt;%
  grim_map_total_n(dispersion = 0:10) %&gt;%
  audit_total_n()
</code></pre>

<hr>
<h2 id='grim_plot'>Visualize GRIM test results</h2><span id='topic+grim_plot'></span>

<h3>Description</h3>

<p><code>grim_plot()</code> visualizes summary data and their mutual GRIM
consistency. Call this function only on a data frame that resulted from a
call to <code><a href="#topic+grim_map">grim_map()</a></code>.
</p>
<p>Consistent and inconsistent value pairs from the input data frame are shown
in distinctive colors. By default, consistent value pairs are blue and
inconsistent ones are red. These and other parameters of the underlying
geoms can be controlled via arguments.
</p>
<p>The background raster follows the <code>rounding</code> argument from the <code>grim_map()</code>
call (unless any of the plotted mean or proportion values has more than 2
decimal places, in which case a gradient is shown, not a raster).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim_plot(
  data = NULL,
  show_data = TRUE,
  show_raster = TRUE,
  show_gradient = TRUE,
  n = NULL,
  digits = NULL,
  rounding = "up_or_down",
  color_cons = "royalblue1",
  color_incons = "red",
  tile_alpha = 1,
  tile_size = 1.5,
  raster_alpha = 1,
  raster_color = "grey75"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim_plot_+3A_data">data</code></td>
<td>
<p>Data frame. Result of a call to <code><a href="#topic+grim_map">grim_map()</a></code>.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_show_data">show_data</code></td>
<td>
<p>Logical. If set to <code>FALSE</code>, test results from the data are
not displayed. Choose this if you only want to show the background raster.
You can then control plot parameters directly via the <code>n</code>, <code>digits</code>, and
<code>rounding</code> arguments. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_show_raster">show_raster</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), the plot has a
background raster.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_show_gradient">show_gradient</code></td>
<td>
<p>Logical. If the number of decimal places is 3 or
greater, should a gradient be shown to signal the overall probability of
GRIM inconsistency? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_n">n</code></td>
<td>
<p>Integer. Maximal value on the x-axis. Default is <code>NULL</code>, in which
case <code>n</code> becomes <code>10 ^ digits</code> (e.g., <code>100</code> if <code>digits</code> is <code>2</code>).</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_digits">digits</code></td>
<td>
<p>Integer. Only relevant if <code>show_data</code> is set to <code>FALSE</code>. The
plot will then be constructed as it would be for data where all <code>x</code> values
have this many decimal places. Default is <code>2</code>.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_rounding">rounding</code></td>
<td>
<p>String. Only relevant if <code>show_data</code> is set to <code>FALSE</code>. The
plot will then be constructed as it would be for data rounded in this
particular way. Default is <code>"up_or_down"</code>.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_color_cons">color_cons</code>, <code id="grim_plot_+3A_color_incons">color_incons</code></td>
<td>
<p>Strings. Fill colors of the consistent and
inconsistent scatter points. Defaults are <code>"royalblue1"</code> (consistent) and
<code>"red"</code> (inconsistent).</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_tile_alpha">tile_alpha</code>, <code id="grim_plot_+3A_tile_size">tile_size</code></td>
<td>
<p>Numeric. Further parameters of the scatter
points: opacity and, indirectly, size. Defaults are <code>1</code> and <code>1.5</code>.</p>
</td></tr>
<tr><td><code id="grim_plot_+3A_raster_alpha">raster_alpha</code>, <code id="grim_plot_+3A_raster_color">raster_color</code></td>
<td>
<p>Numeric and string, respectively. Parameters
of the background raster: opacity and fill color. Defaults are <code>1</code> and
<code>"grey75"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Background raster</h3>

<p>The background raster shows the probability of
GRIM-inconsistency for random means or proportions, from 0 (all
inconsistent) to the greatest number on the x-axis (all consistent). If the
number of decimal places in the inputs &ndash; means or percentages &ndash; is 3 or
greater, individual points would be too small to display. In these cases,
there will not be a raster but a gradient, showing the overall trend.
</p>
<p>As any raster only makes sense with respect to one specific number of
decimal places, the function will throw an error if these numbers differ
among input <code>x</code> values (and <code>show_raster</code> is <code>TRUE</code>). You can avoid the
error and force plotting by specifying <code>digits</code> as the number of decimal
places for which the raster or gradient should be displayed.
</p>
<p>For 1 or 2 decimal places, the raster will be specific to the rounding
procedure. As the raster varies by rounding procedure, it will
automatically correspond to the <code>rounding</code> argument specified in the
preceding <code><a href="#topic+grim_map">grim_map()</a></code> call. This works fast because the raster is based
on data saved in the package itself, so these data don't need to be
generated anew every time the function is called. Inconsistent value sets
are marked with dark boxes. All other places in the raster denote
consistent value sets. The raster is independent of the data &ndash; it only
follows the <code>rounding</code> specification in the <code><a href="#topic+grim_map">grim_map()</a></code> call and the
<code>digits</code> argument in <code>grim_plot()</code>.
</p>
<p>Display an &quot;empty&quot; plot, one without empirical test results, by setting
<code>show_data</code> to <code>FALSE</code>. You can then control key parameters of the plot
with <code>digits</code> and <code>rounding</code>.
</p>
<p>With <code><a href="#topic+grim_map">grim_map()</a></code>'s default for <code>rounding</code>, <code>"up_or_down"</code>, strikingly
few values are flagged as inconsistent for sample sizes 40 and 80 (or 4 and
8). This effect disappears if <code>rounding</code> is set to any other value (see
<code>vignette("rounding-options")</code>).
</p>
<p>The 4/8 leniency effect arises because accepting values rounded either up
or down is more careful and conservative than any other rounding procedure.
In any case, <code>grim_plot()</code> doesn't cause this effect &mdash; it only reveals
it.
</p>


<h3>References</h3>

<p>Brown, N. J. L., &amp; Heathers, J. A. J. (2017). The GRIM Test: A
Simple Technique Detects Numerous Anomalies in the Reporting of Results in
Psychology. <em>Social Psychological and Personality Science</em>, 8(4), 363–369.
https://journals.sagepub.com/doi/10.1177/1948550616673876
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Call `grim_plot()` following `grim_map()`:
pigs1 %&gt;%
  grim_map() %&gt;%
  grim_plot()

# If you change the rounding procedure
# in `grim_map()`, the plot will
# follow automatically if there is
# a difference:
pigs1 %&gt;%
  grim_map(rounding = "ceiling") %&gt;%
  grim_plot()

# For percentages, the y-axis
# label also changes automatically:
pigs2 %&gt;%
  grim_map(percent = TRUE) %&gt;%
  grim_plot()
</code></pre>

<hr>
<h2 id='grim-stats'>Possible GRIM inconsistencies</h2><span id='topic+grim-stats'></span><span id='topic+grim_total'></span><span id='topic+grim_ratio'></span><span id='topic+grim_ratio_upper'></span>

<h3>Description</h3>

<p>Even without GRIM-testing, means / proportions and sample sizes
of granular distributions entail some key data:
</p>

<ul>
<li> <p><code>grim_total()</code> returns the absolute number of GRIM-inconsistencies that
are possible given the mean or percentage's number of decimal places (<code>D</code>)
and the corresponding sample size.
</p>
</li>
<li> <p><code>grim_ratio()</code> returns a proportion that is normalized by <code>10^D</code>, and
therefore comparable across mean or percentage values reported to varying
<code>D</code>.
</p>
</li>
<li> <p><code>grim_ratio_upper()</code> returns the upper bound of <code>grim_ratio()</code> for a
given <code>D</code>.
</p>
</li></ul>

<p>For discussion, see <code>vignette("grim")</code>, section <em>GRIM statistics</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grim_total(x, n, items = 1, percent = FALSE)

grim_ratio(x, n, items = 1, percent = FALSE)

grim_ratio_upper(x, percent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grim-stats_+3A_x">x</code></td>
<td>
<p>String or numeric (length 1). Mean or percentage value computed from
data with integer units (e.g., mean scores on a Likert scale or percentage
of study participants in some condition). <em>Note</em>: Numeric inputs don't
include trailing zeros, but these are important for GRIM functions. See
documentation for <code>grim()</code>.</p>
</td></tr>
<tr><td><code id="grim-stats_+3A_n">n</code></td>
<td>
<p>Integer. Sample size corresponding to <code>x</code>.</p>
</td></tr>
<tr><td><code id="grim-stats_+3A_items">items</code></td>
<td>
<p>Integer. Number of items composing the mean or percentage value
in question. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="grim-stats_+3A_percent">percent</code></td>
<td>
<p>Logical. Set <code>percent</code> to <code>TRUE</code> if <code>x</code> is expressed as a
proportion of 100 rather than 1. The functions will then account for this
fact through increasing the decimal count by 2. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integer or double. The number or proportion of possible GRIM
inconsistencies.
</p>


<h3>References</h3>

<p>Brown, N. J. L., &amp; Heathers, J. A. J. (2017). The GRIM Test: A
Simple Technique Detects Numerous Anomalies in the Reporting of Results in
Psychology. <em>Social Psychological and Personality Science</em>, 8(4), 363–369.
https://journals.sagepub.com/doi/10.1177/1948550616673876
</p>


<h3>See Also</h3>

<p><code>grim()</code> for the GRIM test itself; as well as <code>grim_map()</code> for
applying it to many cases at once.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Many value sets are inconsistent here:
grim_total(x = "83.29", n = 21)
grim_ratio(x = "83.29", n = 21)

# No sets are inconsistent in this case...
grim_total(x = "5.14", n = 83)
grim_ratio(x = "5.14", n = 83)

# ... but most would be if `x` was a percentage:
grim_total(x = "5.14", n = 83, percent = TRUE)
grim_ratio(x = "5.14", n = 83, percent = TRUE)
</code></pre>

<hr>
<h2 id='grimmer'>The GRIMMER test (granularity-related inconsistency of means mapped to error
repeats)</h2><span id='topic+grimmer'></span>

<h3>Description</h3>

<p><code>grimmer()</code> checks if reported mean and SD values of integer
data are mathematically consistent with the reported sample size and the
number of items that compose the mean value. It works much like <code><a href="#topic+grim">grim()</a></code>.
</p>
<p>The function is vectorized, but it is recommended to use <code><a href="#topic+grimmer_map">grimmer_map()</a></code>
for testing multiple cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grimmer(
  x,
  sd,
  n,
  items = 1,
  show_reason = FALSE,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE,
  tolerance = .Machine$double.eps^0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grimmer_+3A_x">x</code></td>
<td>
<p>String. The reported mean value.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_sd">sd</code></td>
<td>
<p>String. The reported standard deviation.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_n">n</code></td>
<td>
<p>Integer. The reported sample size.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_items">items</code></td>
<td>
<p><em>(NOTE: Don't use the <code>items</code> argument. It currently contains a
bug that will be fixed in the future.)</em> Integer. The
number of items composing the <code>x</code> and <code>sd</code> values. Default is 1, the most
common case.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_show_reason">show_reason</code></td>
<td>
<p>Logical. For internal use only. If set to <code>TRUE</code>, the
output is a list of length-2 lists which also contain the reasons for
inconsistencies. Don't specify this manually; instead, use <code>show_reason</code> in
<code><a href="#topic+grimmer_map">grimmer_map()</a></code>. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_rounding">rounding</code></td>
<td>
<p>String. Rounding method or methods to be used for
reconstructing the values to which <code>x</code> will be compared. Default is
<code>"up_or_down"</code> (from 5).</p>
</td></tr>
<tr><td><code id="grimmer_+3A_threshold">threshold</code></td>
<td>
<p>Numeric. If <code>rounding</code> is set to <code>"up_from"</code>, <code>"down_from"</code>,
or <code>"up_from_or_down_from"</code>, set <code>threshold</code> to the number from which the
reconstructed values should then be rounded up or down. Otherwise, this
argument plays no role. Default is <code>5</code>.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_symmetric">symmetric</code></td>
<td>
<p>Logical. Set <code>symmetric</code> to <code>TRUE</code> if the rounding of
negative numbers with <code>"up"</code>, <code>"down"</code>, <code>"up_from"</code>, or <code>"down_from"</code>
should mirror that of positive numbers so that their absolute values are
always equal. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grimmer_+3A_tolerance">tolerance</code></td>
<td>
<p>Numeric. Tolerance of comparison between <code>x</code> and the
possible mean or percentage values. Default is circa 0.000000015
(1.490116e-08), as in <code><a href="dplyr.html#topic+near">dplyr::near()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GRIMMER was originally devised by Anaya (2016). The present
implementation follows Allard's (2018) refined Analytic-GRIMMER (A-GRIMMER)
algorithm. It adapts the R function <code>aGrimmer()</code> provided by Allard and
modifies it to accord with scrutiny's standards, as laid out in
<code>vignette("consistency-tests-in-depth")</code>, sections 1-2. The resulting
<code>grimmer()</code> function, then, is a vectorized version of this basic
implementation. For more context and variable name translations, see the
top of the R/grimmer.R, the source file.
</p>
<p>The present implementation can differ from Allard's in a small number of
cases. In most cases, this means that the original flags a value set as
inconsistent, but scrutiny's <code style="white-space: pre;">&#8288;grimmer*()&#8288;</code> functions don't. For details, see
the end of tests/testthat/test-grimmer.R, the <code>grimmer()</code> test file.
</p>


<h3>Value</h3>

<p>Logical. <code>TRUE</code> if <code>x</code>, <code>sd</code>, <code>n</code>, and <code>items</code> are mutually
consistent, <code>FALSE</code> if not.
</p>


<h3>References</h3>

<p>Allard, A. (2018). Analytic-GRIMMER: a new way of testing the
possibility of standard deviations.
https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/
</p>
<p>Anaya, J. (2016). The GRIMMER test: A method for testing the validity of
reported measures of variability. <em>PeerJ Preprints.</em>
https://peerj.com/preprints/2400v1/
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A mean of 5.23 is not consistent with an SD of 2.55
# and a sample size of 35:
grimmer(x = "5.23", sd = "2.55", n = 35)

# However, mean and SD are consistent with a
# sample size of 31:
grimmer(x = "5.23", sd = "2.55", n = 31)

# For a scale composed of two items:
grimmer(x = "2.74", sd = "0.96", n = 63, items = 2)
</code></pre>

<hr>
<h2 id='grimmer_map'>GRIMMER-test many cases at once</h2><span id='topic+grimmer_map'></span>

<h3>Description</h3>

<p>Call <code>grimmer_map()</code> to GRIMMER-test any number of combinations
of mean, standard deviation, sample size, and number of items. Mapping
function for GRIMMER-testing.
</p>
<p>For summary statistics, call <code><a href="#topic+audit">audit()</a></code> on the results. Visualize results
using <code><a href="#topic+grim_plot">grim_plot()</a></code>, as with GRIM results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grimmer_map(
  data,
  items = 1,
  merge_items = TRUE,
  x = NULL,
  sd = NULL,
  n = NULL,
  show_reason = TRUE,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE,
  tolerance = .Machine$double.eps^0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grimmer_map_+3A_data">data</code></td>
<td>
<p>Data frame with columns <code>x</code>, <code>sd</code>, <code>n</code>, and optionally <code>items</code>
(see documentation for <code>grim()</code>). Any other columns in <code>data</code> will be
returned alongside GRIMMER test results.</p>
</td></tr>
<tr><td><code id="grimmer_map_+3A_items">items</code></td>
<td>
<p><em>(NOTE: Don't use the <code>items</code> argument. It currently contains a
bug that will be fixed in the future.)</em> Integer. If there is no <code>items</code>
column in <code>data</code>, this specifies the number of items composing the <code>x</code> and
<code>sd</code> values. Default is 1, the most common case.</p>
</td></tr>
<tr><td><code id="grimmer_map_+3A_merge_items">merge_items</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), there will be no <code>items</code>
column in the output. Instead, values from an <code>items</code> column or argument
will be multiplied with values in the <code>n</code> column. This does not affect
GRIM- or GRIMMER-testing.</p>
</td></tr>
<tr><td><code id="grimmer_map_+3A_x">x</code>, <code id="grimmer_map_+3A_sd">sd</code>, <code id="grimmer_map_+3A_n">n</code></td>
<td>
<p>Optionally, specify these arguments as column names in <code>data</code>.</p>
</td></tr>
<tr><td><code id="grimmer_map_+3A_show_reason">show_reason</code></td>
<td>
<p>Logical (length 1). Should there be a <code>reason</code> column that
shows the reasons for inconsistencies (and <code>NA</code> for consistent values)?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grimmer_map_+3A_rounding">rounding</code>, <code id="grimmer_map_+3A_threshold">threshold</code>, <code id="grimmer_map_+3A_symmetric">symmetric</code>, <code id="grimmer_map_+3A_tolerance">tolerance</code></td>
<td>
<p>Further parameters of
GRIMMER-testing; see documentation for <code><a href="#topic+grimmer">grimmer()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with these columns &ndash;
</p>

<ul>
<li> <p><code>x</code>, <code>sd</code>, <code>n</code>: the inputs.
</p>
</li>
<li> <p><code>consistency</code>: GRIMMER consistency of <code>x</code>, <code>n</code>, and <code>items</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;&lt;extra&gt;&#8288;</code>: any columns from <code>data</code> other than <code>x</code>, <code>n</code>, and <code>items</code>.
</p>
</li></ul>

<p>The tibble has the <code>scr_grimmer_map</code> class, which is recognized by the
<code><a href="#topic+audit">audit()</a></code> generic. It also has the <code>scr_grim_map</code> class, so it can be
visualized by <code><a href="#topic+grim_plot">grim_plot()</a></code>.
</p>


<h3>Summaries with <code><a href="#topic+audit">audit()</a></code></h3>

<p>There is an S3 method for <code><a href="#topic+audit">audit()</a></code>,
so you can call <code><a href="#topic+audit">audit()</a></code> following <code>grimmer_map()</code> to get a summary of
<code>grimmer_map()</code>'s results. It is a tibble with a single row and these
columns &ndash;
</p>

<ol>
<li> <p><code>incons_cases</code>: number of GRIMMER-inconsistent value sets.
</p>
</li>
<li> <p><code>all_cases</code>: total number of value sets.
</p>
</li>
<li> <p><code>incons_rate</code>: proportion of GRIMMER-inconsistent value sets.
</p>
</li>
<li> <p><code>fail_grim</code>: number of value sets that fail the GRIM test.
</p>
</li>
<li> <p><code>fail_test1</code>: number of value sets that fail the first GRIMMER test (sum
of squares is a whole number).
</p>
</li>
<li> <p><code>fail_test2</code>: number of value sets that fail the second GRIMMER test
(matching SDs).
</p>
</li>
<li> <p><code>fail_test3</code>: number of value sets that fail the third GRIMMER test (equal
parity).
</p>
</li></ol>



<h3>References</h3>

<p>Allard, A. (2018). Analytic-GRIMMER: a new way of testing the
possibility of standard deviations.
https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/
</p>
<p>Anaya, J. (2016). The GRIMMER test: A method for testing the validity of
reported measures of variability. <em>PeerJ Preprints.</em>
https://peerj.com/preprints/2400v1/
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use `grimmer_map()` on data like these:
pigs5

# The `consistency` column shows whether
# the values to its left are GRIMMER-consistent.
# If they aren't, the `reason` column says why:
pigs5 %&gt;%
  grimmer_map()

# Get summaries with `audit()`:
pigs5 %&gt;%
  grimmer_map() %&gt;%
  audit()
</code></pre>

<hr>
<h2 id='grimmer_map_seq'>GRIMMER-testing with dispersed inputs</h2><span id='topic+grimmer_map_seq'></span>

<h3>Description</h3>

<p><code>grimmer_map_seq()</code> performs GRIMMER-testing with values
surrounding the input values. This provides an easy and powerful way to
assess whether small errors in computing or reporting may be responsible
for GRIMMER inconsistencies in published statistics.
</p>
<p>Call <code><a href="#topic+audit_seq">audit_seq()</a></code> on the results for summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grimmer_map_seq(
  data,
  x = NULL,
  sd = NULL,
  n = NULL,
  var = Inf,
  dispersion = 1:5,
  out_min = "auto",
  out_max = NULL,
  include_reported = FALSE,
  include_consistent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grimmer_map_seq_+3A_data">data</code></td>
<td>
<p>A data frame that <code><a href="#topic+grimmer_map">grimmer_map()</a></code> could take.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_x">x</code>, <code id="grimmer_map_seq_+3A_sd">sd</code>, <code id="grimmer_map_seq_+3A_n">n</code></td>
<td>
<p>Optionally, specify these arguments as column names in <code>data</code>.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_var">var</code></td>
<td>
<p>String. Names of the columns that will be dispersed. Default is
<code>c("x", "sd", "n")</code>.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Sequence with steps up and down from the <code>var</code>
inputs. It will be adjusted to these values' decimal levels. For example,
with a reported <code>8.34</code>, the step size is <code>0.01</code>. Default is <code>1:5</code>, for five
steps up and down.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_out_min">out_min</code>, <code id="grimmer_map_seq_+3A_out_max">out_max</code></td>
<td>
<p>If specified, output will be restricted so that it's
not below <code>out_min</code> or above <code>out_max</code>. Defaults are <code>"auto"</code> for
<code>out_min</code>, i.e., a minimum of one decimal unit above zero; and <code>NULL</code> for
<code>out_max</code>, i.e., no maximum.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_include_reported">include_reported</code></td>
<td>
<p>Logical. Should the reported values themselves be
included in the sequences originating from them? Default is <code>FALSE</code> because
this might be redundant and bias the results.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_include_consistent">include_consistent</code></td>
<td>
<p>Logical. Should the function also process
consistent cases (from among those reported), not just inconsistent ones?
Default is <code>FALSE</code> because the focus should be on clarifying
inconsistencies.</p>
</td></tr>
<tr><td><code id="grimmer_map_seq_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code><a href="#topic+grimmer_map">grimmer_map()</a></code>. <em>(NOTE: Don't use the
<code>items</code> argument. It currently contains a bug that will be fixed in the
future.)</em></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble (data frame) with detailed test results.
</p>


<h3>Summaries with <code><a href="#topic+audit_seq">audit_seq()</a></code></h3>

<p>You can call <code><a href="#topic+audit_seq">audit_seq()</a></code>
following <code>grimmer_map_seq()</code>. It will return a data frame with these
columns:
</p>

<ul>
<li> <p><code>x</code>, <code>sd</code>, and <code>n</code> are the original inputs,
tested for <code>consistency</code> here.
</p>
</li>
<li> <p><code>hits_total</code> is the total number of GRIMMER-consistent value sets
found within the specified <code>dispersion</code> range.
</p>
</li>
<li> <p><code>hits_x</code> is the number of GRIMMER-consistent value sets
found by varying <code>x</code>.
</p>
</li>
<li><p> Accordingly with <code>sd</code> and <code>hits_sd</code> as well as <code>n</code> and <code>hits_n</code>.
</p>
</li>
<li><p> (Note that any consistent reported cases will be counted by the
<code style="white-space: pre;">&#8288;hits_*&#8288;</code> columns if both <code>include_reported</code> and <code>include_consistent</code> are
set to <code>TRUE</code>.)
</p>
</li>
<li> <p><code>diff_x</code> reports the absolute difference between <code>x</code> and the next
consistent dispersed value (in dispersion steps, not the actual numeric
difference). <code>diff_x_up</code> and <code>diff_x_down</code> report the difference to the
next higher or lower consistent value, respectively.
</p>
</li>
<li> <p><code>diff_sd</code>, <code>diff_sd_up</code>, and <code>diff_sd_down</code> do the same for <code>sd</code>.
</p>
</li>
<li><p> Likewise with <code>diff_n</code>, <code>diff_n_up</code>, and <code>diff_n_down</code>.
</p>
</li></ul>

<p>Call <code><a href="#topic+audit">audit()</a></code> following <code><a href="#topic+audit_seq">audit_seq()</a></code> to summarize results even
further. It's mostly self-explaining, but <code>na_count</code> and <code>na_rate</code> are the
number and rate of times that a difference could not be computed because of
a lack of corresponding hits within the <code>dispersion</code> range.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># `grimmer_map_seq()` can take any input
# that `grimmer_map()` can take:
pigs5

# All the results:
out &lt;- grimmer_map_seq(pigs5, include_consistent = TRUE)
out

# Case-wise summaries with `audit_seq()`
# can be more important than the raw results:
out %&gt;%
  audit_seq()
</code></pre>

<hr>
<h2 id='grimmer_map_total_n'>GRIMMER-testing with hypothetical group sizes</h2><span id='topic+grimmer_map_total_n'></span>

<h3>Description</h3>

<p>When reporting group means, some published studies only report
the total sample size but no group sizes corresponding to each mean.
However, group sizes are crucial for GRIMMER-testing.
</p>
<p>In the two-groups case, <code>grimmer_map_total_n()</code> helps in these ways:
</p>

<ul>
<li><p> It creates hypothetical group sizes. With an even total sample size, it
incrementally moves up and down from half the total sample size. For example,
with a total sample size of 40, it starts at 20, goes on to 19 and 21, then
to 18 and 22, etc. With odd sample sizes, it starts from the two integers
around half.
</p>
</li>
<li><p> It GRIMMER-tests all of these values together with the group means.
</p>
</li>
<li><p> It reports all the scenarios in which both &quot;dispersed&quot; hypothetical group
sizes are GRIMMER-consistent with the group means.
</p>
</li></ul>

<p>All of this works with one or more total sample sizes at a time. Call
<code><a href="#topic+audit_total_n">audit_total_n()</a></code> for summary statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grimmer_map_total_n(
  data,
  x1 = NULL,
  x2 = NULL,
  sd1 = NULL,
  sd2 = NULL,
  dispersion = 0:5,
  n_min = 1L,
  n_max = NULL,
  constant = NULL,
  constant_index = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grimmer_map_total_n_+3A_data">data</code></td>
<td>
<p>Data frame with string columns <code>x1</code>, <code>x2</code>, <code>sd1</code>, and <code>sd2</code>, as
well as numeric column <code>n</code>. The first two are reported group means. <code>sd1</code>
and <code>sd2</code> are reported group SDs. <code>n</code> is the reported total sample size. It
is not very important whether a value is in <code>x1</code> or in <code>x2</code> because, after
the first round of tests, the function switches roles between <code>x1</code> and
<code>x2</code>, and reports the outcomes both ways. The same applies to <code>sd1</code> and
<code>sd2</code>. However, do make sure the <code style="white-space: pre;">&#8288;x*&#8288;</code> and <code style="white-space: pre;">&#8288;sd*&#8288;</code> values are paired
accurately, as reported.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_x1">x1</code>, <code id="grimmer_map_total_n_+3A_x2">x2</code>, <code id="grimmer_map_total_n_+3A_sd1">sd1</code>, <code id="grimmer_map_total_n_+3A_sd2">sd2</code></td>
<td>
<p>Optionally, specify these arguments as column names in
<code>data</code>.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_dispersion">dispersion</code></td>
<td>
<p>Numeric. Steps up and down from half the <code>n</code> values.
Default is <code>0:5</code>, i.e., half <code>n</code> itself followed by five steps up and down.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_n_min">n_min</code></td>
<td>
<p>Numeric. Minimal group size. Default is 1.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_n_max">n_max</code></td>
<td>
<p>Numeric. Maximal group size. Default is <code>NULL</code>, i.e., no
maximum.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_constant">constant</code></td>
<td>
<p>Optionally, add a length-2 vector or a list of length-2
vectors (such as a data frame with exactly two rows) to accompany the pairs
of dispersed values. Default is <code>NULL</code>, i.e., no constant values.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_constant_index">constant_index</code></td>
<td>
<p>Integer (length 1). Index of <code>constant</code> or the first
<code>constant</code> column in the output tibble. If <code>NULL</code> (the default), <code>constant</code>
will go to the right of <code>n_change</code>.</p>
</td></tr>
<tr><td><code id="grimmer_map_total_n_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code><a href="#topic+grimmer_map">grimmer_map()</a></code>. <em>(NOTE: Don't use the
<code>items</code> argument. It currently contains a bug that will be fixed in the
future.)</em></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with these columns:
</p>

<ul>
<li> <p><code>x</code>, the group-wise reported input statistic, is repeated in row pairs.
</p>
</li>
<li> <p><code>n</code> is dispersed from half the input <code>n</code>, with <code>n_change</code> tracking the
differences.
</p>
</li>
<li> <p><code>both_consistent</code> flags scenarios where both reported <code>x</code> values are
consistent with the hypothetical <code>n</code> values.
</p>
</li>
<li> <p><code>case</code> corresponds to the row numbers of the input data frame.
</p>
</li>
<li> <p><code>dir</code> is <code>"forth"</code> in the first half of rows and <code>"back"</code> in the second
half. <code>"forth"</code> means that <code>x2</code> from the input is paired with the larger
dispersed <code>n</code>, whereas <code>"back"</code> means that <code>x1</code> is paired with the larger
dispersed <code>n</code>.
</p>
</li>
<li><p> Other columns from <code><a href="#topic+grimmer_map">grimmer_map()</a></code> are preserved.
</p>
</li></ul>



<h3>Summaries with <code><a href="#topic+audit_total_n">audit_total_n()</a></code></h3>

<p>You can call
<code><a href="#topic+audit_total_n">audit_total_n()</a></code> following up on <code>grimmer_map_total_n()</code>
to get a tibble with summary statistics. It will have these columns:
</p>

<ul>
<li> <p><code>x1</code>, <code>x2</code>, <code>sd1</code>, <code>sd2</code>, and <code>n</code> are the original inputs.
</p>
</li>
<li> <p><code>hits_total</code> is the number of scenarios in which all of
<code>x1</code>, <code>x2</code>, <code>sd1</code>, and <code>sd2</code> are GRIMMER-consistent. It is the sum
of <code>hits_forth</code> and <code>hits_back</code> below.
</p>
</li>
<li> <p><code>hits_forth</code> is the number of both-consistent cases that result
from pairing <code>x2</code> and <code>sd2</code> with the larger dispersed <code>n</code> value.
</p>
</li>
<li> <p><code>hits_back</code> is the same, except <code>x1</code> and <code>sd1</code> are
paired with the larger dispersed <code>n</code> value.
</p>
</li>
<li> <p><code>scenarios_total</code> is the total number of test scenarios,
whether or not both <code>x1</code> and <code>sd1</code> as well as <code>x2</code> and <code>sd2</code>
are GRIMMER-consistent.
</p>
</li>
<li> <p><code>hit_rate</code> is the ratio of <code>hits_total</code> to <code>scenarios_total</code>.
</p>
</li></ul>



<h3>References</h3>

<p>Bauer, P. J., &amp; Francis, G. (2021). Expression of Concern: Is It
Light or Dark? Recalling Moral Behavior Changes Perception of Brightness.
<em>Psychological Science</em>, 32(12), 2042–2043.
https://journals.sagepub.com/doi/10.1177/09567976211058727
</p>
<p>Allard, A. (2018). Analytic-GRIMMER: a new way of testing the
possibility of standard deviations.
https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/
</p>
<p>Bauer, P. J., &amp; Francis, G. (2021). Expression of Concern: Is It Light or
Dark? Recalling Moral Behavior Changes Perception of Brightness.
<em>Psychological Science</em>, 32(12), 2042–2043.
https://journals.sagepub.com/doi/10.1177/09567976211058727
</p>


<h3>See Also</h3>

<p><code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>, which created the present function using
<code><a href="#topic+grimmer_map">grimmer_map()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run `grimmer_map_total_n()` on data like these:
df &lt;- tibble::tribble(
  ~x1,    ~x2,    ~sd1,   ~sd2,   ~n,
  "3.43", "5.28", "1.09", "2.12", 70,
  "2.97", "4.42", "0.43", "1.65", 65
)
df

grimmer_map_total_n(df)

# `audit_total_n()` summaries can be more important than
# the detailed results themselves.
# The `hits_total` column shows all scenarios in
# which both divergent `n` values are GRIMMER-consistent
# with the `x*` values when paired with them both ways:
df %&gt;%
  grimmer_map_total_n() %&gt;%
  audit_total_n()

# By default (`dispersion = 0:5`), the function goes
# five steps up and down from `n`. If this sequence
# gets longer, the number of hits tends to increase:
df %&gt;%
  grimmer_map_total_n(dispersion = 0:10) %&gt;%
  audit_total_n()
</code></pre>

<hr>
<h2 id='is_numeric_like'>Test whether a vector is numeric or coercible to numeric</h2><span id='topic+is_numeric_like'></span>

<h3>Description</h3>

<p><code>is_numeric_like()</code> tests whether an object is &quot;coercible to
numeric&quot; by the particular standards of scrutiny. This means:
</p>

<ul>
<li><p> Integer and double vectors are <code>TRUE</code>.
</p>
</li>
<li><p> Logical vectors are <code>FALSE</code>, as are non-vector objects.
</p>
</li>
<li><p> Other vectors (most likely strings) are <code>TRUE</code> if all their non-<code>NA</code>
values can be coerced to non-<code>NA</code> numeric values, and <code>FALSE</code> otherwise.
</p>
</li>
<li><p> Factors are first coerced to string, then tested.
</p>
</li>
<li><p> Lists are tested like atomic vectors unless any of their elements have
length greater 1, in which case they are always <code>FALSE</code>.
</p>
</li>
<li><p> If all values are non-numeric, non-logical <code>NA</code>, the output is also <code>NA</code>.
</p>
</li></ul>

<p>See details for discussion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_numeric_like(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_numeric_like_+3A_x">x</code></td>
<td>
<p>Object to be tested.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The scrutiny package often deals with &quot;number-strings&quot;, i.e.,
strings that can be coerced to numeric without introducing new <code>NA</code>s. This
is a matter of displaying data in a certain way, as opposed to their
storage mode.
</p>
<p><code>is_numeric_like()</code> returns <code>FALSE</code> for logical vectors simply because
these are displayed as strings, not as numbers, and the usual coercion
rules would be misleading in this context. Likewise, the function treats
factors like strings because that is how they are displayed: the fact that
factors are stored as integers is irrelevant.
</p>
<p>Why store numbers as strings or factors? Only these data types can preserve
trailing zeros, and only if the data were originally entered as strings.
See <code>vignette("wrangling")</code>, section <em>Trailing zeros</em>.
</p>


<h3>Value</h3>

<p>Logical (length 1).
</p>


<h3>See Also</h3>

<p>The <a href="https://vctrs.r-lib.org/">vctrs</a> package, which provides a
serious typing framework for R; in contrast to this rather ad-hoc function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Numeric vectors are `TRUE`:
is_numeric_like(x = 1:5)
is_numeric_like(x = 2.47)

# Logical vectors are always `FALSE`:
is_numeric_like(x = c(TRUE, FALSE))

# Strings are `TRUE` if all of their non-`NA`
# values can be coerced to non-`NA` numbers,
# and `FALSE` otherwise:
is_numeric_like(x = c("42", "0.7", NA))
is_numeric_like(x = c("42", "xyz", NA))

# Factors are treated like their
# string equivalents:
is_numeric_like(x = as.factor(c("42", "0.7", NA)))
is_numeric_like(x = as.factor(c("42", "xyz", NA)))

# Lists behave like atomic vectors if all of their
# elements have length 1...
is_numeric_like(x = list("42", "0.7", NA))
is_numeric_like(x = list("42", "xyz", NA))

# ...but if they don't, they are `FALSE`:
is_numeric_like(x = list("42", "0.7", NA, c(1, 2, 3)))

# If all values are `NA`, so is the output...
is_numeric_like(x = as.character(c(NA, NA, NA)))

# ...unless the `NA`s are numeric or logical:
is_numeric_like(x = as.numeric(c(NA, NA, NA)))
is_numeric_like(x = c(NA, NA, NA))
</code></pre>

<hr>
<h2 id='manage_helper_col'>Helper column operations</h2><span id='topic+manage_helper_col'></span>

<h3>Description</h3>

<p>If your consistency test mapper function supports helper
columns, call <code>manage_helper_col()</code> internally; once for every such column.
It will check whether a helper column is compatible with its eponymous
argument, i.e., if the argument was not specified by the user but has its
default value.
</p>
<p>By default (<code>affix = TRUE</code>), the function will add the column to the
mapper's input data frame. It returns the input data frame, so reassign its
output to that variable.
</p>
<p>All of this only works in mapper functions that were &quot;handwritten&quot; using
<code style="white-space: pre;">&#8288;function()&#8288;</code>, as opposed to those produced by <code>function_map()</code>. See
<code>vignette("consistency-tests-in-depth")</code>, section <em>Writing mappers
manually</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manage_helper_col(data, var_arg, default, affix = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="manage_helper_col_+3A_data">data</code></td>
<td>
<p>The data frame that is the mapper function's first argument.</p>
</td></tr>
<tr><td><code id="manage_helper_col_+3A_var_arg">var_arg</code></td>
<td>
<p>The argument to the mapper function that has the same name as
the helper column you want to manage.</p>
</td></tr>
<tr><td><code id="manage_helper_col_+3A_default">default</code></td>
<td>
<p>The default for the argument that was specified in <code>var_arg</code>.</p>
</td></tr>
<tr><td><code id="manage_helper_col_+3A_affix">affix</code></td>
<td>
<p>Logical (length 1). If <code>data</code> doesn't include the helper column
already, should <code>var_arg</code> be added to <code>data</code>, bearing its proper name?
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data</code>, possibly modified (see <code>affix</code> argument).
</p>

<hr>
<h2 id='manage_key_colnames'>Enable name-independent key column identification</h2><span id='topic+manage_key_colnames'></span>

<h3>Description</h3>

<p>A handwritten mapper function for consistency tests, such as
<code>grim_map()</code>, may include arguments named after the key columns in its
input data frame. When such an argument is specified by the user as a
column name of the input data frame, it identifies a differently-named
column as that key column.
</p>
<p>Create such functionality in three steps:
</p>

<ol>
<li><p> Add arguments to your mapper function named after the respective key
columns. They should be <code>NULL</code> by default; e.g., <code style="white-space: pre;">&#8288;x = NULL, n = NULL&#8288;</code>.
</p>
</li>
<li><p> Within the mapper, capture the user input by quoting it using
<code>rlang::enexpr()</code>. Reassign these values to the argument variables; e.g.,
<code>x &lt;- rlang::enexpr(x)</code> and <code>n &lt;- rlang::enexpr(n)</code>.
</p>
</li>
<li><p> For every such argument, call <code>manage_key_colnames()</code> and reassign its
value to the input data frame variable, adding a short description;
e.g.,<code>data &lt;- manage_key_colnames(data, x, "mean/proportion")</code> and <code>data &lt;-   manage_key_colnames(data, n, "sample size")</code>.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>manage_key_colnames(data, arg, description = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="manage_key_colnames_+3A_data">data</code></td>
<td>
<p>The mapper function's input data frame.</p>
</td></tr>
<tr><td><code id="manage_key_colnames_+3A_arg">arg</code></td>
<td>
<p>Symbol. The quoted input variable, captured by <code>rlang::enexpr()</code>.</p>
</td></tr>
<tr><td><code id="manage_key_colnames_+3A_description">description</code></td>
<td>
<p>String (length 1). Short description of the column in
question, to be inserted into an error message.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input data frame, <code>data</code>, possibly modified.
</p>


<h3>See Also</h3>

<p><code>vignette("consistency-tests-in-depth")</code>, for context.
</p>

<hr>
<h2 id='parens-extractors'>Extract substrings from before and inside parentheses</h2><span id='topic+parens-extractors'></span><span id='topic+before_parens'></span><span id='topic+inside_parens'></span>

<h3>Description</h3>

<p><code>before_parens()</code> and <code>inside_parens()</code> extract substrings from
before or inside parentheses, or similar separators like brackets or curly
braces.
</p>
<p>See <code><a href="#topic+split_by_parens">split_by_parens()</a></code> to split some or all columns in a data frame into
both parts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>before_parens(string, sep = "parens")

inside_parens(string, sep = "parens")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parens-extractors_+3A_string">string</code></td>
<td>
<p>Vector of strings with parentheses or similar.</p>
</td></tr>
<tr><td><code id="parens-extractors_+3A_sep">sep</code></td>
<td>
<p>String. What to split by. Either <code>"parens"</code>, <code>"brackets"</code>,
<code>"braces"</code>, or a length-2 vector of custom separators. See examples for
<code><a href="#topic+split_by_parens">split_by_parens()</a></code>. Default is <code>"parens"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>String vector of the same length as <code>string</code>. The part of <code>string</code>
before or inside <code>sep</code>, respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
  "3.72 (0.95)",
  "5.86 (2.75)",
  "3.06 (6.48)"
)

before_parens(string = x)

inside_parens(string = x)
</code></pre>

<hr>
<h2 id='pigs1'>Means and sample sizes for GRIM-testing</h2><span id='topic+pigs1'></span>

<h3>Description</h3>

<p>A fictional dataset with means and sample sizes of flying pigs. It can be
used to demonstrate the functionality of <code><a href="#topic+grim_map">grim_map()</a></code> and functions
building up on it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs1
</code></pre>


<h3>Format</h3>

<p>A tibble (data frame) with 12 rows and 2 columns. The columns are:
</p>

<dl>
<dt>x</dt><dd><p>String. Means.</p>
</dd>
<dt>n</dt><dd><p>Numeric. Sample sizes.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A tibble (data frame).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pigs2">pigs2</a></code> for GRIM-testing percentages instead of means, <code><a href="#topic+pigs3">pigs3</a></code>
for DEBIT-testing, and <code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates.
</p>
<p><code><a href="#topic+pigs2">pigs2</a></code> for GRIM-testing percentages instead of means, <code><a href="#topic+pigs3">pigs3</a></code>
for DEBIT-testing, <code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates, and <code><a href="#topic+pigs5">pigs5</a></code> for
GRIMMER-testing.
</p>

<hr>
<h2 id='pigs2'>Percentages and sample sizes for GRIM-testing</h2><span id='topic+pigs2'></span>

<h3>Description</h3>

<p>A fictional dataset with percentages and sample sizes of flying pigs. It can
be used to demonstrate the functionality of <code>grim_map()</code>, particularly its
<code>percent</code> argument, and functions building up on it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs2
</code></pre>


<h3>Format</h3>

<p>A tibble (data frame) with 6 rows and 2 columns. The columns are:
</p>

<dl>
<dt>x</dt><dd><p>String. Percentages.</p>
</dd>
<dt>n</dt><dd><p>Numeric. Sample sizes.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A tibble (data frame).
</p>


<h3>See Also</h3>

<p><code>pigs1</code> for GRIM-testing means instead of percentages, <code><a href="#topic+pigs3">pigs3</a></code> for
DEBIT-testing, and <code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates.
</p>
<p><code>pigs1</code> for GRIM-testing means, <code><a href="#topic+pigs3">pigs3</a></code> for DEBIT-testing,
<code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates, and <code><a href="#topic+pigs5">pigs5</a></code> for GRIMMER-testing.
</p>

<hr>
<h2 id='pigs3'>Binary means and standard deviations for using DEBIT</h2><span id='topic+pigs3'></span>

<h3>Description</h3>

<p>A fictional dataset with means and standard deviations from a binary
distribution related to flying pigs. It can be used to demonstrate the
functionality of <code>debit_map()</code> and functions building up on it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs3
</code></pre>


<h3>Format</h3>

<p>A tibble (data frame) with 7 rows and 3 columns. The columns are:
</p>

<dl>
<dt>x</dt><dd><p>String. Means.</p>
</dd>
<dt>sd</dt><dd><p>String. Standard deviations.</p>
</dd>
<dt>n</dt><dd><p>Numeric. Sample sizes.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A tibble (data frame).
</p>


<h3>See Also</h3>

<p><code>pigs1</code> for GRIM-testing means, <code><a href="#topic+pigs2">pigs2</a></code> for GRIM-testing
percentages, and <code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates.
</p>
<p><code>pigs1</code> for GRIM-testing means, <code><a href="#topic+pigs2">pigs2</a></code> for GRIM-testing
percentages instead of means, <code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates, and
<code><a href="#topic+pigs5">pigs5</a></code> for GRIMMER-testing.
</p>

<hr>
<h2 id='pigs4'>Data with duplications</h2><span id='topic+pigs4'></span>

<h3>Description</h3>

<p>A fictional dataset with observations of flying pigs. It contains multiple
duplicates. The dataset can be used to demonstrate the functionality of
<code style="white-space: pre;">&#8288;duplicate_*()&#8288;</code> functions such as <code>duplicate_count()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs4
</code></pre>


<h3>Format</h3>

<p>A tibble (data frame) with 5 rows and 3 columns, describing various
body measures of the fictional pigs. The columns are:
</p>

<dl>
<dt>snout</dt><dd><p>String. Snout width.</p>
</dd>
<dt>tail</dt><dd><p>String. Tail length.</p>
</dd>
<dt>wings</dt><dd><p>String. Wingspan.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A tibble (data frame).
</p>


<h3>See Also</h3>

<p><code>pigs1</code> for GRIM-testing means, <code><a href="#topic+pigs2">pigs2</a></code> for GRIM-testing
percentages, <code><a href="#topic+pigs3">pigs3</a></code> for using DEBIT, and <code><a href="#topic+pigs5">pigs5</a></code> for GRIMMER-testing.
</p>

<hr>
<h2 id='pigs5'>Means, SDs, and sample sizes for GRIMMER-testing</h2><span id='topic+pigs5'></span>

<h3>Description</h3>

<p>A fictional dataset with means, standard deviations (SDs), and sample sizes
of flying pigs. It can be used to demonstrate the functionality of
<code>grimmer_map()</code> and functions building up on it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs5
</code></pre>


<h3>Format</h3>

<p>A tibble (data frame) with 12 rows and 3 columns. The columns are:
</p>

<dl>
<dt>x</dt><dd><p>String. Means.</p>
</dd>
<dt>sd</dt><dd><p>String. Standard deviations.</p>
</dd>
<dt>n</dt><dd><p>Numeric. Sample sizes.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A tibble (data frame).
</p>


<h3>See Also</h3>

<p><code>pigs1</code> for (only) GRIM-testing the same means as here, <code><a href="#topic+pigs2">pigs2</a></code>
for GRIM-testing percentages instead of means, <code><a href="#topic+pigs3">pigs3</a></code> for DEBIT-testing,
and <code><a href="#topic+pigs4">pigs4</a></code> for detecting duplicates.
</p>

<hr>
<h2 id='reround'>General interface to reconstructing rounded numbers</h2><span id='topic+reround'></span>

<h3>Description</h3>

<p><code>reround()</code> takes one or more intermediate reconstructed values
and rounds them in some specific way &ndash; namely, the way they are supposed
to have been rounded originally, in the process that generated the reported
values.
</p>
<p>This function provides an interface to all of scrutiny's rounding functions
as well as <code><a href="base.html#topic+Round">base::round()</a></code>. It is used as a helper within <code><a href="#topic+grim">grim()</a></code>,
<code><a href="#topic+grimmer">grimmer()</a></code>, and <code><a href="#topic+debit">debit()</a></code>; and it might find use in other places for
consistency testing or reconstruction of statistical analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reround(
  x,
  digits = 0L,
  rounding = "up_or_down",
  threshold = 5,
  symmetric = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reround_+3A_x">x</code></td>
<td>
<p>Numeric. Vector of possibly original values.</p>
</td></tr>
<tr><td><code id="reround_+3A_digits">digits</code></td>
<td>
<p>Integer. Number of decimal places in the reported key values
(i.e., mean or percentage within <code><a href="#topic+grim">grim()</a></code>, or standard deviation within
<code><a href="#topic+grimmer">grimmer()</a></code>).</p>
</td></tr>
<tr><td><code id="reround_+3A_rounding">rounding</code></td>
<td>
<p>String. The rounding method that is supposed to have been
used originally. See <code>vignette("rounding-options")</code>. Default is
<code>"up_or_down"</code>, which returns two values: <code>x</code> rounded up <em>and</em> down.</p>
</td></tr>
<tr><td><code id="reround_+3A_threshold">threshold</code></td>
<td>
<p>Integer. If <code>rounding</code> is set to <code>"up_from"</code>, <code>"down_from"</code>,
or <code>"up_from_or_down_from"</code>, <code>threshold</code> must be set to the number from
which the reconstructed values should then be rounded up or down. Otherwise
irrelevant. Default is <code>5</code>.</p>
</td></tr>
<tr><td><code id="reround_+3A_symmetric">symmetric</code></td>
<td>
<p>Logical. Set <code>symmetric</code> to <code>TRUE</code> if the rounding of
negative numbers with <code>"up_or_down"</code>, <code>"up"</code>, <code>"down"</code>,
<code>"up_from_or_down_from"</code>, <code>"up_from"</code>, or <code>"down_from"</code> should mirror that
of positive numbers so that their absolute values are always equal.
Otherwise irrelevant. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>reround()</code> internally calls the appropriate rounding function(s)
determined by the <code>rounding</code> argument. See <code>vignette("rounding-options")</code>
for a complete list of values that <code>rounding</code> can take.
</p>
<p>For the specific rounding functions themselves, see documentation at
<code><a href="#topic+round_up">round_up()</a></code>, <code><a href="#topic+round_ceiling">round_ceiling()</a></code>, and <code><a href="base.html#topic+Round">base::round()</a></code>.
</p>


<h3>Value</h3>

<p>Numeric vector of length 1 or 2. (It has length 1 unless <code>rounding</code>
is <code>"up_or_down"</code>, <code>"up_from_or_down_from"</code>, or<code>"ceiling_or_floor"</code>, in
which case it has length 2.)
</p>

<hr>
<h2 id='restore_zeros'>Restore trailing zeros</h2><span id='topic+restore_zeros'></span><span id='topic+restore_zeros_df'></span>

<h3>Description</h3>

<p><code>restore_zeros()</code> takes a vector with values that might have
lost trailing zeros, most likely from being registered as numeric. It turns
each value into a string and adds trailing zeros until the mantissa hits
some limit.
</p>
<p>The default for that limit is the number of digits in the longest mantissa
of the vector's values. The length of the integer part plays no role.
</p>
<p>Don't rely on the default limit without checking: The original width could
have been larger because the longest extant mantissa might itself have lost
trailing zeros.
</p>
<p><code>restore_zeros_df()</code> is a variant for data frames. It wraps
<code>restore_zeros()</code> and, by default, applies it to all columns that are
coercible to numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>restore_zeros(
  x,
  width = NULL,
  sep_in = "\\.",
  sep_out = sep_in,
  sep = deprecated()
)

restore_zeros_df(
  data,
  cols = everything(),
  check_numeric_like = TRUE,
  check_decimals = FALSE,
  width = NULL,
  sep_in = "\\.",
  sep_out = NULL,
  sep = deprecated(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="restore_zeros_+3A_x">x</code></td>
<td>
<p>Numeric (or string coercible to numeric). Vector of numbers that
might have lost trailing zeros.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_width">width</code></td>
<td>
<p>Integer. Number of decimal places the mantissas should have,
including the restored zeros. Default is <code>NULL</code>, in which case the number
of characters in the longest mantissa will be used instead.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_sep_in">sep_in</code></td>
<td>
<p>Substring that separates the input's mantissa from its integer
part. Default is <code>"\\."</code>, which renders a decimal point.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_sep_out">sep_out</code></td>
<td>
<p>Substring that will be returned in the output to separate the
mantissa from the integer part. By default, <code>sep_out</code> is the same as
<code>sep_in</code>.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_sep">sep</code></td>
<td>
<p>[<a href="base.html#topic+Deprecated">Deprecated</a>] Use <code>sep_in</code>, not <code>sep</code>. If <code>sep</code> is specified
nonetheless, <code>sep_in</code> takes on <code>sep</code>'s value.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_data">data</code></td>
<td>
<p>Data frame or matrix. Only in <code>restore_zeros_df()</code>, and instead
of <code>x</code>.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_cols">cols</code></td>
<td>
<p>Only in <code>restore_zeros_df()</code>. Select columns from <code>data</code> using
<a href="https://tidyselect.r-lib.org/reference/language.html">tidyselect</a>.
Default is <code>everything()</code>, which selects all columns that pass the test of
<code>check_numeric_like</code>.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_check_numeric_like">check_numeric_like</code></td>
<td>
<p>Logical. Only in <code>restore_zeros_df()</code>. If <code>TRUE</code>
(the default), the function will skip columns that are not numeric or
coercible to numeric, as determined by <code><a href="#topic+is_numeric_like">is_numeric_like()</a></code>.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_check_decimals">check_decimals</code></td>
<td>
<p>Logical. Only in <code>restore_zeros_df()</code>. If set to
<code>TRUE</code>, the function will skip columns where no values have any decimal
places. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="restore_zeros_+3A_...">...</code></td>
<td>
<p>Only in <code>restore_zeros_df()</code>. These dots must be empty.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions exploit the fact that groups of summary values such
as means or percentages are often reported to the same number of decimal
places. If such a number is known but values were not entered as strings,
trailing zeros will be lost. In this case, <code>restore_zeros()</code> or
<code>restore_zeros_df()</code> will be helpful to prepare data for consistency
testing functions such as <code><a href="#topic+grim_map">grim_map()</a></code> or <code><a href="#topic+grimmer_map">grimmer_map()</a></code>.
</p>


<h3>Value</h3>


<ul>
<li><p> For <code>restore_zeros()</code>, a string vector. At least some of the strings
will have newly restored zeros, unless (1) all input values had the same
number of decimal places, and (2) <code>width</code> was not specified as a number
greater than that single number of decimal places.
</p>
</li>
<li><p> For <code>restore_zeros_df()</code>, a data frame.
</p>
</li></ul>



<h3>Displaying decimal places</h3>

<p>You might not see all decimal places of
numeric values in a vector, and consequently wonder if <code>restore_zeros()</code>,
when applied to the vector, adds too many zeros. That is because displayed
numbers, unlike stored numbers, are often rounded.
</p>
<p>For a vector <code>x</code>, you can count the characters of the longest mantissa from
among its values like this:
</p>
<p><code>x %&gt;% decimal_places() %&gt;% max()</code>
</p>


<h3>See Also</h3>

<p>Wrapped functions: <code><a href="base.html#topic+sprintf">sprintf()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># By default, the target width is that of
# the longest mantissa:
vec &lt;- c(212, 75.38, 4.9625)
vec %&gt;%
  restore_zeros()

# Alternatively, supply a number via `width`:
vec %&gt;%
  restore_zeros(width = 6)

# For better printing:
iris &lt;- tibble::as_tibble(iris)

# Apply `restore_zeros()` to all numeric
# columns, but not to the factor column:
iris %&gt;%
  restore_zeros_df()

# Select columns as in `dplyr::select()`:
iris %&gt;%
  restore_zeros_df(starts_with("Sepal"), width = 3)
</code></pre>

<hr>
<h2 id='reverse_map_seq'>Reverse the <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> process</h2><span id='topic+reverse_map_seq'></span>

<h3>Description</h3>

<p><code>reverse_map_seq()</code> takes the output of a function created by
<code><a href="#topic+function_map_seq">function_map_seq()</a></code> and reconstructs the original data frame.
</p>
<p>See <code><a href="#topic+audit_seq">audit_seq()</a></code>, which takes <code>reverse_map_seq()</code> as a basis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reverse_map_seq(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reverse_map_seq_+3A_data">data</code></td>
<td>
<p>Data frame that inherits the <code>"scr_map_seq"</code> class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The reconstructed tibble (data frame) which a factory-made
<code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> function took as its <code>data</code> argument.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Originally reported summary data...
pigs1

# ...GRIM-tested with varying inputs...
out &lt;- grim_map_seq(pigs1, include_consistent = TRUE)

# ...and faithfully reconstructed:
reverse_map_seq(out)
</code></pre>

<hr>
<h2 id='reverse_map_total_n'>Reverse the <code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> process</h2><span id='topic+reverse_map_total_n'></span>

<h3>Description</h3>

<p><code>reverse_map_total_n()</code> takes the output of a function created
by <code><a href="#topic+function_map_total_n">function_map_total_n()</a></code> and reconstructs the original data frame.
</p>
<p>See <code><a href="#topic+audit_total_n">audit_total_n()</a></code>, which takes <code>reverse_map_total_n()</code> as a basis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reverse_map_total_n(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reverse_map_total_n_+3A_data">data</code></td>
<td>
<p>Data frame that inherits the <code>"scr_map_total_n"</code> class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The reconstructed tibble (data frame) which a factory-made
<code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> function took as its <code>data</code> argument.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Originally reported summary data...
df &lt;- tibble::tribble(
  ~x1,    ~x2,   ~n,
  "3.43", "5.28", 90,
  "2.97", "4.42", 103
)
df

# ...GRIM-tested with dispersed `n` values...
out &lt;- grim_map_total_n(df)
out

# ...and faithfully reconstructed:
reverse_map_total_n(out)
</code></pre>

<hr>
<h2 id='rounding_bias'>Compute rounding bias</h2><span id='topic+rounding_bias'></span>

<h3>Description</h3>

<p>Rounding often leads to bias, such that the mean of a rounded
distribution is different from the mean of the original distribution. Call
<code>rounding_bias()</code> to compute the amount of this bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rounding_bias(
  x,
  digits,
  rounding = "up",
  threshold = 5,
  symmetric = FALSE,
  mean = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rounding_bias_+3A_x">x</code></td>
<td>
<p>Numeric or string coercible to numeric.</p>
</td></tr>
<tr><td><code id="rounding_bias_+3A_digits">digits</code></td>
<td>
<p>Integer. Number of decimal digits to which <code>x</code> will be rounded.</p>
</td></tr>
<tr><td><code id="rounding_bias_+3A_rounding">rounding</code></td>
<td>
<p>String. Rounding procedure that will be applied to <code>x</code>. See
<code>vignette("rounding-options")</code>. Default is <code>"up"</code>.</p>
</td></tr>
<tr><td><code id="rounding_bias_+3A_threshold">threshold</code>, <code id="rounding_bias_+3A_symmetric">symmetric</code></td>
<td>
<p>Further arguments passed down to <code><a href="#topic+reround">reround()</a></code>.</p>
</td></tr>
<tr><td><code id="rounding_bias_+3A_mean">mean</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), the mean total of bias will be
returned. Set <code>mean</code> to <code>FALSE</code> to get a vector of individual biases the
length of <code>x</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias is calculated by subtracting the original vector, <code>x</code>, from a
vector rounded in the specified way.
</p>
<p>The function passes all arguments except for <code>mean</code> down to <code><a href="#topic+reround">reround()</a></code>.
Other than there, however, <code>rounding</code> is <code>"up"</code> by default, and it can't be
set to <code>"up_or_down"</code>, <code>"up_from_or_down_from"</code>, or<code>"ceiling_or_floor"</code>.
</p>


<h3>Value</h3>

<p>Numeric. By default of <code>mean</code>, the length is 1; otherwise, it is the
same length as <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Define example vector:
vec &lt;- seq_distance(0.01, string_output = FALSE)
vec

# The default rounds `x` up from 5:
rounding_bias(x = vec, digits = 1)

# Other rounding procedures are supported,
# such as rounding down from 5...
rounding_bias(x = vec, digits = 1, rounding = "down")

# ...or rounding to even with `base::round()`:
rounding_bias(x = vec, digits = 1, rounding = "even")
</code></pre>

<hr>
<h2 id='rounding-common'>Common rounding procedures</h2><span id='topic+rounding-common'></span><span id='topic+round_up_from'></span><span id='topic+round_down_from'></span><span id='topic+round_up'></span><span id='topic+round_down'></span>

<h3>Description</h3>

<p><code>round_up()</code> rounds up from 5, <code>round_down()</code> rounds down from
5. Otherwise, both functions work like <code><a href="base.html#topic+Round">base::round()</a></code>.
</p>
<p><code>round_up()</code> and <code>round_down()</code> are special cases of <code>round_up_from()</code> and
<code>round_down_from()</code>, which allow users to choose custom thresholds for
rounding up or down, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>round_up_from(x, digits = 0L, threshold, symmetric = FALSE)

round_down_from(x, digits = 0L, threshold, symmetric = FALSE)

round_up(x, digits = 0L, symmetric = FALSE)

round_down(x, digits = 0L, symmetric = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rounding-common_+3A_x">x</code></td>
<td>
<p>Numeric. The decimal number to round.</p>
</td></tr>
<tr><td><code id="rounding-common_+3A_digits">digits</code></td>
<td>
<p>Integer. Number of digits to round <code>x</code> to. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="rounding-common_+3A_threshold">threshold</code></td>
<td>
<p>Integer. Only in <code>round_up_from()</code> and <code>round_down_from()</code>.
Threshold for rounding up or down, respectively. Value is <code>5</code> in
<code>round_up()</code>'s internal call to <code>round_up_from()</code> and in <code>round_down()</code>'s
internal call to <code>round_down_from()</code>.</p>
</td></tr>
<tr><td><code id="rounding-common_+3A_symmetric">symmetric</code></td>
<td>
<p>Logical. Set <code>symmetric</code> to <code>TRUE</code> if the rounding of
negative numbers should mirror that of positive numbers so that their
absolute values are equal. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions differ from <code><a href="base.html#topic+Round">base::round()</a></code> mainly insofar as the
decision about rounding 5 up or down is not based on the integer portion of
<code>x</code> (i.e., no &quot;rounding to even&quot;). Instead, in <code>round_up_from()</code>, that
decision is determined by the <code>threshold</code> argument for rounding up, and
likewise with <code>round_down_from()</code>. The threshold is constant at <code>5</code> for
<code>round_up()</code> and <code>round_down()</code>.
</p>
<p>As a result, these functions are more predictable and less prone to
floating-point number quirks than <code><a href="base.html#topic+Round">base::round()</a></code>. Compare <code>round_down()</code>
and <code><a href="base.html#topic+Round">base::round()</a></code> in the data frame for rounding 5 created in the
Examples section below: <code>round_down()</code> yields a continuous sequence of
final digits from 0 to 9, whereas <code><a href="base.html#topic+Round">base::round()</a></code> behaves in a way that
can only be explained by floating point issues.
</p>
<p>However, this surprising behavior on the part of <code><a href="base.html#topic+Round">base::round()</a></code> is not
necessarily a flaw (see its documentation, or this vignette:
https://rpubs.com/maechler/Rounding). In the present version of R (4.0.0 or
later), <code><a href="base.html#topic+Round">base::round()</a></code> works fine, and the functions presented here are
not meant to replace it. Their main purpose as helpers within scrutiny is
to reconstruct the computations of researchers who might have used
different software. See <code>vignette("rounding-options")</code>.
</p>


<h3>Value</h3>

<p>Numeric. <code>x</code> rounded to <code>digits</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+round_ceiling">round_ceiling()</a></code> always rounds up, <code><a href="#topic+round_floor">round_floor()</a></code> always
rounds down, <code><a href="#topic+round_trunc">round_trunc()</a></code> always rounds toward 0, and
<code><a href="#topic+round_anti_trunc">round_anti_trunc()</a></code> always round away from 0.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Both `round_up()` and `round_down()` work like
# `base::round()` unless the closest digit to be
# cut off by rounding is 5:

   round_up(x = 9.273, digits = 1)     # 7 cut off
 round_down(x = 9.273, digits = 1)     # 7 cut off
base::round(x = 9.273, digits = 1)     # 7 cut off

   round_up(x = 7.584, digits = 2)     # 4 cut off
 round_down(x = 7.584, digits = 2)     # 4 cut off
base::round(x = 7.584, digits = 2)     # 4 cut off


# Here is the borderline case of 5 rounded by
# `round_up()`, `round_down()`, and `base::round()`:

original &lt;- c(    # Define example values
  0.05, 0.15, 0.25, 0.35, 0.45,
  0.55, 0.65, 0.75, 0.85, 0.95
)
tibble::tibble(   # Output table
  original,
  round_up = round_up(x = original, digits = 1),
  round_down = round_down(x = original, digits = 1),
  base_round = base::round(x = original, digits = 1)
)

# (Note: Defining `original` as `seq(0.05:0.95, by = 0.1)`
# would lead to wrong results unless `original` is rounded
# to 2 or so digits before it's rounded to 1.)
</code></pre>

<hr>
<h2 id='rounding-uncommon'>Uncommon rounding procedures</h2><span id='topic+rounding-uncommon'></span><span id='topic+round_ceiling'></span><span id='topic+round_floor'></span><span id='topic+round_trunc'></span><span id='topic+anti_trunc'></span><span id='topic+round_anti_trunc'></span>

<h3>Description</h3>

<p>Always round up, down, toward zero, or away from it:
</p>

<ul>
<li> <p><code>round_ceiling()</code> always rounds up.
</p>
</li>
<li> <p><code>round_floor()</code> always rounds down.
</p>
</li>
<li> <p><code>round_trunc()</code> always rounds toward zero.
</p>
</li>
<li> <p><code>round_anti_trunc()</code> always rounds away from zero. (<code>0</code> itself is
rounded to <code>1</code>.)
</p>
</li>
<li> <p><code>anti_trunc()</code> does not round but otherwise works like
<code>round_anti_trunc()</code>.
</p>
</li></ul>

<p>Despite not being widely used, they are featured here in case they are
needed for reconstruction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>round_ceiling(x, digits = 0L)

round_floor(x, digits = 0L)

round_trunc(x, digits = 0L)

anti_trunc(x)

round_anti_trunc(x, digits = 0L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rounding-uncommon_+3A_x">x</code></td>
<td>
<p>Numeric. The decimal number to round.</p>
</td></tr>
<tr><td><code id="rounding-uncommon_+3A_digits">digits</code></td>
<td>
<p>Integer. Number of digits to round <code>x</code> to. Default is <code>0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>round_ceiling()</code>, <code>round_floor()</code>, and <code>round_trunc()</code> generalize
the base R functions <code><a href="base.html#topic+ceiling">ceiling()</a></code>, <code><a href="base.html#topic+floor">floor()</a></code>, and <code><a href="base.html#topic+trunc">trunc()</a></code>, and
include them as special cases: With the default value for <code>digits</code>, 0,
these <code style="white-space: pre;">&#8288;round_*&#8288;</code> functions are equivalent to their respective base
counterparts.
</p>
<p>The last <code style="white-space: pre;">&#8288;round_*&#8288;</code> function, <code>round_anti_trunc()</code>, generalizes another
function presented here: <code>anti_trunc()</code> works like <code>trunc()</code> except it
moves away from 0, rather than towards it. That is, whereas <code>trunc()</code>
minimizes the absolute value of <code>x</code> (as compared to the other rounding
functions), <code>anti_trunc()</code> maximizes it. <code>anti_trunc(x)</code> is therefore equal
to <code>trunc(x)</code> <code> + 1</code> if <code>x</code> is positive, and to <code>trunc(x) - 1</code> if <code>x</code> is
negative.
</p>
<p><code>round_anti_trunc()</code>, then, generalizes <code>anti_trunc()</code> just as
<code>round_ceiling()</code> generalizes <code><a href="base.html#topic+ceiling">ceiling()</a></code>, etc.
</p>
<p>Moreover, <code>round_trunc()</code> is equivalent to <code>round_floor()</code> for positive
numbers and to <code>round_ceiling()</code> for negative numbers. The reverse is again
true for <code>round_anti_trunc()</code>: It is equivalent to <code>round_ceiling()</code> for
positive numbers and to <code>round_floor()</code> for negative numbers.
</p>


<h3>Value</h3>

<p>Numeric. <code>x</code> rounded to <code>digits</code> (except for <code>anti_trunc()</code>, which
has no <code>digits</code> argument).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+round_up">round_up()</a></code> and <code><a href="#topic+round_down">round_down()</a></code> round up or down from 5,
respectively. <code><a href="#topic+round_up_from">round_up_from()</a></code> and <code><a href="#topic+round_down_from">round_down_from()</a></code> allow users to
specify custom thresholds for rounding up or down.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Always round up:
round_ceiling(x = 4.52, digits = 1)        # 2 cut off

# Always round down:
round_floor(x = 4.67, digits = 1)          # 7 cut off

# Always round toward 0:
round_trunc(8.439, digits = 2)             # 9 cut off
round_trunc(-8.439, digits = 2)            # 9 cut off

# Always round away from 0:
round_anti_trunc(x = 8.421, digits = 2)    # 1 cut off
round_anti_trunc(x = -8.421, digits = 2)   # 1 cut off
</code></pre>

<hr>
<h2 id='row_to_colnames'>Turn row values into column names</h2><span id='topic+row_to_colnames'></span>

<h3>Description</h3>

<p>Data frames sometimes have wrong column names, while the correct
column names are stored in one or more rows in the data frame itself. To
remedy this issue, call <code>row_to_colnames()</code> on the data frame: It replaces
the column names by the values of the specified rows (by default, only the
first one). These rows are then dropped by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>row_to_colnames(data, row = 1L, collapse = " ", drop = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="row_to_colnames_+3A_data">data</code></td>
<td>
<p>Data frame or matrix.</p>
</td></tr>
<tr><td><code id="row_to_colnames_+3A_row">row</code></td>
<td>
<p>Integer. Position of the rows (one or more) that jointly contain
the correct column names. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="row_to_colnames_+3A_collapse">collapse</code></td>
<td>
<p>String. If the length of <code>row</code> is greater than 1, each new
column name will be that many row values pasted together. <code>collapse</code>, then,
is the substring between two former row values in the final column names.
Default is <code>" "</code> (a space).</p>
</td></tr>
<tr><td><code id="row_to_colnames_+3A_drop">drop</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), the rows specified with <code>row</code>
are removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If multiple rows are specified, the row values for each individual
column are pasted together. Some special characters might then be missing.
</p>
<p>This function might be useful when importing tables from PDF, e.g. with
<a href="https://cran.r-project.org/package=tabulizer">tabulizer</a>. In R, these
data frames (converted from matrices) do sometimes have the issue described
above.
</p>


<h3>Value</h3>

<p>A tibble (data frame).
</p>


<h3>See Also</h3>

<p><code><a href="unheadr.html#topic+mash_colnames">unheadr::mash_colnames()</a></code>, a more sophisticated solution to the
same problem.
</p>

<hr>
<h2 id='sd-binary'>Standard deviation of binary data</h2><span id='topic+sd-binary'></span><span id='topic+sd_binary_groups'></span><span id='topic+sd_binary_0_n'></span><span id='topic+sd_binary_1_n'></span><span id='topic+sd_binary_mean_n'></span>

<h3>Description</h3>

<p>Compute the sample SD of binary data (i.e., only 0 and 1 values)
in either of four ways, each based on different inputs:
</p>

<ul>
<li> <p><code>sd_binary_groups()</code> takes the cell sizes of both groups, those coded
as 0 and those coded as 1.
</p>
</li>
<li> <p><code>sd_binary_0_n()</code> takes the cell size of the group coded as 0 and the total
sample size.
</p>
</li>
<li> <p><code>sd_binary_1_n()</code> takes the cell size of the group coded as 1 and the total
sample size.
</p>
</li>
<li> <p><code>sd_binary_mean_n()</code> takes the mean and the total sample size.
</p>
</li></ul>

<p>These functions are used as helpers inside <code><a href="#topic+debit">debit()</a></code>, and consequently
<code><a href="#topic+debit_map">debit_map()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sd_binary_groups(group_0, group_1)

sd_binary_0_n(group_0, n)

sd_binary_1_n(group_1, n)

sd_binary_mean_n(mean, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sd-binary_+3A_group_0">group_0</code></td>
<td>
<p>Integer. Cell size of the group coded as 0.</p>
</td></tr>
<tr><td><code id="sd-binary_+3A_group_1">group_1</code></td>
<td>
<p>Integer. Cell size of the group coded as 1.</p>
</td></tr>
<tr><td><code id="sd-binary_+3A_n">n</code></td>
<td>
<p>Integer. Total sample size.</p>
</td></tr>
<tr><td><code id="sd-binary_+3A_mean">mean</code></td>
<td>
<p>Numeric. Mean of the binary data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric. Sample standard deviation.
</p>


<h3>References</h3>

<p>Heathers, James A. J., and Brown, Nicholas J. L. 2019. DEBIT: A
Simple Consistency Test For Binary Data. https://osf.io/5vb3u/.
</p>


<h3>See Also</h3>

<p><code>is_subset_of_vals(x, 0, 1)</code> checks whether <code>x</code> (a list or atomic
vector) contains nothing but binary numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># If 127 values are coded as 0 and 153 as 1...
sd_binary_groups(group_0 = 127, group_1 = 153)

# ...so that n = 280:
sd_binary_0_n(group_0 = 127, n = 280)
sd_binary_1_n(group_1 = 153, n = 280)

# If only the mean and total sample size are
# given, or these are more convenient to use,
# they still lead to the same result as above
# if the mean is given with a sufficiently
# large number of decimal places:
sd_binary_mean_n(mean = 0.5464286, n = 280)
</code></pre>

<hr>
<h2 id='seq_disperse'>Sequence generation with dispersion at decimal level</h2><span id='topic+seq_disperse'></span><span id='topic+seq_disperse_df'></span>

<h3>Description</h3>

<p><code>seq_disperse()</code> creates a sequence around a given number. It
goes a specified number of steps up and down from it. Step size depends on
the number's decimal places. For example, <code>7.93</code> will be surrounded by
values like <code>7.91</code>, <code>7.92</code>, and <code>7.94</code>, <code>7.95</code>, etc.
</p>
<p><code>seq_disperse_df()</code> is a variant that creates a data frame. Further columns
can be added as in <code><a href="tibble.html#topic+tibble">tibble::tibble()</a></code>. Regular arguments are the same as
in <code>seq_disperse()</code>, but with a dot before each.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_disperse(
  from,
  by = NULL,
  dispersion = 1:5,
  offset_from = 0L,
  out_min = "auto",
  out_max = NULL,
  string_output = TRUE,
  include_reported = TRUE,
  track_diff_var = FALSE,
  track_var_change = deprecated()
)

seq_disperse_df(
  .from,
  .by = NULL,
  ...,
  .dispersion = 1:5,
  .offset_from = 0L,
  .out_min = "auto",
  .out_max = NULL,
  .string_output = TRUE,
  .include_reported = TRUE,
  .track_diff_var = FALSE,
  .track_var_change = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq_disperse_+3A_from">from</code>, <code id="seq_disperse_+3A_.from">.from</code></td>
<td>
<p>Numeric (or string coercible to numeric). Starting point of
the sequence.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_by">by</code>, <code id="seq_disperse_+3A_.by">.by</code></td>
<td>
<p>Numeric. Step size of the sequence. If not set, inferred
automatically. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_dispersion">dispersion</code>, <code id="seq_disperse_+3A_.dispersion">.dispersion</code></td>
<td>
<p>Numeric. Vector that determines the steps up
and down, starting at <code>from</code> (or <code>.from</code>, respectively) and proceeding on
the level of its last decimal place. Default is <code>1:5</code>, i.e., five steps up
and down.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_offset_from">offset_from</code>, <code id="seq_disperse_+3A_.offset_from">.offset_from</code></td>
<td>
<p>Integer. If set to a non-zero number, the
starting point will be offset by that many units on the level of the last
decimal digit. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_out_min">out_min</code>, <code id="seq_disperse_+3A_.out_min">.out_min</code>, <code id="seq_disperse_+3A_out_max">out_max</code>, <code id="seq_disperse_+3A_.out_max">.out_max</code></td>
<td>
<p>If specified, output will be
restricted so that it's not below <code>out_min</code> or above <code>out_max</code>. Defaults
are <code>"auto"</code> for <code>out_min</code>, i.e., a minimum of one decimal unit above zero;
and <code>NULL</code> for <code>out_max</code>, i.e., no maximum.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_string_output">string_output</code>, <code id="seq_disperse_+3A_.string_output">.string_output</code></td>
<td>
<p>Logical or string. If <code>TRUE</code> (the
default), the output is a string vector. Decimal places are then padded
with zeros to match <code>from</code>'s number of decimal places. <code>"auto"</code> works like
<code>TRUE</code> if and only if <code>from</code> (<code>.from</code>) is a string.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_include_reported">include_reported</code>, <code id="seq_disperse_+3A_.include_reported">.include_reported</code></td>
<td>
<p>Logical. Should <code>from</code> (<code>.from</code>)
itself be part of the sequence built around it? Default is <code>TRUE</code> for the
sake of continuity, but this can be misleading if the focus is on the
dispersed values, as opposed to the input.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_track_diff_var">track_diff_var</code>, <code id="seq_disperse_+3A_.track_diff_var">.track_diff_var</code></td>
<td>
<p>Logical. In <code>seq_disperse()</code>, ignore
this argument. In <code>seq_disperse_df()</code>, default is <code>TRUE</code>, which creates the
<code>"diff_var"</code> output column.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_track_var_change">track_var_change</code>, <code id="seq_disperse_+3A_.track_var_change">.track_var_change</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
Renamed to <code>track_diff_var</code> / <code>.track_diff_var</code>.</p>
</td></tr>
<tr><td><code id="seq_disperse_+3A_...">...</code></td>
<td>
<p>Further columns, added as in <code><a href="tibble.html#topic+tibble">tibble::tibble()</a></code>. Only in
<code>seq_disperse_df()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike <code><a href="#topic+seq_endpoint">seq_endpoint()</a></code> and friends, the present functions don't
necessarily return continuous or even regular sequences. The greater
flexibility is due to the <code>dispersion</code> (<code>.dispersion</code>) argument, which
takes any numeric vector. By default, however, the output sequence is
regular and continuous.
</p>
<p>Underlying this difference is the fact that <code>seq_disperse()</code> and
<code>seq_disperse_df()</code> do not wrap around <code><a href="base.html#topic+seq">base::seq()</a></code>, although they are
otherwise similar to <code><a href="#topic+seq_endpoint">seq_endpoint()</a></code> and friends.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>seq_disperse()</code> returns a string vector by default
(<code>string_output = TRUE</code>) and a numeric vector otherwise.
</p>
</li>
<li> <p><code>seq_disperse_df()</code> returns a tibble (data frame). The sequence is stored
in the <code>x</code> column. <code>x</code> is string by default (<code>.string_output = TRUE</code>),
numeric otherwise. Other columns might have been added via the dots
(<code>...</code>).
</p>
</li></ul>



<h3>See Also</h3>

<p>Conceptually, <code>seq_disperse()</code> is a blend of two function families:
those around <code><a href="#topic+seq_endpoint">seq_endpoint()</a></code> and those around <code><a href="#topic+disperse">disperse()</a></code>. The
present functions were originally conceived for <code>seq_disperse_df()</code> to be a
helper within the <code><a href="#topic+function_map_seq">function_map_seq()</a></code> implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Basic usage:
seq_disperse(from = 4.02)

# If trailing zeros don't matter,
# the output can be numeric:
seq_disperse(from = 4.02, string_output = FALSE)

# Control steps up and down with
# `dispersion` (default is `1:5`):
seq_disperse(from = 4.02, dispersion = 1:10)

# Sequences might be discontinuous...
disp1 &lt;- seq(from = 2, to = 10, by = 2)
seq_disperse(from = 4.02, dispersion = disp1)

# ...or even irregular:
disp2 &lt;- c(2, 3, 7)
seq_disperse(from = 4.02, dispersion = disp2)

# The data fame variant supports further
# columns added as in `tibble::tibble()`:
seq_disperse_df(.from = 4.02, n = 45)
</code></pre>

<hr>
<h2 id='seq_length'>Set sequence length</h2><span id='topic+seq_length'></span><span id='topic+seq_length+3C-'></span>

<h3>Description</h3>

<p><code>seq_length()</code> seamlessly extends or shortens a linear
sequence using the sequence's own step size.
</p>
<p>Alternatively, you can directly set the length of a linear sequence in this
way: <code>seq_length(x) &lt;- value</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_length(x, value)

seq_length(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq_length_+3A_x">x</code></td>
<td>
<p>Numeric or coercible to numeric. <code>x</code> must be linear, i.e., each
of its elements must differ from the next by the same amount.</p>
</td></tr>
<tr><td><code id="seq_length_+3A_value">value</code></td>
<td>
<p>Numeric (whole number, length 1). The new length for <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the same type as <code>x</code>, with length <code>value</code>.
</p>

<ul>
<li><p> If <code>value &gt; length(x)</code>, all original element of <code>x</code> are preserved. A number
of new elements equal to the difference is appended at the end.
</p>
</li>
<li><p> If <code>value == length(x)</code>, nothing changes.
</p>
</li>
<li><p> If <code>value &lt; length(x)</code>, a number of elements of <code>x</code> equal to the difference
is removed from the end.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 3:7

# Increase the length of `x` from 5 to 10:
seq_length(x, 10)

# Modify `x` directly (but get
# the same results otherwise):
seq_length(x) &lt;- 10
x

# Likewise, decrease the length:
x &lt;- 3:7
seq_length(x, 2)

seq_length(x) &lt;- 2
x

# The functions are sensitive to decimal levels.
# They also return a string vector if (and only if)
# `x` is a string vector:
x &lt;- seq_endpoint(from = 0, to = 0.5)
x

seq_length(x, 10)

seq_length(x) &lt;- 10
x

# Same with decreasing the length:
seq_length(x, 2)

seq_length(x) &lt;- 2
x
</code></pre>

<hr>
<h2 id='seq_test_ranking'>Rank sequence test results</h2><span id='topic+seq_test_ranking'></span>

<h3>Description</h3>

<p>Run this function after generating a sequence with
<code>seq_endpoint_df()</code> or <code>seq_distance_df()</code> and testing it with one of
scrutiny's mapping functions, such as <code>grim_map()</code>. It will rank the test's
consistent and inconsistent results by their positions in the sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_test_ranking(x, explain = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq_test_ranking_+3A_x">x</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="seq_test_ranking_+3A_explain">explain</code></td>
<td>
<p>If <code>TRUE</code> (the default), results come with an explanation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function checks the provenance of the test results and throws a
warning if it's not correct.
</p>


<h3>Value</h3>

<p>A tibble (data frame). The function will also print an explanation of
the results. See examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seq_distance_df(.from = "0.00", n = 50) %&gt;%
  grim_map() %&gt;%
  seq_test_ranking()
</code></pre>

<hr>
<h2 id='seq-decimal'>Sequence generation at decimal level</h2><span id='topic+seq-decimal'></span><span id='topic+seq_endpoint'></span><span id='topic+seq_distance'></span><span id='topic+seq_endpoint_df'></span><span id='topic+seq_distance_df'></span>

<h3>Description</h3>

<p>Functions that provide a smooth interface to generating
sequences based on the input values' decimal depth. Each function creates a
sequence with a step size of one unit on the level of the input values'
ultimate decimal digit (e.g., <code>2.45</code>, <code>2.46</code>, <code>2.47</code>, ...):
</p>

<ul>
<li> <p><code>seq_endpoint()</code> creates a sequence from one input value to another. For
step size, it goes by the value with more decimal places.
</p>
</li>
<li> <p><code>seq_distance()</code> only takes the starting point and, instead of the
endpoint, the desired output length. For step size, it goes by the starting
point by default.
</p>
</li></ul>

<p><code>seq_endpoint_df()</code> and <code>seq_distance_df()</code> are variants that create a data
frame. Further columns can be added as in <code><a href="tibble.html#topic+tibble">tibble::tibble()</a></code>. Regular
arguments are the same as in the respective non-<code>df</code> function, but with a dot
before each.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_endpoint(from, to, offset_from = 0L, offset_to = 0L, string_output = TRUE)

seq_distance(
  from,
  by = NULL,
  length_out = 10L,
  dir = 1,
  offset_from = 0L,
  string_output = TRUE
)

seq_endpoint_df(
  .from,
  .to,
  ...,
  .offset_from = 0L,
  .offset_to = 0L,
  .string_output = TRUE
)

seq_distance_df(
  .from,
  .by = NULL,
  ...,
  .length_out = 10L,
  .dir = 1,
  .offset_from = 0L,
  .string_output = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq-decimal_+3A_from">from</code>, <code id="seq-decimal_+3A_.from">.from</code></td>
<td>
<p>Numeric (or string coercible to numeric). Starting point of
the sequence.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_to">to</code>, <code id="seq-decimal_+3A_.to">.to</code></td>
<td>
<p>Numeric (or string coercible to numeric). Endpoint of the
sequence. Only in <code>seq_endpoint()</code> and <code>seq_endpoint_df()</code>.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_offset_from">offset_from</code>, <code id="seq-decimal_+3A_.offset_from">.offset_from</code></td>
<td>
<p>Integer. If set to a non-zero number, the
starting point will be offset by that many units on the level of the last
decimal digit. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_offset_to">offset_to</code>, <code id="seq-decimal_+3A_.offset_to">.offset_to</code></td>
<td>
<p>Integer. If set to a non-zero number, the
endpoint will be offset by that many units on the level of the last decimal
digit. Default is <code>0</code>. Only in <code>seq_endpoint()</code> and <code>seq_endpoint_df()</code>.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_string_output">string_output</code>, <code id="seq-decimal_+3A_.string_output">.string_output</code></td>
<td>
<p>Logical or string. If <code>TRUE</code> (the
default), the output is a string vector. Decimal places are then padded
with zeros to match <code>from</code>'s (or <code>to</code>'s) number of decimal places. <code>"auto"</code>
works like <code>TRUE</code> if and only if <code>from</code> (<code>.from</code>) is a string.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_by">by</code>, <code id="seq-decimal_+3A_.by">.by</code></td>
<td>
<p>Numeric. Only in <code>seq_distance()</code> and <code>seq_distance_df()</code>. Step
size of the sequence. If not set, inferred automatically. Default is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_length_out">length_out</code>, <code id="seq-decimal_+3A_.length_out">.length_out</code></td>
<td>
<p>Integer. Length of the output vector (i.e., the
number of its values). Default is <code>10</code>. Only in <code>seq_distance()</code> and
<code>seq_distance_df()</code>.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_dir">dir</code>, <code id="seq-decimal_+3A_.dir">.dir</code></td>
<td>
<p>Integer. If set to <code>-1</code>, the sequence goes backward. Default
is <code>1</code>. Only in <code>seq_distance()</code> and <code>seq_distance_df()</code>.</p>
</td></tr>
<tr><td><code id="seq-decimal_+3A_...">...</code></td>
<td>
<p>Further columns, added as in <code><a href="tibble.html#topic+tibble">tibble::tibble()</a></code>. Only in
<code>seq_endpoint_df()</code> and <code>seq_distance_df()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If either <code>from</code> or <code>to</code> ends on zero, be sure to enter that value
as a string! This is crucial because trailing zeros get dropped from
numeric values. A handy way to format numeric values or number-strings
correctly is <code><a href="#topic+restore_zeros">restore_zeros()</a></code>. The output of the present functions is
like that by default (of <code>string_output</code>).
</p>
<p>In <code>seq_endpoint()</code> and <code>seq_endpoint_df()</code>, the step size is determined by
<code>from</code> and <code>to</code>, whichever has more decimal places. In <code>seq_distance()</code> and
<code>seq_distance_df()</code>, it's determined by the decimal places of <code>from</code>.
</p>
<p>These functions are scrutiny's take on <code><a href="base.html#topic+seq">base::seq()</a></code>, and themselves
wrappers around it.
</p>


<h3>Value</h3>

<p>String by default of <code>string_output</code>, numeric otherwise.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+seq_disperse">seq_disperse()</a></code> for sequences centered around the input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sequence between two points:
seq_endpoint(from = 4.7, to = 5)

# Sequence of some length; default is 10:
seq_distance(from = 0.93)
seq_distance(from = 0.93, length_out = 5)

# Both of these functions can offset the
# starting point...
seq_endpoint(from = 14.2, to = 15, offset_from = 4)
seq_distance(from = 14.2, offset_from = 4)

# ...but only `seq_endpoint()` can offset the
# endpoint, because of its `to` argument:
seq_endpoint(from = 9.5, to = 10, offset_to = 2)

# In return, `seq_distance()` can reverse its direction:
seq_distance(from = 20.03, dir = -1)

# Both functions have a `_df` variant that returns
# a data frame. Arguments are the same but with a
# dot, and further columns can be added as in
# `tibble::tibble()`:
seq_endpoint_df(.from = 4.7, .to = 5, n = 20)
seq_distance_df(.from = 0.43, .length_out = 5, sd = 0.08)
</code></pre>

<hr>
<h2 id='seq-predicates'>Is a vector a certain kind of sequence?</h2><span id='topic+seq-predicates'></span><span id='topic+is_seq_linear'></span><span id='topic+is_seq_ascending'></span><span id='topic+is_seq_descending'></span><span id='topic+is_seq_dispersed'></span>

<h3>Description</h3>

<p>Predicate functions that test whether <code>x</code> is a numeric vector
(or coercible to numeric) with some special properties:
</p>

<ul>
<li> <p><code>is_seq_linear()</code> tests whether every two consecutive elements of <code>x</code>
differ by some constant amount.
</p>
</li>
<li> <p><code>is_seq_ascending()</code> and <code>is_seq_descending()</code> test whether the
difference between every two consecutive values is positive or negative,
respectively. <code>is_seq_dispersed()</code> tests whether <code>x</code> values are grouped
around a specific central value, <code>from</code>, with the same distance to both
sides per value pair. By default (<code>test_linear = TRUE</code>), these functions
also test for linearity, like <code>is_seq_linear()</code>.
</p>
</li></ul>

<p><code>NA</code> elements of <code>x</code> are handled in a nuanced way. See <em>Value</em> section below
and the examples in <code>vignette("devtools")</code>, section <em>NA handling</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_seq_linear(x, tolerance = .Machine$double.eps^0.5)

is_seq_ascending(x, test_linear = TRUE, tolerance = .Machine$double.eps^0.5)

is_seq_descending(x, test_linear = TRUE, tolerance = .Machine$double.eps^0.5)

is_seq_dispersed(
  x,
  from,
  test_linear = TRUE,
  tolerance = .Machine$double.eps^0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq-predicates_+3A_x">x</code></td>
<td>
<p>Numeric or coercible to numeric, as determined by
<code>is_numeric_like()</code>. Vector to be tested.</p>
</td></tr>
<tr><td><code id="seq-predicates_+3A_tolerance">tolerance</code></td>
<td>
<p>Numeric. Tolerance of comparison between numbers when
testing. Default is circa 0.000000015 (1.490116e-08), as in
<code>dplyr::near()</code>.</p>
</td></tr>
<tr><td><code id="seq-predicates_+3A_test_linear">test_linear</code></td>
<td>
<p>Logical. In functions other than <code>is_seq_linear()</code>, should
<code>x</code> also be tested for linearity? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="seq-predicates_+3A_from">from</code></td>
<td>
<p>Numeric or coercible to numeric. Only in <code>is_seq_dispersed()</code>. It
will test whether <code>from</code> is at the center of <code>x</code>, and if every pair of
other values is equidistant to it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single logical value. If <code>x</code> contains at least one <code>NA</code> element,
the functions return either <code>NA</code> or <code>FALSE</code>:
</p>

<ul>
<li><p> If all elements of <code>x</code> are <code>NA</code>, the functions return <code>NA</code>.
</p>
</li>
<li><p> If some but not all elements are <code>NA</code>, they check if <code>x</code> <em>might</em> be a
sequence of the kind in question: Is it a linear (and / or ascending, etc.)
sequence after the <code>NA</code>s were replaced by appropriate values? If so, they
return <code>NA</code>; otherwise, they return <code>FALSE</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="validate.html#topic+is_linear_sequence">validate::is_linear_sequence()</a></code>, which is much like
<code>is_seq_linear()</code> but more permissive with <code>NA</code> values. It comes with some
additional features, such as support for date-times.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># These are linear sequences...
is_seq_linear(x = 3:7)
is_seq_linear(x = c(3:7, 8))

# ...but these aren't:
is_seq_linear(x = c(3:7, 9))
is_seq_linear(x = c(10, 3:7))

# All other `is_seq_*()` functions
# also test for linearity by default:
is_seq_ascending(x = c(2, 7, 9))
is_seq_ascending(x = c(2, 7, 9), test_linear = FALSE)

is_seq_descending(x = c(9, 7, 2))
is_seq_descending(x = c(9, 7, 2), test_linear = FALSE)

is_seq_dispersed(x = c(2, 3, 5, 7, 8), from = 5)
is_seq_dispersed(x = c(2, 3, 5, 7, 8), from = 5, test_linear = FALSE)

# These fail their respective
# individual test even
# without linearity testing:
is_seq_ascending(x = c(1, 7, 4), test_linear = FALSE)
is_seq_descending(x = c(9, 15, 3), test_linear = FALSE)
is_seq_dispersed(1:10, from = 5, test_linear = FALSE)
</code></pre>

<hr>
<h2 id='split_by_parens'>Split columns by parentheses, brackets, braces, or similar</h2><span id='topic+split_by_parens'></span>

<h3>Description</h3>

<p>Summary statistics are often presented like <code>"2.65 (0.27)"</code>.
When working with tables copied into R, it can be tedious to separate
values before and inside parentheses. <code>split_by_parens()</code> does this
automatically.
</p>
<p>By default, it operates on all columns. Output can optionally be pivoted
into a longer format by setting <code>transform</code> to <code>TRUE</code>.
</p>
<p>Choose separators other than parentheses with the <code>sep</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_by_parens(
  data,
  cols = everything(),
  check_sep = TRUE,
  keep = FALSE,
  transform = FALSE,
  sep = "parens",
  end1 = "x",
  end2 = "sd",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_by_parens_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_cols">cols</code></td>
<td>
<p>Select columns from <code>data</code> using
<a href="https://tidyselect.r-lib.org/reference/language.html">tidyselect</a>.
Default is <code>everything()</code>, which selects all columns that pass <code>check_sep</code>.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_check_sep">check_sep</code></td>
<td>
<p>Logical. If <code>TRUE</code> (the default), columns are excluded if
they don't contain the <code>sep</code> elements.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_keep">keep</code></td>
<td>
<p>Logical. If set to <code>TRUE</code>, the originally selected columns that
were split by the function also appear in the output. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_transform">transform</code></td>
<td>
<p>Logical. If set to <code>TRUE</code>, the output will be pivoted to be
better suitable for typical follow-up tasks. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_sep">sep</code></td>
<td>
<p>String. What to split by. Either <code>"parens"</code>, <code>"brackets"</code>, or
<code>"braces"</code>; or a length-2 vector of custom separators (see Examples).
Default is <code>"parens"</code>.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_end1">end1</code>, <code id="split_by_parens_+3A_end2">end2</code></td>
<td>
<p>Strings. Endings of the two column names that result from
splitting a column. Default is <code>"x"</code> for <code>end1</code> and <code>"sd"</code> for <code>end2</code>.</p>
</td></tr>
<tr><td><code id="split_by_parens_+3A_...">...</code></td>
<td>
<p>These dots must be empty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+before_parens">before_parens()</a></code> and <code><a href="#topic+inside_parens">inside_parens()</a></code> take a string vector and
extract values from the respective position.
</p>
</li>
<li> <p><code><a href="dplyr.html#topic+across">dplyr::across()</a></code> powers the application of the two above functions
within split_by_parens()', including the creation of new columns.
</p>
</li>
<li> <p><code><a href="tidyr.html#topic+separate_wider_delim">tidyr::separate_wider_delim()</a></code> is a more general function, but it does
not recognize closing elements such as closed parentheses.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Call `split_by_parens()` on data like these:
df1 &lt;- tibble::tribble(
  ~drone,           ~selfpilot,
  "0.09 (0.21)",    "0.19 (0.13)",
  "0.19 (0.28)",    "0.53 (0.10)",
  "0.62 (0.16)",    "0.50 (0.11)",
  "0.15 (0.35)",    "0.57 (0.16)",
)

# Basic usage:
df1 %&gt;%
  split_by_parens()

# Name specific columns with `cols` to only split those:
df1 %&gt;%
  split_by_parens(cols = drone)

# Pivot the data into a longer format
# by setting `transform` to `TRUE`:
df1 %&gt;%
  split_by_parens(transform = TRUE)

# Choose different column names or
# name suffixes with `end1` and `end2`:
df1 %&gt;%
  split_by_parens(end1 = "beta", end2 = "se")

df1 %&gt;%
  split_by_parens(
    transform = TRUE,
    end1 = "beta", end2 = "se"
  )

# With a different separator...
df2 &lt;- tibble::tribble(
  ~drone,           ~selfpilot,
  "0.09 [0.21]",    "0.19 [0.13]",
  "0.19 [0.28]",    "0.53 [0.10]",
  "0.62 [0.16]",    "0.50 [0.11]",
  "0.15 [0.35]",    "0.57 [0.16]",
)

# ... specify `sep`:
df2 %&gt;%
  split_by_parens(sep = "brackets")

# (Accordingly with `{}` and `"braces"`.)

# If the separator is yet a different one...
df3 &lt;- tibble::tribble(
  ~drone,           ~selfpilot,
  "0.09 &lt;0.21&gt;",    "0.19 &lt;0.13&gt;",
  "0.19 &lt;0.28&gt;",    "0.53 &lt;0.10&gt;",
  "0.62 &lt;0.16&gt;",    "0.50 &lt;0.11&gt;",
  "0.15 &lt;0.35&gt;",    "0.57 &lt;0.16&gt;",
)

# ... `sep` should be a length-2 vector
# that contains the separating elements:
df3 %&gt;%
  split_by_parens(sep = c("&lt;", "&gt;"))
</code></pre>

<hr>
<h2 id='subset-superset'>Test for subsets, supersets, and equal sets</h2><span id='topic+subset-superset'></span><span id='topic+is_subset_of'></span><span id='topic+is_superset_of'></span><span id='topic+is_equal_set'></span><span id='topic+is_proper_subset_of'></span><span id='topic+is_proper_superset_of'></span><span id='topic+is_subset_of_vals'></span><span id='topic+is_superset_of_vals'></span><span id='topic+is_equal_set_vals'></span><span id='topic+is_proper_subset_of_vals'></span><span id='topic+is_proper_superset_of_vals'></span><span id='topic+is_subset_of_vecs'></span><span id='topic+is_superset_of_vecs'></span><span id='topic+is_equal_set_vecs'></span><span id='topic+is_proper_subset_of_vecs'></span><span id='topic+is_proper_superset_of_vecs'></span>

<h3>Description</h3>

<p>Predicate functions that take a vector and test whether it has
some particular relation to another vector. That second vector is entered
in either of three ways &ndash;
</p>
<p><strong>Enter it directly (basic functions):</strong>
</p>
<p><code>is_subset_of()</code> tests if a vector is a subset of another vector; i.e., if
all its elements are contained in the second one. <code>is_superset_of()</code> does
the reverse: It tests if the first vector contains all elements of the
second one. <code>is_equal_set()</code> tests if both vectors have exactly the same
values.
</p>
<p><strong>Enter its values:</strong>
</p>
<p><code>is_subset_of_vals()</code>, <code>is_superset_of_vals()</code>, and <code>is_equal_set_vals()</code>
are variants that each take a single vector plus any number of other
arguments. These are treated like elements of the second vector in the
basic functions above.
</p>
<p><strong>Enter multiple vectors that jointly contain its values:</strong>
</p>
<p>Finally, <code>is_subset_of_vecs()</code>, <code>is_superset_of_vecs()</code>, and
<code>is_equal_set_vecs()</code> take one vector plus any number of other vectors and
treat their elements (!) like elements of a second vector in the basic
functions above.
</p>
<p>Each <code style="white-space: pre;">&#8288;is_subset*()&#8288;</code> function has an <code style="white-space: pre;">&#8288;is_proper_subset*()&#8288;</code> variant. These
variants also test whether the sets are unequal, so that <code>x</code> is a subset of
<code>y</code> but <code>y</code> is not a subset of <code>x</code>. The same applies to <code style="white-space: pre;">&#8288;is_superset*()&#8288;</code>
functions and their <code style="white-space: pre;">&#8288;is_proper_superset*()&#8288;</code> variants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_subset_of(x, y)

is_superset_of(x, y)

is_equal_set(x, y)

is_proper_subset_of(x, y)

is_proper_superset_of(x, y)

is_subset_of_vals(x, ...)

is_superset_of_vals(x, ...)

is_equal_set_vals(x, ...)

is_proper_subset_of_vals(x, ...)

is_proper_superset_of_vals(x, ...)

is_subset_of_vecs(x, ...)

is_superset_of_vecs(x, ...)

is_equal_set_vecs(x, ...)

is_proper_subset_of_vecs(x, ...)

is_proper_superset_of_vecs(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset-superset_+3A_x">x</code></td>
<td>
<p>A vector.</p>
</td></tr>
<tr><td><code id="subset-superset_+3A_y">y</code></td>
<td>
<p>A vector. Only in the basic functions, not those with <code style="white-space: pre;">&#8288;*_vals()&#8288;</code> or
<code style="white-space: pre;">&#8288;*_vecs()&#8288;</code>.</p>
</td></tr>
<tr><td><code id="subset-superset_+3A_...">...</code></td>
<td>
<p>In the <code style="white-space: pre;">&#8288;*_vals()&#8288;</code> functions, any number of values <code>x</code> might
contain; in the <code style="white-space: pre;">&#8288;*_vecs()&#8288;</code> functions, any number of vectors the elements of
which <code>x</code> might contain.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code style="white-space: pre;">&#8288;*_vals()&#8288;</code> variants are meant for flexible, interactive
subset/superset testing. That is, in order to test whether certain values
collectively fulfill the role of the second vector, you can just add them
to the function call.
</p>
<p>The <code style="white-space: pre;">&#8288;*_vecs()&#8288;</code> variants likewise offer flexibility, but also bridge the gap
between vectors and values contained in them.
</p>
<p>All functions simply check if values are present, regardless of how often a
value occurs. In other words, they look for types but don't count tokens.
</p>


<h3>Value</h3>

<p>A single logical value. <code>TRUE</code> if the respective test was passed,
<code>FALSE</code> otherwise.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Define example vectors:
ab &lt;- c("a", "b")
abc &lt;- c("a", "b", "c")
abcde &lt;- c("a", "b", "c", "d", "e")

# `is_subset_of()` tests if a vector is
# completely covered by another one:
abc %&gt;% is_subset_of(ab)
abc %&gt;% is_subset_of(abc)
abc %&gt;% is_subset_of(abcde)

# To the contrary, `is_superset_of()` tests if the
# first vector completely covers the second one:
abc %&gt;% is_superset_of(ab)
abc %&gt;% is_superset_of(abc)
abc %&gt;% is_superset_of(abcde)

# `is_equal_set()` tests both of the above --
# i.e., if both vectors have exactly the
# same values:
abc %&gt;% is_equal_set(ab)
abc %&gt;% is_equal_set(abc)
abc %&gt;% is_equal_set(abcde)

# Each of the three functions has a `*_vals()` variant
# that doesn't take a second vector like the first
# one, but any number of other arguments. These are
# jointly treated like the elements of the second
# vector in the basic functions:
abc %&gt;% is_subset_of_vals("a", "b")
abc %&gt;% is_subset_of_vals("a", "b", "c")
abc %&gt;% is_subset_of_vals("a", "b", "c", "d", "e")

# (... and likewise for supersets and equal sets.)
</code></pre>

<hr>
<h2 id='tidyeval'>Tidy eval helpers</h2><span id='topic+tidyeval'></span><span id='topic+enquo'></span><span id='topic+enquos'></span><span id='topic+.data'></span><span id='topic++3A+3D'></span><span id='topic+as_name'></span><span id='topic+as_label'></span>

<h3>Description</h3>

<p>This page lists the tidy eval tools reexported in scrutiny from
rlang. To learn about using tidy eval in scripts and packages at a
high level, see the <a href="https://dplyr.tidyverse.org/articles/programming.html">dplyr programming vignette</a>
and the <a href="https://ggplot2.tidyverse.org/articles/ggplot2-in-packages.html">ggplot2 in packages vignette</a>.
The <a href="https://adv-r.hadley.nz/metaprogramming.html">Metaprogramming section</a> of <a href="https://adv-r.hadley.nz">Advanced R</a> may also be useful for a deeper dive.
</p>

<ul>
<li><p> The tidy eval operators <code style="white-space: pre;">&#8288;{{&#8288;</code>, <code style="white-space: pre;">&#8288;!!&#8288;</code>, and <code style="white-space: pre;">&#8288;!!!&#8288;</code> are syntactic
constructs which are specially interpreted by tidy eval functions.
You will mostly need <code style="white-space: pre;">&#8288;{{&#8288;</code>, as <code style="white-space: pre;">&#8288;!!&#8288;</code> and <code style="white-space: pre;">&#8288;!!!&#8288;</code> are more advanced
operators which you should not have to use in simple cases.
</p>
<p>The curly-curly operator <code style="white-space: pre;">&#8288;{{&#8288;</code> allows you to tunnel data-variables
passed from function arguments inside other tidy eval functions.
<code style="white-space: pre;">&#8288;{{&#8288;</code> is designed for individual arguments. To pass multiple
arguments contained in dots, use <code>...</code> in the normal way.
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, ...) {
  data %&gt;%
    group_by(...) %&gt;%
    summarise(mean = mean({{ var }}))
}
</pre></div>
</li>
<li> <p><code><a href="#topic+enquo">enquo()</a></code> and <code><a href="#topic+enquos">enquos()</a></code> delay the execution of one or several
function arguments. The former returns a single expression, the
latter returns a list of expressions. Once defused, expressions
will no longer evaluate on their own. They must be injected back
into an evaluation context with <code style="white-space: pre;">&#8288;!!&#8288;</code> (for a single expression) and
<code style="white-space: pre;">&#8288;!!!&#8288;</code> (for a list of expressions).
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, ...) {
  # Defuse
  var &lt;- enquo(var)
  dots &lt;- enquos(...)

  # Inject
  data %&gt;%
    group_by(!!!dots) %&gt;%
    summarise(mean = mean(!!var))
}
</pre></div>
<p>In this simple case, the code is equivalent to the usage of <code style="white-space: pre;">&#8288;{{&#8288;</code>
and <code>...</code> above. Defusing with <code>enquo()</code> or <code>enquos()</code> is only
needed in more complex cases, for instance if you need to inspect
or modify the expressions in some way.
</p>
</li>
<li><p> The <code>.data</code> pronoun is an object that represents the current
slice of data. If you have a variable name in a string, use the
<code>.data</code> pronoun to subset that variable with <code>[[</code>.
</p>
<div class="sourceCode"><pre>my_var &lt;- "disp"
mtcars %&gt;% summarise(mean = mean(.data[[my_var]]))
</pre></div>
</li>
<li><p> Another tidy eval operator is <code style="white-space: pre;">&#8288;:=&#8288;</code>. It makes it possible to use
glue and curly-curly syntax on the LHS of <code>=</code>. For technical
reasons, the R language doesn't support complex expressions on
the left of <code>=</code>, so we use <code style="white-space: pre;">&#8288;:=&#8288;</code> as a workaround.
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, suffix = "foo") {
  # Use `{{` to tunnel function arguments and the usual glue
  # operator `{` to interpolate plain strings.
  data %&gt;%
    summarise("{{ var }}_mean_{suffix}" := mean({{ var }}))
}
</pre></div>
</li>
<li><p> Many tidy eval functions like <code>dplyr::mutate()</code> or
<code>dplyr::summarise()</code> give an automatic name to unnamed inputs. If
you need to create the same sort of automatic names by yourself,
use <code>as_label()</code>. For instance, the glue-tunnelling syntax above
can be reproduced manually with:
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, suffix = "foo") {
  var &lt;- enquo(var)
  prefix &lt;- as_label(var)
  data %&gt;%
    summarise("{prefix}_mean_{suffix}" := mean(!!var))
}
</pre></div>
<p>Expressions defused with <code>enquo()</code> (or tunnelled with <code style="white-space: pre;">&#8288;{{&#8288;</code>) need
not be simple column names, they can be arbitrarily complex.
<code>as_label()</code> handles those cases gracefully. If your code assumes
a simple column name, use <code>as_name()</code> instead. This is safer
because it throws an error if the input is not a name as expected.
</p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><code>enquo()</code> returns an expression, <code>enquos()</code> returns a list of
expressions.
</p>
</li>
<li> <p><code>as_name()</code> and <code>as_label()</code> return a string vector of length 1.
</p>
</li>
<li> <p><code>.data</code> is a pronoun that should only be used within tidy eval functions.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;:=&#8288;</code> has no return value. It will throw an error if called outside of the
dynamic dots of a tidy eval function.
</p>
</li></ul>

<p>See the description to learn about the functionality of these objects.
(This value section was only added in scrutiny; not in rlang by the tidy
eval developers.)
</p>

<hr>
<h2 id='unnest_consistency_cols'>Unnest a test result column</h2><span id='topic+unnest_consistency_cols'></span>

<h3>Description</h3>

<p>Within a consistency test mapper function, it may become
necessary to unpack a column resulting from a basic <code style="white-space: pre;">&#8288;*_scalar()&#8288;</code> testing
function. That will be the case if a <code style="white-space: pre;">&#8288;show_*&#8288;</code> argument of the mapper
function like <code>show_rec</code> in <code>grim_map()</code> is <code>TRUE</code>, and the <code style="white-space: pre;">&#8288;*_scalar()&#8288;</code>
function returns a list of values, not just a single value.
</p>
<p>At the point where such as list is stored in a data frame column (most
likely <code>"consistency"</code>), call <code>unnest_consistency_cols()</code> to unnest the
results into multiple columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unnest_consistency_cols(results, col_names, index = FALSE, col = "consistency")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unnest_consistency_cols_+3A_results">results</code></td>
<td>
<p>Data frame containing a list-column by the name passed to
<code>col</code>.</p>
</td></tr>
<tr><td><code id="unnest_consistency_cols_+3A_col_names">col_names</code></td>
<td>
<p>String vector of new names for the unnested columns. It
should start with the same string that was given for <code>col</code>.</p>
</td></tr>
<tr><td><code id="unnest_consistency_cols_+3A_index">index</code></td>
<td>
<p>Logical. Should the list-column be indexed into? Default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="unnest_consistency_cols_+3A_col">col</code></td>
<td>
<p>String (length 1). Name of the list-column within <code>results</code> to
operate on. Default is <code>"consistency"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a custom workaround in place of
<code>tidyr::unnest_wider()</code>, mirroring some of the latter's functionality. It
was created because <code>unnest_wider()</code> can be too slow for use as a helper
function.
</p>


<h3>Value</h3>

<p>Data frame. The column names are determined by <code>col_names</code>.
</p>


<h3>See Also</h3>

<p><code>vignette("consistency-tests-in-depth")</code>, for context.
</p>

<hr>
<h2 id='unround'>Reconstruct rounding bounds</h2><span id='topic+unround'></span>

<h3>Description</h3>

<p><code>unround()</code> takes a rounded number and returns the range of the
original value: lower and upper bounds for the hypothetical earlier number
that was later rounded to the input number. It also displays a range with
inequation signs, showing whether the bounds are inclusive or not.
</p>
<p>By default, the presumed rounding method is rounding up (or down) from 5.
See the <code>Rounding</code> section for other methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unround(x, rounding = "up_or_down", threshold = 5, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unround_+3A_x">x</code></td>
<td>
<p>String or numeric. Rounded number. <code>x</code> must be a string unless
<code>digits</code> is specified (most likely by a function that uses <code>unround()</code> as a
helper).</p>
</td></tr>
<tr><td><code id="unround_+3A_rounding">rounding</code></td>
<td>
<p>String. Rounding method presumably used to create <code>x</code>.
Default is <code>"up_or_down"</code>. For more, see section <code>Rounding</code>.</p>
</td></tr>
<tr><td><code id="unround_+3A_threshold">threshold</code></td>
<td>
<p>Integer. Number from which to round up or down. Other
rounding methods are not affected. Default is <code>5</code>.</p>
</td></tr>
<tr><td><code id="unround_+3A_digits">digits</code></td>
<td>
<p>Integer. This argument is meant to make <code>unround()</code> more
efficient to use as a helper function so that it doesn't need to
redundantly count decimal places. Don't specify it otherwise. Default is
<code>NULL</code>, in which case decimal places really are counted internally and <code>x</code>
must be a string.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is vectorized over <code>x</code> and <code>rounding</code>. This can be
useful to unround multiple numbers at once, or to check how a single number
is unrounded with different assumed rounding methods.
</p>
<p>If both vectors have a length greater than 1, it must be the same
length. However, this will pair numbers with rounding methods, which can be
confusing. It is recommended that at least one of these input vectors has
length 1.
</p>
<p>Why does <code>x</code> need to be a string if <code>digits</code> is not specified? In that
case, <code>unround()</code> must count decimal places by itself. If <code>x</code> then was
numeric, it wouldn't have any trailing zeros because these get dropped from
numerics.
</p>
<p>Trailing zeros are as important for reconstructing boundary values as any
other trailing digits would be. Strings don't drop trailing zeros, so they
are used instead.
</p>


<h3>Value</h3>

<p>A tibble with seven columns: <code>range</code>, <code>rounding</code>, <code>lower</code>,
<code>incl_lower</code>, <code>x</code>, <code>incl_upper</code>, and <code>upper</code>. The <code>range</code> column is a handy
representation of the information stored in the columns from <code>lower</code> to
<code>upper</code>, in the same order.
</p>


<h3>Rounding</h3>

<p>Depending on how <code>x</code> was rounded, the boundary values can
be inclusive or exclusive. The <code>incl_lower</code> and <code>incl_upper</code> columns in the
resulting tibble are <code>TRUE</code> in the first case and <code>FALSE</code> in the second.
The <code>range</code> column reflects this with equation and inequation signs.
</p>
<p>However, these ranges are based on assumptions about the way <code>x</code> was
rounded. Set <code>rounding</code> to the rounding method that hypothetically lead to
<code>x</code>:</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Value of <code>rounding</code></strong> </td><td style="text-align: left;"> <strong>Corresponding range</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"up_or_down"</code> (default) </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;lower &lt;= x &lt;= upper&#8288;</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"up"</code> </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;lower &lt;= x &lt; upper&#8288;</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"down"</code> </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;lower &lt; x &lt;= upper&#8288;</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"even"</code> </td><td style="text-align: left;"> (no fix range) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"ceiling"</code> </td><td style="text-align: left;"> <code>lower &lt; x = upper</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"floor"</code> </td><td style="text-align: left;"> <code>lower = x &lt; upper</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"trunc"</code> (positive <code>x</code>) </td><td style="text-align: left;"> <code>lower = x &lt; upper</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"trunc"</code> (negative <code>x</code>) </td><td style="text-align: left;"> <code>lower &lt; x = upper</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"trunc"</code> (zero <code>x</code>) </td><td style="text-align: left;"> <code style="white-space: pre;">&#8288;lower &lt; x &lt; upper&#8288;</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"anti_trunc"</code> (positive <code>x</code>) </td><td style="text-align: left;"> <code>lower &lt; x = upper</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"anti_trunc"</code> (negative <code>x</code>) </td><td style="text-align: left;"> <code>lower = x &lt; upper</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>"anti_trunc"</code> (zero <code>x</code>) </td><td style="text-align: left;"> (undefined; <code>NA</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Base R's own <code>round()</code> (R version &gt;= 4.0.0), referenced by <code>rounding = "even"</code>, is reconstructed in the same way as <code>"up_or_down"</code>, but whether the
boundary values are inclusive or not is hard to predict. Therefore,
<code>unround()</code> checks if they are, and informs you about it.
</p>


<h3>See Also</h3>

<p>For more about rounding <code>"up"</code>, <code>"down"</code>, or to <code>"even"</code>, see
<code><a href="#topic+round_up">round_up()</a></code>.
</p>
<p>For more about the less likely <code>rounding</code> methods, <code>"ceiling"</code>, <code>"floor"</code>,
<code>"trunc"</code>, and <code>"anti_trunc"</code>, see <code><a href="#topic+round_ceiling">round_ceiling()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># By default, the function assumes that `x`
# was either rounded up or down:
unround(x = "2.7")

# If `x` was rounded up, run this:
unround(x = "2.7", rounding = "up")

# Likewise with rounding down...
unround(x = "2.7", rounding = "down")

# ...and with `base::round()` which, broadly
# speaking, rounds to the nearest even number:
unround(x = "2.7", rounding = "even")

# Multiple input number-strings return
# multiple rows in the output data frame:
unround(x = c(3.6, "5.20", 5.174))
</code></pre>

<hr>
<h2 id='write_doc_audit'>Documentation template for <code><a href="#topic+audit">audit()</a></code></h2><span id='topic+write_doc_audit'></span>

<h3>Description</h3>

<p><code>write_doc_audit()</code> creates a roxygen2 block section to be
inserted into the documentation of a mapper function such as <code><a href="#topic+grim_map">grim_map()</a></code>
or <code><a href="#topic+debit_map">debit_map()</a></code>: functions for which there are, or should be,
<code><a href="#topic+audit">audit()</a></code> methods. The section informs users about the ways in which
<code><a href="#topic+audit">audit()</a></code> summarizes the results of the respective mapper function.
</p>
<p>Copy the output from your console and paste it into the roxygen2 block of
your <code style="white-space: pre;">&#8288;*_map()&#8288;</code> function. To preserve the numbered list structure when
indenting roxygen2 comments with <code>Ctrl</code>+<code>Shift</code>+<code>/</code>, leave empty lines
between the pasted output and the rest of the block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_doc_audit(sample_output, name_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_doc_audit_+3A_sample_output">sample_output</code></td>
<td>
<p>Data frame. Result of a call to <code><a href="#topic+audit">audit()</a></code> on a data
frame that resulted from a call to the mapper function for which you wrote
the <code><a href="#topic+audit">audit()</a></code> method, such as <code>audit(grim_map(pigs1))</code> or
<code>audit(debit_map(pigs3))</code>.</p>
</td></tr>
<tr><td><code id="write_doc_audit_+3A_name_test">name_test</code></td>
<td>
<p>String (length 1). Name of the consistency test which the
mapper function applies, such as <code>"GRIM"</code> or <code>"DEBIT"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string vector formatted by <code><a href="glue.html#topic+glue">glue::glue()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Start by running `audit()`:
out_grim  &lt;- audit(grim_map(pigs1))
out_debit &lt;- audit(debit_map(pigs3))

out_grim
out_debit

# Documenting the `audit()` method for `grim_map()`:
write_doc_audit(sample_output = out_grim, name_test = "GRIM")

# Documenting the `audit()` method for `debit_map()`:
write_doc_audit(sample_output = out_debit, name_test = "DEBIT")
</code></pre>

<hr>
<h2 id='write_doc_audit_seq'>Documentation template for <code><a href="#topic+audit_seq">audit_seq()</a></code></h2><span id='topic+write_doc_audit_seq'></span>

<h3>Description</h3>

<p><code>write_doc_audit_seq()</code> creates a roxygen2 block section to be
inserted into the documentation of functions created with
<code><a href="#topic+function_map_seq">function_map_seq()</a></code>. The section informs users about the ways in which
<code><a href="#topic+audit_seq">audit_seq()</a></code> summarizes the results of the manufactured <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code>
function.
</p>
<p>Copy the output from your console and paste it into the roxygen2 block of
your <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> function. To preserve the bullet-point structure when
indenting roxygen2 comments with <code>Ctrl</code>+<code>Shift</code>+<code>/</code>, leave empty lines
between the pasted output and the rest of the block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_doc_audit_seq(key_args, name_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_doc_audit_seq_+3A_key_args">key_args</code></td>
<td>
<p>String vector with the names of the key columns that are
tested for consistency by the <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> function. The values need to
have the same order as in that function's output.</p>
</td></tr>
<tr><td><code id="write_doc_audit_seq_+3A_name_test">name_test</code></td>
<td>
<p>String (length 1). Name of the consistency test which the
<code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> function applies, such as <code>"GRIM"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string vector formatted by <code><a href="glue.html#topic+glue">glue::glue()</a></code>.
</p>


<h3>See Also</h3>

<p>The sister function <code><a href="#topic+write_doc_audit_total_n">write_doc_audit_total_n()</a></code> and, for context,
<code>vignette("consistency-tests-in-depth")</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For GRIM and `grim_map_seq()`:
write_doc_audit_seq(key_args = c("x", "n"), name_test = "GRIM")

# For DEBIT and `debit_map_seq()`:
write_doc_audit_seq(key_args = c("x", "sd", "n"), name_test = "DEBIT")
</code></pre>

<hr>
<h2 id='write_doc_audit_total_n'>Documentation template for <code><a href="#topic+audit_total_n">audit_total_n()</a></code></h2><span id='topic+write_doc_audit_total_n'></span>

<h3>Description</h3>

<p><code>write_doc_audit_total_n()</code> creates a roxygen2 block section to
be inserted into the documentation of functions created with
<code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>. The section informs users about the ways in
which <code><a href="#topic+audit_seq">audit_seq()</a></code> summarizes the results of the manufactured
<code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> function.
</p>
<p>Copy the output from your console and paste it into the roxygen2 block of
your <code style="white-space: pre;">&#8288;*_map_total_n()&#8288;</code> function. To preserve the bullet-point structure
when indenting roxygen2 comments with <code>Ctrl</code>+<code>Shift</code>+<code>/</code>, leave empty lines
between the pasted output and the rest of the block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_doc_audit_total_n(key_args, name_test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_doc_audit_total_n_+3A_key_args">key_args</code></td>
<td>
<p>String vector with the names of the key columns that are
tested for consistency by the <code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> function. (These are the
original variable names, without <code>"1"</code> and <code>"2"</code> suffixes.) The values need
to have the same order as in that function's output.</p>
</td></tr>
<tr><td><code id="write_doc_audit_total_n_+3A_name_test">name_test</code></td>
<td>
<p>String (length 1). Name of the consistency test which the
<code style="white-space: pre;">&#8288;*_map_seq()&#8288;</code> function applies, such as <code>"GRIM"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string vector formatted by <code><a href="glue.html#topic+glue">glue::glue()</a></code>.
</p>


<h3>See Also</h3>

<p>The sister function <code><a href="#topic+write_doc_audit_seq">write_doc_audit_seq()</a></code> and, for context,
<code>vignette("consistency-tests-in-depth")</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For GRIM and `grim_map_total_n()`:
write_doc_audit_total_n(key_args = c("x", "n"), name_test = "GRIM")

# For DEBIT and `debit_map_total_n()`:
write_doc_audit_total_n(key_args = c("x", "sd", "n"), name_test = "DEBIT")
</code></pre>

<hr>
<h2 id='write_doc_factory_map_conventions'>Documentation template for function factory conventions</h2><span id='topic+write_doc_factory_map_conventions'></span>

<h3>Description</h3>

<p><code>write_doc_factory_map_conventions()</code> creates a roxygen2 block
section to be inserted into the documentation of a function factory such as
<code><a href="#topic+function_map_seq">function_map_seq()</a></code> or <code><a href="#topic+function_map_total_n">function_map_total_n()</a></code>. It lays out the
naming guidelines that users of your function factory should follow when
creating new manufactured functions.
</p>
<p>Copy the output from your console and paste it into the roxygen2 block of
your function factory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_doc_factory_map_conventions(
  ending,
  name_test1 = "GRIM",
  name_test2 = "GRIMMER",
  scrutiny_prefix = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_doc_factory_map_conventions_+3A_ending">ending</code></td>
<td>
<p>String (length 1). The part of your function factory's name
after <code>function_map_</code>. To</p>
</td></tr>
<tr><td><code id="write_doc_factory_map_conventions_+3A_name_test1">name_test1</code>, <code id="write_doc_factory_map_conventions_+3A_name_test2">name_test2</code></td>
<td>
<p>Strings (length 1 each). Plain-text names of
example consistency tests. Defaults are <code>"GRIM"</code> and <code>"GRIMMER"</code>,
respectively.</p>
</td></tr>
<tr><td><code id="write_doc_factory_map_conventions_+3A_scrutiny_prefix">scrutiny_prefix</code></td>
<td>
<p>Logical (length 1). Should the scrutiny functions
mentioned in the output have a <code style="white-space: pre;">&#8288;scrutiny::&#8288;</code> namespace specification? Set
this to <code>TRUE</code> if the output will go into another package's documentation.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string vector formatted by <code><a href="glue.html#topic+glue">glue::glue()</a></code>.
</p>


<h3>See Also</h3>

<p>For context, see
<a href="https://lhdjung.github.io/scrutiny/articles/consistency-tests.html"><em>Implementing
consistency tests</em></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For `function_map_seq()`:
write_doc_factory_map_conventions(ending = "seq")

# For `function_map_total_n()`:
write_doc_factory_map_conventions(ending = "total_n")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
