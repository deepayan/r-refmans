<!DOCTYPE html><html><head><title>Help for package probout</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {probout}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#allProb'><p>Outlier probabilities for all observations</p></a></li>
<li><a href='#leader'><p>Leader Algorithm for Data Partitioning</p></a></li>
<li><a href='#logdens'><p>Log Density for Gaussian Mixture Model</p></a></li>
<li><a href='#LWradius'><p>Wilkinson's default leader-partitioning radius</p></a></li>
<li><a href='#OutlierStatistic'><p>Nonparametric Outlier Statistic</p></a></li>
<li><a href='#partProb'><p>Partition outlier probabilities</p></a></li>
<li><a href='#simData'><p>Simulates observations for outlier determination.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-02-10</td>
</tr>
<tr>
<td>Title:</td>
<td>Unsupervised Multivariate Outlier Probabilities for Large
Datasets</td>
</tr>
<tr>
<td>Author:</td>
<td>Chris Fraley [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chris Fraley  &lt;fraley@u.washington.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), FNN, mclust, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvtnorm, GDAdata, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimates unsupervised outlier probabilities for multivariate numeric data with many observations from a nonparametric outlier statistic.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.r-project.org">https://www.r-project.org</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-10 19:19:52 UTC; cfraley</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-11 12:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='allProb'>Outlier probabilities for all observations</h2><span id='topic+allProb'></span>

<h3>Description</h3>

<p>Outlier probabilities for all of  the data, obtained by assigning
to each observation the probabilty of the its associated leader partition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allProb( leaderInstance, partprob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="allProb_+3A_leaderinstance">leaderInstance</code></td>
<td>

<p>A single component from a call to <code>leader</code>, giving leader algorithm
results for one value of the partitioning radius.
</p>
</td></tr>
<tr><td><code id="allProb_+3A_partprob">partprob</code></td>
<td>

<p>A vector of probabilities for each partition in <code>leaderInstance</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of probabilities for each observation in the data underlying
<code>leaderInstance</code>. Each observation inherits the probability of its
associated partition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+leader">leader</a></code>,
<code><a href="#topic+partProb">partProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 set.seed(0)

 lead &lt;- leader(faithful)
 nlead &lt;- length(lead[[1]]$partitions)

# repeat multiple times to account for randomness
 ntimes &lt;- 100
 probs &lt;- matrix( NA, nlead, ntimes)
 for (i in 1:ntimes) {
    probs[,i] &lt;- partProb( simData(lead[[1]]), method = "distance")
 }

# median probability for each partition
 partprobs &lt;- apply( probs, 1, median)

 quantile(partprobs)

# plot leaders with outlier probability &gt; .95
 plot( faithful[,1], faithful[,2], pch = 16, cex = .5,
       main = "red : instances with outlier probability &gt; .95")
 allprobs &lt;- allProb( lead[[1]], partprobs)
 out &lt;- allprobs &gt; .95
 points( faithful[out,1], faithful[out,2], pch = 8, cex = 1, col = "red")

</code></pre>

<hr>
<h2 id='leader'>Leader Algorithm for Data Partitioning</h2><span id='topic+leader'></span>

<h3>Description</h3>

<p>Partitions the data according to Hartigan's leader algorithm, and 
provides ranges, centroids, and variances for the partitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>leader(data, radius = NULL, scale = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="leader_+3A_data">data</code></td>
<td>

<p>A numeric vector or matrix of observations. If a matrix, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="leader_+3A_radius">radius</code></td>
<td>

<p>A vector of values for the partitioning radius. Wilkinson's default
radius is used if <code>radius</code> is left unspecified (see function 
<code>LWradius</code>).
</p>
</td></tr>
<tr><td><code id="leader_+3A_scale">scale</code></td>
<td>

<p>A logical variable indicating whether or not the data should be mapped
to the unit hypercube. The default is to scale the data. Values of the
radius will not be scaled; they should be specifed relative to the unit 
hypercube unless <code>scale = F</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a partitioning radius <code>r</code>, the leader algorithm makes one pass 
through the data, designating an observation as a new leader if it is not 
within <code>r</code> of an existing leader, and otherwise assigning it to the
partition associated with the nearest existing leader. The set of leaders 
typically depends on the order of the data observations. <br />
If <code>radius = 0</code>, then all of the data observations are leaders, and
only <code>radius</code> and <code>leaders</code> are returned as output components. <br />
This implementation does a completely new nearest-neighbor search for
each observation and for each radius. A more efficient approach would be to 
maintain, for each radius, a data structure (such as a kd-tree) allowing 
fast nearest-neighbor search. These data structures could then be updated 
to account for new observations. Currently, there doesn't seem to be a way 
to do this in R.
</p>


<h3>Value</h3>

<p>A list with one component for each value of <code>radius</code>, each having the
following sub-components:
</p>
<table>
<tr><td><code>radius</code></td>
<td>
<p>The value of the radius associated with the partitioning.</p>
</td></tr>
<tr><td><code>partitions</code></td>
<td>

<p>A list with one component for each partition, giving the indexes (as
observations in the data) of the members of the partition. The first 
index is that of the associated <em>leader</em> (sometimes called 
<em>exemplar</em>).
</p>
</td></tr>
<tr><td><code>leaders</code></td>
<td>

<p>The indexes of the leaders for each partition.
</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>

<p>The centroids for each partition, as a matrix with rows corresponding to
the partitions and columns corresponding to variables if multidimensional.
These will be the data if <code>radius == 0</code>.
</p>
</td></tr>
<tr><td><code>variances</code></td>
<td>

<p>The variances for each partition, as a matrix with rows corresponding to
the partitions and columns corresponding to variables if multidimensional.
</p>
</td></tr>
<tr><td><code>ranges</code></td>
<td>

<p>A list with two components: <code>min</code> and <code>max</code> giving the
minimum and maximum values for each variable for each partition.
These <code>range</code> components are given as a matrix with rows 
corresponding to the partitions and columns corresponding to variables 
if multidimensional.
</p>
</td></tr>
<tr><td><code>maxdist</code></td>
<td>

<p>A vector with one value for each partition, giving the largest distance
from each leader to any member of its partition.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>J. A. Hartigan, <em>Clustering Algorithms</em>, Wiley, 1975.
</p>
<p>L. Wilkinson, Visualizing Outliers, Technical Report, University of
Illinois at Chicago, 2016.
<code>https://www.cs.uic.edu/~wilkinson/Publications/outliers.pdf</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LWradius">LWradius</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 radius.default &lt;- LWradius(nrow(faithful),ncol(faithful))
 lead &lt;- leader(faithful, radius = c(0,radius.default))

# number of partitions for each radius
 sapply(lead, function(x) length(x$partitions))

# plot the leaders for the non-zero radius
 plot( faithful[,1], faithful[,2], 
       main = "blue indicates leaders (default radius)", 
       pch = 16, cex = .5)
 ldrs &lt;- lead[[2]]$leaders
 points( faithful[ldrs,1], faithful[ldrs,2], 
         pch = 8, col = "dodgerblue", cex = .5)

</code></pre>

<hr>
<h2 id='logdens'>Log Density for Gaussian Mixture Model</h2><span id='topic+logdens'></span>

<h3>Description</h3>

<p>Computes the log density for observations in a univariate or multivariate
Gaussian mixture model with spherical or diagonal (co)variance that 
varies across components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logdens( x, simData, shrink = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logdens_+3A_x">x</code></td>
<td>

<p>A numeric vector or matrix for which the log density is to be computed.
</p>
</td></tr>
<tr><td><code id="logdens_+3A_simdata">simData</code></td>
<td>

<p>Observations from a call to <code>simData</code>, which includes
the partition centroids and variance information for the underlying
simulation model.
</p>
</td></tr>
<tr><td><code id="logdens_+3A_shrink">shrink</code></td>
<td>

<p>Shrinkage parameter for the mixture model variance. To be
consistent with the shrinkage as described in <code>partProb</code>,
the variance is scaled by the <em>square</em> of <code>shrink</code>.
The default value is <code>shrink = 1</code>, so that no shrinkage is 
applied to the variance.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If either <code>radius = 0</code>, or <code>simData</code> returns only centroids 
(<code>nsim = 0</code>), then no density estimate is attempted.
</p>


<h3>Value</h3>

<p>A vector giving the log density of <code>x</code> in the model as
specified by <code>simData</code>, with optional shrinkage applied to the
variance.
</p>


<h3>References</h3>

<p>G. Celeux and G. Govaert, Gaussian Parsimonious Mixture Models,
<em>Pattern Recognition</em>, 1995.
</p>
<p>G. J. McLachlan and D. Peel, <em>Finite Mixture Models</em>, Wiley, 2000.
</p>
<p>C. Fraley and A. E. Raftery, Model-based clustering, discriminant analysis
and density estimation, 
<em>Journal of the American Statistical Association</em>, 2002.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partProb">partProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 lead &lt;- leader(faithful)
 sim &lt;- simData( lead)

 logdens( faithful, sim)

</code></pre>

<hr>
<h2 id='LWradius'>Wilkinson's default leader-partitioning radius</h2><span id='topic+LWradius'></span>

<h3>Description</h3>

<p>Wilkinson's default leader-partitioning radius.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LWradius( n, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LWradius_+3A_n">n</code></td>
<td>

<p>The number of observations (rows) in the data.
</p>
</td></tr>
<tr><td><code id="LWradius_+3A_p">p</code></td>
<td>

<p>The number of variables (columns) in the data; <code>p = 1</code> if
univariate.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Wilkinson's default leader partitioning radius <code>0.1/(log(n)^(1/p))</code>.
</p>


<h3>References</h3>

<p>L. Wilkinson (2016), Visualizing Outliers, Technical Report, University of
Illinois at Chicago, 
<code>https://www.cs.uic.edu/~wilkinson/Publications/outliers.pdf</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+leader">leader</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 x1 &lt;- rnorm(10000)
 LWradius(length(x1),1)

 LWradius(nrow(faithful),ncol(faithful))
</code></pre>

<hr>
<h2 id='OutlierStatistic'>Nonparametric Outlier Statistic</h2><span id='topic+OutlierStatistic'></span>

<h3>Description</h3>

<p>Robust nonparametric outlier statistic for univariate or multivariate data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OutlierStatistic( x, nproj=1000, prior=NULL, seed=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OutlierStatistic_+3A_x">x</code></td>
<td>

<p>A numeric vector or matrix for which the outlier statistic is to
be determined.
</p>
</td></tr>
<tr><td><code id="OutlierStatistic_+3A_nproj">nproj</code></td>
<td>

<p>If <code>x</code> is multivariate, the number of random projections to be used
in computing the statistic.
</p>
</td></tr>
<tr><td><code id="OutlierStatistic_+3A_prior">prior</code></td>
<td>

<p>If <code>x</code> is multivariate, a prior estimate of the statistic for each 
observation in <code>x</code>, to be used as a base line for maximization 
relative to new random projections.
</p>
</td></tr>
<tr><td><code id="OutlierStatistic_+3A_seed">seed</code></td>
<td>

<p>An optional integer argument to <code>set.seed</code> for reproducible
simulations. By default the current seed will be used.
Reproducibility can also be achieved by calling <code>set.seed</code>
before calling <code>OutlierStatistic</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector giving the maximum value of the outlier statistic for each 
observation over all projections.
</p>


<h3>References</h3>

<p>W. A. Stahel, <em>Breakdown of Covariance Estimators</em>, doctoral thesis,
Fachgruppe Fur Statistik, Eidgenossische Technische Hochshule (ETH), 1981.
</p>
<p>D. L. Donoho, <em>Breakdown Properties of Multivariate Location Estimators</em>,
doctoral thesis, Department of Statistics, Harvard University, 1982.
</p>


<h3>Note</h3>

<p>Note that partition probabilities are computed from an exponential distribution
fit to the outlier statistic, rather than from the empirical distribution
of the outlier statistic.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partProb">partProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 stat &lt;- OutlierStatistic(faithful)
 q.99 &lt;- quantile(stat,.99)
 out &lt;- stat &gt; q.99

 plot( faithful[,1], faithful[,2], 
       main="red : .99 quantile for outlier statistic", cex=.5)
 points( faithful[out,1], faithful[out,2], 
         pch = 4, col = "red", lwd = 1, cex = .5)

 require(mvtnorm)

 set.seed(0)
 Sigma &lt;- crossprod(matrix(rnorm(2*2),2,2))
 x &lt;- rmvt( 10000, sigma = Sigma, df = 2) 

 stat &lt;- OutlierStatistic(x)
 q.95 &lt;- quantile(stat,.95)

 hist(x, main = "gray : .95 quantile for outlier statistic", col = "black")
 abline( v = x[stat &gt; q.95], col = "gray")
 hist(x, col = "black", add = TRUE)
</code></pre>

<hr>
<h2 id='partProb'>Partition outlier probabilities</h2><span id='topic+partProb'></span>

<h3>Description</h3>

<p>Assigns outlier probabilities to the partitions by fitting an exponential 
distribution to a nonparametric outlier statistic for simulated
data or partition centroids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partProb( simData, method = c("intrinsic","distance","logdensity","distdens",
          "density"), shrink = 1, nproj = 1000, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partProb_+3A_simdata">simData</code></td>
<td>

<p>Observations from a call to <code>simData</code>, which includes
the partition centroids and (optionally) simulated data as well.
</p>
</td></tr>
<tr><td><code id="partProb_+3A_method">method</code></td>
<td>
<p>One of the following options:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>"intrinsic"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> outlier statistic applied to simulation data 
                     (centroids if no simulation) </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"distance"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> outlier statistic applied to distances between
                      NN partitions </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"logdensity"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> outlier statistic applied to
             differences in log density between NN partitions</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"distdens"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> outlier statistic applied to a matrix
        consisting of the <code>"distance"</code> and
             <code>"logdensity"</code> values </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"density"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> outlier statistic applied to
             smallest/largest ratios of density between NN partitions
   </td>
</tr>

</table>

<p>The default is to use the <code>"intrinsic"</code> method.
</p>
</td></tr>
<tr><td><code id="partProb_+3A_shrink">shrink</code></td>
<td>

<p>Shrinkage parameter for outlier detection data. The offsets from
<code>simData</code> are scaled by this factor before adding them to the
partition centroids as data for outlier detection. The default
value is <code>shrink = 1</code>, so that no shrinkage is applied to
simulation offsets.
</p>
</td></tr>
<tr><td><code id="partProb_+3A_nproj">nproj</code></td>
<td>

<p>If the data is multivariate or <code>method = "distdens"</code>, 
the number of random projections to be used
to obtain the outlier statistic.
</p>
</td></tr>
<tr><td><code id="partProb_+3A_seed">seed</code></td>
<td>

<p>An optional integer argument to <code>set.seed</code> for reproducible
outlier statistics. By default the current seed will be used.
Reproducibility can also be achieved by calling <code>set.seed</code>
before calling <code>partProb</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>"logdensity"</code> is generally prefered over <code>"density"</code>, because
negative values that are large in magniude
of the logarithm of the density will not be 
numerically distinguishable as density values.
</p>


<h3>Value</h3>

<p>A vector of probabilities for each partition, obtained by fitting an
exponential distribution to the outlier statistic.
</p>


<h3>References</h3>

<p>C. Fraley, Estimating Outlier Probabilities for Large Datasets, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simData">simData</a></code>,
<code><a href="#topic+OutlierStatistic">OutlierStatistic</a></code>,
<code><a href="#topic+allProb">allProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 set.seed(0)

 lead &lt;- leader(faithful)
 nlead &lt;- length(lead[[1]]$partitions)

# repeat multiple times to account for randomness
 ntimes &lt;- 100
 probs &lt;- matrix( NA, nlead, ntimes)
 for (i in 1:ntimes) {
    probs[,i] &lt;- partProb( simData(lead[[1]]), method = "distance")
 }

# median probability for each partition
 partprobs &lt;- apply( probs, 1, median)

 quantile(probs)

# plot leaders with outlier probability &gt; .95
 plot( faithful[,1], faithful[,2], pch = 16, cex = .5,
       main = "red : leaders with outlier probability &gt; .95")
 out &lt;- partprobs &gt; .95
 l &lt;- lead[[1]]$leaders
 points( faithful[l[out],1], faithful[l[out],2], pch = 8, cex = 1, col = "red")

</code></pre>

<hr>
<h2 id='simData'>Simulates observations for outlier determination.</h2><span id='topic+simData'></span>

<h3>Description</h3>

<p>Simulates observations from a mixture model based on information on
partitions from the <code>leader</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simData( leaderInstance, nsim=NULL, model=c("diagonal","spherical"), seed=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simData_+3A_leaderinstance">leaderInstance</code></td>
<td>

<p>A	single component from a call to <code>leader</code>, giving Leader Algorithm
results for one value of the partitioning radius.
</p>
</td></tr>
<tr><td><code id="simData_+3A_nsim">nsim</code></td>
<td>

<p>The number of observations to be simulated. Only the radius and centroids
are returned of <code>nsim = 0</code> or <code>leaderInstance$radius == 0</code>)
&mdash; no observations are simulated. <br />
Default: <code>min(# observations,max(# partitions, 1000))</code>.
</p>
</td></tr>
<tr><td><code id="simData_+3A_model">model</code></td>
<td>

<p>For multivariate data, a vector of character strings indicating the type of
Gaussian mixture model covariance to be used in generating the simulated 
observations (see <code>details</code>). <br />
For univariate data, the observations are generated from a model
in which the variances may vary across components.
</p>
</td></tr>
<tr><td><code id="simData_+3A_seed">seed</code></td>
<td>

<p>An optional integer argument to <code>set.seed</code> for reproducible
simulations. By default the current seed will be used.
Reproducibility can also be achieved by calling <code>set.seed</code>
before calling <code>simData</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following models are available for multivariate data:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"spherical"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> spherical, varying volume </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"diagonal"</code> </td><td style="text-align: center;"> : </td><td style="text-align: left;"> diagonal, varying volume and shape </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td>
</tr>

</table>

<p>An ellipsoidal model is also possible, but has not yet been implemented. <br />
If <code>nsim = 0</code> or <code>leaderInstance$radius == 0</code>, no observations are 
simulated, and only the radius and partition centroids are returned.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>radius</code></td>
<td>
<p>The value of the radius associated with <code>leaderInstance</code>.</p>
</td></tr>
<tr><td><code>location</code></td>
<td>

<p>The vector or matrix of centroids of the partitions. If a matrix,
rows correspond to the partitions and columns to the variables.
</p>
</td></tr>
<tr><td><code>index</code></td>
<td>

<p>A vector of integer values giving the index of the partition associated 
with each simulated observation.
</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>

<p>A vector of numeric values giving offset for the simulated observations 
from their associated centroids.
</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>

<p>A vector of numeric values between 0 and 1 giving the proportion of data 
observations in each partition.
</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>

<p>The scale (variance) of the mixture components in a univariate or
spherical model. Set to 1 for each component in the diagonal model.
</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>

<p>A matrix giving the variances of the mixture component in a diagonal
model. The rows correspond to the dimensions of the data, while the
columns correspond to the mixture components (partitions).
</p>
</td></tr>
</table>


<h3>References</h3>

<p>C. Fraley, Estimating Outlier Probabilities for Large Datasets, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+leader">leader</a></code>,
<code><a href="#topic+partProb">partProb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 radius.default &lt;- LWradius(nrow(faithful),ncol(faithful))
 lead &lt;- leader(faithful, radius = c(0,radius.default))

# (simulated) data for outlier statistic (no simulation for radius = 0)
 sim &lt;- lapply( lead, simData)

# components of simData output
 lapply( sim, names)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
