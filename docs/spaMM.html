<!DOCTYPE html><html><head><title>Help for package spaMM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {spaMM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjlg'>
<p>Simulated data set for testing sparse-precision code</p></a></li>
<li><a href='#AIC'>
<p>Extractors for information criteria such as AIC</p></a></li>
<li><a href='#algebra'><p>Control of matrix-algebraic methods</p></a></li>
<li><a href='#arabidopsis'>
<p>Arabidopsis genetic and climatic data</p></a></li>
<li><a href='#ARp'>
<p>Random effect with AR(p) (autoregressive of order p) or ARMA(p,q) structure.</p></a></li>
<li><a href='#as_LMLT'>
<p>Conversion to input for procedures from lmerTest package</p></a></li>
<li><a href='#autoregressive'>
<p>Fitting autoregressive models</p></a></li>
<li><a href='#beta_resp'>
<p>Beta-response family object</p></a></li>
<li><a href='#betabin'>
<p>Beta-binomial family object</p></a></li>
<li><a href='#blackcap'>
<p>Genetic polymorphism in relation to migration in the blackcap</p></a></li>
<li><a href='#CauchyCorr'>
<p>Cauchy correlation function and Cauchy formula term</p></a></li>
<li><a href='#clinics'>
<p>Toy dataset for binomial response</p></a></li>
<li><a href='#COMPoisson'>
<p>Conway-Maxwell-Poisson (COM-Poisson) GLM family</p></a></li>
<li><a href='#composite-ranef'>
<p>Composite random effects</p></a></li>
<li><a href='#confint.HLfit'>
<p>Confidence intervals</p></a></li>
<li><a href='#control.HLfit'>
<p>Control parameters of the HLfit fitting algorithm</p></a></li>
<li><a href='#convergence'>
<p>Assessing convergence for fitted models</p></a></li>
<li><a href='#corMatern'><p>Matern Correlation Structure as a corSpatial object</p></a></li>
<li><a href='#corr_family'>
<p><code>corr_family</code> objects</p></a></li>
<li><a href='#corrFamily'>
<p>Using corrFamily constructors and descriptors.</p></a></li>
<li><a href='#corrFamily-definition'>
<p>corrFamily definition</p></a></li>
<li><a href='#corrFamily-design'>
<p>Designing new corrFamily descriptors for parametric correlation families</p></a></li>
<li><a href='#corrHLfit'>
<p>Fits a mixed model, typically a spatial GLMM.</p></a></li>
<li><a href='#corrMatrix'><p>Using a corrMatrix argument</p></a></li>
<li><a href='#covStruct'><p>Specifying correlation structures</p></a></li>
<li><a href='#diallel'>
<p>Random-effect structures for diallel experiments and other dyadic interactions</p></a></li>
<li><a href='#div_info'>
<p>Information about numerical problems</p></a></li>
<li><a href='#DoF'>
<p>Degrees of freedom extractor</p></a></li>
<li><a href='#dofuture'>
<p>Interface for parallel computations</p></a></li>
<li><a href='#dopar'>
<p>Interface for parallel computations</p></a></li>
<li><a href='#drop1.HLfit'>
<p>Drop all possible single fixed-effect terms from a model</p></a></li>
<li><a href='#eval_replicate'>
<p>Evaluating bootstrap replicates</p></a></li>
<li><a href='#external-libraries'>
<p>Installing external libraries</p></a></li>
<li><a href='#extractors'>
<p>Functions to extract various components of a fit.</p></a></li>
<li><a href='#extreme_eig'>
<p>Utilities for regularization of a matrix</p></a></li>
<li><a href='#fitme'>
<p>Fitting function for fixed- and mixed-effect models with GLM response.</p></a></li>
<li><a href='#fitmv'>
<p>Fitting multivariate responses</p></a></li>
<li><a href='#fix_predVar'>
<p>Prediction from models with nearly-singular covariance matrices</p></a></li>
<li><a href='#fixed'><p>Fixing some parameters</p></a></li>
<li><a href='#fixedLRT'>
<p>Likelihood ratio test of fixed effects.</p></a></li>
<li><a href='#freight'><p>Freight dataset</p></a></li>
<li><a href='#get_cPredVar'>
<p>Estimation of prediction variance with bootstrap correction</p></a></li>
<li><a href='#get_inits_from_fit'>
<p>Initiate a fit from another fit</p></a></li>
<li><a href='#get_matrix'>
<p>Extract matrices from a fit</p></a></li>
<li><a href='#get_ranPars'>
<p>Operations on lists of parameters</p></a></li>
<li><a href='#get_RLRsim_args'>
<p>Extractors of arguments for functions from package RLRsim</p></a></li>
<li><a href='#good-practice'><p>Clear and trustworthy formulas and prior weights</p></a></li>
<li><a href='#Gryphon'>
<p>Gryphon data</p></a></li>
<li><a href='#hatvalues.HLfit'>
<p>Leverage extractor for HLfit objects</p></a></li>
<li><a href='#HLCor'>
<p>Fits a (spatially) correlated mixed model, for given correlation parameters</p></a></li>
<li><a href='#HLfit'><p>Fit mixed models with given correlation matrix</p></a></li>
<li><a href='#how'>
<p>Extract information about how an object was obtained</p></a></li>
<li><a href='#inits'>
<p>Controlling optimization strategy through initial values</p></a></li>
<li><a href='#inverse.Gamma'>
<p>Distribution families for Gamma and inverse Gamma-distributed random effects</p></a></li>
<li><a href='#is_separated'>
<p>Checking for (quasi-)separation in binomial-response model.</p></a></li>
<li><a href='#Leuca'>
<p>Leucadendron data</p></a></li>
<li><a href='#lev2bool'>
<p>Conversion of factor to 0/1 variable</p></a></li>
<li><a href='#llm.fit'>
<p>Link-linear regression models (LLMs)</p></a></li>
<li><a href='#Loaloa'>
<p>Loa loa prevalence in North Cameroon, 1991-2001</p></a></li>
<li><a href='#LRT'>
<p>ANOVA tables, and likelihood ratio tests of fixed and random effects.</p></a></li>
<li><a href='#make_scaled_dist'><p>Scaled distances between unique locations</p></a></li>
<li><a href='#mapMM'>
<p>Colorful plots of predictions in two-dimensional space.</p></a></li>
<li><a href='#mat_sqrt'>
<p>Computation of &ldquo;square root&rdquo; of symmetric positive definite matrix</p></a></li>
<li><a href='#MaternCorr'>
<p>Matern correlation function and Matern formula term.</p></a></li>
<li><a href='#MaternIMRFa'>
<p>corrFamily constructor for Interpolated Markov Random Field (IMRF) covariance structure approximating a 2D Matern correlation model.</p></a></li>
<li><a href='#method'>
<p>Fitting methods (objective functions maximized)</p></a></li>
<li><a href='#MSFDR'>
<p>Multiple-Stage False Discovery Rate procedure</p></a></li>
<li><a href='#multIMRF'>
<p>Interpolated Markov Random Field models</p></a></li>
<li><a href='#multinomial'><p>Analyzing multinomial data</p></a></li>
<li><a href='#mv'>
<p>Virtual factor for multivariate responses</p></a></li>
<li><a href='#negbin'>
<p>Family function for negative binomial &ldquo;2&rdquo; response (including truncated variant).</p></a></li>
<li><a href='#negbin1'>
<p>Alternative negative-binomial family</p></a></li>
<li><a href='#numInfo'>
<p>Information matrix</p></a></li>
<li><a href='#options'><p>spaMM options settings</p></a></li>
<li><a href='#pedigree'><p>Fit mixed-effects models incorporating pedigrees</p></a></li>
<li><a href='#phi-resid.model'><p>Residual dispersion model for gaussian and Gamma response</p></a></li>
<li><a href='#plot_effects'>
<p>Partial-dependence effects and plots</p></a></li>
<li><a href='#plot.HLfit'>
<p>Model checking plots for mixed models</p></a></li>
<li><a href='#PLS-internals'><p>Internal functions for procedure using the ((I,0),(Z,X)) block-order</p></a></li>
<li><a href='#Poisson'>
<p>Family function for GLMs and mixed models with Poisson and zero-truncated Poisson response.</p></a></li>
<li><a href='#post-fit'>
<p>Applying post-fit procedures on spaMM results</p></a></li>
<li><a href='#predict'>
<p>Prediction from a model fit</p></a></li>
<li><a href='#predVar'><p>Prediction and response variances</p></a></li>
<li><a href='#pseudoR2'>
<p>Pseudo R-squared</p></a></li>
<li><a href='#random-effects'>
<p>Structure of random effects</p></a></li>
<li><a href='#rankinfo'>
<p>Checking the rank of the fixed-effects design matrix</p></a></li>
<li><a href='#register_cF'>
<p>Declare corrFamily constructor for use in formula</p></a></li>
<li><a href='#resid.model'><p>Structured dispersion models</p></a></li>
<li><a href='#residuals.HLfit'>
<p>Extract model residuals</p></a></li>
<li><a href='#residVar'>
<p>Residual variance extractor</p></a></li>
<li><a href='#salamander'>
<p>Salamander mating data</p></a></li>
<li><a href='#scotlip'><p>Lip cancer in Scotland 1975 - 1980</p></a></li>
<li><a href='#seaMask'>
<p>Masks of seas or lands</p></a></li>
<li><a href='#seeds'>
<p>Seed germination data</p></a></li>
<li><a href='#setNbThreads'>
<p>Parallel computations in fits</p></a></li>
<li><a href='#simulate.HLfit'>
<p>Simulate realizations of a fitted model.</p></a></li>
<li><a href='#spaMM'><p>Inference in mixed models, in particular spatial GLMMs</p></a></li>
<li><a href='#spaMM_boot'>
<p>Parametric bootstrap</p></a></li>
<li><a href='#spaMM_glm.fit'><p>Fitting generalized linear models without initial-value or divergence headaches</p></a></li>
<li><a href='#spaMM-conventions'><p>spaMM conventions and differences from related fitting procedures</p></a></li>
<li><a href='#spaMM-internal'><p>Internal spaMM Functions</p></a></li>
<li><a href='#spaMM-S3'><p>S3 methods of generics defined in other packages</p></a></li>
<li><a href='#spaMM.colors'>
<p>A flashy color palette.</p></a></li>
<li><a href='#spaMM.filled.contour'><p>Level (Contour) Plots with better aspect ratio control (for geographical maps, at least)</p></a></li>
<li><a href='#stripHLfit'>
<p>Reduce the size of fitted objects</p></a></li>
<li><a href='#summary.HLfit'>
<p>Summary and print methods for fit and test results.</p></a></li>
<li><a href='#update.HLfit'>
<p>Updates a fit</p></a></li>
<li><a href='#vcov'>
<p>Extract covariance or correlation components from a fitted model object</p></a></li>
<li><a href='#verbose'><p>Tracking progress of fits</p></a></li>
<li><a href='#wafers'><p>Data from a resistivity experiment for semiconductor materials.</p></a></li>
<li><a href='#welding'>
<p>Welding data set</p></a></li>
<li><a href='#WinterWheat'>
<p>Example of yield stability analysis</p></a></li>
<li><a href='#wrap_parallel'>
<p>Selecting interfaces for parallelisation</p></a></li>
<li><a href='#X.GCA'>
<p>Fixed-effect terms for dyadic interactions</p></a></li>
<li><a href='#ZAXlist'><p>S4 classes for structured matrices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Mixed-Effect Models, with or without Spatial Random Effects</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>4.4.16</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-20</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>François Rousset &lt;francois.rousset@umontpellier.fr&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, graphics, Matrix, MASS, proxy, Rcpp (&ge;
0.12.10), nlme, nloptr, minqa, pbapply, crayon, gmp (&ge; 0.6.0),
ROI, boot, geometry (&ge; 0.4.0), numDeriv, backports</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen (&ge; 0.3.3.5.0)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>maps, testthat, rcdd, foreach, future, future.apply, Infusion
(&ge; 1.3.0), IsoriX (&ge; 0.8.1), blackbox (&ge; 1.1.25), RSpectra,
ROI.plugin.glpk, lme4, rsae, multilevel, agridat</td>
</tr>
<tr>
<td>Enhances:</td>
<td>multcomp, RLRsim, lmerTest</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU Scientific Library (GSL)</td>
</tr>
<tr>
<td>Description:</td>
<td>Inference based on models with or without spatially-correlated random effects, multivariate responses, or non-Gaussian random effects (e.g., Beta). Variation in residual variance (heteroscedasticity) can itself be represented by a mixed-effect model. Both classical geostatistical models (Rousset and Ferdy 2014 &lt;<a href="https://doi.org/10.1111%2Fecog.00566">doi:10.1111/ecog.00566</a>&gt;), and Markov random field models on irregular grids (as considered in the 'INLA' package, <a href="https://www.r-inla.org">https://www.r-inla.org</a>), can be fitted, with distinct computational procedures exploiting the sparse matrix representations for the latter case and other autoregressive models. Laplace approximations are used for likelihood or restricted  likelihood. Penalized quasi-likelihood and other variants discussed in the h-likelihood literature (Lee and Nelder 2001 &lt;<a href="https://doi.org/10.1093%2Fbiomet%2F88.4.987">doi:10.1093/biomet/88.4.987</a>&gt;) are also implemented. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.cecill.info/licences/Licence_CeCILL_V2-en.txt">CeCILL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.r-project.org">https://www.r-project.org</a>,
<a href="https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref">https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-20 12:22:10 UTC; francois.rousset</td>
</tr>
<tr>
<td>Author:</td>
<td>François Rousset <a href="https://orcid.org/0000-0003-4670-0371"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Jean-Baptiste Ferdy [aut, cph],
  Alexandre Courtiol
    <a href="https://orcid.org/0000-0003-0637-2959"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-20 13:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjlg'>
Simulated data set for testing sparse-precision code
</h2><span id='topic+adjlg'></span><span id='topic+adjlgMat'></span>

<h3>Description</h3>

<p>This is used in <code>tests/test-adjacency-long.R</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("adjlg")</code></pre>


<h3>Format</h3>

<p>Includes an adjacency matrix <code>adjlgMat</code>. and a data frame <code>adjlg</code> with 5474 observations on the following 8 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>a factor with levels <code>1</code> to <code>1000</code></p>
</dd>
<dt><code>months</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GENDER</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>AGE</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>month</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BUY</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>The simulation code shown below is derived from an example produced by Jeroen van den Ochtend. 
Following a change incorporated in spaMM version 3.8.0, that implied stricter checks of the input matrix, it appeared that the precision matrix generated by this example had inappropriate (repeated) dimnames. This example was then updated to reproduce past fitting results with a correctly formatted matrix. Note that changing the names of an adjacency matrix (as below) is generally unwise as it generally changes the statistical model because these names are matched whenever possible to levels of the grouping factor in the data.
</p>
<p>The code was also modified to compensate for changes in R's default random number generator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(adjlg)
## See further usage in tests/test-adjacency-long.R
## Not run: 
# as produced by:
  library(data.table) ## Included data produced using version 1.10.4.3
  library(igraph) ## Included data produced using version 1.2.1
  
  rsample &lt;- function(N=100, ## size of implied adjacency matrix
                      month_max=10,seed) {
    if (is.integer(seed)) set.seed(seed)
    dt &lt;- data.table(ID=factor(1:N))
    dt$months &lt;- sample(1:month_max,N,replace=T) ## # of liens for each level of ID
    dt$GENDER &lt;- sample(c("MALE","FEMALE"),N,replace=TRUE)
    dt$AGE &lt;- sample(18:99,N,replace=T)
    dt$X1 &lt;- sample(1000:9900,N,replace=T)
    dt$X2 &lt;-  runif(N)
    
    dt &lt;- dt[, c(.SD, month=data.table(seq(from=1, to=months, by = 1))), by = ID] 
    dt[,BUY := 0]
    dt[month.V1==months,BUY := sample(c(0,1),1),by=ID]
    setnames(dt,"month.V1","month")
    
    #### create adjacency matrix
    Network &lt;- data.table(OUT=sample(dt$ID,N*month_max*4/10))
    Network$IN &lt;- sample(dt$ID,N*month_max*4/10)
    Network &lt;- Network[IN != OUT]
    Network &lt;- unique(Network)
    g &lt;- graph.data.frame(Network,directed=F)
    g &lt;- add_vertices(g,sum(!unique(dt$ID) %in% V(g)),
             name=unique(dt[!dt$ID %in% V(g),list(ID)])) # =&gt; improper names
    Network &lt;- as_adjacency_matrix(g,sparse = TRUE,type="both")
    colnames(Network) &lt;- rownames(Network) &lt;- seq(nrow(Network)) # post-v3.8.0 names 
    return(list(data=dt,adjMatrix=Network))
  }

  RNGkind("Mersenne-Twister", "Inversion", "Rounding"  )
  set.seed(123)
  adjlg_sam &lt;- rsample(N=1000,seed=NULL) 
  RNGkind("Mersenne-Twister", "Inversion", "Rejection"  )
  #
  adjlg &lt;- as.data.frame(adjlg_sam$data)
  adjlgMat &lt;- adjlg_sam$adjMatrix

## End(Not run)
</code></pre>

<hr>
<h2 id='AIC'>
Extractors for information criteria such as AIC
</h2><span id='topic+get_any_IC'></span><span id='topic+AIC'></span><span id='topic+AIC.HLfit'></span><span id='topic+extractAIC'></span><span id='topic+extractAIC.HLfit'></span>

<h3>Description</h3>

<p><code>get_any_IC</code> computes model selection/information criteria such as AIC. See Details for more information about these criteria. The other extractors <code>AIC</code> and <code>extractAIC</code> are methods for <code>HLfit</code> objects of generic functions defined in other packages: <code>AIC</code> is equivalent to <code>get_any_IC</code> (for a single fitted-model object), and <code>extractAIC</code> returns the marginal AIC and the number of degrees of freedom for the fixed effects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_any_IC(object, nsim=0L, ..., verbose=interactive(),
           also_cAIC=TRUE, short.names=NULL)
## S3 method for class 'HLfit'
AIC(object, ..., nsim=0L, k, verbose=interactive(),
                    also_cAIC=TRUE, short.names=NULL)
## S3 method for class 'HLfit'
extractAIC(fit, scale, k, ..., verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AIC_+3A_object">object</code>, <code id="AIC_+3A_fit">fit</code></td>
<td>
<p>A object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="AIC_+3A_scale">scale</code>, <code id="AIC_+3A_k">k</code></td>
<td>
<p>Currently ignored, but are required in the definitions for consistency with the generic.</p>
</td></tr>
<tr><td><code id="AIC_+3A_verbose">verbose</code></td>
<td>
<p> Whether to print the model selection criteria or not. </p>
</td></tr>
<tr><td><code id="AIC_+3A_also_caic">also_cAIC</code></td>
<td>
<p>Whether to include the plug-in estimate of conditional AIC in the result (its computation may be slow).</p>
</td></tr>
<tr><td><code id="AIC_+3A_nsim">nsim</code></td>
<td>
<p>Controls whether to include the bootstrap estimate of conditional AIC (see Details) in the result. If positive, <code>nsim</code> gives the number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="AIC_+3A_short.names">short.names</code></td>
<td>
<p>NULL, or boolean; controls whether the return value uses short names (<code>mAIC</code>, etc., as shown by screen output if <code>verbose</code> is TRUE), or the descriptive names (<code>"   marginal AIC:"</code>, etc.) also shown in the screen output. Short names are more appropriate for programming but descriptive names may be needed for back-compatibility. The default (NULL) ensures back-compatibility by using descriptive names unless the bootstrap estimate of conditional AIC is reported.</p>
</td></tr>
<tr><td><code id="AIC_+3A_...">...</code></td>
<td>
<p>For <code>AIC.HLfit</code>: may include more fitted-model objects, consistently with the generic. For this and the other functions: other arguments that may be needed by some method. For example, if <code>nsim</code> is positive, a <code>seed</code> argument may be passed to <code>simulate</code>, and the other &ldquo;...&rdquo; may be used to control the optional parallel execution of the bootstrap computations (by providing arguments to <code><a href="#topic+dopar">dopar</a></code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AIC is a measure (by Kullback-Leibler directed distance, up to an additive constant) of quality of prediction of new data by a fitted model. 
Comparing information criteria may be viewed as a fast alternative to a comparison of the predictive accuracy of different models by cross-validation. Further procedures for model choice may also be useful (e.g. Williams, 1970; Lewis et al. 2010).
</p>
<p>The <b>conditional AIC</b> (Vaida and Blanchard 2005) applies the AIC concept to new realizations of a mixed model, conditional on the realized values of the random effects. Lee et al. (2006) and Ha et al (2007) defined a corrected AIC [i.e., AIC(D*) in their eq. 7] which is here interpreted as the conditional AIC. 
</p>
<p>Such Kullback-Leibler relative distances cannot generally be evaluated exactly and various estimates have been discussed.
<code>get_any_IC</code> computes, optionally prints, and returns invisibly one or more of the following quantities:<br /> 
* Akaike's classical AIC (<b>marginal AIC</b>, <code>mAIC</code>, i.e., minus twice the marginal log-likelihood plus twice the number of fitted parameters);<br /> 
* a plug-in estimate (<code>cAIC</code>) and/or a bootstrap estimate (<code>b_cAIC</code>) of the conditional AIC;<br /> 
* a focussed AIC for dispersion parameters (<b>dispersion AIC</b>, <code>dAIC</code>). 
</p>
<p>For the <b>conditional AIC</b>, Vaida and Blanchard's plug-in estimator involves the conditional likelihood, and degrees of freedom for (i) estimated residual error parameters and (ii) the overall linear predictor characterized by the <b>Effective degrees of freedom</b> already discussed by previous authors including Lee and Nelder (1996), which gave a plug-in estimator (<code class="reqn">p_D</code>) for it in HGLMs. 
By default, the plug-in estimate of both the conditional AIC and of <code class="reqn">n-p_D</code> (<code>GoFdf</code>, where <code class="reqn">n</code> is the length of the response vector) are returned by <code>get_any_IC</code>. But these are biased estimates of conditional AIC and effective df, and an alternative procedure is available for GLM response families if a non-default positive <code>nsim</code> value is used. In that case, the conditional AIC is estimated by a bootstrap version of Saefken et al. (2014)'s equation 2.5; this involves refitting the model to each bootstrap samples, so it may take time, and a full cross-validation procedure might as well be considered for model selection. 
</p>
<p>The dispersion AIC has been defined from restricted likelihood by Ha et al (2007; eq.10). The present implementation will use restricted likelihood only if made available by an REML fit, otherwise marginal likelihood is used.
</p>


<h3>Value</h3>

<p><code>get_any_IC</code>, a numeric vector whose possible elements are described in the Details, and whose names are controlled by the <code>short.names</code> argument. Note that the bootstrap computation actually makes sense and works also for fixed-effect models (although it is not clear how useful it is in that case). The return value will still refer to its results as conditional AIC.
</p>
<p>For <code>AIC</code>, If just one fit object is provided, the same return value as for <code>get_any_IC</code>. If multiple objects are provided, a data.frame built from such vectors, with rows corresponding to the objects.
</p>
<p>For <code>extractAIC</code>, a numeric vector of length 2, with first and second elements giving
</p>
<table>
<tr><td><code>* edf</code></td>
<td>
<p>the degree of freedom of the fixed-effect terms of the model
for the fitted model <code>fit</code>.</p>
</td></tr>
<tr><td><code>* AIC</code></td>
<td>
<p>the (marginal) Akaike Information Criterion for <code>fit</code>.</p>
</td></tr>
</table>
<p>Likelihood is broadly defined up to a constant, which opens the way for inconsistency between different likelihood and AIC computations. In <span class="pkg">spaMM</span>, likelihood is nothing else than the probability or probability density of the data as function of model parameters. No constant is ever added, in contrast to <code>stats::extractAIC</code> output, so there are discrepancies with the latter function (see Examples). 
</p>


<h3>References</h3>


<p>Ha, I. D., Lee, Y. and MacKenzie, G. (2007) Model selection for multi-component frailty models. Statistics in Medicine 26: 4790-4807.
</p>
<p>Lee Y. and Nelder. J. A. 1996. Hierarchical generalized linear models (with discussion). J. R. Statist. Soc. B, 58: 619-678. 
</p>
<p>Lewis, F., Butler, A. and Gilbert, L. (2011), A unified approach to model selection using the likelihood ratio test. Methods in Ecology and Evolution, 2: 155-162. <a href="https://doi.org/10.1111/j.2041-210X.2010.00063.x">doi:10.1111/j.2041-210X.2010.00063.x</a>
</p>

<p>Saefken B., Kneib T., van Waveren C.-S., Greven S. (2014) A unifying approach to the estimation of the conditional Akaike information in generalized linear mixed models. Electron. J. Statist. 8, 201-225. 
</p>
<p>Vaida, F., and Blanchard, S. (2005) Conditional Akaike information for mixed-effects models. Biometrika 92, 351-370.
</p>
<p>Williams D.A. (1970) Discrimination between regression models to determine the pattern of enzyme synthesis in synchronous cell cultures. Biometrics 26: 23-32.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
m1 &lt;- fitme(y ~ X1+X2+X3+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, 
            family=Gamma(log))

get_any_IC(m1) 
# =&gt; The plug-in estimate is stored in the 'm1' object 
#    as a result of the previous computation, and is now returned even by: 
get_any_IC(m1, also_cAIC=FALSE)

if (spaMM.getOption("example_maxtime")&gt;4) {
 get_any_IC(m1, nsim=100L, seed=123) # provides bootstrap estimate of cAIC.
 # (parallelisation options could be used, e.g. nb_cores=detectCores(logical=FALSE)-1L)
}

extractAIC(m1)

## Not run: 
# Checking (in)consistency with glm example from help("stats::extractAIC"):
utils::example(glm) # =&gt; provides 'glm.D93' fit object
logLik(glm.D93) # logL= -23.38066 (df=5)
dataf &lt;- data.frame(counts=counts,outcome=outcome, treatment=treatment)
extractAIC(fitme(counts ~ outcome + treatment, family = poisson(), data=dataf))
# =&gt; 56.76132 = -2 logL + 2* df
extractAIC(glm.D93) # 56.76132 too
#
# But for LM:
lm.D93 &lt;- lm(counts ~ outcome + treatment, data=dataf)
logLik(lm.D93) # logL=-22.78576 (df=6)
extractAIC(fitme(counts ~ outcome + treatment, data=dataf)) # 57.5715 = -2 logL + 2* df
extractAIC(lm.D93) # 30.03062

### Inconsistency also apparent in drop1 output for :
# Toy data from McCullagh &amp; Nelder (1989, pp. 300-2), as in 'glm' doc:
clotting &lt;- data.frame(
    u = c(5,10,15,20,30,40,60,80,100),
    lot1 = c(118,58,42,35,27,25,21,19,18),
    lot2 = c(69,35,26,21,18,16,13,12,12))
#    
drop1( fitme(lot1 ~ log(u), data = clotting), test = "F") # agains reports marginal AIC
# =&gt; this  may differ strongly from those returned by drop1( &lt; glm() fit &gt; ),
# but the latter are not even consistent with those from drop1( &lt; lm() fit &gt; )
# for linear models. Compare
drop1( lm(lot1 ~ log(u), data = clotting), test = "F") # consistent with drop1.HLfit()
drop1( glm(lot1 ~ log(u), data = clotting), test = "F") # inconsistent

## Discrepancies in drop1 output with Gamma() family:

gglm &lt;- glm(lot1 ~ 1, data = clotting, family=Gamma())
logLik(gglm) # -40.34633 (df=2)

spgglm &lt;-  fitme(lot1 ~ 1, data = clotting, family=Gamma())
logLik(spgglm)                      # -40.33777 (slight difference: 
#   see help("method") for difference in estimation method between glm() and fitme()).
# Yet this does not explain the following:

drop1(  fitme(lot1 ~ log(u), data = clotting, family=Gamma()), test = "F") 
# =&gt; second AIC is 84.676 as expected from above logLik(spgglm).
drop1( glm(lot1 ~ log(u), data = clotting, family=Gamma()), test = "F") 
# =&gt; second AIC is 1465.27, quite different from -2*logLik(gglm) + 2*df


## End(Not run)

</code></pre>

<hr>
<h2 id='algebra'>Control of matrix-algebraic methods</h2><span id='topic+algebra'></span><span id='topic+sparse_precision'></span>

<h3>Description</h3>

<p>Autocorrelated gaussian random effects can be specified in terms of their covariance matrix, or in terms of the precision matrix (i.e. inverse covariance matrix). In a pre-processing step, spaMM may assess whether such precision matrices are sparse but the correlation matrix is dense, and if so, it may use &ldquo;sparse-precision&rdquo; algorithms efficient for this case. If the precision matrix does not appear sufficiently sparser than the correlation matrix, correlation matrices are used, and they can themselves be sparse or dense, with distinct algebraic methods used in each case. 
</p>
<p>For example, when the model includes a corrMatrix term specified by a covariance matrix, the precision matrix may be computed to assess its sparseness. The Example below illustrates a case where detecting sparsity of the precision matrix allows a faster fit. However, such a comparison of correlation and precision matrices takes time and is not performed for all types of random-effect structures. Instead, some fast heuristics may be used (see Details). The default selection of methods may not always be optimal, and may be overcome by using the <code>control.HLfit</code> argument of the fitting function (or by <code>spaMM.options()</code>, see Details). In particular one can use either <code>control.HLfit=list(sparse_precision= &lt;TRUE|FALSE&gt;)</code> or 
<code>control.HLfit=list(algebra= &lt;"spprec"|"spcorr"|"decorr"&gt;)</code> with the obvious expected effects.
</p>
<p>Such control may be useful when you already know that the precision matrix is sparse (as spaMM may even kindly remind you of, see Example below). In that case, it is also efficient to specify the precision matrix directly (see Example in <code><a href="#topic+Gryphon">Gryphon</a></code>), as spaMM then assumes that sparse-precision methods are better without checking the correlation matrix.
</p>
<p>Such control may also be useful when the correlation matrix is nearly singular so that computation of its inverse fails. This may occur if the model is poorly specified, but also occurs sometimes for valid correlation models because inversion of large matrices though Cholesky methods is not numerically accurate enough. In the latter case, you may be directed to this documentation by an error message, and specifying <code>sparse_precision= FALSE</code> may be useful.
</p>


<h3>Details</h3>

<p>Currently the sparse-precision methods are selected by default in two cases (with possible exceptions indicated by specific messages): (1) for models including <code><a href="#topic+IMRF">IMRF</a></code> random effects; and (2) when the <code><a href="#topic+corrMatrix">corrMatrix</a></code> (or <code><a href="#topic+covStruct">covStruct</a></code>) syntax is used to provide a fixed precision matrix. Further, for models including autoregressive terms other than IMRF (i.e., adjacency, AR1), sparse-precision methods may or may not be selected on a simple heuristic based on the likely structure of the correlation matrix. 
</p>
<p>Algebraic methods can be controlled globally over all further fits by using<br /> 
<code>spaMM.options(sparse_precision= &lt;TRUE|FALSE&gt;)</code><br /> 
and, among the correlation-based methods,<br /> 
<code>spaMM.options(QRmethod= &lt;"sparse"|"dense"&gt;)</code><br /> 
to select <code>"spcorr"</code> vs. <code>"decorr"</code> methods. Fit-specific controls (by <code>control.HLfit</code>) override these global ones.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pedigree">pedigree</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;6) {
 data("Gryphon")
 
 gry_df &lt;- fitme(BWT ~ 1 + corrMatrix(1|ID), corrMatrix = Gryphon_A, 
                 data = Gryphon_df, method = "REML")
 how(gry_df)
               
 # =&gt; Note the message about 'Choosing matrix methods...'. 
 # Using control.HLfit=list(algebra="spprec") would indeed 
 # save the time used to select this method.
 
 # Conversely, using a correlation-based method would be a waste of time:
 
 gry_dn &lt;- fitme(BWT ~ 1 + corrMatrix(1|ID), corrMatrix = Gryphon_A, 
               data = Gryphon_df, method = "REML",
               control.HLfit=list(sparse_precision=FALSE))
 how(gry_dn) # forced dense-correlation methods, which is slower here.
}

</code></pre>

<hr>
<h2 id='arabidopsis'>
Arabidopsis genetic and climatic data
</h2><span id='topic+arabidopsis'></span>

<h3>Description</h3>

<p>For 948 &ldquo;accessions&rdquo; from European Arabidopsis thaliana populations, this data set merges the genotypic information at 
four single nucleotide polymorphisms (SNP) putatively involved in adaptation to climate (Fournier-Level et al, 2011, Table 1), 
with 13 climatic variables from Hancock et al. (2011). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("arabidopsis")</code></pre>


<h3>Format</h3>

<p>The data frame includes 948 observations on the following variables:
</p>

<dl>
<dt>pos1046738, pos5510910, pos6235221, pos8132698</dt><dd><p>Genotypes at four SNP loci</p>
</dd>
<dt>LAT</dt><dd><p>latitude</p>
</dd>
<dt>LONG</dt><dd><p>longitude</p>
</dd>
<dt>seasonal, tempWarmest, tempColdest, preciWettest,
preciDriest, preciCV, PAR_SPRING,</dt><dd></dd> 
<dt>growingL, conseqCold, conseqFrFree, RelHumidSp, dayLSp, aridity</dt><dd><p>Thirteen climatic variables. 
See Hancock et al. (2011) for details about these variables.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The  response is binary so <code>method="PQL/L"</code> seems warranted (see Rousset and Ferdy, 2014).  
</p>


<h3>Source</h3>

<p>The data were retrieved from <code>http://bergelson.uchicago.edu/regmap-data/climate-genome-scan</code> on 22 February 2013 (they may no longer be available from there).
</p>


<h3>References</h3>

<p>Fournier-Level A, Korte A., Cooper M. D., Nordborg M., Schmitt J., Wilczek AM (2011). A map of local adaptation in Arabidopsis thaliana. Science 334: 86-89.
</p>
<p>Hancock, A. M., Brachi, B., Faure, N., Horton, M. W., Jarymowycz, L. B., Sperone, F. G., Toomajian, C., Roux, F., and Bergelson, J. 2011. 
Adaptation to climate across the Arabidopsis thaliana genome, Science 334: 83-86.
</p>
<p>Rousset F., Ferdy, J.-B. (2014) Testing environmental and genetic effects in the presence of spatial autocorrelation. Ecography, 37: 781-790.
<a href="https://doi.org/10.1111/ecog.00566">doi:10.1111/ecog.00566</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("arabidopsis")
if (spaMM.getOption("example_maxtime")&gt;2.5) {
  fitme(cbind(pos1046738,1-pos1046738)~seasonal+Matern(1|LAT+LONG),
        fixed=list(rho=0.119278,nu=0.236990,lambda=8.599),
        family=binomial(),method="PQL/L",data=arabidopsis)
}
## The above 'fixed' values are deduced from the following fit:
if (spaMM.getOption("example_maxtime")&gt;46) {
  SNPfit &lt;- fitme(cbind(pos1046738,1-pos1046738)~seasonal+Matern(1|LAT+LONG),
              verbose=c(TRACE=TRUE), 
              family=binomial(),method="PQL/L",data=arabidopsis)
  summary(SNPfit) # p_v=-125.0392
}
</code></pre>

<hr>
<h2 id='ARp'>
Random effect with AR(p) (autoregressive of order p) or ARMA(p,q) structure.
</h2><span id='topic+ARp'></span><span id='topic+ARMA'></span>

<h3>Description</h3>

<p>These times-series correlation models can be declared as correlation models for random effect. 
The AR(p) model is here parametrized by the <b>partial</b> correlation coefficients of the levels of the random effect, {U_t}, corr(U_s,U_t|U_(s+1),...,U_(t-1)), with valid values in the hypercube ]-1,,1[^p (Barndorff-Nielsen and Schou, 1973). 
In the autoregressive-moving average ARMA(p,q) model, the AR part is parametrized in the same way. AR parameters are named <code>"p1"</code>, <code>"p2"</code>..., and MA parameters are named <code>"q1"</code>, <code>"q2"</code>... .
</p>
<p>Implementation of the AR(p) model uses the sparsity of the inverse covariance matrix. In the ARMA(p,q) model, neither the covariance nor its inverse are sparse, so fits are expected to be more time- and memory-consuming. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'># corrFamily constructors:
ARp(p=1L, fixed=NULL, corr=TRUE, tpar=1/(1+seq(p)))
ARMA(p=1L, q=1L, fixed=NULL, tpar=c(1/(1+seq_len(p)),1/(1+seq_len(q))))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ARp_+3A_p">p</code></td>
<td>
<p>Integer: order of the autoregressive process.</p>
</td></tr>
<tr><td><code id="ARp_+3A_q">q</code></td>
<td>
<p>Integer: order of the moving-average process.</p>
</td></tr>
<tr><td><code id="ARp_+3A_tpar">tpar</code></td>
<td>

<p>Numeric vector: template values of the <b>partial coefficient coefficients</b> of the autoregressive process, and the traditional coefficients of the moving-average processe, in this order. The <code>tpar</code> vector must always have full length, even when some parameters are fixed.</p>
</td></tr>
<tr><td><code id="ARp_+3A_fixed">fixed</code></td>
<td>
<p>NULL or numeric vector, to fix the parameters of this model.</p>
</td></tr>
<tr><td><code id="ARp_+3A_corr">corr</code></td>
<td>
<p>For development purposes, better ignored in normal use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>ARp</code> and <code>ARMA</code> functions return a <code><a href="#topic+corrFamily">corrFamily</a></code> descriptor, hence a <code>list</code> including element <code>Cf</code>, a function returning, for given ARMA or AR parameters, the correlation matrix for <code>ARMA</code>, or its <b>inverse</b> for <code>ARp</code>.
</p>
<p>The fitted correlation matrix can be extracted from a fit object, as for any autocorrelated random effect, by <code>Corr(</code>&lt;fit object&gt;<code>)[[</code>&lt;random-effect index&gt;<code>]]</code>. 
</p>


<h3>References</h3>

<p>Barndorff-Nielsen 0. and Schou G., 1973 On the parametrization of autoregressive models by partial autocorrelations. J. Multivariate Analysis 3: 408-419. <a href="https://doi.org/10.1016/0047-259X%2873%2990030-4">doi:10.1016/0047-259X(73)90030-4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;2) {
ts &lt;- data.frame(lh=lh,time=seq(48)) ## using 'lh' data from 'stats' package

## Default 'tpar' =&gt; AR1 model 
#
(ARpfit &lt;-  fitme(lh ~ 1 + ARp(1|time), data=ts, method="REML"))
#
## which is equivalent to
#
(AR1fit &lt;- fitme(lh ~ 1 +AR1(1|time), data=ts, method="REML"))

## AR(3) model 
#
(AR3fit &lt;- fitme(lh ~ 1 + ARp(1|time, p=3), data=ts, method="REML"))

## Same but with fixed 2-lag partial autocorrelation 
#
(AR3fix &lt;- fitme(lh ~ 1 + ARp(1|time, p=3, fixed=c(p2=0)), data=ts, method="REML"))
#      
# The fit should be statistically equivalent to
#
(AR3_fix &lt;- fitme(lh ~ 1 + ARp(1|time, p=3), data=ts, method="REML",
                 fixed=list(corrPars=list("1"=c(p2=0)))))
#                 
# with subtle differences in the structure of the fit objects:
#
get_ranPars(AR3fix)$corrPars     # p2 was not a parameter of the model
get_ranPars(AR3_fix)$corrPars    # p2 was a fixed parameter of the model
#
# get_fittefPars() expectedly ignores 'p2' whichever way it was fixed.    


## Same as 'AR3fix' but with an additional MA(1) component
#
(ARMAfit &lt;- fitme(lh ~ 1 + ARMA(1|time, p=3, q=1, fixed=c(p2=0)), 
                  data=ts, method="REML"))
}


</code></pre>

<hr>
<h2 id='as_LMLT'>
Conversion to input for procedures from lmerTest package
</h2><span id='topic+as_LMLT'></span><span id='topic+LMLTslots'></span><span id='topic+class+3ALMLTslots'></span><span id='topic+LMLTslots-class'></span><span id='topic+model.matrix.LMLTslots'></span>

<h3>Description</h3>

<p>The <code>lmerTest::contest</code> function, <code>drop1</code> and <code>anova</code> methods implement a number of tests for linear mixed models, e.g. using effective degrees of freeedom based on (a generalization of) Satterthwaite's method. These tests can be performed using <span class="pkg">spaMM</span> fits through the conversion of the fit object, by the <code>as_LMLT</code> function, to an ad-hoc format acceptable as input to <span class="pkg">lmerTest</span>'s internal procedures. The separately documented <code><a href="#topic+drop1.HLfit">drop1.HLfit</a></code> and (optionally) <code><a href="#topic+anova.HLfit">anova.HLfit</a></code> methods, when called on a single LMM fit object, perform the conversion by <code>as_LMLT</code> and call <code>drop1</code> or <code>anova</code> methods defined by <span class="pkg">lmerTest</span>.
</p>
<p>Only the tests using <span class="pkg">lmerTest</span>'s default method <code>ddf="Satterthwaite"</code> are formally supported, as the converted object do not have the required format for the other methods. Only LMMs are handled by <span class="pkg">lmerTest</span>, and residual-dispersion models are not yet handled by the conversion. However, the conversion extends <span class="pkg">lmerTest</span>'s functionality by handling all random-effect parameters handled by <code><a href="#topic+numInfo">numInfo</a></code>, therefore including (e.g.) spatial-correlation parameters not handled by <span class="pkg">lme4</span>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_LMLT(fitobject, nuisance=NULL, verbose=TRUE, transf=TRUE, check_deriv=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_LMLT_+3A_fitobject">fitobject</code></td>
<td>

<p>Object of class <code>HLfit</code> resulting from the fit of a linear mixed model (LMM).
</p>
</td></tr>
<tr><td><code id="as_LMLT_+3A_nuisance">nuisance</code></td>
<td>

<p>A list of fitted values of parameters that affect the distribution of the test of fixed effects, in the format of the <code>fixed</code> argument of the <code>fitme</code> function. If NULL (default), then the list is constructed from the fitted values of the random-effect parameters and of <code>phi</code> (residual dispersion parameter). 
The <code>nuisance</code> argument is better ingored unless the extractor he construct the default value fails in some way.
</p>
</td></tr>
<tr><td><code id="as_LMLT_+3A_verbose">verbose</code></td>
<td>

<p>boolean: controls printing of the message that shows the <code>unlist</code>ed value of the <code>nuisance</code> list.
</p>
</td></tr>
<tr><td><code id="as_LMLT_+3A_transf">transf</code></td>
<td>

<p>boolean: whether to evaluate numerical derivatives on a transformed parameter scale, or not (may affect numerical precision).
</p>
</td></tr>
<tr><td><code id="as_LMLT_+3A_check_deriv">check_deriv</code></td>
<td>
<p>See same-named argument of <code><a href="#topic+numInfo">numInfo</a></code></p>
</td></tr> 
<tr><td><code id="as_LMLT_+3A_...">...</code></td>
<td>
<p>Other arguments that may be needed by some method (currently ignored).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value is returned invisibly. It is an S4 object of class <code>"LMLT"</code> with slots matching those required in objects of S4 class <code>"lmerModLmerTest"</code> when used by package <span class="pkg">lmerTest</span> with <code>ddf="Satterthwaite"</code> (many additional slots of a formal <code>"lmerModLmerTest"</code> object are missing). The additional <code>nuisance</code> slot contains the <code>nuisance</code> list.
</p>


<h3>References</h3>

<p>Alexandra Kuznetsova, Per B. Brockhoff and Rune H. B. Christensen (2017) lmerTest Package: Tests in Linear Mixed Effects Models. Journal of Statistical Software, 82(13), 1–26. doi:10.18637/jss.v082.i13
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Reproducing an example from the doc of lmerTest::contest.lmerModLmerTest,
#    using a spaMM fit as input.
## Not run: 
  data("sleepstudy", package="lme4")
  
  ## The fit:
  spfit &lt;- fitme(Reaction ~ Days + I(Days^2) + (1|Subject) + (0+Days|Subject),
             sleepstudy, method="REML")
  
  ## Conversion:           
  spfit_lmlt &lt;-  as_LMLT(spfit) 

  ## Functions from package lmerTest can then be called on this object:
  lmerTest::contest(spfit_lmlt, L=diag(3)[2:3, ])   # Test of 'Days + I(Days^2)'.
  #
  anova(spfit_lmlt, type="1")         # : using lmerTest:::anova.lmerModLmerTest()
  drop1(spfit_lmlt)                   # : using lmerTest:::drop1.lmerModLmerTest()


## End(Not run)
</code></pre>

<hr>
<h2 id='autoregressive'>
Fitting autoregressive models
</h2><span id='topic+autoregressive'></span><span id='topic+adjacency'></span><span id='topic+CAR'></span><span id='topic+AR1'></span>

<h3>Description</h3>

<p>Diverse autoregressive (AR) models are implemented in spaMM. This documentation describe the <code>adjacency</code> model (a conditional AR, i.e., CAR), and the <code>AR1</code> model for time series. Other documentation deals with more or less distantly related models: <code><a href="#topic+ARp">ARp</a></code> for more general AR(p) and ARMA(p,q) models for time series, and <code><a href="#topic+IMRF">IMRF</a></code> and <code><a href="#topic+MaternIMRFa">MaternIMRFa</a></code> for mesh-based approximations of geostatistical models.
</p>
<p>An AR1 random effect is specified as <code>AR1(1|&lt;grouping factor&gt;)</code>. It describes correlations between realizations of the random effect for (typically) successive time-steps by a correlation <code class="reqn">\phi</code>, denoted <code>ARphi</code> in function calls. Nested AR1 effects can be specified by a nested grouping factor, as in <code>AR1(1|&lt;time index&gt; %in% &lt;nesting factor&gt;)</code>.
</p>
<p>A CAR random effect is specified as <code>adjacency(1|&lt;grouping factor&gt;)</code>. The correlations among levels of the random effect form a 
matrix (<b>I</b><code class="reqn">-\rho</code> <code>adjMatrix</code><code class="reqn">)^{-1}</code>, in terms of an <code>adjMatrix</code> matrix which must be provided, and of the scalar <code class="reqn">\rho</code>, denoted <code>rho</code> in function calls. 
The rows and columns of <code>adjMatrix</code> must have names matching those of levels of the random effect <b>or else</b> be ordered as increasing values of the levels of the geographic location index specifying the spatial random effect. For example, if the model formula 
is<br /> 
<code>y ~ adjacency(1|geo.loc)</code> and <code>&lt;data&gt;$geo.loc</code> is 2,4,3,1,... the first row/column of the matrix refers to <code>geo.loc</code>=1, i.e. to the fourth row of the data. 
</p>


<h3>Details</h3>

<p>Efficient algorithms for CAR models have been widely discussed in particular in the econometric literature (e.g., LeSage and Pace 2009), but these models are not necessarily recommended for irregular lattices (see Wall, 2004 and Martellosio, 2012 for some insights on the implications of autoregressive models). 
</p>
<p>In <b>CAR</b> models, the covariance matrix of random effects <b>u</b> can be described as <code class="reqn">\lambda</code>(<b>I</b><code class="reqn">-\rho</code> <b>W</b><code class="reqn">)^{-1}</code> where <b>W</b> is the (symmetric) adjacency matrix. <code>HLCor</code> uses the spectral decomposition of the adjacency matrix, written as <b>W=VDV'</b> where <b>D</b> is a diagonal matrix of eigenvalues <code class="reqn">d_i</code>. The covariance of <b>V'u</b> is 
<code class="reqn">\lambda</code>(<b>I</b><code class="reqn">-\rho</code> <b>D</b><code class="reqn">)^{-1}</code>, which is a diagonal matrix with elements 
<code class="reqn">\lambda_i</code>=<code class="reqn">\lambda</code>/(1<code class="reqn">-\rho d_i</code>). Hence <code class="reqn">1/\lambda_i</code> is in the linear predictor form <code class="reqn">\alpha</code>+<code class="reqn">\beta d_i</code> This can be used to fit <code class="reqn">\lambda</code> and <code class="reqn">\rho</code> efficiently. A call to <code>corrHLfit</code> with the additional argument 
<code>init.HLfit=list(rho=0)</code> should be equivalent in speed and result to the <code>HLCor</code> call. 
</p>
<p>This is fast for small datasets (as in the example below) but more generic maximization algorithms may be preferable for large ones. It is suggested to use <code>fitme</code> generally unless one has a large number of small data sets to analyze. A call to <code>fitme</code> or <code>corrHLfit</code> without that initial value does not use the spectral decomposition. It performs numerical maximization of the likelihood (or restricted likelihood) as function of the correlation parameter <code class="reqn">\rho</code>. The choice of fitting function may slightly impact the results. The ML fits by <code>corrHLfit</code> and <code>HLCor</code> should be practically equivalent. The REML fits should slightly differ from each other, due to the fact that the REML approximation for GLMMs does not maximize a single likelihood function. 
</p>
<p>If <code>HLCor</code> is used, the results are reported as the coefficients <code class="reqn">\alpha</code> (<code>(Intercept)</code>) and <code class="reqn">\beta</code> (<code>adjd</code>) of the predictor for <code class="reqn">1/\lambda_i</code>, in addition to the resulting values of <code class="reqn">\rho</code> and of the common <code class="reqn">\lambda</code> factor.    
</p>
<p>Different fits may also differ in using or not algorithms that exploit the sparsity of the precision matrix of the autoregressive random effect. By default, spaMM tends to select sparse-precision algorithms for large datasets and large (i.e. many-level) random effects (details are complex).
However, for <b>AR1</b> models, the dimension of the implied precision matrix is determined by the extreme values of grouping factor (typically interpreted as a time index), as all intermediate values must be considered. Then, the correlation-based algorithms may be more efficient if only a few levels are present in the data, as only a small correlation matrix is required in that case.    
</p>


<h3>References</h3>

<p>LeSage, J., Pace, R.K. (2009) Introduction to Spatial Econometrics. Chapman &amp; Hall/CRC.
</p>
<p>Martellosio, F. (2012) The correlation structure of spatial autoregressions, Econometric Theory 28, 1373-1391.
</p>
<p>Wall M.M. (2004) A close look at the spatial structure implied by
the CAR and SAR models: Journal of Statistical Planning and Inference 121: 311-324.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##### AR1 random effect:
ts &lt;- data.frame(lh=lh,time=seq(48)) ## using 'lh' data from stats package
fitme(lh ~ 1 +AR1(1|time), data=ts, method="REML")
# With fixed parameters:
# HLCor(lh ~ 1 +AR1(1|time), data=ts, ranPars=list(ARphi=0.5,lambda=0.25,phi=0.001))

##### CAR random effect:
data("scotlip")
# CAR by Laplace with 'outer' estimation of rho
if (spaMM.getOption("example_maxtime")&gt;0.8) {          
  fitme(cases ~ I(prop.ag/10)+adjacency(1|gridcode)+offset(log(expec)),
          adjMatrix=Nmatrix, family=poisson(), data=scotlip) 
}

# CAR by Laplace with 'inner' estimation of rho
HLCor(cases ~ I(prop.ag/10)+adjacency(1|gridcode)+offset(log(expec)),
          adjMatrix=Nmatrix, family=poisson(), data=scotlip, method="ML")
</code></pre>

<hr>
<h2 id='beta_resp'>
Beta-response family object
</h2><span id='topic+beta_resp'></span>

<h3>Description</h3>

<p>Returns a <code>family</code> object for beta-response models.
The model described by such a family is characterized by a linear predictor, a link function, and the beta density for the residual variation.
</p>
<p>The precision parameter <code>prec</code> of this family is a positive value such that the variance of the response given its mean <code class="reqn">\mu</code> is <code class="reqn">\mu(1-\mu)/(1+</code><code>prec</code>). <code>prec</code> is thus the precision parameter <code class="reqn">\phi</code> of Ferrari &amp; Cribari-Neto (2004) and of the <span class="pkg">betareg</span> package (Cribari-Neto &amp; Zeileis 2010).  
</p>
<p>A <b>fixed-effect</b> residual-dispersion model can be fitted, using the  <code><a href="#topic+resid.model">resid.model</a></code> argument, which is used to specify the form of the logarithm of the precision parameter (see Examples). Thus the variance of the response become <code class="reqn">\mu(1-\mu)/(1+</code><code>exp(&lt;specified linear expression&gt;)</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta_resp(prec = stop("beta_resp's 'prec' must be specified"), link = "logit")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beta_resp_+3A_prec">prec</code></td>
<td>

<p>Scalar (or left unspecified): precision parameter of the beta distribution. 
</p>
</td></tr>
<tr><td><code id="beta_resp_+3A_link">link</code></td>
<td>

<p>logit, probit, cloglog or cauchit link, specified by any of the available ways for GLM links (name, character string, one-element character vector, or object of class <code>link-glm</code> as returned by <code><a href="stats.html#topic+make.link">make.link</a></code>). 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prior weights are meaningful for this family and handled as a factor of the precision parameter (as for GLM families) hence here not as a divisor of the variance (in contrast to GLM families): the variance of the response become <code class="reqn">\mu(1-\mu)/(1+</code><code>prec*&lt;prior weights&gt;</code>). However, this feature is experimental and may be removed in the future. The fitting function's <code>resid.model</code> argument may be preferred to obtain the same effect, by specifying an <code>offset(log(&lt;prior weights&gt;))</code> in its formula (given the log link used in that model). As usual in <span class="pkg">spaMM</span>, the offset(.) argument should be a vector and any variable necessary for evaluating it should be in the <code>data</code>.
</p>


<h3>Value</h3>

<p>A list, formally of class <code>c("LLF", "family")</code>.  See <code><a href="#topic+LL-family">LL-family</a></code> for details about the structure and usage of such objects.
</p>


<h3>References</h3>

<p>Cribari-Neto, F., &amp; Zeileis, A. (2010). Beta Regression in R. Journal of Statistical Software, 34(2), 1-24. <a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Ferrari SLP, Cribari-Neto F (2004). “Beta Regression for Modelling Rates and Proportions.”
Journal of Applied Statistics, 31(7), 799-815.
</p>


<h3>See Also</h3>

<p>Further examples in <code><a href="#topic+LL-family">LL-family</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(123)
  beta_dat &lt;- data.frame(y=runif(100),grp=sample(2,100,replace = TRUE), x_het=runif(100))
  
  fitme(y ~1+(1|grp), family=beta_resp(), data= beta_dat)
  ## same logL, halved 'prec' when prior weights=2 are used: 
  # fitme(y ~1+(1|grp), family=beta_resp(), data= beta_dat, prior.weights=rep(2,100))
  
  ## With model for residual dispersion:
  # fitme(y ~1+(1|grp), family=beta_resp(), data= beta_dat, resid.model= ~ x_het)
</code></pre>

<hr>
<h2 id='betabin'>
Beta-binomial family object
</h2><span id='topic+betabin'></span>

<h3>Description</h3>

<p>Returns a <code>family</code> object for beta-binomial models.
The model described by such a family is characterized by a linear predictor, a link function, and the beta-binomial distribution for residual variation. 
</p>
<p>The precision parameter <code>prec</code> of this family is a positive value such that the variance of the beta-distributed latent variable given its mean <code class="reqn">\mu</code> is <code class="reqn">\mu(1-\mu)/(1+</code><code>prec</code>). <code>prec</code> is thus the same precision parameter as for the beta response family (see <code><a href="#topic+beta_resp">beta_resp</a></code>. The variance of the beta-binomial sample of size <code class="reqn">n</code> is response is <code class="reqn">\mu(1-\mu)n(n+</code><code>prec</code><code class="reqn">)/(1+</code><code>prec</code>). 
</p>
<p>A <b>fixed-effect</b> residual-dispersion model can be fitted, using the  <code><a href="#topic+resid.model">resid.model</a></code> argument, which is used to specify the form of the logarithm of the precision parameter (see Examples). Thus the variance of the latent beta-distributed variable becomes <code class="reqn">\mu(1-\mu)/(1+</code><code>exp(&lt;specified linear expression&gt;)</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betabin(prec = stop("betabin's 'prec' must be specified"), link = "logit")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betabin_+3A_prec">prec</code></td>
<td>

<p>Scalar (or left unspecified): precision parameter of the beta distribution. 
</p>
</td></tr>
<tr><td><code id="betabin_+3A_link">link</code></td>
<td>

<p>logit, probit, cloglog or cauchit link, specified by any of the available ways for GLM links (name, character string, one-element character vector, or object of class <code>link-glm</code> as returned by <code><a href="stats.html#topic+make.link">make.link</a></code>). 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prior weights are meaningful for this family and handled as a factor of the precision parameter of the latent beta-distributed variable: the variance of the latent variable become <code class="reqn">\mu(1-\mu)/(1+</code><code>prec*&lt;prior weights&gt;</code>). However, this feature is experimental and may be removed in the future. The fitting function's <code>resid.model</code> argument may be preferred to obtain the same effect, by specifying an <code>offset(log(&lt;prior weights&gt;))</code> in its formula (given the log link used in that model). As usual in <span class="pkg">spaMM</span>, the offset(.) argument should be a vector and any variable necessary for evaluating it should be in the <code>data</code>.
</p>


<h3>Value</h3>

<p>A list, formally of class <code>c("LLF", "family")</code>.  See <code><a href="#topic+LL-family">LL-family</a></code> for details about the structure and usage of such objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("agridat", quietly = TRUE)) {
  data("crowder.seeds", package = "agridat")
  fitme(cbind(germ,n-germ) ~ gen+extract+(1|plate), data=crowder.seeds, family=betabin())
} else {
  data(clinics)
  fitme(cbind(npos,nneg)~1+(1|clinic), family=betabin(), data=clinics)
}
</code></pre>

<hr>
<h2 id='blackcap'>
Genetic polymorphism in relation to migration in the blackcap
</h2><span id='topic+blackcap'></span>

<h3>Description</h3>

<p>This data set is extracted from a study of genetic polymorphisms potentially associated to migration behaviour in the blackcap
(Sylvia atricapilla). Across different populations in Europe and Africa, the average migration behaviour 
was found to correlate with average allele size (dependent on the number of repeats of a small DNA motif) 
at the locus ADCYAP1, encoding a neuropeptide.
This data set is quite small and ill-suited for separating random-effect variance from residual variance. The likelihood surface for the Matérn model actually has local maxima. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("blackcap")</code></pre>


<h3>Format</h3>

<p>The data frame includes 14 observations on the following variables:
</p>

<dl>
<dt>latitude</dt><dd><p>latitude, indeed.</p>
</dd>
<dt>longitude</dt><dd><p>longitude, indeed.</p>
</dd>
<dt>migStatus</dt><dd><p>migration status as determined by Mueller et al, from 0 (resident populations) to 2.5 (long-distance migratory populations)</p>
</dd>
<dt>means</dt><dd><p>Mean allele sizes in each population</p>
</dd>
<dt>pos</dt><dd><p>Numerical index for the populations</p>
</dd>
</dl>



<h3>Details</h3>

<p>Migration status was coded as : pure resident populations as '0', resident populations with 
some migratory restlessness as '0.5', partial migratory populations as '1', completely migratory populations migrating
short-distances as '1.5', intermediate-distance migratory populations as '2' and distinct long-distance migratory populations
as '2.5'.
</p>


<h3>Source</h3>

<p>Data from Mueller et al. (2011), including supplementary material now available from
<a href="https://doi.org/10.1098/rspb.2010.2567">doi:10.1098/rspb.2010.2567</a>.
</p>


<h3>References</h3>

<p>Mueller, J. C., Pulido, F., and Kempenaers, B. 2011. Identification of a
gene associated with avian migratory behaviour, Proc. Roy. Soc. (Lond.)
B 278, 2848-2856.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see 'fitme', 'corrHLfit' and 'fixedLRT' for examples involving these data
</code></pre>

<hr>
<h2 id='CauchyCorr'>
Cauchy correlation function and Cauchy formula term
</h2><span id='topic+CauchyCorr'></span><span id='topic+CauchyCorr.default'></span><span id='topic+CauchyCorr.dsCMatrix'></span><span id='topic+CauchyCorr.dgCMatrix'></span><span id='topic+Cauchy'></span>

<h3>Description</h3>

<p>The Cauchy family of correlation functions is useful to describe spatial processes with power-law decrease of correlation at long distance. It is valid for Euclidean distances in spaces of any dimension, and for great-circle distances on spheres of any dimension. It has a scale parameter (<code>rho</code>, as in the Matérn correlation function), a <code>shape</code> (or &ldquo;smoothness&rdquo;, Gneiting 2013) parameter, and a <code>long</code>-memory <code>dep</code>endence (or, more abstractly, &ldquo;shape&rdquo;; Gneiting 2013) parameter (Gneiting and Schlater 2004). The present implementation also accepts a <code>Nugget</code> parameter. The family can be invoked in two ways. First, the <code>CauchyCorr</code> function evaluates correlations, using distances as input. Second, a term of the form <code>Cauchy(1|</code><em>&lt;...&gt;</em><code>)</code> in a <code>formula</code> specifies a random effect with Cauchy correlation function, using coordinates found in a data frame as input. In the latter case, the correlations between realizations of the random effect for any two observations in the data will be the value of the Cauchy function at the scaled distance between coordinates specified in <em>&lt;...&gt;</em>, using &ldquo;+&rdquo; as separator (e.g., <code>Cauchy(1|longitude+latitude)</code>). A syntax of the form <code>Cauchy(1|longitude+latitude %in% grp)</code> can be used to specify a Cauchy random effect with independent realizations for each level of the grouping variable <code>grp</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
CauchyCorr(d, rho=1, shape, longdep, Nugget=NULL)
# Cauchy(1|...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CauchyCorr_+3A_d">d</code></td>
<td>
<p>Euclidean or great-circle distance</p>
</td></tr>
<tr><td><code id="CauchyCorr_+3A_rho">rho</code></td>
<td>
<p>The scaling factor for distance, a real &gt;0.</p>
</td></tr>
<tr><td><code id="CauchyCorr_+3A_shape">shape</code></td>
<td>
<p>The shape (smoothness) parameter, a real 0&lt;.&lt;=2 for Euclidean distances and 0&lt;.&lt;=1 for great-circle distances. Smoothness increases, and fractal dimension decreases, with increasing shape (the fractal dimension of realizations in spaces of dimension <code class="reqn">d</code> being <code class="reqn">d</code>+1-shape/2).</p>
</td></tr>
<tr><td><code id="CauchyCorr_+3A_longdep">longdep</code></td>
<td>
<p>The long-memory dependence parameter, a real &gt;0. It gives the exponent of the asymptotic decrease of correlation with distance: the <b>smaller</b> <code>longdep</code> is, the longer the dependence.</p>
</td></tr>
<tr><td><code id="CauchyCorr_+3A_nugget">Nugget</code></td>
<td>
<p>(Following the jargon of Kriging) a parameter describing a discontinuous decrease in 
correlation at zero distance. Correlation will always be 1 at <code class="reqn">d=0</code>, and from which it immediately drops to 
(1-Nugget). Defaults to zero.</p>
</td></tr>
<tr><td><code id="CauchyCorr_+3A_...">...</code></td>
<td>
<p>Names of coordinates, using &ldquo;+&rdquo; as separator (e.g., <code>Matern(1|longitude+latitude)</code>. The coordinates are numeric values found in the <code>data</code> data frame provided to the fitting function. No additional declaration of groups, factors, or other specific formatting is required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlation at distance <code class="reqn">d&gt;0</code> is 
</p>
<p style="text-align: center;"><code class="reqn">(1-\textrm{Nugget}) (1+(\rho d)^\textrm{shape})^(-\textrm{longdep/shape})</code>
</p>
 


<h3>Value</h3>

<p>Scalar/vector/matrix depending on input.</p>


<h3>References</h3>

<p>Gneiting, T. and Schlater M. (2004) Stochastic models that separate fractal dimension and the Hurst effect. SIAM Rev.
46: 269–282.
</p>
<p>Gneiting T. (2013) Strictly and non-strictly positive definite functions on spheres. Bernoulli 19: 1327-1349.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap")
fitme(migStatus ~ means+ Cauchy(1|longitude+latitude),data=blackcap,
      fixed=list(longdep=0.5,shape=0.5,rho=0.05))
## The Cauchy family can be used in Euclidean spaces of any dimension:
set.seed(123)
randpts &lt;- matrix(rnorm(20),nrow=5)
distMatrix &lt;- as.matrix(proxy::dist(randpts))
CauchyCorr(distMatrix,rho=0.1,shape=1,longdep=10)

# See ?MaternCorr for examples of syntaxes for group-specific random effects,
#  also handled by Cauchy().
</code></pre>

<hr>
<h2 id='clinics'>
Toy dataset for binomial response
</h2><span id='topic+clinics'></span>

<h3>Description</h3>

<p>A small data set used by Booth &amp; Hobert (1998). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("clinics")</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 4 variables.
</p>

<dl>
<dt><code>npos</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>nneg</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>treatment</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>clinic</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Booth, J.G., Hobert, J.P. (1998) Standard errors of prediction in generalized linear mixed models. J. Am. Stat. Assoc. 93: 262-272. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(clinics)
## Not run: 
# The dataset was built as follows
npos &lt;- c(11,16,14,2,6,1,1,4,10,22,7,1,0,0,1,6)
ntot &lt;- c(36,20,19,16,17,11,5,6,37,32,19,17,12,10,9,7)
treatment &lt;- c(rep(1,8),rep(0,8))
clinic &lt;-c(seq(8),seq(8))
clinics &lt;- data.frame(npos=npos,nneg=ntot-npos,treatment=treatment,clinic=clinic)

## End(Not run)
</code></pre>

<hr>
<h2 id='COMPoisson'>
Conway-Maxwell-Poisson (COM-Poisson) GLM family
</h2><span id='topic+COMPoisson'></span><span id='topic+geometric'></span>

<h3>Description</h3>

<p>The COM-Poisson family is a generalization of the Poisson family which can describe over-dispersed as well as under-dispersed count data. It is indexed by a parameter <code>nu</code> that quantifies such dispersion. For <code>nu</code>&gt;1, the distribution is under-dispersed relative to the Poisson distribution with same mean. It includes the Poisson, geometric and Bernoulli as special (or limit) cases (see Details). The COM-Poisson family is here implemented as a <code><a href="stats.html#topic+family">family</a></code> object, so that it can be fitted by <code><a href="stats.html#topic+glm">glm</a></code>, and further used to model conditional responses in mixed models fitted by this package's functions (see Examples). <code>nu</code> is distinct from the dispersion parameter <code class="reqn">\nu=1/\phi</code> considered elsewhere in this package and in the GLM literature, as <code class="reqn">\nu</code> affects in a more specific way the log-likelihood. 
</p>
<p>Several links are now allowed for this family, corresponding to different versions of the COMPoisson described in the literature (e.g., Sellers &amp; Shmueli 2010; Huang 2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COMPoisson(nu =  stop("COMPoisson's 'nu' must be specified"), 
           link = "loglambda")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="COMPoisson_+3A_link">link</code></td>
<td>
<p>GLM link function. The default is the canonical link <code>"loglambda"</code> (see Details), but other links are allowed (currently log, sqrt or identity links as commonly handled for the Poisson family).</p>
</td></tr>
<tr><td><code id="COMPoisson_+3A_nu">nu</code></td>
<td>

<p>Under-dispersion parameter. The <code>fitme</code> and <code>corrHLfit</code> functions called with <code>family=COMPoisson()</code> (no given <code>nu</code> value) will estimate this parameter. In other usage of this family, <code>nu</code> must be specified. <code>COMPoisson(nu=1)</code> is the Poisson family. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">i</code>th term of the distribution can be written <code class="reqn">q_i/Z</code> where <code class="reqn">q_i=\lambda^i / (i!)^\nu</code> and <code class="reqn">Z=\sum_{(i=0)}^\infty q_i</code>, for <code class="reqn">\lambda=\lambda(\mu)</code> implied by its inverse relationship, the expectation formula <code class="reqn">\mu=\mu(\lambda)=\sum_{(i=0)}^\infty i q_i(\lambda)/Z</code>. The case <code>nu=0</code> is the geometric distribution with parameter <code class="reqn">\lambda</code>; <code>nu=1</code> is the Poisson distribution with mean <code class="reqn">\lambda</code>; and the limit as <code>nu</code> -&gt; <code class="reqn">\infty</code> is the Bernoulli distribution with expectation <code class="reqn">\lambda/(1+\lambda)</code>. 
</p>
<p>From this definition, this is an exponential family model with canonical parameters <code class="reqn">log(\lambda)</code> and <code class="reqn">\nu</code>. When the linear predictor <code class="reqn">\eta</code> specifies <code class="reqn">log(\lambda(\mu))</code>, the canonical link is used (e.g., Sellers &amp; Shmueli 2010). It is here nicknamed <code>"loglambda"</code> and does not have a known expression in terms of elementary functions. To obtain <code class="reqn">\mu</code> as the link inverse of the linear predictor <code class="reqn">\eta</code>, one then first computes <code class="reqn">\lambda=e^\eta</code> and then <code class="reqn">\mu(\lambda)</code> by the  expectation formula. For other links (Huang 2017), one directly computes <code class="reqn">\mu</code> by the link inverse (e.g., <code class="reqn">\mu=e^\eta</code> for link <code>"log"</code>), and then one may solve for <code class="reqn">\lambda= \lambda(\mu)</code> to obtain other features of the distribution.    
</p>
<p>The relationships between <code class="reqn">\lambda</code> and <code class="reqn">\mu</code> or other moments of the distribution involve infinite summations. These sums can be easily approximated by a finite number of terms for large <code>nu</code> but not when <code>nu</code> approaches zero. For this reason, the code may fail to fit distributions with <code>nu</code> approaching 0 (strong residual over-dispersion). The case <code>nu=0</code> (the geometric distribution) is fitted by an ad hoc algorithm devoid of such problems. Otherwise, <code>spaMM</code> truncates the sum, and uses numerical integrals to approximate missing terms (which slows down the fitting operation). In addition, it applies an ad hoc continuity correction to ensure continuity of the result in <code>nu=1</code> (Poisson case). These corrections affect numerical results for the case of residual overdispersion but are negligible for the case of residual underdispersion. Alternatively, <code>spaMM</code> uses Gaunt et al.'s (2017) approximations when the condition defined by <code>spaMM.getOption("CMP_asympto_cond")</code> is satisfied. All approximations reduces the accuracy of computations, in a way that can impede the extended Levenberg-Marquardt algorithm sometimes needed by spaMM.
</p>
<p>The name <code>COMP_nu</code> should be used to set initial values or bounds on <code>nu</code> in control arguments of the fitting functions (e.g., <code>fitme(.,init=list(COMP_nu=1))</code>). Fixed values should be set by the family argument (<code>COMPoisson(nu=.)</code>). 
</p>


<h3>Value</h3>

<p>A family object.
</p>


<h3>References</h3>

<p>Gaunt, Robert E. and Iyengar, Satish and Olde Daalhuis, Adri B. and Simsek, Burcin. (2017) An asymptotic expansion for the normalizing constant of the Conway&ndash;Maxwell&ndash;Poisson distribution. Ann Inst Stat Math <a href="https://doi.org/10.1007/s10463-017-0629-6">doi:10.1007/s10463-017-0629-6</a>.
</p>
<p>Huang, Alan (2017) Mean-parametrized Conway-Maxwell-Poisson regression models for dispersed counts. Stat. Modelling <a href="https://doi.org/10.1177/1471082X17697749">doi:10.1177/1471082X17697749</a> 
</p>
<p>G. Shmueli, T. P. Minka, J. B. Kadane, S. Borle and P. Boatwright (2005) A useful distribution for fitting discrete data: revival of the Conway-Maxwell-Poisson distribution. Appl. Statist. 54: 127-142.
</p>
<p>Sellers KF, Shmueli G (2010) A Flexible Regression Model for Count Data. Ann. Appl. Stat. 4: 943–961
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;0.9) {
  # Fitting COMPoisson model with estimated nu parameter:
  #
  data("freight") ## example from Sellers &amp; Shmueli, Ann. Appl. Stat. 4: 943–961 (2010)
  fitme(broken ~ transfers, data=freight, family = COMPoisson())
  fitme(broken ~ transfers, data=freight, family = COMPoisson(link="log"))

  # glm(), HLCor() and HLfit() handle spaMM::COMPoisson() with fixed overdispersion:
  #
  glm(broken ~ transfers, data=freight, family = COMPoisson(nu=10))
  HLfit(broken ~ transfers+(1|id), data=freight, family = COMPoisson(nu=10),method="ML")
  
  # Equivalence of poisson() and COMPoisson(nu=1):
  #
  COMPglm &lt;- glm(broken ~ transfers, data=freight, family = poisson())
  coef(COMPglm)
  logLik(COMPglm)
  COMPglm &lt;- glm(broken ~ transfers, data=freight, family = COMPoisson(nu=1))
  coef(COMPglm)
  logLik(COMPglm)
  HLfit(broken ~ transfers, data=freight, family = COMPoisson(nu=1))

}
</code></pre>

<hr>
<h2 id='composite-ranef'>
Composite random effects
</h2><span id='topic+composite-ranef'></span>

<h3>Description</h3>

<p>An example of a composite random effect is <code>corrMatrix(sex|pair)</code>. It combines features of a random-coefficient model <code>(sex|pair)</code> and of a random effect <code>corrMatrix(1|pair)</code>. The random-coefficient model is  characterized by a <code class="reqn">2*2</code> covariance matrix <b>C</b> for the random effects <code class="reqn">u_{1,pair}</code> and <code class="reqn">u_{2,pair}</code> both affecting each of the two sexes for each <code>pair</code>, and the <code>corrMatrix</code> random effect assumes that elements of each of the two vectors <code class="reqn">u_i=(u_{i,pair})</code> for <code>pair</code>=1,...,<code class="reqn">P</code> are correlated according to a given <code class="reqn">P*P</code> correlation matrix <b>A</b>. Then the composite random effect is defined as the one with 2<code class="reqn">P*</code>2<code class="reqn">P</code> covariance matrix <code><a href="Matrix.html#topic+kronecker">kronecker</a></code>(<b>C</b>,<b>A</b>).
</p>
<p>The definition of composite random effects through the <code>kronecker</code> product may be motivated and understood in light of a quantitative-genetics application (see help(&quot;Gryphon&quot;) for an example). In this context the two response variables are typically two individual traits. Each trait is affected by two sets of genes, the effect of each set being represented by a gaussian random effect (<code>u_1</code> or <code>u_2</code>). The effect of genetic relatedness on the correlation of random effects <code>u_i,ID</code> among individuals <code>ID</code> within each set <code class="reqn">i</code> of genes is described by the corrMatrix <b>A</b>. The effects on the two traits for each individual are interpreted as different linear combinations of these two random effects (the coefficients of these linear combinations determining the <b>C</b> matrix). Under these assumptions the correlation matrix of the responses (in order (trait, individual)=(1,1)...(1,ID)... (2,1)...(2,ID)...) is indeed <code><a href="Matrix.html#topic+kronecker">kronecker</a></code>(<b>C</b>,<b>A</b>).
</p>
<p>Composite random effects are not restricted to <code>corrMatrix</code> terms, and can also be fitted for multivariate-response models. For example, <code>Matern(mv(1,2)|longitude+latitude)</code> terms can be fitted, in which case the correlation model is still defined through the Kronecker product, where <b>A</b> will be a (fitted) Matérn correlation matrix, and <b>C</b> will be the correlation matrix of the fitted random-coefficient model for the <code><a href="#topic+mv">mv</a></code> virtual factor for multivariate response. 
</p>
<p>The summary of the model provides fitted parameters for <b>A</b> if this matrix derives from a parametric correlation model (e.g., <code>Matern</code>), and a description of the <b>C</b> matrix where it is viewed as a covariance matrix, parametrized by its variances and its correlation coefficient(s). In a standard random-coefficient model these variances would be those of the correlated  random effects (see <code><a href="#topic+summary.HLfit">summary.HLfit</a></code>). In the composite random-effect model this is not necessarily so as the variance of the correlated random effects also depend on the variances implied by the <b>A</b> matrix, which are not necessarily 1 if <b>A</b> is a covariance matrix rather than simply a correlation matrix.    
</p>
<p>A <code>&lt;prefix&gt;(&lt;LHS&gt;|&lt;RHS&gt;)</code> term is *not* a composite random effect when the LHS in boolean, a factor from boolean, or &ldquo;0+numeric&rdquo;. See the Matérn examples, and the corrMatrix &ldquo;<code>&lt;LHS&gt; is 0+numeric</code>&rdquo; example, below.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;1.8) {

########################
#### corrMatrix examples
########################

## Toy data preparation

data("blackcap")
toy &lt;- blackcap
toy$ID &lt;- gl(7,2)
grp &lt;- rep(1:2,7)
toy$migStatus &lt;- toy$migStatus +(grp==2)
toy$loc &lt;- rownames(toy) # to use as levels matching the corrMatrix dimnames

toy$grp &lt;- factor(grp)
toy$bool &lt;- toy$grp==1L
toy$boolfac &lt;- factor(toy$bool)
toy$num &lt;- seq(from=1, to=2, length.out=14)

## Build a toy corrMatrix as perturbation of identity matrix:
n_rhs &lt;- 14L
eps &lt;- 0.1
set.seed(123)
rcov &lt;- ((1-eps)*diag(n_rhs)+eps*rWishart(1,n_rhs,diag(n_rhs)/n_rhs)[,,1])
# eigen(rcov)$values
colnames(rcov) &lt;- rownames(rcov) &lt;- toy$loc # DON'T FORGET NAMES


##### Illustrating the different LHS types

### &lt;LHS&gt; is logical (TRUE/FALSE) =&gt; No induced random-coefficient C matrix; 
#   corrMatrix affects only responses for which &lt;LHS&gt; is TRUE:
#
(fit1 &lt;- fitme(migStatus ~ bool + corrMatrix(bool|loc), data=toy, corrMatrix=rcov))
#
# Matrix::image(get_ZALMatrix(fit1))


### &lt;RHS&gt; is a factor built from a logical =&gt; same a 'logical' case above:
#
(fit2 &lt;- fitme(migStatus ~ boolfac + corrMatrix(boolfac|loc), data=toy, corrMatrix=rcov))
#
# Matrix::image(get_ZALMatrix(fit2))


### &lt;RHS&gt; is a factor not built from a logical: 
# (grp|.) and (0+grp|.) lead to equivalent fits of the same composite model, 
#   but contrasts are not used in the second case and the C matrices differ,
#   as for standard random-coefficient models.
#
(fit1 &lt;- fitme(migStatus ~ grp +  corrMatrix(grp|loc), data=toy, corrMatrix=rcov))
(fit2 &lt;- fitme(migStatus ~ grp +  corrMatrix(0+grp|loc), data=toy, corrMatrix=rcov))
# 
# =&gt; same fits, but different internal structures:
Matrix::image(fit1$ZAlist[[1]]) # (contrasts used) 
Matrix::image(fit2$ZAlist[[1]]) # (contrasts not used)
# Also compare ranef(fit1) versus ranef(fit2) 
#
#
## One can fix the C matrix, as for standard random-coefficient terms 
#
(fit1 &lt;- fitme(migStatus ~ grp +  corrMatrix(0+grp|loc),data=toy, corrMatrix=rcov, 
               fixed=list(ranCoefs=list("1"=c(1,0.5,1)))))
#       
# same result without contrasts hence different 'ranCoefs':             
#
(fit2 &lt;- fitme(migStatus ~ grp +  corrMatrix(grp|loc), data=toy, corrMatrix=rcov, 
               fixed=list(ranCoefs=list("1"=c(1,-0.5,1)))))


### &lt;LHS&gt; is numeric (but not '0+numeric'):
# composite model with C being 2*2 for Intercept and numeric variable
#
(fitme(migStatus ~ num +  corrMatrix(num|loc), data=toy, corrMatrix=rcov))

### &lt;LHS&gt; is 0+numeric: no random-coefficient C matrix 
#  as the Intercept is removed, but the correlated random effects 
#  arising from the corrMatrix are multiplied by sqrt(&lt;numeric variable&gt;)
#
(fitme(migStatus ~ num +  corrMatrix(0+num|loc), data=toy, corrMatrix=rcov))


### &lt;LHS&gt; for multivariate response (see help("Gryphon") for more typical example)
## More toy data preparation for multivariate response
ch &lt;- chol(rcov)
set.seed(123)
v1 &lt;- tcrossprod(ch,t(rnorm(14,sd=1)))
v2 &lt;- tcrossprod(ch,t(rnorm(14,sd=1)))
toy$status &lt;- 2*v1+v2
toy$status2 &lt;- 2*v1-v2

## Fit:
fitmv(submodels=list(mod1=list(status ~ 1+ corrMatrix(0+mv(1,2)|loc)),
                     mod2=list(status2 ~ 1+ corrMatrix(0+mv(1,2)|loc))), 
      data=toy, corrMatrix=rcov)
      
##################################################
#### Matern examples: sex-dependent random effects
##################################################

if (spaMM.getOption("example_maxtime")&gt;2) {
data(Leuca)
subLeuca &lt;- Leuca[c(1:10,79:88),] # subset for faster examples

# The random effects in the following examples are composite because 'sex' is not 
# boolean nor factor from boolean. If 'Matern(factor(female)|x+y)' were used, the effect 
# would be the same 'Matern(female|x)', fitting 

  fitme(fec_div ~ 1 + Matern(sex|x+y),data=subLeuca)  # =&gt; builds a random effect
# correlated across sexes, from 2 independent realizations u_1 and u_2 of 20 values 
# (for the 20 locations in the data). In a (sex|x) term the 20 values would be 
# independent from each other within each u_i. In the Matern(sex|x+y) such 20 values 
# are autocorrelated within each u_i.

# For pedagogic purposes, one can also fit
  fitme(fec_div ~ 1 + Matern(sex|x + y %in% sex),data=subLeuca)
# which again builds a random effect from 2 independent realizations 
# u_1 and u_2, but each u_i now contains two realizations u_i1 and u_i2 of 10 values,
# autocorrelated within each u_ij following the Matern model, 
# but independent between u_i1 and u_i2. As a result, the overall random effect in each sex, 
# v_m or v_f, is a weighted sum of two sex-specific Matern random effect, 
# so that v_m and v_f are independent from each other. 
}

}
</code></pre>

<hr>
<h2 id='confint.HLfit'>
Confidence intervals
</h2><span id='topic+confint.HLfit'></span><span id='topic+confint'></span>

<h3>Description</h3>

<p>This function interfaces two procedures: a profile confidence interval procedure implemented for fixed-effects coefficients only; and a parametric bootstrap procedure that can be used to provide confidence interval for any parameter, whether a canonical parameter of the model or any function of one or several such parameters. 
The bootstrap is performed if the <code>parm</code> argument is a function or a quoted expression or if the <code>boot_args</code> argument is a list. The profile confidence interval is computed if neither of these conditions is true. In that case <code>parm</code> must be the name(s) of some <b>fixed-effect</b> coefficient, and the (<code>p_v</code> approximation of the) profile likelihood ratio for the given parameter is used to define the interval, where the profiling is over all other fitted parameters, including other fixed-effects coefficients, as well as variances of random effects and spatial correlations if these were fitted. 
</p>
<p>Of related interest, see <code><a href="#topic+numInfo">numInfo</a></code> which evaluates numerically the information matrix for given sets of canonical model parameters, from which asymptotic confidence intervals can be deduced.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
confint(object, parm, level=0.95, verbose=TRUE, 
                          boot_args=NULL, format="default", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.HLfit_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="confint.HLfit_+3A_parm">parm</code></td>
<td>
<p>character vector, integer vector, or function, or a quoted expression. If <b>character</b>, the name(s) of parameter(s) to be fitted; if <b>integer</b>, their position in the <code>fixef(object)</code> vector. Valid names are those of this vector. If a <b>function</b>, it must return a (vector of) parameter estimate(s) from a fit object. If a <b>quoted expression</b>, it must likewise extract parameter estimate(s) from a fit object; this expression must refer to the fitted object as &lsquo;hlfit&rsquo; (see Examples).</p>
</td></tr>
<tr><td><code id="confint.HLfit_+3A_level">level</code></td>
<td>
<p>The coverage of the interval.</p>
</td></tr>
<tr><td><code id="confint.HLfit_+3A_verbose">verbose</code></td>
<td>
<p>whether to print the interval or not. As the function returns its more extensive results invisibly, 
this printing is the only visible output.</p>
</td></tr>
<tr><td><code id="confint.HLfit_+3A_boot_args">boot_args</code></td>
<td>
<p>NULL or a list of arguments passed to functions <code><a href="#topic+spaMM_boot">spaMM_boot</a></code> and <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>. It must contain element <code>nsim</code> (for <code>spaMM_boot</code>). The <code>type</code> argument of <code>boot.ci</code> can only be given as element <code>ci_type</code>, to avoid conflict with the <code>type</code> argument of <code>spaMM_boot</code>.
</p>
</td></tr>
<tr><td><code id="confint.HLfit_+3A_format">format</code></td>
<td>
<p>Only effective non-default value is <code>"stats"</code> to return results in the format of the <code>stats::<a href="stats.html#topic+confint">confint</a></code> result (see Value).</p>
</td></tr>
<tr><td><code id="confint.HLfit_+3A_...">...</code></td>
<td>
<p>Additional arguments (maybe not used, but conforming to the generic definition of <code>confint</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The format of the value varies, but in all cases distinguished below, one or more tables are included, as a <code>table</code> attribute, in the format of the <code>stats::<a href="stats.html#topic+confint">confint</a></code> result, to facilitate consistent extraction of results. By default <code>confint</code> returns invisibly the full values described below, but if <code>format="stats"</code>, only the <code>table</code> attribute is returned. 
</p>
<p>If a profile CI has been computed for a single parameter, a list is returned including the confidence <code>interval</code> as shown by <code>verbose=TRUE</code>, and the fits <code>lowerfit</code> and <code>upperfit</code> giving the profile fits at the confidence bounds. This list bears the <code>table</code> attribute. 
</p>
<p>If a profile CI has been computed for several parameters, a structured list, named according to the parameter names, of such single-parameter results is returned, and a single <code>table</code> attribute for all parameters is attached to the upper level of the list. 
</p>
<p>If a bootstrap was performed, for a single parameter the result of the <code>boot.ci</code> call is returned, to which a <code>table</code> attribute is added. This <code>table</code> is now a list of tables for the different bootstrap CI types (default being <code>normal</code>, <code>percent</code>, and <code>basic</code>), each such table in the format of the <code>stats::confint</code> results. For several parameters, a named list of <code>boot.ci</code> results is returned, its names being the parameter names, and the <code>table</code> attribute is attached to the upper level of the list. 
</p>
<p>The <code>boot.ci</code> return value for each parameter includes the call to <code>boot.ci</code>. This call is typically shown including a long <code>t</code> vector, which makes a bulky display. spaMM hacks the printing to abbreviate long <code>t</code>s.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+numInfo">numInfo</a></code> for information matrix.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("wafers")
wfit &lt;- HLfit(y ~X1+(1|batch), family=Gamma(log), data=wafers, method="ML")
confint(wfit,"X1")  # profile CI
if (spaMM.getOption("example_maxtime")&gt;30) {
   
   # bootstrap CI induced by 'boot_args':
   confint(wfit,names(fixef(wfit)), boot_args=list(nsim=99, seed=123)) 
   
   # bootstrap CI induced by 'parm' being a function:
   confint(wfit,parm=function(v) fixef(v), 
           boot_args=list(nb_cores=10, nsim=199, seed=123))
   
   # Same effect if 'parm' is a quoted expression in terms of 'hlfit':
   confint(wfit,parm=quote(fixef(hlfit)), 
           boot_args=list(nb_cores=10, nsim=199, seed=123))
           
   # CI for the variance of the random effect:          
   ci &lt;- confint(wfit,parm=function(fit){get_ranPars(fit)$lambda[1]}, 
        boot_args=list(nb_cores=10, nsim=199, seed=123))
   # The distribution of bootstrap replicates:
   plot(ecdf(ci$call$t))
   # We may be far from ideal condition for accuracy of bootstrap intervals;
   # for variances, a log transformation may sometimes help, but not here.
   
   # Passing arguments to child processes, as documented in help("spaMM_boot"):
   set.seed(123)
   rvar &lt;- runif(nrow(wafers))
   wrfit &lt;- fitme(y ~X1+(1|batch), family=Gamma(log), data=wafers, fixed=list(phi=rvar))
   confint(wrfit, parm = "(Intercept)", boot_args = list(nsim = 100, nb_cores = 2,
           fit_env = list(rvar=rvar)))
   
}
</code></pre>

<hr>
<h2 id='control.HLfit'>
Control parameters of the HLfit fitting algorithm 
</h2><span id='topic+control.HLfit'></span>

<h3>Description</h3>

<p>A list of parameters controlling the <code><a href="#topic+HLfit">HLfit</a></code> fitting algorithm (potentially called by all fitting functions in <span class="pkg">spaMM</span>), which should mostly be ignored in routine use. Possible controls are:
</p>
<p><code>algebra, sparse_precision</code>: see <code><a href="#topic+algebra">algebra</a></code>;
</p>
<p><code>conv.threshold</code> and <code>spaMM_tol</code>: <code>spaMM_tol</code> is a list of tolerance values, with elements <code>Xtol_rel</code> and <code>Xtol_abs</code> that define thresholds for relative and absolute changes in parameter values in iterative algorithms (used in tests of the form &ldquo;d(param)&lt; Xtol_rel * param + Xtol_abs&rdquo;, so that <code>Xtol_abs</code> is operative only for small parameter values). <code>conv.threshold</code> is the older way to control <code>Xtol_rel</code>. Default values are given by spaMM.getOption(&quot;spaMM_tol&quot;);
</p>
<p><code>break_conv_logL</code>: a boolean specifying whether the iterative algorithm should terminate when log-likelihood appears to have converged (roughly, when its relative variation over on iteration is lower than 1e-8). Default is FALSE (convergence is then assessed on the parameter estimates rather than on log-likelihood).
</p>
<p><code>iter.mean.dispFix</code>: the number of iterations of the iterative algorithm for coefficients of the linear predictor,
if no dispersion parameters are estimated by the iterative algorithm. Defaults to 200 except for Gamma(log)-family models; 
</p>
<p><code>iter.mean.dispVar</code>: the number of iterations of the iterative algorithm for coefficients of the linear predictor,
if some dispersion parameter(s) is estimated by the iterative algorithm. Defaults to 50 except for Gamma(log)-family models;  
</p>
<p><code>max.iter</code>: the number of iterations of the iterative algorithm for joint estimation of dispersion parameters and
of coefficients of the linear predictor. Defaults to 200. This is typically much more than necessary, 
unless there is little information to separately estimate <code class="reqn">\lambda</code> and <code class="reqn">\phi</code> parameters;
</p>
<p><code>resid.family</code>: was a previously documented control (before version 2.6.40), and will still operate as previously documented, but should not be used in new code.        


</p>


<h3>Usage</h3>

<pre><code class='language-R'># &lt;fitting function&gt;(., control.HLfit=list(...)) 
</code></pre>

<hr>
<h2 id='convergence'>
Assessing convergence for fitted models
</h2><span id='topic+convergence'></span>

<h3>Description</h3>

<p>spaMM fits can produce various convergence warnings or messages. 
</p>
<p>Messages referring to convergence issues in initialization can generally be ignored but may help to diagnose other apparent problems, if any. 
</p>
<p>Warnings referring to <code>.calc_dispGammaGLM</code> (for residual-dispersion fits) can generally be ignored when they show a small criterion (say &lt;1e-5) but may otherwise suggest that the final fit did not optimize its objective. 
</p>
<p>Messages pointing to slow convergence and drawing users to this doscumentation do not necessarily mean the fit is incorrect. Rather, they suggest that another fitting strategy could be tried. Keep in mind that several parameters (notably the dispersion parameters: the variance of random effects and the residual variance parameter, if any) can be estimated either by the iterative algorithms, or by generic optimization methods. In my experience, slow convergence happens in certain cases where a large random-effect variance is considered by the algorithm used. 
</p>
<p>How to know which algorithm has been selected for each parameter? <code>fitme(., verbose=c(TRACE=TRUE))</code> shows successive values of the variables estimated by optimization (See Examples; if no value appears, then all are estimated by iterative methods). The first lines of the summary of a fit object should tell which variances are estimated by the &ldquo;outer&rdquo; method.
</p>
<p>If the iterative algorithm is being used, then it is worth trying to use the generic optimization methods. In particular, if you used <code>HLfit</code>, try using <code>fitme</code>; if you already use <code>fitme</code>, try to enforce generic optimization of the random-effect variance(s) (see <code><a href="#topic+inits">inits</a></code>). Conversely, if generic optimization is being used, the maximum lambda value could be controlled (say, <code>upper=list(lambda=c(10,NA))</code>), or the iterative algorithm can be called  (see <code><a href="#topic+inits">inits</a></code> again).
</p>
<p>For the largest datasets, it may be worth comparing the speed of the <code>"spcorr"</code> and  <code>"spprec"</code> choices of the <code><a href="#topic+algebra">algebra</a></code> control, in case spaMM has not selected the most appropriate by default. However, this will not be useful for geostatistical models with many spatial locations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See help("inits") for examples of control by initial values.       
</code></pre>

<hr>
<h2 id='corMatern'>Matern Correlation Structure as a corSpatial object</h2><span id='topic+corMatern'></span><span id='topic+Initialize.corMatern'></span><span id='topic+Variogram.corMatern'></span><span id='topic+coef.corMatern'></span><span id='topic+coef+3C-.corMatern'></span><span id='topic+corFactor.corMatern'></span><span id='topic+corMatrix.corMatern'></span><span id='topic+getCovariate.corMatern'></span><span id='topic+logDet.corMatern'></span><span id='topic+recalc.corMatern'></span>

<h3>Description</h3>

<p>This implements the Matérn correlation structure (see <code><a href="#topic+Matern">Matern</a></code>) for use with <code>lme</code> or <code>glmmPQL</code>. Usage is as for others <code>corSpatial</code> objects 
such as <code>corGaus</code> or <code>corExp</code>, except that the Matérn family
has an additional parameter. This function was defined for comparing
results obtained with <code>corrHLfit</code> to those produced by <code>lme</code> and <code>glmmmPQL</code>. There
are problems in fitting (G)LMMs in the latter way, so it is not a
recommended practice. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corMatern(value = c(1, 0.5), form = ~1, nugget = FALSE, nuScaled = FALSE, 
          metric = c("euclidean", "maximum", "manhattan"), fixed = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corMatern_+3A_value">value</code></td>
<td>

<p>An optional vector of parameter values, with serves as initial values or as fixed values depending on the <code>fixed</code> argument. 
It has either two or three elements, depending on the <code>nugget</code> argument.
</p>
<p>If <code>nugget</code> is <code>FALSE</code>, <code>value</code> should have
two elements, corresponding to the &quot;range&quot; and the &quot;smoothness&quot; <code class="reqn">\nu</code> of the
Matérn correlation structure. If <code>value</code> has zero length, 
the default is a range of 90% of the minimum distance and a
smoothness of 0.5 (exponential correlation). 
<b>Warning</b>: the range parameter used in <code>corSpatial</code> objects is the inverse of the scale 
parameter used in <code><a href="#topic+MaternCorr">MaternCorr</a></code> and thus they have opposite meaning despite both being denoted <code class="reqn">\rho</code> elsewhere in this package or in <code>nlme</code> literature. 
</p>
<p>If <code>nugget</code> is <code>TRUE</code>, meaning that a nugget effect
is present, <code>value</code> can contain two or three elements, the first
two as above, the third  being the &quot;nugget effect&quot; (one minus the
correlation between two observations taken arbitrarily close
together). If <code>value</code> has length zero or two, the nugget defaults to 0.1. 
The range and smoothness must be greater than zero and the nugget must be
between zero and one. 
</p>
</td></tr>
<tr><td><code id="corMatern_+3A_form">form</code></td>
<td>

<p>(Pasted from corSpatial) a one sided formula of the form <code>~ S1+...+Sp</code>, or
<code>~ S1+...+Sp | g</code>, specifying spatial covariates <code>S1</code>
through <code>Sp</code> and,  optionally, a grouping factor <code>g</code>. 
When a grouping factor is present in <code>form</code>, the correlation
structure is assumed to apply only to observations within the same
grouping level; observations with different grouping levels are
assumed to be uncorrelated. Defaults to <code>~ 1</code>, which corresponds
to using the order of the observations in the data as a covariate,
and no groups.</p>
</td></tr>
<tr><td><code id="corMatern_+3A_nugget">nugget</code></td>
<td>

<p>an optional logical value indicating whether a nugget
effect is present. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="corMatern_+3A_nuscaled">nuScaled</code></td>
<td>

<p>If <code>nuScaled</code> is set to <code>TRUE</code> the &quot;range&quot; parameter
<code class="reqn">\rho</code> is divided by <code class="reqn">2 \sqrt\nu</code>. With this option and
for large values of <code class="reqn">\nu</code>, <code>corMatern</code> reproduces the
calculation of <code>corGaus</code>. Defaults to <code>FALSE</code>, in which
case the function compares to <code>corGaus</code> with range parameter
<code class="reqn">2(\sqrt\nu)\rho</code> when <code class="reqn">\nu</code> is large.
</p>
</td></tr>
<tr><td><code id="corMatern_+3A_metric">metric</code></td>
<td>

<p>(Pasted from corSpatial) an optional character string specifying the distance
metric to be used. The currently available options are
<code>"euclidean"</code> for the root sum-of-squares of distances;
<code>"maximum"</code> for the maximum difference; and <code>"manhattan"</code>
for the sum of the absolute differences. Partial matching of
arguments is used, so only the first three characters need to be
provided. Defaults to <code>"euclidean"</code>.
</p>
</td></tr>
<tr><td><code id="corMatern_+3A_fixed">fixed</code></td>
<td>

<p>an optional logical value indicating whether the
coefficients should be allowed to vary in the optimization, or kept
fixed at their initial value. Defaults to <code>FALSE</code>, in which case
the coefficients are allowed to vary.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a constructor for the <code>corMatern</code> class,
representing a Matérn spatial correlation structure. See
<code><a href="#topic+MaternCorr">MaternCorr</a></code> for details on the Matérn family. 
</p>


<h3>Value</h3>

<p>an object of class <code>corMatern</code>, also inheriting from class
<code>corSpatial</code>, representing a Matérn spatial correlation
structure.
</p>


<h3>Note</h3>

<p>The R and C code for the methods for <code>corMatern</code> objects builds on code for <code>corSpatial</code> objects, by D.M. Bates, J.C. Pinheiro and S. DebRoy, in a circa-2012 version of nlme.</p>


<h3>References</h3>

<p>Mixed-Effects Models in S and S-PLUS, José C. Pinheiro and Douglas M. Bates, Statistics and Computing Series, Springer-Verlag, New York, NY, 2000.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+glmmPQL">glmmPQL</a></code>, <code><a href="nlme.html#topic+lme">lme</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## LMM
data("blackcap")
blackcapD &lt;- cbind(blackcap,dummy=1) ## obscure, isn't it? 
## With method= 'ML' in lme, The correlated random effect is described 
##  as a correlated residual error and no extra residual variance is fitted:
nlme::lme(fixed = migStatus ~ means, data = blackcapD, random = ~ 1 | dummy, 
    correlation = corMatern(form = ~ longitude+latitude  | dummy), 
    method = "ML", control=nlme::lmeControl(sing.tol=1e-20))

## Binomial GLMM
if (spaMM.getOption("example_maxtime")&gt;32) {
 data("Loaloa")
 LoaloaD &lt;- cbind(Loaloa,dummy=1) 
 MASS::glmmPQL(fixed =cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI, 
        data = LoaloaD, random = ~ 1 | dummy,family=binomial, 
        correlation = corMatern(form = ~ longitude+latitude | dummy))
}
</code></pre>

<hr>
<h2 id='corr_family'>
<code>corr_family</code> objects
</h2><span id='topic+corr_family'></span><span id='topic+SAR_WWt'></span><span id='topic+print.corr_family'></span>

<h3>Description</h3>

<p><code>corr_family</code> objects provide a convenient way to implement correlation models handled by <code>spaMM</code>, analogous to <code>family</code> objects. These objects are undocumented (but there are documentation pages for each of the models implemented).
</p>


<h3>Usage</h3>

<pre><code class='language-R'># Matern(...)           # see help(Matern)
# Cauchy(...)           # see help(Cauchy)
# corrMatrix(...)       # see help(corrMatrix)
# AR1(...)              # see help(AR1)
# adjacency(...)        # see help(adjacency)
# IMRF(...)             # see help(IMRF)
## S3 method for class 'corr_family'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corr_family_+3A_x">x</code></td>
<td>
<p><code>corr_family</code> object.</p>
</td></tr>
<tr><td><code id="corr_family_+3A_...">...</code></td>
<td>
<p>arguments that may be needed by some <code>corr_family</code> object or some print method.</p>
</td></tr>
</table>

<hr>
<h2 id='corrFamily'>
Using corrFamily constructors and descriptors.
</h2><span id='topic+corrFamily'></span>

<h3>Description</h3>

<p>One can declare and fit correlated random effects belonging to a user-defined correlation (or covariance) model (i.e., a parametric family of correlation matrices, although degenerate case with no parameter are also possible). This documentation is a first introduction to this feature. It is experimental in the sense that its design has been formalized only from a limited number of corrFamily examples, and that the documentation is not mature. Implementing prediction for random-effects defined in this way may be tricky. A distinct documentation <code><a href="#topic+corrFamily-design">corrFamily-design</a></code> provides more information for the efficient design of new correlation models to be fitted in this way.  
</p>
<p>A simple example of random-effect model implemented in this way is the autoregressive model of order <code class="reqn">p</code> (AR(p) in the literature; specifically documented elsewhere, see <code><a href="#topic+ARp">ARp</a></code>). It can be used as a formula term like other autocorrelated random-effects predefined in <span class="pkg">spaMM</span>, to be fitted by <code>fitme</code>
or <code>fitmv</code>:
</p>
<pre>
fitme(lh ~ 1 + ARp(1|time, p=3),  # &lt;= declaration of random effect
  &lt; data and other possible arguments &gt;)
</pre>
<p>User-defined correlation models should be registered for this simple syntax to work (see Details for an alternative syntax):  
</p>
<pre>
myARp &lt;- ARp                   # 'myARP' is thus a user-defined model
register_cF("myARp")        # Register it so that the next call works
fitme(lh ~ 1 + myARp(1|time, p=3),  
  &lt; data and other possible arguments &gt;)
</pre>
<p>The <code>ARp</code> object here copied in <code>myARp</code> is a function (the <em>corrFamily constructor</em>) which returns a <code>list</code> (the <em>corrFamily descriptor</em>) which contains the necessary information to fit a random effect with an AR(p) correlation. The <code>p</code> argument in the <code>myARp(1|time, p=3)</code> term enforces evaluation of <code>myARp(p=3)</code>, producing the descriptor for the AR(3) model. The structure of this descriptor is 
</p>
<pre>
List of 5
 $ Cf            :function (parvec)  
  ..- &lt; with some attribute &gt;
 $ tpar         : num [1:3] 0.5 0.333 0.25
 $ type         : chr "precision"
 $ initialize   :function (Zmatrix, ...) 
  ..- &lt; with some attribute &gt;
 $ fixed        : NULL
 $ calc_moreargs:function (corrfamily, ...)  
  ..- &lt; with some attribute &gt;
 $ levels_type        : chr "time_series"
 $ calc_corr_from_dist:function (ranFix, char_rd, distmat, ...)  
  ..- &lt; with some attribute &gt;
 &lt; and possibly other elements &gt; 
</pre>
<p>The meaning of these elements and some additional ones is explained below. 
</p>
<p>Only <code>Cf</code> and <code>tpar</code> are necessary elements of a corrFamily object. If one designs a new descriptor where some other elements are absent, <span class="pkg">spaMM</span> will try to provide plausible defaults for these elements. Further, if the descriptor does not provide parameter names (as the names of <code>tpar</code>, or in some more cryptic way), default names <code>"p1"</code>, <code>"p2"</code>... will be provided.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## corrFamily descriptor provided as a list of the form
#
# list(Cf=&lt;.&gt;, tpar=&lt;.&gt;, ...)

## corrFamily constructor: any function that returns 
#    a valid corrFamily descriptor
#
# function(tpar=&lt;.&gt;, fixed=&lt;.&gt;, ...) # typical but not mandatory arguments

## There is a distinct documentation page for 'register_cF'.
</code></pre>


<h3>Arguments</h3>

<p><b><em>Elements</em> of the corrFamily <em>descriptor</em></b>:
</p>
<table>
<tr><td><code id="corrFamily_+3A_cf">Cf</code></td>
<td>
<p>(required): function returning the correlation matrix (or covariance matrix, or their inverse), given its first argument, a parameter vector.</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_tpar">tpar</code></td>
<td>
<p>(required): a feasible argument of <code>Cf</code>. <code>tpar</code> is <b>not</b> an initial <b>nor</b> a fixed value.</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_type">type</code></td>
<td>
<p>optional, but required if the return value of <code>Cf</code> is an inverse correlation matrix rather than a correlation matrix, in which case one should specify <code>type="precision"</code>.</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_fixed">fixed</code></td>
<td>
<p>optional: fixed values for some correlation parameters, provided as a named vector with names consistent with those to be used for <code>tpar</code>. This is conceived to achieve the same statistical fit as by using the <code>fixed</code> argument of <code>fitme</code>, although the structure of the result of the fit differs in some subtle ways whether parameters are fixed through the descriptor or through the fitting function (see Examples in <code><a href="#topic+ARp">ARp</a></code>).</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_calc_moreargs">calc_moreargs</code></td>
<td>
<p>optional: a function returning a list with possible elements <code>init</code>, <code>lower</code> and <code>upper</code> for control of estimation (and possibly other elements for other purposes). If the descriptor does not provide this function, a default <code>calc_moreargs</code> will be provided, implementing unbounded optimization.</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_initialize">initialize</code></td>
<td>
<p>optional: a function evaluating variables that may be needed repeatedly by <code>Cf</code> or <code>Af</code>.</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_af">Af</code></td>
<td>
<p>This function should be defined if the correlation model requires an <b>A</b> matrix (the middle term in the case the design matrix of a random effect term is described by a triple matrix product <b>ZAL</b> as described in <code><a href="#topic+random-effects">random-effects</a></code>). Examples can be found in the descriptors returned by the <code><a href="#topic+ranGCA">ranGCA</a></code> and <code><a href="#topic+MaternIMRFa">MaternIMRFa</a></code> constructors. 
</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_levels_type">levels_type</code></td>
<td>
<p>In the above example its value <code>"time_series"</code> informs <span class="pkg">spaMM</span> that levels of the random effect should be considered for all integer values within the range of the <code>time</code> variable, not only for levels present in the data. If this element is not provided by the constructor, <span class="pkg">spaMM</span> will internally assume a <code>levels_type</code> suitable for geostatistical models. Further level types may be defined in the future.</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_calc_corr_from_dist">calc_corr_from_dist</code>, <code id="corrFamily_+3A_make_new_corr_lists">make_new_corr_lists</code></td>
<td>
<p>Functions possibly needed for prediction (see Details).</p>
</td></tr> 
<tr><td><code id="corrFamily_+3A_need_cnn">need_Cnn</code></td>
<td>
<p>optional: a boolean; default is TRUE. Controls prediction computations (see Details).</p>
</td></tr>
<tr><td><code id="corrFamily_+3A_public">public</code></td>
<td>
<p>An environment where some variables can be saved, typically by the <code>initialize</code> expression, for inspection at user level and for re-use. See <code><a href="#topic+diallel">diallel</a></code> for an example.</p>
</td></tr>
</table>
<p><b><em>fitting-function</em> arguments</b>:
</p>
<p><code>lower, upper, init</code> and <code>fixed</code> optimization controls can be used to control optimization of continuous parameters as for other random-effect parameters. They are specified as numeric vectors, themselves being element of the <code>corrPars</code> list (see Examples in <code><a href="#topic+corrFamily-design">corrFamily-design</a></code>). Parameter names (consistent with those to be used for the <code>tpar</code> argument) may be required to disambiguate incomplete vectors (e.g., to specify only its second element). Apart from <code>fixed</code> ones, any of the values not specified through the fitting-function arguments will be sought in the return value of the <code>calc_moreargs</code> function, if provided in the descriptor. If the <code>lower</code> or <code>upper</code> information is missing there, it must be provided throught the fitting-function call. If the <code>init</code> information is missing, a default value will be deduced from the bounds. The <code>init</code> specification is thus always optional while the bounds specification is optional only if the descriptor provides default values.  

</p>
<p><b><em>Arguments</em> of the corrFamily <em>constructor</em></b>
</p>
<p>These may be ad libitum, as design rules are defined only for the returned descriptor. However, arguments <code>tpar</code>, <code>fixed</code>, and <code>public</code> of predefined constructors, such as <code>ARp</code>, are designed to match the above respective elements of the descriptor. 
</p>


<h3>Details</h3>

<p><b>* Constructor elements for prediction:</b>
</p>
<p>For prediction of autocorrelated random effects, one must first assess whether levels of the random effect not represented in the fit are possible in new data (corresponding to new spatial locations in geostatistical models, or new time steps in time series). In that case <code>need_Cnn</code> must be TRUE (Interpolated MRFs do not require this as all required random-effect levels are determined by the IMRF <code>mesh</code> argument rather than by the fitted data or new data).
</p>
<p>Next, for autocorrelated random effects where <code>need_Cnn</code> is TRUE, a <code>make_new_corr_lists</code> function must be provided, except when a <code>calc_corr_from_dist</code> function is instead provided (which may be sufficient for models that construct the correlation from a spatial distance matrix). When <code>need_Cnn</code> is FALSE, a <code>make_new_corr_lists</code> function may still be needed. 
</p>
<p>The Examples section provides a simple example of such design, and the source code of the <code>ARp</code> or <code>ARMA</code> constructors provide further examples. They show that the <code>make_new_corr_lists</code> function may assign matrices or vectors as elements of three lists contained in a <code>newLv_env</code> environment. A matrix is assigned in the <code>cov_newLv_oldv_list</code>, specifying correlations between &ldquo;new&rdquo; levels of the random effect (implied by the new data) and &ldquo;old&rdquo; levels (those already included in the design matrix of the random effect for the fit). If <code>need_Cnn</code> is TRUE, a second matrix may be assigned in the <code>cov_newLv_newLv_list</code>, specifying correlation between &ldquo;new&rdquo; levels, and the diagonal of this matrix is assigned in the <code>diag_cov_newLv_newLv_list</code>. The overall structure of the code (the conditions where these assignments are performed, and the list indices), should be conserved. 
</p>
<p><b>* Fitting a <code>corrFamily</code> without a constructor:</b>
</p>
<p>It is possible to use an unregistered corrFamily, as follows: 
</p>
<pre>
AR3 &lt;- ARp(p=3)          # Generate descriptor of AR model of order 3

fitme(lh ~ 1 + corrFamily(1|time),  # &lt;= declaration of random effect
  covStruct=list( 
    corrFamily= AR3     # &lt;= declaration of its correlation structure
  ), 
  &lt; data and other possible arguments &gt;)
</pre>
<p>Here the fit only uses a descriptor list, not a constructor function. This descriptor is here provided to the fitting function as an element of the <code><a href="#topic+covStruct">covStruct</a></code> argument (using the general syntax of this argument), and in the model formula the corresponding random effect is declared as a term of the form<br />
<code>corrFamily(1|&lt;grouping factor&gt;)</code>. 
</p>
<p>This syntax is more complex than the one using a registered constructor, but it might be useful for development purposes (one only has to code the descriptor, not the constructor function). However, it is not general; in particular, using registered constructors may be required to obtain correct results when fitting multivariate-response models by <code>fitmv</code>.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+ARp">ARp</a></code>, <code><a href="#topic+diallel">diallel</a></code>, and <code><a href="#topic+MaternIMRFa">MaternIMRFa</a></code> for basic examples of using a predefined corrFamily descriptor, and <code><a href="#topic+corrFamily-design">corrFamily-design</a></code> for more geeky stuff including examples of implementing simple new correlation families. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
### Minimal (with many features missing) reimplementation 
#     of corrMatrix() terms as a corrFamily 


corrMatrix_cF &lt;- function(corrMatrix) {
  
  force(corrMatrix) # Makes it available in the environment of the functions next defined.
  oldZlevels &lt;- NULL
  
  initialize &lt;- function(Zmatrix, ...) {
    oldZlevels &lt;&lt;- colnames(Zmatrix) # Pass info about levels of the random effect in the data.
  }
  
  Cf &lt;- function(newlevels=oldZlevels ) {
    if (length(newlevels)) {
      corrMatrix[newlevels,newlevels]
    } else corrMatrix[oldZlevels,oldZlevels] # for Cf(tpar=numeric(0L))
  }
  
  calc_moreargs &lt;- function(corrfamily, ...) {
    list(init=c(),lower=c(),upper=c())
  }
  
  make_new_corr_lists &lt;- function(newLv_env, which_mats, newZAlist, new_rd, ...) {
    newlevels &lt;- colnames(newZAlist[[new_rd]])
    newLv_env$cov_newLv_oldv_list[[new_rd]] &lt;- corrMatrix[newlevels,oldZlevels, drop=FALSE]
    if (which_mats$nn[new_rd]) {
      newLv_env$cov_newLv_newLv_list[[new_rd]] &lt;- corrMatrix[newlevels,newlevels, drop=FALSE]
    } else { 
      newLv_env$diag_cov_newLv_newLv_list[[new_rd]] &lt;- rep(1,length(newlevels)) 
    }
  }
  
  list(Cf=Cf, tpar=numeric(0L), initialize=initialize, calc_moreargs=calc_moreargs, 
       make_new_corr_lists=make_new_corr_lists,
       tag="corrMatrix_cF") 
}

register_cF("corrMatrix_cF")

# usage:

data("blackcap") 
MLcorMat &lt;- MaternCorr(proxy::dist(blackcap[,c("latitude","longitude")]),
                       nu=0.6285603,rho=0.0544659)
corrmat &lt;- proxy::as.matrix(MLcorMat, diag=1)

fitme(migStatus ~ means+ corrMatrix_cF(1|name, corrMatrix=corrmat),data=blackcap,
      corrMatrix=MLcorMat,method="ML")
      
unregister_cF("corrMatrix_cF") # Tidy things before leaving.         


## End(Not run)
</code></pre>

<hr>
<h2 id='corrFamily-definition'>
corrFamily definition
</h2><span id='topic+corrFamily-definition'></span>

<h3>Description</h3>

<p>Tentative formal rules for definition of corrFamily descriptors (work in progress). This is likely to repeat and extend information partially given in <code><a href="#topic+corrFamily">corrFamily</a></code> and <code><a href="#topic+corrFamily-design">corrFamily-design</a></code> documentations.
</p>

<p>User-level rules (not relevant fo  corrFamily descriptors internally modified during a fit):
</p>
<dl>
<dt>tpar</dt><dd>
<p>Should always be present. For trivial parameterless cases (e.g. <code>ranGCA</code>), it should be <code>numeric(0L)</code>, not <code>NULL</code>.
</p>
</dd>
<dt>Cf</dt><dd>
<p>function; should always be present. For trivial uncorrelated random effects (e.g. <code>ranGCA</code>, 
where only the <code>Af</code> function carries the information for the model), 
it should return an identity matrix, not <code>NULL</code>, 
with row names to be matched to the column names of the <b>Z</b> matrix for the random effect.
</p>
</dd>
<dt>calc_moreargs</dt><dd>
<p>optional function. If present, it should have formal arguments including at least <code>corrfamily</code> and .... 
</p>
</dd>
<dt>Af</dt><dd>
<p>function; optional. If present, it should have row names to be matched to the column names of the <b>Z</b> matrix for the random effect, and also needs column names if it is to be matched with the row names of a correlation matrix (or its inverse).
</p>
</dd>
<dt>initialize</dt><dd>
<p>Optional function.  If present, should have formal arguments including at least <code>Zmatrix</code> and ....  
</p>
<p>In predefined corrFamily constructors, variables created by <code>initialize</code> for use by <code>Cf</code> or <code>Af</code> should be declared (typically as <code>NULL</code>) in the body of the constructor, so that R CMD check does not complain.
</p>
</dd>
<dt>public</dt><dd>
<p>An environment. <code>initialize</code> may write into it. It might also read into it, for example read the result of a long previous computation by <code>initialize</code> during a previous fit, though this opens the door to various errors. 
</p>
</dd>
</dl>


<hr>
<h2 id='corrFamily-design'>
Designing new corrFamily descriptors for parametric correlation families
</h2><span id='topic+corrFamily-design'></span>

<h3>Description</h3>

<p>This documentation describe additional design features to be taken into account when defining a new <code><a href="#topic+corrFamily">corrFamily</a></code> descriptor for a correlation model. Using such a descriptor will be more efficient than the equally general method, of maximizing an objective function  of the correlation parameters that calls (say) <code>fitme()</code> on a model including a <code>corrMatrix</code> itself function of the correlation parameters. But this may still be inefficient if a few issues are ignored.
</p>

<p><b>For elements of the corrFamily descriptor for basic cases</b>:
</p>
<dl>
<dt>Cf</dt><dd><p>The function value should
(1) be of constant class for all parameter values. For families of mathematically sparse matrices, the <code>CsparseMatrix</code> class is recommended (and more specifically the <code>dsCMatrix</code> class since the matrix is symmetric); (2) have row names that match the levels of the grouping factor  (the nested random effect Example shows the code needed when this nested effect is defined from two variables).</p>
</dd>
<dt>tpar</dt><dd><p>In order to favor the automatic selection of suitable algorithms, <code>tpar</code> should be chosen so that <code>Cf(tpar)</code> is <b>least</b> sparse (i.e., has the minimal number of elements equal to zero) in the correlation family, in terms of its sparsity and of the sparsity of its inverse. A <code>tpar</code> yielding an identity matrix is often a <b>*bad*</b> template as least sparse correlation matrices and their inverses are denser for most families except diagonal ones. For degerate corrFamily objects that describe a constant correlation model rather than a parametric family, use <code>tpar=numeric(0)</code>.</p>
</dd>
<dt>type</dt><dd><p>Do not forget <code>type="precision"</code> it if the return value of <code>Cf</code> is an inverse correlation matrix rather than a correlation matrix, in which case one should specify .</p>
</dd>
<dt>calc_moreargs</dt><dd><p> should have formal arguments including at least <code>corrfamily</code> and <code>...</code>. The source code of <code>ARp</code>, <code>ARMA</code> or <code>diallel</code> shows the expected structure of its return value.</p>
</dd>
</dl>
<p><b>For advanced features of the corrFamily descriptor</b>:
</p>
<dl>
<dt>Af</dt><dd><p><code>Af</code> has (minimally) three formal arguments <code>(newdata, term, ...)</code>. <span class="pkg">spaMM</span> will call <code>Af</code> with distinct values of the <code>newdata</code> argument for the fit, and for predictions for new data. For the curious: the <code>term</code> argument that will be provided by <span class="pkg">spaMM</span> to <code>Af</code> is the formula term for the random effect &ndash; an object of class <code>call</code>, as obtained e.g. by<br /> 
<code>( ~ 1+ corrFamily(1 | longitude + latitude))[[2]][[3]] </code> &ndash;, which will provide the names of the variables that need to be taken from the <code>newdata</code> to construct the matrix returned by <code>Af</code>.
</p>
</dd> 
</dl>



<h3>Details</h3>


<ul>
<li> <p><span class="pkg">spaMM</span> will regularize invalid or nearly-singular correlation or covariance matrices internally if the correlation function has not done so already, but it it better to control this in the correlation function. The <code><a href="#topic+regularize">regularize</a></code> convenience function is available for that purpose, but parametrizations that avoid the need for regularization are even better, since fitting models with nearly-singular correlation matrices is prone to various difficulties (The Toeplitz example below is good to illustrate potential problems but is otherwise poor as it produces non-positive definite matrices; the <code><a href="#topic+ARp">ARp</a></code> constructor illustrates a parametrization that avoids that problem).
</p>

</li>
<li><p> Users should make sure that any regularized matrix still belongs to the intended parametric family of matrices, and they should keep in mind that the <span class="pkg">spaMM</span> output will show the input parameters of the unregularized matrix, not the parameters of the regularized one (e.g., in the Toeplitz example below, the fitted matrix is a regularized Toepliz matrix with slightly different coefficients than the input parameters).  
</p>
<p>And for efficiency,
</p>
</li>
<li><p> Let us repeat that the correlation function should return matrices of constant class, and in sparse format when the matrices are indeed mathematically sparse. For mathematically dense matrices (as in the Toeplitz example below), the <code>dsyMatrix</code> class may be suitable.
</p>
</li>
<li><p> Let us repeat that in order to favor the automatic selection of suitable algorithms, <code>tpar</code> should be chosen so that <code>Cf(tpar)</code> is <b>least</b> sparse in the correlation family. For matrices of <code>CsparseMatrix</code>, a check is implemented to catch wrong choices of <code>tpar</code>.
</p>
</li>
<li><p> For challenging problems (large data, many parameters...) it may pay to optimize a bit the correlation function. The Example of nested effects with heterogenous variance below illustrates a possible trick. In the same cases,  It may also pay to try the alternative <code><a href="#topic+algebra">algebra</a></code>ic methods, by first comparing speed of the different methods (<code>control.HLfit=list(algebra= &lt;"spprec"|"spcorr"|"decorr"&gt;)</code>) for given correlation parameter values, rather than to assume that <span class="pkg">spaMM</span> will find the best method (even if it often does so).
</p>
</li>
<li><p> The corrFamily descriptor may optionally contain booleans <code>possiblyDenseCorr</code> and <code>sparsePrec</code> to help spaMM select the most appropriate matrix algebraic methods. <code>sparsePrec</code> should be set to TRUE if sparse-precision methods are expected to be efficient for fitting the random effect. <code>possiblyDenseCorr</code> should be set to FALSE if the correlation matrix is expected to be sparse, which means here that less than 15% of its elements are non-zero.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;2 &amp;&amp;
      requireNamespace("agridat", quietly = TRUE)) {

data("onofri.winterwheat", package="agridat")

##### Fitting a Toeplitz correlation model for temporal correlations #####

# A Toeplitz correlation matrix of dimension d*d has d-1 parameters 
# (by symmetry, and with 1s on the main diagonal). These d-1 parameters 
# can be fitted as follows:

Toepfn &lt;- function(v) {
  toepmat &lt;- Matrix::forceSymmetric(toeplitz(c(1,v))) # dsyMatrix
  # Many of the matrices in this family are not valid correlation matrices;
  #   the regularize() function is handy here:
  toepmat &lt;- regularize(toepmat, maxcondnum=1e12)
  # And don't forget the rownames!
  rownames(toepmat) &lt;- unique(onofri.winterwheat$year)
  toepmat
}

(Toepfit &lt;- spaMM::fitme(
  yield ~ gen + corrFamily(1|year), data=onofri.winterwheat, method="REML",
  covStruct=list(corrFamily=list(Cf=Toepfn, tpar=rep(1e-4,6))), 
         # (Note the gentle warning if one instead uses tpar=rep(0,6) here)  
  lower=list(corrPars=list("1"=rep(-0.999,6))), 
  upper=list(corrPars=list("1"=rep(0.999,6))))) 

# The fitted matrix is (nearly) singular, and was regularized:

eigen(Corr(Toepfit)[[1]])$values

# which means that the returned likelihood may be inaccurate, 
# and also that the actual matrix elements differ from input parameters:

Corr(Toepfit)[[1]][1,-1]  

### The usual rules for specifying covStruct, 'lower', 'upper' and 'init' apply
# here when the corrFamily term is the second random-effect:

(Toep2 &lt;- spaMM::fitme(
        yield ~ 1 + (1|gen) + corrFamily(1|year), data=onofri.winterwheat, method="REML",
        covStruct=list("1"=NULL, corrFamily=list(Cf=Toepfn, tpar=rep(1e-4,6))), 
        , init=list(corrPars=list("2"=rep(0.1,6))),
        lower=list(corrPars=list("2"=rep(-0.999,6))), 
        upper=list(corrPars=list("2"=rep(0.999,6)))))

##### Fitting one variance among years per each of 8 genotypes. #####

# First, note that this can be *more efficiently* fitted by another syntax:

### Fit as a constrained random-coefficient model: 
    
# Diagonal matrix of NA's, represented as vector for its lower triangle:
ranCoefs_for_diag &lt;- function(nlevels) { 
  vec &lt;- rep(0,nlevels*(nlevels+1L)/2L)
  vec[cumsum(c(1L,rev(seq(nlevels-1L)+1L)))] &lt;- NA
  vec
} 
    
(by_rC &lt;- spaMM::fitme(yield ~ 1 + (0+gen|year), data=onofri.winterwheat, method="REML",
                       fixed=list(ranCoefs=list("1"=ranCoefs_for_diag(8)))))
                         
### Fit as a corrFamily model:   

gy_levels &lt;- paste0(gl(8,1,length =56,labels=levels(onofri.winterwheat$gen)),":",
                        gl(7,8,labels=unique(onofri.winterwheat$year)))
                        
# A log scale is often suitable for variances, hence is used below;

# a correct but crude implementation of the model is
diagf &lt;- function(logvar) {
  corr_map &lt;- kronecker(Matrix::.symDiagonal(n=7),diag(x=exp(logvar)))
  rownames(corr_map) &lt;- gy_levels
  corr_map
}

# but we can minimize matrix operations as follows:

corr_map &lt;- Matrix::.symDiagonal(n=8,x=seq(8))
rownames(corr_map) &lt;- unique(onofri.winterwheat$gen)
      
diagf &lt;- function(logvar) {
  corr_map@x &lt;- exp(logvar)[corr_map@x]
  corr_map
}                 # (and this returns a dsCMatrix)
      
(by_cF &lt;- spaMM::fitme(
        yield ~ 1 + corrFamily(1|gen %in% year), data=onofri.winterwheat, method="REML",
        covStruct=list(corrFamily = list(Cf=diagf, tpar=rep(1,8))), 
        fixed=list(lambda=1),            # Don't forget to fix this redundant parameter!
        # init=list(corrPars=list("1"=rep(log(O.1),8))), # 'init' optional 
        lower=list(corrPars=list("1"=rep(log(1e-6),8))), # 'lower' and 'upper' required
        upper=list(corrPars=list("1"=rep(log(1e6),8)))))

# =&gt; The 'gen' effect is nested in the 'year' effect and this must be specified in the 
# right-hand side of corrFamily(1|gen %in% year) so that the design matrix 'Z' for the 
# random effects to have the correct structure. And then, as for other correlation
# structures (say Matern) it should be necessary to specify only the correlation matrix 
# for a given year, as done above. Should this fail, it is also possible to specify the 
# correlation matrix over years, as done below. spaMM will automatically detect, from   
# its size matching the number of columns of Z, that it must be the matrix over years.  

corr_map &lt;- Matrix::forceSymmetric(kronecker(Matrix::.symDiagonal(n=7),diag(x=seq(8))))
rownames(corr_map) &lt;- gy_levels

diagf &lt;- function(logvar) {
  corr_map@x &lt;- exp(logvar)[corr_map@x]
  corr_map
}                 # (and this returns a dsCMatrix)

(by_cF &lt;- spaMM::fitme(
  yield ~ 1 + corrFamily(1|gen %in% year), data=onofri.winterwheat, method="REML",
  covStruct=list(corrFamily = list(Cf=diagf, tpar=rep(1,8))), 
  fixed=list(lambda=1),            # Don't forget to fix this redundant parameter!
  # init=list(corrPars=list("1"=rep(log(O.1),8))), # 'init' optional 
  lower=list(corrPars=list("1"=rep(log(1e-6),8))), # 'lower' and 'upper' required
  upper=list(corrPars=list("1"=rep(log(1e6),8)))))

exp(get_ranPars(by_cF)$corrPars[[1]]) # fitted variances 
  
}
</code></pre>

<hr>
<h2 id='corrHLfit'>
Fits a mixed model, typically a spatial GLMM.
</h2><span id='topic+corrHLfit'></span>

<h3>Description</h3>

<p>This was the first function for fitting all spatial models in spaMM, and is still fully functional, but it is recommended to use <code><a href="#topic+fitme">fitme</a></code> which has different defaults and generally selects more efficient fitting methods, and will handle all classes of models that spaMM can fit, including non-spatial ones. <code>corrHLfit</code> performs the joint estimation of correlation parameters, fixed effect and dispersion parameters. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrHLfit(formula, data, init.corrHLfit = list(), init.HLfit = list(), 
          ranFix, fixed=list(), lower = list(),  upper = list(), 
          objective = NULL, resid.model = ~1, 
          control.dist = list(), control.corrHLfit = list(),
          processed = NULL, family = gaussian(), method="REML",
          nb_cores = NULL, weights.form = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corrHLfit_+3A_formula">formula</code></td>
<td>

<p>Either a linear model <code><a href="#topic+formula">formula</a></code> (as handled  by various fitting functions) or a <code>predictor</code>, i.e. a formula with attributes (see <code><a href="#topic+Predictor">Predictor</a></code> and examples below). See Details in <code><a href="#topic+spaMM">spaMM</a></code> for allowed terms in the formula.
</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables in the response and the model formula.</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_init.corrhlfit">init.corrHLfit</code></td>
<td>

<p>An optional list of initial values for correlation and/or dispersion parameters, e.g. 
<code>list(rho=1,nu=1,lambda=1,phi=1)</code> where <code>rho</code> and <code>nu</code> are parameters of the Matérn family (see <code><a href="#topic+Matern">Matern</a></code>), and 
<code>lambda</code> and <code>phi</code> are dispersion parameters (see Details in <code><a href="#topic+spaMM">spaMM</a></code> for the meaning of these parameters). 
All are optional, but giving values for 
a dispersion parameter changes the ways it is estimated (see Details).
<code>rho</code>  may be a vector (see <code><a href="#topic+make_scaled_dist">make_scaled_dist</a></code>) and, in that case, it is possible that some or all of its elements are <code>NA</code>, for which <code>corrHLfit</code> substitutes automatically determined values.  
</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_init.hlfit">init.HLfit</code></td>
<td>
<p>See identically named <code><a href="#topic+HLfit">HLfit</a></code> argument.

</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_fixed">fixed</code>, <code id="corrHLfit_+3A_ranfix">ranFix</code></td>
<td>
<p>A list similar to <code>init.corrHLfit</code>, but specifying fixed values of the parameters not estimated. <code>ranFix</code> is the old argument, maintained for back compatibility; <code>fixed</code> is the new argument, uniform across <span class="pkg">spaMM</span> fitting functions. See <code><a href="#topic+ranFix">ranFix</a></code> for further information.</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_lower">lower</code></td>
<td>

<p>An optional (sub)list of values of the parameters specified through <code>init.corrHLfit</code>, in the same format as <code>init.corrHLfit</code>, used as lower values in calls to <code>optim</code>. See Details for default values.
</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_upper">upper</code></td>
<td>
<p>Same as <code>lower</code>, but for upper values.</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_objective">objective</code></td>
<td>
<p> For development purpose, not documented (this had a distinct use in the first version of spaMM, but has been deprecated as such).</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_resid.model">resid.model</code></td>
<td>
<p>See identically named <code><a href="#topic+HLfit">HLfit</a></code> argument.</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_control.dist">control.dist</code></td>
<td>
<p>See <code>control.dist</code> in <code><a href="#topic+HLCor">HLCor</a></code></p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_control.corrhlfit">control.corrHLfit</code></td>
<td>

<p>This may be used control the optimizer. See <code><a href="#topic+spaMM.options">spaMM.options</a></code></p>
</td></tr></table>
<p> for default values.
</p>
<table>
<tr><td><code id="corrHLfit_+3A_processed">processed</code></td>
<td>
<p>For programming purposes, not documented.  </p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_family">family</code></td>
<td>
<p>Either a <code><a href="#topic+family">family</a></code> or a <code><a href="#topic+multi">multi</a></code> value. </p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_method">method</code></td>
<td>
<p>Character: the fitting method to be used, such as <code>"ML"</code>, <code>"REML"</code> or <code>"PQL/L"</code>. <code>"REML"</code> is the default. Other possible values of <code>HLfit</code>'s <code>method</code> argument are handled.
</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_weights.form">weights.form</code></td>
<td>

<p>Specification of prior weights by a one-sided formula: use <code>weights.form = ~ pw</code> instead of <code>prior.weights = pw</code>. The effect will be the same except that such an argument, known to evaluate to an object of class <code>"formula"</code>, is suitable to enforce safe programming practices (see <code><a href="#topic+good-practice">good-practice</a></code>).  
</p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_nb_cores">nb_cores</code></td>
<td>
<p><b>Not yet operative</b>, only for development purposes. Number of cores to use for parallel computations. </p>
</td></tr>
<tr><td><code id="corrHLfit_+3A_...">...</code></td>
<td>

<p>Optional arguments passed to <code><a href="#topic+HLCor">HLCor</a></code>, <code><a href="#topic+HLfit">HLfit</a></code> or  <code><a href="#topic+mat_sqrt">mat_sqrt</a></code>, for example the <code>distMatrix</code> argument 
of <code>HLCor</code>, or the <code>verbose</code> argument of <code>HLfit</code>. Arguments that do not fit within these functions are detected and a warning is issued. In a <code>corrHLfit</code> call, the <code>verbose</code> vector of booleans may include a <code>TRACE=TRUE</code> element, in which case information is displayed for each set of correlation and dispersion parameter values considered by the optimiser (see <code><a href="#topic+verbose">verbose</a></code> for further information, mostly useless except for development purposes).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For approximations of likelihood, see <code><a href="#topic+method">method</a></code>.  For the possible structures of random effects, see <code><a href="#topic+random-effects">random-effects</a></code>,
</p>
<p>By default <code>corrHLfit</code> will estimate correlation parameters by maximizing the <code>objective</code> value returned by <code>HLCor</code> calls wherein the dispersion parameters are estimated jointly with fixed effects for given correlation parameters. If dispersion parameters are specified in <code>init.corrHLfit</code>, they will also be estimated by maximizing the <code>objective</code> value, and <code>HLCor calls</code> will not estimate them jointly with fixed effects. This means that in general the fixed effect estimates may vary depending on <code>init.corrHLfit</code> when any form of REML correction is applied. 
</p>
<p>Correctly using <code>corrHLfit</code> for likelihood ratio tests of fixed effects may then be tricky. It is safe to perform full ML fits of all parameters (using <code>method="ML"</code>) for such tests (see Examples).   The higher level function <code><a href="#topic+fixedLRT">fixedLRT</a></code> is a safe interface for likelihood ratio tests using some form of REML estimation in <code>corrHLfit</code>.  
</p>
<p><code>attr(&lt;fitted object&gt;,"optimInfo")$lower</code> and ...<code>$upper</code> gives the lower and upper bounds for optimization of correlation parameters. These are the default values if the user did not provide explicit values. For the adjacency model, the default values are the inverse of the maximum and minimum eigenvalues of the <code>adjMatrix</code>. For the Matérn model, the default values are not so easily summarized: they are intended to cover the range of values for which there is statistical information to distinguish among them.
</p>


<h3>Value</h3>

<p>The return value of an <code>HLCor</code> call, with additional attributes. The <code>HLCor</code> call is evaluated at the estimated correlation parameter values. These values are included in the return object as its <code>$corrPars</code> member. The attributes added by <code>corrHLfit</code> include the original call of the function (which can be retrived by <code>getCall</code>(&lt;fitted object&gt;), and information about the optimization call within <code>corrHLfit</code>. 
</p>


<h3>See Also</h3>

<p>See more examples on data set <code><a href="#topic+Loaloa">Loaloa</a></code>, to compare fit times by <code>corrHLfit</code> and <code>fitme</code>.
See <code><a href="#topic+fixedLRT">fixedLRT</a></code> for likelihood ratio tests.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with an adjacency matrix (autoregressive model):
if (spaMM.getOption("example_maxtime")&gt;0.7) {          
  corrHLfit(cases~I(prop.ag/10) +adjacency(1|gridcode)+offset(log(expec)),
          adjMatrix=Nmatrix,family=poisson(),data=scotlip,method="ML") 
}

#### Examples with Matern correlations
## A likelihood ratio test based on the ML fits of a full and of a null model.
if (spaMM.getOption("example_maxtime")&gt;1.4) {
 data("blackcap")
 (fullfit &lt;- corrHLfit(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
                    method="ML") )
 (nullfit &lt;- corrHLfit(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap,
                    method="ML",init.corrHLfit=list(phi=1e-6))) 
 ## p-value:
 1-pchisq(2*(logLik(fullfit)-logLik(nullfit)),df=1)
}
</code></pre>

<hr>
<h2 id='corrMatrix'>Using a corrMatrix argument</h2><span id='topic+corrMatrix'></span>

<h3>Description</h3>

<p><code>corrMatrix</code> is an argument of <code>HLCor</code>, of class <code>dist</code> or <code>matrix</code>, with can be used if the model formula contains a term of the form <code>corrMatrix(1|&lt;...&gt;)</code>. It describes a correlation matrix, possibly as a <code>dist</code> object. A covariance matrix can actually be passed through this argument, but then it must be a full matrix, not a <code>dist</code> object. The way the rows and columns of the matrix are matched to the rows of the <code>data</code> depends on the nature of the grouping term <code>&lt;...&gt;</code>.
</p>
<p>The <code><a href="#topic+covStruct">covStruct</a></code> argument can be used for the same purpose and is much more general, in particular allowing to specify several correlation matrices.
</p>


<h3>Details</h3>

<p>The simplest case is illustrated in the first two examples below: the grouping term is identical to a single variable which is present in the <code>data</code>, whose levels match the rownames of the <code>corrMatrix</code>. As illustrated by the second example, the order of the data does not matter in that case, because the factor levels are used to match the <code>data</code> rows to the appropriate row and columns of the <code>corrMatrix</code>. The <code>corrMatrix</code> may even contain rows (and columns) in excess of the levels of the grouping term, in  which case these rows are ignored. 
</p>
<p>These convenient properties no longer hold when the grouping term is not a single variable from the <code>data</code> (third example below), or when its levels do not correspond to row names of the matrix. In these cases, (1) no attempt is made to match the <code>data</code> rows to the row and column names of the <code>corrMatrix</code>. Such attempt could succeed only if the user had given names to the matrix matching those that the called function could create from the information in the <code>data</code>, in which case the user should find easier to specify a single variable that can be matched; (2) the order of <code>data</code> and <code>corrMatrix</code> matter; Internally, a single factor variable is constructed from all levels of the variables in the grouping term (i.e., from all levels of <code>latitude</code> and <code>longitude</code>, in the third example), with levels 1,2,3... that are matched to rows 1,2,3... of the <code>corrMatrix</code>. Thus the first row of the data is always associated to the first row of the matrix; (3) further, the dimension of the matrix must match the number of levels implied by the grouping term. For example, one might consider the case of 14 response values but of correlations between only 7 levels of a random effect, with two responses for each level. Then the matrix must be of dimension 7x7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap") 
## Here we manually reconstruct the correlation matrix 
##  of the ML fit produced by corrHLfit:
MLcorMat &lt;- MaternCorr(proxy::dist(blackcap[,c("longitude","latitude")]),
                        nu=0.6285603,rho=0.0544659)
blackcap$name &lt;- as.factor(rownames(blackcap))                
#

## (1) Single variable present in the data 
#
HLCor(migStatus ~ means+ corrMatrix(1|name),data=blackcap,
      corrMatrix=MLcorMat,method="ML")

## (2) Same, permuted: still gives correct result
#
perm &lt;- sample(14)
# Permuted matrix (with permuted names) as 'dist' object
pmat &lt;- as.matrix(MLcorMat)[perm,perm] 
HLCor(migStatus ~ means+ corrMatrix(1|name),data=blackcap,
      corrMatrix=as.dist(pmat),method="ML")
#
# Permuted matrix (with permuted names) as correlation matrix
pcorr &lt;- proxy::as.matrix(MLcorMat, diag=1)[perm,perm] 
HLCor(migStatus ~ means+ corrMatrix(1|name),data=blackcap,
      corrMatrix=pcorr,method="ML")
#

## (3) Other grouping terms (note the messages):
#
HLCor(migStatus ~ means+ corrMatrix(1|longitude+latitude),data=blackcap,
      corrMatrix=MLcorMat,method="ML")
</code></pre>

<hr>
<h2 id='covStruct'>Specifying correlation structures</h2><span id='topic+covStruct'></span><span id='topic+Predictor'></span><span id='topic+as_precision'></span>

<h3>Description</h3>

<p><code>covStruct</code> is a formal argument of <code>HLCor</code>, also handled by <code>fitme</code> and <code>corrHLfit</code>, that allows one to specify the correlation structure for different types of random effects, It is an alternative to other ad hoc formal arguments such as <code>corrMatrix</code> or <code>adjMatrix</code>. It replaces the deprecated function <code>Predictor(...)</code> which has served as an interface for specifying the design matrices for random effects in early versions of <code>spaMM</code>. 
</p>
<p>The main use of <code>covStruct</code> is to specify the correlation matrix of levels of a given random effect term, or its inverse (a precision matrix). Assuming that the design matrix of each random effect term follows the structure <b>ZAL</b> described in <code><a href="#topic+random-effects">random-effects</a></code>, it is thus an indirect way of specifying the &ldquo;square root&rdquo; <b>L</b> of the correlation matrix. The optional <b>A</b> factor can also be given by the optional <code>"AMatrices"</code> attribute of <code>covStruct</code>.      
</p>
<p><code>covStruct</code> is a <code>list</code> of matrices with names specifying the type of matrix considered:<br /> 
<code>covStruct=list(corrMatrix=&lt;some matrix&gt;)</code> or <code>covStruct=list(adjMatrix=&lt;some matrix&gt;)</code>, where the &ldquo;corrMatrix&rdquo; or &ldquo;adjMatrix&rdquo; labels are used to specify the type of information provided (accordingly, the names can be repeated: <code>covStruct=list(corrMatrix=&lt;.&gt;,corrMatrix=&lt;.&gt;)</code>). 
<code>NULL</code> list members may be necessary, e.g.<br /> 
<code>covStruct=list(corrMatrix=&lt;.&gt;,"2"=NULL,corrMatrix=&lt;.&gt;)</code>)<br />
when correlations matrices are required only for the first and third random effect. 
</p>
<p>The covariance structure of a <code>corrMatrix(1|&lt;grouping factor&gt;)</code> formula term can be specified in two ways (see Examples): either by a correlation matrix factor (<code>covStruct=list(corrMatrix=&lt;some matrix&gt;)</code>), or by a precision matrix factor <b>Q</b> such that the covariance factor is <code class="reqn">\lambda</code><b>Q</b><code class="reqn">^{-1}</code>, using the type name <code>"precision"</code>: <code>covStruct=list(precision=&lt;some matrix&gt;)</code>. 
The function <code>as_precision</code> can be used to perform the conversion from correlation information to precision factor (using a crude solve() that may not always be efficient), but fitting functions may also perform such conversions automatically.
</p>
<p><code>"AMatrices"</code> is a list of matrices. The names of elements of the list does not matter, but the <em>i</em>th <code>A</code> matrix, and its row names, should match the <em>i</em>th <b>Z</b> matrix, and its column names. This implies that <code>NULL</code> list members may be necessary, as for the <code>covStruct</code> list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_precision(corrMatrix, condnum=1e12)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covStruct_+3A_corrmatrix">corrMatrix</code></td>
<td>
<p>Correlation matrix, specified as <code>matrix</code> or as <code>dist</code> object</p>
</td></tr>
<tr><td><code id="covStruct_+3A_condnum">condnum</code></td>
<td>
<p>Numeric: when a standard Cholesky factorization fails, the matrix is regularized so that the regularized matrix has this condition number (in version 3.10.0 this correction has been implemented more exactly than in previous versions).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>covStruct</code> can also be specified as a list with an optional <code>"types"</code> attribute, e.g.<br />
<code>structure(list(&lt;some matrix&gt;,types="corrMatrix"))</code>.
</p>


<h3>Value</h3>

<p><code>as_precision</code> returns a list with additional class <code>precision</code> and with single element a symmetric matrix of class <code>dsCMatrix</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gryphon">Gryphon</a></code> and <code><a href="#topic+pedigree">pedigree</a></code> for a type of applications where declaring a precision matrix is useful.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("blackcap") 
# a 'dist' object can be used to specify a corrMatrix:  
MLdistMat &lt;- MaternCorr(proxy::dist(blackcap[,c("latitude","longitude")]),
                        nu=0.6285603,rho=0.0544659) # a 'dist' object!
blackcap$name &lt;- as.factor(rownames(blackcap))     
fitme(migStatus ~ means + corrMatrix(1|name), data=blackcap,
      corrMatrix=MLdistMat)

#### Same result by different input and algorithm:
fitme(migStatus ~ means + corrMatrix(1|name), data=blackcap,
      covStruct=list(precision=as_precision(MLdistMat)))

# Manual version of the same:
as_mat &lt;- proxy::as.matrix(MLdistMat, diag=1) 
prec_mat &lt;- solve(as_mat) ## precision factor matrix
fitme(migStatus ~ means + corrMatrix(1|name), data=blackcap,
      covStruct=list(precision=prec_mat))

# Since no correlation parameter is estimated, 
# HLcor(., method="ML")  is here equivalent to fitme()

## End(Not run)
</code></pre>

<hr>
<h2 id='diallel'>
Random-effect structures for diallel experiments and other dyadic interactions
</h2><span id='topic+ranGCA'></span><span id='topic+antisym'></span><span id='topic+diallel'></span>

<h3>Description</h3>

<p><code>ranGCA</code> and <code>diallel</code> are random-effect structures designed to represent the effet of symmetric interactions between pairs of individuals (order of individuals in the pair does not matter), while <code>antisym</code> represents anti-symmetric interactions (the effect of reciprocal ordered pairs on the outcome are opposite, as in the so-called Bradley-Terry models). These random-effect structures all account for multiple membership, i.e., the fact that the same individual may act as the first or the second individual among different pairs, or even within one pair if this makes sense).   
</p>
<p>More formally, the outcome of an interaction between a pair <code class="reqn">i,j</code> of agents is subject to a symmetric overall random effect <code class="reqn">v_{ij}</code> when the effect  &ldquo;on&rdquo; individual <code class="reqn">i</code> (or viewed from the perspective of individual <code class="reqn">i</code>) equals the effect on <code class="reqn">j</code>: <code class="reqn">v_{ij}=v_{ji}</code>. This may result from the additive effect of individual random effects <code class="reqn">v_{i}</code> and <code class="reqn">v_{j}</code>:  <code class="reqn">v_{ij}=v_i+v_j</code>, but also from non-additive effects <code class="reqn">v_{ij}=v_i+v_j+a_{ij}</code> if the interaction term  <code class="reqn">a_{ij}</code> is itself symmetric (<code class="reqn">a_{ij}=a_{ji}</code>). <code>ranGCA</code> and <code>diallel</code> effects represent such symmetric effects, additive or non-additive respectively, in a model formula (see Details for the semantic origin of these names and how they can be changed). Conversely, antisymmetry is characterized by <code class="reqn">v_{ij}=v_i-v_j=-v_{ji}</code> and is represented by the <code>antisym</code> formula term.  
</p>
<p>If individual-level random effects of the form (1|ID1)+ (1|ID2) were included in the model formula instead of <code>ranGCA(1|ID1+ID2)</code> for symmetric additive interactions, this would result in different variances being fitted for each random effect (breaking the assumption of symmetry), and the value of the random effect would differ for an individual whether it appears as a level of the first random effect or of the second (which is also inconsistent with the idea that the random effect represents a property of the individual). 
</p>
<p>When <code>ranGCA</code> or <code>antisym</code> random effects are fitted, the individual effects are inferred. By contrast, when a <code>diallel</code> random effect is fitted, an autocorrelated random effect <code class="reqn">v_{ij}</code> is inferred for each <b>unordered</b> pair (no individual effect is inferred), with correlation <code class="reqn">\rho</code> between levels for pairs sharing one individual. This correlation parameter is fitted and is constrained by <code class="reqn">\rho &lt; 0.5</code> (see Details). <code>ranGCA</code> is equivalent to the case <code class="reqn">\rho= 0.5</code>. <code>diallel</code> fits can be slow for large data if the correlation matrix is large, as this matrix can have a fair proportion of nonzero elements. 
There may also be identifiability issues for variance parameters: in a LMM as shown in the examples, there will be three parameters for the random variation (<code>phi</code>, <code>lambda</code> and <code>rho</code>) but only two can be estimated if only one observation is made for each dyad.  
</p>





<h3>Usage</h3>

<pre><code class='language-R'>## formula terms:

# ranGCA(1| &lt;.&gt; + &lt;.&gt;) 
# antisym(1| &lt;.&gt; + &lt;.&gt;) 
# diallel(1|  &lt;.&gt; + &lt;.&gt;, tpar, fixed = NULL, public = NULL)

## where the &lt;.&gt; are two factor identifiers, ** whose levels
## must be identical when representing the same individual **

## corrFamily constructors:
ranGCA() # no argument
antisym() # no argument
diallel(tpar, fixed = NULL, public = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diallel_+3A_tpar">tpar</code></td>
<td>

<p>Numeric: template value of the correlation coefficient for pairs sharing one individual. 
</p>
</td></tr>
<tr><td><code id="diallel_+3A_fixed">fixed</code></td>
<td>

<p>NULL or fixed value of the correlation coefficient.
</p>
</td></tr>
<tr><td><code id="diallel_+3A_public">public</code></td>
<td>
<p>NULL, or an environment. When an empty environment is provided, a template <code>CorNA</code> for the correlation matrix (with NA's in place of <code class="reqn">\rho</code>) will be copied therein, for inspection at user level.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although the symmetric random-effect structures may be used in many different contexts (including social network analysis, or &ldquo;round robin&rdquo; experiments in psychology; another posibly relevant literature keyword here &ldquo;multi membership&rdquo;), their present names refer to the semantics established for diallel experiments (e.g., Lynch &amp; Walsh, 1998, p. 611), because it is not easy to find a more general yet intuitive semantics. If the names <code>ranGCA</code> and <code>diallel</code> sound inappropriate for your context of application, you can declare and use an alternative name for them, taking advantage of the fact that they are random-effect structures defined through <code><a href="#topic+corrFamily">corrFamily</a></code> constructors, which are functions named as the formula term. For example, <code>symAdd(1|ID1+ID2)</code> can be used in a model formula after the following two steps:<br />
</p>
<pre>
# Define the 'symAdd' corrFamily constructor (a function) by copy:
symAdd &lt;- ranGCA     
# Associate the 'symAdd' function to 'symAdd' formula terms:
register_cF("symAdd")  
</pre>
<p>In diallel experiments, one analyzes the phenotypes of offspring from multiple crosses among which the mother in a cross can be the father in another, so this is an example of multiple-membership. The additive genetic effects of each parent's genotypes are described as &ldquo;general combining abilities&rdquo; (GCA). In case of non-additive effect, the half-sib covariance is not half the full-sib covariance and this is represented by the interaction <code class="reqn">a_{ij}</code> described as &ldquo;specific combining abilities&rdquo; (SCA). The sum of GCA and SCA defines a synthetic random effect &ldquo;received&rdquo; by the offspring, with distinct levels for each unordered parental pair, and with correlation <code class="reqn">\rho</code> between effects received by half-sibs (one shared parent). <code class="reqn">\rho</code> corresponds to var(GCA)/[2*var(GCA)+var(SCA)] and is necessarily <code class="reqn">\le 0.5</code>. 
</p>
<p>See the <code><a href="#topic+X.GCA">X.GCA</a></code> documentation for similar constructs for fixed effects.
</p>


<h3>Value</h3>

<p>The functions return corrFamily descriptors whose general format is described in <code><a href="#topic+corrFamily">corrFamily</a></code>. The ones produced by <code>ranGCA</code> and <code>antisym</code> are atypical in that only their <code>Af</code> element is non-trivial.
</p>


<h3>References</h3>

<p>Lynch, M., Walsh, B. (1998) Genetics and analysis of quantitative traits. Sinauer, Sunderland, Mass.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Simulate dyadic data

set.seed(123)
nind &lt;- 10       # Beware data grow as O(nind^2)
x &lt;- runif(nind^2) 
id12 &lt;- expand.grid(id1=seq(nind),id2=seq(nind))
id1 &lt;- id12$id1
id2 &lt;- id12$id2
u &lt;-  rnorm(nind,mean = 0, sd=0.5)

## additive individual effects:
y &lt;-  0.1 + 1*x + u[id1] +  u[id2] + rnorm(nind^2,sd=0.2)

## Same with non-additive individual effects:
dist.u &lt;- abs(u[id1] -  u[id2])
z &lt;- 0.1 + 1*x + dist.u + rnorm(nind^2,sd=0.2)

## anti-smmetric individual effects:
t &lt;-  0.1 + 1*x + u[id1] - u[id2] + rnorm(nind^2,sd=0.2)

dyaddf &lt;- data.frame(x=x, y=y, z=z, t=t, id1=id1,id2=id2)
# : note that this contains two rows per dyad, which avoids identifiability issues.

# Enforce that interactions are between distinct individuals (not essential for the fit):
dyaddf &lt;- dyaddf[- seq.int(1L,nind^2,nind+1L),] 


# Fits:

(addfit &lt;- fitme(y ~x +ranGCA(1|id1+id2), data=dyaddf))
#
# practically equivalent to:
#
(fitme(y ~x +diallel(1|id1+id2, fixed=0.49999), data=dyaddf))

(antifit &lt;- fitme(t ~x +antisym(1|id1+id2), data=dyaddf))

(distfit &lt;- fitme(z ~x +diallel(1|id1+id2), data=dyaddf)) 
     
</code></pre>

<hr>
<h2 id='div_info'>
Information about numerical problems
</h2><span id='topic+div_info'></span><span id='topic+diagnose_conv'></span>

<h3>Description</h3>

<p>This experimental function displays information about parameter values for which some numerical problems have occurred. Some warnings suggest its use.
</p>
<p>Numerical problems may occur if the information matrix (for the augmented linear model used in the iteratively reweighted least-squares algorithm) is nearly singular. <span class="pkg">spaMM</span> may try to check whether such singularity occurs when this algorithm has not converged. But itself may be slow so it is not performed systematically for large matrices. <code>spaMM.options(diagnose_conv=&lt;integer&gt;)</code> may be used to control the maximum size of matrices for which the check is performed.
</p>
<p>When &ldquo;outer&rdquo; generic optimization is performed, information is reported about the range of parameter values for which problems occurred, (see Value). The fit object <code>divinfo</code> element may also contain more informative tables of parameter values. This information is currently missing for &ldquo;inner&rdquo;-optimized parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>div_info(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="div_info_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="div_info_+3A_...">...</code></td>
<td>
<p>Currently not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Used mainly for the side effects (printed output) but returns invisibly either a single parameter vector (if a single numerical problem occurred) or a matrix of parameter ranges, or NULL if there is no problem to report.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Tragically ;-), no simple example of numerical problems 
# that can be diagnosed by div_info() is currently available.
</code></pre>

<hr>
<h2 id='DoF'>
Degrees of freedom extractor
</h2><span id='topic+DoF'></span>

<h3>Description</h3>

<p>This extracts the number of degrees of freedom for a model, in the usual sense for likelihood-ratio tests: a count of number of fitted parameters, distinguishing different classes of parameters (see Value).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DoF(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DoF_+3A_object">object</code></td>
<td>

<p>A fitted-model object, of class <code>"HLfit"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output distinguishes counts of random-effect vs residual-dispersion parameters, following the conceptual distinction between effects that induce correlations between different levels of the resonse vs. observation-level effects. However, a residual-dispersion component can be declared as a random effect, so that the counts for logically equivalent models may differ according to the way a model was declared. For example if residual dispersion for an LLM is declared as an observation-level random effect while <code>phi</code> is fixed, the <code>p_lambda</code> component will include 1 df for what would otherwise be accounted by the <code>p_rdisp</code> component. A more involved case where the same contrast happens is when a negative-binomial model (with a residual-dispersion <code>shape</code> parameter) is declared as a Poisson-gamma mixture model (with a varaince parameter for the Gamma-distributed individual-level random effect).    
</p>


<h3>Value</h3>

<p>A vector with possible elements <code>p_fixef</code>, <code>p_lambda</code>, <code>p_corrPars</code> and <code>p_rdisp</code> for, respectively, the number of fixed-effect coefficients of the main-response model, the number of random-effect variance parameters, the number of random-effect correlation parameters, and the number of residual dispersion parameters (the latter being itself, for a mixed-effect residual-dispersion model, the sum of such components).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+df.residual.HLfit">df.residual.HLfit</a></code>; <code><a href="#topic+get_any_IC">get_any_IC</a></code> for extracting effective degrees of freedom considered in the model-selection literature; <code><a href="#topic+as_LMLT">as_LMLT</a></code> for access to the effective degrees of freedom considered in Satterthwaite's test and its extentions.
</p>

<hr>
<h2 id='dofuture'>
Interface for parallel computations
</h2><span id='topic+dofuture'></span>

<h3>Description</h3>

<p>interface to apply some function <code>fn</code> in parallel on columns of a matrix. It is not logically restricted to mixed-effect applications, hence it can be used more widely. Depending on the <code>nb_cores</code> argument, parallel or serial computation is performed, calling the <code>future.apply::future_apply</code> function. A socket cluster is used by default for parallel computations, but a fork cluster can be requested on linux and alike operating systems by using argument <code>cluster_args=list(type="FORK")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dofuture(newresp, fn, nb_cores=NULL, fit_env, control=list(), 
      cluster_args=NULL, debug.=FALSE, iseed=NULL, 
      showpbar="ignored", pretest_cores="ignored",
      ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dofuture_+3A_newresp">newresp</code></td>
<td>

<p>A matrix on whose columns <code>fn</code> will be applied (e.g., as used internally in <span class="pkg">spaMM</span>, the return value of a <code>simulate.HLfit()</code> call); or an integer, then converted to a trivial matrix <code>matrix(seq(newresp),ncol=newresp,nrow=1)</code>.
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_fn">fn</code></td>
<td>

<p>Function whose first argument is named <code>y</code>. The function will be applied for <code>y</code> taken to be each column of <code>newresp</code>.
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_nb_cores">nb_cores</code></td>
<td>

<p>Integer. Number of cores to use for parallel computations. If &gt;1, a cluster of <code>nb_cores</code> nodes is used. Otherwise, no parallel computation is performed.
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_fit_env">fit_env</code></td>
<td>

<p>(for socket clusters only:)  An environment, or a list, containing variables to be exported on the nodes of the cluster (by <code>parallel::clusterExport</code>).
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_control">control</code></td>
<td>

<p>A list. The only effective control is <code>.combine="rbind"</code> (mimicking the <code>foreach</code> syntax used in the alternative interface <code><a href="#topic+dopar">dopar</a></code>). 
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_cluster_args">cluster_args</code></td>
<td>

<p>A list of arguments passed to <code>parallel::makeCluster</code> or <code>parallel::makeForkCluster</code>. E.g., <code>outfile="log.txt"</code> may be useful to collect output from the nodes, and <code>type="FORK"</code> to force a fork cluster on linux(-alikes).
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_debug.">debug.</code></td>
<td>

<p>(for socket clusters only:)   For debugging purposes. Effect, if any, is to be defined by the <code>fn</code> as provided by the user.
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_iseed">iseed</code></td>
<td>

<p>Integer, or NULL. If an integer, it is used to initialize <code>"L'Ecuyer-CMRG"</code> random-number generator (<code>iseed</code> argument of <code><a href="parallel.html#topic+clusterSetRNGStream">clusterSetRNGStream</a></code>), with identical effect across different models of parallelisation. If <code>iseed</code> is <code>NULL</code>, the seed is not controlled. 
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_showpbar">showpbar</code>, <code id="dofuture_+3A_pretest_cores">pretest_cores</code></td>
<td>

<p>Currently ignored; for consistency with <code>dopar</code> formal arguments.
</p>
</td></tr>
<tr><td><code id="dofuture_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed (unevaluated) to <code>future.apply</code> (and then possibly to <code>fn</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>future.apply</code>.  If the <code>progressr</code> package is loaded, a side-effect of <code>dofuture</code> is to show a progress bar with character 'S' or 'P' or 'F' depending on parallelisation status (serial/socket/fork).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dopar">dopar</a></code> for an alternative implementation of (essentially) the same functionalities, and <code><a href="#topic+wrap_parallel">wrap_parallel</a></code> for its differences from <code>dofuture</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
if (requireNamespace("future.apply", quietly = TRUE)) {

 # Useless function, but requiring some argument beyond the first
 foo &lt;- function(y, somearg, ...) {
   if ( is.null(somearg) || TRUE ) length(y)
 }

 # Whether FORK can be used depends on OS and whether Rstudio is used:
   dofuture(matrix(1,ncol=4,nrow=3), foo, fit_env=list(), somearg=NULL, 
     nb_cores=2, cluster_args=list(type="FORK"))
}

## End(Not run)
</code></pre>

<hr>
<h2 id='dopar'>
Interface for parallel computations
</h2><span id='topic+dopar'></span><span id='topic+combinepar'></span>

<h3>Description</h3>

<p><code>dopar</code> and <code>combinepar</code> are interfaces primarily designed to apply some function <code>fn</code> in parallel on columns of a matrix, although other uses are possible. Depending on the <code>nb_cores</code> argument, parallel or serial computation is performed. A socket cluster is used by default for parallel computations, but a fork cluster can be requested on linux and alike operating systems by using argument <code>cluster_args=list(type="FORK")</code>.
</p>
<p><code>dopar</code> has been designed to provide by default a progress bar in all evaluations contexts. A drawback is that different procedures are called depending e.g. on the type of cluster, with different possible controls. In particular, <code>foreach</code> is called in some cases but not others, so non-trivial values of its <code>.combine</code> control are not always enforced. The alternative interface <code>combinepar</code> will always use <code>foreach</code>, and will still try to provide by default a progress bar but may fail to do so in some cases (see Details).     
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dopar(newresp, fn, nb_cores = NULL, 
      fit_env, control = list(), cluster_args = NULL, 
      debug. = FALSE, iseed = NULL, 
      showpbar = eval(spaMM.getOption("barstyle")), 
      pretest_cores =NULL, ...)
combinepar(newresp, fn, nb_cores = NULL, cluster=NULL,
      fit_env, control = list(), cluster_args = NULL, 
      debug. = FALSE, iseed = NULL, 
      showpbar = eval(spaMM.getOption("barstyle")), 
      pretest_cores =NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dopar_+3A_newresp">newresp</code></td>
<td>

<p>A matrix on whose columns <code>fn</code> will be applied (e.g., as used internally in <span class="pkg">spaMM</span>, the return value of a <code>simulate.HLfit()</code> call); or an integer, then converted to a trivial matrix <code>matrix(seq(newresp),ncol=newresp,nrow=1)</code>.
</p>
</td></tr>
<tr><td><code id="dopar_+3A_fn">fn</code></td>
<td>

<p>Function whose first argument is named <code>y</code>. The function will be applied for <code>y</code> taken to be each column of <code>newresp</code>.
</p>
</td></tr>
<tr><td><code id="dopar_+3A_nb_cores">nb_cores</code></td>
<td>

<p>Integer. Number of cores to use for parallel computations. If &gt;1 (and no cluster is provided by the <code>cluster</code> argument), a cluster of <code>nb_cores</code> nodes is created, used, and stopped on completion of the computation. Otherwise, no parallel computation is performed.
</p>
</td></tr>
<tr><td><code id="dopar_+3A_cluster">cluster</code></td>
<td>

<p>(for <code>combinepar</code> only): a cluster object (as returned by <code>parallel::makeCluster</code> or <code>parallel::makeForkCluster</code>). If this is used, the <code>nb_cores</code> and <code>cluster_args</code> arguments are ignored. The cluster is not stopped  on completion of the computation
</p>
</td></tr>
<tr><td><code id="dopar_+3A_fit_env">fit_env</code></td>
<td>

<p>(for socket clusters only:)  An environment, or a list, containing variables to be exported on the nodes of the cluster (by <code>parallel::clusterExport</code>); e.g., <code>list(bar=bar)</code> to pass object <code>bar</code> to each node. The argument <code>control(.errorhandling = "pass")</code>, below, is useful to find out missing variables.
</p>
</td></tr>
<tr><td><code id="dopar_+3A_control">control</code></td>
<td>

<p>A list following the <code>foreach</code> control syntax, even if <code>foreach</code> is not used. There are limitations when <code>dopar</code> (but not <code>combinepar</code>) is used, in all but the first case below:
</p>

<ol>
<li><p> for socket clusters, with <code>doSNOW</code> attached, <code>foreach</code> is called with default arguments including
<code>i = 1:ncol(newresp), .combine = "cbind", .inorder = TRUE, .errorhandling = "remove", .packages = "spaMM"</code>.
<code>control</code> may be used to provide non-default values of these arguments. For example, <code>.errorhandling = "pass"</code> is useful to get error messages from the nodes, and therefore <b>strongly recommended</b> when first experimenting with this function. 
</p>
</li>
<li><p> for socket clusters, with <code>doSNOW</code> <b>not</b> attached, <code>dopar</code> calls <code>pbapply</code> instead of <code>foreach</code> but <code>control$.packages</code> is still handled. The  result is still in the format returned by <code>foreach</code> with default <code>.combine="cbind"</code> or possible non-default <code>.combine="rbind"</code>. <code>pbapply</code> arguments may be passed through the ... argument. 
</p>
</li>
<li><p> if a fork cluster is used, <code>dopar</code> calls <code>mclapply</code> instead of <code>foreach</code>. <code>control$mc.silent</code> can be used to control the <code>mc.silent</code> argument of <code><a href="parallel.html#topic+mclapply">mclapply</a></code>.
</p>
</li>
<li><p> (if <code>nb_cores=1</code> <code>dopar</code> calls <code>mclapply</code>).
</p>
</li></ol>

</td></tr>
<tr><td><code id="dopar_+3A_cluster_args">cluster_args</code></td>
<td>

<p>A list of arguments passed to <code>parallel::makeCluster</code>. E.g., <code>outfile="log.txt"</code> may be useful to collect output from the nodes, and <code>type="FORK"</code> to force a fork cluster on linux(-alikes).
</p>
</td></tr>
<tr><td><code id="dopar_+3A_debug.">debug.</code></td>
<td>

<p>(for socket clusters only:)   For debugging purposes. Effect, if any, is to be defined by the <code>fn</code> as provided by the user.
</p>
</td></tr>
<tr><td><code id="dopar_+3A_iseed">iseed</code></td>
<td>

<p>(all parallel contexts:) Integer, or NULL. If an integer, it is used as the <code>iseed</code> argument of <code><a href="parallel.html#topic+clusterSetRNGStream">clusterSetRNGStream</a></code> to initialize <code>"L'Ecuyer-CMRG"</code> random-number generator (see Details). If <code>iseed</code> is <code>NULL</code>, the default generator is selected on each node, where its seed is not controlled. 
</p>
</td></tr>
<tr><td><code id="dopar_+3A_showpbar">showpbar</code></td>
<td>

<p>(for socket clusters only:) Controls display of progress bar. See <code><a href="#topic+barstyle">barstyle</a></code> option for details.
</p>
</td></tr>
<tr><td><code id="dopar_+3A_pretest_cores">pretest_cores</code></td>
<td>

<p>(for socket clusters only:) A function to run on the cores before running <code>fn</code>. It may be used to check that all arguments of the <code>fn</code> can be evaluated in the cores' environments (the internal function <code>.pretest_fn_on_cores</code> provides an example).   
</p>
</td></tr>
<tr><td><code id="dopar_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed (unevaluated) to <code>fn</code>, if not caught on the way by <code>pbapply</code> (which means that different results may in principle be obtained depending on the mode of parallelisation, which is the kind of design issues that <code>combinepar</code> aims to resolve by always calling <code>foreach</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Control of random numbers through the <code>"L'Ecuyer-CMRG"</code> generator and the <code>iseed</code> argument is not sufficient for consistent results when the <code>doSNOW</code> parallel backend is used, so if you really need such control in a <code>fn</code> using random numbers, do not use <code>doSNOW</code>. Yet, it is fine to use <code>doSNOW</code> for bootstrap procedures in spaMM, because the fitting functions do not use random numbers: only sample simulation uses them, and it is not performed in parallel.

</p>
<p><code>combinepar</code> calls <code>foreach::%dopar%</code> which assumes that a cluster has been declared using a suitable backend such as <code>doSNOW</code>, <code>doFuture</code> or <code>doParallel</code>. If only the latter is available, no progress bar is displayed. A method to render a bar when <code>doParallel</code> is used can be found on the Web, but that bar is not a valid progress bar as it is displayed only after all the processes have been run.     
</p>


<h3>Value</h3>

<p>The result of calling <code>foreach</code>, <code>pbapply</code> or <code>mclapply</code>, as dependent on the <code>control</code> argument and the interface used. A side-effect of either interface is to show a progress bar whose character informs about the type of parallelisation performed: a <code>"F"</code> or default <code>"="</code> character for fork clusters, a <code>"P"</code> for parallel computation via <code>foreach</code> and <code>doSNOW</code>, a <code>"p"</code> for parallel computation via <code>foreach</code> and <code>doFuture</code> or via <code>pbapply</code>, and <code>"s"</code> for serial computation <code>foreach</code> and <code>doParallel</code> or via <code>pbapply</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dofuture">dofuture</a></code> is yet another interface with (essentially) the same functionalities as <code>dopar</code>. See the documentation of the <code><a href="#topic+wrap_parallel">wrap_parallel</a></code> option for its differences from <code>dopar</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See source code of spaMM_boot()

## Not run: 
# Useless function, but requiring some argument beyond the first
foo &lt;- function(y, somearg, ...) {
  if ( is.null(somearg) || TRUE ) length(y)
}

# Whether FORK can be used depends on OS and whether Rstudio is used:
dopar(matrix(1,ncol=4,nrow=3), foo, fit_env=list(), somearg=NULL, 
  nb_cores=2, cluster_args=list(type="FORK"))

## End(Not run)


</code></pre>

<hr>
<h2 id='drop1.HLfit'>
Drop all possible single fixed-effect terms from a model
</h2><span id='topic+drop1'></span><span id='topic+drop1.HLfit'></span><span id='topic+drop1.LMLT'></span>

<h3>Description</h3>

<p>Drop single terms from the model. The <code>drop1</code> method for <span class="pkg">spaMM</span> fit objects is conceived to replicate the functionality, output format and details of pre-existing methods for similar models. Results for LMs and GLMs should replicate base R <code>drop1</code> results, with some exceptions:<br />
* somewhat stricter default check of non-default <code>scope</code> argument;<br />
* Because the dispersion estimates for Gamma GLMs differ between <code>stats::glm</code> and <span class="pkg">spaMM</span> fits (see Details in <code><a href="#topic+method">method</a></code>), some tests may differ too; results from <span class="pkg">spaMM</span> REML fits being closer than ML fits to those from <code>glm()</code> fits;<br /> 
* AIC values reported in tables are always the marginal AIC as computed by <code>AIC.HLfit</code>, while <code>drop1.glm</code> may report confusing (to me, at least) values (see <code><a href="#topic+AIC.HLfit">AIC.HLfit</a></code>) for reasons that seem to go beyond differences in dispersion estimates.
</p>
<p><b>For LMMs</b>, ANOVA tables are provided by interfacing <code>lmerTest::anova</code> (with non-default <code>type</code>).
</p>
<p>For other classes of models, a table of likelihood ratio tests is returned, each test resulting from a call to <code><a href="#topic+LRT">LRT</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
drop1(object, scope, method="", check_marg=NULL, check_time=60, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drop1.HLfit_+3A_object">object</code></td>
<td>
<p>Fit object returned by a <span class="pkg">spaMM</span> fitting function.</p>
</td></tr>
<tr><td><code id="drop1.HLfit_+3A_scope">scope</code></td>
<td>

<p>Default &ldquo;scope&rdquo; (terms to be tested, specified as a formula, see Examples) is determined by applying <code>stats::drop.scope</code> on fixed-effect terms.
Non-default scope can be specified a formula giving the terms to be considered for dropping. It is also possible to specify them as a character vector, but then one has to make sure that the elements are consistent with term labels produced by <code>terms</code>, as inconsistent elements will be ignored.
</p>
</td></tr>
<tr><td><code id="drop1.HLfit_+3A_method">method</code></td>
<td>

<p>Only non-default value is <code>"LRT"</code> which forces evaluation of a likelihood ratio tests by <code><a href="#topic+LRT">LRT</a></code>, instead of specific methods for specific classes of models.
</p>
</td></tr> 
<tr><td><code id="drop1.HLfit_+3A_check_marg">check_marg</code></td>
<td>

<p>NULL or boolean: whether effects should be checked for marginality. By default, this check is performed when a non-default scope is specified, and then no test is reported for terms that do not satisfy the marginality condition. If <code>check_marg=FALSE</code>, marginality is not checked and tests are always performed.
</p>
</td></tr> 
<tr><td><code id="drop1.HLfit_+3A_check_time">check_time</code></td>
<td>

<p>numeric: whether to output some information when the execution time of <code>drop1</code> may be of the order of the time specified by <code>check_time</code>, or more. This is checked only when random effect are present. Such output can thus be suppressed by <code>check_time=Inf</code>.
</p>
</td></tr> 
<tr><td><code id="drop1.HLfit_+3A_...">...</code></td>
<td>
<p>Further arguments passed from or to methods, or to <code>LRT</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As for the ANOVA-table functionality, it has been included here mainly to provide access to F tests (including, for LMMs, the &ldquo;Satterthwaite method&rdquo;, using pre-existing procedures as template or backend for expediency and familiarity. The procedures for specific classes of models have various limitations, e.g., none of them handle models with variable dispersion parameter. For classes of models not well handled by these procedures (by design or due to the experimental nature of the recent implementation), <code>method="LRT"</code> can still be applied (and will be applied by default for GLMMs). 
</p>


<h3>Value</h3>

<p>The return format is that of the function called (<code>lmerTest::drop1</code> for LMMs), or emulated (base <code>drop1</code> methods for LMs or GLMs), or is a data frame whose rows are each the result of calling <code>LRT</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as_LMLT">as_LMLT</a></code> for the interface to <code>lmerTest::drop1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
#### GLM

wfit &lt;- fitme(y ~ X1+X2+X1*X3+X2*X3+I(X2^2),  family=Gamma(log), data=wafers)
drop1(wfit, test = "F")              
drop1(wfit, test = "F", scope= ~ X1 +  X1 * X3 )  # note the message!

#### LMM
if(requireNamespace("lmerTest", quietly=TRUE)) {
  lmmfit &lt;- fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch),data=wafers)
  drop1(lmmfit) # =&gt; Satterthwaite method here giving p-values quite close to 
                #    traditional t-tests given by:
  summary(lmmfit, details=list(p_value=TRUE)) 
}

#### GLMM 
wfit &lt;- fitme(y ~ X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), family=Gamma(log),
              rand.family=inverse.Gamma(log), resid.model = ~ X3+I(X3^2) , data=wafers)
drop1(wfit)              
drop1(wfit, scope= ~ X1 +  X1 * X3 )  # note the message!
</code></pre>

<hr>
<h2 id='eval_replicate'>
Evaluating bootstrap replicates
</h2><span id='topic+eval_replicate'></span><span id='topic+.eval_replicate2'></span>

<h3>Description</h3>

<p><code>eval_replicate</code> is the default <code>simuland</code> function applied to simulated bootstrap samples by likelihood-ratio testing functions (<code>fixedLRT, LRT, anove.HLfit</code>). This documentation presents the requirements and possible features of this function and of possible user-defined alternatives. 
</p>
<p>An alternative function <code>spaMM:::.eval_replicate2</code> is also provided. It is slower, as it refits the models compared with different initial values for random-effect parameters, which is useful in some difficult cases where initial values matter. The <code>eval_replicate</code> function may also refit the &ldquo;full&rdquo; models with different initial values when the logLik of the refitted full model is substantially lower than that of the refitted null model. &ldquo;Substantially&rdquo; means that a tolerance of <code>1e-04</code> is applied to account for inaccuracies of numerical maximization. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval_replicate(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval_replicate_+3A_y">y</code></td>
<td>

<p>a response vector on which a previously fitted model may be refitted.   
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>likelihood-ratio testing functions have a <code>debug.</code> argument whose effect depends on the <code>simuland</code> function. The default behaviour is thus defined by <code>eval_replicate</code>, as: if <code>debug.=TRUE</code>, upon error in the fitting procedures, <code>dump.frames</code> will be called, in which case <b>a dump file will be written on disk</b>; and a <b>list</b> with debugging information will be returned (so that, say, <code>pbapply</code> will not return a matrix). This behaviour may change in later versions, so non-default <code>debug.</code> values should not be used in reproducible code. In serial computation, <code>debug.=2</code> may induce a <code>stop</code>; this should not happen in parallel computation because the calling functions check against <code>debug.==2</code>.
</p>
<p>Essential information such as the originally fitted models is passed to the function not as arguments but through its environment, which is controlled by the calling functions (see the <code>eval_replicate</code> source code to know which are these arguments). Users should thus not assume that they can control their own <code>simuland</code> function's environment as this environment will be altered.
</p>
<p>Advanced users can define their own <code>simuland</code> function. The <code>eval_replicate</code> source code provides a template showing how to use the function's environment. The Example below illustrates another approach augmenting <code>eval_replicate</code>. A further example is provided in the file<br /> 
<code>tests/testthat/test-LRT-boot.R</code>, using ... to pass additional arguments beyond response values. 
</p>


<h3>Value</h3>

 
<p>A vector of the form <code>c(full=logLik(</code>&lt;refitted full model&gt;<code>),null=logLik(</code>&lt;refitted null model&gt;<code>)</code>; or possibly in debugging contexts, a list with the same elements each with some additional information provided as attribute.
</p>


<h3>See Also</h3>

<p>Calling functions <code><a href="#topic+fixedLRT">fixedLRT</a>, <a href="#topic+LRT">LRT</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simple wrapper enhancing the default 'simuland'
#  with a call to some obscure option, and dealing with 
#  the need to pass the environment assigned to 'simuland'
eval_with_opt &lt;- function(y) { 
  spaMM.options(some_obscure_option="some_obscure_value")
  eval_rep &lt;- spaMM:::.eval_replicate
  environment(eval_rep) &lt;- parent.env(environment()) # passing the environment
  eval_rep(y)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='external-libraries'>
Installing external libraries
</h2><span id='topic+external-libraries'></span>

<h3>Description</h3>

<p>spaMM is conceived to minimize installation issues but it nevertheless suggests using some external libraries. These are all accessed through R packages so their installation should be easy when installing binary packages.  The Details below give hints for installing packages from source. They may all be obsolete if you are using the Rtools42 on Windows. For all cases not considered below, help yourself. If you are using the Rtools40 on Windows, you should have a look at the package manager in the Rtools40 bash shell.
</p>


<h3>Details</h3>

<p>The <code>ROI.plugin.glpk</code> package requires the <code>Rglpk</code> package, which itself requires the external <code>glpk</code> library. For the latter, Debian-ists and alikes should <code>sudo apt-get install libglpk-dev</code>. MacOSX users should <code>brew install glpk</code> if using <code>brew</code>;  Windows users should try using<br />
<code>pacman -S mingw-w64-x86_64-glpk</code> in the Rtools40 bash shell, together with<br />
<code>Sys.setenv(GLPK_HOME = "$(MINGW_PREFIX)")</code> in the R session (but I have not fully tested this; previously I had to install glpk from <a href="https://sourceforge.net/projects/winglpk/">https://sourceforge.net/projects/winglpk/</a>).
</p>
<p>The <code>nloptr</code> package requires the external <code>NLopt</code> library. Windows users should try using<br />
<code>pacman -S mingw-w64-x86_64-nlopt</code> in the Rtools40 bash shell (but again I have not fully tested this; see also the README of <code>nloptr</code>). 

To install nloptr 2.0.0 from sources on Debian one may have to install libnlopt-dev: <code>sudo apt-get install libnlopt-dev</code>
Likewise for gmp one may need to install <code>libgmp3-dev</code>.
</p>

<hr>
<h2 id='extractors'>
Functions to extract various components of a fit.
</h2><span id='topic+model.frame.HLfit'></span><span id='topic+model.matrix.HLfit'></span><span id='topic+extractors'></span><span id='topic+getDistMat'></span><span id='topic+logLik'></span><span id='topic+logLik.HLfit'></span><span id='topic+fitted'></span><span id='topic+fitted.HLfit'></span><span id='topic+fixef'></span><span id='topic+fixef.HLfit'></span><span id='topic+formula'></span><span id='topic+formula.HLfit'></span><span id='topic+family'></span><span id='topic+family.HLfit'></span><span id='topic+terms'></span><span id='topic+terms.HLfit'></span><span id='topic+nobs'></span><span id='topic+nobs.HLfit'></span><span id='topic+ranef'></span><span id='topic+ranef.HLfit'></span><span id='topic+print.ranef'></span><span id='topic+deviance'></span><span id='topic+deviance.HLfit'></span><span id='topic+response'></span><span id='topic+dev_resids'></span><span id='topic+df.residual'></span><span id='topic+df.residual.HLfit'></span><span id='topic+weights'></span><span id='topic+weights.HLfit'></span>

<h3>Description</h3>

<p>Most extractors are methods of generic functions defined in base R (see Usage), for which the base documentation may be useful.
</p>
<p><code>formula</code> extracts the model formula.<br />
<code>family</code> extracts the response family.<br />
<code>terms</code> extracts the formula, with attributes describing the <b>fixed-effect</b> terms.<br /> 
<code>nobs</code> returns the length of the response vector.<br />
<code>logLik</code> extracts the log-likelihood (exact or approximated).<br />
<code>dev_resids</code> returns a vector of squared (unscaled) deviance residuals (the summands defined for GLMs in McCullagh and Nelder 1989, p. 34; see Details of <code><a href="#topic+LL-family">LL-family</a></code> for other response families. <br />
<code>deviance</code> returns the sum of squares of these deviance residuals, possibly weighted by prior weights (consistently with <code>stats::deviance</code>. See <code><a href="#topic+residuals.HLfit">residuals.HLfit</a></code> for details and comparison with related extractors.<br />
<code>fitted</code> extracts fitted values.<br />
<code>response</code> extracts the response (as a vector).<br />
<code>fixef</code> extracts the fixed effects coefficients, <code class="reqn">\beta</code>.<br />
<code>ranef</code> extracts the predicted random effects, <b>Lv</b> (default since version 1.12.0), or optionally <b>u</b> (see <code><a href="#topic+random-effects">random-effects</a></code> for definitions). <code>print.ranef</code> controls their printing. <br />
<code>getDistMat</code> returns a distance matrix for a geostatistical (Matérn etc.) random effect.<br />
<code>df.residual</code> extracts residual degrees-of-freedom for fitted models (here number of observations minus number of parameters of the model except residual dispersion parameters).
<code>wweights</code> extracts prior weights (as defined by the fitting functions's <code>prior.weights</code> argument).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
formula(x, which="hyper", ...)
## S3 method for class 'HLfit'
family(object, ...)
## S3 method for class 'HLfit'
terms(x, ...)
## S3 method for class 'HLfit'
nobs(object, ...)
## S3 method for class 'HLfit'
logLik(object, which, ...)
## S3 method for class 'HLfit'
fitted(object, ...)
## S3 method for class 'HLfit'
fixef(object, na.rm=NULL, ...)
## S3 method for class 'HLfit'
ranef(object, type = "correlated", ...)
## S3 method for class 'ranef'
print(x, max.print = 40L, ...)
## S3 method for class 'HLfit'
deviance(object, ...)
## S3 method for class 'HLfit'
df.residual(object, ...)
## S3 method for class 'HLfit'
weights(object, type, ...)
##
getDistMat(object, scaled=FALSE, which = 1L)
response(object,...)
dev_resids(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractors_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="extractors_+3A_type">type</code></td>
<td>
<p>For <code>ranef</code>, use <code>type="correlated"</code> (default) to display the correlated random effects (<b>Lv</b>), whether in a spatial model, or a random- coefficient model. Use <code>type="uncorrelated"</code> to pretty-print the elements of the <code>&lt;object&gt;$ranef</code> vector (<b>u</b>).<br />
For <code>weights</code>, either <code>"prior"</code> or <code>"working"</code>, with the same meaning as for <code><a href="stats.html#topic+weights.glm">weights.glm</a></code>: respectively the prior weights, or the weights used in the final iteration of the IRLS algorithm.
</p>
</td></tr>
<tr><td><code id="extractors_+3A_which">which</code></td>
<td>
<p>* For <code>logLik</code>, the name of the element of the <code>APHLs</code> list to return (see Details for any further possibility). The default depends on the fitting method. In particular, if it was REML or one of its variants, the default is to return the log restricted likelihood (exact or approximated).<br />
* For <code>getDistMat</code>, an integer, to select a random effect from several for which a distance matrix may be constructed.<br />
* For <code>formula</code>, by default the model formula with non-expanded <code>multIMRF</code> random-effect terms is returned, while for <code>which=""</code> a formula with <code>multIMRF</code> terms expanded as <code>IMRF</code> terms is returned.</p>
</td></tr>
<tr><td><code id="extractors_+3A_na.rm">na.rm</code></td>
<td>
<p>Whether to include NA values for missing coefficients of rank-deficient model matrices. Default is to exclude them for mixed models and to include them for other ones. See Details for the underlying reason.</p>
</td></tr>
<tr><td><code id="extractors_+3A_scaled">scaled</code></td>
<td>
<p>If <code>FALSE</code>, the function ignores the scale parameter <code class="reqn">\rho</code> and returns unscaled distance.</p>
</td></tr>
<tr><td><code id="extractors_+3A_x">x</code></td>
<td>
<p>For <code>print.ranef</code>: the return value of <code>ranef.HLfit</code>.</p>
</td></tr>
<tr><td><code id="extractors_+3A_max.print">max.print</code></td>
<td>
<p>Controls <code>options("max.print")</code> locally.</p>
</td></tr>
<tr><td><code id="extractors_+3A_...">...</code></td>
<td>
<p>Other arguments that may be needed by some method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For rank-deficient model matrices, base R procedures <code>lm</code> and <code>glm</code> estimate coefficients for a rank-trimmed matrix and <code>coefficient()</code> returns a full-length vector completed with NA values for coefficients not estimated, while the <span class="pkg">lme4</span> <code>fixef</code> method returns a trimmed vector. <span class="pkg">spaMM</span> has long followed the base R convention for all models but this may impede use of some post-fit procedures initially conceived for <span class="pkg">lme4</span> objects (such as <span class="pkg">lmerTest</span> procedures for LMMs). So now <code>fixef.HLfit</code> trims the vector by default for mixed-effect models only. The default is thus to maximize consistency/compatibility with preexisting procedures despite their inconsistencies with each other.</p>


<h3>Value</h3>

<p><code>formula</code> returns a <code>formula</code>, except a list of them from <code>fitmv()</code> output.
</p>
<p><code>terms</code> returns an object of class <code>c("terms", "formula")</code> which contains the <em>terms</em> representation of a symbolic model.  See <code><a href="stats.html#topic+terms.object">terms.object</a></code> for its structure. <code>terms(&lt;fitmv() result&gt;)</code> returns a list of such terms.
</p>
<p>Other return values are numeric (for <code>logLik</code>), vectors (most cases), matrices or dist objects (for <code>getDistMat</code>), or a family object (for <code>family</code>). <code>ranef</code> returns a list of vectors or matrices (the latter for random-coefficient terms). 
</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder J. A. (1989) Generalized linear models. Second ed. Chapman &amp; Hall: London.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+summary.HLfit">summary.HLfit</a></code> whose return value include the tables of fixed-effects coefficients and random-effect variances displayed by the summary, <code><a href="#topic+residuals.HLfit">residuals.HLfit</a></code> to extract various residuals, <code><a href="#topic+residVar">residVar</a></code> to extract residual variances or information about residual variance models, <code><a href="#topic+hatvalues">hatvalues</a></code> to extract leverages, <code><a href="#topic+get_matrix">get_matrix</a></code> to extract the model matrix and derived matrices, and <code><a href="#topic+vcov.HLfit">vcov.HLfit</a></code> to extract covariances matrices from a fit, <code><a href="#topic+get_RLRsim_args">get_RLRsim_args</a></code> to extract arguments for (notably) tests of random effects in LMMs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
m1 &lt;- fitme(y ~ X1+X2+(1|batch), data=wafers)
fixef(m1)
ranef(m1)

data("blackcap")
fitobject &lt;- fitme(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap,
                       fixed=list(nu=4,rho=0.4,phi=0.05))
getDistMat(fitobject)

</code></pre>

<hr>
<h2 id='extreme_eig'>
Utilities for regularization of a matrix
</h2><span id='topic+extreme_eig'></span><span id='topic+regularize'></span>

<h3>Description</h3>

<p><code>regularize</code> can be used to regularize (nearly-)singular correlation matrices. It may also be used to  regularize covariance matrices but will not keep their diagonal constant. Use on other types of matrices may give nonsense. The regularization corrects the diagonal of matrices with high condition number so that the condition number of a corrected matrix is the maximum value specified by <code>maxcondnum</code>. For that purpose, it needs the extreme eigenvalues of the matrix, by default provided by the function <code>extreme_eig</code>. Calls functions from <span class="pkg">RSpectra</span> if available, and falls back on base functions otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extreme_eig(M, symmetric, required = TRUE)
regularize(A, EEV=extreme_eig(A,symmetric=TRUE), maxcondnum=1e12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extreme_eig_+3A_m">M</code></td>
<td>

<p>Square matrix. Sparse matrices of class <code>d[s|g]CMatrix</code> (and some others too) are handled (some vagueness, as if it fails for some matrix types, an alternative function shoudl be easy to define based on this one as template.
</p>
</td></tr>
<tr><td><code id="extreme_eig_+3A_a">A</code></td>
<td>

<p>Square matrix as <code>M</code>, assumed symmetric. 
</p>
</td></tr>
<tr><td><code id="extreme_eig_+3A_symmetric">symmetric</code></td>
<td>

<p>Whether the matrix is symmetric. Helpful to select efficient methods for this case if the matrix class does not implies its symmetry.
</p>
</td></tr>
<tr><td><code id="extreme_eig_+3A_required">required</code></td>
<td>

<p>Whether the computation should be attempted independently of the size of the matrix.
</p>
</td></tr>
<tr><td><code id="extreme_eig_+3A_eev">EEV</code></td>
<td>
<p> Two extreme eigenvalue in the return format of <code>extreme_eig</code>
</p>
</td></tr>
<tr><td><code id="extreme_eig_+3A_maxcondnum">maxcondnum</code></td>
<td>
<p> Target condition number when regularization is performed</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>extreme_eig</code> returns a vector of length 2, the largest and the smallest eigenvalues in this order.
<code>regularize</code> returns a matrix, possibly in sparse format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>H10 &lt;- Matrix::Hilbert(10)
extreme_eig(H10,symmetric=TRUE) # ratio &gt; 1e13
rH10 &lt;- regularize(H10)
extreme_eig(rH10,symmetric=TRUE)  # ratio = 1e12
</code></pre>

<hr>
<h2 id='fitme'>
Fitting function for fixed- and mixed-effect models with GLM response. 
</h2><span id='topic+fitme'></span>

<h3>Description</h3>

<p>This is a common interface for fitting most models that spaMM can fit, from linear models to mixed models with non-gaussian random effects, therefore substituting to <code>corrHLfit</code>, <code>HLCor</code> and <code>HLfit</code>. By default, it uses ML rather than REML (differing in this respect from the other fitting functions). It may use &ldquo;outer optimization&rdquo;, i.e., generic optimization methods for estimating all dispersion parameters, rather than the iterative methods implemented in <code>HLfit</code>. The results of REML fits of non-gaussian mixed models by these different methods may (generally slightly) differ. Outer optimization should generally be faster than the alternative algorithms for large data sets when the residual variance model is a single constant term (no structured dispersion). For mixed models, <code>fitme</code> by default tries to select the fastest method when both can be applied, but precise decision criteria are subject to change in the future. <code>corrHLfit</code> (with non-default arguments to control the optimization method most suitable to a particular problem) may be used to ensure better consistency over successive versions of <code>spaMM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitme(formula, data, family = gaussian(), init = list(), fixed = list(), 
      lower = list(), upper = list(), resid.model = ~1, init.HLfit = list(), 
      control = list(), control.dist = list(), method = "ML", 
      HLmethod = method, processed = NULL, nb_cores = NULL, objective = NULL, 
      weights.form = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitme_+3A_formula">formula</code></td>
<td>

<p>Either a linear model <code><a href="#topic+formula">formula</a></code> (as handled  by various fitting functions) or a <code>predictor</code>, i.e. a formula with attributes (see <code><a href="#topic+Predictor">Predictor</a></code> and examples below). See Details in <code><a href="#topic+spaMM">spaMM</a></code> for allowed terms in the formula.
</p>
</td></tr>
<tr><td><code id="fitme_+3A_data">data</code></td>
<td>

<p>A data frame containing the variables in the response and the model formula.
</p>
</td></tr>
<tr><td><code id="fitme_+3A_family">family</code></td>
<td>

<p>Either a response <code><a href="#topic+family">family</a></code> or a <code><a href="#topic+multi">multi</a></code> value. 
</p>
</td></tr>
<tr><td><code id="fitme_+3A_init">init</code></td>
<td>

<p>An optional list of initial values for correlation and/or dispersion parameters and/or response family parameters, e.g. 
<code>list(rho=1,nu=1,lambda=1,phi=1)</code> where <code>rho</code> and <code>nu</code> are parameters of the Matérn family (see <code><a href="#topic+Matern">Matern</a></code>), and 
<code>lambda</code> and <code>phi</code> are dispersion parameters (see Details in <code><a href="#topic+spaMM">spaMM</a></code> for the meaning of these parameters). 
All are optional, but giving values for a dispersion parameter changes the ways it is estimated (see Details and Examples).
<code>rho</code>  may be a vector (see <code><a href="#topic+make_scaled_dist">make_scaled_dist</a></code>) and, in that case, it is possible that some or all of its elements are <code>NA</code>, for which <code>fitme</code> substitutes automatically determined values.  
</p>
</td></tr>
<tr><td><code id="fitme_+3A_fixed">fixed</code></td>
<td>

<p>A list similar to <code>init</code>, but specifying fixed values of the parameters not estimated. See <code><a href="#topic+fixed">fixed</a></code> for further information; and keep in mind that fixed fixed-effect coefficients can be passed as the <code>etaFix</code> argument as part of the &lsquo;...&rsquo;.
</p>
</td></tr>
<tr><td><code id="fitme_+3A_lower">lower</code></td>
<td>

<p>An optional (sub)list of values of the parameters specified through <code>init</code>, in the same format as  <code>init</code>, used as lower values in calls to <code>optim</code>. See Details for default values.
</p>
</td></tr>
<tr><td><code id="fitme_+3A_upper">upper</code></td>
<td>
<p>Same as <code>lower</code>, but for upper values.</p>
</td></tr>
<tr><td><code id="fitme_+3A_resid.model">resid.model</code></td>
<td>
<p> See identically named <code><a href="#topic+HLfit">HLfit</a></code> argument. </p>
</td></tr>
<tr><td><code id="fitme_+3A_init.hlfit">init.HLfit</code></td>
<td>
<p> See identically named <code><a href="#topic+HLfit">HLfit</a></code> argument. </p>
</td></tr>
<tr><td><code id="fitme_+3A_control.dist">control.dist</code></td>
<td>
<p> See <code>control.dist</code> in <code><a href="#topic+HLCor">HLCor</a></code> </p>
</td></tr>
<tr><td><code id="fitme_+3A_method">method</code>, <code id="fitme_+3A_hlmethod">HLmethod</code></td>
<td>
<p>Character: the fitting method to be used, such as <code>"ML"</code>, <code>"REML"</code> or <code>"PQL/L"</code>. <code>"ML"</code> is the default, in contrast to <code>"REML"</code> for <code>HLfit</code>, <code>HLCor</code> and <code>corrHLfit</code>. Other possible values of <code>HLfit</code>'s <code><a href="#topic+method">method</a></code> argument are handled. <code>method=c(&lt;"ML" or "REML"&gt;,"exp")</code> can be distinctly useful for slow fits of models with <code>Gamma(log)</code> response family (see <code><a href="#topic+method">method</a></code>). 
</p>
</td></tr>
<tr><td><code id="fitme_+3A_weights.form">weights.form</code></td>
<td>

<p>Specification of prior weights by a one-sided formula: use <code>weights.form = ~ pw</code> instead of <code>prior.weights = pw</code>. The effect will be the same except that such an argument, known to evaluate to an object of class <code>"formula"</code>, is suitable to enforce safe programming practices (see <code><a href="#topic+good-practice">good-practice</a></code>).  
</p>
</td></tr>
<tr><td><code id="fitme_+3A_control">control</code></td>
<td>
<p>   A list of (rarely needed) control parameters, with possible elements: 
</p>

<ul>
<li> <p><code>refit</code>, a boolean, or a <code>list</code> of booleans with possible elements <code>phi</code>, <code>lambda</code> and <code>ranCoefs</code>. If either element is set to TRUE, then the corresponding parameters are refitted by the internal <code>HLfit</code> methods (see Details), unless these methods were already selected for such parameters in the main fitting step. If <code>refit</code> is a single boolean, it affects all parameters. By default no parameter is refitted. 
</p>
</li>
<li> <p><code>optimizer</code>, the numerical optimizer, specified as a string and whose default is controlled by the global <span class="pkg">spaMM</span> option <code>"optimizer"</code>. Possible values are <code>"nloptr"</code>, <code>"bobyqa"</code>, <code>"L-BFGS-B"</code> and <code>".safe_opt"</code>, whose meanings are detailed in the documentation for the <code>optimizer</code> argument of <code><a href="#topic+spaMM.options">spaMM.options</a></code>. Better left unchanged unless suspect fits are obtained. 
</p>
</li>
<li> <p><code>nloptr</code>, itself a list of control parameters to be copied in the <code>opts</code> argument of <code><a href="nloptr.html#topic+nloptr">nloptr</a></code>. Default value is given by <code>spaMM.getOption('nloptr')</code> and possibly other global <span class="pkg">spaMM</span> options. Better left unchanged unless you are ready to inspect source code.
</p>
</li>
<li> <p><code>bobyqa, optim</code>, lists of controls similar to <code>nloptr</code> but for methods <code>"bobyqa"</code> and <code>"L-BFGS-B"</code>, respectively.
</p>
</li></ul>
   
</td></tr>
<tr><td><code id="fitme_+3A_nb_cores">nb_cores</code></td>
<td>
<p> For development purpose, not documented.</p>
</td></tr> 
<tr><td><code id="fitme_+3A_processed">processed</code></td>
<td>
<p> For programming purpose, not documented.</p>
</td></tr>
<tr><td><code id="fitme_+3A_objective">objective</code></td>
<td>
<p> For development purpose, not documented.</p>
</td></tr>
<tr><td><code id="fitme_+3A_...">...</code></td>
<td>

<p>Optional arguments passed to (or operating as if passed to) <code><a href="#topic+HLCor">HLCor</a></code>, <code><a href="#topic+HLfit">HLfit</a></code> or  <code><a href="#topic+mat_sqrt">mat_sqrt</a></code>, for example <code>rand.family</code>, <code>control.HLfit</code> , <code>verbose</code> or the <code>distMatrix</code> argument of <code>HLCor</code> (so that estimation of Matern or Cauchy parameters can be combined with use of an ad hoc distance matrix). In a <code>fitme</code> call, the <code>verbose</code> vector of booleans may include a <code>TRACE=TRUE</code> element, in which case information is displayed for each set of correlation and dispersion parameter values considered by the optimiser (see <code><a href="#topic+verbose">verbose</a></code> for further information, mostly useless except for development purposes). 


</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For approximations of likelihood, see <code><a href="#topic+method">method</a></code>. For the possible structures of random effects, see <code><a href="#topic+random-effects">random-effects</a></code>,
</p>
<p>For <code>phi</code>, <code>lambda</code>, and <code>ranCoefs</code>, <code>fitme</code> may or may not use the internal fitting methods of <code>HLfit</code>. The latter methods are well suited for structured dispersion models, but require computations which can be slow for large datasets. Therefore, <code>fitme</code> tends to outer-optimize by default for large datasets, unless there is a non-trivial <code>resid.model</code>. The precise criteria for selection of default method by <code>fitme</code> are liable to future changes. 
</p>
<p>Further, the internal fitting methods of <code>HLfit</code> also provide some more information such as the &ldquo;cond. SE&rdquo; (about which see warning in Details of <code><a href="#topic+HLfit">HLfit</a></code>). To force the evaluation of such information after an outer-optimization by a <code>fitme</code> call, use the <code>control$refit</code> argument (see Example). Alternatively (and possibly of limited use), one can force inner-optimization of <code>lambda</code> for a given random effect, or of <code>phi</code>, by setting it to <code>NaN</code> in <code>init</code> (see Example using &lsquo;blackcap&rsquo; data). The same syntax may be tried for <code>phi</code>.
</p>


<h3>Value</h3>

<p>The return value of an <code>HLCor</code> or an <code>HLfit</code> call, with additional attributes. The <code>HLCor</code> call is evaluated at the estimated correlation parameter values. These values are included in the return object as its <code>$corrPars</code> member. The attributes added by <code>fitme</code> include the original call of the function (which can be retrived by <code>getCall</code>(&lt;fitted object&gt;), and information about the optimization call within <code>fitme</code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examples with Matern correlations
## A likelihood ratio test based on the ML fits of a full and of a null model.
 data("blackcap")
 (fullfit &lt;- fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap) )
 (nullfit &lt;- fitme(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap)) 
 ## p-value:
 1-pchisq(2*(logLik(fullfit)-logLik(nullfit)),df=1)

## See ?spaMM for examples of conditional autoregressive model and of non-spatial models. 

## Contrasting different optimization methods:
# We simulate Gamma deviates with mean mu=3 and variance=2, 
#  ie. phi= var/mu^2= 2/9 in the (mu, phi) parametrization of a Gamma 
#  GLM; and shape=9/2, scale=2/3 in the parametrisation of rgamma().
#  Note that phi is not equivalent to scale: 
#  shape = 1/phi and scale = mu*phi.
set.seed(123)
gr &lt;- data.frame(y=rgamma(100,shape=9/2,scale=2/3))
# Here fitme uses HLfit methods which provide cond. SE for phi by default:
fitme(y~1,data=gr,family=Gamma(log))
# To force outer optimization of phi, use the init argument:
fitme(y~1,data=gr,family=Gamma(log),init=list(phi=1))
# To obtain cond. SE for phi after outer optimization, use the 'refit' control:
fitme(y~1,data=gr,family=Gamma(log),,init=list(phi=1),
      control=list(refit=list(phi=TRUE))) ## or ...refit=TRUE...

## Outer-optimization is not necessarily the best way to find a global maximum, 
#  particularly when there is little statistical information in the data:  
if (spaMM.getOption("example_maxtime")&gt;1.6) {
  data("blackcap")
  fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap) # poor
  #  Compare with the following two ways of avoiding outer-optimization of lambda:
  corrHLfit(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
            method="ML")
  fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap, 
        init=list(lambda=NaN))
}

## see help("COMPoisson"), help("negbin"), help("Loaloa"), etc., for further examples.
</code></pre>

<hr>
<h2 id='fitmv'>
Fitting multivariate responses
</h2><span id='topic+fitmv'></span><span id='topic+X2X'></span>

<h3>Description</h3>

<p>This function extends the <code>fitme</code> function to fit a joint model for different responses (following possibly different response families) sharing some random-effects, including a new type of random effect defined to exhibit correlations across different responses (see <code><a href="#topic+mv">mv</a></code>).
It is also possible to declare shared fixed-effect coefficients among different submodels, using the <code>X2X</code> argument.  
Only a few features available for analysis of univariate response may not yet work (see Details). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitmv(submodels, data, fixed=NULL, init=list(), lower=list(), upper=list(), 
      control=list(), control.dist = list(), method="ML", init.HLfit=list(), 
      X2X=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitmv_+3A_submodels">submodels</code></td>
<td>

<p>A list of sublists each specifying a model for each univariate response. The names given to each submodel in the main list are currently ignored. The names and syntax of elements within each sublist are those of a <code>fitme</code> call. In most cases, each sublist should not contain arguments whose names are those of formal arguments of <code>fitmv</code> itself (with the possible exception for <code>fixed</code>). 
</p>
<p><code>prior.weights</code> (or better, <code>weights.form</code>), if any, should be specified as part of a submodel. 
</p>
</td></tr>
<tr><td><code id="fitmv_+3A_data">data</code></td>
<td>

<p>A data frame containing the variables in the response and the model formulas.
</p>
</td></tr>
<tr><td><code id="fitmv_+3A_fixed">fixed</code></td>
<td>
<p>A list of fixed values of the parameters controlling random effects. The syntax is that of the same argument in <code>fitme</code> (the optional <code>fixed</code> argument in each sublist of <code>submodels</code> may also be used but this feature may be confusing). Fixed <code>phi</code> values must be specified as a list, e.g., <code>fixed=list(phi=list("2"=0.1))</code> to set the value for the second submodel.   
</p>
</td></tr>
<tr><td><code id="fitmv_+3A_init">init</code>, <code id="fitmv_+3A_lower">lower</code>, <code id="fitmv_+3A_upper">upper</code></td>
<td>

<p>Lists of initial values or bounds. The syntax is that of the same arguments in <code>fitme</code>. In these lists, random effects should be indexed according to their order of appearance in the total model (see Details). Any <code>init</code>, <code>lower</code>, or <code>upper</code> in a sublist of <code>submodels</code> will be ignored.   
</p>
</td></tr>
<tr><td><code id="fitmv_+3A_control">control</code></td>
<td>
<p>A list of control parameters, with possible elements as described for <code><a href="#topic+fitme">fitme</a></code></p>
</td></tr> 
<tr><td><code id="fitmv_+3A_control.dist">control.dist</code></td>
<td>
<p> See <code>control.dist</code> in <code><a href="#topic+HLCor">HLCor</a></code> </p>
</td></tr>
<tr><td><code id="fitmv_+3A_method">method</code></td>
<td>
<p>Character: the fitting method to be used, such as <code>"ML"</code>, <code>"REML"</code> or <code>"PQL/L"</code>. <code>"ML"</code> is the default, as for <code>fitme</code> and in contrast to <code>"REML"</code> for the other fitting functions. Other possible values of <code>HLfit</code>'s <code>method</code> argument are handled.
</p>
</td></tr>
<tr><td><code id="fitmv_+3A_init.hlfit">init.HLfit</code></td>
<td>
<p> See identically named <code><a href="#topic+HLfit">HLfit</a></code> argument. </p>
</td></tr>
<tr><td><code id="fitmv_+3A_x2x">X2X</code></td>
<td>
<p> NULL, or a matrix <b>M</b> by which one can specify, as <code class="reqn">\beta=</code><b>M</b><code class="reqn">\beta^*</code>, fixed effects <code class="reqn">\beta</code> with some coefficients shared between submodels, e.g. as shown in the &ldquo;Shared fixed effect&rdquo; Example, where <code class="reqn">\beta^*</code> has three distinct elements, and <code class="reqn">\beta</code> has four elements including identical Intercept coefficients among the two submodels. The fixed-effect term <b>X</b><code class="reqn">\beta</code> of the linear predictor thus takes the form <b>XM</b><code class="reqn">\beta^*</code>, meaning that the default design matrix of the model <b>X</b> is replaced by <b>XM</b>. <b>M</b> must have column names, labeling the <code class="reqn">\beta^*</code> coefficients.</p>
</td></tr>
<tr><td><code id="fitmv_+3A_...">...</code></td>
<td>

<p>Optional arguments passed to (or operating as if passed to) <code><a href="#topic+HLCor">HLCor</a></code>, <code><a href="#topic+HLfit">HLfit</a></code> or  <code><a href="#topic+mat_sqrt">mat_sqrt</a></code>, for example  <code>control.HLfit</code> or the <code>covStruct</code>, <code>distMatrix</code>, <code>corrMatrix</code> or <code>adjMatrix</code> arguments of <code>HLCor</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Matching random effects across submodels, and referring to them</b>;<br />
Random effects are recognized as identical across submodels by matching the formula terms. As shown in the Examples, if the two models formulas share the <code>(1|clinic)</code> term, this term is recognized as a single random effect shared between the two responses. But the <code>(1|clinic)</code> and <code>(+1|clinic)</code> terms are recognized as distinct random effects. In that case, the <code>init</code> argument <code>init=list(lambda=c('1'=1,'2'=0.5))</code> is shown to refer to these by names <code>1,2</code>... where the order is defined as the order of first appearance of the terms across the model formulas in the order of the <code>submodels</code> list. 
Alternatively, the syntax <code>fixed=list(lambda=c('clinic.1'=0.5,'clinic'=1))</code> works: this syntax makes order of input irrelevant but assumes that the user guesses names correctly (these are typically the names that appear in the summary of lambda values from the fit object or, more programmatically, <br />
<code>names(&lt;fit object&gt;$lambda.object$print_namesTerms)</code>). Finally, fixed values of parameters can <b>also</b> be specified through each sub-model, with indices referring to the order of random effects with each model.
</p>
<p>The matching of random-effect terms occurs after expansion of <code><a href="#topic+multIMRF">multIMRF</a></code> terms, if any. This may have subtle consequences if two multIMRF terms differ only by their number of levels, as some of the expanded IMRF terms are then shared. 
</p>
<p><b>Capacities and limitations</b>:<br />
Practically all features of models that can be fitted by <code>fitme</code> should be available: this includes all combinations of GLM response families, residual dispersion models, and all types of random-effect terms, whether autocorrelated or not. Among the arguments handled through the ..., <code>covStruct</code>, <code>distMatrix</code>, <code>corrMatrix</code> should be effective; <code>control.HLfit$LevenbergM</code> and <code>verbose=c(TRACE=TRUE)</code> will work but some other controls available in <code>fitme</code> may not. Usage of the <code><a href="#topic+REMLformula">REMLformula</a></code> argument is restricted as it cannot be used to specify a non-standard REML correction (but the more useful <code><a href="#topic+keepInREML">keepInREML</a></code> attribute for fixed fixed-effect coefficients is handled).
</p>
<p>The <code><a href="#topic+multi">multi</a></code> family-like syntax for multinomial models should not be used, but <code>fitmv</code> could provide other means to model multinomial responses.
</p>
<p>Most post-fit functions work, at least with default arguments. This includes point <code>predict</code>ion and prediction variances calculations sensu lato, including with <code>newdata</code>; but also <code>simulate</code>, <code>spaMM_boot</code>, <code>confint</code>, <code>anova</code>, <code>update_resp</code>, and <code>update</code>. The <code>re.form</code> argument now works for <code>predict</code> and <code>simulate</code>. Bootstrap computation may require special care for models where simulation of one response variable may depend on drawns of another one (see Hurdle model example in the &ldquo;Gentle introdution&rdquo; to <span class="pkg">spaMM</span>,
<a href="https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/spaMMintro.pdf">https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/spaMMintro.pdf</a>).
</p>
<p>Prediction functions try to handle most forms of missing information in <code>newdata</code> (including information missing for a residual-dispersion model when predcitiosn fro mit are needed: see Examples). As information may be missing for some submodels but not others, different numbers of predictions are then returned for different submodels. As for univariate-response models, <code>predict</code> will return point predictions as a single 1-column matrix, here concatenating the prediction results of the different submodels. The <code>nobs</code> attribute specifies how may values pertain to each submodel. 
</p>
<p>Some plotting functions may fail. <code>update.formula</code> fails (see <code><a href="#topic+update_formulas">update_formulas</a></code> for details). <code>terms</code> returns a list, which is not usable by other base R functions. <code>stats::step</code> is a good example of resulting limitations, as it is currently unable to perform any sensible operation on <code>fitmv</code> output. <code>spaMM::MSFDR</code> which calls <code>stats::step</code> likewise fails. 
<code>multcomp::glht</code> fails. 

</p>
<p>A perhaps not entirely satisfying feature is that <code>simulate</code> by default stacks the results of simulating each submodel in a single vector. Some non-trivial reformatting may then be required to include such simulation results in a suitable <code>newdata</code> data frame with (say) sufficient information for prediction of all responses. The syntax <br />
<code>update_resp(&lt;fit&gt;, newresp = simulate(&lt;fit&gt;, ...), evaluate = FALSE)$data</code><br /> 
may be particularly useful to reformat simulation results in this perspective. 
</p>
<p><b>Which arguments belong to <code>submodels</code>?</b>:<br /> 
Overall, arguments specifying individuals submodels should go into <code>submodels</code>, while other arguments of <code>fitmv</code> should be those potentially affecting several submodels (notably, random-effect structures, <code>lower</code>, and <code>upper</code>) and fitting controls (such as <code>init</code> and <code>init.HLfit</code>). One rarely-used exception is <code><a href="#topic+REMLformula">REMLformula</a></code> which controls the fitting method but should be specified through the <code>submodels</code>.    
</p>
<p>The function proceeds by first preprocessing all submodels independently, before merging the resulting information by matching random effects across submodels. The merging operation includes some checks of consistency across submodels, implying that redundant arguments may be needed across submodels (e.g. specifying twice a non-default <code>rand.family</code> for a random effect shared by two submodels). 
</p>



<h3>Value</h3>

<p>A (single) list of class <code>HLfit</code>, as returned by other fitting functions in <span class="pkg">spaMM</span>. The main difference is that it contains a <code>families</code> element describing the response families, instead of the <code>family</code> elements of fitted objects for univariate response.
</p>


<h3>See Also</h3>

<p>See further examples in <code><a href="#topic+mv">mv</a></code> (modelling correlated random effects over the different submodels),
and <code><a href="#topic+residVar">residVar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Data preparation
data(clinics)
climv &lt;- clinics
(fitClinics &lt;- HLfit(cbind(npos,nneg)~treatment+(1|clinic),
                     family=binomial(),data=clinics))
set.seed(123)
climv$np2 &lt;- simulate(fitClinics, type="residual")
#
### fits

#### Shared random effect
(mvfit &lt;- fitmv(
   submodels=list(mod1=list(formula=cbind(npos,nneg)~treatment+(1|clinic),family=binomial()),
                  mod2=list(formula=np2~treatment+(1|clinic),
                            family=poisson(), fixed=list(lambda=c("1"=1)))), 
   data=climv))

# Two univariate-response independent fits because random effect terms are distinct
# (note how two lambda values are set; same syntax for 'init' values):   
(mvfitind &lt;- fitmv(
   submodels=list(mod1=list(formula=cbind(npos,nneg)~treatment+(1|clinic),family=binomial()),
                  mod2=list(formula=np2~treatment+(+1|clinic),family=poisson())), 
   data=climv, fixed=list(lambda=c('1'=1,'2'=0.5)))) # '1': (1|clinic); '2': (+1|clinic)

#### Specifying fixed (but not init) values in submodels is also possible (maybe not a good idea)
# (mvfitfix &lt;- fitmv(
#   submodels=list(mod1=list(formula=cbind(npos,nneg)~treatment+(1|clinic),
#                            family=binomial(),fixed=list(lambda=c('1'=1))), # '1': (1|clinic) 
#                  mod2=list(formula=np2~treatment+(+1|clinic),family=poisson(),
#                            fixed=list(lambda=c('1'=0.5)))),              # '2': (+1|clinic) 
#   data=climv))

#### Shared fixed effect
# Suppose we want to fit the same intercept for the two submodels 
# (there may be cases where this is meaningful, even if not here).
# The original fit has four coefficients corresponding to four columns 
# of fixed-effect design matrix:

head(design_X &lt;- model.matrix(mvfit))
#      (Intercept)_1 treatment_1 (Intercept)_2 treatment_2
# [1,]             1           1             0           0
#      ...

# The three coefficients of the intended model are (say) 
# "(Intercept)" "treatment_1" "treatment_2"
# We build a matrix that relates the original 4 coefficients to these 3 ones:

X_4to3 &lt;- 
  matrix(c(1,0,0,
           0,1,0,
           1,0,0,
           0,0,1), nrow=4, ncol=3, byrow=TRUE,
         dimnames=list(NULL, c("(Intercept)","treatment_1","treatment_2")))
                   
# defined such that design_X %*% X_4to3 will be the design matrix for the intended model, 
# and the single "(Intercept)" coefficient of the three-parameter model will operate as 
# a shared estimate of the "(Intercept)_1" and "(Intercept)_2" coefficients
# of the original 4-coefficients model, as intended. 

# The new fit is obtained by providing the matrix as the 'X2X' argument:

(mvfit3 &lt;- fitmv(
    submodels=list(mod1=list(formula=cbind(npos,nneg)~treatment+(1|clinic),family=binomial()),
                   mod2=list(formula=np2~treatment+(1|clinic),
                             family=poisson(), fixed=list(lambda=c("1"=1)))), 
    X2X = X_4to3,
    data=climv))

# =&gt; the column names of 'X_4to3' are the fixed-effect names in all output.

#### Prediction with a residual-dispersion model
set.seed(123)
beta_dat &lt;- data.frame(y=runif(100),grp=sample(2,100,replace = TRUE), x_het=runif(100),
                       y2=runif(100))
(mvfit &lt;- fitmv(list(list(y ~1+(1|grp), family=beta_resp(), resid.model = ~x_het),
                   list(y2 ~1+(1|grp), family=beta_resp())), 
              data= beta_dat))
              
misspred &lt;- beta_dat[1:3,]
misspred$x_het[1] &lt;- NA # missing info for residual variance of first submodel

## =&gt; prediction missing when this info is needed:
#
length(predict(mvfit, newdata=misspred)) # 6 values: missing info not needed for point predictions
length(get_residVar(mvfit, newdata=misspred)) # 5 values  
length(get_respVar(mvfit, newdata=misspred)) # 5 values
#  Missing info not needed for predVar (**as opposed to respVar**)
length(get_predVar(mvfit, newdata=misspred)) # 6 values
#
# Same logic for interval computations:
#
dim(attr(predict(mvfit, newdata=misspred, intervals="respVar"),"intervals")) # 5,2  
dim(attr(predict(mvfit, newdata=misspred, intervals="predVar"),"intervals")) # 6,2  
#
# Same logic for simulate():
#
length(simulate(mvfit, newdata=misspred)) # 5 as simulation requires residVar


</code></pre>

<hr>
<h2 id='fix_predVar'>
Prediction from models with nearly-singular covariance matrices
</h2><span id='topic+fix_predVar'></span>

<h3>Description</h3>

<p>This explains how to handle a warning occurring in computation of prediction variance, where the user is directed here. 
</p>
<p>For <b>Matern or Cauchy</b> correlation models with vanishing scale factor for distances, a warning may be produced when <code>predict.HLfit</code> (or <code>get_predVar</code>, etc.) is called with non-NULL <code>newdata</code>, because a nearly-singular correlation matrix of the random effect is met. <b>To decide what to do</b> in that case, users should compare the values of <code>get_predVar(.)</code> and <code>get_predVar(., newdata=myfit$data)</code> (see Example below). In the absence of numerical inaccuracies, The two values should be identical, and in the presence of such inaccuracies, the more reliable value is the first one. In really poor cases, the second syntax may yield negative prediction variances. If users deem the inaccuracies too large, they should use <code>control=list(fix_predVar=TRUE)</code> in the next call to <code>predict.HLfit</code> (or <code>get_predVar</code>, etc.) as shown in the Example. The drawback of this control is that the computation may be slower, and might even exceed memory capacity for large problems (some matrix operations being performed with exact rational arithmetic, which is memory-consuming for large matrices). it is also still experimental, in the sense that I fear that bugs (<code>stop</code>) may occur. If the user instead chooses <code>control=list(fix_predVar=FALSE)</code>, the default standard floating-point arithmetic is used, but no warning is issued. 
</p>
<p>For <code>fix_predVar</code> left NULL (the default), standard floating-point arithmetic is also used. But in addition (with exceptions: see Details), the warning keeps being issued, and the (possibly costly) computation of the inverse of the correlation matrix is not stored in the fitted model object, hence is repeated for each new prediction variance computation. This is useful to remind users that something needs to be done, but for programming purposes where repeated warnings may be a nuisance, one can use <code>control=list(fix_predVar=NA)</code> which will issue a warning then perform as <code>control=list(fix_predVar=FALSE)</code>, i.e. store an approximate inverse so the warning is not issued again. Finally, <code>control=list(fix_predVar=NaN)</code> will remove the inverse of the correlation matrix from the fitted model object, and start afresh as if the control was NULL.
</p>


<h3>Details</h3>

<p>Nearly-singular correlation matrices of random effects occur in several contexts. For random-slope models, it commonly occurs that the fitted correlation between the random effects for Intercept and slope is 1 or -1, in which case the correlation matrix between these random effects is singular. This led to quite inaccurate computations of prediction variances in spaMM prior to version 3.1.0, but this problem has been fixed. 
</p>
<p><code>control=list(fix_predVar=NaN)</code> may be more appropriate than <code>control=list(fix_predVar=NULL)</code> when <code>predict.HLfit</code> is called through code that one cannot control. For this reason, spaMM provides another mode of control of the default. It will convert <code>control=list(fix_predVar=NULL)</code> to other values when the call stack has call names matching the patterns given by<br /> 
<code>spaMM.getOption("fix_predVar")</code> (as understood by <code><a href="base.html#topic+grep">grep</a></code>). Thus if <code>spaMM.getOption("fix_predVar")$"NA"=="MSL|bboptim"</code>, the default behaviour is that defined by <code>control=list(fix_predVar=NA)</code> when <code>predict.HLfit</code> is called through <code>Infusion::MSL</code> or <code>blackbox::bboptim</code>. FALSE or TRUE are handled in a similar way.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap")
fitobject &lt;- corrHLfit(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap,
                       ranFix=list(nu=10,rho=0.001)) ## numerically singular C
get_predVar(fitobject,newdata=blackcap[6,]) 
## =&gt; warning =&gt; let us apply the recommended procedure:
get_predVar(fitobject) 
get_predVar(fitobject,newdata=fitobject$data) 
# Negative values again in the second case =&gt; easy decision:
get_predVar(fitobject,newdata=blackcap[1:6,], 
            control=list(fix_predVar=TRUE)) # now it's accurate
            # and the accuracy control is stored in the object:
get_predVar(fitobject,newdata=blackcap[1:6,]) 
# Clean and start afresh:
get_predVar(fitobject,newdata=blackcap[1:6,], 
            control=list(fix_predVar=NaN)) 
</code></pre>

<hr>
<h2 id='fixed'>Fixing some parameters</h2><span id='topic+fixed'></span><span id='topic+ranFix'></span><span id='topic+ranPars'></span><span id='topic+etaFix'></span><span id='topic+ranCoefs'></span><span id='topic+corrPars'></span><span id='topic+keepInREML'></span>

<h3>Description</h3>

<p>The fitting functions allow all parameters to be fixed rather than estimated:<br /> 
* Fixed-effect coefficients can be set by way of the <code>etaFix</code> argument (linear predictor coefficients) for all fitting functions.<br /> 
* Random-effect parameters and the <code>phi</code> parameter of the gaussian and Gamma response families can be set for all fitting function by the <code>fixed</code> argument, or for some fitting functions by an alternative argument with the same effect (see Details for this confusing feature, but using <code>fixed</code> uniformly is simpler).<br />
* The ad-hoc dispersion parameter of some response families (<code>COMPoisson</code>, <code>negbin1</code>, <code>negbin2</code>, <code>beta_resp</code>, <code>betabin</code> and possibly future ones) can be fixed using the ad-hoc argument of such families rather than by <code>fixed</code>.
</p>


<h3>Details</h3>

<p><b>etaFix</b> is a list with single documented element <code>beta</code>, which should be a vector of (a subset of) the coefficients (<code class="reqn">\beta</code>) of the fixed effects, with names as shown in a fit without such given values. If REML is used to fit random effect parameters, then <code>etaFix</code> affects by default the REML correction for estimation of dispersion parameters, which depends only on which <code class="reqn">\beta</code> coefficients are estimated rather than given. This default behaviour will be overridden whenever a non-null <code>REMLformula</code> is provided to the fitting functions (see Example). Alternatively, with a non-NULL <code>etaFix$beta</code>, REML can also be performed as if all <code class="reqn">\beta</code> coefficients were estimated, by adding attribute <code>keepInREML=TRUE</code> to <code>etaFix$beta</code>; in that case the REML computation is by default that implied by the fixed effects in the full model formula, unless a non-default <code>REMLformula</code> is also used.  
</p>
<p>The older equivalent for the <code>fixed</code> argument is <code>ranFix</code> for <code>HLfit</code> and <code>corrHLfit</code>, and <code>ranPars</code> for <code>HLCor</code>. Do not use both one such argument and <code>fixed</code> in a call. This older diversity of names was confusing, but its logic was that <code>ranFix</code> allows one to fix parameters that <code>HLfit</code> and <code>corrHLfit</code> would otherwise estimate, while <code>ranPars</code> can be used to set correlation parameters that <code>HLCor</code> does not estimate but nevertheless requires (e.g., Matérn parameters).
</p>
<p>Theses arguments for fixing random-effect parameters all have a common syntax. They is a list, with the following possible elements, whose nature is further detailed below:<br /> 
* <b>phi</b> (variance of residual error, for gaussian and Gamma HGLMs),<br />
* <b>lambda</b> (random-effect variances, except for random-coefficient terms), <br />
* <b>ranCoefs</b> (random-coefficient parameters),<br /> 
* <b>corrPars</b> (correlation parameters, when handled by the fitting function).<br /> 
* Individual correlation parameters such as <b>rho, nu, Nugget, ARphi</b>... are also possible top-level elements of the list when there is no ambiguity as to which random effect these correlation parameters apply. This syntax was conceived when <code>spaMM</code> handled a single spatial random effect, and it is still convenient when applicable, but it should not be mixed with <code>corrPars</code> element usage. 
</p>
<p><b>phi</b> may be a single value or a vector of the same length as the response vector (the number of rows in the <code>data</code>, once non-informative rows are removed).
</p>
<p><b>lambda</b> may be a single value (if there is a single random effect, or a vector allowing to specify unambiguously variance  values for some random effect(s). It can thus take the form <code>lambda=c(NA,1)</code> or <code>lambda=c("2"=1)</code> (note the name) to assign a value only to the variance of the second of two random effects.
</p>
<p><b>ranCoefs</b> is a <code>list</code> of numeric vectors, each numeric vector specifying the variance and correlation parameters for a random-coefficient term. As for <code>lambda</code>, it may be incomplete, using names to specify the random effect to which the parameters apply. For example, to assign variances values 3 and 7, and correlation value -0.05, to the second random effect in a model formula, one can use <code>ranCoefs=list("2"=c(3,-0.05,7))</code> (note the name). The elements of each vector are variances and correlations, matching those of the printed summary of a fit. The order of these elements must be the order of the <code><a href="base.html#topic+lower.tri">lower.tri</a></code> of a covariance matrix, as shown e.g. by<br />
<code>m2 &lt;- matrix(NA, ncol=2,nrow=2); m2[lower.tri(m2,diag=TRUE)] &lt;- seq(3); m2</code>.<br /> 
<code>fitme</code> accepts partially fixed parameters for a random coefficient term, e.g.,<br /> 
<code>ranCoefs=list("2"=c(NA,-0.05,NA))</code>, although this may not mix well with some obscure options, such as<br /> 
<code>control=list(refit=list(ranCoefs=TRUE))</code> which will ignore the fixed values. 
<code><a href="#topic+GxE">GxE</a></code> shows how to use partially-fixed <code>ranCoefs</code> to fit different variances for different levels of a factor.   
</p>
<p><b>corrPars</b> is a list, and it may also be incomplete, using names to specify the affected random effect as shown for <code>lambda</code> and <code>ranCoefs</code>. For example, <code>ranFix=list(corrPars=list("1"=list(nu=0.5)))</code> makes explicit that <code>nu=0.5</code> applies to the first (<code>"1"</code>) random effect in the model formula. Its elements may be the correlation parameters of the given random effect. For the Matérn model, these are the correlation parameters <code>rho</code> (scale parameter(s)), <code>nu</code> (smoothness parameter), and (optionally) <code>Nugget</code> (see <code><a href="#topic+Matern">Matern</a></code>). The <code>rho</code> parameter can itself be a vector with different values for different geographic coordinates. 
For the <code>adjacency</code> model, the only correlation parameter is a scalar <code>rho</code> (see <code><a href="#topic+adjacency">adjacency</a></code>).
For the <code>AR1</code> model, the only correlation parameter is a scalar <code>ARphi</code> (see <code><a href="#topic+AR1">AR1</a></code>).
Consult the documentation for other types of random effects, such as <code><a href="#topic+Cauchy">Cauchy</a></code> or <code><a href="#topic+IMRF">IMRF</a></code>, for any information missing here. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("wafers")
# Fixing random-coefficient parameters:
fitme(y~X1+(X2|batch), data=wafers, fixed=list(ranCoefs=list("1"=c(2760, -0.1, 1844))))
##  HLfit syntax for the same effect (except that REML is used here)
# HLfit(y~X1+(X2|batch), data=wafers, ranFix=list(ranCoefs=list("1"=c(2760, -0.1, 1844))))


### Fixing coefficients of the linear predictor:
#
## ML fit
#
fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, family=Gamma(log), 
      etaFix=list(beta=c("(Intercept)"=5.61208)))
#      
## REML fit
# Evaluation of restricted likelihood depends on which fixed effects are estimated,
# so simply fixing the coefficients to their REML estimates will not yield 
# the same REML fits, as see by comparing the next two fits:
#
unconstr &lt;- fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, 
                  family=Gamma(log), method="REML")
#  
# Second fit is different from 'unconstr' despite the same fixed-effects:     
naive &lt;- fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, family=Gamma(log), 
               method="REML", etaFix=list(beta=fixef(unconstr)))    
#
# Using REMLformula to obtain the same REML fit as the unconstrained one:
fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, family=Gamma(log), 
      method="REML", etaFix=list(beta=fixef(unconstr)),
      REMLformula=y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch))

data("Loaloa")
# Fixing some Matern correlation parameters, in fitme():
fitme(cbind(npos,ntot-npos) ~ elev1 +Matern(1|longitude+latitude),
             data=Loaloa,family=binomial(),fixed=list(nu=0.5,Nugget=2/7))
# Fixing all mandatory Matern correlation parameters, in HLCor():
HLCor(cbind(npos,ntot-npos) ~ elev1 + Matern(1|longitude+latitude),
             data=Loaloa,family=binomial(),ranPars=list(nu=0.5,rho=0.7))

## End(Not run)
</code></pre>

<hr>
<h2 id='fixedLRT'>
Likelihood ratio test of fixed effects.
</h2><span id='topic+fixedLRT'></span>

<h3>Description</h3>

<p><code>fixedLRT</code> performs a likelihood ratio (LR) test between two models, the &ldquo;full&rdquo; and the &ldquo;null&rdquo; models, 
currently differing only in their fixed effects. Parametric bootstrap p-values can be computed, either using the raw bootstrap distribution of the likelihood ratio, or a bootstrap estimate of the Bartlett correction of the LR statistic.
This function differs from <code>LRT</code> in its arguments (model fits for <code>LRT</code>, versus all arguments required to fit the models for <code>fixedLRT</code>), and in the format of its return value. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixedLRT(null.formula, formula, data, method, HLmethod = method, 
         REMLformula = NULL, boot.repl=0, control="DEPRECATED",
         control.boot="DEPRECATED", fittingFunction, seed=NULL,
         resp_testfn = NULL, weights.form = NULL, ...)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixedLRT_+3A_null.formula">null.formula</code></td>
<td>

<p>Either a <code>formula</code> (as in <code>glm</code>) or a <code>predictor</code> (see <code>Predictor</code>) for the null model.
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_formula">formula</code></td>
<td>

<p>Either a <code>formula</code> or a <code>predictor</code> for the full model.
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_method">method</code></td>
<td>

<p>A method to fit the full and null models. 
See <code><a href="#topic+method">method</a></code> information about such methods. 
The two most meaningful values of <code>method</code> in <code>fixedLRT</code> calls are: 
<code>'ML'</code> for an LRT based on ML fits (generally recommended); and
<code>'PQL/L'</code> for an LRT based on PQL/L fits (recommended for spatial binary data). 
</p>
<p>Also feasible, but more tricky, and not really recommended (see Rousset and Ferdy, 2014), is <code>'REML'</code>. 
This will perform an LRT based on two REML fits of the data, *both* of which use the  
same conditional (or &ldquo;restricted&rdquo;) likelihood of residuals for estimating dispersion parameters <code class="reqn">\lambda</code> and <code class="reqn">\phi</code> (see <code>REMLformula</code> argument). 
Further, REML will not be effective on a given dispersion parameter if a non-trivial init.corrHLfit value is provided for this parameter.  
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_hlmethod">HLmethod</code></td>
<td>

<p>Kept for back-compatibility. Same as <code>method</code>, but may work only for<br /> 
<code>fittingFunction=corrHLfit</code>.
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_remlformula">REMLformula</code></td>
<td>

<p>a formula specifying the fixed effects which design matrix is used in the REML correction 
for the estimation of dispersion parameters, if these are estimated by REML. 
This formula is by default that for the *full* model. 
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_weights.form">weights.form</code></td>
<td>

<p>Specification of prior weights by a one-sided formula: use <code>weights.form = ~ pw</code> instead of <code>prior.weights = pw</code>. The effect will be the same except that such an argument, known to evaluate to an object of class <code>"formula"</code>, is suitable to enforce safe programming practices (see <code><a href="#topic+good-practice">good-practice</a></code>).  
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_boot.repl">boot.repl</code></td>
<td>

<p>the number of bootstrap replicates.
</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_control">control</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_control.boot">control.boot</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_fittingfunction">fittingFunction</code></td>
<td>
<p>Character string giving the function used to fit each model: either <code>"corrHLfit"</code> or <code>"fitme"</code>. Default is <code>"corrHLfit"</code> for small data sets (fewer than 300 observations), and <code>"fitme"</code> otherwise, but this may change in future versions.</p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_seed">seed</code></td>
<td>
<p>Passed to <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code></p>
</td></tr>
<tr><td><code id="fixedLRT_+3A_resp_testfn">resp_testfn</code></td>
<td>
<p>See argument <code>resp_testfn</code> of <code><a href="#topic+spaMM_boot">spaMM_boot</a></code></p>
</td></tr>

<tr><td><code id="fixedLRT_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods; presently, additional arguments passed to fitting functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Comparison of REML fits is a priori not suitable for performing likelihood ratio tests. Nevertheless, it is possible to contrive them for testing purposes (Welham &amp; Thompson 1997). This function generalizes some of Wehlam &amp; Thompson's methods to GLMMs. 
</p>
<p>See Details in <code><a href="#topic+LRT">LRT</a></code> for details of the bootstrap procedures.
</p>


<h3>Value</h3>

<p>An object of class <code>fixedLRT</code>, actually a list with as-yet unstable format, but here with  typical elements (depending on the options)
</p>
<table>
<tr><td><code>fullfit</code></td>
<td>
<p>the HLfit object for the full model;</p>
</td></tr> 
<tr><td><code>nullfit</code></td>
<td>
<p>the HLfit object for the null model;</p>
</td></tr>
<tr><td><code>LRTori</code></td>
<td>
<p>A likelihood ratio chi-square statistic</p>
</td></tr> 
<tr><td><code>LRTprof</code></td>
<td>
<p>Another likelihood ratio chi-square statistic, after a profiling step, if any. </p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the number of degrees of freedom of the test.</p>
</td></tr>
<tr><td><code>trace.info</code></td>
<td>
<p>Information on various steps of the computation.  </p>
</td></tr>
</table>
<p>and, if a bootstrap was performed, the additional elements described in <code><a href="#topic+LRT">LRT</a></code>. 
</p>


<h3>References</h3>

<p>Rousset F., Ferdy, J.-B. (2014) Testing environmental and genetic effects in the presence of spatial autocorrelation. Ecography, 37: 781-790.
<a href="https://doi.org/10.1111/ecog.00566">doi:10.1111/ecog.00566</a>
</p>
<p>Welham, S. J., and Thompson, R. (1997) Likelihood ratio tests for fixed model
terms using residual maximum likelihood, J. R. Stat. Soc. B 59, 701-714.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+LRT">LRT</a></code> for simular tests with a different interface, and perhaps <code><a href="#topic+as_LMLT">as_LMLT</a></code> for access to a different testing approach for LMMs, implemented in <code>lmerTest::contest</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;1.9) {
 data("blackcap")
 ## result comparable to the corrHLfit examples based on blackcap
 fixedLRT(null.formula=migStatus ~ 1 + Matern(1|longitude+latitude),
       formula=migStatus ~ means + Matern(1|longitude+latitude), 
       method='ML',data=blackcap)
}
if (spaMM.getOption("example_maxtime")&gt;156) {
 ## longer version with bootstrap
 fixedLRT(null.formula=migStatus ~ 1 + Matern(1|longitude+latitude),
       formula=migStatus ~ means + Matern(1|longitude+latitude), 
       method='ML',data=blackcap, boot.repl=100, seed=123) 
 }
</code></pre>

<hr>
<h2 id='freight'>Freight dataset</h2><span id='topic+freight'></span><span id='topic+freight'></span>

<h3>Description</h3>

<p>A set of data on airfreight breakage. Data are given on 10 air shipments, each carrying
1000 ampules of some substance. For each shipment, the number of ampules found broken upon arrival, and the number of times the shipments were transferred from one aircraft to another, are recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("freight")
</code></pre>


<h3>Format</h3>

<p>The data frame includes 10 observations on the following variables:
</p>

<dl>
<dt>broken</dt><dd><p>number of ampules found broken upon arrival.</p>
</dd>
<dt>transfers</dt><dd><p>number of times the shipments were transferred from one aircraft to another.</p>
</dd>
<dt>id</dt><dd><p>Shipment identifier.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data set is reported by Kutner et al. (2003) and used by Sellers &amp; Shmueli (2010) to illustrate COMPoisson analyses.
</p>


<h3>References</h3>

<p>Kutner MH, Nachtsheim CJ, Neter J, Li W (2005, p. 35). Applied Linear Regression Models, Fourth Edition. McGraw-Hill.
</p>
<p>Sellers KF, Shmueli G (2010) A Flexible Regression Model for Count Data. Ann. Appl. Stat. 4: 943–961
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see ?COMPoisson for examples
</code></pre>

<hr>
<h2 id='get_cPredVar'>
Estimation of prediction variance with bootstrap correction
</h2><span id='topic+get_cPredVar'></span>

<h3>Description</h3>

<p>This function is similar to <code><a href="#topic+get_predVar">get_predVar</a></code> except that is uses a bootstrap procedure to correct for bias in the evaluation of the prediction variance.     
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_cPredVar(pred_object, newdata, nsim, seed, type = "residual", 
             variances=NULL, nb_cores = NULL, fit_env = NULL,
             sim_object=pred_object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_cPredVar_+3A_pred_object">pred_object</code></td>
<td>
<p>an object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_newdata">newdata</code></td>
<td>
<p>passed to <code><a href="#topic+predict.HLfit">predict.HLfit</a></code> (it thus represents a prediction design, not to be confused with the bootstrap samples)</p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_nsim">nsim</code></td>
<td>
<p>passed to <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code></p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_seed">seed</code></td>
<td>
<p>passed to <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code></p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_type">type</code></td>
<td>
<p>passed to <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code></p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_variances">variances</code></td>
<td>
<p>NULL or list; <code>variances["cov"]</code> will be passed to <code><a href="#topic+predict.HLfit">predict.HLfit</a></code> to control whether a covariance matrix is computed or not. Other elements are currently ignored.</p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_nb_cores">nb_cores</code></td>
<td>
<p>integer: number of cores to use for parallel computation of bootstrap. The default is <code>spaMM.getOption("nb_cores")</code>, and 1 if the latter is NULL. <code>nb_cores=1</code> prevents the use of parallelisation procedures.</p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_fit_env">fit_env</code></td>
<td>
<p>For parallel computations: an environment containing objects to be passed to the cores. They should have the same name in <code>fit_env</code> as in the environment they are passed from.</p>
</td></tr>
<tr><td><code id="get_cPredVar_+3A_sim_object">sim_object</code></td>
<td>
<p>an object of class <code>HLfit</code>, passed to <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code> as its <code>object</code> argument. Simulating from this object must produce response values that can be used as replacement to those of the original fitted <code>pred_object</code>. In standard usage, <code>sim_object=pred_object</code> (the default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The result provided by <code>get_cPredVar</code> is similar to the CMSEP (Conditional Mean Standard Error of Prediction) introduced by Booth and Hobert (1998; &ldquo;B&amp;H&rdquo;). This paper is known for pointing the importance of using conditional variances when they differ from unconditional ones. This is hard to miss in spatial models, where the relevant prediction variance typically depends on the variance of random effects conditional on the data. Thus, the alternative function <code>get_predVar</code> already accounts for this and returns a prediction variance that depends on a joint covariance of fixed-effect estimates and of random effects given the data. 
</p>
<p>B&amp;H also used a conditional bootstrap procedure to correct for some bias. <code>get_cPredVar</code> implements a similar procedure, in contrast to <code>get_predVar</code>. Their conditional bootstrap procedure is not applicable for autocorrelated random effects, and parametric bootstrapping of the residuals of the fitted model (as implied by the default value of argument <code>type</code>) is used instead here. Apart from this difference, the returned value includes exactly the same terms as those discussed by B&amp;H: their &ldquo;naive estimate&rdquo; <code class="reqn">\nu_i</code> and its bootstrap correction <code class="reqn">b_i</code>, their correction <code class="reqn">\beta</code> for uncertainty in fixed-effect coefficients, and their correction <code class="reqn">\sigma^2</code> for uncertainty in dispersion parameters. 
</p>
<p>This use of the bootstrap does not account for uncertainty in correlation parameters &ldquo;outer-optimized&rdquo; by <code>fitme</code> or <code>corrHLfit</code>, because the correlation parameters are fixed when the model is refitted on the bootstrap replicates.  Even if it the correlation parameters where refitted, the full computation would not be sufficient to account for uncertainty in them. To account for uncertainty in correlation parameters, one should rather perform a parametric bootstrap of the full model (typically using <code>spaMM_boot(., type="residual")</code>), which may take much more time.
</p>
<p>The &ldquo;naive estimate&rdquo; <code class="reqn">\nu_i</code> is not generally an estimate of anything uniquely defined by the model parameters: for correlated random effects, it depends on the &ldquo;root&rdquo; of the correlation matrix of the random effects, which is not unique. Thus <code class="reqn">\nu_i</code> is not unique, and may differ for example for equivalent fits by sparse-precision methods vs. other methods. Nevertheless, <code>attr(cpredvar,"info")$naive</code> does recover published values in the Examples below, as they involve no correlation matrix. 
</p>


<h3>Value</h3>

<p>A vector of prediction variances, with an attribute <code>info</code> which is an <b>environment</b> containing variables:
</p>
<table>
<tr><td><code>SEs</code></td>
<td>
<p>the standard errors of the estimates (which are those of the bootstrap replicates)</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>the bias term</p>
</td></tr>
<tr><td><code>maive</code></td>
<td>
<p>B&amp;H's &ldquo;naive&rdquo; <code class="reqn">\nu_i</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Booth, J.G., Hobert, J.P. (1998) Standard errors of prediction in generalized linear mixed models. J. Am. Stat. Assoc. 93: 262-272. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if(requireNamespace("rsae", quietly = TRUE)) {
  # LMM example from Booth &amp; Hobert 1998 JASA
  data("landsat", package = "rsae")
  fitCorn &lt;- fitme(HACorn ~ PixelsCorn + PixelsSoybeans + (1|CountyName),data=landsat[-33,])
  newXandZ &lt;- unique(data.frame(PixelsCorn=landsat$MeanPixelsCorn,
                                PixelsSoybeans=landsat$MeanPixelsSoybeans,
                                CountyName=landsat$CountyName))
  (cpredvar &lt;- get_cPredVar(fitCorn, newdata=newXandZ, nsim=200L, seed=123)) # serial computation
  (cpredvar &lt;- get_cPredVar(fitCorn, newdata=newXandZ, nsim=200L, seed=123, 
        nb_cores=parallel::detectCores(logical=FALSE)-1L, 
        fit_env=list2env(list(newXandZ=newXandZ))))
}

# GLMM example from Booth &amp; Hobert 1998 JASA
data(clinics)
fitClinics &lt;- HLfit(cbind(npos,nneg)~treatment+(1|clinic),family=binomial(),data=clinics)
#
(get_cPredVar(fitClinics, newdata=clinics[1:8,], nsim=200L, seed=123))  # serial computation
(get_cPredVar(fitClinics, newdata=clinics[1:8,], nsim=200L, seed=123, 
      nb_cores=parallel::detectCores(logical=FALSE)-1L, 
      fit_env=list2env(list(clinics=clinics))))

## End(Not run)
</code></pre>

<hr>
<h2 id='get_inits_from_fit'>
Initiate a fit from another fit 
</h2><span id='topic+get_inits_from_fit'></span>

<h3>Description</h3>

<p><code>get_inits_from_fit</code> is an extractor of some fitted values from a fit in a convenient format to initiate a next fit.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_inits_from_fit(from, template = NULL, to_fn = NULL, inner_lambdas=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_inits_from_fit_+3A_from">from</code></td>
<td>

<p>Fit object (inheriting from class <code>"HLfit"</code>) from which fitted values are taken.
</p>
</td></tr>
<tr><td><code id="get_inits_from_fit_+3A_template">template</code></td>
<td>

<p>Another fit object. Usage with a <code>template</code> fit object is suitable for refitting this object using fitted values from the <code>from</code> object as starting values.
</p>
</td></tr>
<tr><td><code id="get_inits_from_fit_+3A_to_fn">to_fn</code></td>
<td>

<p>NULL or character: the name of the function to be used the next fit. If NULL, taken from <code>template</code> (if available), else from <code>from</code>. It is meaningful to provide a <code>to_fn</code> distinct from the function used to fit a <code>template</code>. 
</p>
</td></tr> 
<tr><td><code id="get_inits_from_fit_+3A_inner_lambdas">inner_lambdas</code></td>
<td>
<p> Boolean; 
Whether the output should include estimates of the dispersion parameters estimated by the iterative methods implemented in <code>HLfit</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements 
</p>
<table>
<tr><td><code>init</code>, <code>init.corrHLfit</code></td>
<td>
<p>(depending on the fitting function) giving initial values for outer-optimization;</p>
</td></tr> 
<tr><td><code>init.HLfit</code></td>
<td>
<p>giving initial values for the iterative algorithms in <code>HLfit</code>. It is itself a list with possible elements:
</p>

<dl>
<dt><code>fixef</code></dt><dd><p>for the coefficients of the linear predictor, adjusted to the format of the coefficients of the linear predictor of the <code>template</code> object, if available;</p>
</dd>
<dt><code>ranCoefs</code></dt><dd><p>random-coefficients parameters (if <b>not</b> outer-optimized).</p>
</dd>
</dl>

</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+get_ranPars">get_ranPars</a></code> and <code><a href="#topic+VarCorr">VarCorr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("blackcap")
(corrhlfit &lt;- corrHLfit(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
                        method="ML")) 
inits &lt;- get_inits_from_fit(corrhlfit, to_fn = "fitme")                    
(fitfit &lt;- fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap, 
                  init=inits[["init"]])) 
inits &lt;- get_inits_from_fit(corrhlfit, template = fitfit)                    
fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap, 
      init=inits[["init"]])
# In these examples, inits$init.HLfit is useless 
# as it is ignored when LMMs are fitted by fitme().

## End(Not run)
</code></pre>

<hr>
<h2 id='get_matrix'>
Extract matrices from a fit
</h2><span id='topic+get_matrix'></span><span id='topic+get_ZALMatrix'></span>

<h3>Description</h3>

<p><code>get_matrix</code> is a first attempt at a unified extractor of various matrices from a fit. All augmented matrices follow (Henderson's) block order (upper blocks: X,Z; lower blocks: 0,I).
<code>get_ZALMatrix</code> returns the design matrix for the random effects <code class="reqn">v</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_matrix(object, which="model.matrix", augmented=TRUE, ...)
get_ZALMatrix(object, force_bind=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_matrix_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="get_matrix_+3A_augmented">augmented</code></td>
<td>
<p>Boolean; whether to return a matrix for all model coefficients (augmented matrix for fixed-effects coefficients and random-effect predictions) or a matrix only for fixed effects. Not operative for all <code>which</code> values (currently only for <code>which="left_ginv"</code>).</p>
</td></tr>
<tr><td><code id="get_matrix_+3A_which">which</code></td>
<td>
<p>Which element to extract. For <code>"model.matrix"</code>, the design matrix for fixed effects (similarly to <code>stats::model.matrix</code>); for <code>"ZAL"</code>, the design matrix for random effects (same as <code>get_ZALMatrix()</code>), while  <code>"ZA"</code> and  <code>"L"</code> may return these two factors (detailed in <code><a href="#topic+random-effects">random-effects</a></code>); for <code>"AugX"</code>, the (unweighted) augmented design matrix of the least-square problem; for <code>"hat_matrix"</code>, the projection matrix that gives model predictions from the (augmented) response vector; for <code>"left_ginv"</code>, the pseudo-inverse that gives the model coefficients from the (augmented) response vector. See Details for further definitions and options for functions of the augmented design matrix.</p>
</td></tr>  
<tr><td><code id="get_matrix_+3A_force_bind">force_bind</code></td>
<td>
<p>Boolean; with the non-default value <code>FALSE</code>, the function may return an object of class <code><a href="#topic+ZAXlist">ZAXlist</a></code>, which is poorly documented and for development purposes only. </p>
</td></tr>
<tr><td><code id="get_matrix_+3A_...">...</code></td>
<td>
<p>Other arguments that may be needed in some future versions of <code>spaMM</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(Given the pain that it is to write maths in R documentation files, readers are gently asked to be tolerant about any imperfections of the following).
</p>
<p>Model coefficients estimates of a (weighted) linear model can be written as <b>(X'WX)</b><code class="reqn">^{-1}</code><b>X'Wy</b> where <b>X</b> is the design matrix for fixed effects, <b>W</b> a diagonal weight matrix, and <b>y</b> the response vector. In a linear mixed model, the same expression holds in terms of Henderson's augmented design matrix, of an augmented (still diagonal) weight matrix, and of an augmented response vector. For GLMMs and hierarchical GLMs generally, the solution of each step of the iteratively reweighted least squares algorithm again has the same expression in terms of appropriately defined augmented matrices and vectors.  
</p>
<p><code>get_matrix</code> returns, for given values of the <code>which</code> argument, the following matrices from the model fit:<br /> 
<code>"AugX"</code>: <b>X</b>;<br /> 
<code>"wei_AugX"</code>: <b>WX</b>;<br /> 
<code>"wAugX"</code>: <code class="reqn">\sqrt{}</code>(<b>W</b>)<b>X</b>;<br /> 
<code>"left_ginv"</code>: <b>(X'WX)</b><code class="reqn">^{-1}</code><b>X'W</b> (the name stems from the fact that it is generalized inverse, denoted <b>X</b><code class="reqn">^-</code>, since <b>X</b><b>X</b><code class="reqn">^-</code><b>X</b>=<b>X</b>, and it is a left one, since <b>X</b><code class="reqn">^-</code><b>X</b> is an identity matrix when <b>X</b> has full rank);<br /> 
<code>"hat_matrix"</code>: <b>XX</b><code class="reqn">^-</code>=<b>X </b><b>(X'WX)</b><code class="reqn">^{-1}</code><b>X'W</b>;<br /> 
<code>"fixef_left_ginv"</code>: same as <code>"left_ginv"</code> but for the fixed-effect design matrix only (not to be confused with the corresponding block of <code>"left_ginv"</code>);<br /> 
<code>"beta_v_cov"</code>: joint covariance matrix of estimates/predictions of fixed effect coefficients and random effects. 
</p>


<h3>Value</h3>

<p>A matrix, possibly in <code><a href="Matrix.html#topic+sparseMatrix">sparseMatrix</a></code> format.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcov">vcov</a></code> for the variance-covariance matrix of the fixed-effects coefficients, and <code><a href="#topic+Corr">Corr</a></code> for correlation matrices of random effects.
</p>

<hr>
<h2 id='get_ranPars'>
Operations on lists of parameters
</h2><span id='topic+get_ranPars'></span><span id='topic+get_fittedPars'></span><span id='topic+remove_from_parlist'></span>

<h3>Description</h3>

<p><code><a href="#topic+get_fittedPars">get_fittedPars</a></code> returns estimated parameters. 
</p>
<p><code>get_ranPars</code> returns various subsets of random-effect parameters (correlation or variance parameters), as controlled by its <code>which</code> argument. 
It is one of several extractors for fixed or estimated parameters of  different classes of parameters, for which a quick guide is
</p>
<p><code>get_ranPars</code>: for random-effect parameters, excluding residual dispersion (with a subtlety for <code>corrFamily</code> models: see Details);<br />
<code><a href="#topic+VarCorr">VarCorr</a></code>: alternative extractor for random-effect (co)variance and optionally residual variance, in a data frame format;<br />
<code><a href="#topic+residVar">residVar</a></code>: for residual variance parameters, family dispersion parameters, or information about residual variance models;<br />
<code><a href="#topic+get_residVar">get_residVar</a></code>: alternative extractor of residual variances with different features inherited from <code><a href="#topic+get_predVar">get_predVar</a></code>;<br />
<code><a href="#topic+get_inits_from_fit">get_inits_from_fit</a></code>: extracts estimated parameters from a fit, in a different format from <code>get_fittedPars</code>.<br />
</p>
<p><code>remove_from_parlist</code> removes elements from a list of parameters, and from its <code>type</code> attribute. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_fittedPars(object, partial_rC="rm", phiPars=TRUE)
get_ranPars(object, which=NULL, verbose=TRUE, 
            lambda_names = "Group.Term", ...)
remove_from_parlist(parlist, removand=NULL, rm_names=names(unlist(removand)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ranPars_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_partial_rc">partial_rC</code></td>
<td>
<p>Controls handling of partially-fixed random coefficients. The default as set by <code>"rm"</code> is to remove the fixed values as for other parameters. But alternative option <code>"keep"</code> will keep the fixed value, and <code>NA</code> will replace it by a NA.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_phipars">phiPars</code></td>
<td>
<p>Boolean: whether to include the parameters of any residual-dispersion model for <code class="reqn">phi</code> (se <code><a href="#topic+phi-resid.model">phi-resid.model</a></code>) in the <code>rdisPars</code> element of the returned list.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_which">which</code></td>
<td>
<p>NULL or character string. Use <code>which="corrPars"</code> to get the correlation parameters. Use <code>which="lambda"</code> to get variances. see Details for the meaning of this for heteroscedastic models, and Value for other possible <code>which</code> values.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_...">...</code></td>
<td>
<p>Other arguments that may be needed by some method.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_verbose">verbose</code></td>
<td>
<p>Boolean: Whether to print some notes.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_parlist">parlist</code></td>
<td>
<p>A list of parameters. see Details.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_removand">removand</code></td>
<td>
<p>Optional. A list of parameters to be removed from <code>parlist</code>.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_rm_names">rm_names</code></td>
<td>
<p>Names of parameters to be removed from <code>parlist</code>. Mandatory if <code>removand</code> is not given.</p>
</td></tr>
<tr><td><code id="get_ranPars_+3A_lambda_names">lambda_names</code></td>
<td>
<p>By default the names of the <code>lambda</code> vector are built from the Group (RHS of random effect term of the for (LHS|RHS)) and Term (variable from LHS). By setting a non-default value of <code>lambda_names</code> the names will be integer indices of the random-effect term in the model formula (currently, for <code>which="ranef_var"</code> or NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For heteroscedastic random effects, such as conditional autoregressive models, the variance parameter &ldquo;lambda&rdquo; refers to a common scaling coefficient. For other random-effect models, &ldquo;lambda&rdquo; typically refers to the single variance parameter.
</p>
<p><code>remove_from_parlist</code> is designed to manipulate structured lists of parameters, such as a list with elements <code>phi</code>, <code>lambda</code>, and <code>corrPars</code>, the latter being itself a list structured as the return value of <code>get_ranPars(.,which="corrPars")</code>. <code>parlist</code> may have an attribute <code>type</code>, also with elements <code>phi</code>, <code>lambda</code>, and <code>corrPars</code>... If given, <code>removand</code> must have the same structure (but typically not all the elements of <code>parlist</code>); otherwise, <code>rm_names</code> must have elements which match names of <code>unlist(names(parlist))</code>. 
</p>
<p>If a corrFamily parameter is fixed through the formula term, as in <code>ARp(1|time, p=3, fixed=c(p2=0))</code>, the fixed parameter is not considered a model parameter and <code>get_ranPars</code> will not extract it from the object. However, the parameter will be extracted if it has been fixed through <code>fitme</code>'s <code>fixed</code> argument rather than through the formula term (see example in <code><a href="#topic+ARp">ARp</a></code>).
</p>


<h3>Value</h3>

<p><code>get_fittedPars</code> returns a list of model parameters, with possible elements: <code>beta</code> (fixed-effect coefficients); <code>lambda</code>, <code>phi</code>, <code>ranCoefs</code> and <code>corrPars</code> (same meaning as in <code><a href="#topic+fixed">fixed</a></code> parameters); <code>hyper</code>, for <code><a href="#topic+multIMRF">multIMRF</a></code> models;  
the residual-dispersion parameters <code>beta_prec</code>, <code>NB_shape</code> and <code>COMP_nu</code> when they are single scalars; 
and <code>rdisPars</code> for more complex residual-dispersion parameters. See the specific <code><a href="#topic+resid.model">resid.model</a></code> and <code><a href="#topic+phi-resid.model">phi-resid.model</a></code> documentations for the <code>rdisPars</code> format, dependent on the nature of the residual-dispersion parameter being modelized. Use <code>residVar(., which="fam_parm")</code> to extract the vector of fitted values of the dispersion parameter. 
</p>
<p><code>get_ranPars(.,which="corrPars")</code> returns a (possibly nested) list of correlation parameters (or NULL if there is no such parameter). Top-level elements correspond to the different random effects. The list has a <code>"type"</code> attribute having the same nested-list structure and describing whether and how the parameters where fitted: <code>"fix"</code> means they where fixed, not fitted; <code>"var"</code> means they were fitted by <code>HLfit</code>'s specific algorithms; <code>"outer"</code> means they were fitted by a generic optimization method. 
</p>
<p><code>get_ranPars(.,which="lambda")</code> returns a vector of variance values, one per random effect, including both fixed, &ldquo;outer&rdquo;- and &ldquo;inner&rdquo;-optimized ones. The variances of random-coefficients terms with correlation parameters are not included.
</p>
<p><code>get_ranPars(.,which="outer_lambda")</code> returns only &ldquo;outer&rdquo;-optimized variance parameters, ignoring those fitted by <code>HLfit</code>'s specific algorithms. 
</p>
<p><code>get_ranPars(.,which=NULL)</code> (the default) is not fully defined. It returns a list including the results of <code>which="lambda"</code> and <code>which="corrPars"</code>, but possibly other elements too. 
</p>
<p><code>get_ranPars(.,which="fitted")</code> is designed to provide fitted parameters with respect to which an information matrix is to be calculated (using <span class="pkg">numDeriv</span>. It excludes fixed values, and has no <code>type</code> attribute. 
</p>
<p><code>get_ranPars(. which="ranef_var")</code> (experimental) returns a list with elements
</p>

<dl>
<dt><code>Var</code></dt><dd><p>same as <code>get_ranPars(.,which="lambda")</code></p>
</dd>
<dt><code>lembda_est</code></dt><dd><p>A vector of variance values, one for each level of each random effect</p>
</dd>
<dt><code>outer</code></dt><dd><p>A vector or outer-optimized variance values, as returned by <code>get_ranPars(.,which="outer_lambda")</code></p>
</dd>
<dt>...</dt><dd><p>Other elements, subject to change in later versions.</p>
</dd>
</dl>

<p><code>remove_from_parlist</code> returns a list of model parameters with given elements removed, and likewise for its (optional) <code>type</code> attribute. See Details for context of application.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+get_fittedPars">get_fittedPars</a></code>, <code><a href="#topic+VarCorr">VarCorr</a></code>, <code><a href="#topic+residVar">residVar</a></code>, <code><a href="#topic+get_residVar">get_residVar</a></code>, or <code><a href="#topic+get_inits_from_fit">get_inits_from_fit</a></code> as described in the quick guide above. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
m1 &lt;- HLfit(y ~X1+X2+(1|batch), resid.model = ~ 1, data=wafers, method="ML")
get_ranPars(m1,which="corrPars") # NULL since no correlated random effect     

parlist1 &lt;- list(lambda=1,phi=2,corrPars=list("1"=list(rho=3,nu=4),"2"=list(rho=5)))
parlist2 &lt;- list(lambda=NA,corrPars=list("1"=list(rho=NA))) # values of elements do not matter
remove_from_parlist(parlist1,parlist2) ## same result as:
remove_from_parlist(parlist1,rm_names = names(unlist(parlist2)))
</code></pre>

<hr>
<h2 id='get_RLRsim_args'>
Extractors of arguments for functions from package RLRsim
</h2><span id='topic+get_RLRTSim_args'></span><span id='topic+get_RLRsim_args'></span>

<h3>Description</h3>

<p><code>get_RLRsim_args</code> extracts a list of arguments suitable for a call to <code>RLRsim::RLRTSim()</code> or <code>RLRsim::LRTSim()</code>. These functions use an efficient simulation procedure to compute restricted or marginal likelihood ratio tests, respectively, comparing a fixed-effect model and a mixed-effect model with one random effect. They are notably used to test for the presence of one random effect, although the models compared by marginal likelihood (<code>LRTSim()</code>) may differ both in their random and in their fixed effects (as shown in the Example). The tests are exact for small samples (up to simulation error) for LMMs with no free parameters in the random effect (beyond the variance being tested), so not for time-series or spatial models with estimated correlation parameters. Heteroscedasticity of the residuals or of the random effect variance are also not taken into account by the simulation procedure (see Value field below for an hint why this is so). 
</p>
<p><code>get_RLRTSim_args</code> is the older extractor, originally for <code>RLRsim::RLRTSim()</code> only, now handling also ML fits with a warning (though the possible absence of the <code>nullfit</code> argument will result in an error). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_RLRsim_args(fullfit, nullfit, verbose=TRUE, REML=NA, ...)
get_RLRTSim_args(object, verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_RLRsim_args_+3A_object">object</code>, <code id="get_RLRsim_args_+3A_fullfit">fullfit</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>, for the more complete model to be compared.</p>
</td></tr>
<tr><td><code id="get_RLRsim_args_+3A_nullfit">nullfit</code></td>
<td>
<p>Same for the less complete model; required only for (marginal) LR test, as opposed to restricted LR test.</p>
</td></tr>
<tr><td><code id="get_RLRsim_args_+3A_verbose">verbose</code></td>
<td>
<p>NA or boolean; Whether to display some message or not.</p>
</td></tr>
<tr><td><code id="get_RLRsim_args_+3A_reml">REML</code></td>
<td>
<p>For programming purposes, not documented.</p>
</td></tr>
<tr><td><code id="get_RLRsim_args_+3A_...">...</code></td>
<td>
<p>Additional arguments (currently not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the models compared do not differ in their fixed effects, under the null hypothesis there is a probability mass P for a zero likelihood ratio, and the distribution of p-values can be uniform only on the range (0,1-P). If the fixed effects differ (as handled by <code>RLRsim::LRTSim()</code>), this does not occur.   
</p>


<h3>Value</h3>

<p>A list of arguments for a call to <code>RLRsim::RLRTSim()</code>  or <code>RLRsim::LRTSim()</code>. The main arguments are the design matrix for the fixed effects, and the <b>ZA</b> matrix and <b>L</b> detailed in <code><a href="#topic+random-effects">random-effects</a></code> (here represented by the <code>Z</code> and <code>sqrt.Sigma</code> elements). The models handled by the testing procedure are the ones that are sufficiently characterized by these two matrices. <code>LRTSim</code> additionally requires <code>q</code>, the difference in number of parameters of fixed effects between the models. 
</p>


<h3>Note</h3>

<p>The inconsistent capitalisation of 's' in the function names is consistent with the inconsistencies in the <code>RLRsim</code> package.
</p>


<h3>References</h3>

<p>Crainiceanu, C. and Ruppert, D. (2004) Likelihood ratio tests in
linear mixed models with one variance component, <em>Journal of the Royal
Statistical Society: Series B</em>,<b>66</b>,165&ndash;185.
</p>


<h3>See Also</h3>

<p>The bootstrap procedure in <code><a href="#topic+LRT">LRT</a></code> is more general but slower. It appears to provide results quite similar to those of RLRsim when both are applicable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Derived from example in RLRsim::LRTSim
 set.seed(123)
 dat &lt;- data.frame(g = rep(1:10, e = 10), x = (x&lt;-rnorm(100)), 
                   y = 0.1 * x + rnorm(100))
 m &lt;- fitme(y ~ x + (1|g), data=dat)
 m0 &lt;- fitme(y ~ 1, data=dat) 
 (obs.LRT &lt;- 2*(logLik(m)-logLik(m0)))
 args &lt;- get_RLRsim_args(m,m0)
 sim.LRT &lt;- do.call(RLRsim::LRTSim, args )
 (RLRpval &lt;- (sum(sim.LRT &gt;= obs.LRT) + 1) / (length(sim.LRT) + 1))
 ## comparable test using LRT():
 # (bootpval &lt;- LRT(m,m0, boot.repl = 199L)$rawBootLRT$p_value)

## End(Not run)
</code></pre>

<hr>
<h2 id='good-practice'>Clear and trustworthy formulas and prior weights</h2><span id='topic+good-practice'></span><span id='topic+formula_env'></span>

<h3>Description</h3>

<p>Base fitting functions in R will seek variables in the environment where the <code>formula</code> was defined (i.e., typically in the global environment), if they are not in the <code>data</code>. This increases the memory size of fit objects (as the formula and attached environment are part of such objects). This also easily leads to errors (see example in the discussion of <code><a href="#topic+update.HLfit">update.HLfit</a></code>). Indeed Chambers (2008, p.221), after describing how the environment is defined, comments that &ldquo;Where clear and trustworthy software is a priority, I would personally avoid such tricks. Ideally, all the variables in the model frame should come from an explicit, verifiable data source...&rdquo;. Fitting functions in <span class="pkg">spaMM</span> try to adhere to such a principle, as they assume by default that all variables from the <code>formula</code> should be in the <code>data</code> argument (and then, <b>one never needs to specify &ldquo;<code>data$</code>&rdquo; in the <code>formula</code>.</b>. <span class="pkg">spaMM</span> implements this by default by stripping the formula environment from any variable. It is also possible to assign a given environment to the formula, through the control <code>control.HLfit$formula_env</code>: see Examples. 

</p>
<p>The variables defining the <code>prior.weights</code> should also be in the <code>data</code>. However, the implementation of the <code>prior.weights</code> argument has limitations that can be overcome by using the more recently introduced <code>weights.formula</code> argument of <span class="pkg">spaMM</span> fitting functions (see Examples, where this is also compared  with <code>stats::lm</code>'s handling of its <code>weights</code> argument).  

</p>
<p>However, variables used in other arguments such as <code>ranFix</code> are looked up neither in the data nor in the formula environment, but in the calling environment as usual.
</p>


<h3>References</h3>

<p>Chambers J.M. (2008) Software for data analysis: Programming with R. Springer-Verlag New York
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######  Controlling the formula environment

set.seed(123)
d2 &lt;- data.frame(y = seq(10)/2+rnorm(5)[gl(5,2)], x1 = sample(10), grp=gl(5,2), seq10=seq(10))
# Using only variables in the data: basic usage
# HLfit(y ~ x1 + seq10+(1|grp), data = d2)
# is practically equivalent to
HLfit(y ~ x1 + seq10+(1|grp), data = d2, 
      control.HLfit = list(formula_env=list2env(list(data=d2))))
# 
# The 'formula_env' avoids the need for the 'seq10' variable:
HLfit(y ~ x1 + I(seq_len(nrow(data)))+(1|grp), data = d2, 
      control.HLfit = list(formula_env=list2env(list(data=d2))))
#
# Internal imprementation exploits partial matching of argument names
#  so that this can also be in 'control' if 'control.HLfit' is absent:      
fitme(y ~ x1 + I(seq_len(nrow(data)))+(1|grp), data = d2, 
      control = list(formula_env=list2env(list(data=d2))))
      
####### Prior-weights misery

data("hills", package="MASS")

(fit &lt;- lm(time ~ dist + climb, data = hills, weights=1/dist^2)) 
# same as
(fit &lt;- fitme(time ~ dist + climb, data = hills, prior.weights=1/dist^2, method="REML")) 

# possible calls:
(fit &lt;- fitme(time ~ dist + climb, data = hills, prior.weights=quote(1/dist^2))) 
(fit &lt;- fitme(time ~ dist + climb, data = hills, prior.weights= 1/hills$dist^2)) 
(fit &lt;- fitme(time ~ dist + climb, data = hills, weights.form= ~ 1/dist^2)) 
(fit &lt;- fitme(time ~ dist + climb, data = hills, weights.form= ~ I(1/dist^2))) 

# Also syntactically correct since 'dist' is found in the data:
(fit &lt;- fitme(time ~ dist + climb, data = hills, weights.form= ~ rep(2,length(dist)))) 

#### Programming with prior weights:

## Different ways of passing prior weights to fitme() from another function:

wrap_as_form &lt;- function(weights.form) {
  fitme(time ~ dist + climb, data = hills, weights.form=weights.form) 
}

wrap_as_pw &lt;- function(prior.weights) {
  fitme(time ~ dist + climb, data = hills, prior.weights=prior.weights) 
}

wrap_as_dots &lt;- function(...) {
  fitme(time ~ dist + climb, data = hills,...) 
}


## Similarly for lm:

wrap_lm_as_dots &lt;- function(...) {
  lm(time ~ dist + climb, data = hills, ...) 
}

wrap_lm_as_arg &lt;- function(weights) {
  lm(time ~ dist + climb, data = hills,weights=weights) 
}

## Programming errors with stats::lm():

pw &lt;- rep(1e-6,35) # or even NULL

(fit &lt;- wrap_lm_as_arg(weights=pw)) # catches weights from global envir!
(fit &lt;- lm(time ~ dist + climb, data = hills, weights=pw)) # idem!

(fit &lt;- lm(time ~ dist + climb, data = hills, 
           weights=hills$pw)) # fails silently - no $pw in 'hills'
(fit &lt;- wrap_lm_as_dots(weights=hills$pw)) # idem!
(fit &lt;- wrap_lm_as_arg(weights=hills$pw)) # idem!

## Safer spaMM results:

try(fit &lt;- wrap_as_pw(prior.weights= pw)) # correctly catches problem
try(fit &lt;- wrap_as_dots(prior.weights=hills$pw)) # correctly catches problem
(fit &lt;- wrap_as_dots(prior.weights=1/dist^2)) # correct
(fit &lt;- wrap_as_dots(prior.weights=quote(1/dist^2))) # correct

## But 'prior.weights' limitations: 

try(fit &lt;- wrap_as_pw(prior.weights= 1/hills$dist^2)) # fails (stop)
try(fit &lt;- wrap_as_pw(prior.weights= 1/dist^2)) # fails (stop)
try(fit &lt;- wrap_as_pw(prior.weights= quote(1/dist^2))) # fails (stop)

## Problems all solved by using 'weights.form':

try(fit &lt;- wrap_as_form(weights.form= ~ pw)) # correctly catches problem
(fit &lt;- wrap_as_form(weights.form= ~1/dist^2)) # correct
(fit &lt;- wrap_as_form(weights.form= ~1/hills$dist^2)) # correct
(fit &lt;- wrap_as_dots(weights.form= ~ 1/dist^2)) # correct

rm("pw")

      
      
</code></pre>

<hr>
<h2 id='Gryphon'>
Gryphon data
</h2><span id='topic+Gryphon'></span><span id='topic+Gryphon_A'></span><span id='topic+Gryphon_df'></span><span id='topic+Gryphon_pedigree'></span>

<h3>Description</h3>

<p>Loading these data loads three objects describing a mythical 'Gryphon' population used by Wilson et al. to illustrate mixed-effect modelling in quantitative genetics. These objects are a data frame <code>Gryphon_df</code> containing the model variables, a genetic relatedness matrix <code>Gryphon_A</code>, and another data frame <code>Gryphon_pedigree</code> containing pedigree information (which can be used by some packages to reconstruct the relatedness matrix).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Gryphon")</code></pre>


<h3>Format</h3>

<p><code>Gryphon_df</code> is 
</p>
<pre>
'data.frame':	1084 obs. of  6 variables:
 $ ID    : int  1029 1299 ...:               individual identifier 
 $ sex   : Factor w/ 2 levels "1","2":       sex, indeed
 $ year  : Factor w/ 34 levels "968","970", ...: birth year
 $ mother: Factor w/ 429 levels "1","2",..:  individual's mother identifier 
 $ BWT   : num  10.77 9.3  ...:              birth weight 
 $ TARSUS: num  24.8 22.5 12 ...:            tarsus length
</pre>
<p><code>Gryphon_A</code> is a genetic relatedness matrix, in sparse matrix format, for 1309 individuals.
</p>
<p><code>Gryphon_pedigree</code> is 
</p>
<pre>
'data.frame':	1309 obs. of  3 variables:
 $ ID  : int  1306 1304 ...: individual identifier 
 $ Dam : int  NA NA ...:     individual's mother    
 $ Sire: int  NA NA ...:     individual's father
</pre>


<h3>References</h3>

<p>Wilson AJ, et al. (2010) An ecologist's guide to the animal model. Journal of Animal Ecology 79(1): 13-26. 
<a href="https://doi.org/10.1111/j.1365-2656.2009.01639.x">doi:10.1111/j.1365-2656.2009.01639.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Bivariate-response model used as example in Wilson et al. (2010):
# joint modelling of birth weight (BWT) and tarsus length (TARSUS).

# The relatedness matrix is specified as a 'corrMatrix'. The random 
# effect 'corrMatrix(0+mv(1,2)|ID)' then represents genetic effects 
# correlated over traits and individuals (see help("composite-ranef")).
# The ...(0+...) syntax avoids contrasts being used in the design 
# matrix of the random effects, as it would not does make much sense 
# to represent TARSUS as a contrast to BWT. 

# The relatedness matrix will be specified through its inverse,
# using as_precision(), so that spaMM does not have to find out and 
# inform the user that using the inverse is better (as is typically 
# the case for relatedness matrices). But using as_precision() is 
# not required. See help("algebra") for Details.

# The second random effect '(0+mv(1,2)|ID)' represents correlated 
# environmental effects. Since measurements are not repeated within 
# individuals, this effect also absorbs all residual variation. The 
# residual variances 'phi' must then be fixed to some negligible values 
# in order to avoid non-identifiability.

if (spaMM.getOption("example_maxtime")&gt;7) { 
  data("Gryphon")
  gry_prec &lt;- as_precision(Gryphon_A)
  gry_GE &lt;- fitmv(
    submodels=list(BWT ~ 1 + corrMatrix(0+mv(1,2)|ID)+(0+mv(1,2)|ID), 
                  TARSUS ~ 1 + corrMatrix(0+mv(1,2)|ID)+(0+mv(1,2)|ID)), 
    fixed=list(phi=c(1e-6,1e-6)), 
    corrMatrix = gry_prec, 
    data = Gryphon_df, method = "REML")
    
  # Estimates are practically identical to those reported for package 
  # 'asreml' (https://www.vsni.co.uk/software/asreml-r) 
  # according to Supplementary File 3 of Wilson et al., p.7:

  lambda_table &lt;- summary(gry_GE, digits=5,verbose=FALSE)$lambda_table 
  by_spaMM &lt;- na.omit(unlist(lambda_table[,c("Var.","Corr.")]))[1:6]
  by_asreml &lt;- c(3.368449,12.346304,3.849875,17.646017,0.381463,0.401968)
  by_spaMM/by_asreml-1  # relative differences ~ O(1e-4)

}

</code></pre>

<hr>
<h2 id='hatvalues.HLfit'>
Leverage extractor for HLfit objects
</h2><span id='topic+hatvalues'></span><span id='topic+hatvalues.HLfit'></span>

<h3>Description</h3>

<p>This gets &ldquo;leverages&rdquo; or &ldquo;hat values&rdquo; from an object. However, there is hidden complexity in what this may mean, so care must be used in selecting proper arguments for a given use (see Details). To get the full hat matrix, see <code><a href="#topic+get_matrix">get_matrix</a>(., which="hat_matrix")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
hatvalues(model, type = "projection", which = "resid", force=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hatvalues.HLfit_+3A_model">model</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="hatvalues.HLfit_+3A_type">type</code></td>
<td>
<p>Character: <code>"projection"</code>, <code>"std"</code>, or more cryptic values not documented here. See Details.</p>
</td></tr> 
<tr><td><code id="hatvalues.HLfit_+3A_which">which</code></td>
<td>
<p>Character: <code>"resid"</code> for the traditional leverages of the observations, <code>"ranef"</code> for random-effect leverages, or <code>"both"</code> for both.</p>
</td></tr>
<tr><td><code id="hatvalues.HLfit_+3A_force">force</code></td>
<td>
<p>Boolean: to force recomputation of the leverages even if they are available in the object, for checking purposes.</p>
</td></tr>
<tr><td><code id="hatvalues.HLfit_+3A_...">...</code></td>
<td>
<p>For consistency with the generic.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Leverages may have distinct meaning depending on context. The textbook version for linear models is that leverages <code class="reqn">(q_i)</code> are the diagonal elements of a projection matrix (&ldquo;hat matrix&rdquo;), and that they may be used to standardize (&ldquo;studentize&rdquo;) residuals as follows. If the residual variance <code class="reqn">\phi</code> is known, then the variance of each fitted residual <code class="reqn">\hat{e}_i</code> is <code class="reqn">\phi(1-q_i)</code>. Standardized residuals, all with variance 1, are then <code class="reqn">\hat{e}_i/</code><code class="reqn">\sqrt{}</code><code class="reqn">(\phi(1-q_i))</code>. This standardization of variance no longer holds exactly with estimated <code class="reqn">\phi</code>, but if one uses here an unbiased (REML) estimator of <code class="reqn">\phi</code>, the studentized residuals may still practically have a unit expected variance. 
</p>
<p>The need for distinguishing &ldquo;standardizing&rdquo; from &ldquo;projection&rdquo; leverages arises from generalizations of this standardization to other contexts. Indeed, when a simple linear model is fitted by ML, the variance of the fitted residuals is less than <code class="reqn">\phi</code>, but <code class="reqn">\hat{\phi}</code> is downward biased so that residuals standardized only by <code class="reqn">\sqrt{}</code><code class="reqn">(\phi)</code>, without any leverage correction, more closely have expected unit variance than if corrected by the previous leverages. This hints for another definition of leverages such that they are here zero, contrary to the ones derived from the projection matrix.
</p>
<p>Leverages also appear in expressions for derivatives, with respect to the dispersion parameters, of the log-determinant of the information matrices considered in the Laplace approximation for marginal or restricted likelihood (Lee et al. 2006). This provides a basis to generalize the concept of standardizing leverages for ML and REML in mixed-effect models. In particular, in an ML fit, one considers leverages <code class="reqn">(q*_i)</code> that are no longer the diagonal elements of the projection matrix for the mixed model [and, as hinted above, for a simple linear model the ML <code class="reqn">(q*_i)</code> are zero]. The generalized standardizing leverages may include corrections for non-Gaussian response, for non-Gaussian random effects, and for taking into account the variation of the GLM weights in the logdet(info.mat) derivatives. Which corrections are included depend on the precise method used to fit the model (e.g., EQL vs PQL vs REML). Standardizing leverages are also defined for the random effects.
</p>
<p>These distinctions suggest breaking the usual synonymy between &ldquo;leverages&rdquo; or &ldquo;hat values&rdquo;: the term &ldquo;hat values&rdquo; better stands for the diagonal elements of a projection matrix, while &ldquo;leverages&rdquo; better stands for the standardizing values.   
<code>hatvalues(.,type="std")</code> returns the standardizing leverages. By contrast, <code>hatvalues(.,type="projection")</code> will always return hat values from the fitted projection matrix. Note that these values typically differ between ML and REML fit because the fitted projection matrix differs between them.
</p>


<h3>Value</h3>

<p>A list with separate components <code>resid</code> (leverages of the observations) and <code>ranef</code> if <code>which="both"</code>, and a vector otherwise.
</p>


<h3>References</h3>

<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006) Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;0.8) {
data("Orthodont",package = "nlme")
rnge &lt;- (107:108)

# all different:
#
hatvalues(rlfit &lt;- fitme(distance ~ age+(age|Subject), 
                         data = Orthodont, method="REML"))[rnge]
hatvalues(mlfit &lt;- fitme(distance ~ age+(age|Subject), 
                         data = Orthodont))[rnge] 
hatvalues(mlfit,type="std")[rnge]
}
</code></pre>

<hr>
<h2 id='HLCor'>
Fits a (spatially) correlated mixed model, for given correlation parameters 
</h2><span id='topic+HLCor'></span>

<h3>Description</h3>

<p>A fitting function acting as a convenient interface for <code><a href="#topic+HLfit">HLfit</a></code>, constructing the correlation matrix of random effects from the arguments, then estimating fixed effects and dispersion parameters using <code>HLfit</code>. Various arguments are available to constrain the correlation structure, <code>covStruct</code> and <code>distMatrix</code> being the more general ones (for any number of random effects), and <code>adjMatrix</code> and <code>corrMatrix</code> being alternatives to <code>covStruct</code> for a single correlated random effect. <code>uniqueGeo</code> is deprecated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLCor(formula, data, family = gaussian(), fixed=NULL, ranPars, distMatrix,
      adjMatrix, corrMatrix, covStruct=NULL,
      method = "REML", verbose = c(inner=FALSE),
      control.dist = list(), weights.form = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HLCor_+3A_formula">formula</code></td>
<td>

<p>A <code>predictor</code>, i.e. a formula with attributes (see <code><a href="#topic+Predictor">Predictor</a></code>), or possibly simply a simple <code>formula</code> if an offset is not required.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_fixed">fixed</code>, <code id="HLCor_+3A_ranpars">ranPars</code></td>
<td>

<p>A list of given values for correlation parameters (some of which are mandatory), and possibly also dispersion parameters 
(optional, but passed to HLfit if present). <code>ranPars</code> is the old argument, maintained for back compatibility; <code>fixed</code> is the new argument, uniform across <span class="pkg">spaMM</span> fitting functions. See <code><a href="#topic+ranPars">ranPars</a></code> for further information.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_data">data</code></td>
<td>

<p>The data frame to be analyzed.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_family">family</code></td>
<td>
<p>A <code>family</code> object describing the distribution of the response variable. See <code><a href="#topic+HLfit">HLfit</a></code> for further information.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_distmatrix">distMatrix</code></td>
<td>

<p><b>Either</b> a distance matrix between geographic locations, forwarded to <code>MaternCorr</code> or <code>CauchyCorr</code>. It overrides the (by default, Euclidean) distance matrix that would otherwise be deduced from the variables in a <code>Matern(.))</code> or <code>Cauchy(.)</code> term; <br />
<b>or</b> a list of such matrices. The list format is useful when there are several Matern/Cauchy terms, to avoid that all of them are affected by the same <code>distMatrix</code>. <code>NULL</code> list elements may be necessary, e.g.<br /> 
<code>distMatrix=list("1"=NULL,"2"=&lt;.&gt;)</code>) when a matrix is specified only for the second random effect.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_adjmatrix">adjMatrix</code></td>
<td>

<p>An single adjacency matrix, used if a random effect of the form<br />
<code>y ~ adjacency(1|&lt;location index&gt;)</code> is present. See <code><a href="#topic+adjacency">adjacency</a></code> for further details.
If adjacency matrices are needed for several random effects, use <code>covStruct</code>.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_corrmatrix">corrMatrix</code></td>
<td>

<p>A matrix <b>C</b> used if a random effect term of the form <code>corrMatrix(1|&lt;stuff&gt;)</code> is present. This allows to analyze non-spatial model by giving for example a matrix of genetic correlations. Each row corresponds to levels of a variable &lt;stuff&gt;. The covariance matrix of the random effects for each level is then <code class="reqn">\lambda</code><b>C</b>, where as usual <code class="reqn">\lambda</code> denotes a variance factor for the random effects (if <b>C</b> is a correlation matrix, then  <code class="reqn">\lambda</code> is the variance, but other cases are possible). See <code><a href="#topic+corrMatrix">corrMatrix</a></code> for further details.
If matrices are needed for several random effects, use <code>covStruct</code>.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_covstruct">covStruct</code></td>
<td>

<p>An interface for specifying correlation structures for different types of random effect (<code>corrMatrix</code> or <code>adjacency</code>). See <code><a href="#topic+covStruct">covStruct</a></code> for details.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_method">method</code></td>
<td>
<p>Character: the fitting method to be used, such as <code>"ML"</code>, <code>"REML"</code> or <code>"PQL/L"</code>. <code>"REML"</code> is the default. Other possible values of <code>HLfit</code>'s <code>method</code> argument are handled.
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_weights.form">weights.form</code></td>
<td>

<p>Specification of prior weights by a one-sided formula: use <code>weights.form = ~ pw</code> instead of <code>prior.weights = pw</code>. The effect will be the same except that such an argument, known to evaluate to an object of class <code>"formula"</code>, is suitable to enforce safe programming practices (see <code><a href="#topic+good-practice">good-practice</a></code>).  
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_verbose">verbose</code></td>
<td>

<p>A vector of booleans. <code>inner</code> controls various diagnostic (possibly messy) messages about the iterations. This should be distinguished from the <code>TRACE</code> element, meaningful in <code>fitme</code> or <code>corrHLfit</code> calls. 
</p>
</td></tr>
<tr><td><code id="HLCor_+3A_control.dist">control.dist</code></td>
<td>

<p>A list of arguments that control the computation of the distance argument of the correlation functions. Possible elements are
</p>

<dl>
<dt>rho.mapping</dt><dd><p> a set of indices controlling which elements of the <code>rho</code> scale vector scales which dimension(s) of the space in which (spatial) 
correlation matrices of random effects are computed. See same argument in <code><a href="#topic+make_scaled_dist">make_scaled_dist</a></code> for details and examples.</p>
</dd> 
<dt>dist.method</dt><dd><p><code>method</code> argument of <code>proxy::dist</code> function (by default, <code>"Euclidean"</code>, but see <code><a href="#topic+make_scaled_dist">make_scaled_dist</a></code> for other distances such as spherical ones.)</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="HLCor_+3A_...">...</code></td>
<td>

<p>Further parameters passed to <code>HLfit</code> or to <code><a href="#topic+mat_sqrt">mat_sqrt</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For approximations of likelihood, see <code><a href="#topic+method">method</a></code>.  For the possible structures of random effects, see <code><a href="#topic+random-effects">random-effects</a></code>, but note that <code>HLCor</code> cannot adjust parameters of correlation models (with the exception of conditional autoregressive ones). Any such parameter must be specified by the <code>ranPars</code> argument. More generally, the correlation matrix for random effects can be specified by various combinations of formula terms and other arguments  (see Examples):
</p>

<dl>
<dt>Basic Matérn model</dt><dd><p><code>Matern(1|&lt;...&gt;)</code>, using the spatial coordinates in <code>&lt;...&gt;</code>. This will construct a correlation matrix according to the Matérn correlation function (see <code><a href="#topic+MaternCorr">MaternCorr</a></code>);</p>
</dd>
<dt>Basic Cauchy model</dt><dd><p><code>Cauchy(1|&lt;...&gt;)</code>, as for Matern (see <code><a href="#topic+CauchyCorr">CauchyCorr</a></code>);</p>
</dd>
<dt>Same models with given distance matrix</dt><dd><p>as provided by <code>distMatrix</code> (see Examples);</p>
</dd>
<dt>Given correlation matrix</dt><dd><p><code>corrMatrix(1|&lt;...&gt;)</code> with <code>corrMatrix</code> argument. See <code><a href="#topic+corrMatrix">corrMatrix</a></code> for further details.</p>
</dd>
<dt>CAR model with given adjacency matrix</dt><dd><p><code>adjacency(1|&lt;...&gt;)</code> with <code>adjMatrix</code>. See <code><a href="#topic+adjacency">adjacency</a></code> for further details;</p>
</dd>
<dt>AR1 model</dt><dd><p><code>AR1(1|&lt;...&gt;)</code> See <code><a href="#topic+AR1">AR1</a></code> for further details.</p>
</dd> 
</dl>



<h3>Value</h3>

<p>The return value of an <code>HLfit</code> call, with the following additional attributes: 
</p>
<table>
<tr><td><code>HLCorcall</code></td>
<td>
<p>the HLCor call</p>
</td></tr>  
<tr><td><code>info.uniqueGeo</code></td>
<td>
<p>Unique geographic locations.</p>
</td></tr>  
</table>


<h3>See Also</h3>

<p><code><a href="#topic+autoregressive">autoregressive</a></code> for additional examples, <code><a href="#topic+MaternCorr">MaternCorr</a></code>, <code><a href="#topic+HLfit">HLfit</a></code>, and <code><a href="#topic+corrHLfit">corrHLfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with an adjacency matrix (autoregressive model):
# see 'adjacency' documentation page

#### Matern correlation using only the Matern() syntax
data("blackcap")
(fitM &lt;- HLCor(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
      method="ML", ranPars=list(nu=0.6285603,rho=0.0544659)))

#### Using the 'distMatrix' argument
data("blackcap")
#
# Build distance matrix (here equivalent to the default one for a Matern() term)
MLdistMat &lt;- as.matrix(proxy::dist(blackcap[,c("latitude","longitude")]))
#
(fitD &lt;- HLCor(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
      distMatrix=MLdistMat, method="ML", ranPars=list(nu=0.6285603,rho=0.0544659)))
# : result here must be equivalent to the one without the distMatrix.
diff(c(logLik(fitM),logLik(fitD)))
</code></pre>

<hr>
<h2 id='HLfit'>Fit mixed models with given correlation matrix</h2><span id='topic+HLfit'></span><span id='topic+REMLformula'></span><span id='topic+Beta-distribution-random-effects'></span><span id='topic+Beta'></span><span id='topic+prior.weights'></span>

<h3>Description</h3>

<p>This function fits GL(M)Ms as well as some hierarchical generalized linear models (HGLM; Lee and Nelder 2001). It may be called on its own but is now better seen as a backend for the main fitting function <code>fitme</code> (or <code>fitmv</code> for multivariate-response models). This documentation completes the documentation of the latter functions with respect to some arguments they pass to <code>HLfit</code> and with respect to the structure of the objects they return.
</p>
<p>On its own, <code>HLfit</code> fits both fixed effects parameters, and dispersion parameters i.e. the variance of the random effects (full covariance for random-coefficient models), and the variance of the residual error. The linear predictor is of the standard form <code>offset+ X beta + Z b</code>, where X is the design matrix of fixed effects and Z is a design matrix of random effects (typically an incidence matrix with 0s and 1s, but not necessarily). Models are fitted by an iterative algorithm alternating estimation of fixed effects and of dispersion parameters. The residual dispersion may follow a &ldquo;structured-dispersion model&rdquo; modeling heteroscedasticity. 
Estimation of the latter parameters is performed by a form of fit of debiased residuals, which allows fitting a structured-dispersion model (Smyth et al. 2001).  However, evaluation of the debiased residuals can be slow in particular for large datasets. For models without structured dispersion, it is then worth using the <code><a href="#topic+fitme">fitme</a></code> function. Ths function (as well as <code><a href="#topic+corrHLfit">corrHLfit</a></code>) can optimize the likelihood of <code>HLfit</code> fits for different given values of the dispersion parameters (&ldquo;outer optimization&rdquo;), thereby avoiding the need to estimate debiased residuals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLfit(formula, data, family = gaussian(), rand.family = gaussian(), 
      resid.model = ~1, REMLformula = NULL, verbose = c(inner = FALSE), 
      HLmethod = "HL(1,1)", method="REML", control.HLfit = list(), 
      control.glm = list(), init.HLfit = list(), fixed=list(), ranFix, 
      etaFix = list(), prior.weights = NULL, weights.form = NULL, X2X=NULL, 
      processed = NULL)
## see 'rand.family' argument for inverse.Gamma
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HLfit_+3A_formula">formula</code></td>
<td>

<p>A <code><a href="#topic+formula">formula</a></code>; or a <code>predictor</code>, i.e. a formula with attributes created by <code><a href="#topic+Predictor">Predictor</a></code>, if design matrices for random effects have to be provided. See Details in <code><a href="#topic+spaMM">spaMM</a></code> for allowed terms in the formula (except spatial ones).
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_data">data</code></td>
<td>

<p>A data frame containing the variables named in the model formula.  
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_family">family</code></td>
<td>

<p>A <code>family</code> object describing the distribution of the response variable. See Details in <code><a href="#topic+spaMM">spaMM</a></code> for handled families.
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_rand.family">rand.family</code></td>
<td>

<p>A <code>family</code> object describing the distribution of the random effect, or a <code>list</code> of 
family objects for different random effects (see Examples). Possible options are
<code>gaussian()</code>, <code>Gamma(log)</code>, <code>Gamma(identity)</code> (see Details), <code>Beta(logit)</code>, <code>inverse.Gamma(-1/mu)</code>, and <code>inverse.Gamma(log)</code>.
For discussion of these alternatives see Lee and Nelder 2001 or Lee et al. 2006, p. 178-.
Here the family gives the distribution of a random effect <code class="reqn">u</code> 
and the link gives <code>v</code> as function of <code class="reqn">u</code> (see Details).
If there are several random effects and only one family is given, this family holds for all random effects.
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_resid.model">resid.model</code></td>
<td>
<p>Used to specify a model for the dispersion parameter of the mean-response family. See the <code><a href="#topic+resid.model">resid.model</a></code> documentation, and the more specific <code><a href="#topic+phi-resid.model">phi-resid.model</a></code> one for the <code class="reqn">phi</code> parameter of gaussian and Gamma response families.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_remlformula">REMLformula</code></td>
<td>

<p>A model <code>formula</code> that controls the estimation of dispersion parameters and the computation of restricted likelihood (<code>p_bv</code>), where the conditioning inherent in REML is defined by a model different from the predictor <code>formula</code>. A simple example (useless in practice) of its effect is to replicate an ML fit by specifying <code>method="REML"</code> and an <code>REMLformula</code> with no fixed effect. The latter implies that no conditioning is performed and that <code>p_bv</code> equals the marginal likelihood (or its approximation), <code>p_v</code>. One of the examples in <code><a href="#topic+update.HLfit">update.HLfit</a></code> shows how <code>REMLformula</code> can be useful, but otherwise this argument may never be needed for standard REML or ML fits. For non-standard likelihood ratio tests using <code>REMLformula</code>, see <code><a href="#topic+fixedLRT">fixedLRT</a></code>.    
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_verbose">verbose</code></td>
<td>

<p>A vector of booleans or integers. The <code>inner</code> element controls various diagnostic messages (possibly messy) about the iterations. This should be distinguished from the <code>TRACE</code> element, meaningful in <code>fitme</code> or <code>corrHLfit</code> calls, and much more useful. The <code>phifit</code> element controls messages about the progress of <code><a href="#topic+phi-resid.model">phi-resid.model</a></code> fits (see the latter documentation). 
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_method">method</code></td>
<td>
<p>Character: the fitting method. 
allowed values include <code>"REML"</code>, <code>"ML"</code>, <code>"EQL-"</code> and <code>"EQL+"</code> for all models, and <code>"PQL"</code> (=<code>"REPQL"</code>) and <code>"PQL/L"</code> for GLMMs only. <code>method=c(&lt;"ML" or "REML"&gt;,"exp")</code> can be distinctly useful for slow fits of models with <code>Gamma(log)</code> response family. See (see <code><a href="#topic+method">method</a></code>) for details, and further possible values for those curious to experiment. <b>The default is REML</b> (standard REML for LMMs, 
an extended definition for other models). REML can be viewed as a form of conditional inference, and non-standard conditionings can be called by using a non-standard <code>REMLformula</code>.
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_hlmethod">HLmethod</code></td>
<td>
<p>Same as <code>method</code>. It is useless to specify <code>HLmethod</code> when <code>method</code> is specified. The default value <code>"HL(1,1)"</code> means the same as <code>method="REML"</code>, but more accurately relates to definitions of approximations of likelihood in the <code class="reqn">h</code>-likelihood literature.</p>
</td></tr>
<tr><td><code id="HLfit_+3A_control.hlfit">control.HLfit</code></td>
<td>

<p>A list of parameters controlling the fitting algorithms, which should mostly be ignored in routine use. 
See <code><a href="#topic+control.HLfit">control.HLfit</a></code> for possible controls.
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_control.glm">control.glm</code></td>
<td>

<p>List of parameters controlling calls to <code>glm</code>-&ldquo;like&rdquo; fits, passed to <code>glm.control</code>; e.g.<br /> 
<code>control.glm=list(maxit=100)</code>. See <code><a href="stats.html#topic+glm.control">glm.control</a></code> for further details. <code>glm</code>-&ldquo;like&rdquo; fits may be performed as part of mixed-effect model fitting procedures, in particular to provide initial values (possibly using <code><a href="#topic+llm.fit">llm.fit</a></code> for non-GLM families), and for &ldquo;inner&rdquo; estimation of dispersion parameters.  
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_init.hlfit">init.HLfit</code></td>
<td>

<p>A list of initial values for the iterative algorithm, with possible elements of the list are 
<code>fixef</code> for fixed effect estimates (beta),  
<code>v_h</code> for random effects vector <b>v</b> in the linear predictor,
<code>lambda</code> for the parameter determining the variance of random effects <code class="reqn">u</code> as drawn from the <code>rand.family</code> distribution,  
and <code>phi</code> for the residual variance. 
However, this argument can be ignored in routine use. 
</p>
</td></tr>

<tr><td><code id="HLfit_+3A_fixed">fixed</code>, <code id="HLfit_+3A_ranfix">ranFix</code></td>
<td>

<p>A list of fixed values of random effect parameters. <code>ranFix</code> is the old argument, maintained for back compatibility; <code>fixed</code> is the new argument, uniform across <span class="pkg">spaMM</span> fitting functions. See <code><a href="#topic+ranFix">ranFix</a></code> for further information.
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_etafix">etaFix</code></td>
<td>

<p>A list of given values of the coefficients of the linear predictor. See <code><a href="#topic+etaFix">etaFix</a></code> for further information.     
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_prior.weights">prior.weights</code></td>
<td>

<p>An optional vector of prior weights as in <code><a href="stats.html#topic+glm">glm</a></code>. This fits the data to a probability model with residual variance parameter given as <code>phi/prior.weights</code> instead of the canonical parameter <code>phi</code> of the response family, and all further outputs are defined to be consistent with this (see section IV in Details). 
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_weights.form">weights.form</code></td>
<td>

<p>Specification of prior weights by a one-sided formula: use <code>weights.form = ~ pw</code> instead of <code>prior.weights = pw</code>. The effect will be the same except that such an argument, known to evaluate to an object of class <code>"formula"</code>, is suitable to enforce safe programming practices (see <code><a href="#topic+good-practice">good-practice</a></code>).  
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_x2x">X2X</code></td>
<td>

<p>For development purposes, not documented.
</p>
</td></tr>
<tr><td><code id="HLfit_+3A_processed">processed</code></td>
<td>

<p>A list of preprocessed arguments, for programming purposes only.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>I. Approximations of likelihood:</b> see <code><a href="#topic+method">method</a></code>.
</p>
<p><b>II. Possible structure of Random effects:</b> see <code><a href="#topic+random-effects">random-effects</a></code>, but note that <code>HLfit</code> does not fit models with autocorrelated random effects.
</p>
<p><b>III. The standard errors</b> reported may sometimes be misleading. For each set of parameters among <code class="reqn">\beta</code>, <code class="reqn">\lambda</code>, and <code class="reqn">\phi</code> parameters these are computed assuming that the other parameters are known without error. This is why they are labelled <code>Cond. SE</code> (conditional standard error). This is most uninformative in the unusual case where <code class="reqn">\lambda</code> and <code class="reqn">\phi</code> are not separately estimable parameters. Further, the SEs for <code class="reqn">\lambda</code> and <code class="reqn">\phi</code> are rough approximations as discussed in particular by Smyth et al. (2001; <code class="reqn">V_1</code> method).    
</p>
<p><b>IV. prior weights</b>. This controls the likelihood analysis of heteroscedastic models. In particular, changing the weights by a constant factor <em>f</em> should, and will, yield a fit with unchanged likelihood and (Intercept) estimates of <code>phi</code> also increased by <em>f</em> (except if a non-trivial <code>resid.formula</code> with log link is used). This is consistent with what <code>glm</code> does, but other packages may not follow this logic (whatever their documentation may say: check by yourself by changing the weights by a constant factor). Further, post-fit functiosn (in particular those extracting various forms of residuals) may be inconsistent in their handling of prior weights.
</p>


<h3>Value</h3>

<p>An object of class <code>HLfit</code>, which is a list with many elements, not all of which are documented. 
</p>
<p>Various extractor functions are available (see <code><a href="#topic+extractors">extractors</a></code>, <code><a href="#topic+vcov">vcov</a></code>, <code><a href="#topic+get_fittedPars">get_fittedPars</a></code>, <code><a href="#topic+get_matrix">get_matrix</a></code>, and so on). They should be used as far as possible as they should be backward-compatible from version 2.0.0 onwards, while the structure of the return object may still evolve. The following information may be useful for extracting further elements of the object.
</p>
<p>Elements include <b>descriptors of the fit</b>:
</p>
<table>
<tr><td><code>eta</code></td>
<td>
<p>Fitted values on the linear scale  (including the predicted random effects). <code>predict(.,type="link")</code> can be used as a formal extractor;</p>
</td></tr>
<tr><td><code>fv</code></td>
<td>
<p>Fitted values (<code class="reqn">\mu=</code>&lt;inverse-link&gt;(<code class="reqn">\eta</code>)) of the response variable. <code>fitted(.)</code> or <code>predict(.)</code> can be used as formal extractors;</p>
</td></tr>
<tr><td><code>fixef</code></td>
<td>
<p>The fixed effects coefficients, <code class="reqn">\beta</code> (returned by the <code>fixef</code> function);</p>
</td></tr>
<tr><td><code>v_h</code></td>
<td>
<p>The random effects on the linear scale, <code class="reqn">v</code>, with atttribute the random effects <code class="reqn">u</code> (returned by <code>ranef(*,type="uncorrelated")</code>;</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>The residual variance <code class="reqn">\phi</code>. See <code><a href="#topic+residVar">residVar</a></code> for one extractor;</p>
</td></tr>
<tr><td><code>phi.object</code></td>
<td>
<p>A possibly more complex object describing <code class="reqn">\phi</code> (see <code><a href="#topic+residVar">residVar</a></code> again);</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The random-effect (<code class="reqn">u</code>) variance(s) <code class="reqn">\lambda</code> in compact form;</p>
</td></tr>
<tr><td><code>lambda.object</code></td>
<td>
<p>A possibly more complex object describing <code class="reqn">\lambda</code> (see <code><a href="#topic+get_ranPars">get_ranPars</a>(.,which="lambda"))</code> and <code><a href="#topic+VarCorr">VarCorr</a></code> extractors);</p>
</td></tr>
<tr><td><code>ranef_info</code></td>
<td>
<p>environment where information about the structure of random effects is stored (see <code><a href="#topic+Corr">Corr</a></code>);</p>
</td></tr>
<tr><td><code>corrPars</code></td>
<td>
<p>Agglomerates information on correlation parameters, either fixed, or estimated ((see <code><a href="#topic+get_ranPars">get_ranPars</a>(.,which="corrPars"))</code>);</p>
</td></tr>
<tr><td><code>APHLs</code></td>
<td>
<p>A list whose elements are various likelihood components, including conditional likelihood, h-likelihood, and the Laplace approximations: the (approximate) marginal <b>likelihood</b> <code>p_v</code> and the (approximate) <b>restricted likelihood</b> <code>p_bv</code> (the latter two available through the <code>logLik</code> function). See the extractor function <code><a href="#topic+get_any_IC">get_any_IC</a></code> for information criteria (&ldquo;AIC&rdquo;) and effective degrees of freedom;</p>
</td></tr>
</table>
<p>The covariance matrix of <code class="reqn">\beta</code> estimates is not included as such, but can be extracted by <code><a href="#topic+vcov">vcov</a></code>.
</p>
<p><b>Information about the input</b> is contained in output elements named as arguments of the fitting function calls (<code>data,family,resid.family,ranFix,prior.weights</code>), with the following notable exceptions or modifications:
</p>
<table>
<tr><td><code>predictor</code></td>
<td>
<p>The <code>formula</code>, possibly reformatted (returned by the <code>formula</code> extractor);</p>
</td></tr>
<tr><td><code>resid.predictor</code></td>
<td>
<p>Analogous to <code>predictor</code>, for the residual variance (see <code><a href="#topic+residVar">residVar</a>(., which="formula")</code>);</p>
</td></tr>
<tr><td><code>rand.families</code></td>
<td>
<p>corresponding to the <code>rand.family</code> input;</p>
</td></tr>
</table>
<p><b>Further miscellaneous diagnostics and descriptors of model structure:</b>
</p>
<table>
<tr><td><code>X.pv</code></td>
<td>
<p>The design matrix for fixed effects (returned by the <code>model.matrix</code> extractor);</p>
</td></tr>
<tr><td><code>ZAlist</code>, <code>strucList</code></td>
<td>
<p>Two lists of matrices, respectively the design matrices &ldquo;<b>Z</b>&rdquo;, and the &ldquo;<b>L</b>&rdquo; matrices, for the different random-effect terms. The extractor <code><a href="#topic+get_ZALMatrix">get_ZALMatrix</a></code> can be used to reconstruct a single &ldquo;<b>ZL</b>&rdquo; matrix for all terms.</p>
</td></tr>
<tr><td><code>BinomialDen</code></td>
<td>
<p>(binomial data only) the binomial denominators;</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response vector; for binomial data, the frequency response.</p>
</td></tr>
<tr><td><code>models</code></td>
<td>
<p>Additional information on model structure for <code class="reqn">\eta</code>, <code class="reqn">\lambda</code> and <code class="reqn">\phi</code>;</p>
</td></tr>
<tr><td><code>HL</code></td>
<td>
<p>A set of indices that characterize the approximations used for likelihood;</p>
</td></tr>
<tr><td><code>leve_phi</code>, <code>lev_lambda</code></td>
<td>
<p>Leverages (see <code><a href="#topic+hatvalues">hatvalues</a></code> extractor);</p>
</td></tr>
<tr><td><code>dfs</code></td>
<td>
<p>list (possibly structured): some information about degrees of freedom for different components of the model. But its details may be difficult to interpret and the <code><a href="#topic+DoF">DoF</a></code> extractor should be used;</p>
</td></tr> 
<tr><td><code>how</code></td>
<td>
<p>A list containing the information properly extracted by the <code><a href="#topic+how">how</a></code> function;</p>
</td></tr>
<tr><td><code>warnings</code></td>
<td>
<p>A list of warnings for events that may have occurred during the fit.</p>
</td></tr>
</table>
<p>Finally, the object includes programming tools: <code>call, spaMM.version, fit_time</code> and an environment <code>envir</code> that may contain whatever may be needed in some post-fit operations..
</p>


<h3>References</h3>

<p>Lee, Y., Nelder, J. A. (2001)  Hierarchical generalised linear models: A
synthesis of generalised linear models, random-effect models and structured
dispersions. Biometrika 88, 987-1006.
</p>
<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006). Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>
<p>Smyth GK, Huele AF, Verbyla AP (2001). Exact and approximate REML for heteroscedastic regression. Statistical Modelling 1, 161-175. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HLCor">HLCor</a></code> for estimation with given spatial correlation parameters;
<code><a href="#topic+corrHLfit">corrHLfit</a></code> for joint estimation with spatial correlation parameters;
<code><a href="#topic+fitme">fitme</a></code> as an alternative to all these functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
## Gamma GLMM with log link

HLfit(y ~ X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), family=Gamma(log),
          resid.model = ~ X3+I(X3^2) ,data=wafers)

## Gamma - inverseGamma HGLM with log link
HLfit(y ~ X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), family=Gamma(log),
          rand.family=inverse.Gamma(log),
          resid.model = ~ X3+I(X3^2) , data=wafers)
</code></pre>

<hr>
<h2 id='how'>
Extract information about how an object was obtained
</h2><span id='topic+how'></span><span id='topic+how.default'></span><span id='topic+how.HLfit'></span><span id='topic+how.HLfitlist'></span>

<h3>Description</h3>

<p><code>how</code> is defined as a generic with currently only one non-default method, for objects of class <code>HLfit</code>. This method provide information about how such a fit was obtained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>how(object, ...)
## S3 method for class 'HLfit'
how(object, devel=FALSE, verbose=TRUE, format=print, ...)
## S3 method for class 'HLfitlist'
how(object, devel=FALSE, verbose=TRUE, format=print, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="how_+3A_object">object</code></td>
<td>
<p>Any R object.</p>
</td></tr>
<tr><td><code id="how_+3A_devel">devel</code></td>
<td>
<p>Boolean; Whether to provide additional cryptic information. For development purposes, not further documented.</p>
</td></tr>
<tr><td><code id="how_+3A_verbose">verbose</code></td>
<td>
<p>Boolean; Whether to print information about the input object.</p>
</td></tr>
<tr><td><code id="how_+3A_format">format</code></td>
<td>
<p>wrapper for printing format. E.g., <code>cat(crayon::yellow(s),"\n")</code> could be used instead of the default.</p>
</td></tr>
<tr><td><code id="how_+3A_...">...</code></td>
<td>
<p>Other arguments that may be needed by some method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, returned invisibly, whose elements are not further described here, some being slightly cryptic or subject to future changes However, <code>how(.)$fit_time</code> is a clean way of getting the fit time. If <code>verbose</code> is <code>TRUE</code>, the function prints a message presenting some of these elements.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>foo &lt;- HLfit(y~x, data=data.frame(x=runif(3), y=runif(3)), method="ML", ranFix=list(phi=1))
how(foo)
</code></pre>

<hr>
<h2 id='inits'>
Controlling optimization strategy through initial values
</h2><span id='topic+inits'></span>

<h3>Description</h3>

<p>Several parameters (notably the dispersion parameters: the variance of random effects and the residual variance parameter, if any) can be estimated either by iterative algorithms, or by generic optimization methods. The development of the <code>fitme</code> function aims to provide full control of the selection of algorithms. For example, if two random effects are fitted, then<br /> <code>init=list(lambda=c(NA,NaN))</code> enforces generic optimization for the first variance and iterative algorithms for the second.<br /> 
<code>init=list(lambda=c(0.1,NaN))</code> has the same effect and additionally provides control of the initial value for optimization (whereas <code>init.HLfit=list(lambda=c(NA,0.1))</code> will provide control of the initial value for iterations).
</p>
<p>How to know which algorithm has been selected for each parameter? <code>fitme(., verbose=c(TRACE=TRUE))</code> shows successive values of the variables estimated by optimization (See Examples; if no value appears, then all are estimated by iterative methods). The first lines of the summary of a fit object should tell which variances are estimated by the &ldquo;outer&rdquo; method.
</p>
<p><code>corrHLfit</code>, which uses inner optimization by default, can be forced to perform outer optimization. Its control is more limited, as <code>NA</code>s and <code>NaN</code>s are not allowed. Instead, only numeric values as in <code>init=list(lambda=0.1)</code> are allowed. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
air &lt;- data.frame(passengers = as.numeric(AirPassengers),
                  year_z = scale(rep(1949:1960, each = 12)),
                  month = factor(rep(1:12, 12)))
air$time &lt;- 1:nrow(air)
# Use verbose to find that lambda is estimated by optimization
fitme(passengers ~ month * year_z + AR1(1|time), data = air, 
      verbose=c(TRACE=TRUE)) 
# Use init to enforce iterative algorithm for lambda estimation:      
fitme(passengers ~ month * year_z + AR1(1|time), data = air, 
      verbose=c(TRACE=TRUE), init=list(lambda=NaN))
# (but then it may be better to enforce it also for phi: init=list(lambda=NaN, phi=NaN))
#
# Use init to enforce generic optimization for lambda estimation,
#   and control initial value:      
fitme(passengers ~ month * year_z + AR1(1|time), data = air, 
      verbose=c(TRACE=TRUE), init=list(lambda=0.1))
      
# See help("multinomial") for more examples of control by initial values.       

## End(Not run)
</code></pre>

<hr>
<h2 id='inverse.Gamma'>
Distribution families for Gamma and inverse Gamma-distributed random effects
</h2><span id='topic+inverse.Gamma'></span><span id='topic+Gamma'></span>

<h3>Description</h3>

<p>For dispersion parameter <code class="reqn">\lambda</code>, <code>Gamma</code> means that random effects are distributed as <code class="reqn">u ~</code>Gamma(<code>shape=</code>1/<code class="reqn">\lambda</code>,<b>scale=</b><code class="reqn">\lambda</code>), so <code class="reqn">u</code> has mean 1 and variance <code class="reqn">\lambda</code>. Both the log (<code class="reqn">v=log(u)</code>) and identity (<code class="reqn">v=u</code>) links are possible, though in the latter case the variance of <code class="reqn">u</code> is constrained below 1 (otherwise Laplace approximations fail).
</p>
<p>The two-parameter inverse Gamma distribution is the distribution of the reciprocal of a variable distributed according to the Gamma distribution Gamma with the same shape and scale parameters. <code>inverse.Gamma</code> implements the one-parameter inverse Gamma family with shape=1+1/<code class="reqn">\lambda</code> and <b>rate</b>=1/<code class="reqn">\lambda</code>) (rate=1/scale). It is used to model the distribution of random effects. Its mean=1; and its variance =<code class="reqn">\lambda/(1-\lambda))</code> if <code class="reqn">\lambda&lt;1</code>, otherwise infinite. The default link is <code>"-1/mu"</code>, in which case <code>v=-1/u</code> is &ldquo;-Gamma&rdquo;-distributed with the same shape and rate, hence with mean <code class="reqn">-(\lambda+1)</code> and variance <code class="reqn">\lambda(\lambda+1)</code>, which is a different one-parameter Gamma family than the above-described <code>Gamma</code>. The other possible link is <code>v=log(u)</code> in which case<br /> 
<code class="reqn">v ~ -log(X~</code>Gamma<code class="reqn">(1+1/\lambda,1/\lambda))</code>, with mean <code class="reqn">-(log(1/\lambda)+</code>digamma<code class="reqn">(1+1/\lambda))</code> and variance trigamma(<code class="reqn">1+1/\lambda</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inverse.Gamma(link = "-1/mu")
# Gamma(link = "inverse") using stats::Gamma 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inverse.Gamma_+3A_link">link</code></td>
<td>
<p>For <code>Gamma</code>, allowed links are <code>log</code> and <code>identity</code> (the default link from <code><a href="stats.html#topic+family">Gamma</a></code>, <code>"inverse"</code>, cannot be used for the random effect specification). For <code>inverse.Gamma</code>, allowed links are <code>"-1/mu"</code> (default) and <code>log</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># see help("HLfit") for fits using the inverse.Gamma distribution.
</code></pre>

<hr>
<h2 id='is_separated'>
Checking for (quasi-)separation in binomial-response model.
</h2><span id='topic+is_separated'></span><span id='topic+is_separated.formula'></span><span id='topic+separation'></span>

<h3>Description</h3>

<p>Separation occurs in binomial response models when a combination of the predictor variables perfectly predict a level of the response. In such a case the estimates of the coefficients for these variables diverge to (+/-)infinity, and the numerical algorithms typically fail. To anticipate such a problem, the fitting functions in <code>spaMM</code> try to check for separation by default. The check may take much time, and is skipped if the &ldquo;problem size&rdquo; exceeds a threshold defined by <code>spaMM.options(separation_max=&lt;.&gt;)</code>, in which case a message will tell users by how much they should increase <code>separation_max</code> to force the check (its exact meaning and default value are subject to changes without notice but the default value aims to correspond to a separation check time of the order of 1s on the author's computer). 
</p>
<p><code>is_separated</code> is a convenient interface to procedures from the <code>ROI</code> package, allowing them to be called explicitly by the user to check bootstrap samples (see Example in <code><a href="#topic+anova">anova</a></code>). 
<code>is_separated.formula</code> is a variant (not yet a formal S3 method) that performs the same check, but using arguments similar to those of <code>fitme(., family=binomial())</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_separated(x, y, verbose = TRUE, solver=spaMM.getOption("sep_solver"))
is_separated.formula(formula, ..., separation_max=spaMM.getOption("separation_max"),
                     solver=spaMM.getOption("sep_solver"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_separated_+3A_x">x</code></td>
<td>

<p>Design matrix for fixed effects.
</p>
</td></tr>
<tr><td><code id="is_separated_+3A_y">y</code></td>
<td>

<p>Numeric response vector
</p>
</td></tr>
<tr><td><code id="is_separated_+3A_formula">formula</code></td>
<td>

<p>A model formula
</p>
</td></tr>
<tr><td><code id="is_separated_+3A_...">...</code></td>
<td>

<p><code>data</code> and possibly other arguments of a <code>fitme</code> call. <code>family</code> is ignored if present.  
</p>
</td></tr>
<tr><td><code id="is_separated_+3A_separation_max">separation_max</code></td>
<td>

<p>numeric: non-default value allow for easier local control of this spaMM option.  
</p>
</td></tr>
<tr><td><code id="is_separated_+3A_solver">solver</code></td>
<td>

<p>character: name of linear programming solver used to assess separation; passed to <code><a href="ROI.html#topic+ROI_solve">ROI_solve</a></code>'s <code>solver</code> argument. One can select another solver if the corresponding ROI plugin is installed. 
</p>
</td></tr>
<tr><td><code id="is_separated_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some messages (e.g., pointing model terms that cause separation) or not.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a boolean; <code>TRUE</code> means there is (quasi-)separation. Screen output may give further information, such as pointing model terms that cause separation.
</p>


<h3>References</h3>

<p>The method accessible by <code>solver="glpk"</code> implements algorithms described by
</p>
<p>Konis, K. 2007. Linear Programming Algorithms for Detecting Separated Data in Binary Logistic Regression Models. DPhil Thesis, Univ. Oxford. <a href="https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a">https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a</a>.
</p>


<h3>See Also</h3>

<p>See also the 'safeBinaryRegression' and 'detectseparation' package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
d &lt;- data.frame(success = rbinom(10, size = 1, prob = 0.9), x = 1:10)
is_separated.formula(formula= success~x, data=d) # FALSE
is_separated.formula(formula= success~I(success^2), data=d) # TRUE
</code></pre>

<hr>
<h2 id='Leuca'>
Leucadendron data
</h2><span id='topic+Leuca'></span>

<h3>Description</h3>

<p>A data set from Tonnabel et al. (2021) to be fitted by models with sex-specific spatial random effects. Leucadrendron rubrum is a dioecious shrub from South Africa. Various phenotypes were recorded on individuals from a small patch of habitat.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Leuca")</code></pre>


<h3>Format</h3>

<p><code>Leuca</code> is 
</p>
<pre>
'data.frame':	156 obs. of  12 variables:
 $ name   : Factor w/ 156 levels "f_101","f_102",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ sex    : Factor w/ 2 levels "f","m": 1 1 1 1 1 1 1 1 1 1 ...
 $ area   : num  0.857 0.9 0.827 0.654 0.733 ...
 $ diam   : int  60 30 180 50 70 80 130 90 27 59 ...
 $ fec    : num  0.013 0.0137 5.1171 0.2905 1.042 ...
 $ fec_div: num  0.0128 0.0135 5.037 0.2859 1.0257 ...
 $ x      : num  42 41 62.5 58.5 42.5 33.5 24 26.5 25 41 ...
 $ y      : num  23 46 58 63 51 51 55.5 55.5 58.5 63 ...
 $ diamZ  : num  -0.713 -1.479 2.352 -0.968 -0.457 ...
 $ areaZ  : num  0.72 0.92 0.586 -0.2 0.158 ...
 $ male   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
 $ female : logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
</pre>


<h3>Source</h3>

<p>Tonnabel, J., Klein, E.K., Ronce, O., Oddou-Muratorio, S., Rousset, F., Olivieri, I., Courtiol, A. and Mignot, A. (2021), Sex-specific spatial variation in fitness in the highly dimorphic Leucadendron rubrum. Mol Ecol, 30: 1721-1735. <a href="https://doi.org/10.1111/mec.15833">doi:10.1111/mec.15833</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MaternCorr">MaternCorr</a></code> and <code><a href="#topic+composite-ranef">composite-ranef</a></code> for examples using these data.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Leuca)
</code></pre>

<hr>
<h2 id='lev2bool'>
Conversion of factor to 0/1 variable
</h2><span id='topic+lev2bool'></span>

<h3>Description</h3>

<p>It may be straightforward to add columns of indicator variables for each level of a factor to the data, by <br /> 
<em>&lt;data&gt;</em> <code> &lt;- cbind(</code><em>&lt;data&gt;</em><code>, model.matrix( ~ </code><em>&lt;factor&gt;</em><code> - 1, data = </code><em>&lt;data&gt;</em><code>))</code>.
Alternatively, indicator variables can be created on the fly for given levels, using the <code>lev2bool</code> function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lev2bool(fac, lev)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lev2bool_+3A_fac">fac</code></td>
<td>

<p>An object coercible to <code><a href="base.html#topic+factor">factor</a></code>.
</p>
</td></tr>
<tr><td><code id="lev2bool_+3A_lev">lev</code></td>
<td>

<p>The level of <code>fac</code> to be converted to 1.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-column matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Elementary bivariate-response model

# Data preparation
#
fam &lt;- rep(c(1,2),rep(6,2)) # define two biological 'families'
ID &lt;- gl(6,2) # define 6 'individuals'
resp &lt;- as.factor(rep(c("x","y"),6)) # distinguishes two responses per individual
set.seed(123)
toymv &lt;- data.frame(
  fam = factor(fam), ID = ID, resp = resp, 
  y = 1 + (resp=="x") + rnorm(4)[2*(resp=="x")+fam] + rnorm(12)[6*(resp=="x")+as.integer(ID)]
)
toymv &lt;- cbind(toymv, model.matrix( ~ resp - 1, data = toymv)) 

# fit response-specific variances of random effect and residuals: 
#
(fitme(y ~ resp+ (0+respx|fam)+ (0+respy|fam), 
        resid.model = ~ 0+resp ,data=toymv))

# Same result by different syntaxes:

#  * by the lev2bool() specifier:
 (fitme(y ~ resp+ (0+lev2bool(resp,"x")|fam)+ (0+lev2bool(resp,"y")|fam), 
        resid.model = ~ 0+resp ,data=toymv))

#  * or by random-coefficient model using 'resp' factor:    
(fitme(y ~ resp+ (0+resp|fam), resid.model = ~ 0+resp ,data=toymv, 
       fixed=list(ranCoefs=list("1"=c(NA,0,NA)))))
       
#  * or by the dummy() specifier from lme4:
# (fitme(y ~ resp+ (0+dummy(resp,"x")|fam)+ (0+dummy(resp,"y")|fam), 
#        resid.model = ~ 0+resp ,data=toymv))
</code></pre>

<hr>
<h2 id='llm.fit'>
Link-linear regression models (LLMs)
</h2><span id='topic+LL-family'></span><span id='topic+llm.fit'></span>

<h3>Description</h3>

<p>Some &ldquo;family&rdquo; objects in <span class="pkg">spaMM</span> describe models with non-GLM response families, such as the <code><a href="#topic+negbin1">negbin1</a></code> or <code><a href="#topic+beta_resp">beta_resp</a></code> families already widely considered in previous works and other packages. These models are characterized by a linear predictor, a link function, and a distribution for residual variation that does not belong to the exponential family from which GLMs are defined. 
</p>
<p>These family objects are conceived for use with <span class="pkg">spaMM</span>'s fitting functions. They cannot generally be used as argument to the <code>glm</code> function, except when this function is highjacked by use of the <code>method="llm.fit"</code> argument, where llm stands for Link-Linear (as in &ldquo;log-linear&rdquo;, say) regression Model. 
</p>
<p>Mixed-effect models fitted by such methods cannot use expected-Hessian approximations, in contrast to GLM response families. <code><a href="#topic+negbin2">negbin2</a></code> is a family object for a GLM response family (strictly speaking, only for fixed shape and untruncated version) but implemented as an <code>LL-family</code>, in particular using only the observed Hessian matrix.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'># glm(..., method="llm.fit")
## See also 'beta_resp', 'negbin1', 'betabin', and possibly later additions.
</code></pre>


<h3>Details</h3>

<p>These family objects are lists, formally of class <code>c("LLF", "family")</code>. Compared to a <code><a href="stats.html#topic+family">family</a></code> object, they have additional elements, not documented here. 
</p>
<p>As <code>stats::</code> GLM family objects do, they provide deviance residuals through the <code>dev.resids</code> member function. There are various definitions of deviance residuals for non-GLM families in the literature. Here they are defined as &ldquo;2*(saturated_logLik - logLik)&rdquo;, where the likelihood for the saturated model is the likelihood maximized wrt to the mean parameter <code class="reqn">\mu</code> for each observation <code>y</code> independently. The maximizing  <code class="reqn">\mu</code> is not equal to the observation, in contrast to the standard result for GLMs.   
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(scotlip)

### negbin1 response:

# Fixed-effect model
#
(var_shape &lt;- fitme(cases~I(prop.ag/10)+offset(log(expec)),family=negbin1(), 
                    data=scotlip))

# Highjacking glm(): the family parameter must be given 
#
fitted_shape &lt;- residVar(var_shape,which="fam_parm")
glm(cases~I(prop.ag/10)+offset(log(expec)),family=negbin1(shape=fitted_shape), 
    method="llm.fit", data=scotlip)

### Similar exercice with Beta response family: 

set.seed(123)
beta_dat &lt;- data.frame(y=runif(100),grp=sample(2,100,replace = TRUE))
  
# Fixed-effect model
(var_prec &lt;- fitme(y ~1, family=beta_resp(), data= beta_dat))
  
# Highjacking glm(): 
fitted_prec &lt;- residVar(var_prec,which="fam_parm")
glm(y ~1, family=beta_resp(prec=fitted_prec), data= beta_dat, method="llm.fit") 

</code></pre>

<hr>
<h2 id='Loaloa'>
Loa loa prevalence in North Cameroon, 1991-2001
</h2><span id='topic+Loaloa'></span>

<h3>Description</h3>

<p>This data set describes prevalence of infection by the nematode <em>Loa loa</em> in North Cameroon, 1991-2001.
This is a superset of the data discussed by Diggle and Ribeiro (2007) and Diggle et al. (2007).
The study investigated the relationship between altitude, vegetation indices, and prevalence of  the parasite. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Loaloa")</code></pre>


<h3>Format</h3>

<p>The data frame includes 197 observations on the following variables:
</p>

<dl>
<dt>latitude</dt><dd><p>latitude, in degrees.</p>
</dd>
<dt>longitude</dt><dd><p>longitude, in degrees.</p>
</dd>
<dt>ntot</dt><dd><p>sample size per location</p>
</dd>
<dt>npos</dt><dd><p>number of infected individuals per location</p>
</dd>
<dt>maxNDVI</dt><dd><p>maximum normalised-difference vegetation index (NDVI) from repeated satellite scans</p>
</dd>
<dt>seNDVI</dt><dd><p>standard error of NDVI</p>
</dd>
<dt>elev1</dt><dd><p>altitude, in m.</p>
</dd>
<dt>elev2,elev3,elev4</dt><dd><p>Additional altitude variables derived from the previous one, provided for convenience: 
respectively, positive values of altitude-650, positive values of altitude-1000, and positive values of altitude-1300</p>
</dd>
<dt>maxNDVI1</dt><dd><p>a copy of maxNDVI modified as <code>maxNDVI1[maxNDVI1&gt;0.8] &lt;- 0.8</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>The data were last retrieved on March 1, 2013 from P.J. Ribeiro's web resources
at<br /> 
<code>www.leg.ufpr.br/doku.php/pessoais:paulojus:mbgbook:datasets</code>. A current (2022-06-18) source is
<a href="https://www.lancaster.ac.uk/staff/diggle/moredata/Loaloa.txt">https://www.lancaster.ac.uk/staff/diggle/moredata/Loaloa.txt</a>).
</p>


<h3>References</h3>

<p>Diggle, P., and Ribeiro, P. 2007. Model-based geostatistics, Springer series
in statistics, Springer, New York.
</p>
<p>Diggle, P. J., Thomson, M. C., Christensen, O. F., Rowlingson, B., Obsomer,
V., Gardon, J., Wanji, S., Takougang, I., Enyong, P., Kamgno, J., Remme,
J. H., Boussinesq, M., and Molyneux, D. H. 2007. Spatial modelling and
the prediction of Loa loa risk: decision making under uncertainty, Ann.
Trop. Med. Parasitol. 101, 499-509.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Loaloa")
if (spaMM.getOption("example_maxtime")&gt;5) {
  fitme(cbind(npos,ntot-npos)~1 +Matern(1|longitude+latitude),
        data=Loaloa, family=binomial()) 
}

### Variations on the model fit by Diggle et al. 
###    on a subset of the Loaloa data
### In each case this shows the slight differences in syntax,
###    and the difference in 'typical' computation times, 
###    when fit using corrHLfit() or fitme().

if (spaMM.getOption("example_maxtime")&gt;4) {
  corrHLfit(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
                   +Matern(1|longitude+latitude),method="HL(0,1)",
                 data=Loaloa,family=binomial(),ranFix=list(nu=0.5)) 
}
if (spaMM.getOption("example_maxtime")&gt;1.6) {
  fitme(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
                   +Matern(1|longitude+latitude),method="HL(0,1)",
                 data=Loaloa,family=binomial(),fixed=list(nu=0.5)) 
}

if (spaMM.getOption("example_maxtime")&gt;5.8) {
  corrHLfit(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
            +Matern(1|longitude+latitude),
              data=Loaloa,family=binomial(),ranFix=list(nu=0.5))  
}
if (spaMM.getOption("example_maxtime")&gt;2.5) {
  fitme(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
            +Matern(1|longitude+latitude),
              data=Loaloa,family=binomial(),fixed=list(nu=0.5),method="REML")
}

## Diggle and Ribeiro (2007) assumed (in this package notation) Nugget=2/7:
if (spaMM.getOption("example_maxtime")&gt;7) {
  corrHLfit(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
           +Matern(1|longitude+latitude),
             data=Loaloa,family=binomial(),ranFix=list(nu=0.5,Nugget=2/7))  
}
if (spaMM.getOption("example_maxtime")&gt;1.3) {
  fitme(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
           +Matern(1|longitude+latitude),method="REML",
             data=Loaloa,family=binomial(),fixed=list(nu=0.5,Nugget=2/7))  
}

## with nugget estimation:
if (spaMM.getOption("example_maxtime")&gt;17) {
  corrHLfit(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
           +Matern(1|longitude+latitude),
             data=Loaloa,family=binomial(),
             init.corrHLfit=list(Nugget=0.1),ranFix=list(nu=0.5))  
}
if (spaMM.getOption("example_maxtime")&gt;5.5) {
  fitme(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
           +Matern(1|longitude+latitude),
             data=Loaloa,family=binomial(),method="REML",
             init=list(Nugget=0.1),fixed=list(nu=0.5))  
}

</code></pre>

<hr>
<h2 id='LRT'>
ANOVA tables, and likelihood ratio tests of fixed and random effects.
</h2><span id='topic+anova'></span><span id='topic+anova.HLfit'></span><span id='topic+anova.LMLT'></span><span id='topic+LRT'></span>

<h3>Description</h3>

<p>The <code>anova</code> method for fit objects from <span class="pkg">spaMM</span> has two uses: if a single fit object is provided, ANOVA tables may be returned, with specific procedures for univariate-response LMs, GLMs and LMMs (see Details). Alternatively, if a second fit object is provided (<code>object2</code> argument), <code>anova</code> performs as an alias for <code>LRT</code>.  The <code>LRT</code> function here differs from <code><a href="#topic+fixedLRT">fixedLRT</a></code> by its arguments (model fits for <code>LRT</code>, but all arguments required to fit the models for <code>fixedLRT</code>), and by the format of its return value.
</p>
<p><code>LRT</code> performs a likelihood ratio (LR) test between two model fits, the &ldquo;full&rdquo; and the &ldquo;null&rdquo; model fits. It determines which model is the more complete one by comparing model components including the fixed-effect, random-effect, residual-dispersion model specifications, and response families (offsets are ignored). Then, a standard test based on the asymptotic chi-square distribution is performed. In addition, parametric bootstrap p-values can be computed, either using the <em>raw bootstrap</em> distribution of the likelihood ratio, or a bootstrap estimate of the Bartlett correction of the LR statistic.
</p>
<p>These different tests perform diffferently depending on the differences between the two models:<br /> <br /> 
* If the models differ only by their fixed effects, the asymptotic LRT may be anticonservative, but the Bartlett-corrected one is generally well-calibrated. <br /> <br />
* If the two models differ by their random effects, tests based on the chi-square distribution (including their Bartlett-corrected version) may be poorly behaved, as such tests assume unbounded parameters, as contrasted to, e.g., necessarily positive variances. <br />
In such cases the raw boostrap test may be the only reliable test. The procedure aims to detect and report such issues, but may not report all problems: users remain responsible for applying the tests in valid conditions (see <b>Caveats</b> in Details section). In simple cases (such as comparing a fixed-effect to a mixed-effect model with the same fixed-effect term), the chi-square tests may not be reported. In other cases (see Examples) they may otherwise be reported, with a warning when the procedure detects some cases of estimates at the boundary for the full model, or detects cases where the LR statistic of bootstrap replicates is often zero (also suggesting that estimates are at the boundary in such replicates).<br /> <br />
* If the fits differ by the fixed effects terms of their residual-dispersion models (but not by any random effect specification), tests based on the chi-square distribution are reported. A bootstrap can be performed as in other cases.<br />
* Tests for some cases of nested response families (e.g., the Poisson versus its extensions) are tentatively allowed.<br />
* The case where residual-dispersion models of either fit include random effects is problematic as, for such fits, the fitting procedure does not maximize the reported likelihood. Currently the test is prevented when the two fits  differ by their random effects, but is still performed otherwise (see Examples). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
anova(object, object2, type = "2", method="", ...)
#
LRT(object, object2, boot.repl = 0L, resp_testfn = NULL, 
    simuland = eval_replicate, 
    #     many further arguments can be passed to spaMM_boot via the '...'
    #     These include arguments for parallel computations, such as
    # nb_cores, fit_env,
    #     as well as other named arguments and spaMM_boot's own '...'
    ...)    
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRT_+3A_object">object</code></td>
<td>
<p>Fit object returned by a <span class="pkg">spaMM</span> fitting function.</p>
</td></tr>
<tr><td><code id="LRT_+3A_object2">object2</code></td>
<td>
<p>Optional second model fit to be be compared to the first (their order does not matter).</p>
</td></tr>
<tr><td><code id="LRT_+3A_type">type</code></td>
<td>
<p>ANOVA type for LMMs. Note that the default (single-term deletion ANOVA) differs from that of <span class="pkg">lmerTest</span>.</p>
</td></tr> 

<tr><td><code id="LRT_+3A_boot.repl">boot.repl</code></td>
<td>
<p>the number of bootstrap replicates. </p>
</td></tr>
<tr><td><code id="LRT_+3A_resp_testfn">resp_testfn</code></td>
<td>
<p>See argument <code>resp_testfn</code> of <code><a href="#topic+spaMM_boot">spaMM_boot</a></code>.</p>
</td></tr>
<tr><td><code id="LRT_+3A_simuland">simuland</code></td>
<td>

<p>a function, passed to <code><a href="#topic+spaMM_boot">spaMM_boot</a></code>. See argument <code><a href="#topic+eval_replicate">eval_replicate</a></code> for default value and requirements.
</p>
</td></tr>
<tr><td><code id="LRT_+3A_method">method</code></td>
<td>

<p>Only non-default value is <code>"t.Chisq"</code> which forces evaluation of a table of chi-squared tests for each fixed-effect term, using the classical &ldquo;Wald&rdquo; test (see Details). Further methods are available through the ... for specific classes of models.
</p>
</td></tr> 

<tr><td><code id="LRT_+3A_...">...</code></td>
<td>

<p>Further arguments, passed to <code><a href="#topic+spaMM_boot">spaMM_boot</a></code> (e.g., for parallelization) in the case of LRTs. For ANOVA tables, arguments of functions <code><a href="stats.html#topic+anova.lm">anova.lm</a></code> <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>, 
and <code><a href="#topic+as_LMLT">as_LMLT</a></code>, 
respectively for LMs, GLMs and LMMs, may be handled (e.g. the <code>test</code> argument for <code>anova.glm</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>*   The <b>ANOVA-table</b> functionality has been included here mainly to provide access to F tests (including, for LMMs, the &ldquo;Satterthwaite method&rdquo; as developed by Fai and Cornelius, 1996), using pre-existing procedures as template or backend for expediency and familiarity:<br /> 
</p>

<ol>
<li><p> ANOVA tables <b>for LMs and GLMs</b> have been conceived to replicate the functionality, output format and details of base R <code>anova</code>, and therefore replicate some of their limitations, e.g., they only perform sequential analysis (&ldquo;type 1&rdquo;) in the same way as <code>anova.lm</code> and <code>anova.glm</code>. However, a difference occurs for Gamma GLMs, because the dispersion estimates for Gamma GLMs differ between <code>stats::glm</code> and <span class="pkg">spaMM</span> fits (see Details in <code><a href="#topic+method">method</a></code>). Therefore, F tests and Mallows' Cp differ too; results from <span class="pkg">spaMM</span> REML fits being closer than ML fits to those from <code>glm()</code> fits;<br /> </p>
</li>
<li> <p><b>For LMMs</b>, ANOVA tables are provided by interfacing <code>lmerTest::anova</code> (with non-default <code>type</code>). This procedure should handle all types of LMMs that can be fitted by <span class="pkg">spaMM</span>; yet, the displayed information should be inspected to check that some fitted random-effect parameters are not ignored when computing information for the Satterthwaite method. 
</p>
</li>
<li><p>  For fitted models that do not lay within previous categories, such as <b>GLMMs</b>, models with a <b>residual-dispersion</b> submodel, and <b>multivariate-response</b> models, a table of tests for single-term deletions using the classical &ldquo;Wald&rdquo; chi-squared test based on coefficient values and their conditional standard error estimates will be returned. LRTs (moreover, with bootstrap correction) are more reliable than such tests and, as calling them requires a second model to be explicitly specified, they may also help users thinking about the hypothesis they are testing. 
</p>
</li></ol>

<p>* <b>Bootstrap LRTs</b>: A raw bootstrap p-value can be computed from the simulated distribution as <code>(1+sum(t &gt;= t0))/(N+1)</code> where <code>t0</code> is the original likelihood ratio, <code>t</code> the vector of bootstrap replicates and <code>N</code> its length. See Davison &amp; Hinkley (1997, p. 141) for discussion of the adjustments in this formula. However, a computationally more economical use of the bootstrap is to provide a Bartlett correction for the likelihood ratio test in small samples. According to this correction, the mean value <code class="reqn">m</code> of the likelihood ratio statistic under the null hypothesis is computed (here estimated by a parametric bootstrap) and the original LR statistic is multiplied by <code class="reqn">n/m</code> where <code class="reqn">n</code> is the number of degrees of freedom of the test. 
</p>
<p>When models differ by their random-effect specifications, distinguishing the full from the null model is not easy. In particular, equivalent models can be specified by diverse syntaxes, so a simple textual comparison of the random-effect terms may not be enough, and model specifications that hinder such a comparison should be avoided. When differences in random effects are tested, the null distribution of the LR may include a probability mass in 1: the discussion in Details of <code><a href="#topic+get_RLRsim_args">get_RLRsim_args</a></code> applies. 
</p>
<p>* <b>Caveats</b>: (1) An evaluated log-likelihood ratio can be slightly negative, e.g. when a fixed-effect model is compared to a mixed one, or a spatial random effect to a block effect, if parameters of the more complete model are estimated within bounds (e.g., variance&gt;1e-06, or Matern smoothness&gt;0.005) designed to avoid numerical singularities, while the less complete model corresponds to a boundary case (e.g., variance=0, or smoothness=0). The bootstrap procedure tries to identify these cases and then corrects slightly negative logL ratios to 0. (2) The Bartlett correction is applicable when the true distribution of the LRT departs smoothly from the chi-square distribution, but not in cases where it has a probability mass in zero (at typically occurs in the same boundary cases).     
</p>


<h3>Value</h3>

<p><code>LRT</code> returns an object of class <code>fixedLRT</code>, actually a list with typical elements (depending on the options)
</p>
<table>
<tr><td><code>fullfit</code></td>
<td>
<p>the HLfit object for the full model;</p>
</td></tr> 
<tr><td><code>nullfit</code></td>
<td>
<p>the HLfit object for the null model;</p>
</td></tr>
<tr><td><code>basicLRT</code></td>
<td>
<p>A data frame including values of the likelihood ratio chi2 statistic, its degrees of freedom, and the p-value;</p>
</td></tr>
</table>
<p>and, if a bootstrap was performed: 
</p>
<table>
<tr><td><code>rawBootLRT</code></td>
<td>
<p>A data frame including values of the likelihood ratio chi2 statistic, its degrees of freedom, and the raw bootstrap p-value;</p>
</td></tr>
<tr><td><code>BartBootLRT</code></td>
<td>
<p>A data frame including values of the Bartlett-corrected likelihood ratio chi2 statistic, its degrees of freedom, and its p-value;</p>
</td></tr>
<tr><td><code>bootInfo</code></td>
<td>
<p>a list with the following elements:
</p>

<dl>
<dt>bootreps</dt><dd><p>A table of fitted likelihoods for bootstrap replicates;  </p>
</dd>
<dt>meanbootLRT</dt><dd><p>The mean likelihood ratio chi-square statistic for bootstrap replicates;  </p>
</dd>
</dl>
 
</td></tr> 
</table>
<p>When ANOVA tables are computed, the return format is that of the function called (<code>lmerTest::anova</code> for LMMs) or emulated (for LMs or GLMs). For GLMs, by default no test is reported, as has been the default for <code>anova.glm</code> before R 4.4.0.
</p>


<h3>References</h3>

<p>Bartlett, M. S. (1937) Properties of sufficiency and statistical tests. Proceedings of the Royal Society (London) A 160: 268-282.
</p>
<p>Davison A.C., Hinkley D.V. (1997) Bootstrap methods and their applications. Cambridge Univ. Press, Cambridge, UK.
</p>
<p>Fai AH, Cornelius PL (1996). Approximate F-tests of multiple degree of freedom hypotheses in generalised least squares analyses of unbalanced split-plot experiments.
Journal of Statistical Computation and Simulation, 54(4), 363-378. <a href="https://doi.org/10.1080/00949659608811740">doi:10.1080/00949659608811740</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+fixedLRT">fixedLRT</a></code> for a different interface to LRTs,<br /> 
<code><a href="#topic+get_RLRsim_args">get_RLRsim_args</a></code> for efficient simulation-based implementation of exact likelihood ratio tests for testing the presence of variance components,<br />
<code><a href="#topic+as_LMLT">as_LMLT</a></code> for the interface to <code>lmerTest::anova</code>,<br />
and <code><a href="#topic+summary.HLfit">summary.HLfit</a></code><code>(.,details=list(&lt;true|"Wald"&gt;))</code> for reporting the p-value for each t-statistic in the summary table for fixed effects, either by Student's t distribution, or by the approximation of t^2 distribution by the Chi-squared distribution (&ldquo;Wald's test&rdquo;).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
## Gamma GLMM with log link
m1 &lt;- HLfit(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch),family=Gamma(log),
          resid.model = ~ X3+I(X3^2) ,data=wafers,method="ML")
m2 &lt;- update(m1,formula.= ~ . -I(X2^2))
#
anova(m1,m2) # LRT

## 'anova' (Wald chi-squared tests...) for GLMM or model with a 'resid.model'
anova(m1) 

## ANOVA table for GLM
# Gamma example, from McCullagh &amp; Nelder (1989, pp. 300-2), as in 'glm' doc:
clotting &lt;- data.frame(
    u = c(5,10,15,20,30,40,60,80,100),
    lot1 = c(118,58,42,35,27,25,21,19,18),
    lot2 = c(69,35,26,21,18,16,13,12,12))
spglm &lt;- fitme(lot1 ~ log(u), data = clotting, family = Gamma, method="REML")
anova(spglm, test = "F") 
anova(spglm, test = "Cp") 
anova(spglm, test = "Chisq")
anova(spglm, test = "Rao") 

## ANOVA table for LMM
if(requireNamespace("lmerTest", quietly=TRUE)) {
  lmmfit &lt;- fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch),data=wafers)
  print(anova(lmmfit)) # =&gt; Satterthwaite method, here giving p-values 
                       #   quite close to traditional t-tests given by:
  summary(lmmfit, details=list(p_value=TRUE))
}

## Using resp_testfn argument for bootstrap LRT:
## Not run: 
set.seed(1L)
d &lt;- data.frame(success = rbinom(10, size = 1, prob = 0.9), x = 1:10)
xx &lt;- cbind(1,d$x)
table(d$success)
m_x &lt;- fitme(success ~ x, data = d, family = binomial())
m_0 &lt;- fitme(success ~ 1, data = d, family = binomial())
#
# Bootstrap LRTs:
anova(m_x, m_0, boot.repl = 100,
      resp_testfn=function(y) {! is_separated(xx,as.numeric(y),verbose=FALSE)})

## End(Not run)

#### Various cases were asymptotic tests may be unreliable:

set.seed(123)
dat &lt;- data.frame(g = rep(1:10, e = 10), x = (x&lt;-rnorm(100)), 
                   y = 0.1 * x + rnorm(100))
m0 &lt;- fitme(y ~ 1, data=dat) 

## (1) Models differing both by fixed and random effects: 

#
# (note the warning for variance at boundary):
#
if (spaMM.getOption("example_maxtime")&gt;11) { 
  m &lt;- fitme(y ~ x + (1|g), data=dat)
  LRT(m,m0, boot.repl = 199L)
}
## See help("get_RLRsim_args") for a fast and accurate test procedure

## (2) Models differing also by residual-dispersion models:
#
if (spaMM.getOption("example_maxtime")&gt;25) { 
  m &lt;- fitme(y ~ x + (1|g), data=dat, resid.model= ~x)
  LRT(m,m0, boot.repl = 99L)
}

## (3) Models differing (also) by their random-effects in resid.model:
#
m &lt;- fitme(y ~ x, data=dat, resid.model= ~1+(1|g)) 
LRT(m,m0) # no test performed


</code></pre>

<hr>
<h2 id='make_scaled_dist'>Scaled distances between unique locations</h2><span id='topic+make_scaled_dist'></span><span id='topic+rho.mapping'></span><span id='topic+Earth'></span><span id='topic+EarthChord'></span>

<h3>Description</h3>

<p>This function computes scaled distances from whichever relevant argument it can use (see Details). The result can directly by used as input for computation of the Matérn correlation matrix. It is usually called internally by HLCor, so that users may ignore it, except if they wish to control the distance used through <code>control.dist$method</code>, or the parametrization of the scaling through <code>control.dist$rho.mapping</code>. <code>control.dist$method</code> provide access to the distances implemented in the <code>proxy</code> package, as well as to <code>"EarthChord"</code> and <code>"Earth"</code> methods defined in <code>spaMM</code> (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_scaled_dist(uniqueGeo, uniqueGeo2=NULL, distMatrix, rho, 
                 rho.mapping=seq_len(length(rho)), 
                 dist.method="Euclidean",
                 return_matrix=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_scaled_dist_+3A_uniquegeo">uniqueGeo</code></td>
<td>

<p>A matrix of geographical coordinates (e.g. 2 columns for latitude and longitude), without replicates of the same location.  
</p>
</td></tr>
<tr><td><code id="make_scaled_dist_+3A_uniquegeo2">uniqueGeo2</code></td>
<td>

<p>NULL, or a second matrix of geographical coordinates, without replicates of the same location.  
If NULL, scaled distances among <code>uniqueGeo</code> locations are computed. Otherwise, scaled distances between  locations in the two input matrices are computed. 
</p>
</td></tr>
<tr><td><code id="make_scaled_dist_+3A_distmatrix">distMatrix</code></td>
<td>

<p>A distance matrix.
</p>
</td></tr>
<tr><td><code id="make_scaled_dist_+3A_rho">rho</code></td>
<td>

<p>A scalar or vector of positive values. Scaled distance is computed as <code>&lt;distances in each coordinate&gt; * rho</code>, unless a non-trivial
<code>rho.mapping</code> is used.
</p>
</td></tr>
<tr><td><code id="make_scaled_dist_+3A_rho.mapping">rho.mapping</code></td>
<td>

<p>A set of indices controlling which elements of the <code>rho</code> scale vector scales which dimension(s) of the space in which (spatial) 
correlation matrices of random effects are computed. Scaled distance is generally computed as <code>&lt;distances in each coordinate&gt; * rho[rho.mapping]</code>. As shown in the Example, if one wishes to combine isotropic geographical distance and some environmental distance, the coordinates being latitude, longitude and one environmental variable, the scaled distance may be computed
as (say) <code>(lat,long,env) *rho[c(1,1,2)]</code> so that the same scaling <code>rho[1]</code> applies for both geographical coordinates. In this case, <code>rho</code> should have length 2 and <code>rho.mapping</code> should be <code>c(1,1,2)</code>.
</p>
</td></tr>
<tr><td><code id="make_scaled_dist_+3A_dist.method">dist.method</code></td>
<td>
<p><code>method</code> argument of <code>proxy::dist</code> function (by default, <code>"Euclidean"</code>, but other distances are possible (see Details).</p>
</td></tr> 
<tr><td><code id="make_scaled_dist_+3A_return_matrix">return_matrix</code></td>
<td>
<p>Whether to return a <code>matrix</code> rather than a <code>proxy::dist</code> or <code>proxy::crossdist</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the <code>distMatrix</code> argument if provided, in which case rho must be a scalar. Vectorial <code>rho</code> (i.e., different scaling of different dimensions) is feasible only by providing <code>uniqueGeo</code>.
</p>
<p>The <code>dist.method</code> argument gives access to distances implemented in the <code>proxy</code> package, or to user-defined ones that are made accessible to <code>proxy</code> through its database. Of special interest for spatial analyses are distances computed from longitude and latitude (<code>proxy</code> implements <code>"Geodesic"</code> and <code>"Chord"</code> distances but they do not use such coordinates: instead, they use Euclidean distance for 2D computations, i.e. Euclidean distance between points on a circle rather than on a sphere). spaMM implements two such distances: <code>"Earth"</code> and <code>"EarthChord"</code>, using longitude and latitude inputs <b>in that order</b> (see Examples). The <code>"EarthChord"</code> distance is the 3D Euclidean distance &ldquo;through Earth&rdquo;. The <code>"Earth"</code> distance is also known as the orthodromic or great-circle distance, on the Earth surface. Both distances return values in km and are based on approximating the Earth by a sphere of radius 6371.009 km.  
</p>


<h3>Value</h3>

<p>A matrix or <code><a href="proxy.html#topic+dist">dist</a></code> object. If there are two input matrices, rows of the return value correspond to rows of the first matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap")
## a biologically not very meaningful, but syntactically correct example of rho.mapping
fitme(migStatus ~ 1 + Matern(1|longitude+latitude+means),
      data=blackcap, fixed=list(nu=0.5,phi=1e-6),
      init=list(rho=c(1,1)), control.dist=list(rho.mapping=c(1,1,2)))

## Using orthodromic distances: 
# order of variables in Matern(.|longitude+latitude) matters; 
# Matern(1|latitude+longitude) should cause a warning
fitme(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap,
      method="ML", fixed=list(nu=0.5,phi=1e-6),
      control.dist=list(dist.method="Earth"))
</code></pre>

<hr>
<h2 id='mapMM'>
Colorful plots of predictions in two-dimensional space. 
</h2><span id='topic+spaMMplot2D'></span><span id='topic+mapMM'></span><span id='topic+filled.mapMM'></span><span id='topic+map_ranef'></span>

<h3>Description</h3>

<p>These functions provide either a map of predicted response in analyzed locations, or a predicted surface. <code>mapMM</code> is a straightforward representation of the analysis of the data, while <code>filled.mapMM</code> uses interpolation to cope with the fact that all predictor variables may not be known in all locations on a fine spatial grid.  <code>map_ranef</code> maps a single spatial random effect. These three functions takes an <code>HLfit</code> object as input. <code>mapMM</code> calls <code>spaMMplot2D</code>, which is similar but takes a more conventional (x,y,z) input. 
</p>
<p>Using <code>filled.mapMM</code> may involve questionable choices. Plotting a filled contour generally requires prediction in non-observed locations, where predictor variables used in the original data analysis may be missing. In that case, the original model formula cannot be used and an alternative model (controlled by the <code>map.formula</code> argument) must be used to interpolate (not smooth) the predicted values in observed locations (these predictions still resulting from the original analysis based on predictor variables). <code>filled.mapMM</code> always performs such interpolation (it does not allow one to provide values for the predictor variables). As a result (1) <code>filled.mapMM</code> will be slower than a mere plotting function, since it involves the analysis of spatial data; (2) the results may have little useful meaning if the effect of the original predictor variables is not correctly represented by this interpolation step. For example, prediction by interpolation may be biased in a way analogous to prediction of temperature in non-observed locations while ignoring effect of variation in altitude in such locations. Likewise, the <code>variance</code> argument of <code>filled.mapMM</code> allows one only to plot the prediction variance of its own interpolator, rather than that of the input object. 
</p>
<p><code>map_ranef</code> is free of the limitations of <code>filled.mapMM</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaMMplot2D(x, y, z, xrange=range(x, finite = TRUE),
  yrange=range(y, finite = TRUE), margin=1/20, add.map= FALSE, 
  nlevels = 20, color.palette = spaMM.colors, map.asp=NULL,
  col = color.palette(length(levels) - 1), plot.title=NULL, plot.axes=NULL, 
  decorations=NULL, key.title=NULL, key.axes=NULL, xaxs = "i", 
  yaxs = "i", las = 1, axes = TRUE, frame.plot = axes, ...) 

mapMM(fitobject,Ztransf=NULL,coordinates,
  add.points,decorations=NULL,plot.title=NULL,plot.axes=NULL,envir=-3, ...)

filled.mapMM(
  fitobject, Ztransf = NULL, coordinates, xrange = NULL, yrange = NULL, 
  margin = 1/20, map.formula, phi = 1e-05, gridSteps = 41, 
  decorations = quote(points(pred[, coordinates], cex = 1, lwd = 2)),
  add.map = FALSE, axes = TRUE, plot.title = NULL, plot.axes = NULL, 
  map.asp = NULL, variance = NULL, var.contour.args = list(), 
  smoothObject = NULL, return.="smoothObject", ...)

map_ranef(fitobject, re.form, Ztransf=NULL, xrange = NULL, yrange = NULL, 
  margin = 1/20, gridSteps = 41, 
  decorations = quote(points(fitobject$data[, coordinates], cex = 1, lwd = 2)), 
  add.map = FALSE, axes = TRUE, plot.title=NULL, plot.axes=NULL, 
  map.asp = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mapMM_+3A_fitobject">fitobject</code></td>
<td>

<p>The return object of a corrHLfit or fitme call.

</p>
</td></tr>
<tr><td><code id="mapMM_+3A_x">x</code>, <code id="mapMM_+3A_y">y</code>, <code id="mapMM_+3A_z">z</code></td>
<td>

<p>Three vectors of coordinates, with <code>z</code> being expectedly the response.

</p>
</td></tr>
<tr><td><code id="mapMM_+3A_re.form">re.form</code></td>
<td>

<p>A model formula giving the single random effect term to plot, needed only if there are several spatial random effects in the fitted model. In that case, it must be formatted as <code> . ~ &lt;term&gt;</code>, as for the <code>re.form</code> argument of <code>predict.HLfit</code>.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_ztransf">Ztransf</code></td>
<td>

<p>A transformation of the predicted response, given as a function whose only required argument can be a one-column matrix. The name of this argument must be 
<code>Z</code> (not <code>x</code>), as is appropriate for use in <code>do.call(Ztransf,list(Z=Zvalues))</code>. 
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_coordinates">coordinates</code></td>
<td>

<p>The geographical coordinates. By default they are deduced from the model formula. For example if this formula is <code>resp ~ 1 + Matern(1| x + y )</code> the default coordinates are c(&quot;x&quot;,&quot;y&quot;). If this formula is <code>resp ~ 1 + Matern(1| x + y + z )</code>, the user must choose two of the three coordinates.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_xrange">xrange</code></td>
<td>

<p>The x range of the plot (a vector of length 2); by default defined to cover all analyzed points.  
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_yrange">yrange</code></td>
<td>

<p>The y range of the plot (a vector of length 2); by default defined to cover all analyzed points.  
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_margin">margin</code></td>
<td>

<p>This controls how far (in relative terms) the plot extends beyond the x and y ranges of the analyzed points, and is overriden by explicit <code>xrange</code> and <code>yrange</code> arguments.  
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_map.formula">map.formula</code></td>
<td>
<p>NULL, or a formula whose left-hand side is ignored. Provides the formula used for interpolation. If NULL, a default formula with the same spatial effect(s) as in the input <code>fitobject</code> is used.     
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_phi">phi</code></td>
<td>
  
<p>This controls the phi value assumed in the interpolation step. Ideally <code>phi</code> would be zero, but problems with numerically singular matrices may arise when <code>phi</code> is too small.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_gridsteps">gridSteps</code></td>
<td>
<p>The number of levels of the grid of x and y values</p>
</td></tr>
<tr><td><code id="mapMM_+3A_variance">variance</code></td>
<td>
<p>Either NULL, or the name of a component of variance of prediction <em>by the interpolator</em> to be plotted. Must name one of the components that can be returned by <code>predict.HLfit</code>. <code>variance="predVar"</code> is suitable for uncertainty in point prediction.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_var.contour.args">var.contour.args</code></td>
<td>
<p>A list of control parameters for rendering of prediction variances. See <code><a href="graphics.html#topic+contour">contour</a></code> for possible arguments (except <code>x</code>, <code>y</code>, <code>z</code> and <code>add</code>).</p>
</td></tr>
<tr><td><code id="mapMM_+3A_add.map">add.map</code></td>
<td>

<p>Either a boolean or an explicit expression, enclosed in <code>quote</code> (see Examples).
If <code>TRUE</code>, the <code>map</code> function from the <code>maps</code> package (which much therefore the loaded) is used to add a map from its default <code>world</code> database. <code>xrange</code> and <code>yrange</code> are used to select the area, so it is most convenient if the <code>coordinates</code> are longitude and latitude (in this order and in standard units). An explicit expression can also be used for further control.  
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_levels">levels</code></td>
<td>
  
<p>a set of levels which are used to partition the range of z. Must be strictly increasing (and finite). Areas with z values between consecutive levels are painted with the same color.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_nlevels">nlevels</code></td>
<td>
	
<p>if <code>levels</code> is not specified, the range of z, values is divided into *approximately* this many levels (a call to <code><a href="base.html#topic+pretty">pretty</a></code> determines the actual number of levels).
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_color.palette">color.palette</code></td>
<td>
	
<p>a color palette function to be used to assign colors in the plot.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_map.asp">map.asp</code></td>
<td>
  
<p>the y/x aspect ratio of the 2D plot area (not of the full figure including the scale). By default, the scales for x and y are identical unless the x and y ranges are too different. Namely, the scales are identical if (plotted y range)/(plotted x range) is 1/4 &lt; . &lt; 4, and map.asp is 1 otherwise. 
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_col">col</code></td>
<td>
	
<p>an explicit set of colors to be used in the plot. This argument overrides any palette function specification. There should be one less color than levels
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_plot.title">plot.title</code></td>
<td>
	
<p>statements which add titles to the main plot. See Details for differences between functions.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_plot.axes">plot.axes</code></td>
<td>
	
<p>statements which draw axes (and a box) on the main plot. See Details for differences between functions. 
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_decorations">decorations</code></td>
<td>
<p> Either NULL or Additional graphic statements (<code>points</code>, <code>polygon</code>, etc.), enclosed in <code>quote</code> (the default value illustrates the latter syntax).
.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_add.points">add.points</code></td>
<td>
<p>Obsolete, use <code>decorations</code> instead.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_envir">envir</code></td>
<td>
<p>Controls the environment in which <code>plot.title</code>, <code>plot.axes</code>, and 
<code>decorations</code> are evaluated. <code>mapMM</code> calls <code>spaMM2Dplot</code> from where these graphic arguments are evaluated, and the default value -3 means that they are evaluated within the environment from where <code>mapMM</code> was called.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_key.title">key.title</code></td>
<td>
	
<p>statements which add titles for the plot key.
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_key.axes">key.axes</code></td>
<td>
	
<p>statements which draw axes on the plot key. 
</p>
</td></tr>
<tr><td><code id="mapMM_+3A_xaxs">xaxs</code></td>
<td>
<p>the x axis style. The default is to use internal labeling.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_yaxs">yaxs</code></td>
<td>
<p>the y axis style. The default is to use internal labeling.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_las">las</code></td>
<td>
<p>the style of labeling to be used. The default is to use horizontal labeling.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_axes">axes</code>, <code id="mapMM_+3A_frame.plot">frame.plot</code></td>
<td>
<p>logicals indicating if axes and a box should be drawn, as in plot.default.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_smoothobject">smoothObject</code></td>
<td>
<p>Either NULL, or an object inheriting from class <code>HLfit</code> (hence, an object on which <code>predict.HLfit</code> can be called), predicting the response surface in any coordinates. See Details for typical usages.</p>
</td></tr>
<tr><td><code id="mapMM_+3A_return.">return.</code></td>
<td>
<p>character string: see Value</p>
</td></tr>
<tr><td><code id="mapMM_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods. For <code>mapMM</code>, all such arguments are passed to <code>spaMMplot2D</code>; for <code>spaMMplot2D</code>, currently only additional graphical parameters passed to <code>title()</code> (see Details).  For <code>filled.mapMM</code> and <code>map_ranef</code>, these parameters are those that can be passed to <code><a href="#topic+spaMM.filled.contour">spaMM.filled.contour</a></code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>smoothObject</code> argument may be used to redraw a figure faster by recycling the predictor of the response surface returned invisibly by a previous call to <code>filled.mapMM</code>.   
</p>
<p>For <code>smoothObject=NULL</code> (the default), <code>filled.mapMM</code> interpolates the predicted response, with sometimes unpleasant effects. For example, if one interpolates probabilities, the result may not be within [0,1], and then (say) a logarithmic <code>Ztransf</code> may generate NaN values that would otherwise not occur. The <code>smoothObject</code> argument may be used to overcome the default behaviour, by providing an alternative predictor. 
</p>
<p>If you have values for all predictor variables in all locations of a fine spatial grid, <code>filled.mapMM</code> may not be a good choice, since it will ignore that information (see <code>map.formula</code> argument). Rather, one should use <code>predict(&lt;fitobject&gt;,newdata= &lt;all predictor variables &gt;)</code> to generate all predictions, and then either 
<code>spaMM.filled.contour</code> or some other raster functions.
</p>

<p>The different functions are (currently) inconsistent among themselves in the way they handle the <code>plot.title</code> and <code>plot.axes</code> argument:
</p>
<p><b>spaMM.filled.contour</b> behaves like <code>graphics::filled.contour</code>, which (1) handles arguments which are calls such as <code>title(.)</code> or <code>{axis(1);axis(2)}</code>; (2) ignores <code>...</code> arguments if <code>plot.title</code> is missing; and (3) draws axes by default when <code>plot.axes</code> is missing, given <code>axes = TRUE</code>.
</p>
<p>By contrast, <b>filled.mapMM</b> handles arguments which are language expressions such as produced by <code>quote(.)</code> or <code>substitute(.)</code> (see Examples). 
</p>
<p><b>mapMM</b> can handles language expressions, but also accepts at least some calls.
</p>


<h3>Value</h3>

<p><code>filled.mapMM</code> by default returns invisibly the fit object predicting the interpolated response surface; however, for any non-default <code>return.</code> argument (<code>return.="raster"</code> would be recommended to ensure future back-compatibility), it will return a raster of values as a list with elements <code>x</code>, <code>y</code> and <code>z</code>. <code>map_ranef</code> returns invisibly a 3-column matrix containing the spatial coordinates, and the predicted effect <code>z</code> on the linear predictor scale (which is also the scale of the plot, unless a <code>Ztransf</code> is used). <code>mapMM</code> returns invisibly a list with elements <code>x</code>, <code>y</code> and <code>z</code>. Plots are produced as side-effects. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+seaMask">seaMask</a></code> for masking areas in a filled map;
<a href="https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/example_raster.html">https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/example_raster.html</a> for more elaborate plot procedures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap")
bfit &lt;- fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
              fixed=list(lambda=0.5537,phi=1.376e-05,rho=0.0544740,nu=0.6286311))
mapMM(bfit,color.palette = function(n){spaMM.colors(n,redshift=1/2)},add.map=TRUE)
map_ranef(bfit) # providing argument re.form= . ~ Matern(1|longitude+latitude)

if (spaMM.getOption("example_maxtime")&gt;1) {
  ## filled.mapMM takes a bit longer
  # showing 'add.map', 'nlevels', and contour lines for 'variance'
  filled.mapMM(bfit, nlevels=30, add.map=TRUE, plot.axes=quote({axis(1);axis(2)}),
             variance="respVar",
             plot.title=title(main="Inferred migration propensity of blackcaps",
                               xlab="longitude",ylab="latitude"))
                               
  ## Similar plots by ggplot2:
  ## Not run: 
   library(rnaturalearth) # provides sea mask through 'ne_download' function
   library(ggplot2)
   library(sp)
  
   # sea mask 
   sea &lt;- ne_download(scale = 10, type = 'ocean', category = "physical", returnclass = "sf")
   
   # Generation of data.frame for ggplot:
   rastr &lt;- filled.mapMM(bfit, return.="raster")
   spdf &lt;- data.frame(Long=rep(rastr$x, nc), Lat=rastr$y[gl(nr,nc)], z = as.vector(rastr$z))

   ggplot(spdf) + 
     geom_contour_filled(aes(Long,Lat,z=z), bins = 20) +
     guides(fill = "none") +
     geom_sf(data = sea, fill = "black") +
     coord_sf(ylim = range(rastr$y), xlim = range(rastr$x), expand = FALSE)
  
## End(Not run)
                               
}

if (spaMM.getOption("example_maxtime")&gt;3) {
 data("Loaloa")  
 lfit &lt;- fitme(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
                  +Matern(1|longitude+latitude), method="PQL", data=Loaloa,
                  family=binomial(), fixed=list(nu=0.5,rho=2.255197,lambda=1.075))   

 ## longer computation requiring interpolation of 197 points 
 ## Also illustrating effect of 'return.' argument
 res &lt;- filled.mapMM(lfit,add.map=TRUE,plot.axes=quote({axis(1);axis(2)}),
    decorations=quote(points(pred[,coordinates],pch=15,cex=0.3)),
    return.="raster", # so that 'res' is a list representing a raster. 
    plot.title=title(main="Inferred prevalence, North Cameroon",
                     xlab="longitude",ylab="latitude"))
}

</code></pre>

<hr>
<h2 id='mat_sqrt'>
Computation of &ldquo;square root&rdquo; of symmetric positive definite matrix
</h2><span id='topic+mat_sqrt'></span>

<h3>Description</h3>

<p><code>mat_sqrt</code> is not usually directly called by users, but arguments may be passed to it through higher-level calls (see Examples).  
For given matrix <b>C</b>, it computes a factor <b>L</b> such that <b>C</b> = <b>L</b> * t(<b>L</b>), handling issues with nearly-singular matrices.   The default behavior is to try Cholesky factorization, and use <code><a href="base.html#topic+eigen">eigen</a></code> if it fails. 
Matrix roots are not unique (for example, they are lower triangular for <code>t(chol(.))</code>, and symmetric for <code>svd(.)</code>. As matrix roots are used to simulate samples under the fitted model (in particular in the parametric bootstrap implemented in <code>fixedLRT</code>), this implies that for given seed of random numbers, these samples will differ with these different methods (although their distribution should be identical). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mat_sqrt(m = NULL, symSVD = NULL, try.chol = TRUE, condnum=1e12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mat_sqrt_+3A_m">m</code></td>
<td>

<p>The matrix whose 'root' is to be computed. This argument is ignored if <code>symSVD</code> is provided.
</p>
</td></tr>
<tr><td><code id="mat_sqrt_+3A_symsvd">symSVD</code></td>
<td>

<p>A list representing the symmetric singular value decomposition of the matrix which 'root' is to be computed. Must have elements <code>$u</code>, a matrix of eigenvectors, and <code>$d</code>, a vector of eigenvalues. 
</p>
</td></tr>
<tr><td><code id="mat_sqrt_+3A_try.chol">try.chol</code></td>
<td>

<p>If <code>try.chol=TRUE</code>, the Cholesky factorization will be tried. 
</p>
</td></tr>
<tr><td><code id="mat_sqrt_+3A_condnum">condnum</code></td>
<td>
<p> (large) numeric value.  In the case <code>chol()</code> was tried and failed, the matrix is regularized so that its (matrix 2-norm) condition number is reduced to <code>condnum</code> (in version 3.10.0 this correction has been implemented more exactly than in previous versions).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For non-NULL <code>m</code>, its matrix root, with rows and columns labelled according to the columns of the original matrix.
If <code>eigen</code> was used, the symmetric singular value decomposition (a list with members <code>u</code> (matrix of eigenvectors) and <code>d</code> (vector of eigenvalues)) is given as attribute. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## try.chol argument passed to mat_sqrt 
## through the '...' argument of higher-level functions
## such as HLCor, corrHLfit, fixedLRT:
data("scotlip")
HLCor(cases~I(prop.ag/10) +adjacency(1|gridcode)+offset(log(expec)),
      ranPars=list(rho=0.174),adjMatrix=Nmatrix,family=poisson(),
      data=scotlip,try.chol=FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='MaternCorr'>
Matern correlation function and Matern formula term.
</h2><span id='topic+Matern'></span><span id='topic+MaternCorr'></span><span id='topic+MaternCorr.default'></span><span id='topic+MaternCorr.dsCMatrix'></span><span id='topic+MaternCorr.dgCMatrix'></span>

<h3>Description</h3>

<p>The Matérn correlation function describes realizations of Gaussian spatial processes with different smoothnesses 
(i.e. either smooth or rugged surfaces, controlled by the <code class="reqn">\nu</code> parameter). It also includes a <code class="reqn">\rho</code> scaling parameter and an optional 'nugget' parameter. A random effect specified in a model formula as <code>Matern(1|</code><em>&lt;...&gt;</em><code>)</code> has pairwise correlations given by the Matérn function at the scaled Euclidean distance between coordinates specified in <em>&lt;...&gt;</em>, using &ldquo;+&rdquo; as separator (e.g., <code>Matern(1|longitude+latitude)</code>). The Matern family can be used in Euclidean spaces of any dimension; and also for correlations on a sphere (with maximum smoothness <code>nu=0.5</code>). 
</p>
<p>A syntax of the form <code>Matern(1|longitude+latitude %in% grp)</code> can be used to specify a Matern random effect with independent realizations (but identical correlation parameters) for each level of the grouping variable <code>grp</code>. Alternatively, the <code>Matern(&lt;T/F factor&gt;|longitude+latitude)</code> may be used to specify Matern effects specific to individuals identified by the <code>&lt;T/F factor&gt;</code> (see Example with females and males). In that case distinct correlation parameters are fitted for each such Matern term.
</p>
<p>When group-specific autocorrelated random effects are fitted, it may be wise to allow for different means for each group in the Intercept (a message will point this out if the fit results for Matern or Cauchy terms suggest so). 
</p>
<p>By default, <code>fitme</code> and <code>corrHLfit</code> performs optimization over the <code class="reqn">\rho</code> and <code class="reqn">\nu</code> parameters. It is possible to estimate different scaling parameters for the different Euclidean dimensions: see examples in <code><a href="#topic+make_scaled_dist">make_scaled_dist</a></code>.
</p>
<p>The <code>MaternCorr</code> function may be used to vizualise these correlations, using distances as input. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
MaternCorr(d, rho = 1, smoothness, nu = smoothness, Nugget = NULL)
# Matern(1|...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaternCorr_+3A_d">d</code></td>
<td>
<p>A distance or a distance matrix.</p>
</td></tr>
<tr><td><code id="MaternCorr_+3A_rho">rho</code></td>
<td>
<p>A scaling factor for distance. The 'range' considered in some 
formulations is the reciprocal of this scaling factor</p>
</td></tr>
<tr><td><code id="MaternCorr_+3A_smoothness">smoothness</code></td>
<td>
<p>The smoothness parameter, &gt;0. <code class="reqn">\nu=0.5</code> corresponds to the exponential correlation function, 
and the limit function when <code class="reqn">\mu</code> goes to <code class="reqn">\infty</code> is the squared exponential function (as in a Gaussian).</p>
</td></tr>
<tr><td><code id="MaternCorr_+3A_nu">nu</code></td>
<td>
<p>Same as smoothness</p>
</td></tr>
<tr><td><code id="MaternCorr_+3A_nugget">Nugget</code></td>
<td>
<p>(Following the jargon of Kriging) a parameter describing a discontinuous decrease in 
correlation at zero distance. Correlation will always be 1 at <code class="reqn">d=0</code>, and from which it immediately drops to 
(1-Nugget)</p>
</td></tr>
<tr><td><code id="MaternCorr_+3A_...">...</code></td>
<td>
<p>Names of coordinates, using &ldquo;+&rdquo; as separator (e.g., <code>Matern(1|longitude+latitude)</code>. The coordinates are numeric values found in the <code>data</code> data frame provided to the fitting function. No additional declaration of groups, factors, or other specific formatting is required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlation at distance <code class="reqn">d&gt;0</code> is 
</p>
<p style="text-align: center;"><code class="reqn">(1-\textrm{Nugget}) \frac{(\rho d)^\nu  K_\nu(\rho d)}{2^{(\nu - 1)} \Gamma(\nu)}</code>
</p>
 
<p>where
<code class="reqn">K_\nu</code> is the <code><a href="base.html#topic+besselK">besselK</a></code> function of order <code class="reqn">\nu</code>.
</p>
<p>By default the Nugget is set to 0. See one of the examples on data set <code><a href="#topic+Loaloa">Loaloa</a></code> 
for a fit including the estimation of the Nugget.
</p>


<h3>Value</h3>

<p>Scalar/vector/matrix depending on input.</p>


<h3>References</h3>

<p>Stein, M.L. (1999) Statistical Interpolation of Spatial Data: Some Theory for Kriging. Springer, New York.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+corMatern">corMatern</a></code> for an implementation of this correlation function as a <code>corSpatial</code> object for use with <code>lme</code> or <code>glmmPQL</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples in help("HLCor"), help("Loaloa"),  help("make_scaled_dist"), etc.
## Matern correlations in 4-dimensional space:
set.seed(123)
randpts &lt;- matrix(rnorm(20),nrow=5)
distMatrix &lt;- as.matrix(proxy::dist(randpts))
MaternCorr(distMatrix,nu=2)

## Group-specific random effects: 
if (spaMM.getOption("example_maxtime")&gt;1.6) {
  data(Leuca)
  subLeuca &lt;- Leuca[c(1:10,79:88),] # subset of 10 females and 10 males, for faster examples.

  # Independent Matern random effect with different covariance parameters for each sex:
  fitme(fec_div ~ sex + Matern(female|x + y) + Matern(male|x + y),  data = subLeuca) 

  # Independent Matern random effect with the same covariance parameters for each sex:
  fitme(fec_div ~ sex + Matern(1|x+y %in% sex),data=subLeuca)

  # Matern models with random-effects distinct but correlated across sexes 
  # can also be fitted: see Matern examples in help("composite-ranef").   
} 
</code></pre>

<hr>
<h2 id='MaternIMRFa'>
corrFamily constructor for Interpolated Markov Random Field (IMRF) covariance structure approximating a 2D Matern correlation model.
</h2><span id='topic+MaternIMRFa'></span>

<h3>Description</h3>

<p>Reimplements the <code><a href="#topic+IMRF">IMRF</a></code> correlation model approximating a Matern correlation function, through a <code><a href="#topic+corrFamily">corrFamily</a></code> constructor. This allows the efficient joint estimation of the <code>alpha</code> parameter of the approximating Markov random field (in principle related to the smoothness parameter of the <code><a href="#topic+Matern">Matern</a></code> correlation function) together with its <code>kappa</code> parameter. By contrast, random effects terms specified as <code>IMRF(1| . , model = &lt;INLA::inla.spde2.matern result&gt;)</code>  assume a fixed <code>alpha</code>.
</p>
<p>Using this feature requires that the not-on-CRAN package <span class="pkg">INLA</span> (<a href="https://www.r-inla.org">https://www.r-inla.org</a>) is installed so that <code>INLA::inla.spde2.matern</code> can be called for each <code>alpha</code> value. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'># corrFamily constructor:
MaternIMRFa(mesh, tpar = c(alpha = 1.25, kappa = 0.1), fixed = NULL, norm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaternIMRFa_+3A_mesh">mesh</code></td>
<td>

<p>An <code>inla.mesh</code> object as produced by <code>INLA::inla.mesh.2d</code>.
</p>
</td></tr>
</table>
<p>and consistently with the general format of <code><a href="#topic+corrFamily">corrFamily</a></code> constructors:
</p>
<table>
<tr><td><code id="MaternIMRFa_+3A_tpar">tpar</code></td>
<td>

<p>Named numeric vector: template values of the parameters of the model. Better not modified unless you know what you are doing. 
</p>
</td></tr>
<tr><td><code id="MaternIMRFa_+3A_fixed">fixed</code></td>
<td>
<p>NULL or numeric vector, to fix the parameters of this model.</p>
</td></tr>
<tr><td><code id="MaternIMRFa_+3A_norm">norm</code></td>
<td>
<p>Boolean: whether to apply a normalization so that the random effect is homoscedastic (see <code><a href="#topic+IMRF">IMRF</a></code>) for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list suitable as input in the <code>covStruct</code> argument, with the following elements: 
</p>
<table>
<tr><td><code>f</code></td>
<td>
<p>function returning a precision matrix for the random effect in mesh vertices;</p>
</td></tr> 
<tr><td><code>tpar</code></td>
<td>
<p>template parameter vector (see general requirements of a <code><a href="#topic+corrFamily">corrFamily</a></code> descriptor);</p>
</td></tr> 
<tr><td><code>Af</code></td>
<td>
<p>function returning a matrix that implements the prediction of random effect values in data locations by interpolation of values in <code>mesh</code> locations (similarly to <code>INLA::inla.spde.make.A</code>);</p>
</td></tr> 
<tr><td><code>type</code></td>
<td>
<p>specifies that the matrix returned by <code>Cf</code> is a precision matrix rather than a correlation matrix;</p>
</td></tr>  
</table>
<p>and possibly other elements which should not be considered as stable features of the return value.
</p>


<h3>References</h3>

<p>Lindgren F., Rue H., Lindström J. (2011) An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic partial differential equation approach Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73: 423-498. <a href="https://doi.org/10.1111/j.1467-9868.2011.00777.x">doi:10.1111/j.1467-9868.2011.00777.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

if(requireNamespace("INLA", quietly = TRUE)) {

data("Loaloa")

mesh &lt;- INLA::inla.mesh.2d(loc = Loaloa[, c("longitude", "latitude")],
                     max.edge = c(3, 20)) 

### Fit with fixed alpha                     

(fit_MaternIMRF &lt;- fitme(
  cbind(npos,ntot-npos) ~ elev1 + elev2 + elev3 + elev4 + maxNDVI1 + 
        seNDVI +  MaternIMRFa(1|longitude+latitude, mesh, fixed=c(alpha=1.05)),
  family=binomial(), 
  data=Loaloa, verbose=c(TRACE=interactive())) )
   
# For data sets with a small number of locations (as here), fitting
# the Matern model as follows is faster than fitting its MaternIMRFa approximation. 
# Here this appears more than twofold faster

fit_Matern &lt;- fitme(
  cbind(npos,ntot-npos) ~ elev1 + elev2 + elev3 + elev4 + maxNDVI1 + 
        seNDVI + Matern(1|longitude+latitude), 
  fixed=list(nu=0.05),                          # in principle similar to alpha=0.05
  data=Loaloa,family=binomial())   
  
  
  
### Same with variable alpha                     

(fit_MaternIMRF &lt;- fitme(
  cbind(npos,ntot-npos) ~ elev1 + elev2 + elev3 + elev4 + maxNDVI1 + 
        seNDVI + MaternIMRFa(1|longitude+latitude, mesh),         
  family=binomial(), 
  data=Loaloa, verbose=c(TRACE=interactive())) )

# Comparable Matern fit:
fit_Matern &lt;- fitme(
  cbind(npos,ntot-npos) ~ elev1 + elev2 + elev3 + elev4 + maxNDVI1 + 
        seNDVI + Matern(1|longitude+latitude), 
  init=list(nu=0.25), lower=list(nu=0), upper=list(nu=1),
  data=Loaloa,family=binomial())   
  
# Note that the fitted nu and alpha parameters do not quite match each other,
# and that the IMRF likelihood does not really approximate the Matern likelihood.
# Mesh design would also be seen to matter.   

} else print("INLA must be installed to run this example.")


## End(Not run)
</code></pre>

<hr>
<h2 id='method'>
Fitting methods (objective functions maximized)
</h2><span id='topic+method'></span><span id='topic+obsInfo'></span>

<h3>Description</h3>

<p>The <code>method</code> argument of the fitting functions, with possible values <code>"ML"</code>, <code>"REML"</code>,<code>"PQL"</code>, <code>"PQL/L"</code>, and so on, controls whether restricted likelihood techniques are used to estimate residual variance and random-effect parameters, and the way likelihood functions are approximated.
</p>
<p>By default, Laplace approximations are used, as selected by <code>"ML"</code> and <code>"REML"</code> methods. The Laplace approximation to (log-)marginal likelihood can be expressed in terms of the joint log-likelihood of the data and the random effects (or the <em>h</em>-likelihood in works of Lee and Nelder). The Laplace approximation is the joint likelihood minus half the log-determinant of the matrix of second derivatives (Hessian matrix) of the negative joint likelihood with respect to the random effects (observed information matrix). The Laplace approximation to restricted likelihood (for REML estimation) is similarly defined from the Hessian matrix with respect to random effects <b>and</b> fixed effects (for the adventurous, <span class="pkg">spaMM</span> allows some non-standard specification of the fixed effects included in the definition of he Hessian).
</p>
<p>Various additional approximations have been considered. Penalized quasi-likelihood (PQL), as originally defined for GLMMs by Breslow and Clayton (1993), uses a Laplace approximation of restricted likelihood to estimate dispersion parameters, and estimates fixed effects by maximizing the joint likelihood (h-likelihood). Although PQL has been criticized as an approximation of likelihood (and actual implementations may diverge from the original version), it has some interesting inferential properties. <span class="pkg">spaMM</span> allows one to use an ML variant of PQL, named PQL/L.  
</p>
<p>Further approximations defined by Lee, Nelder and collaborators (e.g., Noh and Lee, 2007, for some overview) may mostly be seen as laying between PQL and the full Laplace method in terms of approximation of the likelihood, and as extending them to models with non-gaussian random effects (&ldquo;HGLMs&rdquo;). 
In practice the ML, REML, PQL and PQL/L methods should cover most (all?) needs for GLMMs, and EQL extends the PQL concept to HGLMs. <code>method="EQL"</code> stands for the EQL method of Lee and Nelder (2001). The '+' version includes the d v/ d tau correction described p. 997 of that paper, and the '-' version ignores it. <code>"PQL"</code> can be seen as the version of EQL- for GLMMs. <code>"PQL/L"</code> is PQL without the leverage corrections that characterize REML estimation of random-effect parameters. 
</p>
<p><b><span class="pkg">spaMM</span> uses the observed information matrix by default since version 4.0.0</b>. By contrast, in Laplace approximations of likelihood described in the work of Lee &amp; Nelder, i.e. for mixed-effect models with GLM response families, the information matrix is written in terms of the GLM weights (e.g., Lee &amp; Nelder 2001, p.1004), and is thus effectively the expected information matrix, which differs from the observed information matrix in the case of GLM families with non-canonical link (McCullagh &amp; Nelder 1989, p.42). Therefore, the likelihood approximation based on the expected information matrix differs from the one based on the observed information matrix in the same conditions. 
</p>
<p>For non-GLM response families (currently, the <code><a href="#topic+negbin1">negbin1</a></code>, <code><a href="#topic+beta_resp">beta_resp</a></code> and <code><a href="#topic+betabin">betabin</a></code>), only observed information is available (expected information would at best be quite difficult to evaluate, with no benefits). For GLM response families, use of expected information matrix can be required at a global level by setting <code>spaMM.options(obsInfo=FALSE)</code> or in a specific fit by adding <code>"exp"</code> as a second specifier in the method (e.g., <code>method=c("ML","exp")</code>). This can be distinctly useful (in terms of speed) for fitting models with <code>Gamma(log)</code> response family. Conversely, the <code>"obs"</code> specifier will enforce use of observed information matrix when the alternative is set at a global level.
</p>


<h3>Details</h3>

<p>The <code>method</code> (or <code>HLmethod</code>) argument of fitting functions also accepts values of the form <code>"HL(&lt;...&gt;)"</code>, <code>"ML(&lt;...&gt;)"</code> and <code>"RE(&lt;...&gt;)"</code>, e.g. <code>method="RE(1,1)"</code>, which allow one to experiment with further combinations of approximations. HL and RE are equivalent (both imply an REML correction). The first '1' means that a Laplace approximation to the likelihood is used to estimate fixed effects 
(a '0' would instead mean that the h likelihood is used as the objective function). The second  '1' means that a Laplace approximation to the likelihood or restricted likelihood is used to estimate dispersion parameters, this approximation including the dv/d tau term specifically discussed by Lee &amp; Nelder 2001, p. 997 (a '0' would instead mean that these terms are ignored). It is possible to enforce the EQL approximation for estimation of dispersion parameter (i.e., Lee and Nelder's (2001) method) by adding a third index with value 0. <code>"EQL+"</code> is thus <code>"HL(0,1,0)"</code>, while <code>"EQL-"</code> is <code>"HL(0,0,0)"</code>. <code>"PQL"</code> is EQL- for GLMMs. <code>"REML"</code> is <code>"HL(1,1)"</code>. <code>"ML"</code> is <code>"ML(1,1)"</code>. 
</p>
<p>Some of these distinctions make sense for <b>GLMs</b>, and may help in understanding idiosyncrasies of <code>stats::<a href="stats.html#topic+glm">glm</a></code> for Gamma GLMs. In particular (as stated in the <code>stats::<a href="stats.html#topic+logLik">logLik</a></code> documentation) the logLik of a Gamma GLM fit by <code>glm</code> differs from the exact likelihood. An <code>"ML(0,0,0)"</code> approximation of true ML provides the same log likelihood as <code>stats::logLik</code>. Further, the dispersion estimate returned by <code>summary.glm</code> differs from the one implied by <code>logLik</code>, because <code>summary.glm</code> uses Pearson residuals instead of deviance residuals. This may be confusing, and no <code>method</code> in <span class="pkg">spaMM</span> tries to reproduce simultaneously these distinct features (however, <code><a href="#topic+spaMM_glm">spaMM_glm</a></code> may do so). The dispersion estimate returned by an <code>"HL(.,.,0)"</code> fit matches what can be computed from residual deviance and residual degrees of freedom of a <code>glm</code> fit, but this is not the estimate displayed by <code>summary.glm</code>. The fixed effect estimates are not affected by these tinkerings.     
</p>


<h3>References</h3>

<p>Breslow, NE, Clayton, DG. (1993). Approximate Inference in Generalized Linear Mixed Models.
Journal of the American Statistical Association 88, 9-25.
</p>
<p>Lee, Y., Nelder, J. A. (2001)  Hierarchical generalised linear models: A
synthesis of generalised linear models, random-effect models and structured
dispersions. Biometrika 88, 987-1006.
</p>
<p>McCullagh, P. and Nelder, J.A. (1989) Generalized Linear Models, 2nd edition. London: Chapman &amp; Hall.
</p>
<p>Noh, M., and Lee, Y. (2007). REML estimation for binary data in GLMMs, J.
Multivariate Anal. 98, 896-915.
</p>

<hr>
<h2 id='MSFDR'>
Multiple-Stage False Discovery Rate procedure
</h2><span id='topic+MSFDR'></span>

<h3>Description</h3>

<p>This implements the procedure described by Benjamini and Gavrilov (2009) for model-selection <b>of fixed-effect terms</b> based on False Discovery Rate (FDR) concepts. It uses forward selection based on penalized likelihoods. The penalization for the number of parameters is distinct from that in Akaike's Information Criterion, and variable across iterations of the algorithm (but functions from the <code>stats</code> package for AIC-based model-selection are still called, so that some screen messages refer to AIC). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSFDR(nullfit, fullfit, q = 0.05, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSFDR_+3A_nullfit">nullfit</code></td>
<td>

<p>An ML fit to the minimal model to start the forward selection from; an object of class <code>HLfit</code>.
</p>
</td></tr>
<tr><td><code id="MSFDR_+3A_fullfit">fullfit</code></td>
<td>

<p>An ML fit to the maximal model; an object of class <code>HLfit</code>.
</p>
</td></tr>
<tr><td><code id="MSFDR_+3A_q">q</code></td>
<td>

<p>Nominal error rate of the underlying FDR procedure (expected proportion of
incorrectly rejected null out of the rejected). Benjamini and Gavrilov (2009) recommend <code>q=0.05</code> on the basis of minimizing mean-squared prediction error in various simulation conditions considering only linear models. 
</p>
</td></tr>
<tr><td><code id="MSFDR_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print information about the progress of the procedure.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fit of the final selected model; an object of class <code>HLfit</code>.
</p>


<h3>References</h3>

<p>A simple forward selection procedure based on false discovery rate control. Ann. Appl. Stat, 3, 179-198 (2009).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;1.4) {
data("wafers")
nullfit &lt;- fitme(y~1+(1|batch), data=wafers,family=Gamma(log))
fullfit &lt;- fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, family=Gamma(log))
MSFDR(nullfit=nullfit,fullfit=fullfit)
}
</code></pre>

<hr>
<h2 id='multIMRF'>
Interpolated Markov Random Field models
</h2><span id='topic+IMRF'></span><span id='topic+multIMRF'></span><span id='topic+hyper'></span><span id='topic+str.inla.spde2'></span><span id='topic+inla.spde2.matern'></span><span id='topic+inla.spde2.pcmatern'></span><span id='topic+small_spde'></span>

<h3>Description</h3>

<p><span class="pkg">spaMM</span> can fit random-effect terms of the forms considered by Lindgren et al. (2011) or Nychka et al. (2015, 2018).
The random effects considered here all involve a multivariate Gaussian random effect over a lattice, from which the random-effect value in any spatial position is determined by interpolation of values on the lattice. <b>IMRF</b> stands for <b>I</b>nterpolated <b>M</b>arkov <b>R</b>andom <b>F</b>ield because the specific process considered on the lattice is currently known as a Gaussian Markov Random Field (see the Details for further information). Lindgren et al. considered irregular lattices designed to approximate of the Matern correlation model with fixed smoothness &lt;= 2, while Nychka et al. considered regular grids. 
</p>
<p>The correlation model of Lindgren et al. (2011) can be fitted by <span class="pkg">spaMM</span> by declaring an <code>IMRF</code> random effect term in the model formula, with a <code>model</code> argument in the right-hand side whose value is the result of <code>INLA::inla.spde2.matern</code> (or <code>INLA::inla.spde2.pcmatern</code>) for given smoothness. The <span class="pkg">spaMM</span> functions for such a fit do not call <span class="pkg">INLA</span> functions. Alternatively, the same model with variable smoothness can be fitted by declaring a <code>corrFamily</code> term whose structure is described through the <code><a href="#topic+MaternIMRFa">MaternIMRFa</a></code> function, whose respective documentations should be considered for more details. In the latter case <code>INLA::inla.spde2.matern</code> is called internally by <code>spaMM</code>. The correlation models thus defined are fitted by the same methods as other models in <span class="pkg">spaMM</span>.     
</p>
<p>Regular lattices can also be declared as an <code>IMRF</code> term (with arguments distinct from <code>model</code>). The <code>multIMRF</code> syntax implements the multiresolution model of Nychka et al. Any <code>multIMRF</code> term in a formula is immediately converted to <code>IMRF</code> terms for regular grids wih different step sizes. This has distinct implications for controlling the parameters of these or other random effects in the model by <code>init</code> or <code>fixed</code> values: see Details if you need such control. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'># IMRF( 1 | &lt;coordinates&gt;, model, nd, m, no, ce, ...) 
# multIMRF( 1 | &lt;coordinates&gt;, levels, margin, coarse=10L, 
#            norm=TRUE, centered=TRUE ) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multIMRF_+3A_model">model</code></td>
<td>
<p>An <code>inla.spde2</code> object as produced by <code>INLA::inla.spde2.matern</code> or<br /> 
<code>INLA::inla.spde2.pcmatern</code> (see Examples below, and <a href="https://www.r-inla.org">https://www.r-inla.org</a> for further information).
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_levels">levels</code></td>
<td>
<p>integer; 
Number of levels in the hierarchy, i.e. number of component IMRFs.
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_margin">margin</code>, <code id="multIMRF_+3A_m">m</code></td>
<td>
<p>integer; 
width of the margin, as a number of additional grid points on each side (applies to all levels of the hierarchy).
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_coarse">coarse</code></td>
<td>
<p>integer; 
number of grid points (excluding the margins) per dimension for the coarsest IMRF. The number of grids steps nearly doubles with each level of the hierarchy (see Details). 
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_nd">nd</code></td>
<td>
<p>integer; 
number of grid steps (excluding the margins) per dimension for the given IMRF. 
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_norm">norm</code>, <code id="multIMRF_+3A_no">no</code></td>
<td>
<p>Boolean; whether to apply normalization (see Details), or not.
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_centered">centered</code>, <code id="multIMRF_+3A_ce">ce</code></td>
<td>
<p>Boolean; whether to center the grid in all dimensions, or not.
</p>
</td></tr>
<tr><td><code id="multIMRF_+3A_...">...</code></td>
<td>
<p>Not documented, for programming purposes</p>
</td></tr> 
</table>


<h3>Details</h3>

<p><b>Formulation of the covariance models:</b>
</p>
<p>Gaussian Markov Random Field (MRF) and conditional autoregressive models are essentially the same thing, apart from details of specification. 
<code><a href="#topic+adjacency">adjacency</a></code> and <code><a href="#topic+AR1">AR1</a></code> random effects can be seen as specific MRFs.  
The common idea is the Markov-like property that the distribution of each element <code class="reqn">b_i</code> of the random-effect <b>b</b>, given values of a few specific elements (the &ldquo;neighbours&rdquo; of <code class="reqn">i</code>), is independent of other elements (i.e., of non-neighbours). The non-zero non-diagonal elements of a precision matrix characterize the neighbours. 
</p>
<p>Given the inferred vector <b>b</b> of values of the MRF on the lattice, the interpolation of the MRF in any focal point is of the form <b>Ab</b> where each row of <b>A</b> weights the values of <b>b</b> according to the position of the focal point relative to the vertices of the lattice. Following the original publications,<br /> 
<code style="white-space: pre;">&#8288; * &#8288;</code>for grids given by <code>model=&lt;inla.spde2 object&gt;</code>, the non-zero weights are the barycentric coordinates of the focal point in the enclosing triangle from the mesh triangulation (points from outside the mesh would have zero weights, so the predicted effect <b>Ab=0</b>);<br /> 
<code style="white-space: pre;">&#8288; * &#8288;</code>for regular grids (NULL <code>model</code>), the weights are computed as &lt;Wendland function&gt;(&lt;scaled Euclidean distances between focal point and vertices&gt;). 
</p>
<p>The <code>IMRF</code> model defines both a lattice in space, the precision matrix for a Gaussian MRF over this lattice, and the <b>A</b> matrix of weights. The full specification of the MRF on <b>irregular lattices</b> is complex. The <code class="reqn">\kappa</code> (<code>kappa</code>) parameter considered by <code>spaMM</code> is the <code class="reqn">\kappa</code> scale parameter considered by Lindgren et al and comparable to the <code class="reqn">\rho</code> scale factor of the Matérn model. The <code class="reqn">\alpha</code> argument of the <code>INLA::inla.spde2.matern</code> controls the smoothness of the approximated Matern model, as <code class="reqn">\alpha=\nu + d/2</code>) where <code class="reqn">d</code> is the dimension of the space.   
Correlation models created by <code>INLA::inla.spde2.pcmatern</code> are handled so as to give the same correlation values as when <code>INLA::inla.spde2.matern</code> is used with the same <code>mesh</code> and <code>alpha</code> argument (thus, the extra functionalities of &ldquo;<code>pc</code>&rdquo;<code>matern</code> are ignored). 
</p>
<p>Not all options of the INLA functions may be compatible or meaningful when used with spaMM (only the effects of <code>alpha</code> and <code>cutoff</code> have been checked). 

</p>
<p><b>Normalization</b>:
</p>
<p>For the MRFs on default <b>regular grids</b> (missing <code>model</code> argument), the precision matrix is defined (up to a variance parameter) as <b>M'M</b> where the diagonal elements <code class="reqn">m_{ii}</code> of <b>M</b> are 4+<code class="reqn">\kappa^2</code> and the <code class="reqn">m_{ij}</code> for the four nearest neighbours are -1 (note that <b>M'M</b> involves more than these four neighbours). The precision matrix defined in this way is the inverse of an heteroscedastic covariance matrix <b>C</b>, but (following Nychka et al.) by default a normalization is applied so that the random effect in each data position is homoscedastic (the precision matrix for the latent effect in grid positions is not modified, but it is the <b>A</b> matrix of weights which is is modified). As for other random effects, the variance is further controlled by a multiplicative factor <code class="reqn">\lambda</code>. 
</p>
<p>Without normalization, the covariance matrix of the random effect in data locations is <code class="reqn">\lambda</code><b>ALL'A'</b> (<b>A</b> being the above-described weight matrix, and <b>L</b> is a &ldquo;square root&rdquo; of <b>C</b>), and  <b>AL</b> is the original &ldquo;design matrix&rdquo; of the random effect. <code class="reqn">\lambda</code> may then be quite different from the marginal variance of the random effect, and is difficult to describe in a simple way. 
For normalization, <b>A</b> is modified as <b>WA</b> where <b>W</b> is a diagonal matrix such that <b>WAL</b> is a correlation matrix (<b>WALL'A'W'</b> has unit diagonal); then, <code class="reqn">\lambda</code> is the marginal variance of the random effect. 
</p>
<p>For irregular grids specified using the <code>model</code> argument, the precision matrix described by this object is also the inverse of an heteroscedastic covariance matrix, but here (again following original publicatiosn such as Lindgren at al. 2011) the normalization is not applied by default (and was not even an option before version 4.3.23). But for ease of presentation and interpretation, if for no other reason, the normalized model may be preferable. 
</p>
<p><b>Details for rectangular grids:</b> 
</p>
<p>By default (meaning in particular that <code>model</code> is not used to specify a lattice defined by the INLA procedures), the IMRF lattice is rectangular (currently the only option) and is made of a core lattice, to which margins of <code>margin</code> steps are added on each side. The core lattice is defined as follows: in each of the two spatial dimensions, the range of axial coordinates is determined. The largest range is divided in <code>nd-1</code> steps, determining <code>nd</code> values and step length <code class="reqn">L</code>. The other range is divided in steps of the same length <code class="reqn">L</code>. If it extends over (say) <code class="reqn">2.5 L</code>, a grid of 2 steps and 3 values is defined, and by default centered on the range (the extreme points therefore typically extend slightly beyond the grid, within the first of the additional steps defined by the <code>margin</code>; if not centered, the grid start from the lower coordinate of the range).
</p>
<p><code>multIMRF</code> implements multilevel IMRFs. It defines a sequence of IMRFs, with progressively finer lattices, a common <code class="reqn">\kappa</code> value <code>hy_kap</code> for these IMRFs, and a single variance parameter <code>hy_lam</code> that determines <code class="reqn">\lambda</code> values decreasing by a factor of 4 for successive IMRF terms. By default, each component <code>IMRF</code> is normalized independently as described above (as in Nychka et al. 2019), and <code>hy_lam</code> is the sum of the variances of these terms (e.g., if there are three levels and <code>hy_lam=1</code>, the successive variances are (1,1/4,1/16)/(21/16) ). The <code>nd</code> of the first IMRF is set to the <code>coarse</code> value, and its lattice is defined accordingly. If <code>coarse=4</code>  and <code>margin=5</code>, a grid of 14 coordinates is therefore defined over the largest range. In the second IMRF, the grid spacing is halved, so that new steps are defined halfway between the previous ones (yielding a grid of 27 step in the widest range). The third IMRF proceeds from the second in the same way, and so on.
</p>
<p>To control initial or fixed values of <code>multIMRF</code> <code class="reqn">\kappa</code> and variance parameters, which are hyper-parameter controlling several <code>IMRF</code> terms, the <code>hyper</code> syntax shown in the Examples should be used. <code>hyper</code> is a nested list whose possible elements are named <code>"1"</code>, <code>"2"</code>, ... referring to successive <code>multIMRF</code> terms in the input formula, not to successive random effect in the expanded formula with distinct IMRF terms (see Examples). But the different IMRF terms should be counted as distinct random effects when controlling other parameters (e.g., for fixing the variances of other random effects).
</p>


<h3>References</h3>

<p>D. Nychka, S. Bandyopadhyay, D. Hammerling, F. Lindgren, S. Sain (2015)
A multiresolution gaussian process model for the analysis of large spatial datasets.
Journal of Computational and Graphical Statistics 24 (2), 579-599. <a href="https://doi.org/10.1080/10618600.2014.914946">doi:10.1080/10618600.2014.914946</a>
</p>
<p>D. Nychka, D. Hammerling, Mitchel. Krock, A. Wiens (2018) Modeling and emulation of nonstationary Gaussian fields. Spat. Stat. 28: 21-38. <a href="https://doi.org/10.1016/j.spasta.2018.08.006">doi:10.1016/j.spasta.2018.08.006</a>
</p>

<p>Lindgren F., Rue H., Lindström J. (2011) An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic partial differential equation approach Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73: 423-498. <a href="https://doi.org/10.1111/j.1467-9868.2011.00777.x">doi:10.1111/j.1467-9868.2011.00777.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (spaMM.getOption("example_maxtime")&gt;6) {

data("blackcap") ## toy examples; but IMRF may be useful only for much larger datasets
## and when using the 'cutoff' parameter of INLA::inla.mesh.2d()

########################## Irregular lattice specified by 'model':
#
data("small_spde") ## load object of class 'inla.spde2', created and saved by :
  # spd &lt;- sp::SpatialPointsDataFrame(coords = blackcap[, c("longitude", "latitude")],
  #                            data = blackcap)
  # small_mesh &lt;- INLA::inla.mesh.2d(loc = INLA::inla.mesh.map(sp::coordinates(spd)), 
  #                           max.n=100, # only for demonstration purposes
  #                           max.edge = c(3, 20)) 
  # small_spde &lt;- INLA::inla.spde2.matern(small_mesh)
  # save(small_spde, file="small_spde.RData", version=2)
#  
fit_SPDE &lt;- fitme(migStatus ~ means + IMRF(1|longitude+latitude, model=small_spde), 
                  data=blackcap)
                  
########################## Regular lattices:   
# 
#Using 'hyper' to control fixed hyper-parameters
#
(mrf &lt;- fitme(migStatus ~ 1 + (1|pos) + 
                          multIMRF(1|longitude+latitude,margin=5,levels=2), 
              data=blackcap, fixed=list(phi=1,lambda=c("1"=0.5),
              hyper=list("1"=list(hy_kap=0.1,hy_lam=1)))) )
              
# Using 'hyper' to control initial hyper-parameters
#
(mrf &lt;- fitme(migStatus ~ 1 + multIMRF(1|longitude+latitude,margin=5,levels=2),
                data=blackcap, method="ML", fixed =list(phi=1),
                init=list(hyper=list("1"=list(hy_kap=0.1,hy_lam=1)))) )
                
# *Independent* IMRF terms with default rectangular lattice (often giving dubious results)
#
(mrf &lt;- fitme(migStatus ~ 1 + IMRF(1|longitude+latitude,margin=5, nd=4L)
                              + IMRF(1|longitude+latitude,margin=5, nd=7L),
          data=blackcap,  
          fixed=list(phi=1,lambda=c(1/4,1/16),
                       corrPars=list("1"=list(kappa=0.1),"2"=list(kappa=0.1)))))
                    
}
</code></pre>

<hr>
<h2 id='multinomial'>Analyzing multinomial data</h2><span id='topic+multinomial'></span><span id='topic+binomialize'></span><span id='topic+multi'></span><span id='topic+fitted.HLfitlist'></span><span id='topic+logLik.HLfitlist'></span>

<h3>Description</h3>

<p>These functions facilitate the conversion and analysis of multinomial data as as series of nested binomial data.
The main interface is the <code>multi</code> &ldquo;family&rdquo;, to be used in the <code>family</code> argument of the fitting functions.
Fits using it call <code>binomialize</code>, which can be called directly to check how the data are converted to nested binomial data, and to use these data directly. 
The <code>fitted.HLfitlist</code> method of the <code>fitted</code> generic function returns a matrix of fitted multinomial probabilities.
The <code>logLik.HLfitlist</code> method of the <code>logLik</code> generic function returns a log-likelihood for the joint fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi(binResponse=c("npos","nneg"),binfamily=binomial(),input="types",...)
binomialize(data,responses,sortedTypes=NULL,binResponse=c("npos","nneg"),
             depth=Inf,input="types")
## S3 method for class 'HLfitlist'
fitted(object, version=2L, ...)
## S3 method for class 'HLfitlist'
logLik(object,which,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multinomial_+3A_data">data</code></td>
<td>

<p>The data frame to be analyzed.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_object">object</code></td>
<td>

<p>A list of binomial fits returned by a multinomial analysis
</p>
</td></tr> 
<tr><td><code id="multinomial_+3A_responses">responses</code></td>
<td>

<p>column names of the data, such that <code>&lt;data&gt;[,&lt;responses&gt;]</code> contain the multinomial response data, as levels of factor variables.   
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_sortedtypes">sortedTypes</code></td>
<td>

<p>Names of multinomial types, i.e. levels of the multinomial response factors. Their order determines  which types are taken first to define the nested binomial samples. By default, the most common types are considered first.   
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_binresponse">binResponse</code></td>
<td>

<p>The names to be given to the number of &ldquo;success&rdquo; and &ldquo;failures&rdquo; in the binomial response. 
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_depth">depth</code></td>
<td>

<p>The maximum number of nested binomial responses to be generated from the multinomial data.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_binfamily">binfamily</code></td>
<td>

<p>The family applied to each binomial response.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_input">input</code></td>
<td>

<p>If <code>input="types"</code>, then the <code>responses</code> columns must contain factor levels of the binomial response.
If <code>input="counts"</code>, then the <code>responses</code> columns must contain counts of different factor levels, and the column names are the types.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_which">which</code></td>
<td>
<p>Which element of the <code>APHLs</code> list to return. The default depends on the fitting method.In particular, if it was REML or one of its variants, the function returns the log restricted likelihood (exact or approximated).</p>
</td></tr>
<tr><td><code id="multinomial_+3A_version">version</code></td>
<td>

<p>Integer, for <code>fitted.HLfitlist</code> (i.e. for multinomial fits using <code><a href="#topic+multi">multi</a></code>); <code>1</code> will provide the result of past versions up to 3.5.0 (See Value). 
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_...">...</code></td>
<td>

<p>Other arguments passed from or to other functions.
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>A multinomial response, say counts 17, 13, 25, 8, 3, 1 for types <code>type1</code> to <code>type6</code>, can be represented as a series of nested binomials
e.g. <code>type1</code> against others (17 vs 50) then among these 50 others, <code>type2</code> versus others (13 vs 37), etc.
The <code>binomialize</code> function generates such a representation. By default the representation considers types in decreasing order of the number of positives, i.e. first <code>type3</code> against others (25 vs 42), then <code>type1</code> against others within these 42, etc. It stops if it has reached <code>depth</code> nested binomial responses. This can be modified by the <code>sortedTypes</code> argument, e.g. <code>sortedTypes=c("type6","type4","type2")</code>. 
<code>binomialize</code> returns a list of data frames which can be directly provided as a <code>data</code> argument for the fitting functions, with binomial response.
</p>
<p>Alternatively, one can provide the multinomial response data frame, which will be internally converted to nested binomial data if the <code>family</code> argument is a call to <code>multinomial</code> (see Examples).    
</p>
<p>For mixed models, the multinomial data can be fitted to a model with the same correlation parameters, and either the same or different variances of random effects, for all binomial responses. Which analysis is performed depends on whether the variances are fitted by &ldquo;outer optimization&rdquo; or by <code>HLfit</code>'s &ldquo;inner iterative&rdquo; algorithm, as controlled by the <code>init</code> or <code>init.corrHLfit</code> arguments (see Examples). These initial values therefore affect the definition of the model being fitted.      
<code>corrHLfit</code> will fit different variances by default. Adding an <code>init.corrHLfit</code> will force estimation of a single variance across models. <code>fitme</code>'s default optimization strategy is more complex, and has changed and still change over versions. This creates a <b>back-compatibility issue</b> where the model to be fitted may change over versions of spaMM. To avoid that, it is strongly advised to use an explicit initial value when fitting a <code>multi</code> model by <code>fitme</code>.        
</p>


<h3>Value</h3>

<p><code>binomialize</code> returns a list of data frames appropriate for analysis as binomial response. Each data frame contains the original one plus
two columns named according to <code>binResponse</code>. 
</p>
<p>The main fitting functions, when called on a model with <code>family=multi(.)</code>, return an object of  class <code>HLfitlist</code>, which is a list with attributes. The list elements are fits of the nested binomial models (objects of class <code>HLfit</code>). The attributes provide additional information about the overall multinomial model, such as global log-likelihood values and other information properly extracted by the <code>how()</code> function.  
</p>
<p><code>multi</code> is a function that returns a list, but users may never need to manipulate this output.
</p>
<p><code>fitted.HLfitlist</code> returns a matrix. The current default <code>version=2L</code> provides meaningful fitted values (predicted multinomial frequencies for each response type) even for data rows where the nested binomial fit for a type had no response information remaining. By contrast, the first version provided a matrix with <code>0</code>s for these row*fit combinations, except for the last column; in many cases this may be confusing.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Adding colour to the famous 'iris' dataset:
iriscol &lt;- iris
set.seed(123) # Simulate colours, then fit colour frequencies:
iriscol$col &lt;- sample(c("yellow", "purple", "blue"),replace = TRUE, 
                      size = nrow(iriscol), prob=c(0.5,0.3,0.2))
colfit &lt;- fitme(cbind(npos,nneg) ~ 1+(1|Species), family=multi(responses="col"), 
                data=iriscol, init=list(lambda=NA)) # note warning if no 'init'...
head(fitted(colfit))

# To only generate the binomial datasets:
binomialize(iriscol,responses="col")

## An example considering pseudo-data at one diploid locus for 50 individuals 
set.seed(123)
genecopy1 &lt;- sample(4,size=50,prob=c(1/2,1/4,1/8,1/8),replace=TRUE)
genecopy2 &lt;- sample(4,size=50,prob=c(1/2,1/4,1/8,1/8),replace=TRUE)
alleles &lt;- c("122","124","126","128")
genotypes &lt;- data.frame(type1=alleles[genecopy1],type2=alleles[genecopy2])
## Columns "type1","type2" each contains an allele type =&gt; input is "types" (the default)
datalist &lt;- binomialize(genotypes,responses=c("type1","type2"))

## two equivalent fits:
f1 &lt;- HLfit(cbind(npos,nneg)~1,data=datalist, family=binomial())
f2 &lt;- HLfit(cbind(npos,nneg)~1,data=genotypes, family=multi(responses=c("type1","type2")))
fitted(f2)

if (spaMM.getOption("example_maxtime")&gt;1.7) {

##### Control of lambda estimation over different binomial submodels

genoInSpace &lt;- data.frame(type1=alleles[genecopy1],type2=alleles[genecopy2],
                          x=runif(50),y=runif(50))
method &lt;- "PQL" # for faster exampple

## Fitting distinct variances for all binomial responses:           

multifit &lt;- corrHLfit(cbind(npos,nneg)~1+Matern(1|x+y),data=genoInSpace, 
                      family=multi(responses=c("type1","type2")),
                      ranFix=list(rho=1,nu=0.5), method=method)
length(unique(unlist(lapply(multifit, get_ranPars, which="lambda")))) # 3   

multifit &lt;- fitme(cbind(npos,nneg)~1+Matern(1|x+y),data=genoInSpace, 
                  family=multi(responses=c("type1","type2")),
                  init=list(lambda=NaN), # forcing 'inner' estimation for fitme 
                  fixed=list(rho=1,nu=0.5), method=method)
length(unique(unlist(lapply(multifit, get_ranPars, which="lambda")))) # 3          

## Fitting the same variance for all binomial responses:           

multifit &lt;- fitme(cbind(npos,nneg)~1+Matern(1|x+y),data=genoInSpace, 
                  family=multi(responses=c("type1","type2")),
                  init=list(lambda=NA), # forcing 'outer' estimation for fitme 
                  fixed=list(rho=1,nu=0.5), method=method)
length(unique(unlist(lapply(multifit, get_ranPars, which="lambda")))) # 1          

multifit &lt;- 
  corrHLfit(cbind(npos,nneg)~1+Matern(1|x+y),data=genoInSpace, 
            family=multi(responses=c("type1","type2")),
            init.corrHLfit=list(lambda=1), # forcing 'outer' estimation for corrHLfit 
            ranFix=list(rho=1,nu=0.5), method=method)
length(unique(unlist(lapply(multifit, get_ranPars, which="lambda")))) # 1          
}
</code></pre>

<hr>
<h2 id='mv'>
Virtual factor for multivariate responses
</h2><span id='topic+mv'></span>

<h3>Description</h3>

<p><b>Motivation</b>: In a multivariate-response model fitted by <code>fitmv</code>, one may wish to fit a random-coefficient term appearing in <em>s</em> submodels, that is a random effect with realized values for each of these submodels and each group, with values possibly correlated among submodels within groups. Hence one might wish to specify it as a term of the form <code>(&lt;submodel&gt;|group)</code>, where <code>&lt;submodel&gt;</code> would represent a factor for the <em>s</em> submodels. But the data are not expected to contain a factor for these submodels, so such a syntax would not work without substantial data reshaping. Instead, this effect can be stated as <code>mv(...)</code> where the <code>...</code> are the indices of the submodels here the random effect appears. For example if submodels 2 and 3 include this random-coefficient term, the term can be specified as <code>(mv(2,3)|group)</code>. 
</p>
<p>The <code>mv(...)</code> expression is treated as a factor for all purposes, meaning or example that <code>(0+mv(2,3)|group)</code> can also be used, leading (as for any factor) to an alternative parametrization of the same random-coefficient model (see Examples). The random-effect term is treated as a random-coefficient term for all purposes, meaning for example that fixed values can be specified for it using the <code>ranCoefs</code> syntax (see Examples).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'># mv(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mv_+3A_...">...</code></td>
<td>

<p>Indices of all the submodels where the random effect involving this virtual factor appears.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Not a function, hence no return value. In the summary of the fit, levels for the different submodels <em>s</em> within each group are labelled <code>.mv</code><em>s</em>.
</p>


<h3>See Also</h3>

<p>The <code>X2X</code> argument of <code><a href="#topic+fitmv">fitmv</a></code> for fixed effects shared across sub-models.</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;1.1) {
## data preparation
data("wafers")
me &lt;- fitme(y ~ 1+(1|batch), family=Gamma(log), data=wafers, fixed=list(lambda=0.2))

set.seed(123)
wafers$y1 &lt;- simulate(me, type="marginal")
wafers$y2 &lt;- simulate(me, type="marginal")

## fits
(fitmv1 &lt;- fitmv(
  submodels=list(mod1=list(formula=y1~X1+(mv(1,2)|batch), family=Gamma(log)),
                 mod2=list(formula=y2~X1+(mv(1,2)|batch), family=Gamma(log))), 
  data=wafers))
# alternative '0+' parametrization of the same model:
(fitmv2 &lt;- fitmv(
  submodels=list(mod1=list(formula=y1~X1+(0+mv(1,2)|batch), family=Gamma(log)),
                 mod2=list(formula=y2~X1+(0+mv(1,2)|batch), family=Gamma(log))), 
  data=wafers)) 
# relationship between the *correlated* effects of the two fits
ranef(fitmv2)[[1]][,2]-rowSums(ranef(fitmv1)[[1]]) # ~ 0

# fit with given correlation parameter: 
update(fitmv2, fixed=list(ranCoefs=list("1"=c(NA,-0.5,NA)))) 
}
</code></pre>

<hr>
<h2 id='negbin'>
Family function for negative binomial &ldquo;2&rdquo; response (including truncated variant).
</h2><span id='topic+negbin'></span><span id='topic+negbin2'></span><span id='topic+Tnegbin'></span>

<h3>Description</h3>

<p>Returns a GLM <code><a href="stats.html#topic+family">family</a></code> object for negative-binomial model with variance quadratically related to the mean <code class="reqn">\mu</code>: variance=<code class="reqn">\mu+\mu^2</code>/shape, where the shape parameter need or need not be specified, depending on usage. The zero-truncated variant can be specified as <code>negbin2(., trunc = 0L)</code>. See <code><a href="#topic+negbin1">negbin1</a></code> for the alternative negative-binomial model with variance &ldquo;linearly&rdquo; related to the mean. 
</p>
<p>A <b>fixed-effect</b> residual-dispersion model can be fitted, using the <code><a href="#topic+resid.model">resid.model</a></code> argument, which is used to specify the form of the logarithm of the shape parameter. Thus the variance of the response become <code class="reqn">\mu+\mu^2</code>/<code>exp(&lt;specified linear expression&gt;)</code>.
</p>
<p><code>negbin(.)</code> is an alias for <code>negbin2(.)</code> (truncated or not), and <code>Tnegbin(.)</code> is an alias for <code>negbin2(., trunc = 0L)</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'># (the shape parameter is actually not requested unless this is used in a glm() call)
#
negbin2(shape = stop("negbin2's 'shape' must be specified"), link = "log", trunc = -1L, 
        LLgeneric = TRUE)

# For use with glm(), both negbin2's 'shape' and glm's method="llm.fit" are needed.  

# alias with distinct arguments:
Tnegbin(shape = stop("Tnegbin's 'shape' must be specified"), link = "log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negbin_+3A_shape">shape</code></td>
<td>

<p>Shape parameter of the underlying Gamma distribution: the present negative binomial distribution can be represented as a Poisson-Gamma mixture, where the conditional Poisson mean is <code class="reqn">\mu</code> times a Gamma random variable with mean 1 and variance  <code>1/shape</code> (as produced by <code>rgamma(., shape=shape,scale=1/shape)</code>). 
</p>
</td></tr>
<tr><td><code id="negbin_+3A_link">link</code></td>
<td>

<p>log, sqrt or identity link, specified by any of the available ways for GLM links (name, character string, one-element character vector, or object of class <code>link-glm</code> as returned by <code><a href="stats.html#topic+make.link">make.link</a></code>). 
</p>
</td></tr>
<tr><td><code id="negbin_+3A_trunc">trunc</code></td>
<td>

<p>Either <code>0L</code> for zero-truncated distribution, or <code>-1L</code> for default untruncated distribution.
</p>
</td></tr>
<tr><td><code id="negbin_+3A_llgeneric">LLgeneric</code></td>
<td>

<p>For development purposes, not documented. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>shape</code> is the <code class="reqn">k</code> parameter of McCullagh and Nelder (1989, p.373) and the <code>theta</code> parameter of Venables and Ripley (2002, section 7.4). The latent Gamma variable has mean 1 and variance 1/shape. 
</p>
<p>The name <code>NB_shape</code> should be used to set values of shape in optimization control arguments of the fitting functions (e.g., <code>fitme(.,init=list(NB_shape=1))</code>); but fixed values are set by the <code>shape</code> argument.
</p>
<p>The returned family object is formally suitable for usage with <code>glm</code> if the <code>shape</code> argument is specified, but such usage is <em>not</em> recommended as it will lead to incorrect results for the zero-truncated case.
</p>


<h3>Value</h3>

<p>A family object with structure similar to <code>stats::</code> family object but with additional member functions for usage with <span class="pkg">spaMM</span> fitting functions.
</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J.A. (1989) Generalized Linear Models, 2nd edition. London: Chapman &amp; Hall.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics with S-PLUS. Fourth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fitting negative binomial model with estimated scale parameter:
data("scotlip")
fitme(cases~I(prop.ag/10)+offset(log(expec)),family=negbin(), data=scotlip)
negfit &lt;- fitme(I(1+cases)~I(prop.ag/10)+offset(log(expec)),family=Tnegbin(), data=scotlip)
simulate(negfit,nsim=3)
</code></pre>

<hr>
<h2 id='negbin1'>
Alternative negative-binomial family  
</h2><span id='topic+negbin1'></span>

<h3>Description</h3>

<p>Returns a <code>family</code> object suitable as a <code>fitme</code> argument for fitting negative-binomial models with variance linearly (affinely) related to the mean <code class="reqn">\mu</code>: variance=<code class="reqn">\mu+\mu</code>/shape, where the shape parameter need or need not be specified, depending on usage. 
The model described by such a family is characterized by a linear predictor, a link function, and such a negative-binomial model for the residual variation. The zero-truncated variant of this family is also handled.
</p>
<p>A <b>fixed-effect</b> residual-dispersion model can be fitted, using the <code><a href="#topic+resid.model">resid.model</a></code> argument, which is used to specify the form of the logarithm of the shape parameter. Thus the variance of the response become <code class="reqn">\mu+\mu</code>/<code>exp(&lt;specified linear expression&gt;)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negbin1(shape = stop("negbin1's 'shape' must be specified"), link = "log", trunc = -1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negbin1_+3A_shape">shape</code></td>
<td>

<p>Parameter controlling the mean-variance relationship of the <code>negbin1</code> distribution. This distribution can be represented as a Poisson-Gamma mixture, where the conditional Poisson mean is <code class="reqn">\mu</code> times a Gamma random variable with mean 1 and variance 1/(<code>shape*</code><code class="reqn">\mu</code>) as produced by <code>rgamma(., shape=sh,scale=1/sh)</code> where <code>sh=shape*</code><code class="reqn">\mu</code>, meaning that the family <code>shape</code> parameter controls, but differs from, the gamma <code>shape</code> parameter. 
</p>
</td></tr>
<tr><td><code id="negbin1_+3A_link">link</code></td>
<td>

<p>log, sqrt or identity link, specified by any of the available ways for GLM links (name, character string, one-element character vector, or object of class <code>link-glm</code> as returned by <code><a href="stats.html#topic+make.link">make.link</a></code>). 
</p>
</td></tr>
<tr><td><code id="negbin1_+3A_trunc">trunc</code></td>
<td>

<p>Either <code>0L</code> for zero-truncated distribution, or <code>-1L</code> for default untruncated distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The name <code>NB_shape</code> should be used to set values of shape in optimization control arguments of the fitting functions (e.g., <code>fitme(.,init=list(NB_shape=1))</code>); but fixed values are set by the <code>shape</code> argument.
</p>
<p>The family should not be used as a <code>glm</code> argument as the results would not be correct.
</p>



<h3>Value</h3>

<p>A list, formally of class <code>c("LLF", "family")</code>. See <code><a href="#topic+LL-family">LL-family</a></code> for details about the structure and usage of such objects.
</p>


<h3>See Also</h3>

<p>Examples in <code><a href="#topic+LL-family">LL-family</a></code>. <code><a href="#topic+resid.model">resid.model</a></code> for an example with a residual-dispersion model.</p>

<hr>
<h2 id='numInfo'>
Information matrix
</h2><span id='topic+numInfo'></span><span id='topic+print.singeigs'></span>

<h3>Description</h3>

<p>Computes by numerical derivation the observed information matrix for (ideally) all parameters for mean response model, that is, the matrix of second derivatives of negative log likelihood. 
The default value of the <code>which</code> argument shows all classes of parameters that should be handled, including random-effect parameters (<code>lambda</code>, <code><a href="#topic+ranCoefs">ranCoefs</a></code>, <code><a href="#topic+corrPars">corrPars</a></code>, and <code><a href="#topic+hyper">hyper</a></code>), residual dispersion parameters (<code>phi</code>, <code>NB_shape</code> for <code><a href="#topic+negbin1">negbin1</a></code> and <code><a href="#topic+negbin2">negbin2</a></code>, and <code>beta_prec</code> for <code><a href="#topic+beta_resp">beta_resp</a></code> and <code><a href="#topic+betabin">betabin</a></code>), and fixed-effect coefficients (<code>beta</code>).
</p>
<p>Model fits including a <code><a href="#topic+phi-resid.model">phi-resid.model</a></code> are not fully handled, in two ways: the information matrix does not include their parameters; and if the residual dispersion model include random effects, there is good reason for the <code>numInfo</code> calculation to detect that the fit has not maximized marginal likelihood with respect to most parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numInfo(fitobject, transf = FALSE, which = NULL, check_deriv = TRUE,
        sing=1e-05, verbose=FALSE, refit_hacks=list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numInfo_+3A_fitobject">fitobject</code></td>
<td>

<p>Fit object returned by a <span class="pkg">spaMM</span> fitting function.
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_transf">transf</code></td>
<td>

<p>Whether to perform internal computations on a transformed scale (but computation on 
transformed scale may be implemented for fewer classes of models than default computation). 
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_which">which</code></td>
<td>
<p> NULL, or character vector giving the sets of parameters with respect to which derivatives are to be computed.
The NULL default is equivalent to <code>c("lambda", "ranCoefs", "corrPars", "hyper", "phi", "NB_shape", "beta_prec", "beta")</code> for ML fits,
and to the same except <code>"beta"</code> (fixed effects) for REML fits.
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_check_deriv">check_deriv</code></td>
<td>

<p>Boolean; whether to perform some checks for possible problems (see Details). 
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_sing">sing</code></td>
<td>

<p>numeric value, or <code>FALSE</code>; if it is a nonzero numeric value, eigenvalues of the matrix are checked and values smaller than <code>sing</code>
are highlighted in output (see Value). This will highlight nearly-singular information matrices, but also those with large negative eigenvalues.
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_verbose">verbose</code></td>
<td>

<p>Boolean: whether to print (as a list) the estimates of the parameters for which the Hessian will be computed, additional information about possibly ignored parameters, possible misuse of REML fits, and a (sort of) progress bar if the procedure is expected to last more than a few seconds.
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_refit_hacks">refit_hacks</code></td>
<td>

<p>list of arguments; its name anticipates that it might allow hazardous manipulations in a later version of <span class="pkg">spaMM</span>. But currently only the innocuous element <code>verbose</code> of the list will be taken into account. Notably, <code>refit_hacks=list(verbose=c(TRACE=TRUE))</code> can be used to give information on parameter values used in the computation of numerical derivatives.
</p>
</td></tr>
<tr><td><code id="numInfo_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>numDeriv::hessian</code> and <code>numDeriv::grad</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation of a second derivatives is not necessarily meaningful if a first derivative does not vanish at the parameter estimates. This may occur in particular when the objective function (say, marginal likelihood) is maximized at a boundary of the parameter space (say, at zero for <code>lambda</code> estimates). Further, for such values at a boundary, only one-sided derivatives can be computed, and this is not handled by <code>numDeriv::hessian</code>. So, some checks may be requested to detect non-zero gradients and parameters estimated at their boundaries. The boundary checks are currently performed for <code>lambda</code> and <code>ranCoefs</code> estimates, if <code>check_deriv</code> is set to TRUE or to NULL. Other parameters are not (yet) checked, so <code>numInfo</code> may sometimes fails when such other parameter estimates are at a boundary. If <code>check_deriv</code> is set to TRUE, an additional systematic check of the gradient with respect to all target parameters is performed. 
</p>


<h3>Value</h3>

<p>NULL or a matrix.
</p>
<p>NULL is returned if no parameter is found with respect to which a numerical information &ldquo;should&rdquo; be computed (where what should be done depends on the <code>which</code> and <code>check_derivs</code> arguments). 
</p>
<p>Otherwise a matrix is returned, with an <code>eigvals</code> attribute if <code>sing</code> was non-zero. This attribute is a numeric vector of eigenvalues of the matrix. If some eigenvalue(s) were lower than <code>sing</code>, the vector has additional class <code>"singeigs"</code> so that its printing is controlled by an ad-hoc <code>print.singeigs</code> method highlighting the small eigenvalues. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
lmmfit &lt;- fitme(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch),data=wafers)
numinfo &lt;- numInfo(lmmfit)
(SEs &lt;- sqrt(diag(solve(numinfo))))
#
# =&gt; beta SEs here equal to conditional SEs shown by fit summary.
# Other SEs can be compared to the approximate ones 
# for log(phi) and log(lambda), given by 
#
# update(lmmfit, control=list(refit=TRUE))
#
# =&gt; 1118*0.5289 and 10840*0.1024

data("blackcap")
maternfit &lt;- fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap) 
numInfo(maternfit)
</code></pre>

<hr>
<h2 id='options'>spaMM options settings</h2><span id='topic+spaMM.options'></span><span id='topic+spaMM.getOption'></span><span id='topic+LevenbergM'></span><span id='topic+barstyle'></span>

<h3>Description</h3>

<p>Allow the user to set and examine a variety of <em>options</em>
which affect operations of the spaMM package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaMM.options(..., warn = TRUE)

spaMM.getOption(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="options_+3A_x">x</code></td>
<td>
<p>a character string holding an option name.</p>
</td></tr>
<tr><td><code id="options_+3A_warn">warn</code></td>
<td>
<p>Boolean: whether to warn if a previously undefined options is being defined (a protection against typos).</p>
</td></tr>
<tr><td><code id="options_+3A_...">...</code></td>
<td>
<p>A named value or a list of named values. The following values, with their defaults, 
are used in <code>spaMM</code>:
</p>

<dl>
<dt><code>LevenbergM=NULL</code>:</dt><dd><p>NULL or boolean. Whether to use a Levenberg-Marquardt-like algorithm (see Details) by default in most computations. But it is advised to use instead <code>control.HLfit=list(LevenbergM=...)</code> to control this on a case-by-case basis. The joint default behaviour is that Levenberg-Marquardt is used by default for binomial response data that takes only extreme values (in particular, for binary 0/1 response), and that for other models the fitting algorithm switches to it if divergence is suspected. <code>FALSE</code> inhibits its use; <code>TRUE</code> forces its use for all iterative least-square fits, except when 'confint()' is called.</p>
</dd>
<dt><code>example_maxtime=0.7</code>:</dt><dd><p>Used in the documentation and tests to control whether the longer examples should be run. 
The approximate running time of given examples on one author's laptop is compared to this value.</p>
</dd> 
<dt><code>optimizer1D="optimize"</code>:</dt><dd><p>Optimizer for one-dimensional optimization. If you want to control the initial value, you should select another optimizer.</p>
</dd>
<dt><code>optimizer=".safe_opt"</code>:</dt><dd><p>Optimizer for optimization in several dimensions. Use <code>optimizer="nloptr"</code> to call <code><a href="nloptr.html#topic+nloptr">nloptr</a></code> with method <code>"NLOPT_LN_BOBYQA"</code>; use <code>optimizer="bobyqa"</code> to call <code><a href="minqa.html#topic+bobyqa">bobyqa</a></code>; and use <code>optimizer="L-BFGS-B"</code> to call <code><a href="stats.html#topic+optim">optim</a></code> with method <code>"L-BFGS-B"</code>. The default <code>".safe_opt"</code> uses <code>nloptr</code> except in some cases where it expects or detects problems with it (the source code should be consulted for details). The optimizer can also be specified on a fit-by-fit basis as the value of <code>control$optimizer</code> in a <code>fitme</code> call, or as the value of <code>control.corrHLfit$optimizer</code>.
</p>
</dd>
<dt><code>nloptr</code>:</dt><dd><p>Default control values of <code>nloptr</code> calls.</p>
</dd> 
<dt><code>bobyqa</code>:</dt><dd><p>Default control values of <code>bobyqa</code> calls.</p>
</dd> 
<dt><code>maxLambda=1e10</code>:</dt><dd><p>The maximum value of lambda: higher fitted lambda values in HLfit are reduced to this. Since version 3.1.0, a much smaller lambda bound is deduced from <code>maxLambda</code> for COMPoisson and log-link response families.</p>
</dd>
<dt><code>regul_lev_lambda</code></dt><dd><p>Numeric (default: 1e-8); lambda leverages numerically 1 are replaced by 1- <code>regul_lev_lambda</code></p>
</dd>  
<dt><code>COMP_maxn</code>:</dt><dd><p>Number of terms for truncation of infinite sums that are evaluated in the fitting of <code><a href="#topic+COMPoisson">COMPoisson</a></code> models.</p>
</dd>
<dt><code>CMP_asympto_cond</code>:</dt><dd><p>Function returning the condition for applying an approximation or the COMPoisson response family, as detailed in <code><a href="#topic+COMPoisson">COMPoisson</a></code>.</p>
</dd> 
<dt><code>Gamma_min_y=1e-10</code>:</dt><dd><p>A minimum response value in Gamma-response models; used to check data, and in <code>simulate()</code> to correct the simulation results.</p>
</dd> 
<dt><code>QRmethod</code>:</dt><dd><p>A character string, to control whether dense matrix or sparse matrix methods are used in intensive matrix computations, overcoming the default choices made by <code>spaMM</code> in this respect. Possible values are <code>"dense"</code> and <code>"sparse"</code>.</p>
</dd>
<dt><code>matrix_method</code>:</dt><dd><p>A character string, to control the factorization of dense model matrices. Default value is <code>"def_sXaug_EigenDense_QRP_scaled"</code>. The source code should be consulted for further information.</p>
</dd>
<dt><code>Matrix_method</code>:</dt><dd><p>A character string, to control the factorization of sparse model matrices. Default value is <code>"def_sXaug_Matrix_QRP_CHM_scaled"</code>. The source code should be consulted for further information.</p>
</dd>
<dt><code>stylefns</code>:</dt><dd><p>Default colors of some screen output (notably that of some fitting functions when called with argument <code>verbose=c(TRACE=TRUE)</code>)</p>
</dd>
<dt><code>barstyle</code>:</dt><dd><p>Integer, or Boolean interpreted as Integer, or quoted expression evaluating to such types; controlling the display of some progress bars. If zero, no progress bar should be displayed; otherwise, a bar should be displayed. Further, when <code><a href="utils.html#topic+txtProgressBar">txtProgressBar</a></code> is called, <code>barstyle</code> is passed as its <code>style</code> argument. Default is <code>quote(if(interactive()) {3L} else {0L})</code> (in a parallel setting, child processes may display the bar if the parent process is interactive).</p>
</dd>
</dl>

<p>and many other undocumented values for programming or development purposes. Additional options without default values can also be used (e.g., see <code><a href="#topic+algebra">algebra</a></code>).
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>spaMM.options() provides an interface for changing maximal values of parameters of the Matérn correlation function. However, 
it is not recommended to change these values unless a spaMM message specifically suggests so.
</p>
<p>By default spaMM use Iteratively Reweighted Least Squares (IRLS) methods to estimate fixed-effect parameters (jointly with predictions of random effects). However, a Levenberg-Marquardt algorithm, as described by Nocedal &amp; Wright (1999, p. 266), is also implemented. The Levenberg-Marquardt algorithm is designed to optimize a single objective function with respect to all its parameters. It is thus well suited to compute a PQL fit, which is based on maximization of a single function, the h-likelihood. By contrast, in a fit of a mixed model by (RE)ML, one computes jointly fixed-effect estimates that maximizes marginal likelihood, and random-effect values that maximize h-likelihood given the fixed-effect estimates. The gradient of marginal likelihood with respect to fixed-effect coefficients does not generally vanishes at the solution (although it remains close to zero except in &ldquo;difficult&rdquo; cases with typically little information in the data). The Levenberg-Marquardt algorithm is not directly applicable in this case, as it may produce random-effect values that increases marginal likelihood rather than h-likelihood. The (RE)ML variant of the algorithm implemented in spaMM may therefore use additional nested h-likelihood-maximizing steps for correcting random-effect values. In version 3.1.0 this variant was revised for improved performance in difficult cases. 
</p>


<h3>Value</h3>

<p>For <code>spaMM.getOption</code>, the current value set for option <code>x</code>, or
<code>NULL</code> if the option is unset.
</p>
<p>For <code>spaMM.options()</code>, a list of all set options.  For
<code>spaMM.options(&lt;name&gt;)</code>, a list of length one containing the set value,
or <code>NULL</code> if it is unset.  For uses setting one or more options,
a list with the previous values of the options changed (returned
invisibly).
</p>


<h3>References</h3>

<p>Jorge Nocedal and Stephen J. Wright (1999) Numerical Optimization. Springer-Verlag, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  spaMM.options()
  spaMM.getOption("example_maxtime")
  ## Not run: 
  spaMM.options(maxLambda=1e06)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='pedigree'>Fit mixed-effects models incorporating pedigrees</h2><span id='topic+pedigree'></span>

<h3>Description</h3>

<p>This example illustrates how to use spaMM for quantitative genetic analyses. spaMM appears competitive in terms of speed for GLMMs with large data sets, particularly when using the PQL method, which may be a quite good approximation in such cases. For large pedigrees it may be useful to compute the inverse of the relationship matrix using some efficient ad hoc algorithm, then to provide it as argument of the fit using the <code><a href="#topic+covStruct">covStruct</a>(list(precision=...))</code> syntax. If the precision matrix is not specified, spaMM will generally evaluate it to assess whether it should use sparse-precision methods. see <code><a href="#topic+sparse_precision">sparse_precision</a></code> for further control of this computation, on another example from quantitative genetics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sparse_precision">sparse_precision</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# if(requireNamespace("pedigreemm", quietly=TRUE)) {
    ## derived from help("pedigreemm")
    # p1 &lt;- new("pedigree",
              sire = as.integer(c(NA,NA,1, 1,4,5)),
              dam  = as.integer(c(NA,NA,2,NA,3,2)),
              label = as.character(1:6))
    # A &lt;- pedigreemm::getA(p1) ## relationship matrix 
# }
## =&gt; Manually-built matrix: 
A &lt;- matrix(NA, ncol=6,nrow=6)
A[lower.tri(A,diag=TRUE)] &lt;- c(8,0,4,4,4,2, 8,4,0,2,5, 8,2,5,4.5, 8,5,2.5, 9,5.5, 9)/8
A &lt;- Matrix::forceSymmetric(A,uplo = "L")
colnames(A) &lt;- rownames(A) &lt;- 1:6

## data simulation
cholA &lt;- chol(A)  
varU &lt;- 0.4; varE &lt;- 0.6; rep &lt;- 20
n &lt;- rep*6
set.seed(108)
bStar &lt;- rnorm(6, sd=sqrt(varU))
b &lt;- crossprod(as.matrix(cholA),bStar)
ID &lt;- rep(1:6, each=rep)
e0 &lt;- rnorm(n, sd=sqrt(varE))
y &lt;- b[ID]+e0
obs &lt;- data.frame(y=y,IDgen=ID,IDenv=ID) ## two copies of ID for readability of GLMM results

## fits
fitme(y ~ 1+ corrMatrix(1|IDgen) , corrMatrix=A,data=obs,method="REML")
obs$y01 &lt;- ifelse(y&lt;1.3,0,1)
fitme(y01 ~ 1+ corrMatrix(1|IDgen)+(1|IDenv), corrMatrix=A,data=obs, 
      family=binomial(), method="REML")

prec_mat &lt;- solve(A)
colnames(prec_mat) &lt;- rownames(prec_mat) &lt;- rownames(A) # important
fitme(y01 ~ 1+ corrMatrix(1|IDgen)+(1|IDenv) , covStruct=list(precision=prec_mat),
      data=obs, family=binomial(), method="REML")

## End(Not run)
</code></pre>

<hr>
<h2 id='phi-resid.model'>Residual dispersion model for gaussian and Gamma response</h2><span id='topic+phi-resid.model'></span>

<h3>Description</h3>

<p>A model can be specified for the residual-dispersion parameter <code class="reqn">\phi</code> of gaussian and Gamma response families. The <code>resid.model</code> argument of all fitting functions is used to specify this model. This model may or may not include random effects. It is fitted by a specific method (Lee &amp; Nelder 2006) involving estimation of its parameters by the fit of a Gamma-response model to response values computed by the parent fitting function (e.g., by <code>HLfit</code> in the Examples). The <code>fitme</code> function is used internally to perform this fit, irrespective of the parent fitting function. The <code>resid.model</code> argument of the parent call is used to control the arguments of this <code>fitme</code> call beyond the specification of the model. 
</p>
<p>When the residual-dispersion model includes random effects, no single likelihood objective function appears to be maximized by the joint fit of mean-response and residual dispersion models. A procedure such as <code>numInfo</code> may then detect that the likelihood gradient does not vanish for all parameters. Indeed, this limitation is &ldquo;relatively obvious&rdquo; in Lee &amp; Nelder's original formulation since (as classical REML methods do) they used marginal likelihood and restricted likelihood concepts to fit different parameters of the joint model. But this limitation is also true in the case where marginal likelihood (actually, its Laplace approximation, although the issue could persist even if exact Gamma-GLMM likelihood were used) is used in the residual-dispersion fit.     
</p>


<h3>Usage</h3>

<pre><code class='language-R'># 'resid.model' argument of fitting functions (fitme(), HLfit(), etc)
</code></pre>


<h3>Arguments</h3>

<p><code>resid.model</code> is <b>either</b> a formula (without left-hand side) for the dispersion parameter <code>phi</code> of the residual error (a log link is assumed); <b>or</b> a list of arguments similar to those of a standard fit. The following arguments may be useful:

</p>
<table>
<tr><td><code id="phi-resid.model_+3A_formula">formula</code></td>
<td>
<p>model formula as in formula-only case, without left-hand side.</p>
</td></tr>
<tr><td><code id="phi-resid.model_+3A_family">family</code></td>
<td>
<p>The family is always Gamma. The default link is log. The identity link can be tried but may fail because only the log link ensures that the fitted <code class="reqn">\phi</code> is positive.

</p>
</td></tr>
<tr><td><code id="phi-resid.model_+3A_fixed">fixed</code></td>
<td>
<p>fixed values of parameters of the residual dispersion model itself. Same usage as documented in <code><a href="#topic+fitme">fitme</a></code>, except that it is better not to try to fix its <code>phi</code> (see Details).</p>
</td></tr> 
<tr><td><code id="phi-resid.model_+3A_etafix">etaFix</code></td>
<td>
<p>To fix some of the fixed-effect coefficients, as in the mean response, and with the same format. Note that the same effect can usually be acheived by an offset in the <code>formula</code>.</p>
</td></tr> 
<tr><td><code id="phi-resid.model_+3A_control.dist">control.dist</code></td>
<td>
<p>A list of arguments that control the computation of the distance argument of the correlation functions. Same usage as documented in <code><a href="#topic+HLCor">HLCor</a></code></p>
</td></tr> 
<tr><td><code id="phi-resid.model_+3A_rand.family">rand.family</code></td>
<td>
<p>A <code>family</code> object or a <code>list</code> of family objects describing the distribution of the random effect(s). Same usage as documented for <code><a href="#topic+HLfit">HLfit</a></code></p>
</td></tr> 
<tr><td><code id="phi-resid.model_+3A_init">init</code>, <code id="phi-resid.model_+3A_lower">lower</code>, <code id="phi-resid.model_+3A_upper">upper</code>, <code id="phi-resid.model_+3A_control">control</code></td>
<td>
<p>with same usage as documented in <code><a href="#topic+fitme">fitme</a></code>, may be at least partly heeded.</p>
</td></tr> 
</table>
<p>Other arguments should be ignored (see Details).
</p>


<h3>Details</h3>

<p>The following elements in <code>resid.model</code> should be ignored:
</p>

<dl>
<dt>method</dt><dd><p>which is constrained to be identical to the method from the parent call;</p>
</dd> 
<dt>control.HLfit, control.glm</dt><dd><p>constrained to be identical to the same-named controls from the parent call;</p>
</dd>
<dt>resid.model</dt><dd><p>constrained: no <code>resid.model</code> for a <code>resid.model</code>;</p>
</dd>
<dt>REMLformula</dt><dd><p>constrained to NULL;</p>
</dd>
<dt>data</dt><dd><p>The data of the parent call are used, so they must include all the variables required for the <code>resid.model</code>;</p>
</dd>
<dt>prior.weights</dt><dd><p>constrained: no prior weights;</p>
</dd>
<dt>verbose</dt><dd><p>constrained: will display a progress line summarizing the results of the <code>resid.model</code> fit at each iteration of main loop of the parent call.</p>
</dd>
<dt>init.HLfit</dt><dd><p>if used, this argument may affect the fits. However, it is best ignored in practice: users would have hard time guessing good initial values, and they might have unwarranted effects.</p>
</dd>
</dl>

<p>the <code>phi</code> of the Gamma family of the residual dispersion model is by default set to 1, in agreement with the theory underlying the estimation procedure for the residual model; it can be set to another value, and a <code>resid.model</code>'s <code>fixed=list(phi=NA)</code> will even force its estimation, but this is not warranted.
</p>
<p>Fits with a mixed-effect residual-dispersion model involve repeated (&ldquo;fitme&rdquo; fits of the latter model (themselves within the &ldquo;HLfit&rdquo; calls nested within the main fit), which can be slow particularly when this model involve spatial effects. A specific element <code>phifit</code> of the <code>verbose</code> vector controls screen information about progress of such fits during the full-model fit: when set to 0 (or FALSE) there is no report. For higher values a one-line message is output at the end of each nested &ldquo;fitme&rdquo; call, but it may be overwritten by the next one line message. So the ultimately visible output depends on control of overwriting. When <code>verbose["phifit"]</code> is set to 1 (or TRUE) each output overwrites the previous one so the ultimately visible output is from the last nested &ldquo;fitme&rdquo; call; when it is set to <code>2</code>, theline of output of the final nested &ldquo;fitme&rdquo; call remains visible for each &ldquo;HLfit&rdquo; call; when set to 3, a line of output remains visible from each nested &ldquo;fitme&rdquo; call within each &ldquo;HLfit&rdquo; call.  
</p>


<h3>Value</h3>

<p>When such dispersion models are fitted, the resulting fits are embedded in the main fit object. The <code><a href="#topic+get_fittedPars">get_fittedPars</a></code> extractor will by default )as controlled by its argument <code>phiPars</code>) include in its return value the <code>rdisPars</code> element, which is the list of parameters of the residual-dispersion fit, in the same format as a <code>get_fittedPars</code> value for the mean-response model (<code>rdisPars</code> may also include fits of other residual-dispersion models described in <code><a href="#topic+resid.model">resid.model</a></code>). The <code>phi</code> element of the <code>get_fittedPars</code> value will further contain the residual-dispersion fit itself, as a <code>"glm"</code> or, when it includes random effects, as a <code>"HLfit"</code> object.
</p>


<h3>References</h3>

<p>Lee, Y. and Nelder, J.A. (2006), Double hierarchical generalized linear models (with discussion). Journal of the Royal Statistical Society: Series C (Applied Statistics), 55: 139-185. <a href="https://doi.org/10.1111/j.1467-9876.2006.00538.x">doi:10.1111/j.1467-9876.2006.00538.x</a>
</p>
<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006) Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data("crack") # crack data, Lee et al. 2006 chapter 11 etc
 hlfit &lt;- HLfit(y~crack0+(1|specimen), family=Gamma(log),
                data=crack, rand.family=inverse.Gamma(log), 
                resid.model=list(formula=~cycle+(1|specimen)) )
</code></pre>

<hr>
<h2 id='plot_effects'>
Partial-dependence effects and plots
</h2><span id='topic+plot_effects'></span><span id='topic+pdep_effects'></span>

<h3>Description</h3>

<p>The following functions evaluate or plot <em>partial-dependence</em> effects. 
</p>
<p><code>pdep_effects</code> evaluates the effect of a given fixed-effect variable, as (by default, the average of) predicted values on the response scale, over the empirical distribution of all other fixed-effect variables in the data, and of inferred random effects. This can be seen as the result of an experiment where specific treatments (given values of the focal variable) are applied over all conditions defined by the other fixed effects and by the inferred random effects. Thus, apparent dependencies induced by associations between predictor variables are avoided (see Friedman, 2001, from which the name &ldquo;partial dependence plot&rdquo; is taken; or Hastie et al., 2009, Section 10.13.2). This also avoids biases of possible alternative ways of plotting effects. In particular, such biases occur if the response link is not identity, and if averaging is performed on the linear-predictor scale or when other variables are set to some conventional value other than its average. 
</p>
<p><code>pdep_effects</code> also compute intervals of the type defined by its <code>intervals</code> argument (by default, prediction intervals). By default, it returns a data frame of average values of point predictions and interval bounds for each value of the focal variable, but it can also return lists of all predictions.
</p>
<p>A plot function is available for numeric or factor predictors: <code>plot_effects</code> calls <code>pdep_effects</code> and produces a simple plot (using only base graphic functions) of its results, including prediction bands representing the two average one-sided widths of intervals. The last section of the Examples shows how to obtain more elaborate plots including the same information using <span class="pkg">ggplot2</span>. 
</p>
<p>If added to the plot, the raw data may appear to depart from the partial-dependence predictions, since the data are a priori affected by the associations between variables which the predictions free themselves from. An adapted plot of fit residuals may be then be more useful, and the Examples also show how it can be performed.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdep_effects(object, focal_var, newdata = object$data, length.out = 20, 
             focal_values=NULL, levels = NULL, intervals = "predVar", indiv = FALSE, 
             ...)
plot_effects(object, focal_var, newdata = object$data, focal_values=NULL, 
             effects = NULL, xlab = focal_var, ylab = NULL, 
             rgb.args = col2rgb("blue"), add = FALSE,  ylim=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_effects_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_focal_var">focal_var</code></td>
<td>

<p>Character string: the name of the predictor variable whose effect is to be represented. The variable must be numeric for <code>plot_effects</code> but not necessarily so for <code>pdep_effects</code>. 
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_newdata">newdata</code></td>
<td>

<p>If non-NULL, a data frame passed to <code>predict.HLfit</code>, whose documentation should be consulted for further details.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_effects">effects</code></td>
<td>

<p>If non-NULL, a data frame to substitute to the one produced by default by <code>pdep_effects</code>.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_xlab">xlab</code></td>
<td>

<p>If non-NULL, a character string: X-axis label for the plot.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_ylab">ylab</code></td>
<td>

<p>If non-NULL, a character string: Y-axis label for the plot.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_ylim">ylim</code></td>
<td>

<p>The <code>plot</code>'s <code>ylim</code> argument. Default is based on the (0.025,0.975) quantiles of the response.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_rgb.args">rgb.args</code></td>
<td>

<p>Color control arguments, in the format produced by <code><a href="grDevices.html#topic+col2rgb">col2rgb</a></code>.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_add">add</code></td>
<td>

<p>Boolean: whether to add graphic elements of a previous plot produced by <code>plot_effects</code>
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_length.out">length.out</code></td>
<td>

<p>Integer: for a numeric predictor variable, this controls the number of values at which predictions are evaluated. By default, predictions are made at regular intervals over the range of the predictor variable. If <code>length.out=0</code>, predictions are made for the actual values of the focal predictor in the data. The default behaviour is also overriden by using <code>focal_values</code>, in which case predictions are evaluated at the given <code>focal_values</code> (as if <code>length.out=0</code>), unless a non-zero <code>length.out</code> is also specified. In the latter case, predictions are evaluated at regular intervals over the range of <code>focal_values</code>.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_focal_values">focal_values</code>, <code id="plot_effects_+3A_levels">levels</code></td>
<td>
 <p><code>focal_values</code> may be used to specify the values of the focal variable at which predictions are evaluated. For factor variables, <code>levels</code> is an older implementation of this control, and is now redundant.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_intervals">intervals</code></td>
<td>

<p>Passed to <code>predict.HLfit</code>, whose documentation should be consulted for further details.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_indiv">indiv</code></td>
<td>

<p>Boolean: whether to return all predictions given the values of other predictors in the <code>newdata</code>, or only their means.
</p>
</td></tr>
<tr><td><code id="plot_effects_+3A_...">...</code></td>
<td>

<p>Further arguments passed by <code>plot_effects</code> to <code>pdep_effects</code>, or by <code>pdep_effects</code> to <code>predict.HLfit</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>pdep_effects</code>, a nested list, or a data frame storing values of the <code>focal_var</code>, average point predictions <code>pointp</code> and bounds <code>low</code> and <code>up</code> of intervals, depending on the <code>indiv</code> argument. When <code>indiv</code> is <code>TRUE</code>, each sublist contains vectors for <code>pointp</code>, <code>low</code> and <code>up</code>.  
</p>
<p>For <code>plot_effects</code>, the same value, returned invisibly.
</p>


<h3>References</h3>

<p>J.H. Friedman (2001). Greedy Function Approximation: A Gradient Boosting
Machine. Annals of Statistics 29(5):1189-1232.
</p>
<p>J. Friedman, T. Hastie and R. Tibshirani (2009) The Elements of Statistical Learning, 2nd ed. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("scotlip")
hlcor &lt;- HLCor(cases~I(prop.ag/10) +adjacency(1|gridcode)+offset(log(expec)),
           adjMatrix=Nmatrix,family=poisson(),data=scotlip) 
plot_effects(hlcor,focal_var="prop.ag",ylim=c(0,max(scotlip$cases)))  
points(cases~prop.ag, data=scotlip, col="blue",pch=20)

# Impose specific values of a numeric predictor using 'focal_values':
plot_effects(hlcor, focal_var="prop.ag", focal_values=1:5)

### Adding 'partial residuals' [residuals relative to predict(&lt;fit object&gt;),
###  but plotted relative to pdep_effects() predictions]:

# One first needs predictions for actual values of the predictor variable,
# provided by pdep_effects(.,length.out=0L):
#
pdep_points &lt;- pdep_effects(hlcor,focal_var="prop.ag",length.out=0L)

# Rename for easy prediction for each observation, and add the residuals 
# of the actual fit, using the default residuals() i.e. deviance ones: 
#
rownames(pdep_points) &lt;- pdep_points$focal_var
pdep_res &lt;- pdep_points[paste(hlcor$data$prop.ag),"pointp"] + 
              residuals(hlcor)

points(x = hlcor$data$prop.ag, y = pdep_res, col = "red", pch = 20)

## Not run:  

## Plotting pdep-effects for different categories, using ggplot.
library(ggplot2)

data("Gryphon")
tmp &lt;- na.omit(Gryphon_df)
spfit &lt;- spaMM::fitme(TARSUS ~ BWT*sex, data = tmp)

tmp$sex &lt;- "1"
pdep_1 &lt;- pdep_effects(spfit,"BWT", newdata=tmp)
tmp$sex &lt;- "2"
pdep_2 &lt;- pdep_effects(spfit,"BWT", newdata=tmp)
pdep_1$sex &lt;- "1" ; pdep_2$sex &lt;- "2"  
pdep &lt;- rbind(pdep_1,pdep_2)

ggplot(pdep,aes(y = pointp , x = focal_var ,col = sex, fill=sex)) + geom_point() +
  geom_ribbon(aes(ymin = low, ymax = up), alpha = 0.3) + xlab("BWT") +
  ylab("TARSUS")



## End(Not run)
</code></pre>

<hr>
<h2 id='plot.HLfit'>
Model checking plots for mixed models
</h2><span id='topic+plot'></span><span id='topic+plot.HLfit'></span>

<h3>Description</h3>

<p>This function provides diagnostic plots for residual errors from the mean model and for random effects. Plots for the mean models are similar 
to those for GLMs. They use <em>standardized</em> deviance residuals as described by Lee et al. (2006, p.52). This means that plots for residual errors use the residuals provided by <code>residuals(&lt;fit object&gt;, type="std_dev_res")</code>; and that plots for random effects likewise consider standardized values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
plot(x, which = c("mean", "ranef"), 
      titles = list(
          meanmodel=list(outer="Mean model",devres="Deviance residuals", 
                         absdevres="|Deviance residuals|", resq="Residual quantiles", 
                         devreshist="Deviance residuals"), 
          ranef=list(outer="Random effects and leverages",qq="Random effects Q-Q plot", 
                     levphi=expression(paste("Leverages for ",phi)), 
          levlambda=expression(paste("Leverages for ",lambda))) 
        ), 
      control= list(), ask=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.HLfit_+3A_x">x</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="plot.HLfit_+3A_which">which</code></td>
<td>
<p> A vector of keywords for different types of plots. 
By default, two types of plots are presented on different devices: diagnostic plots for mean values, and diagnostic plots for random effects.
Either one can be selected using this argument. Use keyword <code>"predict"</code> for a plot of predicted response against actual response.
</p>
</td></tr>
<tr><td><code id="plot.HLfit_+3A_titles">titles</code></td>
<td>

<p>A list of the <code>main</code> (inner and outer) titles of the plots. See the default value for the format.
</p>
</td></tr>
<tr><td><code id="plot.HLfit_+3A_control">control</code></td>
<td>

<p>A list of default options for the plots. Defaults are <code>pch="+"</code> and <code>pcol="blue"</code> for points, and <code>lcol="red"</code> for curves.
</p>
</td></tr>
<tr><td><code id="plot.HLfit_+3A_ask">ask</code></td>
<td>

<p>Logical; passed to <code>devAskNewPage</code> which is run when a new device is opened by <code>code.HLfit</code>. 
</p>
</td></tr>
<tr><td><code id="plot.HLfit_+3A_...">...</code></td>
<td>

<p>Options passed from <code>plot.HLfit</code> to <code>par</code>.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In principle the standardized deviance residuals for the mean model should have a nearly Gaussian distribution hence form a nearly straight line on a Q-Q plot. However this is (trivially) not so for well-specified (nearly-)binary response data nor even for well-specified Poisson response data with moderate expectations. Hence this plot is not so useful. The <code>DHARMa</code> package proposes better-behaved diagnostic plots (but the p-value that appears on one of these plots may not stand for a valid goodness-of-fit test). The current version of <code>DHARMa</code> should handle <code>spaMM</code> fit objects; otherwise, see <a href="https://github.com/florianhartig/DHARMa/issues/95">https://github.com/florianhartig/DHARMa/issues/95</a> for how to run <code>DHARMa</code> procedures on <code>spaMM</code> output.   
</p>


<h3>Value</h3>

<p>Returns the input object invisibly.
</p>


<h3>References</h3>

<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006). Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap")
fit &lt;- fitme(migStatus ~ 1+ Matern(1|longitude+latitude),data=blackcap,
             fixed=list(lambda=1,nu=1,rho=1))
plot(fit)
</code></pre>

<hr>
<h2 id='PLS-internals'>Internal functions for procedure using the ((I,0),(Z,X)) block-order</h2><span id='topic+PLS-internals'></span><span id='topic+def_AUGI0_ZX_spprec'></span><span id='topic+def_sXaug_EigenDense_QRP_Chol_scaled'></span><span id='topic+def_sXaug_Matrix_QRP_CHM_scaled'></span><span id='topic+def_sXaug_Matrix_CHM_H_scaled'></span><span id='topic+get_from_MME'></span><span id='topic+get_from_MME.AUGI0_ZX_spprec'></span><span id='topic+get_from_MME.sXaug_EigenDense_QRP_Chol_scaled'></span><span id='topic+get_from_MME.sXaug_Matrix_QRP_CHM_scaled'></span><span id='topic+get_from_MME.sXaug_Matrix_CHM_H_scaled'></span><span id='topic+get_from_MME.default'></span><span id='topic+get_from_MME.sparseMatrix'></span><span id='topic+get_from_MME_default'></span><span id='topic+get_from_MME_default.matrix'></span><span id='topic+get_from_MME_default.Matrix'></span>

<h3>Description</h3>

<p>Internal spaMM functions
</p>


<h3>Details</h3>

<p>These functions use the block order introduced by Bates and DebRoy (2004) and also used in <code>lme4</code>.
These are not to be called by the user, or are waiting for documentation to be written.  
</p>


<h3>References</h3>

<p>Bates D.M., DebRoy S. Linear mixed models and penalized least squares. Journal of Multivariate Analysis 91: 1–17.
</p>

<hr>
<h2 id='Poisson'>
Family function for GLMs and mixed models with Poisson and zero-truncated Poisson response.
</h2><span id='topic+Poisson'></span><span id='topic+Tpoisson'></span>

<h3>Description</h3>

<p><code>Poisson</code> (with a capital P) is a <code><a href="stats.html#topic+family">family</a></code> that specifies the information required to fit a Poisson generalized linear model. Differs from the base version <code>stats::poisson</code> only in that it handles the zero-truncated variant, which can be specified either as <code>Tpoisson(&lt;link&gt;)</code> or as <code>Poisson(&lt;link&gt;, trunc = 0L)</code>. The truncated poisson with mean <code class="reqn">\mu_T</code> is defined from the un-truncated poisson with mean <code class="reqn">\mu_U</code>, by restricting its response strictly positive value. <code class="reqn">\mu_T=\mu_U/(1-p0)</code>, where <code class="reqn">p0:=\exp(-\mu_U)</code> is the probability that the response is 0. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Poisson(link = "log", trunc = -1L, LLgeneric=TRUE)
Tpoisson(link="log")
# &lt;Poisson object&gt;$linkfun(mu, mu_truncated = FALSE)
# &lt;Poisson object&gt;$linkinv(eta, mu_truncated = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Poisson_+3A_link">link</code></td>
<td>

<p>log, sqrt or identity link, specified by any of the available ways for GLM links (name, character string, one-element character vector, or object of class <code>link-glm</code> as returned by <code><a href="stats.html#topic+make.link">make.link</a></code>). 
</p>
</td></tr>
<tr><td><code id="Poisson_+3A_trunc">trunc</code></td>
<td>

<p>Either <code>0L</code> for zero-truncated distribution, or <code>-1L</code> for default untruncated distribution.
</p>
</td></tr>
<tr><td><code id="Poisson_+3A_eta">eta</code>, <code id="Poisson_+3A_mu">mu</code></td>
<td>
<p>Numeric (scalar or array). The linear predictor; and the expectation of response, truncated or not depending on <code>mu_truncated</code> argument. </p>
</td></tr>
<tr><td><code id="Poisson_+3A_mu_truncated">mu_truncated</code></td>
<td>
<p>Boolean. For <code>linkinv</code>, whether to return the expectation of truncated (<code class="reqn">\mu_T</code>) or un-truncated (<code class="reqn">\mu_U</code>) response. For <code>linkfun</code>, whether the <code>mu</code> argument is <code class="reqn">\mu_T</code>, or is <code class="reqn">\mu_U</code>  but has <code class="reqn">\mu_T</code>  as attribute (<code class="reqn">\mu_U</code> without the attribute is not sufficient). </p>
</td></tr>
<tr><td><code id="Poisson_+3A_llgeneric">LLgeneric</code></td>
<td>

<p>For development purposes, not documented. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Molas &amp; Lesaffre (2010) developed expressions for deviance residuals for the truncated Poisson distribution, which were the ones implemented in <span class="pkg">spaMM</span> until version 3.12.0. Later versions implement the (non-equivalent) definition as &ldquo;2*(saturated_logLik - logLik)&rdquo;.   
</p>
<p><code>predict</code>, when applied on an object with a truncated-response family, by default returns <code class="reqn">\mu_T</code>. The simplest way to predict <code class="reqn">\mu_U</code> is to get the linear predictor value by <code>predict(.,type="link")</code>, and deduce <code class="reqn">\mu_U</code> using <code>linkinv(.)</code> (with default argument <code>mu_truncated=FALSE</code>), since getting <code class="reqn">\mu_U</code> from <code class="reqn">\mu_T</code> is comparatively less straightforward. The <code>mu.eta</code> member function is that of the base <code>poisson</code> family, hence its <code>mu</code> argument represents <code class="reqn">\mu_U</code>. 
</p>
<p><code>simulate</code>, when applied on an object with a truncated-response family, simulates the truncated family. There is currently no clean way to override this (trying to pass<code>type="link"</code> to <code>predict</code> will not have the intended effect). 
</p>


<h3>Value</h3>

<p>A <code>family</code> object suitable for use with <code>glm</code>, as <code>stats::</code> family objects.
</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J.A. (1989) Generalized Linear Models, 2nd edition. London: Chapman &amp; Hall.
</p>
<p>Molas M. and Lesaffre E. (2010). Hurdle models for multilevel zero-inflated data via h-likelihood. Statistics in Medicine 29: 3294-3310.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("scotlip")
logLik(glm(I(1+cases)~1,family=Tpoisson(),data=scotlip))
logLik(fitme(I(1+cases)~1+(1|id),family=Tpoisson(),fixed=list(lambda=1e-8),data=scotlip))
</code></pre>

<hr>
<h2 id='post-fit'>
Applying post-fit procedures on spaMM results
</h2><span id='topic+post-fit'></span><span id='topic+RLRsim'></span><span id='topic+multcomp'></span><span id='topic+glht'></span><span id='topic+DHARMa'></span><span id='topic+lmerTest'></span>

<h3>Description</h3>

<p>Packages implementing post-fit procedures define helper functions which may not handle <span class="pkg">spaMM</span>'s fit objects, or which have not always handled them, or which can handle them correctly only with some non-default arguments. This documentation topic gives further directions to apply some such post-fit procedures (from packages <span class="pkg">DHARMa</span>, <span class="pkg">RLRsim</span>, <span class="pkg">multcomp</span> and <span class="pkg">lmerTest</span>) to these fit objects. 
</p>
<p>For other procedures not considered here, diagnosing a failure in a debugging session may suggest a simple solution (as it did for <code>multcomp::glht</code>). 
</p>


<h3>Details</h3>

<p>For multiple comparison procedures by <code style="white-space: pre;">&#8288;multcomp::glht&#8288;</code>, one has to explicitly give the argument <code>coef.=fixef.HLfit</code> (see Examples; <code>fixef.HLfit</code> is the <span class="pkg">spaMM</span> method for the generic function <code>fixef</code>);
</p>
<p>For <span class="pkg">DHARMa</span> plots, see Details of <code><a href="#topic+plot.HLfit">plot.HLfit</a></code>;
</p>
<p>For using <span class="pkg">RLRsim::RLRTSim()</span>, see <code><a href="#topic+get_RLRTSim_args">get_RLRTSim_args</a></code>.
</p>
<p>For using <span class="pkg">lmerTest::contest()</span> or <span class="pkg">lmerTest::anova()</span>, see <code><a href="#topic+as_LMLT">as_LMLT</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("multcomp", quietly = TRUE)) {
  library(multcomp)
  set.seed(123)
  irisr &lt;- cbind(iris,id=sample(4,replace=TRUE,size=nrow(iris)))
  irisfit &lt;- fitme(Petal.Length~ Species +(1|id), data=irisr, family=Gamma(log))
  summary(glht(irisfit,mcp("Species" = "Tukey"), coef.=fixef.HLfit))
}
</code></pre>

<hr>
<h2 id='predict'>
Prediction from a model fit
</h2><span id='topic+predict.HLfit'></span><span id='topic+predict'></span><span id='topic+get_fixefVar'></span><span id='topic+get_predVar'></span><span id='topic+get_residVar'></span><span id='topic+get_respVar'></span><span id='topic+get_intervals'></span><span id='topic+intervals'></span><span id='topic+get_predCov_var_fix'></span><span id='topic+preprocess_fix_corr'></span>

<h3>Description</h3>

<p>The following functions can be used to compute point predictions and/or various measures of uncertainty associated to such predictions:<br /> 
<code style="white-space: pre;">&#8288; * &#8288;</code><code>predict</code> can be used for prediction of the response variable by its expected value obtained as (the inverse link transformation of) the linear predictor (<code class="reqn">\eta</code>) and more generally for terms of the form <b>X</b>_n<code class="reqn">\beta</code>+<b>Z</b>_n<b>L</b><b>v</b>, for new design matrices <b>X</b>_n and <b>Z</b>_n.<br /> 
<code style="white-space: pre;">&#8288; * &#8288;</code>Various components of prediction variances and predictions intervals can also be computed using <code>predict</code>. 
The <code>get_</code>... functions are convenient extractors for such components;<br /> 
<code style="white-space: pre;">&#8288; * &#8288;</code><code>get_predCov_var_fix</code> extracts a block of a prediction covariance matrix. It was conceived for the specific purpose of computing the spatial prediction covariances between two &ldquo;new&rdquo; sets of geographic locations, without computing the full covariance matrix for both the new locations and the original (fitted) locations. When one of the two sets of new locations is fixed while the other varies, some expensive computations can be performed once for all sets of new locations, and be provided as the <code>fix_X_ZAC.object</code> argument. The <code>preprocess_fix_corr</code> extractor is designed to compute this argument. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
predict(object, newdata = newX, newX = NULL, re.form = NULL,
                        variances=list(), binding = FALSE, intervals = NULL,
                        level = 0.95, blockSize = 2000L, type = "response", 
                        verbose=c(showpbar=eval(spaMM.getOption("barstyle"))), 
                        control=list(), na.action=na.omit, cluster_args=list(), ...)
get_predCov_var_fix(object, newdata = NULL, fix_X_ZAC.object, fixdata, re.form = NULL,
                    variances=list(disp=TRUE,residVar=FALSE,cov=FALSE), 
                    control=list(),  ...)    
preprocess_fix_corr(object, fixdata, re.form = NULL,
                   variances=list(residVar=FALSE, cov=FALSE), control=list())
get_fixefVar(...)
get_predVar(..., variances=list(), which="predVar")
get_residVar(...)
get_respVar(...)
get_intervals(..., intervals="predVar")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>

<p>The return object of fitting functions <code>HLfit,corrHLfit,HLCor</code>... returning an object inheriting from <code>HLfit</code> class.
</p>
</td></tr>
<tr><td><code id="predict_+3A_newdata">newdata</code></td>
<td>

<p><b>Either</b> NULL, a matrix or data frame, or a numeric vector. 
</p>
<p>If <code>NULL</code>, the original data are reused. Otherwise, all variables required to evaluate model formulas must be included. Which variables are required may depend on other arguments: see &ldquo;prediction with given phi's&rdquo; example, also illustrating the syntax when formulas include an offset.  
</p>
<p>If <code>newdata</code> is a numeric vector, its names (if any) are ignored. This makes it easier to use <code>predict</code> as an objective function for an 
optimization procedure such as <code>optim</code>, which calls the objective function on unnamed vectors. However, one must make sure that the order of elements in the vector is the order of first occurrence of the variables in the model formula. This order can be checked in the error message returned when calling <code>predict</code> on a <code>newX</code> vector of clearly wrong size, e.g. <code>predict(&lt;object&gt;,newdata=numeric(0))</code>.
</p>
</td></tr>
<tr><td><code id="predict_+3A_newx">newX</code></td>
<td>
<p>equivalent to newdata, available for back-compatibility</p>
</td></tr> 
<tr><td><code id="predict_+3A_re.form">re.form</code></td>
<td>

<p>formula for random effects to include.  By default, it is NULL, in which case all random effects are included. If it is NA, no random effect is included. If it is a formula, only the random effects it contains are retained. The other variance components are removed from both point prediction and <code>variances</code> calculations. If you want to retain only the spatial effects in the point prediction, but all variances, either use re.form  and add missing variances (on linear predictor scale) manually, or ignore this argument and see Details and Examples for different ways of controlling variances.     
</p>
</td></tr>
<tr><td><code id="predict_+3A_variances">variances</code></td>
<td>

<p>A list whose elements control the computation of different estimated variances. 
<code>predict</code> can return four components of prediction variance: <code>fixefVar</code>, <code>predVar</code>, <code>residVar</code> and <code>respVar</code>, whose definitions is detailed in <code><a href="#topic+predVar">predVar</a></code>. They are all returned as attributes of the point predictions. 
</p>
<p>In particular, <code>variances=list(predVar=TRUE)</code> is suitable for uncertainty in point prediction, distinguished from the response variance given by <code>list(respVar=TRUE)</code>. See the <code><a href="#topic+predVar">predVar</a></code> help page for further explanations and other options. 
</p>
</td></tr>
<tr><td><code id="predict_+3A_intervals">intervals</code></td>
<td>

<p>NULL or character string or vector of strings. Provides prediction intervals with nominal level <code>level</code>, deduced from the given prediction variance term, e.g. <code>intervals="predVar"</code>. Currently only intervals from <code>fixefVar</code> and <code>predVar</code> (and for LMMs <code>respVar</code> including the residual variance) may have a probabilistic meaning. Intervals returned in other cases are (currently) meaningless. 
</p>
</td></tr>
<tr><td><code id="predict_+3A_which">which</code></td>
<td>
<p>any of <code>"predVar"</code>,<code>"respVar"</code>,<code>"residVar"</code>, <code>"fixefVar"</code>, <code>"intervals"</code>, or <code>"naive"</code> </p>
</td></tr>
<tr><td><code id="predict_+3A_level">level</code></td>
<td>
<p>Coverage of the intervals.</p>
</td></tr>
<tr><td><code id="predict_+3A_binding">binding</code></td>
<td>

<p>If <code>binding</code> is a character string, the predicted values are bound with the <code>newdata</code> and the result is returned as a data frame. The predicted values column name is the given <code>binding</code>, or a name based on it if the <code>newdata</code> already include a variable with this name. 
If <code>binding</code> is <code>FALSE</code>, The predicted values are returned as a one-column matrix and the data frame used for prediction is returned as an attribute
(unless it was <code>NULL</code>). If <code>binding</code> is <code>NA</code>, a vector is returned, without the previous attributes.
</p>
</td></tr>
<tr><td><code id="predict_+3A_fixdata">fixdata</code></td>
<td>
<p>A data frame describing reference data whose covariances with variable <code>newdata</code> may be requested.</p>
</td></tr>
<tr><td><code id="predict_+3A_fix_x_zac.object">fix_X_ZAC.object</code></td>
<td>
<p>The return value of calling <code>preprocess_fix_corr</code> (see trivial Example). This is a more efficient way of providing information about the <code>fixdata</code> for repeated calls to <code>get_predCov_var_fix</code> with variable <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_blocksize">blockSize</code></td>
<td>
  
<p>For data with many rows, it may be more efficient to perform some operations on slices of the data, and this gives the maximum number or rows of each slice. Further, parallelisation of computations over the slices is possible, as controlled by the <code>cluster_args</code> argument. Slicing and parallelisation may operate only if covariance matrices are not requested. 
</p>
</td></tr>
<tr><td><code id="predict_+3A_type">type</code></td>
<td>
<p>character string; The returned point predictions are on the response scale if <code>type="response"</code> (the default; for binomial response, a frequency 0&lt;.&lt;1). It is on the linear predictor scale if <code>type="link"</code>. <br />
* The &ldquo;prediction variance&rdquo; (as opposed to the response variance, see <code><a href="#topic+predVar">predVar</a></code>) that may be returned as a <code>"predVar"</code>  attribute of the point predictions is always on the linear predictor scale, even when <code>type="response"</code>. If you want to extract this <code>predVar</code> transformed to the response scale, use <code>predict(.,variances=list(respVar=TRUE))</code> and take the difference between the <code>respVar</code> and <code>residVar</code> attributes of the result.<br />
* Prediction intervals (as opposed to the response intervals) will be on the linear predictor or response scale depending on <code>type</code> (new to versions more recent than 3.12.0).</p>
</td></tr>
<tr><td><code id="predict_+3A_control">control</code></td>
<td>

<p>A list; a warning will direct you to relevant usage when needed.
</p>
</td></tr>
<tr><td><code id="predict_+3A_cluster_args">cluster_args</code></td>
<td>

<p>Passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. Parallel computations are possible if the slicing mechanism (as controlled by argument <code>blockSize</code>) is effective.
</p>
</td></tr>
<tr><td><code id="predict_+3A_verbose">verbose</code></td>
<td>

<p>A vector of booleans; it single currently used element is <code>"showpbar"</code>, which controls whether to show a progress bar in certain prediction variance computations.
</p>
</td></tr>
<tr><td><code id="predict_+3A_na.action">na.action</code></td>
<td>

<p>One of the functions dealing with <code>NA</code>s in data frames (see <code><a href="stats.html#topic+na.omit">na.omit</a></code>). if this is set to <code>na.exclude</code>, <code>NA</code>s will be included in the returned point predictions, for rows of the <code>newdata</code> which do not provide information for all required predictor variables. The effect of the default <code>na.omit</code> is to not include such <code>NA</code>s (this differs from the default of, e.g., <code>predict.lm</code>). Implementation is limited; in particular, <code>na.exclude</code> currently does not have the effect of including <code>NA</code>s in the optional attributes providing (co-)variance information, except the <code>"mv"</code> attribute for predictions of multivariate-response fits.
</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods. For the <code>get_</code>... functions, they are passed to <code>predict</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the <code><a href="#topic+predVar">predVar</a></code> help page for information about the different concepts of prediction variances handled by spaMM (uncertainty of point prediction vs. of response) and about options controlling their computation.
</p>
<p>If  <code>newdata</code> is NULL, <code>predict</code> returns the fitted responses, including random effects, from the object. 
Otherwise it computes new predictions including random effects as far as possible.   
For spatial random effects it constructs a correlation matrix <b>C</b> between new locations and locations in the original fit. Then it infers the random effects in the new locations as   <b>C</b> (<b>L</b>'<code class="reqn">)^{-1}</code> <b>v</b> (see <code><a href="#topic+spaMM">spaMM</a></code> for notation).   For non-spatial random effects, it checks whether any group (i.e., level of a random effect) in the new data was represented in the original data, and it adds the inferred random effect for this group to the prediction for individuals in this group. 
</p>
<p>In the <b>point prediction</b> of the linear predictor, the unconditional expected value of <code class="reqn">u</code> is assigned to the realizations of <code class="reqn">u</code> for unobserved levels of non-spatial random effects (it is zero in GLMMs but not for non-gaussian random effects), and the inferred value of <code class="reqn">u</code> is assigned in all other cases. Corresponding values of <code class="reqn">v</code> are then deduced. This computation yields the classical &ldquo;BLUP&rdquo; or empirical Bayes predictor in LMMs, but otherwise it may yield less well characterized predictors, where &ldquo;unconditional&rdquo; <code class="reqn">v</code> may not be its expected value when the <code>rand.family</code> link is not identity. 
</p>
<p>There are cases where prediction without a <code>newdata</code> argument may give results of different length than prediction with <code>newdata=</code>&lt;original data&gt;, as for <code><a href="#topic+predict">predict</a></code>. Notably, for multivariate-response fits, different subsets of lines of the data may be used for each submodel depending on the availability of all variables (including the response variable) for each submodel, and the resulting fitted values from each submodel will be used from prediction; while prediction with <code>newdata</code> does not check the availability of a response variable.
</p>
<p><b>Intervals</b> computations use the relevant variance estimates plugged in a Gaussian approximation, except for the simple linear model where it uses Student's <em>t</em> distribution.   
</p>


<h3>Value</h3>

<p>See Details in <code><a href="#topic+Tpoisson">Tpoisson</a></code> for questions specific to truncated distributions.
</p>
<p>For <code>predict</code>, a matrix or data frame (according to the <code>binding</code> argument), with optional attributes <code>frame</code>, <code>intervals</code>, <code>predVar</code>, <code>fixefVar</code>, <code>residVar</code>, and/or <code>respVar</code>, the last four holding one or more variance vector or covariance matrices. The further attribute <code>fittedName</code> contains the binding name, if any. The <code>frame</code> attribute includes information about any <code>na.action</code> effect on the new data. 
</p>
<p>The <code>get_</code>... extractor functions call <code>predict</code> and extract from its result the attribute implied by the name of the extractor. By default, <code>get_intervals</code> will return prediction intervals using <code>predVar</code>.
<code>get_predVar</code> with non-default <code>which</code> argument has the same effect as the <code>get_</code>... function whose name is implied by <code>which</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predVar">predVar</a></code> for information specific to prediction variances sensu lato, including the definitions of the four components of prediction variance, <code>fixefVar</code>, <code>predVar</code>, <code>residVar</code> and <code>respVar</code>, that can be requested through the <code>variances</code> argument;
<code><a href="#topic+get_cPredVar">get_cPredVar</a></code> for a bootstrap-corrected version of <code>get_predVar</code>;
<code><a href="#topic+residVar">residVar</a></code> for an alternative extractor for residual variances, more general than <code>get_residVar</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("blackcap")
fitobject &lt;- fitme(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap,
                       fixed=list(nu=4,rho=0.4,phi=0.05))
predict(fitobject)

#### multiple controls of prediction variances
## (1) fit with an additional random effect
grouped &lt;- cbind(blackcap,grp=c(rep(1,7),rep(2,7))) 
fitobject2 &lt;- fitme(migStatus ~ 1 +  (1|grp) +Matern(1|longitude+latitude),
                       data=grouped,  fixed=list(nu=4,rho=0.4,phi=0.05))

## (2) re.form usage to remove a random effect from point prediction and variances: 
predict(fitobject2,re.form= ~ 1 +  Matern(1|longitude+latitude))

## (3) comparison of covariance matrices for two types of new data
moregroups &lt;- grouped[1:5,]
rownames(moregroups) &lt;- paste0("newloc",1:5)
moregroups$grp &lt;- rep(3,5) ## all new data belong to an unobserved third group 
cov1 &lt;- get_predVar(fitobject2,newdata=moregroups,
                     variances=list(linPred=TRUE,cov=TRUE))
moregroups$grp &lt;- 3:7 ## all new data belong to distinct unobserved groups
cov2 &lt;- get_predVar(fitobject2,newdata=moregroups,
                     variances=list(linPred=TRUE,cov=TRUE))
cov1-cov2 ## the expected off-diagonal covariance due to the common group in the first fit.

## Not run: 
#### Other extractors:
#
fix_X_ZAC.object &lt;- preprocess_fix_corr(fitobject,fixdata=blackcap)
#
# ... for use in multiple calls to get_predCov_var_fix():
#
get_predCov_var_fix(fitobject,newdata=blackcap[14,],fix_X_ZAC.object=fix_X_ZAC.object)

#### Prediction with distinct given phi's in different locations, 
#   as specified by a resid.model:
#
varphi &lt;- cbind(blackcap,logphi=runif(14))
vphifit &lt;- fitme(migStatus ~ 1 + Matern(1|longitude+latitude), 
                     resid.model = list(formula=~0+offset(logphi)),
                     data=varphi,  fixed=list(nu=4,rho=0.4))
#
# For respVar computation (i.e., response variance, often called prediction variance), 
#   one then also needs to provide the variables used in 'resid.model', here 'logphi':
#
get_respVar(vphifit,newdata=data.frame(latitude=1,longitude=1,logphi=1))
#
# For default 'predVar' computation (i.e., uncertainty in point prediction), 
#   this is not needed:
#
get_predVar(vphifit,newdata=data.frame(latitude=1,longitude=1))                     

#### point predictions and variances with new X and Z
#
if(requireNamespace("rsae", quietly = TRUE)) {
  data("landsat", package = "rsae")
  fitobject &lt;- fitme(HACorn ~ PixelsCorn + PixelsSoybeans + (1|CountyName),
                     data=landsat[-33,])
  newXandZ &lt;- unique(data.frame(PixelsCorn=landsat$MeanPixelsCorn,
                                PixelsSoybeans=landsat$MeanPixelsSoybeans,
                                CountyName=landsat$CountyName))
  predict(fitobject,newdata=newXandZ,variances = list(predVar=TRUE))
  get_predVar(fitobject,newdata=newXandZ,variances = list(predVar=TRUE))
}


## End(Not run)
</code></pre>

<hr>
<h2 id='predVar'>Prediction and response variances</h2><span id='topic+predVar'></span>

<h3>Description</h3>

<p>spaMM allows computation of four variance components of prediction, returned by <code>predict</code> as &ldquo;...<code>Var</code>&rdquo; attributes: <code>predVar</code>, <code>fixefVar</code>, <code>residVar</code>, or <code>respVar</code>. The phrase &ldquo;prediction variance&rdquo; is used inconsistently in the literature. Often it is used to denote the uncertainty in the response (therefore, including the residual variance), but <span class="pkg">spaMM</span> follows some literature for mixed models in departing from this usage. Here, this uncertainly is called the response variance (<code>respVar</code>), while prediction variance (<code>predVar</code>) is used to denote the uncertainty in the linear predictor (as in Booth &amp; Hobert, 1998; see also Jeske &amp; Harville, 1988). The <code>respVar</code> is the <code>predVar</code> plus the residual variance <code>residVar</code>.
</p>
<p>Which components are returned is controlled in particular by the <code>type</code> and <code>variances</code> arguments of the relevant functions. <code>variances</code> is a list of booleans whose possible elements either match the possible returned components: <code>predVar</code>, <code>fixefVar</code>, <code>residVar</code>, or <code>respVar</code>; or may additionally include <code>linPred</code>, <code>disp</code>, <code>cov</code>, <code>as_tcrossfac_list</code> and possibly other cryptic ones. 
</p>
<p>The <code>predict</code> default value for all elements is <code>NULL</code>, which jointly translate to no component being computed, equivalently to setting all elements to <code>FALSE</code>. However, setting one component to <code>TRUE</code> may reverse the default effect for other components. In particular, by default, component <code>predVar</code> implies <code>linPred=TRUE, disp=TRUE</code> and component <code>respVar</code> additionally implies <code>residVar=TRUE</code>; in both cases, the <code>linPred=TRUE</code> default by default implies <code>fixefVar=TRUE</code>. Calling for one variance may imply that some of its components are not only computed but also returned as a distinct attribute.    
</p>
<p>By default the returned components are vectors of variances (with exceptions for some <code>type</code> value). To obtain covariance matrices (when applicable), set <code>cov=TRUE</code>. <code>as_tcrossfac_list=TRUE</code> can be used to return a list of matrices <code class="reqn">X_i</code> such that the <code>predVar</code> covariance matrix equals <code class="reqn">\sum_i X_i X'_i</code>. It thus provides a representation of the <code>predVar</code> that may be useful in particular when the <code>predVar</code> has large dimension, as the component <code class="reqn">X_i</code>s may require less memory (being possibly non-square or sparse).  
</p>
<p><code>residVar=TRUE</code> evaluates <code>residVar</code> the residual variance. For families without a dispersion parameter (e.g., <code>binomial</code> or <code>poisson</code>), this is as given by the <code>variance</code> function of the <code>family</code> object (in the binomial case, it is thus the variance of a single binary draw). For families with a dispersion parameter (such as <code class="reqn">\phi</code> for gaussian or Gamma families, negative-binomial, beta), it is the residual variance as function of the dispersion parameter, whether this parameter is a single scalar or follows a more complex residual-dispersion model.  Prior weights are however ignored (see the <code><a href="#topic+residVar">residVar</a></code> etractor for the opposite feature). For the beta-binomial family, it is also the variance of a single binary draw; although this family has a residual-dispersion parameter the latter variance is not affected by it.
</p>
<p><code>fixefVar=TRUE</code> evaluates <code>fixefVar</code>, the variance due to uncertainty in fixed effects (<b>X</b><code class="reqn">\beta</code>).
</p>
<p>Computations implying <code>linPred=TRUE</code> will take into account the variances of the linear predictor <code class="reqn">\eta</code>, i.e. the uncertainty in fixed effects (<b>X</b><code class="reqn">\beta</code>) and random effects (<b>ZLv</b>), <b>for given dispersion parameters</b> (see Details).
For fixed-effect models, the <code>fixefVar</code> calculations reduces to the <code>linPred</code> one.
</p>
<p>Computations implying <code>disp=TRUE</code> additionally include the effect of uncertainty in estimates of dispersion parameters (<code class="reqn">\lambda</code> and <code class="reqn">\phi</code>), with some limitations: this effect can be computed for a scalar residual variance (<code class="reqn">\phi</code>) and for several random effects with scalar variances (<code class="reqn">\lambda</code>). Thus, the argument <code>variances=list(predVar=TRUE)</code> implies that uncertainty of linear predictor, including uncertainty in dispersion parameters, is taken into account, and the argument <code>variances=list(respVar=TRUE)</code> additionally includes residual variance.
</p>


<h3>Details</h3>

<p><code>fixefVar</code> is the (co)variance of <b>X</b><code class="reqn">\beta</code>, deduced from the asymptotic covariance matrix of <code class="reqn">\beta</code> estimates. 
</p>
<p><code>linPred</code> is the prediction (co)variance of <code class="reqn">\eta</code>=<b>X</b><code class="reqn">\beta</code>+<b>Z</b><b>v</b> (see <code><a href="#topic+HLfit">HLfit</a></code> Details for notation, and keep in mind that new matrices may replace the ones from the fit object when <code>newdata</code> are used), by default computed for given dispersion parameters. It takes into account the joint uncertainty in estimation of <code class="reqn">\beta</code> and prediction of <b>v</b>. 
In particular, for new levels of the random effects, <code>predVar</code> computation takes into account uncertainty in prediction of <b>v</b> for these new levels. For <b>prediction covariance</b> with a new <b>Z</b>, it matters whether a single or multiple new levels are used: see Examples.
</p>
<p>For computations implying <code>disp=TRUE</code>, prediction variance may also include a term accounting for uncertainty in <code class="reqn">\phi</code> and <code class="reqn">\lambda</code>, computed following Booth and Hobert (1998, eq. 19). This computation ignores uncertainties in spatial correlation parameters. 
</p>
<p><code>respVar</code> is the sum of <code>predVar</code> (pre- and post-multiplied by <code class="reqn">\partial\mu/\partial\eta</code> for models with non-identity link) and of <code>residVar</code>. 
</p>
<p>These variance calculations are approximate except for LMMs, and cannot be guaranteed to give accurate results.  
</p>


<h3>References</h3>

<p>Booth, J.G., Hobert, J.P. (1998) Standard errors of prediction in generalized linear mixed models. J. Am. Stat. Assoc. 93: 262-272. 
</p>
<p>Jeske, Daniel R. &amp; Harville, David A. (1988) Prediction-interval procedures and (fixed-effects) confidence-interval procedures for mixed linear models. Communications in Statistics - Theory and Methods, 17: 1053-1087. <a href="https://doi.org/10.1080/03610928808829672">doi:10.1080/03610928808829672</a> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# (but run in help("get_predVar"))
data("blackcap")
fitobject &lt;- fitme(migStatus ~ 1 + Matern(1|longitude+latitude),data=blackcap,
                       fixed=list(nu=4,rho=0.4,phi=0.05))

#### multiple controls of prediction variances
# (1) fit with an additional random effect
grouped &lt;- cbind(blackcap,grp=c(rep(1,7),rep(2,7))) 
fitobject &lt;- fitme(migStatus ~ 1 +  (1|grp) +Matern(1|longitude+latitude),
                       data=grouped,  fixed=list(nu=4,rho=0.4,phi=0.05))

# (2) re.form usage to remove a random effect from point prediction and variances: 
predict(fitobject,re.form= ~ 1 +  Matern(1|longitude+latitude))

# (3) comparison of covariance matrices for two types of new data
moregroups &lt;- grouped[1:5,]
rownames(moregroups) &lt;- paste0("newloc",1:5)
moregroups$grp &lt;- rep(3,5) ## all new data belong to an unobserved third group 
cov1 &lt;- get_predVar(fitobject,newdata=moregroups,
                     variances=list(linPred=TRUE,cov=TRUE))
moregroups$grp &lt;- 3:7 ## all new data belong to distinct unobserved groups
cov2 &lt;- get_predVar(fitobject,newdata=moregroups,
                     variances=list(linPred=TRUE,cov=TRUE))
cov1-cov2 ## the expected off-diagonal covariance due to the common group in the first fit.


## End(Not run)
## see help("get_predVar") for further examples
</code></pre>

<hr>
<h2 id='pseudoR2'>
Pseudo R-squared
</h2><span id='topic+pseudoR2'></span><span id='topic+LR2R2'></span>

<h3>Description</h3>

<p>Generalization of R-squared based on likelihood ratios, called pseudo-R2 below, and variously attributed to Cragg &amp; Uhler (1970), Cox &amp; Snell (1989), Magee (1990) and some other authors (see comments in the References section). The null model used in the definition of R2 can be modified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseudoR2(fitobject, nullform = . ~ 1, R2fun = LR2R2, rescale=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pseudoR2_+3A_fitobject">fitobject</code></td>
<td>

<p>The fitted model object, obtained as the return value of a <span class="pkg">spaMM</span> fitting function.
</p>
</td></tr>
<tr><td><code id="pseudoR2_+3A_nullform">nullform</code></td>
<td>

<p>Mean-response formula for the null model. The default value (including only an intercept) represents the traditional choice in R2 computation for linear models. Alternative formulas (including, e.g., random effects) can be specified using either the <code><a href="#topic+update.formula">update.formula</a></code> syntax (e.g., with a <code>'.'</code> on the right hand side; note that <span class="pkg">spaMM</span>'s updating conventions differ from those implemented by <code>stats::update.formula</code>, see <code><a href="#topic+update.HLfit">update.HLfit</a></code>), or a full formula (which may be a safer syntax).
</p>
</td></tr>
<tr><td><code id="pseudoR2_+3A_r2fun">R2fun</code></td>
<td>

<p>The backend function computing R2 given the fitted and null model. The default implements the pseudo-R2. For linear models, it reduces to the canonical R2 and the value adjusted as in <code>summary.lm</code> is also returned.
</p>
</td></tr>
<tr><td><code id="pseudoR2_+3A_rescale">rescale</code></td>
<td>
<p>Boolean or formula, controlling whether and how to rescale R2 so that its maximum possible value is 1 (often considered for discrete-response models). If a formula, it should specify the model with maximal R2. If TRUE, rescaling is performed in a way meaningful only for binary logistic regression (see  Examples for how this is implemented).</p>
</td></tr>
<tr><td><code id="pseudoR2_+3A_verbose">verbose</code></td>
<td>

<p>Boolean; whether to display various informations about the procedure (most notably, to warn about some potential problem in applying the default procedure to <code>fitobject</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>None of the R2-like computations I am aware of helps in addressing, for the general class of models handled by <span class="pkg">spaMM</span>, a well-defined inference task (comparable to, say, formally testing goodness of fit, or measuring accuracy of prediction of new data as considered for AIC). This problem has been well-known (e.g., Magee, 1990), and the canonical R2 itself for linear models is not devoid of weaknesses from this perspective (e.g., <a href="https://stats.stackexchange.com/questions/13314/is-r2-useful-or-dangerous">https://stats.stackexchange.com/questions/13314/is-r2-useful-or-dangerous</a>). As a consequence, strong statements about the properties that R2 should have are difficult to follow (and this includes the claim that it should always have maximum value 1).
</p>
<p>Given the above problems, (1) ultimately the main reason for computing R2 may be to deal with requests by misguided reviewers; (2) no attempt has been made here to implement the wide diversity of R2-like descriptors discussed in the literature. The <code>LR2R2</code> backend function implements the pseudo-R2, chosen on the basis that this is the simplest general method that makes at least as much sense as any other computation I have seen; and implementation of rescaling by maximal R2 is minimal (the examples explain some of its details). <code>LR2R2</code> allows adaptation of the R2 definition for mixed-effect models, by including some random effect(s) in the null model, using the  <code>nullform</code> argument.
</p>


<h3>Value</h3>

<p>As returned by the function specified by argument <code>R2fun</code>. The default function returns a numeric vector of length 2 for linear models and a single value otherwise.
</p>


<h3>References</h3>

<p>Cox, D.R., Snell, E.J. (1989). The analysis of binary data (2nd ed.). Chapman and Hall.<br />
Often cited in this context, but they barely mention the topic, in an exercise p. 208-209.
</p>
<p>Pseudo-R2 is known to go back at least to<br /> 
Cragg, J. G., &amp; Uhler, R. S. (1970). The demand for automobiles. The Canadian Journal of Economics, 3(3), 386. <a href="https://doi.org/10.2307/133656">doi:10.2307/133656</a><br />
where they already discussed its rescaling by a maximum value, in the context of binary regression.
</p>
<p>Magee, L. (1990) R2 Measures based on Wald and likelihood ratio joint significance tests. The American Statistician, 44, 250-253. <a href="https://doi.org/10.1080/00031305.1990.10475731">doi:10.1080/00031305.1990.10475731</a><br />
also often cited for the pseudo-R2, this paper reformulates some related descriptors and concisely reviews earlier literature. 
</p>
<p>Nagelkerke, N.J.D. (1991) A note on a general definition of the coefficient of determination. Biometrika, Vol. 78, No. 3. (Sep., 1991), pp. 691-692. <a href="https://doi.org/10.1093/biomet/78.3.691">doi:10.1093/biomet/78.3.691</a><br />
details the properties of pseudo-R2 (including the way it &ldquo;partitions&rdquo; variation). Argues emphatically for its rescaling, for which it is often cited.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Pseudo-R2 *is* R2 for linear models:
#
# lmfit &lt;- lm(sr ~ pop15+pop75+dpi+ddpi , data = LifeCycleSavings)
# summary(lmfit) # Multiple R-squared = 0.3385, adjusted = 0.2797
#
spfit &lt;- fitme(sr ~ pop15+pop75+dpi+ddpi , data = LifeCycleSavings)
pseudoR2(spfit)  # consistent with summary(lmfit)

#### Toy example of pseudo-R2 for binary data
#
set.seed(123)
toydf &lt;- data.frame(x=seq(50), y=sample(0:1,50,TRUE))
#
##   Binary logistic regression:
#
binlog &lt;- fitme(y~x, data=toydf, family=binomial())
(blR2 &lt;- pseudoR2(binlog)) # quite low, despite the model being correct
#
##   Rescaling by 'maximum possible' R2 for binary logistic regression:
#
pseudoR2(binlog, rescale=TRUE)
#
#    which is acheived by silently computing the maximum possible R2 value 
#    by the following brutal but effective way:
#
perfbinlog &lt;- fitme(y~I(y), data=toydf, family=binomial())
(maxblR2 &lt;- pseudoR2(perfbinlog)) # = 0.7397...
#
# (this 'maximum possible' value would be modified if the null model were modified).
#
blR2/maxblR2       # again, rescaled value 
#
##   Same by more general syntax:
#
pseudoR2(binlog, rescale=y~I(y)) 
</code></pre>

<hr>
<h2 id='random-effects'>
Structure of random effects
</h2><span id='topic+random-effects'></span>

<h3>Description</h3>

<p>The structure of random-effect models adjustable by spaMM can generally be described by the following steps. 
</p>
<p>First, independent and  identically distributed (iid) random effects <b>u</b> are drawn from one of the following distributions:  <b>Gaussian</b> with zero mean, unit variance, and identity link; <b>Beta</b>-distributed, where <code class="reqn">u</code> <code>~</code> <code class="reqn">B(1/(2\lambda),1/(2\lambda))</code> with mean=1/2, and var<code class="reqn">=\lambda/[4(1+\lambda)]</code>; and with logit link <code>v=logit(u)</code>;
<b>Gamma</b>-distributed random effects, where <code class="reqn">u</code><code> ~ Gamma(shape=</code>1+1/<code class="reqn">\lambda</code>,<b>scale=</b>1/<code class="reqn">\lambda</code>): see <code><a href="#topic+Gamma">Gamma</a></code> for allowed links and further details; and <b>Inverse-Gamma</b>-distributed random effects, where <code class="reqn">u</code> <code>~</code> inverse-Gamma(<code>shape=</code>1+1/<code class="reqn">\lambda</code>,<b>rate=</b>1/<code class="reqn">\lambda</code>): see <code><a href="#topic+inverse.Gamma">inverse.Gamma</a></code> for allowed links and further details.
</p>
<p>Second, a transformation <b>v</b><code class="reqn">=f</code>(<b>u</b>) is applied (this defines <b>v</b> whose elements are still iid). 
</p>
<p>Third, correlated random effects are obtained as <b>Mv</b>, where the matrix <b>M</b> can describe spatial correlation between observed locations, block effects (or repeated observations in given locations), and possibly also correlations involving unobserved locations (as is often the case for autoregressive models). In most cases <b>M</b> is determined from the model formula, but it can also be controlled by <a href="#topic+covStruct">covStruct</a> argument. <b>M</b> takes the form <b>ZL</b> or <b>ZAL</b>, where <b>Z</b> is determined from the model formula, the optional <b>A</b> factor is given by the optional <code>"AMatrices"</code> attribute of argument <code><a href="#topic+covStruct">covStruct</a></code> of <code>HLCor</code> (also handled by <code>fitme</code> and <code>corrHLfit</code>), and <b>L</b> can be determined from the model formula or from <code>covStruct</code>. In particular:
</p>
<p><code style="white-space: pre;">&#8288; * &#8288;</code><b>Z</b> is typically an incidence matrix: its elements <code class="reqn">z_{ij}</code> are 1 if the <code class="reqn">i</code>th observation is affected by the <code class="reqn">j</code>th  element of <code>ALb</code>, and zero otherwise.<br />
</p>
<p><code style="white-space: pre;">&#8288; * &#8288;</code>For spatial random effects, <b>L</b> is typically the Cholesky &ldquo;square root&rdquo; of a correlation matrix determined by the random effect specification (e.g., <code>Matern(...)</code>), or given by the <code>covStruct</code> argument. This may be meaningful only for Gaussian random effects. Coefficients for each level of a random-coefficient model can also be represented as <b>Lv</b> where <b>L</b> is the &ldquo;square root&rdquo; of a correlation matrix.<br />
</p>
<p><code style="white-space: pre;">&#8288; * &#8288;</code>If there is one response value par location, <b>L</b> for a spatial random effect is thus a square matrix whose dimension is the number of observations. Alternatively, several observations may be taken in the same location, and a matrix <b>Z</b> (automatically constructed) tells which element of <b>Lv</b> affects each observation. The linear predictor then contains a term of the form <b>ZLv</b>, where <code>dim(Z)</code> is (number of observations,number of locations). 
</p>
<p><code style="white-space: pre;">&#8288; * &#8288;</code>in <code><a href="#topic+IMRF">IMRF</a></code> random effects (IMRF for Interpolated Markov Random Fields), the realized random effects in response locations are defined as linear combinations <b>ALv</b> of random effects <b>Lv</b> in distinct locations. In that case the dimension of <b>L</b> is the number of such distinct locations, an automatically constructed <b>A</b> matrix maps them to the observed locations, and <b>Z</b> again maps them to possibly repeated observations in observed locations.
</p>

<hr>
<h2 id='rankinfo'>
Checking the rank of the fixed-effects design matrix
</h2><span id='topic+rankinfo'></span><span id='topic+get_rankinfo'></span>

<h3>Description</h3>

<p>By default, fitting functions in <code>spaMM</code> check the rank of the design matrix for fixed effects, as <code>stats::lm</code>
or <code>stats::glm</code> do (but not, say, <code>nlme::lme</code>). This computation can be quite long.  
To save time when fitting different models with the same fixed-effect terms to the same data, 
the result of the check can be extracted from a return object by <code>get_rankinfo()</code>,
and can be provided as argument <code>control.HLfit$rankinfo</code> to another fit. Alternatively, the check will not be performed if
<code>control.HLfit$rankinfo</code> is set to <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_rankinfo(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankinfo_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The check is performed by a call to <code>qr()</code> methods for either dense or sparse matrices. 
If the design matrix is singular, a set of columns from the design matrix that define a non-singular matrix is identified. Note that different sets may be identified by sparse- and dense-matrix <code>qr</code> methods.
</p>


<h3>Value</h3>

<p>A list with elements <code>rank</code>, <code>whichcols</code> (a set of columns that define a non-singular matrix), and <code>method</code> (identifying the algorithm used).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data preparation
# Singular matrix from ?Matrix::qr :
singX &lt;- cbind(int = 1,
           b1=rep(1:0, each=3), b2=rep(0:1, each=3),
           c1=rep(c(1,0,0), 2), c2=rep(c(0,1,0), 2), c3=rep(c(0,0,1),2))
rownames(singX) &lt;- paste0("r", seq_len(nrow(singX)))
donn &lt;- as.data.frame(singX)
set.seed(123)
donn$y &lt;- runif(6)

fitlm &lt;- fitme(y~int+ b1+b2+c1+c2+c3,data=donn)
get_rankinfo(fitlm)

</code></pre>

<hr>
<h2 id='register_cF'>
Declare corrFamily constructor for use in formula
</h2><span id='topic+register_cF'></span><span id='topic+unregister_cF'></span>

<h3>Description</h3>

<p><code>register_cF</code> registers the name of a new corrFamily constructor so that it can be used as the keyword of a random effect in a formula (as in <code>y ~ 1 + ARp()</code>). <code>unregister_cF</code> cancels this.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>register_cF(corrFamilies = NULL, reset = FALSE)
unregister_cF(corrFamilies)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="register_cF_+3A_corrfamilies">corrFamilies</code></td>
<td>

<p>NULL, or character vector of names of corrFamily constructors. 
</p>
</td></tr>
<tr><td><code id="register_cF_+3A_reset">reset</code></td>
<td>

<p>Boolean. Set it to <code>TRUE</code> in order to reset the list of registered constructors to the <span class="pkg">spaMM</span> built-in default, before registering the ones specified by <code>corrFamilies</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value; operates through side-effects on internal variables. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ts &lt;- data.frame(lh=lh,time=seq(48)) ## using 'lh' data from 'stats' package

myARp &lt;- ARp                   #  defines 'new' corrFamily from built-in one

# Now, this would not yet work:

# fitme(lh ~ 1 + myARp(1|time), data=ts, method="REML")

# but this works if we first register "myARp"

register_cF("myARp")           #  registers it

fitme(lh ~ 1 + myARp(1|time), data=ts, method="REML")
#
# same as 
#
fitme(lh ~ 1 + corrFamily(1|time), data=ts, method="REML",
                  covStruct=list(corrFamily=myARp()))
# 
# showing it's possible not to register myARp, 
# although this has limitations (see Details in help("corrFamily")).

## Specifying arguments of the corrFamily constructor:

fitme(lh ~ 1 + myARp(1|time, p=3), data=ts, method="REML")
#                  
# same as
#
fitme(lh ~ 1 + corrFamily(1|time), data=ts, method="REML",
                  covStruct=list(corrFamily=ARp(p=3)))
                  
unregister_cF("myARp") # Tidy things before leaving.                  
                  
</code></pre>

<hr>
<h2 id='resid.model'>Structured dispersion models</h2><span id='topic+resid.model'></span>

<h3>Description</h3>

<p>The <code>resid.model</code> argument of fitting functions can be used to specify a model for a residual-dispersion parameter of various response families, that is, either<br />
(1) the <code class="reqn">\phi</code> parameter of the gaussian and Gamma GLM families;<br />
(2a) the dispersion parameter of some other GLM families, such as the shape parameter of the negbin1 and negbin2 families; or<br />
(2b) the dispersion parameter of some other (non-GLM) response families, such as the precision parameter of the beta response family.
</p>
<p>This documentation is more specifically for case (2). Case (1) is more specifically documented as <code><a href="#topic+phi-resid.model">phi-resid.model</a></code>.
</p>
<p>In case (2) the model for the dispersion parameter is constrained as a fixed-effect model, of the form<br />
dispersion parameter =<code> exp(</code><b>X</b><code class="reqn">\beta</code><code>+offset</code>),<br /> 
and specified using the standard <code>formula</code> syntax. Random effects cannot be included, in contrast to dispersion models for case (1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'># 'resid.model' argument of fitme() and fitmv()
</code></pre>


<h3>Arguments</h3>

<p>The <code>resid.model</code> for case (2) is simply a formula (without left-hand side) for the logarithm of the dispersion parameter. Fixed <code class="reqn">\beta</code> values can be specified through the <code>rdisPars</code> element of the <code>fixed</code> argument in the <code>fitme</code> call (or through the <code>fixed</code> argument of each submodel of a <code>fitmv</code> call). Likewise, initial values can be specified through the <code>init</code> argument.  
</p>


<h3>Details</h3>

<p>In case (2) a fixed &ldquo;heteroscedastic&rdquo; model can also be specified directly through the family specification, e.g., family=negbin1(shape=&lt;vector&gt;) where the vector has the length of the response vector, but this may not be suitable if the model is to be used for prediction purposes (where the residual-dispersion model should be specified in such a way that one can &ldquo;predict&rdquo; new dispersion values from it).
</p>
<p>The design matrix for the specified model is internally rescaled to avoid numerical problems. That means that there is no need to rescale the predictor variable, even if it tends to take large (cf &lsquo;population&rsquo; variable in the Examples) of small values (this is also true for fixed-effect predictors of the mean-response model).
</p>


<h3>Value</h3>

<p>The fit results for the residual model are accessible through the summary and various extractors. In particular, the <code>get_fittedPars</code> extractor will by default include in its return value the <code>rdisPars</code> element, which is here the vector of fitted <code class="reqn">\beta</code> coefficients.  <code>residVar(., which="fam_parm")</code> will return the vector of fitted values of the dispersion parameter. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("scotlip")
if (spaMM.getOption("example_maxtime")&gt;3) {
(toyfit &lt;- fitme(cases~1+(1|id),family=negbin1(), data=scotlip, resid.model = ~ population))

# =&gt; This toy example is a bit challenging to fit because the data set is small and 
# individual-level variation is here described both by a random effect 
# and by a two-parameter negbin1 residual variation. The fit might often stop 
# at a local maximum of the logLik in such cases (although there is no evidence
# that this is presently the case).
}
</code></pre>

<hr>
<h2 id='residuals.HLfit'>
Extract model residuals
</h2><span id='topic+residuals'></span><span id='topic+residuals.HLfit'></span>

<h3>Description</h3>

<p>Extracts several types of residuals from an object of class <code>HLfit</code>. Note that the default type (<code>"deviance"</code>) of returned residuals differs from the default  (response residuals) of equivalent functions in base R.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
residuals(object, 
  type = c("deviance", "pearson", "response", "working", "std_dev_res"), force=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.HLfit_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="residuals.HLfit_+3A_type">type</code></td>
<td>

<p>The type of residuals which should be returned. See Details for additional information. 
</p>
</td></tr>
<tr><td><code id="residuals.HLfit_+3A_force">force</code></td>
<td>
<p>Boolean: to force recomputation of the <code>"std_dev_res"</code> residuals even if they are available in the object, for checking purposes.</p>
</td></tr>
<tr><td><code id="residuals.HLfit_+3A_...">...</code></td>
<td>
<p>For consistency with the generic.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The four types <code>"deviance"</code> (default), <code>"pearson"</code>, <code>"response"</code> are <code>"working"</code> are, for GLM families, the same that are returned by <code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code>. <code>"working"</code> residuals may be returned only for fixed-effect models. <code>"deviance"</code> residuals are the signed square root of those returned by <code><a href="#topic+dev_resids">dev_resids</a></code> when there are no prior weights.
</p>
<p>In the presence of prior weights, what the standard extractors do is often a matter of confusion and <span class="pkg">spaMM</span> has not always been consistent with them. For a gaussian-response GLM (see Examples) <code>stats::deviance.lm</code> calls <code><a href="stats.html#topic+weighted.residuals">weighted.residuals</a>()</code> which returns <em>unscaled</em> deviance residuals weighted by prior weights. Unscaled deviance residuals are defined in McCullagh and Nelder 1989, p. 34 and depend on the response values and fitted values but not on the canonical <code class="reqn">\phi</code> parameter, and prior weights are not considered. <code>weighted.residuals()</code> still ignores <code class="reqn">\phi</code> but accounts for prior weights. This means that different <code>residuals(&lt;glm&gt;)</code> and <code>deviance(&lt;glm&gt;)</code> will be returned for equivalent fits with different parametrizations of the residual variance (as produced by <code>glm(., family=gaussian, weights=rep(2,nrow&lt;data&gt;))</code> versus the <code>glm</code> call without weights). <code>residuals(&lt;HLfit object&gt;,"deviance")</code> and <code>deviance(&lt;HLfit object&gt;,"deviance")</code> are consistent with this behavior. By contrast, <code>dev_resids(&lt;HLfit object&gt;)</code> always return the unscaled deviance residuals by default.   
</p>
<p>Following Lee et al. (2006, p.52), the standardized deviance residuals returned for <code>type="std_dev_res"</code> are defined as the deviance residuals divided by <code class="reqn">\phi\sqrt(1-q)</code>, where the deviance residuals are defined as for a GLM, <code class="reqn">\phi</code> is the dispersion parameter of the response family (a vector of values, for heteroscedastic cases), and <code class="reqn">q</code> is a vector of leverages given by <code>hatvalues(., type="std")</code> (see <code><a href="#topic+hatvalues">hatvalues</a></code> for details about these specific standardizing leverages).
</p>
<p>Some definitions must be extended for non-GLM response families. In the latter case, the deviance residuals are as defined in Details of <code><a href="#topic+llm.fit">llm.fit</a></code> (there is no concept of unscaled residuals here, nor indeed of scaled ones since the residual dispersion parameter is not generally a scale factor, but the returned deviance residuals for non-GLMs are analogous to the scaled ones for GLMs as they depend on residual dispersion). <code>"std_dev_res"</code> residuals are defined from them as shown above for GLM response families, with the additional convention that <code class="reqn">\phi=1</code> (since the family's own residual dispersion parameter already enters in the definition of deviance residuals for non-GLM families).  Pearson residuals and response residuals are defined as in <code>stats:::residuals.glm</code>.  The <code>"working"</code> residuals are defined for each response as <code class="reqn">- [d \log(clik)/d \eta]/[d^2 \log(clik)/d \eta^2]</code> where clik is the conditional likelihood.
</p>


<h3>Value</h3>

<p> A vector of residuals</p>


<h3>References</h3>

<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006). Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
fit &lt;- fitme(y ~X1+(1|batch) ,data=wafers, init=list(phi=NaN))  # : this 'init' 
#                 implies that standardized deviance residuals are saved in the 
#                 fit result, allowing the following comparison: 

r1 &lt;- residuals(fit, type="std_dev_res") # gets stored value
r2 &lt;- residuals(fit, type="std_dev_res", force=TRUE) # forced recomputation
if (diff(range(r1-r2))&gt;1e-14) stop()

##### 
## Not run: 
glmfit &lt;- glm(I(y/1000)~X1, family=gaussian(), data=wafers)
deviance(glmfit) #           3...                       (a)
sum(residuals(glmfit)^2) #   3...                       (b) 

# Same model, with different parametrization of residual variance 
glmfit2 &lt;- glm(I(y/1000)~X1, family=gaussian(), data=wafers, weights=rep(2,198))
deviance(glmfit2) #          6...                       (c)  
sum(residuals(glmfit2)^2) #  6...                       (d)

# Same comparison but for HLfit objects:
spfit &lt;- fitme(I(y/1000)~X1, family=gaussian(), data=wafers)
deviance(spfit) #            3...                       (e)
sum(residuals(spfit)^2) #    3...                       (f)  
sum(dev_resids(spfit)) #     3...                         

spfit2 &lt;- fitme(I(y/1000)~X1, family=gaussian(), data=wafers, prior.weights=rep(2,198))
deviance(spfit2) #           6...                       (g) ~ (c,d) # post v4.2.0
sum(residuals(spfit2)^2) #   6...                       (h) ~ (c,d) 
sum(dev_resids(spfit2)) #    3...                         

# Unscaled residuals should no depend on arbitrarily fixed residual variance:
spfit3 &lt;- fitme(I(y/1000)~X1, family=gaussian(), data=wafers, fixed=list(phi=2),
                prior.weights=rep(2,198))
deviance(spfit3) #           6...                       (i) ~ (g)
sum(residuals(spfit3)^2) #   6...                       (k) ~ (h)
sum(dev_resids(spfit3)) #    3...                         



## End(Not run)
</code></pre>

<hr>
<h2 id='residVar'>
Residual variance extractor
</h2><span id='topic+residVar'></span>

<h3>Description</h3>

<p>Extracts from a fit object the residual variance or, depending on the <code>which</code> argument, a family dispersion parameter phi (which is generally not the residual variance itself except for gaussian-response models without prior weights), or a vector of values of the dispersion parameter, or further information about the residual variance model. 
</p>
<p>For gaussian and Gamma response families, the <code>which = "var"</code> and <code>"phi"</code> cases are distinctive as prior weights, if any, are included in the return value. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residVar(object, which = "var", submodel = NULL, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residVar_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="residVar_+3A_which">which</code></td>
<td>
<p>Character: <code>"var"</code> for the fitted residual variances, <code>"phi"</code> for the fitted phi values, <code>"fam_parm"</code> for the dispersion parameter of <code>COMPoisson</code>, <code>negbin1</code>, <code>negbin2</code>, <code>beta_resp</code> or <code>betabin</code> families, <code>"fit"</code> for the fitted residual model (a GLM or a mixed model for residual variances, if not a simpler object),  and <code>"family"</code> or <code>"formula"</code> for such properties of the residual model.</p>
</td></tr>
<tr><td><code id="residVar_+3A_submodel">submodel</code></td>
<td>
<p>integer: the index of a submodel, if <code>object</code> is a multivariate-response model fitted by <code>fitmv</code>. This argument is mandatory for all <code>which</code> values except <code>"var"</code> and <code>"phi"</code>.</p>
</td></tr>
<tr><td><code id="residVar_+3A_newdata">newdata</code></td>
<td>
<p><b>Either</b> NULL, a matrix or data frame, or a numeric vector. See <code><a href="#topic+predict.HLfit">predict.HLfit</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>which="var"</code> (default) and <code>"phi"</code> always return a vector of residual variances (or, alternatively, phi values) of length determined by the <code>newdata</code> and <code>submodel</code> arguments. <br /> 
<code>which="fit"</code> returns an object of class <code>HLfit</code>, <code>glm</code>, or a single scalar depending on the residual dispersion model (<code>which="fit"</code> is the option to be used to extract the scalar phi value).<br /> 
<code>which="fam_parm"</code> returns either NULL (for families without such a parameter), a vector (if a <code>resid.model</code> was specified for relevant families), a single scalar (relevant families, without <code>resid.model</code>), or a list of such objects (for multivariate-response models).<br />
Other <code>which</code> values return an object of class <code>family</code> or <code>formula</code> as expected. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_residVar">get_residVar</a></code> is a alternative extractor of residual variances with different features inherited from <code>get_predVar</code>. In particular, it is more suited for computing the residual variances of new realizations of a fitted model, not accounting for prior weights used in fitting the model (basic examples of using the <span class="pkg">IsoriX</span> package provide a context where this is the appropriate design decision). By contrast, <code>residVar</code> aims to account for prior weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data preparation: simulated trivial life-history data
set.seed(123)
nind &lt;- 20L
u &lt;- rnorm(nind)
lfh &lt;- data.frame(
  id=seq_len(nind), id2=seq_len(nind), 
  feco= rpois(nind, lambda = exp(1+u)), 
  growth=rgamma(nind,shape=1/0.2, scale=0.2*exp(1+u)) # mean=exp(1+u), var= 0.2*mean^2
)
# multivariate-response fit                  
fitlfh &lt;- fitmv(submodels=list(list(feco ~ 1+(1|id), family=poisson()),
                               list(growth ~ 1+(1|id), family=Gamma(log))),
                data=lfh)
#
residVar(fitlfh)
residVar(fitlfh, which="phi") # shows fixed phi=1 for Poisson responses
residVar(fitlfh, submodel=2)
residVar(fitlfh, which="family", submodel=2)
residVar(fitlfh, which="formula", submodel=2)
residVar(fitlfh, which="fit", submodel=2) # Fit here characterized by a single scalar
</code></pre>

<hr>
<h2 id='salamander'>
Salamander mating data
</h2><span id='topic+salamander'></span>

<h3>Description</h3>

<p>Data from a salamander mating experiment discussed by McCullagh and Nelder (1989, Ch. 14). Twenty males and twenty females from two populations (Rough Butt and Whiteside) were each paired with 6 individuals from their own or from the other population. The experiments were later published by Arnold et al. (1996).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("salamander")</code></pre>


<h3>Format</h3>

<p>The data frame includes 360 observations on the following variables:
</p>

<dl>
<dt>Female</dt><dd><p>Index of the female;</p>
</dd>
<dt>Male</dt><dd><p>Index of the male;</p>
</dd>
<dt>Mate</dt><dd><p>Whether the pair successfully mated or not;</p>
</dd>
<dt>TypeF</dt><dd><p>Population of origin of female;</p>
</dd>
<dt>TypeM</dt><dd><p>Population of origin of male;</p>
</dd>
<dt>Cross</dt><dd><p>Interaction term between <code>TypeF</code> and <code>TypeM</code>;</p>
</dd>
<dt>Season</dt><dd><p>A factor with levels <code>Summer</code> and <code>Fall</code>;</p>
</dd>
<dt>Experiment</dt><dd><p>Index of experiment</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data frame was borrowed from the <code>HGLMMM</code> package (Molas and Lesaffre, 2011), version 0.1.2.
</p>


<h3>References</h3>

<p>Arnold, S.J., Verrell, P.A., and Tilley S.G. (1996) The evolution of asymmetry in sexual isolation: a model and a test case. Evolution 50, 1024-1033.
</p>
<p>McCullagh, P. and Nelder, J.A. (1989). Generalized Linear Models, 2nd edition. London: Chapman &amp; Hall.
</p>
<p>Molas, M., Lesaffre, E. (2011) Hierarchical Generalized Linear Models: The R Package HGLMMM. Journal of Statistical Software 39, 1-20.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("salamander")

## Not run:  

HLfit(cbind(Mate,1-Mate)~TypeF+TypeM+TypeF*TypeM+(1|Female)+(1|Male),
      family=binomial(),data=salamander,method="ML")
# equivalent fo using fitme(), but here a bit faster

## End(Not run)
</code></pre>

<hr>
<h2 id='scotlip'>Lip cancer in Scotland 1975 - 1980</h2><span id='topic+scotlip'></span><span id='topic+Nmatrix'></span>

<h3>Description</h3>

<p>This data set provides counts of lip cancer diagnoses made in Scottish districts from 1975 to 1980, 
and additional information relative to these data from Clayton and Kaldor (1987) and Breslow and Clayton (1993).
The data set contains (for each district) counts of disease events and estimates of the fraction of the population involved 
in outdoor industry (agriculture, fishing, and forestry) which exposes it to sunlight. 
</p>
<p><code>data("scotlip")</code> actually loads a data frame, 
<code>scotlip</code>, and an adjacency matrix, <code>Nmatrix</code>, between 56 Scottish districts, 
as given by Clayton and Kaldor (1987, Table 1). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("scotlip")</code></pre>


<h3>Format</h3>

<p>The data frame includes 56 observations on the following 7 variables:
</p>

<dl>
<dt>gridcode</dt><dd><p>alternative district identifier.</p>
</dd>
<dt>id</dt><dd><p>numeric district identifier (1 to 56).</p>
</dd>
<dt>district</dt><dd><p>district name.</p>
</dd>
<dt>cases</dt><dd><p>number of lip cancer cases diagnosed 1975 - 1980.</p>
</dd>
<dt>population</dt><dd><p>total person years at risk 1975 - 1980.</p>
</dd>
<dt>prop.ag</dt><dd><p>percent of the population engaged in outdoor industry.</p>
</dd>
<dt>expec</dt><dd><p>offsets considered by Breslow and Clayton (1993, Table 6, 'Exp' variable)</p>
</dd>
</dl>

<p>The rows are ordered according to <code>gridcode</code>, so that they match the rows of <code>Nmatrix</code>.
</p>


<h3>References</h3>

<p>Clayton D, Kaldor J (1987). Empirical Bayes estimates of age-standardized relative risks for use in disease mapping. Biometrics, 43: 671 - 681. 
</p>
<p>Breslow, NE, Clayton, DG. (1993). Approximate Inference in Generalized Linear Mixed Models.
Journal of the American Statistical Association: 88 9-25.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("scotlip")
fitme(cases~I(log(expec)), data=scotlip, adjMatrix=Nmatrix, family=poisson)

## see 'help(autoregressive)' for additional examples involving 'scotlip'.
</code></pre>

<hr>
<h2 id='seaMask'>
Masks of seas or lands
</h2><span id='topic+seaMask'></span><span id='topic+oceanmask'></span><span id='topic+landMask'></span><span id='topic+worldcountries'></span>

<h3>Description</h3>

<p>These convenient masks can be added to maps of (parts of) the world to mask map information for these areas. 
</p>
<p>However, many other tools may be available since this documentation was conceived. See e.g. the <span class="pkg">rnaturalearth</span> package,
used to provide a sea mask in an example for <code><a href="#topic+filled.mapMM">filled.mapMM</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("seaMask")
data("landMask")
# data("worldcountries") # deprecated and removed
# data("oceanmask") # deprecated and removed
</code></pre>


<h3>Format</h3>

<p><code>seaMask</code> and <code>landMask</code> are data frames with two variables, <code>x</code> and <code>y</code> for longitude and latitude. 
Its contents are suitable for use with <code><a href="graphics.html#topic+polypath">polypath</a></code>: they define different polygones, each separated by a row of <code>NA</code>s.
</p>
<p><code>worldcountries</code> and <code>oceanmask</code> were <code>sp::SpatialPolygonsDataFrame</code> objects previously included in spaMM (see Details for replacement). Such objects were useful for creating land masks for different geographical projections. 
</p>


<h3>Details</h3>

<p>The removed objects <code>worldcountries</code> and <code>oceanmask</code> were suitable for plots involving geographical projections not available through <code>map</code>, and more generally for raster plots. A land mask could be produced out of <code>worldcountries</code> by filling the countries, as by <code>fill="black"</code> in the code for <code>country.layer</code> in the Examples in <a href="https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/example_raster.html">https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/example_raster.html</a>. These objects may now be available through the same web page, but a better place to look for the same functionality is the <code>IsoriX</code> package (objects <code>CountryBorders</code> and <code>OceanMask</code>).   
</p>
<p><code>seaMask</code> and <code>landMask</code> were created from the world map in the maps package. 
<code>polypath</code> requires polygons, while <code>map(interior=FALSE,plot=FALSE)</code> returns small segments. <code>landMask</code> is the result of reconnecting the segments into full coastlines of all land blocks. 
</p>


<h3>See Also</h3>

<p><a href="https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/example_raster.html">https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/example_raster.html</a> for access to, and use of <code>worldcountries</code> and <code>oceanmask</code>; <a href="https://cran.r-project.org/package=IsoriX">https://cran.r-project.org/package=IsoriX</a> for replacement <code>CountryBorders</code> and <code>OceanMask</code> for these objects.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Predicting behaviour for a land bird: simplified fit for illustration
data("blackcap")
bfit &lt;- fitme(migStatus ~ means+ Matern(1|longitude+latitude),data=blackcap,
               fixed=list(lambda=0.5537,phi=1.376e-05,rho=0.0544740,nu=0.6286311))
                  
## the plot itself, with a sea mask,
## and an ad hoc 'pointmask' to see better the predictions on small islands 
#
def_pointmask &lt;- function(xy,r=1,npts=12) {
  theta &lt;- 2*pi/npts *seq(npts)
  hexas &lt;- lapply(seq(nrow(xy)), function(li){
    p &lt;- as.numeric(xy[li,])
    hexa &lt;- cbind(x=p[1]+r*cos(theta),y=p[2]+r*sin(theta))
    rbind(rep(NA,2),hexa) ## initial NA before each polygon
  })
  do.call(rbind,hexas)
}
ll &lt;- blackcap[,c("longitude","latitude")]
pointmask &lt;- def_pointmask(ll[c(2,4,5,6,7),],r=0.8) ## small islands only
#
if (spaMM.getOption("example_maxtime")&gt;1) {
  data("seaMask")
  
  filled.mapMM(bfit,add.map=TRUE,
             plot.title=title(main="Inferred migration propensity of blackcaps",
                               xlab="longitude",ylab="latitude"),
             decorations=quote(points(pred[,coordinates],cex=1,pch="+")),
             plot.axes=quote({axis(1);axis(2);
                        polypath(rbind(seaMask,pointmask),border=FALSE,
                                 col="grey", rule="evenodd")
             }))
}
</code></pre>

<hr>
<h2 id='seeds'>
Seed germination data
</h2><span id='topic+seeds'></span>

<h3>Description</h3>

<p>A classic toy data set, &ldquo;from research conducted by microbiologist Dr P. Whitney of Surrey University. A batch of tiny seeds is brushed onto a plate covered with a certain extract at a given dilution. The numbers of germinated and ungerminated seeds are subsequently counted&rdquo; (Crowder, 1978). Two seed types and two extracts are here considered in a 2x2 factorial design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("seeds")</code></pre>


<h3>Format</h3>

<p>The data frame includes 21 observations on the following variables:
</p>

<dl>
<dt>plate</dt><dd><p>Factor for replication;</p>
</dd>
<dt>seed</dt><dd><p>Seed type, a factor with two levels O73 and O75;</p>
</dd>
<dt>extract</dt><dd><p>Root extract, a factor with two levels Bean and Cucumber;</p>
</dd>
<dt>r</dt><dd><p>Number of seeds that germinated;</p>
</dd>
<dt>n</dt><dd><p>Total number of seeds tested</p>
</dd>
</dl>



<h3>Source</h3>

<p>Crowder (1978), Table 3.
</p>


<h3>References</h3>

<p>Crowder, M.J., 1978. Beta-binomial anova for proportions. Appl. Statist., 27, 34-37. 
</p>
<p>Y. Lee and J. A. Nelder. 1996. Hierarchical generalized linear models (with discussion). J. R. Statist. Soc. B, 58: 619-678. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># An extended quasi-likelihood (EQL) fit as considered by Lee &amp; Nelder (1996):
data("seeds") 
fitme(cbind(r,n-r)~seed*extract+(1|plate),family=binomial(),
      rand.family=Beta(),
      method="EQL-", # see help("method") for difference with "EQL+" method
      data=seeds)
</code></pre>

<hr>
<h2 id='setNbThreads'>
Parallel computations in fits
</h2><span id='topic+setNbThreads'></span>

<h3>Description</h3>

<p>A few steps of fitting can be parallelized. Currently it is possible to control the use of multiple threads by OpenMP by the Eigen library. By default only one thread will be used, but this may be modified by using <code>control.HLfit$NbThreads</code> in a fitting function's arguments, as in<br />
</p>
<pre>
avail_thr &lt;- parallel::detectCores(logical=FALSE) - 1L 
fitme(., control.HLfit=list(NbThreads=max(avail_thr, 1L)))
</pre>
<p>This control is distinct from that of post-fit steps such as bootstraps where some parallel computations are controlled e.g. the <code>nb_cores</code> argument of <code>spaMM_boot</code>. In cases where post-fits computation imply refits of models (as is typical of parametric bootstraps), the two parallelizations should not be combined, and the <span class="pkg">spaMM</span> code for post-fit operations will in principle automatically take care of this.  
</p>
<p>According to <a href="https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#OpenMP-support">https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#OpenMP-support</a>, using openMP may decrease the precision of some computations, and may be less efficient under Windows; and according to <a href="https://eigen.tuxfamily.org/dox/TopicMultiThreading.html">https://eigen.tuxfamily.org/dox/TopicMultiThreading.html</a> only a few Eigen computations will benefit from such parallelisation, mainly the dense matrix products. <span class="pkg">spaMM</span> will <em>suggest</em> using parallelisation when random effects have many levels and dense-correlation methods are selected (see <code><a href="#topic+algebra">algebra</a></code>), that is mainly for geostatiscal models with many locations. Speed gains appear moderate, as the slowest steps are not parallelized.      
</p>

<hr>
<h2 id='simulate.HLfit'>
Simulate realizations of a fitted model.
</h2><span id='topic+simulate.HLfit'></span><span id='topic+simulate.HLfitlist'></span><span id='topic+simulate_ranef'></span><span id='topic+simulate'></span><span id='topic+simulate4boot'></span>

<h3>Description</h3>

<p>From an HLfit object, <code>simulate.HLfit</code> function generates new samples given the estimated fixed effects 
and dispersion parameters. Simulation may be unconditional (the default, useful in many applications of parametric bootstrap), or conditional on the predicted values of random effects, or may draw from the conditional distribution of random effects given the observed response.
Simulations may be run for the original values of fixed-effect predictor variables and of random effect levels (spatial locations for spatial random effects), or for new values of these. 
</p>
<p><code>simulate4boot</code> is a wrapper around <code>simulate.HLfit</code> that can be used to precompute the bootstrap samples to be used by <code><a href="#topic+spaMM_boot">spaMM_boot</a></code> or <code><a href="#topic+spaMM2boot">spaMM2boot</a></code> through their <code>boot_samples</code> argument (and is called internally by these functions when <code>boot_samples</code> is NULL). 
</p>
<p><code>simulate_ranef</code> will only simulate and return a vector of random effects, more specifically some elements of <b>b</b> in the standard form <code>offset</code>+ <b>X</b><code class="reqn">\beta</code> + <b>Z b</b> for the linear predictor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
simulate(object, nsim = 1, seed = NULL, newdata = NULL, 
                         type = "marginal", re.form, conditional = NULL, 
                         verbose = c(type=TRUE,
                                     showpbar=eval(spaMM.getOption("barstyle"))), 
                         sizes = NULL, resp_testfn = NULL, phi_type = "predict", 
                         prior.weights = object$prior.weights, variances=list(), ...)

## S3 method for class 'HLfitlist'
simulate(object, nsim = 1, seed = NULL, 
                             newdata = object[[1]]$data, sizes = NULL, ...)

simulate4boot(object, nsim, seed=NULL, resp_testfn=NULL, type="marginal", 
              showpbar=eval(spaMM.getOption("barstyle")), ...)
simulate_ranef(object, which=NULL, newdata = NULL, nsim = 1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.HLfit_+3A_object">object</code></td>
<td>

<p>The return object of HLfit or similar function.
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_nsim">nsim</code></td>
<td>

<p>number of response vectors to simulate.  Defaults to '1'.
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_seed">seed</code></td>
<td>

<p>A seed for <code><a href="base.html#topic+set.seed">set.seed</a></code>. If such a value is provided, the initial state of the random number generator at a global level is restored on exit from simulate.
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_newdata">newdata</code></td>
<td>

<p>A data frame closely matching the original data, except that response values are not needed. May provide new values of fixed predictor variables, new spatial locations, new individuals within a block, or new values of the LHS in random-effect terms of the form <code>(&lt;LHS&gt;|&lt;RHS&gt;)</code>.   
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_re.form">re.form</code></td>
<td>
<p> formula for random effects to condition on. Default behaviour depends on the <code>type</code> argument. The joint default is the latter's default, i.e., unconditional simulation. <code>re.form</code> is currently ignored when 
<code>type="predVar"</code> 
(with a warning). Otherwise, <code>re.form=NULL</code> conditions on all random effects (as <code>type="residual"</code> does), and <code>re.form=NA</code> conditions on none of the random effects (as <code>type="marginal"</code> or <code>re.form=~0</code> do).  
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_type">type</code></td>
<td>

<p>character string specifying which uncertainties are taken into account in the linear predictor and notably in the random effect terms. Whatever the <code>type</code>, the residual variance is always accounted in the simulation output. <code>"marginal"</code> accounts for the marginal variance of the random effect (and, by default, also for the uncertainty in fixed effects); <code>"predVar"</code> accounts for the conditional distribution of the random effects given the data (see Details); and <code>"residual"</code> should perhaps be <code>"none"</code> as no uncertainty is accounted in the linear predictor: the simulation variance is only the residual variance of the fitted model.
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_conditional">conditional</code></td>
<td>

<p>Obsolete and will be deprecated. Boolean; TRUE and FALSE are equivalent to <code>type="residual"</code> and <code>type="marginal"</code>, respectively. 
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_verbose">verbose</code></td>
<td>

<p>Either a single boolean (which determines <code>verbose[["type"]]</code>, or a vector of booleans with possible elements <code>"type"</code> (to display basic information about the type of simulation) and <code>"showpbar"</code> (see <code>predict(.,verbose)</code>). 
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_sizes">sizes</code></td>
<td>

<p>A vector of sample sizes to simulate in the case of a binomial fit. Defaults to the sizes in the original data. A non-default value may be needed in particular when <code>newdata</code> of size different from the original data are provided. For multivariate-response fits, the <code>sizes</code> argument should then contain elements for response levels for non-binomial submodels (e.g. for submodels with families and response levels <code>poisson: 3</code> and <code>binomial: 2</code>, respectively, the <code>sizes</code> vector sould contain 5 elements, e.g. 1 1 1 5 10, only the last two of which will be used).  
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_resp_testfn">resp_testfn</code></td>
<td>

<p>NULL, or a function that tests a condition which simulated samples should satisfy. This function takes a response vector as argument and return a boolean (TRUE indicating that the sample satisfies the condition). 
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_phi_type">phi_type</code></td>
<td>

<p>Character string, either <code>"predict"</code> or one of the values possible for <code>type</code>. This controls the residual variance parameter <code class="reqn">\phi</code>. The default is to use predicted <code class="reqn">\phi</code> values from the fit, which are the fitted <code class="reqn">\phi</code> values except when a structured-dispersion model is involved together with non-NULL <code>newdata</code>. However, when a structured-dispersion model is involved, it is also possible to simulate new <code class="reqn">\phi</code> values, and for a mixed-effects structured-dispersion model, the same types of simulation controlled by <code>type</code> for the mean response can be performed as controlled by <code>phi_type</code>. For a fixed-effects structured-dispersion model, these types cannot be distinguished, and any <code>phi_type</code> distinct from <code>"predict"</code> will imply simulation under the fixed-effect model (see Examples). 
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_prior.weights">prior.weights</code></td>
<td>

<p>Prior weights that may be substituted to those of the original fit, with the same effect on the residual variance. 
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_variances">variances</code></td>
<td>

<p>Used when <code>type="predVar"</code>: see Details. 
</p>
</td></tr>  
<tr><td><code id="simulate.HLfit_+3A_...">...</code></td>
<td>

<p>For <code>simulate4boot</code>, further arguments passed to <code>simulate.HLfit</code> (e.g., <code>newdata</code>). For <code>simulate.HLfit</code>, further arguments only passed to <code>predict</code> in a speculative bit of code (see Details). 
</p>
</td></tr>
<tr><td><code id="simulate.HLfit_+3A_which">which</code></td>
<td>

<p>Integer, or integer vector: the random effect(s) (indexed as ordered as in the model formula) to be simulated. If NULL, all of them are simulated. 
</p>
</td></tr>  
<tr><td><code id="simulate.HLfit_+3A_showpbar">showpbar</code></td>
<td>

<p>Controls display of progress bar. See <code><a href="#topic+barstyle">barstyle</a></code> option for details.
</p>
</td></tr>  
</table>


<h3>Details</h3>

<p><code>type="predVar"</code> accounts for the uncertainty of the linear predictor, by drawing new values of the predictor in a multivariate gaussian distribution with mean and covariance matrix of prediction. In this case, the user has to provide a <code>variances</code> argument, passed to <code>predict</code>, which controls what goes into this covariance matrix. For example, with <code>variances=list(linPred=TRUE,disp=TRUE)</code>), the covariance matrix takes into account the joint uncertainty in the fixed-effect coefficients and of any random effects given the response and the point estimates of dispersion and correlation parameters (<code>"linPred"</code> variance component), and in addition accounts for uncertainty in the dispersion parameters (effect of <code>"disp"</code> variance component as further described in <code><a href="#topic+predict.HLfit">predict.HLfit</a></code>).  The total simulation variance is then the response variance. Uncertainty in correlation parameters (such a parameters of the Matern family) is not taken into account. The <code>"linPred"</code> uncertainty is known exactly in LMMs, and otherwise approximated as a Gaussian distribution with mean vector and covariance matrix given as per the Laplace approximation. 
</p>
<p><code>type="(ranef|response)"</code> can be viewed as a special version of <code>type="predVar"</code> where<br /> 
<code>variances=list(linPred=TRUE,disp=FALSE)</code>) and only the uncertainty in the random effects is taken into account.
</p>
<p>A full discussion of the merits of the different <code>type</code>s is beyond the scope of this documentation, but these different types may not all be useful. <code>type="marginal"</code> is typically used for computation of confidence intervals by parametric bootstrap methods. <code>type="residual"</code> is used by <code><a href="#topic+get_cPredVar">get_cPredVar</a></code> for its evaluation of a bias term. The other <code>type</code>s may be used to simulate the uncertainty in the random effects, conditionally on the data, and may therefore be more akin to the computation of prediction intervals conditionally on an (unknown but inferred) realization of the random effects. But these should presumably not be used in a bootstrap computation of such intervals, as this would represent a double accounting of the uncertainty that the boostrap aims to quantify.
</p>
<p>There are cases where simulation without a <code>newdata</code> argument may give results of different length than simulation with <code>newdata=</code>&lt;original data&gt;, as for <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Value</h3>

<p><code>simulate.HLfit</code> returns a vector (if nsim=1) or a matrix with <code>nsim</code> columns, each containing simulated responses (or simulated random effects, for <code>simulated_ranef()</code>). For multivariate-response simulations, an <code>nobs</code> attribute gives the number of responses for each submodel if no <code>resp_testfn</code> was applied.
</p>
<p><code>simulate4boot</code> returns a list with elements 
</p>

<dl>
<dt>bootreps</dt><dd><p>the result of <code>simulate.HLfit</code> as a matrix with <code>nsim</code> columns;</p>
</dd>
<dt>RNGstate</dt><dd><p>the state of <code>.Random.seed</code> at the beginning of the sample simulation.</p>
</dd>  
</dl>

<p>The <code>simulate.HLfitlist</code> method returns a list of simulated responses.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Loaloa")
HLC &lt;- HLCor(cbind(npos,ntot-npos)~Matern(1|longitude+latitude),
           data=Loaloa,family=binomial(),
           ranPars=list(lambda=1,nu=0.5,rho=1/0.7)) 
simulate(HLC,nsim=2)

## Structured dispersion model 
data("wafers")
hl &lt;- HLfit(y ~X1+X2+X1*X3+X2*X3+I(X2^2)+(1|batch),family=Gamma(log),
            resid.model = ~ X3+I(X3^2) ,data=wafers)
simulate(hl,type="marginal",phi_type="simulate",nsim=2)
simulate_ranef(hl,nsim=2)
</code></pre>

<hr>
<h2 id='spaMM'>Inference in mixed models, in particular spatial GLMMs</h2><span id='topic+spaMM'></span><span id='topic+spaMM-package'></span>

<h3>Description</h3>

<p>Fits a range of mixed-effect models, including those with spatially correlated random effects. The random effects are either Gaussian (which defines GLMMs), or other distributions (which defines the wider class of hierarchical GLMs), or simply absent (which makes a LM or GLM).  Multivariate-response models can be fitted by the <code><a href="#topic+fitmv">fitmv</a></code> function. Other models can be fitted by <code><a href="#topic+fitme">fitme</a></code>. Also available are previously conceived fitting functions <code><a href="#topic+HLfit">HLfit</a></code> (sometimes faster, for non-spatial models), <code><a href="#topic+HLCor">HLCor</a></code> (sometimes faster, for conditional-autoregressive models and fixed-correlation models), and <code><a href="#topic+corrHLfit">corrHLfit</a></code> (now of lesser interest). A variety of post-fit procedures are available for prediction, simulation and testing (see, e.g., <code><a href="#topic+fixedLRT">fixedLRT</a></code>, <code><a href="#topic+simulate">simulate</a></code> and <code><a href="#topic+predict">predict</a></code>).
</p>
<p>Both maximum likelihood (ML) and restricted likelihood (REML) can be used for linear mixed models, and extensions of these methods using Laplace approximations are used for non-Gaussian random response. Several variants of these methods discussed in the literature are included (see Details in <code><a href="#topic+HLfit">HLfit</a></code>), the most notable of which may be &ldquo;PQL/L&rdquo; for binary-response GLMMs (see Example for <code><a href="#topic+arabidopsis">arabidopsis</a></code> data). PQL methods implemented in spaMM are closer to (RE)ML methods than those implemented in <code>MASS::glmmPQL</code>. 
</p>


<h3>Details</h3>

<p>The standard response families <code>gaussian</code>, <code>binomial</code>, <code>poisson</code>, and <code>Gamma</code> are handled, as well as negative binomial (see <code><a href="#topic+negbin1">negbin1</a></code> and <code><a href="#topic+negbin2">negbin2</a></code>), beta (<code><a href="#topic+beta_resp">beta_resp</a></code>), beta-binomial (<code><a href="#topic+betabin">betabin</a></code>), zero-truncated poisson and negative binomial and Conway-Maxwell-Poisson response (see <code><a href="#topic+Tpoisson">Tpoisson</a></code>, <code><a href="#topic+Tnegbin">Tnegbin</a></code> and <code><a href="#topic+COMPoisson">COMPoisson</a></code>). A <code>multi</code> family look-alike is also available for <code><a href="#topic+multinomial">multinomial</a></code> response, with some constraints. 
</p>
<p>The variance parameter of residual error is denoted <code class="reqn">\phi</code> (<code>phi</code>): this is the residual variance for gaussian response, but for Gamma-distributed response, the residual variance is <code class="reqn">\phi</code><code class="reqn">\mu^2</code> where <code class="reqn">\mu</code> is expected response. A (possibly mixed-effects) linear predictor for <code class="reqn">\phi</code>, modeling heteroscedasticity, can be considered (see Examples). 
</p>
<p>The package fits models including several nested or crossed random effects, including autocorrelated ones. An interface is being developed allowing users to implement their own parametric correlation models (see <code><a href="#topic+corrFamily">corrFamily</a></code>), beyond the following ones which are built in <span class="pkg">spaMM</span>:<br /> 
<code style="white-space: pre;">&#8288; &#8288;</code> * geostatistical (<code><a href="#topic+Matern">Matern</a></code>, <code><a href="#topic+Cauchy">Cauchy</a></code>),<br /> 
<code style="white-space: pre;">&#8288; &#8288;</code> * interpolated Markov Random Fields (<code><a href="#topic+IMRF">IMRF</a></code>, <code><a href="#topic+MaternIMRFa">MaternIMRFa</a></code>),<br /> 
<code style="white-space: pre;">&#8288; &#8288;</code> * autoregressive time-series (<code><a href="#topic+AR1">AR1</a></code>, <code><a href="#topic+ARp">ARp</a></code>, <code><a href="#topic+ARMA">ARMA</a></code>),<br /> 
<code style="white-space: pre;">&#8288; &#8288;</code> * conditional autoregressive as specified by an <code><a href="#topic+adjacency">adjacency</a></code> matrix,<br /> 
<code style="white-space: pre;">&#8288; &#8288;</code> * pairwise interactions with individual-level random effects, such as diallel experiments (<code><a href="#topic+diallel">diallel</a></code>),<br /> 
<code style="white-space: pre;">&#8288; &#8288;</code> * or any fixed correlation matrix (<code><a href="#topic+corrMatrix">corrMatrix</a></code>). 
</p>
<p>GLMMs and HGLMs are fit via Laplace approximations for (1) the marginal likelihood with respect to random effects and (2) the restricted likelihood (as in REML), i.e. the likelihood of random effect parameters given the fixed effect estimates. All handled models can be formulated in terms of a linear predictor of the traditional form <code>offset</code>+ <b>X</b><code class="reqn">\beta</code> + <b>Z b</b>, where <b>X</b> is the design matrix of fixed effects, <code class="reqn">\beta</code> (<code>beta</code>) is a vector of fixed-effect coefficients, <b>Z</b> is a &ldquo;design matrix&rdquo; for the random effects (which is instead denoted <b>M</b>=<b>ZAL</b> elsewhere in the package documentation), and <b>b</b> a vector of random effect values. The general structure of <b>Mb</b> is described in <code><a href="#topic+random-effects">random-effects</a></code>.
</p>
<p>Gaussian and non-gaussian random effects can be fitted. Different <strong>gaussian</strong> random-effect terms are handled, with the following effects:<br /> 
</p>
<pre>
* (1|&lt;RHS&gt;), for non-autocorrelated random effects as in lme4;
* (&lt;LHS&gt;|&lt;RHS&gt;), for random-coefficient terms as in lme4, *and 
   additional terms depending on the &lt;LHS&gt; type* (further detailed below);
* (&lt;LHS&gt; || &lt;RHS&gt;) is interpreted as in lme4: any such term is immediately 
   converted to ( (1|&lt;RHS&gt;) + (0+&lt;LHS&gt;|&lt;RHS&gt;) ). It should be counted as two 
   random effects for all purposes (e.g., for fixing the variances of the 
   random effects). However, this syntax is useless when the LHS includes a 
   factor (see help('lme4::expandDoubleVerts')).
* &lt;prefix&gt;(1|&lt;RHS&gt;), to specify autocorrelated random effects, 
   e.g. Matern(1|long+lat). 
* &lt;prefix&gt;(&lt;LHS&gt;|&lt;RHS&gt;), where the &lt;LHS&gt; can be used to alter the 
   autocorrelated random effect as detailed below. 
</pre>   
<p>Different LHS types of <strong>gaussian</strong> <code>(&lt;LHS&gt;|&lt;RHS&gt;)</code> random-effect terms are handled, with the following effects:
</p>
<pre>
* &lt;logical&gt; (TRUE/FALSE): affects only responses for which &lt;LHS&gt; is TRUE. 
* &lt;factor built from a logical&gt;: same a &lt;logical&gt; case;
* &lt;factor not built from a logical&gt;: random-coefficient term as in lme4;
* 0 + &lt;factor not built from a logical&gt;: same but contrasts are not used;
* factors specified by the mv(...) expression, generate random-coefficient 
  terms specific to multivariate-response models fitted by fitmv() (see 
  help("mv")). 0 + mv(...) has the expected effect of not using contrasts; 
* &lt;numeric&gt; (but not '0+&lt;numeric&gt;'): random-coefficient term as in lme4, 
  with 2*2 covariance matrix of effects on Intercept and slope;
* 0 + &lt;numeric&gt;: no Intercept so no covariance matrix (random-slope-only 
   term);
</pre>
<p>The '0 + &lt;numeric&gt;' effect is achieved by direct control of the elements of the incidence matrix <b>Z</b> through the <code>&lt;LHS&gt;</code> term: for numeric <code>z</code>, such elements are multiplied by <code>z</code> values, and thus provide a variance of order O(<code>z</code> <b>squared</b>).
</p>
<p>If one wishes to fit uncorrelated group-specific random-effects with distinct variances for different groups or for different response variables, three syntaxes are thus possible. The most general, suitable for fitting several variances (see <code><a href="#topic+GxE">GxE</a></code> for an example), is to fit a (0 + &lt;factor&gt;| &lt;RHS&gt;) random-coefficient term with correlation(s) fixed to 0. Alternatively, one can define <b>numeric</b> (0|1) variables for each group (as <code>as.numeric(&lt;boolean for given group membership&gt;)</code>), and use each of them in a <code style="white-space: pre;">&#8288;0 + &lt;numeric&gt;&#8288;</code> LHS (so that the variance of each such random effect is zero for response not belonging to the given group). See <code><a href="#topic+lev2bool">lev2bool</a></code> for various ways of specifying such indicator variables for several levels.
</p>
<p><strong>Gaussian</strong> <code>&lt;prefix&gt;(&lt;LHS not 1&gt;|&lt;RHS&gt;)</code> random-effect terms may be handled, with two main cases depending on the LHS type, motivated by the following example: independent Matérn effects can be fitted for males and females by using the syntax <code>Matern(male|.) + Matern(female|.)</code>, where <code>male</code> and <code>female</code> are TRUE/FALSE (or a factor with TRUE/FALSE levels). In contrast to a <code>(male|.)</code> term, no random-coefficient correlation matrix is fitted. However, for some other types of RHS, one can fit <em>composite random effects</em> combining a random-coefficient correlation matrix and the correlation model defined by the &ldquo;prefix&rdquo;. This combination is defined in <code><a href="#topic+composite-ranef">composite-ranef</a></code>. This leads to the following distinction:<br /> 
<code style="white-space: pre;">&#8288;   &#8288;</code> * The terms are *not* composite random effects when the non-&lsquo;<code>1</code>&rsquo; LHS type is boolean or factor-from-boolean, a just illustrated, but also <code>0+&lt;numeric&gt;</code>: for example, <code>Matern(0+&lt;numeric&gt;|.)</code> represents an autocorrelated random-slope (only) term or, equivalently, a direct specification of heteroscedasticity of the Matérn random effect.<br />


<code style="white-space: pre;">&#8288;   &#8288;</code> * By contrast, <code>Matern(&lt;numeric&gt;|.)</code> implies estimating a random-coefficient covariance matrix and thus defines a composite random effects, as does an LHS that is a factor constructed from numeric or character levels.<br /> 
Composite random effects can be fitted in principle for all &ldquo;prefixes&rdquo;, including for <code>&lt;<a href="#topic+corrFamily">corrFamily</a>&gt;</code> terms. In practice, this functionality has been checked for <code>Matern</code>, <code>corrMatrix</code>, <code>AR1</code> and the <code>ARp</code>-corrFamily term. In these terms, the <code>&lt;.&gt; %in% &lt;.&gt;</code> form of nested random effect is allowed. 




</p>
<p>The syntax <code>(z-1|.)</code>, for <b>numeric</b> <code>z</code> only, can also be used to fit <strong>some heteroscedastic non-Gaussian</strong> random effects. For example, a Gamma random-effect term <code>(wei-1|block)</code> specifies an heteroscedastic Gamma random effect <code class="reqn">u</code> with constant mean 1 and variance <code>wei^2</code> <code class="reqn">\lambda</code>, where <code class="reqn">\lambda</code> is still the estimated variance parameter. See Details of <code><a href="#topic+negbin">negbin</a></code> for a possible application. Here, this effect is not implemented through direct control of <b>Z</b> (multiplying the elements of an incidence matrix <b>Z</b> by <code>wei</code>), as this would have a different effect on the distribution of the random effect term. <code>(z|.)</code> is not defined for <em>non-Gaussian</em> random effects. It could mean that a correlation structure between random intercepts and random slopes for (say) Gamma-distributed random effects is considered, but such correlation structures are not well-specified by their correlation matrix. 
</p>


<h3>Author(s)</h3>

<p><code>spaMM</code> was initially published by François Rousset and Jean-Baptiste Ferdy, and is continually developed by F. Rousset and tested by Alexandre Courtiol.  
</p>


<h3>References</h3>

<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006). Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>
<p>Rousset F., Ferdy, J.-B. (2014) Testing environmental and genetic effects in the presence of spatial autocorrelation. Ecography, 37: 781-790.
<a href="https://doi.org/10.1111/ecog.00566">doi:10.1111/ecog.00566</a>
</p>


<h3>See Also</h3>

<p>See the <code>test</code> directory of the package for many additional examples of <span class="pkg">spaMM</span> usage beyond those from the formal documentation. 
</p>
<p>See <code><a href="#topic+fitme">fitme</a></code> for multivariate-response models. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
data("scotlip") ## loads 'scotlip' data frame, but also 'Nmatrix'

##     Linear model
fitme(y ~ X1, data=wafers)

##     GLM
fitme(y ~ X1, family=Gamma(log), data=wafers)
fitme(cases ~ I(log(population)), data=scotlip, family=poisson)

##     Non-spatial GLMMs
fitme(y ~ 1+(1|batch), family=Gamma(log), data=wafers)
fitme(cases ~ 1+(1|gridcode), data=scotlip, family=poisson)
#
# Random-slope model (mind the output!)        
fitme(y~X1+(X2|batch),data=wafers, method="REML")

## Spatial, conditional-autoregressive GLMM
if (spaMM.getOption("example_maxtime")&gt;2) {   
  fitme(cases ~ I(log(population))+adjacency(1|gridcode), data=scotlip, family=poisson, 
        adjMatrix=Nmatrix) # with adjacency matrix provided by data("scotlip")
} 
# see ?adjacency for more details on these models 

## Spatial, geostatistical GLMM: 
# see e.g. examples in ?fitme, ?corrHLfit, ?Loaloa, or ?arabidopsis;
# see examples in ?Matern for group-specific spatial effects.

##     Hierachical GLMs with non-gaussian random effects
 data("salamander")
if (spaMM.getOption("example_maxtime")&gt;1) {   
 # both gaussian and non-gaussian random effects
 fitme(cbind(Mate,1-Mate)~1+(1|Female)+(1|Male),family=binomial(),
        rand.family=list(gaussian(),Beta(logit)),data=salamander)
 
 # Random effect of Male nested in that of Female:
 fitme(cbind(Mate,1-Mate)~1+(1|Female/Male),
       family=binomial(),rand.family=Beta(logit),data=salamander)
 # [ also allowed is cbind(Mate,1-Mate)~1+(1|Female)+(1|Male %in% Female) ]
}

##    Modelling residual variance ( = structured-dispersion models)    
# GLM response, fixed effects for residual variance 
fitme( y ~ 1,family=Gamma(log),
      resid.model = ~ X3+I(X3^2) ,data=wafers)
#
# GLMM response, and mixed effects for residual variance
if (spaMM.getOption("example_maxtime")&gt;1.5) {   
  fitme(y ~ 1+(1|batch),family=Gamma(log),
        resid.model = ~ 1+(1|batch) ,data=wafers)
}

</code></pre>

<hr>
<h2 id='spaMM_boot'>
Parametric bootstrap
</h2><span id='topic+spaMM_boot'></span><span id='topic+spaMM2boot'></span>

<h3>Description</h3>

<p><code>spaMM_boot</code> simulates samples from a fit object inheriting from class <code>"HLfit"</code>, as produced by spaMM's fitting functions, and applies a given function to each simulated sample. Parallelization is supported (see Details). 
</p>
<p><code>spaMM2boot</code> is similar except that it assumes that the original model is refitted on the simulated data, and the given function is applied to the refitted model, and the value is in a format directly usable as input for <code>boot::boot.ci</code>. 
</p>
<p>Both of these functions can be used to apply standard parametric bootstrap procedures. <code>spaMM_boot</code> is suitable for more diverse applications, e.g. to fit by one model some samples simulated under another model (see Example).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaMM_boot(object, simuland, nsim, nb_cores=NULL, seed=NULL,
           resp_testfn=NULL, control.foreach=list(),
           debug. = FALSE, type, fit_env=NULL, cluster_args=NULL,
           showpbar= eval(spaMM.getOption("barstyle")),
           boot_samples=NULL,
           ...)
spaMM2boot(object, statFUN, nsim, nb_cores=NULL, seed=NULL,
           resp_testfn=NULL, control.foreach=list(),
           debug. = FALSE, type="marginal", fit_env=NULL, 
           cluster_args=NULL, showpbar= eval(spaMM.getOption("barstyle")),
           boot_samples=NULL,
           ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spaMM_boot_+3A_object">object</code></td>
<td>

<p>The fit object to simulate from.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_simuland">simuland</code></td>
<td>

<p>The function to apply to each simulated sample. See Details for requirements of this function.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_statfun">statFUN</code></td>
<td>

<p>The function to apply to each fit object for each simulated sample. See Details for requirements of this function.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_nsim">nsim</code></td>
<td>

<p>Number of samples to simulate and analyze.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_nb_cores">nb_cores</code></td>
<td>

<p>Number of cores to use for parallel computation. The default is <code>spaMM.getOption("nb_cores")</code>, and 1 if the latter is NULL. <code>nb_cores=1</code> prevents the use of parallelisation procedures.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_seed">seed</code></td>
<td>
<p>Passed to <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code></p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_resp_testfn">resp_testfn</code></td>
<td>
<p>Passed to <code>simulate.HLfit</code>; NULL, or a function that tests a condition which simulated samples should satisfy. This function takes a response vector as argument and return a boolean (TRUE indicating that the sample satisfies the condition).     
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_control.foreach">control.foreach</code></td>
<td>
<p>list of control arguments for <code>foreach</code>. These include in particular <code>.combine</code> (with default value <code>"rbind"</code>), and <code>.errorhandling</code> (with default value <code>"remove"</code>, but <code>"pass"</code> is quite useful for debugging).</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_debug.">debug.</code></td>
<td>

<p>Boolean (or integer, interpreted as boolean). For debugging purposes, given that <code>spaMM_boot</code> does not stop when the fit of a bootstrap replicate fails. Subject to changes with no or little notice. In serial computation, <code>debug.=2</code> will stop on an error. In parallel computation, this would be ignored. The effect of <code>debug.=TRUE</code> depends on what <code>simuland</code> does of it. The default <code>simuland</code> for likelihood ratio testing functions, <code><a href="#topic+eval_replicate">eval_replicate</a></code>, shows how <code>debug.</code> can be used to control a call to <code>dump.frames</code> (however, debugging user-defined functions by such a call does not require control by <code>debug.</code>).  
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_type">type</code></td>
<td>

<p>Character: passed to <code>simulate.HLfit</code>. Defaults, with a warning, to <code>type="marginal"</code> in order to replicate the behaviour of previous versions of <code>spaMM_boot</code>. This is an appropriate default for various parametric bootstrpa analyses, but not necessarily the appropriate <code>type</code> for all possible uses. See Details of <code><a href="#topic+simulate.HLfit">simulate.HLfit</a></code> for other implemented options.
</p>
</td></tr>  
<tr><td><code id="spaMM_boot_+3A_fit_env">fit_env</code></td>
<td>

<p>An environment or list containing variables necessary to evaluate <code>simuland</code> on each sample, and not included in the fit <code>object</code>. E.g., use <code>fit_env=list(phi_fix=phi_fix)</code> if the fit assumed <code>fixed=list(phi=phi_fix)</code>: the name in <code>list(phi_fix=&lt;.&gt;)</code> must be the name of the object that will be sought by the called process when interpreting <code>fixed=list(phi=phi_fix)</code> (if still unsure about the proper syntax, see the <code><a href="parallel.html#topic+clusterExport">clusterExport</a></code> documentation, as <code>fit_env</code> is used in the following context: <code>parallel::clusterExport(cl=&lt;cluster&gt;, varlist=ls(fit_env), envir=fit_env))</code>.   
</p>
</td></tr> 
<tr><td><code id="spaMM_boot_+3A_cluster_args">cluster_args</code></td>
<td>

<p><code>NULL</code> or a <code>list</code> of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. 
</p>
</td></tr>  
<tr><td><code id="spaMM_boot_+3A_showpbar">showpbar</code></td>
<td>

<p>Controls display of progress bar. See <code><a href="#topic+barstyle">barstyle</a></code> option for details.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_boot_samples">boot_samples</code></td>
<td>

<p>NULL, or precomputed bootstrap samples from the fitted model, provided as a matrix with one column per bootstrap replicate (the format of the result of <code>simulate.HLfit</code>), or as a list including a <code>bootreps</code> element with the same matrix format.
</p>
</td></tr>
<tr><td><code id="spaMM_boot_+3A_...">...</code></td>
<td>

<p>Further arguments passed to the <code>simuland</code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>simuland</code> function must take as first argument a vector of response values, and may have other arguments including &lsquo;...&rsquo;. When required, these additional arguments must be passed through the &lsquo;...&rsquo; arguments of <code>spaMM_boot</code>. Variables needed to evaluate them must be available from within the <code>simuland</code> function or otherwise provided as elements of <code>fit_env</code>.
</p>
<p>The <code>statFUN</code> function must take as first argument a fit object, and may have other arguments including &lsquo;...&rsquo; handled as for <code>simuland</code>.
</p>
<p><code>spaMM_boot</code> handles parallel backends with different features. <code>pbapply::pbapply</code> has a very simple interface (essentially equivalent to <code>apply</code>) and provides progress bars, but (in version 1.4.0, at least) does not have efficient load-balancing. <code>doSNOW</code> also provides a progress bar and allows more efficient load-balancing, but its requires <code>foreach</code>. <code>foreach</code> handles errors differently from <code>pbapply</code> (which will simply stop if fitting a model to a bootstrap replicate fails): see the <code>foreach</code> documentation.
</p>
<p><code>spaMM_boot</code> calls <code>simulate.HLfit</code> on the fit <code>object</code> and applies <code>simuland</code> on each column of the matrix returned by this call. 
<code>simulate.HLfit</code> uses the <code>type</code> argument, which must be explicitly provided.
</p>


<h3>Value</h3>

<p><code>spaMM_boot</code> returns a list, with the following element(s) (unless <code>debug.</code> is <code>TRUE</code>): 
</p>

<dl>
<dt>bootreps</dt><dd><p><code>nsim</code> return values in the format returned either by <code>apply</code> or <code>parallel::parApply</code> or by <code>foreach::`%dopar%`</code> as controlled by <code>control.foreach$.combine</code> (which is here <code>"rbind"</code> by default).</p>
</dd>
<dt>RNGstate</dt><dd><p>(absent in the case the <code>boot_samples</code> argument was used to provide the new response values but not the <code>RNGstate</code>) the state of <code>.Random.seed</code> at the beginning of the sample simulation</p>
</dd></dl>
<p>.  

</p>
<p><code>spaMM2boot</code> returns a list suitable for use by <code>boot.ci</code>, with elements:  
</p>

<dl>
<dt>t</dt><dd><p><code>nsim</code> return values of the simulated statistic (in matrix format).</p>
</dd>
<dt>t0</dt><dd><p><code>nsim</code> return the value of <code>statFUN</code> from the original fit.</p>
</dd>
<dt>sim</dt><dd><p>The simulation type (<code>"parametric"</code>).</p>
</dd>
<dt>R</dt><dd><p><code>nsim</code></p>
</dd>
<dt>.Random.seed</dt><dd><p>the state of <code>.Random.seed</code> at the beginning of the sample simulation</p>
</dd></dl>
<p>.  

(other elements of an object of class <code><a href="boot.html#topic+boot">boot</a></code> are currently not included.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (spaMM.getOption("example_maxtime")&gt;7) {
 data("blackcap")
 
 # Generate fits of null and full models:
 lrt &lt;- fixedLRT(null.formula=migStatus ~ 1 + Matern(1|longitude+latitude),
                 formula=migStatus ~ means + Matern(1|longitude+latitude), 
                 method='ML',data=blackcap)

 # The 'simuland' argument: 
 myfun &lt;- function(y, what=NULL, lrt, ...) { 
    data &lt;- lrt$fullfit$data
    data$migStatus &lt;- y ## replaces original response (! more complicated for binomial fits)
    full_call &lt;- getCall(lrt$fullfit) ## call for full fit
    full_call$data &lt;- data
    res &lt;- eval(full_call) ## fits the full model on the simulated response
    if (!is.null(what)) res &lt;- eval(what)(res=res) ## post-process the fit
    return(res) ## the fit, or anything produced by evaluating 'what'
  }
  # where the 'what' argument (not required) of myfun() allows one to control 
  # what the function returns without redefining the function.
  
  # Call myfun() with no 'what' argument: returns a list of fits 
  spaMM_boot(lrt$nullfit, simuland = myfun, nsim=1, lrt=lrt, 
             type ="marginal")[["bootreps"]] 
  
  # Return only a model coefficient for each fit: 
  spaMM_boot(lrt$nullfit, simuland = myfun, nsim=7,
             what=quote(function(res) fixef(res)[2L]), 
             lrt=lrt, type ="marginal")[["bootreps"]]       
  
  ## Not run: 
    # Parametric bootstrap by spaMM2boot() and spaMM_boot():
    boot.ci_info &lt;- spaMM2boot(lrt$nullfit, statFUN = function(refit) fixef(refit)[1], 
                               nsim=99, type ="marginal")
    boot::boot.ci(boot.ci_info, , type=c("basic","perc","norm"))
    
    nullfit &lt;- lrt$nullfit
    boot_t &lt;- spaMM_boot(lrt$nullfit, simuland = function(y, nullfit) {
      refit &lt;- update_resp(nullfit, y)
      fixef(refit)[1]
    }, nsim=99, type ="marginal", nullfit=nullfit)$bootreps
    boot::boot.ci(list(R = length(boot_t), sim="parametric"), t0=fixef(nullfit)[1], 
                  t= t(boot_t), type=c("basic","perc","norm"))


  
## End(Not run)           
}
</code></pre>

<hr>
<h2 id='spaMM_glm.fit'>Fitting generalized linear models without initial-value or divergence headaches</h2><span id='topic+spaMM_glm.fit'></span><span id='topic+spaMM_glm'></span>

<h3>Description</h3>

<p><code>spaMM_glm.fit</code> is a stand-in replacement for <code>glm.fit</code>, which can be called through <code>glm</code> by using
<code>glm(&lt;&gt;, method="spaMM_glm.fit")</code>. Input and output structure are exactly as for <code>glm.fit</code>. It uses a Levenberg-Marquardt algorithm to prevent divergence of estimates. For models families such as <code>Gamma()</code> (with default inverse link) where the linear predictor is constrained to be positive, if the <span class="pkg">rcdd</span> package is installed, the function can automatically find valid starting values or else indicate that no parameter value is feasible. It also automatically provides good starting values in some cases where the base functions request them from the user (notably, for <code>gaussian(log)</code> with some negative response). 
<code>spaMM_glm</code> is a convenient wrapper, calling <code>glm</code> with default method <code>glm.fit</code>, then calling method <code>spaMM_glm.fit</code>, with possibly different initial values, if <code>glm.fit</code> failed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaMM_glm.fit(x, y, weights = rep(1, nobs), start = NULL, etastart = NULL, 
              mustart = NULL, offset = rep(0, nobs), family = gaussian(), 
              control = list(maxit=200), intercept = TRUE, singular.ok = TRUE)
spaMM_glm(formula, family = gaussian, data, weights, subset,
          na.action, start = NULL, etastart, mustart, offset,
          control = list(...), model = TRUE, method = c("glm.fit","spaMM_glm.fit"),
          x = FALSE, y = TRUE, singular.ok = TRUE, contrasts = NULL, strict=FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<p>All arguments except <code>strict</code> are common to these functions and their <code>stats</code> package equivalents, <code>glm</code> and <code>glm.fit</code>. Most arguments operate as for the latter functions, whose documentation is repeated  below. The <code>control</code> argument may operate differently. 
</p>
<table>
<tr><td><code id="spaMM_glm.fit_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>"<a href="#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted.  The details of model specification are given
in the &lsquo;Details&rsquo; section of <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link
function to be used in the model.  For <code>spaMM_glm</code> this can be a
character string naming a family function, a family function or the
result of a call to a family function.  For <code>spaMM_glm.fit</code> only the
third option is supported.  (See <code><a href="#topic+family">family</a></code> for details of
family functions.)</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>glm</code> is called.</p>
</td></tr>  
<tr><td><code id="spaMM_glm.fit_+3A_weights">weights</code></td>
<td>
<p>an optional vector of &lsquo;prior weights&rsquo; to be used
in the fitting process.  Should be <code>NULL</code> or a numeric vector.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and is
<code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.  The &lsquo;factory-fresh&rsquo;
default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.  Another possible value is
<code>NULL</code>, no action.  Value <code><a href="stats.html#topic+na.exclude">na.exclude</a></code> can be useful.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_start">start</code></td>
<td>
<p>starting values for the parameters in the linear predictor.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_etastart">etastart</code></td>
<td>
<p>starting values for the linear predictor.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_mustart">mustart</code></td>
<td>
<p>starting values for the vector of means.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em> known
component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to
the number of cases.  One or more <code><a href="stats.html#topic+offset">offset</a></code> terms can be
included in the formula instead or as well, and if more than one is
specified their sum is used.  See <code><a href="stats.html#topic+model.offset">model.offset</a></code>.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting
process.  This is passed to <code><a href="stats.html#topic+glm.control">glm.control</a></code>, as for <code>glm.fit</code>. 
Because one can assume that <code>spaMM_glm.fit</code> will converge in many cases where <code>glm.fit</code> does not, <code>spaMM_glm.fit</code> allows more iterations (200) by default. However, if <code>spaMM_glm.fit</code> is called through <code>glm(. . ., method="spaMM_glm.fit")</code>, then the number of iterations is controlled by the <code>glm.control</code> call within <code>glm</code>, so that it is 25 by default, overriding the <code>spaMM_glm.fit</code> default. </p>
</td></tr> 
<tr><td><code id="spaMM_glm.fit_+3A_model">model</code></td>
<td>
<p>a logical value indicating whether <em>model frame</em>
should be included as a component of the returned value.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_method">method</code></td>
<td>
<p>A 2-elements vector specifying first the method to be used by <code>spaMM_glm</code> in the first attempt to fit the model, second the method to be used in a second attempt if the first failed. Possible methods include those shown in the default, <code>"model.frame"</code>, which returns the model frame and does no fitting, or user-supplied fitting functions. These functions can be supplied either as a function or a character string naming a function, with a function which takes the same arguments as <code>glm.fit</code>.  
</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_x">x</code>, <code id="spaMM_glm.fit_+3A_y">y</code></td>
<td>
<p>For <code>spaMM_glm</code>: <code>x</code> is a design matrix of dimension
<code>n * p</code>, and <code>y</code> is a vector of observations of length
<code>n</code>.
</p>
<p>For <code>spaMM_glm.fit</code>: <code>x</code> is a design matrix of dimension
<code>n * p</code>, and <code>y</code> is a vector of observations of length
<code>n</code>.
</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_singular.ok">singular.ok</code></td>
<td>
<p>logical; if <code>FALSE</code> a singular fit is an error.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code>
of <code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_intercept">intercept</code></td>
<td>
<p>logical. Should an intercept be included in the
<em>null</em> model?</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_strict">strict</code></td>
<td>
<p>logical. Whether to perform a fit by <code>spaMM_glm.fit</code> if <code>glm.fit</code> returned the warning <code>"glm.fit: algorithm did not converge"</code>.</p>
</td></tr>
<tr><td><code id="spaMM_glm.fit_+3A_...">...</code></td>
<td>

<p>arguments to be used to form the default
<code>control</code> argument if it is not supplied directly.
</p>
</td></tr>  
</table>


<h3>Value</h3>

<p>An object inheriting from class <code>glm</code>. See <code><a href="stats.html#topic+glm">glm</a></code> for details.</p>


<h3>Note</h3>

<p>The source and documentation is derived in large part from those of <code>glm.fit</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(8.752,20.27,24.71,32.88,27.27,19.09)
y &lt;- c(5254,35.92,84.14,641.8,1.21,47.2)

# glm(.) fails:
(check_error &lt;- try(glm(y~ x,data=data.frame(x,y),family=Gamma(log)), silent=TRUE))
if ( ! inherits(check_error,"try-error")) stop("glm(.) call unexpectedly succeeded")

spaMM_glm(y~ x,data=data.frame(x,y),family=Gamma(log))

## Gamma(inverse) examples
x &lt;- c(43.6,46.5,21.7,18.6,17.3,16.7)
y &lt;- c(2420,708,39.6,16.7,46.7,10.8)

# glm(.) fails (can't find starting value)
(check_error &lt;- suppressWarnings(try(glm(y~ x,data=data.frame(x,y),family=Gamma()) , silent=TRUE)))
if ( ! inherits(check_error,"try-error")) stop("glm(.) call unexpectedly succeeded.")

if (requireNamespace("rcdd",quietly=TRUE)) {
  spaMM_glm(y~ x,data=data.frame(x,y),family=Gamma())
}

## A simple exponential regression with some negative response values

set.seed(123)
x &lt;- seq(50)
y &lt;- exp( -0.1 * x) + rnorm(50, sd = 0.1)
glm(y~ x,data=data.frame(x,y),family=gaussian(log), method="spaMM_glm.fit")

# =&gt; without the 'method' argument, stats::gaussian(log)$initialize() is called 
# and stops on negative response values. 



</code></pre>

<hr>
<h2 id='spaMM-conventions'>spaMM conventions and differences from related fitting procedures</h2><span id='topic+spaMM-conventions'></span>

<h3>Description</h3>

<p><b>input arguments</b> are generally similar to those of <code>glm</code> and <code>(g)lmer</code>, in particular for the <code>spaMM::fitme</code>
function, with the exception of the <code>prior.weights</code> argument, which is simply <code>weights</code> in the other packages.
The name <code>prior.weights</code> seems more consistent, since e.g. <code>glm</code> returns its input <code>weights</code> as output <code>prior.weights</code>, while its output <code>weights</code> are instead the weights in the final iteration of an iteratively weighted least-square fit.
</p>
<p>The <b>default likelihood target</b> for dispersion parameters is restricted likelihood (REML estimation) for <code>corrHLfit</code> and (marginal) likelihood (ML estimation) for <code>fitme</code>. 
Model fits may provide restricted likelihood values(<code>ReL</code>) even if restricted likelihood is is not used as an objective function at any step in the analysis.   
</p>
<p>See <code><a href="#topic+good-practice">good-practice</a></code> for advice about the proper syntax of <code>formula</code>.
</p>
<p><b>Computation times</b> depend on control parameters given by  <code>spaMM.getOption("spaMM_tol")</code> parameters (for iterative algorithms), and <code>spaMM.getOption("nloptr")</code> parameters for the default optimizer. Do not use <code>spaMM.options()</code> to control them globally, unless you know what you are doing. Rather control them locally by the <code>control.HLfit</code> argument to control <code>spaMM_tol</code>, and by the control arguments of <code>corrHLfit</code> and <code>fitme</code> to control <code>nloptr</code>. If <code>nloptr$Xtol_rel</code> is set above 5e-06, <code>fitme</code> will by default refit the fixed effects and dispersion parameters (but not other correlation parameters estimated by <code>nloptr</code>) by the iterative algorithm after <code>nloptr</code> convergence. Increasing <code>nloptr$Xtol_rel</code> value may therefore switches the bulk of computation time from the optimizer to the iterative algorithm, and may increase or decrease computation time depending on which algorithm is faster for a given input. Use <code>control$refit</code> if you wish to inhibit this, but note that by default it provides a rescue to a poor <code>nloptr</code> result due to a too large <code>Xtol_rel</code>.       
</p>


<h3>References</h3>

<p>Chambers J.M. (2008) Software for data analysis: Programming with R. Springer-Verlag New York
</p>

<hr>
<h2 id='spaMM-internal'>Internal spaMM Functions</h2><span id='topic+gridIMRF'></span><span id='topic+projpath'></span><span id='topic+glm.nodev.fit'></span><span id='topic+fitme_body'></span><span id='topic+fitmv_body'></span><span id='topic+HLfit.obj'></span><span id='topic+.HLfit_body_augZXy'></span><span id='topic+.solve_IRLS_as_ZX'></span><span id='topic+.solve_IRLS_as_spprec'></span><span id='topic+.is_spprec'></span><span id='topic+.NB_shapeFn'></span><span id='topic+.NB_shapeInv'></span><span id='topic+.ZWZt'></span><span id='topic+.calc_CARdispGammaGLM'></span><span id='topic+.calc_dispGammaGLM'></span><span id='topic+.crossprod'></span><span id='topic+.dispFn'></span><span id='topic+.dispInv'></span><span id='topic+.evalWrapper'></span><span id='topic+.is_spprec_fit'></span><span id='topic+.modify_list'></span><span id='topic+.nuFn'></span><span id='topic+.nuInv'></span><span id='topic+.rhoFn'></span><span id='topic+.rhoInv'></span><span id='topic+.safe_opt'></span><span id='topic+.setCluster'></span><span id='topic+.stripOffset'></span><span id='topic+.stripRanefs'></span><span id='topic+.tcrossprod'></span><span id='topic+.unloads4spaMM'></span><span id='topic+.wrap_Ltri_t_chol'></span><span id='topic+dimnames.bigq'></span><span id='topic+Initialize'></span><span id='topic+Variogram'></span><span id='topic+coef'></span><span id='topic+coef+3C-'></span><span id='topic+corFactor'></span><span id='topic+corMatrix'></span><span id='topic+getCovariate'></span><span id='topic+logDet'></span><span id='topic+recalc'></span><span id='topic+spaMM_Gamma'></span><span id='topic+get_HLCorcall'></span><span id='topic+HLCor.obj'></span><span id='topic+corrHLfit_body'></span><span id='topic+corrMM.LRT'></span><span id='topic+getCall.HLfit'></span><span id='topic+model.offset.HLfit'></span><span id='topic+getPar'></span><span id='topic+HLCor_body'></span><span id='topic+HLfit_body'></span><span id='topic+HLfit_body_old'></span><span id='topic+makeTicks'></span><span id='topic+Matern.corr'></span><span id='topic+niceLabels'></span><span id='topic+overcat'></span><span id='topic+crack'></span><span id='topic+recond'></span>

<h3>Description</h3>

<p>Internal spaMM functions
</p>


<h3>Details</h3>

<p>These are not to be called by the user, or are waiting for documentation to be written.
</p>

<hr>
<h2 id='spaMM-S3'>S3 methods of generics defined in other packages</h2><span id='topic+spaMM-S3'></span><span id='topic+dim.precision'></span><span id='topic+print.arglist'></span><span id='topic+print.predictor'></span><span id='topic+print.vcov.HLfit'></span><span id='topic+print.predictions'></span><span id='topic+print.bootci4print'></span>

<h3>Description</h3>

<p>These are not to be called by the user, or are waiting for documentation to be written.
</p>

<hr>
<h2 id='spaMM.colors'>
A flashy color palette.
</h2><span id='topic+spaMM.colors'></span>

<h3>Description</h3>

<p><code>spaMM.colors</code> is the default color palette for some color plots in <code>spaMM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaMM.colors(n = 64, redshift = 1, adjustcolor_args=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spaMM.colors_+3A_n">n</code></td>
<td>
<p>Number of color levels returned by the function. A calling graphic function with argument <code>nlevels</code> will typically 
take the first (i.e., bluest) <code>nlevels</code> color levels. If <code>n</code>&lt;<code>nlevels</code>, the color levels are recycled
</p>
</td></tr>
<tr><td><code id="spaMM.colors_+3A_redshift">redshift</code></td>
<td>
<p>The higher it is, the more the palette blushes....</p>
</td></tr>
<tr><td><code id="spaMM.colors_+3A_adjustcolor_args">adjustcolor_args</code></td>
<td>
<p>Either NULL or a list of arguments for <code><a href="grDevices.html#topic+adjustcolor">adjustcolor</a></code>, in which case <code>adjustcolor</code> is called to modify <code>spaMM.colors</code>'s default vector of colors. See the documentation of the latter function for further information. All arguments except <code>col</code> are possible.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you don't like this color palette, have a look at the various ones provided by the <code>fields</code> package.
</p>


<h3>Value</h3>

<p>A vector giving the colors in a hexadecimal format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see mapMM examples
</code></pre>

<hr>
<h2 id='spaMM.filled.contour'>Level (Contour) Plots with better aspect ratio control (for geographical maps, at least)</h2><span id='topic+spaMM.filled.contour'></span>

<h3>Description</h3>

<p>This function is derived from <code>filled.contour</code> in the <code>graphics</code> package, and 
this documentation is likewise heavily based on that of <code>filled.contour</code>.
</p>
<p>This function likewise produces a contour plot with the areas between the
contours filled in solid color, and a 
key showing how the colors map to z values is likewise shown to the right of
the plot.
The only difference is the way the aspect ratio is determined and can be controlled (using the <code>map.asp</code> parameter instead of <code>asp</code>),
They thus easily provide nice-looking maps with meaningful latitude/longitude ratio (see Examples). However, this does not work well with rstudio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaMM.filled.contour(x = seq(0, 1, length.out = nrow(z)),
               y = seq(0, 1, length.out = ncol(z)),
               z,
               xrange = range(x, finite = TRUE),
               yrange = range(y, finite = TRUE),
               zrange = range(z, finite = TRUE, na.rm=TRUE),
               margin=1/20,
               levels = pretty(zrange, nlevels), nlevels = 20,
               color.palette = spaMM.colors,
               col = color.palette(length(levels) - 1),
               plot.title, plot.axes, key.title=NULL, key.axes=NULL,
               map.asp = NULL, xaxs = "i", yaxs = "i", las = 1,
               axes = TRUE, frame.plot = axes, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spaMM.filled.contour_+3A_x">x</code>, <code id="spaMM.filled.contour_+3A_y">y</code></td>
<td>
<p>locations of grid lines at which the values in <code>z</code> are
measured.  These must be in ascending order.  (The rest of this
description does not apply to <code>.filled.contour</code>.)
By default, equally spaced values from 0 to 1 are used.  If <code>x</code>
is a <code>list</code>, its components <code>x$x</code> and <code>x$y</code> are used
for <code>x</code> and <code>y</code>, respectively.  If the list has component
<code>z</code> this is used for <code>z</code>.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_z">z</code></td>
<td>
<p>a numeric matrix containing the values to be plotted..  Note that
<code>x</code> can be used instead of <code>z</code> for convenience.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_xrange">xrange</code></td>
<td>
<p>x range of the plot.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_yrange">yrange</code></td>
<td>
<p>y range of the plot.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_zrange">zrange</code></td>
<td>
<p>z range of the plot.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_margin">margin</code></td>
<td>

<p>This controls how far (in relative terms) the plot extends beyond the x and y ranges 
of the analyzed points, and is overriden by explicit <code>xrange</code> and <code>yrange</code> arguments.  
</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_levels">levels</code></td>
<td>
<p>a set of levels which are used to partition the range
of <code>z</code>.  Must be <b>strictly</b> increasing (and finite).  Areas
with <code>z</code> values between consecutive levels are painted with the
same color.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_nlevels">nlevels</code></td>
<td>
<p>if <code>levels</code> is not specified, the range of <code>z</code>,
values is divided into approximately this many levels.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_color.palette">color.palette</code></td>
<td>
<p>a color palette function to be used to assign
colors in the plot.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_col">col</code></td>
<td>
<p>an explicit set of colors to be used in the plot.
This argument overrides any palette function specification.  There
should be one less color than levels</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_plot.title">plot.title</code></td>
<td>
<p>statements which add titles to the main plot.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_plot.axes">plot.axes</code></td>
<td>
<p>statements which draw axes (and a <code><a href="graphics.html#topic+box">box</a></code>)
on the main plot.  This overrides the default axes.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_key.title">key.title</code></td>
<td>
<p>statements which add titles for the plot key.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_key.axes">key.axes</code></td>
<td>
<p>statements which draw axes on the plot key.
This overrides the default axis.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_map.asp">map.asp</code></td>
<td>
  
<p>the y/x aspect ratio of the 2D plot area (not of the full figure including the scale). Default is (plotted y range)/(plotted x range) (i.e., scales for x are identical). 
</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_xaxs">xaxs</code></td>
<td>
<p>the x axis style.  The default is to use internal
labeling.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_yaxs">yaxs</code></td>
<td>
<p>the y axis style.  The default is to use internal
labeling.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_las">las</code></td>
<td>
<p>the style of labeling to be used.  The default is to
use horizontal labeling.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_axes">axes</code>, <code id="spaMM.filled.contour_+3A_frame.plot">frame.plot</code></td>
<td>
<p>logicals indicating if axes and a box should be
drawn, as in <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
<tr><td><code id="spaMM.filled.contour_+3A_...">...</code></td>
<td>
<p>additional <a href="graphics.html#topic+graphical+20parameters">graphical parameters</a>, currently only passed to
<code><a href="graphics.html#topic+title">title</a>()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values to be plotted can contain <code>NA</code>s.  Rectangles with two
or more corner values are <code>NA</code> are omitted entirely: where there
is a single <code>NA</code> value the triangle opposite the <code>NA</code> is
omitted.
</p>
<p>Values to be plotted can be infinite: the effect is similar to that
described for <code>NA</code> values.
</p>


<h3>Value</h3>

<p>This returns invisibly a list with elements of the plot, the  <code>x</code>,  <code>y</code>,  <code>z</code> coordinates and the contour <code>levels</code>.
</p>


<h3>Note</h3>

<p>Builds heavily on filled.contour by Ross Ihaka and R-core.
<code>spaMM.filled.contour</code> uses the <code><a href="graphics.html#topic+layout">layout</a></code> function and so is
restricted to a full page display.
</p>
<p>The output produced by <code>spaMM.filled.contour</code> is actually a combination
of two plots; one is the filled contour and one is the legend.  Two
separate coordinate systems are set up for these two plots, but they
are only used internally &ndash; once the function has returned these
coordinate systems are lost.  If you want to annotate the main contour
plot, for example to add points, you can specify graphics commands in
the <code>plot.axes</code> argument.  See the Examples.
</p>


<h3>References</h3>

<p>Cleveland, W. S. (1993)
<em>Visualizing Data</em>.
Summit, New Jersey: Hobart.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+contour">contour</a></code>, <code><a href="Matrix.html#topic+image">image</a></code>,
<code><a href="grDevices.html#topic+palette">palette</a></code>; <code><a href="lattice.html#topic+levelplot">contourplot</a></code>
and <code><a href="lattice.html#topic+levelplot">levelplot</a></code> from package <code>lattice</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>spaMM.filled.contour(volcano, color = spaMM.colors) # simple

## Comparing the layout with that of filled.contour:
#  (except that it does not always achieve the intended effect 
#  in RStudio Plots pane). 

x &lt;- 10*1:nrow(volcano)
y &lt;- 10*1:ncol(volcano)
spaMM.filled.contour(x, y, volcano, color = terrain.colors,
    plot.title = title(main = "The Topography of Maunga Whau",
    xlab = "Meters North", ylab = "Meters West"),
    plot.axes = { axis(1, seq(100, 800, by = 100))
                  axis(2, seq(100, 600, by = 100)) },
    key.title = title(main = "Height\n(meters)"),
    key.axes = axis(4, seq(90, 190, by = 10)))  # maybe also asp = 1
mtext(paste("spaMM.filled.contour(.) from", R.version.string),
      side = 1, line = 4, adj = 1, cex = .66)

## compare with      

filled.contour(x, y, volcano, color = terrain.colors,
    plot.title = title(main = "The Topography of Maunga Whau",
    xlab = "Meters North", ylab = "Meters West"),
    plot.axes = { axis(1, seq(100, 800, by = 100))
                  axis(2, seq(100, 600, by = 100)) },
    key.title = title(main = "Height\n(meters)"),
    key.axes = axis(4, seq(90, 190, by = 10)))  # maybe also asp = 1
mtext(paste("filled.contour(.) from", R.version.string),
      side = 1, line = 4, adj = 1, cex = .66)

</code></pre>

<hr>
<h2 id='stripHLfit'>
Reduce the size of fitted objects 
</h2><span id='topic+stripHLfit'></span>

<h3>Description</h3>

<p>Large matrices and other memory-expensive objects may be stored in a fit object. This function removes them in order to reduce the size of the object, particularly when stored on disk. In principle, the removed objects can be regenerated automatically when needed (e.g., for a predict()). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stripHLfit(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stripHLfit_+3A_object">object</code></td>
<td>

<p>The result of a fit (an object of class <code>HLfit</code>).
</p>
</td></tr>
<tr><td><code id="stripHLfit_+3A_...">...</code></td>
<td>

<p>Further arguments, not currently used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input fit objects with some elements removed.
</p>


<h3>Note</h3>

<p>The effect may change without notice between versions as the efficiency of the operation is highly sensitive to implementation details.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## rather unconvincing example : quantitative effect is small.

# measure size of saved object:
saveSize &lt;- function (object,...) {
    tf &lt;- tempfile(fileext = ".RData")
    on.exit(unlink(tf))
    save(object, file = tf,...)
    file.size(tf)
  }
data("Loaloa")  
lfit &lt;- fitme(cbind(npos,ntot-npos)~elev1+elev2+elev3+elev4+maxNDVI1+seNDVI
                   +Matern(1|longitude+latitude), method="HL(0,1)",
              data=Loaloa, family=binomial(), fixed=list(nu=0.5,rho=1,lambda=0.5))
saveSize(lfit)                 
pfit &lt;- predict(lfit,newdata=Loaloa,variances=list(cov=TRUE)) # increases size!
saveSize(lfit)
lfit &lt;- stripHLfit(lfit)
saveSize(lfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.HLfit'>
Summary and print methods for fit and test results.
</h2><span id='topic+summary'></span><span id='topic+summary.HLfit'></span><span id='topic+summary.HLfitlist'></span><span id='topic+summary.fixedLRT'></span><span id='topic+print'></span><span id='topic+print.HLfit'></span><span id='topic+print.HLfitlist'></span><span id='topic+print.fixedLRT'></span>

<h3>Description</h3>

<p>Summary and print methods for results from HLfit or related functions. <code>summary</code> may also be used as an extractor (see e.g. <code><a href="#topic+beta_table">beta_table</a></code>).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
summary(object, details=FALSE, max.print=100L, verbose=TRUE, ...)
## S3 method for class 'HLfitlist'
summary(object, ...)
## S3 method for class 'fixedLRT'
summary(object, verbose=TRUE, ...)
## S3 method for class 'HLfit'
print(x,...)
## S3 method for class 'HLfitlist'
print(x,...)
## S3 method for class 'fixedLRT'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.HLfit_+3A_object">object</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>
<tr><td><code id="summary.HLfit_+3A_x">x</code></td>
<td>
<p>  The return object of HLfit or related functions.</p>
</td></tr>
<tr><td><code id="summary.HLfit_+3A_verbose">verbose</code></td>
<td>
<p> For <code>summary.HLfit</code>, whether to print the screen output that is the primary purpose of summary. <code>verbose=FALSE</code> may be convenient when <code>summary</code> is used as an extractor. For <code>summary.fixedLRT</code>, whether to print the model fits or not. </p>
</td></tr>
<tr><td><code id="summary.HLfit_+3A_max.print">max.print</code></td>
<td>
<p>Controls <code>options("max.print")</code> locally.</p>
</td></tr>
<tr><td><code id="summary.HLfit_+3A_details">details</code></td>
<td>
<p>A vector with elements controlling whether to print some obscure details. Element <code>ranCoefs=TRUE</code> will print details about random-coefficients terms (see Details); and element <code>p_value="Wald"</code> will print a p-value for the t-value of each fixed-effect coefficient, assuming a gaussian distribution of the test statistic (but, beyond the generally questionable nature of p-value tables, see e.g. <code>LRT</code> and <code>fixedLRT</code> for alternative testing approaches).</p>
</td></tr>
<tr><td><code id="summary.HLfit_+3A_...">...</code></td>
<td>
<p>  further arguments passed to or from other methods. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The random effect terms of the linear predictor are of the form <b>ZLv</b>. In particular, for <b>random-coefficients models</b> (i.e., including random-effect terms such as <code>(z|group)</code> specifying a random-slope component), correlated random effects are represented as <b>b = Lv</b> for some matrix <b>L</b>, and where the elements of <b>v</b> are uncorrelated. In the output of the fit, the <code>Var.</code> column gives the
variances of the correlated effects, <b>b=Lv</b>. The <code>Corr.</code> column(s) give their correlation(s). If <code>details</code> is TRUE, estimates and SEs of the (log) variances of the elements of <b>v</b> are reported as for other random effects in the <code>Estimate</code> and <code>cond.SE.</code> columns of the table of lambda coefficients. However, this non-default output is potentially misleading as the elements of <b>v</b> cannot generally be assigned to specific terms (such as intercept and slope) of the random-effect formula, and the representation of <b>b</b> as <b>Lv</b> is not unique.
</p>


<h3>Value</h3>

<p>The return value is a list whose elements may be subject to changes, but two of them can be considered stable, and are thus part of the API: the <code>beta_table</code> and <code>lambda_table</code> which are the displayed tables for the coefficients of fixed effects and random-effect variances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples of fitme() or corrHLfit() usage
</code></pre>

<hr>
<h2 id='update.HLfit'>
Updates a fit 
</h2><span id='topic+update.HLfit'></span><span id='topic+update.formula'></span><span id='topic+update_formulas'></span><span id='topic+update_resp'></span><span id='topic+respName'></span><span id='topic+refit'></span>

<h3>Description</h3>

<p><code>update</code> and <code>update_resp</code> will update and (by default) re-fit a model. They do this mostly by extracting the call stored in the object, updating the call and evaluating that call. Using <code>update(&lt;fit&gt;)</code> is a risky programming style (see Details). <code>update_formulas(&lt;mv fit&gt;, ...)</code> can update formulas from a <code>fitmv</code> fit as well as the single formula of a fit by the other fitting functions.
</p>
<p><code>update_resp</code> handles a new response vector as produced by <code>simulate</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
update(object, formula., ..., evaluate = TRUE)
update_resp(object, newresp, ..., evaluate = TRUE)

update_formulas(object, formula., ...)

# &lt;fit object&gt;$respName[s] : see Details.
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update.HLfit_+3A_object">object</code></td>
<td>

<p>A return object from an HLfit call.
</p>
</td></tr>
<tr><td><code id="update.HLfit_+3A_formula.">formula.</code></td>
<td>

<p>A standard <code>formula</code>; or a <code>formula</code> with a peculiar syntax only describing changes to the original model formula 
(see <code><a href="stats.html#topic+update.formula">update.formula</a></code> for details); or (for multivariate-response models) a list of <code>formula</code> of such types.
</p>
</td></tr>
<tr><td><code id="update.HLfit_+3A_newresp">newresp</code></td>
<td>
<p>New response vector.</p>
</td></tr>
<tr><td><code id="update.HLfit_+3A_...">...</code></td>
<td>

<p>Additional arguments to the call, or arguments with changed values. Use <em>name</em><code> = NULL</code> to remove the argument with given <em>name</em>.
</p>
</td></tr>
<tr><td><code id="update.HLfit_+3A_evaluate">evaluate</code></td>
<td>

<p>If TRUE, evaluate the new call else return the call.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p><b>Controlling response updating</b>: Updating the data may be tricky when the response specified in a formula is not simply the name of a variable in the data. For example,
if the response was specified as <code>I(foo^2)</code> the variable <code>foo</code> is not what <code>simulate.HLfit</code> will simulate, so <code>foo</code> should not be updated with such simulation results, yet this is what should be updated in the <code>data</code>. For some time <span class="pkg">spaMM</span> has handled such cases by using an alternative way to provide updated response information, but this has some limitations. So <span class="pkg">spaMM</span> now update the data after checking that this is correct, which the consequence that when response updating is needed (notably, for bootstrap procedures), the response should preferably be specified as the name of a variable in the data, rather than a more complicated expression. 
</p>
<p>However, in some cases, dynamic evaluation of the response variable may be helpful. For example, for bootstrapping hurdle models, the zero-truncated response may be specified as <code>I(count[presence&gt;0] &lt;- NA; count)</code> (where both the zero-truncated <code>count</code> and binary <code>presence</code> variables are both updated by the bootstrap simulation). In that case the names of the two variables to be updated is provided by setting (say)<br />
<code>&lt;fit object&gt;$respNames &lt;- c("presence", "count")</code><br />
for an hurdle model fit as a bivariate-response model, with first submodel for presence/absence, and second submodel for zero-truncated response. A full example is developed in the &ldquo;Gentle introduction&rdquo; to <span class="pkg">spaMM</span> (
<a href="https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/spaMMintro.pdf">https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref/-/blob/master/vignettePlus/spaMMintro.pdf</a>).
Alternatively for univariate-response fits, use <br /> 
<code>&lt;fit object&gt;$respName &lt;- "count"</code>
</p>
<p><b>Controlling formula updating</b>: Early versions of <span class="pkg">spaMM</span>'s <code>update</code> method relied on <code>stats::update.formula</code> whose results endorse <code>stats</code>'s (sometimes annoying) convention that a formula without an explicit intercept term actually includes an intercept. <code>spaMM::update.HLfit</code> was then defined to avoid this problem. <b>Formula updates should still be carefully checked</b>, as getting them perfect has not been on the priority list. 
</p>
<p>Various post-fit functions from base R may use <code>update.formula</code> directly, rather than using automatic method selection for <code>update</code>. <code>update.formula</code> is not itself a generic, which leads to the following problem. To make <code>update.formula()</code> work on multivariate-response fits, one would like to be able to redefine it as a generic, with an <code>HLfit</code> method that would perform what <code>update_formulas</code> does, but such a redefinition appears to be forbidden in a package distributed on CRAN. Instead it is suggested to define a new generic <code>spaMM::update</code>, which could have a <code>spaMM::update.formula</code> as a method (possibly itself a generic). This would be of limited interest as the new <code>spaMM::update.formula</code> would be visible to <code>spaMM::update</code> but not to <code>stats::update</code>, and thus the post-fit functions from base R would still not use this method.  
</p>
<p><b>Safe updating</b>: <code>update(&lt;fit&gt;, ...)</code>, as a general rule, is tricky. <code>update</code> methods are easily affected in a non-transparent way by changes in variables used in the original call. For example
</p>
<pre>
foo &lt;- rep(1,10)
m &lt;- lm(rnorm(10)~1, weights=foo)
rm(foo)
update(m, .~.) # Error
</pre>
<p>To avoid such problems, <span class="pkg">spaMM</span> tries to avoid references to variables in the global environment, by enforcing that the data are explicitly provided to the fitting functions by the <code>data</code> argument, and that any variable used in the <code>prior.weights</code> argument is in the data.
</p>
<p>Bugs can also result when calling <code>update</code> on a fit produced within some function, say function <code>somefn</code> calling <code>fitme(data=mydata,...)</code>, as e.g. <code>update(&lt;fit&gt;)</code> will then seek a global variable <code>mydata</code> that may differ from the fitted <code>mydata</code> which was local to <code>somefn</code>.   
</p>


<h3>Value</h3>

<p><code>update.formula(object)</code> returns an object of the same nature as <code>formula(object)</code>. The other functions and methods return an HLfit fit of the same type as the input object, or a call object, depending on the <code>evaluate</code> value. <b>Warning:</b> The object returned by <code>update_resp</code> cannot be used safely for further programming, for the reason explained in the Details section.  
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+HLCor">HLCor</a></code>,  <code><a href="#topic+HLfit">HLfit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
## First the fit to be updated:
wFit &lt;- HLfit(y ~X1*X3+X2*X3+I(X2^2)+(1|batch),family=Gamma(log),
          resid.model = ~ X3+I(X3^2) ,data=wafers)

newresp &lt;- simulate(wFit)
update_resp(wFit,newresp=newresp)

# For estimates given by Lee et al., Appl. Stochastic Models Bus. Ind. (2011) 27:  315-328:
# Refit with given beta or/and phi values:
 
betavals &lt;- c(5.55,0.08,-0.14,-0.21,-0.08,-0.09,-0.09)
# reconstruct fitted phi value from predictor for log(phi)
Xphi &lt;- with(wafers,cbind(1,X3,X3^2)) ## design matrix
phifit &lt;- exp(Xphi %*% c(-2.90,0.1,0.95))
upd_wafers &lt;- wafers
designX &lt;- get_matrix(wFit)
upd_wafers$off_b &lt;- designX %*% betavals
update(wFit,formula.= . ~ offset(off_b)+(1|batch), data=upd_wafers,
       ranFix=list(lambda=exp(-3.67),phi=phifit))

## There are subtlety in performing REML fits of constrained models,
##   illustrated by the fact that the following fit does not recover 
##   the original likelihood values, because dispersion parameters are
##   estimated but the REML correction changes with the formula:
upd_wafers$off_f &lt;- designX %*% fixef(wFit) ## = predict(wFit,re.form=NA,type="link")
update(wFit,formula.= . ~ offset(off_f)+(1|batch), data=upd_wafers)
#
## To maintain the original REML correction, Consider instead
update(wFit,formula.= . ~ offset(off_f)+(1|batch), data=upd_wafers,
       REMLformula=formula(wFit))  ## recover original p_v and p_bv     
## Alternatively, show original wFit as differences from betavals:  
update(wFit,formula.= . ~ . +offset(off_f), data=upd_wafers)
</code></pre>

<hr>
<h2 id='vcov'>
Extract covariance or correlation components from a fitted model object</h2><span id='topic+beta_table'></span><span id='topic+vcov'></span><span id='topic+vcov.HLfit'></span><span id='topic+Corr'></span><span id='topic+VarCorr'></span><span id='topic+VarCorr.HLfit'></span>

<h3>Description</h3>

<p><code>summary(&lt;fit object&gt;)$beta_table</code> returns the table of fixed-effect coefficients as it is printed by <code>summary</code>, including standard errors and t-values.
</p>
<p><code>vcov</code> returns the variance-covariance matrix of the fixed-effects coefficients.
</p>
<p><code>Corr</code> by default returns correlation matrices of random effects (though see Details for user-defined correlation models).
</p>
<p><code>VarCorr</code> returns (co)variance parameters of random effects, and optionally the residual variance(s), from a fit object, in a data frame format roughly consistent with the method of objects of class <code>"lme"</code>, in particular including columns with consistent names for easier extraction. One may have to consult the summary of the object to check the meaning of the contents of this data frame (e.g., of 'variance' coefficients for non-gaussian random effects). Other extractors to consider are <code><a href="#topic+get_ranPars">get_ranPars</a></code> and <code><a href="#topic+get_inits_from_fit">get_inits_from_fit</a></code>, the latter providing parameters in a form suitable for initializing a fit.
</p>
<p>The covariance matrix of residuals of a fit can be obtained as a block of the hat matrix<br /> 
(<code><a href="#topic+get_matrix">get_matrix</a>(., which="hat_matrix")</code>).  
This is (as other covariances matrices above) a matrix of expected values, generally assuming that the fitted model is correct and that its parameters are &ldquo;well&rdquo; estimated, and should not to be confused with the computation of diagnostic correlations among inferred residuals of a fit.     
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HLfit'
vcov(object, ...)
## S3 method for class 'HLfit'
VarCorr(x, sigma = 1, add_residVars=TRUE, verbose=TRUE, ...)
Corr(object, A=TRUE, cov2cor.=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov_+3A_object">object</code>, <code id="vcov_+3A_x">x</code></td>
<td>
<p>A fitted model object, inheriting from class <code>"HLfit"</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td></tr>

<tr><td><code id="vcov_+3A_add_residvars">add_residVars</code></td>
<td>
<p>Boolean; whether to include residual variance information in the returned table.</p>
</td></tr>
<tr><td><code id="vcov_+3A_sigma">sigma</code></td>
<td>
<p> ignored argument, included for consistency with the generic function. </p>
</td></tr>
<tr><td><code id="vcov_+3A_a">A</code></td>
<td>
<p>Boolean: Whether to return the correlation matrix described by the <b>AL</b> matrix product, when there is an <b>A</b> matrix (as for <code>IMRF</code> terms; see <code><a href="#topic+random-effects">random-effects</a></code>).</p>
</td></tr>
<tr><td><code id="vcov_+3A_cov2cor.">cov2cor.</code></td>
<td>
<p>Boolean: Whether to convert covariance matrices to correlation matrices (see Details).</p>
</td></tr>
<tr><td><code id="vcov_+3A_verbose">verbose</code></td>
<td>
<p>Boolean: Whether to print some notes.</p>
</td></tr>
<tr><td><code id="vcov_+3A_...">...</code></td>
<td>
<p>Other arguments that may be needed by some method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any matrix returned by the <code>Corr</code> extractor is by default the unconditional correlation matrix of a vector &ldquo;<b>ALv</b>&rdquo; of random effects (as defined in  <code><a href="#topic+random-effects">random-effects</a></code>). 
</p>
<p>But it may also be an heteroscedastic matrix for some random effects if <code>cov2cor.</code> is set to FALSE. In particular, the <code><a href="#topic+IMRF">IMRF</a></code> and <code><a href="#topic+MaternIMRFa">MaternIMRFa</a></code> models are by default defined in terms of the inverse of an heteroscedastic covariance matrix (with <code>tcrossprod</code> factor <b>L</b>), and of a <b>A</b> matrix of weights. The product <b>AL</b> will be the <code>tcrossprod</code> factor of a covariance matrix rather than a correlation matrix, unless a non-default normalization was requested when declaring the random-effect terms. User-defined random-effects models may also be heteroscedastic. In all these cases <code>Corr</code> will by default return the correlation matrix, by applying <code>cov2cor</code> to the tcrossproduct. 
</p>


<h3>Value</h3>

<p><code>vcov</code> returns a matrix. 
</p>
<p><code>Corr</code> returns a list, for the different random effect terms. For each random-effect term with nontrivial correlation structure, the returned element is a matrix, returned in base matrix format or in some class from <span class="pkg">Matrix</span>. Otherwise the it is an information message.
</p>
<p><code>VarCorr</code> returns either NULL (if no variance to report, as for a poisson GLM) or a data frame with columns for the grouping factor, term, variance of random effect,  standard deviation (the root of the variance), and optionally for correlation of random effect in random-coefficient terms.  Information about the residual variance is optionally included as the last row(s) of the data frame, when relevant (gaussian- or Gamma-response models with single scalar parameter; beware the meaning of the residual variance parameter for Gamma-response models). 
</p>
<p>Some variance parameters may be removed from the <code>VarCorr</code> output, with a message, such as the slope of the linear predictor describing the correlation model of an <code>adjacency</code> term (see <code>autoregressive</code>). The rare user of such parametrization should not consider this as a stable feature.   
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_inits_from_fit">get_inits_from_fit</a></code> and <code><a href="#topic+get_ranPars">get_ranPars</a></code>.
<code><a href="#topic+get_matrix">get_matrix</a>(., which="beta_v_cov")</code> for the joint covariance matrix of estimates/predictions of fixed effect coefficients and random effects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wafers")
m1 &lt;- HLfit(y ~ X1+X2+(1|batch), resid.model = ~ 1 ,data=wafers, method="ML")
vcov(m1)

# Example from VarCorr() documentation in 'nlme' package
data("Orthodont",package = "nlme")
sp1 &lt;- fitme(distance ~ age+(age|Subject), data = Orthodont, method="REML")
VarCorr(sp1)
</code></pre>

<hr>
<h2 id='verbose'>Tracking progress of fits</h2><span id='topic+verbose'></span>

<h3>Description</h3>

<p>This (partially) documents the usage of the <code>verbose</code> argument of the fitting functions, and more specifically of <code>verbose["TRACE"]</code> values. 
</p>
<p>Default is <code>TRACE=FALSE</code> (or 0) which is self-explanatory. <code>TRACE=TRUE</code> (or 1) shows values of outer-estimated parameters (and possibly fixed values of parameters that would be outer-estimated), some cryptic progress bar, and the attained value of the likelihood objective function (but when there inner-estimated dispersion parameters, the output is more difficult to describe concisely). Other values have effect may change in later versions without notice see Details).
</p>
<p>If the fitted model includes a residual-dispersion mdoel, some tracing output for the latter may be confusingly intermingled with tracing output of the mean-response model. The Details are valid only for the mean-response model.
</p>


<h3>Details</h3>

<p>0&lt;<code>TRACE</code>&lt;1 only shows the cryptic progress bar.<br />  <code>TRACE=2</code> will further show information about the progress of Levenberg-Marquardt-like steps for linear-predictor coefficients.<br /> <code>TRACE=3</code> will further show information about the progress of distinct Levenberg-Marquardt-like steps random effects given fixed-effect coefficients.<br /> <code>TRACE=4</code> will further show cryptic information about which matrix computations are requested.<br /> <code>TRACE=5</code> will further report (through a call to the base <code>trace</code> function) the <code>str(.)</code> of the results of such matrix computations.<br /> <code>TRACE=6</code> will further pause between iterations of the reweighted least-squares algorithm, allowing a browser session to be called.
</p>

<hr>
<h2 id='wafers'>Data from a resistivity experiment for semiconductor materials.</h2><span id='topic+wafers'></span>

<h3>Description</h3>

<p>This data set was reported and analyzed by Robinson et al. (2006) and reanalyzed by Lee et al. (2011). The data 
&ldquo;deal with wafers in a single etching process in semiconductor manufacturing.
Wafers vary through time since there are some variables that are not perfectly controllable in the etching process. For this
reason, wafers produced on any given day (batch) may be different from those produced on another day (batch). To measure
variation over batch, wafers are tested by choosing several days at random. In this data, resistivity is the response of interest.
There are three variables, gas flow rate (x1), temperature (x2), and pressure (x3) and one random effect (batch or day).&rdquo;  (Lee et al 2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("wafers")</code></pre>


<h3>Format</h3>

<p>The data frame includes 198 observations on the following variables:
</p>

<dl>
<dt>y</dt><dd><p>resistivity.</p>
</dd>
<dt>batch</dt><dd><p>batch, indeed.</p>
</dd>
<dt>X1</dt><dd><p>gas flow rate.</p>
</dd>
<dt>X2</dt><dd><p>temperature.</p>
</dd>
<dt>X3</dt><dd><p>pressure.</p>
</dd>
</dl>



<h3>Source</h3>

<p>This data set was manually pasted from Table 3 of Lee et al. (2011). Transcription errors may have occurred. 
</p>


<h3>References</h3>

<p>Robinson TJ, Wulff SS, Montgomery DC, Khuri AI. 2006. Robust parameter design using generalized linear mixed models. Journal of Quality
Technology 38: 38&ndash;65.
</p>
<p>Lee, Y., Nelder, J.A., and Park, H. 2011. HGLMs for quality improvement. 
Applied Stochastic Models in Business and Industry 27, 315-328.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples in the main Documentation page for the package.
</code></pre>

<hr>
<h2 id='welding'>
Welding data set
</h2><span id='topic+welding'></span>

<h3>Description</h3>

<p>The data give the results of an unreplicated experiment for factors affecting welding
quality conducted by the National Railway Corporation of Japan (Taguchi and Wu, 1980, cited in Smyth et al., 2001). It is a toy example 
for heteroscedastic models and is also suitable for illustrating fit of overparameterized models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("welding")</code></pre>


<h3>Format</h3>

<p>The data frame includes 16 observations on 10 variables:
</p>

<dl>
<dt>Strengh</dt><dd><p>response variable;</p>
</dd>
<dt>...</dt><dd><p>nine two-level factors.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data were downloaded from http://www.statsci.org/data/general/welding.txt on 2014/08/19 and are consistent with those shown
in table 5 of Bergman and Hynén (1997).
</p>


<h3>References</h3>

<p>Bergman B, Hynén A (1997) Dispersion effects from
unreplicated designs in the <code class="reqn">2^{k-p}</code> series.
Technometrics, 39, 191–98.
</p>
<p>Smyth GK, Huele AF, Verbyla AP (2001). Exact and approximate REML for heteroscedastic regression. Statistical Modelling 1, 161-175. 
</p>
<p>Taguchi G, Wu Y (1980) Introduction to off-line
quality control. Nagoya, Japan: Central Japan
Quality Control Association.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("welding")
## toy example from Smyth et al.
fitme(Strength ~ Drying + Material,resid.model = ~ Material+Preheating ,data=welding, method="REML")
## toy example of overparameterized model
fitme(Strength ~ Rods+Thickness*Angle+(1|Rods),resid.model = ~ Rods+Thickness*Angle ,data=welding)
</code></pre>

<hr>
<h2 id='WinterWheat'>
Example of yield stability analysis
</h2><span id='topic+WinterWheat'></span><span id='topic+GxE'></span>

<h3>Description</h3>

<p>Translation of an example that may be found at<br />
<a href="https://www.r-bloggers.com/2019/06/genotype-experiments-fitting-a-stability-variance-model-with-r/">https://www.r-bloggers.com/2019/06/genotype-experiments-fitting-a-stability-variance-model-with-r/</a>,
based on yield of eight durum wheat genotypes over seven years, following a randomised block design with three replicates.
A genotype-in-year random effect is used to quantify genotype-by-environment interactions. 
In the first fit (<code>constvar</code>), the variance of this random effect is constant over genotypes. 
In the second fit (<code>varvar</code>), different variances are fitted for the distinct genotypes, to assess the relative stability of yield of the different genotypes over environments. This second model can be fitted as a 
constrained random-coefficient model, where the constraint describes a diagonal covariance matrix for the random coefficients.
</p>
<p>This example uses the fact that the argument <code>fixed=list(ranCoefs=&lt;...&gt;)</code> can be used to fit a 
covariance matrix with an arbitrary set of constrained elements. Only elements 
left as 'NA' (here the diagonal elements of the matrix) are fitted.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (spaMM.getOption("example_maxtime")&gt;1.5 &amp;&amp;
      requireNamespace("agridat", quietly = TRUE)) {

data("onofri.winterwheat", package="agridat")

(constvar &lt;- fitme(
  yield ~ gen + (1|year) + (1|block %in% year)+(1|gen %in% year), 
  data=onofri.winterwheat, method="REML"))
  
# Diagonal matrix of NA's, represented as vector for its lower triangle:
ranCoefs_for_diag &lt;- function(nlevels) { 
 ## Conceptual version
 # diagmat &lt;- matrix(NA, ncol=nlevels,nrow=nlevels)
 # diagmat[lower.tri(diagmat,diag=FALSE)] &lt;- 0
 # return(diagmat[lower.tri(diagmat,diag=TRUE)])
 ## which amounts to:
 vec &lt;- rep(0,nlevels*(nlevels+1L)/2L)
 vec[cumsum(c(1L,rev(seq(nlevels-1L)+1L)))] &lt;- NA
 vec
} 

(varvar &lt;- fitme(
  yield ~ gen + (1|year) + (1|block %in% year)+(0+gen|gen %in% year), method="REML", 
  data=onofri.winterwheat, fixed=list(ranCoefs=list("3"=ranCoefs_for_diag(8L)))))

}

</code></pre>

<hr>
<h2 id='wrap_parallel'>
Selecting interfaces for parallelisation
</h2><span id='topic+wrap_parallel'></span>

<h3>Description</h3>

<p>spaMM implements three interfaces for parallelisation. Depending on their arguments, either serial computation (default), a socket cluster (parallelisation default), or a fork cluster (available in linux and alike operating systems) can be used by all interfaces. 
</p>
<p><code><a href="#topic+dopar">dopar</a></code> is called by default by its bootstrap procedures, and <code><a href="#topic+dofuture">dofuture</a></code> has been developed as an alternative, whose use is controlled by <code>spaMM.options(wrap_parallel="dofuture")</code> (versus the default, <code>spaMM.options(wrap_parallel="dopar")</code>. <code><a href="#topic+combinepar">combinepar</a></code> is the third and more recent interface; it is not a formally supported <code>wrap_parallel</code> option because its additional functionalities are of no use in <span class="pkg">spaMM</span>'s bootstrap procedures.
</p>
<p><code>dopar</code> is based on a patchwork of backends: for socket clusters, depending whether the <span class="pkg">doSNOW</span> package is attached, <code>foreach</code> or <code>pbapply</code> is called (<span class="pkg">doSNOW</span> allows more efficient load balancing than <code>pbapply</code>); for fork clusters, <code>parallel::mclapply</code> is used. This makes it impossible to ensure consistency of options accross computation environments, notably of enforcing the <code>.combine</code> control of <code>foreach</code>; and this makes it error-prone to ensure identical control of random number generators in all cases (although <code>dopar</code> and <code>combinepar</code> still aim to ensure the latter control).  
</p>
<p>By contrast, <code>dofuture</code> is based only on the <span class="pkg">future</span> and <span class="pkg">future.apply</span> packages, in principle allowing a single syntax to control of random number generator across the different cases, hence repeatable results across them. This does <b>not</b> make a difference for bootstrap computations in <span class="pkg">spaMM</span> as the bootstrap samples are never simulated in parallel: only refitting the models is performed in parallel, and fit results do not depend on random numbers. Further, the <span class="pkg">future</span>-based code for socket clusters appears significantly slower than the one used by <code>dopar</code>. For these reasons, the latter function is used by default by <span class="pkg">spaMM</span>.
</p>
<p><code>combinepar</code> is a third and more recent approach designed to address the other issue: it always uses <span class="pkg">foreach</span> so that the <code>.combine</code> control is consistently enforced. It uses <span class="pkg">future</span> only when no alternative is available to produce a progress bar (namely, for socket clusters when <span class="pkg">doSNOW</span> is not available).
</p>

<hr>
<h2 id='X.GCA'>
Fixed-effect terms for dyadic interactions
</h2><span id='topic+X.GCA'></span><span id='topic+X.antisym'></span>

<h3>Description</h3>

<p><code>X.GCA</code> and <code>X.antisym</code> are functions which, when called in a model formula, stand for terms designed to represent the effet of symmetric interactions between pairs of individuals (order of individuals in the pair does not matter). <code>antisym</code> likewise represents anti-symmetric interactions (the effect of reciprocal ordered pairs on the outcome are opposite, as in the so-called Bradley-Terry models). These constructs all account for multiple membership, i.e., the fact that the same individual may act as the first or the second individual among different pairs, or even within one pair if this makes sense).   
</p>
<p>The outcome of an interaction between a pair <code class="reqn">i,j</code> of agents is subject to a symmetric overall effect <code class="reqn">a_{ij}</code> when the effect  &ldquo;on&rdquo; individual <code class="reqn">i</code> (or viewed from the perspective of individual <code class="reqn">i</code>) equals the effect on <code class="reqn">j</code>: <code class="reqn">a_{ij}=a_{ji}</code>. This may result from the additive effect of individual effects <code class="reqn">a_{i}</code> and <code class="reqn">a_{j}</code>:  <code class="reqn">a_{ij}=a_i+a_j</code>. A <code>X.GCA</code> call represents such symmetric additive effects. Conversely, antisymmetry is characterized by <code class="reqn">a_{ij}=a_i-a_j=-a_{ji}</code> and is represented by a <code>X.antisym</code> call. See the <code><a href="#topic+diallel">diallel</a></code> documentation for similar constructs for random effects, for additional comments on semantics (e.g. about &ldquo;GCA&rdquo;), and for further references. 
</p>
<p>If individual-level factors ID1 + ID2 were included in a formula for dyadic interactions, this would result in different coefficients being fitted for the same level in each factor. By contrast, the present constucts ensure that a single coefficient is fitted for the same-named levels of factors ID1 and ID2. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X.GCA(term, contr="contr.treatment", ...) 
X.antisym(term, contr="contr.treatment", ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="X.GCA_+3A_term">term</code></td>
<td>

<p>an expression of the form &lt;.&gt;:&lt;.&gt; where each &lt;.&gt; represents a factor (or a variable that will automaticall be converted to a factor) present in the <code>data</code> of the fitting function call. 
</p>
</td></tr>
<tr><td><code id="X.GCA_+3A_contr">contr</code></td>
<td>

<p>The <code><a href="stats.html#topic+contrasts">contrasts</a></code> used. Only the default and <code>"contr.sum"</code> are implemented.
</p>
</td></tr>
<tr><td><code id="X.GCA_+3A_...">...</code></td>
<td>

<p>For programming purposes, not documented.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fixed-effect terms (<code>GCA(Par1,Par2)</code>, etc) from the <span class="pkg">lmDiallel</span> package (Onofri &amp; Terzaroli, 2021), defined by functions returning design matrices for usage with <code>stats:lm</code>, work in a formula for a <span class="pkg">spaMM</span> fit, and users can define use such functions as templates for additional functions that will work similarly. However, not all post-fit functions will handle terms defined in this way well: checking robustness of <code>predict</code> on small and permuted <code>newdata</code>, as shown in the Examples, is a good test. Such problems happen because the formula-handling machinery of R handles terms represented by either a matrix or a factor, while both the model matrix and the factor information used to construct dyadic-interaction terms are needed to correctly predict, with new data, from models including such terms.  
</p>
<p>The presently designed functions are defined to solve this issue. By using such functions as template, users can define additional functions with the same return format (as further explained in the documented source code of <code>X.antisym</code>), which will allow them to perform correct predictions from fitted models.    
</p>


<h3>Value</h3>

<p>The functions return design matrices with additional class <code>"factorS"</code> and attributes <code>"call"</code> and <code>"spec_levs"</code>.
</p>


<h3>References</h3>

<p>Onofri A., Terzaroli N. (2021) lmDiallel:  Linear fixed effects models for diallel crosses. Version 0.9.4. <a href="https://cran.r-project.org/package=lmDiallel">https://cran.r-project.org/package=lmDiallel</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Simulate dyadic data

set.seed(123)
nind &lt;- 10       # Beware data grow as O(nind^2)
x &lt;- runif(nind^2) 
id12 &lt;- expand.grid(id1=seq(nind),id2=seq(nind))
id1 &lt;- id12$id1
id2 &lt;- id12$id2
u &lt;-  rnorm(nind,mean = 0, sd=0.5)

## additive individual effects:
y &lt;-  0.1 + 1*x + u[id1] +  u[id2] + rnorm(nind^2,sd=0.2)

## anti-smmetric individual effects:
t &lt;-  0.1 + 1*x + u[id1] - u[id2] + rnorm(nind^2,sd=0.2)

dyaddf &lt;- data.frame(x=x, y=y, t=t, id1=id1,id2=id2)
# : note that this contains two rows per dyad, which avoids identifiability issues.

# Enforce that interactions are between distinct individuals (not essential for the fit):
dyaddf &lt;- dyaddf[- seq.int(1L,nind^2,nind+1L),] 


# Fits:

(addfit &lt;- fitme(y ~x +X.GCA(id1:id2), data=dyaddf))

(antifit &lt;- fitme(t ~x +X.antisym(id1:id2), data=dyaddf))

if (FALSE) { #### check of correct handling by predict():

  # First scramble the data so that input factors are in no particular order
  set.seed(123)
  dyaddf &lt;- dyaddf[sample(nrow(dyaddf)),]
  
  addfiti &lt;- fitme(y ~x +X.GCA(id1:id2), data=dyaddf)
  foo &lt;- rev(2:4)
  p1 &lt;- predict(addfiti)[foo]
  p2 &lt;- predict(addfiti, newdata=dyaddf[foo,])
  diff(range(p1-p2))&lt;1e-10    # must be TRUE
}
</code></pre>

<hr>
<h2 id='ZAXlist'>S4 classes for structured matrices</h2><span id='topic+ZAXlist'></span><span id='topic+class+3AZAXlist'></span><span id='topic+ZAXlist-class'></span><span id='topic+missingOrNULL'></span><span id='topic+class+3AmissingOrNULL'></span><span id='topic+missingOrNULL-class'></span><span id='topic++25+2A+25-methods'></span><span id='topic+crossprod-methods'></span><span id='topic+tcrossprod-methods'></span><span id='topic++25+2A+25+2CZAXlist+2CMatrix-method'></span><span id='topic++25+2A+25+2CZAXlist+2Cmatrix-method'></span><span id='topic++25+2A+25+2CZAXlist+2Cnumeric-method'></span><span id='topic++25+2A+25+2Cnumeric+2CZAXlist-method'></span><span id='topic+t.ZAXlist'></span><span id='topic+crossprod+2CZAXlist+2CMatrix-method'></span><span id='topic+crossprod+2CZAXlist+2Cmatrix-method'></span><span id='topic+crossprod+2CZAXlist+2Cnumeric-method'></span><span id='topic+tcrossprod+2CZAXlist+2CmissingOrNULL-method'></span><span id='topic+Kronfacto'></span><span id='topic+class+3AKronfacto'></span><span id='topic+Kronfacto-class'></span><span id='topic+dim.Kronfacto'></span><span id='topic++25+2A+25+2CKronfacto+2Cnumeric-method'></span><span id='topic+crossprod+2CKronfacto+2CMatrix-method'></span><span id='topic+crossprod+2CKronfacto+2Cmatrix-method'></span><span id='topic+crossprod+2CKronfacto+2Cnumeric-method'></span>

<h3>Description</h3>

<p>A <code>ZAXlist</code> object is a representation of the &ldquo;<code>ZAL</code>&rdquo; matrix as an S4 class holding a list of descriptors of each <code>ZAL</code> block for each random effect.
</p>
<p>A <code>Kronfacto</code> object is a representation of a Kronecker product as an S4 class holding its factors. Methods defined for this class may avoid the computation of the Kronecker product as an actual matrix of large dimensions.
</p>
<p>This documentation is for development purposes and may be incomplete. The objects and methods are not part of the programming interface and are subject to modification without notice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'># new("ZAXlist", LIST=.) 
# new("Kronfacto", BLOB=.) 
</code></pre>


<h3>Slots</h3>


<dl>
<dt><code>LIST</code>:</dt><dd><p>A list whose each block is either a <code>(M|m)atrix</code>, 
or a list with two elements (and additional class <code>ZA_QCHM</code>): <code>ZA</code>, and the <code><a href="Matrix.html#topic+Cholesky">Cholesky</a></code> factor <code>Q_CHMfactor</code> of the precision matrix (<code>L=solve(Q_CHMfactor,system="Lt")</code>).</p>
</dd>
<dt><code>BLOB</code>:</dt><dd><p>An environment holding <code>lhs</code> and <code>rhs</code>, the factors of the Kronecker product, and other objects initialized as promises. See the source code of the non-exported <code>.def_Kranfacto</code> constructor for further information.</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
