<!DOCTYPE html><html lang="en"><head><title>Help for package image.textlinedetector</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {image.textlinedetector}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#image_textlines_astar'><p>Text Line Segmentation based on the A* Path Planning Algorithm</p></a></li>
<li><a href='#image_textlines_crop'><p>Crop an image to extract only the region containing text</p></a></li>
<li><a href='#image_textlines_flor'><p>Text Line Segmentation based on valley finding in projection profiles</p></a></li>
<li><a href='#image_wordsegmentation'><p>Find Words by Connected Components Labelling</p></a></li>
<li><a href='#lines.textlines'><p>Extract the polygons of the textlines</p></a></li>
<li><a href='#ocv_deslant'><p>Deslant images by putting cursive text upright</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Segment Images in Text Lines and Words</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jan Wijffels &lt;jwijffels@bnosac.be&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Find text lines in scanned images and segment the lines into words.
    Includes implementations of the paper 'Novel A* Path Planning Algorithm for Line Segmentation of Handwritten Documents' by Surinta O. et al (2014) &lt;<a href="https://doi.org/10.1109%2FICFHR.2014.37">doi:10.1109/ICFHR.2014.37</a>&gt; available at <a href="https://github.com/smeucci/LineSegm">https://github.com/smeucci/LineSegm</a>,
    an implementation of 'A Statistical approach to line segmentation in handwritten documents' by Arivazhagan M. et al (2007) &lt;<a href="https://doi.org/10.1117%2F12.704538">doi:10.1117/12.704538</a>&gt;, 
    and a wrapper for an image segmentation technique to detect words in text lines as described in the paper 'Scale Space Technique for Word Segmentation in Handwritten Documents' by Manmatha R. and Srimal N. (1999) paper at &lt;<a href="https://doi.org/10.1007%2F3-540-48236-9_3">doi:10.1007/3-540-48236-9_3</a>&gt;, wrapper for code available at <a href="https://github.com/arthurflor23/text-segmentation">https://github.com/arthurflor23/text-segmentation</a>.
    Provides as well functionality to put cursive text in images upright using the approach defined in the paper 'A new normalization technique for cursive handwritten words' by  Vinciarelli A. and Luettin J. (2001) &lt;<a href="https://doi.org/10.1016%2FS0167-8655%2801%2900042-3">doi:10.1016/S0167-8655(01)00042-3</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/DIGI-VUB/image.textlinedetector">https://github.com/DIGI-VUB/image.textlinedetector</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.9), magick</td>
</tr>
<tr>
<td>Suggests:</td>
<td>opencv</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17 or C++11 and OpenCV 3 or newer: libopencv-dev
(Debian, Ubuntu) or opencv-devel (Fedora)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-09 21:53:05 UTC; jwijffels</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan Wijffels [aut, cre, cph] (R wrapper),
  Vrije Universiteit Brussel - DIGI: Brussels Platform for Digital
    Humanities [cph] (R wrapper),
  Jeroen Ooms [ctb, cph] (More details in LICENSE.note file),
  Arthur Fl√¥r [ctb, cph] (More details in LICENSE.note file),
  Saverio Meucci [ctb, cph] (More details in LICENSE.note file),
  Yeara Kozlov [ctb, cph] (More details in LICENSE.note file),
  Tino Weinkauf [ctb, cph] (More details in LICENSE.note file),
  Harald Scheidl [ctb, cph] (More details in LICENSE.note file)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 23:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='image_textlines_astar'>Text Line Segmentation based on the A* Path Planning Algorithm</h2><span id='topic+image_textlines_astar'></span>

<h3>Description</h3>

<p>Text Line Segmentation based on the A* Path Planning Algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_textlines_astar(x, morph = FALSE, step = 2, mfactor = 5, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="image_textlines_astar_+3A_x">x</code></td>
<td>
<p>an object of class magick-image</p>
</td></tr>
<tr><td><code id="image_textlines_astar_+3A_morph">morph</code></td>
<td>
<p>logical indicating to apply a morphological 5x5 filter</p>
</td></tr>
<tr><td><code id="image_textlines_astar_+3A_step">step</code></td>
<td>
<p>step size of A-star</p>
</td></tr>
<tr><td><code id="image_textlines_astar_+3A_mfactor">mfactor</code></td>
<td>
<p>multiplication factor in the cost heuristic of the A-star algorithm</p>
</td></tr>
<tr><td><code id="image_textlines_astar_+3A_trace">trace</code></td>
<td>
<p>logical indicating to show the evolution of the line detection</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements
</p>

<ul>
<li><p>n: the number of lines found
</p>
</li>
<li><p>overview: an opencv-image of the detected areas
</p>
</li>
<li><p>paths: a list of data.frame's with the x/y location of the baseline paths
</p>
</li>
<li><p>textlines: a list of opencv-image's, one for each rectangular text line area
</p>
</li>
<li><p>lines: a data.frame with the x/y positions of the detected lines
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(opencv)
library(magick)
library(image.textlinedetector)
path   &lt;- system.file(package = "image.textlinedetector", "extdata", "example.png")
img    &lt;- image_read(path)
img    &lt;- image_resize(img, "x1000")
areas  &lt;- image_textlines_astar(img, morph = TRUE, step = 2, mfactor = 5, trace = TRUE)
areas  &lt;- lines(areas, img)
areas$n
areas$overview
areas$lines
areas$textlines[[2]]
areas$textlines[[4]]
combined &lt;- lapply(areas$textlines, FUN=function(x) image_read(ocv_bitmap(x)))
combined &lt;- do.call(c, combined)
combined
image_append(combined, stack = TRUE)



plt &lt;- image_draw(img)
lapply(areas$paths, FUN=function(line){
  lines(x = line$x, y = line$y, col = "red")  
})
dev.off()
plt

</code></pre>

<hr>
<h2 id='image_textlines_crop'>Crop an image to extract only the region containing text</h2><span id='topic+image_textlines_crop'></span>

<h3>Description</h3>

<p>Applies a sequence of image operations to obtain a region which contains relevant texts
by cropping white space on the borders of the image.
This is done in the following steps:
morphological opening, morphological closing, blurring, canny edge detection, convex hull contours of the edges, 
keep only contours above the mean contour area, find approximated contour lines of the convex hull contours of these, 
dilation and thresholding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_textlines_crop(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="image_textlines_crop_+3A_x">x</code></td>
<td>
<p>an object of class magick-image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class magick-image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(opencv)
library(magick)
library(image.textlinedetector)
path  &lt;- system.file(package = "image.textlinedetector", "extdata", "example.png")
img   &lt;- image_read(path)
image_info(img)
img   &lt;- image_textlines_crop(img)
image_info(img)

</code></pre>

<hr>
<h2 id='image_textlines_flor'>Text Line Segmentation based on valley finding in projection profiles</h2><span id='topic+image_textlines_flor'></span>

<h3>Description</h3>

<p>Text Line Segmentation based on valley finding in projection profiles
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_textlines_flor(
  x,
  light = TRUE,
  type = c("none", "niblack", "sauvola", "wolf")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="image_textlines_flor_+3A_x">x</code></td>
<td>
<p>an object of class magick-image</p>
</td></tr>
<tr><td><code id="image_textlines_flor_+3A_light">light</code></td>
<td>
<p>logical indicating to remove light effects due to scanning</p>
</td></tr>
<tr><td><code id="image_textlines_flor_+3A_type">type</code></td>
<td>
<p>which type of binarisation to perform before doing line segmentation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements
</p>

<ul>
<li><p>n: the number of lines found
</p>
</li>
<li><p>overview: an opencv-image of the detected areas
</p>
</li>
<li><p>textlines: a list of opencv-image's, one for each text line area
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(opencv)
library(magick)
library(image.textlinedetector)
path   &lt;- system.file(package = "image.textlinedetector", "extdata", "example.png")
img    &lt;- image_read(path)
img    &lt;- image_resize(img, "1000x")
areas  &lt;- image_textlines_flor(img, light = TRUE, type = "sauvola")
areas  &lt;- lines(areas, img)
areas$n
areas$overview
combined &lt;- lapply(areas$textlines, FUN=function(x) image_read(ocv_bitmap(x)))
combined &lt;- do.call(c, combined)
combined
image_append(combined, stack = TRUE)

</code></pre>

<hr>
<h2 id='image_wordsegmentation'>Find Words by Connected Components Labelling</h2><span id='topic+image_wordsegmentation'></span>

<h3>Description</h3>

<p>Filter the image using the gaussian kernel 
and extract components which are connected which are to be considered as words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_wordsegmentation(x, kernelSize = 11L, sigma = 11L, theta = 7L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="image_wordsegmentation_+3A_x">x</code></td>
<td>
<p>an object of class opencv-image containing black/white binary data (type CV_8U1)</p>
</td></tr>
<tr><td><code id="image_wordsegmentation_+3A_kernelsize">kernelSize</code></td>
<td>
<p>size of the kernel</p>
</td></tr>
<tr><td><code id="image_wordsegmentation_+3A_sigma">sigma</code></td>
<td>
<p>sigma of the kernel</p>
</td></tr>
<tr><td><code id="image_wordsegmentation_+3A_theta">theta</code></td>
<td>
<p>theta of the kernel</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements
</p>

<ul>
<li><p>n: the number of lines found
</p>
</li>
<li><p>overview: an opencv-image of the detected areas
</p>
</li>
<li><p>words: a list of opencv-image's, one for each word area
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(opencv)
library(magick)
library(image.textlinedetector)
path  &lt;- system.file(package = "image.textlinedetector", "extdata", "example.png")
img   &lt;- image_read(path)
img   &lt;- image_resize(img, "x1000")
areas &lt;- image_textlines_flor(img, light = TRUE, type = "sauvola")
areas$overview
areas$textlines[[6]]
textwords &lt;- image_wordsegmentation(areas$textlines[[6]])
textwords$n
textwords$overview
textwords$words[[2]]
textwords$words[[3]]

</code></pre>

<hr>
<h2 id='lines.textlines'>Extract the polygons of the textlines</h2><span id='topic+lines.textlines'></span>

<h3>Description</h3>

<p>Extract the polygons of the textlines as a cropped rectangular image containing the image content of the line segmented polygon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textlines'
lines(x, image, crop = TRUE, channels = c("bgr", "gray"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lines.textlines_+3A_x">x</code></td>
<td>
<p>an object of class <code>textlines</code> as returned by <code><a href="#topic+image_textlines_astar">image_textlines_astar</a></code> or <code><a href="#topic+image_textlines_flor">image_textlines_flor</a></code></p>
</td></tr>
<tr><td><code id="lines.textlines_+3A_image">image</code></td>
<td>
<p>an object of class magick-image</p>
</td></tr>
<tr><td><code id="lines.textlines_+3A_crop">crop</code></td>
<td>
<p>extract only the bounding box of the polygon of the text lines</p>
</td></tr>
<tr><td><code id="lines.textlines_+3A_channels">channels</code></td>
<td>
<p>either 'bgr' or 'gray' to work on the colored data or on binary greyscale data</p>
</td></tr>
<tr><td><code id="lines.textlines_+3A_...">...</code></td>
<td>
<p>further arguments passed on</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the object <code>x</code> where element <code>textlines</code> is replaced with the extracted polygons of text lines
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See the examples in ?image_textlines_astar or ?image_textlines_flor
</code></pre>

<hr>
<h2 id='ocv_deslant'>Deslant images by putting cursive text upright</h2><span id='topic+ocv_deslant'></span><span id='topic+image_deslant'></span>

<h3>Description</h3>

<p>This algorithm sets handwritten text in images upright by removing cursive writing style. 
One can use it as a preprocessing step for handwritten text recognition.<br />
</p>

<ul>
<li><p><code>image_deslant</code> expects a magick-image and performs grayscaling before doing deslanting
</p>
</li>
<li><p><code>ocv_deslant</code> expects a ocv-image and does not perform grayscaling before doing deslanting
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ocv_deslant(image, bgcolor = 255, lower_bound = -1, upper_bound = 1)

image_deslant(image, bgcolor = 255, lower_bound = -1, upper_bound = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ocv_deslant_+3A_image">image</code></td>
<td>
<p>an object of class opencv-image (for <code>ocv_deslant</code>) with pixel values between 0 and 255 or a magick-image (for <code>image_deslant</code>)</p>
</td></tr>
<tr><td><code id="ocv_deslant_+3A_bgcolor">bgcolor</code></td>
<td>
<p>integer value with the background color to use to fill the gaps of the sheared image that is returned. Defaults to white: 255</p>
</td></tr>
<tr><td><code id="ocv_deslant_+3A_lower_bound">lower_bound</code></td>
<td>
<p>lower bound of shear values. Defaults to -1</p>
</td></tr>
<tr><td><code id="ocv_deslant_+3A_upper_bound">upper_bound</code></td>
<td>
<p>upper bound of shear values. Defaults to 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class opencv-image or magick-image with the deslanted image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(magick)
library(opencv)
library(image.textlinedetector)
path &lt;- system.file(package = "image.textlinedetector", "extdata", "cursive.png")
img  &lt;- ocv_read(path)
img  &lt;- ocv_grayscale(img)
img
up   &lt;- ocv_deslant(img)
up

img  &lt;- image_read(path)
img
image_deslant(img)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
