<!DOCTYPE html><html><head><title>Help for package cNORM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cNORM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bestModel'><p>Best-fitting Regression Model Based on Powers and Interactions</p></a></li>
<li><a href='#buildFunction'><p>Build regression function for bestModel</p></a></li>
<li><a href='#calcPolyInL'><p>Internal function for retrieving regression function coefficients at specific age</p></a></li>
<li><a href='#calcPolyInLBase'><p>Internal function for retrieving regression function coefficients at specific age</p></a></li>
<li><a href='#calcPolyInLBase2'><p>Internal function for retrieving regression function coefficients at specific</p>
age (optimized)</a></li>
<li><a href='#CDC'><p>BMI growth curves from age 2 to 25</p></a></li>
<li><a href='#checkConsistency'><p>Check the consistency of the norm data model</p></a></li>
<li><a href='#checkWeights'><p>Check, if NA or values &lt;= 0 occur and issue warning</p></a></li>
<li><a href='#cnorm'><p>Continuous Norming</p></a></li>
<li><a href='#cnorm.cv'><p>Cross-validation for Term Selection in cNORM</p></a></li>
<li><a href='#cNORM.GUI'><p>Launcher for the graphical user interface of cNORM</p></a></li>
<li><a href='#computePowers'><p>Compute powers of the explanatory variable a as well as of the person</p>
location l (data preparation)</a></li>
<li><a href='#computeWeights'><p>Weighting of cases through iterative proportional fitting (Raking)</p></a></li>
<li><a href='#derivationTable'><p>Create a table based on first order derivative of the regression model for specific age</p></a></li>
<li><a href='#derive'><p>Derivative of regression model</p></a></li>
<li><a href='#elfe'><p>Sentence completion test from ELFE 1-6</p></a></li>
<li><a href='#epm'><p>Simulated dataset (Educational and Psychological Measurement, EPM)</p></a></li>
<li><a href='#getGroups'><p>Determine groups and group means</p></a></li>
<li><a href='#getNormCurve'><p>Computes the curve for a specific T value</p></a></li>
<li><a href='#getNormScoreSE'><p>Calculates the standard error (SE) or root mean square error (RMSE) of the norm scores</p>
In case of large datasets, both results should be almost identical</a></li>
<li><a href='#life'><p>Life expectancy at birth from 1960 to 2017</p></a></li>
<li><a href='#modelSummary'><p>Prints the results and regression function of a cnorm model</p></a></li>
<li><a href='#mortality'><p>Mortality of infants per 1000 life birth from 1960 to 2017</p></a></li>
<li><a href='#normTable'><p>Create a norm table based on model for specific age</p></a></li>
<li><a href='#plot.cnorm'><p>S3 function for plotting cnorm objects</p></a></li>
<li><a href='#plotCnorm'><p>General convencience plotting function</p></a></li>
<li><a href='#plotDensity'><p>Plot the density function per group by raw score</p></a></li>
<li><a href='#plotDerivative'><p>Plot first order derivative of regression model</p></a></li>
<li><a href='#plotNorm'><p>Plot manifest and fitted norm scores</p></a></li>
<li><a href='#plotNormCurves'><p>Plot norm curves</p></a></li>
<li><a href='#plotPercentiles'><p>Plot norm curves against actual percentiles</p></a></li>
<li><a href='#plotPercentileSeries'><p>Generates a series of plots with number curves by percentile for different models</p></a></li>
<li><a href='#plotRaw'><p>Plot manifest and fitted raw scores</p></a></li>
<li><a href='#plotSubset'><p>Evaluate information criteria for regression model</p></a></li>
<li><a href='#ppvt'><p>Vocabulary development from 2.5 to 17</p></a></li>
<li><a href='#predictNorm'><p>Retrieve norm value for raw score at a specific age</p></a></li>
<li><a href='#predictRaw'><p>Predict single raw value</p></a></li>
<li><a href='#prepareData'><p>Prepare data for modeling in one step (convenience method)</p></a></li>
<li><a href='#prettyPrint'><p>Format raw and norm tables</p>
The function takes a raw or norm table, condenses intervals at the bottom and top
and round the numbers to meaningful interval.</a></li>
<li><a href='#print.cnorm'><p>S3 method for printing model selection information</p></a></li>
<li><a href='#printSubset'><p>Print Model Selection Information</p></a></li>
<li><a href='#rangeCheck'><p>Check for horizontal and vertical extrapolation</p></a></li>
<li><a href='#rankByGroup'><p>Determine the norm scores of the participants in each subsample</p></a></li>
<li><a href='#rankBySlidingWindow'><p>Determine the norm scores of the participants by sliding window (experimental)</p></a></li>
<li><a href='#rawTable'><p>Create a table with norm scores assigned to raw scores for a specific age based on the regression model</p></a></li>
<li><a href='#regressionFunction'><p>Regression function</p></a></li>
<li><a href='#simMean'><p>Simulate mean per age</p></a></li>
<li><a href='#simSD'><p>Simulate sd per age</p></a></li>
<li><a href='#simulateRasch'><p>Simulate raw test scores based on Rasch model</p></a></li>
<li><a href='#standardizeRakingWeights'><p>Function for standardizing raking weights</p>
Raking weights get divided by the smallest weight. Thereby, all weights
become larger or equal to 1 without changing the ratio of the weights
to each other.</a></li>
<li><a href='#summary.cnorm'><p>S3 method for printing the results and regression function of a cnorm model</p></a></li>
<li><a href='#weighted.quantile'><p>Weighted quantile estimator</p></a></li>
<li><a href='#weighted.quantile.harrell.davis'><p>Weighted Harrell-Davis quantile estimator</p></a></li>
<li><a href='#weighted.quantile.inflation'><p>Weighted quantile estimator through case inflation</p></a></li>
<li><a href='#weighted.quantile.type7'><p>Weighted type7 quantile estimator</p></a></li>
<li><a href='#weighted.rank'><p>Weighted rank estimation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Continuous Norming</td>
</tr>
<tr>
<td>Version:</td>
<td>3.0.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Wolfgang Lenhard &lt;wolfgang.lenhard@uni-wuerzburg.de&gt;</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-08</td>
</tr>
<tr>
<td>Description:</td>
<td>Conventional methods for producing standard scores or percentiles 
    in psychometrics or biometrics are often plagued with 'jumps' or 'gaps' 
    (i.e., discontinuities) in norm tables and low confidence for assessing 
    extreme scores. The continuous norming method introduced by A. Lenhard et al.
    (2016, &lt;<a href="https://doi.org/10.1177%2F1073191116656437">doi:10.1177/1073191116656437</a>&gt;; 2019, &lt;<a href="https://doi.org/10.1371%2Fjournal.pone.0222279">doi:10.1371/journal.pone.0222279</a>&gt;;
    2021 &lt;<a href="https://doi.org/10.1177%2F0013164420928457">doi:10.1177/0013164420928457</a>&gt;) estimates percentile development 
    (e. g. over age) and generates continuous test norm scores on the basis of 
    the raw data from standardization samples, without requiring assumptions 
    about the distribution of the raw data: Norm scores are directly established 
    from raw data by modeling the latter ones as a function of both percentile 
    scores and an explanatory variable (e.g., age). The method minimizes bias 
    arising from sampling and measurement error, while handling marked deviations 
    from normality, addressing bottom or ceiling effects and capturing almost 
    all of the variance in the original norm data sample. It includes procedures 
    for post stratification of norm samples to overcome bias in data collection 
    and to mitigate violations of representativeness. An online demonstration is 
    available via <a href="https://cnorm.shinyapps.io/cNORM/">https://cnorm.shinyapps.io/cNORM/</a>.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lattice (&ge; 0.21), leaps (&ge; 3.1), latticeExtra (&ge; 0.6)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, shiny, shinycssloaders, foreign, readxl, rmarkdown,
testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL-3</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.psychometrica.de/cNorm_en.html">https://www.psychometrica.de/cNorm_en.html</a>,
<a href="https://github.com/WLenhard/cNORM">https://github.com/WLenhard/cNORM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/WLenhard/cNORM/issues">https://github.com/WLenhard/cNORM/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-08 09:35:17 UTC; gbpa005</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexandra Lenhard <a href="https://orcid.org/0000-0001-8680-4381"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Wolfgang Lenhard <a href="https://orcid.org/0000-0002-8184-6889"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Sebastian Gary [aut],
  WPS publisher [fnd] (&lt;https://www.wpspublish.com/&gt;)</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-08 10:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bestModel'>Best-fitting Regression Model Based on Powers and Interactions</h2><span id='topic+bestModel'></span>

<h3>Description</h3>

<p>Computes and selects the best-fitting regression model by evaluating a series of models with increasing predictors.
It aims to find a parsimonious model that effectively captures the variance in the data. This can be useful in
psychometric test construction to smooth out data and reduce noise while retaining key diagnostic information.
Model selection can be based on the number of terms or the explained variance (R^2). Setting high values for the
number of terms, R^2 cutoff, or 'k' may lead to overfitting. Typical recommended starting points are 'terms = 5',
'R^2 = .99', and 'k = 4'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bestModel(
  data,
  raw = NULL,
  R2 = NULL,
  k = NULL,
  t = NULL,
  predictors = NULL,
  terms = 0,
  weights = NULL,
  force.in = NULL,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bestModel_+3A_data">data</code></td>
<td>
<p>Preprocessed dataset with 'raw' scores, powers, interactions, and usually an explanatory variable (like age).</p>
</td></tr>
<tr><td><code id="bestModel_+3A_raw">raw</code></td>
<td>
<p>Name of the raw score variable (default: 'raw').</p>
</td></tr>
<tr><td><code id="bestModel_+3A_r2">R2</code></td>
<td>
<p>Adjusted R^2 stopping criterion for model building (default: 0.99).</p>
</td></tr>
<tr><td><code id="bestModel_+3A_k">k</code></td>
<td>
<p>Power constant influencing model complexity (default: 4, max: 6).</p>
</td></tr>
<tr><td><code id="bestModel_+3A_t">t</code></td>
<td>
<p>Age power parameter. If unset, defaults to 'k'.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_predictors">predictors</code></td>
<td>
<p>List of predictors or regression formula for model selection. Overrides 'k' and can include additional variables.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_terms">terms</code></td>
<td>
<p>Desired number of terms in the model.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_weights">weights</code></td>
<td>
<p>Optional case weights. If set to FALSE, default weights (if any) are ignored.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_force.in">force.in</code></td>
<td>
<p>Variables forcibly included in the regression.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_plot">plot</code></td>
<td>
<p>If TRUE (default), displays a percentile plot of the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Additional functions like <code>plotSubset(model)</code> and <code>cnorm.cv</code> can aid in model evaluation.
</p>


<h3>Value</h3>

<p>The model meeting the R^2 criteria. Further exploration can be done using <code>plotSubset(model)</code> and <code>plotPercentiles(data, model)</code>.
</p>


<h3>See Also</h3>

<p>plotSubset, plotPercentiles, plotPercentileSeries, checkConsistency
</p>
<p>Other model: 
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example with sample data
normData &lt;- prepareData(elfe)
model &lt;- bestModel(normData)
plotSubset(model)
plotPercentiles(normData, model)

# Specifying variables explicitly
preselectedModel &lt;- bestModel(normData, predictors = c("L1", "L3", "L1A3", "A2", "A3"))
print(regressionFunction(preselectedModel))

# Modeling based on the CDC data
bmi.data &lt;- prepareData(CDC, raw = "bmi", group = "group", age = "age")
bmi.model &lt;- bestModel(bmi.data, raw = "bmi")
printSubset(bmi.model)

# Using a precomputed model formula for gender-specific models
bmi.model.boys &lt;- bestModel(bmi.data[bmi.data$sex == 1, ], predictors = bmi.model$terms)
bmi.model.girls &lt;- bestModel(bmi.data[bmi.data$sex == 2, ], predictors = bmi.model$terms)

# Using a custom list of predictors and incorporating the 'sex' variable
bmi.sex &lt;- bestModel(bmi.data, raw = "bmi", predictors = c(
  "L1", "L3", "A3", "L1A1", "L1A2", "L1A3", "L2A1", "L2A2",
  "L2A3", "L3A1", "L3A2", "L3A3", "sex", force.in = c("sex"))

## End(Not run)
</code></pre>

<hr>
<h2 id='buildFunction'>Build regression function for bestModel</h2><span id='topic+buildFunction'></span>

<h3>Description</h3>

<p>Build regression function for bestModel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildFunction(raw, k, t, age, covariates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="buildFunction_+3A_raw">raw</code></td>
<td>
<p>name of the raw score variable</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_k">k</code></td>
<td>
<p>the power degree for location</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_t">t</code></td>
<td>
<p>the power degree for age</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_age">age</code></td>
<td>
<p>use age</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_covariates">covariates</code></td>
<td>
<p>use covariates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>reression function
</p>

<hr>
<h2 id='calcPolyInL'>Internal function for retrieving regression function coefficients at specific age</h2><span id='topic+calcPolyInL'></span>

<h3>Description</h3>

<p>The function is an inline for searching zeros in the inverse regression
function. It collapses the regression function at a specific age and simplifies
the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPolyInL(raw, age, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcPolyInL_+3A_raw">raw</code></td>
<td>
<p>The raw value (subtracted from the intercept)</p>
</td></tr>
<tr><td><code id="calcPolyInL_+3A_age">age</code></td>
<td>
<p>The age</p>
</td></tr>
<tr><td><code id="calcPolyInL_+3A_model">model</code></td>
<td>
<p>The cNORM regression model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients
</p>

<hr>
<h2 id='calcPolyInLBase'>Internal function for retrieving regression function coefficients at specific age</h2><span id='topic+calcPolyInLBase'></span>

<h3>Description</h3>

<p>The function is an inline for searching zeros in the inverse regression
function. It collapses the regression function at a specific age and simplifies
the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPolyInLBase(raw, age, coeff, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcPolyInLBase_+3A_raw">raw</code></td>
<td>
<p>The raw value (subtracted from the intercept)</p>
</td></tr>
<tr><td><code id="calcPolyInLBase_+3A_age">age</code></td>
<td>
<p>The age</p>
</td></tr>
<tr><td><code id="calcPolyInLBase_+3A_coeff">coeff</code></td>
<td>
<p>The cNORM regression model coefficients</p>
</td></tr>
<tr><td><code id="calcPolyInLBase_+3A_k">k</code></td>
<td>
<p>The cNORM regression model power parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients
</p>

<hr>
<h2 id='calcPolyInLBase2'>Internal function for retrieving regression function coefficients at specific
age (optimized)</h2><span id='topic+calcPolyInLBase2'></span>

<h3>Description</h3>

<p>The function is an inline for searching zeros in the inverse regression
function. It collapses the regression function at a specific age and
simplifies the coefficients. Optimized version of the prior 'calcPolyInLBase'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPolyInLBase2(raw, age, coeff, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcPolyInLBase2_+3A_raw">raw</code></td>
<td>
<p>The raw value (subtracted from the intercept)</p>
</td></tr>
<tr><td><code id="calcPolyInLBase2_+3A_age">age</code></td>
<td>
<p>The age</p>
</td></tr>
<tr><td><code id="calcPolyInLBase2_+3A_coeff">coeff</code></td>
<td>
<p>The cNORM regression model coefficients</p>
</td></tr>
<tr><td><code id="calcPolyInLBase2_+3A_k">k</code></td>
<td>
<p>The cNORM regression model power parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients
</p>

<hr>
<h2 id='CDC'>BMI growth curves from age 2 to 25</h2><span id='topic+CDC'></span>

<h3>Description</h3>

<p>By the courtesy of the Center of Disease Control (CDC), cNORM includes human growth data for children and adolescents
age 2 to 25 that can be used to model trajectories of the body mass index and to estimate percentiles for clinical
definitions of under- and overweight. The data stems from the NHANES surveys in the US and was published in 2012
as public domain. The data was cleaned by removing missing values and it includes the following variables from or
based on the original dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDC
</code></pre>


<h3>Format</h3>

<p>A data frame with 45053 rows and 7 variables:
</p>

<dl>
<dt>age</dt><dd><p>continuous age in years, based on the month variable</p>
</dd>
<dt>group</dt><dd><p>age group; chronological age in years at the time of examination</p>
</dd>
<dt>month</dt><dd><p>chronological age in month at the time of examination</p>
</dd>
<dt>sex</dt><dd><p>sex of the participant, 1 = male, 2 = female</p>
</dd>
<dt>height</dt><dd><p>height of the participants in cm</p>
</dd>
<dt>weight</dt><dd><p>weight of the participants in kg</p>
</dd>
<dt>bmi</dt><dd><p>the body mass index, computed by (weight in kg)/(height in m)^2</p>
</dd>
</dl>

<p>A data frame with 45035 rows and 7 columns
</p>


<h3>Source</h3>

<p><a href="https://www.cdc.gov/nchs/nhanes/index.htm">https://www.cdc.gov/nchs/nhanes/index.htm</a>
</p>


<h3>References</h3>

<p>CDC (2012). National Health and Nutrition Examination Survey: Questionnaires, Datasets and Related
Documentation. available <a href="https://www.cdc.gov/nchs/nhanes/index.htm">https://www.cdc.gov/nchs/nhanes/index.htm</a> (date of retrieval: 25/08/2018)
</p>

<hr>
<h2 id='checkConsistency'>Check the consistency of the norm data model</h2><span id='topic+checkConsistency'></span>

<h3>Description</h3>

<p>While abilities increase and decline over age, within one age group, the
norm scores always have to show a linear increase or decrease with increasing raw
scores. Violations of this assumption are a strong indication for problems
in modeling the relationship between raw and norm scores. There are
several reasons, why this might occur:
</p>

<ol>
<li><p> Vertical extrapolation: Choosing extreme norm scores, e. g. values
-3 &lt;= x and x &gt;= 3 In order to model these extreme values, a large sample
dataset is necessary.
</p>
</li>
<li><p> Horizontal extrapolation: Taylor polynomials converge in a certain
radius. Using the model values outside the original dataset may
lead to inconsistent results.
</p>
</li>
<li><p> The data cannot be modeled with Taylor polynomials, or you need
another power parameter (k) or R2 for the model.
</p>
</li></ol>

<p>In general, extrapolation (point 1 and 2) can carefully be done to a
certain degree outside the original sample, but it should in general
be handled with caution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkConsistency(
  model,
  minAge = NULL,
  maxAge = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  minRaw = NULL,
  maxRaw = NULL,
  stepAge = 1,
  stepNorm = 1,
  warn = FALSE,
  silent = FALSE,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkConsistency_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_minage">minAge</code></td>
<td>
<p>Age to start with checking</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_maxage">maxAge</code></td>
<td>
<p>Upper end of the age check</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_minnorm">minNorm</code></td>
<td>
<p>Lower end of the norm value range</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Upper end of the norm value range</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_minraw">minRaw</code></td>
<td>
<p>clipping parameter for the lower bound of raw scores</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_maxraw">maxRaw</code></td>
<td>
<p>clipping parameter for the upper bound of raw scores</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_stepage">stepAge</code></td>
<td>
<p>Stepping parameter for the age check, usually 1 or 0.1; lower
values indicate higher precision / closer checks</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_stepnorm">stepNorm</code></td>
<td>
<p>Stepping parameter for the norm table check within age with lower
scores indicating a higher precision. The choice depends of the norm scale
used. With T scores a stepping parameter of 1 is suitable</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_warn">warn</code></td>
<td>
<p>If set to TRUE, already minor violations of the model assumptions
are displayed (default = FALSE)</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_silent">silent</code></td>
<td>
<p>turn off messages</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Boolean, indicating model violations (TRUE) or no problems (FALSE)
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
modelViolations &lt;- checkConsistency(result,
  minAge = 2, maxAge = 5, stepAge = 0.1,
  minNorm = 25, maxNorm = 75, minRaw = 0, maxRaw = 28, stepNorm = 1
)
plotDerivative(result, minAge = 2, maxAge = 5, minNorm = 25, maxNorm = 75)
</code></pre>

<hr>
<h2 id='checkWeights'>Check, if NA or values &lt;= 0 occur and issue warning</h2><span id='topic+checkWeights'></span>

<h3>Description</h3>

<p>Check, if NA or values &lt;= 0 occur and issue warning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkWeights(weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkWeights_+3A_weights">weights</code></td>
<td>
<p>Raking weights</p>
</td></tr>
</table>

<hr>
<h2 id='cnorm'>Continuous Norming</h2><span id='topic+cnorm'></span>

<h3>Description</h3>

<p>Conducts continuous norming in one step and returns an object including ranked
raw data and the continuous norming model. Please consult the function
description ' of 'rankByGroup', 'rankBySlidingWindow' and 'bestModel' for specifics
of the steps in the data preparation and modeling process. In addition to the
raw scores, either provide
</p>

<ul>
<li><p>a numeric vector for the grouping information (group)
</p>
</li>
<li><p>a numeric age vector and the width of the sliding window (age, width)
</p>
</li></ul>

<p>for the ranking of the raw scores. You can
adjust the grade of smoothing of the regression model by setting the k and terms
parameter. In general, increasing k to more than 4 and the number of terms lead
to a higher fit, while lower values lead to more smoothing. The power parameter
for the age trajectory can be specified independently by 't'. If both parameters
are missing, cnorm uses k = 5 and t = 3 by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm(
  raw = NULL,
  group = NULL,
  age = NULL,
  width = NA,
  weights = NULL,
  scale = "T",
  method = 4,
  descend = FALSE,
  k = NULL,
  t = NULL,
  terms = 0,
  R2 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cnorm_+3A_raw">raw</code></td>
<td>
<p>Numeric vector of raw scores</p>
</td></tr>
<tr><td><code id="cnorm_+3A_group">group</code></td>
<td>
<p>Numeric vector of grouping variable, e. g. grade. If no group
or age variable is provided, conventional norming is applied</p>
</td></tr>
<tr><td><code id="cnorm_+3A_age">age</code></td>
<td>
<p>Numeric vector with chronological age, please additionally specify
width of window</p>
</td></tr>
<tr><td><code id="cnorm_+3A_width">width</code></td>
<td>
<p>Size of the moving window in case an age vector is used</p>
</td></tr>
<tr><td><code id="cnorm_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each
individual case. It can be used to compensate for moderate imbalances due to
insufficient norm data stratification. Weights should be numerical and positive.</p>
</td></tr>
<tr><td><code id="cnorm_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as
well, be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="cnorm_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="cnorm_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="cnorm_+3A_k">k</code></td>
<td>
<p>The power constant. Higher values result in more detailed approximations
but have the danger of over-fit (max = 6). If not set, it uses t and if both
parameters are NULL, k is set to 5.</p>
</td></tr>
<tr><td><code id="cnorm_+3A_t">t</code></td>
<td>
<p>The age power parameter (max = 6). If not set, it uses k and if both
parameters are NULL, k is set to 3, since age trajectories are most often well
captured by cubic polynomials.</p>
</td></tr>
<tr><td><code id="cnorm_+3A_terms">terms</code></td>
<td>
<p>Selection criterion for model building. The best fitting model with
this number of terms is used</p>
</td></tr>
<tr><td><code id="cnorm_+3A_r2">R2</code></td>
<td>
<p>Adjusted R square as a stopping criterion for the model building
(default R2 = 0.99)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cnorm object including the ranked raw data and the regression model
</p>


<h3>References</h3>


<ol>
<li><p> Gary, S. &amp; Lenhard, W. (2021). In norming we trust. Diagnostica.
</p>
</li>
<li><p> Gary, S., Lenhard, W. &amp; Lenhard, A. (2021). Modelling Norm Scores with the cNORM Package in R. Psych, 3(3), 501-521. https://doi.org/10.3390/psych3030033
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Suggate, S. &amp; Segerer, R. (2016). A continuous solution to the norming problem. Assessment, Online first, 1-14. doi:10.1177/1073191116656437
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Gary, S. (2018). Continuous Norming (cNORM). The Comprehensive R Network, Package cNORM, available: https://CRAN.R-project.org/package=cNORM
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Gary, S. (2019). Continuous norming of psychometric tests: A simulation study of parametric and semi-parametric approaches. PLoS ONE, 14(9),  e0222279. doi:10.1371/journal.pone.0222279
</p>
</li>
<li><p> Lenhard, W., &amp; Lenhard, A. (2020). Improvement of Norm Score Quality via Regression-Based Continuous Norming. Educational and Psychological Measurement(Online First), 1-33. https://doi.org/10.1177/0013164420928457
</p>
</li></ol>



<h3>See Also</h3>

<p>rankByGroup, rankBySlidingWindow, computePowers, bestModel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Using this function with the example dataset 'elfe'

# Conventional norming (no modelling over age)
cnorm(raw=elfe$raw)

# Continuous norming
# You can use the 'getGroups()' function to set up grouping variable in case,
# you have a continuous age variable.
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# return norm tables including 90% confidence intervals for a
# test with a reliability of r = .85; table are set to mean of quartal
# in grade 3 (children completed 2 years of schooling)
normTable(c(2.125, 2.375, 2.625, 2.875), cnorm.elfe, CI = .90, reliability = .95)

# ... or instead of raw scores for norm scores, the other way round
rawTable(c(2.125, 2.375, 2.625, 2.875), cnorm.elfe, CI = .90, reliability = .95)


# Using a continuous age variable instead of distinct groups, using a sliding
# window for percentile estimation. Please specify continuos variable for age
# and the sliding window size.
cnorm.ppvt.continuous &lt;- cnorm(raw = ppvt$raw, age = ppvt$age, width=1)


# In case of unbalanced datasets, deviating from the census, the norm data
# can be weighted by the means of raking / post stratification. Please generate
# the weights with the computeWeights() function and pass them as the weights
# parameter. For computing the weights, please specify a data.frame with the
# population margins (further information is available in the computeWeights
# function). A demonstration based on sex and migration status in vocabulary
# development (ppvt dataset):
margins &lt;- data.frame(variables = c("sex", "sex",
                                    "migration", "migration"),
                      levels = c(1, 2, 0, 1),
                      share = c(.52, .48, .7, .3))
weights &lt;- computeWeights(ppvt, margins)
model &lt;- cnorm(raw = ppvt$raw, group=ppvt$group, weights = weights)

## End(Not run)
</code></pre>

<hr>
<h2 id='cnorm.cv'>Cross-validation for Term Selection in cNORM</h2><span id='topic+cnorm.cv'></span>

<h3>Description</h3>

<p>Assists in determining the optimal number of terms for the regression model using repeated Monte Carlo
cross-validation. It leverages an 80-20 split between training and validation data, with stratification by norm group
or random sample in case of using sliding window ranking.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm.cv(
  data,
  formula = NULL,
  repetitions = 5,
  norms = TRUE,
  min = 1,
  max = 12,
  cv = "full",
  pCutoff = NULL,
  width = NA,
  raw = NULL,
  group = NULL,
  age = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cnorm.cv_+3A_data">data</code></td>
<td>
<p>Data frame of norm sample or a cnorm object. Should have ranking, powers, and interaction of L and A.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_formula">formula</code></td>
<td>
<p>Formula from an existing regression model; min/max functions ignored. If using a cnorm object, this is automatically fetched.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_repetitions">repetitions</code></td>
<td>
<p>Number of repetitions for cross-validation.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_norms">norms</code></td>
<td>
<p>If TRUE, computes norm score crossfit and R^2. Note: Computationally intensive.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_min">min</code></td>
<td>
<p>Start with a minimum number of terms (default = 1).</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_max">max</code></td>
<td>
<p>Maximum terms in model, up to (k + 1) * (t + 1) - 1.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_cv">cv</code></td>
<td>
<p>&quot;full&quot; (default) splits data into training/validation, then ranks. Otherwise, expects a pre-ranked dataset.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_pcutoff">pCutoff</code></td>
<td>
<p>Checks stratification for unbalanced data. Performs a t-test per group. Default set to 0.2 to minimize beta error.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_width">width</code></td>
<td>
<p>If provided, ranking done via 'rankBySlidingWindow'. Otherwise, by group.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_raw">raw</code></td>
<td>
<p>Name of the raw score variable.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_group">group</code></td>
<td>
<p>Name of the grouping variable.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_age">age</code></td>
<td>
<p>Name of the age variable.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_weights">weights</code></td>
<td>
<p>Name of the weighting parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Successive models, with an increasing number of terms, are evaluated, and the RMSE for raw scores plotted. This
encompasses the training, validation, and entire dataset. If 'norms' is set to TRUE (default), the function will also
calculate the mean norm score reliability and crossfit measures. Note that due to the computational requirements
of norm score calculations, execution can be slow, especially with numerous repetitions or terms.
</p>
<p>When 'cv' is set to &quot;full&quot; (default), both test and validation datasets are ranked separately, providing comprehensive
cross-validation. For a more streamlined validation process focused only on modeling, a pre-ranked dataset can be used.
The output comprises RMSE for raw score models, norm score R^2, delta R^2, crossfit, and the norm score SE according
to Oosterhuis, van der Ark, &amp; Sijtsma (2016).
</p>
<p>For assessing overfitting:
</p>
<p style="text-align: center;"><code class="reqn">CROSSFIT = R(Training; Model)^2 / R(Validation; Model)^2</code>
</p>

<p>A CROSSFIT &gt; 1 suggests overfitting, &lt; 1 suggests potential underfitting, and values around 1 are optimal,
given a low raw score RMSE and high norm score validation R^2.
</p>
<p>Suggestions for ideal model selection:
</p>

<ul>
<li><p> Visual inspection of percentiles with 'plotPercentiles' or 'plotPercentileSeries'.
</p>
</li>
<li><p> Pair visual inspection with repeated cross-validation (e.g., 10 repetitions).
</p>
</li>
<li><p> Aim for low raw score RMSE and high norm score R^2, avoiding terms with significant overfit (e.g., crossfit &gt; 1.1).
</p>
</li></ul>



<h3>Value</h3>

<p>Table with results per term number: RMSE for raw scores, R^2 for norm scores, and crossfit measure.
</p>


<h3>References</h3>

<p>Oosterhuis, H. E. M., van der Ark, L. A., &amp; Sijtsma, K. (2016). Sample Size Requirements for Traditional
and Regression-Based Norms. Assessment, 23(2), 191â€“202. https://doi.org/10.1177/1073191115580638
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example: Plot cross-validation RMSE by number of terms (up to 9) with three repetitions.
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
cnorm.cv(result$data, min = 2, max = 9, repetitions = 3)

# Using a cnorm object examines the predefined formula.
cnorm.cv(result, repetitions = 1)

# For cross-validation without a cnorm model, rank data first and compute powers:
data &lt;- rankByGroup(data = elfe, raw = "raw", group = "group")
data &lt;- computePowers(data)
cnorm.cv(data)

# Specify formulas deliberately:
data &lt;- rankByGroup(data = elfe, raw = "raw", group = "group")
data &lt;- computePowers(data)
cnorm.cv(data, formula = formula(raw ~ L3 + L1A1 + L3A3 + L4 + L5))

## End(Not run)

</code></pre>

<hr>
<h2 id='cNORM.GUI'>Launcher for the graphical user interface of cNORM</h2><span id='topic+cNORM.GUI'></span>

<h3>Description</h3>

<p>Launcher for the graphical user interface of cNORM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cNORM.GUI(launch.browser = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cNORM.GUI_+3A_launch.browser">launch.browser</code></td>
<td>
<p>Default TRUE; automatically open browser for GUI</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Launch graphical user interface
cNORM.GUI()

## End(Not run)
</code></pre>

<hr>
<h2 id='computePowers'>Compute powers of the explanatory variable a as well as of the person
location l (data preparation)</h2><span id='topic+computePowers'></span>

<h3>Description</h3>

<p>The function computes powers of the norm variable e. g. T scores (location, L),
an explanatory variable, e. g. age or grade of a data frame (age, A) and the
interactions of both (L X A). The k variable indicates the degree up to which
powers and interactions are build. These predictors can be used later on in the
<code><a href="#topic+bestModel">bestModel</a></code> function to model the norm sample. Higher values of k
allow for modeling the norm sample closer, but might lead to over-fit. In general
k = 3 or k = 4 (default) is sufficient to model human performance data. For example,
k = 2 results in the variables L1, L2, A1, A2, and their interactions L1A1, L2A1, L1A2
and L2A2 (but k = 2 is usually not sufficient for the modeling). Please note, that
you do not need to use a normal rank transformed scale like T r IQ, but you can
as well use the percentiles for the 'normValue' as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computePowers(
  data,
  k = 5,
  norm = NULL,
  age = NULL,
  t = 3,
  covariate = NULL,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computePowers_+3A_data">data</code></td>
<td>
<p>data.frame with the norm data</p>
</td></tr>
<tr><td><code id="computePowers_+3A_k">k</code></td>
<td>
<p>degree</p>
</td></tr>
<tr><td><code id="computePowers_+3A_norm">norm</code></td>
<td>
<p>the variable containing the norm data in the data.frame; might be
T scores, IQ scores, percentiles ...</p>
</td></tr>
<tr><td><code id="computePowers_+3A_age">age</code></td>
<td>
<p>Explanatory variable like age or grade, which was as well used for the grouping.
Can be either the grouping variable itself or a finer grained variable like the exact age. Other
explanatory variables can be used here instead an age variable as well, as long as the variable is
at least ordered metric, e. g. language or development levels ... The label 'age' is used, as this is the
most common field of application.</p>
</td></tr>
<tr><td><code id="computePowers_+3A_t">t</code></td>
<td>
<p>the age power parameter (default NULL). If not set, cNORM automatically uses k. The age power parameter
can be used to specify the k to produce rectangular matrices and specify the course of scores per independently from k</p>
</td></tr>
<tr><td><code id="computePowers_+3A_covariate">covariate</code></td>
<td>
<p>Include a binary covariate into the preparation and subsequently modeling,
either by specifying the variable name or including the variable itself. If this has already
been done in the ranking, the function uses the according variable. BEWARE!
Not all subsequent functions are already prepared for it. It is an experimental feature and
may lead to unstable models subsequently.</p>
</td></tr>
<tr><td><code id="computePowers_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with the powers and interactions of location and explanatory variable / age
</p>


<h3>See Also</h3>

<p>bestModel
</p>
<p>Other prepare: 
<code><a href="#topic+prepareData">prepareData</a>()</code>,
<code><a href="#topic+rankByGroup">rankByGroup</a>()</code>,
<code><a href="#topic+rankBySlidingWindow">rankBySlidingWindow</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Dataset with grade levels as grouping
data.elfe &lt;- rankByGroup(elfe)
data.elfe &lt;- computePowers(data.elfe)

# Dataset with continuous age variable and k = 5
data.ppvt &lt;- rankByGroup(ppvt)
data.ppvt &lt;- computePowers(data.ppvt, age = "age", k = 5)
</code></pre>

<hr>
<h2 id='computeWeights'>Weighting of cases through iterative proportional fitting (Raking)</h2><span id='topic+computeWeights'></span>

<h3>Description</h3>

<p>Computes and standardizes weights via raking to compensate for non-stratified
samples. It is based on the implementation in the survey R package. It reduces
data collection #' biases in the norm data by the means of post stratification,
thus reducing the effect of unbalanced data in percentile estimation and norm
data modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeWeights(data, population.margins, standardized = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeWeights_+3A_data">data</code></td>
<td>
<p>data.frame with norm sample data.</p>
</td></tr>
<tr><td><code id="computeWeights_+3A_population.margins">population.margins</code></td>
<td>
<p>A data.frame including three columns, specifying the
variable name in the original dataset used for data stratification, the factor
level of the variable and the according population share. Please ensure, the
original data does not include factor levels, not present in the
population.margins. Additionally, summing up the shares of the different
levels of a variable should result in a value near 1.0. The first column must
specify the name of the stratification variable, the second the level and
the third the proportion</p>
</td></tr>
<tr><td><code id="computeWeights_+3A_standardized">standardized</code></td>
<td>
<p>If TRUE (default), the raking weights are scaled to
weights/min(weights)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes standardized raking weights to overcome biases in norm
samples. It generates weights, by drawing on the information of population
shares (e. g. for sex, ethnic group, region ...) and subsequently reduces the
influence of over-represented groups or increases underrepresented cases. The
returned weights are either raw or standardized and scaled to be larger than 0.
</p>
<p>Raking in general has a number of advantages over post stratification and it
additionally allows cNORM to draw on larger datasets, since less cases have
to be removed during stratification. To use this function, additionally to the
data, a data frame with stratification variables has to be specified. The data
frame should include a row with (a) the variable name, (b) the level of the
variable and (c) the according population proportion.
</p>


<h3>Value</h3>

<p>a vector with the standardized weights
</p>


<h3>Examples</h3>

<pre><code class='language-R'># cNORM features a dataset on vocabulary development (ppvt)
# that includes variables like sex or migration. In order
# to weight the data, we have to specify the population shares.
# According to census, the population includes 52% boys
# (factor level 1 in the ppvt dataset) and 70% / 30% of persons
# without / with a a history of migration (= 0 / 1 in the dataset).
# First we set up the popolation margins with all shares of the
# different levels:

margins &lt;- data.frame(variables = c("sex", "sex",
                                    "migration", "migration"),
                      levels = c(1, 2, 0, 1),
                      share = c(.52, .48, .7, .3))
head(margins)

# Now we use the population margins to generate weights
# through raking

weights &lt;- computeWeights(ppvt, margins)


# There are as many different weights as combinations of
# factor levels, thus only four in this specific case

unique(weights)


# To include the weights in the cNORM modelling, we have
# to pass them as weights. They are then used to set up
# weighted quantiles and as weights in the regession.

model &lt;- cnorm(raw = ppvt$raw,
               group=ppvt$group,
               weights = weights)
</code></pre>

<hr>
<h2 id='derivationTable'>Create a table based on first order derivative of the regression model for specific age</h2><span id='topic+derivationTable'></span>

<h3>Description</h3>

<p>In order to check model assumptions, a table of the first order derivative of the model
coefficients is created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derivationTable(
  A,
  model,
  minNorm = NULL,
  maxNorm = NULL,
  step = 0.1,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="derivationTable_+3A_a">A</code></td>
<td>
<p>the age</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower bound of the norm value range</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper bound of the norm value range</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_step">step</code></td>
<td>
<p>Stepping parameter with lower values indicating higher precision</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with norm scores and the predicted scores based on the
derived regression function
</p>


<h3>See Also</h3>

<p>plotDerivative, derive
</p>
<p>Other predict: 
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# retrieve function for time point 6
d &lt;- derivationTable(6, cnorm.elfe, step = 0.5)

</code></pre>

<hr>
<h2 id='derive'>Derivative of regression model</h2><span id='topic+derive'></span>

<h3>Description</h3>

<p>Calculates the derivative of the location / norm value from the regression model with the first
derivative as the default. This is useful for finding violations of model assumptions and problematic
distribution features as f. e. bottom and ceiling effects, non-progressive norm scores within an
age group or in general #' intersecting percentile curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derive(model, order = 1, covariate = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="derive_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="derive_+3A_order">order</code></td>
<td>
<p>The degree of the derivate, default: 1</p>
</td></tr>
<tr><td><code id="derive_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The derived coefficients
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>normData &lt;- prepareData(elfe)
m &lt;- bestModel(normData)
derivedCoefficients &lt;- derive(m)
</code></pre>

<hr>
<h2 id='elfe'>Sentence completion test from ELFE 1-6</h2><span id='topic+elfe'></span>

<h3>Description</h3>

<p>A dataset containing the raw data of 1400 students from grade 2 to 5 in the sentence
comprehension test from ELFE 1-6 (Lenhard &amp; Schneider, 2006). In this test, students
are presented lists of sentences with one gap. The student has to fill in the correct
solution by selecting from a list of 5 alternatives per sentence. The alternatives
include verbs, adjectives, nouns, pronouns and conjunctives. Each item stems from
the same word type. The text is speeded, with a time cutoff of 180 seconds. The
variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elfe
</code></pre>


<h3>Format</h3>

<p>A data frame with 1400 rows and 3 variables:
</p>

<dl>
<dt>personID</dt><dd><p>ID of the student</p>
</dd>
<dt>group</dt><dd><p>grade level, with x.5 indicating the end of the school year and x.0 indicating the middle of the school year</p>
</dd>
<dt>raw</dt><dd><p>the raw score of the student, spanning values from 0 to 28</p>
</dd>
</dl>

<p>A data frame with 1400 rows and 3 columns
</p>


<h3>Source</h3>

<p><a href="https://www.psychometrica.de/elfe2.html">https://www.psychometrica.de/elfe2.html</a>
</p>


<h3>References</h3>

<p>Lenhard, W. &amp; Schneider, W.(2006). Ein Leseverstaendnistest fuer Erst- bis Sechstklaesser. Goettingen/Germany: Hogrefe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># prepare data, retrieve model and plot percentiles
data.elfe &lt;- prepareData(elfe)
model.elfe &lt;- bestModel(data.elfe)
plotPercentiles(data.elfe, model.elfe)
</code></pre>

<hr>
<h2 id='epm'>Simulated dataset (Educational and Psychological Measurement, EPM)</h2><span id='topic+epm'></span>

<h3>Description</h3>

<p>A simulated dataset, based on the the simRasch function. The data were generated on the basis of a 1PL IRT model with
50 items with a normal distribution and a mean difficulty of m = 0 and sd = 1 and 1400 cases. The age trajectory features a curve
linear increase wit a slight scissor effect. The sample consists of seven age groups with 200 cases each and it includes
information on the latent ability, the age specific latent ability and norm scores based on conventional norming with
differing granularity of the age brackets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epm
</code></pre>


<h3>Format</h3>

<p>A data frame with 1400 rows and 10 variables:
</p>

<dl>
<dt>raw</dt><dd><p>the raw score</p>
</dd>
<dt>ageSpecificZ</dt><dd><p>the age specific latent ability, z standardized</p>
</dd>
<dt>latentTrait</dt><dd><p>the overall latent trait with respect to the population model</p>
</dd>
<dt>age</dt><dd><p>the chronological age</p>
</dd>
<dt>halfYearGroup</dt><dd><p>grouping variable based on six month age brackets</p>
</dd>
<dt>spcnT</dt><dd><p>Resulting norm score of cNORM, based on the automatic model selection</p>
</dd>
<dt>T1</dt><dd><p>conventional T scores on the basis of one month age brackets</p>
</dd>
<dt>T3</dt><dd><p>conventional T scores on the basis of three month age brackets</p>
</dd>
<dt>T6</dt><dd><p>conventional T scores on the basis of six month age brackets</p>
</dd>
<dt>T12</dt><dd><p>conventional T scores on the basis of one year age brackets</p>
</dd>
</dl>

<p>A data frame with 1400 rows and 10 columns
</p>


<h3>Source</h3>

<p><a href="https://osf.io/ntydc/">https://osf.io/ntydc/</a>
</p>


<h3>References</h3>

<p>Lenhard, W. &amp; Lenhard, A. (2020). Improvement of Norm Score Quality via Regression-Based Continuous Norming. Educational and Psychological Measurement. https://doi.org/10.1177/0013164420928457
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example with continuous age variable
data.epm &lt;- prepareData(epm, raw=epm$raw, group=epm$halfYearGroup, age=epm$age)
model.epm &lt;- bestModel(data.epm)

## End(Not run)
</code></pre>

<hr>
<h2 id='getGroups'>Determine groups and group means</h2><span id='topic+getGroups'></span>

<h3>Description</h3>

<p>Helps to split the continuous explanatory variable into groups and assigns
the group mean. The groups can be split either into groups of equal size (default)
or equal number of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getGroups(x, n = NULL, equidistant = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getGroups_+3A_x">x</code></td>
<td>
<p>The continuous variable to be split</p>
</td></tr>
<tr><td><code id="getGroups_+3A_n">n</code></td>
<td>
<p>The number of groups; if NULL then the function determines a number
of groups with usually 100 cases or 3 &lt;= n &lt;= 20.</p>
</td></tr>
<tr><td><code id="getGroups_+3A_equidistant">equidistant</code></td>
<td>
<p>If set to TRUE, builds equidistant interval, otherwise (default)
with equal number of observations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with group means for each observation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1000, m = 50, sd = 10)
m &lt;- getGroups(x, n = 10)

</code></pre>

<hr>
<h2 id='getNormCurve'>Computes the curve for a specific T value</h2><span id='topic+getNormCurve'></span>

<h3>Description</h3>

<p>As with this continuous norming regression approach, raw scores are modeled as a function of age and norm score
(location), getNormCurve is a straightforward approach to show the raw score development over
age, while keeping the norm value constant. This way, e. g. academic performance or intelligence development
of a specific ability is shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNormCurve(
  norm,
  model,
  minAge = NULL,
  maxAge = NULL,
  step = 0.1,
  minRaw = NULL,
  maxRaw = NULL,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getNormCurve_+3A_norm">norm</code></td>
<td>
<p>The specific norm score, e. g. T value</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_model">model</code></td>
<td>
<p>The model from the regression modeling or a cnorm object</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_minage">minAge</code></td>
<td>
<p>Age to start from</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_maxage">maxAge</code></td>
<td>
<p>Age to stop at</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_step">step</code></td>
<td>
<p>Stepping parameter for the precision when retrieving of the values, lower
values indicate higher precision (default 0.1).</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_minraw">minRaw</code></td>
<td>
<p>lower bound of the range of raw scores (default = 0)</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_maxraw">maxRaw</code></td>
<td>
<p>upper bound of raw scores</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate or
the specific value here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame of the variables raw, age and norm
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)
getNormCurve(35, cnorm.elfe)
</code></pre>

<hr>
<h2 id='getNormScoreSE'>Calculates the standard error (SE) or root mean square error (RMSE) of the norm scores
In case of large datasets, both results should be almost identical</h2><span id='topic+getNormScoreSE'></span>

<h3>Description</h3>

<p>Calculates the standard error (SE) or root mean square error (RMSE) of the norm scores
In case of large datasets, both results should be almost identical
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNormScoreSE(model, type = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getNormScoreSE_+3A_model">model</code></td>
<td>
<p>a cnorm object</p>
</td></tr>
<tr><td><code id="getNormScoreSE_+3A_type">type</code></td>
<td>
<p>either '1' for the standard error senso Oosterhuis et al. (2016) or '2' for
the RMSE (default)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standard error (SE) of the norm scores sensu Oosterhuis et al. (2016) or the RMSE
</p>


<h3>References</h3>

<p>Oosterhuis, H. E. M., van der Ark, L. A., &amp; Sijtsma, K. (2016). Sample Size Requirements for Traditional and Regression-Based Norms. Assessment, 23(2), 191â€“202. https://doi.org/10.1177/1073191115580638
</p>

<hr>
<h2 id='life'>Life expectancy at birth from 1960 to 2017</h2><span id='topic+life'></span>

<h3>Description</h3>

<p>The data is available by the courtesy of the World Bank under Creative Commons Attribution 4.0 (CC-BY 4.0).
It includes the life expectancy at birth on nation level from 1960 to 2017. The data has been converted to
long data format, aggregates for groups of nations and missings have been deleted and a grouping variable
with a broader scope spanning 4 years each has been added. It shows, that it can be better to reduce
predictors. The model does not converge anymore after using 8 predictors and the optimal solution is
achieved with four predictors, equaling R2=.9825.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>life
</code></pre>


<h3>Format</h3>

<p>A data frame with 11182 rows and 4 variables:
</p>

<dl>
<dt>Country</dt><dd><p>The name of the country</p>
</dd>
<dt>year</dt><dd><p>reference year of data collection</p>
</dd>
<dt>life</dt><dd><p>the life expectancy at birth</p>
</dd>
<dt>group</dt><dd><p>a grouping variable based on 'year' but with a lower resolution; spans intervals of 4 years each</p>
</dd>
</dl>

<p>A data frame with 11182 rows and 4 columns
</p>


<h3>Source</h3>

<p><a href="https://data.worldbank.org/indicator/sp.dyn.le00.in">https://data.worldbank.org/indicator/sp.dyn.le00.in</a>
</p>


<h3>References</h3>

<p>The World Bank (2018). Life expectancy at birth, total (years). Data Source	World Development Indicators
available <a href="https://data.worldbank.org/indicator/sp.dyn.le00.in">https://data.worldbank.org/indicator/sp.dyn.le00.in</a> (date of retrieval: 01/09/2018)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# data preparation
data.life &lt;- rankByGroup(life, raw="life")
data.life &lt;- computePowers(data.life, age="year")

#determining best suiting model by plotting series
model.life &lt;- bestModel(data.life, raw="life")
plotPercentileSeries(data.life, model.life, end=10)

# model with four predictors seems to work best
model2.life &lt;- bestModel(data.life, raw="life", terms=4)

## End(Not run)
</code></pre>

<hr>
<h2 id='modelSummary'>Prints the results and regression function of a cnorm model</h2><span id='topic+modelSummary'></span>

<h3>Description</h3>

<p>Prints the results and regression function of a cnorm model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelSummary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelSummary_+3A_object">object</code></td>
<td>
<p>A regression model or cnorm object</p>
</td></tr>
<tr><td><code id="modelSummary_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A report on the regression function, weights, R2 and RMSE
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>

<hr>
<h2 id='mortality'>Mortality of infants per 1000 life birth from 1960 to 2017</h2><span id='topic+mortality'></span>

<h3>Description</h3>

<p>The data is available by the courtesy of the World Bank under Creative Commons Attribution 4.0 (CC-BY 4.0).
It includes the mortality rate of life birth per country from 1960 to 2017. The data has been converted to
long data format, aggregates for groups of nations and missings have been deleted and a grouping variable
with a broader scope spanning 4 years each has been added. It can be used for demonstrating intersecting
percentile curves at bottom effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mortality
</code></pre>


<h3>Format</h3>

<p>A data frame with 9547 rows and 4 variables:
</p>

<dl>
<dt>Country</dt><dd><p>The name of the country</p>
</dd>
<dt>year</dt><dd><p>reference year of data collection</p>
</dd>
<dt>mortality</dt><dd><p>the mortality per 1000 life born children</p>
</dd>
<dt>group</dt><dd><p>grouping variable based on 'year' with a lower resolution; spans intervals of 4 years each</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://data.worldbank.org/indicator/SP.DYN.IMRT.IN">https://data.worldbank.org/indicator/SP.DYN.IMRT.IN</a>
</p>


<h3>References</h3>

<p>The World Bank (2018). Mortality rate, infant (per 1,000 live births). Data Source	available
<a href="https://data.worldbank.org/indicator/SP.DYN.IMRT.IN">https://data.worldbank.org/indicator/SP.DYN.IMRT.IN</a> (date of retrieval: 02/09/2018)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data preparation
data.mortality &lt;- rankByGroup(mortality, raw="mortality")
data.mortality &lt;- computePowers(data.mortality, age="year")

# modeling
model.mortality &lt;- bestModel(data.mortality, raw="mortality")
plotSubset(model.mortality, type = 0)
plotPercentileSeries(data.mortality, model.mortality, end=9, percentiles = c(.1, .25, .5, .75, .9))

</code></pre>

<hr>
<h2 id='normTable'>Create a norm table based on model for specific age</h2><span id='topic+normTable'></span>

<h3>Description</h3>

<p>This function generates a norm table for a specific age based on the regression
model by assigning raw scores to norm scores. Please specify the
range of norm scores, you want to cover. A T value of 25 corresponds to a percentile
of .6. As a consequence, specifying a range of T = 25 to T = 75 would cover 98.4 
the population. Please be careful when extrapolating vertically (at the lower and
upper end of the age specific distribution). Depending on the size of your standardization
sample, extreme values with T &lt; 20 or T &gt; 80 might lead to inconsistent results.
In case a confidence coefficient (CI, default .9) and the reliability is specified,
confidence intervals are computed for the true score estimates, including a correction for
regression to the mean (Eid &amp; Schmidt, 2012, p. 272).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normTable(
  A,
  model,
  minNorm = NULL,
  maxNorm = NULL,
  minRaw = NULL,
  maxRaw = NULL,
  step = NULL,
  covariate = NULL,
  monotonuous = TRUE,
  CI = 0.9,
  reliability = NULL,
  pretty = T
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normTable_+3A_a">A</code></td>
<td>
<p>the age as single value or a vector of age values</p>
</td></tr>
<tr><td><code id="normTable_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="normTable_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower bound of the norm score range</p>
</td></tr>
<tr><td><code id="normTable_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper bound of the norm score range</p>
</td></tr>
<tr><td><code id="normTable_+3A_minraw">minRaw</code></td>
<td>
<p>clipping parameter for the lower bound of raw scores</p>
</td></tr>
<tr><td><code id="normTable_+3A_maxraw">maxRaw</code></td>
<td>
<p>clipping parameter for the upper bound of raw scores</p>
</td></tr>
<tr><td><code id="normTable_+3A_step">step</code></td>
<td>
<p>Stepping parameter with lower values indicating higher precision</p>
</td></tr>
<tr><td><code id="normTable_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
<tr><td><code id="normTable_+3A_monotonuous">monotonuous</code></td>
<td>
<p>corrects for decreasing norm scores in case of model inconsistencies (default)</p>
</td></tr>
<tr><td><code id="normTable_+3A_ci">CI</code></td>
<td>
<p>confidence coefficient, ranging from 0 to 1, default .9</p>
</td></tr>
<tr><td><code id="normTable_+3A_reliability">reliability</code></td>
<td>
<p>coefficient, ranging between  0 to 1</p>
</td></tr>
<tr><td><code id="normTable_+3A_pretty">pretty</code></td>
<td>
<p>Format table by collapsing intervals and rounding to meaningful precision</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either data.frame with norm scores, predicted raw scores and percentiles in case of simple A
value or a list #' of norm tables if vector of A values was provided
</p>


<h3>References</h3>

<p>Eid, M. &amp; Schmidt, K. (2012). Testtheorie und Testkonstruktion. Hogrefe.
</p>


<h3>See Also</h3>

<p>rawTable
</p>
<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# create single norm table
norms &lt;- normTable(3.5, cnorm.elfe, minNorm = 25, maxNorm = 75, step = 0.5)

# create list of norm tables
norms &lt;- normTable(c(2.5, 3.5, 4.5), cnorm.elfe,
  minNorm = 25, maxNorm = 75,
  step = 1, minRaw = 0, maxRaw = 26
)
</code></pre>

<hr>
<h2 id='plot.cnorm'>S3 function for plotting cnorm objects</h2><span id='topic+plot.cnorm'></span>

<h3>Description</h3>

<p>S3 function for plotting cnorm objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnorm'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cnorm_+3A_x">x</code></td>
<td>
<p>the cnorm object</p>
</td></tr>
<tr><td><code id="plot.cnorm_+3A_y">y</code></td>
<td>
<p>the type of plot as a string, can be one of
'raw' (1), 'norm' (2), 'curves' (3), 'percentiles' (4), 'series' (5), 'subset' (6),
or 'derivative' (7), either as a string or the according index</p>
</td></tr>
<tr><td><code id="plot.cnorm_+3A_...">...</code></td>
<td>
<p>additional parameters for the specific plotting function</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>

<hr>
<h2 id='plotCnorm'>General convencience plotting function</h2><span id='topic+plotCnorm'></span>

<h3>Description</h3>

<p>General convencience plotting function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCnorm(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotCnorm_+3A_x">x</code></td>
<td>
<p>a cnorm object</p>
</td></tr>
<tr><td><code id="plotCnorm_+3A_y">y</code></td>
<td>
<p>the type of plot as a string, can be one of
'raw' (1), 'norm' (2), 'curves' (3), 'percentiles' (4), 'series' (5), 'subset' (6),
or 'derivative' (7), either as a string or the according index</p>
</td></tr>
<tr><td><code id="plotCnorm_+3A_...">...</code></td>
<td>
<p>additional parameters for the specific plotting function</p>
</td></tr>
</table>

<hr>
<h2 id='plotDensity'>Plot the density function per group by raw score</h2><span id='topic+plotDensity'></span>

<h3>Description</h3>

<p>The function plots the density  curves based on the regression model against
the actual percentiles from the raw data. As in 'plotNormCurves',
please check for inconsistent curves, especially curves showing implausible shapes as f. e.
violations of biuniqueness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDensity(
  model,
  minRaw = NULL,
  maxRaw = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  group = NULL,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDensity_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_minraw">minRaw</code></td>
<td>
<p>Lower bound of the raw score</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_maxraw">maxRaw</code></td>
<td>
<p>Upper bound of the raw score</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_minnorm">minNorm</code></td>
<td>
<p>Lower bound of the norm score</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Upper bound of the norm score</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_group">group</code></td>
<td>
<p>Column of groups to plot</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>plotNormCurves, plotPercentiles
</p>
<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results for age values 2, 4 and 6
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotDensity(result, group = c (2, 4, 6))
</code></pre>

<hr>
<h2 id='plotDerivative'>Plot first order derivative of regression model</h2><span id='topic+plotDerivative'></span>

<h3>Description</h3>

<p>Plots the scores obtained via the first order derivative of the regression model
in dependence of the norm score. The results indicate the progression of the
norm scores within each age group. The regression based modeling approach
relies on the assumption of a linear progression of the norm scores.
Negative scores in the first order derivative indicate a violation of this
assumption. Scores near zero are typical for bottom and ceiling effects in the raw data.
The regression models usually converge within the range of the original
values. In case of vertical and horizontal extrapolation, with increasing
distance to the original data, the risk of assumption violation increases
as well.
ATTENTION: plotDerivative is currently still incompatible with reversed raw
score scales ('descent' option)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDerivative(
  model,
  minAge = NULL,
  maxAge = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  stepAge = 0.2,
  stepNorm = 1,
  order = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDerivative_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_minage">minAge</code></td>
<td>
<p>Age to start with checking</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_maxage">maxAge</code></td>
<td>
<p>Upper end of the age check</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_minnorm">minNorm</code></td>
<td>
<p>Lower end of the norm score range, in case of T scores, 25 might be good</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Upper end of the norm score range, in case of T scores, 25 might be good</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_stepage">stepAge</code></td>
<td>
<p>Stepping parameter for the age check, usually 1 or 0.1; lower
values indicate higher precision / closer checks</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_stepnorm">stepNorm</code></td>
<td>
<p>Stepping parameter for norm scores</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_order">order</code></td>
<td>
<p>Degree of the derivative (default = 1)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>checkConsistency, bestModel, derive
</p>
<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotDerivative(result, minAge=2, maxAge=5, step=.2, minNorm=25, maxNorm=75, stepNorm=1)
</code></pre>

<hr>
<h2 id='plotNorm'>Plot manifest and fitted norm scores</h2><span id='topic+plotNorm'></span>

<h3>Description</h3>

<p>The function plots the manifest norm score against the fitted norm score from
the inverse regression model per group. This helps to inspect the precision
of the modeling process. The scores should not deviate too far from
regression line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNorm(data, model, group = "", minNorm = NULL, maxNorm = NULL, type = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotNorm_+3A_data">data</code></td>
<td>
<p>The raw data within a data.frame or a cnorm object</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_model">model</code></td>
<td>
<p>The regression model (optional)</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_group">group</code></td>
<td>
<p>The grouping variable, use empty string for no group</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_minnorm">minNorm</code></td>
<td>
<p>lower bound of fitted norm scores</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_maxnorm">maxNorm</code></td>
<td>
<p>upper bound of fitted norm scores</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_type">type</code></td>
<td>
<p>Type of display: 0 = plot manifest against fitted values, 1 = plot
manifest against difference values</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
## Not run: 
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotNorm(result, group="group", minNorm=25, maxNorm=75)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotNormCurves'>Plot norm curves</h2><span id='topic+plotNormCurves'></span>

<h3>Description</h3>

<p>The function plots the norm curves based on the regression model.
Please check the function for inconsistent curves: The different
curves should not intersect. Violations of this assumption are a strong
indication for violations of model assumptions in modeling the relationship between raw
and norm scores. There are several reasons, why this might occur:
</p>

<ol>
<li><p> Vertical extrapolation: Choosing extreme norm scores, e. g. scores
-3 &lt;= x and x &gt;= 3 In order to model these extreme scores, a large sample
dataset is necessary.
</p>
</li>
<li><p> Horizontal extrapolation: Taylor polynomials converge in a certain
radius. Using the model scores outside the original dataset may
lead to inconsistent results.
</p>
</li>
<li><p> The data cannot be modeled with Taylor polynomials, or you need
another power parameter (k) or R2 for the model.
</p>
</li></ol>

<p>In general, extrapolation (point 1 and 2) can carefully be done to a
certain degree outside the original sample, but it should in general
be handled with caution.
checkConsistency and derivationPlot can be used to further inspect the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNormCurves(
  model,
  normList = NULL,
  minAge = NULL,
  maxAge = NULL,
  step = 0.1,
  minRaw = NULL,
  maxRaw = NULL,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotNormCurves_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_normlist">normList</code></td>
<td>
<p>Vector with norm scores to display</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_minage">minAge</code></td>
<td>
<p>Age to start with checking</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_maxage">maxAge</code></td>
<td>
<p>Upper end of the age check</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_step">step</code></td>
<td>
<p>Stepping parameter for the age check, usually 1 or 0.1; lower
scores indicate higher precision / closer checks</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_minraw">minRaw</code></td>
<td>
<p>Lower end of the raw score range, used for clipping implausible results
(default = 0)</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_maxraw">maxRaw</code></td>
<td>
<p>Upper end of the raw score range, used for clipping implausible results</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>checkConsistency, derivationPlot, plotPercentiles
</p>
<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
normData &lt;- prepareData(elfe)
m &lt;- bestModel(data = normData)
plotNormCurves(m, minAge=2, maxAge=5)
</code></pre>

<hr>
<h2 id='plotPercentiles'>Plot norm curves against actual percentiles</h2><span id='topic+plotPercentiles'></span>

<h3>Description</h3>

<p>The function plots the norm curves based on the regression model against
the actual percentiles from the raw data. As in 'plotNormCurves',
please check for inconsistent curves, especially intersections.
Violations of this assumption are a strong
indication for problems
in modeling the relationship between raw and norm scores.
In general, extrapolation (point 1 and 2) can carefully be done to a
certain degree outside the original sample, but it should in general
be handled with caution.
The original percentiles are displayed as distinct points in the according
color, the model based projection of percentiles are drawn as lines.
Please note, that the estimation of the percentiles of the raw data is done with
the quantile function with the default settings. Please consult help(quantile)
and change the 'type' parameter accordingly.
In case, you get 'jagged' or disorganized percentile curve, try to reduce the 'k'
parameter in modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPercentiles(
  data,
  model,
  minRaw = NULL,
  maxRaw = NULL,
  minAge = NULL,
  maxAge = NULL,
  raw = NULL,
  group = NULL,
  percentiles = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
  scale = NULL,
  type = 7,
  title = NULL,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotPercentiles_+3A_data">data</code></td>
<td>
<p>The raw data including the percentiles and norm scores or a cnorm object</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function (optional)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_minraw">minRaw</code></td>
<td>
<p>Lower bound of the raw score (default = 0)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_maxraw">maxRaw</code></td>
<td>
<p>Upper bound of the raw score</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_minage">minAge</code></td>
<td>
<p>Variable to restrict the lower bound of the plot to a specific age</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_maxage">maxAge</code></td>
<td>
<p>Variable to restrict the upper bound of the plot to a specific age</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_raw">raw</code></td>
<td>
<p>The name of the raw variable</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_group">group</code></td>
<td>
<p>The name of the grouping variable; the distinct groups are automatically
determined</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_percentiles">percentiles</code></td>
<td>
<p>Vector with percentile scores, ranging from 0 to 1 (exclusive)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_scale">scale</code></td>
<td>
<p>The norm scale, either 'T', 'IQ', 'z', 'percentile' or
self defined with a double vector with the mean and standard deviation,
f. e. c(10, 3) for Wechsler scale index points; if NULL, scale information from the
data preparation is used (default)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_type">type</code></td>
<td>
<p>The type parameter of the quantile function to estimate the percentiles
of the raw data (default 7)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_title">title</code></td>
<td>
<p>custom title for plot</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here. If no covariate is specified, both degrees will be plotted.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>plotNormCurves, plotPercentileSeries
</p>
<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotPercentiles(result)
</code></pre>

<hr>
<h2 id='plotPercentileSeries'>Generates a series of plots with number curves by percentile for different models</h2><span id='topic+plotPercentileSeries'></span>

<h3>Description</h3>

<p>This functions makes use of 'plotPercentiles' to generate a series of plots
with different number of predictors. It draws on the information provided by the model object
to determine the bounds of the modeling (age and standard score range). It can be used as an
additional model check to determine the best fitting model. Please have a look at the
' plotPercentiles' function for further information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPercentileSeries(
  data,
  model,
  start = 1,
  end = NULL,
  group = NULL,
  percentiles = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
  type = 7,
  filename = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotPercentileSeries_+3A_data">data</code></td>
<td>
<p>The raw data including the percentiles and norm scores or a cnorm object</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function (optional)</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_start">start</code></td>
<td>
<p>Number of predictors to start with</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_end">end</code></td>
<td>
<p>Number of predictors to end with</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_group">group</code></td>
<td>
<p>The name of the grouping variable; the distinct groups are automatically
determined</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_percentiles">percentiles</code></td>
<td>
<p>Vector with percentile scores, ranging from 0 to 1 (exclusive)</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_type">type</code></td>
<td>
<p>The type parameter of the quantile function to estimate the percentiles
of the raw data (default 7)</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_filename">filename</code></td>
<td>
<p>Prefix of the filename. If specified, the plots are saves as
png files in the directory of the workspace, instead of displaying them</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the complete list of plots
</p>


<h3>See Also</h3>

<p>plotPercentiles
</p>
<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotPercentileSeries(result, start=1, end=5, group="group")
</code></pre>

<hr>
<h2 id='plotRaw'>Plot manifest and fitted raw scores</h2><span id='topic+plotRaw'></span>

<h3>Description</h3>

<p>The function plots the raw data against the fitted scores from
the regression model per group. This helps to inspect the precision
of the modeling process. The scores should not deviate too far from
regression line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRaw(data, model, group = NULL, raw = NULL, type = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotRaw_+3A_data">data</code></td>
<td>
<p>The raw data within a data.frame or cnorm object</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_model">model</code></td>
<td>
<p>The regression model (optional)</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_group">group</code></td>
<td>
<p>The grouping variable</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_raw">raw</code></td>
<td>
<p>The raw score variable</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_type">type</code></td>
<td>
<p>Type of display: 0 = plot manifest against fitted values, 1 = plot
manifest against difference values</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute model with example dataset and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotRaw(result)
</code></pre>

<hr>
<h2 id='plotSubset'>Evaluate information criteria for regression model</h2><span id='topic+plotSubset'></span>

<h3>Description</h3>

<p>Plots the information criterion - either Cp (default) or BIC - against
the adjusted R square of the feature selection in the modeling process.
Both BIC and Mallow's Cp are measures to avoid over-fitting. Please
choose the model that has a high information criterion, while modeling
the original data as close as possible. R2 adjusted values of ~ .99 might
work well, depending on your scenario. In other words: Look out for the
elbow in the curve and choose th model where the information criterion
begins to drop. Nonetheless, inspect the according model with <code>plotPercentiles(data, group)</code>
to visually inspect the course of the percentiles.
In the plot, Mallow's Cp is log transformed and the BIC is always highly
negative. The R2 cutoff that was specified in the bestModel function is
displayed as a dashed line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSubset(model, type = 0, index = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotSubset_+3A_model">model</code></td>
<td>
<p>The regression model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="plotSubset_+3A_type">type</code></td>
<td>
<p>Type of chart with 0 = adjusted R2 by number of predictors,
1 = log transformed Mallow's Cp by adjusted R2, 2 = Bayesian Information
Criterion (BIC) by adjusted R2, 3 = Root Mean Square Error (RMSE),
4 = Residual Sum of Squares by number, 5 = F-test statistic for consecutive models
and 6 = p-value for model tests
of predictors</p>
</td></tr>
<tr><td><code id="plotSubset_+3A_index">index</code></td>
<td>
<p>add index labels to data points</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>bestModel, plotPercentiles, printSubset
</p>
<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute model with example data and plot information function
cnorm.model &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotSubset(cnorm.model)
</code></pre>

<hr>
<h2 id='ppvt'>Vocabulary development from 2.5 to 17</h2><span id='topic+ppvt'></span>

<h3>Description</h3>

<p>A dataset based on an unstratified sample of PPVT4 data (German adaption). The PPVT4 consists of blocks of items with
12 items each. Each item consists of 4 pictures. The test taker is given a word orally and he or she has to point out
the picture matching the oral word. Bottom and ceiling blocks of items are determined according to age and performance. For
instance, when a student knows less than 4 word from a block of 12 items, the testing stops. The sample is not identical
with the norm sample and includes doublets of cases in order to align the sample size per age group. It is
primarily intended for running the cNORM analyses with regard to modeling and stratification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppvt
</code></pre>


<h3>Format</h3>

<p>A data frame with 4542 rows and 6 variables:
</p>

<dl>
<dt>age</dt><dd><p>the chronological age of the child</p>
</dd>
<dt>sex</dt><dd><p>the sex of the test taker, 1=male, 2=female</p>
</dd>
<dt>migration</dt><dd><p>migration status of the family, 0=no, 1=yes</p>
</dd>
<dt>region</dt><dd><p>factor specifiying the region, the data were collected; grouped into south, north, east and west</p>
</dd>
<dt>raw</dt><dd><p>the raw score of the student, spanning values from 0 to 228</p>
</dd>
<dt>group</dt><dd><p>age group of the child, determined by the getGroups()-function with 12 equidistant age groups</p>
</dd>
</dl>

<p>A data frame with 5600 rows and 9 columns
</p>


<h3>Source</h3>

<p><a href="https://www.psychometrica.de/ppvt4.html">https://www.psychometrica.de/ppvt4.html</a>
</p>


<h3>References</h3>

<p>Lenhard, A., Lenhard, W., Segerer, R. &amp; Suggate, S. (2015). Peabody Picture Vocabulary Test - Revision IV (Deutsche Adaption). Frankfurt a. M./Germany: Pearson Assessment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example with continuous age variable, ranked with sliding window
model.ppvt.sliding &lt;- cnorm(age=ppvt$age, raw=ppvt$raw, width=1)

# Example with age groups; you might first want to experiment with
# the granularity of the groups via the 'getGroups()' function
model.ppvt.group &lt;- cnorm(group=ppvt$group, raw=ppvt$raw) # with predefined groups
model.ppvt.group &lt;- cnorm(group=getGroups(ppvt$age, n=15, equidistant = T),
                          raw=ppvt$raw) # groups built 'on the fly'


# plot information function
plot(model.ppvt.group, "subset")

# check model consistency
checkConsistency(model.ppvt.group)

# plot percentiles
plot(model.ppvt.group, "percentiles")

## End(Not run)
</code></pre>

<hr>
<h2 id='predictNorm'>Retrieve norm value for raw score at a specific age</h2><span id='topic+predictNorm'></span>

<h3>Description</h3>

<p>This functions numericaly determines the norm score for raw scores depending on the
level of the explanatory variable A, e. g. norm scores for raw scores at given ages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictNorm(
  raw,
  A,
  model,
  minNorm = NULL,
  maxNorm = NULL,
  force = FALSE,
  covariate = NULL,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictNorm_+3A_raw">raw</code></td>
<td>
<p>The raw value, either single numeric or numeric vector</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_a">A</code></td>
<td>
<p>the explanatory variable (e. g. age), either single numeric or numeric vector</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower bound of the norm score range</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper bound of the norm score range</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_force">force</code></td>
<td>
<p>Try to resolve missing norm scores in case of inconsistent models</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted norm score for a raw score, either single value or vector
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# return norm value for raw value 21 for grade 2, month 9
specificNormValue &lt;- predictNorm(raw = 21, A = 2.75, cnorm.elfe)

# predicted norm scores for the elfe dataset
# predictNorm(elfe$raw, elfe$group, cnorm.elfe)

</code></pre>

<hr>
<h2 id='predictRaw'>Predict single raw value</h2><span id='topic+predictRaw'></span>

<h3>Description</h3>

<p>Most elementary function to predict raw score based on Location (L, T score),
Age (grouping variable) and the coefficients from a regression model.
WARNING! This function, and all functions  depending on it, only works with regression
functions including L, A and interactions. Manually adding predictors to bestModel via the
predictors parameter is currently incompatible.
In that case, and if you are primarily interested on fitting a complete data set,
rather user the predict function of the stats:lm package on the ideal model solution.
You than have to provide a prepared data frame with the according input variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictRaw(
  norm,
  age,
  coefficients,
  minRaw = -Inf,
  maxRaw = Inf,
  covariate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictRaw_+3A_norm">norm</code></td>
<td>
<p>The norm score, e. g. a specific T score or a vector of scores</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_age">age</code></td>
<td>
<p>The age value or a vector of scores</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_coefficients">coefficients</code></td>
<td>
<p>The coefficients from the regression model or a cnorm model</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_minraw">minRaw</code></td>
<td>
<p>Minimum score for the results; can be used for clipping unrealistic outcomes,
usually set to the lower bound of the range of values of the test (default: 0)</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_maxraw">maxRaw</code></td>
<td>
<p>Maximum score for the results; can be used for clipping unrealistic outcomes
usually set to the upper bound of the range of values of the test</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predicted raw score or a data.frame of scores in case, lists of norm scores or age is used
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prediction of single scores
normData &lt;- prepareData(elfe)
m &lt;- bestModel(data = normData)
predictRaw(35, 3.5, m$coefficients)

# using a cnorm object
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
predictRaw(35, 3.5, result)

# Fitting complete data sets
fitted.values &lt;- predict(m)

# break up contribution of each predictor variable
fitted.partial &lt;- predict(m, type = "terms")
</code></pre>

<hr>
<h2 id='prepareData'>Prepare data for modeling in one step (convenience method)</h2><span id='topic+prepareData'></span>

<h3>Description</h3>

<p>This is a convenience method to either load the inbuilt sample dataset, or
to provide a data frame with the variables &quot;raw&quot; (for the raw scores) and &quot;group&quot;
The function ranks the data within groups, computes norm values, powers of the norm
scores and interactions. Afterwards, you can use these preprocessed data to
determine the best fitting model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepareData(
  data = NULL,
  group = "group",
  raw = "raw",
  age = "group",
  k = 4,
  t = NULL,
  width = NA,
  weights = NULL,
  scale = "T",
  descend = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepareData_+3A_data">data</code></td>
<td>
<p>data.frame with a grouping variable named 'group' and a raw score variable
named 'raw'.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_group">group</code></td>
<td>
<p>grouping variable in the data, e. g. age groups, grades ...
Setting group = FALSE deactivates modeling in dependence of age. Use this in case you do want
conventional norm tables.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_raw">raw</code></td>
<td>
<p>the raw scores</p>
</td></tr>
<tr><td><code id="prepareData_+3A_age">age</code></td>
<td>
<p>the continuous explanatory variable; by default set to &quot;group&quot;</p>
</td></tr>
<tr><td><code id="prepareData_+3A_k">k</code></td>
<td>
<p>The power parameter, default = 4</p>
</td></tr>
<tr><td><code id="prepareData_+3A_t">t</code></td>
<td>
<p>the age power parameter (default NULL). If not set, cNORM automatically uses k. The age power parameter
can be used to specify the k to produce rectangular matrices and specify the course of scores per  independently from k</p>
</td></tr>
<tr><td><code id="prepareData_+3A_width">width</code></td>
<td>
<p>if a width is provided, the function switches to rankBySlidingWindow to determine the
observed raw scores, otherwise, ranking is done by group (default)</p>
</td></tr>
<tr><td><code id="prepareData_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each individual case. It can be used
to compensate for moderate imbalances due to insufficient norm data stratification. Weights should be numerical
and positive. Please use the 'computeWeights' function for this purpose.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as well,
be provided f. e. c(10, 3) for Wechsler scale index point</p>
</td></tr>
<tr><td><code id="prepareData_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="prepareData_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame including the norm scores, powers and interactions of the norm score and
grouping variable
</p>


<h3>See Also</h3>

<p>Other prepare: 
<code><a href="#topic+computePowers">computePowers</a>()</code>,
<code><a href="#topic+rankByGroup">rankByGroup</a>()</code>,
<code><a href="#topic+rankBySlidingWindow">rankBySlidingWindow</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># conducts ranking and computation of powers and interactions with the 'elfe' dataset
data.elfe &lt;- prepareData(elfe)

# use vectors instead of data frame
data.elfe &lt;- prepareData(raw=elfe$raw, group=elfe$group)

# variable names can be specified as well, here with the BMI data included in the package
## Not run: 
data.bmi &lt;- prepareData(CDC, group = "group", raw = "bmi", age = "age")

## End(Not run)

# modeling with only one group with the 'elfe' dataset as an example
# this results in conventional norming
data.elfe2 &lt;- prepareData(data = elfe, group = FALSE)
m &lt;- bestModel(data.elfe2)
</code></pre>

<hr>
<h2 id='prettyPrint'>Format raw and norm tables
The function takes a raw or norm table, condenses intervals at the bottom and top
and round the numbers to meaningful interval.</h2><span id='topic+prettyPrint'></span>

<h3>Description</h3>

<p>Format raw and norm tables
The function takes a raw or norm table, condenses intervals at the bottom and top
and round the numbers to meaningful interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prettyPrint(table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prettyPrint_+3A_table">table</code></td>
<td>
<p>The table to format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>formatted table
</p>

<hr>
<h2 id='print.cnorm'>S3 method for printing model selection information</h2><span id='topic+print.cnorm'></span>

<h3>Description</h3>

<p>After conducting the model fitting procedure on the data set, the best fitting
model has to be chosen. The print function shows the R2 and other information
on the different best fitting models with increasing number of predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnorm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cnorm_+3A_x">x</code></td>
<td>
<p>The model from the 'bestModel' function or a cnorm object</p>
</td></tr>
<tr><td><code id="print.cnorm_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with information criteria
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>

<hr>
<h2 id='printSubset'>Print Model Selection Information</h2><span id='topic+printSubset'></span>

<h3>Description</h3>

<p>Displays R^2 and other metrics for models with varying predictors, aiding in choosing the best-fitting model
after model fitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printSubset(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="printSubset_+3A_x">x</code></td>
<td>
<p>Model output from 'bestModel' or a cnorm object.</p>
</td></tr>
<tr><td><code id="printSubset_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Table with model information criteria.
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using cnorm object from sample data
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
printSubset(result)
</code></pre>

<hr>
<h2 id='rangeCheck'>Check for horizontal and vertical extrapolation</h2><span id='topic+rangeCheck'></span>

<h3>Description</h3>

<p>Regression model only work in a specific range and extrapolation horizontally (outside
the original range) or vertically (extreme norm scores) might lead to inconsistent
results. The function generates a message, indicating extrapolation and the range of the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rangeCheck(
  object,
  minAge = NULL,
  maxAge = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  digits = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rangeCheck_+3A_object">object</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_minage">minAge</code></td>
<td>
<p>The lower age bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_maxage">maxAge</code></td>
<td>
<p>The upper age bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower norm value bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper norm value bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_digits">digits</code></td>
<td>
<p>The precision for rounding the norm and age data</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the report
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>normData &lt;- prepareData(elfe)
m &lt;- bestModel(normData)
rangeCheck(m)
</code></pre>

<hr>
<h2 id='rankByGroup'>Determine the norm scores of the participants in each subsample</h2><span id='topic+rankByGroup'></span>

<h3>Description</h3>

<p>This is the initial step, usually done in all kinds of test norming projects,
after the scale is constructed and the norm sample is established. First,
the data is grouped according to a grouping variable and afterwards, the percentile
for each raw value is retrieved. The percentile can be used for the modeling
procedure, but in case, the samples to not deviate too much from normality,
T, IQ or z scores can be computed via a normal rank procedure based on the
inverse cumulative normal distribution. In case of bindings, we use the medium rank
and there are different methods for estimating the percentiles (default RankIt).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankByGroup(
  data = NULL,
  group = "group",
  raw = "raw",
  weights = NULL,
  method = 4,
  scale = "T",
  descend = FALSE,
  descriptives = TRUE,
  covariate = NULL,
  na.rm = TRUE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankByGroup_+3A_data">data</code></td>
<td>
<p>data.frame with norm sample data. If no data.frame is provided, the raw score
and group vectors are directly used</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_group">group</code></td>
<td>
<p>name of the grouping variable (default 'group') or numeric vector, e. g. grade, setting
group to FALSE cancels grouping (data is treated as one group)</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_raw">raw</code></td>
<td>
<p>name of the raw value variable (default 'raw') or numeric vector</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each individual case. It can be used
to compensate for moderate imbalances due to insufficient norm data stratification. Weights should be numerical
and positive.  Please use the 'computeWeights' function for this purpose.</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as well,
be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_descriptives">descriptives</code></td>
<td>
<p>If set to TRUE (default), information in n, mean, median and
standard deviation per group is added to each observation</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_covariate">covariate</code></td>
<td>
<p>Include a binary covariate into the preparation and subsequently modeling,
either by specifying the variable name or including the variable itself. BEWARE!
Not all subsequent functions are already prepared for it.  It is an experimental feature.</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_na.rm">na.rm</code></td>
<td>
<p>remove values, where the percentiles could not be estimated,
most likely happens in the context of weighting</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the dataset with the percentiles and norm scales per group
</p>


<h3>Remarks on using covariates</h3>

<p>So far the inclusion of a binary covariate is experimental and far from optimized.
The according variable name has to be specified in the ranking procedure
and the modeling includes this in the further process. At the moment, during ranking
the data are split into the according cells group x covariate, which leads to small
sample sizes. Please take care to have enough cases in each combination. Additionally,
covariates can lead to unstable modeling solutions. The question, if it is really
reasonable to include covariates when norming a test is a decision beyond the pure data
modeling. Please use with care or alternatively split the dataset into the two groups
beforehand and model them separately.
</p>


<h3>See Also</h3>

<p>rankBySlidingWindow, computePowers, computeWeights, weighted.rank
</p>
<p>Other prepare: 
<code><a href="#topic+computePowers">computePowers</a>()</code>,
<code><a href="#topic+prepareData">prepareData</a>()</code>,
<code><a href="#topic+rankBySlidingWindow">rankBySlidingWindow</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Transformation with default parameters: RankIt and converting to T scores
data.elfe &lt;- rankByGroup(elfe, group = "group") # using a data frame with vector names
data.elfe2 &lt;- rankByGroup(raw=elfe$raw, group=elfe$group) # use vectors for raw score and group

# Transformation into Wechsler scores with Yu &amp; Huang (2001) ranking procedure
data.elfe &lt;- rankByGroup(raw = elfe$raw, group = elfe$group, method = 7, scale = c(10, 3))

# cNORM can as well be used for conventional norming, in case no group is given
d &lt;- rankByGroup(raw = elfe$raw)
d &lt;- computePowers(d)
m &lt;- bestModel(d)
rawTable(0, m) # please use an arbitrary value for age when generating the tables
</code></pre>

<hr>
<h2 id='rankBySlidingWindow'>Determine the norm scores of the participants by sliding window (experimental)</h2><span id='topic+rankBySlidingWindow'></span>

<h3>Description</h3>

<p>The function retrieves all individuals in the predefined age range (x +/- width/2)
around each case and ranks that individual based on this individually drawn sample.
This function can be directly used with a continuous age variable in order to avoid
grouping. When collecting data on the basis of a continuous age variable, cases
located far from the mean age of the group receive distorted percentiles when building
discrete groups and generating percentiles with the traditional approach. The distortion
increases with distance from the group mean and this effect can be avoided by the
sliding window. Nonetheless, please ensure, that the optional grouping variable in fact
represents the correct mean age of the respective age groups, as this variable is
later on used for displaying the manifest data in the percentile plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankBySlidingWindow(
  data = NULL,
  age = "age",
  raw = "raw",
  weights = NULL,
  width,
  method = 4,
  scale = "T",
  descend = FALSE,
  descriptives = TRUE,
  nGroup = 0,
  group = NA,
  covariate = NULL,
  na.rm = TRUE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankBySlidingWindow_+3A_data">data</code></td>
<td>
<p>data.frame with norm sample data</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_age">age</code></td>
<td>
<p>the continuous age variable. Setting 'age' to FALSE inhibits computation of
powers of age and the interactions</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_raw">raw</code></td>
<td>
<p>name of the raw value variable (default 'raw')</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each individual case. It can be used
to compensate for moderate imbalances due to insufficient norm data stratification. Weights should be numerical
and positive. It can be resource intense when applied to the sliding window. Please use the 'computeWeights' function for this purpose.</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_width">width</code></td>
<td>
<p>the width of the sliding window</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as well,
be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_descriptives">descriptives</code></td>
<td>
<p>If set to TRUE (default), information in n, mean, median and
standard deviation per group is added to each observation</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_ngroup">nGroup</code></td>
<td>
<p>If set to a positive value, a grouping variable is created with the desired number of
equi distant groups, named by the group mean age of each group. It creates the
column 'group' in the data.frame and in case, there is already one with that name,
overwrites it.</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_group">group</code></td>
<td>
<p>Optional parameter for providing the name of the grouping variable (if present; overwritten
if ngroups is used)</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_covariate">covariate</code></td>
<td>
<p>Include a binary covariate into the preparation and subsequently modeling,
either by specifying the variable name or including the variable itself. BEWARE!
Not all subsequent functions are already prepared for it.  It is an experimental feature.</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_na.rm">na.rm</code></td>
<td>
<p>remove values, where the percentiles could not be estimated,
most likely happens in the context of weighting</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In case of bindings, the function uses the medium rank and applies the algorithms
already described in the <code><a href="#topic+rankByGroup">rankByGroup</a></code> function. At the upper and lower end of the
data sample, the sliding stops and the sample is drawn from the interval min + width and
max - width, respectively.
</p>


<h3>Value</h3>

<p>the dataset with the individual percentiles and norm scores
</p>


<h3>Remarks on using covariates</h3>

<p>So far the inclusion of a binary covariate is experimental and far from optimized.
The according variable name has to be specified in the ranking procedure
and the modeling includes this in the further process. At the moment, during ranking
the data are split into the according degrees of the covariate and the ranking is done
separately. This may lead to small sample sizes. Please take care to have enough cases in each combination. Additionally,
covariates can lead to unstable modeling solutions. The question, if it is really
reasonable to include covariates when norming a test is a decision beyond the pure data
modeling. Please use with care or alternatively split the dataset into the two groups
beforehand and model them separately.
</p>


<h3>See Also</h3>

<p>rankByGroup, computePowers, computeWeights, weighted.rank, weighted.quantile
</p>
<p>Other prepare: 
<code><a href="#topic+computePowers">computePowers</a>()</code>,
<code><a href="#topic+prepareData">prepareData</a>()</code>,
<code><a href="#topic+rankByGroup">rankByGroup</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Transformation using a sliding window
data.elfe2 &lt;- rankBySlidingWindow(relfe, raw = "raw", age = "group", width = 0.5)

# Comparing this to the traditional approach should give us exactly the same
# values, since the sample dataset only has a grouping variable for age
data.elfe &lt;- rankByGroup(elfe, group = "group")
mean(data.elfe$normValue - data.elfe2$normValue)

## End(Not run)
</code></pre>

<hr>
<h2 id='rawTable'>Create a table with norm scores assigned to raw scores for a specific age based on the regression model</h2><span id='topic+rawTable'></span>

<h3>Description</h3>

<p>This function is comparable to 'normTable', despite it reverses the assignment:
A table with raw scores and the according norm scores for a specific age based on the regression
model is generated. This way, the inverse function of the regression model is solved numerically with
brute force. Please specify the range of raw values, you want to cover. With higher precision
and smaller stepping, this function becomes computational intensive.
In case a confidence coefficient (CI, default .9) and the reliability is specified,
confidence intervals are computed for the true score estimates, including a correction for
regression to the mean (Eid &amp; Schmidt, 2012, p. 272).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rawTable(
  A,
  model,
  minRaw = NULL,
  maxRaw = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  step = 1,
  covariate = NULL,
  monotonuous = TRUE,
  CI = 0.9,
  reliability = NULL,
  pretty = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rawTable_+3A_a">A</code></td>
<td>
<p>the age, either single value or vector with age values</p>
</td></tr>
<tr><td><code id="rawTable_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="rawTable_+3A_minraw">minRaw</code></td>
<td>
<p>The lower bound of the raw score range</p>
</td></tr>
<tr><td><code id="rawTable_+3A_maxraw">maxRaw</code></td>
<td>
<p>The upper bound of the raw score range</p>
</td></tr>
<tr><td><code id="rawTable_+3A_minnorm">minNorm</code></td>
<td>
<p>Clipping parameter for the lower bound of norm scores (default 25)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Clipping parameter for the upper bound of norm scores (default 25)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_step">step</code></td>
<td>
<p>Stepping parameter for the raw scores (default 1)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_covariate">covariate</code></td>
<td>
<p>In case, a covariate has been used, please specify the degree of the covariate /
the specific value here.</p>
</td></tr>
<tr><td><code id="rawTable_+3A_monotonuous">monotonuous</code></td>
<td>
<p>corrects for decreasing norm scores in case of model inconsistencies (default)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_ci">CI</code></td>
<td>
<p>confidence coefficient, ranging from 0 to 1, default .9</p>
</td></tr>
<tr><td><code id="rawTable_+3A_reliability">reliability</code></td>
<td>
<p>coefficient, ranging between  0 to 1</p>
</td></tr>
<tr><td><code id="rawTable_+3A_pretty">pretty</code></td>
<td>
<p>Format table by collapsing intervals and rounding to meaningful precision</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either data.frame with raw scores and the predicted norm scores in case of simple A value or a list
of norm tables if vector of A values was provided
</p>


<h3>References</h3>

<p>Eid, M. &amp; Schmidt, K. (2012). Testtheorie und Testkonstruktion. Hogrefe.
</p>


<h3>See Also</h3>

<p>normTable
</p>
<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)
# generate a norm table for the raw value range from 0 to 28 for the time point month 7 of grade 3
table &lt;- rawTable(3 + 7 / 12, cnorm.elfe, minRaw = 0, maxRaw = 28)

# generate several raw tables
table &lt;- rawTable(c(2.5, 3.5, 4.5), cnorm.elfe, minRaw = 0, maxRaw = 28)

# additionally compute confidence intervals
table &lt;- rawTable(c(2.5, 3.5, 4.5), cnorm.elfe, minRaw = 0, maxRaw = 28, CI = .9, reliability = .94)
</code></pre>

<hr>
<h2 id='regressionFunction'>Regression function</h2><span id='topic+regressionFunction'></span>

<h3>Description</h3>

<p>The method builds the regression function for the regression model,
including the beta weights.
It can be used to predict the raw scores based on age and location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regressionFunction(model, raw = NULL, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regressionFunction_+3A_model">model</code></td>
<td>
<p>The regression model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="regressionFunction_+3A_raw">raw</code></td>
<td>
<p>The name of the raw value variable (default 'raw')</p>
</td></tr>
<tr><td><code id="regressionFunction_+3A_digits">digits</code></td>
<td>
<p>Number of digits for formatting the coefficients</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The regression formula as a string
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
regressionFunction(result)
</code></pre>

<hr>
<h2 id='simMean'>Simulate mean per age</h2><span id='topic+simMean'></span>

<h3>Description</h3>

<p>Simulate mean per age
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simMean(age)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simMean_+3A_age">age</code></td>
<td>
<p>the age variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return predicted means
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- simMean(a)

## End(Not run)
</code></pre>

<hr>
<h2 id='simSD'>Simulate sd per age</h2><span id='topic+simSD'></span>

<h3>Description</h3>

<p>Simulate sd per age
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simSD(age)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simSD_+3A_age">age</code></td>
<td>
<p>the age variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return predicted sd
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- simSD(a)

## End(Not run)
</code></pre>

<hr>
<h2 id='simulateRasch'>Simulate raw test scores based on Rasch model</h2><span id='topic+simulateRasch'></span>

<h3>Description</h3>

<p>For testing purposes only:
The function simulates raw test scores based on a virtual Rasch based test with n results per
age group, an evenly distributed age variable, items.n test items with a simulated difficulty and
standard deviation. The development trajectories over age group are modeled by a curve linear
function of age, with at first fast progression, which slows down over age, and a slightly increasing
standard deviation in order to model a scissor effects. The item difficulties can be accessed via $theta
and the raw data via $data of the returned object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRasch(
  data = NULL,
  n = 100,
  minAge = 1,
  maxAge = 7,
  items.n = 21,
  items.m = 0,
  items.sd = 1,
  Theta = "random",
  width = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateRasch_+3A_data">data</code></td>
<td>
<p>data.frame from previous simulations for recomputation (overrides n, minAge, maxAge)</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_n">n</code></td>
<td>
<p>The sample size per age group</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_minage">minAge</code></td>
<td>
<p>The minimum age (default 1)</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_maxage">maxAge</code></td>
<td>
<p>The maximum age (default 7)</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_items.n">items.n</code></td>
<td>
<p>The number of items of the test</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_items.m">items.m</code></td>
<td>
<p>The mean difficulty of the items</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_items.sd">items.sd</code></td>
<td>
<p>The standard deviation of the item difficulty</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_theta">Theta</code></td>
<td>
<p>irt scales difficulty parameters, either &quot;random&quot; for drawing a random sample,
&quot;even&quot; for evenly distributed or a set of predefined values, which then overrides the item.n
parameters</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_width">width</code></td>
<td>
<p>The width of the window size for the continuous age per group; +- 1/2 width around group
center
on items.m and item.sd; if set to FALSE, the distribution is not drawn randomly but normally nonetheless</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the simulated data and thetas
</p>

<dl>
<dt>data</dt><dd><p>the data.frame with only age, group and raw</p>
</dd>
<dt>sim</dt><dd><p>the complete simulated data with item level results</p>
</dd>
<dt>theta</dt><dd><p>the difficulty of the items</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># simulate data for a rather easy test (m = -1.0)
sim &lt;- simulateRasch(n=150, minAge=1,
                     maxAge=7, items.n = 30, items.m = -1.0,
                     items.sd = 1, Theta = "random", width = 1.0)

# Show item difficulties
mean(sim$theta)
sd(sim$theta)
hist(sim$theta)

# Plot raw scores
boxplot(raw~group, data=sim$data)

# Model data
data &lt;- prepareData(sim$data, age="age")
model &lt;- bestModel(data, k = 4)
printSubset(model)
plotSubset(model, type=0)
</code></pre>

<hr>
<h2 id='standardizeRakingWeights'>Function for standardizing raking weights
Raking weights get divided by the smallest weight. Thereby, all weights
become larger or equal to 1 without changing the ratio of the weights
to each other.</h2><span id='topic+standardizeRakingWeights'></span>

<h3>Description</h3>

<p>Function for standardizing raking weights
Raking weights get divided by the smallest weight. Thereby, all weights
become larger or equal to 1 without changing the ratio of the weights
to each other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardizeRakingWeights(weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardizeRakingWeights_+3A_weights">weights</code></td>
<td>
<p>Raking weights computed by computeWeights()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the standardized weights
</p>

<hr>
<h2 id='summary.cnorm'>S3 method for printing the results and regression function of a cnorm model</h2><span id='topic+summary.cnorm'></span>

<h3>Description</h3>

<p>S3 method for printing the results and regression function of a cnorm model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnorm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.cnorm_+3A_object">object</code></td>
<td>
<p>A regression model or cnorm object</p>
</td></tr>
<tr><td><code id="summary.cnorm_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A report on the regression function, weights, R2 and RMSE
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>
</p>

<hr>
<h2 id='weighted.quantile'>Weighted quantile estimator</h2><span id='topic+weighted.quantile'></span>

<h3>Description</h3>

<p>Computes weighted quantiles (code from Andrey Akinshin via https://aakinshin.net/posts/weighted-quantiles/
Code made available via the CC BY-NC-SA 4.0 license) on the basis of either the weighted Harrell-Davis
quantile estimator or an adaption of the type 7 quantile estimator of the generic quantile function in
the base package. Please provide a vector with raw values, the pobabilities for the quantiles and an
additional vector with the weight of each observation. In case the weight vector is NULL, a normal
quantile estimation is done. The vectors may not include NAs and the weights should be positive non-zero
values. Please draw on the computeWeights() function for retrieving weights in post stratification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile(x, probs, weights = NULL, type = "Harrell-Davis")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.quantile_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_type">type</code></td>
<td>
<p>Type of estimator, can either be &quot;inflation&quot;, &quot;Harrell-Davis&quot; using a beta function to
approximate the weighted percentiles (Harrell &amp; Davis, 1982) or &quot;Type7&quot; (default; Hyndman &amp; Fan, 1996), an adaption
of the generic quantile function in R, including weighting. The inflation procedure is essentially
a numerical, non-parametric solution that gives the same results as Harrel-Davis. It requires less
ressources with small datasets and always finds a solution (e. g. 1000 cases with
weights between 1 and 10). If it becomes too resource intense, it switches to Harrell-Davis automatically.
Harrel-Davis and Type7 code is  based on the work of Akinshin (2020).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the weighted quantiles
</p>


<h3>References</h3>


<ol>
<li><p> Harrell, F.E. &amp; Davis, C.E. (1982). A new distribution-free quantile estimator. Biometrika, 69(3), 635-640.
</p>
</li>
<li><p> Hyndman, R. J. &amp; Fan, Y. (1996). Sample quantiles in statistical packages, American Statistician 50, 361â€“365.
</p>
</li>
<li><p> Akinshin, A. (2020). Weighted quantile estimators. https://aakinshin.net/posts/weighted-quantiles/
</p>
</li></ol>



<h3>See Also</h3>

<p>weighted.quantile.inflation, weighted.quantile.harrell.davis, weighted.quantile.type7
</p>

<hr>
<h2 id='weighted.quantile.harrell.davis'>Weighted Harrell-Davis quantile estimator</h2><span id='topic+weighted.quantile.harrell.davis'></span>

<h3>Description</h3>

<p>Computes weighted quantiles; code from Andrey Akinshin via https://aakinshin.net/posts/weighted-quantiles/
Code made available via the CC BY-NC-SA 4.0 license
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile.harrell.davis(x, probs, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.quantile.harrell.davis_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile.harrell.davis_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile.harrell.davis_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x.
If no weights are provided (NULL), it falls back to the base quantile function, type 7</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the quantiles
</p>

<hr>
<h2 id='weighted.quantile.inflation'>Weighted quantile estimator through case inflation</h2><span id='topic+weighted.quantile.inflation'></span>

<h3>Description</h3>

<p>Applies weighted ranking numerically by inflating cases according to weight. This function
will be resource intensive, if inflated cases get too high and in this cases, it switches
to the parametric Harrell-Davis estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile.inflation(
  x,
  probs,
  weights = NULL,
  degree = 3,
  cutoff = 1e+07
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.quantile.inflation_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x.</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_degree">degree</code></td>
<td>
<p>power parameter for case inflation (default = 3, equaling factor 1000)
If no weights are provided (NULL), it falls back to the base quantile function, type 7</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_cutoff">cutoff</code></td>
<td>
<p>stop criterion for the sum of standardized weights to switch to Harrell-Davis,
default = 1000000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the quantiles
</p>

<hr>
<h2 id='weighted.quantile.type7'>Weighted type7 quantile estimator</h2><span id='topic+weighted.quantile.type7'></span>

<h3>Description</h3>

<p>Computes weighted quantiles; code from Andrey Akinshin via https://aakinshin.net/posts/weighted-quantiles/
Code made available via the CC BY-NC-SA 4.0 license
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile.type7(x, probs, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.quantile.type7_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile.type7_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile.type7_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x.
If no weights are provided (NULL), it falls back to the base quantile function, type 7</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the quantiles
</p>

<hr>
<h2 id='weighted.rank'>Weighted rank estimation</h2><span id='topic+weighted.rank'></span>

<h3>Description</h3>

<p>Conducts weighted ranking on the basis of sums of weights per unique raw score.
Please provide a vector with raw values and an additional vector with the weight of each
observation. In case the weight vector is NULL, a normal ranking is done. The vectors may not
include NAs and the weights should be positive non-zero values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.rank(x, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.rank_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.rank_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the weighted absolute ranks
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
