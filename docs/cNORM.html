<!DOCTYPE html><html lang="en"><head><title>Help for package cNORM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cNORM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bestModel'><p>Determine Regression Model</p></a></li>
<li><a href='#betaCoefficients'><p>Compute Parameters of a Beta Binomial Distribution</p></a></li>
<li><a href='#buildCnormObject'><p>Build cnorm object from data and bestModel model object</p></a></li>
<li><a href='#buildFunction'><p>Build regression function for bestModel</p></a></li>
<li><a href='#calcPolyInL'><p>Internal function for retrieving regression function coefficients at specific age</p></a></li>
<li><a href='#calcPolyInLBase'><p>Internal function for retrieving regression function coefficients at specific age</p></a></li>
<li><a href='#calcPolyInLBase2'><p>Internal function for retrieving regression function coefficients at specific</p>
age (optimized)</a></li>
<li><a href='#CDC'><p>BMI growth curves from age 2 to 25</p></a></li>
<li><a href='#check_monotonicity'><p>Check Monotonicity of Predicted Values</p></a></li>
<li><a href='#checkConsistency'><p>Check the consistency of the norm data model</p></a></li>
<li><a href='#checkWeights'><p>Check, if NA or values &lt;= 0 occur and issue warning</p></a></li>
<li><a href='#cnorm'><p>Continuous Norming</p></a></li>
<li><a href='#cnorm.betabinomial'><p>Fit a beta-binomial regression model for continuous norming</p></a></li>
<li><a href='#cnorm.betabinomial1'><p>Fit a beta binomial regression model</p></a></li>
<li><a href='#cnorm.betabinomial2'><p>Fit a beta-binomial regression model for continuous norming</p></a></li>
<li><a href='#cnorm.cv'><p>Cross-validation for Term Selection in cNORM</p></a></li>
<li><a href='#cNORM.GUI'><p>Launcher for the graphical user interface of cNORM</p></a></li>
<li><a href='#compare'><p>Compare Two Norm Models Visually</p></a></li>
<li><a href='#computePowers'><p>Compute powers of the explanatory variable a as well as of the person</p>
location l (data preparation)</a></li>
<li><a href='#computeWeights'><p>Weighting of cases through iterative proportional fitting (Raking)</p></a></li>
<li><a href='#derivationTable'><p>Create a table based on first order derivative of the regression model for specific age</p></a></li>
<li><a href='#derive'><p>Derivative of regression model</p></a></li>
<li><a href='#diagnostics.betabinomial'><p>Diagnostic Information for Beta-Binomial Model</p></a></li>
<li><a href='#elfe'><p>Sentence completion test from ELFE 1-6</p></a></li>
<li><a href='#getGroups'><p>Determine groups and group means</p></a></li>
<li><a href='#getNormCurve'><p>Computes the curve for a specific T value</p></a></li>
<li><a href='#getNormScoreSE'><p>Calculates the standard error (SE) or root mean square error (RMSE) of the norm scores</p>
In case of large datasets, both results should be almost identical</a></li>
<li><a href='#log_likelihood'><p>Calculate the negative log-likelihood for a beta binomial regression model</p></a></li>
<li><a href='#log_likelihood2'><p>Calculate the negative log-likelihood for a beta-binomial regression model</p></a></li>
<li><a href='#modelSummary'><p>Prints the results and regression function of a cnorm model</p></a></li>
<li><a href='#normTable'><p>Create a norm table based on model for specific age</p></a></li>
<li><a href='#normTable.betabinomial'><p>Calculate Cumulative Probabilities, Density, Percentiles, and Z-Scores for</p>
Beta-Binomial Distribution</a></li>
<li><a href='#plot.cnorm'><p>S3 function for plotting cnorm objects</p></a></li>
<li><a href='#plot.cnormBetaBinomial'><p>Plot cnormBetaBinomial Model with Data and Percentile Lines</p></a></li>
<li><a href='#plot.cnormBetaBinomial2'><p>Plot cnormBetaBinomial Model with Data and Percentile Lines</p></a></li>
<li><a href='#plotCnorm'><p>General convenience plotting function</p></a></li>
<li><a href='#plotDensity'><p>Plot the density function per group by raw score</p></a></li>
<li><a href='#plotDerivative'><p>Plot first order derivative of regression model</p></a></li>
<li><a href='#plotNorm'><p>Plot manifest and fitted norm scores</p></a></li>
<li><a href='#plotNormCurves'><p>Plot norm curves</p></a></li>
<li><a href='#plotPercentiles'><p>Plot norm curves against actual percentiles</p></a></li>
<li><a href='#plotPercentileSeries'><p>Generates a series of plots with number curves by percentile for different models</p></a></li>
<li><a href='#plotRaw'><p>Plot manifest and fitted raw scores</p></a></li>
<li><a href='#plotSubset'><p>Evaluate information criteria for regression model</p></a></li>
<li><a href='#ppvt'><p>Vocabulary development from 2.5 to 17</p></a></li>
<li><a href='#predict.cnormBetaBinomial'><p>Predict Norm Scores from Raw Scores</p></a></li>
<li><a href='#predict.cnormBetaBinomial2'><p>Predict Norm Scores from Raw Scores</p></a></li>
<li><a href='#predictCoefficients'><p>Predict mean and standard deviation for a beta binomial regression model</p></a></li>
<li><a href='#predictCoefficients2'><p>Predict alpha and beta parameters for a beta-binomial regression model</p></a></li>
<li><a href='#predictNorm'><p>Retrieve norm value for raw score at a specific age</p></a></li>
<li><a href='#predictRaw'><p>Predict raw values</p></a></li>
<li><a href='#prepareData'><p>Prepare data for modeling in one step (convenience method)</p></a></li>
<li><a href='#prettyPrint'><p>Format raw and norm tables</p>
The function takes a raw or norm table, condenses intervals at the bottom and top
and round the numbers to meaningful interval.</a></li>
<li><a href='#print.cnorm'><p>S3 method for printing model selection information</p></a></li>
<li><a href='#printSubset'><p>Print Model Selection Information</p></a></li>
<li><a href='#rangeCheck'><p>Check for horizontal and vertical extrapolation</p></a></li>
<li><a href='#rankByGroup'><p>Determine the norm scores of the participants in each subsample</p></a></li>
<li><a href='#rankBySlidingWindow'><p>Determine the norm scores of the participants by sliding window</p></a></li>
<li><a href='#rawTable'><p>Create a table with norm scores assigned to raw scores for a specific age based on the regression model</p></a></li>
<li><a href='#regressionFunction'><p>Regression function</p></a></li>
<li><a href='#simMean'><p>Simulate mean per age</p></a></li>
<li><a href='#simSD'><p>Simulate sd per age</p></a></li>
<li><a href='#simulateRasch'><p>Simulate raw test scores based on Rasch model</p></a></li>
<li><a href='#standardize'><p>Standardize a numeric vector</p></a></li>
<li><a href='#standardizeRakingWeights'><p>Function for standardizing raking weights</p>
Raking weights get divided by the smallest weight. Thereby, all weights
become larger or equal to 1 without changing the ratio of the weights
to each other.</a></li>
<li><a href='#subsample_lm'><p>K-fold Resampled Coefficient Estimation for Linear Regression</p></a></li>
<li><a href='#summary.cnorm'><p>S3 method for printing the results and regression function of a cnorm model</p></a></li>
<li><a href='#summary.cnormBetaBinomial'><p>Summarize a Beta-Binomial Continuous Norming Model</p></a></li>
<li><a href='#summary.cnormBetaBinomial2'><p>Summarize a Beta-Binomial Continuous Norming Model</p></a></li>
<li><a href='#taylorSwift'><p>Swiftly compute Taylor regression models for distribution free continuous norming</p></a></li>
<li><a href='#weighted.quantile'><p>Weighted quantile estimator</p></a></li>
<li><a href='#weighted.quantile.harrell.davis'><p>Weighted Harrell-Davis quantile estimator</p></a></li>
<li><a href='#weighted.quantile.inflation'><p>Weighted quantile estimator through case inflation</p></a></li>
<li><a href='#weighted.quantile.type7'><p>Weighted type7 quantile estimator</p></a></li>
<li><a href='#weighted.rank'><p>Weighted rank estimation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Continuous Norming</td>
</tr>
<tr>
<td>Version:</td>
<td>3.4.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Wolfgang Lenhard &lt;wolfgang.lenhard@uni-wuerzburg.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A comprehensive toolkit for generating continuous test norms in 
    psychometrics and biometrics, and analyzing model fit. The package offers both 
    distribution-free modeling using Taylor polynomials and parametric modeling 
    using the beta-binomial distribution. Originally developed for achievement 
    tests, it is applicable to a wide range of mental, physical, or other test 
    scores dependent on continuous or discrete explanatory variables. The package 
    provides several advantages: It minimizes deviations from representativeness 
    in subsamples, interpolates between discrete levels of explanatory variables, 
    and significantly reduces the required sample size compared to conventional 
    norming per age group. cNORM enables graphical and analytical evaluation of 
    model fit, accommodates a wide range of scales including those with negative 
    and descending values, and even supports conventional norming. It generates 
    norm tables including confidence intervals. It also includes methods for 
    addressing representativeness issues through Iterative Proportional Fitting.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>leaps (&ge; 3.1), ggplot2 (&ge; 3.5.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, shiny, foreign, readxl, rmarkdown, testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL-3</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.psychometrica.de/cNorm_en.html">https://www.psychometrica.de/cNorm_en.html</a>,
<a href="https://github.com/WLenhard/cNORM">https://github.com/WLenhard/cNORM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/WLenhard/cNORM/issues">https://github.com/WLenhard/cNORM/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-04 10:56:00 UTC; gbpa005</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexandra Lenhard <a href="https://orcid.org/0000-0001-8680-4381"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Wolfgang Lenhard <a href="https://orcid.org/0000-0002-8184-6889"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Sebastian Gary [aut],
  WPS publisher [fnd] (&lt;https://www.wpspublish.com/&gt;)</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-04 11:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bestModel'>Determine Regression Model</h2><span id='topic+bestModel'></span>

<h3>Description</h3>

<p>Computes Taylor polynomial regression models by evaluating a series of models with increasing predictors.
It aims to find a consistent model that effectively captures the variance in the data. It draws on the
regsubsets function from the leaps package and builds up to 20 models for each number of predictors, evaluates
these models regarding model consistency and selects consistent model with the highest R^2.
This automatic model selection should usually be accompanied with visual inspection of the percentile plots
and assessment of fit statistics. Set R^2 or number of terms manually to retrieve a more parsimonious model,
if desired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bestModel(
  data,
  raw = NULL,
  R2 = NULL,
  k = NULL,
  t = NULL,
  predictors = NULL,
  terms = 0,
  weights = NULL,
  force.in = NULL,
  plot = TRUE,
  extensive = TRUE,
  subsampling = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bestModel_+3A_data">data</code></td>
<td>
<p>Preprocessed dataset with 'raw' scores, powers, interactions, and usually an explanatory variable (like age).</p>
</td></tr>
<tr><td><code id="bestModel_+3A_raw">raw</code></td>
<td>
<p>Name of the raw score variable (default: 'raw').</p>
</td></tr>
<tr><td><code id="bestModel_+3A_r2">R2</code></td>
<td>
<p>Adjusted R^2 stopping criterion for model building.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_k">k</code></td>
<td>
<p>Power constant influencing model complexity (default: 4, max: 6).</p>
</td></tr>
<tr><td><code id="bestModel_+3A_t">t</code></td>
<td>
<p>Age power parameter. If unset, defaults to 'k'.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_predictors">predictors</code></td>
<td>
<p>List of predictors or regression formula for model selection. Overrides 'k' and can include additional variables.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_terms">terms</code></td>
<td>
<p>Desired number of terms in the model.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_weights">weights</code></td>
<td>
<p>Optional case weights. If set to FALSE, default weights (if any) are ignored.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_force.in">force.in</code></td>
<td>
<p>Variables forcibly included in the regression.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_plot">plot</code></td>
<td>
<p>If TRUE (default), displays a percentile plot of the model and information about the
regression object. FALSE turns off plotting and report.</p>
</td></tr>
<tr><td><code id="bestModel_+3A_extensive">extensive</code></td>
<td>
<p>If TRUE (default), screen models for consistency and - if possible, exclude inconsistent ones</p>
</td></tr>
<tr><td><code id="bestModel_+3A_subsampling">subsampling</code></td>
<td>
<p>If TRUE (default), model coefficients are calculated using 10-folds and averaged across the folds.
This produces more robust estimates with a slight increase in bias.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>rankBySlidingWindow</code>, <code>rankByGroup</code>, <code>bestModel</code>,
<code>computePowers</code> and <code>prepareData</code> are usually not called directly, but accessed
through other functions like <code>cnorm</code>.
</p>
<p>Additional functions like <code>plotSubset(model)</code> and <code>cnorm.cv</code> can aid in model evaluation.
</p>


<h3>Value</h3>

<p>The model. Further exploration can be done using <code>plotSubset(model)</code> and <code>plotPercentiles(data, model)</code>.
</p>


<h3>See Also</h3>

<p>plotSubset, plotPercentiles, plotPercentileSeries, checkConsistency
</p>
<p>Other model: 
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example with sample data
## Not run: 
# It is not recommende to use this function. Rather use 'cnorm' instead.
normData &lt;- prepareData(elfe)
model &lt;- bestModel(normData)
plotSubset(model)
plotPercentiles(buildCnormObject(normData, model))

# Specifying variables explicitly
preselectedModel &lt;- bestModel(normData, predictors = c("L1", "L3", "L1A3", "A2", "A3"))
print(regressionFunction(preselectedModel))

## End(Not run)
</code></pre>

<hr>
<h2 id='betaCoefficients'>Compute Parameters of a Beta Binomial Distribution</h2><span id='topic+betaCoefficients'></span>

<h3>Description</h3>

<p>This function calculates the <code class="reqn">\alpha</code> (a) and <code class="reqn">\beta</code> (b) parameters of a beta binomial
distribution, along with the mean (m), variance (var) based on the input vector 'x'
and the maximum number 'n'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaCoefficients(x, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betaCoefficients_+3A_x">x</code></td>
<td>
<p>A numeric vector of non-negative integers representing observed counts.</p>
</td></tr>
<tr><td><code id="betaCoefficients_+3A_n">n</code></td>
<td>
<p>The maximum number or the maximum possible value of 'x'. If not specified, uses max(x) instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The beta-binomial distribution is a discrete probability distribution that models the
number of successes in a fixed number of trials, where the probability of success varies
from trial to trial. This variability in success probability is modeled by a beta
distribution. Such a calculation is particularly relevant in scenarios where there is
heterogeneity in success probabilities across trials, which is common in real-world
situations, as for example the number of correct solutions in a psychometric test, where
the test has a fixed number of items.
</p>


<h3>Value</h3>

<p>A numeric vector containing the calculated parameters in the following order:
alpha (a), beta (b), mean (m), standard deviation (sd), and the maximum number (n).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1, 2, 3, 4, 5)
n &lt;- 5

betaCoefficients(x, n) # or, to set n to max(x)
betaCoefficients(x)

</code></pre>

<hr>
<h2 id='buildCnormObject'>Build cnorm object from data and bestModel model object</h2><span id='topic+buildCnormObject'></span>

<h3>Description</h3>

<p>Helper function to build a cnorm object from a data object and
a model object from the bestModel function for compatibility reasons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildCnormObject(data, model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="buildCnormObject_+3A_data">data</code></td>
<td>
<p>A data object from 'prepareData', or from 'rankByGroup' and
'computePower'</p>
</td></tr>
<tr><td><code id="buildCnormObject_+3A_model">model</code></td>
<td>
<p>Object obtained from the bestModel function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cnorm object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data &lt;- prepareData(elfe)
  model &lt;- bestModel(data, k = 4)
  model.cnorm &lt;- buildCnormObject(data, model)

## End(Not run)

</code></pre>

<hr>
<h2 id='buildFunction'>Build regression function for bestModel</h2><span id='topic+buildFunction'></span>

<h3>Description</h3>

<p>Build regression function for bestModel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildFunction(raw, k, t, age)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="buildFunction_+3A_raw">raw</code></td>
<td>
<p>name of the raw score variable</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_k">k</code></td>
<td>
<p>the power degree for location</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_t">t</code></td>
<td>
<p>the power degree for age</p>
</td></tr>
<tr><td><code id="buildFunction_+3A_age">age</code></td>
<td>
<p>use age</p>
</td></tr>
</table>


<h3>Value</h3>

<p>regression function
</p>

<hr>
<h2 id='calcPolyInL'>Internal function for retrieving regression function coefficients at specific age</h2><span id='topic+calcPolyInL'></span>

<h3>Description</h3>

<p>The function is an inline for searching zeros in the inverse regression
function. It collapses the regression function at a specific age and simplifies
the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPolyInL(raw, age, model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcPolyInL_+3A_raw">raw</code></td>
<td>
<p>The raw value (subtracted from the intercept)</p>
</td></tr>
<tr><td><code id="calcPolyInL_+3A_age">age</code></td>
<td>
<p>The age</p>
</td></tr>
<tr><td><code id="calcPolyInL_+3A_model">model</code></td>
<td>
<p>The cNORM regression model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients
</p>

<hr>
<h2 id='calcPolyInLBase'>Internal function for retrieving regression function coefficients at specific age</h2><span id='topic+calcPolyInLBase'></span>

<h3>Description</h3>

<p>The function is an inline for searching zeros in the inverse regression
function. It collapses the regression function at a specific age and simplifies
the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPolyInLBase(raw, age, coeff, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcPolyInLBase_+3A_raw">raw</code></td>
<td>
<p>The raw value (subtracted from the intercept)</p>
</td></tr>
<tr><td><code id="calcPolyInLBase_+3A_age">age</code></td>
<td>
<p>The age</p>
</td></tr>
<tr><td><code id="calcPolyInLBase_+3A_coeff">coeff</code></td>
<td>
<p>The cNORM regression model coefficients</p>
</td></tr>
<tr><td><code id="calcPolyInLBase_+3A_k">k</code></td>
<td>
<p>The cNORM regression model power parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients
</p>

<hr>
<h2 id='calcPolyInLBase2'>Internal function for retrieving regression function coefficients at specific
age (optimized)</h2><span id='topic+calcPolyInLBase2'></span>

<h3>Description</h3>

<p>The function is an inline for searching zeros in the inverse regression
function. It collapses the regression function at a specific age and
simplifies the coefficients. Optimized version of the prior 'calcPolyInLBase'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPolyInLBase2(raw, age, coeff, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcPolyInLBase2_+3A_raw">raw</code></td>
<td>
<p>The raw value (subtracted from the intercept)</p>
</td></tr>
<tr><td><code id="calcPolyInLBase2_+3A_age">age</code></td>
<td>
<p>The age</p>
</td></tr>
<tr><td><code id="calcPolyInLBase2_+3A_coeff">coeff</code></td>
<td>
<p>The cNORM regression model coefficients</p>
</td></tr>
<tr><td><code id="calcPolyInLBase2_+3A_k">k</code></td>
<td>
<p>The cNORM regression model power parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients
</p>

<hr>
<h2 id='CDC'>BMI growth curves from age 2 to 25</h2><span id='topic+CDC'></span>

<h3>Description</h3>

<p>By the courtesy of the Center of Disease Control (CDC), cNORM includes human growth data for children and adolescents
age 2 to 25 that can be used to model trajectories of the body mass index and to estimate percentiles for clinical
definitions of under- and overweight. The data stems from the NHANES surveys in the US and was published in 2012
as public domain. The data was cleaned by removing missing values and it includes the following variables from or
based on the original dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDC
</code></pre>


<h3>Format</h3>

<p>A data frame with 45053 rows and 7 variables:
</p>

<dl>
<dt>age</dt><dd><p>continuous age in years, based on the month variable</p>
</dd>
<dt>group</dt><dd><p>age group; chronological age in years at the time of examination</p>
</dd>
<dt>month</dt><dd><p>chronological age in month at the time of examination</p>
</dd>
<dt>sex</dt><dd><p>sex of the participant, 1 = male, 2 = female</p>
</dd>
<dt>height</dt><dd><p>height of the participants in cm</p>
</dd>
<dt>weight</dt><dd><p>weight of the participants in kg</p>
</dd>
<dt>bmi</dt><dd><p>the body mass index, computed by (weight in kg)/(height in m)^2</p>
</dd>
</dl>

<p>A data frame with 45035 rows and 7 columns
</p>


<h3>Source</h3>

<p><a href="https://www.cdc.gov/nchs/nhanes/index.htm">https://www.cdc.gov/nchs/nhanes/index.htm</a>
</p>


<h3>References</h3>

<p>CDC (2012). National Health and Nutrition Examination Survey: Questionnaires, Datasets and Related
Documentation. available <a href="https://www.cdc.gov/nchs/nhanes/index.htm">https://www.cdc.gov/nchs/nhanes/index.htm</a> (date of retrieval: 25/08/2018)
</p>

<hr>
<h2 id='check_monotonicity'>Check Monotonicity of Predicted Values</h2><span id='topic+check_monotonicity'></span>

<h3>Description</h3>

<p>This function checks if the predicted values from a linear model are
monotonically increasing or decreasing across a range of L values for
multiple age points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_monotonicity(lm_model, pred_data, minRaw, maxRaw)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_monotonicity_+3A_lm_model">lm_model</code></td>
<td>
<p>An object of class 'lm' representing the fitted linear model.</p>
</td></tr>
<tr><td><code id="check_monotonicity_+3A_pred_data">pred_data</code></td>
<td>
<p>Matrix with prediction values</p>
</td></tr>
<tr><td><code id="check_monotonicity_+3A_minraw">minRaw</code></td>
<td>
<p>lowest raw score in prediction</p>
</td></tr>
<tr><td><code id="check_monotonicity_+3A_maxraw">maxRaw</code></td>
<td>
<p>highest raw score in prediction</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates a prediction data frame using all combinations
of the provided L values and age points. It then generates predictions
using the provided linear model and checks if these predictions are
monotonically increasing or decreasing for each age point across the
range of L values.
</p>


<h3>Value</h3>

<p>A named character vector where each element corresponds to an age point.
Possible values for each element are 1 for &quot;Monotonically increasing&quot;
-1 for &quot;Monotonically decreasing&quot;, or 0 for &quot;Not monotonic&quot;.
</p>

<hr>
<h2 id='checkConsistency'>Check the consistency of the norm data model</h2><span id='topic+checkConsistency'></span>

<h3>Description</h3>

<p>While abilities increase and decline over age, within one age group, the
norm scores always have to show a monotonic increase or decrease with increasing raw
scores. Violations of this assumption are an indication for problems
in modeling the relationship between raw and norm scores. There are
several reasons, why this might occur:
</p>

<ol>
<li><p> Vertical extrapolation: Choosing extreme norm scores, e. g. values
-3 &lt;= x and x &gt;= 3 In order to model these extreme values, a large sample
dataset is necessary.
</p>
</li>
<li><p> Horizontal extrapolation: Taylor polynomials converge in a certain
radius. Using the model values outside the original dataset may
lead to inconsistent results.
</p>
</li>
<li><p> The data cannot be modeled with Taylor polynomials, or you need
another power parameter (k) or R2 for the model.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>checkConsistency(
  model,
  minAge = NULL,
  maxAge = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  minRaw = NULL,
  maxRaw = NULL,
  stepAge = NULL,
  stepNorm = 1,
  warn = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkConsistency_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_minage">minAge</code></td>
<td>
<p>Age to start with checking</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_maxage">maxAge</code></td>
<td>
<p>Upper end of the age check</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_minnorm">minNorm</code></td>
<td>
<p>Lower end of the norm value range</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Upper end of the norm value range</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_minraw">minRaw</code></td>
<td>
<p>clipping parameter for the lower bound of raw scores</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_maxraw">maxRaw</code></td>
<td>
<p>clipping parameter for the upper bound of raw scores</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_stepage">stepAge</code></td>
<td>
<p>Stepping parameter for the age check.
values indicate higher precision / closer checks</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_stepnorm">stepNorm</code></td>
<td>
<p>Stepping parameter for the norm table check within age with lower
scores indicating a higher precision. The choice depends of the norm scale
used. With T scores a stepping parameter of 1 is suitable</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_warn">warn</code></td>
<td>
<p>If set to TRUE, already minor violations of the model assumptions
are displayed (default = FALSE)</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_silent">silent</code></td>
<td>
<p>turn off messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, extrapolation (point 1 and 2) can carefully be done to a
certain degree outside the original sample, but it should in general
be handled with caution. Please note that at extreme values, the models
most likely become independent and it is thus recommended to restrict the
norm score range to the relevant range of abilities, e.g. +/- 2.5 SD via
the minNorm and maxNorm parameter.
</p>


<h3>Value</h3>

<p>Boolean, indicating model violations (TRUE) or no problems (FALSE)
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- cnorm(raw = elfe$raw, group = elfe$group, plot = FALSE)
modelViolations &lt;- checkConsistency(model, minNorm = 25, maxNorm = 75)
plotDerivative(model, minNorm = 25, maxNorm = 75)

</code></pre>

<hr>
<h2 id='checkWeights'>Check, if NA or values &lt;= 0 occur and issue warning</h2><span id='topic+checkWeights'></span>

<h3>Description</h3>

<p>Check, if NA or values &lt;= 0 occur and issue warning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkWeights(weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkWeights_+3A_weights">weights</code></td>
<td>
<p>Raking weights</p>
</td></tr>
</table>

<hr>
<h2 id='cnorm'>Continuous Norming</h2><span id='topic+cnorm'></span>

<h3>Description</h3>

<p>Conducts continuous norming in one step and returns an object including ranked
raw data and the continuous norming model. Please consult the function
description ' of 'rankByGroup', 'rankBySlidingWindow' and 'bestModel' for specifics
of the steps in the data preparation and modeling process. In addition to the
raw scores, either provide
</p>

<ul>
<li><p>a numeric vector for the grouping information (group)
</p>
</li>
<li><p>a numeric age vector and the width of the sliding window (age, width)
</p>
</li></ul>

<p>for the ranking of the raw scores. You can
adjust the grade of smoothing of the regression model by setting the k and terms
parameter. In general, increasing k to more than 4 and the number of terms lead
to a higher fit, while lower values lead to more smoothing. The power parameter
for the age trajectory can be specified independently by 't'. If both parameters
are missing, cnorm uses k = 5 and t = 3 by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm(
  raw = NULL,
  group = NULL,
  age = NULL,
  width = NA,
  weights = NULL,
  scale = "T",
  method = 4,
  descend = FALSE,
  k = NULL,
  t = NULL,
  terms = 0,
  R2 = NULL,
  plot = TRUE,
  extensive = TRUE,
  subsampling = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cnorm_+3A_raw">raw</code></td>
<td>
<p>Numeric vector of raw scores</p>
</td></tr>
<tr><td><code id="cnorm_+3A_group">group</code></td>
<td>
<p>Numeric vector of grouping variable, e. g. grade. If no group
or age variable is provided, conventional norming is applied</p>
</td></tr>
<tr><td><code id="cnorm_+3A_age">age</code></td>
<td>
<p>Numeric vector with chronological age, please additionally specify
width of window</p>
</td></tr>
<tr><td><code id="cnorm_+3A_width">width</code></td>
<td>
<p>Size of the sliding window in case an age vector is used</p>
</td></tr>
<tr><td><code id="cnorm_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each
individual case. It can be used to compensate for moderate imbalances due to
insufficient norm data stratification. Weights should be numerical and positive.</p>
</td></tr>
<tr><td><code id="cnorm_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as
well, be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="cnorm_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="cnorm_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="cnorm_+3A_k">k</code></td>
<td>
<p>The power constant. Higher values result in more detailed approximations
but have the danger of over-fit (max = 6). If not set, it uses t and if both
parameters are NULL, k is set to 5.</p>
</td></tr>
<tr><td><code id="cnorm_+3A_t">t</code></td>
<td>
<p>The age power parameter (max = 6). If not set, it uses k and if both
parameters are NULL, k is set to 3, since age trajectories are most often well
captured by cubic polynomials.</p>
</td></tr>
<tr><td><code id="cnorm_+3A_terms">terms</code></td>
<td>
<p>Selection criterion for model building. The best fitting model with
this number of terms is used</p>
</td></tr>
<tr><td><code id="cnorm_+3A_r2">R2</code></td>
<td>
<p>Adjusted R square as a stopping criterion for the model building
(default R2 = 0.99)</p>
</td></tr>
<tr><td><code id="cnorm_+3A_plot">plot</code></td>
<td>
<p>Default TRUE; plots the regression model and prints report</p>
</td></tr>
<tr><td><code id="cnorm_+3A_extensive">extensive</code></td>
<td>
<p>If TRUE, screen models for consistency and - if possible, exclude inconsistent ones</p>
</td></tr>
<tr><td><code id="cnorm_+3A_subsampling">subsampling</code></td>
<td>
<p>If TRUE (default), model coefficients are calculated using 10-folds and averaged across the folds.
This produces more robust estimates with a slight increase in bias.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cnorm object including the ranked raw data and the regression model
</p>


<h3>References</h3>


<ol>
<li><p> Gary, S. &amp; Lenhard, W. (2021). In norming we trust. Diagnostica.
</p>
</li>
<li><p> Gary, S., Lenhard, W. &amp; Lenhard, A. (2021). Modelling Norm Scores with the cNORM Package in R. Psych, 3(3), 501-521. https://doi.org/10.3390/psych3030033
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Suggate, S. &amp; Segerer, R. (2016). A continuous solution to the norming problem. Assessment, Online first, 1-14. doi:10.1177/1073191116656437
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Gary, S. (2018). Continuous Norming (cNORM). The Comprehensive R Network, Package cNORM, available: https://CRAN.R-project.org/package=cNORM
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Gary, S. (2019). Continuous norming of psychometric tests: A simulation study of parametric and semi-parametric approaches. PLoS ONE, 14(9),  e0222279. doi:10.1371/journal.pone.0222279
</p>
</li>
<li><p> Lenhard, W., &amp; Lenhard, A. (2020). Improvement of Norm Score Quality via Regression-Based Continuous Norming. Educational and Psychological Measurement(Online First), 1-33. https://doi.org/10.1177/0013164420928457
</p>
</li></ol>



<h3>See Also</h3>

<p>rankByGroup, rankBySlidingWindow, computePowers, bestModel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Using this function with the example dataset 'elfe'

# Conventional norming (no modelling over age)
cnorm(raw=elfe$raw)

# Continuous norming
# You can use the 'getGroups()' function to set up grouping variable in case,
# you have a continuous age variable.
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# return norm tables including 90% confidence intervals for a
# test with a reliability of r = .85; table are set to mean of quartal
# in grade 3 (children completed 2 years of schooling)
normTable(c(2.125, 2.375, 2.625), cnorm.elfe, CI = .90, reliability = .95)

# ... or instead of raw scores for norm scores, the other way round
rawTable(c(2.125, 2.375, 2.625), cnorm.elfe, CI = .90, reliability = .95)


# Using a continuous age variable instead of distinct groups, using a sliding
# window for percentile estimation. Please specify continuos variable for age
# and the sliding window size.
cnorm.ppvt.continuous &lt;- cnorm(raw = ppvt$raw, age = ppvt$age, width=1)


# In case of unbalanced datasets, deviating from the census, the norm data
# can be weighted by the means of raking / post stratification. Please generate
# the weights with the computeWeights() function and pass them as the weights
# parameter. For computing the weights, please specify a data.frame with the
# population margins (further information is available in the computeWeights
# function). A demonstration based on sex and migration status in vocabulary
# development (ppvt dataset):
margins &lt;- data.frame(variables = c("sex", "sex",
                                    "migration", "migration"),
                      levels = c(1, 2, 0, 1),
                      share = c(.52, .48, .7, .3))
weights &lt;- computeWeights(ppvt, margins)
model &lt;- cnorm(raw = ppvt$raw, group=ppvt$group, weights = weights)

## End(Not run)
</code></pre>

<hr>
<h2 id='cnorm.betabinomial'>Fit a beta-binomial regression model for continuous norming</h2><span id='topic+cnorm.betabinomial'></span>

<h3>Description</h3>

<p>This function fits a beta-binomial regression model where both the <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>
parameters of the beta-binomial distribution are modeled as polynomial functions
of the predictor variable (typically age). Setting mode to 1 fits a beta-binomial
model on the basis of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, setting it to 2 (default) fits a beta-binomial
model directly on the basis of <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm.betabinomial(
  age,
  score,
  n = NULL,
  weights = NULL,
  mode = 2,
  alpha = 3,
  beta = 3,
  control = NULL,
  scale = "T",
  plot = T
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cnorm.betabinomial_+3A_age">age</code></td>
<td>
<p>A numeric vector of predictor values (e.g., age).</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_score">score</code></td>
<td>
<p>A numeric vector of response values.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_n">n</code></td>
<td>
<p>The maximum score (number of trials in the beta-binomial distribution). If NULL, max(score) is used.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of weights for each observation. Default is NULL (equal weights).</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_mode">mode</code></td>
<td>
<p>Integer specifying the mode of the model. Default is 2 (direct modelling of <code class="reqn">\gamma</code> and <code class="reqn">\beta</code>).
If set to 1, the model is fitted on the basis of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, the predicted
mean and standard deviation over age.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_alpha">alpha</code></td>
<td>
<p>Integer specifying the degree of the polynomial for the alpha model.
Default is 3. If mode is set to 1, this parameter is used to specify the degree
of the polynomial for the <code class="reqn">\mu</code> model.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_beta">beta</code></td>
<td>
<p>Integer specifying the degree of the polynomial for the beta model. Default is 3.
If mode is set to 1, this parameter is used to specify the degree of the polynomial
for the <code class="reqn">\sigma</code> model.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_control">control</code></td>
<td>
<p>A list of control parameters to be passed to the 'optim' function.
If NULL, default values are used, namely control = list(reltol = 1e-8, maxit = 1000)
for mode 1 and control = list(factr = 1e-8, maxit = 1000) for mode 2.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_scale">scale</code></td>
<td>
<p>Type of norm scale, either &quot;T&quot; (default), &quot;IQ&quot;, &quot;z&quot; or a double vector with the mean and standard deviation.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial_+3A_plot">plot</code></td>
<td>
<p>Logical indicating whether to plot the model. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function standardizes the input variables, fits polynomial models for both
the alpha and beta parameters, and uses maximum likelihood estimation to
find the optimal parameters. The optimization is performed using the L-BFGS-B method.
</p>


<h3>Value</h3>

<p>A list of class &quot;cnormBetaBinomial&quot; or &quot;cnormBetaBinomial2&quot;. In case of mode 2
containing:
</p>
<table role = "presentation">
<tr><td><code>alpha_est</code></td>
<td>
<p>Estimated coefficients for the alpha model</p>
</td></tr>
<tr><td><code>beta_est</code></td>
<td>
<p>Estimated coefficients for the beta model</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Standard errors of the estimated coefficients</p>
</td></tr>
<tr><td><code>alpha_degree</code></td>
<td>
<p>Degree of the polynomial for the alpha model</p>
</td></tr>
<tr><td><code>beta_degree</code></td>
<td>
<p>Degree of the polynomial for the beta model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>Full result from the optimization procedure</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Fit a beta-binomial regression model to the PPVT data
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw, n = 228)
summary(model)

# Use weights for post-stratification
marginals &lt;- data.frame(var = c("sex", "sex", "migration", "migration"),
                        level = c(1,2,0,1),
                        prop = c(0.51, 0.49, 0.65, 0.35))
weights &lt;- computeWeights(ppvt, marginals)
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw, n = 228, weights = weights)

## End(Not run)
</code></pre>

<hr>
<h2 id='cnorm.betabinomial1'>Fit a beta binomial regression model</h2><span id='topic+cnorm.betabinomial1'></span>

<h3>Description</h3>

<p>This function fits a beta binomial regression model where both the mean and
standard deviation of the response variable are modeled as polynomial functions
of the predictor variable. While 'cnorm-betabinomial2' fits a beta-binomial model
on the basis of <code class="reqn">\gamma</code> and <code class="reqn">\beta</code> of a beta binomial function, this function
fits <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, which are then used to estimate the beta binomial distribution
parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm.betabinomial1(
  age,
  score,
  n = NULL,
  weights = NULL,
  mu = 3,
  sigma = 3,
  control = NULL,
  scale = "T",
  plot = T
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cnorm.betabinomial1_+3A_age">age</code></td>
<td>
<p>A numeric vector of predictor values (e.g., age).</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_score">score</code></td>
<td>
<p>A numeric vector of response values.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_n">n</code></td>
<td>
<p>Number of items in the test, resp. maximum score to be achieved</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of weights for each observation. Default is NULL (equal weights).</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_mu">mu</code></td>
<td>
<p>Integer specifying the degree of the polynomial for the mean model. Default is 2.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_sigma">sigma</code></td>
<td>
<p>Integer specifying the degree of the polynomial for the standard deviation model. Default is 1.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_control">control</code></td>
<td>
<p>A list of control parameters to be passed to the 'optim' function.
If NULL, default values are used.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as
well, be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial1_+3A_plot">plot</code></td>
<td>
<p>Logical indicating whether to plot the model. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function standardizes the input variables, fits polynomial models for both
the mean and standard deviation, and uses maximum likelihood estimation to
find the optimal parameters. The optimization is performed using the BFGS method.
</p>


<h3>Value</h3>

<p>A list of class &quot;cnormBetaBinomial&quot; containing:
</p>
<table role = "presentation">
<tr><td><code>beta_est</code></td>
<td>
<p>Estimated coefficients for the mean model</p>
</td></tr>
<tr><td><code>gamma_est</code></td>
<td>
<p>Estimated coefficients for the log-standard deviation model</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Standard errors of the estimated coefficients</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Degree of the polynomial for the mean model</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Degree of the polynomial for the standard deviation model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>Full result from the optimization procedure</p>
</td></tr>
</table>

<hr>
<h2 id='cnorm.betabinomial2'>Fit a beta-binomial regression model for continuous norming</h2><span id='topic+cnorm.betabinomial2'></span>

<h3>Description</h3>

<p>This function fits a beta-binomial regression model where both the alpha and beta
parameters of the beta-binomial distribution are modeled as polynomial functions
of the predictor variable (typically age). While 'cnorm-betabinomial' fits a beta-binomial model
on the basis of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, this function fits a beta-binomial model directly on the basis
of <code class="reqn">\gamma</code> and <code class="reqn">\beta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm.betabinomial2(
  age,
  score,
  n = NULL,
  weights = NULL,
  alpha_degree = 3,
  beta_degree = 3,
  control = NULL,
  scale = "T",
  plot = T
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cnorm.betabinomial2_+3A_age">age</code></td>
<td>
<p>A numeric vector of predictor values (e.g., age).</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_score">score</code></td>
<td>
<p>A numeric vector of response values.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_n">n</code></td>
<td>
<p>The maximum score (number of trials in the beta-binomial distribution). If NULL, max(score) is used.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of weights for each observation. Default is NULL (equal weights).</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_alpha_degree">alpha_degree</code></td>
<td>
<p>Integer specifying the degree of the polynomial for the alpha model. Default is 3.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_beta_degree">beta_degree</code></td>
<td>
<p>Integer specifying the degree of the polynomial for the beta model. Default is 3.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_control">control</code></td>
<td>
<p>A list of control parameters to be passed to the 'optim' function.
If NULL, default values are used.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_scale">scale</code></td>
<td>
<p>Type of norm scale, either &quot;T&quot; (default), &quot;IQ&quot;, &quot;z&quot; or a double vector with the mean and standard deviation.</p>
</td></tr>
<tr><td><code id="cnorm.betabinomial2_+3A_plot">plot</code></td>
<td>
<p>Logical indicating whether to plot the model. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function standardizes the input variables, fits polynomial models for both
the alpha and beta parameters, and uses maximum likelihood estimation to
find the optimal parameters. The optimization is performed using the L-BFGS-B method.
</p>


<h3>Value</h3>

<p>A list of class &quot;cnormBetaBinomial2&quot; containing:
</p>
<table role = "presentation">
<tr><td><code>alpha_est</code></td>
<td>
<p>Estimated coefficients for the alpha model</p>
</td></tr>
<tr><td><code>beta_est</code></td>
<td>
<p>Estimated coefficients for the beta model</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Standard errors of the estimated coefficients</p>
</td></tr>
<tr><td><code>alpha_degree</code></td>
<td>
<p>Degree of the polynomial for the alpha model</p>
</td></tr>
<tr><td><code>beta_degree</code></td>
<td>
<p>Degree of the polynomial for the beta model</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>Full result from the optimization procedure</p>
</td></tr>
</table>

<hr>
<h2 id='cnorm.cv'>Cross-validation for Term Selection in cNORM</h2><span id='topic+cnorm.cv'></span>

<h3>Description</h3>

<p>Assists in determining the optimal number of terms for the regression model using repeated Monte Carlo
cross-validation. It leverages an 80-20 split between training and validation data, with stratification by norm group
or random sample in case of using sliding window ranking.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cnorm.cv(
  data,
  formula = NULL,
  repetitions = 5,
  norms = TRUE,
  min = 1,
  max = 12,
  cv = "full",
  pCutoff = NULL,
  width = NA,
  raw = NULL,
  group = NULL,
  age = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cnorm.cv_+3A_data">data</code></td>
<td>
<p>Data frame of norm sample or a cnorm object. Should have ranking, powers, and interaction of L and A.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_formula">formula</code></td>
<td>
<p>Formula from an existing regression model; min/max functions ignored. If using a cnorm object, this is automatically fetched.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_repetitions">repetitions</code></td>
<td>
<p>Number of repetitions for cross-validation.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_norms">norms</code></td>
<td>
<p>If TRUE, computes norm score crossfit and R^2. Note: Computationally intensive.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_min">min</code></td>
<td>
<p>Start with a minimum number of terms (default = 1).</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_max">max</code></td>
<td>
<p>Maximum terms in model, up to (k + 1) * (t + 1) - 1.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_cv">cv</code></td>
<td>
<p>&quot;full&quot; (default) splits data into training/validation, then ranks. Otherwise, expects a pre-ranked dataset.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_pcutoff">pCutoff</code></td>
<td>
<p>Checks stratification for unbalanced data. Performs a t-test per group. Default set to 0.2 to minimize beta error.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_width">width</code></td>
<td>
<p>If provided, ranking done via 'rankBySlidingWindow'. Otherwise, by group.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_raw">raw</code></td>
<td>
<p>Name of the raw score variable.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_group">group</code></td>
<td>
<p>Name of the grouping variable.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_age">age</code></td>
<td>
<p>Name of the age variable.</p>
</td></tr>
<tr><td><code id="cnorm.cv_+3A_weights">weights</code></td>
<td>
<p>Name of the weighting parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Successive models, with an increasing number of terms, are evaluated, and the RMSE for raw scores plotted. This
encompasses the training, validation, and entire dataset. If 'norms' is set to TRUE (default), the function will also
calculate the mean norm score reliability and crossfit measures. Note that due to the computational requirements
of norm score calculations, execution can be slow, especially with numerous repetitions or terms.
</p>
<p>When 'cv' is set to &quot;full&quot; (default), both test and validation datasets are ranked separately, providing comprehensive
cross-validation. For a more streamlined validation process focused only on modeling, a pre-ranked dataset can be used.
The output comprises RMSE for raw score models, norm score R^2, delta R^2, crossfit, and the norm score SE according
to Oosterhuis, van der Ark, &amp; Sijtsma (2016).
</p>
<p>This function is not yet prepared for the 'extensive' search strategy, introduced in version 3.3, but instead
relies on the first model per number of terms, without consistency check.
</p>
<p>For assessing overfitting:
</p>
<p style="text-align: center;"><code class="reqn">CROSSFIT = R(Training; Model)^2 / R(Validation; Model)^2</code>
</p>

<p>A CROSSFIT &gt; 1 suggests overfitting, &lt; 1 suggests potential underfitting, and values around 1 are optimal,
given a low raw score RMSE and high norm score validation R^2.
</p>
<p>Suggestions for ideal model selection:
</p>

<ul>
<li><p> Visual inspection of percentiles with 'plotPercentiles' or 'plotPercentileSeries'.
</p>
</li>
<li><p> Pair visual inspection with repeated cross-validation (e.g., 10 repetitions).
</p>
</li>
<li><p> Aim for low raw score RMSE and high norm score R^2, avoiding terms with significant overfit (e.g., crossfit &gt; 1.1).
</p>
</li></ul>



<h3>Value</h3>

<p>Table with results per term number: RMSE for raw scores, R^2 for norm scores, and crossfit measure.
</p>


<h3>References</h3>

<p>Oosterhuis, H. E. M., van der Ark, L. A., &amp; Sijtsma, K. (2016). Sample Size Requirements for Traditional
and Regression-Based Norms. Assessment, 23(2), 191202. https://doi.org/10.1177/1073191115580638
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example: Plot cross-validation RMSE by number of terms (up to 9) with three repetitions.
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
cnorm.cv(result$data, min = 2, max = 9, repetitions = 3)

# Using a cnorm object examines the predefined formula.
cnorm.cv(result, repetitions = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='cNORM.GUI'>Launcher for the graphical user interface of cNORM</h2><span id='topic+cNORM.GUI'></span>

<h3>Description</h3>

<p>Launcher for the graphical user interface of cNORM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cNORM.GUI(launch.browser = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cNORM.GUI_+3A_launch.browser">launch.browser</code></td>
<td>
<p>Default TRUE; automatically open browser for GUI</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Launch graphical user interface
cNORM.GUI()

## End(Not run)
</code></pre>

<hr>
<h2 id='compare'>Compare Two Norm Models Visually</h2><span id='topic+compare'></span>

<h3>Description</h3>

<p>This function creates a visualization comparing two norm models by displaying
their percentile curves. The first model is shown with solid lines, the second
with dashed lines. If age and score vectors are provided, manifest percentiles
are displayed as dots. The function works with both regular cnorm models and
beta-binomial models and allows comparison between different model types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare(
  model1,
  model2,
  percentiles = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
  age = NULL,
  score = NULL,
  weights = NULL,
  title = NULL,
  subtitle = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_+3A_model1">model1</code></td>
<td>
<p>First model object (distribution free or beta-binomial)</p>
</td></tr>
<tr><td><code id="compare_+3A_model2">model2</code></td>
<td>
<p>Second model object (distribution free or beta-binomial)</p>
</td></tr>
<tr><td><code id="compare_+3A_percentiles">percentiles</code></td>
<td>
<p>Vector with percentile scores, ranging from 0 to 1 (exclusive)</p>
</td></tr>
<tr><td><code id="compare_+3A_age">age</code></td>
<td>
<p>Optional vector with manifest age or group values</p>
</td></tr>
<tr><td><code id="compare_+3A_score">score</code></td>
<td>
<p>Optional vector with manifest raw score values</p>
</td></tr>
<tr><td><code id="compare_+3A_weights">weights</code></td>
<td>
<p>Optional vector with manifest weights</p>
</td></tr>
<tr><td><code id="compare_+3A_title">title</code></td>
<td>
<p>Custom title for plot (optional)</p>
</td></tr>
<tr><td><code id="compare_+3A_subtitle">subtitle</code></td>
<td>
<p>Custom subtitle for plot (optional)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object showing the comparison of both models
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Compare different types of models
model1 &lt;- cnorm(group = elfe$group, raw = elfe$raw)
model2 &lt;- cnorm.betabinomial(elfe$group, elfe$raw)
compare(model1, model2, age = elfe$group, score = elfe$raw)

## End(Not run)

</code></pre>

<hr>
<h2 id='computePowers'>Compute powers of the explanatory variable a as well as of the person
location l (data preparation)</h2><span id='topic+computePowers'></span>

<h3>Description</h3>

<p>The function computes powers of the norm variable e. g. T scores (location, L),
an explanatory variable, e. g. age or grade of a data frame (age, A) and the
interactions of both (L X A). The k variable indicates the degree up to which
powers and interactions are build. These predictors can be used later on in the
<code><a href="#topic+bestModel">bestModel</a></code> function to model the norm sample. Higher values of k
allow for modeling the norm sample closer, but might lead to over-fit. In general
k = 3 or k = 4 (default) is sufficient to model human performance data. For example,
k = 2 results in the variables L1, L2, A1, A2, and their interactions L1A1, L2A1, L1A2
and L2A2 (but k = 2 is usually not sufficient for the modeling). Please note, that
you do not need to use a normal rank transformed scale like T r IQ, but you can
as well use the percentiles for the 'normValue' as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computePowers(data, k = 5, norm = NULL, age = NULL, t = 3, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computePowers_+3A_data">data</code></td>
<td>
<p>data.frame with the norm data</p>
</td></tr>
<tr><td><code id="computePowers_+3A_k">k</code></td>
<td>
<p>degree</p>
</td></tr>
<tr><td><code id="computePowers_+3A_norm">norm</code></td>
<td>
<p>the variable containing the norm data in the data.frame; might be
T scores, IQ scores, percentiles ...</p>
</td></tr>
<tr><td><code id="computePowers_+3A_age">age</code></td>
<td>
<p>Explanatory variable like age or grade, which was as well used for the grouping.
Can be either the grouping variable itself or a finer grained variable like the exact age. Other
explanatory variables can be used here instead an age variable as well, as long as the variable is
at least ordered metric, e. g. language or development levels ... The label 'age' is used, as this is the
most common field of application.</p>
</td></tr>
<tr><td><code id="computePowers_+3A_t">t</code></td>
<td>
<p>the age power parameter (default NULL). If not set, cNORM automatically uses k. The age power parameter
can be used to specify the k to produce rectangular matrices and specify the course of scores per independently from k</p>
</td></tr>
<tr><td><code id="computePowers_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>rankBySlidingWindow</code>, <code>rankByGroup</code>, <code>bestModel</code>,
<code>computePowers</code> and <code>prepareData</code> are usually not called directly, but accessed
through other functions like <code>cnorm</code>.
</p>


<h3>Value</h3>

<p>data.frame with the powers and interactions of location and explanatory variable / age
</p>


<h3>See Also</h3>

<p>bestModel
</p>
<p>Other prepare: 
<code><a href="#topic+prepareData">prepareData</a>()</code>,
<code><a href="#topic+rankByGroup">rankByGroup</a>()</code>,
<code><a href="#topic+rankBySlidingWindow">rankBySlidingWindow</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Dataset with grade levels as grouping
data.elfe &lt;- rankByGroup(elfe)
data.elfe &lt;- computePowers(data.elfe)

# Dataset with continuous age variable and k = 5
data.ppvt &lt;- rankByGroup(ppvt)
data.ppvt &lt;- computePowers(data.ppvt, age = "age", k = 5)
</code></pre>

<hr>
<h2 id='computeWeights'>Weighting of cases through iterative proportional fitting (Raking)</h2><span id='topic+computeWeights'></span>

<h3>Description</h3>

<p>Computes and standardizes weights via raking to compensate for non-stratified
samples. It is based on the implementation in the survey R package. It reduces
data collection #' biases in the norm data by the means of post stratification,
thus reducing the effect of unbalanced data in percentile estimation and norm
data modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeWeights(data, population.margins, standardized = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeWeights_+3A_data">data</code></td>
<td>
<p>data.frame with norm sample data.</p>
</td></tr>
<tr><td><code id="computeWeights_+3A_population.margins">population.margins</code></td>
<td>
<p>A data.frame including three columns, specifying the
variable name in the original dataset used for data stratification, the factor
level of the variable and the according population share. Please ensure, the
original data does not include factor levels, not present in the
population.margins. Additionally, summing up the shares of the different
levels of a variable should result in a value near 1.0. The first column must
specify the name of the stratification variable, the second the level and
the third the proportion</p>
</td></tr>
<tr><td><code id="computeWeights_+3A_standardized">standardized</code></td>
<td>
<p>If TRUE (default), the raking weights are scaled to
weights/min(weights)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes standardized raking weights to overcome biases in norm
samples. It generates weights, by drawing on the information of population
shares (e. g. for sex, ethnic group, region ...) and subsequently reduces the
influence of over-represented groups or increases underrepresented cases. The
returned weights are either raw or standardized and scaled to be larger than 0.
</p>
<p>Raking in general has a number of advantages over post stratification and it
additionally allows cNORM to draw on larger datasets, since less cases have
to be removed during stratification. To use this function, additionally to the
data, a data frame with stratification variables has to be specified. The data
frame should include a row with (a) the variable name, (b) the level of the
variable and (c) the according population proportion.
</p>


<h3>Value</h3>

<p>a vector with the standardized weights
</p>


<h3>Examples</h3>

<pre><code class='language-R'># cNORM features a dataset on vocabulary development (ppvt)
# that includes variables like sex or migration. In order
# to weight the data, we have to specify the population shares.
# According to census, the population includes 52% boys
# (factor level 1 in the ppvt dataset) and 70% / 30% of persons
# without / with a a history of migration (= 0 / 1 in the dataset).
# First we set up the popolation margins with all shares of the
# different levels:

margins &lt;- data.frame(variables = c("sex", "sex",
                                    "migration", "migration"),
                      levels = c(1, 2, 0, 1),
                      share = c(.52, .48, .7, .3))
head(margins)

# Now we use the population margins to generate weights
# through raking

weights &lt;- computeWeights(ppvt, margins)


# There are as many different weights as combinations of
# factor levels, thus only four in this specific case

unique(weights)


# To include the weights in the cNORM modelling, we have
# to pass them as weights. They are then used to set up
# weighted quantiles and as weights in the regession.

model &lt;- cnorm(raw = ppvt$raw,
               group=ppvt$group,
               weights = weights)
</code></pre>

<hr>
<h2 id='derivationTable'>Create a table based on first order derivative of the regression model for specific age</h2><span id='topic+derivationTable'></span>

<h3>Description</h3>

<p>In order to check model assumptions, a table of the first order derivative of the model
coefficients is created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derivationTable(A, model, minNorm = NULL, maxNorm = NULL, step = 0.1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derivationTable_+3A_a">A</code></td>
<td>
<p>the age</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower bound of the norm value range</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper bound of the norm value range</p>
</td></tr>
<tr><td><code id="derivationTable_+3A_step">step</code></td>
<td>
<p>Stepping parameter with lower values indicating higher precision</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with norm scores and the predicted scores based on the
derived regression function
</p>


<h3>See Also</h3>

<p>plotDerivative, derive
</p>
<p>Other predict: 
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# retrieve function for time point 6
d &lt;- derivationTable(6, cnorm.elfe, step = 0.5)

</code></pre>

<hr>
<h2 id='derive'>Derivative of regression model</h2><span id='topic+derive'></span>

<h3>Description</h3>

<p>Calculates the derivative of the location / norm value from the regression model with the first
derivative as the default. This is useful for finding violations of model assumptions and problematic
distribution features as f. e. bottom and ceiling effects, non-progressive norm scores within an
age group or in general #' intersecting percentile curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derive(model, order = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derive_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="derive_+3A_order">order</code></td>
<td>
<p>The degree of the derivate, default: 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The derived coefficients
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- cnorm(raw = elfe$raw, group = elfe$group)
derivedCoefficients &lt;- derive(m)
</code></pre>

<hr>
<h2 id='diagnostics.betabinomial'>Diagnostic Information for Beta-Binomial Model</h2><span id='topic+diagnostics.betabinomial'></span>

<h3>Description</h3>

<p>This function provides diagnostic information for a fitted beta-binomial model
from the cnorm.betabinomial function. It returns various metrics related to
model convergence, fit, and complexity. In case, age and raw scores are provided,
the function as well computes R2, rmse and bias for the norm scores based on
the manifest and predicted norm scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagnostics.betabinomial(model, age = NULL, score = NULL, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diagnostics.betabinomial_+3A_model">model</code></td>
<td>
<p>An object of class &quot;cnormBetaBinomial&quot;, typically the result of a call to cnorm.betabinomial().</p>
</td></tr>
<tr><td><code id="diagnostics.betabinomial_+3A_age">age</code></td>
<td>
<p>An optional vector with age values</p>
</td></tr>
<tr><td><code id="diagnostics.betabinomial_+3A_score">score</code></td>
<td>
<p>An optional vector with raw values</p>
</td></tr>
<tr><td><code id="diagnostics.betabinomial_+3A_weights">weights</code></td>
<td>
<p>An optional vector with weights</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AIC and BIC are calculated as:
AIC = 2k - 2ln(L)
BIC = ln(n)k - 2ln(L)
where k is the number of parameters, L is the maximum likelihood, and n is the number of observations.
</p>


<h3>Value</h3>

<p>A list containing the following diagnostic information:
</p>

<ul>
<li><p> converged: Logical indicating whether the optimization algorithm converged.
</p>
</li>
<li><p> n_evaluations: Number of function evaluations performed during optimization.
</p>
</li>
<li><p> n_gradient: Number of gradient evaluations performed during optimization.
</p>
</li>
<li><p> final_value: Final value of the objective function (negative log-likelihood).
</p>
</li>
<li><p> message: Any message returned by the optimization algorithm.
</p>
</li>
<li><p> AIC: Akaike Information Criterion.
</p>
</li>
<li><p> BIC: Bayesian Information Criterion.
</p>
</li>
<li><p> max_gradient: Maximum absolute gradient at the solution (if available).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Fit a beta-binomial model
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw)

# Get diagnostic information
diag_info &lt;- diagnostics.betabinomial(model)

# Print the diagnostic information
print(diag_info)

# Summary the diagnostic information
summary(diag_info)

# Check if the model converged
if(diag_info$converged) {
  cat("Model converged successfully.\n")
} else {
  cat("Warning: Model did not converge.\n")
}

# Compare AIC and BIC
cat("AIC:", diag_info$AIC, "\n")
cat("BIC:", diag_info$BIC, "\n")

## End(Not run)

</code></pre>

<hr>
<h2 id='elfe'>Sentence completion test from ELFE 1-6</h2><span id='topic+elfe'></span>

<h3>Description</h3>

<p>A dataset containing the raw data of 1400 students from grade 2 to 5 in the sentence
comprehension test from ELFE 1-6 (Lenhard &amp; Schneider, 2006). In this test, students
are presented lists of sentences with one gap. The student has to fill in the correct
solution by selecting from a list of 5 alternatives per sentence. The alternatives
include verbs, adjectives, nouns, pronouns and conjunctives. Each item stems from
the same word type. The text is speeded, with a time cutoff of 180 seconds. The
variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elfe
</code></pre>


<h3>Format</h3>

<p>A data frame with 1400 rows and 3 variables:
</p>

<dl>
<dt>personID</dt><dd><p>ID of the student</p>
</dd>
<dt>group</dt><dd><p>grade level, with x.5 indicating the end of the school year and x.0 indicating the middle of the school year</p>
</dd>
<dt>raw</dt><dd><p>the raw score of the student, spanning values from 0 to 28</p>
</dd>
</dl>

<p>A data frame with 1400 rows and 3 columns
</p>


<h3>Source</h3>

<p><a href="https://www.psychometrica.de/elfe2.html">https://www.psychometrica.de/elfe2.html</a>
</p>


<h3>References</h3>

<p>Lenhard, W. &amp; Schneider, W.(2006). Ein Leseverstaendnistest fuer Erst- bis Sechstklaesser. Goettingen/Germany: Hogrefe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># prepare data, retrieve model and plot percentiles
model &lt;- cnorm(elfe$group, elfe$raw)
</code></pre>

<hr>
<h2 id='getGroups'>Determine groups and group means</h2><span id='topic+getGroups'></span>

<h3>Description</h3>

<p>Helps to split the continuous explanatory variable into groups and assigns
the group mean. The groups can be split either into groups of equal size (default)
or equal number of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getGroups(x, n = NULL, equidistant = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getGroups_+3A_x">x</code></td>
<td>
<p>The continuous variable to be split</p>
</td></tr>
<tr><td><code id="getGroups_+3A_n">n</code></td>
<td>
<p>The number of groups; if NULL then the function determines a number
of groups with usually 100 cases or 3 &lt;= n &lt;= 20.</p>
</td></tr>
<tr><td><code id="getGroups_+3A_equidistant">equidistant</code></td>
<td>
<p>If set to TRUE, builds equidistant interval, otherwise (default)
with equal number of observations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with group means for each observation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1000, m = 50, sd = 10)
m &lt;- getGroups(x, n = 10)

</code></pre>

<hr>
<h2 id='getNormCurve'>Computes the curve for a specific T value</h2><span id='topic+getNormCurve'></span>

<h3>Description</h3>

<p>As with this continuous norming regression approach, raw scores are modeled as a function of age and norm score
(location), getNormCurve is a straightforward approach to show the raw score development over
age, while keeping the norm value constant. This way, e. g. academic performance or intelligence development
of a specific ability is shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNormCurve(
  norm,
  model,
  minAge = NULL,
  maxAge = NULL,
  step = 0.1,
  minRaw = NULL,
  maxRaw = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getNormCurve_+3A_norm">norm</code></td>
<td>
<p>The specific norm score, e. g. T value</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_model">model</code></td>
<td>
<p>The model from the regression modeling obtained with the cnorm function</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_minage">minAge</code></td>
<td>
<p>Age to start from</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_maxage">maxAge</code></td>
<td>
<p>Age to stop at</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_step">step</code></td>
<td>
<p>Stepping parameter for the precision when retrieving of the values, lower
values indicate higher precision (default 0.1).</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_minraw">minRaw</code></td>
<td>
<p>lower bound of the range of raw scores (default = 0)</p>
</td></tr>
<tr><td><code id="getNormCurve_+3A_maxraw">maxRaw</code></td>
<td>
<p>upper bound of raw scores</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame of the variables raw, age and norm
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)
getNormCurve(35, cnorm.elfe)
</code></pre>

<hr>
<h2 id='getNormScoreSE'>Calculates the standard error (SE) or root mean square error (RMSE) of the norm scores
In case of large datasets, both results should be almost identical</h2><span id='topic+getNormScoreSE'></span>

<h3>Description</h3>

<p>Calculates the standard error (SE) or root mean square error (RMSE) of the norm scores
In case of large datasets, both results should be almost identical
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNormScoreSE(model, type = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getNormScoreSE_+3A_model">model</code></td>
<td>
<p>a cnorm object</p>
</td></tr>
<tr><td><code id="getNormScoreSE_+3A_type">type</code></td>
<td>
<p>either '1' for the standard error senso Oosterhuis et al. (2016) or '2' for
the RMSE (default)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The standard error (SE) of the norm scores sensu Oosterhuis et al. (2016) or the RMSE
</p>


<h3>References</h3>

<p>Oosterhuis, H. E. M., van der Ark, L. A., &amp; Sijtsma, K. (2016). Sample Size Requirements for Traditional and Regression-Based Norms. Assessment, 23(2), 191202. https://doi.org/10.1177/1073191115580638
</p>

<hr>
<h2 id='log_likelihood'>Calculate the negative log-likelihood for a beta binomial regression model</h2><span id='topic+log_likelihood'></span>

<h3>Description</h3>

<p>This function computes the negative log-likelihood for a beta binomial regression model
where both the mean and standard deviation are modeled as functions of predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_likelihood(params, X, Z, y, weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_likelihood_+3A_params">params</code></td>
<td>
<p>A numeric vector containing all model parameters. The first n_beta elements
are coefficients for the mean model, and the remaining elements are
coefficients for the log-standard deviation model.</p>
</td></tr>
<tr><td><code id="log_likelihood_+3A_x">X</code></td>
<td>
<p>A matrix of predictors for the mean model.</p>
</td></tr>
<tr><td><code id="log_likelihood_+3A_z">Z</code></td>
<td>
<p>A matrix of predictors for the log-standard deviation model.</p>
</td></tr>
<tr><td><code id="log_likelihood_+3A_y">y</code></td>
<td>
<p>A numeric vector of response values.</p>
</td></tr>
<tr><td><code id="log_likelihood_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of weights for each observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The negative log-likelihood of the model.
</p>

<hr>
<h2 id='log_likelihood2'>Calculate the negative log-likelihood for a beta-binomial regression model</h2><span id='topic+log_likelihood2'></span>

<h3>Description</h3>

<p>This function computes the negative log-likelihood for a beta-binomial regression model
where both the alpha and beta parameters are modeled as functions of predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_likelihood2(params, X, Z, y, n, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_likelihood2_+3A_params">params</code></td>
<td>
<p>A numeric vector containing all model parameters. The first n_alpha elements
are coefficients for the alpha model, and the remaining elements are
coefficients for the beta model.</p>
</td></tr>
<tr><td><code id="log_likelihood2_+3A_x">X</code></td>
<td>
<p>A matrix of predictors for the alpha model.</p>
</td></tr>
<tr><td><code id="log_likelihood2_+3A_z">Z</code></td>
<td>
<p>A matrix of predictors for the beta model.</p>
</td></tr>
<tr><td><code id="log_likelihood2_+3A_y">y</code></td>
<td>
<p>A numeric vector of response values.</p>
</td></tr>
<tr><td><code id="log_likelihood2_+3A_n">n</code></td>
<td>
<p>The maximum score (number of trials in the beta-binomial distribution).</p>
</td></tr>
<tr><td><code id="log_likelihood2_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of weights for each observation. If NULL, equal weights are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses a numerically stable implementation of the beta-binomial log-probability.
It allows for weighted observations, which can be useful for various modeling scenarios.
</p>


<h3>Value</h3>

<p>The negative log-likelihood of the model.
</p>

<hr>
<h2 id='modelSummary'>Prints the results and regression function of a cnorm model</h2><span id='topic+modelSummary'></span>

<h3>Description</h3>

<p>Prints the results and regression function of a cnorm model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelSummary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modelSummary_+3A_object">object</code></td>
<td>
<p>A regression model or cnorm object</p>
</td></tr>
<tr><td><code id="modelSummary_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A report on the regression function, weights, R2 and RMSE
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>

<hr>
<h2 id='normTable'>Create a norm table based on model for specific age</h2><span id='topic+normTable'></span>

<h3>Description</h3>

<p>This function generates a norm table for a specific age based on the regression
model by assigning raw scores to norm scores. Please specify the
range of norm scores, you want to cover. A T value of 25 corresponds to a percentile
of .6. As a consequence, specifying a range of T = 25 to T = 75 would cover 98.4 
the population. Please be careful when extrapolating vertically (at the lower and
upper end of the age specific distribution). Depending on the size of your standardization
sample, extreme values with T &lt; 20 or T &gt; 80 might lead to inconsistent results.
In case a confidence coefficient (CI, default .9) and the reliability is specified,
confidence intervals are computed for the true score estimates, including a correction for
regression to the mean (Eid &amp; Schmidt, 2012, p. 272).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normTable(
  A,
  model,
  minNorm = NULL,
  maxNorm = NULL,
  minRaw = NULL,
  maxRaw = NULL,
  step = NULL,
  monotonuous = TRUE,
  CI = 0.9,
  reliability = NULL,
  pretty = T
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normTable_+3A_a">A</code></td>
<td>
<p>the age as single value or a vector of age values</p>
</td></tr>
<tr><td><code id="normTable_+3A_model">model</code></td>
<td>
<p>The regression model from the cnorm function</p>
</td></tr>
<tr><td><code id="normTable_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower bound of the norm score range</p>
</td></tr>
<tr><td><code id="normTable_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper bound of the norm score range</p>
</td></tr>
<tr><td><code id="normTable_+3A_minraw">minRaw</code></td>
<td>
<p>clipping parameter for the lower bound of raw scores</p>
</td></tr>
<tr><td><code id="normTable_+3A_maxraw">maxRaw</code></td>
<td>
<p>clipping parameter for the upper bound of raw scores</p>
</td></tr>
<tr><td><code id="normTable_+3A_step">step</code></td>
<td>
<p>Stepping parameter with lower values indicating higher precision</p>
</td></tr>
<tr><td><code id="normTable_+3A_monotonuous">monotonuous</code></td>
<td>
<p>corrects for decreasing norm scores in case of model inconsistencies (default)</p>
</td></tr>
<tr><td><code id="normTable_+3A_ci">CI</code></td>
<td>
<p>confidence coefficient, ranging from 0 to 1, default .9</p>
</td></tr>
<tr><td><code id="normTable_+3A_reliability">reliability</code></td>
<td>
<p>coefficient, ranging between  0 to 1</p>
</td></tr>
<tr><td><code id="normTable_+3A_pretty">pretty</code></td>
<td>
<p>Format table by collapsing intervals and rounding to meaningful precision</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either data.frame with norm scores, predicted raw scores and percentiles in case of simple A
value or a list #' of norm tables if vector of A values was provided
</p>


<h3>References</h3>

<p>Eid, M. &amp; Schmidt, K. (2012). Testtheorie und Testkonstruktion. Hogrefe.
</p>


<h3>See Also</h3>

<p>rawTable
</p>
<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# create single norm table
norms &lt;- normTable(3.5, cnorm.elfe, minNorm = 25, maxNorm = 75, step = 0.5)

# create list of norm tables
norms &lt;- normTable(c(2.5, 3.5, 4.5), cnorm.elfe,
  minNorm = 25, maxNorm = 75,
  step = 1, minRaw = 0, maxRaw = 26
)

# conventional norming, set age to arbitrary value
model &lt;- cnorm(raw=elfe$raw)
normTable(0, model)

</code></pre>

<hr>
<h2 id='normTable.betabinomial'>Calculate Cumulative Probabilities, Density, Percentiles, and Z-Scores for
Beta-Binomial Distribution</h2><span id='topic+normTable.betabinomial'></span>

<h3>Description</h3>

<p>This function generates a norm table for a specific ages based on the beta binomial
regression model. In case a confidence coefficient (CI, default .9) and the
reliability is specified, confidence intervals are computed for the true score
estimates, including a correction for regression to the mean (Eid &amp; Schmidt, 2012, p. 272).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normTable.betabinomial(
  model,
  ages,
  n = NULL,
  m = NULL,
  range = 3,
  CI = 0.9,
  reliability = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normTable.betabinomial_+3A_model">model</code></td>
<td>
<p>The model, which was fitted using the 'optimized.model' function.</p>
</td></tr>
<tr><td><code id="normTable.betabinomial_+3A_ages">ages</code></td>
<td>
<p>A numeric vector of age points at which to make predictions.</p>
</td></tr>
<tr><td><code id="normTable.betabinomial_+3A_n">n</code></td>
<td>
<p>The number of items resp. the maximum score.</p>
</td></tr>
<tr><td><code id="normTable.betabinomial_+3A_m">m</code></td>
<td>
<p>An optional stop criterion in table generation. Positive integer lower than n.</p>
</td></tr>
<tr><td><code id="normTable.betabinomial_+3A_range">range</code></td>
<td>
<p>The range of the norm scores in standard deviations. Default is 3. Thus, scores in the
range of +/- 3 standard deviations are considered.</p>
</td></tr>
<tr><td><code id="normTable.betabinomial_+3A_ci">CI</code></td>
<td>
<p>confidence coefficient, ranging from 0 to 1, default .9</p>
</td></tr>
<tr><td><code id="normTable.betabinomial_+3A_reliability">reliability</code></td>
<td>
<p>coefficient, ranging between  0 to 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of data frames with columns: x, Px, Pcum, Percentile, z, norm score
and possibly confidence interval
</p>

<hr>
<h2 id='plot.cnorm'>S3 function for plotting cnorm objects</h2><span id='topic+plot.cnorm'></span>

<h3>Description</h3>

<p>S3 function for plotting cnorm objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnorm'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cnorm_+3A_x">x</code></td>
<td>
<p>the cnorm object</p>
</td></tr>
<tr><td><code id="plot.cnorm_+3A_y">y</code></td>
<td>
<p>the type of plot as a string, can be one of
'raw' (1), 'norm' (2), 'curves' (3), 'percentiles' (4), 'series' (5), 'subset' (6),
or 'derivative' (7), either as a string or the according index</p>
</td></tr>
<tr><td><code id="plot.cnorm_+3A_...">...</code></td>
<td>
<p>additional parameters for the specific plotting function</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>

<hr>
<h2 id='plot.cnormBetaBinomial'>Plot cnormBetaBinomial Model with Data and Percentile Lines</h2><span id='topic+plot.cnormBetaBinomial'></span>

<h3>Description</h3>

<p>This function creates a visualization of a fitted cnormBetaBinomial model,
including the original data points manifest percentiles and specified percentile lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnormBetaBinomial'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cnormBetaBinomial_+3A_x">x</code></td>
<td>
<p>A fitted model object of class &quot;cnormBetaBinomial&quot; or &quot;cnormBetaBinomial2&quot;.</p>
</td></tr>
<tr><td><code id="plot.cnormBetaBinomial_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the plot method.
</p>

<ul>
<li><p> age A vector the age data.
</p>
</li>
<li><p> A vector of the score data.
</p>
</li>
<li><p> weights An optional numeric vector of weights for each observation.
</p>
</li>
<li><p> percentiles An optional vector with the percentiles to plot.
</p>
</li>
<li><p> points Logical indicating whether to plot the data points. Default is TRUE.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# Computing beta binomial models already displays plot
model.bb &lt;- cnorm.betabinomial(elfe$group, elfe$raw)

# Without data points
plot(model.bb, age = elfe$group, score = elfe$raw, weights=NULL, points=FALSE)


## End(Not run)
</code></pre>

<hr>
<h2 id='plot.cnormBetaBinomial2'>Plot cnormBetaBinomial Model with Data and Percentile Lines</h2><span id='topic+plot.cnormBetaBinomial2'></span>

<h3>Description</h3>

<p>This function creates a visualization of a fitted cnormBetaBinomial model,
including the original data points manifest percentiles and specified percentile lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnormBetaBinomial2'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cnormBetaBinomial2_+3A_x">x</code></td>
<td>
<p>A fitted model object of class &quot;cnormBetaBinomial&quot; or &quot;cnormBetaBinomial2&quot;.</p>
</td></tr>
<tr><td><code id="plot.cnormBetaBinomial2_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the plot method.
</p>

<ul>
<li><p> age A vector the age data.
</p>
</li>
<li><p> A vector of the score data.
</p>
</li>
<li><p> weights An optional numeric vector of weights for each observation.
</p>
</li>
<li><p> percentiles An optional vector with the percentiles to plot.
</p>
</li>
<li><p> points Logical indicating whether to plot the data points. Default is TRUE.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>

<hr>
<h2 id='plotCnorm'>General convenience plotting function</h2><span id='topic+plotCnorm'></span>

<h3>Description</h3>

<p>General convenience plotting function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCnorm(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCnorm_+3A_x">x</code></td>
<td>
<p>a cnorm object</p>
</td></tr>
<tr><td><code id="plotCnorm_+3A_y">y</code></td>
<td>
<p>the type of plot as a string, can be one of
'raw' (1), 'norm' (2), 'curves' (3), 'percentiles' (4), 'series' (5), 'subset' (6),
or 'derivative' (7), either as a string or the according index</p>
</td></tr>
<tr><td><code id="plotCnorm_+3A_...">...</code></td>
<td>
<p>additional parameters for the specific plotting function</p>
</td></tr>
</table>

<hr>
<h2 id='plotDensity'>Plot the density function per group by raw score</h2><span id='topic+plotDensity'></span>

<h3>Description</h3>

<p>This function plots density curves based on the regression model against the raw scores.
It supports both traditional continuous norming models and beta-binomial models.
The function allows for customization of the plot range and groups to be displayed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDensity(
  model,
  minRaw = NULL,
  maxRaw = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  group = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDensity_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function, a cnorm object, or a cnormBetaBinomial or cnormBetaBinomial2 object.</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_minraw">minRaw</code></td>
<td>
<p>Lower bound of the raw score. If NULL, it's automatically determined based on the model type.</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_maxraw">maxRaw</code></td>
<td>
<p>Upper bound of the raw score. If NULL, it's automatically determined based on the model type.</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_minnorm">minNorm</code></td>
<td>
<p>Lower bound of the norm score. If NULL, it's automatically determined based on the model type.</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Upper bound of the norm score. If NULL, it's automatically determined based on the model type.</p>
</td></tr>
<tr><td><code id="plotDensity_+3A_group">group</code></td>
<td>
<p>Numeric vector specifying the age groups to plot. If NULL, groups are automatically selected.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates density curves for specified age groups, allowing for easy comparison of score distributions
across different ages.
</p>
<p>For beta-binomial models, the density is based on the probability mass function, while for
traditional models, it uses a normal distribution based on the norm scores.
</p>


<h3>Value</h3>

<p>A ggplot object representing the density functions.
</p>


<h3>Note</h3>

<p>Please check for inconsistent curves, especially those showing implausible shapes
such as violations of biuniqueness in the cnorm models.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotNormCurves">plotNormCurves</a></code>, <code><a href="#topic+plotPercentiles">plotPercentiles</a></code>
</p>
<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# For traditional continuous norming model
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotDensity(result, group = c(2, 4, 6))

# For beta-binomial model
bb_model &lt;- cnorm.betabinomial(age = ppvt$age, score = ppvt$raw, n = 228)
plotDensity(bb_model)

## End(Not run)

</code></pre>

<hr>
<h2 id='plotDerivative'>Plot first order derivative of regression model</h2><span id='topic+plotDerivative'></span>

<h3>Description</h3>

<p>This function plots the scores obtained via the first order derivative of the regression model
in dependence of the norm score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDerivative(
  model,
  minAge = NULL,
  maxAge = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  stepAge = NULL,
  stepNorm = NULL,
  order = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDerivative_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function, a cnorm object.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_minage">minAge</code></td>
<td>
<p>Minimum age to start checking. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_maxage">maxAge</code></td>
<td>
<p>Maximum age for checking. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_minnorm">minNorm</code></td>
<td>
<p>Lower end of the norm score range. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Upper end of the norm score range. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_stepage">stepAge</code></td>
<td>
<p>Stepping parameter for the age check, usually 1 or 0.1; lower values indicate higher precision.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_stepnorm">stepNorm</code></td>
<td>
<p>Stepping parameter for norm scores.</p>
</td></tr>
<tr><td><code id="plotDerivative_+3A_order">order</code></td>
<td>
<p>Degree of the derivative (default = 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The results indicate the progression of the norm scores within each age group. The regression-based
modeling approach relies on the assumption of a linear progression of the norm scores. Negative scores
in the first order derivative indicate a violation of this assumption. Scores near zero are typical
for bottom and ceiling effects in the raw data.
</p>
<p>The regression models usually converge within the range of the original values. In case of vertical
and horizontal extrapolation, with increasing distance to the original data, the risk of assumption
violation increases as well.
</p>


<h3>Value</h3>

<p>A ggplot object representing the derivative of the regression function.
</p>


<h3>Note</h3>

<p>This function is currently incompatible with reversed raw score scales ('descent' option).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkConsistency">checkConsistency</a></code>, <code><a href="#topic+bestModel">bestModel</a></code>, <code><a href="#topic+derive">derive</a></code>
</p>
<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For traditional continuous norming model
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotDerivative(result, minAge=2, maxAge=5, stepAge=.2, minNorm=25, maxNorm=75, stepNorm=1)


</code></pre>

<hr>
<h2 id='plotNorm'>Plot manifest and fitted norm scores</h2><span id='topic+plotNorm'></span>

<h3>Description</h3>

<p>This function plots the manifest norm score against the fitted norm score from
the inverse regression model per group. This helps to inspect the precision
of the modeling process. The scores should not deviate too far from
the regression line. Applicable for Taylor polynomial models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNorm(
  model,
  age = NULL,
  score = NULL,
  width = NULL,
  weights = NULL,
  group = FALSE,
  minNorm = NULL,
  maxNorm = NULL,
  type = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotNorm_+3A_model">model</code></td>
<td>
<p>The regression model, usually from the 'cnorm' or 'cnorm.betabinomial' function</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_age">age</code></td>
<td>
<p>In case of beta binomial model, please provide the age vector</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_score">score</code></td>
<td>
<p>In case of beta binomial model, please provide the score vector</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_width">width</code></td>
<td>
<p>In case of beta binomial model, please provide the width for the sliding window.
If null, the function tries to determine a sensible setting.</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each
individual case. If NULL, no weights are used.</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_group">group</code></td>
<td>
<p>On optional grouping variable, use empty string for no group, the variable name
for Taylor polynomial models or a vector with the groups for beta binomial models</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_minnorm">minNorm</code></td>
<td>
<p>lower bound of fitted norm scores</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_maxnorm">maxNorm</code></td>
<td>
<p>upper bound of fitted norm scores</p>
</td></tr>
<tr><td><code id="plotNorm_+3A_type">type</code></td>
<td>
<p>Type of display: 0 = plot manifest against fitted values, 1 = plot
manifest against difference values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object representing the norm scores plot.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load example data set, compute model and plot results

# Taylor polynomial model
model &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plot(model, "norm")

# Beta binomial models; maximum number of items in elfe is n = 28
model.bb &lt;- cnorm.betabinomial(elfe$group, elfe$raw, n = 28)
plotNorm(model.bb, age = elfe$group, score = elfe$raw)

## End(Not run)

</code></pre>

<hr>
<h2 id='plotNormCurves'>Plot norm curves</h2><span id='topic+plotNormCurves'></span>

<h3>Description</h3>

<p>This function plots the norm curves based on the regression model. It supports both
Taylor polynomial models and beta-binomial models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNormCurves(
  model,
  normList = NULL,
  minAge = NULL,
  maxAge = NULL,
  step = 0.1,
  minRaw = NULL,
  maxRaw = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotNormCurves_+3A_model">model</code></td>
<td>
<p>The model from the bestModel function, a cnorm object, or a cnormBetaBinomial / cnormBetaBinomial2 object.</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_normlist">normList</code></td>
<td>
<p>Vector with norm scores to display. If NULL, default values are used.</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_minage">minAge</code></td>
<td>
<p>Age to start with checking. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_maxage">maxAge</code></td>
<td>
<p>Upper end of the age check. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_step">step</code></td>
<td>
<p>Stepping parameter for the age check, usually 1 or 0.1; lower scores indicate higher precision.</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_minraw">minRaw</code></td>
<td>
<p>Lower end of the raw score range, used for clipping implausible results. If NULL, it's automatically determined from the model.</p>
</td></tr>
<tr><td><code id="plotNormCurves_+3A_maxraw">maxRaw</code></td>
<td>
<p>Upper end of the raw score range, used for clipping implausible results. If NULL, it's automatically determined from the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please check the function for inconsistent curves: The different curves should not intersect.
Violations of this assumption are a strong indication of violations of model assumptions in
modeling the relationship between raw and norm scores.
</p>
<p>Common reasons for inconsistencies include:
1. Vertical extrapolation: Choosing extreme norm scores (e.g., scores &lt;= -3 or &gt;= 3).
2. Horizontal extrapolation: Using the model scores outside the original dataset.
3. The data cannot be modeled with the current approach, or you need another power parameter (k) or R2 for the model.
</p>


<h3>Value</h3>

<p>A ggplot object representing the norm curves.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkConsistency">checkConsistency</a></code>, <code><a href="#topic+plotDerivative">plotDerivative</a></code>, <code><a href="#topic+plotPercentiles">plotPercentiles</a></code>
</p>
<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# For Taylor continuous norming model
m &lt;- cnorm(raw = ppvt$raw, group = ppvt$group)
plotNormCurves(m, minAge=2, maxAge=5)

# For beta-binomial model
bb_model &lt;- cnorm.betabinomial(age = ppvt$age, score = ppvt$raw, n = 228)
plotNormCurves(bb_model)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotPercentiles'>Plot norm curves against actual percentiles</h2><span id='topic+plotPercentiles'></span>

<h3>Description</h3>

<p>The function plots the norm curves based on the regression model against
the actual percentiles from the raw data. As in 'plotNormCurves',
please check for inconsistent curves, especially intersections.
Violations of this assumption are a strong
indication for problems
in modeling the relationship between raw and norm scores.
In general, extrapolation (point 1 and 2) can carefully be done to a
certain degree outside the original sample, but it should in general
be handled with caution.
The original percentiles are displayed as distinct points in the according
color, the model based projection of percentiles are drawn as lines.
Please note, that the estimation of the percentiles of the raw data is done with
the quantile function with the default settings.
In case, you get 'jagged' or disorganized percentile curve, try to reduce the 'k'
and/or 't' parameter in modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPercentiles(
  model,
  minRaw = NULL,
  maxRaw = NULL,
  minAge = NULL,
  maxAge = NULL,
  raw = NULL,
  group = NULL,
  percentiles = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
  scale = NULL,
  title = NULL,
  subtitle = NULL,
  points = F
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotPercentiles_+3A_model">model</code></td>
<td>
<p>The Taylor polynomial regression model object from the cNORM</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_minraw">minRaw</code></td>
<td>
<p>Lower bound of the raw score (default = 0)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_maxraw">maxRaw</code></td>
<td>
<p>Upper bound of the raw score</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_minage">minAge</code></td>
<td>
<p>Variable to restrict the lower bound of the plot to a specific age</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_maxage">maxAge</code></td>
<td>
<p>Variable to restrict the upper bound of the plot to a specific age</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_raw">raw</code></td>
<td>
<p>The name of the raw variable</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_group">group</code></td>
<td>
<p>The name of the grouping variable; the distinct groups are automatically
determined</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_percentiles">percentiles</code></td>
<td>
<p>Vector with percentile scores, ranging from 0 to 1 (exclusive)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_scale">scale</code></td>
<td>
<p>The norm scale, either 'T', 'IQ', 'z', 'percentile' or
self defined with a double vector with the mean and standard deviation,
f. e. c(10, 3) for Wechsler scale index points; if NULL, scale information from the
data preparation is used (default)</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_title">title</code></td>
<td>
<p>custom title for plot</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_subtitle">subtitle</code></td>
<td>
<p>custom title for plot</p>
</td></tr>
<tr><td><code id="plotPercentiles_+3A_points">points</code></td>
<td>
<p>Logical indicating whether to plot the data points. Default is TRUE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>plotNormCurves, plotPercentileSeries
</p>
<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotPercentiles(result)
</code></pre>

<hr>
<h2 id='plotPercentileSeries'>Generates a series of plots with number curves by percentile for different models</h2><span id='topic+plotPercentileSeries'></span>

<h3>Description</h3>

<p>This functions makes use of 'plotPercentiles' to generate a series of plots
with different number of predictors. It draws on the information provided by the model object
to determine the bounds of the modeling (age and standard score range). It can be used as an
additional model check to determine the best fitting model. Please have a look at the
' plotPercentiles' function for further information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPercentileSeries(
  model,
  start = 1,
  end = NULL,
  group = NULL,
  percentiles = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975),
  filename = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotPercentileSeries_+3A_model">model</code></td>
<td>
<p>The Taylor polynomial regression model object from the cNORM</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_start">start</code></td>
<td>
<p>Number of predictors to start with</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_end">end</code></td>
<td>
<p>Number of predictors to end with</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_group">group</code></td>
<td>
<p>The name of the grouping variable; the distinct groups are automatically
determined</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_percentiles">percentiles</code></td>
<td>
<p>Vector with percentile scores, ranging from 0 to 1 (exclusive)</p>
</td></tr>
<tr><td><code id="plotPercentileSeries_+3A_filename">filename</code></td>
<td>
<p>Prefix of the filename. If specified, the plots are saves as
png files in the directory of the workspace, instead of displaying them</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the complete list of plots
</p>


<h3>See Also</h3>

<p>plotPercentiles
</p>
<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data set, compute model and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotPercentileSeries(result, start=4, end=6)

</code></pre>

<hr>
<h2 id='plotRaw'>Plot manifest and fitted raw scores</h2><span id='topic+plotRaw'></span>

<h3>Description</h3>

<p>The function plots the raw data against the fitted scores from
the regression model per group. This helps to inspect the precision
of the modeling process. The scores should not deviate too far from
regression line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRaw(model, group = FALSE, raw = NULL, type = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotRaw_+3A_model">model</code></td>
<td>
<p>The regression model from the 'cnorm' function</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_group">group</code></td>
<td>
<p>Should the fit be displayed by group?</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_raw">raw</code></td>
<td>
<p>Vector of the observed raw data</p>
</td></tr>
<tr><td><code id="plotRaw_+3A_type">type</code></td>
<td>
<p>Type of display: 0 = plot manifest against fitted values, 1 = plot
manifest against difference values</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotSubset">plotSubset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute model with example dataset and plot results
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotRaw(result)
</code></pre>

<hr>
<h2 id='plotSubset'>Evaluate information criteria for regression model</h2><span id='topic+plotSubset'></span>

<h3>Description</h3>

<p>This function plots various information criteria and model fit statistics against
the number of predictors or adjusted R-squared, depending on the type of plot selected.
It helps in model selection by visualizing different aspects of model performance. Models,
which did not pass the initial consistency check are depicted with an empty circle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSubset(model, type = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotSubset_+3A_model">model</code></td>
<td>
<p>The regression model from the bestModel function or a cnorm object.</p>
</td></tr>
<tr><td><code id="plotSubset_+3A_type">type</code></td>
<td>
<p>Integer specifying the type of plot to generate:
</p>

<ul>
<li><p> 0: Adjusted R2 by number of predictors (default)
</p>
</li>
<li><p> 1: Log-transformed Mallow's Cp by adjusted R2
</p>
</li>
<li><p> 2: Bayesian Information Criterion (BIC) by adjusted R2
</p>
</li>
<li><p> 3: Root Mean Square Error (RMSE) by number of predictors
</p>
</li>
<li><p> 4: Residual Sum of Squares (RSS) by number of predictors
</p>
</li>
<li><p> 5: F-test statistic for consecutive models by number of predictors
</p>
</li>
<li><p> 6: p-value for model tests by number of predictors
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates different plots to help in model selection:
</p>
<p>- For types 1 and 2 (Mallow's Cp and BIC), look for the &quot;elbow&quot; in the curve where
the information criterion begins to drop. This often indicates a good balance
between model fit and complexity.
- For type 0 (Adjusted R2), higher values indicate better fit, but be cautious
of overfitting with values approaching 1.
- For types 3 and 4 (RMSE and RSS), lower values indicate better fit.
- For type 5 (F-test), higher values suggest significant improvement with added predictors.
- For type 6 (p-values), values below the significance level (typically 0.05)
suggest significant improvement with added predictors.
</p>


<h3>Value</h3>

<p>A ggplot object representing the selected information criterion plot.
</p>


<h3>Note</h3>

<p>It's important to balance statistical measures with practical considerations and
to visually inspect the model fit using functions like <code>plotPercentiles</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bestModel">bestModel</a></code>, <code><a href="#topic+plotPercentiles">plotPercentiles</a></code>, <code><a href="#topic+printSubset">printSubset</a></code>
</p>
<p>Other plot: 
<code><a href="#topic+compare">compare</a>()</code>,
<code><a href="#topic+plot.cnorm">plot.cnorm</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial">plot.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+plot.cnormBetaBinomial2">plot.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+plotDensity">plotDensity</a>()</code>,
<code><a href="#topic+plotDerivative">plotDerivative</a>()</code>,
<code><a href="#topic+plotNorm">plotNorm</a>()</code>,
<code><a href="#topic+plotNormCurves">plotNormCurves</a>()</code>,
<code><a href="#topic+plotPercentileSeries">plotPercentileSeries</a>()</code>,
<code><a href="#topic+plotPercentiles">plotPercentiles</a>()</code>,
<code><a href="#topic+plotRaw">plotRaw</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute model with example data and plot information function
cnorm.model &lt;- cnorm(raw = elfe$raw, group = elfe$group)
plotSubset(cnorm.model)

# Plot BIC against adjusted R-squared
plotSubset(cnorm.model, type = 2)

# Plot RMSE against number of predictors
plotSubset(cnorm.model, type = 3)

</code></pre>

<hr>
<h2 id='ppvt'>Vocabulary development from 2.5 to 17</h2><span id='topic+ppvt'></span>

<h3>Description</h3>

<p>A dataset based on an unstratified sample of PPVT4 data (German adaption). The PPVT4 consists of blocks of items with
12 items each. Each item consists of 4 pictures. The test taker is given a word orally and he or she has to point out
the picture matching the oral word. Bottom and ceiling blocks of items are determined according to age and performance. For
instance, when a student knows less than 4 word from a block of 12 items, the testing stops. The sample is not identical
with the norm sample and includes doublets of cases in order to align the sample size per age group. It is
primarily intended for running the cNORM analyses with regard to modeling and stratification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppvt
</code></pre>


<h3>Format</h3>

<p>A data frame with 4542 rows and 6 variables:
</p>

<dl>
<dt>age</dt><dd><p>the chronological age of the child</p>
</dd>
<dt>sex</dt><dd><p>the sex of the test taker, 1=male, 2=female</p>
</dd>
<dt>migration</dt><dd><p>migration status of the family, 0=no, 1=yes</p>
</dd>
<dt>region</dt><dd><p>factor specifying the region, the data were collected; grouped into south, north, east and west</p>
</dd>
<dt>raw</dt><dd><p>the raw score of the student, spanning values from 0 to 228</p>
</dd>
<dt>group</dt><dd><p>age group of the child, determined by the getGroups()-function with 12 equidistant age groups</p>
</dd>
</dl>

<p>A data frame with 5600 rows and 9 columns
</p>


<h3>Source</h3>

<p><a href="https://www.psychometrica.de/ppvt4.html">https://www.psychometrica.de/ppvt4.html</a>
</p>


<h3>References</h3>

<p>Lenhard, A., Lenhard, W., Segerer, R. &amp; Suggate, S. (2015). Peabody Picture Vocabulary Test - Revision IV (Deutsche Adaption). Frankfurt a. M./Germany: Pearson Assessment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example with continuous age variable, ranked with sliding window
model.ppvt.sliding &lt;- cnorm(age=ppvt$age, raw=ppvt$raw, width=1)

# Example with age groups; you might first want to experiment with
# the granularity of the groups via the 'getGroups()' function
model.ppvt.group &lt;- cnorm(group=ppvt$group, raw=ppvt$raw) # with predefined groups
model.ppvt.group &lt;- cnorm(group=getGroups(ppvt$age, n=15, equidistant = T),
                          raw=ppvt$raw) # groups built 'on the fly'


# plot information function
plot(model.ppvt.group, "subset")

# check model consistency
checkConsistency(model.ppvt.group)

# plot percentiles
plot(model.ppvt.group, "percentiles")

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.cnormBetaBinomial'>Predict Norm Scores from Raw Scores</h2><span id='topic+predict.cnormBetaBinomial'></span>

<h3>Description</h3>

<p>This function calculates norm scores based on raw scores, age, and a fitted cnormBetaBinomial model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnormBetaBinomial'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cnormBetaBinomial_+3A_object">object</code></td>
<td>
<p>A fitted model object of class 'cnormBetaBinomial' or 'cnormBetaBinomial2'.</p>
</td></tr>
<tr><td><code id="predict.cnormBetaBinomial_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the prediction method:
</p>

<ul>
<li><p> age A numeric vector of ages, same length as raw.
</p>
</li>
<li><p> score A numeric vector of raw scores.
</p>
</li>
<li><p> range The range of the norm scores in standard deviations. Default is 3. Thus, scores in the range of +/- 3 standard deviations are considered.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first predicts the alpha and beta parameters of the beta-binomial distribution
for each age using the provided model. It then calculates the cumulative probability for
each raw score given these parameters. Finally, it converts these probabilities to the
norm scale specified in the model.
</p>


<h3>Value</h3>

<p>A numeric vector of norm scores.
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Assuming you have a fitted model named 'bb_model':
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw)
raw &lt;- c(100, 121, 97, 180)
ages &lt;- c(7, 8, 9, 10)
norm_scores &lt;- predict(model, ages, raw)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.cnormBetaBinomial2'>Predict Norm Scores from Raw Scores</h2><span id='topic+predict.cnormBetaBinomial2'></span>

<h3>Description</h3>

<p>This function calculates norm scores based on raw scores, age, and a fitted cnormBetaBinomial model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnormBetaBinomial2'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cnormBetaBinomial2_+3A_object">object</code></td>
<td>
<p>A fitted model object of class 'cnormBetaBinomial' or 'cnormBetaBinomial2'.</p>
</td></tr>
<tr><td><code id="predict.cnormBetaBinomial2_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the prediction method:
</p>

<ul>
<li><p> age A numeric vector of ages, same length as raw.
</p>
</li>
<li><p> score A numeric vector of raw scores.
</p>
</li>
<li><p> range The range of the norm scores in standard deviations. Default is 3. Thus, scores in the range of +/- 3 standard deviations are considered.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first predicts the alpha and beta parameters of the beta-binomial distribution
for each age using the provided model. It then calculates the cumulative probability for
each raw score given these parameters. Finally, it converts these probabilities to the
norm scale specified in the model.
</p>


<h3>Value</h3>

<p>A numeric vector of norm scores.
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Assuming you have a fitted model named 'bb_model':
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw)
raw &lt;- c(100, 121, 97, 180)
ages &lt;- c(7, 8, 9, 10)
norm_scores &lt;- predict(model, ages, raw)

## End(Not run)

</code></pre>

<hr>
<h2 id='predictCoefficients'>Predict mean and standard deviation for a beta binomial regression model</h2><span id='topic+predictCoefficients'></span>

<h3>Description</h3>

<p>This function generates predictions from a fitted beta binomial regression model
for new age points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictCoefficients(model, ages, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictCoefficients_+3A_model">model</code></td>
<td>
<p>An object of class &quot;cnormBetaBinomial&quot;, typically the result of a call to <code><a href="#topic+cnorm.betabinomial">cnorm.betabinomial</a></code>.</p>
</td></tr>
<tr><td><code id="predictCoefficients_+3A_ages">ages</code></td>
<td>
<p>A numeric vector of age points at which to make predictions.</p>
</td></tr>
<tr><td><code id="predictCoefficients_+3A_n">n</code></td>
<td>
<p>The maximum score to be achieved.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a fitted beta binomial regression model and generates predictions
for new age points. It applies the same standardization used in model fitting,
generates predictions on the standardized scale, and then transforms these back
to the original scale.
</p>


<h3>Value</h3>

<p>A data frame with columns:
</p>
<table role = "presentation">
<tr><td><code>age</code></td>
<td>
<p>The input age points</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Predicted mean values</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Predicted standard deviation values</p>
</td></tr>
</table>

<hr>
<h2 id='predictCoefficients2'>Predict alpha and beta parameters for a beta-binomial regression model</h2><span id='topic+predictCoefficients2'></span>

<h3>Description</h3>

<p>This function generates predictions from a fitted beta-binomial regression model
for new age points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictCoefficients2(model, ages, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictCoefficients2_+3A_model">model</code></td>
<td>
<p>An object of class &quot;cnormBetaBinomial2&quot;, typically the result of a call to cnorm.betabinomial2().</p>
</td></tr>
<tr><td><code id="predictCoefficients2_+3A_ages">ages</code></td>
<td>
<p>A numeric vector of age points at which to make predictions.</p>
</td></tr>
<tr><td><code id="predictCoefficients2_+3A_n">n</code></td>
<td>
<p>The maximum score to be achieved.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a fitted beta-binomial regression model and generates predictions
for new age points. It applies the same standardization used in model fitting,
generates predictions on the standardized scale, and then transforms these back
to the original scale.
</p>


<h3>Value</h3>

<p>A data frame with columns:
</p>
<table role = "presentation">
<tr><td><code>age</code></td>
<td>
<p>The input age points</p>
</td></tr>
<tr><td><code>a</code></td>
<td>
<p>Predicted alpha values</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>Predicted beta values</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Predicted mean values</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Predicted standard deviation values</p>
</td></tr>
</table>

<hr>
<h2 id='predictNorm'>Retrieve norm value for raw score at a specific age</h2><span id='topic+predictNorm'></span>

<h3>Description</h3>

<p>This functions numerically determines the norm score for raw scores depending on the
level of the explanatory variable A, e. g. norm scores for raw scores at given ages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictNorm(
  raw,
  A,
  model,
  minNorm = NULL,
  maxNorm = NULL,
  force = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictNorm_+3A_raw">raw</code></td>
<td>
<p>The raw value, either single numeric or numeric vector</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_a">A</code></td>
<td>
<p>the explanatory variable (e. g. age), either single numeric or numeric vector</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower bound of the norm score range</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper bound of the norm score range</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_force">force</code></td>
<td>
<p>Try to resolve missing norm scores in case of inconsistent models</p>
</td></tr>
<tr><td><code id="predictNorm_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted norm score for a raw score, either single value or vector
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)

# return norm value for raw value 21 for grade 2, month 9
specificNormValue &lt;- predictNorm(raw = 21, A = 2.75, cnorm.elfe)

# predicted norm scores for the elfe dataset
# predictNorm(elfe$raw, elfe$group, cnorm.elfe)

</code></pre>

<hr>
<h2 id='predictRaw'>Predict raw values</h2><span id='topic+predictRaw'></span>

<h3>Description</h3>

<p>Most elementary function to predict raw score based on Location (L, T score),
Age (grouping variable) and the coefficients from a regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictRaw(norm, age, coefficients, minRaw = -Inf, maxRaw = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictRaw_+3A_norm">norm</code></td>
<td>
<p>The norm score, e. g. a specific T score or a vector of scores</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_age">age</code></td>
<td>
<p>The age value or a vector of scores</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_coefficients">coefficients</code></td>
<td>
<p>The a cnorm object or the coefficients from the regression model</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_minraw">minRaw</code></td>
<td>
<p>Minimum score for the results; can be used for clipping unrealistic outcomes,
usually set to the lower bound of the range of values of the test (default: 0)</p>
</td></tr>
<tr><td><code id="predictRaw_+3A_maxraw">maxRaw</code></td>
<td>
<p>Maximum score for the results; can be used for clipping unrealistic outcomes
usually set to the upper bound of the range of values of the test</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predicted raw score or a data.frame of scores in case, lists of norm scores or age is used
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+rawTable">rawTable</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prediction of single scores
model &lt;- cnorm(raw = elfe$raw, group = elfe$group)
predictRaw(35, 3.5, model)


</code></pre>

<hr>
<h2 id='prepareData'>Prepare data for modeling in one step (convenience method)</h2><span id='topic+prepareData'></span>

<h3>Description</h3>

<p>This is a convenience method to either load the inbuilt sample dataset, or
to provide a data frame with the variables &quot;raw&quot; (for the raw scores) and &quot;group&quot;
The function ranks the data within groups, computes norm values, powers of the norm
scores and interactions. Afterwards, you can use these preprocessed data to
determine the best fitting model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepareData(
  data = NULL,
  group = "group",
  raw = "raw",
  age = "group",
  k = 4,
  t = NULL,
  width = NA,
  weights = NULL,
  scale = "T",
  descend = FALSE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prepareData_+3A_data">data</code></td>
<td>
<p>data.frame with a grouping variable named 'group' and a raw score variable
named 'raw'.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_group">group</code></td>
<td>
<p>grouping variable in the data, e. g. age groups, grades ...
Setting group = FALSE deactivates modeling in dependence of age. Use this in case you do want
conventional norm tables.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_raw">raw</code></td>
<td>
<p>the raw scores</p>
</td></tr>
<tr><td><code id="prepareData_+3A_age">age</code></td>
<td>
<p>the continuous explanatory variable; by default set to &quot;group&quot;</p>
</td></tr>
<tr><td><code id="prepareData_+3A_k">k</code></td>
<td>
<p>The power parameter, default = 4</p>
</td></tr>
<tr><td><code id="prepareData_+3A_t">t</code></td>
<td>
<p>the age power parameter (default NULL). If not set, cNORM automatically uses k. The age power parameter
can be used to specify the k to produce rectangular matrices and specify the course of scores per  independently from k</p>
</td></tr>
<tr><td><code id="prepareData_+3A_width">width</code></td>
<td>
<p>if a width is provided, the function switches to rankBySlidingWindow to determine the
observed raw scores, otherwise, ranking is done by group (default)</p>
</td></tr>
<tr><td><code id="prepareData_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each individual case. It can be used
to compensate for moderate imbalances due to insufficient norm data stratification. Weights should be numerical
and positive. Please use the 'computeWeights' function for this purpose.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as well,
be provided f. e. c(10, 3) for Wechsler scale index point</p>
</td></tr>
<tr><td><code id="prepareData_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="prepareData_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>rankBySlidingWindow</code>, <code>rankByGroup</code>, <code>bestModel</code>,
<code>computePowers</code> and <code>prepareData</code> are usually not called directly, but accessed
through other functions like <code>cnorm</code>.
</p>


<h3>Value</h3>

<p>data frame including the norm scores, powers and interactions of the norm score and
grouping variable
</p>


<h3>See Also</h3>

<p>Other prepare: 
<code><a href="#topic+computePowers">computePowers</a>()</code>,
<code><a href="#topic+rankByGroup">rankByGroup</a>()</code>,
<code><a href="#topic+rankBySlidingWindow">rankBySlidingWindow</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># conducts ranking and computation of powers and interactions with the 'elfe' dataset
data.elfe &lt;- prepareData(elfe)

# use vectors instead of data frame
data.elfe &lt;- prepareData(raw=elfe$raw, group=elfe$group)

# variable names can be specified as well, here with the BMI data included in the package
## Not run: 
data.bmi &lt;- prepareData(CDC, group = "group", raw = "bmi", age = "age")

## End(Not run)

# modeling with only one group with the 'elfe' dataset as an example
# this results in conventional norming
data.elfe2 &lt;- prepareData(data = elfe, group = FALSE)
m &lt;- bestModel(data.elfe2)
</code></pre>

<hr>
<h2 id='prettyPrint'>Format raw and norm tables
The function takes a raw or norm table, condenses intervals at the bottom and top
and round the numbers to meaningful interval.</h2><span id='topic+prettyPrint'></span>

<h3>Description</h3>

<p>Format raw and norm tables
The function takes a raw or norm table, condenses intervals at the bottom and top
and round the numbers to meaningful interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prettyPrint(table)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prettyPrint_+3A_table">table</code></td>
<td>
<p>The table to format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>formatted table
</p>

<hr>
<h2 id='print.cnorm'>S3 method for printing model selection information</h2><span id='topic+print.cnorm'></span>

<h3>Description</h3>

<p>After conducting the model fitting procedure on the data set, the best fitting
model has to be chosen. The print function shows the R2 and other information
on the different best fitting models with increasing number of predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnorm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.cnorm_+3A_x">x</code></td>
<td>
<p>The model from the 'bestModel' function or a cnorm object</p>
</td></tr>
<tr><td><code id="print.cnorm_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with information criteria
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>

<hr>
<h2 id='printSubset'>Print Model Selection Information</h2><span id='topic+printSubset'></span>

<h3>Description</h3>

<p>Displays R^2 and other metrics for models with varying predictors, aiding in choosing the best-fitting model
after model fitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>printSubset(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="printSubset_+3A_x">x</code></td>
<td>
<p>Model output from 'bestModel' or a cnorm object.</p>
</td></tr>
<tr><td><code id="printSubset_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Table with model information criteria.
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using cnorm object from sample data
result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
printSubset(result)
</code></pre>

<hr>
<h2 id='rangeCheck'>Check for horizontal and vertical extrapolation</h2><span id='topic+rangeCheck'></span>

<h3>Description</h3>

<p>Regression model only work in a specific range and extrapolation horizontally (outside
the original range) or vertically (extreme norm scores) might lead to inconsistent
results. The function generates a message, indicating extrapolation and the range of the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rangeCheck(
  object,
  minAge = NULL,
  maxAge = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  digits = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rangeCheck_+3A_object">object</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_minage">minAge</code></td>
<td>
<p>The lower age bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_maxage">maxAge</code></td>
<td>
<p>The upper age bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_minnorm">minNorm</code></td>
<td>
<p>The lower norm value bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_maxnorm">maxNorm</code></td>
<td>
<p>The upper norm value bound</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_digits">digits</code></td>
<td>
<p>The precision for rounding the norm and age data</p>
</td></tr>
<tr><td><code id="rangeCheck_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the report
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- cnorm(raw = elfe$raw, group = elfe$group)
rangeCheck(m)
</code></pre>

<hr>
<h2 id='rankByGroup'>Determine the norm scores of the participants in each subsample</h2><span id='topic+rankByGroup'></span>

<h3>Description</h3>

<p>This is the initial step, usually done in all kinds of test norming projects,
after the scale is constructed and the norm sample is established. First,
the data is grouped according to a grouping variable and afterwards, the percentile
for each raw value is retrieved. The percentile can be used for the modeling
procedure, but in case, the samples to not deviate too much from normality,
T, IQ or z scores can be computed via a normal rank procedure based on the
inverse cumulative normal distribution. In case of bindings, we use the medium rank
and there are different methods for estimating the percentiles (default RankIt).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankByGroup(
  data = NULL,
  group = "group",
  raw = "raw",
  weights = NULL,
  method = 4,
  scale = "T",
  descend = FALSE,
  descriptives = TRUE,
  na.rm = TRUE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rankByGroup_+3A_data">data</code></td>
<td>
<p>data.frame with norm sample data. If no data.frame is provided, the raw score
and group vectors are directly used</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_group">group</code></td>
<td>
<p>name of the grouping variable (default 'group') or numeric vector, e. g. grade, setting
group to FALSE cancels grouping (data is treated as one group)</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_raw">raw</code></td>
<td>
<p>name of the raw value variable (default 'raw') or numeric vector</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each individual case. It can be used
to compensate for moderate imbalances due to insufficient norm data stratification. Weights should be numerical
and positive.  Please use the 'computeWeights' function for this purpose.</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as well,
be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_descriptives">descriptives</code></td>
<td>
<p>If set to TRUE (default), information in n, mean, median and
standard deviation per group is added to each observation</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_na.rm">na.rm</code></td>
<td>
<p>remove values, where the percentiles could not be estimated,
most likely happens in the context of weighting</p>
</td></tr>
<tr><td><code id="rankByGroup_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the dataset with the percentiles and norm scales per group
</p>


<h3>Remarks on using covariates</h3>

<p>So far the inclusion of a binary covariate is experimental and far from optimized.
The according variable name has to be specified in the ranking procedure
and the modeling includes this in the further process. At the moment, during ranking
the data are split into the according cells group x covariate, which leads to small
sample sizes. Please take care to have enough cases in each combination. Additionally,
covariates can lead to unstable modeling solutions. The question, if it is really
reasonable to include covariates when norming a test is a decision beyond the pure data
modeling. Please use with care or alternatively split the dataset into the two groups
beforehand and model them separately.
</p>
<p>The functions <code>rankBySlidingWindow</code>, <code>rankByGroup</code>, <code>bestModel</code>,
<code>computePowers</code> and <code>prepareData</code> are usually not called directly, but accessed
through other functions like <code>cnorm</code>.
</p>


<h3>See Also</h3>

<p>rankBySlidingWindow, computePowers, computeWeights, weighted.rank
</p>
<p>Other prepare: 
<code><a href="#topic+computePowers">computePowers</a>()</code>,
<code><a href="#topic+prepareData">prepareData</a>()</code>,
<code><a href="#topic+rankBySlidingWindow">rankBySlidingWindow</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Transformation with default parameters: RankIt and converting to T scores
data.elfe &lt;- rankByGroup(elfe, group = "group") # using a data frame with vector names
data.elfe2 &lt;- rankByGroup(raw=elfe$raw, group=elfe$group) # use vectors for raw score and group

# Transformation into Wechsler scores with Yu &amp; Huang (2001) ranking procedure
data.elfe &lt;- rankByGroup(raw = elfe$raw, group = elfe$group, method = 7, scale = c(10, 3))

# cNORM can as well be used for conventional norming, in case no group is given
d &lt;- rankByGroup(raw = elfe$raw)
d &lt;- computePowers(d)
m &lt;- bestModel(d)
rawTable(0, m) # please use an arbitrary value for age when generating the tables
</code></pre>

<hr>
<h2 id='rankBySlidingWindow'>Determine the norm scores of the participants by sliding window</h2><span id='topic+rankBySlidingWindow'></span>

<h3>Description</h3>

<p>The function retrieves all individuals in the predefined age range (x +/- width/2)
around each case and ranks that individual based on this individually drawn sample.
This function can be directly used with a continuous age variable in order to avoid
grouping. When collecting data on the basis of a continuous age variable, cases
located far from the mean age of the group receive distorted percentiles when building
discrete groups and generating percentiles with the traditional approach. The distortion
increases with distance from the group mean and this effect can be avoided by the
sliding window. Nonetheless, please ensure, that the optional grouping variable in fact
represents the correct mean age of the respective age groups, as this variable is
later on used for displaying the manifest data in the percentile plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankBySlidingWindow(
  data = NULL,
  age = "age",
  raw = "raw",
  weights = NULL,
  width,
  method = 4,
  scale = "T",
  descend = FALSE,
  descriptives = TRUE,
  nGroup = 0,
  group = NA,
  na.rm = TRUE,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rankBySlidingWindow_+3A_data">data</code></td>
<td>
<p>data.frame with norm sample data</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_age">age</code></td>
<td>
<p>the continuous age variable. Setting 'age' to FALSE inhibits computation of
powers of age and the interactions</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_raw">raw</code></td>
<td>
<p>name of the raw value variable (default 'raw')</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each individual case. It can be used
to compensate for moderate imbalances due to insufficient norm data stratification. Weights should be numerical
and positive. It can be resource intense when applied to the sliding window. Please use the 'computeWeights' function for this purpose.</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_width">width</code></td>
<td>
<p>the width of the sliding window</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as well,
be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_descriptives">descriptives</code></td>
<td>
<p>If set to TRUE (default), information in n, mean, median and
standard deviation per group is added to each observation</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_ngroup">nGroup</code></td>
<td>
<p>If set to a positive value, a grouping variable is created with the desired number of
equi distant groups, named by the group mean age of each group. It creates the
column 'group' in the data.frame and in case, there is already one with that name,
overwrites it.</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_group">group</code></td>
<td>
<p>Optional parameter for providing the name of the grouping variable (if present; overwritten
if ngroups is used)</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_na.rm">na.rm</code></td>
<td>
<p>remove values, where the percentiles could not be estimated,
most likely happens in the context of weighting</p>
</td></tr>
<tr><td><code id="rankBySlidingWindow_+3A_silent">silent</code></td>
<td>
<p>set to TRUE to suppress messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In case of bindings, the function uses the medium rank and applies the algorithms
already described in the <code><a href="#topic+rankByGroup">rankByGroup</a></code> function. At the upper and lower end of the
data sample, the sliding stops and the sample is drawn from the interval min + width and
max - width, respectively.
</p>


<h3>Value</h3>

<p>the dataset with the individual percentiles and norm scores
</p>


<h3>Remarks on using covariates</h3>

<p>So far the inclusion of a binary covariate is experimental and far from optimized.
The according variable name has to be specified in the ranking procedure
and the modeling includes this in the further process. At the moment, during ranking
the data are split into the according degrees of the covariate and the ranking is done
separately. This may lead to small sample sizes. Please take care to have enough cases in each combination. Additionally,
covariates can lead to unstable modeling solutions. The question, if it is really
reasonable to include covariates when norming a test is a decision beyond the pure data
modeling. Please use with care or alternatively split the dataset into the two groups
beforehand and model them separately.
</p>
<p>The functions <code>rankBySlidingWindow</code>, <code>rankByGroup</code>, <code>bestModel</code>,
<code>computePowers</code> and <code>prepareData</code> are usually not called directly, but accessed
through other functions like <code>cnorm</code>.
</p>


<h3>See Also</h3>

<p>rankByGroup, computePowers, computeWeights, weighted.rank, weighted.quantile
</p>
<p>Other prepare: 
<code><a href="#topic+computePowers">computePowers</a>()</code>,
<code><a href="#topic+prepareData">prepareData</a>()</code>,
<code><a href="#topic+rankByGroup">rankByGroup</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Transformation using a sliding window
data.elfe2 &lt;- rankBySlidingWindow(relfe, raw = "raw", age = "group", width = 0.5)

# Comparing this to the traditional approach should give us exactly the same
# values, since the sample dataset only has a grouping variable for age
data.elfe &lt;- rankByGroup(elfe, group = "group")
mean(data.elfe$normValue - data.elfe2$normValue)

## End(Not run)
</code></pre>

<hr>
<h2 id='rawTable'>Create a table with norm scores assigned to raw scores for a specific age based on the regression model</h2><span id='topic+rawTable'></span>

<h3>Description</h3>

<p>This function is comparable to 'normTable', despite it reverses the assignment:
A table with raw scores and the according norm scores for a specific age based on the regression
model is generated. This way, the inverse function of the regression model is solved numerically with
brute force. Please specify the range of raw values, you want to cover. With higher precision
and smaller stepping, this function becomes computational intensive.
In case a confidence coefficient (CI, default .9) and the reliability is specified,
confidence intervals are computed for the true score estimates, including a correction for
regression to the mean (Eid &amp; Schmidt, 2012, p. 272).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rawTable(
  A,
  model,
  minRaw = NULL,
  maxRaw = NULL,
  minNorm = NULL,
  maxNorm = NULL,
  step = 1,
  monotonuous = TRUE,
  CI = 0.9,
  reliability = NULL,
  pretty = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rawTable_+3A_a">A</code></td>
<td>
<p>the age, either single value or vector with age values</p>
</td></tr>
<tr><td><code id="rawTable_+3A_model">model</code></td>
<td>
<p>The regression model or a cnorm object</p>
</td></tr>
<tr><td><code id="rawTable_+3A_minraw">minRaw</code></td>
<td>
<p>The lower bound of the raw score range</p>
</td></tr>
<tr><td><code id="rawTable_+3A_maxraw">maxRaw</code></td>
<td>
<p>The upper bound of the raw score range</p>
</td></tr>
<tr><td><code id="rawTable_+3A_minnorm">minNorm</code></td>
<td>
<p>Clipping parameter for the lower bound of norm scores (default 25)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_maxnorm">maxNorm</code></td>
<td>
<p>Clipping parameter for the upper bound of norm scores (default 25)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_step">step</code></td>
<td>
<p>Stepping parameter for the raw scores (default 1)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_monotonuous">monotonuous</code></td>
<td>
<p>corrects for decreasing norm scores in case of model inconsistencies (default)</p>
</td></tr>
<tr><td><code id="rawTable_+3A_ci">CI</code></td>
<td>
<p>confidence coefficient, ranging from 0 to 1, default .9</p>
</td></tr>
<tr><td><code id="rawTable_+3A_reliability">reliability</code></td>
<td>
<p>coefficient, ranging between  0 to 1</p>
</td></tr>
<tr><td><code id="rawTable_+3A_pretty">pretty</code></td>
<td>
<p>Format table by collapsing intervals and rounding to meaningful precision</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either data.frame with raw scores and the predicted norm scores in case of simple A value or a list
of norm tables if vector of A values was provided
</p>


<h3>References</h3>

<p>Eid, M. &amp; Schmidt, K. (2012). Testtheorie und Testkonstruktion. Hogrefe.
</p>


<h3>See Also</h3>

<p>normTable
</p>
<p>Other predict: 
<code><a href="#topic+derivationTable">derivationTable</a>()</code>,
<code><a href="#topic+getNormCurve">getNormCurve</a>()</code>,
<code><a href="#topic+normTable">normTable</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial">predict.cnormBetaBinomial</a>()</code>,
<code><a href="#topic+predict.cnormBetaBinomial2">predict.cnormBetaBinomial2</a>()</code>,
<code><a href="#topic+predictNorm">predictNorm</a>()</code>,
<code><a href="#topic+predictRaw">predictRaw</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate cnorm object from example data
cnorm.elfe &lt;- cnorm(raw = elfe$raw, group = elfe$group)
# generate a norm table for the raw value range from 0 to 28 for the time point month 7 of grade 3
table &lt;- rawTable(3 + 7 / 12, cnorm.elfe, minRaw = 0, maxRaw = 28)

# generate several raw tables
table &lt;- rawTable(c(2.5, 3.5, 4.5), cnorm.elfe, minRaw = 0, maxRaw = 28)

# additionally compute confidence intervals
table &lt;- rawTable(c(2.5, 3.5, 4.5), cnorm.elfe, minRaw = 0, maxRaw = 28, CI = .9, reliability = .94)

# conventional norming, set age to arbitrary value
model &lt;- cnorm(raw=elfe$raw)
rawTable(0, model)

</code></pre>

<hr>
<h2 id='regressionFunction'>Regression function</h2><span id='topic+regressionFunction'></span>

<h3>Description</h3>

<p>The method builds the regression function for the regression model,
including the beta weights.
It can be used to predict the raw scores based on age and location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regressionFunction(model, raw = NULL, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="regressionFunction_+3A_model">model</code></td>
<td>
<p>The regression model from the bestModel function or a cnorm object</p>
</td></tr>
<tr><td><code id="regressionFunction_+3A_raw">raw</code></td>
<td>
<p>The name of the raw value variable (default 'raw')</p>
</td></tr>
<tr><td><code id="regressionFunction_+3A_digits">digits</code></td>
<td>
<p>Number of digits for formatting the coefficients</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The regression formula as a string
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+summary.cnorm">summary.cnorm</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>result &lt;- cnorm(raw = elfe$raw, group = elfe$group)
regressionFunction(result)
</code></pre>

<hr>
<h2 id='simMean'>Simulate mean per age</h2><span id='topic+simMean'></span>

<h3>Description</h3>

<p>Simulate mean per age
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simMean(age)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simMean_+3A_age">age</code></td>
<td>
<p>the age variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return predicted means
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- simMean(a)

## End(Not run)
</code></pre>

<hr>
<h2 id='simSD'>Simulate sd per age</h2><span id='topic+simSD'></span>

<h3>Description</h3>

<p>Simulate sd per age
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simSD(age)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simSD_+3A_age">age</code></td>
<td>
<p>the age variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return predicted sd
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- simSD(a)

## End(Not run)
</code></pre>

<hr>
<h2 id='simulateRasch'>Simulate raw test scores based on Rasch model</h2><span id='topic+simulateRasch'></span>

<h3>Description</h3>

<p>For testing purposes only:
The function simulates raw test scores based on a virtual Rasch based test with n results per
age group, an evenly distributed age variable, items.n test items with a simulated difficulty and
standard deviation. The development trajectories over age group are modeled by a curve linear
function of age, with at first fast progression, which slows down over age, and a slightly increasing
standard deviation in order to model a scissor effects. The item difficulties can be accessed via $theta
and the raw data via $data of the returned object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRasch(
  data = NULL,
  n = 100,
  minAge = 1,
  maxAge = 7,
  items.n = 21,
  items.m = 0,
  items.sd = 1,
  Theta = "random",
  width = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateRasch_+3A_data">data</code></td>
<td>
<p>data.frame from previous simulations for recomputation (overrides n, minAge, maxAge)</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_n">n</code></td>
<td>
<p>The sample size per age group</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_minage">minAge</code></td>
<td>
<p>The minimum age (default 1)</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_maxage">maxAge</code></td>
<td>
<p>The maximum age (default 7)</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_items.n">items.n</code></td>
<td>
<p>The number of items of the test</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_items.m">items.m</code></td>
<td>
<p>The mean difficulty of the items</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_items.sd">items.sd</code></td>
<td>
<p>The standard deviation of the item difficulty</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_theta">Theta</code></td>
<td>
<p>irt scales difficulty parameters, either &quot;random&quot; for drawing a random sample,
&quot;even&quot; for evenly distributed or a set of predefined values, which then overrides the item.n
parameters</p>
</td></tr>
<tr><td><code id="simulateRasch_+3A_width">width</code></td>
<td>
<p>The width of the window size for the continuous age per group; +- 1/2 width around group
center
on items.m and item.sd; if set to FALSE, the distribution is not drawn randomly but normally nonetheless</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the simulated data and thetas
</p>

<dl>
<dt>data</dt><dd><p>the data.frame with only age, group and raw</p>
</dd>
<dt>sim</dt><dd><p>the complete simulated data with item level results</p>
</dd>
<dt>theta</dt><dd><p>the difficulty of the items</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># simulate data for a rather easy test (m = -1.0)
sim &lt;- simulateRasch(n=150, minAge=1,
                     maxAge=7, items.n = 30, items.m = -1.0,
                     items.sd = 1, Theta = "random", width = 1.0)

# Show item difficulties
mean(sim$theta)
sd(sim$theta)
hist(sim$theta)

# Plot raw scores
boxplot(raw~group, data=sim$data)

# Model data
data &lt;- prepareData(sim$data, age="age")
model &lt;- bestModel(data, k = 4)
printSubset(model)
plotSubset(model, type=0)
</code></pre>

<hr>
<h2 id='standardize'>Standardize a numeric vector</h2><span id='topic+standardize'></span>

<h3>Description</h3>

<p>This function standardizes a numeric vector by subtracting the mean
and dividing by the standard deviation. The resulting vector will have
a mean of 0 and a standard deviation of 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardize(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardize_+3A_x">x</code></td>
<td>
<p>A numeric vector to be standardized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of the same length as x, containing the standardized values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- c(1, 2, 3, 4, 5)
standardized_data &lt;- standardize(data)
print(standardized_data)

</code></pre>

<hr>
<h2 id='standardizeRakingWeights'>Function for standardizing raking weights
Raking weights get divided by the smallest weight. Thereby, all weights
become larger or equal to 1 without changing the ratio of the weights
to each other.</h2><span id='topic+standardizeRakingWeights'></span>

<h3>Description</h3>

<p>Function for standardizing raking weights
Raking weights get divided by the smallest weight. Thereby, all weights
become larger or equal to 1 without changing the ratio of the weights
to each other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardizeRakingWeights(weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardizeRakingWeights_+3A_weights">weights</code></td>
<td>
<p>Raking weights computed by computeWeights()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the standardized weights
</p>

<hr>
<h2 id='subsample_lm'>K-fold Resampled Coefficient Estimation for Linear Regression</h2><span id='topic+subsample_lm'></span>

<h3>Description</h3>

<p>Performs k-fold resampling to estimate averaged coefficients for linear regression.
The coefficients are averaged across k different subsets of the data to provide
more stable estimates. For small samples (n &lt; 100), returns a standard linear model instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsample_lm(text, data, weights, k = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="subsample_lm_+3A_text">text</code></td>
<td>
<p>A character string or formula specifying the model to be fitted</p>
</td></tr>
<tr><td><code id="subsample_lm_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="subsample_lm_+3A_weights">weights</code></td>
<td>
<p>Optional numeric vector of weights. If NULL, unweighted regression is performed</p>
</td></tr>
<tr><td><code id="subsample_lm_+3A_k">k</code></td>
<td>
<p>Integer specifying the number of resampling folds (default = 10)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function splits the data into k subsets, fits a linear model on k-1 subsets,
and stores the coefficients. This process is repeated k times, and the final
coefficients are averaged across all iterations to provide more stable estimates.
</p>


<h3>Value</h3>

<p>An object of class 'lm' with averaged coefficients from k-fold resampling.
For small samples, returns a standard lm object.
</p>

<hr>
<h2 id='summary.cnorm'>S3 method for printing the results and regression function of a cnorm model</h2><span id='topic+summary.cnorm'></span>

<h3>Description</h3>

<p>S3 method for printing the results and regression function of a cnorm model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnorm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.cnorm_+3A_object">object</code></td>
<td>
<p>A regression model or cnorm object</p>
</td></tr>
<tr><td><code id="summary.cnorm_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A report on the regression function, weights, R2 and RMSE
</p>


<h3>See Also</h3>

<p>Other model: 
<code><a href="#topic+bestModel">bestModel</a>()</code>,
<code><a href="#topic+checkConsistency">checkConsistency</a>()</code>,
<code><a href="#topic+cnorm.cv">cnorm.cv</a>()</code>,
<code><a href="#topic+derive">derive</a>()</code>,
<code><a href="#topic+modelSummary">modelSummary</a>()</code>,
<code><a href="#topic+print.cnorm">print.cnorm</a>()</code>,
<code><a href="#topic+printSubset">printSubset</a>()</code>,
<code><a href="#topic+rangeCheck">rangeCheck</a>()</code>,
<code><a href="#topic+regressionFunction">regressionFunction</a>()</code>
</p>

<hr>
<h2 id='summary.cnormBetaBinomial'>Summarize a Beta-Binomial Continuous Norming Model</h2><span id='topic+summary.cnormBetaBinomial'></span>

<h3>Description</h3>

<p>This function provides a summary of a fitted beta-binomial continuous norming model,
including model fit statistics, convergence information, and parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnormBetaBinomial'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.cnormBetaBinomial_+3A_object">object</code></td>
<td>
<p>An object of class &quot;cnormBetaBinomial&quot; or &quot;cnormBetaBinomial2&quot;, typically
the result of a call to <code><a href="#topic+cnorm.betabinomial">cnorm.betabinomial</a></code>.</p>
</td></tr>
<tr><td><code id="summary.cnormBetaBinomial_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the summary method:
</p>

<ul>
<li><p> age An optional numeric vector of age values corresponding to the raw scores. If provided along with <code>raw</code>, additional fit statistics (R-squared, RMSE, bias) will be calculated.
</p>
</li>
<li><p> score An optional numeric vector of raw scores. Must be provided if <code>age</code> is given.
</p>
</li>
<li><p> weights An optional numeric vector of weights for each observation.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary includes:
</p>

<ul>
<li><p> Basic model information (type, number of observations, number of parameters)
</p>
</li>
<li><p> Model fit statistics (log-likelihood, AIC, BIC)
</p>
</li>
<li><p> R-squared, RMSE, and bias (if age and raw scores are provided)
in comparison to manifest norm scores
</p>
</li>
<li><p> Convergence information
</p>
</li>
<li><p> Parameter estimates with standard errors, z-values, and p-values
</p>
</li></ul>



<h3>Value</h3>

<p>Invisibly returns a list containing detailed diagnostic information about the model.
The function primarily produces printed output summarizing the model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cnorm.betabinomial">cnorm.betabinomial</a></code>, <code><a href="#topic+diagnostics.betabinomial">diagnostics.betabinomial</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw, n = 228)
summary(model)

# Including R-squared, RMSE, and bias in the summary:
summary(model, age = ppvt$age, score = ppvt$raw)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.cnormBetaBinomial2'>Summarize a Beta-Binomial Continuous Norming Model</h2><span id='topic+summary.cnormBetaBinomial2'></span>

<h3>Description</h3>

<p>This function provides a summary of a fitted beta-binomial continuous norming model,
including model fit statistics, convergence information, and parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cnormBetaBinomial2'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.cnormBetaBinomial2_+3A_object">object</code></td>
<td>
<p>An object of class &quot;cnormBetaBinomial&quot; or &quot;cnormBetaBinomial2&quot;, typically
the result of a call to <code><a href="#topic+cnorm.betabinomial">cnorm.betabinomial</a></code>.</p>
</td></tr>
<tr><td><code id="summary.cnormBetaBinomial2_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the summary method:
</p>

<ul>
<li><p> age An optional numeric vector of age values corresponding to the raw scores. If provided along with <code>raw</code>, additional fit statistics (R-squared, RMSE, bias) will be calculated.
</p>
</li>
<li><p> score An optional numeric vector of raw scores. Must be provided if <code>age</code> is given.
</p>
</li>
<li><p> weights An optional numeric vector of weights for each observation.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary includes:
</p>

<ul>
<li><p> Basic model information (type, number of observations, number of parameters)
</p>
</li>
<li><p> Model fit statistics (log-likelihood, AIC, BIC)
</p>
</li>
<li><p> R-squared, RMSE, and bias (if age and raw scores are provided)
in comparison to manifest norm scores
</p>
</li>
<li><p> Convergence information
</p>
</li>
<li><p> Parameter estimates with standard errors, z-values, and p-values
</p>
</li></ul>



<h3>Value</h3>

<p>Invisibly returns a list containing detailed diagnostic information about the model.
The function primarily produces printed output summarizing the model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cnorm.betabinomial">cnorm.betabinomial</a></code>, <code><a href="#topic+diagnostics.betabinomial">diagnostics.betabinomial</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
model &lt;- cnorm.betabinomial(ppvt$age, ppvt$raw, n = 228)
summary(model)

# Including R-squared, RMSE, and bias in the summary:
summary(model, age = ppvt$age, raw = ppvt$raw)

## End(Not run)
</code></pre>

<hr>
<h2 id='taylorSwift'>Swiftly compute Taylor regression models for distribution free continuous norming</h2><span id='topic+taylorSwift'></span>

<h3>Description</h3>

<p>Conducts distribution free continuous norming and aims to find a fitting model. Raw data are modelled as a Taylor polynomial
of powers of age and location and their interactions. In addition to the
raw scores, either provide a numeric vector for the grouping information (group)
for the ranking of the raw scores. You can adjust the grade of smoothing of the regression model by setting the k, t and terms
parameter. In general, increasing k and t leads to a higher fit, while lower values lead to more smoothing. If both parameters
are missing, taylorSwift uses k = 5 and t = 3 by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taylorSwift(
  raw = NULL,
  group = NULL,
  age = NULL,
  width = NA,
  weights = NULL,
  scale = "T",
  method = 4,
  descend = FALSE,
  k = NULL,
  t = NULL,
  terms = 0,
  R2 = NULL,
  plot = TRUE,
  extensive = TRUE,
  subsampling = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="taylorSwift_+3A_raw">raw</code></td>
<td>
<p>Numeric vector of raw scores</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_group">group</code></td>
<td>
<p>Numeric vector of grouping variable, e. g. grade. If no group
or age variable is provided, conventional norming is applied</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_age">age</code></td>
<td>
<p>Numeric vector with chronological age, please additionally specify
width of window</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_width">width</code></td>
<td>
<p>Size of the sliding window in case an age vector is used</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_weights">weights</code></td>
<td>
<p>Vector or variable name in the dataset with weights for each
individual case. It can be used to compensate for moderate imbalances due to
insufficient norm data stratification. Weights should be numerical and positive.</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_scale">scale</code></td>
<td>
<p>type of norm scale, either T (default), IQ, z or percentile (= no
transformation); a double vector with the mean and standard deviation can as
well, be provided f. e. c(10, 3) for Wechsler scale index points</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_method">method</code></td>
<td>
<p>Ranking method in case of bindings, please provide an index,
choosing from the following methods: 1 = Blom (1958), 2 = Tukey (1949),
3 = Van der Warden (1952), 4 = Rankit (default), 5 = Levenbach (1953),
6 = Filliben (1975), 7 = Yu &amp; Huang (2001)</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_descend">descend</code></td>
<td>
<p>ranking order (default descent = FALSE): inverses the
ranking order with higher raw scores getting lower norm scores; relevant
for example when norming error scores, where lower scores mean higher
performance</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_k">k</code></td>
<td>
<p>The power constant. Higher values result in more detailed approximations
but have the danger of over-fit (max = 6). If not set, it uses t and if both
parameters are NULL, k is set to 5.</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_t">t</code></td>
<td>
<p>The age power parameter (max = 6). If not set, it uses k and if both
parameters are NULL, k is set to 3, since age trajectories are most often well
captured by cubic polynomials.</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_terms">terms</code></td>
<td>
<p>Selection criterion for model building. The best fitting model with
this number of terms is used</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_r2">R2</code></td>
<td>
<p>Adjusted R square as a stopping criterion for the model building
(default R2 = 0.99)</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_plot">plot</code></td>
<td>
<p>Default TRUE; plots the regression model and prints report</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_extensive">extensive</code></td>
<td>
<p>If TRUE, screen models for consistency and - if possible, exclude inconsistent ones</p>
</td></tr>
<tr><td><code id="taylorSwift_+3A_subsampling">subsampling</code></td>
<td>
<p>If TRUE (default), model coefficients are calculated using 10-folds and averaged across the folds.
This produces more robust estimates with a slight increase in bias.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cnorm object including the ranked raw data and the regression model
</p>


<h3>References</h3>


<ol>
<li><p> Gary, S. &amp; Lenhard, W. (2021). In norming we trust. Diagnostica.
</p>
</li>
<li><p> Gary, S., Lenhard, W. &amp; Lenhard, A. (2021). Modelling Norm Scores with the cNORM Package in R. Psych, 3(3), 501-521. https://doi.org/10.3390/psych3030033
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Suggate, S. &amp; Segerer, R. (2016). A continuous solution to the norming problem. Assessment, Online first, 1-14. doi:10.1177/1073191116656437
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Gary, S. (2018). Continuous Norming (cNORM). The Comprehensive R Network, Package cNORM, available: https://CRAN.R-project.org/package=cNORM
</p>
</li>
<li><p> Lenhard, A., Lenhard, W., Gary, S. (2019). Continuous norming of psychometric tests: A simulation study of parametric and semi-parametric approaches. PLoS ONE, 14(9),  e0222279. doi:10.1371/journal.pone.0222279
</p>
</li>
<li><p> Lenhard, W., &amp; Lenhard, A. (2020). Improvement of Norm Score Quality via Regression-Based Continuous Norming. Educational and Psychological Measurement(Online First), 1-33. https://doi.org/10.1177/0013164420928457
</p>
</li></ol>



<h3>See Also</h3>

<p>rankByGroup, rankBySlidingWindow, computePowers, bestModel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Using this function with the example dataset 'ppvt'
# You can use the 'getGroups()' function to set up grouping variable in case,
# you have a continuous age variable.
model &lt;- taylorSwift(raw = ppvt$raw, group = ppvt$group)

# return norm tables including 90% confidence intervals for a
# test with a reliability of r = .85; table are set to mean of quartal
# in grade 3 (children completed 2 years of schooling)
normTable(c(5, 15), model, CI = .90, reliability = .95)

# ... or instead of raw scores for norm scores, the other way round
rawTable(c(8, 12), model, CI = .90, reliability = .95)

## End(Not run)
</code></pre>

<hr>
<h2 id='weighted.quantile'>Weighted quantile estimator</h2><span id='topic+weighted.quantile'></span>

<h3>Description</h3>

<p>Computes weighted quantiles (code from Andrey Akinshin (2023) &quot;Weighted quantile estimators&quot; arXiv:2304.07265 [stat.ME]
Code made available via the CC BY-NC-SA 4.0 license) on the basis of either the weighted Harrell-Davis
quantile estimator or an adaption of the type 7 quantile estimator of the generic quantile function in
the base package. Please provide a vector with raw values, the probabilities for the quantiles and an
additional vector with the weight of each observation. In case the weight vector is NULL, a normal
quantile estimation is done. The vectors may not include NAs and the weights should be positive non-zero
values. Please draw on the computeWeights() function for retrieving weights in post stratification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile(x, probs, weights = NULL, type = "Harrell-Davis")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.quantile_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x</p>
</td></tr>
<tr><td><code id="weighted.quantile_+3A_type">type</code></td>
<td>
<p>Type of estimator, can either be &quot;inflation&quot;, &quot;Harrell-Davis&quot; using a beta function to
approximate the weighted percentiles (Harrell &amp; Davis, 1982) or &quot;Type7&quot; (default; Hyndman &amp; Fan, 1996), an adaption
of the generic quantile function in R, including weighting. The inflation procedure is essentially
a numerical, non-parametric solution that gives the same results as Harrel-Davis. It requires less
ressources with small datasets and always finds a solution (e. g. 1000 cases with
weights between 1 and 10). If it becomes too resource intense, it switches to Harrell-Davis automatically.
Harrel-Davis and Type7 code is based on the work of Akinshin (2023).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the weighted quantiles
</p>


<h3>References</h3>


<ol>
<li><p> Harrell, F.E. &amp; Davis, C.E. (1982). A new distribution-free quantile estimator. Biometrika, 69(3), 635-640.
</p>
</li>
<li><p> Hyndman, R. J. &amp; Fan, Y. (1996). Sample quantiles in statistical packages, American Statistician 50, 361365.
</p>
</li>
<li><p> Akinshin, A. (2023). Weighted quantile estimators arXiv:2304.07265 [stat.ME]
</p>
</li></ol>



<h3>See Also</h3>

<p>weighted.quantile.inflation, weighted.quantile.harrell.davis, weighted.quantile.type7
</p>

<hr>
<h2 id='weighted.quantile.harrell.davis'>Weighted Harrell-Davis quantile estimator</h2><span id='topic+weighted.quantile.harrell.davis'></span>

<h3>Description</h3>

<p>Computes weighted quantiles; code from Andrey Akinshin (2023) &quot;Weighted quantile estimators&quot; arXiv:2304.07265 [stat.ME]
Code made available via the CC BY-NC-SA 4.0 license
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile.harrell.davis(x, probs, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.quantile.harrell.davis_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile.harrell.davis_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile.harrell.davis_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x.
If no weights are provided (NULL), it falls back to the base quantile function, type 7</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the quantiles
</p>

<hr>
<h2 id='weighted.quantile.inflation'>Weighted quantile estimator through case inflation</h2><span id='topic+weighted.quantile.inflation'></span>

<h3>Description</h3>

<p>Applies weighted ranking numerically by inflating cases according to weight. This function
will be resource intensive, if inflated cases get too high and in this cases, it switches
to the parametric Harrell-Davis estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile.inflation(
  x,
  probs,
  weights = NULL,
  degree = 3,
  cutoff = 1e+07
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.quantile.inflation_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x.</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_degree">degree</code></td>
<td>
<p>power parameter for case inflation (default = 3, equaling factor 1000)
If no weights are provided (NULL), it falls back to the base quantile function, type 7</p>
</td></tr>
<tr><td><code id="weighted.quantile.inflation_+3A_cutoff">cutoff</code></td>
<td>
<p>stop criterion for the sum of standardized weights to switch to Harrell-Davis,
default = 1000000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the quantiles
</p>

<hr>
<h2 id='weighted.quantile.type7'>Weighted type7 quantile estimator</h2><span id='topic+weighted.quantile.type7'></span>

<h3>Description</h3>

<p>Computes weighted quantiles; code from Andrey Akinshin (2023) &quot;Weighted quantile estimators&quot; arXiv:2304.07265 [stat.ME]
Code made available via the CC BY-NC-SA 4.0 license
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.quantile.type7(x, probs, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.quantile.type7_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.quantile.type7_+3A_probs">probs</code></td>
<td>
<p>Numerical vector of quantiles</p>
</td></tr>
<tr><td><code id="weighted.quantile.type7_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x.
If no weights are provided (NULL), it falls back to the base quantile function, type 7</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the quantiles
</p>

<hr>
<h2 id='weighted.rank'>Weighted rank estimation</h2><span id='topic+weighted.rank'></span>

<h3>Description</h3>

<p>Conducts weighted ranking on the basis of sums of weights per unique raw score.
Please provide a vector with raw values and an additional vector with the weight of each
observation. In case the weight vector is NULL, a normal ranking is done. The vectors may not
include NAs and the weights should be positive non-zero values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.rank(x, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.rank_+3A_x">x</code></td>
<td>
<p>A numerical vector</p>
</td></tr>
<tr><td><code id="weighted.rank_+3A_weights">weights</code></td>
<td>
<p>A numerical vector with weights; should have the same length as x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the weighted absolute ranks
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
