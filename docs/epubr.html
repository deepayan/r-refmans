<!DOCTYPE html><html><head><title>Help for package epubr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {epubr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#count_words'><p>Word count</p></a></li>
<li><a href='#epub'><p>Extract and read EPUB e-books</p></a></li>
<li><a href='#epub_cat'><p>Pretty printing of EPUB text</p></a></li>
<li><a href='#epub_head'><p>Preview the first n characters</p></a></li>
<li><a href='#epub_recombine'><p>Recombine text sections</p></a></li>
<li><a href='#epub_reorder'><p>Reorder sections</p></a></li>
<li><a href='#epub_sift'><p>Sift EPUB sections</p></a></li>
<li><a href='#epubr'><p>epubr: Read EPUB file metadata and text.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.6.4</td>
</tr>
<tr>
<td>Title:</td>
<td>Read EPUB File Metadata and Text</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions supporting the reading and parsing of internal e-book content from EPUB files. 
    The 'epubr' package provides functions supporting the reading and parsing of internal e-book content from EPUB files. 
    E-book metadata and text content are parsed separately and joined together in a tidy, nested tibble data frame. 
    E-book formatting is not completely standardized across all literature. 
    It can be challenging to curate parsed e-book content across an arbitrary collection of e-books 
    perfectly and in completely general form, to yield a singular, consistently formatted output. 
    Many EPUB files do not even contain all the same pieces of information in their respective metadata. 
    EPUB file parsing functionality in this package is intended for relatively general application to arbitrary EPUB e-books. 
    However, poorly formatted e-books or e-books with highly uncommon formatting may not work with this package. 
    There may even be cases where an EPUB file has DRM or some other property that makes it impossible to read with 'epubr'. 
    Text is read 'as is' for the most part. The only nominal changes are minor substitutions, for example curly quotes changed to straight quotes. 
    Substantive changes are expected to be performed subsequently by the user as part of their text analysis. 
    Additional text cleaning can be performed at the user's discretion, such as with functions from packages like 'tm' or 'qdap'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://docs.ropensci.org/epubr/">https://docs.ropensci.org/epubr/</a> (website)
<a href="https://github.com/ropensci/epubr">https://github.com/ropensci/epubr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ropensci/epubr/issues">https://github.com/ropensci/epubr/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, readr</td>
</tr>
<tr>
<td>Imports:</td>
<td>xml2, xslt, magrittr, tibble, dplyr, tidyr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-10 02:21:58 UTC; Matt</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthew Leonawicz <a href="https://orcid.org/0000-0001-9452-2771"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthew Leonawicz &lt;mfleonawicz@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-10 03:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='count_words'>Word count</h2><span id='topic+count_words'></span>

<h3>Description</h3>

<p>Count the number of words in a string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_words(x, word_pattern = "[A-Za-z0-9&amp;]", break_pattern = " |\n")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_words_+3A_x">x</code></td>
<td>
<p>character, a string containing words to be counted. May be a vector.</p>
</td></tr>
<tr><td><code id="count_words_+3A_word_pattern">word_pattern</code></td>
<td>
<p>character, regular expression to match words. Elements not matched are not counted.</p>
</td></tr>
<tr><td><code id="count_words_+3A_break_pattern">break_pattern</code></td>
<td>
<p>character, regular expression to split a string between words.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the number of words in strings. Words are first separated using <code>break_pattern</code>.
Then the resulting character vector elements are counted, including only those that are matched by <code>word_pattern</code>.
The approach taken is meant to be simple and flexible.
</p>
<p><code>epub</code> uses this function internally to estimate the number of words for each e-book section alongside the use of <code>nchar</code> for counting individual characters.
It can be used directly on character strings and is convenient for applying with different regular expression pattern arguments as needed.
</p>
<p>These two arguments are provided for control, but the defaults are likely good enough.
By default, strings are split only on spaces and new line characters.
The &quot;words&quot; that are counted in the resulting vector are those that contain any alphanumeric characters or the ampersand.
This means for example that hyphenated words, acronyms and numbers displayed with digits, are all counted as words.
The presence of any other characters does not negate that a word has been found.
</p>


<h3>Value</h3>

<p>an integer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- " This   sentence will be counted to have:\n\n10 (ten) words."
count_words(x)
</code></pre>

<hr>
<h2 id='epub'>Extract and read EPUB e-books</h2><span id='topic+epub'></span><span id='topic+epub_meta'></span><span id='topic+epub_unzip'></span>

<h3>Description</h3>

<p>Read EPUB format e-books into a data frame using <code>epub</code> or extract EPUB archive files for direct use with <code>epub_unzip</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epub(
  file,
  fields = NULL,
  drop_sections = NULL,
  chapter_pattern = NULL,
  encoding = "UTF-8",
  ...
)

epub_meta(file)

epub_unzip(file, exdir = tempdir())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epub_+3A_file">file</code></td>
<td>
<p>character, input EPUB filename. May be a vector for <code>epub</code> and <code>epub_meta</code>. Always a single file for <code>epub_unzip</code>.</p>
</td></tr>
<tr><td><code id="epub_+3A_fields">fields</code></td>
<td>
<p>character, vector of metadata fields (data frame columns) to parse from metadata, if they exist. See details.</p>
</td></tr>
<tr><td><code id="epub_+3A_drop_sections">drop_sections</code></td>
<td>
<p>character, a regular expression pattern string to identify text sections (rows of nested text data frame) to drop.</p>
</td></tr>
<tr><td><code id="epub_+3A_chapter_pattern">chapter_pattern</code></td>
<td>
<p>character, a regular expression pattern string to attempt distinguishing nested data frame rows of chapter text entries from other types of entries.</p>
</td></tr>
<tr><td><code id="epub_+3A_encoding">encoding</code></td>
<td>
<p>character, defaults to <code>"UTF-8"</code>.</p>
</td></tr>
<tr><td><code id="epub_+3A_...">...</code></td>
<td>
<p>additional arguments. With the exception of passing <code>title</code> (see details), currently developmental/unsupported.</p>
</td></tr>
<tr><td><code id="epub_+3A_exdir">exdir</code></td>
<td>
<p>for <code>epub_unzip</code>, extraction directory to place archive contents (files). It will be created if necessary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The primary function here is <code>epub</code>. It parses EPUB file metadata and textual content into a data frame.
The output data frame has one row for each file in <code>file</code>.
It has metadata in all columns except the <code>data</code> column, which is a column of nested data frames containing e-book text by book section (e.g., chapters).
Both the primary and nested data frames are tibbles and safe to print to the console &quot;as is&quot;.
</p>
<p>Be careful if <code>file</code> is a long vector of many EPUB files.
This could take a long time to process as well as could potentially use up all of your system RAM if you have far too many large books in one call to <code>epub</code>.
</p>
<p>On a case by case basis, you can always select columns and filter rows of a resulting data frame for a single e-book subsequent to visual inspection.
However, the optional arguments <code>fields</code>, <code>drop_sections</code> and <code>chapter_pattern</code> allow you to do some of this as part of the EPUB file reading process.
You can ignore these arguments and do all your own post-processing of the resulting data frame, but if using these arguments,
they are most likely to be useful for bulk e-book processing where <code>file</code> is a vector of like-formatted files.
</p>


<h4>Main columns</h4>

<p>The <code>fields</code> argument can be used to limit the columns returned in the primary data frame.
E.g., <code>fields = c("title", "creator", "date", "identifier", "publisher", "file")</code>. Some fields will be returned even if not in <code>fields</code>, such as <code>data</code> and <code>title</code>.
<br /><br />
Ideally, you should already know what metadata fields are in the EPUB file. This is not possible for large collections with possibly different formatting.
Note that when <code>"file"</code> is included in <code>fields</code>, the output will include a column of the original file names, in case this is different from the content of a <code>source</code> field that may be present in the metadata.
So this field is always available even if not part of the file metadata.
<br /><br />
Additionally, if there is no <code>title</code> field in the metadata, the output data frame will include a <code>title</code> column filled in with the same file names,
unless you pass the additional optional title argument, e.g. <code>title = "TitleFieldID"</code> so that another field can me mapped to <code>title</code>.
If supplying a <code>title</code> argument that also does not match an existing field in the e-book, the output <code>title</code> column will again default to file names.
File names are the fallback option because unlike e-book metadata fields, file names always exist and should also always be unique when performing vectorized reads over multiple books,
ensuring that <code>title</code> can be a column in the output data frame that uniquely identifies different e-books even if the books did not have a <code>title</code> field in their metadata.
<br /><br />
Columns of the nested data frames in <code>data</code> are fixed. Select from these in subsequent data frame manipulations.
</p>



<h4>Nested rows</h4>

<p>The <code>chapter_pattern</code> argument may be helpful for bulk processing of similarly formatted EPUB files. This should be ignored for poorly formatted EPUB files or where there is inconsistent naming across an e-book collection.
Like with <code>fields</code>, you should explore file metadata in advance or this argument will not be useful. If provided, a column <code>nchap</code> is added to the output data frame giving the guessed number of chapters.
In the <code>data</code> column, the <code>section</code> column of the nested data frames will also be updated to reflect guessed chapters with new, consistent chapter IDs, always beginning with <code>ch</code> and ending with digits.
<br /><br />
The <code>drop_sections</code> argument also uses regular expression pattern matching like <code>chapter_pattern</code> and operates on the same <code>section</code> column. It simply filters out any matched rows.
This is useful for dropping rows that may pertain to book cover, copyright and acknowledgements pages, and other similar, clearly non-chapter text, e-book sections.
An example that might work for many books could be <code>drop_sections = "^co(v|p)|^ack"</code>
<br /><br />
Rows of the primary data frame are fixed. Filter or otherwise manipulate these in subsequent data frame manipulations. There is one row per file so filtering does not make sense to do as part of the initial file reading.
</p>



<h4>EPUB metadata</h4>

<p>Use <code>epub_meta</code> to return a data frame of only the metadata for each file in <code>file</code>. This skips the reading of each file's text contents, strictly parsing the metadata.
It returns a data frame with one row for each file and <code>n</code> columns where <code>n</code> is equal to the union of all fields identified across all files in <code>file</code>.
Fields available for at least one e-book in <code>file</code> will return <code>NA</code> in that column for any row pertaining to an e-book that does not have that field in its metadata.
If the metadata contains multiple entries for a field, such as multiple subjects or publication dates, they are collapsed using the pipe character.
</p>



<h4>Unzipping EPUB files</h4>

<p>If using <code>epub_unzip</code> directly on individual EPUB files, this gives you control over where to extract archive files to and what to do with them subsequently.
<code>epub</code> and <code>epub_meta</code> use <code>epub_unzip</code> internally to extract EPUB archive files to the R session temp directory (with <code>tempdir()</code>).
You do not need to use <code>epub_unzip</code> directly prior to using these other functions. It is only needed if you want the internal files for some other purpose in or out of R.
</p>



<h3>Value</h3>

<p><code>epub</code> returns a data frame. <code>epub_unzip</code> returns nothing but extracts files from an EPUB file archive.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use a local example EPUB file included in the package
file &lt;- system.file("dracula.epub", package = "epubr")
bookdir &lt;- file.path(tempdir(), "dracula")
epub_unzip(file, exdir = bookdir) # unzip to directly inspect archive files
list.files(bookdir, recursive = TRUE)


epub_meta(file) # parse EPUB file metadata only

x &lt;- epub(file) # parse entire e-book
x
x$data[[1]]

epub(file, fields = c("title", "creator"), drop_sections = "^cov")

</code></pre>

<hr>
<h2 id='epub_cat'>Pretty printing of EPUB text</h2><span id='topic+epub_cat'></span>

<h3>Description</h3>

<p>Print EPUB text to the console in a more readable format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epub_cat(
  x,
  max_paragraphs = 10,
  skip = 0,
  paragraph_spacing = 1,
  paragraph_indent = 2,
  section_sep = "====",
  book_sep = "====\n===="
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epub_cat_+3A_x">x</code></td>
<td>
<p>a data frame returned by <code><a href="#topic+epub">epub</a></code> or a character string giving the EPUB filename(s).</p>
</td></tr>
<tr><td><code id="epub_cat_+3A_max_paragraphs">max_paragraphs</code></td>
<td>
<p>integer, maximum number of paragraphs (non-empty lines) to <code>cat</code> to console.</p>
</td></tr>
<tr><td><code id="epub_cat_+3A_skip">skip</code></td>
<td>
<p>integer, number of paragraphs to skip.</p>
</td></tr>
<tr><td><code id="epub_cat_+3A_paragraph_spacing">paragraph_spacing</code></td>
<td>
<p>integer, number of empty lines between paragraphs.</p>
</td></tr>
<tr><td><code id="epub_cat_+3A_paragraph_indent">paragraph_indent</code></td>
<td>
<p>integer, number of spaces to indent paragraphs.</p>
</td></tr>
<tr><td><code id="epub_cat_+3A_section_sep">section_sep</code></td>
<td>
<p>character, a string to indicate section breaks.</p>
</td></tr>
<tr><td><code id="epub_cat_+3A_book_sep">book_sep</code></td>
<td>
<p>character, separator shown between books when <code>x</code> has multiple rows (books).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function prints text from EPUB files to the console using <code>cat</code>.
This is useful for quickly obtaining an overview of the book text parsed by <code><a href="#topic+epub">epub</a></code> that is easier to read that looking at strings in the table.
<code>max_paragraphs</code> is set low by default to prevent accidentally printing entire books to the console.
To print everything in <code>x</code>, set <code>max_paragraphs = NULL</code>.
</p>


<h3>Value</h3>

<p>nothing is returned but a more readable format of the text content for books in <code>x</code> is printed to the console.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epub_head">epub_head</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("dracula.epub", package = "epubr")
d &lt;- epub(file)
epub_cat(d, max_paragraphs = 2, skip = 147)

</code></pre>

<hr>
<h2 id='epub_head'>Preview the first n characters</h2><span id='topic+epub_head'></span>

<h3>Description</h3>

<p>Preview the first n characters of each EPUB e-book section.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epub_head(x, n = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epub_head_+3A_x">x</code></td>
<td>
<p>a data frame returned by <code><a href="#topic+epub">epub</a></code> or a character string giving the EPUB filename(s).</p>
</td></tr>
<tr><td><code id="epub_head_+3A_n">n</code></td>
<td>
<p>integer, first n characters to retain from each e-book section.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a simplified data frame of only the unnested <code>section</code> and <code>text</code> columns of a data frame returned by <code><a href="#topic+epub">epub</a></code>, with the text included only up to the first <code>n</code> characters.
This is useful for previewing the opening text of each e-book section to inspect for possible useful regular expression patterns to use for text-based section identification.
For example, an e-book may not have meaningful section IDs that distinguish one type of book section from another, such as chapters from non-chapter sections,
but the text itself may contain this information at or near the start of a section.
</p>


<h3>Value</h3>

<p>a data frame.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epub_cat">epub_cat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("dracula.epub", package = "epubr")
epub_head(file)

</code></pre>

<hr>
<h2 id='epub_recombine'>Recombine text sections</h2><span id='topic+epub_recombine'></span>

<h3>Description</h3>

<p>Split and recombine EPUB text sections based on regular expression pattern matching.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epub_recombine(data, pattern, sift = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epub_recombine_+3A_data">data</code></td>
<td>
<p>a data frame created by <code>epub</code>.</p>
</td></tr>
<tr><td><code id="epub_recombine_+3A_pattern">pattern</code></td>
<td>
<p>character, a regular expression.</p>
</td></tr>
<tr><td><code id="epub_recombine_+3A_sift">sift</code></td>
<td>
<p><code>NULL</code> or a named list of parameters passed to <code><a href="#topic+epub_sift">epub_sift</a></code>. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a regular expression and uses it to determine new break points for the full e-book text.
This is particularly useful when sections pulled from EPUB metadata have arbitrary breaks and the text contains meaningful breaks at random locations in various sections.
<code>epub_recombine</code> collapses the text and then creates a new nested data frame containing new chapter/section labels, word counts and character counts,
associated with the text based on the new break points.
</p>
<p>Usefulness depends on the quality of the e-book. While this function exists to improve the data structure of e-book content parsed from e-books with poor metadata formatting,
it still requires original formatting that will at least allow such an operation to be successful, specifically a consistent, non-ambiguous regular expression pattern.
See examples below using the built in e-book dataset.
</p>
<p>When used in conjunction with <code>epub_sift</code> via the <code>sift</code> argument, recombining and resifting is done recursively.
This is because it is possible that sifting can create a need to rerun the recombine step in order to regenerate proper chapter indexing for the section column.
However, recombining a second time does not lead to a need to resift, so recursion ends after one round regardless.
</p>
<p>This is a convenient way to avoid the syntax:
</p>
<p><code>epub_recombine([args]) %&gt;% epub_sift([args]) %&gt;% epub_recombine([args])</code>.
</p>


<h3>Value</h3>

<p>a data frame
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epub_sift">epub_sift</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("dracula.epub", package = "epubr")
x &lt;- epub(file) # parse entire e-book
x$data[[1]] # note arbitrary section breaks (not between chapters)

pat &lt;- "CHAPTER [IVX]+" # but a reliable pattern exists for new breaks
epub_recombine(x, pat) # not as expected; pattern also in table of contents

epub_recombine(x, pat, sift = list(n = 1000)) # sift low word-count sections

</code></pre>

<hr>
<h2 id='epub_reorder'>Reorder sections</h2><span id='topic+epub_reorder'></span>

<h3>Description</h3>

<p>Reorder text sections in an e-book based on a user-provided function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epub_reorder(data, .f, pattern)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epub_reorder_+3A_data">data</code></td>
<td>
<p>a data frame created by <code>epub</code>.</p>
</td></tr>
<tr><td><code id="epub_reorder_+3A_.f">.f</code></td>
<td>
<p>a scalar function to determine a single row index based on a matched regular expression. It must take two strings, the text and the pattern, and return a single number. See examples.</p>
</td></tr>
<tr><td><code id="epub_reorder_+3A_pattern">pattern</code></td>
<td>
<p>regular expression passed to <code>.f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many e-books have chronologically ordered sections based on quality metadata.
This results in properly book sections in the nested data frame.
However, some poorly formatted e-books have their internal sections occur in an arbitrary order.
This can be frustrating to work with when doing text analysis on each section and where order matters.
</p>
<p>This function addresses this case by reordering the text sections in the nested data frame based on a user-provided function that re-indexes the data frame rows based on their content.
In general, the approach is to find something in the content of each section that describes the section order.
For example, <code>epub_recombine</code> can use a regular expression to identify chapters.
Taking this a step further, <code>epub_reorder</code> can use a function that works with the same information to reorder the rows.
</p>
<p>It is enough in the former case to identify where in the text the pattern occurs. There is no need to extract numeric ordering from it.
The latter takes more effort. In the example EPUB file included in <code>epubr</code>, chapters can be identified using a pattern of the word CHAPTER in capital letters followed by a space and then some Roman numerals.
The user must provide a function that would parse the Roman numerals in this pattern so that the rows of the data frame can be reordered properly.
</p>


<h3>Value</h3>

<p>a data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("dracula.epub", package = "epubr")
x &lt;- epub(file) # parse entire e-book
x &lt;- epub_recombine(x, "CHAPTER [IVX]+", sift = list(n = 1000)) # clean up

library(dplyr)
set.seed(1)
x$data[[1]] &lt;- sample_frac(x$data[[1]]) # randomize rows for example
x$data[[1]]

f &lt;- function(x, pattern) as.numeric(as.roman(gsub(pattern, "\\1", x)))
x &lt;- epub_reorder(x, f, "^CHAPTER ([IVX]+).*")
x$data[[1]]

</code></pre>

<hr>
<h2 id='epub_sift'>Sift EPUB sections</h2><span id='topic+epub_sift'></span>

<h3>Description</h3>

<p>Sift out EPUB sections that have suspiciously low word or character count.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epub_sift(data, n, type = c("word", "char"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epub_sift_+3A_data">data</code></td>
<td>
<p>a data frame created by <code>epub</code>.</p>
</td></tr>
<tr><td><code id="epub_sift_+3A_n">n</code></td>
<td>
<p>integer, minimum number of words or characters to retain a section.</p>
</td></tr>
<tr><td><code id="epub_sift_+3A_type">type</code></td>
<td>
<p>character, <code>"word"</code> or <code>"character"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is like a sieve that lets small section rows fall through.
Choose the minimum number of words or characters to accept as a meaningful section in the e-book worth retaining in the nested data frame, e.g., book chapters.
Data frame rows pertaining to smaller sections are dropped.
</p>
<p>This function is helpful for isolating meaningful content by removing extraneous e-book sections that may be difficult to remove by other methods when working with poorly formatted e-books.
The EPUB file included in <code>epubr</code> is a good example of this. It does not contain meaningful section identifiers in its metadata.
This creates a need to restructure the text table after reading it with <code>epub</code> by subsequently calling <code>epub_recombine</code>.
However, some unavoidable ambiguity in this leads to many small sections appearing from the table of contents.
These can then be dropped with <code>epub_sift</code>. See a more comprehensive in the <code><a href="#topic+epub_recombine">epub_recombine</a></code> documentation.
A simpler example is shown below.
</p>


<h3>Value</h3>

<p>a data frame
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epub_recombine">epub_recombine</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
file &lt;- system.file("dracula.epub", package = "epubr")
x &lt;- epub(file) # parse entire e-book
x$data[[1]]

x &lt;- epub_sift(x, n = 3000) # drops last two sections
x$data[[1]]

</code></pre>

<hr>
<h2 id='epubr'>epubr: Read EPUB file metadata and text.</h2><span id='topic+epubr'></span><span id='topic+epubr-package'></span>

<h3>Description</h3>

<p><code>epubr</code> provides functions supporting the reading and parsing of internal e-book content from EPUB files.
E-book metadata and textual contents are parsed separately.
</p>


<h3>Details</h3>

<p>E-book formatting is not completely standardized across all literature.
It can be challenging to curate parsed e-book content across an arbitrary collection of e-books perfectly and in completely general form, to yield a singular, consistently formatted output.
Many EPUB files do not even contain all the same pieces of information in their respective metadata.
</p>
<p>EPUB file parsing functionality in this package is intended for relatively general application to arbitrary EPUB e-books.
However, poorly formatted e-books or e-books with highly uncommon formatting may not work with this package.
There may even be cases where an EPUB file has DRM or some other property that makes it impossible to read with <code>epubr</code>.
</p>
<p>Text is read as is for the most part. The only nominal changes are minor substitutions, for example curly quotes changed to straight quotes.
Substantive changes are expected to be performed subsequently by the user as part of their text analysis.
Additional text cleaning can be performed at the user's discretion, such as with functions from packages like <code>tm</code> or <code>qdap</code>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
