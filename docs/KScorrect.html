<!DOCTYPE html><html><head><title>Help for package KScorrect</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {KScorrect}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#KScorrect-package'><p>KScorrect: Lilliefors-Corrected Kolmogorov-Smirnov Goodness-of-Fit Tests</p></a></li>
<li><a href='#dlunif'><p>The Log Uniform Distribution</p></a></li>
<li><a href='#dmixnorm'><p>The Normal Mixture Distribution</p></a></li>
<li><a href='#ks_test_stat'><p>Internal KScorrect Function.</p></a></li>
<li><a href='#LcKS'><p>Lilliefors-corrected Kolmogorov-Smirnov Goodness-Of-Fit Test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Lilliefors-Corrected Kolmogorov-Smirnov Goodness-of-Fit Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.0</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS (&ge; 7.3.0), doParallel (&ge; 1.0.14), foreach (&ge; 1.4.4),
iterators (&ge; 1.0.10), parallel (&ge; 3.6.0), mclust (&ge; 5.4)</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-06-30</td>
</tr>
<tr>
<td>Author:</td>
<td>Phil Novack-Gottshall, Steve C. Wang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Phil Novack-Gottshall &lt;pnovack-gottshall@ben.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the Lilliefors-corrected Kolmogorov-Smirnov test for use
    in goodness-of-fit tests, suitable when population parameters are unknown and
    must be estimated by sample statistics. P-values are estimated by simulation.
    Can be used with a variety of continuous distributions, including normal,
    lognormal, univariate mixtures of normals, uniform, loguniform, exponential,
    gamma, and Weibull distributions. Functions to generate random numbers and
    calculate density, distribution, and quantile functions are provided for use
    with the log uniform and mixture distributions.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode">CC0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/pnovack-gottshall/KScorrect">https://github.com/pnovack-gottshall/KScorrect</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pnovack-gottshall/KScorrect/issues">https://github.com/pnovack-gottshall/KScorrect/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-07-03 19:01:26 UTC; pnovack-gottshall</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-07-03 19:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='KScorrect-package'>KScorrect: Lilliefors-Corrected Kolmogorov-Smirnov Goodness-of-Fit Tests</h2><span id='topic+KScorrect-package'></span><span id='topic+KScorrect'></span>

<h3>Description</h3>

<p>Implements the Lilliefors-corrected Kolmogorov-Smirnov test for use in
goodness-of-fit tests.
</p>


<h3>Details</h3>

<p>KScorrect implements the Lilliefors-corrected Kolmogorov-Smirnov test for
use in goodness-of-fit tests, suitable when population parameters are unknown
and must be estimated by sample statistics. <em>P</em>-values are estimated by
simulation. Coded to complement <code><a href="stats.html#topic+ks.test">ks.test</a></code>, it can be used
with a variety of continuous distributions, including normal, lognormal,
univariate mixtures of normals, uniform, loguniform, exponential, gamma, and
Weibull distributions.
</p>
<p>Functions to generate random numbers and calculate density, distribution, and
quantile functions are provided for use with the loguniform and mixture
distributions.
</p>


<h3>Author(s)</h3>

<p>Phil Novack-Gottshall <a href="mailto:pnovack-gottshall@ben.edu">pnovack-gottshall@ben.edu</a>
</p>
<p>Steve C. Wang <a href="mailto:scwang@swarthmore.edu">scwang@swarthmore.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get the package version and citation of KScorrect
packageVersion("KScorrect")
citation("KScorrect")

x &lt;- runif(200)
Lc &lt;- LcKS(x, cdf="pnorm", nreps=999)
hist(Lc$D.sim)
abline(v = Lc$D.obs, lty = 2)
print(Lc, max=50)  # Print first 50 simulated statistics
# Approximate p-value (usually) &lt;&lt; 0.05

# Confirmation uncorrected version has increased Type II error rate when
#   using sample statistics to estimate parameters:
ks.test(x, "pnorm", mean(x), sd(x))   # p-value always larger, (usually) &gt; 0.05

x &lt;- rlunif(200, min=exp(1), max=exp(10)) # random loguniform sample
Lc &lt;- LcKS(x, cdf="plnorm")
Lc$p.value      # Approximate p-value: (usually) &lt;&lt; 0.05
</code></pre>

<hr>
<h2 id='dlunif'>The Log Uniform Distribution</h2><span id='topic+dlunif'></span><span id='topic+plunif'></span><span id='topic+qlunif'></span><span id='topic+rlunif'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random generation for
the log uniform distribution in the interval from <code>min</code> to <code>max</code>.
Parameters must be raw values (not log-transformed) and will be
log-transformed using specified <code>base</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlunif(x, min, max, base = exp(1))

plunif(q, min, max, base = exp(1))

qlunif(p, min, max, base = exp(1))

rlunif(n, min, max, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dlunif_+3A_x">x</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="dlunif_+3A_min">min</code></td>
<td>
<p>Lower limit of the distribution, in raw (not log-transformed)
values. Negative values will give warning.</p>
</td></tr>
<tr><td><code id="dlunif_+3A_max">max</code></td>
<td>
<p>Upper limit of the distribution, in raw (not log-transformed)
values. Negative values will give warning.</p>
</td></tr>
<tr><td><code id="dlunif_+3A_base">base</code></td>
<td>
<p>The base to which logarithms are computed. Defaults to
<code>e=exp(1)</code>. Must be a positive number.</p>
</td></tr>
<tr><td><code id="dlunif_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="dlunif_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="dlunif_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A log uniform (or loguniform or log-uniform) random variable has a
uniform distribution when log-transformed.
</p>


<h3>Value</h3>

<p><code>dlunif</code> gives the density, <code>plunif</code> gives the distribution
function, <code>qlunif</code> gives the quantile function, and <code>rlunif</code>
generates random numbers.
</p>


<h3>Note</h3>

<p>Parameters <code>min, max</code> must be provided as raw (not
log-transformed) values and will be log-transformed using <code>base</code>. In
other words, when log-transformed, a log uniform random variable with
parameters <code>min=a</code> and <code>max=b</code> is uniform over the interval from
<code>log(a)</code> to <code>log(b)</code>.
</p>


<h3>Author(s)</h3>

<p>Steve Wang <a href="mailto:scwang@swarthmore.edu">scwang@swarthmore.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for other standard distributions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(1:100, dlunif(1:100, exp(1), exp(10)), type="l", main="Loguniform density")
plot(log(1:100), dlunif(log(1:100), log(1), log(10)), type="l",
     main="Loguniform density")

plot(1:100, plunif(1:100, exp(1), exp(10)), type="l", main="Loguniform cumulative")
plot(qlunif(ppoints(100), exp(1), exp(10)), type="l", main="Loguniform quantile")

hist(rlunif(1000, exp(1), exp(10)), main="random loguniform sample")
hist(log(rlunif(10000, exp(1), exp(10))), main="random loguniform sample")
hist(log(rlunif(10000, exp(1), exp(10), base=10), base=10), main="random loguniform sample")

</code></pre>

<hr>
<h2 id='dmixnorm'>The Normal Mixture Distribution</h2><span id='topic+dmixnorm'></span><span id='topic+pmixnorm'></span><span id='topic+qmixnorm'></span><span id='topic+rmixnorm'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation for
a univariate (one-dimensional) distribution composed of a mixture of normal
distributions with means equal to <code>mean</code>, standard deviations equal to
<code>sd</code>, and mixing proportion of the components equal to <code>pro</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmixnorm(x, mean, sd, pro)

pmixnorm(q, mean, sd, pro)

qmixnorm(p, mean, sd, pro, expand = 1)

rmixnorm(n, mean, sd, pro)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dmixnorm_+3A_x">x</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_mean">mean</code></td>
<td>
<p>Vector of means, one for each component.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_sd">sd</code></td>
<td>
<p>Vector of standard deviations, one for each component. If a single
value is provided, an equal-variance mixture model is implemented. Must be
non-negative.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_pro">pro</code></td>
<td>
<p>Vector of mixing proportions, one for each component. If missing,
an equal-proportion model is implemented, with a warning. If proportions do
not sum to unity, they are rescaled to do so. Must be non-negative.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_expand">expand</code></td>
<td>
<p>Value to expand the range of probabilities for quantile
approximation. <code>Default = 1.0</code>. See <code>details</code> below.</p>
</td></tr>
<tr><td><code id="dmixnorm_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use, modify, and wrap around those from the
<code>mclust</code> package, especially <code><a href="mclust.html#topic+dens">dens</a></code>, and
<code><a href="mclust.html#topic+sim">sim</a></code>. Functions are slightly faster than the
corresponding <code>mclust</code> functions when used with univariate
distributions.
</p>
<p>Unlike <code>mclust</code>, which primarily focuses on parameter estimation based
on mixture samples, the functions here are modified to calculate PDFs,
CDFs, approximate quantiles, and random numbers for mixture distributions
with user-specified parameters. The functions are written to emulate the
syntax of other R distribution functions (e.g.,
<code><a href="stats.html#topic+Normal">Normal</a></code>).
</p>
<p>The number of mixture components (argument <code>G</code> in <code>mclust</code>) is
specified from the length of the <code>mean</code> vector. If a single <code>sd</code>
value is provided, an equal-variance mixture model (<code>modelNames="E"</code>
in <code>mclust</code>) is implemented; if multiple values are provided, a
variable-variance model (<code>modelNames="V"</code> in <code>mclust</code>) is
implemented. If mixing proportion <code>pro</code> is missing, all components are
assigned equal mixing proportions, with a warning. Mixing proportions are
rescaled to sum to unity. If the lengths of supplied means, standard
deviations, and mixing proportions conflict, an error is called.
</p>
<p>Analytical solutions are not available to calculate a quantile function for
all combinations of mixture parameters. <code>qmixnorm</code> approximates the
quantile function using a spline function calculated from cumulative
density functions for the specified mixture distribution. Quantile values
for probabilities near zero and one are approximated by taking a randomly
generated sample (with sample size equal to the product of 1000 and the
number of mixture components), and expanding that range positively and
negatively by a multiple (specified by <code>(default) expand = 1</code>) of the
observed range in the random sample. In cases where the distribution range
is large (such as when mixture components are discrete or there are large
distances between components), resulting extreme probability values will be
very close to zero or one and can result in non-calculable (<code>NaN</code>)
quantiles (and a warning). Use of other <code>expand</code> values (especially
<code>expand &lt; 1.0</code> that expand the ranges by smaller multiples) often will
yield improved approximations. Note that <code>expand</code> values equal to or
close to 0 may result in inaccurate approximation of extreme quantiles. In
situations requiring extreme quantile values, it is recommended that the
largest <code>expand</code> value that does not result in a non-calculable
quantile (i.e., no warning called) be used. See <code>examples</code> for
confirmation that approximations are accurate, comparing the approximate
quantiles from a single 'mixture' distribution to those calculated for the
same distribution using <code>qnorm</code>, and demonstrating cases in which
using non-default <code>expand</code> values will allow correct approximation of
quantiles.
</p>


<h3>Value</h3>

<p><code>dmixnorm</code> gives the density, <code>pmixnorm</code> gives the
distribution function, <code>qmixnorm</code> approximates the quantile function,
and <code>rmixnorm</code> generates random numbers.
</p>


<h3>Author(s)</h3>

<p>Phil Novack-Gottshall <a href="mailto:pnovack-gottshall@ben.edu">pnovack-gottshall@ben.edu</a> and Steve
Wang <a href="mailto:scwang@swarthmore.edu">scwang@swarthmore.edu</a>, based on functions written by Luca
Scrucca.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for other standard distributions,
and <code>mclust::<a href="mclust.html#topic+dens">dens</a></code>, <code><a href="mclust.html#topic+sim">sim</a></code>, and
<code><a href="mclust.html#topic+cdfMclust">cdfMclust</a></code> for alternative density, quantile, and
random number functions for multivariate mixture distributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mixture of two normal distributions
mean &lt;- c(3, 6)
pro &lt;- c(.25, .75)
sd &lt;- c(.5, 1)
x &lt;- rmixnorm(n=5000, mean=mean, pro=pro, sd=sd)
hist(x, n=20, main="random bimodal sample")

## Not run: 
# Requires functions from the 'mclust' package
require(mclust)
# Confirm 'rmixnorm' above produced specified model
mod &lt;- mclust::Mclust(x)
mod             # Best model (correctly) has two-components with unequal variances
mod$parameters	# and approximately same parameters as specified above
sd^2            # Note reports var (sigma-squared) instead of sd used above

## End(Not run)

# Density, distribution, and quantile functions
plot(seq(0, 10, .1), dmixnorm(seq(0, 10, .1), mean=mean, sd=sd, pro=pro),
     type="l", main="Normal mixture density")
plot(seq(0, 10, .1), pmixnorm(seq(0, 10, .1), mean=mean, sd=sd, pro=pro),
     type="l", main="Normal mixture cumulative")
plot(stats::ppoints(100), qmixnorm(stats::ppoints(100), mean=mean, sd=sd, pro=pro),
     type="l", main="Normal mixture quantile")

# Any number of mixture components are allowed
plot(seq(0, 50, .01), pmixnorm(seq(0, 50, .01), mean=1:50, sd=.05, pro=rep(1, 50)),
     type="l", main="50-component normal mixture cumulative")

# 'expand' can be specified to prevent non-calculable quantiles:
q1 &lt;- qmixnorm(stats::ppoints(30), mean=c(1, 20), sd=c(1, 1), pro=c(1, 1))
q1 # Calls a warning because of NaNs
# Reduce 'expand'. (Values &lt; 0.8 allow correct approximation)
q2 &lt;- qmixnorm(stats::ppoints(30), mean=c(1, 20), sd=c(1, 1), pro=c(1, 1), expand=.5)
plot(stats::ppoints(30), q2, type="l", main="Quantile with reduced range")

## Not run: 
# Requires functions from the 'mclust' package
# Confirmation that qmixnorm approximates correct solution
#   (single component 'mixture' should mimic qnorm):
x &lt;- rmixnorm(n=5000, mean=0, pro=1, sd=1)
mpar &lt;- mclust::Mclust(x)$param
approx &lt;- qmixnorm(p=ppoints(100), mean=mpar$mean, pro=mpar$pro,
     sd=sqrt(mpar$variance$sigmasq))
known &lt;- qnorm(p=ppoints(100), mean=mpar$mean, sd=sqrt(mpar$variance$sigmasq))
cor(approx, known)  # Approximately the same
plot(approx, main="Quantiles for (unimodal) normal")
lines(known)
legend("topleft", legend=c("known", "approximation"), pch=c(NA,1),
     lty=c(1, NA), bty="n")

## End(Not run)
</code></pre>

<hr>
<h2 id='ks_test_stat'>Internal KScorrect Function.</h2><span id='topic+ks_test_stat'></span>

<h3>Description</h3>

<p>Internal function not intended to be called directly by users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ks_test_stat(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ks_test_stat_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="ks_test_stat_+3A_y">y</code></td>
<td>
<p>a character string naming a cumulative distribution function or an
actual cumulative distribution function such as pnorm. Only continuous CDFs
are valid. See /codeLcKS for accepted functions.</p>
</td></tr>
<tr><td><code id="ks_test_stat_+3A_...">...</code></td>
<td>
<p>parameters of the distribution specified (as a character string)
by y.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simplified and faster <code><a href="stats.html#topic+ks.test">ks.test</a></code> function that calculates just the
two-sided test statistic D.
</p>


<h3>Note</h3>

<p>Calculating the Kolmogorov-Smirnov test statistic D by itself is faster
than calculating the other ouput that that function produces.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ks.test">ks.test</a></code>
</p>

<hr>
<h2 id='LcKS'>Lilliefors-corrected Kolmogorov-Smirnov Goodness-Of-Fit Test</h2><span id='topic+LcKS'></span>

<h3>Description</h3>

<p>Implements the Lilliefors-corrected Kolmogorov-Smirnov test for use in
goodness-of-fit tests, suitable when population parameters are unknown and
must be estimated by sample statistics. It uses Monte Carlo simulation to
estimate <em>p</em>-values. Using a modification of
<code><a href="stats.html#topic+ks.test">ks.test</a></code>, it can be used with a variety of continuous
distributions, including normal, lognormal, univariate mixtures of normals,
uniform, loguniform, exponential, gamma, and Weibull distributions. The Monte
Carlo algorithm can run 'in parallel.'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LcKS(x, cdf, nreps = 4999, G = 1:9, varModel = c("E", "V"),
  parallel = FALSE, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LcKS_+3A_x">x</code></td>
<td>
<p>A numeric vector of data values (observed sample).</p>
</td></tr>
<tr><td><code id="LcKS_+3A_cdf">cdf</code></td>
<td>
<p>Character string naming a cumulative distribution function. Case
insensitive. Only continuous CDFs are valid. Allowed CDFs
include:</p>
<ul>
<li> <p><code>"pnorm"</code> for normal, </p>
</li>
<li> <p><code>"pmixnorm"</code>
for (univariate) normal mixture, </p>
</li>
<li> <p><code>"plnorm"</code> for lognormal
(log-normal, log normal), </p>
</li>
<li> <p><code>"punif"</code> for uniform, </p>
</li>
<li>
<p><code>"plunif"</code> for loguniform (log-uniform, log uniform), </p>
</li>
<li>
<p><code>"pexp"</code> for exponential, </p>
</li>
<li> <p><code>"pgamma"</code> for gamma, </p>
</li>
<li>
<p><code>"pweibull"</code> for Weibull.</p>
</li></ul>
</td></tr>
<tr><td><code id="LcKS_+3A_nreps">nreps</code></td>
<td>
<p>Number of replicates to use in simulation algorithm.
<code>Default = 4999</code> replicates. See <code>details</code> below. Should be a
positive integer.</p>
</td></tr>
<tr><td><code id="LcKS_+3A_g">G</code></td>
<td>
<p>Numeric vector of mixture components to consider, for mixture models
only. <code>Default = 1:9</code> fits up to 9 components. Must contain positive
integers. See <code>details</code> below.</p>
</td></tr>
<tr><td><code id="LcKS_+3A_varmodel">varModel</code></td>
<td>
<p>For mixture models, character string determining whether to
allow equal-variance mixture components (<code>E</code>), variable-variance
mixture components (<code>V</code>) or both (the <code>default</code>).</p>
</td></tr>
<tr><td><code id="LcKS_+3A_parallel">parallel</code></td>
<td>
<p>Logical value that switches between running Monte Carlo
algorithm in parallel (if <code>TRUE</code>) or not (if <code>FALSE</code>, the
<code>default</code>).</p>
</td></tr>
<tr><td><code id="LcKS_+3A_cores">cores</code></td>
<td>
<p>Numeric value to control how many cores to build when running in
parallel. <code>Default = <a href="parallel.html#topic+detectCores">detectCores</a> - 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function builds a simulation distribution <code>D.sim</code> of length
<code>nreps</code> by drawing random samples from the specified continuous
distribution function <code>cdf</code> with parameters calculated from the
provided sample <code>x</code>. Observed statistic <em><code>D</code></em> and simulated
test statistics are calculated using a simplified version of
<code><a href="stats.html#topic+ks.test">ks.test</a></code>.
</p>
<p>The default <code>nreps = 4999</code> provides accurate <em>p</em>-values.
<code>nreps = 1999</code> is sufficient for most cases, and computationally
faster when dealing with more complicated distributions (such as univariate
normal mixtures, gamma, and Weibull). See below for potentially faster
parallel implementations.
</p>
<p>The <em>p</em>-value is calculated as the number of Monte Carlo samples with
test statistics <em>D</em> as extreme as or more extreme than that in the
observed sample <code>D.obs</code>, divided by the <code>nreps</code> number of Monte
Carlo samples. A value of 1 is added to both the numerator and denominator
to allow the observed sample to be represented within the null distribution
(Manly 2004); this has the benefit of avoiding nonsensical <code>p.value =
  0.000</code> and accounts for the fact that the <em>p</em>-value is an estimate.
</p>
<p>Parameter estimates are calculated for the specified continuous
distribution, using maximum-likelihood estimates. When testing against the
gamma and Weibull distributions, <code>MASS::<a href="MASS.html#topic+fitdistr">fitdistr</a></code> is used
to calculate parameter estimates using maximum likelihood optimization,
with sensible starting values. Because this incorporates an optimization
routine, the simulation algorithm can be slow if using large <code>nreps</code>
or problematic samples. Warnings often occur during these optimizations,
caused by difficulties estimating sample statistic standard errors. Because
such SEs are not used in the Lilliefors-corrected simulation algorithm,
warnings are suppressed during these optimizations.
</p>
<p>Sample statistics for the (univariate) normal mixture distribution
<code><a href="#topic+pmixnorm">pmixnorm</a></code> are calculated using package <code>mclust</code>, which
uses BIC to identify the optimal mixture model for the sample, and the EM
algorithm to calculate parameter estimates for this model. The number of
mixture components <code>G</code> (with default allowing up to 9 components),
variance model (whether equal <code>E</code> or variable <code>V</code> variance), and
component statistics (<code>mean</code>s, <code>sd</code>s, and mixing proportions
<code>pro</code>) are estimated from the sample when calculating <code>D.obs</code> and
passed internally when creating random Monte Carlo samples. It is possible
that some of these samples may differ in their optimal <code>G</code> (for
example a two-component input sample might yield a three-component random
sample within the simulation distribution). This can be constrained by
specifying that simulation BIC-optimizations only consider <code>G</code> mixture
components.
</p>
<p>Be aware that constraining <code>G</code> changes the null hypothesis. The
default (<code>G = 1:9</code>) null hypothesis is that a sample was drawn from
<em>any <code>G = 1:9</code>-component mixture distribution</em>. Specifying a
particular value, such as <code>G = 2</code>, restricts the null hypothesis to
particular mixture distributions with just <code>G</code> components, even if
simulated samples might better be represented as different mixture models.
</p>
<p>The <code>LcKS(cdf = "pmixnorm")</code> test implements two control loops to
avoid errors caused by this constraint and when working with problematic
samples. The first loop occurs during model-selection for the observed
sample <code>x</code>, and allows for estimation of parameters for the
second-best model when those for the optimal model are not able to be
calculated by the EM algorithm. A second loop occurs during the simulation
algorithm, rejecting samples that cannot be fit by the mixture model
specified by the observed sample <code>x</code>. Such problematic cases are most
common when the observed or simulated samples have a component(s) with very
small variance (i.e., duplicate observations) or when a Monte Carlo sample
cannot be fit by the specified <code>G</code>.
</p>
<p>Parellel computing can be implemented using <code>parallel = TRUE</code>, using
the operating-system versatile <code><a href="doParallel.html#topic+doParallel-package">doParallel-package</a></code>
and <code><a href="foreach.html#topic+foreach">foreach</a></code> infrastructure, using a default
<code><a href="parallel.html#topic+detectCores">detectCores</a> - 1</code> number of cores. Parallel computing
is generally advisable for the more complicated cumulative density
functions (i.e., univariate normal mixture, gamma, Weibull), where maximum
likelihood estimation is time-intensive, but is generally not advisable for
density functions with quickly calculated sample statistics (i.e., other
distribution functions). Warnings within the function provide sensible
recommendations, but users are encouraged to experiment to discover their
fastest implementation for their individual cases.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>D.obs</code></td>
<td>
<p>The value of the test statistic <em>D</em> for the observed
sample.</p>
</td></tr> <tr><td><code>D.sim</code></td>
<td>
<p>Simulation distribution of test statistics, with
<code>length = nreps</code>. This can be used to calculate critical values; see
examples.</p>
</td></tr> <tr><td><code>p.value</code></td>
<td>
<p><em>p</em>-value of the test, calculated as
<code class="reqn">(\sum(D.sim &gt; D.obs) + 1) / (nreps + 1)</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Kolmogorov-Smirnov (such as <code>ks.test</code>) is only valid as a
goodness-of-fit test when the population parameters are known. This is
typically not the case in practice. This invalidation occurs because
estimating the parameters changes the null distribution of the test
statistic; i.e., using the sample to estimate population parameters brings
the Kolmogorov-Smirnov test statistic <em>D</em> closer to the null
distribution than it would be under the hypothesis where the population
parameters are known. In other words, it is biased and results in increased
Type II error rates. Lilliefors (1967, 1969) provided a solution, using
Monte Carlo simulation to approximate the shape of the null distribution
when the sample statistics are used to estimate population parameters, and
to use this null distribution as the basis for critical values. The
function <code>LcKS</code> generalizes this solution for a range of continuous
distributions.
</p>


<h3>Author(s)</h3>

<p>Phil Novack-Gottshall <a href="mailto:pnovack-gottshall@ben.edu">pnovack-gottshall@ben.edu</a>, based on
code from Charles Geyer (University of Minnesota).
</p>


<h3>References</h3>

<p>Lilliefors, H. W. 1967. On the Kolmogorov-Smirnov test for
normality with mean and variance unknown. <em>Journal of the American
Statistical Association</em> 62(318):399-402.
</p>
<p>Lilliefors, H. W. 1969. On the Kolmogorov-Smirnov test for the
exponential distribution with mean unknown. <em>Journal of the American
Statistical Association</em> 64(325):387-389.
</p>
<p>Manly, B. F. J. 2004. <em>Randomization, Bootstrap and Monte
Carlo Methods in Biology</em>. Chapman &amp; Hall, Cornwall, Great Britain.
</p>
<p>Parsons, F. G., and P. H. Wirsching. 1982. A Kolmogorov-Smirnov
goodness-of-fit test for the two-parameter Weibull distribution when the
parameters are estimated from the data. <em>Microelectronics Reliability</em>
22(2):163-167.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for standard cumulative
distribution functions, <code><a href="#topic+plunif">plunif</a></code> for the loguniform cumulative
distribution function, and <code><a href="#topic+pmixnorm">pmixnorm</a></code> for the univariate normal
mixture cumulative distribution function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(200)
Lc &lt;- LcKS(x, cdf = "pnorm", nreps = 999)
hist(Lc$D.sim)
abline(v = Lc$D.obs, lty = 2)
print(Lc, max = 50)  # Print first 50 simulated statistics
# Approximate p-value (usually) &lt;&lt; 0.05

# Confirmation uncorrected version has increased Type II error rate when
#   using sample statistics to estimate parameters:
ks.test(x, "pnorm", mean(x), sd(x))   # p-value always larger, (usually) &gt; 0.05

# Confirm critical values for normal distribution are correct
nreps &lt;- 9999
x &lt;- rnorm(25)
Lc &lt;- LcKS(x, "pnorm", nreps = nreps)
sim.Ds &lt;- sort(Lc$D.sim)
crit &lt;- round(c(.8, .85, .9, .95, .99) * nreps, 0)
# Lilliefors' (1967) critical values, using improved values from
#   Parsons &amp; Wirsching (1982) (for n = 25):
# 0.141 0.148 0.157 0.172 0.201
round(sim.Ds[crit], 3)			# Approximately the same critical values

# Confirm critical values for exponential are the same as reported by Lilliefors (1969)
nreps &lt;- 9999
x &lt;- rexp(25)
Lc &lt;- LcKS(x, "pexp", nreps = nreps)
sim.Ds &lt;- sort(Lc$D.sim)
crit &lt;- round(c(.8, .85, .9, .95, .99) * nreps, 0)
# Lilliefors' (1969) critical values (for n = 25):
# 0.170 0.180 0.191 0.210 0.247
round(sim.Ds[crit], 3)			# Approximately the same critical values

## Not run: 
# Gamma and Weibull tests require functions from the 'MASS' package
# Takes time for maximum likelihood optimization of statistics
require(MASS)
x &lt;- runif(100, min = 1, max = 100)
Lc &lt;- LcKS(x, cdf = "pgamma", nreps = 499)
Lc$p.value

# Confirm critical values for Weibull the same as reported by Parsons &amp; Wirsching (1982)
nreps &lt;- 9999
x &lt;- rweibull(25, shape = 1, scale = 1)
Lc &lt;- LcKS(x, "pweibull", nreps = nreps)
sim.Ds &lt;- sort(Lc$D.sim)
crit &lt;- round(c(.8, .85, .9, .95, .99) * nreps, 0)
# Parsons &amp; Wirsching (1982) critical values (for n = 25):
# 0.141 0.148 0.157 0.172 0.201
round(sim.Ds[crit], 3)			# Approximately the same critical values

# Mixture test requires functions from the 'mclust' package
# Takes time to identify model parameters
require(mclust)
x &lt;- rmixnorm(200, mean = c(10, 20), sd = 2, pro = c(1,3))
Lc &lt;- LcKS(x, cdf = "pmixnorm", nreps = 499, G = 1:9)   # Default G (1:9) takes long time
Lc$p.value
G &lt;- Mclust(x)$parameters$variance$G              # Optimal model has only two components
Lc &lt;- LcKS(x, cdf = "pmixnorm", nreps = 499, G = G)     # Restricting to likely G saves time
# But note changes null hypothesis: now testing against just two-component mixture
Lc$p.value

# Running 'in parallel'
require(doParallel)
set.seed(3124)
x &lt;- rmixnorm(300, mean = c(110, 190, 200), sd = c(3, 15, .1), pro = c(1, 3, 1))
system.time(LcKS(x, "pgamma"))
system.time(LcKS(x, "pgamma", parallel = TRUE)) # Should be faster

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
