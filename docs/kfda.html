<!DOCTYPE html><html><head><title>Help for package kfda</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kfda}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#kfda'><p>Kernel Fisher Discriminant Analysis (KFDA)</p></a></li>
<li><a href='#kfda.predict'><p>Predict Method for Kernel Fisher Discriminant Analysis (KFDA) fit</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Kernel Fisher Discriminant Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-09-27</td>
</tr>
<tr>
<td>Author:</td>
<td>Donghwan Kim</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Donghwan Kim &lt;donhkim9714@korea.ac.kr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Kernel Fisher Discriminant Analysis (KFDA) is performed using Kernel Principal Component Analysis (KPCA) and Fisher Discriminant Analysis (FDA).
    There are some similar packages. First, 'lfda' is a package that performs Local Fisher Discriminant Analysis (LFDA) and performs other functions.
    In particular, 'lfda' seems to be impossible to test because it needs the label information of the data in the function argument. Also, the 'ks' package has a limited dimension, which makes it difficult to analyze properly.
    This package is a simple and practical package for KFDA based on the paper of Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) &lt;<a href="https://doi.org/10.1016%2Fj.patcog.2003.10.015">doi:10.1016/j.patcog.2003.10.015</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ainsuotain/kfda">https://github.com/ainsuotain/kfda</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), kernlab, MASS</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-09-27 00:52:55 UTC; David</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-09-27 11:06:54 UTC</td>
</tr>
</table>
<hr>
<h2 id='kfda'>Kernel Fisher Discriminant Analysis (KFDA)</h2><span id='topic+kfda'></span>

<h3>Description</h3>

<p>Train the trainData using KFDA. Basically, we run KFDA using Gaussian kernel. Returns trained KFDA object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfda(trainData = data, kernel.name = "rbfdot", kpar.sigma = 0.001, threshold = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfda_+3A_traindata">trainData</code></td>
<td>
<p>an optional <code>data frame</code> or <code>matrix</code> containing the variables in the model. In particular, the last column of the data frame should contain the target value.
</p>
</td></tr>
<tr><td><code id="kfda_+3A_kernel.name">kernel.name</code></td>
<td>
<p>the kernel function used in training and predicting. This parameter is fixed in the <code>rbfdot</code>(Gaussian kernel).</p>
</td></tr>
<tr><td><code id="kfda_+3A_kpar.sigma">kpar.sigma</code></td>
<td>

<p>hyper-parameter of selected kernel. <code>sigma</code> inverse kernel width for the Gaussian kernel function &quot;rbfdot&quot;.
</p>
</td></tr>
<tr><td><code id="kfda_+3A_threshold">threshold</code></td>
<td>

<p>the value of the eigenvalue under which principal components are ignored (only valid when features = 0). (default : 1e-05).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Train the trainData using KFDA. Basically, we run KFDA using Gaussian kernel. Returns trained KFDA object.
Since this function performs KFDA with the appropriate combination of <code>kpca</code> and <code>lda</code>, the following values can show the result of each function.
</p>


<h3>Value</h3>

<p>An object of class <code>kfda</code>.
</p>
<table>
<tr><td><code>kpca.train</code></td>
<td>
<p>An object of class &quot;kpca&quot;. It has results of <code>kpca</code> function. (see<code><a href="kernlab.html#topic+kpca">kpca</a></code> (in package <span class="pkg">kernlab</span>))</p>
</td></tr>
<tr><td><code>lda.rotation.train</code></td>
<td>
<p>The result of applying LDA, After KPCA is performed on trainData.</p>
</td></tr>
<tr><td><code>LDs</code></td>
<td>
<p>A dataframe of linear discriminants of LDA.</p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>A vector of class label of trainData.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This package is an early version and will be updated in the future.
</p>


<h3>Author(s)</h3>

<p>Donghwan Kim<br />
<a href="mailto:ainsuotain@hanmail.net">ainsuotain@hanmail.net</a>
<a href="mailto:donhkim9714@korea.ac.kr">donhkim9714@korea.ac.kr</a>
<a href="mailto:dhkim2@bistel.com">dhkim2@bistel.com</a>
</p>


<h3>References</h3>

<p>Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) &lt;DOI:10.1016/j.patcog.2003.10.015&gt;. Essence of kernel Fisher discriminant: KPCA plus LDA. <em>Pattern Recognition</em>, 37(10): 2097-2100.
</p>


<h3>See Also</h3>

<p><code><a href="kernlab.html#topic+kpca">kpca</a></code> (in package <span class="pkg">kernlab</span>)
<code><a href="MASS.html#topic+lda">lda</a></code> (in package <span class="pkg">MASS</span>)
<code><a href="#topic+kfda.predict">kfda.predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data input
data(iris)

# data separation
idx &lt;- sample(1:dim(iris)[1], round(dim(iris)[1]*0.7))
trainData &lt;- iris[idx, ]

# training KFDA model
kfda.model &lt;- kfda(trainData = trainData, kernel.name = "rbfdot")

# structure of kfda.model
str(kfda.model)
</code></pre>

<hr>
<h2 id='kfda.predict'>Predict Method for Kernel Fisher Discriminant Analysis (KFDA) fit</h2><span id='topic+kfda.predict'></span>

<h3>Description</h3>

<p>Test the testData using KFDA. This function is used after training phase is performed using the kfda function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfda.predict(object = obj, testData = data)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfda.predict_+3A_object">object</code></td>
<td>
<p>An <code>R</code> object of class <code>kfda</code>.</p>
</td></tr>
<tr><td><code id="kfda.predict_+3A_testdata">testData</code></td>
<td>
<p>an optional <code>data frame</code> or <code>matrix</code> containing the variables in the model. In particular, the order of variables in the data frame must be the same as trainData, and the target value must be removed in advance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since this function inherits <code>KPCA</code> and <code>LDA</code>, various learning can be possible by adjusting the hyper-parameters of each function.
</p>


<h3>Value</h3>

<p>The result of performing testData on the KFDA model.
</p>
<table>
<tr><td><code>class</code></td>
<td>
<p>A class label of testData.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>A posterior probabilities for the classes.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The scores of testData on up to <code>kfda</code> discriminant variables.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Donghwan Kim<br />
<a href="mailto:ainsuotain@hanmail.net">ainsuotain@hanmail.net</a>
<a href="mailto:donhkim9714@korea.ac.kr">donhkim9714@korea.ac.kr</a>
<a href="mailto:dhkim2@bistel.com">dhkim2@bistel.com</a>
</p>


<h3>References</h3>

<p>Yang, J., Jin, Z., Yang, J. Y., Zhang, D., and Frangi, A. F. (2004) &lt;DOI:10.1016/j.patcog.2003.10.015&gt;. Essence of kernel Fisher discriminant: KPCA plus LDA. <em>Pattern Recognition</em>, 37(10): 2097-2100.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kfda">kfda</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># data input
data(iris)

# data separation
idx &lt;- sample(1:dim(iris)[1], round(dim(iris)[1]*0.7))
trainData &lt;- iris[idx, ]
testData &lt;- iris[-(idx), -dim(iris)[2]]
testData.Label &lt;- iris[-(idx), dim(iris)[2]]

# training KFDA model
kfda.model &lt;- kfda(trainData = trainData, kernel.name = "rbfdot")

# testing new(test)data by KFDA model
pre &lt;- kfda.predict(object = kfda.model, testData = testData)

# plotting
plot(kfda.model$LDs, col = kfda.model$label, pch = 19, main = "Plot for KFDA")
points(pre$x, col = pre$class, cex = 2)
legend("topleft", legend = c("trainData","testData"), pch = c(19,1))

# prediction result
table(pre$class, (testData.Label))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
