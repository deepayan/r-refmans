<!DOCTYPE html><html lang="en-US"><head><title>Help for package nonprobsvy</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<script type="text/javascript" src="mathjax-config.js"></script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nonprobsvy}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cloglog_model_nonprobsvy'><p>Complementary log-log model for weights adjustment</p></a></li>
<li><a href='#confint.nonprobsvy'><p>Confidence Intervals for Model Parameters</p></a></li>
<li><a href='#controlInf'><p>Control parameters for inference</p></a></li>
<li><a href='#controlOut'><p>Control parameters for outcome model</p></a></li>
<li><a href='#controlSel'><p>Control parameters for selection model</p></a></li>
<li><a href='#genSimData'><p>Simulation data</p></a></li>
<li><a href='#logit_model_nonprobsvy'><p>Logit model for weights adjustment</p></a></li>
<li><a href='#nonprob'><p>Inference with the non-probability survey samples</p></a></li>
<li><a href='#pop.size'><p>Estimate size of population</p></a></li>
<li><a href='#probit_model_nonprobsvy'><p>Probit model for weights adjustment</p></a></li>
<li><a href='#summary.nonprobsvy'><p>Summary statistics for model of nonprobsvy class.</p></a></li>
<li><a href='#vcov.nonprobsvy'><p>Obtain Covariance Matrix estimation.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Inference Based on Non-Probability Samples</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical inference with non-probability samples when auxiliary information from external sources such as probability samples or population totals or means is available. Details can be found in: Wu et al. (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2019.1677241">doi:10.1080/01621459.2019.1677241</a>&gt;, Kim et al. (2021) &lt;<a href="https://doi.org/10.1111%2Frssa.12696">doi:10.1111/rssa.12696</a>&gt;, Wu et al. (2023) <a href="https://www150.statcan.gc.ca/n1/pub/12-001-x/2022002/article/00002-eng.htm">https://www150.statcan.gc.ca/n1/pub/12-001-x/2022002/article/00002-eng.htm</a>, Kim et al. (2021) <a href="https://www150.statcan.gc.ca/n1/pub/12-001-x/2021001/article/00004-eng.htm">https://www150.statcan.gc.ca/n1/pub/12-001-x/2021001/article/00004-eng.htm</a>, Kim et al. (2020) &lt;<a href="https://doi.org/10.1111%2Frssb.12354">doi:10.1111/rssb.12354</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>mathjaxr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ncn-foreigners/nonprobsvy">https://github.com/ncn-foreigners/nonprobsvy</a>,
<a href="https://ncn-foreigners.github.io/nonprobsvy/">https://ncn-foreigners.github.io/nonprobsvy/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ncn-foreigners/nonprobsvy/issues">https://github.com/ncn-foreigners/nonprobsvy/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>tinytest, covr, sampling, spelling</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), survey</td>
</tr>
<tr>
<td>Imports:</td>
<td>maxLik, stats, Matrix, MASS, ncvreg, mathjaxr, RANN, Rcpp (&ge;
1.0.12), nleqslv, doParallel, foreach, parallel</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-14 05:38:13 UTC; berenz</td>
</tr>
<tr>
<td>Author:</td>
<td>Łukasz Chrostowski [aut, cre],
  Maciej Beręsewicz <a href="https://orcid.org/0000-0002-8281-4301"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb],
  Piotr Chlebicki [aut, ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Łukasz Chrostowski &lt;lukchr@st.amu.edu.pl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-14 07:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cloglog_model_nonprobsvy'>Complementary log-log model for weights adjustment</h2><span id='topic+cloglog_model_nonprobsvy'></span>

<h3>Description</h3>

<p><code>cloglog_model_nonprobsvy</code> returns all the methods/objects/functions required to estimate the model, assuming a cloglog link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloglog_model_nonprobsvy(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cloglog_model_nonprobsvy_+3A_...">...</code></td>
<td>
<p>Additional, optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with selected methods/objects/functions.
</p>


<h3>Author(s)</h3>

<p>Łukasz Chrostowski, Maciej Beręsewicz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonprob">nonprob()</a></code> &ndash; for fitting procedure with non-probability samples.
</p>

<hr>
<h2 id='confint.nonprobsvy'>Confidence Intervals for Model Parameters</h2><span id='topic+confint.nonprobsvy'></span>

<h3>Description</h3>

<p>A function that computes confidence intervals
for selection model coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nonprobsvy'
confint(object, parm, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.nonprobsvy_+3A_object">object</code></td>
<td>
<p>object of nonprobsvy class.</p>
</td></tr>
<tr><td><code id="confint.nonprobsvy_+3A_parm">parm</code></td>
<td>
<p>names of parameters for which confidence intervals are to be
computed, if missing all parameters will be considered.</p>
</td></tr>
<tr><td><code id="confint.nonprobsvy_+3A_level">level</code></td>
<td>
<p>confidence level for intervals.</p>
</td></tr>
<tr><td><code id="confint.nonprobsvy_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with named columns that include upper and
lower limit of confidence intervals.
</p>

<hr>
<h2 id='controlInf'>Control parameters for inference</h2><span id='topic+controlInf'></span>

<h3>Description</h3>

<p><code>controlInf</code> constructs a list with all necessary control parameters
for statistical inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>controlInf(
  vars_selection = FALSE,
  var_method = c("analytic", "bootstrap"),
  rep_type = c("auto", "JK1", "JKn", "BRR", "bootstrap", "subbootstrap", "mrbbootstrap",
    "Fay"),
  bias_inf = c("union", "div"),
  num_boot = 500,
  bias_correction = FALSE,
  alpha = 0.05,
  cores = 1,
  keep_boot,
  nn_exact_se = FALSE,
  pi_ij
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="controlInf_+3A_vars_selection">vars_selection</code></td>
<td>
<p>If <code>TRUE</code>, then variables selection model is used.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_var_method">var_method</code></td>
<td>
<p>variance method.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_rep_type">rep_type</code></td>
<td>
<p>replication type for weights in the bootstrap method for variance estimation passed to <code><a href="survey.html#topic+as.svrepdesign">survey::as.svrepdesign()</a></code>.
Default is <code>subbootstrap</code>.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_bias_inf">bias_inf</code></td>
<td>
<p>inference method in the bias minimization.
</p>

<ul>
<li><p> if <code>union</code> then final model is fitting on union of selected variables for selection and outcome models
</p>
</li>
<li><p> if <code>div</code> then final model is fitting separately on division of selected variables into relevant ones for
selection and outcome model.
</p>
</li></ul>
</td></tr>
<tr><td><code id="controlInf_+3A_num_boot">num_boot</code></td>
<td>
<p>number of iteration for bootstrap algorithms.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_bias_correction">bias_correction</code></td>
<td>
<p>if <code>TRUE</code>, then bias minimization estimation used during fitting the model.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_alpha">alpha</code></td>
<td>
<p>Significance level, Default is 0.05.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_cores">cores</code></td>
<td>
<p>Number of cores in parallel computing.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_keep_boot">keep_boot</code></td>
<td>
<p>Logical indicating whether statistics from bootstrap should be kept.
By default set to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="controlInf_+3A_nn_exact_se">nn_exact_se</code></td>
<td>
<p>Logical value indicating whether to compute the exact
standard error estimate for <code>nn</code> or <code>pmm</code> estimator. The variance estimator for
estimation based on <code>nn</code> or <code>pmm</code> can be decomposed into three parts, with the
third being computed using covariance between imputed values for units in
probability sample using predictive matches from non-probability sample.
In most situations this term is negligible and is very computationally
expensive so by default this is set to <code>FALSE</code>, but it is recommended to
set this value to <code>TRUE</code> before submitting final results.</p>
</td></tr>
<tr><td><code id="controlInf_+3A_pi_ij">pi_ij</code></td>
<td>
<p>TODO, either matrix or <code>ppsmat</code> class object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with selected parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonprob">nonprob()</a></code> &ndash; for fitting procedure with non-probability samples.
</p>

<hr>
<h2 id='controlOut'>Control parameters for outcome model</h2><span id='topic+controlOut'></span>

<h3>Description</h3>

<p><code>controlOut</code> constructs a list with all necessary control parameters
for outcome model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>controlOut(
  epsilon = 1e-04,
  maxit = 100,
  trace = FALSE,
  k = 1,
  penalty = c("SCAD", "lasso", "MCP"),
  a_SCAD = 3.7,
  a_MCP = 3,
  lambda_min = 0.001,
  nlambda = 100,
  nfolds = 10,
  treetype = "kd",
  searchtype = "standard",
  predictive_match = 1:2,
  pmm_weights = c("none", "prop_dist"),
  pmm_k_choice = c("none", "min_var"),
  pmm_reg_engine = c("glm", "loess")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="controlOut_+3A_epsilon">epsilon</code></td>
<td>
<p>Tolerance for fitting algorithms. Default is <code>1e-6</code>.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_trace">trace</code></td>
<td>
<p>logical value. If <code>TRUE</code> trace steps of the fitting algorithms. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_k">k</code></td>
<td>
<p>The k parameter in the <code><a href="RANN.html#topic+nn2">RANN::nn2()</a></code> function. Default is 5.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_penalty">penalty</code></td>
<td>
<p>penalty algorithm for variable selection. Default is <code>SCAD</code></p>
</td></tr>
<tr><td><code id="controlOut_+3A_a_scad">a_SCAD</code></td>
<td>
<p>The tuning parameter of the SCAD penalty for outcome model. Default is 3.7.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_a_mcp">a_MCP</code></td>
<td>
<p>The tuning parameter of the MCP penalty for outcome model. Default is 3.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_lambda_min">lambda_min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of lambda.max. Default is .001.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values. Default is 100.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds during cross-validation for variables selection model.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_treetype">treetype</code></td>
<td>
<p>Type of tree for nearest neighbour imputation passed to <code><a href="RANN.html#topic+nn2">RANN::nn2()</a></code> function.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_searchtype">searchtype</code></td>
<td>
<p>Type of search for nearest neighbour imputation passed to <code><a href="RANN.html#topic+nn2">RANN::nn2()</a></code> function.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_predictive_match">predictive_match</code></td>
<td>
<p>(Only for predictive mean matching)
Indicates how to select 'closest' unit from nonprobability sample for each
unit in probability sample. Either <code>1</code> (default) or <code>2</code> where
<code>2</code> is matching by minimizing distance between \(\hat{y}_{i}\) for
\(i \in S_{A}\) and \(y_{j}\) for \(j \in S_{B}\) and <code>1</code>
is matching by minimizing distance between \(\hat{y}_{i}\) for
\(i \in S_{A}\) and \(\hat{y}_{i}\) for \(i \in S_{A}\).</p>
</td></tr>
<tr><td><code id="controlOut_+3A_pmm_weights">pmm_weights</code></td>
<td>
<p>(Only for predictive mean matching)
Indicate how to weight <code>k</code> nearest neighbours in \(S_{B}\) to
create imputed value for units in \(S_{A}\). The default value
<code>"none"</code> indicates that mean of <code>k</code> nearest \(y\)'s from
\(S_{B}\) should be used whereas <code>"prop_dist"</code> results in
weighted mean of these <code>k</code> values where weights are inversely
proportional to distance between matched values.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_pmm_k_choice">pmm_k_choice</code></td>
<td>
<p>Character value indicating how <code>k</code> hyper-parameter
should be chosen, by default <code>"none"</code> meaning <code>k</code> provided in
<code>control_outcome</code> argument will be used. For now the only other
option <code>"min_var"</code> means that <code>k</code>  will be chosen by minimizing
estimated variance of estimator for mean. Parameter <code>k</code> provided in
this control list will be chosen as starting point.</p>
</td></tr>
<tr><td><code id="controlOut_+3A_pmm_reg_engine">pmm_reg_engine</code></td>
<td>
<p>TODO</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with selected parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonprob">nonprob()</a></code> &ndash; for fitting procedure with non-probability samples.
</p>

<hr>
<h2 id='controlSel'>Control parameters for selection model</h2><span id='topic+controlSel'></span>

<h3>Description</h3>

<p><code>controlSel</code> constructs a list with all necessary control parameters
for selection model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>controlSel(
  method = "glm.fit",
  epsilon = 1e-04,
  maxit = 500,
  trace = FALSE,
  optimizer = c("maxLik", "optim"),
  maxLik_method = "NR",
  optim_method = "BFGS",
  dependence = FALSE,
  key = NULL,
  est_method_sel = c("mle", "gee"),
  h = c(1, 2),
  penalty = c("SCAD", "lasso", "MCP"),
  a_SCAD = 3.7,
  a_MCP = 3,
  lambda = -1,
  lambda_min = 0.001,
  nlambda = 50,
  nfolds = 10,
  print_level = 0,
  start_type = c("glm", "naive", "zero"),
  nleqslv_method = c("Broyden", "Newton"),
  nleqslv_global = c("dbldog", "pwldog", "cline", "qline", "gline", "hook", "none"),
  nleqslv_xscalm = c("fixed", "auto")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="controlSel_+3A_method">method</code></td>
<td>
<p>estimation method.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_epsilon">epsilon</code></td>
<td>
<p>Tolerance for fitting algorithms by default <code>1e-6</code>.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_trace">trace</code></td>
<td>
<p>logical value. If <code>TRUE</code> trace steps of the fitting algorithms. Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="controlSel_+3A_optimizer">optimizer</code></td>
<td>

<ul>
<li><p> optimization function for maximum likelihood estimation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="controlSel_+3A_maxlik_method">maxLik_method</code></td>
<td>
<p>maximisation method that will be passed to <code><a href="maxLik.html#topic+maxLik">maxLik::maxLik()</a></code> function. Default is <code>NR</code>.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_optim_method">optim_method</code></td>
<td>
<p>maximisation method that will be passed to <code><a href="stats.html#topic+optim">stats::optim()</a></code> function. Default is <code>BFGS</code>.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_dependence">dependence</code></td>
<td>
<p>logical value - <code>TRUE</code> if samples are dependent.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_key">key</code></td>
<td>
<p>binary key variable</p>
</td></tr>
<tr><td><code id="controlSel_+3A_est_method_sel">est_method_sel</code></td>
<td>
<p>Method of estimation for propensity score model.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_h">h</code></td>
<td>
<p>Smooth function for the generalized estimating equations methods taking the following values
</p>

<ul>
<li><p> if <code>1</code> then \(\mathbf{h}\left(\mathbf{x}, \boldsymbol{\theta}\right) =
  \frac{\pi(\mathbf{x}, \boldsymbol{\theta})}{\mathbf{x}}\)
</p>
</li>
<li><p> if <code>2</code> then \( \mathbf{h}\left(\mathbf{x}, \boldsymbol{\theta}\right) = \mathbf{x}\)
</p>
</li></ul>
</td></tr>
<tr><td><code id="controlSel_+3A_penalty">penalty</code></td>
<td>
<p>The penanlization function used during variables selection.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_a_scad">a_SCAD</code></td>
<td>
<p>The tuning parameter of the SCAD penalty for selection model. Default is 3.7.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_a_mcp">a_MCP</code></td>
<td>
<p>The tuning parameter of the MCP penalty for selection model. Default is 3.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_lambda">lambda</code></td>
<td>
<p>A user-specified \(\lambda\) value during variable selection model fitting.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_lambda_min">lambda_min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of <code>lambda.max</code>. Default is .001.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values. Default is 50.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds for cross validation. Default is 10.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_print_level">print_level</code></td>
<td>
<p>this argument determines the level of printing which is done during the optimization (for propensity score model) process.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_start_type">start_type</code></td>
<td>

<ul>
<li><p> Type of method for start points for model fitting taking the following values
</p>

<ul>
<li><p> if <code>glm</code> then start taken from the glm function called on samples.
</p>
</li>
<li><p> if <code>naive</code> then start consists of a vector which has the value of an estimated parameter for one-dimensional data (on intercept) and 0 for the rest.
</p>
</li>
<li><p> if <code>zero</code> then start is a vector of zeros.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="controlSel_+3A_nleqslv_method">nleqslv_method</code></td>
<td>
<p>The method that will be passed to <code><a href="nleqslv.html#topic+nleqslv">nleqslv::nleqslv()</a></code> function.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_nleqslv_global">nleqslv_global</code></td>
<td>
<p>The global strategy that will be passed to <code><a href="nleqslv.html#topic+nleqslv">nleqslv::nleqslv()</a></code> function.</p>
</td></tr>
<tr><td><code id="controlSel_+3A_nleqslv_xscalm">nleqslv_xscalm</code></td>
<td>
<p>The type of x scaling that will be passed to <code><a href="nleqslv.html#topic+nleqslv">nleqslv::nleqslv()</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with selected parameters.
</p>


<h3>Author(s)</h3>

<p>Łukasz Chrostowski, Maciej Beręsewicz
<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonprob">nonprob()</a></code> &ndash; for fitting procedure with non-probability samples.
</p>

<hr>
<h2 id='genSimData'>Simulation data</h2><span id='topic+genSimData'></span>

<h3>Description</h3>

<p>Generate simulated data according to Chen, Li &amp; Wu (2020), section 5.
</p>
<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>


<h3>Usage</h3>

<pre><code class='language-R'>genSimData(N = 10000, n = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genSimData_+3A_n">N</code></td>
<td>
<p><code>integer</code>, population size, default 10000</p>
</td></tr>
<tr><td><code id="genSimData_+3A_n">n</code></td>
<td>
<p><code>integer</code>, big data sample, default 1000</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>genSimData</code> returns a data.frame, with the following columns:
</p>

<ul>
<li><p>x0 &ndash; intercept
</p>
</li>
<li><p>x1 &ndash; the first variable based on z1
</p>
</li>
<li><p>x2 &ndash; the second variable based on z2 and x1
</p>
</li>
<li><p>x3 &ndash; the third variable based on z3 and x1 and x2
</p>
</li>
<li><p>x4 &ndash; the third variable based on z4 and x1, x2 and x3
</p>
</li>
<li><p>\(y30\) &ndash; \(y\) generated from the model \(y=2+x1+x2+x3+x4+\sigma \cdot \varepsilon\), so the cor(y,y_hat) = 0.30
</p>
</li>
<li><p>\(y60\) &ndash; \(y\) generated from the model \(y=2+x1+x2+x3+x4+\sigma \cdot \varepsilon\), so the cor(y,y_hat) = 0.60
</p>
</li>
<li><p>\(y80\) &ndash; \(y\) generated from the model \(y=2+x1+x2+x3+x4+\sigma \cdot \varepsilon\), so the cor(y,y_hat) = 0.80
</p>
</li>
<li><p>rho &ndash; true propensity scores for big data such that sum(rho)=n
</p>
</li>
<li><p>srs &ndash; probabilities of inclusion to random sample such that max(srs)/min(srs)=50
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Łukasz Chrostowski, Maciej Beręsewicz
</p>


<h3>References</h3>

<p>Chen, Y., Li, P., &amp; Wu, C. (2020). Doubly Robust Inference With Nonprobability Survey Samples. Journal of the American Statistical Association, 115(532), 2011–2021. doi:10.1080/01621459.2019.1677241
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data with N=20000 and n=2000
genSimData(N = 20000, n = 2000)

## generate data when big data is almost as N
genSimData(N = 10000, n = 9000)

</code></pre>

<hr>
<h2 id='logit_model_nonprobsvy'>Logit model for weights adjustment</h2><span id='topic+logit_model_nonprobsvy'></span>

<h3>Description</h3>

<p><code>logit_model_nonprobsvy</code> returns all the methods/objects/functions required to estimate the model, assuming a logit link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit_model_nonprobsvy(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logit_model_nonprobsvy_+3A_...">...</code></td>
<td>
<p>Additional, optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with selected methods/objects/functions.
</p>


<h3>Author(s)</h3>

<p>Łukasz Chrostowski, Maciej Beręsewicz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonprob">nonprob()</a></code> &ndash; for fitting procedure with non-probability samples.
</p>

<hr>
<h2 id='nonprob'>Inference with the non-probability survey samples</h2><span id='topic+nonprob'></span>

<h3>Description</h3>

<p><code>nonprob</code> fits model for inference based on non-probability surveys (including big data) using various methods.
The function allows you to estimate the population mean with access to a reference probability sample, as well as sums and means of covariates.
</p>
<p>The package implements state-of-the-art approaches recently proposed in the literature: Chen et al. (2020),
Yang et al. (2020), Wu (2022) and uses the <a href="https://CRAN.R-project.org/package=survey">Lumley 2004</a> <code>survey</code> package for inference.
</p>
<p>It provides propensity score weighting (e.g. with calibration constraints), mass imputation (e.g. nearest neighbour) and
doubly robust estimators that take into account minimisation of the asymptotic bias of the population mean estimators or
variable selection.
The package uses <code>survey</code> package functionality when a probability sample is available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonprob(
  data,
  selection = NULL,
  outcome = NULL,
  target = NULL,
  svydesign = NULL,
  pop_totals = NULL,
  pop_means = NULL,
  pop_size = NULL,
  method_selection = c("logit", "cloglog", "probit"),
  method_outcome = c("glm", "nn", "pmm"),
  family_outcome = c("gaussian", "binomial", "poisson"),
  subset = NULL,
  strata = NULL,
  weights = NULL,
  na_action = NULL,
  control_selection = controlSel(),
  control_outcome = controlOut(),
  control_inference = controlInf(),
  start_selection = NULL,
  start_outcome = NULL,
  verbose = FALSE,
  x = TRUE,
  y = TRUE,
  se = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nonprob_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with data from the non-probability sample.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_selection">selection</code></td>
<td>
<p><code>formula</code>, the selection (propensity) equation.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_outcome">outcome</code></td>
<td>
<p><code>formula</code>, the outcome equation.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_target">target</code></td>
<td>
<p><code>formula</code> with target variables.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_svydesign">svydesign</code></td>
<td>
<p>an optional <code>svydesign</code> object (from the survey package) containing probability sample and design weights.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_pop_totals">pop_totals</code></td>
<td>
<p>an optional <code style="white-space: pre;">&#8288;named vector&#8288;</code> with population totals of the covariates.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_pop_means">pop_means</code></td>
<td>
<p>an optional <code style="white-space: pre;">&#8288;named vector&#8288;</code> with population means of the covariates.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_pop_size">pop_size</code></td>
<td>
<p>an optional <code>double</code> with population size.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_method_selection">method_selection</code></td>
<td>
<p>a <code>character</code> with method for propensity scores estimation.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_method_outcome">method_outcome</code></td>
<td>
<p>a <code>character</code> with method for response variable estimation.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_family_outcome">family_outcome</code></td>
<td>
<p>a <code>character</code> string describing the error distribution and link function to be used in the model. Default is &quot;gaussian&quot;. Currently supports: gaussian with identity link, poisson and binomial.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_subset">subset</code></td>
<td>
<p>an optional <code>vector</code> specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_strata">strata</code></td>
<td>
<p>an optional <code>vector</code> specifying strata.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_weights">weights</code></td>
<td>
<p>an optional <code>vector</code> of prior weights to be used in the fitting process. Should be NULL or a numeric vector. It is assumed that this vector contains frequency or analytic weights.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_na_action">na_action</code></td>
<td>
<p>a function which indicates what should happen when the data contain <code>NAs</code>.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_control_selection">control_selection</code></td>
<td>
<p>a <code>list</code> indicating parameters to use in fitting selection model for propensity scores.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_control_outcome">control_outcome</code></td>
<td>
<p>a <code>list</code> indicating parameters to use in fitting model for outcome variable.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_control_inference">control_inference</code></td>
<td>
<p>a <code>list</code> indicating parameters to use in inference based on probability and non-probability samples, contains parameters such as estimation method or variance method.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_start_selection">start_selection</code></td>
<td>
<p>an optional <code>vector</code> with starting values for the parameters of the selection equation.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_start_outcome">start_outcome</code></td>
<td>
<p>an optional <code>vector</code> with starting values for the parameters of the outcome equation.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_verbose">verbose</code></td>
<td>
<p>verbose, numeric.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_x">x</code></td>
<td>
<p>Logical value indicating whether to return model matrix of covariates as a part of output.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_y">y</code></td>
<td>
<p>Logical value indicating whether to return vector of outcome variable as a part of output.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_se">se</code></td>
<td>
<p>Logical value indicating whether to calculate and return standard error of estimated mean.</p>
</td></tr>
<tr><td><code id="nonprob_+3A_...">...</code></td>
<td>
<p>Additional, optional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let \(y\) be the response variable for which we want to estimate the population mean,
given by \[\mu_{y} = \frac{1}{N} \sum_{i=1}^N y_{i}.\] For this purpose we consider data integration
with the following structure. Let \(S_A\) be the non-probability sample with the design matrix of covariates as
\[
\boldsymbol{X}_A =
  \begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1p} \cr
x_{21} & x_{22} & \cdots & x_{2p} \cr
\vdots & \vdots & \ddots & \vdots \cr
x_{n_{A}1} & x_{n_{A}2} & \cdots & x_{n_{A}p} \cr
\end{bmatrix}
\]
and vector of outcome variable
\[
\boldsymbol{y} =
  \begin{bmatrix}
y_{1} \cr
y_{2} \cr
\vdots \cr
y_{n_{A}}.
\end{bmatrix}
\]
On the other hand, let \(S_B\) be the probability sample with design matrix of covariates be
\[
\boldsymbol{X}_B =
  \begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1p} \cr
x_{21} & x_{22} & \cdots & x_{2p} \cr
\vdots & \vdots & \ddots & \vdots \cr
x_{n_{B}1} & x_{n_{B}2} & \cdots & x_{n_{B}p}. \cr
\end{bmatrix}
\]
Instead of a sample of units we can consider a vector of population sums in the form of \(\tau_x = (\sum_{i \in \mathcal{U}}\boldsymbol{x}_{i1}, \sum_{i \in \mathcal{U}}\boldsymbol{x}_{i2}, ..., \sum_{i \in \mathcal{U}}\boldsymbol{x}_{ip})\) or means
\(\frac{\tau_x}{N}\), where \(\mathcal{U}\) refers to a finite population. Note that we do not assume access to the response variable for \(S_B\).
In general we make the following assumptions:
</p>

<ol>
<li><p> The selection indicator of belonging to non-probability sample \(R_{i}\) and the response variable \(y_i\) are independent given the set of covariates \(\boldsymbol{x}_i\).
</p>
</li>
<li><p> All units have a non-zero propensity score, i.e., \(\pi_{i}^{A} > 0\) for all i.
</p>
</li>
<li><p> The indicator variables \(R_{i}^{A}\) and \(R_{j}^{A}\) are independent for given \(\boldsymbol{x}_i\) and \(\boldsymbol{x}_j\) for \(i \neq j\).
</p>
</li></ol>

<p>There are three possible approaches to the problem of estimating population mean using non-probability samples:
</p>

<ol>
<li><p> Inverse probability weighting - The main drawback of non-probability sampling is the unknown selection mechanism for a unit to be included in the sample.
This is why we talk about the so-called &quot;biased sample&quot; problem. The inverse probability approach is based on the assumption that a reference probability sample
is available and therefore we can estimate the propensity score of the selection mechanism.
The estimator has the following form:
\[\hat{\mu}_{IPW} = \frac{1}{N^{A}}\sum_{i \in S_{A}} \frac{y_{i}}{\hat{\pi}_{i}^{A}}.\]
For this purpose several estimation methods can be considered. The first approach is maximum likelihood estimation with a corrected
log-likelihood function, which is given by the following formula
\[
 \ell^{*}(\boldsymbol{\theta}) = \sum_{i \in S_{A}}\log \left\lbrace \frac{\pi(\boldsymbol{x}_{i}, \boldsymbol{\theta})}{1 - \pi(\boldsymbol{x}_{i},\boldsymbol{\theta})}\right\rbrace + \sum_{i \in S_{B}}d_{i}^{B}\log \left\lbrace 1 - \pi({\boldsymbol{x}_{i},\boldsymbol{\theta})}\right\rbrace.\]
In the literature, the main approach to modelling propensity scores is based on the logit link function.
However, we extend the propensity score model with the additional link functions such as cloglog and probit.
The pseudo-score equations derived from ML methods can be replaced by the idea of generalised estimating equations
with calibration constraints defined by equations.
\[
 \mathbf{U}(\boldsymbol{\theta})=\sum_{i \in S_A} \mathbf{h}\left(\mathbf{x}_i, \boldsymbol{\theta}\right)-\sum_{i \in S_B} d_i^B \pi\left(\mathbf{x}_i, \boldsymbol{\theta}\right) \mathbf{h}\left(\mathbf{x}_i, \boldsymbol{\theta}\right).\]
Notice that for \( \mathbf{h}\left(\mathbf{x}_i, \boldsymbol{\theta}\right) = \frac{\pi(\boldsymbol{x}, \boldsymbol{\theta})}{\boldsymbol{x}}\) We do not need a probability sample and can use a vector of population totals/means.
</p>
</li>
<li><p> Mass imputation &ndash; This method is based on a framework where imputed values of outcome variables are created for the entire probability sample. In this case, we treat the large sample as a training data set that is used to build an imputation model.
Using the imputed values for the probability sample and the (known) design weights,
we can build a population mean estimator of the form:
\[\hat{\mu}_{MI} = \frac{1}{N^B}\sum_{i \in S_{B}} d_{i}^{B} \hat{y}_i.\]
It opens the the door to a very flexible method for imputation models. The package uses generalized linear models from <code><a href="stats.html#topic+glm">stats::glm()</a></code>,
the nearest neighbour algorithm using <code><a href="RANN.html#topic+nn2">RANN::nn2()</a></code> and predictive mean matching.
</p>
</li>
<li><p> Doubly robust estimation &ndash; The IPW and MI estimators are sensitive to misspecified models for the propensity score and outcome variable, respectively.
To this end, so-called doubly robust methods are presented that take these problems into account.
It is a simple idea to combine propensity score and imputation models during inference, leading to the following estimator
\[\hat{\mu}_{DR} = \frac{1}{N^A}\sum_{i \in S_A} \hat{d}_i^A (y_i - \hat{y}_i) + \frac{1}{N^B}\sum_{i \in S_B} d_i^B \hat{y}_i.\]
In addition, an approach based directly on bias minimisation has been implemented. The following formula
\[
   \begin{aligned}
   bias(\hat{\mu}_{DR}) = & \mathbb{E} (\hat{\mu}_{DR} - \mu) \cr = & \mathbb{E} \left\lbrace \frac{1}{N} \sum_{i=1}^N (\frac{R_i^A}{\pi_i^A (\boldsymbol{x}_i^{\mathrm{T}} \boldsymbol{\theta})}
   - 1 ) (y_i - \operatorname{m}(\boldsymbol{x}_i^{\mathrm{T}} \boldsymbol{\beta})) \right\rbrace \cr + & \mathbb{E} \left\lbrace \frac{1}{N} \sum_{i=1}^N (R_i^B d_i^B - 1) \operatorname{m}( \boldsymbol{x}_i^{\mathrm{T}} \boldsymbol{\beta}) \right\rbrace,
   \end{aligned}
   \]
lead us to system of equations
\[
   \begin{aligned}
   J(\theta, \beta) =
   \left\lbrace
   \begin{array}{c}
                      J_1(\theta, \beta) \cr
                      J_2(\theta, \beta)
                      \end{array}\right\rbrace = \left\lbrace \begin{array}{c}
                                               \sum_{i=1}^N R_i^A\ \left\lbrace \frac{1}{\pi(\boldsymbol{x}_i, \boldsymbol{\theta})}-1 \right\rbrace \left\lbrace y_i-m(\boldsymbol{x}_i, \boldsymbol{\beta}) \right\rbrace \boldsymbol{x}_i \cr
                                               \sum_{i=1}^N \frac{R_i^A}{\pi(\boldsymbol{x}_i, \boldsymbol{\theta})} \frac{\partial m(\boldsymbol{x}_i, \boldsymbol{\beta})}{\partial \boldsymbol{\beta}}
                                               - \sum_{i \in \mathcal{S}_{\mathrm{B}}} d_i^{\mathrm{B}} \frac{\partial m(\boldsymbol{x}_i, \boldsymbol{\beta})}{\partial \boldsymbol{\beta}}
  \end{array} \right\rbrace,
  \end{aligned}
  \]
where \(m\left(\boldsymbol{x}_{i}, \boldsymbol{\beta}\right)\) is a mass imputation (regression) model for the outcome variable and
propensity scores \(\pi_i^A\) are estimated using a <code>logit</code> function for the model. As with the <code>MLE</code> and <code>GEE</code> approaches we have extended
this method to <code>cloglog</code> and <code>probit</code> links.
</p>
</li></ol>

<p>As it is not straightforward to calculate the variances of these estimators, asymptotic equivalents of the variances derived using the Taylor approximation have been proposed in the literature.
Details can be found <a href="https://ncn-foreigners.github.io/nonprobsvy-book/intro.html">here</a>.
In addition, a bootstrap approach can be used for variance estimation.
</p>
<p>The function also allows variables selection using known methods that have been implemented to handle the integration of probability and non-probability sampling.
In the presence of high-dimensional data, variable selection is important, because it can reduce the variability in the estimate that results from using irrelevant variables to build the model.
Let \(\operatorname{U}\left( \boldsymbol{\theta}, \boldsymbol{\beta} \right)\) be the joint estimating function for \(\left( \boldsymbol{\theta}, \boldsymbol{\beta} \right)\). We define the
penalized estimating functions as
\[
  \operatorname{U}^p \left(\boldsymbol{\theta}, \boldsymbol{\beta}\right) = \operatorname{U}\left(\boldsymbol{\theta}, \boldsymbol{\beta}\right) - \left\lbrace \begin{array}{c}
  q_{\lambda_\theta}(|\boldsymbol{\theta}|) \operatorname{sgn}(\boldsymbol{\theta}) \
  q_{\lambda_\beta}(|\boldsymbol{\beta}|) \operatorname{sgn}(\boldsymbol{\beta})
  \end{array} \right\rbrace,
  \]
where \(\lambda_{\theta}\) and \(q_{\lambda_{\beta}}\) are some smooth functions. We let \(q_{\lambda} \left(x\right) = \frac{\partial p_{\lambda}}{\partial x}\), where \(p_{\lambda}\) is some penalization function.
Details of penalization functions and techniques for solving this type of equation can be found <a href="https://ncn-foreigners.github.io/nonprobsvy-book/variableselection.html">here</a>.
To use the variable selection model, set the <code>vars_selection</code> parameter in the <code><a href="#topic+controlInf">controlInf()</a></code> function to <code>TRUE</code>. In addition, in the other control functions such as <code><a href="#topic+controlSel">controlSel()</a></code> and <code><a href="#topic+controlOut">controlOut()</a></code>
you can set parameters for the selection of the relevant variables, such as the number of folds during cross-validation algorithm or the lambda value for penalizations. Details can be found
in the documentation of the control functions for <code>nonprob</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>c("nonprobsvy", "nonprobsvy_dr")</code> in case of doubly robust estimator,
<code>c("nonprobsvy", "nonprobsvy_mi")</code> in case of mass imputation estimator and
<code>c("nonprobsvy", "nonprobsvy_ipw")</code> in case of inverse probability weighting estimator
with type <code>list</code> containing:<br />
</p>

<ul>
<li><p><code>X</code> &ndash; model matrix containing data from probability and non-probability samples if specified at a function call.
</p>
</li>
<li><p><code>y</code> &ndash; list of vector of outcome variables if specified at a function call.
</p>
</li>
<li><p><code>R</code> &ndash; vector indicating the probablistic (0) or non-probablistic (1) units in the matrix X.
</p>
</li>
<li><p><code>prob</code> &ndash; vector of estimated propensity scores for non-probability sample.
</p>
</li>
<li><p><code>weights</code> &ndash; vector of estimated weights for non-probability sample.
</p>
</li>
<li><p><code>control</code> &ndash; list of control functions.
</p>
</li>
<li><p><code>output</code> &ndash; output of the model with information on the estimated population mean and standard errors.
</p>
</li>
<li><p><code>SE</code> &ndash; standard error of the estimator of the population mean, divided into errors from probability and non-probability samples.
</p>
</li>
<li><p><code>confidence_interval</code> &ndash; confidence interval of population mean estimator.
</p>
</li>
<li><p><code>nonprob_size</code> &ndash; size of non-probability sample.
</p>
</li>
<li><p><code>prob_size</code> &ndash; size of probability sample.
</p>
</li>
<li><p><code>pop_size</code> &ndash; estimated population size derived from estimated weights (non-probability sample) or known design weights (probability sample).
</p>
</li>
<li><p><code>pop_totals</code> &ndash; the total values of the auxiliary variables derived from a probability sample or vector of total/mean values.
</p>
</li>
<li><p><code>outcome</code> &ndash; list containing information about the fitting of the mass imputation model, in the case of regression model the object containing the list returned by
<code><a href="stats.html#topic+glm">stats::glm()</a></code>, in the case of the nearest neighbour imputation the object containing list returned by <code><a href="RANN.html#topic+nn2">RANN::nn2()</a></code>. If <code>bias_correction</code> in <code><a href="#topic+controlInf">controlInf()</a></code> is set to <code>TRUE</code>, the estimation is based on
the joint estimating equations for the <code>selection</code> and <code>outcome</code> model and therefore, the list is different from the one returned by the <code><a href="stats.html#topic+glm">stats::glm()</a></code> function and contains elements such as
</p>

<ul>
<li><p><code>coefficients</code> &ndash; estimated coefficients of the regression model.
</p>
</li>
<li><p><code>std_err</code> &ndash; standard errors of the estimated coefficients.
</p>
</li>
<li><p><code>residuals</code> &ndash; The response residuals.
</p>
</li>
<li><p><code>variance_covariance</code> &ndash; The variance-covariance matrix of the coefficient estimates.
</p>
</li>
<li><p><code>df_residual</code> &ndash; The degrees of freedom for residuals.
</p>
</li>
<li><p><code>family</code> &ndash; specifies the error distribution and link function to be used in the model.
</p>
</li>
<li><p><code>fitted.values</code> &ndash; The predicted values of the response variable based on the fitted model.
</p>
</li>
<li><p><code>linear.predictors</code> &ndash; The linear fit on link scale.
</p>
</li>
<li><p><code>X</code> &ndash; The design matrix.
</p>
</li>
<li><p><code>method</code> &ndash; set on <code>glm</code>, since the regression method.
</p>
</li>
<li><p><code>model_frame</code> &ndash; Matrix of data from probability sample used for mass imputation.
</p>
</li></ul>


<p>In addition, if the variable selection model for the outcome variable is fitting, the list includes the
</p>

<ul>
<li><p><code>cve</code> &ndash; the error for each value of <code>lambda</code>, averaged across the cross-validation folds.
</p>
</li></ul>

</li>
<li><p><code>selection</code> &ndash; list containing information about fitting of propensity score model, such as
</p>

<ul>
<li><p><code>coefficients</code> &ndash; a named vector of coefficients.
</p>
</li>
<li><p><code>std_err</code> &ndash; standard errors of the estimated model coefficients.
</p>
</li>
<li><p><code>residuals</code> &ndash; the response residuals.
</p>
</li>
<li><p><code>variance</code> &ndash; the root mean square error.
</p>
</li>
<li><p><code>fitted_values</code> &ndash; the fitted mean values, obtained by transforming the linear predictors by the inverse of the link function.
</p>
</li>
<li><p><code>link</code> &ndash; the <code>link</code> object used.
</p>
</li>
<li><p><code>linear_predictors</code> &ndash; the linear fit on link scale.
</p>
</li>
<li><p><code>aic</code> &ndash;	A version of Akaike's An Information Criterion, minus twice the maximized log-likelihood plus twice the number of parameters.
</p>
</li>
<li><p><code>weights</code> &ndash; vector of estimated weights for non-probability sample.
</p>
</li>
<li><p><code>prior.weights</code> &ndash; the weights initially supplied, a vector of 1s if none were.
</p>
</li>
<li><p><code>est_totals</code> &ndash; the estimated total values of auxiliary variables derived from a non-probability sample.
</p>
</li>
<li><p><code>formula</code> &ndash; the formula supplied.
</p>
</li>
<li><p><code>df_residual</code> &ndash; the residual degrees of freedom.
</p>
</li>
<li><p><code>log_likelihood</code> &ndash; value of log-likelihood function if <code>mle</code> method, in the other case <code>NA</code>.
</p>
</li>
<li><p><code>cve</code> &ndash; the error for each value of the <code>lambda</code>, averaged across the cross-validation folds for the variable selection model
when the propensity score model is fitting. Returned only if selection of variables for the model is used.
</p>
</li>
<li><p><code>method_selection</code> &ndash; Link function, e.g. <code>logit</code>, <code>cloglog</code> or <code>probit</code>.
</p>
</li>
<li><p><code>hessian</code> &ndash; Hessian Gradient of the log-likelihood function from <code>mle</code> method.
</p>
</li>
<li><p><code>gradient</code> &ndash; Gradient of the log-likelihood function from <code>mle</code> method.
</p>
</li>
<li><p><code>method</code> &ndash; An estimation method for selection model, e.g. <code>mle</code> or <code>gee</code>.
</p>
</li>
<li><p><code>prob_der</code> &ndash; Derivative of the inclusion probability function for units in a non&ndash;probability sample.
</p>
</li>
<li><p><code>prob_rand</code> &ndash; Inclusion probabilities for unit from a probabiliy sample from <code>svydesign</code> object.
</p>
</li>
<li><p><code>prob_rand_est</code> &ndash; Inclusion probabilites to a non&ndash;probabiliy sample for unit from probability sample.
</p>
</li>
<li><p><code>prob_rand_est_der</code> &ndash; Derivative of the inclusion probabilites to a non&ndash;probabiliy sample for unit from probability sample.
</p>
</li></ul>


</li>
<li><p><code>stat</code> &ndash; matrix of the estimated population means in each bootstrap iteration.
Returned only if a bootstrap method is used to estimate the variance and <code>keep_boot</code> in
<code><a href="#topic+controlInf">controlInf()</a></code> is set on <code>TRUE</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Łukasz Chrostowski, Maciej Beręsewicz
</p>
<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>


<h3>References</h3>

<p>Kim JK, Park S, Chen Y, Wu C. Combining non-probability and
probability survey samples through mass imputation. J R Stat Soc Series A. 2021;184:941–
963.
</p>
<p>Shu Yang, Jae Kwang Kim, Rui Song. Doubly robust inference when combining probability
and non-probability samples with high dimensional data. J. R. Statist. Soc. B (2020)
</p>
<p>Yilin Chen , Pengfei Li &amp; Changbao Wu (2020) Doubly Robust Inference
With Nonprobability Survey Samples, Journal of the American Statistical Association, 115:532,
2011-2021
</p>
<p>Shu Yang, Jae Kwang Kim and Youngdeok Hwang Integration of data from
probability surveys and big found data for finite population inference using mass imputation.
Survey Methodology, June 2021 29 Vol. 47, No. 1, pp. 29-58
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">stats::optim()</a></code> &ndash; For more information on the <code>optim</code> function used in the
<code>optim</code> method of propensity score model fitting.
</p>
<p><code><a href="maxLik.html#topic+maxLik">maxLik::maxLik()</a></code> &ndash; For more information on the <code>maxLik</code> function used in
<code>maxLik</code> method of propensity score model fitting.
</p>
<p><code><a href="ncvreg.html#topic+cv.ncvreg">ncvreg::cv.ncvreg()</a></code> &ndash; For more information on the <code>cv.ncvreg</code> function used in
variable selection for the outcome model.
</p>
<p><code><a href="nleqslv.html#topic+nleqslv">nleqslv::nleqslv()</a></code> &ndash; For more information on the <code>nleqslv</code> function used in
estimation process of the bias minimization approach.
</p>
<p><code><a href="stats.html#topic+glm">stats::glm()</a></code> &ndash; For more information about the generalised linear models used during mass imputation process.
</p>
<p><code><a href="RANN.html#topic+nn2">RANN::nn2()</a></code> &ndash; For more information about the nearest neighbour algorithm used during mass imputation process.
</p>
<p><code><a href="#topic+controlSel">controlSel()</a></code> &ndash; For the control parameters related to selection model.
</p>
<p><code><a href="#topic+controlOut">controlOut()</a></code> &ndash; For the control parameters related to outcome model.
</p>
<p><code><a href="#topic+controlInf">controlInf()</a></code> &ndash; For the control parameters related to statistical inference.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data based on Doubly Robust Inference With Non-probability Survey Samples (2021)
# Yilin Chen , Pengfei Li &amp; Changbao Wu
library(sampling)
set.seed(123)
# sizes of population and probability sample
N &lt;- 20000 # population
n_b &lt;- 1000 # probability
# data
z1 &lt;- rbinom(N, 1, 0.7)
z2 &lt;- runif(N, 0, 2)
z3 &lt;- rexp(N, 1)
z4 &lt;- rchisq(N, 4)

# covariates
x1 &lt;- z1
x2 &lt;- z2 + 0.3 * z2
x3 &lt;- z3 + 0.2 * (z1 + z2)
x4 &lt;- z4 + 0.1 * (z1 + z2 + z3)
epsilon &lt;- rnorm(N)
sigma_30 &lt;- 10.4
sigma_50 &lt;- 5.2
sigma_80 &lt;- 2.4

# response variables
y30 &lt;- 2 + x1 + x2 + x3 + x4 + sigma_30 * epsilon
y50 &lt;- 2 + x1 + x2 + x3 + x4 + sigma_50 * epsilon
y80 &lt;- 2 + x1 + x2 + x3 + x4 + sigma_80 * epsilon

# population
sim_data &lt;- data.frame(y30, y50, y80, x1, x2, x3, x4)
## propensity score model for non-probability sample (sum to 1000)
eta &lt;- -4.461 + 0.1 * x1 + 0.2 * x2 + 0.1 * x3 + 0.2 * x4
rho &lt;- plogis(eta)

# inclusion probabilities for probability sample
z_prob &lt;- x3 + 0.2051
sim_data$p_prob &lt;- inclusionprobabilities(z_prob, n = n_b)

# data
sim_data$flag_nonprob &lt;- UPpoisson(rho) ## sampling nonprob
sim_data$flag_prob &lt;- UPpoisson(sim_data$p_prob) ## sampling prob
nonprob_df &lt;- subset(sim_data, flag_nonprob == 1) ## non-probability sample
svyprob &lt;- svydesign(
  ids = ~1, probs = ~p_prob,
  data = subset(sim_data, flag_prob == 1),
  pps = "brewer"
) ## probability sample

## mass imputation estimator
MI_res &lt;- nonprob(
  outcome = y80 ~ x1 + x2 + x3 + x4,
  data = nonprob_df,
  svydesign = svyprob
)
summary(MI_res)
## inverse probability weighted estimator
IPW_res &lt;- nonprob(
  selection = ~ x1 + x2 + x3 + x4,
  target = ~y80,
  data = nonprob_df,
  svydesign = svyprob
)
summary(IPW_res)
## doubly robust estimator
DR_res &lt;- nonprob(
  outcome = y80 ~ x1 + x2 + x3 + x4,
  selection = ~ x1 + x2 + x3 + x4,
  data = nonprob_df,
  svydesign = svyprob
)
summary(DR_res)

</code></pre>

<hr>
<h2 id='pop.size'>Estimate size of population</h2><span id='topic+pop.size'></span>

<h3>Description</h3>

<p>Estimate size of population
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pop.size(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pop.size_+3A_object">object</code></td>
<td>
<p>object returned by <code>nonprobsvy</code>.</p>
</td></tr>
<tr><td><code id="pop.size_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector returning the value of the estimated population size.
</p>

<hr>
<h2 id='probit_model_nonprobsvy'>Probit model for weights adjustment</h2><span id='topic+probit_model_nonprobsvy'></span>

<h3>Description</h3>

<p><code>probit_model_nonprobsvy</code> returns all the methods/objects/functions required to estimate the model, assuming a probit link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit_model_nonprobsvy(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probit_model_nonprobsvy_+3A_...">...</code></td>
<td>
<p>Additional, optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with selected methods/objects/functions.
</p>


<h3>Author(s)</h3>

<p>Łukasz Chrostowski, Maciej Beręsewicz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonprob">nonprob()</a></code> &ndash; for fitting procedure with non-probability samples.
</p>

<hr>
<h2 id='summary.nonprobsvy'>Summary statistics for model of nonprobsvy class.</h2><span id='topic+summary.nonprobsvy'></span>

<h3>Description</h3>

<p>Summary statistics for model of nonprobsvy class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nonprobsvy'
summary(object, test = c("t", "z"), correlation = FALSE, cov = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.nonprobsvy_+3A_object">object</code></td>
<td>
<p>object of nonprobsvy class</p>
</td></tr>
<tr><td><code id="summary.nonprobsvy_+3A_test">test</code></td>
<td>
<p>Type of test for significance of parameters <code>"t"</code> for t-test
and <code>"z"</code> for normal approximation of students t distribution, by
default <code>"z"</code> is used if there are more than 30 degrees of freedom
and <code>"t"</code> is used in other cases.</p>
</td></tr>
<tr><td><code id="summary.nonprobsvy_+3A_correlation">correlation</code></td>
<td>
<p>correlation Logical value indicating whether correlation matrix should
be computed from covariance matrix by default <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summary.nonprobsvy_+3A_cov">cov</code></td>
<td>
<p>Covariance matrix corresponding to regression parameters</p>
</td></tr>
<tr><td><code id="summary.nonprobsvy_+3A_...">...</code></td>
<td>
<p>Additional optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code>summary_nonprobsvy</code> class containing:
</p>

<ul>
<li> <p><code>call</code> &ndash; A call which created <code>object</code>.
</p>
</li>
<li> <p><code>pop_total</code> &ndash; A list containing information about the estimated population mean, its standard error and confidence interval.
</p>
</li>
<li> <p><code>sample_size</code> &ndash; The size of the samples used in the model.
</p>
</li>
<li> <p><code>population_size</code> &ndash; The estimated size of the population from which the non&ndash;probability sample was drawn.
</p>
</li>
<li> <p><code>test</code> &ndash; Type of statistical test performed.
</p>
</li>
<li> <p><code>control</code> &ndash; A List of control parameters used in fitting the model.
</p>
</li>
<li> <p><code>model</code> &ndash; A descriptive name of the model used, e.g., &quot;Doubly-Robust&quot;, &quot;Inverse probability weighted&quot;, or &quot;Mass Imputation&quot;.
</p>
</li>
<li> <p><code>aic</code> &ndash; Akaike's information criterion.
</p>
</li>
<li> <p><code>bic</code> &ndash; Bayesian (Schwarz's) information criterion.
</p>
</li>
<li> <p><code>residuals</code> &ndash; Residuals from the model, providing information on the difference between observed and predicted values.
</p>
</li>
<li> <p><code>likelihood</code> &ndash; Logarithm of likelihood function evaluated at coefficients.
</p>
</li>
<li> <p><code>df_residual</code> &ndash; Residual degrees of freedom.
</p>
</li>
<li> <p><code>weights</code> &ndash; Distribution of estimated weights obtained from the model.
</p>
</li>
<li> <p><code>coef</code> &ndash; Regression coefficients estimated by the model.
</p>
</li>
<li> <p><code>std_err</code> &ndash; Standard errors of the regression coefficients.
</p>
</li>
<li> <p><code>w_val</code> &ndash; Wald statistic values for the significance testing of coefficients.
</p>
</li>
<li> <p><code>p_values</code> &ndash; P-values corresponding to the Wald statistic values, assessing the significance of coefficients.
</p>
</li>
<li> <p><code>crr</code> &ndash; The correlation matrix of the model coefficients, if requested.
</p>
</li>
<li> <p><code>confidence_interval_coef</code> &ndash; Confidence intervals for the model coefficients.
</p>
</li>
<li> <p><code>names</code> &ndash; Names of the fitted models.
</p>
</li></ul>


<hr>
<h2 id='vcov.nonprobsvy'>Obtain Covariance Matrix estimation.</h2><span id='topic+vcov.nonprobsvy'></span>

<h3>Description</h3>

<p>A <code>vcov</code> method for <code>nonprobsvy</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nonprobsvy'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vcov.nonprobsvy_+3A_object">object</code></td>
<td>
<p>object of nonprobsvy class.</p>
</td></tr>
<tr><td><code id="vcov.nonprobsvy_+3A_...">...</code></td>
<td>
<p>additional arguments for method functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a estimated covariance matrix for model coefficients
calculated from analytic hessian or Fisher information matrix usually
utilising asymptotic effectiveness of maximum likelihood estimates.
</p>


<h3>Value</h3>

<p>A covariance matrix for fitted coefficients
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
