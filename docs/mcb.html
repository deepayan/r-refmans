<!DOCTYPE html><html lang="en"><head><title>Help for package mcb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mcb}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Diabetes'><p>Diabetes</p></a></li>
<li><a href='#mcb'><p>Model Confidence Bound</p></a></li>
<li><a href='#mcb.compare'><p>Comparisons of Model Confidence Bounds for Different Variable selection Methods</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Model Confidence Bounds</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.15</td>
</tr>
<tr>
<td>Author:</td>
<td>Yang Li, Yichen Qin, Heming Deng</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Heming Deng&lt;dheming@ruc.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>When choosing proper variable selection methods, it is important to consider the uncertainty of a certain method. The model confidence bound for variable selection identifies two nested models (upper and lower confidence bound models) containing the true model at a given confidence level. A good variable selection method is the one of which the model confidence bound under a certain confidence level has the shortest width. When visualizing the variability of model selection and comparing different model selection procedures, model uncertainty curve is a good graphical tool. A good variable selection method is the one of whose model uncertainty curve will tend to arch towards the upper left corner. This function aims to obtain the model confidence bound and draw the model uncertainty curve of certain single model selection method under a coverage rate equal or little higher than user-given confidential level. About what model confidence bound is and how it work please see Li,Y., Luo,Y., Ferrari,D., Hu,X. and Qin,Y. (2019) Model Confidence Bounds for Variable Selection. Biometrics, 75:392-403. &lt;<a href="https://doi.org/10.1111%2Fbiom.13024">doi:10.1111/biom.13024</a>&gt;. Besides, 'flare' is needed only you apply the SQRT or LAD method ('mcb' totally has 8 methods). Although 'flare' has been archived by CRAN, you can still get it in <a href="https://CRAN.R-project.org/package=flare">https://CRAN.R-project.org/package=flare</a> and the latest version is useful for 'mcb'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel,methods,leaps,lars,MASS,glmnet,ncvreg,smoothmest,ggplot2,reshape2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>flare, testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-06-05 07:45:11 UTC; 超会议咸鱼</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-05 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Diabetes'>Diabetes</h2><span id='topic+Diabetes'></span>

<h3>Description</h3>

<p>This diabetes data set has n = 352 samples and there are p = 6 predictors: lamotrigine (ltg), total serum cholesterol (tc), total cholesterol (tch), low- and high-density lipoprotein (ldl and hdl) and glucose (glu). The response variable is the measurement of the disease progression one year after baseline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Diabetes</code></pre>


<h3>Format</h3>

<p>A dataframe containing 352 records</p>


<h3>References</h3>

<p>B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. Least angle regression. Annals of statistics, 32(2):407–499, 2004.
</p>

<hr>
<h2 id='mcb'>Model Confidence Bound</h2><span id='topic+mcb'></span>

<h3>Description</h3>

<p>When choosing proper variable selection methods, it is important to consider the uncertainty of a certain method. The MCB for variable selection identifies two nested models (upper and lower confidence bound models) containing the true model at a given confidence level. A good variable selection method is the one of which the MCB under a certain confidence level has the shortest width. When visualizing the variability of model selection and comparing different model selection procedures, Model uncertainty curve is a good graphical tool. A good variable selection method is the one of whose MUC will tend to arch towards the upper left corner. This function aims to obtain the MCB and draw the MUC of certain single model selection method under a coverage rate equal or little higher than user-given confidential level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcb(x, y, B=200, lambda=NA, method='Lasso', level=0.95, seed=122)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcb_+3A_x">x</code></td>
<td>
<p>input matrix; each column is an observation vector of certain independent variable, and will be given a name automatically in the order of x1, x2, x3…</p>
</td></tr>
<tr><td><code id="mcb_+3A_y">y</code></td>
<td>
<p>y is a matrix of one column which presents the response vector
B	number of bootstrap replicates to perform, default value is 200.</p>
</td></tr>
<tr><td><code id="mcb_+3A_b">B</code></td>
<td>
<p>number of bootstrap replicates to perform; Default value is 200.</p>
</td></tr>
<tr><td><code id="mcb_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda value. It is the penalty tuning parameter for the variable selection method tested. The default value is the optimization outcome automatically computed in consideration of the specific case.</p>
</td></tr>
<tr><td><code id="mcb_+3A_method">method</code></td>
<td>
<p>Default value is ‘Lasso; user can choose from 'aLasso', 'Lasso', 'SCAD', 'MCP', 'stepwise', 'LAD', 'SQRT'</p>
</td></tr>
<tr><td><code id="mcb_+3A_level">level</code></td>
<td>
<p>a positive value between 0 and 1, like the concept of confidence level for point estimation; Default value is 0.95</p>
</td></tr>
<tr><td><code id="mcb_+3A_seed">seed</code></td>
<td>
<p>seed for bootstrap procedures; Default value is 122;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mcb method returns an object of class “mcb” The generic accessor functions mcb, mucplot and mcbframe extract various useful features of the value returned by mcb.
An object of class “mcb” is a list containing at least the following components:
</p>
<table role = "presentation">
<tr><td><code>mcb</code></td>
<td>
<p>a list containing the bootstrap coverage rate (which is the closest to the user-given confidence level) and the corresponding model confidence bound of the user-chosen variable selection method in the form of lower confidence bound and upper confidence bound.</p>
</td></tr>
<tr><td><code>mucplot</code></td>
<td>
<p>plot of the model uncertainty curve for this specific user-chosen variable selectionmethod.</p>
</td></tr>
<tr><td><code>mcbframe</code></td>
<td>
<p>a dataframe containing all the information about MCBs for the specific variable selectionmethod under all bootstrap coverage rates including width(w), lower confidence bound(lcb) and upper confidence bound(ucb) for each bootstrap coverage rate(bcr)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Li,Y., Luo,Y., Ferrari,D., Hu,X. and Qin,Y. (2019) Model Confidence Bounds for Variable Selection. Biometrics, 75:392-403.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Diabetes) # load data
x &lt;- Diabetes[,c('S1', 'S2', 'S3', 'S4', 'S5')]
y &lt;- Diabetes[,c('Y')]
x &lt;- data.matrix(x)
y &lt;- data.matrix(y)
result &lt;- mcb(x=x, y=y)
# plot of the model uncertainty curve
result$mucplot
# a list containing the bootstrap coverage rate and mcb
result$mcb
# a dataframe containing all the information about MCBs
result$mcbframe
</code></pre>

<hr>
<h2 id='mcb.compare'>Comparisons of Model Confidence Bounds for Different Variable selection Methods</h2><span id='topic+mcb.compare'></span>

<h3>Description</h3>

<p>This function is a supplement of the function mcb. It is used to compare different variable selection methods and would return all the MUCs on same canvas. A good variable selection method’s MUC will tend to arch towards the upper left corner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcb.compare(x, y, B=200, lambdas=NA, methods=NA, level=0.95, seed=122)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcb.compare_+3A_x">x</code></td>
<td>
<p>input matrix presenting independent variables as in mcb.</p>
</td></tr>
<tr><td><code id="mcb.compare_+3A_y">y</code></td>
<td>
<p>response vector as in mcb.</p>
</td></tr>
<tr><td><code id="mcb.compare_+3A_b">B</code></td>
<td>
<p>number of bootstrap replicates to perform; Default value is 200.</p>
</td></tr>
<tr><td><code id="mcb.compare_+3A_lambdas">lambdas</code></td>
<td>
<p>A vector of penalty tuning parameters for each variable selection method. The default values are the optimal choices for each selection method computed automatically.</p>
</td></tr>
<tr><td><code id="mcb.compare_+3A_methods">methods</code></td>
<td>
<p>a vector including all variable selection methods the user wants to test and compare. The default value is c ('aLasso', 'Lasso', 'SCAD', 'MCP', 'stepwise', 'LAD', 'SQRT')</p>
</td></tr>
<tr><td><code id="mcb.compare_+3A_level">level</code></td>
<td>
<p>user-defined confidence level as in mcb; Default value is 0.95.</p>
</td></tr>
<tr><td><code id="mcb.compare_+3A_seed">seed</code></td>
<td>
<p>Default value is 122.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mcb.compare method returns an object of class “mcb.compare”
An object of class &quot;mcb.compare &quot; is a list containing at least the following components:
</p>
<table role = "presentation">
<tr><td><code>mcb</code></td>
<td>
<p>a list containing the bootstrap coverage rate and the corresponding model confidence bound for all user-given variable selection methods.</p>
</td></tr>
<tr><td><code>mucplot</code></td>
<td>
<p>plot of the model uncertainty curves for all variable selection methods and could be used to choose the best method.</p>
</td></tr>
<tr><td><code>mcbframe</code></td>
<td>
<p>a list containing all the information about MCBs for all variable selection methods under all available bootstrap coverage rates.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Li,Y., Luo,Y., Ferrari,D., Hu,X. and Qin,Y. (2019) Model Confidence Bounds for Variable Selection. Biometrics, 75:392-403.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Diabetes) # load data
x &lt;- Diabetes[,c('S1', 'S2', 'S3', 'S4', 'S5')]
y &lt;- Diabetes[,c('Y')]
x &lt;- data.matrix(x)
y &lt;- data.matrix(y)
result &lt;- mcb.compare(x=x, y=y)
# plot of the model uncertainty curves for all variable selection methods
result$mucplot
# a list containing the bootstrap coverage rate and mcb which based on Lasso
result$mcb$Lasso
# a dataframe containing all the information about MCBs which based on Lasso
result$mcbframe$Lasso
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
