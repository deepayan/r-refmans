<!DOCTYPE html><html><head><title>Help for package RcppHMM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RcppHMM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Change Log'><p>Changes Made to Package RcppHMM</p></a></li>
<li><a href='#evaluation'>
<p>Observed sequence evaluation given a model</p></a></li>
<li><a href='#forwardBackward'>
<p>Forward-backward algortihm for hidden state decoding</p></a></li>
<li><a href='#generateObservations'>
<p>Generate observations given a model</p></a></li>
<li><a href='#initGHMM'>
<p>Random Initialization for a Hidden Markov Model with emissions modeled as continuous variables</p></a></li>
<li><a href='#initHMM'>
<p>Random Initialization for a Hidden Markov Model with emissions modeled as categorical variables</p></a></li>
<li><a href='#initPHMM'>
<p>Random Initialization for a Hidden Markov Model with emissions modeled as discrete variables</p></a></li>
<li><a href='#learnEM'>
<p>Expectation-Maximization algorithm to estimate the model parameters</p></a></li>
<li><a href='#loglikelihood'>
<p>Evaluation of multiple observed sequences given a model</p></a></li>
<li><a href='#RcppHMM-package'>
<p>Overview of Package RcppHMM</p></a></li>
<li><a href='#setNames'>
<p>Set the names of the model</p></a></li>
<li><a href='#setParameters'>
<p>Set the model parameters</p></a></li>
<li><a href='#verifyModel'>
<p>Model parameter verification</p></a></li>
<li><a href='#viterbi'>
<p>Viterbi algorithm for hidden state decoding</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Rcpp Hidden Markov Model</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-11-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Roberto A. Cardenas-Ovando, Julieta Noguez and Claudia Rangel-Escareno</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Roberto A. Cardenas-Ovando &lt;robalecarova@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Collection of functions to evaluate sequences, decode hidden states and estimate parameters from a single or multiple sequences of a discrete time Hidden Markov Model. The observed values can be modeled by a multinomial distribution for categorical/labeled emissions, a mixture of Gaussians for continuous data and also a mixture of Poissons for discrete values. It includes functions for random initialization, simulation, backward or forward sequence evaluation, Viterbi or forward-backward decoding and parameter estimation using an Expectation-Maximization approach.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.6)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-11-21 19:02:00 UTC; Dell</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-11-21 19:27:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='Change+20Log'>Changes Made to Package RcppHMM</h2><span id='topic+Changes'></span>

<h3>Description</h3>

<p>This page contains a listing of recent changes made to the package.
</p>


<h3>Details</h3>


<ol>
<li><p> More examples were added to some functions. (November 2017)
</p>
</li>
<li><p> Since there are different classes of HMMs and each of them with the same algorithms, a verification step was added to avoid memory leaks and variable compatibility. (May 2017)
</p>
</li>
<li><p> The class of HMM with observations being modelled by a Gaussian Mixture Model (GHMM) was updated to have also a multivariate version (see <code><a href="#topic+initGHMM">initGHMM</a></code>). (July 2017)
</p>
</li>
<li><p> The emission matrix of the GHMM model was divided into two parameters: Mu and Sigma. Mu is now a 2D matrix with number of rows equal to the dimensionality of the observation vector and the number of columns equal to the number of hidden states. Sigma is now a 3D matrix with number of rows and columns equal to the the dimensionality of the observation vector and the number of slices equal to the number of hidden states (see <code><a href="#topic+initGHMM">initGHMM</a></code>). (July 2017)
</p>
</li></ol>

<hr>
<h2 id='evaluation'>
Observed sequence evaluation given a model
</h2><span id='topic+evaluation'></span>

<h3>Description</h3>

<p>This function computes the log-likelihood of an observed sequence being generated by a hidden Markov model with fixed parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation(hmm , sequence , method = "f" )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="evaluation_+3A_sequence">sequence</code></td>
<td>
<p>sequence of observations to be evaluated. HMM and PHMM use a vector. GHMM uses a matrix.</p>
</td></tr>
<tr><td><code id="evaluation_+3A_method">method</code></td>
<td>
<p>method specified to perform the evaluation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods to be selected can be &quot;f&quot; for the forward algorithm or &quot;b&quot; for the backward algorithm. GHMM uses a matrix with the variables as rows and consecutive observations in the columns.
</p>


<h3>Value</h3>

<p>A value that represents the log-likelihood of the sequence given the hiddden Markov model.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateObservations">generateObservations</a></code> , <code><a href="#topic+verifyModel">verifyModel</a></code> , <code><a href="#topic+loglikelihood">loglikelihood</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations
# Set the model parameters
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.5, 0.5)

params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

HMM &lt;- verifyModel(params)

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM, length)

#Sequence evaluation

# It assumes that it will be evaluated using the forward algorithm
evaluation(HMM, observationSequence$Y)  

# The user sets the backward algorithm to evaluate the algorithm
evaluation(HMM, observationSequence$Y, "b") 

## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.discrete, length)

#Sequence evaluation

# It assumes that it will be evaluated using the forward algorithm
evaluation(HMM.discrete, observationSequence$Y)  

# The user sets the backward algorithm to evaluate the algorithm
evaluation(HMM.discrete, observationSequence$Y, "b") 

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

HMM.cont.univariate &lt;- verifyModel(list( "Model"="GHMM", 
                                         "StateNames" = N,
                                         "A" = A, 
                                         "Mu" = Mu, 
                                         "Sigma" = Sigma, 
                                         "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.univariate, length)

#Sequence evaluation

# It assumes that it will be evaluated using the forward algorithm
evaluation(HMM.cont.univariate, observationSequence$Y)  

# The user sets the backward algorithm to evaluate the algorithm
evaluation(HMM.cont.univariate, observationSequence$Y, "b") 

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6, 0.4,
              0.3, 0.7), 
            ncol = length(N),
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

HMM.cont.multi &lt;- verifyModel(list( "Model" = "GHMM",
                                    "StateNames" = N,
                                    "A" = A, 
                                    "Mu" = Mu, 
                                    "Sigma" = Sigma, 
                                    "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.multi, length)

#Sequence evaluation

# It assumes that it will be evaluated using the forward algorithm
evaluation(HMM.cont.multi, observationSequence$Y)  

# The user sets the backward algorithm to evaluate the algorithm
evaluation(HMM.cont.multi, observationSequence$Y, "b") 

</code></pre>

<hr>
<h2 id='forwardBackward'>
Forward-backward algortihm for hidden state decoding
</h2><span id='topic+forwardBackward'></span>

<h3>Description</h3>

<p>Function used to get the most likely hidden states at each observation in the provided sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forwardBackward(hmm, sequence)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forwardBackward_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="forwardBackward_+3A_sequence">sequence</code></td>
<td>
<p>sequence of observations to be decoded. HMM and PHMM use a vector. GHMM uses a matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GHMM uses a matrix with the variables as rows and consecutive observations in the columns. 
</p>


<h3>Value</h3>

<p>A vector of hidden states in the traveled path of observations.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateObservations">generateObservations</a></code> , <code><a href="#topic+verifyModel">verifyModel</a></code> , <code><a href="#topic+viterbi">viterbi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations
# Set the model parameters
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.5, 0.5)

params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

HMM &lt;- verifyModel(params)

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM, length)

#Sequence decoding
hiddenStates &lt;- forwardBackward(HMM, observationSequence$Y)
print(hiddenStates)

## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.discrete, length)

#Sequence decoding
hiddenStates &lt;- forwardBackward(HMM.discrete, observationSequence$Y)
print(hiddenStates)

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

HMM.cont.univariate &lt;- verifyModel(list( "Model"="GHMM", 
                                         "StateNames" = N,
                                         "A" = A, 
                                         "Mu" = Mu, 
                                         "Sigma" = Sigma, 
                                         "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.univariate, length)

#Sequence decoding
hiddenStates &lt;- forwardBackward(HMM.cont.univariate, observationSequence$Y)
print(hiddenStates)

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6, 0.4,
              0.3, 0.7), 
            ncol = length(N),
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

HMM.cont.multi &lt;- verifyModel(list( "Model" = "GHMM",
                                    "StateNames" = N,
                                    "A" = A, 
                                    "Mu" = Mu, 
                                    "Sigma" = Sigma, 
                                    "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.multi, length)

#Sequence decoding
hiddenStates &lt;- forwardBackward(HMM.cont.multi, observationSequence$Y)
print(hiddenStates)

</code></pre>

<hr>
<h2 id='generateObservations'>
Generate observations given a model
</h2><span id='topic+generateObservations'></span>

<h3>Description</h3>

<p>Function used to generate simulated observations given a hidden Markov model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateObservations(hmm, length)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateObservations_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="generateObservations_+3A_length">length</code></td>
<td>
<p>the number of observations will be generated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the generated observations and the hidden state that generated it.
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>a vector representing the path of hidden states.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>generated observations. HMM and PHMM return a vector. GHMM returns a matrix.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations
# Set the model parameters
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.5, 0.5)

params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

HMM &lt;- verifyModel(params)

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM, length)
# Observed data
head(observationSequence$Y)
# Hidden states path
head(observationSequence$X)


## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.discrete, length)
# Observed data
head(observationSequence$Y)
# Hidden states path
head(observationSequence$X)


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

HMM.cont.univariate &lt;- verifyModel(list( "Model"="GHMM", 
                                         "StateNames" = N,
                                         "A" = A, 
                                         "Mu" = Mu, 
                                         "Sigma" = Sigma, 
                                         "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.univariate, length)
# Observed data
observationSequence$Y[,1:6]
# Hidden states path
head(observationSequence$X)


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6, 0.4,
              0.3, 0.7), 
            ncol = length(N),
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

HMM.cont.multi &lt;- verifyModel(list( "Model" = "GHMM",
                                    "StateNames" = N,
                                    "A" = A, 
                                    "Mu" = Mu, 
                                    "Sigma" = Sigma, 
                                    "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.multi, length)
# Observed data
observationSequence$Y[,1:6]
# Hidden states path
head(observationSequence$X)

</code></pre>

<hr>
<h2 id='initGHMM'>
Random Initialization for a Hidden Markov Model with emissions modeled as continuous variables
</h2><span id='topic+initGHMM'></span>

<h3>Description</h3>

<p>Function used to generate a hidden Markov model with continuous variables and random parameters. This method allows using the univariate version of a Gaussian Mixture Model when setting m = 1. The code for the methods with categorical values or discrete data can be viewed in <code>"<a href="#topic+initHMM">initHMM</a>"</code> and <code>"<a href="#topic+initPHMM">initPHMM</a>"</code>, respectively.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initGHMM(n,m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initGHMM_+3A_n">n</code></td>
<td>
<p>the number of hidden states to use.</p>
</td></tr>
<tr><td><code id="initGHMM_+3A_m">m</code></td>
<td>
<p>the number of variables generated by the hidden states (Dimensionality of the bbserved vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the required values to specify the model.
</p>
<table>
<tr><td><code>Model</code></td>
<td>
<p>it specifies that the observed values are to be modeled as a Gaussian mixture model.</p>
</td></tr>
<tr><td><code>StateNames</code></td>
<td>
<p>the set of hidden state names.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>the transition probabilities matrix.</p>
</td></tr> 
<tr><td><code>Mu</code></td>
<td>
<p>a matrix of means of the observed variables (rows) in each states (columns).</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>a 3D matrix that has the covariance matrix of each state. The number of slices is equal to the maximum number of hidden states.</p>
</td></tr> 
<tr><td><code>Pi</code></td>
<td>
<p>the initial probability vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 3
m &lt;- 5
model &lt;- initGHMM(n, m)
print(model)
</code></pre>

<hr>
<h2 id='initHMM'>
Random Initialization for a Hidden Markov Model with emissions modeled as categorical variables
</h2><span id='topic+initHMM'></span>

<h3>Description</h3>

<p>Function used to generate a hidden Markov model with categorical variables and random parameters. The code for the methods with continuous values or discrete data can be viewed in <code>"<a href="#topic+initGHMM">initGHMM</a>"</code> and <code>"<a href="#topic+initPHMM">initPHMM</a>"</code>, respectively.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initHMM(n, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initHMM_+3A_n">n</code></td>
<td>
<p>the number of hidden states to use.</p>
</td></tr>
<tr><td><code id="initHMM_+3A_m">m</code></td>
<td>
<p>the number of possible categories (labels) generated by the hidden states.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the required values to specify the model.
</p>
<table>
<tr><td><code>Model</code></td>
<td>
<p>it specifies that the observed values are to be modeled as a multinomial distribution.</p>
</td></tr>
<tr><td><code>StateNames</code></td>
<td>
<p>the set of hidden state names.</p>
</td></tr>
<tr><td><code>ObservationNames</code></td>
<td>
<p>the set of possible observed values.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>the transition probabilities matrix.</p>
</td></tr> 
<tr><td><code>B</code></td>
<td>
<p>the emission probabilities matrix.</p>
</td></tr> 
<tr><td><code>Pi</code></td>
<td>
<p>the initial probability vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 2
m &lt;- 2
model &lt;- initHMM(n,m)
print(model)
</code></pre>

<hr>
<h2 id='initPHMM'>
Random Initialization for a Hidden Markov Model with emissions modeled as discrete variables
</h2><span id='topic+initPHMM'></span>

<h3>Description</h3>

<p>Function used to generate a hidden Markov model with discrete observations and random parameters. This model is used when the observed data are counts that can be modelled with a mixture of Poissons. The code for the methods with categorical values or continuous data can be viewed in <code>"<a href="#topic+initHMM">initHMM</a>"</code> and <code>"<a href="#topic+initGHMM">initGHMM</a>"</code>, respectively.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initPHMM(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initPHMM_+3A_n">n</code></td>
<td>
<p>the number of hidden states to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains all the required values to specify the model.
</p>
<table>
<tr><td><code>Model</code></td>
<td>
<p>it specifies that the observed values are to be modeled as a Poisson mixture model.</p>
</td></tr>
<tr><td><code>StateNames</code></td>
<td>
<p>the set of hidden state names.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>the transition probabilities matrix.</p>
</td></tr> 
<tr><td><code>B</code></td>
<td>
<p>a vector with the lambda parameter for each Poisson distribution.</p>
</td></tr> 
<tr><td><code>Pi</code></td>
<td>
<p>the initial probability vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 2
  model &lt;- initPHMM(n)
  print(model)
</code></pre>

<hr>
<h2 id='learnEM'>
Expectation-Maximization algorithm to estimate the model parameters
</h2><span id='topic+learnEM'></span>

<h3>Description</h3>

<p>Expectation-Maximization algorithm to estimate the model parameters based on a single or multiple observed sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnEM(hmm, sequences, iter = 100, delta = 1e-05, pseudo = 0, print = TRUE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnEM_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="learnEM_+3A_sequences">sequences</code></td>
<td>
<p>sequences of observations to be used as training set. HMM and PHMM use a matrix. GHMM uses a 3D array.</p>
</td></tr>
<tr><td><code id="learnEM_+3A_iter">iter</code></td>
<td>
<p>a value that sets the maximum number of iterations to run.</p>
</td></tr>
<tr><td><code id="learnEM_+3A_delta">delta</code></td>
<td>
<p>a value set to be the minimum error considered as a convergence criteria.</p>
</td></tr>
<tr><td><code id="learnEM_+3A_pseudo">pseudo</code></td>
<td>
<p>a value set to consider pseudo-counts.</p>
</td></tr>
<tr><td><code id="learnEM_+3A_print">print</code></td>
<td>
<p>a logical value to print the error at each iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used for univariate or multivariate distributions. HMM and PHMM use a matrix with different sequences as rows and consecutive observations in the columns. GHMM uses an array with the variables as rows, consecutive observations in the columns and different sequences as slices. 
</p>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the estimated hidden Markov model parameters.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateObservations">generateObservations</a></code> , <code><a href="#topic+verifyModel">verifyModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations
# Set the model parameters
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.5, 0.5)

params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

HMM &lt;- verifyModel(params)

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 10

# Multiple sequences to be used as training set
observationSequences&lt;- c()
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM , length)$Y
  observationSequences &lt;- rbind(observationSequences , Y)
}

# New model random initialization
# Model to be trained
set.seed(1000)
newModel &lt;- initHMM(2,4) 
n = c("X1","X2")
m = c("A","T","C","G")
newModel &lt;- setNames(newModel,
                     list( "StateNames" = n,
                           "ObservationNames" = m) )


  newModel &lt;- learnEM(newModel,
                      observationSequences,
                      iter= 50, 
                      delta = 1E-5,
                      pseudo = 3,
                      print = TRUE)


print(newModel)   

## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 50

# Multiple sequences to be evaluated
observationSequences&lt;- c()
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM.discrete , length)$Y
  observationSequences &lt;- rbind(observationSequences , Y)
}

dim(observationSequences)
# New model random initialization
# Model to be trained
set.seed(1000)
newModel &lt;- initPHMM(3) 

  newModel &lt;- learnEM(newModel,
                      observationSequences,
                      iter= 50, 
                      delta = 1E-5,
                      print = FALSE)


print(newModel)   


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

HMM.cont.univariate &lt;- verifyModel(list( "Model"="GHMM", 
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 50

# Multiple sequences to be evaluated
observationSequences&lt;- array(0, dim = c(1, length, seqs) )
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM.cont.univariate , length)$Y
  observationSequences[,,i] &lt;- Y
}

dim(observationSequences)

# New model random initialization
# Model to be trained
set.seed(1000)
newModel &lt;- initGHMM(3) 

  newModel &lt;- learnEM(newModel,
                      observationSequences,
                      iter= 50, 
                      delta = 1E-5,
                      print = FALSE)


print(newModel)   


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6,0.4,
              0.3, 0.7), 
            ncol = length(N),
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

HMM.cont.multi &lt;- verifyModel(list( "Model" = "GHMM",
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 50

# Multiple sequences to be evaluated
observationSequences&lt;- array(0, dim = c(M, length, seqs) )
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM.cont.multi , length)$Y
  observationSequences[,,i] &lt;- Y
}

dim(observationSequences)

# New model random initialization
# Model to be trained
set.seed(1000)
newModel &lt;- initGHMM(2, M) 

  newModel &lt;- learnEM(newModel,
                      observationSequences,
                      iter= 50, 
                      delta = 1E-5,
                      print = FALSE)


print(newModel)   
</code></pre>

<hr>
<h2 id='loglikelihood'>
Evaluation of multiple observed sequences given a model
</h2><span id='topic+loglikelihood'></span>

<h3>Description</h3>

<p>This function computes the log-likelihood of multiple observed sequences generated by a hidden Markov model with fixed parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglikelihood(hmm, sequences)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglikelihood_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="loglikelihood_+3A_sequences">sequences</code></td>
<td>
<p>sequences of observations to be evaluated. HMM and PHMM use a matrix. GHMM uses a 3D array.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value that represents the log-likelihood of the multiple observed sequences given the hiddden Markov model. HMM and PHMM use a matrix with different sequences as rows and consecutive observations in the columns. GHMM uses an array with the variables as rows, consecutive observations in the columns and different sequences as slices. 
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateObservations">generateObservations</a></code> , <code><a href="#topic+verifyModel">verifyModel</a></code> , <code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations
# Set the model parameters
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.5, 0.5)

params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

HMM &lt;- verifyModel(params)

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 10

# Multiple sequences to be evaluated
observationSequences&lt;- c()
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM , length)$Y
  observationSequences &lt;- rbind(observationSequences , Y)
}

dim(observationSequences)

#Sequences evaluation
loglikelihood(HMM, observationSequences)


## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 10

# Multiple sequences to be evaluated
observationSequences&lt;- c()
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM.discrete , length)$Y
  observationSequences &lt;- rbind(observationSequences , Y)
}

dim(observationSequences)

#Sequences evaluation
loglikelihood(HMM.discrete, observationSequences)

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

HMM.cont.univariate &lt;- verifyModel(list( "Model"="GHMM", 
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 10

# Multiple sequences to be evaluated
observationSequences&lt;- array(0, dim = c(1, length, seqs) )
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM.cont.univariate , length)$Y
  observationSequences[,,i] &lt;- Y
}

dim(observationSequences)

#Sequences evaluation
loglikelihood(HMM.cont.univariate, observationSequences)


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6,0.4,
              0.3, 0.7), 
            ncol = length(N),
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

HMM.cont.multi &lt;- verifyModel(list( "Model" = "GHMM",
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
seqs &lt;- 10

# Multiple sequences to be evaluated
observationSequences&lt;- array(0, dim = c(M, length, seqs) )
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM.cont.multi , length)$Y
  observationSequences[,,i] &lt;- Y
}

dim(observationSequences)

#Sequences evaluation
loglikelihood(HMM.cont.multi, observationSequences)

</code></pre>

<hr>
<h2 id='RcppHMM-package'>
Overview of Package RcppHMM
</h2><span id='topic+RcppHMM-package'></span><span id='topic+RcppHMM'></span>

<h3>Description</h3>

<p>This package can model observations based on hidden Markov models. The observations can be considered to be emitted by a multinomial distribution, A mixture of Gaussians or a mixture of Poissons. It can be used for inference, parameter estimation and simulation.  
</p>


<h3>Details</h3>

<p>The package can be used to represent a discrete-time hidden Markov model. The states can generate categorical (labeled), continuous or discrete observations. The hidden state transition and observations can be randomly generated based on fixed parameters. Also, the inference methods can be used to evaluate sequences or decode the hidden states that generated the observations. Finally, the model parameters can be estimated by a single or multiple observed sequences.  
</p>


<h3>Author(s)</h3>

<p>Roberto A. Cardenas-Ovando, Julieta Noguez and Claudia Rangel-Escareno
</p>
<p>Maintainer: Roberto A. Cardenas-Ovando &lt;robalecarova@gmail.com&gt;
</p>


<h3>References</h3>

<p>Bilmes, J.E. (1998). A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models. <em>International Computer Science Institute</em>.
</p>
<p>Ibe, O. (2009). Markov processes for stochastic modeling. <em>Oxford</em>.
</p>
<p>Rabiner, L.R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. <em>Proceedings of the IEEE</em>.
</p>
<p>Rabiner L.; Juang, B.H. (1993) Fundamentals of Speech Recognition. <em>Prentice Hall Signal Processing Series</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multinomial case
# Set the model parameters to be estimated
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)
            
Pi &lt;- c(0.5, 0.5)


params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

# Model parameters validation

HMM &lt;- verifyModel(params)

# Data simulation
# Multiple sequences

set.seed(100)
length &lt;- 100
seqs &lt;- 100
observationSequences&lt;- c()
for(i in 1:seqs){
  Y &lt;- generateObservations(HMM , length)$Y
  observationSequences &lt;- rbind(observationSequences , Y)
}

# New model random initialization

set.seed(1000)
newModel &lt;- initHMM(2,4) 
n = c("X1","X2")
m = c("A","T","C","G")

# Change model names

newModel &lt;- setNames(newModel,
                        list( "StateNames" = n,
                              "ObservationNames" = m) )

# Model parameters estimation

newModel &lt;- learnEM(newModel,
        observationSequences,
        iter=300, 
        delta = 1E-8,
        pseudo = 0,
        print = TRUE)

# New sequence simulation to compare the new model
# Data simulation

# Single sequence
Y &lt;- generateObservations(HMM , length)$Y

# Evaluation

evaluation(newModel, Y, "f")
evaluation(newModel, Y, "b")

# Hidden state decoding

hiddenStatesViterbi &lt;- viterbi(newModel, Y)
hiddenStatesFB &lt;- forwardBackward( newModel, Y)
</code></pre>

<hr>
<h2 id='setNames'>
Set the names of the model
</h2><span id='topic+setNames'></span>

<h3>Description</h3>

<p>Function used to set new hidden state names to the model. If it is a categorical model, it also sets the labels for the observations. This function verifies that all the parameters and new names agree in size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  setNames(hmm , names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setNames_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="setNames_+3A_names">names</code></td>
<td>
<p>a list with the new names to be set in the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the verified hidden Markov model parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations

set.seed(1000)
newModel &lt;- initHMM(2,4)
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
newModel &lt;- setNames(newModel,
                    list( "StateNames" = n,
                          "ObservationNames" = m) )

## Values for a hidden Markov model with continuous observations

set.seed(1000)
newModel &lt;- initGHMM(3) 
n &lt;- c("Low",  "Normal", "High" )
newModel &lt;- setNames(newModel,
                     list( "StateNames" = n))

## Values for a hidden Markov model with discrete observations

set.seed(1000)
newModel &lt;- initPHMM(3) 
n &lt;- c("Low",  "Normal", "High" )
newModel &lt;- setNames(newModel,
                     list( "StateNames" = n))

</code></pre>

<hr>
<h2 id='setParameters'>
Set the model parameters
</h2><span id='topic+setParameters'></span>

<h3>Description</h3>

<p>Function used to set the model parameters. This function verifies that parameters and names correspond.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setParameters(hmm , params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setParameters_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="setParameters_+3A_params">params</code></td>
<td>
<p>a list with the new parameters to be set in the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the verified hidden Markov model parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations

set.seed(1000)
newModel &lt;- initHMM(2,4)

A &lt;- matrix(c(0.378286,0.621714,
              0.830970,0.169030),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.1930795, 0.2753869, 0.3463100, 0.1852237,
              0.2871577, 0.1848870, 0.1614925, 0.3664628),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.4757797, 0.5242203)

newModel &lt;- setParameters(newModel,
                          list( "A" = A,
                                "B" = B,
                                "Pi" = Pi) )

## Values for a hidden Markov model with discrete observations

set.seed(1000)
n &lt;- 3
newModel &lt;- initPHMM(n) 

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=n, byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/n , n)


newModel &lt;- setParameters(newModel,
                          list( "A" = A,
                                "B" = B,
                                "Pi" = Pi) )

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model
N &lt;- 3
newModel &lt;- initGHMM(N)

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= N, byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = N)
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,N))
Pi &lt;- rep(1/N, N)

newModel &lt;- setParameters(newModel,
                          list( "A" = A, 
                                "Mu" = Mu, 
                                "Sigma" = Sigma, 
                                "Pi" = Pi))


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N &lt;- 2
M &lt;- 3
set.seed(100)
newModel &lt;- initGHMM(N,M)

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,N))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6,0.4,
              0.3, 0.7), 
            ncol = N,
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

newModel &lt;- setParameters(newModel, 
                          list( "A" = A, 
                                "Mu" = Mu, 
                                "Sigma" = Sigma, 
                                "Pi" = Pi))


                                
</code></pre>

<hr>
<h2 id='verifyModel'>
Model parameter verification
</h2><span id='topic+verifyModel'></span>

<h3>Description</h3>

<p>Function used to verify that all the parameters satisfy the model constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verifyModel(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="verifyModel_+3A_model">model</code></td>
<td>
<p> a list with the necessary parameters to set a hidden Markov model with fixed values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model must have a stochastic transition matrix and a stochastic initial probability vector, also the row and column sizes must coincide with the number of provided state names. If the model uses categorical values, the emission matrix also must be stochastic and must have a column for each observation label and a row for each state name. And if the model uses discrete data, all the values must be positive assuming that they are counts.  
</p>


<h3>Value</h3>

<p>A <code>"<a href="base.html#topic+list">list</a>"</code> that contains the verified hidden Markov model parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations

n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.378286,0.621714,
              0.830970,0.169030),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.1930795, 0.2753869, 0.3463100, 0.1852237,
              0.2871577, 0.1848870, 0.1614925, 0.3664628),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.4757797, 0.5242203)


params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

verifiedModel &lt;- verifyModel(params)
print(verifiedModel)

## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))
print(HMM.discrete)

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

newModel &lt;- verifyModel(list( "Model"="GHMM", 
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))


## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), nrow = M)

A &lt;- matrix(c(0.6,0.3,
              0.4, 0.7), ncol = length(N))
Pi &lt;- c(0.5, 0.5)

newModel &lt;- verifyModel(list( "Model" = "GHMM",
                                "StateNames" = N,
                                "A" = A, 
                                "Mu" = Mu, 
                                "Sigma" = Sigma, 
                                "Pi" = Pi))


</code></pre>

<hr>
<h2 id='viterbi'>
Viterbi algorithm for hidden state decoding
</h2><span id='topic+viterbi'></span>

<h3>Description</h3>

<p>Function used to get the most likely path of hidden states generated by the observed sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>viterbi(hmm, sequence)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="viterbi_+3A_hmm">hmm</code></td>
<td>
<p>a list with the necessary variables to define a hidden Markov model.</p>
</td></tr>
<tr><td><code id="viterbi_+3A_sequence">sequence</code></td>
<td>
<p>sequence of observations to be decoded. HMM and PHMM use a vector. GHMM uses a matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Viterbi algorithm is based in a greedy approach, therefore it would only the give the most probable path. GHMM uses a matrix with the variables as rows and consecutive observations in the columns. 
</p>


<h3>Value</h3>

<p>A vector with the path of hidden states that generated the observed sequence.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+RcppHMM">RcppHMM</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateObservations">generateObservations</a></code> , <code><a href="#topic+verifyModel">verifyModel</a></code> , <code><a href="#topic+forwardBackward">forwardBackward</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Values for a hidden Markov model with categorical observations
# Set the model parameters
n &lt;- c("First","Second")
m &lt;- c("A","T","C","G")
A &lt;- matrix(c(0.8,0.2,
              0.1,0.9),
            nrow = 2,
            byrow = TRUE)

B &lt;- matrix(c(0.2, 0.2, 0.3, 0.3,
              0.4, 0.4, 0.1, 0.1),
            nrow = 2,
            byrow = TRUE)

Pi &lt;- c(0.5, 0.5)

params &lt;- list( "Model" = "HMM",
                "StateNames" = n,
                "ObservationNames" = m,
                "A" = A,
                "B" = B,
                "Pi" = Pi)

HMM &lt;- verifyModel(params)

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM, length)

#Sequence decoding
hiddenStates &lt;- viterbi(HMM, observationSequence$Y)
print(hiddenStates)

## Values for a hidden Markov model with discrete observations

n &lt;- c("Low","Normal","High")

A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol=length(n), byrow=TRUE)

B &lt;- c(2600,  # First distribution with mean 2600
       2700,  # Second distribution with mean 2700
       2800)  # Third distribution with mean 2800

Pi &lt;- rep(1/length(n), length(n))

HMM.discrete &lt;- verifyModel(list("Model"="PHMM", "StateNames" = n, "A" = A, "B" = B, "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.discrete, length)

#Sequence decoding
hiddenStates &lt;- viterbi(HMM.discrete, observationSequence$Y)
print(hiddenStates)

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 3
# Univariate gaussian mixture model

N = c("Low","Normal", "High")
A &lt;- matrix(c(0.5, 0.3,0.2,
              0.2, 0.6, 0.2,
              0.1, 0.3, 0.6),
            ncol= length(N), byrow = TRUE)

Mu &lt;- matrix(c(0, 50, 100), ncol = length(N))
Sigma &lt;- array(c(144, 400, 100), dim = c(1,1,length(N)))
Pi &lt;- rep(1/length(N), length(N))

HMM.cont.univariate &lt;- verifyModel(list( "Model"="GHMM", 
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.univariate, length)

#Sequence decoding
hiddenStates &lt;- viterbi(HMM.cont.univariate, observationSequence$Y)
print(hiddenStates)

## Values for a hidden Markov model with continuous observations                          
# Number of hidden states = 2
# Multivariate gaussian mixture model
# Observed vector with dimensionality of 3
N = c("X1","X2")
M &lt;- 3

# Same number of dimensions
Sigma &lt;- array(0, dim =c(M,M,length(N)))
Sigma[,,1] &lt;- matrix(c(1.0,0.8,0.8,
                       0.8,1.0,0.8,
                       0.8,0.8,1.0), ncol = M,  
                     byrow = TRUE)
Sigma[,,2] &lt;- matrix(c(1.0,0.4,0.6,
                       0.4,1.0,0.8,
                       0.6,0.8,1.0), ncol = M,
                     byrow = TRUE)
Mu &lt;- matrix(c(0, 5, 
               10, 0, 
               5, 10), 
             nrow = M, 
             byrow = TRUE)

A &lt;- matrix(c(0.6, 0.4,
              0.3, 0.7), 
            ncol = length(N),
            byrow = TRUE)
Pi &lt;- c(0.5, 0.5)

HMM.cont.multi &lt;- verifyModel(list( "Model" = "GHMM",
                              "StateNames" = N,
                              "A" = A, 
                              "Mu" = Mu, 
                              "Sigma" = Sigma, 
                              "Pi" = Pi))

# Data simulation
set.seed(100)
length &lt;- 100
observationSequence &lt;- generateObservations(HMM.cont.multi, length)

#Sequence decoding
hiddenStates &lt;- viterbi(HMM.cont.multi, observationSequence$Y)
print(hiddenStates)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
