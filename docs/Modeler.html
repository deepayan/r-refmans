<!DOCTYPE html><html><head><title>Help for package Modeler</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Modeler}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#feature.filters'><p>Feature Filtering</p></a></li>
<li><a href='#feature.selection'><p>Feature Selection</p></a></li>
<li><a href='#FittedModel'>
<p>Creating FittedModel objects</p></a></li>
<li><a href='#FittedModel-class'><p>Class &quot;FittedModel&quot;</p></a></li>
<li><a href='#learn'>
<p>Learning models from data</p></a></li>
<li><a href='#learnCCP'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnKNN'>
<p>Fit models and make predictions with a KNN classifier</p></a></li>
<li><a href='#learnLR'>
<p>Fit models and make predictions with a logistic regression classifier</p></a></li>
<li><a href='#learnNNET'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnNNET2'>
<p>Fit models and make predictions with a multi-level neural network classifier</p></a></li>
<li><a href='#learnPCALR'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnRF'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnRPART'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnSelectedLR'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnSVM'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#learnTailRank'>
<p>Fit models and make predictions with a PCA-LR classifier</p></a></li>
<li><a href='#Modeler'>
<p>Constructor for &quot;Modeler&quot; objects</p></a></li>
<li><a href='#Modeler-class'><p>Class &quot;Modeler&quot;</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>3.4.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-05-06</td>
</tr>
<tr>
<td>Title:</td>
<td>Classes and Methods for Training and Using Binary Prediction
Models</td>
</tr>
<tr>
<td>Author:</td>
<td>Kevin R. Coombes</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kevin R. Coombes &lt;krc@silicovore.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), ClassDiscovery, ClassComparison, oompaBase</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, class, rpart, TailRank, e1071, randomForest,
nnet, neuralnet</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Biobase</td>
</tr>
<tr>
<td>Description:</td>
<td>Defines classes and methods to learn models and use them
  to predict binary outcomes.  These are generic tools, but we also
  include specific examples for many common classifiers.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License (== 2.0)</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>biocViews:</td>
<td>Microarray, Clustering</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://oompa.r-forge.r-project.org/">http://oompa.r-forge.r-project.org/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-05-06 16:54:44 UTC; Kevin Coombes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-05-06 17:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='feature.filters'>Feature Filtering</h2><span id='topic+filterMean'></span><span id='topic+filterSD'></span><span id='topic+filterRange'></span><span id='topic+filterIQR'></span><span id='topic+filterMin'></span><span id='topic+filterMax'></span><span id='topic+filterMedian'></span>

<h3>Description</h3>

<p>Functions to create functions that filter potential predictive
features using statistics that do not access class labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterMean(cutoff)
filterMedian(cutoff)
filterSD(cutoff)
filterMin(cutoff)
filterMax(cutoff)
filterRange(cutoff)
filterIQR(cutoff)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="feature.filters_+3A_cutoff">cutoff</code></td>
<td>

<p>A real number, the level above which features with this statistic
should be retained and below which should be discarded.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following the usual conventions introduced from the world of
gene expression microarrays, a typical data matrix is constructed from
columns representing samples on which we want to make predictions
amd rows representing the features used to construct the predictive
model. In this context, we define a <em>filter</em> to be a function
that accepts a data matrix as its only argument and returns a logical
vector, whose length equals the number of rows in the matrix, where
'TRUE' indicates features that should be retrained. Most filtering
functions belong to parametrized families, with one of the most common
examples being
&quot;retain all features whose mean is above some pre-specified cutoff&quot;.
We implement this idea using a set of function-generating functions,
whose arguments are the parameters that pick out the desired member
of the family.  The return value is an instantiation of a particular
filtering function.  The decison to define things this way is to be
able to apply the methods in cross-validation (or other) loops where
we want to ensure that we use the same filtering rule each time.
</p>


<h3>Value</h3>

<p>Each of the seven functions described here return a filter function,
<code>f</code>, that can be used by code that basically looks like
<code>logicalVector &lt;- filter(data)</code>.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(246391)
data &lt;- matrix(rnorm(1000*30), nrow=1000, ncol=30)
fm &lt;- filterMean(1)
summary(fm(data))

summary(filterMedian(1)(data))
summary(filterSD(1)(data))
</code></pre>

<hr>
<h2 id='feature.selection'>Feature Selection</h2><span id='topic+keepAll'></span><span id='topic+fsTtest'></span><span id='topic+fsModifiedFisher'></span><span id='topic+fsPearson'></span><span id='topic+fsSpearman'></span><span id='topic+fsMedSplitOddsRatio'></span><span id='topic+fsChisquared'></span><span id='topic+fsEntropy'></span><span id='topic+fsFisherRandomForest'></span><span id='topic+fsTailRank'></span>

<h3>Description</h3>

<p>Functions to create functions that perform feature selection (or at
least feature reduction)  using statistics that access class labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keepAll(data, group)
fsTtest(fdr, ming=500)
fsModifiedFisher(q)
fsPearson(q = NULL, rho)
fsSpearman(q = NULL, rho)
fsMedSplitOddsRatio(q = NULL, OR)
fsChisquared(q = NULL, cutoff)
fsEntropy(q = 0.9, kind=c("information.gain", "gain.ratio", "symmetric.uncertainty"))
fsFisherRandomForest(q)
fsTailRank(specificity=0.9, tolerance=0.5, confidence=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="feature.selection_+3A_data">data</code></td>
<td>

<p>A matrix containng the data; columns are samples and rows are features.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_group">group</code></td>
<td>

<p>A factor with two levels defining the sample classes.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_fdr">fdr</code></td>
<td>

<p>A real number between 0 and 1 specifying the target false discovery rate (FDR).
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_ming">ming</code></td>
<td>

<p>An integer specifing the minimum number of features to return;
overrides the FDR.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_q">q</code></td>
<td>

<p>A real number between 0.5 and 1 specifiying the fraction of features to discard.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_rho">rho</code></td>
<td>

<p>A real number between 0 and 1 specifying the absolute value of the
correlation coefficient used to filter features.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_or">OR</code></td>
<td>

<p>A real number specifying the desired odds ratio for filtering features.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_cutoff">cutoff</code></td>
<td>

<p>A real number specifiyng the targeted cutoff rate when using the
statistic to filter features.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_kind">kind</code></td>
<td>

<p>The kind of information metric to use for filtering features.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_specificity">specificity</code></td>
<td>

<p>See <code><a href="TailRank.html#topic+TailRankTest">TailRankTest</a></code>.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_tolerance">tolerance</code></td>
<td>

<p>See <code><a href="TailRank.html#topic+TailRankTest">TailRankTest</a></code>.
</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_confidence">confidence</code></td>
<td>

<p>See <code><a href="TailRank.html#topic+TailRankTest">TailRankTest</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following the usual conventions introduced from the world of
gene expression microarrays, a typical data matrix is constructed from
columns representing samples on which we want to make predictions
amd rows representing the features used to construct the predictive
model. In this context, we define a <em>feature selector</em> or
<em>pruner</em> to be a function that accepts a data matrix and a
two-level factor as its only arguments and returns a logical 
vector, whose length equals the number of rows in the matrix, where
'TRUE' indicates features that should be retrained. Most pruning
functions belong to parametrized families.  We implement this idea
using a set of function-generating functions, whose arguments are the
parameters that pick out the desired member of the family.  The return
value is an instantiation of a particular filtering function.  The
decison to define things this way is to be able to apply the methods
in cross-validaiton (or other) loops where we want to ensure that we
use the same feature selection rule each time.
</p>
<p>We have implemented the following algorithms:
</p>

<ul>
<li> <p><code>keepAll</code>: retain all features; do nothing.
</p>
</li>
<li> <p><code>fsTtest</code>: Keep features based on the false discovery rate
from a two-goup t-test, but always retain a specified minimum number
of genes.
</p>
</li>
<li> <p><code>fsModifiedFisher</code> Retain the top quantile of features
for the statistic </p>
<p style="text-align: center;"><code class="reqn">\frac{(m_A - m)^2 + (m_B - m)^2}{v_A + v_B}</code>
</p>

<p>where m is the mean and v is the variance.
</p>
</li>
<li> <p><code>fsPearson</code>: Retain the top quantile of features based on
the absolute value of the Pearson correlation with the binary outcome.
</p>
</li>
<li> <p><code>fsSpearman</code>: Retain the top quantile of features based on
the absolute value of the Spearman correlation with the binary outcome.
</p>
</li>
<li> <p><code>fsMedSplitOddsRatio</code>: Retain the top quantile of
features based on the odds ratio to predict the binary outcome,
after first dichotomizing the continuous predictor using a split at
the median value. 
</p>
</li>
<li> <p><code>fsChisquared</code>: retain the top quantile of features based
on a chi-squared test comparing the binary outcome to continous
predictors discretized into ten bins.
</p>
</li>
<li> <p><code>fsEntropy</code>: retain the top quantile of features based on
one of three information-theoretic measures of entropy. 
</p>
</li>
<li> <p><code>fsFisherRandomForest</code>: retain the top features based on
their importance in a random forest analysis, after first filtering
using the modified Fisher statistic. 
</p>
</li>
<li> <p><code>fsTailRank</code>: Retain features that are significant based
on the TailRank test, which is a measure of whether the tails of the
distributions are different.
</p>
</li></ul>



<h3>Value</h3>

<p>The <code>keepAll</code> function is a &quot;pruner&quot;; it takes the data matrix and
grouping factor as arguments, and returns a logical vector indicating
which features to retain.
</p>
<p>Each of the other nine functions described here return uses its
arguments to contruct and return a pruning function,
<code>f</code>, that has the same interface as <code>keepAll</code>.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(246391)
data &lt;- matrix(rnorm(1000*36), nrow=1000, ncol=36)
data[1:50, 1:18] &lt;- data[1:50, 1:18] + 1
status &lt;- factor(rep(c("A", "B"), each=18))

fsel &lt;- fsPearson(q = 0.9)
summary(fsel(data, status))
fsel &lt;- fsPearson(rho=0.3)
summary(fsel(data, status))

fsel &lt;- fsEntropy(kind="gain.ratio")
summary(fsel(data, status))

</code></pre>

<hr>
<h2 id='FittedModel'>
Creating FittedModel objects
</h2><span id='topic+FittedModel'></span>

<h3>Description</h3>

<p>Construct an object of the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FittedModel(predict, data, status, details, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FittedModel_+3A_predict">predict</code></td>
<td>

<p>A function that applies the model to predict outcomes on new test data.
</p>
</td></tr>
<tr><td><code id="FittedModel_+3A_data">data</code></td>
<td>

<p>A matrix containing the training data.
</p>
</td></tr>
<tr><td><code id="FittedModel_+3A_status">status</code></td>
<td>

<p>A vector containing the training outcomes, which should either be a
binary-valued factor or a numeric vector of contiuous outcomes.
</p>
</td></tr>
<tr><td><code id="FittedModel_+3A_details">details</code></td>
<td>

<p>A list of the fitted parameters for the specified model.
</p>
</td></tr>
<tr><td><code id="FittedModel_+3A_...">...</code></td>
<td>

<p>Any extra information that is produced while learning the model; these
wil be saved in the <code>extras</code> slot of the <code>FittedModel</code> object.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most users will never need to use this function; instead, they will
first use an existing object of the <code><a href="#topic+Modeler-class">Modeler-class</a></code>, 
call the <code><a href="#topic+learn">learn</a></code> method of that object with the training data
to obtain a <code>FittedModel</code> object, and then apply its
<code><a href="stats.html#topic+predict">predict</a></code> method to test data.  Only people who want to
implement the learn-predict interface for a new classification algorithm
are likely to need to call this function directly.
</p>


<h3>Value</h3>

<p>Returns an object of the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com.
</p>


<h3>See Also</h3>

<p>See the descriptions of the <code><a href="#topic+learn">learn</a></code> function and
the <code><a href="stats.html#topic+predict">predict</a></code> method for details on how to fit models on
training data and make predictions on new test data. 
</p>
<p>See the description of the <code><a href="#topic+Modeler-class">Modeler-class</a></code> for details
about the kinds of objects produced by <code><a href="#topic+learn">learn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see the examples for learn and predict and for specific
# implementations of classifiers.
</code></pre>

<hr>
<h2 id='FittedModel-class'>Class &quot;FittedModel&quot; </h2><span id='topic+FittedModel-class'></span><span id='topic+predict+2CFittedModel-method'></span>

<h3>Description</h3>

<p>	Objects of this class represent parametrized statistical
models (of the <code><a href="#topic+Modeler-class">Modeler-class</a></code>) after they have been fit
to a training data set.  These objects can be used to
<code><a href="stats.html#topic+predict">predict</a></code> binary outcomes on new test data sets.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls to the constructor function,
<code><a href="#topic+FittedModel">FittedModel</a></code>.  In practice, however, most
<code>FittedModel</code> objects are created as the result of applying the
<code><a href="#topic+learn">learn</a></code> function to an object of the
<code><a href="#topic+Modeler-class">Modeler-class</a></code>. 
</p>


<h3>Slots</h3>


<dl>
<dt><code>predictFunction</code>:</dt><dd><p>Object of class <code>"function"</code> that
implemnts the ability to make predictions using the fitted model. </p>
</dd>
<dt><code>trainData</code>:</dt><dd><p>Object of class <code>"matrix"</code> containing
the trainng data set.  Rowes are features and columns are samples. </p>
</dd>
<dt><code>trainStatus</code>:</dt><dd><p>Object of class <code>"vector"</code>. Should
either be a numeric vector representing outcome or a factor with two
levels, containing the classes of the training data set.</p>
</dd>
<dt><code>details</code>:</dt><dd><p>Object of class <code>"list"</code> containing the
fitted parameters for the specific model. </p>
</dd>
<dt><code>extras</code>:</dt><dd><p>Object of class <code>"list"</code> containing any
extra information (such as diagnostics) produced a a result of
learning the model from the training data set.</p>
</dd>
<dt><code>fsVector</code>:</dt><dd><p>Logical vector indicating which features
should be retained (TRUE) of discared (FALSE) after performing
featgure selection on the training data.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>predict</dt><dd><p><code>signature(object = "FittedModel")</code>: Predict the
binary outcome on a new data set.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krcoombes@mdanderson.org&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+learn">learn</a></code> for details on
how to fit a model to data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("FittedModel")
</code></pre>

<hr>
<h2 id='learn'>
Learning models from data
</h2><span id='topic+learn'></span>

<h3>Description</h3>

<p>The <code>learn</code> function provides an abstraction that can be used to
fit a binary classification model to a training data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learn(model, data, status, prune=keepAll)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learn_+3A_model">model</code></td>
<td>

<p>An object of the <code><a href="#topic+Modeler-class">Modeler-class</a></code>
</p>
</td></tr>
<tr><td><code id="learn_+3A_data">data</code></td>
<td>

<p>A matrix containing the training data, with rows as features and
columns as samples to be classified.
</p>
</td></tr>
<tr><td><code id="learn_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, containing the known classification of
the training data.
</p>
</td></tr>
<tr><td><code id="learn_+3A_prune">prune</code></td>
<td>
<p>A &quot;pruning&quot; funciton; that is, a funciton that takes two
arguments (a data matrix and a class factor) and returns a logical
vector indicating which features to retain.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects of the <code><a href="#topic+Modeler-class">Modeler-class</a></code> contain functions to learn
models from training data to make predictions on new test data.  These
functions have to be prepared as pairs, since they have a shared
opinion about how to record and use specific details about the
parameters of the model.  As a result, the learn function is
implemented by:
</p>
<pre>
  learn &lt;- function(model, data, status) {
    model@learn(data, status, model@params, model@predict)
  }
</pre>


<h3>Value</h3>

<p>An object of the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="stats.html#topic+predict">predict</a></code> for how to make predictions on new test data
from an object of the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set up a generic RPART model
rpart.mod &lt;- Modeler(learnRPART, predictRPART, minsplit=2, minbucket=1)

# simulate fake data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# learn the specific RPART model
fm &lt;- learn(rpart.mod, data, status)

# show the predicted results from the model on the trianing data
predict(fm)

# set up a nearest neighbor model
knn.mod &lt;- Modeler(learnKNN, predictKNN, k=3)

# fit the 3NN model on the same data
fm3 &lt;- learn(knn.mod, data, status)
# show its performance
predict(fm3)
</code></pre>

<hr>
<h2 id='learnCCP'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnCCP'></span><span id='topic+predictCCP'></span><span id='topic+modelerCCP'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic modeling
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnCCP(data, status, params, pfun)
predictCCP(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnCCP_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnCCP_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnCCP_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnCCP_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictCCP</code>.
</p>
</td></tr>
<tr><td><code id="learnCCP_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnCCP_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnCCP_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnCCP</code> and <code>predictCCP</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The CCP classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnCCP</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnCCP</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictCCP</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnCCP</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a CCP classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictCCP</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnCCP</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
ccp.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model
fm &lt;- learnCCP(data, status, ccp.params, predictCCP)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictCCP(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnKNN'>
Fit models and make predictions with a KNN classifier
</h2><span id='topic+learnKNN'></span><span id='topic+predictKNN'></span><span id='topic+modeler3NN'></span><span id='topic+modeler5NN'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a K-nearest neighbors (KNN) classifier. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnKNN(data, status, params, pfun)
predictKNN(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnKNN_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features and columns as the samples to
be classified.
</p>
</td></tr>
<tr><td><code id="learnKNN_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnKNN_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnKNN_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.
</p>
</td></tr>
<tr><td><code id="learnKNN_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnKNN_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnKNN_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnKNN</code> and <code>predictKNN</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The implementation uses the <code><a href="class.html#topic+knn">knn</a></code> method from the
<code><a href="base.html#topic+class">class</a></code> package.  The <code>params</code> argument to
<code>learnKNN</code> must be alist that at least includes the component
<code>k</code> that specifies the number of neighbors used.
</p>


<h3>Value</h3>

<p>The <code>learnKNN</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, logically representing a KNN
classifier that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictKNN</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>References</h3>

<p>Ripley, B. D. (1996) <em>Pattern Recognition and Neural Networks</em>.
Cambridge.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied
Statistics with S</em>. Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnPCALR</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
knn.params &lt;- list(k=5)

# learn the model
fm &lt;- learnKNN(data, status, knn.params, predictKNN)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictKNN(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnLR'>
Fit models and make predictions with a logistic regression classifier
</h2><span id='topic+learnLR'></span><span id='topic+predictLR'></span><span id='topic+modelerLR'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a logistic regression (LR) classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnLR(data, status, params, pfun)
predictLR(newdata, details, status, type ="response", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnLR_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictLR</code>.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_type">type</code></td>
<td>

<p>A character string indicating the type of prediciton to make.
</p>
</td></tr>
<tr><td><code id="learnLR_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnLR</code> and <code>predictLR</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The LR classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnLR</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnLR</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictLR</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnLR</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a LR classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictLR</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnLR</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
lr.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model -- this is slow
fm &lt;- learnLR(data, status, lr.params, predictLR)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictLR(newdata, fm@details, status)

## End(Not run)
</code></pre>

<hr>
<h2 id='learnNNET'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnNNET'></span><span id='topic+predictNNET'></span><span id='topic+modelerNNET'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnNNET(data, status, params, pfun)
predictNNET(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnNNET_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnNNET_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnNNET_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnNNET_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictNNET</code>.
</p>
</td></tr>
<tr><td><code id="learnNNET_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnNNET_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnNNET_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnNNET</code> and <code>predictNNET</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The NNET classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnNNET</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnNNET</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictNNET</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnNNET</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a NNET classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictNNET</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnNNET</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
nnet.params &lt;- list()

# learn the model
#fm &lt;- learnNNET(data, status, nnet.params, predictNNET)

# Make predictions on some new simulated data
#newdata &lt;- matrix(rnorm(100*30), ncol=30)
#predictNNET(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnNNET2'>
Fit models and make predictions with a multi-level neural network classifier
</h2><span id='topic+learnNNET2'></span><span id='topic+predictNNET2'></span><span id='topic+modelerNNET2'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier usinfg neural networks. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnNNET2(data, status, params, pfun)
predictNNET2(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnNNET2_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnNNET2_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnNNET2_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnNNET2_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictNNET2</code>.
</p>
</td></tr>
<tr><td><code id="learnNNET2_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnNNET2_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnNNET2_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnNNET2</code> and <code>predictNNET2</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The NNET2 classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnNNET2</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnNNET2</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictNNET2</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnNNET2</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a NNET2 classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictNNET2</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnNNET2</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
nnet.params &lt;- list()

# learn the model
#fm &lt;- learnNNET2(data, status, nnet.params, predictNNET2)

# Make predictions on some new simulated data
#newdata &lt;- matrix(rnorm(100*30), ncol=30)
#predictNNET2(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnPCALR'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnPCALR'></span><span id='topic+predictPCALR'></span><span id='topic+modelerPCALR'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnPCALR(data, status, params, pfun)
predictPCALR(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnPCALR_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnPCALR_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnPCALR_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnPCALR_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictPCALR</code>.
</p>
</td></tr>
<tr><td><code id="learnPCALR_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnPCALR_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnPCALR_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnPCALR</code> and <code>predictPCALR</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The PCALR classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnPCALR</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnPCALR</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictPCALR</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnPCALR</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a PCALR classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictPCALR</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnPCALR</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
pcalr.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model
fm &lt;- learnPCALR(data, status, pcalr.params, predictPCALR)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictPCALR(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnRF'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnRF'></span><span id='topic+predictRF'></span><span id='topic+modelerRF'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnRF(data, status, params, pfun)
predictRF(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnRF_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnRF_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnRF_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnRF_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictRF</code>.
</p>
</td></tr>
<tr><td><code id="learnRF_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnRF_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnRF_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnRF</code> and <code>predictRF</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The RF classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnRF</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnRF</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictRF</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnRF</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a RF classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictRF</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnRF</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
svm.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model
#fm &lt;- learnRF(data, status, svm.params, predictRF)

# Make predictions on some new simulated data
#newdata &lt;- matrix(rnorm(100*30), ncol=30)
#predictRF(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnRPART'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnRPART'></span><span id='topic+predictRPART'></span><span id='topic+modelerRPART'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnRPART(data, status, params, pfun)
predictRPART(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnRPART_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnRPART_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnRPART_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnRPART_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictRPART</code>.
</p>
</td></tr>
<tr><td><code id="learnRPART_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnRPART_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnRPART_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnRPART</code> and <code>predictRPART</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The RPART classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnRPART</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnRPART</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictRPART</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnRPART</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a RPART classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictRPART</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnRPART</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
rpart.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model
fm &lt;- learnRPART(data, status, rpart.params, predictRPART)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictRPART(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnSelectedLR'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnSelectedLR'></span><span id='topic+predictSelectedLR'></span><span id='topic+modelerSelectedLR'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnSelectedLR(data, status, params, pfun)
predictSelectedLR(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnSelectedLR_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnSelectedLR_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnSelectedLR_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnSelectedLR_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictSelectedLR</code>.
</p>
</td></tr>
<tr><td><code id="learnSelectedLR_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnSelectedLR_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnSelectedLR_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnSelectedLR</code> and <code>predictSelectedLR</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The SelectedLR classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnSelectedLR</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnSelectedLR</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictSelectedLR</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnSelectedLR</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a SelectedLR classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictSelectedLR</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to tain and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnSelectedLR</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
slr.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model
fm &lt;- learnSelectedLR(data, status, slr.params, predictSelectedLR)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictSelectedLR(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnSVM'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnSVM'></span><span id='topic+predictSVM'></span><span id='topic+modelerSVM'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnSVM(data, status, params, pfun)
predictSVM(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnSVM_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnSVM_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnSVM_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnSVM_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictSVM</code>.
</p>
</td></tr>
<tr><td><code id="learnSVM_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnSVM_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnSVM_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnSVM</code> and <code>predictSVM</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The SVM classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnSVM</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnSVM</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictSVM</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnSVM</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a SVM classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictSVM</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnSVM</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
svm.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model
fm &lt;- learnSVM(data, status, svm.params, predictSVM)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictSVM(newdata, fm@details, status)
</code></pre>

<hr>
<h2 id='learnTailRank'>
Fit models and make predictions with a PCA-LR classifier
</h2><span id='topic+learnTailRank'></span><span id='topic+predictTailRank'></span><span id='topic+modelerTailRank'></span>

<h3>Description</h3>

<p>These functions are used to apply the generic train-and-test
mechanism to a classifier that combines principal component analysis
(PCA) with logistic regression (LR). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnTailRank(data, status, params, pfun)
predictTailRank(newdata, details, status, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnTailRank_+3A_data">data</code></td>
<td>

<p>The data matrix, with rows as features (&quot;genes&quot;) and columns as the
samples to be classified.
</p>
</td></tr>
<tr><td><code id="learnTailRank_+3A_status">status</code></td>
<td>

<p>A factor, with two levels, classifying the samples. The length must
equal the number of <code>data</code> columns.
</p>
</td></tr>
<tr><td><code id="learnTailRank_+3A_params">params</code></td>
<td>

<p>A list of additional parameters used by the classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnTailRank_+3A_pfun">pfun</code></td>
<td>

<p>The function used to make predictions on new data, using the
trained classifier.  Should always be set to
<code>predictTailRank</code>.
</p>
</td></tr>
<tr><td><code id="learnTailRank_+3A_newdata">newdata</code></td>
<td>

<p>Another data matrix, with the same number of rows as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="learnTailRank_+3A_details">details</code></td>
<td>

<p>A list of additional parameters describing details about the
particular classifier; see Details.
</p>
</td></tr>
<tr><td><code id="learnTailRank_+3A_...">...</code></td>
<td>

<p>Optional extra parameters required by the generic &quot;predict&quot; method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input arguments to both <code>learnTailRank</code> and <code>predictTailRank</code>
are dictated by the requirements of the general train-and-test
mechanism provided by the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>
<p>The TailRank classifier is similar in spirit to the &quot;supervised principal
components&quot; method implemented in the <code>superpc</code> package.  We
start by performing univariate two-sample t-tests to identify features
that are differentially expressed between two groups of training
samples.  We then set a cutoff to select features using a bound
(<code>alpha</code>) on the false discovery rate (FDR).  If the number of
selected features is smaller than a prespecified goal
(<code>minNgenes</code>), then we increase the FDR until we get the desired
number of features.  Next, we perform PCA on the selected features
from the trqining data.  we retain enough principal components (PCs)
to explain a prespecified fraction of the variance (<code>perVar</code>).
We then fit a logistic regression model using these PCs to predict the
binary class of the training data.  In order to use this model to make
binary predictions, you must specify a <code>prior</code> probability that a
sample belongs to the first of the two groups (where the ordering is
determined by the levels of the classification factor, <code>status</code>).
</p>
<p>In order to fit the model to data, the <code>params</code> argument to the
<code>learnTailRank</code> function should be a list containing components
named <code>alpha</code>, <code>minNgenes</code>, <code>perVar</code>, and <code>prior</code>.
It may also contain a logical value called <code>verbose</code>, which
controls the amount of information that is output as the algorithm runs.
</p>
<p>The result of fitting the model using <code>learnTailRank</code> is a member of
the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code>.  In additon to storing the
prediction function (<code>pfun</code>) and the training data and status,
the FittedModel stores those details about the model that are required
in order to make predictions of the outcome on new data.  In this
acse, the details are: the <code>prior</code> probability, the set of 
selected features (<code>sel</code>, a logical vector), the principal
component decomposition (<code>spca</code>, an object of the
<code><a href="ClassDiscovery.html#topic+SamplePCA">SamplePCA</a></code> class), the logistic
regression model (<code>mmod</code>, of class <code><a href="stats.html#topic+glm">glm</a></code>), the number
of PCs used (<code>nCompUsed</code>) as well as the number of components
available (<code>nCompAvail</code>) and the number of gene-features selected
(<code>nGenesSelecets</code>).  The <code>details</code> object is appropriate for
sending as the second argument to the <code>predictTailRank</code> function in
order to make predictions with the model on new data.  Note that the
status vector here is the one used for the <em>training</em> data, since
the prediction function only uses the <em>levels</em> of this factor to
make sure that the direction of the predicitons is interpreted
correctly.
</p>


<h3>Value</h3>

<p>The <code>learnTailRank</code> function returns an object of the
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code>, representing a TailRank classifier
that has been fitted on a training <code>data</code> set.
</p>
<p>The <code>predictTailRank</code> function returns a factor containing the
predictions of the model when applied to the new data set.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Modeler-class">Modeler-class</a></code> and <code><a href="#topic+Modeler">Modeler</a></code> for details
about how to train and test models.  See
<code><a href="#topic+FittedModel-class">FittedModel-class</a></code> and <code><a href="#topic+FittedModel">FittedModel</a></code> for
details about the structure of the object returned by <code>learnTailRank</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# simulate some data
data &lt;- matrix(rnorm(100*20), ncol=20)
status &lt;- factor(rep(c("A", "B"), each=10))

# set up the parameter list
tr.params &lt;- list(minNgenes=10, alpha=0.10, perVar=0.80, prior=0.5)

# learn the model -- this is slow
fm &lt;- learnTailRank(data, status, tr.params, predictTailRank)

# Make predictions on some new simulated data
newdata &lt;- matrix(rnorm(100*30), ncol=30)
predictTailRank(newdata, fm@details, status)

## End(Not run)
</code></pre>

<hr>
<h2 id='Modeler'>
Constructor for &quot;Modeler&quot; objects
</h2><span id='topic+Modeler'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+Modeler-class">Modeler-class</a></code> represents (parametrized but not yet
fit) statistical models that can predict binary outcomes. The
<code>Modeler</code> function is used to construct objects of this class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Modeler(learn, predict, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Modeler_+3A_learn">learn</code></td>
<td>

<p>Object of class <code>"function"</code> that will be used to fit the model
to a data set.  See <code><a href="#topic+learn">learn</a></code> for details.
</p>
</td></tr>
<tr><td><code id="Modeler_+3A_predict">predict</code></td>
<td>

<p>Object of class <code>"function"</code> that will be used to make
predictions on new data from a fitted model.  See
<code><a href="stats.html#topic+predict">predict</a></code> for details.
</p>
</td></tr>
<tr><td><code id="Modeler_+3A_...">...</code></td>
<td>

<p>Additional parameters required for the specific kind of
classificaiton model that will be constructed.  See Details. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects of the <code><a href="#topic+Modeler-class">Modeler-class</a></code> provide a general
abstraction for classification models that can be learned from one
data set and then applied to a new data set.  Each type of classifier
is likely to have its own specific parameters.  For instance, a
K-nearest neighbors classifier requires you to specify <code>k</code>.  The
more complex classifier, PCA-LR has many more parameters, including
the false discovery rate (<code>alpha</code>) used to select features and
the percentage of variance (<code>perVar</code>) that should be explained by
the number of principal components created from those features.  All
additional parameters should be suplied as named arguments to the
<code>Modeler</code> constructor; these additional parameters will be
bundled into a list and inserted into the <code>params</code> slot of the
resulting object of the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>


<h3>Value</h3>

<p>Returns an object of the <code><a href="#topic+Modeler-class">Modeler-class</a></code>.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See the descriptions of the <code><a href="#topic+learn">learn</a></code> function and
the <code><a href="stats.html#topic+predict">predict</a></code> method for details on how to fit models on
training data and make predictions on new test data. 
</p>
<p>See the description of the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code> for details
about the kinds of objects produced by <code><a href="#topic+learn">learn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>learnNNET
predictNNET
modelerNNET &lt;- Modeler(learnNNET, predictNNET, size=5)
modelerNNET
</code></pre>

<hr>
<h2 id='Modeler-class'>Class &quot;Modeler&quot; </h2><span id='topic+Modeler-class'></span>

<h3>Description</h3>

<p>The <code>Modeler</code> class represents (parametrized but not
yet fit) statistical models that can predict binary outcomes.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls to the constructor fuinction, <code><a href="#topic+Modeler">Modeler</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>learnFunction</code>:</dt><dd><p>Object of class <code>"function"</code> that is used
to fit the model to a data set.  See <code><a href="#topic+learn">learn</a></code> for details.</p>
</dd>
<dt><code>predictFunction</code>:</dt><dd><p>Object of class <code>"function"</code> that is
used to make predictions on new data from a fitted model.  See
<code><a href="stats.html#topic+predict">predict</a></code> for details. </p>
</dd>
<dt><code>paramList</code>:</dt><dd><p>Object of class <code>"list"</code> that contains
parameters that are specific for one type of classifier.</p>
</dd>
</dl>



<h3>Methods</h3>

<p>No methods are defined with class &quot;Modeler&quot; in the signature.  The only
function that can be applied to a <code>Modeler</code> object is
<code><a href="#topic+learn">learn</a></code>, which has not been made into a generic funtion.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes &lt;krc@silicovore.com&gt;
</p>


<h3>See Also</h3>

<p>See the description of the <code><a href="#topic+FittedModel-class">FittedModel-class</a></code> for details
about the kinds of objects produced by <code><a href="#topic+learn">learn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("Modeler")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
