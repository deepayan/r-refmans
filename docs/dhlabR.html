<!DOCTYPE html><html><head><title>Help for package dhlabR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dhlabR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#get_collocations'><p>Get collocations for word in corpus</p></a></li>
<li><a href='#get_concordance'><p>Retrieve Concordance for Words in Documents</p></a></li>
<li><a href='#get_dispersion'><p>Dispersion of tokens in a text</p></a></li>
<li><a href='#get_document_corpus'><p>Get Document Corpus</p></a></li>
<li><a href='#get_document_frequencies'><p>Retrieve Token Frequencies in Documents</p></a></li>
<li><a href='#get_metadata'><p>Get National Library Metadata for identifiers</p></a></li>
<li><a href='#get_ngram'><p>Hidden internal function to get NGRAM</p></a></li>
<li><a href='#get_ngram_from_books'><p>Get Ngram Count per Year for National Library Book Collection</p></a></li>
<li><a href='#get_ngram_from_newspapers'><p>Get Ngram Count per Year for National Library Newspaper Collection</p></a></li>
<li><a href='#get_reference_words'><p>Retrieve Reference Words Count and Relative Frequency</p></a></li>
<li><a href='#get_urn_frequencies'><p>Get word count frequencies for a list of URNs or dhlabids</p></a></li>
<li><a href='#ngram'><p>Function to get and convert NGRAM</p></a></li>
<li><a href='#ngram_conv'><p>Hidden internal function to convert NGRAM</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>National Library of Norway Quantitative Text Data API Tools</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for accessing data from National Library of Norway's dhlab (digital humanities laboratory).
    Provides wrappers for accessing our API services at <a href="https://api.nb.no/dhlab/">https://api.nb.no/dhlab/</a>.
    To learn more about dhlab, visit out site <a href="https://www.nb.no/dh-lab/">https://www.nb.no/dh-lab/</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, httr, jsonlite, purrr, tibble, zoo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-09 08:42:14 UTC; larsm</td>
</tr>
<tr>
<td>Author:</td>
<td>Lars Tungland [aut, cre],
  Andre KÃ¥sen [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lars Tungland &lt;lars.tungland@nb.no&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-09 14:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='get_collocations'>Get collocations for word in corpus</h2><span id='topic+get_collocations'></span>

<h3>Description</h3>

<p>This function retrieves collocation data from a corpus using a given word and a list of unique identifiers (pids) of corpus data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_collocations(pids, word, before = 10, after = 10, sample_size = 5000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_collocations_+3A_pids">pids</code></td>
<td>
<p>A vector or data frame containing the unique identifiers of the texts in the corpus.</p>
</td></tr>
<tr><td><code id="get_collocations_+3A_word">word</code></td>
<td>
<p>The target word for which you want to find concordances.</p>
</td></tr>
<tr><td><code id="get_collocations_+3A_before">before</code></td>
<td>
<p>The number of words before the target word to include in the context (default is 10).</p>
</td></tr>
<tr><td><code id="get_collocations_+3A_after">after</code></td>
<td>
<p>The number of words after the target word to include in the context (default is 10).</p>
</td></tr>
<tr><td><code id="get_collocations_+3A_sample_size">sample_size</code></td>
<td>
<p>The number of samples to retrieve from the API (default is 5000).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of concordances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pids &lt;- c("URN:NBN:no-nb_digibok_2008051404065", "URN:NBN:no-nb_digibok_2010092120011")
word &lt;- "."
collocations &lt;- get_collocations(pids, word)

</code></pre>

<hr>
<h2 id='get_concordance'>Retrieve Concordance for Words in Documents</h2><span id='topic+get_concordance'></span>

<h3>Description</h3>

<p>This function obtains the concordance for specified words within given documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_concordance(pids, words, window = 20, limit = 5000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_concordance_+3A_pids">pids</code></td>
<td>
<p>A vector or data frame containing document IDs.</p>
</td></tr>
<tr><td><code id="get_concordance_+3A_words">words</code></td>
<td>
<p>A string of words (tokens) for which the concordance will be retrieved. For multiple tokens use keyword OR</p>
</td></tr>
<tr><td><code id="get_concordance_+3A_window">window</code></td>
<td>
<p>An optional numeric value specifying the number of characters before and after the matching word (default is 20).</p>
</td></tr>
<tr><td><code id="get_concordance_+3A_limit">limit</code></td>
<td>
<p>An optional numeric value specifying the maximum number of results to return (default is 5000).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the concordance results for each word in the specified documents. Returns NULL if the API request fails or no results are found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>document_ids &lt;- c("URN:NBN:no-nb_digibok_2008051404065", "URN:NBN:no-nb_digibok_2010092120011")
tokens &lt;- "Norge"
window &lt;- 20
limit &lt;- 1000
result &lt;- get_concordance(document_ids, tokens, window, limit)
</code></pre>

<hr>
<h2 id='get_dispersion'>Dispersion of tokens in a text</h2><span id='topic+get_dispersion'></span>

<h3>Description</h3>

<p>This function wraps a call to the dispersion service, which calculates the
dispersion of a list of tokens throughout a text in the National Library of
Norway's collection, given by the URN. The text is divided into chunks, and
the count of tokens in each chunk is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dispersion(urn = NULL, words = list(".", ","), window = 500, pr = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dispersion_+3A_urn">urn</code></td>
<td>
<p>A National Library of Norway URN to a text object.</p>
</td></tr>
<tr><td><code id="get_dispersion_+3A_words">words</code></td>
<td>
<p>A list or vector of words (tokens) to analyze for dispersion.</p>
</td></tr>
<tr><td><code id="get_dispersion_+3A_window">window</code></td>
<td>
<p>The size of the text chunk to count the tokens within.</p>
</td></tr>
<tr><td><code id="get_dispersion_+3A_pr">pr</code></td>
<td>
<p>(Per) Determines the step size for moving forward to the next chunk.
If 'pr' is equal to 'window', the text is divided into non-overlapping
chunks of size 'window'. If 'pr' is smaller than 'window', the chunks
will overlap, creating a smoother curve.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the count of tokens in each chunk.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>urn &lt;- "URN:NBN:no-nb_digibok_2013060406055"
words &lt;- c("Dracula", "Mina", "Helsing")
window &lt;- 1000
pr &lt;- 1000
dispersion_result &lt;- get_dispersion(urn, words, window, pr)
</code></pre>

<hr>
<h2 id='get_document_corpus'>Get Document Corpus</h2><span id='topic+get_document_corpus'></span>

<h3>Description</h3>

<p>Retrieve a corpus of documents based on the given parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_document_corpus(
  doctype = "digibok",
  author = NULL,
  ddk = NULL,
  freetext = NULL,
  subject = NULL,
  from_timestamp = NULL,
  to_timestamp = NULL,
  publisher = NULL,
  limit = 10,
  order_and_limit_by_rank = NULL,
  title = NULL,
  from_year = NULL,
  to_year = NULL,
  fulltext = NULL,
  lang = "nob"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_document_corpus_+3A_doctype">doctype</code></td>
<td>
<p>Character, document type (default: 'digibok')</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_author">author</code></td>
<td>
<p>Character, author name (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_ddk">ddk</code></td>
<td>
<p>Character, Dewey Decimal Classification (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_freetext">freetext</code></td>
<td>
<p>Character, free text search (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_subject">subject</code></td>
<td>
<p>Character, subject of the document (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_from_timestamp">from_timestamp</code></td>
<td>
<p>Character, timestamp range start (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_to_timestamp">to_timestamp</code></td>
<td>
<p>Character, timestamp range end (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_publisher">publisher</code></td>
<td>
<p>Character, publisher name (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_limit">limit</code></td>
<td>
<p>Integer, maximum number of results (default: 10)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_order_and_limit_by_rank">order_and_limit_by_rank</code></td>
<td>
<p>Logical, order and limit results by rank (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_title">title</code></td>
<td>
<p>Character, title of the document (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_from_year">from_year</code></td>
<td>
<p>Integer, year range start (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_to_year">to_year</code></td>
<td>
<p>Integer, year range end (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_fulltext">fulltext</code></td>
<td>
<p>Character, full text search (default: NULL)</p>
</td></tr>
<tr><td><code id="get_document_corpus_+3A_lang">lang</code></td>
<td>
<p>Character, language code (default: 'nob')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of metadata
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  get_document_corpus(doctype = 'digibok', author = 'Henrik Ibsen', limit = 2)

</code></pre>

<hr>
<h2 id='get_document_frequencies'>Retrieve Token Frequencies in Documents</h2><span id='topic+get_document_frequencies'></span>

<h3>Description</h3>

<p>This function obtains token frequencies within specified documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_document_frequencies(pids, cutoff = 0, words = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_document_frequencies_+3A_pids">pids</code></td>
<td>
<p>A vector or data frame containing document IDs.</p>
</td></tr>
<tr><td><code id="get_document_frequencies_+3A_cutoff">cutoff</code></td>
<td>
<p>A numeric value specifying the frequency cutoff for tokens.</p>
</td></tr>
<tr><td><code id="get_document_frequencies_+3A_words">words</code></td>
<td>
<p>A vector of words (tokens) to retrieve frequencies for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements for each document:
</p>

<ul>
<li><p> Document ID
</p>
</li>
<li><p> Token
</p>
</li>
<li><p> Token frequency in the document
</p>
</li>
<li><p> Total tokens in the document
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>document_ids &lt;- c("URN:NBN:no-nb_digibok_2008051404065", "URN:NBN:no-nb_digibok_2010092120011")
frequency_cutoff &lt;- 10
tokens &lt;- c(".", ",", "men")
result &lt;- get_document_frequencies(document_ids, frequency_cutoff, tokens)
</code></pre>

<hr>
<h2 id='get_metadata'>Get National Library Metadata for identifiers</h2><span id='topic+get_metadata'></span>

<h3>Description</h3>

<p>This function retrieves metadata for objects from the National Library API based on either a vector of dhlabids or a vector of National Library URNs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_metadata(dhlabids = NULL, urns = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_metadata_+3A_dhlabids">dhlabids</code></td>
<td>
<p>A vector of dhlabids (default is NULL). When provided, the function will use dhlabids to fetch metadata.</p>
</td></tr>
<tr><td><code id="get_metadata_+3A_urns">urns</code></td>
<td>
<p>A vector of National Library URNs (default is NULL). When provided, the function will use URNs to fetch metadata.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the National Library metadata for the specified objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  urns_example &lt;- c("URN:NBN:no-nb_digibok_2008051404065", "URN:NBN:no-nb_digibok_2010092120011")
  metadata_urns &lt;- get_metadata(urns = urns_example)
</code></pre>

<hr>
<h2 id='get_ngram'>Hidden internal function to get NGRAM</h2><span id='topic+get_ngram'></span>

<h3>Description</h3>

<p>Hidden internal function to get NGRAM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ngram(word, corpus, language = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ngram_+3A_word">word</code></td>
<td>
<p>The word to get NGRAM for.</p>
</td></tr>
<tr><td><code id="get_ngram_+3A_corpus">corpus</code></td>
<td>
<p>The corpus to use. Options are 'avis' and 'bok'.</p>
</td></tr>
<tr><td><code id="get_ngram_+3A_language">language</code></td>
<td>
<p>The language to use. Default is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list that contains the NGRAM.
</p>

<hr>
<h2 id='get_ngram_from_books'>Get Ngram Count per Year for National Library Book Collection</h2><span id='topic+get_ngram_from_books'></span>

<h3>Description</h3>

<p>This function queries the National Library's book collection API to retrieve
the ngram count per year for the specified parameters. It can be used to plot
an ngram based on the words' presence in books in the library's collection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ngram_from_books(
  city = NULL,
  ddk = NULL,
  lang = NULL,
  period = list(),
  publisher = NULL,
  title = NULL,
  topic = NULL,
  word = list("hus", "blokk")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ngram_from_books_+3A_city">city</code></td>
<td>
<p>(character, optional) The city of publication. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_ddk">ddk</code></td>
<td>
<p>(character, optional) The Dewey Decimal Classification (DDC) code. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_lang">lang</code></td>
<td>
<p>(character, optional) The language code of the books. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_period">period</code></td>
<td>
<p>(list, optional) A list containing the start and end years of the period to search. Default is an empty list.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_publisher">publisher</code></td>
<td>
<p>(character, optional) The publisher's name. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_title">title</code></td>
<td>
<p>(character, optional) The title or a part of the title of the books. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_topic">topic</code></td>
<td>
<p>(character, optional) A topic or subject associated with the books. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_books_+3A_word">word</code></td>
<td>
<p>(list, optional) A list of words (ngrams) to search for in the books. Default is list(&quot;hus&quot;, &quot;blokk&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the ngram count per year for the specified parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get ngram count for the words "hus" and "blokk" in the specified period
get_ngram_from_books(period = list(1990, 2000))

# Get ngram count for the word "library" in English books
get_ngram_from_books(lang = "eng", word = list("library"))
</code></pre>

<hr>
<h2 id='get_ngram_from_newspapers'>Get Ngram Count per Year for National Library Newspaper Collection</h2><span id='topic+get_ngram_from_newspapers'></span>

<h3>Description</h3>

<p>This function queries the National Library's book collection API to retrieve
the ngram count per year for the specified parameters. It can be used to plot
an ngram based on the words' presence in books in the library's collection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ngram_from_newspapers(
  city = NULL,
  ddk = NULL,
  lang = NULL,
  period = list(),
  publisher = NULL,
  title = NULL,
  topic = NULL,
  word = list("hus", "blokk")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ngram_from_newspapers_+3A_city">city</code></td>
<td>
<p>(character, optional) The city of publication. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_ddk">ddk</code></td>
<td>
<p>(character, optional) The Dewey Decimal Classification (DDC) code. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_lang">lang</code></td>
<td>
<p>(character, optional) The language code of the books. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_period">period</code></td>
<td>
<p>(list, optional) A list containing the start and end years of the period to search. Default is an empty list.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_publisher">publisher</code></td>
<td>
<p>(character, optional) The publisher's name. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_title">title</code></td>
<td>
<p>(character, optional) The title or a part of the title of the books. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_topic">topic</code></td>
<td>
<p>(character, optional) A topic or subject associated with the books. Default is NULL.</p>
</td></tr>
<tr><td><code id="get_ngram_from_newspapers_+3A_word">word</code></td>
<td>
<p>(list, optional) A list of words (ngrams) to search for in the books. Default is list(&quot;hus&quot;, &quot;blokk&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the ngram count per year for the specified parameters.
</p>

<hr>
<h2 id='get_reference_words'>Retrieve Reference Words Count and Relative Frequency</h2><span id='topic+get_reference_words'></span>

<h3>Description</h3>

<p>This function obtains the count and relative frequency of a vector of words within a year range for specified document types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_reference_words(
  doctype = "digibok",
  from_year = 1990,
  to_year = 2000,
  words = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_reference_words_+3A_doctype">doctype</code></td>
<td>
<p>A character string indicating the document type. One of &quot;digibok&quot;, &quot;digavis&quot;, or &quot;digitidsskrift&quot;.</p>
</td></tr>
<tr><td><code id="get_reference_words_+3A_from_year">from_year</code></td>
<td>
<p>A numeric value indicating the starting year of the range.</p>
</td></tr>
<tr><td><code id="get_reference_words_+3A_to_year">to_year</code></td>
<td>
<p>A numeric value indicating the ending year of the range.</p>
</td></tr>
<tr><td><code id="get_reference_words_+3A_words">words</code></td>
<td>
<p>A vector of words for which the count and relative frequency will be retrieved.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the count and relative frequency of the specified words within the given year range and document type.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>doctype &lt;- "digibok"
from_year &lt;- 1900
to_year &lt;- 2000
words &lt;- c("og", "eller", "men")
result &lt;- get_reference_words(doctype, from_year, to_year, words)
</code></pre>

<hr>
<h2 id='get_urn_frequencies'>Get word count frequencies for a list of URNs or dhlabids</h2><span id='topic+get_urn_frequencies'></span>

<h3>Description</h3>

<p>This function takes a list of National Library of Norway (NB) identifiers,
either URNs or dhlabids, and returns the word count for each object.
It queries the National Library's API to fetch the word count data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_urn_frequencies(urns = NULL, dhlabids = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_urn_frequencies_+3A_urns">urns</code></td>
<td>
<p>A list or data frame of URNs from the National Library of Norway.
If a data frame, it should have a column named 'urn'.</p>
</td></tr>
<tr><td><code id="get_urn_frequencies_+3A_dhlabids">dhlabids</code></td>
<td>
<p>A list of 'dhlabid' ids from National Library DHLAB.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with two columns: 'dhlabid' and 'frequencies'.
Each row represents a library text resource with its corresponding word count.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example usage with a list of URNs
urn_list &lt;- c("URN:NBN:no-nb_digibok_2008051404065", "URN:NBN:no-nb_digibok_2010092120011")
word_counts &lt;- get_urn_frequencies(urn_list)
print(word_counts)

# Example usage with a data frame of URNs
urn_list &lt;-  c("URN:NBN:no-nb_digibok_2008051404065", "URN:NBN:no-nb_digibok_2010092120011")
urn_dataframe &lt;- data.frame(urn = urn_list)
word_counts &lt;- get_urn_frequencies(urn_dataframe)

</code></pre>

<hr>
<h2 id='ngram'>Function to get and convert NGRAM</h2><span id='topic+ngram'></span>

<h3>Description</h3>

<p>Function to get and convert NGRAM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ngram(
  word = "havet",
  corpus = "bok",
  language = NULL,
  smooth = 1,
  years = c(1810, 2013),
  mode = "relative"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ngram_+3A_word">word</code></td>
<td>
<p>The word to get NGRAM for. Default is &quot;havet&quot;.</p>
</td></tr>
<tr><td><code id="ngram_+3A_corpus">corpus</code></td>
<td>
<p>The corpus to use. Options are 'avis' and 'bok'. Default is &quot;bok&quot;.</p>
</td></tr>
<tr><td><code id="ngram_+3A_language">language</code></td>
<td>
<p>The language to use. Default is NULL.</p>
</td></tr>
<tr><td><code id="ngram_+3A_smooth">smooth</code></td>
<td>
<p>Smoothing factor. Default is 1.</p>
</td></tr>
<tr><td><code id="ngram_+3A_years">years</code></td>
<td>
<p>A vector that contains the start and end years. Default is c(1810,2013).</p>
</td></tr>
<tr><td><code id="ngram_+3A_mode">mode</code></td>
<td>
<p>The mode to use. Default is 'relative'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame that contains the NGRAM.
</p>

<hr>
<h2 id='ngram_conv'>Hidden internal function to convert NGRAM</h2><span id='topic+ngram_conv'></span>

<h3>Description</h3>

<p>Hidden internal function to convert NGRAM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ngram_conv(ngrams, smooth = 1, years = c(1810, 2013), mode = "relative")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ngram_conv_+3A_ngrams">ngrams</code></td>
<td>
<p>The NGRAMs to convert.</p>
</td></tr>
<tr><td><code id="ngram_conv_+3A_smooth">smooth</code></td>
<td>
<p>Smoothing factor. Default is 1.</p>
</td></tr>
<tr><td><code id="ngram_conv_+3A_years">years</code></td>
<td>
<p>A vector that contains the start and end years. Default is c(1810,2013).</p>
</td></tr>
<tr><td><code id="ngram_conv_+3A_mode">mode</code></td>
<td>
<p>The mode to use. Default is 'relative'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame that contains the converted NGRAM.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
