<!DOCTYPE html><html><head><title>Help for package boot</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {boot}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abc.ci'>
<p>Nonparametric ABC Confidence Intervals</p></a></li>
<li><a href='#acme'>
<p>Monthly Excess Returns</p></a></li>
<li><a href='#aids'>
<p>Delay in AIDS Reporting in England and Wales</p></a></li>
<li><a href='#aircondit'>
<p>Failures of Air-conditioning Equipment</p></a></li>
<li><a href='#amis'>
<p>Car Speeding and Warning Signs</p></a></li>
<li><a href='#aml'>
<p>Remission Times for Acute Myelogenous Leukaemia</p></a></li>
<li><a href='#beaver'>
<p>Beaver Body Temperature Data</p></a></li>
<li><a href='#bigcity'>
<p>Population of U.S. Cities</p></a></li>
<li><a href='#boot'>
<p>Bootstrap Resampling</p></a></li>
<li><a href='#boot-practicals'><p> Functions for Bootstrap Practicals</p></a></li>
<li><a href='#boot.array'>
<p>Bootstrap Resampling Arrays</p></a></li>
<li><a href='#boot.ci'>
<p>Nonparametric Bootstrap Confidence Intervals</p></a></li>
<li><a href='#brambles'>
<p>Spatial Location of Bramble Canes</p></a></li>
<li><a href='#breslow'>
<p>Smoking Deaths Among Doctors</p></a></li>
<li><a href='#calcium'>
<p>Calcium Uptake Data</p></a></li>
<li><a href='#cane'>
<p>Sugar-cane Disease Data</p></a></li>
<li><a href='#capability'>
<p>Simulated Manufacturing Process Data</p></a></li>
<li><a href='#catsM'>
<p>Weight Data for Domestic Cats</p></a></li>
<li><a href='#cav'>
<p>Position of Muscle Caveolae</p></a></li>
<li><a href='#cd4'>
<p>CD4 Counts for HIV-Positive Patients</p></a></li>
<li><a href='#cd4.nested'>
<p>Nested Bootstrap of cd4 data</p></a></li>
<li><a href='#censboot'>
<p>Bootstrap for Censored Data</p></a></li>
<li><a href='#channing'>
<p>Channing House Data</p></a></li>
<li><a href='#claridge'>
<p>Genetic Links to Left-handedness</p></a></li>
<li><a href='#cloth'>
<p>Number of Flaws in Cloth</p></a></li>
<li><a href='#co.transfer'>
<p>Carbon Monoxide Transfer</p></a></li>
<li><a href='#coal'>
<p>Dates of Coal Mining Disasters</p></a></li>
<li><a href='#control'>
<p>Control Variate Calculations</p></a></li>
<li><a href='#corr'>
<p>Correlation Coefficient</p></a></li>
<li><a href='#cum3'>
<p>Calculate Third Order Cumulants</p></a></li>
<li><a href='#cv.glm'>
<p>Cross-validation for Generalized Linear Models</p></a></li>
<li><a href='#darwin'>
<p>Darwin's Plant Height Differences</p></a></li>
<li><a href='#dogs'><p> Cardiac Data for Domestic Dogs</p></a></li>
<li><a href='#downs.bc'>
<p>Incidence of Down's Syndrome in British Columbia</p></a></li>
<li><a href='#ducks'>
<p>Behavioral and Plumage Characteristics of Hybrid Ducks</p></a></li>
<li><a href='#EEF.profile'><p> Empirical Likelihoods</p></a></li>
<li><a href='#empinf'>
<p>Empirical Influence Values</p></a></li>
<li><a href='#envelope'>
<p>Confidence Envelopes for Curves</p></a></li>
<li><a href='#exp.tilt'>
<p>Exponential Tilting</p></a></li>
<li><a href='#fir'>
<p>Counts of Balsam-fir Seedlings</p></a></li>
<li><a href='#freq.array'>
<p>Bootstrap Frequency Arrays</p></a></li>
<li><a href='#frets'>
<p>Head Dimensions in Brothers</p></a></li>
<li><a href='#glm.diag'>
<p>Generalized Linear Model Diagnostics</p></a></li>
<li><a href='#glm.diag.plots'>
<p>Diagnostics plots for generalized linear models</p></a></li>
<li><a href='#gravity'>
<p>Acceleration Due to Gravity</p></a></li>
<li><a href='#hirose'>
<p>Failure Time of PET Film</p></a></li>
<li><a href='#Imp.Estimates'>
<p>Importance Sampling Estimates</p></a></li>
<li><a href='#imp.weights'>
<p>Importance Sampling Weights</p></a></li>
<li><a href='#inv.logit'>
<p>Inverse Logit Function</p></a></li>
<li><a href='#islay'>
<p>Jura Quartzite Azimuths on Islay</p></a></li>
<li><a href='#jack.after.boot'>
<p>Jackknife-after-Bootstrap Plots</p></a></li>
<li><a href='#k3.linear'>
<p>Linear Skewness Estimate</p></a></li>
<li><a href='#linear.approx'>
<p>Linear Approximation of Bootstrap Replicates</p></a></li>
<li><a href='#lines.saddle.distn'>
<p>Add a Saddlepoint Approximation to a Plot</p></a></li>
<li><a href='#logit'>
<p>Logit of Proportions</p></a></li>
<li><a href='#manaus'>
<p>Average Heights of the Rio Negro river at Manaus</p></a></li>
<li><a href='#melanoma'>
<p>Survival from Malignant Melanoma</p></a></li>
<li><a href='#motor'>
<p>Data from a Simulated Motorcycle Accident</p></a></li>
<li><a href='#neuro'>
<p>Neurophysiological Point Process Data</p></a></li>
<li><a href='#nitrofen'>
<p>Toxicity of Nitrofen in Aquatic Systems</p></a></li>
<li><a href='#nodal'>
<p>Nodal Involvement in Prostate Cancer</p></a></li>
<li><a href='#norm.ci'>
<p>Normal Approximation Confidence Intervals</p></a></li>
<li><a href='#nuclear'>
<p>Nuclear Power Station Construction Data</p></a></li>
<li><a href='#paulsen'>
<p>Neurotransmission in Guinea Pig Brains</p></a></li>
<li><a href='#plot.boot'>
<p>Plots of the Output of a Bootstrap Simulation</p></a></li>
<li><a href='#poisons'>
<p>Animal Survival Times</p></a></li>
<li><a href='#polar'>
<p>Pole Positions of New Caledonian Laterites</p></a></li>
<li><a href='#print.boot'>
<p>Print a Summary of a Bootstrap Object</p></a></li>
<li><a href='#print.bootci'>
<p>Print Bootstrap Confidence Intervals</p></a></li>
<li><a href='#print.saddle.distn'>
<p>Print Quantiles of Saddlepoint Approximations</p></a></li>
<li><a href='#print.simplex'>
<p>Print Solution to Linear Programming Problem</p></a></li>
<li><a href='#remission'>
<p>Cancer Remission and Cell Activity</p></a></li>
<li><a href='#saddle'>
<p>Saddlepoint Approximations for Bootstrap Statistics</p></a></li>
<li><a href='#saddle.distn'>
<p>Saddlepoint Distribution Approximations for Bootstrap Statistics</p></a></li>
<li><a href='#saddle.distn.object'>
<p>Saddlepoint Distribution Approximation Objects</p></a></li>
<li><a href='#salinity'>
<p>Water Salinity and River Discharge</p></a></li>
<li><a href='#simplex'>
<p>Simplex Method for Linear Programming Problems</p></a></li>
<li><a href='#simplex.object'>
<p>Linear Programming Solution Objects</p></a></li>
<li><a href='#smooth.f'>
<p>Smooth Distributions on Data Points</p></a></li>
<li><a href='#sunspot'>
<p>Annual Mean Sunspot Numbers</p></a></li>
<li><a href='#survival'>
<p>Survival of Rats after Radiation Doses</p></a></li>
<li><a href='#tau'>
<p>Tau Particle Decay Modes</p></a></li>
<li><a href='#tilt.boot'>
<p>Non-parametric Tilted Bootstrap</p></a></li>
<li><a href='#tsboot'>
<p>Bootstrapping of Time Series</p></a></li>
<li><a href='#tuna'>
<p>Tuna Sighting Data</p></a></li>
<li><a href='#urine'>
<p>Urine Analysis Data</p></a></li>
<li><a href='#var.linear'>
<p>Linear Variance Estimate</p></a></li>
<li><a href='#wool'>
<p>Australian Relative Wool Prices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Priority:</td>
<td>recommended</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3-30</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-19</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alessandra R. Brazzale &lt;brazzale@stat.unipd.it&gt;</td>
</tr>
<tr>
<td>Note:</td>
<td>Maintainers are not available to give advice on using a package
they did not author.</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions and datasets for bootstrapping from the
  book "Bootstrap Methods and Their Application" by A. C. Davison and 
  D. V. Hinkley (1997, CUP), originally written by Angelo Canty for S.</td>
</tr>
<tr>
<td>Title:</td>
<td>Bootstrap Functions (Originally by Angelo Canty for S)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), graphics, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, survival</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td>Unlimited</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-25 16:23:08 UTC; brazzale</td>
</tr>
<tr>
<td>Author:</td>
<td>Angelo Canty [aut] (author of original code for S),
  Brian Ripley [aut, trl] (conversion to R, maintainer 1999--2022, author of
    parallel support),
  Alessandra R. Brazzale [ctb, cre] (minor bug fixes)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-26 00:40:11 UTC</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.4.0; ; 2024-03-26 07:26:16 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='abc.ci'>
Nonparametric ABC Confidence Intervals
</h2><span id='topic+abc.ci'></span>

<h3>Description</h3>

<p>Calculate equi-tailed two-sided nonparametric approximate bootstrap confidence 
intervals for a parameter, given a set of data and an estimator of the 
parameter, using numerical differentiation.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abc.ci(data, statistic, index=1, strata=rep(1, n), conf=0.95, 
       eps=0.001/n, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abc.ci_+3A_data">data</code></td>
<td>

<p>A data set expressed as a vector, matrix or data frame.
</p>
</td></tr>
<tr><td><code id="abc.ci_+3A_statistic">statistic</code></td>
<td>

<p>A function which returns the statistic of interest.  The function must
take at least 2 arguments; the first argument should be the data and the
second a vector of weights.  The weights passed to <code>statistic</code> will be 
normalized to sum to 1 within each stratum.  Any other arguments should be 
passed to <code>abc.ci</code> as part of the <code>...{}</code> argument.  
</p>
</td></tr>
<tr><td><code id="abc.ci_+3A_index">index</code></td>
<td>

<p>If <code>statistic</code> returns a vector of length greater than 1, then this indicates
the position of the variable of interest within that vector.
</p>
</td></tr>
<tr><td><code id="abc.ci_+3A_strata">strata</code></td>
<td>

<p>A factor or numerical vector indicating to which sample each
observation belongs in multiple sample problems.  The default 
is the one-sample case.  
</p>
</td></tr>
<tr><td><code id="abc.ci_+3A_conf">conf</code></td>
<td>

<p>A scalar or vector containing the confidence level(s) of the required
interval(s).
</p>
</td></tr>
<tr><td><code id="abc.ci_+3A_eps">eps</code></td>
<td>

<p>The value of epsilon to be used for the numerical differentiation.
</p>
</td></tr>
<tr><td><code id="abc.ci_+3A_...">...</code></td>
<td>

<p>Any other arguments for <code>statistic</code>.  These will be passed unchanged to
<code>statistic</code> each time it is called within <code>abc.ci</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is based on the function <code>abcnon</code> written by R. Tibshirani.
A listing of the original function is available in DiCiccio and Efron (1996).
The function uses numerical differentiation for the first and second
derivatives of the statistic and then uses these values to approximate
the bootstrap BCa intervals.  The total number of evaluations of the
statistic is <code>2*n+2+2*length(conf)</code> where <code>n</code> is the number of data points
(plus calculation of the original value of the statistic).  The function 
works for the multiple sample case
without the need to rewrite the statistic in an artificial form since
the stratified normalization is done internally by the function.
</p>


<h3>Value</h3>

<p>A <code>length(conf)</code> by 3 matrix where each row contains the confidence level 
followed by the lower and upper end-points of the ABC interval at that
level.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>, Chapter 5. 
Cambridge University Press. 
</p>
<p>DiCiccio, T. J. and Efron B. (1992) More accurate confidence intervals in 
exponential families. <em>Biometrika</em>, <b>79</b>, 231&ndash;245.
</p>
<p>DiCiccio, T. J.  and Efron  B. (1996) Bootstrap confidence intervals (with
Discussion). 
<em>Statistical Science</em>, <b>11</b>, 189&ndash;228.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.ci">boot.ci</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# 90% and 95% confidence intervals for the correlation 
# coefficient between the columns of the bigcity data

abc.ci(bigcity, corr, conf=c(0.90,0.95))

# A 95% confidence interval for the difference between the means of
# the last two samples in gravity
mean.diff &lt;- function(y, w)
{    gp1 &lt;- 1:table(as.numeric(y$series))[1]
     sum(y[gp1, 1] * w[gp1]) - sum(y[-gp1, 1] * w[-gp1])
}
grav1 &lt;- gravity[as.numeric(gravity[, 2]) &gt;= 7, ]
## IGNORE_RDIFF_BEGIN
abc.ci(grav1, mean.diff, strata = grav1$series)
## IGNORE_RDIFF_END

</code></pre>

<hr>
<h2 id='acme'>
Monthly Excess Returns
</h2><span id='topic+acme'></span>

<h3>Description</h3>

<p>The <code>acme</code> data frame has 60 rows and 3 columns.
</p>
<p>The excess return for the Acme Cleveland Corporation are recorded along with
those for all stocks listed on the New York and American Stock Exchanges were
recorded over a five year period.  These excess returns are relative to the
return on a risk-less investment such a U.S. Treasury bills.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acme
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>month</code></dt><dd>
<p>A character string representing the month of the observation.
</p>
</dd>
<dt><code>market</code></dt><dd>
<p>The excess return of the market as a whole.
</p>
</dd>
<dt><code>acme</code></dt><dd>
<p>The excess return for the Acme Cleveland Corporation.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Simonoff, J.S. and Tsai, C.-L. (1994) Use of modified profile likelihood for 
improved tests of constancy of variance in regression. 
<em>Applied Statistics</em>, <b>43</b>, 353&ndash;370.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='aids'>
Delay in AIDS Reporting in England and Wales
</h2><span id='topic+aids'></span>

<h3>Description</h3>

<p>The <code>aids</code> data frame has 570 rows and 6 columns.
</p>
<p>Although all cases of AIDS in England and Wales must be reported to the
Communicable Disease Surveillance Centre, there is often a considerable delay
between the time of diagnosis and the time that it is reported.  In estimating
the prevalence of AIDS, account must be taken of the unknown number of cases
which have been diagnosed but not reported.  The data set here records the
reported cases of AIDS diagnosed from July 1983 and until the end of 1992.  
The data are cross-classified by the date of diagnosis and the time delay in 
the reporting of the cases.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aids
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>year</code></dt><dd>
<p>The year of the diagnosis.
</p>
</dd>
<dt><code>quarter</code></dt><dd>
<p>The quarter of the year in which diagnosis was made.
</p>
</dd>
<dt><code>delay</code></dt><dd>
<p>The time delay (in months) between diagnosis and reporting. 0 means that the
case was reported within one month.  Longer delays are grouped in 3 month
intervals and the value of <code>delay</code> is the midpoint of the interval (therefore
a value of <code>2</code> indicates that reporting was delayed for between 1 and 3 
months).
</p>
</dd>
<dt><code>dud</code></dt><dd>
<p>An indicator of censoring. These are categories for which full information is
not yet available and the number recorded is a lower bound only.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>The time interval of the diagnosis. That is the number of quarters from July
1983 until the end of the quarter in which these cases were diagnosed.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>The number of AIDS cases reported.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>De Angelis, D. and Gilks, W.R. (1994) Estimating acquired immune
deficiency syndrome accounting for reporting delay.
<em>Journal of the Royal Statistical Society, A</em>, <b>157</b>, 31&ndash;40.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997)
<em>Bootstrap Methods and Their Application</em>.
Cambridge University Press.
</p>

<hr>
<h2 id='aircondit'>
Failures of Air-conditioning Equipment
</h2><span id='topic+aircondit'></span><span id='topic+aircondit7'></span>

<h3>Description</h3>

<p>Proschan (1963) reported on the times between failures of the air-conditioning
equipment in 10 Boeing 720 aircraft. The <code>aircondit</code> data frame contains 
the intervals for the ninth aircraft while <code>aircondit7</code> contains those for the
seventh aircraft. 
</p>
<p>Both data frames have just one column.  Note that the data have been sorted 
into increasing order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aircondit
</code></pre>


<h3>Format</h3>

<p>The data frames contain the following column:
</p>

<dl>
<dt><code>hours</code></dt><dd>
<p>The time interval in hours between successive failures of the air-conditioning
equipment
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were taken from
</p>
<p>Cox, D.R. and Snell, E.J. (1981) 
<em>Applied Statistics: Principles and Examples</em>. Chapman and Hall.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Proschan, F. (1963) Theoretical explanation of observed decreasing failure 
rate. <em>Technometrics</em>, <b>5</b>, 375-383.
</p>

<hr>
<h2 id='amis'>
Car Speeding and Warning Signs
</h2><span id='topic+amis'></span>

<h3>Description</h3>

<p>The <code>amis</code> data frame has 8437 rows and 4 columns.
</p>
<p>In a study into the effect that warning signs have on speeding patterns, 
Cambridgeshire County Council considered 14 pairs of locations.
The locations were paired to account for factors such as traffic volume
and type of road.  One site in each pair had a sign erected warning of the
dangers of speeding and asking drivers to slow down.  No action was taken at
the second site.  Three sets of measurements were taken at each site.  Each set
of measurements was nominally of the speeds of 100 cars but not all sites have
exactly 100 measurements. These speed measurements were taken before the 
erection of the sign, shortly after the erection of the sign, and again after 
the sign had been in place for some time.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amis
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>speed</code></dt><dd>
<p>Speeds of cars (in miles per hour).
</p>
</dd>
<dt><code>period</code></dt><dd>
<p>A numeric column indicating the time that the reading was taken.
A value of 1 indicates a reading taken before the sign was erected, 
a 2 indicates a reading
taken shortly after erection of the sign and a 3 indicates a reading taken 
after the sign had been in place for some time.
</p>
</dd>
<dt><code>warning</code></dt><dd>
<p>A numeric column indicating whether the location of the reading was chosen to
have a warning sign erected. A value of 1 indicates presence of a sign and a
value of 2 indicates that no sign was erected.
</p>
</dd>
<dt><code>pair</code></dt><dd>
<p>A numeric column giving the pair number at which the reading was taken. Pairs
were numbered from 1 to 14.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were kindly made available by Mr. Graham Amis, Cambridgeshire County
Council, U.K.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='aml'>
Remission Times for Acute Myelogenous Leukaemia
</h2><span id='topic+aml'></span>

<h3>Description</h3>

<p>The <code>aml</code> data frame has 23 rows and 3 columns.
</p>
<p>A clinical trial to evaluate the efficacy of maintenance chemotherapy for
acute myelogenous leukaemia was 
conducted by Embury et al. (1977) at Stanford University.  After reaching a
stage of remission through treatment by chemotherapy, patients were randomized
into two groups. The first group received maintenance chemotherapy and the 
second group did not.  The aim of the study was to see if maintenance 
chemotherapy increased the length of the remission.  The data here formed a
preliminary analysis which was conducted in October 1974.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aml
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>time</code></dt><dd>
<p>The length of the complete remission (in weeks).
</p>
</dd>
<dt><code>cens</code></dt><dd>
<p>An indicator of right censoring.  1 indicates that the patient had a relapse
and so <code>time</code> is the length of the remission. 0 indicates that the patient
had left the study or was still in remission in October 1974, that is the
length of remission is right-censored.
</p>
</dd>
<dt><code>group</code></dt><dd>
<p>The group into which the patient was randomized.  Group 1 received
maintenance chemotherapy, group 2 did not.
</p>
</dd></dl>


<h3>Note</h3>

<p>Package <span class="pkg">survival</span> also has a dataset <code>aml</code>. It is the same
data with different names and with <code>group</code> replaced by a factor
<code>x</code>.
</p>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Miller, R.G. (1981) <em>Survival Analysis</em>. John Wiley.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Embury, S.H, Elias, L., Heller, P.H., Hood, C.E., Greenberg, P.L. and
Schrier, S.L. (1977) Remission maintenance therapy in  acute myelogenous
leukaemia. <em>Western Journal of Medicine</em>, <b>126</b>, 267-272.
</p>

<hr>
<h2 id='beaver'>
Beaver Body Temperature Data
</h2><span id='topic+beaver'></span>

<h3>Description</h3>

<p>The <code>beaver</code> data frame has 100 rows and 4 columns.  It is a multivariate
time series of class <code>"ts"</code> and also inherits from class <code>"data.frame"</code>.
</p>
<p>This data set is part of a long study into body temperature regulation in
beavers.  Four adult female beavers were live-trapped and had a 
temperature-sensitive radio transmitter surgically implanted.  Readings were
taken every 10 minutes.  The location of the beaver was also recorded and
her activity level was dichotomized by whether she was in the retreat or 
outside of it since high-intensity activities only occur outside of the 
retreat.
</p>
<p>The data in this data frame are those readings for one of the beavers on a day
in autumn.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beaver
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>day</code></dt><dd>
<p>The day number.  The data includes only data from day 307 and early 308.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>The time of day formatted as hour-minute.
</p>
</dd>
<dt><code>temp</code></dt><dd>
<p>The body temperature in degrees Celsius.
</p>
</dd>
<dt><code>activ</code></dt><dd>
<p>The dichotomized activity indicator. <code>1</code> indicates that the beaver is outside
of the retreat and therefore engaged in high-intensity activity.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Reynolds, P.S. (1994) Time-series analyses of beaver body temperatures.
In <em>Case Studies in Biometry</em>. N. Lange, L. Ryan, L. Billard, 
D. Brillinger, L. Conquest and J. Greenhouse (editors), 211&ndash;228. John Wiley.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='bigcity'>
Population of U.S. Cities
</h2><span id='topic+bigcity'></span><span id='topic+city'></span>

<h3>Description</h3>

<p>The <code>bigcity</code> data frame has 49 rows and 2 columns. 
</p>
<p>The <code>city</code> data frame has 10 rows and 2 columns.  
</p>
<p>The measurements are the
population (in 1000's) of 49 U.S. cities in 1920 and 1930.  The 49 cities are 
a random sample taken from the 196 largest cities in 1920.  The <code>city</code> data 
frame consists of the first 10 observations in <code>bigcity</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigcity
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>u</code></dt><dd>
<p>The 1920 population.
</p>
</dd>
<dt><code>x</code></dt><dd>
<p>The 1930 population.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Cochran, W.G. (1977) <em>Sampling Techniques</em>. Third edition. John Wiley
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='boot'>
Bootstrap Resampling
</h2><span id='topic+boot'></span><span id='topic+boot.return'></span><span id='topic+c.boot'></span>

<h3>Description</h3>

<p>Generate <code>R</code> bootstrap replicates of a statistic applied to data.  Both
parametric and nonparametric resampling are possible.  For the nonparametric
bootstrap, possible resampling methods are the ordinary bootstrap, the 
balanced bootstrap, antithetic resampling, and permutation.
For nonparametric multi-sample problems stratified resampling is used:
this is specified by including a vector of strata in the call to boot.
Importance resampling weights may be specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot(data, statistic, R, sim = "ordinary", stype = c("i", "f", "w"), 
     strata = rep(1,n), L = NULL, m = 0, weights = NULL, 
     ran.gen = function(d, p) d, mle = NULL, simple = FALSE, ...,
     parallel = c("no", "multicore", "snow"),
     ncpus = getOption("boot.ncpus", 1L), cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot_+3A_data">data</code></td>
<td>

<p>The data as a vector, matrix or data frame.  If it is a matrix or
data frame then each row is considered as one multivariate
observation.
</p>
</td></tr>
<tr><td><code id="boot_+3A_statistic">statistic</code></td>
<td>

<p>A function which when applied to data returns a vector containing
the statistic(s) of interest.  When <code>sim = "parametric"</code>, the
first argument to <code>statistic</code> must be the data.  For each
replicate a simulated dataset returned by <code>ran.gen</code> will be
passed.  In all other cases <code>statistic</code> must take at least two
arguments.  The first argument passed will always be the original
data.  The second will be a vector of indices, frequencies or weights
which define the bootstrap sample.  Further, if predictions are
required, then a third argument is required which would be a vector
of the random indices used to generate the bootstrap predictions.
Any further arguments can be passed to <code>statistic</code> through the
<code>...</code> argument.
</p>
</td></tr>
<tr><td><code id="boot_+3A_r">R</code></td>
<td>

<p>The number of bootstrap replicates.  Usually this will be a single
positive integer.  For importance resampling, some resamples may use
one set of weights and others use a different set of weights.  In
this case <code>R</code> would be a vector of integers where each
component gives the number of resamples from each of the rows of
weights.
</p>
</td></tr>
<tr><td><code id="boot_+3A_sim">sim</code></td>
<td>

<p>A character string indicating the type of simulation required.
Possible values are <code>"ordinary"</code> (the default),
<code>"parametric"</code>, <code>"balanced"</code>, <code>"permutation"</code>, or
<code>"antithetic"</code>.  Importance resampling is specified by
including importance weights; the type of importance resampling must
still be specified but may only be <code>"ordinary"</code> or
<code>"balanced"</code> in this case.
</p>
</td></tr>
<tr><td><code id="boot_+3A_stype">stype</code></td>
<td>

<p>A character string indicating what the second argument of <code>statistic</code>
represents.  Possible values of stype are <code>"i"</code> (indices - the
default), <code>"f"</code> (frequencies), or <code>"w"</code> (weights).  Not
used for <code>sim = "parametric"</code>.
</p>
</td></tr>
<tr><td><code id="boot_+3A_strata">strata</code></td>
<td>

<p>An integer vector or factor specifying the strata for multi-sample
problems.  This may be specified for any simulation, but is ignored
when <code>sim = "parametric"</code>.  When <code>strata</code> is
supplied for a nonparametric bootstrap, the simulations are done
within the specified strata.
</p>
</td></tr>
<tr><td><code id="boot_+3A_l">L</code></td>
<td>

<p>Vector of influence values evaluated at the observations.  This is
used only when <code>sim</code> is <code>"antithetic"</code>.  If not supplied,
they are calculated through a call to <code>empinf</code>.  This will use
the infinitesimal jackknife provided that <code>stype</code> is
<code>"w"</code>, otherwise the usual jackknife is used.
</p>
</td></tr>
<tr><td><code id="boot_+3A_m">m</code></td>
<td>

<p>The number of predictions which are to be made at each bootstrap
replicate.  This is most useful for (generalized) linear models.
This can only be used when <code>sim</code> is <code>"ordinary"</code>.
<code>m</code> will usually be a single integer but, if there are strata,
it may be a vector with length equal to the number of strata,
specifying how many of the errors for prediction should come from
each strata.  The actual predictions should be returned as the final
part of the output of <code>statistic</code>, which should also take an
argument giving the vector of indices of the errors to be used for
the predictions.
</p>
</td></tr>
<tr><td><code id="boot_+3A_weights">weights</code></td>
<td>

<p>Vector or matrix of importance weights.  If a vector then it should
have as many elements as there are observations in <code>data</code>.
When simulation from more than one set of weights is required,
<code>weights</code> should be a matrix where each row of the matrix is
one set of importance weights.  If <code>weights</code> is a matrix then
<code>R</code> must be a vector of length <code>nrow(weights)</code>.  This
parameter is ignored if <code>sim</code> is not <code>"ordinary"</code> or
<code>"balanced"</code>.
</p>
</td></tr>
<tr><td><code id="boot_+3A_ran.gen">ran.gen</code></td>
<td>

<p>This function is used only when <code>sim = "parametric"</code>
when it describes how random values are to be generated.  It should
be a function of two arguments.  The first argument should be the
observed data and the second argument consists of any other
information needed (e.g. parameter estimates).  The second argument
may be a list, allowing any number of items to be passed to
<code>ran.gen</code>.  The returned value should be a simulated data set
of the same form as the observed data which will be passed to
<code>statistic</code> to get a bootstrap replicate.  It is important that the
returned value be of the same shape and type as the original
dataset.  If <code>ran.gen</code> is not specified, the default is a
function which returns the original <code>data</code> in which case all
simulation should be included as part of <code>statistic</code>.  Use of
<code>sim = "parametric"</code> with a suitable <code>ran.gen</code> allows the
user to implement any types of nonparametric resampling which are
not supported directly.
</p>
</td></tr>
<tr><td><code id="boot_+3A_mle">mle</code></td>
<td>

<p>The second argument to be passed to <code>ran.gen</code>.  Typically these
will be maximum likelihood estimates of the parameters.  For
efficiency <code>mle</code> is often a list containing all of the objects
needed by <code>ran.gen</code> which can be calculated using the original
data set only.
</p>
</td></tr>
<tr><td><code id="boot_+3A_simple">simple</code></td>
<td>
<p>logical, only allowed to be <code>TRUE</code> for
<code>sim = "ordinary", stype = "i", n = 0</code> (otherwise ignored with a
warning).  By default a <code>n</code> by <code>R</code> index array is created:
this can be large and if <code>simple = TRUE</code> this is avoided by
sampling separately for each replication, which is slower but uses
less memory.
</p>
</td></tr>
<tr><td><code id="boot_+3A_...">...</code></td>
<td>

<p>Other named arguments for <code>statistic</code> which are passed
unchanged each time it is called.  Any such arguments to
<code>statistic</code> should follow the arguments which <code>statistic</code> is
required to have for the simulation.  Beware of partial matching to
arguments of <code>boot</code> listed above, and that arguments named
<code>X</code> and <code>FUN</code> cause conflicts in some versions of
<span class="pkg">boot</span> (but not this one).
</p>
</td></tr>
<tr><td><code id="boot_+3A_parallel">parallel</code></td>
<td>

<p>The type of parallel operation to be used (if any).  If missing, the
default is taken from the option <code>"boot.parallel"</code> (and if that
is not set, <code>"no"</code>).
</p>
</td></tr>
<tr><td><code id="boot_+3A_ncpus">ncpus</code></td>
<td>

<p>integer: number of processes to be used in parallel operation:
typically one would chose this to the number of available CPUs.
</p>
</td></tr>
<tr><td><code id="boot_+3A_cl">cl</code></td>
<td>

<p>An optional <span class="pkg">parallel</span> or <span class="pkg">snow</span> cluster for use if
<code>parallel = "snow"</code>.  If not supplied, a cluster on the
local machine is created for the duration of the <code>boot</code> call.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The statistic to be bootstrapped can be as simple or complicated as
desired as long as its arguments correspond to the dataset and (for
a nonparametric bootstrap) a vector of indices, frequencies or
weights.  <code>statistic</code> is treated as a black box by the
<code>boot</code> function and is not checked to ensure that these
conditions are met.
</p>
<p>The first order balanced bootstrap is described in Davison, Hinkley
and Schechtman (1986).  The antithetic bootstrap is described by
Hall (1989) and is experimental, particularly when used with strata.
The other non-parametric simulation types are the ordinary bootstrap
(possibly with unequal probabilities), and permutation which returns
random permutations of cases. All of these methods work
independently within strata if that argument is supplied.
</p>
<p>For the parametric bootstrap it is necessary for the user to specify
how the resampling is to be conducted.  The best way of
accomplishing this is to specify the function <code>ran.gen</code> which
will return a simulated data set from the observed data set and a
set of parameter estimates specified in <code>mle</code>.
</p>


<h3>Value</h3>

<p>The returned value is an object of class <code>"boot"</code>, containing the
following components:
</p>
<table>
<tr><td><code>t0</code></td>
<td>

<p>The observed value of <code>statistic</code> applied to <code>data</code>. 
</p>
</td></tr>
<tr><td><code>t</code></td>
<td>

<p>A matrix with <code>sum(R)</code> rows each of which is a bootstrap replicate
of the result of calling <code>statistic</code>.
</p>
</td></tr>
<tr><td><code>R</code></td>
<td>

<p>The value of <code>R</code> as passed to <code>boot</code>.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>The <code>data</code> as passed to <code>boot</code>.
</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>

<p>The value of <code>.Random.seed</code> when <code>boot</code> started work.  
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>

<p>The function <code>statistic</code> as passed to <code>boot</code>.
</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>

<p>Simulation type used.
</p>
</td></tr>
<tr><td><code>stype</code></td>
<td>

<p>Statistic type as passed to <code>boot</code>.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The original call to <code>boot</code>.
</p>
</td></tr>
<tr><td><code>strata</code></td>
<td>

<p>The strata used.  This is the vector passed to <code>boot</code>, if it
was supplied or a vector of ones if there were no strata.  It is not
returned if <code>sim</code> is <code>"parametric"</code>.
</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>

<p>The importance sampling weights as passed to <code>boot</code> or the empirical 
distribution function weights if no importance sampling weights were
specified.  It is omitted if <code>sim</code> is not one of
<code>"ordinary"</code> or <code>"balanced"</code>.
</p>
</td></tr>
<tr><td><code>pred.i</code></td>
<td>

<p>If predictions are required (<code>m &gt; 0</code>) this is the matrix of
indices at which predictions were calculated as they were passed to
statistic.  Omitted if <code>m</code> is <code>0</code> or <code>sim</code> is not
<code>"ordinary"</code>. 
</p>
</td></tr>
<tr><td><code>L</code></td>
<td>

<p>The influence values used when <code>sim</code> is <code>"antithetic"</code>.
If no such values were specified and <code>stype</code> is not <code>"w"</code>
then <code>L</code> is returned as consecutive integers corresponding to
the assumption that data is ordered by influence values. This
component is omitted when <code>sim</code> is not <code>"antithetic"</code>.
</p>
</td></tr>
<tr><td><code>ran.gen</code></td>
<td>

<p>The random generator function used if <code>sim</code> is
<code>"parametric"</code>. This component is omitted for any other value
of <code>sim</code>.
</p>
</td></tr>
<tr><td><code>mle</code></td>
<td>

<p>The parameter estimates passed to <code>boot</code> when <code>sim</code> is
<code>"parametric"</code>.  It is omitted for all other values of
<code>sim</code>.
</p>
</td></tr>
</table>
<p>There are <code>c</code>, <code>plot</code> and <code>print</code> methods for this class.
</p>


<h3>Parallel operation</h3>

<p>When <code>parallel = "multicore"</code> is used (not available on Windows),
each worker process inherits the environment of the current session,
including the workspace and the loaded namespaces and attached
packages (but not the random number seed: see below).
</p>
<p>More work is needed when <code>parallel = "snow"</code> is used: the worker
processes are newly created <span class="rlang"><b>R</b></span> processes, and <code>statistic</code> needs
to arrange to set up the environment it needs: often a good way to do
that is to make use of lexical scoping since when <code>statistic</code> is
sent to the worker processes its enclosing environment is also sent.
(E.g. see the example for <code><a href="#topic+jack.after.boot">jack.after.boot</a></code> where
ancillary functions are nested inside the <code>statistic</code> function.)
<code>parallel = "snow"</code> is primarily intended to be used on
multi-core Windows machine where <code>parallel = "multicore"</code> is not
available.
</p>
<p>For most of the <code>boot</code> methods the resampling is done in the
master process, but not if <code>simple = TRUE</code> nor <code>sim =
  "parametric"</code>.  In those cases (or where <code>statistic</code> itself uses
random numbers), more care is needed if the results need to be
reproducible.  Resampling is done in the worker processes by
<code><a href="#topic+censboot">censboot</a>(sim = "wierd")</code> and by most of the schemes in
<code><a href="#topic+tsboot">tsboot</a></code> (the exceptions being <code>sim == "fixed"</code> and
<code>sim == "geom"</code> with the default <code>ran.gen</code>).
</p>
<p>Where random-number generation is done in the worker processes, the
default behaviour is that each worker chooses a separate seed,
non-reproducibly.  However, with <code>parallel = "multicore"</code> or
<code>parallel = "snow"</code> using the default cluster, a second approach
is used if <code><a href="base.html#topic+RNGkind">RNGkind</a>("L'Ecuyer-CMRG")</code> has been selected.
In that approach each worker gets a different subsequence of the RNG
stream based on the seed at the time the worker is spawned and so the
results will be reproducible if <code>ncpus</code> is unchanged, and for
<code>parallel = "multicore"</code> if <code>parallel::<a href="parallel.html#topic+mc.reset.stream">mc.reset.stream</a>()</code> is
called: see the examples for <code><a href="parallel.html#topic+mclapply">mclapply</a></code>.
</p>
<p>Note that loading the <span class="pkg">parallel</span> namespace may change the random
seed, so for maximum reproducibility this should be done before
calling this function.
</p>


<h3>References</h3>

<p>There are many references explaining the bootstrap and its variations.
Among them are :
</p>
<p>Booth, J.G., Hall, P. and Wood, A.T.A. (1993) Balanced importance resampling 
for the bootstrap. <em>Annals of Statistics</em>, <b>21</b>, 286&ndash;298.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Davison, A.C., Hinkley, D.V. and Schechtman, E. (1986) Efficient bootstrap 
simulation. <em>Biometrika</em>, <b>73</b>, 555&ndash;566.
</p>
<p>Efron, B. and Tibshirani, R. (1993) <em>An Introduction to the Bootstrap</em>.
Chapman &amp; Hall.
</p>
<p>Gleason, J.R. (1988) Algorithms for balanced bootstrap simulations.
<em> American Statistician</em>, <b>42</b>, 263&ndash;266.
</p>
<p>Hall, P. (1989) Antithetic resampling for the bootstrap. <em>Biometrika</em>,
<b>73</b>, 713&ndash;724.
</p>
<p>Hinkley, D.V. (1988) Bootstrap methods (with Discussion). 
<em>Journal of the  Royal Statistical Society, B</em>, <b>50</b>,
312&ndash;337, 355&ndash;370.
</p>
<p>Hinkley, D.V. and Shi, S. (1989) Importance sampling and the nested bootstrap.
<em>Biometrika</em>, <b>76</b>, 435&ndash;446.
</p>
<p>Johns M.V. (1988) Importance sampling for bootstrap confidence intervals.
<em>Journal of the American Statistical Association</em>, <b>83</b>, 709&ndash;714.
</p>
<p>Noreen, E.W. (1989) <em>Computer Intensive Methods for Testing Hypotheses</em>. 
John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.array">boot.array</a></code>, <code><a href="#topic+boot.ci">boot.ci</a></code>,
<code><a href="#topic+censboot">censboot</a></code>, <code><a href="#topic+empinf">empinf</a></code>,
<code><a href="#topic+jack.after.boot">jack.after.boot</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code>,
<code><a href="#topic+tsboot">tsboot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Usual bootstrap of the ratio of means using the city data
ratio &lt;- function(d, w) sum(d$x * w)/sum(d$u * w)
boot(city, ratio, R = 999, stype = "w")


# Stratified resampling for the difference of means.  In this
# example we will look at the difference of means between the final
# two series in the gravity data.
diff.means &lt;- function(d, f)
{    n &lt;- nrow(d)
     gp1 &lt;- 1:table(as.numeric(d$series))[1]
     m1 &lt;- sum(d[gp1,1] * f[gp1])/sum(f[gp1])
     m2 &lt;- sum(d[-gp1,1] * f[-gp1])/sum(f[-gp1])
     ss1 &lt;- sum(d[gp1,1]^2 * f[gp1]) - (m1 *  m1 * sum(f[gp1]))
     ss2 &lt;- sum(d[-gp1,1]^2 * f[-gp1]) - (m2 *  m2 * sum(f[-gp1]))
     c(m1 - m2, (ss1 + ss2)/(sum(f) - 2))
}
grav1 &lt;- gravity[as.numeric(gravity[,2]) &gt;= 7,]
boot(grav1, diff.means, R = 999, stype = "f", strata = grav1[,2])

# In this example we show the use of boot in a prediction from
# regression based on the nuclear data.  This example is taken
# from Example 6.8 of Davison and Hinkley (1997).  Notice also
# that two extra arguments to 'statistic' are passed through boot.
nuke &lt;- nuclear[, c(1, 2, 5, 7, 8, 10, 11)]
nuke.lm &lt;- glm(log(cost) ~ date+log(cap)+ne+ct+log(cum.n)+pt, data = nuke)
nuke.diag &lt;- glm.diag(nuke.lm)
nuke.res &lt;- nuke.diag$res * nuke.diag$sd
nuke.res &lt;- nuke.res - mean(nuke.res)

# We set up a new data frame with the data, the standardized 
# residuals and the fitted values for use in the bootstrap.
nuke.data &lt;- data.frame(nuke, resid = nuke.res, fit = fitted(nuke.lm))

# Now we want a prediction of plant number 32 but at date 73.00
new.data &lt;- data.frame(cost = 1, date = 73.00, cap = 886, ne = 0,
                       ct = 0, cum.n = 11, pt = 1)
new.fit &lt;- predict(nuke.lm, new.data)

nuke.fun &lt;- function(dat, inds, i.pred, fit.pred, x.pred)
{
     lm.b &lt;- glm(fit+resid[inds] ~ date+log(cap)+ne+ct+log(cum.n)+pt,
                 data = dat)
     pred.b &lt;- predict(lm.b, x.pred)
     c(coef(lm.b), pred.b - (fit.pred + dat$resid[i.pred]))
}

nuke.boot &lt;- boot(nuke.data, nuke.fun, R = 999, m = 1, 
                  fit.pred = new.fit, x.pred = new.data)
# The bootstrap prediction squared error would then be found by
mean(nuke.boot$t[, 8]^2)
# Basic bootstrap prediction limits would be
new.fit - sort(nuke.boot$t[, 8])[c(975, 25)]


# Finally a parametric bootstrap.  For this example we shall look 
# at the air-conditioning data.  In this example our aim is to test 
# the hypothesis that the true value of the index is 1 (i.e. that 
# the data come from an exponential distribution) against the 
# alternative that the data come from a gamma distribution with
# index not equal to 1.
air.fun &lt;- function(data) {
     ybar &lt;- mean(data$hours)
     para &lt;- c(log(ybar), mean(log(data$hours)))
     ll &lt;- function(k) {
          if (k &lt;= 0) 1e200 else lgamma(k)-k*(log(k)-1-para[1]+para[2])
     }
     khat &lt;- nlm(ll, ybar^2/var(data$hours))$estimate
     c(ybar, khat)
}

air.rg &lt;- function(data, mle) {
    # Function to generate random exponential variates.
    # mle will contain the mean of the original data
    out &lt;- data
    out$hours &lt;- rexp(nrow(out), 1/mle)
    out
}

air.boot &lt;- boot(aircondit, air.fun, R = 999, sim = "parametric",
                 ran.gen = air.rg, mle = mean(aircondit$hours))

# The bootstrap p-value can then be approximated by
sum(abs(air.boot$t[,2]-1) &gt; abs(air.boot$t0[2]-1))/(1+air.boot$R)

</code></pre>

<hr>
<h2 id='boot-practicals'> Functions for Bootstrap Practicals</h2><span id='topic+nested.corr'></span><span id='topic+lik.CI'></span>

<h3>Description</h3>

<p>Functions for use with the practicals in Davison and Hinkley (1997).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nested.corr(data, w, t0, M)
lik.CI(like, lim)
</code></pre>


<h3>Details</h3>

<p><code>nested.corr</code> is meant for use with the double bootstrap
in practical 5.5 of Davison and Hinkley (1997).
</p>
<p><code>lik.CI</code> is meant for use with practicals 10.1 and 10.2 of
Davison and Hinkley (1997). 
</p>


<h3>Author(s)</h3>

<p>Angelo J. Canty.  Faster version of <code>nested.corr</code> for
<span class="pkg">boot</span> 1.3-1 by Brian Ripley.
</p>


<h3>References</h3>

 
<p>Davison, A. C. and Hinkley, D. V. (1997)
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='boot.array'>
Bootstrap Resampling Arrays
</h2><span id='topic+boot.array'></span>

<h3>Description</h3>

<p>This function takes a bootstrap object calculated by one of the
functions <code>boot</code>, <code>censboot</code>, or <code>tilt.boot</code> and
returns the frequency (or index) array for the bootstrap
resamples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.array(boot.out, indices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.array_+3A_boot.out">boot.out</code></td>
<td>

<p>An object of class <code>"boot"</code> returned by one of the generation
functions for such an object.
</p>
</td></tr>
<tr><td><code id="boot.array_+3A_indices">indices</code></td>
<td>

<p>A logical argument which specifies whether to return the frequency
array or the raw index array.  The default is <code>indices=FALSE</code>
unless <code>boot.out</code> was created by <code>tsboot</code> in which case the
default is <code>indices=TRUE</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The process by which the original index array was generated is
repeated with the same value of <code>.Random.seed</code>.  If the frequency
array is required then <code>freq.array</code> is called to convert the
index array to a frequency array.
</p>
<p>A resampling array can only be returned when such a concept makes
sense.  In particular it cannot be found for any parametric or
model-based resampling schemes.  Hence for objects generated by
<code>censboot</code> the only resampling scheme for which such an array can
be found is ordinary case resampling. Similarly if <code>boot.out$sim</code>
is <code>"parametric"</code> in the case of <code>boot</code> or <code>"model"</code> in
the case of <code>tsboot</code> the array cannot be found.  Note also that
for post-blackened bootstraps from <code>tsboot</code> the indices found
will relate to those prior to any post-blackening and so will not be
useful.
</p>
<p>Frequency arrays are used in many post-bootstrap calculations such as
the jackknife-after-bootstrap and finding importance sampling weights.
They are also used to find empirical influence values through the
regression method.
</p>


<h3>Value</h3>

<p>A matrix with <code>boot.out$R</code> rows and <code>n</code> columns where
<code>n</code> is the number of observations in <code>boot.out$data</code>.  If
<code>indices</code> is <code>FALSE</code> then this will give the frequency of
each of the original observations in each bootstrap resample. If
<code>indices</code> is <code>TRUE</code> it will give the indices of the
bootstrap resamples in the order in which they would have been passed
to the statistic.
</p>


<h3>Side Effects</h3>

<p>This function temporarily resets <code>.Random.seed</code> to the value in
<code>boot.out$seed</code> and then returns it to its original value at the
end of the function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+censboot">censboot</a></code>, <code><a href="#topic+freq.array">freq.array</a></code>,
<code><a href="#topic+tilt.boot">tilt.boot</a></code>, <code><a href="#topic+tsboot">tsboot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  A frequency array for a nonparametric bootstrap
city.boot &lt;- boot(city, corr, R = 40, stype = "w")
boot.array(city.boot)

perm.cor &lt;- function(d,i) cor(d$x,d$u[i])
city.perm &lt;- boot(city, perm.cor, R = 40, sim = "permutation")
boot.array(city.perm, indices = TRUE)
</code></pre>

<hr>
<h2 id='boot.ci'>
Nonparametric Bootstrap Confidence Intervals
</h2><span id='topic+boot.ci'></span>

<h3>Description</h3>

<p>This function generates 5 different types of equi-tailed two-sided
nonparametric confidence intervals.  These are the first order normal 
approximation, the basic bootstrap interval, the studentized bootstrap 
interval, the bootstrap percentile interval, and the adjusted bootstrap 
percentile (BCa) interval.  All or a subset of these intervals can be 
generated.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.ci(boot.out, conf = 0.95, type = "all", 
        index = 1:min(2,length(boot.out$t0)), var.t0 = NULL, 
        var.t = NULL, t0 = NULL, t = NULL, L = NULL,
        h = function(t) t, hdot = function(t) rep(1,length(t)),
        hinv = function(t) t, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.ci_+3A_boot.out">boot.out</code></td>
<td>

<p>An object of class <code>"boot"</code> containing the output of a bootstrap
calculation.  
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_conf">conf</code></td>
<td>

<p>A scalar or vector containing the confidence level(s) of the required
interval(s).
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_type">type</code></td>
<td>

<p>A vector of character strings representing the type of intervals
required. The value should be any subset of the values
<code>c("norm","basic", "stud", "perc", "bca")</code> or simply <code>"all"</code>
which will compute all five types of intervals.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_index">index</code></td>
<td>

<p>This should be a vector of length 1 or 2.  The first element of
<code>index</code> indicates the position of the variable of interest in
<code>boot.out$t0</code> and the relevant column in <code>boot.out$t</code>.  The
second element indicates the position of the variance of the variable of
interest.  If both <code>var.t0</code> and <code>var.t</code> are supplied then the
second element of <code>index</code> (if present) is ignored.  The default is
that the variable of interest is in position 1 and its variance is in
position 2 (as long as there are 2 positions in <code>boot.out$t0</code>).
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_var.t0">var.t0</code></td>
<td>

<p>If supplied, a value to be used as an estimate of the variance of
the statistic for the normal approximation and studentized intervals.
If it is not supplied and <code>length(index)</code> is 2 then <code>var.t0</code>
defaults to <code>boot.out$t0[index[2]]</code> otherwise <code>var.t0</code> is
undefined.  For studentized intervals <code>var.t0</code> must be defined.
For the normal approximation, if <code>var.t0</code> is undefined it defaults
to <code>var(t)</code>.  If a transformation is supplied through the argument
<code>h</code> then <code>var.t0</code> should be the variance of the untransformed
statistic.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_var.t">var.t</code></td>
<td>

<p>This is a vector (of length <code>boot.out$R</code>) of variances of the
bootstrap replicates of the variable of interest.  It is used only for
studentized intervals.  If it is not supplied and <code>length(index)</code>
is 2 then <code>var.t</code> defaults to <code>boot.out$t[,index[2]]</code>,
otherwise its value is undefined which will cause an error for
studentized intervals.  If a transformation is supplied through the
argument <code>h</code> then <code>var.t</code> should be the variance of the
untransformed bootstrap statistics.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_t0">t0</code></td>
<td>

<p>The observed value of the statistic of interest.  The default value
is <code>boot.out$t0[index[1]]</code>.  Specification of <code>t0</code> and
<code>t</code> allows the user to get intervals for a transformed statistic
which may not be in the bootstrap output object.  See the second example
below.  An alternative way of achieving this would be to supply the
functions <code>h</code>, <code>hdot</code>, and <code>hinv</code> below.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_t">t</code></td>
<td>

<p>The bootstrap replicates of the statistic of interest.  It must be a
vector of length <code>boot.out$R</code>.  It is an error to supply one of
<code>t0</code> or <code>t</code> but not the other.  Also if studentized
intervals are required and <code>t0</code> and <code>t</code> are supplied then
so should be <code>var.t0</code> and <code>var.t</code>.  The default value is
<code>boot.out$t[,index]</code>.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_l">L</code></td>
<td>

<p>The empirical influence values of the statistic of interest for the
observed data.  These are used only for BCa intervals.  If a
transformation is supplied through the parameter <code>h</code> then
<code>L</code> should be the influence values for <code>t</code>; the values for
<code>h(t)</code> are derived from these and <code>hdot</code> within the
function. If <code>L</code> is not supplied then the values are calculated
using <code>empinf</code> if they are needed.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_h">h</code></td>
<td>

<p>A function defining a transformation.  The intervals are calculated
on the scale of <code>h(t)</code> and the inverse function <code>hinv</code>
applied to the resulting intervals.  It must be a function of one
variable only and for a vector argument, it must return a vector of
the same length, i.e. <code>h(c(t1,t2,t3))</code> should return
<code>c(h(t1),h(t2),h(t3))</code>. The default is the identity function.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_hdot">hdot</code></td>
<td>

<p>A function of one argument returning the derivative of <code>h</code>.  It
is a required argument if <code>h</code> is supplied and normal,
studentized or BCa intervals are required.  The function is used for
approximating the variances of <code>h(t0)</code> and <code>h(t)</code> using
the delta method, and also for finding the empirical influence
values for BCa intervals.  Like <code>h</code> it should be able to take a
vector argument and return a vector of the same length.  The default
is the constant function 1.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_hinv">hinv</code></td>
<td>

<p>A function, like <code>h</code>, which returns the inverse of <code>h</code>.
It is used to transform the intervals calculated on the scale of
<code>h(t)</code> back to the original scale. The default is the identity
function.  If <code>h</code> is supplied but <code>hinv</code> is not, then the
intervals returned will be on the transformed scale.
</p>
</td></tr>
<tr><td><code id="boot.ci_+3A_...">...</code></td>
<td>

<p>Any extra arguments that <code>boot.out$statistic</code> is
expecting. These arguments are needed only if BCa intervals are required
and <code>L</code> is not supplied since in that case <code>L</code> is calculated
through a call to <code>empinf</code> which calls <code>boot.out$statistic</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formulae on which the calculations are based can be found in
Chapter 5 of Davison and Hinkley (1997).  Function <code>boot</code> must be
run prior to running this function to create the object to be passed as
<code>boot.out</code>.
</p>
<p>Variance estimates are required for studentized intervals.  The variance
of the observed statistic is optional for normal theory intervals.  If
it is not supplied then the bootstrap estimate of variance is used.  The
normal intervals also use the bootstrap bias correction.
</p>
<p>Interpolation on the normal quantile scale is used when a non-integer order
statistic is required.  If the order statistic used is the smallest or
largest of the R values in boot.out a warning is generated and such
intervals should not be considered reliable.  
</p>


<h3>Value</h3>

<p>An object of type <code>"bootci"</code> which contains the intervals.
It has components
</p>
<table>
<tr><td><code>R</code></td>
<td>

<p>The number of bootstrap replicates on which the intervals were based.
</p>
</td></tr>
<tr><td><code>t0</code></td>
<td>

<p>The observed value of the statistic on the same scale as the intervals.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The call to <code>boot.ci</code> which generated the object.
</p>
<p>It will also contain one or more of the following components depending
on the value of <code>type</code> used in the call to <code>bootci</code>.
</p>
</td></tr>
<tr><td><code>normal</code></td>
<td>

<p>A matrix of intervals calculated using the normal approximation.  It will
have 3 columns, the first being the level and the other two being the upper
and lower endpoints of the intervals.
</p>
</td></tr>
<tr><td><code>basic</code></td>
<td>

<p>The intervals calculated using the basic bootstrap method.
</p>
</td></tr>
<tr><td><code>student</code></td>
<td>

<p>The intervals calculated using the studentized bootstrap method.
</p>
</td></tr>
<tr><td><code>percent</code></td>
<td>

<p>The intervals calculated using the bootstrap percentile method.
</p>
</td></tr>
<tr><td><code>bca</code></td>
<td>

<p>The intervals calculated using the adjusted bootstrap percentile
(BCa) method.
</p>
<p>These latter four components will be matrices with 5 columns,  the
first column containing the level, the next two containing the
indices of the order statistics used in the calculations and the
final two the calculated endpoints themselves. 
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>, Chapter 5.
Cambridge University Press.
</p>
<p>DiCiccio, T.J. and Efron  B. (1996) Bootstrap confidence intervals (with 
Discussion). <em>Statistical Science</em>, <b>11</b>, 189&ndash;228.
</p>
<p>Efron, B. (1987) Better bootstrap confidence intervals (with Discussion).
<em>Journal of the American Statistical Association</em>, <b>82</b>, 171&ndash;200.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+abc.ci">abc.ci</a></code>, <code><a href="#topic+boot">boot</a></code>,
<code><a href="#topic+empinf">empinf</a></code>, <code><a href="#topic+norm.ci">norm.ci</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># confidence intervals for the city data
ratio &lt;- function(d, w) sum(d$x * w)/sum(d$u * w)
city.boot &lt;- boot(city, ratio, R = 999, stype = "w", sim = "ordinary")
boot.ci(city.boot, conf = c(0.90, 0.95),
        type = c("norm", "basic", "perc", "bca"))

# studentized confidence interval for the two sample 
# difference of means problem using the final two series
# of the gravity data. 
diff.means &lt;- function(d, f)
{    n &lt;- nrow(d)
     gp1 &lt;- 1:table(as.numeric(d$series))[1]
     m1 &lt;- sum(d[gp1,1] * f[gp1])/sum(f[gp1])
     m2 &lt;- sum(d[-gp1,1] * f[-gp1])/sum(f[-gp1])
     ss1 &lt;- sum(d[gp1,1]^2 * f[gp1]) - (m1 *  m1 * sum(f[gp1]))
     ss2 &lt;- sum(d[-gp1,1]^2 * f[-gp1]) - (m2 *  m2 * sum(f[-gp1]))
     c(m1 - m2, (ss1 + ss2)/(sum(f) - 2))
}
grav1 &lt;- gravity[as.numeric(gravity[,2]) &gt;= 7, ]
grav1.boot &lt;- boot(grav1, diff.means, R = 999, stype = "f",
                   strata = grav1[ ,2])
boot.ci(grav1.boot, type = c("stud", "norm"))

# Nonparametric confidence intervals for mean failure time 
# of the air-conditioning data as in Example 5.4 of Davison
# and Hinkley (1997)
mean.fun &lt;- function(d, i) 
{    m &lt;- mean(d$hours[i])
     n &lt;- length(i)
     v &lt;- (n-1)*var(d$hours[i])/n^2
     c(m, v)
}
air.boot &lt;- boot(aircondit, mean.fun, R = 999)
boot.ci(air.boot, type = c("norm", "basic", "perc", "stud"))

# Now using the log transformation
# There are two ways of doing this and they both give the
# same intervals.

# Method 1
boot.ci(air.boot, type = c("norm", "basic", "perc", "stud"), 
        h = log, hdot = function(x) 1/x)

# Method 2
vt0 &lt;- air.boot$t0[2]/air.boot$t0[1]^2
vt &lt;- air.boot$t[, 2]/air.boot$t[ ,1]^2
boot.ci(air.boot, type = c("norm", "basic", "perc", "stud"), 
        t0 = log(air.boot$t0[1]), t = log(air.boot$t[,1]),
        var.t0 = vt0, var.t = vt)
</code></pre>

<hr>
<h2 id='brambles'>
Spatial Location of Bramble Canes
</h2><span id='topic+brambles'></span>

<h3>Description</h3>

<p>The <code>brambles</code> data frame has 823 rows and 3 columns.
</p>
<p>The location of living bramble canes in a 9m square plot was recorded.  
We take 9m to be the unit of distance so that the plot can be thought of
as a unit square. The bramble canes were also classified by their age.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brambles
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>x</code></dt><dd>
<p>The x coordinate of the position of the cane in the plot.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>The y coordinate of the position of the cane in the plot.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>The age classification of the canes; <code>0</code> indicates a newly emerged cane,
<code>1</code> indicates a one year old cane and <code>2</code> indicates a two year old cane.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Diggle, P.J. (1983) <em>Statistical Analysis of Spatial Point Patterns</em>.
Academic Press.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='breslow'>
Smoking Deaths Among Doctors
</h2><span id='topic+breslow'></span>

<h3>Description</h3>

<p>The <code>breslow</code> data frame has 10 rows and 5 columns.
</p>
<p>In 1961 Doll and Hill sent out a questionnaire to all men on the British 
Medical Register enquiring about their smoking habits. Almost 70% of 
such men replied.  Death certificates were obtained for medical practitioners
and causes of death were assigned on the basis of these certificates.  The
<code>breslow</code> data set contains the person-years of observations and deaths from
coronary artery disease accumulated during the first ten years of the study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breslow
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>age</code></dt><dd>
<p>The mid-point of the 10 year age-group for the doctors.
</p>
</dd>
<dt><code>smoke</code></dt><dd>
<p>An indicator of whether the doctors smoked (1) or not (0).
</p>
</dd>
<dt><code>n</code></dt><dd>
<p>The number of person-years in the category.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>The number of deaths attributed to coronary artery disease.
</p>
</dd>
<dt><code>ns</code></dt><dd>
<p>The number of smoker years in the category (<code>smoke*n</code>).
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Breslow, N.E. (1985) Cohort Analysis in Epidemiology. In 
<em>A Celebration of Statistics</em> 
A.C. Atkinson and S.E. Fienberg (editors), 109&ndash;143.
Springer-Verlag.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Doll, R. and Hill, A.B. (1966) Mortality of British doctors in relation to 
smoking: Observations on coronary thrombosis. 
<em>National Cancer Institute Monograph</em>, <b>19</b>, 205-268.
</p>

<hr>
<h2 id='calcium'>
Calcium Uptake Data
</h2><span id='topic+calcium'></span>

<h3>Description</h3>

<p>The <code>calcium</code> data frame has 27 rows and 2 columns.
</p>
<p>Howard Grimes from the Botany Department, North Carolina State University,
conducted an experiment for biochemical analysis of intracellular storage
and transport of calcium across plasma membrane.  Cells were
suspended in a solution of radioactive calcium for a certain length of time and
then the amount of radioactive calcium that was absorbed by the cells was
measured.  The experiment was repeated independently with 9 different
times of suspension each replicated 3 times.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcium
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>time</code></dt><dd>
<p>The time (in minutes) that the cells were suspended in the solution.
</p>
</dd>
<dt><code>cal</code></dt><dd>
<p>The amount of calcium uptake (nmoles/mg).
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Rawlings, J.O. (1988) <em>Applied Regression Analysis</em>. 
Wadsworth and Brooks/Cole Statistics/Probability Series.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='cane'>
Sugar-cane Disease Data
</h2><span id='topic+cane'></span>

<h3>Description</h3>

<p>The <code>cane</code> data frame has 180 rows and 5 columns. 
The data frame represents a randomized
block design with 45 varieties of sugar-cane and 4 blocks.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cane
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>n</code></dt><dd>
<p>The total number of shoots in each plot.
</p>
</dd>
<dt><code>r</code></dt><dd>
<p>The number of diseased shoots.
</p>
</dd>
<dt><code>x</code></dt><dd>
<p>The number of pieces of the stems, out of 50, planted in each plot.
</p>
</dd>
<dt><code>var</code></dt><dd>
<p>A factor indicating the variety of sugar-cane in each plot.
</p>
</dd>
<dt><code>block</code></dt><dd>
<p>A factor for the blocks.
</p>
</dd></dl>



<h3>Details</h3>

<p>The aim of the experiment was to classify the varieties into
resistant, intermediate and susceptible to a disease called &quot;coal of
sugar-cane&quot; (carvao da cana-de-acucar).  This is a disease that is
common in sugar-cane plantations in certain areas of Brazil.
</p>
<p>For each plot, fifty pieces of sugar-cane stem were put in a solution
containing the disease agent and then some were planted in the plot.
After a fixed period of time, the total number of shoots and the number
of diseased shoots were recorded.
</p>


<h3>Source</h3>

<p>The data were kindly supplied by Dr. C.G.B. Demetrio of Escola
Superior de Agricultura, Universidade de Sao Paolo, Brazil.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='capability'>
Simulated Manufacturing Process Data
</h2><span id='topic+capability'></span>

<h3>Description</h3>

<p>The <code>capability</code> data frame has 75 rows and 1 columns.
</p>
<p>The data are simulated successive observations from a process in equilibrium.
The process is assumed to have specification limits (5.49, 5.79).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>capability
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following column:
</p>

<dl>
<dt><code>y</code></dt><dd>
<p>The simulated measurements.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Bissell, A.F. (1990) How reliable is your capability index?
<em>Applied Statistics</em>, <b>39</b>, 331&ndash;340.
</p>


<h3>References</h3>

<p>Canty, A.J. and Davison, A.C. (1996) Implementation of saddlepoint 
approximations to resampling distributions. To appear in 
<em>Computing Science and Statistics; Proceedings of the 28th Symposium on the Interface</em>.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='catsM'>
Weight Data for Domestic Cats
</h2><span id='topic+catsM'></span>

<h3>Description</h3>

<p>The <code>catsM</code> data frame has 97 rows and 3 columns.
</p>
<p>144 adult (over 2kg in weight) cats used for experiments with the drug
digitalis had their heart and body weight recorded.  47 of the cats were
female and 97 were male.  The <code>catsM</code> data frame consists of the data for
the male cats.  The full data are in dataset <code><a href="MASS.html#topic+cats">cats</a></code>
in package <code>MASS</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catsM
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Sex</code></dt><dd>
<p>A factor for the sex of the cat (levels are <code>F</code> and <code>M</code>: all
cases are <code>M</code> in this subset).
</p>
</dd>
<dt><code>Bwt</code></dt><dd>
<p>Body weight in kg.
</p>
</dd>
<dt><code>Hwt</code></dt><dd>
<p>Heart weight in g.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Fisher, R.A. (1947) The analysis of covariance method for the relation
between a part and the whole. <em>Biometrics</em>, <b>3</b>, 65&ndash;68.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Venables, W.N. and Ripley, B.D. (1994) 
<em>Modern Applied Statistics with S-Plus</em>. Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+cats">cats</a></code>
</p>

<hr>
<h2 id='cav'>
Position of Muscle Caveolae
</h2><span id='topic+cav'></span>

<h3>Description</h3>

<p>The <code>cav</code> data frame has 138 rows and 2 columns.
</p>
<p>The data gives the positions of the individual caveolae in a square region
with sides of length 500 units.  This grid was originally on a 2.65mum
square of muscle fibre.  The data are those points falling in the lower left 
hand quarter of the region used for the
dataset <code>caveolae.dat</code> in the <span class="pkg">spatial</span> package by B.D. Ripley (1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cav
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>x</code></dt><dd>
<p>The x coordinate of the caveola's position in the region.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>The y coordinate of the caveola's position in the region.
</p>
</dd></dl>


<h3>References</h3>

<p>Appleyard, S.T., Witkowski, J.A., Ripley, B.D., Shotton, D.M. and Dubowicz, V.
(1985) A novel procedure for pattern analysis of features present on freeze 
fractured plasma membranes. <em>Journal of Cell Science</em>, <b>74</b>, 105&ndash;117.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='cd4'>
CD4 Counts for HIV-Positive Patients
</h2><span id='topic+cd4'></span>

<h3>Description</h3>

<p>The <code>cd4</code> data frame has 20 rows and 2 columns.
</p>
<p>CD4 cells are carried in the blood as part of the human immune system.  One of
the effects of the HIV virus is that these cells die.  The count of CD4 cells is
used in determining the onset of full-blown AIDS in a patient.  In this study of
the effectiveness of a new anti-viral drug on HIV, 20 HIV-positive patients had
their CD4 counts recorded and then were put on a course of treatment with this
drug.  After using the drug for one year, their CD4 counts were again recorded.
The aim of the experiment was to show that patients taking the drug had
increased CD4 counts which is not generally seen in HIV-positive patients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cd4
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>baseline</code></dt><dd>
<p>The CD4 counts (in 100's) on admission to the trial.
</p>
</dd>
<dt><code>oneyear </code></dt><dd>
<p>The CD4 counts (in 100's) after one year of treatment with the new drug.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>DiCiccio, T.J. and Efron  B. (1996) Bootstrap confidence intervals (with 
Discussion). <em>Statistical Science</em>, <b>11</b>, 189&ndash;228.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='cd4.nested'>
Nested Bootstrap of cd4 data
</h2><span id='topic+cd4.nested'></span>

<h3>Description</h3>

<p>This is an example of a nested bootstrap for the correlation 
coefficient of the <code>cd4</code> data frame.  It is used in a practical
in Chapter 5 of Davison and Hinkley (1997).
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cd4">cd4</a></code>
</p>

<hr>
<h2 id='censboot'>
Bootstrap for Censored Data
</h2><span id='topic+censboot'></span><span id='topic+cens.return'></span>

<h3>Description</h3>

  
<p>This function applies types of bootstrap resampling which have
been suggested to deal with right-censored data.  It can also do model-based
resampling using a Cox regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>censboot(data, statistic, R, F.surv, G.surv, strata = matrix(1,n,2),
         sim = "ordinary", cox = NULL, index = c(1, 2), ...,
         parallel = c("no", "multicore", "snow"),
         ncpus = getOption("boot.ncpus", 1L), cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="censboot_+3A_data">data</code></td>
<td>

<p>The data frame or matrix containing the data.  It must have at least two
columns, one of which contains the times and the other the censoring
indicators.  It is allowed to have as many other columns as desired
(although efficiency is reduced for large numbers of columns) except for
<code>sim = "weird"</code> when it should only have two columns - the times and
censoring indicators.  The columns of <code>data</code> referenced by the
components of <code>index</code> are taken to be the times and censoring
indicators.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_statistic">statistic</code></td>
<td>

<p>A function which operates on the data frame and returns the required
statistic.  Its first argument must be the data. Any other arguments
that it requires can be passed using the <code>...</code> argument.  In
the case of <code>sim = "weird"</code>, the data passed to <code>statistic</code> only
contains the times and censoring indicator regardless of the actual
number of columns in <code>data</code>. In all other cases the data passed to
statistic will be of the same form as the original data.  When
<code>sim = "weird"</code>, the actual number of observations in the resampled
data sets may not be the same as the number in <code>data</code>.  For this
reason, if <code>sim = "weird"</code> and <code>strata</code> is supplied,
<code>statistic</code> should also take a numeric vector indicating the
strata.  This allows the statistic to depend on the strata if required.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_r">R</code></td>
<td>

<p>The number of bootstrap replicates.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_f.surv">F.surv</code></td>
<td>

<p>An object returned from a call to <code>survfit</code> giving the survivor
function for the data. This is a required argument unless
<code>sim = "ordinary"</code> or <code>sim = "model"</code> and <code>cox</code> is missing.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_g.surv">G.surv</code></td>
<td>

<p>Another object returned from a call to <code>survfit</code> but with the
censoring indicators reversed to give the product-limit estimate of the
censoring distribution.  Note that for consistency the uncensored times
should be reduced by a small amount in the call to <code>survfit</code>.  This
is a required argument whenever <code>sim = "cond"</code> or when
<code>sim = "model"</code> and <code>cox</code> is supplied.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_strata">strata</code></td>
<td>

<p>The strata used in the calls to <code>survfit</code>.  It can be a vector or a
matrix with 2 columns.  If it is a vector then it is assumed to be the
strata for the survival distribution, and the censoring distribution is
assumed to be the same for all observations.  If it is a matrix then the
first column is the strata for the survival distribution and the second
is the strata for the censoring distribution.  When <code>sim = "weird"</code>
only the strata for the survival distribution are used since the
censoring times are considered fixed.  When <code>sim = "ordinary"</code>, only
one set of strata is used to stratify the observations, this is taken to
be the first column of <code>strata</code> when it is a matrix.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_sim">sim</code></td>
<td>

<p>The simulation type.  Possible types are <code>"ordinary"</code> (case
resampling), <code>"model"</code> (equivalent to <code>"ordinary"</code> if
<code>cox</code> is missing, otherwise it is model-based resampling),
<code>"weird"</code> (the weird bootstrap - this cannot be used if <code>cox</code>
is supplied), and <code>"cond"</code> (the conditional bootstrap, in which
censoring times are resampled from the conditional censoring
distribution).
</p>
</td></tr>
<tr><td><code id="censboot_+3A_cox">cox</code></td>
<td>

<p>An object returned from <code>coxph</code>.  If it is supplied, then
<code>F.surv</code> should have been generated by a call of the form
<code>survfit(cox)</code>.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_index">index</code></td>
<td>

<p>A vector of length two giving the positions of the columns in
<code>data</code> which correspond to the times and censoring indicators
respectively.
</p>
</td></tr>
<tr><td><code id="censboot_+3A_...">...</code></td>
<td>

<p>Other named arguments which are passed unchanged to <code>statistic</code>
each time it is called.  Any such arguments to <code>statistic</code> must
follow the arguments which <code>statistic</code> is required to have for
the simulation.  Beware of partial matching to arguments of
<code>censboot</code> listed above, and that arguments named <code>X</code>
and <code>FUN</code> cause conflicts in some versions of <span class="pkg">boot</span> (but
not this one).
</p>
</td></tr>
<tr><td><code id="censboot_+3A_parallel">parallel</code>, <code id="censboot_+3A_ncpus">ncpus</code>, <code id="censboot_+3A_cl">cl</code></td>
<td>

<p>See the help for <code><a href="#topic+boot">boot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The various types of resampling are described in Davison and Hinkley (1997)
in sections 3.5 and 7.3.  The simplest is case resampling which simply 
resamples with replacement from the observations.  
</p>
<p>The conditional bootstrap simulates failure times from the estimate of
the survival distribution.  Then, for each observation its simulated
censoring time is equal to the observed censoring time if the
observation was censored and generated from the estimated censoring
distribution conditional on being greater than the observed failure time
if the observation was uncensored.  If the largest value is censored
then it is given a nominal failure time of <code>Inf</code> and conversely if
it is uncensored it is given a nominal censoring time of <code>Inf</code>.
This is necessary to allow the largest observation to be in the
resamples.
</p>
<p>If a Cox regression model is fitted to the data and supplied, then the
failure times are generated from the survival distribution using that
model.  In this case the censoring times can either be simulated from
the estimated censoring distribution (<code>sim = "model"</code>) or from the
conditional censoring distribution as in the previous paragraph
(<code>sim = "cond"</code>).
</p>
<p>The weird bootstrap holds the censored observations as fixed and also
the observed failure times.  It then generates the number of events at
each failure time using a binomial distribution with mean 1 and
denominator the number of failures that could have occurred at that time
in the original data set.  In our implementation we insist that there is
a least one simulated event in each stratum for every bootstrap dataset.
</p>
<p>When there are strata involved and <code>sim</code> is either <code>"model"</code>
or <code>"cond"</code> the situation becomes more difficult.  Since the strata
for the survival and censoring distributions are not the same it is
possible that for some observations both the simulated failure time and
the simulated censoring time are infinite.  To see this consider an
observation in stratum 1F for the survival distribution and stratum 1G
for the censoring distribution.  Now if the largest value in stratum 1F
is censored it is given a nominal failure time of <code>Inf</code>, also if
the largest value in stratum 1G is uncensored it is given a nominal
censoring time of <code>Inf</code> and so both the simulated failure and
censoring times could be infinite.  When this happens the simulated
value is considered to be a failure at the time of the largest observed
failure time in the stratum for the survival distribution.
</p>
<p>When <code>parallel = "snow"</code> and <code>cl</code> is not supplied,
<code>library(survival)</code> is run in each of the worker processes.
</p>


<h3>Value</h3>

<p>An object of class <code>"boot"</code> containing the following components:
</p>
<table>
<tr><td><code>t0</code></td>
<td>

<p>The value of <code>statistic</code> when applied to the original data.
</p>
</td></tr>
<tr><td><code>t</code></td>
<td>

<p>A matrix of bootstrap replicates of the values of <code>statistic</code>.
</p>
</td></tr>
<tr><td><code>R</code></td>
<td>

<p>The number of bootstrap replicates performed.
</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>

<p>The simulation type used.  This will usually be the input value of
<code>sim</code> unless that was <code>"model"</code> but <code>cox</code> was not
supplied, in which case it will be <code>"ordinary"</code>.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>The data used for the bootstrap. This will generally be the input
value of <code>data</code> unless <code>sim = "weird"</code>, in which case it
will just be the columns containing the times and the censoring
indicators. 
</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>

<p>The value of <code>.Random.seed</code> when <code>censboot</code> started work.
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>

<p>The input value of <code>statistic</code>.
</p>
</td></tr>
<tr><td><code>strata</code></td>
<td>

<p>The strata used in the resampling.  When <code>sim = "ordinary"</code>
this will be a vector which stratifies the observations, when
<code>sim = "weird"</code> it is the strata for the survival distribution
and in all other cases it is a matrix containing the strata for the
survival distribution and the censoring distribution.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The original call to <code>censboot</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Angelo J. Canty.  Parallel extensions by Brian Ripley</p>


<h3>References</h3>

<p>Andersen, P.K., Borgan, O., Gill, R.D. and Keiding,
N. (1993) <em>Statistical Models Based on Counting
Processes</em>. Springer-Verlag.
</p>
<p>Burr, D. (1994) A comparison of certain bootstrap confidence intervals
in the Cox model. <em>Journal of the American Statistical
Association</em>, <b>89</b>, 1290&ndash;1302.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Efron, B. (1981) Censored data and the bootstrap. 
<em>Journal of the  American Statistical Association</em>, <b>76</b>, 312&ndash;319.
</p>
<p>Hjort, N.L. (1985) Bootstrapping Cox's regression model. Technical report 
NSF-241, Dept. of Statistics, Stanford University.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, 
<code><a href="survival.html#topic+coxph">coxph</a></code>, <code><a href="survival.html#topic+survfit">survfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
# Example 3.9 of Davison and Hinkley (1997) does a bootstrap on some
# remission times for patients with a type of leukaemia.  The patients
# were divided into those who received maintenance chemotherapy and 
# those who did not.  Here we are interested in the median remission 
# time for the two groups.
data(aml, package = "boot") # not the version in survival.
aml.fun &lt;- function(data) {
     surv &lt;- survfit(Surv(time, cens) ~ group, data = data)
     out &lt;- NULL
     st &lt;- 1
     for (s in 1:length(surv$strata)) {
          inds &lt;- st:(st + surv$strata[s]-1)
          md &lt;- min(surv$time[inds[1-surv$surv[inds] &gt;= 0.5]])
          st &lt;- st + surv$strata[s]
          out &lt;- c(out, md)
     }
     out
}
aml.case &lt;- censboot(aml, aml.fun, R = 499, strata = aml$group)

# Now we will look at the same statistic using the conditional 
# bootstrap and the weird bootstrap.  For the conditional bootstrap 
# the survival distribution is stratified but the censoring 
# distribution is not. 

aml.s1 &lt;- survfit(Surv(time, cens) ~ group, data = aml)
aml.s2 &lt;- survfit(Surv(time-0.001*cens, 1-cens) ~ 1, data = aml)
aml.cond &lt;- censboot(aml, aml.fun, R = 499, strata = aml$group,
     F.surv = aml.s1, G.surv = aml.s2, sim = "cond")


# For the weird bootstrap we must redefine our function slightly since
# the data will not contain the group number.
aml.fun1 &lt;- function(data, str) {
     surv &lt;- survfit(Surv(data[, 1], data[, 2]) ~ str)
     out &lt;- NULL
     st &lt;- 1
     for (s in 1:length(surv$strata)) {
          inds &lt;- st:(st + surv$strata[s] - 1)
          md &lt;- min(surv$time[inds[1-surv$surv[inds] &gt;= 0.5]])
          st &lt;- st + surv$strata[s]
          out &lt;- c(out, md)
     }
     out
}
aml.wei &lt;- censboot(cbind(aml$time, aml$cens), aml.fun1, R = 499,
     strata = aml$group,  F.surv = aml.s1, sim = "weird")

# Now for an example where a cox regression model has been fitted
# the data we will look at the melanoma data of Example 7.6 from 
# Davison and Hinkley (1997).  The fitted model assumes that there
# is a different survival distribution for the ulcerated and 
# non-ulcerated groups but that the thickness of the tumour has a
# common effect.  We will also assume that the censoring distribution
# is different in different age groups.  The statistic of interest
# is the linear predictor.  This is returned as the values at a
# number of equally spaced points in the range of interest.
data(melanoma, package = "boot")
library(splines)# for ns
mel.cox &lt;- coxph(Surv(time, status == 1) ~ ns(thickness, df=4) + strata(ulcer),
                 data = melanoma)
mel.surv &lt;- survfit(mel.cox)
agec &lt;- cut(melanoma$age, c(0, 39, 49, 59, 69, 100))
mel.cens &lt;- survfit(Surv(time - 0.001*(status == 1), status != 1) ~
                    strata(agec), data = melanoma)
mel.fun &lt;- function(d) { 
     t1 &lt;- ns(d$thickness, df=4)
     cox &lt;- coxph(Surv(d$time, d$status == 1) ~ t1+strata(d$ulcer))
     ind &lt;- !duplicated(d$thickness)
     u &lt;- d$thickness[!ind]
     eta &lt;- cox$linear.predictors[!ind]
     sp &lt;- smooth.spline(u, eta, df=20)
     th &lt;- seq(from = 0.25, to = 10, by = 0.25)
     predict(sp, th)$y
}
mel.str &lt;- cbind(melanoma$ulcer, agec)

# this is slow!
mel.mod &lt;- censboot(melanoma, mel.fun, R = 499, F.surv = mel.surv,
     G.surv = mel.cens, cox = mel.cox, strata = mel.str, sim = "model")
# To plot the original predictor and a 95% pointwise envelope for it
mel.env &lt;- envelope(mel.mod)$point
th &lt;- seq(0.25, 10, by = 0.25)
plot(th, mel.env[1, ],  ylim = c(-2, 2),
     xlab = "thickness (mm)", ylab = "linear predictor", type = "n")
lines(th, mel.mod$t0, lty = 1)
matlines(th, t(mel.env), lty = 2)
</code></pre>

<hr>
<h2 id='channing'>
Channing House Data
</h2><span id='topic+channing'></span>

<h3>Description</h3>

<p>The <code>channing</code> data frame has 462 rows and 5 columns.
</p>
<p>Channing House is a retirement centre in Palo Alto, California.  These data 
were
collected between the opening of the house in 1964 until July 1, 1975.  In that
time 97 men and 365 women passed through the centre.  For each of these, their
age on entry and also on leaving or death was recorded.  A large number of the
observations were censored mainly due to the resident being alive on July 1,
1975 when the data was collected.  Over the time of the study 130 women and
46 men died at Channing House.  Differences between the survival of the sexes,
taking age into account, was one of the primary concerns of this study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>channing
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>sex</code></dt><dd>
<p>A factor for the sex of each resident (<code>"Male"</code> or <code>"Female"</code>).
</p>
</dd>
<dt><code>entry</code></dt><dd>
<p>The residents age (in months) on entry to the centre
</p>
</dd>
<dt><code>exit</code></dt><dd>
<p>The age (in months) of the resident on death, leaving the centre or July 1, 
1975 whichever event occurred first.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>The length of time (in months) that the resident spent at Channing House.
(<code>time=exit-entry</code>)
</p>
</dd>
<dt><code>cens</code></dt><dd>
<p>The indicator of right censoring.  1 indicates that the resident died at
Channing House, 0 indicates that they left the house prior to July 1, 1975 or
that they were still alive and living in the centre at that date.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Hyde, J. (1980) Testing survival with incomplete observations. 
<em>Biostatistics Casebook</em>.  
R.G. Miller, B. Efron, B.W. Brown and L.E. Moses (editors), 
31&ndash;46. John Wiley.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='claridge'>
Genetic Links to Left-handedness
</h2><span id='topic+claridge'></span>

<h3>Description</h3>

<p>The <code>claridge</code> data frame has 37 rows and 2 columns.  
</p>
<p>The data are from an experiment which was designed to look for a relationship 
between a certain genetic characteristic
and handedness.  The 37 subjects were women who had a son with mental
retardation due to inheriting a defective X-chromosome.  For each such mother
a genetic measurement of their DNA was made.  Larger values of this measurement
are known to be linked to the defective gene and it was hypothesized that 
larger values might also be linked to a progressive shift away from 
right-handednesss.  Each woman also filled in a 
questionnaire regarding which hand they used for various tasks.  From these
questionnaires a measure of hand preference was found for each mother.  The 
scale of
this measure goes from 1, indicating someone who always favours their right 
hand, to 8, indicating someone who always favours their left hand. Between 
these two extremes are people who favour one hand for some tasks and the other 
for other tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>claridge
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>dnan</code></dt><dd>
<p>The genetic measurement on each woman's DNA.
</p>
</dd>
<dt><code>hand</code></dt><dd>
<p>The measure of left-handedness on an integer scale from 1 to 8.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were kindly made available by Dr. Gordon S. Claridge from the
Department of Experimental Psychology, University of Oxford.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='cloth'>
Number of Flaws in Cloth
</h2><span id='topic+cloth'></span>

<h3>Description</h3>

<p>The <code>cloth</code> data frame has 32 rows and 2 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloth
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>x</code></dt><dd>
<p>The length of the roll of cloth.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>The number of flaws found in the roll.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Bissell, A.F. (1972) A negative binomial model with varying element size.
<em>Biometrika</em>, <b>59</b>, 435&ndash;441.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='co.transfer'>
Carbon Monoxide Transfer
</h2><span id='topic+co.transfer'></span>

<h3>Description</h3>

<p>The <code>co.transfer</code> data frame has 7 rows and 2 columns.  Seven smokers with
chickenpox had their levels of carbon monoxide transfer measured on entry
to hospital and then again after 1 week.  The main question being whether
one week of hospitalization  has changed the carbon monoxide transfer factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>co.transfer
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>entry</code></dt><dd>
<p>Carbon monoxide transfer factor on entry to hospital.
</p>
</dd>
<dt><code>week</code></dt><dd>
<p>Carbon monoxide transfer one week after admittance to hospital.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Hand, D.J., Daly, F., Lunn, A.D., McConway, K.J. and Ostrowski, E (1994)
<em>A Handbook of Small Data Sets</em>. Chapman and Hall.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Ellis, M.E., Neal, K.R. and Webb, A.K. (1987) Is smoking a risk factor for
pneumonia in patients with chickenpox? <em>British Medical Journal</em>,
<b>294</b>, 1002.
</p>

<hr>
<h2 id='coal'>
Dates of Coal Mining Disasters 
</h2><span id='topic+coal'></span>

<h3>Description</h3>

<p>The <code>coal</code> data frame has 191 rows and 1 columns.
</p>
<p>This data frame gives the dates of 191 explosions in coal mines which
resulted in 10 or more fatalities.  The time span of the data is from March 15,
1851 until March 22 1962.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coal
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following column:
</p>

<dl>
<dt><code>date</code></dt><dd>
<p>The date of the disaster.  The integer part of <code>date</code> gives the year.  The day
is represented as the fraction of the year that had elapsed on that day.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Hand, D.J., Daly, F., Lunn, A.D., McConway, K.J. and Ostrowski, E. (1994)
<em>A Handbook of Small Data Sets</em>, Chapman and Hall.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Jarrett, R.G. (1979) A note on the intervals between coal-mining disasters.
<em>Biometrika</em>, <b>66</b>, 191-193.
</p>

<hr>
<h2 id='control'>
Control Variate Calculations
</h2><span id='topic+control'></span>

<h3>Description</h3>

<p>This function will find control variate estimates from a bootstrap
output object.  It can either find the adjusted bias estimate using
post-simulation balancing or it can estimate the bias, variance, third
cumulant and quantiles, using the linear approximation as a control
variate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>control(boot.out, L = NULL, distn = NULL, index = 1, t0 = NULL,
        t = NULL, bias.adj = FALSE, alpha = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="control_+3A_boot.out">boot.out</code></td>
<td>

<p>A bootstrap output object returned from <code>boot</code>.  The bootstrap
replicates must have been generated using the usual nonparametric
bootstrap.
</p>
</td></tr>
<tr><td><code id="control_+3A_l">L</code></td>
<td>

<p>The empirical influence values for the statistic of interest.  If
<code>L</code> is not supplied then <code>empinf</code> is called to calculate
them from <code>boot.out</code>.
</p>
</td></tr>
<tr><td><code id="control_+3A_distn">distn</code></td>
<td>

<p>If present this must be the output from <code>smooth.spline</code> giving
the distribution function of the linear approximation.  This is used
only if <code>bias.adj</code> is <code>FALSE</code>.  Normally this would be
found using a saddlepoint approximation. If it is not supplied in
that case then it is calculated by <code>saddle.distn</code>.
</p>
</td></tr>
<tr><td><code id="control_+3A_index">index</code></td>
<td>

<p>The index of the variable of interest in the output of
<code>boot.out$statistic</code>.
</p>
</td></tr>
<tr><td><code id="control_+3A_t0">t0</code></td>
<td>

<p>The observed value of the statistic of interest on the original data
set <code>boot.out$data</code>.  This argument is used only if
<code>bias.adj</code> is <code>FALSE</code>. The input value is ignored if
<code>t</code> is not also supplied.  The default value is is
<code>boot.out$t0[index]</code>.
</p>
</td></tr>
<tr><td><code id="control_+3A_t">t</code></td>
<td>

<p>The bootstrap replicate values of the statistic of interest.  This
argument is used only if <code>bias.adj</code> is <code>FALSE</code>.  The input
is ignored if <code>t0</code> is not supplied also.  The default value is
<code>boot.out$t[,index]</code>.
</p>
</td></tr>
<tr><td><code id="control_+3A_bias.adj">bias.adj</code></td>
<td>

<p>A logical variable which if <code>TRUE</code> specifies that the adjusted
bias estimate using post-simulation balance is all that is required.
If <code>bias.adj</code> is <code>FALSE</code> (default) then the linear
approximation to the statistic is calculated and used as a control
variate in estimates of the bias, variance and third cumulant as
well as quantiles.
</p>
</td></tr>
<tr><td><code id="control_+3A_alpha">alpha</code></td>
<td>

<p>The alpha levels for the required quantiles if <code>bias.adj</code> is
<code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="control_+3A_...">...</code></td>
<td>

<p>Any additional arguments that <code>boot.out$statistic</code> requires.
These are passed unchanged every time <code>boot.out$statistic</code> is
called.  <code>boot.out$statistic</code> is called once if <code>bias.adj</code>
is <code>TRUE</code>, otherwise it may be called by <code>empinf</code> for
empirical influence calculations if <code>L</code> is not supplied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>bias.adj</code> is <code>FALSE</code> then the linear approximation to
the statistic is found and evaluated at each bootstrap replicate.
Then using the equation <em>T* = Tl*+(T*-Tl*)</em>, moment estimates can
be found.  For quantile estimation the distribution of the linear
approximation to <code>t</code> is approximated very accurately by
saddlepoint methods, this is then combined with the bootstrap
replicates to approximate the bootstrap distribution of <code>t</code> and
hence to estimate the bootstrap quantiles of <code>t</code>.
</p>


<h3>Value</h3>

<p>If <code>bias.adj</code> is <code>TRUE</code> then the returned value is the
adjusted bias estimate.
</p>
<p>If <code>bias.adj</code> is <code>FALSE</code> then the returned value is a list
with the following components
</p>
<table>
<tr><td><code>L</code></td>
<td>

<p>The empirical influence values used.  These are the input values if
supplied, and otherwise they are the values calculated by
<code>empinf</code>.
</p>
</td></tr>
<tr><td><code>tL</code></td>
<td>

<p>The linear approximations to the bootstrap replicates <code>t</code> of
the statistic of interest.
</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>

<p>The control estimate of bias using the linear approximation to
<code>t</code> as a control variate.
</p>
</td></tr>
<tr><td><code>var</code></td>
<td>

<p>The control estimate of variance using the linear approximation to
<code>t</code> as a control variate.
</p>
</td></tr>
<tr><td><code>k3</code></td>
<td>

<p>The control estimate of the third cumulant using the linear
approximation to <code>t</code> as a control variate.
</p>
</td></tr>
<tr><td><code>quantiles</code></td>
<td>

<p>A matrix with two columns; the first column are the alpha levels
used for the quantiles and the second column gives the corresponding
control estimates of the quantiles using the linear approximation to
<code>t</code> as a control variate.
</p>
</td></tr>
<tr><td><code>distn</code></td>
<td>

<p>An output object from <code>smooth.spline</code> describing the
saddlepoint approximation to the bootstrap distribution of the
linear approximation to <code>t</code>.  If <code>distn</code> was supplied on
input then this is the same as the input otherwise it is calculated
by a call to <code>saddle.distn</code>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Davison, A.C., Hinkley, D.V. and Schechtman, E. (1986) Efficient bootstrap 
simulation. <em>Biometrika</em>, <b>73</b>, 555&ndash;566.
</p>
<p>Efron, B. (1990) More efficient bootstrap computations.
<em>Journal of the American Statistical Association</em>, <b>55</b>, 79&ndash;89.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+empinf">empinf</a></code>, <code><a href="#topic+k3.linear">k3.linear</a></code>, <code><a href="#topic+linear.approx">linear.approx</a></code>, <code><a href="#topic+saddle.distn">saddle.distn</a></code>, <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>, <code><a href="#topic+var.linear">var.linear</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use of control variates for the variance of the air-conditioning data
mean.fun &lt;- function(d, i)
{    m &lt;- mean(d$hours[i])
     n &lt;- nrow(d)
     v &lt;- (n-1)*var(d$hours[i])/n^2
     c(m, v)
}
air.boot &lt;- boot(aircondit, mean.fun, R = 999)
control(air.boot, index = 2, bias.adj = TRUE)
air.cont &lt;- control(air.boot, index = 2)
# Now let us try the variance on the log scale.
air.cont1 &lt;- control(air.boot, t0 = log(air.boot$t0[2]),
                     t = log(air.boot$t[, 2]))
</code></pre>

<hr>
<h2 id='corr'>
Correlation Coefficient
</h2><span id='topic+corr'></span>

<h3>Description</h3>

<p>Calculates the weighted correlation given a data set and a set of weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corr(d, w = rep(1, nrow(d))/nrow(d))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corr_+3A_d">d</code></td>
<td>

<p>A matrix with two columns corresponding to the two variables whose correlation
we wish to calculate.
</p>
</td></tr>
<tr><td><code id="corr_+3A_w">w</code></td>
<td>

<p>A vector of weights to be applied to each pair of observations.  The default
is equal weights for each pair.  Normalization takes place within the function
so <code>sum(w)</code> need not equal 1.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function finds the correlation coefficient in weighted form.  This is
often useful in bootstrap methods since it allows for numerical differentiation
to get the empirical influence values.  It is also necessary to have the 
statistic in this form to find ABC intervals.
</p>


<h3>Value</h3>

<p>The correlation coefficient between <code>d[,1]</code> and <code>d[,2]</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>
</p>

<hr>
<h2 id='cum3'>
Calculate Third Order Cumulants
</h2><span id='topic+cum3'></span>

<h3>Description</h3>

<p>Calculates an estimate of the third cumulant, or skewness, of a vector. 
Also, if more than one vector is specified, a product-moment of order 3 is
estimated. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cum3(a, b = a, c = a, unbiased = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cum3_+3A_a">a</code></td>
<td>

<p>A vector of observations.
</p>
</td></tr>
<tr><td><code id="cum3_+3A_b">b</code></td>
<td>

<p>Another vector of observations,  if not supplied it is set to the value of <code>a</code>.
If supplied then it must be the same length as <code>a</code>.
</p>
</td></tr>
<tr><td><code id="cum3_+3A_c">c</code></td>
<td>

<p>Another vector of observations,  if not supplied it is set to the value of <code>a</code>.
If supplied then it must be the same length as <code>a</code>.
</p>
</td></tr>
<tr><td><code id="cum3_+3A_unbiased">unbiased</code></td>
<td>

<p>A logical value indicating whether the unbiased estimator should be used.  
</p>
</td></tr></table>


<h3>Details</h3>

<p>The unbiased estimator uses a multiplier of <code>n/((n-1)*(n-2))</code> where <code>n</code> is
the sample size, if <code>unbiased</code> is <code>FALSE</code> then a multiplier of <code>1/n</code> is used.
This is multiplied by <code>sum((a-mean(a))*(b-mean(b))*(c-mean(c)))</code> to give the
required estimate.
</p>


<h3>Value</h3>

<p>The required estimate.
</p>

<hr>
<h2 id='cv.glm'>
Cross-validation for Generalized Linear Models
</h2><span id='topic+cv.glm'></span>

<h3>Description</h3>

<p>This function calculates the estimated K-fold cross-validation prediction 
error for generalized linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.glm(data, glmfit, cost, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.glm_+3A_data">data</code></td>
<td>

<p>A matrix or data frame containing the data.  The rows should be cases and
the columns correspond to variables, one of which is the response.
</p>
</td></tr>
<tr><td><code id="cv.glm_+3A_glmfit">glmfit</code></td>
<td>

<p>An object of class <code>"glm"</code> containing the results of a generalized linear
model fitted to <code>data</code>.
</p>
</td></tr>
<tr><td><code id="cv.glm_+3A_cost">cost</code></td>
<td>

<p>A function of two vector arguments specifying the cost function for the 
cross-validation.  The first argument to <code>cost</code> should correspond to the
observed responses and the second argument should correspond to the predicted
or fitted responses from the generalized linear model.  <code>cost</code> must return a
non-negative scalar value.  The default is the average squared error function.
</p>
</td></tr>
<tr><td><code id="cv.glm_+3A_k">K</code></td>
<td>

<p>The number of groups into which the data should be split to estimate the
cross-validation prediction error.  The value of <code>K</code> must be such that all
groups are of approximately equal size.  If the supplied value of <code>K</code> does
not satisfy this criterion then it will be set to the closest integer which
does and a warning is generated specifying the value of <code>K</code> used.  The default
is to set <code>K</code> equal to the number of observations in <code>data</code> which gives the
usual leave-one-out cross-validation.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The data is divided randomly into <code>K</code> groups.  For each group the generalized
linear model is fit to <code>data</code> omitting that group, then the function <code>cost</code>
is applied to the observed responses in the group that was omitted from the fit
and the prediction made by the fitted models for those observations.
</p>
<p>When <code>K</code> is the number of observations leave-one-out cross-validation is used
and all the possible splits of the data are used.  When <code>K</code> is less than
the number of observations the <code>K</code> splits to be used are found by randomly
partitioning the data into <code>K</code> groups of approximately equal size.  In this
latter case a certain amount of bias is introduced.  This can be reduced by
using a simple adjustment (see equation 6.48 in Davison and Hinkley, 1997).
The second value returned in <code>delta</code> is the estimate adjusted by this method.
</p>


<h3>Value</h3>

<p>The returned value is a list with the following components.
</p>
<table>
<tr><td><code>call</code></td>
<td>

<p>The original call to <code>cv.glm</code>.
</p>
</td></tr>
<tr><td><code>K</code></td>
<td>

<p>The value of <code>K</code> used for the K-fold cross validation.
</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>

<p>A vector of length two.  The first component is the raw cross-validation
estimate of prediction error.  The second component is the adjusted
cross-validation estimate.  The adjustment is designed to compensate for the
bias introduced by not using leave-one-out cross-validation.
</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>

<p>The value of <code>.Random.seed</code> when <code>cv.glm</code> was called. 
</p>
</td></tr></table>


<h3>Side Effects</h3>

<p>The value of <code>.Random.seed</code> is updated.
</p>


<h3>References</h3>

<p>Breiman, L., Friedman, J.H., Olshen, R.A. and Stone, C.J. (1984)
<em>Classification and Regression Trees</em>. Wadsworth.
</p>
<p>Burman, P. (1989) A comparative study of ordinary cross-validation, 
<em>v</em>-fold cross-validation and repeated learning-testing methods.
<em>Biometrika</em>, <b>76</b>, 503&ndash;514
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Efron, B. (1986) How biased is the apparent error rate of a prediction rule?
<em>Journal of the American Statistical Association</em>, <b>81</b>, 461&ndash;470.
</p>
<p>Stone, M.  (1974) Cross-validation choice and assessment of statistical
predictions (with Discussion). 
<em>Journal of the Royal Statistical Society, B</em>, <b>36</b>, 111&ndash;147.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+glm.diag">glm.diag</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># leave-one-out and 6-fold cross-validation prediction error for 
# the mammals data set.
data(mammals, package="MASS")
mammals.glm &lt;- glm(log(brain) ~ log(body), data = mammals)
(cv.err &lt;- cv.glm(mammals, mammals.glm)$delta)
(cv.err.6 &lt;- cv.glm(mammals, mammals.glm, K = 6)$delta)

# As this is a linear model we could calculate the leave-one-out 
# cross-validation estimate without any extra model-fitting.
muhat &lt;- fitted(mammals.glm)
mammals.diag &lt;- glm.diag(mammals.glm)
(cv.err &lt;- mean((mammals.glm$y - muhat)^2/(1 - mammals.diag$h)^2))


# leave-one-out and 11-fold cross-validation prediction error for 
# the nodal data set.  Since the response is a binary variable an
# appropriate cost function is
cost &lt;- function(r, pi = 0) mean(abs(r-pi) &gt; 0.5)

nodal.glm &lt;- glm(r ~ stage+xray+acid, binomial, data = nodal)
(cv.err &lt;- cv.glm(nodal, nodal.glm, cost, K = nrow(nodal))$delta)
(cv.11.err &lt;- cv.glm(nodal, nodal.glm, cost, K = 11)$delta)
</code></pre>

<hr>
<h2 id='darwin'>
Darwin's Plant Height Differences
</h2><span id='topic+darwin'></span>

<h3>Description</h3>

<p>The <code>darwin</code> data frame has 15 rows and 1 columns.
</p>
<p>Charles Darwin conducted an experiment to examine the superiority of
cross-fertilized plants over self-fertilized plants.  15 pairs of plants
were used. Each pair consisted of one cross-fertilized plant and one
self-fertilized plant which germinated at the same time and grew in the
same pot. The plants were measured at a fixed time after planting and
the difference in heights between the cross- and self-fertilized plants are
recorded in eighths of an inch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>darwin
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following column:
</p>

<dl>
<dt><code>y</code></dt><dd>
<p>The difference in heights for the pairs of plants (in units of 0.125 inches).
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Fisher, R.A. (1935) <em>Design of Experiments</em>. Oliver and Boyd.
</p>


<h3>References</h3>

<p>Darwin, C. (1876) 
<em>The Effects of Cross- and Self-fertilisation in the Vegetable Kingdom</em>. 
John Murray.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='dogs'> Cardiac Data for Domestic Dogs </h2><span id='topic+dogs'></span>

<h3>Description</h3>

<p>The <code>dogs</code> data frame has 7 rows and 2 columns.
</p>
<p>Data on the cardiac oxygen consumption and left ventricular
pressure were gathered on 7 domestic dogs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dogs</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>mvo</dt><dd><p>Cardiac Oxygen Consumption</p>
</dd>
<dt>lvp</dt><dd><p>Left Ventricular Pressure</p>
</dd>
</dl>



<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997)
<em>Bootstrap Methods and Their Application</em>. Cambridge University
Press.
</p>

<hr>
<h2 id='downs.bc'>
Incidence of Down's Syndrome in British Columbia
</h2><span id='topic+downs.bc'></span>

<h3>Description</h3>

<p>The <code>downs.bc</code> data frame has 30 rows and 3 columns.
</p>
<p>Down's syndrome is a genetic disorder caused by an extra chromosome 21 or
a part of chromosome 21 being translocated to another chromosome.  The 
incidence of Down's syndrome is highly dependent on the mother's age and rises
sharply after age 30.  In the 1960's a large scale study of the effect of
maternal age on the incidence of Down's syndrome was conducted at the
British Columbia Health Surveillance Registry.  These are the data which was
collected in that study. 
</p>
<p>Mothers were classified by age. Most groups correspond to the age in years but
the first group comprises all mothers with ages in the range 15-17 and the 
last is those with ages 46-49.  No data for
mothers over 50 or below 15 were collected. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downs.bc
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>age</code></dt><dd>
<p>The average age of all mothers in the age category.
</p>
</dd>
<dt><code>m</code></dt><dd>
<p>The total number of live births to mothers in the age category.
</p>
</dd>
<dt><code>r</code></dt><dd>
<p>The number of cases of Down's syndrome.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Geyer, C.J. (1991) Constrained maximum likelihood exemplified by isotonic 
convex logistic regression. 
<em>Journal of the American Statistical Association</em>, <b>86</b>, 717&ndash;724.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='ducks'>
Behavioral and Plumage Characteristics of Hybrid Ducks
</h2><span id='topic+ducks'></span>

<h3>Description</h3>

<p>The <code>ducks</code> data frame has 11 rows and 2 columns.
</p>
<p>Each row of the data frame represents a male duck who is a second
generation cross of mallard and pintail ducks.  For 11 such ducks a
behavioural and plumage index were calculated.  These were measured on
scales devised for this experiment which was to examine whether there
was any link between which species the ducks resembled physically and
which they resembled in behaviour.  The scale for the physical
appearance ranged from 0 (identical in appearance to a mallard) to 20
(identical to a pintail).  The behavioural traits of the ducks were on
a scale from 0 to 15 with lower numbers indicating closer to
mallard-like in behaviour.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ducks
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>plumage</code></dt><dd>
<p>The index of physical appearance based on the plumage of individual ducks.
</p>
</dd>
<dt><code>behaviour</code></dt><dd>
<p>The index of behavioural characteristics of the ducks.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Larsen, R.J. and Marx, M.L. (1986) 
<em>An Introduction to Mathematical Statistics and its Applications</em> 
(Second Edition). Prentice-Hall.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Sharpe, R.S., and Johnsgard, P.A. (1966)
Inheritance of behavioral characters in
<code class="reqn">F_2</code> mallard  x  pintail
(<em>Anas Platyrhynchos L.  x  Anas Acuta L.</em>) 
hybrids. <em>Behaviour</em>, <b>27</b>, 259-272.
</p>

<hr>
<h2 id='EEF.profile'> Empirical Likelihoods</h2><span id='topic+EEF.profile'></span><span id='topic+EL.profile'></span>

<h3>Description</h3>

<p>Construct the empirical log likelihood or empirical exponential 
family log likelihood for a mean.</p>


<h3>Usage</h3>

<pre><code class='language-R'>EEF.profile(y, tmin = min(y) + 0.1, tmax = max(y) - 0.1, n.t = 25, 
            u = function(y, t) y - t)
EL.profile(y, tmin  =  min(y) + 0.1, tmax = max(y) - 0.1, n.t  =  25, 
           u = function(y, t) y - t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EEF.profile_+3A_y">y</code></td>
<td>
<p>A vector or matrix of data</p>
</td></tr>
<tr><td><code id="EEF.profile_+3A_tmin">tmin</code></td>
<td>
<p> The minimum value of the range over which the 
likelihood should be computed.  This must be larger than 
<code>min(y)</code>.</p>
</td></tr>
<tr><td><code id="EEF.profile_+3A_tmax">tmax</code></td>
<td>
<p> The maximum value of the range over which the 
likelihood should be computed.  This must be smaller than 
<code>max(y)</code>.</p>
</td></tr>
<tr><td><code id="EEF.profile_+3A_n.t">n.t</code></td>
<td>
<p> The number of points between <code>tmin</code> and
<code>tmax</code> at which the value of the log-likelihood should be
computed.</p>
</td></tr>
<tr><td><code id="EEF.profile_+3A_u">u</code></td>
<td>
<p>A function of the data and the parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions calculate the log likelihood for a mean using either
an empirical likelihood or an empirical exponential family likelihood.
They are supplied as part of the package <code>boot</code> for demonstration
purposes with the practicals in chapter 10 of Davison and Hinkley (1997).
The functions are not intended for general use and are not supported
as part of the <code>boot</code>package.  For more general and more robust
code to calculate empirical likelihoods see Professor A. B. Owen's 
empirical likelihood home page at the URL
<a href="https://artowen.su.domains/empirical/">https://artowen.su.domains/empirical/</a>
</p>


<h3>Value</h3>

<p>A matrix with <code>n.t</code> rows.  The first column contains the
values of the parameter used.  The second column of the output
of <code>EL.profile</code> contains the values of the empirical
log likelihood. The second and third columns of the output of
<code>EEF.profile</code> contain two versions of the empirical
exponential family log-likelihood.  The final column of the
output matrix contains the values of the Lagrange multiplier
used in the optimization procedure.
</p>


<h3>Author(s)</h3>

<p>Angelo J. Canty</p>


<h3>References</h3>

 
<p>Davison, A. C. and Hinkley, D. V. (1997)
<em>Bootstrap Methods and Their Application</em>. Cambridge University
Press.
</p>

<hr>
<h2 id='empinf'>
Empirical Influence Values
</h2><span id='topic+empinf'></span>

<h3>Description</h3>

<p>This function calculates the empirical influence values for a
statistic applied to a data set.  It allows four types of calculation,
namely the infinitesimal jackknife (using numerical differentiation),
the usual jackknife estimates, the &lsquo;positive&rsquo; jackknife
estimates and a method which estimates the empirical influence values
using regression of bootstrap replicates of the statistic.  All
methods can be used with one or more samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empinf(boot.out = NULL, data = NULL, statistic = NULL,
       type = NULL, stype = NULL ,index = 1, t = NULL,
       strata = rep(1, n), eps = 0.001, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="empinf_+3A_boot.out">boot.out</code></td>
<td>

<p>A bootstrap object created by the function <code>boot</code>.  If
<code>type</code> is <code>"reg"</code> then this argument is required.  For any
of the other types it is an optional argument.  If it is included
when optional then the values of <code>data</code>, <code>statistic</code>,
<code>stype</code>, and <code>strata</code> are taken from the components of
<code>boot.out</code> and any values passed to <code>empinf</code> directly are
ignored.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_data">data</code></td>
<td>

<p>A vector, matrix or data frame containing the data for which
empirical influence values are required.  It is a required argument
if <code>boot.out</code> is not supplied.  If <code>boot.out</code> is supplied
then <code>data</code> is set to <code>boot.out$data</code> and any value
supplied is ignored.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_statistic">statistic</code></td>
<td>

<p>The statistic for which empirical influence values are required.  It
must be a function of at least two arguments, the data set and a
vector of weights, frequencies or indices.  The nature of the second
argument is given by the value of <code>stype</code>.  Any other arguments
that it takes must be supplied to <code>empinf</code> and will be passed
to <code>statistic</code> unchanged. This is a required argument if
<code>boot.out</code> is not supplied, otherwise its value is taken from
<code>boot.out</code> and any value supplied here will be ignored.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_type">type</code></td>
<td>

<p>The calculation type to be used for the empirical influence
values. Possible values of <code>type</code> are <code>"inf"</code>
(infinitesimal jackknife), <code>"jack"</code> (usual jackknife),
<code>"pos"</code> (positive jackknife), and <code>"reg"</code> (regression
estimation).  The default value depends on the other arguments.  If
<code>t</code> is supplied then the default value of <code>type</code> is
<code>"reg"</code> and <code>boot.out</code> should be present so that its
frequency array can be found.  It <code>t</code> is not supplied then if
<code>stype</code> is <code>"w"</code>, the default value of <code>type</code> is
<code>"inf"</code>; otherwise, if <code>boot.out</code> is present the default
is <code>"reg"</code>.  If none of these conditions apply then the default
is <code>"jack"</code>.  Note that it is an error for <code>type</code> to be
<code>"reg"</code> if <code>boot.out</code> is missing or to be  <code>"inf"</code> if
<code>stype</code> is not <code>"w"</code>.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_stype">stype</code></td>
<td>

<p>A character variable giving the nature of the second argument to
<code>statistic</code>. It can take on three values: <code>"w"</code> (weights),
<code>"f"</code> (frequencies), or <code>"i"</code> (indices).  If
<code>boot.out</code> is supplied the value of <code>stype</code> is set to
<code>boot.out$stype</code> and any value supplied here is ignored.
Otherwise it is an optional argument which defaults to <code>"w"</code>.
If <code>type</code> is <code>"inf"</code> then <code>stype</code> MUST be
<code>"w"</code>.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_index">index</code></td>
<td>

<p>An integer giving the position of the variable of interest in the
output of <code>statistic</code>.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_t">t</code></td>
<td>

<p>A vector of length <code>boot.out$R</code> which gives the bootstrap
replicates of the statistic of interest.  <code>t</code> is used only when
<code>type</code> is <code>reg</code> and it defaults to
<code>boot.out$t[,index]</code>.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_strata">strata</code></td>
<td>

<p>An integer vector or a factor specifying the strata for multi-sample
problems. If <code>boot.out</code> is supplied  the value of <code>strata</code>
is set to <code>boot.out$strata</code>. Otherwise it is an optional
argument which has default corresponding to the single sample
situation.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_eps">eps</code></td>
<td>

<p>This argument is used only if <code>type</code> is <code>"inf"</code>.  In that
case the value of epsilon to be used for numerical differentiation
will be <code>eps</code> divided by the number of observations in
<code>data</code>.
</p>
</td></tr>
<tr><td><code id="empinf_+3A_...">...</code></td>
<td>

<p>Any other arguments that <code>statistic</code> takes.  They will be
passed unchanged to <code>statistic</code> every time that it is called.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>type</code> is <code>"inf"</code> then numerical differentiation is used
to approximate the empirical influence values.  This makes sense only
for statistics which are written in weighted form (i.e. <code>stype</code>
is <code>"w"</code>).  If <code>type</code> is <code>"jack"</code> then the usual
leave-one-out jackknife estimates of the empirical influence are
returned.  If <code>type</code> is <code>"pos"</code> then the positive
(include-one-twice) jackknife values are used.  If <code>type</code> is
<code>"reg"</code> then a bootstrap object must be supplied. The regression
method then works by regressing the bootstrap replicates of
<code>statistic</code> on the frequency array from which they were derived.
The bootstrap frequency array is obtained through a call to
<code>boot.array</code>.  Further details of the methods are given in
Section 2.7 of Davison and Hinkley (1997).
</p>
<p>Empirical influence values are often used frequently in nonparametric
bootstrap applications.  For this reason many other functions call
<code>empinf</code> when they are required.  Some examples of their use are
for nonparametric delta estimates of variance, BCa intervals and
finding linear approximations to statistics for use as control
variates.  They are also used for antithetic bootstrap resampling.
</p>


<h3>Value</h3>

<p>A vector of the empirical influence values of <code>statistic</code> applied
to <code>data</code>.  The values will be in the same order as the
observations in data.
</p>


<h3>Warning</h3>

<p>All arguments to <code>empinf</code> must be passed using the <code>name =
    value</code> convention.  If this is not followed then unpredictable
errors can occur.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997)
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Efron, B. (1982) <em>The Jackknife, the Bootstrap and Other
Resampling Plans</em>. CBMS-NSF Regional Conference Series in Applied
Mathematics, <b>38</b>, SIAM.
</p>
<p>Fernholtz, L.T. (1983) <em>von Mises Calculus for Statistical Functionals</em>.
Lecture Notes in Statistics, <b>19</b>, Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+boot.array">boot.array</a></code>, <code><a href="#topic+boot.ci">boot.ci</a></code>,
<code><a href="#topic+control">control</a></code>, <code><a href="#topic+jack.after.boot">jack.after.boot</a></code>,
<code><a href="#topic+linear.approx">linear.approx</a></code>, <code><a href="#topic+var.linear">var.linear</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The empirical influence values for the ratio of means in
# the city data.
ratio &lt;- function(d, w) sum(d$x *w)/sum(d$u*w)
empinf(data = city, statistic = ratio)
city.boot &lt;- boot(city, ratio, 499, stype="w")
empinf(boot.out = city.boot, type = "reg")

# A statistic that may be of interest in the difference of means
# problem is the t-statistic for testing equality of means.  In
# the bootstrap we get replicates of the difference of means and
# the variance of that statistic and then want to use this output
# to get the empirical influence values of the t-statistic.
grav1 &lt;- gravity[as.numeric(gravity[,2]) &gt;= 7,]
grav.fun &lt;- function(dat, w) {
     strata &lt;- tapply(dat[, 2], as.numeric(dat[, 2]))
     d &lt;- dat[, 1]
     ns &lt;- tabulate(strata)
     w &lt;- w/tapply(w, strata, sum)[strata]
     mns &lt;- as.vector(tapply(d * w, strata, sum)) # drop names
     mn2 &lt;- tapply(d * d * w, strata, sum)
     s2hat &lt;- sum((mn2 - mns^2)/ns)
     c(mns[2] - mns[1], s2hat)
}

grav.boot &lt;- boot(grav1, grav.fun, R = 499, stype = "w",
                  strata = grav1[, 2])

# Since the statistic of interest is a function of the bootstrap
# statistics, we must calculate the bootstrap replicates and pass
# them to empinf using the t argument.
grav.z &lt;- (grav.boot$t[,1]-grav.boot$t0[1])/sqrt(grav.boot$t[,2])
empinf(boot.out = grav.boot, t = grav.z)
</code></pre>

<hr>
<h2 id='envelope'>
Confidence Envelopes for Curves
</h2><span id='topic+envelope'></span>

<h3>Description</h3>

<p>This function calculates overall and pointwise confidence envelopes for a 
curve based on bootstrap replicates of the curve evaluated at a number of
fixed points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>envelope(boot.out = NULL, mat = NULL, level = 0.95, index = 1:ncol(mat))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="envelope_+3A_boot.out">boot.out</code></td>
<td>

<p>An object of class <code>"boot"</code> for which <code>boot.out$t</code> contains the replicates
of the curve at a number of fixed points.
</p>
</td></tr>
<tr><td><code id="envelope_+3A_mat">mat</code></td>
<td>

<p>A matrix of bootstrap replicates of the values of the curve at a number of
fixed points.  This is a required argument if <code>boot.out</code> is not supplied
and is set to <code>boot.out$t</code> otherwise.
</p>
</td></tr>
<tr><td><code id="envelope_+3A_level">level</code></td>
<td>

<p>The confidence level of the envelopes required.  The default is to
find 95% confidence envelopes.  It can be a scalar or a vector of length 2.  
If it is scalar then both the pointwise and the overall
envelopes are found at that level.  If is a vector then the first element gives 
the level for the pointwise envelope and the second gives the level for the
overall envelope.
</p>
</td></tr>
<tr><td><code id="envelope_+3A_index">index</code></td>
<td>

<p>The numbers of the columns of <code>mat</code> which contain the bootstrap replicates.
This can be used to ensure that other statistics which may have been calculated
in the bootstrap are not considered as values of the function.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The pointwise envelope is found by simply looking at the quantiles of the
replicates at each point.  The overall error for that envelope is then
calculated using equation (4.17) of Davison and Hinkley (1997).  A sequence
of pointwise envelopes is then found until one of them has overall error
approximately equal to the level required.  If no such envelope can be
found then the envelope returned will just contain the extreme values of each
column of <code>mat</code>.
</p>


<h3>Value</h3>

<p>A list with the following components :
</p>
<table>
<tr><td><code>point</code></td>
<td>

<p>A matrix with two rows corresponding to the values of the upper and lower
pointwise confidence envelope at the same points as the bootstrap replicates
were calculated.
</p>
</td></tr>
<tr><td><code>overall</code></td>
<td>

<p>A matrix similar to <code>point</code> but containing the envelope which controls the
overall error.
</p>
</td></tr>
<tr><td><code>k.pt</code></td>
<td>

<p>The quantiles used for the pointwise envelope.
</p>
</td></tr>
<tr><td><code>err.pt</code></td>
<td>

<p>A vector with two components, the first gives the pointwise error rate for the
pointwise envelope, and the second the overall error rate for that envelope.
</p>
</td></tr>
<tr><td><code>k.ov</code></td>
<td>

<p>The quantiles used for the overall envelope.
</p>
</td></tr>
<tr><td><code>err.ov</code></td>
<td>

<p>A vector with two components, the first gives the pointwise error rate for the
overall envelope, and the second the overall error rate for that envelope.
</p>
</td></tr>
<tr><td><code>err.nom</code></td>
<td>

<p>A vector of length 2 giving the nominal error rates for the pointwise and the
overall envelopes.
</p>
</td></tr></table>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+boot.ci">boot.ci</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Testing whether the final series of measurements of the gravity data
# may come from a normal distribution.  This is done in Examples 4.7 
# and 4.8 of Davison and Hinkley (1997).
grav1 &lt;- gravity$g[gravity$series == 8]
grav.z &lt;- (grav1 - mean(grav1))/sqrt(var(grav1))
grav.gen &lt;- function(dat, mle) rnorm(length(dat))
grav.qqboot &lt;- boot(grav.z, sort, R = 999, sim = "parametric",
                    ran.gen = grav.gen)
grav.qq &lt;- qqnorm(grav.z, plot.it = FALSE)
grav.qq &lt;- lapply(grav.qq, sort)
plot(grav.qq, ylim = c(-3.5, 3.5), ylab = "Studentized Order Statistics",
     xlab = "Normal Quantiles")
grav.env &lt;- envelope(grav.qqboot, level = 0.9)
lines(grav.qq$x, grav.env$point[1, ], lty = 4)
lines(grav.qq$x, grav.env$point[2, ], lty = 4)
lines(grav.qq$x, grav.env$overall[1, ], lty = 1)
lines(grav.qq$x, grav.env$overall[2, ], lty = 1)
</code></pre>

<hr>
<h2 id='exp.tilt'>
Exponential Tilting
</h2><span id='topic+exp.tilt'></span>

<h3>Description</h3>

<p>This function calculates exponentially tilted multinomial distributions 
such that the resampling distributions of the linear approximation to a
statistic have the required means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp.tilt(L, theta = NULL, t0 = 0, lambda = NULL,
         strata = rep(1, length(L)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp.tilt_+3A_l">L</code></td>
<td>

<p>The empirical influence values for the statistic of interest based on the 
observed data.  The length of <code>L</code> should be the same as the size of the 
original data set.  Typically <code>L</code> will be calculated by a call to <code>empinf</code>.
</p>
</td></tr>
<tr><td><code id="exp.tilt_+3A_theta">theta</code></td>
<td>

<p>The value at which the tilted distribution is to be centred.  This is not
required if <code>lambda</code> is supplied but is needed otherwise.
</p>
</td></tr>
<tr><td><code id="exp.tilt_+3A_t0">t0</code></td>
<td>

<p>The current value of the statistic.  The default is that the statistic equals 0.
</p>
</td></tr>
<tr><td><code id="exp.tilt_+3A_lambda">lambda</code></td>
<td>

<p>The Lagrange multiplier(s).  For each value of <code>lambda</code> a multinomial 
distribution
is found with probabilities proportional to <code>exp(lambda * L)</code>.  In general
<code>lambda</code> is not known and so <code>theta</code> would be supplied, and the corresponding
value of <code>lambda</code> found.  If both <code>lambda</code> and <code>theta</code> are supplied then
<code>lambda</code> is ignored and the multipliers for tilting to <code>theta</code> are found.
</p>
</td></tr>
<tr><td><code id="exp.tilt_+3A_strata">strata</code></td>
<td>

<p>A vector or factor of the same length as <code>L</code> giving the strata for the
observed data and the empirical influence values <code>L</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Exponential tilting involves finding a set of weights for a data set to
ensure that the bootstrap distribution of the linear approximation to a 
statistic of interest has mean <code>theta</code>.  The weights chosen to achieve this
are given by <code>p[j]</code> proportional to 
<code>exp(lambda*L[j]/n)</code>, where <code>n</code> is the number of data points.  
<code>lambda</code> is then 
chosen to make the mean of the bootstrap
distribution, of the linear approximation to the statistic of interest, equal
to the required value <code>theta</code>.  Thus <code>lambda</code> is defined as the 
solution of a nonlinear equation.   
The equation is solved by minimizing the Euclidean distance between 
the left and right hand sides of the equation using the function <code>nlmin</code>.
If this minimum is not equal to zero then the method fails.
</p>
<p>Typically exponential tilting is used to find suitable weights for importance
resampling.  If a small tail probability or quantile of the distribution of
the statistic of interest is required then a more efficient simulation is to
centre the resampling distribution close to the point of interest and
then use the functions <code>imp.prob</code> or <code>imp.quantile</code> to estimate the required
quantity.
</p>
<p>Another method of achieving a similar shifting of the distribution is through
the use of <code>smooth.f</code>.  The function <code>tilt.boot</code> uses <code>exp.tilt</code> or <code>smooth.f</code>
to find the weights for a tilted bootstrap.
</p>


<h3>Value</h3>

<p>A list with the following components :
</p>
<table>
<tr><td><code>p</code></td>
<td>

<p>The tilted probabilities.  There will be <code>m</code> distributions where <code>m</code> is the
length of <code>theta</code> (or <code>lambda</code> if supplied).  If <code>m</code> is 1 then <code>p</code> is a vector
of <code>length(L)</code> probabilities.  If <code>m</code> is greater than 1 then <code>p</code> is a matrix
with <code>m</code> rows, each of which contain <code>length(L)</code> probabilities.  In this case
the vector <code>p[i,]</code> is the distribution tilted to <code>theta[i]</code>.  <code>p</code> is
in the form required by the argument <code>weights</code> of the function <code>boot</code> for
importance resampling.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>The Lagrange multiplier used in the equation to determine the tilted
probabilities.  <code>lambda</code> is a vector of the same length as <code>theta</code>.
</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>

<p>The values of <code>theta</code> to which the distributions have been tilted.  In general
this will be the input value of <code>theta</code> but if <code>lambda</code> was supplied then 
this is the vector of the corresponding <code>theta</code> values.
</p>
</td></tr></table>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Efron, B. (1981) Nonparametric standard errors and confidence intervals 
(with Discussion). <em>Canadian Journal of Statistics</em>, <b>9</b>, 139&ndash;172.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+empinf">empinf</a></code>, <code><a href="#topic+imp.prob">imp.prob</a></code>, <code><a href="#topic+imp.quantile">imp.quantile</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="#topic+smooth.f">smooth.f</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 9.8 of Davison and Hinkley (1997) requires tilting the resampling
# distribution of the studentized statistic to be centred at the observed
# value of the test statistic 1.84.  This can be achieved as follows.
grav1 &lt;- gravity[as.numeric(gravity[,2]) &gt;=7 , ]
grav.fun &lt;- function(dat, w, orig) {
     strata &lt;- tapply(dat[, 2], as.numeric(dat[, 2]))
     d &lt;- dat[, 1]
     ns &lt;- tabulate(strata)
     w &lt;- w/tapply(w, strata, sum)[strata]
     mns &lt;- as.vector(tapply(d * w, strata, sum)) # drop names
     mn2 &lt;- tapply(d * d * w, strata, sum)
     s2hat &lt;- sum((mn2 - mns^2)/ns)
     c(mns[2]-mns[1], s2hat, (mns[2]-mns[1]-orig)/sqrt(s2hat))
}
grav.z0 &lt;- grav.fun(grav1, rep(1, 26), 0)
grav.L &lt;- empinf(data = grav1, statistic = grav.fun, stype = "w", 
                 strata = grav1[,2], index = 3, orig = grav.z0[1])
grav.tilt &lt;- exp.tilt(grav.L, grav.z0[3], strata = grav1[,2])
boot(grav1, grav.fun, R = 499, stype = "w", weights = grav.tilt$p,
     strata = grav1[,2], orig = grav.z0[1])
</code></pre>

<hr>
<h2 id='fir'>
Counts of Balsam-fir Seedlings
</h2><span id='topic+fir'></span>

<h3>Description</h3>

<p>The <code>fir</code> data frame has 50 rows and 3 columns.
</p>
<p>The number of balsam-fir seedlings in each quadrant of a grid of 50 five foot 
square quadrants were counted.  The grid consisted of 5 rows of 10 quadrants in
each row.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fir
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>count</code></dt><dd>
<p>The number of seedlings in the quadrant.
</p>
</dd>
<dt><code>row</code></dt><dd>
<p>The row number of the quadrant. 
</p>
</dd>
<dt><code>col</code></dt><dd>
<p>The quadrant number within the row.
</p>
</dd></dl>


<h3>Source</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='freq.array'>
Bootstrap Frequency Arrays
</h2><span id='topic+freq.array'></span>

<h3>Description</h3>

<p>Take a matrix of indices for nonparametric bootstrap resamples and
return the frequencies of the original observations in each resample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq.array(i.array)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freq.array_+3A_i.array">i.array</code></td>
<td>

<p>This will be an matrix of integers between 1 and n, where n is the number
of observations in a data set.  The matrix will have n columns and R rows
where R is the number of bootstrap resamples.  Such matrices are found by
<code>boot</code> when doing nonparametric bootstraps.  They can also be found after a
bootstrap has been run through the function <code>boot.array</code>.
</p>
</td></tr></table>


<h3>Value</h3>

<p>A matrix of the same dimensions as the input matrix.  Each row of the 
matrix corresponds to a single bootstrap resample.  Each column of the
matrix corresponds to one of the original observations and specifies its
frequency in each bootstrap resample.  Thus the first column tells us how
often the first observation appeared in each bootstrap resample.  Such
frequency arrays are often useful for diagnostic purposes such as the
jackknife-after-bootstrap plot.  They are also necessary for the regression
estimates of empirical influence values and for finding importance sampling 
weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.array">boot.array</a></code>
</p>

<hr>
<h2 id='frets'>
Head Dimensions in Brothers
</h2><span id='topic+frets'></span>

<h3>Description</h3>

<p>The <code>frets</code> data frame has 25 rows and 4 columns.
</p>
<p>The data consist of measurements of the length and breadth of the heads of 
pairs of adult brothers in 25 randomly sampled families.  All measurements
are expressed in millimetres.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frets
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>l1</code></dt><dd>
<p>The head length of the eldest son.
</p>
</dd>
<dt><code>b1</code></dt><dd>
<p>The head breadth of the eldest son.
</p>
</dd>
<dt><code>l2</code></dt><dd>
<p>The head length of the second son.
</p>
</dd>
<dt><code>b2</code></dt><dd>
<p>The head breadth of the second son.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Frets, G.P. (1921) Heredity of head form in man. <em>Genetica</em>, <b>3</b>,
193.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Whittaker, J. (1990) <em>Graphical Models in Applied Multivariate Statistics</em>.
John Wiley.
</p>

<hr>
<h2 id='glm.diag'>
Generalized Linear Model Diagnostics
</h2><span id='topic+glm.diag'></span>

<h3>Description</h3>

<p>Calculates jackknife deviance residuals, standardized deviance residuals, 
standardized Pearson residuals, approximate Cook statistic, leverage and
estimated dispersion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.diag(glmfit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm.diag_+3A_glmfit">glmfit</code></td>
<td>

<p><code>glmfit</code> is a <code>glm.object</code> - the result of a call to <code>glm()</code>
</p>
</td></tr></table>


<h3>Value</h3>

<p>Returns a list with the following components
</p>
<table>
<tr><td><code>res</code></td>
<td>

<p>The vector of jackknife deviance residuals.
</p>
</td></tr>
<tr><td><code>rd</code></td>
<td>

<p>The vector of standardized deviance residuals.
</p>
</td></tr>
<tr><td><code>rp</code></td>
<td>

<p>The vector of standardized Pearson residuals.
</p>
</td></tr>
<tr><td><code>cook</code></td>
<td>

<p>The vector of approximate Cook statistics.
</p>
</td></tr>
<tr><td><code>h</code></td>
<td>

<p>The vector of leverages of the observations.
</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>

<p>The value used to standardize the residuals.  This is the estimate of
residual standard deviation in the Gaussian family and is the square root of
the estimated shape parameter in the Gamma family.  In all other cases it is 1.
</p>
</td></tr></table>


<h3>Note</h3>

<p>See the help for <code><a href="#topic+glm.diag.plots">glm.diag.plots</a></code> for an example of the
use of <code>glm.diag</code>.
</p>


<h3>References</h3>

<p>Davison, A.C. and Snell, E.J.  (1991)  Residuals and diagnostics.  
In <em>Statistical Theory and Modelling: In Honour of Sir David Cox</em>.
D.V. Hinkley, N. Reid and E.J. Snell (editors), 83&ndash;106.  Chapman and Hall. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+glm.diag.plots">glm.diag.plots</a></code>, <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>
</p>

<hr>
<h2 id='glm.diag.plots'>
Diagnostics plots for generalized linear models
</h2><span id='topic+glm.diag.plots'></span>

<h3>Description</h3>

<p>Makes plot of jackknife deviance residuals against linear predictor, 
normal scores plots of standardized deviance residuals, plot of approximate Cook statistics against leverage/(1-leverage), and case plot of Cook statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.diag.plots(glmfit, glmdiag = glm.diag(glmfit), subset = NULL,
               iden = FALSE, labels = NULL, ret = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm.diag.plots_+3A_glmfit">glmfit</code></td>
<td>

<p><code>glm.object</code> : the result of a call to <code>glm()</code>
</p>
</td></tr>
<tr><td><code id="glm.diag.plots_+3A_glmdiag">glmdiag</code></td>
<td>

<p>Diagnostics of <code>glmfit</code> obtained from a call to <code>glm.diag</code>.  If
it is not supplied then it is calculated.  
</p>
</td></tr>
<tr><td><code id="glm.diag.plots_+3A_subset">subset</code></td>
<td>

<p>Subset of <code>data</code> for which <code>glm</code> fitting performed: should be the same as the 
<code>subset</code> option used in the call to <code>glm()</code> which generated <code>glmfit</code>.  Needed 
only if the <code>subset=</code> option was used in the call to <code>glm</code>.  
</p>
</td></tr>
<tr><td><code id="glm.diag.plots_+3A_iden">iden</code></td>
<td>

<p>A logical argument. If <code>TRUE</code> then, after the plots are drawn, the user will
be prompted for an integer between 0 and 4.  A positive integer will select
a plot and invoke <code>identify()</code> on that plot.  After exiting <code>identify()</code>, the
user is again prompted, this loop continuing until the user responds to the
prompt with 0.  If <code>iden</code> is <code>FALSE</code> (default) the user cannot interact with the plots.
</p>
</td></tr>
<tr><td><code id="glm.diag.plots_+3A_labels">labels</code></td>
<td>

<p>A vector of labels for use with <code>identify()</code> if <code>iden</code> is <code>TRUE</code>.  If it is not 
supplied then the labels are derived from <code>glmfit</code>.
</p>
</td></tr>
<tr><td><code id="glm.diag.plots_+3A_ret">ret</code></td>
<td>

<p>A logical argument indicating if <code>glmdiag</code> should be returned.  The default is
<code>FALSE</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The diagnostics required for the plots are calculated by <code>glm.diag</code>.  These are
then used to produce the four plots on the current graphics device.
</p>
<p>The plot on the top left is a plot of the jackknife deviance residuals 
against the fitted values.
</p>
<p>The plot on the top right is a normal QQ plot of the standardized deviance 
residuals.  The dotted line is the expected line if the standardized residuals
are normally distributed, i.e. it is the line with intercept 0 and slope 1.
</p>
<p>The bottom two panels are plots of the Cook statistics.  On the left is a plot
of the Cook statistics against the standardized leverages.  In general there
will be two dotted lines on this plot.  The horizontal line is at 8/(n-2p)
where n is the number of observations and p is the number of parameters 
estimated.  Points above this line may be points with high influence on the
model.  The vertical line is at 2p/(n-2p) and points to the right of this
line have high leverage compared to the variance of the raw residual at that 
point.  If all points are below the horizontal line or to the left of the
vertical line then the line is not shown.
</p>
<p>The final plot again shows the Cook statistic this time plotted against case
number enabling us to find which observations are influential.
</p>
<p>Use of <code>iden=T</code> is encouraged for proper exploration of these four plots as
a guide to how well the model fits the data and whether certain observations
have an unduly large effect on parameter estimates.
</p>


<h3>Value</h3>

<p>If <code>ret</code> is <code>TRUE</code> then the value of <code>glmdiag</code> is returned otherwise there is
no returned value.
</p>


<h3>Side Effects</h3>

<p>The current device is cleared and four plots are plotted by use of
<code>split.screen(c(2,2))</code>.  If <code>iden</code> is <code>TRUE</code>, interactive identification of 
points is enabled.  All screens are closed, but not cleared, on termination of 
the function.
</p>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Davison, A.C. and Snell, E.J.  (1991)  Residuals and diagnostics.  In 
<em>Statistical Theory and Modelling: In Honour of Sir David Cox</em>
D.V. Hinkley, N. Reid, and E.J. Snell (editors), 83&ndash;106. Chapman and Hall.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+glm.diag">glm.diag</a></code>, <code><a href="graphics.html#topic+identify">identify</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># In this example we look at the leukaemia data which was looked at in 
# Example 7.1 of Davison and Hinkley (1997)
data(leuk, package = "MASS")
leuk.mod &lt;- glm(time ~ ag-1+log10(wbc), family = Gamma(log), data = leuk)
leuk.diag &lt;- glm.diag(leuk.mod)
glm.diag.plots(leuk.mod, leuk.diag)
</code></pre>

<hr>
<h2 id='gravity'>
Acceleration Due to Gravity
</h2><span id='topic+gravity'></span><span id='topic+grav'></span>

<h3>Description</h3>

<p>The <code>gravity</code> data frame has 81 rows and 2 columns.
</p>
<p>The <code>grav</code> data set has 26 rows and 2 columns.
</p>
<p>Between May 1934 and July 1935, the National Bureau of Standards in
Washington D.C. conducted a series of experiments to estimate the
acceleration due to gravity, <em>g</em>, at Washington.  Each experiment
produced a number of replicate estimates of <em>g</em> using the same
methodology.  Although the basic method remained the same for all
experiments, that of the reversible pendulum, there were changes in
configuration.
</p>
<p>The <code>gravity</code> data frame contains the data from all eight
experiments.  The <code>grav</code> data frame contains the data from the
experiments 7 and 8.  The data are expressed as deviations from 980.000
in centimetres per second squared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gravity
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>g</code></dt><dd>
<p>The deviation of the estimate from 980.000 centimetres per second squared.
</p>
</dd>
<dt><code>series</code></dt><dd>
<p>A factor describing from which experiment the estimate was derived.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Cressie, N. (1982) Playing safe with misweighted means. 
<em>Journal of the American Statistical Association</em>, <b>77</b>, 754&ndash;759.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='hirose'>
Failure Time of PET Film
</h2><span id='topic+hirose'></span>

<h3>Description</h3>

<p>The <code>hirose</code> data frame has 44 rows and 3 columns.
</p>
<p>PET film is used in electrical insulation.  In this accelerated life test
the failure times for 44 samples in gas insulated transformers.  4 different
voltage levels were used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hirose
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>volt</code></dt><dd>
<p>The voltage (in kV).
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>The failure or censoring time in hours.
</p>
</dd>
<dt><code>cens</code></dt><dd>
<p>The censoring indicator; <code>1</code> means right-censored data.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Hirose, H. (1993) Estimation of threshold stress in accelerated life-testing.
<em>IEEE Transactions on Reliability</em>, <b>42</b>, 650&ndash;657.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='Imp.Estimates'>
Importance Sampling Estimates
</h2><span id='topic+Imp.Estimates'></span><span id='topic+imp.moments'></span><span id='topic+imp.prob'></span><span id='topic+imp.quantile'></span><span id='topic+imp.reg'></span>

<h3>Description</h3>

<p>Central moment, tail probability, and quantile estimates for a statistic
under importance resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imp.moments(boot.out = NULL, index = 1, t = boot.out$t[, index], 
            w = NULL, def = TRUE, q = NULL)
imp.prob(boot.out = NULL, index = 1, t0 = boot.out$t0[index], 
         t = boot.out$t[, index], w = NULL, def = TRUE, q = NULL)
imp.quantile(boot.out = NULL, alpha = NULL, index = 1, 
             t = boot.out$t[, index], w = NULL, def = TRUE, q = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Imp.Estimates_+3A_boot.out">boot.out</code></td>
<td>

<p>A object of class <code>"boot"</code> generated by a call to <code>boot</code> or
<code>tilt.boot</code>. Use of these functions makes sense only when the
bootstrap resampling used unequal weights for the observations.  If the
importance weights <code>w</code> are not supplied then <code>boot.out</code> is a
required argument. It is also required if <code>t</code> is not supplied.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_alpha">alpha</code></td>
<td>

<p>The alpha levels for the required quantiles.  The default is to calculate
the 1%, 2.5%, 5%, 10%, 90%, 95%, 97.5% and 99% quantiles.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_index">index</code></td>
<td>

<p>The index of the variable of interest in the output of
<code>boot.out$statistic</code>.  This is not used if the argument
<code>t</code> is supplied.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_t0">t0</code></td>
<td>

<p>The values at which tail probability estimates are required.  For
each value <code>t0[i]</code> the function will estimate the bootstrap cdf
evaluated at <code>t0[i]</code>.  If <code>imp.prob</code> is called without the
argument <code>t0</code> then the bootstrap cdf evaluated at the observed
value of the statistic is found.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_t">t</code></td>
<td>

<p>The bootstrap replicates of a statistic.  By default these are taken
from the bootstrap output object <code>boot.out</code> but they can be
supplied separately if required (e.g. when the statistic of interest
is a function of the calculated values in <code>boot.out</code>).  Either
<code>boot.out</code> or <code>t</code> must be supplied.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_w">w</code></td>
<td>

<p>The importance resampling weights for the bootstrap replicates.  If they are
not supplied then <code>boot.out</code> must be supplied, in which case
the importance weights are calculated by a call to
<code>imp.weights</code>.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_def">def</code></td>
<td>

<p>A logical value indicating whether a defensive mixture is to be used
for weight calculation.  This is used only if <code>w</code> is missing
and it is passed unchanged to <code>imp.weights</code> to calculate
<code>w</code>.
</p>
</td></tr>
<tr><td><code id="Imp.Estimates_+3A_q">q</code></td>
<td>

<p>A vector of probabilities specifying the resampling distribution
from which any estimates should be found.  In general this would
correspond to the usual bootstrap resampling distribution which
gives equal weight to each of the original observations. The
estimates depend on this distribution only through the importance
weights <code>w</code> so this argument is ignored if <code>w</code> is
supplied.  If <code>w</code> is missing then <code>q</code> is passed as an
argument to <code>imp.weights</code> and used to find <code>w</code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components :
</p>
<table>
<tr><td><code>alpha</code></td>
<td>

<p>The <code>alpha</code> levels used for the quantiles, if
<code>imp.quantile</code> is used.
</p>
</td></tr>
<tr><td><code>t0</code></td>
<td>

<p>The values at which the tail probabilities are estimated, if
<code>imp.prob</code> is used.
</p>
</td></tr>
<tr><td><code>raw</code></td>
<td>

<p>The raw importance resampling estimates.  For <code>imp.moments</code>
this has length 2, the first component being the estimate of the
mean and the second being the variance estimate.  For
<code>imp.prob</code>, <code>raw</code> is of the same length as <code>t0</code>, and
for <code>imp.quantile</code> it is of the same length as <code>alpha</code>.
</p>
</td></tr>
<tr><td><code>rat</code></td>
<td>

<p>The ratio importance resampling estimates.  In this method the
weights <code>w</code> are rescaled to have average value one before they
are used.  The format of this vector is the same as <code>raw</code>.
</p>
</td></tr>
<tr><td><code>reg</code></td>
<td>

<p>The regression importance resampling estimates.  In this method the weights
which are used are derived from a regression of <code>t*w</code> on
<code>w</code>.  This choice of weights can be shown to minimize the
variance of the weights and also the Euclidean distance of the
weights from the uniform weights.  The format of this vector is the
same as <code>raw</code>.
</p>
</td></tr></table>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Hesterberg, T. (1995) Weighted average importance sampling and defensive 
mixture distributions. <em>Technometrics</em>, <b>37</b>, 185&ndash;194.
</p>
<p>Johns, M.V.  (1988) Importance sampling for bootstrap confidence intervals.
<em>Journal of the American Statistical Association</em>, <b>83</b>, 709&ndash;714.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+exp.tilt">exp.tilt</a></code>, <code><a href="#topic+imp.weights">imp.weights</a></code>,
<code><a href="#topic+smooth.f">smooth.f</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 9.8 of Davison and Hinkley (1997) requires tilting the 
# resampling distribution of the studentized statistic to be centred 
# at the observed value of the test statistic, 1.84.  In this example
# we show how certain estimates can be found using resamples taken from
# the tilted distribution.
grav1 &lt;- gravity[as.numeric(gravity[,2]) &gt;= 7, ]
grav.fun &lt;- function(dat, w, orig) {
     strata &lt;- tapply(dat[, 2], as.numeric(dat[, 2]))
     d &lt;- dat[, 1]
     ns &lt;- tabulate(strata)
     w &lt;- w/tapply(w, strata, sum)[strata]
     mns &lt;- as.vector(tapply(d * w, strata, sum)) # drop names
     mn2 &lt;- tapply(d * d * w, strata, sum)
     s2hat &lt;- sum((mn2 - mns^2)/ns)
     c(mns[2] - mns[1], s2hat, (mns[2] - mns[1] - orig)/sqrt(s2hat))
}
grav.z0 &lt;- grav.fun(grav1, rep(1, 26), 0)
grav.L &lt;- empinf(data = grav1, statistic = grav.fun, stype = "w", 
                 strata = grav1[,2], index = 3, orig = grav.z0[1])
grav.tilt &lt;- exp.tilt(grav.L, grav.z0[3], strata = grav1[, 2])
grav.tilt.boot &lt;- boot(grav1, grav.fun, R = 199, stype = "w", 
                       strata = grav1[, 2], weights = grav.tilt$p,
                       orig = grav.z0[1])
# Since the weights are needed for all calculations, we shall calculate
# them once only.
grav.w &lt;- imp.weights(grav.tilt.boot)
grav.mom &lt;- imp.moments(grav.tilt.boot, w = grav.w, index = 3)
grav.p &lt;- imp.prob(grav.tilt.boot, w = grav.w, index = 3, t0 = grav.z0[3])
unlist(grav.p)
grav.q &lt;- imp.quantile(grav.tilt.boot, w = grav.w, index = 3, 
                       alpha = c(0.9, 0.95, 0.975, 0.99))
as.data.frame(grav.q)
</code></pre>

<hr>
<h2 id='imp.weights'>
Importance Sampling Weights
</h2><span id='topic+imp.weights'></span>

<h3>Description</h3>

<p>This function calculates the importance sampling weight required to correct
for simulation from a distribution with probabilities <code>p</code> when estimates 
are required assuming that simulation was from an alternative distribution 
with probabilities <code>q</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imp.weights(boot.out, def = TRUE, q = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imp.weights_+3A_boot.out">boot.out</code></td>
<td>

<p>A object of class <code>"boot"</code> generated by <code>boot</code> or <code>tilt.boot</code>.  Typically the 
bootstrap simulations would have
been done using importance resampling and we wish to do our calculations
under the assumption of sampling with equal probabilities.
</p>
</td></tr>
<tr><td><code id="imp.weights_+3A_def">def</code></td>
<td>

<p>A logical variable indicating whether the defensive mixture distribution
weights should be calculated.  This makes sense only in the case where the 
replicates in <code>boot.out</code> were simulated under a number of different 
distributions.  If this is the case then the defensive mixture weights use a 
mixture of the distributions used in the bootstrap.  The alternative is to 
calculate the weights for each replicate using knowledge of the distribution 
from which the bootstrap resample was generated.
</p>
</td></tr>
<tr><td><code id="imp.weights_+3A_q">q</code></td>
<td>

<p>A vector of probabilities specifying the resampling distribution from which 
we require inferences to be made. In general this would correspond to the usual
bootstrap resampling distribution which gives equal weight to each of the 
original observations and this is the default.  <code>q</code> must have length equal
to the number of observations in the <code>boot.out$data</code> and all elements of <code>q</code>
must be positive.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The importance sampling weight for a bootstrap replicate with frequency
vector <code>f</code> is given by <code>prod((q/p)^f)</code>.  This reweights the replicates so that
estimates can be found as if the bootstrap resamples were generated according
to the probabilities <code>q</code> even though, in fact, they came from the 
distribution <code>p</code>.
</p>


<h3>Value</h3>

<p>A vector of importance weights of the same length as <code>boot.out$t</code>.  These 
weights can then be used to reweight <code>boot.out$t</code> so that estimates can be 
found as if the simulations were from a distribution with probabilities <code>q</code>.
</p>


<h3>Note</h3>

<p>See the example in the help for <code>imp.moments</code> for an example of using 
<code>imp.weights</code>.
</p>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Hesterberg, T. (1995) Weighted average importance sampling and defensive 
mixture distributions. <em>Technometrics</em>, <b>37</b>, 185&ndash;194.
</p>
<p>Johns, M.V.  (1988) Importance sampling for bootstrap confidence intervals.
<em>Journal of the American Statistical Association</em>, <b>83</b>, 709&ndash;714.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+exp.tilt">exp.tilt</a></code>, <code><a href="#topic+imp.moments">imp.moments</a></code>, <code><a href="#topic+smooth.f">smooth.f</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code>
</p>

<hr>
<h2 id='inv.logit'>
Inverse Logit Function
</h2><span id='topic+inv.logit'></span>

<h3>Description</h3>

<p>Given a numeric object return the inverse logit of the values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.logit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv.logit_+3A_x">x</code></td>
<td>

<p>A numeric object. Missing values (<code>NA</code>s) are allowed.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The inverse logit is defined by <code>exp(x)/(1+exp(x))</code>.  Values in <code>x</code> of
<code>-Inf</code> or <code>Inf</code> return logits of 0 or 1 respectively.  Any <code>NA</code>s in the input 
will also be <code>NA</code>s in the output.
</p>


<h3>Value</h3>

<p>An object of the same type as <code>x</code> containing the inverse logits of the
input values.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logit">logit</a></code>, <code><a href="stats.html#topic+plogis">plogis</a></code> for which this is a wrapper.
</p>

<hr>
<h2 id='islay'>
Jura Quartzite Azimuths on Islay
</h2><span id='topic+islay'></span>

<h3>Description</h3>

<p>The <code>islay</code> data frame has 18 rows and 1 columns.
</p>
<p>Measurements were taken of paleocurrent azimuths from the Jura Quartzite on
the Scottish island of Islay.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>islay
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following column:
</p>

<dl>
<dt><code>theta</code></dt><dd>
<p>The angle of the azimuth in degrees East of North.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Hand, D.J., Daly, F., Lunn, A.D., McConway, K.J. and Ostrowski, E. (1994)
<em>A Handbook of Small Data Sets</em>, Chapman and Hall.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Till, R. (1974) <em>Statistical Methods for the Earth Scientist</em>. Macmillan.
</p>

<hr>
<h2 id='jack.after.boot'>
Jackknife-after-Bootstrap Plots
</h2><span id='topic+jack.after.boot'></span>

<h3>Description</h3>

<p>This function calculates the jackknife influence values from a bootstrap
output object and plots the corresponding jackknife-after-bootstrap plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jack.after.boot(boot.out, index = 1, t = NULL, L = NULL,
                useJ = TRUE, stinf = TRUE, alpha = NULL,
                main = "", ylab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jack.after.boot_+3A_boot.out">boot.out</code></td>
<td>

<p>An object of class <code>"boot"</code> which would normally be created by a call
to <code><a href="#topic+boot">boot</a></code>. It should represent a nonparametric bootstrap.
For reliable results <code>boot.out$R</code> should be reasonably large.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_index">index</code></td>
<td>

<p>The index of the statistic of interest in the output of <code>boot.out$statistic</code>.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_t">t</code></td>
<td>

<p>A vector of length <code>boot.out$R</code> giving the bootstrap replicates of the statistic
of interest.  This is useful if the statistic of interest is a function of 
the calculated bootstrap output.  If it is not supplied then the default is
<code>boot.out$t[,index]</code>.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_l">L</code></td>
<td>

<p>The empirical influence values for the statistic of interest.  These are used
only if <code>useJ</code> is <code>FALSE</code>.  If they are not supplied and are needed, they are
calculated by a call to <code>empinf</code>.  If <code>L</code> is supplied then it is assumed that
they are the infinitesimal jackknife values.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_usej">useJ</code></td>
<td>

<p>A logical variable indicating if the jackknife influence values calculated from
the bootstrap replicates should be used.  If <code>FALSE</code> the empirical influence
values are used.  The default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_stinf">stinf</code></td>
<td>

<p>A logical variable indicating whether to standardize the jackknife values
before plotting them.  If <code>TRUE</code> then the jackknife values used are divided by 
their standard error.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_alpha">alpha</code></td>
<td>

<p>The quantiles at which the plots are required.  The default is 
<code>c(0.05, 0.1, 0.16, 0.5, 0.84, 0.9, 0.95)</code>.  
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_main">main</code></td>
<td>

<p>A character string giving the main title for the plot.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_ylab">ylab</code></td>
<td>

<p>The label for the Y axis.  If the default values of <code>alpha</code> are used and <code>ylab</code>
is not supplied then a label indicating which percentiles are plotted is used.
If <code>alpha</code> is supplied then the default label will not say which percentiles
were used.
</p>
</td></tr>
<tr><td><code id="jack.after.boot_+3A_...">...</code></td>
<td>

<p>Any extra arguments required by <code>boot.out$statistic</code>.  These are required only
if <code>useJ</code> is <code>FALSE</code> and <code>L</code> is not supplied, in which case they are passed to
<code>empinf</code> for use in calculation of the empirical influence values.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The centred jackknife quantiles for each observation are estimated from those 
bootstrap samples in which  the particular observation did not appear.  These 
are then plotted against the influence values.  If <code>useJ</code> is <code>TRUE</code> then the
influence values are found in the same way as the difference between the 
mean of the statistic in the samples excluding the observations and the mean in 
all samples.  If <code>useJ</code> is <code>FALSE</code> then empirical influence values are 
calculated by calling <code>empinf</code>.
</p>
<p>The resulting plots are useful diagnostic tools for looking at the way
individual observations affect the bootstrap output.
</p>
<p>The plot will consist of a number of horizontal dotted lines which correspond
to the quantiles of the centred bootstrap distribution.  For each data point
the quantiles of the bootstrap distribution calculated by omitting that point
are plotted against the (possibly standardized) jackknife values.  The 
observation number is printed below the plots.  To make it easier to see 
the effect of omitting points on quantiles, the plotted quantiles are joined
by line segments.  These plots provide a useful diagnostic tool in
establishing the effect of individual observations on the bootstrap 
distribution.  See the references below for some guidelines on the 
interpretation of the plots.
</p>


<h3>Value</h3>

<p>There is no returned value but a plot is generated on the current graphics
display.
</p>


<h3>Side Effects</h3>

<p>A plot is created on the current graphics device.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Efron, B. (1992) Jackknife-after-bootstrap standard errors and influence 
functions (with Discussion). 
<em>Journal of the Royal Statistical Society, B</em>, <b>54</b>, 83&ndash;127.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+empinf">empinf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  To draw the jackknife-after-bootstrap plot for the head size data as in
#  Example 3.24 of Davison and Hinkley (1997)
frets.fun &lt;- function(data, i) {
    pcorr &lt;- function(x) { 
    #  Function to find the correlations and partial correlations between
    #  the four measurements.
         v &lt;- cor(x)
         v.d &lt;- diag(var(x))
         iv &lt;- solve(v)
         iv.d &lt;- sqrt(diag(iv))
         iv &lt;- - diag(1/iv.d) %*% iv %*% diag(1/iv.d)
         q &lt;- NULL
         n &lt;- nrow(v)
         for (i in 1:(n-1)) 
              q &lt;- rbind( q, c(v[i, 1:i], iv[i,(i+1):n]) )
         q &lt;- rbind( q, v[n, ] )
         diag(q) &lt;- round(diag(q))
         q
    }
    d &lt;- data[i, ]
    v &lt;- pcorr(d)
    c(v[1,], v[2,], v[3,], v[4,])
}
frets.boot &lt;- boot(log(as.matrix(frets)), frets.fun, R = 999)
#  we will concentrate on the partial correlation between head breadth
#  for the first son and head length for the second.  This is the 7th
#  element in the output of frets.fun so we set index = 7
jack.after.boot(frets.boot, useJ = FALSE, stinf = FALSE, index = 7)
</code></pre>

<hr>
<h2 id='k3.linear'>
Linear Skewness Estimate
</h2><span id='topic+k3.linear'></span>

<h3>Description</h3>

<p>Estimates the skewness of a statistic from its empirical influence values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k3.linear(L, strata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k3.linear_+3A_l">L</code></td>
<td>

<p>Vector of the empirical influence values of a statistic.  These will usually
be calculated by a call to <code>empinf</code>.
</p>
</td></tr>
<tr><td><code id="k3.linear_+3A_strata">strata</code></td>
<td>

<p>A numeric vector or factor specifying which observations (and hence which
components of <code>L</code>) come from which strata.
</p>
</td></tr></table>


<h3>Value</h3>

<p>The skewness estimate calculated from <code>L</code>.
</p>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+empinf">empinf</a></code>, <code><a href="#topic+linear.approx">linear.approx</a></code>, <code><a href="#topic+var.linear">var.linear</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  To estimate the skewness of the ratio of means for the city data.
ratio &lt;- function(d, w) sum(d$x * w)/sum(d$u * w)
k3.linear(empinf(data = city, statistic = ratio))
</code></pre>

<hr>
<h2 id='linear.approx'>
Linear Approximation of Bootstrap Replicates
</h2><span id='topic+linear.approx'></span>

<h3>Description</h3>

<p>This function takes a bootstrap object and for each bootstrap replicate
it calculates the linear approximation to the statistic of interest for 
that bootstrap sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear.approx(boot.out, L = NULL, index = 1, type = NULL,
              t0 = NULL, t = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linear.approx_+3A_boot.out">boot.out</code></td>
<td>

<p>An object of class <code>"boot"</code> representing a nonparametric bootstrap.  It will
usually be created by the function <code>boot</code>.
</p>
</td></tr>
<tr><td><code id="linear.approx_+3A_l">L</code></td>
<td>

<p>A vector containing the empirical influence values for the statistic of
interest.  If it is not supplied then <code>L</code> is calculated through a call 
to <code>empinf</code>.
</p>
</td></tr>
<tr><td><code id="linear.approx_+3A_index">index</code></td>
<td>

<p>The index of the variable of interest within the output of 
<code>boot.out$statistic</code>. 
</p>
</td></tr>
<tr><td><code id="linear.approx_+3A_type">type</code></td>
<td>

<p>This gives the type of empirical influence values to be calculated.  It is
not used if <code>L</code> is supplied.  The possible types of empirical influence
values are described in the help for <code><a href="#topic+empinf">empinf</a></code>.
</p>
</td></tr>
<tr><td><code id="linear.approx_+3A_t0">t0</code></td>
<td>

<p>The observed value of the statistic of interest.  The input value is used only 
if one of <code>t</code> or <code>L</code> is also supplied.  The default value is 
<code>boot.out$t0[index]</code>.  If <code>t0</code> is supplied but neither <code>t</code> nor <code>L</code> are supplied
then <code>t0</code> is set to <code>boot.out$t0[index]</code> and a warning is generated.
</p>
</td></tr>
<tr><td><code id="linear.approx_+3A_t">t</code></td>
<td>

<p>A vector of bootstrap replicates of the statistic of interest.  If <code>t0</code> is 
missing then <code>t</code> is not used, otherwise it is used to calculate the empirical 
influence values (if they are not supplied in <code>L</code>).  
</p>
</td></tr>
<tr><td><code id="linear.approx_+3A_...">...</code></td>
<td>

<p>Any extra arguments required by <code>boot.out$statistic</code>.  These are needed if
<code>L</code> is not supplied as they are used by <code>empinf</code> to calculate empirical 
influence values.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The linear approximation to a bootstrap replicate with frequency vector <code>f</code>
is given by <code>t0 + sum(L * f)/n</code> in the one sample with an easy extension
to the stratified case.  The frequencies are found by calling <code>boot.array</code>.
</p>


<h3>Value</h3>

<p>A vector of length <code>boot.out$R</code> with the linear approximations to the
statistic of interest for each of the bootstrap samples.  
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+empinf">empinf</a></code>, <code><a href="#topic+control">control</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using the city data let us look at the linear approximation to the 
# ratio statistic and its logarithm. We compare these with the 
# corresponding plots for the bigcity data 

ratio &lt;- function(d, w) sum(d$x * w)/sum(d$u * w)
city.boot &lt;- boot(city, ratio, R = 499, stype = "w")
bigcity.boot &lt;- boot(bigcity, ratio, R = 499, stype = "w")
op &lt;- par(pty = "s", mfrow = c(2, 2))

# The first plot is for the city data ratio statistic.
city.lin1 &lt;- linear.approx(city.boot)
lim &lt;- range(c(city.boot$t,city.lin1))
plot(city.boot$t, city.lin1, xlim = lim, ylim = lim, 
     main = "Ratio; n=10", xlab = "t*", ylab = "tL*")
abline(0, 1)

# Now for the log of the ratio statistic for the city data.
city.lin2 &lt;- linear.approx(city.boot,t0 = log(city.boot$t0), 
                           t = log(city.boot$t))
lim &lt;- range(c(log(city.boot$t),city.lin2))
plot(log(city.boot$t), city.lin2, xlim = lim, ylim = lim, 
     main = "Log(Ratio); n=10", xlab = "t*", ylab = "tL*")
abline(0, 1)

# The ratio statistic for the bigcity data.
bigcity.lin1 &lt;- linear.approx(bigcity.boot)
lim &lt;- range(c(bigcity.boot$t,bigcity.lin1))
plot(bigcity.lin1, bigcity.boot$t, xlim = lim, ylim = lim,
     main = "Ratio; n=49", xlab = "t*", ylab = "tL*")
abline(0, 1)

# Finally the log of the ratio statistic for the bigcity data.
bigcity.lin2 &lt;- linear.approx(bigcity.boot,t0 = log(bigcity.boot$t0), 
                              t = log(bigcity.boot$t))
lim &lt;- range(c(log(bigcity.boot$t),bigcity.lin2))
plot(bigcity.lin2, log(bigcity.boot$t), xlim = lim, ylim = lim,
     main = "Log(Ratio); n=49", xlab = "t*", ylab = "tL*")
abline(0, 1)

par(op)
</code></pre>

<hr>
<h2 id='lines.saddle.distn'>
Add a Saddlepoint Approximation to a Plot
</h2><span id='topic+lines.saddle.distn'></span>

<h3>Description</h3>

<p>This function adds a line corresponding to a saddlepoint density or 
distribution function approximation to the current plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'saddle.distn'
lines(x, dens = TRUE, h = function(u) u, J = function(u) 1, 
      npts = 50, lty = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lines.saddle.distn_+3A_x">x</code></td>
<td>

<p>An object of class <code>"saddle.distn"</code>  (see
<code><a href="#topic+saddle.distn.object">saddle.distn.object</a></code> representing a saddlepoint
approximation to a distribution.
</p>
</td></tr>
<tr><td><code id="lines.saddle.distn_+3A_dens">dens</code></td>
<td>

<p>A logical variable indicating whether the saddlepoint density
(<code>TRUE</code>; the default) or the saddlepoint distribution function
(<code>FALSE</code>) should be plotted.
</p>
</td></tr>
<tr><td><code id="lines.saddle.distn_+3A_h">h</code></td>
<td>

<p>Any transformation of the variable that is required.  Its first argument
must be the value at which the approximation is being performed and the
function must be vectorized.
</p>
</td></tr>
<tr><td><code id="lines.saddle.distn_+3A_j">J</code></td>
<td>

<p>When <code>dens=TRUE</code> this function specifies the Jacobian for any
transformation that may be necessary.  The first argument of <code>J</code>
must the value at which the approximation is being performed and the
function must be vectorized. If <code>h</code> is supplied <code>J</code> must
also be supplied and both must have the same argument list.
</p>
</td></tr>
<tr><td><code id="lines.saddle.distn_+3A_npts">npts</code></td>
<td>

<p>The number of points to be used for the plot.  These points will be evenly
spaced over the range of points used in finding the saddlepoint
approximation.
</p>
</td></tr>
<tr><td><code id="lines.saddle.distn_+3A_lty">lty</code></td>
<td>

<p>The line type to be used.
</p>
</td></tr>
<tr><td><code id="lines.saddle.distn_+3A_...">...</code></td>
<td>

<p>Any additional arguments to <code>h</code> and <code>J</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses <code>smooth.spline</code> to produce the saddlepoint
curve.  When <code>dens=TRUE</code> the spline is on the log scale and when
<code>dens=FALSE</code> it is on the probit scale.
</p>


<h3>Value</h3>

<p><code>sad.d</code> is returned invisibly.
</p>


<h3>Side Effects</h3>

<p>A line is added to the current plot.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+saddle.distn">saddle.distn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># In this example we show how a plot such as that in Figure 9.9 of
# Davison and Hinkley (1997) may be produced.  Note the large number of
# bootstrap replicates required in this example.
expdata &lt;- rexp(12)
vfun &lt;- function(d, i) {
     n &lt;- length(d)
     (n-1)/n*var(d[i])
}
exp.boot &lt;- boot(expdata,vfun, R = 9999)
exp.L &lt;- (expdata - mean(expdata))^2 - exp.boot$t0
exp.tL &lt;- linear.approx(exp.boot, L = exp.L)
hist(exp.tL, nclass = 50, probability = TRUE)
exp.t0 &lt;- c(0, sqrt(var(exp.boot$t)))
exp.sp &lt;- saddle.distn(A = exp.L/12,wdist = "m", t0 = exp.t0)

# The saddlepoint approximation in this case is to the density of
# t-t0 and so t0 must be added for the plot.
lines(exp.sp, h = function(u, t0) u+t0, J = function(u, t0) 1,
      t0 = exp.boot$t0)
</code></pre>

<hr>
<h2 id='logit'>
Logit of Proportions
</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>This function calculates the logit of proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_+3A_p">p</code></td>
<td>

<p>A numeric Splus object, all of whose values are in the range [0,1].  Missing
values (<code>NA</code>s) are allowed.
</p>
</td></tr></table>


<h3>Details</h3>

<p>If any elements of <code>p</code> are outside the unit interval then an error message
is generated.  Values of <code>p</code> equal to 0 or 1 (to within machine precision)
will return <code>-Inf</code> or <code>Inf</code> respectively.  Any <code>NA</code>s in the input will also
be <code>NA</code>s in the output.
</p>


<h3>Value</h3>

<p>A numeric object of the same type as <code>p</code> containing the logits of the input
values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inv.logit">inv.logit</a></code>, <code><a href="stats.html#topic+qlogis">qlogis</a></code> for which this is a wrapper.
</p>

<hr>
<h2 id='manaus'>
Average Heights of the Rio Negro river at Manaus
</h2><span id='topic+manaus'></span>

<h3>Description</h3>

<p>The <code>manaus</code> time series is of class <code>"ts"</code> and has
1080 observations on one variable.
</p>
<p>The data values are monthly averages of the daily stages (heights) of
the Rio Negro at Manaus.  Manaus is 18km upstream from the confluence of
the Rio Negro with the Amazon but because of the tiny slope of the water
surface and the lower courses of its flatland affluents, they may be
regarded as a good approximation of the water level in the Amazon at the
confluence.  The data here cover 90 years from January 1903 until
December 1992.
</p>
<p>The Manaus gauge is tied in with an arbitrary bench mark of 100m set in
the steps of the Municipal Prefecture; gauge readings are usually
referred to sea level, on the basis of a mark on the steps leading to
the Parish Church (Matriz), which is assumed to lie at an altitude of
35.874 m according to observations made many years ago under the
direction of Samuel Pereira, an engineer in charge of the Manaus
Sanitation Committee Whereas such an altitude cannot, by any means, be
considered to be a precise datum point, observations have been
provisionally referred to it.  The measurements are in metres.
</p>


<h3>Source</h3>

<p>The data were kindly made available by Professors H. O'Reilly Sternberg and 
D. R. Brillinger of the University of California at Berkeley.  
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Sternberg, H. O'R. (1987) Aggravation of floods in the Amazon river as a
consequence of deforestation? <em>Geografiska Annaler</em>, <b>69A</b>, 201-219.
</p>
<p>Sternberg, H. O'R. (1995) Waters and wetlands of Brazilian Amazonia: An
uncertain future. In <em>The Fragile Tropics of Latin America:
Sustainable Management of Changing Environments</em>, Nishizawa, T. and
Uitto, J.I. (editors), United Nations University Press, 113-179.
</p>

<hr>
<h2 id='melanoma'>
Survival from Malignant Melanoma
</h2><span id='topic+melanoma'></span>

<h3>Description</h3>

<p>The <code>melanoma</code> data frame has 205 rows and 7 columns.
</p>
<p>The data consist of measurements made on patients with malignant melanoma.
Each patient had their tumour removed by surgery at the Department of Plastic
Surgery, University Hospital of Odense, Denmark during the period 1962 to 1977.
The surgery consisted of complete removal of the tumour together with about
2.5cm of the surrounding skin.  Among the measurements taken were the thickness
of the tumour and whether it was ulcerated or not.  These are thought to be
important prognostic variables in that patients with a thick and/or ulcerated
tumour have an increased chance of death from melanoma.
Patients were followed until the end of 1977.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melanoma
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>time</code></dt><dd>
<p>Survival time in days since the operation, possibly censored.
</p>
</dd>
<dt><code>status</code></dt><dd>
<p>The patients status at the end of the study. 1 indicates that they had died
from melanoma, 2 indicates that they were still alive and 3 indicates that they
had died from causes unrelated to their melanoma.
</p>
</dd>
<dt><code>sex</code></dt><dd>
<p>The patients sex; 1=male, 0=female.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>Age in years at the time of the operation.
</p>
</dd>
<dt><code>year</code></dt><dd>
<p>Year of operation.
</p>
</dd>
<dt><code>thickness</code></dt><dd>
<p>Tumour thickness in mm.
</p>
</dd>
<dt><code>ulcer</code></dt><dd>
<p>Indicator of ulceration; 1=present, 0=absent.
</p>
</dd></dl>


<h3>Note</h3>

<p>This dataset is not related to the dataset in the <span class="pkg">lattice</span> package
with the same name.
</p>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Andersen, P.K., Borgan, O., Gill, R.D. and Keiding, N. (1993)
<em>Statistical Models Based on Counting Processes</em>. Springer-Verlag.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Venables, W.N. and Ripley, B.D. (1994) 
<em>Modern Applied Statistics with S-Plus</em>. Springer-Verlag.
</p>

<hr>
<h2 id='motor'>
Data from a Simulated Motorcycle Accident
</h2><span id='topic+motor'></span>

<h3>Description</h3>

<p>The <code>motor</code> data frame has 94 rows and 4 columns.  The rows are
obtained by removing replicate values of <code>time</code> from the dataset 
<code><a href="MASS.html#topic+mcycle">mcycle</a></code>.  Two extra columns are added to allow for strata with
a different residual variance in each stratum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>motor
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>times</code></dt><dd>
<p>The time in milliseconds since impact.
</p>
</dd>
<dt><code>accel</code></dt><dd>
<p>The recorded head acceleration (in g).
</p>
</dd>
<dt><code>strata</code></dt><dd>
<p>A numeric column indicating to which of the three strata (numbered 1, 2 and 3)
the observations belong.
</p>
</dd>
<dt><code>v</code></dt><dd>
<p>An estimate of the residual variance for the observation.  <code>v</code> is constant
within the strata but a different
estimate is used for each of the three strata.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Silverman, B.W. (1985) Some aspects of the spline smoothing approach to
non-parametric curve fitting. 
<em>Journal of the Royal Statistical Society, B</em>, <b>47</b>, 1&ndash;52.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Venables, W.N. and Ripley, B.D. (1994) 
<em>Modern Applied Statistics with S-Plus</em>. Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+mcycle">mcycle</a></code>
</p>

<hr>
<h2 id='neuro'>
Neurophysiological Point Process Data
</h2><span id='topic+neuro'></span>

<h3>Description</h3>

<p><code>neuro</code> is a matrix containing times of observed firing of a neuron in windows
of 250ms either side of the application of a stimulus to a human subject.
Each row of the matrix is a replication of the experiment and there were a 
total of 469 replicates.
</p>


<h3>Note</h3>

<p>There are a lot of missing values in the matrix as different numbers of 
firings 
were observed in different replicates.  The number of firings observed varied 
from 2 to 6.
</p>


<h3>Source</h3>

<p>The data were collected and kindly made available by Dr. S.J. Boniface of the
Neurophysiology Unit at the Radcliffe Infirmary, Oxford.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Ventura, V., Davison, A.C. and Boniface, S.J. (1997) A stochastic model for 
the effect of magnetic brain stimulation on a motorneurone. To appear in
<em>Applied Statistics</em>. 
</p>

<hr>
<h2 id='nitrofen'>
Toxicity of Nitrofen in Aquatic Systems
</h2><span id='topic+nitrofen'></span>

<h3>Description</h3>

<p>The <code>nitrofen</code> data frame has 50 rows and 5 columns.
</p>
<p>Nitrofen is a herbicide that was used extensively for the control of 
broad-leaved and grass weeds in cereals and rice. Although it is relatively
non-toxic to adult mammals, nitrofen is a significant tetragen and mutagen.
It is also acutely toxic and reproductively toxic to cladoceran zooplankton.
Nitrofen is no longer in commercial use in the U.S., having been the first
pesticide to be withdrawn due to tetragenic effects.
</p>
<p>The data here come from an experiment to measure the reproductive toxicity
of nitrofen on a species of zooplankton (<em>Ceriodaphnia dubia</em>).  50 animals
were randomized into batches of 10 and each batch was put in a solution with
a measured concentration of nitrofen.  Then the number of live offspring in
each of the three broods to each animal was recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nitrofen
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>conc</code></dt><dd>
<p>The nitrofen concentration in the solution (mug/litre).
</p>
</dd>
<dt><code>brood1</code></dt><dd>
<p>The number of live offspring in the first brood.
</p>
</dd>
<dt><code>brood2</code></dt><dd>
<p>The number of live offspring in the second brood.
</p>
</dd>
<dt><code>brood3</code></dt><dd>
<p>The number of live offspring in the third brood.
</p>
</dd>
<dt><code>total</code></dt><dd>
<p>The total number of live offspring in the first three broods.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Bailer, A.J. and Oris, J.T. (1994) Assessing toxicity of pollutants in aquatic 
systems. In <em>Case Studies in Biometry</em>. N. Lange, L. Ryan, L. Billard,
D. Brillinger, L. Conquest and J. Greenhouse (editors), 25&ndash;40. John Wiley.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='nodal'>
Nodal Involvement in Prostate Cancer
</h2><span id='topic+nodal'></span>

<h3>Description</h3>

<p>The <code>nodal</code> data frame has 53 rows and 7 columns.
</p>
<p>The treatment strategy for a patient diagnosed with cancer of the prostate
depend highly on whether the cancer has spread to the surrounding lymph nodes.
It is common to operate on the patient to get samples from the nodes which can
then be analysed under a microscope but clearly it would be preferable if an
accurate assessment of nodal involvement could be made without surgery.
</p>
<p>For a sample of 53 prostate cancer patients, a number of possible predictor
variables were measured before surgery.  The patients then had surgery to 
determine nodal involvement.  It was required to see if nodal involvement could 
be accurately predicted from the predictor variables and which ones were
most important.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nodal
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>m</code></dt><dd>
<p>A column of ones.
</p>
</dd>
<dt><code>r</code></dt><dd>
<p>An indicator of nodal involvement. 
</p>
</dd>
<dt><code>aged</code></dt><dd>
<p>The patients age dichotomized into less than 60 (<code>0</code>) and 60 or over <code>1</code>.
</p>
</dd>
<dt><code>stage</code></dt><dd>
<p>A measurement of the size and position of the tumour observed by palpitation
with the fingers via the rectum.  A value of <code>1</code> indicates a more serious
case of the cancer.
</p>
</dd>
<dt><code>grade</code></dt><dd>
<p>Another indicator of the seriousness of the cancer, this one is determined by
a pathology reading of a biopsy taken by needle before surgery.
A value of <code>1</code> indicates a more serious case of the cancer.
</p>
</dd>
<dt><code>xray</code></dt><dd>
<p>A third measure of the seriousness of the cancer taken from an X-ray reading.
A value of <code>1</code> indicates a more serious case of the cancer.
</p>
</dd>
<dt><code>acid</code></dt><dd>
<p>The level of acid phosphatase in the blood serum.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Brown, B.W. (1980) Prediction analysis for binary data. In 
<em>Biostatistics Casebook</em>.
R.G. Miller, B. Efron, B.W. Brown and L.E. Moses (editors),
3&ndash;18. John Wiley.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='norm.ci'>
Normal Approximation Confidence Intervals
</h2><span id='topic+norm.ci'></span>

<h3>Description</h3>

<p>Using the normal approximation to a statistic, calculate equi-tailed two-sided 
confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.ci(boot.out = NULL, conf = 0.95, index = 1, var.t0 = NULL, 
        t0 = NULL, t = NULL, L = NULL, h = function(t) t, 
        hdot = function(t) 1, hinv = function(t) t)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm.ci_+3A_boot.out">boot.out</code></td>
<td>

<p>A bootstrap output object returned from a call to <code>boot</code>.  If
<code>t0</code> is missing then <code>boot.out</code> is a required argument.  It is
also required if both <code>var.t0</code> and <code>t</code> are missing.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_conf">conf</code></td>
<td>

<p>A scalar or vector containing the confidence level(s) of the required 
interval(s).
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_index">index</code></td>
<td>

<p>The index of the statistic of interest within the output of a call to
<code>boot.out$statistic</code>.  It is not used if <code>boot.out</code> is
missing, in which case <code>t0</code> must be supplied.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_var.t0">var.t0</code></td>
<td>

<p>The variance of the statistic of interest.  If it is not supplied then 
<code>var(t)</code> is used.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_t0">t0</code></td>
<td>

<p>The observed value of the statistic of interest.  If it is missing then it is
taken from <code>boot.out</code> which is required in that case.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_t">t</code></td>
<td>

<p>Bootstrap replicates of the variable of interest.  These are used to estimate 
the variance of the statistic of interest if <code>var.t0</code> is not
supplied.  The default value is <code>boot.out$t[,index]</code>.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_l">L</code></td>
<td>

<p>The empirical influence values for the statistic of interest.  These are
used to calculate <code>var.t0</code> if neither <code>var.t0</code> nor
<code>boot.out</code> are supplied.  If a transformation is supplied through
<code>h</code> then the influence values must be for the untransformed
statistic <code>t0</code>.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_h">h</code></td>
<td>

<p>A function defining a monotonic transformation,  the intervals are
calculated on the scale of <code>h(t)</code> and the inverse function
<code>hinv</code> is applied to the resulting intervals.  <code>h</code> must be a
function of one variable only and must be vectorized. The default is
the identity function.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_hdot">hdot</code></td>
<td>

<p>A function of one argument returning the derivative of <code>h</code>.  It
is a required argument if <code>h</code> is supplied and is used for
approximating the variance of <code>h(t0)</code>.  The default is the
constant function 1.
</p>
</td></tr>
<tr><td><code id="norm.ci_+3A_hinv">hinv</code></td>
<td>

<p>A function, like <code>h</code>, which returns the inverse of <code>h</code>.  It is
used to transform the intervals calculated on the scale of <code>h(t)</code>
back to the original scale. The default is the identity function.  If
<code>h</code> is supplied but <code>hinv</code> is not, then the intervals returned
will be on the transformed scale. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is assumed that the statistic of interest has an approximately
normal distribution with variance <code>var.t0</code> and so a confidence
interval of length <code>2*qnorm((1+conf)/2)*sqrt(var.t0)</code> is found.
If <code>boot.out</code> or <code>t</code> are supplied then the interval is
bias-corrected using the bootstrap bias estimate, and so the interval
would be centred at <code>2*t0-mean(t)</code>.  Otherwise the interval is
centred at <code>t0</code>.
</p>


<h3>Value</h3>

<p>If <code>length(conf)</code> is 1 then a vector containing the confidence
level and the endpoints of the interval is returned.  Otherwise, the
returned value is a matrix where each row corresponds to a different
confidence level.
</p>


<h3>Note</h3>

<p>This function is primarily designed to be called by <code>boot.ci</code> to
calculate the normal approximation after a bootstrap but it can also be
used without doing any bootstrap calculations as long as <code>t0</code> and
<code>var.t0</code> can be supplied.  See the examples below.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.ci">boot.ci</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  In Example 5.1 of Davison and Hinkley (1997), normal approximation 
#  confidence intervals are found for the air-conditioning data.
air.mean &lt;- mean(aircondit$hours)
air.n &lt;- nrow(aircondit)
air.v &lt;- air.mean^2/air.n
norm.ci(t0 = air.mean, var.t0 = air.v)
exp(norm.ci(t0 = log(air.mean), var.t0 = 1/air.n)[2:3])

# Now a more complicated example - the ratio estimate for the city data.
ratio &lt;- function(d, w)
     sum(d$x * w)/sum(d$u *w)
city.v &lt;- var.linear(empinf(data = city, statistic = ratio))
norm.ci(t0 = ratio(city,rep(0.1,10)), var.t0 = city.v)
</code></pre>

<hr>
<h2 id='nuclear'>
Nuclear Power Station Construction Data
</h2><span id='topic+nuclear'></span>

<h3>Description</h3>

<p>The <code>nuclear</code> data frame has 32 rows and 11 columns.
</p>
<p>The data relate to the construction of 32 light water reactor (LWR) plants 
constructed in the U.S.A in the late 1960's and early 1970's.  The data was
collected with the aim of predicting the cost of construction of further
LWR plants.  6 of the power plants had partial turnkey guarantees and it is
possible that, for these plants, some manufacturers' subsidies may be hidden 
in the quoted capital costs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nuclear
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>cost</code></dt><dd>
<p>The capital cost of construction in millions of dollars adjusted to 1976 base.
</p>
</dd>
<dt><code>date</code></dt><dd>
<p>The date on which the construction permit was issued.  The data are measured in
years since January 1 1990 to the nearest month.
</p>
</dd>
<dt><code>t1</code></dt><dd>
<p>The time between application for and issue of the construction permit.
</p>
</dd>
<dt><code>t2</code></dt><dd>
<p>The time between issue of operating license and construction permit.
</p>
</dd>
<dt><code>cap</code></dt><dd>
<p>The net capacity of the power plant (MWe).
</p>
</dd>
<dt><code>pr</code></dt><dd>
<p>A binary variable where <code>1</code> indicates the prior existence of a LWR plant at
the same site.
</p>
</dd>
<dt><code>ne</code></dt><dd>
<p>A binary variable where <code>1</code> indicates that the plant was constructed in the 
north-east region of the U.S.A.
</p>
</dd>
<dt><code>ct</code></dt><dd>
<p>A binary variable where <code>1</code> indicates the use of a cooling tower in the plant.
</p>
</dd>
<dt><code>bw</code></dt><dd>
<p>A binary variable where <code>1</code> indicates that the nuclear steam supply system was
manufactured by Babcock-Wilcox.
</p>
</dd>
<dt><code>cum.n</code></dt><dd>
<p>The cumulative number of power plants constructed by each architect-engineer.
</p>
</dd>
<dt><code>pt</code></dt><dd>
<p>A binary variable where <code>1</code> indicates those plants with partial turnkey
guarantees.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Cox, D.R. and Snell, E.J. (1981) 
<em>Applied Statistics: Principles and Examples</em>. Chapman and Hall.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='paulsen'>
Neurotransmission in Guinea Pig Brains
</h2><span id='topic+paulsen'></span>

<h3>Description</h3>

<p>The <code>paulsen</code> data frame has 346 rows and 1 columns.  
</p>
<p>Sections were prepared from the brain of adult guinea pigs. Spontaneous
currents that flowed into individual brain cells were then recorded and
the peak amplitude of each current measured.  The aim of the experiment 
was to see if the current flow was
quantal in nature (i.e. that it is not a single burst but instead is built up
of many smaller bursts of current).  If the current was indeed quantal then it
would be expected that the distribution of the current amplitude would be
multimodal with modes at regular intervals.  The modes would be expected to
decrease in magnitude for higher current amplitudes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paulsen
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following column:
</p>

<dl>
<dt><code>y</code></dt><dd>
<p>The current flowing into individual brain cells. The currents are
measured in pico-amperes.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were kindly made available by Dr. O. Paulsen from the Department
of Pharmacology at the University of Oxford. 
</p>
<p>Paulsen, O. and Heggelund, P. (1994) The quantal size at retinogeniculate 
synapses determined from spontaneous and evoked EPSCs in guinea-pig thalamic 
slices. <em>Journal of Physiology</em>, <b>480</b>, 505&ndash;511. 
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='plot.boot'>
Plots of the Output of a Bootstrap Simulation
</h2><span id='topic+plot.boot'></span>

<h3>Description</h3>

<p>This takes a bootstrap object and produces plots for the bootstrap
replicates of the variable of interest.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boot'
plot(x, index = 1, t0 = NULL, t = NULL, jack = FALSE,
     qdist = "norm", nclass = NULL, df, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.boot_+3A_x">x</code></td>
<td>

<p>An object of class <code>"boot"</code> returned from one of the bootstrap
generation functions. 
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_index">index</code></td>
<td>

<p>The index of the variable of interest within the output of
<code>boot.out</code>.  This is ignored if <code>t</code> and <code>t0</code> are
supplied. 
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_t0">t0</code></td>
<td>

<p>The original value of the statistic.  This defaults to
<code>boot.out$t0[index]</code> unless <code>t</code> is supplied when it
defaults to <code>NULL</code>. In that case no vertical line is drawn on
the histogram.
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_t">t</code></td>
<td>

<p>The bootstrap replicates of the statistic.  Usually this will take
on its default value of <code>boot.out$t[,index]</code>, however it may be
useful sometimes to supply a different set of values which are a
function of <code>boot.out$t</code>.
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_jack">jack</code></td>
<td>

<p>A logical value indicating whether a jackknife-after-bootstrap plot is 
required.  The default is not to produce such a plot.
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_qdist">qdist</code></td>
<td>

<p>The distribution against which the Q-Q plot should be drawn.  At
present <code>"norm"</code> (normal distribution - the default) and
<code>"chisq"</code> (chi-squared distribution) are the only possible
values.
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_nclass">nclass</code></td>
<td>

<p>An integer giving the number of classes to be used in the bootstrap
histogram.  The default is the integer between 10 and 100 closest to
<code>ceiling(length(t)/25)</code>.
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_df">df</code></td>
<td>

<p>If <code>qdist</code> is <code>"chisq"</code> then this is the degrees of
freedom for the chi-squared distribution to be used.  It is a
required argument in that case.
</p>
</td></tr>
<tr><td><code id="plot.boot_+3A_...">...</code></td>
<td>

<p>When <code>jack</code> is <code>TRUE</code> additional parameters to
<code>jack.after.boot</code> can be supplied.  See the help file for
<code>jack.after.boot</code> for details of the possible parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will generally produce two side-by-side plots.  The left
plot will be a histogram of the bootstrap replicates.  Usually the
breaks of the histogram will be chosen so that <code>t0</code> is at a
breakpoint and all intervals are of equal length.  A vertical dotted
line indicates the position of <code>t0</code>.  This cannot be done if
<code>t</code> is supplied but <code>t0</code> is not and so, in that case, the
breakpoints are computed by <code>hist</code> using the <code>nclass</code>
argument and no vertical line is drawn.
</p>
<p>The second plot is a Q-Q plot of the bootstrap replicates.  The order
statistics of the replicates can be plotted against normal or
chi-squared quantiles.  In either case the expected line is also
plotted.  For the normal, this will have intercept <code>mean(t)</code> and
slope <code>sqrt(var(t))</code> while for the chi-squared it has intercept 0
and slope 1.
</p>
<p>If <code>jack</code> is <code>TRUE</code> a third plot is produced beneath these
two.  That plot is the jackknife-after-bootstrap plot.  This plot may
only be requested when nonparametric simulation has been used.  See
<code>jack.after.boot</code> for further details of this plot.  
</p>


<h3>Value</h3>

<p><code>boot.out</code> is returned invisibly.
</p>


<h3>Side Effects</h3>

<p>All screens are closed and cleared and a number of plots are produced
on the current graphics device.  Screens are closed but not cleared at
termination of this function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+jack.after.boot">jack.after.boot</a></code>, <code><a href="#topic+print.boot">print.boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We fit an exponential model to the air-conditioning data and use
# that for a parametric bootstrap.  Then we look at plots of the
# resampled means.
air.rg &lt;- function(data, mle) rexp(length(data), 1/mle)

air.boot &lt;- boot(aircondit$hours, mean, R = 999, sim = "parametric",
                 ran.gen = air.rg, mle = mean(aircondit$hours))
plot(air.boot)

# In the difference of means example for the last two series of the 
# gravity data
grav1 &lt;- gravity[as.numeric(gravity[, 2]) &gt;= 7, ]
grav.fun &lt;- function(dat, w) {
     strata &lt;- tapply(dat[, 2], as.numeric(dat[, 2]))
     d &lt;- dat[, 1]
     ns &lt;- tabulate(strata)
     w &lt;- w/tapply(w, strata, sum)[strata]
     mns &lt;- as.vector(tapply(d * w, strata, sum)) # drop names
     mn2 &lt;- tapply(d * d * w, strata, sum)
     s2hat &lt;- sum((mn2 - mns^2)/ns)
     c(mns[2] - mns[1], s2hat)
}

grav.boot &lt;- boot(grav1, grav.fun, R = 499, stype = "w", strata = grav1[, 2])
plot(grav.boot)
# now suppose we want to look at the studentized differences.
grav.z &lt;- (grav.boot$t[, 1]-grav.boot$t0[1])/sqrt(grav.boot$t[, 2])
plot(grav.boot, t = grav.z, t0 = 0)

# In this example we look at the one of the partial correlations for the
# head dimensions in the dataset frets.
frets.fun &lt;- function(data, i) {
    pcorr &lt;- function(x) { 
    #  Function to find the correlations and partial correlations between
    #  the four measurements.
         v &lt;- cor(x)
         v.d &lt;- diag(var(x))
         iv &lt;- solve(v)
         iv.d &lt;- sqrt(diag(iv))
         iv &lt;- - diag(1/iv.d) %*% iv %*% diag(1/iv.d)
         q &lt;- NULL
         n &lt;- nrow(v)
         for (i in 1:(n-1)) 
              q &lt;- rbind( q, c(v[i, 1:i], iv[i,(i+1):n]) )
         q &lt;- rbind( q, v[n, ] )
         diag(q) &lt;- round(diag(q))
         q
    }
    d &lt;- data[i, ]
    v &lt;- pcorr(d)
    c(v[1,], v[2,], v[3,], v[4,])
}
frets.boot &lt;- boot(log(as.matrix(frets)),  frets.fun,  R = 999)
plot(frets.boot, index = 7, jack = TRUE, stinf = FALSE, useJ = FALSE)
</code></pre>

<hr>
<h2 id='poisons'>
Animal Survival Times
</h2><span id='topic+poisons'></span>

<h3>Description</h3>

<p>The <code>poisons</code> data frame has 48 rows and 3 columns.
</p>
<p>The data form a 3x4 factorial experiment, the factors being three poisons
and four treatments.  Each combination of the two factors was used for
four animals, the allocation to animals having been completely randomized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisons
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>time</code></dt><dd>
<p>The survival time of the animal in units of 10 hours.
</p>
</dd>
<dt><code>poison</code></dt><dd>
<p>A factor with levels <code>1</code>, <code>2</code> and <code>3</code> giving the type of poison used.
</p>
</dd>
<dt><code>treat</code></dt><dd>
<p>A factor with levels <code>A</code>, <code>B</code>, <code>C</code> and <code>D</code> giving the treatment.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Box, G.E.P. and Cox, D.R. (1964) An analysis of transformations (with
Discussion). 
<em> Journal of the Royal Statistical Society, B</em>, <b>26</b>, 211&ndash;252.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='polar'>
Pole Positions of New Caledonian Laterites
</h2><span id='topic+polar'></span>

<h3>Description</h3>

<p>The <code>polar</code> data frame has 50 rows and 2 columns.
</p>
<p>The data are the pole positions from a paleomagnetic study of New Caledonian
laterites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polar
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>lat</code></dt><dd>
<p>The latitude (in degrees) of the pole position.  Note that all latitudes
are negative as the axis is taken to be in the lower hemisphere.
</p>
</dd>
<dt><code>long</code></dt><dd>
<p>The longitude (in degrees) of the pole position.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Fisher, N.I., Lewis, T. and Embleton, B.J.J. (1987) 
<em>Statistical Analysis of Spherical Data</em>. Cambridge University Press.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='print.boot'>
Print a Summary of a Bootstrap Object
</h2><span id='topic+print.boot'></span>

<h3>Description</h3>

<p>This is a method for the function <code>print()</code> for objects of the
class <code>"boot"</code> created by a call to <code><a href="#topic+boot">boot</a></code>,
<code><a href="#topic+censboot">censboot</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code> or <code><a href="#topic+tsboot">tsboot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boot'
print(x, digits = getOption("digits"), 
      index = 1:ncol(boot.out$t), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.boot_+3A_x">x</code></td>
<td>

<p>A bootstrap output object of class <code>"boot"</code> generated by one
of the bootstrap functions.
</p>
</td></tr>
<tr><td><code id="print.boot_+3A_digits">digits</code></td>
<td>

<p>The number of digits to be printed in the summary statistics.
</p>
</td></tr>
<tr><td><code id="print.boot_+3A_index">index</code></td>
<td>

<p>Indices indicating for which elements of the bootstrap output
summary statistics are required.
</p>
</td></tr>
<tr><td><code id="print.boot_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each statistic calculated in the bootstrap the original value and
the bootstrap estimates of its bias and standard error are printed.
If <code>boot.out$t0</code> is missing (such as when it was created by a
call to <code>tsboot</code> with <code>orig.t = FALSE</code>) the bootstrap mean and
standard error are printed. If resampling was done using importance
resampling weights, then the bootstrap estimates are reweighted as if
uniform resampling had been done.  The ratio importance sampling
estimates are used and if there were a number of distributions then
defensive mixture distributions are used.  In this case an extra
column with the mean of the observed bootstrap statistics is also
printed.
</p>


<h3>Value</h3>

<p>The bootstrap object is returned invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+censboot">censboot</a></code>, <code><a href="#topic+imp.moments">imp.moments</a></code>,
<code><a href="#topic+plot.boot">plot.boot</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code>, <code><a href="#topic+tsboot">tsboot</a></code>
</p>

<hr>
<h2 id='print.bootci'>
Print Bootstrap Confidence Intervals
</h2><span id='topic+print.bootci'></span>

<h3>Description</h3>

<p>This is a method for the function <code>print()</code> to print objects of the
class <code>"bootci"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bootci'
print(x, hinv = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bootci_+3A_x">x</code></td>
<td>

<p>The output from a call to <code>boot.ci</code>.
</p>
</td></tr>
<tr><td><code id="print.bootci_+3A_hinv">hinv</code></td>
<td>

<p>A transformation to be made to the interval end-points before they are
printed.
</p>
</td></tr>
<tr><td><code id="print.bootci_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function prints out the results from <code>boot.ci</code> in a &quot;nice&quot; format.
It also notes whether the scale of the intervals is the original scale
of the input to <code>boot.ci</code> or a different scale and whether the calculations
were done on a transformed scale.  It also looks at the order statistics
that were used in calculating the intervals.  If the smallest or largest
values were used then it prints a message 
</p>
<p><code>Warning : Intervals used Extreme Quantiles</code>
</p>
<p>Such intervals should be considered very unstable and not relied upon for
inferences.  Even if the extreme values are not used, it is possible that the
intervals are unstable if they used quantiles close to the extreme values.
The function alerts the user to intervals which use the upper
or lower 10 order statistics with the message
</p>
<p><code>Some intervals may be unstable</code>
</p>


<h3>Value</h3>

<p>The object <code>ci.out</code> is returned invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.ci">boot.ci</a></code>
</p>

<hr>
<h2 id='print.saddle.distn'>
Print Quantiles of Saddlepoint Approximations
</h2><span id='topic+print.saddle.distn'></span>

<h3>Description</h3>

<p>This is a method for the function <code>print()</code> to print objects of class
<code>"saddle.distn"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'saddle.distn'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.saddle.distn_+3A_x">x</code></td>
<td>

<p>An object of class <code>"saddle.distn"</code> created by a call to
<code>saddle.distn</code>.
</p>
</td></tr>
<tr><td><code id="print.saddle.distn_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The quantiles of the saddlepoint approximation to the distribution are printed
along with the original call and some other useful information.
</p>


<h3>Value</h3>

<p>The input is returned invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lines.saddle.distn">lines.saddle.distn</a></code>, <code><a href="#topic+saddle.distn">saddle.distn</a></code>
</p>

<hr>
<h2 id='print.simplex'>
Print Solution to Linear Programming Problem
</h2><span id='topic+print.simplex'></span>

<h3>Description</h3>

<p>This is a method for the function <code>print()</code> to print objects of class
<code>"simplex"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'simplex'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.simplex_+3A_x">x</code></td>
<td>

<p>An object of class <code>"simplex"</code> created by calling the
function <code>simplex</code> to solve a linear programming problem.
</p>
</td></tr>
<tr><td><code id="print.simplex_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coefficients of the objective function are printed.
If a solution to the linear programming problem was found then the solution
and the optimal value of the objective function are printed.  If a feasible
solution was found but the maximum number of iterations was exceeded then the
last feasible solution and the objective function value at that point are
printed.  If no feasible solution could be found then a message stating that is
printed.
</p>


<h3>Value</h3>

<p><code>x</code> is returned silently.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simplex">simplex</a></code>
</p>

<hr>
<h2 id='remission'>
Cancer Remission and Cell Activity
</h2><span id='topic+remission'></span>

<h3>Description</h3>

<p>The <code>remission</code> data frame has 27 rows and 3 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remission
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>LI</code></dt><dd>
<p>A measure of cell activity.
</p>
</dd>
<dt><code>m</code></dt><dd>
<p>The number of patients in each group (all values are actually 1 here).
</p>
</dd>
<dt><code>r</code></dt><dd>
<p>The number of patients (out of <code>m</code>) who went into remission.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Freeman, D.H. (1987) <em>Applied Categorical Data Analysis</em>. Marcel Dekker.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='saddle'>
Saddlepoint Approximations for Bootstrap Statistics
</h2><span id='topic+saddle'></span>

<h3>Description</h3>

<p>This function calculates a saddlepoint approximation to the
distribution of a linear combination of <b>W</b> at a particular point
<code>u</code>, where <b>W</b> is a vector of random variables.  The
distribution of <b>W</b> may be multinomial (default), Poisson or
binary.  Other distributions are possible also if the adjusted
cumulant generating function and its second derivative are given.
Conditional saddlepoint approximations to the distribution of one
linear combination given the values of other linear combinations of
<b>W</b> can be calculated for <b>W</b> having binary or Poisson
distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saddle(A = NULL, u = NULL, wdist = "m", type = "simp", d = NULL,
       d1 = 1, init = rep(0.1, d), mu = rep(0.5, n), LR = FALSE,
       strata = NULL, K.adj = NULL, K2 = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="saddle_+3A_a">A</code></td>
<td>

<p>A vector or matrix of known coefficients of the linear combinations
of <b>W</b>. It is a required argument unless <code>K.adj</code> and
<code>K2</code> are supplied, in which case it is ignored.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_u">u</code></td>
<td>

<p>The value at which it is desired to calculate the saddlepoint
approximation to the distribution of the linear combination of
<b>W</b>. It is a required argument unless <code>K.adj</code> and
<code>K2</code> are supplied, in which case it is ignored.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_wdist">wdist</code></td>
<td>

<p>The distribution of <b>W</b>.  This can be one of <code>"m"</code>
(multinomial), <code>"p"</code> (Poisson), <code>"b"</code> (binary) or
<code>"o"</code> (other).  If <code>K.adj</code> and <code>K2</code> are given
<code>wdist</code> is set to <code>"o"</code>.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_type">type</code></td>
<td>

<p>The type of saddlepoint approximation.  Possible types are
<code>"simp"</code> for simple saddlepoint and <code>"cond"</code> for the
conditional saddlepoint.  When <code>wdist</code> is <code>"o"</code> or
<code>"m"</code>, <code>type</code> is automatically set to <code>"simp"</code>, which
is the only type of saddlepoint currently implemented for those
distributions.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_d">d</code></td>
<td>

<p>This specifies the dimension of the whole statistic.  This argument
is required only when <code>wdist = "o"</code> and defaults to 1 if not
supplied in that case.  For other distributions it is set to
<code>ncol(A)</code>.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_d1">d1</code></td>
<td>

<p>When <code>type</code> is <code>"cond"</code> this is the dimension of the
statistic of interest which must be less than <code>length(u)</code>.
Then the saddlepoint approximation to the conditional distribution
of the first <code>d1</code> linear combinations given the values of the
remaining combinations is found.  Conditional distribution function
approximations can only be found if the value of <code>d1</code> is 1.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_init">init</code></td>
<td>

<p>Used if <code>wdist</code> is either <code>"m"</code> or <code>"o"</code>, this gives
initial values to <code>nlmin</code> which is used to solve the
saddlepoint equation.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_mu">mu</code></td>
<td>

<p>The values of the parameters of the distribution of <b>W</b> when
<code>wdist</code> is <code>"m"</code>, <code>"p"</code> <code>"b"</code>.  <code>mu</code> must
be of the same length as W (i.e. <code>nrow(A)</code>). The default is
that all values of <code>mu</code> are equal and so the elements of
<b>W</b> are identically distributed.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_lr">LR</code></td>
<td>

<p>If <code>TRUE</code> then the Lugananni-Rice approximation to the cdf is used,
otherwise the approximation used is based on Barndorff-Nielsen's r*. 
</p>
</td></tr>
<tr><td><code id="saddle_+3A_strata">strata</code></td>
<td>

<p>The strata for stratified data.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_k.adj">K.adj</code></td>
<td>

<p>The adjusted cumulant generating function used when <code>wdist</code> is
<code>"o"</code>.  This is a function of a single parameter, <code>zeta</code>,
which calculates <code>K(zeta)-u%*%zeta</code>, where <code>K(zeta)</code> is
the cumulant generating function of <b>W</b>.
</p>
</td></tr>
<tr><td><code id="saddle_+3A_k2">K2</code></td>
<td>

<p>This is a function of a single parameter <code>zeta</code> which returns the 
matrix of second derivatives of <code>K(zeta)</code> for use when
<code>wdist</code> is <code>"o"</code>.  If <code>K.adj</code> is given then this must
be given also.  It is called only once with the calculated solution
to the saddlepoint equation being passed as the argument.  This
argument is ignored if <code>K.adj</code> is not supplied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>wdist</code> is <code>"o"</code> or <code>"m"</code>, the saddlepoint equations
are solved using <code>nlmin</code> to minimize <code>K.adj</code> with respect to
its parameter <code>zeta</code>.  For the Poisson and binary cases, a
generalized linear model is fitted such that the parameter estimates
solve the saddlepoint equations.  The response variable 'y' for the
<code>glm</code> must satisfy the equation <code>t(A)%*%y = u</code> (<code>t()</code>
being the transpose function).  Such a vector can be found as a feasible
solution to a linear programming problem.  This is done by a call to
<code>simplex</code>.  The covariate matrix for the <code>glm</code> is given by
<code>A</code>.
</p>


<h3>Value</h3>

<p>A list consisting of the following components
</p>
<table>
<tr><td><code>spa</code></td>
<td>

<p>The saddlepoint approximations.  The first value is the density approximation
and the second value is the distribution function approximation.
</p>
</td></tr>
<tr><td><code>zeta.hat</code></td>
<td>

<p>The solution to the saddlepoint equation.  For the conditional saddlepoint
this is the solution to the saddlepoint equation for the numerator.
</p>
</td></tr>
<tr><td><code>zeta2.hat</code></td>
<td>

<p>If <code>type</code> is <code>"cond"</code> this is the solution to the
saddlepoint equation for the denominator.  This component is not
returned for any other value of <code>type</code>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Booth, J.G. and Butler, R.W. (1990) Randomization distributions and 
saddlepoint approximations in generalized linear models. 
<em>Biometrika</em>, <b>77</b>, 787&ndash;796.
</p>
<p>Canty, A.J. and Davison, A.C. (1997) Implementation of saddlepoint 
approximations to resampling distributions.  
<em>Computing Science and Statistics; Proceedings of the 28th Symposium on the Interface</em>, 248&ndash;253.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and their Application</em>. Cambridge University Press.
</p>
<p>Jensen, J.L. (1995) <em>Saddlepoint Approximations</em>. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+saddle.distn">saddle.distn</a></code>, <code><a href="#topic+simplex">simplex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To evaluate the bootstrap distribution of the mean failure time of 
# air-conditioning equipment at 80 hours
saddle(A = aircondit$hours/12, u = 80)

# Alternatively this can be done using a conditional poisson
saddle(A = cbind(aircondit$hours/12,1), u = c(80, 12),
       wdist = "p", type = "cond")

# To use the Lugananni-Rice approximation to this
saddle(A = cbind(aircondit$hours/12,1), u = c(80, 12),
       wdist = "p", type = "cond", 
       LR = TRUE)

# Example 9.16 of Davison and Hinkley (1997) calculates saddlepoint 
# approximations to the distribution of the ratio statistic for the
# city data. Since the statistic is not in itself a linear combination
# of random Variables, its distribution cannot be found directly.  
# Instead the statistic is expressed as the solution to a linear 
# estimating equation and hence its distribution can be found.  We
# get the saddlepoint approximation to the pdf and cdf evaluated at
# t = 1.25 as follows.
jacobian &lt;- function(dat,t,zeta)
{
     p &lt;- exp(zeta*(dat$x-t*dat$u))
     abs(sum(dat$u*p)/sum(p))
}
city.sp1 &lt;- saddle(A = city$x-1.25*city$u, u = 0)
city.sp1$spa[1] &lt;- jacobian(city, 1.25, city.sp1$zeta.hat) * city.sp1$spa[1]
city.sp1
</code></pre>

<hr>
<h2 id='saddle.distn'>
Saddlepoint Distribution Approximations for Bootstrap Statistics
</h2><span id='topic+saddle.distn'></span>

<h3>Description</h3>

<p>Approximate an entire distribution using saddlepoint methods.  This
function can calculate simple and conditional saddlepoint distribution
approximations for a univariate quantity of interest.  For the simple
saddlepoint the quantity of interest is a linear combination of
<b>W</b> where <b>W</b> is a vector of random variables.  For the
conditional saddlepoint we require the distribution of one linear
combination given the values of any number of other linear
combinations. The distribution of <b>W</b> must be one of multinomial,
Poisson or binary.  The primary use of this function is to calculate
quantiles of bootstrap distributions using saddlepoint approximations.
Such quantiles are required by the function <code><a href="#topic+control">control</a></code> to
approximate the distribution of the linear approximation to a
statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saddle.distn(A, u = NULL, alpha = NULL, wdist = "m", 
             type = "simp", npts = 20, t = NULL, t0 = NULL, 
             init = rep(0.1, d), mu = rep(0.5, n), LR = FALSE, 
             strata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="saddle.distn_+3A_a">A</code></td>
<td>

<p>This is a matrix of known coefficients or a function which returns
such a matrix.  If a function then its first argument must be the
point <code>t</code> at which a saddlepoint is required.   The most common
reason for A being a function would be if the statistic is not
itself a linear combination of the <b>W</b> but is the solution to a
linear estimating equation.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_u">u</code></td>
<td>

<p>If <code>A</code> is a function then <code>u</code>  must also be a function
returning a vector with length equal to the number of columns of the
matrix returned by <code>A</code>. Usually all components other than the
first will be constants as the other components are the values of
the conditioning variables. If <code>A</code> is a matrix with more than
one column (such as when <code>wdist = "cond"</code>) then <code>u</code> should
be a vector with length one less than <code>ncol(A)</code>.  In this case
<code>u</code> specifies the values of the conditioning variables.  If
<code>A</code> is a matrix with one column or a vector then <code>u</code> is
not used.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_alpha">alpha</code></td>
<td>

<p>The alpha levels for the quantiles of the distribution which should be
returned.  By default the 0.1, 0.5, 1, 2.5, 5, 10, 20, 50, 80, 90,
95, 97.5, 99, 99.5 and 99.9 percentiles are calculated. 
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_wdist">wdist</code></td>
<td>

<p>The distribution of <b>W</b>.  Possible values are <code>"m"</code>
(multinomial), <code>"p"</code> (Poisson), or <code>"b"</code> (binary).
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_type">type</code></td>
<td>

<p>The type of saddlepoint to be used.  Possible values are
<code>"simp"</code> (simple saddlepoint) and <code>"cond"</code> (conditional).
If <code>wdist</code> is <code>"m"</code>, <code>type</code> is set to <code>"simp"</code>.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_npts">npts</code></td>
<td>

<p>The number of points at which the saddlepoint approximation should be
calculated and then used to fit the spline.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_t">t</code></td>
<td>

<p>A vector of points at which the saddlepoint approximations are
calculated. These points should extend beyond the extreme quantiles
required but still be in the possible range of the bootstrap
distribution.  The observed value of the statistic should not be
included in <code>t</code> as the distribution function approximation
breaks down at that point.  The points should, however cover the
entire effective range of the distribution including close to the
centre. If <code>t</code> is supplied then <code>npts</code> is set to
<code>length(t)</code>. When <code>t</code> is not supplied, the function
attempts to find the effective range of the distribution and then
selects points to cover this range.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_t0">t0</code></td>
<td>

<p>If <code>t</code> is not supplied then a vector of length 2 should be
passed as <code>t0</code>. The first component of <code>t0</code> should be the
centre of the distribution and the second should be an estimate of
spread (such as a standard error). These two are then used to find
the effective range of the distribution. The range finding mechanism
does rely on an accurate estimate of location in <code>t0[1]</code>.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_init">init</code></td>
<td>

<p>When <code>wdist</code> is <code>"m"</code>, this vector should contain the
initial values to be passed to <code>nlmin</code> when it is called to
solve the saddlepoint equations.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_mu">mu</code></td>
<td>

<p>The vector of parameter values for the distribution.  The
default is that the components of <b>W</b> are identically distributed.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_lr">LR</code></td>
<td>

<p>A logical flag.  When <code>LR</code> is <code>TRUE</code> the Lugananni-Rice
cdf approximations are calculated and used to fit the spline.
Otherwise the cdf approximations used are based on
Barndorff-Nielsen's r*.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_strata">strata</code></td>
<td>

<p>A vector giving the strata when the rows of A relate to stratified
data.  This is used only when <code>wdist</code> is <code>"m"</code>.
</p>
</td></tr>
<tr><td><code id="saddle.distn_+3A_...">...</code></td>
<td>

<p>When <code>A</code> and <code>u</code> are functions any additional arguments
are passed unchanged each time one of them is called.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The range at which the saddlepoint is used is such that the cdf
approximation at the endpoints is more extreme than required by the
extreme values of <code>alpha</code>.  The lower endpoint is found by
evaluating the saddlepoint at the points <code>t0[1]-2*t0[2]</code>,
<code>t0[1]-4*t0[2]</code>, <code>t0[1]-8*t0[2]</code> etc.  until a point is
found with a cdf approximation less than <code>min(alpha)/10</code>, then a
bisection method is used to find the endpoint which has cdf
approximation in the range (<code>min(alpha)/1000</code>,
<code>min(alpha)/10</code>). Then a number of, equally spaced, points are
chosen between the lower endpoint and <code>t0[1]</code> until a total of
<code>npts/2</code> approximations have been made. The remaining
<code>npts/2</code> points are chosen to the right of <code>t0[1]</code> in a
similar manner.  Any points which are very close to the centre of the
distribution are then omitted as the cdf approximations are not
reliable at the centre. A smoothing spline is then fitted to the
probit of the saddlepoint distribution function approximations at the
remaining points and the required quantiles are predicted from the
spline.
</p>
<p>Sometimes the function will terminate with the message
<code>"Unable to find range"</code>.  There are two main reasons why this may
occur.  One is that the distribution is too discrete and/or the
required quantiles too extreme, this can cause the function to be
unable to find a point within the allowable range which is beyond the
extreme quantiles.  Another possibility is that the value of
<code>t0[2]</code> is too small and so too many steps are required to find
the range. The first problem cannot be solved except by asking for
less extreme quantiles, although for very discrete distributions the
approximations may not be very good.  In the second case using a
larger value of <code>t0[2]</code> will usually solve the problem.
</p>


<h3>Value</h3>

<p>The returned value is an object of class <code>"saddle.distn"</code>.  See the help
file for <code><a href="#topic+saddle.distn.object">saddle.distn.object</a></code> for a description of such
an object.
</p>


<h3>References</h3>

<p>Booth, J.G. and Butler, R.W. (1990) Randomization distributions and 
saddlepoint approximations in generalized linear models. 
<em>Biometrika</em>, <b>77</b>, 787&ndash;796.
</p>
<p>Canty, A.J. and Davison, A.C. (1997) Implementation of saddlepoint 
approximations to resampling distributions. 
<em>Computing Science and Statistics; Proceedings of the 28th
Symposium on the Interface</em> 248&ndash;253.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and their Application</em>. Cambridge University Press.
</p>
<p>Jensen, J.L. (1995) <em>Saddlepoint Approximations</em>. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lines.saddle.distn">lines.saddle.distn</a></code>, <code><a href="#topic+saddle">saddle</a></code>,
<code><a href="#topic+saddle.distn.object">saddle.distn.object</a></code>, <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  The bootstrap distribution of the mean of the air-conditioning 
#  failure data: fails to find value on R (and probably on S too)
air.t0 &lt;- c(mean(aircondit$hours), sqrt(var(aircondit$hours)/12))
## Not run: saddle.distn(A = aircondit$hours/12, t0 = air.t0)

# alternatively using the conditional poisson
saddle.distn(A = cbind(aircondit$hours/12, 1), u = 12, wdist = "p",
             type = "cond", t0 = air.t0)

# Distribution of the ratio of a sample of size 10 from the bigcity 
# data, taken from Example 9.16 of Davison and Hinkley (1997).
ratio &lt;- function(d, w) sum(d$x *w)/sum(d$u * w)
city.v &lt;- var.linear(empinf(data = city, statistic = ratio))
bigcity.t0 &lt;- c(mean(bigcity$x)/mean(bigcity$u), sqrt(city.v))
Afn &lt;- function(t, data) cbind(data$x - t*data$u, 1)
ufn &lt;- function(t, data) c(0,10)
saddle.distn(A = Afn, u = ufn, wdist = "b", type = "cond",
             t0 = bigcity.t0, data = bigcity)

# From Example 9.16 of Davison and Hinkley (1997) again, we find the 
# conditional distribution of the ratio given the sum of city$u.
Afn &lt;- function(t, data) cbind(data$x-t*data$u, data$u, 1)
ufn &lt;- function(t, data) c(0, sum(data$u), 10)
city.t0 &lt;- c(mean(city$x)/mean(city$u), sqrt(city.v))
saddle.distn(A = Afn, u = ufn, wdist = "p", type = "cond", t0 = city.t0, 
             data = city)
</code></pre>

<hr>
<h2 id='saddle.distn.object'>
Saddlepoint Distribution Approximation Objects
</h2><span id='topic+saddle.distn.object'></span>

<h3>Description</h3>

<p>Class of objects that result from calculating saddlepoint distribution
approximations by a call to <code>saddle.distn</code>.
</p>


<h3>Generation</h3>

<p>This class of objects is returned from calls to the function
<code><a href="#topic+saddle.distn">saddle.distn</a></code>.
</p>


<h3>Methods</h3>

<p>The class <code>"saddle.distn"</code> has methods for the functions
<code><a href="graphics.html#topic+lines">lines</a></code> and <code><a href="base.html#topic+print">print</a></code>.
</p>


<h3>Structure</h3>

<p>Objects of class <code>"saddle.distn"</code> are implemented as a list with
the following components.
</p>

<dl>
<dt>quantiles</dt><dd>
<p>A matrix with 2 columns.  The first column contains the
probabilities <code>alpha</code> and the second column contains the
estimated quantiles of the distribution at those probabilities
derived from the spline.
</p>
</dd>
<dt>points</dt><dd>
<p>A matrix of evaluations of the saddlepoint approximation.  The first
column contains the values of <code>t</code> which were used, the second
and third contain the density and cdf approximations at those points
and the rest of the columns contain the solutions to the saddlepoint
equations.  When <code>type</code> is <code>"simp"</code>, there is only one of
those.  When <code>type</code> is <code>"cond"</code> there are <code>2*d-1</code>
where <code>d</code> is the number of columns in <code>A</code> or the output of
<code>A(t,...{})</code>. The first <code>d</code> of these correspond to the
numerator and the remainder correspond to the denominator.
</p>
</dd>
<dt>distn</dt><dd>
<p>An object of class <code>smooth.spline</code>.  This corresponds to the
spline fitted to the saddlepoint cdf approximations in points in
order to approximate the entire distribution.  For the structure of
the object see <code>smooth.spline</code>.
</p>
</dd>
<dt>call</dt><dd>
<p>The original call to <code>saddle.distn</code> which generated the object.
</p>
</dd>
<dt>LR</dt><dd>
<p>A logical variable indicating whether the Lugananni-Rice
approximations were used.
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+lines.saddle.distn">lines.saddle.distn</a></code>, <code><a href="#topic+saddle.distn">saddle.distn</a></code>,
<code><a href="#topic+print.saddle.distn">print.saddle.distn</a></code>
</p>

<hr>
<h2 id='salinity'>
Water Salinity and River Discharge
</h2><span id='topic+salinity'></span>

<h3>Description</h3>

<p>The <code>salinity</code> data frame has 28 rows and 4 columns.
</p>
<p>Biweekly averages of the water salinity and river discharge in Pamlico
Sound, North Carolina were recorded between the years 1972 and 1977.
The data in this set consists only of those measurements in March, April
and May.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>salinity
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>sal</code></dt><dd>
<p>The average salinity of the water over two weeks.
</p>
</dd>
<dt><code>lag</code></dt><dd>
<p>The average salinity of the water lagged two weeks.  Since only spring is used,
the value of <code>lag</code> is not always equal to the previous value of <code>sal</code>.
</p>
</dd>
<dt><code>trend</code></dt><dd>
<p>A factor indicating in which of the 6 biweekly periods between March and May,
the observations were taken. The levels of the factor are from 0 to 5 with
0 being the first two weeks in March.
</p>
</dd>
<dt><code>dis</code></dt><dd>
<p>The amount of river discharge during the two weeks for which <code>sal</code> is the
average salinity.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Ruppert, D. and Carroll, R.J. (1980) Trimmed least squares estimation in the 
linear model. 
<em>Journal of the American Statistical Association</em>, <b>75</b>, 828&ndash;838.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='simplex'>
Simplex Method for Linear Programming Problems
</h2><span id='topic+simplex'></span>

<h3>Description</h3>

<p>This function will optimize the linear function <code>a%*%x</code> subject
to the constraints <code>A1%*%x &lt;= b1</code>, <code>A2%*%x &gt;= b2</code>,
<code>A3%*%x = b3</code> and <code>x &gt;= 0</code>.  Either maximization or
minimization is possible but the default is minimization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplex(a, A1 = NULL, b1 = NULL, A2 = NULL, b2 = NULL, A3 = NULL,
        b3 = NULL, maxi = FALSE, n.iter = n + 2 * m, eps = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplex_+3A_a">a</code></td>
<td>

<p>A vector of length <code>n</code> which gives the coefficients of the
objective function.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_a1">A1</code></td>
<td>

<p>An <code>m1</code> by <code>n</code> matrix of coefficients for the <code class="reqn">\leq</code> type of
constraints.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_b1">b1</code></td>
<td>

<p>A vector of length <code>m1</code> giving the right hand side of the <code class="reqn">\leq</code>
constraints. This argument is required if <code>A1</code> is given and
ignored otherwise.  All values in <code>b1</code> must be non-negative.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_a2">A2</code></td>
<td>

<p>An <code>m2</code> by <code>n</code> matrix of coefficients for the <code class="reqn">\geq</code> type of
constraints.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_b2">b2</code></td>
<td>

<p>A vector of length <code>m2</code> giving the right hand side of the <code class="reqn">\geq</code>
constraints. This argument is required if <code>A2</code> is given and
ignored otherwise.  All values in <code>b2</code> must be non-negative.
Note that the constraints <code>x &gt;= 0</code> are included automatically
and so should not be repeated here.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_a3">A3</code></td>
<td>

<p>An <code>m3</code> by <code>n</code> matrix of coefficients for the equality
constraints.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_b3">b3</code></td>
<td>

<p>A vector of length <code>m3</code> giving the right hand side of equality
constraints. This argument is required if <code>A3</code> is given and
ignored otherwise.  All values in <code>b3</code> must be non-negative.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_maxi">maxi</code></td>
<td>

<p>A logical flag which specifies minimization if <code>FALSE</code>
(default) and maximization otherwise.  If <code>maxi</code> is <code>TRUE</code>
then the maximization problem is recast as a minimization problem by
changing the objective function coefficients to their negatives.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_n.iter">n.iter</code></td>
<td>

<p>The maximum number of iterations to be conducted in each phase of
the simplex method.  The default is <code>n+2*(m1+m2+m3)</code>.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_eps">eps</code></td>
<td>

<p>The floating point tolerance to be used in tests of equality.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method employed by this function is the two phase tableau simplex
method. If there are <code class="reqn">\geq</code> or equality constraints an initial feasible
solution is not easy to find.  To find a feasible solution an
artificial variable is introduced into each <code class="reqn">\geq</code> or equality
constraint and an auxiliary objective function is defined as the sum
of these artificial variables.  If a feasible solution to the set of
constraints exists then the auxiliary objective will be minimized when
all of the artificial variables are 0. These are then discarded and
the original problem solved starting at the solution to the auxiliary
problem.  If the only constraints are of the <code class="reqn">\leq</code> form, the origin is
a feasible solution and so the first stage can be omitted.
</p>


<h3>Value</h3>

<p>An object of class <code>"simplex"</code>: see <code><a href="#topic+simplex.object">simplex.object</a></code>.
</p>


<h3>Note</h3>

<p>The method employed here is suitable only for relatively small
systems.  Also if possible the number of constraints should be reduced
to a minimum in order to speed up the execution time which is
approximately proportional to the cube of the number of constraints.
In particular if there are any constraints of the form <code>x[i] &gt;=
    b2[i]</code> they should be omitted by setting <code>x[i] = x[i]-b2[i]</code>,
changing all the constraints and the objective function accordingly
and then transforming back after the solution has been found.
</p>


<h3>References</h3>

<p>Gill, P.E., Murray, W. and Wright, M.H. (1991)
<em>Numerical Linear Algebra and Optimization Vol. 1</em>. Addison-Wesley.
</p>
<p>Press, W.H., Teukolsky, S.A., Vetterling, W.T. and Flannery, B.P. (1992)
<em>Numerical Recipes: The Art of Scientific Computing (Second Edition)</em>.
Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This example is taken from Exercise 7.5 of Gill, Murray and Wright (1991).
enj &lt;- c(200, 6000, 3000, -200)
fat &lt;- c(800, 6000, 1000, 400)
vitx &lt;- c(50, 3, 150, 100)
vity &lt;- c(10, 10, 75, 100)
vitz &lt;- c(150, 35, 75, 5)
simplex(a = enj, A1 = fat, b1 = 13800, A2 = rbind(vitx, vity, vitz),
        b2 = c(600, 300, 550), maxi = TRUE)
</code></pre>

<hr>
<h2 id='simplex.object'>
Linear Programming Solution Objects
</h2><span id='topic+simplex.object'></span>

<h3>Description</h3>

<p>Class of objects that result from solving a linear programming
problem using <code>simplex</code>.
</p>


<h3>Generation</h3>

<p>This class of objects is returned from calls to the function <code>simplex</code>.
</p>


<h3>Methods</h3>

<p>The class <code>"saddle.distn"</code> has a method for the function <code>print</code>.
</p>


<h3>Structure</h3>

<p>Objects of class <code>"simplex"</code> are implemented as a list with the
following components.
</p>

<dl>
<dt>soln</dt><dd>
<p>The values of <code>x</code> which optimize the objective function under
the specified constraints provided those constraints are jointly feasible.
</p>
</dd>
<dt>solved</dt><dd>
<p>This indicates whether the problem was solved.  A value of <code>-1</code>
indicates that no feasible solution could be found.  A value of
<code>0</code> that the maximum number of iterations was reached without
termination of the second stage.  This may indicate an unbounded
function or simply that more iterations are needed. A value of
<code>1</code> indicates that an optimal solution has been found.
</p>
</dd>
<dt>value</dt><dd>
<p>The value of the objective function at <code>soln</code>.
</p>
</dd>
<dt>val.aux</dt><dd>
<p>This is <code>NULL</code> if a feasible solution is found. Otherwise it is
a positive value giving the value of the auxiliary objective
function when it was minimized.
</p>
</dd>
<dt>obj</dt><dd>
<p>The original coefficients of the objective function.
</p>
</dd>
<dt>a</dt><dd>
<p>The objective function coefficients re-expressed such that the basic
variables have coefficient zero.
</p>
</dd>
<dt>a.aux</dt><dd>
<p>This is <code>NULL</code> if a feasible solution is found. Otherwise it is the
re-expressed auxiliary objective function at the termination of the first
phase of the simplex method.
</p>
</dd>
<dt>A</dt><dd>
<p>The final constraint matrix which is expressed in terms of the
non-basic variables.  If a feasible solution is found then this will
have dimensions <code>m1+m2+m3</code> by <code>n+m1+m2</code>, where the final
<code>m1+m2</code> columns correspond to slack and surplus variables.  If
no feasible solution is found there will be an additional
<code>m1+m2+m3</code> columns for the artificial variables introduced to
solve the first phase of the problem.
</p>
</dd>
<dt>basic</dt><dd>
<p>The indices of the basic (non-zero) variables in the solution.
Indices between <code>n+1</code> and <code>n+m1</code> correspond to slack
variables, those between <code>n+m1+1</code> and <code>n+m2</code> correspond to
surplus variables and those greater than <code>n+m2</code> are artificial
variables.  Indices greater than <code>n+m2</code> should occur only if
<code>solved</code> is <code>-1</code> as the artificial variables are discarded in
the second stage of the simplex method.
</p>
</dd>
<dt>slack</dt><dd>
<p>The final values of the <code>m1</code> slack variables which arise when
the &quot;&lt;=&quot; constraints are re-expressed as the equalities
<code>A1%*%x + slack = b1</code>.
</p>
</dd>
<dt>surplus</dt><dd>
<p>The final values of the <code>m2</code> surplus variables which arise when
the &quot;&lt;=&quot; constraints are re-expressed as the equalities <code>A2%*%x -
        surplus = b2</code>.
</p>
</dd>
<dt>artificial</dt><dd>
<p>This is NULL if a feasible solution can be found.  If no solution
can be found then this contains the values of the <code>m1+m2+m3</code>
artificial variables which minimize their sum subject to the
original constraints.  A feasible solution exists only if all of the
artificial variables can be made 0 simultaneously.
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+print.simplex">print.simplex</a></code>, <code><a href="#topic+simplex">simplex</a></code>
</p>

<hr>
<h2 id='smooth.f'>
Smooth Distributions on Data Points
</h2><span id='topic+smooth.f'></span>

<h3>Description</h3>

<p>This function uses the method of frequency smoothing to find a distribution 
on a data set which has a required value, <code>theta</code>,  of the statistic of 
interest.  The method results in distributions which vary smoothly with 
<code>theta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth.f(theta, boot.out, index = 1, t = boot.out$t[, index],
         width = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.f_+3A_theta">theta</code></td>
<td>

<p>The required value for the statistic of interest.  If <code>theta</code> is a vector,
a separate distribution will be found for each element of <code>theta</code>.
</p>
</td></tr>
<tr><td><code id="smooth.f_+3A_boot.out">boot.out</code></td>
<td>

<p>A bootstrap output object returned by a call to <code>boot</code>.  
</p>
</td></tr>
<tr><td><code id="smooth.f_+3A_index">index</code></td>
<td>

<p>The index of the variable of interest in the output of <code>boot.out$statistic</code>.
This argument is ignored if <code>t</code> is supplied.  <code>index</code> must be a scalar.
</p>
</td></tr>
<tr><td><code id="smooth.f_+3A_t">t</code></td>
<td>

<p>The bootstrap values of the statistic of interest.  This must be a vector of
length <code>boot.out$R</code> and the values must be in the same order as the bootstrap
replicates in <code>boot.out</code>.
</p>
</td></tr>
<tr><td><code id="smooth.f_+3A_width">width</code></td>
<td>

<p>The standardized width for the kernel smoothing.  The smoothing uses a
value of <code>width*s</code> for epsilon, where <code>s</code> is the bootstrap estimate of the 
standard error of the statistic of interest.  <code>width</code> should take a value in 
the range (0.2, 1) to produce a reasonable
smoothed distribution.  If <code>width</code> is too large then the distribution becomes
closer to uniform. 
</p>
</td></tr></table>


<h3>Details</h3>

<p>The new distributional weights are found by applying a normal kernel smoother
to the observed values of <code>t</code> weighted by the observed frequencies in the
bootstrap simulation.  The resulting distribution may not have
parameter value exactly equal to the required value <code>theta</code> but it will 
typically have a value which is close to <code>theta</code>.  The details of how this
method works can be found in Davison, Hinkley and Worton (1995) and Section
3.9.2 of Davison and Hinkley (1997).
</p>


<h3>Value</h3>

<p>If <code>length(theta)</code> is 1 then a vector with the same length as the data set
<code>boot.out$data</code> is returned.  The value in position <code>i</code> is the probability 
to be given to the data point in position <code>i</code> so that the distribution has 
parameter value approximately equal to <code>theta</code>.
If <code>length(theta)</code> is bigger than 1 then the returned value is a matrix with 
<code>length(theta)</code> rows each of which corresponds to a distribution with the 
parameter value approximately equal to the corresponding value of <code>theta</code>.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Davison, A.C., Hinkley, D.V. and Worton, B.J. (1995) Accurate and efficient 
construction of bootstrap likelihoods. <em>Statistics and Computing</em>, 
<b>5</b>, 257&ndash;264.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+exp.tilt">exp.tilt</a></code>, <code><a href="#topic+tilt.boot">tilt.boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 9.8 of Davison and Hinkley (1997) requires tilting the resampling
# distribution of the studentized statistic to be centred at the observed
# value of the test statistic 1.84.  In the book exponential tilting was used
# but it is also possible to use smooth.f.
grav1 &lt;- gravity[as.numeric(gravity[, 2]) &gt;= 7, ]
grav.fun &lt;- function(dat, w, orig) {
     strata &lt;- tapply(dat[, 2], as.numeric(dat[, 2]))
     d &lt;- dat[, 1]
     ns &lt;- tabulate(strata)
     w &lt;- w/tapply(w, strata, sum)[strata]
     mns &lt;- as.vector(tapply(d * w, strata, sum)) # drop names
     mn2 &lt;- tapply(d * d * w, strata, sum)
     s2hat &lt;- sum((mn2 - mns^2)/ns)
     c(mns[2] - mns[1], s2hat, (mns[2]-mns[1]-orig)/sqrt(s2hat))
}
grav.z0 &lt;- grav.fun(grav1, rep(1, 26), 0)
grav.boot &lt;- boot(grav1, grav.fun, R = 499, stype = "w", 
                  strata = grav1[, 2], orig = grav.z0[1])
grav.sm &lt;- smooth.f(grav.z0[3], grav.boot, index = 3)

# Now we can run another bootstrap using these weights
grav.boot2 &lt;- boot(grav1, grav.fun, R = 499, stype = "w", 
                   strata = grav1[, 2], orig = grav.z0[1],
                   weights = grav.sm)

# Estimated p-values can be found from these as follows
mean(grav.boot$t[, 3] &gt;= grav.z0[3])
imp.prob(grav.boot2, t0 = -grav.z0[3], t = -grav.boot2$t[, 3])


# Note that for the importance sampling probability we must 
# multiply everything by -1 to ensure that we find the correct
# probability.  Raw resampling is not reliable for probabilities
# greater than 0.5. Thus
1 - imp.prob(grav.boot2, index = 3, t0 = grav.z0[3])$raw
# can give very strange results (negative probabilities).
</code></pre>

<hr>
<h2 id='sunspot'>
Annual Mean Sunspot Numbers
</h2><span id='topic+sunspot'></span>

<h3>Description</h3>

<p><code>sunspot</code> is a time series and contains 289 observations.
</p>
<p>The Zurich sunspot numbers have been analyzed in almost all books on time
series analysis as well as numerous papers.  The data set, usually attributed
to Rudolf Wolf, consists of means of daily relative numbers of sunspot 
sightings.
The relative number for a day is given by k(f+10g) where g is the number of
sunspot groups observed, f is the total number of spots within the groups and
k is a scaling factor relating the observer and telescope to a baseline. The
relative numbers are then averaged to give an annual figure.   
See Inzenman (1983) for a discussion of the relative numbers. The figures are
for the years 1700-1988.
</p>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Tong, H. (1990) <em>Nonlinear Time Series: A Dynamical System Approach</em>.
Oxford University Press
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Inzenman, A.J. (1983) J.R. Wolf and H.A. Wolfer: An historical note on the
Zurich sunspot relative numbers. 
<em>Journal of the Royal Statistical Society, A</em>, <b>146</b>,
311-318.
</p>
<p>Waldmeir, M. (1961) <em>The Sunspot Activity in the Years 1610-1960</em>.
Schulthess and Co.
</p>

<hr>
<h2 id='survival'>
Survival of Rats after Radiation Doses
</h2><span id='topic+survival'></span>

<h3>Description</h3>

<p>The <code>survival</code> data frame has 14 rows and 2 columns.
</p>
<p>The data measured the survival percentages of batches of rats who were given 
varying doses of radiation.  At each of 6 doses there were two or three
replications of the experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survival
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>dose</code></dt><dd>
<p>The dose of radiation administered (rads).
</p>
</dd>
<dt><code>surv</code></dt><dd>
<p>The survival rate of the batches expressed as a percentage.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Efron, B. (1988) Computer-intensive methods in statistical regression.
<em>SIAM Review</em>, <b>30</b>, 421&ndash;449.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='tau'>
Tau Particle Decay Modes
</h2><span id='topic+tau'></span>

<h3>Description</h3>

<p>The <code>tau</code> data frame has 60 rows and 2 columns.
</p>
<p>The tau particle is a heavy electron-like particle discovered in the 1970's
by Martin Perl at the Stanford Linear Accelerator Center.  Soon after its
production the tau particle decays into various collections of more stable
particles.  About 86% of the time the decay involves just one charged particle.
This rate has been measured independently 13 times.  
</p>
<p>The one-charged-particle event is made up of four major modes of decay as well
as a collection of other events.  The four main types of decay are denoted
rho, pi, e and mu.  These rates have been measured independently 6, 7, 14 and
19 times respectively.  Due to physical constraints each experiment can only
estimate the composite one-charged-particle decay rate or the rate of one of
the major modes of decay.  
</p>
<p>Each experiment consists of a major research project involving many years work.
One of the goals of the experiments was to estimate the rate of decay due to 
events other than the four main modes of decay.  These are uncertain events and
so cannot themselves be observed directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tau
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>rate</code></dt><dd>
<p>The decay rate expressed as a percentage.
</p>
</dd>
<dt><code>decay</code></dt><dd>
<p>The type of decay measured in the experiment.  It is a factor with levels
<code>1</code>, <code>rho</code>, <code>pi</code>, <code>e</code> and <code>mu</code>.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Efron, B. (1992) Jackknife-after-bootstrap standard errors and influence 
functions (with Discussion). 
<em>Journal of the Royal Statistical Society, B</em>, <b>54</b>, 83&ndash;127.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Hayes, K.G., Perl, M.L. and Efron, B. (1989) Application of the bootstrap
statistical method to the tau-decay-mode problem. 
<em>Physical Review, D</em>, <b>39</b>,
274-279.
</p>

<hr>
<h2 id='tilt.boot'>
Non-parametric Tilted Bootstrap
</h2><span id='topic+tilt.boot'></span>

<h3>Description</h3>

<p>This function will run an initial bootstrap with equal resampling 
probabilities (if required) and will use the output of the initial run to 
find resampling probabilities which put the
value of the statistic at required values.  It then runs an importance
resampling bootstrap using the calculated probabilities as the resampling
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tilt.boot(data, statistic, R, sim = "ordinary", stype = "i", 
          strata = rep(1, n), L = NULL, theta = NULL, 
          alpha = c(0.025, 0.975), tilt = TRUE, width = 0.5, 
          index = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tilt.boot_+3A_data">data</code></td>
<td>

<p>The data as a vector, matrix or data frame.  If it is a matrix or
data frame then each row is considered as one (multivariate)
observation.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_statistic">statistic</code></td>
<td>

<p>A function which when applied to data returns a vector containing the
statistic(s) of interest.  It must take at least two arguments.  The first
argument will always be <code>data</code> and the second should be a
vector of indices, weights or frequencies describing the bootstrap
sample.  Any other arguments must be supplied to <code>tilt.boot</code>
and will be passed unchanged to statistic each time it is called.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_r">R</code></td>
<td>

<p>The number of bootstrap replicates required.  This will generally be
a vector, the first value stating how many uniform bootstrap
simulations are to be performed at the initial stage.  The remaining
values of <code>R</code> are the number of simulations to be performed
resampling from each reweighted distribution. The first value of
<code>R</code> must always be present, a value of 0 implying that no
uniform resampling is to be carried out.  Thus <code>length(R)</code>
should always equal <code>1+length(theta)</code>.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_sim">sim</code></td>
<td>

<p>This is a character string indicating the type of bootstrap
simulation required.  There are only two possible values that this
can take: <code>"ordinary"</code> and <code>"balanced"</code>.  If other
simulation types are required for the initial un-weighted bootstrap
then it will be necessary to run <code>boot</code>, calculate the weights
appropriately, and run <code>boot</code> again using the calculated
weights.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_stype">stype</code></td>
<td>

<p>A character string indicating the type of second argument expected
by <code>statistic</code>.  The possible values that <code>stype</code> can take
are <code>"i"</code> (indices), <code>"w"</code> (weights) and <code>"f"</code>
(frequencies).
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_strata">strata</code></td>
<td>

<p>An integer vector or factor representing the strata for multi-sample
problems.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_l">L</code></td>
<td>

<p>The empirical influence values for the statistic of interest.  They
are used only for exponential tilting when <code>tilt</code> is
<code>TRUE</code>.  If <code>tilt</code> is <code>TRUE</code> and they are not
supplied then <code>tilt.boot</code> uses <code>empinf</code> to calculate
them.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_theta">theta</code></td>
<td>

<p>The required parameter value(s) for the tilted distribution(s).
There should be one value of <code>theta</code> for each of the
non-uniform distributions.  If <code>R[1]</code> is 0 <code>theta</code> is a
required argument.  Otherwise <code>theta</code> values can be estimated
from the initial uniform bootstrap and the values in <code>alpha</code>.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_alpha">alpha</code></td>
<td>

<p>The alpha level to which tilting is required.  This parameter is
ignored if <code>R[1]</code> is 0 or if <code>theta</code> is supplied,
otherwise it is used to find the values of <code>theta</code> as quantiles
of the initial uniform bootstrap.  In this case <code>R[1]</code> should
be large enough that <code>min(c(alpha, 1-alpha))*R[1] &gt; 5</code>, if this
is not the case then a warning is generated to the effect that the
<code>theta</code> are extreme values and so the tilted output may be
unreliable. 
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_tilt">tilt</code></td>
<td>

<p>A logical variable which if <code>TRUE</code> (the default) indicates that
exponential tilting should be used, otherwise local frequency
smoothing (<code>smooth.f</code>) is used.  If <code>tilt</code> is <code>FALSE</code>
then <code>R[1]</code> must be positive.  In fact in this case the value
of <code>R[1]</code> should be fairly large (in the region of 500 or
more).
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_width">width</code></td>
<td>

<p>This argument is used only if <code>tilt</code> is <code>FALSE</code>, in which
case it is passed unchanged to <code>smooth.f</code> as the standardized
bandwidth for the smoothing operation.  The value should generally
be in the range (0.2, 1). See <code>smooth.f</code> for for more details.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_index">index</code></td>
<td>

<p>The index of the statistic of interest in the output from
<code>statistic</code>.  By default the first element of the output of
<code>statistic</code> is used.
</p>
</td></tr>
<tr><td><code id="tilt.boot_+3A_...">...</code></td>
<td>

<p>Any additional arguments required by <code>statistic</code>.  These are
passed unchanged to <code>statistic</code> each time it is called.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"boot"</code> with the following components
</p>
<table>
<tr><td><code>t0</code></td>
<td>

<p>The observed value of the statistic on the original data.
</p>
</td></tr>
<tr><td><code>t</code></td>
<td>

<p>The values of the bootstrap replicates of the statistic.  There will
be <code>sum(R)</code> of these, the first <code>R[1]</code> corresponding to the
uniform bootstrap and the remainder to the tilted bootstrap(s).
</p>
</td></tr>
<tr><td><code>R</code></td>
<td>

<p>The input vector of the number of bootstrap replicates.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>The original data as supplied.
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>

<p>The <code>statistic</code> function as supplied.
</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>

<p>The simulation type used in the bootstrap(s), it can either be
<code>"ordinary"</code> or <code>"balanced"</code>.
</p>
</td></tr>
<tr><td><code>stype</code></td>
<td>

<p>The type of statistic supplied, it is the same as the input value
<code>stype</code>.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>A copy of the original call to <code>tilt.boot</code>.
</p>
</td></tr>
<tr><td><code>strata</code></td>
<td>

<p>The strata as supplied.
</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>

<p>The matrix of weights used.  If <code>R[1]</code> is greater than 0 then the
first row will be the uniform weights and each subsequent row the
tilted weights. If <code>R[1]</code> equals 0 then the uniform weights are
omitted and only the tilted weights are output.
</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>

<p>The values of <code>theta</code> used for the tilted distributions.  These
are either the input values or the values derived from the uniform
bootstrap and <code>alpha</code>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Booth, J.G., Hall, P. and Wood, A.T.A. (1993) Balanced importance resampling 
for the bootstrap. <em>Annals of Statistics</em>, <b>21</b>, 286&ndash;298.
</p>
<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Hinkley, D.V. and Shi, S. (1989) Importance sampling and the nested bootstrap. 
<em>Biometrika</em>, <b>76</b>, 435&ndash;446.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="#topic+exp.tilt">exp.tilt</a></code>, <code><a href="#topic+Imp.Estimates">Imp.Estimates</a></code>, <code><a href="#topic+imp.weights">imp.weights</a></code>, <code><a href="#topic+smooth.f">smooth.f</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Note that these examples can take a while to run.

# Example 9.9 of Davison and Hinkley (1997).
grav1 &lt;- gravity[as.numeric(gravity[,2]) &gt;= 7, ]
grav.fun &lt;- function(dat, w, orig) {
     strata &lt;- tapply(dat[, 2], as.numeric(dat[, 2]))
     d &lt;- dat[, 1]
     ns &lt;- tabulate(strata)
     w &lt;- w/tapply(w, strata, sum)[strata]
     mns &lt;- as.vector(tapply(d * w, strata, sum)) # drop names
     mn2 &lt;- tapply(d * d * w, strata, sum)
     s2hat &lt;- sum((mn2 - mns^2)/ns)
     c(mns[2]-mns[1],s2hat,(mns[2]-mns[1]-orig)/sqrt(s2hat))
}
grav.z0 &lt;- grav.fun(grav1, rep(1, 26), 0)
tilt.boot(grav1, grav.fun, R = c(249, 375, 375), stype = "w", 
          strata = grav1[,2], tilt = TRUE, index = 3, orig = grav.z0[1]) 


#  Example 9.10 of Davison and Hinkley (1997) requires a balanced 
#  importance resampling bootstrap to be run.  In this example we 
#  show how this might be run.  
acme.fun &lt;- function(data, i, bhat) {
     d &lt;- data[i,]
     n &lt;- nrow(d)
     d.lm &lt;- glm(d$acme~d$market)
     beta.b &lt;- coef(d.lm)[2]
     d.diag &lt;- boot::glm.diag(d.lm)
     SSx &lt;- (n-1)*var(d$market)
     tmp &lt;- (d$market-mean(d$market))*d.diag$res*d.diag$sd
     sr &lt;- sqrt(sum(tmp^2))/SSx
     c(beta.b, sr, (beta.b-bhat)/sr)
}
acme.b &lt;- acme.fun(acme, 1:nrow(acme), 0)
acme.boot1 &lt;- tilt.boot(acme, acme.fun, R = c(499, 250, 250), 
                        stype = "i", sim = "balanced", alpha = c(0.05, 0.95), 
                        tilt = TRUE, index = 3, bhat = acme.b[1])
</code></pre>

<hr>
<h2 id='tsboot'>
Bootstrapping of Time Series
</h2><span id='topic+tsboot'></span><span id='topic+ts.return'></span>

<h3>Description</h3>

<p>Generate <code>R</code> bootstrap replicates of a statistic applied to a
time series.  The replicate time series can be generated using fixed
or random block lengths or can be model based replicates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tsboot(tseries, statistic, R, l = NULL, sim = "model",
       endcorr = TRUE, n.sim = NROW(tseries), orig.t = TRUE,
       ran.gen, ran.args = NULL, norm = TRUE, ...,
       parallel = c("no", "multicore", "snow"),
       ncpus = getOption("boot.ncpus", 1L), cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tsboot_+3A_tseries">tseries</code></td>
<td>

<p>A univariate or multivariate time series.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_statistic">statistic</code></td>
<td>

<p>A function which when applied to <code>tseries</code> returns a vector
containing the statistic(s) of interest.  Each time <code>statistic</code> is
called it is passed a time series of length <code>n.sim</code> which is of the
same class as the original <code>tseries</code>.  Any other arguments which
<code>statistic</code> takes must remain constant for each bootstrap replicate
and should be supplied through the ... argument to <code>tsboot</code>.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_r">R</code></td>
<td>

<p>A positive integer giving the number of bootstrap replicates required.  
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_sim">sim</code></td>
<td>

<p>The type of simulation required to generate the replicate time series.  The
possible input values are <code>"model"</code> (model based resampling),
<code>"fixed"</code> (block resampling with fixed block lengths of
<code>l</code>), <code>"geom"</code> (block resampling with block lengths
having a geometric distribution with mean <code>l</code>) or
<code>"scramble"</code> (phase scrambling).
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_l">l</code></td>
<td>

<p>If <code>sim</code> is <code>"fixed"</code> then <code>l</code> is the fixed block
length used in generating the replicate time series.  If <code>sim</code> is
<code>"geom"</code> then <code>l</code> is the mean of the geometric distribution
used to generate the block lengths. <code>l</code> should be a positive
integer less than the length of <code>tseries</code>.  This argument is not
required when <code>sim</code> is <code>"model"</code> but it is required for all
other simulation types.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_endcorr">endcorr</code></td>
<td>

<p>A logical variable indicating whether end corrections are to be
applied when <code>sim</code> is <code>"fixed"</code>.  When <code>sim</code> is
<code>"geom"</code>, <code>endcorr</code> is automatically set to <code>TRUE</code>;
<code>endcorr</code> is not used when <code>sim</code> is <code>"model"</code> or
<code>"scramble"</code>.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_n.sim">n.sim</code></td>
<td>

<p>The length of the simulated time series.  Typically this will be equal
to the length of the original time series but there are situations when
it will be larger.  One obvious situation is if prediction is required.
Another situation in which <code>n.sim</code> is larger than the original
length is if <code>tseries</code> is a residual time series from fitting some
model to the original time series. In this case, <code>n.sim</code> would
usually be the length of the original time series.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_orig.t">orig.t</code></td>
<td>

<p>A logical variable which indicates whether <code>statistic</code> should be
applied to <code>tseries</code> itself as well as the bootstrap replicate
series.  If <code>statistic</code> is expecting a longer time series than
<code>tseries</code> or if applying <code>statistic</code> to <code>tseries</code> will
not yield any useful information then <code>orig.t</code> should be set to
<code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_ran.gen">ran.gen</code></td>
<td>

<p>This is a function of three arguments.  The first argument is a time
series.  If <code>sim</code> is <code>"model"</code> then it will always be
<code>tseries</code> that is passed.  For other simulation types it is the
result of selecting <code>n.sim</code> observations from <code>tseries</code> by
some scheme and converting the result back into a time series of the
same form as <code>tseries</code> (although of length <code>n.sim</code>).  The
second argument to <code>ran.gen</code> is always the value <code>n.sim</code>, and
the third argument is <code>ran.args</code>, which is used to supply any other
objects needed by <code>ran.gen</code>.  If <code>sim</code> is <code>"model"</code> then
the generation of the replicate time series will be done in
<code>ran.gen</code> (for example through use of <code><a href="stats.html#topic+arima.sim">arima.sim</a></code>).
For the other simulation types <code>ran.gen</code> is used for
&lsquo;post-blackening&rsquo;.  The default is that the function simply returns
the time series passed to it.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_ran.args">ran.args</code></td>
<td>

<p>This will be supplied to <code>ran.gen</code> each time it is called.  If
<code>ran.gen</code> needs any extra arguments then they should be
supplied as components of <code>ran.args</code>. Multiple arguments may be
passed by making <code>ran.args</code> a list.  If <code>ran.args</code> is
<code>NULL</code> then it should not be used within <code>ran.gen</code> but
note that <code>ran.gen</code> must still have its third argument.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_norm">norm</code></td>
<td>

<p>A logical argument indicating whether normal margins should be used
for phase scrambling.  If <code>norm</code> is <code>FALSE</code> then margins
corresponding to the exact empirical margins are used.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_...">...</code></td>
<td>

<p>Extra named arguments to <code>statistic</code> may be supplied here.
Beware of partial matching to the arguments of <code>tsboot</code> listed above.
</p>
</td></tr>
<tr><td><code id="tsboot_+3A_parallel">parallel</code>, <code id="tsboot_+3A_ncpus">ncpus</code>, <code id="tsboot_+3A_cl">cl</code></td>
<td>

<p>See the help for <code><a href="#topic+boot">boot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>sim</code> is <code>"fixed"</code> then each replicate time series is
found by taking blocks of length <code>l</code>, from the original time
series and putting them end-to-end until a new series of length
<code>n.sim</code> is created.  When <code>sim</code> is <code>"geom"</code> a similar
approach is taken except that now the block lengths are generated from
a geometric distribution with mean <code>l</code>.  Post-blackening can be
carried out on these replicate time series by including the function
<code>ran.gen</code> in the call to <code>tsboot</code> and having <code>tseries</code>
as a time series of residuals.
</p>
<p>Model based resampling is very similar to the parametric bootstrap and
all simulation must be in one of the user specified functions.  This
avoids the complicated problem of choosing the block length but relies
on an accurate model choice being made.
</p>
<p>Phase scrambling is described in Section 8.2.4 of Davison and Hinkley
(1997).  The types of statistic for which this method produces
reasonable results is very limited and the other methods seem to do
better in most situations.  Other types of resampling in the frequency
domain can be accomplished using the function <code>boot</code> with the
argument <code>sim = "parametric"</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"boot"</code> with the following components.
</p>
<table>
<tr><td><code>t0</code></td>
<td>

<p>If <code>orig.t</code> is <code>TRUE</code> then <code>t0</code> is the result of
<code>statistic(tseries,...{})</code> otherwise it is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code>t</code></td>
<td>

<p>The results of applying <code>statistic</code> to the replicate time series. 
</p>
</td></tr>
<tr><td><code>R</code></td>
<td>

<p>The value of <code>R</code> as supplied to <code>tsboot</code>.
</p>
</td></tr>
<tr><td><code>tseries</code></td>
<td>

<p>The original time series.
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>

<p>The function <code>statistic</code> as supplied.
</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>

<p>The simulation type used in generating the replicates.
</p>
</td></tr>
<tr><td><code>endcorr</code></td>
<td>

<p>The value of <code>endcorr</code> used.  The value is meaningful only when
<code>sim</code> is <code>"fixed"</code>; it is ignored for model based simulation
or phase scrambling and is always set to <code>TRUE</code> if <code>sim</code> is
<code>"geom"</code>.
</p>
</td></tr>
<tr><td><code>n.sim</code></td>
<td>

<p>The value of <code>n.sim</code> used.
</p>
</td></tr>
<tr><td><code>l</code></td>
<td>

<p>The value of <code>l</code> used for block based resampling.  This will be
<code>NULL</code> if block based resampling was not used.
</p>
</td></tr>
<tr><td><code>ran.gen</code></td>
<td>

<p>The <code>ran.gen</code> function used for generating the series or for
&lsquo;post-blackening&rsquo;.
</p>
</td></tr>
<tr><td><code>ran.args</code></td>
<td>

<p>The extra arguments passed to <code>ran.gen</code>.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The original call to <code>tsboot</code>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>
<p>Kunsch, H.R. (1989) The jackknife and the bootstrap for general stationary
observations. <em>Annals of Statistics</em>, <b>17</b>, 1217&ndash;1241.
</p>
<p>Politis, D.N. and Romano, J.P. (1994) The stationary bootstrap. 
<em>Journal of the American Statistical Association</em>, <b>89</b>, 1303&ndash;1313.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot">boot</a></code>, <code><a href="stats.html#topic+arima.sim">arima.sim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lynx.fun &lt;- function(tsb) {
     ar.fit &lt;- ar(tsb, order.max = 25)
     c(ar.fit$order, mean(tsb), tsb)
}

# the stationary bootstrap with mean block length 20
lynx.1 &lt;- tsboot(log(lynx), lynx.fun, R = 99, l = 20, sim = "geom")

# the fixed block bootstrap with length 20
lynx.2 &lt;- tsboot(log(lynx), lynx.fun, R = 99, l = 20, sim = "fixed")

# Now for model based resampling we need the original model
# Note that for all of the bootstraps which use the residuals as their
# data, we set orig.t to FALSE since the function applied to the residual
# time series will be meaningless.
lynx.ar &lt;- ar(log(lynx))
lynx.model &lt;- list(order = c(lynx.ar$order, 0, 0), ar = lynx.ar$ar)
lynx.res &lt;- lynx.ar$resid[!is.na(lynx.ar$resid)]
lynx.res &lt;- lynx.res - mean(lynx.res)

lynx.sim &lt;- function(res,n.sim, ran.args) {
     # random generation of replicate series using arima.sim 
     rg1 &lt;- function(n, res) sample(res, n, replace = TRUE)
     ts.orig &lt;- ran.args$ts
     ts.mod &lt;- ran.args$model
     mean(ts.orig)+ts(arima.sim(model = ts.mod, n = n.sim,
                      rand.gen = rg1, res = as.vector(res)))
}

lynx.3 &lt;- tsboot(lynx.res, lynx.fun, R = 99, sim = "model", n.sim = 114,
                 orig.t = FALSE, ran.gen = lynx.sim, 
                 ran.args = list(ts = log(lynx), model = lynx.model))

#  For "post-blackening" we need to define another function
lynx.black &lt;- function(res, n.sim, ran.args) {
     ts.orig &lt;- ran.args$ts
     ts.mod &lt;- ran.args$model
     mean(ts.orig) + ts(arima.sim(model = ts.mod,n = n.sim,innov = res))
}

# Now we can run apply the two types of block resampling again but this
# time applying post-blackening.
lynx.1b &lt;- tsboot(lynx.res, lynx.fun, R = 99, l = 20, sim = "fixed",
                  n.sim = 114, orig.t = FALSE, ran.gen = lynx.black, 
                  ran.args = list(ts = log(lynx), model = lynx.model))

lynx.2b &lt;- tsboot(lynx.res, lynx.fun, R = 99, l = 20, sim = "geom",
                  n.sim = 114, orig.t = FALSE, ran.gen = lynx.black, 
                  ran.args = list(ts = log(lynx), model = lynx.model))

# To compare the observed order of the bootstrap replicates we
# proceed as follows.
table(lynx.1$t[, 1])
table(lynx.1b$t[, 1])
table(lynx.2$t[, 1])
table(lynx.2b$t[, 1])
table(lynx.3$t[, 1])
# Notice that the post-blackened and model-based bootstraps preserve
# the true order of the model (11) in many more cases than the others.
</code></pre>

<hr>
<h2 id='tuna'>
Tuna Sighting Data
</h2><span id='topic+tuna'></span>

<h3>Description</h3>

<p>The <code>tuna</code> data frame has 64 rows and 1 columns.  
</p>
<p>The data come from an aerial
line transect survey of Southern Bluefin Tuna in the Great Australian Bight.
An aircraft with two spotters on board flies randomly allocated line transects.
Each school of tuna sighted is counted and its perpendicular distance from the
transect measured.  The survey was conducted in summer when tuna tend to stay
on the surface.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuna
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following column:
</p>

<dl>
<dt><code>y</code></dt><dd>
<p>The perpendicular distance, in miles, from the transect for 64 independent 
sightings of tuna schools.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Chen, S.X. (1996) Empirical likelihood confidence intervals for
nonparametric density estimation. <em>Biometrika</em>, <b>83</b>, 329&ndash;341.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='urine'>
Urine Analysis Data
</h2><span id='topic+urine'></span>

<h3>Description</h3>

<p>The <code>urine</code> data frame has 79 rows and 7 columns.
</p>
<p>79 urine specimens were analyzed in an effort to determine if certain physical
characteristics of the urine might be related to the formation of calcium
oxalate crystals.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>urine
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>r</code></dt><dd>
<p>Indicator of the presence of calcium oxalate crystals.
</p>
</dd>
<dt><code>gravity</code></dt><dd>
<p>The specific gravity of the urine.
</p>
</dd>
<dt><code>ph</code></dt><dd>
<p>The pH reading of the urine.
</p>
</dd>
<dt><code>osmo</code></dt><dd>
<p>The osmolarity of the urine. Osmolarity is proportional to the concentration
of molecules in solution.
</p>
</dd>
<dt><code>cond</code></dt><dd>
<p>The conductivity of the urine.  Conductivity is proportional to the 
concentration of charged ions in solution.
</p>
</dd>
<dt><code>urea</code></dt><dd>
<p>The urea concentration in millimoles per litre.
</p>
</dd>
<dt><code>calc</code></dt><dd>
<p>The calcium concentration in millimoles per litre.
</p>
</dd></dl>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Andrews, D.F. and Herzberg, A.M. (1985) 
<em>Data: A Collection of Problems from Many Fields for the Student and Research Worker</em>. Springer-Verlag.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) 
<em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

<hr>
<h2 id='var.linear'>
Linear Variance Estimate
</h2><span id='topic+var.linear'></span>

<h3>Description</h3>

<p>Estimates the variance of a statistic from its empirical influence values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var.linear(L, strata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var.linear_+3A_l">L</code></td>
<td>

<p>Vector of the empirical influence values of a statistic.  These will usually
be calculated by a call to <code>empinf</code>.
</p>
</td></tr>
<tr><td><code id="var.linear_+3A_strata">strata</code></td>
<td>

<p>A numeric vector or factor specifying which  observations (and hence empirical
influence values) come from which strata.
</p>
</td></tr></table>


<h3>Value</h3>

<p>The variance estimate calculated from <code>L</code>.
</p>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+empinf">empinf</a></code>, <code><a href="#topic+linear.approx">linear.approx</a></code>, <code><a href="#topic+k3.linear">k3.linear</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  To estimate the variance of the ratio of means for the city data.
ratio &lt;- function(d,w) sum(d$x * w)/sum(d$u * w)
var.linear(empinf(data = city, statistic = ratio))
</code></pre>

<hr>
<h2 id='wool'>
Australian Relative Wool Prices
</h2><span id='topic+wool'></span>

<h3>Description</h3>

<p><code>wool</code> is a time series of class <code>"ts"</code> and contains 309 observations.
</p>
<p>Each week that the market is open the Australian Wool Corporation set a floor
price which determines their policy on intervention and is therefore a 
reflection of the overall price of wool for the week in question.  Actual prices
paid can vary considerably about the floor price.  The series here is the log
of the ratio between the price for fine grade wool and the floor price, each
market week between July 1976 and Jun 1984.
</p>


<h3>Source</h3>

<p>The data were obtained from
</p>
<p>Diggle, P.J. (1990) <em>Time Series: A Biostatistical Introduction</em>.
Oxford University Press.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997) <em>Bootstrap Methods and Their Application</em>. Cambridge University Press.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
