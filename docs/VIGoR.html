<!DOCTYPE html><html><head><title>Help for package VIGoR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {VIGoR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#hyperpara'>
<p>Calculation of hyperparameter values</p></a></li>
<li><a href='#predict_vigor'>
<p>Predict Y of new data using a training result with vigor</p></a></li>
<li><a href='#vigor'><p>Variational Bayesian inference for genome-wide regression</p></a></li>
<li><a href='#X'>
<p>An example of SNP genotypes (explanatory variables)</p></a></li>
<li><a href='#Y'>
<p>An example of response variables.</p></a></li>
<li><a href='#Z'>
<p>An example of fixed effects (explanatory variables)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variational Bayesian Inference for Genome-Wide Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-06-05</td>
</tr>
<tr>
<td>Description:</td>
<td>Conducts linear regression using variational Bayesian inference, particularly optimized for genome-wide association mapping and whole-genome prediction which use a number of DNA markers as the explanatory variables. Provides seven regression models which select the important variables (i.e., the variables related to response variables) among the given explanatory variables in different ways (i.e., model structures).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-05 05:05:39 UTC; lbds2</td>
</tr>
<tr>
<td>Author:</td>
<td>Akio Onogi [aut, cre, cph],
  R Core Team [ctb] (Provide Rdynload.h and Boolean.h),
  Hiroyoshi Iwata [cph],
  Takuji Nishimura [ctb] (Developer of Mersenne twister in header1.h),
  Makoto Matsumoto [ctb] (Developer of Mersenne twister in header1.h),
  STRUCTURE software contributors [ctb] (Provide snorm and RNormal
    functions in header2.h),
  Alan Miller [ctb] (Program mylgamma function in header2.h),
  Peter Beerli [ctb] (Translate mylgamma function in header2.h)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Akio Onogi &lt;onogiakio@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-05 05:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='hyperpara'>
Calculation of hyperparameter values
</h2><span id='topic+hyperpara'></span>

<h3>Description</h3>

<p>This function determines the hyperparameter values of regression methods,
based on two assumptions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hyperpara(X, Mvar, Model = c("BL", "EBL", "BayesA", "BayesB", "BayesC", "BRR"),
          Kappa = 0.01, Xtype = c("Geno", "Var"), f = 0, BL.Phi = 1, EBL.Phi = 0.1,
          EBL.Omega = 0.1, EBL.Psi = 1, Nu = 5, Verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hyperpara_+3A_x">X</code></td>
<td>

<p>An (N x P) matrix, where N and P denote the number of samples and variables, respectively. When X is SNP genotypes as specified by Xtype = &quot;Geno&quot;, SNP genotypes should be coded with values between 0 and 2. SNP genotypes are used to calculate sum (2*Q*(1-Q)*(1+f)) where Q is a vector of allele frequencies and f is the inbreeding coefficient. Missing values in X are not allowed. When X is &quot;Var&quot;(variables other than SNPs), variances of variables are used instead of sum (2*Q*(1-Q)*(1+f)).
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_mvar">Mvar</code></td>
<td>

<p>A scalar or vector denoting the assumed proportion of variance of Y that can be explained by X. Mvar is &lt; 1.0 in BL and EBL, and &lt;= 1.0 in the other methods.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_model">Model</code></td>
<td>

<p>One of the six regression methods (BL, EBL, BayesA, BayesB, BayesC, BRR).
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_kappa">Kappa</code></td>
<td>

<p>A scalar or vector containing the assumed proportion of variables with NON-ZERO EFFECTS. Used when BL, EBL, BayesB, and BayesC. Kappa is set to 1 when BayesA and BRR are used.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_xtype">Xtype</code></td>
<td>

<p>Allowed Xtypes are &quot;Geno&quot; and &quot;Var&quot;. Enter &quot;Geno&quot; when X contains the SNP genotypes and &quot;Var&quot; when X contains variables other than SNP genotypes.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_f">f</code></td>
<td>

<p>A scalar representing the inbreeding coefficient. Enter 1 for inbred species.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_bl.phi">BL.Phi</code></td>
<td>

<p>A scalar or vector containing Phi values of BL.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_ebl.phi">EBL.Phi</code></td>
<td>

<p>A scalar or vector containing Phi values of EBL.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_ebl.omega">EBL.Omega</code></td>
<td>

<p>A scalar or vector containing Omega values of EBL.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_ebl.psi">EBL.Psi</code></td>
<td>

<p>A scalar or vector containing Psi values of EBL.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_nu">Nu</code></td>
<td>

<p>A scalar or vector containing Nu values of BayesA, BayesB, BayesC, and BRR.
</p>
</td></tr>
<tr><td><code id="hyperpara_+3A_verbose">Verbose</code></td>
<td>

<p>Specifies whether to print information (TRUE) or not (FALSE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To run vigor, users must specify the following hyperparameter values.<br />
</p>

<ul>
<li><p> BL: Phi, Omega
</p>
</li>
<li><p> EBL: Phi, Omega, Psi, Theta
</p>
</li>
<li><p> BayesA: Nu, S2
</p>
</li>
<li><p> BayesB: Nu, S2, Kappa
</p>
</li>
<li><p> BayesC: Nu, S2, Kappa
</p>
</li>
<li><p> BRR: Nu, S2
</p>
</li></ul>

<p>This function calculates the Omega of BL; Theta of EBL; S2 of BayesA, BayesB, BayesC, and BRR. Mvar, Kappa, and the other hyperparameters required by each method are specified by the user. The definitions of Mvar and Kappa are intuitively understandable and relatively easy to specify (see Arguments). For the other hyperparameters, the default values are recommended. When the arguments of hyperpara are vectors, all value-combinations are returned as a matrix. The hyperparameters are explained in the details of vigor and in the pdf manual of VIGoR (Onogi 2021).
</p>


<h3>Value</h3>

<p>This function returns a vector when yielding a single hyperparameter set, and a matrix when yielding multiple hyperparameter sets. The rows and columns of the matrix correspond to the sets (value combinations) and the hyperparameters, respectively. See examples below.<br />
</p>


<h3>References</h3>

<p>Onogi A., Variational Bayesian inference for genome-wide regression: joint estimation of multiple learners, in prep.<br />
Onogi A. &amp; Iwata H., 2016 VIGoR: Variational Bayesian Inference for Genome-Wide Regression.
Journal of Open Research Software, 4: e11<br />
Onogi A., 2021, Documents for VIGoR ver. 1.1.0, https://github.com/Onogi/VIGoR<br />
</p>


<h3>See Also</h3>

<p>vigor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#data
data(sampledata)
dim(X) #500 samples and 1000 variables
unique(X[1:(100*1000)]) #coded as 0, 1, 2

#A single Mvar (0.5) and Kappa (0.01) value is assumed for BL.
#A vector is returned.
hyperpara(X, 0.5, "BL", 0.01, Verbose = TRUE)

#Phi is set to 1 as default. To change Phi, use BL.Phi.
hyperpara(X, 0.5, "BL", 0.01, BL.Phi = 5)

#Calculate multiple hyperparameter value sets of BayesC assuming that Kappa is 0.1 and 0.01.
#A matrix is returned.
hyperpara(X, 0.5, "BayesC", c(0.1, 0.01))

#The output vector can be used as the argument of vigor
ETA &lt;- list(list(model = "BayesB",X = X,
                 H = hyperpara(X, 0.5, "BayesC", c(0.1, 0.01))))
Result &lt;- vigor(Y, ETA, Function = "tuning")
Result$Metrics

#Calculate hyperparameter values of EBL
hyperpara(X, c(0.2, 0.5), "EBL", c(0.1, 0.01), EBL.Omega = c(0.5, 1))
#Total 2 (Mvar) x 2 (Kappa) x 2 (EBL.Omega) = 8 sets are returned.

</code></pre>

<hr>
<h2 id='predict_vigor'>
Predict Y of new data using a training result with vigor
</h2><span id='topic+predict_vigor'></span>

<h3>Description</h3>

<p>This function predicts Y of new data using a training result with vigor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_vigor(training_result, newX)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_vigor_+3A_training_result">training_result</code></td>
<td>

<p>Result of vigor
</p>
</td></tr>
<tr><td><code id="predict_vigor_+3A_newx">newX</code></td>
<td>

<p>A list of X. newX contains X for each learner. The length and order of learners should be same as those of ETA used for training. Each element of newX is a matrix. When BLUP is used, X is an n1 x n2 relationship matrix where n1 and n2 are the numbers of samples in test and training data, respectively. When the other methods are used, X is an n1 x p matrix where p is the number of explanatory variables. p should be the same as the training data. When the intercept is added automatically, newX needs not to include the intercept.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function predict Y of new data (newX). When multiple learners are included in the model, predicted values are calculated for each element of newX, and the summation of all predicted values is returned (predicted values of each learner are not returned). When contributions of each learner (method) are of interest, add NULL to the elements of newX to be ignored (see examples).
</p>


<h3>Value</h3>

<p>A vector of predicted values is returned.
</p>


<h3>See Also</h3>

<p>vigor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#data
data(sampledata)
dim(X) #Matrix of SNP genotypes (explanatory variables)
dim(Z) #Matrix of a fixed effect (explanatory variables)
length(Y) #Vector of response variables

#Train EBL using the first 80 percent of data
#Then predict the remaining 20 percent data
ETA &lt;- list(list(model = "EBL",X = X[1:400, ]))
Train &lt;- vigor(Y[1:400], ETA)
newX &lt;- list(X[401:500, ])
Predict &lt;- predict_vigor(Train, newX)
plot(Y[401:500], Predict)
#When the intercept is automatically added when training,
#the intercept is again automatically added to predicted values

#Use multiple regression methods
#Fit additive and dominance effects using BayesC with different shrinkage levels
#Also fixed effects are added
X.d &lt;- X
X.d[X == 2] &lt;- 0 #heterozygotes are 1 and homozygotes are 0
Z.matrix &lt;- model.matrix(~ Z)
ETA &lt;- list(list(model = "FIXED", X = Z.matrix[1:400, ]),
            list(model = "BayesC", X = X[1:400, ], H = c(5, 0.1, 0.01)),
            list(model = "BayesC", X = X.d[1:400, ], H = c(5, 0.1, 0.001)))
Train &lt;- vigor(Y[1:400], ETA)
newX &lt;- list(Z.matrix[401:500, ], X[401:500, ], X.d[401:500, ])
Predict &lt;- predict_vigor(Train, newX)
plot(Y[401:500], Predict)

#When fixed effects are specified using formula,
Data &lt;- data.frame(Z = factor(Z))
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data[1:400, ,drop=FALSE]),
            list(model = "BayesB", X = X[1:400, ], H = c(5, 0.1, 0.01)),
            list(model = "BayesB", X = X.d[1:400, ], H = c(5, 0.1, 0.001)))
Train &lt;- vigor(Y[1:400], ETA)
newX &lt;- list(~ Z, data = Data[401:500, , drop=FALSE], X[401:500, ], X.d[401:500, ])
Predict &lt;- predict_vigor(Train, newX)
plot(Y[401:500], Predict)
#NOTE: please confirm that levels of fixed effects are consistent
#between the training and testing data

#Contributions of each learner can be assessed by filling newX with NULL
##Contribution of additive effect
newX &lt;- list(NULL, X[401:500, ], NULL)
Predict &lt;- predict_vigor(Train, newX)
plot(Y[401:500], Predict)

##Contribution of dominance effect
newX &lt;- list(NULL, NULL, X.d[401:500, ])
Predict &lt;- predict_vigor(Train, newX)
plot(Y[401:500], Predict)

</code></pre>

<hr>
<h2 id='vigor'>Variational Bayesian inference for genome-wide regression</h2><span id='topic+vigor'></span>

<h3>Description</h3>

<p>This function performs Bayesian genome-wide regression using variational Bayesian algorithms.
The available regression methods are Bayesian lasso (BL), extended Bayesian lasso (EBL),
BayesA, BayesB, BayesC, Bayesian ridge regression (BRR), BLUP, and fixed effects (FIXED) (fixed effects mean regression using noninformative priors). This function allows multiple regression methods (learners) in a single model. For example, additive effects and interaction effects can be incorporated in a single model using BL and BayesB which provide different shrinkage levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vigor(Y, ETA, Function = c("fitting", "tuning", "cv"), Nfold = 5, CVFoldTuning = 5,
      Partition = NULL, Thresholdvalue = 1e-5,
      Maxiteration = 1000, RandomIni = TRUE, Metrics = c("rmse", "cor"), Verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vigor_+3A_y">Y</code></td>
<td>

<p>An N-length vector of response variables, where N is the number of samples. Missing data (coded as NA) are allowed.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_eta">ETA</code></td>
<td>

<p>A nested list to specify regression methods, explanatory variables, and hyperparameters. The length of ETA is the number of methods (learners) incorporated in a single model. See details below.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_function">Function</code></td>
<td>

<p>One of the strings &quot;fitting&quot;, &quot;tuning&quot;, and &quot;cv&quot;. See details below.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_nfold">Nfold</code></td>
<td>

<p>An integer value. When n &gt; 1, n-fold cross-validation (CV) is performed on randomly partitioned individuals. When the integer is -1, leave-one-out CV is conducted. Used when Function = &quot;cv&quot; and Partition == NULL.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_cvfoldtuning">CVFoldTuning</code></td>
<td>

<p>An integer specifying the fold number of the CV in hyperparameter tuning. Used when Function = &quot;cv&quot; or &quot;tuning&quot; and multiple hyperparameter sets are given.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_partition">Partition</code></td>
<td>

<p>A matrix defining the partitions of CV. See details and examples below. Used when Function = &quot;cv&quot;.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_thresholdvalue">Thresholdvalue</code></td>
<td>

<p>Specifies the convergence threshold. Smaller values indicate stricter thresholds.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_maxiteration">Maxiteration</code></td>
<td>

<p>Maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_randomini">RandomIni</code></td>
<td>

<p>If TRUE, the initial values of the SNP effects are randomly determined. Otherwise, they are set to 0.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_metrics">Metrics</code></td>
<td>

<p>One of the strings &quot;rmse&quot; and &quot;cor&quot; to specify the metrics used in CV. rmse and cor use RMSE and Pearson correlation, respectively.
</p>
</td></tr>
<tr><td><code id="vigor_+3A_verbose">Verbose</code></td>
<td>

<p>If TRUE, print the run information to the console.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Regression methods</b><br />
Vigor supports the following regression methods;
</p>

<ul>
<li><p> BL (Bayesian lasso)
</p>
</li>
<li><p> EBL (extended Bayesian lasso)
</p>
</li>
<li><p> BayesA
</p>
</li>
<li><p> BayesB
</p>
</li>
<li><p> BayesC
</p>
</li>
<li><p> BRR (Bayesian ridge regression)
</p>
</li>
<li><p> BLUP
</p>
</li>
<li><p> FIXED (fixed effects)
</p>
</li></ul>

<p>These methods can be included in a single model simultaneously with different explanatory variables. For the details of these methods and the theoretical backgrounds of vigor, see the pdf document (Onogi 2021). <br />
</p>
<p><b>ETA</b><br />
Each element (list) of ETA consists of the following objects.<br />
</p>

<ul>
<li><p> model : One of strings representing regression methods, &quot;BL&quot;, &quot;EBL&quot;, &quot;BayesA&quot;, &quot;BayesB&quot;, &quot;BayesC&quot;, &quot;BRR&quot;, &quot;BLUP&quot;, or &quot;FIXED&quot;
</p>
</li>
<li><p> X     : An explanatory variables (e.g., SNP genotypes) of (N x P) matrix, where N and P denote the number of samples and variables, respectively
</p>
</li>
<li><p> K     : An N x N kernel matrix (e.g., genomic relationship matrix) used when BLUP is specified as model. When BLUP is specified but K is lacked, the linear kernel is created from X as scale(X)*t(scale(X))/ncol(X).
</p>
</li>
<li><p> H     : A vector or matrix including hyperparameters
</p>
</li>
<li><p> data  : A data frame containing fixed effects. Used to model FIXED using formula.
</p>
</li></ul>

<p>Specification of model is essential for all methods. For regression methods except for BLUP and FIXED, X is essential. For BLUP, either X or K is essential. For FIXED, either X or formula with data is essential.
</p>
<p><b>Hyperparameters</b><br />
The regression methods require hyperparameters as H in ETA. H can be a vector or matrix. Below is the order of hyperparameters in H (order of columns in the case of matrix). Default values are shown in parenthesis.<br />
</p>

<ul>
<li><p> BL     : Phi(1), Omega(1)
</p>
</li>
<li><p> EBL    : Phi(0.1), Omega(0.1), Psi(1), Theta(0.1)
</p>
</li>
<li><p> BayesA : Nu(5), S2(0.01)
</p>
</li>
<li><p> BayesB : Nu(5), S2(0.1), Kappa(0.01)
</p>
</li>
<li><p> BayesC : Nu(5), S2(0.1), Kappa(0.01)
</p>
</li>
<li><p> BRR    : Nu(5), S2(0.01)
</p>
</li>
<li><p> BLUP   : Nu(5), S2(0.3)
</p>
</li></ul>

<p><b>Note that Kappa is the proportion of explanatory variables with NON-ZERO EFFECTS</b>. Also note that Y is standardized automatically. To specify multiple hyperparameter sets, give an S x Nh matrix where S is the number of sets and Nh is the number of hyperparameters of the method to ETA. See the pdf document (Onogi 2021) for the details of hyperparameters.<br />
</p>
<p><b>Functions</b><br />
The functions of vigor are &quot;fitting&quot;, &quot;tuning&quot;, and &quot;cv&quot;.
</p>

<ul>
<li><p> &quot;fitting&quot; : Fits the specified regression model to the data. When H (hyperparameters) includes multiple hyperparameter sets (i.e., H is a matrix), only the first set is used.
</p>
</li>
<li><p> &quot;tuning&quot;  : Selects the best hyperparameter set using CV for tuning. This set is then used for model fitting. The CV is performed on randomly partitioned data. The number of folds is determined by CVFoldTuning. When multiple hyperparameter sets are given to multiple methods, all combinations of hyperparameters are attempted.
</p>
</li>
<li><p> &quot;cv&quot;      : Conducts CV and returns the predicted values. When multiple hyperparameter sets are given, tuning is performed at each fold of the CV. As in Tuning, when multiple hyperparameter sets are given to multiple methods, all combinations of hyperparameters are attempted.
</p>
</li></ul>

<p><b>Partition matrix</b><br />
The following is a possible Partition of 20 individuals evaluated in a five-fold CV:<br /><br />
14 11  3  2  7<br />
5  4 20 10  9<br />
6  8 16 15 12<br />
18 13 17  1 19<br /><br />
Sample (row numbers in Y/X/K) 14, 5, 6, and 18 are removed from the training set at the first fold of the five-fold CV. Samples 11, 4, 8, and 13 are removed at the next fold. This process is repeated up to the fold number of the CV. If the number of samples N is 19, the gap is filled with -9. For example,<br /><br />
8  6  3 14 18<br />
12  4  1 15  5<br />
17  9 13 11 10<br />
19 16  7  2 -9<br /><br />
An example of random sampling validation in which samples can be sampled more than once is shown below.<br /><br />
18  3 11 16 13<br />
17  8 13 13 18<br />
7 15 14 19  7<br />
1 13 12  7  2<br /><br />
Samples 18, 13, and 7 are repeatedly used as testing samples.<br /><br />
Random partitioning outputs a Partition matrix, which can be input as the Partition matrix in subsequent analysis.<br />
</p>
<p><b>Intercept</b><br />
If No FIXED is given in ETA, vigor automatically adds the intercept to the regression model as a fixed effect (FIXED). If FIXED is given by the user, vigor regards the first column as the intercept<br />
</p>
<p><b>Standardization</b><br />
Vigor standardizes Y (response variables). Although most returned values are scaled back to the original scale, the lower bound of the marginal log likelihood is returned as the standardized scale.
</p>


<h3>Value</h3>

<p>When Function = &quot;fitting&quot; or &quot;tuning&quot;, a list containing the following elements is returned.
</p>
<table>
<tr><td><code>$LB</code></td>
<td>
<p>Lower bound of the marginal log likelihood of Y.</p>
</td></tr>
<tr><td><code>$ResidualVar</code></td>
<td>
<p>Residual variances (1/Tau02) at each iteration (from start to end).</p>
</td></tr>
<tr><td><code>$H</code></td>
<td>
<p>Used hyperparameters.</p>
</td></tr>
<tr><td><code>$Fittedvalue</code></td>
<td>
<p>Fitted values.</p>
</td></tr>
<tr><td><code>$Metrics</code></td>
<td>
<p>Metrics for hyperparameter tuning. Returned when Function = &quot;tuning&quot;</p>
</td></tr>
<tr><td><code>$ETA</code></td>
<td>
<p>A list containing results for each method.
</p>

<ul>
<li><p> Beta: Posterior means of regression coefficients of X
</p>
</li>
<li><p> Sd.beta: Posterior standard deviations of Beta (uncertainty of Beta)
</p>
</li>
<li><p> Sigma2: Posterior means of variance of Beta or U
</p>
</li>
<li><p> Rho: Posterior means of model-inclusion probabilities
</p>
</li>
<li><p> U: Posterior means of random effects of BLUP
</p>
</li>
<li><p> Sd.u: Posterior standard deviations of U (uncertainty of U)
</p>
</li>
<li><p> iK: Inverse of K
</p>
</li></ul>

<p>Beta and Sd.beta are returned for BL, EBL, BayesA, BayesB, BayesC, and FIXED, and U, Sd.u, and iK are returned for BLUP. Rho is returned for BayesB and BayesC. Sigma2 is returned for methods except for BL and EBL.</p>
</td></tr>
<tr><td><code>$AddIntercept</code></td>
<td>
<p>True when the intercept was added automatically.</p>
</td></tr>
</table>
<p>When Function = &quot;cv&quot;, a list containing the following elements is returned.
</p>
<table>
<tr><td><code>$Prediction</code></td>
<td>
<p>A vector of predicted values</p>
</td></tr>
<tr><td><code>$Metrics</code></td>
<td>
<p>Metrics of hyperparameter tuning. Chosen sets and corresponding metrics at each fold are returned.</p>
</td></tr>
<tr><td><code>$Partition</code></td>
<td>
<p>A matrix representing the partition used in random partitioning. This matrix can be used as the argument Partition in subsequent analyses.</p>
</td></tr>
<tr><td><code>$AddIntercept</code></td>
<td>
<p>True when the intercept was added automatically.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Akio Onogi
</p>


<h3>References</h3>

<p>Onogi A., Variational Bayesian inference for genome-wide regression: joint estimation of multiple learners, in prep.<br />
Onogi A. &amp; Iwata H., 2016 VIGoR: Variational Bayesian Inference for Genome-Wide Regression.
Journal of Open Research Software, 4: e11<br />
Onogi A., 2021, Documents for VIGoR ver. 1.1.0, https://github.com/Onogi/VIGoR<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#DATA###########################################################################
data(sampledata)
dim(X) #Matrix of SNP genotypes (explanatory variables)
dim(Z) #Matrix of a fixed effect (explanatory variables)
length(Y) #Vector of response variables


#Fitting########################################################################
#Example 1: Fit SNP genotypes with BayesC
ETA &lt;- list(list(model = "BayesC", X = X))
Result &lt;- vigor(Y, ETA)
##see estimated SNP effects
plot(abs(Result$ETA[[1]]$Beta), pch = 20)
##10 SNPs at 1, 101, ..., 901 have non-zero effects
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
##see inclusion probability
plot(Result$ETA[[1]]$Rho, pch = 20)
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
##Intercept is added automatically as the last learner
Result$ETA[[2]]$Beta


#Example 2: Fit fixed effects and SNP genotypes
##There are two approaches to fit fixed effects
##(1) Create model matrix
Z #Z consists of three categories (A, B, and C)
Z.matrix &lt;- model.matrix(~ Z)
head(Z.matrix) #The first column is the intercept
##Fit with EBL
ETA &lt;- list(list(model = "FIXED", X = Z.matrix),
            list(model = "EBL", X = X))
Result &lt;- vigor(Y, ETA)
##Estimated fixed effects (intercept, B, and C)
Result$ETA[[1]]$Beta
##Estimated SNP effects
plot(abs(Result$ETA[[2]]$Beta), pch = 20)
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
##NOTE: when FIXED is added by user, the intercept is not automatically added.
##Thus, variables in FIXED should contain the intercept.

##(2) Use formula
Data &lt;- data.frame(Z = factor(Z))
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "BayesA", X = X))
Result &lt;- vigor(Y, ETA)
##Estimated fixed effects (intercept, B, and C)
Result$ETA[[1]]$Beta
plot(abs(Result$ETA[[2]]$Beta), pch = 20)
abline(v=seq(1,1000,100),col=2,lty=2)
##NOTE: formula automatically adds the intercept


#Example 3: Multiple regression methods in a single model
##Some SNPs in X have dominance (non-additive) effects
##Fit SNP genotypes coded as additive and dominance with different shrinkage levels
X.d &lt;- X
X.d[X == 2] &lt;- 0 #heterozygotes are 1 and homozygotes are 0
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "BayesC", X = X, H = c(5, 0.1, 0.01)),
            list(model = "BayesC", X = X.d, H = c(5, 0.1, 0.001)))
Result &lt;- vigor(Y, ETA)
##Inclusion probability for additive effects
plot(Result$ETA[[2]]$Rho, pch = 20)
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
##Inclusion probability for dominance effects
plot(Result$ETA[[3]]$Rho, pch = 20)
##SNPs at 1, 201, ..., 801 have non-zero effects
abline(v = seq(1, 1000, 200), col = 2, lty = 2)

##Fit additive and dominance effects with different learners
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "BL", X = X, H = c(1, 0.01)),
            list(model = "BayesC", X = X.d, H = c(5, 0.1, 0.001)))
Result &lt;- vigor(Y, ETA)
plot(abs(Result$ETA[[2]]$Beta), pch = 20)
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
plot(Result$ETA[[3]]$Rho, pch = 20)
abline(v = seq(1, 1000, 200), col = 2, lty = 2)


#Tuning hyperparameters#########################################################
#Example 4: Model fitting after hyperparameter tuning with cross-validation
##Candidate hyperparameter values are determined with hyperpara
##Use BayesB
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "BayesB", X = X,
                 H = hyperpara(X, 0.5, "BayesB", c(0.1,0.01))))
Result &lt;- vigor(Y, ETA, Function = "tuning")
##See the tuned result
Result$Metrics
##The model was fitted to the full data with the best set
Result$H
plot(Result$ETA[[2]]$Rho, pch = 20)
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
##See how much the model was fitted
plot(Y, Result$Fittedvalue); abline(0, 1)

##When multiple learners used, all combinations of hyperparameter sets are compared
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "BayesB", X = X,
                 H = hyperpara(X, 0.5, "BayesB", c(0.1,0.01))),
            list(model = "BayesC", X = X.d,
                 H = hyperpara(X, 0.5, "BayesC", c(0.1,0.01))))
Result &lt;- vigor(Y, ETA, Function = "tuning")
##BayesB and BayesC have two candidate sets, respectively.
##Thus, total 2 x 2 = 4 combinations are compared.
Result$Metrics
##The model was fitted to the full data with the best combination.
Result$H
plot(Result$ETA[[2]]$Rho, pch = 20)
abline(v = seq(1, 1000, 100), col = 2, lty = 2)
plot(Result$ETA[[3]]$Rho, pch = 20)
abline(v = seq(1, 1000, 200), col = 2, lty = 2)


#Cross-validation###############################################################
#Example 5: Cross-validation with random splitting
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "BayesC", X = X,
                 H = hyperpara(X, 0.5, "BayesC", c(0.1,0.01))))
Result &lt;- vigor(Y, ETA, Function="cv")
##Because two hyperparameter sets are provided,
##nested CV is conducted at each fold to tune hyperparameters
##See which set was selected at each fold
Result$Metrics
##See predicted values
plot(Y, Result$Prediction)
cor(Y, Result$Prediction)

#Example 6: Cross-validation with the specified splitting
##Perform CV using the same partition as Example 5. Use EBL
ETA &lt;- list(list(~ Z, model = "FIXED", data = Data),
            list(model = "EBL", X = X))
Result2 &lt;- vigor(Y, ETA, Function="cv", Partition = Result$Partition)
plot(Y, Result2$Prediction)
cor(Y, Result2$Prediction)

</code></pre>

<hr>
<h2 id='X'>
An example of SNP genotypes (explanatory variables)
</h2><span id='topic+X'></span>

<h3>Description</h3>

<p>An example of SNP genotypes consisting of 1000 SNPs and 500 samples. The genotypes are coded as 0 (AA), 1 (AB), and 2 (BB). The genotypes were randomly generated as described in the details. The first, 101th, ..., and 901th SNP have additive effects. The first, 201th, ..., and 801th SNPs have also dominance effects.
</p>


<h3>Details</h3>

<p>X was generated by<br /><br />
N &lt;- 500<br />
P &lt;- 1000<br />
X &lt;- matrix(sample(c(0, 1, 2), N * P, replace = T,<br />
prob = c(0.49, 0.42, 0.09)), nc = P)<br />
</p>


<h3>See Also</h3>

<p>Y, Z
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sampledata)
dim(X) #500 samples and 1000 SNPs
unique(X[1:(500*1000)]) #0,1,2
</code></pre>

<hr>
<h2 id='Y'>
An example of response variables.
</h2><span id='topic+Y'></span>

<h3>Description</h3>

<p>A vector consisting of 500 samples.
</p>


<h3>Details</h3>

<p>Y mimicked phenotypic values in quantitative genetics. Y was created from X (SNP genotypes) and Z (fixed effect). 10 SNPs in X have additive effects, and 5 out of 10 SNPs have dominance effects further. Y also include environmental noises. The variances of additive, dominance, and noise are approximately 1 : 1 : 1.
</p>


<h3>See Also</h3>

<p>X, Z
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sampledata)
length(Y) #500 samples
any(is.na(Y)) #FALSE. Y has no missing (but it's allowed).
</code></pre>

<hr>
<h2 id='Z'>
An example of fixed effects (explanatory variables)
</h2><span id='topic+Z'></span>

<h3>Description</h3>

<p>An example of fixed effects for 500 samples. The effect consists of three levels, &quot;A&quot;, &quot;B&quot;, and &quot;C.
</p>


<h3>Details</h3>

<p>Compared with the mean of &quot;A&quot;, the mean of &quot;B&quot; is 3 lower and the mean of &quot;C&quot; is 3 higher.
</p>


<h3>See Also</h3>

<p>Y, X
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sampledata)
dim(Z) #500 samples and 1 effect
unique(Z) #"A", "B", and "C"
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
