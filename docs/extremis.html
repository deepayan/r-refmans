<!DOCTYPE html><html lang="en"><head><title>Help for package extremis</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {extremis}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#angcdf'><p>Empirical-Likelihood Based Inference for the Angular Measure</p></a></li>
<li><a href='#angdensity'><p>Empirical-Likelihood Based Inference for the Angular Density</p></a></li>
<li><a href='#angscdf'><p>Smooth Empirical-Likelihood Based Inference for the Angular Measure</p></a></li>
<li><a href='#beatenberg'><p>Beatenberg</p></a></li>
<li><a href='#cdensity'><p>Kernel Smoothed Scedasis Density</p></a></li>
<li><a href='#cdf'><p>Empirical Scedasis Distribution Function</p></a></li>
<li><a href='#cmodes'><p>Mode Mass Function</p></a></li>
<li><a href='#kgvar'><p>K-Geometric Means Algorithm for Value-at-Risk</p></a></li>
<li><a href='#khetmeans'><p>K-Means Clustering for Heteroscedastic Extremes</p></a></li>
<li><a href='#lse'><p>Selected Stocks from the London Stock Exchange</p></a></li>
<li><a href='#plotFrechet'><p>Unit Fréchet Scatterplot in Log-log Scale</p></a></li>
<li><a href='#sp500'><p>Standard &amp; Poor 500</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-12-06</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistics of Extremes</td>
</tr>
<tr>
<td>Description:</td>
<td>Conducts inference in statistical models for extreme values (de Carvalho et al (2012), &lt;<a href="https://doi.org/10.1080%2F03610926.2012.709905">doi:10.1080/03610926.2012.709905</a>&gt;; de Carvalho and Davison (2014), &lt;<a href="https://doi.org/10.1080%2F01621459.2013.872651">doi:10.1080/01621459.2013.872651</a>&gt;; Einmahl et al (2016), &lt;<a href="https://doi.org/10.1111%2Frssb.12099">doi:10.1111/rssb.12099</a>&gt;).</td>
</tr>
<tr>
<td>Author:</td>
<td>Miguel de Carvalho [aut, cre],
  Rodrigo Rubio [aut],
  Vianey Palacios [aut]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.1)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Miguel de Carvalho &lt;miguel.decarvalho@ed.ac.uk&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Imports:</td>
<td>emplik,methods,MASS,evd</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-08 19:32:09 UTC; kramirez</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-12-09 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='angcdf'>Empirical-Likelihood Based Inference for the Angular Measure</h2><span id='topic+angcdf'></span><span id='topic+angcdf.default'></span>

<h3>Description</h3>

<p>This function computes empirical-likelihood based estimators for the
angular distribution function of a bivariate extreme value
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angcdf(Y, tau = 0.95, method = "euclidean", raw = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="angcdf_+3A_y">Y</code></td>
<td>
<p>data frame with two columns from which the estimate is to
be computed.</p>
</td></tr>
<tr><td><code id="angcdf_+3A_tau">tau</code></td>
<td>
<p>value used to threshold the data; by default it is set as
the 0.95 quantile of the pseudo-radius <code>tau = 0.95</code>.</p>
</td></tr>
<tr><td><code id="angcdf_+3A_method">method</code></td>
<td>
<p>a character string setting the method to be used. By
default <code>method = "euclidean"</code>, the other option being
<code>method = "empirical"</code>. See details.</p>
</td></tr>
<tr><td><code id="angcdf_+3A_raw">raw</code></td>
<td>
<p>logical; if <code>TRUE</code>, <code>Y</code> will be converted to
unit Fréchet scale. If <code>FALSE</code>, <code>Y</code> will be understood as
already in unit Fréchet scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>method = "euclidean"</code> implements the maximum Euclidean
likelihood spectral distribution function as introduced by de
Carvalho et al (2013). <code>method = "empirical"</code> implements the
maximum Empirical likelihood spectral distribution function as
introduced by Einmahl and Segers (2009).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>H</code></td>
<td>
<p>angular distribution function.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>pseudo-angles.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>data.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the empirical likelihood-based
angular distribution function.
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>References</h3>

<p>de Carvalho, M., Oumow, B., Segers, J. and Warchol, M. (2013) A
Euclidean likelihood estimator for bivariate tail dependence.
<em>Communications in Statistics&mdash;Theory and Methods</em>, 42,
1176&ndash;1192.
</p>
<p>Einmahl, J. H. J., and Segers, J. (2009) Maximum empirical
likelihood estimation of the spectral measure of an extreme-value
distribution.  <em>The Annals of Statistics</em>, 37, 2953&ndash;2989.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## de Carvalho et al (2013, Fig. 7)
data(beatenberg)
attach(beatenberg)
fit &lt;- angcdf(beatenberg, tau = 0.98, raw = FALSE)
plot(fit)
rug(fit$w)
</code></pre>

<hr>
<h2 id='angdensity'>Empirical-Likelihood Based Inference for the Angular Density</h2><span id='topic+angdensity'></span><span id='topic+angdensity.default'></span>

<h3>Description</h3>

<p>This function computes empirical-likelihood based estimators for the
angular distribution function of a bivariate extreme value
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angdensity(Y, tau = 0.95, nu, grid = seq(0.01, 0.99, length = 2^8),
	   method = "euclidean", raw = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="angdensity_+3A_y">Y</code></td>
<td>
<p>data frame with two columns from which the estimate is to
be computed.</p>
</td></tr>
<tr><td><code id="angdensity_+3A_tau">tau</code></td>
<td>
<p>value used to threshold the data; by default it is set as
the 0.95 quantile of the pseudo-radius.</p>
</td></tr>
<tr><td><code id="angdensity_+3A_nu">nu</code></td>
<td>
<p>concentration parameter of beta distribution which
controls the amount of smoothing.</p>
</td></tr>
<tr><td><code id="angdensity_+3A_grid">grid</code></td>
<td>
<p>grid with coordinates of the points where the angular
density is estimated; by default <code>grid = seq(0.01, 0.99, length
  = 2^8)</code>.</p>
</td></tr>
<tr><td><code id="angdensity_+3A_method">method</code></td>
<td>
<p>a character string setting the method to be used. By
default <code>method = "euclidean"</code>, the other option being
<code>method = "empirical"</code>. See details.</p>
</td></tr>
<tr><td><code id="angdensity_+3A_raw">raw</code></td>
<td>
<p>logical; if <code>TRUE</code>, <code>Y</code> will be converted to
unit Fréchet scale. If <code>FALSE</code>, <code>Y</code> will be understood as
already in unit Fréchet scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The smooth angular density was introduced in by de Carvalho et al
(2013). <code>method = "euclidean"</code> implements the version of the
method based on Euclidean likelihood weights, whereas <code>method =
  "empirical"</code> uses Empirical likelihood weights. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>h</code></td>
<td>
<p>the estimate angular density values.</p>
</td></tr>
<tr><td><code>grid</code></td>
<td>
<p>grid with coordinates of the points where the angular
density is estimated.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>pseudo-angles.</p>
</td></tr>
<tr><td><code>nu</code></td>
<td>
<p>concentration parameter of the Beta-kernel.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the smooth angular density.
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>References</h3>

<p>de Carvalho, M., Oumow, B., Segers, J. and Warchol, M. (2013) A
Euclidean likelihood estimator for bivariate tail dependence.
<em>Communications in Statistics&mdash;Theory and Methods</em>, 42,
1176&ndash;1192.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## de Carvalho et al (2013, Fig. 7)
data(beatenberg)
attach(beatenberg)
fit &lt;- angdensity(beatenberg, tau = 0.98, nu = 163, raw = FALSE)
plot(fit)
rug(fit$w)
</code></pre>

<hr>
<h2 id='angscdf'>Smooth Empirical-Likelihood Based Inference for the Angular Measure</h2><span id='topic+angscdf'></span><span id='topic+angscdf.default'></span>

<h3>Description</h3>

<p>This function computes smooth empirical-likelihood based estimators for the
angular distribution function of a bivariate extreme value
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angscdf(Y, tau = 0.95, nu, grid = seq(0.01, 0.99, length = 2^8),
	method = "euclidean", raw = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="angscdf_+3A_y">Y</code></td>
<td>
<p>data frame with two columns from which the estimate is to
be computed.</p>
</td></tr>
<tr><td><code id="angscdf_+3A_tau">tau</code></td>
<td>
<p>value used to threshold the data; by default it is set as
the 0.95 quantile of the pseudo-radius <code>tau = 0.95</code>.</p>
</td></tr>
<tr><td><code id="angscdf_+3A_nu">nu</code></td>
<td>
<p>concentration parameter of beta distribution which
controls the amount of smoothing.</p>
</td></tr>
<tr><td><code id="angscdf_+3A_grid">grid</code></td>
<td>
<p>grid with coordinates of the points where the angular
measure is estimated; by default <code>grid = seq(0.01, 0.99, length
  = 2^8)</code>.</p>
</td></tr>
<tr><td><code id="angscdf_+3A_method">method</code></td>
<td>
<p>a character string setting the method to be used. By
default <code>method = "euclidean"</code>, the other option being
<code>method = "empirical"</code>. See details.</p>
</td></tr>
<tr><td><code id="angscdf_+3A_raw">raw</code></td>
<td>
<p>logical; if <code>TRUE</code>, <code>Y</code> will be converted to
unit Fréchet scale. If <code>FALSE</code>, <code>Y</code> will be understood as
already in unit Fréchet scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>method = "euclidean"</code> implements the maximum Euclidean
likelihood spectral distribution function as introduced by de
Carvalho et al (2013). <code>method = "empirical"</code> implements the
maximum Empirical likelihood spectral distribution function as
introduced by Einmahl and Segers (2009). 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>H</code></td>
<td>
<p>the estimated angular distribution function values.</p>
</td></tr>
<tr><td><code>grid</code></td>
<td>
<p>grid with coordinates of the points where the angular
measure is estimated.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>pseudo-angles.</p>
</td></tr>
<tr><td><code>nu</code></td>
<td>
<p>concentration parameter of the Beta-kernel.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the empirical likelihood-based
angular distribution function.
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>References</h3>

<p>de Carvalho, M., Oumow, B., Segers, J. and Warchol, M. (2013) A
Euclidean likelihood estimator for bivariate tail dependence.
<em>Communications in Statistics&mdash;Theory and Methods</em>, 42,
1176&ndash;1192.
</p>
<p>Einmahl, J. H. J., and Segers, J. (2009) Maximum empirical
likelihood estimation of the spectral measure of an extreme-value
distribution.  <em>The Annals of Statistics</em>, 37, 2953&ndash;2989.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## de Carvalho et al (2013, Fig. 7)
data(beatenberg)
attach(beatenberg)
fit &lt;- angscdf(beatenberg, tau = 0.98, nu = 163, raw = FALSE)
plot(fit)
rug(fit$w)
</code></pre>

<hr>
<h2 id='beatenberg'>Beatenberg</h2><span id='topic+beatenberg'></span>

<h3>Description</h3>

<p>Preprocessed pairs of temperatures in unit Fréchet scale from
Beatenberg forest, registered under forest cover and in the open
field. Preprocessing is conducted as described in Ferrez et al
(2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beatenberg</code></pre>


<h3>Format</h3>

<p>The <code>beatenberg</code> data frame has 2839 rows and 2 columns.
</p>


<h3>References</h3>

<p>Ferrez, J., A. C. Davison, and Rebetez., M. (2011) Extreme
temperature analysis under forest cover compared to an open field.
<em>Agricultural and Forest Meteorology</em>, 151, 992&ndash;1001.
</p>

<hr>
<h2 id='cdensity'>Kernel Smoothed Scedasis Density</h2><span id='topic+cdensity'></span><span id='topic+cdensity.default'></span>

<h3>Description</h3>

<p>This function computes a kernel scedasis density estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdensity(Y, threshold = quantile(Y[, 2], 0.95), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cdensity_+3A_y">Y</code></td>
<td>
<p>data frame from which the estimate is to be computed; first
column corresponds to time and the second to the variable of interest.</p>
</td></tr>  
<tr><td><code id="cdensity_+3A_threshold">threshold</code></td>
<td>
<p>value used to threshold the data <code>y</code>; by default
<code>threshold = quantile(y, 0.95)</code>.</p>
</td></tr>
<tr><td><code id="cdensity_+3A_...">...</code></td>
<td>
<p>further arguments for <code>density</code> methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kernel smoothing for the scedasis density was introduced by
Einmahl et al (2016). 


</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>c</code></td>
<td>
<p>scedasis density estimator.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of exceedances above the threshold.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>standardized indices of exceedances.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the smooth scedasis density. 
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>References</h3>





<p>Einmahl, J. H., Haan, L., and Zhou, C. (2016) Statistics of
heteroscedastic extremes. <em>Journal of the Royal Statistical
Society: Ser. B</em>, 78(1), 31&ndash;51.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lse)
attach(lse)
Y &lt;- data.frame(DATE[-1], -diff(log(ROYAL.DUTCH.SHELL.B)))
T &lt;- dim(Y)[1]
k &lt;- floor((0.4258597) * T / (log(T)))
fit &lt;- cdensity(Y, kernel = "biweight", bw = 0.1 / sqrt(7), 
                threshold = sort(Y[, 2])[T - k])
plot(fit)
plot(fit, original = FALSE)
</code></pre>

<hr>
<h2 id='cdf'>Empirical Scedasis Distribution Function</h2><span id='topic+cdf'></span><span id='topic+cdf.default'></span>

<h3>Description</h3>

<p>This function computes the empirical scedasis distribution function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdf(Y, threshold = quantile(Y[, 2], 0.95))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cdf_+3A_y">Y</code></td>
<td>
<p>data frame from which the estimate is to be computed; first
column corresponds to time and the second to the variable of interest.</p>
</td></tr>
<tr><td><code id="cdf_+3A_threshold">threshold</code></td>
<td>
<p>value used to threshold the data <code>y</code>; by default
<code>threshold = quantile(Y[, 2], 0.95)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical scedasis distribution function was introduced by Einmahl
et al (2016).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>C</code></td>
<td>
<p>empirical scedasis distribution function.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>standardized indices of exceedances.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of exceedances above a threshold.</p>
</td></tr>  
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the empirical cumulative scedasis
function, and the reference line for the case of constant frequency of
extremes over time (if <code>uniform = TRUE</code>). 
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>References</h3>

<p>Einmahl, J. H., Haan, L., and Zhou, C. (2016) Statistics of
heteroscedastic extremes. <em>Journal of the Royal Statistical
Society: Ser. B</em>, 78(1), 31&ndash;51.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sp500)
attach(sp500)
Y &lt;- data.frame(date[-1], -diff(log(close)))
fit &lt;- cdf(Y)
plot(fit)
plot(fit, original = FALSE)
</code></pre>

<hr>
<h2 id='cmodes'>Mode Mass Function</h2><span id='topic+cmodes'></span><span id='topic+cmodes.default'></span>

<h3>Description</h3>

<p>This function computes the mode mass function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmodes(Y, thresholds = apply(Y[, -1], 2, quantile, probs =
                 0.95), nu = 100, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cmodes_+3A_y">Y</code></td>
<td>
<p>data frame from which the estimate is to be computed; first
column corresponds to time and the second to the variable of interest.</p>
</td></tr>  
<tr><td><code id="cmodes_+3A_thresholds">thresholds</code></td>
<td>
<p>values used to threshold the data <code>y</code>; by default
<code>threshold = quantile(y, 0.95)</code>.</p>
</td></tr>
<tr><td><code id="cmodes_+3A_nu">nu</code></td>
<td>
<p>concentration parameter of beta kernel used to smooth mode
mass function.</p>
</td></tr>
<tr><td><code id="cmodes_+3A_...">...</code></td>
<td>
<p>further arguments for <code>density</code> methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The scedasis functions on which the mode mass function is based are
computed using the default <code>"nrd0"</code> option for bandwidth.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>c</code></td>
<td>
<p>scedasis density estimators.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of exceedances above the threshold.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>standardized indices of exceedances.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the smooth mode mass function along
with the smooth scedasis densities. 
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>References</h3>

<p>Rubio, R., de Carvalho, M., and Huser, R. (2018)
Similarity-Based Clustering of Extreme Losses from the London Stock
Exchange. Submitted. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lse)
attach(lse)
nlr &lt;- -apply(log(lse[, -1]), 2, diff)
Y &lt;- data.frame(DATE[-1], nlr)
T &lt;- dim(Y)[1]
k &lt;- floor((0.4258597) * T / (log(T)))
fit &lt;- cmodes(Y, thresholds = as.numeric(apply(nlr, 2, sort)[T - k, ]),  
              kernel = "biweight", bw = 0.1 / sqrt(7), nu = 100)
plot(fit)
</code></pre>

<hr>
<h2 id='kgvar'>K-Geometric Means Algorithm for Value-at-Risk</h2><span id='topic+kgvar'></span><span id='topic+kgvar.default'></span>

<h3>Description</h3>

<p>This function performs k-geometric means for time-varying
value-at-risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  kgvar(y, centers, iter.max = 10, conf.level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kgvar_+3A_y">y</code></td>
<td>
<p>data frame from which the estimate is to be computed; first
column corresponds to time and the second to the remainder of
interest.</p>
</td></tr>
<tr><td><code id="kgvar_+3A_centers">centers</code></td>
<td>
<p>the number of clusters or a set of initial
(distinct) cluster centres. If a number, a random set of (distinct)
rows in <code>y</code> is chosen as the initial centers.</p>
</td></tr>
<tr><td><code id="kgvar_+3A_iter.max">iter.max</code></td>
<td>
<p>the maximum number of iterations allowed. The
default is 10.</p>
</td></tr>
<tr><td><code id="kgvar_+3A_conf.level">conf.level</code></td>
<td>
<p>the confidence level. The default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intermediate sequence <code class="reqn">\kappa_T</code> is chosen
proportional to <code class="reqn">T/\log T</code>.
</p>


<h3>Value</h3>

<p>kgvar returns an object of class <code>"kgvar"</code> which has a
fitted method.  It is a list with at least the following components:
</p>
<table role = "presentation">
<tr><td><code>var.new</code></td>
<td>
<p>cluster center value-at-risk function.</p>
</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>cluster allocation.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
<tr><td><code>n.clust</code></td>
<td>
<p>number of clusters.</p>
</td></tr>
<tr><td><code>scale.param</code></td>
<td>
<p>the scale parameters in the Pareto-like tail
specification.</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>
<p>the confidence level.</p>
</td></tr>
<tr><td><code>hill</code></td>
<td>
<p>hill estimator of extreme value index.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the k-geometric means algorithm for
time-varying value-at-risk. If <code>c.c</code> is <code>TRUE</code>, the method displays the
cluster means.
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho, Rodrigo Rubio.</p>


<h3>References</h3>

<p>Rubio, R., de Carvalho, M. and Huser, R. (2018)
Similarity-Based Clustering of Extreme Losses from the London Stock
Exchange. Submitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Example (Overlapping version of Fig. 8 in Supplementary Materials)
data(lse)
attach(lse)
y &lt;- -apply(log(lse[, -1]), 2, diff) 
fit &lt;- kgvar(y, centers = 3)
plot(fit, c.c = TRUE, ylim = c(0, 0.1))

## End(Not run)
</code></pre>

<hr>
<h2 id='khetmeans'>K-Means Clustering for Heteroscedastic Extremes</h2><span id='topic+khetmeans'></span><span id='topic+khetmeans.default'></span>

<h3>Description</h3>

<p>This function performs k-means clustering for heteroscedastic extremes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  khetmeans(y, centers, iter.max = 10, alpha = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="khetmeans_+3A_y">y</code></td>
<td>
<p>data frame from which the estimate is to be computed; first
column corresponds to time and the second to the remainder of interest.</p>
</td></tr> 
<tr><td><code id="khetmeans_+3A_centers">centers</code></td>
<td>
<p>the number of clusters or a set of initial (distinct)
cluster centres. If a number, a random set of (distinct) rows in
<code>y</code> is chosen as the initial centers.</p>
</td></tr>
<tr><td><code id="khetmeans_+3A_iter.max">iter.max</code></td>
<td>
<p>the maximum number of iterations allowed. The
default is 10.</p>
</td></tr>
<tr><td><code id="khetmeans_+3A_alpha">alpha</code></td>
<td>
<p>the tuning parameter. The default is 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intermediate sequence <code class="reqn">\kappa_T</code> is chosen
proportional to <code class="reqn">T/\log T</code>.
</p>


<h3>Value</h3>

<p>khetmeans returns an object of class &quot;<code>khetmeans</code>&quot; which has a
fitted method. It is a list with at least the following components:
</p>
<table role = "presentation">
<tr><td><code>mus.new</code></td>
<td>
<p>cluster center scedasis density.</p>
</td></tr>
<tr><td><code>mugamma.new</code></td>
<td>
<p>cluster center extreme value index.</p>
</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>cluster allocation.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>raw data.</p>
</td></tr>
<tr><td><code>n.clust</code></td>
<td>
<p>number of clusters.</p>
</td></tr>
</table>
<p>The <code>plot</code> method depicts the k-means clustering for
heteroscedastic extremes. If <code>c.c</code> is <code>TRUE</code>, the method
displays the cluster means.
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho, Rodrigo Rubio.</p>


<h3>References</h3>

<p>Rubio, R., de Carvalho, M. and Huser, R. (2018) 
Similarity-Based Clustering of Extreme Losses from the London Stock
Exchange. Submitted.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Example 1  (Scenario B, T = 5000)
## This example requires package evd 
require(evd)
set.seed(12)
T &lt;- 5000
n &lt;- 30
b &lt;- 0.1
gamma1 &lt;- 0.7
gamma2 &lt;- 1
grid &lt;- seq(0, 1, length = 100)
c2 &lt;- function(s)
    dbeta(s, 2, 5)
c3 &lt;- function(s)
    dbeta(s, 5, 2)
X &lt;- matrix(0, ncol = T, nrow = n)
for(i in 1:5)
  for(j in 1:T)
    X[i,  j] &lt;- rgev(1, c2(j / T), c2(j / T), gamma1)
for(i in 6:15)
  for(j in 1:T)
    X[i,  j] &lt;- rgev(1, c2(j / T), c2(j / T), gamma2)
for(i in 16:20)
  for(j in 1:T)
    X[i,  j] &lt;- rgev(1, c3(j / T), c3(j / T), gamma1)
for(i in 21:30)
  for(j in 1:T)
    X[i,  j] &lt;- rgev(1, c3(j / T), c3(j / T), gamma2)
Y &lt;- t(X)
fit &lt;- khetmeans(Y, centers = 4)
plot(fit, c.c = TRUE)
lines(grid, c2(grid), type = 'l', lwd = 8, col = 'black')
lines(grid, c3(grid), type = 'l', lwd = 8, col = 'black')

## End(Not run)

## Not run: 
## Example 2 (Overlapping version of Fig. 5 in Supplementary Materials)
data(lse)
attach(lse)
y &lt;- -apply(log(lse[, -1]), 2, diff)
fit &lt;- khetmeans(y, centers = 3)
plot(fit, c.c = TRUE, ylim = c(0, 3))

## End(Not run)
</code></pre>

<hr>
<h2 id='lse'>Selected Stocks from the London Stock Exchange</h2><span id='topic+lse'></span>

<h3>Description</h3>

<p>Prices at close from 26 selected stocks from the London stock exchange
from 1989 till 2016. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lse</code></pre>


<h3>Format</h3>

<p>The <code>lse</code> data frame has 6894 rows and 27 columns.
</p>


<h3>References</h3>

<p>Rubio, R., de Carvalho, M., and Huser (2018) Similarity-based
clustering of extreme losses from the London stock exchange.
</p>

<hr>
<h2 id='plotFrechet'>Unit Fréchet Scatterplot in Log-log Scale</h2><span id='topic+plotFrechet'></span><span id='topic+plotFrechet.default'></span>

<h3>Description</h3>

<p>This function depicts a scatterplot of bivariate data transformed 
to unit Fréchet scale. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFrechet(Y, tau = 0.95, raw = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotFrechet_+3A_y">Y</code></td>
<td>
<p>list with data from which the estimates are to be computed.</p>
</td></tr>
<tr><td><code id="plotFrechet_+3A_tau">tau</code></td>
<td>
<p>value used to threshold the data <code>y</code>; by default
<code>treshold = quantile(y, 0.95)</code>.</p>
</td></tr>
<tr><td><code id="plotFrechet_+3A_raw">raw</code></td>
<td>
<p>logical; if <code>TRUE</code>, <code>Y</code> will be converted to unit Fréchet
scale. If <code>FALSE</code>, <code>Y</code> will be understood as already in unit Fréchet scale.</p>
</td></tr>
<tr><td><code id="plotFrechet_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The solid line corresponds to the boundary threshold in the log-log
scale, with both axes being logarithmic.
</p>


<h3>Author(s)</h3>

<p>Miguel de Carvalho</p>


<h3>Examples</h3>

<pre><code class='language-R'>## de Carvalho et al (2013, Fig. 5)
data(beatenberg)
plotFrechet(beatenberg, xlab = "Forest Cover", ylab = "Open Field",
            raw = FALSE)
</code></pre>

<hr>
<h2 id='sp500'>Standard &amp; Poor 500</h2><span id='topic+sp500'></span>

<h3>Description</h3>

<p>Daily Standard and Poor’s index at close from 1988 till 2007. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sp500</code></pre>


<h3>Format</h3>

<p>The <code>sp500</code> data frame has 5043 rows and 2 columns.
</p>


<h3>References</h3>

<p>de Carvalho, M. (2016) Statistics of extremes: Challenges and
opportunities.  In: <em>Handbook of EVT and its Applications to Finance
and Insurance</em>. Eds F. Longin. Hoboken: Wiley.
</p>
<p>Einmahl, J. H., Haan, L., and Zhou, C. (2016) Statistics of
heteroscedastic extremes. <em>Journal of the Royal Statistical
Society: Ser. B</em>, 78(1), 31&ndash;51.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
