<!DOCTYPE html><html><head><title>Help for package GenericML</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GenericML}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BLP'><p>Performs BLP regression</p></a></li>
<li><a href='#CLAN'><p>Performs CLAN</p></a></li>
<li><a href='#GATES'><p>Performs GATES regression</p></a></li>
<li><a href='#GenericML'><p>Generic Machine Learning Inference</p></a></li>
<li><a href='#GenericML_combine'><p>Combine several GenericML objects</p></a></li>
<li><a href='#GenericML_single'><p>Single iteration of the GenericML algorithm</p></a></li>
<li><a href='#get_best'><p>Accessor function for the best learner estimates</p></a></li>
<li><a href='#get_BLP'><p>Accessor function for the BLP generic target estimates</p></a></li>
<li><a href='#get_CLAN'><p>Accessor function for the CLAN generic target estimates</p></a></li>
<li><a href='#get_GATES'><p>Accessor function for the GATES generic target estimates</p></a></li>
<li><a href='#heterogeneity_CLAN'><p>Evaluate treatment effect heterogeneity along CLAN variables</p></a></li>
<li><a href='#lambda_parameters'><p>Estimate the two lambda parameters</p></a></li>
<li><a href='#Med'><p>Calculate lower and upper median</p></a></li>
<li><a href='#plot.GenericML'><p>Plot method for a <code>"GenericML"</code> object</p></a></li>
<li><a href='#print.BLP_info'><p>Print method for a <code>"BLP_info"</code> object</p></a></li>
<li><a href='#print.CLAN_info'><p>Print method for a <code>"CLAN_info"</code> object</p></a></li>
<li><a href='#print.GATES_info'><p>Print method for a <code>"GATES_info"</code> object</p></a></li>
<li><a href='#print.GenericML'><p>Print method for a <code>GenericML</code> object</p></a></li>
<li><a href='#print.heterogeneity_CLAN'><p>Print method for a <code>"heterogeneity_CLAN"</code> object</p></a></li>
<li><a href='#propensity_score'><p>Propensity score estimation</p></a></li>
<li><a href='#proxy_BCA'><p>Baseline Conditional Average</p></a></li>
<li><a href='#proxy_CATE'><p>Conditional Average Treatment Effect</p></a></li>
<li><a href='#quantile_group'><p>Partition a vector into quantile groups</p></a></li>
<li><a href='#setup_diff'><p>Setup function for <code>diff</code> arguments</p></a></li>
<li><a href='#setup_plot'><p>Set up information for a <code>GenericML()</code> plot</p></a></li>
<li><a href='#setup_stratify'><p>Setup function for stratified sampling</p></a></li>
<li><a href='#setup_vcov'><p>Setup function for <code>vcov_control</code> arguments</p></a></li>
<li><a href='#setup_X1'><p>Setup function controlling the matrix <code class="reqn">X_1</code> in the BLP or GATES regression</p></a></li>
<li><a href='#TrueIfUnix'><p>Check if user's OS is a Unix system</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Generic Machine Learning Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Max Welz <a href="https://orcid.org/0000-0003-2945-1860"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Andreas Alfons <a href="https://orcid.org/0000-0002-2513-3788"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Mert Demirer [aut],
  Victor Chernozhukov [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Max Welz &lt;welz@ese.eur.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Generic Machine Learning Inference on heterogeneous treatment effects in randomized experiments as proposed in Chernozhukov, Demirer, Duflo and Fernández-Val (2020) &lt;<a href="https://doi.org/10.48550/arXiv.1712.04802">doi:10.48550/arXiv.1712.04802</a>&gt;. This package's workhorse is the 'mlr3' framework of Lang et al. (2019) &lt;<a href="https://doi.org/10.21105%2Fjoss.01903">doi:10.21105/joss.01903</a>&gt;, which enables the specification of a wide variety of machine learners. The main functionality, GenericML(), runs Algorithm 1 in Chernozhukov, Demirer, Duflo and Fernández-Val (2020) &lt;<a href="https://doi.org/10.48550/arXiv.1712.04802">doi:10.48550/arXiv.1712.04802</a>&gt; for a suite of user-specified machine learners. All steps in the algorithm are customizable via setup functions. Methods for printing and plotting are available for objects returned by GenericML(). Parallel computing is supported.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mwelz/GenericML/">https://github.com/mwelz/GenericML/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mwelz/GenericML/issues/">https://github.com/mwelz/GenericML/issues/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>ggplot2, mlr3, mlr3learners</td>
</tr>
<tr>
<td>Imports:</td>
<td>sandwich, lmtest, splitstackshape, stats, parallel, abind</td>
</tr>
<tr>
<td>Suggests:</td>
<td>glmnet, ranger, rpart, e1071, xgboost, kknn, DiceKriging,
testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-18 07:33:48 UTC; mwelz</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-18 08:00:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='BLP'>Performs BLP regression</h2><span id='topic+BLP'></span>

<h3>Description</h3>

<p>Performs the linear regression for the Best Linear Predictor (BLP) procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BLP(
  Y,
  D,
  propensity_scores,
  proxy_BCA,
  proxy_CATE,
  HT = FALSE,
  X1_control = setup_X1(),
  vcov_control = setup_vcov(),
  significance_level = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BLP_+3A_y">Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="BLP_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="BLP_+3A_propensity_scores">propensity_scores</code></td>
<td>
<p>A numeric vector of propensity scores. We recommend to use the estimates of a <code>"<a href="#topic+propensity_score">propensity_score</a>"</code> object.</p>
</td></tr>
<tr><td><code id="BLP_+3A_proxy_bca">proxy_BCA</code></td>
<td>
<p>A numeric vector of proxy baseline conditional average (BCA) estimates. We recommend to use the estimates of a <code>"<a href="#topic+proxy_BCA">proxy_BCA</a>"</code> object.</p>
</td></tr>
<tr><td><code id="BLP_+3A_proxy_cate">proxy_CATE</code></td>
<td>
<p>A numeric vector of proxy conditional average treatment effect (CATE) estimates. We recommend to use the estimates of a <code>"<a href="#topic+proxy_CATE">proxy_CATE</a>"</code> object.</p>
</td></tr>
<tr><td><code id="BLP_+3A_ht">HT</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a Horvitz-Thompson (HT) transformation is applied (BLP2 in the paper). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="BLP_+3A_x1_control">X1_control</code></td>
<td>
<p>Specifies the design matrix <code class="reqn">X_1</code> in the regression. Must be an object of class <code>"<a href="#topic+setup_X1">setup_X1</a>"</code>. See the documentation of <code><a href="#topic+setup_X1">setup_X1</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="BLP_+3A_vcov_control">vcov_control</code></td>
<td>
<p>Specifies the covariance matrix estimator. Must be an object of class <code>"<a href="#topic+setup_vcov">setup_vcov</a>"</code>. See the documentation of <code><a href="#topic+setup_vcov">setup_vcov</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="BLP_+3A_significance_level">significance_level</code></td>
<td>
<p>Significance level. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"BLP"</code>, consisting of the following components:
</p>

<dl>
<dt><code>generic_targets</code></dt><dd><p>A matrix of the inferential results on the BLP generic targets.</p>
</dd>
<dt><code>coefficients</code></dt><dd><p>An object of class <code>"<a href="lmtest.html#topic+coeftest">coeftest</a>"</code>, contains the coefficients of the BLP regression.</p>
</dd>
<dt><code>lm</code></dt><dd><p>An object of class <code>"<a href="stats.html#topic+lm">lm</a>"</code> used to fit the linear regression model.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setup_X1">setup_X1</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>,
<code><a href="#topic+setup_vcov">setup_vcov</a>()</code>,
<code><a href="#topic+propensity_score">propensity_score</a>()</code>,
<code><a href="#topic+proxy_BCA">proxy_BCA</a>()</code>,
<code><a href="#topic+proxy_CATE">proxy_CATE</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1)
n  &lt;- 150                        # number of observations
p  &lt;- 5                          # number of covariates
D  &lt;- rbinom(n, 1, 0.5)          # random treatment assignment
Y  &lt;- runif(n)                   # outcome variable
propensity_scores &lt;- rep(0.5, n) # propensity scores
proxy_BCA         &lt;- runif(n)    # proxy BCA estimates
proxy_CATE        &lt;- runif(n)    # proxy CATE estimates

## perform BLP
BLP(Y, D, propensity_scores, proxy_BCA, proxy_CATE)

</code></pre>

<hr>
<h2 id='CLAN'>Performs CLAN</h2><span id='topic+CLAN'></span>

<h3>Description</h3>

<p>Performs Classification Analysis (CLAN) on all variables in a design matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CLAN(
  Z_CLAN,
  membership,
  equal_variances = FALSE,
  diff = setup_diff(),
  significance_level = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CLAN_+3A_z_clan">Z_CLAN</code></td>
<td>
<p>A numeric matrix holding variables on which classification analysis (CLAN) shall be performed. CLAN will be performed on each column of the matrix.</p>
</td></tr>
<tr><td><code id="CLAN_+3A_membership">membership</code></td>
<td>
<p>A logical matrix that indicates the group membership of each observation in <code>Z_CLAN</code>. Needs to be of type <code>"<a href="#topic+quantile_group">quantile_group</a>"</code>. Typically, the grouping is based on CATE estimates, which are for instance returned by <code>proxy_CATE</code>.</p>
</td></tr>
<tr><td><code id="CLAN_+3A_equal_variances">equal_variances</code></td>
<td>
<p>If <code>TRUE</code>, then all within-group variances of the CLAN groups are assumed to be equal. Default is <code>FALSE</code>. This specification is required for heteroskedasticity-robust variance estimation on the difference of two CLAN generic targets (i.e. variance of the difference of two means). If <code>TRUE</code> (corresponds to homoskedasticity assumption), the pooled variance is used. If <code>FALSE</code> (heteroskedasticity), the variance of Welch's t-test is used.</p>
</td></tr>
<tr><td><code id="CLAN_+3A_diff">diff</code></td>
<td>
<p>Specifies the generic targets of CLAN. Must be an object of class <code>"<a href="#topic+setup_diff">setup_diff</a>"</code>. See the documentation of <code><a href="#topic+setup_diff">setup_diff</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="CLAN_+3A_significance_level">significance_level</code></td>
<td>
<p>Significance level. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>"CLAN"</code>, consisting of the following components:
</p>

<dl>
<dt><code>generic_targets</code></dt><dd><p>A list of result matrices for each variable in <code>Z_CLAN</code>. Each matrix contains inferential results on the CLAN generic targets.</p>
</dd>
<dt><code>coefficients</code></dt><dd><p>A matrix of point estimates of each CLAN generic target parameter.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quantile_group">quantile_group</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1)
n  &lt;- 150                              # number of observations
p  &lt;- 5                                # number of covariates
Z_CLAN &lt;- matrix(runif(n*p), n, p)     # design matrix to perform CLAN on
membership &lt;- quantile_group(rnorm(n)) # group membership

## perform CLAN
CLAN(Z_CLAN, membership)

</code></pre>

<hr>
<h2 id='GATES'>Performs GATES regression</h2><span id='topic+GATES'></span>

<h3>Description</h3>

<p>Performs the linear regression for the Group Average Treatments Effects (GATES) procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GATES(
  Y,
  D,
  propensity_scores,
  proxy_BCA,
  proxy_CATE,
  membership,
  HT = FALSE,
  X1_control = setup_X1(),
  vcov_control = setup_vcov(),
  diff = setup_diff(),
  significance_level = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GATES_+3A_y">Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="GATES_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="GATES_+3A_propensity_scores">propensity_scores</code></td>
<td>
<p>A numeric vector of propensity scores. We recommend to use the estimates of a <code>"<a href="#topic+propensity_score">propensity_score</a>"</code> object.</p>
</td></tr>
<tr><td><code id="GATES_+3A_proxy_bca">proxy_BCA</code></td>
<td>
<p>A numeric vector of proxy baseline conditional average (BCA) estimates. We recommend to use the estimates of a <code>"<a href="#topic+proxy_BCA">proxy_BCA</a>"</code> object.</p>
</td></tr>
<tr><td><code id="GATES_+3A_proxy_cate">proxy_CATE</code></td>
<td>
<p>A numeric vector of proxy conditional average treatment effect (CATE) estimates. We recommend to use the estimates of a <code>"<a href="#topic+proxy_CATE">proxy_CATE</a>"</code> object.</p>
</td></tr>
<tr><td><code id="GATES_+3A_membership">membership</code></td>
<td>
<p>A logical matrix that indicates the group membership of each observation in <code>Z_CLAN</code>. Needs to be of type <code>"<a href="#topic+quantile_group">quantile_group</a>"</code>. Typically, the grouping is based on CATE estimates, which are for instance returned by <code><a href="#topic+proxy_CATE">proxy_CATE</a>()</code>.</p>
</td></tr>
<tr><td><code id="GATES_+3A_ht">HT</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a Horvitz-Thompson (HT) transformation is applied (GATES2 in the paper). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GATES_+3A_x1_control">X1_control</code></td>
<td>
<p>Specifies the design matrix <code class="reqn">X_1</code> in the regression. Must be an object of class  <code>"<a href="#topic+setup_X1">setup_X1</a>"</code>. See the documentation of <code><a href="#topic+setup_X1">setup_X1</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GATES_+3A_vcov_control">vcov_control</code></td>
<td>
<p>Specifies the covariance matrix estimator. Must be an object of class <code>"<a href="#topic+setup_vcov">setup_vcov</a>"</code>. See the documentation of <code><a href="#topic+setup_vcov">setup_vcov</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GATES_+3A_diff">diff</code></td>
<td>
<p>Specifies the generic targets of CLAN. Must be an object of class <code>"<a href="#topic+setup_diff">setup_diff</a>"</code>. See the documentation of <code><a href="#topic+setup_diff">setup_diff</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GATES_+3A_significance_level">significance_level</code></td>
<td>
<p>Significance level. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"GATES"</code>, consisting of the following components:
</p>

<dl>
<dt><code>generic_targets</code></dt><dd><p>A matrix of the inferential results on the GATES generic targets.</p>
</dd>
<dt><code>coefficients</code></dt><dd><p>An object of class <code>"<a href="lmtest.html#topic+coeftest">coeftest</a>"</code>, contains the coefficients of the GATES regression.</p>
</dd>
<dt><code>lm</code></dt><dd><p>An object of class <code>"<a href="stats.html#topic+lm">lm</a>"</code> used to fit the linear regression model.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setup_X1">setup_X1</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>,
<code><a href="#topic+setup_vcov">setup_vcov</a>()</code>,
<code><a href="#topic+propensity_score">propensity_score</a>()</code>,
<code><a href="#topic+proxy_BCA">proxy_BCA</a>()</code>,
<code><a href="#topic+proxy_CATE">proxy_CATE</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1)
n  &lt;- 150                                # number of observations
p  &lt;- 5                                  # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                  # random treatment assignment
Y  &lt;- runif(n)                           # outcome variable
propensity_scores &lt;- rep(0.5, n)         # propensity scores
proxy_BCA         &lt;- runif(n)            # proxy BCA estimates
proxy_CATE        &lt;- runif(n)            # proxy CATE estimates
membership &lt;- quantile_group(proxy_CATE) # group membership

## perform GATES
GATES(Y, D, propensity_scores, proxy_BCA, proxy_CATE, membership)

</code></pre>

<hr>
<h2 id='GenericML'>Generic Machine Learning Inference</h2><span id='topic+GenericML'></span>

<h3>Description</h3>

<p>Performs generic machine learning inference on heterogeneous treatment effects as in <a href="https://arxiv.org/abs/1712.04802">Chernozhukov, Demirer, Duflo and Fernández-Val (2020)</a> with user-specified machine learning methods. Intended for randomized experiments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenericML(
  Z,
  D,
  Y,
  learners_GenericML,
  learner_propensity_score = "constant",
  num_splits = 100,
  Z_CLAN = NULL,
  HT = FALSE,
  quantile_cutoffs = c(0.25, 0.5, 0.75),
  X1_BLP = setup_X1(),
  X1_GATES = setup_X1(),
  diff_GATES = setup_diff(),
  diff_CLAN = setup_diff(),
  vcov_BLP = setup_vcov(),
  vcov_GATES = setup_vcov(),
  equal_variances_CLAN = FALSE,
  prop_aux = 0.5,
  stratify = setup_stratify(),
  significance_level = 0.05,
  min_variation = 1e-05,
  parallel = FALSE,
  num_cores = parallel::detectCores(),
  seed = NULL,
  store_learners = FALSE,
  store_splits = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenericML_+3A_z">Z</code></td>
<td>
<p>A numeric design matrix that holds the covariates in its columns.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_y">Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_learners_genericml">learners_GenericML</code></td>
<td>
<p>A character vector specifying the machine learners to be used for estimating the baseline conditional average (BCA) and conditional average treatment effect (CATE). Either <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or a custom learner specified with <code>mlr3</code> syntax. In the latter case, do <em>not</em> specify in the <code>mlr3</code> syntax specification if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 100)'</code> for a random forest learner with 100 trees. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_learner_propensity_score">learner_propensity_score</code></td>
<td>
<p>The estimator of the propensity scores. Either a numeric vector (which is then taken as estimates of the propensity scores) or a string specifying the estimator. In the latter case, the string must either be equal to <code>'constant'</code> (estimates the propensity scores by <code>mean(D)</code>), <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or <code>mlr3</code> syntax. Note that in case of <code>mlr3</code> syntax, do <em>not</em> specify if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 100)'</code> for a random forest learner with 100 trees. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_num_splits">num_splits</code></td>
<td>
<p>Number of sample splits. Default is 100. Must be larger than one. If you want to run <code>GenericML</code> on a single split, please use <code><a href="#topic+GenericML_single">GenericML_single</a>()</code>.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_z_clan">Z_CLAN</code></td>
<td>
<p>A numeric matrix holding variables on which classification analysis (CLAN) shall be performed. CLAN will be performed on each column of the matrix. If <code>NULL</code> (default), then <code>Z_CLAN = Z</code>, i.e. CLAN is performed for all variables in <code>Z</code>.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_ht">HT</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a Horvitz-Thompson (HT) transformation is applied in the BLP and GATES regressions. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_quantile_cutoffs">quantile_cutoffs</code></td>
<td>
<p>The cutoff points of the quantiles that shall be used for GATES grouping. Default is <code>c(0.25, 0.5, 0.75)</code>, which corresponds to the four quartiles.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_x1_blp">X1_BLP</code></td>
<td>
<p>Specifies the design matrix <code class="reqn">X_1</code> in the regression. Must be an object of class  <code>"<a href="#topic+setup_X1">setup_X1</a>"</code>. See the documentation of <code><a href="#topic+setup_X1">setup_X1</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_x1_gates">X1_GATES</code></td>
<td>
<p>Same as <code>X1_BLP</code>, just for the GATES regression.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_diff_gates">diff_GATES</code></td>
<td>
<p>Specifies the generic targets of GATES. Must be an object of class <code>"<a href="#topic+setup_diff">setup_diff</a>"</code>. See the documentation of <code><a href="#topic+setup_diff">setup_diff</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_diff_clan">diff_CLAN</code></td>
<td>
<p>Same as <code>diff_GATES</code>, just for the CLAN generic targets.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_vcov_blp">vcov_BLP</code></td>
<td>
<p>Specifies the covariance matrix estimator in the BLP regression. Must be an object of class <code>"<a href="#topic+setup_vcov">setup_vcov</a>"</code>. See the documentation of <code><a href="#topic+setup_vcov">setup_vcov</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_vcov_gates">vcov_GATES</code></td>
<td>
<p>Same as <code>vcov_BLP</code>, just for the GATES regression.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_equal_variances_clan">equal_variances_CLAN</code></td>
<td>
<p>Logical. If <code>TRUE</code>, then all within-group variances of the CLAN groups are assumed to be equal. Default is <code>FALSE</code>. This specification is required for heteroskedasticity-robust variance estimation on the difference of two CLAN generic targets (i.e. variance of the difference of two means). If <code>TRUE</code> (corresponds to homoskedasticity assumption), the pooled variance is used. If <code>FALSE</code> (heteroskedasticity), the variance of Welch's t-test is used.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_prop_aux">prop_aux</code></td>
<td>
<p>Proportion of samples that shall be in the auxiliary set in case of random sample splitting. Default is 0.5. The number of samples in the auxiliary set will be equal to <code>floor(prop_aux * length(Y))</code>. If the data set is large, you can save computing time by choosing <code>prop_aux</code> to be smaller than 0.5. In case of stratified sampling (controlled through the argument <code>stratify</code> via <code><a href="#topic+setup_stratify">setup_stratify</a>()</code>), <code>prop_aux</code> does not have an effect, and the number of samples in the auxiliary set is specified via <code><a href="#topic+setup_stratify">setup_stratify</a>()</code>.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_stratify">stratify</code></td>
<td>
<p>A list that specifies whether or not stratified sample splitting shall be performed. It is recommended to use the returned object of <code><a href="#topic+setup_stratify">setup_stratify</a>()</code> as this list. See the documentation of <code><a href="#topic+setup_stratify">setup_stratify</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_significance_level">significance_level</code></td>
<td>
<p>Significance level for VEIN. Default is 0.05.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_min_variation">min_variation</code></td>
<td>
<p>Specifies a threshold for the minimum variation of the BCA/CATE predictions. If the variation of a BCA/CATE prediction falls below this threshold, random noise with distribution <code class="reqn">N(0, var(Y)/20)</code> is added to it. Default is <code>1e-05</code>.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_parallel">parallel</code></td>
<td>
<p>Logical. If <code>TRUE</code>, parallel computing will be used. Default is <code>FALSE</code>. On Unix systems, this will be done via forking (shared memory across threads). On non-Unix systems, this will be done through parallel socket clusters.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to be used in parallelization (if applicable). Default is the number of cores of the user's machine.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code> for no random seeding.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_store_learners">store_learners</code></td>
<td>
<p>Logical. If <code>TRUE</code>, all intermediate results of the learners will be stored. That is, for each learner and each split, all BCA and CATE predictions as well as all BLP, GATES, CLAN, and <code class="reqn">\Lambda</code> estimates will be stored. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GenericML_+3A_store_splits">store_splits</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), the sample splits will be stored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specifications <code>"lasso"</code>, <code>"random_forest"</code>, and <code>"tree"</code> in <code>learners_GenericML</code> and <code>learner_propensity_score</code> correspond to the following <code>mlr3</code> specifications (we omit the keywords <code>classif.</code> and <code>regr.</code>). <code>"lasso"</code> is a cross-validated Lasso estimator, which corresponds to <code>'mlr3::lrn("cv_glmnet", s = "lambda.min", alpha = 1)'</code>. <code>"random_forest"</code> is a random forest with 500 trees, which corresponds to <code>'mlr3::lrn("ranger", num.trees = 500)'</code>. <code>"tree"</code> is a tree learner, which corresponds to <code>'mlr3::lrn("rpart")'</code>. <strong>Warning:</strong> <code><a href="#topic+GenericML">GenericML</a>()</code> can be quite memory-intensive, in particular when the data set is large. To alleviate memory usage, consider setting <code>store_learners = FALSE</code>, choosing a low number of cores via <code>num_cores</code> (at the expense of longer computing time), setting <code>prop_aux</code> to a value smaller than the default of 0.5, or using <code><a href="#topic+GenericML_combine">GenericML_combine</a>()</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"GenericML"</code>. On this object, we recommend to use the accessor functions <code><a href="#topic+get_BLP">get_BLP</a>()</code>, <code><a href="#topic+get_GATES">get_GATES</a>()</code>, and <code><a href="#topic+get_CLAN">get_CLAN</a>()</code> to extract the results of the analyses of BLP, GATES, and CLAN, respectively. An object of class <code>"GenericML"</code> contains the following components:
</p>

<dl>
<dt><code>VEIN</code></dt><dd><p>A list containing two sub-lists called <code>best_learners</code> and <code>all_learners</code>, respectively. Each of these two sub-lists contains the inferential VEIN results on the generic targets of the BLP, GATES, and CLAN analyses. <code>all_learners</code> does this for all learners specified in the argument <code>learners_GenericML</code>, <code>best_learners</code> only for the corresponding best learners. Which learner is best for which analysis is assessed by the <code class="reqn">\Lambda</code> criteria discussed in Sections 5.2 and 5.3 of the paper.</p>
</dd>
<dt><code>best</code></dt><dd><p>A list containing information on the evaluation of which learner is the best for which analysis. Contains four components. The first three contain the name of the best learner for BLP, GATES, and CLAN, respectively. The fourth component, <code>overview</code>, contains the two <code class="reqn">\Lambda</code> criteria used to determine the best learners (discussed in Sections 5.2 and 5.3 of the paper).</p>
</dd>
<dt><code>propensity_scores</code></dt><dd><p>The propensity score estimates as well as the <code>"mlr3"</code> objects used to estimate them (if <code>mlr3</code> was used for estimation).</p>
</dd>
<dt><code>GenericML_single</code></dt><dd><p>Only nonempty if <code>store_learners = TRUE</code>. Contains all intermediate results of each learners for each split. That is, for a given learner (first level of the list) and split (second level),  objects of classes <code>"<a href="#topic+BLP">BLP</a>"</code>, <code>"<a href="#topic+GATES">GATES</a>"</code>, <code>"<a href="#topic+CLAN">CLAN</a>"</code>, <code>"<a href="#topic+proxy_BCA">proxy_BCA</a>"</code>, <code>"<a href="#topic+proxy_CATE">proxy_CATE</a>"</code> as well as the <code class="reqn">\Lambda</code> criteria (<code>"best"</code>)) are listed, which were computed with the given learner and split.</p>
</dd>
<dt><code>splits</code></dt><dd><p>Only nonempty if <code>store_splits = TRUE</code>. Contains a character matrix of dimension <code>length(Y)</code> by <code>num_splits</code>. Contains the group membership (main or auxiliary) of each observation (rows) in each split (columns). <code>"M"</code> denotes the main set, <code>"A"</code> the auxiliary set.</p>
</dd>
<dt><code>generic_targets</code></dt><dd><p>A list of generic target estimates for each learner. More specifically, each component is a list of the generic target estimates pertaining to the BLP, GATES, and CLAN analyses. Each of those lists contains a three-dimensional array containing the generic targets of a single learner for all sample splits (except CLAN where there is one more layer of lists).</p>
</dd>
<dt><code>arguments</code></dt><dd><p>A list of arguments used in the function call.</p>
</dd>
</dl>



<h3>Note</h3>

<p>In an earlier development version, Lucas Kitzmueller alerted us to several minor bugs and proposed fixes. Many thanks to him!
</p>


<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>
<p>Lang M., Binder M., Richter J., Schratz P., Pfisterer F., Coors S., Au Q., Casalicchio G., Kotthoff L., Bischl B. (2019). &ldquo;mlr3: A Modern Object-Oriented Machine Learning Framework in R.&rdquo; <em>Journal of Open Source Software</em>, <b>4</b>(44), 1903. doi: <a href="https://doi.org/10.21105/joss.01903">10.21105/joss.01903</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.GenericML">plot.GenericML</a>()</code>
<code><a href="#topic+print.GenericML">print.GenericML</a>()</code>
<code><a href="#topic+get_BLP">get_BLP</a>()</code>,
<code><a href="#topic+get_GATES">get_GATES</a>()</code>,
<code><a href="#topic+get_CLAN">get_CLAN</a>()</code>,
<code><a href="#topic+setup_X1">setup_X1</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>,
<code><a href="#topic+setup_vcov">setup_vcov</a>()</code>,
<code><a href="#topic+setup_stratify">setup_stratify</a>()</code>,
<code><a href="#topic+GenericML_single">GenericML_single</a>()</code>,
<code><a href="#topic+GenericML_combine">GenericML_combine</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("glmnet") &amp;&amp; require("ranger")) {

## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## column names of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("lasso", "mlr3::lrn('ranger', num.trees = 10)")

## glmnet v4.1.3 isn't supported on Solaris, so skip Lasso in this case
if(Sys.info()["sysname"] == "SunOS") learners &lt;- learners[-1]

## specify quantile cutoffs (the 4 quartile groups here)
quantile_cutoffs &lt;- c(0.25, 0.5, 0.75)

## specify the differenced generic targets of GATES and CLAN
# use G4-G1, G4-G2, G4-G3 as differenced generic targets in GATES
diff_GATES &lt;- setup_diff(subtract_from = "most",
                        subtracted = c(1,2,3))
# use G1-G3, G1-G2 as differenced generic targets in CLAN
diff_CLAN  &lt;- setup_diff(subtract_from = "least",
                         subtracted = c(3,2))

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               quantile_cutoffs = quantile_cutoffs,
               diff_GATES = diff_GATES,
               diff_CLAN = diff_CLAN,
               parallel = FALSE)

## access BLP generic targets for best learner and make plot
get_BLP(x, plot = TRUE)

## access GATES generic targets for best learner and make plot
get_GATES(x, plot = TRUE)

## access CLAN generic targets for "V1" &amp; best learner and make plot
get_CLAN(x, variable = "V1", plot = TRUE)

}

</code></pre>

<hr>
<h2 id='GenericML_combine'>Combine several GenericML objects</h2><span id='topic+GenericML_combine'></span>

<h3>Description</h3>

<p>This function combines multiple <code>"<a href="#topic+GenericML">GenericML</a>"</code> objects into one  <code>"<a href="#topic+GenericML">GenericML</a>"</code> object. Combining several  <code>"<a href="#topic+GenericML">GenericML</a>"</code> objects can be useful when you cannot run <code><a href="#topic+GenericML">GenericML</a>()</code> for sufficiently many splits due to memory constraints. In this case, you may run <code><a href="#topic+GenericML">GenericML</a>()</code> multiple times with only a small number of sample splits each and combine the returned <code>"<a href="#topic+GenericML">GenericML</a>"</code> objects into one <code>GenericML</code> object with this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenericML_combine(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenericML_combine_+3A_x">x</code></td>
<td>
<p>A list of <code>"<a href="#topic+GenericML">GenericML</a>"</code> objects, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To ensure consistency of the estimates, all <code>"<a href="#topic+GenericML">GenericML</a>"</code> objects in the list <code>x</code> must have the exact same parameter specifications in their original call to <code><a href="#topic+GenericML">GenericML</a>()</code>, except for the parameters <code>num_splits</code>, <code>parallel</code>, <code>num_cores</code>, <code>seed</code>, and <code>store_learners</code> (i.e. these arguments may vary between the <code>"<a href="#topic+GenericML">GenericML</a>"</code> objects in the list <code>x</code>). An error will be thrown if this is not satisfied.
</p>


<h3>Value</h3>

<p>A<code>"<a href="#topic+GenericML">GenericML</a>"</code> object as returned by <code><a href="#topic+GenericML">GenericML</a>()</code>. In the <code>arguments</code> component of this object, the objects <code>parallel</code>, <code>num_cores</code>, <code>seed</code>, and <code>store_learners</code> are set to <code>NULL</code> as these might differ between the individual <code>GenericML</code> objects in <code>x</code>. Moreover, the <code>propensity_scores</code> component of the returned object is taken from the first <code>"<a href="#topic+GenericML">GenericML</a>"</code> object in <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("glmnet") &amp;&amp; require("ranger")) {

## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## column names of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("lasso", "mlr3::lrn('ranger', num.trees = 10)")

## glmnet v4.1.3 isn't supported on Solaris, so skip Lasso in this case
if(Sys.info()["sysname"] == "SunOS") learners &lt;- learners[-1]

## call GenericML three times and store the returned objects in a list x
x &lt;- lapply(1:3, function(...) GenericML(Z, D, Y,
                               learners, num_splits = 2,
                               parallel = FALSE))

## combine the objects in x into one GenericML object
genML &lt;- GenericML_combine(x)

## you can use all methods of GenericML objects on the combined object, for instance accessors:
get_BLP(genML, plot = TRUE)
}

</code></pre>

<hr>
<h2 id='GenericML_single'>Single iteration of the GenericML algorithm</h2><span id='topic+GenericML_single'></span>

<h3>Description</h3>

<p>Performs generic ML inference for a single learning technique and a given split of the data. Can be seen as a single iteration of Algorithm 1 in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenericML_single(
  Z,
  D,
  Y,
  learner,
  propensity_scores,
  M_set,
  A_set = setdiff(1:length(Y), M_set),
  Z_CLAN = NULL,
  HT = FALSE,
  quantile_cutoffs = c(0.25, 0.5, 0.75),
  X1_BLP = setup_X1(),
  X1_GATES = setup_X1(),
  diff_GATES = setup_diff(),
  diff_CLAN = setup_diff(),
  vcov_BLP = setup_vcov(),
  vcov_GATES = setup_vcov(),
  equal_variances_CLAN = FALSE,
  significance_level = 0.05,
  min_variation = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenericML_single_+3A_z">Z</code></td>
<td>
<p>A numeric design matrix that holds the covariates in its columns.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_y">Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_learner">learner</code></td>
<td>
<p>A character specifying the machine learner to be used for estimating the baseline conditional average (BCA) and conditional average treatment effect (CATE). Either <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or a custom learner specified with <code>mlr3</code> syntax. In the latter case, do <em>not</em> specify in the <code>mlr3</code> syntax specification if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 100)'</code> for a random forest learner with 100 trees. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_propensity_scores">propensity_scores</code></td>
<td>
<p>A numeric vector of propensity score estimates.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_m_set">M_set</code></td>
<td>
<p>A numerical vector of indices of observations in the main sample.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_a_set">A_set</code></td>
<td>
<p>A numerical vector of indices of observations in the auxiliary sample. Default is complementary set to <code>M_set</code>.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_z_clan">Z_CLAN</code></td>
<td>
<p>A numeric matrix holding variables on which classification analysis (CLAN) shall be performed. CLAN will be performed on each column of the matrix. If <code>NULL</code> (default), then <code>Z_CLAN = Z</code>, i.e. CLAN is performed for all variables in <code>Z</code>.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_ht">HT</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a Horvitz-Thompson (HT) transformation is applied in the BLP and GATES regressions. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_quantile_cutoffs">quantile_cutoffs</code></td>
<td>
<p>The cutoff points of the quantiles that shall be used for GATES grouping. Default is <code>c(0.25, 0.5, 0.75)</code>, which corresponds to the four quartiles.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_x1_blp">X1_BLP</code></td>
<td>
<p>Specifies the design matrix <code class="reqn">X_1</code> in the regression. Must be an object of class  <code>"<a href="#topic+setup_X1">setup_X1</a>"</code>. See the documentation of <code><a href="#topic+setup_X1">setup_X1</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_x1_gates">X1_GATES</code></td>
<td>
<p>Same as <code>X1_BLP</code>, just for the GATES regression.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_diff_gates">diff_GATES</code></td>
<td>
<p>Specifies the generic targets of GATES. Must be an object of class <code>"<a href="#topic+setup_diff">setup_diff</a>"</code>. See the documentation of <code><a href="#topic+setup_diff">setup_diff</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_diff_clan">diff_CLAN</code></td>
<td>
<p>Same as <code>diff_GATES</code>, just for the CLAN generic targets.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_vcov_blp">vcov_BLP</code></td>
<td>
<p>Specifies the covariance matrix estimator in the BLP regression. Must be an object of class <code>"<a href="#topic+setup_vcov">setup_vcov</a>"</code>. See the documentation of <code><a href="#topic+setup_vcov">setup_vcov</a>()</code> for details.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_vcov_gates">vcov_GATES</code></td>
<td>
<p>Same as <code>vcov_BLP</code>, just for the GATES regression.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_equal_variances_clan">equal_variances_CLAN</code></td>
<td>
<p>Logical. If <code>TRUE</code>, then all within-group variances of the CLAN groups are assumed to be equal. Default is <code>FALSE</code>. This specification is required for heteroskedasticity-robust variance estimation on the difference of two CLAN generic targets (i.e. variance of the difference of two means). If <code>TRUE</code> (corresponds to homoskedasticity assumption), the pooled variance is used. If <code>FALSE</code> (heteroskedasticity), the variance of Welch's t-test is used.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_significance_level">significance_level</code></td>
<td>
<p>Significance level for VEIN. Default is 0.05.</p>
</td></tr>
<tr><td><code id="GenericML_single_+3A_min_variation">min_variation</code></td>
<td>
<p>Specifies a threshold for the minimum variation of the BCA/CATE predictions. If the variation of a BCA/CATE prediction falls below this threshold, random noise with distribution <code class="reqn">N(0, var(Y)/20)</code> is added to it. Default is <code>1e-05</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specifications <code>"lasso"</code>, <code>"random_forest"</code>, and <code>"tree"</code> in <code>learner</code> correspond to the following <code>mlr3</code> specifications (we omit the keywords <code>classif.</code> and <code>regr.</code>). <code>"lasso"</code> is a cross-validated Lasso estimator, which corresponds to <code>'mlr3::lrn("cv_glmnet", s = "lambda.min", alpha = 1)'</code>. <code>"random_forest"</code> is a random forest with 500 trees, which corresponds to <code>'mlr3::lrn("ranger", num.trees = 500)'</code>. <code>"tree"</code> is a tree learner, which corresponds to <code>'mlr3::lrn("rpart")'</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>

<dl>
<dt><code>BLP</code></dt><dd><p>An object of class <code>"<a href="#topic+BLP">BLP</a>"</code>.</p>
</dd>
<dt><code>GATES</code></dt><dd><p>An object of class <code>"<a href="#topic+GATES">GATES</a>"</code>.</p>
</dd>
<dt><code>CLAN</code></dt><dd><p>An object of class <code>"<a href="#topic+CLAN">CLAN</a>"</code>.</p>
</dd>
<dt><code>proxy_BCA</code></dt><dd><p>An object of class <code>"<a href="#topic+proxy_BCA">proxy_BCA</a>"</code>.</p>
</dd>
<dt><code>proxy_CATE</code></dt><dd><p>An object of class <code>"<a href="#topic+proxy_CATE">proxy_CATE</a>"</code>.</p>
</dd>
<dt><code>best</code></dt><dd><p>Estimates of the <code class="reqn">\Lambda</code> parameters for finding the best learner. Returned by <code><a href="#topic+lambda_parameters">lambda_parameters</a>()</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>
<p>Lang M., Binder M., Richter J., Schratz P., Pfisterer F., Coors S., Au Q., Casalicchio G., Kotthoff L., Bischl B. (2019). &ldquo;mlr3: A Modern Object-Oriented Machine Learning Framework in R.&rdquo; <em>Journal of Open Source Software</em>, <b>4</b>(44), 1903. doi: <a href="https://doi.org/10.21105/joss.01903">10.21105/joss.01903</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                        # number of observations
p  &lt;- 5                          # number of covariates
Z  &lt;- matrix(runif(n*p), n, p)   # design matrix
D  &lt;- rbinom(n, 1, 0.5)          # random treatment assignment
Y  &lt;- runif(n)                   # outcome variable
propensity_scores &lt;- rep(0.5, n) # propensity scores
M_set &lt;- sample(1:n, size = n/2) # main set

## specify learner
learner &lt;- "mlr3::lrn('ranger', num.trees = 10)"

## run single GenericML iteration
GenericML_single(Z, D, Y, learner, propensity_scores, M_set)
}

</code></pre>

<hr>
<h2 id='get_best'>Accessor function for the best learner estimates</h2><span id='topic+get_best'></span>

<h3>Description</h3>

<p>The best learner is determined by maximizing the criteria <code class="reqn">\Lambda</code> and <code class="reqn">\bar{\Lambda}</code>, see Sections 5.2 and 5.3 of the paper. This function accesses the estimates of these two criteria,
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_best(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_best_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"best"</code>, which consists of the following components:
</p>

<dl>
<dt><code>BLP</code></dt><dd><p>A string holding the name of the best learner for a BLP analysis.</p>
</dd>
<dt><code>GATES</code></dt><dd><p>A string holding the name of the best learner for a GATES analysis.</p>
</dd>
<dt><code>CLAN</code></dt><dd><p>A string holding the name of the best learner for a CLAN analysis (same learner as in <code>GATES</code>).</p>
</dd>
<dt><code>overview</code></dt><dd><p>A numeric matrix of the estimates of the performance measures <code class="reqn">\Lambda</code> and <code class="reqn">\bar{\Lambda}</code> for each learner.</p>
</dd></dl>



<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+get_BLP">get_BLP</a>()</code>,
<code><a href="#topic+get_GATES">get_GATES</a>()</code>,
<code><a href="#topic+get_CLAN">get_CLAN</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("rpart") &amp;&amp; require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## column names of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("tree", "mlr3::lrn('ranger', num.trees = 10)")

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               parallel = FALSE)

## access best learner
get_best(x)

## access BLP generic targets for best learner w/o plot
get_BLP(x, learner = "best", plot = FALSE)

## access BLP generic targets for ranger learner w/o plot
get_BLP(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access GATES generic targets for best learner w/o plot
get_GATES(x, learner = "best", plot = FALSE)

## access GATES generic targets for ranger learner w/o plot
get_GATES(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access CLAN generic targets for "V1" &amp; best learner, w/o plot
get_CLAN(x, learner = "best", variable = "V1", plot = FALSE)

## access CLAN generic targets for "V1" &amp; ranger learner, w/o plot
get_CLAN(x, learner = "mlr3::lrn('ranger', num.trees = 10)",
         variable = "V1", plot = FALSE)
}

</code></pre>

<hr>
<h2 id='get_BLP'>Accessor function for the BLP generic target estimates</h2><span id='topic+get_BLP'></span>

<h3>Description</h3>

<p>Accessor function for the BLP generic target estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_BLP(x, learner = "best", plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_BLP_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="get_BLP_+3A_learner">learner</code></td>
<td>
<p>A character string of the learner whose BLP generic target estimates shall be accessed. Default is <code>"best"</code> for the best learner for BLP.</p>
</td></tr>
<tr><td><code id="get_BLP_+3A_plot">plot</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), a <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code> object is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"BLP_info"</code>, which consists of the following components:
</p>

<dl>
<dt><code>estimate</code></dt><dd><p>A numeric vector of point estimates of the BLP generic targets.</p>
</dd>
<dt><code>confidence_interval</code></dt><dd><p>A numeric matrix of the lower and upper confidence bounds for each generic target. The confidence level of the implied confidence interval is equal to <code>1 - 2 * significance_level</code>.</p>
</dd>
<dt><code>confidence_level</code></dt><dd><p>The confidence level of the confidence intervals. Equals <code>1 - 2 * significance_level</code>.</p>
</dd>
<dt><code>learner</code></dt><dd><p>The argument <code>learner</code>.</p>
</dd>
<dt><code>plot</code></dt><dd><p>An object of class <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code>. Only returned if the argument <code>plot = TRUE</code>.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+get_GATES">get_GATES</a>()</code>,
<code><a href="#topic+get_CLAN">get_CLAN</a>()</code>,
<code><a href="#topic+get_best">get_best</a>()</code>,
<code><a href="#topic+print.BLP_info">print.BLP_info</a>()</code>,
<code><a href="#topic+print.GATES_info">print.GATES_info</a>()</code>,
<code><a href="#topic+print.CLAN_info">print.CLAN_info</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("rpart") &amp;&amp; require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## column names of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("tree", "mlr3::lrn('ranger', num.trees = 10)")

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               parallel = FALSE)

## access best learner
get_best(x)

## access BLP generic targets for best learner w/o plot
get_BLP(x, learner = "best", plot = FALSE)

## access BLP generic targets for ranger learner w/o plot
get_BLP(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access GATES generic targets for best learner w/o plot
get_GATES(x, learner = "best", plot = FALSE)

## access GATES generic targets for ranger learner w/o plot
get_GATES(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access CLAN generic targets for "V1" &amp; best learner, w/o plot
get_CLAN(x, learner = "best", variable = "V1", plot = FALSE)

## access CLAN generic targets for "V1" &amp; ranger learner, w/o plot
get_CLAN(x, learner = "mlr3::lrn('ranger', num.trees = 10)",
         variable = "V1", plot = FALSE)
}

</code></pre>

<hr>
<h2 id='get_CLAN'>Accessor function for the CLAN generic target estimates</h2><span id='topic+get_CLAN'></span>

<h3>Description</h3>

<p>Accessor function for the CLAN generic target estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_CLAN(x, variable, learner = "best", plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_CLAN_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="get_CLAN_+3A_variable">variable</code></td>
<td>
<p>The (character) name of a variabe on which CLAN was performed.</p>
</td></tr>
<tr><td><code id="get_CLAN_+3A_learner">learner</code></td>
<td>
<p>A character string of the learner whose CLAN generic target estimates shall be accessed. Default is <code>"best"</code> for the best learner for CLAN</p>
</td></tr>
<tr><td><code id="get_CLAN_+3A_plot">plot</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), a <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code> object is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"CLAN_info"</code>, which consists of the following components:
</p>

<dl>
<dt><code>estimate</code></dt><dd><p>A numeric vector of point estimates of the CLAN generic targets.</p>
</dd>
<dt><code>confidence_interval</code></dt><dd><p>A numeric matrix of the lower and upper confidence bounds for each generic target. The confidence level of the implied confidence interval is equal to <code>1 - 2 * significance_level</code>.</p>
</dd>
<dt><code>confidence_level</code></dt><dd><p>The confidence level of the confidence intervals. Equals <code>1 - 2 * significance_level</code>.</p>
</dd>
<dt><code>learner</code></dt><dd><p>The argument <code>learner</code>.</p>
</dd>
<dt><code>plot</code></dt><dd><p>An object of class <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code>. Only returned if the argument <code>plot = TRUE</code>.</p>
</dd>
<dt><code>CLAN_variable</code></dt><dd><p>The name of the CLAN variable of interest.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+get_BLP">get_BLP</a>()</code>,
<code><a href="#topic+get_GATES">get_GATES</a>()</code>,
<code><a href="#topic+get_best">get_best</a>()</code>,
<code><a href="#topic+print.BLP_info">print.BLP_info</a>()</code>,
<code><a href="#topic+print.GATES_info">print.GATES_info</a>()</code>,
<code><a href="#topic+print.CLAN_info">print.CLAN_info</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("rpart") &amp;&amp; require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## column names of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("tree", "mlr3::lrn('ranger', num.trees = 10)")

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               parallel = FALSE)

## access best learner
get_best(x)

## access BLP generic targets for best learner w/o plot
get_BLP(x, learner = "best", plot = FALSE)

## access BLP generic targets for ranger learner w/o plot
get_BLP(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access GATES generic targets for best learner w/o plot
get_GATES(x, learner = "best", plot = FALSE)

## access GATES generic targets for ranger learner w/o plot
get_GATES(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access CLAN generic targets for "V1" &amp; best learner, w/o plot
get_CLAN(x, learner = "best", variable = "V1", plot = FALSE)

## access CLAN generic targets for "V1" &amp; ranger learner, w/o plot
get_CLAN(x, learner = "mlr3::lrn('ranger', num.trees = 10)",
         variable = "V1", plot = FALSE)
}

</code></pre>

<hr>
<h2 id='get_GATES'>Accessor function for the GATES generic target estimates</h2><span id='topic+get_GATES'></span>

<h3>Description</h3>

<p>Accessor function for the GATES generic target estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_GATES(x, learner = "best", plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_GATES_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="get_GATES_+3A_learner">learner</code></td>
<td>
<p>A character string of the learner whose GATES generic target estimates shall be accessed. Default is <code>"best"</code> for the best learner for GATES.</p>
</td></tr>
<tr><td><code id="get_GATES_+3A_plot">plot</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), a <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code> object is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"GATES_info"</code>, which consists of the following components:
</p>

<dl>
<dt><code>estimate</code></dt><dd><p>A numeric vector of point estimates of the GATES generic targets.</p>
</dd>
<dt><code>confidence_interval</code></dt><dd><p>A numeric matrix of the lower and upper confidence bounds for each generic target. The confidence level of the implied confidence interval is equal to <code>1 - 2 * significance_level</code>.</p>
</dd>
<dt><code>confidence_level</code></dt><dd><p>The confidence level of the confidence intervals. Equals <code>1 - 2 * significance_level</code>.</p>
</dd>
<dt><code>learner</code></dt><dd><p>The argument <code>learner</code>.</p>
</dd>
<dt><code>plot</code></dt><dd><p>An object of class <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code>. Only returned if the argument <code>plot = TRUE</code>.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+get_BLP">get_BLP</a>()</code>,
<code><a href="#topic+get_CLAN">get_CLAN</a>()</code>,
<code><a href="#topic+get_best">get_best</a>()</code>,
<code><a href="#topic+print.BLP_info">print.BLP_info</a>()</code>,
<code><a href="#topic+print.GATES_info">print.GATES_info</a>()</code>,
<code><a href="#topic+print.CLAN_info">print.CLAN_info</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("rpart") &amp;&amp; require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## column names of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("tree", "mlr3::lrn('ranger', num.trees = 10)")

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               parallel = FALSE)

## access best learner
get_best(x)

## access BLP generic targets for best learner w/o plot
get_BLP(x, learner = "best", plot = FALSE)

## access BLP generic targets for ranger learner w/o plot
get_BLP(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access GATES generic targets for best learner w/o plot
get_GATES(x, learner = "best", plot = FALSE)

## access GATES generic targets for ranger learner w/o plot
get_GATES(x, learner = "mlr3::lrn('ranger', num.trees = 10)", plot = FALSE)

## access CLAN generic targets for "V1" &amp; best learner, w/o plot
get_CLAN(x, learner = "best", variable = "V1", plot = FALSE)

## access CLAN generic targets for "V1" &amp; ranger learner, w/o plot
get_CLAN(x, learner = "mlr3::lrn('ranger', num.trees = 10)",
         variable = "V1", plot = FALSE)
}

</code></pre>

<hr>
<h2 id='heterogeneity_CLAN'>Evaluate treatment effect heterogeneity along CLAN variables</h2><span id='topic+heterogeneity_CLAN'></span>

<h3>Description</h3>

<p>This function tests for statistical significance of all CLAN difference parameters that were specified in the function <code><a href="#topic+setup_diff">setup_diff</a>()</code>. It reports all CLAN variables along which there are significant difference parameters, which corresponds to evidence for treatment effect heterogeneity along this variable, at the specified significance level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heterogeneity_CLAN(x, learner = "best", significance_level = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heterogeneity_CLAN_+3A_x">x</code></td>
<td>
<p>An object of class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="heterogeneity_CLAN_+3A_learner">learner</code></td>
<td>
<p>A character string of the learner whose CLAN generic target estimates are of interest. Default is <code>"best"</code> for the best learner for CLAN.</p>
</td></tr>
<tr><td><code id="heterogeneity_CLAN_+3A_significance_level">significance_level</code></td>
<td>
<p>Level for the significance tests. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"heterogeneity_CLAN"</code>, consisting of the following components:
</p>

<dl>
<dt><code>p_values</code></dt><dd><p>A matrix of p values of all CLAN difference parameters for all CLAN variables.</p>
</dd>
<dt><code>significant</code></dt><dd><p>The names of variables with at least one significant CLAN difference parameter (<code>"variables"</code>), their number <code>"num_variables"</code>, and the total number of significant CLAN difference parameters <code>"num_params"</code>. All significance tests were performed at level <code>significance_level</code>.</p>
</dd>
<dt><code>min_pval</code></dt><dd><p>Information on the smallest p value: Its value (<code>"value"</code>), the variable in which it was estimated (<code>"variable"</code>), the CLAN difference parameter it belongs to (<code>"parameter"</code>), and whether or not it is significant at level <code>significance_level</code> (<code>"significant"</code>).</p>
</dd>
<dt><code>"learner"</code></dt><dd><p>Name of the learner whose median estimates we used for the listed results.</p>
</dd>
<dt><code>"significance_level"</code></dt><dd><p>The level of the significance tests.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>
</p>

<hr>
<h2 id='lambda_parameters'>Estimate the two lambda parameters</h2><span id='topic+lambda_parameters'></span>

<h3>Description</h3>

<p>Estimates the lambda parameters <code class="reqn">\Lambda</code> and <code class="reqn">\bar{\Lambda}</code> whose medians are used to find the best ML method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda_parameters(BLP, GATES, proxy_CATE, membership)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda_parameters_+3A_blp">BLP</code></td>
<td>
<p>An object of class <code>"<a href="#topic+BLP">BLP</a>"</code>.</p>
</td></tr>
<tr><td><code id="lambda_parameters_+3A_gates">GATES</code></td>
<td>
<p>An object of class <code>"<a href="#topic+GATES">GATES</a>"</code>.</p>
</td></tr>
<tr><td><code id="lambda_parameters_+3A_proxy_cate">proxy_CATE</code></td>
<td>
<p>Proxy estimates of the CATE.</p>
</td></tr>
<tr><td><code id="lambda_parameters_+3A_membership">membership</code></td>
<td>
<p>A logical matrix that indicates the group membership of each observation in <code>Z_CLAN</code>. Needs to be of type <code>"<a href="#topic+quantile_group">quantile_group</a>"</code>. Typically, the grouping is based on CATE estimates, which are for instance returned by <code><a href="#topic+proxy_CATE">proxy_CATE</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the estimates of <code class="reqn">\Lambda</code> and <code class="reqn">\bar{\Lambda}</code>, denoted <code>lambda</code> and <code>lambda.bar</code>, respectively.
</p>


<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1)
n  &lt;- 200                                # number of observations
p  &lt;- 5                                  # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                  # random treatment assignment
Y  &lt;- runif(n)                           # outcome variable
propensity_scores &lt;- rep(0.5, n)         # propensity scores
proxy_BCA         &lt;- runif(n)            # proxy BCA estimates
proxy_CATE        &lt;- runif(n)            # proxy CATE estimates
membership &lt;- quantile_group(proxy_CATE) # group membership

## perform BLP
BLP &lt;- BLP(Y, D, propensity_scores, proxy_BCA, proxy_CATE)

## perform GATES
GATES &lt;- GATES(Y, D, propensity_scores, proxy_BCA, proxy_CATE, membership)

## get estimates of the lambda parameters
lambda_parameters(BLP, GATES, proxy_CATE, membership)

</code></pre>

<hr>
<h2 id='Med'>Calculate lower and upper median</h2><span id='topic+Med'></span>

<h3>Description</h3>

<p>Calculates the lower and and median of a vector as proposed in Comment 4.2 in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Med(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Med_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the upper and lower median and the Med statistic (which is their mean).
</p>


<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- runif(100)
Med(x)

</code></pre>

<hr>
<h2 id='plot.GenericML'>Plot method for a <code>"GenericML"</code> object</h2><span id='topic+plot.GenericML'></span>

<h3>Description</h3>

<p>Visualizes the estimates of the generic targets of interest: plots the point estimates as well as the corresponding confidence intervals. The generic targets of interest can be (subsets of) the parameters of the BLP, GATES, or CLAN analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GenericML'
plot(
  x,
  type = "GATES",
  learner = "best",
  CLAN_variable = NULL,
  groups = "all",
  ATE = TRUE,
  limits = NULL,
  title = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.GenericML_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_type">type</code></td>
<td>
<p>The analysis whose parameters shall be plotted. Either <code>"GATES"</code>, <code>"BLP"</code>, or <code>"CLAN"</code>. Default is <code>"GATES"</code>.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_learner">learner</code></td>
<td>
<p>The learner whose results are to be returned. Default is <code>"best"</code> for the best learner as measured by the <code class="reqn">\Lambda</code> parameters.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_clan_variable">CLAN_variable</code></td>
<td>
<p>Name of the CLAN variable to be plotted. Only applicable if <code>type = "CLAN"</code>.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_groups">groups</code></td>
<td>
<p>Character vector indicating the per-group parameter estimates that shall be plotted in GATES and CLAN analyses. Default is <code>"all"</code> for all parameters. If there are <code class="reqn">K</code> groups, this variable is a subset of <code>c("G1", "G2",...,"GK", "G1-G2", "G1-G2",..., "G1-GK", "GK-G1", "GK-G2",...)</code>, where Gk denotes the k-th group. Note that this set depends on the choices of the arguments <code>"diff_GATES"</code> and <code>"diff_CLAN"</code> of the <code>"<a href="#topic+GenericML">GenericML</a>"</code> object.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_ate">ATE</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), then the BLP estimate of the average treatment effect along with confidence intervals will be added to the plot. Only applicable if <code>type</code> is <code>"CLAN"</code> or <code>"GATES"</code>.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_limits">limits</code></td>
<td>
<p>A numeric vector of length two holding the limits of the y-axis of the plot.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="plot.GenericML_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you wish to retrieve the data frame that this plot method visualizes, please use <code><a href="#topic+setup_plot">setup_plot</a>()</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"<a href="ggplot2.html#topic+ggplot">ggplot</a>"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+setup_plot">setup_plot</a>()</code>,
<code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+get_BLP">get_BLP</a>()</code>,
<code><a href="#topic+get_GATES">get_GATES</a>()</code>,
<code><a href="#topic+get_CLAN">get_CLAN</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("ranger")) {

## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## name the columns of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("random_forest")

## specify quantile cutoffs (the 4 quartile groups here)
quantile_cutoffs &lt;- c(0.25, 0.5, 0.75)

## specify the differenced generic targets of GATES and CLAN
diff_GATES &lt;- setup_diff(subtract_from = "most",
                         subtracted = c(1,2,3))
diff_CLAN  &lt;- setup_diff(subtract_from = "least",
                         subtracted = c(3,2))

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               quantile_cutoffs = quantile_cutoffs,
               diff_GATES = diff_GATES,
               diff_CLAN = diff_CLAN,
               parallel = FALSE)

## plot BLP parameters
plot(x, type = "BLP")

## plot GATES parameters "G1", "G4", "G4-G1"
plot(x, type = "GATES", groups = c("G1", "G4", "G4-G1"))

## plot CLAN parameters "G1", "G2", "G2-G1" of variable "V1":
plot(x, type = "CLAN", CLAN_variable = "V1",
     groups = c("G1", "G2", "G1-G3"))
}

</code></pre>

<hr>
<h2 id='print.BLP_info'>Print method for a <code>"BLP_info"</code> object</h2><span id='topic+print.BLP_info'></span>

<h3>Description</h3>

<p>Print method for a <code>"BLP_info"</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BLP_info'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.BLP_info_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"BLP_info"</code>, as returned by the function <code><a href="#topic+get_BLP">get_BLP</a>()</code>.</p>
</td></tr>
<tr><td><code id="print.BLP_info_+3A_digits">digits</code></td>
<td>
<p>Number of digits to print.</p>
</td></tr>
<tr><td><code id="print.BLP_info_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A print to the console.
</p>

<hr>
<h2 id='print.CLAN_info'>Print method for a <code>"CLAN_info"</code> object</h2><span id='topic+print.CLAN_info'></span>

<h3>Description</h3>

<p>Print method for a <code>"CLAN_info"</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CLAN_info'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.CLAN_info_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"CLAN_info"</code>, as returned by the function <code><a href="#topic+get_CLAN">get_CLAN</a>()</code>.</p>
</td></tr>
<tr><td><code id="print.CLAN_info_+3A_digits">digits</code></td>
<td>
<p>Number of digits to print.</p>
</td></tr>
<tr><td><code id="print.CLAN_info_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A print to the console.
</p>

<hr>
<h2 id='print.GATES_info'>Print method for a <code>"GATES_info"</code> object</h2><span id='topic+print.GATES_info'></span>

<h3>Description</h3>

<p>Print method for a <code>"GATES_info"</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GATES_info'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.GATES_info_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"GATES_info"</code>, as returned by the function <code><a href="#topic+get_GATES">get_GATES</a>()</code>.</p>
</td></tr>
<tr><td><code id="print.GATES_info_+3A_digits">digits</code></td>
<td>
<p>Number of digits to print.</p>
</td></tr>
<tr><td><code id="print.GATES_info_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A print to the console.
</p>

<hr>
<h2 id='print.GenericML'>Print method for a <code>GenericML</code> object</h2><span id='topic+print.GenericML'></span>

<h3>Description</h3>

<p>Prints key results of the analyses conducted in <code><a href="#topic+GenericML">GenericML</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GenericML'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.GenericML_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="print.GenericML_+3A_digits">digits</code></td>
<td>
<p>Number of digits to print.</p>
</td></tr>
<tr><td><code id="print.GenericML_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A print to the console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("ranger")){

## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## specify learners
learners &lt;- c("random_forest")

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners, num_splits = 2,
               parallel = FALSE)

## print
print(x)
}

</code></pre>

<hr>
<h2 id='print.heterogeneity_CLAN'>Print method for a <code>"heterogeneity_CLAN"</code> object</h2><span id='topic+print.heterogeneity_CLAN'></span>

<h3>Description</h3>

<p>Print method for a <code>"heterogeneity_CLAN"</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'heterogeneity_CLAN'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.heterogeneity_CLAN_+3A_x">x</code></td>
<td>
<p>An object of class <code>"<a href="#topic+heterogeneity_CLAN">heterogeneity_CLAN</a>"</code>.</p>
</td></tr>
<tr><td><code id="print.heterogeneity_CLAN_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A print to the console.
</p>

<hr>
<h2 id='propensity_score'>Propensity score estimation</h2><span id='topic+propensity_score'></span>

<h3>Description</h3>

<p>Estimates the propensity scores <code class="reqn">Pr[D = 1 | Z]</code> for binary treatment assignment <code class="reqn">D</code> and covariates <code class="reqn">Z</code>. Either done by taking the empirical mean of <code class="reqn">D</code> (which should equal roughly 0.5, since we assume a randomized experiment), or by direct machine learning estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propensity_score(Z, D, estimator = "constant")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="propensity_score_+3A_z">Z</code></td>
<td>
<p>A numeric design matrix that holds the covariates in its columns.</p>
</td></tr>
<tr><td><code id="propensity_score_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="propensity_score_+3A_estimator">estimator</code></td>
<td>
<p>Character specifying the estimator. Must either be equal to <code>'constant'</code> (estimates the propensity scores by <code>mean(D)</code>), <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or <code>mlr3</code> syntax. Note that in case of <code>mlr3</code> syntax, do <em>not</em> specify if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 500)'</code> for a random forest learner. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specifications <code>"lasso"</code>, <code>"random_forest"</code>, and <code>"tree"</code> in <code>estimator</code> correspond to the following <code>mlr3</code> specifications (we omit the keywords <code>classif.</code> and <code>regr.</code>). <code>"lasso"</code> is a cross-validated Lasso estimator, which corresponds to <code>'mlr3::lrn("cv_glmnet", s = "lambda.min", alpha = 1)'</code>. <code>"random_forest"</code> is a random forest with 500 trees, which corresponds to <code>'mlr3::lrn("ranger", num.trees = 500)'</code>. <code>"tree"</code> is a tree learner, which corresponds to <code>'mlr3::lrn("rpart")'</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"propensity_score"</code>, consisting of the following components:
</p>

<dl>
<dt><code>estimates</code></dt><dd><p>A numeric vector of propensity score estimates.</p>
</dd>
<dt><code>mlr3_objects</code></dt><dd><p><code>"mlr3"</code> objects used for estimation. Only non-empty if <code>mlr3</code> was used.</p>
</dd>
</dl>



<h3>References</h3>

<p>Rosenbaum P.R., Rubin D.B. (1983). &ldquo;The Central Role of the Propensity Score in Observational Studies for Causal Effects.&rdquo; <em>Biometrika</em>, <b>70</b>(1), 41&ndash;55. doi: <a href="https://doi.org/10.1093/biomet/70.1.41">10.1093/biomet/70.1.41</a>.
</p>
<p>Lang M., Binder M., Richter J., Schratz P., Pfisterer F., Coors S., Au Q., Casalicchio G., Kotthoff L., Bischl B. (2019). &ldquo;mlr3: A Modern Object-Oriented Machine Learning Framework in R.&rdquo; <em>Journal of Open Source Software</em>, <b>4</b>(44), 1903. doi: <a href="https://doi.org/10.21105/joss.01903">10.21105/joss.01903</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1)
n  &lt;- 100                        # number of observations
p  &lt;- 5                          # number of covariates
D  &lt;- rbinom(n, 1, 0.5)          # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)   # design matrix

## estimate propensity scores via mean(D)...
propensity_score(Z, D, estimator = "constant")

## ... and via SVM with cache size 40
if(require("e1071")){
  propensity_score(Z, D,
   estimator = 'mlr3::lrn("svm", cachesize = 40)')
}

</code></pre>

<hr>
<h2 id='proxy_BCA'>Baseline Conditional Average</h2><span id='topic+proxy_BCA'></span>

<h3>Description</h3>

<p>Proxy estimation of the Baseline Conditional Average (BCA), defined by <code class="reqn">E[Y | D=0, Z]</code>. Estimation is done on the auxiliary sample, but BCA predictions are made for all observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proxy_BCA(Z, D, Y, A_set, learner, min_variation = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proxy_BCA_+3A_z">Z</code></td>
<td>
<p>A numeric design matrix that holds the covariates in its columns.</p>
</td></tr>
<tr><td><code id="proxy_BCA_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="proxy_BCA_+3A_y">Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="proxy_BCA_+3A_a_set">A_set</code></td>
<td>
<p>A numerical vector of the indices of the observations in the auxiliary sample.</p>
</td></tr>
<tr><td><code id="proxy_BCA_+3A_learner">learner</code></td>
<td>
<p>A string specifying the machine learner for the estimation. Either <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or a custom learner specified with <code>mlr3</code> syntax. In the latter case, do <em>not</em> specify in the <code>mlr3</code> syntax specification if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 100)'</code> for a random forest learner with 100 trees. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td></tr>
<tr><td><code id="proxy_BCA_+3A_min_variation">min_variation</code></td>
<td>
<p>Specifies a threshold for the minimum variation of the predictions. If the variation of a BCA prediction falls below this threshold, random noise with distribution <code class="reqn">N(0, var(Y)/20)</code> is added to it. Default is <code>1e-05</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specifications <code>"lasso"</code>, <code>"random_forest"</code>, and <code>"tree"</code> in <code>learner</code> correspond to the following <code>mlr3</code> specifications (we omit the keywords <code>classif.</code> and <code>regr.</code>). <code>"lasso"</code> is a cross-validated Lasso estimator, which corresponds to <code>'mlr3::lrn("cv_glmnet", s = "lambda.min", alpha = 1)'</code>. <code>"random_forest"</code> is a random forest with 500 trees, which corresponds to <code>'mlr3::lrn("ranger", num.trees = 500)'</code>. <code>"tree"</code> is a tree learner, which corresponds to <code>'mlr3::lrn("rpart")'</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"proxy_BCA"</code>, consisting of the following components:
</p>

<dl>
<dt><code>estimates</code></dt><dd><p>A numeric vector of BCA estimates of each observation.</p>
</dd>
<dt><code>mlr3_objects</code></dt><dd><p><code>"mlr3"</code> objects used for estimation.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>
<p>Lang M., Binder M., Richter J., Schratz P., Pfisterer F., Coors S., Au Q., Casalicchio G., Kotthoff L., Bischl B. (2019). &ldquo;mlr3: A Modern Object-Oriented Machine Learning Framework in R.&rdquo; <em>Journal of Open Source Software</em>, <b>4</b>(44), 1903. doi: <a href="https://doi.org/10.21105/joss.01903">10.21105/joss.01903</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+proxy_CATE">proxy_CATE</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome
A_set &lt;- sample(1:n, size = n/2)           # auxiliary set

## BCA predictions via random forest
proxy_BCA(Z, D, Y, A_set, learner = "mlr3::lrn('ranger', num.trees = 10)")
}

</code></pre>

<hr>
<h2 id='proxy_CATE'>Conditional Average Treatment Effect</h2><span id='topic+proxy_CATE'></span>

<h3>Description</h3>

<p>Proxy estimation of the Conditional Average Treatment Effect (CATE), defined by <code class="reqn">E[Y | D=1, Z] - E[Y | D=0, Z]</code>. Estimation is done on the auxiliary sample, but CATE predictions are made for all observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proxy_CATE(Z, D, Y, A_set, learner, proxy_BCA = NULL, min_variation = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proxy_CATE_+3A_z">Z</code></td>
<td>
<p>A numeric design matrix that holds the covariates in its columns.</p>
</td></tr>
<tr><td><code id="proxy_CATE_+3A_d">D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td></tr>
<tr><td><code id="proxy_CATE_+3A_y">Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td></tr>
<tr><td><code id="proxy_CATE_+3A_a_set">A_set</code></td>
<td>
<p>A numerical vector of the indices of the observations in the auxiliary sample.</p>
</td></tr>
<tr><td><code id="proxy_CATE_+3A_learner">learner</code></td>
<td>
<p>A string specifying the machine learner for the estimation. Either <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or a custom learner specified with <code>mlr3</code> syntax. In the latter case, do <em>not</em> specify in the <code>mlr3</code> syntax specification if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 100)'</code> for a random forest learner with 100 trees. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td></tr>
<tr><td><code id="proxy_CATE_+3A_proxy_bca">proxy_BCA</code></td>
<td>
<p>A vector of proxy estimates of the baseline conditional average, BCA, <code class="reqn">E[Y | D=0, Z]</code>. If <code>NULL</code>, these will be estimated separately.</p>
</td></tr>
<tr><td><code id="proxy_CATE_+3A_min_variation">min_variation</code></td>
<td>
<p>Minimum variation of the predictions before random noise with distribution <code class="reqn">N(0, var(Y)/20)</code> is added. Default is <code>1e-05</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specifications <code>"lasso"</code>, <code>"random_forest"</code>, and <code>"tree"</code> in <code>learner</code> correspond to the following <code>mlr3</code> specifications (we omit the keywords <code>classif.</code> and <code>regr.</code>). <code>"lasso"</code> is a cross-validated Lasso estimator, which corresponds to <code>'mlr3::lrn("cv_glmnet", s = "lambda.min", alpha = 1)'</code>. <code>"random_forest"</code> is a random forest with 500 trees, which corresponds to <code>'mlr3::lrn("ranger", num.trees = 500)'</code>. <code>"tree"</code> is a tree learner, which corresponds to <code>'mlr3::lrn("rpart")'</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"proxy_CATE"</code>, consisting of the following components:
</p>

<dl>
<dt><code>estimates</code></dt><dd><p>A numeric vector of CATE estimates of each observation.</p>
</dd>
<dt><code>mlr3_objects</code></dt><dd><p><code>"mlr3"</code> objects used for estimation of <code class="reqn">E[Y | D=1, Z]</code> (<code>Y1_learner</code>) and <code class="reqn">E[Y | D=0, Z]</code> (<code>Y0_learner</code>). The latter is not available if <code>proxy_BCA = NULL</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>
<p>Lang M., Binder M., Richter J., Schratz P., Pfisterer F., Coors S., Au Q., Casalicchio G., Kotthoff L., Bischl B. (2019). &ldquo;mlr3: A Modern Object-Oriented Machine Learning Framework in R.&rdquo; <em>Journal of Open Source Software</em>, <b>4</b>(44), 1903. doi: <a href="https://doi.org/10.21105/joss.01903">10.21105/joss.01903</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+proxy_BCA">proxy_BCA</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome
A_set &lt;- sample(1:n, size = n/2)           # auxiliary set

## CATE predictions via random forest
proxy_CATE(Z, D, Y, A_set, learner = "mlr3::lrn('ranger', num.trees = 10)")
}

</code></pre>

<hr>
<h2 id='quantile_group'>Partition a vector into quantile groups</h2><span id='topic+quantile_group'></span>

<h3>Description</h3>

<p>Partitions a vector into quantile groups and returns a logical matrix indicating group membership.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_group(x, cutoffs = c(0.25, 0.5, 0.75))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quantile_group_+3A_x">x</code></td>
<td>
<p>A numeric vector to be partitioned.</p>
</td></tr>
<tr><td><code id="quantile_group_+3A_cutoffs">cutoffs</code></td>
<td>
<p>A numeric vector denoting the quantile cutoffs for the partition. Default are the quartiles: <code>c(0.25, 0.5, 0.75)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type <code>"quantile_group"</code>, which is a logical matrix indicating group membership.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- runif(100)
cutoffs &lt;- c(0.25, 0.5, 0.75)
quantile_group(x, cutoffs)

</code></pre>

<hr>
<h2 id='setup_diff'>Setup function for <code>diff</code> arguments</h2><span id='topic+setup_diff'></span>

<h3>Description</h3>

<p>This setup function controls how differences of generic target parameters are taken. Returns a list with two components, called <code>subtract_from</code> and <code>subtracted</code>. The first element (<code>subtract_from</code>) denotes what shall be the base group to subtract from in the generic targets of interest (GATES or CLAN); either <code>"most"</code> or <code>"least"</code>. The second element (<code>subtracted</code>) are the groups to be subtracted from <code>subtract_from</code>, which is a subset of <code class="reqn">{1,2,...,K}</code>, where <code class="reqn">K</code> equals the number of groups. The number of groups should be consistent with the number of groups induced by the argument <code>quantile_cutoffs</code>, which is the cardinality of <code>quantile_cutoffs</code>, plus one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_diff(subtract_from = "most", subtracted = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_diff_+3A_subtract_from">subtract_from</code></td>
<td>
<p>String indicating the base group to subtract from, either <code>"most"</code> (default) or <code>"least"</code>. The most affected group corresponds to the <code class="reqn">K</code>-th group in the paper (there are <code class="reqn">K</code> groups). The least affected group corresponds to the first group.</p>
</td></tr>
<tr><td><code id="setup_diff_+3A_subtracted">subtracted</code></td>
<td>
<p>Vector indicating the groups to be subtracted from the group specified in <code>subtract_from</code>. If there are <code class="reqn">K</code> groups, <code>subtracted</code> should be a subset of <code class="reqn">{1,2,...,K}</code>. Be careful to not specify a zero difference: If <code>subtract_from = "most"</code>, subtracting group K results in a zero difference. Same if <code>subtract_from = "least"</code> and we subtract group 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of this setup function is intended to be used as argument in the functions <code><a href="#topic+GenericML">GenericML</a>()</code> and <code><a href="#topic+GenericML_single">GenericML_single</a>()</code> (arguments <code>diff_GATES</code>, <code>diff_CLAN</code>), as well as <code><a href="#topic+GATES">GATES</a>()</code> and <code><a href="#topic+CLAN">CLAN</a>()</code> (argument <code>diff</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"setup_diff"</code>, consisting of the following components:
</p>

<dl>
<dt><code>subtract_from</code></dt><dd><p>A character equal to <code>"most"</code> or <code>"least"</code>.</p>
</dd>
<dt><code>subtracted</code></dt><dd><p>A numeric vector of group indices.</p>
</dd>
</dl>

<p>See the description above for details.
</p>


<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+GenericML_single">GenericML_single</a>()</code>,
<code><a href="#topic+CLAN">CLAN</a>()</code>,
<code><a href="#topic+GATES">GATES</a>()</code>,
<code><a href="#topic+setup_X1">setup_X1</a>()</code>,
<code><a href="#topic+setup_vcov">setup_vcov</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## specify quantile cutoffs (the 4 quartile groups here)
quantile_cutoffs &lt;- c(0.25, 0.5, 0.75)

## Use group difference GK-G1 as generic targets in GATES and CLAN
## Gx is the x-th group
setup_diff(subtract_from = "most", subtracted = 1)

## Use GK-G1, GK-G2, GK-G3 as differenced generic targets
setup_diff(subtract_from = "most", subtracted = c(1,2,3))

## Use G1-G2, G1-G3 as differenced generic targets
setup_diff(subtract_from = "least", subtracted = c(3,2))

</code></pre>

<hr>
<h2 id='setup_plot'>Set up information for a <code>GenericML()</code> plot</h2><span id='topic+setup_plot'></span>

<h3>Description</h3>

<p>Extract the relevant information for visualizing the point and interval estimates of the generic targets of interest. The generic targets of interest can be (subsets of) the parameters of the BLP, GATES, or CLAN analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_plot(
  x,
  type = "GATES",
  learner = "best",
  CLAN_variable = NULL,
  groups = "all"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_plot_+3A_x">x</code></td>
<td>
<p>An object of the class <code>"<a href="#topic+GenericML">GenericML</a>"</code>, as returned by the function <code><a href="#topic+GenericML">GenericML</a>()</code>.</p>
</td></tr>
<tr><td><code id="setup_plot_+3A_type">type</code></td>
<td>
<p>The analysis whose parameters shall be plotted. Either <code>"GATES"</code>, <code>"BLP"</code>, or <code>"CLAN"</code>. Default is <code>"GATES"</code>.</p>
</td></tr>
<tr><td><code id="setup_plot_+3A_learner">learner</code></td>
<td>
<p>The learner whose results are to be returned. Default is <code>"best"</code> for the best learner as measured by the <code class="reqn">\Lambda</code> parameters.</p>
</td></tr>
<tr><td><code id="setup_plot_+3A_clan_variable">CLAN_variable</code></td>
<td>
<p>Name of the CLAN variable to be plotted. Only applicable if <code>type = "CLAN"</code>.</p>
</td></tr>
<tr><td><code id="setup_plot_+3A_groups">groups</code></td>
<td>
<p>Character vector indicating the per-group parameter estimates that shall be plotted in GATES and CLAN analyses. Default is <code>"all"</code> for all parameters. If there are <code class="reqn">K</code> groups, this variable is a subset of <code>c("G1", "G2",...,"GK", "G1-G2", "G1-G2",..., "G1-GK", "GK-G1", "GK-G2",...)</code>, where Gk denotes the k-th group. Note that this set depends on the choices of the arguments <code>"diff_GATES"</code> and <code>"diff_CLAN"</code> of the <code>"<a href="#topic+GenericML">GenericML</a>"</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used internally by <code><a href="#topic+plot.GenericML">plot.GenericML</a>()</code>. It may also be useful for users who want to produce a similar plot, but who want more control over what information to display or how to display that information.
</p>


<h3>Value</h3>

<p>An object of class <code>"setup_plot"</code>, which is a list with the following elements.
</p>

<dl>
<dt><code>data_plot</code></dt><dd><p>A data frame containing point and interval estimates of the generic target specified in the argument <code>type</code>.</p>
</dd>
<dt><code>data_BLP</code></dt><dd><p>A data frame containing point and interval estimates of the BLP analysis.</p>
</dd>
<dt><code>confidence_level</code></dt><dd><p>The confidence level of the confidence intervals. The confidence level is equal to  <code>1 - 2 * significance_level</code>, which is the adjustment proposed in the paper.</p>
</dd></dl>



<h3>See Also</h3>

<p><code><a href="#topic+plot.GenericML">plot.GenericML</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("ranger") &amp;&amp; require("ggplot2")) {

## generate data
set.seed(1)
n  &lt;- 150                                  # number of observations
p  &lt;- 5                                    # number of covariates
D  &lt;- rbinom(n, 1, 0.5)                    # random treatment assignment
Z  &lt;- matrix(runif(n*p), n, p)             # design matrix
Y0 &lt;- as.numeric(Z %*% rexp(p) + rnorm(n)) # potential outcome without treatment
Y1 &lt;- 2 + Y0                               # potential outcome under treatment
Y  &lt;- ifelse(D == 1, Y1, Y0)               # observed outcome

## name the columns of Z
colnames(Z) &lt;- paste0("V", 1:p)

## specify learners
learners &lt;- c("random_forest")

## perform generic ML inference
# small number of splits to keep computation time low
x &lt;- GenericML(Z, D, Y, learners,
               num_splits = 2,
               parallel = FALSE)

## the plot we wish to replicate
plot(x = x, type = "GATES")

## get the data to plot the GATES estimates
data &lt;- setup_plot(x = x, type = "GATES")

## define variables to appease the R CMD check
group &lt;- estimate &lt;- ci_lower &lt;- ci_upper &lt;- NULL

## replicate the plot(x, type = "GATES")
# for simplicity, we skip aligning the colors
ggplot(mapping = aes(x = group,
                     y = estimate), data = data$data_plot) +
  geom_hline(aes(yintercept = 0),
             color = "black", linetype = "dotted") +
  geom_hline(aes(yintercept = data$data_BLP["beta.1", "estimate"],
                 color = "ATE"),
             linetype = "dashed") +
  geom_hline(aes(yintercept = data$data_BLP["beta.1", "ci_lower"],
                 color = paste0(100*data$confidence_level, "% CI (ATE)")),
             linetype = "dashed")  +
  geom_hline(yintercept = data$data_BLP["beta.1", "ci_upper"],
             linetype = "dashed", color = "red") +
  geom_point(aes(color = paste0("GATES with ",  100*data$confidence_level, "% CI")), size = 3) +
  geom_errorbar(mapping = aes(ymin = ci_lower,
                              ymax = ci_upper))
}

</code></pre>

<hr>
<h2 id='setup_stratify'>Setup function for stratified sampling</h2><span id='topic+setup_stratify'></span>

<h3>Description</h3>

<p>This function controls whether or not stratified sample splitting shall be performed. If no stratified sampling shall be performed, do not pass any arguments to this function (this is the default). If stratified sampling shall be performed, use this function to pass arguments to <code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code> in the package <a href="https://CRAN.R-project.org/package=splitstackshape">&quot;splitstackshape&quot;</a>. In this case, the specification for <code>prop_aux</code> in <code><a href="#topic+GenericML">GenericML</a>()</code> does not have an effect because the number of samples in the auxiliary set is specified with the <code>size</code> argument in <code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_stratify(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_stratify_+3A_...">...</code></td>
<td>
<p>Named objects that shall be used as arguments in <code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code>. If empty (default), ordinary random sampling will be performed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of this setup function is intended to be used as argument <code>stratify</code> in the function <code><a href="#topic+GenericML">GenericML</a>()</code>. If arguments are passed to <code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code> via this function, make sure to  pass the necessary objects that <code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code> in the <a href="https://CRAN.R-project.org/package=splitstackshape">&quot;splitstackshape&quot;</a> package requires. The necessary objects are called <code>indt</code>, <code>group</code>, and <code>size</code> (see the documentation of  <code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code> for details). If either of these objects is missing, an error is thrown.
</p>


<h3>Value</h3>

<p>A list of named objects (possibly empty) specifying the stratified sampling strategy. If empty, no stratified sampling will be performed and instead ordinary random sampling will be performed.
</p>


<h3>See Also</h3>

<p><code><a href="splitstackshape.html#topic+stratified">stratified</a>()</code>,
<code><a href="#topic+GenericML">GenericML</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## sample data of group membership (with two groups)
set.seed(1)
n &lt;- 500
groups &lt;- data.frame(group1 = rbinom(n, 1, 0.2),
                     group2 = rbinom(n, 1, 0.3))

## suppose we want both groups to be present in a strata...
group &lt;- c("group1", "group2")

## ... and that the size of the strata equals half of the observations per group
size &lt;- 0.5

## obtain a list of arguments that will be passed to splitstackshape::stratified()
setup_stratify(indt = groups, group = group, size = size)

## if no stratified sampling shall be used, do not pass anything
setup_stratify()

</code></pre>

<hr>
<h2 id='setup_vcov'>Setup function for <code>vcov_control</code> arguments</h2><span id='topic+setup_vcov'></span>

<h3>Description</h3>

<p>Returns a list with two elements called <code>estimator</code> and <code>arguments</code>. The element <code>estimator</code> is a string specifying the covariance matrix estimator to be used in the linear regression regression of interest and needs to be a covariance estimator function in the <a href="https://CRAN.R-project.org/package=sandwich">&quot;sandwich&quot;</a> package. The second element, <code>arguments</code>, is a list of arguments that shall be passed to the function specified in the first element, <code>estimator</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_vcov(estimator = "vcovHC", arguments = list(type = "const"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_vcov_+3A_estimator">estimator</code></td>
<td>
<p>Character specifying a covariance matrix estimator in the <a href="https://CRAN.R-project.org/package=sandwich">&quot;sandwich&quot;</a> package. Default is <code>"vcovHC"</code>. Supported estimators are <code>"vcovBS"</code>, <code>"vcovCL"</code>, <code>"vcovHAC"</code>, and <code>"vcovHC"</code>.</p>
</td></tr>
<tr><td><code id="setup_vcov_+3A_arguments">arguments</code></td>
<td>
<p>A list of arguments that are to be passed to the function in the <code>"sandwich"</code> package that is specified in <code>estimator</code>. Default is <code>list(type = "const")</code>, which specifies the homoskedastic ordinary least squares covariance matrix estimator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of this setup function is intended to be used as argument in the functions <code><a href="#topic+GenericML">GenericML</a>()</code> and <code><a href="#topic+GenericML_single">GenericML_single</a>()</code> (arguments <code>vcov_BLP</code>, <code>vcov_GATES</code>), as well as <code><a href="#topic+BLP">BLP</a>()</code> and <code><a href="#topic+GATES">GATES</a>()</code> (argument <code>vcov_control</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"setup_vcov"</code>, consisting of the following components:
</p>

<dl>
<dt><code>estimator</code></dt><dd><p>A character equal to covariance estimation function names in the <a href="https://CRAN.R-project.org/package=sandwich">&quot;sandwich&quot;</a> package.</p>
</dd>
<dt><code>arguments</code></dt><dd><p>A list of arguments that shall be passed to the function specified in the <code>estimator</code> argument.</p>
</dd>
</dl>

<p>See the description above for details.
</p>


<h3>References</h3>

<p>Zeileis A. (2004). &ldquo;Econometric Computing with HC and HAC Covariance Matrix Estimators.&rdquo; <em>Journal of Statistical Software</em>, <b>11</b>(10), 1&ndash;17. doi: <a href="https://doi.org/10.18637/jss.v011.i10">10.18637/jss.v011.i10</a>
</p>
<p>Zeileis A. (2006). &ldquo;Object-Oriented Computation of Sandwich Estimators.&rdquo; <em>Journal of Statistical Software</em>, <b>16</b>(9), 1&ndash;16. doi: <a href="https://doi.org/10.18637/jss.v016.i09">10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+GenericML_single">GenericML_single</a>()</code>,
<code><a href="#topic+BLP">BLP</a>()</code>,
<code><a href="#topic+GATES">GATES</a>()</code>,
<code><a href="#topic+setup_X1">setup_X1</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use standard homoskedastic OLS covariance matrix estimate
setup_vcov(estimator = "vcovHC", arguments = list(type = "const"))

# use White's heteroskedasticity-robust estimator
setup_vcov(estimator = "vcovHC", arguments = list(type = "HC0"))

if (require("sandwich")){

# use HAC-robust estimator with prewhitening and Andrews' (Econometrica, 1991) weights
# since weightsAndrews() is a function in 'sandwich', require this package
setup_vcov(estimator = "vcovHAC", arguments = list(prewhite = TRUE, weights = weightsAndrews))

}

</code></pre>

<hr>
<h2 id='setup_X1'>Setup function controlling the matrix <code class="reqn">X_1</code> in the BLP or GATES regression</h2><span id='topic+setup_X1'></span>

<h3>Description</h3>

<p>Returns a list with three elements. The first element of the list, <code>funs_Z</code>, controls which functions of matrix <code>Z</code> are used as regressors in <code class="reqn">X_1</code>. The second element, <code>covariates</code>, is an optional matrix of custom covariates that shall be included in <code class="reqn">X_1</code>. The third element, <code>fixed_effects</code>, controls the inclusion of fixed effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_X1(funs_Z = c("B"), covariates = NULL, fixed_effects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_X1_+3A_funs_z">funs_Z</code></td>
<td>
<p>Character vector controlling the functions of <code>Z</code> to be included in <code class="reqn">X_1</code>. Subset of <code>c("S", "B", "p")</code>, where <code>"p"</code> corresponds to the propensity scores, <code>"B"</code> to the proxy baseline estimates, and <code>"S"</code> to the proxy CATE estimates. Default is <code>"B"</code>.</p>
</td></tr>
<tr><td><code id="setup_X1_+3A_covariates">covariates</code></td>
<td>
<p>Optional numeric matrix containing additional covariates to be included in <code class="reqn">X_1</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="setup_X1_+3A_fixed_effects">fixed_effects</code></td>
<td>
<p>Numeric vector of integers that indicates cluster membership of the observations: For each cluster, a fixed effect will be added. Default is <code>NULL</code> for no fixed effects.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of this setup function is intended to be used as argument in the functions <code><a href="#topic+GenericML">GenericML</a>()</code> and <code><a href="#topic+GenericML_single">GenericML_single</a>()</code> (arguments <code>X1_BLP</code>, <code>X1_GATES</code>), as well as <code><a href="#topic+BLP">BLP</a>()</code> and <code><a href="#topic+GATES">GATES</a>()</code> (argument <code>X1_control</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"setup_X1"</code>, consisting of the following components:
</p>

<dl>
<dt><code>funs_Z</code></dt><dd><p>A character vector, being a subset of <code>c("S", "B", "p")</code>.</p>
</dd>
<dt><code>covariates</code></dt><dd><p>Either <code>NULL</code> or a numeric matrix.</p>
</dd>
<dt><code>fixed_effects</code></dt><dd><p>Either <code>NULL</code> or an integer vector indicating cluster membership.</p>
</dd>
</dl>

<p>See the description above for details.
</p>


<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). &ldquo;Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.&rdquo; <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GenericML">GenericML</a>()</code>,
<code><a href="#topic+GenericML_single">GenericML_single</a>()</code>,
<code><a href="#topic+BLP">BLP</a>()</code>,
<code><a href="#topic+GATES">GATES</a>()</code>,
<code><a href="#topic+setup_vcov">setup_vcov</a>()</code>,
<code><a href="#topic+setup_diff">setup_diff</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100 # sample size
p &lt;- 5   # number of covariates
covariates &lt;- matrix(runif(n*p), n, p) # sample matrix of covariates

# let there be three clusters; assign membership randomly
fixed_effects &lt;- sample(c(1,2,3), size = n, replace = TRUE)

# use BCA estimates in matrix X1
setup_X1(funs_Z = "B", covariates = NULL, fixed_effects = NULL)

# use BCA and propensity score estimates in matrix X1
# uses uniform covariates and fixed effects
setup_X1(funs_Z = c("B", "p"), covariates = covariates, fixed_effects = NULL)

</code></pre>

<hr>
<h2 id='TrueIfUnix'>Check if user's OS is a Unix system</h2><span id='topic+TrueIfUnix'></span>

<h3>Description</h3>

<p>Check if user's OS is a Unix system
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TrueIfUnix()
</code></pre>


<h3>Value</h3>

<p>A Boolean that is <code>TRUE</code> if the user's operating system is a Unix system and <code>FALSE</code> otherwise.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
