<!DOCTYPE html><html><head><title>Help for package scorecardModelUtils</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scorecardModelUtils}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cat_new_class'><p>Clubbing class of categorical variables with low population percentage with another class of similar event rate</p></a></li>
<li><a href='#categorical_iv'><p>IV table for individual categorical variable</p></a></li>
<li><a href='#club_cat_class'><p>Clubbing class of a categorical variable with low population percentage with another class of similar event rate</p></a></li>
<li><a href='#cv_filter'><p>Variable reduction based on Cramer's V filter</p></a></li>
<li><a href='#cv_table'><p>Pairwise Cramer's V among a list of categorical variables</p></a></li>
<li><a href='#cv_test'><p>Cramer's V value between two categorical variables</p></a></li>
<li><a href='#dtree_split_val'><p>Getting the split value for terminal nodes from decision tree</p></a></li>
<li><a href='#dtree_trend_iv'><p>Recursive Decision Tree partitioning with monotonic event rate along with IV table for individual numerical variable</p></a></li>
<li><a href='#fn_conf_mat'><p>Creates confusion matrix and its related measures</p></a></li>
<li><a href='#fn_cross_index'><p>Creates random index for k-fold cross validation</p></a></li>
<li><a href='#fn_error'><p>Computes error measures between observed and predicted values</p></a></li>
<li><a href='#fn_mode'><p>Calculating mode value of a vector</p></a></li>
<li><a href='#fn_target'><p>Redefines target value</p></a></li>
<li><a href='#gini_table'><p>Performance measure table with Gini coefficient, KS-statistics and Gini lift curve</p></a></li>
<li><a href='#gradient_boosting_parameters'><p>Hyperparameter optimisation or parameter tuning for Gradient Boosting Regression Modelling by grid search</p></a></li>
<li><a href='#iv_filter'><p>Variable reduction based on Information Value filter</p></a></li>
<li><a href='#iv_table'><p>WOE and IV table for list of numerical and categorical variables</p></a></li>
<li><a href='#missing_val'><p>Missing value imputation</p></a></li>
<li><a href='#num_to_cat'><p>Binning numerical variables based on cuts from IV table</p></a></li>
<li><a href='#others_class'><p>Clubbing of classes of categorical variable with low population percentage into one class</p></a></li>
<li><a href='#random_forest_parameters'><p>Hyperparameter optimisation or parameter tuning for Random Forest by grid search</p></a></li>
<li><a href='#sampling'><p>Random sampling of data into train and test</p></a></li>
<li><a href='#scalling'><p>Converting coefficients of logistic regression into scores for scorecard building</p></a></li>
<li><a href='#scoring'><p>Scoring a dataset with class based on a scalling logic to arrive at final score</p></a></li>
<li><a href='#support_vector_parameters'><p>Hyperparameter optimisation or parameter tuning for Suppert Vector Machine by grid search</p></a></li>
<li><a href='#univariate'><p>Univariate analysis of variables</p></a></li>
<li><a href='#vif_filter'><p>Removing multicollinearity from a model using vif test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Credit Scorecard Modelling Utils</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides infrastructure functionalities such as missing value treatment, information value calculation, GINI calculation etc. which are used for developing a traditional credit scorecard as well as a machine learning based model. The functionalities defined are standard steps for any credit underwriting scorecard development, extensively used in financial domain.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>car, e1071, gbm, partykit, randomForest, reshape2, sqldf,
stringr, stats, ggplot2, utils</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-04-14 16:04:05 UTC; ARYASOURYA</td>
</tr>
<tr>
<td>Author:</td>
<td>Arya Poddar [aut, cre],
  Aiana Goyal [ctb],
  Kanishk Dogar [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-04-14 20:53:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='cat_new_class'>Clubbing class of categorical variables with low population percentage with another class of similar event rate</h2><span id='topic+cat_new_class'></span>

<h3>Description</h3>

<p>The function groups classes of categorical variables, which have population percentage less than a threshold, with another class of similar event rate. If a class of exactly same event rate is not available, it is clubbed with the one having a higher event rate closest to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat_new_class(base, target, cat_var_name, threshold, event = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cat_new_class_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="cat_new_class_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="cat_new_class_+3A_cat_var_name">cat_var_name</code></td>
<td>
<p>column name or array of column names of categorical variable on which the operation is to be done, to be passed as string</p>
</td></tr>
<tr><td><code id="cat_new_class_+3A_threshold">threshold</code></td>
<td>
<p>threshold population percentage below which the class will be considered to be be clubbed with another class, to be provided as decimal/fraction</p>
</td></tr>
<tr><td><code id="cat_new_class_+3A_event">event</code></td>
<td>
<p>(optional) the event class, to be passed as 0 or 1 (default is 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an object of class &quot;cat_new_class&quot; which is a list containing the following components:
</p>
<table>
<tr><td><code>base_new</code></td>
<td>
<p>a dataframe after clubbing low percentage classes with another class of similar or closest but higher event rate</p>
</td></tr>
<tr><td><code>cat_class_new</code></td>
<td>
<p>a dataframe with mapping between original classes and new clubbed classes (if any)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Kanishk Dogar &lt;Kanishkd4@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris[1:110,]
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data_newclass &lt;- cat_new_class(base = data,target = "Y",cat_var_name = "Species",threshold = 0.1)
</code></pre>

<hr>
<h2 id='categorical_iv'>IV table for individual categorical variable</h2><span id='topic+categorical_iv'></span>

<h3>Description</h3>

<p>The function takes base data, target and the categorical variable for which IV is to be calculated. It returns a dataframe with the WOE and IV value of the variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorical_iv(base, target, variable, event = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categorical_iv_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="categorical_iv_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="categorical_iv_+3A_variable">variable</code></td>
<td>
<p>categorical variable name for which IV is to be calculated, to be passed as string</p>
</td></tr>
<tr><td><code id="categorical_iv_+3A_event">event</code></td>
<td>
<p>(optional) the event class, to be passed as 0 or 1 (default is 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Aiana Goyal &lt;aianagoel002@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
cat_iv &lt;- categorical_iv(base = data,target = "Y",variable = "Species",event = 1)
</code></pre>

<hr>
<h2 id='club_cat_class'>Clubbing class of a categorical variable with low population percentage with another class of similar event rate</h2><span id='topic+club_cat_class'></span>

<h3>Description</h3>

<p>The function groups classes of categorical variable, which have population percentage less than a threshold, with another class of similar event rate. If a class of exactly same event rate is not available, it is clubbed with the one having a higher event rate closest to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>club_cat_class(base, target, variable, threshold, event = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="club_cat_class_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="club_cat_class_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="club_cat_class_+3A_variable">variable</code></td>
<td>
<p>column name of categorical variable on which the operation is to be done, to be passed as string</p>
</td></tr>
<tr><td><code id="club_cat_class_+3A_threshold">threshold</code></td>
<td>
<p>threshold population percentage below which the class will be considered to be be clubbed with another class, to be provided as decimal/fraction</p>
</td></tr>
<tr><td><code id="club_cat_class_+3A_event">event</code></td>
<td>
<p>(optional) the event class, to be passed as 0 or 1 (default is 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe after clubbing low percentage classes with another class of similar or closest but higher event rate.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Kanishk Dogar &lt;kanishkd4@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris[1:110,]
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data_clubclass &lt;- club_cat_class(base = data,target = "Y",variable = "Species",threshold = 0.2)
</code></pre>

<hr>
<h2 id='cv_filter'>Variable reduction based on Cramer's V filter</h2><span id='topic+cv_filter'></span>

<h3>Description</h3>

<p>The function returns a list of variables that can be dropped because of high correlation with another variable, based on Cramer's V and IV. If V1 and V2 have a Cramer's V value more than a user defined threshold, the variable with lower IV will be recommended to be dropped by this function. The variable which got dropped wont be considered for dropping any more variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_filter(cv_table, iv_table, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_filter_+3A_cv_table">cv_table</code></td>
<td>
<p>dataframe of class cv_table with three columns - var_1, var_2, cv_value</p>
</td></tr>
<tr><td><code id="cv_filter_+3A_iv_table">iv_table</code></td>
<td>
<p>dataframe of class iv_table with two columns - Variable_name, iv</p>
</td></tr>
<tr><td><code id="cv_filter_+3A_threshold">threshold</code></td>
<td>
<p>Cramers' V value above which one of the variable will be recommended to be dropped</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;cv_filter&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>retain_var_list</code></td>
<td>
<p>list of variables remaining post CV filter</p>
</td></tr>
<tr><td><code>dropped_var_list</code></td>
<td>
<p>list of variables that can be dropped based on CV filter</p>
</td></tr>
<tr><td><code>dropped_var_tab</code></td>
<td>
<p>CV correlation value for dropped variables as a dataframe</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>threshold CV value used as input parameter</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
cv_tab_list &lt;- cv_table(data, c("Species", "Sepal.Length"))
cv_tab &lt;- cv_tab_list$cv_val_tab
x &lt;- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
iv_table_list &lt;- iv_table(base = data,target = "Y",num_var_name = x,cat_var_name = "Species")
iv_tab &lt;- iv_table_list$iv_table
cv_filter_list &lt;- cv_filter(cv_table = cv_tab,iv_table = iv_tab,threshold = 0.5)
cv_filter_list$retain_var_list
cv_filter_list$dropped_var_list
cv_filter_list$dropped_var_tab
cv_filter_list$threshold
</code></pre>

<hr>
<h2 id='cv_table'>Pairwise Cramer's V among a list of categorical variables</h2><span id='topic+cv_table'></span>

<h3>Description</h3>

<p>The function gives a dataframe with pairwise Cramer's V value between all possible combination of categorical variables from the list of variables provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_table(base, column_name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_table_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="cv_table_+3A_column_name">column_name</code></td>
<td>
<p>column name or array of column names for which Cramer's V is to be calculated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;cv_table&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>cv_val_tab</code></td>
<td>
<p>pairwise Cramer's V value as a dataframe</p>
</td></tr>
<tr><td><code>single_class_var_index</code></td>
<td>
<p>array of column index of variables with only one class</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Sepal.Length &lt;- as.character(floor(data$Sepal.Length))
cv_tab_list &lt;- cv_table(data, c("Species", "Sepal.Length"))
cv_tab_list$cv_val_tab
cv_tab_list$single_class_var_index
</code></pre>

<hr>
<h2 id='cv_test'>Cramer's V value between two categorical variables</h2><span id='topic+cv_test'></span>

<h3>Description</h3>

<p>The function gives the pairwise Cramer's V value between two input categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_test(base, var_1, var_2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_test_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="cv_test_+3A_var_1">var_1</code></td>
<td>
<p>categorical variable name, to be passed as string</p>
</td></tr>
<tr><td><code id="cv_test_+3A_var_2">var_2</code></td>
<td>
<p>categorical variable name, to be passed as string</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe with pairwise CV value.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Sepal.Length &lt;- as.character(floor(data$Sepal.Length))
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
cv_result &lt;- cv_test(base = data,var_1 = "Species",var_2 = "Sepal.Length")
</code></pre>

<hr>
<h2 id='dtree_split_val'>Getting the split value for terminal nodes from decision tree</h2><span id='topic+dtree_split_val'></span>

<h3>Description</h3>

<p>The function takes a ctree type model, with only one numerical variable, as argument input and gives a dataframe with the minimum and maximum value of each node. The intervals are open ended at lower limit and closed at upper limit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtree_split_val(desc_model, variable)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dtree_split_val_+3A_desc_model">desc_model</code></td>
<td>
<p>ctree class model with one variable</p>
</td></tr>
<tr><td><code id="dtree_split_val_+3A_variable">variable</code></td>
<td>
<p>numerical variable name which on which decision tree was run, to be passed as string</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe giving the lower and upper bound of split values of each node.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Y &lt;- ifelse(data$Species=="setosa",1,0)
</code></pre>

<hr>
<h2 id='dtree_trend_iv'>Recursive Decision Tree partitioning with monotonic event rate along with IV table for individual numerical variable</h2><span id='topic+dtree_trend_iv'></span>

<h3>Description</h3>

<p>The function takes base data, target and the numerical variable which is to be binned. It returns the optimal cuts based on recursive partitioning decision tree such that the trend of event rate holds good ie. it is strictly monotonically increasing or decreasing. If missing values are imputed by any extreme value, the same can be passed as an argument, and it will be shown as a different category. The output is a dataframe with the WOE and IV value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtree_trend_iv(base, target, variable, num_missing = -99999,
  mincriterion = 0.1, event = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dtree_trend_iv_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="dtree_trend_iv_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="dtree_trend_iv_+3A_variable">variable</code></td>
<td>
<p>numerical variable name which is to be binned into categorical buckets, to be passed as string</p>
</td></tr>
<tr><td><code id="dtree_trend_iv_+3A_num_missing">num_missing</code></td>
<td>
<p>(optional) imputed missing value for numerical variable or an array of values which are to be kept as different bucket in binning step (default value is -99999)</p>
</td></tr>
<tr><td><code id="dtree_trend_iv_+3A_mincriterion">mincriterion</code></td>
<td>
<p>(optional) the value of the test statistic or (1 - p-value) that must be exceeded in order to implement a split (default value is 0.1)</p>
</td></tr>
<tr><td><code id="dtree_trend_iv_+3A_event">event</code></td>
<td>
<p>(optional) the event class, to be passed as 0 or 1 (default is 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe with count and iv.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Aiana Goyal &lt;aianagoel002@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Y &lt;- ifelse(data$Species=="setosa",1,0)
dtree_trend_tab &lt;- dtree_trend_iv(base = data,target = "Y",variable = "Sepal.Length",event = 1)
</code></pre>

<hr>
<h2 id='fn_conf_mat'>Creates confusion matrix and its related measures</h2><span id='topic+fn_conf_mat'></span>

<h3>Description</h3>

<p>The function takes the base dataframe with observed/actual and predicted columns. The actual/predicted class preferably should be binary and if not, it will be considered as event vs rest. It computes the performance measures like accuracy, precision, recall, sensitivity, specificity and f1 score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fn_conf_mat(base, observed_col, predicted_col, event)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fn_conf_mat_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="fn_conf_mat_+3A_observed_col">observed_col</code></td>
<td>
<p>column / field name of the observed event</p>
</td></tr>
<tr><td><code id="fn_conf_mat_+3A_predicted_col">predicted_col</code></td>
<td>
<p>column / field name of the predicted event</p>
</td></tr>
<tr><td><code id="fn_conf_mat_+3A_event">event</code></td>
<td>
<p>the event class, to be passed as string</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;fn_conf_mat&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>confusion_mat</code></td>
<td>
<p>confusion matrix as a table</p>
</td></tr>
<tr><td><code>accuracy</code></td>
<td>
<p>accuracy measure</p>
</td></tr>
<tr><td><code>precision</code></td>
<td>
<p>precision measure</p>
</td></tr>
<tr><td><code>recall</code></td>
<td>
<p>recall measure</p>
</td></tr>
<tr><td><code>sensitivity</code></td>
<td>
<p>sensitivity measure</p>
</td></tr>
<tr><td><code>specificity</code></td>
<td>
<p>specificity measure</p>
</td></tr>
<tr><td><code>f1_score</code></td>
<td>
<p>F1 score</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data$Y_pred &lt;- sample(0:1,size=nrow(data),replace=TRUE)
fn_conf_mat_list &lt;- fn_conf_mat(base = data,observed_col = "Y",predicted_col = "Y_pred",event = 1)
fn_conf_mat_list$confusion_mat
fn_conf_mat_list$accuracy
fn_conf_mat_list$precision
fn_conf_mat_list$recall
fn_conf_mat_list$sensitivity
fn_conf_mat_list$specificity
fn_conf_mat_list$f1_score
</code></pre>

<hr>
<h2 id='fn_cross_index'>Creates random index for k-fold cross validation</h2><span id='topic+fn_cross_index'></span>

<h3>Description</h3>

<p>The function base and returns a list of length k, to be used for k-fold cross validation sampling. Each element of the returned list is an array of random index for sampling for k-fold cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fn_cross_index(base, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fn_cross_index_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="fn_cross_index_+3A_k">k</code></td>
<td>
<p>number of cross validation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function a list of length k, each holding an array of index/row number for sampling the base.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data$Y_pred &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data_k_list &lt;- fn_cross_index(base = data,k = 5)
data_k_list$index1
data_k_list$index2
data_k_list$index3
data_k_list$index4
data_k_list$index5
</code></pre>

<hr>
<h2 id='fn_error'>Computes error measures between observed and predicted values</h2><span id='topic+fn_error'></span>

<h3>Description</h3>

<p>The function takes the input dataframe with observed and predicted columns and computes mean absolute error, mean squared error and root mean squared error terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fn_error(base, observed_col, predicted_col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fn_error_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="fn_error_+3A_observed_col">observed_col</code></td>
<td>
<p>column / field name of the observed event</p>
</td></tr>
<tr><td><code id="fn_error_+3A_predicted_col">predicted_col</code></td>
<td>
<p>column / field name of the predicted event</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;fn_error&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>mean_abs_error</code></td>
<td>
<p>mean absolute error between observed and predicted value</p>
</td></tr>
<tr><td><code>mean_sq_error</code></td>
<td>
<p>mean squared error between observed and predicted value</p>
</td></tr>
<tr><td><code>root_mean_sq_error</code></td>
<td>
<p>root mean squared error between observed and predicted value</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data$Y_pred &lt;- sample(0:1,size=nrow(data),replace=TRUE)
fn_error_list &lt;- fn_error(base = data,observed_col = "Y",predicted_col = "Y_pred")
fn_error_list$mean_abs_error
fn_error_list$mean_sq_error
fn_error_list$root_mean_sq_error
</code></pre>

<hr>
<h2 id='fn_mode'>Calculating mode value of a vector</h2><span id='topic+fn_mode'></span>

<h3>Description</h3>

<p>The function returns the mode of a vector. The vector can be of any datatype ie. numerical or categorical.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fn_mode(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fn_mode_+3A_x">x</code></td>
<td>
<p>a vector of string or number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the mode value of the input vector.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fn_mode(c(1,2,3,1,4,1,7))
</code></pre>

<hr>
<h2 id='fn_target'>Redefines target value</h2><span id='topic+fn_target'></span>

<h3>Description</h3>

<p>The function redefines the &quot;binary&quot; target variable to be used for modelling. It takes the variable or field name of the target and the event class. It changes the target field name to &quot;Target&quot;, changes the events into 1 and non-events as 0 and places the target column at the end of the dataframe before returning it as output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fn_target(base, target, event)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fn_target_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="fn_target_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable, to be passed as string</p>
</td></tr>
<tr><td><code id="fn_target_+3A_event">event</code></td>
<td>
<p>the event class, to be passed as string</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe after changing the target classes to 0 or 1.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)

data2 &lt;- fn_target(base = data,target = "Y",event = 1)
</code></pre>

<hr>
<h2 id='gini_table'>Performance measure table with Gini coefficient, KS-statistics and Gini lift curve</h2><span id='topic+gini_table'></span>

<h3>Description</h3>

<p>The function takes a dataframe along with a model or the name of a column with predicted value. If a model (only lm or glm works is guaranted to work perfectly) is provided as argument, the response on the data is predicted. Otherwise, if the data already contains a predicted column, it can be referred as an argument. The predicted column, thus obtained, is classified into bands to get the Gini coefficient, Kolmogorov-Smirnov statistics and Gini lift curve. The number of bands required can be passed as argument, with default value as 10 ie. decile binning is done. Otherwise, the cutpoints for converting the predicted value into bands can also be specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gini_table(base, target, col_pred = F, model = F, brk = F,
  quantile_pt = 10, event_rate_direction = "decreasing")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gini_table_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="gini_table_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="gini_table_+3A_col_pred">col_pred</code></td>
<td>
<p>(optional) column name which contains the predicted value, not required if &quot;model&quot;=TRUE (default value is FALSE)</p>
</td></tr>
<tr><td><code id="gini_table_+3A_model">model</code></td>
<td>
<p>(optional) object of type lm or glm model, required only if &quot;col_pred&quot;=FALSE (default value is FALSE)</p>
</td></tr>
<tr><td><code id="gini_table_+3A_brk">brk</code></td>
<td>
<p>(optional) array of break points of predicted value (default value is FALSE)</p>
</td></tr>
<tr><td><code id="gini_table_+3A_quantile_pt">quantile_pt</code></td>
<td>
<p>(optional) number of quantiles to divide the predicted value range (default value is 10)</p>
</td></tr>
<tr><td><code id="gini_table_+3A_event_rate_direction">event_rate_direction</code></td>
<td>
<p>(optional) directionality of event rate with increasing value of predicted column, to be chosen among &quot;increasing&quot; or &quot;decreasing&quot; (default value is decreasing)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;gini_table&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>prediction</code></td>
<td>
<p>base with the predicted value as a dataframe</p>
</td></tr>
<tr><td><code>gini_tab</code></td>
<td>
<p>gini table as a dataframe</p>
</td></tr>
<tr><td><code>gini_value</code></td>
<td>
<p>gini coefficient value</p>
</td></tr>
<tr><td><code>gini_plot</code></td>
<td>
<p>gini curve plot</p>
</td></tr>
<tr><td><code>ks_value</code></td>
<td>
<p>Kolmogorov-Smirnov statistic</p>
</td></tr>
<tr><td><code>breaks</code></td>
<td>
<p>break points</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Aiana Goyal &lt;aianagoel002@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y_pred &lt;- sample(300:900,size=nrow(data),replace=TRUE)
gini_tab_list &lt;- gini_table(base = data,target = "Y",col_pred = "Y_pred",quantile_pt = 10)
gini_tab_list$prediction
gini_tab_list$gini_tab
gini_tab_list$gini_value
gini_tab_list$gini_plot
gini_tab_list$ks_value
gini_tab_list$breaks
</code></pre>

<hr>
<h2 id='gradient_boosting_parameters'>Hyperparameter optimisation or parameter tuning for Gradient Boosting Regression Modelling by grid search</h2><span id='topic+gradient_boosting_parameters'></span>

<h3>Description</h3>

<p>The function runs a grid search with k-fold cross validation to arrive at best parameter decided by some performance measure. The parameters that can be tuned using this function for gradient boosting regression modelling algorithm are - ntree, depth, shrinkage, min_obs and bag_fraction. The objective function to be minimised is the error (mean absolute error / mean squared error / root mean squared error). For the grid search, the possible values of each tuning parameter needs to be passed as an array into the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gradient_boosting_parameters(base, target, ntree, depth, shrinkage, min_obs,
  bag_fraction, error = "rmse", cv = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gradient_boosting_parameters_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to be fitted</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_depth">depth</code></td>
<td>
<p>maximum depth of variable interactions</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_shrinkage">shrinkage</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_min_obs">min_obs</code></td>
<td>
<p>minimum size of terminal nodes</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_bag_fraction">bag_fraction</code></td>
<td>
<p>fraction of the training set observations randomly selected for next tree</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_error">error</code></td>
<td>
<p>(optional) error measure as objective function to be minimised, to be chosen among &quot;mae&quot;, &quot;mse&quot; and &quot;rmse&quot; (default value is &quot;rmse&quot;)</p>
</td></tr>
<tr><td><code id="gradient_boosting_parameters_+3A_cv">cv</code></td>
<td>
<p>(optional) k vakue for k-fold cross validation to be performed (default value is 1 ie. without cross validation)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;gradient_boosting_parameters&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>error_tab_detailed</code></td>
<td>
<p>error summary for each cross validation sample of the parameter combinations iterated during grid search as a dataframe</p>
</td></tr>
<tr><td><code>error_tab_summary</code></td>
<td>
<p>error summary for each combination of parameters as a dataframe</p>
</td></tr>
<tr><td><code>best_ntree</code></td>
<td>
<p>ntree parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_depth</code></td>
<td>
<p>depth parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_shrinkage</code></td>
<td>
<p>shrinkage parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_min_obs</code></td>
<td>
<p>cost min_obs of the optimal solution</p>
</td></tr>
<tr><td><code>best_bag_fraction</code></td>
<td>
<p>bag_fraction parameter of the optimal solution</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>
<p>runtime of the entire process</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
gbm_params_list &lt;- gradient_boosting_parameters(base = data,target = "Y",ntree = 2,depth = 2,
                   shrinkage = 0.1,min_obs = 0.1,bag_fraction = 0.7)
gbm_params_list$error_tab_detailed
gbm_params_list$error_tab_summary
gbm_params_list$best_ntree
gbm_params_list$best_depth
gbm_params_list$best_shrinkage
gbm_params_list$best_min_obs
gbm_params_list$best_bag_fraction
gbm_params_list$runtime
</code></pre>

<hr>
<h2 id='iv_filter'>Variable reduction based on Information Value filter</h2><span id='topic+iv_filter'></span>

<h3>Description</h3>

<p>The function returns a list of variables that can be dropped because of low discriminatory power, based on Information Value. If IV for a variable is less than a user defined threshold, the variable will be recommended to be dropped by this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iv_filter(base, iv_table, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iv_filter_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="iv_filter_+3A_iv_table">iv_table</code></td>
<td>
<p>dataframe of class iv_table with two columns - Variable_name, iv</p>
</td></tr>
<tr><td><code id="iv_filter_+3A_threshold">threshold</code></td>
<td>
<p>threshold IV value below which the variable will be recommended to be dropped</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;iv_filter&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>retain_var_tab</code></td>
<td>
<p>variables remaining post IV filter as a dataframe</p>
</td></tr>
<tr><td><code>retain_var_name</code></td>
<td>
<p>array of column names of variables to be retained</p>
</td></tr>
<tr><td><code>dropped_var_tab</code></td>
<td>
<p>variables that can be dropped based on IV filter as a dataframe</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>threshold IV value used as input parameter</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
x &lt;- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
iv_table_list &lt;- iv_table(base = data,target = "Y",num_var_name = x,cat_var_name = "Species")
ivf_list &lt;- iv_filter(base = data,iv_table = iv_table_list$iv_table,threshold = 0.02)
ivf_list$retain_var_tab
ivf_list$retain_var_name
ivf_list$dropped_var_tab
ivf_list$threshold
</code></pre>

<hr>
<h2 id='iv_table'>WOE and IV table for list of numerical and categorical variables</h2><span id='topic+iv_table'></span>

<h3>Description</h3>

<p>The function takes column indices of categorical and numerical variables and returns a list with four dataframes - WOE table of numerical variables, categorical variables, consolidated table of both numerical &amp; categorical variables and a IV table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iv_table(base, target, num_var_name = F, num_missing = -99999,
  cat_var_name = F, mincriterion = 0.1, event = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iv_table_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="iv_table_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="iv_table_+3A_num_var_name">num_var_name</code></td>
<td>
<p>column name or array of column names of numerical variable for which IV is to be calculated, to be passed as string</p>
</td></tr>
<tr><td><code id="iv_table_+3A_num_missing">num_missing</code></td>
<td>
<p>(optional) imputed missing value for numerical variable or an array of values which are to be kept as different bucket in binning step (default value is -99999)</p>
</td></tr>
<tr><td><code id="iv_table_+3A_cat_var_name">cat_var_name</code></td>
<td>
<p>column name or array of column names of categorical variable for which IV is to be calculated, to be passed as string</p>
</td></tr>
<tr><td><code id="iv_table_+3A_mincriterion">mincriterion</code></td>
<td>
<p>(optional) the value of the test statistic or (1 - p-value) that must be exceeded in order to implement a split (default value is 0.1)</p>
</td></tr>
<tr><td><code id="iv_table_+3A_event">event</code></td>
<td>
<p>(optional) the event class, to be passed as 0 or 1 (default is 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;iv_table&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>num_woe_table</code></td>
<td>
<p>numerical woe table with IV as a dataframe</p>
</td></tr>
<tr><td><code>cat_woe_table</code></td>
<td>
<p>categorical woe table with IV as a dataframe</p>
</td></tr>
<tr><td><code>woe_table</code></td>
<td>
<p>numerical and categorical woe table with IV as a dataframe</p>
</td></tr>
<tr><td><code>iv_table</code></td>
<td>
<p>Variable with IV value as a dataframe</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Aiana Goyal &lt;aianagoel002@gmail.com&gt;
</p>
<p>Kanishk Dogar &lt;kanishkd4@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
x &lt;- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
iv_table_list &lt;- iv_table(base = data,target = "Y",num_var_name = x,cat_var_name = "Species")
iv_table_list$num_woe_table
iv_table_list$cat_woe_table
iv_table_list$woe_table
iv_table_list$iv_table
</code></pre>

<hr>
<h2 id='missing_val'>Missing value imputation</h2><span id='topic+missing_val'></span>

<h3>Description</h3>

<p>The function imputes the missing value in the input dataset. For numerical variables, missing values can be replaced by four possible method - 1. &quot;mean&quot; - mean or simple average of the non-missing values ; 2. - &quot;median&quot; - median or the 50th percentile of the non-missing values; 3. &quot;mode&quot;- mode or the value with maximum frequency among the non-mising values; 4. special extreme value of users' choice to be passes as an argument (-99999 is the default value). For categorical value, missing class can be replaced by two possible methods - 1. &quot;mode&quot; - mode or the class with maximum frequency among the non-mising values; 2. special class of users' choice to be passes as an argument (&quot;missing_value&quot; is the default class). The target column will remain unchanged.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missing_val(base, target, num_missing = -99999,
  cat_missing = "missing_value")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missing_val_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="missing_val_+3A_target">target</code></td>
<td>
<p>column/field name of the target variable, to be passed as a string</p>
</td></tr>
<tr><td><code id="missing_val_+3A_num_missing">num_missing</code></td>
<td>
<p>(optional) method for replacing missing values for numerical type fields - to be chosen between &quot;mean&quot;, &quot;median&quot;, &quot;mode&quot; or a value of users' choice (default value is -99999)</p>
</td></tr>
<tr><td><code id="missing_val_+3A_cat_missing">cat_missing</code></td>
<td>
<p>(optional) method for replacing missing values for categorical type fields - to be chosen between &quot;mode&quot; or a class of users' choice (default value is &quot;missing_value&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an object of class &quot;missing_val&quot; which is a list containing the following components:
</p>
<table>
<tr><td><code>base</code></td>
<td>
<p>a dataframe after imputing missing values</p>
</td></tr>
<tr><td><code>mapping_table</code></td>
<td>
<p>a dataframe with mapping between original variable and imputed missing value (if any)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data[sample(1:nrow(data),size=25),"Sepal.Length"] &lt;- NA
data[sample(1:nrow(data),size=10),"Species"] &lt;- NA

missing_list &lt;- missing_val(base = data,target = "Y")
missing_list$base
missing_list$mapping_table
</code></pre>

<hr>
<h2 id='num_to_cat'>Binning numerical variables based on cuts from IV table</h2><span id='topic+num_to_cat'></span>

<h3>Description</h3>

<p>The function takes the num_woe_table output from a class &quot;iv_table&quot;. Based on the split points from the num_woe_table, the numerical variables are binned into categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>num_to_cat(base, num_woe_table, num_missing = -99999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="num_to_cat_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="num_to_cat_+3A_num_woe_table">num_woe_table</code></td>
<td>
<p>num_woe_table class from iv table output</p>
</td></tr>
<tr><td><code id="num_to_cat_+3A_num_missing">num_missing</code></td>
<td>
<p>(optional) imputed missing value for numerical variable (default value is -99999)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe after converting the numerical variables into categorical classes.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
x &lt;- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
iv_table_list &lt;- iv_table(base = data,target = "Y",num_var_name = x,cat_var_name = "Species")
num_cat &lt;- num_to_cat(base = data,num_woe_table = iv_table_list$num_woe_table)
</code></pre>

<hr>
<h2 id='others_class'>Clubbing of classes of categorical variable with low population percentage into one class</h2><span id='topic+others_class'></span>

<h3>Description</h3>

<p>The function groups the classes of a categorical variable which have population percentage less than a threshold as &quot;Low_pop_perc&quot;. The user can choose whether to club the missing class or keep it as separate class. The default setting is that missing classes are not treated separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>others_class(base, target, column_name, threshold, char_missing = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="others_class_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="others_class_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="others_class_+3A_column_name">column_name</code></td>
<td>
<p>column name or array of column names of the dataframe on which the operation is to be done</p>
</td></tr>
<tr><td><code id="others_class_+3A_threshold">threshold</code></td>
<td>
<p>threshold population percentage below which the class is to be classified as others, to be provided as decimal/fraction</p>
</td></tr>
<tr><td><code id="others_class_+3A_char_missing">char_missing</code></td>
<td>
<p>(optional) imputed missing value for categorical variable if its to be kept separate (default value is NA)</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>base</code></td>
<td>
<p>a dataframe after converting all low percentage classes into &quot;Low_pop_perc&quot; class</p>
</td></tr>
<tr><td><code>mapping_table</code></td>
<td>
<p>a dataframe with mapping between original classes which are now &quot;Low_pop_perc&quot; class (if any)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris[c(1:110),]
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
data$Species &lt;- as.character(data$Species)
data_otherclass &lt;- others_class(base = data,target = "Y",column_name = "Species",threshold = 0.15)
</code></pre>

<hr>
<h2 id='random_forest_parameters'>Hyperparameter optimisation or parameter tuning for Random Forest by grid search</h2><span id='topic+random_forest_parameters'></span>

<h3>Description</h3>

<p>The function runs a grid search with k-fold cross validation to arrive at best parameter decided by some performance measure. The parameters that can be tuned using this function for random forest algorithm are - ntree, mtry, maxnodes and nodesize. The objective function to be minimised is the error (mean absolute error / mean squared error / root mean squared error). For the grid search, the possible values of each tuning parameter needs to be passed as an array into the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_forest_parameters(base, target, model_type, ntree, mtry,
  maxnodes = NULL, nodesize, error = "rmse", cv = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_forest_parameters_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_model_type">model_type</code></td>
<td>
<p>to be chosen among &quot;regression&quot; or &quot;classification&quot;</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to be fitted</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_mtry">mtry</code></td>
<td>
<p>number of variable to be sampled as split criteria at each node</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_maxnodes">maxnodes</code></td>
<td>
<p>(optional) Maximum number of terminal nodes (default is NULL ie. no restriction on depth of the trees)</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_nodesize">nodesize</code></td>
<td>
<p>minimum size of terminal nodes</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_error">error</code></td>
<td>
<p>(optional) error measure as objective function to be minimised, to be chosen among &quot;mae&quot;, &quot;mse&quot; and &quot;rmse&quot; (default value is &quot;rmse&quot;)</p>
</td></tr>
<tr><td><code id="random_forest_parameters_+3A_cv">cv</code></td>
<td>
<p>(optional) k vakue for k-fold cross validation to be performed (default value is 1 ie. without cross validation)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;random_forest_parameters&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>error_tab_detailed</code></td>
<td>
<p>error summary for each cross validation sample of the parameter combinations iterated during grid search as a dataframe</p>
</td></tr>
<tr><td><code>error_tab_summary</code></td>
<td>
<p>error summary for each combination of parameters as a dataframe</p>
</td></tr>
<tr><td><code>best_ntree</code></td>
<td>
<p>ntree parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_mtry</code></td>
<td>
<p>mtry parameter of the optimal solution</p>
</td></tr>
<tr><td><code>maxnodes</code></td>
<td>
<p>maxnodes parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_nodesize</code></td>
<td>
<p>nodesize parameter of the optimal solution</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>
<p>runtime of the entire process</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>
<p>Aiana Goyal &lt;aianagoel002@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
rf_params_list &lt;- random_forest_parameters(base = data,target = "Y",
                  model_type = "classification",ntree = 2,mtry = 1,nodesize = 3)
rf_params_list$error_tab_detailed
rf_params_list$error_tab_summary
rf_params_list$best_ntree
rf_params_list$best_mtry
rf_params_list$maxnodes
rf_params_list$best_nodesize
rf_params_list$runtime
</code></pre>

<hr>
<h2 id='sampling'>Random sampling of data into train and test</h2><span id='topic+sampling'></span>

<h3>Description</h3>

<p>The function does random sampling of the data and split it into train and test datasets. Training base percentage and seed value(optional) is taken as arguments. If seed value is not specified, random seed will be generated on different iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampling(base, train_perc = 0.7, seed = NA, replace = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampling_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="sampling_+3A_train_perc">train_perc</code></td>
<td>
<p>(optional) percentage of total base to be kept as training sample, to be provided as decimal/fraction (default percentage is 0.7)</p>
</td></tr>
<tr><td><code id="sampling_+3A_seed">seed</code></td>
<td>
<p>(optional) seed value (if not given random seed is generated)</p>
</td></tr>
<tr><td><code id="sampling_+3A_replace">replace</code></td>
<td>
<p>(optional) whether replacement will e with or without replacement (default is FALSE ie. without replacement)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;sampling&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>train_sample</code></td>
<td>
<p>training sample as a dataframe</p>
</td></tr>
<tr><td><code>test_sample</code></td>
<td>
<p>test sample as a dataframe</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>seed used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
sampling_list &lt;- sampling(base = data,train_perc = 0.7,seed = 1234)
sampling_list$train
sampling_list$test
sampling_list$seed
</code></pre>

<hr>
<h2 id='scalling'>Converting coefficients of logistic regression into scores for scorecard building</h2><span id='topic+scalling'></span>

<h3>Description</h3>

<p>The function takes a logistic model as input and scales the coefficients into scores to be used for scorecard generation. The
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scalling(base, target, model, point = 15, factor = 2, setscore = 660)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scalling_+3A_base">base</code></td>
<td>
<p>base input dataframe</p>
</td></tr>
<tr><td><code id="scalling_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="scalling_+3A_model">model</code></td>
<td>
<p>input logistic model from which the coefficients are to be picked</p>
</td></tr>
<tr><td><code id="scalling_+3A_point">point</code></td>
<td>
<p>(optional) points after which the log odds will get multiplied by &quot;factor&quot; (default value is 15)</p>
</td></tr>
<tr><td><code id="scalling_+3A_factor">factor</code></td>
<td>
<p>(optional) factor by which the log odds must get multiplied after a step of &quot;points&quot; (default value is 2)</p>
</td></tr>
<tr><td><code id="scalling_+3A_setscore">setscore</code></td>
<td>
<p>(optional) input for setting offset (default value is 660)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe with the coefficients and scalled scores for each class of all explanatory variables of the model.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
x &lt;- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
iv_table_list &lt;- iv_table(base = data,target = "Y",num_var_name = x,cat_var_name = "Species")
num_cat &lt;- num_to_cat(base = data,num_woe_table = iv_table_list$num_woe_table)
log_model &lt;- glm(Y ~ ., data = num_cat, family = "binomial")
scaling_tab &lt;- scalling(base = num_cat,target = "Y",model = log_model)
</code></pre>

<hr>
<h2 id='scoring'>Scoring a dataset with class based on a scalling logic to arrive at final score</h2><span id='topic+scoring'></span>

<h3>Description</h3>

<p>The function takes the data, with each variable as class. The dataframe of class scalling is used to convert the class into scores and finally arrive at the row level final scores by adding up the score values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoring(base, target, scalling)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoring_+3A_base">base</code></td>
<td>
<p>input dataframe with classes same as scalling logic</p>
</td></tr>
<tr><td><code id="scoring_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="scoring_+3A_scalling">scalling</code></td>
<td>
<p>dataframe of class scalling with atleast two columns - Variable, Category, Coefficient, D(i,j)_hat, Score</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a dataframe with classes converted to scores and the final score for each record in the input dataframe.
</p>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
x &lt;- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
iv_table_list &lt;- iv_table(base = data,target = "Y",num_var_name = x,cat_var_name = "Species")
num_cat &lt;- num_to_cat(base = data,num_woe_table = iv_table_list$num_woe_table)
log_model &lt;- glm(Y ~ ., data = num_cat, family = "binomial")
scaling_tab &lt;- scalling(base = num_cat,target = "Y",model = log_model)
score_tab &lt;- scoring(base = num_cat,target = "Y",scalling = scaling_tab)
</code></pre>

<hr>
<h2 id='support_vector_parameters'>Hyperparameter optimisation or parameter tuning for Suppert Vector Machine by grid search</h2><span id='topic+support_vector_parameters'></span>

<h3>Description</h3>

<p>The function runs a grid search with k-fold cross validation to arrive at best parameter decided by some performance measure. The parameters that can be tuned using this function for support vector machine algorithm are - kernel (linear / polynomial / radial / sigmoid), degree of polynomial, gamma and cost. The objective function to be minimised is the error (mean absolute error / mean squared error / root mean squared error). For the grid search, the possible values of each tuning parameter needs to be passed as an array into the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>support_vector_parameters(base, target, scale = T, kernel, degree = 2,
  gamma, cost, error = "rmse", cv = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="support_vector_parameters_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_scale">scale</code></td>
<td>
<p>(optional) logical vector indicating the variables to be scaled (default value is TRUE)</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_kernel">kernel</code></td>
<td>
<p>an array of kernels to be iterated on; kernel used in training and predicting, to be cheosen among &quot;linear&quot;, &quot;polynomial&quot;, &quot;radial&quot; and &quot;sigmoid&quot;</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_degree">degree</code></td>
<td>
<p>(optional) an array of degree of polynomial to be iterated on; parameter needed for kernel of type &quot;polynomial&quot; (default value is 2)</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_gamma">gamma</code></td>
<td>
<p>an array of gamma values to be iterated on; parameter needed for all kernels except linear</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_cost">cost</code></td>
<td>
<p>an array of cost to be iterated on; cost of constraints violation</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_error">error</code></td>
<td>
<p>(optional) error measure as objective function to be minimised, to be chosen among &quot;mae&quot;, &quot;mse&quot; and &quot;rmse&quot; (default value is &quot;rmse&quot;)</p>
</td></tr>
<tr><td><code id="support_vector_parameters_+3A_cv">cv</code></td>
<td>
<p>(optional) k vakue for k-fold cross validation to be performed (default value is 1 ie. without cross validation)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;support_vector_parameters&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>error_tab_detailed</code></td>
<td>
<p>error summary for each cross validation sample of the parameter combinations iterated during grid search as a dataframe</p>
</td></tr>
<tr><td><code>error_tab_summary</code></td>
<td>
<p>error summary for each combination of parameters as a dataframe</p>
</td></tr>
<tr><td><code>best_kernel</code></td>
<td>
<p>kernel parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_degree</code></td>
<td>
<p>degree parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_gamma</code></td>
<td>
<p>gamma parameter of the optimal solution</p>
</td></tr>
<tr><td><code>best_cost</code></td>
<td>
<p>cost parameter of the optimal solution</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>
<p>runtime of the entire process</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
svm_params_list &lt;- support_vector_parameters(base = data,target = "Y",gamma = 0.1,
                   cost = 0.1,kernel = "radial")
svm_params_list$error_tab_detailed
svm_params_list$error_tab_summary
svm_params_list$best_kernel
svm_params_list$best_degree
svm_params_list$best_gamma
svm_params_list$best_cost
svm_params_list$runtime
</code></pre>

<hr>
<h2 id='univariate'>Univariate analysis of variables</h2><span id='topic+univariate'></span>

<h3>Description</h3>

<p>The function gives univariate analysis of the variables as output dataframe. The univariate statistics includes - minimum, maximum, mean, median, number of distinct values, variable type, counts of null value, percentage of null value, maximum population percentage among all classes/values, correlation with target. It also returns the list of names of character and numerical variable types along with variable name with population concentration more than a threshold at a class/value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univariate(base, target, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="univariate_+3A_base">base</code></td>
<td>
<p>input dataframe</p>
</td></tr>
<tr><td><code id="univariate_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="univariate_+3A_threshold">threshold</code></td>
<td>
<p>sparsity threshold, to be provided as decimal/fraction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an object of class &quot;univariate&quot; which is a list containing the following components:
</p>
<table>
<tr><td><code>univar_table</code></td>
<td>
<p>univariate summary of variables</p>
</td></tr>
<tr><td><code>num_var_name</code></td>
<td>
<p>array of column names of numerical type variables</p>
</td></tr>
<tr><td><code>char_var_name</code></td>
<td>
<p>array of column names of categorical type variables</p>
</td></tr>
<tr><td><code>sparse_var_name</code></td>
<td>
<p>array of column names where population concentration at a class or value is more then the sparsity threshold</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
data$Species &lt;- as.character(data$Species)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)

univariate_list &lt;- univariate(base = data,target = "Y",threshold = 0.95)
univariate_list$univar_table
univariate_list$num_var_name
univariate_list$char_var_name
univariate_list$sparse_var_name
</code></pre>

<hr>
<h2 id='vif_filter'>Removing multicollinearity from a model using vif test</h2><span id='topic+vif_filter'></span>

<h3>Description</h3>

<p>The function takes a dataset with the starting variables and target only. The vif is calculated and if the maximum vif value is more than the threshold, the variable is dropped from the model and the vif's are recomputed. These steps of computing vif and dropping variable keep iterating till the maximum vif value is less than or equal to the threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vif_filter(base, target, threshold = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vif_filter_+3A_base">base</code></td>
<td>
<p>input dataframe with set of final variables only along with target</p>
</td></tr>
<tr><td><code id="vif_filter_+3A_target">target</code></td>
<td>
<p>column / field name for the target variable to be passed as string (must be 0/1 type)</p>
</td></tr>
<tr><td><code id="vif_filter_+3A_threshold">threshold</code></td>
<td>
<p>threshold value for vif (default value is 2)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;vif_filter&quot; is a list containing the following components:
</p>
<table>
<tr><td><code>vif_table</code></td>
<td>
<p>vif table post vif filtering</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the model used for vif calculation</p>
</td></tr>
<tr><td><code>retain_var_list</code></td>
<td>
<p>variables remaining in the model post vif filter as an array</p>
</td></tr>
<tr><td><code>dropped_var_list</code></td>
<td>
<p>variables dropped from the model in vif filter step</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>threshold </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arya Poddar &lt;aryapoddar290990@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris
suppressWarnings(RNGversion('3.5.0'))
set.seed(11)
data$Y &lt;- sample(0:1,size=nrow(data),replace=TRUE)
vif_data_list &lt;- vif_filter(base = data,target = "Y")
vif_data_list$vif_table
vif_data_list$model
vif_data_list$retain_var_list
vif_data_list$dropped_var_list
vif_data_list$threshold
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
