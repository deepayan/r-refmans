<!DOCTYPE html><html><head><title>Help for package CoOL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CoOL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CoOL_0_binary_encode_exposure_data'><p>Binary encode exposure data</p></a></li>
<li><a href='#CoOL_0_common_simulation'><p>Common example</p></a></li>
<li><a href='#CoOL_0_complex_simulation'><p>Complex example</p></a></li>
<li><a href='#CoOL_0_confounding_simulation'><p>Confounding example</p></a></li>
<li><a href='#CoOL_0_mediation_simulation'><p>Mediation example</p></a></li>
<li><a href='#CoOL_0_working_example'><p>CoOL working example with sex, drug A, and drug B</p></a></li>
<li><a href='#CoOL_1_initiate_neural_network'><p>Initiates a non-negative neural network</p></a></li>
<li><a href='#CoOL_2_train_neural_network'><p>Training the non-negative neural network</p></a></li>
<li><a href='#CoOL_3_plot_neural_network'><p>Plotting the non-negative neural network</p></a></li>
<li><a href='#CoOL_4_AUC'><p>Plot the ROC AUC</p></a></li>
<li><a href='#CoOL_4_predict_risks'><p>Predict the risk of the outcome using the fitted non-negative neural network</p></a></li>
<li><a href='#CoOL_5_layerwise_relevance_propagation'><p>Layer-wise relevance propagation of the fitted non-negative neural network</p></a></li>
<li><a href='#CoOL_6_calibration_plot'><p>Calibration curve</p></a></li>
<li><a href='#CoOL_6_dendrogram'><p>Dendrogram and sub-groups</p></a></li>
<li><a href='#CoOL_6_individual_effects_matrix'><p>Risk contribution matrix based on individual effects (had all other exposures been set to zero)</p></a></li>
<li><a href='#CoOL_6_number_of_sub_groups'><p>Number of subgroups</p></a></li>
<li><a href='#CoOL_6_sub_groups'><p>Assign sub-groups</p></a></li>
<li><a href='#CoOL_6_sum_of_individual_effects'><p>Predict the risk based on the sum of individual effects</p></a></li>
<li><a href='#CoOL_7_prevalence_and_mean_risk_plot'><p>Prevalence and mean risk plot</p></a></li>
<li><a href='#CoOL_8_mean_risk_contributions_by_sub_group'><p>Mean risk contributions by sub-groups</p></a></li>
<li><a href='#CoOL_9_visualised_mean_risk_contributions'><p>Visualisation of the mean risk contributions by sub-groups</p></a></li>
<li><a href='#CoOL_9_visualised_mean_risk_contributions_legend'><p>Legend to the visualisation of the mean risk contributions by sub-groups</p></a></li>
<li><a href='#CoOL_default'><p>The default analysis for computational phase of CoOL</p></a></li>
<li><a href='#cpp_train_network_relu'><p>Function used as part of other functions</p></a></li>
<li><a href='#random'><p>Function used as part of other functions</p></a></li>
<li><a href='#rcpprelu'><p>Function used as part of other functions</p></a></li>
<li><a href='#rcpprelu_neg'><p>Function used as part of other functions</p></a></li>
<li><a href='#relu'><p>Function used as part of other functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Causes of Outcome Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-23</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andreas Rieckmann &lt;aric@sund.ku.dk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementing the computational phase of the Causes of Outcome Learning approach as described in Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;<a href="https://doi.org/10.1093%2Fije%2Fdyac078">doi:10.1093/ije/dyac078</a>&gt;. The optional 'ggtree' package can be obtained through Bioconductor.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bioconductor.org">https://bioconductor.org</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, data.table, pROC, graphics, mltools, stats, plyr,
ggplot2, ClustGeo, wesanderson, grDevices</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggtree, imager</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-24 09:34:01 UTC; lvb917</td>
</tr>
<tr>
<td>Author:</td>
<td>Andreas Rieckmann [aut, cre],
  Piotr Dworzynski [aut],
  Leila Arras [ctb],
  Claus Thorn Ekstrom [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-24 10:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='CoOL_0_binary_encode_exposure_data'>Binary encode exposure data</h2><span id='topic+CoOL_0_binary_encode_exposure_data'></span>

<h3>Description</h3>

<p>This function binary encodes the exposure data set so that each category is coded 0 and 1 (e.g. the variable sex will be two variables men (1/0) and women (0/1)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_0_binary_encode_exposure_data(exposure_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_0_binary_encode_exposure_data_+3A_exposure_data">exposure_data</code></td>
<td>
<p>The exposure data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame with the expanded exposure data, where all variables are binary encoded.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example

</code></pre>

<hr>
<h2 id='CoOL_0_common_simulation'>Common example</h2><span id='topic+CoOL_0_common_simulation'></span>

<h3>Description</h3>

<p>To reproduce the common causes example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_0_common_simulation(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_0_common_simulation_+3A_n">n</code></td>
<td>
<p>number of observations for the synthetic data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the columns Y, A, B, C, D, E, F and n rows.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>

<hr>
<h2 id='CoOL_0_complex_simulation'>Complex example</h2><span id='topic+CoOL_0_complex_simulation'></span>

<h3>Description</h3>

<p>To reproduce the complex example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_0_complex_simulation(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_0_complex_simulation_+3A_n">n</code></td>
<td>
<p>number of observations for the synthetic data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the columns Y, Physically_active, Low_SES, Mutation_X, LDL, Night_shifts, Air_pollution and n rows.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>

<hr>
<h2 id='CoOL_0_confounding_simulation'>Confounding example</h2><span id='topic+CoOL_0_confounding_simulation'></span>

<h3>Description</h3>

<p>To reproduce the confounding example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_0_confounding_simulation(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_0_confounding_simulation_+3A_n">n</code></td>
<td>
<p>number of observations for the synthetic data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the columns Y, A, B, C, D, E, F and n rows.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>

<hr>
<h2 id='CoOL_0_mediation_simulation'>Mediation example</h2><span id='topic+CoOL_0_mediation_simulation'></span>

<h3>Description</h3>

<p>To reproduce the mediation example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_0_mediation_simulation(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_0_mediation_simulation_+3A_n">n</code></td>
<td>
<p>number of observations for the synthetic data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the columns Y, A,B ,C, D, E, F and n rows.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>

<hr>
<h2 id='CoOL_0_working_example'>CoOL working example with sex, drug A, and drug B</h2><span id='topic+CoOL_0_working_example'></span>

<h3>Description</h3>

<p>To reproduce the CoOL working example with sex, drug A, and drug B.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_0_working_example(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_0_working_example_+3A_n">n</code></td>
<td>
<p>number of observations for the synthetic data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the columns Y, sex, drug_a, drug_b and rows equal to n.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	while (FALSE) {
 library(CoOL)
 set.seed(1)
 data &lt;- CoOL_0_working_example(n=10000)
 outcome_data &lt;- data[,1]
 exposure_data &lt;- data[,-1]
 exposure_data &lt;- CoOL_0_binary_encode_exposure_data(exposure_data)
 model &lt;- CoOL_1_initiate_neural_network(inputs=ncol(exposure_data),
 output = outcome_data,hidden=5)
 model &lt;- CoOL_2_train_neural_network(lr = 1e-4,X_train=exposure_data,
 Y_train=outcome_data,X_test=exposure_data, Y_test=outcome_data,
 model=model, epochs=1000,patience = 200, input_parameter_reg = 1e-3
 ) # Train the non-negative model (The model can be retrained)
 model &lt;- CoOL_2_train_neural_network(lr = 1e-5,X_train=exposure_data,
 Y_train=outcome_data,X_test=exposure_data, Y_test=outcome_data, model=model,
 epochs=1000,patience = 100, input_parameter_reg = 1e-3)
 # Train the non-negative model (The model can be retrained)
 model &lt;- CoOL_2_train_neural_network(lr = 1e-6,X_train=exposure_data,
 Y_train=outcome_data,X_test=exposure_data, Y_test=outcome_data, model=model,
 epochs=1000,patience = 50, input_parameter_reg = 1e-3
 ) # Train the non-negative model (The model can be retrained)
 plot(model$train_performance,type='l',yaxs='i',ylab="Mean squared error",
 xlab="Epochs",main="A) Performance during training\n\n",
 ylim=quantile(model$train_performance,c(0,.975))) # Model performance
 CoOL_3_plot_neural_network(model,names(exposure_data),5/max(model[[1]]),
 title = "B) Model connection weights\nand intercepts") # Model visualization
 CoOL_4_AUC(outcome_data,exposure_data,model,
 title = "C) Receiver operating\ncharacteristic curve") # AUC
 risk_contributions &lt;- CoOL_5_layerwise_relevance_propagation(exposure_data,model
 ) # Risk contributions
 CoOL_6_number_of_sub_groups(risk_contributions = risk_contributions,
 low_number = 1, high_number = 5)
 CoOL_6_dendrogram(risk_contributions,number_of_subgroups = 3,
 title = "D) Dendrogram with 3 sub-groups") # Dendrogram
 sub_groups &lt;- CoOL_6_sub_groups(risk_contributions,number_of_subgroups = 3
 ) # Assign sub-groups
 CoOL_6_calibration_plot(exposure_data = exposure_data,
 outcome_data = outcome_data, model = model, sub_groups = sub_groups)
 CoOL_7_prevalence_and_mean_risk_plot(risk_contributions,sub_groups,
 title = "E) Prevalence and mean risk of sub-groups") # Prevalence and mean risk plot
 results &lt;- CoOL_8_mean_risk_contributions_by_sub_group(risk_contributions,
 sub_groups,outcome_data = outcome_data,exposure_data = exposure_data,
 model=model,exclude_below = 0.01) #  Mean risk contributions by sub-groups
	CoOL_9_visualised_mean_risk_contributions(results = results,  sub_groups = sub_groups)
	CoOL_9_visualised_mean_risk_contributions_legend(results = results)
	}
</code></pre>

<hr>
<h2 id='CoOL_1_initiate_neural_network'>Initiates a non-negative neural network</h2><span id='topic+CoOL_1_initiate_neural_network'></span>

<h3>Description</h3>

<p>This function initiates a non-negative neural network. The one-hidden layer non-negative neural network is designed to resemble a DAG with hidden synergistic components. With the model, we intend to learn the various synergistic interactions between the exposures and outcome. The model needs to be non-negative and estimate the risk on an additive scale. Neural networks include hidden activation functions (if the sum of the input exceeds a threshold, information is passed on), which can model minimum threshold values of interactions between exposures. We need to specify the upper limit of the number of possible hidden activation functions and through model fitting, the model may be able to learn both stand-alone and synergistically interacting factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_1_initiate_neural_network(inputs, output, hidden = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_1_initiate_neural_network_+3A_inputs">inputs</code></td>
<td>
<p>The number of exposures.</p>
</td></tr>
<tr><td><code id="CoOL_1_initiate_neural_network_+3A_output">output</code></td>
<td>
<p>The outbut variable is used to calcualte the mean of it used to initiate the baseline risk.</p>
</td></tr>
<tr><td><code id="CoOL_1_initiate_neural_network_+3A_hidden">hidden</code></td>
<td>
<p>Number of hidden nodes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The non-negative neural network can be denoted as:
</p>
<p style="text-align: center;"><code class="reqn">
P(Y=1|X^+)=\sum_{j}\Big(w_{j,k}^+ReLU_j\big(\sum_{i}(w_{i,j}^+X_i^+) + b_j^-\big)\Big) + R^{b}
</code>
</p>



<h3>Value</h3>

<p>A list with connection weights, bias weights and meta data.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example

</code></pre>

<hr>
<h2 id='CoOL_2_train_neural_network'>Training the non-negative neural network</h2><span id='topic+CoOL_2_train_neural_network'></span>

<h3>Description</h3>

<p>This function trains the non-negative neural network. Fitting the model is done in a step-wise procedure one individual at a time, where the model estimates individual's risk of the disease outcome, estimates the prediction's residual error and adjusts the model parameters to reduce this error. By iterating through all individuals for multiple epochs (one complete iterations through all individuals is called an epoch), we end with parameters for the model, where the errors are smallest possible for the full population. The model fit follows the linear expectation that synergism is a combined effect larger than the sum of independent effects. The initial values, derivatives, and learning rates are described in further detail in the Supplementary material. The non-negative model ensures that the predicted value cannot be negative. The model does not prevent estimating probabilities above 1, but this would be unlikely, as risks of disease and mortality even for high risk groups in general are far below 1. The use of a test dataset does not seem to assist deciding on the optimal number of epochs possibly due to the constrains due to the non-negative assumption. We suggest splitting data into a train and test data set, such that findings from the train data set can be confirmed in the test data set before developing hypotheses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_2_train_neural_network(
  X_train,
  Y_train,
  X_test,
  Y_test,
  C_train = 0,
  C_test = 0,
  model,
  lr = c(1e-04, 1e-05, 1e-06),
  epochs = 2000,
  patience = 100,
  monitor = TRUE,
  plot_and_evaluation_frequency = 50,
  input_parameter_reg = 0.001,
  spline_df = 10,
  restore_par_options = TRUE,
  drop_out = 0,
  fix_baseline_risk = -1,
  ipw = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_2_train_neural_network_+3A_x_train">X_train</code></td>
<td>
<p>The exposure data for the training data.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_y_train">Y_train</code></td>
<td>
<p>The outcome data for the training data.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_x_test">X_test</code></td>
<td>
<p>The exposure data for the test data (currently the training data is used).</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_y_test">Y_test</code></td>
<td>
<p>The outcome data for the test data (currently the training data is used).</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_c_train">C_train</code></td>
<td>
<p>One variable to adjust the analysis for such as calendar time (training data).</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_c_test">C_test</code></td>
<td>
<p>One variable to adjust the analysis for such as calendar time (currently the training data is used).</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_model">model</code></td>
<td>
<p>The fitted non-negative neural network.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_lr">lr</code></td>
<td>
<p>Learning rate (several LR can be provided, such that the model training will train for each LR and continue to the next).</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_epochs">epochs</code></td>
<td>
<p>Epochs.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_patience">patience</code></td>
<td>
<p>The number of epochs allowed without an improvement in performance.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_monitor">monitor</code></td>
<td>
<p>Whether a monitoring plot will be shown during training.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_plot_and_evaluation_frequency">plot_and_evaluation_frequency</code></td>
<td>
<p>The interval for plotting the performance and checking the patience.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_input_parameter_reg">input_parameter_reg</code></td>
<td>
<p>Regularisation decreasing parameter value at each iteration for the input parameters.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_spline_df">spline_df</code></td>
<td>
<p>Degrees of freedom for the spline fit for the performance plots.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_drop_out">drop_out</code></td>
<td>
<p>To drop connections if their weights reaches zero.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_fix_baseline_risk">fix_baseline_risk</code></td>
<td>
<p>To fix the baseline risk at a value.</p>
</td></tr>
<tr><td><code id="CoOL_2_train_neural_network_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated list of connection weights, bias weights and meta data.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_3_plot_neural_network'>Plotting the non-negative neural network</h2><span id='topic+CoOL_3_plot_neural_network'></span>

<h3>Description</h3>

<p>This function plots the non-negative neural network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_3_plot_neural_network(
  model,
  names,
  arrow_size = NA,
  title = "Model connection weights and intercepts",
  restore_par_options = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_3_plot_neural_network_+3A_model">model</code></td>
<td>
<p>The fitted non-negative neural network.</p>
</td></tr>
<tr><td><code id="CoOL_3_plot_neural_network_+3A_names">names</code></td>
<td>
<p>Labels of each exposure.</p>
</td></tr>
<tr><td><code id="CoOL_3_plot_neural_network_+3A_arrow_size">arrow_size</code></td>
<td>
<p>Define the arrow_size for the model illustration in the reported training progress.</p>
</td></tr>
<tr><td><code id="CoOL_3_plot_neural_network_+3A_title">title</code></td>
<td>
<p>Title on the plot.</p>
</td></tr>
<tr><td><code id="CoOL_3_plot_neural_network_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot visualizing the connection weights.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_4_AUC'>Plot the ROC AUC</h2><span id='topic+CoOL_4_AUC'></span>

<h3>Description</h3>

<p>Plot the ROC AUC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_4_AUC(
  outcome_data,
  exposure_data,
  model,
  title = "Receiver operating\ncharacteristic curve",
  restore_par_options = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_4_AUC_+3A_outcome_data">outcome_data</code></td>
<td>
<p>The outcome data.</p>
</td></tr>
<tr><td><code id="CoOL_4_AUC_+3A_exposure_data">exposure_data</code></td>
<td>
<p>The exposure data.</p>
</td></tr>
<tr><td><code id="CoOL_4_AUC_+3A_model">model</code></td>
<td>
<p>The fitted the non-negative neural network.</p>
</td></tr>
<tr><td><code id="CoOL_4_AUC_+3A_title">title</code></td>
<td>
<p>Title on the plot.</p>
</td></tr>
<tr><td><code id="CoOL_4_AUC_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the ROC and the ROC AUC value.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_4_predict_risks'>Predict the risk of the outcome using the fitted non-negative neural network</h2><span id='topic+CoOL_4_predict_risks'></span>

<h3>Description</h3>

<p>Predict the risk of the outcome using the fitted non-negative neural network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_4_predict_risks(X, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_4_predict_risks_+3A_x">X</code></td>
<td>
<p>The exposure data.</p>
</td></tr>
<tr><td><code id="CoOL_4_predict_risks_+3A_model">model</code></td>
<td>
<p>The fitted the non-negative neural network.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the predicted risk of the outcome for each individual.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_5_layerwise_relevance_propagation'>Layer-wise relevance propagation of the fitted non-negative neural network</h2><span id='topic+CoOL_5_layerwise_relevance_propagation'></span>

<h3>Description</h3>

<p>Calculates risk contributions for each exposure and a baseline using layer-wise relevance propagation of the fitted non-negative neural network and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_5_layerwise_relevance_propagation(X, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_5_layerwise_relevance_propagation_+3A_x">X</code></td>
<td>
<p>The exposure data.</p>
</td></tr>
<tr><td><code id="CoOL_5_layerwise_relevance_propagation_+3A_model">model</code></td>
<td>
<p>The fitted the non-negative neural network.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each individual:</p>
<p style="text-align: center;"><code class="reqn">
P(Y=1|X^+)=R^b+\sum_iR^X_i
</code>
</p>

<p>The below procedure is conducted for all individuals in a one by one fashion. The baseline risk, $R^b$, is simply parameterised in the model. The decomposition of the risk contributions for exposures, $R^X_i$, takes 3 steps:
</p>
<p>Step 1 - Subtract the baseline risk, $R^b$:
</p>
<p style="text-align: center;"><code class="reqn">
R^X_k =  P(Y=1|X^+)-R^b
</code>
</p>

<p>Step 2 - Decompose to the hidden layer:
</p>
<p style="text-align: center;"><code class="reqn">
R^{X}_j =  \frac{H_j w_{j,k}}{\sum_j(H_j w_{j,k})} R^X_k
</code>
</p>

<p>Where $H_j$ is the value taken by each of the $ReLU()_j$ functions for the specific individual.
</p>
<p>Step 3 - Hidden layer to exposures:
</p>
<p style="text-align: center;"><code class="reqn">
R^{X}_i = \sum_j \Big(\frac{X_i^+ w_{i,j}}{\sum_i( X_i^+ w_{i,j})}R^X_j\Big)
</code>
</p>

<p>This creates a dataset with the dimensions equal to the number of individuals times the number of exposures plus a baseline risk value, which can be termed a risk contribution matrix. Instead of exposure values, individuals are given risk contributions, R^X_i.
</p>


<h3>Value</h3>

<p>A data frame with the risk contribution matrix [number of individuals, risk contributors + the baseline risk].
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_6_calibration_plot'>Calibration curve</h2><span id='topic+CoOL_6_calibration_plot'></span>

<h3>Description</h3>

<p>Shows the calibration curve e.i. the predicted risk vs the actual risk by subgroups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_6_calibration_plot(
  exposure_data,
  outcome_data,
  model,
  sub_groups,
  ipw = 1,
  restore_par_options = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_6_calibration_plot_+3A_exposure_data">exposure_data</code></td>
<td>
<p>The exposure dataset.</p>
</td></tr>
<tr><td><code id="CoOL_6_calibration_plot_+3A_outcome_data">outcome_data</code></td>
<td>
<p>The outcome vector.</p>
</td></tr>
<tr><td><code id="CoOL_6_calibration_plot_+3A_model">model</code></td>
<td>
<p>The fitted non-negative neural network.</p>
</td></tr>
<tr><td><code id="CoOL_6_calibration_plot_+3A_sub_groups">sub_groups</code></td>
<td>
<p>The vector with the assigned sub_group numbers.</p>
</td></tr>
<tr><td><code id="CoOL_6_calibration_plot_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
<tr><td><code id="CoOL_6_calibration_plot_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A calibration curve.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_6_dendrogram'>Dendrogram and sub-groups</h2><span id='topic+CoOL_6_dendrogram'></span>

<h3>Description</h3>

<p>Calculates presents a dendrogram coloured by the pre-defined number of sub-groups and provides the vector with sub-groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_6_dendrogram(
  risk_contributions,
  number_of_subgroups = 3,
  title = "Dendrogram",
  colours = NA,
  ipw = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_6_dendrogram_+3A_risk_contributions">risk_contributions</code></td>
<td>
<p>The risk contributions.</p>
</td></tr>
<tr><td><code id="CoOL_6_dendrogram_+3A_number_of_subgroups">number_of_subgroups</code></td>
<td>
<p>The number of sub-groups chosen (Visual inspection is necessary).</p>
</td></tr>
<tr><td><code id="CoOL_6_dendrogram_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="CoOL_6_dendrogram_+3A_colours">colours</code></td>
<td>
<p>Colours indicating each sub-group.</p>
</td></tr>
<tr><td><code id="CoOL_6_dendrogram_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dendrogram illustrating similarities between individuals based on their risk contributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_6_individual_effects_matrix'>Risk contribution matrix based on individual effects (had all other exposures been set to zero)</h2><span id='topic+CoOL_6_individual_effects_matrix'></span>

<h3>Description</h3>

<p>Estimating the risk contribution for each exposure if each individual had been exposed to only one exposure, with the value the individual actually had.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_6_individual_effects_matrix(X, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_6_individual_effects_matrix_+3A_x">X</code></td>
<td>
<p>The exposure data.</p>
</td></tr>
<tr><td><code id="CoOL_6_individual_effects_matrix_+3A_model">model</code></td>
<td>
<p>The fitted the non-negative neural network.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix [Number of individuals, exposures] with the estimated individual effects by each exposure had all other values been set to zero.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_6_number_of_sub_groups'>Number of subgroups</h2><span id='topic+CoOL_6_number_of_sub_groups'></span>

<h3>Description</h3>

<p>Calculates the mean distance by several number of subgroups to determine the optimal number of subgroups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_6_number_of_sub_groups(
  risk_contributions,
  low_number = 1,
  high_number = 5,
  ipw = 1,
  restore_par_options = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_6_number_of_sub_groups_+3A_risk_contributions">risk_contributions</code></td>
<td>
<p>The risk contributions.</p>
</td></tr>
<tr><td><code id="CoOL_6_number_of_sub_groups_+3A_low_number">low_number</code></td>
<td>
<p>The lowest number of subgroups.</p>
</td></tr>
<tr><td><code id="CoOL_6_number_of_sub_groups_+3A_high_number">high_number</code></td>
<td>
<p>The highest number of subgroups.</p>
</td></tr>
<tr><td><code id="CoOL_6_number_of_sub_groups_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
<tr><td><code id="CoOL_6_number_of_sub_groups_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the mean distance by the number of subgroups. The mean distance converges when the optimal number of subgroups are found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_6_sub_groups'>Assign sub-groups</h2><span id='topic+CoOL_6_sub_groups'></span>

<h3>Description</h3>

<p>Calculates presents a dendrogram coloured by the pre-defined number of sub-groups and provides the vector with sub-groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_6_sub_groups(risk_contributions, number_of_subgroups = 3, ipw = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_6_sub_groups_+3A_risk_contributions">risk_contributions</code></td>
<td>
<p>The risk contributions.</p>
</td></tr>
<tr><td><code id="CoOL_6_sub_groups_+3A_number_of_subgroups">number_of_subgroups</code></td>
<td>
<p>The number of sub-groups chosen (Visual inspection is necessary).</p>
</td></tr>
<tr><td><code id="CoOL_6_sub_groups_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector [number of individuals] with an assigned sub-group.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_6_sum_of_individual_effects'>Predict the risk based on the sum of individual effects</h2><span id='topic+CoOL_6_sum_of_individual_effects'></span>

<h3>Description</h3>

<p>By summing the through the risk as if each individual had been exposed to only one exposure, with the value the individual actually had.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_6_sum_of_individual_effects(X, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_6_sum_of_individual_effects_+3A_x">X</code></td>
<td>
<p>The exposure data.</p>
</td></tr>
<tr><td><code id="CoOL_6_sum_of_individual_effects_+3A_model">model</code></td>
<td>
<p>The fitted the non-negative neural network.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value the sum of indivisual effects, had there been no interactions between exposures.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_7_prevalence_and_mean_risk_plot'>Prevalence and mean risk plot</h2><span id='topic+CoOL_7_prevalence_and_mean_risk_plot'></span>

<h3>Description</h3>

<p>This plot shows the prevalence and mean risk for each sub-group. Its distribution hits at sub-groups with great public health potential.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_7_prevalence_and_mean_risk_plot(
  risk_contributions,
  sub_groups,
  title = "Prevalence and mean risk\nof sub-groups",
  y_max = NA,
  restore_par_options = TRUE,
  colours = NA,
  ipw = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_risk_contributions">risk_contributions</code></td>
<td>
<p>The risk contributions.</p>
</td></tr>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_sub_groups">sub_groups</code></td>
<td>
<p>The vector with the sub-groups.</p>
</td></tr>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_title">title</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_y_max">y_max</code></td>
<td>
<p>Fix the axis of the risk of the outcome.</p>
</td></tr>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_colours">colours</code></td>
<td>
<p>Colours indicating each sub-group.</p>
</td></tr>
<tr><td><code id="CoOL_7_prevalence_and_mean_risk_plot_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot with prevalence and mean risks by sub-groups.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_8_mean_risk_contributions_by_sub_group'>Mean risk contributions by sub-groups</h2><span id='topic+CoOL_8_mean_risk_contributions_by_sub_group'></span>

<h3>Description</h3>

<p>Table with the mean risk contributions by sub-groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_8_mean_risk_contributions_by_sub_group(
  risk_contributions,
  sub_groups,
  exposure_data,
  outcome_data,
  model,
  exclude_below = 0.001,
  restore_par_options = TRUE,
  colours = NA,
  ipw = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_risk_contributions">risk_contributions</code></td>
<td>
<p>The risk contributions.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_sub_groups">sub_groups</code></td>
<td>
<p>The vector with the sub-groups.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_exposure_data">exposure_data</code></td>
<td>
<p>The exposure data.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_outcome_data">outcome_data</code></td>
<td>
<p>The outcome data.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_model">model</code></td>
<td>
<p>The trained non-negative model.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_exclude_below">exclude_below</code></td>
<td>
<p>A lower cut-off for which risk contributions shown.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_colours">colours</code></td>
<td>
<p>Colours indicating each sub-group.</p>
</td></tr>
<tr><td><code id="CoOL_8_mean_risk_contributions_by_sub_group_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot and a dataset with the mean risk contributions by sub-groups.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_9_visualised_mean_risk_contributions'>Visualisation of the mean risk contributions by sub-groups</h2><span id='topic+CoOL_9_visualised_mean_risk_contributions'></span>

<h3>Description</h3>

<p>Visualisation of the mean risk contributions by sub-groups. The function uses the output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_9_visualised_mean_risk_contributions(
  results,
  sub_groups,
  ipw = 1,
  restore_par_options = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_9_visualised_mean_risk_contributions_+3A_results">results</code></td>
<td>
<p>CoOL_8_mean_risk_contributions_by_sub_group.</p>
</td></tr>
<tr><td><code id="CoOL_9_visualised_mean_risk_contributions_+3A_sub_groups">sub_groups</code></td>
<td>
<p>The vector with the sub-groups.</p>
</td></tr>
<tr><td><code id="CoOL_9_visualised_mean_risk_contributions_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
<tr><td><code id="CoOL_9_visualised_mean_risk_contributions_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_9_visualised_mean_risk_contributions_legend'>Legend to the visualisation of the mean risk contributions by sub-groups</h2><span id='topic+CoOL_9_visualised_mean_risk_contributions_legend'></span>

<h3>Description</h3>

<p>Legend to the visualisation of the mean risk contributions by sub-groups. The function uses the output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_9_visualised_mean_risk_contributions_legend(
  results,
  restore_par_options = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_9_visualised_mean_risk_contributions_legend_+3A_results">results</code></td>
<td>
<p>CoOL_8_mean_risk_contributions_by_sub_group.</p>
</td></tr>
<tr><td><code id="CoOL_9_visualised_mean_risk_contributions_legend_+3A_restore_par_options">restore_par_options</code></td>
<td>
<p>Restore par options.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See the example under CoOL_0_working_example
</code></pre>

<hr>
<h2 id='CoOL_default'>The default analysis for computational phase of CoOL</h2><span id='topic+CoOL_default'></span>

<h3>Description</h3>

<p>The analysis and plots presented in the main paper. We recommend using View(CoOL_default) and View() on the many sub-functions to understand the steps and modify to your own research question. 3 sets of training will run with a learning rate of 1e-4 and a patience of 200 epochs, a learning rate of 1e-5 and a patience of 100 epochs, and a learning rate of 1e-6 and a patience of 50 epochs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoOL_default(
  data,
  sub_groups = 3,
  exclude_below = 0.01,
  input_parameter_reg = 0.001,
  hidden = 10,
  monitor = TRUE,
  epochs = 10000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoOL_default_+3A_data">data</code></td>
<td>
<p>A data.frame(cbind(outcome_data,exposure_data)).</p>
</td></tr>
<tr><td><code id="CoOL_default_+3A_sub_groups">sub_groups</code></td>
<td>
<p>Define the number of expected sub-groups.</p>
</td></tr>
<tr><td><code id="CoOL_default_+3A_exclude_below">exclude_below</code></td>
<td>
<p>Risk contributions below this value are not shown in the table.</p>
</td></tr>
<tr><td><code id="CoOL_default_+3A_input_parameter_reg">input_parameter_reg</code></td>
<td>
<p>The regularization of the input parameters.</p>
</td></tr>
<tr><td><code id="CoOL_default_+3A_hidden">hidden</code></td>
<td>
<p>The number of synergy-functions.</p>
</td></tr>
<tr><td><code id="CoOL_default_+3A_monitor">monitor</code></td>
<td>
<p>Whether monitoring plots will be shown in R.</p>
</td></tr>
<tr><td><code id="CoOL_default_+3A_epochs">epochs</code></td>
<td>
<p>The maximum number of epochs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A series of plots across the full Causes of Outcome Learning approach.
</p>


<h3>References</h3>

<p>Rieckmann, Dworzynski, Arras, Lapuschkin, Samek, Arah, Rod, Ekstrom. 2022. Causes of outcome learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome. International Journal of Epidemiology &lt;https://doi.org/10.1093/ije/dyac078&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Not run
while (FALSE) {
#See the example under CoOL_0_working_example for a more detailed tutorial
library(CoOL)
data &lt;- CoOL_0_working_example(n=10000)
CoOL_default(data)
}
</code></pre>

<hr>
<h2 id='cpp_train_network_relu'>Function used as part of other functions</h2><span id='topic+cpp_train_network_relu'></span>

<h3>Description</h3>

<p>Non-negative neural network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpp_train_network_relu(
  x,
  y,
  c,
  testx,
  testy,
  testc,
  W1_input,
  B1_input,
  W2_input,
  B2_input,
  C2_input,
  ipw,
  lr = 0.01,
  maxepochs = 100,
  input_parameter_reg = 1e-06,
  drop_out = 0L,
  fix_baseline_risk = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cpp_train_network_relu_+3A_x">x</code></td>
<td>
<p>A matrix of predictors for the training dataset of shape (nsamples, nfeatures)</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_y">y</code></td>
<td>
<p>A vector of output values for the training data with a length similar to the number of rows of x</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_c">c</code></td>
<td>
<p>A vector of the data to adjust the analysis for such as calendar time (training data) with the same number of rows as x.</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_testx">testx</code></td>
<td>
<p>A matrix of predictors for the test dataset of shape (nsamples, nfeatures)</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_testy">testy</code></td>
<td>
<p>A vector of output values for the test data with a length similar to the number of rows of x</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_testc">testc</code></td>
<td>
<p>A vector the data to adjust the analysis for such as calendar time (training data) with the same number of rows as x.</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_w1_input">W1_input</code></td>
<td>
<p>Input-hidden layer weights of shape (nfeatuers, hidden)</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_b1_input">B1_input</code></td>
<td>
<p>Biases for the hidden layer of shape (1, hidden)</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_w2_input">W2_input</code></td>
<td>
<p>Hidden-output layer weights of shape (hidden, 1)</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_b2_input">B2_input</code></td>
<td>
<p>Bias for the output layer (the baseline risk) af shape (1, 1)</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_c2_input">C2_input</code></td>
<td>
<p>Bias for the data to adjust the analysis for</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_ipw">ipw</code></td>
<td>
<p>a vector of weights per observation to allow for inverse probability of censoring weighting to correct for selection bias</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_lr">lr</code></td>
<td>
<p>Initial learning rate</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_maxepochs">maxepochs</code></td>
<td>
<p>The maximum number of epochs</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_input_parameter_reg">input_parameter_reg</code></td>
<td>
<p>Regularisation decreasing parameter value at each iteration for the input parameters</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_drop_out">drop_out</code></td>
<td>
<p>To drop connections if their weights reaches zero.</p>
</td></tr>
<tr><td><code id="cpp_train_network_relu_+3A_fix_baseline_risk">fix_baseline_risk</code></td>
<td>
<p>To fix the baseline risk at a value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class &quot;SCL&quot; giving the estimated matrices and performance indicators
</p>


<h3>Author(s)</h3>

<p>Andreas Rieckmann, Piotr Dworzynski, Leila Arras, Claus Ekstrøm
</p>

<hr>
<h2 id='random'>Function used as part of other functions</h2><span id='topic+random'></span>

<h3>Description</h3>

<p>Function used as part of other functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random(r, c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_+3A_r">r</code></td>
<td>
<p>rows in matrix</p>
</td></tr>
<tr><td><code id="random_+3A_c">c</code></td>
<td>
<p>columns in matrix</p>
</td></tr>
</table>

<hr>
<h2 id='rcpprelu'>Function used as part of other functions</h2><span id='topic+rcpprelu'></span>

<h3>Description</h3>

<p>relu-function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcpprelu(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcpprelu_+3A_x">x</code></td>
<td>
<p>input in the relu function</p>
</td></tr>
</table>

<hr>
<h2 id='rcpprelu_neg'>Function used as part of other functions</h2><span id='topic+rcpprelu_neg'></span>

<h3>Description</h3>

<p>negative relu-function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcpprelu_neg(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcpprelu_neg_+3A_x">x</code></td>
<td>
<p>input in the negative relu-function</p>
</td></tr>
</table>

<hr>
<h2 id='relu'>Function used as part of other functions</h2><span id='topic+relu'></span>

<h3>Description</h3>

<p>Function used as part of other functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relu(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="relu_+3A_input">input</code></td>
<td>
<p>input in the relu function</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
