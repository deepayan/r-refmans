<!DOCTYPE html><html><head><title>Help for package HTLR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HTLR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HTLR-package'><p>Bayesian Logistic Regression with Heavy-Tailed Priors</p></a></li>
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#as.matrix.htlr.fit'><p>Create a Matrix of Markov Chain Samples</p></a></li>
<li><a href='#bcbcsf_deltas'><p>Bias-corrected Bayesian classification initial state</p></a></li>
<li><a href='#colon'><p>Colon Tissues</p></a></li>
<li><a href='#diabetes392'><p>Pima Indians Diabetes</p></a></li>
<li><a href='#evaluate_pred'><p>Evaluate Prediction Results</p></a></li>
<li><a href='#gendata_FAM'><p>Generate Simulated Data with Factor Analysis Model</p></a></li>
<li><a href='#gendata_MLR'><p>Generate Simulated Data with Multinomial Logistic Regression Model</p></a></li>
<li><a href='#htlr'><p>Fit a HTLR Model</p></a></li>
<li><a href='#htlr_fit'><p>Fit a HTLR Model (Internal API)</p></a></li>
<li><a href='#htlr_predict'><p>Make Prediction on New Data (Advanced)</p></a></li>
<li><a href='#htlr_prior'><p>Generate Prior Configuration</p></a></li>
<li><a href='#lasso_deltas'><p>Lasso Initial State</p></a></li>
<li><a href='#nzero_idx'><p>Get Indices of Non-Zero Coefficients</p></a></li>
<li><a href='#order_ftest'><p>Order features by F-statistic</p></a></li>
<li><a href='#order_kruskal'><p>Order features by Kruskal-Wallis test</p></a></li>
<li><a href='#order_plain'><p>Plain order function</p></a></li>
<li><a href='#predict.htlr.fit'><p>Make Prediction on New Data</p></a></li>
<li><a href='#split_data'><p>Split Data into Train and Test Partitions</p></a></li>
<li><a href='#std'><p>Standardizes a Design Matrix</p></a></li>
<li><a href='#summary.htlr.fit'><p>Posterior Summaries</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.4-4</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Logistic Regression with Heavy-Tailed Priors</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient Bayesian multinomial logistic regression based on heavy-tailed
  (hyper-LASSO, non-convex) priors. The posterior of coefficients and hyper-parameters
  is sampled with restricted Gibbs sampling for leveraging the high-dimensionality and
  Hamiltonian Monte Carlo for handling the high-correlation among coefficients. A detailed
  description of the method: Li and Yao (2018), 
  Journal of Statistical Computation and Simulation, 88:14, 2827-2851, &lt;<a href="https://doi.org/10.48550/arXiv.1405.3319">doi:10.48550/arXiv.1405.3319</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://longhaisk.github.io/HTLR/">https://longhaisk.github.io/HTLR/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/longhaiSK/HTLR/issues">https://github.com/longhaiSK/HTLR/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, corrplot, testthat (&ge; 2.1.0), bayesplot, knitr,
rmarkdown</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.0), BCBCSF, glmnet, magrittr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp (&ge; 0.12.0), RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-21 18:03:46 UTC; xil</td>
</tr>
<tr>
<td>Author:</td>
<td>Longhai Li <a href="https://orcid.org/0000-0002-3074-8584"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Steven Liu [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Longhai Li &lt;longhai@math.usask.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-22 12:47:53 UTC</td>
</tr>
</table>
<hr>
<h2 id='HTLR-package'>Bayesian Logistic Regression with Heavy-Tailed Priors</h2><span id='topic+HTLR-package'></span>

<h3>Description</h3>

<p>Efficient Bayesian multinomial logistic regression based on heavy-tailed priors. 
This package is suitable for classification and feature selection with high-dimensional 
features, such as gene expression profiles. Heavy-tailed priors can impose stronger 
shrinkage (compared to Gaussian and Laplace priors) to the coefficients associated with 
a large number of useless features, but still allow coefficients of a small number of 
useful features to stand out without punishment. It can also automatically make selection 
within a large number of correlated features. The posterior of coefficients and hyper-
parameters is sampled with restricted Gibbs sampling for leveraging high-dimensionality 
and Hamiltonian Monte Carlo for handling high-correlations among coefficients.
</p>


<h3>References</h3>

<p>Longhai Li and Weixin Yao (2018). Fully Bayesian Logistic Regression 
with Hyper-Lasso Priors for High-dimensional Feature Selection.
<em>Journal of Statistical Computation and Simulation</em> 2018, 88:14, 2827-2851.
</p>

<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic++25+3E+25">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='as.matrix.htlr.fit'>Create a Matrix of Markov Chain Samples</h2><span id='topic+as.matrix.htlr.fit'></span>

<h3>Description</h3>

<p>The Markov chain samples (without warmup) included in a <code>htlr.fit</code> object will be coerced to a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'htlr.fit'
as.matrix(x, k = NULL, include.warmup = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.htlr.fit_+3A_x">x</code></td>
<td>
<p>An object of S3 class <code>htlr.fit</code>.</p>
</td></tr>
<tr><td><code id="as.matrix.htlr.fit_+3A_k">k</code></td>
<td>
<p>Coefficients associated with class <code>k</code> will be drawn. Must be a positive integer in 
1,2,...,C-1 for C-class traning labels (base class 0 can not be chosen). By default the last class
is selected. For binary logistic model this argument can be ignored.</p>
</td></tr>
<tr><td><code id="as.matrix.htlr.fit_+3A_include.warmup">include.warmup</code></td>
<td>
<p>Whether or not to include warmup samples</p>
</td></tr>
<tr><td><code id="as.matrix.htlr.fit_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with <code>(p + 1)</code> columns and <code>i</code> rows, where <code>p</code> is the number of features 
excluding intercept, and <code>i</code> is the number of iterations after burnin.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## No. of features used: 100; No. of iterations after burnin: 15 
fit &lt;- htlr(X = colon$X, y = colon$y, fsel = 1:100, iter = 20, warmup = 5)

dim(as.matrix(fit))
  
</code></pre>

<hr>
<h2 id='bcbcsf_deltas'>Bias-corrected Bayesian classification initial state</h2><span id='topic+bcbcsf_deltas'></span>

<h3>Description</h3>

<p>Generate initial Markov chain state with Bias-corrected Bayesian classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcbcsf_deltas(X, y, alpha = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bcbcsf_deltas_+3A_x">X</code></td>
<td>
<p>Design matrix of traning data; 
rows should be for the cases, and columns for different features.</p>
</td></tr>
<tr><td><code id="bcbcsf_deltas_+3A_y">y</code></td>
<td>
<p>Vector of class labels in training or test data set. 
Must be coded as non-negative integers, e.g., 1,2,...,C for C classes.</p>
</td></tr>
<tr><td><code id="bcbcsf_deltas_+3A_alpha">alpha</code></td>
<td>
<p>The regularization proportion (between 0 and 1) for mixing the 
diagonal covariance estimates and the sample covariance estimated with the 
training samples. The default is 0, the covariance matrix is assumed to be diagonal, 
which is the most robust.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Caveat: This method can be used only for continuous predictors such as gene expression profiles, 
and it does not make sense for categorical predictors such as SNP profiles.
</p>


<h3>Value</h3>

<p>A matrix - the initial state of Markov Chain for HTLR model fitting.
</p>


<h3>References</h3>

<p>Longhai Li (2012). Bias-corrected hierarchical Bayesian classification 
with a selected subset of high-dimensional features. 
<em>Journal of the American Statistical Association</em>, 107(497), 120-134.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lasso_deltas">lasso_deltas</a></code>
</p>

<hr>
<h2 id='colon'>Colon Tissues</h2><span id='topic+colon'></span>

<h3>Description</h3>

<p>In this dataset, expression levels of 40 tumor and 22 normal colon tissues 
for 6500 human genes are measured using the Affymetrix technology. 
A selection of 2000 genes with highest minimal intensity across the samples
has been made by Alon et al. (1999). The data is preprocessed by carrying out 
a base 10 logarithmic transformation and standardizing each tissue sample to 
zero mean and unit variance across the genes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("colon")
</code></pre>


<h3>Format</h3>

<p>A list contains data matrix <code>X</code> and response vector <code>y</code>:
</p>

<dl>
<dt>X</dt><dd><p>A matrix with 66 rows (observations) and 2000 columns (features).</p>
</dd>
<dt>y</dt><dd><p>A binary vector where 0 indicates normal colon tissues and 1 indicates tumor colon tissues.</p>
</dd>
</dl>



<h3>References</h3>

<p>Dettling Marcel, and Peter BÃ¼hlmann (2002). Supervised clustering of genes.
<em>Genome biology</em>, 3(12), research0069-1.
</p>

<hr>
<h2 id='diabetes392'>Pima Indians Diabetes</h2><span id='topic+diabetes392'></span>

<h3>Description</h3>

<p>This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases.
The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, 
based on certain diagnostic measurements included in the dataset. Several constraints were placed 
on the selection of these instances from a larger database. In particular, all patients here are 
females at least 21 years old of Pima Indian heritage. Different from the UCI original version, 
the dataset has been preprocessed such that rows with missing values are removed, and features are scaled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("diabetes392")
</code></pre>


<h3>Format</h3>

<p>A list contains data matrix <code>X</code> and response vector <code>y</code>:
</p>

<dl>
<dt>X</dt><dd><p>A matrix with 392 rows (observations) and 8 columns (features).</p>
</dd>
<dt>y</dt><dd><p>A binary vector where 1 indicates diabetes patients and 0 for otherwise.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.kaggle.com/uciml/pima-indians-diabetes-database">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a>
</p>


<h3>References</h3>

<p>Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., &amp; Johannes, R.S. (1988). 
Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. 
<em>In Proceedings of the Symposium on Computer Applications and Medical Care</em> (pp. 261&ndash;265). 
IEEE Computer Society Press.
</p>


<h3>See Also</h3>

<p><a href="https://avehtari.github.io/modelselection/diabetes.html">https://avehtari.github.io/modelselection/diabetes.html</a>
</p>

<hr>
<h2 id='evaluate_pred'>Evaluate Prediction Results</h2><span id='topic+evaluate_pred'></span>

<h3>Description</h3>

<p>This function compares the prediction results returned by a classifier with ground truth, 
and finally gives a summary of the evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate_pred(y.pred, y.true, caseid = names(y.true), showplot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate_pred_+3A_y.pred">y.pred</code></td>
<td>
<p>A matrix of predicted probabilities, as returned by a classifier.</p>
</td></tr>
<tr><td><code id="evaluate_pred_+3A_y.true">y.true</code></td>
<td>
<p>Ground truth labels vector.</p>
</td></tr>
<tr><td><code id="evaluate_pred_+3A_caseid">caseid</code></td>
<td>
<p>The names of test cases which we take account of. By default all test cases are used for evaluation.</p>
</td></tr>
<tr><td><code id="evaluate_pred_+3A_showplot">showplot</code></td>
<td>
<p>Logical; if <code>TRUE</code>, a summary plot will be generated.</p>
</td></tr>
<tr><td><code id="evaluate_pred_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of evaluation result.
</p>

<hr>
<h2 id='gendata_FAM'>Generate Simulated Data with Factor Analysis Model</h2><span id='topic+gendata_FAM'></span>

<h3>Description</h3>

<p>This function generates inputs <code>X</code> given by the response variable <code>y</code> 
using a multivariate normal model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendata_FAM(n, muj, A, sd_g = 0, stdx = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendata_FAM_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="gendata_FAM_+3A_muj">muj</code></td>
<td>
<p>C by p matrix, with row c representing y = c, and column j representing <code class="reqn">x_j</code>.
Used to specify <code>y</code>.</p>
</td></tr>
<tr><td><code id="gendata_FAM_+3A_a">A</code></td>
<td>
<p>Factor loading matrix of size p by p, see details.</p>
</td></tr>
<tr><td><code id="gendata_FAM_+3A_sd_g">sd_g</code></td>
<td>
<p>Numeric value indicating noise level <code class="reqn">\delta</code>, see details.</p>
</td></tr>
<tr><td><code id="gendata_FAM_+3A_stdx">stdx</code></td>
<td>
<p>Logical; if <code>TRUE</code>, data <code>X</code> is standardized to have <code>mean = 0</code> and <code>sd = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The means of each covariate <code class="reqn">x_j</code> depend on <code>y</code> specified by the 
matrix <code>muj</code>; the covariate matrix <code class="reqn">\Sigma</code> of the multivariate normal 
is equal to <code class="reqn">AA^t\delta^2I</code>, where <code>A</code> is the factor loading matrix
and <code class="reqn">\delta</code> is the noise level.
</p>


<h3>Value</h3>

<p>A list contains input matrix <code>X</code>, response variables <code>y</code>,
covariate matrix <code>SGM</code> and <code>muj</code> (standardized if <code>stdx = TRUE</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gendata_MLR">gendata_MLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## feature #1: marginally related feature
## feature #2: marginally unrelated feature, but feature #2 is correlated with feature #1
## feature #3-5: marginally related features and also internally correlated
## feature #6-10: noise features without relationship with the y

set.seed(12345)
n &lt;- 100
p &lt;- 10

means &lt;- rbind(
  c(0, 1, 0),
  c(0, 0, 0),
  c(0, 0, 1),
  c(0, 0, 1),
  c(0, 0, 1)
) * 2

means &lt;- rbind(means, matrix(0, p - 5, 3))

A &lt;- diag(1, p)
A[1:5, 1:3] &lt;- rbind(
  c(1, 0, 0),
  c(2, 1, 0),
  c(0, 0, 1),
  c(0, 0, 1),
  c(0, 0, 1)
)

dat &lt;- gendata_FAM(n, means, A, sd_g = 0.5, stdx = TRUE)
ggplot2::qplot(dat$y, bins = 6)
corrplot::corrplot(cor(dat$X))

</code></pre>

<hr>
<h2 id='gendata_MLR'>Generate Simulated Data with Multinomial Logistic Regression Model</h2><span id='topic+gendata_MLR'></span>

<h3>Description</h3>

<p>This function generates the response variables <code>y</code> given 
optional supplied <code>X</code> using a multinomial logistic regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendata_MLR(n, p, NC = 3, nu = 2, w = 1, X = NULL, betas = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendata_MLR_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="gendata_MLR_+3A_p">p</code></td>
<td>
<p>Number of features.</p>
</td></tr>
<tr><td><code id="gendata_MLR_+3A_nc">NC</code></td>
<td>
<p>Number of classes for response variables.</p>
</td></tr>
<tr><td><code id="gendata_MLR_+3A_nu">nu</code>, <code id="gendata_MLR_+3A_w">w</code></td>
<td>
<p>If <code>betas</code> is not supplied (default), the regression coefficients are generated with 
t prior with df = <code>nu</code>, scale = <code>sqrt(w)</code>; will be ignored if <code>betas</code> is supplied.</p>
</td></tr>
<tr><td><code id="gendata_MLR_+3A_x">X</code></td>
<td>
<p>The design matrix; will be generated from standard normal distribution if not supplied.</p>
</td></tr>
<tr><td><code id="gendata_MLR_+3A_betas">betas</code></td>
<td>
<p>User supplied regression coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list contains input matrix <code>X</code>, response variables <code>y</code>, and regression coefficients <code>deltas</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gendata_FAM">gendata_FAM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
dat &lt;- gendata_MLR(n = 100, p = 10)
ggplot2::qplot(dat$y, bins = 6)
corrplot::corrplot(cor(dat$X))

</code></pre>

<hr>
<h2 id='htlr'>Fit a HTLR Model</h2><span id='topic+htlr'></span>

<h3>Description</h3>

<p>This function trains linear logistic regression models with HMC in restricted Gibbs sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htlr(
  X,
  y,
  fsel = 1:ncol(X),
  stdx = TRUE,
  prior = "t",
  df = 1,
  iter = 2000,
  warmup = floor(iter/2),
  thin = 1,
  init = "lasso",
  leap = 50,
  leap.warm = floor(leap/10),
  leap.stepsize = 0.3,
  cut = 0.05,
  verbose = FALSE,
  rep.legacy = FALSE,
  keep.warmup.hist = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htlr_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension nobs by nvars; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="htlr_+3A_y">y</code></td>
<td>
<p>Vector of response variables. Must be coded as non-negative integers, 
e.g., 1,2,...,C for C classes, label 0 is also allowed.</p>
</td></tr>
<tr><td><code id="htlr_+3A_fsel">fsel</code></td>
<td>
<p>Subsets of features selected before fitting, such as by univariate screening.</p>
</td></tr>
<tr><td><code id="htlr_+3A_stdx">stdx</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the original feature values are standardized to have <code>mean = 0</code> 
and <code>sd = 1</code>.</p>
</td></tr>
<tr><td><code id="htlr_+3A_prior">prior</code></td>
<td>
<p>The prior to be applied to the model. Either a list of hyperparameter settings 
returned by <code><a href="#topic+htlr_prior">htlr_prior</a></code> or a character string from &quot;t&quot; (student-t), &quot;ghs&quot; (horseshoe), 
and &quot;neg&quot; (normal-exponential-gamma).</p>
</td></tr>
<tr><td><code id="htlr_+3A_df">df</code></td>
<td>
<p>The degree freedom of t/ghs/neg prior for coefficients. Will be ignored if the 
configuration list from <code><a href="#topic+htlr_prior">htlr_prior</a></code> is passed to <code>prior</code>.</p>
</td></tr>
<tr><td><code id="htlr_+3A_iter">iter</code></td>
<td>
<p>A positive integer specifying the number of iterations (including warmup).</p>
</td></tr>
<tr><td><code id="htlr_+3A_warmup">warmup</code></td>
<td>
<p>A positive integer specifying the number of warmup (aka burnin). 
The number of warmup iterations should not be larger than iter and the default is <code>iter / 2</code>.</p>
</td></tr>
<tr><td><code id="htlr_+3A_thin">thin</code></td>
<td>
<p>A positive integer specifying the period for saving samples.</p>
</td></tr>
<tr><td><code id="htlr_+3A_init">init</code></td>
<td>
<p>The initial state of Markov Chain; it accepts three forms:
</p>
 
<ul>
<li><p> a previously fitted <code>fithtlr</code> object, 
</p>
</li>
<li><p>  a user supplied initial coeficient matrix of (p+1)*K, where p is the number of features, K is the number of classes in y minus 1, 
</p>
</li>
<li><p> a character string matches the following:  
</p>

<ul>
<li><p> &quot;lasso&quot; - (Default) Use Lasso initial state with <code>lambda</code> chosen by 
cross-validation. Users may specify their own candidate <code>lambda</code> values via 
optional argument <code>lasso.lambda</code>. Further customized Lasso initial 
states can be generated by <code><a href="#topic+lasso_deltas">lasso_deltas</a></code>.    
</p>
</li>
<li><p> &quot;bcbc&quot; - Use initial state generated by package <code>BCBCSF</code> 
(Bias-corrected Bayesian classification). Further customized BCBCSF initial 
states can be generated by <code><a href="#topic+bcbcsf_deltas">bcbcsf_deltas</a></code>. WARNING: This type of 
initial states can be used for continuous features such as gene expression profiles, 
but it should not be used for categorical features such as SNP profiles.
</p>
</li>
<li><p> &quot;random&quot; - Use random initial values sampled from N(0, 1).     
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="htlr_+3A_leap">leap</code></td>
<td>
<p>The length of leapfrog trajectory in sampling phase.</p>
</td></tr>
<tr><td><code id="htlr_+3A_leap.warm">leap.warm</code></td>
<td>
<p>The length of leapfrog trajectory in burnin phase.</p>
</td></tr>
<tr><td><code id="htlr_+3A_leap.stepsize">leap.stepsize</code></td>
<td>
<p>The integrator step size used in the Hamiltonian simulation.</p>
</td></tr>
<tr><td><code id="htlr_+3A_cut">cut</code></td>
<td>
<p>The coefficients smaller than this criteria will be fixed in each HMC updating step.</p>
</td></tr>
<tr><td><code id="htlr_+3A_verbose">verbose</code></td>
<td>
<p>Logical; setting it to <code>TRUE</code> for tracking MCMC sampling iterations.</p>
</td></tr>
<tr><td><code id="htlr_+3A_rep.legacy">rep.legacy</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the output produced in <code>HTLR</code> versions up to 
legacy-3.1-1 is reproduced. The speed will be typically slower than non-legacy mode on
multi-core machine. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="htlr_+3A_keep.warmup.hist">keep.warmup.hist</code></td>
<td>
<p>Warmup iterations are not recorded by default, set <code>TRUE</code> to enable it.</p>
</td></tr>
<tr><td><code id="htlr_+3A_...">...</code></td>
<td>
<p>Other optional parameters:
</p>

<ul>
<li><p> rda.alpha - A user supplied alpha value for <code><a href="#topic+bcbcsf_deltas">bcbcsf_deltas</a></code>. Default: 0.2.
</p>
</li>
<li><p> lasso.lambda - A user supplied lambda sequence for <code><a href="#topic+lasso_deltas">lasso_deltas</a></code>. 
Default: {.01, .02, ..., .05}. Will be ignored if <code>rep.legacy</code> is set to <code>TRUE</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class <code>htlr.fit</code>.
</p>


<h3>References</h3>

<p>Longhai Li and Weixin Yao (2018). Fully Bayesian Logistic Regression 
with Hyper-Lasso Priors for High-dimensional Feature Selection.
<em>Journal of Statistical Computation and Simulation</em> 2018, 88:14, 2827-2851.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
data("colon")

## fit HTLR models with selected features, note that the chain length setting is for demo only

## using t prior with 1 df and log-scale fixed to -10 
fit.t &lt;- htlr(X = colon$X, y = colon$y, fsel = 1:100,
              prior = htlr_prior("t", df = 1, logw = -10), 
              init = "bcbc", iter = 20, thin = 1)

## using NEG prior with 1 df and log-scale fixed to -10 
fit.neg &lt;- htlr(X = colon$X, y = colon$y, fsel = 1:100,
                prior = htlr_prior("neg", df = 1, logw = -10), 
                init = "bcbc", iter = 20, thin = 1)

## using horseshoe prior with 1 df and auto-selected log-scale   
fit.ghs &lt;- htlr(X = colon$X, y = colon$y, fsel = 1:100,
                prior = "ghs", df = 1, init = "bcbc",
                iter = 20, thin = 1)

</code></pre>

<hr>
<h2 id='htlr_fit'>Fit a HTLR Model (Internal API)</h2><span id='topic+htlr_fit'></span>

<h3>Description</h3>

<p>This function trains linear logistic regression models with HMC in restricted Gibbs sampling.
It also makes predictions for test cases if <code>X_ts</code> are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htlr_fit(
  X_tr,
  y_tr,
  fsel = 1:ncol(X_tr),
  stdzx = TRUE,
  ptype = c("t", "ghs", "neg"),
  sigmab0 = 2000,
  alpha = 1,
  s = -10,
  eta = 0,
  iters_h = 1000,
  iters_rmc = 1000,
  thin = 1,
  leap_L = 50,
  leap_L_h = 5,
  leap_step = 0.3,
  hmc_sgmcut = 0.05,
  initial_state = "lasso",
  keep.warmup.hist = FALSE,
  silence = TRUE,
  rep.legacy = TRUE,
  alpha.rda = 0.2,
  lasso.lambda = seq(0.05, 0.01, by = -0.01),
  X_ts = NULL,
  predburn = NULL,
  predthin = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htlr_fit_+3A_x_tr">X_tr</code></td>
<td>
<p>Input matrix, of dimension nobs by nvars; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_y_tr">y_tr</code></td>
<td>
<p>Vector of response variables. Must be coded as non-negative integers, 
e.g., 1,2,...,C for C classes, label 0 is also allowed.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_fsel">fsel</code></td>
<td>
<p>Subsets of features selected before fitting, such as by univariate screening.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_stdzx">stdzx</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the original feature values are standardized to have <code>mean = 0</code> 
and <code>sd = 1</code>.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_ptype">ptype</code></td>
<td>
<p>The prior to be applied to the model. Either &quot;t&quot; (student-t, default), 
&quot;ghs&quot; (horseshoe), or &quot;neg&quot; (normal-exponential-gamma).</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_sigmab0">sigmab0</code></td>
<td>
<p>The <code>sd</code> of the normal prior for the intercept.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_alpha">alpha</code></td>
<td>
<p>The degree freedom of t/ghs/neg prior for coefficients.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_s">s</code></td>
<td>
<p>The log scale of priors (logw) for coefficients.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_eta">eta</code></td>
<td>
<p>The <code>sd</code> of the normal prior for logw. When it is set to 0, logw is fixed. 
Otherwise, logw is assigned with a normal prior and it will be updated during sampling.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_iters_h">iters_h</code></td>
<td>
<p>A positive integer specifying the number of warmup (aka burnin).</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_iters_rmc">iters_rmc</code></td>
<td>
<p>A positive integer specifying the number of iterations after warmup.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_thin">thin</code></td>
<td>
<p>A positive integer specifying the period for saving samples.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_leap_l">leap_L</code></td>
<td>
<p>The length of leapfrog trajectory in sampling phase.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_leap_l_h">leap_L_h</code></td>
<td>
<p>The length of leapfrog trajectory in burnin phase.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_leap_step">leap_step</code></td>
<td>
<p>The stepsize adjustment multiplied to the second-order partial derivatives of log posterior.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_hmc_sgmcut">hmc_sgmcut</code></td>
<td>
<p>The coefficients smaller than this criteria will be fixed in 
each HMC updating step.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_initial_state">initial_state</code></td>
<td>
<p>The initial state of Markov Chain; can be a previously 
fitted <code>fithtlr</code> object, or a user supplied initial state vector, or 
a character string matches the following:  
</p>

<ul>
<li><p> &quot;lasso&quot; - (Default) Use Lasso initial state with <code>lambda</code> chosen by 
cross-validation. Users may specify their own candidate <code>lambda</code> values via 
optional argument <code>lasso.lambda</code>. Further customized Lasso initial 
states can be generated by <code><a href="#topic+lasso_deltas">lasso_deltas</a></code>.    
</p>
</li>
<li><p> &quot;bcbcsfrda&quot; - Use initial state generated by package <code>BCBCSF</code> 
(Bias-corrected Bayesian classification). Further customized BCBCSF initial 
states can be generated by <code><a href="#topic+bcbcsf_deltas">bcbcsf_deltas</a></code>. WARNING: This type of 
initial states can be used for continuous features such as gene expression profiles, 
but it should not be used for categorical features such as SNP profiles.
</p>
</li>
<li><p> &quot;random&quot; - Use random initial values sampled from N(0, 1).     
</p>
</li></ul>
</td></tr>
<tr><td><code id="htlr_fit_+3A_keep.warmup.hist">keep.warmup.hist</code></td>
<td>
<p>Warmup iterations are not recorded by default, set <code>TRUE</code> to enable it.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_silence">silence</code></td>
<td>
<p>Setting it to <code>FALSE</code> for tracking MCMC sampling iterations.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_rep.legacy">rep.legacy</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the output produced in <code>HTLR</code> versions up to 
legacy-3.1-1 is reproduced. The speed would be typically slower than non-legacy mode on
multi-core machine.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_alpha.rda">alpha.rda</code></td>
<td>
<p>A user supplied alpha value for <code><a href="#topic+bcbcsf_deltas">bcbcsf_deltas</a></code> when
setting up BCBCSF initial state. Default: 0.2.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_lasso.lambda">lasso.lambda</code></td>
<td>
<p>- A user supplied lambda sequence for <code><a href="#topic+lasso_deltas">lasso_deltas</a></code> when 
setting up Lasso initial state. Default: {.01, .02, ..., .05}. Will be ignored if 
<code>rep.legacy</code> is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_x_ts">X_ts</code></td>
<td>
<p>Test data which predictions are to be made.</p>
</td></tr>
<tr><td><code id="htlr_fit_+3A_predburn">predburn</code>, <code id="htlr_fit_+3A_predthin">predthin</code></td>
<td>
<p>For prediction base on <code>X_ts</code> (when supplied), <code>predburn</code> of 
Markov chain (super)iterations will be discarded, and only every <code>predthin</code> are used for inference.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of fitting results. If <code>X_ts</code> is not provided, the list is an object 
with S3 class <code>htlr.fit</code>.
</p>


<h3>References</h3>

<p>Longhai Li and Weixin Yao (2018). Fully Bayesian Logistic Regression 
with Hyper-Lasso Priors for High-dimensional Feature Selection.
<em>Journal of Statistical Computation and Simulation</em> 2018, 88:14, 2827-2851.
</p>

<hr>
<h2 id='htlr_predict'>Make Prediction on New Data (Advanced)</h2><span id='topic+htlr_predict'></span>

<h3>Description</h3>

<p>This function uses MCMC samples from fitted <code>htlrfit</code> object OR user supplied 
regression coefficient to predict the class labels of test cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htlr_predict(
  X_ts,
  fithtlr = NULL,
  deltas = NULL,
  burn = NULL,
  thin = 1,
  usedmc = NULL,
  rep.legacy = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htlr_predict_+3A_x_ts">X_ts</code></td>
<td>
<p>Matrix of values at which predictions are to be made.</p>
</td></tr>
<tr><td><code id="htlr_predict_+3A_fithtlr">fithtlr</code></td>
<td>
<p>Fitted HTLR model object.</p>
</td></tr>
<tr><td><code id="htlr_predict_+3A_deltas">deltas</code></td>
<td>
<p>The values of deltas (for example true deltas) used to make prediction; 
will override <code>fithtlr</code> if provided.</p>
</td></tr>
<tr><td><code id="htlr_predict_+3A_burn">burn</code>, <code id="htlr_predict_+3A_thin">thin</code></td>
<td>
<p><code>burn</code> of Markov chain (super)iterations will be discarded for prediction,
and only every <code>thin</code> are used.</p>
</td></tr>
<tr><td><code id="htlr_predict_+3A_usedmc">usedmc</code></td>
<td>
<p>Indices of Markov chain iterations used for inference. 
If supplied, <code>burn</code> and <code>thin</code> will be ignored.</p>
</td></tr>
<tr><td><code id="htlr_predict_+3A_rep.legacy">rep.legacy</code></td>
<td>
<p>To reproduce (actually incorrect) results in legacy version.
See <a href="https://github.com/longhaiSK/HTLR/issues/7">https://github.com/longhaiSK/HTLR/issues/7</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictive probabilities, with rows for cases, cols for classes.
</p>

<hr>
<h2 id='htlr_prior'>Generate Prior Configuration</h2><span id='topic+htlr_prior'></span>

<h3>Description</h3>

<p>Configure prior hyper-parameters for HTLR model fitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htlr_prior(
  ptype = c("t", "ghs", "neg"),
  df = 1,
  logw = -(1/df) * 10,
  eta = ifelse(df &gt; 1, 3, 0),
  sigmab0 = 2000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htlr_prior_+3A_ptype">ptype</code></td>
<td>
<p>The prior to be applied to the model. Either &quot;t&quot; (student-t, default), &quot;ghs&quot; (horseshoe), 
or &quot;neg&quot; (normal-exponential-gamma).</p>
</td></tr>
<tr><td><code id="htlr_prior_+3A_df">df</code></td>
<td>
<p>The degree freedom (aka alpha) of t/ghs/neg prior for coefficients.</p>
</td></tr>
<tr><td><code id="htlr_prior_+3A_logw">logw</code></td>
<td>
<p>The log scale of priors for coefficients.</p>
</td></tr>
<tr><td><code id="htlr_prior_+3A_eta">eta</code></td>
<td>
<p>The <code>sd</code> of the normal prior for logw. When it is set to 0, logw is fixed. 
Otherwise, logw is assigned with a normal prior and it will be updated during sampling.</p>
</td></tr>
<tr><td><code id="htlr_prior_+3A_sigmab0">sigmab0</code></td>
<td>
<p>The <code>sd</code> of the normal prior for the intercept.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output is a configuration list which is to be passed to <code>prior</code> argument of <code>htlr</code>.     
For naive users, you only need to specify the prior type and degree freedom, then the other hyper-parameters
will be chosen automatically. For advanced users, you can supply each prior hyper-parameters by yourself.
For suggestion of picking hyper-parameters, see <code>references</code>.
</p>


<h3>Value</h3>

<p>A configuration list containing <code>ptype</code>, <code>alpha</code>, <code>logw</code>, <code>eta</code>, and <code>sigmab0</code>.
</p>


<h3>References</h3>

<p>Longhai Li and Weixin Yao. (2018). Fully Bayesian Logistic Regression 
with Hyper-Lasso Priors for High-dimensional Feature Selection.
<em>Journal of Statistical Computation and Simulation</em> 2018, 88:14, 2827-2851.
</p>

<hr>
<h2 id='lasso_deltas'>Lasso Initial State</h2><span id='topic+lasso_deltas'></span>

<h3>Description</h3>

<p>Generate initial Markov chain state with Lasso.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso_deltas(
  X,
  y,
  lambda = NULL,
  verbose = FALSE,
  alpha = 1,
  rank_fn = order_plain,
  k = ncol(X)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lasso_deltas_+3A_x">X</code></td>
<td>
<p>Design matrix of traning data; 
rows should be for the cases, and columns for different features.</p>
</td></tr>
<tr><td><code id="lasso_deltas_+3A_y">y</code></td>
<td>
<p>Vector of class labels in training or test data set. 
Must be coded as non-negative integers, e.g., 1,2,...,C for C classes.</p>
</td></tr>
<tr><td><code id="lasso_deltas_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence for <code>glmnet</code> cross-validation.
<code>NULL</code> by default, and it will be generated by <code>glmnet</code>.</p>
</td></tr>
<tr><td><code id="lasso_deltas_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter for <code>glmnet</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix - the initial state of Markov Chain for HTLR model fitting.
</p>


<h3>References</h3>

<p>Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010).
Regularization Paths for Generalized Linear Models via Coordinate
Descent. <em>Journal of Statistical Software</em>, 33(1), 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bcbcsf_deltas">bcbcsf_deltas</a></code>
</p>

<hr>
<h2 id='nzero_idx'>Get Indices of Non-Zero Coefficients</h2><span id='topic+nzero_idx'></span>

<h3>Description</h3>

<p>Get the indices of non-zero coefficients from fitted HTLR model objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nzero_idx(fit, cut = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nzero_idx_+3A_fit">fit</code></td>
<td>
<p>An object of S3 class <code>htlr.fit</code>.</p>
</td></tr>
<tr><td><code id="nzero_idx_+3A_cut">cut</code></td>
<td>
<p>Threshold on relative SDB to distinguish zero coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Indices vector of non-zero coefficients in the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
data("colon")

fit &lt;- htlr(X = colon$X, y = colon$y, fsel = 1:100, iter = 20)
nzero_idx(fit)

</code></pre>

<hr>
<h2 id='order_ftest'>Order features by F-statistic</h2><span id='topic+order_ftest'></span>

<h3>Description</h3>

<p>This function orders all features in terms of ANOVA F-statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>order_ftest(X, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="order_ftest_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension <code>nobs</code> by <code>nvars</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="order_ftest_+3A_y">y</code></td>
<td>
<p>Vector of response variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Order of all features of length <code>nvars</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("diabetes392")
order_ftest(diabetes392$X, diabetes392$y)

</code></pre>

<hr>
<h2 id='order_kruskal'>Order features by Kruskal-Wallis test</h2><span id='topic+order_kruskal'></span>

<h3>Description</h3>

<p>This function orders all features in terms of Kruskal-Wallis test p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>order_kruskal(X, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="order_kruskal_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension <code>nobs</code> by <code>nvars</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="order_kruskal_+3A_y">y</code></td>
<td>
<p>Vector of response variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Order of all features of length <code>nvars</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("diabetes392")
order_kruskal(diabetes392$X, diabetes392$y)

</code></pre>

<hr>
<h2 id='order_plain'>Plain order function</h2><span id='topic+order_plain'></span>

<h3>Description</h3>

<p>A placeholder order function that returns the original order of given features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>order_plain(X, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="order_plain_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension <code>nobs</code> by <code>nvars</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="order_plain_+3A_y">y</code></td>
<td>
<p>Vector of response variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sequence starting from 1 to <code>nvars</code>.
</p>

<hr>
<h2 id='predict.htlr.fit'>Make Prediction on New Data</h2><span id='topic+predict.htlr.fit'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this function returns predictions from a fitted <code>htlrfit</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'htlr.fit'
predict(object, newx, type = c("response", "class"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.htlr.fit_+3A_object">object</code></td>
<td>
<p>A fitted model object with S3 class <code>htlrfit</code>.</p>
</td></tr>
<tr><td><code id="predict.htlr.fit_+3A_newx">newx</code></td>
<td>
<p>A Matrix of values at which predictions are to be made.</p>
</td></tr>
<tr><td><code id="predict.htlr.fit_+3A_type">type</code></td>
<td>
<p>Type of prediction required. Type &quot;response&quot; gives the fitted probabilities.
Type &quot;class&quot; produces the class label corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="predict.htlr.fit_+3A_...">...</code></td>
<td>
<p>Advanced options to specify the Markov chain iterations used for inference. 
See <code><a href="#topic+htlr_predict">htlr_predict</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.
</p>

<hr>
<h2 id='split_data'>Split Data into Train and Test Partitions</h2><span id='topic+split_data'></span>

<h3>Description</h3>

<p>This function splits the input data and response variables into training and testing parts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_data(X, y, p.train = 0.7, n.train = round(nrow(X) * p.train))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_data_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension <code>nobs</code> by <code>nvars</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="split_data_+3A_y">y</code></td>
<td>
<p>Vector of response variables.</p>
</td></tr>
<tr><td><code id="split_data_+3A_p.train">p.train</code></td>
<td>
<p>Percentage of training set.</p>
</td></tr>
<tr><td><code id="split_data_+3A_n.train">n.train</code></td>
<td>
<p>Number of cases for training; will override <code>p.train</code> if specified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of training data <code>x.tr</code>, <code>y.tr</code> and testing data <code>x.te</code>, <code>y.te</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- gendata_MLR(n = 100, p = 10)
dat &lt;- split_data(dat$X, dat$y, p.train = 0.7)
dim(dat$x.tr)
dim(dat$x.te)
   
</code></pre>

<hr>
<h2 id='std'>Standardizes a Design Matrix</h2><span id='topic+std'></span>

<h3>Description</h3>

<p>This function accepts a design matrix and returns a standardized version of that matrix, 
the statistics of each column such as <code>median</code> and <code>sd</code> are also provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std(X, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="std_+3A_x">X</code></td>
<td>
<p>Design matrix, of dimension <code>nobs</code> by <code>nvars</code>; each row is an observation vector; 
can also be an object that can be coerced to a matrix, e.g. a data.frame.</p>
</td></tr>
<tr><td><code id="std_+3A_tol">tol</code></td>
<td>
<p>The tolerance value; a column of <code>X</code> is considered as singular if the <code>sd</code>
of its entries (observations) is less than <code>tol</code>. Singular columns will be dropped by the end.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each column of <code>X</code>, the standardization is done by first subtracting its median, 
then dividing by its sample standard deviation, while the original version in <code>ncvreg</code> uses
mean and population standard deviation. Its speed is slower than <code>ncvreg</code> because of the
complexity of median finding, but still substantially faster than <code>scale()</code> provided by R base.
</p>


<h3>Value</h3>

<p>The standardized design matrix with the following attributes:
</p>

<dl>
<dt>nonsingular</dt><dd><p>Indices of non-singular columns.</p>
</dd>
<dt>center</dt><dd><p>Median of each non-singular column which is used for standardization.</p>
</dd>
<dt>scale</dt><dd><p>Standard deviation of each non-singular column which is used for standardization.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Patrick Breheny (original) <br /> Steven Liu (modification)
</p>


<h3>See Also</h3>

<p><a href="http://pbreheny.github.io/ncvreg/reference/std.html">http://pbreheny.github.io/ncvreg/reference/std.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
mat &lt;- matrix(rnorm(n = 80 * 90, mean = 100, sd = 50), 80, 90)
mat %&gt;% as.numeric() %&gt;% ggplot2::qplot(bins = 30, xlab = '')
mat %&gt;% std() %&gt;% as.numeric() %&gt;% ggplot2::qplot(bins = 30, xlab = '')
 
</code></pre>

<hr>
<h2 id='summary.htlr.fit'>Posterior Summaries</h2><span id='topic+summary.htlr.fit'></span>

<h3>Description</h3>

<p>This function gives a summary of posterior of parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'htlr.fit'
summary(
  object,
  features = 1L:object$p,
  method = median,
  usedmc = get_sample_indice(dim(object$mcdeltas)[3], object$mc.param$iter.rmc),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.htlr.fit_+3A_object">object</code></td>
<td>
<p>An object of S3 class <code>htlr.fit</code>.</p>
</td></tr>
<tr><td><code id="summary.htlr.fit_+3A_features">features</code></td>
<td>
<p>A vector of indices (int) or names (char) that specify the parameters we will look at.
By default all parameters are selected.</p>
</td></tr>
<tr><td><code id="summary.htlr.fit_+3A_method">method</code></td>
<td>
<p>A function that is used to aggregate the MCMC samples. The default is <code>median</code>, 
other built-in/customized statistical functions such as <code>mean</code>, <code>sd</code>, and <code>mad</code>
can also be used.</p>
</td></tr>
<tr><td><code id="summary.htlr.fit_+3A_usedmc">usedmc</code></td>
<td>
<p>Indices of Markov chain iterations used for inference. By default all iterations are used.</p>
</td></tr>
<tr><td><code id="summary.htlr.fit_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A point summary of MCMC samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
data("colon")

fit &lt;- htlr(X = colon$X, y = colon$y, fsel = 1:100, iter = 20)
summary(fit, features = 1:16)
  
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
