<!DOCTYPE html><html lang="en"><head><title>Help for package elmNNRcpp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {elmNNRcpp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#elm'><p>Fit an extreme learning model</p></a></li>
<li><a href='#elm_predict'><p>Extreme Learning Machine predict function</p></a></li>
<li><a href='#elm_train'><p>Extreme Learning Machine training function</p></a></li>
<li><a href='#onehot_encode'><p>One-hot-encoding of the labels in case of classification</p></a></li>
<li><a href='#predict.elm'><p>Predict with elm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The Extreme Learning Machine Algorithm</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-01-27</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mlampros/elmNNRcpp/issues">https://github.com/mlampros/elmNNRcpp/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mlampros/elmNNRcpp">https://github.com/mlampros/elmNNRcpp</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Training and predict functions for Single Hidden-layer Feedforward Neural Networks (SLFN) using the Extreme Learning Machine (ELM) algorithm. The ELM algorithm differs from the traditional gradient-based algorithms for very short training times (it doesn't need any iterative tuning, this makes learning time very fast) and there is no need to set any other parameters like learning rate, momentum, epochs, etc. This is a reimplementation of the 'elmNN' package using 'RcppArmadillo' after the 'elmNN' package was archived. For more information, see "Extreme learning machine: Theory and applications" by Guang-Bin Huang, Qin-Yu Zhu, Chee-Kheong Siew (2006), Elsevier B.V, &lt;<a href="https://doi.org/10.1016%2Fj.neucom.2005.12.126">doi:10.1016/j.neucom.2005.12.126</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.0.2), KernelKnn</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.17)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo (&ge; 0.8)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-27 19:08:20 UTC; lampros</td>
</tr>
<tr>
<td>Author:</td>
<td>Lampros Mouselimis
    <a href="https://orcid.org/0000-0002-8024-1546"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Alberto Gosso [aut],
  Edwin de Jonge <a href="https://orcid.org/0000-0002-6580-4718"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (Github: Github Contributor)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lampros Mouselimis &lt;mouselimislampros@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-28 03:20:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='elm'>Fit an extreme learning model</h2><span id='topic+elm'></span>

<h3>Description</h3>

<p>Formula interface for <code><a href="#topic+elm_train">elm_train</a></code>, transforms a data frame and formula
into the necessary input for elm_train, automatically calls <code><a href="#topic+onehot_encode">onehot_encode</a></code>
for classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elm(
  formula,
  data,
  nhid,
  actfun,
  init_weights = "normal_gaussian",
  bias = FALSE,
  moorep_pseudoinv_tol = 0.01,
  leaky_relu_alpha = 0,
  seed = 1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elm_+3A_formula">formula</code></td>
<td>
<p>formula used to specify the regression or classification.</p>
</td></tr>
<tr><td><code id="elm_+3A_data">data</code></td>
<td>
<p>data.frame with the data</p>
</td></tr>
<tr><td><code id="elm_+3A_nhid">nhid</code></td>
<td>
<p>a numeric value specifying the hidden neurons. Must be &gt;= 1</p>
</td></tr>
<tr><td><code id="elm_+3A_actfun">actfun</code></td>
<td>
<p>a character string specifying the type of activation function. It should be one of the following : 'sig' <em>( sigmoid )</em>, 'sin' <em>( sine )</em>, 'radbas' <em>( radial basis )</em>, 'hardlim' <em>( hard-limit )</em>, 'hardlims' <em>( symmetric hard-limit )</em>, 'satlins' <em>( satlins )</em>, 'tansig' <em>( tan-sigmoid )</em>, 'tribas' <em>( triangular basis )</em>, 'relu' <em>( rectifier linear unit )</em> or 'purelin' <em>( linear )</em></p>
</td></tr>
<tr><td><code id="elm_+3A_init_weights">init_weights</code></td>
<td>
<p>a character string spcecifying the distribution from which the <em>input-weights</em> and the <em>bias</em> should be initialized. It should be one of the following : 'normal_gaussian' <em>(normal / Gaussian distribution with zero mean and unit variance)</em>, 'uniform_positive' <em>( in the range [0,1] )</em> or 'uniform_negative' <em>( in the range [-1,1] )</em></p>
</td></tr>
<tr><td><code id="elm_+3A_bias">bias</code></td>
<td>
<p>either TRUE or FALSE. If TRUE then <em>bias</em> weights will be added to the hidden layer</p>
</td></tr>
<tr><td><code id="elm_+3A_moorep_pseudoinv_tol">moorep_pseudoinv_tol</code></td>
<td>
<p>a numeric value. See the references web-link for more details on <em>Moore-Penrose pseudo-inverse</em> and specifically on the <em>pseudo inverse tolerance value</em></p>
</td></tr>
<tr><td><code id="elm_+3A_leaky_relu_alpha">leaky_relu_alpha</code></td>
<td>
<p>a numeric value between 0.0 and 1.0. If 0.0 then a simple <em>relu</em> ( f(x) = 0.0 for x &lt; 0, f(x) = x for x &gt;= 0 ) activation function will be used, otherwise a <em>leaky-relu</em> ( f(x) = alpha * x for x &lt; 0, f(x) = x for x &gt;= 0 ). It is applicable only if <em>actfun</em> equals to 'relu'</p>
</td></tr>
<tr><td><code id="elm_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the random seed. Defaults to 1</p>
</td></tr>
<tr><td><code id="elm_+3A_verbose">verbose</code></td>
<td>
<p>a boolean. If TRUE then information will be printed in the console</p>
</td></tr>
</table>


<h3>Value</h3>

<p>elm object which can be used with predict, residuals and fitted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>elm(Species ~ ., data = iris, nhid = 20, actfun="sig")

mod_elm &lt;- elm(Species ~ ., data = iris, nhid = 20, actfun="sig")

# predict classes
predict(mod_elm, newdata = iris[1:3,-5])

# predict probabilities
predict(mod_elm, newdata = iris[1:3,-5], type="prob")

# predict elm output
predict(mod_elm, newdata = iris[1:3,-5], type="raw")

data("Boston")
elm(medv ~ ., data = Boston, nhid = 40, actfun="relu")

data("ionosphere")
elm(class ~ ., data = ionosphere, nhid=20, actfun="relu")

</code></pre>

<hr>
<h2 id='elm_predict'>Extreme Learning Machine predict function</h2><span id='topic+elm_predict'></span>

<h3>Description</h3>

<p>Extreme Learning Machine predict function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elm_predict(elm_train_object, newdata, normalize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elm_predict_+3A_elm_train_object">elm_train_object</code></td>
<td>
<p>it should be the output of the <em>elm_train</em> function</p>
</td></tr>
<tr><td><code id="elm_predict_+3A_newdata">newdata</code></td>
<td>
<p>an input matrix with number of columns equal to the <em>x</em> parameter of the <em>elm_train</em> function</p>
</td></tr>
<tr><td><code id="elm_predict_+3A_normalize">normalize</code></td>
<td>
<p>a boolean specifying if the output predictions <em>in case of classification</em> should be normalized. If TRUE then the values of each row of the output-probability-matrix that are less than 0 and greater than 1 will be pushed to the [0,1] range</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(elmNNRcpp)

#-----------
# Regression
#-----------

data(Boston, package = 'KernelKnn')

Boston = as.matrix(Boston)
dimnames(Boston) = NULL

x = Boston[, -ncol(Boston)]
y = matrix(Boston[, ncol(Boston)], nrow = length(Boston[, ncol(Boston)]), ncol = 1)

out_regr = elm_train(x, y, nhid = 20, actfun = 'purelin', init_weights = 'uniform_negative')

pr_regr = elm_predict(out_regr, x)


#---------------
# Classification
#---------------

data(ionosphere, package = 'KernelKnn')

x_class = ionosphere[, -c(2, ncol(ionosphere))]
x_class = as.matrix(x_class)
dimnames(x_class) = NULL

y_class = as.numeric(ionosphere[, ncol(ionosphere)])

y_class_onehot = onehot_encode(y_class - 1)     # class labels should begin from 0

out_class = elm_train(x_class, y_class_onehot, nhid = 20, actfun = 'relu')

pr_class = elm_predict(out_class, x_class, normalize = TRUE)

</code></pre>

<hr>
<h2 id='elm_train'>Extreme Learning Machine training function</h2><span id='topic+elm_train'></span>

<h3>Description</h3>

<p>Extreme Learning Machine training function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elm_train(
  x,
  y,
  nhid,
  actfun,
  init_weights = "normal_gaussian",
  bias = FALSE,
  moorep_pseudoinv_tol = 0.01,
  leaky_relu_alpha = 0,
  seed = 1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="elm_train_+3A_x">x</code></td>
<td>
<p>a matrix. The columns of the input matrix should be of type numeric</p>
</td></tr>
<tr><td><code id="elm_train_+3A_y">y</code></td>
<td>
<p>a matrix. In case of regression the matrix should have <em>n</em> rows and <em>1</em> column. In case of classification it should consist of <em>n</em> rows and <em>n</em> columns, where <em>n &gt; 1</em> and equals to the number of the unique labels.</p>
</td></tr>
<tr><td><code id="elm_train_+3A_nhid">nhid</code></td>
<td>
<p>a numeric value specifying the hidden neurons. Must be &gt;= 1</p>
</td></tr>
<tr><td><code id="elm_train_+3A_actfun">actfun</code></td>
<td>
<p>a character string specifying the type of activation function. It should be one of the following : 'sig' <em>( sigmoid )</em>, 'sin' <em>( sine )</em>, 'radbas' <em>( radial basis )</em>, 'hardlim' <em>( hard-limit )</em>, 'hardlims' <em>( symmetric hard-limit )</em>, 'satlins' <em>( satlins )</em>, 'tansig' <em>( tan-sigmoid )</em>, 'tribas' <em>( triangular basis )</em>, 'relu' <em>( rectifier linear unit )</em> or 'purelin' <em>( linear )</em></p>
</td></tr>
<tr><td><code id="elm_train_+3A_init_weights">init_weights</code></td>
<td>
<p>a character string spcecifying the distribution from which the <em>input-weights</em> and the <em>bias</em> should be initialized. It should be one of the following : 'normal_gaussian' <em>(normal / Gaussian distribution with zero mean and unit variance)</em>, 'uniform_positive' <em>( in the range [0,1] )</em> or 'uniform_negative' <em>( in the range [-1,1] )</em></p>
</td></tr>
<tr><td><code id="elm_train_+3A_bias">bias</code></td>
<td>
<p>either TRUE or FALSE. If TRUE then <em>bias</em> weights will be added to the hidden layer</p>
</td></tr>
<tr><td><code id="elm_train_+3A_moorep_pseudoinv_tol">moorep_pseudoinv_tol</code></td>
<td>
<p>a numeric value. See the references web-link for more details on <em>Moore-Penrose pseudo-inverse</em> and specifically on the <em>pseudo inverse tolerance value</em></p>
</td></tr>
<tr><td><code id="elm_train_+3A_leaky_relu_alpha">leaky_relu_alpha</code></td>
<td>
<p>a numeric value between 0.0 and 1.0. If 0.0 then a simple <em>relu</em> ( f(x) = 0.0 for x &lt; 0, f(x) = x for x &gt;= 0 ) activation function will be used, otherwise a <em>leaky-relu</em> ( f(x) = alpha * x for x &lt; 0, f(x) = x for x &gt;= 0 ). It is applicable only if <em>actfun</em> equals to 'relu'</p>
</td></tr>
<tr><td><code id="elm_train_+3A_seed">seed</code></td>
<td>
<p>a numeric value specifying the random seed. Defaults to 1</p>
</td></tr>
<tr><td><code id="elm_train_+3A_verbose">verbose</code></td>
<td>
<p>a boolean. If TRUE then information will be printed in the console</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input matrix should be of type numeric. This means the user should convert any <em>character</em>, <em>factor</em> or <em>boolean</em> columns to numeric values before using the <em>elm_train</em> function
</p>


<h3>References</h3>

<p>http://arma.sourceforge.net/docs.html
</p>
<p>https://en.wikipedia.org/wiki/Moore
</p>
<p>https://www.kaggle.com/robertbm/extreme-learning-machine-example
</p>
<p>http://rt.dgyblog.com/ml/ml-elm.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(elmNNRcpp)

#-----------
# Regression
#-----------

data(Boston, package = 'KernelKnn')

Boston = as.matrix(Boston)
dimnames(Boston) = NULL

x = Boston[, -ncol(Boston)]
y = matrix(Boston[, ncol(Boston)], nrow = length(Boston[, ncol(Boston)]), ncol = 1)

out_regr = elm_train(x, y, nhid = 20, actfun = 'purelin', init_weights = 'uniform_negative')


#---------------
# Classification
#---------------

data(ionosphere, package = 'KernelKnn')

x_class = ionosphere[, -c(2, ncol(ionosphere))]
x_class = as.matrix(x_class)
dimnames(x_class) = NULL

y_class = as.numeric(ionosphere[, ncol(ionosphere)])

y_class_onehot = onehot_encode(y_class - 1)     # class labels should begin from 0

out_class = elm_train(x_class, y_class_onehot, nhid = 20, actfun = 'relu')

</code></pre>

<hr>
<h2 id='onehot_encode'>One-hot-encoding of the labels in case of classification</h2><span id='topic+onehot_encode'></span>

<h3>Description</h3>

<p>One-hot-encoding of the labels in case of classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onehot_encode(y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="onehot_encode_+3A_y">y</code></td>
<td>
<p>a numeric vector consisting of the response variable labels. The minimum value of the unique labels should begin from 0</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(elmNNRcpp)

y = sample(0:3, 100, replace = TRUE)

y_expand = onehot_encode(y)

</code></pre>

<hr>
<h2 id='predict.elm'>Predict with elm</h2><span id='topic+predict.elm'></span>

<h3>Description</h3>

<p>Wrapper for <code><a href="#topic+elm_predict">elm_predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'elm'
predict(object, newdata, type = c("class", "prob", "raw"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.elm_+3A_object">object</code></td>
<td>
<p>elm model fitted with <code><a href="#topic+elm">elm</a></code>.</p>
</td></tr>
<tr><td><code id="predict.elm_+3A_newdata">newdata</code></td>
<td>
<p>data.frame with the new data</p>
</td></tr>
<tr><td><code id="predict.elm_+3A_type">type</code></td>
<td>
<p>only used with classification, can be either &quot;class&quot;, &quot;prob&quot;, &quot;raw&quot;, 
which are class (vector), probability (matrix) or the output of the elm function (matrix).</p>
</td></tr>
<tr><td><code id="predict.elm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted values
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
