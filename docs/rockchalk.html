<!DOCTYPE html><html lang="en"><head><title>Help for package rockchalk</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rockchalk}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#rockchalk-package'><p>rockchalk: regression functions</p></a></li>
<li><a href='#addLines'><p>Superimpose regression lines on a plotted plane</p></a></li>
<li><a href='#centerNumerics'><p>Find numeric columns, center them, re-name them, and join them with the original data.</p></a></li>
<li><a href='#centralValues'><p>Central Tendency estimates for variables</p></a></li>
<li><a href='#cheating'><p>Cheating and Looting in Japanese Electoral Politics</p></a></li>
<li><a href='#checkIntFormat'><p>A way of checking if a string is a valid file name.</p></a></li>
<li><a href='#checkPosDef'><p>Check a matrix for positive definitness</p></a></li>
<li><a href='#combineLevels'><p>recode a factor by &quot;combining&quot; levels</p></a></li>
<li><a href='#cutByQuantile'><p>Calculates the &quot;center&quot; quantiles, always including the median, when n is odd.</p></a></li>
<li><a href='#cutBySD'><p>Returns center values of x, the mean, mean-std.dev, mean+std.dev</p></a></li>
<li><a href='#cutByTable'><p>Select most frequently occurring values from numeric or categorical variables.</p></a></li>
<li><a href='#cutFancy'><p>Create an ordinal variable by grouping numeric data input.</p></a></li>
<li><a href='#descriptiveTable'><p>Summary stats table-maker for regression users</p></a></li>
<li><a href='#dir.create.unique'><p>Create a uniquely named directory. Appends number &amp; optionally date to directory</p>
name.</a></li>
<li><a href='#drawnorm'><p>draw a normal distribution with beautiful illustrations</p></a></li>
<li><a href='#focalVals'><p>Create a focal value vector.</p></a></li>
<li><a href='#formatSummarizedFactors'><p>Prints out the contents of an object created by summarizeFactors</p>
in the style of base::summary</a></li>
<li><a href='#formatSummarizedNumerics'><p>Reformat numeric summarize output as one column per variable,</p>
similar to R summary</a></li>
<li><a href='#genCorrelatedData'><p>Generates a data frame for regression analysis</p></a></li>
<li><a href='#genCorrelatedData2'><p>Generates a data frame for regression analysis.</p></a></li>
<li><a href='#genCorrelatedData3'><p>Generate correlated data for simulations (third edition)</p></a></li>
<li><a href='#genX'><p>Generate correlated data (predictors) for one unit</p></a></li>
<li><a href='#getAuxRsq'><p>retrieves estimates of the coefficient of determination from a list of regressions</p></a></li>
<li><a href='#getDeltaRsquare'><p>Calculates the delta R-squares, also known as squared</p>
semi-partial correlation coefficients.</a></li>
<li><a href='#getFocal'><p>Select focal values from an observed variable.</p></a></li>
<li><a href='#getPartialCor'><p>Calculates partial correlation coefficients after retrieving data matrix froma fitted regression model</p></a></li>
<li><a href='#getVIF'><p>Converts the R-square to the variance inflation factor</p></a></li>
<li><a href='#gmc'><p>Group Mean Center: Generate group summaries and individual deviations within groups</p></a></li>
<li><a href='#kurtosis'><p>Calculate excess kurtosis</p></a></li>
<li><a href='#lazyCor'><p>Create correlation matrices.</p></a></li>
<li><a href='#lazyCov'><p>Create covariance matrix from correlation and standard deviation</p>
information</a></li>
<li><a href='#lmAuxiliary'><p>Estimate leave-one-variable-out regressions</p></a></li>
<li><a href='#magRange'><p>magRange</p>
Magnify the range of a variable.</a></li>
<li><a href='#makeSymmetric'><p>Create Symmetric Matrices, possibly covariance or correlation</p>
matrices, or check a matrix for symmetry and serviceability.</a></li>
<li><a href='#makeVec'><p>makeVec for checking or creating vectors</p></a></li>
<li><a href='#mcDiagnose'><p>Multi-collinearity diagnostics</p></a></li>
<li><a href='#mcGraph1'><p>Illustrate multicollinearity in regression, part 1.</p></a></li>
<li><a href='#meanCenter'><p>meanCenter</p></a></li>
<li><a href='#model.data'><p>Create a &quot;raw&quot; (UNTRANSFORMED) data frame equivalent to the input</p>
data that would be required to fit the given model.</a></li>
<li><a href='#model.data.default'><p>Create a data frame suitable for estimating a model</p></a></li>
<li><a href='#mvrnorm'><p>Minor revision of mvrnorm (from <code>MASS</code>) to facilitate replication</p></a></li>
<li><a href='#newdata'><p>Create a newdata frame for usage in predict methods</p></a></li>
<li><a href='#outreg'><p>Creates a publication quality result table for</p>
regression models. Works with models fitted with lm, glm, as well
as lme4.</a></li>
<li><a href='#outreg2HTML'><p>Convert LaTeX output from outreg to HTML markup</p></a></li>
<li><a href='#padW0'><p>Pad with 0's.</p></a></li>
<li><a href='#pctable'><p>Creates a cross tabulation with counts and percentages</p></a></li>
<li><a href='#perspEmpty'><p>perspEmpty</p></a></li>
<li><a href='#plot.testSlopes'><p>Plot testSlopes objects</p></a></li>
<li><a href='#plotCurves'><p>Assists creation of predicted value curves for regression models.</p></a></li>
<li><a href='#plotFancy'><p>Regression plots with predicted value lines, confidence intervals, color coded interactions</p></a></li>
<li><a href='#plotFancyCategories'><p>Draw display for discrete predictor in plotSlopes</p></a></li>
<li><a href='#plotPlane'><p>Draw a 3-D regression plot for two predictors from any linear or nonlinear lm or glm object</p></a></li>
<li><a href='#plotSeq'><p>Create sequences for plotting</p></a></li>
<li><a href='#plotSlopes'><p>Generic function for plotting regressions and interaction effects</p></a></li>
<li><a href='#predictCI'><p>Calculate a predicted value matrix (fit, lwr, upr) for a</p>
regression, either lm or glm, on either link or response scale.</a></li>
<li><a href='#predictOMatic'><p>Create predicted values after choosing values of predictors.  Can</p>
demonstrate marginal effects of the predictor variables.</a></li>
<li><a href='#print.pctable'><p>Display pctable objects</p></a></li>
<li><a href='#print.summarize'><p>print method for output from summarize</p></a></li>
<li><a href='#print.summary.pctable'><p>print method for summary.pctable objects</p></a></li>
<li><a href='#rbindFill'><p>Stack together data frames</p></a></li>
<li><a href='#religioncrime'><p>Religious beliefs and crime rates</p></a></li>
<li><a href='#removeNULL'><p>Remove NULL values variables from a list</p></a></li>
<li><a href='#residualCenter'><p>Calculates a &quot;residual-centered&quot; interaction regression.</p></a></li>
<li><a href='#se.bars'><p>Draw standard error bar for discrete variables</p></a></li>
<li><a href='#skewness'><p>Calculate skewness</p></a></li>
<li><a href='#standardize'><p>Estimate standardized regression coefficients for all variables</p></a></li>
<li><a href='#summarize'><p>Sorts numeric from discrete variables and returns separate</p>
summaries for those types of variables.</a></li>
<li><a href='#summarizeFactors'><p>Extracts non-numeric variables, calculates summary information,</p>
including entropy as a diversity indicator.</a></li>
<li><a href='#summarizeNumerics'><p>Extracts numeric variables and presents an summary in</p>
a workable format.</a></li>
<li><a href='#summary.factor'><p>Tabulates observed values and calculates entropy</p></a></li>
<li><a href='#summary.pctable'><p>Extract presentation from a pctable object</p></a></li>
<li><a href='#testSlopes'><p>Hypothesis tests for Simple Slopes Objects</p></a></li>
<li><a href='#vech2Corr'><p>Convert the vech (column of strictly lower trianglar values from a matrix) into a correlation matrix.</p></a></li>
<li><a href='#vech2mat'><p>Convert a half-vector (vech) into a matrix.</p></a></li>
<li><a href='#waldt'><p>T-test for the difference in 2 regression parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Regression Estimation and Presentation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.8.157</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-25</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul E. Johnson &lt;pauljohn@ku.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions for interpretation and presentation
    of regression analysis.  These functions are used
    to produce the statistics lectures in
    <a href="https://pj.freefaculty.org/guides/">https://pj.freefaculty.org/guides/</a>. Includes regression
    diagnostics, regression tables, and plots of interactions and
    "moderator" variables. The emphasis is on "mean-centered" and
    "residual-centered" predictors. The vignette 'rockchalk' offers a
    fairly comprehensive overview.  The vignette 'Rstyle' has advice
    about coding in R.  The package title 'rockchalk' refers to our
    school motto, 'Rock Chalk Jayhawk, Go K.U.'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3.0)</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, methods, lme4, carData, MASS, kutils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>tables, Hmisc, car, mvtnorm, scatterplot3d, HH</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-26 01:06:41 UTC; pauljohn</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul E. Johnson [aut, cre],
  Gabor Grothendieck [ctb],
  Dimitri Papadopoulos OrfanosGabor [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-06 17:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='rockchalk-package'>rockchalk: regression functions</h2><span id='topic+rockchalk-package'></span><span id='topic+rockchalk'></span>

<h3>Description</h3>

<p>Includes an ever-growing collection of functions that assist in
the presentation of regression models.  The initial function was
<code><a href="#topic+outreg">outreg</a></code>, which produces LaTeX tables that summarize
one or many fitted regression models.  It also offers plotting
conveniences like <code><a href="#topic+plotPlane">plotPlane</a></code> and
<code><a href="#topic+plotSlopes">plotSlopes</a></code>, which illustrate some of the variables
from a fitted regression model. For a detailed check on
multicollinearity, see <code><a href="#topic+mcDiagnose">mcDiagnose</a></code>.  The user should
be aware of this fact: Not all of these functions lead to models
or types of analysis that we endorese.  Rather, they all lead to
analysis that is endorsed by some scholars, and we feel it is
important to facilitate the comparison of competing methods.  For
example, the function <code><a href="#topic+standardize">standardize</a></code> will calculate
standardized regression coefficients for all predictors in a
regression model's design matrix in order to replicate results
from other statistical frameworks, no matter how unwise the use of
such coefficients might be. The function <code><a href="#topic+meanCenter">meanCenter</a></code>
will allow the user to more selectively choose variables for
centering (and possibly standardization) before they are entered
into the design matrix.  Because of the importance of interaction
variables in regression analysis, the <code><a href="#topic+residualCenter">residualCenter</a></code>
and <code><a href="#topic+meanCenter">meanCenter</a></code> functions are offered.  While mean
centering does not actually help with multicollinearity of
interactive terms, many scholars have argued that it does.  The
meanCenter function can be compared with the &quot;residual centering&quot;
of interaction terms.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>References</h3>

<p>http://pj.freefaculty.org/R
</p>

<hr>
<h2 id='addLines'>Superimpose regression lines on a plotted plane</h2><span id='topic+addLines'></span>

<h3>Description</h3>

<p>The examples will demonstrate the intended usage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addLines(to = NULL, from = NULL, col, lwd = 2, lty = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addLines_+3A_to">to</code></td>
<td>
<p>a 3d plot object produced by plotPlane</p>
</td></tr>
<tr><td><code id="addLines_+3A_from">from</code></td>
<td>
<p>output from a plotSlopes or plotCurves function (class=&quot;rockchalk&quot;)</p>
</td></tr>
<tr><td><code id="addLines_+3A_col">col</code></td>
<td>
<p>color of plotted lines (default: &quot;red&quot;)</p>
</td></tr>
<tr><td><code id="addLines_+3A_lwd">lwd</code></td>
<td>
<p>line width of added lines (default: 2)</p>
</td></tr>
<tr><td><code id="addLines_+3A_lty">lty</code></td>
<td>
<p>line type of added lines (default: 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From an educational stand point, the objective is to assist with the
student's conceptualization of the two and three dimensional regression
relationships.
</p>


<h3>Value</h3>

<p>NULL, nothing, nicht, nada.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##library(rockchalk)


set.seed(12345)

dfadd &lt;- genCorrelatedData2(100, means = c(0,0,0,0), sds = 1, rho = 0,
       beta = c(0.03, 0.01, 0.1, 0.4, -0.1), stde = 2)

dfadd$xcat1 &lt;- gl(2,50, labels=c("M","F"))

dfadd$xcat2 &lt;- cut(rnorm(100), breaks=c(-Inf, 0, 0.4, 0.9, 1, Inf),
                   labels=c("R", "M", "D", "P", "G"))

dfadd$y2 &lt;- 0.03 + 0.1*dfadd$x1 + 0.1*dfadd$x2 +
    0.25*dfadd$x1*dfadd$x2 + 0.4*dfadd$x3 - 0.1*dfadd$x4 +
    0.2 * as.numeric(dfadd$xcat1) +
    contrasts(dfadd$xcat2)[as.numeric(dfadd$xcat2), ] %*% c(-0.1, 0.1, 0.2, 0) +
    1 * rnorm(100)

summarize(dfadd)

## linear ordinary regression
m1 &lt;- lm(y ~ x1 + x2 + x3 + x4, data = dfadd)
summary(m1)

mcDiagnose(m1)

## These will be parallel lines

plotSlopes(m1, plotx = "x1", modx = "x2", modxVals = "std.dev.",
           n = 5, main = "A plotSlopes result with \"std.dev.\" values of modx")


m1ps &lt;- plotSlopes(m1, plotx = "x1", modx = "x2", modxVals = c(-2,0,2))

m1pp &lt;- plotPlane(m1, plotx1 = "x1", plotx2 = "x2",
                  ticktype = "detailed", npp = 10)

addLines(from = m1ps, to = m1pp, lty = 1, lwd = 2)

m1pp &lt;- plotPlane(m1, plotx1 = "x1", plotx2 = "x2", ticktype = "detailed",
                  npp = 10)
addLines(from = m1ps, to = m1pp, lty = 2, lwd = 5, col = "green")

## Other approach would wrap same into the linesFrom argument in plotPlane

plotPlane(m1, plotx1 = "x1", plotx2 = "x2", ticktype = "detailed",
          npp = 10, linesFrom = m1ps)

## Need to think more on whether dotted lines from ps object should
## be converted to solid lines in plotPlane.
</code></pre>

<hr>
<h2 id='centerNumerics'>Find numeric columns, center them, re-name them, and join them with the original data.</h2><span id='topic+centerNumerics'></span>

<h3>Description</h3>

<p>The meanCentered regression function requires centered-inputs when
calculations are predicted. For comparison with ordinary
regression, it is convenient to have both centered and the
original data side-by-side.  This function handles that.  If the
input data has columns c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;), then the centered result
will have columns c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x1c&quot;,&quot;x2c&quot;,&quot;x3c&quot;), where &quot;c&quot;
indicates &quot;mean-centered&quot;. If standardize=TRUE, then the result
will have columns c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x1cs&quot;,&quot;x2cs&quot;,&quot;x3cs&quot;), where &quot;cs&quot;
indicate &quot;centered and scaled&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centerNumerics(data, center, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centerNumerics_+3A_data">data</code></td>
<td>
<p>Required. data frame or matrix.</p>
</td></tr>
<tr><td><code id="centerNumerics_+3A_center">center</code></td>
<td>
<p>Optional. If nc is NOT supplied, then all numeric columns
in data will be centered (possiblly scaled).  Can be specified in 2 formats. 1) Vector of column names that are to be centered, 2) Vector named elements giving values of means to be used in centering.  Values must be named, as in c(&quot;x1&quot; = 17, &quot;x2&quot; = 44).
(possibly scaled).</p>
</td></tr>
<tr><td><code id="centerNumerics_+3A_standardize">standardize</code></td>
<td>
<p>Default FALSE. If TRUE, the variables are
first mean-centered, and then divided by their standard deviations
(scaled). User can supply a named vector of scale values by which
to divide each variable (otherwise sd is used). Vector must have same
names and length as center argument. Variables can be entered in any order (will be resorted inside function).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with 1) All original columns 2) additional
columns with centered/scaled data, variables renamed &quot;c&quot; or &quot;cs&quot;
to indicate the data is centered or centered and
scaled. Attributes &quot;centers&quot; and &quot;scales&quot; are created for &quot;record
keeping&quot; on centering and scaling values.
</p>


<h3>Author(s)</h3>

<p><a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
dat &lt;- data.frame(x1=rnorm(100, m = 50), x2 = rnorm(100, m = 50),
    x3 = rnorm(100, m = 50), y = rnorm(100),
    x4 = gl(2, 50, labels = c("Male","Female")))
datc1 &lt;- centerNumerics(dat)
head(datc1)
summarize(datc1)
datc2 &lt;- centerNumerics(dat, center=c("x1", "x2"))
head(datc2)
summarize(datc2)
attributes(datc2)
datc3 &lt;- centerNumerics(dat, center = c("x1" = 30, "x2" = 40))
head(datc3)
summarize(datc3)
attributes(datc3)
datc4 &lt;- centerNumerics(dat, center=c("x1", "x2"), standardize = TRUE)
head(datc3)
summarize(datc4)
attributes(datc4)
datc5 &lt;- centerNumerics(dat, center=c("x1"=30, "x2"=40),
standardize = c("x2" = 5, "x1" = 7))
head(datc5)
summarize(datc5)
attributes(datc5)
</code></pre>

<hr>
<h2 id='centralValues'>Central Tendency estimates for variables</h2><span id='topic+centralValues'></span>

<h3>Description</h3>

<p>This is needed for the creation of summaries and predicted values
of regression models. It takes a data frame and returns a new data
frame with one row in which the mean or mode of the columns is
reported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centralValues(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="centralValues_+3A_x">x</code></td>
<td>
<p>a data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame with the same variables and one row, the summary indicators.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myDat &lt;- data.frame(x=rnorm(100), y=rpois(100,l=4), z = cut(rnorm(100), c(-10,-1,0,10)))
centralValues(myDat)
</code></pre>

<hr>
<h2 id='cheating'>Cheating and Looting in Japanese Electoral Politics</h2><span id='topic+cheating'></span>

<h3>Description</h3>

<p>Extracted from the &quot;cheating-replication.dta&quot; data file
with permission by the authors, Benjamin Nyblade and Steven
Reed. The Stata data file provided by the authors included
many constructed variables that have been omitted.  Within
R, these can be easily re-contructed by users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cheating)
</code></pre>


<h3>Format</h3>

<p>data.frame: 16623 obs. on 27 variables
</p>


<h3>Details</h3>

<p>Special thanks to NyBlade and Reed for permission to repackage
this data. Also special thanks to them for creating an especially
transparent variable naming scheme.
</p>
<p>The data set includes many columns for variables that can easily
be re-constructed from the columns that are provided here.  While
Stata users might need to manually create 'dummy variables' and
interactions, R users generally do not do that manually.
</p>
<p>These variables from the original data set were omitted:
</p>
<p>Dummy variables for the year variable: c(&quot;yrd1&quot;, &quot;yrd2&quot;, ...,
&quot;yrd17&quot;, &quot;yrd18&quot;)
</p>
<p>Dummy variables for the ku variable:
c(&quot;ku1&quot;, &quot;ku2&quot;, ..., &quot;ku141&quot;, &quot;ku142&quot;)
</p>
<p>Constructed product variables: c(&quot;actualratiosq&quot;, &quot;viabsq&quot;,
&quot;viab_candcamp_divm&quot;, &quot;viab_candothercamp_divm&quot;,
&quot;viabsq_candcamp_divm&quot;, &quot;viabsq_candothercamp_divm&quot;,
&quot;absviab_candcamp&quot;, &quot;absviab_candothercamp&quot;,
&quot;absviab_candcamp_divm&quot;, &quot;absviab_candothercamp_divm&quot;,
&quot;viabsq_candcamp&quot;, &quot;viabsq_candothercamp&quot;, &quot;viab_candcamp&quot;,
&quot;viab_candothercamp&quot;, &quot;candothercamp_divm&quot;, &quot;candcamp_divm&quot;,
&quot;candcampminusm&quot;, &quot;candothercampminusm&quot;, &quot;predratiosq&quot;, &quot;absviab&quot;)
</p>
<p>Mean centered variables: constr2 &lt;- c(&quot;viab_candcampminusm&quot;,
&quot;viab_candothercampminusm&quot;, &quot;viabsq_candothercampminusm&quot;,
&quot;viabsq_candcampminusm&quot;)
</p>
<p>In the end, we are left with these variables:
</p>
<p>[1] &quot;ku&quot;
[2] &quot;prefecture&quot;
[3] &quot;dist&quot;
[4] &quot;year&quot;
[5] &quot;yr&quot;
[6] &quot;cdnr&quot;
[7] &quot;jiban&quot;
[8] &quot;cheating&quot;
[9] &quot;looting&quot;
[10] &quot;actualratio&quot;
[11] &quot;viab&quot;
[12] &quot;inc&quot;
[13] &quot;cons&quot;
[14] &quot;ur&quot;
[15] &quot;newcand&quot;
[16] &quot;jwins&quot;
[17] &quot;cons_cwins&quot;
[18] &quot;oth_cwins&quot;
[19] &quot;camp&quot;
[20] &quot;fleader&quot;
[21] &quot;incablast&quot;
[22] &quot;predratio&quot;
[23] &quot;m&quot;
[24] &quot;candcamp&quot;
[25] &quot;candothercamp&quot;
[26] &quot;kunocheat&quot;
[27] &quot;kunoloot&quot;
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>, on behalf of Benjamin Nyblade and Steven Reed
</p>


<h3>Source</h3>

<p><a href="https://bnyblade.com/research/publications/">https://bnyblade.com/research/publications/</a>.
</p>


<h3>References</h3>

<p>Benjamin Nyblade and Steven Reed, &quot;Who Cheats? Who
Loots? Political Competition and Corruption in Japan, 1947-1993.&quot;
American Journal of Political Science 52(4): 926-41. October 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(rockchalk)
data(cheating)

table1model2 &lt;- glm(cheating ~ viab + I(viab^2) + inc + cons + ur
+ newcand + jwins + cons_cwins + oth_cwins, family = binomial(link
= "logit"), data = cheating)

predictOMatic(table1model2)

predictOMatic(table1model2, interval = "confidence")

## The publication used "rare events logistic", which I'm not bothering
## with here because I don't want to invoke additional imported packages.
## But the ordinary logit results are proof of concept.
</code></pre>

<hr>
<h2 id='checkIntFormat'>A way of checking if a string is a valid file name.</h2><span id='topic+checkIntFormat'></span>

<h3>Description</h3>

<p>A copy from R's grDevices:::checkIntFormat because it is not
exported there
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkIntFormat(s)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkIntFormat_+3A_s">s</code></td>
<td>
<p>An integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical: TRUE or FALSE
</p>


<h3>Author(s)</h3>

<p>R Core Development Team
</p>

<hr>
<h2 id='checkPosDef'>Check a matrix for positive definitness</h2><span id='topic+checkPosDef'></span>

<h3>Description</h3>

<p>Uses eigen to check positive definiteness. Follows example used
in <code>MASS</code> package by W. N. Venables and Brian D. Ripley
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkPosDef(X, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkPosDef_+3A_x">X</code></td>
<td>
<p>A matrix</p>
</td></tr>
<tr><td><code id="checkPosDef_+3A_tol">tol</code></td>
<td>
<p>Tolerance (closeness to 0 required to declare failure)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE or FALSE
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='combineLevels'>recode a factor by &quot;combining&quot; levels</h2><span id='topic+combineLevels'></span>

<h3>Description</h3>

<p>This makes it easy to put levels together and create a new factor
variable. If a
factor variable is currently coded with levels
c(&quot;Male&quot;,&quot;Female&quot;,&quot;Man&quot;, &quot;M&quot;), and the user needs to combine the
redundant levels for males, this is the function to use!  This is a surprisingly difficult problem in R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combineLevels(fac, levs, newLabel = "combinedLevels")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combineLevels_+3A_fac">fac</code></td>
<td>
<p>An R factor variable, either ordered or not.</p>
</td></tr>
<tr><td><code id="combineLevels_+3A_levs">levs</code></td>
<td>
<p>The levels to be combined. Users may specify either a
numerical vector of level values, such as c(1,2,3), to combine the
first three elements of level(fac), or they may specify level
names.  This can be done as a character vector of *correctly
spelled* factor values, such as c(&quot;Yes&quot;,&quot;Maybe&quot;,&quot;Always&quot;) or it
may be provided as a subset of the output from levels, such as
levels(fac)[1:3].</p>
</td></tr>
<tr><td><code id="combineLevels_+3A_newlabel">newLabel</code></td>
<td>
<p>A character string that represents the label of
the new level to be created when <code>levs</code> values are combined.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the factor is an ordinal factor, then levels may be combined
only if they are adjacent. A factor with levels
c(&quot;Lo&quot;,&quot;Med&quot;,&quot;Hi&quot;,&quot;Extreme&quot;) allows us to combine responses &quot;Lo&quot;
and &quot;Med&quot;, while it will NOT allow us to combine &quot;Lo&quot; with &quot;Hi&quot;.
</p>
<p>A non-ordered factor can be reorganized to combine any values, no
matter what positions they occupy in the levels vector.
</p>


<h3>Value</h3>

<p>A new factor variable, with unused levels removed.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("M","A","B","C","A","B","A","M")
x &lt;- factor(x)
levels(x)
x2a &lt;- combineLevels(x, levs = c("M","A"), newLabel = "M_or_A")
addmargins(table(x2a, x, exclude=NULL))
x2b &lt;- combineLevels(x, c(1,4), "M_or_A")
addmargins(table(x2b, x, exclude=NULL))
x3 &lt;- combineLevels(x, levs = c("M","A","C"), newLabel = "MAC")
addmargins(table(x3, x, exclude=NULL))
## Now an ordinal factor
z &lt;- c("M","A","B","C","A","B","A","M")
z &lt;- ordered(z)
levels(z)
table(z, exclude=NULL)
z2a &lt;-  combineLevels(z, levs = c(1,2), "Good")
addmargins(table(z2a, z, exclude = NULL))
z2b &lt;- combineLevels(z, levs = c("A","B"), "AorB")
addmargins(table(z2b, z, exclude = NULL))

</code></pre>

<hr>
<h2 id='cutByQuantile'>Calculates the &quot;center&quot; quantiles, always including the median, when n is odd.</h2><span id='topic+cutByQuantile'></span>

<h3>Description</h3>

<p>If the numeric variable has fewer than 6 unique observed values,
this will send the data to <code>cutByTable</code>.  The default return
will find dividing points at three quantiles: c(0.25, 0.50, 0.75)
If n=4, the dividing points will be c(0.20, 0.40, 0.60, 0.80) If
n=5, c(0.0, 0.25, 0.50, 0.75, 1.0) Larger n that are odd will
include 0.5 and evenly spaced points out to proportions 0 and
1.0. Larger n that is even will return evenly spaced points
calculated by R's <code>pretty</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutByQuantile(x, n = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cutByQuantile_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="cutByQuantile_+3A_n">n</code></td>
<td>
<p>The number of quantile points. See details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='cutBySD'>Returns center values of x, the mean, mean-std.dev, mean+std.dev</h2><span id='topic+cutBySD'></span>

<h3>Description</h3>

<p>If the numeric variable has fewer than 6 unique observed values,
this will send the data to cutByTable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutBySD(x, n = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cutBySD_+3A_x">x</code></td>
<td>
<p>A numeric variable</p>
</td></tr>
<tr><td><code id="cutBySD_+3A_n">n</code></td>
<td>
<p>Should be an odd number 1, 3, 5, or 7. If 2 &lt; n &lt; 5,
values that divide the data at c(m-sd, m, m+sd) are returned. If n
&gt; 4, the returned values are c(m-2sd, m-sd, m, m+sd, m+2sd).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named vector
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100, m = 100, s = 20)
cutBySD (x, n = 3)
cutBySD (x, n = 5)
</code></pre>

<hr>
<h2 id='cutByTable'>Select most frequently occurring values from numeric or categorical variables.</h2><span id='topic+cutByTable'></span>

<h3>Description</h3>

<p>The &quot;n&quot; most frequently occurring values are returned, sorted by
frequency of occurrence (in descending order). The names attribute
includes information about the percentage of cases that have the
indicated values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutByTable(x, n = 5, pct = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cutByTable_+3A_x">x</code></td>
<td>
<p>A numeric or character variable</p>
</td></tr>
<tr><td><code id="cutByTable_+3A_n">n</code></td>
<td>
<p>The maximum number of values that may be returned.</p>
</td></tr>
<tr><td><code id="cutByTable_+3A_pct">pct</code></td>
<td>
<p>Default = TRUE. Include percentage of responses within each category</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is used by plotSlopes, plotCurves, and other &quot;newdata&quot; making
functions.
</p>


<h3>Value</h3>

<p>A named vector.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='cutFancy'>Create an ordinal variable by grouping numeric data input.</h2><span id='topic+cutFancy'></span>

<h3>Description</h3>

<p>This is a convenience function for usage of R's <code>cut</code>
function. Users can specify cutpoints or category labels or
desired proportions of groups in various ways. In that way, it has
a more flexible interface than <code>cut</code>. It also tries to notice
and correct some common user errors, such as omitting the outer
boundaries from the probs argument. The returned values are
labeled by their midpoints, rather than cut's usual boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutFancy(y, cutpoints = "quantile", probs, categories)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cutFancy_+3A_y">y</code></td>
<td>
<p>The input data from which the categorized variable will
be created.</p>
</td></tr>
<tr><td><code id="cutFancy_+3A_cutpoints">cutpoints</code></td>
<td>
<p>Optional paramter, a vector of thresholds at
which to cut the data. If it is not supplied, the default
value <code>cutpoints="quantile"</code> will take effect. Users can
supplement with <code>probs</code> and/or <code>categories</code> as shown
in examples.</p>
</td></tr>
<tr><td><code id="cutFancy_+3A_probs">probs</code></td>
<td>
<p>This is an optional parameter, relevant only when the
R function <code><a href="stats.html#topic+quantile">quantile</a></code> function is used to
calculate cutpoints. The length should be number of desired
categories PLUS ONE, as in <code>c(0, .3, .6, 1)</code>. That will
create categories that represent 1) less than .3, between .3
and .6, and above .6.  A common user error is to specify only
the internal divider values, such as <code>probs = c(.3,
.6)</code>. To anticipate and correct that error, this function will
insert the lower limit of 0 and the upper limit of 1 if they
are not already present in <code>probs</code>.</p>
</td></tr>
<tr><td><code id="cutFancy_+3A_categories">categories</code></td>
<td>
<p>Can be a number to designate the number of
sub-groups created, or it can be a vector of names used. If
<code>cutpoints</code> and <code>probs</code> are not specified, the
parameter <code>categories</code> should be an integer to specify
how many data groups to create.It is required if
cutpoints=&quot;quantile&quot; and probs is not specified. Can also be a
vector of names to be used for the categories that are
created. If category names are not provided, the names for the
ordinal variable will be the midpoint of the numeric range
from which they are constructed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dividing points, thought of as &quot;thresholds&quot; or &quot;cutpoints&quot;,
can be specified in several ways.  <code>cutFancy</code> will
automatically create equally-sized sets of observations for a
given number of categories if neither <code>probs</code> nor
<code>cutpoints</code> is specified. The bare minimum input needed is
<code>categories=5</code>, for example, to ask for 5 equally sized
groups. More user control can be had by specifying either
<code>cutpoints</code> or <code>probs</code>. If <code>cutpoints</code> is not
specified at all, or if <code>cutpoints="quantile"</code>, then
<code>probs</code> can be used to specify the proportions of the data
points that are to fall within each range. On the other hand, one
can specify <code>cutpoints = "quantile"</code> and then <code>probs</code> will
be used to specify the proportions of the data points that are to
fall within each range.
</p>
<p>If <code>categories</code> is not specified, the category names will be
created. Names for ordinal categories will be the numerical
midpoints for the outcomes.  Perhaps this will deviate from your
expectation, which might be ordinal categories name &quot;0&quot;, &quot;1&quot;, &quot;2&quot;,
and so forth.  The numerically labeled values we provide can be
used in various ways during the analysis process. Read &quot;?factor&quot;
to learn ways to convert the ordinal output to other
formats. Examples include various ways of converting the ordinal
output to numeric.
</p>
<p>The <code>categories</code> parameter works together with
<code>cutpoints</code>.  <code>cutpoints</code> allows a character string
&quot;quantile&quot;. If <code>cutpoints</code> is not specified, or if the user
specifies a character string <code>cutpoints="quantile"</code>, then the
<code>probs</code> would be used to determine the cutpoints.  However,
if <code>probs</code> is not specified, then the <code>categories</code>
argument can be used. If <code>cutpoints="quantile"</code>, then
</p>

<ul>
<li><p> if <code>categories</code> is one integer, then it is interpreted
as the number of &quot;equally sized&quot; categories to be created, or
</p>
</li>
<li> <p><code>categories</code> can be a vector of names. The length
of the vector is used to determine the number of categories, and
the values are put to use as factor labels.
</p>
</li></ul>



<h3>Value</h3>

<p>an ordinal vector with attributes &quot;cutpoints&quot; and &quot;props&quot;
(proportions)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234234)
y &lt;- rnorm(1000, m = 35, sd = 14)
yord &lt;- cutFancy(y, cutpoints = c(30, 40, 50))
table(yord)
attr(yord, "props")
attr(yord, "cutpoints")
yord &lt;- cutFancy(y, categories = 4L)
table(yord, exclude = NULL)
attr(yord, "props")
attr(yord, "cutpoints")
yord &lt;- cutFancy(y, probs = c(0, .1, .3, .7, .9, 1.0),
                  categories = c("A", "B", "C", "D", "E"))
table(yord, exclude = NULL)
attr(yord, "props")
attr(yord, "cutpoints")
yord &lt;- cutFancy(y, probs = c(0, .1, .3, .7, .9, 1.0))
table(yord, exclude = NULL)
attr(yord, "props")
attr(yord, "cutpoints")
yasinteger &lt;- as.integer(yord)
table(yasinteger, yord)
yasnumeric &lt;- as.numeric(levels(yord))[yord]
table(yasnumeric, yord)
barplot(attr(yord, "props"))
hist(yasnumeric)
X1a &lt;-
   genCorrelatedData3("y ~ 1.1 + 2.1 * x1 + 3 * x2 + 3.5 * x3 + 1.1 * x1:x3",
                       N = 10000, means = c(x1 = 1, x2 = -1, x3 = 3),
                       sds = 1, rho = 0.4)
## Create cutpoints from quantiles
probs &lt;- c(.3, .6)
X1a$yord &lt;- cutFancy(X1a$y, probs = probs)
attributes(X1a$yord)
table(X1a$yord, exclude = NULL)
</code></pre>

<hr>
<h2 id='descriptiveTable'>Summary stats table-maker for regression users</h2><span id='topic+descriptiveTable'></span>

<h3>Description</h3>

<p>rockchalk::summarize does the numerical calculations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descriptiveTable(
  object,
  stats = c("mean", "sd", "min", "max"),
  digits = 4,
  probs = c(0, 0.5, 1),
  varLabels,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="descriptiveTable_+3A_object">object</code></td>
<td>
<p>A fitted regression or an R data.frame, or any
other object type that does not fail in codemodel.frame(object).</p>
</td></tr>
<tr><td><code id="descriptiveTable_+3A_stats">stats</code></td>
<td>
<p>Default is a vector c(&quot;mean&quot;, &quot;sd&quot;, &quot;min&quot;, &quot;max&quot;). Other
stats reported by rockchalk::summarize should work fine as well</p>
</td></tr>
<tr><td><code id="descriptiveTable_+3A_digits">digits</code></td>
<td>
<p>2 decimal points is default</p>
</td></tr>
<tr><td><code id="descriptiveTable_+3A_probs">probs</code></td>
<td>
<p>Probability cut points to be used in the calculation
of summaries of numeric variables.  Default is c(0, 0.5, 1), meaning
<code>min, median, max</code>.</p>
</td></tr>
<tr><td><code id="descriptiveTable_+3A_varlabels">varLabels</code></td>
<td>
<p>A named vector of variables labels, as in outreg function.
Format is c(&quot;oldname&quot;=&quot;newlabel&quot;).</p>
</td></tr>
<tr><td><code id="descriptiveTable_+3A_...">...</code></td>
<td>
<p>Other arguments passed to rockchalk::summarizeNumerics and
summarizeFactors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is, roughly speaking, doing the right thing, but
not in a clever way. For the categorical variables, the
only summary is proportions.
</p>


<h3>Value</h3>

<p>a character matrix
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- genCorrelatedData2(1000, means=c(10, 10, 10), sds = 3, 
                          stde = 3, beta = c(1, 1, -1, 0.5))
dat$xcat1 &lt;- factor(sample(c("a", "b", "c", "d"), 1000, replace=TRUE))
dat$xcat2 &lt;- factor(sample(c("M", "F"), 1000, replace=TRUE), levels = c("M", "F"),
labels = c("Male", "Female"))
dat$y &lt;- dat$y + contrasts(dat$xcat1)[dat$xcat1, ] %*% c(0.1, 0.2, 0.3)
m4 &lt;- lm(y ~ x1 + x2  + x3 + xcat1 + xcat2, dat)
m4.desc &lt;- descriptiveTable(m4)
m4.desc
## Following may cause scientific notation, want to avoid.
dat &lt;- genCorrelatedData2(1000, means=c(10, 100, 400), 
                 sds = c(3, 10, 20), stde = 3, beta = c(1, 1, -1, 0.5))
m5 &lt;- lm(y ~ x1 + x2  + x3, dat)
m5.desc &lt;- descriptiveTable(m5, digits = 4)
m5.desc

</code></pre>

<hr>
<h2 id='dir.create.unique'>Create a uniquely named directory. Appends number &amp; optionally date to directory
name.</h2><span id='topic+dir.create.unique'></span>

<h3>Description</h3>

<p>Checks if the requested directory exists. If so, will create new
directory name. My favorite method is to have the target directory
with a date-based subdirectory, but set usedate as FALSE if you
don't like that. Arguments showWarnings, recursive, and mode are
passed along to R's dir.create, which does the actual work here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dir.create.unique(
  path,
  usedate = TRUE,
  showWarnings = TRUE,
  recursive = TRUE,
  mode = "0777"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dir.create.unique_+3A_path">path</code></td>
<td>
<p>A character string for the base name of the directory.</p>
</td></tr>
<tr><td><code id="dir.create.unique_+3A_usedate">usedate</code></td>
<td>
<p>TRUE or FALSE: Insert YYYYMMDD information?</p>
</td></tr>
<tr><td><code id="dir.create.unique_+3A_showwarnings">showWarnings</code></td>
<td>
<p>default TRUE. Show warnings? Will be passed on
to dir.create</p>
</td></tr>
<tr><td><code id="dir.create.unique_+3A_recursive">recursive</code></td>
<td>
<p>default TRUE. Will be passed on to dir.create</p>
</td></tr>
<tr><td><code id="dir.create.unique_+3A_mode">mode</code></td>
<td>
<p>Default permissions on unix-alike systems. Will be
passed on to dir.create</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Default response to dir = &quot;../output/&quot; fixes the directory name
like this, &quot;../output/20151118-1/&quot; because usedate is assumed
TRUE. If usedate = FALSE, then output names will be like
&quot;../output-1/&quot;, &quot;../output-2/&quot;, and so forth.
</p>


<h3>Value</h3>

<p>a character string with the directory name
</p>


<h3>Author(s)</h3>

<p>Paul E Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='drawnorm'>draw a normal distribution with beautiful illustrations</h2><span id='topic+drawnorm'></span>

<h3>Description</h3>

<p>This was developed for the R Working Example collection
in my website, pj.freefaculty.org/R/WorkingExamples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drawnorm(
  mu = 0,
  sigma = 1,
  xlab = "A Normally Distributed Variable",
  ylab = "Probability Density",
  main,
  ps = par("ps"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drawnorm_+3A_mu">mu</code></td>
<td>
<p>The mu parameter</p>
</td></tr>
<tr><td><code id="drawnorm_+3A_sigma">sigma</code></td>
<td>
<p>The sigma parameter</p>
</td></tr>
<tr><td><code id="drawnorm_+3A_xlab">xlab</code></td>
<td>
<p>Label for x axis</p>
</td></tr>
<tr><td><code id="drawnorm_+3A_ylab">ylab</code></td>
<td>
<p>Label for Y axis</p>
</td></tr>
<tr><td><code id="drawnorm_+3A_main">main</code></td>
<td>
<p>Title for plot. OK to ignore this, we'll make a nice one for you</p>
</td></tr>
<tr><td><code id="drawnorm_+3A_ps">ps</code></td>
<td>
<p>pointsize of text</p>
</td></tr>
<tr><td><code id="drawnorm_+3A_...">...</code></td>
<td>
<p>arguments passed to par</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>drawnorm(mu = 10, sigma = 20)
drawnorm(mu= 0, sigma = 1)
drawnorm(mu = 102, sigma = 313)
drawnorm(mu = 0, sigma = 1, main = "A Standard Normal Distribution, N(0,1)",
         xlab = "X", ylab = "Density", ps = 7)
drawnorm(mu = 0, sigma = 1, ylab = "Density", ps = 14) 
</code></pre>

<hr>
<h2 id='focalVals'>Create a focal value vector.</h2><span id='topic+focalVals'></span>

<h3>Description</h3>

<p>This selects some values of a variable and creates a new &quot;focal vector&quot;
from them. Can use one &quot;divider&quot; algorithm, to be selected by name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focalVals(x, divider = "quantile", n = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="focalVals_+3A_x">x</code></td>
<td>
<p>The input variable may be numeric or a factor.</p>
</td></tr>
<tr><td><code id="focalVals_+3A_divider">divider</code></td>
<td>
<p>Either a quoted string name of an algorithm or a
function. Default = &quot;quantile&quot; for numeric variables, &quot;table&quot; for
factors. Other valid values: &quot;seq&quot; for an evenly spaced sequence
from minimum to maximum, &quot;std.dev.&quot; for a sequence that has the
mean at the center and values on either side that are proportional
to the standard deviation.</p>
</td></tr>
<tr><td><code id="focalVals_+3A_n">n</code></td>
<td>
<p>Desired number of focal values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a &quot;wrapper&quot; (or convenience) function that re-directs work
to other functions. The functions that do the work to select the
focal values for types (&quot;table&quot;, &quot;quantile&quot;, &quot;std.dev.&quot;, &quot;seq&quot;) are
(cutByTable(), cutByQuantile(), cutBySD(), and plotSeq())
</p>
<p>The built-in R function <code>pretty()</code>
works as of rockchalk 1.7.2. Any function that accepts an argument
n will work, as long as it creates a vector of values.
</p>


<h3>Value</h3>

<p>A named vector of focal values selected from a variable. The
values of the names should be informative and useful for plotting or
other diagnostic work.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p><code>predictOMatic</code> <code>newdata</code>
</p>

<hr>
<h2 id='formatSummarizedFactors'>Prints out the contents of an object created by summarizeFactors
in the style of base::summary</h2><span id='topic+formatSummarizedFactors'></span>

<h3>Description</h3>

<p>An object with class &quot;summarizedFactors&quot; is the input. Such an
object should be created with the function
rockchalk::summarizeFactors. Each element in that list is then
organized for printing in a tabular summary.  This should look
almost like R's own summary function, except for the additional
information that these factor summaries include.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatSummarizedFactors(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="formatSummarizedFactors_+3A_x">x</code></td>
<td>
<p>A summarizedFactors object produced by summarizeFactors</p>
</td></tr>
<tr><td><code id="formatSummarizedFactors_+3A_...">...</code></td>
<td>
<p>optional arguments. Only value currently used is digits,
which defaults to 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table of formatted output
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summarize">summarize</a></code>, <code><a href="#topic+summarizeFactors">summarizeFactors</a></code>, <code><a href="#topic+formatSummarizedNumerics">formatSummarizedNumerics</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(xcat1 = gl(10, 3), xcat2 = gl(5, 6))
summarizeFactors(dat, maxLevels = 8)
formatSummarizedFactors(summarizeFactors(dat))
</code></pre>

<hr>
<h2 id='formatSummarizedNumerics'>Reformat numeric summarize output as one column per variable,
similar to R summary</h2><span id='topic+formatSummarizedNumerics'></span>

<h3>Description</h3>

<p>The summarizeNumeric function returns a data frame with the
variable names on the rows and summary statistics (mean, median,
std. deviation) in the columns.This transposes and abbreviates
the information to look more like R summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatSummarizedNumerics(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="formatSummarizedNumerics_+3A_x">x</code></td>
<td>
<p>numeric summaries from summarize function</p>
</td></tr>
<tr><td><code id="formatSummarizedNumerics_+3A_...">...</code></td>
<td>
<p>Other arguments, such as digits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R <code>table</code> object
</p>


<h3>Author(s)</h3>

<p>Paul Johnson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(21234)
X &lt;- matrix(rnorm(10000), ncol = 10, dimnames = list(NULL, paste0("xvar", 1:10)))
Xsum &lt;- summarize(X)
Xsum$numerics
formatSummarizedNumerics(Xsum$numerics)
formatSummarizedNumerics(Xsum$numerics, digits = 5)
Xsum.fmt &lt;- formatSummarizedNumerics(Xsum$numerics)
str(Xsum.fmt)
</code></pre>

<hr>
<h2 id='genCorrelatedData'>Generates a data frame for regression analysis</h2><span id='topic+genCorrelatedData'></span>

<h3>Description</h3>

<p>The output is a data frame (x1, x2, y) with user-specified
correlation between x1 and x2. The y (output) variable is created
according to the equation<br />
</p>
<p style="text-align: center;"><code class="reqn">
y = beta1 + beta2 * x1 + beta3 * x2 + beta4 * x1 * x2 + e.
</code>
</p>

<p>The arguments determine the scales of the X matrix, the random
error, and the slope coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCorrelatedData(
  N = 100,
  means = c(50, 50),
  sds = c(10, 10),
  rho = 0,
  stde = 1,
  beta = c(0, 0.2, 0.2, 0)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCorrelatedData_+3A_n">N</code></td>
<td>
<p>Number of cases desired</p>
</td></tr>
<tr><td><code id="genCorrelatedData_+3A_means">means</code></td>
<td>
<p>2-vector of means for x1 and x2</p>
</td></tr>
<tr><td><code id="genCorrelatedData_+3A_sds">sds</code></td>
<td>
<p>2-vector of standard deviations for x1 and x2</p>
</td></tr>
<tr><td><code id="genCorrelatedData_+3A_rho">rho</code></td>
<td>
<p>Correlation coefficient for x1 and x2</p>
</td></tr>
<tr><td><code id="genCorrelatedData_+3A_stde">stde</code></td>
<td>
<p>standard deviation of the error term in the data
generating equation</p>
</td></tr>
<tr><td><code id="genCorrelatedData_+3A_beta">beta</code></td>
<td>
<p>beta vector of at most 4 coefficients for intercept,
slopes, and interaction</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector (x1,x2) is drawn from a multivariate normal
distribution in which the expected value (argument <code>means</code>).
The covariance matrix of X is
built from the standard deviations (<code>sds</code>)
and the specified correlation between x1 and x2 (<code>rho</code>).
It is also necessary to specify the standard deviation
of the error term (<code>stde</code>) and the coefficients
of the regression equation (<code>beta</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1000 observations of uncorrelated x1 and x2 with no
## interaction between x1 and x2
dat &lt;- genCorrelatedData(N=1000, rho=0, beta=c(1, 1.0, -1.1, 0.0))
  mcGraph1(dat$x1, dat$x2, dat$y, theta=20, phi=8,
  ticktype="detailed", nticks=10)
m1 &lt;- lm(y ~ x1 + x2, data = dat)
plotPlane(m1, plotx1 = "x1", plotx2 = "x2")

</code></pre>

<hr>
<h2 id='genCorrelatedData2'>Generates a data frame for regression analysis.</h2><span id='topic+genCorrelatedData2'></span>

<h3>Description</h3>

<p>Unlike <code>genCorrelatedData</code>, this new-and-improved
function can generate a data frame with as many predictors
as the user requests along with an arbitrarily complicated
regression formula.  The result will be a data frame with
columns named (y, x1, x2, ..., xp).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCorrelatedData2(
  N = 100,
  means = c(50, 50, 50),
  sds = c(10, 10, 10),
  rho = c(0, 0, 0),
  stde = 100,
  beta = c(0, 0.15, 0.1, -0.1),
  intercept = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCorrelatedData2_+3A_n">N</code></td>
<td>
<p>Number of cases desired</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_means">means</code></td>
<td>
<p>P-vector of means for X. Implicitly sets the dimension of
the predictor matrix as N x P.</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_sds">sds</code></td>
<td>
<p>Values for standard deviations for columns of X. If
less than P values are supplied, they will be recycled.</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_rho">rho</code></td>
<td>
<p>Correlation coefficient for X. Several input formats
are allowed (see <code>lazyCor</code>). This can be a single number (common
correlation among all variables), a full matrix of correlations
among all variables, or a vector that is interpreted as the
strictly lower triangle (a vech).</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_stde">stde</code></td>
<td>
<p>standard deviation of the error term in the data
generating equation</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_beta">beta</code></td>
<td>
<p>beta vector of coefficients for intercept, slopes, and
interaction terma.  The first P+1 values are the
intercept and slope coefficients for the predictors. Additional
elements in beta are interpreted as coefficients for nonlinear and
interaction coefficients.  I have decided to treat these as a
column (vech) that fills into a lower triangular matrix. It
is easy to see what's going on if you run the examples. There
is also explanation in Details.</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_intercept">intercept</code></td>
<td>
<p>Default FALSE. Should the predictors include an
intercept?</p>
</td></tr>
<tr><td><code id="genCorrelatedData2_+3A_verbose">verbose</code></td>
<td>
<p>TRUE or FALSE. Should information about the data
generation be reported to the terminal?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Arguments supplied must have enough information so that an
N x P matrix of predictors can be constructed.
The matrix X is drawn from a multivariate normal
distribution, the expected value vector (mu vector) is given by
the <code>means</code> and the var/covar matrix (Sigma) is
built from user supplied standard deviations <code>sds</code>
and the correlations between the columns of X, given by <code>rho</code>.
The user can also set the standard deviation
of the error term (<code>stde</code>) and the coefficients
of the regression equation (<code>beta</code>).
</p>
<p>If called with no arguments, this creates a data frame with
X ~ MVN(mu = c(50,50,50), Sigma = diag(c(10,10,10))).
y = X 
is N(m = 0, sd = 200). All of these details can be
changed by altering the arguments.
</p>
<p>The y (output) variable is created according to the
equation<br />
</p>
<p style="text-align: center;"><code class="reqn">
y = b1 + b2 * x1 + ...+ bk * xk + b[k+1] * x1 * ...interactions.. + e</code>
</p>

<p><br />
For shorthand, I write b1 for beta[1], b2 for beta[2], and so forth.<br />
</p>
<p>The first P+1 arguments in the argument beta are the coefficients
for the intercept and the columns of the X matrix.  Any additional
elements in beta are the coefficients for nonlinear and interaction terms.<br />
</p>
<p>Those additional values in the beta vector are completely
optional. Without them, the true model is a linear
regression. However, one can incorporate the effect of squared terms
(conceptualize that as x1 * x1, for example) or interactions
(x1 * x2) easily.  This is easier to illustrate than describe.
Suppose there are 4 columns in X. Then a beta
vector like beta = c(0, 1, 2, 3, 4, 5, 6, 7, 8) would amount to
asking for<br />
</p>
<p style="text-align: center;"><code class="reqn">
y = 0 + 1 x1 + 2 x2 + 3 x3 + 4 x4 + 5 x1^2 + 6 x1 x2 + 7 x1 x3 + 8 x1 x4 + error
</code>
</p>

<p><br />
If beta supplies more coefficients, they are interpeted as additional
interactions.<br />
</p>
<p>When there are a many predictors and the beta vector is long, this
can become confusing. I think of this as a vech for the lower
triangle of a coefficient matrix. In the example with 4
predictors, beta[1:5] are used for the intercepts and slopes. The
rest of the  beta elements lay in like so:<br />
</p>
<p>X1   X2  X3  X4<br />
X1 b6   .    .<br />
X2 b7   b10  .<br />
X3 b8   b11  b13<br />
X4 b9   b12  b14 b15<br />
</p>
<p>If the user only supplies b6 and b7, the rest are assumed  to  be 0.<br />
</p>
<p>To make this clear, the formula used to calculate y is printed to
the console when genCorrelatedData2 is called.
</p>


<h3>Value</h3>

<p>A data matrix that has columns c(y, x1, x2, ..., xP)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1000 observations of uncorrelated X with no interactions
set.seed(234234)
dat &lt;- genCorrelatedData2(N = 10, rho = 0.0, beta = c(1, 2, 1, 1),
    means = c(0,0,0), sds = c(1,1,1), stde = 0)
summarize(dat)
## The perfect regression!
m1 &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m1)

dat &lt;- genCorrelatedData2(N = 1000, rho = 0,
    beta = c(1, 0.2, -3.3, 1.1), stde = 50)
m1 &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m1)
predictOMatic(m1)
plotCurves(m1, plotx = "x2")

## interaction between x1 and x2
dat &lt;- genCorrelatedData2(N = 1000, rho = 0.2,
    beta = c(1, 1.0, -1.1, 0.1, 0.0, 0.16), stde = 1)
summarize(dat)
## Fit wrong model? get "wrong" result
m2w &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m2w)
## Include interaction
m2 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m2)

dat &lt;- genCorrelatedData2(N = 1000, rho = 0.2,
    beta = c(1, 1.0, -1.1, 0.1, 0.0, 0.16), stde = 100)
summarize(dat)
m2.2 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m2.2)

dat &lt;- genCorrelatedData2(N = 1000, means = c(100, 200, 300, 100),
    sds = 20,  rho = c(0.2, 0.3, 0.1, 0, 0, 0),
    beta = c(1, 1.0, -1.1, 0.1, 0.0, 0.16, 0, 0, 0.2, 0, 0, 1.1, 0, 0, 0.1),
    stde = 200)
summarize(dat)
m2.3w &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m2)

m2.3 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m2.3)

predictOMatic(m2.3)
plotCurves(m2.3, plotx = "x1", modx = "x2", modxVals = "std.dev.", n = 5)

simReg &lt;- lapply(1:100, function(x){
    dat &lt;- genCorrelatedData2(N = 1000, rho = c(0.2),
        beta = c(1, 1.0, -1.1, 0.1, 0.0, 0.46), verbose = FALSE)
    mymod &lt;- lm (y ~ x1 * x2 + x3, data = dat)
    summary(mymod)
})

x3est &lt;- sapply(simReg, function(reg) {coef(reg)[4 ,1] })
summarize(x3est)
hist(x3est,  breaks = 40, prob = TRUE,
    xlab = "Estimated Coefficients for column x3")

r2est &lt;- sapply(simReg, function(reg) {reg$r.square})
summarize(r2est)
hist(r2est,  breaks = 40, prob = TRUE, xlab = "Estimates of R-square")

## No interaction, collinearity
dat &lt;- genCorrelatedData2(N = 1000, rho = c(0.1, 0.2, 0.7),
    beta = c(1, 1.0, -1.1, 0.1), stde = 1)
m3 &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m3)

dat &lt;- genCorrelatedData2(N=1000, rho=c(0.1, 0.2, 0.7),
    beta = c(1, 1.0, -1.1, 0.1), stde = 200)
m3 &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m3)
mcDiagnose(m3)

dat &lt;- genCorrelatedData2(N = 1000, rho = c(0.9, 0.5, 0.4),
    beta = c(1, 1.0, -1.1, 0.1), stde = 200)
m3b &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m3b)
mcDiagnose(m3b)

</code></pre>

<hr>
<h2 id='genCorrelatedData3'>Generate correlated data for simulations (third edition)</h2><span id='topic+genCorrelatedData3'></span>

<h3>Description</h3>

<p>This is a revision of <code>genCorrelatedData2</code>.  The output is a
data frame that has columns for the predictors along with an error
term, the linear predictor, and the observed value of the outcome
variable.  The new features are in the user interface. It has a
better way to specify beta coefficients. It is also more flexible
in the specification of the names of the predictor columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genCorrelatedData3(
  formula,
  N = 100,
  means = c(x1 = 50, x2 = 50, x3 = 50),
  sds = 10,
  rho = 0,
  stde = 1,
  beta = c(0, 0.15, 0.1, -0.1),
  intercept = FALSE,
  col.names,
  verbose = FALSE,
  ...,
  distrib = rnorm
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genCorrelatedData3_+3A_formula">formula</code></td>
<td>
<p>a text variable, e.g., <code>"y ~ 1 + 2*x1"</code>. Use
&quot;:&quot; to create squared and interaction terms,
<code>"y ~ 1 + 2*x1 + 1.1*x1:x1 + 0.2*x1:x2".</code> Multi-way
interactions are allowed, eg
<code>"y ~ 1 + 2*x1 + .4*x2 + .1*x3 + 1.1*x1:x1 + 0.2*x1:x2:x3".</code>
Note author can specify any order of interation.</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_means">means</code></td>
<td>
<p>averages of predictors, can include names c(x1 = 10,
x2 = 20) that will be used in the data.frame result.</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_sds">sds</code></td>
<td>
<p>standard deviations, 1 (common value for all variables)
or as many elements as in <code>means</code>.</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_rho">rho</code></td>
<td>
<p>correlations, can be 1 or a vech for a correlation
matrix</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_stde">stde</code></td>
<td>
<p>The scale of the error term. If <code>distrib=rnorm</code>,
stde is the standard deviation of the error term. If the user
changes the distribution, this is a scale parameter that may
not be equal to the standard deviation. For example,
<code>distrib=rlogist</code> has a scale parameter such that a value
of stde implies the error's standard deviation will be
<code class="reqn">stde * pi / sqrt(3)</code>.</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_beta">beta</code></td>
<td>
<p>slope coefficients, use either this or <code>formula</code>,
not both. It is easier (less error prone) to use named
coefficients, but (for backwards compatability with
<code>genCorrelatedData2</code>) names are not required. If named,
use &quot;Intercept&quot; for the intercept coefficient, and use
variable names that match the <code>xmeans</code> vector.  Un-named
coefficients follow same rules as in
<code><a href="#topic+genCorrelatedData2">genCorrelatedData2</a></code>. The first (1 + p) values are
for the intercept and p main effects.  With 3 predictors and
no squares or interactions, specify four betas corresponding
to <code>c(Intercept, x1, x2, x3)</code>. The squared and
interaction terms may follow.  The largest possible model
would correspond to <code>c(Intercept, x1, x2, x3, x1:x1,
x1:x2, x1:x3, x2:x2, x2:x3, x3:x3)</code>.  Squares and interactions
fill in a &quot;lower triangle&quot;. The unnamed beta vector can be
terminated with the last non-zero coefficient, the function
will insert 0's for the coefficients at the end of the vector.</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_intercept">intercept</code></td>
<td>
<p>TRUE or FALSE. Should the output data set include
a column of 1's. If beta is an unnamed vector, should the
first element be treated as an intercept?</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_col.names">col.names</code></td>
<td>
<p>Can override names in means vector</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_verbose">verbose</code></td>
<td>
<p>TRUE for diagnostics</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_...">...</code></td>
<td>
<p>extra arguments, ignored for now. We use that to ignore
unrecognized parameters.</p>
</td></tr>
<tr><td><code id="genCorrelatedData3_+3A_distrib">distrib</code></td>
<td>
<p>An R random data generating function.  Default is
<code>rnorm</code>. Also <code>rlogis</code> or any other two-parameter
location/scale distribution will work. Special configuration
allows <code>rt</code>. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The enhanced methods for authors to specify a data-generating
process are as follows. Either way will work and the choice
between the methods is driven by the author's convenience.<br />
</p>

<ul>
<li><p> 1. Use the formula argument as a quoted string:
<code>"1 + 2.2 * x1 + 2.3 * x2 + 3.3 * x3 + 1.9 * x1:x2"</code>.
The &quot;*&quot; represents multiplication of coefficient times variable,
and the colon &quot;:&quot; has same meaning but it is used for products of variables.
</p>
</li>
<li><p> 2. Use the beta argument with parameter names, <code>beta =
c("Intercept" = 1, x1 = 2.2, x2 = 2.3, x3 = 3.3, "x1:x2" = 1.9)</code>
where the names are the same as the names of the variables in the
formula. Names of the variables in the formula or the beta vector
should be used also in either the means parameter or the col.names
parameter.
</p>
</li></ul>

<p>The error distribution can be specified. Default is normal, with
draws provided by R's <code>rnorm</code>. All error models assume
<code class="reqn">E[e] = 0</code> and the scale coefficient is the parameter
<code>stde</code>. Thus, the default setup's error will be drawn from
<code>rnorm(N, 0, stde)</code>. Any two parameter &quot;location&quot; and &quot;scale&quot;
distribution should work as well, as long as the first coefficient
is location (because we set that as 0 in all cases) and the second
argument is scale. For example, <code>distrib=rlogis</code>, will lead
to errors drawn from <code>rlogis(N, 0, stde)</code>. Caution: in rlogis,
the scale parameter is not the same as standard deviation.
</p>
<p>The only one parameter distribution currently supported is the T
distribution.  If user specifies <code>distrib=rt</code>, then the
<code>stde</code> is passed through to the parameter <code>df</code>. Note
that if increasing the stde parameter will cause the standard
deviation of <code>rt</code> to get smaller. <code>df=1</code> implies sd =
794.6; <code>df=2</code> implies sd = 3.27; <code>df=3</code> implies 1.7773.
</p>
<p>Methods to specify error distributions in a more flexible way need
to be considered.
</p>


<h3>Value</h3>

<p>a data frame
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a> and Gabor Grothendieck &lt;ggrothendieck@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123123)
## note: x4 is an unused variable in formula
X1a &lt;-
    genCorrelatedData3("y ~ 1.1 + 2.1 * x1 + 3 * x2 + 3.5 * x3 + 1.1 * x1:x3",
                       N = 1000, means = c(x1 = 1, x2 = -1, x3 = 3, x4 = 1),
                       sds = 1, rho = 0.4, stde = 5)
lm1a &lt;- lm(y ~ x1 + x2 + x3 + x1:x3, data = X1a)
## note that normal errors have std.error. close to 5
summary(lm1a)
attr(X1a, "beta") 
attr(X1a, "formula")
## Demonstrate name beta vector method to provide named arguments
set.seed(123123)
X2 &lt;- genCorrelatedData3(N = 1000, means = c(x1 = 1, x2 = -1, x3 = 3, x4 = 1),
          sds = 1, rho = 0.4, 
          beta = c("Intercept" = 1.1, x1 = 2.1, x2 = 3,
                    x3 = 3.5, "x1:x3" = 1.1),
                    intercept = TRUE, stde = 5)
attr(X2, c("beta"))
attr(X2, c("formula"))
head(X2)
lm2 &lt;- lm(y ~ x1 + x2 + x3 + x1:x3, data = X2)
summary(lm2)

## Equivalent with unnamed beta vector. Must carefully count empty
## spots, fill in 0's when coefficient is not present. This
## method was in genCorrelated2. Order of coefficents is
## c(intercept, x1, ..., xp, x1:x1, x1:x2, x1:xp, x2:x2, x2:x3, ..., )
## filling in a lower triangle.
set.seed(123123)
X3 &lt;- genCorrelatedData3(N = 1000, means = c(x1 = 1, x2 = -1, x3 = 3, x4 = 1),
          sds = 1, rho = 0.4, 
          beta = c(1.1, 2.1, 3, 3.5, 0, 0, 0, 1.1),
                    intercept = TRUE, stde = 5)
attr(X3, c("beta"))
attr(X3, c("formula"))
head(X3)
lm3 &lt;- lm(y ~ x1 + x2 + x3 + x1:x3, data = X3)
summary(lm3)

## Same with more interesting variable names in the means vector
X3 &lt;- genCorrelatedData3(N = 1000,
          means = c(friend = 1, enemy = -1, ally = 3, neutral = 1),
          sds = 1, rho = 0.4, 
          beta = c(1.1, 2.1, 3, 3.5, 0, 0, 0, 1.1),
                    intercept = TRUE, stde = 5)
head(X3)
attr(X3, c("beta"))


X3 &lt;- genCorrelatedData3(N = 1000, means = c(x1 = 50, x2 = 50, x3 = 50),
          sds = 10, rho = 0.4,
          beta = c("Intercept" = .1, x1 = .01, x2 = .2, x3 = .5,
                   "x1:x3" = .1))
lm3 &lt;- lm(y ~ x1 + x2 + x3 + x1:x3, data = X3)


## Names via col.names argument: must match formula
X2 &lt;- genCorrelatedData3("y ~ 1.1 + 2.1 * educ + 3 * hlth + 3 * ses + 1.1 * educ:ses",
         N = 100, means = c(50, 50, 50, 20),
         sds = 10, rho = 0.4, col.names = c("educ", "hlth", "ses", "wght"))
str(X2) 

X3 &lt;- genCorrelatedData3("y ~ 1.1 + 2.1 * educ + 3 * hlth + 3 * ses + 1.1 * educ:ses",
         N = 100, means = c(50, 50, 50, 20),
         sds = 10, rho = 0.4, col.names = c("educ", "hlth", "ses", "wght"),
         intercept = TRUE)
str(X3)

## note the logistic errors have residual std.error approximately 5 * pi/sqrt(3)
X1b &lt;-
    genCorrelatedData3("y ~ 1.1 + 2.1 * x1 + 3 * x2 + 3.5 * x3 + 1.1 * x1:x3",
                       N = 1000, means = c(x1 = 1, x2 = -1, x3 = 3),
                       sds = 1, rho = 0.4, stde = 5, distrib = rlogis)
lm1b &lt;- lm(y ~ x1 + x2 + x3 + x1:x3, data = X1b)
summary(lm1b)

## t distribution is very sensitive for fractional df between 1 and 2 (recall
## stde parameter is passed through to df in rt.
X1c &lt;-
    genCorrelatedData3("y ~ 1.1 + 2.1 * x1 + 3 * x2 + 3.5 * x3 + 1.1 * x1:x3",
                       N = 1000, means = c(x1 = 1, x2 = -1, x3 = 3),
                       sds = 1, rho = 0.4, stde = 1.2, distrib = rt)
lm1c &lt;- lm(y ~ x1 + x2 + x3 + x1:x3, data = X1c)
summary(lm1c)

</code></pre>

<hr>
<h2 id='genX'>Generate correlated data (predictors) for one unit</h2><span id='topic+genX'></span>

<h3>Description</h3>

<p>This is used to generate data for one unit. It is recently
re-designed to serve as a building block in a multi-level data
simulation exercise.  The new arguments &quot;unit&quot; and &quot;idx&quot; can be
set as NULL to remove the multi-level unit and row naming
features.  This function uses the rockchalk::mvrnorm function, but
introduces a convenience layer by allowing users to supply
standard deviations and the correlation matrix rather than the
variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genX(
  N,
  means,
  sds,
  rho,
  Sigma = NULL,
  intercept = TRUE,
  col.names = NULL,
  unit = NULL,
  idx = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genX_+3A_n">N</code></td>
<td>
<p>Number of cases desired</p>
</td></tr>
<tr><td><code id="genX_+3A_means">means</code></td>
<td>
<p>A vector of means for p variables. It is optional to
name them.  This implicitly sets the dimension of the
predictor matrix as N x p. If no names are supplied, the
automatic variable names will be &quot;x1&quot;, &quot;x2&quot;, and so forth. If
means is named, such as c(&quot;myx1&quot; = 7, &quot;myx2&quot; = 13, &quot;myx3&quot; =
44), those names will be come column names in the output
matrix.</p>
</td></tr>
<tr><td><code id="genX_+3A_sds">sds</code></td>
<td>
<p>Standard deviations for the variables.  If less than p
values are supplied, they will be recycled.</p>
</td></tr>
<tr><td><code id="genX_+3A_rho">rho</code></td>
<td>
<p>Correlation coefficient for p variables. Several input
formats are allowed (see <code>lazyCor</code>). This can be a single
number (common correlation among all variables), a full matrix
of correlations among all variables, or a vector that is
interpreted as the strictly lower triangle (a vech).</p>
</td></tr>
<tr><td><code id="genX_+3A_sigma">Sigma</code></td>
<td>
<p>P x P variance/covariance matrix.</p>
</td></tr>
<tr><td><code id="genX_+3A_intercept">intercept</code></td>
<td>
<p>Default = TRUE, do you want a first column filled
with 1?</p>
</td></tr>
<tr><td><code id="genX_+3A_col.names">col.names</code></td>
<td>
<p>Names supplied here will override column names
supplied with the means parameter. If no names are supplied
with means, or here, we will name variables x1, x2, x3,
... xp, with Intercept at front of list if intercept =
TRUE.</p>
</td></tr>
<tr><td><code id="genX_+3A_unit">unit</code></td>
<td>
<p>A character string for the name of the unit being
simulated. Might be referred to as a &quot;group&quot; or &quot;district&quot; or
&quot;level 2&quot; membership indicator.</p>
</td></tr>
<tr><td><code id="genX_+3A_idx">idx</code></td>
<td>
<p>If set TRUE, a column &quot;idx&quot; is added, numbering the
rows from 1:N. If the argument unit is not NULL, then idx is
set to TRUE, but that behavior can be overridded by
setting idx = FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Today I've decided to make the return object a data frame.  This
allows the possibility of including a character variable &quot;unit&quot;
within the result.  For multi-level models, that will help.  If
unit is not NULL, its value will be added as a column in the data
frame. If unit is not null, the rownames will be constructed by
pasting &quot;unit&quot; name and idx. If unit is not null, then idx will
be included as another column, unless the user explicitly sets
idx = FALSE.
</p>


<h3>Value</h3>

<p>A data frame with rownames to specify unit and
individual values, including an attribute &quot;unit&quot; with the
unit's name.
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- genX(10, means = c(7, 8), sds = 3, rho = .4)
X2 &lt;- genX(10, means = c(7, 8), sds = 3, rho = .4, unit = "Kansas")
head(X2)
X3 &lt;- genX(10, means = c(7, 8), sds = 3, rho = .4, idx = FALSE, unit = "Iowa")
head(X3)
X4 &lt;- genX(10, means = c("A" = 7, "B" = 8), sds = c(3), rho = .4)
head(X4)
X5 &lt;- genX(10, means = c(7, 3, 7, 5), sds = c(3, 6),
            rho = .5, col.names = c("Fred", "Sally", "Henry", "Barbi"))
head(X5)
Sigma &lt;- lazyCov(Rho = c(.2, .3, .4, .5, .2, .1), Sd = c(2, 3, 1, 4))
X6 &lt;- genX(10, means = c(5, 2, -19, 33), Sigma = Sigma, unit = "Winslow_AZ")
head(X6)

</code></pre>

<hr>
<h2 id='getAuxRsq'>retrieves estimates of the coefficient of determination from a list of regressions</h2><span id='topic+getAuxRsq'></span>

<h3>Description</h3>

<p>Asks each regression model in a list for a summary and then reports the R-squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAuxRsq(auxRegs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getAuxRsq_+3A_auxregs">auxRegs</code></td>
<td>
<p>a list of fitted regression objects</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of the same length as auxRegs.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='getDeltaRsquare'>Calculates the delta R-squares, also known as squared
semi-partial correlation coefficients.</h2><span id='topic+getDeltaRsquare'></span>

<h3>Description</h3>

<p>The change in the R-square when a variable is removed from a
regression is called delta R-square. It is sometimes suggested as
a way to determine whether a variable has a substantial effect on
an outcome. This is also known as the squared semi-partial correlation
coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDeltaRsquare(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDeltaRsquare_+3A_model">model</code></td>
<td>
<p>a fitted regression model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of estimates of the delta R-squares
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- genCorrelatedData(N=250, means=c(100,100),
sds=c(30,20), rho=0.0,  stde = 7, beta=c(1.1, 2.4, 4.1, 0))
m1 &lt;- lm(y ~ x1 + x2, data=dat1)
getDeltaRsquare(m1)
## more problematic in presence of collinearity
dat2 &lt;- genCorrelatedData(N=250, means=c(100,100),
sds=c(30,20), rho=0.6,  stde = 7, beta=c(1.1, 2.4, 4.1, 0))
m2 &lt;- lm(y ~ x1 + x2, data=dat2)
getDeltaRsquare(m2)
</code></pre>

<hr>
<h2 id='getFocal'>Select focal values from an observed variable.</h2><span id='topic+getFocal'></span><span id='topic+getFocal.default'></span><span id='topic+getFocal.factor'></span><span id='topic+getFocal.character'></span>

<h3>Description</h3>

<p>This is a generic function with 2 methods, getFocal.default
handles numeric variables, while getFocal.factor handles
factors. No other methods have been planned for preparation.
</p>
<p>Many plotting functions need to select &quot;focal&quot; values from
a variable. There is a family of functions that are used
to do that.  User requests can be accepted in a number
of ways. Numeric and character variables will be treated
differently. Please see details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFocal(x, ...)

## Default S3 method:
getFocal(x, xvals = NULL, n = 3, pct = TRUE, ...)

## S3 method for class 'factor'
getFocal(x, xvals = NULL, n = 3, pct = TRUE, ...)

## S3 method for class 'character'
getFocal(x, xvals = NULL, n = 3, pct = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getFocal_+3A_x">x</code></td>
<td>
<p>Required. A variable</p>
</td></tr>
<tr><td><code id="getFocal_+3A_...">...</code></td>
<td>
<p>Other arguments that will be passed to the
user-specified xvals function.</p>
</td></tr>
<tr><td><code id="getFocal_+3A_xvals">xvals</code></td>
<td>
<p>A function name (either &quot;quantile&quot;, &quot;std.dev.&quot;,
&quot;table&quot;, or &quot;seq&quot;) or a user-supplied function that can receive
x and return a selection of values.</p>
</td></tr>
<tr><td><code id="getFocal_+3A_n">n</code></td>
<td>
<p>Number of values to be selected.</p>
</td></tr>
<tr><td><code id="getFocal_+3A_pct">pct</code></td>
<td>
<p>Default TRUE. Include percentage of observed cases
in variable name? (used in legends)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is used in functions like <code>plotSlopes</code> or
<code>plotCurves</code>.
</p>
<p>If <code>xvals</code> is not provided, a default divider for numeric
variables will be the algorithm &quot;quantile&quot;. The divider algorithms
provided with rockchalk are c(&quot;quantile&quot;, &quot;std.dev.&quot;, &quot;table&quot;,
&quot;seq&quot;).  <code>xvals</code> can also be the name of a user-supplied
function, such as R's <code>pretty()</code>. If the user supplies a
vector of possible values, that selection will be checked to make
sure all elements are within a slightly expanded range of
<code>x</code>. If a value out of range is requested, a warning is
issued. Maybe that should be an outright error?
</p>
<p>With factor variables, <code>xvals</code> is generally not used because
the only implemented divider algorithm is &quot;table&quot; (see
<code>cutByTable</code>), which selects the <code>n</code> most frequently
observed values. That is the default algorithm. It is legal to
specify xvals = &quot;table&quot;, but there is no point in doing
that. However, xvals may take two other formats. It may be a
user-specified function that can select levels values from
<code>x</code> or it may be a vector of labels (or, names of
levels). The purpose of the latter is to check that the requested
levels are actually present in the supplied data vector
<code>x</code>. If the levels specified are not in the observed
variable, then this function stops with an error message.
</p>


<h3>Value</h3>

<p>A vector.
</p>
<p>A named vector of values.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
getFocal(x)
getFocal(x, xvals = "quantile")
getFocal(x, xvals = "quantile", n = 5)
getFocal(x, xvals = "std.dev")
getFocal(x, xvals = "std.dev", n = 5)
getFocal(x, xvals = c(-1000, 0.2, 0,5))
x &lt;- factor(c("A","B","A","B","C","D","D","D"))
getFocal(x)
getFocal(x, n = 2)

x &lt;- c("A","B","A","B","C","D","D","D")
getFocal(x)
getFocal(x, n = 2)

</code></pre>

<hr>
<h2 id='getPartialCor'>Calculates partial correlation coefficients after retrieving data matrix froma fitted regression model</h2><span id='topic+getPartialCor'></span>

<h3>Description</h3>

<p>The input is a fitted regression model, from which the design
matrix is retrieved, along with the dependent variable. The
partial correlation is calculated using matrix algebra that
has not been closely inspected for numerical precision.  That is to
say, it is in the stats book style, rather than the numerically
optimized calculating format that functions like <code>lm()</code> have adopted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPartialCor(model, dvonly = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPartialCor_+3A_model">model</code></td>
<td>
<p>A fitted regression model, such as output from
lm(). Any object that has methods model.matrix and model.frame
will be sufficient.</p>
</td></tr>
<tr><td><code id="getPartialCor_+3A_dvonly">dvonly</code></td>
<td>
<p>Default = TRUE. Only show first column of the full
partial correlation matrix. That corresponds to the partial correlation of each predictor with y. I mean, r[yx].[others]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>I often criticize partial correlations because they change in a
very unstable way as terms are added or removed in regression
models. Nevertheless, I teach with books that endorse them, and in
order to have something to criticize, I need to have a function
like this. There are other packages that offer partial correlation
calculations, but they are either 1) not easy to install from CRAN
because of dependencies or 2) do not directly calculate the values
we want to see.
</p>
<p>To students. 1) This gives the same result as the function
<code>cov2pcor</code> in <code>gRbase</code>, so far as I can tell. Why use
this?  Simply for convenenience.  We have found that installing
gRbase is a problem because it depends on packages in
Bioconductor.  2) By default, I show only one column of output,
the partial correlations involving the dependent variable as
something being explained. The other columns that would depict the
dependent variable as a predictor of the independent variables
have been omitted. You can let me know if you think that's wrong.
</p>
<p>Please note I have not gone out of my way to make this calculation
&quot;numerically stable.&quot;  It does not use any orthogonal matrix
calculations; it is using the same textbook theoretical stats
formula that is used by cov2pcor in gRbase and in every other
package or online source I could find. I prepared a little
WorkingExample file matrix-partial-correlations-1.R that
discusses this, in case you are interested (http://pj.freefaculty.org/R).
</p>


<h3>Value</h3>

<p>A column or matrix of partial correlation coefficients
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='getVIF'>Converts the R-square to the variance inflation factor</h2><span id='topic+getVIF'></span>

<h3>Description</h3>

<p>calculates vif = 1/(1-R-square)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getVIF(rsq)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getVIF_+3A_rsq">rsq</code></td>
<td>
<p>a vector of real values, presumably fitted R-squares</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of vif estimates
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='gmc'>Group Mean Center: Generate group summaries and individual deviations within groups</h2><span id='topic+gmc'></span>

<h3>Description</h3>

<p>Multilevel modelers often need to include predictors like the
within-group mean and the deviations of individuals around the
mean. This function makes it easy (almost foolproof) to calculate
those variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmc(dframe, x, by, FUN = mean, suffix = c("_mn", "_dev"), fulldataframe = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gmc_+3A_dframe">dframe</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="gmc_+3A_x">x</code></td>
<td>
<p>Variable names or a vector of variable names. Do NOT
supply a variable like dat$x1, do supply a quoted variable
name &quot;x1&quot; or a vector c(&quot;x1&quot;, &quot;x2&quot;)</p>
</td></tr>
<tr><td><code id="gmc_+3A_by">by</code></td>
<td>
<p>A grouping variable name or a vector of grouping
names. Do NOT supply a variable like dat$xfactor, do supply a
name &quot;xfactor&quot;, or a vector c(&quot;xfac1&quot;, &quot;xfac2&quot;).</p>
</td></tr>
<tr><td><code id="gmc_+3A_fun">FUN</code></td>
<td>
<p>Defaults to the mean, have not tested alternatives</p>
</td></tr>
<tr><td><code id="gmc_+3A_suffix">suffix</code></td>
<td>
<p>The suffixes to be added to column 1 and column 2</p>
</td></tr>
<tr><td><code id="gmc_+3A_fulldataframe">fulldataframe</code></td>
<td>
<p>Default TRUE. original data frame is returned
with new columna added (which I would call &quot;Stata style&quot;). If
FALSE, this will return only newly created columns, the
variables with suffix[1] and suffix[2] appended to names.
TRUE is easier (maybe safer), but also wastes memory.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This was originally just for &quot;group mean-centered&quot; data, but now
is more general, can accept functions like median to calculate
center and then deviations about that center value within the
group.
</p>
<p>Similar to Stata egen, except more versatile and fun! Will create
2 new columns for each variable, with suffixes for the summary and
deviations (default suffixes are &quot;_mn&quot; and &quot;_dev&quot;. Rows will match
the rows of the original data frame, so it will be easy to merge
or cbind them back together.
</p>


<h3>Value</h3>

<p>Depending on <code>fulldataframe</code>, either a new data frame
with center and deviation columns, or or original data frame
with &quot;x_mn&quot; and &quot;x_dev&quot; variables appended (Stata style).
</p>


<h3>Author(s)</h3>

<p>Paul Johnson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Make a data frame out of the state data collection (see ?state)
data(state)
statenew &lt;- as.data.frame(state.x77)
statenew$region &lt;- state.region
statenew$state &lt;- rownames(statenew)
head(statenew.gmc1 &lt;- gmc(statenew, c("Income", "Population"), by = "region"))
head(statenew.gmc2 &lt;- gmc(statenew, c("Income", "Population"), by = "region",
   fulldataframe = FALSE))
## Note dangerous step: assumes row alignment is correct.
## return has rownames from original set to identify danger
head(statenew2 &lt;- cbind(statenew, statenew.gmc2))
if(!all.equal(rownames(statenew), rownames(statenew.gmc2))){
   warning("Data row-alignment probable error")
}
## The following box plots should be identical
boxplot(Income ~ region, statenew.gmc1)
boxplot((Income_mn + Income_dev) ~ region, statenew.gmc1)
## Multiple by variables
fakedat &lt;- data.frame(i = 1:200, j = gl(4, 50), k = gl(20, 10),
                      y1 = rnorm(200), y2 = rnorm(200))
head(gmc(fakedat, "y1", by = "k"), 20)
head(gmc(fakedat, "y1", by = c("j", "k"), fulldataframe = FALSE), 40)
head(gmc(fakedat, c("y1", "y2"), by = c("j", "k"), fulldataframe = FALSE))
## Check missing value management
fakedat[2, "k"] &lt;- NA
fakedat[4, "j"] &lt;- NA##' head(gmc(fakedat, "y1", by = "k"), 20)
head(gmc(fakedat, "y1", by = c("j", "k"), fulldataframe = FALSE), 40)
</code></pre>

<hr>
<h2 id='kurtosis'>Calculate excess kurtosis</h2><span id='topic+kurtosis'></span>

<h3>Description</h3>

<p>Kurtosis is a summary of a distribution's shape, using the Normal
distribution as a comparison. A distribution with high kurtosis is
said to be leptokurtic. It has wider, &quot;fatter&quot; tails and a
&quot;sharper&quot;, more &quot;peaked&quot; center than a Normal distribution. In a
standard Normal distribution, the kurtosis is 3.  The term
&quot;excess kurtosis&quot; refers to the difference <code class="reqn">kurtosis - 3</code>.
Many researchers use the term kurtosis to refer to
&quot;excess kurtosis&quot; and this function follows suit.  The user may
set excess = FALSE, in which case the uncentered kurtosis is
returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kurtosis(x, na.rm = TRUE, excess = TRUE, unbiased = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kurtosis_+3A_x">x</code></td>
<td>
<p>A numeric variable (vector)</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_na.rm">na.rm</code></td>
<td>
<p>default TRUE. If na.rm = FALSE and there are missing
values, the mean and variance are undefined and this function
returns NA.</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_excess">excess</code></td>
<td>
<p>default TRUE. If true, function returns excess
kurtosis (kurtosis -3). If false, the return is simply
kurtosis as defined above.</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_unbiased">unbiased</code></td>
<td>
<p>default TRUE. Should the denominator of the
variance estimate be divided by N-1, rather than N?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If kurtosis is smaller than 3 (or excess kurtosis is negative),
the tails are &quot;thinner&quot; than the normal distribution (there is
lower chance of extreme deviations around the mean). If kurtosis
is greater than 3 (excess kurtosis positive), then the tails are
fatter (observations can be spread more widely than in the Normal
distribution).
</p>
<p>The kurtosis may be calculated with the small-sample
bias-corrected estimate of the variance. Set unbiased = FALSE if
this is not desired.  It appears somewhat controversial whether
this is necessary. According to the
US NIST,
<a href="http://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm">http://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm</a>,
kurtosis is defined as
</p>
<p style="text-align: center;"><code class="reqn">kurtosis =  ( mean((x - mean(x))^4) )/ var(x)^2</code>
</p>

<p>where <code class="reqn">var(x)</code> is calculated with the denominator <code class="reqn">N</code>,
rather than <code class="reqn">N-1</code>.
</p>
<p>A distribution is said to be leptokurtic if it is tightly bunched
in the center (spiked) and there are long tails. The long tails
reflect the probability of extreme values.
</p>


<h3>Value</h3>

<p>A scalar value or NA
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='lazyCor'>Create correlation matrices.</h2><span id='topic+lazyCor'></span>

<h3>Description</h3>

<p>Use can supply either a single value (the common correlation among
all variables), a column of the lower triangular values for a
correlation matrix, or a candidate matrix. The function will check
X and do the right thing. If X is a matrix, check that it
is a valid correlation matrix. If its a single value, use that
to fill up a matrix. If itis a vector, try to use it as a vech
to fill the lower triangle..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lazyCor(X, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lazyCor_+3A_x">X</code></td>
<td>
<p>Required. May be one value, a vech, or a matrix</p>
</td></tr>
<tr><td><code id="lazyCor_+3A_d">d</code></td>
<td>
<p>Optional. The number of rows in the correlation matrix to
be created. lazyCor will deduce the desired size from X if
possible. If X is a single value, d is a required argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lazyCor(0.5, 8)
lazyCor(c(0.1, 0.2, 0.3))
lazyCor(c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6))
</code></pre>

<hr>
<h2 id='lazyCov'>Create covariance matrix from correlation and standard deviation
information</h2><span id='topic+lazyCov'></span>

<h3>Description</h3>

<p>This is a flexible function that allows lazy R programmers to
create covariance matrix. The user may be lazy because the
correlation and standard deviation infomation may be supplied in a
variety of formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lazyCov(Rho, Sd, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lazyCov_+3A_rho">Rho</code></td>
<td>
<p>Required. May be a single value (correlation common
among all variables), a vector of the lower triangular values
(vech) of a correlation matrix, or a symmetric matrix of
correlation coefficients.</p>
</td></tr>
<tr><td><code id="lazyCov_+3A_sd">Sd</code></td>
<td>
<p>Required. May be a single value (standard deviation
common among all variables) or a vector of standard deviations,
one for each variable.</p>
</td></tr>
<tr><td><code id="lazyCov_+3A_d">d</code></td>
<td>
<p>Optional. Number of rows or columns. lazyCov may be able
to deduce the required dimension of the final matrix from the
input. However, when the user supplies only a single value for
both Rho and Sd, d is necessary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>covariance matrix.
</p>


<h3>Author(s)</h3>

<p><a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##correlation 0.8 for all pairs, standard deviation 1.0 of each
lazyCov(Rho = 0.8, Sd = 1.0, d = 3)
## supply a vech (lower triangular values in a column)
lazyCov(Rho = c(0.1, 0.2, 0.3), Sd = 1.0)
## supply vech with different standard deviations
lazyCov(Rho = c(0.1, 0.2, 0.3), Sd = c(1.0, 2.2, 3.3))
newRho &lt;- lazyCor(c(0.5, 0.6, 0.7, -0.1, 0.1, 0.2))
lazyCov(Rho = newRho, Sd = 1.0)
lazyCov(Rho = newRho, Sd = c(3, 4, 5, 6))
</code></pre>

<hr>
<h2 id='lmAuxiliary'>Estimate leave-one-variable-out regressions</h2><span id='topic+lmAuxiliary'></span>

<h3>Description</h3>

<p>This is a convenience for analysis of multicollinearity in regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmAuxiliary(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lmAuxiliary_+3A_model">model</code></td>
<td>
<p>a fitted regression model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of fitted regressions, one for each omitted variable.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='magRange'>magRange
Magnify the range of a variable.</h2><span id='topic+magRange'></span>

<h3>Description</h3>

<p>By default, R's range function returns the minimum and maximum
values of a variable. This returns a magnified range. It is used
for some plotting functions in the rockchalk package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>magRange(x, mult = 1.25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="magRange_+3A_x">x</code></td>
<td>
<p>an R vector variable</p>
</td></tr>
<tr><td><code id="magRange_+3A_mult">mult</code></td>
<td>
<p>a multiplier by which to magnify the range of the
variable.  A value of 1 leaves the range unchanged. May be a
scalar, in which case both ends of the range are magnified by the
same amount.  May also be a two valued vector, such as c(minMag,
maxMag), in which case the magnification applied to the minimum is
minMag and the magnification of the maximum is maxMag.  After
version 1.5.5, mult may be smaller than 1, thus shrinking the
range. Setting mult to values closer to 0 causes the range to
shrink to the center point from both sides.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- c(0, 0.5, 1.0)
range(x1)
magRange(x1, 1.1)
magRange(x1, c(1.1, 1.4))
magRange(x1, 0.5)
magRange(x1, c(0.1, 0.1))
x1 &lt;- rnorm(100)
range(x1)
magRange(x1)
magRange(x1, 1.5)
magRange(x1, c(1,1.5))
</code></pre>

<hr>
<h2 id='makeSymmetric'>Create Symmetric Matrices, possibly covariance or correlation
matrices, or check a matrix for symmetry and serviceability.</h2><span id='topic+makeSymmetric'></span>

<h3>Description</h3>

<p>Check X and do the right thing. If X is a matrix, check that it is
a valid for the intended purpose (symmetric or correlation or
covariance).  If X a single value, use that to fill up a
matrix. If it is a vector, try to use it as a vech to fill the
lower triangle. If d is supplied as an integer, use that as desired size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeSymmetric(X, d = NULL, diag = NULL, corr = FALSE, cov = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makeSymmetric_+3A_x">X</code></td>
<td>
<p>A single value, a vector (a vech), or a matrix</p>
</td></tr>
<tr><td><code id="makeSymmetric_+3A_d">d</code></td>
<td>
<p>Optional. An integer, the desired number of rows (or
columns). Don't specify this argument if X is already a
matrix.  Only required if X is an integer and diag is not
supplied. Otherwise, the function tries to deduce desired size
of output from X (as a vech) and diag.</p>
</td></tr>
<tr><td><code id="makeSymmetric_+3A_diag">diag</code></td>
<td>
<p>Values for the diagonal. This is important because it
alters the way X is interpreted.  If diag is not provided,
then X is understood to include diagonal elements.</p>
</td></tr>
<tr><td><code id="makeSymmetric_+3A_corr">corr</code></td>
<td>
<p>TRUE or FALSE: Should we construct a correlation
matrix</p>
</td></tr>
<tr><td><code id="makeSymmetric_+3A_cov">cov</code></td>
<td>
<p>TRUE or FALSE: Should this be a covariance matrix?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A d x d matrix
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>makeSymmetric(X = 3, d = 4)
makeSymmetric(X = 3, d = 4, diag = c(99, 98, 97, 96))
makeSymmetric(c(1,2,3))
makeSymmetric(c(1,2,3), d = 5)
makeSymmetric(c(0.8,0.4, 0.2), cov = TRUE)
makeSymmetric(c(0.8,0.4, 0.2), cov = TRUE, diag = c(44, 55, 66))

</code></pre>

<hr>
<h2 id='makeVec'>makeVec for checking or creating vectors</h2><span id='topic+makeVec'></span>

<h3>Description</h3>

<p>This is a convenience for handling function arguments. If x is a
single value, it makes a vector of length d in which all values
are equal to x. If x is a vector, check that its length is d.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeVec(x = NULL, d = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makeVec_+3A_x">x</code></td>
<td>
<p>A single value or a vector</p>
</td></tr>
<tr><td><code id="makeVec_+3A_d">d</code></td>
<td>
<p>An integer, the desired size of the vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length d
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='mcDiagnose'>Multi-collinearity diagnostics</h2><span id='topic+mcDiagnose'></span>

<h3>Description</h3>

<p>Conducts a series of checks for multicollinearity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcDiagnose(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcDiagnose_+3A_model">model</code></td>
<td>
<p>a fitted regression model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of the &quot;auxiliary regressions&quot; that were
fitted during the analysis
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(rockchalk)
N &lt;- 100
dat &lt;- genCorrelatedData3(y~ 0 + 0.2*x1 + 0.2*x2, N=N, means=c(100,200),
                          sds=c(20,30), rho=0.4, stde=10)
dat$x3 &lt;- rnorm(100, m=40, s=4)
m1 &lt;- lm(y ~ x1 + x2 + x3, data=dat)
summary(m1)
m1d &lt;- mcDiagnose(m1)

m2 &lt;- lm(y ~ x1 * x2 + x3, data=dat)
summary(m2)
m2d &lt;- mcDiagnose(m2)



m3 &lt;- lm(y ~ log(10+x1) + x3 + poly(x2,2), data=dat)
summary(m3)
m3d &lt;- mcDiagnose(m3)

N &lt;- 100
x1 &lt;- 50 + rnorm(N)
x2 &lt;- log(rgamma(N, 2,1))
x3 &lt;- rpois(N, lambda=17)
z1 &lt;- gl(5, N/5)
dummies &lt;- contrasts(z1)[ as.numeric(z1), ]
dimnames(dummies) &lt;- NULL ## Avoids row name conflict in data.frame below
y3 &lt;- x1  -.5 * x2 + 0.1 * x2^2 + dummies %*% c(0.1,-0.1,-0.2,0.2)+ 5 * rnorm(N)
dat &lt;- data.frame(x1=x1, x2=x2, x3=x3,  z1=z1, y3 = y3)

m3 &lt;- lm(y3 ~ x1 + poly(x2,2)  + log(x1) + z1, dat)
summary(m3)

mcDiagnose(m3)



</code></pre>

<hr>
<h2 id='mcGraph1'>Illustrate multicollinearity in regression, part 1.</h2><span id='topic+mcGraph1'></span><span id='topic+mcGraph2'></span><span id='topic+mcGraph3'></span>

<h3>Description</h3>

<p>This is a set of functions that faciliates the examination
of multicollinearity. Suppose the &quot;true&quot; relationship is
y[i] = 0.2 * x1[i] + 0.2 * x2[i] + e
where e is Normal(0, stde^2).
</p>
<p>mcGraph1 draws the 3D regression space, but all of the points
are illustrated &quot;in&quot; the flat plane of x1-x2 variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcGraph1(x1, x2, y, x1lab, x2lab, ylab, ...)

mcGraph2(x1, x2, y, rescaley = 1, drawArrows = TRUE, x1lab, x2lab, ylab, ...)

mcGraph3(
  x1,
  x2,
  y,
  interaction = FALSE,
  drawArrows = TRUE,
  x1lab,
  x2lab,
  ylab,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcGraph1_+3A_x1">x1</code></td>
<td>
<p>a predictor vector</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_x2">x2</code></td>
<td>
<p>a predictor vector</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_y">y</code></td>
<td>
<p>the dependent variable</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_x1lab">x1lab</code></td>
<td>
<p>label for the x1 axis, (the one called &quot;xlab&quot; inside persp)</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_x2lab">x2lab</code></td>
<td>
<p>label for the x2 axis, (the one called &quot;ylab&quot; inside persp)</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_ylab">ylab</code></td>
<td>
<p>label for the y (vertical) axis (the one called &quot;zlab&quot; inside persp)</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_...">...</code></td>
<td>
<p>additional parameters passed to persp</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_rescaley">rescaley</code></td>
<td>
<p>a single scalar value or a vector of the same
length as y.</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_drawarrows">drawArrows</code></td>
<td>
<p>TRUE or FALSE, do you want arrows from the plane to observed y?</p>
</td></tr>
<tr><td><code id="mcGraph1_+3A_interaction">interaction</code></td>
<td>
<p>a TRUE or FALSE request for inclusion of the x1-x2 interaction in the regression calculation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are specialized to a particular purpose. If you
just want to draw 3D regressions, look at plotPlane.
</p>


<h3>Value</h3>

<p>mcGraph1 and mcGraph2 return only the perspective matrix
from persp. It is returned so that users can add additional embellishments on the 3D plot (can be used with trans3d)
</p>
<p>mcGraph3 returns a list of 2 objects. 1) the fitted
regression model2) the perspective matrix used with persp to draw
the image.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
## Create data with x1 and x2 correlated at 0.10
dat &lt;- genCorrelatedData(rho=.1, stde=7)

mcGraph1(dat$x1, dat$x2, dat$y, theta=20, phi=8, ticktype="detailed", nticks=10)

set.seed(12345)
## Create data with x1 and x2 correlated at 0.10
dat &lt;- genCorrelatedData(rho=.1, stde=7)
## This will "grow" the "cloud" of points up from the
## x1-x2 axis
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.0, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.1, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.2, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.3, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.4, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.5, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.6, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.7, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.8, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 0.9, theta = 0)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 1, theta = 0)

##rotate this
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 1, theta = 20)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 1, theta = 40)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 1, theta = 60)
mcGraph2(dat$x1, dat$x2, dat$y, rescaley = 1, theta = 80)

## once they reach the top, make them glitter a while
for(i in 1:20){
  mcGraph2(dat$x1, dat$x2, dat$y, rescaley = runif(length(dat$x1), .9,1.1), theta = 0)
}

set.seed(12345)
## Create data with x1 and x2 correlated at 0.10
dat &lt;- genCorrelatedData(rho=.1, stde=7)

mcGraph3(dat$x1, dat$x2, dat$y, theta = 0)

dat2 &lt;- genCorrelatedData(rho = 0, stde = 7)

mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = 0, phi = 10)
mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = 30, phi = 10)
mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = -30, phi = 10)
mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = -30, phi = -10)
mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = -30, phi = -15)

## Run regressions with not-strongly correlated data
modset1 &lt;- list()
for(i in 1:20){
  dat2 &lt;- genCorrelatedData(rho = .1, stde = 7)
  summary(lm( y ~ x1 + x2 , data = dat2))
  modset1[[i]] &lt;- mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = -30)
}


## Run regressions with strongly correlated data
modset2 &lt;- list()
for(i in 1:20){
  dat2 &lt;- genCorrelatedData(rho = .981, stde = 7)
  summary(lm( y ~ x1 + x2 , data = dat2))
  modset2[[i]] &lt;- mcGraph3(dat2$x1, dat2$x2, dat2$y, theta = -30)
}

dat3 &lt;- genCorrelatedData(rho = .981, stde = 100, beta=c(0.1, 0.2, 0.3, -0.1))
mcGraph3(dat3$x1, dat3$x2, dat3$y, theta=-10, interaction = TRUE)
</code></pre>

<hr>
<h2 id='meanCenter'>meanCenter</h2><span id='topic+meanCenter'></span><span id='topic+meanCenter.default'></span>

<h3>Description</h3>

<p>meanCenter selectively centers or standarizes variables in a regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanCenter(
  model,
  centerOnlyInteractors = TRUE,
  centerDV = FALSE,
  standardize = FALSE,
  terms = NULL
)

## Default S3 method:
meanCenter(
  model,
  centerOnlyInteractors = TRUE,
  centerDV = FALSE,
  standardize = FALSE,
  terms = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meanCenter_+3A_model">model</code></td>
<td>
<p>a fitted regression model (presumably from lm)</p>
</td></tr>
<tr><td><code id="meanCenter_+3A_centeronlyinteractors">centerOnlyInteractors</code></td>
<td>
<p>Default TRUE. If FALSE, all numeric
predictors in the regression data frame are centered before
the regression is conducted.</p>
</td></tr>
<tr><td><code id="meanCenter_+3A_centerdv">centerDV</code></td>
<td>
<p>Default FALSE. Should the dependent variable be
centered? Do not set this option to TRUE unless the dependent
variable is a numeric variable. Otherwise, it is an error.</p>
</td></tr>
<tr><td><code id="meanCenter_+3A_standardize">standardize</code></td>
<td>
<p>Default FALSE. Instead of simply mean-centering
the variables, should they also be &quot;standardized&quot; by first
mean-centering and then dividing by the estimated standard
deviation.</p>
</td></tr>
<tr><td><code id="meanCenter_+3A_terms">terms</code></td>
<td>
<p>Optional. A vector of variable names to be
centered. Supplying this argument will stop meanCenter from
searching for interaction terms that might need to be
centered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Works with &quot;lm&quot; class objects, objects estimated by <code>glm()</code>. This
centers some or all of the the predictors and then re-fits the
original model with the new variables. This is a convenience to
researchers who are often urged to center their predictors.  This
is sometimes suggested as a way to ameliorate multi-collinearity
in models that include interaction terms (Aiken and West, 1991;
Cohen, et al 2002). Mean-centering may enhance interpretation of
the regression intercept, but it actually does not help with
multicollinearity.  (Echambadi and Hess, 2007). This function
facilitates comparison of mean-centered models with others by
calculating centered variables.  The defaults will cause a
regression's numeric interactive variables to be mean
centered. Variations on the arguments are discussed in details.
</p>
<p>Suppose the user's formula that fits the original model is
<code>m1 &lt;- lm(y ~ x1*x2 + x3 + x4, data = dat)</code>. The fitted model
will include estimates for predictors <code>x1</code>, <code>x2</code>,
<code>x1:x2</code>, <code>x3</code> and <code>x4</code>. By default,
<code>meanCenter(m1)</code> scans the output to see if there are
interaction terms of the form <code>x1:x2</code>. If so, then x1 and x2
are replaced by centered versions (m1-mean(m1)) and
(m2-mean(m2)). The model is re-estimated with those new variables.
model (the main effect and the interaction). The resulting thing
is &quot;just another regression model&quot;, which can be analyzed or
plotted like any R regression object.
</p>
<p>The user can claim control over which variables are centered in
several ways. Most directly, by specifying a vector of variable
names, the user can claim direct control. For example, the
argument <code>terms=c("x1","x2","x3")</code> would cause 3 predictors
to be centered. If one wants all predictors to be centered, the
argument <code>centerOnlyInteractors</code> should be set to
FALSE. Please note, this WILL NOT center factor variables. But it
will find all numeric predictors and center them.
</p>
<p>The dependent variable will not be centered, unless the user
explicitly requests it by setting centerDV = TRUE.
</p>
<p>As an additional convenience to the user, the argument
<code>standardize = TRUE</code> can be used.  This will divide each
centered variable by its observed standard deviation. For people
who like standardized regression, I suggest this is a better
approach than the <code>standardize</code> function (which is brain-dead
in the style of SPSS). meanCenter with <code>standardize = TRUE</code>
will only try to standardize the numeric predictors.
</p>
<p>To be completely clear, I believe mean-centering is not helpful
with the multicollinearity problem. It doesn't help, it doesn't
hurt.  Only a misunderstanding leads its proponents to claim
otherwise. This is emphasized in the vignette &quot;rockchalk&quot; that is
distributed with this package.
</p>


<h3>Value</h3>

<p>A regression model of the same type as the input model,
with attributes representing the names of the centered variables.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>References</h3>

<p>Aiken, L. S. and West, S.G. (1991). Multiple
Regression: Testing and Interpreting Interactions. Newbury
Park, Calif: Sage Publications.
</p>
<p>Cohen, J., Cohen, P., West, S. G., and Aiken, L. S. (2002). Applied
Multiple Regression/Correlation Analysis for the Behavioral Sciences
(Third.). Routledge Academic.
</p>
<p>Echambadi, R., and Hess, J. D. (2007). Mean-Centering Does Not Alleviate
Collinearity Problems in Moderated Multiple Regression Models.
Marketing Science, 26(3), 438-445.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+standardize">standardize</a></code>
<code><a href="#topic+residualCenter">residualCenter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(rockchalk)
N &lt;- 100
dat &lt;- genCorrelatedData(N = N, means = c(100, 200), sds = c(20, 30),
                         rho = 0.4, stde = 10)
dat$x3 &lt;- rnorm(100, m = 40, s = 4)

m1 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m1)
mcDiagnose(m1)

m1c &lt;- meanCenter(m1)
summary(m1c)
mcDiagnose(m1c)

m2 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m2)
mcDiagnose(m2)

m2c &lt;- meanCenter(m2, standardize = TRUE)
summary(m2c)
mcDiagnose(m2c)

m2c2 &lt;- meanCenter(m2, centerOnlyInteractors = FALSE)
summary(m2c2)

m2c3 &lt;- meanCenter(m2, centerOnlyInteractors = FALSE, centerDV = TRUE)
summary(m2c3)

dat &lt;- genCorrelatedData(N = N, means = c(100, 200), sds = c(20, 30),
                         rho = 0.4, stde = 10)
dat$x3 &lt;- rnorm(100, m = 40, s = 4)
dat$x3 &lt;- gl(4, 25, labels = c("none", "some", "much", "total"))

m3 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m3)
## visualize, for fun
plotPlane(m3, "x1", "x2")

m3c1 &lt;- meanCenter(m3)
summary(m3c1)

## Not exactly the same as a "standardized" regression because the
## interactive variables are centered in the model frame,
## and the term "x1:x2" is never centered again.
m3c2 &lt;- meanCenter(m3, centerDV = TRUE,
                   centerOnlyInteractors = FALSE, standardize = TRUE)
summary(m3c2)

m3st &lt;- standardize(m3)
summary(m3st)

## Make a bigger dataset to see effects better
N &lt;- 500
dat &lt;- genCorrelatedData(N = N, means = c(200,200), sds = c(60,30),
                         rho = 0.2, stde = 10)
dat$x3 &lt;- rnorm(100, m = 40, s = 4)
dat$x3 &lt;- gl(4, 25, labels = c("none", "some", "much", "total"))
dat$y2 &lt;- with(dat,
               0.4 - 0.15 * x1 + 0.04 * x1^2 -
               drop(contrasts(dat$x3)[dat$x3, ] %*% c(-1.9, 0, 5.1))  +
               1000* rnorm(nrow(dat)))
dat$y2 &lt;- drop(dat$y2)

m4literal &lt;- lm(y2 ~ x1 + I(x1*x1) + x2 + x3, data = dat)
summary(m4literal)
plotCurves(m4literal, plotx="x1")
## Superficially, there is multicollinearity (omit the intercept)
cor(model.matrix(m4literal)[ -1 , -1 ])

m4literalmc &lt;- meanCenter(m4literal, terms = "x1")
summary(m4literalmc)

m4literalmcs &lt;- meanCenter(m4literal, terms = "x1", standardize = TRUE)
summary(m4literalmcs)

m4 &lt;- lm(y2 ~ poly(x1, 2, raw = TRUE) + x2 + x3, data = dat)
summary(m4)
plotCurves(m4, plotx="x1")

m4mc1 &lt;- meanCenter(m4, terms = "x1")
summary(m4mc1)

m4mc2 &lt;- meanCenter(m4, terms = "x1", standardize = TRUE)
summary(m4mc2)

m4mc3 &lt;- meanCenter(m4, terms = "x1", centerDV = TRUE, standardize = TRUE)
summary(m4mc3)
</code></pre>

<hr>
<h2 id='model.data'>Create a &quot;raw&quot; (UNTRANSFORMED) data frame equivalent to the input
data that would be required to fit the given model.</h2><span id='topic+model.data'></span>

<h3>Description</h3>

<p>This is a generic method. Unlike model.frame and
model.matrix, this does not return transformed variables. It deals
with regression formulae that have functions like poly(x, d) in
them. It differentiates x from d in those expressions. And it also
manages log(x + 10). The default method works for standarad R
regression models like lm and glm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.data(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model.data_+3A_model">model</code></td>
<td>
<p>A fitted regression model in which the data argument
is specified. This function will fail if the model was not fit
with the data option.</p>
</td></tr>
<tr><td><code id="model.data_+3A_...">...</code></td>
<td>
<p>Arguments passed to implementing methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='model.data.default'>Create a data frame suitable for estimating a model</h2><span id='topic+model.data.default'></span>

<h3>Description</h3>

<p>This is the default method. Works for lm and glm fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
model.data(model, na.action = na.omit, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model.data.default_+3A_model">model</code></td>
<td>
<p>A fitted model</p>
</td></tr>
<tr><td><code id="model.data.default_+3A_na.action">na.action</code></td>
<td>
<p>Defaults to na.omit, so model as it would appear
in user workspace is re-created, except that rows with missing
values are deleted.  Changing this argument to na.pass will
provide the data as it was in the workspace.</p>
</td></tr>
<tr><td><code id="model.data.default_+3A_...">...</code></td>
<td>
<p>Place holder for other arguments, not used at present</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rockchalk)






## first, check if model.data works when there is no data argument
## This used to fail, now OK

x1 &lt;- rnorm(100, m = 100, s = 10)
x2 &lt;- rnorm(100, m = 50, s =20)
y &lt;- rnorm(100, m = 40, s = 3)

m0 &lt;- lm(y ~ log(10+x1) + x2)
m0.data &lt;- model.data(m0)
head(m0.data)


m1 &lt;- lm(log(43 + y) ~ log(10+x1) + x2)
m1.data &lt;- model.data(m1)
head(m1.data)

d &lt;- 3

m2 &lt;- lm(log(d + y) ~ log(10+x1) + x2)
m2.data &lt;- model.data(m2)
head(m2.data)

m3 &lt;- lm(log(y + d) ~ log(10+x1) + x2)
m3.data &lt;- model.data(m3)
head(m3.data)



## check numeric and categorical predictors

x1 &lt;- rpois(100, l=6)
x2 &lt;- rnorm(100, m=50, s=10)
x3 &lt;- rnorm(100)
xcat1 &lt;- gl(2,50, labels=c("M","F"))
xcat2 &lt;- cut(rnorm(100), breaks=c(-Inf, 0, 0.4, 0.9, 1, Inf),
             labels=c("R", "M", "D", "P", "G"))
dat &lt;- data.frame(x1, x2, x3, xcat1, xcat2)
rm(x1, x2, x3, xcat1, xcat2)
dat$xcat1n &lt;- with(dat, contrasts(xcat1)[xcat1, ,drop=FALSE])
dat$xcat2n &lt;- with(dat, contrasts(xcat2)[xcat2, ])

STDE &lt;- 20
dat$y &lt;- with(dat,
              0.03 + 0.8*x1 + 0.1*x2 + 0.7*x3 +
              xcat1n %*% c(2) + xcat2n %*% c(0.1,-2,0.3, 0.1) +
              STDE*rnorm(100))



m1 &lt;- lm(y ~ poly(x1, 2), data=dat)
m1.data &lt;- model.data(m1)
head(m1.data)
attr(m1.data, "varNamesRHS")

## Check to make sure d is not mistaken for a data column
d &lt;- 2
m2 &lt;- lm(y ~ poly(x1, d), data=dat)
m2.data &lt;- model.data(m2)
head(m2.data)
attr(m2.data, "varNamesRHS")


## Check to see how the 10 in log is handled
m3 &lt;- lm(y ~ log(10 + x1) + poly(x1, d) + sin(x2), data=dat)
m3.data &lt;- model.data(m3)
head(m3.data)
attr(m3.data, "varNamesRHS")


m4 &lt;- lm(log(50+y) ~ log(d+10+x1) + poly(x1, 2), data=dat)
m4.data &lt;- model.data(m4)
head(m4.data)
attr(m4.data, "varNamesRHS")


m5 &lt;- lm(y ~ x1*x1, data=dat)
m5.data &lt;- model.data(m5)
head(m5.data)
attr(m5.data, "varNamesRHS")


m6 &lt;- lm(y ~ x1 + I(x1^2), data=dat)
m6.data &lt;- model.data(m6)
head(m6.data)
attr(m6.data, "varNamesRHS")


## Put in some missings.
## poly doesn't work if there are missings, but
## can test with log
dat$x1[sample(100, 5)] &lt;- NA
dat$y[sample(100, 5)] &lt;- NA
dat$x2[sample(100, 5)] &lt;- NA
dat$x3[sample(100,10)] &lt;- NA

m1 &lt;- lm(y ~ log(10 + x1), data=dat)
m1.data &lt;- model.data(m1)
head(m1.data)
summarize(m1.data)
attr(m1.data, "varNamesRHS")



m2 &lt;- lm(y ~ log(x1 + 10), data=dat)
m2.data &lt;- model.data(m2)
head(m2.data)
summarize(m1.data)
attr(m1.data, "varNamesRHS")

d &lt;- 2
m3 &lt;- lm(log(50+y) ~ log(d+10+x1) + x2 + sin(x3), data=dat)
m3.data &lt;- model.data(m3)
head(m3.data)
summarize(m3.data)
attr(m3.data, "varNamesRHS")


m4 &lt;- lm(y ~ I(x1) + I(x1^2) + log(x2), data=dat)
m4.data &lt;- model.data(m4)
summarize(m4.data)
attr(m4.data, "varNamesRHS")


m5 &lt;- lm(y ~ x1 + I(x1^2) + cos(x2), data=dat)
m5.data &lt;- model.data(m5)
head(m5.data)
summarize(m5.data)
attr(m5.data, "varNamesRHS")



## Now try with some variables in the dataframe, some not

x10 &lt;- rnorm(100)
x11 &lt;- rnorm(100)



m6 &lt;- lm(y ~ x1 + I(x1^2) + cos(x2) + log(10 + x10) + sin(x11) +
         x10*x11, data = dat)
m6.data &lt;- model.data(m6)
head(m6.data)
dim(m6.data)
summarize(m5.data)
attr(m6.data, "varNamesRHS")


</code></pre>

<hr>
<h2 id='mvrnorm'>Minor revision of mvrnorm (from <code>MASS</code>) to facilitate replication</h2><span id='topic+mvrnorm'></span>

<h3>Description</h3>

<p>This is the <code><a href="MASS.html#topic+mvrnorm">mvrnorm</a></code> function from the MASS
package (Venables and Ripley, 2002), with one small modification
to facilitate replication of random samples. The aim is to make
sure that, after the seed is reset, the first rows of generated
data are identical no matter what value is chosen for n.  The one
can draw 100 observations, reset the seed, and then draw 110
observations, and the first 100 will match exactly. This is done
to prevent unexpected and peculiar patterns that are observed
when n is altered with MASS package's mvrnorm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrnorm(n = 1, mu, Sigma, tol = 1e-06, empirical = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvrnorm_+3A_n">n</code></td>
<td>
<p>the number of samples (&quot;rows&quot; of data) required.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_mu">mu</code></td>
<td>
<p>a vector giving the means of the variables.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_sigma">Sigma</code></td>
<td>
<p>positive-definite symmetric matrix specifying the
covariance matrix of the variables.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_tol">tol</code></td>
<td>
<p>tolerance (relative to largest variance) for numerical lack
of positive-definiteness in <code>Sigma</code></p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_empirical">empirical</code></td>
<td>
<p>logical. If true, mu and Sigma specify the empirical
not population mean and covariance matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To assure replication, only a very small change is made. The code
in <code>MASS::mvrnorm</code> draws a random sample and fills a matrix
by column, and that matrix is then decomposed.  The change
implemented here fills that matrix by row and the problem is
eliminated.
</p>
<p>Some peculiarities are noticed when the covariance matrix changes
from a diagonal matrix to a more general symmetric matrix
(non-zero elements off-diagonal).  When the covariance is strictly
diagonal, then just one column of the simulated multivariate
normal data will be replicated, but the others are not. This has
very troublesome implications for simulations that draw samples of
various sizes and then base calculations on the separate simulated
columns (i.e., some columns are identical, others are completely
uncorrelated).
</p>


<h3>Value</h3>

<p>If <code>n = 1</code> a vector of the same length as <code>mu</code>, otherwise an
<code>n</code> by <code>length(mu)</code> matrix with one sample in each row.
</p>


<h3>Author(s)</h3>

<p>Ripley, B.D. with revision by Paul E. Johnson
</p>


<h3>References</h3>

<p>Venables, W. N. &amp; Ripley, B. D. (2002) Modern Applied Statistics with
S. Fourth Edition. Springer, New York. ISBN 0-387-95457-0
</p>


<h3>See Also</h3>

<p>For an alternative multivariate normal generator
function, one which has had this fix applied to it,
consider using the new versions of <code><a href="mvtnorm.html#topic+rmvnorm">rmvnorm</a></code> in the
package <code>mvtnorm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
library(rockchalk)

set.seed(12345)
X0 &lt;- MASS::mvrnorm(n=10, mu = c(0,0,0), Sigma = diag(3))
## create a smaller data set, starting at same position
set.seed(12345)
X1 &lt;- MASS::mvrnorm(n=5, mu = c(0,0,0), Sigma = diag(3))
## Create a larger data set
set.seed(12345)
X2 &lt;- MASS::mvrnorm(n=15, mu = c(0,0,0), Sigma = diag(3))
## The first 5 rows in X0, X1, and X2 are not the same
X0
X1
X2
set.seed(12345)
Y0 &lt;- mvrnorm(n=10, mu = c(0,0,0), Sigma = diag(3))
set.seed(12345)
Y1 &lt;- mvrnorm(n=5, mu = c(0,0,0), Sigma = diag(3))
set.seed(12345)
Y2 &lt;- mvrnorm(n=15, mu = c(0,0,0), Sigma = diag(3))
# note results are the same in the first 5 rows:
Y0
Y1
Y2
identical(Y0[1:5, ], Y1[1:5, ])
identical(Y1[1:5, ], Y2[1:5, ])

myR &lt;- lazyCor(X = 0.3, d = 5)
mySD &lt;- c(0.5, 0.5, 0.5, 1.5, 1.5)
myCov &lt;- lazyCov(Rho = myR, Sd = mySD)

set.seed(12345)
X0 &lt;- MASS::mvrnorm(n=10, mu = rep(0, 5), Sigma = myCov)
## create a smaller data set, starting at same position
set.seed(12345)
X1 &lt;- MASS::mvrnorm(n=5, mu = rep(0, 5), Sigma = myCov)
X0
X1
##' set.seed(12345)
Y0 &lt;- rockchalk::mvrnorm(n=10, mu = rep(0, 5), Sigma = myCov)
## create a smaller data set, starting at same position
set.seed(12345)
Y1 &lt;- rockchalk::mvrnorm(n=5, mu = rep(0, 5), Sigma = myCov)
Y0
Y1

</code></pre>

<hr>
<h2 id='newdata'>Create a newdata frame for usage in predict methods</h2><span id='topic+newdata'></span><span id='topic+newdata.default'></span>

<h3>Description</h3>

<p>This is a generic function. The default method covers almost all
regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newdata(model, predVals, n, ...)

## Default S3 method:
newdata(
  model = NULL,
  predVals = NULL,
  n = 3,
  emf = NULL,
  divider = "quantile",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newdata_+3A_model">model</code></td>
<td>
<p>Required. Fitted regression model</p>
</td></tr>
<tr><td><code id="newdata_+3A_predvals">predVals</code></td>
<td>
<p>Predictor Values that deserve investigation.
Previously, the argument was called &quot;fl&quot;.  This can be 1) a
keyword, one of c(&quot;auto&quot;, &quot;margins&quot;) 2) a vector
of variable names, which will use default methods for all named
variables and the central values for non-named variabled, 3) a
named vector with predictor variables and divider algorithms, or
4) a full list that supplies variables and possible values. Please
see details and examples.</p>
</td></tr>
<tr><td><code id="newdata_+3A_n">n</code></td>
<td>
<p>Optional. Default = 3. How many focal values are desired?
This value is used when various divider algorithms are put to use
if the user has specified keywords &quot;default&quot;, &quot;quantile&quot;, &quot;std.dev.&quot;
&quot;seq&quot;, and &quot;table&quot;.</p>
</td></tr>
<tr><td><code id="newdata_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
<tr><td><code id="newdata_+3A_emf">emf</code></td>
<td>
<p>Optional. data frame used to fit model (not a model
frame, which may include transformed variables like
log(x1). Instead, use output from function <code>model.data</code>). It
is UNTRANSFORMED variables (&quot;x&quot; as opposed to poly(x,2).1 and
poly(x,2).2).</p>
</td></tr>
<tr><td><code id="newdata_+3A_divider">divider</code></td>
<td>
<p>Default is &quot;quantile&quot;. Determines the method of
selection. Should be one of c(&quot;quantile&quot;, &quot;std.dev&quot;, &quot;seq&quot;, &quot;table&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It scans the fitted model, discerns the names of the predictors,
and then generates a new data frame.  It can guess values of the
variables that might be substantively interesting, but that
depends on the user-supplied value of predVals.  If not supplied
with a predVals argument, newdata returns a data frame with one
row &ndash; the central values (means and modes) of the variables in
the data frame that was used to fit the model. The user can supply
a keyword &quot;auto&quot; or &quot;margins&quot;. The function will try to do the
&quot;right thing.&quot;
</p>
<p>The <code>predVals</code> can be a named list that supplies specific
values for particular predictors.  Any legal vector of values is
allowed. For example, <code>predVals = list(x1 = c(10, 20, 30), x2
= c(40, 50), xcat = levels(xcat)))</code>. That will create a newdata
object that has all of the &quot;mix and match&quot; combinations for those
values, while the other predictors are set at their central
values.
</p>
<p>If the user declares a variable with the &quot;default&quot; keyword, then
the default divider algorithm is used to select focal values.  The
default divider algorithm is an optional argument of this
function. If the default is not desired, the user can specify a
divider algorithm by character string, either &quot;quantile&quot;,
&quot;std.dev.&quot;, &quot;seq&quot;, or &quot;table&quot;.  The user can mix and match
algorithms along with requests for specific focal values, as in
<code>predVals = list(x1 = "quantile", x2 = "std.dev.", x3 = c(10,
20, 30), xcat1 &lt;- levels(xcat1))</code>
</p>


<h3>Value</h3>

<p>A data frame of x values that could be used as the
data = argument in the original regression model. The attribute
&quot;varNamesRHS&quot; is a vector of the predictor variable names.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p><code>predictOMatic</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rockchalk)

## Replicate some R classics.  The budworm.lg data from predict.glm
## will work properly after re-formatting the information as a data.frame:

## example from Venables and Ripley (2002, pp. 190-2.)
df &lt;- data.frame(ldose = rep(0:5, 2),
                 sex = factor(rep(c("M", "F"), c(6, 6))),
                 SF.numdead = c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16))
df$SF.numalive = 20 - df$SF.numdead

budworm.lg &lt;- glm(cbind(SF.numdead, SF.numalive) ~ sex*ldose,
                  data = df,  family = binomial)

predictOMatic(budworm.lg)

predictOMatic(budworm.lg, n = 7)

predictOMatic(budworm.lg, predVals = c("ldose"), n = 7)

predictOMatic(budworm.lg, predVals = c(ldose = "std.dev.", sex = "table"))



## Now make up a data frame with several numeric and categorical predictors.

set.seed(12345)
N &lt;- 100
x1 &lt;- rpois(N, l = 6)
x2 &lt;- rnorm(N, m = 50, s = 10)
x3 &lt;- rnorm(N)
xcat1 &lt;- gl(2,50, labels = c("M","F"))
xcat2 &lt;- cut(rnorm(N), breaks = c(-Inf, 0, 0.4, 0.9, 1, Inf),
             labels = c("R", "M", "D", "P", "G"))
dat &lt;- data.frame(x1, x2, x3, xcat1, xcat2)
rm(x1, x2, x3, xcat1, xcat2)
dat$xcat1n &lt;- with(dat, contrasts(xcat1)[xcat1, , drop = FALSE])
dat$xcat2n &lt;- with(dat, contrasts(xcat2)[xcat2, ])
STDE &lt;- 15
dat$y &lt;- with(dat,
              0.03 + 0.8*x1 + 0.1*x2 + 0.7*x3 + xcat1n %*% c(2) +
              xcat2n %*% c(0.1,-2,0.3, 0.1) + STDE*rnorm(N))
## Impose some random missings
dat$x1[sample(N, 5)] &lt;- NA
dat$x2[sample(N, 5)] &lt;- NA
dat$x3[sample(N, 5)] &lt;- NA
dat$xcat2[sample(N, 5)] &lt;- NA
dat$xcat1[sample(N, 5)] &lt;- NA
dat$y[sample(N, 5)] &lt;- NA
summarize(dat)


m0 &lt;- lm(y ~ x1 + x2 + xcat1, data = dat)
summary(m0)
## The model.data() function in rockchalk creates as near as possible
## the input data frame.
m0.data &lt;- model.data(m0)
summarize(m0.data)

## no predVals: analyzes each variable separately
(m0.p1 &lt;- predictOMatic(m0))

## requests confidence intervals from the predict function
(m0.p2 &lt;- predictOMatic(m0, interval = "confidence"))

## predVals as vector of variable names: gives "mix and match" predictions
(m0.p3 &lt;- predictOMatic(m0, predVals = c("x1", "x2")))

## predVals as vector of variable names: gives "mix and match" predictions
(m0.p3s &lt;- predictOMatic(m0, predVals = c("x1", "x2"), divider = "std.dev."))

## "seq" is an evenly spaced sequence across the predictor.
(m0.p3q &lt;- predictOMatic(m0, predVals = c("x1", "x2"), divider = "seq"))

(m0.p3i &lt;- predictOMatic(m0, predVals = c("x1", "x2"),
                         interval = "confidence", n = 3))

(m0.p3p &lt;- predictOMatic(m0, predVals = c("x1", "x2"), divider = pretty))

## predVals as vector with named divider algorithms.
(m0.p3 &lt;- predictOMatic(m0, predVals = c(x1 = "seq", x2 = "quantile")))
## predVals as named vector of divider algorithms

## same idea, decided to double-check
(m0.p3 &lt;- predictOMatic(m0, predVals = c(x1 = "quantile", x2 = "std.dev.")))
getFocal(m0.data$x2, xvals =  "std.dev.", n = 5)


## Change from quantile to standard deviation divider
(m0.p5 &lt;- predictOMatic(m0, divider = "std.dev.", n = 5))

## Still can specify particular values if desired
(m0.p6 &lt;- predictOMatic(m0, predVals = list("x1" = c(6,7),
                            "xcat1" = levels(m0.data$xcat1))))

(m0.p7 &lt;- predictOMatic(m0, predVals = c(x1 = "quantile", x2 = "std.dev.")))
getFocal(m0.data$x2, xvals =  "std.dev.", n = 5)

(m0.p8 &lt;- predictOMatic(m0, predVals = list( x1 = quantile(m0.data$x1,
                        na.rm = TRUE, probs = c(0, 0.1, 0.5, 0.8,
                        1.0)), xcat1 = levels(m0.data$xcat1))))

(m0.p9 &lt;- predictOMatic(m0, predVals = list(x1 = "seq", "xcat1" =
                                levels(m0.data$xcat1)), n = 8) )


(m0.p10 &lt;- predictOMatic(m0, predVals = list(x1 = "quantile",
                                 "xcat1" = levels(m0.data$xcat1)), n =  5) )


(m0.p11 &lt;- predictOMatic(m0, predVals = c(x1 = "std.dev."), n = 10))

## Previous same as

(m0.p11 &lt;- predictOMatic(m0, predVals = c(x1 = "default"), divider =
                         "std.dev.", n = 10))

## Previous also same as

(m0.p11 &lt;- predictOMatic(m0, predVals = c("x1"), divider = "std.dev.", n = 10))


(m0.p11 &lt;- predictOMatic(m0,  predVals = list(x1 = c(0, 5, 8), x2 = "default"),
                         divider = "seq"))



m1 &lt;- lm(y ~ log(10+x1) + sin(x2) + x3, data = dat)
m1.data &lt;- model.data(m1)
summarize(m1.data)


(newdata(m1))
(newdata(m1, predVals = list(x1 = c(6, 8, 10))))
(newdata(m1, predVals = list(x1 = c(6, 8, 10), x3 = c(-1,0,1))))
(newdata(m1, predVals = list(x1 = c(6, 8, 10),
                 x2 = quantile(m1.data$x2, na.rm = TRUE), x3 = c(-1,0,1))))

(m1.p1 &lt;- predictOMatic(m1, divider = "std.dev", n = 5))
(m1.p2 &lt;- predictOMatic(m1, divider = "quantile", n = 5))

(m1.p3 &lt;- predictOMatic(m1, predVals = list(x1 = c(6, 8, 10),
                            x2 = median(m1.data$x2, na.rm = TRUE))))

(m1.p4 &lt;- predictOMatic(m1, predVals = list(x1 = c(6, 8, 10),
                                x2 = quantile(m1.data$x2, na.rm = TRUE))))

(m1.p5 &lt;- predictOMatic(m1))
(m1.p6 &lt;- predictOMatic(m1, divider = "std.dev."))
(m1.p7 &lt;- predictOMatic(m1, divider = "std.dev.", n = 3))
(m1.p8 &lt;- predictOMatic(m1, divider = "std.dev.", interval = "confidence"))


m2 &lt;- lm(y ~ x1 + x2 + x3 + xcat1 + xcat2, data = dat)
##  has only columns and rows used in model fit
m2.data &lt;- model.data(m2)
summarize(m2.data)

## Check all the margins
(predictOMatic(m2, interval = "conf"))

## Lets construct predictions the "old fashioned way" for comparison

m2.new1 &lt;- newdata(m2, predVals = list(xcat1 = levels(m2.data$xcat1),
                           xcat2 = levels(m2.data$xcat2)), n = 5)
predict(m2, newdata = m2.new1)


(m2.p1 &lt;- predictOMatic(m2,
                        predVals = list(xcat1 = levels(m2.data$xcat1),
                            xcat2 = levels(m2.data$xcat2)),
                        xcat2 = c("M","D")))
## See? same!

## Pick some particular values for focus
m2.new2 &lt;- newdata(m2, predVals = list(x1 = c(1,2,3), xcat2 = c("M","D")))
## Ask for predictions
predict(m2, newdata = m2.new2)


## Compare: predictOMatic generates a newdata frame and predictions in one step

(m2.p2 &lt;- predictOMatic(m2, predVals = list(x1 = c(1,2,3),
                                xcat2 = c("M","D"))))

(m2.p3 &lt;- predictOMatic(m2, predVals = list(x2 = c(0.25, 1.0),
                                xcat2 = c("M","D"))))

(m2.p4 &lt;- predictOMatic(m2, predVals = list(x2 = plotSeq(m2.data$x2, 10),
                                xcat2 = c("M","D"))))

(m2.p5 &lt;- predictOMatic(m2, predVals = list(x2 = c(0.25, 1.0),
                                xcat2 = c("M","D")), interval = "conf"))

(m2.p6 &lt;- predictOMatic(m2, predVals = list(x2 = c(49, 51),
                                xcat2 = levels(m2.data$xcat2),
                                x1 = plotSeq(dat$x1))))

plot(y ~ x1, data = m2.data)
by(m2.p6, list(m2.p6$xcat2), function(x) {
    lines(x$x1, x$fit, col = x$xcat2, lty = as.numeric(x$xcat2))
})

m2.newdata &lt;- newdata(m2, predVals = list(x2 = c(48, 50, 52),
                              xcat2 = c("M","D")))
predict(m2, newdata = m2.newdata)

(m2.p7 &lt;- predictOMatic(m2, predVals = list(x2 = c(48, 50, 52),
                                xcat2 = c("M","D"))))

(m2.p8 &lt;- predictOMatic(m2,
             predVals = list(x2 = range(m2.data$x2, na.rm = TRUE),
             xcat2 = c("M","D"))))

(m2.p9 &lt;- predictOMatic(m2, predVals = list(x2 = plotSeq(m2.data$x2),
             x1 = quantile(m2.data$x1, pr =c(0.33, 0.66), na.rm = TRUE),
             xcat2 = c("M","D"))))
plot(y ~ x2 , data = m2.data)

by(m2.p9, list(m2.p9$x1, m2.p9$xcat2), function(x) {lines(x$x2, x$fit)})



(predictOMatic(m2, predVals = list(x2 = c(50, 60), xcat2 = c("M","D")),
               interval = "conf"))

## create a dichotomous dependent variable
y2 &lt;- ifelse(rnorm(N) &gt; 0.3, 1, 0)
dat &lt;- cbind(dat, y2)

m3 &lt;- glm(y2 ~ x1 + x2 + x3 + xcat1, data = dat, family = binomial(logit))
summary(m3)
m3.data &lt;- model.data(m3)
summarize(m3.data)

(m3.p1 &lt;- predictOMatic(m3, divider = "std.dev."))

(m3.p2 &lt;- predictOMatic(m3, predVals = list(x2 = c(40, 50, 60),
                             xcat1 = c("M","F")),
                        divider = "std.dev.", interval = "conf"))

## Want a full accounting for each value of x2?
(m3.p3 &lt;- predictOMatic(m3,
                predVals = list(x2 = unique(m3.data$x2),
                    xcat1 = c("M","F")), interval = "conf"))


## Would like to write a more beautiful print method
## for output object, but don't want to obscure structure from user.
## for (i in names(m3.p1)){
##     dns &lt;- cbind(m3.p1[[i]][i], m3.p1[[i]]$fit)
##     colnames(dns) &lt;- c(i, "predicted")
##     print(dns)
## }


</code></pre>

<hr>
<h2 id='outreg'>Creates a publication quality result table for
regression models. Works with models fitted with lm, glm, as well
as lme4.</h2><span id='topic+outreg'></span>

<h3>Description</h3>

<p>This provides &quot;markup&quot; that the user is will copy into a LaTeX
document. As of rockchalk 1.8.4, can also create HTML markup.
The rockchalk vignette demonstrates use of outreg in Sweave.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outreg(
  modelList,
  type = "latex",
  modelLabels = NULL,
  varLabels = NULL,
  tight = TRUE,
  centering = c("none", "siunitx", "dcolumn"),
  showAIC = FALSE,
  float = FALSE,
  request,
  runFuns,
  digits = 3,
  alpha = c(0.05, 0.01, 0.001),
  SElist = NULL,
  PVlist = NULL,
  Blist = NULL,
  title,
  label,
  gofNames,
  print.results = TRUE,
  browse = identical(type, "html") &amp;&amp; interactive()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="outreg_+3A_modellist">modelList</code></td>
<td>
<p>A regression model or an R list of regression
models. Default model names will be M1, M2, and so forth. User
specified names are allowed, such as <code>list("My Model" =
m1, "Her Model" = m2)</code>.  This is the currently recommended way
to supply model lables. This is less error prone than the use
of the modelLabels argument.</p>
</td></tr>
<tr><td><code id="outreg_+3A_type">type</code></td>
<td>
<p>Default = &quot;latex&quot;. The alternatives are &quot;html&quot; and
&quot;csv&quot;</p>
</td></tr>
<tr><td><code id="outreg_+3A_modellabels">modelLabels</code></td>
<td>
<p>This is allowed, but discouraged. A vector of
character string variables, one for each element in
modelList. Will override the names in modelList.</p>
</td></tr>
<tr><td><code id="outreg_+3A_varlabels">varLabels</code></td>
<td>
<p>To beautify the parameter names printed.  Must be
a named vector in the format c(parmname = &quot;displayName&quot;,
parmname = &quot;displayName&quot;). Include as many parameters as
desired, it is not necessary to supply new labels for all of
the parameters.</p>
</td></tr>
<tr><td><code id="outreg_+3A_tight">tight</code></td>
<td>
<p>Table format. If TRUE, parameter estimates and
standard errors are printed in a single column.  If FALSE,
parameter estimates and standard errors are printed side by
side.</p>
</td></tr>
<tr><td><code id="outreg_+3A_centering">centering</code></td>
<td>
<p>Default is &quot;none&quot;, but may be &quot;siunitx&quot; or
&quot;dcolumn&quot;. No centering has been the only way until this
version. User feedback requested.  Don't forget to insert
usepackage statment in document preamble for siunitx or
dcolumn. If user specifies <code>centering=TRUE</code>, the
<code>siunitx</code> method will be used. The <code>dcolumn</code>
approach assumes that the values reported in the column use
fewer than 3 integer places and 3 decimal places. Additional
room is allocated for the significance stars.</p>
</td></tr>
<tr><td><code id="outreg_+3A_showaic">showAIC</code></td>
<td>
<p>This is a legacy argument, before the
<code>request</code> argument was created.  If TRUE, the AIC
estimate is included with the diagnostic values. It has the
same effect as described by <code>request</code>.</p>
</td></tr>
<tr><td><code id="outreg_+3A_float">float</code></td>
<td>
<p>Default = FALSE. Include boilerplate for a LaTeX
table float, with the tabular markup inside it. Not relevant
if type = &quot;html&quot;.</p>
</td></tr>
<tr><td><code id="outreg_+3A_request">request</code></td>
<td>
<p>Extra information to be retrieved from the
summary(model) and displayed. This must be a vector of named
arguments, such as c(adj.r.squared = &quot;adj $R^2$&quot;, fstatistic =
&quot;F&quot;). The name must be a valid name of the output object, the
value should be the label the user wants printed in the
table. See details.</p>
</td></tr>
<tr><td><code id="outreg_+3A_runfuns">runFuns</code></td>
<td>
<p>A list of functions</p>
</td></tr>
<tr><td><code id="outreg_+3A_digits">digits</code></td>
<td>
<p>Default = 3. How many digits after decimal sign are
to be displayed.</p>
</td></tr>
<tr><td><code id="outreg_+3A_alpha">alpha</code></td>
<td>
<p>Default = c(0.05, 0.01, 0.001). I think stars are
dumb, but enough people have asked me for more stars that I'm
caving in.</p>
</td></tr>
<tr><td><code id="outreg_+3A_selist">SElist</code></td>
<td>
<p>Optional. Replacement standard errors. Must be a
list of named vectors. <code>outreg</code> uses the R <code>summary</code>
to retrieve standard errors, but one might instead want to use
robust or bootstrapped standard errors.  This argument may
supply a new SE vector for each fitted regression model, but
it is also allowed to supply the SE replacement for just one
of the models. The format should be <code>list("A Model Label"
= c(0.1, 0.3, 0.4), "Another Model Label" = c(0.4, 0.2, 0.3)</code>.
On the left, one must use the same names that are used in the
modelList argument.</p>
</td></tr>
<tr><td><code id="outreg_+3A_pvlist">PVlist</code></td>
<td>
<p>Optional. A list of replacement &quot;p values&quot;. It must
be a list of named vectors, similar in format to SElist. The
which the elements are the &quot;p values&quot; that the user wants to
use for each model.</p>
</td></tr>
<tr><td><code id="outreg_+3A_blist">Blist</code></td>
<td>
<p>Optional. This is only needed in the rare case where
a model's parameters cannot be discerned from its
summary. List must have names for models, and vectors slope
coefficient. See discussion of SElist and PVlist.</p>
</td></tr>
<tr><td><code id="outreg_+3A_title">title</code></td>
<td>
<p>A LaTeX caption for the table. Not relevant if type =
&quot;html&quot;.</p>
</td></tr>
<tr><td><code id="outreg_+3A_label">label</code></td>
<td>
<p>A string to be used as a LaTeX label in the table to
be created. Not relevant if type = &quot;html&quot;.</p>
</td></tr>
<tr><td><code id="outreg_+3A_gofnames">gofNames</code></td>
<td>
<p>Optional pretty names. R regression summaries use
names like &quot;sigma&quot; or &quot;r.squared&quot; that we might want to revise
for presentation. I prefer to refer to &quot;sigma&quot; as &quot;RMSE&quot;, but
perhaps you instead prefer something like <code>gofnames =
c("sigma" = "That Estimate I don't understand", "deviance" =
"Another Mystery")</code>. The words that you might replace are
&quot;sigma&quot;, &quot;r.squared&quot;, &quot;deviance&quot;, &quot;adj.r.squared&quot;,
&quot;fstatistic&quot;.</p>
</td></tr>
<tr><td><code id="outreg_+3A_print.results">print.results</code></td>
<td>
<p>Default TRUE, marked-up table will be
displayed in session.  If FALSE, same result is returned as an
object.</p>
</td></tr>
<tr><td><code id="outreg_+3A_browse">browse</code></td>
<td>
<p>Display the regression model in a browse? Defaults
to TRUE if type = &quot;html&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>outreg</code> returns a string vector. It is suggested that users
should save the outreg result and then use cat to save it. That is
myMod &lt;- outreg(m1, ...)  cat(myMod, file = &quot;myMod.html&quot;) or
cat(myMod, file = &quot;myMod.tex&quot;.  In version 1.8.66, we write the
html file to a temporary location and display it in a web
browser. Many word processors will not accept a cut-and paste
transfer from the browser, they will, however, be able to open the
html file itself and automatically re-format it in the native
table format.
</p>
<p>In version 1.8.111, an argument <code>print.results</code> was introduced.
This is TRUE by default, so the marked-up table is printed into
the session, and it is returned as well.  If the function should
run silently (as suggested in the last few versions), include
<code>print.results = TRUE</code>. 
</p>
<p>The table includes a minimally sufficient (in my opinion) model
summary.  It offers parameter estimates, standard errors, and
minimally sufficient goodness of fit.  My tastes tend toward
minimal tables, but users request more features, and
<code>outreg</code>'s interface hass been generalized to allow
specialized requests. See <code>request</code> and <code>runFuns</code>
arguments.
</p>
<p>I don't want to write a separate table function for every
different kind of regression model that exists (how
exhausting). So I've tried to revise <code>outreg()</code> to work with
regression functions that follow the standard R framework. It is
known to work <code>lm</code> and <code>glm</code>, as well as <code>merMod</code>
class from <code>lme4</code>, but it will try to interact with other
kinds of regression models.  Those models should have methods
<code>summary()</code>, <code>coef()</code>, <code>vcov()</code> and <code>nobs()</code>.
Package writes should provide those, its not my job.
</p>
<p>Do you want &quot;robust standard errors&quot;? P values calculated
according to some alternative logic?  Go ahead, calculate them in
your code, outreg will now accept them as arguments. As of Version
1.8.4, users can provide their own standard errors and/or p-values
for each model. Thus, if a model answers in the usual way to the
standard R request <code>coef(summary(model))</code>, outreg can work if
users supply standard errors.
</p>
<p>About the customizations <code>request</code>.  The <code>request</code>
argument supplies a list of names of summary output elements that
are desired. The format is a pair, a value to be retrieved from
<code>summary(model)</code>, and a pretty name to be printed for
it. With the <code>lm()</code> regression, for example, one might want
the output of the F test and the adjusted R-square: Include
<code>request = c(adj.r.squared = "adj. $R^2$", "fstatistic" =
"F")</code>. The value on the left is the name of the desired
information in the summary object, while the value on the right is
<em>any</em> valid LaTeX (or HTML) markup that the user desires to
display in the table. <code>request</code> terms that generate a single
numerical value will generally work fine, while requests that ask
for more structured information, such as the F test (including the
2 degrees of freedom values) may work (user feedback needed).
</p>
<p>The <code>runFuns</code> argument is inspired by a user request: could
this include the BIC or other summaries that can be easily
calculated?  Any R function, such as <code>AIC</code> or <code>BIC</code>,
should work, as long as it returns a single value.  This is a
two-part specification, a function name and a pretty label to be
used in printing. For example, <code>runFuns = c("AIC" = "Akaike
Criterion", "BIC" = "Schwartz Criterion", "logLik" = "LL")</code>.
</p>
<p>About centering with dcolumn or siunitx. It appears now that
results are better with <code>siunitx</code> but <code>dcolumn</code> is more
familiar to users.  The user has the duty to make sure that the
document preamble includes the correct package,
<code>\usepackage{dcolumn}</code> or <code>\usepackage{siunitx}</code>.
In this version, I have eliminated the need for the user to
specify document-wide settings for <code>siunitx</code>. All of the
details are explicitly written in the header of each tabular.
It is done that way to more easily allow user customizations.
</p>


<h3>Value</h3>

<p>A character vector, one element per row of the regression
table.
</p>


<h3>Note</h3>

<p>There are many R packages that can be used to create LaTeX
regression tables. memisc, texreg, apsrtable, xtables, and rms
are some. This &quot;outreg&quot; version was in use in our labs before
we were aware that those packages were in development. It is
not intended as a competitor, it is just a slightly different
version of the same that is more suited to our needs.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson  <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2134234)
dat &lt;- data.frame(x1 = rnorm(100), x2 = rnorm(100))
dat$y1 &lt;- 30 + 5 * rnorm(100) + 3 * dat$x1 + 4 * dat$x2
dat$y2 &lt;- rnorm(100) + 5 * dat$x2
m1 &lt;- lm(y1 ~ x1, data = dat)
m2 &lt;- lm(y1 ~ x2, data = dat)
m3 &lt;- lm(y1 ~ x1 + x2, data = dat)
gm1 &lt;- glm(y1 ~ x1, family = Gamma, data = dat)
outreg(m1, title = "My One Tightly Printed Regression", float = TRUE)
ex1 &lt;- outreg(m1, title = "My One Tightly Printed Regression",
               float = TRUE, print.results = FALSE, centering = "siunitx")
## Show markup, Save to file with cat()
cat(ex1)
## cat(ex1, file = "ex1.tex")
 
ex2 &lt;- outreg(list("Fingers" = m1), tight = FALSE, 
    title = "My Only Spread Out Regressions", float = TRUE,
    alpha = c(0.05, 0.01, 0.001)) 

ex3 &lt;- outreg(list("Model A" = m1, "Model B label with Spaces" = m2),
    varLabels = list(x1 = "Billie"), 
    title = "My Two Linear Regressions", request = c(fstatistic = "F"),
    print.results = TRUE)
cat(ex3)

ex4 &lt;- outreg(list("Model A" = m1, "Model B" = m2),
    modelLabels = c("Overrides ModelA", "Overrides ModelB"),
    varLabels = list(x1 = "Billie"),
    title = "Note modelLabels Overrides model names")
cat(ex4)
##'
ex5 &lt;- outreg(list("Whichever" = m1, "Whatever" = m2),
    title = "Still have showAIC argument, as in previous versions",
    showAIC = TRUE, float = TRUE, centering = "siunitx")

ex5s &lt;- outreg(list("Whichever" = m1, "Whatever" = m2),
    title = "Still have showAIC argument, as in previous versions",
    showAIC = TRUE, float = TRUE, centering = "siunitx")


## Launches HTML browse
ex5html &lt;- outreg(list("Whichever" = m1, "Whatever" = m2),
    title = "Still have showAIC argument, as in previous versions",
    showAIC = TRUE, type = "html")
## Could instead, make a file:
## fn &lt;- "some_name_you_choose.html"
## cat(ex5html, file = fn)
## browseURL(fn)
## Open that HTML file in LibreOffice or MS Word


ex6 &lt;- outreg(list("Whatever" = m1, "Whatever" =m2),
    title = "Another way to get AIC output",
    runFuns = c("AIC" = "Akaike IC"))
cat(ex6)

ex7 &lt;- outreg(list("Amod" = m1, "Bmod" = m2, "Gmod" = m3),
       title = "My Three Linear Regressions", float = FALSE)
cat(ex7)

## A new feature in 1.85 is ability to provide vectors of beta estimates
## standard errors, and p values if desired. 
## Suppose you have robust standard errors!
if (require(car)){
   newSE &lt;- sqrt(diag(car::hccm(m3)))
   ex8 &lt;- outreg(list("Model A" = m1, "Model B" = m2, "Model C" = m3, "Model C w Robust SE" = m3),
        SElist= list("Model C w Robust SE" = newSE))
   cat(ex8)
}

ex11 &lt;- outreg(list("I Love Long Titles" = m1,
          "Prefer Brevity" = m2,
          "Short" = m3), tight = FALSE, float = FALSE)
cat(ex11)
##'
ex12 &lt;- outreg(list("GLM" = gm1), float = TRUE)
cat(ex12)

ex13 &lt;- outreg(list("OLS" = m1, "GLM" = gm1), float = TRUE,
        alpha = c(0.05, 0.01))
cat(ex13)
##'
ex14 &lt;- outreg(list(OLS = m1, GLM = gm1), float = TRUE,
    request = c(fstatistic = "F"), runFuns = c("BIC" = "BIC"))
cat(ex14)
ex15 &lt;- outreg(list(OLS = m1, GLM = gm1), float = TRUE,
    request = c(fstatistic = "F"), runFuns = c("BIC" = "BIC"),
    digits = 5, alpha = c(0.01))

ex16 &lt;- outreg(list("OLS 1" = m1, "OLS 2" = m2,  GLM = gm1), float = TRUE,
    request = c(fstatistic = "F"),
    runFuns = c("BIC" = "BIC", logLik = "ll"),
    digits = 5, alpha = c(0.05, 0.01, 0.001))

ex17 &lt;- outreg(list("Model A" = gm1, "Model B label with Spaces" = m2),
    request = c(fstatistic = "F"),
    runFuns = c("BIC" = "Schwarz IC", "AIC" = "Akaike IC",
    "nobs" = "N Again?"))

## Here's a fit example from lme4.
if (require(lme4) &amp;&amp; require(car)){
  fm1 &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
  ex18 &lt;- outreg(fm1)
  cat(ex18)
  ## Fit same with lm for comparison
  lm1 &lt;- lm(Reaction ~ Days, sleepstudy)
  ## Get robust standard errors
  lm1rse &lt;- sqrt(diag(car::hccm(lm1)))

  if(interactive()){
  ex19 &lt;- outreg(list("Random Effects" = fm1, 
       "OLS" = lm1, "OLS Robust SE" = lm1),
       SElist = list("OLS Robust SE" = lm1rse), type = "html")
  }
  ## From the glmer examples
  gm2 &lt;- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial)
  lm2 &lt;- lm(incidence/size ~ period,  data = cbpp)
  lm2rse &lt;- sqrt(diag(car::hccm(lm2)))
  ## Lets see what MASS::rlm objects do? Mostly OK
  rlm2 &lt;- MASS::rlm(incidence/size ~ period, data = cbpp)
  
  ex20 &lt;- outreg(list("GLMER" = gm2, "lm" = lm2, "lm w/robust se" = lm2,
            "rlm" = rlm2), SElist = list("lm w/robust se" = lm2rse),
            type = "html")
   
}
</code></pre>

<hr>
<h2 id='outreg2HTML'>Convert LaTeX output from outreg to HTML markup</h2><span id='topic+outreg2HTML'></span>

<h3>Description</h3>

<p>This function is deprecated. Instead, please use <code>outreg(type = "html")</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outreg2HTML(outreg, filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="outreg2HTML_+3A_outreg">outreg</code></td>
<td>
<p>output from outreg</p>
</td></tr>
<tr><td><code id="outreg2HTML_+3A_filename">filename</code></td>
<td>
<p>A file name into which the regression markup is to be saved. Should end in .html.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This will write the html on the screen, but if a filename argument is
supplied, it will write a file. One can
then open or insert the file into Libre Office or other popular
&quot;word processor&quot; programs.
</p>


<h3>Value</h3>

<p>A vector of strings
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- genCorrelatedData2(means = c(50,50,50,50,50,50),
    sds = c(10,10,10,10,10,10), rho = 0.2, beta = rnorm(7), stde = 50)
m1 &lt;- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x1*x2, data = dat)
summary(m1)

m1out &lt;- outreg(list("Great Regression" = m1), alpha = c(0.05, 0.01, 0.001),
         request = c("fstatistic" = "F"), runFuns = c(AIC = "AIC"),
         float = TRUE)
##html markup will appear on screen
outreg2HTML(m1out)
## outreg2HTML(m1out, filename = "funky.html")
## I'm not running that for you because you
## need to be in the intended working directory

m2 &lt;- lm(y ~ x1 + x2, data = dat)

m2out &lt;- outreg(list("Great Regression" = m1, "Small Regression" = m2),
               alpha = c(0.05, 0.01, 0.01),
                request = c("fstatistic" = "F"), runFuns = c(BIC = "BIC"))
outreg2HTML(m2out)
## Run this for yourself, it will create the output file funky2.html
## outreg2HTML(m2out, filename = "funky2.html")
## Please inspect the file "funky2.html

</code></pre>

<hr>
<h2 id='padW0'>Pad with 0's.</h2><span id='topic+padW0'></span>

<h3>Description</h3>

<p>Sometimes we receive this c(1, 22, 131) and we need character
variables of the same size, such as c(&quot;001&quot;, &quot;022&quot;, &quot;131&quot;).  This
happens if a user has mistakenly converted a zip code (US regional
identifier) like &quot;00231&quot; to a number. This function converts the
number back to a 0 padded string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>padW0(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="padW0_+3A_x">x</code></td>
<td>
<p>a numeric  variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This works differently if the number provided is an integer, or a
character string.  Integers are left padded with the character
&quot;0&quot;.  A character string will be left-padded with blanks.
</p>


<h3>Value</h3>

<p>A character string vector padded with 0's
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1 , 11, 22, 121, 14141, 31)
(xpad &lt;- padW0(x))
x &lt;- rpois(7, lambda = 11)
(xpad &lt;- padW0(x))
x &lt;- c("Alabama", "Iowa", "Washington")
</code></pre>

<hr>
<h2 id='pctable'>Creates a cross tabulation with counts and percentages</h2><span id='topic+pctable'></span><span id='topic+pctable.default'></span><span id='topic+pctable.formula'></span><span id='topic+pctable.character'></span>

<h3>Description</h3>

<p>This function is pronounced &quot;presentable&quot;!  The original purpose
was to create a particular kind of cross tabulation that I ask for
in class: counts with column percentages. Requests from users have
caused a bit more generality to be built into the function. Now,
optionally, it will provide row percents. This is a generic function.
Most users will find the formula method most convenient. Use the
colpct and rowpct arguments to indicate if column or row percentages
are desired.
</p>
<p>I suggest most users will use the formula method for this. Running
a command like this will, generally, do the right thing:
</p>
<p><code>tab &lt;- pctable(y ~ x, data = dat)</code>
</p>
<p>There is also a method that will work with characters representing
variable names.
</p>
<p><code>tab &lt;- pctable("y", "x", data = dat)</code>
</p>
<p>Running the function should write a table in the output console,
but it also creates an object (<code>tab</code>). That object
can be displayed in a number of ways.
</p>
<p>A summary method is provided, so one could look at different
representations of the same table.
</p>
<p><code>summary(tab, rowpct = TRUE, colpct = FALSE)</code>
</p>
<p>or
</p>
<p><code>summary(tab, rowpct = TRUE, colpct = TRUE)</code>
</p>
<p>Tables that include only row or column percentages will be
compatible with the html and latex exporters in the
excellent <code>tables</code> package.
</p>
<p>The formula method is the recommended method for users. Run
<code>pctable(myrow ~ mycol, data = dat)</code>. In an earlier version,
I gave different advice, so please adjust your usage.
</p>
<p>The character method exists only for variety.  It accepts
character strings rather than a formula to define the columns that
should be plotted.  The method used most often for most users should
be the formula method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pctable(rv, ...)

## Default S3 method:
pctable(
  rv,
  cv,
  rvlab = NULL,
  cvlab = NULL,
  colpct = TRUE,
  rowpct = FALSE,
  rounded = FALSE,
  ...
)

## S3 method for class 'formula'
pctable(
  formula,
  data = NULL,
  rvlab = NULL,
  cvlab = NULL,
  colpct = TRUE,
  rowpct = FALSE,
  rounded = FALSE,
  ...
)

## S3 method for class 'character'
pctable(
  rv,
  cv,
  data = NULL,
  rvlab = NULL,
  cvlab = NULL,
  colpct = TRUE,
  rowpct = FALSE,
  rounded = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pctable_+3A_rv">rv</code></td>
<td>
<p>A row variable name</p>
</td></tr>
<tr><td><code id="pctable_+3A_...">...</code></td>
<td>
<p>Other arguments. So far, the most likely additional
arguments are to be passed along to the table function, such as
&quot;exclude&quot;, &quot;useNA&quot;, or &quot;dnn&quot; (which will override the rvlab and
cvlab arguments provided by some methods). Some methods will
also pass along these arguments to model.frame, &quot;subset&quot; 
&quot;xlev&quot;, &quot;na.action&quot;, &quot;drop.unused.levels&quot;.</p>
</td></tr>
<tr><td><code id="pctable_+3A_cv">cv</code></td>
<td>
<p>Column variable</p>
</td></tr>
<tr><td><code id="pctable_+3A_rvlab">rvlab</code></td>
<td>
<p>Optional: row variable label</p>
</td></tr>
<tr><td><code id="pctable_+3A_cvlab">cvlab</code></td>
<td>
<p>Optional: col variable label</p>
</td></tr>
<tr><td><code id="pctable_+3A_colpct">colpct</code></td>
<td>
<p>Default TRUE: are column percentags desired in the
presentation of this result?</p>
</td></tr>
<tr><td><code id="pctable_+3A_rowpct">rowpct</code></td>
<td>
<p>Default FALSE: are row percentages desired in the
presentation of this result</p>
</td></tr>
<tr><td><code id="pctable_+3A_rounded">rounded</code></td>
<td>
<p>Default FALSE, rounds to 10's for privacy purposes.</p>
</td></tr>
<tr><td><code id="pctable_+3A_formula">formula</code></td>
<td>
<p>A two sided formula.</p>
</td></tr>
<tr><td><code id="pctable_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please bear in mind the following. The output object is a
list of tables of partial information, which are then assembled in
various ways by the print method (print.pctable). A lovely table
will appear on the screen, but the thing itself has more
information and a less beautiful structure.
</p>
<p>A print method is supplied.
For any <code>pctable</code> object, it is possible to run follow-ups like
</p>
<p>print(tab, rowpct = TRUE, colpct = FALSE)
</p>
<p>The method <code>print.pctable(tab)</code> assembles the object into (my
opinion of) a presentable form. The print method has argumnets
<code>rowpct</code> and <code>colpct</code> that determine which percentages
are included in the presentation.
</p>
<p>When using character arguments, the row variable rv rowvar must be
a quoted string if the user intends the method pctable.character
to be dispatched. The column variable cv may be a string or just a
variable name (which this method will coerce to a string).
</p>


<h3>Value</h3>

<p>A list with tables (count, column percent, row percent) as
well as a copy of the call.
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="tables.html#topic+tabular">tabular</a></code> and the CrossTable function
in <code>gmodels</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- data.frame(x = gl(4, 25),
                  y = sample(c("A", "B", "C", "D", "E"), 100, replace= TRUE))
pctable(y ~ x, dat)
pctable(y ~ x, dat, exclude = NULL)
pctable(y ~ x, dat, rvlab = "My Outcome Var", cvlab = "My Columns")
pctable(y ~ x, dat, rowpct = TRUE, colpct = FALSE)
pctable(y ~ x, dat, rowpct = TRUE, colpct = TRUE)
pctable(y ~ x, dat, rowpct = TRUE, colpct = TRUE, exclude = NULL)
tab &lt;- pctable(y ~ x, dat, rvlab = "Outcome", cvlab = "Predictor")
dat &lt;- data.frame(x1 = gl(4, 25, labels = c("Good", "Bad", "Ugly", "Indiff")),
                x2 = gl(5, 20, labels = c("Denver", "Cincy", "Baltimore", "NY", "LA")), 
                y = sample(c("A", "B", "C", "D", "E"), 100, replace= TRUE))
tab &lt;- pctable(y ~ x1, data = dat, rvlab = "my row label",
    subset = dat$x1 %in% c("Good", "Bad"),
    drop.unused.levels = TRUE)
tab &lt;- pctable(y ~ x1, data = dat, rvlab = "my row label",
    subset = dat$x1 %in% c("Good", "Bad"))
pctable("y", "x1", dat)
pctable("y", x1, dat)
tab &lt;- pctable(y ~ x2, data = dat, rvlab = "A Giant Variable")
summary(tab, rowpct = TRUE, colpct = FALSE)
tabsum &lt;- summary(tab)

## if user has tables package, can push out to latex or html
if (require(tables) &amp; require(Hmisc)){
    tabsumtab &lt;- tables::as.tabular(tabsum)
    Hmisc::html(tabsumtab)
    fn &lt;- tempfile(pattern = "file", tmpdir = tempdir(), 
            fileext = ".html")
    Hmisc::html(tabsumtab, file = fn)
    print(paste("The file saved was named", fn, "go get it."))
    if (interactive()) browseURL(fn)
    unlink(fn)
    ## go get the fn file if you want to import it in document
    ## Now LaTeX output
    ## have to escape the percent signs
    tabsumtab &lt;- apply(tabsumtab, 1:2, function(x) {gsub("%", "\\\\%", x) })
    fn2 &lt;- tempfile(pattern = "file", tmpdir = tempdir(), 
                   fileext = ".tex")
    Hmisc::latex(tabsumtab, file = fn2)
    print(paste("The file saved was named", fn2, "go get it."))
}

</code></pre>

<hr>
<h2 id='perspEmpty'>perspEmpty</h2><span id='topic+perspEmpty'></span>

<h3>Description</h3>

<p>Creates a persp plot without drawing anything in the interior.
Does equivalent <code>of plot( type="n")</code> for persp.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perspEmpty(
  x1,
  x2,
  y,
  x1lab = "x1",
  x2lab = "x2",
  ylab = "y",
  x1lim,
  x2lim,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="perspEmpty_+3A_x1">x1</code></td>
<td>
<p>data for the first horizontal axis, an R vector</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_x2">x2</code></td>
<td>
<p>data for the second horizontal axis, an R vector</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_y">y</code></td>
<td>
<p>data for the vertical axis, an R vector</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_x1lab">x1lab</code></td>
<td>
<p>label for the x1 axis, (the one called &quot;xlab&quot; inside persp)</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_x2lab">x2lab</code></td>
<td>
<p>label for the x2 axis, (the one called &quot;ylab&quot; inside persp)</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_ylab">ylab</code></td>
<td>
<p>label for the y (vertical) axis (the one called &quot;zlab&quot; inside persp)</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_x1lim">x1lim</code></td>
<td>
<p>Optional: limits for x1 axis (should be a vector with 2 elements)</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_x2lim">x2lim</code></td>
<td>
<p>Optional: limits for x2 axis (should be a vector with 2 elements)</p>
</td></tr>
<tr><td><code id="perspEmpty_+3A_...">...</code></td>
<td>
<p>further arguments that are passed to persp. Please note
Please remember that y is the vertical axis, but for persp, that
is the one I call x2.  Thus dot-dot-dot arguments including xlab,
ylab, zlab, xlim, ylim, and zlim are going to be ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regression demonstrations require a blank slate in which
points and planes can be drawn. This function creates that
blank persp canvas for those projects. It is not necessary
that x1, x2 and y be vectors of the same length, since this
function's only purpose is to plot an empty box with ranges
determined by the input variables. persp calls the 3 axes
x, y, and z, but here they are called x1, x2, and y.
</p>


<h3>Value</h3>

<p>The perspective matrix that is returned by persp
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- 1:10
x2 &lt;- 41:50
y &lt;-  rnorm(10)
perspEmpty(x1, x2, y)
res &lt;- perspEmpty(x1, x2, y, ticktype="detailed", nticks=10)
mypoints1 &lt;- trans3d ( x1, x2, y, pmat = res )
points( mypoints1, pch = 16, col= "blue")
</code></pre>

<hr>
<h2 id='plot.testSlopes'>Plot testSlopes objects</h2><span id='topic+plot.testSlopes'></span>

<h3>Description</h3>

<p>plot.testSlopes is a method for the
generic function plot. It has been revised so that it creates a plot
illustrating the marginal effect, using the
Johnson-Neyman interval calculations to highlight the
&quot;statistically significantly different from zero&quot; slopes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'testSlopes'
plot(x, ..., shade = TRUE, col = rgb(1, 0, 0, 0.1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.testSlopes_+3A_x">x</code></td>
<td>
<p>A testSlopes object.</p>
</td></tr>
<tr><td><code id="plot.testSlopes_+3A_...">...</code></td>
<td>
<p>Additional arguments that are ignored currently.</p>
</td></tr>
<tr><td><code id="plot.testSlopes_+3A_shade">shade</code></td>
<td>
<p>Optional. Create colored polygon for significant regions.</p>
</td></tr>
<tr><td><code id="plot.testSlopes_+3A_col">col</code></td>
<td>
<p>Optional. Color of the shaded area. Default transparent pink.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>
</p>


<h3>Author(s)</h3>

<p><a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='plotCurves'>Assists creation of predicted value curves for regression models.</h2><span id='topic+plotCurves'></span>

<h3>Description</h3>

<p>Creates a predicted value plot that includes a separate predicted
value line for each value of a focal variable. The x axis variable
is specified by the <code>plotx</code> argument. As of rockchalk 1.7.x,
the moderator argument, modx, is optional. Think of this a new
version of R's <code>termplot</code>, but it allows for
interactions. And it handles some nonlinear transformations more
gracefully than termplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCurves(
  model,
  plotx,
  nx = 40,
  modx,
  plotxRange = NULL,
  n,
  modxVals = NULL,
  interval = c("none", "confidence", "prediction"),
  plotPoints = TRUE,
  plotLegend = TRUE,
  legendTitle = NULL,
  legendPct = TRUE,
  col = c("black", "blue", "darkgreen", "red", "orange", "purple", "green3"),
  llwd = 2,
  opacity = 100,
  envir = environment(formula(model)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCurves_+3A_model">model</code></td>
<td>
<p>Required. Fitted regression object. Must have a
predict method</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_plotx">plotx</code></td>
<td>
<p>Required. String with name of predictor for the x axis</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_nx">nx</code></td>
<td>
<p>Number of values of plotx at which to calculate the predicted
value.  Default = 40.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_modx">modx</code></td>
<td>
<p>Optional. String for moderator variable name. May be
either numeric or factor.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_plotxrange">plotxRange</code></td>
<td>
<p>Optional. If not specified, the observed
range of plotx will be used to determine the axis range.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_n">n</code></td>
<td>
<p>Optional.  Number of focal values of <code>modx</code>, used by
algorithms specified by modxVals; will be ignored if modxVals
supplies a vector of focal values.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_modxvals">modxVals</code></td>
<td>
<p>Optional. A vector of focal values for which
predicted values are to be plotted. May also be a character string
to select an algorithm (&quot;quantile&quot;,&quot;std.dev.&quot; or &quot;table&quot;), or a
user-supplied function to select focal values (a new method
similar to <code>getFocal</code>). If modx is a factor, currently, the
only available algorithm is &quot;table&quot; (see <code>getFocal.factor</code>.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_interval">interval</code></td>
<td>
<p>Optional. Intervals provided by the
<code>predict.lm</code> may be supplied, either &quot;conf&quot; (95
interval for the estimated conditional mean) or &quot;pred&quot; (95
interval for observed values of y given the rest of the model).</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_plotpoints">plotPoints</code></td>
<td>
<p>Optional. TRUE or FALSE: Should the plot include
the scatterplot points along with the lines.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_plotlegend">plotLegend</code></td>
<td>
<p>Optional. TRUE or FALSE: Should the default
legend be included?</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_legendtitle">legendTitle</code></td>
<td>
<p>Optional. You'll get an automatically generated
title, such as &quot;Moderator: modx&quot;, but if you don't like that,
specify your own string here.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_legendpct">legendPct</code></td>
<td>
<p>Default = TRUE. Variable labels print with sample percentages.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_col">col</code></td>
<td>
<p>I offer my preferred color vector as default.
Replace if you like. User may supply a vector of valid
color names, or  <code>rainbow(10)</code> or
<code>gray.colors(5)</code>. Color names will be recycled if there
are more focal values of <code>modx</code> than colors provided.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_llwd">llwd</code></td>
<td>
<p>Optional. Line widths for predicted values. Can be
single value or a vector, which will be recycled as necessary.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_opacity">opacity</code></td>
<td>
<p>Optional, default = 100. A number between 1 and
255. 1 means &quot;transparent&quot; or invisible, 255 means very dark.  the
darkness of confidence interval regions</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_envir">envir</code></td>
<td>
<p>environment to search for variables.</p>
</td></tr>
<tr><td><code id="plotCurves_+3A_...">...</code></td>
<td>
<p>further arguments that are passed to plot or
predict. The arguments that are monitored to be sent to predict
are c(&quot;type&quot;, &quot;se.fit&quot;, &quot;dispersion&quot;, &quot;interval&quot;, &quot;level&quot;,
&quot;terms&quot;, &quot;na.action&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is similar to <code>plotSlopes</code>, but it accepts regressions
in which there are transformed variables, such as &quot;log(x1)&quot;.
It creates a plot of the predicted dependent
variable against one of the numeric predictors, <code>plotx</code>. It
draws a predicted value line for each value of <code>modx</code>, a
moderator variable. The moderator may be a numeric or categorical
moderator variable.
</p>
<p>The user may designate which particular values of the moderator
are used for calculating the predicted value lines.  That is,
<code>modxVals = c( 12,22,37)</code> would draw lines for values 12, 22,
and 37 of the moderator. User may instead supply a character
string to choose one of the built in algorithms. The default
algorithm is &quot;quantile&quot;, which will select <code>n</code> values that
are evenly spaced along the <code>modx</code> axis. The algorithm
&quot;std.dev&quot; will select the mean of <code>modx</code> (m) and then it will
select values that step away from the mean in standard deviation
sd units. For example, if <code>n = 3</code>, the focal
values will <code>m, m - sd, am + sd</code>.
</p>


<h3>Value</h3>

<p>A plot is created as a side effect, a list is returned
including 1) the call, 2) a newdata object that includes
information on the curves that were plotted, 3) a vector modxVals,
the values for which curves were drawn.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(rockchalk)

## Replicate some R classics.  The budworm.lg data from predict.glm
## will work properly after re-formatting the information as a data.frame:

## example from Venables and Ripley (2002, pp. 190-2.)
df &lt;- data.frame(ldose = rep(0:5, 2),
                 sex = factor(rep(c("M", "F"), c(6, 6))),
                 SF.numdead = c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16))
df$SF.numalive = 20 - df$SF.numdead

budworm.lg &lt;- glm(cbind(SF.numdead, SF.numalive) ~ sex*ldose, data = df,
                  family = binomial)


plotCurves(budworm.lg, plotx = "ldose", modx = "sex", interval = "confidence",
           ylim = c(0, 1))

## See infert
model2 &lt;- glm(case ~ age + parity + education + spontaneous + induced,
              data = infert, family = binomial())

## Curvature so slight we can barely see it
model2pc1 &lt;- plotCurves(model2, plotx = "age", modx = "education",
                        interval = "confidence", ylim = c(0, 1))


model2pc2 &lt;- plotCurves(model2, plotx = "age", modx = "education",
                        modxVals = levels(infert$education)[1],
                        interval = "confidence", ylim = c(0, 1))


model2pc2 &lt;- plotCurves(model2, plotx = "age", modx = "education",
                        modxVals = levels(infert$education)[c(2,3)],
                        interval = "confidence", ylim = c(0, 1))

model2pc2 &lt;- plotCurves(model2, plotx = "age", modx = "education",
                        modxVals = levels(infert$education)[c(2,3)],
                        ylim = c(0, 1), type = "response")





## Manufacture some data
set.seed(12345)
N &lt;- 500
dat &lt;- genCorrelatedData2(N = 500, means = c(5, 0, 0, 0), sds = rep(1, 4),
                          rho = 0.2, beta = rep(1, 5), stde = 20)

dat$xcat1 &lt;- gl(2, N/2, labels = c("Monster", "Human"))
dat$xcat2 &lt;- cut(rnorm(N), breaks = c(-Inf, 0, 0.4, 0.9, 1, Inf),
             labels = c("R", "M", "D", "P", "G"))

###The design matrix for categorical variables, xcat numeric
dat$xcat1n &lt;- with(dat, contrasts(xcat1)[xcat1, ])
dat$xcat2n &lt;- with(dat, contrasts(xcat2)[xcat2, ])


stde &lt;- 2
dat$y &lt;- with(dat, 0.03 + 11.5 * log(x1) * contrasts(dat$xcat1)[dat$xcat1] +
              0.1 * x2 + 0.04 * x2^2 + stde*rnorm(N))

stde &lt;- 1
dat$y2 &lt;- with(dat, 0.03 + 0.1 * x1 + 0.1 * x2 + 0.25 * x1 * x2 + 0.4 * x3 -
               0.1 * x4 + stde * rnorm(N))
stde &lt;- 8
dat$y3 &lt;- with(dat, 3 + 0.5 * x1 + 1.2 * (as.numeric(xcat1)-1) +
-0.8 * (as.numeric(xcat1)-1) * x1 +  stde * rnorm(N))

stde &lt;- 8
dat$y4 &lt;- with(dat, 3 + 0.5 * x1 +
               contrasts(dat$xcat2)[dat$xcat2, ] %*% c(0.1, -0.2, 0.3, 0.05)  +
               stde * rnorm(N))


## Curvature with interaction
m1 &lt;- lm(y ~ log(x1)*xcat1 + x2 + I(x2^2), data=dat)
summary(m1)

## First, with no moderator
plotCurves(m1, plotx = "x1")

plotCurves(m1, plotx = "x1", modx = "xcat1")

## ## Verify that plot by comparing against a manually contructed alternative
## par(mfrow=c(1,2))
## plotCurves(m1, plotx = "x1", modx = "xcat1")
## newdat &lt;- with(dat, expand.grid(x1 = plotSeq(x1, 30), xcat1 = levels(xcat1)))
## newdat$x2 &lt;-  with(dat, mean(x2, na.rm = TRUE))
## newdat$m1p &lt;- predict(m1, newdata = newdat)
## plot( y ~ x1, data = dat, type = "n", ylim = magRange(dat$y, c(1, 1.2)))
## points( y ~ x1, data = dat, col = dat$xcat1, cex = 0.4, lwd = 0.5)
## by(newdat, newdat$xcat1, function(dd) {lines(dd$x1, dd$m1p)})
## legend("topleft", legend=levels(dat$xcat1), col = as.numeric(dat$xcat1), lty = 1)
## par(mfrow = c(1,1))
## ##Close enough!


plotCurves(m1, plotx = "x2", modx = "x1")

plotCurves(m1, plotx = "x2", modx = "xcat1")

plotCurves(m1, plotx = "x2", modx = "xcat1", interval = "conf")


m2 &lt;- lm(y ~ log(x1)*xcat1 + xcat1*(x2 + I(x2^2)), data = dat)
summary(m2)
plotCurves(m2, plotx = "x2", modx = "xcat1")

plotCurves(m2, plotx  ="x2", modx = "x1")


m3a &lt;- lm(y ~ poly(x2, 2) + xcat1, data = dat)

plotCurves(m3a, plotx = "x2")
plotCurves(m3a, plotx = "x2", modx = "xcat1")
#OK

m4 &lt;- lm(log(y+10) ~ poly(x2, 2)*xcat1 + x1, data = dat)
summary(m4)
plotCurves(m4, plotx = "x2")

plotCurves(m4, plotx  ="x2", modx = "xcat1")

plotCurves(m4, plotx = "x2", modx = "x1")

plotCurves(m4, plotx = "x2", modx = "xcat1")

plotCurves(m4, plotx = "x2", modx = "xcat1", modxVals = c("Monster"))


##ordinary interaction
m5 &lt;- lm(y2 ~ x1*x2 + x3 +x4, data = dat)
summary(m5)
plotCurves(m5, plotx = "x1", modx = "x2")
plotCurves(m5, plotx = "x1", modx = "x2", modxVals = c( -2, -1, 0, 1, 2))
plotCurves(m5, plotx = "x1", modx = "x2", modxVals = c(-2))
plotCurves(m5, plotx = "x1", modx = "x2", modxVals = "std.dev.")
plotCurves(m5, plotx = "x1", modx = "x2", modxVals = "quantile")
plotCurves(m5, plotx = "x3", modx = "x2")


if(require(carData)){
    mc1 &lt;- lm(statusquo ~ income * sex, data = Chile)
    summary(mc1)
    plotCurves(mc1, plotx = "income")
    plotCurves(mc1, modx = "sex", plotx = "income")
    plotCurves(mc1, modx = "sex", plotx = "income", modxVals = "M")
    
    mc2 &lt;- lm(statusquo ~ region * income, data =  Chile)
    summary(mc2)
    plotCurves(mc2, modx = "region", plotx = "income")
    plotCurves(mc2, modx = "region", plotx = "income",
               modxVals = levels(Chile$region)[c(1,4)])
    plotCurves(mc2, modx = "region", plotx = "income", modxVals = c("S","M","SA"))
    plotCurves(mc2, modx = "region", plotx = "income", modxVals = c("S","M","SA"),
               interval = "conf")
    
    plotCurves(mc2, modx = "region", plotx = "income", plotPoints = FALSE)
 
    mc3 &lt;- lm(statusquo ~ region * income + sex + age, data =  Chile)
    summary(mc3)
    plotCurves(mc3, modx = "region", plotx = "income")
 
    mc4 &lt;- lm(statusquo ~ income * (age + I(age^2)) + education + sex + age, data = Chile)
    summary(mc4)
    plotCurves(mc4, plotx = "age")
    plotCurves(mc4, plotx = "age", interval = "conf")
     
    plotCurves(mc4, plotx = "age", modx = "income")
    plotCurves(mc4, plotx = "age", modx = "income", plotPoints = FALSE)
    
    plotCurves(mc4,  plotx = "income", modx = "age")
    plotCurves(mc4,  plotx = "income", modx = "age", n = 8)
    
    plotCurves(mc4,  plotx = "income", modx = "age", modxVals = "std.dev.")
    plotCurves(mc4, modx = "income", plotx = "age", plotPoints = FALSE)
}
</code></pre>

<hr>
<h2 id='plotFancy'>Regression plots with predicted value lines, confidence intervals, color coded interactions</h2><span id='topic+plotFancy'></span>

<h3>Description</h3>

<p>This is the back-end for the functions plotSlopes and plotCurves. Don't use it directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFancy(
  newdf,
  olddf,
  plotx,
  modx,
  modxVals,
  interval,
  plotPoints,
  legendArgs,
  col = NULL,
  llwd = 2,
  opacity,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotFancy_+3A_newdf">newdf</code></td>
<td>
<p>The new data frame with predictors and fit, lwr, upr
variables</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_olddf">olddf</code></td>
<td>
<p>A data frame with variables(modxVar, plotxVar,
depVar)</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_plotx">plotx</code></td>
<td>
<p>Character string for name of variable on horizontal
axis</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_modx">modx</code></td>
<td>
<p>Character string for name of moderator variable.</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_modxvals">modxVals</code></td>
<td>
<p>Values of moderator for which lines are desired</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_interval">interval</code></td>
<td>
<p>TRUE or FALSE: want confidence intervals?</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_plotpoints">plotPoints</code></td>
<td>
<p>TRUE or FALSE: want to see observed values in
plot?</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_legendargs">legendArgs</code></td>
<td>
<p>Set as &quot;none&quot; for no legend. Otherwise, a list
of arguments for the legend function</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_col">col</code></td>
<td>
<p>requested color scheme for lines and points. One per
value of modxVals.</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_llwd">llwd</code></td>
<td>
<p>requested line width, will re-cycle.</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_opacity">opacity</code></td>
<td>
<p>Value in 0, 255 for darkness of interval shading</p>
</td></tr>
<tr><td><code id="plotFancy_+3A_...">...</code></td>
<td>
<p>Other arguments passed to plot function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>col, lty, and lwd information
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='plotFancyCategories'>Draw display for discrete predictor in plotSlopes</h2><span id='topic+plotFancyCategories'></span>

<h3>Description</h3>

<p>There's plotFancy for numeric predictor. This is for discrete
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFancyCategories(
  newdf,
  olddf,
  plotx,
  modx = NULL,
  modxVals,
  xlab,
  xlim,
  ylab,
  ylim,
  col = c("black", "blue", "darkgreen", "red", "orange", "purple", "green3"),
  opacity = 120,
  main,
  space = c(0, 1),
  width = 0.2,
  llwd = 1,
  offset = 0,
  ...,
  gridArgs = list(lwd = 0.3, lty = 5),
  legendArgs
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotFancyCategories_+3A_newdf">newdf</code></td>
<td>
<p>The new data object, possibly from predictOMatic</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_olddf">olddf</code></td>
<td>
<p>The model data matrix</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_plotx">plotx</code></td>
<td>
<p>Name of horizontal axis variable</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_modx">modx</code></td>
<td>
<p>Name of moderator</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_modxvals">modxVals</code></td>
<td>
<p>values for modx</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_xlab">xlab</code></td>
<td>
<p>X axis label</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_xlim">xlim</code></td>
<td>
<p>x axis limits. Don't bother setting this, the internal
numbering is too complicated.</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_ylab">ylab</code></td>
<td>
<p>y axis label</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_ylim">ylim</code></td>
<td>
<p>y axis limits</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_col">col</code></td>
<td>
<p>color pallet for values of moderator variable</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_opacity">opacity</code></td>
<td>
<p>Value in 0, 255 for darkness of interval shading</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_main">main</code></td>
<td>
<p>main title</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_space">space</code></td>
<td>
<p>same as space in barplot, vector c(0, 1) is
c(space_between, space_before_first)</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_width">width</code></td>
<td>
<p>width of shaded bar area, default is 0.2. Maximum is 1.</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_llwd">llwd</code></td>
<td>
<p>requested line width, will re-cycle.</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_offset">offset</code></td>
<td>
<p>Shifts display to right (not tested)</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_...">...</code></td>
<td>
<p>Arguments sent to par</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_gridargs">gridArgs</code></td>
<td>
<p>A list of values to control printing of reference grid.
Set as &quot;none&quot; if no grid is desired.</p>
</td></tr>
<tr><td><code id="plotFancyCategories_+3A_legendargs">legendArgs</code></td>
<td>
<p>Arguments to the legend function. Set as &quot;none&quot;
if no legend is needed. Otherwise, provide a list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='plotPlane'>Draw a 3-D regression plot for two predictors from any linear or nonlinear lm or glm object</h2><span id='topic+plotPlane'></span><span id='topic+plotPlane.default'></span>

<h3>Description</h3>

<p>This allows user to fit a regression model with many variables and
then plot 2 of its predictors and the output plane for those
predictors with other variables set at mean or mode (numeric or
factor).  This is a front-end (wrapper) for R's persp function.
Persp does all of the hard work, this function reorganizes the
information for the user in a more readily understood way.  It
intended as a convenience for students (or others) who do not
want to fight their way through the details needed to use persp to
plot a regression plane.  The fitted model can have any number of
input variables, this will display only two of them. And, at least
for the moment, I insist these predictors must be numeric
variables. They can be transformed in any of the usual ways, such
as poly, log, and so forth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPlane(
  model = NULL,
  plotx1 = NULL,
  plotx2 = NULL,
  drawArrows = FALSE,
  plotPoints = TRUE,
  npp = 20,
  x1lab,
  x2lab,
  ylab,
  x1lim,
  x2lim,
  x1floor = 5,
  x2floor = 5,
  pch = 1,
  pcol = "blue",
  plwd = 0.5,
  pcex = 1,
  llwd = 0.3,
  lcol = 1,
  llty = 1,
  acol = "red",
  alty = 4,
  alwd = 0.3,
  alength = 0.1,
  linesFrom,
  lflwd = 3,
  envir = environment(formula(model)),
  ...
)

## Default S3 method:
plotPlane(
  model = NULL,
  plotx1 = NULL,
  plotx2 = NULL,
  drawArrows = FALSE,
  plotPoints = TRUE,
  npp = 20,
  x1lab,
  x2lab,
  ylab,
  x1lim,
  x2lim,
  x1floor = 5,
  x2floor = 5,
  pch = 1,
  pcol = "blue",
  plwd = 0.5,
  pcex = 1,
  llwd = 0.3,
  lcol = 1,
  llty = 1,
  acol = "red",
  alty = 4,
  alwd = 0.3,
  alength = 0.1,
  linesFrom,
  lflwd = 3,
  envir = environment(formula(model)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotPlane_+3A_model">model</code></td>
<td>
<p>an lm or glm fitted model object</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_plotx1">plotx1</code></td>
<td>
<p>name of one variable to be used on the x1 axis</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_plotx2">plotx2</code></td>
<td>
<p>name of one variable to be used on the x2 axis</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_drawarrows">drawArrows</code></td>
<td>
<p>draw red arrows from prediction plane toward observed values TRUE or FALSE</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_plotpoints">plotPoints</code></td>
<td>
<p>Should the plot include scatter of observed scores?</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_npp">npp</code></td>
<td>
<p>number of points at which to calculate prediction</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_x1lab">x1lab</code></td>
<td>
<p>optional label</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_x2lab">x2lab</code></td>
<td>
<p>optional label</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_ylab">ylab</code></td>
<td>
<p>optional label</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_x1lim">x1lim</code></td>
<td>
<p>optional lower and upper bounds for x1, as vector like c(0,1)</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_x2lim">x2lim</code></td>
<td>
<p>optional lower and upper bounds for x2, as vector like c(0,1)</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_x1floor">x1floor</code></td>
<td>
<p>Default=5. Number of &quot;floor&quot; lines to be drawn for variable x1</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_x2floor">x2floor</code></td>
<td>
<p>Default=5. Number of &quot;floor&quot; lines to be drawn for variable x2</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_pch">pch</code></td>
<td>
<p>plot character, passed on to the &quot;points&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_pcol">pcol</code></td>
<td>
<p>color for points, col passed to &quot;points&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_plwd">plwd</code></td>
<td>
<p>line width, lwd passed to &quot;points&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_pcex">pcex</code></td>
<td>
<p>character expansion, cex passed to &quot;points&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_llwd">llwd</code></td>
<td>
<p>line width, lwd passed to the &quot;lines&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_lcol">lcol</code></td>
<td>
<p>line color, col passed to the &quot;lines&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_llty">llty</code></td>
<td>
<p>line type, lty passed to the &quot;lines&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_acol">acol</code></td>
<td>
<p>color for arrows, col passed to &quot;arrows&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_alty">alty</code></td>
<td>
<p>arrow line type, lty passed to the &quot;arrows&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_alwd">alwd</code></td>
<td>
<p>arrow line width, lwd passed to the &quot;arrows&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_alength">alength</code></td>
<td>
<p>arrow head length, length passed to &quot;arrows&quot; function</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_linesfrom">linesFrom</code></td>
<td>
<p>object with information about &quot;highlight&quot; lines to be added to the 3d plane (output from plotCurves or plotSlopes)</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_lflwd">lflwd</code></td>
<td>
<p>line widths for linesFrom highlight lines</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_envir">envir</code></td>
<td>
<p>environment from whence to grab data</p>
</td></tr>
<tr><td><code id="plotPlane_+3A_...">...</code></td>
<td>
<p>additional parameters that will go to persp</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Besides a fitted model object, plotPlane requires two additional
arguments, plotx1 and plotx2. These are the names of the plotting
variables. Please note, that if the term in the regression is
something like poly(fish,2) or log(fish), then the argument to
plotx1 should be the quoted name of the variable &quot;fish&quot;.
plotPlane will handle the work of re-organizing the information so
that R's predict functions can generate the desired information.
This might be thought of as a 3D version of &quot;termplot&quot;, with a
significant exception. The calculation of predicted values depends
on predictors besides plotx1 and plotx2 in a different ways. The
sample averages are used for numeric variables, but for factors
the modal value is used.
</p>
<p>This function creates an empty 3D drawing and then fills in the
pieces. It uses the R functions <code>lines</code>, <code>points</code>, and
<code>arrows</code>. To allow customization, several parameters are
introduced for the users to choose colors and such. These options
are prefixed by &quot;l&quot; for the lines that draw the plane, &quot;p&quot; for the
points, and &quot;a&quot; for the arrows. Of course, if plotPoints=FALSE or
drawArrows=FALSE, then these options are irrelevant.
</p>


<h3>Value</h3>

<p>The main point is the plot that is drawn, but for record
keeping the return object is a list including 1) res: the
transformation matrix that was created by persp 2) the call that
was issued, 3) x1seq, the &quot;plot sequence&quot; for the x1 dimension, 4)
x2seq, the &quot;plot sequence&quot; for the x2 dimension, 5) zplane, the
values of the plane corresponding to locations x1seq and x2seq.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+persp">persp</a></code>, <code><a href="scatterplot3d.html#topic+scatterplot3d">scatterplot3d</a></code>, <code><a href="HH.html#topic+regr2.plot">regr2.plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rockchalk)


set.seed(12345)
x1 &lt;- rnorm(100)
x2 &lt;- rnorm(100)
x3 &lt;- rnorm(100)
x4 &lt;- rnorm(100)
y &lt;- rnorm(100)
y2 &lt;- 0.03 + 0.1*x1 + 0.1*x2 + 0.25*x1*x2 + 0.4*x3 -0.1*x4 + 1*rnorm(100)
dat &lt;- data.frame(x1,x2,x3,x4,y, y2)
rm(x1, x2, x3, x4, y, y2)

## linear ordinary regression
m1 &lt;- lm(y ~ x1 + x2 +x3 + x4, data = dat)

plotPlane(m1, plotx1 = "x3", plotx2 = "x4")

plotPlane(m1, plotx1 = "x3", plotx2 = "x4", drawArrows = TRUE)

plotPlane(m1, plotx1 = "x1", plotx2 = "x4", drawArrows = TRUE)


plotPlane(m1, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE, npp = 10)
plotPlane(m1, plotx1 = "x3", plotx2 = "x2", drawArrows = TRUE, npp = 40)

plotPlane(m1, plotx1 = "x3", plotx2 = "x2", drawArrows = FALSE,
          npp = 5, ticktype = "detailed")


## regression with interaction
m2 &lt;- lm(y ~ x1  * x2 +x3 + x4, data = dat)

plotPlane(m2, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE)


plotPlane(m2, plotx1 = "x1", plotx2 = "x4", drawArrows = TRUE)
plotPlane(m2, plotx1 = "x1", plotx2 = "x3", drawArrows = TRUE)

plotPlane(m2, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE,
          phi = 10, theta = 30)



## regression with quadratic;
## Required some fancy footwork in plotPlane, so be happy
dat$y3 &lt;- 0 + 1 * dat$x1 + 2 * dat$x1^2 + 1 * dat$x2 +
    0.4*dat$x3 + 8 * rnorm(100)
m3 &lt;- lm(y3 ~ poly(x1,2) + x2 +x3 + x4, data = dat)
summary(m3)

plotPlane(m3, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE,
          x1lab = "my great predictor", x2lab = "a so-so predictor",
          ylab = "Most awesomest DV ever")

plotPlane(m3, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE,
          x1lab = "my great predictor", x2lab = "a so-so predictor",
          ylab = "Most awesomest DV ever", phi = -20)

plotPlane(m3, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE,
          phi = 10, theta = 30)

plotPlane(m3, plotx1 = "x1", plotx2 = "x4", drawArrows = TRUE,
          ticktype = "detailed")
plotPlane(m3, plotx1 = "x1", plotx2 = "x3", drawArrows = TRUE)

plotPlane(m3, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE,
          phi = 10, theta = 30)

m4 &lt;- lm(y ~ sin(x1) + x2*x3 +x3 + x4, data = dat)
summary(m4)


plotPlane(m4, plotx1 = "x1", plotx2 = "x2", drawArrows = TRUE)
plotPlane(m4, plotx1 = "x1", plotx2 = "x3", drawArrows = TRUE)



eta3 &lt;- 1.1 + .9*dat$x1 - .6*dat$x2 + .5*dat$x3
dat$y4 &lt;- rbinom(100, size = 1, prob = exp( eta3)/(1+exp(eta3)))
gm1 &lt;- glm(y4 ~ x1 + x2 + x3, data = dat, family = binomial(logit))
summary(gm1)
plotPlane(gm1, plotx1 = "x1", plotx2 = "x2")
plotPlane(gm1, plotx1 = "x1", plotx2 = "x2", phi = -10)

plotPlane(gm1, plotx1 = "x1", plotx2 = "x2", ticktype = "detailed")
plotPlane(gm1, plotx1 = "x1", plotx2 = "x2", ticktype = "detailed",
          npp = 30, theta = 30)
plotPlane(gm1, plotx1 = "x1", plotx2 = "x3", ticktype = "detailed",
          npp = 70, theta = 60)

plotPlane(gm1, plotx1 = "x1", plotx2 = "x2", ticktype = c("detailed"),
          npp = 50, theta = 40)

dat$x2 &lt;- 5 * dat$x2
dat$x4 &lt;- 10 * dat$x4
eta4 &lt;- 0.1 + .15*dat$x1 - 0.1*dat$x2 + .25*dat$x3 + 0.1*dat$x4
dat$y4 &lt;- rbinom(100, size = 1, prob = exp( eta4)/(1+exp(eta4)))
gm2 &lt;- glm(y4 ~ x1 + x2 + x3 + x4, data = dat, family = binomial(logit))
summary(gm2)
plotPlane(gm2, plotx1 = "x1", plotx2 = "x2")
plotPlane(gm2, plotx1 = "x2", plotx2 = "x1")
plotPlane(gm2, plotx1 = "x1", plotx2 = "x2", phi = -10)
plotPlane(gm2, plotx1 = "x1", plotx2 = "x2", phi = 5, theta = 70, npp = 40)

plotPlane(gm2, plotx1 = "x1", plotx2 = "x2", ticktype = "detailed")
plotPlane(gm2, plotx1 = "x1", plotx2 = "x2", ticktype = "detailed",
          npp = 30, theta = -30)
plotPlane(gm2, plotx1 = "x1", plotx2 = "x3", ticktype = "detailed",
          npp = 70, theta = 60)

plotPlane(gm2, plotx1 = "x4", plotx2 = "x3", ticktype = "detailed",
          npp = 50, theta = 10)

plotPlane(gm2, plotx1 = "x1", plotx2 = "x2", ticktype = c("detailed"))
</code></pre>

<hr>
<h2 id='plotSeq'>Create sequences for plotting</h2><span id='topic+plotSeq'></span>

<h3>Description</h3>

<p><code>plotSeq</code> is a convenience for the creation of sequence
across the range of a variable.
By default, the length of the plotting
sequence will be equal to the length of the original sequence.
In that case, the only effect is to create an evenly-spaced
set of values. If <code>length.out</code> is specified, the user
determines the number of elements in plotSeq.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSeq(x, length.out = length(x))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotSeq_+3A_x">x</code></td>
<td>
<p>an R vector variable</p>
</td></tr>
<tr><td><code id="plotSeq_+3A_length.out">length.out</code></td>
<td>
<p>the number of elements in the desired plotting sequence.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The primary intended usage is for the creation of
plotting sequences of numeric variables.  It takes
a variable's range and the fills in evenly spaced steps.
If x is a factor variable, the levels will be returned.
Uses of this functionality are planned in the future.
</p>


<h3>See Also</h3>

<p><code>pretty</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Create a quadratic regression

stde &lt;- 14
x &lt;- rnorm(100, m = 50, s = 10)
y &lt;- 0.2 - 02*x + 0.2*x^2 + stde*rnorm(100)
mod1 &lt;- lm (y ~ poly(x, 2))

plot(x, y, main="The Quadratic Regression")
seqx &lt;- plotSeq(x, length.out = 10)
seqy &lt;- predict(mod1, newdata = data.frame(x = seqx))
lines(seqx, seqy, col = "red")

# Notice the bad result when a plotting sequence is
# not used.
plot(x, y, main = "Bad Plot Result")
seqy &lt;- predict(mod1)
lines(x, seqy, col = "green")

</code></pre>

<hr>
<h2 id='plotSlopes'>Generic function for plotting regressions and interaction effects</h2><span id='topic+plotSlopes'></span><span id='topic+plotSlopes.lm'></span>

<h3>Description</h3>

<p>This is a function for plotting regression
objects. So far, there is an implementation for <code>lm()</code> objects.
I've been revising plotSlopes so that it should handle the work
performed by plotCurves.  As sure as that belief is verified,
the plotCurves work will be handled by plotSlopes. Different
plot types are created, depending on whether the x-axis predictor
<code>plotx</code> is numeric or categorical.
##'
</p>
<p>This is a &quot;simple slope&quot; plotter for regression objects created by
<code>lm()</code> or similar functions that have capable predict methods
with newdata arguments. The term &quot;simple slopes&quot; was coined by
psychologists (Aiken and West, 1991; Cohen, et al 2002) for
analysis of interaction effects for particular values of a
moderating variable. The moderating variable may be continuous or
categorical, lines will be plotted for focal values of that
variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSlopes(model, plotx, ...)

## S3 method for class 'lm'
plotSlopes(
  model,
  plotx,
  modx = NULL,
  n = 3,
  modxVals = NULL,
  plotxRange = NULL,
  interval = c("none", "confidence", "prediction"),
  plotPoints = TRUE,
  legendPct = TRUE,
  legendArgs,
  llwd = 2,
  opacity = 100,
  ...,
  col = c("black", "blue", "darkgreen", "red", "orange", "purple", "green3"),
  type = c("response", "link"),
  gridArgs,
  width = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotSlopes_+3A_model">model</code></td>
<td>
<p>Required. A fitted Regression</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_plotx">plotx</code></td>
<td>
<p>Required. Name of one predictor from the fitted
model to be plotted on horizontal axis. May be numeric or factor.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to methods. Often includes
arguments that are passed to plot. Any arguments that customize
plot output, such as lwd, cex, and so forth, may be
supplied. These arguments intended for the predict method will be
used: c(&quot;type&quot;, &quot;se.fit&quot;, &quot;interval&quot;, &quot;level&quot;, &quot;dispersion&quot;,
&quot;terms&quot;, &quot;na.action&quot;)</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_modx">modx</code></td>
<td>
<p>Optional. String for moderator variable name. May be
either numeric or factor. If omitted, a single predicted value
line will be drawn.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_n">n</code></td>
<td>
<p>Optional. Number of focal values of <code>modx</code>, used by
algorithms specified by modxVals; will be ignored if modxVals
supplies a vector of focal values.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_modxvals">modxVals</code></td>
<td>
<p>Optional. Focal values of <code>modx</code> for which
lines are desired. May be a vector of values or the name of an
algorithm, &quot;quantile&quot;, &quot;std.dev.&quot;, or &quot;table&quot;.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_plotxrange">plotxRange</code></td>
<td>
<p>Optional. If not specified, the observed range
of plotx will be used to determine the axis range.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_interval">interval</code></td>
<td>
<p>Optional. Intervals provided by the
<code>predict.lm</code> may be supplied, either &quot;confidence&quot;
(confidence interval for the estimated conditional mean) or
&quot;prediction&quot; (interval for observed values of y given the rest
of the model).  The level can be specified as an argument
(which goes into ...  and then to the predict method)</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_plotpoints">plotPoints</code></td>
<td>
<p>Optional. TRUE or FALSE: Should the plot include
the scatterplot points along with the lines.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_legendpct">legendPct</code></td>
<td>
<p>Default = TRUE. Variable labels print with sample
percentages.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_legendargs">legendArgs</code></td>
<td>
<p>Set as &quot;none&quot; if no legend is
desired. Otherwise, this can be a list of named arguments that
will override the settings I have for the legend.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_llwd">llwd</code></td>
<td>
<p>Optional, default = 2. Line widths for predicted
values. Can be single value or a vector, which will be
recycled as necessary.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_opacity">opacity</code></td>
<td>
<p>Optional, default = 100. A number between 1 and
255.  1 means &quot;transparent&quot; or invisible, 255 means very dark.
Determines the darkness of confidence interval regions</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_col">col</code></td>
<td>
<p>Optional.I offer my preferred color vector as default.
Replace if you like. User may supply a vector of valid
color names, or  <code>rainbow(10)</code> or
<code>gray.colors(5)</code>. Color names will be recycled if there
are more focal values of <code>modx</code> than colors provided.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_type">type</code></td>
<td>
<p>Argument passed to the predict function. If model is glm,
can be either &quot;response&quot; or &quot;link&quot;. For lm, no argument of this
type is needed, since both types have same value.</p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_gridargs">gridArgs</code></td>
<td>
<p>Only used if plotx (horizontal axis) is a factor
variable. Designates reference lines between values. Set as
&quot;none&quot; if no grid lines are needed.  Default will be
<code>gridArgs = list(lwd = 0.3, lty = 5)</code></p>
</td></tr>
<tr><td><code id="plotSlopes_+3A_width">width</code></td>
<td>
<p>Only used if plotx (horizontal axis) is a factor. Designates
thickness of shading for bars that depict confidence intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original <code>plotSlopes</code> did not work well with nonlinear
predictors (log(x) and poly(x)). The separate function
<code>plotCurves()</code> was created for nonlinear predictive equations
and generalized linear models, but the separation of the two
functions was confusing for users. I've been working to make
plotSlopes handle everything and <code>plotCurves</code> will disappear
at some point.  <code>plotSlopes</code> can create an object which
is then tested with <code>testSlopes()</code> and that can be graphed
by a plot method.
</p>
<p>The argument <code>plotx</code> is the name of the horizontal plotting
variable. An innovation was introduced in Version 1.8.33 so that
<code>plotx</code> can be either  numeric or categorical.
</p>
<p>The argument <code>modx</code> is the moderator variable. It may be
either a numeric or a factor variable. As of version 1.7, the modx
argument may be omitted. A single predicted value line will be
drawn. That version also introduced the arguments interval and n.
</p>
<p>There are many ways to specify focal values using the arguments
<code>modxVals</code> and <code>n</code>. This changed in rockchalk-1.7.0.  If
<code>modxVals</code> is omitted, a default algorithm for the variable
type will be used to select <code>n</code> values for
plotting. <code>modxVals</code> may be a vector of values (for a numeric
moderator) or levels (for a factor).  If modxVals is a vector of
values, then the argument <code>n</code> is ignored.  However, if
modxVals is one of the name of one of the algorithms, &quot;table&quot;,
&quot;quantile&quot;, or &quot;std.dev.&quot;, then the argument <code>n</code> sets number
of focal values to be selected.  For numeric <code>modx</code>, n
defaults to 3, but for factors <code>modx</code> will be the number of
observed values of <code>modx</code>. If modxVals is omitted, the
defaults will be used (&quot;table&quot; for factors, &quot;quantile&quot; for numeric
variables).
</p>
<p>For the predictors besides <code>modx</code> and <code>plotx</code> (the ones
that are not explicitly included in the plot), predicted values
are calculated with variables set to the mean and mode, for numeric
or factor variables (respectively). Those values can be reviewed
in the newdata object that is created as a part of the output from
this function
</p>


<h3>Value</h3>

<p>Creates a plot and an output object that summarizes it.
</p>
<p>The return object includes the &quot;newdata&quot; object that was
used to create the plot, along with the &quot;modxVals&quot; vector, the
values of the moderator for which lines were drawn, and the
color vector. It also includes the call that generated the
plot.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>References</h3>

<p>Aiken, L. S. and West, S.G. (1991). Multiple
Regression: Testing and Interpreting Interactions. Newbury
Park, Calif: Sage Publications.
</p>
<p>Cohen, J., Cohen, P., West, S. G., and Aiken, L. S. (2002).
Applied Multiple Regression/Correlation Analysis for the Behavioral
Sciences (Third.). Routledge Academic.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+testSlopes">testSlopes</a></code> <code><a href="#topic+plotCurves">plotCurves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Manufacture some predictors
set.seed(12345)

dat &lt;- genCorrelatedData2 (N = 100, means = rep(0,4), sds = 1, rho = 0.2,
                           beta = c(0.3, 0.5, -0.45, 0.5, -0.1, 0, 0.6),
                           stde = 2)

dat$xcat1 &lt;- gl(2, 50, labels = c("M", "F"))
dat$xcat2 &lt;- cut(rnorm(100), breaks = c(-Inf, 0, 0.4, 0.9, 1, Inf),
                 labels = c("R", "M", "D", "P", "G"))
## incorporate effect of categorical predictors
dat$y &lt;- dat$y + 1.9 * dat$x1 * contrasts(dat$xcat1)[dat$xcat1] +
           contrasts(dat$xcat2)[dat$xcat2 , ] %*% c(0.1, -0.16, 0, 0.2)

m1 &lt;- lm(y ~ x1 * x2 + x3 + x4 + xcat1* xcat2, data = dat)
summary(m1)

## New in rockchalk 1.7.x. No modx required:
plotSlopes(m1, plotx = "x1")
## Confidence interval, anybody?
plotSlopes(m1, plotx = "x1", interval = "conf")

## Prediction interval.
plotSlopes(m1, plotx = "x1", interval = "pred")

plotSlopes(m1, plotx = "x1", modx = "xcat2", modxVals = c("R", "M"))

plotSlopes(m1, plotx = "x1", modx = "xcat2",  interval = "pred")

plotSlopes(m1, plotx = "xcat1", modx = "xcat2",  interval = "conf", space = c(0,1))

plotSlopes(m1, plotx = "xcat1", modx = "xcat2", 
           modxVals = c("Print R" = "R" , "Show M" = "M"), gridArgs = "none")

## Now experiment with a moderator variable
## let default quantile algorithm do its job
plotSlopes(m1, plotx = "xcat2", interval = "none")
plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "none")
plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "confidence",
           legendArgs = list(title = "xcat2"), ylim = c(-3, 3), lwd = 0.4)
plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "confidence",
           legendArgs = list(title = "xcat2"), ylim = c(-3, 3), lwd = 0.4, width = 0.25)
m1.ps &lt;- plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "prediction")
m1.ps &lt;- plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "prediction", space=c(0,2))
plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "prediction", gridArgs = "none")

plotSlopes(m1, plotx = "xcat2", modx = "xcat1", interval = "confidence", ylim = c(-3, 3))
plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "confidence", 
           col = c("black", "blue", "green", "red", "orange"), lty = c(1, 4, 6, 3))

plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "confidence", 
           col = gray.colors(4, end = 0.5), lty = c(1, 4, 6, 3), legendArgs = list(horiz=TRUE))


plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "confidence", 
           col = c("pink", "orange"))

plotSlopes(m1, plotx = "xcat1", interval = "confidence", 
           col = c("black", "blue", "green", "red", "orange"))

plotSlopes(m1, plotx = "xcat1", modx = "xcat2", interval = "confidence", 
           col = c("black", "blue", "green", "red", "orange"),
           gridlwd = 0.2)

## previous uses default equivalent to
## plotSlopes(m1, plotx = "x1", modx = "x2", modxVals = "quantile")
## Want more focal values?
plotSlopes(m1, plotx = "x1", modx = "x2", n = 5)
## Pick focal values yourself?
plotSlopes(m1, plotx = "x1", modx = "x2", modxVals = c(-2, 0, 0.5))
## Alternative algorithm?
plotSlopes(m1, plotx = "x1", modx = "x2", modxVals = "std.dev.",
           main = "Uses \"std.dev.\" Divider for the Moderator",
           xlab = "My Predictor", ylab = "Write Anything You Want for ylab")

## Will catch output object from this one
m1ps &lt;- plotSlopes(m1, plotx = "x1", modx = "x2", modxVals = "std.dev.", n = 5,
                 main = "Setting n = 5 Selects More Focal Values for Plotting")

m1ts &lt;- testSlopes(m1ps)

plot(m1ts)

### Examples with categorical Moderator variable

m3 &lt;- lm (y ~ x1 + xcat1, data = dat)
summary(m3)
plotSlopes(m3, modx = "xcat1", plotx = "x1")
plotSlopes(m3, modx = "xcat1", plotx = "x1", interval = "predict")
plotSlopes(m3, modx = "x1", plotx = "xcat1", interval = "confidence",
           legendArgs = list(x = "bottomright", title = ""))

m4 &lt;- lm (y ~ x1 * xcat1, data = dat)
summary(m4)
plotSlopes(m4, modx = "xcat1", plotx = "x1")
plotSlopes(m4, modx = "xcat1", plotx = "x1", interval = "conf")


m5 &lt;- lm (y ~ x1 + x2 + x1 * xcat2, data = dat)
summary(m5)
plotSlopes(m5, modx = "xcat2", plotx = "x1")
m5ps &lt;- plotSlopes(m5, modx = "xcat2", plotx = "x1", interval = "conf")

testSlopes(m5ps)



## Now examples with real data. How about Chilean voters?
library(carData)
m6 &lt;- lm(statusquo ~ income * sex, data = Chile)
summary(m6)
plotSlopes(m6, modx = "sex", plotx = "income")
m6ps &lt;- plotSlopes(m6, modx = "sex", plotx = "income", col = c("orange", "blue"))

testSlopes(m6ps)

m7 &lt;- lm(statusquo ~ region * income, data= Chile)
summary(m7)
plotSlopes(m7, plotx = "income", modx = "region")

plotSlopes(m7, plotx = "income", modx = "region", plotPoints = FALSE)
plotSlopes(m7, plotx = "income", modx = "region", plotPoints = FALSE,
           interval = "conf")
plotSlopes(m7, plotx = "income", modx = "region", modxVals = c("SA","S", "C"),
           plotPoints = FALSE, interval = "conf")
## Same, choosing 3 most frequent values
plotSlopes(m7, plotx = "income", modx = "region", n = 3, plotPoints = FALSE,
           interval = "conf")


m8 &lt;- lm(statusquo ~ region * income + sex + age, data= Chile)
summary(m8)
plotSlopes(m8, modx = "region", plotx = "income")


m9 &lt;- lm(statusquo ~ income * age + education + sex + age, data = Chile)
summary(m9)
plotSlopes(m9, modx = "income", plotx = "age")

m9ps &lt;- plotSlopes(m9, modx = "income", plotx = "age")
m9psts &lt;- testSlopes(m9ps)
plot(m9psts) ## only works if moderator is numeric

## Demonstrate re-labeling
plotSlopes(m9, modx = "income", plotx = "age", n = 5,
           modxVals = c("Very poor" = 7500,  "Rich" = 125000), 
           main = "Chile Data", legendArgs = list(title = "Designated Incomes"))

plotSlopes(m9, modx = "income", plotx = "age", n = 5, modxVals = c("table"), 
           main = "Moderator: mean plus/minus 2 SD")

## Convert education to numeric, for fun
Chile$educationn &lt;- as.numeric(Chile$education)
m10 &lt;- lm(statusquo ~ income * educationn + sex + age, data = Chile)
summary(m10)
plotSlopes(m10, plotx = "educationn",  modx = "income")

## Now, the occupational prestige data. Please note careful attention
## to consistency of colors selected
data(Prestige)
m11 &lt;- lm(prestige ~ education * type, data = Prestige)

plotSlopes(m11, plotx = "education", modx = "type", interval = "conf")
dev.new()
plotSlopes(m11, plotx = "education", modx = "type",
           modxVals = c("prof"), interval = "conf")
dev.new()
plotSlopes(m11, plotx = "education", modx = "type",
           modxVals = c("bc"), interval = "conf")
dev.new()
plotSlopes(m11, plotx = "education", modx = "type",
           modxVals = c("bc", "wc"), interval = "conf")
</code></pre>

<hr>
<h2 id='predictCI'>Calculate a predicted value matrix (fit, lwr, upr) for a
regression, either lm or glm, on either link or response scale.</h2><span id='topic+predictCI'></span>

<h3>Description</h3>

<p>This adapts code from predict.glm and predict.lm. I eliminated
type = &quot;terms&quot; from consideration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictCI(
  object,
  newdata = NULL,
  type = c("response", "link"),
  interval = c("none", "confidence", "prediction"),
  dispersion = NULL,
  scale = NULL,
  na.action = na.pass,
  level = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictCI_+3A_object">object</code></td>
<td>
<p>Regression object, class must include glm or lm.</p>
</td></tr>
<tr><td><code id="predictCI_+3A_newdata">newdata</code></td>
<td>
<p>Data frame including focal values for predictors</p>
</td></tr>
<tr><td><code id="predictCI_+3A_type">type</code></td>
<td>
<p>One of c(&quot;response&quot;, &quot;link&quot;), defaults to former.</p>
</td></tr>
<tr><td><code id="predictCI_+3A_interval">interval</code></td>
<td>
<p>One of c(&quot;none&quot;, &quot;confidence&quot;,
&quot;prediction&quot;). &quot;prediction&quot; is defined only for lm objects, not
for glm.</p>
</td></tr>
<tr><td><code id="predictCI_+3A_dispersion">dispersion</code></td>
<td>
<p>Will be estimated if not provided. The variance
coefficient of the glm, same as scale squared. Dispersion is
allowed as an argument in predict.glm.</p>
</td></tr>
<tr><td><code id="predictCI_+3A_scale">scale</code></td>
<td>
<p>The square root of dispersion. In an lm, this is the
RMSE, called sigma in summary.lm.</p>
</td></tr>
<tr><td><code id="predictCI_+3A_na.action">na.action</code></td>
<td>
<p>What to do with missing values</p>
</td></tr>
<tr><td><code id="predictCI_+3A_level">level</code></td>
<td>
<p>Optional. Default = 0.95.  Specify whatever
confidence level one desires.</p>
</td></tr>
<tr><td><code id="predictCI_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to predict</p>
</td></tr>
</table>


<h3>Details</h3>

<p>R's predict.glm does not have an interval argument. There are
about 50 methods to calculate CIs for predicted values of GLMs,
that's a major worry. This function takes the simplest route, calculating the
(fit, lwr, upr) in the linear predictor scale, and then if type=
&quot;response&quot;, those 3 columns are put through linkinv().  This is
the same method that SAS manuals suggest they use, same as Ben
Bolker suggests in r-help (2010).  I'd rather use one of the
fancy tools like Edgeworth expansion, but that R code is not
available (but is promised).
</p>
<p>Use predict.lm with se.fit = TRUE to calculate fit and se.fit.
Then calculate lwr and upr as fit +/- tval * se.fit. If model is
lm, the model df.residual will be used to get tval. If glm, this
is a normal approximation, so we thugishly assert tval = 1.98.
</p>
<p>There's some confusing term translation. I wish R lm and glm would
be brought into line. For lm, residual.scale = sigma. For glm,
residual.scale = sqrt(dispersion)
</p>


<h3>Value</h3>

<p>c(fit, lwr, upr), and possibly more.
</p>

<hr>
<h2 id='predictOMatic'>Create predicted values after choosing values of predictors.  Can
demonstrate marginal effects of the predictor variables.</h2><span id='topic+predictOMatic'></span>

<h3>Description</h3>

<p>It creates &quot;newdata&quot; frames which are passed
to predict. The key idea is that each predictor has certain focal
values on which we want to concentrate. We want a more-or-less
easy way to spawn complete newdata objects along with fitted values.
The <code>newdata</code> function creates those objects, its documentation
might be helpful in understanding some nuances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictOMatic(
  model = NULL,
  predVals = "margins",
  divider = "quantile",
  n = 5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictOMatic_+3A_model">model</code></td>
<td>
<p>Required. A fitted regression model. A <code>predict</code>
method must exist for that model.</p>
</td></tr>
<tr><td><code id="predictOMatic_+3A_predvals">predVals</code></td>
<td>
<p>Optional. How to choose predictor values?  Can be
as simple as a keyword &quot;auto&quot; or &quot;margins&quot;. May also be very
fine-grained detail, including 1) a vector of variable names (for
which values will be automatically selected) 2) a named
vector of variable names and divider functions, or 3) a list
naming variables and values. See details and examples.</p>
</td></tr>
<tr><td><code id="predictOMatic_+3A_divider">divider</code></td>
<td>
<p>An algorithm name from c(&quot;quantile&quot;, &quot;std.dev&quot;,
&quot;seq&quot;, &quot;table&quot;) or a user-provided function.  This sets the method
for selecting values of the predictor. Documentation for the
rockchalk methods can be found in the functions
<code>cutByQuantile</code>, <code>cutBySD</code>, <code>plotSeq</code>, and
<code>cutByTable</code>,.</p>
</td></tr>
<tr><td><code id="predictOMatic_+3A_n">n</code></td>
<td>
<p>Default = 5. The number of values for which
predictions are sought.</p>
</td></tr>
<tr><td><code id="predictOMatic_+3A_...">...</code></td>
<td>
<p>Optional arguments to be passed to the predict
function. In particular, the arguments se.fit and interval are
extracted from ... and used to control the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no predVals argument is supplied (same as
<code>predVals = "margins"</code>, predictOMatic creates a list of new
data frames, one for each predictor variable. It uses the default
divider algorithm (see the divider argument) and it estimates
predicted values for <code>n</code> different values of the predictor. A
model with formula <code>y ~ x1 + x2 + x3</code> will cause 3 separate
output data frames, one for each predictor. They will be named
objects in the list.
</p>
<p>The default approach will have marginal tables, while the setting
<code>predVals = "auto"</code> will create a single large newdata frame
that holds the Cartesian product of the focal values of each predictor.
</p>
<p><code>predVals</code> may be a vector of variable names, or it may be a
list of names and particular values. Whether a vector or a list is supplied,
<code>predVals</code> must name only predictors that are fitted in the
model. <code>predictOMatic</code> will choose the mean or mode for
variables that are not explicitly listed, and selected values of
the named variables are &quot;mixed and matched&quot; to make a data set.
There are many formats in which it can be supplied.  Suppose a
regression formula is <code>y1 ~ sex + income + health +
height</code>. The simplest format for predVals will be a vector of
variable names, leaving the selection of detailed values to the
default algorithms. For example, <code>predVals = c("income",
"height")</code> will cause sex and health to be set at central values
and income and height will have target values selected according
to the divider algorithm (see the argument <code>divider</code>).
</p>
<p>The user can spcecify divider algoriths to choose focal values,
<code>predvals = c(income = "quantile", height = "std.dev.")</code>. The
dividers provided by the rockchalk package are &quot;quantile&quot;,
&quot;std.dev.&quot;, &quot;seq&quot; and &quot;table&quot;.  Those are discussed more
completely in the help for <code>focalVals</code>.  The appropriate
algorithms will select focal values of the predictors and they
will supply <code>n</code> values for each in a &quot;mix and match&quot; data
frame. After rockchalk 1.7.2, the divider argument can also be the
name of a function, such as R's pretty.
</p>
<p>Finally, users who want very fine grained control over
predictOMatic can supply a named list of predictor
values. For example,
<code>predVals = list(height = c(5.5, 6.0, 6.5),
income = c(10, 20, 30, 40, 50), sex = levels(dat$sex))</code>. One can
also use algorithm names, <code>predVals = list(height =
c(5.5, 6.0, 6.5), income = "quantile")</code> and so forth. Examples are
offered below.
</p>
<p>The variables named in the <code>predVals</code> argument should be the names
of the variables in the raw data frame, not the names that R
creates when it interprets a formula. We want &quot;x&quot;, not the
transformation in the functions (not <code>log(x)</code>, or
<code>as.factor(x)</code> or <code>as.numeric(x)</code>). If a formula has a
predictor <code>poly(height, 3)</code>, then the predVals argument
should refer to height, not <code>poly(height, 3)</code>.  I've invested
quite a bit of effort to make sure this &quot;just works&quot; (many
alternative packages that calculate predicted values do not).
</p>
<p>It it important to make sure that diagnostic plots and summaries
of predictions are calculated with the exact same data that was
used to fit the model. This is surprisingly difficult because
formulas can include things like log(income + d) and so forth. The
function <code>model.data</code> is the magic bullet for that part of
the problem.
</p>
<p>Here is one example sequence that fits a model, discerns some
focal values, and then uses predictOMatic.
</p>
<p><code>
d &lt;- 3
alpha &lt;- 13
m1 &lt;- lm(yout ~ xin + xout + poly(xother,2) + log(xercise + alpha), data = dat)
m1dat &lt;- model.data(m1)
</code>
</p>
<p>Now, when you are thinking about which values you might like to
specify in predVals, use m1dat to decide. Try
</p>
<p><code>summarize(m1dat)</code>
</p>
<p>Then run something like
</p>
<p><code>predictOMatic( m1, predVals = list(xin = median(m1dat$xin), xout =
c(1,2,3), xother = quantile(m1dat$xother))</code>
</p>
<p>Get the idea?
</p>


<h3>Value</h3>

<p>A data frame or a list of data frames.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rockchalk)

## Replicate some R classics.  The budworm.lg data from predict.glm
## will work properly after re-formatting the information as a data.frame:

## example from Venables and Ripley (2002, pp. 190-2.)
df &lt;- data.frame(ldose = rep(0:5, 2),
                 sex = factor(rep(c("M", "F"), c(6, 6))),
                 SF.numdead = c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16))
df$SF.numalive = 20 - df$SF.numdead

budworm.lg &lt;- glm(cbind(SF.numdead, SF.numalive) ~ sex*ldose,
                  data = df,  family = binomial)

predictOMatic(budworm.lg)

predictOMatic(budworm.lg, n = 7)

predictOMatic(budworm.lg, predVals = c("ldose"), n = 7)

predictOMatic(budworm.lg, predVals = c(ldose = "std.dev.", sex = "table"))



## Now make up a data frame with several numeric and categorical predictors.

set.seed(12345)
N &lt;- 100
x1 &lt;- rpois(N, l = 6)
x2 &lt;- rnorm(N, m = 50, s = 10)
x3 &lt;- rnorm(N)
xcat1 &lt;- gl(2,50, labels = c("M","F"))
xcat2 &lt;- cut(rnorm(N), breaks = c(-Inf, 0, 0.4, 0.9, 1, Inf),
             labels = c("R", "M", "D", "P", "G"))
dat &lt;- data.frame(x1, x2, x3, xcat1, xcat2)
rm(x1, x2, x3, xcat1, xcat2)
dat$xcat1n &lt;- with(dat, contrasts(xcat1)[xcat1, , drop = FALSE])
dat$xcat2n &lt;- with(dat, contrasts(xcat2)[xcat2, ])
STDE &lt;- 15
dat$y &lt;- with(dat,
              0.03 + 0.8*x1 + 0.1*x2 + 0.7*x3 + xcat1n %*% c(2) +
              xcat2n %*% c(0.1,-2,0.3, 0.1) + STDE*rnorm(N))
## Impose some random missings
dat$x1[sample(N, 5)] &lt;- NA
dat$x2[sample(N, 5)] &lt;- NA
dat$x3[sample(N, 5)] &lt;- NA
dat$xcat2[sample(N, 5)] &lt;- NA
dat$xcat1[sample(N, 5)] &lt;- NA
dat$y[sample(N, 5)] &lt;- NA
summarize(dat)


m0 &lt;- lm(y ~ x1 + x2 + xcat1, data = dat)
summary(m0)
## The model.data() function in rockchalk creates as near as possible
## the input data frame.
m0.data &lt;- model.data(m0)
summarize(m0.data)

## no predVals: analyzes each variable separately
(m0.p1 &lt;- predictOMatic(m0))

## requests confidence intervals from the predict function
(m0.p2 &lt;- predictOMatic(m0, interval = "confidence"))

## predVals as vector of variable names: gives "mix and match" predictions
(m0.p3 &lt;- predictOMatic(m0, predVals = c("x1", "x2")))

## predVals as vector of variable names: gives "mix and match" predictions
(m0.p3s &lt;- predictOMatic(m0, predVals = c("x1", "x2"), divider = "std.dev."))

## "seq" is an evenly spaced sequence across the predictor.
(m0.p3q &lt;- predictOMatic(m0, predVals = c("x1", "x2"), divider = "seq"))

(m0.p3i &lt;- predictOMatic(m0, predVals = c("x1", "x2"),
                         interval = "confidence", n = 3))

(m0.p3p &lt;- predictOMatic(m0, predVals = c("x1", "x2"), divider = pretty))

## predVals as vector with named divider algorithms.
(m0.p3 &lt;- predictOMatic(m0, predVals = c(x1 = "seq", x2 = "quantile")))
## predVals as named vector of divider algorithms

## same idea, decided to double-check
(m0.p3 &lt;- predictOMatic(m0, predVals = c(x1 = "quantile", x2 = "std.dev.")))
getFocal(m0.data$x2, xvals =  "std.dev.", n = 5)


## Change from quantile to standard deviation divider
(m0.p5 &lt;- predictOMatic(m0, divider = "std.dev.", n = 5))

## Still can specify particular values if desired
(m0.p6 &lt;- predictOMatic(m0, predVals = list("x1" = c(6,7),
                            "xcat1" = levels(m0.data$xcat1))))

(m0.p7 &lt;- predictOMatic(m0, predVals = c(x1 = "quantile", x2 = "std.dev.")))
getFocal(m0.data$x2, xvals =  "std.dev.", n = 5)

(m0.p8 &lt;- predictOMatic(m0, predVals = list( x1 = quantile(m0.data$x1,
                        na.rm = TRUE, probs = c(0, 0.1, 0.5, 0.8,
                        1.0)), xcat1 = levels(m0.data$xcat1))))

(m0.p9 &lt;- predictOMatic(m0, predVals = list(x1 = "seq", "xcat1" =
                                levels(m0.data$xcat1)), n = 8) )


(m0.p10 &lt;- predictOMatic(m0, predVals = list(x1 = "quantile",
                                 "xcat1" = levels(m0.data$xcat1)), n =  5) )


(m0.p11 &lt;- predictOMatic(m0, predVals = c(x1 = "std.dev."), n = 10))

## Previous same as

(m0.p11 &lt;- predictOMatic(m0, predVals = c(x1 = "default"), divider =
                         "std.dev.", n = 10))

## Previous also same as

(m0.p11 &lt;- predictOMatic(m0, predVals = c("x1"), divider = "std.dev.", n = 10))


(m0.p11 &lt;- predictOMatic(m0,  predVals = list(x1 = c(0, 5, 8), x2 = "default"),
                         divider = "seq"))



m1 &lt;- lm(y ~ log(10+x1) + sin(x2) + x3, data = dat)
m1.data &lt;- model.data(m1)
summarize(m1.data)


(newdata(m1))
(newdata(m1, predVals = list(x1 = c(6, 8, 10))))
(newdata(m1, predVals = list(x1 = c(6, 8, 10), x3 = c(-1,0,1))))
(newdata(m1, predVals = list(x1 = c(6, 8, 10),
                 x2 = quantile(m1.data$x2, na.rm = TRUE), x3 = c(-1,0,1))))

(m1.p1 &lt;- predictOMatic(m1, divider = "std.dev", n = 5))
(m1.p2 &lt;- predictOMatic(m1, divider = "quantile", n = 5))

(m1.p3 &lt;- predictOMatic(m1, predVals = list(x1 = c(6, 8, 10),
                            x2 = median(m1.data$x2, na.rm = TRUE))))

(m1.p4 &lt;- predictOMatic(m1, predVals = list(x1 = c(6, 8, 10),
                                x2 = quantile(m1.data$x2, na.rm = TRUE))))

(m1.p5 &lt;- predictOMatic(m1))
(m1.p6 &lt;- predictOMatic(m1, divider = "std.dev."))
(m1.p7 &lt;- predictOMatic(m1, divider = "std.dev.", n = 3))
(m1.p8 &lt;- predictOMatic(m1, divider = "std.dev.", interval = "confidence"))


m2 &lt;- lm(y ~ x1 + x2 + x3 + xcat1 + xcat2, data = dat)
##  has only columns and rows used in model fit
m2.data &lt;- model.data(m2)
summarize(m2.data)

## Check all the margins
(predictOMatic(m2, interval = "conf"))

## Lets construct predictions the "old fashioned way" for comparison

m2.new1 &lt;- newdata(m2, predVals = list(xcat1 = levels(m2.data$xcat1),
                           xcat2 = levels(m2.data$xcat2)), n = 5)
predict(m2, newdata = m2.new1)


(m2.p1 &lt;- predictOMatic(m2,
                        predVals = list(xcat1 = levels(m2.data$xcat1),
                            xcat2 = levels(m2.data$xcat2)),
                        xcat2 = c("M","D")))
## See? same!

## Pick some particular values for focus
m2.new2 &lt;- newdata(m2, predVals = list(x1 = c(1,2,3), xcat2 = c("M","D")))
## Ask for predictions
predict(m2, newdata = m2.new2)


## Compare: predictOMatic generates a newdata frame and predictions in one step

(m2.p2 &lt;- predictOMatic(m2, predVals = list(x1 = c(1,2,3),
                                xcat2 = c("M","D"))))

(m2.p3 &lt;- predictOMatic(m2, predVals = list(x2 = c(0.25, 1.0),
                                xcat2 = c("M","D"))))

(m2.p4 &lt;- predictOMatic(m2, predVals = list(x2 = plotSeq(m2.data$x2, 10),
                                xcat2 = c("M","D"))))

(m2.p5 &lt;- predictOMatic(m2, predVals = list(x2 = c(0.25, 1.0),
                                xcat2 = c("M","D")), interval = "conf"))

(m2.p6 &lt;- predictOMatic(m2, predVals = list(x2 = c(49, 51),
                                xcat2 = levels(m2.data$xcat2),
                                x1 = plotSeq(dat$x1))))

plot(y ~ x1, data = m2.data)
by(m2.p6, list(m2.p6$xcat2), function(x) {
    lines(x$x1, x$fit, col = x$xcat2, lty = as.numeric(x$xcat2))
})

m2.newdata &lt;- newdata(m2, predVals = list(x2 = c(48, 50, 52),
                              xcat2 = c("M","D")))
predict(m2, newdata = m2.newdata)

(m2.p7 &lt;- predictOMatic(m2, predVals = list(x2 = c(48, 50, 52),
                                xcat2 = c("M","D"))))

(m2.p8 &lt;- predictOMatic(m2,
             predVals = list(x2 = range(m2.data$x2, na.rm = TRUE),
             xcat2 = c("M","D"))))

(m2.p9 &lt;- predictOMatic(m2, predVals = list(x2 = plotSeq(m2.data$x2),
             x1 = quantile(m2.data$x1, pr =c(0.33, 0.66), na.rm = TRUE),
             xcat2 = c("M","D"))))
plot(y ~ x2 , data = m2.data)

by(m2.p9, list(m2.p9$x1, m2.p9$xcat2), function(x) {lines(x$x2, x$fit)})



(predictOMatic(m2, predVals = list(x2 = c(50, 60), xcat2 = c("M","D")),
               interval = "conf"))

## create a dichotomous dependent variable
y2 &lt;- ifelse(rnorm(N) &gt; 0.3, 1, 0)
dat &lt;- cbind(dat, y2)

m3 &lt;- glm(y2 ~ x1 + x2 + x3 + xcat1, data = dat, family = binomial(logit))
summary(m3)
m3.data &lt;- model.data(m3)
summarize(m3.data)

(m3.p1 &lt;- predictOMatic(m3, divider = "std.dev."))

(m3.p2 &lt;- predictOMatic(m3, predVals = list(x2 = c(40, 50, 60),
                             xcat1 = c("M","F")),
                        divider = "std.dev.", interval = "conf"))

## Want a full accounting for each value of x2?
(m3.p3 &lt;- predictOMatic(m3,
                predVals = list(x2 = unique(m3.data$x2),
                    xcat1 = c("M","F")), interval = "conf"))


## Would like to write a more beautiful print method
## for output object, but don't want to obscure structure from user.
## for (i in names(m3.p1)){
##     dns &lt;- cbind(m3.p1[[i]][i], m3.p1[[i]]$fit)
##     colnames(dns) &lt;- c(i, "predicted")
##     print(dns)
## }


</code></pre>

<hr>
<h2 id='print.pctable'>Display pctable objects</h2><span id='topic+print.pctable'></span>

<h3>Description</h3>

<p>This is not very fancy. Note that the saved pctable object
has the information inside it that is required to write both
column and row percentages. The arguments colpct and rowpct
are used to ask for the two types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pctable'
print(x, colpct = TRUE, rowpct = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.pctable_+3A_x">x</code></td>
<td>
<p>A pctable object</p>
</td></tr>
<tr><td><code id="print.pctable_+3A_colpct">colpct</code></td>
<td>
<p>Default TRUE: include column percentages?</p>
</td></tr>
<tr><td><code id="print.pctable_+3A_rowpct">rowpct</code></td>
<td>
<p>Default FALSE: include row percentages?</p>
</td></tr>
<tr><td><code id="print.pctable_+3A_...">...</code></td>
<td>
<p>Other arguments passed through to print method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table object for the final printed table.
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='print.summarize'>print method for output from summarize</h2><span id='topic+print.summarize'></span>

<h3>Description</h3>

<p>Be aware that the unrounded numeric matrix
is available as an attribute of the returned object.
This method displays a rounded, character-formatted
display of the numeric varibles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summarize'
print(x, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summarize_+3A_x">x</code></td>
<td>
<p>Object produced by summarize</p>
</td></tr>
<tr><td><code id="print.summarize_+3A_digits">digits</code></td>
<td>
<p>Decimal values to display, defaults as 2.</p>
</td></tr>
<tr><td><code id="print.summarize_+3A_...">...</code></td>
<td>
<p>optional arguments for print function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>x, unchanged
Prints objects created by summarize
</p>

<hr>
<h2 id='print.summary.pctable'>print method for summary.pctable objects</h2><span id='topic+print.summary.pctable'></span>

<h3>Description</h3>

<p>prints pctab objects. Needed only to deal properly with quotes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.pctable'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.pctable_+3A_x">x</code></td>
<td>
<p>a summary.pctable object</p>
</td></tr>
<tr><td><code id="print.summary.pctable_+3A_...">...</code></td>
<td>
<p>Other arguments to print method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing is returned
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='rbindFill'>Stack together data frames</h2><span id='topic+rbindFill'></span>

<h3>Description</h3>

<p>In the end of the code for plyr::rbind.fill, the author explains
that is uses an experimental function to build the data.frame.  I
would rather not put any weight on an experimental function, so I
sat out to create a new rbindFill. This function uses no
experimental functions. It does not rely on any functions from
packages that are not in base of R, except, of course, for functions
in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbindFill(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbindFill_+3A_...">...</code></td>
<td>
<p>Data frames</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Along the way, I noticed a feature that seems to be a flaw in both
rbind and rbind.fill.  In the examples, there is a demonstration
of the fact that base R rbind and plyr::rbind.fill both have
undesirable properties when data sets containing factors and
ordered variables are involved. This function introduces a
&quot;data consistency check&quot; that prevents corruption of variables
when data frames are combined.  This &quot;safe&quot; version will notice
differences in classes of variables among data.frames and stop
with an error message to alert the user to the problem.
</p>


<h3>Value</h3>

<p>A stacked data frame
</p>


<h3>Author(s)</h3>

<p>Paul Johnson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123123)
N &lt;- 10000
dat &lt;- genCorrelatedData2(N, means = c(10, 20, 5, 5, 6, 7, 9), sds = 3,
           stde = 3, rho = .2,  beta = c(1, 1, -1, 0.5))
dat1 &lt;- dat
dat1$xcat1 &lt;- factor(sample(c("a", "b", "c", "d"), N, replace=TRUE))
dat1$xcat2 &lt;- factor(sample(c("M", "F"), N, replace=TRUE),
                    levels = c("M", "F"), labels = c("Male", "Female"))
dat1$y &lt;- dat$y +
          as.vector(contrasts(dat1$xcat1)[dat1$xcat1, ] %*% c(0.1, 0.2, 0.3))
dat1$xchar1 &lt;- rep(letters[1:26], length.out = N)
dat2 &lt;- dat
dat1$x3 &lt;- NULL
dat2$x2 &lt;- NULL
dat2$xcat2 &lt;- factor(sample(c("M", "F"), N, replace=TRUE),
                     levels = c("M", "F"), labels = c("Male", "Female"))
dat2$xcat3 &lt;- factor(sample(c("K1", "K2", "K3", "K4"), N, replace=TRUE))
dat2$xchar1 &lt;- "1"
dat3 &lt;- dat
dat3$x1 &lt;- NULL
dat3$xcat3 &lt;-  factor(sample(c("L1", "L2", "L3", "L4"), N, replace=TRUE)) 
dat.stack &lt;- rbindFill(dat1, dat2, dat3)
str(dat.stack)

## Possible BUG alert about base::rbind and plyr::rbind.fill
## Demonstrate the problem of a same-named variable that is factor in one and
## an ordered variable in the other
dat5 &lt;- data.frame(ds = "5", x1 = rnorm(N),
                   xcat1 = gl(20, 5, labels = LETTERS[20:1]))
dat6 &lt;- data.frame(ds = "6", x1 = rnorm(N),
                   xcat1 = gl(20, 5, labels = LETTERS[1:20], ordered = TRUE))
## rbind reduces xcat1 to factor, whether we bind dat5 or dat6 first.
stack1 &lt;- base::rbind(dat5, dat6)
str(stack1)
## note xcat1 levels are ordered T, S, R, Q
stack2 &lt;- base::rbind(dat6, dat5)
str(stack2)
## xcat1 levels are A, B, C, D
## stack3 &lt;- plyr::rbind.fill(dat5, dat6)
## str(stack3)
## xcat1 is a factor with levels T, S, R, Q ...
## stack4 &lt;- plyr::rbind.fill(dat6, dat5)
## str(stack4)
## oops, xcat1 is ordinal with levels A &lt; B &lt; C &lt; D
## stack5 &lt;- rbindFill(dat5, dat6)
</code></pre>

<hr>
<h2 id='religioncrime'>Religious beliefs and crime rates</h2><span id='topic+religioncrime'></span>

<h3>Description</h3>

<p>The data national-level summary indicators of public opinion about
the existence of heaven and hell as well as the national rate of
violent crime.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(religioncrime)
</code></pre>


<h3>Format</h3>

<p>data.frame: 51 obs. of 3 variables
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a> and Anonymous
</p>


<h3>Source</h3>

<p>Anonymous researcher who claims the data is real.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(rockchalk)
data(religioncrime)
mod1 &lt;- lm(crime ~ heaven, data=religioncrime)
mod2 &lt;- lm(crime ~ hell, data=religioncrime)
mod3 &lt;- lm(crime ~ heaven + hell, data=religioncrime)
with(religioncrime,
mcGraph1(heaven, hell, crime)
)
with(religioncrime,
mcGraph2(heaven, hell, crime)
)
mod1 &lt;- with(religioncrime,
mcGraph3(heaven, hell, crime)
)
summary(mod1[[1]])
##TODO: Draw more with perspective matrix mod1[[2]]
</code></pre>

<hr>
<h2 id='removeNULL'>Remove NULL values variables from a list</h2><span id='topic+removeNULL'></span>

<h3>Description</h3>

<p>Unlike vectors, lists can hold objects with
value NULL. This gets rid of them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeNULL(aList)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="removeNULL_+3A_alist">aList</code></td>
<td>
<p>A list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This version is NOT recursive
</p>
<p>plyr::rbind.fill uses an experimental function
that I choose to avoid. This is the &quot;safe&quot; version.
</p>


<h3>Value</h3>

<p>Same list with NULL's removed
</p>


<h3>Author(s)</h3>

<p>Paul Johnson
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Note it is non-recursive, NULL remains in e
x &lt;- list(a = rnorm(5), b = NULL, c = rnorm(5), d = NULL,
     e = list(f = rnorm(2), g = NULL))
x
removeNULL(x)
</code></pre>

<hr>
<h2 id='residualCenter'>Calculates a &quot;residual-centered&quot; interaction regression.</h2><span id='topic+residualCenter'></span><span id='topic+residualCenter.default'></span><span id='topic+predict.rcreg'></span>

<h3>Description</h3>

<p>Given a fitted <code>lm</code>, this function scans for coefficients
estimated from &quot;interaction terms&quot; by checking for colon
symbols. The function then calculates the &quot;residual centered&quot;
estimate of the interaction term and replaces the interaction term
with that residual centered estimate. It works for any order of
interaction, unlike other implementations of the same
approach. The function <code>lmres</code> in the now-archived package
pequod was a similar function.
</p>
<p>Calculates predicted values of
residual centered interaction regressions estimated in
any type of regression framework (lm, glm, etc).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residualCenter(model)

## Default S3 method:
residualCenter(model)

## S3 method for class 'rcreg'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residualCenter_+3A_model">model</code></td>
<td>
<p>A fitted lm object</p>
</td></tr>
<tr><td><code id="residualCenter_+3A_object">object</code></td>
<td>
<p>Fitted residual-centered regression from residualCenter</p>
</td></tr>
<tr><td><code id="residualCenter_+3A_...">...</code></td>
<td>
<p>Other named arguments. May include newdata, a dataframe of 
predictors. That should include values for individual predictor, need 
not include interactions that are constructed by residualCenter. 
These parameters that will be passed to the predict method of the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a regression model of the type as the input model, with
the exception that the residualCentered predictor is used in place
of the original interaction. The return model includes new
variable centeringRegressions: a list including each of the
intermediate regressions that was calculated in order to create
the residual centered interaction terms. These latter objects may
be necessary for diagnostics and to calculate predicted values for
hypothetical values of the inputs. If there are no interactive
terms, then NULL is returned.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>References</h3>

<p>Little, T. D., Bovaird, J. A.,
&amp; Widaman, K. F. (2006). On the Merits of Orthogonalizing
Powered and Product Terms: Implications for Modeling
Interactions Among Latent Variables.
Structural Equation Modeling, 13(4), 497-519.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x1 &lt;- rnorm(100)
x2 &lt;- rnorm(100)
x3 &lt;- rnorm(100)
x4 &lt;- rnorm(100)
y &lt;- rnorm(100)
dat &lt;- data.frame(y, x1,x2,x3,x4)
rm(x1,x2,x3,x4,y)
m1 &lt;- lm(y~ x1*x2 + x4, data = dat)
 
m1RC &lt;- residualCenter(m1)

m1RCs &lt;- summary(m1RC)
## The stage 1 centering regressions can be viewed as well
## lapply(m1RC$rcRegressions, summary)

## Verify residualCenter() output against the manual calculation
dat$x1rcx2 &lt;- as.numeric(resid(lm(I(x1*x2) ~ x1 + x2, data = dat)))
m1m &lt;- lm(y ~ x1 + x2 + x4 + x1rcx2, data=dat)
summary(m1m)
cbind("residualCenter" = coef(m1RC), "manual" = coef(m1m))


m2 &lt;- lm(y~ x1*x2*x3 + x4, data=dat)
m2RC &lt;- residualCenter(m2)
m2RCs &lt;- summary(m2RC)

## Verify that result manually
dat$x2rcx3 &lt;- as.numeric(resid(lm(I(x2*x3) ~ x2 + x3, data = dat)))
dat$x1rcx3 &lt;- as.numeric(resid(lm(I(x1*x3) ~ x1 + x3, data = dat)))
dat$x1rcx2rcx3 &lt;- as.numeric( resid(lm(I(x1*x2*x3) ~ x1 + x2 + x3 + x1rcx2 +
                                       x1rcx3 + x2rcx3 , data=dat)))
(m2m &lt;- lm(y ~ x1 + x2 + x3+ x4 + x1rcx2 + x1rcx3 + x2rcx3 + x1rcx2rcx3,
           data = dat))

cbind("residualCenter" = coef(m2RC), "manual" = coef(m2m))


### As good as pequod's lmres
### not run because pequod generates R warnings
###
### if (require(pequod)){
###  pequodm1 &lt;- lmres(y ~ x1*x2*x3 + x4, data=dat) 
###  pequodm1s &lt;- summary(pequodm1)
###  coef(pequodm1s)
### }

### Works with any number of interactions. See:

m3 &lt;- lm(y~ x1*x2*x3*x4, data=dat)
m3RC &lt;- residualCenter(m3)
summary(m3RC)
##'
## Verify that one manually (Gosh, this is horrible to write out)
dat$x1rcx4 &lt;- as.numeric(resid(lm(I(x1*x4) ~ x1 + x4, data=dat)))
dat$x2rcx4 &lt;- as.numeric(resid(lm(I(x2*x4) ~ x2 + x4, data=dat)))
dat$x3rcx4 &lt;- as.numeric(resid(lm(I(x3*x4) ~ x3 + x4, data=dat)))
dat$x1rcx2rcx4 &lt;- as.numeric(resid(lm(I(x1*x2*x4) ~ x1 + x2 + x4 +
                                      x1rcx2 + x1rcx4 + x2rcx4, data=dat)))
dat$x1rcx3rcx4 &lt;- as.numeric(resid(lm(I(x1*x3*x4) ~ x1 + x3 + x4 +
                                      x1rcx3 + x1rcx4 + x3rcx4, data=dat)))
dat$x2rcx3rcx4 &lt;- as.numeric(resid(lm(I(x2*x3*x4) ~ x2 + x3 + x4 +
                                      x2rcx3 + x2rcx4 + x3rcx4, data=dat)))
dat$x1rcx2rcx3rcx4 &lt;-
    as.numeric(resid(lm(I(x1*x2*x3*x4) ~ x1 + x2 + x3 + x4 +
                        x1rcx2 + x1rcx3 + x2rcx3 + x1rcx4  + x2rcx4 +
                        x3rcx4  + x1rcx2rcx3 + x1rcx2rcx4 + x1rcx3rcx4 +
                        x2rcx3rcx4, data=dat)))
(m3m &lt;- lm(y ~ x1 + x2 + x3 + x4 + x1rcx2 + x1rcx3 + x2rcx3 + x1rcx4 +
           x2rcx4 + x3rcx4 + x1rcx2rcx3 + x1rcx2rcx4 + x1rcx3rcx4 +
           x2rcx3rcx4 + x1rcx2rcx3rcx4, data=dat))

cbind("residualCenter"=coef(m3RC), "manual"=coef(m3m))

### If you want to fit a sequence of models, as in pequod, can do.

tm &lt;-terms(m2)
tmvec &lt;- attr(terms(m2), "term.labels")
f1 &lt;- tmvec[grep(":", tmvec, invert = TRUE)]
f2 &lt;- tmvec[grep(":.*:", tmvec, invert = TRUE)]
f3 &lt;- tmvec[grep(":.*:.*:", tmvec, invert = TRUE)]

## &gt; f1
## [1] "x1" "x2" "x3" "x4"
## &gt; f2
## [1] "x1"    "x2"    "x3"    "x4"    "x1:x2" "x1:x3" "x2:x3"
## &gt; f3
## [1] "x1"       "x2"       "x3"       "x4"       "x1:x2"    "x1:x3"    "x2:x3"   
## [8] "x1:x2:x3"

f1 &lt;- lm(as.formula(paste("y","~", paste(f1, collapse=" + "))), data=dat)
f1RC &lt;- residualCenter(f1)
summary(f1RC)

f2 &lt;- lm(as.formula(paste("y","~", paste(f2, collapse=" + "))), data=dat)
f2RC &lt;- residualCenter(f2)
summary(f2RC)

f3 &lt;- lm(as.formula(paste("y","~", paste(f3, collapse=" + "))), data=dat)
f3RC &lt;- residualCenter(f3)
summary(f3RC)

library(rockchalk)
dat &lt;- genCorrelatedData(1000, stde=5)

m1 &lt;- lm(y ~ x1 * x2, data=dat)

m1mc &lt;- meanCenter(m1)
summary(m1mc)

m1rc &lt;- residualCenter(m1)
summary(m1rc)


newdf &lt;- apply(dat, 2, summary)
newdf &lt;- as.data.frame(newdf)

predict(m1rc, newdata=newdf)
</code></pre>

<hr>
<h2 id='se.bars'>Draw standard error bar for discrete variables</h2><span id='topic+se.bars'></span>

<h3>Description</h3>

<p>Used with plotSlopes if plotx is discrete. This is not currently
exported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>se.bars(x, y, lwr, upr, width = 0.2, col, opacity = 120, lwd = 1, lty = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="se.bars_+3A_x">x</code></td>
<td>
<p>The x center point</p>
</td></tr>
<tr><td><code id="se.bars_+3A_y">y</code></td>
<td>
<p>The fitted &quot;predicted&quot; value</p>
</td></tr>
<tr><td><code id="se.bars_+3A_lwr">lwr</code></td>
<td>
<p>The lower confidence interval bound</p>
</td></tr>
<tr><td><code id="se.bars_+3A_upr">upr</code></td>
<td>
<p>The upper confidence interval bound</p>
</td></tr>
<tr><td><code id="se.bars_+3A_width">width</code></td>
<td>
<p>Thickness of shaded column</p>
</td></tr>
<tr><td><code id="se.bars_+3A_col">col</code></td>
<td>
<p>Color for a bar</p>
</td></tr>
<tr><td><code id="se.bars_+3A_opacity">opacity</code></td>
<td>
<p>Value in c(0, 254). 120 is default, that's partial see through.</p>
</td></tr>
<tr><td><code id="se.bars_+3A_lwd">lwd</code></td>
<td>
<p>line width, usually 1</p>
</td></tr>
<tr><td><code id="se.bars_+3A_lty">lty</code></td>
<td>
<p>line type, usually 1</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul Johnson
</p>

<hr>
<h2 id='skewness'>Calculate skewness</h2><span id='topic+skewness'></span>

<h3>Description</h3>

<p>Skewness is a summary of the symmetry of a distribution's
probability density function. In a Normal distribution, the
skewness is 0, indicating symmetry about the expected value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewness(x, na.rm = TRUE, unbiased = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skewness_+3A_x">x</code></td>
<td>
<p>A numeric variable (vector)</p>
</td></tr>
<tr><td><code id="skewness_+3A_na.rm">na.rm</code></td>
<td>
<p>default TRUE. Should missing data be removed?</p>
</td></tr>
<tr><td><code id="skewness_+3A_unbiased">unbiased</code></td>
<td>
<p>default TRUE. Should the denominator of the
variance estimate be divided by N-1?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If na.rm = FALSE and there are missing values, the mean and
variance are undefined and this function returns NA.
</p>
<p>The skewness may be calculated with the small-sample bias-corrected
estimate of the standard deviation.  It appears somewhat controversial
whether this is necessary, hence the argument unbiased is provided.
Set unbiased = FALSE if it is desired to have the one recommended
by NIST, for example. According to the US NIST,
<a href="http://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm">http://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm</a>,
skewness is defined as the mean of cubed deviations divided by the
cube of the standard deviation.
</p>
<p>mean((x - mean(x))^3)
skewness =    ___________________
sd(x)^3
</p>
<p>where sd(x) is calculated with the denominator N, rather than
N-1. This is the Fisher-Pearson coefficient of skewness, they claim.
The unbiased variant uses the standard deviation divisor (N-1) to
bias-correct the standard deviation.
</p>


<h3>Value</h3>

<p>A scalar value or NA
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='standardize'>Estimate standardized regression coefficients for all variables</h2><span id='topic+standardize'></span><span id='topic+standardize.lm'></span>

<h3>Description</h3>

<p>This is brain-dead standardization of all variables in the design
matrix.  It mimics the silly output of SPSS, which standardizes
all regressors, even if they represent categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardize(model)

## S3 method for class 'lm'
standardize(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardize_+3A_model">model</code></td>
<td>
<p>a fitted lm object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an lm fitted with the standardized variables
</p>
<p>a standardized regression object
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meanCenter">meanCenter</a></code> which will center or
re-scale only numberic variables
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(rockchalk)
N &lt;- 100
dat &lt;- genCorrelatedData(N = N, means = c(100,200), sds = c(20,30), rho = 0.4, stde = 10)
dat$x3 &lt;- rnorm(100, m = 40, s = 4)

m1 &lt;- lm(y ~ x1 + x2 + x3, data = dat)
summary(m1)

m1s &lt;- standardize(m1)
summary(m1s)



m2 &lt;- lm(y ~ x1 * x2 + x3, data = dat)
summary(m2)

m2s &lt;- standardize(m2)
summary(m2s)

m2c &lt;- meanCenter(m2)
summary(m2c)

</code></pre>

<hr>
<h2 id='summarize'>Sorts numeric from discrete variables and returns separate
summaries for those types of variables.</h2><span id='topic+summarize'></span>

<h3>Description</h3>

<p>The work is done by the functions <code>summarizeNumerics</code> and
<code>summarizeFactors</code>.  Please see the help pages for those
functions for complete details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize(
  dat,
  alphaSort = FALSE,
  stats = c("mean", "sd", "skewness", "kurtosis", "entropy", "normedEntropy", "nobs",
    "nmiss"),
  probs = c(0, 0.5, 1),
  digits = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarize_+3A_dat">dat</code></td>
<td>
<p>A data frame</p>
</td></tr>
<tr><td><code id="summarize_+3A_alphasort">alphaSort</code></td>
<td>
<p>If TRUE, the columns are re-organized in
alphabetical order. If FALSE, they are presented in the
original order.</p>
</td></tr>
<tr><td><code id="summarize_+3A_stats">stats</code></td>
<td>
<p>A vector of desired summary statistics. Set
<code>stats = NULL</code> to omit all stat summaries. Legal elements
are <code>c("min", "med", "max", "mean", "sd", "var",
"skewness", "kurtosis", "entropy", "normedEntropy", "nobs",
"nmiss")</code>. The statistics <code>c("entropy", "normedEntropy")</code>
are available only for factor variables, while mean, variance,
and so forth will be calculated only for numeric variables.
<code>"nobs"</code> is the number of observations with non-missing,
finite scores (not NA, NaN, -Inf, or Inf). <code>"nmiss"</code> is
the number of cases with values of NA. The default setting for
<code>probs</code> will cause <code>c("min", "med", "max")</code> to be
included, they need not be requested explicitly. To disable
them, revise <code>probs</code>.</p>
</td></tr>
<tr><td><code id="summarize_+3A_probs">probs</code></td>
<td>
<p>For numeric variables, is used with the
<code>quantile</code> function. The default is
<code>probs = c(0, .50, 1.0)</code>, which are labeled in output as
<code>c("min", "med", and "max")</code>. Set <code>probs = NULL</code>
to prevent these in the output.</p>
</td></tr>
<tr><td><code id="summarize_+3A_digits">digits</code></td>
<td>
<p>Decimal values to display, defaults as 2.</p>
</td></tr>
<tr><td><code id="summarize_+3A_...">...</code></td>
<td>
<p>Optional arguments that are passed to
<code>summarizeNumerics</code> and <code>summarizeFactors</code>. For
numeric variables, one can specify <code>na.rm</code> and
<code>unbiased</code>.  For discrete variables, the key argument is
<code>maxLevels</code>, which determines the number of levels that
will be reported in tables for discrete variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The major purpose here is to generate summary data structure
that is more useful in subsequent data analysis.  The numeric
portion of the summaries are a data frame that can be used in
plots or other diagnostics.
</p>
<p>The term &quot;factors&quot; was used, but &quot;discrete variables&quot; would have
been more accurate.  The factor summaries will collect all
logical, factor, ordered, and character variables.
</p>
<p>Other variable types, such as Dates, will be ignored, with a
warning.
</p>


<h3>Value</h3>

<p>Return is a list with two objects 1) output from
summarizeNumerics: a data frame with variable names on rows
and summary stats on columns, 2) output from summarizeFactors:
a list with summary information about each discrete
variable. The display on-screen is governed by a method
<code>print.summarize</code>.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rockchalk)


set.seed(23452345)
N &lt;- 100
x1 &lt;- gl(12, 2, labels = LETTERS[1:12])
x2 &lt;- gl(8, 3, labels = LETTERS[12:24])
x1 &lt;- sample(x = x1, size=N, replace = TRUE)
x2 &lt;- sample(x = x2, size=N, replace = TRUE)
z1 &lt;- rnorm(N)
a1 &lt;- rnorm(N, mean = 1.2, sd = 11.7)
a2 &lt;- rpois(N, lambda = 10 + abs(a1))
a3 &lt;- rgamma(N, 0.5, 4)
b1 &lt;- rnorm(N, mean = 211.3, sd = 0.4)
dat &lt;- data.frame(z1, a1, x2, a2, x1, a3, b1)
summary(dat)

summarize(dat)

summarize(dat, digits = 4)

summarize(dat, stats = c("min", "max", "mean", "sd"),
          probs = c(0.25, 0.75))

summarize(dat, probs = c(0, 0.20, 0.80),
          stats = c("nobs", "mean", "med", "entropy"))

summarize(dat, probs = c(0, 0.20, 0.50),
          stats = c("nobs", "nmiss", "mean", "entropy"), maxLevels=10)

dat.sum &lt;- summarize(dat, probs = c(0, 0.20, 0.50),
                     stats = c("nobs", "nmiss", "mean", "entropy"), maxLevels=10)
dat.sum
## Inspect unformatted structure of objects within return
dat.sum[["numerics"]]
dat.sum[["factors"]]

## Only quantile values, no summary stats for numeric variables
## Discrete variables get entropy
summarize(dat, 
          probs = c(0, 0.25, 0.50, 0.75, 1.0),
          stats = "entropy", digits = 2)

## Quantiles and the mean for numeric variables.
## No diversity stats for discrete variables (entropy omitted)
summarize(dat, 
          probs = c(0, 0.25, 0.50, 0.75, 1.0),
          stats = "mean")

summarize(dat, 
          probs = NULL,
          stats = "mean")

## Note: output is not beautified by a print method
dat.sn &lt;- summarizeNumerics(dat)
dat.sn
formatSummarizedNumerics(dat.sn)
formatSummarizedNumerics(dat.sn, digits = 5)

dat.summ &lt;- summarize(dat)


dat.sf &lt;- summarizeFactors(dat, maxLevels = 20)
dat.sf
formatSummarizedFactors(dat.sf)

## See actual values of factor summaries, without
## beautified printing
summarizeFactors(dat, maxLevels = 5)
formatSummarizedFactors(summarizeFactors(dat, maxLevels = 5))

summarize(dat, alphaSort = TRUE) 

summarize(dat, digits = 6, alphaSort = FALSE)


summarize(dat, maxLevels = 2)

datsumm &lt;- summarize(dat, stats = c("mean", "sd", "var", "entropy", "nobs"))

## Unbeautified numeric data frame, variables on the rows
datsumm[["numerics"]]
## Beautified versions 1. shows saved version:
attr(datsumm, "numeric.formatted")
## 2. Run formatSummarizedNumerics to re-specify digits:
formatSummarizedNumerics(datsumm[["numerics"]], digits = 10)

datsumm[["factors"]]
formatSummarizedFactors(datsumm[["factors"]])
formatSummarizedFactors(datsumm[["factors"]], digits = 6, maxLevels = 10)
</code></pre>

<hr>
<h2 id='summarizeFactors'>Extracts non-numeric variables, calculates summary information,
including entropy as a diversity indicator.</h2><span id='topic+summarizeFactors'></span>

<h3>Description</h3>

<p>This function finds the non- numeric variables and ignores the
others. (See <code>summarizeNumerics</code> for a function that
handles numeric variables.)  It then treats all non-numeric
variables as if they were factors, and summarizes each. The main
benefits from this compared to R's default summary are 1) more
summary information is returned for each variable (entropy
estimates ofdispersion), 2) the columns in the output are
alphabetized. To prevent alphabetization, use alphaSort = FALSE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeFactors(
  dat = NULL,
  maxLevels = 5,
  alphaSort = TRUE,
  stats = c("entropy", "normedEntropy", "nobs", "nmiss"),
  digits = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarizeFactors_+3A_dat">dat</code></td>
<td>
<p>A data frame</p>
</td></tr>
<tr><td><code id="summarizeFactors_+3A_maxlevels">maxLevels</code></td>
<td>
<p>The maximum number of levels that will be
reported.</p>
</td></tr>
<tr><td><code id="summarizeFactors_+3A_alphasort">alphaSort</code></td>
<td>
<p>If TRUE (default), the columns are re-organized
in alphabetical order. If FALSE, they are presented in the
original order.</p>
</td></tr>
<tr><td><code id="summarizeFactors_+3A_stats">stats</code></td>
<td>
<p>Default is <code>c("nobs", "nmiss", "entropy",
"normedEntropy")</code>.</p>
</td></tr>
<tr><td><code id="summarizeFactors_+3A_digits">digits</code></td>
<td>
<p>Default 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Entropy is one possible measure of diversity. If all outcomes are
equally likely, the entropy is maximized, while if all outcomes
fall into one possible category, entropy is at its lowest
values. The lowest possible value for entropy is 0, while the
maximum value is dependent on the number of categories. Entropy is
also called Shannon's information index in some fields of study
(Balch, 2000 ; Shannon, 1949 ).
</p>
<p>Concerning the use of entropy as a diversity index, the user might
consult Balch(). For each possible outcome category, let p
represent the observed proportion of cases. The diversity
contribution of each category is -p * log2(p). Note that if p is
either 0 or 1, the diversity contribution is 0.  The sum of those
diversity contributions across possible outcomes is the entropy
estimate. The entropy value is a lower bound of 0, but there is no
upper bound that is independent of the number of possible
categories. If m is the number of categories, the maximum possible
value of entropy is -log2(1/m).
</p>
<p>Because the maximum value of entropy depends on the number of
possible categories, some scholars wish to re-scale so as to bring
the values into a common numeric scale. The normed entropy is
calculated as the observed entropy divided by the maximum possible
entropy.  Normed entropy takes on values between 0 and 1, so in a
sense, its values are more easily comparable. However, the
comparison is something of an illusion, since variables with the
same number of categories will always be comparable by their
entropy, whether it is normed or not.
</p>
<p>Warning: Variables of class POSIXt will be ignored. This will be
fixed in the future. The function works perfectly well with
numeric, factor, or character variables.  Other more elaborate
structures are likely to be trouble.
</p>


<h3>Value</h3>

<p>A list of factor summaries
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>References</h3>

<p>Balch, T. (2000). Hierarchic Social Entropy: An Information
Theoretic Measure of Robot Group Diversity. Auton. Robots, 8(3),
209-238.
</p>
<p>Shannon, Claude. E. (1949). The Mathematical Theory of
Communication. Urbana: University of Illinois Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summarizeNumerics">summarizeNumerics</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(21234)
x &lt;- runif(1000)
xn &lt;- ifelse(x &lt; 0.2, 0, ifelse(x &lt; 0.6, 1, 2))
xf &lt;- factor(xn, levels=c(0,1,2), labels("A","B","C"))
dat &lt;- data.frame(xf, xn, x)
summarizeFactors(dat)
##see help for summarize for more examples
</code></pre>

<hr>
<h2 id='summarizeNumerics'>Extracts numeric variables and presents an summary in
a workable format.</h2><span id='topic+summarizeNumerics'></span>

<h3>Description</h3>

<p>Finds the numeric variables, and ignores the others. (See
<code>summarizeFactors</code> for a function that handles non-numeric
variables). It will provide quantiles (specified <code>probs</code> as
well as other summary statistics, specified <code>stats</code>.  Results
are returned in a data frame. The main benefits from this compared
to R's default summary are 1) more summary information is returned
for each variable (dispersion), 2) the results are returned in a
form that is easy to use in further analysis, 3) the variables in
the output may be alphabetized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeNumerics(
  dat,
  alphaSort = FALSE,
  probs = c(0, 0.5, 1),
  stats = c("mean", "sd", "skewness", "kurtosis", "nobs", "nmiss"),
  na.rm = TRUE,
  unbiased = TRUE,
  digits = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarizeNumerics_+3A_dat">dat</code></td>
<td>
<p>a data frame or a matrix</p>
</td></tr>
<tr><td><code id="summarizeNumerics_+3A_alphasort">alphaSort</code></td>
<td>
<p>If TRUE, the columns are re-organized in
alphabetical order. If FALSE, they are presented in the
original order.</p>
</td></tr>
<tr><td><code id="summarizeNumerics_+3A_probs">probs</code></td>
<td>
<p>Controls calculation of quantiles (see the R
<code>quantile</code> function's <code>probs</code> argument). If FALSE or
NULL, no quantile estimates are provided. Default is
<code>c("min" = 0, "med" = 0.5, "max" = 1.0)</code>, which will
appear in output as <code>c("min", "med", "max")</code>. Other
values between 0 and 1 are allowed. For example, <code>c(0.3, 0.7)</code>
will appear in output as <code>pctile_30%</code> and
<code>pctile_70%</code>.</p>
</td></tr>
<tr><td><code id="summarizeNumerics_+3A_stats">stats</code></td>
<td>
<p>A vector including any of these: <code>c("min",
"med", "max", "mean", "sd", "var", "skewness", "kurtosis",
"nobs", "nmiss")</code>. Default includes all except <code>var</code>.
&quot;nobs&quot; means number of observations with non-missing, finite
scores (not NA, NaN, -Inf, or Inf). &quot;nmiss&quot; is the number of
cases with values of NA. If FALSE or NULL, provide none of
these.</p>
</td></tr>
<tr><td><code id="summarizeNumerics_+3A_na.rm">na.rm</code></td>
<td>
<p>default TRUE. Should missing data be removed to
calculate summaries?</p>
</td></tr>
<tr><td><code id="summarizeNumerics_+3A_unbiased">unbiased</code></td>
<td>
<p>If TRUE (default), skewness and kurtosis are
calculated with biased corrected (N-1) divisor in the standard
deviation.</p>
</td></tr>
<tr><td><code id="summarizeNumerics_+3A_digits">digits</code></td>
<td>
<p>Number of digits reported after decimal
point. Default is 2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with one column per summary element (rows are
the variables).
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p>summarize and summarizeFactors
</p>

<hr>
<h2 id='summary.factor'>Tabulates observed values and calculates entropy</h2><span id='topic+summary.factor'></span>

<h3>Description</h3>

<p>This adapts code from R base summary.factor. It adds
the calculation of entropy as a measure of diversity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
summary(y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.factor_+3A_y">y</code></td>
<td>
<p>a factor (non-numeric variable)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, including the summary table and vector of summary
stats if requested.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='summary.pctable'>Extract presentation from a pctable object</h2><span id='topic+summary.pctable'></span>

<h3>Description</h3>

<p>Creates a column and/or row percent display of a pctable
result
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pctable'
summary(object, ..., colpct = TRUE, rowpct = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.pctable_+3A_object">object</code></td>
<td>
<p>A pctable object</p>
</td></tr>
<tr><td><code id="summary.pctable_+3A_...">...</code></td>
<td>
<p>Other arguments, currently unused</p>
</td></tr>
<tr><td><code id="summary.pctable_+3A_colpct">colpct</code></td>
<td>
<p>Default TRUE: should column percents be included</p>
</td></tr>
<tr><td><code id="summary.pctable_+3A_rowpct">rowpct</code></td>
<td>
<p>Default FALSE: should row percents be included</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class summary.pctable
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>

<hr>
<h2 id='testSlopes'>Hypothesis tests for Simple Slopes Objects</h2><span id='topic+testSlopes'></span>

<h3>Description</h3>

<p>Conducts t-test of the hypothesis that the &quot;simple slope&quot; line for
one predictor is statistically significantly different from zero
for each value of a moderator variable. The user must first run
<code>plotSlopes()</code>, and then give the output object to
<code>plotSlopes()</code>. A plot method has been implemented for
testSlopes objects. It will create an interesting display, but
only when the moderator is a numeric variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testSlopes(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testSlopes_+3A_object">object</code></td>
<td>
<p>Output from the plotSlopes function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function scans the input object to detect the focal values of
the moderator variable (the variable declared as <code>modx</code> in
<code>plotSlopes</code>). Consider a regression with interactions
</p>
<p>y &lt;- b0 + b1*x1 + b2*x2 + b3*(x1*x2) + b4*x3 + ... + error
</p>
<p>If <code>plotSlopes</code> has been run with the argument plotx=&quot;x1&quot; and
the argument modx=&quot;x2&quot;, then there will be several plotted lines,
one for each of the chosen values of x2.  The slope of each of
these lines depends on x1's effect, b1, as well as the interactive
part, b3*x2.
</p>
<p>This function performs a test of the null hypothesis of the slope
of each fitted line in a <code>plotSlopes</code> object is statistically
significant from zero. A simple t-test for each line is offered.
No correction for the conduct of multiple hypothesis tests (no
Bonferroni correction).
</p>
<p>When <code>modx</code> is a numeric variable, it is possible to conduct
further analysis. We ask &quot;for which values of <code>modx</code> would
the effect of <code>plotx</code> be statistically significant?&quot;  This is
called a Johnson-Neyman (Johnson-Neyman, 1936) approach in
Preacher, Curran, and Bauer (2006). The interval is calculated
here.  A plot method is provided to illustrate the result.
</p>


<h3>Value</h3>

<p>A list including 1) the hypothesis test table, 2) a copy of
the plotSlopes object, and, for numeric
modx variables, 3) the Johnson-Neyman (J-N) interval boundaries.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>References</h3>

<p>Preacher, Kristopher J, Curran, Patrick J.,and Bauer, Daniel J. (2006).
Computational Tools for Probing Interactions in Multiple Linear
Regression, Multilevel Modeling, and Latent Curve Analysis.
Journal of Educational and Behavioral Statistics. 31,4, 437-448.
</p>
<p>Johnson, P.O. and Neyman, J. (1936). &quot;Tests of certain linear
hypotheses and their applications to some educational problems.
Statistical Research Memoirs, 1, 57-93.
</p>


<h3>See Also</h3>

<p>plotSlopes
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rockchalk)
library(carData)
m1 &lt;- lm(statusquo ~ income * age + education + sex + age, data = Chile)
m1ps &lt;- plotSlopes(m1, modx = "income", plotx = "age")
m1psts &lt;- testSlopes(m1ps)
plot(m1psts)


dat2 &lt;- genCorrelatedData(N = 400, rho = .1, means = c(50, -20),
                          stde = 300, beta = c(2, 0, 0.1, -0.4))
m2 &lt;- lm(y ~ x1*x2, data = dat2)
m2ps &lt;- plotSlopes(m2, plotx = "x1", modx = "x2")
m2psts &lt;- testSlopes(m2ps)
plot(m2psts)
m2ps &lt;- plotSlopes(m2, plotx = "x1", modx = "x2", modxVals = "std.dev", n = 5)
m2psts &lt;- testSlopes(m2ps)
plot(m2psts)

## Try again with longer variable names

colnames(dat2) &lt;- c("oxygen","hydrogen","species")
m2a &lt;- lm(species ~ oxygen*hydrogen, data = dat2)
m2aps1 &lt;- plotSlopes(m2a, plotx = "oxygen", modx = "hydrogen")
m2aps1ts &lt;- testSlopes(m2aps1)
plot(m2aps1ts)
m2aps2 &lt;- plotSlopes(m2a, plotx = "oxygen", modx = "hydrogen",
                     modxVals = "std.dev", n = 5)
m2bps2ts &lt;- testSlopes(m2aps2)
plot(m2bps2ts)



dat3 &lt;- genCorrelatedData(N = 400, rho = .1, stde = 300,
                          beta = c(2, 0, 0.3, 0.15),
                          means = c(50,0), sds = c(10, 40))
m3 &lt;- lm(y ~ x1*x2, data = dat3)
m3ps &lt;- plotSlopes(m3, plotx = "x1", modx = "x2")
m3sts &lt;- testSlopes(m3ps)
plot(testSlopes(m3ps))
plot(testSlopes(m3ps), shade = FALSE)

## Finally, if model has no relevant interactions, testSlopes does nothing.
m9 &lt;- lm(statusquo ~ age + income * education + sex + age, data = Chile)
m9ps &lt;- plotSlopes(m9, modx = "education", plotx = "age", plotPoints = FALSE)
m9psts &lt;- testSlopes(m9ps)
</code></pre>

<hr>
<h2 id='vech2Corr'>Convert the vech (column of strictly lower trianglar values from a matrix) into a correlation matrix.</h2><span id='topic+vech2Corr'></span>

<h3>Description</h3>

<p>vech2Corr is a convenience function for creating correlation matrices
from a vector of the lower triangular values. It checks the arguments
to make sure they are consistent with the requirements of a
correlation matrix. All values must be in [-1, 1], and the number
of values specified must be correct for a lower triangle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vech2Corr(vech)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vech2Corr_+3A_vech">vech</code></td>
<td>
<p>A vector of values for the strictly lower triangle of
a matrix. All values must be in the [0,1] interval (because
they are correlations) and the matrix formed must be positive
definite.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use this in combination with the <code>lazyCov</code> function to
convert a vector of standard deviations and the correlation matrix
into a covariance matrix.
</p>


<h3>Value</h3>

<p>A symmetric correlation matrix, with 1's on the diagonal.
</p>


<h3>Author(s)</h3>

<p>Paul E. Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>See Also</h3>

<p>Similar functions exist in many packages, see
<code>vec2sm</code> in corpcor, <code>xpnd</code> in MCMCpack
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v &lt;- c(0.1, 0.4, -0.5)
vech2Corr(v)
v &lt;- c(0.1, 0.4, -0.4, 0.4, 0.5, 0.1)
vech2Corr(v)
</code></pre>

<hr>
<h2 id='vech2mat'>Convert a half-vector (vech) into a matrix.</h2><span id='topic+vech2mat'></span>

<h3>Description</h3>

<p>Fills a matrix from a vector that represents the lower triangle.
If user does not supply a value for diag, then the vech will fill
in the diagonal as well as the strictly lower triangle.  If diag
is provided (either a number or a vector), then vech is for the
strictly lower triangular part.  The default value for lowerOnly
is FALSE, which means that a symmetric matrix will be created. See
examples for a demonstration of how to fill in the lower triangle
and leave the diagonal and the upper triangle empty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vech2mat(vech, diag = NULL, lowerOnly = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vech2mat_+3A_vech">vech</code></td>
<td>
<p>A vector</p>
</td></tr>
<tr><td><code id="vech2mat_+3A_diag">diag</code></td>
<td>
<p>Optional. A single value or a vector for the
diagonal. A vech is a strictly lower triangluar vech, it
does not include diagonal values. diag can be either a single
value (to replace all elements along the diagonal) or a vector of
the correct length to replace the diagonal.</p>
</td></tr>
<tr><td><code id="vech2mat_+3A_loweronly">lowerOnly</code></td>
<td>
<p>Default = FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Similar functions exist in many packages, see
<code>vec2sm</code> in corpcor, <code>xpnd</code> in MCMCpack
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:6
vech2mat(x)
vech2mat(x, diag = 7)
vech2mat(x, diag = c(99, 98, 97, 96))
vech2mat(x, diag = 0, lowerOnly = TRUE)
</code></pre>

<hr>
<h2 id='waldt'>T-test for the difference in 2 regression parameters</h2><span id='topic+waldt'></span>

<h3>Description</h3>

<p>This is the one the students call the &quot;fancy t test&quot;. It is just
the simplest, most easy to use version of the t test to decide if
2 coefficients are equal. It is not as general as other functions
in other packages. This is simpler to use for beginners.  The
<code>car</code> package's function <code>linearHypothesis</code> is more
general, but its documentation is much more difficult to understand.
It gives statistically identical results, albeit phrased as an F
test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>waldt(parm1, parm2, model, model.cov = NULL, digits = getOption("digits"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="waldt_+3A_parm1">parm1</code></td>
<td>
<p>A parameter name, in quotes!</p>
</td></tr>
<tr><td><code id="waldt_+3A_parm2">parm2</code></td>
<td>
<p>Another parameter name, in quotes!</p>
</td></tr>
<tr><td><code id="waldt_+3A_model">model</code></td>
<td>
<p>A fitted regression model</p>
</td></tr>
<tr><td><code id="waldt_+3A_model.cov">model.cov</code></td>
<td>
<p>Optional, another covariance matrix to use while
calculating the test. Primarily used for robust (or otherwise
adjusted) standard errors</p>
</td></tr>
<tr><td><code id="waldt_+3A_digits">digits</code></td>
<td>
<p>How many digits to print? This affects only the on-screen
printout. The return object is numeric, full precision.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>I did this because we have trouble understanding terminology in
documentation for more abstract functions in other R
packages.
</p>
<p>It has an additional feature, it can import robust standard errors
to conduct the test.
</p>


<h3>Value</h3>

<p>A vector with the difference, std. err., t-stat, and p
value. Prints a formatted output statement.
</p>


<h3>Author(s)</h3>

<p>Paul Johnson <a href="mailto:pauljohn@ku.edu">pauljohn@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mdat &lt;- data.frame(x1 = rnorm(100), x2 = rnorm(100))
stde &lt;- 2
mdat$y &lt;- 0.2 * mdat$x1 + 0.24 * mdat$x2 + stde * rnorm(100)
m1 &lt;- lm(y ~ x1 + x2, data = mdat)
waldt("x1", "x2", m1)
waldt("x1", "x2", m1, digits = 2)
## Returned object is not "rounded characters". It is still numbers
stillnumeric &lt;-  waldt("x1", "x2", m1, digits = 2)
stillnumeric
## Equivalent to car package linearHypothesis:
if(require(car)){
    linearHypothesis(m1, "x1 = x2")
}
## recall t = sqrt(F) for a 1 degree of freedom test.
## If we could understand instructions for car, we probably
## would not need this function, actually.
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
