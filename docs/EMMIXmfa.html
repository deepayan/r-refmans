<!DOCTYPE html><html lang="en"><head><title>Help for package EMMIXmfa</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EMMIXmfa}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EMMIXmfa-package'>
<p>Mixture Models with Component-Wise Factor Analyzers</p></a></li>
<li><a href='#ari'>
<p>Computes adjusted Rand Index</p></a></li>
<li><a href='#factor_scores'>
<p>Computes Factor Scores</p></a></li>
<li><a href='#gmf'>
<p>General Matrix Factorization</p></a></li>
<li><a href='#mcfa'>
<p>Mixture of Common Factor Analyzers</p></a></li>
<li><a href='#mfa'>
<p>Mixtures of Factor Analyzers</p></a></li>
<li><a href='#minmis'>
<p>Minimum Number of Misallocations</p></a></li>
<li><a href='#plot_factors'>
<p>Plot Function for Factor Scores</p></a></li>
<li><a href='#predict.emmix'>
<p>Extend Clustering to New Observations</p></a></li>
<li><a href='#print.emmix'>
<p>Print Method for Class 'emmix'</p></a></li>
<li><a href='#rmix'>
<p>Random Deviates from EMMIX Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Mixture Models with Component-Wise Factor Analyzers</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.14</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-24</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/suren-rathnayake/EMMIXmfa">https://github.com/suren-rathnayake/EMMIXmfa</a></td>
</tr>
<tr>
<td>Author:</td>
<td>Suren Rathnayake, Geoff McLachlan, David Peel, Jangsun Baek</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Suren Rathnayake &lt;surenr@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>We provide functions to fit finite mixtures of multivariate normal or t-distributions to 
    data with various factor analytic structures adopted for the covariance/scale matrices. The 
    factor analytic structures available include mixtures of factor analyzers and mixtures of common 
    factor analyzers. The latter approach is so termed because the matrix of factor loadings is
    common to components before the component-specific rotation of the component factors to 
    make them white noise. Note that the component-factor loadings are not common after 
    this rotation. Maximum likelihood estimators of model parameters are obtained via the 
    Expectation-Maximization algorithm. See descriptions of the algorithms used in
    McLachlan GJ, Peel D (2000) &lt;<a href="https://doi.org/10.1002%2F0471721182.ch8">doi:10.1002/0471721182.ch8</a>&gt;
    McLachlan GJ, Peel D (2000) &lt;ISBN:1-55860-707-2&gt; 
    McLachlan GJ, Peel D, Bean RW (2003) &lt;<a href="https://doi.org/10.1016%2FS0167-9473%2802%2900183-4">doi:10.1016/S0167-9473(02)00183-4</a>&gt; 
    McLachlan GJ, Bean RW, Ben-Tovim Jones L (2007) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2006.09.015">doi:10.1016/j.csda.2006.09.015</a>&gt; 
    Baek J, McLachlan GJ, Flack LK (2010) &lt;<a href="https://doi.org/10.1109%2FTPAMI.2009.149">doi:10.1109/TPAMI.2009.149</a>&gt; 
    Baek J, McLachlan GJ (2011) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtr112">doi:10.1093/bioinformatics/btr112</a>&gt; 
    McLachlan GJ, Baek J, Rathnayake SI (2011) &lt;<a href="https://doi.org/10.1002%2F9781119995678.ch9">doi:10.1002/9781119995678.ch9</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvtnorm, GGally, ggplot2</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-25 19:55:32 UTC; suren</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-25 20:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='EMMIXmfa-package'>
Mixture Models with Component-Wise Factor Analyzers
</h2><span id='topic+EMMIXmfa-package'></span><span id='topic+emmixmfa-package'></span><span id='topic+EMMIXmfa'></span><span id='topic+emmixmfa'></span>

<h3>Description</h3>

<p>This package provides functions for fitting
mixtures of factor analyzers (MFA) and
mixtures of common factor analyzers (MCFA) models.
</p>
<p>MFA and MCFA models belong to the class of finite mixture models,
that adopt factor models for the component-covariance matrices.
More specifically, under the factor model,
the correlations between feature variables can be explained by the
linear dependance of these variables on a smaller small number
<em>q</em> of (unobservable) latent factors.
The component distributions can be either from the family of
multivariate normals or from the family of multivariate
<em>t</em>-distributions.
Maximum likelihood estimation of the model parameters
is implemented using the Expectation&ndash;Maximization algorithm.
</p>
<p>The joint distribution of the factors and errors can be taken
to be either the multivariate normal or <em>t</em>-distribution.
The factor analytic representation of the component-covariance
matrices is a way of dimension reduction in that it
enables the mixture distributions
to be fitted  to data with dimension <em>p</em>
relatively large compared to the sample size <em>n</em>.
</p>
<p>Unlike MFA, MCFA models can be used to display the
observed data points in the <em>q</em>-dimensional factor space.
The MCFA would also provide a greater reduction in the number of
parameters in the model.
</p>


<h3>Author(s)</h3>

<p>Suren Rathnayake, Geoffrey McLachlan, David Peel, Jangsun Baek
</p>


<h3>References</h3>

<p>Baek J, and McLachlan GJ (2008). Mixtures of factor analyzers with
common factor loadings for the clustering and visualisation of
high-dimensional data. <em>Technical Report NI08018-SCH</em>, Preprint Series
of the Isaac Newton Institute for Mathematical Sciences, Cambridge.
</p>
<p>Baek J, McLachlan GJ, and Flack LK (2010). Mixtures of factor analyzers
with common factor loadings: applications to the clustering and visualisation
of high-dimensional data. <em>IEEE Transactions on Pattern Analysis and
Machine Intelligence</em> <strong>32</strong>, 2089&ndash;2097.
</p>
<p>Baek J, and McLachlan GJ (2011). Mixtures of common <em>t</em>-factor analyzers
for clustering highdimensional microarray data.
<em>Bioinformatics</em> <strong>27</strong>, 1269&ndash;1276.
</p>
<p>McLachlan GJ, Baek J, and Rathnayake SI (2011). Mixtures of factor analyzers
for the analysis of high-dimensional data.
In <em>Mixture Estimation and Applications</em>,
KL Mengersen, CP Robert, and DM Titterington (Eds).
Hoboken, New Jersey: Wiley, pp. 171&ndash;191.
</p>
<p>McLachlan GJ and Peel D (2000). 
<em>Finite Mixture Models</em>. New York: Wiley. 
</p>
<p>McLachlan GJ, and Peel D (2000). Mixtures of factor analyzers. In
<em>Proceedings of the Seventeenth International Conference on Machine Learning</em>,
P. Langley (Ed.). San Francisco: Morgan Kaufmann, pp. 599&ndash;606.
</p>
<p>McLachlan GJ, Bean RW, Ben-Tovim Jones L (2007). Extension of the mixture
of factor analyzers model to incorporate the multivariate <em>t</em>
distribution.
<em>Computational Statistics &amp; Data Analysis</em>, <strong>51</strong>, 5327&ndash;5338.
</p>
<p>McLachlan GJ, Peel D, and Bean RW (2003). Modelling high-dimensional data
by mixtures of factor analyzers.
<em>Computational Statistics &amp; Data Analysis</em> <strong>41</strong>, 379&ndash;388.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
Y &lt;- iris[, -5]
mfa_model &lt;- mfa(Y, g = 3, q = 3)
mtfa_model &lt;- mtfa(Y, g = 3, q = 3)
mcfa_model &lt;- mcfa(Y, g = 3, q = 3)
mctfa_model &lt;- mctfa(Y, g = 3, q = 3)

</code></pre>

<hr>
<h2 id='ari'>
Computes adjusted Rand Index
</h2><span id='topic+ari'></span>

<h3>Description</h3>

<p>Computes adjusted Rand index. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ari(cls, hat_cls)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ari_+3A_cls">cls</code></td>
<td>

<p>A numeric or character vector of labels.
</p>
</td></tr>
<tr><td><code id="ari_+3A_hat_cls">hat_cls</code></td>
<td>

<p>A numeric or character vector of labels same length as <code>cls</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Measures the agreement between two sets of partitions. 
The upper bound of 1 implies perfect agreement. 
The expected value is zero if the partitions are random.
</p>


<h3>Value</h3>

<p>Scaler specifying how closely two partitions agree.    
</p>


<h3>References</h3>

<p>Hubert L, and Arabie P (1985). Comparing Partitions.
<em>Journal of the Classification</em> <strong>2</strong>, 193&ndash;218.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+minmis">minmis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1984)
Y &lt;- scale(iris[, -5])
model &lt;- mfa(Y, g = 3, q = 3, nkmeans = 1, nrandom = 0)
#
ari(model$clust, iris[, 5])
#
minmis(model$clust, iris[, 5])
</code></pre>

<hr>
<h2 id='factor_scores'>
Computes Factor Scores
</h2><span id='topic+factor_scores'></span><span id='topic+factor_scores.mcfa'></span><span id='topic+factor_scores.mctfa'></span><span id='topic+plot.emmix'></span>

<h3>Description</h3>

<p>This function computes factor scores for observations. 
Using factor scores,
we can represent the original data point <code class="reqn">y_j</code> in a 
<em>q</em>-dimensional reduced space. This is only meaningful
in the case of <code>mcfa</code> or <code>mctfa</code> models,
as the factor cores for <code>mfa</code> and <code>mtfa</code> are
white noise.
</p>
<p>The (estimated conditional expectation of) unobservable factors
<code class="reqn">U_{ij}</code> given <code class="reqn">y_j</code> and the component membership
can be expressed by,
</p>
<p style="text-align: center;"><code class="reqn">
\hat{u}_{ij} = E_{\hat{\Psi}}\{U_{ij} \mid y_j, z_{ij} = 1\}.
</code>
</p>

<p>The estimated mean <code class="reqn">U_{ij}</code> (over the
component membership of <code class="reqn">y_j</code>)
is give as
</p>
<p style="text-align: center;"><code class="reqn">
\hat{u}_{j} = \sum_{i=1}^g \tau_i(y_j; \hat{\Psi}) \hat{u}_{ij},
</code>
</p>

<p>where <code class="reqn">\tau_i(y_j; \hat{\Psi})</code>
estimated posterior probability of <code class="reqn">y_j</code>
belonging to the <code class="reqn">i</code>th component.
</p>
<p>An alternative estimate of <code class="reqn">u_j</code>, the posterior expectation
of the factor corresponding to the <em>j</em>th observation <code class="reqn">y_j</code>, is
defined by replacing <code class="reqn">\tau_i(y_j;\,\hat{\Psi})</code> by <code class="reqn">\hat{z}_{ij}</code>,
where
<code class="reqn">\hat{z}_{ij} = 1</code>, if <code class="reqn">\hat{\tau}_i(y_j; \hat{\Psi})</code>
&gt;= <code class="reqn">\hat{\tau_h}(y_j; \hat{\Psi})
(h=1,\,\dots,\,g; h \neq i)</code>, else
<code class="reqn">\hat{z}_{ij} = 0</code>.
</p>
<p style="text-align: center;"><code class="reqn">
\hat{u}_{j}^C = \sum_{i=1}^g \hat{z}_{ij} \hat{u}_{ij}.
</code>
</p>

<p>For MFA, we have
</p>
<p style="text-align: center;"><code class="reqn">
\hat{u}_{ij} = \hat{\beta}_i^T (y_j - \hat{\mu}_i),
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
\hat{u}_{j} = \sum_{i=1}^g \tau_i(y_j;  \hat{\Psi}) \hat{\beta}_i^T
  (y_j - \hat{\mu}_i)
</code>
</p>

<p>for <code class="reqn">j = 1, \dots, n</code> where
<code class="reqn">\hat{\beta}_i = (B_iB_i^T + D_i)^{-1} B_i</code>.
</p>
<p>For MCFA,
</p>
<p style="text-align: center;"><code class="reqn">
\hat{u}_{ij} = \hat{\xi}_i + \hat{\gamma}_i^T (y_j -\hat{A}\hat{\xi}_i),
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\hat{u}_{j} = \sum_{i=1}^g\tau_i(y_j; \hat{\Psi})
\{\hat{\xi}_i + \hat{\gamma}_i^T(y_j -\hat{A}\hat{\xi}_i)\},
</code>
</p>

<p>where <code class="reqn">\gamma_i =  (A \Omega_i A + D)^{-1} A \Omega_i</code>.
</p>
<p>With M<em>t</em>FA and MC<em>t</em>FA, the distribution of
<code class="reqn">\hat{u}_{ij}</code> and of <code class="reqn">\hat{u}_{j}</code>
have the same form as those of MFA and MCFA, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factor_scores(model, Y, ...)
## S3 method for class 'mcfa'
factor_scores(model, Y, tau = NULL, clust= NULL, ...)
## S3 method for class 'mctfa'
factor_scores(model, Y, tau = NULL, clust= NULL, ...)
## S3 method for class 'emmix'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="factor_scores_+3A_model">model</code></td>
<td>

<p>An object of class <code>mfa, mcfa, mtfa</code> or <code>mctfa</code>.
</p>
</td></tr>
<tr><td><code id="factor_scores_+3A_x">x</code></td>
<td>

<p>An object of class <code>mfa, mcfa, mtfa</code> or <code>mctfa</code>.
</p>
</td></tr>
<tr><td><code id="factor_scores_+3A_y">Y</code></td>
<td>

<p>Data matrix with variables in columns in the same order as used in
model estimation.
</p>
</td></tr>
<tr><td><code id="factor_scores_+3A_tau">tau</code></td>
<td>

<p>Optional. Posterior probabilities of belonging to the components
in the mixture model. If not provided, they will be computed based on 
the <code>model</code> parameters.
</p>
</td></tr>
<tr><td><code id="factor_scores_+3A_clust">clust</code></td>
<td>

<p>Optional. Indicators of belonging to the components.
If not provided, will be estimated using <code>tau</code>.
</p>
</td></tr>
<tr><td><code id="factor_scores_+3A_...">...</code></td>
<td>

<p>Not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Factor scores can be used in visualization of the data
in the factor space.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Uscores</code></td>
<td>

<p>Estimated conditional expected component scores of the
unobservable factors given the data and the component membership
(<code class="reqn">\hat{u}_{ij}</code>).
Size is <code class="reqn">n \times q \times g</code>, where <code>n</code> is the number of sample,
<code>q</code> is the number of factors and <code>g</code> is the number components.
</p>
</td></tr>
<tr><td><code>Umean</code></td>
<td>

<p>Means of the estimated conditional expected factors scores over
estimated posterior distributions (<code class="reqn">\hat{u}_{j}</code>).
Size <code class="reqn">n \times q</code>.
</p>
</td></tr>
<tr><td><code>Uclust</code></td>
<td>

<p>Alternative estimate of <code>Umean</code> where the posterior probabilities
for each sample are replaced by component indicator vectors
which contain one in the element corresponding to the highest posterior
probability while others zero (<code class="reqn">\hat{u}_{j}^C</code>).  Size <code class="reqn">n \times q</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Geoff McLachlan, Suren Rathnayake, Jungsun Baek
</p>


<h3>References</h3>

<p>McLachlan GJ, Baek J, and Rathnayake SI (2011). Mixtures of factor analyzers
for the analysis of high-dimensional data.
In <em>Mixture Estimation and Applications</em>,
KL Mengersen, CP Robert, and DM Titterington (Eds).
Hoboken, New Jersey: Wiley, pp. 171&ndash;191.
</p>
<p>McLachlan GJ, and Peel D (2000). <em>Finite Mixture Models</em>.
New York: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a MCFA model to a subset
set.seed(1)
samp_size &lt;- dim(iris)[1]
sel_subset &lt;- sample(1 : samp_size, 50)
model &lt;- mcfa(iris[sel_subset, -5], g = 3, q = 2, 
                          nkmeans = 1, nrandom = 0, itmax = 100)

# plot the data points in the factor space
plot(model)

# Allocating new samples to the clusters
Y &lt;- iris[-c(sel_subset), -5]
Y &lt;- as.matrix(Y)
clust &lt;- predict(model, Y)

fa_scores &lt;- factor_scores(model, Y)
# Visualizing new data in factor space
plot_factors(fa_scores, type = "Umean", clust = clust)
</code></pre>

<hr>
<h2 id='gmf'>
General Matrix Factorization
</h2><span id='topic+gmf'></span>

<h3>Description</h3>

<p>Performs a matrix factorization on the given data set.
The factorization is done using a stochastic gradient decent method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmf(Y, q, maxit = 1000, lambda = 0.01, cor_rate = 0.9)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gmf_+3A_y">Y</code></td>
<td>

<p>data matrix containing all numerical values.
</p>
</td></tr>
<tr><td><code id="gmf_+3A_maxit">maxit</code></td>
<td>

<p>maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="gmf_+3A_q">q</code></td>
<td>

<p>number of factors.
</p>
</td></tr>
<tr><td><code id="gmf_+3A_lambda">lambda</code></td>
<td>

<p>initial learning rate.
</p>
</td></tr>
<tr><td><code id="gmf_+3A_cor_rate">cor_rate</code></td>
<td>

<p>correction rate.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unsupervised matrix factorization of a <code class="reqn">n \times p</code> data matrix
<code class="reqn">Y</code> can be expressed as,
</p>
<p style="text-align: center;"><code class="reqn">
 Y^{\top} \approx A B^{\top},
</code>
</p>

<p>where <code class="reqn">A</code> is a <code class="reqn">p \times q</code> matrix and <code class="reqn">B</code> is
<code class="reqn">n \times q</code> matrix.
With this matrix factorization method, one replaces 
the <code class="reqn">i</code>th row in matrix <code class="reqn">Y</code> by the <code class="reqn">i</code>th row in matrix <code class="reqn">B</code>.
The matrices <code class="reqn">A</code> and <code class="reqn">B</code> are chosen to minimize an objective
function <code class="reqn">f(Y, A, B)</code> with under constraints specific 
to the matrix factorization method.
</p>
<p>It is imperative that columns of the data matrix be on the same scale.
Otherwise, it may not be possible to obtain a factorization
of the data using this approach.
</p>


<h3>Value</h3>

<p>A list containing,
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p>A numeric matrix of size <code class="reqn">p \times q</code></p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>A numeric matrix of size <code class="reqn">n \times q</code> matrix</p>
</td></tr>
</table>


<h3>References</h3>

<p>Nikulin V, Huang T-H, Ng SK, Rathnayake SI, &amp; McLachlan GJ (2011).
A very fast algorithm for matrix factorization.
<em>Statistics &amp; Probability Letters</em> <strong>81</strong>, 773&ndash;782.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lst &lt;- gmf(iris[, -5], q = 2, maxit = 100)
</code></pre>

<hr>
<h2 id='mcfa'>
Mixture of Common Factor Analyzers
</h2><span id='topic+mcfa'></span><span id='topic+mcfa.default'></span><span id='topic+mctfa'></span><span id='topic+mctfa.default'></span>

<h3>Description</h3>

<p>Functions for fitting mixtures of common factor analyzers (MCFA)
models.
MCFA models are mixture of factor analyzers
(belong to the class of multivariate finite mixture models)
with a common component matrix for the
factor loadings before the transformation of the latent factors to be
white noise. It is designed specifically for the task of displaying the
observed data points in a  lower (<em>q</em>-dimensional) space,
where <em>q</em> is the number of factors adopted in the
factor-analytic representation of the observed vector.
</p>
<p>The <code>mcfa</code> function fits mixtures common factor analyzers
where the  components distributions belong to the family of
multivariate normal distributions.
The <code>mctfa</code> function fits
mixtures of common <em>t</em>-factor analyzers where
the component distributions corresponds to multivariate
<em>t</em> distributions.
Maximum likelihood estimates of the model parameters are obtained
using the Expectation&ndash;Maximization algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcfa(Y, g, q, itmax = 500, nkmeans = 5, nrandom = 20,
  tol = 1.e-5, init_clust = NULL, init_para = NULL,
  init_method = NULL, conv_measure = 'diff',
  warn_messages = TRUE, ...)
mctfa(Y, g, q, itmax = 500, nkmeans = 5, nrandom = 20,
  tol = 1.e-5, df_init = rep(30, g), df_update = TRUE,
  init_clust = NULL, init_para = NULL, init_method = NULL,
  conv_measure = 'diff', warn_messages = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcfa_+3A_y">Y</code></td>
<td>

<p>A matrix or a data frame of which rows correspond to
observations and columns to variables.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_g">g</code></td>
<td>

<p>Number of components.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_itmax">itmax</code></td>
<td>

<p>Maximum number of EM iterations.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_nkmeans">nkmeans</code></td>
<td>

<p>The number of times the k-means algorithm to be used in partition
the data into <code>g</code> groups. These groupings are then used in
initializing the parameters for the EM algorithm.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_nrandom">nrandom</code></td>
<td>

<p>The number of random <code>g</code>-group partitions for the data to be used
initializing the EM algorithm.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_tol">tol</code></td>
<td>

<p>The EM algorithm terminates if the measure of convergence falls below
this value.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_init_clust">init_clust</code></td>
<td>

<p>A vector or matrix consisting of partition of samples to be used
in the EM algorithm. For matrix of partitions, columns must corresponds
individual partitions of the data. Optional.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_init_para">init_para</code></td>
<td>

<p>A list containing model parameters to be used as initial
parameter estimates for the EM algorithm. Optional.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_init_method">init_method</code></td>
<td>

<p>To determine how the initial parameter values are computed. See Details.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_conv_measure">conv_measure</code></td>
<td>

<p>The default <code>'diff'</code> stops the EM iterations if
|<code class="reqn">l^{(k+1)}</code> - <code class="reqn">l^{(k)}</code>| &lt; <code>tol</code> where
<code class="reqn">l^{(k)}</code> is the log-likelihood at the <code class="reqn">k</code>th EM iteration.
If <code>'ratio'</code>, then the convergence of the EM steps is measured
using the |(<code class="reqn">l^{(k+1)}</code> - <code class="reqn">l^{(k)}</code>)/<code class="reqn">l^{(k+1)}</code>|.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_df_init">df_init</code></td>
<td>

<p>Initial values of the degree of freedom parameters for <code>mctfa</code>.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_df_update">df_update</code></td>
<td>

<p>If <code>df_update = TRUE</code> (default), then the degree of freedom parameters
values will be updated during the EM iterations.
Otherwise, if <code>df_update = FALSE</code>, they will be fixed at the initial
values specified in <code>df_init</code>.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_warn_messages">warn_messages</code></td>
<td>

<p>With <code>warn_messages = TRUE</code> (default), the output would
include some description of the reasons where, if any, the model fitting
function failed to provide a fit for a given set of initial
parameter values.
</p>
</td></tr>
<tr><td><code id="mcfa_+3A_...">...</code></td>
<td>

<p>Not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With <code>init_method = NULL</code>, the default,
model parameters are initialized using all available methods.
With the <code>init_method = "rand-A"</code>, the initialization of
the parameters is done using the procedure in
Baek et al. (2010) where initial values for elements of
<code class="reqn">A</code> are drawn from the <code class="reqn">N(0, 1)</code> distribution.
This method is appropriate when the columns of the data
are on the same scale. The
<code>init_method = "eigen-A"</code>
takes the first <code class="reqn">q</code> eigenvectors of <code class="reqn">Y</code> as the
initial value for the loading matrix <code class="reqn">A</code>. 
If <code>init_method = "gmf"</code> then the data are factorized using
<code>gmf</code> with <code class="reqn">q</code> factors and the resulting loading
matrix is used as the initial value for <code class="reqn">A</code>.
</p>
<p>If specified, the optional argument <code>init_para</code>
must be a list or an object of class <code>mcfa</code> or <code>mctfa</code>.
When fitting an <code>mcfa</code> model, only the
model parameters <code>q</code>, <code>g</code>,
<code>pivec</code>, <code>A</code>, <code>xi</code>,
<code>omega</code>, and <code>D</code> are extracted from
<code>init_para</code>, while one extra parameter
<code>nu</code> is extracted when fitting <code>mctfa</code>.
Everything else in <code>init_para</code> will be discarded.
</p>


<h3>Value</h3>

<p>Object of class <code>c("emmix", "mcfa")</code> or <code>c("emmix",
"mctfa")</code> containing the fitted model parameters is returned.
Details of the components are as follows:
</p>
<table role = "presentation">
<tr><td><code>g</code></td>
<td>

<p>Number of mixture components.
</p>
</td></tr>
<tr><td><code>q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code>pivec</code></td>
<td>

<p>Mixing proportions of the components.
</p>
</td></tr>
<tr><td><code>A</code></td>
<td>

<p>Loading matrix. Size <code class="reqn">p \times q</code>.
</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>

<p>Matrix containing factor means for components in columns.
Size <code class="reqn">q \times g</code>.
</p>
</td></tr>
<tr><td><code>omega</code></td>
<td>

<p>Array containing factor covariance matrices for components.
Size <code class="reqn">q \times q \times g</code>.
</p>
</td></tr>
<tr><td><code>D</code></td>
<td>

<p>Error covariance matrix. Size <code class="reqn">p \times p.</code>
</p>
</td></tr>
<tr><td><code>Uscores</code></td>
<td>

<p>Estimated conditional expected component scores of the
unobservable factors given the data and the component membership.
Size <code class="reqn">n \times q \times g</code>.
</p>
</td></tr>
<tr><td><code>Umean</code></td>
<td>

<p>Means of the estimated conditional expected factors scores over
estimated posterior distributions. Size <code class="reqn">n \times q</code>.
</p>
</td></tr>
<tr><td><code>Uclust</code></td>
<td>

<p>Alternative estimate of <code>Umean</code> where the posterior probabilities
for each sample are replaced by component indicator vectors
which contain one in the element corresponding to the highest posterior
probability while others zero.  Size <code class="reqn">n \times q</code>.
</p>
</td></tr>
<tr><td><code>clust</code></td>
<td>
<p>Cluster labels.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Posterior probabilities.
</p>
</td></tr>
<tr><td><code>logL</code></td>
<td>
<p>Log-likelihood at the convergence.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Bayesian information criterion.
</p>
</td></tr>
<tr><td><code>warn_msg</code></td>
<td>
<p>Description of error messages, if any.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suren Rathnayake, Jangsun Baek, Geoff McLachlan
</p>


<h3>References</h3>

<p>Baek J, McLachlan GJ, and Flack LK (2010). Mixtures of factor analyzers
with common factor loadings: applications to the clustering and visualisation
of high-dimensional data. <em>IEEE Transactions on Pattern Analysis and
Machine Intelligence</em> <strong>32</strong>, 2089&ndash;2097.
</p>
<p>Baek J, and McLachlan GJ (2011). Mixtures of common <em>t</em>-factor analyzers
for clustering highdimensional microarray data.
<em>Bioinformatics</em> <strong>27</strong>, 1269&ndash;1276.
</p>
<p>McLachlan GJ, Baek J, and Rathnayake SI (2011). Mixtures of factor analyzers
for the analysis of high-dimensional data.
In <em>Mixture Estimation and Applications</em>,
KL Mengersen, CP Robert, and DM Titterington (Eds).
Hoboken, New Jersey: Wiley, pp. 171&ndash;191.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mfa">mfa</a></code>, <code><a href="#topic+plot_factors">plot_factors</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mcfa_fit &lt;- mcfa(iris[, -5], g = 3, q = 3, itmax = 25,
                  nkmeans = 5, nrandom = 5, tol = 1.e-5)

plot(mcfa_fit)

mctfa_fit &lt;- mcfa(iris[, -5], g = 3, q = 3, itmax = 500,
                  nkmeans = 5, nrandom = 5, tol = 1.e-5, df_update = TRUE)

</code></pre>

<hr>
<h2 id='mfa'>
Mixtures of Factor Analyzers
</h2><span id='topic+mfa'></span><span id='topic+mfa.default'></span><span id='topic+plot.mfa'></span><span id='topic+mtfa'></span><span id='topic+mtfa.default'></span><span id='topic+plot.mtfa'></span>

<h3>Description</h3>

<p>Functions for fitting mixtures of factor analyzers (MFA) and
mixtures of <em>t</em>-factor analyzers (M<em>t</em>FA) to data.
Maximum Likelihood estimates of the model parameters are obtained
using the Alternating Expectation Conditional Maximization (AECM)
algorithm.
</p>
<p>In the case of MFA, component distributions belong to the family of
multivariate normal distributions, while with M<code class="reqn">t</code>FA
the component distributions correspond to multivariate
<em>t</em> distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mfa(Y, g, q, itmax = 500, nkmeans = 20, nrandom = 20,
  tol = 1.e-5, sigma_type = 'common', D_type = 'common', init_clust = NULL,
  init_para = NULL, conv_measure = 'diff', warn_messages = TRUE, ...)
mtfa(Y, g, q, itmax = 500, nkmeans = 20, nrandom = 20,
  tol = 1.e-5, df_init = rep(30, g), df_update = TRUE,
  sigma_type = 'common', D_type = 'common', init_clust = NULL,
  init_para = NULL, conv_measure = 'diff', warn_messages = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mfa_+3A_y">Y</code></td>
<td>

<p>A matrix or a data frame of which rows correspond to
observations and columns to variables.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_g">g</code></td>
<td>

<p>Number of components.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_itmax">itmax</code></td>
<td>

<p>Maximum number of EM iterations.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_nkmeans">nkmeans</code></td>
<td>

<p>The number of times the k-means algorithm to be used in partition
the data into <code>g</code> groups. These groupings are then used in
initializing the parameters for the EM algorithm.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_nrandom">nrandom</code></td>
<td>

<p>The number of random <code>g</code>-group partitions for the data to be used
initializing the EM algorithm.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_tol">tol</code></td>
<td>

<p>The EM algorithm terminates if the measure of convergence falls below
this value.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_sigma_type">sigma_type</code></td>
<td>

<p>To specify whether the covariance matrices (for <code>mfa</code>)
or the scale matrices (for <code>mtfa</code>) of the components
are constrained 
to be the same (default, <code>sigma_type = "common"</code>)
or not (<code>sigma_type = "unique"</code>).
</p>
</td></tr>
<tr><td><code id="mfa_+3A_d_type">D_type</code></td>
<td>

<p>To specify whether the diagonal error covariance matrix is common to all
the components or not. If <code>sigma_type = "unique"</code>, then
<code>D_type</code> could either be <code>"common"</code>
(the default) to each component, or <code>"unique"</code>.
If the <code>sigma_type = "common"</code>, then
<code>D_type</code> must also be <code> "common"</code>.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_init_clust">init_clust</code></td>
<td>

<p>A vector or matrix consisting of partition of samples to be used
in the EM algorithm. For matrix of partitions, columns must corresponds
individual partitions of the data. Optional.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_init_para">init_para</code></td>
<td>

<p>A list containing model parameters to be used as initial
parameter estimates for the EM algorithm. Optional.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_conv_measure">conv_measure</code></td>
<td>

<p>The default <code>'diff'</code> stops the EM iterations if
|<code class="reqn">l^{(k+1)}</code> - <code class="reqn">l^{(k)}</code>| &lt; <code>tol</code> where
<code class="reqn">l^{(k)}</code> is the log-likelihood at the <code class="reqn">k</code>th EM iteration.
If <code>'ratio'</code>, then the convergence of the EM steps is measured
using the |(<code class="reqn">l^{(k+1)}</code> - <code class="reqn">l^{(k)}</code>)/<code class="reqn">l^{(k+1)}</code>|.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_df_init">df_init</code></td>
<td>

<p>Initial values of the degree of freedom parameters for <code>mtfa</code>.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_df_update">df_update</code></td>
<td>

<p>If <code>df_update = TRUE</code> (default), then the degree of freedom parameters
values will be updated during the EM iterations.
Otherwise, if <code>df_update = FALSE</code>, they will be fixed at the initial
values specified in <code>df_init</code>.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_warn_messages">warn_messages</code></td>
<td>

<p>With <code>warn_messages = TRUE</code> (default), the output would
include some description of the reasons where, if any, the model fitting
function failed to provide a fit for a given set of initial
parameter values.
</p>
</td></tr>
<tr><td><code id="mfa_+3A_...">...</code></td>
<td>

<p>Not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cluster a given data set using mixtures of factor analyzers or
approach or using mixtures of <em>t</em>-factor analyzers.
</p>


<h3>Value</h3>

<p>Object of class <code>c("emmix", "mfa")</code> or <code>c("emmix",
"mtfa")</code> containing the fitted model parameters is returned.
Details of the components are as fellows:
</p>
<table role = "presentation">
<tr><td><code>g</code></td>
<td>

<p>Number of mixture components.
</p>
</td></tr>
<tr><td><code>q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code>pivec</code></td>
<td>

<p>Mixing proportions of the components.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>Matrix containing estimates of component means (in columns) 
of mixture component. Size <code class="reqn">p \times g</code>.
</p>
</td></tr>
<tr><td><code>B</code></td>
<td>

<p>Array containing component dependent loading matrices. Size
<code class="reqn">p \times q \times g</code>.
</p>
</td></tr>
<tr><td><code>D</code></td>
<td>

<p>Estimates of error covariance matrices. If <code>D_type = "common"</code>
was used then <code>D</code> is <code class="reqn">p \times p</code> matrix common to
all components,  if <code>D_type = "unique"</code>, then <code>D</code> is a
size <code class="reqn">p \times p \times g</code> array.
</p>
</td></tr>
<tr><td><code>v</code></td>
<td>

<p>Degrees of freedom for each component.
</p>
</td></tr>
<tr><td><code>logL</code></td>
<td>

<p>Log-likelihood at the convergence.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>Bayesian information criterion.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>Matrix of posterior probabilities for the data
used based on the fitted values. Matrix of size <code>n by g</code>.
</p>
</td></tr>
<tr><td><code>clust</code></td>
<td>

<p>Vector of integers 1 to g indicating cluster allocations
of the observations.
</p>
</td></tr>
<tr><td><code>Uscores</code></td>
<td>

<p>Estimated conditional expected component scores of the
unobservable factors given the data and the component membership.
Size is Size <code class="reqn">n \times q \times g</code>.
</p>
</td></tr>
<tr><td><code>Umean</code></td>
<td>

<p>Means of the estimated conditional expected factors scores over
estimated posterior distributions. Size <code class="reqn">n \times q</code>.
</p>
</td></tr>
<tr><td><code>Uclust</code></td>
<td>

<p>Alternative estimate of <code>Umean</code> where the posterior probabilities
for each sample are replaced by component indicator vectors
which contain one in the element corresponding to the highest posterior
probability while others zero.  Size <code class="reqn">n \times q</code>.
</p>
</td></tr>
<tr><td><code>ERRMSG</code></td>
<td>

<p>Description of messages, if any.
</p>
</td></tr>
<tr><td><code>D_type</code></td>
<td>

<p>Whether common or unique error covariance is used, as specified in
model fitting.
</p>
</td></tr>
<tr><td><code>df_update</code></td>
<td>

<p>Whether the degree of freedom parameter 
(<code>v</code>) was fixed or estimated (only for <code>mtfa</code>).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suren Rathnayake, Geoffrey McLachlan
</p>


<h3>References</h3>

<p>Ghahramani Z, and Hinton GE (1997). 
The EM algorithm for mixture of factor analyzers.
<em>Technical Report, CRG-TR-96-1</em>, University of Toronto, Toronto.
</p>
<p>McLachlan GJ, Bean RW, Ben-Tovim Jones L (2007). 
Extension of the mixture of factor analyzers model to incorporate the 
multivariate <em>t</em> distribution.
<em>Computational Statistics &amp; Data Analysis</em>, <strong>51</strong>, 5327&ndash;5338.
</p>
<p>McLachlan GJ, Baek J, and Rathnayake SI (2011). Mixtures of factor analyzers
for the analysis of high-dimensional data.
In <em>Mixture Estimation and Applications</em>,
KL Mengersen, CP Robert, and DM Titterington (Eds).
Hoboken, New Jersey: Wiley, pp. 171&ndash;191.
</p>
<p>McLachlan GJ, Peel D, and Bean RW (2003). 
Modelling high-dimensional data by mixtures of factor analyzers.
<em>Computational Statistics &amp; Data Analysis</em> <strong>41</strong>, 379&ndash;388.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcfa">mcfa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- mfa(iris[, -5], g=3, q=2, itmax=200, nkmeans=1, nrandom=5)
summary(model)

model &lt;- mtfa(iris[, -5], g=3, q=2, itmax=200, nkmeans=1, nrandom=5)
  
</code></pre>

<hr>
<h2 id='minmis'>
Minimum Number of Misallocations
</h2><span id='topic+minmis'></span>

<h3>Description</h3>

<p>Given two vectors each corresponding to a set of categories,
this function finds the minimum number of misallocations
by rotating the categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minmis(cls, hat_cls)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="minmis_+3A_cls">cls</code></td>
<td>

<p>A numeric or character vector of labels.
</p>
</td></tr>
<tr><td><code id="minmis_+3A_hat_cls">hat_cls</code></td>
<td>

<p>A numeric or character vector of labels same length as <code>cls</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rotates the categories for all possible permutations, and
returns the minimum number of misallocations.
The number of categories in each set of labels does not need to
be the same.
It may take several minutes to compute when the number of categories
is large.
</p>


<h3>Value</h3>

<p>Integer specifying the minimum number of misallocations.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ari">ari</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1984)
Y &lt;- scale(iris[, -5])
model &lt;- mcfa(Y, g = 3, q = 3, nkmeans = 1, nrandom = 0, itmax = 200)
ari(model$clust, iris[, 5])
minmis(model$clust, iris[, 5])
</code></pre>

<hr>
<h2 id='plot_factors'>
Plot Function for Factor Scores
</h2><span id='topic+plot_factors'></span>

<h3>Description</h3>

<p>Plot functions for factor scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_factors(scores, type = "Umean",
    clust=if (exists('clust', where = scores)) scores$clust else NULL,
    limx = NULL, limy = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_factors_+3A_scores">scores</code></td>
<td>

<p>A list containing factor scores specified by
<code>Umean</code>, <code>Uclust</code> or <code>Uscores</code>, or a
model of class <code>mcfa, mctfa, mfa</code>, or <code>mtfa</code>.
</p>
</td></tr>
<tr><td><code id="plot_factors_+3A_type">type</code></td>
<td>

<p>What type of factor scores are to be plotted. See Details.
</p>
</td></tr>
<tr><td><code id="plot_factors_+3A_clust">clust</code></td>
<td>

<p>Indicators of belonging to components. If available, they will be
portrayed in plots.
If not provided, looks for <code>clust</code> in <code>scores</code>,
and sets to <code>NULL</code> if still not available.
</p>
</td></tr>
<tr><td><code id="plot_factors_+3A_limx">limx</code></td>
<td>

<p>Numeric vector. Values in <code>limx</code> will only be used in setting
the x-axis range for 1-D and 2-D plots.
</p>
</td></tr>
<tr><td><code id="plot_factors_+3A_limy">limy</code></td>
<td>

<p>Numeric vector. Values in <code>limy</code> will only be used in setting
the y-axis range for 1-D and 2-D plots.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the factor scores were obtained using <code>mcfa</code>
or <code>mctfa</code>, then a visualization of the group structure 
can be obtained by plotting the factor scores.
In the case of <code>mfa</code> and <code>mtfa</code>, the factor scores
simply corresponds to white noise.
</p>
<p>The <code>type</code> should either be <code>"Uscores"</code>, <code>"Uclust"</code> or
the default <code>"Umean"</code>. See <code>factor_scores</code> for a detailed
description of the factor scores.
</p>


<h3>Author(s)</h3>

<p>Geoffrey McLachlan, Suren Rathnayake, Jungsun Baek
</p>


<h3>References</h3>

<p>McLachlan GJ, Baek J, and Rathnayake SI (2011). 
Mixtures of factor analyzers
for the analysis of high-dimensional data.
In <em>Mixture Estimation and Applications</em>,
KL Mengersen, CP Robert, and DM Titterington (Eds).
Hoboken, New Jersey: Wiley, pp. 171&ndash;191.
</p>
<p>McLachlan GJ, and Peel D (2000).
<em>Finite Mixture Models</em>. New York: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Visualizing data used in model estimation
set.seed(1)
inds &lt;- dim(iris)[1]
indSample &lt;- sample(1 : inds, 50)
model &lt;- mcfa (iris[indSample, -5], g = 3, q = 2, 
                nkmeans = 1, nrandom = 0, itmax = 150)
minmis(model$clust, iris[indSample, 5])

#same as plot_factors(model, tyep = "Umean", clust = model$clust)
plot(model)

#can provide alternative groupings of samples via plot_factors
plot_factors(model, clust = iris[indSample, 5])

#same as plot_factors(model, tyep = "Uclust")
plot(model, type = "Uclust")

Y &lt;- iris[-c(indSample), -5]
Y &lt;- as.matrix(Y)
clust &lt;- predict(model, Y)
minmis(clust, iris[-c(indSample), 5])

fac_scores &lt;- factor_scores(model, Y)
plot_factors(fac_scores, type = "Umean", clust = clust)
plot_factors(fac_scores, type = "Umean", clust = iris[-c(indSample), 5])
</code></pre>

<hr>
<h2 id='predict.emmix'>
Extend Clustering to New Observations
</h2><span id='topic+predict.emmix'></span><span id='topic+predict.mfa'></span><span id='topic+predict.mcfa'></span><span id='topic+predict.mtfa'></span><span id='topic+predict.mctfa'></span>

<h3>Description</h3>

<p>Given a fitted model of class
<code>'emmix'</code> (or of class
<code>'mfa'</code>, <code>'mcfa'</code>, <code>'mtfa'</code> and
<code>'mctfa'</code>), the <code>predict</code> function
predict clusters for observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmix'
predict(object, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.emmix_+3A_object">object</code></td>
<td>

<p>An object of class <code>'emmix'</code>.
</p>
</td></tr>
<tr><td><code id="predict.emmix_+3A_y">Y</code></td>
<td>

<p>A data matrix with variable in the same
column locations as the data used in
fitting the model <code>object</code>.
</p>
</td></tr>
<tr><td><code id="predict.emmix_+3A_...">...</code></td>
<td>

<p>Not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A vector integers of length equal to number of
observations (rows) in the data. The integers range from 1 to
<code class="reqn">g</code> where <code class="reqn">g</code> in the number of components
in the model.
</p>
<p>The variables in <code>Y</code> of the <code>predict</code> 
function should be in the order as those used in
obtaining the fitted model <code>object</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(42)
test &lt;- sample(1 : nrow(iris), 100)
model &lt;- mfa(iris[test, -5], g=3, q=3, itmax=500, nkmeans=3, nrandom=5)
pred_clust &lt;- predict(model, iris[-test, -5])
minmis(pred_clust, iris[-test, 5])

</code></pre>

<hr>
<h2 id='print.emmix'>
Print Method for Class 'emmix'
</h2><span id='topic+print.emmix'></span><span id='topic+summary.emmix'></span><span id='topic+print.mfa'></span><span id='topic+print.mcfa'></span><span id='topic+print.mtfa'></span><span id='topic+print.mctfa'></span>

<h3>Description</h3>

<p>Prints a formatted model parameters of
<code>EMMIXmfa</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmix'
print(x, ...)
## S3 method for class 'emmix'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.emmix_+3A_x">x</code>, <code id="print.emmix_+3A_object">object</code></td>
<td>

<p>An object of class <code>'emmix'</code>.
</p>
</td></tr>
<tr><td><code id="print.emmix_+3A_...">...</code></td>
<td>

<p>Not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the formatted model parameter values to
the screen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1984)
Y &lt;- scale(iris[, -5])
model &lt;- mcfa(Y, g = 3, q = 3, nkmeans = 1, nrandom = 0, itmax = 100)
#
print(model)
summary(model)

</code></pre>

<hr>
<h2 id='rmix'>
Random Deviates from EMMIX Models
</h2><span id='topic+rmix'></span>

<h3>Description</h3>

<p>Random number generator for <code>emmix</code> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmix(n, model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmix_+3A_model">model</code></td>
<td>

<p>An object of class <code>'emmix'</code> containing a mode of
<code>mfa, mcfa, mtfa</code>, or <code>mctfa</code>.
</p>
</td></tr>
<tr><td><code id="rmix_+3A_n">n</code></td>
<td>

<p>Number of sample to generate.
</p>
</td></tr>
<tr><td><code id="rmix_+3A_...">...</code></td>
<td>

<p>Not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>rmvnorm</code> and
<code>rmvt</code> functions from the
<span class="pkg">mvtnorm</span> package to generate samples
from the mixture components.
</p>
<p>Algorithm works by first drawing a component based on
the mixture proprotion in the model, and then drawing
a sample from the component distribution.
</p>


<h3>Value</h3>

<p>A numeric matrix with samples drawn in rows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
model &lt;- mcfa(iris[, -5], g=3, q=2, nkmeans=1, nrandom=1, itmax = 25)
dat &lt;- rmix(n = 10, model = model)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
