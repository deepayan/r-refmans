<!DOCTYPE html><html><head><title>Help for package polspline</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {polspline}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#beta.polyclass'><p>Polyclass: polychotomous regression and multiple classification</p></a></li>
<li><a href='#clspec'><p>Lspec: logspline estimation of a spectral distribution</p></a></li>
<li><a href='#cpolyclass'><p>Polyclass: polychotomous regression and multiple classification</p></a></li>
<li><a href='#design.polymars'><p>Polymars: multivariate adaptive polynomial spline regression</p></a></li>
<li><a href='#dhare'><p>Hare: hazard regression</p></a></li>
<li><a href='#dheft'><p>Heft: hazard estimation with flexible tails</p></a></li>
<li><a href='#dlogspline'><p>Logspline Density Estimation</p></a></li>
<li><a href='#doldlogspline'><p>Logspline Density Estimation - 1992 version</p></a></li>
<li><a href='#hare'><p>Hare: hazard regression</p></a></li>
<li><a href='#heft'><p>Heft: hazard estimation with flexible tails</p></a></li>
<li><a href='#logspline'><p> Logspline Density Estimation</p></a></li>
<li><a href='#lspec'><p>Lspec: logspline estimation of a spectral distribution</p></a></li>
<li><a href='#oldlogspline'><p> Logspline Density Estimation - 1992 version</p></a></li>
<li><a href='#oldlogspline.to.logspline'><p>Logspline Density Estimation - 1992 to 1997 version</p></a></li>
<li><a href='#persp.polymars'><p>Polymars: multivariate adaptive polynomial spline regression</p></a></li>
<li><a href='#plot.hare'><p>Hare: hazard regression</p></a></li>
<li><a href='#plot.heft'><p>Heft: hazard estimation with flexible tails</p></a></li>
<li><a href='#plot.logspline'><p>Logspline Density Estimation</p></a></li>
<li><a href='#plot.lspec'><p>Lspec: logspline estimation of a spectral distribution</p></a></li>
<li><a href='#plot.oldlogspline'><p>Logspline Density Estimation - 1992 version</p></a></li>
<li><a href='#plot.polyclass'><p>Polyclass: polychotomous regression and multiple classification</p></a></li>
<li><a href='#plot.polymars'><p>Polymars: multivariate adaptive polynomial spline regression</p></a></li>
<li><a href='#polyclass'><p>Polyclass: polychotomous regression and multiple classification</p></a></li>
<li><a href='#polymars'><p>Polymars: multivariate adaptive polynomial spline regression</p></a></li>
<li><a href='#predict.polymars'><p>Polymars: multivariate adaptive polynomial spline regression</p></a></li>
<li><a href='#summary.hare'><p>Hare: hazard regression</p></a></li>
<li><a href='#summary.heft'><p>Heft: hazard estimation with flexible tails</p></a></li>
<li><a href='#summary.logspline'><p>Logspline Density Estimation</p></a></li>
<li><a href='#summary.lspec'><p>Lspec: logspline estimation of a spectral distribution</p></a></li>
<li><a href='#summary.oldlogspline'><p> Logspline Density Estimation - 1992 version</p></a></li>
<li><a href='#summary.polyclass'><p>Polyclass: polychotomous regression and multiple classification</p></a></li>
<li><a href='#summary.polymars'><p>Polymars: multivariate adaptive polynomial spline regression</p></a></li>
<li><a href='#testhare'><p>Fake survival data for Hare and Heft</p></a></li>
<li><a href='#unstrip'><p>Reformat data as vector or matrix</p></a></li>
<li><a href='#xhare'><p>Hare: hazard regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1.24</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-26</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Charles Kooperberg &lt;clk@fredhutch.org&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Polynomial Spline Routines</td>
</tr>
<tr>
<td>Description:</td>
<td>Routines for the polynomial spline fitting routines
  hazard regression, hazard estimation with flexible tails, logspline,
  lspec, polyclass, and polymars, by C. Kooperberg and co-authors.</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Charles Kooperberg [aut, cre],
  Cleve Moler [ctb] (LINPACK routines in src),
  Jack Dongarra [ctb] (LINPACK routines in src)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-26 19:12:32 UTC; clk</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-26 19:50:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='beta.polyclass'>Polyclass: polychotomous regression and multiple classification</h2><span id='topic+beta.polyclass'></span>

<h3>Description</h3>

<p>Produces a beta-plot for a <code>polyclass</code> object.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>beta.polyclass(fit, which, xsp = 0.4, cex) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beta.polyclass_+3A_fit">fit</code></td>
<td>
<p><code>polyclass</code> object, typically the result of <code><a href="#topic+polyclass">polyclass</a></code>.  </p>
</td></tr>
<tr><td><code id="beta.polyclass_+3A_which">which</code></td>
<td>
<p>which classes should be compared? Default is to compare all classes.  </p>
</td></tr>
<tr><td><code id="beta.polyclass_+3A_xsp">xsp</code></td>
<td>
<p>location of the vertical line to the left of the axis. Useful for making 
high quality, device dependent, graphics.  </p>
</td></tr>
<tr><td><code id="beta.polyclass_+3A_cex">cex</code></td>
<td>
<p>character size. Default is whatever the present character size is. 
Useful for making high quality, device dependent, graphics. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A beta plot. One line for each basis function. The left part of the plot 
indicates the basis function, the right half the relative location of the 
betas (coefficients) of that basis function, normalized with respect 
to parent basis functions, for all classes. The scaling is supposed 
to suggest a relative importance of the basis functions. This may 
suggest which basis functions are important for separating particular classes. 
</p>


<h3>Note</h3>

<p>This is not a generic function, and the complete name, beta.polyclass, has to
be specified.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p> Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997). 
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong. 
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+polyclass">polyclass</a></code>,
<code><a href="#topic+plot.polyclass">plot.polyclass</a></code>, 
<code><a href="#topic+summary.polyclass">summary.polyclass</a></code>, 
<code><a href="#topic+cpolyclass">cpolyclass</a></code>, 
<code><a href="#topic+ppolyclass">ppolyclass</a></code>, 
<code><a href="#topic+rpolyclass">rpolyclass</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
fit.iris &lt;- polyclass(iris[,5], iris[,1:4])
beta.polyclass(fit.iris)
</code></pre>

<hr>
<h2 id='clspec'>Lspec: logspline estimation of a spectral distribution</h2><span id='topic+clspec'></span><span id='topic+dlspec'></span><span id='topic+plspec'></span><span id='topic+rlspec'></span>

<h3>Description</h3>

<p>Autocorrelations, autocovariances
(<code>clspec</code>), spectral densities and line spectrum (<code>dlspec</code>),
spectral distributions (<code>plspec</code>) or a
random time series(<code>rlspec</code>) from a model fitted with <code><a href="#topic+lspec">lspec</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>clspec(lag, fit, cov = TRUE, mm) 
dlspec(freq, fit) 
plspec(freq, fit, mm) 
rlspec(n, fit, mean = 0, cosmodel = FALSE, mm)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clspec_+3A_lag">lag</code></td>
<td>
<p> vector of integer-valued lags for which the  autocorrelations or autocorrelations are to be computed.  </p>
</td></tr>
<tr><td><code id="clspec_+3A_fit">fit</code></td>
<td>
 <p><code>lspec</code> object, typically the result of <code><a href="#topic+lspec">lspec</a></code>.</p>
</td></tr>
<tr><td><code id="clspec_+3A_cov">cov</code></td>
<td>
<p> compute autocovariances (<code>TRUE</code>) or autocorrelations (<code>FALSE</code>).  </p>
</td></tr>
<tr><td><code id="clspec_+3A_mm">mm</code></td>
<td>
<p> number of points used in integration and the fft. Default is the 
smallest power of two larger than <code>max(fit\$sample, max(lag),1024)</code>  for
<code>clspec</code> and <code>plspec</code>
or the smallest power of two larger than <code>max(fit\$sample, n, max(lag),
1024)</code> for  (<code>rlspec</code>).  </p>
</td></tr>
<tr><td><code id="clspec_+3A_freq">freq</code></td>
<td>
<p> vector of frequencies. For <code>plspec</code> frequencies should be between <code class="reqn">-\pi</code> and <code class="reqn">\pi</code>.  </p>
</td></tr>
<tr><td><code id="clspec_+3A_n">n</code></td>
<td>
<p> length of the random time series to be generated.  </p>
</td></tr>
<tr><td><code id="clspec_+3A_mean">mean</code></td>
<td>
<p> mean level of the time series to be generated.  </p>
</td></tr>
<tr><td><code id="clspec_+3A_cosmodel">cosmodel</code></td>
<td>
<p> indicate that the data should be generated from a model with constant 
harmonic terms rather than a true Gaussian time series.  </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Autocovariances or autocorrelations (<code>clspec</code>); 
values of the spectral distribution at the requested frequencies. (<code>plspec</code>); 
random time series of length <code>n</code> (<code>rlspec</code>); 
or a  list with three components  (<code>dlspec</code>):
</p>
<table>
<tr><td><code>d</code></td>
<td>
<p>the  spectral density evaluated at the vector of frequencies,</p>
</td></tr>
<tr><td><code>modfreq</code></td>
<td>
<p>modified frequencies of the form <code class="reqn">\frac{2\pi j}{T}</code> that are close to the 
frequencies that were requested,</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>mass of the line spectrum at the modified frequencies.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

 
<p>Charles Kooperberg, Charles J. Stone, and Young K. Truong (1995). 
Logspline Estimation of a Possibly Mixed Spectral Distribution.
<em>Journal of Time Series Analysis</em>, <b>16</b>, 359-388.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong. 
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+lspec">lspec</a></code>, <code><a href="#topic+plot.lspec">plot.lspec</a></code>, <code><a href="#topic+summary.lspec">summary.lspec</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(co2)
co2.detrend &lt;- lm(co2~c(1:length(co2)))$residuals
fit &lt;- lspec(co2.detrend)
clspec(0:12,fit)
plspec((0:314)/100, fit)
dlspec((0:314)/100, fit)
rlspec(length(co2),fit)
</code></pre>

<hr>
<h2 id='cpolyclass'>Polyclass: polychotomous regression and multiple classification</h2><span id='topic+cpolyclass'></span><span id='topic+ppolyclass'></span><span id='topic+rpolyclass'></span>

<h3>Description</h3>

<p> Classify new cases (<code>cpolyclass</code>), compute class probabilities
for new cases (<code>ppolyclass</code>), and generate random multinomials for new cases
(<code>rpolyclass</code>) for a <code><a href="#topic+polyclass">polyclass</a></code> model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpolyclass(cov, fit)
ppolyclass(data, cov, fit) 
rpolyclass(n, cov, fit) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cpolyclass_+3A_cov">cov</code></td>
<td>
<p> covariates. Should be a matrix with <code>fit\$ncov</code> columns.  
For <code>rpolyclass</code> <code>cov</code> should either have one row, in 
which case all random numbers are based on the same covariates, or <code>n</code> 
rows in which case each random number has its own covariates.  </p>
</td></tr>
<tr><td><code id="cpolyclass_+3A_fit">fit</code></td>
<td>
 <p><code>polyclass</code> object, typically the result of <code><a href="#topic+polyclass">polyclass</a></code>. </p>
</td></tr>
<tr><td><code id="cpolyclass_+3A_data">data</code></td>
<td>

<p>there are several possibilities. If data is a vector with as many elements 
as cov has rows, each element of data corresponds to a row of cov; if 
only one value is given, the probability of being in that class is computed 
for all sets of covariates. If data is omitted, all class probabilities are 
provided. 
</p>
</td></tr>
<tr><td><code id="cpolyclass_+3A_n">n</code></td>
<td>
<p> number of pseudo random numbers to be generated.  </p>
</td></tr>
</table>


<h3>Value</h3>

<p> Most likely classes (<code>cpolyclass</code>),
probabilities (<code>cpolyclass</code>), or
random classes according to the estimated probabilities (<code>rpolyclass</code>).
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p> Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyclass">polyclass</a></code>,
<code><a href="#topic+plot.polyclass">plot.polyclass</a></code>, 
<code><a href="#topic+summary.polyclass">summary.polyclass</a></code>,
<code><a href="#topic+beta.polyclass">beta.polyclass</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
fit.iris &lt;- polyclass(iris[,5], iris[,1:4])
class.iris &lt;- cpolyclass(iris[,1:4], fit.iris)
table(class.iris, iris[,5])
prob.setosa &lt;- ppolyclass(1, iris[,1:4], fit.iris)
prob.correct &lt;- ppolyclass(iris[,5], iris[,1:4], fit.iris) 
rpolyclass(100, iris[64,1:4], fit.iris)
</code></pre>

<hr>
<h2 id='design.polymars'>Polymars: multivariate adaptive polynomial spline regression</h2><span id='topic+design.polymars'></span>

<h3>Description</h3>

<p>Produces a design matrux for a model of class <code>polymars</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>design.polymars(object, x) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="design.polymars_+3A_object">object</code></td>
<td>

<p>object of the class <code>polymars</code>, typically the result of <code><a href="#topic+polymars">polymars</a></code>.</p>
</td></tr>
<tr><td><code id="design.polymars_+3A_x">x</code></td>
<td>

<p>the predictor values at which the design matrix will be computed.  The 
predictor values can be in a number of formats. It can take the form of a 
vector of length equal to the number of predictors in the original data set 
or it can be shortened to the length of only those predictors that occur in 
the model, in the same order as they appear in the original data set.  
Similarly, <code>x</code> can take the form of a matrix with the number of columns equal to 
the number of predictors in the original data set, or shortened to the 
number of predictors in the model. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The design matrix corresponding to the fitted <code><a href="#topic+polymars">polymars</a></code> model.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg</p>


<h3>References</h3>

<p> Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polymars">polymars</a></code>,
<code><a href="#topic+plot.polymars">plot.polymars</a></code>,
<code><a href="#topic+predict.polymars">predict.polymars</a></code>,
<code><a href="#topic+summary.polymars">summary.polymars</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(state)
state.pm &lt;- polymars(state.region, state.x77, knots = 15, classify = TRUE, gcv = 1)
desmat &lt;- design.polymars(state.pm, state.x77)
# compute traditional summary of the fit for the first class
summary(lm(((state.region=="Northeast")*1) ~ desmat -1))
</code></pre>

<hr>
<h2 id='dhare'>Hare: hazard regression</h2><span id='topic+dhare'></span><span id='topic+hhare'></span><span id='topic+phare'></span><span id='topic+qhare'></span><span id='topic+rhare'></span>

<h3>Description</h3>

<p>Density (<code>dhare</code>), cumulative probability (<code>phare</code>), hazard rate (<code>hhare</code>), quantiles
(<code>qhare</code>), and  random samples (<code>rhare</code>) from 
a <code><a href="#topic+hare">hare</a></code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhare(q, cov, fit) 
hhare(q, cov, fit) 
phare(q, cov, fit) 
qhare(p, cov, fit) 
rhare(n, cov, fit) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dhare_+3A_q">q</code></td>
<td>
<p> vector of quantiles. Missing values (<code>NA</code>s) are allowed.  </p>
</td></tr>
<tr><td><code id="dhare_+3A_p">p</code></td>
<td>
<p> vector of probabilities. Missing values (<code>NA</code>s) are allowed.  </p>
</td></tr>
<tr><td><code id="dhare_+3A_n">n</code></td>
<td>

<p>sample size. If <code>length(n)</code> is larger than 1, then 
<code>length(n)</code> random values are returned. 
</p>
</td></tr>
<tr><td><code id="dhare_+3A_cov">cov</code></td>
<td>

<p>covariates. There are several possibilities. If a vector of length 
<code>fit\$ncov</code> is provided, these covariates are used for all elements of <code>p</code> or 
<code>q</code> or for all random numbers. If a matrix of dimension <code>length(p)</code>,
<code>length(q)</code>, or <code>n</code> by <code>fit\$ncov</code> is provided, the rows of <code>cov</code> are 
matched with the elements of <code>p</code> or <code>q</code> or every row of <code>cov</code> has its own 
random number. If a matrix of dimension <code>m</code> times <code>fit\$ncov</code> is provided, 
while <code>length(p) = 1</code> or <code>length(q) = 1</code> or <code>n = 1</code>, the single element of <code>p</code> or <code>q</code> is 
used <code>m</code> times, or <code>m</code> random numbers with different sets of covariates are 
generated. 
</p>
</td></tr>
<tr><td><code id="dhare_+3A_fit">fit</code></td>
<td>
 <p><code>hare</code> object, typically obtained from <code><a href="#topic+hare">hare</a></code>.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Elements of <code>q</code> or <code>p</code> that are missing will cause the 
corresponding elements of the result to be missing. 
</p>


<h3>Value</h3>

<p>Densities (<code>dhare</code>), hazard rates (<code>hhare</code>), 
probabilities (<code>phare</code>), quantiles (<code>qhare</code>), 
or a random sample (<code>rhare</code>) from a <code><a href="#topic+hare">hare</a></code> object.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995). 
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong. 
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+hare">hare</a></code>,
<code><a href="#topic+plot.hare">plot.hare</a></code>,
<code><a href="#topic+summary.hare">summary.hare</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- hare(testhare[,1], testhare[,2], testhare[,3:8])
dhare(0:10, testhare[117,3:8], fit)
hhare(0:10, testhare[1:11,3:8], fit)
phare(10, testhare[1:25,3:8], fit)
qhare((1:19)/20, testhare[117,3:8], fit)
rhare(10, testhare[117,3:8], fit)
</code></pre>

<hr>
<h2 id='dheft'>Heft: hazard estimation with flexible tails</h2><span id='topic+dheft'></span><span id='topic+hheft'></span><span id='topic+pheft'></span><span id='topic+qheft'></span><span id='topic+rheft'></span>

<h3>Description</h3>

<p>Density (<code>dheft</code>), cumulative probability (<code>pheft</code>), hazard rate (<code>hheft</code>),
quantiles (<code>qheft</code>), and  random samples (<code>rheft</code>) from a <code><a href="#topic+heft">heft</a></code> object</p>


<h3>Usage</h3>

<pre><code class='language-R'>dheft(q, fit) 
hheft(q, fit) 
pheft(q, fit) 
qheft(p, fit) 
rheft(n, fit) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dheft_+3A_q">q</code></td>
<td>
<p> vector of quantiles. Missing values (<code>NA</code>s) are allowed.  </p>
</td></tr>
<tr><td><code id="dheft_+3A_p">p</code></td>
<td>
<p> vector of probabilities. Missing values (<code>NA</code>s) are allowed.  </p>
</td></tr>
<tr><td><code id="dheft_+3A_n">n</code></td>
<td>

<p>sample size. If <code>length(n)</code> is larger than 1, then
<code>length(n)</code> random values are returned.
</p>
</td></tr>
<tr><td><code id="dheft_+3A_fit">fit</code></td>
<td>

<p><code>heft</code> object, typically obtained from <code><a href="#topic+heft">heft</a></code>.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Elements of <code>q</code> or <code>p</code> that are missing will cause the
corresponding elements of the result to be missing.
</p>


<h3>Value</h3>

<p>Densities (<code>dheft</code>), hazard rates (<code>hheft</code>),
probabilities (<code>pheft</code>), quantiles (<code>qheft</code>),
or a random sample (<code>rheft</code>) from a <code><a href="#topic+heft">heft</a></code> object.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+heft">heft</a></code>, <code><a href="#topic+plot.heft">plot.heft</a></code>, <code><a href="#topic+summary.heft">summary.heft</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- heft(testhare[,1],testhare[,2])
dheft(0:10,fit)
hheft(0:10,fit)
pheft(0:10,fit)
qheft((1:19)/20,fit)
rheft(10,fit)
</code></pre>

<hr>
<h2 id='dlogspline'>Logspline Density Estimation</h2><span id='topic+dlogspline'></span><span id='topic+plogspline'></span><span id='topic+qlogspline'></span><span id='topic+rlogspline'></span>

<h3>Description</h3>

<p>Density (<code>dlogspline</code>), cumulative probability (<code>plogspline</code>), quantiles
(<code>qlogspline</code>), and  random samples (<code>rlogspline</code>) from 
a logspline density that was fitted using
the 1997 knot addition and deletion algorithm (<code><a href="#topic+logspline">logspline</a></code>). 
The 1992 algorithm is available using the <code><a href="#topic+oldlogspline">oldlogspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlogspline(q, fit, log = FALSE) 
plogspline(q, fit) 
qlogspline(p, fit) 
rlogspline(n, fit) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dlogspline_+3A_q">q</code></td>
<td>

<p>vector of quantiles. Missing values (NAs) are allowed. 
</p>
</td></tr>
<tr><td><code id="dlogspline_+3A_p">p</code></td>
<td>

<p>vector of probabilities. Missing values (NAs) are allowed. 
</p>
</td></tr>
<tr><td><code id="dlogspline_+3A_n">n</code></td>
<td>

<p>sample size. If <code>length(n)</code> is larger than 1, then 
<code>length(n)</code> random values are returned.
</p>
</td></tr>
<tr><td><code id="dlogspline_+3A_fit">fit</code></td>
<td>

<p><code>logspline</code> object, typically the result of <code><a href="#topic+logspline">logspline</a></code>.
</p>
</td></tr>
<tr><td><code id="dlogspline_+3A_log">log</code></td>
<td>

<p>should dlogspline return densities (TRUE) or log-densities (FALSE)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Elements of <code>q</code> or <code>p</code> that are missing will cause the 
corresponding elements of the result to be missing. 
</p>


<h3>Value</h3>

<p>Densities (<code>dlogspline</code>), probabilities (<code>plogspline</code>), quantiles (<code>qlogspline</code>), 
or a random sample (<code>rlogspline</code>) from a <code>logspline</code> density that was fitted using
knot addition and deletion.
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong. 
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+logspline">logspline</a></code>,      
<code><a href="#topic+plot.logspline">plot.logspline</a></code>,
<code><a href="#topic+summary.logspline">summary.logspline</a></code>,
<code><a href="#topic+oldlogspline">oldlogspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
fit &lt;- logspline(x)
qq &lt;- qlogspline((1:99)/100, fit)
plot(qnorm((1:99)/100), qq)                  # qq plot of the fitted density
pp &lt;- plogspline((-250:250)/100, fit)
plot((-250:250)/100, pp, type = "l")
lines((-250:250)/100,pnorm((-250:250)/100))  # asses the fit of the distribution
dd &lt;- dlogspline((-250:250)/100, fit)
plot((-250:250)/100, dd, type = "l")
lines((-250:250)/100, dnorm((-250:250)/100)) # asses the fit of the density
rr &lt;- rlogspline(100, fit)                   # random sample from fit
</code></pre>

<hr>
<h2 id='doldlogspline'>Logspline Density Estimation - 1992 version </h2><span id='topic+doldlogspline'></span><span id='topic+poldlogspline'></span><span id='topic+qoldlogspline'></span><span id='topic+roldlogspline'></span>

<h3>Description</h3>

<p>Probability density function (<code>doldlogspline</code>), distribution
function (<code>poldlogspline</code>), quantiles 
(<code>qoldlogspline</code>), and  random samples (<code>roldlogspline</code>) from
a logspline density that was fitted using
the 1992 knot deletion algorithm (<code><a href="#topic+oldlogspline">oldlogspline</a></code>). 
The 1997 algorithm using knot
deletion and addition is available using the <code><a href="#topic+logspline">logspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doldlogspline(q, fit) 
poldlogspline(q, fit) 
qoldlogspline(p, fit) 
roldlogspline(n, fit) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="doldlogspline_+3A_q">q</code></td>
<td>

<p>vector of quantiles. Missing values (NAs) are allowed. 
</p>
</td></tr>
<tr><td><code id="doldlogspline_+3A_p">p</code></td>
<td>

<p>vector of probabilities. Missing values (NAs) are allowed. 
</p>
</td></tr>
<tr><td><code id="doldlogspline_+3A_n">n</code></td>
<td>

<p>sample size. If <code>length(n)</code> is larger than 1, then 
<code>length(n)</code> random values are returned.
</p>
</td></tr>
<tr><td><code id="doldlogspline_+3A_fit">fit</code></td>
<td>

<p><code>oldlogspline</code> object, typically the result of <code><a href="#topic+oldlogspline">oldlogspline</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Elements of  <code>q</code> or <code>p</code> that are missing will cause the 
corresponding elements of the result to be missing. 
</p>


<h3>Value</h3>

<p> Densities (<code>doldlogspline</code>), probabilities (<code>poldlogspline</code>), quantiles (<code>qoldlogspline</code>), 
or a random sample (<code>roldlogspline</code>)
from an <code>oldlogspline</code> density that was fitted using
knot deletion.
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspline">logspline</a></code>,
<code><a href="#topic+oldlogspline">oldlogspline</a></code>,
<code><a href="#topic+plot.oldlogspline">plot.oldlogspline</a></code>,
<code><a href="#topic+summary.oldlogspline">summary.oldlogspline</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
fit &lt;- oldlogspline(x)
qq &lt;- qoldlogspline((1:99)/100, fit)
plot(qnorm((1:99)/100), qq)                  # qq plot of the fitted density
pp &lt;- poldlogspline((-250:250)/100, fit)
plot((-250:250)/100, pp, type = "l")
lines((-250:250)/100, pnorm((-250:250)/100)) # asses the fit of the distribution
dd &lt;- doldlogspline((-250:250)/100, fit)
plot((-250:250)/100, dd, type = "l")
lines((-250:250)/100, dnorm((-250:250)/100)) # asses the fit of the density
rr &lt;- roldlogspline(100, fit)                # random sample from fit
</code></pre>

<hr>
<h2 id='hare'>Hare: hazard regression</h2><span id='topic+hare'></span>

<h3>Description</h3>

<p>Fit a hazard regression model: linear splines are used to model
the baseline hazard, covariates, and interactions. Fitted models
can be, but do not need to be, proportional hazards models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hare(data, delta, cov, penalty, maxdim, exclude, include, prophaz = FALSE,
additive = FALSE, linear, fit, silent = TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hare_+3A_data">data</code></td>
<td>

<p>vector of observations. Observations may or may not be right censored. All 
observations should be nonnegative. 
</p>
</td></tr>
<tr><td><code id="hare_+3A_delta">delta</code></td>
<td>

<p>binary vector with the same length as <code>data</code>. Elements of <code>data</code> 
for which the corresponding element of <code>delta</code> is 0 are assumed to be 
right censored, elements of <code>data</code> 
for which the corresponding element of <code>delta</code> is 1 are assumed to be 
uncensored. If <code>delta</code> is missing, all observations are assumed to be uncensored. 
</p>
</td></tr>
<tr><td><code id="hare_+3A_cov">cov</code></td>
<td>

<p>covariates: matrix with as many rows as the length of <code>data</code>. May be omitted 
if there are no covariates. (If there are no covariates, however,
<code><a href="#topic+heft">heft</a></code> will provide a more flexible model using cubic splines.)
</p>
</td></tr>
<tr><td><code id="hare_+3A_penalty">penalty</code></td>
<td>

<p>the parameter to be used in the AIC criterion. The method chooses 
the number of knots that minimizes <code>-2 * loglikelihood + penalty * (dimension)</code>. 
The default is to use <code>penalty = log(samplesize)</code> as in BIC. The effect of 
this parameter is summarized in <code><a href="#topic+summary.hare">summary.hare</a></code>. 
</p>
</td></tr>
<tr><td><code id="hare_+3A_maxdim">maxdim</code></td>
<td>

<p>maximum dimension (default is <code class="reqn">6*\mbox{length(data)}^0.2)</code>. 
</p>
</td></tr>
<tr><td><code id="hare_+3A_exclude">exclude</code></td>
<td>

<p>combinations to be excluded - this should be a matrix with 2 
columns - if for example <code>exclude[1, 1] = 2</code> and <code>exclude[1, 2] = 3</code> no 
interaction between covariate 2 and 3 is included. 0 represents time. 
</p>
</td></tr>
<tr><td><code id="hare_+3A_include">include</code></td>
<td>

<p>those combinations that can be included. Should have the same format 
as <code>exclude</code>. Only one of <code>exclude</code> and <code>include</code> can be specified .
</p>
</td></tr>
<tr><td><code id="hare_+3A_prophaz">prophaz</code></td>
<td>
<p> should the model selection be restricted to proportional hazards models?  </p>
</td></tr>
<tr><td><code id="hare_+3A_additive">additive</code></td>
<td>
<p> should the model selection be restricted to additive models?  </p>
</td></tr>
<tr><td><code id="hare_+3A_linear">linear</code></td>
<td>

<p>vector indicating for which of the variables no knots should 
be entered. For example, if <code>linear = c(2, 3)</code> no knots for either covariate 
2 or 3 are entered. 0 represents time. The default is none.
</p>
</td></tr>
<tr><td><code id="hare_+3A_fit">fit</code></td>
<td>

<p><code><a href="#topic+hare">hare</a></code> object. If  <code>fit</code> is specified, <code><a href="#topic+hare">hare</a></code> adds 
basis functions starting with those in <code>fit</code>. 
</p>
</td></tr>
<tr><td><code id="hare_+3A_silent">silent</code></td>
<td>

<p>suppresses the printing of diagnostic output about basis functions added 
or deleted, Rao-statistics, Wald-statistics and log-likelihoods. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class
<code>hare</code>, which is organized to serve as input for <code><a href="#topic+plot.hare">plot.hare</a></code>, 
<code><a href="#topic+summary.hare">summary.hare</a></code>, <code><a href="#topic+dhare">dhare</a></code> (conditional density), <code><a href="#topic+hhare">hhare</a></code>
(conditional hazard rate), <code><a href="#topic+phare">phare</a></code> (conditional probabilities), <code><a href="#topic+qhare">qhare</a></code>
(conditional quantiles), and <code><a href="#topic+rhare">rhare</a></code> (random numbers). 
The object is a list with the following members: 
</p>
<table>
<tr><td><code>ncov</code></td>
<td>
<p> number of covariates.  </p>
</td></tr>
<tr><td><code>ndim</code></td>
<td>
<p> number of dimensions of the fitted model.  </p>
</td></tr>
<tr><td><code>fcts</code></td>
<td>
<p> matrix of size <code>ndim x 6</code>. each row is a basis function. 
First element: first covariate involved (0 means time); 
</p>
<p>second element: which knot (0 means: constant (time) or linear (covariate)); 
</p>
<p>third element: second covariate involved (<code>NA</code> means: this is a function of one variable); 
</p>
<p>fourth element: knot involved (if the third element is <code>NA</code>, of no relevance); 
</p>
<p>fifth element: beta; 
</p>
<p>sixth element: standard error of beta.</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>

<p>a matrix with <code>ncov</code> rows.
Covariate <code>i</code> has row <code>i+1</code>, time has row 1. 
First column: number of knots in this dimension;
other columns: the knots, appended with <code>NA</code>s to make it a matrix.
</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p> the parameter used in the AIC criterion.</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p> maximum element of survival data.</p>
</td></tr>
<tr><td><code>ranges</code></td>
<td>
<p> column <code>i</code> gives the range of the <code>i</code>-th covariate.</p>
</td></tr>
<tr><td><code>logl</code></td>
<td>

<p>matrix with two columns. The <code>i</code>-th element of the first column  
is the loglikelihood of the model of dimension <code>i</code>. The second column indicates whether this 
model was fitted during the addition stage (1) or during the deletion stage (0). 
</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p> sample size.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+heft">heft</a></code>,
<code><a href="#topic+plot.hare">plot.hare</a></code>,
<code><a href="#topic+summary.hare">summary.hare</a></code>,
<code><a href="#topic+dhare">dhare</a></code>,
<code><a href="#topic+hhare">hhare</a></code>,
<code><a href="#topic+phare">phare</a></code>,
<code><a href="#topic+qhare">qhare</a></code>,
<code><a href="#topic+rhare">rhare</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- hare(testhare[,1], testhare[,2], testhare[,3:8]) 
</code></pre>

<hr>
<h2 id='heft'>Heft: hazard estimation with flexible tails</h2><span id='topic+heft'></span>

<h3>Description</h3>

<p>Hazard estimation using cubic splines to 
approximate the log-hazard function and special functions to allow
non-polynomial shapes in both tails. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heft(data, delta, penalty, knots, leftlin, shift, leftlog,
rightlog, maxknots, mindist, silent = TRUE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heft_+3A_data">data</code></td>
<td>

<p>vector of observations. Observations may or may not be right censored. All
observations should be nonnegative.
</p>
</td></tr>
<tr><td><code id="heft_+3A_delta">delta</code></td>
<td>

<p>binary vector with the same length as <code>data</code>. Elements of <code>data</code>
for which the corresponding element of <code>delta</code> is 0 are assumed to be
right censored, elements of <code>data</code>
for which the corresponding element of <code>delta</code> is 1 are assumed to be
uncensored. If <code>delta</code> is missing, all observations are assumed to be uncensored.
</p>
</td></tr>
<tr><td><code id="heft_+3A_penalty">penalty</code></td>
<td>

<p>the parameter to be used in the AIC criterion. The method chooses
the number of knots that minimizes <code>-2 * loglikelihood + penalty * (dimension)</code>.
The default is to use <code>penalty = log(samplesize)</code> as in BIC. The effect of
this parameter is summarized in <code><a href="#topic+summary.heft">summary.heft</a></code>.
</p>
</td></tr>
<tr><td><code id="heft_+3A_knots">knots</code></td>
<td>

<p>ordered vector of values, which forces the method to start with these knots. 
If <code>knots</code> is not specified, a default knot-placement rule is employed. 
</p>
</td></tr>
<tr><td><code id="heft_+3A_leftlin">leftlin</code></td>
<td>

<p>if <code>leftlin</code> is <code>TRUE</code> an extra basis-function, which is linear to the left 
of the first knot, is included in the basis. 
If any of <code>data</code> is exactly 0, the default of <code>leftlin</code> is <code>TRUE</code>,
otherwise it is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="heft_+3A_shift">shift</code></td>
<td>

<p>parameter for the log terms. Default is <code>quantile(data[delta == 1], .75)</code>. 
</p>
</td></tr>
<tr><td><code id="heft_+3A_leftlog">leftlog</code></td>
<td>

<p>coefficient of <code class="reqn">\log \frac x{x + \mbox{shift}}</code>, which must be greater than 
<code>-1</code>. 
(In particular, if <code>leftlog</code> equals zero no 
<code class="reqn">\log \frac x{x + \mbox{shift}}</code> term 
is included.) If <code>leftlog</code> is missing its maximum likelihood estimate is used. 
If any of <code>data</code> is exactly zero, <code>leftlog</code> is  
set to zero. 
</p>
</td></tr>
<tr><td><code id="heft_+3A_rightlog">rightlog</code></td>
<td>

<p>coefficient of <code class="reqn">\log (x + \mbox{shift})</code>, which must be greater than 
<code>-1</code>.
(In particular, if <code>leftlog</code> equals zero no  
<code class="reqn">\log (x + \mbox{shift})</code> term
is included.)
If <code>rightlog</code> is missing its maximum likelihood estimate is used. 
</p>
</td></tr>
<tr><td><code id="heft_+3A_maxknots">maxknots</code></td>
<td>

<p>maximum number of knots allowed in the model (default is 
<code class="reqn">4*n^{0.2})</code>, where <code class="reqn">n</code> is the length of
<code>data</code>.
</p>
</td></tr>
<tr><td><code id="heft_+3A_mindist">mindist</code></td>
<td>
<p> minimum distance in order statistics between knots. The
default is 5.  </p>
</td></tr>
<tr><td><code id="heft_+3A_silent">silent</code></td>
<td>

<p>suppresses the printing of diagnostic output about knots added or deleted, 
Rao-statistics, Wald-statistics and log-likelihoods. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class
<code>heft</code>, which is organized to serve as input for <code><a href="#topic+plot.heft">plot.heft</a></code>,
<code><a href="#topic+summary.heft">summary.heft</a></code>, <code><a href="#topic+dheft">dheft</a></code> (density), <code><a href="#topic+hheft">hheft</a></code>
(hazard rate), <code><a href="#topic+pheft">pheft</a></code> (probabilities), <code><a href="#topic+qheft">qheft</a></code>
(quantiles), and <code><a href="#topic+rheft">rheft</a></code> (random numbers).
The object is a list with the following members:
</p>
<table>
<tr><td><code>knots</code></td>
<td>

<p>vector of the locations of the knots in the <code>heft</code> model. 
</p>
</td></tr>
<tr><td><code>logl</code></td>
<td>

<p>the <code>k</code>-th element is the log-likelihood of the fit with <code>k</code> knots. 
</p>
</td></tr>
<tr><td><code>thetak</code></td>
<td>

<p>coefficients of the knot part of the 
spline. The k-th coefficient is the coefficient 
of  <code class="reqn">(x-t(k))^3_+</code>. If a coefficient is zero the corresponding 
knot was considered and then deleted from the model. 
</p>
</td></tr>
<tr><td><code>thetap</code></td>
<td>

<p>coefficients of the polynomial part of the spline. 
The first element is the constant term and 
the second element is the linear term. 
</p>
</td></tr>
<tr><td><code>thetal</code></td>
<td>

<p>coefficients of the logarithmic terms. The first element equals 
<code>leftlog</code> and the second element equals <code>rightlog</code>. 
</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>

<p>the penalty that was used. 
</p>
</td></tr>
<tr><td><code>shift</code></td>
<td>
<p> parameter used in the definition of the log terms.  </p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p> the sample size.  </p>
</td></tr>
<tr><td><code>logse</code></td>
<td>
<p> the standard errors of <code>thetal</code>.  </p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p> the largest element of data.  </p>
</td></tr>
<tr><td><code>ad</code></td>
<td>
<p> vector indicating whether a model of this dimension 
was not fit (2), fit during the addition stage (0) or during 
the deletion stage (1).  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+hare">hare</a></code>,
<code><a href="#topic+plot.heft">plot.heft</a></code>,
<code><a href="#topic+summary.heft">summary.heft</a></code>,
<code><a href="#topic+dheft">dheft</a></code>,
<code><a href="#topic+hheft">hheft</a></code>,
<code><a href="#topic+pheft">pheft</a></code>,
<code><a href="#topic+qheft">qheft</a></code>,
<code><a href="#topic+rheft">rheft</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- heft(testhare[,1], testhare[,2])
# modify tail behavior
fit2 &lt;- heft(testhare[,1], testhare[,2], leftlog = FALSE, rightlog = FALSE, 
          leftlin = TRUE)   
fit3 &lt;- heft(testhare[,1], testhare[,2], penalty = 0)   # select largest model
</code></pre>

<hr>
<h2 id='logspline'> Logspline Density Estimation </h2><span id='topic+logspline'></span>

<h3>Description</h3>

<p>Fits a <code>logspline</code> density using splines to approximate the log-density
using 
the 1997 knot addition and deletion algorithm (<code><a href="#topic+logspline">logspline</a></code>). 
The 1992 algorithm is available using the <code><a href="#topic+oldlogspline">oldlogspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logspline(x, lbound, ubound, maxknots = 0, knots, nknots = 0, penalty,
silent = TRUE, mind = -1, error.action = 2) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logspline_+3A_x">x</code></td>
<td>
<p> data vector. The data needs to be uncensored. <code><a href="#topic+oldlogspline">oldlogspline</a></code>
can deal with right- left- and interval-censored data.  </p>
</td></tr>
<tr><td><code id="logspline_+3A_lbound">lbound</code>, <code id="logspline_+3A_ubound">ubound</code></td>
<td>

<p>lower/upper bound for the support of the density. For example, if there 
is a priori knowledge that the density equals zero to the left of 0, 
and has a discontinuity at 0, 
the user could specify <code>lbound = 0</code>. However, if the density is  
essentially zero near 0, one does not need to specify <code>lbound</code>. 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_maxknots">maxknots</code></td>
<td>

<p>the maximum number of knots. The routine stops adding knots 
when this number of knots is reached. 
The method has an automatic rule 
for selecting maxknots if this parameter is not specified. 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_knots">knots</code></td>
<td>

<p>ordered vector of values (that should cover the complete range of the 
observations), which forces the method to start with these knots. 
Overrules knots.	 
If <code>knots</code> is not specified, a default knot-placement rule is employed. 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_nknots">nknots</code></td>
<td>

<p>forces the method to start with <code>nknots</code> knots. 
The method has an automatic rule 
for selecting <code>nknots</code> if this parameter is not specified. 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_penalty">penalty</code></td>
<td>

<p>the parameter to be used in the AIC criterion. The method chooses 
the number of knots that minimizes
<code>-2 * loglikelihood + penalty * (number of knots - 1)</code>. 
The default 
is to use a penalty parameter of <code>penalty = log(samplesize)</code> as in BIC. The effect of 
this parameter is summarized in <code><a href="#topic+summary.logspline">summary.logspline</a></code>. 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_silent">silent</code></td>
<td>

<p>should diagnostic output be printed? 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_mind">mind</code></td>
<td>

<p>minimum distance, in order statistics, between knots. 
</p>
</td></tr>
<tr><td><code id="logspline_+3A_error.action">error.action</code></td>
<td>
<p>how should <code>logspline</code> deal with non-convergence problems? Very-very rarely
in some extreme situations
<code>logspline</code> has convergence problems. The only two situations that I am aware of are when
there is effectively a sharp bound, but this bound was not specified, or when the data is severly
rounded. <code>logspline</code> can deal with this in three ways. If <code>error.action</code> is 2, the same
data is rerun with the slightly more stable, but less flexible <code>oldlogspline</code>. The object is translated
in a <code>logspline</code> object using <code>oldlogspline.to.logspline</code>, so this is almost
invisible to the user. It is particularly useful when you run simulation studies, as he code can
seemlessly continue. Only the <code>lbound</code> and <code>ubound</code> options are passed on to
<code>oldlogspline</code>, other options revert to the default. If <code>error.action</code> is 1, a warning is printed,
and <code>logspline</code> returns nothing (but does not crash). This is useful if you run a
simulation, but do not like to revert to <code>oldlogspline</code>. If <code>error.action</code> is 0, the
code crashes using the <code>stop</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of the class <code>logspline</code>, that is intended as input for
<code><a href="#topic+plot.logspline">plot.logspline</a></code> (summary plots), 
<code><a href="#topic+summary.logspline">summary.logspline</a></code> (fitting summary), 
<code><a href="#topic+dlogspline">dlogspline</a></code> (densities), 
<code><a href="#topic+plogspline">plogspline</a></code> (probabilities),
<code><a href="#topic+qlogspline">qlogspline</a></code> (quantiles),
<code><a href="#topic+rlogspline">rlogspline</a></code> (random numbers from the fitted distribution).
</p>
<p>The object has the following members: 
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the command that was executed.</p>
</td></tr>
<tr><td><code>nknots</code></td>
<td>
<p>the number of knots in the model that was selected.</p>
</td></tr>
<tr><td><code>coef.pol</code></td>
<td>
<p>coefficients of the polynomial part of the spline.
The first coefficient is the constant term and
the second is the linear term.</p>
</td></tr>
<tr><td><code>coef.kts</code></td>
<td>
<p>coefficients of the knots  part of the spline.
The <code>k</code>-th element is the coefficient 
of <code class="reqn">(x-t(k))^3_+</code> (where <code class="reqn">x^3_+</code> means the positive part of the third power
of <code class="reqn">x</code>, 
and <code class="reqn">t(k)</code> means knot <code>k</code>).</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>vector of the locations of the knots in the <code>logspline</code> model.</p>
</td></tr>
<tr><td><code>maxknots</code></td>
<td>
<p>the largest number of knots minus one considered during fitting
(i.e. with <code>maxknots = 6</code> the maximum number of knots is 5).</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>the penalty that was used.  </p>
</td></tr>
<tr><td><code>bound</code></td>
<td>

<p>first element: 0 - <code>lbound</code> was <code class="reqn">-\inf</code> 1 it was something else; second 
element: <code>lbound</code>, if specified; third element: 0 - <code>ubound</code> was <code class="reqn">\inf</code>, 
1 it was something else; fourth element: <code>ubound</code>, if specified. 
</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>the sample size.</p>
</td></tr>
<tr><td><code>logl</code></td>
<td>
<p>matrix with 3 columns. Column one: number of knots; column two:
model fitted during addition (1) or deletion (2); column 3: log-likelihood.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>range of the input data.</p>
</td></tr>
<tr><td><code>mind</code></td>
<td>
<p>minimum distance in order statistics between knots required during fitting
(the actual minimum distance may be much larger).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+plot.logspline">plot.logspline</a></code>, 
<code><a href="#topic+summary.logspline">summary.logspline</a></code>,
<code><a href="#topic+dlogspline">dlogspline</a></code>, 
<code><a href="#topic+plogspline">plogspline</a></code>,
<code><a href="#topic+qlogspline">qlogspline</a></code>, <br />
<code><a href="#topic+rlogspline">rlogspline</a></code>,
<code><a href="#topic+oldlogspline">oldlogspline</a>,</code>
<code><a href="#topic+oldlogspline.to.logspline">oldlogspline.to.logspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
fit &lt;- logspline(y)       
plot(fit)
#
# as (4 == length(-2, -1, 0, 1, 2) -1), this forces these initial knots,
# and does no knot selection
fit &lt;- logspline(y, knots = c(-2, -1, 0, 1, 2), maxknots = 4, penalty = 0)  
#
# the following example give one of the rare examples where logspline
# crashes, and this shows the use of error.action = 2.
#
set.seed(118)
zz &lt;- rnorm(300)
zz[151:300] &lt;- zz[151:300]+5
zz &lt;- round(zz)
fit &lt;- logspline(zz)
#
# you could rerun this with 
# fit &lt;- logspline(zz, error.action=0)
# or
# fit &lt;- logspline(zz, error.action=1)
</code></pre>

<hr>
<h2 id='lspec'>Lspec: logspline estimation of a spectral distribution</h2><span id='topic+lspec'></span>

<h3>Description</h3>

<p> Fit an <code>lspec</code> model
to a time-series or a periodogram.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lspec(data, period, penalty, minmass, knots, maxknots, atoms, maxatoms,
maxdim , odd = FALSE, updown = 3, silent = TRUE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lspec_+3A_data">data</code></td>
<td>

<p>time series (exactly one of <code>data</code> and <code>period</code> should be specified). 
If <code>data</code> is specified, <code>lspec</code> first computes the modulus 
of the fast Fourier transform 
of the series using the function
<code><a href="stats.html#topic+fft">fft</a></code>, resulting in a periodogram of length
<code>floor(length(data)/2)</code>. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_period">period</code></td>
<td>

<p>value of the periodogram for a time series at frequencies 
<code class="reqn">\frac{2\pi j}T</code>, for <code class="reqn">1\leq j \leq T/2</code>. If period is specified, odd should indicate 
whether the length of the series T is odd <code>(odd = TRUE)</code> or even <code>(odd = FALSE)</code>. 
Exactly one of <code>data</code> and <code>period</code> should be specified. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_penalty">penalty</code></td>
<td>

<p>the parameter to be used in the AIC criterion. The method chooses 
the number of basis 
functions that minimizes <code>-2 * loglikelihood + penalty * (number of basis 
functions)</code>. 
Default is to use a penalty parameter of <code>penalty = log(length(period))</code> as in BIC.  </p>
</td></tr>
<tr><td><code id="lspec_+3A_minmass">minmass</code></td>
<td>

<p>threshold value for atoms. No atoms having smaller mass than <code>minmass</code> are 
included in the model. If <code>minmass</code> takes its default value, in 
95% of the samples, when data is Gaussian white noise, the model will not 
contain atoms.  </p>
</td></tr>
<tr><td><code id="lspec_+3A_knots">knots</code></td>
<td>

<p>ordered vector of values, which forces the method to start with these knots. 
If <code>knots</code> is not specified, the program starts with one knot at zero and then 
employs stepwise addition of knots and atoms. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_maxknots">maxknots</code></td>
<td>
<p> maximum number of knots allowed in the model. Does not need to be 
specified, since the program has a default for <code>maxdim</code> and 
the number of dimensions equals the number of knots plus the number of 
atoms. If <code>maxknots = 1</code> the fitted spectral density function is 
constant. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_atoms">atoms</code></td>
<td>

<p>ordered vector of values, which forces the method to start with discrete 
components at these frequencies. The values of atoms are rounded 
to the nearest multiple of <code class="reqn">\frac{2\pi}T</code>. 
If atoms is not specified, the program starts with no atoms and then performs 
stepwise addition of knots and atoms. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_maxatoms">maxatoms</code></td>
<td>

<p>maximum number of discrete components allowed in the model. Does not need to be 
specified, since the program has a default for <code>maxdim</code> and 
the number of dimensions equals the number of knots plus the number of 
atoms. If <code>maxatoms = 0</code> a continuous 
spectral distribution is fit. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_maxdim">maxdim</code></td>
<td>

<p>maximum number of basis 
functions allowed in the model (default is 
<code class="reqn">\max(15,4\times\mbox{length(period)}^{0.2})</code>). 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_odd">odd</code></td>
<td>

<p>see <code>period</code>. If <code>period</code> is not specified, <code>odd</code> is not relevant. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_updown">updown</code></td>
<td>

<p>the maximal number of times that <code>lspec</code> should go through a cycle of stepwise 
addition and stepwise deletion until a stable solution is reached. 
</p>
</td></tr>
<tr><td><code id="lspec_+3A_silent">silent</code></td>
<td>

<p>should printing of information be suppressed?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>lspec</code>.
The output is organized to serve as input for <code><a href="#topic+plot.lspec">plot.lspec</a></code>
(summary plots),
<code><a href="#topic+summary.lspec">summary.lspec</a></code> (summarizes fitting), <code><a href="#topic+clspec">clspec</a></code> (for
autocorrelations and autocovariances), <code><a href="#topic+dlspec">dlspec</a></code> (for spectral density and line-spectrum,) 
<code><a href="#topic+plspec">plspec</a></code> (for the spectral distribution), and <code><a href="#topic+rlspec">rlspec</a></code>
(for random time series with the same spectrum).
</p>
<table>
<tr><td><code>call</code></td>
<td>

<p>the command that was executed. 
</p>
</td></tr>
<tr><td><code>thetap</code></td>
<td>

<p>coefficients of the polynomial part of the spline. 
</p>
</td></tr>
<tr><td><code>nknots</code></td>
<td>

<p>the number of knots that were retained. 
</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>

<p>vector of the locations of the knots in the logspline model. 
Only the knots that were retained are in this vector.  
</p>
</td></tr>
<tr><td><code>thetak</code></td>
<td>

<p>coefficients of the knot part of the 
spline. The k-th coefficient is the coefficient 
of  <code class="reqn">(x-t(k))^3_+</code>. 
</p>
</td></tr>
<tr><td><code>natoms</code></td>
<td>

<p>the number of atoms that were retained. 
</p>
</td></tr>
<tr><td><code>atoms</code></td>
<td>

<p>vector of the locations of the atoms in the model. 
Only the atoms that were retained are in this vector.  
</p>
</td></tr>
<tr><td><code>mass</code></td>
<td>

<p>The k-th coefficient is the mass at <code>atom[k]</code>. 
</p>
</td></tr>
<tr><td><code>logl</code></td>
<td>

<p>the log-likelihood of the model. 
</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>

<p>the penalty that was used. 
</p>
</td></tr>
<tr><td><code>minmass</code></td>
<td>

<p>the minimum mass for an atom that was allowed. 
</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>

<p>the sample size that was used, either computed as <code>length(data)</code> or 
as <code>(2 * length(period))</code>  when <code>odd = FALSE</code> or as
<code>(2 * length(period) + 1)</code>  when <code>odd = TRUE</code>. 
</p>
</td></tr>
<tr><td><code>updown</code></td>
<td>

<p>the actual number of times that <code>lspec</code> went through a cycle of  
stepwise addition and stepwise  deletion  
until a stable solution was reached, or 
minus the number of times that lspec went through a cycle of  
stepwise addition and stepwise  deletion until it decided to quit. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone, and Young K. Truong (1995).
Logspline Estimation of a Possibly Mixed Spectral Distribution.
<em>Journal of Time Series Analysis</em>, <b>16</b>, 359-388.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.lspec">plot.lspec</a></code>, <code><a href="#topic+summary.lspec">summary.lspec</a></code>, <code><a href="#topic+clspec">clspec</a></code>, <code><a href="#topic+dlspec">dlspec</a></code>,
<code><a href="#topic+plspec">plspec</a></code>, <code><a href="#topic+rlspec">rlspec</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(co2)
co2.detrend &lt;- unstrip(lm(co2~c(1:length(co2)))$residuals)
fit &lt;- lspec(co2.detrend)
</code></pre>

<hr>
<h2 id='oldlogspline'> Logspline Density Estimation - 1992 version </h2><span id='topic+oldlogspline'></span>

<h3>Description</h3>

<p>Fits a <code>logspline</code> density using splines to approximate the log-density
using 
the 1992 knot deletion algorithm (<code><a href="#topic+oldlogspline">oldlogspline</a></code>). 
The 1997 algorithm using knot
deletion and addition is available using the <code><a href="#topic+logspline">logspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oldlogspline(uncensored, right, left, interval, lbound,
ubound, nknots, knots, penalty, delete = TRUE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oldlogspline_+3A_uncensored">uncensored</code></td>
<td>

<p>vector of uncensored observations from the distribution whose density is 
to be estimated. If there are no uncensored observations, this argument can 
be omitted. However, either <code>uncensored</code> or <code>interval</code> must be specified. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_right">right</code></td>
<td>

<p>vector of right censored observations from the distribution 
whose density is to be estimated. If there are no right censored 
observations, this argument can be omitted. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_left">left</code></td>
<td>

<p>vector of left censored observations from the distribution 
whose density is to be estimated. If there are no left censored 
observations, this argument can be omitted. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_interval">interval</code></td>
<td>

<p>two column matrix of lower and upper bounds of observations 
that are interval censored from the distribution whose density is 
to be estimated. If there are no interval censored observations, this 
argument can be omitted. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_lbound">lbound</code>, <code id="oldlogspline_+3A_ubound">ubound</code></td>
<td>

<p>lower/upper bound for the support of the density. For example, if there 
is a priori knowledge that the density equals zero to the left of 0, 
and has a discontinuity at 0, 
the user could specify <code>lbound = 0</code>. However, if the density is  
essentially zero near 0, one does not need to specify <code>lbound</code>. The
default for <code>lbound</code> is <code>-inf</code> and the default for
<code>ubound</code> is <code>inf</code>.
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_nknots">nknots</code></td>
<td>

<p>forces the method to start with nknots knots (<code>delete = TRUE</code>) or to fit a 
density with nknots knots (<code>delete = FALSE</code>). The method has an automatic rule 
for selecting nknots if this parameter is not specified. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_knots">knots</code></td>
<td>

<p>ordered vector of values (that should cover the complete range of the 
observations), which forces the method to start with these knots (<code>delete = TRUE</code>)
or to fit a density with these knots <code>delete = FALSE</code>). Overrules <code>nknots</code>. 
If <code>knots</code> is not specified, a default knot-placement rule is employed. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_penalty">penalty</code></td>
<td>

<p>the parameter to be used in the AIC criterion. The method chooses 
the number of knots that minimizes <code>-2 * loglikelihood + penalty * (number of knots - 1)</code>. 
The default is to use  a penalty parameter of <code>penalty = log(samplesize)</code> as in BIC. The effect of 
this parameter is summarized in <code><a href="#topic+summary.oldlogspline">summary.oldlogspline</a></code>. 
</p>
</td></tr>
<tr><td><code id="oldlogspline_+3A_delete">delete</code></td>
<td>

<p>should stepwise knot deletion be employed? 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of the class <code>oldlogspline</code>, that is intended as input for
<code><a href="#topic+plot.oldlogspline">plot.oldlogspline</a></code>, 
<code><a href="#topic+summary.oldlogspline">summary.oldlogspline</a></code>, 
<code><a href="#topic+doldlogspline">doldlogspline</a></code> (densities), 
<code><a href="#topic+poldlogspline">poldlogspline</a></code> (probabilities),<br />
<code><a href="#topic+qoldlogspline">qoldlogspline</a></code> (quantiles),
<code><a href="#topic+roldlogspline">roldlogspline</a></code> (random numbers from the fitted distribution).
The function <code><a href="#topic+oldlogspline.to.logspline">oldlogspline.to.logspline</a></code> can translate an object of the class
<code>oldlogspline</code> to an object of the class <code>logspline</code>.
</p>
<p>The object has the following members: 
</p>
<table>
<tr><td><code>call</code></td>
<td>

<p>the command that was executed. 
</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>

<p>vector of the locations of the knots in the <code>oldlogspline</code> model. 
old
</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>

<p>coefficients of the spline. The first coefficient is the constant term, 
the second is the linear term and the k-th <code class="reqn">(k&gt;2)</code> is the coefficient 
of <code class="reqn">(x-t(k-2))^3_+</code> (where <code class="reqn">x^3_+</code> means the positive part of the third power
of <code class="reqn">x</code>, 
and <code class="reqn">t(k-2)</code> means knot <code class="reqn">k-2</code>). If a coefficient is zero the corresponding 
knot was deleted from the model. 
</p>
</td></tr>
<tr><td><code>bound</code></td>
<td>

<p>first element: 0 - <code>lbound</code> was <code class="reqn">-\inf</code> 1 it was something else; second 
element: <code>lbound</code>, if specified; third element: 0 - <code>ubound</code> was <code class="reqn">\inf</code>, 
1 it was something else; fourth element: <code>ubound</code>, if specified. 
</p>
</td></tr>
<tr><td><code>logl</code></td>
<td>

<p>the <code>k</code>-th element is the log-likelihood of the fit with <code>k+2</code> knots. 
</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>

<p>the penalty that was used. 
</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>

<p>the sample size that was used. 
</p>
</td></tr>
<tr><td><code>delete</code></td>
<td>

<p>was stepwise knot deletion employed? 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+logspline">logspline</a></code>,      
<code><a href="#topic+oldlogspline">oldlogspline</a></code>,
<code><a href="#topic+plot.oldlogspline">plot.oldlogspline</a></code>,
<code><a href="#topic+summary.oldlogspline">summary.oldlogspline</a></code>,<br />
<code><a href="#topic+doldlogspline">doldlogspline</a></code>,
<code><a href="#topic+poldlogspline">poldlogspline</a></code>,
<code><a href="#topic+qoldlogspline">qoldlogspline</a></code>,
<code><a href="#topic+roldlogspline">roldlogspline</a></code>,
<code><a href="#topic+oldlogspline.to.logspline">oldlogspline.to.logspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># A simple example
y &lt;- rnorm(100)
fit &lt;- oldlogspline(y)       
plot(fit)
# An example involving censoring and a lower bound
y &lt;- rlnorm(1000)
censoring &lt;- rexp(1000) * 4
delta &lt;- 1 * (y &lt;= censoring)
y[delta == 0] &lt;- censoring[delta == 0]
fit &lt;- oldlogspline(y[delta == 1], y[delta == 0], lbound = 0)
</code></pre>

<hr>
<h2 id='oldlogspline.to.logspline'>Logspline Density Estimation - 1992 to 1997 version </h2><span id='topic+oldlogspline.to.logspline'></span>

<h3>Description</h3>

<p>Translates an <code>oldlogspline</code> object in an
<code>logspline</code> object. This routine is mostly used in <code>logspline</code>,
as it allows the routine to use <code>oldlogspline</code> for some situations
where <code>logspline</code> crashes. The other use is when you have censored data,
and thus have to use <code>oldlogspline</code> to fit, but wish to use the
auxiliary routines from <code>logspline</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>oldlogspline.to.logspline(obj, data) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oldlogspline.to.logspline_+3A_obj">obj</code></td>
<td>

<p>object of class <code>logspline</code>
</p>
</td></tr>
<tr><td><code id="oldlogspline.to.logspline_+3A_data">data</code></td>
<td>

<p>the original data. Used to compute the <code>range</code> component of the
new object. if <code>data</code> is not available, the 1/(n+1) and n/(n+1)
quantiles of the fitted distribution are used for <code>range</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> object of the class <code>logspline</code>. The <code>call</code> component
of the new object is not useful. The <code>delete</code> component of the old
object is ignored.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspline">logspline</a></code>,
<code><a href="#topic+oldlogspline">oldlogspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
fit.old &lt;- oldlogspline(x)
fit.translate &lt;- oldlogspline.to.logspline(fit.old,x)
fit.new &lt;- logspline(x)
plot(fit.new)
plot(fit.old,add=TRUE,col=2)
#
# should look almost the same, the differences are the
# different fitting routines
#
</code></pre>

<hr>
<h2 id='persp.polymars'>Polymars: multivariate adaptive polynomial spline regression</h2><span id='topic+persp.polymars'></span>

<h3>Description</h3>

<p>This function is not intended for direct use. It is called
by <code><a href="#topic+plot.polymars">plot.polymars</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polymars'
persp(x, predictor1, predictor2, response, n = 33,
xlim, ylim, xx, contour.polymars, main, intercept, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="persp.polymars_+3A_x">x</code>, <code id="persp.polymars_+3A_predictor1">predictor1</code>, <code id="persp.polymars_+3A_predictor2">predictor2</code></td>
<td>
<p>this function is not intended to be called directly.</p>
</td></tr>
<tr><td><code id="persp.polymars_+3A_response">response</code>, <code id="persp.polymars_+3A_n">n</code>, <code id="persp.polymars_+3A_xlim">xlim</code>, <code id="persp.polymars_+3A_ylim">ylim</code></td>
<td>
<p>this function is not intended to be called directly.</p>
</td></tr>
<tr><td><code id="persp.polymars_+3A_xx">xx</code>, <code id="persp.polymars_+3A_contour.polymars">contour.polymars</code></td>
<td>
<p>this function is not intended to be called directly.</p>
</td></tr>
<tr><td><code id="persp.polymars_+3A_main">main</code>, <code id="persp.polymars_+3A_intercept">intercept</code>, <code id="persp.polymars_+3A_...">...</code></td>
<td>
<p>this function is not intended to be called directly.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a 3-d contour or perspective plot. It is intended
to be called by <code><a href="#topic+plot.polymars">plot.polymars</a></code>.</p>


<h3>Author(s)</h3>

<p>Martin O'Connor.</p>


<h3>References</h3>

<p>Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polymars">polymars</a></code>, 
<code><a href="#topic+plot.polymars">plot.polymars</a></code>.</p>

<hr>
<h2 id='plot.hare'>Hare: hazard regression</h2><span id='topic+plot.hare'></span>

<h3>Description</h3>

<p>Plots a density, distribution function, hazard 
function or survival function for
a <code>hare</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hare'
plot(x, cov, n = 100, which = 0, what = "d", time, add = FALSE, xlim,
xlab, ylab, type, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hare_+3A_x">x</code></td>
<td>
<p><code>hare</code> object, typically the result of <code><a href="#topic+hare">hare</a></code>.  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_cov">cov</code></td>
<td>
<p>a vector of length <code>fit\$ncov</code>, indicating for which combination of  
covariates the plot should be made. Can be omitted only if <code>fit\$ncov</code> is 0.  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_n">n</code></td>
<td>
<p>the number of equally spaced points at which to plot the function.  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_which">which</code></td>
<td>
<p>for which coordinate should the plot be made. 0: time; positive value 
i: covariate i. Note that if which is the positive value i, then the 
element corresponding to this covariate must be given in <code>cov</code> even 
though its actual value is irrelevant.  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_what">what</code></td>
<td>

<p>what should be plotted: <code>"d"</code> (density), <code>"p"</code> (distribution function), <code>"s"</code> (survival 
function) or <code>"h"</code> (hazard function).  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_time">time</code></td>
<td>
<p>if which is not equal to 0, the value of time for which the plot should be made.  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_add">add</code></td>
<td>
<p>should the plot be added to an existing plot?  </p>
</td></tr>
<tr><td><code id="plot.hare_+3A_xlim">xlim</code></td>
<td>
<p>plotting limits; default is from the maximum of 0 
and 10% before the 1st percentile
to  the minimmum of
10% further than the 99th percentile and the largest observation.</p>
</td></tr>
<tr><td><code id="plot.hare_+3A_xlab">xlab</code>, <code id="plot.hare_+3A_ylab">ylab</code></td>
<td>
<p>labels for the axes. Per default no labels are printed.</p>
</td></tr>
<tr><td><code id="plot.hare_+3A_type">type</code></td>
<td>
<p>plotting type. The default is lines.</p>
</td></tr>
<tr><td><code id="plot.hare_+3A_...">...</code></td>
<td>
<p>all other plotting options are passed on.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a plot of a <code><a href="#topic+hare">hare</a></code> fit at <code>n</code> equally 
spaced points roughly covering the support of the density. (Use 
<code>xlim=c(from,to)</code> to change the range of these points.) 
</p>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+hare">hare</a></code>,
<code><a href="#topic+summary.hare">summary.hare</a></code>,
<code><a href="#topic+dhare">dhare</a></code>,
<code><a href="#topic+hhare">hhare</a></code>,
<code><a href="#topic+phare">phare</a></code>,
<code><a href="#topic+qhare">qhare</a></code>,
<code><a href="#topic+rhare">rhare</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- hare(testhare[,1], testhare[,2], testhare[,3:8])       
# hazard curve for covariates like case 1 
plot(fit, testhare[1,3:8], what = "h") 
# survival function as a function of covariate 2, for covariates as case 1 at t=3 
plot(fit, testhare[1,3:8], which = 2, what = "s",  time = 3)  
</code></pre>

<hr>
<h2 id='plot.heft'>Heft: hazard estimation with flexible tails</h2><span id='topic+plot.heft'></span>

<h3>Description</h3>

<p>Plots a density, distribution function, hazard
function or survival function for
a <code>heft</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'heft'
plot(x, n = 100, what = "d", add = FALSE, xlim, xlab, ylab,
type, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.heft_+3A_x">x</code></td>
<td>
<p><code>heft</code> object, typically the result of <code><a href="#topic+heft">heft</a></code>.  </p>
</td></tr>
<tr><td><code id="plot.heft_+3A_n">n</code></td>
<td>
<p>the number of equally spaced points at which to plot the function.  </p>
</td></tr>
<tr><td><code id="plot.heft_+3A_what">what</code></td>
<td>

<p>what should be plotted: <code>"d"</code> (density), <code>"p"</code> (distribution function), <code>"s"</code> (survival
function) or <code>"h"</code> (hazard function).  </p>
</td></tr>
<tr><td><code id="plot.heft_+3A_add">add</code></td>
<td>
<p>should the plot be added to an existing plot?  </p>
</td></tr>
<tr><td><code id="plot.heft_+3A_xlim">xlim</code></td>
<td>
<p>plotting limits; default is from the maximum of 0
and 10% before the 1st percentile
to  the minimmum of
10% further than the 99th percentile and the largest observation.</p>
</td></tr>
<tr><td><code id="plot.heft_+3A_xlab">xlab</code>, <code id="plot.heft_+3A_ylab">ylab</code></td>
<td>
<p>labels for the axes. The default is no labels.</p>
</td></tr>
<tr><td><code id="plot.heft_+3A_type">type</code></td>
<td>
<p>plotting type. The default is lines.</p>
</td></tr>
<tr><td><code id="plot.heft_+3A_...">...</code></td>
<td>
<p>all other plotting options are passed on.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a plot of a <code><a href="#topic+heft">heft</a></code> fit at <code>n</code> equally
spaced points roughly covering the support of the density. (Use
<code>xlim=c(from,to)</code> to change the range of these points.)
</p>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+heft">heft</a></code>,
<code><a href="#topic+summary.heft">summary.heft</a></code>,
<code><a href="#topic+dheft">dheft</a></code>,
<code><a href="#topic+hheft">hheft</a></code>,
<code><a href="#topic+pheft">pheft</a></code>,
<code><a href="#topic+qheft">qheft</a></code>,
<code><a href="#topic+rheft">rheft</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- heft(testhare[,1], testhare[,2])
plot(fit1, what = "h")
# modify tail behavior
fit2 &lt;- heft(testhare[,1], testhare[,2], leftlog = FALSE, rightlog = FALSE, 
    leftlin = TRUE)   
plot(fit2, what = "h", add = TRUE,lty = 2)
fit3 &lt;- heft(testhare[,1], testhare[,2], penalty = 0)   # select largest model
plot(fit3, what = "h", add = TRUE,lty = 3)
</code></pre>

<hr>
<h2 id='plot.logspline'>Logspline Density Estimation </h2><span id='topic+plot.logspline'></span>

<h3>Description</h3>

<p>Plots a <code>logspline</code> density, distribution function, hazard 
function or survival function 
from 
a logspline density that was fitted using
the 1997 knot addition and deletion algorithm (<code><a href="#topic+logspline">logspline</a></code>). 
The 1992 algorithm is available using the <code><a href="#topic+oldlogspline">oldlogspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logspline'
plot(x, n = 100, what = "d", add = FALSE, xlim, xlab = "",
ylab = "", type = "l", ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.logspline_+3A_x">x</code></td>
<td>
<p><code>logspline</code> object, typically the result of <code><a href="#topic+logspline">logspline</a></code>.</p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_n">n</code></td>
<td>
<p>the number of equally spaced points at which to plot the density.  </p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_what">what</code></td>
<td>
<p>what should be plotted: 
<code>"d"</code> (density), <code>"p"</code> (distribution function), <code>"s"</code> (survival 
function) or <code>"h"</code> (hazard function).  </p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_add">add</code></td>
<td>
<p>should the plot be added to an existing plot.</p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_xlim">xlim</code></td>
<td>

<p>range of data on which to plot. Default is from the 1th to the 99th percentile of
the density, extended by 10% on each end.</p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_xlab">xlab</code>, <code id="plot.logspline_+3A_ylab">ylab</code></td>
<td>
<p>labels plotted on the axes.  </p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_type">type</code></td>
<td>
<p>type of plot.</p>
</td></tr>
<tr><td><code id="plot.logspline_+3A_...">...</code></td>
<td>
<p>other plotting options, as desired</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a plot of a <code><a href="#topic+logspline">logspline</a></code> fit at <code>n</code> equally 
spaced points roughly covering the support of the density. (Use 
<code>xlim = c(from, to)</code> to change the range of these points.) 
</p>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspline">logspline</a></code>,      
<code><a href="#topic+summary.logspline">summary.logspline</a></code>,
<code><a href="#topic+dlogspline">dlogspline</a></code>,
<code><a href="#topic+plogspline">plogspline</a></code>,
<code><a href="#topic+qlogspline">qlogspline</a></code>,
<code><a href="#topic+rlogspline">rlogspline</a></code>,
</p>
<p><code><a href="#topic+oldlogspline">oldlogspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
fit &lt;- logspline(y)       
plot(fit) 
</code></pre>

<hr>
<h2 id='plot.lspec'>Lspec: logspline estimation of a spectral distribution</h2><span id='topic+plot.lspec'></span>

<h3>Description</h3>

<p>Plots a spectral density function,
line spectrum, or spectral distribution from a model fitted with <code><a href="#topic+lspec">lspec</a></code> </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lspec'
plot(x, what = "b", n, add = FALSE, xlim, ylim, xlab = "", ylab = "",
type, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lspec_+3A_x">x</code></td>
<td>
<p><code>lspec</code> object, typically the result of <code><a href="#topic+lspec">lspec</a></code>.</p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_what">what</code></td>
<td>
<p>what should be plotted: b (spectral density and line spectrum 
superimposed), d (spectral density function), 
l (line spectrum)  or p  (spectral distribution function).  </p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_n">n</code></td>
<td>
<p>the number of equally spaced points at which to plot the fit;  default is <code>max(100,fit\$sample)</code>.  </p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_add">add</code></td>
<td>
<p>indicate that the plot should be added to an existing plot.  </p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_xlim">xlim</code></td>
<td>
<p>X-axis plotting limits: default is <code class="reqn">c(0,\pi)</code>, except
when what = &quot;p&quot;, when the default is <code class="reqn">c(-\pi,\pi)</code>.</p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_ylim">ylim</code></td>
<td>
<p>Y-axis plotting limits.</p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_xlab">xlab</code>, <code id="plot.lspec_+3A_ylab">ylab</code></td>
<td>
<p>axis labels.</p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_type">type</code></td>
<td>
<p>plotting type; default is <code>"l"</code> when <code>what = "d"</code>
and <code>what = "p"</code>, <code>"h"</code> when <code>what = "l"</code>, and
a combination of <code>"h"</code> and <code>"l"</code> when <code>what ="b"</code></p>
</td></tr>
<tr><td><code id="plot.lspec_+3A_...">...</code></td>
<td>
<p>all regular plotting options are passed on.  </p>
</td></tr>
</table>


<h3>Note</h3>

<p>If <code>what = "p"</code> 
the plotting range cannot extend beyond the interval <code class="reqn">[-\pi,\pi]</code>.  </p>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone, and Young K. Truong (1995).
Logspline Estimation of a Possibly Mixed Spectral Distribution.
<em>Journal of Time Series Analysis</em>, <b>16</b>, 359-388.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+lspec">lspec</a></code>, <code><a href="#topic+summary.lspec">summary.lspec</a></code>, <code><a href="#topic+clspec">clspec</a></code>, <code><a href="#topic+dlspec">dlspec</a></code>,
<code><a href="#topic+plspec">plspec</a></code>, <code><a href="#topic+rlspec">rlspec</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(co2)
co2.detrend &lt;- lm(co2~c(1:length(co2)))$residuals
fit &lt;- lspec(co2.detrend)
plot(fit)
</code></pre>

<hr>
<h2 id='plot.oldlogspline'>Logspline Density Estimation - 1992 version </h2><span id='topic+plot.oldlogspline'></span>

<h3>Description</h3>

<p>Plots an <code>oldlogspline</code> density, distribution function, hazard 
function or survival function 
from 
a logspline density that was fitted using
the 1992 knot deletion algorithm.
The 1997 algorithm using knot
deletion and addition is available using the <code><a href="#topic+logspline">logspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oldlogspline'
plot(x, n = 100, what = "d", xlim, xlab = "", ylab = "",
type = "l", add = FALSE, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.oldlogspline_+3A_x">x</code></td>
<td>
<p><code>logspline</code> object, typically the result of <code><a href="#topic+logspline">logspline</a></code>.</p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_n">n</code></td>
<td>
<p>the number of equally spaced points at which to plot the density.  </p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_what">what</code></td>
<td>
<p>what should be plotted: 
<code>"d"</code> (density), <code>"p"</code> (distribution function), <code>"s"</code> (survival 
function) or <code>"h"</code> (hazard function).  </p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_xlim">xlim</code></td>
<td>

<p>range of data on which to plot. Default is from the 1th to the 99th percentile of
the density, extended by 10% on each end.</p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_xlab">xlab</code>, <code id="plot.oldlogspline_+3A_ylab">ylab</code></td>
<td>
<p>labels plotted on the axes.  </p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_type">type</code></td>
<td>
<p>type of plot.</p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_add">add</code></td>
<td>
<p>should the plot be added to an existing plot.</p>
</td></tr>
<tr><td><code id="plot.oldlogspline_+3A_...">...</code></td>
<td>
<p>other plotting options, as desired</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a plot of a <code><a href="#topic+oldlogspline">oldlogspline</a></code> fit at <code>n</code> equally
spaced points roughly covering the support of the density. (Use
<code>xlim=c(from,to)</code> to change the range of these points.)
</p>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspline">logspline</a></code>,
<code><a href="#topic+oldlogspline">oldlogspline</a></code>,
<code><a href="#topic+summary.oldlogspline">summary.oldlogspline</a></code>,
<code><a href="#topic+doldlogspline">doldlogspline</a></code>,
<code><a href="#topic+poldlogspline">poldlogspline</a></code>,<br />
<code><a href="#topic+qoldlogspline">qoldlogspline</a></code>,
<code><a href="#topic+roldlogspline">roldlogspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
fit &lt;- oldlogspline(y)       
plot(fit) 
</code></pre>

<hr>
<h2 id='plot.polyclass'>Polyclass: polychotomous regression and multiple classification</h2><span id='topic+plot.polyclass'></span>

<h3>Description</h3>

<p>Probability or classification plots for a  <code><a href="#topic+polyclass">polyclass</a></code> model.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polyclass'
plot(x, cov, which, lims, what, data, n, xlab="", ylab="",
zlab="", ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.polyclass_+3A_x">x</code></td>
<td>
<p><code>polyclass</code> object, typically the result of <code><a href="#topic+polyclass">polyclass</a></code>. </p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_cov">cov</code></td>
<td>

<p>a vector of length <code>fit\$ncov</code>, indicating for which combination of  
covariates the plot should be made. Can never be omitted. Should always have 
length <code>fit\$ncov</code>, even if some values are irrelevant.  </p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_which">which</code></td>
<td>

<p>for which covariates should the plot be made.  
Number or a character string defining the name, if the 
same names were used with the call to <code><a href="#topic+polyclass">polyclass</a></code>. Which should have length one if 
<code>what</code> is 6 or larger and length two if <code>what</code> is 5 or smaller.  </p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_lims">lims</code></td>
<td>
<p>plotting limits. If omitted, the plot is made over the same range 
of the covariate as in the original data. Otherwise a vector of 
length two of the form <code>c(min, max)</code> if what is 6 or larger and a vector of 
length four of the form <code>c(xmin, xmax, ymin ,ymax)</code> if <code>what</code> is 5 or smaller.  </p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_what">what</code></td>
<td>

<p>an integer between 1 and 8, defining the type of plot to be made. 
</p>

<ol>
<li><p> Plots the probability of one class as a contour plot of two variables. 
</p>
</li>
<li><p> Plots the probability of one class as a perspective plot of two variables. 
</p>
</li>
<li><p> Plots the probability of one class as an image plot of two variables. 
</p>
</li>
<li><p> Classifies the area as a contour plot of two variables. 
</p>
</li>
<li><p> Classifies the area as an image plot of two variables. 
</p>
</li>
<li><p> Classifies the line as a plot of one variable. 
</p>
</li>
<li><p> Plots the probabilities of all classes as a function of one variable. 
</p>
</li>
<li><p> Plots the probability of one class as a function of one variable. 
</p>
</li></ol>

</td></tr>
<tr><td><code id="plot.polyclass_+3A_data">data</code></td>
<td>
<p>Class for which the plot is made. Should be provided if <code>what</code> is 1, 2, 3 or 8.  </p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_n">n</code></td>
<td>

<p>the number of equally spaced points at which to plot the fit. The 
default is 250 if <code>what</code> is 6 or larger or 50 (which results in 2500 plotting 
points) if <code>what</code> is 5 or smaller. 
</p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_xlab">xlab</code>, <code id="plot.polyclass_+3A_ylab">ylab</code>, <code id="plot.polyclass_+3A_zlab">zlab</code></td>
<td>
<p>axis plotting labels.</p>
</td></tr>
<tr><td><code id="plot.polyclass_+3A_...">...</code></td>
<td>

<p>all other options are passed on.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyclass">polyclass</a></code>,
<code><a href="#topic+summary.polyclass">summary.polyclass</a></code>,
<code><a href="#topic+beta.polyclass">beta.polyclass</a></code>,
<code><a href="#topic+cpolyclass">cpolyclass</a></code>,
<code><a href="#topic+ppolyclass">ppolyclass</a></code>,
<code><a href="#topic+rpolyclass">rpolyclass</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
fit.iris &lt;- polyclass(iris[,5], iris[,1:4])
plot(fit.iris, iris[64,1:4], which=c(3,4), data=2, what=1) 
plot(fit.iris,iris[64,1:4], which=c(3,4), what=5) 
plot(fit.iris,iris[64,1:4], which=4, what=7) 
</code></pre>

<hr>
<h2 id='plot.polymars'>Polymars: multivariate adaptive polynomial spline regression</h2><span id='topic+plot.polymars'></span>

<h3>Description</h3>

<p>Produces two and three dimensional plots of the 
fitted values from a <code>polymars</code> object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polymars'
plot(x, predictor1, response, predictor2, xx, add = FALSE, n,
xyz = FALSE, contour.polymars = FALSE, xlim, ylim, intercept, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.polymars_+3A_x">x</code></td>
<td>
<p><code>polymars</code> object, typically the result of <code><a href="#topic+polymars">polymars</a></code>. </p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_predictor1">predictor1</code></td>
<td>
<p>the index of a predictor that was used when the <code>polymars</code> model was fit. 
For the two dimensional plots, this variable is plotted along the X-axis.  </p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_response">response</code></td>
<td>

<p>if the model was fitted to multiple response data the response index 
should be specified. </p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_predictor2">predictor2</code></td>
<td>

<p>the index of a predictor that was used when the <code>polymars</code> model was fit. For the three  
dimensional plots, this variable is plotted along the Y-axis.   
See <code>xyz</code>. 
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_xx">xx</code></td>
<td>

<p>should be a vector of length equal to the number of predictors in the  
original data set. The values should be in the same order as in the original  
dataset. By default the function uses the median values of the data that was  
used to fit the model.  Although the values for predictor and predictor2 are  
not used, they should still be provided as part of <code>xx</code>. 
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_add">add</code></td>
<td>

<p>should the plot be added to a previously created plot? Works only for two 
dimensional plots. 
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_n">n</code></td>
<td>

<p>number of plotting points (2 dimensional plot) or plotting points along each 
axis (3 dimensional plot). The default is <code>n = 100</code> for 2 dimensional plots and 
<code>n = 33</code> for 3 dimensional plots. 
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_xyz">xyz</code></td>
<td>

<p>is the plot being made a 3 dimensional plot? 
If there is only one response it need not be set, if two numerical values  
accompany the model in the call they will be understood as two predictors 
for a 3-d plot. By default a 3-d plot uses the <code><a href="graphics.html#topic+persp">persp</a></code> function. 
Categorical predictors cannot be used for 3 dimensional plots. 
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_contour.polymars">contour.polymars</code></td>
<td>

<p>if the plot being made a 3 dimensional plot should it be made as a contour plot 
(<code>TRUE</code>) or a perspective plot (<code>FALSE</code>).
function <a href="graphics.html#topic+contour">contour</a> is being made. 
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_intercept">intercept</code></td>
<td>

<p>Setting intercept equal to <code>FALSE</code> evaluates the object without intercept. The  
intercept may also be given any numerical value which overrides the fitted  
coefficient from the object. The default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_xlim">xlim</code>, <code id="plot.polymars_+3A_ylim">ylim</code></td>
<td>
<p>Plotting limits. The function tries to choose intelligent limits itself</p>
</td></tr>
<tr><td><code id="plot.polymars_+3A_...">...</code></td>
<td>

<p>other options are passed on.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a 2-d plot of 1 predictor and response of a <code>polymars</code> object
at n equally spaced points or a 3-d plot of two predictors and response of a 
<code>polymars</code> object.  The range of the plot is by default equal to the range of the 
particular predictor(s) in the original data, but this can be changed by  
<code>xlim = c(from, to)</code> and
<code>ylim = c(from, to)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin O'Connor.</p>


<h3>References</h3>

<p>Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+design.polymars">design.polymars</a></code>,
<code><a href="#topic+polymars">polymars</a></code>,
<code><a href="#topic+predict.polymars">predict.polymars</a></code>,
<code><a href="#topic+summary.polymars">summary.polymars</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(state)
state.pm &lt;- polymars(state.region, state.x77, knots = 15, classify = TRUE, gcv = 1)
plot(state.pm, 3, 4)
</code></pre>

<hr>
<h2 id='polyclass'>Polyclass: polychotomous regression and multiple classification</h2><span id='topic+polyclass'></span>

<h3>Description</h3>

<p>Fit a polychotomous regression and multiple classification 
using linear splines and selected tensor products.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>polyclass(data, cov, weight, penalty, maxdim, exclude, include,
additive = FALSE, linear, delete = 2, fit,  silent = TRUE, 
normweight = TRUE, tdata, tcov, tweight, cv, select, loss, seed) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polyclass_+3A_data">data</code></td>
<td>
<p>vector of classes:
<code>data</code> should ranges over consecutive integers with 0 or 1 as the minimum value. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_cov">cov</code></td>
<td>
<p>covariates: matrix with as many rows as the length of <code>data</code>.  </p>
</td></tr>
<tr><td><code id="polyclass_+3A_weight">weight</code></td>
<td>
<p>optional vector of case-weights.  Should have the same length as 
<code>data</code>.</p>
</td></tr>
<tr><td><code id="polyclass_+3A_penalty">penalty</code></td>
<td>

<p>the parameter to be used in the AIC criterion if the 
model selection is carried out by AIC.  The program chooses 
the number of knots that minimizes <code>-2 * loglikelihood + penalty * (dimension)</code>. 
The default is to use <code>penalty = log(length(data))</code> as in BIC. If the model 
selection is carried out by cross-validation or using a test set, the 
program uses the number of knots that minimizes 
<code>loss + penalty * dimension * (loss for smallest model)</code>. In this case 
the default of <code>penalty</code> is 0. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_maxdim">maxdim</code></td>
<td>

<p>maximum dimension (default is 
<code class="reqn">\min(n, 4 * n^{1/3}*(cl-1)</code>, where 
<code class="reqn">n</code> is <code>length(data)</code> and
<code class="reqn">cl</code> the number of classes.
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_exclude">exclude</code></td>
<td>

<p>combinations to be excluded - this should be a matrix with 2 
columns - if for example <code>exclude[1, 1] = 2</code> and <code>exclude[1, 2] = 3</code> no 
interaction between covariate 2 and 3 is included. 0 represents time. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_include">include</code></td>
<td>

<p>those combinations that can be included. Should have the same format 
as <code>exclude</code>. Only one of <code>exclude</code> and <code>include</code> can be specified .
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_additive">additive</code></td>
<td>
<p>should the model selection be restricted to additive models?  </p>
</td></tr>
<tr><td><code id="polyclass_+3A_linear">linear</code></td>
<td>

<p>vector indicating for which of the variables no knots should 
be entered. For example, if <code>linear = c(2, 3)</code> no knots for either covariate 
2 or 3 are entered. 0 represents time. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_delete">delete</code></td>
<td>

<p>should complete basis functions be deleted at once (2), should 
only individual dimensions be deleted (1) or should only the addition 
stage of the model selection be carried out (0)? 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_fit">fit</code></td>
<td>

<p><code>polyclass</code> object. If  <code>fit</code> is specified, <code><a href="#topic+polyclass">polyclass</a></code> adds 
basis functions starting with those in <code>fit</code>. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_silent">silent</code></td>
<td>

<p>suppresses the printing of diagnostic output about basis functions added 
or deleted, Rao-statistics, Wald-statistics and log-likelihoods. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_normweight">normweight</code></td>
<td>

<p>should the weights be normalized so that they average to one? This option 
has only an effect if the model is selected using AIC. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_tdata">tdata</code>, <code id="polyclass_+3A_tcov">tcov</code>, <code id="polyclass_+3A_tweight">tweight</code></td>
<td>

<p>test set. Should satisfy the same requirements as <code>data</code>, <code>cov</code> and
<code>weight</code>. If 
all test set weights are one, <code>tweight</code> can be omitted. If <code>tdata</code> and <code>tcov</code> are 
specified, the model selection is carried out using this test set, irrespective 
of the input for <code>penalty</code> or <code>cv</code>. 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_cv">cv</code></td>
<td>

<p>in how many subsets should the data be divided for cross-validation? If <code>cv</code> is 
specified and tdata is omitted, the model selection is carried out by 
cross-validation.
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_select">select</code></td>
<td>

<p>if a test set is provided, or if the model is selected using cross validation, 
should the model be select that minimizes (misclassification) loss (0), that 
maximizes test set log-likelihood (1) or that minimizes test set 
squared error loss (2)? 
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_loss">loss</code></td>
<td>

<p>a rectangular matrix specifying the loss function, whose 
size is the number of 
classes times number of actions. 
Used for cross-validation and test set model 
selection. <code>loss[i, j]</code> contains the loss for 
assigning action <code>j</code>  to an object whose true class is <code>i</code>. 
The default is 1 minus the identity matrix. 
<code>loss</code> does not need to be square.
</p>
</td></tr>
<tr><td><code id="polyclass_+3A_seed">seed</code></td>
<td>

<p>optional 
seed for the random number generator that determines the sequence of the 
cases for cross-validation. If the seed has length 12 or more, 
the first twelve elements are assumed to be <code>.Random.seed</code>, otherwise 
the function <code><a href="base.html#topic+set.seed">set.seed</a></code> is used.  
If <code>seed</code> is 0 or <code>rep(0, 12)</code>, it is assumed that the user 
has already provided a (random) ordering. 
If <code>seed</code> is not provided, while a fit with 
an element <code>fit\$seed</code> is provided, 
<code>.Random.seed</code> is set using <code>set.seed(fit\$seed)</code>. Otherwise 
the present value of <code>.Random.seed</code> is used. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output is an object of class <code>polyclass</code>, organized
to serve as input for <code><a href="#topic+plot.polyclass">plot.polyclass</a></code>, 
<code><a href="#topic+beta.polyclass">beta.polyclass</a></code>,
<code><a href="#topic+summary.polyclass">summary.polyclass</a></code>, <code><a href="#topic+ppolyclass">ppolyclass</a></code> (fitted probabilities),
<code><a href="#topic+cpolyclass">cpolyclass</a></code> (fitted classes) and <code><a href="#topic+rpolyclass">rpolyclass</a></code> (random classes). 
The function returns a list with the following members: 
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the command that was executed.  </p>
</td></tr>
<tr><td><code>ncov</code></td>
<td>
<p>number of covariates.  </p>
</td></tr>
<tr><td><code>ndim</code></td>
<td>
<p>number of dimensions of the fitted model.  </p>
</td></tr>
<tr><td><code>nclass</code></td>
<td>
<p>number of classes.  </p>
</td></tr>
<tr><td><code>nbas</code></td>
<td>
<p>number of basis functions.  </p>
</td></tr>
<tr><td><code>naction</code></td>
<td>
<p>number of possible actions that are considered.  </p>
</td></tr>
<tr><td><code>fcts</code></td>
<td>
<p>matrix of size <code>nbas x (nclass + 4)</code>. each row is a basis function. 
First element: first covariate involved (<code>NA</code> = constant); 
</p>
<p>second element: which knot (<code>NA</code> means: constant or linear); 
</p>
<p>third element: second covariate involved (<code>NA</code> means: this is a function 
of one variable); 
</p>
<p>fourth element: knot involved (if the third element is <code>NA</code>, of no relevance); 
</p>
<p>fifth, sixth,...  element: beta (coefficient) for class one, two, ... 
</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>

<p>a matrix with <code>ncov</code> rows.
Covariate <code>i</code> has row <code>i+1</code>, time has row 1. 
First column: number of knots in this dimension;
other columns: the knots, appended with <code>NA</code>s to make it a matrix.
</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>

<p>in how many sets was the data divided for cross-validation. 
Only provided if <code>method = 2</code>. 
</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>

<p>the loss matrix used in cross-validation and test set. 
Only provided if <code>method = 1</code> or <code>method = 2</code>.
</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>

<p>the parameter used in the AIC criterion. Only provided if <code>method = 0</code>.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>0 = AIC, 1 = test set, 2 = cross-validation. 
</p>
</td></tr>
<tr><td><code>ranges</code></td>
<td>

<p>column <code>i</code> gives the range of the <code>i</code>-th covariate. 
</p>
</td></tr>
<tr><td><code>logl</code></td>
<td>

<p>matrix with eight or eleven columns. Summarizes fits. 
Column one indicates the dimension, column 
column two the AIC or loss value, whichever was 
used during the model selection 
appropriate, column three four and five give the training set log-likelihood, 
(misclassification) loss and squared error loss, columns six to 
eight give the same information for the test set, column nine (or column 
six if <code>method = 0</code> or <code>method = 2</code>) indicates whether the 
model was fitted during the addition stage (1) or during the deletion stage (0), 
column ten and eleven (or seven and eight) the minimum and maximum 
penalty parameter for which AIC would have selected this model. 
</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>sample size. 
</p>
</td></tr>
<tr><td><code>tsample</code></td>
<td>
<p>the sample size of the test set. Only prvided if <code>method = 1</code>.  </p>
</td></tr>
<tr><td><code>wgtsum</code></td>
<td>
<p>sum of the case weights.  </p>
</td></tr>
<tr><td><code>covnames</code></td>
<td>
<p>names of the covariates.  </p>
</td></tr>
<tr><td><code>classnames</code></td>
<td>
<p>(numerical) names of the classes.  </p>
</td></tr>
<tr><td><code>cv.aic</code></td>
<td>
<p>the penalty value that was determined optimal by 
by cross validation. Only provided if <code>method = 2</code>.  </p>
</td></tr>
<tr><td><code>cv.tab</code></td>
<td>
<p>table with three columns. Column one and two indicate the penalty parameter 
range for which the cv-loss in column three would be realized.  
Only provided if <code>method = 2</code>.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>the random seed that was used to determine the order 
of the cases for cross-validation. 
Only provided if <code>method = 2</code>.</p>
</td></tr>
<tr><td><code>delete</code></td>
<td>

<p>were complete basis functions deleted at once (2), were 
only individual dimensions deleted (1) or was only the addition 
stage of the model selection carried out (0)? 
</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>

<p>moments of basisfunctions. Needed for <code><a href="#topic+beta.polyclass">beta.polyclass</a></code>.
</p>
</td></tr>
<tr><td><code>select</code></td>
<td>

<p>if a test set is provided, or if the model is selected using cross validation, 
was the model selected that minimized (misclassification) loss (0), that 
maximized test set log-likelihood (1) or that minimized test set 
squared error loss (2)? 
</p>
</td></tr>
<tr><td><code>anova</code></td>
<td>

<p>matrix with three columns. The first two elements in a line 
indicate the subspace to which the line refers. The third element indicates 
the percentage of variance explained by that subspace. 
</p>
</td></tr>
<tr><td><code>twgtsum</code></td>
<td>

<p>sum of the test set case weights (only if <code>method = 1</code>). 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polymars">polymars</a></code>,
<code><a href="#topic+plot.polyclass">plot.polyclass</a></code>,
<code><a href="#topic+summary.polyclass">summary.polyclass</a></code>,
<code><a href="#topic+beta.polyclass">beta.polyclass</a></code>,
<code><a href="#topic+cpolyclass">cpolyclass</a></code>,<br />
<code><a href="#topic+ppolyclass">ppolyclass</a></code>,
<code><a href="#topic+rpolyclass">rpolyclass</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
fit.iris &lt;- polyclass(iris[,5], iris[,1:4])
</code></pre>

<hr>
<h2 id='polymars'>Polymars: multivariate adaptive polynomial spline regression</h2><span id='topic+polymars'></span>

<h3>Description</h3>

<p>An adaptive regression procedure using piecewise linear splines to model the response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polymars(responses, predictors, maxsize, gcv = 4, additive = FALSE, 
startmodel, weights, no.interact, knots, knot.space = 3, ts.resp, 
ts.pred, ts.weights, classify, factors, tolerance, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polymars_+3A_responses">responses</code></td>
<td>
<p>vector of responses, or a matrix for multiple response regression. 
In the case of a matrix each column corresponds to a response and each 
row corresponds to an observation. Missing values are not allowed. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_predictors">predictors</code></td>
<td>
<p>matrix of predictor variables for the regression. Each column corresponds to a 
predictor and each row corresponds to an observation in the same order as 
they appear in the response argument. Missing values are not allowed. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_maxsize">maxsize</code></td>
<td>
<p>the maximum number of basis functions that the model is allowed to grow to in 
the stepwise addition procedure. Default is 
<code class="reqn">\min(6*(n^{1/3}),n/4,100)</code>, where <code>n</code> is the number of observations. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_gcv">gcv</code></td>
<td>
<p>parameter used to find the overall best model from a sequence of fitted models. 
The residual sum of squares of a model is penalized by dividing by the square of   
<code>1-(gcv x model size)/cases</code>.   
A larger gcv value would tend to produce a smaller model.
Models for which <code>1-(gcv x model size)/cases</code> is smaller or equal than 0 are
never selected.
</p>
</td></tr>
<tr><td><code id="polymars_+3A_additive">additive</code></td>
<td>
<p>Should the fitted model be additive in the predictors? 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_startmodel">startmodel</code></td>
<td>
<p>the first model that is to be fit by <code>polymars</code>. It is either an 
object of the class <code>polymars</code> or a model dreamed up by the user.
In that case, 
it takes the form of a <code>4 x n</code> matrix, where 
<code>n</code> is the  number of basis functions in the starting model excluding
the intercept. Each row corresponds to one basis 
function (with two possible components). Column 1 is the index of the first 
predictor involved. Column 2 is a possible knot in this predictor. If column 
2 is <code>NA</code>, the first component is linear. Column 3 is the possible second 
predictor involved (if column 3 is <code>NA</code> the basis function only depends on one 
predictor). Column 4 contains the possible knot for the predictor in column 3, 
and it is <code>NA</code> when this component is linear.  Example: if a row reads 
<code>3 NA 2 4.7</code>, the corresponding basis function is <code class="reqn">[X_3 * (X_2-4.7)_+]</code>; if a row 
reads <code>2 4.3 NA NA</code> the corresponding basis function is <code class="reqn">[(X_2-4.3)_+]</code>. 
A fifth column can be added with 1s and 0s, The 1s specify which basis 
functions of the startmodel must be in each model. Thus, these 
functions stay in the model during the whole stepwise fitting procedure. 
If <code>startmodel</code> is not specified <code>polymars</code> starts with a model that only contains  
the intercept. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_weights">weights</code></td>
<td>
<p>optional vector of observation weights; if supplied, the algorithm fits to minimize the 
sum of the weights multiplied by the squared residuals.  The length of 
weights must be the same as the number of observations. The weights must 
be nonnegative. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_no.interact">no.interact</code></td>
<td>
<p>an optional matrix used if certain predictor interactions are not allowed in the model. 
It is given as a matrix of size <code>2 x m</code>, with predictor indices as entries.  The two 
predictors of any row cannot have interaction terms with each other. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_knots">knots</code></td>
<td>
<p>defines how the function is to find potential knots for the spline basis 
functions.  This can be set to the maximum number of knots you would 
like to be considered for each predictor. 
Usually, to avoid the design matrix becoming singular the actual number of 
knots produced is constrained to at most every third order statistic in any 
predictor. This constraint can be adjusted using the <code>knot.space</code> argument. 
It can also 
be a vector with the number of potential knots for each predictor. 
Again the actual number of knots produced is constrained to be at most every 
third order statistic any predictor.  
A third possibility is to provide a matrix where each columns corresponds 
to the ordered knots you would like to have considered for that predictor. 
This matrix should be filled out to a rectangular data structure with NAs. 
The default is <code>min(20, round(n/4))</code> knots per predictor. 
When specifying knots as a vector an entry of <code>-1</code> indicates that the predictor  
is a categorical variable and each unique entry in it's column is treated as a  
level. 
</p>
<p>When specifying knots as a single number or a matrix and there are categorical  
variables these are specified separately as such using the factor argument. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_knot.space">knot.space</code></td>
<td>

<p>is an integer describing the minimum number of order statistics apart that 
two knots can be. Knots should not be too close to insure numerical stability. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_ts.resp">ts.resp</code></td>
<td>

<p>testset responses for model selection. Should have the same number of columns 
as the training set response. A testset can be used for the model selection. 
Depending on the value of classify, either the model with the smallest testset 
residual sum of squares or the smallest testset classification error is 
provided.  Overrides <code>gcv</code>. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_ts.pred">ts.pred</code></td>
<td>

<p>testset predictors. Should have the same number of columns 
as the training set predictors. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_ts.weights">ts.weights</code></td>
<td>

<p>testset observation weights. A vector of length equal to the number of cases 
of the testset. All weights must be non-negative. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_classify">classify</code></td>
<td>

<p>when the response is discrete (categorical), polymars can be used for 
classification. In particular, when <code>classify = TRUE</code>, a discrete response 
with <code>K</code> levels is replaced by <code>K</code> indicator variables as response. Model 
selection is still being carried out using gcv, except when a testset is 
provided, in which case testset misclassification is used to select the best 
model. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_factors">factors</code></td>
<td>

<p>used to indicate that certain variables in the predictor set are categorical  
variables. Specified as a vector containing the appropriate predictor  
indices (column numbers of categorical variables in predictors matrix). Factors  
can also be set when the <code>knots</code> argument is given as a vector, with 
<code>-1</code> as  
the appropriate entries for factors. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_tolerance">tolerance</code></td>
<td>

<p>for each possible candidate to be added/deleted the resulting residual sums  
of squares of the model, with/without this candidate, must be calculated.  
The inversion of of the &quot;X-transpose by X&quot; matrix, X being the design matrix,  
is done by an updating procedure c.f. C.R. Rao - Linear Statistical Inference  
and Its Applications, 2nd. edition, page 33.   
In the inversion the size of the bottom right-hand entry of this matrix is  
critical. If it<code>s value is near zero or the value of it</code>s inverse is   
almost zero then the  
inversion procedure becomes somewhat inaccurate. The lower the tolerance value the  
more careful the procedure is in selecting candidates for addition to the model  
but it may exclude too conservatively. And the other hand if the tolerance is set 
too high a spurious result with a singular or otherwise sub-optimal model may  
occur. By default tolerance is set to 1.0e-5. 
</p>
</td></tr>
<tr><td><code id="polymars_+3A_verbose">verbose</code></td>
<td>

<p>when set  to <code>TRUE</code>, the function will print out a line for each addition or deletion  
stage. For example, &quot; + 8 : 5 3.25 2 NA&quot; means adding interaction basis function  
of predictor 5 with knot at 3.25 and predictor 2 (linear), 
to make a model of size 8, including intercept. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <a href="#topic+polymars">polymars</a>.
The returned object contains information about the fitting steps and the model 
selected. The first data frame contains a row for each step of the fitting 
procedure. In the columns are: a 1 for an addition step or a 0 for a deletion 
step, the size of the model at each step, residual sums of squares (RSS) and  
the generalized cross validation value (GCV), testset residual sums of squares 
or testset misclassification, whatever was used for the model selection. 
The second data frame, model, contains a row for each basis function of the 
model. Each row corresponds to one basis 
function (with two possible components). The pred1 column contains the indices 
of the first predictor of the basis function. Column knot1 is a possible knot  
in this predictor. If this column is NA, the first component is linear. If  
any of the basis functions of the model is categorical then there will be a  
level1 column. Column pred2 is the possible second predictor involved (if  
it is NA the basis function only depends on one  
predictor). Column knot2 contains the possible knot for the predictor pred2,  
and it is NA when this component is linear. This is a similar format  
to the startmodel argument together with an additional first row corresponding to the  
intercept but the startmodel doesn't use a separate column to specify levels of a  
categorical variable . If any predictor in pred2 is categorical then there will be a level2  
column. The column &quot;coefs&quot; (more than one column in the case of multiple response  
regression) contains the coefficients. 
The returned object also contains the fitted values and residuals of the data used 
in fitting the model. 
</p>


<h3>Note</h3>

<p>The algorithm employed by <code>polymars</code> is different from the MARS(tm)
algorithm of Friedman (1991), though it has many similarities. (The name
<code>polymars</code> has been used for this algorithm well before MARS was trademarked.)
Some of the main differences are:
</p>
<p><code>polymars</code> requires linear terms of a predictor to be in the model
before nonlinear terms using the same predictor can be added;
</p>
<p><code>polymars</code> requires a univariate basis function to be in the model
before a tensor-product basis function involving the univariate
basis function can be in the model;
</p>
<p>during stepwise deletion the same hierarchy is maintained;
</p>
<p><code>polymars</code> can be fit to multiple outcomes simultaneously, with
categorical outcomes it can be used for multiple classification; and
</p>
<p><code><a href="#topic+polyclass">polyclass</a></code> uses the same modeling strategy as <code>polymars</code>,
but uses a logistic (polychotomous) likelihood.
</p>
<p>MARS is a registered trademark of Jeril, Inc and is used here
with permission. Commercial licenses and versions of PolyMARS may be
obtained from Salford Systems at http://www.salford-systems.com</p>


<h3>Author(s)</h3>

<p>Martin O'Connor.</p>


<h3>References</h3>

<p>Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Friedman, J. H. (1991). Multivariate adaptive regression splines 
(with discussion).  <em>The Annals of Statistics</em>, <b>19</b>, 1&ndash;141.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyclass">polyclass</a></code>,
<code><a href="#topic+design.polymars">design.polymars</a></code>,
<code><a href="#topic+persp.polymars">persp.polymars</a></code>,
<code><a href="#topic+plot.polymars">plot.polymars</a></code>,
<code><a href="#topic+predict.polymars">predict.polymars</a></code>,
<code><a href="#topic+summary.polymars">summary.polymars</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(state)
state.pm &lt;- polymars(state.region, state.x77, knots = 15, classify = TRUE)
state.pm2 &lt;- polymars(state.x77[, 2], state.x77[,-2], gcv = 2)
plot(fitted(state.pm2), residuals(state.pm2))
</code></pre>

<hr>
<h2 id='predict.polymars'>Polymars: multivariate adaptive polynomial spline regression</h2><span id='topic+predict.polymars'></span>

<h3>Description</h3>

<p>Produces fitted values for a model of class <code>polymars</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polymars'
predict(object, x, classify = FALSE, intercept, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.polymars_+3A_object">object</code></td>
<td>

<p>object of the class <code>polymars</code>, typically the result of <code><a href="#topic+polymars">polymars</a></code>.</p>
</td></tr>
<tr><td><code id="predict.polymars_+3A_x">x</code></td>
<td>

<p>the predictor values at which the fitted values will be computed.  The 
predictor values can be in a number of formats. It can take the form of a 
vector of length equal to the number of predictors in the original data set 
or it can be shortened to the length of only those predictors that occur in 
the model, in the same order as they appear in the original data set.  
Similarly, <code>x</code> can take the form of a matrix with the number of columns equal to 
the number of predictors in the original data set, or shortened to the 
number of predictors in the model. 
</p>
</td></tr>
<tr><td><code id="predict.polymars_+3A_classify">classify</code></td>
<td>

<p>if the original call to polymars was for a classification problem and you would 
like the classifications (class predictions), set this option equal to <code>TRUE</code>. Otherwise the 
function returns a response column for each class (the highest values in each 
row is its class for the case when <code>classify = TRUE</code>).  </p>
</td></tr>
<tr><td><code id="predict.polymars_+3A_intercept">intercept</code></td>
<td>

<p>Setting intercept equal to <code>FALSE</code> evaluates the object without intercept. The  
intercept may also be given any numerical value which overrides the fitted  
coefficient from the object. The defualt is  <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="predict.polymars_+3A_...">...</code></td>
<td>
<p>other arguments are ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of fitted values.
The number of columns in the 
returned matrix equals the number of responses in the original call to <code><a href="#topic+polymars">polymars</a></code>.</p>


<h3>Author(s)</h3>

<p> Martin O'Connor.</p>


<h3>References</h3>

<p> Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polymars">polymars</a></code>,
<code><a href="#topic+design.polymars">design.polymars</a></code>,
<code><a href="#topic+plot.polymars">plot.polymars</a></code>,
<code><a href="#topic+summary.polymars">summary.polymars</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(state)
state.pm &lt;- polymars(state.region, state.x77, knots = 15, classify = TRUE, gcv = 1)
table(predict(state.pm, x = state.x77, classify = TRUE), state.region)
</code></pre>

<hr>
<h2 id='summary.hare'>Hare: hazard regression</h2><span id='topic+summary.hare'></span><span id='topic+print.hare'></span>

<h3>Description</h3>

<p>This function summarizes both the stepwise selection process of the
model fitting by <code><a href="#topic+hare">hare</a></code>, as well as the final model
that was selected using AIC/BIC.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hare'
summary(object, ...) 
## S3 method for class 'hare'
print(x, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.hare_+3A_object">object</code>, <code id="summary.hare_+3A_x">x</code></td>
<td>
 <p><code>hare</code> object, typically the result of <code><a href="#topic+hare">hare</a></code>.  </p>
</td></tr>
<tr><td><code id="summary.hare_+3A_...">...</code></td>
<td>
<p>other arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These function produce identical printed output. The main body consists of 
two tables. 
</p>
<p>The first table has six columns: the first column is a 
possible number of dimensions for the fitted model; 
</p>
<p>the second column indicates whether this model was fitted during 
the addition or deletion stage; 
</p>
<p>the third column is the log-likelihood for the fit; 
</p>
<p>the fourth column is <code>-2 * loglikelihood + penalty * (dimension)</code>, 
which is the AIC criterion - <code>hare</code> selected the model with 
the minimum value of AIC;  
</p>
<p>the last two columns give the 
endpoints of the interval of values of penalty that would yield the 
model with the indicated number of dimensions  
(<code>NA</code>s imply that the model is not optimal for any choice of penalty). 
</p>
<p>At the bottom of the first table the 
dimension of the selected model is reported, as is 
the value of penalty that was used. 
</p>
<p>Each row of the second table summarizes the information about  
a basis function in 
the final model. It shows the variables involved, the knot locations, the 
estimated coefficient and its standard error and Wald statistic (estimate/SE). 
</p>


<h3>Note</h3>

<p>Since the basis functions are selected in an adaptive fashion, typically
most Wald statistics are larger than (the magical) 2. These statistics
should be taken with a grain of salt though, as they are inflated because
of the adaptivity of the model selection.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+hare">hare</a></code>,
<code><a href="#topic+plot.hare">plot.hare</a></code>,
<code><a href="#topic+dhare">dhare</a></code>,
<code><a href="#topic+hhare">hhare</a></code>,
<code><a href="#topic+phare">phare</a></code>,
<code><a href="#topic+qhare">qhare</a></code>,
<code><a href="#topic+rhare">rhare</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- hare(testhare[,1], testhare[,2], testhare[,3:8]) 
summary(fit) 
</code></pre>

<hr>
<h2 id='summary.heft'>Heft: hazard estimation with flexible tails</h2><span id='topic+summary.heft'></span><span id='topic+print.heft'></span>

<h3>Description</h3>

<p>This function summarizes both the stepwise selection process of the
model fitting by <code><a href="#topic+heft">heft</a></code>, as well as the final model
that was selected using AIC/BIC.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'heft'
summary(object, ...) 
## S3 method for class 'heft'
print(x, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.heft_+3A_object">object</code>, <code id="summary.heft_+3A_x">x</code></td>
<td>
 <p><code>heft</code> object, typically the result of <code><a href="#topic+heft">heft</a></code>.  </p>
</td></tr>
<tr><td><code id="summary.heft_+3A_...">...</code></td>
<td>
<p>other arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These function produce identical printed output. The main body 
is a table with six columns: 
</p>
<p>the first column is a possible number 
of knots for the fitted model; 
</p>
<p>the second column is 0 if the model was fitted during the 
addition stage and 1 if the model was fitted during the deletion stage; 
</p>
<p>the third column is the log-likelihood for the fit; 
</p>
<p>the fourth column is <code>-2 * loglikelihood + penalty * (dimension)</code>,
which is the AIC criterion - <code>heft</code> selected the model with
the minimum value of AIC;
</p>
<p>the fifth and sixth columns give the 
endpoints of the interval of values of penalty that would yield the 
model with the indicated number of knots. (<code>NA</code>s imply that the model is 
not optimal for any choice of penalty.)  
</p>
<p>At the bottom of the table the 
number of knots corresponding to the selected model is reported, as are 
the value of penalty that was used and the coefficients of the log-based 
terms in the fitted model and their standard errors. 
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+heft">heft</a></code>,
<code><a href="#topic+plot.heft">plot.heft</a></code>,
<code><a href="#topic+dheft">dheft</a></code>,
<code><a href="#topic+hheft">hheft</a></code>,
<code><a href="#topic+pheft">pheft</a></code>,
<code><a href="#topic+qheft">qheft</a></code>,
<code><a href="#topic+rheft">rheft</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- heft(testhare[,1], testhare[,2])
summary(fit1)
# modify tail behavior
fit2 &lt;- heft(testhare[,1], testhare[,2], leftlog = FALSE, rightlog = FALSE, 
    leftlin = TRUE)   
summary(fit2)
fit3 &lt;- heft(testhare[,1], testhare[,2], penalty = 0)   # select largest model
summary(fit3)
</code></pre>

<hr>
<h2 id='summary.logspline'>Logspline Density Estimation </h2><span id='topic+summary.logspline'></span><span id='topic+print.logspline'></span>

<h3>Description</h3>

<p> This function summarizes both the stepwise selection process of the
model fitting by <code><a href="#topic+logspline">logspline</a></code>, as well as the final model
that was selected using AIC/BIC. A
<code>logspline</code> object was fit using the 1997 knot addition and deletion algorithm.
The 1992 algorithm is available using the <code><a href="#topic+oldlogspline">oldlogspline</a></code> function.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logspline'
summary(object, ...) 
## S3 method for class 'logspline'
print(x, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.logspline_+3A_object">object</code>, <code id="summary.logspline_+3A_x">x</code></td>
<td>
<p><code>logspline</code> object, typically the result of <code><a href="#topic+logspline">logspline</a></code></p>
</td></tr>
<tr><td><code id="summary.logspline_+3A_...">...</code></td>
<td>
<p> other arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These function produce identical printed output. The main body 
is a table with five columns: the first column is a possible number 
of knots for the fitted model; 
</p>
<p>the second column is the log-likelihood for the fit; 
</p>
<p>the third column is <code>-2 * loglikelihood + penalty * (number of knots - 1)</code>, 
which is the AIC criterion; <code><a href="#topic+logspline">logspline</a></code> selected the model with 
the smallest value of AIC; 
</p>
<p>the fourth and fifth columns give the 
endpoints of the interval of values of penalty that would yield the 
model with the indicated number of knots. (<code>NA</code>s imply that the model is 
not optimal for any choice of <code>penalty</code>.) At the bottom of the table the 
number of knots corresponding to the selected model is reported, as is 
the value of penalty that was used. 
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+logspline">logspline</a></code>,      
<code><a href="#topic+plot.logspline">plot.logspline</a></code>,
<code><a href="#topic+dlogspline">dlogspline</a></code>,
<code><a href="#topic+plogspline">plogspline</a></code>,
<code><a href="#topic+qlogspline">qlogspline</a></code>,
<code><a href="#topic+rlogspline">rlogspline</a></code>,<br />
<code><a href="#topic+oldlogspline">oldlogspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
fit &lt;- logspline(y)       
summary(fit) 
</code></pre>

<hr>
<h2 id='summary.lspec'>Lspec: logspline estimation of a spectral distribution</h2><span id='topic+summary.lspec'></span><span id='topic+print.lspec'></span>

<h3>Description</h3>

<p>Summary of a model fitted with <code><a href="#topic+lspec">lspec</a></code> </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lspec'
summary(object, ...) 
## S3 method for class 'lspec'
print(x, ...) </code></pre>


<h3>Arguments</h3>

 <table>
<tr><td><code id="summary.lspec_+3A_object">object</code>, <code id="summary.lspec_+3A_x">x</code></td>
<td>
 <p><code>lspec</code> object, typically the result of <code><a href="#topic+lspec">lspec</a></code>.</p>
</td></tr>
<tr><td><code id="summary.lspec_+3A_...">...</code></td>
<td>
<p>other options are ignored.</p>
</td></tr></table>


<h3>Details</h3>

<p>These function produce an identical printed summary of an <code>lspec</code> object.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone, and Young K. Truong (1995).
Logspline Estimation of a Possibly Mixed Spectral Distribution.
<em>Journal of Time Series Analysis</em>, <b>16</b>, 359-388.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><a href="#topic+lspec">lspec</a>, <a href="#topic+plot.lspec">plot.lspec</a>, <a href="#topic+clspec">clspec</a>, <a href="#topic+dlspec">dlspec</a>,
<a href="#topic+plspec">plspec</a>, <a href="#topic+rlspec">rlspec</a>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(co2)
co2.detrend &lt;- lm(co2~c(1:length(co2)))$residuals
fit &lt;- lspec(co2.detrend)
summary(fit)
</code></pre>

<hr>
<h2 id='summary.oldlogspline'> Logspline Density Estimation - 1992 version </h2><span id='topic+summary.oldlogspline'></span><span id='topic+print.oldlogspline'></span>

<h3>Description</h3>

<p> This function summarizes both the stepwise selection process of the
model fitting by <code><a href="#topic+oldlogspline">oldlogspline</a></code>, as well as the final model
that was selected using AIC/BIC. A
<code>logspline</code> object was fit using
the 1992 knot deletion algorithm (<code><a href="#topic+oldlogspline">oldlogspline</a></code>). 
The 1997 algorithm using knot
deletion and addition is available using the <code><a href="#topic+logspline">logspline</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oldlogspline'
summary(object, ...) 
## S3 method for class 'oldlogspline'
print(x, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.oldlogspline_+3A_object">object</code>, <code id="summary.oldlogspline_+3A_x">x</code></td>
<td>

<p><code>oldlogspline</code> object, typically the result of <code><a href="#topic+oldlogspline">oldlogspline</a></code>
</p>
</td></tr>
<tr><td><code id="summary.oldlogspline_+3A_...">...</code></td>
<td>
<p> other arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These function produces the same printed output. The main body 
is a table with five columns: the first column is a possible number 
of knots for the fitted model; 
</p>
<p>the second column is the log-likelihood for the fit; 
</p>
<p>the third column is <code>-2 * loglikelihood + penalty * (number of knots - 1)</code>,
which is the AIC criterion; <code><a href="#topic+logspline">logspline</a></code> selected the model with
the smallest value of AIC;
</p>
<p>the fourth and fifth columns give the 
endpoints of the interval of values of penalty that would yield the 
model with the indicated number of knots. (<code>NA</code>s imply that the model is 
not optimal for any choice of <code>penalty</code>.) At the bottom of the table the 
number of knots corresponding to the selected model is reported, as is 
the value of penalty that was used. 
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg and Charles J. Stone.  Logspline density estimation
for censored data (1992). <em>Journal of Computational and Graphical
Statistics</em>, <b>1</b>, 301&ndash;328.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+logspline">logspline</a></code>,
<code><a href="#topic+oldlogspline">oldlogspline</a></code>,
<code><a href="#topic+plot.oldlogspline">plot.oldlogspline</a></code>,
<code><a href="#topic+doldlogspline">doldlogspline</a></code>,
<code><a href="#topic+poldlogspline">poldlogspline</a></code>,<br />
<code><a href="#topic+qoldlogspline">qoldlogspline</a></code>,
<code><a href="#topic+roldlogspline">roldlogspline</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
fit &lt;- oldlogspline(y)       
summary(fit) 
</code></pre>

<hr>
<h2 id='summary.polyclass'>Polyclass: polychotomous regression and multiple classification</h2><span id='topic+summary.polyclass'></span><span id='topic+print.polyclass'></span>

<h3>Description</h3>

<p>This function summarizes both the stepwise selection process of the
model fitting by <code><a href="#topic+polyclass">polyclass</a></code>, as well as the final model
that was selected</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polyclass'
summary(object, ...) 
## S3 method for class 'polyclass'
print(x, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.polyclass_+3A_object">object</code>, <code id="summary.polyclass_+3A_x">x</code></td>
<td>
  <p><code>polyclass</code> object, typically the result of <code><a href="#topic+polyclass">polyclass</a></code>.  </p>
</td></tr>
<tr><td><code id="summary.polyclass_+3A_...">...</code></td>
<td>
<p>other arguments are ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>These function summarize a <code>polyclass</code> fit identically. They also give information 
about fits that could have been obtained with other  
model selection options in <code><a href="#topic+polyclass">polyclass</a></code>. 
</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p> Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polyclass">polyclass</a></code>,
<code><a href="#topic+plot.polyclass">plot.polyclass</a></code>,
<code><a href="#topic+beta.polyclass">beta.polyclass</a></code>,
<code><a href="#topic+cpolyclass">cpolyclass</a></code>,
<code><a href="#topic+ppolyclass">ppolyclass</a></code>,
<code><a href="#topic+rpolyclass">rpolyclass</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
fit.iris &lt;- polyclass(iris[,5], iris[,1:4])
summary(fit.iris)
</code></pre>

<hr>
<h2 id='summary.polymars'>Polymars: multivariate adaptive polynomial spline regression</h2><span id='topic+summary.polymars'></span><span id='topic+print.polymars'></span>

<h3>Description</h3>

<p> Gives details of a <code>polymars</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'polymars'
summary(object, ...) 
## S3 method for class 'polymars'
print(x, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.polymars_+3A_object">object</code>, <code id="summary.polymars_+3A_x">x</code></td>
<td>
<p> object of the class <code>polymars</code>, typically the result of <code><a href="#topic+polymars">polymars</a></code>.</p>
</td></tr>
<tr><td><code id="summary.polymars_+3A_...">...</code></td>
<td>
<p>other arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These two functions provide identical printed information.
about the fitting steps and the model 
selected. The first data frame contains a row for each step of the fitting 
procedure. In the columns are: a 1 for an addition step or a 0 for a deletion 
step, the size of the model at each step, residual sums of squares (RSS) and  
the generalized cross validation value (GCV), testset residual sums of squares 
or testset misclassification, whatever was used for the model selection. 
The second data frame, model, contains a row for each basis function of the 
model. Each row corresponds to one basis 
function (with two possible components). The pred1 column contains the indices 
of the first predictor of the basis function. Column knot1 is a possible knot  
in this predictor. If this column is NA, the first component is linear. If  
any of the basis functions of the model is categorical then there will be a  
level1 column. Column pred2 is the possible second predictor involved (if  
it is NA the basis function only depends on one  
predictor). Column knot2 contains the possible knot for the predictor pred2,  
and it is NA when this component is linear. This is a similar format  
to the startmodel argument together with an additional first row corresponding to the  
intercept but the startmodel doesn't use a separate column to specify levels of a  
categorical variable . If any predictor in pred2 is categorical then there will be a level2  
column. The column &quot;coefs&quot; (more than one column in the case of multiple response  
regression) contains the coefficients. 
</p>


<h3>Author(s)</h3>

<p>Martin O'Connor.</p>


<h3>References</h3>

<p> Charles Kooperberg, Smarajit Bose, and  Charles J. Stone (1997).
Polychotomous regression. <em>Journal of the American Statistical
Association</em>, <b>92</b>, 117&ndash;127.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

<p><code><a href="#topic+polymars">polymars</a></code>,
<code><a href="#topic+design.polymars">design.polymars</a></code>,
<code><a href="#topic+persp.polymars">persp.polymars</a></code>,
<code><a href="#topic+plot.polymars">plot.polymars</a></code>,
<code><a href="#topic+predict.polymars">predict.polymars</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(state)
state.pm &lt;- polymars(state.region, state.x77, knots = 15, classify = TRUE)
summary(state.pm)
</code></pre>

<hr>
<h2 id='testhare'>Fake survival data for Hare and Heft</h2><span id='topic+testhare'></span>

<h3>Description</h3>

<p>Fake survival analysis data set for testing <code><a href="#topic+hare">hare</a></code> and <code><a href="#topic+heft">heft</a></code></p>


<h3>Usage</h3>

<pre><code class='language-R'>testhare</code></pre>


<h3>Format</h3>

<p>A matrix with 2000 lines (observations) and 8 columns. Column 1 is
intended to be the survival time, column 2 the censoring indicator, and
columns 3 through 8 are predictors (covariates).</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>Source</h3>

<p>I started out with a real data set; then I sampled, transformed and added noise.
Virtually no number is unchanged.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+hare">hare</a></code>, <code><a href="#topic+heft">heft</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>harefit &lt;- hare(testhare[,1], testhare[,2], testhare[,3:8]) 
heftfit &lt;- heft(testhare[,1], testhare[,2])
</code></pre>

<hr>
<h2 id='unstrip'>Reformat data as vector or matrix</h2><span id='topic+unstrip'></span>

<h3>Description</h3>

<p>This function tries to convert a date.frame or a matrix to a no-frills matrix without labels,
and a vector or time-series to a no-frills vector without labels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>unstrip(x) </code></pre>


<h3>Arguments</h3>

 <table>
<tr><td><code id="unstrip_+3A_x">x</code></td>
<td>
<p> one- or two-dimensional object.</p>
</td></tr> </table>


<h3>Details</h3>

<p>Many of the functions for <code><a href="#topic+logspline">logspline</a></code>, <code><a href="#topic+oldlogspline">oldlogspline</a></code>, 
<code><a href="#topic+lspec">lspec</a></code>, <code><a href="#topic+polyclass">polyclass</a></code>,
<code><a href="#topic+hare">hare</a></code>, <code><a href="#topic+heft">heft</a></code>, and <code><a href="#topic+polymars">polymars</a></code> were written in the &ldquo;before data.frame&rdquo; era;
<code>unstrip</code> attempts to keep all these functions useful with more advanced input objects.
In particular, many of these functions call <code>unstrip</code> before doing anything else.</p>


<h3>Value</h3>

<p>If <code>x</code> is two-dimensional a  matrix
without names, if <code>x</code> is one-dimensional  a numerical vector</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(co2)
unstrip(co2)
data(iris)
unstrip(iris)
</code></pre>

<hr>
<h2 id='xhare'>Hare: hazard regression</h2><span id='topic+xhare'></span>

<h3>Description</h3>

<p>Driver function for <code><a href="#topic+dhare">dhare</a></code>, <code><a href="#topic+hhare">hhare</a></code>, <code><a href="#topic+phare">phare</a></code>, <code><a href="#topic+qhare">qhare</a></code>,
and <code><a href="#topic+rhare">rhare</a></code>. This function is not intended for use by itself.</p>


<h3>Usage</h3>

<pre><code class='language-R'>xhare(arg1, arg2, arg3, arg4) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xhare_+3A_arg1">arg1</code>, <code id="xhare_+3A_arg2">arg2</code>, <code id="xhare_+3A_arg3">arg3</code>, <code id="xhare_+3A_arg4">arg4</code></td>
<td>
<p> arguments.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p> This function is used internally.  </p>


<h3>Note</h3>

<p>This function is not intended for direct use.</p>


<h3>Author(s)</h3>

<p> Charles Kooperberg <a href="mailto:clk@fredhutch.org">clk@fredhutch.org</a>.</p>


<h3>References</h3>

<p>Charles Kooperberg, Charles J. Stone and Young K. Truong (1995).
Hazard regression.  <em>Journal of the American Statistical
Association</em>, <b>90</b>, 78-94.
</p>
<p>Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong.
The use of polynomial splines and their tensor products in extended
linear modeling (with discussion) (1997).  <em>Annals of Statistics</em>,
<b>25</b>, 1371&ndash;1470.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+hare">hare</a></code>,
<code><a href="#topic+dhare">dhare</a></code>, <code><a href="#topic+hhare">hhare</a></code>, <code><a href="#topic+phare">phare</a></code>, <code><a href="#topic+qhare">qhare</a></code>,
<code><a href="#topic+rhare">rhare</a></code>.</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
