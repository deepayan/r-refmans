<!DOCTYPE html><html><head><title>Help for package lmboot</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lmboot}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lmboot-package'>
<p>Bootstrap in Linear Models</p></a></li>
<li><a href='#ANOVA.boot'>
<p>Residual and wild bootstrap in 1-way and 2-way ANOVA</p></a></li>
<li><a href='#bayesian.boot'>
<p>Bayesian Bootstrap in Linear Models</p></a></li>
<li><a href='#jackknife'>
<p>Delete-1 Jackknife in Linear Models</p></a></li>
<li><a href='#paired.boot'>
<p>Paired Bootstrap in Linear Models</p></a></li>
<li><a href='#residual.boot'>
<p>Residual bootstrap in linear models</p></a></li>
<li><a href='#wild.boot'><p>Wild Bootstrap in Linear Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bootstrap in Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-05-13</td>
</tr>
<tr>
<td>Description:</td>
<td>Various efficient and robust bootstrap methods are implemented for 
    linear models with least squares estimation.  Functions within this package 
    allow users to create bootstrap sampling distributions for model parameters, 
    test hypotheses about parameters, and visualize the bootstrap sampling or null 
    distributions.  Methods implemented for linear models include the wild bootstrap by 
    Wu (1986) &lt;<a href="https://doi.org/10.1214%2Faos%2F1176350142">doi:10.1214/aos/1176350142</a>&gt;, the residual and paired bootstraps by
    Efron (1979, ISBN:978-1-4612-4380-9), the delete-1 jackknife by 
    Quenouille (1956) &lt;<a href="https://doi.org/10.2307%2F2332914">doi:10.2307/2332914</a>&gt;, and the Bayesian bootstrap by 
    Rubin (1981) &lt;<a href="https://doi.org/10.1214%2Faos%2F1176345338">doi:10.1214/aos/1176345338</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>evd (&ge; 2.3.0), stats (&ge; 3.6.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-05-31 16:54:35 UTC; heyman</td>
</tr>
<tr>
<td>Author:</td>
<td>Megan Heyman [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Megan Heyman &lt;heyman@rose-hulman.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-06-03 13:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='lmboot-package'>
Bootstrap in Linear Models
</h2><span id='topic+lmboot-package'></span><span id='topic+lmboot'></span>

<h3>Description</h3>

<p>Various efficient and robust bootstrap methods are implemented for 
    linear models with least squares estimation.  Functions within this package 
    allow users to create bootstrap sampling distributions for model parameters, 
    test hypotheses about parameters, and visualize the bootstrap sampling or null 
    distributions.  Methods implemented for linear models include the wild bootstrap by 
    Wu (1986) &lt;doi:10.1214/aos/1176350142&gt;, the residual and paired bootstraps by
    Efron (1979, ISBN:978-1-4612-4380-9), the delete-1 jackknife by 
    Quenouille (1956) &lt;doi:10.2307/2332914&gt;, and the Bayesian bootstrap by 
    Rubin (1981) &lt;doi:10.1214/aos/1176345338&gt;.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> lmboot</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Bootstrap in Linear Models</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.0.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2019-05-13</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> person("Megan", "Heyman", email="heyman@rose-hulman.edu", role=c("aut","cre"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Various efficient and robust bootstrap methods are implemented for 
    linear models with least squares estimation.  Functions within this package 
    allow users to create bootstrap sampling distributions for model parameters, 
    test hypotheses about parameters, and visualize the bootstrap sampling or null 
    distributions.  Methods implemented for linear models include the wild bootstrap by 
    Wu (1986) &lt;doi:10.1214/aos/1176350142&gt;, the residual and paired bootstraps by
    Efron (1979, ISBN:978-1-4612-4380-9), the delete-1 jackknife by 
    Quenouille (1956) &lt;doi:10.2307/2332914&gt;, and the Bayesian bootstrap by 
    Rubin (1981) &lt;doi:10.1214/aos/1176345338&gt;.</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> evd (&gt;= 2.3.0),
stats (&gt;= 3.6.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 6.1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Megan Heyman [aut, cre]</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Megan Heyman &lt;heyman@rose-hulman.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
ANOVA.boot              Residual and wild bootstrap in 1-way and 2-way
                        ANOVA
bayesian.boot           Bayesian Bootstrap in Linear Models
jackknife               Delete-1 Jackknife in Linear Models
lmboot-package          Bootstrap in Linear Models
paired.boot             Paired Bootstrap in Linear Models
residual.boot           Residual bootstrap in linear models
wild.boot               Wild Bootstrap in Linear Models
</pre>
<p>This package is useful to users who wish to perform bootstrap in linear models.  The package contains functions to create
the sampling distributions for linear model parameters using either efficient or robust bootstrap methods.  
</p>
<p>As classified by
Liu and Singh (1992), efficient bootstrap types include the residual bootstrap (<code>residual.boot()</code>).  These types of
bootstrap are useful when it is not reasonable to assume that errors come from a normal distribution, but you may make other
classical assumptions:  errors are independent, have mean 0, and have constant variance.
</p>
<p>Robust bootstrap types include the paired bootstrap (<code>paired.boot</code>), wild bootstrap (<code>wild.boot</code>), and the jackknife (<code>jackknife</code>).
These types of bootstrap are useful when it is not reasonable to assumet that errors have constant variance, but you may make other
classical assumptions:  errors are independent and have mean 0.
</p>
<p>The package also contains a function for Bayesian bootstrap (<code>bayesian.boot</code> and a function to perform bootstrap in the
ANOVA hypothesis test (<code>ANOVA.boot</code>).  The ANOVA bootstrap function has options to use the wild or residual bootstrap techniques
and has been tested to work in 2-way ANOVA.  Its functionality allows K-way ANOVA, however those capabilities have not been fully tested.
</p>
<p>Currently, the user must manipulate the output of the function to conduct hypothesis tests and create 
confidence intervals for the predictor coefficients.  More convenient/streamlined output is expected
in future package versions.
</p>


<h3>Author(s)</h3>

<p>NA
</p>
<p>Maintainer: NA
</p>


<h3>References</h3>

<p>Efron, B.  (1979). &quot;Bootstrap methods: Another look at the jackknife.&quot;  <em>Annals of Statistics</em>.  Vol. 7, pp.1-26.
</p>
<p>Liu, R. Y. and Singh, K. (1992). &quot;Efficiency and Robustness in Resampling.&quot;  <em>Annals of Statistics</em>. Vol. 20, No. 1, pp.370-384.
</p>
<p>Rubin, D. B.  (1981). &quot;The Bayesian Bootstrap.&quot;  <em>Annals of Statistics</em>.  Vol. 9, No. 1,  pp.130-134.
</p>
<p>Wu, C.F.J.  (1986). &quot;Jackknife, Bootstrap, and Other Resampling Methods in Regression Analysis.&quot;  <em>Annals of Statistics</em>.  Vol. 14, No. 4, pp.1261 - 1295.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Seed &lt;- 14
set.seed(Seed)
y &lt;- rnorm(20) #randomly generated response
x &lt;- rnorm(20) #randomly generated predictor

ResidObj &lt;- residual.boot(y~x, B=100, seed=Seed) #perform the residual bootstrap
WildObj &lt;- wild.boot(y~x, B=100, seed=Seed) #perform the wild bootstrap

#residual bootstrap 95% CI for slope parameter (percentile method)
quantile(ResidObj$bootEstParam[,2], probs=c(.025, .975))

#bootstrap 95% CI for slope parameter (percentile method)
quantile(WildObj$bootEstParam[,2], probs=c(.025, .975))
</code></pre>

<hr>
<h2 id='ANOVA.boot'>
Residual and wild bootstrap in 1-way and 2-way ANOVA
</h2><span id='topic+ANOVA.boot'></span>

<h3>Description</h3>

<p>This function performs the residual bootstrap as described by Efron (1979) and wild bootstrap as described by Wu (1986)
for ANOVA hypothesis testing.  Linear models 
incorporating categorical and/or quantitative predictor variables with a quantitative response are allowed.  
The function output creates the bootstrap null distribution for each term to be tested.  
Estimation is performed via least squares and only Type I sum of squares are calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ANOVA.boot(formula, B = 1000, type = "residual", wild.dist = "normal", 
            seed = NULL, data = NULL, keep.boot.resp = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ANOVA.boot_+3A_formula">formula</code></td>
<td>

<p>input a linear model formula of the form <code>response</code>~<code>predictors</code> as you would in the <code>lm()</code> 
function.  All variables must contain non-missing entries.
</p>
</td></tr>
<tr><td><code id="ANOVA.boot_+3A_b">B</code></td>
<td>

<p>number of bootstrap samples.  This should be a large, positive integer value.
</p>
</td></tr>
<tr><td><code id="ANOVA.boot_+3A_type">type</code></td>
<td>

<p>type of bootstrap to perform.  Select either &quot;residual&quot; for residual bootstrap or &quot;wild&quot; for wild bootstrap.
</p>
</td></tr>
<tr><td><code id="ANOVA.boot_+3A_wild.dist">wild.dist</code></td>
<td>

<p>distribution used to create the wild bootstrap weights for the residuals.  Allowed distributions include
<code>"normal"</code>, <code>"uniform"</code>, <code>"exponential"</code>, <code>"laplace"</code>, <code>"lognormal"</code>, 
<code>"gumbel"</code>, <code>"t5"</code>, <code>"t8"</code>, and <code>"t14"</code>.  The numbers after the t-distributions
indicate the degrees of freedom.  Any selected distribution creates weights with mean 0 and variance 1 from
the named distribution.
</p>
</td></tr>
<tr><td><code id="ANOVA.boot_+3A_seed">seed</code></td>
<td>

<p>optionally, set a value for the seed for the bootstrap sample generation.  The default <code>NULL</code> will
pick a random value for the seed.
</p>
</td></tr>
<tr><td><code id="ANOVA.boot_+3A_data">data</code></td>
<td>

<p>optionally, input the name of the dataset where variables appearing in the model are stored.
</p>
</td></tr>
<tr><td><code id="ANOVA.boot_+3A_keep.boot.resp">keep.boot.resp</code></td>
<td>

<p>a boolean indicating whether the list of returns includes raw bootstrap responses.  Setting this to TRUE
may not be possible for larger datasets or too many bootstrap samples due to memory usage.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the user must manipulate the output of the function manually to view the bootstrap ANOVA table components
and visualize the null distribution.  More convenient/streamlined output is expected
in future package versions.
</p>
<p>Thanks to Bochuan Lyu who helped to coding to this function.
</p>


<h3>Value</h3>

<table>
<tr><td><code>terms</code></td>
<td>
<p>names of the terms/rows of the ANOVA table.  These correspond to each predictor variable input to the formula.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom associated with each term/row in the ANOVA table.  These correspond to the number of categories in
each predictor variable (or are 1 for quantitative predictors)</p>
</td></tr>
<tr><td><code>origFStats</code></td>
<td>
<p>original F-statistic value.  Same value as obtained by <code>aov()</code> using type I sum of squares.</p>
</td></tr>
<tr><td><code>origSSE</code></td>
<td>
<p>original sum of squares, error.  Same value as obtained by <code>aov()</code> using type I sum of squares.</p>
</td></tr>
<tr><td><code>origSSTr</code></td>
<td>
<p>original sum of squares, treatment.  Vector containing the sum of squares for each term in the ANOVA model.
These are the same values as obtained by <code>aov()</code> using type I sum of squares.</p>
</td></tr>
<tr><td><code>bootFStats</code></td>
<td>
<p>matrix containing the bootstrap F statistics.  Each column corresponds to a term in the ANOVA table.  There
are <code>B</code> rows.</p>
</td></tr>
<tr><td><code>bootSSE</code></td>
<td>
<p>matrix containing the bootstrap sum of squares, error.  Each column corresponds to a term in the ANOVA table.  There
are <code>B</code> rows.  These are calculated using type I sum of squares.</p>
</td></tr>
<tr><td><code>bootSSTr</code></td>
<td>
<p>matrix containing the bootstrap sum of squares, treatment.  Each column corresponds to a term in the ANOVA table.  There
are <code>B</code> rows.  These are calculated using type I sum of squares.</p>
</td></tr>
<tr><td><code>`p-values`</code></td>
<td>
<p>vector containing the bootstrap p-values for each predictor term in the ANOVA model.  These are calculated by
counting the number of bootstrap test statistics which are greater than the original observed test statistic and
dividing by <code>B</code> </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Megan Heyman, heyman@rose-hulman.edu
</p>


<h3>References</h3>

<p>Efron, B.  (1979). &quot;Bootstrap methods: Another look at the jackknife.&quot;  <em>Annals of Statistics</em>.  Vol. 7, pp.1-26.
</p>
<p>Wu, C.F.J.  (1986). &quot;Jackknife, Bootstrap, and Other Resampling Methods in Regression Analysis.&quot;  <em>Annals of Statistics</em>.  Vol. 14, No. 4, pp.1261 - 1295.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wild.boot">wild.boot</a></code>, <code><a href="#topic+residual.boot">residual.boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)         #load an example dataset
myANOVA2 &lt;- ANOVA.boot(mpg~as.factor(cyl)*as.factor(am), data=mtcars)
myANOVA2$`p-values`  #bootstrap p-values for 2-way interactions model

myANOVA1 &lt;- ANOVA.boot(mpg~as.factor(cyl), data=mtcars)
myANOVA1$`p-values` #bootstrap p-values for 1-way model

myANOVA2a &lt;- ANOVA.boot(mpg~as.factor(cyl)+as.factor(am), data=mtcars)
myANOVA2a$`p-values` #bootstrap p-values for 1-way additive model

</code></pre>

<hr>
<h2 id='bayesian.boot'>
Bayesian Bootstrap in Linear Models
</h2><span id='topic+bayesian.boot'></span>

<h3>Description</h3>

<p>This function performs the bayesian bootstrap in linear models as described by Rubin (1981) &lt;doi:10.1214/aos/1176345338&gt;.  
Linear models incorporating categorical and/or quantitative predictor variables with a quantitative response are allowed.  
The function output creates the bootstrap sampling distribution for each coefficient.  
Estimation is performed via least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayesian.boot(formula, B = 1000, seed = NULL, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayesian.boot_+3A_formula">formula</code></td>
<td>

<p>input a linear model formula of the form <code>response</code>~<code>predictors</code> as you would in the <code>lm()</code> 
function.  All variables must contain non-missing entries.
</p>
</td></tr>
<tr><td><code id="bayesian.boot_+3A_b">B</code></td>
<td>

<p>number of bootstrap samples.  This should be a large, positive integer value.
</p>
</td></tr>
<tr><td><code id="bayesian.boot_+3A_seed">seed</code></td>
<td>

<p>optionally, set a value for the seed for the bootstrap sample generation.  The default <code>NULL</code> will
pick a random value for the seed.
</p>
</td></tr>
<tr><td><code id="bayesian.boot_+3A_data">data</code></td>
<td>

<p>optionally, input the name of the dataset where variables appearing in the model are stored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the user must manipulate the output of the function to conduct hypothesis tests and create 
confidence intervals for the predictor coefficients.  More convenient/streamlined output is expected
in future package versions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bootEstParam</code></td>
<td>
<p>matrix containing the bootstrap parameter estimates.  Each column corresponds to a 
coefficient.  There are <code>B</code> rows, each corresponding to a bootstrap sample.</p>
</td></tr>
<tr><td><code>origEstParam</code></td>
<td>
<p>vector containing the least squares parameter estimates.  These are the same as
estimates obtained from <code>lm</code>.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>numerical value set for the seed.  This is associated with the set of bootstrap parameter
estimates and helps the process to be reproducible.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Megan Heyman, heyman@rose-hulman.edu
</p>


<h3>References</h3>

<p>Rubin, D. B.  (1981). &quot;The Bayesian Bootstrap.&quot;  <em>Annals of Statistics</em>.  Vol. 9, No. 1,  pp.130-134.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Seed &lt;- 14
set.seed(Seed)
y &lt;- rnorm(20) #randomly generated response
x &lt;- rnorm(20) #randomly generated predictor
BayesObj &lt;- bayesian.boot(y~x, B=100, seed=Seed) #perform the Bayesian bootstrap

#plot the sampling distribution of the slope coefficient
hist(BayesObj$bootEstParam[,2], main="Bayesian Bootstrap Sampling Distn.",
     xlab="Slope Estimate") 

#bootstrap 95% CI for slope parameter (percentile method)
quantile(BayesObj$bootEstParam[,2], probs=c(.025, .975))

</code></pre>

<hr>
<h2 id='jackknife'>
Delete-1 Jackknife in Linear Models
</h2><span id='topic+jackknife'></span>

<h3>Description</h3>

<p>This function performs the delete-1 jackknife in linear models as described by Quenouille (1956) &lt;doi:10.2307/2332914&gt;.  
Linear models incorporating categorical and/or quantitative predictor variables with a quantitative response are allowed.  
The function output creates the jackknife sampling distribution for each coefficient.  
Estimation is performed via least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jackknife(formula, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jackknife_+3A_formula">formula</code></td>
<td>

<p>input a linear model formula of the form <code>response</code>~<code>predictors</code> as you would in the <code>lm()</code> 
function.  All variables must contain non-missing entries.
</p>
</td></tr>
<tr><td><code id="jackknife_+3A_data">data</code></td>
<td>

<p>optionally, input the name of the dataset where variables appearing in the model are stored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the user must manipulate the output of the function to conduct hypothesis tests and create 
confidence intervals for the predictor coefficients.  More convenient/streamlined output is expected
in future package versions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bootEstParam</code></td>
<td>
<p>matrix containing the jackknife parameter estimates.  Each column corresponds to a 
coefficient.  There are <code>n-1</code> rows, each corresponding to a jackknife sample.</p>
</td></tr>
<tr><td><code>origEstParam</code></td>
<td>
<p>vector containing the least squares parameter estimates.  These are the same as
estimates obtained from <code>lm</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Megan Heyman, heyman@rose-hulman.edu
</p>


<h3>References</h3>

<p>Quenouille, M. (1956). &quot;Notes on bias in estimation.&quot;  <em>Biometrika</em>.  Vol. 61,  pp.1-15
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Seed &lt;- 14
set.seed(Seed)
y &lt;- rnorm(20) #randomly generated response
x &lt;- rnorm(20) #randomly generated predictor
JackObj &lt;- jackknife(y~x) #perform the jackknife

#plot the sampling distribution of the slope coefficient
hist(JackObj$bootEstParam[,2], main="Jackknife Sampling Distn.",
     xlab="Slope Estimate") 

#jackknife 95% CI for slope parameter (percentile method)
quantile(JackObj$bootEstParam[,2], probs=c(.025, .975))
</code></pre>

<hr>
<h2 id='paired.boot'>
Paired Bootstrap in Linear Models
</h2><span id='topic+paired.boot'></span>

<h3>Description</h3>

<p>This function performs the paired bootstrap in linear models as described by Efron (1979, ISBN:978-1-4612-4380-9).  
Linear models  incorporating categorical and/or quantitative predictor variables with a quantitative response are allowed.  
The function output creates the bootstrap sampling distribution for each coefficient.  
Estimation is performed via least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paired.boot(formula, B = 1000, seed = NULL, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paired.boot_+3A_formula">formula</code></td>
<td>

<p>input a linear model formula of the form <code>response</code>~<code>predictors</code> as you would in the <code>lm()</code> 
function.  All variables must contain non-missing entries.
</p>
</td></tr>
<tr><td><code id="paired.boot_+3A_b">B</code></td>
<td>

<p>number of bootstrap samples.  This should be a large, positive integer value.
</p>
</td></tr>
<tr><td><code id="paired.boot_+3A_seed">seed</code></td>
<td>

<p>optionally, set a value for the seed for the bootstrap sample generation.  The default <code>NULL</code> will
pick a random value for the seed.
</p>
</td></tr>
<tr><td><code id="paired.boot_+3A_data">data</code></td>
<td>

<p>optionally, input the name of the dataset where variables appearing in the model are stored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the user must manipulate the output of the function to conduct hypothesis tests and create 
confidence intervals for the predictor coefficients.  More convenient/streamlined output is expected
in future package versions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bootEstParam</code></td>
<td>
<p>matrix containing the bootstrap parameter estimates.  Each column corresponds to a 
coefficient.  There are <code>B</code> rows, each corresponding to a bootstrap sample.</p>
</td></tr>
<tr><td><code>origEstParam</code></td>
<td>
<p>vector containing the least squares parameter estimates.  These are the same as
estimates obtained from <code>lm</code>.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>numerical value set for the seed.  This is associated with the set of bootstrap parameter
estimates and helps the process to be reproducible.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Megan Heyman, heyman@rose-hulman.edu
</p>


<h3>References</h3>

<p>Efron, B.  (1979). &quot;Bootstrap methods: Another look at the jackknife.&quot;  <em>Annals of Statistics</em>.  Vol. 7, pp.1-26.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Seed &lt;- 14
set.seed(Seed)
y &lt;- rnorm(20) #randomly generated response
x &lt;- rnorm(20) #randomly generated predictor
PairObj &lt;- paired.boot(y~x, B=100, seed=Seed) #perform the paired bootstrap

#plot the sampling distribution of the slope coefficient
hist(PairObj$bootEstParam[,2], main="Paired Bootstrap Sampling Distn.",
     xlab="Slope Estimate") 

#bootstrap 95% CI for slope parameter (percentile method)
quantile(PairObj$bootEstParam[,2], probs=c(.025, .975))
</code></pre>

<hr>
<h2 id='residual.boot'>
Residual bootstrap in linear models
</h2><span id='topic+residual.boot'></span>

<h3>Description</h3>

<p>This function performs the residual bootstrap in linear models as described by Efron (1979, ISBN:978-1-4612-4380-9).  
Linear models incorporating categorical and/or quantitative predictor variables with a quantitative response are allowed.  
The function output creates the bootstrap sampling distribution for each coefficient.  
Estimation is performed via least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residual.boot(formula, B = 1000, data = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residual.boot_+3A_formula">formula</code></td>
<td>

<p>input a linear model formula of the form <code>response</code>~<code>predictors</code> as you would in the <code>lm()</code> 
function.  All variables must contain non-missing entries.
</p>
</td></tr>
<tr><td><code id="residual.boot_+3A_b">B</code></td>
<td>

<p>number of bootstrap samples.  This should be a large, positive integer value.
</p>
</td></tr>
<tr><td><code id="residual.boot_+3A_data">data</code></td>
<td>

<p>optionally, input the name of the dataset where variables appearing in the model are stored.
</p>
</td></tr>
<tr><td><code id="residual.boot_+3A_seed">seed</code></td>
<td>

<p>optionally, set a value for the seed for the bootstrap sample generation.  The default <code>NULL</code> will
pick a random value for the seed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the user must manipulate the output of the function to conduct hypothesis tests and create 
confidence intervals for the predictor coefficients.  More convenient/streamlined output is expected
in future package versions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bootEstParam</code></td>
<td>
<p>matrix containing the bootstrap parameter estimates.  Each column corresponds to a 
coefficient.  There are <code>B</code> rows, each corresponding to a bootstrap sample.</p>
</td></tr>
<tr><td><code>origEstParam</code></td>
<td>
<p>vector containing the least squares parameter estimates.  These are the same as
estimates obtained from <code>lm</code>.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>numerical value set for the seed.  This is associated with the set of bootstrap parameter
estimates and helps the process to be reproducible.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Megan Heyman, heyman@rose-hulman.edu
</p>


<h3>References</h3>

<p>Efron, B.  (1979). &quot;Bootstrap methods: Another look at the jackknife.&quot;  <em>Annals of Statistics</em>.  Vol. 7, pp.1-26.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Seed &lt;- 14
set.seed(Seed)
y &lt;- rnorm(20) #randomly generated response
x &lt;- rnorm(20) #randomly generated predictor
ResidObj &lt;- residual.boot(y~x, B=100, seed=Seed) #perform the residual bootstrap

#plot the sampling distribution of the slope coefficient
hist(ResidObj$bootEstParam[,2], main="Residual Bootstrap Sampling Distn.",
     xlab="Slope Estimate") 

#bootstrap 95% CI for slope parameter (percentile method)
quantile(ResidObj$bootEstParam[,2], probs=c(.025, .975))
</code></pre>

<hr>
<h2 id='wild.boot'>Wild Bootstrap in Linear Models
</h2><span id='topic+wild.boot'></span>

<h3>Description</h3>

<p>This function performs the wild/external bootstrap in linear models as described by Wu (1986) &lt;doi:10.1214/aos/1176350142&gt;.  
Linear models incorporating categorical and/or quantitative predictor variables with a quantitative response are allowed.  
The function output creates the bootstrap sampling distribution for each coefficient.  
Estimation is performed via least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wild.boot(formula, B = 1000, data = NULL, seed = NULL, bootDistn = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wild.boot_+3A_formula">formula</code></td>
<td>

<p>input a linear model formula of the form <code>response</code>~<code>predictors</code> as you would in the <code>lm()</code> 
function.  All variables must contain non-missing entries.
</p>
</td></tr>
<tr><td><code id="wild.boot_+3A_b">B</code></td>
<td>

<p>number of bootstrap samples.  This should be a large, positive integer value.
</p>
</td></tr>
<tr><td><code id="wild.boot_+3A_data">data</code></td>
<td>

<p>optionally, input the name of the dataset where variables appearing in the model are stored.
</p>
</td></tr>
<tr><td><code id="wild.boot_+3A_seed">seed</code></td>
<td>

<p>optionally, set a value for the seed for the bootstrap sample generation.  The default <code>NULL</code> will
pick a random value for the seed.
</p>
</td></tr>
<tr><td><code id="wild.boot_+3A_bootdistn">bootDistn</code></td>
<td>

<p>distribution used to create the wild bootstrap weights for the residuals.  Allowed distributions include
<code>"normal"</code>, <code>"uniform"</code>, <code>"exponential"</code>, <code>"laplace"</code>, <code>"lognormal"</code>, 
<code>"gumbel"</code>, <code>"t5"</code>, <code>"t8"</code>, and <code>"t14"</code>.  The numbers after the t-distributions
indicate the degrees of freedom.  Any selected distribution creates weights with mean 0 and variance 1 from
the named distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the user must manipulate the output of the function to conduct hypothesis tests and create 
confidence intervals for the predictor coefficients.  More convenient/streamlined output is expected
in future package versions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>bootEstParam</code></td>
<td>
<p>matrix containing the bootstrap parameter estimates.  Each column corresponds to a 
coefficient.  There are <code>B</code> rows, each corresponding to a bootstrap sample.</p>
</td></tr>
<tr><td><code>origEstParam</code></td>
<td>
<p>vector containing the least squares parameter estimates.  These are the same as
estimates obtained from <code>lm</code>.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>numerical value set for the seed.  This is associated with the set of bootstrap parameter
estimates and helps the process to be reproducible.</p>
</td></tr>
<tr><td><code>bootDistn</code></td>
<td>
<p>type of distribution used to generate the wild bootstrap weights for the residuals</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Megan Heyman, heyman@rose-hulman.edu
</p>


<h3>References</h3>

<p>Wu, C.F.J.  (1986). &quot;Jackknife, Bootstrap, and Other Resampling Methods in Regression Analysis.&quot;  <em>Annals of Statistics</em>.  Vol. 14, No. 4, pp.1261 - 1295.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Seed &lt;- 14
set.seed(Seed)
y &lt;- rnorm(20) #randomly generated response
x &lt;- rnorm(20) #randomly generated predictor
WildObj &lt;- wild.boot(y~x, B=100, seed=Seed) #perform the wild bootstrap

#plot the sampling distribution of the slope coefficient
hist(WildObj$bootEstParam[,2], main="Wild Bootstrap Sampling Distn.",
     xlab="Slope Estimate") 

#bootstrap 95% CI for slope parameter (percentile method)
quantile(WildObj$bootEstParam[,2], probs=c(.025, .975))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
