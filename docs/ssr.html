<!DOCTYPE html><html><head><title>Help for package ssr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ssr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#friedman1'><p>friedman1 dataset.</p></a></li>
<li><a href='#plot.ssr'><p>Plots a ssr object</p></a></li>
<li><a href='#predict.ssr'><p>Predictions from a fitted ssr object</p></a></li>
<li><a href='#split_train_test'><p>Splits a data frame into train and test sets.</p></a></li>
<li><a href='#ssr'><p>Fits a semi-supervised regression model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Semi-Supervised Regression Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of semi-supervised regression methods including self-learning and co-training by committee based on Hady, M. F. A., Schwenker, F., &amp; Palm, G. (2009) &lt;<a href="https://doi.org/10.1007%2F978-3-642-04274-4_13">doi:10.1007/978-3-642-04274-4_13</a>&gt;. Users can define which set of regressors to use as base models from the 'caret' package, other packages, or custom functions.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/enriquegit/ssr">https://github.com/enriquegit/ssr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/enriquegit/ssr/issues">https://github.com/enriquegit/ssr/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, e1071</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, tgp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-02 14:19:24 UTC; enriqueg</td>
</tr>
<tr>
<td>Author:</td>
<td>Enrique Garcia-Ceja
    <a href="https://orcid.org/0000-0001-6864-8557"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Enrique Garcia-Ceja &lt;e.g.mx@ieee.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-02 15:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='friedman1'>friedman1 dataset.</h2><span id='topic+friedman1'></span>

<h3>Description</h3>

<p>A dataset generated with <code><a href="tgp.html#topic+friedman.1.data">friedman.1.data</a></code> from 'tgp' package.
The friedman1 data set is commonly used to test semi-supervised regression methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>friedman1
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows and 11 numeric variables. All variables were scaled to 0-1.
X1 to X10 are the input variables and Ytrue is the output variable.</p>

<hr>
<h2 id='plot.ssr'>Plots a ssr object</h2><span id='topic+plot.ssr'></span>

<h3>Description</h3>

<p>Plots the results of a fitted ssr object if a testset was provided when fitting the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ssr'
plot(x, metric = "rmse", ptype = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ssr_+3A_x">x</code></td>
<td>
<p>a fitted object of class &quot;ssr&quot;.</p>
</td></tr>
<tr><td><code id="plot.ssr_+3A_metric">metric</code></td>
<td>
<p>the type of metric to be plotted (&quot;rmse&quot;, &quot;mae&quot;, &quot;cor&quot;), defaults to &quot;rmse&quot;. &quot;cor&quot; is for pearson correlation.</p>
</td></tr>
<tr><td><code id="plot.ssr_+3A_ptype">ptype</code></td>
<td>
<p>an integer specifying the type of plot. The default 1, plots the performance metric of the fitted model.
Any value different of 1, plots the performance metric of the individual regressors used to build the model.</p>
</td></tr>
<tr><td><code id="plot.ssr_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the plot function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates performance plots to quickly inspect the results of the fitted model.
The fitted model contains all the necessary data so the user can create custom plots, if required.
</p>


<h3>Value</h3>

<p>a NULL invisible object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- friedman1 # Load dataset.

set.seed(1234)

# Prepare the data.
split1 &lt;- split_train_test(dataset, pctTrain = 70)
split2 &lt;- split_train_test(split1$trainset, pctTrain = 5)
L &lt;- split2$trainset
U &lt;- split2$testset[, -11]
testset &lt;- split1$testset
regressors &lt;- list(knn = caret::knnreg)
model &lt;- ssr("Ytrue ~ .", L, U, regressors = regressors, testdata = testset, maxits = 10)

# Plot the RMSE of the fitted model.
plot(model, metric = "rmse", ptype = 1)

# Plot the MAE.
plot(model, metric = "mae", ptype = 1)
</code></pre>

<hr>
<h2 id='predict.ssr'>Predictions from a fitted ssr object</h2><span id='topic+predict.ssr'></span>

<h3>Description</h3>

<p>Returns a vector of predicted responses from the fitted ssr object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ssr'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ssr_+3A_object">object</code></td>
<td>
<p>fitted object of class ssr.</p>
</td></tr>
<tr><td><code id="predict.ssr_+3A_newdata">newdata</code></td>
<td>
<p>data frame with the input variables from which the response variable is to be predicted.</p>
</td></tr>
<tr><td><code id="predict.ssr_+3A_...">...</code></td>
<td>
<p>additional arguments (not used)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector with the predictions for each row of the input data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- friedman1 # Load friedman1 dataset.

set.seed(1234)

# Split the dataset into 70% for training and 30% for testing.
split1 &lt;- split_train_test(dataset, pctTrain = 70)

# Choose 5% of the train set as the labeled set L and the remaining will be the unlabeled set U.
split2 &lt;- split_train_test(split1$trainset, pctTrain = 5)

L &lt;- split2$trainset

U &lt;- split2$testset[, -11] # Remove the labels.

testset &lt;- split1$testset

regressors &lt;- list(knn = caret::knnreg)

model &lt;- ssr("Ytrue ~ .", L, U, regressors = regressors, testdata = testset, maxits = 10)

# Plot RMSE.
plot(model)

# Get the predictions on the testset.
predictions &lt;- predict(model, testset)

# Calculate RMSE on the test set.
sqrt(mean((predictions - testset$Ytrue)^2))
</code></pre>

<hr>
<h2 id='split_train_test'>Splits a data frame into train and test sets.</h2><span id='topic+split_train_test'></span>

<h3>Description</h3>

<p>Utility function to randomly split a data frame into train and test sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_train_test(df, pctTrain)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_train_test_+3A_df">df</code></td>
<td>
<p>a data frame.</p>
</td></tr>
<tr><td><code id="split_train_test_+3A_pcttrain">pctTrain</code></td>
<td>
<p>numeric value that specifies the percentage of rows to be included in the train set. The remaining rows are added to the test set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the first element being the train set and the second element the test set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)

dataset &lt;- friedman1

nrow(dataset) # print number of rows

split1 &lt;- split_train_test(dataset, pctTrain = 70) # select 70% for training

nrow(split1$trainset) # number of rows of the train set

nrow(split1$testset) # number of rows of the test set

head(split1$trainset) # display first rows of train set

</code></pre>

<hr>
<h2 id='ssr'>Fits a semi-supervised regression model</h2><span id='topic+ssr'></span>

<h3>Description</h3>

<p>This function implements the <em>co-training by committee</em> and <em>self-learning</em> semi-supervised regression algorithms with a set of <em>n</em> base regressor(s) specified by the user.
When only one model is present in the list of regressors, self-learning is performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssr(theFormula, L, U, regressors = list(lm = lm, knn = caret::knnreg),
  regressors.params = NULL, pool.size = 20, gr = 1, maxits = 20,
  testdata = NULL, shuffle = TRUE, verbose = TRUE,
  plotmetrics = FALSE, U.y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssr_+3A_theformula">theFormula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> that specifies the response and the predictor variables.
Two formats are supported: <code>"Y ~ ."</code> and <code>"Y ~ var1 + var2 + ... + varn"</code>.</p>
</td></tr>
<tr><td><code id="ssr_+3A_l">L</code></td>
<td>
<p>a data frame that contains the initial labeled training set.</p>
</td></tr>
<tr><td><code id="ssr_+3A_u">U</code></td>
<td>
<p>a data frame that contains the unlabeled data.
If the provided data frame has the response variable as one of its columns, it will be discarded.</p>
</td></tr>
<tr><td><code id="ssr_+3A_regressors">regressors</code></td>
<td>
<p>a list of custom functions and/or strings naming the regression models to be used.
The strings must contain a valid name of a regression model from the 'caret' package.
The list of available regression models from the 'caret' package can be found <a href="https://topepo.github.io/caret/available-models.html">here</a>.
Functions must be named, e.g., <code>list(linearModel=lm)</code>. List names for models defined with strings are optional.
A list can contain both, strings and functions: <code>list("kknn", linearModel=lm)</code>.
For better performance in time, it is recommended to pass functions directly rather than using 'caret' strings since 'caret' does additional preprocessing when training models.
Examples can be found in the vignettes.</p>
</td></tr>
<tr><td><code id="ssr_+3A_regressors.params">regressors.params</code></td>
<td>
<p>a list of lists that specifies the parameters for each custom function.
For 'caret' models specified as strings in <code>regressors</code>, parameters cannot be passed, use <code>NULL</code> instead.
The parameters are specified with a named list.
For example, if <code>regressors = list("lm", knn=knnreg)</code>, the number of nearest neighbors for knn can be set with <code>list(NULL, list(k = 7))</code>.</p>
</td></tr>
<tr><td><code id="ssr_+3A_pool.size">pool.size</code></td>
<td>
<p>specifies the number of candidate elements to be sampled from the unlabeled set <code>U</code>.
The best candidate elements from the pool are labeled and added to the training set.
The <code>gr</code> parameter controls how many of the best candidates are used to augment the training set at each iteration.
This parameter has big influence in computational time since in each iteration, <code>pool.size * length(regressors)</code> models are trained and evaluated in order to find the best candidate data points.</p>
</td></tr>
<tr><td><code id="ssr_+3A_gr">gr</code></td>
<td>
<p>an integer specifying the <em>growth rate</em>, i.e., how many of the best elements from the pool are added to the training set for each base model at each iteration.</p>
</td></tr>
<tr><td><code id="ssr_+3A_maxits">maxits</code></td>
<td>
<p>an integer that specifies the maximum number of iterations.
The training phase will terminate either when <code>maxits</code> is reached or when <code>U</code> becomes empty.</p>
</td></tr>
<tr><td><code id="ssr_+3A_testdata">testdata</code></td>
<td>
<p>a data frame containing the test set to be evaluated within each iteration.
If <code>verbose = TRUE</code> and <code>plotmetrics = TRUE</code> the predictive performance of the model on the test set will be printed/plotted for each iteration.</p>
</td></tr>
<tr><td><code id="ssr_+3A_shuffle">shuffle</code></td>
<td>
<p>a boolean specifying whether or not to shuffle the data frames rows before training the models. Defaults to <code>TRUE</code>.
Some models like neural networks are sensitive to row ordering. Often, you may want to shuffle before training.</p>
</td></tr>
<tr><td><code id="ssr_+3A_verbose">verbose</code></td>
<td>
<p>a boolean specifying whether or not to print diagnostic information to the console within each iteration.
If <code>testdata</code> is provided, the information includes performance on the test set such as RMSE and improvement percent with respect to the initial model before data from <code>U</code> was used.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ssr_+3A_plotmetrics">plotmetrics</code></td>
<td>
<p>a boolean that specifies if performance metrics should be plotted for each iteration when <code>testdata</code> is provided. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ssr_+3A_u.y">U.y</code></td>
<td>
<p>an optional numeric vector with the true values fo the response variable for the unlabeled set <code>U</code>.
If this parameter is <code>!= NULL</code> then, the true values will be used to determine the best candidates to augment the training set
and the true values will be kept when adding them to the training set.
<em>This parameter should be used with caution</em> and is intended to be used to generate an upper bound model for comparison purposes only.
This is to simulate the case when the model can label the unlabeled data points used to augment the training set with 100% accuracy.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The co-training by committee implementation is based on Hady et al. (2009). It consists of a set of <em>n</em> base models (the committee), each, initially trained with independent bootstrap samples from the labeled training set <code>L</code>. The Out-of-Bag (OOB) elements are used for validation. The training set for each base model <em>b</em> is augmented by selecting the most relevant elements from the unlabeled data set <code>U</code>. To determine the most relevant elements for each base model <em>b</em>, the other models (excluding <em>b</em>) label a set of data <code>pool.size</code> points sampled from <code>U</code> by taking the average of their predictions. For each newly labeled data point, the base model <em>b</em> is trained with its current labeled training data plus the new data point and the error on its OOB validation data is computed. The top <code>gr</code> points that reduce the error the most are kept and used to augment the labeled training set of <em>b</em> and removed from <code>U</code>.
</p>
<p>When the <code>regressors</code> list contains a single model, <em>self-learning</em> is performed. In this case, the base model labels its own data points as opposed to co-training by committee in which the data points for a given model are labeled by the other models.
</p>
<p>In the original paper, Hady et al. (2009) use the same type of regressor for the base models but with different parameters to introduce diversity. The <code>ssr</code> function allows the user to specify any type of regressors as the base models. The regressors can be models from the 'caret' package, other packages, or custom functions. Models from other packages or custom functions need to comply with certain structure. First, the model's function used for training must have a formula as its first parameter and a parameter named <code>data</code> that accepts a data frame as the training set. Secondly, the <code>predict()</code> function must have the trained model as its first parameter. Most of the models from other libraries follow this pattern. If they do not follow this pattern, you can still use them by writing a wrapper function. To see examples of all those cases, please check the vignettes.
</p>


<h3>Value</h3>

<p>A list object of class &quot;ssr&quot; containing:
</p>
<p><b>models</b> A list of the final trained models in the last iteration.
</p>
<p><b>formula</b> The formula provided by the user in <code>theFormula</code>.
</p>
<p><b>regressors</b> The list of initial <code>regressors</code> set by the user with formatted names.
</p>
<p><b>regressors.names</b> The names of the regressors <code>names(regressors)</code>.
</p>
<p><b>regressors.params</b> The initial list of parameters provided by the user.
</p>
<p><b>pool.size</b> The initial <code>pool.size</code> specified by the user.
</p>
<p><b>gr</b> The initial <code>gr</code> specified by the user.
</p>
<p><b>testdata</b> A boolean indicating if test data was provided by the user: <code>!is.null(testdata)</code>.
</p>
<p><b>U.y</b> A boolean indicating if <code>U.y</code> was provided by the user: <code>!is.null(U.y)</code>.
</p>
<p><b>numits</b> The total number of iterations performed by the algorithm.
</p>
<p><b>shuffle</b> The initial <code>shuffle</code> value specified by the user.
</p>
<p><b>valuesRMSE</b> A numeric vector with the Root Mean Squared error on the <code>testdata</code> for each iteration.
The length is the number of iterations + 1.
The first position <code>valuesRMSE[1]</code> stores the initial RMSE before using any data from <code>U</code>.
</p>
<p><b>valuesRMSE.all</b> A numeric matrix with <em>n</em> rows and <em>m</em> columns.
Stores Root Mean Squared Errors of the individual regression models.
The number of rows is equal to the number of iterations + 1 and the number of columns is equal to the number of regressors.
A column represents a regressor in the same order as they were provided in <code>regressors</code>.
Each row stores the RMSE for each iteration and for each regression model.
The first row stores the initial RMSE before using any data from <code>U</code>.
</p>
<p><b>valuesMAE</b> Stores Mean Absolute Error information. Equivalent to <b>valuesRMSE</b>.
</p>
<p><b>valuesMAE.all</b> Stores Mean Absolute Errors of the individual regression models. Equivalent to <b>valuesRMSE.all</b>
</p>
<p><b>valuesCOR</b> Stores Pearson Correlation information. Equivalent to <b>valuesRMSE</b>.
</p>
<p><b>valuesCOR.all</b> Stores the Pearson Correlation of the individual regression models. Equivalent to <b>valuesRMSE.all</b>
</p>


<h3>References</h3>

<p>Hady, M. F. A., Schwenker, F., &amp; Palm, G. (2009). Semi-supervised Learning for Regression with Co-training by Committee. In International Conference on Artificial Neural Networks (pp. 121-130). Springer, Berlin, Heidelberg.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- friedman1 # Load friedman1 dataset.

set.seed(1234)

# Split the dataset into 70% for training and 30% for testing.
split1 &lt;- split_train_test(dataset, pctTrain = 70)

# Choose 5% of the train set as the labeled set L and the remaining will be the unlabeled set U.
split2 &lt;- split_train_test(split1$trainset, pctTrain = 5)

L &lt;- split2$trainset

U &lt;- split2$testset[, -11] # Remove the labels.

testset &lt;- split1$testset

# Define list of regressors. Here, only one regressor (KNN). This trains a self-learning model.
# For co-training by committee, add more regressors to the list. See the vignettes for examples.
regressors &lt;- list(knn = caret::knnreg)

# Fit the model.
model &lt;- ssr("Ytrue ~ .", L, U, regressors = regressors, testdata = testset, maxits = 10)

# Plot RMSE.
plot(model)

# Get the predictions on the testset.
predictions &lt;- predict(model, testset)

# Calculate RMSE on the test set.
sqrt(mean((predictions - testset$Ytrue)^2))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
