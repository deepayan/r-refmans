<!DOCTYPE html><html><head><title>Help for package surbayes</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {surbayes}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#surbayes-package'><p>surbayes: Bayesian Analysis of Seemingly Unrelated Regression Models</p></a></li>
<li><a href='#fastKronEye_crossprod'><p>Fast kronecker product of crossproduct matrix</p></a></li>
<li><a href='#fastKronEye_Y'><p>Fast kronecker product with response vector</p></a></li>
<li><a href='#predict_surbayes_cpp'><p>Sample from predictive posterior density C++ helper</p></a></li>
<li><a href='#predict_surbayes_helper'><p>Get one sample from predictive posterior of SUR</p></a></li>
<li><a href='#predict.surbayes'><p>Get predictive posterior samples</p></a></li>
<li><a href='#sample_sigma'><p>Sample Sigma via Gibbs for SUR model</p></a></li>
<li><a href='#sur_sample'><p>Sample from seemingly unrelated regression</p></a></li>
<li><a href='#sur_sample_cov_helper_cpp'><p>Helper function to sample covariance</p></a></li>
<li><a href='#sur_sample_cpp'><p>Sample from SUR via Direct Monte Carlo (C++ version)</p></a></li>
<li><a href='#sur_sample_dmc'><p>Sample SUR model via direct Monte Carlo</p></a></li>
<li><a href='#sur_sample_gibbs_cpp'><p>Power Prior Gibbs sampling</p></a></li>
<li><a href='#sur_sample_powerprior'><p>Sample from SUR posterior via power prior</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Analysis of Seemingly Unrelated Regression Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-08-24</td>
</tr>
<tr>
<td>Author:</td>
<td>Ethan Alt</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ethan Alt &lt;ethanalt@live.unc.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the direct Monte Carlo approach of 
             Zellner and Ando (2010) &lt;<a href="https://doi.org/10.1016%2Fj.jeconom.2010.04.005">doi:10.1016/j.jeconom.2010.04.005</a>&gt;
             to sample from posterior of 
             Seemingly Unrelated Regression (SUR) models. In 
             addition, a Gibbs sampler is implemented that allows 
             the user to analyze SUR models using the power prior.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.4.6), Matrix, rlist</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>Collate:</td>
<td>'RcppExports.R' 'predict.surbayes.R' 'sur_sample_powerprior.R'
'sur_sample_dmc.R' 'sur_sample.R' 'surbayes-package.R'</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ethan-alt/surbayes">https://github.com/ethan-alt/surbayes</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ethan-alt/surbayes/issues">https://github.com/ethan-alt/surbayes/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-08-24 13:15:14 UTC; ethanalt</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-08-26 09:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='surbayes-package'>surbayes: Bayesian Analysis of Seemingly Unrelated Regression Models</h2><span id='topic+surbayes'></span><span id='topic+surbayes-package'></span>

<h3>Description</h3>

<p>Implementation of the direct Monte Carlo approach of 
Zellner and Ando (2010) &lt;doi:10.1016/j.jeconom.2010.04.005&gt;
to sample from posterior of 
Seemingly Unrelated Regression (SUR) models. In 
addition, a Gibbs sampler is implemented that allows 
the user to analyze SUR models using the power prior.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/ethan-alt/surbayes">https://github.com/ethan-alt/surbayes</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ethan-alt/surbayes/issues">https://github.com/ethan-alt/surbayes/issues</a>
</p>
</li></ul>


<hr>
<h2 id='fastKronEye_crossprod'>Fast kronecker product of crossproduct matrix</h2><span id='topic+fastKronEye_crossprod'></span>

<h3>Description</h3>

<p>This is a c++ implementation of the fast kronecker product
t(X) 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastKronEye_crossprod(XtX, Sigma, pvec, n, J)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastKronEye_crossprod_+3A_xtx">XtX</code></td>
<td>
<p>a matrix that is crossprod((X1, ..., XJ)) in R</p>
</td></tr>
<tr><td><code id="fastKronEye_crossprod_+3A_sigma">Sigma</code></td>
<td>
<p>JxJ covariance matrix</p>
</td></tr>
<tr><td><code id="fastKronEye_crossprod_+3A_pvec">pvec</code></td>
<td>
<p>J-dimensional vector giving number of observations for each endpoint</p>
</td></tr>
<tr><td><code id="fastKronEye_crossprod_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="fastKronEye_crossprod_+3A_j">J</code></td>
<td>
<p>number of endpoints</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>matrix</code> result of <code class="reqn">X' (\Sigma \otimes I_n) X</code>
</p>

<hr>
<h2 id='fastKronEye_Y'>Fast kronecker product with response vector</h2><span id='topic+fastKronEye_Y'></span>

<h3>Description</h3>

<p>This is a c++ implementation of the fast kronecker product with response vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastKronEye_Y(Sigma, Y, n, J)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastKronEye_Y_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix</p>
</td></tr>
<tr><td><code id="fastKronEye_Y_+3A_y">Y</code></td>
<td>
<p>matrix of response variables (Y1, ..., YJ)</p>
</td></tr>
<tr><td><code id="fastKronEye_Y_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="fastKronEye_Y_+3A_j">J</code></td>
<td>
<p>number of endpoints</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector with result of <code> kron(Sigma, diag(n)) % y </code>
</p>

<hr>
<h2 id='predict_surbayes_cpp'>Sample from predictive posterior density C++ helper</h2><span id='topic+predict_surbayes_cpp'></span>

<h3>Description</h3>

<p>C++ implementation to obtain a matrix of samples from predictive posterior density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_surbayes_cpp(Mu, Sigmalist, n, J, nsims)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_surbayes_cpp_+3A_mu">Mu</code></td>
<td>
<p>matrix of means</p>
</td></tr>
<tr><td><code id="predict_surbayes_cpp_+3A_sigmalist">Sigmalist</code></td>
<td>
<p>list of covariance matrices</p>
</td></tr>
<tr><td><code id="predict_surbayes_cpp_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="predict_surbayes_cpp_+3A_j">J</code></td>
<td>
<p>number of endpoints</p>
</td></tr>
<tr><td><code id="predict_surbayes_cpp_+3A_nsims">nsims</code></td>
<td>
<p>Number of simulations (number of rows in Mu)</p>
</td></tr>
</table>

<hr>
<h2 id='predict_surbayes_helper'>Get one sample from predictive posterior of SUR</h2><span id='topic+predict_surbayes_helper'></span>

<h3>Description</h3>

<p>C++ implementation to obtain one sample from predictive posterior
density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_surbayes_helper(mu, Sigma, n, J)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_surbayes_helper_+3A_mu">mu</code></td>
<td>
<p>vector of means</p>
</td></tr>
<tr><td><code id="predict_surbayes_helper_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix shared among all observations</p>
</td></tr>
<tr><td><code id="predict_surbayes_helper_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="predict_surbayes_helper_+3A_j">J</code></td>
<td>
<p>number of endpoints</p>
</td></tr>
</table>

<hr>
<h2 id='predict.surbayes'>Get predictive posterior samples</h2><span id='topic+predict.surbayes'></span>

<h3>Description</h3>

<p>This function returns a list of new data sets by sampling
from the posterior predictive density of Y | Y0, Xnew.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'surbayes'
predict(object, newdata, nsims = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.surbayes_+3A_object">object</code></td>
<td>
<p>Result from calling <code>sur_sample</code></p>
</td></tr>
<tr><td><code id="predict.surbayes_+3A_newdata">newdata</code></td>
<td>
<p><code>data.frame</code> of new data</p>
</td></tr>
<tr><td><code id="predict.surbayes_+3A_nsims">nsims</code></td>
<td>
<p>number of posterior draws to take. The default and minimum is 1. The maximum is the number of simulations in surbayes</p>
</td></tr>
<tr><td><code id="predict.surbayes_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>n x J x nsims</code> <code>array</code> of predicted values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Taken from bayesm package
if(nchar(Sys.getenv("LONG_TEST")) != 0) {M=1000} else {M=10}
set.seed(66)
## simulate data from SUR
beta1 = c(1,2)
beta2 = c(1,-1,-2)
nobs = 100
nreg = 2
iota = c(rep(1, nobs))
X1 = cbind(iota, runif(nobs))
X2 = cbind(iota, runif(nobs), runif(nobs))
Sigma = matrix(c(0.5, 0.2, 0.2, 0.5), ncol = 2)
U = chol(Sigma)
E = matrix( rnorm( 2 * nobs ), ncol = 2) %*% U
y1 = X1 %*% beta1 + E[,1]
y2 = X2 %*% beta2 + E[,2]
X1 = X1[, -1]
X2 = X2[, -1]
data = data.frame(y1, y2, X1, X2)
names(data) = c( paste0( 'y', 1:2 ), paste0('x', 1:(ncol(data) - 2) ))
## run DMC sampler
formula.list = list(y1 ~ x1, y2 ~ x2 + x3)

## Fit model
out = sur_sample( formula.list, data, M = M )

## Obtain predictions
pred = predict(out, data, nsims = 1)

</code></pre>

<hr>
<h2 id='sample_sigma'>Sample Sigma via Gibbs for SUR model</h2><span id='topic+sample_sigma'></span>

<h3>Description</h3>

<p>This is a c++ implementation of sampling Sigma via Gibbs in SUR model&ndash;inverse Wishart
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_sigma(nu, V, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_sigma_+3A_nu">nu</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code id="sample_sigma_+3A_v">V</code></td>
<td>
<p>scale matrix</p>
</td></tr>
<tr><td><code id="sample_sigma_+3A_p">p</code></td>
<td>
<p>dimension of covariance matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sampled covariance matrix
</p>

<hr>
<h2 id='sur_sample'>Sample from seemingly unrelated regression</h2><span id='topic+sur_sample'></span>

<h3>Description</h3>

<p>This function is a wrapper function that performs either (1) Direct Monte Carlo or (2) Gibbs sampling
of the SUR model depending on whether 1 or 2 data sets are specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sur_sample(
  formula.list,
  data,
  M,
  histdata = NULL,
  Sigma0 = NULL,
  a0 = 1,
  burnin = 0,
  thin = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sur_sample_+3A_formula.list">formula.list</code></td>
<td>
<p>A list of formulas, each element giving the formula for the corresponding endpoint.</p>
</td></tr>
<tr><td><code id="sur_sample_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing all the variables contained in <code>formula.list]</code></p>
</td></tr>
<tr><td><code id="sur_sample_+3A_m">M</code></td>
<td>
<p>Number of samples to be drawn</p>
</td></tr>
<tr><td><code id="sur_sample_+3A_histdata">histdata</code></td>
<td>
<p>A <code>data.frame</code> of historical data to apply power prior on</p>
</td></tr>
<tr><td><code id="sur_sample_+3A_sigma0">Sigma0</code></td>
<td>
<p><em>optional</em> a <code class="reqn">J \times J</code> <code>matrix</code> giving the initial covariance matrix. Default is the MLE. Ignored if <code>histdata</code> is null</p>
</td></tr>
<tr><td><code id="sur_sample_+3A_a0">a0</code></td>
<td>
<p>A scalar between 0 and 1 giving the power prior parameter. Ignored if <code>histdata</code> is null</p>
</td></tr>
<tr><td><code id="sur_sample_+3A_burnin">burnin</code></td>
<td>
<p>A non-negative integer giving the burn-in parameter. Ignored if <code>histdata</code> is null as direct Monte Carlo is performed</p>
</td></tr>
<tr><td><code id="sur_sample_+3A_thin">thin</code></td>
<td>
<p>A positive integer giving the thin parameter. Ignored if <code>histdata</code> is null as direct Monte Carlo is performed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. First element is posterior draws. Second element is list of JxJ covariance matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Taken from bayesm package
if(nchar(Sys.getenv("LONG_TEST")) != 0) {M=1000} else {M=10}
set.seed(66)
## simulate data from SUR
beta1 = c(1,2)
beta2 = c(1,-1,-2)
nobs = 100
nreg = 2
iota = c(rep(1, nobs))
X1 = cbind(iota, runif(nobs))
X2 = cbind(iota, runif(nobs), runif(nobs))
Sigma = matrix(c(0.5, 0.2, 0.2, 0.5), ncol = 2)
U = chol(Sigma)
E = matrix( rnorm( 2 * nobs ), ncol = 2) %*% U
y1 = X1 %*% beta1 + E[,1]
y2 = X2 %*% beta2 + E[,2]
X1 = X1[, -1]
X2 = X2[, -1]
data = data.frame(y1, y2, X1, X2)
names(data) = c( paste0( 'y', 1:2 ), paste0('x', 1:(ncol(data) - 2) ))
## run DMC sampler
formula.list = list(y1 ~ x1, y2 ~ x2 + x3)

## Fit models
out_dmc = sur_sample( formula.list, data, M = M )            ## DMC used
out_powerprior = sur_sample( formula.list, data, M, data )   ## Gibbs used
</code></pre>

<hr>
<h2 id='sur_sample_cov_helper_cpp'>Helper function to sample covariance</h2><span id='topic+sur_sample_cov_helper_cpp'></span>

<h3>Description</h3>

<p>This function is called by <code>sur_sample_cov_cpp</code>.
It samples the covariance matrix of a SUR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sur_sample_cov_helper_cpp(Y, Xlist, n, J, pj, sigma11, r1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_y">Y</code></td>
<td>
<p>A <code>matrix</code>, each column a <code>vector</code> of responses</p>
</td></tr>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_xlist">Xlist</code></td>
<td>
<p>A <code>list</code>, each element a design <code>matrix</code></p>
</td></tr>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_n">n</code></td>
<td>
<p>Integer giving number of observations</p>
</td></tr>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_j">J</code></td>
<td>
<p>Integer giving number of endpoints</p>
</td></tr>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_pj">pj</code></td>
<td>
<p>A <code>vector</code> giving number of covariates per endpoint</p>
</td></tr>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_sigma11">sigma11</code></td>
<td>
<p>A scalar giving a draw for the (1,1) component of the covariance matrix</p>
</td></tr>
<tr><td><code id="sur_sample_cov_helper_cpp_+3A_r1">r1</code></td>
<td>
<p>A <code>vector</code> of residuals for the first endpoint's regression</p>
</td></tr>
</table>

<hr>
<h2 id='sur_sample_cpp'>Sample from SUR via Direct Monte Carlo (C++ version)</h2><span id='topic+sur_sample_cpp'></span>

<h3>Description</h3>

<p>C++ implementation of Zellner and Ando (2010) Direct Monte Carlo
method for sampling from the posterior of a Bayesian SUR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sur_sample_cpp(Y, Xlist, y, X, XtX, pj, M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sur_sample_cpp_+3A_y">Y</code></td>
<td>
<p><code>matrix</code> <code class="reqn">(y_1, \ldots y_J)</code></p>
</td></tr>
<tr><td><code id="sur_sample_cpp_+3A_xlist">Xlist</code></td>
<td>
<p>A <code>list</code>, each element a design <code>matrix</code></p>
</td></tr>
<tr><td><code id="sur_sample_cpp_+3A_y">y</code></td>
<td>
<p><code>vector</code> of responses</p>
</td></tr>
<tr><td><code id="sur_sample_cpp_+3A_x">X</code></td>
<td>
<p>design <code>matrix</code></p>
</td></tr>
<tr><td><code id="sur_sample_cpp_+3A_xtx">XtX</code></td>
<td>
<p><code>matrix</code> giving <code>crossprod(cbind(X1, ..., XJ))</code></p>
</td></tr>
<tr><td><code id="sur_sample_cpp_+3A_pj">pj</code></td>
<td>
<p><code>vector</code> giving number of covariates per endpoint</p>
</td></tr>
<tr><td><code id="sur_sample_cpp_+3A_m">M</code></td>
<td>
<p>An integer giving the number of desired samples</p>
</td></tr>
</table>

<hr>
<h2 id='sur_sample_dmc'>Sample SUR model via direct Monte Carlo</h2><span id='topic+sur_sample_dmc'></span>

<h3>Description</h3>

<p>This function samples from the posterior of a SUR model using the DMC method of Ando and Zellner (2010)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sur_sample_dmc(formula.list, data, M = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sur_sample_dmc_+3A_formula.list">formula.list</code></td>
<td>
<p>A list of formulas, each element giving the formula for the corresponding endpoint.</p>
</td></tr>
<tr><td><code id="sur_sample_dmc_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing all the variables contained in <code>formula.list]</code></p>
</td></tr>
<tr><td><code id="sur_sample_dmc_+3A_m">M</code></td>
<td>
<p>Number of samples to be drawn</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. First element is posterior draws. Second element is list of JxJ covariance matrices. Other elements are helpful statistics about the SUR model to pass to other functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Taken from bayesm package
if(nchar(Sys.getenv("LONG_TEST")) != 0) {M=1000} else {M=10}
set.seed(66)
## simulate data from SUR
beta1 = c(1,2)
beta2 = c(1,-1,-2)
nobs = 100
nreg = 2
iota = c(rep(1, nobs))
X1 = cbind(iota, runif(nobs))
X2 = cbind(iota, runif(nobs), runif(nobs))
Sigma = matrix(c(0.5, 0.2, 0.2, 0.5), ncol = 2)
U = chol(Sigma)
E = matrix( rnorm( 2 * nobs ), ncol = 2) %*% U
y1 = X1 %*% beta1 + E[,1]
y2 = X2 %*% beta2 + E[,2]
X1 = X1[, -1]
X2 = X2[, -1]
data = data.frame(y1, y2, X1, X2)
names(data) = c( paste0( 'y', 1:2 ), paste0('x', 1:(ncol(data) - 2) ))
## run DMC sampler
formula.list = list(y1 ~ x1, y2 ~ x2 + x3)

## fit using historical data as current data set--never done in practice
out = sur_sample_powerprior( formula.list, data, histdata = data, M = M )

</code></pre>

<hr>
<h2 id='sur_sample_gibbs_cpp'>Power Prior Gibbs sampling</h2><span id='topic+sur_sample_gibbs_cpp'></span>

<h3>Description</h3>

<p>This is a c++ implementation of Gibbs sampling SUR model with power prior
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sur_sample_gibbs_cpp(
  Sigma,
  M,
  X,
  X0,
  XtX,
  X0tX0,
  Y,
  Y0,
  y,
  y0,
  a0,
  pvec,
  burnin,
  thin
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_sigma">Sigma</code></td>
<td>
<p>initial value for covariance matrix</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_m">M</code></td>
<td>
<p>number of samples</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_x">X</code></td>
<td>
<p>design matrix for current data</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_x0">X0</code></td>
<td>
<p>design matrix for historical data</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_xtx">XtX</code></td>
<td>
<p>matrix that is <code>crossprod(cbind(X1, ..., XJ))</code></p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_x0tx0">X0tX0</code></td>
<td>
<p>matrix that is <code>crossprod(cbind(X01, ..., X0J))</code></p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_y">Y</code></td>
<td>
<p>future response as matrix (Y1, ..., YJ)</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_y0">Y0</code></td>
<td>
<p>historical response as matrix (Y01, ..., Y0J)</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_y">y</code></td>
<td>
<p>future response as vector</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_y0">y0</code></td>
<td>
<p>historical response as vector</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_a0">a0</code></td>
<td>
<p>power prior parameter</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_pvec">pvec</code></td>
<td>
<p><code>vector</code> giving number of covariates per endpoint</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_burnin">burnin</code></td>
<td>
<p>Burn-in parameter</p>
</td></tr>
<tr><td><code id="sur_sample_gibbs_cpp_+3A_thin">thin</code></td>
<td>
<p>Thin parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sampled covariance matrix
</p>

<hr>
<h2 id='sur_sample_powerprior'>Sample from SUR posterior via power prior</h2><span id='topic+sur_sample_powerprior'></span>

<h3>Description</h3>

<p>This function uses Gibbs sampling to sample from the posterior density of a SUR model
using the power prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sur_sample_powerprior(
  formula.list,
  data,
  histdata,
  M,
  Sigma0 = NULL,
  a0 = 1,
  burnin = 0,
  thin = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sur_sample_powerprior_+3A_formula.list">formula.list</code></td>
<td>
<p>A list of formulas, each element giving the formula for the corresponding endpoint.</p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing all the variables contained in <code>formula.list]</code></p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_histdata">histdata</code></td>
<td>
<p>A <code>data.frame</code> of historical data to apply power prior on</p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_m">M</code></td>
<td>
<p>Number of samples to be drawn</p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_sigma0">Sigma0</code></td>
<td>
<p>A <code class="reqn">J \times J</code> <code>matrix</code> giving the initial covariance matrix. Default is the MLE.</p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_a0">a0</code></td>
<td>
<p>A scalar between 0 and 1 giving the power prior parameter</p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_burnin">burnin</code></td>
<td>
<p>A non-negative integer giving the burn-in parameter</p>
</td></tr>
<tr><td><code id="sur_sample_powerprior_+3A_thin">thin</code></td>
<td>
<p>A positive integer giving the thin parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. First element is posterior draws. Second element is list of JxJ covariance matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Taken from bayesm package
if(nchar(Sys.getenv("LONG_TEST")) != 0) {M=1000} else {M=10}
set.seed(66)
## simulate data from SUR
beta1 = c(1,2)
beta2 = c(1,-1,-2)
nobs = 100
nreg = 2
iota = c(rep(1, nobs))
X1 = cbind(iota, runif(nobs))
X2 = cbind(iota, runif(nobs), runif(nobs))
Sigma = matrix(c(0.5, 0.2, 0.2, 0.5), ncol = 2)
U = chol(Sigma)
E = matrix( rnorm( 2 * nobs ), ncol = 2) %*% U
y1 = X1 %*% beta1 + E[,1]
y2 = X2 %*% beta2 + E[,2]
X1 = X1[, -1]
X2 = X2[, -1]
data = data.frame(y1, y2, X1, X2)
names(data) = c( paste0( 'y', 1:2 ), paste0('x', 1:(ncol(data) - 2) ))
## run DMC sampler
formula.list = list(y1 ~ x1, y2 ~ x2 + x3)

## fit using historical data as current data set--never done in practice
out = sur_sample_powerprior( formula.list, data, histdata = data, M = M )
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
