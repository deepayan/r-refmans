<!DOCTYPE html><html lang="en"><head><title>Help for package SplitSoftening</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SplitSoftening}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#predictSoftsplits'><p>Prediction according to &lsquo;soft tree&rsquo;.</p></a></li>
<li><a href='#soften'><p>Create a &lsquo;soft tree&rsquo; structure with softening parameters set</p>
using one of the named method.</a></li>
<li><a href='#softening.by.data.range'><p>Make split softening based on data ranges.</p></a></li>
<li><a href='#softening.by.esd'><p>Soften splits separately using error standard deviation.</p></a></li>
<li><a href='#softening.optimized'><p>Make split softening optimized with Nelder-Mead.</p></a></li>
<li><a href='#softsplits'><p>Create &lsquo;soft tree&rsquo; structure from a tree object.</p></a></li>
<li><a href='#SplitSoftening'><p>Package: Softening splits in classification trees</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1-1</td>
</tr>
<tr>
<td>Title:</td>
<td>Softening Splits in Decision Trees</td>
</tr>
<tr>
<td>Author:</td>
<td>Jakub Dvorak [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jakub Dvorak &lt;JakubDvorak@email.cz&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Enhances:</td>
<td>tree</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gsl</td>
</tr>
<tr>
<td>Description:</td>
<td>Allows to produce and use classification trees with soft (probability) splits,
	as described in: Dvořák, J. (2019), &lt;<a href="https://doi.org/10.1007%2Fs00180-019-00867-1">doi:10.1007/s00180-019-00867-1</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-27 20:15:56 UTC; jakub</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-27 20:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='predictSoftsplits'>Prediction according to &lsquo;soft tree&rsquo;.</h2><span id='topic+predictSoftsplits'></span>

<h3>Description</h3>

<p>Prediction according to &lsquo;soft tree&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictSoftsplits(fit, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictSoftsplits_+3A_fit">fit</code></td>
<td>
<p>The soft tree.</p>
</td></tr>
<tr><td><code id="predictSoftsplits_+3A_newdata">newdata</code></td>
<td>
<p>Data to classify.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The matrix of predicted class probabilities.
</p>

<hr>
<h2 id='soften'>Create a &lsquo;soft tree&rsquo; structure with softening parameters set
using one of the named method.</h2><span id='topic+soften'></span>

<h3>Description</h3>

<p>This is a convenience method implemented over <code><a href="#topic+softsplits">softsplits</a></code>
and the softening functions from this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soften(fit, ds, method, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="soften_+3A_fit">fit</code></td>
<td>
<p>A classification tree - either an object <code>tree</code> which represents a classification tree,
or already a &lsquo;soft tree&rsquo; like created by the <code><a href="#topic+softsplits">softsplits</a></code> function.</p>
</td></tr>
<tr><td><code id="soften_+3A_ds">ds</code></td>
<td>
<p>A data frame used as training data for softening</p>
</td></tr>
<tr><td><code id="soften_+3A_method">method</code></td>
<td>
<p>A name of softening method.
One of: &quot;DR0&quot;, &quot;DR1&quot;, &quot;DR2&quot;, ..., &quot;ESD&quot;, &quot;C4.5&quot;, &quot;optim_d&quot;, &quot;optim_d^2&quot;, &quot;optim_d^4&quot;, &quot;optim_auc&quot;
</p>
<p>The 'method = &quot;DR<em>x</em>&quot;' for some number <em>x</em>: The softening parameters are set
according to &lsquo;data ranges&rsquo; appropriate to tree nodes.
The parameters are configured such that in each node the distance of the boundary of the softened area from split value is
<code class="reqn">2^{-x}r</code>, where <code class="reqn">r</code> is the distance from the split value to the furthest data point in the tree node
projected to the direction from the split value to the boundary.
</p>
<p>The 'method = &quot;ESD&quot;' sets boundaries of the softening using error standard deviation.
This is how C4.5 method sets &quot;probabilistic splits&quot;; for that reason value <code>"C4.5"</code> is an alias for <code>"ESD"</code>.
</p>
<p>The 'method = &quot;optim_d^<em>q</em>&quot;' for some number <em>q</em>: The softening parameters are set
by optimization process which minimizes <code class="reqn">\code{mean}((1.0-p)^q)</code> where <code class="reqn">p</code> is for each data point in 
<code>ds</code> the predicted probability of the correct label.
</p>
<p>If 'method = &quot;optim_auc&quot;': The classification tree <code>fit</code> must perform prediction to two classes.
The value of the &lsquo;area under ROC curve&rsquo; computed on the data set <code>ds</code> is maximized by optimization.</p>
</td></tr>
<tr><td><code id="soften_+3A_control">control</code></td>
<td>
<p>List of additional configuration paramaters. Possible members in the list are:
<code>verbosity</code>, <code>implementation</code>, <code>iteration.count</code>, <code>sft.ini</code>,
which correspond to the paramaters of <code><a href="#topic+softening.optimized">softening.optimized</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The &lsquo;soft tree&rsquo; structure representing the same tree structure
as given in the parameter <code>fit</code>,
but with softening parameters set using the given method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictSoftsplits">predictSoftsplits</a></code>.
</p>

<hr>
<h2 id='softening.by.data.range'>Make split softening based on data ranges.</h2><span id='topic+softening.by.data.range'></span>

<h3>Description</h3>

<p>This softening configures each softening parameter in the tree
according to &lsquo;data ranges&rsquo; appropriate to tree nodes.
The parameters are configured such that in each node the distance of the boundary of the softened area from split value is
<code>factor</code> * the distance from the split value to the furthest data point in the tree node
projected to the direction from the split value to the boundary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softening.by.data.range(tr, ds, factor = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softening.by.data.range_+3A_tr">tr</code></td>
<td>
<p>The soft tree</p>
</td></tr>
<tr><td><code id="softening.by.data.range_+3A_ds">ds</code></td>
<td>
<p>The data set to be used for determining data boundaries</p>
</td></tr>
<tr><td><code id="softening.by.data.range_+3A_factor">factor</code></td>
<td>
<p>The scalar factor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The soft tree with the new softening parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(require(tree)) {
  train.data &lt;- iris[c(TRUE,FALSE),]
  test.data &lt;- iris[c(FALSE,TRUE),]
  tr &lt;- tree( Species~., train.data )
  
  # tree with "zero softening"
  s0 &lt;- softsplits( tr )
  # softened tree
  s1 &lt;- softening.by.data.range( s0, train.data, .5 )
  
  response0 &lt;- predictSoftsplits( s0, test.data )
  response1 &lt;- predictSoftsplits( s1, test.data )
  # get class with the highest response
  classification0 &lt;- levels(train.data$Species)[apply( response0, 1, which.max )]
  classification1 &lt;- levels(train.data$Species)[apply( response1, 1, which.max )]
  
  # compare classifiction to the labels
  table( classification0, test.data$Species )
  table( classification1, test.data$Species )
}


</code></pre>

<hr>
<h2 id='softening.by.esd'>Soften splits separately using error standard deviation.</h2><span id='topic+softening.by.esd'></span>

<h3>Description</h3>

<p>Set boundaries determined by given data to the splits in the tree,
such that in any inner node if its splitting value would be moved there,
then the number of misclassified cases in this node would be one standard deviation over the actual misclassification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softening.by.esd(fit, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softening.by.esd_+3A_fit">fit</code></td>
<td>
<p>The soft tree</p>
</td></tr>
<tr><td><code id="softening.by.esd_+3A_d">d</code></td>
<td>
<p>The data set</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the same approach as C4.5 uses for &quot;probabilistic splits&quot;
</p>


<h3>References</h3>

<p>Quinlan, J. Ross (1993), <em>C4.5: programs for machine learning</em>, San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
</p>

<hr>
<h2 id='softening.optimized'>Make split softening optimized with Nelder-Mead.</h2><span id='topic+softening.optimized'></span>

<h3>Description</h3>

<p>This softening configures all parameters in the tree
with optimization method Nelder-Mead to minimize the given &lsquo;miss&rsquo; function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softening.optimized(
  tr,
  d,
  miss.fn,
  verbosity = 0,
  implementation = c("gsl", "R"),
  iteration.count = NULL,
  sft.ini = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softening.optimized_+3A_tr">tr</code></td>
<td>
<p>The soft tree</p>
</td></tr>
<tr><td><code id="softening.optimized_+3A_d">d</code></td>
<td>
<p>The data set to be used in intialization for determining data boundaries
and in optimization step to evaluate the objective function on the predictions
on this data set by the soft tree with updated softening parameters.</p>
</td></tr>
<tr><td><code id="softening.optimized_+3A_miss.fn">miss.fn</code></td>
<td>
<p>Function to provide the value of the objective function for optimization.
</p>
<p>The function obtains as an argument the matrix of class probabilities
as returned by <code><a href="#topic+predictSoftsplits">predictSoftsplits</a></code>
when making predictions for the data set <code>d</code> using the soft tree <code>tr</code>
but with some softening parameters reset within optimization procedure.
The function is expected to return one numeric value;
this value is minimized by the optimization method.</p>
</td></tr>
<tr><td><code id="softening.optimized_+3A_verbosity">verbosity</code></td>
<td>
<p>The verbosity level configures how many additional information is printed</p>
</td></tr>
<tr><td><code id="softening.optimized_+3A_implementation">implementation</code></td>
<td>
<p>Indentify implementation of optimizer.</p>
</td></tr>
<tr><td><code id="softening.optimized_+3A_iteration.count">iteration.count</code></td>
<td>
<p>Number of optimizer iterations.</p>
</td></tr>
<tr><td><code id="softening.optimized_+3A_sft.ini">sft.ini</code></td>
<td>
<p>Parameter of softening used as the initial value for the optimization.
</p>

<dl>
<dt><code>"gsl"</code></dt><dd><p> uses <code>multimin</code> function from <code>gsl</code> package.</p>
</dd>
<dt><code>"R"</code></dt><dd><p> uses <code>optim</code> - the standard optimization function in R.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>The soft tree with the new softening parameters
</p>

<hr>
<h2 id='softsplits'>Create &lsquo;soft tree&rsquo; structure from a tree object.</h2><span id='topic+softsplits'></span>

<h3>Description</h3>

<p>Create &lsquo;soft tree&rsquo; structure from a tree object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softsplits(fit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softsplits_+3A_fit">fit</code></td>
<td>
<p>A tree object: must be a classification tree</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data structure suitable for softening splits in the tree
and for evaluation of &lsquo;soft tree&rsquo; on submitted data.
The returned object is ready for softening, but it is not yet softened.
The result of prediction for some data with the returned object
is still the same as with the original tree <code>fit</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictSoftsplits">predictSoftsplits</a></code>.
</p>

<hr>
<h2 id='SplitSoftening'>Package: Softening splits in classification trees</h2><span id='topic+SplitSoftening'></span>

<h3>Description</h3>

<p>The basic idea of split softening is to modify the process of classification
of an input case with a decision tree such that
in the area near the threshold of a softened split both branches
of the tree are used to provide a prediction for the submitted case
and their results are combined.
</p>


<h3>Details</h3>

<p>Functions in this package allow to add softening to the nodes of
a classification tree created with the package <code>tree</code>.
Each node where a decision on a continuous variable is made is enriched
with softening parameters which specify the boundaries of the softening area
and which together with the original split threshold determine the weights
of the branches when combined.
</p>
<p>The weights of branches are (1/2, 1/2) in the original split threshold.
Other points inside the softening area have weights given by linear interpolation
to reach the values (0, 1), or vice versa, on the boundaries of the softening area.
</p>
<p>A data structure for a decision tree prepared for softening
can be created from a <code>tree</code> object
with the <code><a href="#topic+softsplits">softsplits</a></code> function.
</p>
<p>Softening parameters may be set to the &lsquo;soft tree&rsquo; structure.
The package offers the following functions for this purpose:
</p>

<ul>
<li><p><code><a href="#topic+softening.by.data.range">softening.by.data.range</a></code>
</p>
</li>
<li><p><code><a href="#topic+softening.by.esd">softening.by.esd</a></code>
</p>
</li>
<li><p><code><a href="#topic+softening.optimized">softening.optimized</a></code>
</p>
</li>
<li><p><code><a href="#topic+soften">soften</a></code>
</p>
</li></ul>

<p>A softened tree might be used to obtain a prediction for a dataset
using the <code><a href="#topic+predictSoftsplits">predictSoftsplits</a></code> function.
</p>


<h3>References</h3>

<p>Dvořák, J. (2019), <em>Classification trees with soft splits optimized for ranking</em> &lt;doi:10.1007/s00180-019-00867-1&gt;
<code>https://rdcu.be/bkeW2</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
