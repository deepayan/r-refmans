<!DOCTYPE html><html><head><title>Help for package rfvimptest</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rfvimptest}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#allinone'><p>Apply all available (sequential) permutation testing approaches of variable importance measures with one function call</p></a></li>
<li><a href='#hearth2'><p>Data on Coronary Artery Disease</p></a></li>
<li><a href='#rfvimptest'><p>Testing the statistical significance of predictors in random forests using sequential permutation testing</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sequential Permutation Testing of Random Forest Variable
Importance Measures</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-01-25</td>
</tr>
<tr>
<td>Description:</td>
<td>Sequential permutation testing for statistical
  significance of predictors in random forests. The main function
  of the package is rfvimptest(), which allows to test for the
  statistical significance of predictors in random forests using different 
  (sequential) permutation test strategies. The advantage of
  sequential over conventional permutation tests is that they
  are computationally considerably less intensive, as the sequential
  procedure is stopped as soon as there is sufficient evidence
  for either the null or the alternative hypothesis.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>party, ranger, permimp</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-25 14:47:23 UTC; hornung</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander Hapfelmeier [aut],
  Roman Hornung [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Roman Hornung &lt;hornung@ibe.med.uni-muenchen.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-25 15:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='allinone'>Apply all available (sequential) permutation testing approaches of variable importance measures with one function call</h2><span id='topic+allinone'></span>

<h3>Description</h3>

<p>This is a helper function, which allows to perform all (sequential) permutation testing approaches of variable importance measures described in <code><a href="#topic+rfvimptest">rfvimptest</a></code>
with a single function call. This may be useful for comparing the results obtained using the different approaches.
Importantly, this function is computationally efficient by re-using the permuted variable importance values obtained
for the conventional permutation test (that performs all <code>Mmax</code> permutations) for the other approaches. For details
on the different approaches see <code><a href="#topic+rfvimptest">rfvimptest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allinone(
  data,
  yname,
  Mmax = 500,
  varnames = NULL,
  p0 = 0.06,
  p1 = 0.04,
  alpha = 0.05,
  beta = 0.2,
  A = 0.1,
  B = 10,
  h = 8,
  nperm = 1,
  ntree = 500,
  progressbar = TRUE,
  condinf = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="allinone_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing the variables in the model.</p>
</td></tr>
<tr><td><code id="allinone_+3A_yname">yname</code></td>
<td>
<p>Name of outcome variable.</p>
</td></tr>
<tr><td><code id="allinone_+3A_mmax">Mmax</code></td>
<td>
<p>Maximum number of permutations used in each permutation test. Default is 500.</p>
</td></tr>
<tr><td><code id="allinone_+3A_varnames">varnames</code></td>
<td>
<p>Optional. Names of the variables for which testing should be performed. By default all variables in <code>data</code> with the exception of the outcome variable are used.</p>
</td></tr>
<tr><td><code id="allinone_+3A_p0">p0</code></td>
<td>
<p>The value of the p-value in the null hypothesis (H0: p = p0) of SPRT and SAPT. Default is 0.06.</p>
</td></tr>
<tr><td><code id="allinone_+3A_p1">p1</code></td>
<td>
<p>The value of the p-value in the alternative hypothesis (H1: p = p1) of SPRT and SAPT. Default is 0.04.</p>
</td></tr>
<tr><td><code id="allinone_+3A_alpha">alpha</code></td>
<td>
<p>The significance level of SPRT when p = p0. Also known as type I error. Default is 0.05.</p>
</td></tr>
<tr><td><code id="allinone_+3A_beta">beta</code></td>
<td>
<p>One minus the power of SPRT when p = p1. Also known as type II error. Default is 0.2.</p>
</td></tr>
<tr><td><code id="allinone_+3A_a">A</code></td>
<td>
<p>The quantity A in the formula of SAPT. Default is 0.1 for a type I error of 0.05. Usually not changed by the user.</p>
</td></tr>
<tr><td><code id="allinone_+3A_b">B</code></td>
<td>
<p>The quantity B in the formula of SAPT. Default is 10 (1/A) for a type I error of 0.05. Usually not changed by the user.</p>
</td></tr>
<tr><td><code id="allinone_+3A_h">h</code></td>
<td>
<p>The quantity h in the formula for the sequential Monte Carlo p-value. The default value for h is 8. Larger values lead to more precise p-value estimates,
but are computationally more expensive.</p>
</td></tr>
<tr><td><code id="allinone_+3A_nperm">nperm</code></td>
<td>
<p>The numbers of permutations of the out-of-bag observations over which the results are averaged, when calculating the variable importance measure values. Default is 1. Larger values than 1 can only be considered when <code>condinf=TRUE</code>, that is, when using random forests
with conditional inference trees (Hothorn et al., 2006) as base learners.</p>
</td></tr>
<tr><td><code id="allinone_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees per forest. Default is 500.</p>
</td></tr>
<tr><td><code id="allinone_+3A_progressbar">progressbar</code></td>
<td>
<p>Output the current progress of the calculations for each variable to the console? Default is TRUE.</p>
</td></tr>
<tr><td><code id="allinone_+3A_condinf">condinf</code></td>
<td>
<p>Set this value to <code>TRUE</code> if random forests using conditional inference trees (Hothorn et al., 2006) should
be used and to <code>FALSE</code> if classical random forests using CART trees should be used. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="allinone_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>ranger::ranger</code> (if <code>condinf=FALSE</code>) or <br /> <code>party::cforest_unbiased()</code> (if <code>condinf=TRUE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>allinone</code> with elements
</p>
<table>
<tr><td><code>varimp</code></td>
<td>
<p>Variable importance for each considered independent variable.</p>
</td></tr>
<tr><td><code>testres</code></td>
<td>
<p>The results (&quot;keep H0&quot; vs. &quot;accept H1&quot;) of the tests for each considered independent variable.</p>
</td></tr>
<tr><td><code>pvalues</code></td>
<td>
<p>The p-values of the tests for each considered independent variable. Note that p-values are only obtained for the
method types &quot;pval&quot; and &quot;complete&quot;.</p>
</td></tr>
<tr><td><code>stoppedearly</code></td>
<td>
<p>For each independent variable, whether the calculations stopped early (&quot;yes&quot;) or the maximum of <code>Mmax</code> permutations was reached (&quot;no&quot;).</p>
</td></tr>
<tr><td><code>perms</code></td>
<td>
<p>The number of permutations performed for each independent variable.</p>
</td></tr>
<tr><td><code>Mmax</code></td>
<td>
<p>Maximum number of permutations used in each permutation test.</p>
</td></tr>
<tr><td><code>ntree</code></td>
<td>
<p>Number of trees per forest.</p>
</td></tr>
<tr><td><code>comptime</code></td>
<td>
<p>The time the computations needed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander Hapfelmeier, Roman Hornung
</p>


<h3>References</h3>


<ul>
<li><p> Breiman, L. (2001). Random forests. Mach Learn, 45:5-32, &lt;doi: <a href="https://doi.org/10.1023/A:1010933404324">10.1023/A:1010933404324</a>&gt;.
</p>
</li>
<li><p> Coleman, T., Peng, W., Mentch, L. (2019). Scalable and efficient hypothesis testing with random forests. arXiv preprint arXiv:1904.07830, &lt;doi: <a href="https://doi.org/10.48550/arXiv.1904.07830">10.48550/arXiv.1904.07830</a>&gt;.
</p>
</li>
<li><p> Hapfelmeier, A., Hornung, R., Haller, B. (2022). Sequential Permutation Testing of Random Forest Variable Importance Measures. arXiv preprint arXiv:2206.01284, &lt;doi: <a href="https://doi.org/10.48550/arXiv.2206.01284">10.48550/arXiv.2206.01284</a>&gt;.
</p>
</li>
<li><p> Hapfelmeier, A., Ulm, K. (2013). A new variable selection approach using Random Forests. CSDA 60:50–69, &lt;doi: <a href="https://doi.org/10.1016/j.csda.2012.09.020">10.1016/j.csda.2012.09.020</a>&gt;.
</p>
</li>
<li><p> Hapfelmeier, A., Hothorn, T., Ulm, K., Strobl, C. (2014). A new variable importance measure for random forests with missing data. Stat Comput 24:21–34, &lt;doi: <a href="https://doi.org/10.1007/s11222-012-9349-1">10.1007/s11222-012-9349-1</a>&gt;.
</p>
</li>
<li><p> Hothorn, T., Hornik, K., Zeileis, A. (2006). Unbiased Recursive Partitioning: A Conditional Inference Framework. J Comput Graph Stat 15(3):651–674, &lt;doi: <a href="https://doi.org/10.1198/106186006X133933">10.1198/106186006X133933</a>&gt;.
</p>
</li>
<li><p> Wright, M. N., Ziegler, A. (2017). ranger: A fast implementation of random forests for high dimensional data in C++ and R. J Stat Softw 77:1-17, &lt;doi: <a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a>&gt;.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rfvimptest">rfvimptest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Load package:
library("rfvimptest")

# Set seed to obtain reproducible results:
set.seed(1234)

# Load example data:
data(hearth2)

# NOTE: For illustration purposes very small numbers of maximum
# permutations are considered in the below examples.
# This number would be much too small for actual applications.
# The default number is Max=500.

# When using condinf=FALSE (default) the results for the two-sample
# permutation tests are not obtained:
(ptest &lt;- allinone(data=hearth2, yname="Class",  Mmax=20))

# Variable importance values with p-values from the Monte Carlo p-value
# and the complete approach:
ptest$varimp
ptest$pvalues$pval
ptest$pvalues$complete


# When setting condinf=TRUE the results are obtained for all approaches,
# that is, including those for the two-sample permutation tests
# (in this illustration very small number of trees ntree=30 are used,
# in practice much larger numbers should be used; the default is ntree=500):
(ptest_ci &lt;- allinone(data=hearth2, yname="Class", condinf=TRUE, ntree=30, Mmax=10))
ptest_ci$testres



</code></pre>

<hr>
<h2 id='hearth2'>Data on Coronary Artery Disease</h2><span id='topic+hearth2'></span>

<h3>Description</h3>

<p>This data includes 294 patients undergoing angiography at the Hungarian Institute of Cardiology in Budapest between 1983 and 1987.
</p>


<h3>Format</h3>

<p>A data frame with 294 observations, ten covariates and one two-class outcome variable
</p>


<h3>Details</h3>

<p>The variables are as follows:
</p>

<ul>
<li> <p><code>age</code>. numeric. Age in years
</p>
</li>
<li> <p><code>sex</code>. factor. Sex (1 = male; 0 = female)
</p>
</li>
<li> <p><code>chest_pain</code>. factor. Chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic)
</p>
</li>
<li> <p><code>trestbps</code>. numeric. Resting blood pressure (in mm Hg on admission to the hospital)
</p>
</li>
<li> <p><code>chol</code>. numeric. Serum cholestoral in mg/dl
</p>
</li>
<li> <p><code>fbs</code>. factor. Fasting blood sugar &gt; 120 mg/dl (1 = true; 0 = false)
</p>
</li>
<li> <p><code>restecg</code>. factor. Resting electrocardiographic results (1 = having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV); 0 = normal)
</p>
</li>
<li> <p><code>thalach</code>. numeric. Maximum heart rate achieved
</p>
</li>
<li> <p><code>exang</code>. factor. Exercise induced angina (1 = yes; 0 = no)
</p>
</li>
<li> <p><code>oldpeak</code>. numeric. ST depression induced by exercise relative to rest
</p>
</li>
<li> <p><code>Class</code>. factor. Disease satus (1 = no disease; 2 = coronary artery disease)
</p>
</li></ul>

<p><code style="white-space: pre;">&#8288; &#8288;</code><br />
The original openML dataset was pre-processed in the following way: <br />
</p>
<p>1. The variables were re-named according to the description given on openML.
</p>
<p>2. The missing values which were coded as &quot;-9&quot; were replaced by NA values.
</p>
<p>3. The variables <code>slope</code>, <code>ca</code>, and <code>thal</code> were excluded, because these featured
too many missing values.
</p>
<p>4. The categorical covariates were transformed into factors.
</p>
<p>5. There were 6 <code>restecg</code> values of &quot;2&quot; which were replaced by &quot;1&quot;.
</p>
<p>6. The missing values were imputed: The missing values of the numerical covariates were replaced by the means
of the corresponding non-missing values. The missing values of the categorical covariates were replaced by
the modes of the corresponding non-missing values.
</p>
<p>Note that this dataset is also included in a slightly different form in the R package <code>ordinalForest</code> (version 2.4-2)
under the name <code>hearth</code>. The only difference is that in <code>hearth2</code>, the ordinal outcome variable
<code>Class</code> was transformed into a two-class outcome by only differentiating between diseased vs. healthy,
rather than differentiating between different levels of disease severity.
</p>


<h3>Source</h3>

<p>OpenML: data.name: heart-h, data.id: 1565, link: <a href="https://www.openml.org/d/1565/">https://www.openml.org/d/1565/</a>
</p>


<h3>References</h3>


<ul>
<li><p> Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J.-J., Sandhu, S., Guppy, K. H., Lee, S., Froelicher, V. (1989) International application of a new probability algorithm for the diagnosis of coronary artery disease. The American Journal Of Cardiology, 64, 304&ndash;310.
</p>
</li>
<li><p> Vanschoren, J., van Rijn, J. N., Bischl, B., Torgo, L. (2013) OpenML: networked science in machine learning. SIGKDD Explorations, 15(2), 49&ndash;60.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(hearth2)

table(hearth2$Class)
dim(hearth2)

head(hearth2)

</code></pre>

<hr>
<h2 id='rfvimptest'>Testing the statistical significance of predictors in random forests using sequential permutation testing</h2><span id='topic+rfvimptest'></span>

<h3>Description</h3>

<p>Implements several strategies for testing the statistical significance of predictors in random forests using sequential permutation testing procedures based on the permutation variable importance measure.
See Hapfelmeier et al. (2022) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfvimptest(
  data,
  yname,
  Mmax = 500,
  varnames = NULL,
  p0 = 0.06,
  p1 = 0.04,
  alpha = 0.05,
  beta = 0.2,
  A = 0.1,
  B = 10,
  h = 8,
  nperm = 1,
  ntree = 500,
  progressbar = TRUE,
  test = c("general", "twosample")[1],
  type = c("SPRT", "SAPT", "pval", "certain", "complete")[1],
  condinf = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rfvimptest_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing the variables in the model.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_yname">yname</code></td>
<td>
<p>Name of outcome variable.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_mmax">Mmax</code></td>
<td>
<p>Maximum number of permutations used in each permutation test. Default is 500.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_varnames">varnames</code></td>
<td>
<p>Optional. Names of the variables for which testing should be performed. By default all variables in <code>data</code> with the exception of the outcome variable are used.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_p0">p0</code></td>
<td>
<p>The value of the p-value in the null hypothesis (H0: p = p0) of SPRT and SAPT. Default is 0.06.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_p1">p1</code></td>
<td>
<p>The value of the p-value in the alternative hypothesis (H1: p = p1) of SPRT and SAPT. Default is 0.04.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_alpha">alpha</code></td>
<td>
<p>The significance level of SPRT when p = p0. Also known as type I error. Default is 0.05.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_beta">beta</code></td>
<td>
<p>One minus the power of SPRT when p = p1. Also known as type II error. Default is 0.2.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_a">A</code></td>
<td>
<p>The quantity A in the formula of SAPT. Default is 0.1 for a type I error of 0.05. Usually not changed by the user.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_b">B</code></td>
<td>
<p>The quantity B in the formula of SAPT. Default is 10 (1/A) for a type I error of 0.05. Usually not changed by the user.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_h">h</code></td>
<td>
<p>The quantity h in the formula for the sequential Monte Carlo p-value. The default value for h is 8. Larger values lead to more precise p-value estimates,
but are computationally more expensive.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_nperm">nperm</code></td>
<td>
<p>The numbers of permutations of the out-of-bag observations over which the results are averaged, when calculating the variable importance measure values. Default is 1. Larger values than 1 can only be considered when <code>condinf=TRUE</code>, that is, when using random forests
with conditional inference trees (Hothorn et al., 2006) as base learners.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees per forest. Default is 500.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_progressbar">progressbar</code></td>
<td>
<p>Output the current progress of the calculations for each variable to the console? Default is TRUE.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_test">test</code></td>
<td>
<p>Type of the permutation test to perform. This can be either &quot;general&quot; or &quot;twosample&quot;, where &quot;general&quot; refers to the usual (sequential) permutation
test and &quot;twosample&quot; refers to the two-sample (sequential) permutation test. For the latter, see also Coleman et al. (2019).
Note, however, that &quot;twosample&quot; is experimental and should not be used for formal testing. See the details section below.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_type">type</code></td>
<td>
<p>Type of the sequential method to use in the permutation tests. The choices are: &quot;SPRT&quot;, &quot;SAPT&quot;, &quot;pval&quot;, &quot;certain&quot;, and &quot;complete&quot;. See the 'Details' section below for details.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_condinf">condinf</code></td>
<td>
<p>Set this value to <code>TRUE</code> if random forests using conditional inference trees (Hothorn et al., 2006) should
be used and to <code>FALSE</code> if classical random forests using CART trees should be used. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="rfvimptest_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>ranger::ranger</code> (if <code>condinf=FALSE</code>) or <br /> <code>party::cforest_unbiased()</code> (if <code>condinf=TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only the general permutation test (<code>test="general"</code>) controls the type I error. In contrast, the two-sample permutation test (<code>test="twosample"</code>)
is associated with inflated type I error, which can lead to false positive findings. An advantage of the two-sample permutation test is that it is
very fast. Therefore, this experimental approach may be used as an informal screening tool for finding informative variables.
It is, however, not a valid testing procedure. Note also that
the paper of Coleman et al. (2019) on which the two-sample test is based has not yet been published in a peer-reviewed journal and that
the theory underlying this procedure might thus still need further review.
</p>
<p>SRPT (<code>type="SRPT"</code>) and SAPT (<code>type="SAPT"</code>) are similar sequential procedures, where SRPT is faster with respect to accepting H0, that is, detecting non-informative variables,
whereas SAPT is faster with respect to accepting H1, that is, detecting informative variables. Therefore, SRPT may be preferred for
datasets with only few informative variables, whereas SAPT is preferable for datasets with many informative variables.
The Monte Carlo p-value based testing procedure (<code>type="pval"</code>) should be used, when p-values are required.
The choice <code>type="complete"</code> offers a conventional permutation test (that is, without sequential testing) (Hapfelmeier and Ulm, 2013). This choice
is computationally the most intensive. Lastly, the choice <code>type="certain"</code> is similar to <code>type="complete"</code>, but performs
early stopping by ending the permutation iterations as soon as it is certain which outcome the conventional permutation test would
take. That is, <code>type="certain"</code> can be considered as a computationally more effective version of <code>type="complete"</code>.
</p>


<h3>Value</h3>

<p>Object of class <code>rfvimptest</code> with elements
</p>
<table>
<tr><td><code>testtype</code></td>
<td>
<p>Type of the permutation test performed and sequential method used.</p>
</td></tr>
<tr><td><code>varimp</code></td>
<td>
<p>Variable importance for each considered independent variable.</p>
</td></tr>
<tr><td><code>testres</code></td>
<td>
<p>The results (&quot;keep H0&quot; vs. &quot;accept H1&quot;) of the tests for each considered independent variable.</p>
</td></tr>
<tr><td><code>pvalues</code></td>
<td>
<p>The p-values of the tests for each considered independent variable. Note that p-values are only obtained for the
method types &quot;pval&quot; and &quot;complete&quot;.</p>
</td></tr>
<tr><td><code>stoppedearly</code></td>
<td>
<p>For each independent variable, whether the calculations stopped early (&quot;yes&quot;) or the maximum of <code>Mmax</code> permutations was reached (&quot;no&quot;).</p>
</td></tr>
<tr><td><code>perms</code></td>
<td>
<p>The number of permutations performed for each independent variable.</p>
</td></tr>
<tr><td><code>Mmax</code></td>
<td>
<p>Maximum number of permutations used in each permutation test.</p>
</td></tr>
<tr><td><code>ntree</code></td>
<td>
<p>Number of trees per forest.</p>
</td></tr>
<tr><td><code>comptime</code></td>
<td>
<p>The time the computations needed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander Hapfelmeier, Roman Hornung
</p>


<h3>References</h3>


<ul>
<li><p> Breiman, L. (2001). Random forests. Mach Learn, 45:5-32, &lt;doi: <a href="https://doi.org/10.1023/A:1010933404324">10.1023/A:1010933404324</a>&gt;.
</p>
</li>
<li><p> Coleman, T., Peng, W., Mentch, L. (2019). Scalable and efficient hypothesis testing with random forests. arXiv preprint arXiv:1904.07830, &lt;doi: <a href="https://doi.org/10.48550/arXiv.1904.07830">10.48550/arXiv.1904.07830</a>&gt;.
</p>
</li>
<li><p> Hapfelmeier, A., Hornung, R., Haller, B. (2022). Sequential Permutation Testing of Random Forest Variable Importance Measures. arXiv preprint arXiv:2206.01284, &lt;doi: <a href="https://doi.org/10.48550/arXiv.2206.01284">10.48550/arXiv.2206.01284</a>&gt;.
</p>
</li>
<li><p> Hapfelmeier, A., Ulm, K. (2013). A new variable selection approach using Random Forests. CSDA 60:50–69, &lt;doi: <a href="https://doi.org/10.1016/j.csda.2012.09.020">10.1016/j.csda.2012.09.020</a>&gt;.
</p>
</li>
<li><p> Hapfelmeier, A., Hothorn, T., Ulm, K., Strobl, C. (2014). A new variable importance measure for random forests with missing data. Stat Comput 24:21–34, &lt;doi: <a href="https://doi.org/10.1007/s11222-012-9349-1">10.1007/s11222-012-9349-1</a>&gt;.
</p>
</li>
<li><p> Hothorn, T., Hornik, K., Zeileis, A. (2006). Unbiased Recursive Partitioning: A Conditional Inference Framework. J Comput Graph Stat 15(3):651–674, &lt;doi: <a href="https://doi.org/10.1198/106186006X133933">10.1198/106186006X133933</a>&gt;.
</p>
</li>
<li><p> Wright, M. N., Ziegler, A. (2017). ranger: A fast implementation of random forests for high dimensional data in C++ and R. J Stat Softw 77:1-17, &lt;doi: <a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a>&gt;.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

## Load package:
library("rfvimptest")

## Set seed to obtain reproducible results:
set.seed(1234)

# Load example data:
data(hearth2)

# NOTE: For illustration purposes a very small number (Mmax=20) of maximum
# permutations is considered. This number would be much too small for actual
# applications. The default number is Max=500.

# By default, SPRT is performed:
(ptest_sprt &lt;- rfvimptest(data=hearth2, yname="Class", Mmax=20))
ptest_sprt$varimp
ptest_sprt$testres

# Calculation of p-values using the Monte Carlo p-value based testing procedure:
(ptest_pval &lt;- rfvimptest(data=hearth2, yname="Class", type="pval", Mmax=20))
ptest_pval$pvalues

# If the frequency of informative variables is expected to be high SAPT can be used:
(ptest_sapt &lt;- rfvimptest(data=hearth2, yname="Class", type="SAPT", Mmax=20))
ptest_sapt$testres


# If it is only of interest to test specific variables in the dataset these variables
# should be passed to rfvimptest() vias the argument 'varnames' because this
# reduces the computational burden considerably:

(ptest_twovar &lt;- rfvimptest(data=hearth2, yname="Class", varnames=c("age", "sex"), Mmax=20))
ptest_twovar$varimp
ptest_twovar$testres


# Two-sample permutation test procedures:

# NOTE: These should be used only for informal screening for informative variables.
# They are not valid statistical tests.

# Here, the maximum number of permutations can be much higher because it is necessary
# here to construct a new forest for each permutation:
rfvimptest(data=hearth2, yname="Class", test="twosample", condinf=TRUE, Mmax=1000)

rfvimptest(data=hearth2, yname="Class", test="twosample", type="pval", condinf=TRUE, Mmax=1000)

rfvimptest(data=hearth2, yname="Class", test="twosample", type="SAPT", condinf=TRUE, Mmax=1000)



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
