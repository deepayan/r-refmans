<!DOCTYPE html><html lang="en"><head><title>Help for package SIMPLE.REGRESSION</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SIMPLE.REGRESSION}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SIMPLE.REGRESSION-package'><p>SIMPLE.REGRESSION</p></a></li>
<li><a href='#COUNT_REGRESSION'><p>Count data regression</p></a></li>
<li><a href='#data_Bauer_Curran_2005'><p>data_Bauer_Curran_2005</p></a></li>
<li><a href='#data_Bodner_2016'><p>data_Bodner_2016</p></a></li>
<li><a href='#data_Chapman_Little_2016'><p>data_Chapman_Little_2016</p></a></li>
<li><a href='#data_Cohen_Aiken_West_2003_7'><p>data_Cohen_Aiken_West_2003_7</p></a></li>
<li><a href='#data_Cohen_Aiken_West_2003_9'><p>data_Cohen_Aiken_West_2003_9</p></a></li>
<li><a href='#data_Green_Salkind_2014'><p>data_Green_Salkind_2014</p></a></li>
<li><a href='#data_Halvorson_2022_log'><p>data_Halvorson_2022_log</p></a></li>
<li><a href='#data_Halvorson_2022_pois'><p>data_Halvorson_2022_pois</p></a></li>
<li><a href='#data_Huitema_2011'><p>data_Huitema_2011</p></a></li>
<li><a href='#data_Kremelburg_2011'><p>data_Kremelburg_2011</p></a></li>
<li><a href='#data_Lorah_Wong_2018'><p>data_Lorah_Wong_2018</p></a></li>
<li><a href='#data_Meyers_2013'><p>data_Meyers_2013</p></a></li>
<li><a href='#data_OConnor_Dvorak_2001'><p>data_OConnor_Dvorak_2001</p></a></li>
<li><a href='#data_Orme_2009_2'><p>data_Orme_2009_2</p></a></li>
<li><a href='#data_Orme_2009_5'><p>data_Orme_2009_5</p></a></li>
<li><a href='#data_Pedhazur_1997'><p>data_Pedhazur_1997</p></a></li>
<li><a href='#data_Pituch_Stevens_2016'><p>data_Pituch_Stevens_2016</p></a></li>
<li><a href='#LOGISTIC_REGRESSION'><p>Logistic regression</p></a></li>
<li><a href='#MODERATED_REGRESSION'><p>Moderated multiple regression</p></a></li>
<li><a href='#OLS_REGRESSION'><p>Ordinary least squares regression</p></a></li>
<li><a href='#PARTIAL_COEFS'><p>Standardized coefficients and partial correlations for multiple regression</p></a></li>
<li><a href='#PLOT_MODEL'><p>Plots predicted values for a regression model</p></a></li>
<li><a href='#REGIONS_OF_SIGNIFICANCE'><p>Plots of Johnson-Neyman regions of significance for interactions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>OLS, Moderated, Logistic, and Count Regressions Made Simple</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-11</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian P. O'Connor [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian P. O'Connor  &lt;brian.oconnor@ubc.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides SPSS- and SAS-like output for least squares multiple regression,
    logistic regression, and count variable regressions. Detailed output is also provided for
    OLS moderated regression, interaction plots, and Johnson-Neyman
    regions of significance. The output includes standardized
    coefficients, partial and semi-partial correlations, collinearity diagnostics,
    plots of residuals, and detailed information about simple slopes for interactions. 
    The output for some functions includes Bayes Factors and, if requested,  
    regression coefficients from Bayesian Markov Chain Monte Carlo analyses.
    There are numerous options for model plots.
    The REGIONS_OF_SIGNIFICANCE function also provides
    Johnson-Neyman regions of significance and plots of interactions for both lm
    and lme models.</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, utils, nlme, MASS, BayesFactor, rstanarm,
pscl</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-12 00:12:27 UTC; brianoconnor</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-12 00:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='SIMPLE.REGRESSION-package'>SIMPLE.REGRESSION</h2><span id='topic+SIMPLE.REGRESSION-package'></span>

<h3>Description</h3>

<p>Provides SPSS- and SAS-like output for least squares multiple regression,
logistic regression, and count variable regressions. Detailed output is also provided for
OLS moderated regression, interaction plots, and Johnson-Neyman
regions of significance. The output includes standardized
coefficients, partial and semi-partial correlations, collinearity diagnostics,
plots of residuals, and detailed information about simple slopes for interactions. 
The output for some functions includes Bayes Factors and, if requested,  
regression coefficients from Bayesian Markov Chain Monte Carlo (MCMC) analyses.
There are numerous options for model plots.
<br /><br /> The REGIONS_OF_SIGNIFICANCE function also provides
Johnson-Neyman regions of significance and plots of interactions for both lm
and lme models (lme models are from the nlme package).
</p>


<h3>References</h3>

<p>Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and multilevel 
regression: Inferential and graphical techniques. <em>Multivariate Behavioral 
Research, 40(3),</em> 373-400.
<br /><br /> Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied 
multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). 
Lawrence Erlbaum Associates.
<br /><br /> Darlington, R. B., &amp; Hayes, A. F. (2017). <em>Regression analysis and linear models: 
Concepts, applications, and implementation.</em> Guilford Press.
<br /><br /> Dunn, P. K., &amp; Smyth, G. K. (2018). <em>Generalized linear models 
with examples in R.</em> Springer.
<br /><br /> Hayes, A. F. (2018a). <em>Introduction to mediation, moderation, and conditional 
process analysis: A regression-based approach</em> (2nd ed.). Guilford Press.
<br /><br /> Huitema, B. (2011). <em>The analysis of covariance and alternatives: Statistical  
methods for experiments, quasi-experiments, and single-case studies.</em> John Wiley &amp; Sons.
<br /><br /> Johnson, P. O., &amp; Fey, L. C. (1950). The Johnson-Neyman technique, its theory, and 
application. <em>Psychometrika, 15,</em> 349-367.
<br /><br /> Lorah, J. A. &amp; Wong, Y. J. (2018). Contemporary applications of moderation 
analysis in counseling psychology. <em>Counseling Psychology, 65(5),</em> 629-640.
<br /><br /> Orme, J. G., &amp; Combs-Orme, T. (2009). <em>Multiple regression with discrete 
dependent variables.</em> Oxford University Press.
<br /><br /> Pedhazur, E. J. (1997). <em>Multiple regression in behavioral research: Explanation 
and prediction.</em> (3rd ed.). Wadsworth Thomson Learning.
</p>

<hr>
<h2 id='COUNT_REGRESSION'>Count data regression</h2><span id='topic+COUNT_REGRESSION'></span>

<h3>Description</h3>

<p>Provides SPSS- and SAS-like output for count data
regression, including Poisson, quasi-Poisson, negative binomial,
zero-inflated poisson, and zero-inflated negative binomial models.  
The output includes model summaries, classification tables, omnibus tests of 
the model coefficients, overdispersion tests, model effect sizes, the 
model coefficients, correlation matrix for the model coefficients, collinearity 
statistics, and casewise regression diagnostics.</p>


<h3>Usage</h3>

<pre><code class='language-R'>COUNT_REGRESSION(data, DV, forced = NULL, hierarchical = NULL,
                 family = 'poisson',
                 offset = NULL,
                 plot_type = 'residuals',
                 CI_level = 95,
                 MCMC = FALSE,
                 Nsamples = 4000,
                 verbose = TRUE )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="COUNT_REGRESSION_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases and the columns are the variables.</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_dv">DV</code></td>
<td>

<p>The name of the dependent variable. 
<br /> Example: DV = 'outcomeVar'.</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_forced">forced</code></td>
<td>

<p>(optional) A vector of the names of the predictor variables for a forced/simultaneous  
entry regression. The variables can be numeric or factors. 
<br /> Example: forced = c('VarA', 'VarB', 'VarC')</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_hierarchical">hierarchical</code></td>
<td>

<p>(optional) A list with the names of the predictor variables for each step of a 
hierarchical regression. The variables can be numeric or factors.
<br /> Example: hierarchical = list(step1=c('VarA', 'VarB'), step2=c('VarC', 'VarD'))</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_family">family</code></td>
<td>

<p>(optional) The name of the error distribution to be 
used in the model. The options are:
</p>

<ul>
<li><p>&quot;poisson&quot; (the default),
</p>
</li>
<li><p>&quot;quasipoisson&quot;,
</p>
</li>
<li><p>&quot;negbin&quot;, for negative binomial,
</p>
</li>
<li><p>&quot;zinfl_poisson&quot;, for zero-inflated poisson, or
</p>
</li>
<li><p>&quot;zinfl_negbin&quot;, for zero-inflated negative binomial.
</p>
</li></ul>

<p>Example: family = 'quasipoisson'</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_offset">offset</code></td>
<td>

<p>(optional) The name of the offset variable, if there is one. This variable
should be in the desired metric (e.g., log). No transformation of an
offset variable is performed internally.
<br /> Example: offset = 'Varname'</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_plot_type">plot_type</code></td>
<td>

<p>(optional) The kind of plots, if any. The options are:
</p>

<ul>
<li><p>'residuals' (the default),
</p>
</li>
<li><p>'diagnostics', for regression diagnostics, and
</p>
</li>
<li><p>'none', for no plots.
</p>
</li></ul>

<p>Example: plot_type = 'diagnostics'</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_ci_level">CI_level</code></td>
<td>

<p>(optional) The confidence interval for the output, in whole numbers.
The default is 95.</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_mcmc">MCMC</code></td>
<td>

<p>(logical) Should Bayesian MCMC analyses be conducted? The default is FALSE.</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_nsamples">Nsamples</code></td>
<td>

<p>(optional) The number of samples for MCMC analyses. The default is 10000.</p>
</td></tr>
<tr><td><code id="COUNT_REGRESSION_+3A_verbose">verbose</code></td>
<td>

<p>(optional) Should detailed results be displayed in console? <br /> The options are: 
TRUE (default) or FALSE. If TRUE, plots of residuals are also produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the glm function from the stats package, and the 
negative.binomial function from the MASS package, and
supplements the output with additional statistics and in formats that resembles
SPSS and SAS output. The predictor variables can be numeric or factors.
</p>
<p>The analyses for the zero-inflated poisson and zero-inflated negative binomial
analyses are conducted using the pscl package (Zeileis, Kleiber, &amp; Jackman, 2008).
</p>
<p>Predicted values, for selected levels of the predictor variables,
can be produced and plotted using the PLOT_MODEL funtion in this package.
</p>
<p>The Bayesian MCMC analyses can be time-consuming for larger datasets. The MCMC 
analyses are conducted using functions, and their default settings, from the 
rstanarm package (Goodrich, Gabry, Ali, &amp; Brilleman, 2024). 
Family = 'quasibinomial' analyses are currently not possible for the MCMC 
analyses. family = 'binomial' is therefore used instead.
The Bayesian MCMC analyses are also currently not available for zero-inflated 
poisson and zero-inflated negative binomial models.
</p>
<p>The MCMC results can be verified using the model checking functions in the
rstanarm package (e.g., Muth, Oravecz, &amp; Gabry, 2018).
</p>
<p>Good sources for interpreting count data regression residuals and diagnostics plots:
</p>

<ul>
<li><p><a href="https://rpubs.com/benhorvath/glm_diagnostics">rpubs.com/benhorvath</a>
</p>
</li>
<li><p><a href="https://library.virginia.edu/data/articles/understanding-deviance-residuals">library.virginia.edu</a>
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class &quot;COUNT_REGRESSION&quot;. The object is a list containing the
following possible components:
</p>
<table role = "presentation">
<tr><td><code>modelMAIN</code></td>
<td>
<p>All of the glm function output for the regression model.</p>
</td></tr>
<tr><td><code>modelMAINsum</code></td>
<td>
<p>All of the summary.glm function output for the regression model.</p>
</td></tr>
<tr><td><code>modeldata</code></td>
<td>
<p>All of the predictor and outcome raw data that were used in the model,
along with regression diagnostic statistics for each case.</p>
</td></tr>
<tr><td><code>collin_diags</code></td>
<td>
<p>Collinearity diagnostic coefficients for models without interaction terms.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Atkins, D. C., &amp; Gallop, R. J. (2007). Rethinking how family researchers 
model infrequent outcomes: A tutorial on count regression and zero-inflated 
models. <em>Journal of Family Psychology, 21(4),</em> 726-735.
<br /><br /> Beaujean, A. A., &amp; Grant, M. B. (2019). Tutorial on using regression 
models with count outcomes using R. <em>Practical Assessment, 
Research, and Evaluation: Vol. 21, Article 2.</em>
<br /><br /> Coxe, S., West, S.G., &amp; Aiken, L.S. (2009). The analysis of count data: 
A gentle introduction to Poisson regression and its alternatives. 
<em>Journal of Personality Assessment, 91,</em> 121-136.
<br /><br /> Dunn, P. K., &amp; Smyth, G. K. (2018). <em>Generalized linear models 
with examples in R.</em> Springer.
<br /><br /> Hardin, J. W., &amp; Hilbe, J. M. (2007). <em>Generalized linear models 
and extensions.</em> Stata Press.
<br /><br /> Muth, C., Oravecz, Z., &amp; Gabry, J. (2018). User-friendly Bayesian regression 
modeling: A tutorial with rstanarm and shinystan. <em>The Quantitative Methods 
for Psychology, 14(2),</em> 99119. 
<br /> https://doi.org/10.20982/tqmp.14.2.p099
<br /><br /> Orme, J. G., &amp; Combs-Orme, T. (2009). <em>Multiple regression with discrete 
dependent variables.</em> Oxford University Press.
<br /><br /> Rindskopf, D. (2023). Generalized linear models. In H. Cooper, M. N. 
Coutanche, L. M. McMullen, A. T. Panter, D. Rindskopf, &amp; K. J. Sher (Eds.), 
<em>APA handbook of research methods in psychology: Data analysis and 
research publication, </em> (2nd ed., pp. 201-218). American Psychological Association.
<br /><br /> Zeileis, A., Kleiber, C., &amp; Jackman, S. (2008). Regression Models for Count Data in R. 
<em>Journal of Statistical Software, 27(8).</em> https://www.jstatsoft.org/v27/i08/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>COUNT_REGRESSION(data=data_Kremelburg_2011, DV='OVRJOYED', 
                 forced=c('AGE','EDUC','REALRINC','SEX_factor'))

COUNT_REGRESSION(data=data_Kremelburg_2011, DV='OVRJOYED', 
                 forced=c('AGE','EDUC','REALRINC','SEX_factor'),  family = 'negbin')


# negative binomial regression
COUNT_REGRESSION(data=data_Kremelburg_2011, DV='HURTATWK', 
                 forced=c('AGE','EDUC','REALRINC','SEX_factor'),
                 family = 'negbin',
                 plot_type = 'diagnostics')

# with an offset variable
COUNT_REGRESSION(data=data_Orme_2009_5, DV='NumberAdopted', forced=c('Married'), 
                 offset='lnYearsFostered')

# zero-inflated poisson regression
COUNT_REGRESSION(data=data_Kremelburg_2011, DV='HURTATWK', 
                 forced=c('AGE','EDUC','REALRINC','SEX_factor'),
                 family = 'zinfl_poisson',
                 plot_type = 'diagnostics')

# zero-inflated negative binomial regression
COUNT_REGRESSION(data=data_Kremelburg_2011, DV='HURTATWK', 
                 forced=c('AGE','EDUC','REALRINC','SEX_factor'),
                 family = 'zinfl_negbin',
                 plot_type = 'diagnostics')

</code></pre>

<hr>
<h2 id='data_Bauer_Curran_2005'>data_Bauer_Curran_2005</h2><span id='topic+data_Bauer_Curran_2005'></span>

<h3>Description</h3>

<p>Multilevel moderated regression data from Bauer and Curran (2005). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Bauer_Curran_2005)</code></pre>


<h3>Source</h3>

<p>Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and multilevel 
regression: Inferential and graphical techniques. <em>Multivariate Behavioral 
Research, 40(3),</em> 373-400.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Bauer_Curran_2005)

HSBmod &lt;-nlme::lme(MathAch ~ Sector + CSES + CSES:Sector,
                   data = data_Bauer_Curran_2005, 
                   random = ~1 + CSES|School, method = "ML") 
summary(HSBmod)

REGIONS_OF_SIGNIFICANCE(model=HSBmod,  
                        plot_title='Johnson-Neyman Regions of Significance', 
                        Xaxis_label='Child SES',
                        Yaxis_label='Slopes of School Sector on Math achievement')  

</code></pre>

<hr>
<h2 id='data_Bodner_2016'>data_Bodner_2016</h2><span id='topic+data_Bodner_2016'></span>

<h3>Description</h3>

<p>Moderated regression data used by Bodner (2016) to illustrate the
tumble graphs method of plotting interactions. The data were also used by
Bauer and Curran (2005). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Bodner_2016)</code></pre>


<h3>Source</h3>

<p>Bodner, T. E. (2016). Tumble Graphs: Avoiding misleading end point 
extrapolation when graphing interactions from a moderated multiple 
regression analysis. 
<em>Journal of Educational and Behavioral Statistics, 41(6),</em> 593-604.
<br /><br /> Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and 
multilevel regression: Inferential and graphical techniques. 
<em>Multivariate Behavioral Research, 40(3),</em> 373-400.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Bodner_2016)

# replicates p 599 of Bodner (2016)
MODERATED_REGRESSION(data=data_Bodner_2016, DV='math90',
                     IV='Anti90', IV_range='tumble',
                     MOD='Hyper90', MOD_levels='quantiles', 
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     COVARS=c('age90month','female','grade90','minority'),
                     center = FALSE, 
                     plot_type = 'interaction')	

</code></pre>

<hr>
<h2 id='data_Chapman_Little_2016'>data_Chapman_Little_2016</h2><span id='topic+data_Chapman_Little_2016'></span>

<h3>Description</h3>

<p>Moderated regression data from Chapman and Little (2016).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Chapman_Little_2016)</code></pre>


<h3>Source</h3>

<p>Chapman, D. A., &amp; Little, B. (2016). Climate change and disasters: How framing affects 
justifications for giving or withholding aid to disaster victims. 
<em>Social Psychological and Personality Science, 7,</em> 13-20.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Chapman_Little_2016)
 
# the data used by Hayes (2018, Introduction to Mediation, Moderation, and 
# Conditional Process Analysis: A Regression-Based Approach), replicating p. 239
MODERATED_REGRESSION(data=data_Chapman_Little_2016, DV='justify',
                     IV='frame', IV_range='tumble',
                     MOD='skeptic', MOD_levels='AikenWest', 
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = FALSE, 
                     plot_type = 'regions') 

</code></pre>

<hr>
<h2 id='data_Cohen_Aiken_West_2003_7'>data_Cohen_Aiken_West_2003_7</h2><span id='topic+data_Cohen_Aiken_West_2003_7'></span>

<h3>Description</h3>

<p>Moderated regression data for a continuous predictor and a
continuous moderator from Cohen, Cohen, West, &amp; Aiken (2003, Chapter 7). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Cohen_Aiken_West_2003_7)</code></pre>


<h3>Source</h3>

<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied 
multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). 
Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Cohen_Aiken_West_2003_7)

# replicates p 276 of Chapter 7 of Cohen, Cohen, West, &amp; Aiken (2003)
MODERATED_REGRESSION(data=data_Cohen_Aiken_West_2003_7, DV='yendu',
                     IV='xage', IV_range='tumble',
                     MOD='zexer', MOD_levels='AikenWest', 
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = TRUE, 
                     plot_type = 'regions') 

</code></pre>

<hr>
<h2 id='data_Cohen_Aiken_West_2003_9'>data_Cohen_Aiken_West_2003_9</h2><span id='topic+data_Cohen_Aiken_West_2003_9'></span>

<h3>Description</h3>

<p>Moderated regression data for a continuous predictor and a
categorical moderator from Cohen, Cohen, West, &amp; Aiken (2003, Chapter 9). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Cohen_Aiken_West_2003_9)</code></pre>


<h3>Source</h3>

<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied 
multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). 
Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Cohen_Aiken_West_2003_9)

# replicates p 376 of Chapter 9 of Cohen, Cohen, West, &amp; Aiken (2003)
MODERATED_REGRESSION(data=data_Cohen_Aiken_West_2003_9, DV='SALARY',
                     IV='PUB', IV_range='tumble',
                     MOD='DEPART_f', MOD_type = 'factor', MOD_levels='AikenWest', 
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = TRUE,  
                     plot_type = 'regions') 

</code></pre>

<hr>
<h2 id='data_Green_Salkind_2014'>data_Green_Salkind_2014</h2><span id='topic+data_Green_Salkind_2014'></span>

<h3>Description</h3>

<p>Mutiple regression data from Green and Salkind (2018). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Green_Salkind_2014)</code></pre>


<h3>Source</h3>

<p>Green, S. B., &amp; Salkind, N. J. (2014). Lesson 34: Multiple linear regression
(pp. 257-269). In, <em>Using SPSS for Windows and Macintosh: Analyzing and 
understanding data.</em> New York, NY: Pearson.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Green_Salkind_2014)

# forced (simultaneous) entry; replicating the output on p. 263	
OLS_REGRESSION(data=data_Green_Salkind_2014, DV='injury', 
               forced=c('quads','gluts','abdoms','arms','grip')) 

# hierarchical entry; replicating the output on p. 265-266	
OLS_REGRESSION(data=data_Green_Salkind_2014, DV='injury', 
               hierarchical = list( step1=c('quads','gluts','abdoms'), 
                                    step2=c('arms','grip')) )

</code></pre>

<hr>
<h2 id='data_Halvorson_2022_log'>data_Halvorson_2022_log</h2><span id='topic+data_Halvorson_2022_log'></span>

<h3>Description</h3>

<p>Logistic regression data from Halvorson et al. (2022, p. 291). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Halvorson_2022_log)</code></pre>


<h3>Source</h3>

<p>Halvorson, M. A., McCabe, C. J., Kim, D. S., Cao, X., &amp; King, K. M. (2022). 
Making sense of some odd ratios: A tutorial and improvements to present practices 
in reporting and visualizing quantities of interest for binary and count outcome 
models. <em>Psychology of Addictive Behaviors, 36(3),</em> 284-295.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Halvorson_2022_log)

log_Halvorson &lt;-
  LOGISTIC_REGRESSION(data=data_Halvorson_2022_log, DV='Y', forced=c('x1','x2'), 
                      plot_type = 'diagnostics')

# high &amp; low values for x2
x2_high &lt;- mean(data_Halvorson_2022_log$x1) + sd(data_Halvorson_2022_log$x1)
x2_low  &lt;- mean(data_Halvorson_2022_log$x1) - sd(data_Halvorson_2022_log$x1)

PLOT_MODEL(model = log_Halvorson, 
           IV_focal_1 = 'x1',   
           IV_focal_2 = 'x2',  IV_focal_2_values = c(x2_low, x2_high),
           bootstrap=FALSE, N_sims=1000, CI_level=95, 
           ylim = c(0, 1), 
           xlab = 'x1',
           ylab = 'Expected Probability', 
           title = 'Probability of Y by x1 and x2 for Simulated Data Example') 
 

</code></pre>

<hr>
<h2 id='data_Halvorson_2022_pois'>data_Halvorson_2022_pois</h2><span id='topic+data_Halvorson_2022_pois'></span>

<h3>Description</h3>

<p>Poisson regression data from Halvorson et al. (2022, p. 293). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Halvorson_2022_pois)</code></pre>


<h3>Source</h3>

<p>Halvorson, M. A., McCabe, C. J., Kim, D. S., Cao, X., &amp; King, K. M. (2022). 
Making sense of some odd ratios: A tutorial and improvements to present practices 
in reporting and visualizing quantities of interest for binary and count outcome 
models. <em>Psychology of Addictive Behaviors, 36(3),</em> 284-295.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Halvorson_2022_pois)

# replicating Table 3, p 293
pois_Halvorson &lt;-
  COUNT_REGRESSION(data=data_Halvorson_2022_pois, DV='Neg_OH_conseqs', 
          forced=c('Gender_factor','Positive_Urgency_new','Planning','Sensation_seeking'), 
        plot_type = 'diagnostics')

# replicating Figure 4, p 294
PLOT_MODEL(model = pois_Halvorson, 
           IV_focal_1 = 'Positive_Urgency_new',   
           IV_focal_2 = 'Gender_factor',
           bootstrap=FALSE, N_sims=1000, CI_level=95, 
           ylim = c(0, 20), 
           xlab = 'Positive Urgency',
           ylab = 'Expected Count of Alcohol Consequences', 
         title = 'Expected Count of Alcohol Consequences by Positive Urgency and Gender') 

</code></pre>

<hr>
<h2 id='data_Huitema_2011'>data_Huitema_2011</h2><span id='topic+data_Huitema_2011'></span>

<h3>Description</h3>

<p>Moderated regression data for a continuous predictor and a
dichotomous moderator from Huitema (2011, p. 253). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Huitema_2011)</code></pre>


<h3>Source</h3>

<p>Huitema, B. (2011). <em>The analysis of covariance and alternatives: Statistical methods 
for experiments, quasi-experiments, and single-case studies.</em> Hoboken, NJ: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Huitema_2011)

# replicating results on p. 255 for the Johnson-Neyman technique for a categorical moderator
MODERATED_REGRESSION(data=data_Huitema_2011, DV='Y', 
                     IV='X', IV_range='tumble',
                     MOD='D', MOD_type = 'factor',  
                     center = FALSE,  
                     plot_type = 'interaction',
                     JN_type = 'Huitema') 

</code></pre>

<hr>
<h2 id='data_Kremelburg_2011'>data_Kremelburg_2011</h2><span id='topic+data_Kremelburg_2011'></span>

<h3>Description</h3>

<p>Logistic and Poisson regression data from Kremelburg (2011). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Kremelburg_2011)</code></pre>


<h3>Source</h3>

<p>Kremelburg, D. (2011). Chapter 6: Logistic, ordered, multinomial, negative
binomial, and Poisson regression. <em>Practical statistics: A quick and easy guide 
to IBM SPSS Statistics, STATA, and other statistical software.</em> Sage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Kremelburg_2011)

LOGISTIC_REGRESSION(data = data_Kremelburg_2011, DV='OCCTRAIN',
                    hierarchical=list( step1=c('AGE'), step2=c('EDUC','REALRINC')) )
         
COUNT_REGRESSION(data=data_Kremelburg_2011, DV='OVRJOYED', 
                 forced=c('AGE','EDUC','REALRINC','SEX_factor'))

</code></pre>

<hr>
<h2 id='data_Lorah_Wong_2018'>data_Lorah_Wong_2018</h2><span id='topic+data_Lorah_Wong_2018'></span>

<h3>Description</h3>

<p>Moderated regression data from Lorah and Wong (2018). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Lorah_Wong_2018)</code></pre>


<h3>Source</h3>

<p>Lorah, J. A. &amp; Wong, Y. J. (2018). Contemporary applications of moderation 
analysis in counseling psychology. <em>Journal of Counseling Psychology, 65(5),</em> 629-640.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Lorah_Wong_2018)

model_Lorah &lt;- 
MODERATED_REGRESSION(data=data_Lorah_Wong_2018, DV='suicidal',
                     IV='burden', IV_range='tumble',
                     MOD='belong_thwarted', MOD_levels='quantiles',
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     COVARS='depression', center = TRUE, 
                     plot_type = 'regions') 
       
REGIONS_OF_SIGNIFICANCE(model=model_Lorah,  
                        plot_title='Johnson-Neyman Regions of Significance', 
                        Xaxis_label='Thwarted Belongingness', 
                        Yaxis_label='Slopes of Burdensomeness on Suicical Ideation', 
                        legend_label=NULL)        

</code></pre>

<hr>
<h2 id='data_Meyers_2013'>data_Meyers_2013</h2><span id='topic+data_Meyers_2013'></span>

<h3>Description</h3>

<p>Logistic regression data from Myers et al. (2013). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Meyers_2013)</code></pre>


<h3>Source</h3>

<p>Meyers, L. S., Gamst, G. C., &amp; Guarino, A. J. (2013). Chapter 30: Binary 
logistic regression. <em>Performing data analysis using IBM SPSS.</em>
Hoboken, NJ: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Meyers_2013)

LOGISTIC_REGRESSION(data= data_Meyers_2013, DV='graduated', forced= c('sex','family_encouragement'))

</code></pre>

<hr>
<h2 id='data_OConnor_Dvorak_2001'>data_OConnor_Dvorak_2001</h2><span id='topic+data_OConnor_Dvorak_2001'></span>

<h3>Description</h3>

<p>Moderated regression data from O'Connor and Dvorak (2001)</p>


<h3>Details</h3>

<p>A data frame with scores for 131 male adolescents on resiliency,
maternal harshness, and aggressive behavior. The data are from
O'Connor and Dvorak (2001, p. 17) and are provided as trial moderated 
regression data for the MODERATED_REGRESSION and REGIONS_OF_SIGNIFICANCE functions.
</p>


<h3>References</h3>

<p>O'Connor, B. P., &amp; Dvorak, T. (2001). Conditional associations between parental behavior 
and adolescent problems: A search for personality-environment interactions. 
<em>Journal of Research in Personality, 35,</em> 1-26.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_OConnor_Dvorak_2001)

mharsh_agg &lt;- 
  MODERATED_REGRESSION(data=data_OConnor_Dvorak_2001, DV='Aggressive_Behavior',
                       IV='Maternal_Harshness', IV_range=c(1,7.7), 
                       MOD='Resiliency',MOD_levels='AikenWest', 
                       quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                       center = FALSE,  
                       plot_type = 'interaction', 
                       DV_range = c(1,6), 
                       Xaxis_label='Maternal Harshness', 
                       Yaxis_label='Adolescent Aggressive Behavior', 
                       legend_label='Resiliency') 

REGIONS_OF_SIGNIFICANCE(model=mharsh_agg,  
           plot_title='Slopes of Maternal Harshness on Aggression by Resiliency', 
           Xaxis_label='Resiliency', 
           Yaxis_label='Slopes of Maternal Harshness on Aggressive Behavior ') 

</code></pre>

<hr>
<h2 id='data_Orme_2009_2'>data_Orme_2009_2</h2><span id='topic+data_Orme_2009_2'></span>

<h3>Description</h3>

<p>Logistic regression data from Orme and Combs-Orme (2009), Chapter 2. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Orme_2009_2)</code></pre>


<h3>Source</h3>

<p>Orme, J. G., &amp; Combs-Orme, T. (2009). <em>Multiple Regression With Discrete 
Dependent Variables.</em> Oxford University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LOGISTIC_REGRESSION(data = data_Orme_2009_2, DV='ContinueFostering', 
                    forced= c('zResources', 'Married'))
</code></pre>

<hr>
<h2 id='data_Orme_2009_5'>data_Orme_2009_5</h2><span id='topic+data_Orme_2009_5'></span>

<h3>Description</h3>

<p>Data for count regression from Orme and Combs-Orme (2009), Chapter 5. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Orme_2009_5)</code></pre>


<h3>Source</h3>

<p>Orme, J. G., &amp; Combs-Orme, T. (2009). <em>Multiple Regression With Discrete 
Dependent Variables.</em> Oxford University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>COUNT_REGRESSION(data=data_Orme_2009_5, DV='NumberAdopted', forced=c('Married','zParentRole'))
</code></pre>

<hr>
<h2 id='data_Pedhazur_1997'>data_Pedhazur_1997</h2><span id='topic+data_Pedhazur_1997'></span>

<h3>Description</h3>

<p>Moderated regression data for a continuous predictor and a
dichotomous moderator from Pedhazur (1997, p. 588). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Pedhazur_1997)</code></pre>


<h3>Source</h3>

<p>Pedhazur, E. J. (1997). <em>Multiple regression in behavioral research: Explanation 
and prediction.</em> (3rd ed.). Fort Worth, Texas: Wadsworth Thomson Learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Pedhazur_1997)

# replicating results on p. 594 for the Johnson-Neyman technique for a categorical moderator	
MODERATED_REGRESSION(data=data_Pedhazur_1997, DV='Y', 
                     IV='X', IV_range='tumble',
                     MOD='Directive', MOD_type = 'factor', MOD_levels='quantiles', 
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = FALSE, 
                     plot_type = 'interaction', 
                     JN_type = 'Pedhazur') 

</code></pre>

<hr>
<h2 id='data_Pituch_Stevens_2016'>data_Pituch_Stevens_2016</h2><span id='topic+data_Pituch_Stevens_2016'></span>

<h3>Description</h3>

<p>Logistic regression data from Pituch and Stevens (2016), Chapter 11. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_Pituch_Stevens_2016)</code></pre>


<h3>Source</h3>

<p>Pituch, K. A., &amp; Stevens, J. P. (2016). 
<em>Applied multivariate statistics for the social sciences : Analyses with 
SAS and IBMs SPSS,</em> (6th ed.). Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LOGISTIC_REGRESSION(data = data_Pituch_Stevens_2016, DV='Health', 
                    forced= c('Treatment','Motivation'))
</code></pre>

<hr>
<h2 id='LOGISTIC_REGRESSION'>Logistic regression</h2><span id='topic+LOGISTIC_REGRESSION'></span>

<h3>Description</h3>

<p>Logistic regression analyses with SPSS- and SAS-like output. The output includes 
model summaries, classification tables, omnibus tests of model coefficients, 
the model coefficients, likelihood ratio tests for the predictors, overdispersion 
tests, model effect sizes, the correlation matrix for the model coefficients,
collinearity statistics, and casewise regression diagnostics.</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOGISTIC_REGRESSION(data, DV, forced = NULL, hierarchical = NULL,
                    ref_category = NULL,
                    family = 'binomial',
                    plot_type = 'residuals',
                    CI_level = 95,
                    MCMC = FALSE,
                    Nsamples = 4000,
                    verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LOGISTIC_REGRESSION_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases and the columns are the variables.</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_dv">DV</code></td>
<td>

<p>The name of the dependent variable. 
<br /> Example: DV = 'outcomeVar'.</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_forced">forced</code></td>
<td>

<p>(optional) A vector of the names of the predictor variables for a forced/simultaneous  
entry regression. The variables can be numeric or factors. 
<br /> Example: forced = c('VarA', 'VarB', 'VarC')</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_hierarchical">hierarchical</code></td>
<td>

<p>(optional) A list with the names of the predictor variables for each step of a 
hierarchical regression. The variables can be numeric or factors.
<br /> Example: hierarchical = list(step1=c('VarA', 'VarB'), step2=c('VarC', 'VarD'))</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_ref_category">ref_category</code></td>
<td>

<p>(optional) The reference category for DV. 
<br /> Example: ref_category = 'alive'</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_family">family</code></td>
<td>

<p>(optional) The name of the error distribution to be used in the model. The options are:
</p>

<ul>
<li><p>&quot;binomial&quot; (the default), or
</p>
</li>
<li><p>&quot;quasibinomial&quot;, which should be used when there is overdispersion.
</p>
</li></ul>

<p>Example: family = 'quasibinomial'</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_plot_type">plot_type</code></td>
<td>

<p>(optional) The kind of plots, if any. The options are:
</p>

<ul>
<li><p>'residuals' (the default),
</p>
</li>
<li><p>'diagnostics', for regression diagnostics, and
</p>
</li>
<li><p>'none', for no plots.
</p>
</li></ul>

<p>Example: plot_type = 'diagnostics'</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_ci_level">CI_level</code></td>
<td>

<p>(optional) The confidence interval for the output, in whole numbers.
The default is 95.</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_mcmc">MCMC</code></td>
<td>

<p>(logical) Should Bayesian MCMC analyses be conducted? The default is FALSE.</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_nsamples">Nsamples</code></td>
<td>

<p>(optional) The number of samples for MCMC analyses. The default is 10000.</p>
</td></tr>
<tr><td><code id="LOGISTIC_REGRESSION_+3A_verbose">verbose</code></td>
<td>

<p>(optional) Should detailed results be displayed in console? <br /> The options are: 
TRUE (default) or FALSE. If TRUE, plots of residuals are also produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the glm function from the stats package and
supplements the output with additional statistics and in formats that resembles
SPSS and SAS output. The predictor variables can be numeric or factors.
</p>
<p>Predicted values for this model, for selected levels of the predictor variables,
can be produced and plotted using the PLOT_MODEL funtion in this package.
</p>
<p>The Bayesian MCMC analyses can be time-consuming for larger datasets. The MCMC 
analyses are conducted using functions, and their default settings, from the 
rstanarm package (Goodrich, Gabry, Ali, &amp; Brilleman, 2024). 
The MCMC results can be verified using the model checking functions in the
rstanarm package (e.g., Muth, Oravecz, &amp; Gabry, 201).
</p>
<p>Good sources for interpreting logistic regression residuals and diagnostics plots:
</p>

<ul>
<li><p><a href="https://rpubs.com/benhorvath/glm_diagnostics">rpubs.com/benhorvath</a>
</p>
</li>
<li><p><a href="https://library.virginia.edu/data/articles/understanding-deviance-residuals">library.virginia.edu</a>
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class &quot;LOGISTIC_REGRESSION&quot;. The object is a list containing the
following possible components:
</p>
<table role = "presentation">
<tr><td><code>modelMAIN</code></td>
<td>
<p>All of the glm function output for the regression model.</p>
</td></tr>
<tr><td><code>modelMAINsum</code></td>
<td>
<p>All of the summary.glm function output for the regression model.</p>
</td></tr>
<tr><td><code>modeldata</code></td>
<td>
<p>All of the predictor and outcome raw data that were used in the model,
along with regression diagnostic statistics for each case.</p>
</td></tr>
<tr><td><code>collin_diags</code></td>
<td>
<p>Collinearity diagnostic coefficients for models without interaction terms.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Dunn, P. K., &amp; Smyth, G. K. (2018). <em>Generalized linear models 
with examples in R.</em> Springer.
<br /><br /> Field, A., Miles, J., &amp; Field, Z. (2012). 
<em>Discovering statistics using R.</em> Los Angeles, CA: Sage.
<br /><br /> Goodrich, B., Gabry, J., Ali, I., &amp; Brilleman, S. (2024). <em>rstanarm:  
Bayesian applied regression modeling via Stan.</em> R package version 2.32.1, 
https://mc-stan.org/rstanarm/.
<br /><br /> Hair, J. F., Black, W. C., Babin, B. J., &amp; Anderson, R. E. (2014). 
<em>Multivariate data analysis,</em> (8th ed.).
Lawrence Erlbaum Associates.
<br /><br /> Hosmer, D. W., Lemeshow, S., &amp; Sturdivant, R. X. (2013) 
<em>Applied logistic regression.</em> (3rd ed.). John Wiley &amp; Sons.
<br /><br /> Muth, C., Oravecz, Z., &amp; Gabry, J. (2018). User-friendly Bayesian regression 
modeling: A tutorial with rstanarm and shinystan. <em>The Quantitative Methods 
for Psychology, 14(2),</em> 99119. 
<br /> https://doi.org/10.20982/tqmp.14.2.p099
<br /><br /> Orme, J. G., &amp; Combs-Orme, T. (2009). <em>Multiple regression with discrete 
dependent variables.</em> Oxford University Press.
<br /><br /> Pituch, K. A., &amp; Stevens, J. P. (2016). 
<em>Applied multivariate statistics for the social sciences: Analyses with 
SAS and IBM's SPSS,</em> (6th ed.). Routledge.
<br /><br /> Rindskopf, D. (2023). Generalized linear models. In H. Cooper, M. N. 
Coutanche, L. M. McMullen, A. T. Panter, D. Rindskopf, &amp; K. J. Sher (Eds.), 
<em>APA handbook of research methods in psychology: Data analysis and 
research publication, </em> (2nd ed., pp. 201-218). American Psychological Association.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># forced (simultaneous) entry
LOGISTIC_REGRESSION(data = data_Meyers_2013, DV='graduated', 
                    forced=c('sex','family_encouragement'),
                    plot_type = 'diagnostics')
	
# hierarchical entry, and using family = "quasibinomial"
LOGISTIC_REGRESSION(data = data_Kremelburg_2011, DV='OCCTRAIN',
                    hierarchical=list( step1=c('AGE'), step2=c('EDUC','REALRINC')),
                    family = "quasibinomial") 

</code></pre>

<hr>
<h2 id='MODERATED_REGRESSION'>Moderated multiple regression</h2><span id='topic+MODERATED_REGRESSION'></span><span id='topic+MODERATED.REGRESSION'></span>

<h3>Description</h3>

<p>Conducts moderated regression analyses for two-way interactions with
extensive options for interaction plots, including Johnson-Neyman
regions of significance. The output includes the
Anova Table (Type III tests), standardized coefficients, 
partial and semi-partial correlations, collinearity statistics,
casewise regression diagnostics, plots of residuals and regression diagnostics, 
and detailed information about simple slopes.
The output includes Bayes Factors and, if requested, regression coefficients from
Bayesian Markov Chain Monte Carlo (MCMC) analyses.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MODERATED_REGRESSION(data, DV, IV, MOD,
                     IV_type = 'numeric', IV_range = 'tumble',
                     MOD_type='numeric', MOD_levels='quantiles', MOD_range=NULL,
                     quantiles_IV = c(.1, .9), quantiles_MOD = c(.25, .5, .75),
                     COVARS = NULL,
                     center = TRUE, 
                     CI_level = 95,
                     MCMC = FALSE,
                     Nsamples = 10000,
                     plot_type = 'residuals', plot_title = NULL, DV_range = NULL,
                     Xaxis_label = NULL, Yaxis_label = NULL, legend_label = NULL,
                     JN_type = 'Huitema', 
                     verbose = TRUE )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MODERATED_REGRESSION_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases and the columns are the variables.</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_dv">DV</code></td>
<td>

<p>The name of the dependent variable. 
<br /> Example: DV = 'outcomeVar'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_iv">IV</code></td>
<td>

<p>The name of the independent variable.
<br /> Example: IV = 'varA'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_mod">MOD</code></td>
<td>

<p>The name of the moderator variable
<br /> Example: MOD = 'varB'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_iv_type">IV_type</code></td>
<td>

<p>(optional) The type of independent variable. The
options are 'numeric' (the default) or 'factor'. 
<br /> Example: IV_type = 'factor'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_iv_range">IV_range</code></td>
<td>

<p>(optional) The independent variable range for a moderated regression plot.
The options are:
</p>

<ul>
<li><p>'tumble' (the default), for tumble graphs following Bodner (2016)
</p>
</li>
<li><p>'quantiles', in which case the 10th and 90th quantiles of the IV will be used
(alternative values can be specified using the quantiles_IV argument);
</p>
</li>
<li><p>'AikenWest', in which case the IV mean - one SD, and the IV mean + one SD, will be used;
</p>
</li>
<li><p>a vector of two user-provided values (e.g., c(1, 10)); and
</p>
</li>
<li><p>NULL, in which case the minimum and maximum IV values will be used.
</p>
</li></ul>

<p>Example: IV_range = 'AikenWest'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_mod_type">MOD_type</code></td>
<td>

<p>(optional) The type of moderator variable. The
options are 'numeric' (the default) or 'factor'. 
<br /> Example: MOD_type = 'factor'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_mod_levels">MOD_levels</code></td>
<td>

<p>(optional) The levels of the moderator variable to be used if MOD is continuous.
The options are:
</p>

<ul>
<li><p>'quantiles', in which case the .25, .5, and .75 quantiles of the MOD variable will be used
(alternative values can be specified using the quantiles_MOD argument);
</p>
</li>
<li><p>'AikenWest', in which case the mean of MOD, the mean of MOD - one SD, and the 
mean of MOD + one SD, will be used; and
</p>
</li>
<li><p>a vector of two user-provided values.
</p>
</li></ul>

<p>Example: MOD_levels = c(1, 10)</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_mod_range">MOD_range</code></td>
<td>

<p>(optional) The range of the MOD values to be used in the Johnson-Neyman regions 
of significance analyses. The options are:
NULL (the default), in which case the minimum and maximum MOD values will be used; and
a vector of two user-provided values. 
<br /> Example: MOD_range = c(1, 10)</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_quantiles_iv">quantiles_IV</code></td>
<td>

<p>(optional) The quantiles of the independent variable to be used as the IV range for 
a moderated regression plot.
<br /> Example: quantiles_IV = c(.10, .90)</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_quantiles_mod">quantiles_MOD</code></td>
<td>

<p>(optional) The quantiles the moderator variable to be used as the MOD simple slope  
values in the moderated regression analyses.
<br /> Example: quantiles_MOD = c(.25, .5, .75)</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_covars">COVARS</code></td>
<td>

<p>(optional) The name(s) of possible covariates.
<br /> Example: COVARS = c('CovarA', 'CovarB', 'CovarC')</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_center">center</code></td>
<td>

<p>(optional) Logical, indicating whether the IV and MOD variables should be centered
(default = TRUE).
<br /> Example: center = FALSE</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_ci_level">CI_level</code></td>
<td>

<p>(optional) The confidence interval for the output, in whole numbers.
The default is 95.</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_mcmc">MCMC</code></td>
<td>

<p>(logical) Should Bayesian MCMC analyses be conducted? The default is FALSE.</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_nsamples">Nsamples</code></td>
<td>

<p>(optional) The number of samples for MCMC analyses. The default is 10000.</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_plot_type">plot_type</code></td>
<td>

<p>(optional)  The kind of plot, if any. The options are:
</p>

<ul>
<li><p>'residuals' (the default)
</p>
</li>
<li><p>'diagnostics' (for regression diagnostics)
</p>
</li>
<li><p>'interaction' (for a traditional moderated regression interaction plot)
</p>
</li>
<li><p>'regions' (for a moderated regression Johnson-Neyman regions of significance plot), and
</p>
</li>
<li><p>'none' (for no plots).
</p>
</li></ul>

<p>Example: plot_type = 'diagnostics'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_plot_title">plot_title</code></td>
<td>

<p>(optional) The plot title.
<br /> Example: plot_title = 'Interaction Plot'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_dv_range">DV_range</code></td>
<td>

<p>(optional) The range of Y-axis values for the plot. 
<br /> Example: DV_range = c(1,10)</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_xaxis_label">Xaxis_label</code></td>
<td>

<p>(optional) A label for the X axis to be used in the requested plot.
<br /> Example: Xaxis_label = 'IV name'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_yaxis_label">Yaxis_label</code></td>
<td>

<p>(optional) A label for the Y axis to be used in the requested plot.
<br /> Example: Yaxis_label = 'DV name'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_legend_label">legend_label</code></td>
<td>

<p>(optional) A legend label for the plot.
<br /> Example: legend_label = 'MOD name'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_jn_type">JN_type</code></td>
<td>

<p>(optional) The formula to be used in computing the critical F value for the
Johnson-Neyman regions of significance analyses. The options are 'Huitema' (the default),
or 'Pedhazur'.
<br /> Example: JN_type = 'Pedhazur'</p>
</td></tr>
<tr><td><code id="MODERATED_REGRESSION_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in console? The options are: 
TRUE (default) or FALSE. If TRUE, plots of residuals are also produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian MCMC analyses can be time-consuming for larger datasets. The MCMC 
analyses are conducted using functions, and their default settings, from the 
BayesFactor package (Morey &amp; Rouder, 2024).
The MCMC results can be verified using the model checking functions in the
rstanarm package (e.g., Muth, Oravecz, &amp; Gabry, 201).
</p>


<h3>Value</h3>

<p>An object of class &quot;MODERATED_REGRESSION&quot;. The object is a list containing the
following possible components:
</p>
<table role = "presentation">
<tr><td><code>modelMAINsum</code></td>
<td>
<p>All of the summary.lm function output for the regression model 
without interaction terms.</p>
</td></tr>
<tr><td><code>anova_table</code></td>
<td>
<p>Anova Table (Type III tests).</p>
</td></tr>
<tr><td><code>mainRcoefs</code></td>
<td>
<p>Predictor coefficients for the model without interaction terms.</p>
</td></tr>
<tr><td><code>modeldata</code></td>
<td>
<p>All of the predictor and outcome raw data that were used in the model,
along with regression diagnostic statistics for each case.</p>
</td></tr>
<tr><td><code>collin_diags</code></td>
<td>
<p>Collinearity diagnostic coefficients for models without interaction terms.</p>
</td></tr>
<tr><td><code>modelXNsum</code></td>
<td>
<p>Regression model statistics with interaction terms.</p>
</td></tr>
<tr><td><code>RsqchXn</code></td>
<td>
<p>Rsquared change for the interaction.</p>
</td></tr>
<tr><td><code>fsquaredXN</code></td>
<td>
<p>fsquared change for the interaction.</p>
</td></tr>
<tr><td><code>xnRcoefs</code></td>
<td>
<p>Predictor coefficients for the model with interaction terms.</p>
</td></tr>
<tr><td><code>simslop</code></td>
<td>
<p>The simple slopes.</p>
</td></tr>
<tr><td><code>simslopZ</code></td>
<td>
<p>The standardized simple slopes.</p>
</td></tr>
<tr><td><code>plotdon</code></td>
<td>
<p>The plot data for a moderated regression.</p>
</td></tr>
<tr><td><code>JN.data</code></td>
<td>
<p>The Johnson-Neyman results for a moderated regression.</p>
</td></tr>
<tr><td><code>ros</code></td>
<td>
<p>The Johnson-Neyman regions of significance for a moderated regression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Bodner, T. E. (2016). Tumble graphs: Avoiding misleading end point extrapolation when  
graphing interactions from a moderated multiple regression analysis. 
<em>Journal of Educational and Behavioral Statistics, 41,</em> 593-604.
<br /><br /> Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied 
multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). 
Lawrence Erlbaum Associates.
<br /><br /> Darlington, R. B., &amp; Hayes, A. F. (2017). <em>Regression analysis and linear models: 
Concepts, applications, and implementation.</em> Guilford Press.
<br /><br /> Hayes, A. F. (2018a). <em>Introduction to mediation, moderation, and conditional process 
analysis: A regression-based approach</em> (2nd ed.). Guilford Press.
<br /><br /> Hayes, A. F., &amp; Montoya, A. K. (2016). A tutorial on testing, visualizing, and probing 
an interaction involving a multicategorical variable in linear regression analysis. 
<em>Communication Methods and Measures, 11,</em> 1-30.
<br /><br /> Lee M. D., &amp; Wagenmakers, E. J. (2014) <em>Bayesian cognitive modeling: A practical 
course.</em> Cambridge University Press.
<br /><br /> Morey, R. &amp; Rouder, J. (2024). <em>BayesFactor: Computation of Bayes Factors for 
Common Designs.</em> R package version 0.9.12-4.7, 
https://github.com/richarddmorey/bayesfactor.
<br /><br /> Muth, C., Oravecz, Z., &amp; Gabry, J. (2018). User-friendly Bayesian regression 
modeling: A tutorial with rstanarm and shinystan. <em>The Quantitative Methods 
for Psychology, 14(2),</em> 99119. 
<br /> https://doi.org/10.20982/tqmp.14.2.p099
<br /><br /> O'Connor, B. P. (1998). All-in-one programs for exploring interactions in moderated 
multiple regression. <em>Educational and Psychological Measurement, 58,</em> 833-837.
<br /><br /> Pedhazur, E. J. (1997). <em>Multiple regression in behavioral research: Explanation 
and prediction.</em> (3rd ed.). Wadsworth Thomson Learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># moderated regression	-- with IV_range = 'AikenWest'
MODERATED_REGRESSION(data=data_Lorah_Wong_2018, DV='suicidal', IV='burden',  MOD='belong_thwarted', 
                     IV_range='AikenWest',
                     MOD_levels='quantiles',
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = TRUE, COVARS='depression', 
                     plot_type = 'interaction', plot_title=NULL, DV_range = c(1,1.25))

# moderated regression	-- with  IV_range = 'tumble'
MODERATED_REGRESSION(data=data_Lorah_Wong_2018, DV='suicidal', IV='burden', MOD='belong_thwarted', 
                     IV_range='tumble',
                     MOD_levels='quantiles',
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = TRUE, COVARS='depression', 
                     plot_type = 'interaction', plot_title=NULL, DV_range = c(1,1.25)) 

# moderated regression	-- with numeric values for IV_range &amp; MOD_levels='AikenWest'       
MODERATED_REGRESSION(data=data_OConnor_Dvorak_2001, DV='Aggressive_Behavior', 
                     IV='Maternal_Harshness', MOD='Resiliency', 
                     IV_range=c(1,7.7), 
                     MOD_levels='AikenWest', MOD_range=NULL,
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     center = FALSE, 
                     plot_type = 'interaction', 
                     DV_range = c(1,6), 
                     Xaxis_label='Maternal Harshness', 
                     Yaxis_label='Adolescent Aggressive Behavior', 
                     legend_label='Resiliency')

</code></pre>

<hr>
<h2 id='OLS_REGRESSION'>Ordinary least squares regression</h2><span id='topic+OLS_REGRESSION'></span><span id='topic+SIMPLE.REGRESSION'></span>

<h3>Description</h3>

<p>Provides SPSS- and SAS-like output for ordinary least squares simultaneous 
entry regression and hierarchical entry regression. The output includes the
Anova Table (Type III tests), standardized coefficients, 
partial and semi-partial correlations, collinearity statistics,
casewise regression diagnostics, plots of residuals and regression diagnostics.
The output includes Bayes Factors and, if requested, regression coefficients from
Bayesian Markov Chain Monte Carlo (MCMC) analyses.</p>


<h3>Usage</h3>

<pre><code class='language-R'>OLS_REGRESSION(data, DV, forced=NULL, hierarchical=NULL, 
               COVARS=NULL,
               plot_type = 'residuals', 
               CI_level = 95,
               MCMC = FALSE,
               Nsamples = 10000,
               verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OLS_REGRESSION_+3A_data">data</code></td>
<td>

<p>A dataframe where the rows are cases and the columns are the variables.</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_dv">DV</code></td>
<td>

<p>The name of the dependent variable. 
<br /> Example: DV = 'outcomeVar'</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_forced">forced</code></td>
<td>

<p>(optional) A vector of the names of the predictor variables for a forced/simultaneous  
entry regression. The variables can be numeric or factors.
<br /> Example: forced = c('VarA', 'VarB', 'VarC')</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_hierarchical">hierarchical</code></td>
<td>

<p>(optional) A list with the names of the predictor variables for each step of 
a hierarchical regression. The variables can be numeric or factors.
<br /> Example: hierarchical = list(step1=c('VarA', 'VarB'), step2=c('VarC', 'VarD'))</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_covars">COVARS</code></td>
<td>

<p>(optional) The name(s) of possible covariates variable for a moderated regression
analysis.
<br /> Example: COVARS = c('CovarA', 'CovarB', 'CovarC')</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_plot_type">plot_type</code></td>
<td>

<p>(optional)  The kind of plots, if any. The options are:
</p>

<ul>
<li><p>'residuals' (the default)
</p>
</li>
<li><p>'diagnostics' (for regression diagnostics), or
</p>
</li>
<li><p>'none' (for no plots).
</p>
</li></ul>

<p>Example: plot_type = 'diagnostics'</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_ci_level">CI_level</code></td>
<td>

<p>(optional) The confidence interval for the output, in whole numbers.
The default is 95.</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_mcmc">MCMC</code></td>
<td>

<p>(logical) Should Bayesian MCMC analyses be conducted? The default is FALSE.</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_nsamples">Nsamples</code></td>
<td>

<p>(optional) The number of samples for MCMC analyses. The default is 10000.</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in console? The options are: 
TRUE (default) or FALSE. If TRUE, plots of residuals are also produced.</p>
</td></tr>
<tr><td><code id="OLS_REGRESSION_+3A_...">...</code></td>
<td>
<p>(dots, for internal purposes only at this time.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the lm function from the stats package,
supplements the output with additional statistics, and it formats the output
so that it resembles SPSS and SAS regression output. The predictor
variables can be numeric or factors.
</p>
<p>The Bayesian MCMC analyses can be time-consuming for larger datasets. The MCMC 
analyses are conducted using functions, and their default settings, from the 
BayesFactor	package (Morey &amp; Rouder, 2024). 
The MCMC results can be verified using the model checking functions in the
rstanarm package (e.g., Muth, Oravecz, &amp; Gabry, 2018).
</p>
<p>Good sources for interpreting residuals and diagnostics plots:
</p>

<ul>
<li><p><a href="https://library.virginia.edu/data/articles/diagnostic-plots">library.virginia.edu</a>
</p>
</li>
<li><p><a href="https://www.andrew.cmu.edu/user/achoulde/94842/homework/regression_diagnostics.html">andrew.cmu.edu</a>
</p>
</li>
<li><p><a href="https://www.sthda.com/english/articles/index.php?url=/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/">sthda.com</a>
</p>
</li>
<li><p><a href="https://boostedml.com/2019/03/linear-regression-plots-fitted-vs-residuals.html">boostedml.com</a>
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class &quot;OLS_REGRESSION&quot;. The object is a list containing the
following possible components:
</p>
<table role = "presentation">
<tr><td><code>modelMAIN</code></td>
<td>
<p>All of the lm function output for the regression model 
without interaction terms.</p>
</td></tr>
<tr><td><code>modelMAINsum</code></td>
<td>
<p>All of the summary.lm function output for the regression model 
without interaction terms.</p>
</td></tr>
<tr><td><code>anova_table</code></td>
<td>
<p>Anova Table (Type III tests).</p>
</td></tr>
<tr><td><code>mainRcoefs</code></td>
<td>
<p>Predictor coefficients for the model without interaction terms.</p>
</td></tr>
<tr><td><code>modeldata</code></td>
<td>
<p>All of the predictor and outcome raw data that were used in the model,
along with regression diagnostic statistics for each case.</p>
</td></tr>
<tr><td><code>collin_diags</code></td>
<td>
<p>Collinearity diagnostic coefficients for models without interaction terms.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Bodner, T. E. (2016). Tumble graphs: Avoiding misleading end point extrapolation when  
graphing interactions from a moderated multiple regression analysis. 
<em>Journal of Educational and Behavioral Statistics, 41,</em> 593-604.
<br /><br /> Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied 
multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). 
Lawrence Erlbaum Associates.
<br /><br /> Darlington, R. B., &amp; Hayes, A. F. (2017). <em>Regression analysis and linear models: 
Concepts, applications, and implementation.</em> Guilford Press.
<br /><br /> Hayes, A. F. (2018a). <em>Introduction to mediation, moderation, and conditional process 
analysis: A regression-based approach</em> (2nd ed.). Guilford Press.
<br /><br /> Hayes, A. F., &amp; Montoya, A. K. (2016). A tutorial on testing, visualizing, and probing 
an interaction involving a multicategorical variable in linear regression analysis. 
<em>Communication Methods and Measures, 11,</em> 1-30.
<br /><br /> Lee M. D., &amp; Wagenmakers, E. J. (2014) <em>Bayesian cognitive modeling: A practical 
course.</em> Cambridge University Press.
<br /><br /> Morey, R. &amp; Rouder, J. (2024). <em>BayesFactor: Computation of Bayes Factors for 
Common Designs.</em> R package version 0.9.12-4.7, 
https://github.com/richarddmorey/bayesfactor.
<br /><br /> Muth, C., Oravecz, Z., &amp; Gabry, J. (2018). User-friendly Bayesian regression 
modeling: A tutorial with rstanarm and shinystan. <em>The Quantitative Methods 
for Psychology, 14(2),</em> 99119. 
<br /> https://doi.org/10.20982/tqmp.14.2.p099
<br /><br /> O'Connor, B. P. (1998). All-in-one programs for exploring interactions in moderated 
multiple regression. <em>Educational and Psychological Measurement, 58,</em> 833-837.
<br /><br /> Pedhazur, E. J. (1997). <em>Multiple regression in behavioral research: Explanation 
and prediction.</em> (3rd ed.). Wadsworth Thomson Learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># forced (simultaneous) entry
head(data_Green_Salkind_2014)
OLS_REGRESSION(data=data_Green_Salkind_2014, DV='injury', 
               forced = c('quads','gluts','abdoms','arms','grip'))

# hierarchical entry
OLS_REGRESSION(data=data_Green_Salkind_2014, DV='injury', 
               hierarchical = list( step1=c('quads','gluts','abdoms'), 
                                    step2=c('arms','grip')) )

</code></pre>

<hr>
<h2 id='PARTIAL_COEFS'>Standardized coefficients and partial correlations for multiple regression</h2><span id='topic+PARTIAL_COEFS'></span>

<h3>Description</h3>

<p>Produces standardized regression coefficients, partial correlations,   
and semi-partial correlations for a correlation matrix in which one variable 
is a dependent or outcome variable and the other variables are independent
or predictor variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PARTIAL_COEFS(cormat, modelRsq=NULL, verbose=TRUE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PARTIAL_COEFS_+3A_cormat">cormat</code></td>
<td>

<p>A correlation matrix. The DV (the dependent or outcome variable) must be in 
the first row/column of cormat.
<br /> Example: cormat = correls</p>
</td></tr>
<tr><td><code id="PARTIAL_COEFS_+3A_modelrsq">modelRsq</code></td>
<td>

<p>(optional) The model Rsquared, which makes the computations slightly faster
when it is available.
<br /> Example: modelRsq = .22</p>
</td></tr>
<tr><td><code id="PARTIAL_COEFS_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in console? <br /> The options are: TRUE (default) or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing the standardized regression coefficients (betas), 
the Pearson correlations, the partial correlations, and the semi-partial correlations for each
variable with the DV.
</p>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied 
multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). 
Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PARTIAL_COEFS(cormat = cor(data_Green_Salkind_2014))
</code></pre>

<hr>
<h2 id='PLOT_MODEL'>Plots predicted values for a regression model</h2><span id='topic+PLOT_MODEL'></span>

<h3>Description</h3>

<p>Plots predicted values of the outcome variable for specified levels 
of predictor variables for OLS_REGRESSION, MODERATED_REGRESSION, 
LOGISTIC_REGRESSION, and COUNT_REGRESSION models from this package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLOT_MODEL(model, 
           IV_focal_1, IV_focal_1_values=NULL, 
           IV_focal_2=NULL, IV_focal_2_values=NULL, 
           IVs_nonfocal_values = NULL,
           bootstrap=FALSE, N_sims=100, CI_level=95, 
           xlim=NULL, xlab=NULL,
           ylim=NULL, ylab=NULL,
           title = NULL,
           verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PLOT_MODEL_+3A_model">model</code></td>
<td>

<p>The returned output from the OLS_REGRESSION, MODERATED_REGRESSION, 
LOGISTIC_REGRESSION, or COUNT_REGRESSION functions in this package.</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_iv_focal_1">IV_focal_1</code></td>
<td>

<p>The name of the focal, varying predictor variable. 
<br /> Example: IV_focal_1 = 'age'</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_iv_focal_1_values">IV_focal_1_values</code></td>
<td>

<p>(optional) Values for IV_focal_1, for which predictions of the
outcome will be produced and plotted.
IV_focal_1_values will appear on the x-axis in the plot.
If IV_focal_1 is numeric and IV_focal_1_values is not provided,
then a sequence based on the range of the model data values for IV_focal_1 will be used.
If IV_focal_1 is a factor &amp; IV_focal_1_values is not provided, then the
factor levels from the model data values for IV_focal_1 will be used.
<br /> Example: IV_focal_1_values = seq(20, 80, 1)
<br /> Example: IV_focal_1_values = c(20, 40, 60)</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_iv_focal_2">IV_focal_2</code></td>
<td>

<p>(optional) If desired, the name of a second focal predictor variable for the plot. 
<br /> Example: IV_focal_2 = 'height'</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_iv_focal_2_values">IV_focal_2_values</code></td>
<td>

<p>(optional) Values for IV_focal_2 for which predictions of the
outcome will be produced and plotted.
If IV_focal_2 is numeric and IV_focal_2_values is not provided, then
the following three values for IV_focal_2_values, derived from the model data,
will be used for plotting: the mean, one SD below the mean, and one SD above the mean.
If IV_focal_2 is a factor &amp; IV_focal_2_values is not provided, then the
factor levels from the model data values for IV_focal_2 will be used.
<br /> Example: IV_focal_2_values = c(20, 40, 60)</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_ivs_nonfocal_values">IVs_nonfocal_values</code></td>
<td>

<p>(optional) A list with the desired constant values for the non focal predictors, 
if any. If IVs_nonfocal_values is not provided, then the mean values of numeric non focal
predictors and the baseline values of factors will be used as the defaults.
It is also possible to specify values for only some of the IVs_nonfocal variables
on this argument.
<br /> Example: IVs_nonfocal_values = list(AGE = 25, EDUC = 12)
</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_bootstrap">bootstrap</code></td>
<td>

<p>(optional) Should bootstrapping be used for the confidence intervals?
The options are TRUE or FALSE (the default).</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_n_sims">N_sims</code></td>
<td>

<p>(optional) The number of bootstrap simulations. 
<br /> Example: N_sims = 1000</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_ci_level">CI_level</code></td>
<td>

<p>(optional) The desired confidence interval, in whole numbers.
<br /> Example: CI_level = 95</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_xlim">xlim</code></td>
<td>

<p>(optional) The x-axis limits for the plot. 
<br /> Example: xlim = c(1, 9)</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_xlab">xlab</code></td>
<td>

<p>(optional) A x-axis label for the plot. 
<br /> Example: xlab = 'IVname'</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_ylim">ylim</code></td>
<td>

<p>(optional) The y-axis limits for the plot. 
<br /> Example: ylim = c(0, 80)</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_ylab">ylab</code></td>
<td>

<p>(optional) A y-axis label for the plot. 
<br /> Example: ylab = 'DVname'</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_title">title</code></td>
<td>

<p>(optional) A title for the plot. 
<br /> Example: title = 'OLS prediction of DV'</p>
</td></tr>
<tr><td><code id="PLOT_MODEL_+3A_verbose">verbose</code></td>
<td>

<p>Should detailed results be displayed in console? <br /> The options are: 
TRUE (default) or FALSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots predicted values of the outcome variable for specified levels 
of predictor variables for OLS_REGRESSION, MODERATED_REGRESSION, 
LOGISTIC_REGRESSION, and COUNT_REGRESSION models from this package.
</p>
<p>A plot with both IV_focal_1 and IV_focal_2 predictor variables will look like an
interaction plot. But it is only a true interaction plot if the required product
term(s) was entered as a predictor when the model was created.
</p>


<h3>Value</h3>

<p>A matrix with the levels of the variables that were used for the plot along 
with the predicted values, confidence intervals, and se.fit values.
</p>


<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>Examples</h3>

<pre><code class='language-R'>ols_GS &lt;- 
OLS_REGRESSION(data=data_Green_Salkind_2014, DV='injury', 
               hierarchical = list( step1=c('age','quads','gluts','abdoms'), 
                                    step2=c('arms','grip')) )

PLOT_MODEL(model = ols_GS, 
           IV_focal_1 = 'gluts', IV_focal_1_values=NULL,
           IV_focal_2='age', IV_focal_2_values=NULL, 
           IVs_nonfocal_values = NULL,
           bootstrap=TRUE, N_sims=100, CI_level=95, 
           ylim=NULL, ylab=NULL, title=NULL,
           verbose=TRUE) 
	
ols_LW &lt;- 
MODERATED_REGRESSION(data=data_Lorah_Wong_2018, DV='suicidal', IV='burden', MOD='belong_thwarted', 
                     IV_range='tumble',
                     MOD_levels='quantiles',
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     COVARS='depression', 
                     plot_type = 'interaction', DV_range = c(1,1.25)) 
                     
PLOT_MODEL(model = ols_LW, 
           IV_focal_1 = 'burden', IV_focal_1_values=NULL,
           IV_focal_2='belong_thwarted', IV_focal_2_values=NULL, 
           bootstrap=TRUE, N_sims=100, CI_level=95) 
                     
logmod_Meyers &lt;- 
  LOGISTIC_REGRESSION(data= data_Meyers_2013, DV='graduated', 
                      forced= c('sex','family_encouragement') ) 

PLOT_MODEL(model = logmod_Meyers, 
           IV_focal_1 = 'family_encouragement', IV_focal_1_values=NULL,
           IV_focal_2=NULL, IV_focal_2_values=NULL, 
           bootstrap=FALSE, N_sims=100, CI_level=95) 
           
pois_Krem &lt;-
  COUNT_REGRESSION(data=data_Kremelburg_2011, DV='OVRJOYED', forced=NULL, 
                   hierarchical= list( step1=c('AGE','SEX_factor'), 
                                       step2=c('EDUC','REALRINC','DEGREE')) )

PLOT_MODEL(model = pois_Krem, 
           IV_focal_1 = 'AGE', 
           IV_focal_2='DEGREE',
           IVs_nonfocal_values = list( EDUC = 5, SEX_factor = '2'),
           bootstrap=FALSE, N_sims=100, CI_level=95) 
           

</code></pre>

<hr>
<h2 id='REGIONS_OF_SIGNIFICANCE'>Plots of Johnson-Neyman regions of significance for interactions</h2><span id='topic+REGIONS_OF_SIGNIFICANCE'></span>

<h3>Description</h3>

<p>Plots of Johnson-Neyman regions of significance for interactions 
in moderated multiple regression, for both MODERATED_REGRESSION models (which are
produced by this package) and for lme models (from the nlme package).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>REGIONS_OF_SIGNIFICANCE(model,
                        IV_range=NULL, MOD_range=NULL,
                        plot_title=NULL, Xaxis_label=NULL,
                        Yaxis_label=NULL, legend_label=NULL,
                        names_IV_MOD=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_model">model</code></td>
<td>

<p>The name of a MODERATED_REGRESSION model, or of an lme model from the nlme package.</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_iv_range">IV_range</code></td>
<td>

<p>(optional) The range of the IV to be used in the plot.
<br /> Example: IV_range = c(1, 10)</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_mod_range">MOD_range</code></td>
<td>

<p>(optional)  The range of the MOD values to be used in the plot.
<br /> Example: MOD_range = c(2, 4, 6)</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_plot_title">plot_title</code></td>
<td>

<p>(optional)  The plot title.
<br /> Example: plot_title = 'Regions of Significance Plot'</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_xaxis_label">Xaxis_label</code></td>
<td>

<p>(optional)  A label for the X axis to be used in the plot.
<br /> Example: Xaxis_label = 'IV name'</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_yaxis_label">Yaxis_label</code></td>
<td>

<p>(optional)  A label for the Y axis to be used in the plot.
<br /> Example: Yaxis_label = 'DV name'</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_legend_label">legend_label</code></td>
<td>

<p>(optional)  The legend label.
<br /> Example: legend_label = 'Simple Slopes'</p>
</td></tr>
<tr><td><code id="REGIONS_OF_SIGNIFICANCE_+3A_names_iv_mod">names_IV_MOD</code></td>
<td>

<p>(optional) and for lme/nlme models only. Use this argument to ensure
that the IV and MOD variables are correctly identified for the plot.
There are three scenarios in particular that may require specification of this
argument:
</p>

<ul>
<li><p>when there are covariates in addition to IV &amp; MOD as predictors,
</p>
</li>
<li><p>if the order of the variables in model is not IV then MOD, or,
</p>
</li>
<li><p>if the IV is a two-level factor (because lme alters the variable names in this case).
</p>
</li></ul>

<p>Example: names_IV_MOD = c('IV name', 'MOD name')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following possible components:
</p>
<table role = "presentation">
<tr><td><code>JN.data</code></td>
<td>
<p>The Johnson-Neyman results for a moderated regression.</p>
</td></tr>
<tr><td><code>ros</code></td>
<td>
<p>The Johnson-Neyman regions of significance for a moderated regression.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Brian P. O'Connor </p>


<h3>References</h3>

<p>Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and multilevel 
regression: Inferential and graphical techniques. <em>Multivariate Behavioral 
Research, 40(3),</em> 373-400.
<br /><br /> Huitema, B. (2011). <em>The analysis of covariance and alternatives: Statistical  
methods for experiments, quasi-experiments, and single-case studies.</em> John Wiley &amp; Sons.
<br /><br /> Johnson, P. O., &amp; Neyman, J. (1936). Tests of certain linear hypotheses and their 
application to some educational problems. <em>Statistical Research Memoirs, 1,</em> 57-93.
<br /><br /> Johnson, P. O., &amp; Fey, L. C. (1950). The Johnson-Neyman technique, its theory, and 
application. <em>Psychometrika, 15,</em> 349-367.
<br /><br /> Pedhazur, E. J. (1997). <em>Multiple regression in behavioral research: Explanation 
and prediction.</em> (3rd ed.). Wadsworth Thomson Learning
<br /><br /> Rast, P., Rush, J., Piccinin, A. M., &amp; Hofer, S. M. (2014). The identification of regions of 
significance in the effect of multimorbidity on depressive symptoms using longitudinal data: An 
application of the Johnson-Neyman technique. <em>Gerontology, 60,</em> 274-281.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(data_Cohen_Aiken_West_2003_7)

CAW_7 &lt;- 
MODERATED_REGRESSION(data=data_Cohen_Aiken_West_2003_7, DV='yendu',
                     IV='xage',IV_range='tumble',
                     MOD='zexer', MOD_levels='quantiles', 
                     quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                     plot_type = 'interaction') 

REGIONS_OF_SIGNIFICANCE(model=CAW_7) 

head(data_Bauer_Curran_2005)

HSBmod &lt;-nlme::lme(MathAch ~ Sector + CSES + CSES:Sector,
                   data = data_Bauer_Curran_2005, 
                   random = ~1 + CSES|School, method = "ML") 
summary(HSBmod)

REGIONS_OF_SIGNIFICANCE(model=HSBmod,  
                        plot_title='Johnson-Neyman Regions of Significance', 
                        Xaxis_label='Child SES',
                        Yaxis_label='Slopes of School Sector on Math achievement')  
                        

# moderated regression	-- with numeric values for IV_range &amp; MOD_levels='AikenWest'       
mharsh_agg &lt;- 
  MODERATED_REGRESSION(data=data_OConnor_Dvorak_2001, DV='Aggressive_Behavior',
                       IV='Maternal_Harshness', IV_range=c(1,7.7), 
                       MOD='Resiliency', MOD_levels='AikenWest', 
                       quantiles_IV=c(.1, .9), quantiles_MOD=c(.25, .5, .75),
                       center = FALSE, 
                       plot_type = 'interaction', 
                       DV_range = c(1,6), 
                       Xaxis_label='Maternal Harshness', 
                       Yaxis_label='Adolescent Aggressive Behavior', 
                       legend_label='Resiliency') 

REGIONS_OF_SIGNIFICANCE(model=mharsh_agg,  
                        plot_title='Johnson-Neyman Regions of Significance', 
                        Xaxis_label='Resiliency', 
                        Yaxis_label='Slopes of Maternal Harshness on Aggressive Behavior') 

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
