<!DOCTYPE html><html><head><title>Help for package carSurv</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {carSurv}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#carSurv-package'><p>Correlation-Adjusted Regression Survival Scores</p></a></li>
<li><a href='#carSurvScore'><p>Estimate Correlation-Adjusted Regression Survival (CARS) Scores</p></a></li>
<li><a href='#carVarSelect'><p>Variable selection with Correlation-Adjusted Regression Survival (CARS) Scores</p></a></li>
<li><a href='#weightedCovarRcpp'><p>Estimate weighted covariance</p></a></li>
<li><a href='#weightedCovarRcppN'><p>Estimate weighted covariance</p></a></li>
<li><a href='#weightedVarRcpp'><p>Estimate weighted variance</p></a></li>
<li><a href='#weightedVarRcppN'><p>Estimate weighted variance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Correlation-Adjusted Regression Survival (CARS) Scores</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas Welchowski</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Welchowski &lt;welchow@imbie.meb.uni-bonn.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions to estimate the Correlation-Adjusted Regression Survival (CARS) Scores. The method is described in Welchowski, T. and Zuber, V. and Schmid, M., (2018), Correlation-Adjusted Regression Survival Scores for High-Dimensional Variable Selection, &lt;<a href="https://doi.org/10.48550/arXiv.1802.08178">doi:10.48550/arXiv.1802.08178</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, survival, corpcor, mboost, fdrtool</td>
</tr>
<tr>
<td>Suggests:</td>
<td>microbenchmark, mvtnorm</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-02-24 10:36:15 UTC; Thomas</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-02-26 12:34:39 UTC</td>
</tr>
</table>
<hr>
<h2 id='carSurv-package'>Correlation-Adjusted Regression Survival Scores</h2><span id='topic+carSurv-package'></span>

<h3>Description</h3>

<p>Contains functions to estimate the Correlation-Adjusted Regression Survival (CARS) Scores. 
The main function is <code><a href="#topic+carSurvScore">carSurvScore</a></code>, which estimates CARS scores of each variable. 
The higher the absolute values of CARS scores, the higher the variable importance. 
Additionally there is the function <code><a href="#topic+carVarSelect">carVarSelect</a></code> to select cut-off thresholds 
to separate variables associated with survival from noise variables. There are two possible 
cut-off threshold options: False non-discovery rate q-values and empirical quantiles of the 
raw scores.
</p>


<h3>Details</h3>

<p>Package:	 carSurv <br />
<br />
Type:	 Package <br />
<br />
Version:	 1.0.0 <br />
<br />
Date:	 2018-02-24 <br />
<br />
License:	 GPL-3
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski (Maintainer) <a href="mailto:welchow@imbie.meb.uni-bonn.de">welchow@imbie.meb.uni-bonn.de</a>
</p>


<h3>References</h3>

<p>Welchowski, T. and Zuber, V. and Schmid, M., (2018), Correlation-Adjusted Regression Survival Scores for High-Dimensional Variable Selection, &lt;arXiv:1802.08178&gt;
</p>
<p>Zuber, V. and Strimmer, K., (2011), High-Dimensional Regression and Variable 
Selection Using CAR Scores, Statistical Applications in Genetics and Molecular Biology
</p>
<p>Schaefer, J. and Strimmer, K., (2005), A Shrinkage Approach to Large-Scale Covariance Matrix Estimation and Implications for Functional Genomics,
Statistical Applications in Genetics and Molecular Biology
</p>
<p>Van der Laan, M. J. and Robins, J. M., (2003), Unified Methods for Censored Longitudinal Data and Causality, Springer Series in Statistics
Strimmer, K., (2008), A unified approach to false discovery rate estimation, BMC Bioinformatics
</p>

<hr>
<h2 id='carSurvScore'>Estimate Correlation-Adjusted Regression Survival (CARS) Scores</h2><span id='topic+carSurvScore'></span>

<h3>Description</h3>

<p>Estimates CARS scores. CARS scores measure the relative importance of each 
variable with respect to the survival times adjusted by IPC weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>carSurvScore(obsTime, obsEvent, X, maxIPCweight = 10, denom = "1/n")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="carSurvScore_+3A_obstime">obsTime</code></td>
<td>
<p>Observed time points of a right censored survival process
(numeric vector).</p>
</td></tr>
<tr><td><code id="carSurvScore_+3A_obsevent">obsEvent</code></td>
<td>
<p>Observed event indicator of right censored survival process
(numeric vector) 0=no event, 1=event</p>
</td></tr>
<tr><td><code id="carSurvScore_+3A_x">X</code></td>
<td>
<p>Data of design variables (numeric matrix). Must be already encoded.</p>
</td></tr>
<tr><td><code id="carSurvScore_+3A_maxipcweight">maxIPCweight</code></td>
<td>
<p>Specifies the maximum possible weight, 
to ensure numerical stability.</p>
</td></tr>
<tr><td><code id="carSurvScore_+3A_denom">denom</code></td>
<td>
<p>Specifies the denominator of the weighted sums. Two options are available: 
The default value &quot;1/n&quot; uses the sample size as denominator. Option &quot;sum_w&quot; uses the sum of all IPC weights in the denominator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CARS scores are defined as theta=P_X^(-1/2) P_(X, log(T)). 
The term P_X^(-1/2) is the inverse square root of the correlation matrix between 
covariates X. P_(X, log(T)) is the correlation vector between covariates and 
the logarithmic survival time adjusted for censoring by IPC weighting.
</p>


<h3>Value</h3>

<p>Estimated CAR survival score of each variable (numeric vector).
</p>


<h3>Note</h3>

<p>It is recommended to use default setting &quot;denom=1/n&quot; because in this case 
CARS scores are consistent. Furthermore the simulation results of &quot;1/n&quot; show lower 
root mean squared error of CARS scores with respect to the true parameter.
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski
</p>


<h3>References</h3>

<p>Welchowski, T. and Zuber, V. and Schmid, M., (2018), Correlation-Adjusted Regression Survival Scores for High-Dimensional Variable Selection, &lt;arXiv:1802.08178&gt;
</p>
<p>Zuber, V. and Strimmer, K., (2011), High-Dimensional Regression and Variable 
Selection Using CAR Scores, Statistical Applications in Genetics and Molecular Biology
</p>
<p>Schaefer, J. and Strimmer, K., (2005), A Shrinkage Approach to Large-Scale Covariance Matrix Estimation and Implications for Functional Genomics,
Statistical Applications in Genetics and Molecular Biology
</p>
<p>Van der Laan, M. J. and Robins, J. M., (2003), Unified Methods for Censored Longitudinal Data and Causality, Springer Series in Statistics
</p>


<h3>See Also</h3>

<p><code><a href="#topic+carVarSelect">carVarSelect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########################################
# Simulate accelerated, failure time model

# Generate multivariate normal distributed covariates
noObs &lt;- 100
noCovar &lt;- 10
library(mvtnorm)
set.seed(190)
X &lt;- rmvnorm(noObs, mean=rep(0, noCovar), sigma=diag(noCovar))

# Generate gamma distributed survival times
# Only the first 5 variables have an influence
eta &lt;- 1 - 2 * X[,1] - X[,2] + X[,3] +
0.5 * X[,4] + 1.5 * X[,5]

# Function to generate survival times
genSurv &lt;- function(x) {
set.seed(x)
rgamma(1, shape=2, scale=exp(eta[x]))
}

# Generate survival times
survT &lt;- sapply(1:length(eta), genSurv)

# Generate exponential distributed censoring times
censT &lt;- rexp(noObs, rate=1)

# Calculate event indicator
eventInd &lt;- ifelse(survT &lt;= censT, 1, 0)

# Calculate observed times
obsTime &lt;- survT
obsTime[survT &gt; censT] &lt;- censT [survT &gt; censT]

# Estimate CAR scores
carScores &lt;- carSurvScore(obsTime=obsTime, obsEvent=eventInd, X=X)
carScores
</code></pre>

<hr>
<h2 id='carVarSelect'>Variable selection with Correlation-Adjusted Regression Survival (CARS) Scores</h2><span id='topic+carVarSelect'></span>

<h3>Description</h3>

<p>Computes the CARS scores and selects significant variables. 
If the false non discovery rate (fndr) approach is used, significant and null variables
are distinguished by an a priori defined q-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>carVarSelect(carSurvScores, method = "fndr", plotDiag = FALSE,
  threshold = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="carVarSelect_+3A_carsurvscores">carSurvScores</code></td>
<td>
<p>Estimated CAR survival scores of each variable (numeric vector).
See function <code><a href="#topic+carSurvScore">carSurvScore</a></code>.</p>
</td></tr>
<tr><td><code id="carVarSelect_+3A_method">method</code></td>
<td>
<p>Gives the variable selection procedure. Default is &quot;fndr&quot;, which is based
on the false non-discovery-rate. The other option is &quot;threshold&quot;, which selects only 
variables above a given empirical quantile.</p>
</td></tr>
<tr><td><code id="carVarSelect_+3A_plotdiag">plotDiag</code></td>
<td>
<p>Should diagnostic plots of the null distribution be plotted? 
Default is FALSE (logical scalar).</p>
</td></tr>
<tr><td><code id="carVarSelect_+3A_threshold">threshold</code></td>
<td>
<p>If method=&quot;threshold&quot;, then this specifies the quantile threshold of
the CAR survival scores. Every score above this threshold is then a significant variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Index giving the significant variables of the original data (integer vector).
</p>


<h3>Note</h3>

<p>The quality of estimated, significant variables depends on the sample size 
and on the number of variables.
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski
</p>


<h3>References</h3>

<p>Strimmer, K., (2008), A unified approach to false discovery rate estimation, BMC Bioinformatics
</p>


<h3>See Also</h3>

<p><code><a href="#topic+carSurvScore">carSurvScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########################################
# Simulate accelerated, failure time model

# Generate multivariate normal distributed covariates
noObs &lt;- 100
noCovar &lt;- 250
library(mvtnorm)
set.seed(7903)
X &lt;- rmvnorm(noObs, mean=rep(0, noCovar), sigma=diag(noCovar))

# Generate gamma distributed survival times
# Only the first 5 variables have an influence
eta &lt;- 1 - 2 * X[,1] - X[,2] + X[,3] +
0.5 * X[,4] + 1.5 * X[,5]

# Function to generate survival times
genSurv &lt;- function(x) {
set.seed(x)
rgamma(1, shape=2, scale=exp(eta[x]))
}

# Generate survival times
survT &lt;- sapply(1:length(eta), genSurv)

# Generate exponential distributed censoring times
censT &lt;- rexp(noObs, rate=1)

# Calculate event indicator
eventInd &lt;- ifelse(survT &lt;= censT, 1, 0)

# Calculate observed times
obsTime &lt;- survT
obsTime[survT &gt; censT] &lt;- censT [survT &gt; censT]

# Conduct variable selection using fndr
carScores &lt;- carSurvScore(obsTime=obsTime, obsEvent=eventInd, X=X)
selectedVar &lt;- carVarSelect(carSurvScores=carScores)
selectedVar

# Check true positive and true negative rate
TPR &lt;- mean(c(1:5) %in% selectedVar)
TNR &lt;- mean(c(6:250) %in% setdiff(6:250, selectedVar))
perf &lt;- TPR + TNR -1
perf
</code></pre>

<hr>
<h2 id='weightedCovarRcpp'>Estimate weighted covariance</h2><span id='topic+weightedCovarRcpp'></span>

<h3>Description</h3>

<p>Efficient C implementation of the sample covariance estimator. 
The denominator is defined as the sum of all weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedCovarRcpp(x, y, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedCovarRcpp_+3A_x">x</code></td>
<td>
<p>Covariate without weighting (numeric vector).</p>
</td></tr>
<tr><td><code id="weightedCovarRcpp_+3A_y">y</code></td>
<td>
<p>Response. The mean of the response contains weights (numeric vector).</p>
</td></tr>
<tr><td><code id="weightedCovarRcpp_+3A_w">w</code></td>
<td>
<p>Weights for averaging (numeric vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Weighted variance (numeric scalar).
</p>


<h3>Note</h3>

<p>If all weights are set to 1, the denominator is identical to n. 
There are no safety checks of input arguments.
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate two random vectors
set.seed(3975)
x &lt;- rnorm(100)
set.seed(-3975)
y &lt;- rnorm(100)
# Calculate variance with standard R function
# Rescaling ensures that both calculations use same denominator "n"
covarEst &lt;- cov(x, y) * (100-1) / 100
# Calculate weighted variance with equal weights
equalW &lt;- rep(1, 100)
weightCovarEst &lt;- weightedCovarRcpp(x=x, y=y, w=equalW)
# Output comparison
all.equal(covarEst, weightCovarEst)
# Runtime comparison
library(microbenchmark)
microbenchmark(Default=cov(x, y), New=weightedCovarRcpp(x=x, y=y, w=equalW), times=25)
# -&gt; New method is multiple times faster
</code></pre>

<hr>
<h2 id='weightedCovarRcppN'>Estimate weighted covariance</h2><span id='topic+weightedCovarRcppN'></span>

<h3>Description</h3>

<p>Efficient C implementation of the sample covariance estimator. 
The denominator is defined as the sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedCovarRcppN(x, y, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedCovarRcppN_+3A_x">x</code></td>
<td>
<p>Covariate without weighting (numeric vector).</p>
</td></tr>
<tr><td><code id="weightedCovarRcppN_+3A_y">y</code></td>
<td>
<p>Response. The mean of the response contains weights (numeric vector).</p>
</td></tr>
<tr><td><code id="weightedCovarRcppN_+3A_w">w</code></td>
<td>
<p>Weights for averaging (numeric vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Weighted variance (numeric scalar).
</p>


<h3>Note</h3>

<p>There are no safety checks of input arguments.
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate two random vectors
set.seed(3975)
x &lt;- rnorm(100)
set.seed(-3975)
y &lt;- rnorm(100)
# Calculate variance with standard R function
# Rescaling ensures that both calculations use same denominator "n"
covarEst &lt;- cov(x, y) * (100-1) / 100
# Calculate weighted variance with equal weights
equalW &lt;- rep(1, 100)
weightCovarEst &lt;- weightedCovarRcppN(x=x, y=y, w=equalW)
# Output comparison
all.equal(covarEst, weightCovarEst)
# Runtime comparison
library(microbenchmark)
microbenchmark(Default=cov(x, y), New=weightedCovarRcpp(x=x, y=y, w=equalW), times=25)
# -&gt; New method is multiple times faster
</code></pre>

<hr>
<h2 id='weightedVarRcpp'>Estimate weighted variance</h2><span id='topic+weightedVarRcpp'></span>

<h3>Description</h3>

<p>Efficient C implementation of the sample variance estimator. 
The denominator is defined as sum of all weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedVarRcpp(y, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedVarRcpp_+3A_y">y</code></td>
<td>
<p>Response. The mean of the response contains weights (numeric vector).</p>
</td></tr>
<tr><td><code id="weightedVarRcpp_+3A_w">w</code></td>
<td>
<p>Weights for averaging (numeric vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Weighted variance (numeric scalar).
</p>


<h3>Note</h3>

<p>If all weights are set to 1, the denominator is identical to n.
There are no safety checks of input arguments.
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate a random vector
set.seed(3975)
x &lt;- rnorm(100)
# Calculate variance with standard implementation
# Rescaling ensures that both calculations use same denominator "n"
varEst &lt;- var(x) * (100-1) / 100
# Calculate weighted variance with equal weights
equalW &lt;- rep(1/100, 100)
weightVarEst &lt;- weightedVarRcpp(y=x, w=equalW)
# Output comparison
all.equal(varEst, weightVarEst)
# Runtime comparison
library(microbenchmark)
microbenchmark(Default=var(x), New=weightedVarRcppN(y=x, w=equalW), times=25)
# -&gt; New method is multiple times faster
</code></pre>

<hr>
<h2 id='weightedVarRcppN'>Estimate weighted variance</h2><span id='topic+weightedVarRcppN'></span>

<h3>Description</h3>

<p>Efficient C implementation of the sample variance estimator. 
The denominator is defined as the sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedVarRcppN(y, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedVarRcppN_+3A_y">y</code></td>
<td>
<p>Response. The mean of the response contains weights (numeric vector).</p>
</td></tr>
<tr><td><code id="weightedVarRcppN_+3A_w">w</code></td>
<td>
<p>Weights for averaging (numeric vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Weighted variance (numeric scalar).
</p>


<h3>Note</h3>

<p>There are no safety checks of input arguments.
</p>


<h3>Author(s)</h3>

<p>Thomas Welchowski
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate a random vector
set.seed(3975)
x &lt;- rnorm(100)
# Calculate variance with standard implementation
varEst &lt;- var(x) * (100-1) / 100
# Calculate weighted variance with equal weights
equalW &lt;- rep(1, 100)
weightVarEst &lt;- weightedVarRcppN(y=x, w=equalW)
# Output comparison
all.equal(varEst, weightVarEst)
# Runtime comparison
library(microbenchmark)
microbenchmark(Default=var(x), New=weightedVarRcppN(y=x, w=equalW), times=25)
# -&gt; New method is multiple times faster
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
