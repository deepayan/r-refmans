<!DOCTYPE html><html lang="en"><head><title>Help for package Infusion</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Infusion}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Infusion'><p>Inference using simulation</p></a></li>
<li><a href='#.update_obs'>
<p>Updating an 'SLik_j' object for new data</p></a></li>
<li><a href='#add_reftable'>
<p>Create or augment a list of simulated distributions of summary statistics</p></a></li>
<li><a href='#add_simulation'>
<p>Create or augment a list of simulated distributions of summary statistics</p></a></li>
<li><a href='#check_raw_stats'>
<p>Check linear dependencies among raw summary statistics</p></a></li>
<li><a href='#confint.SLik'>
<p>Compute confidence intervals by (profile) summary likelihood</p></a></li>
<li><a href='#constr_crits'>
<p>Specificying arbitrary constraints on parameters</p></a></li>
<li><a href='#declare_latent'>
<p>Modeling and predicting latent variables</p></a></li>
<li><a href='#densv'>
<p>Saved computations of inferred log-likelihoods</p></a></li>
<li><a href='#dMixmod'>
<p>Internal S4 classes.</p></a></li>
<li><a href='#example_raw'><p>Workflow for primitive method, without projections</p></a></li>
<li><a href='#example_raw_proj'><p>Workflow for primitive method, with projections</p></a></li>
<li><a href='#example_reftable'><p>Workflow for method with reference table</p></a></li>
<li><a href='#extractors'>
<p>Summary, print and logLik methods for Infusion results.</p></a></li>
<li><a href='#focal_refine'>
<p>Refine summary likelihood profile in focal parameter values</p></a></li>
<li><a href='#get_from'>
<p>Backward-compatible extractor from summary-likelihood objects</p></a></li>
<li><a href='#get_LRboot'>
<p>Summary likelihood ratio tests</p></a></li>
<li><a href='#get_nbCluster_range'>
<p>Control of number of components in Gaussian mixture modelling</p></a></li>
<li><a href='#get_workflow_design'>
<p>Workflow design</p></a></li>
<li><a href='#goftest'>
<p>Assessing goodness of fit of inference using simulation</p></a></li>
<li><a href='#handling_NAs'>
<p>Discrete probability masses and NA/NaN/Inf in distributions of summary statistics.</p></a></li>
<li><a href='#infer_logLs'>
<p>Infer log Likelihoods using simulated distributions of summary statistics</p></a></li>
<li><a href='#infer_SLik_joint'>
<p>Infer a (summary) likelihood surface from a simulation table</p></a></li>
<li><a href='#infer_surface'>
<p>Infer a (summary) likelihood or tail probability surface from inferred likelihoods</p></a></li>
<li><a href='#Infusion-internal'><p>Internal Infusion Functions</p></a></li>
<li><a href='#init_reftable'>
<p>Define starting points in parameter space.</p></a></li>
<li><a href='#MAF.options'>
<p>Control of MAF design and training</p></a></li>
<li><a href='#MSL'>
<p>Maximum likelihood from an inferred likelihood surface</p></a></li>
<li><a href='#multi_binning'>
<p>Multivariate histogram</p></a></li>
<li><a href='#options'><p>Infusion options settings</p></a></li>
<li><a href='#plot_proj'>
<p>Diagnostic plots for projections</p></a></li>
<li><a href='#plot.SLik'>
<p>Plot SLik or SLikp objects</p></a></li>
<li><a href='#plot1Dprof'>
<p>Plot likelihood profiles</p></a></li>
<li><a href='#predict.SLik_j'>
<p>Evaluate log-likelihood for given parameters</p></a></li>
<li><a href='#profile.SLik'>
<p>Compute profile summary likelihood</p></a></li>
<li><a href='#project.character'>
<p>Learn a projection method for statistics and apply it</p></a></li>
<li><a href='#refine'>
<p>Refine estimates iteratively</p></a></li>
<li><a href='#reparam_fit'>
<p>Conversion to new parameter spaces</p></a></li>
<li><a href='#rparam'>
<p>Sample the parameter space</p></a></li>
<li><a href='#save_MAFs'>
<p>Save or load MAF Python objects</p></a></li>
<li><a href='#simulate.SLik_j'>
<p>Simulate method for an <code>SLik_j</code> object.</p></a></li>
<li><a href='#summLik'>
<p>Model density evaluation for given data and parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Inference Using Simulation</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements functions for simulation-based inference. In particular, implements functions to perform likelihood inference from data summaries whose distributions are simulated. The package implements more advanced methods than the ones first described in: Rousset, Gouy, Almoyna and Courtiol  (2017) &lt;<a href="https://doi.org/10.1111%2F1755-0998.12627">doi:10.1111/1755-0998.12627</a>&gt;.  </td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-26</td>
</tr>
<tr>
<td>Imports:</td>
<td>spaMM (&ge; 4.4.16), proxy, blackbox (&ge; 1.1.41), mvtnorm,
methods, numDeriv, pbapply, ranger, foreach, matrixStats, boot,
nloptr, geometry, cli, viridisLite</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, Rmixmod, caret, xLLiM, reticulate, mafR (&ge; 1.0.11)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>François Rousset &lt;francois.rousset@umontpellier.fr&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.cecill.info/licences/Licence_CeCILL_V2-en.txt">CeCILL-2</a></td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://gitlab.mbb.univ-montp2.fr/francois/Infusion">https://gitlab.mbb.univ-montp2.fr/francois/Infusion</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-26 14:51:05 UTC; francois.rousset</td>
</tr>
<tr>
<td>Author:</td>
<td>François Rousset <a href="https://orcid.org/0000-0003-4670-0371"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-26 21:00:49 UTC</td>
</tr>
</table>
<hr>
<h2 id='Infusion'>Inference using simulation</h2><span id='topic+Infusion'></span><span id='topic+Infusion-package'></span>

<h3>Description</h3>

<p>Implements a collection of methods to perform inferences based on simulation of realizations of the model considered. In particular it implements 
&ldquo;summary likelihood&rdquo;, an approach that effectively evaluates and uses the likelihood of simulated summary statistics. 
</p>
<p>The procedures for the &ldquo;primitive&rdquo; workflow, implemented in the first published version of the package, are being maintained for back compatibility, but users are urged to use the distinct, up-to-date workflow (see Examples). The package is expected to perform best when used in combination with <span class="pkg">Rmixmod</span> for multivariate Gaussian mixture modeling, although the <span class="pkg">mclust</span> package can also be used (with less control and perhaps decreased performance). The inference workflow typically (but not necessarily) includes dimension-reduction steps (&ldquo;projections&rdquo;) for summary statistics, and has been more finely tuned for projections performed using the <span class="pkg">ranger</span> package (though <span class="pkg">Infusion</span> should handle other methods). 
</p>
<p>The up-to-date workflow builds and updates an object of class <code>"SLik_j"</code> which is designed to carry all the information required for pursuing the inference. Thus, successive inference steps (in particular, successive calls to the key <code><a href="#topic+refine">refine</a></code> function) can be carried on different computers, with the caveats noted below, by transferring the object between computers. 
</p>
<p>The <code>"SLik_j"</code> object includes in particular the reference table, information about all projections (this can be memory-expensive, so it has been made possible to remove non-essential information, specifically for <span class="pkg">ranger</span> results, using <code><a href="#topic+deforest_projectors">deforest_projectors</a></code>: this information will be regenerated automatically if needed), and a sample-simulation function. If the latter function is a wrapper for an external simulation program, then this simulation program must be provided in addition to the <code>"SLik_j"</code> object. If an external program has to be called differently on different computers, information specific to each computer can be provided by the optional <code>control.Simulate</code> argument of <code><a href="#topic+refine">refine</a></code>.
</p>
<p>People used to the functional-programming style common in R, where the return value entirely defines the effect of a function call, may be surprized by the distinct style of some of functions of this package. Indeed, the <code>"SLik_j"</code> objects include environments that may be modified by functions, independently of what these functions return. Notably, the profile plots (see <code><a href="#topic+plot1Dprof">plot1Dprof</a></code>) and summary-likelihood ratio tests (<code><a href="#topic+SLRT">SLRT</a></code>) may update the  summary-likelihood estimates. 
However, the more significant caveat of such usage of environments, from an inferential viewpoint, is that the projectors stored in input and output fit objects of a <code>refine</code> call are stored in the same environment, and therefore the projectors stored in the input object are modified in light of new simulations (or by any other operation affecting them in the refine), which alters the statistical meaning of any subsequent operation reusing the projectors from the input object. To keep the unmodified version of the projectors, users may need to save a fit object on disk before a refine call. This feature could of course be modified, but is retained for the following reasons: (1) in the routine workflow, only the latest fit object and its projectors will be relevant (but when comparing performance of the inference method for, e.g., reference tables of different sizes, more care is needed); and (2) projectors can be memory-expensive objects, so keeping distinct versions of them in successive fit objects may have substantial drawbacks.  
</p>


<h3>Details</h3>

<p>The methods implemented in <code>Infusion</code> by default assume that the summary statistics have densities. Special values of some statistic, having discrete probability mass, can be more or less automatically handled by the up-to-date workflow, which also handles automatically NA values of summary statistics. For the primitive workflow, both of these problems could be handled to a limited extent using the <code>boundaries</code> attribute of the observed summary statistics (see <code><a href="#topic+handling_NAs">handling_NAs</a></code> for one use of this attribute).              
</p>


<h3>Note</h3>

<p>See examples <code><a href="#topic+example_reftable">example_reftable</a></code> for the most complete example using up-to-date workflow, and <code><a href="#topic+example_raw_proj">example_raw_proj</a></code> or <code><a href="#topic+example_raw">example_raw</a></code> for older workflows.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='.update_obs'>
Updating an 'SLik_j' object for new data
</h2><span id='topic+.update_obs'></span>

<h3>Description</h3>

<p><code>.update_obs</code> is an <em>experimental</em> utility to recycle the information in an inference object to produce an inference for different data without repeating a simulation workflow. Beyond its experimental nature, its result is not expected to provide the same precision of inference as a standard iterative <span class="pkg">Infusion</span> workflow, since the recycled simulations were adapted to the original data only (<code>.update_obs</code> indeed allows one to investigate the effect of using this non-adapted information). So the new results should not be used as a equivalent to a full <span class="pkg">Infusion</span> iterative workflow.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.update_obs(object, new.obs, CIs = FALSE, eval_RMSEs = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".update_obs_+3A_object">object</code></td>
<td>

<p>an object of class <code>"SLik_j"</code> as createded by <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> (possible updated by <code>MSL</code> and <code>refine</code>).
</p>
</td></tr>
<tr><td><code id=".update_obs_+3A_new.obs">new.obs</code></td>
<td>

<p>A named vector of summary statistics (ideally the projected ones, but raw ones are handled)
</p>
</td></tr>
<tr><td><code id=".update_obs_+3A_cis">CIs</code>, <code id=".update_obs_+3A_eval_rmses">eval_RMSEs</code>, <code id=".update_obs_+3A_...">...</code></td>
<td>

<p>further arguments passed to <code><a href="#topic+MSL">MSL</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"SLik_j"</code> as the input <code>object</code>.
</p>

<hr>
<h2 id='add_reftable'>
Create or augment a list of simulated distributions of summary statistics 
</h2><span id='topic+add_reftable'></span>

<h3>Description</h3>

<p><code>add_reftable</code> creates or augments a reference table of simulations, and formats the results appropriately for further use. The user does not have to think about this return format. Instead, s-he only has to think about the very simple return format of the function given as its <code>Simulate</code> argument. The primary role of his function is to wrap the call(s) of the function specified by <code>Simulate</code>. Depending on the arguments, parallel or serial computation is performed. 
</p>
<p>When parallelization is implied, it is performed by by default a &ldquo;socket&rdquo; cluster, available on all operating systems. Special care is then needed to ensure that all required packages are loaded in the called processes, and that all required variables and functions are passed therein: check the <code>packages</code> and <code>env</code> arguments. For socket clusters, <code>foreach</code> or <code>pbapply</code> is called depending whether the <code>doSNOW</code> package is attached (<code>doSNOW</code> allows more efficient load balancing than <code>pbapply</code>). 
</p>
<p>Alternatively, if the simulation function cannot be called directly by the R code, simulated samples can be added using the <code>newsimuls</code> argument. Finally, a generic data frame of simulated samples can be reformatted as a reference table by using only the <code>reftable</code> argument.
</p>
<p><code>add_simulation</code> is a wrapper for <code>add_reftable</code>, suitable when <code>nRealizations</code>&gt;1. It is now distinctly documented: the distinct features of <code>add_simulation</code> were conceived for the first workflow implemented in <code>Infusion</code> but are somewhat obsolete now.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_reftable(reftable=NULL, Simulate, parsTable=par.grid, par.grid=NULL, 
             nRealizations = 1L, newsimuls = NULL, 
             verbose = interactive(), nb_cores = NULL, packages = NULL, 
             env = NULL, control.Simulate=NULL, cluster_args=list(), 
             cl_seed=NULL, constr_crits=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_reftable_+3A_reftable">reftable</code></td>
<td>

<p>Data frame: a reference table. Each row contains parameters value of a simulated realization of the data-generating process, and the simulated summary statistics.  
As parameters should be told apart from statistics by <span class="pkg">Infusion</span> functions, information about parameter names should be attached to the <code>reftable</code> <b>*if*</b> it is not available otherwise. Thus if no <code>parsTable</code> is provided, the <code>reftable</code> should have an attribute <code>"LOWER"</code> (a named vectors giving lower bounds for the parameters which will vary in the analysis, as in the return value of the function).  
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_simulate">Simulate</code></td>
<td>

<p>An *R* function, or the name (as a character string) of an *R* function used to generate summary statistics for samples form a data-generating process. When an external simulation program is called, <code>Simulate</code> must therefore be an R function wrapping the call to the external program. Two function APIs are handled:<br /> <code> * </code><b>If the function has a <code>parsTable</code> argument</b>, it must return a <b>*data frame*</b> of summary statistics, each line of which contains the vector of summary statistics for one realization of the data-generating process. The <code>parsTable</code> argument of <code>add_reftable</code> will be passed to <code>Simulate</code> and lines of the output data frame must be ordered, as in the input <code>parsTable</code> as these two data frames will be bound together.<br /> <code> * </code><code>Otherwise</code>, the <code>Simulate</code> function must return a <b>*vector*</b> of summary statistics with named vector members, and it must have <b>one argument for each element</b> of the parameter vector (i.e. of each column of a matching <code>parsTable</code>).
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_parstable">parsTable</code>, <code id="add_reftable_+3A_par.grid">par.grid</code></td>
<td>

<p>A data frame of which each line is the vector of parameters needed by <code>Simulate</code> for each simulation of the data-generating process. <code>par.grid</code> is an alias for <code>parsTable</code>; the latter argument may be preferred in order not to suggest that the parameter values should form a regular grid.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_nrealizations">nRealizations</code></td>
<td>

<p>The number of simulated samples of summary statistics, for each parameter vector (each row of <code>parsTable</code>). If not 1, theold wrkflow is assumed and <code><a href="#topic+add_simulation">add_simulation</a></code> is called.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_newsimuls">newsimuls</code></td>
<td>

<p>If the function used to generate empirical distributions cannot be called by R, then <code>newsimuls</code> can be used to provide these distributions. See Details for the structure of this argument.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Number of cores for parallel simulation; <code>NULL</code> or integer value, acting as a shortcut for <code>cluster_args$spec</code>. This is effective only if the simulation function is called separately for each row of <code>parsTable</code>. Otherwise, if the simulation function is called once one the whole <code>parsTable</code>, parallelisation could be controlled only through that function's own arguments.   
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. May contain a non-null <code>spec</code> element, in which case the distinct <code>nb_cores</code> argument and the global <span class="pkg">Infusion</span> option <code>nb_cores</code> are ignored. A typical usage would thus be <code>control_args=list(spec=&lt;number of 'children'&gt;)</code>. Additional elements <code>outfile="log.txt"</code> may be useful to collect output from the nodes, and <code>type="FORK"</code> may be used to force a fork cluster on linux(-alikes) (otherwise a socket cluster is set up as this is the default effect of <code>parallel::makeCluster</code>). Do <b>*not*</b> use a structured list with an <code>add_reftable</code> element as is possible for <code>refine</code> (see Details of <code><a href="#topic+refine">refine</a></code> documentation).
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>Simulate</code>, beyond the parameter vector. These arguments should be constant through all the simulation workflow. 
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_control.simulate">control.Simulate</code></td>
<td>
<p>A list, used as an exclusive alternative to &ldquo;...&rdquo; to pass additional arguments to <code>Simulate</code>, beyond the parameter vector. The list must contain the same elements as would otherwise go in the &ldquo;...&rdquo; (if <code>control.Simulate</code> is left NULL, a default value is constructed from the ...).</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_packages">packages</code></td>
<td>
<p>For parallel evaluation: Names of additional libraries to be loaded on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_env">env</code></td>
<td>
<p>For parallel evaluation: an environment containing additional objects to be exported on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_cl_seed">cl_seed</code></td>
<td>

<p>(all parallel contexts:) Integer, or NULL. If an integer, it is used to initialize <code>"L'Ecuyer-CMRG"</code> random-number generator. If <code>cl_seed</code> is <code>NULL</code>, the default generator is selected on each node, where its seed is not controlled. Providing the seed allows repeatable results for given parallelization settings, but may not allow identical results across different settings. 
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_constr_crits">constr_crits</code></td>
<td>
<p>NULL, or quoted expression specifying a constraints on parameters, beyond the ones defined by the ranges over each parameter: see <code><a href="#topic+constr_crits">constr_crits</a></code> for details. However, if sampled parameters were generated by <code>init_reftable(., constr_crits=...)</code>, there is no need to apply the constraints again through <code>add_reftable</code>; and given the choice, it is better to apply them when calling <code>init_reftable</code>, as this allows a better control of the size of the reference table.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>newsimuls</code> argument should have the same structure as the return value of the function itself, except that <code>newsimuls</code> may include only a subset of the attributes returned by the function. It is thus a data frame; its required attributes are <code>LOWER</code> and <code>UPPER</code> which are named vectors giving bounds for the parameters which are variable in the whole analysis (note that the names identify these parameters in the case this information is not available otherwise from the arguments). The values in these vectors may be incorrect in the sense of failing to bound the parameters in the <code>newsimuls</code>, as the actual bounds are then corrected using parameter values in <code>newsimuls</code> and attributes from <code>reftable</code>.  
</p>


<h3>Value</h3>

<p>A data.frame (with additional attributes) is returned. 
</p>
<p>The value has the following attributes: <code>LOWER</code> and <code>UPPER</code> which are each a vector of per-parameter minima and maxima deduced from any <code>newsimuls</code> argument, and optionally any of the arguments <code>Simulate, control.Simulate, packages, env, parsTable</code> and  <code>reftable</code> (all corresponding to input arguments when provided, except that the actual <code>Simulate</code> function is returned even if it was input as a name).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package for other typical usage
</code></pre>

<hr>
<h2 id='add_simulation'>
Create or augment a list of simulated distributions of summary statistics 
</h2><span id='topic+add_simulation'></span>

<h3>Description</h3>

<p><code>add_simulation</code> is suitable for the primitive <span class="pkg">Infusion</span> workflow; otherwise, it is cleaer to call <code><a href="#topic+add_reftable">add_reftable</a></code> directly. 
<code>add_simulation</code> creates or augments a list of simulated distributions of summary statistics, and formats the results appropriately for further use. Alternatively, if the simulation function cannot be called directly by the R code, simulated distributions can be added using the <code>newsimuls</code> argument, using a simple format (see <code>onedistrib</code> in the Examples). Finally, a generic data frame of simulations can be reformatted as a reference table by using only the <code>simulations</code> argument.
</p>
<p>Depending on the arguments, parallel or serial computation is performed. When parallelization is implied, by default a &ldquo;socket&rdquo; cluster, available on all operating systems. Special care is then needed to ensure that all required packages are loaded in the called processes, and that all required variables and functions are passed therein: check the <code>packages</code> and <code>env</code> arguments. For socket clusters, <code>foreach</code> or <code>pbapply</code> is called depending whether the <code>doSNOW</code> package is attached (<code>doSNOW</code> allows more efficient load balancing than <code>pbapply</code>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_simulation(simulations=NULL, Simulate, parsTable=par.grid, par.grid=NULL, 
               nRealizations=Infusion.getOption("nRealizations"),
               newsimuls=NULL, verbose=interactive(), nb_cores=NULL, 
               packages=NULL, env=NULL, control.Simulate=NULL,
               cluster_args=list(), cl_seed=NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_simulation_+3A_simulations">simulations</code></td>
<td>

<p>A list of matrices each representing a simulated distribution for given parameters in a format consistent with the return format of <code>add_simulation</code>.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_nrealizations">nRealizations</code></td>
<td>

<p>The number of simulated samples of summary statistics, for each empirical distribution (each row of <code>par.grid</code>).
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_simulate">Simulate</code></td>
<td>

<p>An *R* function, or the name (as a character string) of an *R* function used to generate empirical distributions of summary statistics. When an external simulation program is called, <code>Simulate</code> must therefore be an R function wrapping the call to the external program. The <code>Simulate</code> function must have one argument for each element of the parameter vector (i.e. of each row of <code>par.grid</code>). It must return a vector of summary statistics with named vector members; <b>or</b> a single matrix of <code>nRealizations</code> simulations, in which case its rows and row names must represent the summary statistics, it should have <code>nRealizations</code> columns, and <code>nRealizations</code> should be named integer of the form &ldquo;<code>c(as_one=.)</code>&rdquo; (see Examples).
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_parstable">parsTable</code>, <code id="add_simulation_+3A_par.grid">par.grid</code></td>
<td>

<p>A data frame of which each line is the vector of parameters needed by <code>Simulate</code> for each simulation of the data-generating process. <code>par.grid</code> is an alias for <code>parsTable</code>; the latter argument may be preferred in order not to suggest that the parameter values should form a regular grid.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_newsimuls">newsimuls</code></td>
<td>

<p>If the function used to generate empirical distributions cannot be called by R, then <code>newsimuls</code> can be used to provide these distributions. See Details for the structure of this argument.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Number of cores for parallel simulation; <code>NULL</code> or integer value, acting as a shortcut for <code>cluster_args$spec</code>. The effect is complicated: see Details.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. May contain a non-null <code>spec</code> element, in which case the distinct <code>nb_cores</code> argument and the global <span class="pkg">Infusion</span> option <code>nb_cores</code> are ignored. A typical usage would thus be <code>control_args=list(spec=&lt;number of 'children'&gt;)</code>. Additional elements <code>outfile="log.txt"</code> may be useful to collect output from the nodes, and <code>type="FORK"</code> may be used to force a fork cluster on linux(-alikes) (otherwise a socket cluster is set up as this is the default effect of <code>parallel::makeCluster</code>).
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_...">...</code></td>
<td>

<p>Arguments passed to <code>add_reftable</code> (and possibly beyond, to the simulation function: see <code>nsim</code> argument of <code>myrnorm_tab()</code> in the Examples. These arguments should be constant through all the simulation workflow.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_control.simulate">control.Simulate</code></td>
<td>
<p>A list, used as an exclusive alternative to &ldquo;...&rdquo; to pass additional arguments to <code>Simulate</code>, beyond the parameter vector. The list must contain the same elements as would go in the &ldquo;...&rdquo;.</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_packages">packages</code></td>
<td>
<p>For parallel evaluation: Names of additional libraries to be loaded on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_env">env</code></td>
<td>
<p>For parallel evaluation: an environment containing additional objects to be exported on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_cl_seed">cl_seed</code></td>
<td>
<p>Integer, or NULL. Providing the seed was conceived to allow repeatable results at least for given parallelization settings, if not identical results across different parallelization contexts. However, this functionality may have been been lost as the code was adapted for the up-to-date workflow using <code>add_reftable</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>newsimuls</code> argument should have the same structure as the return value of the function itself, except that <code>newsimuls</code> may include only a subset of the attributes returned by the function. <code>newsimuls</code> should thus be list of matrices, each with a <code>par</code> attribute (see Examples). Rows of each matrix stand for simulation replicates and columns stand for the different summary statistics. 
</p>
<p>When <code>nRealizations</code>&gt;1L, if <code>nb_cores</code> is unnamed or has name <code>"replic"</code> and if the simulation function does not return a single table for all replicates (thus, if <code>nRealizations</code> is <b>not</b> a named integer of the form &ldquo;<code>c(as_one=.)</code>&rdquo;, parallelisation is over the different samples for each parameter value (and the seed of the random number generator is not controlled in a parallel context). For any other explicit name (e.g., <code>nb_cores=c(foo=7)</code>), or if <code>nRealizations</code> is a named integer of the form &ldquo;<code>c(as_one=.)</code>&rdquo;, parallelisation is over the parameter values (the rows of <code>par.grid</code>). In all cases, the progress bar is over parameter values. See Details in <code><a href="#topic+Infusion.options">Infusion.options</a></code> for the subtle way these different cases are distinguished in the progress bar.
</p>
<p>Using a FORK cluster with <code>nRealizations</code>&gt;1 is warned as unreliable: in particular, anyone trying this combination should check whether other desired controls, such as random generator seed, or progress bar are effective. 
</p>


<h3>Value</h3>

<p>If <code>nRealizations</code>&gt;1L, the return value is an object of class <code>EDFlist</code>, which is a list-with-attributes of matrices-with-attribute. Each matrix contains a simulated distribution of summary statistics for given parameters, and the <code>"par"</code> attribute is a 1-row data.frame of parameters. If <code>Simulate</code> is used, this must give all the parameters to be estimated; otherwise it must at least include all variable parameters in this <b>or later</b> simulations to be appended to the simulation list. 
</p>
<p>The value has the following attributes: <code>LOWER</code> and <code>UPPER</code> which are each a vector of per-parameter minima and maxima deduced from any <code>newsimuls</code> argument, and optionally any of the arguments <code>Simulate, control.Simulate, packages, env, par.grid</code> and  <code>simulations</code> (all corresponding to input arguments when provided, except that the actual <code>Simulate</code> function is returned even if it was input as a name).
</p>
<p>If <code>nRealizations</code>=1 <code>add_reftable</code> is called: see its distinct return value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Examples using init_grid and add_simulation, for primitive workflow
### Use init_reftable and add_reftable for the up-to-date workflow

# example of building a list of simulations from scratch:
myrnorm &lt;- function(mu,s2,sample.size) {
  s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
  return(c(mean=mean(s),var=var(s)))
}
set.seed(123)
onedistrib &lt;- t(replicate(100,myrnorm(1,1,10))) # toy example of simulated distribution
attr(onedistrib,"par") &lt;- c(mu=1,sigma=1,sample.size=10) ## important!
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         newsimuls=list("example"=onedistrib))

# standard use: smulation over a grid of parameter values
parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.2,sample.size=40),
                   upper=c(mu=5.2,s2=3,sample.size=40))
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         par.grid = parsp[1:7,])
                         
## Not run:  # example continued: parallel versions of the same
# Slow computations, notably because cluster setup is slow.

#    ... parallel over replicates, serial over par.grid rows
# =&gt; cl_seed has no effect and can be ignored
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         par.grid = parsp[1:7,], nb_cores=7)
#                         
#    ... parallel over 'par.grid' rows =&gt; cl_seed is effective
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         cl_seed=123, # for repeatable results
                         par.grid = parsp[1:7,], nb_cores=c(foo=7))

## End(Not run)
                     
####### Example where a single 'Simulate' returns all replicates:

myrnorm_tab &lt;- function(mu,s2,sample.size, nsim) {
  ## By default, Infusion.getOption('nRealizations') would fail on nodes!
  replicate(nsim, 
            myrnorm(mu=mu,s2=s2,sample.size=sample.size)) 
}

parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.2,sample.size=40),
                   upper=c(mu=5.2,s2=3,sample.size=40))

# 'as_one' syntax for 'Simulate' function returning a simulation table: 
simuls &lt;- add_simulation(NULL, Simulate="myrnorm_tab",
              nRealizations=c(as_one=500),
              nsim=500, # myrnorm_tab() argument, part of the 'dots'
              parsTable=parsp)

## Not run:  # example continued: parallel versions of the same.
# Slow cluster setup again
simuls &lt;- add_simulation(NULL,Simulate="myrnorm_tab", parsTable=parsp,
              nb_cores=7L,
              nRealizations=c(as_one=500),
              nsim=500, # myrnorm_tab() argument again
              cl_seed=123, # for repeatable results
              # need to export other variables used by *myrnorm_tab* to the nodes:
              env=list2env(list(myrnorm=myrnorm)))

## End(Not run)

## see main documentation page for the package for other typical usage
</code></pre>

<hr>
<h2 id='check_raw_stats'>
Check linear dependencies among raw summary statistics
</h2><span id='topic+check_raw_stats'></span>

<h3>Description</h3>

<p>A convenient wrapper function for <code>caret::findLinearCombos</code>, allowing to detect linear dependencies among the statistics, 
and optionally to remove variables that induce them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_raw_stats(x, statNames, remove = FALSE, verbose = interactive())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_raw_stats_+3A_x">x</code></td>
<td>
<p>data frame (particularly inheriting from class <code>"reftable"</code>, i.e. a reference table of simulations); or possibly a matrix with column names</p>
</td></tr>
<tr><td><code id="check_raw_stats_+3A_statnames">statNames</code></td>
<td>

<p>Character vector: variables among which dependencies are sought. Must belong column names of <code>x</code>. For a <code>reftable</code>, this argument is optional and by default, all raw statistic are included. For other classes of input, this argument is required. 
</p>
</td></tr>
<tr><td><code id="check_raw_stats_+3A_remove">remove</code></td>
<td>
<p>Boolean: whether to return <code>x</code> with &ldquo;offending&rdquo; columns removed, or other information.</p>
</td></tr>
<tr><td><code id="check_raw_stats_+3A_verbose">verbose</code></td>
<td>
<p>Boolean: whether to display some messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return type depends on the availability of the <span class="pkg">caret</span> package, and on the <code>remove</code> argument, as follows. if <code>remove=TRUE</code>, an object of the same class as <code>x</code> is returned (with redundant columns removed). If <code>remove=FALSE</code>, either the <span class="pkg">caret</span> package is available, in which case a list is returned with the same structure as the return value of  <code>caret::findLinearCombos</code> but with column indices replaced by column names; or a message pointing that <span class="pkg">caret</span> is not available is returned (and another is printed, only once per session).
</p>

<hr>
<h2 id='confint.SLik'>
Compute confidence intervals by (profile) summary likelihood 
</h2><span id='topic+confint.SLik'></span><span id='topic+confint.SLik_j'></span><span id='topic+confint.SLikp'></span><span id='topic+confint'></span><span id='topic+allCIs'></span>

<h3>Description</h3>

<p><code>confint</code> takes an <code>SLik</code> object (as produced by <code><a href="#topic+MSL">MSL</a></code>) and deduces confidence bounds for each parameter, using a (profile, if relevant) likelihood ratio method, and optionally a bootstrap method. 
</p>
<p><code>allCIs</code> calls <code>confint</code> for all fitted parameters and re-structure the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allCIs(object, level=0.95, verbose=TRUE, ...)
## S3 method for class 'SLik_j'
confint(object, parm, level=0.95, verbose=interactive(), fixed=NULL,
                         which=c(TRUE,TRUE), nsim=0L, reset=TRUE, 
                         cluster_args=NULL, nb_cores=NULL, type="perc",...)
## S3 method for class 'SLik'
confint(object, parm, level=0.95, verbose=interactive(), fixed=NULL, 
                       which=c(TRUE,TRUE), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.SLik_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_parm">parm</code></td>
<td>

<p>The parameter which confidence bounds are to be computed
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_level">level</code></td>
<td>

<p>The desired coverage of the interval
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_fixed">fixed</code></td>
<td>
<p>When this is <code>NULL</code> the computed interval is a profile confidence interval over all parameters excluding <code>parm</code>.
<code>fixed</code> allows one to set fixed values to some of these parameters.  
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_which">which</code></td>
<td>

<p>A pair of booleans, controlling whether to compute respectively the lower and the upper CI bounds.
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_nsim">nsim</code></td>
<td>

<p>Integer: number of bootstrap replicates. If &gt;1, bootstrap interval(s) are computed as further controlled by the  <code>type</code> argument. Note that this will be ignored if the bootstrap has previously been run and <code>reset=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_reset">reset</code></td>
<td>

<p>Boolean: Whether to use any previously computed distribution (see Details) or not.
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_cluster_args">cluster_args</code>, <code id="confint.SLik_+3A_nb_cores">nb_cores</code></td>
<td>

<p>Passed to parallelization wrappers such as <code><a href="spaMM.html#topic+dopar">dopar</a></code>.
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_type">type</code></td>
<td>

<p>Character vector, ignored if <code>nsim</code> = 0: bootstrap CI type(s). Possible types are <code>"norm", "basic",  "perc"</code> (as handled by <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>), and <code>"Bartlett"</code> (where the interval bounds are defined by threshold values of the likelihood ratio statistics modified using a Bartlett correction).
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods. <code>allCIs</code> passes them to <code>confint</code>, so that, e.g.,  <code>nsim</code> can be passed through the .... <code>confint</code> passes them to parallelization wrappers such as <code><a href="spaMM.html#topic+dopar">dopar</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>confint.SLik_j</code> results are stored in the <code>object</code> (until the next <code>refine</code>), including the result of the bootstrap simulations if it was performed. This distribution may then be reused by a next call to <code>confint</code> for the same <code>parm</code> if <code>reset=FALSE</code>. The default is however to recompute the distribution (<code>reset=TRUE</code>).
</p>
<p>Bootstrap CIs computed using <code>boot.ci</code> are stored as distinct elements of the return list (see Value). However, for the <code>"Bartlett"</code> type of CI, the <code>interval</code> element of the return value is modified. 
</p>


<h3>Value</h3>

<p>Both functions modify the fit <code>object</code> as a side effect (see Details).
</p>
<p><code>confint</code> returns a list with sublists for each parameter, each sublist containing: the bounds of the one-dimensional confidence interval (element <code>interval</code>, a vector); the parameter point for the lower bound (element <code>lowerpar</code>, a vector including all parameters fitted in the <code>SLik</code> object), the full parameter point for the upper bound (element <code>upperpar</code>, formatted as <code>lowerpar</code>), and optionally if a bootstrap was run, the return value of a <code>boot::boot.ci</code> call (element <code>bootCI</code>) and the simulated distribution of parameter estimates (element <code>booreps</code>, 1-column matrix).
</p>
<p><code>allCIs</code> returns invisibly a list with elements including <code>CIs</code> (itself a list of <code>confint</code> results), <code>bounds</code> (a matrix made of bound points for all parameters), and some other elements.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLRT">SLRT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;3) {
#### Provide fit for minimal toy example: 
myrnorm &lt;- function(mu,s2,sample.size) {
  s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
  return(c(mean=mean(s),var=var(s)))
} # simulate means and variances of normal samples of size 'sample.size'
set.seed(123)
# simulated data with stands for the actual data to be analyzed:  
ssize &lt;- 40L
(Sobs &lt;- myrnorm(mu=4,s2=1,sample.size=ssize) )
## Construct initial reference table:
# Uniform sampling in parameter space:
parsp &lt;- init_reftable(lower=c(mu=2.8, s2=0.4, sample.size=ssize), 
                         upper=c(mu=5.2, s2=2.4, sample.size=ssize))
# Build simulation table:
# set.seed(456) 
simuls &lt;- add_reftable(Simulate="myrnorm", parsTable=parsp)

# Infer surface:
densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs)
# Usual workflow using inferred surface:
slik_1 &lt;- MSL(densv) ## find the maximum of the log-likelihood surface

####  Confidence interval calculations:
(ci1 &lt;- confint(slik_1,"mu")) # basic likelihood ratio interval
(ci2 &lt;- confint(slik_1,"mu", nsim=199L)) # Percentile interval added
(ci3 &lt;- confint(slik_1,"mu", nsim=199L, type="Bartlett")) # 'interval' corrected

# Previous bootstrap computations are stored in the fit object,  
# and recycled if reset=FALSE *and* nsim &gt; 0:
(ci4 &lt;- confint(slik_1,"mu", nsim=199L, type= "Bartlett", reset=FALSE)) # = ci3
(ci5 &lt;- confint(slik_1,"mu", nsim=199L, type= "perc", reset=FALSE)) # = ci2
}
</code></pre>

<hr>
<h2 id='constr_crits'>
Specificying arbitrary constraints on parameters
</h2><span id='topic+constr_crits'></span><span id='topic+constraints'></span>

<h3>Description</h3>

<p><code>constr_crits</code> is an argument of <code><a href="#topic+init_reftable">init_reftable</a></code>, <code><a href="#topic+add_reftable">add_reftable</a></code>,  <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>, and <code>profile.SLik_j</code>,
allowing to specify constraints on parameters, beyond the ones defined by the ranges over each parameter.  Depending on the function it controls, this argument will affect the generation of parameter points or the maximization of the summary-likelihood. The <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> return value contains the <code>constr_crits</code> information it was given, allowing subsequent <code><a href="#topic+refine">refine</a></code> calls to take constraints into account. 
</p>
<p>The constraints are represented as a mathematical expression for a vector of quantities that should all be negative when the constraints are satisfied. For example, to incorporate the constraint <code>t1 &lt; t3 &amp;&amp; t2 &lt; t3</code> between three time parameters <code>t1</code>, <code>t2</code> and <code>t3</code> present in the reference table, one can use<br />
<code>constr_crits = quote({ c(t1-t3, t2-t3) })</code>.<br />
See Examples in <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> for a nice artificial toy example.
</p>
<p>For computational efficiency, it may be better to avoid using this feature when the constraints can be represented as box constraints (i.e., independent ranges for each parameter) by some intuitive reparametrization.
</p>

<hr>
<h2 id='declare_latent'>
Modeling and predicting latent variables
</h2><span id='topic+declare_latent'></span><span id='topic+pplatent'></span><span id='topic+latint'></span>

<h3>Description</h3>

<p>Latent variables are unobserved variables which, for given model parameters, are random. Since they are unobserved, they cannot appear in data nor used to infer parameters. However, they can be predicted if their joint distribution with the data is learned from the reference table. Thus for inference about latent variables, these should be returned along summary statistics by the simulation function generating the samples for the reference table, but they should be declared as such so that later inference steps can distinguish them from both parameters and summary statistics. The <code>declare_latent</code> function is used for that purpose. 
</p>
<p>The <code>pplatent</code> function can be used to point-predict latent values, by their inferred mean or median given the (projected) summary statistics and fitted parameter values. 
</p>
<p>The <code>latint</code> function provides prediction intervals for the latent variable, accounting for uncertainty in parameter estimates, using a bootstrap method (see Details).     
</p>


<h3>Usage</h3>

<pre><code class='language-R'>declare_latent(reftable, latentVars)
pplatent(object, type="mean",
         newDP=NULL,
         sumstats= t(get_from(object,"stat.obs")), 
         pars=t(object$MSL$MSLE), 
         size=1000L, ...)
latint(object, nsim=199L, levels=c(0.025,0.975), 
       sumstats= t(get_from(object,"stat.obs")), 
       Simulate, control.Simulate=get_from(object,"control.Simulate"), 
       bootSamples=NULL,
       ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="declare_latent_+3A_reftable">reftable</code></td>
<td>

<p>A reference table of simulation as returned by <code><a href="#topic+add_reftable">add_reftable</a></code>
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_latentvars">latentVars</code></td>
<td>

<p>A vector of names of variables to be treated as latent variables.
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_object">object</code></td>
<td>

<p>An object of class <code>SLik_j</code>.
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_type">type</code></td>
<td>

<p>Character: the only handled non-default value is <code>"median"</code>.
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_newdp">newDP</code>, <code id="declare_latent_+3A_sumstats">sumstats</code>, <code id="declare_latent_+3A_pars">pars</code></td>
<td>

<p>Matrices of data and/or (<em>projected</em>) summary statistics, with one column for each variable. <code>newDP</code> should contain both, and if NULL, is constructed from the next two arguments, <code>sumstats</code> holding statistics and <code>pars</code> holding parameters.
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_levels">levels</code></td>
<td>

<p>Numeric vector: one-sided confidence levels (cumulative probabilities at which quantiles of the predictive distribution will be returned).
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_nsim">nsim</code></td>
<td>

<p>Integer: number of bootstrap replicates.
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_size">size</code></td>
<td>

<p>Integer: number of draws for estimating the median.
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_simulate">Simulate</code></td>
<td>

<p>May be used to provide the simulation function if it is not stored in the <code>object</code>; usage is then as for <code><a href="#topic+add_reftable">add_reftable</a></code>. If it is set to NULL, bootstrap samples will instead be drawn from the gaussian mixture fit, but this shoudl be avoided for good performance. When the argument is missing (default), the <code>Simulate</code> information is sought in the <code>object</code>, and if absent, the gaussian mixture fit is used with a warning. 
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_control.simulate">control.Simulate</code></td>
<td>

<p>A list of arguments of the <code>Simulate</code> function (see<code><a href="#topic+add_simulation">add_simulation</a></code>). The default value should be used unless you understand enough of its structure to modify it wisely (e.g., it may contain the path of an executable used to perform the fit on one machine and a different path may be specified to compute the prediction interval on another machine).  
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_bootsamples">bootSamples</code></td>
<td>

<p>A data frame. The bootstrap samples may be provided by this argument, otherwise they will be automatically simulated by the function provided by the <code>Simulate</code> argument.  The boot samples may for example be obtained by calling <code>simulate(</code>&lt;<em>Slik_j object</em>&gt;<code>, SGP=TRUE)</code>. 
</p>
</td></tr>
<tr><td><code id="declare_latent_+3A_...">...</code></td>
<td>

<p>For <code>pplatent</code>: Not currently used. For <code>latint</code>: may be used to pass arguments <code>verbose</code>, <code>nb_cores</code>, <code>packages</code>, <code>env</code>, <code>control.Simulate</code>, <code>cluster_args</code>, and <code>cl_seed</code>, with usage as described for <code><a href="#topic+add_reftable">add_reftable</a></code>, to the bootstrap sample simulation step. Parallelisation controls will also be used for the other steps of the bootstrap procedure.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>latint</code> function aims to provide intervals for the latent variable <code class="reqn">V</code>, with controlled coverage for given parameter values. The parametric bootstrap method of Lawless &amp; Fredette (2005) can be adapted to the present problem. First, new data <code class="reqn">D^*</code> and new latent values <code class="reqn">V^*</code> are jointly simulated, given the summary-ML estimates (this uses the sample-generating process simulator, but these simulations are not added to the reference table). Second, their original method requires the evaluation for each new <code class="reqn">(D^*,V^*)</code> of <code class="reqn">F_V(V=V^*|D^*;\theta(D^*))</code>, the value of the cumulative distribution function <code class="reqn">F_V</code> of <code class="reqn">V</code> evaluated at <code class="reqn">V=V^*</code> values, given <code class="reqn">D^*</code> and given new parameter estimates <code class="reqn">\theta(D^*)</code>. 
It also requires the quantile function of <code class="reqn">V</code> for the original data and parameter estimates. <code>latint</code> uses the fit of the multivariate gaussian mixture model to the reference table, stored in the fit object, for fast parameter refitting and for fast estimation of these functions on each bootstrap sample <code class="reqn">(D^*,V^*)</code>. 
</p>
<p><code>latint(., levels=c(0.5))</code> will return the median of the predictive distribution, 
conceptually distinct from the plug-in prediction by <code>pplatent(slik_j, type="median")</code>   
</p>
<p>Quantile computations in <code>pplatent</code> and <code>latint</code> are approximate and might be modified in some future version, but were sufficient to obtain reasonable results in simulations. 
</p>


<h3>Value</h3>

<p><code>declare_latent</code> returns the input <code>reftable</code> with modified attributes. <code>pplatent</code> returns a vector of predicted latent values.
</p>
<p><code>pplatent</code> returns a single numeric value or a vector.
<code>latint</code> returns a list of matrices. Each matrix has with one column per element of <code>levels</code>, and one row per row of <code>sumstats</code>. There is one such matrix for each latent variable.  
</p>


<h3>References</h3>

<p>Lawless J. F., Fredette M. (2005) Frequentist prediction intervals and predictive distributions. Biometrika 92: 529–542, &lt;doi:10.1093/biomet/92.3.529&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  ##### A toy example motivated by some inference problem for genomic data #####
  # A model with three parameters logNe, Vs and Es is fitted.
  # Data from 100 loci are here summarized by three genome-wide summary statistics 
  # (slogNe, sVs and sEs), and one locus-specific statistic that will provide 
  # information about a locus-specific latent variable.
  
  ## Simulation function 
  genomloc &lt;- function(logNe=parvec["logNe"],Es=parvec["Es"],Vs=parvec["Vs"], 
                       latent=TRUE, # returns the latent value by default
                       parvec) {
    slogNe &lt;- rnorm(1,logNe, sd=0.3)
    genom_s &lt;- rgamma(99, shape=Es/Vs,scale=Vs) # all loci except the focal one
    sEs &lt;- mean(genom_s)
    sVs &lt;- var(genom_s)
    latentv &lt;- rgamma(1, shape=Es/Vs,scale=Vs) # locus-specific latent variable to predict
    sloc &lt;- rnorm(1, mean=latentv-sEs,sd=latentv/3) # locus-specific statistic
    resu &lt;- list(slogNe=slogNe,sEs=sEs,sVs=sVs, sloc=sloc)
    if (latent) resu$latentv &lt;- latentv
    unlist(resu)
  } 
  #
  ## simulated data, standing for the actual data to be analyzed:  
  set.seed(123)
  Sobs &lt;- genomloc(logNe=4,Es=0.05, Vs=0.1,latent=FALSE) ## no latent value
  #
  workflow_design &lt;- get_workflow_design(npar=3L, n_proj_stats=4L, n_latent=1L)
  parsp &lt;- init_reftable(lower=c(logNe=2,Es=0.001,Vs=0.001), 
                         upper=c(logNe=6,Es=0.2,Vs=0.2),
                         nUnique=workflow_design$init_reft_size)
  simuls &lt;- add_reftable(Simulate=genomloc, parsTable=parsp)
  
  simuls &lt;- declare_latent(simuls,"latentv") 

  ## Projections are not necessary here since the number of statistics is minimal,
  # but will be discussed later.
  { ############ Without projections
    { ## Usual workflow for estimation: 
      densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs)
      slik_j &lt;- MSL(densv) ## find the maximum of the log-likelihood surface
      slik_j &lt;- refine(slik_j,maxit=2,update_projectors=TRUE)
      # plot1Dprof(slik_j) ## 1D profiles show parameter inference is OK
    }
    { ## inference about latent values:
      pplatent(slik_j)
      pplatent(slik_j, type="median")
      latint(slik_j, nsim=999, levels=c(0.025,0.5,0.975))
    }
    { ## Assessing prediction of latent variable:
      # Builds testing set:
      test_simuls &lt;- t(replicate(1000, genomloc(logNe=4,Es=0.05, Vs=0.1)))
      test_data &lt;- test_simuls[,-5]
      # Point prediction:
      pred &lt;- pplatent(slik_j, sumstats = test_data)
      
      plot(test_simuls[,"latentv"], pred); abline(0,1) # prediction vs. true latent values
    }
  }
  
  { ########## Beyond standard use of projections for estimation of parameter values, 
    # projections can also be used when several individual-level statistics inform about 
    # the latent variable, to reduce them to a single summary statistic.
    # Projection will then be needed at the prediction step too.
    
    { # projection with latent variable as response:
      platent &lt;- (project("latentv", data=simuls, stats=c("slogNe","sEs","sVs","sloc")))
      # (This example only serves to show the syntax since no dimention reduction occurs)
      
      dprojectors &lt;- list(SLOC=platent,slogNe=NULL,sEs=NULL, sVs=NULL)
      
      # =&gt; As soon as one projection is used, The 'projectors' argument must include 
      # all projectors used for the inference, whether for parameters or for latent variables. 
      # NULL projectors should then be declared for raw statistics retained 
      # in the projected reference table.
      
      # Apply projections on simulated statistics and 'data':
      projSimuls &lt;- project(simuls,projectors=dprojectors,verbose=FALSE)
      projSobs &lt;- project(Sobs,projectors=dprojectors)
    }
    
    { ## Estimation: 
      ddensv &lt;- infer_SLik_joint(projSimuls,stat.obs=projSobs)
      dslik_j &lt;- MSL(ddensv) ## find the maximum of the log-likelihood surface
      dslik_j &lt;- refine(dslik_j,maxit=2,update_projectors=TRUE)
      # plot1Dprof(dslik_j)
    }
    
    { ## Assessing prediction of latent variable: do not forget to project!
      
      test_simuls &lt;- t(replicate(1000, genomloc(logNe=4,Es=0.05, Vs=0.1)))
      test_data &lt;- test_simuls[,-5] # removing column of latent variable
      ptest_data &lt;- project(test_data,projectors=dprojectors,verbose=FALSE) # Here!
      pred &lt;- pplatent(dslik_j, sumstats = ptest_data)
      
      plot(test_simuls[,"latentv"], pred); abline(0,1)
    }
  }


## End(Not run)
</code></pre>

<hr>
<h2 id='densv'>
Saved computations of inferred log-likelihoods
</h2><span id='topic+densv'></span><span id='topic+densb'></span><span id='topic+saved_seed'></span>

<h3>Description</h3>

<p>These are saved results from toy examples used in other documentation page for the package. They give estimates by simulation of log-likelihoods of the <code>(mu,s2)</code> parameters of a Gaussian distribution for a given sample of size 20 with mean 4.1416238 and (bias-corrected) variance 0.9460778. <code>densv</code> is based on the sample mean and sample variance as summary statistics, and <code>densb</code> on more contrived summary statistics.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("densv")
data("densb")
</code></pre>


<h3>Format</h3>

<p>Data frames (with additional attributes) with observations on the following 5 variables.
</p>

<dl>
<dt><code>mu</code></dt><dd><p>a numeric vector; mean parameter of simulated Gaussian samples</p>
</dd>
<dt><code>s2</code></dt><dd><p>a numeric vector; variance parameter of simulated Gaussian samples</p>
</dd>
<dt><code>sample.size</code></dt><dd><p>a numeric vector; size of simulated Gaussian samples</p>
</dd>
<dt><code>logL</code></dt><dd><p>a numeric vector; log probability density of a given statistic vector inferred from simulated values for the given parameters</p>
</dd>
<dt><code>isValid</code></dt><dd><p>a boolean vector. See <code><a href="#topic+infer_logLs">infer_logLs</a></code> for its meaning.</p>
</dd> 
</dl>

<p>Both data frames are return objects of a call to <code><a href="#topic+infer_logLs">infer_logLs</a></code>, and as such they includes attributes providing information about the parameter names and statistics names (not detailed here).
</p>


<h3>See Also</h3>

<p>See step (3) of the workflow in the Example on the main <code><a href="#topic+Infusion">Infusion</a></code> documentation page, showing how <code>densv</code> was produced, and the Example in <code><a href="#topic+project">project</a></code> showing how <code>densb</code> was produced.
</p>

<hr>
<h2 id='dMixmod'>
Internal S4 classes. 
</h2><span id='topic+dMixmod'></span><span id='topic+class+3AdMixmod'></span><span id='topic+dMixmod-class'></span><span id='topic+NULLorChar'></span><span id='topic+class+3ANULLorChar'></span><span id='topic+NULLorChar-class'></span><span id='topic+NULLorNum'></span><span id='topic+class+3ANULLorNum'></span><span id='topic+NULLorNum-class'></span><span id='topic+plot.dMixmod'></span>

<h3>Description</h3>

<p>The objects or methods referenced here are not to be called by the user, or are waiting for documentation to be written.  
</p>
<p><code>dMixmod</code> is an S4 class describing some distributions that extend the multivariate gaussian mixture models (MGMM) by possibly involving discrete probability masses for some variables and gaussian mixtures for other variables conditional on such discrete events. In terms of the represented probability models, and of its slots, is effectively extends the <code>MixmodResults</code> class from the <code>Rmixmod</code> package. But it does not formally extends this class in terms of OOP programming. It should not be considered as part of the programming interface, and may be subject to backward-incompatible modifications without notice. In the current implementation it cannot represent general mixtures of discrete probabilities and MGMMs, and may yield correct results only for the degenerate case of pure MGMMs or when inference can be based on the conditional density of continuous variables conditional on the (joint-, if relevant) discrete event observed in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'># dMixmod: Don't try to use it! It's for programming only.
</code></pre>


<h3>Value</h3>

<p>A <code>dMixmod</code> object has the same slots as a <code>MixmodResults</code> object, plus additional ones: <code>@freq</code> is the frequency of the conditioning event for the gaussian mixture model. In the <code>Infusion</code> code, this event is defined jointly by the &ldquo;observed&rdquo; summary statistics and the reference simulation table: a probability mass for specific values <b>v</b> is identified from the simulated distribution of summary statistics in the reference table, and <code>freq</code> is an estimate of the probability mass if the summary statistics match <b>v</b>, or the converse probability if they do not match.
</p>


<h3>Note</h3>

<p>Use <code>str(attributes(.))</code> to see the slots of a <code>dMixmod</code> object if <code>str(.)</code> does not work.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The dMixmod object can be used internally to handle repeated and boundary values 
# of summary statistics. The user has to add an attribute to the observations,
# as explained in help("boundaries-attribute"):
Sobs &lt;- c(mean=4.321, se=0.987) # hypothetical observation
attr(Sobs,"boundaries") &lt;- c(someSummStat=-1)  
</code></pre>

<hr>
<h2 id='example_raw'>Workflow for primitive method, without projections</h2><span id='topic+example_raw'></span>

<h3>Description</h3>

<p>Example of the workflow with <code>add_simulation</code>), implementing the method described in the original publication 
(Rousset et al. 2017 &lt;doi:10.1111/1755-0998.12627&gt;).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The following example illustrates the workflow.
## However, most steps run longer than accepted by the CRAN checks,
## So by default they will not run.
##
## (1) The user must provide the function for simulation of summary statistics
myrnorm &lt;- function(mu,s2,sample.size) {
 s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
 return(c(mean=mean(s),var=var(s)))
} # simulate means and variances of normal samples of size 'sample.size'
#
## simulated data:  
set.seed(123)
Sobs &lt;- myrnorm(mu=4,s2=1,sample.size=40) ## stands for the actual data to be analyzed
#
## (2) Generate, and simulate distributions for, 
##        an irregular grid of parameter values, with some replicates
if (Infusion.getOption("example_maxtime")&gt;40) {
  parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.2,sample.size=40),
                     upper=c(mu=5.2,s2=3,sample.size=40))
  simuls &lt;- add_simulation(NULL,Simulate="myrnorm", parsTable=parsp)
  
  ## (3) infer logL(pars,stat.obs) for each simulated 'pars'
  # Relatively slow, hence saved as data 'densv'
  densv &lt;- infer_logLs(simuls,stat.obs=Sobs)
} else {
  data(densv)
  .Random.seed &lt;- saved_seed
}
#
## (4) infer a log-likelihood surface and its maximum;
##       plot and extract various information. 
if (Infusion.getOption("example_maxtime")&gt;11) {
 slik &lt;- infer_surface(densv)
 slik &lt;- MSL(slik) ## find the maximum of the log-likelihood surface
 plot(slik)
 profile(slik,c(mu=4)) ## profile summary logL for given parameter value
 confint(slik,"mu") ## compute confidence interval for given parameter
 plot1Dprof(slik,pars="s2",gridSteps=40) ## 1D profile
}
#
## (5) ## refine iteratively
if (Infusion.getOption("example_maxtime")&gt;39) {
 slik &lt;- refine(slik) 
}
</code></pre>

<hr>
<h2 id='example_raw_proj'>Workflow for primitive method, with projections</h2><span id='topic+example_raw_proj'></span>

<h3>Description</h3>

<p>Example of the workflow with <code>add_simulation</code>), implementing the method described in the original publication 
(Rousset et al. 2017 &lt;doi:10.1111/1755-0998.12627&gt;), modified to use projectors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;117) {
## Normal(mu,sd) model, with inefficient raw summary statistics:
## To illustrate that case we transform normal random deviates rnorm(,mu,sd)
## so that the mean of transformed sample is not sufficient for mu,
## and the variance of transformed sample is not sufficient for sd.
blurred &lt;- function(mu,s2,sample.size) {
  s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
  s &lt;- exp(s/4)
  return(c(mean=mean(s),var=var(s)))
}

set.seed(123)
dSobs &lt;- blurred(mu=4,s2=1,sample.size=20) ## stands for the actual data to be analyzed

## Sampling design as in canonical example 
parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.4,sample.size=20),
                      upper=c(mu=5.2,s2=2.4,sample.size=20))
# simulate distributions
dsimuls &lt;- add_simulation(,Simulate="blurred", parsTable=parsp) 

## Use projection to construct better summary statistics for each each parameter 
mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls)
s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls)

## apply projections on simulated statistics
corrSobs &lt;- project(dSobs,projectors=list("MEAN"=mufit,"VAR"=s2fit))
corrSimuls &lt;- project(dsimuls,projectors=list("MEAN"=mufit,"VAR"=s2fit))

## Analyze 'projected' data as any data (cf canonical example)
densb &lt;- infer_logLs(corrSimuls,stat.obs=corrSobs) 
} else data(densb)
#########
if (Infusion.getOption("example_maxtime")&gt;10) {
slik &lt;- infer_surface(densb) ## infer a log-likelihood surface
slik &lt;- MSL(slik) ## find the maximum of the log-likelihood surface
}
if (Infusion.getOption("example_maxtime")&gt;500) {
slik &lt;- refine(slik,10, update_projectors=TRUE) ## refine iteratively
}
</code></pre>

<hr>
<h2 id='example_reftable'>Workflow for method with reference table</h2><span id='topic+example_reftable'></span>

<h3>Description</h3>

<p>Examples of workflow with a reference table produced by <code>add_reftable</code>, to be preferred the primitive method described in the first publication of <span class="pkg">Infusion</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;56) {

  ## Normal(mu,sd) model, with inefficient raw summary statistics:
  ## To illustrate that case we transform normal random deviates rnorm(,mu,sd)
  ## so that the mean of transformed sample is not sufficient for mu,
  ## and the variance of transformed sample is not sufficient for sd.
  blurred &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    s &lt;- exp(s/4)
    return(c(mean=mean(s),var=var(s)))
  }
  
  ## simulated data which stands for the actual data to be analyzed:  
  set.seed(123)
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40)
  
  ## Construct initial reference table:
  parsp_j &lt;- init_reftable(lower=c(mu=2.5, s2=0.25, sample.size=40), 
                           upper=c(mu=5.2, s2=2.4, sample.size=40))
  dsimuls &lt;- add_reftable(,Simulate="blurred", parsTable=parsp_j,verbose=FALSE)

  #- When no 'Simulate' function is provided, 
  #- but only a data.frame 'toydf' of simulations,
  #- a formal reference table can be produced by  
  # dsimuls &lt;- structure(toydf, LOWER=c(mu=2,s2=0,sample.size=40))
  # dsimuls &lt;- add_reftable(dsimuls)
  #- where the 'LOWER' attribute tells 
  #- the parameters apart from the summary statistics.
  
  ## Construct projections
  mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls,verbose=FALSE)
  s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls,verbose=FALSE)
  dprojectors &lt;- list(MEAN=mufit,VAR=s2fit)
  
  ## Apply projections on simulated statistics and 'data':
  dprojSimuls &lt;- project(dsimuls,projectors=dprojectors,verbose=FALSE)
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  
  ## Summary-likelihood inference:
  # Infer log-likelihood surface
  slik_j &lt;- infer_SLik_joint(dprojSimuls,stat.obs=dprojSobs,verbose=TRUE)
  # Find maximum, confidence intervals...
  slik_j &lt;- MSL(slik_j)
  
  # Convenience function for plotting projections...
  plot_proj(slik_j)
  plot_importance(slik_j, parm="mu")
  
  # ... and for computing likelihoods for new parameters and/or data:
  summLik(slik_j, parm=slik_j$MSL$MSLE+0.1)
  
  ## refine estimates iteratively
  maxrefines &lt;- 2L
  # See get_workflow_design() for a suggested number of refine() calls, 
  # typically more than the 2 refine calls shown in this small example.
  for(it in 1:maxrefines) slik_j &lt;- 
    refine(slik_j, eval_RMSEs=it==maxrefines, CIs=it==maxrefines)
  ##

  if (Infusion.getOption("example_maxtime")&gt;99) { # Post-fit procedures,
    #                                   all with distinct documentation: 
  
    plot(slik_j)
    profile(slik_j,c(mu=4)) ## profile summary logL for given parameter value
    confint(slik_j,"mu") ## compute 1D confidence interval for given parameter
    plot1Dprof(slik_j,pars="s2",gridSteps=40) ## 1D profile
    summary(slik_j) # or print()
    logLik(slik_j)
    
    SLRT(slik_j, h0=slik_j$MSL$MSLE+0.1, nsim = 100L) # LRT
    SLRT(slik_j, h0=slik_j$MSL$MSLE[1]+0.1, nsim = 100L) # profile LRT
    
    goftest(slik_j) # goodness of fit test
    
    # Low-level predict() method (rarely directly used, but documented)
    predict(slik_j, newdata = slik_j$MSL$MSLE)   # the 'data' are here parameters!

    # 'ranger' projections can take a lot of memory. One can reduce them by... 
    # deforest_projectors(slik_j)
    # ...before...
    # save(slik_j, file="slik_j")
    # They will be rebuilt on the fly if needed for further iterations.
  }
}
</code></pre>

<hr>
<h2 id='extractors'>
Summary, print and logLik methods for Infusion results.
</h2><span id='topic+extractors'></span><span id='topic+summary'></span><span id='topic+print'></span><span id='topic+logLik'></span><span id='topic+summary.logLs'></span><span id='topic+summary.SLik'></span><span id='topic+summary.SLik_j'></span><span id='topic+summary.SLikp'></span><span id='topic+print.SLik'></span><span id='topic+print.SLik_j'></span><span id='topic+print.logLs'></span><span id='topic+print.SLikp'></span><span id='topic+logLik.SLik'></span><span id='topic+logLik.SLik_j'></span>

<h3>Description</h3>

<p><code>summary</code> prints information about the fit.
<code>print</code> is an alias for <code>summary</code>.
<code>logLik</code> extracts the log-likelihood (exact or approximated). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
summary(object, ...)
## S3 method for class 'SLik'
print(x, ...)
## S3 method for class 'SLik'
logLik(object, ...)
# and identical usage for 'SLik_j' objects
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extractors_+3A_object">object</code>, <code id="extractors_+3A_x">x</code></td>
<td>

<p>An object of class <code>SLik</code> or  <code>SLik_j</code>;
</p>
</td></tr>
<tr><td><code id="extractors_+3A_...">...</code></td>
<td>
<p>  further arguments passed to or from other methods (currently without any specific effect). </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>logLik</code> returns the inferred likelihood maximum, with attribute <code>RMSE</code> giving its root means square error of estimation. 
<code>summary</code> and <code>summary</code> return the object invisibly. They print details of the fits in a convenient form.
</p>


<h3>Note</h3>

<p>See workflow example in <code><a href="#topic+example_reftable">example_reftable</a></code>.</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+get_from">get_from</a></code> for a more general interface for extracting elements from Infusion results, and <code><a href="#topic+summLik">summLik</a></code> for using a fit object to evaluate the likelihood function for distinct parameter values and even distinct data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See Note
</code></pre>

<hr>
<h2 id='focal_refine'>
Refine summary likelihood profile in focal parameter values
</h2><span id='topic+focal_refine'></span>

<h3>Description</h3>

<p>This function refines an <code>SLik_j</code> object in a focused way defined by focal parameter values. It is paticularly useful to check a suspect pattern in a likelihood profile. If there is a suspect dip or peak at value &lt;somepar&gt;=&lt;somevalue&gt;, <code>focal_refine(</code>&lt;SLik_j object&gt;<code>, focal</code>=c(&lt;somepar&gt;=&lt;somevalue&gt;)<code>, size</code>=&lt;size&gt;) will define &lt;size&gt; parameter points near <code>c(</code>&lt;somepar&gt;=&lt;somevalue&gt;) and (subject to these points being in the parameter bounds of the object) simulate new samples for these parameter points and refine the object using these new simulations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focal_refine(object, focal, size, plotprof = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="focal_refine_+3A_object">object</code></td>
<td>

<p>An object of class <code>SLik_j</code>.
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_focal">focal</code></td>
<td>

<p>Parameter value(s) (as a vector of named values) 
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_size">size</code></td>
<td>

<p>Target number of points to add to the reference table
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_plotprof">plotprof</code></td>
<td>

<p>Whether to replot a likelihood profile (1D or 2D depending on the dimension of <code>focal</code>).
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code>profile.SLik_j</code> (but not including argument <code>return.optim</code>) or <code>refine</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated <code>object</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Using the slik_j object from the toy example in help("example_reftable"):

plot1Dprof(slik_j,"s2")
slik_fix &lt;- focal_refine(slik_j,focal=c(s2=2), size=100)
plot1Dprof(slik_fix,"s2")

# In that case the effect is not spectacular because 
# there is no major problem in the starting profile. 

## End(Not run)
</code></pre>

<hr>
<h2 id='get_from'>
Backward-compatible extractor from summary-likelihood objects
</h2><span id='topic+get_from'></span><span id='topic+get_from.default'></span><span id='topic+get_from.SLik'></span><span id='topic+get_from.SLik_j'></span>

<h3>Description</h3>

<p>A generic function, whose default method works for <code>list</code>, and with specific methods for objects inheriting from classes <code>SLik_j</code> and <code>SLik</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_from(object, which, ...)

## S3 methods with additional argument(s)
## S3 method for class 'SLik'
get_from(object, which, raw=FALSE, force=FALSE, ...)
## S3 method for class 'SLik_j'
get_from(object, which, raw=FALSE, force=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_from_+3A_object">object</code></td>
<td>

<p>Any object with a list structure.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_which">which</code></td>
<td>

<p>Character: identifier for the element to be extracted. See Examples for possible values.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_raw">raw</code></td>
<td>

<p>Boolean: if TRUE, <code>object[[which]]</code> is returned, without any particular check of its value. By default, <code>raw</code> is FALSE and various operations may be performed on the extracted value (see &ldquo;example&rdquo; below), including optional recomputation if <code>force</code> is TRUE.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_force">force</code></td>
<td>

<p>Boolean: if TRUE, the extracted element may be computed if it appears to be missing from the <code>object</code>. This is notably so for <code>which="RMSEs"</code> or <code>which="par_RMSEs"</code>;  in these cases, the results of the computation are further saved in the original object.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Will depend on <code>which</code>, but aims to retain a convenient format backward-compatible with version 1.4.0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logLik">logLik</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # ##### 0bserved summary statistics 
  # #  (raw data)
  #   get_from(slik, "raw_data") 
  # #  (projected data, with raw ones as attribute, if relevant)
  #   get_from(slik, which="obs") # or which="stat.obs" or "proj_data"
  # 
  # ##### Reference-table information 
  # #  (raw = unprojected):
  #   get_from(slik, "reftable_raw")
  # # : but this is NULL if no projections were performed.
  #
  # # Projected:
  #   get_from(slik, "reftable")
  # # : including all parameters, latent variables, statistics,
  # #   'cumul_iter' (the iteration in which each sample was added),
  # #   and attributes.
  #
  # ##### RMSEs
  # # On any summary-likelihood object 'slik':
  #   get_from(slik, which="par_RMSEs") # matrix
  # # despite &lt;object&gt;$par_RMSEs being an environment if 
  # #  'slik' was created by version &gt; 1.4.0, as then shown by
  #   get_from(slik, which="par_RMSEs", raw=TRUE)
  #
  # # Further, if 
  #   get_from(slik, which="par_RMSEs")
  # # returns NULL because the element is absent from the object, 
  # # then one can force its computation by 
  #   get_from(slik, which="par_RMSEs", force=TRUE)
  # # The result are saved in the 'slik' object, so running again 
  #   get_from(slik, which="par_RMSEs")
  # # will no longer return NULL.
  #
  # ##### Other, less commonly needed elements
  #   get_from(slik, "Simulate"")
  #   get_from(slik, "control.Simulate")
  #   get_from(slik, "env")
  #   get_from(slik, "packages")
  # # =&gt; for these elements, the documentation and arguments of refine.default() 
  # #    provides meaning and context where they may be used.
  #
  # Number of elements of the multivariate gaussian mixture model:
  #   get_from(slik, "nbCluster") 
</code></pre>

<hr>
<h2 id='get_LRboot'>
Summary likelihood ratio tests
</h2><span id='topic+get_LRboot'></span><span id='topic+SLRT'></span>

<h3>Description</h3>

<p><code>SLRT</code> computes likelihood ratio tests based on the summary-likelihood surface and optionally on a fast bootstrap approximation implemented in <code>get_LRboot</code> (the latter function can be called directly but is rather typically called directly through <code>SLRT</code>). When bootstrapping is used, several correction of the basic likelihood ratio test may be reported, some more speculative than others, and bootstrap confidence intervals may be returned too.
</p>
<p><code>get_LRboot</code> provides a fast approximation to bootstrap distribution of likelihood ratio statistic (and optionally, of parameter estimates).
The bootstrap distribution of the likelihood ratio (LR) statistic may be used to correct the tests based on its asymptotic chi-square distribution. However, the standard bootstrap involves resimulating the data-generating process, given the ML estimates on the original data. This function implements a fast approximation avoiding such simulation, instead drawing from the inferred distribution of (projected, if relevant) summary statistics, again given the maximum (summary-)likelihood estimates.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLRT(object, h0, nsim=0L, BGP=NULL, type="perc", 
     level=0.95, nsteps=10L, variants=NULL, ...)
get_LRboot(object, h0_pars = NULL, nsim = 100L, reset = TRUE, 
           BGP=object$MSL$MSLE, which="ecdf_2lr",  
           bootCI.args=list(type="perc", conf = 0.95), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_LRboot_+3A_object">object</code></td>
<td>

<p>an <code>SLik_j</code> object.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_h0">h0</code></td>
<td>

<p>Numeric named vector of tested parameter values.    
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_nsteps">nsteps</code></td>
<td>

<p>Integer. Any value &gt; 1 calls a profiling procedure (see Details).     
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_h0_pars">h0_pars</code></td>
<td>

<p>either <code>NULL</code> (the default), to approximate the distribution of the LR statistic for the full vector of estimated parameters; or a vector of names of a subset of this vector, to approximate the distribution of the profile LR statistic for this subset.    
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_nsim">nsim</code></td>
<td>

<p>Integer: number of bootstrap replicates. Values lower than the default are not recommended. Note that this will be ignored if the distribution has previously been simulated and <code>reset=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_reset">reset</code></td>
<td>

<p>Boolean: Whether to use any previously computed distribution (see Details) or not.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_bgp">BGP</code></td>
<td>
<p>Named numeric vector of &ldquo;Bootstrap-Generating Parameters&rdquo;. Ideally the distribution of the LR test statistic would be pivotal and thus the parameter values under which this distribution is simulated would not matter. In practice, simulating by default its distribution under the &ldquo;best&rdquo; available information (the MSLE for <code>get_LRboot</code>, or the specifically tested hypothesis defined by the <code>h0</code> argument of <code>SLRT</code>) may be more accurate than under alternative parametric values. For <code>h0</code> being an incomplete parameter vector and <code>BGP</code> is NULL (the default), <code>SLRT</code> will simulate under a completed parameter vector using estimates of other parameters maximizing the likelihood profile for <code>h0</code>. 
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_which">which</code></td>
<td>

<p>NULL or character string: controls the return value. If NULL, the function returns a list; otherwise, this specifies which element of the list to return. 
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_type">type</code>, <code id="get_LRboot_+3A_level">level</code></td>
<td>

<p>vector of character strings: passed to <code><a href="boot.html#topic+boot.ci">boot.ci</a></code> as arguments <code>type</code> and <code>conf</code>. 
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_bootci.args">bootCI.args</code></td>
<td>

<p>list of arguments passed to <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>. Should not include the <code>boot.out</code> argument.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_...">...</code></td>
<td>

<p>For <code>SLRT</code>: further arguments passed to <code>get_LRboot</code>. For <code>get_LRboot</code>: further arguments controlling parallelization, including <code>nb_cores</code>. However, parallelization may be best ignored in most cases (see Details).
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_variants">variants</code></td>
<td>

<p>For development purposes, not documented.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation of the likelihood ratio in high-dimensional models is easily confounded by maximization issues. Computation of a likelihood profile for a tested parameter between its summary-ML estimate and the tested value may be useful to reduce these issues. The number of steps of the profile is controlled by the <code>nsteps</code> value.
</p>
<p><b>Bootstraps:</b>
</p>
<p>The result of calling <code>get_LRboot</code> (either directly or through <code>SLRT</code>) with given <code>h0_pars</code> is stored in the <code>object</code> (until the next <code>refine</code>), and this saved result is returned by a next call to <code>get_LRboot</code> with the same <code>h0_pars</code> if <code>reset=FALSE</code>. The default is however to recompute the distribution (<code>reset=TRUE</code>).
</p>
<p>Parallelization is possible but maybe not useful because computations for each bootstrap replicate are fast relative to parallelization overhead. It will be called when the ... arguments include an <code>nb_cores</code>&gt;1. The ... may include further arguments passed to <code><a href="spaMM.html#topic+dopar">dopar</a></code>, but among the <code>dopar</code> arguments, <code>iseed</code> will be ignored, and <code>fit_env</code> should not be used.
</p>
<p>A raw bootstrap p-value can be computed from the simulated distribution as <code>(1+sum(t &gt;= t0))/(N+1)</code> where <code>t0</code> is the original likelihood ratio, <code>t</code> the vector of bootstrap replicates and <code>N</code> its length. See Davison &amp; Hinkley (1997, p. 141) for discussion of the adjustments in this formula. However, a sometimes more economical use of the bootstrap is to provide a Bartlett correction for the likelihood ratio test in small samples. According to this correction, the mean value <code class="reqn">m</code> of the likelihood ratio statistic under the null hypothesis is computed (here estimated by simulation) and the original LR statistic is multiplied by <code class="reqn">n/m</code> where <code class="reqn">n</code> is the number of degrees of freedom of the test. Unfortunately, the underlying assumption that the corrected LR statistic follows the chi-square distribution does not always work well. 
</p>


<h3>Value</h3>

<p><code>get_LRboot</code> with default <code>which</code> argument returns a numeric vector representing the simulated distribution of the LR statistic, i.e. <b>twice</b> the log-likelihood difference, as directly used in <code>pchisq()</code> to get the p-value. 
</p>
<p><code>SLRT</code> returns a list with the following element(s), each being a one-row data frame:
</p>
<table role = "presentation">
<tr><td><code>basicLRT</code></td>
<td>
<p>A data frame including values of the likelihood ratio chi2 statistic, its degrees of freedom, and the p-value. The chi2 statistic may bear as an attribute a solution vector value copied from the log-likelihood <code><a href="#topic+profile">profile</a></code> return value for the tested <code>h0</code>.</p>
</td></tr>
</table>
<p>and, if a bootstrap was performed: 
</p>
<table role = "presentation">
<tr><td><code>BartBootLRT</code></td>
<td>
<p>A data frame including values of the Bartlett-corrected likelihood ratio chi2 statistic, its degrees of freedom, and its p-value;</p>
</td></tr>
<tr><td><code>rawBootLRT</code></td>
<td>
<p>A data frame including values of the likelihood ratio chi2 statistic, its degrees of freedom, and the raw bootstrap p-value;</p>
</td></tr>
<tr><td><code>bootCI</code></td>
<td>
<p>(present if <code>h0</code> specified a single parameter and <code>nsim</code>&gt;2) The result of <code>boot::boot.ci</code>, with slightly edited <code>call</code> element for conciseness.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bartlett, M. S. (1937) Properties of sufficiency and statistical tests. Proceedings of the Royal Society (London) A 160: 268-282.
</p>
<p>Davison A.C., Hinkley D.V. (1997) Bootstrap methods and their applications. Cambridge Univ. Press, Cambridge, UK.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## See help("example_reftable") for SLRT() examples;
## continuing from there, after refine() steps for good results:
# set.seed(123);mean(get_LRboot(slik_j, nsim=500, reset=TRUE)) # close to df=2 
# mean(get_LRboot(slik_j, h0_pars = "s2", nsim=500, reset=TRUE)) # close to df=1 

## Not run: 
### *Old* simulation study of performance of the corrected LRTs: 

## Same toy example as in help("example_reftable"):
blurred &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    s &lt;- exp(s/4)
    return(c(mean=mean(s),var=var(s)))
  }

## First build a largish reference table and projections to be used in all replicates
# Only the 600 first rows will be used as initial reference table for each "data"
#
set.seed(123)
#
parsp_j &lt;- data.frame(mu=runif(6000L,min=2.8,max=5.2),
                      s2=runif(6000L,min=0.4,max=2.4),sample.size=40)
dsimuls &lt;- add_reftable(,Simulate="blurred", parsTable=parsp_j,verbose=FALSE)
#
mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls,verbose=TRUE)
s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls,verbose=TRUE)
dprojectors &lt;- list(MEAN=mufit,VAR=s2fit)
dprojSimuls &lt;- project(dsimuls,projectors=dprojectors,verbose=FALSE)

## Function for single-data analysis:
#
foo &lt;- function(y, refine_maxit=0L, verbose=FALSE) {
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40) 
  ## ----Inference workflow-----------------------------------------------
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  dslik &lt;- infer_SLik_joint(dprojSimuls[1:600,],stat.obs=dprojSobs,verbose=FALSE)
  dslik &lt;- MSL(dslik, verbose=verbose, eval_RMSEs=FALSE)
  if (refine_maxit) dslik &lt;- refine(dslik, maxit=refine_maxit)
  ## ---- LRT-----------------------------------------------
  lrt &lt;- SLRT(dslik, h0=c(s2=1), nsim=200)
  c(basic=lrt$basicLRT$p_value,raw=lrt$rawBootLRT$p_value,
    bart=lrt$BartBootLRT$p_value,safe=lrt$safeBartBootLRT$p_value)
}

## Simulations using convenient parallelization interface:
#
# library(doSNOW) # optional
#
bootreps &lt;- spaMM::dopar(matrix(1,ncol=200,nrow=1),              # 200 replicates of foo()
  fn=foo, fit_env=list(blurred=blurred, dprojectors=dprojectors, dprojSimuls=dprojSimuls), 
  control=list(.errorhandling = "pass", .packages = "Infusion"),
  refine_maxit=5L,
  nb_cores=parallel::detectCores()-1L, iseed=123)
#
plot(ecdf(bootreps["basic",]))
abline(0,1)
plot(ecdf(bootreps["bart",]), add=TRUE, col="blue")
plot(ecdf(bootreps["safe",]), add=TRUE, col="red")
plot(ecdf(bootreps["raw",]), add=TRUE, col="green") 
#
# Note that refine() iterations are important for good performance.
# Without them, even a larger reftable of 60000 lines 
# may exhibit poor results for some of the CI types.

## End(Not run)
</code></pre>

<hr>
<h2 id='get_nbCluster_range'>
Control of number of components in Gaussian mixture modelling
</h2><span id='topic+get_nbCluster_range'></span><span id='topic+refine_nbCluster'></span><span id='topic+seq_nbCluster'></span>

<h3>Description</h3>

<p>These functions implement the default values for the number of components tried in Gaussian mixture modelling (matching the <code>nbCluster</code> argument of <code>Rmixmod::mixmodCluster()</code>). <code>get_nbCluster_range</code> allows the user to reproduce the internal rules used by <span class="pkg">Infusion</span> to determine this argument. <code>seq_nbCluster</code> is a wrapper to the function defined by the <code>seq_nbCluster</code> global option of the package. Its default result is a sequence of integers determined by the number of rows of the data (see <code><a href="#topic+Infusion.options">Infusion.options</a></code>). <code>get_nbCluster_range()</code> further checks the feasibility of the values generated by <code>seq_nbCluster())</code>, using additional criteria involving the number of columns of the data to determine the maximum feasible number of clusters. This maximum is controlled by the function defined by the <code>maxnbCluster</code> global option of the package. 
</p>
<p><code>refine_nbCluster</code> controls the default number of clusters of <code><a href="#topic+refine">refine</a></code>: it gets the range from <code>seq_nbCluster</code> and keeps only the maximum value of this range if this maximum is higher than the <code>onlymax</code> argument.
</p>
<p>Adventurous users can change the rules used by <span class="pkg">Infusion</span> by changing the global options <code>seq_nbCluster</code> and <code>maxnbCluster</code> (while conforming to the interfaces of these functions). Less ambitiously, they can for example use the maximum value of the result of <code>get_nbCluster_range()</code> as a single reasonable value for the <code>nbCluster</code> argument of <code>infer_SLik_joint</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_nbCluster(nr)
refine_nbCluster(nr, onlymax=7)
get_nbCluster_range(projdata, nr = nrow(projdata), nc = ncol(projdata), 
                    nbCluster = seq_nbCluster(nr), verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_nbCluster_range_+3A_projdata">projdata</code></td>
<td>
<p>data frame: the data to be clustered, which typically include parameters and <b>projected</b> summary statistics;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_nr">nr</code></td>
<td>
<p>integer: number of rows of the data to be clustered;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_onlymax">onlymax</code></td>
<td>
<p>integer: see Description;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_nc">nc</code></td>
<td>
<p>integer: number of columns of the data to be clustered, typically <b>twice</b> the number of estimated parameters;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_nbcluster">nbCluster</code></td>
<td>
<p>integer or vector of integers: candidate values, which feasability is checked by the function.</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_verbose">verbose</code></td>
<td>
<p>boolean. Whether to print some information, or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> An integer vector</p>


<h3>Examples</h3>

<pre><code class='language-R'># Determination of number of clusters when attempting to estimate 
#   20 parameters from a reference table with 30000 rows:
seq_nbCluster(nr=30000L)
get_nbCluster_range(nr=30000L, nc=40L) # nc = *twice* the number of parameters
</code></pre>

<hr>
<h2 id='get_workflow_design'>
Workflow design
</h2><span id='topic+get_workflow_design'></span>

<h3>Description</h3>

<p><code>get_workflow_design</code> provides default control values for the simulation plan, ideally chosen for good performance. The default design is ilustrated in the examples.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_workflow_design(npar, n_proj_stats=npar, n_latent=0L,
                    final_reft_size=NULL,
                    refine_blocksize=NULL, subblock_nbr=NULL,
                    version=packageVersion("Infusion"),
                    cumn_over_maxit = NULL,
                    test_fac=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_workflow_design_+3A_npar">npar</code></td>
<td>

<p>Number of fitted parameters of the statistical model.
</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_n_proj_stats">n_proj_stats</code></td>
<td>
<p>number of projected summary statistics.</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_n_latent">n_latent</code></td>
<td>
<p>Number of latent variables to be predicted.</p>
</td></tr>
</table>
<p><code>npar</code>, <code>n_proj_stats</code> and <code>n_latent</code> are here distinguished for clarity, but only their sum is currently used to define the sampling design.  
</p>
<table role = "presentation">
<tr><td><code id="get_workflow_design_+3A_final_reft_size">final_reft_size</code></td>
<td>

<p>NULL, or integer specifying a non-default value of the final reference table size.
</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_refine_blocksize">refine_blocksize</code></td>
<td>

<p>NULL, or integer specifying a non-default value of the number of points added per refine() call (except perhaps the first refine call in a workflow).
</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_subblock_nbr">subblock_nbr</code></td>
<td>

<p>NULL, or integer specifying a non-default value of the target number of iterations per refine() call (actual number of iterations may differ).
</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_version">version</code></td>
<td>

<p>A version number for <span class="pkg">Infusion</span>. This is intended to allow reproducibility of results of some past versions, as return values have changed over versions.
</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_cumn_over_maxit">cumn_over_maxit</code></td>
<td>

<p>logical; Whether to stop iteration when the target cumulative number of points is added to the reference table, or when the target number of iterations is first reached.
</p>
</td></tr>
<tr><td><code id="get_workflow_design_+3A_test_fac">test_fac</code></td>
<td>

<p>optional numeric value; for testing a workflow, it may be useful to run it with smaller reference table sizes. <code>test_fac</code> specifies a reduction factor for these sizes, relative to the default design.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_workflow_design</code> returns a list of control values, with elements <code>final_reft_size</code>, <code>init_reft_size</code>, <code>refine_blocksize</code>, <code>reftable_sizes</code>, and <code>subblock_nbr</code>, which can be used as shown in the Examples; as well as <code>cumn_over_maxit</code>, <code>first_refine_ntot</code>, and possibly other elements.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This shows how the get_workflow_design() may be used, 
## but in most cases one does not need to manipulate it.

## Not run: 
  blurred &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    s &lt;- exp(s/4)
    return(c(mean=mean(s),var=var(s)))
  }
  
  ## Simulated data:
  set.seed(123)
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40)
  
  workflow_design &lt;- get_workflow_design(npar=2L)

  ## Construct initial reference table:
  
  # Sample its parameters:
  if (IMPLICIT &lt;- TRUE) { # use implicit control by get_workflow_design()
    parsp_j &lt;- init_reftable(lower=c(mu=2.5,s2=0.25,sample.size=40),
                           upper=c(mu=5.2,s2=2.4,sample.size=40))
    # =&gt; get_workflow_design() has been called internally with default values 
    #    to provide the dimension of the initial reference table.  
    #    The following syntax provides a more explicit control:
  } else {
    parsp_j &lt;- init_reftable(lower=c(mu=2.5,s2=0.25,sample.size=40),
                             upper=c(mu=5.2,s2=2.4,sample.size=4,
                             nUnique=workflow_design$init_reft_size))
  }
  # and yet another way to the same result could be
  #
  # parsp_j &lt;- data.frame(mu=runif(init_reft_size,min=2.5,max=5.2),
  #                       s2=runif(init_reft_size,min=0.25,max=2.4),
  #                       sample.size=40)
  
  # Generate the initial simulations:
  dsimuls &lt;- add_reftable(, Simulate="blurred", parsTable=parsp_j, verbose=FALSE)
  
  ## Construct projections
  mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls,verbose=FALSE)
  s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls,verbose=FALSE)
  dprojectors &lt;- list(MEAN=mufit,VAR=s2fit)
  
  ## Apply projections on simulated statistics and 'data':
  dprojSimuls &lt;- project(dsimuls,projectors=dprojectors,verbose=FALSE)
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  
  ## Summary-likelihood inference:
  # Initial Inference of log-likelihood surface
  slik_j &lt;- infer_SLik_joint(dprojSimuls, stat.obs=dprojSobs, verbose=TRUE)
  # Find maximum, confidence intervals...
  slik_j &lt;- MSL(slik_j, eval_RMSEs=FALSE, CIs=FALSE)
  
  ## Refinements over iterations
  # Here, with only two estimated parameters, workflow_design$final_reft_size
  # suggests a final reference table of 5000 simulations, attained through
  # 6 refine() calls with intermediate sizes given by 
  (workflow_design$reftable_sizes)
  # here 500, 1000, 2000, 3000, 4000, 5000.
  # 
  if (IMPLICIT) { # Again using implicit control by get_workflow_design()
    # Essentially, it suffices to call 
    for (it in seq(6)) slik_j &lt;- 
      refine(slik_j, eval_RMSEs= it==6L, CIs= it==6L)
    # to run the default workflow. Again, the following syntax, 
    # showing how successive table sizes are controlled internally, 
    # provides a more explicit control:
  } else {
    reftable_sizes &lt;- workflow_design$reftable_sizes
    init_reft_size &lt;- workflow_design$init_reft_size
    refine_sizes &lt;- diff(c(init_reft_size, reftable_sizes))
    maxit &lt;- workflow_design$subblock_nbr
    for(it in seq_len(length(refine_sizes)-1L)) {
      add_it &lt;- refine_sizes[it]
      slik_j &lt;- refine(slik_j, ntot=add_it, maxit=maxit, 
                       eval_RMSEs=FALSE, CIs=FALSE)
    }
    add_it &lt;- tail(refine_sizes,1L)
    slik_j &lt;- refine(slik_j, ntot=add_it, maxit=maxit, 
                     CIs=add_it, eval_RMSEs=add_it)
  }

## End(Not run)
  
</code></pre>

<hr>
<h2 id='goftest'>
Assessing goodness of fit of inference using simulation
</h2><span id='topic+goftest'></span><span id='topic+summary.goftest'></span><span id='topic+print.goftest'></span>

<h3>Description</h3>

<p>A goodness-of-fit test is performed in the case projected statistics have been used for inference. Otherwise some plots of limited interest are produced.
</p>
<p><code>summary</code> and <code>print</code> methods for results of <code>goftest</code> call <code>str</code> to display the structure of this result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goftest(object, nsim = 99L, method = "", stats=NULL, plot. = TRUE, nb_cores = NULL, 
        Simulate = get_from(object,"Simulate"), 
        control.Simulate=get_from(object,"control.Simulate"),
        packages = get_from(object,"packages"), 
        env = get_from(object,"env"), verbose = interactive(),
        cl_seed=.update_seed(object), get_gof_stats=.get_gof_stats)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goftest_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_nsim">nsim</code></td>
<td>

<p>Number of draws of summary statistics.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_method">method</code></td>
<td>

<p>For development purposes, not documented.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_stats">stats</code></td>
<td>

<p>Character vector, or NULL: the set of summary statistics to be used to construct the test. If NULL, the union, across all projections, of the raw summary statistics used for projections is potentially used for goodness of fit; however, if this set is too large for gaussian mixture modelling, a subset of variable may be selected. How they are selected is not yet fully settled (see Details).  
</p>
</td></tr>
<tr><td><code id="goftest_+3A_plot.">plot.</code></td>
<td>

<p>Control diagnostic plots. <code>plot.</code> can be of logical, character or numeric type. If <code>plot.</code> is <code>FALSE</code>, no plot is produced. If <code>plot.</code> is <code>TRUE</code> (the default), a data frame of up to 8 goodness-of-fit statistics (the statistics denoted <em>u</em> in Details) is plotted. If more than eight raw summary statistics (denoted <em>s</em> in Details) were used, then only the first eight <em>u</em> are retained (see Details for the ordering of the <em>u</em>s here). 
If <code>plot.</code> is a <b>numeric vector</b>, then <em>u</em><code>[plot.]</code> are retained (possibly more than 8 statistics, as in the next case). If <code>plot.</code> is a <b>character vector</b>, then it is used to match the names of the <em>u</em> statistics (not of <em>s</em>) to be retained in the plot; the names of <em>u</em> are built from names of <em>s</em> by wrapping the latter within <code>"Res(".")"</code> (see axes labels of default plots for examples of valid names).    
</p>
</td></tr>
<tr><td><code id="goftest_+3A_nb_cores">nb_cores</code>, <code id="goftest_+3A_simulate">Simulate</code>, <code id="goftest_+3A_packages">packages</code>, <code id="goftest_+3A_env">env</code>, <code id="goftest_+3A_verbose">verbose</code></td>
<td>

<p>See same-named <code><a href="#topic+add_simulation">add_simulation</a></code> arguments.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_control.simulate">control.Simulate</code></td>
<td>

<p>A list of arguments of the <code>Simulate</code> function (see<code><a href="#topic+add_simulation">add_simulation</a></code>). The default value should generally be used, unless e.g. it contains the path of an executable on one machine and a different path must be specified on another machine.  
</p>
</td></tr>
<tr><td><code id="goftest_+3A_cl_seed">cl_seed</code></td>
<td>
<p>NULL or integer (see <code><a href="#topic+refine">refine</a></code> for Details).</p>
</td></tr>
<tr><td><code id="goftest_+3A_get_gof_stats">get_gof_stats</code></td>
<td>
<p>function for selecting raw statistics (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Testing goodness-of-fit:</b> The test is somewhat heuristic but appears to give reasonable results (the Example shows how this can be verified). It assumes that all summary statistics are reduced to projections predicting all model parameters. It is then conceived as if any projection <em>p</em> predicting a parameter were a sufficient statistic for this parameter, given the information contained in the summary statistics <b>s</b> (this is certainly the ideal objective of machine-learning regression methods). Then a statistic <em>u</em> independent (under the fitted model) from all projections should be a suitable statistic for testing goodness of fit: if the model is correctly specified, the quantile of observed <em>u</em>, in the distribution of <em>u</em> under the fitted model, should be uniformly distributed over repeated sampling under the data-generating process. The procedure constructs statistics uncorrelated to all <b>p</b> (over repeated sampling under the fitted model) and proceeds as if they were independent from <em>p</em> (rather than simply uncorrelated). A number (depending on the size of the reference table) of statistics <em>u</em> uncorrelated to <em>p</em> are then defined. Each such statistic is obtained as the residual of the regression of a given raw summary statistic to all projections, where the regression input is a simulation table of <code>nsim</code> replicates of <b>s</b> under the fitted model, and of their projections <b>p</b> (using the &ldquo;projectors&rdquo; constructed from the full reference table). The latter regression involves one more, small-<code>nsim</code>, approximation (as it is the sample correlation that is zeroed) but using the residuals is crucially better than using the original summary statistics (as some ABC software may do). An additional feature of the procedure is to construct a single test statistic <em>t</em> from joint residuals <b>u</b>, by estimating their joint distribution (using Gaussian mixture modelling) and letting <em>t</em> be the density of <b>u</b> in this distribution.  
</p>
<p><b>Selection of raw summary statistics:</b> See the code of the <code>Infusion:::..get_gof_stats</code> function for the method used. It requires that <code>ranger</code> has been used to produce the projectors, and that the latter include variable importance statistics (by default, <span class="pkg">Infusion</span> calls <code>ranger</code> with argument <code>importance="permutation"</code>). <code>.get_gof_stats</code> then selects the raw summary statistics with <em>least</em> importance over projections (this may not be optimal, and in particular appears redundant with the procedure described below to construct goodness-of-fit statistics from raw summary statistics; so this might change in a later version), and returns a vector of names of raw statistics, sorted by increasing least-importance. The number of summary statistics can be controlled by the global package option <code>gof_nstats_fn</code>, a function with arguments <code>nr</code> and <code>nstats</code> for, respectively, the number of simulations of the processus (as controlled by <code>goftest(.,nsim)</code>) and the total number of raw summary statistics used in the projections.
</p>
<p>The <b>diagnostic plot</b> will show a data frame of residuals <em>u</em> of the summary statistics identified as the first elements of the vector returned by <code>Infusion:::..get_gof_stats</code>, i.e. again a set of raw statistics with least-importance over projectors. 
</p>


<h3>Value</h3>

<p>An object of class <code>goftest</code>, which is a<code>list</code> with element(s)
</p>
<table role = "presentation">
<tr><td><code>pval</code></td>
<td>
<p>The p-value of the test (NULL if the test is not feasible).</p>
</td></tr>
<tr><td><code>plotframe</code></td>
<td>
<p>The data frame which is (by default) plotted by the function.
Its last line contains the residuals <em>u</em> for the analyzed data, and other lines contain the bootstrap replicates.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>### See end of example("example_reftable") for minimal example.

## Not run: 
### Performance of GoF test over replicate draws from data-generating process

# First, run 
example("example_reftable") 
# (at least up to the final 'slik_j' object), then

# as a shortcut, the same projections will be used in all replicates:
dprojectors &lt;- slik_j$projectors 

set.seed(123)
gof_draws &lt;- replicate(200, {
  cat(" ")
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40) 
  ## ----Inference workflow-----------------------------------------------
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  dslik &lt;- infer_SLik_joint(dprojSimuls,stat.obs=dprojSobs,verbose=FALSE)
  dslik &lt;- MSL(dslik, verbose=FALSE, eval_RMSEs=FALSE)
  ## ----GoF test-----------------------------------------------
  gof &lt;- goftest(dslik,nb_cores = 1L, plot.=FALSE,verbose=FALSE) 
  cat(unlist(gof))
  gof
})
# ~ uniform distribution under correctly-specified model: 
plot(ecdf(unlist(gof_draws)))

## End(Not run)

</code></pre>

<hr>
<h2 id='handling_NAs'>
Discrete probability masses and NA/NaN/Inf in distributions of summary statistics.
</h2><span id='topic+handling_NAs'></span><span id='topic+NA_handling'></span><span id='topic+boundaries-attribute'></span>

<h3>Description</h3>

<p>This section was written for the primitive workflow and may be largely irrelevant for the up-to-date one. 
It explains the use of the <code>boundaries</code> attribute of observed statistics to handle (1) values of the summary statistics that can occur with some probability mass; (2) special values (NA/NaN/Inf) in distributions of summary statistics. This further explains why <code>Infusion</code> handles special values by removing affected distributions unless the <code>boundaries</code> attribute is used.   
</p>


<h3>Details</h3>

<p>Special values may be encountered in an analysis. For example, trying to estimate a regression coefficient when the predictor variable is constant may return a NaN. Since functions such as <code>refine</code> automatically add simulated distributions, this problem must be automatically handled by the user's simulation function or by the package functions, rather than by user's tinkering with the Infusion procedures.   
</p>
<p>The user must consider what s-he would do if actual data also included NA/NaN/Inf values. If such data would not be subject to a statistical analysis, then the simulation procedure must reflect that, otherwise the analysis will be biased. The processing of reference tables by Infusion functions applies <code>na.omit()</code> on the tables so any line containing NA's will be removed. The drawbacks are that the number of informative simulations is reduced and that inference will be difficult if the data-generating parameters were indeed prone to induce data that would not be subject to statistical analysis. Thus, it may be necessary to simulate alternative data until no special values are obtained and the target size of the simulated distribution is reached. One solution is for the user to write a simulation function that calls itself recursively until a valid summary statistic is produced. Care is then needed to avoid infinite recursion (which might well indicate unlikely parameter values). 
</p>
<p>Alternatively, if one considers that special values are informative about parameters (in the above example of a regression coefficient, if a constant predictor variable says something about the parameters), then NA/NaN/Inf must be replaced by a (fixed) dummy numerical value which is flagged to be distinctly handled, using the <code>boundaries</code> attribute of the observed summary statistics. The simulation function should return statistic <code>foo=-1</code> (say) instead of <code>foo=NaN</code>, and one should then set <code>attr(&lt;observed&gt;,"boundaries") &lt;- c(foo=-1)</code>. 
</p>
<p>The boundary attribute is also useful to handle all values of the summary statistics that can occur with some probability mass. For example if the estimate <code>est_p</code> of a probability takes values 0 or 1 with positive probability, one should set <code>attr(&lt;observed&gt;,"boundaries") &lt;- c(p_est=0,p_est=1)</code>.
</p>

<hr>
<h2 id='infer_logLs'>
Infer log Likelihoods using simulated distributions of summary statistics
</h2><span id='topic+infer_logLs'></span><span id='topic+infer_tailp'></span><span id='topic+infer_logL_by_GLMM'></span><span id='topic+infer_logL_by_Rmixmod'></span><span id='topic+infer_logL_by_mclust'></span><span id='topic+infer_logL_by_Hlscv.diag'></span>

<h3>Description</h3>

<p>The functions described here are either experimental or relevant only for the primitive workflow.
</p>
<p>For each simulated distribution of summary statistics, <code>infer_logLs</code> infers a probability density function, and the density of the observed values of the summary statistics is deduced. By default, inference of each density is performed by <code>infer_logL_by_Rmixmod</code>, which fits a distribution of summary statistics using procedures from the <code>Rmixmod</code> package.        
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer_logLs(object, stat.obs, 
            logLname = Infusion.getOption("logLname"), 
            verbose = list(most=interactive(), 
                           final=FALSE), 
            method = Infusion.getOption("mixturing"),
            nb_cores = NULL, packages = NULL, cluster_args,
            ...)
infer_tailp(object, refDensity, stat.obs,
                tailNames=Infusion.getOption("tailNames"),
                verbose=interactive(), method=NULL, cluster_args, ...)
infer_logL_by_GLMM(EDF,stat.obs,logLname,verbose)
infer_logL_by_Rmixmod(EDF,stat.obs,logLname,verbose)
infer_logL_by_mclust(EDF,stat.obs,logLname,verbose)
infer_logL_by_Hlscv.diag(EDF,stat.obs,logLname,verbose)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="infer_logLs_+3A_object">object</code></td>
<td>

<p>A list of simulated distributions (the return object of <code><a href="#topic+add_simulation">add_simulation</a></code>)
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_edf">EDF</code></td>
<td>

<p>An empirical distribution, with a required <code>par</code> attribute (an element of the <code>object</code> list).
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_stat.obs">stat.obs</code></td>
<td>

<p>Named numeric vector of observed values of summary statistics.
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_loglname">logLname</code></td>
<td>

<p>The name to be given to the log Likelihood in the return object, or the root of the latter name in case of conflict with other names in this object.
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_tailnames">tailNames</code></td>
<td>

<p>Names of &ldquo;positives&rdquo; and &ldquo;negatives&rdquo; in the binomial response for the inference of tail probabilities. 
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_refdensity">refDensity</code></td>
<td>

<p>An object representing a reference density (such as an <span class="pkg">spaMM</span> fit object or other objects with a similar <code>predict</code> method) which, together with the density inferred from each empirical density, defines a likelihood ratio used to define a rejection region.   
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_verbose">verbose</code></td>
<td>
<p> A list as shown by the default, or simply a vector of booleans, indicating respectively
whether to display (1) some information about progress; (2) a final summary of the results after all elements of <code>simuls</code> have been processed. If a count of 'outlier'(s) is reported, this typically means that <code>stat.obs</code> is not within the envelope of a simulated distribution (or whatever other meaning the user attaches to an <code>FALSE isValid</code> code: see Details)
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_method">method</code></td>
<td>

<p>A function for density estimation. See Description for the default behaviour and Details for the constraints on input and output of the function. 
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Number of cores for parallel computation. The default is <code>Infusion.getOption("nb_cores")</code>, and 1 if the latter is NULL. <code>nb_cores=1</code> which prevents the use of parallelisation procedures.</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. May contain a non-null <code>spec</code> element, in which case the distinct <code>nb_cores</code> argument is ignored.</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_packages">packages</code></td>
<td>
<p>For parallel evaluation: Names of additional libraries to be loaded on the cores, necessary for evaluation of a user-defined 'method'.</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, density estimation is based on <code>Rmixmod</code> methods. Other available methods are not routinely used and not all of <code>Infusion</code> features may work with them. The function <code>Rmixmod::mixmodCluster</code>
is called, with arguments <code>nbCluster=seq_nbCluster(nr=nrow(data))</code> and <code>mixmodGaussianModel=Infusion.getOption("mixmodGaussianModel")</code>. If <code>Infusion.getOption("seq_nbCluster")</code> specifies a sequence of values, then several clusterings are computed and AIC is used to select among them.  
</p>
<p><code>infer_logL_by_GLMM</code>, <code>infer_logL_by_Rmixmod</code>, <code>infer_logL_by_mclust</code>, and <code>infer_logL_by_Hlscv.diag</code> are examples of the method that may be provided for density estimation. Other <code>method</code>s may be provided with the same arguments. Their return value must include the element <code>logL</code>, an estimate of the log-density of <code>stat.obs</code>, and the element <code>isValid</code> with values <code>FALSE</code>/<code>TRUE</code> (or 0/1). The standard format for the return value is <code>unlist(c(attr(EDF,"par"),logL,isValid=isValid))</code>.
</p>
<p><code>isValid</code> is primarily intended to indicate whether the log likelihood of <code>stat.obs</code> inferred by a given density estimation method was suitable input for inference of the likelihood surface. <code>isValid</code> has two effects: to distinguish points for which isValid is FALSE in the plot produced by <code><a href="#topic+plot.SLik">plot.SLik</a></code>; and more critically, to control the sampling of new parameter points within <code><a href="#topic+refine">refine</a></code> so that points for which isValid is FALSE are less likely to be sampled. 
</p>
<p>Invalid values may for example indicate a likelihood estimated as zero (since log(0) is not suitable input), or (for density estimation methods which may infer erroneously large values when extrapolating), whether <code>stat.obs</code> is within the convex hull of the EDF. In user-defined <code>method</code>s, invalid inferred logL should be replaced by some alternative low estimate, as all methods included in the package do.    
</p>
<p>The source code of <code>infer_logL_by_Hlscv.diag</code> illustrates how to test whether <code>stat.obs</code> is within the convex hull of the EDF, using functions <code>resetCHull</code> and <code>isPointInCHull</code> (exported from the <code>blackbox</code> package).
</p>
<p><code>infer_logL_by_Rmixmod</code> calls <code>Rmixmod::mixmodCluster</code>
<code>infer_logL_by_mclust</code> calls <code>mclust::densityMclust</code>, 
<code>infer_logL_by_Hlscv.diag</code> calls <code>ks::kde</code>, and <code>infer_logL_by_GLMM</code> fits a binned distribution of summary statistics using a Poisson GLMM with autocorrelated random effects, where the binning is based on a tesselation of a volume containing the whole simulated distribution. Limited experiments so far suggest that the mixture models methods are fast and appropriate (<code>Rmixmod</code>, being a bit faster, is the default method); that the kernel smoothing method is more erratic and moreover requires additional input from the user, hence is not really applicable, for distributions in dimension <em>d</em>= 4 or above; and that the GLMM method is a very good density estimator for <em>d</em>=2 but will challenge one's patience for <em>d</em>=3 and further challenge the computer's memory for <em>d</em>=4.
</p>


<h3>Value</h3>

<p>For <code>infer_logLs</code>, a data frame containing parameter values and their log likelihoods, and additional information such as attributes providing information about the parameter names and statistics names (not detailed here). These attributes are essential for further inferences.
</p>
<p>See Details for the required value of the <code>method</code>s called by <code>infer_logLs</code>.
</p>


<h3>See Also</h3>

<p>See step (3) of the workflow in the Example on the main <code><a href="#topic+Infusion">Infusion</a></code> documentation page.  
</p>

<hr>
<h2 id='infer_SLik_joint'>
Infer a (summary) likelihood surface from a simulation table
</h2><span id='topic+infer_SLik_joint'></span>

<h3>Description</h3>

<p>This infers the likelihood surface from a simulation table where each simulated data set is drawn for a distinct (vector-valued) parameter, as is usual for reference tables in other forms of simulation-based inference such as Approximate Bayesian Computation.
A parameter density is inferred, as well as a joint density of parameters and summary statistics, and the likelihood surface is inferred from these two densities. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer_SLik_joint(data, stat.obs, logLname = Infusion.getOption("logLname"), 
                Simulate = attr(data, "Simulate"), 
                nbCluster= seq_nbCluster(nr=nrow(data)),
                using = Infusion.getOption("mixturing"), 
                verbose = list(most=interactive(),pedantic=FALSE,final=FALSE),
                marginalize = TRUE,
                constr_crits=NULL,
                projectors=NULL,
                is_trainset)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="infer_SLik_joint_+3A_data">data</code></td>
<td>

<p>A data frame, whose each row contains a vector of parameters and one realization of the summary statistics for these parameters. Typically this holds the projected reference table (but see <code>projectors</code> argument for an experimental alternative). 
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_stat.obs">stat.obs</code></td>
<td>

<p>Named numeric vector of observed values of summary statistics. Typically this holds the projected values (but see <code>projectors</code> argument for an experimental alternative).
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_loglname">logLname</code></td>
<td>

<p>The name to be given to the log Likelihood in the return object, or the root of the latter name in case of conflict with other names in this object.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_simulate">Simulate</code></td>
<td>
<p>Either NULL or the name of the simulation function if it can be called from the R session (see <code><a href="#topic+add_reftable">add_reftable</a></code> for more information on this function). 
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_nbcluster">nbCluster</code></td>
<td>
<p>controls the <code>nbCluster</code> argument of <code>Rmixmod::mixmodCluster</code>
; a vector of integers, or <code>"max"</code> which is interpreted as the maximum of the default <code>nbCluster</code> value.   
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_using">using</code></td>
<td>
<p>Either <code>"Rmixmod"</code> or <code>"mclust"</code> to select the clustering methods used. 
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_marginalize">marginalize</code></td>
<td>
<p>Boolean; whether to derive the clustering of fitted parameters by marginalization of the joint clustering; if not, a distinct call to a clustering function is performed. It is strongly advised not to change the default. This argument might be deprecated in future versions.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_constr_crits">constr_crits</code></td>
<td>
<p>NULL, or quoted expression specifying a constraints on parameters, beyond the ones defined by the ranges over each parameter: see <code><a href="#topic+constr_crits">constr_crits</a></code> for details.  This will control the parameter space both for maximization of the summary-likelihood, and for generation of new parameter points when <code>refine()</code> is called on the return object. See Examples section for a nice artificial toy example.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_verbose">verbose</code></td>
<td>

<p>A list as shown by the default, or simply a vector of booleans, indicating respectively
whether to display (1) some information about progress; (2) more information whose importance is not clear to me; (3) a final summary of the results after all elements of <code>simuls</code> have been processed.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_projectors">projectors</code></td>
<td>

<p>if not NULL, this argument may be passed to <code>project</code> in the case the <code>data</code> or <code>stat.obs</code> do not yet contain the projected statistics. This <b>experimental</b> feature aims to remove the two user-level calls to <code>project</code> in the inference workflow.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_is_trainset">is_trainset</code></td>
<td>

<p>Passed to <code>project</code> in the case the <code>projectors</code> argument is used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>SLik_j</code>, which is a list including an <code>Rmixmod::mixmodCluster</code>
object (or equivalent objects produced by non-default methods), and additional members not documented here. If projection was used, the list includes a  data.frame <code>reftable_raw</code> of cumulated unprojected simulations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;50) {
  myrnorm &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    return(c(mean=mean(s),var=var(s)))
  } # simulate means and variances of normal samples of size 'sample.size'
  set.seed(123)
  # simulated data with stands for the actual data to be analyzed:  
  ssize &lt;- 40
  Sobs &lt;- myrnorm(mu=4,s2=1,sample.size=ssize) 
  # Uniform sampling in parameter space:
  npoints &lt;- 600
  parsp &lt;- data.frame(mu=runif(npoints,min=2.8,max=5.2),
                      s2=runif(npoints,min=0.4,max=2.4),sample.size=ssize)
  # Build simulation table:
  simuls &lt;- add_reftable(Simulate="myrnorm", parsTable=parsp)
  # Infer surface:
  densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs)
  # Usual workflow using inferred surface:
  slik_j &lt;- MSL(densv) ## find the maximum of the log-likelihood surface
  slik_j &lt;- refine(slik_j,maxit=5)
  plot(slik_j)
  # etc:
  profile(slik_j,c(mu=4)) ## profile summary logL for given parameter value
  confint(slik_j,"mu") ## compute 1D confidence interval for given parameter
  plot1Dprof(slik_j,pars="s2",gridSteps=40) ## 1D profile
  
  # With constraints:
  heart &lt;- quote({ x &lt;- 3*(mu-4.25);  y &lt;- 3*(s2-0.75); x^2+(y-(x^2)^(1/3))^2-1})
  c_densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs, constr_crits = heart)
  c_slik_j &lt;- MSL(c_densv, CIs=FALSE) 
  refine(c_slik_j, target_LR=10, ntot=3000) 

}
</code></pre>

<hr>
<h2 id='infer_surface'>
Infer a (summary) likelihood or tail probability surface from inferred likelihoods
</h2><span id='topic+infer_surface'></span><span id='topic+infer_surface.logLs'></span><span id='topic+infer_surface.tailp'></span>

<h3>Description</h3>

<p>These functions are either for the primitive workflow or experimental. For standard use of <span class="pkg">Infusion</span> see instead the functions used in the up-to-date workflow (<code><a href="#topic+example_reftable">example_reftable</a></code>)
</p>
<p>The <code>logLs</code> method uses a standard smoothing method (prediction under linear mixed models, a.k.a. Kriging) to infer a likelihood surface, using as input likelihood values themselves inferred with some error for different parameter values. The <code>tailp</code> method use a similar approach for smoothing binomial response data, using the algorithms implemented in the spaMM package for fitting GLMMs with autocorrelated random effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logLs'
infer_surface(object, method="REML",verbose=interactive(),allFix=NULL,...)
## S3 method for class 'tailp'
infer_surface(object, method="PQL",verbose=interactive(),allFix,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="infer_surface_+3A_object">object</code></td>
<td>
 
<p>A data frame with attributes, containing independent prediction of logL or of LR tail probabilities for different parameter points, as produced by <code><a href="#topic+infer_logLs">infer_logLs</a></code> or <code><a href="#topic+infer_tailp">infer_tailp</a></code>.  
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_method">method</code></td>
<td>

<p>methods used to estimate the smoothing parameters. If <code>method="GCV"</code>, a generalized cross-validation procedure is used (for <code>logLs</code> method only). Other methods are as described in the <code><a href="spaMM.html#topic+HLfit">HLfit</a></code> documentation.   
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_verbose">verbose</code></td>
<td>

<p>Whether to display some information about progress or not.
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_allfix">allFix</code></td>
<td>

<p>Fixed values in the estimation of smoothing parameters. For development purposes, not for routine use. For <code>infer_surface.logLs</code>, this should typically include values of all parameters fitted by <code><a href="spaMM.html#topic+fitme">fitme</a></code> (<code class="reqn">\rho,\nu,\phi,\lambda</code>, and <code>$etaFix=</code><code class="reqn">\beta</code>).
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>SLik</code> or <code>SLikp</code>, which is a list including the fit object returned by <code><a href="spaMM.html#topic+fitme">fitme</a></code>, and additional members not documented here.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package
</code></pre>

<hr>
<h2 id='Infusion-internal'>Internal Infusion Functions</h2><span id='topic+projpath'></span><span id='topic+calc.lrthreshold'></span><span id='topic+calc.lrthreshold.default'></span><span id='topic+calc.lrthreshold.SLik'></span><span id='topic+calc.lrthreshold.SLikp'></span><span id='topic+str.MAF'></span><span id='topic+predict.dMixmod'></span><span id='topic+predict.dMclust'></span><span id='topic+predict.SLik'></span><span id='topic+predict.MixmodResults'></span><span id='topic+predict.SLikp'></span><span id='topic+plot.MixmodResults'></span><span id='topic+myrnorm'></span><span id='topic+mapMM'></span><span id='topic+isPointInCHull'></span><span id='topic+resetCHull'></span>

<h3>Description</h3>

<p>Internal Infusion functions
</p>


<h3>Details</h3>

<p>These are not to be called by the user, or are waiting for documentation to be written.
</p>

<hr>
<h2 id='init_reftable'>
Define starting points in parameter space.
</h2><span id='topic+init_reftable'></span><span id='topic+init_grid'></span>

<h3>Description</h3>

<p>These functions sample the space of estimated parameters, and also handle other fixed arguments that need to be passed to the function simulating the summary statistics. The current sampling strategy of these functions is crude but achieves desirable effects for present applications: it samples the space more uniformly than independent sampling of each point would, by generating fewer pairs of close points; and it is not exactly a regular grid. 
</p>
<p><code>init_reftable</code> allows constraints to be applied on parameters.
<code>init_grid</code> does not handle such constraints, and further generates replicates of <code>nRepl</code> of the parameter points sampled, which were required in the primitive workflow for good smoothing of the likelihood surface. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_reftable(lower=c(par=0), upper=c(par=1), steps=NULL, 
          nUnique=NULL,                            
          maxmin=(nUnique * length(lower)^2)&lt;400000L, 
          jitterFac=0.5, constr_crits=NULL, ...)
init_grid(lower=c(par=0), upper=c(par=1), steps=NULL, nUnique=NULL, 
          nRepl=min(10L,nUnique), maxmin=TRUE, jitterFac=0.5)
</code></pre>


<h3>Arguments</h3>

<p><b>## Arguments recommended for up-to-date workflow</b>
</p>
<table role = "presentation">
<tr><td><code id="init_reftable_+3A_lower">lower</code></td>
<td>

<p>A vector of lower bounds for the parameters, as well as fixed arguments to be passed to the function simulating the summary statistics. Elements must be named. Fixed parameters character strings.   
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_upper">upper</code></td>
<td>

<p>A vector of upper bounds for the parameters, as well as fixed parameters. Elements must be named and match those of <code>lower</code>.  
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_nunique">nUnique</code></td>
<td>

<p>Number of distinct values of parameter vectors in output. The default for <code>init_reftable</code> is determined by a call to <code><a href="#topic+get_workflow_design">get_workflow_design</a></code> with <code>npar</code> argument being the number of variable parameters as determined by comparison of <code>lower</code> and <code>upper</code>. The result from <code>get_workflow_design</code> can be modified by passing further arguments to this function through the ....
</p>
<p>The default for <code>init_grid</code> is a less elaborate heuristic guess for good start from not too many points, computed as <code>floor(50^((v/3)^(1/3)))</code> where <code>v</code> is the number of variable parameters.  
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_constr_crits">constr_crits</code></td>
<td>
<p>NULL, or quoted expression specifying a constraints on parameters, beyond the ones defined by the ranges over each parameter: see <code><a href="#topic+constr_crits">constr_crits</a></code> for details.
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_maxmin">maxmin</code></td>
<td>

<p>Boolean. If TRUE, use a greedy max-min strategy (GMM, inspired from Ravi et al. 1994) in the selection of points from a larger set of points generated by an hypercube-sampling step. If FALSE, <code>sample</code> is instead used for this second step. This may be useful as the default method becomes slow when thousands of points are to be sampled. 
</p>
</td></tr>
</table>
<p><b>## Other, less useful arguments</b>
</p>
<table role = "presentation">
<tr><td><code id="init_reftable_+3A_steps">steps</code></td>
<td>

<p>Number of steps of the grid, in each dimension of estimated parameters. If NULL, a default value is defined from the other arguments. If a single value is given, it is applied to all dimensions. Otherwise, this must have the same length as <code>lower</code> and <code>upper</code> and named in the same way as the variable parameters in these arguments.    
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_nrepl">nRepl</code></td>
<td>

<p>Number of replicates of distinct values of parameter vectors in output.
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_jitterfac">jitterFac</code></td>
<td>

<p>Controls the amount of jitter of the points around regular grid nodes. The default value 0.5 means that a mode can move by up to half a grid step (independently in each dimension), so that two adjacent nodes moved toward each other can (almost) meet each other. 
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="#topic+get_workflow_design">get_workflow_design</a></code> when <code>nUnique</code> is left NULL. Can be used notably to specify non-default <code>n_proj_stats</code> or <code>n_latent</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame. Each row defines a list of arguments of vector of the function simulating the summary statistics.
</p>


<h3>Note</h3>

<p><code>init_grid</code> is an exported function from the <span class="pkg">blackbox</span> package. 
</p>


<h3>References</h3>

<p>Ravi S.S., Rosenkrantz D.J., Tayi G.K. 1994. Heuristic and special case algorithms for dispersion problems. Operations Research 42, 299-310.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
init_reftable(lower=c(mu=2.8,s2=0.5,sample.size=20),
              upper=c(mu=5.2,s2=4.5,sample.size=20))
# Less recommended:          
init_reftable(lower=c(mu=2.8,s2=0.5,sample.size=20),
              upper=c(mu=5.2,s2=4.5,sample.size=20),
              steps=c(mu=7,s2=9),nUnique=63)
init_grid()
</code></pre>

<hr>
<h2 id='MAF.options'>
Control of MAF design and training
</h2><span id='topic+config_mafR'></span><span id='topic+MAF.options'></span>

<h3>Description</h3>

<p>Masked Autoregressive Flows can be used by <span class="pkg">Infusion</span> to infer various densities.
This functionality requires the <span class="pkg">mafR</span> package, and is requested through the <code>using</code> argument of 
<code>infer.SLik.joint</code> or <code>refine</code> (see Details).
</p>
<p><code>config_mafR</code> is a convenient way to reset the Python session (erasing all results stored in its memory), and in particular to enforce GPU usage.
</p>
<p><code>MAF.options</code> is a wrapper for <code>Infusion.options</code> which facilitates the specification of 
options that control the design of Masked Autoregressive Flows and their training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config_mafR(torch_device, ...)
MAF.options(template = "zuko-like", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MAF.options_+3A_torch_device">torch_device</code></td>
<td>

<p>character: <code>"cpu"</code>, <code>"cuda"</code> (or <code>"cuda:0"</code>, etc., useful if several GPUs are available) or <code>"mps"</code>.
</p>
</td></tr>
<tr><td><code id="MAF.options_+3A_template">template</code></td>
<td>

<p>Defines a template list of options, subsequently modified by options specified through the ..., if any.
Possible values of <code>template</code> are <code>"zuko-like"</code>, <code>"PSM19"</code>, <code>NULL</code>, or a <code>list</code> of options. The default value <code>"zuko-like"</code> reproduces <span class="pkg">Infusion</span>'s defaults. 
</p>
</td></tr>
<tr><td><code id="MAF.options_+3A_...">...</code></td>
<td>
<p>For <code>MAF.options</code>: a named value, or several of them, that override or complete the <code>template</code> values. For <code>config_mafR</code>: for development purposes; not documented.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Possible <code>using</code> values:</b>
</p>
<p>With <code>using="c.mafR"</code> four different MAFs are computed in every iteration:
the density of statistics given parameters (providing the likelihood), the joint density, the instrumental density of parameters, and the &ldquo;instrumental posterior&rdquo; density of parameters given the data.
</p>
<p>With <code>using="MAFmix"</code>, MAFs are computed only for the joint density and the instrumental density. The likelihood is deduced from them and a multivariate Gaussian mixture model is used to infer the &ldquo;instrumental posterior&rdquo; density.
</p>
<p><code>using="mafR"</code> can be used to let <span class="pkg">Infusion</span> select one of the above options. <code>"MAFmix"</code> is currently called as it is faster, but this is liable to change in the future, so do not use this if you want a repeatable workflow.
</p>
<p><b>Possible <code>template</code> values for <code>MAF.options</code>:</b>
</p>
<p><code>"PSM19"</code> defines a template list of control values recommended by Papamakarios et al. (2019, Section 5.1).
<code>"zuko-like"</code> defines a template list of values inspired from the tutorials of the <span class="pkg">zuko</span> Python package, with some extra twists. Concretely, their definition is
</p>
<pre>
    if (template == "zuko-like") {
        optns &lt;- list(design_hidden_layers = .design_hidden_layers_MGM_like, 
            MAF_patience = 30, MAF_auto_layers = 3L, Adam_learning_rate = 0.001)
    }
    else if (template == "PSM19") {
        optns &lt;- list(design_hidden_layers = .design_hidden_layers_PSM19, 
            MAF_patience = 20, MAF_auto_layers = 5L, Adam_learning_rate = 1e-04)
    }
</pre>
<p>and any replacement value should match the types (function, numeric, integer...) of the shown values, and the formals of the internal functions, in order to avoid cryptic errors. 
</p>
<p>The internal <code>.design_hidden_layers...</code> functions return a vector of numbers <code class="reqn">H_i</code> of hidden values per layer <code class="reqn">i</code> of the neural network. THevector has an attribute giving the resulting approximate number of parameters <code class="reqn">P</code> of the deep-learning model according to Supplementary Table 1 of Papamakarios et al. 2017. <code class="reqn">H_i=</code><code>50L</code> for <code>"PSM19"</code>. For <code>"zuko-like"</code>, a typically higher value will be used. It is defined as a power of two such that <code class="reqn">P</code> is of the order of 8 to 16 times the default number of parameters of the multivariate gaussian mixture model that could be used instead of MAFs.     
</p>
<p>Other controls which can be modified through the ... are <br />
<code> * MAF_validasize</code>, a function which returns the size of the validation set,
whose default definition returns 5% of its input value <code>nr</code> which is the number of samples in the reference table (consistently with Papamakarios et al., 2019);<br />
<code> * MAF_batchsize</code>, a function that returns the batch size for the Adam optimizer. Its default simply returns <code>100L</code>, but non-default functions can be defined, with at least the ... as formal arguments (more elaborate formals are possible but not part of the API).
</p>


<h3>Value</h3>

<p><code>config_mafR</code> is used for its side effects. Returns NULL invisibly.
</p>
<p><code>MAF.options</code> returns the result of calling <code>Infusion.options</code> on the arguments defined by the <code>template</code> and the ... . Hence, it is a list of <b>previous</b> values of the affected options. 
</p>


<h3>References</h3>

<p>Papamakarios, G., T. Pavlakou, and I. Murray (2017) Masked Autoregressive
Flow for Density Estimation. Pp. 2335–2344 in I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds.
Advances in Neural Information Processing Systems 30. Curran Associates,
Inc.<br />
http://papers.nips.cc/paper/6828-masked-autoregressive-flow-for-density-estimation
</p>
<p>Rozet, F., Divo, F., Schnake, S (2023) Zuko: Normalizing flows in PyTorch. 
https://doi.org/10.5281/zenodo.7625672
</p>


<h3>See Also</h3>

<p><code><a href="#topic+save_MAFs">save_MAFs</a></code> for saving and loading MAF objects.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  MAF.options(template = "zuko-like", 
              Adam_learning_rate=1e-4,
              MAF_batchsize = function(...) 100L)

## Not run: 
## These examples require the mafR package, 
## and a Python installation with cuda capabilities.

if (requireNamespace("mafR", quietly=TRUE)) {

config_mafR() # set default: "cpu", i.e. GPU not used
config_mafR("cuda") # sets cuda as GPU backend 
config_mafR() # reset python session, keeping latest backend


  config_mafR(torch_device="cuda")
  
  # function for sampling from N(.,sd=1)
  toyrnorm &lt;- function(mu) {
    sam &lt;- rnorm(n=40,mean=mu,sd=1)
    return(c(mean1=mean(sam)))
  } 

  # simulated data, standing for the actual data to be analyzed:  
  set.seed(123)
  Sobs &lt;- toyrnorm(mu=4) 

  parsp &lt;- init_reftable(lower=c(mu=2.8), 
                         upper=c(mu=5.2))
  simuls &lt;- add_reftable(Simulate="toyrnorm", parsTable=parsp)

  MAF.options(template = "zuko-like")
  densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs, using="mafR")

  # Usual workflow using inferred surface:
  slik_j &lt;- MSL(densv, eval_RMSEs = FALSE) ## find the maximum of the log-likelihood surface
  # ETC.
  
  save_MAFs(slik_j, prefix = "toy_") # See its distinct documentation.
}

## End(Not run)
</code></pre>

<hr>
<h2 id='MSL'>
Maximum likelihood from an inferred likelihood surface
</h2><span id='topic+MSL'></span>

<h3>Description</h3>

<p>This computes the maximum of an object of class <code>SLik</code> representing an inferred (summary) likelihood surface</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSL(object, CIs = prod(dim(object$logLs)) &lt; 12000L, level = 0.95, 
    verbose = interactive(),
    RMSE_n=Infusion.getOption("RMSE_nsim"), 
    eval_RMSEs=(RMSE_n&gt;1L) * prod(dim(object$logLs))&lt;12000L, 
    cluster_args=list(), nb_cores=NULL,
    init=NULL, prior_logL=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MSL_+3A_object">object</code></td>
<td>

<p>an object of class <code>SLik_j</code> as produced by <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> (or, in the primitive workflow,  of class <code>SLik</code> as produced by <code><a href="#topic+infer_surface.logLs">infer_surface.logLs</a></code>).
</p>
</td></tr>
<tr><td><code id="MSL_+3A_cis">CIs</code></td>
<td>

<p>If <code>TRUE</code>, construct one-dimensional confidence intervals for all parameters. See <code><a href="#topic+confint.SLik_j">confint.SLik_j</a></code> to obtain bootstrap confidence intervals. 
</p>
</td></tr>
<tr><td><code id="MSL_+3A_level">level</code></td>
<td>

<p>Intended coverage probability of the confidence intervals.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_verbose">verbose</code></td>
<td>

<p>Whether to display some information about progress and results. 
</p>
</td></tr>
<tr><td><code id="MSL_+3A_rmse_n">RMSE_n</code></td>
<td>

<p>Integer: number of simulation replicates for evaluation of prediction uncertainty for 
likelihoods/ likelihood ratios/ parameters. The default value (10) provides quick but inaccurate estimates.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_eval_rmses">eval_RMSEs</code></td>
<td>

<p>Logical: whether to evaluate prediction uncertainty for likelihoods/ likelihood ratios/ parameters. 
</p>
</td></tr>
<tr><td><code id="MSL_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, to control parallel computation of RMSEs. Beware that parallel computation of RMSEs tends to be memory-intensive. The list may contain a non-null <code>spec</code> element, in which case the <code>nb_cores</code> global <span class="pkg">Infusion</span> option is ignored. Do <b>*not*</b> use a structured list with an <code>RMSE</code> element as is possible for <code>refine</code> (see Details of <code><a href="#topic+refine">refine</a></code> documentation).</p>
</td></tr>
<tr><td><code id="MSL_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Integer: shortcut for specifying <code>cluster_args$spec</code>.</p>
</td></tr>
<tr><td><code id="MSL_+3A_init">init</code></td>
<td>
<p>Initial value for the optimiser. Better ignored.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_prior_logl">prior_logL</code></td>
<td>
<p>(effective only for up-to-date workflow using gaussian mixture modelling of a joint distribution of parameters and statistics) a function that returns a vector of prior log-likelihood values, which is then added to the likelihood deduced from the summary likelihood analysis. The function's single argument must handle a matrix similar to the <code>newdata</code> argument of <code><a href="#topic+predict.SLik_j">predict.SLik_j</a></code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If Kriging has been used to construct the likelihood surface, <code>RMSEs</code> are computed using approximate formulas for prediction (co-)variances in linear mixed midels (see Details in <code><a href="spaMM.html#topic+predict">predict</a></code>). Otherwise, a more computer-intensive bootstrap method is used.   
<code>par_RMSEs</code> are computed from <code>RMSEs</code> and from the numerical gradient of profile log-likelihood at each CI bound. Only <code>RMSEs</code>, not <code>par_RMSEs</code>, are compared to <code>precision</code>.
</p>


<h3>Value</h3>

<p>The <code>object</code> is returned invisibly, with the following (possibly) added members, each of which being (as from version 1.5.0) an environment:
</p>

<dl>
<dt><code>MSL</code></dt><dd><p>containing variables <code>MSLE</code> and <code>maxlogL</code> that match the <code>par</code> and <code>value</code> returned by an <code>optim</code> call. Also contains the <code>hessian</code> of summary likelihood at its maximum.</p>
</dd>
<dt><code>CIobject</code></dt><dd><p>The return value of calling <code><a href="#topic+allCIs">allCIs</a></code>, converted to an environment.</p>
</dd>
<dt><code>RMSEs</code></dt><dd><p>containing, as variable <code>RMSEs</code>, the root mean square errors of the log-likelihood at its inferred maximum and of the log-likelihood ratios at the CI bounds.</p>
</dd>
<dt><code>par_RMSEs</code></dt><dd><p>containing, as variable <code>par_RMSEs</code>, root mean square errors of the CI bounds.</p>
</dd>
</dl>

<p>To ensure backward-compatibility of code to possible future changes in the structure of the objects, the extractor function <code><a href="#topic+get_from">get_from</a></code> should be used to extract the <code>RMSEs</code> and <code>par_RMSEs</code> variables from their respective environments, and more generally to extract any element from the objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package
</code></pre>

<hr>
<h2 id='multi_binning'>
Multivariate histogram
</h2><span id='topic+multi_binning'></span>

<h3>Description</h3>

<p>Constructs a multivariate histogram of the points. Optionally, first tests whether a given value is within the convex hull of input points and constructs the histogram only if this test is TRUE. This function is available for development purposes but is not required otherwise . It is sparsely documented and subject to changes without notice.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_binning(m, subsize=trunc(nrow(m)^(Infusion.getOption("binningExponent"))),
              expand=5/100, focal=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multi_binning_+3A_m">m</code></td>
<td>

<p>A matrix representing points in <em>d</em>-dimensional space, where <em>d</em> is the number of columns
</p>
</td></tr>
<tr><td><code id="multi_binning_+3A_subsize">subsize</code></td>
<td>

<p>A control parameter for an undocumented algorithm
</p>
</td></tr>
<tr><td><code id="multi_binning_+3A_expand">expand</code></td>
<td>

<p>A control parameter for an undocumented algorithm
</p>
</td></tr>
<tr><td><code id="multi_binning_+3A_focal">focal</code></td>
<td>

<p>Value to be tested for inclusion within the convex hull. Its elements must have names.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm may be detailed later.
</p>


<h3>Value</h3>

<p>Either NULL (if the optional test returned FALSE), or an histogram represented as a data frame each row of which represents an histogram cell by its barycenter (a point in <em>d</em>-dimensional space), its &ldquo;binFactor&rdquo; (the volume of the cell times the total number of observations) and its &ldquo;count&rdquo; (the number of observations within the cell).
The returned data frame has the following attributes: <code>attr(.,"stats")</code> are the column names of the <em>d</em>-dimensional points; 
<code>attr(.,"count")</code> is the column name of the count, and 
<code>attr(.,"binFactor")</code> is the column name of the binFactor.
</p>

<hr>
<h2 id='options'>Infusion options settings</h2><span id='topic+Infusion.options'></span><span id='topic+Infusion.getOption'></span><span id='topic+parallel'></span>

<h3>Description</h3>

<p>Allow the user to set and examine a variety of <em>options</em>
which affect operations of the Infusion package. 
However, typically these should not be modified, and if they are, not more than once in a data analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Infusion.options(...)

Infusion.getOption(x)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="options_+3A_x">x</code></td>
<td>
<p>a character string holding an option name.</p>
</td></tr>
<tr><td><code id="options_+3A_...">...</code></td>
<td>
<p>A named value, or several of them, or a single unnamed argument which is a named list). 
The following values, with their defaults, are used in <code>Infusion</code>:
</p>

<dl>
<dt><code>mixturing</code></dt><dd><p>character string: package or function to be used for mixture modelling. Recognized packages are <code>"Rmixmod"</code> (the default) and <code>"mclust"</code>;   </p>
</dd>
<dt><code>train_cP_size</code>:</dt><dd><p>Expression for <code>train_cP_size</code> argument of <code><a href="#topic+project.character">project.character</a></code>.</p>
</dd>
<dt><code>trainingsize</code>:</dt><dd><p>Expression for <code>trainingsize</code> argument of <code><a href="#topic+project.character">project.character</a></code>.</p>
</dd>
<dt><code>projKnotNbr = 1000</code>:</dt><dd><p>default value of <code>trainingsize</code> argument of <code><a href="#topic+project.character">project.character</a></code> for REML (as implied by default expression for <code>trainingsize</code>).</p>
</dd>
<dt><code>logLname = "logL"</code>:</dt><dd><p>default value of <code>logLname</code> argument of <code><a href="#topic+infer_logLs">infer_logLs</a></code>. The name given to the inferred log likelihoods in all analyses.</p>
</dd>
<dt><code>LRthreshold= - qchisq(0.999,df=1)/2</code>:</dt><dd><p>A value used internally by <code><a href="#topic+sample_volume">sample_volume</a></code> to sample points 
in the upper region of the likelihood surface, as defined by the given likelihood ratio threshold.
</p>
</dd>
<dt><code>precision = 0.25</code>:</dt><dd><p>default value of <code>precision</code> argument of <code><a href="#topic+refine">refine</a></code>. Targets RMSE of log L and log LR estimates.</p>
</dd>
<dt><code>nRealizations=1000</code>:</dt><dd><p>default value of <code>nRealizations</code> argument of <code><a href="#topic+add_simulation">add_simulation</a></code>. Number of realizations for each empirical distribution.</p>
</dd>
<dt><code>mixmodGaussianModel="Gaussian_pk_Lk_Ck"</code>:</dt><dd><p>default models used in clustering by <code>Rmixmod</code>. Run <code>Rmixmod::mixmodGaussianModel()</code> for a list of possible models, and see the statistical documentation (Mixmod Team 2016) for explanations about them.</p>
</dd>
<dt><code>global_strategy_args</code>:</dt><dd><p>list of arguments for <code>Rmixmod::mixmodStrategy()</code>.</p>
</dd>
<dt><code>seq_nbCluster= function(projdata, nr=nrow(projdata)) {seq(ceiling(nr^0.31))}</code>:</dt><dd><p>function to control the value of <code>nbCluster</code> used in clustering by <code>Rmixmod</code> (see Details for discussion of this default).</p>
</dd>
<dt><code>maxnbCluster = function(projdata) {...} </code>:</dt><dd><p>function to control the maximum number of clusters (see Details).</p>
</dd>
<dt><code>example_maxtime=2.5</code>:</dt><dd><p>Used in the documentation to control whether the longer examples should be run. 
The approximate running time of given examples (or some very rough approximation for it) on one author's laptop is compared to this value.</p>
</dd> 
<dt><code>nb_cores</code></dt><dd><p>Number of cores for parallel computations (see Details for implementation of these).</p>
</dd>
<dt><code>gof_nstats_fn</code></dt><dd><p>See <code><a href="#topic+goftest">goftest</a></code>.</p>
</dd>
</dl>
 
<p>and possibly other undocumented values for development purposes.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The set of the number of clusters tried (<code>nbCluster</code> argument in <code>Rmixmod</code>) is controlled by two options: <code>seq_nbCluster</code> and <code>maxnbCluster</code>. The second is used to correct the first, using the dimensions of the <code>projdata</code> locally used for clustering, which typically differs from the dimensions of the user-level <code>data</code> (if projections have been applied, in particular). The default upper value of the <code>nbCluster</code> range is derived from the value <code class="reqn">n^{0.3}</code> recommended in the <code>mixmod</code> statistical documentation (Mixmod Team, 2016), but modified based on different considerations. First, that recommendation may be suitable for a large input of points in low dimension, but may request estimation of too many clustering parameters as the dimension of data points increases, justifying the correction according to<code>maxnbCluster</code>. Conversely, for large number of points, experience shows that the maximum value derived from such rules is practically always selected by AIC, supporting a rule specifying a higher number of points (such as the currently retained default <code class="reqn">n^{0.31}</code>).
</p>
<p><code>Infusion</code> can perform parallel computations if several cores are available and requested though <code>Infusion.options(nb_cores=.)</code>. If the <code>doSNOW</code> back-end is attached (by explicit request from the user), it will be used; otherwise, <code>pbapply</code> will be used. Both provide progress bars, but <code>doSNOW</code> may provide more efficient load-balancing. The character shown in the progress bar is <code>'P'</code> for parallel via <code>doSNOW</code> backend, <code>'p'</code> for parallel via <code>pbapply</code> functions, and <code>'s'</code> for serial via <code>pbapply</code> functions. In addition, <code>add_simulation</code> can parallelise at two levels: at an outer level over parameter point, or at an inner level over simulation replicates for each parameter point. The progress bar of the outer computation is shown, but the character shown in the progress bar is <code>'N'</code> if the inner computation is parallel via the <code>doSNOW</code> backend, and <code>'n'</code> if it is parallel via <code>pbapply</code> functions. So, one should see either <code>'P'</code> or <code>'N'</code> when using <code>doSNOW</code>.
</p>


<h3>Value</h3>

<p>For <code>Infusion.getOption</code>, the current value set for option <code>x</code>, or
<code>NULL</code> if the option is unset.
</p>
<p>For <code>Infusion.options()</code>, a list of all set options.  For
<code>Infusion.options(name)</code>, a list of length one containing the set value,
or <code>NULL</code> if it is unset.  For uses setting one or more options,
a list with the previous values of the options changed (returned
invisibly).
</p>


<h3>References</h3>

<p>Mixmod Team (2016). Mixmod Statistical Documentation. Université de Franche-Comté,
Besançon, France. Version: February 10, 2016 retrieved from <a href="https://www.mixmod.org">https://www.mixmod.org</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  Infusion.options()
  Infusion.getOption("LRthreshold")
  ## Not run: 
  Infusion.options(LRthreshold=- qchisq(0.99,df=1)/2)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='plot_proj'>
Diagnostic plots for projections 
</h2><span id='topic+plot_proj'></span><span id='topic+plot_importance'></span>

<h3>Description</h3>

<p><code>plot_proj</code> and <code>plot_importance</code> are convenience functions providing diagnostic plots for projections, <code>plot_proj</code> plots predictions. This function is tailored for use on <span class="pkg">ranger</span> projections, with out-of bag predictions for the training set shown in blue, and predictions for points outside the training set shown in black. Either <code>parm</code> or <code>proj</code> will then be needed to identify the projection to be plotted (perhaps both in some programming contexts, or if other projections methods are used). 
</p>
<p><code>plot_importance</code> plots the importance metric <code>variable.importance</code>  stored in a <code>ranger</code> object. Here, the projection may be identified by either <code>parm</code> or <code>proj</code>, or even directly provided as the <code>object</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_proj(
  object, parm=NULL, proj, 
  new_rawdata, 
  use_oob=Infusion.getOption("use_oob"), is_trainset=FALSE, 
  xlab=NULL, ylab=NULL, ...) 

plot_importance(object, parm, proj, n.var = 30L, xlim=NULL, 
                xlab = "Variable Importance", ylab = "", main="", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_proj_+3A_object">object</code></td>
<td>
<p>An object of class <code>SLik_j</code>. For <code>plot_importance</code>, it may also be an object of class <code>ranger</code>.</p>
</td></tr>
<tr><td><code id="plot_proj_+3A_parm">parm</code></td>
<td>
<p>Character string: a parameter name. Either one of <code>parm</code> or <code>proj</code> is required to get a diagnostic plot for a specific projector. Otherwise, a multipanel plot will be produced for all projectors.</p>
</td></tr>
<tr><td><code id="plot_proj_+3A_proj">proj</code></td>
<td>
<p>Character string: name of projected statistic.</p>
</td></tr>
<tr><td><code id="plot_proj_+3A_new_rawdata">new_rawdata</code></td>
<td>
<p>Reference table on which projections should be computed. If NULL,
projections are not recomputed. Instead,  the values stored in the <code>object</code> are used.</p>
</td></tr>
<tr><td><code id="plot_proj_+3A_use_oob">use_oob</code>, <code id="plot_proj_+3A_is_trainset">is_trainset</code></td>
<td>
<p> Passed to <code><a href="#topic+project.default">project.default</a></code>. Ignored if <code>new_rawdata</code> is NULL.</p>
</td></tr>
<tr><td><code id="plot_proj_+3A_n.var">n.var</code></td>
<td>
<p>Integer: (maximum) number of predictor variables to be included in the plot.</p>
</td></tr>
<tr><td><code id="plot_proj_+3A_xlim">xlim</code>, <code id="plot_proj_+3A_xlab">xlab</code>, <code id="plot_proj_+3A_ylab">ylab</code>, <code id="plot_proj_+3A_main">main</code>, <code id="plot_proj_+3A_...">...</code></td>
<td>
<p>Passed to <code>plot</code> (for <code>plot_proj</code>) or to <code><a href="graphics.html#topic+dotchart">dotchart</a></code>  (for <code>plot_importance</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Projectors may be updated in an object after the projected statistics have been computed and included in the reference table, without any explicit action of the user on the object (see general information about <span class="pkg"><a href="#topic+Infusion">Infusion</a></span> for why and when this may occur). In particular the projectors stored in input and output fit objects of a <code>refine</code> call are stored in the same environment, and therefore the projectors stored in the input object are modified in light of new simulations. In that case, the plots produced by <code>plot_proj</code> may reflect properties either of the updated projections (if <code>new_rawdata</code> is used), or worse, may mix results of different projections (if <code>new_rawdata</code> is not used). A message or a warning may be issued when such events occur.   
</p>


<h3>Value</h3>

<p>These functions are mainly used for their side effect (the plot). <code>plot_importance</code> returns the vector of importance values invisibly. <code>plot_proj</code> returns invisibly, for each parameter a list with the <code>x</code>,<code>y</code> <code>xlab</code> and <code>ylab</code> elements of the <code>plot</code> call, or a structured list of such lists when plots are produced for several parameters.
</p>


<h3>Note</h3>

<p>See workflow examples in <code><a href="#topic+example_reftable">example_reftable</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='plot.SLik'>
Plot SLik or SLikp objects
</h2><span id='topic+plot.SLik'></span><span id='topic+plot.SLik_j'></span><span id='topic+plot.SLikp'></span>

<h3>Description</h3>

<p>Primarily conceived for exposition purposes, for the two-parameters case. 
The black-filled points are those for which the observed summary statistic was outside of the convex hull of the simulated empirical distribution. The crosses mark the estimated ML point and the confidence intervals points, that is, the outmost points on the contour defined by the profile likelihood threshold for the profile confidence intervals. There is a pair of CI points for each interval.
The smaller black dots mark points added in the latest iteration, if <code>refine</code> was used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
plot(x, y, filled = FALSE, decorations = NULL,
                    color.palette = NULL, plot.axes = NULL, 
                    plot.title = NULL, plot.slices=TRUE, ...)
## S3 method for class 'SLik_j'
plot(x, y, filled = nrow(x$logLs)&gt;5000L, decorations = NULL, 
                      color.palette = NULL, plot.axes = NULL, 
                      plot.title = NULL, from_refine=FALSE, plot.slices=TRUE, 
                      show_latest=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.SLik_+3A_x">x</code></td>
<td>

<p>An object of class <code>SLik</code> or <code>SLikp</code>
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_y">y</code></td>
<td>

<p>Not used, but included for consistency with the <code>plot</code> generic. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_filled">filled</code></td>
<td>

<p>whether to plot a <code><a href="spaMM.html#topic+mapMM">mapMM</a></code> or a <code><a href="spaMM.html#topic+filled.mapMM">filled.mapMM</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_decorations">decorations</code></td>
<td>

<p>Graphic directives added to the default <code>decorations</code> value in calls of <code><a href="spaMM.html#topic+mapMM">mapMM</a></code> or a <code><a href="spaMM.html#topic+filled.mapMM">filled.mapMM</a></code> (see the source code of <code>plot.SLik</code> for the latter default values). 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_color.palette">color.palette</code></td>
<td>

<p>Either NULL or a function that can replace the default color function used by <code>plot.SLik</code>. The function must have a single argument, giving the number of color levels. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_plot.title">plot.title</code></td>
<td>
	
<p>statements which replace the default titles to the main plot (see Details). 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_plot.axes">plot.axes</code></td>
<td>
	
<p>statements which replace the default axes on the main plot (see Details). 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_from_refine">from_refine</code></td>
<td>
	
<p>For programming purposes, not documented. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_plot.slices">plot.slices</code></td>
<td>
	
<p>boolean: whether to plot &ldquo;slices&rdquo; of the summary-likelihood surface for pairs of parameters (p1,p2), when more than two parameters are fitted. In such plots the additional parameters p3, p4... are fixed to their estimates [in contrast to profile plots where p3, p4... take distinct values for each (p1,p2), maximizing the function for each (p1,p2)].  
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_show_latest">show_latest</code></td>
<td>
	
<p>Logical: whether to show distinctly the points added in the latest iteration. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently can be used to pass a few arguments such as <code>map.asp</code> in all cases, 
or <code>variances</code> to <code>filled.mapMM</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Different graphic functions are called depending on the number of estimated parameters. For two parameters, <code><a href="spaMM.html#topic+mapMM">mapMM</a></code> or <code><a href="spaMM.html#topic+filled.mapMM">filled.mapMM</a></code> are called. For more than two parameters, <code><a href="spaMM.html#topic+spaMM.filled.contour">spaMM.filled.contour</a></code> is called. See the documentation of these functions for the appropriate format of the <code>plot.title</code> and <code>plot.axes</code> arguments.  
</p>


<h3>Value</h3>

<p><code>plot.SLik_j</code> returns invisibly a list including coordinates of the plot(s) (at least if the latest version of the spaMM package is installed). 
The exact format will depend on the nature of the plot but the names of elements should be self-explanatory. 
<code>plot.SLik</code> returns the plotted object invisibly. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Using 'slik_j' object from the example in help("example_reftable") 
plot(slik_j,filled=TRUE,
     plot.title=quote(title("Summary-likelihood-ratio surface",
                             xlab=expression(mu),
                             ylab=expression(sigma^2))))

## End(Not run)
</code></pre>

<hr>
<h2 id='plot1Dprof'>
Plot likelihood profiles
</h2><span id='topic+plot1Dprof'></span><span id='topic+plot2Dprof'></span>

<h3>Description</h3>

<p>These functions plot 1D and 2D profiles from a summary-likelihood object.
</p>
<p>If you feel the 1D profiles are ugly, see the Details. Confidence intervals may still be correct in such cases.
</p>
<p>High quality 2D plots may be slow to compute, and there may be many of them in high-dimensional parameter spaces, so parallelization of the computation of each profile point has been implemented for them. Usual caveats apply: there is an time cost of launching processes on a cluster, particularly on socket clusters, possibly offsetting the benefits of parallelization when each profile point is fast to evaluate. Further, summary-likelihood objects are typically big (memory-wise), notably when theyinclude many projections, and this may constrain the number of processes that can run in parallel.
</p>
<p>Parallelization is also implemented for 1D profiles, but over the parameter for which profiles are computed, rather than over points in a profile. So it is effective only if profiles are computed for several parameters.  
</p>
<p>In default 2D plots, some areas may be left blank, for distinct reasons: the function values may be too low (as controlled by the <code>min_logLR</code> argument), or the likelihood profile may be maximized at parameter values which do not satisfy constraints defined by the <code>constr_crits</code> of the <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> function. Low profile values, even when shown, are not accurate anyway, since the inference workflow aims at inferring the top of likelihood &ldquo;hill&rdquo;  relevant for the computation of confidence regions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot1Dprof(object, pars=object$colTypes$fittedPars, fixed=NULL, 
           type="logLR", gridSteps=21, xlabs=list(), ylab, scales=NULL,
           plotpar=list(pch=20), 
           control=list(min=-7.568353, shadow_col="grey70"),
           decorations = function(par) NULL, 
           profiles=NULL, add=NULL, safe=TRUE,
           cluster_args=NULL, do_plot=TRUE, CIlevels=NULL,
           lower=NULL, upper=NULL,
           verbose=TRUE,
           ...)
plot2Dprof(object, pars=object$colTypes$fittedPars, fixed=NULL, 
           type="logLR", gridSteps=17, xylabs=list(), main, scales=NULL,
           plotpar=list(pch=20), margefrac = 0,
           decorations = function(par1,par2) NULL, 
           filled.contour.fn = "spaMM.filled.contour", cluster_args=NULL, 
           min_logLR = qchisq(0.95,df=length(object$colTypes$fittedPars))/2 +3,
           lower=NULL, upper=NULL, color.palette=NULL, profiles=NULL,
           ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot1Dprof_+3A_object">object</code></td>
<td>
<p>An <code>SLik</code> or <code>SLik_j</code> object</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_pars">pars</code></td>
<td>
<p> Control of parameters for which profiles will be computed. If <code>pars</code> is specified as a vector of names, profiles are plotted for each parameter, or (2D case) for all pairs of distinct parameters. 
</p>
<p>Finer control is possible in the 2D case: the <code>pars</code> may be specified as a two-column natrix, in which case profiles are generated for all pairs of distinct parameters specified by rows of the matrix. It may also be specified as a two-element list, where each element is a vector of parameter names. In that case, profiles are generated for all pairs of distinct parameters combining one element of each vector.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_fixed">fixed</code></td>
<td>
<p>A named vector of parameter values to keep fixed in the profile computation: these parameters will be excluded from the <code>pars</code> as well as from the paramters over which maximization occurs.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_type">type</code></td>
<td>

<p>Character: possible values are <code>"logL"</code> to plot the log-likelihood profile; <code>"logLR"</code> (or <code>"LR"</code> for the not-log version) to plot the log-likelihood-ratio profile; and, for 1D profiles, <code>"zoom"</code>, <code>"ranges"</code> and <code>"dual"</code> which are variants of the <code>"logLR"</code> plot controlling the plot ranges in different ways (see Details). </p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_gridsteps">gridSteps</code></td>
<td>
<p> The number of values (in each dimension for 2D plots) for which likelihood  should be computed. For 1D plots, 
<code>gridSteps=0</code> is now obsolete.
</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_xlabs">xlabs</code></td>
<td>
<p> A <em>list</em> of alternative axis labels. The names  of the list elements should be elements of <code>pars</code> (see Examples)</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_xylabs">xylabs</code></td>
<td>
<p> Same as <code>xlabs</code> but affecting both axes in 2D plots</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_ylab">ylab</code></td>
<td>
<p> Same as <code>ylab</code> argument of <code>plot</code>. Default depends on <code>type</code> argument.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_main">main</code></td>
<td>
<p> Same as <code>main</code> argument of <code>plot</code>. Default depends on <code>type</code> argument.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_scales">scales</code></td>
<td>
<p> A named character vector, which controls ticks and tick labels on axes, so that these can be expressed as (say) the exponential of the parameter inferred in the SLik object. 
For example if the likelihood of <code>logPop</code> = log(population size) was thus inferred, <code>scales=c(logPop="log")</code> will give population size values on the axis (but will retain a log scale for this parameter). Possible values of each element of the vector are <code>"identity"</code> (default), <code>"log"</code>, and <code>"log10"</code>,   
</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_plotpar">plotpar</code></td>
<td>
<p>Arguments for <code>par()</code> such as font sizes, etc.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_control">control</code></td>
<td>
<p>Control of <code>"zoom"</code> or <code>"dual"</code> plots (see Details).</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_decorations">decorations</code></td>
<td>
<p> A function implementing graphic directives added to the plot (anything that is not a function is converted to the default function). Its formal parameters are as shown by its trivial default value, the <code>par</code>[.] arguments being parameters names (as a vector of character strings), to allow the additional plot elements to depend on the parameter of each subplot (see Plot 3 in Examples).</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_margefrac">margefrac</code></td>
<td>
<p> For development purposes, not documented.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_safe">safe</code></td>
<td>
<p> For development purposes, not documented.</p>
</td></tr> 
<tr><td><code id="plot1Dprof_+3A_filled.contour.fn">filled.contour.fn</code></td>
<td>
<p>Name of a possible alternative to <code>graphics::filled.contour</code> to be used for rendering the plot.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_cluster_args">cluster_args</code></td>
<td>
<p>NULL, or a list in which case a cluster may be created and used. The list elements must match the arguments <code>spec</code> and <code>type</code> of <code>parallel::makeCluster</code>. A socket cluster is created unless <code>type="FORK"</code> (on operating systems that support fork clusters). For <code>plot1Dprof</code>, parallelisation is over the parametrs for which profiles are computed; For <code>plot2Dprof</code>,it is over the grid of points for each profile.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_profiles">profiles</code></td>
<td>
<p>The <code>profiles</code> element of the return value of a previous call of the function. The point coordinates it provides for a given parameter or pair of parameters will be used, instead of recomputing the profile.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_add">add</code></td>
<td>
<p>The <code>profiles</code> element of the return value of a previous <code>plot1Dprof()</code> call. The point coordinates it provides for a given parameter will be added to the profile produced by other arguments, using the graphic directives specified by the ...\ to distingush them.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_min_loglr">min_logLR</code></td>
<td>
<p>Numeric; the minimal value of the log-likelihood ratio to be shown on 2D plots of type <code>logLR</code>, parameter regions having lower ratios being left blank.
</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_do_plot">do_plot</code></td>
<td>
<p>Boolean: whether to actually plot the profiles or only return computations for it.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_cilevels">CIlevels</code></td>
<td>
<p>NULL, or a vector of confidence levels whose bounds will be added to the plot. Suggested values are <code>c(0.99, 0.95,0.90,0.75)</code></p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_lower">lower</code>, <code id="plot1Dprof_+3A_upper">upper</code></td>
<td>
<p>Numeric vectors of bounds for the parameters.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_verbose">verbose</code></td>
<td>
<p>Boolean: whether to print information about the progress of the computation.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_color.palette">color.palette</code></td>
<td>

<p>Either NULL or a function that can replace the default color function used by <code>plot2Dprof</code>. The function must have a single argument, giving the number of color levels. 
</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_...">...</code></td>
<td>
<p> Further arguments passed by another function. Currently these arguments are ignored, except when handling the <code>add</code> argument, where they are passed to <code>graphics::lines</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Possible issues in computing the profiles:</b>
Computation of profiles is complicated by local maximization issues, which may result in highly visible artefacts in the plots. <code>plot1Dprof</code> tries to reduce their impact by computing the profile points starting from parameter values closest to the identified likelihood-maximizing value, and by using a method for selecting initial values for maximization which is partially controlled by the result of computation of the previous profile point. A second sequential computation of points profile may additionally be performed, this time starting from parameter values closest to the identified 95%\ confidence intervals rather than from the MLEs, when such intervals are available in the fit object or if they are requested by the <code>CIlevels</code> argument.  
</p>
<p><b>Graphic details of the plots:</b> 
The 2D profile plots will typically include a contour level for the 95% 2D confidence region, labelled &ldquo;2D CI&rdquo; on the scale.
</p>
<p>A <code>"zoom"</code> plot shows only the top part of the profile, defined as points whose y-values are above a threshold minus-log-likelihood ratio <code>control$min</code>, whose default is -7.568353, the 0.9999 p-value threshold.
</p>
<p>A <code>"ranges"</code> (for <code>plot1Dprof</code>) is similar to <code>"zoom"</code> but maintains a fixed y range, facilitating comparison of profiles with and among different <code>plot1Dprof</code> calls. Few of the originally computed points may appear in the retained x range, in which case it may be useful to generate additional points ensured to appear in the plot, using the <code>CIlevels</code> argument.
</p>
<p>A <code>"dual"</code> plot displays both the zoom, and a shadow graph showing the full profile. The dual plot is shown only when requested and if there are values above and below <code>control$min</code>. The shadow curve color is given by <code>control$shadow_col</code>.
</p>


<h3>Value</h3>

<p>Both functions return a list, invisibly for <code>plot1Dprof</code>. The list has elements<br />
<code> * MSL_updated</code> which is a boolean indicating whether the summary-likelihood maximum has been recomputed (if it is TRUE, a message is printed);<br />
<code> * profiles</code>, itself a list which stores information about each profile. The format of the information per profile is not yet stable (subject to changes without notice), 
but consistent with the one handled by the <code>profiles</code> and <code>add</code> argument). Its elements currently include<br />
<code>    - </code>the x,y or x,y,z coordinates of the putative plot;<br /> 
<code>    - </code>the full coordinates of the profile points in a <code>profpts</code> matrix (1D plot) or a 3D array (2D plot; first dimension are the fitted parameters, second and third are x and y steps). 
</p>
<p><code>plot1Dprof</code> may have the side effect of adding confidence interval information to the fit object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (Infusion.getOption("example_maxtime")&gt;20) { # 2D plots relatively slow
  #### Toy bivariate gaussian model, three parameters, no projections
  #
  myrnorm2 &lt;- function(mu1,mu2,s2,sample.size) {
    sam1 &lt;- rnorm(n=sample.size,mean=mu1,sd=sqrt(s2))
    sam2 &lt;- rnorm(n=sample.size,mean=mu2,sd=sqrt(s2))
    s &lt;- c(sam1,sam2)
    e_mu &lt;- mean(s)
    e_s2 &lt;- var(s)
    c(mean=e_mu,var=e_s2,kurt=sum((s-e_mu)^4)/e_s2^2)
  } 
  #
  ## simulated data, standing for the actual data to be analyzed:  
  set.seed(123)
  Sobs &lt;- myrnorm2(mu1=4,mu2=2,s2=1,sample.size=40) ## 
  #
  ## build reference table
  parsp &lt;- init_reftable(lower=c(mu1=2.8,mu2=1,s2=0.2), 
                         upper=c(mu1=5.2,mu2=3,s2=3))
  parsp &lt;- cbind(parsp,sample.size=40)
  simuls &lt;- add_reftable(Simulate="myrnorm2", parsTable=parsp)
  
  ## Inferring the summary-likelihood surface...
  densvj &lt;- infer_SLik_joint(simuls,stat.obs=Sobs)
  slik_j &lt;- MSL(densvj) ## find the maximum of the log-likelihood surface
  
  ### plots
  # Plot 1: a 1D profile:
  prof1 &lt;- plot1Dprof(slik_j,pars="s2",gridSteps=40,xlabs=list(s2=expression(paste(sigma^2))))
  
  # Using 'add' for comparison of successive profiles:
  slik_2 &lt;- refine(slik_j, n=600)
  # Plot 2: comparing 1D profiles of different iterations:
  prof2 &lt;- plot1Dprof(slik_2,"s2", gridSteps=40,xlabs=list(s2=expression(paste(sigma^2))), 
                      add=prof1$profiles, col="grey30") 
                      
  # Plot 3: using 'decorations' and 'profiles' for recycling previous computation for s2:
  DGpars &lt;- c(mu1=4,mu2=2,s2=1,sample.size=40) # data-generating parameters
  plot1Dprof(slik_2, gridSteps=40,xlabs=list(s2=expression(paste(sigma^2))), 
             profiles=prof2$profiles,
   decorations=function(par) {
      points(y=-7,x=DGpars[par],pch=20,cex=2,col="red");
      points(y=-0.5,x=slik_2$MSL$MSLE[par],pch=20,cex=2,col="blue")
   }
  ) 

  plot2Dprof(slik_j,gridSteps=21,
             ## alternative syntaxes for non-default 'pars':
             # pars = c("mu1","mu2"), # =&gt; all combinations of given elements
             # pars = list("s2",c("mu1","mu2")), # =&gt; combinations via expand.grid()
             # pars = matrix(c("mu1","mu2","s2","mu1"), ncol=2), # =&gt; each row of matrix
             xylabs=list(
               mu1=expression(paste(mu[1])),
               mu2=expression(paste(mu[2])),
               s2=expression(paste(sigma^2))
             )) 
  # One could also add (e.g.) 
  #            cluster_args=list(spec=4, type="FORK"), 
  # when longer computations are requested.
}

if (Infusion.getOption("example_maxtime")&gt;5) {
 #### Older example with primitive workflow 
 data(densv)
 slik &lt;- infer_surface(densv) ## infer a log-likelihood surface
 slik &lt;- MSL(slik) ## find the maximum of the log-likelihood surface
 prof1 &lt;- plot1Dprof(slik,pars="s2",gridSteps=40,xlabs=list(s2=expression(paste(sigma^2)))) 
}

</code></pre>

<hr>
<h2 id='predict.SLik_j'>
Evaluate log-likelihood for given parameters
</h2><span id='topic+predict.SLik_j'></span>

<h3>Description</h3>

<p>As the Title says. As likelihood is obtained as a prediction from a statistical model for the likelihood surface, this has been implemented as a method of the <code>predict</code> generic, for objects created by the up-to-date workflow using gaussian mixture modelling of a joint distribution of parameters and statistics. Hence, it has a <code>newdata</code> argument, as shared by many <code>predict</code> methods; but these <code>newdata</code> should be parameter values, not data). You can use the alternative <code><a href="#topic+summLik">summLik</a></code> extractor if you do not like this syntax.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik_j'
predict(
  object, newdata, log = TRUE, which = "safe", 
  tstat = t(get_from(object,"stat.obs")), 
  solve_t_chol_sigma_lists = object$clu_params$solve_t_chol_sigma_lists, 
  constr_tuning= FALSE,
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.SLik_j_+3A_object">object</code></td>
<td>

<p>an object of class <code>SLik_j</code>, as produced by <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_newdata">newdata</code></td>
<td>

<p>A matrix, whose rows each contain a full vector of the fitted parameters; or a single vector. If parameter names are not provided (as column names in the matrix case), then the vector is assumed to be ordered as <code>object$colTypes$fittedPars</code>.
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_log">log</code></td>
<td>

<p>Boolean: whether to return log-likelihood or likelihood.
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_which">which</code></td>
<td>

<p><code>"safe"</code> or <code>"lik"</code>. The default protects against some artefacts of extrapolation: see Details. 
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_tstat">tstat</code></td>
<td>

<p>The data (as projected summary statistics). Defaults to the data input in the inference procedure (i.e., the projected statistics used as <code>stat.obs</code> argument of <code>infer_SLik_joint</code>). 
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_solve_t_chol_sigma_lists">solve_t_chol_sigma_lists</code></td>
<td>
<p>For programming purposes. Do not change this argument.</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_constr_tuning">constr_tuning</code></td>
<td>
<p>positive number, or FALSE: controls the effect of parameter constraints specified by the <code>constr_crits</code> argument of <code>infer_SLik_joint</code> on the evaluation of summary log-likelihood. When it is <code>FALSE</code> (or 0), no penalty is applied; when this is <code>Inf</code>, the log-likelihood of parameters violating constraints will be <code>-Inf</code>. Intermediate values allow an intermediate penalization (the source code should be consulted for further details), but their use is not recommended. 
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_...">...</code></td>
<td>

<p>For consistency with the generic. Currently ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An  object of class <code>SLik_j</code> contains a simulated joint distribution of parameters and (projected) summary statistics, and a fit of a multivariate gaussian mixture model to this simulated distribution, the &ldquo;jointdens&rdquo;, from which a marginal density &ldquo;pardens&rdquo; of parameters can be deduced. The raw likelihood(P;D) is the probability of the data D given the parameters P, viewed as function the parameters and for fixed data. It is inferred as jointdens(D,P)/pardens(P) (for different P, each of jointdens and pardens are probabilities from a single (multivariate) gaussian mixture model, but this is not so for their ratio). 
</p>
<p>When pardens(P) is low, indicating that the region of parameter space around P has been poorly sampled in the reference table, inference of likelihood in such regions is unreliable. Spuriously high likelihood may be inferred, which results notably in poor inference based on likelihood ratios. For this reason, it is often better to use the argument  <code>which="safe"</code> whereby the likelihood may be penalized where pardens(P) is low. The penalization is applied to cases where the uncorrected likelihood is higher than the maximum one in the reference table, and pardens(P) is lower than a threshold also determined from the reference table. The source code should be consulted for further details.  
</p>


<h3>Value</h3>

<p>Numeric: a single value, or a vector of (log-)likelihoods for different rows of the input <code>newdata</code>. When <code>which="safe"</code>, a <code>"lowdens"</code> attribute will be added when at least on parameter points had a low &ldquo;pardens&rdquo; (see Details).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see help("example_reftable")
</code></pre>

<hr>
<h2 id='profile.SLik'>
Compute profile summary likelihood 
</h2><span id='topic+profile.SLik'></span><span id='topic+profile.SLik_j'></span><span id='topic+profile'></span>

<h3>Description</h3>

<p>Predicts the profile likelihood for a given parameter value (or vector of such values) using predictions from an <code>SLik_j</code> (or older <code>SLik</code>) object (as produced by <code><a href="#topic+MSL">MSL</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik_j'
profile(fitted, value, fixed=NULL, return.optim=FALSE, 
        init = "default", which="safe", 
        constr_crits=fitted$constr_crits, 
        eq_constr=NULL, ...)
## S3 method for class 'SLik'
profile(fitted, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="profile.SLik_+3A_fitted">fitted</code></td>
<td>
<p>an <code>SLik</code> object.</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_value">value</code></td>
<td>

<p>The parameter value (as a vector of named values) for which the profile is to be computed. Setting in explictly to NULL will maximize likelihood subject only to optional constraints specified by other arguments.
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_fixed">fixed</code></td>
<td>
<p>This argument appears redundant with the <code>value</code> argument, so it will be deprecated and its use should be avoided. When it is non-<code>NULL</code>, the profile is computed for <code>value</code> updated to <code>c(value, fixed)</code>.
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_return.optim">return.optim</code></td>
<td>
<p>If this is TRUE, and if maximization of likelihood given <code>value</code> and <code>fixed</code> is indeed required, then the full result of the optimization call is returned.</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_constr_crits">constr_crits</code></td>
<td>

<p>Inequality constraints, by default those provided in the first iteration of the workflow, if any. See <code><a href="#topic+constr_crits">constr_crits</a></code> for details. 
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_eq_constr">eq_constr</code></td>
<td>

<p>Optional equality constraints, provided in the same format as <code><a href="#topic+constr_crits">constr_crits</a></code> (<b>This feature is experimental</b>: in particular the procedure for finding initial values for maximization of likelihood does not use the <code>eq_constr</code> information). 
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_...">...</code></td>
<td>

<p>For <code>SLik_j</code> method, arguments passed to <code>SLik</code> method.
For <code>SLik_j</code> method, currently not used.
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_init">init</code></td>
<td>
<p>Better ignored. Either a named vector of parameter values (initial value for some optimizations) or a character string. The default is to call a procedure to find a good initial point from a set of candidates. The source code should be consulted for further details and is subject to change without notice.</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_which">which</code></td>
<td>
<p>Better ignored (for development purpose).</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>If <code>return.optim</code> is FALSE (default): the predicted summary profile log-likelihood, with possible attribute <code>"solution"</code>, the optimization solution vector (named numeric vector, missing if no profiling was needed). if <code>return.optim</code> is TRUE, the result of an optimization call, a list including elements <code>solution</code> (solution vector) and <code>objective</code> (log-likelihood). 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+example_reftable">example_reftable</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## see e.g. 'example_reftable' documentation
</code></pre>

<hr>
<h2 id='project.character'>
Learn a projection method for statistics and apply it 
</h2><span id='topic+project'></span><span id='topic+project.character'></span><span id='topic+project.default'></span><span id='topic+get_projector'></span><span id='topic+get_projection'></span><span id='topic+deforest_projectors'></span><span id='topic+neuralNet'></span>

<h3>Description</h3>

<p><code>project</code> is a generic function with two methods. If the first argument is a parameter name, 
<code>project.character</code> (alias: <code>get_projector</code>) defines a projection function from several statistics to an output statistic predicting  
this parameter. <code>project.default</code>  (alias: <code>get_projection</code>) produces a vector of projected statistics using such a projection. <code>project</code> is particularly useful to reduce a large number of summary statistics to a vector of projected summary statistics, with as many elements as parameters to infer. This dimension reduction can substantially speed up subsequent computations. 
The concept implemented in <code>project</code> is to fit a parameter to the various statistics available, using machine-learning or mixed-model prediction methods. All such methods can be seen as nonlinear projection to a one-dimensional space. <code>project.character</code> is an interface that allows different projection methods to be used, provided they return an object of a class that has a defined <code>predict</code> method with a <code>newdata</code> argument.
</p>
<p><code>deforest_projectors</code> is an utility to reduce the saved size of objects containing <span class="pkg">ranger</span> objects (<code><a href="#topic+reproject">reproject</a></code> can be used to reverse this). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>project(x,...)

## S3 method for building the projection 
## S3 method for class 'character'
project(x, stats, data, 
             trainingsize=  eval(Infusion.getOption("trainingsize")),
             train_cP_size= eval(Infusion.getOption("train_cP_size")), method, 
             methodArgs=eval(Infusion.getOption("proj_methodArgs")), 
             verbose=TRUE, keep_data=TRUE, ...)
get_projector(...) # alias for project.character

## S3 method for applying the projection
## Default S3 method:
project(x, projectors, use_oob=Infusion.getOption("use_oob"), 
                          is_trainset=FALSE, methodArgs=list(), ext_projdata, ...)
get_projection(...) # alias for project.default

##
deforest_projectors(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="project.character_+3A_x">x</code></td>
<td>

<p>The name of the parameter to be predicted, or a vector/matrix/list of matrices of summary statistics.  
</p>
</td></tr>
<tr><td><code id="project.character_+3A_stats">stats</code></td>
<td>

<p>Statistics from which the predictor is to be predicted 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_use_oob">use_oob</code></td>
<td>

<p>Boolean: whether to use out-of-bag predictions for data used in the training set, when such oob predictions are available (i.e. for random forest methods). Default as controlled by the same-named package option, is TRUE. This by default involves a costly check on each row of the input <code>x</code>, whether it belongs to the training set, so it is better to set it to FALSE if you are sure <code>x</code> does not belong to the training set (for true data in particular). Alternatively the check can be bypassed if you are sure that <code>x</code> was used as the training set.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_is_trainset">is_trainset</code></td>
<td>

<p>Boolean. In a <code>project</code> call, set it to TRUE if <code>x</code> was used as the training set, to bypass a costly check (see <code>use_oob</code> argument). The same logic may apply in a <code>plot_proj</code> call, except that it is not immediately obvious for users whether the full reference table in an <code>object</code> was used as the training set, so trying to save time by setting <code>is_trainset=TRUE</code> requires more insight.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_data">data</code></td>
<td>

<p>A list of simulated empirical distributions, as produced by <code><a href="#topic+add_simulation">add_simulation</a></code>, or a data frame with all required variables.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_trainingsize">trainingsize</code>, <code id="project.character_+3A_train_cp_size">train_cP_size</code></td>
<td>
<p> Integers;
for most projection methods (excluding <code>"REML"</code> but including <code>"ranger"</code>) only  <code>trainingsize</code> is taken into account: it gives the maximum size of the training set (and is infinite by default for <code>"ranger"</code> method). If the <code>data</code> have more rows the training set is randomly sampled from it. For the <code>"REML"</code> method, <code>train_cP_size</code> is the maximum size of the data used for estimation of smoothing parameters, and <code>trainingsize</code> is the maximum size of the data from which the predictor is built given the smoothing parameters.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_method">method</code></td>
<td>

<p>character string: <code>"REML"</code>, <code>"GCV"</code>, or the name of a suitable projection function. The latter may be defined in another package, e.g. <code>"ranger"</code> or <code>"randomForest"</code>, or predefined by <code style="white-space: pre;">&#8288;Infusion&#8288;</code>, or defined by the user. See Details for predefined functions and for defining new ones. The default method is <code>"ranger"</code> if this package is installed, and <code>"REML"</code> otherwise. Defaults may change in later versions, so it is advised to provide an explicit <code>method</code> to improve reproducibility. 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_methodargs">methodArgs</code></td>
<td>

<p>A list of arguments for the projection method. For <code>project.character</code>, the <code>ranger</code> method is run with some default argument if no <code>methodArgs</code> are specified. Beware that a NULL <code>methodArgs$splitrule</code> is interpreted as the <code>"extratrees"</code> <code>splitrule</code>, whereas in a direct call to <code>ranger</code>, this would be interpreted as the <code>"variance"</code> <code>splitrule</code>. For <code>project.default</code>, the only <code>methodArgs</code> element handled is <code>num.threads</code> passed to <code>predict.ranger</code> (which can also be controlled globally by <code>Infusion.options(nb_cores=.)</code>).   
</p>
<p>For other methods, <code>project</code> kindly (tries to) assign values to the required arguments if they are absent from <code>methodArgs</code>, according to the following rules:
</p>
<p>If <code>"REML"</code> or <code>"GCV"</code> methods are used (in which case <code>methodArgs</code> is completely ignored); or
</p>
<p>if the projection method uses <code>formula</code> and <code>data</code> arguments (in particular if the formula is of the form 
<code>response ~ var1 + var2 + ...</code>; otherwise the formula should be provided through <code>methodArgs</code>). This works 
for example for methods based on <code>nnet</code>; or
</p>
<p>if the projection method uses <code>x</code> and <code>y</code> arguments. This works for example for the (somewhat obsolete) method <code>randomForest</code> (though not with the generic function <code>method="randomForest"</code>, but only with the internal function 
<code>method="randomForest:::randomForest.default"</code>).
</p>
</td></tr>
<tr><td><code id="project.character_+3A_projectors">projectors</code></td>
<td>

<p>A list with elements of two possible forms: (1) <code>&lt;name&gt;=&lt;project result&gt;</code>, where the <code>&lt;name&gt;</code> must differ from any name of <code>x</code> and <code>&lt;project result&gt;</code> is the return object of a <code>project</code> call; or (2) <code>&lt;name&gt;=NULL</code> where <code>&lt;name&gt;</code> is the name of a variable (raw summary statistic) in <code>x</code> (such explicit NULLs are <b>needed</b> for any raw statistic to be retained in the projected data; see Value). 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not. In particular, <code>TRUE</code>, true-vs.-predicted diagnostic plots will be drawn for projection methods &ldquo;known&rdquo; by Infusion (notably <code>"ranger"</code>, <code>"fastai.tabular.learner.TabularLearner"</code>, <code>"keras::keras.engine.training.Model"</code>, <code>"randomForest"</code>, <code>"GCV"</code>, <code>caret::train</code>).
</p>
</td></tr>
<tr><td><code id="project.character_+3A_keep_data">keep_data</code>, <code id="project.character_+3A_ext_projdata">ext_projdata</code></td>
<td>

<p>(experimental, and only when <span class="pkg">ranger</span> is used). Setting <code>keep_data=FALSE</code> allows the input data to be removed from the return object of <code>project.character</code> (where they are otherwise part of its <code>call</code> element). This may be useful to save memory when multiple projections are based on the same data. However, as this data information is sometimes used, it must then be manually added as element <code>projdata</code> to the return value of <code>infer_SLik_joint</code>, and provided to <code>project.default</code> calls through the <code>ext_projdata</code> argument.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_object">object</code></td>
<td>

<p>An object of class <code>SLik_j</code>.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other functions. Currently, they are passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The preferred <code>project</code> method is non-parametric regression by (variants of) the random forest method as implemented in <span class="pkg">ranger</span>. It is the default method, if that package is installed. Alternative methods have been interfaced as detailed below, but the functionality of most interfaces is infrequently tested. 
</p>
<p>By default, the ranger call through <code>project</code> will use the split rule <code>"extratrees"</code>, with some other controls also differing from the <span class="pkg">ranger</span> package defaults. If the split rule <code>"variance"</code> is used, the default value of <code>mtry</code> used in the call is also distinct from the <span class="pkg">ranger</span> default, but consistent with Breiman 2001 for regression tasks. 
</p>
<p>Machine learning methods such as random forests overfit, <em>except if</em> out-of-bag predictions are used. When they are not, the bias is manifest in the fact that using the same simulation table for learning the projectors and for other steps of the analyses tend to lead to too narrow confidence regions. This bias disappears over iterations of <code><a href="#topic+refine">refine</a></code> when the projectors are kept constant. <code>Infusion</code> avoid this bias by using out-of-bag predictions when relevant, when <code>ranger</code> and <code>randomForest</code> are used. But it provides no code handling that problem for other machine-learning methods. Then, users should cope with that problems, and at a minimum should not update projectors in every iteration (the &ldquo;<a href="https://gitlab.mbb.univ-montp2.fr/francois/Infusion/-/blob/master/documents/InfusionIntro.pdf">Gentle Introduction to Infusion</a> may contain further information about this problem&rdquo;).       
</p>
<p>Prediction can be based on a linear mixed model (LMM) with autocorrelated random effects,
internally calling the <code><a href="spaMM.html#topic+fitme">fitme</a></code> function with formula
<code>&lt;parameter&gt; ~ 1+ Matern(1|&lt;stat1&gt;+...+&lt;statn&gt;)</code>. This approach allows in principle to produce arbitrarily 
complex predictors (given sufficient input) and avoids overfitting in the same way as restricted likelihood methods avoids overfitting in LMM. REML methods are then used by default to estimate the smoothing parameters. However, faster methods are generally required.
</p>
<p>To keep REML computation reasonably fast, the <code>train_cP_size</code> and <code>trainingsize</code> arguments determine respectively the size of the subset used to estimate the smoothing parameters and the size of the subset defining the predictor given the smoothing parameters.  REML fitting is already slow for data sets of this size (particularly as the number of predictor variables increase).
</p>
<p>If <code>method="GCV"</code>, a generalized cross-validation procedure (Golub et al. 1979) is used to estimate the smoothing parameters. This is faster but still slow, so a random subset of size <code>trainingsize</code> is still used to estimate the smoothing parameters and generate the predictor.
</p>
<p>Alternatively, various machine-learning methods can be used (see e.g. Hastie et al., 2009,  for an introduction). A random subset of size <code>trainingsize</code> is again used, with a larger default value bearing the assumption that these methods are faster. Predefined methods include
</p>

<ul>
<li> <p><code>"ranger"</code>, the default, a computationally efficient implementation of random forest;
</p>
</li>
<li> <p><code>"randomForest"</code>, the older default, probably obsolete now;
</p>
</li>
<li> <p><code>"neuralNet"</code>, a neural network method, using  the <code>train</code> function from the <code>caret</code> package (probably obsolete too);
</p>
</li>
<li> <p><code>"fastai"</code> deep learning using the <code>fastai</code> package;
</p>
</li>
<li> <p><code>"keras"</code> deep learning using the <code>keras</code> package.
</p>
</li></ul>

<p>The last two interfaces may yet offer limited or undocumented control: using deep learning seems attractive but the benefits over <code>"ranger"</code> are not clear (notably, the latter provide out-of-bag predictions that avoid overfitting).   
</p>
<p>In principle, any object suitable for prediction could be used as one of the <code>projectors</code>, and <code>Infusion</code> implements their usage so that in principle unforeseen projectors could be used. That is, if predictions of a parameter can be performed using an object <code>MyProjector</code> of class <code>MyProjectorClass</code>, 
<code>MyProjector</code> could be used in place of a <code>project</code> result 
if <code>predict.MyProjectorClass(object,newdata,...)</code> is defined. However, there is no guarantee that this will work on unforeseen projection methods, as each method tends to have some syntactic idiosyncrasies. For example, if the learning method that generated the projector used
a formula-data syntax, then its <code>predict</code> method is likely to request names for its <code>newdata</code>, that need to be provided through <code>attr(MyProjector,"stats")</code> (these names cannot be assumed to be in the <code>newdata</code> when <code>predict</code> is called through <code>optim</code>). 
</p>


<h3>Value</h3>

<p><code>project.character</code> returns an object of the class returned by the called <code>method</code> (by default, a <code>ranger</code> object for the up-to-date workflow).
</p>
<p><code>project.default</code> returns an object of the same class and structure as the input <code>x</code>, containing the variables named in the <code>projectors</code> argument, each variable being a projected statistics inferred from the input summary statistics, or a summary statistic copied from the input <code>x</code> (if an <b>explicit</b> NULL projector was included for this statistic in the <code>projectors</code> argument).
</p>
<p><code>deforest_projectors</code> is used for its side effect  (the contents of an environment within the input object been modifed), and returns a character string emphasizing this feature.
</p>


<h3>Note</h3>

<p>See workflow examples in <code><a href="#topic+example_reftable">example_reftable</a></code> and <code><a href="#topic+example_raw_proj">example_raw_proj</a></code>.</p>


<h3>References</h3>

<p>Breiman, L. (2001). Random forests. Mach Learn, 45:5-32. &lt;doi:10.1023/A:1010933404324&gt;
</p>
<p>Golub, G. H., Heath, M. and Wahba, G. (1979) Generalized Cross-Validation as a method for choosing a good ridge parameter. 
Technometrics 21: 215-223.
</p>
<p>T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning: Data Mining, Inference,
and Prediction. Springer, New York, 2nd edition, 2009.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot_proj">plot_proj</a></code> and <code><a href="#topic+plot_importance">plot_importance</a></code> for diagnostic plots of the projections.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='refine'>
Refine estimates iteratively    
</h2><span id='topic+refine'></span><span id='topic+refine.default'></span><span id='topic+refine.SLik'></span><span id='topic+refine.SLik_j'></span><span id='topic+refine.SLikp'></span><span id='topic+reproject'></span><span id='topic+recluster'></span>

<h3>Description</h3>

<p><code>refine</code> is a generic function with methods for objects of the classes produced by <code><a href="#topic+MSL">MSL</a></code>. In the up-to-date workflow, it can automatically (1) define new parameters points, (2) add simulations to the reference table for these points, (3) optionally recompute projections, (4) update the inference of the likelihood surface, and (5) provides new point estimates, confidence intervals, and other results of an <code><a href="#topic+MSL">MSL</a></code> call. It can repeat these steps iteratively as controlled by its <code>workflow_design</code>. 
Although it has many control arguments, few of them may be needed in any application. In particular it is designed to use reasonable default controls for the number of iterations, the number of points added in each iteration, and whether to update projections or not, when given only the current fit object as input.
</p>
<p><code>reproject</code> and <code>recluster</code> are wrappers for <code>refine(..., ntot=0L)</code>, updating the object after either recomputing the projections or only re-performing the multivariate gaussian mixture clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
refine(object, method=NULL, ...)
## Default S3 method:
refine(
    object, 
    ##       reference table simulations  
    Simulate = attr(surfaceData,"Simulate"),
    control.Simulate = attr(surfaceData,"control.Simulate"),
    newsimuls = NULL,
    ##       CIs
    CIs = workflow_design$reftable_sizes[useCI], 
    useCI = prod(dim(object$logLs))&lt;12000L, level = 0.95,
    ##       workflow design
    workflow_design = get_workflow_design(
        npar=length(fittedPars), n_proj_stats = length(statNames),
        n_latent=length(latentVars)), 
    maxit, ntot= maxit*.get_size_first_iter(object), n=NULL,
    ##       termination conditions 
    precision = Infusion.getOption("precision"),
    eval_RMSEs = workflow_design$reftable_sizes,
    ##       verbosity
    verbose = list(notable=TRUE, most=interactive(),final=NULL, movie=FALSE,
                 proj=FALSE, rparam=NULL, progress_bars=interactive()),
    ##       projection controls
    update_projectors = NULL,
    methodArgs = list(),
    ##       Likelihood surface modeling (up-to-date workflow)
    using = object$using, 
    nbCluster = quote(refine_nbCluster(nr=nrow(data))),
    ##       parallelisation
    cluster_args = list(), nb_cores=NULL, env=get_from(object,"env"), 
    packages = get_from(object,"packages"), cl_seed=.update_seed(object),
    ##       obscure stuff
    target_LR = NULL,  
    ##       not explicitly needed in up-to-date workflow
    trypoints = NULL,
    surfaceData, 
    method, 
    useEI = list(max=TRUE,profileCI=TRUE,rawCI=FALSE),
    rparamFn = Infusion.getOption("rparamFn"),
    ## 
    ... 
)
            
reproject(object, eval_RMSEs = NULL, CIs = NULL, ...)
recluster(object, eval_RMSEs = NULL, CIs = NULL, update_projectors=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="refine_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object
</p>
</td></tr>
</table>
<p><b>## reference table simulations</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_simulate">Simulate</code></td>
<td>

<p>Character string: name of the function used to simulate samples. As it is typically stored in the object this argument does not need to be explicitly given; otherwise this should be the same function provided to <code><a href="#topic+add_reftable">add_reftable</a></code>, whose documentation details the design requirements. The only meaningful non-default value is <code>NULL</code>, in which case <code>refine</code> may return (if <code>newsimuls</code> is also <code>NULL</code>) a data frame of parameter points on which to run a simulation function.
</p>
</td></tr>
<tr><td><code id="refine_+3A_control.simulate">control.Simulate</code></td>
<td>

<p>A list of arguments of the <code>Simulate</code> function (see <code><a href="#topic+add_simulation">add_simulation</a></code>). The default value should be used unless you understand enough of its structure to modify it wisely (e.g., it may contain the path of an executable on one machine and a different path may be specified to refine a fit on another machine).  
</p>
</td></tr>
<tr><td><code id="refine_+3A_newsimuls">newsimuls</code></td>
<td>

<p>For the <code>SLik_j</code> method, a matrix or data frame, with the same parameters and summary statistics as the <code>data</code> of the original <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> call.
</p>
<p>For other methods, a <code>list</code> of simulation of distributions of summary statistics, in the same format as for <code>link{add_simulation}</code>. 
If no such list is provided (i.e., if <code>newsimuls</code> remains <code>NULL</code>), the function extracted by <code>get_from(object,"Simulate")</code> is used (it is inherited from the <code>Simulate</code> 
argument of <code><a href="#topic+add_simulation">add_simulation</a></code> through the initial sequence of calls of functions <code>add_simulation</code>,
<code>infer_logLs</code> or <code>infer_tailp</code>, and <code>infer_surface</code>). If no such function is available, then this function returns parameters for which new distribution should be provided by the user.
</p>
</td></tr>
</table>
<p><b>## CIs</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_cis">CIs</code></td>
<td>

<p>Boolean, or boolean vector, or numeric (preferably integer) vector: controls to infer bounds of (one-dimensional, profile) confidence intervals. The numeric vector form allows to specify reference table size(s) for which CIs should be computed when these sizes are first reached. TRUE or FALSE will force or inhibit computation in all iterations. Finally (and probably less useful), a boolean vector such as <code>CIs=c(TRUE,FALSE,TRUE)</code> requests computation of CIs when the number of points cumulatively added reaches the target number of points for the first, third, and any subsequent iterations up to <code>maxit</code> (this may differ in certain cases from the first, third, and so on, iterations: see Details).  
</p>
<p>The default for <code>refine</code> is described in the Details. The default for <code>reproject</code> is to update the CIs if there are computed ones within the input <code>object</code>.
</p>
</td></tr>
<tr><td><code id="refine_+3A_useci">useCI</code></td>
<td>

<p>whether to perform RMSE computations for inferred confidence interval points.
</p>
</td></tr>
<tr><td><code id="refine_+3A_level">level</code></td>
<td>

<p>Intended coverage of confidence intervals 
</p>
</td></tr>
</table>
<p><b>## workflow design</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_workflow_design">workflow_design</code></td>
<td>

<p>A list structured as the return value of <code><a href="#topic+get_workflow_design">get_workflow_design</a></code>. The default value makes reference to elements of the input object's <code>colTypes</code> element.</p>
</td></tr>
<tr><td><code id="refine_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of iterative refinements (see also <code>precision</code> argument).
</p>
</td></tr>
<tr><td><code id="refine_+3A_ntot">ntot</code></td>
<td>

<p>NULL or numeric: control of the total number of simulated samples (one for each new parameter point) to be added to the reference table over the <code>maxit</code> iterations.  See Details for the rules used to determine the number of points added in each iteration. Reasonable default values are defined for <code>ntot</code> and <code>maxit</code> (see Details), so that beginners (and ideally, even more advanced users) do not have to find good values.
</p>
<p><code>ntot=0L</code> may be used to re-generate the projectors or the clustering without augmenting the reference table.
</p>
</td></tr>
<tr><td><code id="refine_+3A_n">n</code></td>
<td>

<p>NULL or numeric, for a number of parameter points (excluding replicates and confidence interval points in the primitive workflow), whose likelihood should be computed in each iteration 
(see <code>n</code> argument of <code><a href="#topic+sample_volume">sample_volume</a></code>). Slightly less intutive alternative to <code>ntot</code> specification, as there is at least one iteration where the actual number of added points is not the nominal <code>n</code> (see Details).   
<code>n=0L</code> will have the same effect as <code>ntot=0L</code>.
</p>
</td></tr>
</table>
<p><b>## termination conditions</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_precision">precision</code></td>
<td>

<p>Requested local precision of surface estimation, in terms of prediction standard errors (RMSEs) of both the maximum summary log-likelihood and the likelihood ratio at any CI bound available. Iterations will stop when either <code>maxit</code> is reached, or if the RMSEs have been computed for the object (see <code>eval_RMSEs</code> argument) and this precision is reached for the RMSEs.
A given precision on the CI bounds themselves might seem more interesting, but is not well specified by a single precision parameter if the parameters are on widely different scales.
</p>
</td></tr>
<tr><td><code id="refine_+3A_eval_rmses">eval_RMSEs</code></td>
<td>
<p>Same usage as for <code>CIs</code>; controls the <code>eval_RMSEs</code> argument of <code><a href="#topic+MSL">MSL</a></code> in each iteration. See Details for the default. 
The default for <code>reproject</code> is to update the RMSEs if there are computed ones within the input <code>object</code>.</p>
</td></tr>
</table>
<p><b>## verbosity</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_verbose">verbose</code></td>
<td>
<p> A list as shown by the default, or simply a vector of booleans. <code>verbose$most</code> controls whether to display information about progress and results, except plots; <code>$final</code> controls whether to <code>plot()</code> the final <code>object</code> to show the final likelihood surface. Default is to plot it only in an interactive session and if fewer than three parameters are estimated; <code>$movie</code> controls whether to <code>plot()</code> the updated <code>object</code> in each iteration; <code>verbose$proj</code> controls the <code>verbose</code> argument of <code><a href="#topic+project.character">project.character</a></code>; <code>verbose$rparam</code> controls (cryptic) information about generation of new parameter points; <code>verbose$progress_bars</code> controls display of some progress bars. If <code>verbose</code> is an unnamed vector of booleans, they are interpreted as as-many first elements of the<code>verbose</code> vector, in the order shown by the default. 
</p>
</td></tr>
</table>
<p><b>## projection controls</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_update_projectors">update_projectors</code></td>
<td>
<p>Same usage as for <code>CIs</code>; this controls in which iterations the projectors are updated. The default <code>NULL</code> value is strongly recommended. See Details for further explanations.</p>
</td></tr>
<tr><td><code id="refine_+3A_methodargs">methodArgs</code></td>
<td>
<p>A list of arguments for the projection method. By default the <code>methodArgs</code> of the original <code><a href="#topic+project.character">project.character</a></code> calls are reused over iteration, but elements of the new <code>methodArgs</code> list will be used to update the original <code>methodArgs</code>. Note that the updated list becomes the new default for further iterations.</p>
</td></tr>
</table>
<p><b>## Likelihood surface modeling</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_using">using</code></td>
<td>
<p>Passed to <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>: a character string used to control the joint-density estimation method, as documented for that function (see <code>method</code> instead for equivalent control in primitive workflow). Default is to use to same method as in the the first iteration, but this argument allows a change of method.</p>
</td></tr>
<tr><td><code id="refine_+3A_nbcluster">nbCluster</code></td>
<td>
<p>Passed to <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>. The <code>data</code> in the expression for the default value refers to the <code>data</code> argument of the latter function.</p>
</td></tr>
</table>
<p><b>## parallelisation</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments for <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, in addition to <code>makeCluster</code>'s <code>spec</code> argument which is in most cases best specified by the <code>nb_cores</code> argument. Cluster arguments allow independent control of parallel computations for the different steps of a <code>refine</code> iteration (see Details; as a rough but effective summary, use only <code>nb_cores</code> when the simulations support it, and see the <code>methodArgs</code> argument if independent control of parallelisation of the projection procedure is needed).</p>
</td></tr>
<tr><td><code id="refine_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Integer: shortcut for specifying <code>cluster_args$spec</code> for sample simulation.</p>
</td></tr>
<tr><td><code id="refine_+3A_packages">packages</code></td>
<td>
<p>NULL or a list with possible elements <code>add_simulation</code> and <code>logL_method</code> (the latter for the primitive workflow). These elements should be formatted as the <code>packages</code> arguments of <code>add_simulation</code> and <code>infer_logLs</code>, respectively, wherein they are the additional packages to be loaded on child processes. The effect of the default value of this argument is to pass over successive <code>refine</code> calls the value stored in the input fit object (itself determined by the latest use of the <code>packages</code> argument in, e.g., <code>add_simulation</code> or in previous <code>refine</code>s).</p>
</td></tr>
<tr><td><code id="refine_+3A_env">env</code></td>
<td>
<p>An environment, passed as the <code>env</code> argument to <code>add_simulation</code>. The default value keeps the pre-<code>refine</code> value over iterations.</p>
</td></tr>
<tr><td><code id="refine_+3A_cl_seed">cl_seed</code></td>
<td>
<p>NULL or integer, passed to <code>add_simulation</code>. The default code uses an internal function, <code>.update_seed</code>, to update it from a previous iteration.</p>
</td></tr>
</table>
<p><b>## others</b>
</p>
<table role = "presentation">
<tr><td><code id="refine_+3A_target_lr">target_LR</code></td>
<td>
<p>Likelihood ratio threshold used to control the sampling of new points and the selection of points for projections. Do not change it unless you known what you are doing.</p>
</td></tr>
<tr><td><code id="refine_+3A_method">method</code></td>
<td>
<p>For the primitive workflow: (a vector of) suggested method(s) for estimation of smoothing parameters (see <code>method</code> argument of <code><a href="#topic+infer_surface">infer_surface</a></code>). The ith element of the vector is
used in the ith iteration, if available; otherwise the last element is used. This argument is not always heeded, in that REML may be used if the suggested method is GCV but it appears to perform poorly. The default for <code>SLikp</code> and <code>SLikp</code> objects are <code>"REML"</code> and <code>"PQL"</code>, respectively. 
</p>
</td></tr>
<tr><td><code id="refine_+3A_trypoints">trypoints</code></td>
<td>

<p>A data frame of parameters on which the simulation function <code>get_from(object,"Simulate")</code> should be called to extend the reference table. Only for programming by expert users, because poorly thought input <code>trypoints</code> could severely affect the inferences.     
</p>
</td></tr>
<tr><td><code id="refine_+3A_useei">useEI</code></td>
<td>

<p>for the primitive workflow only: cf this argument in <code><a href="#topic+rparam">rparam</a></code>.
</p>
</td></tr>
<tr><td><code id="refine_+3A_surfacedata">surfaceData</code></td>
<td>

<p>for the primitive workflow only: a data.frame with attributes, usually taken from the <code>object</code> and thus <b>not</b> specified by user, usable as input for <code><a href="#topic+infer_surface">infer_surface</a></code>.  
</p>
</td></tr>
<tr><td><code id="refine_+3A_rparamfn">rparamFn</code></td>
<td>

<p>Function used to sample new parameter values.
</p>
</td></tr>
<tr><td><code id="refine_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods. <code>refine</code> passes these arguments to the <code>plot</code> method suitable for the <code>object</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code> * </code><b>Controls of exploration of parameter space</b>: New parameter points are sampled so as to fill the space of parameters contained in the confidence regions defined by the <code>level</code> argument, and to surround it by a region sampled proportionally to likelihood. 
</p>
<p>Each <code>refine</code> call performs several iterations, these iterations stopping when <code>ntot</code> points have been added to the simulation table. The target number of points potentially added in each iteration is controlled by the <code>ntot</code> and <code>maxit</code> arguments as described below, but fewer points may be actually added in each iteration, and more than <code>maxit</code> iterations may be needed to add the <code>ntot</code> points, if in a given iteration too few &ldquo;good&rdquo; candidate points are generated according to the internal rules for sampling the parameter region with high likelihood.  In that case, the next iteration tries to keep up with the missing points by adding more points than the target number, but if not enough points have been added after <code>maxit</code> iterations, further iterations will be run. 
</p>
<p>CIs and RMSEs may be computed in any iteration but the default values of <code>eval_RMSEs</code> and <code>CIs</code> are chosen so as to avoid performing these computations too often, particularly when they are expected to be slow. The default implies that the RMSE for the maximum logL will be computed at the end each block of iterations that defines a refine (itself defined to reach to reference table sizes specified by the <code>workflow_design</code> and its default value). If the reference table is not too large (see default value of <code>useCI</code> for the precise condition), RMSEs of the logL are also computed at the inferred bounds of profile-based confidence intervals for each parameter. 
</p>
<p>Although the <code>update_projectors</code> argument allow similar control of the iterations where projections are updated, it is advised to keep it NULL (default value), so that whether projectors are updated in a given iteration is controlled by default internal rules. Setting it to <code>TRUE</code> would induce updating whenever any of the target reference table sizes implied by the <code>workflow_design$subblock_sizes</code> is reached. The default <code>NULL</code>, as the same effect subject to additional conditions: updating may not be performed when the training set is considered too similar to the one used to compute pre-existing projections, or when the train set includes more samples than the limit define by the global package option <code>upd_proj_subrows_thr</code>
</p>
<p>Default values of <code>ntot</code> and <code>maxit</code> are controlled by the value of the <code>workflow_design</code>, which itself has the shown default value, and are distinct for the first vs. subsequent <code>refine</code>s. 
The target number of points in each iteration is also controlled differently for the first vs. subsequent <code>refine</code>s. This design is motivated by the fact that the likelihood surface is typically poorly inferred in the first refine so that the parameter points sampled then tend to be less relevant than those that can be sampled in later iterations. In the first <code>refine</code> call, the target number of points increases roughly as powers of two over iterations, to reach <code>ntot</code> cumulatively after <code>maxit</code> iterations. The default <code>ntot</code> is twice the size of the initial reference table, and the default <code>maxit</code> is 5. The <code><a href="#topic+example_reftable">example_reftable</a></code> Example illustrates this, where the initial reference table holds 200 simulations, and the default target number of points to be added in 5 iterations by the first <code>refine</code> call are 25, 25, 50, 100 and 200.  In later <code>refine</code> calls, the target number is <code>ntot/maxit</code> in each iteration.
</p>
<p><code> * </code>Independent <b>control of parallelisation</b> may be needed in the different steps, e.g. if the simulations are not easily parallelised whereas the projection method natively handles parallelisation. In the up-to-date workflow with default <code>ranger</code> projection method, distinct parallelisation controls may be passed to <code>add_reftable</code> for sample simulations, to <code>project</code> methods when projections are updated, and to <code>MSL</code> for RMSE computations (alternatively for the primitive workflow, <code>add_simulation</code>, <code>infer_logLs</code> and <code>MSL</code> are called). 
The most explicit way of specifying distinct controls is by a list structured as </p>
<pre>
cluster_args=list(reftable=list(&lt;makeCluster arguments&gt;),
                  RMSEs=list(&lt;makeCluster arguments&gt;))
</pre> 
<p>A <code>project=list(num.threads=&lt;.&gt;)</code> element can be added to this list, providing control of the <code>num.threads</code> argument of <span class="pkg">ranger</span> functions. However, this is retained mainly for back compatibility as the <code>methodArgs</code> argument can now be used to specify the <code>num.threads</code>.
</p>
<p>Simpler arguments may be used and will be interpreted as follows: <code>nb_cores</code>, if given and not overriden by a <code>spec</code> argument in <code>cluster_args</code> (or in sublists of it), will control simulation and projection steps (but not RMSE computation): that is, <code>nb_cores</code> then gives the number of parallel processes for sample simulation, with additional <code>makeCluster</code> arguments taken from <code>cluster_args</code>, but RMSE computations are performed serially. On the other hand, a <code>spec</code> argument in
<code>cluster_args=list(spec=&lt;.&gt;, &lt;other makeCluster arguments&gt;))</code> will instead apply the same arguments to both reference table and RMSE computation, overcoming the default effect of <code>nb_cores</code> in both of them.
</p>


<h3>Value</h3>

<p><code>refine</code> returns an updated <code>SLik</code> or <code>SLik_j</code> object, unless both <code>newsimuls</code> and <code>Simulate</code> arguments are NULL, in which case a data frame of parameter points is returned.
</p>


<h3>Note</h3>

<p>See workflow examples in (by order of decreasing relevance) <code><a href="#topic+example_reftable">example_reftable</a></code>, <code><a href="#topic+example_raw_proj">example_raw_proj</a></code> and <code><a href="#topic+example_raw">example_raw</a></code>.
</p>
<p>See <code><a href="#topic+get_workflow_design">get_workflow_design</a></code>, the function that controls 
the default value of the <code>workflow_design</code> argument, and can be used to provide non-default controls.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='reparam_fit'>
Conversion to new parameter spaces
</h2><span id='topic+reparam_fit'></span><span id='topic+reparam_reftable'></span>

<h3>Description</h3>

<p>Functions to facilitate inferences using alternative parametrizations of the same model, reusing an existing reference table. <code>reparam_reftable</code> produces a reference table in the new parametrization.  <code>reparam_fit</code> does the same internally, and runs <code>infer_SLik_joint</code> and <code>MSL</code> on the new reference table. 
</p>
<p><code>reparam_fit</code> is <b>experimental</b> and may have various limitations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reparam_fit(fitobject, to, reparamfn, 
             LOWER=NULL, UPPER=NULL, nbCluster="max", 
             constr_crits = get_from(fitobject, "constr_crits"),
             raw=FALSE, 
             
             reftable_attrs=NULL,
             ...)
reparam_reftable(fitobject, to, reparamfn, 
             LOWER=NULL, UPPER=NULL, raw=FALSE, reftable_attrs=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reparam_fit_+3A_fitobject">fitobject</code></td>
<td>

<p>an object of class <code>SLik_j</code>.
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_to">to</code></td>
<td>

<p>Character vector: names of all parameters in the new parametrization.
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_reparamfn">reparamfn</code></td>
<td>

<p>A function which can convert a data frame/matrix/vector of &ldquo;old&rdquo; parameters to an object of the same class in the new parametrization. It must have two arguments: its first argument must hold the &ldquo;old&rdquo; data frame/matrix/vector; and the second argument is either <code>to</code> (holding the <code>to</code> argument given to <code>reparam_reftable</code>) if <code>reparamfn</code> needs this information, or <code>...</code>.
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_lower">LOWER</code>, <code id="reparam_fit_+3A_upper">UPPER</code></td>
<td>

<p>Optional named vectors of bounds. They may be incomplete, containing values only for new parameters, and not necessarily for all of them (missing information is deduced from the observed ranges in the reference table).  
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_nbcluster">nbCluster</code></td>
<td>

<p>Passed to <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>.
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_constr_crits">constr_crits</code></td>
<td>

<p><code><a href="#topic+constr_crits">constr_crits</a></code> applicable in the new parametrization. The suitability of such constraints is checked on the transformed reference table. When this argument is ignored, its default value is taken from the input object and therefore refers to the old parametrization. The check may then highlight the need for providing constraints redefined in reference to the new parametrization.   
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_raw">raw</code></td>
<td>
<p>Boolean; if TRUE, the object is re-built starting from the raw 
reference table. In particular the projections are re-computed.
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_reftable_attrs">reftable_attrs</code></td>
<td>

<p>A <code>list</code> whose elements are set as attributes to the re-parametrized reference table (see Value in <code><a href="#topic+add_reftable">add_reftable</a></code>). Elements not provided by this argument will be copied from the input reference table. A typical use is to provide as <code>Simulate</code> function in the new parametrization (see Examples). 
</p>
</td></tr>
<tr><td><code id="reparam_fit_+3A_...">...</code></td>
<td>

<p>Passed to <code><a href="#topic+MSL">MSL</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>reparam_reftable</code> returns a reference table with attributes, suitable as input for <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>.
<code>reparam_fit</code> returns the return value of an <code><a href="#topic+MSL">MSL</a></code> call.
</p>
<p>The information about projections retained in these objects come from original <code>fitobject</code>.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## Toy simulation function 
# (inspired by elementary population-genetic scenario)

hezsim &lt;- function(logNe=parvec["logNe"],
                   logmu=parvec["logmu"],parvec) {
  Ne &lt;- 10^logNe
  mu &lt;- 10^logmu
  Es &lt;- Ne*mu
  Vs &lt;- 1/log(1+Ne) 
  genom_s &lt;- rgamma(5, shape=Es/Vs,scale=Vs) # 5 summary statistics
  names(genom_s) &lt;- paste0("stat",seq(5))
  genom_s
} 


{ ## Analysis with 'canonical' parameters
  #
  ## simulated data, standing for the actual data to be analyzed:  
  set.seed(123)
  Sobs &lt;- hezsim(logNe=4,logmu=-4) 
  #
  parsp &lt;- init_reftable(lower=c(logNe=1,logmu=-5), 
                         upper=c(logNe=6,logmu=-2))
  init_reft_size &lt;- nrow(parsp)
  simuls &lt;- add_reftable(Simulate=hezsim, parsTable=parsp)
  
  { 
    plogNe &lt;- project("logNe", data=simuls, stats=paste0("stat",seq(5)))
    plogmu &lt;- project("logmu", data=simuls, stats=paste0("stat",seq(5)))

    dprojectors &lt;- list(plogNe=plogNe,plogmu=plogmu)
    
    projSimuls &lt;- project(simuls,projectors=dprojectors,verbose=FALSE)
    projSobs &lt;- project(Sobs,projectors=dprojectors)
  }
  
  { ## Estimation: 
    ddensv &lt;- infer_SLik_joint(projSimuls,stat.obs=projSobs)
    dslik_j &lt;- MSL(ddensv, eval_RMSEs=FALSE) ## find the maximum of the log-likelihood surface
    refined_dslik_j &lt;- refine(dslik_j, eval_RMSEs=FALSE, CIs=FALSE)
  }
}

{  ## Reparametrization to composite parameters

  locreparamfn &lt;- function(object, ...) {
    logTh &lt;- object[["logmu"]]+object[["logNe"]]
    if (inherits(object,"data.frame")) { # *data.frame case always needed.*
      data.frame(logTh=logTh,
                 logNe=object[["logNe"]])
    } else if (is.matrix(object)) {
      cbind(logTh=logTh,
            logNe=object[["logNe"]])
    } else c(logTh=logTh,
             logNe=object[["logNe"]])
  }
  
  { ## without re-projection
     rps &lt;- reparam_fit(refined_dslik_j, to=c("logTh","logNe"),
                      reparamfn = locreparamfn)
     plot(rps)
  }

  
  { ## with re-projection [necessary to allow refine()'s]
  
    # For refine() a new simulation will be needed, with new input parameters: 
    hezsim2 &lt;- function(logNe=parvec["logNe"],logTh=parvec["logTh"],parvec) {
      hezsim(logNe=logNe,logmu=logTh-logNe)
    } 
    
    rps &lt;- reparam_fit(refined_dslik_j, to=c("logTh","logNe"),
                       reparamfn = locreparamfn, 
                       raw=TRUE,                   # to allow re-projection
                       reftable_attrs=list(Simulate=hezsim2))
    plot(rps)
    refine(rps)

  }
  
}

## End(Not run)
</code></pre>

<hr>
<h2 id='rparam'>
Sample the parameter space
</h2><span id='topic+rparam'></span><span id='topic+sample_volume'></span>

<h3>Description</h3>

<p>These functions are relevant only for the primitive workflow. They take an <code>SLik</code> object (as produced by <code><a href="#topic+MSL">MSL</a></code>) and samples its parameter space in (hopefully) clever ways, not yet well documented. <code>rparam</code> calls <code>sample_volume</code> to define points targeting the likelihood maximum and the bounds of confidence intervals, with <code>n</code> for these different targets dependent on the mean square error of prediction of likelihood at the maximum and at CI bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rparam(object, n= 1, useEI = list(max=TRUE,profileCI=TRUE,rawCI=FALSE), 
       useCI = TRUE, verbose = interactive(), tryn=30*n,  
       level = 0.95, CIweight=Infusion.getOption("CIweight"))

sample_volume(object, n = 6, useEI, vertices=NULL,
              dlr = NULL, verbose = interactive(), 
              fixed = NULL, tryn= 30*n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rparam_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object
</p>
</td></tr>
<tr><td><code id="rparam_+3A_n">n</code></td>
<td>

<p>The number of parameter points to be produced 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_useei">useEI</code></td>
<td>
<p> List of booleans, each determining whether to use an &ldquo;expected improvement&rdquo; (EI) criterion (e.g. Bingham et al., 2014) to select candidate parameter points to better ascertain a particular focal point. The elements <code>max</code>, <code>profileCI</code> and <code>rawCI</code> determine this for three types of focal points, respectively the MSL estimate, profile CI bounds, and full-dimensional bounds. When EI is used, <code>n</code> points with best EI are selected among <code>tryn</code> points randomly generated in some neighborhood of the focal point. 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_vertices">vertices</code></td>
<td>
<p>Points are sampled within a convex hull defined by <code>vertices</code>. By default, these vertices are taken from <code>object$fit$data</code>.  
</p>
</td></tr>
<tr><td><code id="rparam_+3A_useci">useCI</code></td>
<td>

<p>Whether to define points targeting the bounds of confidence intervals for the parameters. An expected improvement criterion is also used here.
</p>
</td></tr>
<tr><td><code id="rparam_+3A_level">level</code></td>
<td>

<p>If <code>useCI</code> is <code>TRUE</code> but confidence intervals are not available from the <code>object</code>, such intervals are computed with coverage <code>level</code>. 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_dlr">dlr</code></td>
<td>

<p>A (log)likelihood ratio threshold used to select points in the upper region of the likelihood surface. Default value is 
given by <code>Infusion.getOption("LRthreshold")</code>   
</p>
</td></tr>
<tr><td><code id="rparam_+3A_verbose">verbose</code></td>
<td>

<p>Whether to display some information about selection of points, or not
</p>
</td></tr>
<tr><td><code id="rparam_+3A_fixed">fixed</code></td>
<td>

<p>A list or named vector, of which each element is of the form <code>&lt;parameter name&gt;=&lt;value&gt;</code>, defining a one-dimensional constraint in parameter space.
Points will be sampled in the intersection of the volume defined by the <code>object</code> and of such constraint(s).
</p>
</td></tr>
<tr><td><code id="rparam_+3A_tryn">tryn</code></td>
<td>

<p>See <code>useEI</code> argument. 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_ciweight">CIweight</code></td>
<td>

<p>For development purposes, not documented. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame of parameter points. Only parameters variable in the <code>SLik</code> object are considered. 
</p>


<h3>References</h3>

<p>D. Bingham, P. Ranjan, and W.J. Welch (2014) Design of Computer Experiments for Optimization, Estimation of Function Contours, and Related Objectives, pp. 109-124 in Statistics in Action: A Canadian Outlook (J.F. Lawless, ed.). Chapman and Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;10) {
 data(densv)
 summliksurf &lt;- infer_surface(densv) ## infer a log-likelihood surface
 sample_volume(summliksurf)
}
</code></pre>

<hr>
<h2 id='save_MAFs'>
Save or load MAF Python objects
</h2><span id='topic+save_MAFs'></span><span id='topic+load_MAFs'></span>

<h3>Description</h3>

<p><span class="pkg">Infusion</span> fit results created using the <span class="pkg">mafR</span> package contain (pointers to) Python objects, which are lost (their pointers being reduced to null pointers) when the fit object is saved on file and reloaded. The functions described here circumvent this issue. 
</p>
<p><code>save_MAFs</code> will save the Python objects in distinct files. <code>load_MAFs</code> will load them back into the fit object, <b>not</b> overriding anyone pre-existing into the target fit object. 
The Python objects are saved under, and read from, files whose names are made of <code>"jointdens"</code>, <code>"pardens"</code>... and the given <code>prefix</code> and <code>ext</code>ension.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_MAFs(object, ext="_MAF.pkl", prefix="")
load_MAFs(object, ext="_MAF.pkl", prefix="", set_path_only=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="save_MAFs_+3A_object">object</code></td>
<td>

<p>An object of class <code>"SLik_j"</code> as produced by the up-to-date <span class="pkg">Infusion</span> workflow.
</p>
</td></tr>
<tr><td><code id="save_MAFs_+3A_prefix">prefix</code>, <code id="save_MAFs_+3A_ext">ext</code></td>
<td>

<p>Character: Prefix and extension for the filename of each saved MAF object.  
</p>
</td></tr>
<tr><td><code id="save_MAFs_+3A_set_path_only">set_path_only</code></td>
<td>

<p>Boolean: if TRUE, checks the presence of the saved MAF files, but do not load them, and (re)set the path information in the <code>object</code> (see Details for a programming context of usage).  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both functions can write file path information into the input <code>object</code>'s <code>load_MAFs_info</code> element (an environment), where it can be read afterwards. <code>save_MAFs</code> will do so in all cases, and <code>load_MAFs</code> will do so when called with argument <code>set_path_only=TRUE</code>. When a bootstrap is run using parallelisation, the child processes can thus load files using their location information stored in this way. When the files have been moved after the <code>save_MAFs</code> call, their location information must then be updated using <code>load_MAFs(., set_path_onlTRUE)</code>.
</p>


<h3>Value</h3>

<p>Both functions return the updated input <code>object</code>. 
</p>


<h3>See Also</h3>

<p><code>reticulate::<a href="reticulate.html#topic+py_save_object">py_save_object</a></code> is used to save the Python objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Given object 'slik_j' of class SLik_j
# save_MAFs(slik_j, prefix = "2024Feb30_")
## =&gt; '2024Feb30_jointdens_MAF.pkl', etc.
# save(slik_j, file="slik_j.rda") 
## =&gt; Objects from Python environments are not saved in the RData file. 

# and later:
# load(file="slik_j.rda") 
# slik_j &lt;- load_MAFs(slik_j, prefix = "2024Feb30_")
## Objects from pkl files are put back at the right place in 'slik_j'. 

</code></pre>

<hr>
<h2 id='simulate.SLik_j'>
Simulate method for an <code>SLik_j</code> object.
</h2><span id='topic+simulate'></span><span id='topic+simulate.SLik_j'></span>

<h3>Description</h3>

<p><code><a href="stats.html#topic+simulate">simulate</a></code> method for <code>SLik_j</code> objects, by default simulating realizations of the vector of projected summary statistics, drawn from their inferred distribution, given the summary-ML estimates which are the default value of the <code>given</code> argument. 
</p>
<p>For any non-default <code>given</code> argument, the sampling distribution is still deduced from the multivariate Gaussian mixture fit of the reference table, by conditioning it on <code>given</code> values. Any variable included in the mixture model may be included in <code>given</code>, allowing to simulate from other distributions than that of the vector of projected summary statistics.  
</p>
<p>This usage should not be confused with simulating the sample-generating process, necessarily distinctly available to the user, and which does not rely on the mixture model stored in the fit object.
Simulations of the sample-generating process for <code>given</code> parameter values can be obtained by setting non-default option <code>SGP=TRUE</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik_j'
simulate(object, nsim = 1, seed = NULL, given=object$MSL$MSLE, 
                          norm_or_t=.wrap_rmvnorm, SGP=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulate.SLik_j_+3A_object">object</code></td>
<td>

<p>An object of class <code>SLik_j</code> as produced by the up-to-date workflow. 
</p>
</td></tr>
<tr><td><code id="simulate.SLik_j_+3A_nsim">nsim</code></td>
<td>

<p>number of response vectors of projected summary statistics to simulate. 
</p>
</td></tr>
<tr><td><code id="simulate.SLik_j_+3A_seed">seed</code></td>
<td>

<p>Seed for the random number generator (RNG). Here this controls the <code>.Random.seed</code> in the global environment, as in <code>simulate.lm</code>. This means that if a non-NULL <code>seed</code> is specified, it controls the RNG during the <code>simulate</code> call, but the RNG is reset to its prior state on exit.  
</p>
</td></tr>
<tr><td><code id="simulate.SLik_j_+3A_given">given</code></td>
<td>

<p>The default is the summary-MLE, a full vector of fitted parameters; but Any variable included in the mixture fit of the referencetable may be included (see Description).  
</p>
</td></tr>
<tr><td><code id="simulate.SLik_j_+3A_norm_or_t">norm_or_t</code></td>
<td>

<p>Controls the sampler in in cluster of the mixture. The default value is a trivial wrapper around the <code><a href="mvtnorm.html#topic+rmvnorm">rmvnorm</a></code> sampler (consistently with the fitted model), but this argument makes it possible to specify other samplers (e.g., <code>norm_or_t=Infusion:::.wrap_rmvt</code> to sample from <code><a href="mvtnorm.html#topic+rmvt">rmvt</a>(., df=1)</code>; or used-defined samplers with the same interface).   
</p>
</td></tr>
<tr><td><code id="simulate.SLik_j_+3A_sgp">SGP</code></td>
<td>
<p>Boolean. Whether to sample from the sample-generating process.</p>
</td></tr>
<tr><td><code id="simulate.SLik_j_+3A_...">...</code></td>
<td>

<p>Additional arguments. Currently ignored, except when <code>SGP=TRUE</code>, in which case e.g. <code>control.Simulate</code> can be passed through the dots to control the sample simulator.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>By default (<code>SGP=FALSE</code>), a matrix of size <code>nsim</code> times the number of <b>projected</b> summary statistics; if <code>SGP=TRUE</code>, a data frame with columns for parameters, for <b>raw</b> summary statistics, and optionally for latent variables if relevant.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Assuming an object 'slik_j' of class 'SLik_j':
# simulate(slik_j, nsim=3)
</code></pre>

<hr>
<h2 id='summLik'>
Model density evaluation for given data and parameters
</h2><span id='topic+summLik'></span><span id='topic+summLik.SLik_j'></span><span id='topic+summLik.default'></span>

<h3>Description</h3>

<p>Evaluation of inferred probability density as function of parameters and of (projected) summary statistics is implemented as a generic function <code>summLik</code>.
This documentation deals mostly with its method for objects of class <code>SLik_j</code> produced by the up-to-date version of the summary-likelihood workflow.
</p>
<p>Given the (projected) statistics for the data used to build the <code>SLik_j</code> object, and the fitted parameters, this returns the (log)likelihood, as the generic
<code>logLik</code> extractor does. However, parameters can be varied (so that <code>summLik</code> provides the likelihood function rather than simply its maximum), the data can be varied too, and likelihood profiles (or even full new estimates) are computed when an incomplete parameter vector (or even NULL) is specified. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summLik(object, parm, data, ...)

## S3 method for class 'SLik_j'
summLik(object, parm, data=t(get_from(object,"proj_data")), 
                         log=TRUE, which="safe", constr_tuning = Inf, 
                         newMSL=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summLik_+3A_object">object</code></td>
<td>
<p>An <code>SLik</code> or <code>SLik_j</code> object</p>
</td></tr>
<tr><td><code id="summLik_+3A_parm">parm</code></td>
<td>
<p>Vector, data frame or matrix, containing coordinates of parameter points for which (log) likelihoods will be computed; or NULL. A profile will be computed if a single incomplete parameter vector is provided. A full new estimate will be computed in <code>parm</code> is NULL.</p>
</td></tr>
<tr><td><code id="summLik_+3A_data">data</code></td>
<td>
<p>Matrix of (projected, if relevant) summary statistics for which the likelihood of given parameters is to be computed. By default, the (projected) statistics for the data used to build the <code>SLik_j</code> object</p>
</td></tr>
<tr><td><code id="summLik_+3A_log">log</code></td>
<td>
<p>Boolean: whether to return log likelihood or raw likelihood. Better ignored.</p>
</td></tr>
<tr><td><code id="summLik_+3A_which">which</code></td>
<td>
<p>character string: <code>"lik"</code> for (log) likelihood deduced from the multivariate gaussian mixture model for joint parameters and summary statistics, without further modifications. But the default, <code>"safe"</code>, may correct this result to deal with possible extrapolation artefacts (see Details of <code><a href="#topic+predict.SLik_j">predict.SLik_j</a></code>).
</p>
</td></tr>
<tr><td><code id="summLik_+3A_constr_tuning">constr_tuning</code></td>
<td>
<p>Passed to <code><a href="#topic+predict.SLik_j">predict.SLik_j</a></code>.</p>
</td></tr>
<tr><td><code id="summLik_+3A_newmsl">newMSL</code></td>
<td>

<p>Boolean. If this is TRUE and a profile was computed, attributes are added to the result (see Value).
</p>
</td></tr>
<tr><td><code id="summLik_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods. Currently only passed to <code>predict.SLik_j</code> when no likelihood profile is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector, with optional attribute(s).
</p>
<p>If no profile is computed, it may have attributes from the return value of <code><a href="#topic+predict.SLik_j">predict.SLik_j</a></code>. If a profile is computed, the returned value has attribute <code>"profpt"</code> giving the profile-maximizing parameter vector. Further, if <code>newMSL=TRUE</code>, the following attributes are added: <code>"newobs_MSL"</code>, a list with information about unconstrained summary-likelihood maximization (useful mainly when there are new <code>data</code>); and <code>"LRstat"</code>, the resulting log-likelihood ratio.  
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+predict.SLik_j">predict.SLik_j</a></code>) for case without profiling; 
<code><a href="#topic+logLik">logLik</a></code>, the standard extractor of likelihood for the model fitted to the original data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Using 'slik_j' object from the example in help("example_reftable") 
summLik(slik_j, parm=slik_j$MSL$MSLE+0.1)

# summLik() generalizes logLik():
summLik(slik_j, parm=slik_j$MSL$MSLE) == logLik(slik_j) # must be TRUE

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
