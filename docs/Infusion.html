<!DOCTYPE html><html><head><title>Help for package Infusion</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Infusion}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Infusion'><p>Inference using simulation</p></a></li>
<li><a href='#add_reftable'>
<p>Create or augment a list of simulated distributions of summary statistics</p></a></li>
<li><a href='#add_simulation'>
<p>Create or augment a list of simulated distributions of summary statistics</p></a></li>
<li><a href='#check_raw_stats'>
<p>Check linear dependencies among raw summary statistics</p></a></li>
<li><a href='#confint.SLik'>
<p>Compute confidence intervals by (profile) summary likelihood</p></a></li>
<li><a href='#densv'>
<p>Saved computations of inferred log-likelihoods</p></a></li>
<li><a href='#dMixmod'>
<p>Internal S4 classes.</p></a></li>
<li><a href='#example_raw'><p>Workflow for primitive method, without projections</p></a></li>
<li><a href='#example_raw_proj'><p>Workflow for primitive method, with projections</p></a></li>
<li><a href='#example_reftable'><p>Workflow for method with reference table</p></a></li>
<li><a href='#extractors'>
<p>Summary, print and logLik methods for Infusion results.</p></a></li>
<li><a href='#focal_refine'>
<p>Refine summary likelihood profile in focal parameter values</p></a></li>
<li><a href='#get_from'>
<p>Backward-compatible extractor from summary-likelihood objects</p></a></li>
<li><a href='#get_LRboot'>
<p>Summary likelihood ratio tests</p></a></li>
<li><a href='#get_nbCluster_range'>
<p>Control of number of components in Gaussian mixture modelling</p></a></li>
<li><a href='#goftest'>
<p>Assessing goodness of fit of inference using simulation</p></a></li>
<li><a href='#handling_NAs'>
<p>Discrete probability masses and NA/NaN/Inf in distributions of summary statistics.</p></a></li>
<li><a href='#infer_logLs'>
<p>Infer log Likelihoods using simulated distributions of summary statistics</p></a></li>
<li><a href='#infer_SLik_joint'>
<p>Infer a (summary) likelihood surface from a simulation table</p></a></li>
<li><a href='#infer_surface'>
<p>Infer a (summary) likelihood or tail probability surface from inferred likelihoods</p></a></li>
<li><a href='#Infusion-internal'><p>Internal Infusion Functions</p></a></li>
<li><a href='#init_reftable'>
<p>Define starting points in parameter space.</p></a></li>
<li><a href='#MSL'>
<p>Maximum likelihood from an inferred likelihood surface</p></a></li>
<li><a href='#multi_binning'>
<p>Multivariate histogram</p></a></li>
<li><a href='#options'><p>Infusion options settings</p></a></li>
<li><a href='#plot.SLik'>
<p>Plot SLik or SLikp objects</p></a></li>
<li><a href='#plot1Dprof'>
<p>Plot likelihood profiles</p></a></li>
<li><a href='#predict.SLik_j'>
<p>Evaluate log-likelihood for given parameters</p></a></li>
<li><a href='#profile.SLik'>
<p>Compute profile summary likelihood</p></a></li>
<li><a href='#project.character'>
<p>Learn a projection method for statistics and apply it</p></a></li>
<li><a href='#refine'>
<p>Refine estimates iteratively.</p></a></li>
<li><a href='#rparam'>
<p>Sample the parameter space</p></a></li>
<li><a href='#summLik'>
<p>Model density evaluation for given data and parameters</p></a></li>
<li><a href='#write_workflow'>
<p>Workflow template</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Inference Using Simulation</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements functions for simulation-based inference. In particular, implements functions to perform likelihood inference from data summaries whose distributions are simulated. A first approach was described in Rousset et al. (2017 &lt;<a href="https://doi.org/10.1111%2F1755-0998.12627">doi:10.1111/1755-0998.12627</a>&gt;) but the package implements more advanced methods.  </td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-03</td>
</tr>
<tr>
<td>Imports:</td>
<td>spaMM (&ge; 4.1.66), proxy, blackbox (&ge; 1.1.41), mvtnorm,
methods, numDeriv, viridis, pbapply, ranger, foreach,
matrixStats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, Rmixmod, crayon, caret, xLLiM</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>François Rousset &lt;francois.rousset@umontpellier.fr&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.cecill.info/licences/Licence_CeCILL_V2-en.txt">CeCILL-2</a></td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.R-project.org">https://www.R-project.org</a>,
<a href="https://gitlab.mbb.univ-montp2.fr/francois/Infusion">https://gitlab.mbb.univ-montp2.fr/francois/Infusion</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-03 08:05:24 UTC; francois.rousset</td>
</tr>
<tr>
<td>Author:</td>
<td>François Rousset <a href="https://orcid.org/0000-0003-4670-0371"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-03 11:00:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='Infusion'>Inference using simulation</h2><span id='topic+Infusion'></span><span id='topic+Infusion-package'></span>

<h3>Description</h3>

<p>Implements a collection of methods to perform inferences based on simulation of realizations of the model considered. In particular it implements 
&ldquo;summary likelihood&rdquo;, an approach that effectively evaluates and uses the likelihood of simulated summary statistics. 
</p>


<h3>Details</h3>

<p>The methods implemented in <code>Infusion</code> by default assume that the summary statistics have densities. Special values of some statistic, having discrete probability mass, can be handled using the <code>boundaries</code> attribute of the observed summary statistics (see <code><a href="#topic+handling_NAs">handling_NAs</a></code> for a further use of this attribute).              
</p>


<h3>Note</h3>

<p>See examples <code><a href="#topic+example_reftable">example_reftable</a></code> for the most complete example using up-to-date workflow, and <code><a href="#topic+example_raw_proj">example_raw_proj</a></code> or <code><a href="#topic+example_raw">example_raw</a></code> for older workflows.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='add_reftable'>
Create or augment a list of simulated distributions of summary statistics 
</h2><span id='topic+add_reftable'></span>

<h3>Description</h3>

<p><code>add_reftable</code> creates or augments a reference table of simulations, and formats the results appropriately for further use. The user does not have to think about this return format. Instead, s-he only has to think about the very simple return format of the function given as its <code>Simulate</code> argument. The primary role of his function is to wrap the call(s) of the function specified by <code>Simulate</code>. Depending on the arguments, parallel or serial computation is performed. 
</p>
<p>When parallelization is implied, it is performed by by default a &ldquo;socket&rdquo; cluster, available on all operating systems. Special care is then needed to ensure that all required packages are loaded in the called processes, and that all required variables and functions are passed therein: check the <code>packages</code> and <code>env</code> arguments. For socket clusters, <code>foreach</code> or <code>pbapply</code> is called depending whether the <code>doSNOW</code> package is attached (<code>doSNOW</code> allows more efficient load balancing than <code>pbapply</code>). 
</p>
<p>Alternatively, if the simulation function cannot be called directly by the R code, simulated samples can be added using the <code>newsimuls</code> argument. Finally, a generic data frame of simulated samples can be reformatted as a reference table by using only the <code>reftable</code> argument.
</p>
<p><code>add_simulation</code> is a wrapper for <code>add_reftable</code>, suitable when <code>nRealizations</code>&gt;1. It is now distinctly documented: the distinct features of <code>add_simulation</code> were conceived for the first workflow implemented in <code>Infusion</code> but are somewhat obsolete now.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_reftable(reftable=NULL, Simulate, parsTable=par.grid, par.grid=NULL, 
               nRealizations = 1L, newsimuls = NULL, 
               verbose = interactive(), nb_cores = NULL, packages = NULL, env = NULL,
               control.Simulate=NULL, cluster_args=list(), cl_seed=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_reftable_+3A_reftable">reftable</code></td>
<td>

<p>Data frame: a reference table. Each row contains parameters value of a simulated realization of the data-generating process, and the simulated summary statistics.  
As parameters should be told apart from statistics by <span class="pkg">Infusion</span> functions, information about parameter names should be attached to the <code>reftable</code> <b>*if*</b> it is not available otherwise. Thus if no <code>parsTable</code> is provided, the <code>reftable</code> should have an attribute <code>"LOWER"</code> (a named vectors giving lower bounds for the parameters which will vary in the analysis, as in the return value of the function).  
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_simulate">Simulate</code></td>
<td>

<p>An *R* function, or the name (as a character string) of an *R* function used to generate summary statistics for samples form a data-generating process. When an external simulation program is called, <code>Simulate</code> must therefore be an R function wrapping the call to the external program. Two function APIs are handled:<br /> <code> * </code>If the function has a <code>parsTable</code> argument, it must return a data frame of summary statistics, each line of which contains the vector of summary statistics for one realization of the data-generating process. The <code>parsTable</code> argument of <code>add_reftable</code> will be passed to <code>Simulate</code> and lines of the output data frame must be ordered, as in the input <code>parsTable</code> as these two data frames will be bound together.<br /> <code> * </code>Otherwise, the <code>Simulate</code> function must have one argument for each element of the parameter vector (i.e. of each row of <code>parsTable</code>). It must return a vector of summary statistics with named vector member.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_parstable">parsTable</code>, <code id="add_reftable_+3A_par.grid">par.grid</code></td>
<td>

<p>A data frame of which each line is the vector of parameters needed by <code>Simulate</code> for each simulation of the data-generating process. <code>par.grid</code> is an alias for <code>parsTable</code>; the latter argument may be preferred in order not to suggest that the parameter values should form a regular grid.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_nrealizations">nRealizations</code></td>
<td>

<p>The number of simulated samples of summary statistics, for each parameter vector (each row of <code>parsTable</code>). If not 1, theold wrkflow is assumed and <code><a href="#topic+add_simulation">add_simulation</a></code> is called.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_newsimuls">newsimuls</code></td>
<td>

<p>If the function used to generate empirical distributions cannot be called by R, then <code>newsimuls</code> can be used to provide these distributions. See Details for the structure of this argument.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Number of cores for parallel simulation; <code>NULL</code> or integer value, acting as a shortcut for <code>cluster_args$spec</code>. This is effective only if the simulation function is called separately for each row of <code>parsTable</code>. Otherwise, if the simulation function is called once one the whole <code>parsTable</code>, parallelisation could be controlled only through that function's own arguments.   
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. May contain a non-null <code>spec</code> element, in which case the distinct <code>nb_cores</code> argument and the global <span class="pkg">Infusion</span> option <code>nb_cores</code> are ignored. A typical usage would thus be <code>control_args=list(spec=&lt;number of 'children'&gt;)</code>. Additional elements <code>outfile="log.txt"</code> may be useful to collect output from the nodes, and <code>type="FORK"</code> may be used to force a fork cluster on linux(-alikes) (otherwise a socket cluster is set up as this is the default effect of <code>parallel::makeCluster</code>). Do <b>*not*</b> use a structured list with an <code>add_reftable</code> element as is possible for <code>refine</code> (see Details of <code><a href="#topic+refine">refine</a></code> documentation).
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not.
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>Simulate</code>, beyond the parameter vector. These arguments should be constant through all the simulation workflow. 
</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_control.simulate">control.Simulate</code></td>
<td>
<p>A list, used as an exclusive alternative to &ldquo;...&rdquo; to pass additional arguments to <code>Simulate</code>, beyond the parameter vector. The list must contain the same elements as would otherwise go in the &ldquo;...&rdquo; (if <code>control.Simulate</code> is left NULL, a default value is constructed from the ...).</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_packages">packages</code></td>
<td>
<p>For parallel evaluation: Names of additional libraries to be loaded on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_env">env</code></td>
<td>
<p>For parallel evaluation: an environment containing additional objects to be exported on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_reftable_+3A_cl_seed">cl_seed</code></td>
<td>

<p>(all parallel contexts:) Integer, or NULL. If an integer, it is used to initialize <code>"L'Ecuyer-CMRG"</code> random-number generator. If <code>cl_seed</code> is <code>NULL</code>, the default generator is selected on each node, where its seed is not controlled. Providing the seed allows repeatable results for given parallelization settings, but may not allow identical results across different settings. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>newsimuls</code> argument should have the same structure as the return value of the function itself, except that <code>newsimuls</code> may include only a subset of the attributes returned by the function. It is thus a data frame; its required attributes are <code>LOWER</code> and <code>UPPER</code> which are named vectors giving bounds for the parameters which are variable in the whole analysis (note that the names identify these parameters in the case this information is not available otherwise from the arguments). The values in these vectors may be incorrect in the sense of failing to bound the parameters in the <code>newsimuls</code>, as the actual bounds are then corrected using parameter values in <code>newsimuls</code> and attributes from <code>reftable</code>.  
</p>


<h3>Value</h3>

<p>A data.frame (with additional attributes) is returned. 
</p>
<p>The value has the following attributes: <code>LOWER</code> and <code>UPPER</code> which are each a vector of per-parameter minima and maxima deduced from any <code>newsimuls</code> argument, and optionally any of the arguments <code>Simulate, control.Simulate, packages, env, parsTable</code> and  <code>reftable</code> (all corresponding to input arguments when provided, except that the actual <code>Simulate</code> function is returned even if it was input as a name).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package for other typical usage
</code></pre>

<hr>
<h2 id='add_simulation'>
Create or augment a list of simulated distributions of summary statistics 
</h2><span id='topic+add_simulation'></span>

<h3>Description</h3>

<p><code>add_simulation</code> is suitable for the primitive <span class="pkg">Infusion</span> workflow; otherwise, it is cleaer to call <code><a href="#topic+add_reftable">add_reftable</a></code> directly. 
<code>add_simulation</code> creates or augments a list of simulated distributions of summary statistics, and formats the results appropriately for further use. Alternatively, if the simulation function cannot be called directly by the R code, simulated distributions can be added using the <code>newsimuls</code> argument, using a simple format (see <code>onedistrib</code> in the Examples). Finally, a generic data frame of simulations can be reformatted as a reference table by using only the <code>simulations</code> argument.
</p>
<p>Depending on the arguments, parallel or serial computation is performed. When parallelization is implied, by default a &ldquo;socket&rdquo; cluster, available on all operating systems. Special care is then needed to ensure that all required packages are loaded in the called processes, and that all required variables and functions are passed therein: check the <code>packages</code> and <code>env</code> arguments. For socket clusters, <code>foreach</code> or <code>pbapply</code> is called depending whether the <code>doSNOW</code> package is attached (<code>doSNOW</code> allows more efficient load balancing than <code>pbapply</code>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_simulation(simulations=NULL, Simulate, parsTable=par.grid, par.grid=NULL, 
               nRealizations=Infusion.getOption("nRealizations"),
               newsimuls=NULL, verbose=interactive(), nb_cores=NULL, 
               packages=NULL, env=NULL, control.Simulate=NULL,
               cluster_args=list(), cl_seed=NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_simulation_+3A_simulations">simulations</code></td>
<td>

<p>A list of matrices each representing a simulated distribution for given parameters in a format consistent with the return format of <code>add_simulation</code>.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_nrealizations">nRealizations</code></td>
<td>

<p>The number of simulated samples of summary statistics, for each empirical distribution (each row of <code>par.grid</code>).
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_simulate">Simulate</code></td>
<td>

<p>An *R* function, or the name (as a character string) of an *R* function used to generate empirical distributions of summary statistics. When an external simulation program is called, <code>Simulate</code> must therefore be an R function wrapping the call to the external program. The <code>Simulate</code> function must have one argument for each element of the parameter vector (i.e. of each row of <code>par.grid</code>). It must return a vector of summary statistics with named vector members; <b>or</b> a single matrix of <code>nRealizations</code> simulations, in which case its rows and row names must represent the summary statistics, it should have <code>nRealizations</code> columns, and <code>nRealizations</code> should be named integer of the form &ldquo;<code>c(as_one=.)</code>&rdquo; (see Examples).
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_parstable">parsTable</code>, <code id="add_simulation_+3A_par.grid">par.grid</code></td>
<td>

<p>A data frame of which each line is the vector of parameters needed by <code>Simulate</code> for each simulation of the data-generating process. <code>par.grid</code> is an alias for <code>parsTable</code>; the latter argument may be preferred in order not to suggest that the parameter values should form a regular grid.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_newsimuls">newsimuls</code></td>
<td>

<p>If the function used to generate empirical distributions cannot be called by R, then <code>newsimuls</code> can be used to provide these distributions. See Details for the structure of this argument.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Number of cores for parallel simulation; <code>NULL</code> or integer value, acting as a shortcut for <code>cluster_args$spec</code>. The effect is complicated: see Details.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. May contain a non-null <code>spec</code> element, in which case the distinct <code>nb_cores</code> argument and the global <span class="pkg">Infusion</span> option <code>nb_cores</code> are ignored. A typical usage would thus be <code>control_args=list(spec=&lt;number of 'children'&gt;)</code>. Additional elements <code>outfile="log.txt"</code> may be useful to collect output from the nodes, and <code>type="FORK"</code> may be used to force a fork cluster on linux(-alikes) (otherwise a socket cluster is set up as this is the default effect of <code>parallel::makeCluster</code>).
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_...">...</code></td>
<td>

<p>Arguments passed to <code>add_reftable</code> (and possibly beyond, to the simulation function: see <code>nsim</code> argument of <code>myrnorm_tab()</code> in the Examples. These arguments should be constant through all the simulation workflow.
</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_control.simulate">control.Simulate</code></td>
<td>
<p>A list, used as an exclusive alternative to &ldquo;...&rdquo; to pass additional arguments to <code>Simulate</code>, beyond the parameter vector. The list must contain the same elements as would go in the &ldquo;...&rdquo;.</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_packages">packages</code></td>
<td>
<p>For parallel evaluation: Names of additional libraries to be loaded on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_env">env</code></td>
<td>
<p>For parallel evaluation: an environment containing additional objects to be exported on the cores, necessary for <code>Simulate</code> evaluation.</p>
</td></tr>
<tr><td><code id="add_simulation_+3A_cl_seed">cl_seed</code></td>
<td>
<p>Integer, or NULL. Providing the seed was conceived to allow repeatable results at least for given parallelization settings, if not identical results across different parallelization contexts. However, this functionality may have been been lost as the code was adapted for the up-to-date workflow using <code>add_reftable</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>newsimuls</code> argument should have the same structure as the return value of the function itself, except that <code>newsimuls</code> may include only a subset of the attributes returned by the function. <code>newsimuls</code> should thus be list of matrices, each with a <code>par</code> attribute (see Examples). Rows of each matrix stand for simulation replicates and columns stand for the different summary statistics. 
</p>
<p>When <code>nRealizations</code>&gt;1L, if <code>nb_cores</code> is unnamed or has name <code>"replic"</code> and if the simulation function does not return a single table for all replicates (thus, if <code>nRealizations</code> is <b>not</b> a named integer of the form &ldquo;<code>c(as_one=.)</code>&rdquo;, parallelisation is over the different samples for each parameter value (and the seed of the random number generator is not controlled in a parallel context). For any other explicit name (e.g., <code>nb_cores=c(foo=7)</code>), or if <code>nRealizations</code> is a named integer of the form &ldquo;<code>c(as_one=.)</code>&rdquo;, parallelisation is over the parameter values (the rows of <code>par.grid</code>). In all cases, the progress bar is over parameter values. See Details in <code><a href="#topic+Infusion.options">Infusion.options</a></code> for the subtle way these different cases are distinguished in the progress bar.
</p>
<p>Using a FORK cluster with <code>nRealizations</code>&gt;1 is warned as unreliable: in particular, anyone trying this combination should check whether other desired controls, such as random generator seed, or progress bar are effective. 
</p>


<h3>Value</h3>

<p>If <code>nRealizations</code>&gt;1L, the return value is an object of class <code>EDFlist</code>, which is a list-with-attributes of matrices-with-attribute. Each matrix contains a simulated distribution of summary statistics for given parameters, and the <code>"par"</code> attribute is a 1-row data.frame of parameters. If <code>Simulate</code> is used, this must give all the parameters to be estimated; otherwise it must at least include all variable parameters in this <b>or later</b> simulations to be appended to the simulation list. 
</p>
<p>The value has the following attributes: <code>LOWER</code> and <code>UPPER</code> which are each a vector of per-parameter minima and maxima deduced from any <code>newsimuls</code> argument, and optionally any of the arguments <code>Simulate, control.Simulate, packages, env, par.grid</code> and  <code>simulations</code> (all corresponding to input arguments when provided, except that the actual <code>Simulate</code> function is returned even if it was input as a name).
</p>
<p>If <code>nRealizations</code>=1 <code>add_reftable</code> is called: see its distinct return value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Examples using init_grid and add_simulation, for primitive workflow
### Use init_reftable and add_reftable for the up-to-date workflow

# example of building a list of simulations from scratch:
myrnorm &lt;- function(mu,s2,sample.size) {
  s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
  return(c(mean=mean(s),var=var(s)))
}
set.seed(123)
onedistrib &lt;- t(replicate(100,myrnorm(1,1,10))) # toy example of simulated distribution
attr(onedistrib,"par") &lt;- c(mu=1,sigma=1,sample.size=10) ## important!
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         newsimuls=list("example"=onedistrib))

# standard use: smulation over a grid of parameter values
parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.2,sample.size=40),
                   upper=c(mu=5.2,s2=3,sample.size=40))
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         par.grid = parsp[1:7,])
                         
## Not run:  # example continued: parallel versions of the same
# Slow computations, notably because cluster setup is slow.

#    ... parallel over replicates, serial over par.grid rows
# =&gt; cl_seed has no effect and can be ignored
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         par.grid = parsp[1:7,], nb_cores=7)
#                         
#    ... parallel over 'par.grid' rows =&gt; cl_seed is effective
simuls &lt;- add_simulation(NULL, Simulate="myrnorm", nRealizations=500,
                         cl_seed=123, # for repeatable results
                         par.grid = parsp[1:7,], nb_cores=c(foo=7))

## End(Not run)
                     
####### Example where a single 'Simulate' returns all replicates:

myrnorm_tab &lt;- function(mu,s2,sample.size, nsim) {
  ## By default, Infusion.getOption('nRealizations') would fail on nodes!
  replicate(nsim, 
            myrnorm(mu=mu,s2=s2,sample.size=sample.size)) 
}

parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.2,sample.size=40),
                   upper=c(mu=5.2,s2=3,sample.size=40))

# 'as_one' syntax for 'Simulate' function returning a simulation table: 
simuls &lt;- add_simulation(NULL, Simulate="myrnorm_tab",
              nRealizations=c(as_one=500),
              nsim=500, # myrnorm_tab() argument, part of the 'dots'
              par.grid=parsp)

## Not run:  # example continued: parallel versions of the same.
# Slow cluster setup again
simuls &lt;- add_simulation(NULL,Simulate="myrnorm_tab",par.grid=parsp,
              nb_cores=7L,
              nRealizations=c(as_one=500),
              nsim=500, # myrnorm_tab() argument again
              cl_seed=123, # for repeatable results
              # need to export other variables used by *myrnorm_tab* to the nodes:
              env=list2env(list(myrnorm=myrnorm)))

## End(Not run)

## see main documentation page for the package for other typical usage
</code></pre>

<hr>
<h2 id='check_raw_stats'>
Check linear dependencies among raw summary statistics
</h2><span id='topic+check_raw_stats'></span>

<h3>Description</h3>

<p>A convenient wrapper function for <code>caret::findLinearCombos</code>, allowing to detect linear dependencies among the statistics, 
and optionally to remove variables that induce them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_raw_stats(x, statNames, remove = FALSE, verbose = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_raw_stats_+3A_x">x</code></td>
<td>
<p>data frame (particularly inheriting from class <code>"reftable"</code>, i.e. a reference table of simulations); or possibly a matrix with column names</p>
</td></tr>
<tr><td><code id="check_raw_stats_+3A_statnames">statNames</code></td>
<td>

<p>Character vector: variables among which dependencies are sought. Must belong column names of <code>x</code>. For a <code>reftable</code>, this argument is optional and by default, all raw statistic are included. For other classes of input, this argument is required. 
</p>
</td></tr>
<tr><td><code id="check_raw_stats_+3A_remove">remove</code></td>
<td>
<p>Boolean: whether to return <code>x</code> with &ldquo;offending&rdquo; columns removed, or other information.</p>
</td></tr>
<tr><td><code id="check_raw_stats_+3A_verbose">verbose</code></td>
<td>
<p>Boolean: whether to display some messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return type depends on the availability of the <span class="pkg">caret</span> package, and on the <code>remove</code> argument, as follows. if <code>remove=TRUE</code>, an object of the same class as <code>x</code> is returned (with redundant columns removed). If <code>remove=FALSE</code>, either the <span class="pkg">caret</span> package is available, in which case a list is returned with the same structure as the return value of  <code>caret::findLinearCombos</code> but with column indices replaced by column names; or a message pointing that <span class="pkg">caret</span> is not available is returned (and another is printed, only once per session).
</p>

<hr>
<h2 id='confint.SLik'>
Compute confidence intervals by (profile) summary likelihood 
</h2><span id='topic+confint.SLik'></span><span id='topic+confint.SLik_j'></span><span id='topic+confint.SLikp'></span><span id='topic+confint'></span>

<h3>Description</h3>

<p>This takes an <code>SLik</code> object (as produced by <code><a href="#topic+MSL">MSL</a></code>) and deduces confidence bounds for each parameter, using a (profile, if relevant) likelihood ratio method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
confint(object, parm,
                       level=0.95, verbose=interactive(),
                       fixed=NULL,which=c(TRUE,TRUE),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.SLik_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_parm">parm</code></td>
<td>

<p>The parameter which confidence bounds are to be computed
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_level">level</code></td>
<td>

<p>The desired coverage of the interval
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_fixed">fixed</code></td>
<td>
<p>When this is <code>NULL</code> the computed interval is a profile confidence interval over all parameters excluding <code>parm</code>.
<code>fixed</code> allows one to set fixed values to some of these parameters.  
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_which">which</code></td>
<td>

<p>A pair of booleans, controlling whether to compute respectively the lower and the upper CI bounds.
</p>
</td></tr>
<tr><td><code id="confint.SLik_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with sublists for each parameter, each sublist containing of three vectors: the bounds of the one-dimensional confidence interval; the &ldquo;full&rdquo; 
(only parameters variable in the <code>SLik</code> object are considered) parameter point for the lower bound, and the full parameter point for the upper bound
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package
</code></pre>

<hr>
<h2 id='densv'>
Saved computations of inferred log-likelihoods
</h2><span id='topic+densv'></span><span id='topic+densb'></span><span id='topic+saved_seed'></span>

<h3>Description</h3>

<p>These are saved results from toy examples used in other documentation page for the package. It gives estimates by simulation of log-likelihoods of the <code>(mu,s2)</code> parameters of a Gaussian distribution for a given sample of size 20 with mean 4.1416238 and (bias-corrected) variance 0.9460778. <code>densv</code> is based on the sample mean and sample variance as summary statistics, and <code>densb</code> on more contrived summary statistics.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("densv")
data("densb")
</code></pre>


<h3>Format</h3>

<p>Data frames (with additional attributes) with observations on the following 5 variables.
</p>

<dl>
<dt><code>mu</code></dt><dd><p>a numeric vector; mean parameter of simulated Gaussian samples</p>
</dd>
<dt><code>s2</code></dt><dd><p>a numeric vector; variance parameter of simulated Gaussian samples</p>
</dd>
<dt><code>sample.size</code></dt><dd><p>a numeric vector; size of simulated Gaussian samples</p>
</dd>
<dt><code>logL</code></dt><dd><p>a numeric vector; log probability density of a given statistic vector inferred from simulated values for the given parameters</p>
</dd>
<dt><code>isValid</code></dt><dd><p>a boolean vector. See <code><a href="#topic+infer_logLs">infer_logLs</a></code> for its meaning.</p>
</dd> 
</dl>

<p>Both data frames are return objects of a call to <code><a href="#topic+infer_logLs">infer_logLs</a></code>, and as such they includes attributes providing information about the parameter names and statistics names (not detailed here).
</p>


<h3>See Also</h3>

<p>See step (3) of the workflow in the Example on the main <code><a href="#topic+Infusion">Infusion</a></code> documentation page, showing how <code>densv</code> was produced, and the Example in <code><a href="#topic+project">project</a></code> showing how <code>densb</code> was produced.
</p>

<hr>
<h2 id='dMixmod'>
Internal S4 classes. 
</h2><span id='topic+dMixmod'></span><span id='topic+class+3AdMixmod'></span><span id='topic+dMixmod-class'></span><span id='topic+NULLorChar'></span><span id='topic+class+3ANULLorChar'></span><span id='topic+NULLorChar-class'></span><span id='topic+NULLorNum'></span><span id='topic+class+3ANULLorNum'></span><span id='topic+NULLorNum-class'></span><span id='topic+plot.dMixmod'></span>

<h3>Description</h3>

<p>The objects or methods referenced here are not to be called by the user, or are waiting for documentation to be written.  
</p>
<p><code>dMixmod</code> is an S4 class describing some distributions that extend the multivariate gaussian mixture models (MGMM) by possibly involving discrete probability masses for some variables and gaussian mixtures for other variables conditional on such discrete events. In terms of the represented probability models, and of its slots, is effectively extends the <code>MixmodResults</code> class from the <code>Rmixmod</code> package. But it does not formally extends this class in terms of OOP programming. It should not be considered as part of the programming interface, and may be subject to backward-incompatible modifications without notice. In the current implementation it cannot represent general mixtures of discrete probabilities and MGMMs, and may yield correct results only for the degenerate case of pure MGMMs or when inference can be based on the conditional density of continuous variables conditional on the (joint-, if relevant) discrete event observed in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'># dMixmod: Don't try to use it! It's for programming only.
</code></pre>


<h3>Value</h3>

<p>A <code>dMixmod</code> object has the same slots as a <code>MixmodResults</code> object, plus additional ones: <code>@freq</code> is the frequency of the conditioning event for the gaussian mixture model. In the <code>Infusion</code> code, this event is defined jointly by the &ldquo;observed&rdquo; summary statistics and the reference simulation table: a probability mass for specific values <b>v</b> is identified from the simulated distribution of summary statistics in the reference table, and <code>freq</code> is an estimate of the probability mass if the summary statistics match <b>v</b>, or the converse probability if they do not match.
</p>


<h3>Note</h3>

<p>Use <code>str(attributes(.))</code> to see the slots of a <code>dMixmod</code> object if <code>str(.)</code> does not work.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The dMixmod object can be used internally to handle repeated and boundary values 
# of summary statistics. The user has to add an attribute to the observations,
# as explained in help("boundaries-attribute"):
Sobs &lt;- c(mean=4.321, se=0.987) # hypothetical observation
attr(Sobs,"boundaries") &lt;- c(someSummStat=-1)  
</code></pre>

<hr>
<h2 id='example_raw'>Workflow for primitive method, without projections</h2><span id='topic+example_raw'></span>

<h3>Description</h3>

<p>Example of the workflow with <code>add_simulation</code>), implementing the method described in the original publication 
(Rousset et al. 2017 &lt;doi:10.1111/1755-0998.12627&gt;).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The following example illustrates the workflow.
## However, most steps run longer than accepted by the CRAN checks,
## So by default they will not run.
##
## (1) The user must provide the function for simulation of summary statistics
myrnorm &lt;- function(mu,s2,sample.size) {
 s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
 return(c(mean=mean(s),var=var(s)))
} # simulate means and variances of normal samples of size 'sample.size'
#
## pseudo-sample:  
set.seed(123)
Sobs &lt;- myrnorm(mu=4,s2=1,sample.size=40) ## stands for the actual data to be analyzed
#
## (2) Generate, and simulate distributions for, 
##        an irregular grid of parameter values, with some replicates
if (Infusion.getOption("example_maxtime")&gt;40) {
  parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.2,sample.size=40),
                     upper=c(mu=5.2,s2=3,sample.size=40))
  simuls &lt;- add_simulation(NULL,Simulate="myrnorm",par.grid=parsp)
  
  ## (3) infer logL(pars,stat.obs) for each simulated 'pars'
  # Relatively slow, hence saved as data 'densv'
  densv &lt;- infer_logLs(simuls,stat.obs=Sobs)
} else {
  data(densv)
  .Random.seed &lt;- saved_seed
}
#
## (4) infer a log-likelihood surface and its maximum;
##       plot and extract various information. 
if (Infusion.getOption("example_maxtime")&gt;11) {
 slik &lt;- infer_surface(densv)
 slik &lt;- MSL(slik) ## find the maximum of the log-likelihood surface
 plot(slik)
 profile(slik,c(mu=4)) ## profile summary logL for given parameter value
 confint(slik,"mu") ## compute confidence interval for given parameter
 plot1Dprof(slik,pars="s2",gridSteps=40) ## 1D profile
}
#
## (5) ## refine iteratively
if (Infusion.getOption("example_maxtime")&gt;39) {
 slik &lt;- refine(slik) 
}
</code></pre>

<hr>
<h2 id='example_raw_proj'>Workflow for primitive method, with projections</h2><span id='topic+example_raw_proj'></span>

<h3>Description</h3>

<p>Example of the workflow with <code>add_simulation</code>), implementing the method described in the original publication 
(Rousset et al. 2017 &lt;doi:10.1111/1755-0998.12627&gt;), modified to use projectors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;170) {
## Normal(mu,sd) model, with inefficient raw summary statistics:
## To illustrate that case we transform normal random deviates rnorm(,mu,sd)
## so that the mean of transformed sample is not sufficient for mu,
## and the variance of transformed sample is not sufficient for sd.
blurred &lt;- function(mu,s2,sample.size) {
  s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
  s &lt;- exp(s/4)
  return(c(mean=mean(s),var=var(s)))
}

set.seed(123)
dSobs &lt;- blurred(mu=4,s2=1,sample.size=20) ## stands for the actual data to be analyzed

## Sampling design as in canonical example 
parsp &lt;- init_grid(lower=c(mu=2.8,s2=0.4,sample.size=20),
                      upper=c(mu=5.2,s2=2.4,sample.size=20))
# simulate distributions
dsimuls &lt;- add_simulation(,Simulate="blurred", par.grid=parsp) 

## Use projection to construct better summary statistics for each each parameter 
mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls)
s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls)

## additional plots for some projection method
if (inherits(mufit,"HLfit")) mapMM(mufit,map.asp=1,
  plot.title=title(main="prediction of normal mean",xlab="exp mean",ylab="exp var"))
if (inherits(s2fit,"HLfit")) mapMM(s2fit,map.asp=1,
  plot.title=title(main="prediction of normal var",xlab="exp mean",ylab="exp var"))

## apply projections on simulated statistics
corrSobs &lt;- project(dSobs,projectors=list("MEAN"=mufit,"VAR"=s2fit))
corrSimuls &lt;- project(dsimuls,projectors=list("MEAN"=mufit,"VAR"=s2fit))

## Analyze 'projected' data as any data (cf canonical example)
densb &lt;- infer_logLs(corrSimuls,stat.obs=corrSobs) 
} else data(densb)
#########
if (Infusion.getOption("example_maxtime")&gt;10) {
slik &lt;- infer_surface(densb) ## infer a log-likelihood surface
slik &lt;- MSL(slik) ## find the maximum of the log-likelihood surface
}
if (Infusion.getOption("example_maxtime")&gt;500) {
slik &lt;- refine(slik,10, update_projectors=TRUE) ## refine iteratively
}
</code></pre>

<hr>
<h2 id='example_reftable'>Workflow for method with reference table</h2><span id='topic+example_reftable'></span>

<h3>Description</h3>

<p>Examples of workflow with a reference table produced by <code>add_reftable</code>, possibly faster in many applications than the originally described method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;46) {

  ## Normal(mu,sd) model, with inefficient raw summary statistics:
  ## To illustrate that case we transform normal random deviates rnorm(,mu,sd)
  ## so that the mean of transformed sample is not sufficient for mu,
  ## and the variance of transformed sample is not sufficient for sd.
  blurred &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    s &lt;- exp(s/4)
    return(c(mean=mean(s),var=var(s)))
  }
  
  ## pseudo-sample which stands for the actual data to be analyzed:  
  set.seed(123)
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40)
  
  ## Construct reference table:
  parsp_j &lt;- data.frame(mu=runif(600L,min=2.8,max=5.2),
                        s2=runif(600L,min=0.4,max=2.4),sample.size=40)
  dsimuls &lt;- add_reftable(,Simulate="blurred",par.grid=parsp_j,verbose=FALSE)
  
  #- When no 'Simulate' function is provided, 
  #- but only a data.frame 'toydf' of simulations,
  #- a formal reference table can be produced by  
  # dsimuls &lt;- structure(toydf, LOWER=c(mu=2,s2=0,sample.size=40))
  # dsimuls &lt;- add_reftable(dsimuls)
  #- where the 'LOWER' attribute tells 
  #- the parameters apart from the summary statistics.
  
  ## Construct projections
  mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls,verbose=FALSE)
  s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls,verbose=FALSE)
  dprojectors &lt;- list(MEAN=mufit,VAR=s2fit)
  
  ## Apply projections on simulated statistics and 'data':
  dprojSimuls &lt;- project(dsimuls,projectors=dprojectors,verbose=FALSE)
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  
  ## Summary-likelihood inference:
  # Infer log-likelihood surface
  slik_j &lt;- infer_SLik_joint(dprojSimuls,stat.obs=dprojSobs,verbose=TRUE)
  # Find maximum, confidence intervals...
  slik_j &lt;- MSL(slik_j)
  
  # Convenience function for plotting projections...
  plot_proj(slik_j, parm="mu", proj="MEAN")
  
  # ... and for computing likelihoods for new parameters and/or data:
  summLik(slik_j, parm=slik_j$MSL$MSLE+0.1)
  
  ## refine estimates iteratively
  slik_j &lt;- refine(slik_j,maxit=5, update_projectors=TRUE)
  
  if (Infusion.getOption("example_maxtime")&gt;99) { # Post-fit procedures,
    #                                   all with distinct documentation: 
  
    plot(slik_j)
    profile(slik_j,c(mu=4)) ## profile summary logL for given parameter value
    confint(slik_j,"mu") ## compute 1D confidence interval for given parameter
    plot1Dprof(slik_j,pars="s2",gridSteps=40) ## 1D profile
    summary(slik_j) # or print()
    logLik(slik_j)
    
    SLRT(slik_j, h0=slik_j$MSL$MSLE+0.1, nsim = 100L) # LRT
    SLRT(slik_j, h0=slik_j$MSL$MSLE[1]+0.1, nsim = 100L) # profile LRT
    
    goftest(slik_j) # goodness of fit test
    
    # Low-level predict() method (rarely directly used, otherwise see its documentation!)
    predict(slik_j, newdata = slik_j$MSL$MSLE)         # the 'data' are here parameters!

    
  }
}
</code></pre>

<hr>
<h2 id='extractors'>
Summary, print and logLik methods for Infusion results.
</h2><span id='topic+extractors'></span><span id='topic+summary'></span><span id='topic+print'></span><span id='topic+logLik'></span><span id='topic+summary.logLs'></span><span id='topic+summary.SLik'></span><span id='topic+summary.SLik_j'></span><span id='topic+summary.SLikp'></span><span id='topic+print.SLik'></span><span id='topic+print.SLik_j'></span><span id='topic+print.logLs'></span><span id='topic+print.SLikp'></span><span id='topic+logLik.SLik'></span><span id='topic+logLik.SLik_j'></span>

<h3>Description</h3>

<p><code>summary</code> prints information about the fit.
<code>print</code> is an alias for <code>summary</code>.
<code>logLik</code> extracts the log-likelihood (exact or approximated). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
summary(object, ...)
## S3 method for class 'SLik'
print(x, ...)
## S3 method for class 'SLik'
logLik(object, ...)
# and identical usage for 'SLik_j' objects
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractors_+3A_object">object</code>, <code id="extractors_+3A_x">x</code></td>
<td>

<p>An object of class <code>SLik</code> or  <code>SLik_j</code>;
</p>
</td></tr>
<tr><td><code id="extractors_+3A_...">...</code></td>
<td>
<p>  further arguments passed to or from other methods (currently without any specific effect). </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>logLik</code> returns the inferred likelihood maximum, with attribute <code>RMSE</code> giving its root means square error of estimation. 
<code>summary</code> and <code>summary</code> return the object invisibly. They print details of the fits in a convenient form.
</p>


<h3>Note</h3>

<p>See workflow example in <code><a href="#topic+example_reftable">example_reftable</a></code>.</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+get_from">get_from</a></code> for a more general interface for extracting elements from Infusion results, and <code><a href="#topic+summLik">summLik</a></code> for using a fit object to evaluate the likelihood function for distinct parameter values and even distinct data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See Note
</code></pre>

<hr>
<h2 id='focal_refine'>
Refine summary likelihood profile in focal parameter values
</h2><span id='topic+focal_refine'></span>

<h3>Description</h3>

<p>This function refines an <code>SLik_j</code> object in a focused way defined by focal parameter values. It is paticularly useful to check a suspect pattern in a likelihood profile. If there is a suspect dip or peak at value &lt;somepar&gt;=&lt;somevalue&gt;, <code>focal_refine(</code>&lt;SLik_j object&gt;<code>, focal</code>=c(&lt;somepar&gt;=&lt;somevalue&gt;)<code>, size</code>=&lt;size&gt;) will define &lt;size&gt; parameter points near <code>c(</code>&lt;somepar&gt;=&lt;somevalue&gt;) and (subject to these points being in the parameter bounds of the object) simulate new samples for these parameter points and refine the object using these new simulations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>focal_refine(object, focal, size, plotprof = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="focal_refine_+3A_object">object</code></td>
<td>

<p>An object of class <code>SLik_j</code>.
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_focal">focal</code></td>
<td>

<p>Parameter value(s) (as a vector of named values) 
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_size">size</code></td>
<td>

<p>Target number of points to add to the reference table
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_plotprof">plotprof</code></td>
<td>

<p>Whether to replot a likelihood profile (1D or 2D depending on the dimension of <code>focal</code>).
</p>
</td></tr>
<tr><td><code id="focal_refine_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code>profile.SLik_j</code> (but not including argument <code>return.optim</code>) or <code>refine</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The updated <code>object</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Using the slik_j object from the toy example in help("example_reftable"):

plot1Dprof(slik_j,"s2")
slik_fix &lt;- focal_refine(slik_j,focal=c(s2=2), size=100)
plot1Dprof(slik_fix,"s2")

# In that case the effect is not spectacular because 
# there is no major problem in the starting profile. 

## End(Not run)
</code></pre>

<hr>
<h2 id='get_from'>
Backward-compatible extractor from summary-likelihood objects
</h2><span id='topic+get_from'></span><span id='topic+get_from.default'></span><span id='topic+get_from.SLik'></span><span id='topic+get_from.SLik_j'></span><span id='topic+get_from'></span>

<h3>Description</h3>

<p>A generic function, whose default method works for list, and with specific methods for objects inheriting from classes <code>SLik_j</code> and <code>SLik</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_from(object, which, ...)

## S3 methods with additional argument(s)
## S3 method for class 'SLik'
get_from(object, which, raw=FALSE, force=FALSE, ...)
## S3 method for class 'SLik_j'
get_from(object, which, raw=FALSE, force=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_from_+3A_object">object</code></td>
<td>

<p>Any object with a list structure.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_which">which</code></td>
<td>

<p>Character: names of element to be extracted.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_raw">raw</code></td>
<td>

<p>Boolean: if TRUE, <code>object[[which]]</code> is returned, without any particular check of its value. By default, <code>raw</code> is FALSE and various operations may be performed on the extracted value (see &ldquo;example&rdquo; below), including optional recomputation if <code>force</code> is TRUE.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_force">force</code></td>
<td>

<p>Boolean: if TRUE, the extracted element may be computed if it appears to be missing from the <code>object</code>. This is notably so for <code>which="RMSEs"</code> or <code>which="par_RMSEs"</code>;  in these cases, the results of the computation are further saved in the original object.
</p>
</td></tr>
<tr><td><code id="get_from_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Will depend on <code>which</code>, but aims to retain a convenient format backward compatible with version 1.4.0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logLik">logLik</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # # 0bserved summary statistics 
  # #  (projected, with raw ones as attribute, if relevant)
  #   get_from(slik, "obs") 
  # 
  # # On any summary-likelihood object 'slik':
  #   get_from(slik, which="par_RMSEs") # matrix
  # # despite &lt;object&gt;$par_RMSEs being an environment if 
  # #  'slik' was created by version &gt; 1.4.0, as then shown by
  #   get_from(slik, which="par_RMSEs", raw=TRUE)
  #
  # # Further, if 
  #   get_from(slik, which="par_RMSEs")
  # # returns NULL because the element is absent from the object, 
  # # then one can force its computation by 
  #   get_from(slik, which="par_RMSEs", force=TRUE)
  # # The result are saved in the 'slik' object, so running again 
  #   get_from(slik, which="par_RMSEs")
  # # will no longer return NULL.
</code></pre>

<hr>
<h2 id='get_LRboot'>
Summary likelihood ratio tests
</h2><span id='topic+get_LRboot'></span><span id='topic+SLRT'></span>

<h3>Description</h3>

<p><code>get_LRboot</code> provides a fast approximation to bootstrap distribution of likelihood ratio statistic.
The bootstrap distribution of the likelihood ratio (LR) statistic may be used to correct the tests based on its asymptotic chi-square distribution. However, the standard bootstrap involves resimulating the data-generating process, given the ML estimates on the original data. This function implements a fast approximation avoiding such simulation, instead drawing from the inferred distribution of (projected, if relevant) summary statistics, again given the maximum (summary-)likelihood estimates.   
</p>
<p><code>SLRT</code> computes likelihood ratio tests based on the summary-likelihood surface and optionally on <code>get_LRboot</code> results. Several correction of the basic likelihood ratio test may be reported, some more speculative than others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLRT(object, h0, nsim=0L, BGP=NULL, ...)
get_LRboot(object, h0_pars = NULL, nsim = 100L, reset = TRUE, BGP=object$MSL$MSLE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_LRboot_+3A_object">object</code></td>
<td>

<p>an <code>SLik_j</code> object.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_h0">h0</code></td>
<td>

<p>Numeric named vector of tested parameter values.    
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_h0_pars">h0_pars</code></td>
<td>

<p>either <code>NULL</code> (the default), to approximate the distribution of the LR statistic for the full vector of estimated parameters; or a vector of names of a subset of this vector, to approximate the distribution of the profile LR statistic for this subset.    
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_nsim">nsim</code></td>
<td>

<p>Integer: number of bootstrap replicates. Values lower than the default are not recommended. Note that this will be ignored if the distribution has previously been simulated and <code>reset=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_reset">reset</code></td>
<td>

<p>Boolean: Whether to use any previously computed distribution (see Details) or not.
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_bgp">BGP</code></td>
<td>
<p>Named numeric vector of &ldquo;Bootstrap-Generating Parameters&rdquo;. Ideally the distribution of the LR test statistic would be pivotal and thus the parameter values under which this distribution is simulated would not matter. In practice, simulating by default its distribution under the &ldquo;best&rdquo; available information (the MSLE for <code>get_LRboot</code>, or the specifically tested hypothesis defined by the <code>h0</code> argument of <code>SLRT</code>) may be more accurate than under alternative parametric values. For <code>h0</code> being an incomplete parameter vector and <code>BGP</code> is NULL (the default), <code>SLRT</code> will simulate under a completed parameter vector using estimates of other parameters maximizing the likelihood profile for <code>h0</code>. 
</p>
</td></tr>
<tr><td><code id="get_LRboot_+3A_...">...</code></td>
<td>

<p>For <code>SLRT</code>: further arguments passed to <code>get_LRboot</code>. For <code>get_LRboot</code>: further arguments controlling parallelization, including <code>nb_cores</code>. However, parallelization may be best ignored in most cases (see Details).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The result of calling <code>get_LRboot</code> (either directly or through <code>SLRT</code>) with given <code>h0_pars</code> is stored in the <code>object</code> (until the next <code>refine</code>), and this saved result is returned by a next call to <code>get_LRboot</code> with the same <code>h0_pars</code> if <code>reset=FALSE</code>. The default is however to recompute the distribution (<code>reset=TRUE</code>).
</p>
<p>Parallelization is possible but maybe not useful because computations for each bootstrap replicate are fast relative to parallelization overhead. It will be called when the ... arguments include an <code>nb_cores</code>&gt;1. The ... may include further arguments passed to <code><a href="spaMM.html#topic+dopar">dopar</a></code>, but among the <code>dopar</code> arguments, <code>iseed</code> will be ignored, and <code>fit_env</code> should not be used.
</p>
<p>A raw bootstrap p-value can be computed from the simulated distribution as <code>(1+sum(t &gt;= t0))/(N+1)</code> where <code>t0</code> is the original likelihood ratio, <code>t</code> the vector of bootstrap replicates and <code>N</code> its length. See Davison &amp; Hinkley (1997, p. 141) for discussion of the adjustments in this formula. However, a sometimes more economical use of the bootstrap is to provide a Bartlett correction for the likelihood ratio test in small samples. According to this correction, the mean value <code class="reqn">m</code> of the likelihood ratio statistic under the null hypothesis is computed (here estimated by simulation) and the original LR statistic is multiplied by <code class="reqn">n/m</code> where <code class="reqn">n</code> is the number of degrees of freedom of the test. Unfortunately, the underlying assumption that the corrected LR statistic follows the chi-square distribution does not always work well. 
</p>


<h3>Value</h3>

<p><code>get_LRboot</code> returns a numeric vector representing the simulated distribution of the LR statistic, i.e. <b>twice</b> the log-likelihood difference, as directly used in <code>pchisq()</code> to get the p-value.
</p>
<p><code>SLRT</code> returns a list with the following element(s), each being a one-row data frame:
</p>
<table>
<tr><td><code>basicLRT</code></td>
<td>
<p>A data frame including values of the likelihood ratio chi2 statistic, its degrees of freedom, and the p-value;</p>
</td></tr>
</table>
<p>and, if a bootstrap was performed: 
</p>
<table>
<tr><td><code>BartBootLRT</code></td>
<td>
<p>A data frame including values of the Bartlett-corrected likelihood ratio chi2 statistic, its degrees of freedom, and its p-value;</p>
</td></tr>
<tr><td><code>rawBootLRT</code></td>
<td>
<p>A data frame including values of the likelihood ratio chi2 statistic, its degrees of freedom, and the raw bootstrap p-value;</p>
</td></tr>
<tr><td><code>safeBartBootLRT</code></td>
<td>
<p>equal to <code>rawBootLRT</code> if the mean bootstrap value of the LR statistic is lower than the number of degrees of freedom, and to <code>BartBootLRT</code> otherwise.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bartlett, M. S. (1937) Properties of sufficiency and statistical tests. Proceedings of the Royal Society (London) A 160: 268-282.
</p>
<p>Davison A.C., Hinkley D.V. (1997) Bootstrap methods and their applications. Cambridge Univ. Press, Cambridge, UK.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## See help("example_reftable") for SLRT() examples;
## continuing from there, after refine() steps for good results:
# set.seed(123);mean(get_LRboot(slik_j, nsim=500, reset=TRUE)) # close to df=2 
# mean(get_LRboot(slik_j, h0_pars = "s2", nsim=500, reset=TRUE)) # close to df=1 

## Not run: 
### Simulation study of performance of the corrected LRTs: 

## Same toy example as in help("example_reftable"):
blurred &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    s &lt;- exp(s/4)
    return(c(mean=mean(s),var=var(s)))
  }

## First build a largish reference table and projections to be used in all replicates
# Only the 600 first rows will be used as initial reference table for each "data"
#
set.seed(123)
#
parsp_j &lt;- data.frame(mu=runif(6000L,min=2.8,max=5.2),
                      s2=runif(6000L,min=0.4,max=2.4),sample.size=40)
dsimuls &lt;- add_reftable(,Simulate="blurred",par.grid=parsp_j,verbose=FALSE)
#
mufit &lt;- project("mu",stats=c("mean","var"),data=dsimuls,verbose=TRUE)
s2fit &lt;- project("s2",stats=c("mean","var"),data=dsimuls,verbose=TRUE)
dprojectors &lt;- list(MEAN=mufit,VAR=s2fit)
dprojSimuls &lt;- project(dsimuls,projectors=dprojectors,verbose=FALSE)

## Function for single-data analysis:
#
foo &lt;- function(y, refine_maxit=0L, verbose=FALSE) {
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40) 
  ## ----Inference workflow-----------------------------------------------
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  dslik &lt;- infer_SLik_joint(dprojSimuls[1:600,],stat.obs=dprojSobs,verbose=FALSE)
  dslik &lt;- MSL(dslik, verbose=verbose, eval_RMSEs=FALSE)
  if (refine_maxit) dslik &lt;- refine(dslik, maxit=refine_maxit)
  ## ---- LRT-----------------------------------------------
  lrt &lt;- SLRT(dslik, h0=c(s2=1), nsim=200)
  c(basic=lrt$basicLRT$p_value,raw=lrt$rawBootLRT$p_value,
    bart=lrt$BartBootLRT$p_value,safe=lrt$safeBartBootLRT$p_value)
}

## Simulations using convenient parallelization interface:
#
# library(doSNOW) # optional
#
bootreps &lt;- spaMM::dopar(matrix(1,ncol=200,nrow=1),              # 200 replicates of foo()
  fn=foo, fit_env=list(blurred=blurred, dprojectors=dprojectors, dprojSimuls=dprojSimuls), 
  control=list(.errorhandling = "pass", .packages = "Infusion"),
  refine_maxit=5L,
  nb_cores=parallel::detectCores()-1L, iseed=123)
#
plot(ecdf(bootreps["basic",]))
abline(0,1)
plot(ecdf(bootreps["bart",]), add=TRUE, col="blue")
plot(ecdf(bootreps["safe",]), add=TRUE, col="red")
plot(ecdf(bootreps["raw",]), add=TRUE, col="green") 
#
# Note that refine() iterations are important for good performance.
# Without them, even a larger reftable of 60000 lines 
# may exhibit poor results for some of the CI types.

## End(Not run)
</code></pre>

<hr>
<h2 id='get_nbCluster_range'>
Control of number of components in Gaussian mixture modelling
</h2><span id='topic+get_nbCluster_range'></span><span id='topic+refine_nbCluster'></span><span id='topic+seq_nbCluster'></span>

<h3>Description</h3>

<p>These functions implement the default values for the number of components tried in Gaussian mixture modelling (matching the <code>nbCluster</code> argument of <code>Rmixmod::mixmodCluster()</code>). <code>get_nbCluster_range</code> allows the user to reproduce the internal rules used by <span class="pkg">Infusion</span> to determine this argument. <code>seq_nbCluster</code> is a wrapper to the function defined by the <code>seq_nbCluster</code> global option of the package. Its default result is a sequence of integers determined by the number of rows of the data (see <code><a href="#topic+Infusion.options">Infusion.options</a></code>). <code>get_nbCluster_range()</code> further checks the feasibility of the values generated by <code>seq_nbCluster())</code>, using additional criteria involving the number of columns of the data to determine the maximum feasible number of clusters. This maximum is controlled by the function defined by the <code>maxnbCluster</code> global option of the package. 
</p>
<p><code>refine_nbCluster</code> controls the default number of clusters of <code><a href="#topic+refine">refine</a></code>: it gets the range from <code>seq_nbCluster</code> and keeps only the maximum value of this range if this maximum is higher than the <code>onlymax</code> argument.
</p>
<p>Adventurous users can change the rules used by <span class="pkg">Infusion</span> by changing the global options <code>seq_nbCluster</code> and <code>maxnbCluster</code> (while conforming to the interfaces of these functions). Less ambitiously, they can for example use the maximum value of the result of <code>get_nbCluster_range()</code> as a single reasonable value for the <code>nbCluster</code> argument of <code>infer_SLik_joint</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_nbCluster(nr)
refine_nbCluster(nr, onlymax=7)
get_nbCluster_range(projdata, nr = nrow(projdata), nc = ncol(projdata), 
                    nbCluster = seq_nbCluster(nr))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_nbCluster_range_+3A_projdata">projdata</code></td>
<td>
<p>data frame: the data to be clustered, which typically include parameters and <b>projected</b> summary statistics;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_nr">nr</code></td>
<td>
<p>integer: number of rows of the data to be clustered;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_onlymax">onlymax</code></td>
<td>
<p>integer: see Description;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_nc">nc</code></td>
<td>
<p>integer: number of columns of the data to be clustered, typically <b>twice</b> the number of estimated parameters;</p>
</td></tr>
<tr><td><code id="get_nbCluster_range_+3A_nbcluster">nbCluster</code></td>
<td>
<p>integer or vector of integers: candidate values, which feasability is checked by the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> An integer vector</p>


<h3>Examples</h3>

<pre><code class='language-R'># Determination of number of clusters when attempting to estimate 
#   20 parameters from a reference table with 30000 rows:
seq_nbCluster(nr=30000L)
get_nbCluster_range(nr=30000L, nc=40L) # nc = *twice* the number of parameters
</code></pre>

<hr>
<h2 id='goftest'>
Assessing goodness of fit of inference using simulation
</h2><span id='topic+goftest'></span>

<h3>Description</h3>

<p>A goodness-of-fit test is performed in the case projected statistics have been used for inference. Otherwise some plots of limited interest are produced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goftest(object, nsim = 99L, method = "", stats=NULL, plot. = TRUE, nb_cores = NULL, 
        Simulate = attr(object$logLs, "Simulate"), 
        packages = attr(object$logLs, "packages"), 
        env = attr(object$logLs, "env"), verbose = interactive(),
        cl_seed=.update_seed(object), get_gof_stats=.get_gof_stats)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goftest_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_nsim">nsim</code></td>
<td>

<p>Number of draws of summary statistics.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_method">method</code></td>
<td>

<p>For development purposes, not documented.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_stats">stats</code></td>
<td>

<p>Character vector, or NULL: the set of summary statistics to be used to construct the test. If NULL, the union, across all projections, of the raw summary statistics used for projections is potentially used for goodness of fit; however, if this set is too large for gaussian mixture modelling, a subset of variable may be selected. How they are selected is not yet fully settled (see Details).  
</p>
</td></tr>
<tr><td><code id="goftest_+3A_plot.">plot.</code></td>
<td>

<p>Control diagnostic plots. <code>plot.</code> can be of logical, character or numeric type. If <code>plot.</code> is <code>FALSE</code>, no plot is produced. If <code>plot.</code> is <code>TRUE</code> (the default), a data frame of up to 8 goodness-of-fit statistics (the statistics denoted <em>u</em> in Details) is plotted. If more than eight raw summary statistics (denoted <em>s</em> in Details) were used, then only the first eight <em>u</em> are retained (see Details for the ordering of the <em>u</em>s here). 
If <code>plot.</code> is a <b>numeric vector</b>, then <em>u</em><code>[plot.]</code> are retained (possibly more than 8 statistics, as in the next case). If <code>plot.</code> is a <b>character vector</b>, then it is used to match the names of the <em>u</em> statistics (not of <em>s</em>) to be retained in the plot; the names of <em>u</em> are built from names of <em>s</em> by wrapping the latter within <code>"Res(".")"</code> (see axes labels of default plots for examples of valid names).    
</p>
</td></tr>
<tr><td><code id="goftest_+3A_nb_cores">nb_cores</code>, <code id="goftest_+3A_simulate">Simulate</code>, <code id="goftest_+3A_packages">packages</code>, <code id="goftest_+3A_env">env</code>, <code id="goftest_+3A_verbose">verbose</code></td>
<td>

<p>See same-named <code><a href="#topic+add_simulation">add_simulation</a></code> arguments.
</p>
</td></tr>
<tr><td><code id="goftest_+3A_cl_seed">cl_seed</code></td>
<td>
<p>NULL or integer (see <code><a href="#topic+refine">refine</a></code> for Details).</p>
</td></tr>
<tr><td><code id="goftest_+3A_get_gof_stats">get_gof_stats</code></td>
<td>
<p>function for selecting raw statistics (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Testing goodness-of-fit:</b> The test is somewhat heuristic but appears to give reasonable results (the Example shows how this can be verified). It assumes that all summary statistics are reduced to projections predicting all model parameters. It is then conceived as if any projection <em>p</em> predicting a parameter were a sufficient statistic for this parameter, given the information contained in the summary statistics <b>s</b> (this is certainly the ideal objective of machine-learning regression methods). Then a statistic <em>u</em> independent (under the fitted model) from all projections should be a suitable statistic for testing goodness of fit: if the model is correctly specified, the quantile of observed <em>u</em>, in the distribution of <em>u</em> under the fitted model, should be uniformly distributed over repeated sampling under the data-generating process. The procedure constructs statistics uncorrelated to all <b>p</b> (over repeated sampling under the fitted model) and proceeds as if they were independent from <em>p</em> (rather than simply uncorrelated). A number (depending on the size of the reference table) of statistics <em>u</em> uncorrelated to <em>p</em> are then defined. Each such statistic is obtained as the residual of the regression of a given raw summary statistic to all projections, where the regression input is a simulation table of <code>nsim</code> replicates of <b>s</b> under the fitted model, and of their projections <b>p</b> (using the &ldquo;projectors&rdquo; constructed from the full reference table). The latter regression involves one more, small-<code>nsim</code>, approximation (as it is the sample correlation that is zeroed) but using the residuals is crucially better than using the original summary statistics (as some ABC software may do). An additional feature of the procedure is to construct a single test statistic <em>t</em> from joint residuals <b>u</b>, by estimating their joint distribution (using Gaussian mixture modelling) and letting <em>t</em> be the density of <b>u</b> in this distribution.  
</p>
<p><b>Selection of raw summary statistics:</b> See the code of the <code>Infusion:::..get_gof_stats</code> function for the method used. It requires that <code>ranger</code> has been used to produce the projectors, and that the latter include variable importance statistics (by default, <span class="pkg">Infusion</span> calls <code>ranger</code> with argument <code>importance="permutation"</code>). <code>.get_gof_stats</code> then selects the raw summary statistics with <em>least</em> importance over projections (this may not be optimal, and in particular appears redundant with the procedure described below to construct goodness-of-fit statistics from raw summary statistics; so this might change in a later version), and returns a vector of names of raw statistics, sorted by increasing least-importance. The number of summary statistics can be controlled by the global package option <code>gof_nstats_fn</code>, a function with arguments <code>nr</code> and <code>nstats</code> for, respectively, the number of simulations of the processus (as controlled by <code>goftest(.,nsim)</code>) and the total number of raw summary statistics used in the projections.
</p>
<p>The <b>diagnostic plot</b> will show a data frame of residuals <em>u</em> of the summary statistics identified as the first elements of the vector returned by <code>Infusion:::..get_gof_stats</code>, i.e. again a set of raw statistics with least-importance over projectors. 
</p>


<h3>Value</h3>

<p>A list with currently a single element
</p>
<table>
<tr><td><code>pval</code></td>
<td>
<p>The p-value of the test (NULL if the test is not feasible).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>### See end of example("example_reftable") for minimal example.

## Not run: 
### Performance of GoF test over replicate draws from data-generating process

# First, run 
example("example_reftable") 
# (at least up to the final 'slik_j' object), then

# as a shortcut, the same projections will be used in all replicates:
dprojectors &lt;- slik_j$projectors 

set.seed(123)
gof_draws &lt;- replicate(200, {
  cat(" ")
  dSobs &lt;- blurred(mu=4,s2=1,sample.size=40) 
  ## ----Inference workflow-----------------------------------------------
  dprojSobs &lt;- project(dSobs,projectors=dprojectors)
  dslik &lt;- infer_SLik_joint(dprojSimuls,stat.obs=dprojSobs,verbose=FALSE)
  dslik &lt;- MSL(dslik, verbose=FALSE, eval_RMSEs=FALSE)
  ## ----GoF test-----------------------------------------------
  gof &lt;- goftest(dslik,nb_cores = 1L, plot.=FALSE,verbose=FALSE) 
  cat(unlist(gof))
  gof
})
# ~ uniform distribution under correctly-specified model: 
plot(ecdf(unlist(gof_draws)))

## End(Not run)

</code></pre>

<hr>
<h2 id='handling_NAs'>
Discrete probability masses and NA/NaN/Inf in distributions of summary statistics.
</h2><span id='topic+handling_NAs'></span><span id='topic+NA_handling'></span><span id='topic+boundaries-attribute'></span>

<h3>Description</h3>

<p>This explains the use of the <code>boundaries</code> attribute of observed statistics to handle (1) values of the summary statistics that can occur with some probability mass; (2) special values (NA/NaN/Inf) in distributions of summary statistics. This further explains why <code>Infusion</code> handles special values by removing affected distributions unless the <code>boundaries</code> attribute is used.   
</p>


<h3>Details</h3>

<p>Special values may be encountered in an analysis. For example, trying to estimate a regression coefficient when the predictor variable is constant may return a NaN. Since functions such as <code>refine</code> automatically add simulated distributions, this problem must be automatically handled by the user's simulation function or by the package functions, rather than by user's tinkering with the Infusion procedures.   
</p>
<p>The user must consider what s-he would do if actual data also included NA/NaN/Inf values. If such data would not be subject to a statistical analysis, then the simulation procedure must reflect that, otherwise the analysis will be biased. The processing of reference tables by Infusion functions applies <code>na.omit()</code> on the tables so any line containing NA's will be removed. The drawbacks are that the number of informative simulations is reduced and that inference will be difficult if the data-generating parameters were indeed prone to induce data that would not be subject to statistical analysis. Thus, it may be necessary to simulate alternative data until no special values are obtained and the target size of the simulated distribution is reached. One solution is for the user to write a simulation function that calls itself recursively until a valid summary statistic is produced. Care is then needed to avoid infinite recursion (which might well indicate unlikely parameter values). 
</p>
<p>Alternatively, if one considers that special values are informative about parameters (in the above example of a regression coefficient, if a constant predictor variable says something about the parameters), then NA/NaN/Inf must be replaced by a (fixed) dummy numerical value which is flagged to be distinctly handled, using the <code>boundaries</code> attribute of the observed summary statistics. The simulation function should return statistic <code>foo=-1</code> (say) instead of <code>foo=NaN</code>, and one should then set <code>attr(&lt;observed&gt;,"boundaries") &lt;- c(foo=-1)</code>. 
</p>
<p>The boundary attribute is also useful to handle all values of the summary statistics that can occur with some probability mass. For example if the estimate <code>est_p</code> of a probability takes values 0 or 1 with positive probability, one should set <code>attr(&lt;observed&gt;,"boundaries") &lt;- c(p_est=0,p_est=1)</code>.
</p>

<hr>
<h2 id='infer_logLs'>
Infer log Likelihoods using simulated distributions of summary statistics
</h2><span id='topic+infer_logLs'></span><span id='topic+infer_tailp'></span><span id='topic+infer_logL_by_GLMM'></span><span id='topic+infer_logL_by_Rmixmod'></span><span id='topic+infer_logL_by_mclust'></span><span id='topic+infer_logL_by_Hlscv.diag'></span>

<h3>Description</h3>

<p>For each simulated distribution of summary statistics, <code>infer_logLs</code> infers a probability density function, and the density of the observed values of the summary statistics is deduced. By default, inference of each density is performed by <code>infer_logL_by_Rmixmod</code>, which fits a distribution of summary statistics using procedures from the <code>Rmixmod</code> package.        
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer_logLs(object, stat.obs, 
            logLname = Infusion.getOption("logLname"), 
            verbose = list(most=interactive(), 
                           final=FALSE), 
            method = Infusion.getOption("mixturing"),
            nb_cores = NULL, packages = NULL, cluster_args,
            ...)
infer_tailp(object, refDensity, stat.obs,
                tailNames=Infusion.getOption("tailNames"),
                verbose=interactive(), method=NULL, cluster_args, ...)
infer_logL_by_GLMM(EDF,stat.obs,logLname,verbose)
infer_logL_by_Rmixmod(EDF,stat.obs,logLname,verbose)
infer_logL_by_mclust(EDF,stat.obs,logLname,verbose)
infer_logL_by_Hlscv.diag(EDF,stat.obs,logLname,verbose)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer_logLs_+3A_object">object</code></td>
<td>

<p>A list of simulated distributions (the return object of <code><a href="#topic+add_simulation">add_simulation</a></code>)
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_edf">EDF</code></td>
<td>

<p>An empirical distribution, with a required <code>par</code> attribute (an element of the <code>object</code> list).
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_stat.obs">stat.obs</code></td>
<td>

<p>Named numeric vector of observed values of summary statistics.
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_loglname">logLname</code></td>
<td>

<p>The name to be given to the log Likelihood in the return object, or the root of the latter name in case of conflict with other names in this object.
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_tailnames">tailNames</code></td>
<td>

<p>Names of &ldquo;positives&rdquo; and &ldquo;negatives&rdquo; in the binomial response for the inference of tail probabilities. 
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_refdensity">refDensity</code></td>
<td>

<p>An object representing a reference density (such as an <code><a href="spaMM.html#topic+HLfit">HLfit</a></code> fit object or other objects with a similar <code>predict</code> method) which, together with the density inferred from each empirical density, defines a likelihood ratio used to define a rejection region.   
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_verbose">verbose</code></td>
<td>
<p> A list as shown by the default, or simply a vector of booleans, indicating respectively
whether to display (1) some information about progress; (2) a final summary of the results after all elements of <code>simuls</code> have been processed. If a count of 'outlier'(s) is reported, this typically means that <code>stat.obs</code> is not within the envelope of a simulated distribution (or whatever other meaning the user attaches to an <code>FALSE isValid</code> code: see Details)
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_method">method</code></td>
<td>

<p>A function for density estimation. See Description for the default behaviour and Details for the constraints on input and output of the function. 
</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Number of cores for parallel computation. The default is <code>spaMM.getOption("nb_cores")</code>, and 1 if the latter is NULL. <code>nb_cores=1</code> which prevents the use of parallelisation procedures.</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. May contain a non-null <code>spec</code> element, in which case the distinct <code>nb_cores</code> argument is ignored.</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_packages">packages</code></td>
<td>
<p>For parallel evaluation: Names of additional libraries to be loaded on the cores, necessary for evaluation of a user-defined 'method'.</p>
</td></tr>
<tr><td><code id="infer_logLs_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, density estimation is based on <code>Rmixmod</code> methods. Other available methods are not routinely used and not all of <code>Infusion</code> features may work with them. The function <code>Rmixmod::mixmodCluster</code>
is called, with arguments <code>nbCluster=seq_nbCluster(nr=nrow(data))</code> and <code>mixmodGaussianModel=Infusion.getOption("mixmodGaussianModel")</code>. If <code>Infusion.getOption("seq_nbCluster")</code> specifies a sequence of values, then several clusterings are computed and AIC is used to select among them.  
</p>
<p><code>infer_logL_by_GLMM</code>, <code>infer_logL_by_Rmixmod</code>, <code>infer_logL_by_mclust</code>, and <code>infer_logL_by_Hlscv.diag</code> are examples of the method that may be provided for density estimation. Other <code>method</code>s may be provided with the same arguments. Their return value must include the element <code>logL</code>, an estimate of the log-density of <code>stat.obs</code>, and the element <code>isValid</code> with values <code>FALSE</code>/<code>TRUE</code> (or 0/1). The standard format for the return value is <code>unlist(c(attr(EDF,"par"),logL,isValid=isValid))</code>.
</p>
<p><code>isValid</code> is primarily intended to indicate whether the log likelihood of <code>stat.obs</code> inferred by a given density estimation method was suitable input for inference of the likelihood surface. <code>isValid</code> has two effects: to distinguish points for which isValid is FALSE in the plot produced by <code><a href="#topic+plot.SLik">plot.SLik</a></code>; and more critically, to control the sampling of new parameter points within <code><a href="#topic+refine">refine</a></code> so that points for which isValid is FALSE are less likely to be sampled. 
</p>
<p>Invalid values may for example indicate a likelihood estimated as zero (since log(0) is not suitable input), or (for density estimation methods which may infer erroneously large values when extrapolating), whether <code>stat.obs</code> is within the convex hull of the EDF. In user-defined <code>method</code>s, invalid inferred logL should be replaced by some alternative low estimate, as all methods included in the package do.    
</p>
<p>The source code of <code>infer_logL_by_Hlscv.diag</code> illustrates how to test whether <code>stat.obs</code> is within the convex hull of the EDF, using functions <code>resetCHull</code> and <code>isPointInCHull</code> (exported from the <code>blackbox</code> package).
</p>
<p><code>infer_logL_by_Rmixmod</code> calls <code>Rmixmod::mixmodCluster</code>
<code>infer_logL_by_mclust</code> calls <code>mclust::densityMclust</code>, 
<code>infer_logL_by_Hlscv.diag</code> calls <code>ks::kde</code>, and <code>infer_logL_by_GLMM</code> fits a binned distribution of summary statistics using a Poisson GLMM with autocorrelated random effects, where the binning is based on a tesselation of a volume containing the whole simulated distribution. Limited experiments so far suggest that the mixture models methods are fast and appropriate (<code>Rmixmod</code>, being a bit faster, is the default method); that the kernel smoothing method is more erratic and moreover requires additional input from the user, hence is not really applicable, for distributions in dimension <em>d</em>= 4 or above; and that the GLMM method is a very good density estimator for <em>d</em>=2 but will challenge one's patience for <em>d</em>=3 and further challenge the computer's memory for <em>d</em>=4.
</p>


<h3>Value</h3>

<p>For <code>infer_logLs</code>, a data frame containing parameter values and their log likelihoods, and additional information such as attributes providing information about the parameter names and statistics names (not detailed here). These attributes are essential for further inferences.
</p>
<p>See Details for the required value of the <code>method</code>s called by <code>infer_logLs</code>.
</p>


<h3>See Also</h3>

<p>See step (3) of the workflow in the Example on the main <code><a href="#topic+Infusion">Infusion</a></code> documentation page.  
</p>

<hr>
<h2 id='infer_SLik_joint'>
Infer a (summary) likelihood surface from a simulation table
</h2><span id='topic+infer_SLik_joint'></span>

<h3>Description</h3>

<p>This infers the likelihood surface from a simulation table where each simulated data set is drawn for a distinct (vector-valued) parameter, as is usual for reference tables in ABC.
A parameter density is inferred, as well as a joint density of parameters and summary statistics, and the likelihood surface is inferred from these two densities. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infer_SLik_joint(data, stat.obs, logLname = Infusion.getOption("logLname"), 
                Simulate = attr(data, "Simulate"), 
                nbCluster= seq_nbCluster(nr=nrow(data)),
                using = Infusion.getOption("mixturing"), 
                verbose = list(most=interactive(),pedantic=FALSE,final=FALSE),
                marginalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer_SLik_joint_+3A_data">data</code></td>
<td>

<p>A data frame, whose each row contains a vector of parameters and one realization of the summary statistics for these parameters.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_stat.obs">stat.obs</code></td>
<td>

<p>Named numeric vector of observed values of summary statistics.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_loglname">logLname</code></td>
<td>

<p>The name to be given to the log Likelihood in the return object, or the root of the latter name in case of conflict with other names in this object.
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_simulate">Simulate</code></td>
<td>
<p>Either NULL or the name of the simulation function if it can be called from the R session. 
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_nbcluster">nbCluster</code></td>
<td>
<p>controls the <code>nbCluster</code> argument of <code>Rmixmod::mixmodCluster</code>
; a vector of integers, or <code>"max"</code> which is interpreted as the maximum of the default <code>nbCluster</code> value.   
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_using">using</code></td>
<td>
<p>Either <code>"Rmixmod"</code> or <code>"mclust"</code> to select the clustering methods used. 
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_marginalize">marginalize</code></td>
<td>
<p>Boolean; whether to derive the clustering of fitted parameters by marginalization of the joint clustering (default, and introduced in version 1.3.5); or by a distinct call to a clustering function. 
</p>
</td></tr>
<tr><td><code id="infer_SLik_joint_+3A_verbose">verbose</code></td>
<td>

<p>A list as shown by the default, or simply a vector of booleans, indicating respectively
whether to display (1) some information about progress; (2) more information whose importance is not clear to me; (3) a final summary of the results after all elements of <code>simuls</code> have been processed.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>SLik_j</code>, which is a list including an <code>Rmixmod::mixmodCluster</code>
object (or equivalent objects produced by non-default methods), and additional members not documented here. If projection was used, the list includes a  data.frame <code>raw_data</code> of cumulated unprojected simulations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;50) {
  myrnorm &lt;- function(mu,s2,sample.size) {
    s &lt;- rnorm(n=sample.size,mean=mu,sd=sqrt(s2))
    return(c(mean=mean(s),var=var(s)))
  } # simulate means and variances of normal samples of size 'sample.size'
  set.seed(123)
  # pseudo-sample with stands for the actual data to be analyzed:  
  ssize &lt;- 40
  Sobs &lt;- myrnorm(mu=4,s2=1,sample.size=ssize) 
  # Uniform sampling in parameter space:
  npoints &lt;- 600
  parsp &lt;- data.frame(mu=runif(npoints,min=2.8,max=5.2),
                      s2=runif(npoints,min=0.4,max=2.4),sample.size=ssize)
  # Build simulation table:
  simuls &lt;- add_reftable(Simulate="myrnorm",par.grid=parsp)
  # Infer surface:
  densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs)
  # Usual workflow using inferred surface:
  slik_j &lt;- MSL(densv) ## find the maximum of the log-likelihood surface
  slik_j &lt;- refine(slik_j,maxit=5)
  plot(slik_j)
  # etc:
  profile(slik_j,c(mu=4)) ## profile summary logL for given parameter value
  confint(slik_j,"mu") ## compute 1D confidence interval for given parameter
  plot1Dprof(slik_j,pars="s2",gridSteps=40) ## 1D profile
}
</code></pre>

<hr>
<h2 id='infer_surface'>
Infer a (summary) likelihood or tail probability surface from inferred likelihoods
</h2><span id='topic+infer_surface'></span><span id='topic+infer_surface.logLs'></span><span id='topic+infer_surface.tailp'></span>

<h3>Description</h3>

<p>The <code>logLs</code> method uses a standard smoothing method (prediction under linear mixed models, a.k.a. Kriging) to infer a likelihood surface, using as input likelihood values themselves inferred with some error for different parameter values. The <code>tailp</code> method use a similar approach for smoothing binomial response data, using the algorithms implemented in the spaMM package for fitting GLMMs with autocorrelated random effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logLs'
infer_surface(object, method="REML",verbose=interactive(),allFix=NULL,...)
## S3 method for class 'tailp'
infer_surface(object, method="PQL",verbose=interactive(),allFix,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infer_surface_+3A_object">object</code></td>
<td>
 
<p>A data frame with attributes, containing independent prediction of logL or of LR tail probabilities for different parameter points, as produced by <code><a href="#topic+infer_logLs">infer_logLs</a></code> or <code><a href="#topic+infer_tailp">infer_tailp</a></code>.  
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_method">method</code></td>
<td>

<p>methods used to estimate the smoothing parameters. If <code>method="GCV"</code>, a generalized cross-validation procedure is used (for <code>logLs</code> method only). Other methods are as described in the <code><a href="spaMM.html#topic+HLfit">HLfit</a></code> documentation.   
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_verbose">verbose</code></td>
<td>

<p>Whether to display some information about progress or not.
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_allfix">allFix</code></td>
<td>

<p>Fixed values in the estimation of smoothing parameters. For development purposes, not for routine use. For <code>infer_surface.logLs</code>, this should typically include values of all parameters fitted by <code>spaMM::corrHLfit</code> (<code class="reqn">\rho,\nu,\phi,\lambda</code>, and <code>$etaFix=</code><code class="reqn">\beta</code>).
</p>
</td></tr>
<tr><td><code id="infer_surface_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>SLik</code> or <code>SLikp</code>, which is a list including an <code>HLfit</code> object as returned by <code><a href="spaMM.html#topic+corrHLfit">corrHLfit</a></code>, and additional members not documented here.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package
</code></pre>

<hr>
<h2 id='Infusion-internal'>Internal Infusion Functions</h2><span id='topic+projpath'></span><span id='topic+calc.lrthreshold'></span><span id='topic+calc.lrthreshold.default'></span><span id='topic+calc.lrthreshold.SLik'></span><span id='topic+calc.lrthreshold.SLikp'></span><span id='topic+predict.dMixmod'></span><span id='topic+predict.dMclust'></span><span id='topic+predict.SLik'></span><span id='topic+predict.MixmodResults'></span><span id='topic+predict.SLikp'></span><span id='topic+plot.MixmodResults'></span><span id='topic+myrnorm'></span><span id='topic+mapMM'></span><span id='topic+isPointInCHull'></span><span id='topic+resetCHull'></span>

<h3>Description</h3>

<p>Internal Infusion functions
</p>


<h3>Details</h3>

<p>These are not to be called by the user, or are waiting for documentation to be written.
</p>

<hr>
<h2 id='init_reftable'>
Define starting points in parameter space.
</h2><span id='topic+init_reftable'></span><span id='topic+init_grid'></span>

<h3>Description</h3>

<p>These functions sample the space of estimated parameters, and also handle other fixed arguments that need to be passed to the function simulating the summary statistics (sample size is likely to be one such argument). The current sampling strategy of these functions is crude but achieves desirable effects for present applications: it samples the space more uniformly, by generating fewer pairs of close points than independent sampling of each point would; it is not exactly a regular grid; and <code>init_grid</code> generates replicates of a few parameter points, which were required in the primitive workflow for good smoothing of the likelihood surface. <code>init_reftable</code> is a trivial wrapper around <code>init_grid</code>, setting the number of replicates to zero, which is appropriate in up-to-date workflows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_reftable(lower=c(par=0), upper=c(par=1), steps=NULL, 
          nUnique=NULL, maxmin=TRUE, jitterFac=0.5)
init_grid(lower=c(par=0), upper=c(par=1), steps=NULL, nUnique=NULL, 
          nRepl=min(10L,nUnique), maxmin=TRUE, jitterFac=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_reftable_+3A_lower">lower</code></td>
<td>

<p>A vector of lower bounds for the parameters, as well as fixed arguments to be passed to the function simulating the summary statistics. Elements must be named. Fixed parameters character strings.   
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_upper">upper</code></td>
<td>

<p>A vector of upper bounds for the parameters, as well as fixed parameters. Elements must be named and match those of <code>lower</code>.  
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_steps">steps</code></td>
<td>

<p>Number of steps of the grid, in each dimension of estimated parameters. If NULL, a default value is defined from the other arguments. If a single value is given, it is applied to all dimensions. Otherwise, this must have the same length as <code>lower</code> and <code>upper</code> and named in the same way as the variable parameters in these arguments.    
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_nunique">nUnique</code></td>
<td>

<p>Number of distinct values of parameter vectors in output. Default is an heuristic guess for good start from not too many points, computed as  <code>floor(50^((v/3)^(1/3)))</code> where <code>v</code> is the number of variable parameters.  
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_nrepl">nRepl</code></td>
<td>

<p>Number of replicates of distinct values of parameter vectors in output.
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_maxmin">maxmin</code></td>
<td>

<p>Boolean. If TRUE, use a greedy max-min strategy (GMM, inspired from Ravi et al. 1994) in the selection of points from a larger set of points generated by an hypercube-sampling step. If FALSE, <code>sample</code> is instead used for this second step. This may be useful as the default method becomes slow when thousands of points are to be sampled. 
</p>
</td></tr>
<tr><td><code id="init_reftable_+3A_jitterfac">jitterFac</code></td>
<td>

<p>Controls the amount of jitter of the points around regular grid nodes. The default value 0.5 means that a mode can move by up to half a grid step (independently in each dimension), so that two adjacent nodes moved toward each other can (almost) meet each other. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame. Each row defines a list of arguments of vector of the function simulating the summary statistics.
</p>


<h3>Note</h3>

<p><code>init_grid</code> is an exported function from the <span class="pkg">blackbox</span> package. 
</p>


<h3>References</h3>

<p>Ravi S.S., Rosenkrantz D.J., Tayi G.K. 1994. Heuristic and special case algorithms for dispersion problems. Operations Research 42, 299-310.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
init_grid()
init_grid(lower=c(mu=2.8,s2=0.5,sample.size=20),
          upper=c(mu=5.2,s2=4.5,sample.size=20),
          steps=c(mu=7,s2=9),nUnique=63)
</code></pre>

<hr>
<h2 id='MSL'>
Maximum likelihood from an inferred likelihood surface
</h2><span id='topic+MSL'></span>

<h3>Description</h3>

<p>This computes the maximum of an object of class <code>SLik</code> representing an inferred (summary) likelihood surface</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSL(object, CIs = TRUE, level = 0.95, verbose = interactive(),
    eval_RMSEs = TRUE, cluster_args=list(),init=NULL, prior_logL=NULL,
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSL_+3A_object">object</code></td>
<td>

<p>an object of class <code>SLik_j</code> as produced by <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> (or, in the primitive workflow,  of class <code>SLik</code> as produced by <code><a href="#topic+infer_surface.logLs">infer_surface.logLs</a></code>).
</p>
</td></tr>
<tr><td><code id="MSL_+3A_cis">CIs</code></td>
<td>

<p>If <code>TRUE</code>, construct one-dimensional confidence intervals for all parameters.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_level">level</code></td>
<td>

<p>Intended coverage probability of the confidence intervals.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_verbose">verbose</code></td>
<td>

<p>Whether to display some information about progress and results.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_eval_rmses">eval_RMSEs</code></td>
<td>

<p>Logical: whether to evaluate prediction uncertainty for likelihoods/ likelihood ratios/ parameters. 

</p>
</td></tr>
<tr><td><code id="MSL_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments, passed to <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, to control parallel computation of RMSEs. Beware that parallel computation of RMSEs tends to be memory-intensive. The list may contain a non-null <code>spec</code> element, in which case the <code>nb_cores</code> global <span class="pkg">Infusion</span> option is ignored. Do <b>*not*</b> use a structured list with an <code>RMSE</code> element as is possible for <code>refine</code> (see Details of <code><a href="#topic+refine">refine</a></code> documentation).</p>
</td></tr>
<tr><td><code id="MSL_+3A_init">init</code></td>
<td>
<p>Initial value for the optimiser. Better ignored.
</p>
</td></tr>
<tr><td><code id="MSL_+3A_prior_logl">prior_logL</code></td>
<td>
<p>(effective only for up-to-date workflow using gaussian mixture modelling of a joint distribution of parameters and statistics) a function that returns a vector of prior log-likelihood values, which is then added to the likelihood deduced from the summary likelihood analysis. The function's single argument must handle a matrix similar to the <code>newdata</code> argument of <code><a href="#topic+predict.SLik_j">predict.SLik_j</a></code>. 
</p>
</td></tr>
<tr><td><code id="MSL_+3A_...">...</code></td>
<td>
<p>Further arguments passed from or to other methods. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If Kriging has been used to construct the likelihood surface, <code>RMSEs</code> are computed using approximate formulas for prediction (co-)variances in linear mixed midels (see Details in <code><a href="spaMM.html#topic+predict">predict</a></code>). Otherwise, a more computer-intensive bootstrap method is used.   
<code>par_RMSEs</code> are computed from <code>RMSEs</code> and from the numerical gradient of profile log-likelihood at each CI bound. Only <code>RMSEs</code>, not <code>par_RMSEs</code>, are compared to <code>precision</code>.
</p>


<h3>Value</h3>

<p>The <code>object</code> is returned invisibly, with the following added members, each of which being (as from version 1.5.0) an environment:
</p>

<dl>
<dt><code>MSL</code></dt><dd><p>containing variables <code>MSLE</code> and <code>maxlogL</code> that match the <code>par</code> and <code>value</code> returned by an <code>optim</code> call. Also contain the <code>hessian</code> of summary likelihood at its maximum.</p>
</dd>
<dt><code>RMSEs</code></dt><dd><p>containing, as variable <code>RMSEs</code>, the root mean square errors of the log-likelihood at its inferred maximum and of the log-likelihood ratios at the CI bounds.</p>
</dd>
<dt><code>par_RMSEs</code></dt><dd><p>containing, as variable <code>par_RMSEs</code>, root mean square errors of the CI bounds.</p>
</dd>
</dl>

<p>To ensure backward-compatibility of code to possible future changes in the structure of the objects, the extractor function <code><a href="#topic+get_from">get_from</a></code> should be used to extract the <code>RMSEs</code> and <code>par_RMSEs</code> variables from their respective environments, and more generally to extract any element from the objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package
</code></pre>

<hr>
<h2 id='multi_binning'>
Multivariate histogram
</h2><span id='topic+multi_binning'></span>

<h3>Description</h3>

<p>Constructs a multivariate histogram of the points. Optionally, first tests whether a given value is within the convex hull of input points and constructs the histogram only if this test is TRUE. This function is available for development purposes but is not required otherwise . It is sparsely documented and subject to changes without notice.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_binning(m, subsize=trunc(nrow(m)^(Infusion.getOption("binningExponent"))),
              expand=5/100, focal=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi_binning_+3A_m">m</code></td>
<td>

<p>A matrix representing points in <em>d</em>-dimensional space, where <em>d</em> is the number of columns
</p>
</td></tr>
<tr><td><code id="multi_binning_+3A_subsize">subsize</code></td>
<td>

<p>A control parameter for an undocumented algorithm
</p>
</td></tr>
<tr><td><code id="multi_binning_+3A_expand">expand</code></td>
<td>

<p>A control parameter for an undocumented algorithm
</p>
</td></tr>
<tr><td><code id="multi_binning_+3A_focal">focal</code></td>
<td>

<p>Value to be tested for inclusion within the convex hull. Its elements must have names.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm may be detailed later.
</p>


<h3>Value</h3>

<p>Either NULL (if the optional test returned FALSE), or an histogram represented as a data frame each row of which represents an histogram cell by its barycenter (a point in <em>d</em>-dimensional space), its &ldquo;binFactor&rdquo; (the volume of the cell times the total number of observations) and its &ldquo;count&rdquo; (the number of observations within the cell).
The returned data frame has the following attributes: <code>attr(.,"stats")</code> are the column names of the <em>d</em>-dimensional points; 
<code>attr(.,"count")</code> is the column name of the count, and 
<code>attr(.,"binFactor")</code> is the column name of the binFactor.
</p>

<hr>
<h2 id='options'>Infusion options settings</h2><span id='topic+Infusion.options'></span><span id='topic+Infusion.getOption'></span><span id='topic+parallel'></span>

<h3>Description</h3>

<p>Allow the user to set and examine a variety of <em>options</em>
which affect operations of the Infusion package. 
However, typically these should not be modified, and if they are, not more than once in a data analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Infusion.options(...)

Infusion.getOption(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="options_+3A_x">x</code></td>
<td>
<p>a character string holding an option name.</p>
</td></tr>
<tr><td><code id="options_+3A_...">...</code></td>
<td>
<p>A named value or a list of named values. The following values, with their defaults, 
are used in <code>Infusion</code>:
</p>

<dl>
<dt><code>mixturing</code></dt><dd><p>character string: package or function to be used for mixture modelling. Recognized packages are <code>"Rmixmod"</code> (the default) and <code>"mclust"</code>;   </p>
</dd>
<dt><code>train_cP_size</code>:</dt><dd><p>Expression for <code>train_cP_size</code> argument of <code><a href="#topic+project.character">project.character</a></code>.</p>
</dd>
<dt><code>trainingsize</code>:</dt><dd><p>Expression for <code>trainingsize</code> argument of <code><a href="#topic+project.character">project.character</a></code>.</p>
</dd>
<dt><code>projKnotNbr = 1000</code>:</dt><dd><p>default value of <code>trainingsize</code> argument of <code><a href="#topic+project.character">project.character</a></code> for REML (as implied by default expression for <code>trainingsize</code>).</p>
</dd>
<dt><code>logLname = "logL"</code>:</dt><dd><p>default value of <code>logLname</code> argument of <code><a href="#topic+infer_logLs">infer_logLs</a></code>. The name given to the inferred log likelihoods in all analyses.</p>
</dd>
<dt><code>LRthreshold= - qchisq(0.999,df=1)/2</code>:</dt><dd><p>A value used internally by <code><a href="#topic+sample_volume">sample_volume</a></code> to sample points 
in the upper region of the likelihood surface, as defined by the given likelihood ratio threshold.
</p>
</dd>
<dt><code>precision = 0.1</code>:</dt><dd><p>default value of <code>precision</code> argument of <code><a href="#topic+refine">refine</a></code>. Targets RMSE of log L and log LR estimates.</p>
</dd>
<dt><code>nRealizations=1000</code>:</dt><dd><p>default value of <code>nRealizations</code> argument of <code><a href="#topic+add_simulation">add_simulation</a></code>. Number of realizations for each empirical distribution.</p>
</dd>
<dt><code>mixmodGaussianModel="Gaussian_pk_Lk_Dk_A_Dk"</code>:</dt><dd><p>default models used in clustering by <code>Rmixmod</code>. Run <code>Rmixmod::mixmodGaussianModel()</code> for a list of possible models, and see the statistical documentation (Mixmod Team 2016) for explanations about them.</p>
</dd>
<dt><code>seq_nbCluster= function(projdata, nr=nrow(projdata)) {seq(ceiling(nr^0.3))}</code>:</dt><dd><p>function to control the value of <code>nbCluster</code> used in clustering by <code>Rmixmod</code> (see Details for discussion of this default).</p>
</dd>
<dt><code>maxnbCluster = function(projdata) {...} </code>:</dt><dd><p>function to control the maximum number of clusters (see Details).</p>
</dd>
<dt><code>example_maxtime=2.5</code>:</dt><dd><p>Used in the documentation to control whether the longer examples should be run. 
The approximate running time of given examples (or some very rough approximation for it) on one author's laptop is compared to this value.</p>
</dd> 
<dt><code>nb_cores</code></dt><dd><p>Number of cores for parallel computations (see Details for implementation of these).</p>
</dd>
<dt><code>gof_nstats_fn</code></dt><dd><p>See <code><a href="#topic+goftest">goftest</a></code>.</p>
</dd>
</dl>
 
<p>and possibly other undocumented values for development purposes.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The set of the number of clusters tried (<code>nbCluster</code> argument in <code>Rmixmod</code>) is controlled by two options: <code>seq_nbCluster</code> and <code>maxnbCluster</code>. The second is used to correct the first, using the dimensions of the <code>projdata</code> locally used for clustering, which typically differs from the dimensions of the user-level <code>data</code> (if projections have been applied, in particular). The default upper value of the <code>nbCluster</code> range is the value recommended in the <code>mixmod</code> statistical documentation (Mixmod Team, 2016). But this default may be suitable only for low-dimensional data, hence the need for correcting it by<code>maxnbCluster</code>.
</p>
<p><code>Infusion</code> can perform parallel computations if several cores are available and requested though <code>Infusion.options(nb_cores=.)</code>. If the <code>doSNOW</code> back-end is attached (by explicit request from the user), it will be used; otherwise, <code>pbapply</code> will be used. Both provide progress bars, but <code>doSNOW</code> may provide more efficient load-balancing. The character shown in the progress bar is <code>'P'</code> for parallel via <code>doSNOW</code> backend, <code>'p'</code> for parallel via <code>pbapply</code> functions, and <code>'s'</code> for serial via <code>pbapply</code> functions. In addition, <code>add_simulation</code> can parallelise at two levels: at an outer level over parameter point, or at an inner level over simulation replicates for each parameter point. The progress bar of the outer computation is shown, but the character shown in the progress bar is <code>'N'</code> if the inner computation is parallel via the <code>doSNOW</code> backend, and <code>'n'</code> if it is parallel via <code>pbapply</code> functions. So, one should see either <code>'P'</code> or <code>'N'</code> when using <code>doSNOW</code>.
</p>


<h3>Value</h3>

<p>For <code>Infusion.getOption</code>, the current value set for option <code>x</code>, or
<code>NULL</code> if the option is unset.
</p>
<p>For <code>Infusion.options()</code>, a list of all set options.  For
<code>Infusion.options(name)</code>, a list of length one containing the set value,
or <code>NULL</code> if it is unset.  For uses setting one or more options,
a list with the previous values of the options changed (returned
invisibly).
</p>


<h3>References</h3>

<p>Mixmod Team (2016). Mixmod Statistical Documentation. Université de Franche-Comté,
Besançon, France. Version: February 10, 2016 retrieved from <a href="https://www.mixmod.org">https://www.mixmod.org</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  Infusion.options()
  Infusion.getOption("LRthreshold")
  ## Not run: 
  Infusion.options(LRthreshold=- qchisq(0.99,df=1)/2)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='plot.SLik'>
Plot SLik or SLikp objects
</h2><span id='topic+plot.SLik'></span><span id='topic+plot.SLik_j'></span><span id='topic+plot.SLikp'></span>

<h3>Description</h3>

<p>Mostly conceived for exposition purposes, for the two-parameters case.
The black-filled points are those for which the observed summary statistic was outside of the convex hull of the simulated empirical distribution. The crosses mark the estimated ML point and the confidence intervals points, that is, the outmost points on the contour defined by the profile likelihood threshold for the profile confidence intervals. There is a pair of CI points for each interval.
The smaller black dots mark points added in the latest iteration, if <code>refine</code> was used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
plot(x, y, filled = FALSE, decorations = NULL,
                    color.palette = NULL, plot.axes = NULL, 
                    plot.title = NULL, plot.slices=TRUE, ...)
## S3 method for class 'SLik_j'
plot(x, y, filled = nrow(x$logLs)&gt;5000L, decorations = NULL, 
                      color.palette = NULL, plot.axes = NULL, 
                      plot.title = NULL, from_refine=FALSE, plot.slices=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SLik_+3A_x">x</code></td>
<td>

<p>An object of class <code>SLik</code> or <code>SLikp</code>
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_y">y</code></td>
<td>

<p>Not used, but included for consistency with the <code>plot</code> generic. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_filled">filled</code></td>
<td>

<p>whether to plot a <code><a href="spaMM.html#topic+mapMM">mapMM</a></code> or a <code><a href="spaMM.html#topic+filled.mapMM">filled.mapMM</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_decorations">decorations</code></td>
<td>

<p>Graphic directives added to the default <code>decorations</code> value in calls of <code><a href="spaMM.html#topic+mapMM">mapMM</a></code> or a <code><a href="spaMM.html#topic+filled.mapMM">filled.mapMM</a></code> (see the source code of <code>plot.SLik</code> for the latter default values). 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_color.palette">color.palette</code></td>
<td>

<p>Either NULL or a function that can replace the default color function used by <code>plot.SLik</code>. The function must have a single argument, giving the number of color levels. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_plot.title">plot.title</code></td>
<td>
	
<p>statements which replace the default titles to the main plot (see Details). 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_plot.axes">plot.axes</code></td>
<td>
	
<p>statements which replace the default axes on the main plot (see Details). 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_from_refine">from_refine</code></td>
<td>
	
<p>For programming purposes, not documented. 
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_plot.slices">plot.slices</code></td>
<td>
	
<p>boolean: whether to plot &ldquo;slices&rdquo; of the summary-likelihood surface for pairs of parameters (p1,p2), when more than two parameters are fitted. In such plots the additional parameters p3, p4... are fixed to their estimates [in contrast to profile plots where p3, p4... take distinct values for each (p1,p2), maximizing the function for each (p1,p2)].  
</p>
</td></tr>
<tr><td><code id="plot.SLik_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods (currently can be used to pass a few arguments such as <code>map.asp</code> in all cases, 
or <code>variances</code> to <code>filled.mapMM</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Different graphic functions are called depending on the number of estimated parameters. For two parameters, <code><a href="spaMM.html#topic+mapMM">mapMM</a></code> or <code><a href="spaMM.html#topic+filled.mapMM">filled.mapMM</a></code> are called. For more than two parameters, <code><a href="spaMM.html#topic+spaMM.filled.contour">spaMM.filled.contour</a></code> is called. See the documentation of these functions for the appropriate format of the <code>plot.title</code> and <code>plot.axes</code> arguments.  
</p>


<h3>Value</h3>

<p>Returns the plotted object invisibly.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Using 'slik_j' object from the example in help("example_reftable") 
plot(slik_j,filled=TRUE,
     plot.title=quote(title("Summary-likelihood-ratio surface",
                             xlab=expression(mu),
                             ylab=expression(sigma^2))))

## End(Not run)
</code></pre>

<hr>
<h2 id='plot1Dprof'>
Plot likelihood profiles
</h2><span id='topic+plot1Dprof'></span><span id='topic+plot2Dprof'></span>

<h3>Description</h3>

<p>These functions plot 1D and 2D profiles from a summary-likelihood object.
</p>
<p>High quality 2D plots may be slow to compute, and there may be many of them in high-dimensional parameter spaces, so parallelization of the computation of each profile point has been implemented for them. Usual caveats apply: there is an time cost of launching processes on a cluster, particularly on socket clusters, possibly offsetting the benefits of parallelization when each profile point is fast to evaluate. Further, summary-likelihood objects are typically big (memory-wise), which may constrain the number of concurrent processes.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot1Dprof(object, pars=object$colTypes$fittedPars, type="logLR",   
           gridSteps=21, xlabs=list(), ylab, scales=NULL,
           plotpar=list(pch=20), 
           control=list(min=-7.568353, shadow_col="grey70"),
           decorations = function(par) NULL, ...)
plot2Dprof(object, pars=object$colTypes$fittedPars, type="logLR",  
           gridSteps=17, xylabs=list(), main, scales=NULL,
           plotpar=list(pch=20), margefrac = 0,
           decorations = function(par1,par2) NULL, 
           filled.contour.fn = "spaMM.filled.contour", 
           cluster_args=NULL, ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot1Dprof_+3A_object">object</code></td>
<td>
<p>An <code>SLik</code> or <code>SLik_j</code> object</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_pars">pars</code></td>
<td>
<p> Control of parameters for which profiles will be computed. If <code>pars</code> is specified as a vector of names, profiles are plotted for each parameter, or (2D case) for all pairs of distinct parameters. Finer control is possible in the 2D case (see Details).</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_type">type</code></td>
<td>
<p>Character: <code>"logL"</code> to plot the log-likelihood profile; <code>"logLR"</code> (or <code>"LR"</code> for the not-log version) to plot the log-likelihood-ratio profile (the default); or <code>"zoom"</code> or <code>"dual"</code> for variants of <code>"logLR"</code> (see details). </p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_gridsteps">gridSteps</code></td>
<td>
<p> The number of values (in each dimension for 2D plots) which likelihood  should be computed. For 1D plots, 
<code>gridSteps=0</code> is now obsolete.
</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_xlabs">xlabs</code></td>
<td>
<p> A <em>list</em> of alternative axis labels. The names  of the list elements should be elements of <code>pars</code> (see Examples)</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_xylabs">xylabs</code></td>
<td>
<p> Same as <code>xlabs</code> but affecting both axes in 2D plots</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_ylab">ylab</code></td>
<td>
<p> Same as <code>ylab</code> argument of <code>plot</code>. Default depends on <code>type</code> argument.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_main">main</code></td>
<td>
<p> Same as <code>main</code> argument of <code>plot</code>. Default depends on <code>type</code> argument.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_scales">scales</code></td>
<td>
<p> A named character vector, which controls ticks and tick labels on axes, so that these can be expressed as (say) the exponential of the parameter inferred in the SLik object. 
For example if the likelihood of <code>logPop</code> = log(population size) was thus inferred, <code>scales=c(logPop="log")</code> will give population size values on the axis (but will retain a log scale for this parameter). Possible values of each element of the vector are <code>"identity"</code> (default), <code>"log"</code>, and <code>"log10"</code>,   
</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_plotpar">plotpar</code></td>
<td>
<p>Arguments for <code>par()</code> such as font sizes, etc.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_control">control</code></td>
<td>
<p>Control of <code>"zoom"</code> or <code>"dual"</code> plots (see Details).</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_decorations">decorations</code></td>
<td>
<p> A function with formals parameters as shown by the default (being parameters names represented as character strings), implementing graphic directives added to the plot.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_margefrac">margefrac</code></td>
<td>
<p> For development purposes, not documented.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_filled.contour.fn">filled.contour.fn</code></td>
<td>
<p>Name of a possible alternative to <code>graphics::filled.contour</code> to be used for rendering the plot.</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_cluster_args">cluster_args</code></td>
<td>
<p>NULL, or a list in which case a cluster may be created and used. The list elements must match the arguments <code>spec</code> and <code>type</code> of <code>parallel::makeCluster</code>. A socket cluster is created unless <code>type="FORK"</code> (on operating systems that support fork clusters).</p>
</td></tr>
<tr><td><code id="plot1Dprof_+3A_...">...</code></td>
<td>
<p> Further arguments passed by another function. Currently these arguments are ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the 2D case, the <code>pars</code> may be specified as a two-column natrix, in which case profiles are generated for all pairs of distinct parameters specified by rows of the matrix. It may also be specified as a two-element list, where each element is a vector of parameter names. In that case, profiles are generated for all pairs of distinct parameters combining one element of each vector.
</p>
<p>A <code>"zoom"</code> plot shows only the top part of the profile, defined as points whose y-values are above a threshold minus-log-likelihood ratio <code>control$min</code>, whose default is -7.568353, the 0.9999 p-value threshold.
</p>
<p>A <code>"dual"</code> plot displays both the zoom, and a shadow graph showing the full profile. The dual plot is shown only when requested and if there are values above and below <code>control$min</code>. The shadow curve color is given by <code>control$shadow_col</code>.
</p>


<h3>Value</h3>

<p>Both functions return a list, which currently has a single element <code>MSL_updated</code> which is a boolean indicating whether the summary-likelihood maximum (but not the intervals) has been recomputed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (Infusion.getOption("example_maxtime")&gt;20) { 
  #### Toy bivariate gaussian model, three parameters, no projections
  #
  myrnorm2 &lt;- function(mu1,mu2,s2,sample.size) {
    sam1 &lt;- rnorm(n=sample.size,mean=mu1,sd=sqrt(s2))
    sam2 &lt;- rnorm(n=sample.size,mean=mu2,sd=sqrt(s2))
    s &lt;- c(sam1,sam2)
    e_mu &lt;- mean(s)
    e_s2 &lt;- var(s)
    c(mean=e_mu,var=e_s2,kurt=sum((s-e_mu)^4)/e_s2^2)
  } 
  #
  ## pseudo-sample, standing for the actual data to be analyzed:  
  set.seed(123)
  Sobs &lt;- myrnorm2(mu1=4,mu2=2,s2=1,sample.size=40) ## 
  #
  ## build reference table
  parsp &lt;- init_reftable(lower=c(mu1=2.8,mu2=1,s2=0.2), 
                         upper=c(mu1=5.2,mu2=3,s2=3),
                         nUnique=600)
  parsp &lt;- cbind(parsp,sample.size=40)
  simuls &lt;- add_reftable(Simulate="myrnorm2",par.grid=parsp)
  
  ## Inferring the summary-likelihood surface...
  densv &lt;- infer_SLik_joint(simuls,stat.obs=Sobs)
  slik_j &lt;- MSL(densv) ## find the maximum of the log-likelihood surface
  
  ## plots
  plot2Dprof(slik_j,gridSteps=21,
             ## alternative syntaxes for non-default 'pars':
             # pars = c("mu1","mu2"), # =&gt; all combinations of given elements
             # pars = list("s2",c("mu1","mu2")), # =&gt; combinations via expand.grid()
             # pars = matrix(c("mu1","mu2","s2","mu1"), ncol=2), # =&gt; each row of matrix
             xylabs=list(
               mu1=expression(paste(mu[1])),
               mu2=expression(paste(mu[2])),
               s2=expression(paste(sigma^2))
             )) 
  # One could also add (e.g.) 
  #            cluster_args=list(spec=4, type="FORK"), 
  # when longer computations are requested.
}

if (Infusion.getOption("example_maxtime")&gt;40) {
 #### Older example with primitive workflow 
 data(densv)
 slik &lt;- infer_surface(densv) ## infer a log-likelihood surface
 slik &lt;- MSL(slik) ## find the maximum of the log-likelihood surface
 plot1Dprof(slik,pars="s2",gridSteps=40,xlabs=list(s2=expression(paste(sigma^2)))) 
}

</code></pre>

<hr>
<h2 id='predict.SLik_j'>
Evaluate log-likelihood for given parameters
</h2><span id='topic+predict.SLik_j'></span>

<h3>Description</h3>

<p>As the Title says. Implemented as a method of the <code>predict</code> generic, for objects created by the up-to-date workflow using gaussian mixture modelling of a joint distribution of parameters and statistics (hence the <code>newdata</code> argument, shared by many <code>predict</code> methods; but these <code>newdata</code> should be parameter values, not data).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik_j'
predict(
  object, newdata, log = TRUE, which = "lik", 
  tstat = t(attr(object$logLs, "stat.obs")), 
  solve_t_chol_sigma_lists = object$clu_params$solve_t_chol_sigma_lists, 
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.SLik_j_+3A_object">object</code></td>
<td>

<p>an object of class <code>SLik_j</code>, as produced by <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_newdata">newdata</code></td>
<td>

<p>A matrix, whose rows each contain a full vector of the fitted parameters; or a single vector. If parameter names are not provided (as column names in the matrix case), then the vector is assumed to be ordered as <code>object$colTypes$fittedPars</code>.
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_log">log</code></td>
<td>

<p>Boolean: whether to return log-likelihood or likelihood.
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_which">which</code></td>
<td>

<p><code>"lik"</code> or <code>"safe"</code>. The latter protects against some artefacts of predictions beyond the regions of parameter space well sampled by the inference procedure. 
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_tstat">tstat</code></td>
<td>

<p>The data (as projected summary statistics). Defaults to the data input in the inference procedure (i.e., the projected statistics used as <code>stat.obs</code> argument of <code>infer_SLik_joint</code>). 
</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_solve_t_chol_sigma_lists">solve_t_chol_sigma_lists</code></td>
<td>
<p>For programming purposes. Do not change this argument.</p>
</td></tr>
<tr><td><code id="predict.SLik_j_+3A_...">...</code></td>
<td>

<p>For consistency with the generic. Currently ignored.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric: a single value, or a vector of (log-)likelihoods for different rows of the input <code>newdata</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see help("example_reftable")
</code></pre>

<hr>
<h2 id='profile.SLik'>
Compute profile summary likelihood 
</h2><span id='topic+profile.SLik'></span><span id='topic+profile.SLik_j'></span><span id='topic+profile'></span>

<h3>Description</h3>

<p>Predicts the profile likelihood for a given parameter value (or vector of such values) using predictions from an <code>SLik</code> object (as produced by <code><a href="#topic+MSL">MSL</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
profile(fitted, value, fixed=NULL, return.optim=FALSE, 
                       init = "default", which="safe", ...)
## S3 method for class 'SLik_j'
profile(fitted, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="profile.SLik_+3A_fitted">fitted</code></td>
<td>
<p>an <code>SLik</code> object.</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_value">value</code></td>
<td>

<p>The parameter value (as a vector of named values) for which the profile is to be computed
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_fixed">fixed</code></td>
<td>
<p>When this is <code>NULL</code> the computed interval is a profile confidence interval over all parameters excluding <code>value</code>.
<code>fixed</code> allows one to set fixed values to some of these parameters.  
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_return.optim">return.optim</code></td>
<td>
<p>If this is TRUE, and if maximization of likelihood given <code>value</code> and <code>fixed</code> is indeed required, then the full result of the optimization call is returned.</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_...">...</code></td>
<td>

<p>For <code>SLik_j</code> method, arguments passed to <code>SLik</code> method.
For <code>SLik_j</code> method, currently not used.
</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_init">init</code></td>
<td>
<p>Better ignored. Either a named vector of parameter values (initial value for some optimizations) or a character string. The default is to call a procedure to find a good initial point from a set of candidates. The source code should be consulted for further details and is subject to change without notice.</p>
</td></tr>
<tr><td><code id="profile.SLik_+3A_which">which</code></td>
<td>
<p>Better ignored (for development purpose).</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>The predicted summary profile log-likelihood; or possibly the result of an optimization call if <code>return.optim</code> is TRUE. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see main documentation page for the package
</code></pre>

<hr>
<h2 id='project.character'>
Learn a projection method for statistics and apply it 
</h2><span id='topic+project'></span><span id='topic+project.character'></span><span id='topic+project.default'></span><span id='topic+get_projector'></span><span id='topic+get_projection'></span><span id='topic+project.default'></span><span id='topic+plot_proj'></span><span id='topic+neuralNet'></span>

<h3>Description</h3>

<p><code>project</code> is a generic function with two methods. If the first argument is a parameter name, 
<code>project.character</code> (alias: <code>get_projector</code>) defines a projection function from several statistics to an output statistic predicting  
this parameter. <code>project.default</code>  (alias: <code>get_projection</code>) produces a vector of projected statistics using such a projection. <code>project</code> is particularly useful to reduce a large number of summary statistics to a vector of projected summary statistics, with as many elements as parameters to infer. This dimension reduction can substantially speed up subsequent computations. 
The concept implemented in <code>project</code> is to fit a parameter to the various statistics available, using machine-learning or mixed-model prediction methods. All such methods can be seen as nonlinear projection to a one-dimensional space. <code>project.character</code> is an interface that allows different projection methods to be used, provided they return an object of a class that has a defined <code>predict</code> method with a <code>newdata</code> argument (as expected, see <code><a href="stats.html#topic+predict">predict</a></code>).
</p>
<p><code>plot_proj</code> is a hastily written convenience function to plot a diagnostic plot for a projection from an object of class <code>SLik_j</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>project(x,...)

## S3 method for building the projection 
## S3 method for class 'character'
project(x, stats, data, 
             trainingsize=  eval(Infusion.getOption("trainingsize")),
             train_cP_size= eval(Infusion.getOption("train_cP_size")),
             method, methodArgs=list(), verbose=TRUE,...)
get_projector(...) # alias for project.character

## S3 method for applying the projection
## Default S3 method:
project(x, projectors, use_oob=Infusion.getOption("use_oob"), 
                          is_trainset=FALSE, methodArgs=list(), ...)
get_projection(...) # alias for project.default

plot_proj(object, parm, proj, xlab=parm, ylab=proj, ...) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="project.character_+3A_x">x</code></td>
<td>

<p>The name of the parameter to be predicted, or a vector/matrix/list of matrices of summary statistics.  
</p>
</td></tr>
<tr><td><code id="project.character_+3A_stats">stats</code></td>
<td>

<p>Statistics from which the predictor is to be predicted 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_use_oob">use_oob</code></td>
<td>

<p>Boolean: whether to use out-of-bag predictions for data used in the training set, when such oob predictions are available (i.e. for random forest methods). Default as controlled by the same-named package option, is TRUE. This by default involves a costly check on each row of the input <code>x</code>, whetehr it belongs to the training set, so it is better to set it to FALSE if you are sure <code>x</code> does not belong to the training set (for true data in particular). Alternatively the check can be bypassed if you are sure that <code>x</code> was used as the training set.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_is_trainset">is_trainset</code></td>
<td>

<p>Boolean. Set it to TRUE if <code>x</code> was used as the training set, to bypass a costly check (see <code>use_oob</code> argument). 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_data">data</code></td>
<td>

<p>A list of simulated empirical distributions, as produced by <code><a href="#topic+add_simulation">add_simulation</a></code>, or a data frame with all required variables.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_trainingsize">trainingsize</code>, <code id="project.character_+3A_train_cp_size">train_cP_size</code></td>
<td>
<p> Integers;
for most projection methods (excluding <code>"REML"</code> but including <code>"ranger"</code>) only  <code>trainingsize</code> is taken into account: it gives the maximum size of the training set (and is infinite by default for <code>"ranger"</code> method). If the <code>data</code> have more rows the training set is randomly sampled from it. For the <code>"REML"</code> method, <code>train_cP_size</code> is the maximum size of the data used for estimation of smoothing parameters, and <code>trainingsize</code> is the maximum size of the data from which the predictor is built given the smoothing parameters.
</p>
</td></tr>
<tr><td><code id="project.character_+3A_method">method</code></td>
<td>

<p>character string: <code>"REML"</code>, <code>"GCV"</code>, or the name of a suitable projection function. The latter may be defined in another package, e.g. <code>"ranger"</code> or <code>"randomForest"</code>, or predefined by <code style="white-space: pre;">&#8288;Infusion&#8288;</code>, or defined by the user. See Details for predefined functions and for defining new ones. The default method is <code>"ranger"</code> if this package is installed, and <code>"REML"</code> otherwise. Defaults may change in later versions, so it is advised to provide an explicit <code>method</code> to improve reproducibility. 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_methodargs">methodArgs</code></td>
<td>

<p>A list of arguments for the projection method. For <code>project.character</code>, the <code>ranger</code> method is run with some default argument if no <code>methodArgs</code> are specified. Beware that a NULL <code>methodArgs$splitrule</code> is interpreted as the <code>"extratrees"</code> <code>splitrule</code>, whereas in a direct call to <code>ranger</code>, this would be interpreted as the <code>"variance"</code> <code>splitrule</code>. For <code>project.default</code>, the only <code>methodArgs</code> element handled is <code>num.threads</code> passed to <code>predict.ranger</code> (which can also be controlled globally by <code>Infusion.options(nb_cores=.)</code>).   
</p>
<p>For other methods, <code>project</code> kindly (tries to) assign values to the required arguments if they are absent from <code>methodArgs</code>, according to the following rules:
</p>
<p>If <code>"REML"</code> or <code>"GCV"</code> methods are used (in which case <code>methodArgs</code> is completely ignored); or
</p>
<p>if the projection method uses <code>formula</code> and <code>data</code> arguments (in particular if the formula is of the form 
<code>response ~ var1 + var2 + ...</code>; otherwise the formula should be provided through <code>methodArgs</code>). This works 
for example for methods based on <code>nnet</code>; or
</p>
<p>if the projection method uses <code>x</code> and <code>y</code> arguments. This works for example for the (somewhat obsolete) method <code>randomForest</code> (though not with the generic function <code>method="randomForest"</code>, but only with the internal function 
<code>method="randomForest:::randomForest.default"</code>).
</p>
</td></tr>
<tr><td><code id="project.character_+3A_projectors">projectors</code></td>
<td>

<p>A list with elements of the form <code>&lt;name&gt;=&lt;project result&gt;</code>, where the <code>&lt;name&gt;</code> must differ from any name of <code>x</code>. 
<code>&lt;project result&gt;</code> may indeed be the return object of a <code>project</code> call. 
</p>
</td></tr>
<tr><td><code id="project.character_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print some information or not. In particular, <code>TRUE</code>, true-vs.-predicted diagnostic plots will be drawn for projection methods &ldquo;known&rdquo; by Infusion (notably <code>"ranger"</code>, <code>"fastai.tabular.learner.TabularLearner"</code>, <code>"keras::keras.engine.training.Model"</code>, <code>"randomForest"</code>, <code>"GCV"</code>, <code>caret::train</code>).
</p>
</td></tr>
<tr><td><code id="project.character_+3A_object">object</code></td>
<td>
<p>An object of class <code>SLik_j</code>.</p>
</td></tr>
<tr><td><code id="project.character_+3A_parm">parm</code></td>
<td>
<p>Character string: a parameter name.</p>
</td></tr>
<tr><td><code id="project.character_+3A_proj">proj</code></td>
<td>
<p>Character string: name of projected statistic.</p>
</td></tr>
<tr><td><code id="project.character_+3A_xlab">xlab</code>, <code id="project.character_+3A_ylab">ylab</code></td>
<td>
<p>Passed to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
<tr><td><code id="project.character_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other functions. For <code>plot_proj</code>, they are passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The preferred <code>project</code> method is non-parametric regression by (variants of) the random forest method as implemented in <span class="pkg">ranger</span>. It is the default method, if that package is installed. Alternative methods have been interfaced as detailed below, but the functionality of most interfaces is infrequently tested. 
</p>
<p>By default, the ranger call through <code>project</code> will use the split rule <code>"extratrees"</code>, with some other controls also differing from the <span class="pkg">ranger</span> package defaults. If the split rule <code>"variance"</code> is used, the default value of <code>mtry</code> used in the call is also distinct from the <span class="pkg">ranger</span> default, but consistent with Breiman 2001 for regression tasks. 
</p>
<p>Machine learning methods such as random forests overfit, <em>except if</em> out-of-bag predictions are used. When they are not, the bias is manifest in the fact that using the same simulation table for learning the projectors and for other steps of the analyses tend to lead to too narrow confidence regions. This bias disappears over iterations of <code><a href="#topic+refine">refine</a></code> when the projectors are kept constant. <code>Infusion</code> avoid this bias by using out-of-bag predictions when relevant, when <code>ranger</code> and <code>randomForest</code> are used. But it provides no code handling that problem for other machine-learning methods. Then, users should cope with that problems, and at a minimum should not update projectors in every iteration (the &ldquo;<a href="https://gitlab.mbb.univ-montp2.fr/francois/Infusion/-/blob/master/documents/InfusionIntro.pdf">Gentle Introduction to Infusion</a> may contain further information about this problem&rdquo;).       
</p>
<p>Prediction can be based on a linear mixed model (LMM) with autocorrelated random effects,
internally calling the <code><a href="spaMM.html#topic+corrHLfit">corrHLfit</a></code> function with formula
<code>&lt;parameter&gt; ~ 1+ Matern(1|&lt;stat1&gt;+...+&lt;statn&gt;)</code>. This approach allows in principle to produce arbitrarily 
complex predictors (given sufficient input) and avoids overfitting in the same way as restricted likelihood methods avoids overfitting in LMM. REML methods are then used by default to estimate the smoothing parameters. However, faster methods are generally required.
</p>
<p>To keep REML computation reasonably fast, the <code>train_cP_size</code> and <code>trainingsize</code> arguments determine respectively the size of the subset used to estimate the smoothing parameters and the size of the subset defining the predictor given the smoothing parameters.  REML fitting is already slow for data sets of this size (particularly as the number of predictor variables increase).
</p>
<p>If <code>method="GCV"</code>, a generalized cross-validation procedure (Golub et al. 1979) is used to estimate the smoothing parameters. This is faster but still slow, so a random subset of size <code>trainingsize</code> is still used to estimate the smoothing parameters and generate the predictor.
</p>
<p>Alternatively, various machine-learning methods can be used (see e.g. Hastie et al., 2009,  for an introduction). A random subset of size <code>trainingsize</code> is again used, with a larger default value bearing the assumption that these methods are faster. Predefined methods include
</p>

<ul>
<li> <p><code>"ranger"</code>, the default, a computationally efficient implementation of random forest;
</p>
</li>
<li> <p><code>"randomForest"</code>, the older default, probably obsolete now;
</p>
</li>
<li> <p><code>"neuralNet"</code>, a neural network method, using  the <code>train</code> function from the <code>caret</code> package (probably obsolete too);
</p>
</li>
<li> <p><code>"fastai"</code> deep learning using the <code>fastai</code> package;
</p>
</li>
<li> <p><code>"keras"</code> deep learning using the <code>keras</code> package.
</p>
</li></ul>

<p>The last two interfaces may yet offer limited or undocumented control: using deep learning seems attractive but the benefits over <code>"ranger"</code> are not clear (notably, the latter provide out-of-bag predictions that avoid overfitting).   
</p>
<p>In principle, any object suitable for prediction could be used as one of the <code>projectors</code>, and <code>Infusion</code> implements their usage so that in principle unforeseen projectors could be used. That is, if predictions of a parameter can be performed using an object <code>MyProjector</code> of class <code>MyProjectorClass</code>, 
<code>MyProjector</code> could be used in place of a <code>project</code> result 
if <code>predict.MyProjectorClass(object,newdata,...)</code> is defined. However, there is no guarantee that this will work on unforeseen projection methods, as each method tends to have some syntactic idiosyncrasies. For example, if the learning method that generated the projector used
a formula-data syntax, then its <code>predict</code> method is likely to request names for its <code>newdata</code>, that need to be provided through <code>attr(MyProjector,"stats")</code> (these names cannot be assumed to be in the <code>newdata</code> when <code>predict</code> is called through <code>optim</code>). 
</p>


<h3>Value</h3>

<p><code>project.character</code> returns an object of class returned by the <code>method</code> (methods <code>"REML"</code> and <code>"GCV"</code> will call <code><a href="spaMM.html#topic+corrHLfit">corrHLfit</a></code> which returns an object of class <code>spaMM</code>)
<code>project.default</code> returns an object of the same class and structure as the input <code>x</code>, containing the projected statistics inferred from the input summary statistics.
</p>


<h3>Note</h3>

<p>See workflow examples in <code><a href="#topic+example_reftable">example_reftable</a></code> and <code><a href="#topic+example_raw_proj">example_raw_proj</a></code>.</p>


<h3>References</h3>

<p>Breiman, L. (2001). Random forests. Mach Learn, 45:5-32. &lt;doi:10.1023/A:1010933404324&gt;
</p>
<p>Golub, G. H., Heath, M. and Wahba, G. (1979) Generalized Cross-Validation as a method for choosing a good ridge parameter. 
Technometrics 21: 215-223.
</p>
<p>T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning: Data Mining, Inference,
and Prediction. Springer, New York, 2nd edition, 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='refine'>
Refine estimates iteratively.    
</h2><span id='topic+refine'></span><span id='topic+refine.default'></span><span id='topic+refine.SLik'></span><span id='topic+refine.SLik_j'></span><span id='topic+refine.SLikp'></span>

<h3>Description</h3>

<p>This is a generic function with currently methods for <code>SLik</code>, <code>SLik_j</code> and <code>SLikp</code> objects (as produced by <code><a href="#topic+MSL">MSL</a></code>). Depending on the value of its <code>newsimuls</code> argument, and on whether the function used to generate empirical distributions can be called by R, it (1) defines new parameters points and/or (2) infers their summary likelihood or tail probabilities for each parameter point independently, adds the inferred values results as input for refined inference of likelihood or P-value response surface, and provides new point estimates and confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SLik'
refine(object, method=NULL, ...)
## Default S3 method:
refine(object, surfaceData, Simulate =
            attr(surfaceData,"Simulate"), maxit = 1, n = NULL, 
            useEI = list(max=TRUE,profileCI=TRUE,rawCI=FALSE), 
            newsimuls = NULL, trypoints=NULL, CIs = useCI, useCI = TRUE, level = 0.95, 
            verbose = list(most=interactive(),final=NULL,movie=FALSE,proj=FALSE),
            precision = Infusion.getOption("precision"),
            nb_cores = NULL, packages=attr(object$logLs,"packages"), 
            env=attr(object$logLs,"env"), method,  using = object$using, 
            eval_RMSEs=TRUE, update_projectors = FALSE,
            cluster_args=list(),
            cl_seed=.update_seed(object),
            nbCluster=quote(refine_nbCluster(nr=nrow(data))),
            ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="refine_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object
</p>
</td></tr>
<tr><td><code id="refine_+3A_surfacedata">surfaceData</code></td>
<td>

<p>A data.frame with attributes, usually taken from the <code>object</code> and thus <b>not</b> specified by user, usable as input for <code><a href="#topic+infer_surface">infer_surface</a></code>.  
</p>
</td></tr>
<tr><td><code id="refine_+3A_simulate">Simulate</code></td>
<td>

<p>Character string: name of the function used to simulate samples. The only meaningful non-default value is <code>NULL</code>, in which case <code>refine</code> may return (if <code>newsimuls</code> is also <code>NULL</code>) a data frame of parameter points on which to run a simulation function.
</p>
</td></tr>
<tr><td><code id="refine_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of iterative refinements (see also <code>precision</code> argument)
</p>
</td></tr>
<tr><td><code id="refine_+3A_n">n</code></td>
<td>

<p>NULL or numeric, for a number of parameter points (excluding replicates and confidence interval points in the primitive workflow), whose likelihood should be computed 
(see <code>n</code> argument of <code><a href="#topic+sample_volume">sample_volume</a></code>). This argument is typically not heeded in the first refinement iteration (only one fifth as many points may be produced), but will be closely approached in later ones (so four refinement iterations with <code>n=1000</code> is expected to produce 3200 new points). If <code>n</code> is left NULL, the number of points of the initial reference table is used as a reference, but with a somewhat different effect: four refinement iterations starting from a reference table of <code>1000</code> ones iis expected to produce 4000 new points (though again, possibly only 200 in the first refinement iteration).      
</p>
</td></tr>
<tr><td><code id="refine_+3A_useei">useEI</code></td>
<td>

<p>Cf this argument in <code><a href="#topic+rparam">rparam</a></code>
</p>
</td></tr>
<tr><td><code id="refine_+3A_newsimuls">newsimuls</code></td>
<td>

<p>For the <code>SLik_j</code> method, a matrix or data frame, with the same parameters and summary statistics as the <code>data</code> of the original <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code> call.
</p>
<p>For other methods, a <code>list</code> of simulation of distributions of summary statistics, in the same format as for <code>link{add_simulation}</code>. 
If no such list is provided (i.e., if <code>newsimuls</code> remains <code>NULL</code>), the <code>attr(object$logLs,"Simulate")</code> function is used (it is inherited from the <code>Simulate</code> 
argument of <code><a href="#topic+add_simulation">add_simulation</a></code> through the initial sequence of calls of functions <code>add_simulation</code>,
<code>infer_logLs</code> or <code>infer_tailp</code>, and <code>infer_surface</code>). If no such function is available, then this function returns parameters for which new distribution should be provided by the user.
</p>
</td></tr>
<tr><td><code id="refine_+3A_trypoints">trypoints</code></td>
<td>

<p>A data frame of parameters on which the simulation function <code>attr(object$logLs,"Simulate")</code> should be called to extend the reference table. Only for programming by expert users, because poorly thought input <code>trypoints</code> could severely affect the inferences.     
</p>
</td></tr>
<tr><td><code id="refine_+3A_cis">CIs</code></td>
<td>

<p>Boolean: whether to infer bounds of (one-dimensional, profile) confidence intervals. Their computation is not quite reliable in parameter spaces of large dimensions, so they should not be trusted per se, yet they may be useful for the definition of new parameter points.   
</p>
</td></tr>
<tr><td><code id="refine_+3A_useci">useCI</code></td>
<td>

<p>whether to include parameter points near the inferred confidence interval points in the set of points whose likelihood should be computed. Effective only if <code>CIs</code> was TRUE.
</p>
</td></tr>
<tr><td><code id="refine_+3A_level">level</code></td>
<td>

<p>Intended coverage of confidence intervals 
</p>
</td></tr>
<tr><td><code id="refine_+3A_verbose">verbose</code></td>
<td>
<p> A list as shown by the default, or simply a vector of booleans. <code>verbose$most</code> controls whether to display information about progress and results, except plots; <code>$final</code> controls whether to <code>plot()</code> the final <code>object</code> to show the final likelihood surface. Default is to plot it only in an interactive session and if fewer than three parameters are estimated; <code>$movie</code> controls whether to <code>plot()</code> the updated <code>object</code> in each iteration; <code>verbose$proj</code> controls the <code>verbose</code> argument of <code><a href="#topic+project.character">project.character</a></code>. If <code>verbose</code> is an unnamed vector of booleans, they are matched to as many elements from <code>"most","movie","final","proj"</code>, in that order. 
</p>
</td></tr>
<tr><td><code id="refine_+3A_precision">precision</code></td>
<td>

<p>Requested local precision of surface estimation, in terms of prediction standard errors (RMSEs) of both the maximum summary log-likelihood and the likelihood ratio at any CI bound available. Iterations will stop when either <code>maxit</code> is reached, or if the RMSEs have been computed for the object (see <code>eval_RMSEs</code> argument) and this precision is reached for the RMSEs.
A given precision on the CI bounds themselves might seem more interesting, but is not well specified by a single precision parameter if the parameters are on widely different scales.
</p>
</td></tr>
<tr><td><code id="refine_+3A_nb_cores">nb_cores</code></td>
<td>
<p>Shortcut for <code>cluster_args$spec</code> for sample simulation.</p>
</td></tr>
<tr><td><code id="refine_+3A_cluster_args">cluster_args</code></td>
<td>
<p>A list of arguments for <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, in addition to <code>makeCluster</code>'s <code>spec</code> argument which is in most cases best specified by the <code>nb_cores</code> argument. Cluster arguments allow independent control of parallel computations for the different steps of a <code>refine</code> iteration (see Details; as a rough but effective summary, use only <code>nb_cores</code> when the simulations support it, and only <code>cluster_args=list(project=list(num.threads=&lt;.&gt;))</code> when they do not).</p>
</td></tr>
<tr><td><code id="refine_+3A_packages">packages</code></td>
<td>
<p>NULL or a list with possible elements <code>add_simulation</code> and <code>logL_method</code>, passed respectively as the <code>packages</code> arguments of <code>add_simulation</code> and <code>infer_logLs</code>, wherein they are the additional packages to be loaded on child processes. The default value keeps pre-<code>refine</code> values over iterations.</p>
</td></tr>
<tr><td><code id="refine_+3A_env">env</code></td>
<td>
<p>An environment, passed as the <code>env</code> argument to <code>add_simulation</code>. The default value keeps the pre-<code>refine</code> value over iterations.</p>
</td></tr>
<tr><td><code id="refine_+3A_using">using</code></td>
<td>
<p>Passed to <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>: a charcter string used to control the joint-density estimation method, as documented for that function. Default is to use to same method as in the the first iteration, but this argument allows a change of method.</p>
</td></tr>
<tr><td><code id="refine_+3A_method">method</code></td>
<td>
<p>(A vector of) suggested method(s) for estimation of smoothing parameters (see <code>method</code> argument of <code><a href="#topic+infer_surface">infer_surface</a></code>), and therefore controlling the primitive workflow (see <code>using</code> instead for controlling the up-to-date workflow). The ith element of the vector is
used in the ith iteration, if available; otherwise the last element is used. This argument is not always heeded, in that REML may be used if the suggested method is GCV but it appears to perform poorly. The default for <code>SLikp</code> and <code>SLikp</code> objects are <code>"REML"</code> and <code>"PQL"</code>, respectively. 
</p>
</td></tr>
<tr><td><code id="refine_+3A_eval_rmses">eval_RMSEs</code></td>
<td>
<p>passed to <code><a href="#topic+MSL">MSL</a></code></p>
</td></tr>
<tr><td><code id="refine_+3A_update_projectors">update_projectors</code></td>
<td>
<p>Boolean; whether to update the projectors at each iteration.</p>
</td></tr>
<tr><td><code id="refine_+3A_cl_seed">cl_seed</code></td>
<td>
<p>NULL or integer, passed to <code>add_simulation</code>. The default code uses an internal function, <code>.update_seed</code>, to update it from a previous iteration.</p>
</td></tr>
<tr><td><code id="refine_+3A_nbcluster">nbCluster</code></td>
<td>
<p>Passed to <code><a href="#topic+infer_SLik_joint">infer_SLik_joint</a></code>. The <code>data</code> in the expression for the default value refers to the <code>data</code> argument of the latter function.</p>
</td></tr>
<tr><td><code id="refine_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods. <code>refine</code> passes these arguments to the <code>plot</code> method suitable for the <code>object</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>New parameter points are sampled as follows: the algorithm aims to sample uniformly the space of parameters contained in the confidence regions defined by the <code>level</code> argument, and to surround it by a region sampled proportionally to likelihood. In each iteration the algorithm aims to add as many points (say <em>n</em>) as computed in the first iteration, so that after <em>k</em> iterations of <code>refine</code>, there are <code class="reqn">n * (k+1)</code> points in the simulation table. However, when not enough points satisfy certain criteria, only <em>n/5</em> points may be added in an iteration, this being compensated in further iterations. For example, if <code class="reqn">n=600</code>, the table may include only 720 points after the first refine, but 1800 after the second.
</p>
<p>Independent control of parallelisation may be needed in the different steps, e.g. if the simulations are not easily parallelised whereas the projection method natively handles parallelisation. In the up-to-date workflow with default <code>ranger</code> projection method, prarallelisation controls may be passed to <code>add_reftable</code> for sample simulations, to <code>project</code> methods when projections are updated, and to <code>MSL</code> for RMSE computations (alternatively for the primitive workflow, <code>add_simulation</code>, <code>infer_logLs</code> and <code>MSL</code> are called). <code>nb_cores</code>, if given and not overcome by other options, will control simulation and projection steps (but not RMSE computation): <code>nb_cores</code> gives the number of parallel processes for sample simulation, with additional <code>makeCluster</code> arguments taken from <code>cluster_args</code>, but RMSE computations are performed serially. Further independent control is possible as follows:<br />
<code>cluster_args=list(project=list(num.threads=&lt;.&gt;))</code> allows control of the <code>num.threads</code> argument of <span class="pkg">ranger</span> functions;<br /> 
<code>cluster_args=list(RMSE=list(spec=&lt;number of 'children'&gt;))</code> can be used to force parallel computation of RMSEs;<br />
<code>cluster_args=list(spec=&lt;.&gt;, &lt;other makeCluster arguments&gt;))</code> would instead apply the same arguments to both reference table and RMSE computation, overcoming the default effect of <code>nb_cores</code> in both of them; finally<br /> 
<code>cluster_args=list(reftable=list(&lt;makeCluster arguments&gt;),RMSEs=list(&lt;makeCluster arguments&gt;))</code> allows full independent control of parallelisation for the two computations.
</p>


<h3>Value</h3>

<p><code>refine</code> returns an updated <code>SLik</code> or <code>SLik_j</code> object.
</p>


<h3>Note</h3>

<p>See workflow examples in (by order of decreasing relevance) <code><a href="#topic+example_reftable">example_reftable</a></code>, <code><a href="#topic+example_raw_proj">example_raw_proj</a></code> and <code><a href="#topic+example_raw">example_raw</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## see Note for links to examples.
</code></pre>

<hr>
<h2 id='rparam'>
Sample the parameter space
</h2><span id='topic+rparam'></span><span id='topic+sample_volume'></span>

<h3>Description</h3>

<p>These functions take an <code>SLik</code> object (as produced by <code><a href="#topic+MSL">MSL</a></code>) and samples its parameter space in (hopefully) clever ways, not yet well documented. <code>rparam</code> calls <code>sample_volume</code> to define points targeting the likelihood maximum and the bounds of confidence intervals, with <code>n</code> for these different targets dependent on the mean square error of prediction of likelihood at the maximum and at CI bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rparam(object, n= 1, useEI = list(max=TRUE,profileCI=TRUE,rawCI=FALSE), 
       useCI = TRUE, verbose = interactive(), tryn=30*n,  
       level = 0.95, CIweight=Infusion.getOption("CIweight"))

sample_volume(object, n = 6, useEI, vertices=NULL,
              dlr = NULL, verbose = interactive(), 
              fixed = NULL, tryn= 30*n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rparam_+3A_object">object</code></td>
<td>

<p>an <code>SLik</code> or <code>SLik_j</code> object
</p>
</td></tr>
<tr><td><code id="rparam_+3A_n">n</code></td>
<td>

<p>The number of parameter points to be produced 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_useei">useEI</code></td>
<td>
<p> List of booleans, each determining whether to use an &ldquo;expected improvement&rdquo; (EI) criterion (e.g. Bingham et al., 2014) to select candidate parameter points to better ascertain a particular focal point. The elements <code>max</code>, <code>profileCI</code> and <code>rawCI</code> determine this for three types of focal points, respectively the MSL estimate, profile CI bounds, and full-dimensional bounds. When EI is used, <code>n</code> points with best EI are selected among <code>tryn</code> points randomly generated in some neighborhood of the focal point. 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_vertices">vertices</code></td>
<td>
<p>Points are sampled within a convex hull defined by <code>vertices</code>. By default, these vertices are taken from <code>object$fit$data</code>.  
</p>
</td></tr>
<tr><td><code id="rparam_+3A_useci">useCI</code></td>
<td>

<p>Whether to define points targeting the bounds of confidence intervals for the parameters. An expected improvement criterion is also used here.
</p>
</td></tr>
<tr><td><code id="rparam_+3A_level">level</code></td>
<td>

<p>If <code>useCI</code> is <code>TRUE</code> but confidence intervals are not available from the <code>object</code>, such intervals are computed with coverage <code>level</code>. 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_dlr">dlr</code></td>
<td>

<p>A (log)likelihood ratio threshold used to select points in the upper region of the likelihood surface. Default value is 
given by <code>Infusion.getOption("LRthreshold")</code>   
</p>
</td></tr>
<tr><td><code id="rparam_+3A_verbose">verbose</code></td>
<td>

<p>Whether to display some information about selection of points, or not
</p>
</td></tr>
<tr><td><code id="rparam_+3A_fixed">fixed</code></td>
<td>

<p>A list or named vector, of which each element is of the form <code>&lt;parameter name&gt;=&lt;value&gt;</code>, defining a one-dimensional constraint in parameter space.
Points will be sampled in the intersection of the volume defined by the <code>object</code> and of such constraint(s).
</p>
</td></tr>
<tr><td><code id="rparam_+3A_tryn">tryn</code></td>
<td>

<p>See <code>useEI</code> argument. 
</p>
</td></tr>
<tr><td><code id="rparam_+3A_ciweight">CIweight</code></td>
<td>

<p>For development purposes, not documented. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame of parameter points. Only parameters variable in the <code>SLik</code> object are considered. 
</p>


<h3>References</h3>

<p>D. Bingham, P. Ranjan, and W.J. Welch (2014) Design of Computer Experiments for Optimization, Estimation of Function Contours, and Related Objectives, pp. 109-124 in Statistics in Action: A Canadian Outlook (J.F. Lawless, ed.). Chapman and Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (Infusion.getOption("example_maxtime")&gt;10) {
 data(densv)
 summliksurf &lt;- infer_surface(densv) ## infer a log-likelihood surface
 sample_volume(summliksurf)
}
</code></pre>

<hr>
<h2 id='summLik'>
Model density evaluation for given data and parameters
</h2><span id='topic+summLik'></span><span id='topic+summLik.SLik_j'></span><span id='topic+summLik.default'></span>

<h3>Description</h3>

<p>Evaluation of inferred probability density as function of parameters and of (projected) summary statistics is implemented as a generic function <code>summLik</code>.
Given the (projected) statistics for the data used to build the <code>SLik_j</code> object, and the fitted parameters, this returns the (log)likelihood as the generic
<code>logLik</code> extractor. However, parameters can be varied (providing the likelihood function), and the data too.
</p>
<p>This documentation deals mostly with the method for objects of class <code>SLik_j</code> produced by the up-to-date version of the summary-likelihood workflow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summLik(object, parm, data, ...)

# S3 method for class 'SLik_j'
## S3 method for class 'SLik_j'
summLik(object, parm, data=t(attr(object$logLs,"stat.obs")), 
                         log=TRUE, which="lik", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summLik_+3A_object">object</code></td>
<td>
<p>An <code>SLik</code> or <code>SLik_j</code> object</p>
</td></tr>
<tr><td><code id="summLik_+3A_parm">parm</code></td>
<td>
<p>data frame or matrix, containing coordinates of parameter points for which (log) likelihoods will be computed</p>
</td></tr>
<tr><td><code id="summLik_+3A_data">data</code></td>
<td>
<p>The (projected, if relevant) summary statistics for which the likelihood of given parameters is to be computed. By default, the (projected) statistics for the data used to build the <code>SLik_j</code> object</p>
</td></tr>
<tr><td><code id="summLik_+3A_log">log</code></td>
<td>
<p>Boolean: whether to return log likelihood or raw likelihood. Better ignored.</p>
</td></tr>
<tr><td><code id="summLik_+3A_which">which</code></td>
<td>
<p>character string: <code>"lik"</code> for (log) likelihood inferred directly from the gaussian mixture model for joint parameters and summary statistics.
But <code>"safe"</code>, which deals with a possible problem of this direct computation (see Details), is used internally by Infusion in all maximizations of likelihood.
</p>
</td></tr>
<tr><td><code id="summLik_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An  object of class <code>SLik_j</code> contains a simulated joint distribution of parameters and (projected) summary statistics, and a fit of a multivariate gaussian mixture model to this simulated distribution, the &ldquo;jointdens&rdquo;, from which a marginal density &ldquo;margpardens&rdquo; of parameters can be deduced. The raw likelihood(P;D) is the probability of the data D given the parameters P, viewed as function the parameters and for fixed data. It is inferred as jointdens(D,P)/margpardens(P) (for different P, each of jointdens and margdens are probabilities from a single (multivariate) gaussian mixture model, but this is not so for their ratio). 
</p>
<p>When margdens(P) is low, indicating that the region of parameter space around P has been poorly sampled in the simulation step, inference of likelihood is unreliable. Spuriously high likelihood may be inferred, which results notably in poor inference based on likelihood ratios. For this reason, it is often better to use the argument  <code>which="safe"</code> whereby the likelihood is penalized when margdens(P) is low. The penalization is of the form<br /> 
<code>penalized= unpenalized * pmin(1,margpardens/object$thr_dpar)</code>, where <code>thr_dpar</code> is a marginal density threshold stored in the <code>SLik_j</code> object. The source code should be consulted for details, and is subject to changes without notice.  
</p>


<h3>Value</h3>

<p>Numeric vector
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+logLik">logLik</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Using 'slik_j' object from the example in help("example_reftable") 
summLik(slik_j, parm=slik_j$MSL$MSLE+0.1)

# summLik() generalizes logLik():
summLik(slik_j, parm=slik_j$MSL$MSLE) == logLik(slik_j) # must be TRUE

## End(Not run)
</code></pre>

<hr>
<h2 id='write_workflow'>
Workflow template
</h2><span id='topic+write_workflow'></span>

<h3>Description</h3>

<p>codewrite_workflow writes a workflow script for inference. Beyond possibly saving some typing, this suggests what may be a reasonably good starting workflow. One should not expect to control all options of the workflow through the <code>write_workflow</code> arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_workflow(con = stdout(), lower, upper, nUnique, Simulate, simulator_args=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_workflow_+3A_con">con</code></td>
<td>

<p>A connection object or a character string. Passed to <code><a href="base.html#topic+writeLines">writeLines</a></code>.
</p>
</td></tr>
<tr><td><code id="write_workflow_+3A_lower">lower</code></td>
<td>

<p>A named numeric vector of lower bounds for parameter space. 
</p>
</td></tr>
<tr><td><code id="write_workflow_+3A_upper">upper</code></td>
<td>

<p>A named numeric vector of upper bounds for parameter space. 
</p>
</td></tr>
<tr><td><code id="write_workflow_+3A_nunique">nUnique</code></td>
<td>

<p>Number of simulations of the process (i.e. of rows of the reference table) in the first iteration. 
</p>
</td></tr>
<tr><td><code id="write_workflow_+3A_simulate">Simulate</code></td>
<td>

<p>Function, or function name as a string. Sets the same-named <code>add_reftable</code> argument.
</p>
</td></tr>
<tr><td><code id="write_workflow_+3A_simulator_args">simulator_args</code></td>
<td>

<p>list of arguments for the simulator. Sets the ... in the <code>add_reftable</code> call.
</p>
</td></tr>
<tr><td><code id="write_workflow_+3A_...">...</code></td>
<td>

<p>Sets additional arguments in the <code>refine</code> call.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value. Used for the side-effect text, written to the connection.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  write_workflow(
    ## arguments for init_reftable():
    lower=c(logTh1=-2,logTh2=-2,logTh3=-2,logTh4=-2,ar=0.01,logMu=-5,MEANP=0.01),
    upper=c(logTh1=1, logTh2=1, logTh3=1, logTh4=1, ar=0.99,logMu=-2,MEANP=0.99),
    nUnique = 1000,
    #
    ## for add_reftable():
    Simulate="schtroumf",   # name of a user-defined R function
    simulator_args= list(   # Imagine that schtroumf() require arguments 'exe_path' and 'cmdline':
      exe_path="'path_to_smurf_executable'",      
      cmdline="'smurf.exe -a -b -c -d'"
    ),    # Do check the quotation marks in the output...
    #
    ## optional arguments for refine():    
    n=8000/3.2, CIs=TRUE, update_projectors=FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
