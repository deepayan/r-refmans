<!DOCTYPE html><html><head><title>Help for package FedIRT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FedIRT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#example_data_2PL'><p>Binary Response Dataset for Federated 2PL Model</p></a></li>
<li><a href='#example_data_2PL_1'><p>Binary Response Dataset for Federated 2PL Model</p></a></li>
<li><a href='#example_data_2PL_2'><p>Binary Response Dataset for Federated 2PL Model</p></a></li>
<li><a href='#example_data_graded'><p>Graded Response Dataset for Federated Graded Model</p></a></li>
<li><a href='#example_data_graded_and_binary'><p>Graded Response Dataset for Federated Graded Model</p></a></li>
<li><a href='#fedirt_2PL'><p>Federated 2PL estimate function</p></a></li>
<li><a href='#fedirt_2PL_data'><p>Federated 2PL model</p></a></li>
<li><a href='#fedirt_2PL_median_data'><p>Federated 2PL model</p></a></li>
<li><a href='#fedirt_gpcm'><p>Federated Graded Response Model Estimation Function</p></a></li>
<li><a href='#fedirt_gpcm_data'><p>Federated gpcm model</p></a></li>
<li><a href='#g_logL'><p>Gradient of Log-Likelihood for the federated 2PL Model</p></a></li>
<li><a href='#g_logL_entry'><p>Aggregated Gradient of Log-Likelihood for Federated Learning</p></a></li>
<li><a href='#g_logL_gpcm'><p>Gradient of Log-Likelihood for the federated graded Model</p></a></li>
<li><a href='#logL'><p>Log-Likelihood of the federated 2PL Model</p></a></li>
<li><a href='#logL_entry'><p>Aggregate Log-Likelihood Function for Federated Learning</p></a></li>
<li><a href='#logL_gpcm'><p>Log-Likelihood of the federated graded Model</p></a></li>
<li><a href='#memoize'><p>Memoization Function for Speed Optimization</p></a></li>
<li><a href='#runclient'><p>Client for Federated IRT Model Estimation</p></a></li>
<li><a href='#runserver'><p>Server for Federated IRT Model Estimation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Federated Item Response Theory Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Integrate Item Response Theory (IRT) and Federated Learning to estimate traditional IRT models, including the 2-Parameter Logistic (2PL) and the Graded Response Models, with enhanced privacy. It allows for the estimation in a distributed manner without compromising accuracy. A user-friendly 'shiny' application is included. For more details, see Biying Zhou, Feng Ji (2024) "'FedIRT': An R package and 'shiny' app for estimating federated item response theory models" <a href="https://github.com/Feng-Ji-Lab/FedIRT/blob/main/paper/paper.pdf">https://github.com/Feng-Ji-Lab/FedIRT/blob/main/paper/paper.pdf</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>purrr, pracma, shiny, httr, callr, DT, ggplot2, shinyjs,</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-10 16:50:56 UTC; zby15</td>
</tr>
<tr>
<td>Author:</td>
<td>Biying Zhou [cre],
  Feng Ji [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Biying Zhou &lt;zby.zhou@mail.utoronto.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-10 20:00:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='example_data_2PL'>Binary Response Dataset for Federated 2PL Model</h2><span id='topic+example_data_2PL'></span>

<h3>Description</h3>

<p>A synthetic dataset composed of responses from 160 students to 10 items, with all responses binary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_data_2PL
</code></pre>


<h3>Format</h3>

<p>A dataframe with 160 rows and 10 columns.
Each row corresponds to a student's set of responses, and each column represents the responses of all students to a particular item.
</p>


<h3>Details</h3>

<p>A response of 1 indicates a correct answer, and 0 represents an incorrect answer.
</p>


<h3>Source</h3>

<p>The data are synthetically generated and are not reflective of any real student data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data_2PL)

</code></pre>

<hr>
<h2 id='example_data_2PL_1'>Binary Response Dataset for Federated 2PL Model</h2><span id='topic+example_data_2PL_1'></span>

<h3>Description</h3>

<p>A synthetic dataset composed of responses from 81 students to 10 items, with all responses binary.
It is the first part of &quot;example_data_2PL&quot;.
It is used to test the correctness of federated 2PL model.
A response of 1 indicates a correct answer, and 0 represents an incorrect answer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_data_2PL_1
</code></pre>


<h3>Format</h3>

<p>A dataframe with 81 rows and 10 columns.
Each row corresponds to a student's set of responses, and each column represents the responses of all students to a particular item.
</p>


<h3>Source</h3>

<p>The data are synthetically generated and are not reflective of any real student data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data_2PL_1)

</code></pre>

<hr>
<h2 id='example_data_2PL_2'>Binary Response Dataset for Federated 2PL Model</h2><span id='topic+example_data_2PL_2'></span>

<h3>Description</h3>

<p>A synthetic dataset composed of responses from 79 students to 10 items, with all responses binary.
It is the second part of &quot;example_data_2PL&quot;.
It is used to test the correctness of federated 2PL model.
A response of 1 indicates a correct answer, and 0 represents an incorrect answer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_data_2PL_2
</code></pre>


<h3>Format</h3>

<p>A dataframe with 79 rows and 10 columns.
Each row corresponds to a student's set of responses, and each column represents the responses of all students to a particular item.
</p>


<h3>Source</h3>

<p>The data are synthetically generated and are not reflective of any real student data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data_2PL_2)

</code></pre>

<hr>
<h2 id='example_data_graded'>Graded Response Dataset for Federated Graded Model</h2><span id='topic+example_data_graded'></span>

<h3>Description</h3>

<p>A synthetic dataset containing responses of 100 students across 10 items, with all items a graded response (0-3 points). This kind of dataset is typically used for testing and validating federated graded response models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_data_graded
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows and 10 columns. Each row represents the responses of a single student, and each column represents one of the 10 graded response items.
</p>


<h3>Details</h3>

<p>The dataset is particularly suitable for testing federated graded model.
</p>


<h3>Source</h3>

<p>The data have been created for demonstration purposes and do not correspond to any actual student's grades.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data_graded)

</code></pre>

<hr>
<h2 id='example_data_graded_and_binary'>Graded Response Dataset for Federated Graded Model</h2><span id='topic+example_data_graded_and_binary'></span>

<h3>Description</h3>

<p>A synthetic dataset containing 160 students and 8 items, with the first item graded response (0-3 points) and other items binary response.
It could be used in the federated graded model testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_data_graded_and_binary
</code></pre>


<h3>Format</h3>

<p>A dataframe with 160 rows and 8 columns. Each row denotes a student's responding status, and each column denotes the responding status for all students in one item.
</p>


<h3>Source</h3>

<p>The data were generated synthetically for illustrative purposes and not representing any real answering status.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data_graded_and_binary)

</code></pre>

<hr>
<h2 id='fedirt_2PL'>Federated 2PL estimate function</h2><span id='topic+fedirt_2PL'></span>

<h3>Description</h3>

<p>This function implements a federated learning approach to estimate the parameters of the 2PL IRT model. It allows for collaborative estimation across multiple datasets, while maintaining the privacy of each individual data source. The federated 2PL model is particularly useful in contexts where data sharing might be limited due to privacy concerns or logistical constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fedirt_2PL(J, logL_entry, g_logL_entry)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fedirt_2PL_+3A_j">J</code></td>
<td>
<p>An integer indicating the number of items in the IRT model across all sites.
This number should be consistent for all response matrices provided.</p>
</td></tr>
<tr><td><code id="fedirt_2PL_+3A_logl_entry">logL_entry</code></td>
<td>
<p>A function that calculates the sum of log-likelihoods for the response matrices across all sites.
This function is crucial for evaluating the fit of the model at each iteration.</p>
</td></tr>
<tr><td><code id="fedirt_2PL_+3A_g_logl_entry">g_logL_entry</code></td>
<td>
<p>A function that computes the aggregated gradient of the log-likelihood across all participating entities.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm leverages federated learning techniques to estimate shared item parameters and individual ability levels without requiring the raw data to be combined into a single dataset.
The estimation procedure is composed of several steps, including initialization, local computations at each data source, communication of summary statistics to a central server, and global parameter updates.
This cycle is repeated until convergence criteria are met and the global parameters stabilize.
</p>
<p>Regarding the input parameters, 'J' is the number of items across all sites, which should be consistent and known in advance.
The 'logL_entry' parameter should be a function that computes the log-likelihood of the observed responses given the current model parameters.
Likewise, 'g_logL_entry' is expected to be a function that computes the gradient of the log-likelihood with respect to the model parameters to inform the optimization process during parameter estimation.
</p>


<h3>Value</h3>

<p>A list containing the following components from the federated 2PL model estimation:
</p>

<ul>
<li> <p><code>par</code>: Numeric vector of model's fitted parameters including item discrimination (a) and item difficulty (b) parameters.
</p>
</li>
<li> <p><code>value</code>: The optimization objective function's value at the found solution, typically the log-likelihood.
</p>
</li>
<li> <p><code>counts</code>: Named integer vector with counts of function evaluations and gradient evaluations during optimization.
</p>
</li>
<li> <p><code>convergence</code>: Integer code indicating the optimization's convergence status (0 indicates successful convergence).
</p>
</li>
<li> <p><code>message</code>: Message from optimizer about optimization process, NULL if no message is available.
</p>
</li>
<li> <p><code>loglik</code>: The calculated log-likelihood of the fitted model, identical to the 'value' element when the objective function is log-likelihood.
</p>
</li>
<li> <p><code>a</code>: Numeric vector of estimated item discrimination parameters.
</p>
</li>
<li> <p><code>b</code>: Numeric vector of estimated item difficulty parameters.
</p>
</li>
<li> <p><code>person</code>: List containing person-related estimates with elements:
</p>

<ul>
<li> <p><code>a</code>: Vector of discrimination parameters (same as top-level 'a').
</p>
</li>
<li> <p><code>b</code>: Vector of difficulty parameters (same as top-level 'b').
</p>
</li>
<li> <p><code>ability</code>: List of numeric vectors with person abilities per site.
</p>
</li>
<li> <p><code>site</code>: Numeric vector of abilities or locations specific to each site.
</p>
</li>
<li> <p><code>person</code>: List of numeric vectors of person abilities minus site ability.
</p>
</li></ul>

</li></ul>


<hr>
<h2 id='fedirt_2PL_data'>Federated 2PL model</h2><span id='topic+fedirt_2PL_data'></span>

<h3>Description</h3>

<p>This function is only used to test the accuracy and processing time of this algorithm. It inputs a list of responding matrices and return the federated 2PL parameters.
Note: This function can only calculate one combined dataset. To use federated 2PL in distributed datasets, please use fedirt_2PL().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fedirt_2PL_data(inputdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fedirt_2PL_data_+3A_inputdata">inputdata</code></td>
<td>
<p>A List of all responding matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input is a List of responding matrices from each school, every responding matrix is one site's data.
</p>


<h3>Value</h3>

<p>A list with the estimated global discrimination a, global difficulty b, person's abilities ability, sites' abilities site, and log-likelihood value loglik.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>inputdata = list(as.matrix(example_data_2PL))
fedresult = fedirt_2PL_data(inputdata)

inputdata = list(as.matrix(example_data_2PL_1), as.matrix(example_data_2PL_2))
fedresult = fedirt_2PL_data(inputdata)

</code></pre>

<hr>
<h2 id='fedirt_2PL_median_data'>Federated 2PL model</h2><span id='topic+fedirt_2PL_median_data'></span>

<h3>Description</h3>

<p>This function is only used to test the accuracy and processing time of this algorithm. It inputs a list of responding matrices and return the federated 2PL parameters.
Note: This function can only calculate one combined dataset. To use federated 2PL in distributed datasets, please use fedirt_2PL().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fedirt_2PL_median_data(inputdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fedirt_2PL_median_data_+3A_inputdata">inputdata</code></td>
<td>
<p>A List of all responding matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input is a List of responding matrices from each school, every responding matrix is one site's data. It uses Federated median instead of FedAvg and FedSGD. The results are not same as traditional 2PL method, but is robust if there are outliers.
</p>


<h3>Value</h3>

<p>A list with the estimated global discrimination a, global difficulty b, person's abilities ability, sites' abilities site, and log-likelihood value loglik.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
inputdata = list(as.matrix(example_data_2PL))
fedresult = fedirt_2PL_median_data(inputdata)

inputdata = list(as.matrix(example_data_2PL_1), as.matrix(example_data_2PL_2))
fedresult = fedirt_2PL_median_data(inputdata)

</code></pre>

<hr>
<h2 id='fedirt_gpcm'>Federated Graded Response Model Estimation Function</h2><span id='topic+fedirt_gpcm'></span>

<h3>Description</h3>

<p>Implements a federated learning approach for the estimation of the graded response model parameters, enabling collaborative parameter estimation across distributed datasets while ensuring individual data source privacy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fedirt_gpcm(J, M, logL_entry, g_logL_entry)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fedirt_gpcm_+3A_j">J</code></td>
<td>
<p>An integer indicating the number of items in the IRT model across all sites.
This number should be consistent for all response matrices provided.</p>
</td></tr>
<tr><td><code id="fedirt_gpcm_+3A_m">M</code></td>
<td>
<p>An integer vector indicating the maximum level (number of categories minus one) for each item across all sites, which determines the total number of step difficulties to estimate for the graded response model.</p>
</td></tr>
<tr><td><code id="fedirt_gpcm_+3A_logl_entry">logL_entry</code></td>
<td>
<p>A function that calculates the sum of log-likelihoods for the response matrices across all sites.
This function is crucial for evaluating the fit of the model at each iteration.</p>
</td></tr>
<tr><td><code id="fedirt_gpcm_+3A_g_logl_entry">g_logL_entry</code></td>
<td>
<p>A function that computes the aggregated gradient of the log-likelihood across all participating entities.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function adopts a federated learning framework to perform estimation of item step difficulties and individual ability levels in an IRT graded response model without needing to pool the data into one centralized dataset. The estimator follows an iterative optimization procedure consisisting of local computations, information sharing with a central aggregator, and updating of the global parameters.
</p>


<h3>Value</h3>

<p>A list containing the following components from the federated graded model estimation:
</p>

<ul>
<li> <p><code>par</code>: Numeric vector of model's fitted parameters including item discrimination (a) and item difficulty (b) parameters.
</p>
</li>
<li> <p><code>value</code>: The optimization objective function's value at the found solution, typically the log-likelihood.
</p>
</li>
<li> <p><code>counts</code>: Named integer vector with counts of function evaluations and gradient evaluations during optimization.
</p>
</li>
<li> <p><code>convergence</code>: Integer code indicating the optimization's convergence status (0 indicates successful convergence).
</p>
</li>
<li> <p><code>message</code>: Message from optimizer about optimization process, NULL if no message is available.
</p>
</li>
<li> <p><code>loglik</code>: The calculated log-likelihood of the fitted model, identical to the 'value' element when the objective function is log-likelihood.
</p>
</li>
<li> <p><code>a</code>: Numeric vector of estimated item discrimination parameters.
</p>
</li>
<li> <p><code>b</code>: Numeric vector of estimated item difficulty parameters.
</p>
</li></ul>

<p>#' @references
Muraki, E. (1992). &quot;A generalized partial credit model: Application of an EM algorithm.&quot;
<em>Applied Psychological Measurement</em>, <b>16</b>(2), 159&ndash;176.
<a href="https://doi.org/10.1177/014662169201600206">doi:10.1177/014662169201600206</a>
</p>

<hr>
<h2 id='fedirt_gpcm_data'>Federated gpcm model</h2><span id='topic+fedirt_gpcm_data'></span>

<h3>Description</h3>

<p>This function is only used to test the accuracy and processing time of this algorithm. It inputs a list of responding matrices and return the federated gpcm parameters.
Note: This function can only calculate one combined dataset. To use federated gpcm in distributed datasets, please use fedirt_gpcm().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fedirt_gpcm_data(inputdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fedirt_gpcm_data_+3A_inputdata">inputdata</code></td>
<td>
<p>A List of all responding matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input is a List of responding matrices from each school, every responding matrix is one site's data.
</p>


<h3>Value</h3>

<p>A list with the estimated global discrimination a, global difficulty b, person's abilities ability, sites' abilities site, and log-likelihood value loglik.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
inputdata = list(as.matrix(example_data_graded))
fedresult = fedirt_gpcm_data(inputdata)

inputdata = list(as.matrix(example_data_graded_and_binary))
fedresult = fedirt_gpcm_data(inputdata)

</code></pre>

<hr>
<h2 id='g_logL'>Gradient of Log-Likelihood for the federated 2PL Model</h2><span id='topic+g_logL'></span>

<h3>Description</h3>

<p>Calculates the gradients of the log-likelihood function with respect to the item discrimination (a) and difficulty (b) parameters for the Two-Parameter Logistic (2PL) Item Response Theory (IRT) model. This computation is vital for optimizing the item parameters via gradient-based optimization algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_logL(a, b, data, q = 21, lower_bound = -3, upper_bound = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_logL_+3A_a">a</code></td>
<td>
<p>Numeric vector of item discrimination parameters in the 2PL model.</p>
</td></tr>
<tr><td><code id="g_logL_+3A_b">b</code></td>
<td>
<p>Numeric vector of item difficulty parameters in the 2PL model.</p>
</td></tr>
<tr><td><code id="g_logL_+3A_data">data</code></td>
<td>
<p>The matrix of observed item responses, with individuals in rows and items in columns.</p>
</td></tr>
<tr><td><code id="g_logL_+3A_q">q</code></td>
<td>
<p>The number of Gaussian quadrature points for numerical integration (default is 21).</p>
</td></tr>
<tr><td><code id="g_logL_+3A_lower_bound">lower_bound</code></td>
<td>
<p>The lower bound for Gaussian quadrature integration (default is -3).</p>
</td></tr>
<tr><td><code id="g_logL_+3A_upper_bound">upper_bound</code></td>
<td>
<p>The upper bound for Gaussian quadrature integration (default is 3).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function approximates the partial derivatives by utilizing Gaussian quadrature for numerical integration. Memoization techniques are used to cache intermediate results, which is crucial for efficient computation because it avoids redundant calculations. This can significantly speed up iterative algorithms, particularly in the context of large datasets.
</p>
<p>The partial gradient for each parameter is:
</p>
<p style="text-align: center;"><code class="reqn"> \frac{ \partial l_k}  { \partial \alpha_j } = \sum\limits_{n=1}^{q} \sum\limits_{i=1}^{N_k} (V_{ik}(n) - \beta_j) [ r_{ijnk} - m_{ink} P_j(V_{ik}(n))] </code>
</p>

<p style="text-align: center;"><code class="reqn"> \frac{ \partial l_k}  { \partial \beta_j } = (-\alpha_j)\sum\limits_{n=1}^{q} \sum\limits_{i=1}^{N_k} [ r_{ijnk} - m_{ink} P_j(V_{ik}(n))] </code>
</p>



<h3>Value</h3>

<p>A list containing two elements: the gradient vector with respect to item discrimination parameters ('a') and the gradient vector with respect to item difficulty parameters ('b').
</p>

<hr>
<h2 id='g_logL_entry'>Aggregated Gradient of Log-Likelihood for Federated Learning</h2><span id='topic+g_logL_entry'></span>

<h3>Description</h3>

<p>Calculates the sum of the gradients of the log-likelihood with respect to item discrimination (a) and difficulty (b) parameters across all schools participating in a federated learning process. The function <code>g_logL_entry</code> is a critical component in the gradient-based optimization process within <code>fedirt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_logL_entry(ps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_logL_entry_+3A_ps">ps</code></td>
<td>
<p>A numeric vector including the model's current estimates for the item parameters, organized consecutively with discrimination parameters followed by difficulty parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function aggregates the gradients computed locally at each school. The cumulative gradient is then used in the optimization algorithm to update the model parameters. Each school should implement the function <code>get_g_logL_from_index</code> which computes the gradients of log-likelihood locally. This function needs to be aligned with the federated learning framework, typically involving network communication to retrieve the gradient information.
</p>
<p>In simplified scenarios, or during initial testing and development, users can substitute the network communication with a direct call to a local <code>g_logL</code> function that computes the gradient of log-likelihood.
</p>


<h3>Value</h3>

<p>A matrix where the first half of rows corresponds to the aggregated gradient with respect to item discrimination parameters and the second half corresponds to the aggregated gradient with respect to item difficulty parameters.
</p>

<hr>
<h2 id='g_logL_gpcm'>Gradient of Log-Likelihood for the federated graded Model</h2><span id='topic+g_logL_gpcm'></span>

<h3>Description</h3>

<p>Calculates the gradients of the log-likelihood function with respect to the item discrimination (a) and difficulty (b) parameters for the graded IRT model. This computation is vital for optimizing the item parameters via gradient-based optimization algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g_logL_gpcm(a, b, data, q = 21, lower_bound = -3, upper_bound = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g_logL_gpcm_+3A_a">a</code></td>
<td>
<p>Numeric vector of item discrimination parameters in the graded model.</p>
</td></tr>
<tr><td><code id="g_logL_gpcm_+3A_b">b</code></td>
<td>
<p>Numeric vector of item difficulty parameters in the graded model.</p>
</td></tr>
<tr><td><code id="g_logL_gpcm_+3A_data">data</code></td>
<td>
<p>The matrix of observed item responses, with individuals in rows and items in columns.</p>
</td></tr>
<tr><td><code id="g_logL_gpcm_+3A_q">q</code></td>
<td>
<p>The number of Gaussian quadrature points for numerical integration (default is 21).</p>
</td></tr>
<tr><td><code id="g_logL_gpcm_+3A_lower_bound">lower_bound</code></td>
<td>
<p>The lower bound for Gaussian quadrature integration (default is -3).</p>
</td></tr>
<tr><td><code id="g_logL_gpcm_+3A_upper_bound">upper_bound</code></td>
<td>
<p>The upper bound for Gaussian quadrature integration (default is 3).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function approximates the partial derivatives by utilizing Gaussian quadrature for numerical integration. Memoization techniques are used to cache intermediate results, which is crucial for efficient computation because it avoids redundant calculations. This can significantly speed up iterative algorithms, particularly in the context of large datasets.
</p>


<h3>Value</h3>

<p>A list containing two elements: the gradient vector with respect to item discrimination parameters ('a') and the gradient vector with respect to item difficulty parameters ('b').
</p>

<hr>
<h2 id='logL'>Log-Likelihood of the federated 2PL Model</h2><span id='topic+logL'></span>

<h3>Description</h3>

<p>Computes the log-likelihood of the Two-Parameter Logistic (2PL) IRT model given item parameters and response data. The computation utilizes numerical integration and is optimized through memoization for repeated evaluations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logL(a, b, data, q = 21, lower_bound = -3, upper_bound = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logL_+3A_a">a</code></td>
<td>
<p>The vector of item discrimination parameters in the 2PL model.</p>
</td></tr>
<tr><td><code id="logL_+3A_b">b</code></td>
<td>
<p>The vector of item difficulty parameters in the 2PL model.</p>
</td></tr>
<tr><td><code id="logL_+3A_data">data</code></td>
<td>
<p>The matrix of observed responses, with individuals in rows and items in columns.</p>
</td></tr>
<tr><td><code id="logL_+3A_q">q</code></td>
<td>
<p>The number of Gaussian quadrature points to use for numerical integration (default is 21). Gaussian quadrature is a numerical integration technique to approximate the integral of a function, and is particularly useful for accurate and efficient computation.</p>
</td></tr>
<tr><td><code id="logL_+3A_lower_bound">lower_bound</code></td>
<td>
<p>The lower limit for the Gaussian quadrature integration (default is -3).</p>
</td></tr>
<tr><td><code id="logL_+3A_upper_bound">upper_bound</code></td>
<td>
<p>The upper limit for the Gaussian quadrature integration (default is 3).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs numerical integration over a set of quadrature points to calculate the probabilities of the observed responses under the 2PL model, considering the item discrimination (a) and difficulty (b) parameters. Memoization is used to cache computed values of the probabilities, logits, and log-likelihoods to avoid redundant calculations and speed up the process.
</p>


<h3>Value</h3>

<p>The computed log-likelihood of the 2PL model as a single numeric value.
</p>

<hr>
<h2 id='logL_entry'>Aggregate Log-Likelihood Function for Federated Learning</h2><span id='topic+logL_entry'></span>

<h3>Description</h3>

<p>Computes the sum of log-likelihoods across multiple schools in a federated learning setting. The function <code>logL_entry</code> aggregates contribution of each school's log-likelihood to the overall model. It is designed to be used within the optimization process of <code>fedirt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logL_entry(ps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logL_entry_+3A_ps">ps</code></td>
<td>
<p>A parameter vector consisting of item parameters; it should include both discrimination (a) and difficulty (b) parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a federated learning context, each school computes its log-likelihood locally. The <code>logL_entry</code> function is responsible for aggregating these values. Users are expected to provide an implementation for <code>getlogL_from_index</code>, which should include network requests to retrieve log-likelihoods calculated by each school, or for simplified prototyping purposes, could directly use a <code>logL</code> function to compute likelihoods locally.
</p>


<h3>Value</h3>

<p>The sum of log-likelihoods as a single numeric value, representing the likelihood of the entire federated dataset under the current model's parameters.
</p>

<hr>
<h2 id='logL_gpcm'>Log-Likelihood of the federated graded Model</h2><span id='topic+logL_gpcm'></span>

<h3>Description</h3>

<p>Computes the log-likelihood of the graded IRT model given item parameters and response data. The computation utilizes numerical integration and is optimized through memoization for repeated evaluations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logL_gpcm(a, b, data, q = 21, lower_bound = -3, upper_bound = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logL_gpcm_+3A_a">a</code></td>
<td>
<p>The vector of item discrimination parameters in the graded model.</p>
</td></tr>
<tr><td><code id="logL_gpcm_+3A_b">b</code></td>
<td>
<p>The vector of item difficulty parameters in the graded model.</p>
</td></tr>
<tr><td><code id="logL_gpcm_+3A_data">data</code></td>
<td>
<p>The matrix of observed responses, with individuals in rows and items in columns.</p>
</td></tr>
<tr><td><code id="logL_gpcm_+3A_q">q</code></td>
<td>
<p>The number of Gaussian quadrature points to use for numerical integration (default is 21). Gaussian quadrature is a numerical integration technique to approximate the integral of a function, and is particularly useful for accurate and efficient computation.</p>
</td></tr>
<tr><td><code id="logL_gpcm_+3A_lower_bound">lower_bound</code></td>
<td>
<p>The lower limit for the Gaussian quadrature integration (default is -3).</p>
</td></tr>
<tr><td><code id="logL_gpcm_+3A_upper_bound">upper_bound</code></td>
<td>
<p>The upper limit for the Gaussian quadrature integration (default is 3).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs numerical integration over a set of quadrature points to calculate the probabilities of the observed responses under the graded model, considering the item discrimination (a) and difficulty (b) parameters. Memoization is used to cache computed values of the probabilities, logits, and log-likelihoods to avoid redundant calculations and speed up the process.
</p>


<h3>Value</h3>

<p>The computed log-likelihood of the graded model as a single numeric value.
</p>

<hr>
<h2 id='memoize'>Memoization Function for Speed Optimization</h2><span id='topic+memoize'></span>

<h3>Description</h3>

<p>A simple memoization function that stores the results of expensive function calls and reuses those results when the same inputs occur again. This technique greatly speeds up the computation of <code>fedirt</code> function by caching previously computed values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>memoize(f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="memoize_+3A_f">f</code></td>
<td>
<p>Function to be memoized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a memoized version of function <code>f</code> that will cache its previously computed results for faster subsequent evaluations, especially beneficial when applied to <code>fedirt</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To memoize a function, simply wrap it with `memoize`:
memoize(function(a,b){return(a+b)})
</code></pre>

<hr>
<h2 id='runclient'>Client for Federated IRT Model Estimation</h2><span id='topic+runclient'></span>

<h3>Description</h3>

<p>Initializes a client interface for the federated learning estimation of Item Response Theory (IRT) model parameters, connecting to a central server to participate in collaborative parameter estimation. It is essential to start the server prior to the client to ensure the client can establish a successful connection, otherwise an error will occur.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runclient()
</code></pre>


<h3>Details</h3>

<p>The client interface, built with Shiny, provides an interactive platform that enables users to upload response matrix data in CSV format, connect to a central server, and receive the estimation results once the computation is complete. The client sends computed local statistics or partial results to the server, which then aggregates information from all clients to update the global IRT model parameters. Users can input the server's IP address and port number, reconnect if needed, and visualize the computed item and ability parameters through plots and tables displayed in the interface.
</p>
<p>The client is capable of uploading data, processing it locally to compute log-likelihood or gradient information, and sending these details to the server based on HTTP POST requests. The client also includes functionality to handle responses from the server, either to signal the status of the connection or to receive and display results of the federated estimation process. Through this interactive client-server architecture, the federated IRT model estimation becomes a seamless process, allowing participants to contribute computational resources while preserving data privacy within their local environments.
</p>
<p>Additional client functions include local IP retrieval for network communication, server connection initiation, response data processing, and result visualization. Interactive components built in Shiny enable a smooth user experience and real-time updates, making the client an integral part of the federated IRT model estimation framework.
</p>


<h3>Value</h3>

<p>shows the discriminations and difficulties of each item and plot them. Also displays each students' abilities.
</p>


<h3>Note</h3>

<p>This shiny app should be used together with server version. Run server before run client, and get the correct address from server interface to initialize the estimating process.
</p>

<hr>
<h2 id='runserver'>Server for Federated IRT Model Estimation</h2><span id='topic+runserver'></span>

<h3>Description</h3>

<p>Launches a server that handles federated learning across multiple schools or institutions for the estimation of Item Response Theory (IRT) model parameters. This server facilitates communication between the central aggregator and distributed data sources, coordinating the data sharing process while maintaining privacy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runserver()
</code></pre>


<h3>Details</h3>

<p>The server establishes a federated learning environment where each participating entity (school) computes parts of the model locally. The server then collects summary statistics from each entity and uses them to update the global model parameters. It features a user interface for initiating the estimation process and for displaying the results of the federated learning procedure. The user interface provides real-time information about the connected schools, data consistency checks, and the mode of the IRT model being estimated (binary or graded).
</p>
<p>Function 'updateM' checks for consistency in the number of maximum item levels across all schools, setting a flag to indicate whether a binary or graded model should be used. Function 'check_J' ensures that all schools have a consistent number of items in their datasets. The 'ui' function serves as the user interface for the server, while 'getLocalIP' retrieves the server's IP address for connections. Finally, the 'server' function contains the logic for receiving data from schools, triggering the estimation process, and sending the results back to participating schools.
</p>
<p>Overall, the 'runserver' function orchestrates the federated IRT model estimation process by combining local computations from schools, managing data traffic, executing the appropriate estimation function, and providing users with an interactive web interface.
</p>
<p>The web interface is built using Shiny, allowing users to check connection statuses, start the estimation process, and view results. It supports both GET and POST HTTP methods for handling data exchange with clients. The server is designed to be flexible and can be adapted for various federated learning scenarios in the education sector.
</p>


<h3>Value</h3>

<p>No return value, called for side effects (initiates interactive Shiny server session) and display estimates on the interface.
</p>


<h3>Note</h3>

<p>This shiny app should be used together with client version.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
