<!DOCTYPE html><html><head><title>Help for package copent</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {copent}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ci'><p> Conditional independence test with copula entropy</p></a></li>
<li><a href='#construct_empirical_copula'><p> Construct empirical copula by rank statistic</p></a></li>
<li><a href='#copent'><p> Estimating copula entropy</p></a></li>
<li><a href='#entknn'><p> Estimating entropy from data with kNN method</p></a></li>
<li><a href='#mvnt'><p> Multivariate normality test with copula entropy</p></a></li>
<li><a href='#transent'><p> Estimating transfer entropy via copula entropy</p></a></li>
<li><a href='#tst'><p> Two-sample test with copula entropy</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-05</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimating Copula Entropy and Transfer Entropy</td>
</tr>
<tr>
<td>Author:</td>
<td>MA Jian [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>MA Jian &lt;majian03@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.7.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mnormt</td>
</tr>
<tr>
<td>Description:</td>
<td>The nonparametric methods for estimating copula entropy, transfer entropy, and the statistics for multivariate normality test and two-sample test are implemented. The methods for estimating transfer entropy and the statistics for multivariate normality test and two-sample test are based on the method for estimating copula entropy. Please refer to Ma and Sun (2011) &lt;<a href="https://doi.org/10.1016%2FS1007-0214%2811%2970008-6">doi:10.1016/S1007-0214(11)70008-6</a>&gt;, Ma (2019) &lt;<a href="https://doi.org/10.48550/arXiv.1910.04375">doi:10.48550/arXiv.1910.04375</a>&gt;, Ma (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2206.05956">doi:10.48550/arXiv.2206.05956</a>&gt;, and Ma (2023) &lt;<a href="https://doi.org/10.48550/arXiv.2307.07247">doi:10.48550/arXiv.2307.07247</a>&gt; for more information.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/majianthu/copent">https://github.com/majianthu/copent</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-12 00:01:48 UTC; majian</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-12 03:50:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='ci'> Conditional independence test with copula entropy </h2><span id='topic+ci'></span>

<h3>Description</h3>

<p>Testing conditional independence between (x,y) conditional on z with copula entropy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci(x,y,z,k=3,dt=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_+3A_x">x</code></td>
<td>
<p> the data with 1 row.</p>
</td></tr>
<tr><td><code id="ci_+3A_y">y</code></td>
<td>
<p> the data with 1 row.</p>
</td></tr>
<tr><td><code id="ci_+3A_z">z</code></td>
<td>
<p> the data with 1 row.</p>
</td></tr>
<tr><td><code id="ci_+3A_k">k</code></td>
<td>
<p> kth nearest neighbour, default = 3.</p>
</td></tr>
<tr><td><code id="ci_+3A_dt">dt</code></td>
<td>
<p> the type of distance between samples, 1 for Eclidean distance; 2 for Maximum distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves testing conditional independence between (<b>x,y</b>) conditional on <b>z</b> with copula entropy nonparametrically. It was proposed in Ma (2019). 
</p>
<p>The algorithm composes of two simple steps: estimating three copula entropy terms with <code><a href="#topic+copent">copent</a></code> and then calculate the test statistic.
</p>
<p>The argument <b>x,y,z</b> are for the data with 1 row and same length as samples from random variables. The argument <b>k</b> and <b>dt</b> is used in the kNN method for estimating entropy. <b>k</b> is for the kth nearest neighbour (default = 3) and <b>dt</b> is for the type of distance between samples which has currently two value options (1 for Eclidean distance, and 2(default) for Maximum distance).
</p>


<h3>Value</h3>

<p>The function returns the value of the test statistic of conditional independence.
</p>


<h3>References</h3>

 
<p>Ma, Jian. Estimating Transfer Entropy via Copula Entropy. arXiv preprint arXiv:1910.04375, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(copent)
library(mnormt)
rho1 &lt;- 0.5
rho2 &lt;- 0.6
rho3 &lt;- 0.5
sigma &lt;- matrix(c(1,rho1,rho2,rho1,1,rho3,rho2,rho3,1),3,3)
x &lt;- rmnorm(500,c(0,0,0),sigma)
ci1 &lt;- ci(x[,1],x[,2],x[,3])

</code></pre>

<hr>
<h2 id='construct_empirical_copula'> Construct empirical copula by rank statistic </h2><span id='topic+construct_empirical_copula'></span>

<h3>Description</h3>

<p>Construct empirical copula by rank statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>construct_empirical_copula(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="construct_empirical_copula_+3A_x">x</code></td>
<td>
<p> the data with each row as a sample.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves estimating empirical copula from data by rank statistic nonparametrically. It was proposed in Ma and Sun (2008, 2011). The algorithm is the first step of estimating copula entropy <code><a href="#topic+copent">copent</a></code>.
</p>
<p>The argument <b>x</b> is for the data with each row as a sample from random variables. 
</p>


<h3>Value</h3>

<p>The function returns the estimated empirical copula of data <b>x</b>.
</p>


<h3>References</h3>

 
<p>Ma, J., &amp; Sun, Z. (2011). Mutual information is copula entropy. <em>Tsinghua Science &amp; Technology</em>, <b>16</b>(1): 51-54. See also <em>ArXiv preprint</em>, arXiv: 0808.0845, 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mnormt)
rho &lt;- 0.5
sigma &lt;- matrix(c(1,rho,rho,1),2,2)
x &lt;- rmnorm(500,c(0,0),sigma)
xc1 &lt;- construct_empirical_copula(x)

</code></pre>

<hr>
<h2 id='copent'> Estimating copula entropy </h2><span id='topic+copent'></span>

<h3>Description</h3>

<p>Estimating copula entropy nonparametrically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copent(x,k=3,dt=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="copent_+3A_x">x</code></td>
<td>
<p> the data with each row as a sample.</p>
</td></tr>
<tr><td><code id="copent_+3A_k">k</code></td>
<td>
<p> kth nearest neighbour, default = 3.</p>
</td></tr>
<tr><td><code id="copent_+3A_dt">dt</code></td>
<td>
<p> the type of distance between samples, 1 for Eclidean distance; 2 for Maximum distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves estimating copula entropy from data nonparametrically. It was proposed in Ma and Sun (2008, 2011). 
</p>
<p>The algorithm composes of two simple steps: estimating empirical copula by rank statistic using <code><a href="#topic+construct_empirical_copula">construct_empirical_copula</a></code> and then estimating copula entropy with kNN method using <code><a href="#topic+entknn">entknn</a></code> proposed in Kraskov et al (2004).
</p>
<p>The argument <b>x</b> is for the data with each row as a sample from random variables. The argument <b>k</b> and <b>dt</b> is used in the kNN method for estimating entropy. <b>k</b> is for the kth nearest neighbour (default = 3) and <b>dt</b> is for the type of distance between samples which has currently two value options (1 for Eclidean distance, and 2(default) for Maximum distance).
</p>
<p>Copula Entropy is proved to be equivalent to negative mutual information so this program can also be used to estimate multivariate mutual information.
</p>


<h3>Value</h3>

<p>The function returns <em>negative</em> value of copula entropy of data <b>x</b>.
</p>


<h3>References</h3>

 
<p>Ma, J., &amp; Sun, Z. (2011). Mutual information is copula entropy. <em>Tsinghua Science &amp; Technology</em>, <b>16</b>(1): 51-54. See also arXiv preprint arXiv:0808.0845, 2008.
</p>
<p>Kraskov, A., St\&quot;ogbauer, H., &amp; Grassberger, P. (2004). Estimating Mutual Information. <em>Physical Review E</em>, <b>69</b>(6), 66138.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mnormt)
rho &lt;- 0.5
sigma &lt;- matrix(c(1,rho,rho,1),2,2)
x &lt;- rmnorm(500,c(0,0),sigma)
ce1 &lt;- copent(x,3,2)

</code></pre>

<hr>
<h2 id='entknn'> Estimating entropy from data with kNN method </h2><span id='topic+entknn'></span>

<h3>Description</h3>

<p>Estimating entropy from data with kNN method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entknn(x,k=3,dt=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="entknn_+3A_x">x</code></td>
<td>
<p> the data with each row as a sample.</p>
</td></tr>
<tr><td><code id="entknn_+3A_k">k</code></td>
<td>
<p> kth nearest neighbour, default = 3.</p>
</td></tr>
<tr><td><code id="entknn_+3A_dt">dt</code></td>
<td>
<p> the type of distance between samples, = 1 for Eclidean distance; other for Maximum distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves estimating entropy from data by kNN method. It was proposed in Kraskov et al (2004). The algorithm is the second step of estimating copula entropy <code><a href="#topic+copent">copent</a></code>. 
</p>
<p>The argument <b>x</b> is for the data with each row as a sample from random variables. The argument <b>k</b> and <b>dt</b> is used in the kNN method for estimating entropy. <b>k</b> is for the kth nearest neighbour (default = 3) and <b>dt</b> is for the type of distance between samples which has currently two value options (1 for Eclidean distance, and 2(default) for Maximum distance).
</p>


<h3>Value</h3>

<p>The function returns the estimated entropy value of data <b>x</b>.
</p>


<h3>References</h3>

 
<p>Kraskov, A., St\&quot;ogbauer, H., &amp; Grassberger, P. (2004). Estimating Mutual Information. <em>Physical Review E</em>, <b>69</b>(6), 66138.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mnormt)
rho &lt;- 0.5
sigma &lt;- matrix(c(1,rho,rho,1),2,2)
x &lt;- rmnorm(500,c(0,0),sigma)
xent1 &lt;- entknn(x)

</code></pre>

<hr>
<h2 id='mvnt'> Multivariate normality test with copula entropy </h2><span id='topic+mvnt'></span>

<h3>Description</h3>

<p>Estimating the statistic for testing multivariate normality based on copula entropy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnt(x,k=3,dt=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnt_+3A_x">x</code></td>
<td>
<p> the data with each row as a sample of d-dimensional random variables.</p>
</td></tr>
<tr><td><code id="mvnt_+3A_k">k</code></td>
<td>
<p> kth nearest neighbour, default = 3.</p>
</td></tr>
<tr><td><code id="mvnt_+3A_dt">dt</code></td>
<td>
<p> the type of distance between samples, 1 for Eclidean distance; 2 for Maximum distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves estimating the statistic for testing multivariate normality based on copula entropy. It was proposed in Ma (2022). The test statistic is defined as the difference between the
copula entropies of unknown distribution and the Gaussian distribution with same covariance.
</p>
<p>The argument <b>x</b> is for the data with each row as a sample of d-dimensional random variables. The argument <b>k</b> and <b>dt</b> is used in the kNN method for estimating entropy. <b>k</b> is for the kth nearest neighbour (default = 3) and <b>dt</b> is for the type of distance between samples which has currently two value options (1 for Eclidean distance, and 2(default) for Maximum distance).
</p>


<h3>Value</h3>

<p>The function returns the statistic for testing multivariate normality of <b>x</b>.
</p>


<h3>References</h3>

 
<p>Ma, Jian. Multivariate Normality Test with Copula Entropy. arXiv preprint arXiv:2206.05956, 2022.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mnormt)
rho &lt;- 0.5
sigma &lt;- matrix(c(1,rho,rho,1),2,2)
x &lt;- rmnorm(1000,c(0,0),sigma)
mvnt(x)

</code></pre>

<hr>
<h2 id='transent'> Estimating transfer entropy via copula entropy </h2><span id='topic+transent'></span>

<h3>Description</h3>

<p>Estimating transfer entropy via copula entropy nonparametrically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transent(x,y,lag=1,k=3,dt=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transent_+3A_x">x</code></td>
<td>
<p> the data with 1 row.</p>
</td></tr>
<tr><td><code id="transent_+3A_y">y</code></td>
<td>
<p> the data with 1 row.</p>
</td></tr>
<tr><td><code id="transent_+3A_lag">lag</code></td>
<td>
<p> time lag, &gt;0</p>
</td></tr>
<tr><td><code id="transent_+3A_k">k</code></td>
<td>
<p> kth nearest neighbour, default = 3.</p>
</td></tr>
<tr><td><code id="transent_+3A_dt">dt</code></td>
<td>
<p> the type of distance between samples, 1 for Eclidean distance; 2 for Maximum distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves estimating transfer entropy from <b>y</b> to <b>x</b> with time lag <b>lag</b> via copula entropy nonparametrically. It was proposed in Ma (2019). 
</p>
<p>The algorithm first prepare the data according to <b>lag</b>, and then call <code><a href="#topic+ci">ci</a></code> for conditional independence testing.
</p>
<p>The argument <b>x,y</b> are for the data with 1 row as samples from random variables. The argument <b>lag</b> is for time lag. The argument <b>k</b> and <b>dt</b> is used in the kNN method for estimating entropy. <b>k</b> is for the kth nearest neighbour (default = 3) and <b>dt</b> is for the type of distance between samples which has currently two value options (1 for Eclidean distance, and 2(default) for Maximum distance).
</p>


<h3>Value</h3>

<p>The function returns the value of transfer entropy from <b>y</b> to <b>x</b> with time lag <b>lag</b>.
</p>


<h3>References</h3>

 
<p>Ma, Jian. Estimating Transfer Entropy via Copula Entropy. arXiv preprint arXiv:1910.04375, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(copent)
num = 300
x = rnorm(num)
y = rnorm(num)
transent(y,x,2)

</code></pre>

<hr>
<h2 id='tst'> Two-sample test with copula entropy </h2><span id='topic+tst'></span>

<h3>Description</h3>

<p>Estimating the statistic for two-sample test based on copula entropy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tst(s0,s1,n=12,k=3,dt=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tst_+3A_s0">s0</code>, <code id="tst_+3A_s1">s1</code></td>
<td>
<p> two samples with each row as a sample of d-dimensional random variables.</p>
</td></tr>
<tr><td><code id="tst_+3A_n">n</code></td>
<td>
<p> repeat time of estimation to reduce estimation bias.</p>
</td></tr>
<tr><td><code id="tst_+3A_k">k</code></td>
<td>
<p> kth nearest neighbour, default = 3.</p>
</td></tr>
<tr><td><code id="tst_+3A_dt">dt</code></td>
<td>
<p> the type of distance between samples, 1 for Eclidean distance; 2 for Maximum distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This program involves estimating the statistic for non-parametric multivariate two-sample test based on copula entropy. It was proposed in Ma (2023). The test statistic is defined as the difference between the copula entropies of the null hypothesis and the alternative of two-sample test.
</p>
<p>The argument <b>s0,s1</b> is for the two samples with each row as a sample of d-dimensional random variables. The argument <b>n</b> is the repeat time of estimation for reducing the estimation bias (dafault = 12). The argument <b>k</b> and <b>dt</b> is used in the kNN method for estimating entropy. <b>k</b> is for the kth nearest neighbour (default = 3) and <b>dt</b> is for the type of distance between samples which has currently two value options (1 for Eclidean distance, and 2(default) for Maximum distance).
</p>


<h3>Value</h3>

<p>The function returns the statistic for two-sample test on <b>s0,s1</b>.
</p>


<h3>References</h3>

 
<p>Ma, Jian. Two-Sample Test with Copula Entropy. arXiv preprint arXiv:2307.07247, 2023.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mnormt)
rho &lt;- 0.5
sigma &lt;- matrix(c(1,rho,rho,1),2,2)
s0 &lt;- rmnorm(400,c(0,0),sigma)
s1 &lt;- rmnorm(500,c(5,5),sigma)
tst(s0,s1)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
