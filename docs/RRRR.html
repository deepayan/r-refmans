<!DOCTYPE html><html lang="en-AU"><head><title>Help for package RRRR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RRRR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RRRR-package'><p>Online Robust Reduced-Rank Regression Estimation</p></a></li>
<li><a href='#ORRRR'><p>Online Robust Reduced-Rank Regression</p></a></li>
<li><a href='#plot.RRRR'><p>Plot Objective value of a Robust Reduced-Rank Regression</p></a></li>
<li><a href='#RRR'><p>Reduced-Rank Regression using Gaussian MLE</p></a></li>
<li><a href='#RRR_sim'><p>Simulating data for Reduced-Rank Regression</p></a></li>
<li><a href='#RRRR'><p>Robust Reduced-Rank Regression using Majorisation-Minimisation</p></a></li>
<li><a href='#update.RRRR'><p>Update the RRRR/ORRRR type model with addition data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Online Robust Reduced-Rank Regression Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for estimating online robust reduced-rank regression. 
    The Gaussian maximum likelihood estimation method is described in Johansen, S. (1991) &lt;<a href="https://doi.org/10.2307%2F2938278">doi:10.2307/2938278</a>&gt;.
    The majorisation-minimisation estimation method is partly described in Zhao, Z., &amp; Palomar, D. P. (2017) &lt;<a href="https://doi.org/10.1109%2FGlobalSIP.2017.8309093">doi:10.1109/GlobalSIP.2017.8309093</a>&gt;.
    The description of the generic stochastic successive upper-bound minimisation method
    and the sample average approximation can be found in Razaviyayn, M., Sanjabi, M., &amp; Luo, Z. Q. (2016) &lt;<a href="https://doi.org/10.1007%2Fs10107-016-1021-7">doi:10.1007/s10107-016-1021-7</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://pkg.yangzhuoranyang.com/RRRR/">https://pkg.yangzhuoranyang.com/RRRR/</a>,
<a href="https://github.com/FinYang/RRRR">https://github.com/FinYang/RRRR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/FinYang/RRRR/issues/">https://github.com/FinYang/RRRR/issues/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>matrixcalc, expm, ggplot2, magrittr, mvtnorm, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lazybar, knitr, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-AU</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-24 03:52:12 UTC; fyan0012</td>
</tr>
<tr>
<td>Author:</td>
<td>Yangzhuoran Fin Yang
    <a href="https://orcid.org/0000-0002-1232-8017"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Ziping Zhao <a href="https://orcid.org/0000-0002-8668-6263"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yangzhuoran Fin Yang &lt;yangyangzhuoran@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-24 09:02:29 UTC</td>
</tr>
</table>
<hr>
<h2 id='RRRR-package'>Online Robust Reduced-Rank Regression Estimation</h2><span id='topic+RRRR-package'></span>

<h3>Description</h3>

<p>Methods for estimating online Robust Reduced-Rank Regression.
</p>


<h3>Author(s)</h3>

<p>Yangzhuoran Yang. <a href="mailto:yangyangzhuoran@gmail.com">yangyangzhuoran@gmail.com</a>
</p>
<p>Ziping Zhao. <a href="mailto:zhaoziping@shanghaitech.edu.cn">zhaoziping@shanghaitech.edu.cn</a>
</p>

<hr>
<h2 id='ORRRR'>Online Robust Reduced-Rank Regression</h2><span id='topic+ORRRR'></span>

<h3>Description</h3>

<p>Online robust reduced-rank regression with two major estimation methods:
</p>

<dl>
<dt>SMM</dt><dd><p>Stochastic Majorisation-Minimisation</p>
</dd>
<dt>SAA</dt><dd><p>Sample Average Approximation</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>ORRRR(
  y,
  x,
  z = NULL,
  mu = TRUE,
  r = 1,
  initial_size = 100,
  addon = 10,
  method = c("SMM", "SAA"),
  SAAmethod = c("optim", "MM"),
  ...,
  initial_A = matrix(rnorm(P * r), ncol = r),
  initial_B = matrix(rnorm(Q * r), ncol = r),
  initial_D = matrix(rnorm(P * R), ncol = R),
  initial_mu = matrix(rnorm(P)),
  initial_Sigma = diag(P),
  ProgressBar = requireNamespace("lazybar"),
  return_data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ORRRR_+3A_y">y</code></td>
<td>
<p>Matrix of dimension N*P. The matrix for the response variables. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_x">x</code></td>
<td>
<p>Matrix of dimension N*Q. The matrix for the explanatory variables to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_z">z</code></td>
<td>
<p>Matrix of dimension N*R. The matrix for the explanatory variables not to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_mu">mu</code></td>
<td>
<p>Logical. Indicating if a constant term is included.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_r">r</code></td>
<td>
<p>Integer. The rank for the reduced-rank matrix <code class="reqn">AB'</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_initial_size">initial_size</code></td>
<td>
<p>Integer. The number of data points to be used in the first iteration.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_addon">addon</code></td>
<td>
<p>Integer. The number of data points to be added in the algorithm in each iteration after the first.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_method">method</code></td>
<td>
<p>Character. The estimation method. Either &quot;SMM&quot; or &quot;SAA&quot;. See <code>Description</code> and <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_saamethod">SAAmethod</code></td>
<td>
<p>Character. The sub solver used in each iteration when the <code>method</code> is chosen to be &quot;SAA&quot;. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_...">...</code></td>
<td>
<p>Additional arguments to function
</p>

<dl>
<dt><code>optim</code></dt><dd><p>when the <code>method</code> is &quot;SAA&quot; and the <code>SAAmethod</code> is &quot;optim&quot;</p>
</dd>
<dt><code>RRRR</code></dt><dd><p>when the <code>method</code> is &quot;SAA&quot; and the <code>SAAmethod</code> is &quot;MM&quot;</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="ORRRR_+3A_initial_a">initial_A</code></td>
<td>
<p>Matrix of dimension P*r. The initial value for matrix <code class="reqn">A</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_initial_b">initial_B</code></td>
<td>
<p>Matrix of dimension Q*r. The initial value for matrix <code class="reqn">B</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_initial_d">initial_D</code></td>
<td>
<p>Matrix of dimension P*R. The initial value for matrix <code class="reqn">D</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_initial_mu">initial_mu</code></td>
<td>
<p>Matrix of dimension P*1. The initial value for the constant <code class="reqn">mu</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_initial_sigma">initial_Sigma</code></td>
<td>
<p>Matrix of dimension P*P. The initial value for matrix Sigma. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_progressbar">ProgressBar</code></td>
<td>
<p>Logical. Indicating if a progress bar is shown during the estimation process.
The progress bar requires package <code>lazybar</code> to work.</p>
</td></tr>
<tr><td><code id="ORRRR_+3A_return_data">return_data</code></td>
<td>
<p>Logical. Indicating if the data used is return in the output.
If set to <code>TRUE</code>, <code>update.RRRR</code> can update the model by simply provide new data.
Set to <code>FALSE</code> to save output size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formulation of the reduced-rank regression is as follow:
</p>
<p style="text-align: center;"><code class="reqn">y = \mu +AB'  x + D z+innov,</code>
</p>

<p>where for each realization <code class="reqn">y</code> is a vector of dimension <code class="reqn">P</code> for the <code class="reqn">P</code> response variables,
<code class="reqn">x</code> is a vector of dimension <code class="reqn">Q</code> for the <code class="reqn">Q</code> explanatory variables that will be projected to
reduce the rank,
<code class="reqn">z</code> is a vector of dimension <code class="reqn">R</code> for the <code class="reqn">R</code> explanatory variables
that will not be projected,
<code class="reqn">\mu</code> is the constant vector of dimension <code class="reqn">P</code>,
<code class="reqn">innov</code> is the innovation vector of dimension <code class="reqn">P</code>,
<code class="reqn">D</code> is a coefficient matrix for <code class="reqn">z</code> with dimension <code class="reqn">P*R</code>,
<code class="reqn">A</code> is the so called exposure matrix with dimension <code class="reqn">P*r</code>, and
<code class="reqn">B</code> is the so called factor matrix with dimension <code class="reqn">Q*r</code>.
The matrix resulted from <code class="reqn">AB'</code> will be a reduced rank coefficient matrix with rank of <code class="reqn">r</code>.
The function estimates parameters <code class="reqn">\mu</code>, <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">D</code>, and <code class="reqn">Sigma</code>, the covariance matrix of
the innovation's distribution.
</p>
<p>The algorithm is online in the sense that the data is continuously incorporated
and the algorithm can update the parameters accordingly. See <code>?update.RRRR</code> for more details.
</p>
<p>At each iteration of SAA, a new realisation of the parameters is achieved by
solving the minimisation problem of the sample average of
the desired objective function using the data currently incorporated.
This can be computationally expensive when the objective function is highly nonconvex.
The SMM method overcomes this difficulty by replacing the objective function
by a well-chosen majorising surrogate function which can be much easier to optimise.
</p>
<p>SMM method is robust in the sense that it assumes a heavy-tailed Cauchy distribution
for the innovations.
</p>


<h3>Value</h3>

<p>A list of the estimated parameters of class <code>ORRRR</code>.
</p>

<dl>
<dt>method</dt><dd><p>The estimation method being used</p>
</dd>
<dt>SAAmethod</dt><dd><p>If SAA is the major estimation method, what is the sub solver in each iteration.</p>
</dd>
<dt>spec</dt><dd><p>The input specifications. <code class="reqn">N</code> is the sample size.</p>
</dd>
<dt>history</dt><dd><p>The path of all the parameters during optimization and the path of the objective value.</p>
</dd>
<dt>mu</dt><dd><p>The estimated constant vector. Can be <code>NULL</code>.</p>
</dd>
<dt>A</dt><dd><p>The estimated exposure matrix.</p>
</dd>
<dt>B</dt><dd><p>The estimated factor matrix.</p>
</dd>
<dt>D</dt><dd><p>The estimated coefficient matrix of <code>z</code>.</p>
</dd>
<dt>Sigma</dt><dd><p>The estimated covariance matrix of the innovation distribution.</p>
</dd>
<dt>obj</dt><dd><p>The final objective value.</p>
</dd>
<dt>data</dt><dd><p>The data used in estimation if <code>return_data</code> is set to <code>TRUE</code>. <code>NULL</code> otherwise.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yangzhuoran Yang
</p>


<h3>See Also</h3>

<p><code>update.RRRR</code>, <code>RRRR</code>, <code>RRR</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(2222)
data &lt;- RRR_sim()
res &lt;- ORRRR(y=data$y, x=data$x, z = data$z)
res

</code></pre>

<hr>
<h2 id='plot.RRRR'>Plot Objective value of a Robust Reduced-Rank Regression</h2><span id='topic+plot.RRRR'></span>

<h3>Description</h3>

<p>Plot Objective value of a Robust Reduced-Rank Regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RRRR'
plot(x, aes_x = c("iteration", "runtime"), xlog10 = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.RRRR_+3A_x">x</code></td>
<td>
<p>An RRRR object.</p>
</td></tr>
<tr><td><code id="plot.RRRR_+3A_aes_x">aes_x</code></td>
<td>
<p>Either &quot;iteration&quot; or &quot;runtime&quot;. The x axis in the plot.</p>
</td></tr>
<tr><td><code id="plot.RRRR_+3A_xlog10">xlog10</code></td>
<td>
<p>Logical, indicates whether the scale of x axis is log 10 transformed.</p>
</td></tr>
<tr><td><code id="plot.RRRR_+3A_...">...</code></td>
<td>
<p>Additional argument to <code>ggplot2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An ggplot2 object
</p>


<h3>Author(s)</h3>

<p>Yangzhuoran Fin Yang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2222)
data &lt;- RRR_sim()
res &lt;- RRRR(y=data$y, x=data$x, z = data$z)
plot(res)
</code></pre>

<hr>
<h2 id='RRR'>Reduced-Rank Regression using Gaussian MLE</h2><span id='topic+RRR'></span>

<h3>Description</h3>

<p>Gaussian Maximum Likelihood Estimation method for Reduced-Rank Regression.
This method is not robust in the sense that it assumes a Gaussian distribution
for the innovations
which does not take into account the heavy-tailedness of the true distribution and
outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RRR(y, x, z = NULL, mu = TRUE, r = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RRR_+3A_y">y</code></td>
<td>
<p>Matrix of dimension N*P. The matrix for the response variables. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_+3A_x">x</code></td>
<td>
<p>Matrix of dimension N*Q. The matrix for the explanatory variables to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_+3A_z">z</code></td>
<td>
<p>Matrix of dimension N*R. The matrix for the explanatory variables not to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_+3A_mu">mu</code></td>
<td>
<p>Logical. Indicating if a constant term is included.</p>
</td></tr>
<tr><td><code id="RRR_+3A_r">r</code></td>
<td>
<p>Integer. The rank for the reduced-rank matrix <code class="reqn">AB'</code>. See <code>Detail</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formulation of the reduced-rank regression is as follow:
</p>
<p style="text-align: center;"><code class="reqn">y = \mu +AB'  x + D z+innov,</code>
</p>

<p>where for each realization <code class="reqn">y</code> is a vector of dimension <code class="reqn">P</code> for the <code class="reqn">P</code> response variables,
<code class="reqn">x</code> is a vector of dimension <code class="reqn">Q</code> for the <code class="reqn">Q</code> explanatory variables that will be projected to
reduce the rank,
<code class="reqn">z</code> is a vector of dimension <code class="reqn">R</code> for the <code class="reqn">R</code> explanatory variables
that will not be projected,
<code class="reqn">\mu</code> is the constant vector of dimension <code class="reqn">P</code>,
<code class="reqn">innov</code> is the innovation vector of dimension <code class="reqn">P</code>,
<code class="reqn">D</code> is a coefficient matrix for <code class="reqn">z</code> with dimension <code class="reqn">P*R</code>,
<code class="reqn">A</code> is the so called exposure matrix with dimension <code class="reqn">P*r</code>, and
<code class="reqn">B</code> is the so called factor matrix with dimension <code class="reqn">Q*r</code>.
The matrix resulted from <code class="reqn">AB'</code> will be a reduced rank coefficient matrix with rank of <code class="reqn">r</code>.
The function estimates parameters <code class="reqn">\mu</code>, <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">D</code>, and <code class="reqn">Sigma</code>, the covariance matrix of
the innovation's distribution, assuming the innovation has a Gaussian distribution.
</p>


<h3>Value</h3>

<p>A list of the estimated parameters of class <code>RRR</code>.
</p>

<dl>
<dt>spec</dt><dd><p>The input specifications. <code class="reqn">N</code> is the sample size.</p>
</dd>
<dt>mu</dt><dd><p>The estimated constant vector. Can be <code>NULL</code>.</p>
</dd>
<dt>A</dt><dd><p>The estimated exposure matrix.</p>
</dd>
<dt>B</dt><dd><p>The estimated factor matrix.</p>
</dd>
<dt>D</dt><dd><p>The estimated coefficient matrix of <code>z</code>. Can be <code>NULL</code>.</p>
</dd>
<dt>Sigma</dt><dd><p>The estimated covariance matrix of the innovation distribution.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yangzhuoran Yang
</p>


<h3>References</h3>

<p>S. Johansen, &quot;Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models,&quot;Econometrica, vol. 59,p. 1551, Nov. 1991.
</p>


<h3>See Also</h3>

<p>For robust reduced-rank regression estimation see function <code><a href="#topic+RRRR">RRRR</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2222)
data &lt;- RRR_sim()
res &lt;- RRR(y=data$y, x=data$x, z = data$z)
res
</code></pre>

<hr>
<h2 id='RRR_sim'>Simulating data for Reduced-Rank Regression</h2><span id='topic+RRR_sim'></span>

<h3>Description</h3>

<p>Simulate data for Reduced-rank regression. See <code>Detail</code> for the formulation
of the simulated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RRR_sim(
  N = 1000,
  P = 3,
  Q = 3,
  R = 1,
  r = 1,
  mu = rep(0.1, P),
  A = matrix(rnorm(P * r), ncol = r),
  B = matrix(rnorm(Q * r), ncol = r),
  D = matrix(rnorm(P * R), ncol = R),
  varcov = diag(P),
  innov = mvtnorm::rmvt(N, sigma = varcov, df = 3),
  mean_x = 0,
  mean_z = 0,
  x = NULL,
  z = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RRR_sim_+3A_n">N</code></td>
<td>
<p>Integer. The total number of simulated realizations.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_p">P</code></td>
<td>
<p>Integer. The dimension of the response variable matrix. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_q">Q</code></td>
<td>
<p>Integer. The dimension of the explanatory variable matrix to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_r">R</code></td>
<td>
<p>Integer. The dimension of the explanatory variable matrix not to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_r">r</code></td>
<td>
<p>Integer. The rank of the reduced rank coefficient matrix. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_mu">mu</code></td>
<td>
<p>Vector with length P. The constants. Can be <code>NULL</code> to drop the term. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_a">A</code></td>
<td>
<p>Matrix with dimension P*r. The exposure matrix. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_b">B</code></td>
<td>
<p>Matrix with dimension Q*r. The factor matrix. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_d">D</code></td>
<td>
<p>Matrix with dimension P*R. The coefficient matrix for <code>z</code>. Can be <code>NULL</code> to drop the term. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_varcov">varcov</code></td>
<td>
<p>Matrix with dimension P*P. The covariance matrix of the innovation. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_innov">innov</code></td>
<td>
<p>Matrix with dimension N*P. The innovations. Default to be simulated from a Student t distribution, See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_mean_x">mean_x</code></td>
<td>
<p>Integer. The mean of the normal distribution <code class="reqn">x</code> is simulated from.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_mean_z">mean_z</code></td>
<td>
<p>Integer. The mean of the normal distribution <code class="reqn">z</code> is simulated from.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_x">x</code></td>
<td>
<p>Matrix with dimension N*Q. Can be used to specify <code class="reqn">x</code> instead of simulating form a normal distribution.</p>
</td></tr>
<tr><td><code id="RRR_sim_+3A_z">z</code></td>
<td>
<p>Matrix with dimension N*R. Can be used to specify <code class="reqn">z</code> instead of simulating form a normal distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data simulated can be used for the standard reduced-rank regression testing
with the following formulation
</p>
<p style="text-align: center;"><code class="reqn">y = \mu +AB'  x + D z+innov,</code>
</p>

<p>where for each realization <code class="reqn">y</code> is a vector of dimension <code class="reqn">P</code> for the <code class="reqn">P</code> response variables,
<code class="reqn">x</code> is a vector of dimension <code class="reqn">Q</code> for the <code class="reqn">Q</code> explanatory variables that will be projected to
reduce the rank,
<code class="reqn">z</code> is a vector of dimension <code class="reqn">R</code> for the <code class="reqn">R</code> explanatory variables
that will not be projected,
<code class="reqn">\mu</code> is the constant vector of dimension <code class="reqn">P</code>,
<code class="reqn">innov</code> is the innovation vector of dimension <code class="reqn">P</code>,
<code class="reqn">D</code> is a coefficient matrix for <code class="reqn">z</code> with dimension <code class="reqn">P*R</code>,
<code class="reqn">A</code> is the so called exposure matrix with dimension <code class="reqn">P*r</code>, and
<code class="reqn">B</code> is the so called factor matrix with dimension <code class="reqn">Q*r</code>.
The matrix resulted from <code class="reqn">AB'</code> will be a reduced rank coefficient matrix with rank of <code class="reqn">r</code>.
The function simulates <code class="reqn">x</code>, <code class="reqn">z</code> from multivariate normal distribution and <code class="reqn">y</code> by specifying
parameters <code class="reqn">\mu</code>, <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">D</code>, and <code class="reqn">varcov</code>, the covariance matrix of
the innovation's distribution.  The constant <code class="reqn">\mu</code> and the term <code class="reqn">Dz</code> can be
dropped by setting <code>NULL</code> for arguments <code>mu</code> and <code>D</code>. The <code>innov</code> in the argument is
the collection of innovations of all the realizations.
</p>


<h3>Value</h3>

<p>A list of the input specifications and the data <code class="reqn">y</code>, <code class="reqn">x</code>, and <code class="reqn">z</code>, of class <code>RRR_data</code>.
</p>

<dl>
<dt>y</dt><dd><p>Matrix of dimension N*P</p>
</dd>
<dt>x</dt><dd><p>Matrix of dimension N*Q</p>
</dd>
<dt>z</dt><dd><p>Matrix of dimension N*R</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yangzhuoran Yang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2222)
data &lt;- RRR_sim()

</code></pre>

<hr>
<h2 id='RRRR'>Robust Reduced-Rank Regression using Majorisation-Minimisation</h2><span id='topic+RRRR'></span>

<h3>Description</h3>

<p>Majorisation-Minimisation based Estimation for Reduced-Rank Regression with a Cauchy Distribution Assumption.
This method is robust in the sense that it assumes a heavy-tailed Cauchy distribution
for the innovations. This method is an iterative optimization algorithm. See <code>References</code> for a similar setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RRRR(
  y,
  x,
  z = NULL,
  mu = TRUE,
  r = 1,
  itr = 100,
  earlystop = 1e-04,
  initial_A = matrix(rnorm(P * r), ncol = r),
  initial_B = matrix(rnorm(Q * r), ncol = r),
  initial_D = matrix(rnorm(P * R), ncol = R),
  initial_mu = matrix(rnorm(P)),
  initial_Sigma = diag(P),
  return_data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RRRR_+3A_y">y</code></td>
<td>
<p>Matrix of dimension N*P. The matrix for the response variables. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_x">x</code></td>
<td>
<p>Matrix of dimension N*Q. The matrix for the explanatory variables to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_z">z</code></td>
<td>
<p>Matrix of dimension N*R. The matrix for the explanatory variables not to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_mu">mu</code></td>
<td>
<p>Logical. Indicating if a constant term is included.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_r">r</code></td>
<td>
<p>Integer. The rank for the reduced-rank matrix <code class="reqn">AB'</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_itr">itr</code></td>
<td>
<p>Integer. The maximum number of iteration.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_earlystop">earlystop</code></td>
<td>
<p>Scalar. The criteria to stop the algorithm early. The algorithm will stop if the improvement
on objective function is small than <code class="reqn">earlystop * objective_from_last_iteration</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_initial_a">initial_A</code></td>
<td>
<p>Matrix of dimension P*r. The initial value for matrix <code class="reqn">A</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_initial_b">initial_B</code></td>
<td>
<p>Matrix of dimension Q*r. The initial value for matrix <code class="reqn">B</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_initial_d">initial_D</code></td>
<td>
<p>Matrix of dimension P*R. The initial value for matrix <code class="reqn">D</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_initial_mu">initial_mu</code></td>
<td>
<p>Matrix of dimension P*1. The initial value for the constant <code class="reqn">mu</code>. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_initial_sigma">initial_Sigma</code></td>
<td>
<p>Matrix of dimension P*P. The initial value for matrix Sigma. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="RRRR_+3A_return_data">return_data</code></td>
<td>
<p>Logical. Indicating if the data used is return in the output.
If set to <code>TRUE</code>, <code>update.RRRR</code> can update the model by simply provide new data.
Set to <code>FALSE</code> to save output size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formulation of the reduced-rank regression is as follow:
</p>
<p style="text-align: center;"><code class="reqn">y = \mu +AB'  x + D z+innov,</code>
</p>

<p>where for each realization <code class="reqn">y</code> is a vector of dimension <code class="reqn">P</code> for the <code class="reqn">P</code> response variables,
<code class="reqn">x</code> is a vector of dimension <code class="reqn">Q</code> for the <code class="reqn">Q</code> explanatory variables that will be projected to
reduce the rank,
<code class="reqn">z</code> is a vector of dimension <code class="reqn">R</code> for the <code class="reqn">R</code> explanatory variables
that will not be projected,
<code class="reqn">\mu</code> is the constant vector of dimension <code class="reqn">P</code>,
<code class="reqn">innov</code> is the innovation vector of dimension <code class="reqn">P</code>,
<code class="reqn">D</code> is a coefficient matrix for <code class="reqn">z</code> with dimension <code class="reqn">P*R</code>,
<code class="reqn">A</code> is the so called exposure matrix with dimension <code class="reqn">P*r</code>, and
<code class="reqn">B</code> is the so called factor matrix with dimension <code class="reqn">Q*r</code>.
The matrix resulted from <code class="reqn">AB'</code> will be a reduced rank coefficient matrix with rank of <code class="reqn">r</code>.
The function estimates parameters <code class="reqn">\mu</code>, <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">D</code>, and <code class="reqn">Sigma</code>, the covariance matrix of
the innovation's distribution, assuming the innovation has a Cauchy distribution.
</p>


<h3>Value</h3>

<p>A list of the estimated parameters of class <code>RRRR</code>.
</p>

<dl>
<dt>spec</dt><dd><p>The input specifications. <code class="reqn">N</code> is the sample size.</p>
</dd>
<dt>history</dt><dd><p>The path of all the parameters during optimization and the path of the objective value.</p>
</dd>
<dt>mu</dt><dd><p>The estimated constant vector. Can be <code>NULL</code>.</p>
</dd>
<dt>A</dt><dd><p>The estimated exposure matrix.</p>
</dd>
<dt>B</dt><dd><p>The estimated factor matrix.</p>
</dd>
<dt>D</dt><dd><p>The estimated coefficient matrix of <code>z</code>.</p>
</dd>
<dt>Sigma</dt><dd><p>The estimated covariance matrix of the innovation distribution.</p>
</dd>
<dt>obj</dt><dd><p>The final objective value.</p>
</dd>
<dt>data</dt><dd><p>The data used in estimation if <code>return_data</code> is set to <code>TRUE</code>. <code>NULL</code> otherwise.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yangzhuoran Yang
</p>


<h3>References</h3>

<p>Z. Zhao and D. P. Palomar, &quot;Robust maximum likelihood estimation of sparse vector error correction model,&quot; in2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP),  pp. 913&ndash;917,IEEE, 2017.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2222)
data &lt;- RRR_sim()
res &lt;- RRRR(y=data$y, x=data$x, z = data$z)
res

</code></pre>

<hr>
<h2 id='update.RRRR'>Update the RRRR/ORRRR type model with addition data</h2><span id='topic+update.RRRR'></span>

<h3>Description</h3>

<p><code>update.RRRR</code> will update online robust reduced-rank regression model with class <code>RRRR</code>(<code>ORRRR</code>) using newly added data
to achieve online estimation.
Estimation methods:
</p>

<dl>
<dt>SMM</dt><dd><p>Stochastic Majorisation-Minimisation</p>
</dd>
<dt>SAA</dt><dd><p>Sample Average Approximation</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RRRR'
update(
  object,
  newy,
  newx,
  newz = NULL,
  addon = object$spec$addon,
  method = object$method,
  SAAmethod = object$SAAmethod,
  ...,
  ProgressBar = requireNamespace("lazybar")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update.RRRR_+3A_object">object</code></td>
<td>
<p>A model with class <code>RRRR</code>(<code>ORRRR</code>)</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_newy">newy</code></td>
<td>
<p>Matrix of dimension N*P, the new data y. The matrix for the response variables. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_newx">newx</code></td>
<td>
<p>Matrix of dimension N*Q, the new data x. The matrix for the explanatory variables to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_newz">newz</code></td>
<td>
<p>Matrix of dimension N*R, the new data z. The matrix for the explanatory variables not to be projected. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_addon">addon</code></td>
<td>
<p>Integer. The number of data points to be added in the algorithm in each iteration after the first.</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_method">method</code></td>
<td>
<p>Character. The estimation method. Either &quot;SMM&quot; or &quot;SAA&quot;. See <code>Description</code>.</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_saamethod">SAAmethod</code></td>
<td>
<p>Character. The sub solver used in each iteration when the <code>methid</code> is chosen to be &quot;SAA&quot;. See <code>Detail</code>.</p>
</td></tr>
<tr><td><code id="update.RRRR_+3A_...">...</code></td>
<td>
<p>Additional arguments to function
</p>

<dl>
<dt><code>optim</code></dt><dd><p>when the <code>method</code> is &quot;SAA&quot; and the <code>SAAmethod</code> is &quot;optim&quot;</p>
</dd>
<dt><code>RRRR</code></dt><dd><p>when the <code>method</code> is &quot;SAA&quot; and the <code>SAAmethod</code> is &quot;MM&quot;</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="update.RRRR_+3A_progressbar">ProgressBar</code></td>
<td>
<p>Logical. Indicating if a progress bar is shown during the estimation process.
The progress bar requires package <code>lazybar</code> to work.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formulation of the reduced-rank regression is as follow:
</p>
<p style="text-align: center;"><code class="reqn">y = \mu +AB'  x + D z+innov,</code>
</p>

<p>where for each realization <code class="reqn">y</code> is a vector of dimension <code class="reqn">P</code> for the <code class="reqn">P</code> response variables,
<code class="reqn">x</code> is a vector of dimension <code class="reqn">Q</code> for the <code class="reqn">Q</code> explanatory variables that will be projected to
reduce the rank,
<code class="reqn">z</code> is a vector of dimension <code class="reqn">R</code> for the <code class="reqn">R</code> explanatory variables
that will not be projected,
<code class="reqn">\mu</code> is the constant vector of dimension <code class="reqn">P</code>,
<code class="reqn">innov</code> is the innovation vector of dimension <code class="reqn">P</code>,
<code class="reqn">D</code> is a coefficient matrix for <code class="reqn">z</code> with dimension <code class="reqn">P*R</code>,
<code class="reqn">A</code> is the so called exposure matrix with dimension <code class="reqn">P*r</code>, and
<code class="reqn">B</code> is the so called factor matrix with dimension <code class="reqn">Q*r</code>.
The matrix resulted from <code class="reqn">AB'</code> will be a reduced rank coefficient matrix with rank of <code class="reqn">r</code>.
The function estimates parameters <code class="reqn">\mu</code>, <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">D</code>, and <code class="reqn">Sigma</code>, the covariance matrix of
the innovation's distribution.
</p>
<p>See <code>?ORRRR</code> for details about the estimation methods.
</p>


<h3>Value</h3>

<p>A list of the estimated parameters of class <code>ORRRR</code>.
</p>

<dl>
<dt>method</dt><dd><p>The estimation method being used</p>
</dd>
<dt>SAAmethod</dt><dd><p>If SAA is the major estimation method, what is the sub solver in each iteration.</p>
</dd>
<dt>spec</dt><dd><p>The input specifications. <code class="reqn">N</code> is the sample size.</p>
</dd>
<dt>history</dt><dd><p>The path of all the parameters during optimization and the path of the objective value.</p>
</dd>
<dt>mu</dt><dd><p>The estimated constant vector. Can be <code>NULL</code>.</p>
</dd>
<dt>A</dt><dd><p>The estimated exposure matrix.</p>
</dd>
<dt>B</dt><dd><p>The estimated factor matrix.</p>
</dd>
<dt>D</dt><dd><p>The estimated coefficient matrix of <code>z</code>.</p>
</dd>
<dt>Sigma</dt><dd><p>The estimated covariance matrix of the innovation distribution.</p>
</dd>
<dt>obj</dt><dd><p>The final objective value.</p>
</dd>
<dt>data</dt><dd><p>The data used in estimation.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yangzhuoran Yang
</p>


<h3>See Also</h3>

<p><code>ORRRR</code>, <code>RRRR</code>, <code>RRR</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(2222)
data &lt;- RRR_sim()
newdata &lt;- RRR_sim(A = data$spec$A,
                   B = data$spec$B,
                   D = data$spec$D)
res &lt;- ORRRR(y=data$y, x=data$x, z = data$z)
res &lt;- update(res, newy=newdata$y, newx=newdata$x, newz=newdata$z)
res

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
