<!DOCTYPE html><html lang="en"><head><title>Help for package mildsvm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mildsvm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mildsvm-package'><p>mildsvm: Multiple-Instance Learning with Support Vector Machines</p></a></li>
<li><a href='#as_mi_df'><p>Coerce to MI data frame</p></a></li>
<li><a href='#as_mild_df'><p>Coerce to MILD data frame</p></a></li>
<li><a href='#bag_instance_sampling'><p>Sample <code>mild_df</code> object by bags and instances</p></a></li>
<li><a href='#build_fm'><p>Build a feature map on new data</p></a></li>
<li><a href='#build_instance_feature'><p>Flatten <code>mild_df</code> data to the instance level</p></a></li>
<li><a href='#classify_bags'><p>Classify y from bags</p></a></li>
<li><a href='#cv_misvm'><p>Fit MI-SVM model to the data using cross-validation</p></a></li>
<li><a href='#formatting'><p>Printing multiple instance data frames</p></a></li>
<li><a href='#generate_mild_df'><p>Generate mild_df using multivariate t and normal distributions.</p></a></li>
<li><a href='#kfm_exact'><p>Create an exact kernel feature map</p></a></li>
<li><a href='#kfm_nystrom'><p>Fit a Nyström kernel feature map approximation</p></a></li>
<li><a href='#kme'><p>Calculate the kernel mean embedding matrix</p></a></li>
<li><a href='#mi'><p>Create an <code>mi</code> object</p></a></li>
<li><a href='#mi_df'><p>Build a multiple instance (MI) data frame</p></a></li>
<li><a href='#mild'><p>Create a mild object</p></a></li>
<li><a href='#mild_df'><p>Build a MILD data frame</p></a></li>
<li><a href='#mior'><p>Fit MIOR model to the data</p></a></li>
<li><a href='#mismm'><p>Fit MILD-SVM model to the data</p></a></li>
<li><a href='#misvm'><p>Fit MI-SVM model to the data</p></a></li>
<li><a href='#misvm_orova'><p>Fit MI-SVM model to ordinal outcome data using One-vs-All</p></a></li>
<li><a href='#omisvm'><p>Fit MI-SVM-OR model to ordinal outcome data</p></a></li>
<li><a href='#ordmvnorm'><p>Sample ordinal MIL data using mvnorm</p></a></li>
<li><a href='#predict.cv_misvm'><p>Predict method for <code>cv_misvm</code> object</p></a></li>
<li><a href='#predict.mior'><p>Predict method for <code>mior</code> object</p></a></li>
<li><a href='#predict.mismm'><p>Predict method for <code>mismm</code> object</p></a></li>
<li><a href='#predict.misvm'><p>Predict method for <code>misvm</code> object</p></a></li>
<li><a href='#predict.misvm_orova'><p>Predict method for <code>misvm_orova</code> object</p></a></li>
<li><a href='#predict.omisvm'><p>Predict method for <code>omisvm</code> object</p></a></li>
<li><a href='#predict.smm'><p>Predict method for <code>smm</code> object</p></a></li>
<li><a href='#predict.svor_exc'><p>Predict method for <code>svor_exc</code> object</p></a></li>
<li><a href='#smm'><p>Fit SMM model to the data</p></a></li>
<li><a href='#summarize_samples'><p>Summarize data across functions</p></a></li>
<li><a href='#svor_exc'><p>Fit SVOR-EXC model to ordinal outcome data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multiple-Instance Learning with Support Vector Machines</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Weakly supervised (WS), multiple instance (MI) data lives in
    numerous interesting applications such as drug discovery, object
    detection, and tumor prediction on whole slide images. The 'mildsvm'
    package provides an easy way to learn from this data by training
    Support Vector Machine (SVM)-based classifiers. It also contains
    helpful functions for building and printing multiple instance data
    frames. The core methods from 'mildsvm' come from the following
    references: Kent and Yu (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2206.14704">doi:10.48550/arXiv.2206.14704</a>&gt;; Xiao, Liu, and Hao
    (2018) &lt;<a href="https://doi.org/10.1109%2FTNNLS.2017.2766164">doi:10.1109/TNNLS.2017.2766164</a>&gt;; Muandet et al. (2012)
    <a href="https://proceedings.neurips.cc/paper/2012/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper.pdf">https://proceedings.neurips.cc/paper/2012/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper.pdf</a>;
    Chu and Keerthi (2007) &lt;<a href="https://doi.org/10.1162%2Fneco.2007.19.3.792">doi:10.1162/neco.2007.19.3.792</a>&gt;; and Andrews
    et al. (2003)
    <a href="https://papers.nips.cc/paper/2232-support-vector-machines-for-multiple-instance-learning.pdf">https://papers.nips.cc/paper/2232-support-vector-machines-for-multiple-instance-learning.pdf</a>.
    Many functions use the 'Gurobi' optimization back-end to improve the
    optimization problem speed; the 'gurobi' R package and associated
    software can be downloaded from <a href="https://www.gurobi.com">https://www.gurobi.com</a> after
    obtaining a license.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/skent259/mildsvm">https://github.com/skent259/mildsvm</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/skent259/mildsvm/issues">https://github.com/skent259/mildsvm/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, e1071, kernlab, magrittr, mvtnorm, pillar, pROC, purrr,
rlang, stats, tibble, tidyr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, gurobi, Matrix, testthat</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-08 22:49:54 UTC; spkent</td>
</tr>
<tr>
<td>Author:</td>
<td>Sean Kent <a href="https://orcid.org/0000-0001-8697-9069"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Yifei Liou [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sean Kent &lt;skent259@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-14 09:00:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='mildsvm-package'>mildsvm: Multiple-Instance Learning with Support Vector Machines</h2><span id='topic+mildsvm'></span><span id='topic+mildsvm-package'></span>

<h3>Description</h3>

<p>Weakly supervised (WS), multiple instance (MI) data lives in numerous interesting applications such as drug discovery, object detection, and tumor prediction on whole slide images. The 'mildsvm' package provides an easy way to learn from this data by training Support Vector Machine (SVM)-based classifiers. It also contains helpful functions for building and printing multiple instance data frames. The core methods from 'mildsvm' come from the following references: Kent and Yu (2022) &lt;arXiv:2206.14704&gt;; Xiao, Liu, and Hao (2018) &lt;doi:10.1109/TNNLS.2017.2766164&gt;; Muandet et al. (2012) &lt;https://proceedings.neurips.cc/paper/2012/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper.pdf&gt;; Chu and Keerthi (2007) &lt;doi:10.1162/neco.2007.19.3.792&gt;; and Andrews et al. (2003) &lt;https://papers.nips.cc/paper/2232-support-vector-machines-for-multiple-instance-learning.pdf&gt;. Many functions use the 'Gurobi' optimization back-end to improve the optimization problem speed; the 'gurobi' R package and associated software can be downloaded from &lt;https://www.gurobi.com&gt; after obtaining a license.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Sean Kent <a href="mailto:skent259@gmail.com">skent259@gmail.com</a> (<a href="https://orcid.org/0000-0001-8697-9069">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Yifei Liou
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/skent259/mildsvm">https://github.com/skent259/mildsvm</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/skent259/mildsvm/issues">https://github.com/skent259/mildsvm/issues</a>
</p>
</li></ul>


<hr>
<h2 id='as_mi_df'>Coerce to MI data frame</h2><span id='topic+as_mi_df'></span>

<h3>Description</h3>

<p><code>as_mi_df()</code> turns an existing object, such as a data frame, into a MI
data frame, a data frame with 'mi_df'. This is in contrast with
<code><a href="#topic+mi_df">mi_df()</a></code>, which builds a MI data frame from individual columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_mi_df(
  x,
  bag_label = "bag_label",
  bag_name = "bag_name",
  instance_label = "instance_label",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_mi_df_+3A_x">x</code></td>
<td>
<p>A data-frame or similar to convert.</p>
</td></tr>
<tr><td><code id="as_mi_df_+3A_bag_label">bag_label</code></td>
<td>
<p>A character (default <code>'bag_label'</code>) describing which column
refers to the bag label.</p>
</td></tr>
<tr><td><code id="as_mi_df_+3A_bag_name">bag_name</code></td>
<td>
<p>A character (default <code>'bag_name'</code>) describing which column
refers to the bag name.</p>
</td></tr>
<tr><td><code id="as_mi_df_+3A_instance_label">instance_label</code></td>
<td>
<p>A character (default <code>'instance_label'</code>) describing which
column refers to the instance labels. If NULL, no instance_labels will be
used.</p>
</td></tr>
<tr><td><code id="as_mi_df_+3A_...">...</code></td>
<td>
<p>Arguments reserved for other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 'mi_df' object. This data.frame-like has columns <code>bag_label</code>,
<code>bag_name</code>, and potentially others. It also inherits from the
<code>'tbl_df'</code> and <code>'tbl'</code> classes.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mi_df">mi_df()</a></code> to build a <code>mi_df</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = data.frame('bag_LABEL' = factor(c(1, 1, 0)),
               'bag_name' = c(rep('bag_1', 2), 'bag_2'),
               'X1' = c(-0.4, 0.5, 2),
               'instance_label' = c(0, 1, 0))

df &lt;- as_mi_df(x)

</code></pre>

<hr>
<h2 id='as_mild_df'>Coerce to MILD data frame</h2><span id='topic+as_mild_df'></span>

<h3>Description</h3>

<p><code>as_mild_df()</code> turns an existing object, such as a data frame, into a MILD
data frame, a data frame with 'mild_df'. This is in contrast with
<code><a href="#topic+mild_df">mild_df()</a></code>, which builds a MILD data frame from individual columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_mild_df(
  x,
  bag_label = "bag_label",
  bag_name = "bag_name",
  instance_name = "instance_name",
  instance_label = "instance_label",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_mild_df_+3A_x">x</code></td>
<td>
<p>A data-frame or similar to convert.</p>
</td></tr>
<tr><td><code id="as_mild_df_+3A_bag_label">bag_label</code></td>
<td>
<p>A character (default <code>'bag_label'</code>) describing which column
refers to the bag label.</p>
</td></tr>
<tr><td><code id="as_mild_df_+3A_bag_name">bag_name</code></td>
<td>
<p>A character (default <code>'bag_name'</code>) describing which column
refers to the bag name.</p>
</td></tr>
<tr><td><code id="as_mild_df_+3A_instance_name">instance_name</code></td>
<td>
<p>A character (default <code>'instance_name'</code>) describing which
column refers to the instance name.</p>
</td></tr>
<tr><td><code id="as_mild_df_+3A_instance_label">instance_label</code></td>
<td>
<p>A character (default <code>'instance_label'</code>) describing which
column refers to the instance labels. If NULL, no instance_labels will be
used.</p>
</td></tr>
<tr><td><code id="as_mild_df_+3A_...">...</code></td>
<td>
<p>Arguments reserved for other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 'mild_df' object. This data.frame-like has columns <code>bag_label</code>,
<code>bag_name</code>, <code>instance_name</code>, and potentially others. It also inherits from
the <code>'tbl_df'</code> and <code>'tbl'</code> classes.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mild_df">mild_df()</a></code> to build a <code>mild_df</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- data.frame('bag_LABEL' = factor(c(1, 1, 0)),
               'bag_name' = c(rep('bag_1', 2), 'bag_2'),
               'instance_name' = c('bag_1_inst_1', 'bag_1_inst_2', 'bag_2_inst_1'),
               'X1' = c(-0.4, 0.5, 2),
               'instance_label' = c(0, 1, 0))

df &lt;- as_mild_df(x)

</code></pre>

<hr>
<h2 id='bag_instance_sampling'>Sample <code>mild_df</code> object by bags and instances</h2><span id='topic+bag_instance_sampling'></span>

<h3>Description</h3>

<p>From a <code>mild_df</code> object, return a sample that evenly pulls from the unique
bags and unique instances from each bag as much as possible.  This is a form
of stratified sampling to avoid randomly sampling many rows from a few bags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bag_instance_sampling(data, size)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bag_instance_sampling_+3A_data">data</code></td>
<td>
<p>A <code>mild_df</code> object containing the data.</p>
</td></tr>
<tr><td><code id="bag_instance_sampling_+3A_size">size</code></td>
<td>
<p>A non-negative integer giving the number of rows to choose from
<code>data</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of length <code>size</code> indicating which rows were sampled.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mil_data &lt;- generate_mild_df(positive_dist = "mvnormal",
                             nbag = 2,
                             ninst = 2,
                             nsample = 2)

rows &lt;- bag_instance_sampling(mil_data, 6)
table(mil_data$bag_name[rows])
table(mil_data$instance_name[rows])

rows &lt;- bag_instance_sampling(mil_data, 4)
table(mil_data$bag_name[rows])
table(mil_data$instance_name[rows])

</code></pre>

<hr>
<h2 id='build_fm'>Build a feature map on new data</h2><span id='topic+build_fm'></span><span id='topic+build_fm.kfm_exact'></span><span id='topic+build_fm.kfm_nystrom'></span>

<h3>Description</h3>

<p>Feature maps provide a set of covariates in a transformed space.  The
<code>build_fm()</code> function creates these covariates based on an object that
specifies the feature map and a provided dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_fm(kfm_fit, new_data, ...)

## S3 method for class 'kfm_exact'
build_fm(kfm_fit, new_data, ...)

## S3 method for class 'kfm_nystrom'
build_fm(kfm_fit, new_data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build_fm_+3A_kfm_fit">kfm_fit</code></td>
<td>
<p>An object from a function in the <code style="white-space: pre;">&#8288;kfm_*&#8288;</code> family, such as
<code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code>.</p>
</td></tr>
<tr><td><code id="build_fm_+3A_new_data">new_data</code></td>
<td>
<p>The data to generate features from.</p>
</td></tr>
<tr><td><code id="build_fm_+3A_...">...</code></td>
<td>
<p>Additional arguments for methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of covariates in the feature space, with the same number of
rows as <code>new_data</code>.  If <code>new_data</code> is a <code>mild_df</code> object, <code>build_fm()</code>
will also return the columns containing 'bag_label', 'bag_name',
'instance_name'.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>kfm_exact</code>: Method for <code>kfm_exact</code> class.
</p>
</li>
<li> <p><code>kfm_nystrom</code>: Method for <code>kfm_nystrom</code> class.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code> fit a Nystrom kernel feature map approximation.
</p>
</li>
<li> <p><code><a href="#topic+kfm_exact">kfm_exact()</a></code> create an exact kernel feature map.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  X1 = c(2,   3,   4,   5,   6, 7, 8),
  X2 = c(1, 1.2, 1.3, 1.4, 1.1, 7, 1),
  X3 = rnorm(7)
)

fit &lt;- kfm_nystrom(df, m = 7, r = 6, kernel = "radial", sigma = 0.05)
fm &lt;- build_fm(fit, df)

fit &lt;- kfm_exact(kernel = "polynomial", degree = 2, const = 1)
fm &lt;- build_fm(fit, df)

</code></pre>

<hr>
<h2 id='build_instance_feature'>Flatten <code>mild_df</code> data to the instance level</h2><span id='topic+build_instance_feature'></span>

<h3>Description</h3>

<p>Flatten <code>mild_df</code> type of data to regular multiple instance data where
each instance is a vector by extracting distribution sample quantiles, mean
and sd.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_instance_feature(
  data,
  qtls = seq(0.05, 0.95, length.out = 10),
  mean = TRUE,
  sd = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build_instance_feature_+3A_data">data</code></td>
<td>
<p>A <code>mild_df</code> object.</p>
</td></tr>
<tr><td><code id="build_instance_feature_+3A_qtls">qtls</code></td>
<td>
<p>Quantiles to be extracted from each instance empirical
distribution.</p>
</td></tr>
<tr><td><code id="build_instance_feature_+3A_mean">mean</code></td>
<td>
<p>A logical for whether or not to extract mean.</p>
</td></tr>
<tr><td><code id="build_instance_feature_+3A_sd">sd</code></td>
<td>
<p>A logical for whether or not to extract standard deviation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summarized data.frame at the instance level.
</p>


<h3>Author(s)</h3>

<p>Yifei Liu
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summarize_samples">summarize_samples()</a></code> for a more general way to make a similar data
frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mild_df1 &lt;- generate_mild_df(positive_degree = 3, nbag = 3)
df1 &lt;- build_instance_feature(mild_df1, seq(0.05, 0.95, length.out = 10))

</code></pre>

<hr>
<h2 id='classify_bags'>Classify y from bags</h2><span id='topic+classify_bags'></span>

<h3>Description</h3>

<p>Formally, this function applies <code>max()</code> on <code>y</code> for each level of <code>bags</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classify_bags(y, bags, condense = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classify_bags_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="classify_bags_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="classify_bags_+3A_condense">condense</code></td>
<td>
<p>A logical (default <code>TRUE</code>) for whether to return
classification at the level of unique bags or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named vector of length <code>length(unique(b))</code> which gives the
classification for each bag.  Names come from <code>bags</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- c(1, 0, 0, 1, 1, 1, 0, 0, 0)
bags &lt;- rep(1:3, each = 3)

classify_bags(y, bags)
classify_bags(y, bags, condense = FALSE)

# works with regular vector too
scores &lt;- 1:9
classify_bags(scores, bags)

</code></pre>

<hr>
<h2 id='cv_misvm'>Fit MI-SVM model to the data using cross-validation</h2><span id='topic+cv_misvm'></span><span id='topic+cv_misvm.default'></span><span id='topic+cv_misvm.formula'></span><span id='topic+cv_misvm.mi_df'></span>

<h3>Description</h3>

<p>Cross-validation wrapper on the <code><a href="#topic+misvm">misvm()</a></code> function to fit the MI-SVM model
over a variety of specified cost parameters.  The optimal cost parameter
is chosen by the best AUC of the cross-fit models.  See <code>?misvm</code> for
more details on the fitting function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
cv_misvm(
  x,
  y,
  bags,
  cost_seq,
  n_fold,
  fold_id,
  method = c("heuristic", "mip", "qp-heuristic"),
  weights = TRUE,
  control = list(kernel = "linear", sigma = 1, nystrom_args = list(m = nrow(x), r =
    nrow(x), sampling = "random"), max_step = 500, type = "C-classification", scale =
    TRUE, verbose = FALSE, time_limit = 60, start = FALSE),
  ...
)

## S3 method for class 'formula'
cv_misvm(formula, data, cost_seq, n_fold, fold_id, ...)

## S3 method for class 'mi_df'
cv_misvm(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_misvm_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents a sample.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_cost_seq">cost_seq</code></td>
<td>
<p>A sequence of <code>cost</code> arguments (default <code>2^(-2:2)</code>) in
<code>misvm()</code>.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_n_fold">n_fold</code></td>
<td>
<p>The number of folds (default 5). If this is specified,
<code>fold_id</code> need not be specified.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_fold_id">fold_id</code></td>
<td>
<p>The ids for the specific the fold for each instance. Care must
be taken to ensure that ids respect the bag structure to avoid information
leakage.  If <code>n_fold</code> is specified, <code>fold_id</code> will be computed
automatically.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, which employs an algorithm similar to Andrews et
al. (2003). When <code>method = 'mip'</code>, the novel MIP method will be used.  When
<code style="white-space: pre;">&#8288;method = 'qp-heuristic&#8288;</code>, the heuristic algorithm is computed using the
dual SVM.  See details.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>nystrom_args</code> a list of parameters to pass to <code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code>. This is
used when <code>method = 'mip'</code> and <code>kernel = 'radial'</code> to generate a Nystrom
approximation of the kernel features.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>type</code>: argument used when <code>method = 'heuristic'</code>. The <code>type</code> argument is
passed to <code>e1071::svm()</code>.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>start</code> argument used when <code>method = 'mip'</code>.  If <code>TRUE</code>, the mip program
will be warm_started with the solution from <code>method = 'qp-heuristic'</code> to
potentially improve speed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="cv_misvm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_formula">formula</code></td>
<td>
<p>a formula with specification <code>mi(y, bags) ~ x</code> which uses the
<code>mi</code> function to create the bag-instance structure. This argument is an
alternative to the <code style="white-space: pre;">&#8288;x, y, bags&#8288;</code> arguments, but requires the <code>data</code>
argument. See examples.</p>
</td></tr>
<tr><td><code id="cv_misvm_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>cv_misvm</code>.  The object contains the following
components:
</p>

<ul>
<li> <p><code>misvm_fit</code>: A fit object of class <code>misvm</code> trained on the full data with
the cross-validated choice of cost parameter. See <code><a href="#topic+misvm">misvm()</a></code> for details.
</p>
</li>
<li> <p><code>cost_seq</code>: the input sequence of cost arguments
</p>
</li>
<li> <p><code>cost_aucs</code>: estimated AUC for the models trained for each <code>cost_seq</code>
parameter.  These are the average of the fold models for that cost, excluding
any folds that don't have both levels of <code>y</code> in the validation set.
</p>
</li>
<li> <p><code>best_cost</code>: The optimal choice of cost parameter, chosen as that which has
the maximum AUC.  If there are ties, this will pick the smallest cost with
maximum AUC.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent, Yifei Liu
</p>


<h3>See Also</h3>

<p><code><a href="#topic+misvm">misvm()</a></code> for fitting without cross-validation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
mil_data &lt;- generate_mild_df(nbag = 20,
                             positive_prob = 0.15,
                             dist = rep("mvnormal", 3),
                             mean = list(rep(1, 10), rep(2, 10)),
                             sd_of_mean = rep(0.1, 3))
df &lt;- build_instance_feature(mil_data, seq(0.05, 0.95, length.out = 10))
cost_seq &lt;- 2^seq(-5, 7, length.out = 3)

# Heuristic method
mdl1 &lt;- cv_misvm(x = df[, 4:123], y = df$bag_label,
                 bags = df$bag_name, cost_seq = cost_seq,
                 n_fold = 3, method = "heuristic")
mdl2 &lt;- cv_misvm(mi(bag_label, bag_name) ~ X1_mean + X2_mean + X3_mean, data = df,
                 cost_seq = cost_seq, n_fold = 3)

if (require(gurobi)) {
  # solve using the MIP method
  mdl3 &lt;- cv_misvm(x = df[, 4:123], y = df$bag_label,
                   bags = df$bag_name, cost_seq = cost_seq,
                   n_fold = 3, method = "mip")
}

predict(mdl1, new_data = df, type = "raw", layer = "bag")

# summarize predictions at the bag layer
suppressWarnings(library(dplyr))
df %&gt;%
  bind_cols(predict(mdl2, df, type = "class")) %&gt;%
  bind_cols(predict(mdl2, df, type = "raw")) %&gt;%
  distinct(bag_name, bag_label, .pred_class, .pred)

</code></pre>

<hr>
<h2 id='formatting'>Printing multiple instance data frames</h2><span id='topic+formatting'></span><span id='topic+print.mi_df'></span><span id='topic+print.mild_df'></span>

<h3>Description</h3>

<p>Specialized print methods for the <code>mi_df</code>, <code>mild_df</code> classes. These return
helpful information such as the number of rows, columns, bags, and instances
(for <code>mild_df</code> objects).
</p>
<p>These methods print the data frame based on the underlying subclass. This
allows for additional arguments that can be passed to <code>print.tbl()</code> when the
subclass is a tibble (<code>tbl_df</code>, <code>tbl</code>), documented below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mi_df'
print(x, ...)

## S3 method for class 'mild_df'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="formatting_+3A_x">x</code></td>
<td>
<p>Object to format or print.</p>
</td></tr>
<tr><td><code id="formatting_+3A_...">...</code></td>
<td>
<p>Passed to other methods.  See <code><a href="pillar.html#topic+print.tbl">print.tbl()</a></code> or details for more
information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following extra arguments are available when <code>x</code> has subclass <code>tbl</code>:
</p>

<ul>
<li> <p><code>n</code>: Number of rows to show. If <code>NULL</code>, the default, will print all rows
if less than the <code>print_max</code> <a href="pillar.html#topic+pillar_options">option</a>. Otherwise,
will print as many rows as specified by the <code>print_min</code>
<a href="pillar.html#topic+pillar_options">option</a>.
</p>
</li>
<li> <p><code>width</code>: Width of text output to generate. This defaults to <code>NULL</code>, which
means use the <code>width</code> <a href="pillar.html#topic+pillar_options">option</a>.
</p>
</li>
<li> <p><code>max_extra_cols</code>: Number of extra columns to print abbreviated
information for, if the width is too small for the entire tibble. If
<code>NULL</code>, the <code>max_extra_cols</code> <a href="pillar.html#topic+pillar_options">option</a> is used. The
previously defined <code>n_extra</code> argument is soft-deprecated.
</p>
</li>
<li> <p><code>max_footer_lines</code>: Maximum number of footer lines. If <code>NULL</code>, the
<code>max_footer_lines</code> <a href="pillar.html#topic+pillar_options">option</a> is used.
</p>
</li></ul>



<h3>Value</h3>

<p>The object passed in <code>x</code>, invisibly. Primarily called to print the
object to the console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ordmvnorm")
print(as_mi_df(ordmvnorm, instance_label = "inst_label"))

print(as_mi_df(ordmvnorm, instance_label = "inst_label"), n = 2)

</code></pre>

<hr>
<h2 id='generate_mild_df'>Generate mild_df using multivariate t and normal distributions.</h2><span id='topic+generate_mild_df'></span>

<h3>Description</h3>

<p>This function samples multiple instance distributional data (a <code>mild_df</code>
object) where each row corresponds to a sample from a given instance
distribution.  Instance distributions can be multivariate t and normal, with
mean and variance parameters that can be fixed or sampled based on prior
parameters.  These instances are grouped into bags and the bag labels
follow the standard MI assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_mild_df(
  nbag = 50,
  ninst = 4,
  nsample = 50,
  ncov = 10,
  nimp_pos = 1:ncov,
  nimp_neg = 1:ncov,
  positive_prob = 0.2,
  dist = c("mvt", "mvnormal", "mvnormal"),
  mean = list(rep(0, length(nimp_pos)), rep(0, length(nimp_neg)), 0),
  sd_of_mean = c(0.5, 0.5, 0.5),
  cov = list(diag(1, nrow = length(nimp_pos)), diag(1, nrow = length(nimp_neg)), 1),
  sample_cov = FALSE,
  df_wishart_cov = c(length(nimp_pos), length(nimp_neg), ncov - length(nimp_pos)),
  degree = c(3, NA, NA),
  positive_bag_prob = NULL,
  n_noise_inst = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_mild_df_+3A_nbag">nbag</code></td>
<td>
<p>The number of bags (default 50).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_ninst">ninst</code></td>
<td>
<p>The number of instances for each bag (default 4).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_nsample">nsample</code></td>
<td>
<p>The number of samples for each instance (default 50).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_ncov">ncov</code></td>
<td>
<p>The number of total covariates (default 10).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_nimp_pos">nimp_pos</code></td>
<td>
<p>An index of important covariates for positve instances
(default <code>1:ncov</code>).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_nimp_neg">nimp_neg</code></td>
<td>
<p>An index of important covariates for negative instances
(default <code>1:ncov</code>).
(default <code>1:ncov</code>).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_positive_prob">positive_prob</code></td>
<td>
<p>A numeric value between 0 and 1 indicating the
probability of an instance being positive (default 0.2).</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_dist">dist</code></td>
<td>
<p>A vector (length 3) of distributions for the positive, negative, and
remaining instances, respectively.  Distributions can be one of
<code>'mvnormal'</code> for multivariate normal or <code>'mvt'</code> for multivariate
student's t.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_mean">mean</code></td>
<td>
<p>A list (length 3) of mean vectors for the positive, negative, and
remaining distributions.  <code>mean[[1]]</code> should match <code>nimp_pos</code> in length;
<code>mean[[2]]</code> should match <code>nimp_neg</code> in length.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_sd_of_mean">sd_of_mean</code></td>
<td>
<p>A vector (length 3) of standard deviations in sampling the
mean for positive, negative, and remaining distributions, where the prior
is given by <code>mean</code>.  Use <code>sd_of_mean = c(0, 0, 0)</code> to keep the mean
consistent across all instances.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_cov">cov</code></td>
<td>
<p>A list (length 3) of covariance matrices for the positive,
negative, and remaining distributions.  <code>cov[[3]]</code> should be an integer
since the dimension of remaining features can vary depending on if the
important distribution is positive or negative.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_sample_cov">sample_cov</code></td>
<td>
<p>A logical value for whether to sample the covariance for
each distribution.  If <code>FALSE</code> (the default), each covariance is fixed at
<code>cov</code>. If <code>TRUE</code>, the prior is given by <code>cov</code> and sampled from a Wishart
distribution with <code>df_wishart_cov</code> degrees of freedom to have an
expectation of <code>cov</code>.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_df_wishart_cov">df_wishart_cov</code></td>
<td>
<p>A vector (length 3) of degrees-of-freedom to use in the
Wishart covariance matrix sampling.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_degree">degree</code></td>
<td>
<p>A vector (length 3) of degrees-of-freedom used when any of
<code>dist</code> is <code>'mvt'</code>.  This parameter is ignored when <code>dist[i] == 'mvnormal'</code>,
in which case <code>NA</code> can be specified.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_positive_bag_prob">positive_bag_prob</code></td>
<td>
<p>A numeric value between 0 and 1 indicating the
probability of a bag being positive. Must be specified jointly with
<code>n_noise_inst</code>, in which case <code>positive_prob</code> is ignored.  If <code>NULL</code> (the
default), instance labels are sampled first according to <code>positive_prob</code>.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_n_noise_inst">n_noise_inst</code></td>
<td>
<p>An integer indicating the number of negative instances in
a positive bag. Must be specified jointly with <code>positive_bag_prob</code>.
<code>n_noise_inst</code> should be less than <code>ninst</code>.</p>
</td></tr>
<tr><td><code id="generate_mild_df_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first consideration to use this function is to determine the number of
bags, instances per bag, and samples per instance using the <code>nbag</code>, <code>ninst</code>,
and <code>nsample</code> arguments. Next, one must consider the number of covariates
<code>ncov</code>, and how those covariates will differ between instances with positive
and negative labels.  Some covariates can be common between the positive and
negative instances, which we call the remainder distribution.  Use <code>nimp_pos</code>
and <code>nimp_neg</code> to specify the index of the important (non-remainder)
covariates in the distributions with positive and negative instance labels.
</p>
<p>The structure of how many instances/bags are positive and negative is
determined by <code>positive_prob</code> or the joint specification of
<code>positive_bag_prob</code> and <code>n_noise_inst</code>. In the first case, instances labels
have independent Bernoulli draws based on <code>positive_prob</code> and bag labels are
determined by the standard MI assumption (i.e. positive if any instance in
the bag is positive).  In the second case, bag labels are drawn independently
as Bernoilli with <code>positive_bag_prob</code> chance of success.  Each positive bag
will be given <code>n_noise_inst</code> values with instance label of 0, and the
remaining with instance label of 1.
</p>
<p>The remaining arguments are used to determine the distributions used for the
positive, negative, and remaining features.  Each argument will be a vector
of list of length 3 corresponding to these 3 different groups.  To create
different distributions, the strategy is to first draw the mean parameter
from Normal(<code>mean</code>, <code>sd_of_mean</code> * I) and the covariance parameter from
Wishart(<code>df_wishart_cov</code>, <code>cov</code>), with expectation equal to <code>cov</code>.  Then we
can sample i.i.d. draws from the specified distribution (either multivariate
normal or student's t). To ensure that each instance distribution has the
same mean, set <code>sd_of_mean</code> to 0. To ensure that each instance distribution
has the same covariance, set <code>sample_cov = FALSE</code>.
</p>
<p>The final data.frame will have <code>nsample</code> * <code>nbag</code> * <code>ninst</code> rows and <code>ncov + 3</code> columns including the bag_label, bag_name, instance_name, and <code>ncov</code>
sampled covariates.
</p>


<h3>Value</h3>

<p>A <code>mild_df</code> object.
</p>


<h3>Author(s)</h3>

<p>Yifei Liu, Sean Kent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
mild_data &lt;- generate_mild_df(nbag = 7, ninst = 3, nsample = 20,
                              ncov = 2,
                              nimp_pos = 1,
                              dist = rep("mvnormal", 3),
                              mean = list(
                                rep(5, 1),
                                rep(15, 2),
                                0
                              ))

library(dplyr)
distinct(mild_data, bag_label, bag_name, instance_name)
split(mild_data[, 4:5], mild_data$instance_name) %&gt;%
  sapply(colMeans) %&gt;%
  round(2) %&gt;%
  t()
</code></pre>

<hr>
<h2 id='kfm_exact'>Create an exact kernel feature map</h2><span id='topic+kfm_exact'></span>

<h3>Description</h3>

<p>For some kernels, it is possible to create the exact features from given
data. This function stores the information needed to build those exact
features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfm_exact(kernel = "polynomial", degree = 2, const = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfm_exact_+3A_kernel">kernel</code></td>
<td>
<p>A character determining the kernel to use.  Currently, only
<code>'radial'</code> is implemented.</p>
</td></tr>
<tr><td><code id="kfm_exact_+3A_degree">degree</code></td>
<td>
<p>A numeric value (default 2) that provides the degree for
<code>kernel</code> = 'polynomial'</p>
</td></tr>
<tr><td><code id="kfm_exact_+3A_const">const</code></td>
<td>
<p>A numeric value (default 1) for the constant term when <code>kernel = 'polynomial'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the following kernels are supported:
</p>

<ul>
<li> <p><code>'polynomial'</code>, with <code>degree</code> = d and <code>const</code> = c
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>kfm_exact</code> with the following components,
returned from the inputs:
</p>

<ul>
<li> <p><code>kernel</code>
</p>
</li>
<li> <p><code>degree</code>
</p>
</li>
<li> <p><code>const</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p>Other kernel feature map functions: 
<code><a href="#topic+kfm_nystrom">kfm_nystrom</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  X1 = c(2,   3,   4,   5,   6, 7, 8),
  X2 = c(1, 1.2, 1.3, 1.4, 1.1, 7, 1),
  X3 = rnorm(7)
)

fit &lt;- kfm_exact(kernel = "polynomial", degree = 2, const = 1)
fm &lt;- build_fm(fit, df)

</code></pre>

<hr>
<h2 id='kfm_nystrom'>Fit a Nyström kernel feature map approximation</h2><span id='topic+kfm_nystrom'></span><span id='topic+kfm_nystrom.default'></span><span id='topic+kfm_nystrom.mild_df'></span>

<h3>Description</h3>

<p>Use the Nyström method to fit a feature map that approximates a given kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfm_nystrom(df, m, r, kernel, sampling, ...)

## Default S3 method:
kfm_nystrom(
  df,
  m = nrow(df),
  r = m,
  kernel = "radial",
  sampling = "random",
  ...
)

## S3 method for class 'mild_df'
kfm_nystrom(
  df,
  m = nrow(df),
  r = m,
  kernel = "radial",
  sampling = "random",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfm_nystrom_+3A_df">df</code></td>
<td>
<p>An object containing covariates for training.  Usually a data.frame
or matrix.</p>
</td></tr>
<tr><td><code id="kfm_nystrom_+3A_m">m</code></td>
<td>
<p>The number of examples from <code>df</code> to sample in fitting.</p>
</td></tr>
<tr><td><code id="kfm_nystrom_+3A_r">r</code></td>
<td>
<p>The rank of matrix approximation to use. Must be less than or equal
to <code>m</code>, the default.</p>
</td></tr>
<tr><td><code id="kfm_nystrom_+3A_kernel">kernel</code></td>
<td>
<p>A character determining the kernel to use.  Currently, only
<code>'radial'</code> is implemented.</p>
</td></tr>
<tr><td><code id="kfm_nystrom_+3A_sampling">sampling</code></td>
<td>
<p>A character determining how to sample instances.  Default is
<code>'random'</code>. For <code>kfm_nystrom.mild_df()</code>, one can specify <code>sampling = 'stratified'</code> to ensure that samples are chosen evenly from bags and
instances. <code>sampling</code> can also be a numeric vector of length <code>m</code> of
pre-determined samples.</p>
</td></tr>
<tr><td><code id="kfm_nystrom_+3A_...">...</code></td>
<td>
<p>additional parameters needed for the kernels.  See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the <code>...</code> argument, the additional parameters depend on which kernel is
used:
</p>

<ul>
<li><p> For <code>kernel = 'radial'</code>, specify <code>sigma</code> to define kernel bandwidth.
</p>
</li></ul>



<h3>Value</h3>

<p>an object of class <code>kfm_nystrom</code> with the following components:
</p>

<ul>
<li> <p><code>df_sub</code> the sub-sampled version of <code>df</code>
</p>
</li>
<li> <p><code>dv</code> pre-multiplication matrix which contains information on the
eigenvalues and eigenvectors of <code>df_sub</code>
</p>
</li>
<li> <p><code>method</code> <code>'nystrom'</code>
</p>
</li>
<li> <p><code>kernel</code> the input parameter <code>kernel</code>
</p>
</li>
<li> <p><code>kernel_params</code> parameters passed to <code>...</code>
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: For use on objects of class <code>data.frame</code> or <code>matrix</code>.
</p>
</li>
<li> <p><code>mild_df</code>: Ignore the information columns <code>'bag_label'</code>,
<code>'bag_name'</code>, and <code>'instance_name'</code> when calculating kernel approximation.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>References</h3>

<p>Williams, C., &amp; Seeger, M. (2001). Using the Nyström Method to
Speed Up Kernel Machines. <em>Advances in Neural Information Processing
Systems</em>, <em>13</em>, 682–688.
</p>
<p>Kent, S., &amp; Yu, M. (2022). Non-convex SVM for cancer diagnosis based on
morphologic features of tumor microenvironment <em>arXiv preprint</em>
<a href="https://arxiv.org/abs/2206.14704">arXiv:2206.14704</a>
</p>


<h3>See Also</h3>

<p>Other kernel feature map functions: 
<code><a href="#topic+kfm_exact">kfm_exact</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  X1 = c(2,   3,   4,   5,   6, 7, 8),
  X2 = c(1, 1.2, 1.3, 1.4, 1.1, 7, 1),
  X3 = rnorm(7)
)

fit &lt;- kfm_nystrom(df, m = 7, r = 6, kernel = "radial", sigma = 0.05)
fm &lt;- build_fm(fit, df)

</code></pre>

<hr>
<h2 id='kme'>Calculate the kernel mean embedding matrix</h2><span id='topic+kme'></span><span id='topic+kme.default'></span><span id='topic+kme.mild_df'></span>

<h3>Description</h3>

<p>Function to calculate the kernel mean embedding for to distributional data
sets. It uses the empirical approximation for the integral
</p>
<p style="text-align: center;"><code class="reqn">\int_{\mathcal X} \int_{\mathcal Y} K(x, y) d P_X d Q_Y </code>
</p>
<p> for a given
kernel <code class="reqn">K(\cdot, \cdot)</code>. Currently only supports radial basis function
kernel for fast computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
kme(df, df2 = NULL, sigma = 0.05, ...)

## S3 method for class 'mild_df'
kme(df, df2 = NULL, sigma = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kme_+3A_df">df</code></td>
<td>
<p>A data.frame of <code>mild_df</code> object, must have column
<code>'instance_name'</code> which defines the instances.</p>
</td></tr>
<tr><td><code id="kme_+3A_df2">df2</code></td>
<td>
<p>A data.frame, <code>mild_df</code> object, or <code>NULL</code> (default <code>NULL</code>).</p>
</td></tr>
<tr><td><code id="kme_+3A_sigma">sigma</code></td>
<td>
<p>The parameter for <code>'radial'</code> kernel (default <code>0.05</code>).</p>
</td></tr>
<tr><td><code id="kme_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>df2 = NULL</code>, calculate the kernel mean embedding matrix of (<code>df</code>, <code>df</code>)
otherwise calculate (<code>df</code>, <code>df2</code>)
</p>


<h3>Value</h3>

<p>A matrix of kernel mean embedding at the instance level.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default S3 method
</p>
</li>
<li> <p><code>mild_df</code>: S3 method for class <code>mild_df</code>
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Yifei Liu, Sean Kent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = data.frame('instance_name' = c('inst_1', 'inst_2', 'inst_1'),
               'X1' = c(-0.4, 0.5, 2))
kme(x)

mild_df1 &lt;- generate_mild_df(nbag = 10, positive_degree = 3)
kme(mild_df1)

</code></pre>

<hr>
<h2 id='mi'>Create an <code>mi</code> object</h2><span id='topic+mi'></span>

<h3>Description</h3>

<p>Create an <code>mi</code> object, usually used as a response variable in a model
formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi(bag_label, bag_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mi_+3A_bag_label">bag_label</code></td>
<td>
<p>The bag label or response, recorded as 0 = negative, 1 =
positive.</p>
</td></tr>
<tr><td><code id="mi_+3A_bag_name">bag_name</code></td>
<td>
<p>A unique bag identifier for each instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>mi</code>.  Currently, no methods are implemented for
this.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p>Other multiple instance formula helper functions: 
<code><a href="#topic+mild">mild</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mil_data &lt;- generate_mild_df(positive_degree = 3, nbag = 10)
with(mil_data, head(mi(bag_label, bag_name)))
df &lt;- get_all_vars(mi(bag_label, bag_name) ~ X1 + X2, data = mil_data)
head(df)

</code></pre>

<hr>
<h2 id='mi_df'>Build a multiple instance (MI) data frame</h2><span id='topic+mi_df'></span>

<h3>Description</h3>

<p><code>mi_df()</code> constructs a data frame that corresponds to Multiple Instance (MI)
data.  A <code>mi_df</code> object must have two special columns:
</p>

<ul>
<li> <p><code>bag_label</code>, determines the label of each bag, typically from <code>c(0, 1)</code>
</p>
</li>
<li> <p><code>bag_name</code>, character or factor that specifies the bag that each sample
belongs to.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>mi_df(
  bag_label = character(),
  bag_name = character(),
  ...,
  instance_label = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mi_df_+3A_bag_label">bag_label</code></td>
<td>
<p>A <code>character</code>, <code>factor</code>, or <code>numeric</code> vector.</p>
</td></tr>
<tr><td><code id="mi_df_+3A_bag_name">bag_name</code></td>
<td>
<p>A <code>character</code> or <code>factor</code> vector.</p>
</td></tr>
<tr><td><code id="mi_df_+3A_...">...</code></td>
<td>
<p>A set of name-value pairs. These construct the covariates for a
<code>mi_df</code>.</p>
</td></tr>
<tr><td><code id="mi_df_+3A_instance_label">instance_label</code></td>
<td>
<p>A <code>character</code>, <code>factor</code>, or <code>numeric</code> vector, or
<code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We refer to the rows of a <code>mi_df</code> as <em>instances</em>. Each instance is
contained in a bag, with a corresponding label. Bags will typically have
several instances within them. Instance labels can be provided, but they will
be pulled in as an attribute.
</p>


<h3>Value</h3>

<p>A 'mi_df' object. This data.frame-like has columns <code>bag_label</code>,
<code>bag_name</code>, and those specified in <code>...</code>. It also inherits from the
<code>'tbl_df'</code> and <code>'tbl'</code> classes.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+as_mi_df">as_mi_df()</a></code> to convert data.frames to <code>mi_df</code>s.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>mi_df('bag_label' = factor(c(1, 1, 0)),
      'bag_name' = c(rep('bag_1', 2), 'bag_2'),
      'X1' = c(-0.4, 0.5, 2),
      'instance_label' = c(0, 1, 0))

</code></pre>

<hr>
<h2 id='mild'>Create a mild object</h2><span id='topic+mild'></span>

<h3>Description</h3>

<p>Create a <code>mild</code> object, usually used as a response variable in a model
formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mild(bag_label, bag_name, instance_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mild_+3A_bag_label">bag_label</code></td>
<td>
<p>The bag label or response, recorded as 0 = negative, 1 =
positive.</p>
</td></tr>
<tr><td><code id="mild_+3A_bag_name">bag_name</code></td>
<td>
<p>A unique bag identifier for each instance.</p>
</td></tr>
<tr><td><code id="mild_+3A_instance_name">instance_name</code></td>
<td>
<p>A unique instance identifier for each sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>mild</code>.  Currently, no methods are implemented for
this.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p>Other multiple instance formula helper functions: 
<code><a href="#topic+mi">mi</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mil_data &lt;- generate_mild_df(positive_degree = 3, nbag = 10)
with(mil_data, head(mild(bag_label, bag_name, instance_name)))
df &lt;- get_all_vars(mild(bag_label, bag_name) ~ X1 + X2, data = mil_data)
head(df)

</code></pre>

<hr>
<h2 id='mild_df'>Build a MILD data frame</h2><span id='topic+mild_df'></span>

<h3>Description</h3>

<p><code>mild_df()</code> constructs a data frame that corresponds to Multiple Instance
Learning with Distributional Instances (MILD) data.  A <code>mild_df</code> object must
have three special columns:
</p>

<ul>
<li> <p><code>bag_label</code>, determines the label of each bag, typically from <code>c(0, 1)</code>
</p>
</li>
<li> <p><code>bag_name</code>, character or factor that specifies the bag that each sample
belongs to.
</p>
</li>
<li> <p><code>instance_name</code>, character or factor that specifies the instance that
each sample belongs to.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>mild_df(
  bag_label = character(),
  bag_name = character(),
  instance_name = character(),
  ...,
  instance_label = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mild_df_+3A_bag_label">bag_label</code></td>
<td>
<p>A <code>character</code>, <code>factor</code>, or <code>numeric</code> vector.</p>
</td></tr>
<tr><td><code id="mild_df_+3A_bag_name">bag_name</code></td>
<td>
<p>A <code>character</code> or <code>factor</code> vector.</p>
</td></tr>
<tr><td><code id="mild_df_+3A_instance_name">instance_name</code></td>
<td>
<p>A <code>character</code> or <code>factor</code> vector.</p>
</td></tr>
<tr><td><code id="mild_df_+3A_...">...</code></td>
<td>
<p>A set of name-value pairs. These construct the covariates for a
<code>mild_df</code>.</p>
</td></tr>
<tr><td><code id="mild_df_+3A_instance_label">instance_label</code></td>
<td>
<p>A <code>character</code>, <code>factor</code>, or <code>numeric</code> vector, or
<code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We refer to the rows of a <code>mild_df</code> as <em>samples</em>, since they are
thought of as draws from the distribution that determines each instance.
Each instance is contained in a bag, with a corresponding label.  Instance
labels can be provided, but they will be pulled in as an attribute.
</p>


<h3>Value</h3>

<p>A 'mild_df' object. This data.frame-like has columns <code>bag_label</code>,
<code>bag_name</code>, <code>instance_name</code>, and those specified in <code>...</code>. It also inherits
from the <code>'tbl_df'</code> and <code>'tbl'</code> classes.
</p>


<h3>Author(s)</h3>

<p>Yifei Liu, Sean Kent
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+as_mild_df">as_mild_df()</a></code> to convert data.frames to <code>mild_df</code>s.
</p>
</li>
<li> <p><code><a href="#topic+generate_mild_df">generate_mild_df()</a></code> for simulating a <code>mild_df</code> object.
</p>
</li>
<li> <p><code><a href="#topic+summarize_samples">summarize_samples()</a></code> for summarizing the <code>mild_df</code> into a multiple
instance learning data set.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>mild_df('bag_label' = factor(c(1, 1, 0)),
        'bag_name' = c(rep('bag_1', 2), 'bag_2'),
        'instance_name' = c('bag_1_inst_1', 'bag_1_inst_2', 'bag_2_inst_1'),
        'X1' = c(-0.4, 0.5, 2),
        'instance_label' = c(0, 1, 0))

</code></pre>

<hr>
<h2 id='mior'>Fit MIOR model to the data</h2><span id='topic+mior'></span><span id='topic+mior.default'></span><span id='topic+mior.formula'></span><span id='topic+mior.mi_df'></span>

<h3>Description</h3>

<p>This function fits the MIOR model, proposed by Xiao Y, Liu B, and Hao Z
(2018) in &quot;Multiple-instance Ordinal Regression&quot;.  MIOR is a modified SVM
framework with parallel, ordered hyperplanes where the error terms are based
only on the instance closest to a midpoint between hyperplanes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
mior(
  x,
  y,
  bags,
  cost = 1,
  cost_eta = 1,
  method = "qp-heuristic",
  weights = NULL,
  control = list(kernel = "linear", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    max_step = 500, scale = TRUE, verbose = FALSE, time_limit = 60, option =
    c("corrected", "xiao")),
  ...
)

## S3 method for class 'formula'
mior(formula, data, ...)

## S3 method for class 'mi_df'
mior(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mior_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents an instance. If a <code>mi_df</code> object is passed, <code style="white-space: pre;">&#8288;y, bags&#8288;</code> are
automatically extracted, and all other columns will be used as predictors.</p>
</td></tr>
<tr><td><code id="mior_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="mior_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="mior_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM. If <code>method = 'heuristic'</code>, this will
be fed to <code>kernlab::ksvm()</code>, otherwise it is similarly in internal
functions.</p>
</td></tr>
<tr><td><code id="mior_+3A_cost_eta">cost_eta</code></td>
<td>
<p>The additional cost parameter in MIOR which controls how far
away the first and last separating hyperplanes are relative to other costs.</p>
</td></tr>
<tr><td><code id="mior_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, which employs an algorithm similar to Andrews et
al. (2003). When <code>method = 'mip'</code>, the novel MIP method will be used.  When
<code style="white-space: pre;">&#8288;method = 'qp-heuristic&#8288;</code>, the heuristic algorithm is computed using the
dual SVM.  See details.</p>
</td></tr>
<tr><td><code id="mior_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="mior_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>option</code> argument the controls the constraint calculation.  See details.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mior_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="mior_+3A_formula">formula</code></td>
<td>
<p>a formula with specification <code>mi(y, bags) ~ x</code> which uses the
<code>mi</code> function to create the bag-instance structure. This argument is an
alternative to the <code style="white-space: pre;">&#8288;x, y, bags&#8288;</code> arguments, but requires the <code>data</code>
argument. See examples.</p>
</td></tr>
<tr><td><code id="mior_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions (see <code><a href="#topic+predict.mior">predict.mior()</a></code>) are determined by considering the smallest
distance from each point to the midpoint hyperplanes across all instances in
the bag.  The prediction corresponds to the hyperplane having such a minimal
distance.
</p>
<p>It appears as though an error in Equation (12) persists to the dual form in
(21). A corrected version of this dual formulation can be used with
<code>control$option = 'corrected'</code>, or the formulation as written can be used
with <code>control$option = 'xiao'</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>mior</code>  The object contains at least the following
components:
</p>

<ul>
<li> <p><code>gurobi_fit</code>: A fit from model optimization that includes relevant
components.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>misvm()</code> was called
with.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>weights</code>: The calculated weights on the <code>cost</code> parameter.
</p>
</li>
<li> <p><code>repr_inst</code>: The instances from positive bags that are selected to be
most representative of the positive instances.
</p>
</li>
<li> <p><code>n_step</code>: If <code>method %in% c('heuristic', 'qp-heuristic')</code>, the total
steps used in the heuristic algorithm.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>References</h3>

<p>Xiao, Y., Liu, B., &amp; Hao, Z. (2017). Multiple-instance ordinal
regression. <em>IEEE Transactions on Neural Networks and Learning Systems</em>,
<em>29</em>(9), 4398-4413. doi: <a href="https://doi.org/10.1109/TNNLS.2017.2766164">10.1109/TNNLS.2017.2766164</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.misvm">predict.misvm()</a></code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require(gurobi)) {
  set.seed(8)
  # make some data
  n &lt;- 15
  X &lt;- rbind(
    mvtnorm::rmvnorm(n/3, mean = c(4, -2, 0)),
    mvtnorm::rmvnorm(n/3, mean = c(0, 0, 0)),
    mvtnorm::rmvnorm(n/3, mean = c(-2, 1, 0))
  )
  score &lt;- X %*% c(2, -1, 0)
  y &lt;- as.numeric(cut(score, c(-Inf, quantile(score, probs = 1:2 / 3), Inf)))
  bags &lt;- 1:length(y)

  # add in points outside boundaries
  X &lt;- rbind(
    X,
    mvtnorm::rmvnorm(n, mean = c(6, -3, 0)),
    mvtnorm::rmvnorm(n, mean = c(-6, 3, 0))
  )
  y &lt;- c(y, rep(-1, 2*n))
  bags &lt;- rep(bags, 3)
  repr &lt;- c(rep(1, n), rep(0, 2*n))

  y_bag &lt;- classify_bags(y, bags, condense = FALSE)

  mdl1 &lt;- mior(X, y_bag, bags)
  predict(mdl1, X, new_bags = bags)
}

</code></pre>

<hr>
<h2 id='mismm'>Fit MILD-SVM model to the data</h2><span id='topic+mismm'></span><span id='topic+mismm.default'></span><span id='topic+mismm.formula'></span><span id='topic+mismm.mild_df'></span>

<h3>Description</h3>

<p>This function fits the MILD-SVM model, which takes a multiple-instance
learning with distributions (MILD) data set and fits a modified SVM to it.
The MILD-SVM methodology is based on research in progress.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
mismm(
  x,
  y,
  bags,
  instances,
  cost = 1,
  method = c("heuristic", "mip", "qp-heuristic"),
  weights = TRUE,
  control = list(kernel = "radial", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    nystrom_args = list(m = nrow(x), r = nrow(x), sampling = "random"), max_step = 500,
    scale = TRUE, verbose = FALSE, time_limit = 60, start = FALSE),
  ...
)

## S3 method for class 'formula'
mismm(formula, data, ...)

## S3 method for class 'mild_df'
mismm(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mismm_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents a sample. If a <code>mild_df</code> object is passed, <code style="white-space: pre;">&#8288;y, bags, instances&#8288;</code> are automatically extracted, and all other columns will be used
as predictors.</p>
</td></tr>
<tr><td><code id="mismm_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="mismm_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="mismm_+3A_instances">instances</code></td>
<td>
<p>A vector specifying which samples belong to each instance.
Can be a string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="mismm_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM. If <code>method = 'heuristic'</code>, this will
be fed to <code>kernlab::ksvm()</code>, otherwise it is similarly in internal
functions.</p>
</td></tr>
<tr><td><code id="mismm_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, the algorithm iterates between selecting positive
witnesses and solving an underlying <code><a href="#topic+smm">smm()</a></code> problem.  When <code>method = 'mip'</code>, the novel MIP method will be used.  When <code>method = 'qp-heuristic'</code>,
the heuristic algorithm is computed using a slightly modified dual SMM.
See details</p>
</td></tr>
<tr><td><code id="mismm_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="mismm_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>nystrom_args</code> a list of parameters to pass to <code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code>. This is
used when <code>method = 'mip'</code> and <code>kernel = 'radial'</code> to generate a Nystrom
approximation of the kernel features.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>start</code> argument used when <code>method = 'mip'</code>.  If <code>TRUE</code>, the mip program
will be warm_started with the solution from <code>method = 'qp-heuristic'</code> to
potentially improve speed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mismm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="mismm_+3A_formula">formula</code></td>
<td>
<p>A formula with specification <code>mild(y, bags, instances) ~ x</code>
which uses the <code>mild</code> function to create the bag-instance structure. This
argument is an alternative to the <code style="white-space: pre;">&#8288;x, y, bags, instances &#8288;</code> arguments, but
requires the <code>data</code> argument. See examples.</p>
</td></tr>
<tr><td><code id="mismm_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several choices of fitting algorithm are available, including a version of
the heuristic algorithm proposed by Andrews et al. (2003) and a novel
algorithm that explicitly solves the mixed-integer programming (MIP) problem
using the gurobi package optimization back-end.
</p>


<h3>Value</h3>

<p>An object of class <code>mismm</code>  The object contains at least the
following components:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;*_fit&#8288;</code>: A fit object depending on the <code>method</code> parameter.  If <code>method =   'heuristic'</code>, this will be a <code>ksvm</code> fit from the kernlab package.  If
<code>method = 'mip'</code> this will be <code>gurobi_fit</code> from a model optimization.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>misvm()</code> was called
with.
</p>
</li>
<li> <p><code>x</code>: The training data needed for computing the kernel matrix in
prediction.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>weights</code>: The calculated weights on the <code>cost</code> parameter.
</p>
</li>
<li> <p><code>sigma</code>: The radial basis function kernel parameter.
</p>
</li>
<li> <p><code>repr_inst</code>: The instances from positive bags that are selected to be
most representative of the positive instances.
</p>
</li>
<li> <p><code>n_step</code>: If <code>method %in% c('heuristic', 'qp-heuristic')</code>, the total
steps used in the heuristic algorithm.
</p>
</li>
<li> <p><code>useful_inst_idx</code>: The instances that were selected to represent the bags
in the heuristic fitting.
</p>
</li>
<li> <p><code>inst_order</code>: A character vector that is used to modify the ordering of
input data.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mild_df</code>: Method for <code>mild_df</code> objects
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent, Yifei Liu
</p>


<h3>References</h3>

<p>Kent, S., &amp; Yu, M. (2022). Non-convex SVM for cancer diagnosis
based on morphologic features of tumor microenvironment <em>arXiv preprint</em>
<a href="https://arxiv.org/abs/2206.14704">arXiv:2206.14704</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.mismm">predict.mismm()</a></code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
mil_data &lt;- generate_mild_df(nbag = 15, nsample = 20, positive_prob = 0.15,
                             sd_of_mean = rep(0.1, 3))

# Heuristic method
mdl1 &lt;- mismm(mil_data)
mdl2 &lt;- mismm(mild(bag_label, bag_name, instance_name) ~ X1 + X2 + X3, data = mil_data)

# MIP method
if (require(gurobi)) {
  mdl3 &lt;- mismm(mil_data, method = "mip", control = list(nystrom_args = list(m = 10, r = 10)))
  predict(mdl3, mil_data)
}

predict(mdl1, new_data = mil_data, type = "raw", layer = "bag")

# summarize predictions at the bag layer
library(dplyr)
mil_data %&gt;%
  bind_cols(predict(mdl2, mil_data, type = "class")) %&gt;%
  bind_cols(predict(mdl2, mil_data, type = "raw")) %&gt;%
  distinct(bag_name, bag_label, .pred_class, .pred)


</code></pre>

<hr>
<h2 id='misvm'>Fit MI-SVM model to the data</h2><span id='topic+misvm'></span><span id='topic+misvm.default'></span><span id='topic+misvm.formula'></span><span id='topic+misvm.mi_df'></span><span id='topic+misvm.mild_df'></span>

<h3>Description</h3>

<p>This function fits the MI-SVM model, first proposed by Andrews et al. (2003).
It is a variation on the traditional SVM framework that carefully treats data
from the multiple instance learning paradigm, where instances are grouped
into bags, and a label is only available for each bag.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
misvm(
  x,
  y,
  bags,
  cost = 1,
  method = c("heuristic", "mip", "qp-heuristic"),
  weights = TRUE,
  control = list(kernel = "linear", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    nystrom_args = list(m = nrow(x), r = nrow(x), sampling = "random"), max_step = 500,
    type = "C-classification", scale = TRUE, verbose = FALSE, time_limit = 60, start =
    FALSE),
  ...
)

## S3 method for class 'formula'
misvm(formula, data, ...)

## S3 method for class 'mi_df'
misvm(x, ...)

## S3 method for class 'mild_df'
misvm(x, .fns = list(mean = mean, sd = stats::sd), cor = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="misvm_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents an instance. If a <code>mi_df</code> object is passed, <code style="white-space: pre;">&#8288;y, bags&#8288;</code> are
automatically extracted, and all other columns will be used as predictors.
If a <code>mild_df</code> object is passed, <code style="white-space: pre;">&#8288;y, bags, instances&#8288;</code> are automatically
extracted, and all other columns will be used as predictors.</p>
</td></tr>
<tr><td><code id="misvm_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="misvm_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="misvm_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM. If <code>method = 'heuristic'</code>, this will
be fed to <code>kernlab::ksvm()</code>, otherwise it is similarly in internal
functions.</p>
</td></tr>
<tr><td><code id="misvm_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, which employs an algorithm similar to Andrews et
al. (2003). When <code>method = 'mip'</code>, the novel MIP method will be used.  When
<code style="white-space: pre;">&#8288;method = 'qp-heuristic&#8288;</code>, the heuristic algorithm is computed using the
dual SVM.  See details.</p>
</td></tr>
<tr><td><code id="misvm_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="misvm_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>nystrom_args</code> a list of parameters to pass to <code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code>. This is
used when <code>method = 'mip'</code> and <code>kernel = 'radial'</code> to generate a Nystrom
approximation of the kernel features.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>type</code>: argument used when <code>method = 'heuristic'</code>. The <code>type</code> argument is
passed to <code>e1071::svm()</code>.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>start</code> argument used when <code>method = 'mip'</code>.  If <code>TRUE</code>, the mip program
will be warm_started with the solution from <code>method = 'qp-heuristic'</code> to
potentially improve speed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="misvm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="misvm_+3A_formula">formula</code></td>
<td>
<p>a formula with specification <code>mi(y, bags) ~ x</code> which uses the
<code>mi</code> function to create the bag-instance structure. This argument is an
alternative to the <code style="white-space: pre;">&#8288;x, y, bags&#8288;</code> arguments, but requires the <code>data</code>
argument. See examples.</p>
</td></tr>
<tr><td><code id="misvm_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted.</p>
</td></tr>
<tr><td><code id="misvm_+3A_.fns">.fns</code></td>
<td>
<p>(argument for <code>misvm.mild_df()</code> method) list of functions to
summarize instances over.</p>
</td></tr>
<tr><td><code id="misvm_+3A_cor">cor</code></td>
<td>
<p>(argument for <code>misvm.mild_df()</code> method) logical, whether to
include correlations between all features in the summarization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several choices of fitting algorithm are available, including a version of
the heuristic algorithm proposed by Andrews et al. (2003) and a novel
algorithm that explicitly solves the mixed-integer programming (MIP) problem
using the gurobi package optimization back-end.
</p>


<h3>Value</h3>

<p>An object of class <code>misvm.</code>  The object contains at least the
following components:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;*_fit&#8288;</code>: A fit object depending on the <code>method</code> parameter.  If <code>method =   'heuristic'</code>, this will be an <code>svm</code> fit from the e1071 package.  If
<code style="white-space: pre;">&#8288;method = 'mip', 'qp-heuristic'&#8288;</code> this will be <code>gurobi_fit</code> from a model
optimization.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>misvm()</code> was called
with.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>weights</code>: The calculated weights on the <code>cost</code> parameter.
</p>
</li>
<li> <p><code>repr_inst</code>: The instances from positive bags that are selected to be
most representative of the positive instances.
</p>
</li>
<li> <p><code>n_step</code>: If <code>method %in% c('heuristic', 'qp-heuristic')</code>, the total
steps used in the heuristic algorithm.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates.
</p>
</li>
<li> <p><code>mild_df</code>: Method for <code>mild_df</code> objects. Summarize samples to the
instance level based on specified functions, then perform <code>misvm()</code> on
instance level data.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent, Yifei Liu
</p>


<h3>References</h3>

<p>Andrews, S., Tsochantaridis, I., &amp; Hofmann, T. (2002). Support
vector machines for multiple-instance learning. <em>Advances in neural
information processing systems</em>, <em>15</em>.
</p>
<p>Kent, S., &amp; Yu, M. (2022). Non-convex SVM for cancer diagnosis based on
morphologic features of tumor microenvironment <em>arXiv preprint</em>
<a href="https://arxiv.org/abs/2206.14704">arXiv:2206.14704</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+predict.misvm">predict.misvm()</a></code> for prediction on new data.
</p>
</li>
<li> <p><code><a href="#topic+cv_misvm">cv_misvm()</a></code> for cross-validation fitting.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
mil_data &lt;- generate_mild_df(nbag = 20,
                             positive_prob = 0.15,
                             sd_of_mean = rep(0.1, 3))
df &lt;- build_instance_feature(mil_data, seq(0.05, 0.95, length.out = 10))

# Heuristic method
mdl1 &lt;- misvm(x = df[, 4:123], y = df$bag_label,
              bags = df$bag_name, method = "heuristic")
mdl2 &lt;- misvm(mi(bag_label, bag_name) ~ X1_mean + X2_mean + X3_mean, data = df)

# MIP method
if (require(gurobi)) {
  mdl3 &lt;- misvm(x = df[, 4:123], y = df$bag_label,
                bags = df$bag_name, method = "mip")
}

predict(mdl1, new_data = df, type = "raw", layer = "bag")

# summarize predictions at the bag layer
library(dplyr)
df %&gt;%
  bind_cols(predict(mdl2, df, type = "class")) %&gt;%
  bind_cols(predict(mdl2, df, type = "raw")) %&gt;%
  distinct(bag_name, bag_label, .pred_class, .pred)


</code></pre>

<hr>
<h2 id='misvm_orova'>Fit MI-SVM model to ordinal outcome data using One-vs-All</h2><span id='topic+misvm_orova'></span><span id='topic+misvm_orova.default'></span><span id='topic+misvm_orova.formula'></span><span id='topic+misvm_orova.mi_df'></span>

<h3>Description</h3>

<p>This function uses the one-vs-all multiclass classification strategy to fit a
series of MI-SVM models for predictions on ordinal outcome data.  For an
ordinal outcome with K levels, we fit K MI-SVM models to predict an
individual level vs not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
misvm_orova(
  x,
  y,
  bags,
  cost = 1,
  method = c("heuristic", "mip", "qp-heuristic"),
  weights = TRUE,
  control = list(kernel = "linear", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    nystrom_args = list(m = nrow(x), r = nrow(x), sampling = "random"), max_step = 500,
    type = "C-classification", scale = TRUE, verbose = FALSE, time_limit = 60, start =
    FALSE),
  ...
)

## S3 method for class 'formula'
misvm_orova(formula, data, ...)

## S3 method for class 'mi_df'
misvm_orova(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="misvm_orova_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents an instance. If a <code>mi_df</code> object is passed, <code style="white-space: pre;">&#8288;y, bags&#8288;</code> are
automatically extracted, and all other columns will be used as predictors.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM. If <code>method = 'heuristic'</code>, this will
be fed to <code>kernlab::ksvm()</code>, otherwise it is similarly in internal
functions.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, which employs an algorithm similar to Andrews et
al. (2003). When <code>method = 'mip'</code>, the novel MIP method will be used.  When
<code style="white-space: pre;">&#8288;method = 'qp-heuristic&#8288;</code>, the heuristic algorithm is computed using the
dual SVM.  See details.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>nystrom_args</code> a list of parameters to pass to <code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code>. This is
used when <code>method = 'mip'</code> and <code>kernel = 'radial'</code> to generate a Nystrom
approximation of the kernel features.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>type</code>: argument used when <code>method = 'heuristic'</code>. The <code>type</code> argument is
passed to <code>e1071::svm()</code>.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>start</code> argument used when <code>method = 'mip'</code>.  If <code>TRUE</code>, the mip program
will be warm_started with the solution from <code>method = 'qp-heuristic'</code> to
potentially improve speed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="misvm_orova_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_formula">formula</code></td>
<td>
<p>a formula with specification <code>mi(y, bags) ~ x</code> which uses the
<code>mi</code> function to create the bag-instance structure. This argument is an
alternative to the <code style="white-space: pre;">&#8288;x, y, bags&#8288;</code> arguments, but requires the <code>data</code>
argument. See examples.</p>
</td></tr>
<tr><td><code id="misvm_orova_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>misvm_orova</code>  The object contains at least the
following components:
</p>

<ul>
<li> <p><code>fits</code>: a list of <code>misvm</code> objects with length equal to the number of
classes in <code>y</code>. See <code><a href="#topic+misvm">misvm()</a></code> for details on the <code>misvm</code> object.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>misvm_orova()</code> was
called with.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>References</h3>

<p>Andrews, S., Tsochantaridis, I., &amp; Hofmann, T. (2002). Support
vector machines for multiple-instance learning. <em>Advances in neural
information processing systems</em>, <em>15</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.misvm_orova">predict.misvm_orova()</a></code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ordmvnorm")
x &lt;- ordmvnorm[, 3:7]
y &lt;- ordmvnorm$bag_label
bags &lt;- ordmvnorm$bag_name

mdl1 &lt;- misvm_orova(x, y, bags)
predict(mdl1, x, new_bags = bags)

</code></pre>

<hr>
<h2 id='omisvm'>Fit MI-SVM-OR model to ordinal outcome data</h2><span id='topic+omisvm'></span><span id='topic+omisvm.default'></span><span id='topic+omisvm.formula'></span><span id='topic+omisvm.mi_df'></span>

<h3>Description</h3>

<p>This function fits a modification of MI-SVM to ordinal outcome data based on
the research method proposed by Kent and Yu.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
omisvm(
  x,
  y,
  bags,
  cost = 1,
  h = 1,
  s = Inf,
  method = c("qp-heuristic"),
  weights = TRUE,
  control = list(kernel = "linear", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    max_step = 500, type = "C-classification", scale = TRUE, verbose = FALSE, time_limit
    = 60),
  ...
)

## S3 method for class 'formula'
omisvm(formula, data, ...)

## S3 method for class 'mi_df'
omisvm(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="omisvm_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents an instance. If a <code>mi_df</code> object is passed, <code style="white-space: pre;">&#8288;y, bags&#8288;</code> are
automatically extracted, and all other columns will be used as predictors.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_bags">bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM. If <code>method = 'heuristic'</code>, this will
be fed to <code>kernlab::ksvm()</code>, otherwise it is similarly in internal
functions.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_h">h</code></td>
<td>
<p>A scalar that controls the trade-off between maximizing the margin
and minimizing distance between hyperplanes.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_s">s</code></td>
<td>
<p>An integer for how many replication points to add to the dataset. If
<code>k</code> represents the number of labels in y, must have <code style="white-space: pre;">&#8288;1 &lt;= s &lt;= k-1&#8288;</code>. The
default, <code>Inf</code>, uses the maximum number of replication points, <code>k-1</code>.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, which employs an algorithm similar to Andrews et
al. (2003). When <code>method = 'mip'</code>, the novel MIP method will be used.  When
<code style="white-space: pre;">&#8288;method = 'qp-heuristic&#8288;</code>, the heuristic algorithm is computed using the
dual SVM.  See details.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>nystrom_args</code> a list of parameters to pass to <code><a href="#topic+kfm_nystrom">kfm_nystrom()</a></code>. This is
used when <code>method = 'mip'</code> and <code>kernel = 'radial'</code> to generate a Nystrom
approximation of the kernel features.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>type</code>: argument used when <code>method = 'heuristic'</code>. The <code>type</code> argument is
passed to <code>e1071::svm()</code>.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>start</code> argument used when <code>method = 'mip'</code>.  If <code>TRUE</code>, the mip program
will be warm_started with the solution from <code>method = 'qp-heuristic'</code> to
potentially improve speed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="omisvm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_formula">formula</code></td>
<td>
<p>a formula with specification <code>mi(y, bags) ~ x</code> which uses the
<code>mi</code> function to create the bag-instance structure. This argument is an
alternative to the <code style="white-space: pre;">&#8288;x, y, bags&#8288;</code> arguments, but requires the <code>data</code>
argument. See examples.</p>
</td></tr>
<tr><td><code id="omisvm_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, the only method available is a heuristic algorithm in linear SVM
space. Additional methods should be available shortly.
</p>


<h3>Value</h3>

<p>An object of class <code>omisvm.</code>  The object contains at least the
following components:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;*_fit&#8288;</code>: A fit object depending on the <code>method</code> parameter.  If <code>method =   'qp-heuristic'</code> this will be <code>gurobi_fit</code> from a model optimization.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>omisvm()</code> was called
with.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>weights</code>: The calculated weights on the <code>cost</code> parameter.
</p>
</li>
<li> <p><code>repr_inst</code>: The instances from positive bags that are selected to be
most representative of the positive instances.
</p>
</li>
<li> <p><code>n_step</code>: If <code>method == 'qp-heuristic'</code>, the total steps used in the
heuristic algorithm.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.omisvm">predict.omisvm()</a></code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require(gurobi)) {
  data("ordmvnorm")
  x &lt;- ordmvnorm[, 3:7]
  y &lt;- ordmvnorm$bag_label
  bags &lt;- ordmvnorm$bag_name

  mdl1 &lt;- omisvm(x, y, bags, weights = NULL)
  predict(mdl1, x, new_bags = bags)
}

</code></pre>

<hr>
<h2 id='ordmvnorm'>Sample ordinal MIL data using mvnorm</h2><span id='topic+ordmvnorm'></span>

<h3>Description</h3>

<p>A data set that demonstrates the ordinal multiple-instance learning
structure with feature columns randomly sampled from a multivariate normal
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordmvnorm
</code></pre>


<h3>Format</h3>

<p>An MI data frame with 1000 rows 8 variables, and 5 bags. Instance
labels can be accessed via <code>attr(ordmvnorm, "instance_label")</code>.
</p>

<dl>
<dt>bag_label</dt><dd><p>outcome label at the bag level. This is the maximum of the <code>inst_label</code> for each bag</p>
</dd>
<dt>bag_name</dt><dd><p>indicator of each bag</p>
</dd>
<dt>V1</dt><dd><p>Variable with mean equal to <code>2 * inst_label</code></p>
</dd>
<dt>V2</dt><dd><p>Variable with mean equal to <code>-1 * inst_label</code></p>
</dd>
<dt>V3</dt><dd><p>Variable with mean equal to <code>1 * inst_label</code></p>
</dd>
<dt>V4</dt><dd><p>Variable with mean 0, essentially noise</p>
</dd>
<dt>V5</dt><dd><p>Variable with mean 0, essentially noise</p>
</dd>
</dl>


<hr>
<h2 id='predict.cv_misvm'>Predict method for <code>cv_misvm</code> object</h2><span id='topic+predict.cv_misvm'></span>

<h3>Description</h3>

<p>Predict method for <code>cv_misvm</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv_misvm'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("bag", "instance"),
  new_bags = "bag_name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv_misvm_+3A_object">object</code></td>
<td>
<p>An object of class <code>cv_misvm</code>.</p>
</td></tr>
<tr><td><code id="predict.cv_misvm_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.cv_misvm_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.cv_misvm_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.cv_misvm_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.cv_misvm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column '.pred_class'.  If <code>type = 'raw'</code>, the tibble will have
a column '.pred'.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mil_data &lt;- generate_mild_df(
  nbag = 10,
  nsample = 20,
  positive_degree = 3
)
df1 &lt;- build_instance_feature(mil_data, seq(0.05, 0.95, length.out = 10))
mdl1 &lt;- cv_misvm(x = df1[, 4:123], y = df1$bag_label,
                 bags = df1$bag_name, cost_seq = 2^(-2:2),
                 n_fold = 3, method = "heuristic")

predict(mdl1, new_data = df1, type = "raw", layer = "bag")

# summarize predictions at the bag layer
suppressWarnings(library(dplyr))
df1 %&gt;%
  bind_cols(predict(mdl1, df1, type = "class")) %&gt;%
  bind_cols(predict(mdl1, df1, type = "raw")) %&gt;%
  distinct(bag_name, bag_label, .pred_class, .pred)

</code></pre>

<hr>
<h2 id='predict.mior'>Predict method for <code>mior</code> object</h2><span id='topic+predict.mior'></span>

<h3>Description</h3>

<p>Predict method for <code>mior</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mior'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("bag", "instance"),
  new_bags = "bag_name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.mior_+3A_object">object</code></td>
<td>
<p>An object of class <code>mior</code></p>
</td></tr>
<tr><td><code id="predict.mior_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.mior_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.mior_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.mior_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.mior_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the parameters
<code>new_bags</code> and <code>new_instances</code> are not necessary, as long as the names match
the original function call.
</p>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will have
a column <code>.pred</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mior">mior()</a></code> for fitting the <code>mior</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require(gurobi)) {
  set.seed(8)
  # make some data
  n &lt;- 15
  X &lt;- rbind(
    mvtnorm::rmvnorm(n/3, mean = c(4, -2, 0)),
    mvtnorm::rmvnorm(n/3, mean = c(0, 0, 0)),
    mvtnorm::rmvnorm(n/3, mean = c(-2, 1, 0))
  )
  score &lt;- X %*% c(2, -1, 0)
  y &lt;- as.numeric(cut(score, c(-Inf, quantile(score, probs = 1:2 / 3), Inf)))
  bags &lt;- 1:length(y)

  # add in points outside boundaries
  X &lt;- rbind(
    X,
    mvtnorm::rmvnorm(n, mean = c(6, -3, 0)),
    mvtnorm::rmvnorm(n, mean = c(-6, 3, 0))
  )
  y &lt;- c(y, rep(-1, 2*n))
  bags &lt;- rep(bags, 3)
  repr &lt;- c(rep(1, n), rep(0, 2*n))

  y_bag &lt;- classify_bags(y, bags, condense = FALSE)

  mdl1 &lt;- mior(X, y_bag, bags)
  # summarize predictions at the bag layer
  library(dplyr)
  df1 &lt;- bind_cols(y = y_bag, bags = bags, as.data.frame(X))
  df1 %&gt;%
    bind_cols(predict(mdl1, df1, new_bags = bags, type = "class")) %&gt;%
    bind_cols(predict(mdl1, df1, new_bags = bags, type = "raw")) %&gt;%
    distinct(y, bags, .pred_class, .pred)
}

</code></pre>

<hr>
<h2 id='predict.mismm'>Predict method for <code>mismm</code> object</h2><span id='topic+predict.mismm'></span>

<h3>Description</h3>

<p>Predict method for <code>mismm</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mismm'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("bag", "instance"),
  new_bags = "bag_name",
  new_instances = "instance_name",
  kernel = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.mismm_+3A_object">object</code></td>
<td>
<p>An object of class <code>mismm</code>.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_new_instances">new_instances</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the instance names in
<code>new_data</code> (default <code>'instance_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has instance name for each row.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_kernel">kernel</code></td>
<td>
<p>An optional pre-computed kernel matrix at the instance level or
<code>NULL</code> (default <code>NULL</code>). The rows should correspond to instances in the new
data to predict, and columns should correspond to instances in the original
training data, such as a call to <code><a href="#topic+kme">kme()</a></code>.</p>
</td></tr>
<tr><td><code id="predict.mismm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the parameters
<code>new_bags</code> and <code>new_instances</code> are not necessary, as long as the names match
the original function call.
</p>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will have
a column <code>.pred</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mismm">mismm()</a></code> for fitting the <code>mismm</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mil_data &lt;- generate_mild_df(nbag = 15, nsample = 20, positive_prob = 0.15,
                             sd_of_mean = rep(0.1, 3))

mdl1 &lt;- mismm(mil_data, control = list(sigma = 1/5))

# bag level predictions
library(dplyr)
mil_data %&gt;%
    bind_cols(predict(mdl1, mil_data, type = "class")) %&gt;%
    bind_cols(predict(mdl1, mil_data, type = "raw")) %&gt;%
    distinct(bag_name, bag_label, .pred_class, .pred)

# instance level prediction
mil_data %&gt;%
    bind_cols(predict(mdl1, mil_data, type = "class", layer = "instance")) %&gt;%
    bind_cols(predict(mdl1, mil_data, type = "raw", layer = "instance")) %&gt;%
    distinct(bag_name, instance_name, bag_label, .pred_class, .pred)

</code></pre>

<hr>
<h2 id='predict.misvm'>Predict method for <code>misvm</code> object</h2><span id='topic+predict.misvm'></span>

<h3>Description</h3>

<p>Predict method for <code>misvm</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'misvm'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("bag", "instance"),
  new_bags = "bag_name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.misvm_+3A_object">object</code></td>
<td>
<p>An object of class <code>misvm</code>.</p>
</td></tr>
<tr><td><code id="predict.misvm_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.misvm_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.misvm_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.misvm_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.misvm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the parameters
<code>new_bags</code> and <code>new_instances</code> are not necessary, as long as the names match
the original function call.
</p>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will have
a column <code>.pred</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+misvm">misvm()</a></code> for fitting the <code>misvm</code> object.
</p>
</li>
<li> <p><code><a href="#topic+cv_misvm">cv_misvm()</a></code> for fitting the <code>misvm</code> object with cross-validation.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>mil_data &lt;- generate_mild_df(nbag = 20,
                             positive_prob = 0.15,
                             sd_of_mean = rep(0.1, 3))
df1 &lt;- build_instance_feature(mil_data, seq(0.05, 0.95, length.out = 10))
mdl1 &lt;- misvm(x = df1[, 4:63], y = df1$bag_label,
              bags = df1$bag_name, method = "heuristic")

predict(mdl1, new_data = df1, type = "raw", layer = "bag")

# summarize predictions at the bag layer
library(dplyr)
df1 %&gt;%
  bind_cols(predict(mdl1, df1, type = "class")) %&gt;%
  bind_cols(predict(mdl1, df1, type = "raw")) %&gt;%
  distinct(bag_name, bag_label, .pred_class, .pred)

</code></pre>

<hr>
<h2 id='predict.misvm_orova'>Predict method for <code>misvm_orova</code> object</h2><span id='topic+predict.misvm_orova'></span>

<h3>Description</h3>

<p>Predict method for <code>misvm_orova</code> object.  Predictions use the K fitted MI-SVM
models.  For class predictions, we return the class whose MI-SVM model has
the highest raw predicted score.  For raw predictions, a full matrix of
predictions is returned, with one column for each model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'misvm_orova'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("bag", "instance"),
  new_bags = "bag_name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.misvm_orova_+3A_object">object</code></td>
<td>
<p>An object of class <code>misvm_orova</code></p>
</td></tr>
<tr><td><code id="predict.misvm_orova_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.misvm_orova_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values based on the highest output
of an individual model.  If <code>'raw'</code>, return the raw predicted scores for
each model.</p>
</td></tr>
<tr><td><code id="predict.misvm_orova_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.misvm_orova_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.misvm_orova_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the
parameters <code>new_bags</code> and <code>new_instances</code> are not necessary, as long as the
names match the original function call.
</p>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will have
K columns <code style="white-space: pre;">&#8288;.pred_{class_name}&#8288;</code> corresponding to the raw predictions of the
K models.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+misvm_orova">misvm_orova()</a></code> for fitting the <code>misvm_orova</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ordmvnorm")
x &lt;- ordmvnorm[, 3:7]
y &lt;- ordmvnorm$bag_label
bags &lt;- ordmvnorm$bag_name

mdl1 &lt;- misvm_orova(x, y, bags)

# summarize predictions at the bag layer
library(dplyr)
df1 &lt;- bind_cols(y = y, bags = bags, as.data.frame(x))
df1 %&gt;%
  bind_cols(predict(mdl1, df1, new_bags = bags, type = "class")) %&gt;%
  bind_cols(predict(mdl1, df1, new_bags = bags, type = "raw")) %&gt;%
  select(-starts_with("V")) %&gt;%
  distinct()

</code></pre>

<hr>
<h2 id='predict.omisvm'>Predict method for <code>omisvm</code> object</h2><span id='topic+predict.omisvm'></span>

<h3>Description</h3>

<p>Predict method for <code>omisvm</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'omisvm'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("bag", "instance"),
  new_bags = "bag_name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.omisvm_+3A_object">object</code></td>
<td>
<p>An object of class <code>omisvm</code></p>
</td></tr>
<tr><td><code id="predict.omisvm_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.omisvm_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.omisvm_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.omisvm_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.omisvm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the parameters
<code>new_bags</code> and <code>new_instances</code> are not necessary, as long as the names match
the original function call.
</p>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will have
a column <code>.pred</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+omisvm">omisvm()</a></code> for fitting the <code>omisvm</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require(gurobi)) {
  data("ordmvnorm")
  x &lt;- ordmvnorm[, 3:7]
  y &lt;- ordmvnorm$bag_label
  bags &lt;- ordmvnorm$bag_name

  mdl1 &lt;- omisvm(x, y, bags, weights = NULL)

  # summarize predictions at the bag layer
  library(dplyr)
  df1 &lt;- bind_cols(y = y, bags = bags, as.data.frame(x))
  df1 %&gt;%
    bind_cols(predict(mdl1, df1, new_bags = bags, type = "class")) %&gt;%
    bind_cols(predict(mdl1, df1, new_bags = bags, type = "raw")) %&gt;%
    distinct(y, bags, .pred_class, .pred)
}

</code></pre>

<hr>
<h2 id='predict.smm'>Predict method for <code>smm</code> object</h2><span id='topic+predict.smm'></span>

<h3>Description</h3>

<p>Predict method for <code>smm</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'smm'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = "instance",
  new_instances = "instance_name",
  new_bags = "bag_name",
  kernel = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.smm_+3A_object">object</code></td>
<td>
<p>an object of class <code>smm</code></p>
</td></tr>
<tr><td><code id="predict.smm_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.smm_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.smm_+3A_layer">layer</code></td>
<td>
<p>If <code>'instance'</code>, return predictions at the instance level.
Option <code>'bag'</code> returns predictions at the bag level, but only if the model
was fit with <code>smm.mild_df()</code>,</p>
</td></tr>
<tr><td><code id="predict.smm_+3A_new_instances">new_instances</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the instance names in
<code>new_data</code> (default <code>'instance_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has instance name for each row.</p>
</td></tr>
<tr><td><code id="predict.smm_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Only relevant when fit with
<code>smm.mild_df()</code>, which contains bag level information.  Can specify a
singular character that provides the column name for the bag names in
<code>new_data</code>, default = &quot;bag_name&quot;.  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each instance.</p>
</td></tr>
<tr><td><code id="predict.smm_+3A_kernel">kernel</code></td>
<td>
<p>An optional pre-computed kernel matrix at the instance level or
<code>NULL</code> (default <code>NULL</code>). The rows should correspond to instances in the new
data to predict, and columns should correspond to instances in the original
training data, such as a call to <code><a href="#topic+kme">kme()</a></code>.</p>
</td></tr>
<tr><td><code id="predict.smm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the parameters
<code>new_bags</code> and <code>new_instances</code> are not necessary, as long as the names match
the original function call.
</p>


<h3>Value</h3>

<p>tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column named <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will
have a column name <code>.pred</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smm">smm()</a></code> for fitting the <code>smm</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
n_instances &lt;- 10
n_samples &lt;- 20
y &lt;- rep(c(1, -1), each = n_samples * n_instances / 2)
instances &lt;- as.character(rep(1:n_instances, each = n_samples))
x &lt;- data.frame(x1 = rnorm(length(y), mean = 1*(y==1)),
                x2 = rnorm(length(y), mean = 2*(y==1)),
                x3 = rnorm(length(y), mean = 3*(y==1)))

mdl &lt;- smm(x, y, instances, control = list(sigma = 1/3))

# instance level predictions (training data)
suppressWarnings(library(dplyr))
data.frame(instance_name = instances, y = y, x) %&gt;%
  bind_cols(predict(mdl, type = "raw", new_data = x, new_instances = instances)) %&gt;%
  bind_cols(predict(mdl, type = "class", new_data = x, new_instances = instances)) %&gt;%
  distinct(instance_name, y, .pred, .pred_class)

# test data
new_inst &lt;- rep(c("11", "12"), each = 30)
new_y &lt;- rep(c(1, -1), each = 30)
new_x &lt;- data.frame(x1 = rnorm(length(new_inst), mean = 1*(new_inst=="11")),
                    x2 = rnorm(length(new_inst), mean = 2*(new_inst=="11")),
                    x3 = rnorm(length(new_inst), mean = 3*(new_inst=="11")))

# instance level predictions (test data)
data.frame(instance_name = new_inst, y = new_y, new_x) %&gt;%
  bind_cols(predict(mdl, type = "raw", new_data = new_x, new_instances = new_inst)) %&gt;%
  bind_cols(predict(mdl, type = "class", new_data = new_x, new_instances = new_inst)) %&gt;%
  distinct(instance_name, y, .pred, .pred_class)

</code></pre>

<hr>
<h2 id='predict.svor_exc'>Predict method for <code>svor_exc</code> object</h2><span id='topic+predict.svor_exc'></span>

<h3>Description</h3>

<p>Predict method for <code>svor_exc</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'svor_exc'
predict(
  object,
  new_data,
  type = c("class", "raw"),
  layer = c("instance", "bag"),
  new_bags = "bag_name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.svor_exc_+3A_object">object</code></td>
<td>
<p>An object of class <code>svor_exc</code>.</p>
</td></tr>
<tr><td><code id="predict.svor_exc_+3A_new_data">new_data</code></td>
<td>
<p>A data frame to predict from. This needs to have all of the
features that the data was originally fitted with.</p>
</td></tr>
<tr><td><code id="predict.svor_exc_+3A_type">type</code></td>
<td>
<p>If <code>'class'</code>, return predicted values with threshold of 0 as
-1 or +1.  If <code>'raw'</code>, return the raw predicted scores.</p>
</td></tr>
<tr><td><code id="predict.svor_exc_+3A_layer">layer</code></td>
<td>
<p>If <code>'bag'</code>, return predictions at the bag level.  If
<code>'instance'</code>, return predictions at the instance level.</p>
</td></tr>
<tr><td><code id="predict.svor_exc_+3A_new_bags">new_bags</code></td>
<td>
<p>A character or character vector.  Can specify a singular
character that provides the column name for the bag names in <code>new_data</code>
(default <code>'bag_name'</code>).  Can also specify a vector of length
<code>nrow(new_data)</code> that has bag name for each row.</p>
</td></tr>
<tr><td><code id="predict.svor_exc_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the object was fitted using the <code>formula</code> method, then the parameter
<code>new_bags</code> is not necessary, as long as the names match
the original function call.
</p>


<h3>Value</h3>

<p>A tibble with <code>nrow(new_data)</code> rows.  If <code>type = 'class'</code>, the tibble
will have a column <code>.pred_class</code>.  If <code>type = 'raw'</code>, the tibble will have
a column <code>.pred</code>.
</p>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>See Also</h3>

<p><code><a href="#topic+svor_exc">svor_exc()</a></code> for fitting the <code>svor_exc</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ordmvnorm")
x &lt;- ordmvnorm[, 3:7]
y &lt;- attr(ordmvnorm, "instance_label")

mdl1 &lt;- svor_exc(x, y)
predict(mdl1, x)
predict(mdl1, x, type = "raw")

</code></pre>

<hr>
<h2 id='smm'>Fit SMM model to the data</h2><span id='topic+smm'></span><span id='topic+smm.default'></span><span id='topic+smm.formula'></span><span id='topic+smm.mild_df'></span>

<h3>Description</h3>

<p>Function to carry out support measure machines algorithm which is appropriate
for multiple instance learning. The algorithm calculates the kernel matrix of
different empirical measures using kernel mean embedding. The data set should
be passed in with rows corresponding to samples from a set of instances.  SMM
will compute a kernel on the instances and pass that to <code>kernlab::ksvm()</code> to
train the appropriate SVM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
smm(
  x,
  y,
  instances,
  cost = 1,
  weights = TRUE,
  control = list(kernel = "radial", sigma = if (is.vector(x)) 1 else 1/ncol(x), scale =
    TRUE),
  ...
)

## S3 method for class 'formula'
smm(formula, data, instances = "instance_name", ...)

## S3 method for class 'mild_df'
smm(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smm_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents a sample. If a <code>mild_df</code> object is passed, <code style="white-space: pre;">&#8288;y, instances&#8288;</code>
are automatically extracted, <code>bags</code> is ignored, and all other columns will
be used as predictors.</p>
</td></tr>
<tr><td><code id="smm_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="smm_+3A_instances">instances</code></td>
<td>
<p>A vector specifying which samples belong to each instance.
Can be a string, numeric, of factor.</p>
</td></tr>
<tr><td><code id="smm_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM, fed to the <code>C</code> argument in
<code>kernlab::ksvm()</code>.</p>
</td></tr>
<tr><td><code id="smm_+3A_weights">weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td></tr>
<tr><td><code id="smm_+3A_control">control</code></td>
<td>
<p>A list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li></ul>
</td></tr>
<tr><td><code id="smm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="smm_+3A_formula">formula</code></td>
<td>
<p>A formula with specification <code>y ~ x</code>. This argument is an
alternative to the <code>x</code>, <code>y</code> arguments, but requires the <code>data</code> and
<code>instances</code> argument. See examples.</p>
</td></tr>
<tr><td><code id="smm_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>smm</code>  The object contains at least the
following components:
</p>

<ul>
<li> <p><code>ksvm_fit</code>: A fit of class <code>ksvm</code> from the kernlab package.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>smm()</code> was called with.
</p>
</li>
<li> <p><code>x</code>: The training data needed for computing the kernel matrix in
prediction.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>sigma</code>: The radial basis function kernel parameter.
</p>
</li>
<li> <p><code>weights</code>: The calculated weights on the <code>cost</code> parameter, if applicable.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mild_df</code>: Method for <code>mild_df</code> objects. Use the <code>bag_label</code> as <code>y</code> at
the instance level, then perform <code>smm()</code> ignoring the MIL structure.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent, Yifei Liu
</p>


<h3>References</h3>

<p>Muandet, K., Fukumizu, K., Dinuzzo, F., &amp; Schölkopf, B. (2012).
Learning from distributions via support measure machines. <em>Advances in
neural information processing systems</em>, <em>25</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.smm">predict.smm()</a></code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
n_instances &lt;- 10
n_samples &lt;- 20
y &lt;- rep(c(1, -1), each = n_samples * n_instances / 2)
instances &lt;- as.character(rep(1:n_instances, each = n_samples))
x &lt;- data.frame(x1 = rnorm(length(y), mean = 1*(y==1)),
                x2 = rnorm(length(y), mean = 2*(y==1)),
                x3 = rnorm(length(y), mean = 3*(y==1)))

df &lt;- data.frame(instance_name = instances, y = y, x)

mdl &lt;- smm(x, y, instances)
mdl2 &lt;- smm(y ~ ., data = df)

# instance level predictions
suppressWarnings(library(dplyr))
df %&gt;%
  dplyr::bind_cols(predict(mdl, type = "raw", new_data = x, new_instances = instances)) %&gt;%
  dplyr::bind_cols(predict(mdl, type = "class", new_data = x, new_instances = instances)) %&gt;%
  dplyr::distinct(instance_name, y, .pred, .pred_class)

</code></pre>

<hr>
<h2 id='summarize_samples'>Summarize data across functions</h2><span id='topic+summarize_samples'></span><span id='topic+summarize_samples.default'></span><span id='topic+summarize_samples.mild_df'></span>

<h3>Description</h3>

<p>Summarize a numeric data frame based on specified grouping columns and a list
of functions.  This is useful in summarizing a <code>mild_df</code> object from the
sample level to the instance level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
summarize_samples(data, group_cols, .fns = list(mean = mean), cor = FALSE, ...)

## S3 method for class 'mild_df'
summarize_samples(data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarize_samples_+3A_data">data</code></td>
<td>
<p>A data.frame, 'mild_df' object, or similar of data to summarize.</p>
</td></tr>
<tr><td><code id="summarize_samples_+3A_group_cols">group_cols</code></td>
<td>
<p>A character vector of column(s) that describe groups to
summarize across.</p>
</td></tr>
<tr><td><code id="summarize_samples_+3A_.fns">.fns</code></td>
<td>
<p>A list of functions (default <code>list(mean = mean)</code>).</p>
</td></tr>
<tr><td><code id="summarize_samples_+3A_cor">cor</code></td>
<td>
<p>A logical (default <code>FALSE</code>) for whether to include correlations
between all features in the summarization.</p>
</td></tr>
<tr><td><code id="summarize_samples_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with summarized data.  There will be one row for each set
of distinct groups specified by <code>group_cols</code>. There will be one column for
each of the <code>group_cols</code>, plus <code>length(.fns)</code> columns for each of the
features in <code>data</code>, plus correlation columns if specified.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects.
</p>
</li>
<li> <p><code>mild_df</code>: Method for <code>mild_df</code> objects.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fns &lt;- list(mean = mean, sd = sd)
summarize_samples(mtcars, group_cols = c("cyl", "gear"), .fns = fns)
summarize_samples(mtcars, group_cols = c("cyl", "gear"), .fns = fns, cor = TRUE)

</code></pre>

<hr>
<h2 id='svor_exc'>Fit SVOR-EXC model to ordinal outcome data</h2><span id='topic+svor_exc'></span><span id='topic+svor_exc.default'></span><span id='topic+svor_exc.formula'></span><span id='topic+svor_exc.mi_df'></span>

<h3>Description</h3>

<p>This function fits the Support Vector Ordinal Regression with Explicit
Constraints based on the research of Chu and Keerthi (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
svor_exc(
  x,
  y,
  cost = 1,
  method = c("smo"),
  weights = NULL,
  control = list(kernel = "linear", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    max_step = 500, scale = TRUE, verbose = FALSE),
  ...
)

## S3 method for class 'formula'
svor_exc(formula, data, ...)

## S3 method for class 'mi_df'
svor_exc(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="svor_exc_+3A_x">x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents an instance. If a <code>mi_df</code> object is passed, <code>y</code> is
automatically extracted, <code>bags</code> is ignored, and all other columns will be
used as predictors.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_y">y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_cost">cost</code></td>
<td>
<p>The cost parameter in SVM.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_method">method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'smo'</code>).  When
<code>method = 'smo'</code>, the modified SMO algorithm from Chu and Keerthi (2007) is
used.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_weights">weights</code></td>
<td>
<p><code>NULL</code>, since weights are not implemented for this function.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_control">control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li></ul>
</td></tr>
<tr><td><code id="svor_exc_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_formula">formula</code></td>
<td>
<p>A formula with specification <code>y ~ x</code>. This argument is an
alternative to the <code>x</code>, <code>y</code> arguments, but requires the <code>data</code> argument.
See examples.</p>
</td></tr>
<tr><td><code id="svor_exc_+3A_data">data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>svor_exc</code>  The object contains at least the
following components:
</p>

<ul>
<li> <p><code>smo_fit</code>: A fit object from running the modified ordinal smo algorithm.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>svor_exc()</code> was called
with.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>n_step</code>: The total steps used in the heuristic algorithm.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates. Use the <code>bag_label</code> as <code>y</code> at the
instance level, then perform <code>svor_exc()</code> ignoring the MIL structure and
bags.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>References</h3>

<p>Chu, W., &amp; Keerthi, S. S. (2007). Support vector ordinal
regression. <em>Neural computation</em>, <em>19</em>(3), 792-815.
doi: <a href="https://doi.org/10.1162/neco.2007.19.3.792">10.1162/neco.2007.19.3.792</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.svor_exc">predict.svor_exc()</a></code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ordmvnorm")
x &lt;- ordmvnorm[, 3:7]
y &lt;- attr(ordmvnorm, "instance_label")

mdl1 &lt;- svor_exc(x, y)
predict(mdl1, x)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
