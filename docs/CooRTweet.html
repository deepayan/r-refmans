<!DOCTYPE html><html><head><title>Help for package CooRTweet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CooRTweet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#account_stats'><p>account_stats</p></a></li>
<li><a href='#detect_groups'><p>detect_groups</p></a></li>
<li><a href='#do_remove_loops'><p>Remove loops from the result.</p></a></li>
<li><a href='#filter_min_participation'><p>Filter the result by minimum participation</p></a></li>
<li><a href='#flag_speed_share'><p>flag_speed_share</p></a></li>
<li><a href='#generate_coordinated_network'><p>generate_coordinated_network</p></a></li>
<li><a href='#group_stats'><p>group_stats</p></a></li>
<li><a href='#load_many_tweets_json'><p>load_many_tweets_json</p></a></li>
<li><a href='#load_tweets_json'><p>load_tweets_json</p></a></li>
<li><a href='#load_twitter_users_json'><p>load_twitter_users_json</p></a></li>
<li><a href='#normalize_text'><p>Normalize text</p></a></li>
<li><a href='#prep_data'><p>prep_data</p></a></li>
<li><a href='#preprocess_tweets'><p>preprocess_tweets</p></a></li>
<li><a href='#preprocess_twitter_users'><p>preprocess_twitter_users</p></a></li>
<li><a href='#remove_hashtags'><p>Remove hashtags</p></a></li>
<li><a href='#reshape_tweets'><p>reshape_tweets</p></a></li>
<li><a href='#russian_coord_tweets'><p>Pro-Government Russian Tweet Dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-28</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Coordinated Networks Detection on Social Media</td>
</tr>
<tr>
<td>Description:</td>
<td>Detects a variety of coordinated actions on social media and outputs the network of coordinated users along with related information.</td>
</tr>
<tr>
<td>Author:</td>
<td>Nicola Righetti <a href="https://orcid.org/0000-0002-9257-5113"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Paul Balluff <a href="https://orcid.org/0000-0001-9548-3225"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicola Righetti &lt;nicola.righetti@univie.ac.at&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/nicolarighetti/CooRTweet">https://github.com/nicolarighetti/CooRTweet</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nicolarighetti/CooRTweet/issues">https://github.com/nicolarighetti/CooRTweet/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, tidytable, RcppSimdJson, lubridate, igraph,
stringi</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-28 08:46:25 UTC; righetti</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-29 07:20:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='account_stats'>account_stats</h2><span id='topic+account_stats'></span>

<h3>Description</h3>

<p>Calculate account statistics: total posts shared, average time delta,
average edge symmetry score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>account_stats(
  coord_graph,
  result,
  weight_threshold = c("full", "fast", "none")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="account_stats_+3A_coord_graph">coord_graph</code></td>
<td>
<p>an <code>igraph</code> object generated by <a href="#topic+generate_coordinated_network">generate_coordinated_network</a></p>
</td></tr>
<tr><td><code id="account_stats_+3A_result">result</code></td>
<td>
<p>a table generated by <a href="#topic+detect_groups">detect_groups</a></p>
</td></tr>
<tr><td><code id="account_stats_+3A_weight_threshold">weight_threshold</code></td>
<td>
<p>The threshold to be used for filtering the graph
(options: &quot;full&quot;, &quot;fast&quot;, or &quot;none&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With this helper function, you can obtain summary statistics for the accounts in
the network. When applied to a network for which a narrower <code>time_window</code> has
been calculated using the <a href="#topic+flag_speed_share">flag_speed_share</a> function, the summary statistics
are computed separately for the full and faster networks depending on the
'weight_threshold' option. When this option is set to &quot;full&quot;, metrics are
computed on the set of nodes and edges surpassing the user-defined
edge_weight threshold in the <a href="#topic+generate_coordinated_network">generate_coordinated_network</a> function. Also,
metrics for nodes and edges in the fastest network are returned, but they are
calculated on the specified subgraph. The same applies when the 'weight_threshold'
option is set to &quot;fast&quot;. In this case, metrics are calculated on the fast subgraph.
When the option is set to &quot;null&quot;, the entire inputted graph without further
subsetting is considered.
</p>
<p>The node share count is performed thanks to the table resulting from the
<a href="#topic+detect_groups">detect_groups</a> function. If the user has used the optional
<a href="#topic+flag_speed_share">flag_speed_share</a> function and decides to calculate statistics on
the fastest graph (by setting weight_threshold = &quot;fast&quot;), the share count
is calculated considering only shares made in the fastest time window.
Alternatively, shares in the largest time window are considered (option
weight_threshold = &quot;full&quot; or weight_threshold = &quot;none&quot;). When calculating the
share count, all shares made by accounts are considered, regardless of
whether they are shares of posts shared in a coordinated fashion or not,
according to the edge weight threshold. In other words, this is a measure of
an account's activity in the time window under consideration.
</p>


<h3>Value</h3>

<p>a data.table with summary statistics for each account
</p>

<hr>
<h2 id='detect_groups'>detect_groups</h2><span id='topic+detect_groups'></span>

<h3>Description</h3>

<p>Function to perform the initial stage in detecting coordinated behavior.
It identifies pairs of accounts that share the same objects in a time_window.
See details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_groups(
  x,
  time_window = 10,
  min_participation = 2,
  remove_loops = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect_groups_+3A_x">x</code></td>
<td>
<p>a data.table with the columns: <code>object_id</code> (uniquely identifies
coordinated content), <code>account_id</code> (unique ids for accounts), <code>content_id</code>
(id of account generated content), <code>timestamp_share</code> (integer). See also
<a href="#topic+reshape_tweets">reshape_tweets</a> and <a href="#topic+prep_data">prep_data</a>.</p>
</td></tr>
<tr><td><code id="detect_groups_+3A_time_window">time_window</code></td>
<td>
<p>the number of seconds within which shared contents
are to be considered as coordinated (default to 10 seconds).</p>
</td></tr>
<tr><td><code id="detect_groups_+3A_min_participation">min_participation</code></td>
<td>
<p>The minimum number of actions required for a account
to be included in subsequent analysis (default set at 2). This ensures that
only accounts with a minimum level of activity in the original dataset are
included in subsequent analysis. It is important to distinguish this from the
frequency of repeated interactions an account has with another specific account,
as represented by edge weight. The edge weight parameter is utilized in the
<code>generate_coordinated_network</code> function as a concluding step in identifying
coordinated behavior.</p>
</td></tr>
<tr><td><code id="detect_groups_+3A_remove_loops">remove_loops</code></td>
<td>
<p>Should loops (shares of the same objects made by the same
account within the time window) be removed? (default to TRUE).</p>
</td></tr>
<tr><td><code id="detect_groups_+3A_...">...</code></td>
<td>
<p>keyword arguments for backwards compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function achieves the initial stage in detecting coordinated
behavior by identifying accounts who share identical objects within the same
temporal window, and is preliminary to the network analysis conducted using
the <a href="#topic+generate_coordinated_network">generate_coordinated_network</a> function.
<code>detect_groups</code> groups the data by <code>object_id</code> (uniquely identifies
content) and calculates the time differences between all
<code>content_id</code> (ids of account generated contents) within their groups.
It then filters out all <code>content_id</code> that are higher than the <code>time_window</code>
(in seconds). It returns a <code>data.table</code> with all IDs of coordinated
contents. The <code>object_id</code> can be for example: hashtags, IDs of tweets being
retweeted, or URLs being shared. For twitter data, best use <a href="#topic+reshape_tweets">reshape_tweets</a>.
</p>


<h3>Value</h3>

<p>a data.table with ids of coordinated contents. Columns:
<code>object_id</code>, <code>account_id</code>, <code>account_id_y</code>, <code>content_id</code>, <code>content_id_y</code>,
<code>timedelta</code>. The <code>account_id</code> and <code>content_id</code> represent the &quot;older&quot;
data points, <code>account_id_y</code> and <code>content_id_y</code> represent the &quot;newer&quot;
data points. For example, account A retweets from account B, then account A's
content is newer (i.e., <code>account_id_y</code>).
</p>

<hr>
<h2 id='do_remove_loops'>Remove loops from the result.</h2><span id='topic+do_remove_loops'></span>

<h3>Description</h3>

<p>This function is a private utility function that removes loops (i.e., accounts
sharing their own content) from the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_remove_loops(result)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do_remove_loops_+3A_result">result</code></td>
<td>
<p>The result of the previous filtering steps.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result with loops removed.
</p>

<hr>
<h2 id='filter_min_participation'>Filter the result by minimum participation</h2><span id='topic+filter_min_participation'></span>

<h3>Description</h3>

<p>This private function filters the result by the minimum number of participation required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter_min_participation(x, result, min_participation)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter_min_participation_+3A_x">x</code></td>
<td>
<p>The original data table where a preliminary filter is applied</p>
</td></tr>
<tr><td><code id="filter_min_participation_+3A_result">result</code></td>
<td>
<p>A data table containing the result data from calc_group_combinations.</p>
</td></tr>
<tr><td><code id="filter_min_participation_+3A_min_participation">min_participation</code></td>
<td>
<p>The minimum activity threshold. accounts with participation count
greater than this threshold will be retained in the final 'result' table.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data table with filtered rows based on the specified minimum participation.
</p>

<hr>
<h2 id='flag_speed_share'>flag_speed_share</h2><span id='topic+flag_speed_share'></span>

<h3>Description</h3>

<p>Function to update result based on a narrower time_window.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flag_speed_share(x, result, min_participation, time_window)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flag_speed_share_+3A_x">x</code></td>
<td>
<p>A data table from a coordination detection function</p>
</td></tr>
<tr><td><code id="flag_speed_share_+3A_result">result</code></td>
<td>
<p>A data table containing the result data.</p>
</td></tr>
<tr><td><code id="flag_speed_share_+3A_min_participation">min_participation</code></td>
<td>
<p>The minimum participation threshold. Accounts with participation count
greater than this threshold will be retained (default parameter equal to
the one used in the <a href="#topic+detect_groups">detect_groups</a> function).</p>
</td></tr>
<tr><td><code id="flag_speed_share_+3A_time_window">time_window</code></td>
<td>
<p>The number of seconds within which shared contents are to be considered as
coordinated according to the new time_window (default parameter equal to
the one used in the <a href="#topic+detect_groups">detect_groups</a> function).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function identifies and marks the subset of results that match a more
stringent time window.
</p>


<h3>Value</h3>

<p>A results data table that includes an additional column set to 1 when the share
corresponds with the new time_window, and 0 otherwise.
</p>

<hr>
<h2 id='generate_coordinated_network'>generate_coordinated_network</h2><span id='topic+generate_coordinated_network'></span>

<h3>Description</h3>

<p>This function takes the results of <a href="#topic+detect_groups">detect_groups</a>
and generates a network from the data. It performs the second step in
coordinated detection analysis by identifying users who repeatedly engage in
identical actions within a predefined time window. The function offers
multiple options to identify various types of networks, allowing for
filtering based on different edge weights and facilitating the extraction
of distinct subgraphs. See details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_coordinated_network(
  x,
  fast_net = FALSE,
  edge_weight = 0.5,
  subgraph = 0,
  objects = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_coordinated_network_+3A_x">x</code></td>
<td>
<p>a data.table (result from <a href="#topic+detect_groups">detect_groups</a>) with the
Columns: <code>object_id</code>, <code>account_id</code>, <code>account_id_y</code>, <code>content_id</code>, <code>content_id_y</code>,
<code>timedelta</code></p>
</td></tr>
<tr><td><code id="generate_coordinated_network_+3A_fast_net">fast_net</code></td>
<td>
<p>If the data.table x has been updated with the
<a href="#topic+flag_speed_share">flag_speed_share</a> function and this parameter is set to TRUE, two columns
weight_full and weight_fast are created, the first containing the edge weights
of the full graph, the second those of the subgraph that includes the shares
made in the narrower time window.</p>
</td></tr>
<tr><td><code id="generate_coordinated_network_+3A_edge_weight">edge_weight</code></td>
<td>
<p>This parameter defines the edge weight threshold, expressed
as a percentile of the edge weight distribution within the network. This applies
also to the faster network, if 'fast_net' is set to TRUE (and the data is updated
using the <a href="#topic+flag_speed_share">flag_speed_share</a> function). Edges with a weight exceeding this
threshold are marked as 0 (not exceeding) or 1 (exceeding). The parameter accepts
any numeric value between 0 and 1. The default value is set to &quot;0.5&quot;, representing
the median value of edge weights in the network.</p>
</td></tr>
<tr><td><code id="generate_coordinated_network_+3A_subgraph">subgraph</code></td>
<td>
<p>Generate and return the following subgraph (default value is 0,
meaning that no subgraph is created):
</p>

<ul>
<li><p> If 1 reduces the graph to the subgraph whose edges have a value that exceeds
the threshold given in the edge_weight parameter (weighted subgraph).
</p>
</li>
<li><p> If 2 reduces the subgraph whose nodes exhibit coordinated behavior in the
narrowest time window (as established with the <a href="#topic+flag_speed_share">flag_speed_share</a> function),
to the subgraph whose edges have a value that exceeds the threshold given in
the edge_weight parameter (fast weighted subgraph).
</p>
</li>
<li><p> If 3 reduces the graph to the subgraph whose nodes exhibit coordinated
behavior in the narrowest time window established with the <a href="#topic+flag_speed_share">flag_speed_share</a>
function (fast subgraph), and the vertices adjacent to their edges. In other
words, this option identifies the fastest network, along with a contextual set
of accounts that shared the same objects but in the wider time window. It
also add a  vertex attribute color_v to facilitate further analyses or the
generation of the graph plot. This attribute is 1 when for the coordinated
accounts and 0 for the neighbor accounts.
</p>
</li></ul>
</td></tr>
<tr><td><code id="generate_coordinated_network_+3A_objects">objects</code></td>
<td>
<p>Keep track of the IDs of shared objects for further analysis with
<code>group_stats</code> (default FALSE). There could be a performance impact when this
option is set to TRUE, although the actual impact may vary. For smaller datasets,
the difference might be negligible. However, for very large datasets, or in
scenarios where optimal performance is crucial, you might experience a more
significant slowdown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two users may coincidentally share the same objects within the same
time window, but it is unlikely that they do so repeatedly (Giglietto et al.,
2020). Such repetition is thus considered an indicator of potential
coordination. This function utilizes percentile edge weight to represent
recurrent shares by the same user pairs within a predefined time window. By
considering the edge weight distribution across the data and setting the
percentile value <em>p</em> between 0 and 1, we can identify edges that fall within
the top <em>p</em> percentile of the edge weight distribution. Selecting a
sufficiently high percentile (e.g., 0.99) allows us to pinpoint users who
share an unusually high number of objects (for instance, more than 99% of
user pairs in the network) in the same time window.
</p>
<p>The graph also incorporates the contribution of each node within the pair to
the pair's edge weight, specifically, the number of shared <code>content_id</code> that
contribute to the edge weight. Additionally, an <code>edge_symmetry_score</code> is
included, which equals 1 in cases of equal contributions from both users and
approaches 0 as the contributions become increasingly unequal.
The edge_symmetry_score is determined as the proportion of the unique
content_ids (unique content) shared by each vertex to the total content_ids
shared by both users.
This score, along with the value of contributions, can be utilized for further
filtering or examining cases where the score is particularly low. Working with
an undirected graph, it is plausible that the activity of highly active users
disproportionately affects the weight of edges connecting them to less active
users. For instance, if user A shares the same objects (<code>object_id</code>) 100
times, and user B shares the same object only once, but within a time frame
that matches the <code>time_window</code> defined in the parameter for all of user A's
100 shares, then the edge weight between A and B will be 100, although this
weight is almost entirely influenced by the hyperactivity of user A. The
<code>edge_symmetry_score</code>, along with the counts of shares by each user <code>user_id</code>
and <code>user_id_y</code> (<code>n_content_id</code> and <code>n_content_id_y</code>), allows for monitoring
and controlling this phenomenon.
</p>


<h3>Value</h3>

<p>A weighted, undirected network (igraph object) where the vertices (nodes)
are users and edges (links) are the membership in coordinated groups (<code>object_id</code>).
</p>


<h3>References</h3>

<p>Giglietto, F., Righetti, N., Rossi, L., &amp; Marino, G. (2020). It takes a village to manipulate the media: coordinated link sharing behavior during 2018 and 2019 Italian elections. <em>Information, Communication &amp; Society</em>, 23(6), 867-891.
</p>

<hr>
<h2 id='group_stats'>group_stats</h2><span id='topic+group_stats'></span>

<h3>Description</h3>

<p>With this helper function, you can obtain summary statistics for the objects
in the network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>group_stats(coord_graph, weight_threshold = c("full", "fast", "none"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="group_stats_+3A_coord_graph">coord_graph</code></td>
<td>
<p>A result <code>igraph</code> generated by <a href="#topic+generate_coordinated_network">generate_coordinated_network</a></p>
</td></tr>
<tr><td><code id="group_stats_+3A_weight_threshold">weight_threshold</code></td>
<td>
<p>The level of the network for which to calculate the statistic.
It can be &quot;full,&quot; &quot;fast,&quot; or &quot;none.&quot; The first two options are applicable only
if the data includes information on a faster network, as calculated with the
<a href="#topic+flag_speed_share">flag_speed_share</a> function. These options preliminarily filter the nodes
based on their inclusion in the subgraph filtered by edge weight threshold
(&quot;full&quot;), filtered by edges created in the faster time window and surpassing
the edge weight threshold in that network (&quot;fast&quot;), or apply to the unfiltered
graph (&quot;none&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.table</code> with summary statistics
</p>

<hr>
<h2 id='load_many_tweets_json'>load_many_tweets_json</h2><span id='topic+load_many_tweets_json'></span>

<h3>Description</h3>

<p>EXPERIMENTAL. Batched version of <a href="#topic+load_tweets_json">load_tweets_json</a> with control over
retained columns. Not as efficient as <a href="#topic+load_tweets_json">load_tweets_json</a>
but requires less memory.
Wrapper of the function <a href="RcppSimdJson.html#topic+fload">fload</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_many_tweets_json(
  data_dir,
  batch_size = 1000,
  keep_cols = c("text", "possibly_sensitive", "public_metrics", "lang",
    "edit_history_tweet_ids", "attachments", "geo"),
  query = NULL,
  query_error_ok = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_many_tweets_json_+3A_data_dir">data_dir</code></td>
<td>
<p>string that leads to the directory containing JSON files</p>
</td></tr>
<tr><td><code id="load_many_tweets_json_+3A_batch_size">batch_size</code></td>
<td>
<p>integer specifying the number of JSON files
to load per batch. Default: <code>1000</code></p>
</td></tr>
<tr><td><code id="load_many_tweets_json_+3A_keep_cols">keep_cols</code></td>
<td>
<p>character vector with the names of columns you want to
keep. Set it to <code>NULL</code> to only retain the required columns.
Default: keep_cols = c(&quot;text&quot;, &quot;possibly_sensitive&quot;, &quot;public_metrics&quot;,
&quot;lang&quot;, &quot;edit_history_tweet_ids&quot;, &quot;attachments&quot;, &quot;geo&quot;)</p>
</td></tr>
<tr><td><code id="load_many_tweets_json_+3A_query">query</code></td>
<td>
<p>(string) JSON Pointer query passed on to
<a href="RcppSimdJson.html#topic+fload">fload</a> (optional). Default: <code>NULL</code></p>
</td></tr>
<tr><td><code id="load_many_tweets_json_+3A_query_error_ok">query_error_ok</code></td>
<td>
<p>(Boolean) stop if <code>query</code> causes an error. Passed on
to <a href="RcppSimdJson.html#topic+fload">fload</a> (optional). Default: <code>FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike <a href="#topic+load_tweets_json">load_tweets_json</a> this function loads JSON files
in batches and processes each batch before loading the next batch.
You can specify which columns to keep, which in turn requires less memory.
For example, you can decide not to keep the <code style="white-space: pre;">&#8288;"text&#8288;</code> column, which
requires quite a lot of memory.
</p>


<h3>Value</h3>

<p>a data.table with all tweets loaded
</p>

<hr>
<h2 id='load_tweets_json'>load_tweets_json</h2><span id='topic+load_tweets_json'></span>

<h3>Description</h3>

<p>Very efficient and fast way to load tweets stored in JSON files.
Wrapper of the function <a href="RcppSimdJson.html#topic+fload">fload</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_tweets_json(data_dir, query = NULL, query_error_ok = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_tweets_json_+3A_data_dir">data_dir</code></td>
<td>
<p>string that leads to the directory containing JSON files</p>
</td></tr>
<tr><td><code id="load_tweets_json_+3A_query">query</code></td>
<td>
<p>(string) JSON Pointer query passed on to
<a href="RcppSimdJson.html#topic+fload">fload</a> (optional). Default: <code>NULL</code></p>
</td></tr>
<tr><td><code id="load_tweets_json_+3A_query_error_ok">query_error_ok</code></td>
<td>
<p>(Boolean) stop if <code>query</code> causes an error. Passed on
to <a href="RcppSimdJson.html#topic+fload">fload</a> (optional). Default: <code>FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is optimized to load tweets that were
collected using the academicTwittr Package (Twitter API V2).
It uses RcppSimdJson to load the JSON files, which is extremely
fast and efficient. It returns the twitter data as is. The only changes
are that the function renames the <code>id</code> of tweets to <code>tweet_id</code>, and
it also deduplicates the data (by <code>tweet_id</code>).
The function expects that the individual JSON files start with <code>data</code>.
</p>


<h3>Value</h3>

<p>a data.table with all tweets loaded
</p>

<hr>
<h2 id='load_twitter_users_json'>load_twitter_users_json</h2><span id='topic+load_twitter_users_json'></span>

<h3>Description</h3>

<p>Very efficient and fast way to load user information from JSON files.
Wrapper of the function <a href="RcppSimdJson.html#topic+fload">fload</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_twitter_users_json(data_dir, query_error_ok = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_twitter_users_json_+3A_data_dir">data_dir</code></td>
<td>
<p>string that leads to the directory containing JSON files</p>
</td></tr>
<tr><td><code id="load_twitter_users_json_+3A_query_error_ok">query_error_ok</code></td>
<td>
<p>(Boolean) stop if <code>query</code> causes an error. Passed on
to <a href="RcppSimdJson.html#topic+fload">fload</a> (optional). Default: <code>TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is optimized to load user data JSON files that were
collected using the academicTwittr Package (Twitter API V2).
It uses RcppSimdJson to load the JSON files, which is extremely
fast and efficient. It returns the user data as is. The only changes
are that the function renames the <code>id</code> of tweets to <code>user_id</code>, and
it also deduplicates the data (by <code>user_id</code>).
The function expects that the individual JSON files start with <code>user</code>.
</p>


<h3>Value</h3>

<p>a data.table with all users loaded
</p>

<hr>
<h2 id='normalize_text'>Normalize text</h2><span id='topic+normalize_text'></span>

<h3>Description</h3>

<p>Utility function that normalizes text by removing mentions of other accounts, removing &quot;RT&quot;,
converting to lower case, and trimming whitespace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize_text(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_text_+3A_x">x</code></td>
<td>
<p>The text to be normalized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The normalized text.
</p>

<hr>
<h2 id='prep_data'>prep_data</h2><span id='topic+prep_data'></span>

<h3>Description</h3>

<p>Function to rename columns of a given data.table. This function standardizes
column names to &quot;object_id&quot;, &quot;account_id&quot;, &quot;content_id&quot;, and &quot;timestamp_share&quot;.
It is useful for preparing datasets for further analysis by ensuring
consistent column naming.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_data(
  x,
  object_id = NULL,
  account_id = NULL,
  content_id = NULL,
  timestamp_share = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prep_data_+3A_x">x</code></td>
<td>
<p>A data.table or an object that can be converted into a data.table.
This is the dataset whose columns will be renamed.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_object_id">object_id</code></td>
<td>
<p>The current name of the column that should be renamed to &quot;object_id&quot;.
If NULL, no renaming is performed on this column.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_account_id">account_id</code></td>
<td>
<p>The current name of the column that should be renamed to &quot;account_id&quot;.
If NULL, no renaming is performed on this column.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_content_id">content_id</code></td>
<td>
<p>The current name of the column that should be renamed to &quot;content_id&quot;.
If NULL, no renaming is performed on this column.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_timestamp_share">timestamp_share</code></td>
<td>
<p>The current name of the column that should be renamed to &quot;timestamp_share&quot;.
The data in this column should be either in UNIX format or in a &quot;%Y-%m-%d %H:%M:%S&quot; format.
If the data is in a different format or conversion is unsuccessful, the function stops with an error.
If NULL, no renaming or conversion is performed on this column.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows the user to specify the current names of columns in
their data.table that they wish to rename to a standard format. The function
checks for each parameter and renames the corresponding column in the data.table.
If the parameter is NULL, no change is made to that column. The function
ensures the data input is a data.table; if not, it converts it before renaming.
For the 'timestamp_share' column, the function expects the format to be either UNIX format
(integer representing seconds since the Unix epoch) or &quot;%Y-%m-%d %H:%M:%S&quot;. If the 'timestamp_share'
is in a different format, the function attempts to convert it to UNIX format using base R functions.
</p>


<h3>Value</h3>

<p>A data.table with the specified columns renamed according to the input parameters.
If no renaming is required, the original data.table is returned unaltered.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dt &lt;- data.table::data.table(old_object_id = 1:3, old_account_id_y = 4:6)
dt &lt;- prep_data(dt, object_id = "old_object_id", account_id = "old_account_id_y")

</code></pre>

<hr>
<h2 id='preprocess_tweets'>preprocess_tweets</h2><span id='topic+preprocess_tweets'></span>

<h3>Description</h3>

<p>Reformat nested Twitter data (retrieved from Twitter V2 API).
Spreads out columns and reformats nested a <code>data.table</code> to
a named list of unnested data.tables.
All output is in long-format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocess_tweets(
  tweets,
  tweets_cols = c("possibly_sensitive", "lang", "text", "public_metrics_retweet_count",
    "public_metrics_reply_count", "public_metrics_like_count",
    "public_metrics_quote_count")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocess_tweets_+3A_tweets">tweets</code></td>
<td>
<p>a data.table to unnest. Twitter data loaded
with <a href="#topic+load_tweets_json">load_tweets_json</a>'.</p>
</td></tr>
<tr><td><code id="preprocess_tweets_+3A_tweets_cols">tweets_cols</code></td>
<td>
<p>a character vector specifying the columns to keep (optional).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Restructure your nested Twitter data that you loaded with
<a href="#topic+load_tweets_json">load_tweets_json</a>. The function unnests the following columns:
<code>public_metrics</code> (likes, retweets, quotes),
<code>referenced_tweets</code> (IDs of &quot;replied to&quot; and &quot;retweet&quot;),
<code>entities</code> (hashtags, URLs, other accounts).
Returns a named list with several <code>data.tables</code>,
each <code>data.table</code> represents one aspect of the nested data.
The function also expects that the following additional
columns are present in the <code>data.table</code>:
<code>created_at</code>, <code>tweet_id</code>, <code>author_id</code>,
<code>conversation_id</code>, <code>text</code>,
<code>in_reply_to_user_id</code>.
Implicitely dropped columns: <code>edit_history_tweet_ids</code>
</p>


<h3>Value</h3>

<p>a named <code>list</code> with 5 data.tables:
tweets (contains all tweets and their meta-data),
referenced (information on referenced tweets),
urls (all urls mentioned in tweets),
mentions (other accounts mentioned in tweets),
hashtags (hashtags mentioned in tweets)
</p>

<hr>
<h2 id='preprocess_twitter_users'>preprocess_twitter_users</h2><span id='topic+preprocess_twitter_users'></span>

<h3>Description</h3>

<p>Reformat nested twitter user data (retrieved from Twitter v2 API).
Spreads out columns and reformats nested <code>data.table</code> to long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocess_twitter_users(users)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preprocess_twitter_users_+3A_users">users</code></td>
<td>
<p>a data.table with unformatted (nested user data).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Take the Twitter user data that you loaded with
<a href="#topic+load_twitter_users_json">load_twitter_users_json</a> and unnests the
following columns: <code>public_metrics</code> and <code>entities</code>.
</p>


<h3>Value</h3>

<p>a data.table with reformatted user data.
</p>

<hr>
<h2 id='remove_hashtags'>Remove hashtags</h2><span id='topic+remove_hashtags'></span>

<h3>Description</h3>

<p>Utility function that removes hashtags from tags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_hashtags(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_hashtags_+3A_x">x</code></td>
<td>
<p>The text to be processed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The text without hashtags.
</p>

<hr>
<h2 id='reshape_tweets'>reshape_tweets</h2><span id='topic+reshape_tweets'></span>

<h3>Description</h3>

<p>Reshape twitter data for coordination detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reshape_tweets(
  tweets,
  intent = c("retweets", "hashtags", "urls", "urls_domains", "cotweet"),
  drop_retweets = TRUE,
  drop_replies = TRUE,
  drop_hashtags = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reshape_tweets_+3A_tweets">tweets</code></td>
<td>
<p>a named list of Twitter data
(output of <a href="#topic+preprocess_tweets">preprocess_tweets</a>)</p>
</td></tr>
<tr><td><code id="reshape_tweets_+3A_intent">intent</code></td>
<td>
<p>the desired intent for analysis.</p>
</td></tr>
<tr><td><code id="reshape_tweets_+3A_drop_retweets">drop_retweets</code></td>
<td>
<p>Option passed to <code>intent = "cotweet"</code>.
When analysing tweets based on text similarity, you can choose to drop
all tweets that are retweets. Default: TRUE</p>
</td></tr>
<tr><td><code id="reshape_tweets_+3A_drop_replies">drop_replies</code></td>
<td>
<p>Option passed to <code>intent = "cotweet"</code>.
When analysing tweets based on text similarity, you can choose to drop
all tweets that are replies to other tweets. Default: TRUE</p>
</td></tr>
<tr><td><code id="reshape_tweets_+3A_drop_hashtags">drop_hashtags</code></td>
<td>
<p>Option passed to <code>intent = "cotweet"</code>. You can choose to
remove all hashtags from the tweet texts. Default: FALSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes the pre-processed Twitter data
(output of <a href="#topic+preprocess_tweets">preprocess_tweets</a>) and reshapes it
for coordination detection (<a href="#topic+detect_groups">detect_groups</a>).
You can choose the intent for reshaping the data. Use
<code>"retweets"</code> to detect coordinated retweeting behaviour;
<code>"hashtags"</code> for coordinated usage of hashtags;
<code>"urls"</code> to detect coordinated link sharing behaviour;
<code>"urls_domain"</code> to detect coordinated link sharing behaviour
at the domain level.
<code>"cotweet"</code> to detect coordinated cotweeting behaviour
(accounts posting same text).
The output of this function is a reshaped <code>data.table</code> that
can be passed to <a href="#topic+detect_groups">detect_groups</a>.
</p>


<h3>Value</h3>

<p>a reshaped data.table
</p>

<hr>
<h2 id='russian_coord_tweets'>Pro-Government Russian Tweet Dataset</h2><span id='topic+russian_coord_tweets'></span>

<h3>Description</h3>

<p>A anonymized dataset of Tweets.
All IDs have been obscured using sha256 algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>russian_coord_tweets
</code></pre>


<h3>Format</h3>



<h4><code>russian_coord_tweets</code></h4>

<p>A data frame with 35,125 rows and 4 columns:
</p>

<dl>
<dt>object_id</dt><dd><p>ID of retweeted content.
Twitter API calls this &quot;referenced_tweet_id&quot;.</p>
</dd>
<dt>account_id</dt><dd><p>ID of the user who tweeted. Twitter API: &quot;author_id&quot;</p>
</dd>
<dt>content_id</dt><dd><p>Tweet ID.</p>
</dd>
<dt>timestamp_share</dt><dd><p>Ingeger. Timestamp (posix time)</p>
</dd>
</dl>




<h3>Source</h3>

<p>Kulichkina (in Press).
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
