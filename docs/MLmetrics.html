<!DOCTYPE html><html><head><title>Help for package MLmetrics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MLmetrics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Accuracy'><p>Accuracy</p></a></li>
<li><a href='#Area_Under_Curve'><p>Calculate the Area Under the Curve</p></a></li>
<li><a href='#AUC'><p>Area Under the Receiver Operating Characteristic Curve (ROC AUC)</p></a></li>
<li><a href='#ConfusionDF'><p>Confusion Matrix (Data Frame Format)</p></a></li>
<li><a href='#ConfusionMatrix'><p>Confusion Matrix</p></a></li>
<li><a href='#F1_Score'><p>F1 Score</p></a></li>
<li><a href='#FBeta_Score'><p>F-Beta Score</p></a></li>
<li><a href='#GainAUC'><p>Area Under the Gain Chart</p></a></li>
<li><a href='#Gini'><p>Gini Coefficient</p></a></li>
<li><a href='#KS_Stat'><p>Kolmogorov-Smirnov Statistic</p></a></li>
<li><a href='#LiftAUC'><p>Area Under the Lift Chart</p></a></li>
<li><a href='#LogLoss'><p>Log loss / Cross-Entropy Loss</p></a></li>
<li><a href='#MAE'><p>Mean Absolute Error Loss</p></a></li>
<li><a href='#MAPE'><p>Mean Absolute Percentage Error Loss</p></a></li>
<li><a href='#MedianAE'><p>Median Absolute Error Loss</p></a></li>
<li><a href='#MedianAPE'><p>Median Absolute Percentage Error Loss</p></a></li>
<li><a href='#MLmetrics'><p>MLmetrics: Machine Learning Evaluation Metrics</p></a></li>
<li><a href='#MSE'><p>Mean Square Error Loss</p></a></li>
<li><a href='#MultiLogLoss'><p>Multi Class Log Loss</p></a></li>
<li><a href='#NormalizedGini'><p>Normalized Gini Coefficient</p></a></li>
<li><a href='#Poisson_LogLoss'><p>Poisson Log loss</p></a></li>
<li><a href='#PRAUC'><p>Area Under the Precision-Recall Curve (PR AUC)</p></a></li>
<li><a href='#Precision'><p>Precision</p></a></li>
<li><a href='#R2_Score'><p>R-Squared (Coefficient of Determination) Regression Score</p></a></li>
<li><a href='#RAE'><p>Relative Absolute Error Loss</p></a></li>
<li><a href='#Recall'><p>Recall</p></a></li>
<li><a href='#RMSE'><p>Root Mean Square Error Loss</p></a></li>
<li><a href='#RMSLE'><p>Root Mean Squared Logarithmic Error Loss</p></a></li>
<li><a href='#RMSPE'><p>Root Mean Square Percentage Error Loss</p></a></li>
<li><a href='#RRSE'><p>Root Relative Squared Error Loss</p></a></li>
<li><a href='#Sensitivity'><p>Sensitivity</p></a></li>
<li><a href='#Specificity'><p>Specificity</p></a></li>
<li><a href='#ZeroOneLoss'><p>Normalized Zero-One Loss (Classification Error Loss)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Machine Learning Evaluation Metrics</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of evaluation metrics, including loss, score and
    utility functions, that measure regression, classification and ranking performance.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://github.com/yanyachen/MLmetrics">http://github.com/yanyachen/MLmetrics</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/yanyachen/MLmetrics/issues">http://github.com/yanyachen/MLmetrics/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, ROCR</td>
</tr>
<tr>
<td>Suggests:</td>
<td>e1071</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-05-09 06:13:55 UTC; Administrator</td>
</tr>
<tr>
<td>Author:</td>
<td>Yachen Yan [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yachen Yan &lt;yanyachen21@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-05-13 23:57:26</td>
</tr>
</table>
<hr>
<h2 id='Accuracy'>Accuracy</h2><span id='topic+Accuracy'></span>

<h3>Description</h3>

<p>Compute the accuracy classification score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Accuracy(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Accuracy_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="Accuracy_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Accuracy
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
Accuracy(y_pred = pred, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='Area_Under_Curve'>Calculate the Area Under the Curve</h2><span id='topic+Area_Under_Curve'></span>

<h3>Description</h3>

<p>Calculate the area under the curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Area_Under_Curve(x, y, method = c("trapezoid", "step", "spline"),
  na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Area_Under_Curve_+3A_x">x</code></td>
<td>
<p>the x-points of the curve</p>
</td></tr>
<tr><td><code id="Area_Under_Curve_+3A_y">y</code></td>
<td>
<p>the y-points of the curve</p>
</td></tr>
<tr><td><code id="Area_Under_Curve_+3A_method">method</code></td>
<td>
<p>can be &quot;trapezoid&quot; (default), &quot;step&quot; or &quot;spline&quot;</p>
</td></tr>
<tr><td><code id="Area_Under_Curve_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether NA values should be stripped before the computation proceeds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Area Under the Curve (AUC)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0, pi, length.out = 200)
plot(x = x, y = sin(x), type = "l")
Area_Under_Curve(x = x, y = sin(x), method = "trapezoid", na.rm = TRUE)
</code></pre>

<hr>
<h2 id='AUC'>Area Under the Receiver Operating Characteristic Curve (ROC AUC)</h2><span id='topic+AUC'></span>

<h3>Description</h3>

<p>Compute the Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="AUC_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Area Under the ROC Curve (ROC AUC)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
AUC(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='ConfusionDF'>Confusion Matrix (Data Frame Format)</h2><span id='topic+ConfusionDF'></span>

<h3>Description</h3>

<p>Compute data frame format confusion matrix for internal usage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConfusionDF(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConfusionDF_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="ConfusionDF_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame of Confusion Matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
ConfusionDF(y_pred = pred, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='ConfusionMatrix'>Confusion Matrix</h2><span id='topic+ConfusionMatrix'></span>

<h3>Description</h3>

<p>Compute confusion matrix to evaluate the accuracy of a classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConfusionMatrix(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConfusionMatrix_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="ConfusionMatrix_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a table of Confusion Matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
ConfusionMatrix(y_pred = pred, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='F1_Score'>F1 Score</h2><span id='topic+F1_Score'></span>

<h3>Description</h3>

<p>Compute the F1 Score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F1_Score(y_true, y_pred, positive = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F1_Score_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
<tr><td><code id="F1_Score_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="F1_Score_+3A_positive">positive</code></td>
<td>
<p>An optional character string for the factor level that
corresponds to a &quot;positive&quot; result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>F1 Score
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
F1_Score(y_pred = pred, y_true = mtcars$vs, positive = "0")
F1_Score(y_pred = pred, y_true = mtcars$vs, positive = "1")
</code></pre>

<hr>
<h2 id='FBeta_Score'>F-Beta Score</h2><span id='topic+FBeta_Score'></span>

<h3>Description</h3>

<p>Compute the F-Beta Score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBeta_Score(y_true, y_pred, positive = NULL, beta = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBeta_Score_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
<tr><td><code id="FBeta_Score_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="FBeta_Score_+3A_positive">positive</code></td>
<td>
<p>An optional character string for the factor level that
corresponds to a &quot;positive&quot; result</p>
</td></tr>
<tr><td><code id="FBeta_Score_+3A_beta">beta</code></td>
<td>
<p>Weight of precision in harmonic mean</p>
</td></tr>
</table>


<h3>Value</h3>

<p>F-Beta Score
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
FBeta_Score(y_pred = pred, y_true = mtcars$vs, positive = "0", beta = 2)
FBeta_Score(y_pred = pred, y_true = mtcars$vs, positive = "1", beta = 2)
</code></pre>

<hr>
<h2 id='GainAUC'>Area Under the Gain Chart</h2><span id='topic+GainAUC'></span>

<h3>Description</h3>

<p>Compute the Area Under the Gain Chart from prediction scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GainAUC(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GainAUC_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="GainAUC_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Area Under the Gain Chart
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
GainAUC(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='Gini'>Gini Coefficient</h2><span id='topic+Gini'></span>

<h3>Description</h3>

<p>Compute the Gini Coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gini(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gini_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="Gini_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gini Coefficient
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
Gini(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='KS_Stat'>Kolmogorov-Smirnov Statistic</h2><span id='topic+KS_Stat'></span>

<h3>Description</h3>

<p>Compute the Kolmogorov-Smirnov statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KS_Stat(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KS_Stat_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="KS_Stat_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Kolmogorov-Smirnov statistic
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
KS_Stat(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='LiftAUC'>Area Under the Lift Chart</h2><span id='topic+LiftAUC'></span>

<h3>Description</h3>

<p>Compute the Area Under the Lift Chart from prediction scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LiftAUC(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LiftAUC_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="LiftAUC_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Area Under the Lift Chart
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
LiftAUC(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='LogLoss'>Log loss / Cross-Entropy Loss</h2><span id='topic+LogLoss'></span>

<h3>Description</h3>

<p>Compute the log loss/cross-entropy loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogLoss(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LogLoss_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="LogLoss_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log loss/Cross-Entropy Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
LogLoss(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='MAE'>Mean Absolute Error Loss</h2><span id='topic+MAE'></span>

<h3>Description</h3>

<p>Compute the mean absolute error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="MAE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Mean Absolute Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
MAE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='MAPE'>Mean Absolute Percentage Error Loss</h2><span id='topic+MAPE'></span>

<h3>Description</h3>

<p>Compute the mean absolute percentage error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAPE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAPE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="MAPE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Mean Absolute Percentage Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
MAPE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='MedianAE'>Median Absolute Error Loss</h2><span id='topic+MedianAE'></span>

<h3>Description</h3>

<p>Compute the median absolute error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MedianAE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MedianAE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="MedianAE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Median Absolute Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
MedianAE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='MedianAPE'>Median Absolute Percentage Error Loss</h2><span id='topic+MedianAPE'></span>

<h3>Description</h3>

<p>Compute the Median absolute percentage error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MedianAPE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MedianAPE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="MedianAPE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Median Absolute Percentage Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
MedianAPE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='MLmetrics'>MLmetrics: Machine Learning Evaluation Metrics</h2><span id='topic+MLmetrics'></span><span id='topic+MLmetrics-package'></span>

<h3>Description</h3>

<p>A collection of evaluation metrics, including loss, score and utility functions, 
that measure regression and classification performance.
</p>

<hr>
<h2 id='MSE'>Mean Square Error Loss</h2><span id='topic+MSE'></span>

<h3>Description</h3>

<p>Compute the mean squared error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="MSE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Mean Square Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
MSE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='MultiLogLoss'>Multi Class Log Loss</h2><span id='topic+MultiLogLoss'></span>

<h3>Description</h3>

<p>Compute the multi class log loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiLogLoss(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultiLogLoss_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities matrix, as returned by a classifier</p>
</td></tr>
<tr><td><code id="MultiLogLoss_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) labels vector or a matrix of
correct labels indicating by 0-1, same format as probabilities matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Multi Class Log Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
svm.model &lt;- e1071::svm(Species~., data = iris, probability = TRUE)
pred &lt;- predict(svm.model, iris, probability = TRUE)
MultiLogLoss(y_true = iris$Species, y_pred = attr(pred, "probabilities"))
</code></pre>

<hr>
<h2 id='NormalizedGini'>Normalized Gini Coefficient</h2><span id='topic+NormalizedGini'></span>

<h3>Description</h3>

<p>Compute the Normalized Gini Coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NormalizedGini(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NormalizedGini_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a model</p>
</td></tr>
<tr><td><code id="NormalizedGini_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Normalized Gini Coefficient
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d_AD &lt;- data.frame(treatment = gl(3,3), outcome = gl(3,1,9),
                   counts = c(18,17,15,20,10,20,25,13,12))
glm_poisson &lt;- glm(counts ~ outcome + treatment,
                   family = poisson(link = "log"), data = d_AD)
NormalizedGini(y_pred = glm_poisson$fitted.values, y_true = d_AD$counts)
</code></pre>

<hr>
<h2 id='Poisson_LogLoss'>Poisson Log loss</h2><span id='topic+Poisson_LogLoss'></span>

<h3>Description</h3>

<p>Compute the log loss/cross-entropy loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Poisson_LogLoss(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Poisson_LogLoss_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a model</p>
</td></tr>
<tr><td><code id="Poisson_LogLoss_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log loss/Cross-Entropy Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d_AD &lt;- data.frame(treatment = gl(3,3), outcome = gl(3,1,9),
                   counts = c(18,17,15,20,10,20,25,13,12))
glm_poisson &lt;- glm(counts ~ outcome + treatment,
                   family = poisson(link = "log"), data = d_AD)
Poisson_LogLoss(y_pred = glm_poisson$fitted.values, y_true = d_AD$counts)
</code></pre>

<hr>
<h2 id='PRAUC'>Area Under the Precision-Recall Curve (PR AUC)</h2><span id='topic+PRAUC'></span>

<h3>Description</h3>

<p>Compute the Area Under the Precision-Recall Curve (PR AUC) from prediction scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PRAUC(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PRAUC_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted probabilities vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="PRAUC_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Area Under the PR Curve (PR AUC)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
PRAUC(y_pred = logreg$fitted.values, y_true = mtcars$vs)
</code></pre>

<hr>
<h2 id='Precision'>Precision</h2><span id='topic+Precision'></span>

<h3>Description</h3>

<p>Compute the precision score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Precision(y_true, y_pred, positive = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Precision_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
<tr><td><code id="Precision_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="Precision_+3A_positive">positive</code></td>
<td>
<p>An optional character string for the factor level that
corresponds to a &quot;positive&quot; result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Precision
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
Precision(y_pred = pred, y_true = mtcars$vs, positive = "0")
Precision(y_pred = pred, y_true = mtcars$vs, positive = "1")
</code></pre>

<hr>
<h2 id='R2_Score'>R-Squared (Coefficient of Determination) Regression Score</h2><span id='topic+R2_Score'></span>

<h3>Description</h3>

<p>Compute the R-Squared (Coefficient of Determination) Regression Score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2_Score(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2_Score_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="R2_Score_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>R^2 Score
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
R2_Score(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='RAE'>Relative Absolute Error Loss</h2><span id='topic+RAE'></span>

<h3>Description</h3>

<p>Compute the relative absolute error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RAE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="RAE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Relative Absolute Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
RAE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='Recall'>Recall</h2><span id='topic+Recall'></span>

<h3>Description</h3>

<p>Compute the recall score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Recall(y_true, y_pred, positive = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Recall_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
<tr><td><code id="Recall_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="Recall_+3A_positive">positive</code></td>
<td>
<p>An optional character string for the factor level that
corresponds to a &quot;positive&quot; result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Recall
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
Recall(y_pred = pred, y_true = mtcars$vs, positive = "0")
Recall(y_pred = pred, y_true = mtcars$vs, positive = "1")
</code></pre>

<hr>
<h2 id='RMSE'>Root Mean Square Error Loss</h2><span id='topic+RMSE'></span>

<h3>Description</h3>

<p>Compute the root mean squared error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="RMSE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Root Mean Square Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
RMSE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='RMSLE'>Root Mean Squared Logarithmic Error Loss</h2><span id='topic+RMSLE'></span>

<h3>Description</h3>

<p>Compute the root mean squared logarithmic error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSLE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSLE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="RMSLE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Root Mean Squared Logarithmic Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
RMSLE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='RMSPE'>Root Mean Square Percentage Error Loss</h2><span id='topic+RMSPE'></span>

<h3>Description</h3>

<p>Compute the root mean squared percentage error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSPE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSPE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="RMSPE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Root Mean Squared Percentage Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
RMSPE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='RRSE'>Root Relative Squared Error Loss</h2><span id='topic+RRSE'></span>

<h3>Description</h3>

<p>Compute the root relative squared error regression loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RRSE(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RRSE_+3A_y_pred">y_pred</code></td>
<td>
<p>Estimated target values vector</p>
</td></tr>
<tr><td><code id="RRSE_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) target values vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Root Relative Squared Error Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
reg &lt;- lm(log(dist) ~ log(speed), data = cars)
RRSE(y_pred = exp(reg$fitted.values), y_true = cars$dist)
</code></pre>

<hr>
<h2 id='Sensitivity'>Sensitivity</h2><span id='topic+Sensitivity'></span>

<h3>Description</h3>

<p>Compute the sensitivity score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sensitivity(y_true, y_pred, positive = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sensitivity_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
<tr><td><code id="Sensitivity_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="Sensitivity_+3A_positive">positive</code></td>
<td>
<p>An optional character string for the factor level that
corresponds to a &quot;positive&quot; result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sensitivity
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
Sensitivity(y_pred = pred, y_true = mtcars$vs, positive = "0")
Sensitivity(y_pred = pred, y_true = mtcars$vs, positive = "1")
</code></pre>

<hr>
<h2 id='Specificity'>Specificity</h2><span id='topic+Specificity'></span>

<h3>Description</h3>

<p>Compute the specificity score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Specificity(y_true, y_pred, positive = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Specificity_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
<tr><td><code id="Specificity_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="Specificity_+3A_positive">positive</code></td>
<td>
<p>An optional character string for the factor level that
corresponds to a &quot;positive&quot; result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Specificity
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
Specificity(y_pred = pred, y_true = mtcars$vs, positive = "0")
Specificity(y_pred = pred, y_true = mtcars$vs, positive = "1")
</code></pre>

<hr>
<h2 id='ZeroOneLoss'>Normalized Zero-One Loss (Classification Error Loss)</h2><span id='topic+ZeroOneLoss'></span>

<h3>Description</h3>

<p>Compute the normalized zero-one classification loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ZeroOneLoss(y_pred, y_true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ZeroOneLoss_+3A_y_pred">y_pred</code></td>
<td>
<p>Predicted labels vector, as returned by a classifier</p>
</td></tr>
<tr><td><code id="ZeroOneLoss_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth (correct) 0-1 labels vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Zero-One Loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cars)
logreg &lt;- glm(formula = vs ~ hp + wt,
              family = binomial(link = "logit"), data = mtcars)
pred &lt;- ifelse(logreg$fitted.values &lt; 0.5, 0, 1)
ZeroOneLoss(y_pred = pred, y_true = mtcars$vs)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
