<!DOCTYPE html><html><head><title>Help for package DAP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DAP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dap-package'><p>Discriminant Analysis via Projections</p></a></li>
<li><a href='#apply_DAP'><p>Apply DAP for binary classification</p></a></li>
<li><a href='#classify_DAP'><p>Classification via DAP</p></a></li>
<li><a href='#cv_DAP'><p>Cross-validation for DAP</p></a></li>
<li><a href='#solve_DAP_C'><p>Solves DAP optimization problem for a given lambda value</p></a></li>
<li><a href='#solve_DAP_seq'><p>Solves DAP optimization problem for a given sequence of lambda values</p></a></li>
<li><a href='#standardizeData'><p>Divides the features matrix into two standardized submatrices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Discriminant Analysis via Projections</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-03-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Tianying Wang and Irina Gaynanova</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tianying Wang &lt;tianying@stat.tamu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of Discriminant Analysis via Projections (DAP) method for high-dimensional binary classification in the case of unequal covariance matrices. See Irina Gaynanova and Tianying Wang (2018) &lt;<a href="https://doi.org/10.48550/arXiv.1711.04817">doi:10.48550/arXiv.1711.04817</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, stats</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://github.com/irinagain/DAP">http://github.com/irinagain/DAP</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/irinagain/DAP/issues">http://github.com/irinagain/DAP/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-03-05 18:56:56 UTC; tianying</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-03-05 20:05:33 UTC</td>
</tr>
</table>
<hr>
<h2 id='dap-package'>Discriminant Analysis via Projections</h2><span id='topic+dap-package'></span>

<h3>Description</h3>

<p>This package provides tools for discriminant analysis on binary classification. It contains functions <code>apply_DAP, classify_DAP, cv_DAP, solve_DAP_C, solve_DAP, solve_DAP_seq</code> for implementing the method Discriminant Analysis via Projections.
</p>


<h3>Author(s)</h3>

<p>Irina Gaynanova and Tianying Wang.
</p>


<h3>References</h3>

<p>Gaynanova, I. and Wang, T. &quot;Sparse quadratic classification rules via linear dimension reduction&quot;. arxiv.org/abs/1711.04817 (2018+)
</p>

<hr>
<h2 id='apply_DAP'>Apply DAP for binary classification</h2><span id='topic+apply_DAP'></span>

<h3>Description</h3>

<p>Applies Discriminant Analysis via Projections to perform binary classification on the test dataset based on the training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply_DAP(xtrain, ytrain, xtest, ytest = NULL, lambda_seq = NULL,
  n_lambda = 50, maxmin_ratio = 0.1, nfolds = 5, eps = 1e-04,
  maxiter = 10000, myseed = 1001, prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply_DAP_+3A_xtrain">xtrain</code></td>
<td>
<p>A n x p training dataset; n observations on the rows and p features on the columns.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_ytrain">ytrain</code></td>
<td>
<p>A n vector of training group labels, either 1 or 2.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_xtest">xtest</code></td>
<td>
<p>A m x p testing dataset; m observations on the rows and p features on the columns.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_ytest">ytest</code></td>
<td>
<p>An optional m vector of testing group labels, either 1 or 2. If supplied,
the function returns misclassification error rate;
if <code>NULL</code>, the function returns predicted labels for <code>xtest</code>. 
Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_lambda_seq">lambda_seq</code></td>
<td>
<p>An optional sequence of tunning parameters lambda. Default is <code>NULL</code>, and the function generates its own sequence.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_n_lambda">n_lambda</code></td>
<td>
<p>Number of lambda values, the default is 50.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_maxmin_ratio">maxmin_ratio</code></td>
<td>
<p>Smallest value for lambda, as a fraction of maximal value for which all coefficients are zero. The default is 0.1.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for cross-validation, the default is 5.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold for the block-coordinate decent
algorithm based on the maximum element-wise change in <code class="reqn">V</code>. The
default is 1e-4.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations, the default is 10000.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_myseed">myseed</code></td>
<td>
<p>Optional specification of random seed for generating the folds, the default value is 1001.</p>
</td></tr>
<tr><td><code id="apply_DAP_+3A_prior">prior</code></td>
<td>
<p>A logical indicating whether to put larger weights to the groups of larger size; the default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no feature is selected by DAP, the function will return <code>error</code> of 0.5 and no <code>ypred</code>, indicating that the classifier is no better than random guessing.
</p>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>error</code></td>
<td>
<p>Misclassification error rate (if <code>ytest</code> is provided).</p>
</td></tr>
<tr><td><code>ypred</code></td>
<td>
<p>Predicted labels on the test set (if <code>ytest</code> is <code>NULL</code>).</p>
</td></tr>
<tr><td><code>features</code></td>
<td>
<p>Number of selected features.</p>
</td></tr>
<tr><td><code>feature_id</code></td>
<td>
<p>Index of selected features.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## This is an example for apply_DAP

## Generate data
n_train = 50
n_test = 50
p = 100
mu1 = rep(0, p)
mu2 = rep(3, p)
Sigma1 = diag(p)
Sigma2 = 0.5* diag(p)

## Build training data and test data
x1 = MASS::mvrnorm(n = n_train, mu = mu1, Sigma = Sigma1)
x2 = MASS::mvrnorm(n = n_train, mu = mu2, Sigma = Sigma2)
xtrain = rbind(x1, x2)
x1_test = MASS::mvrnorm(n = n_test, mu = mu1, Sigma = Sigma1)
x2_test = MASS::mvrnorm(n = n_test, mu = mu2, Sigma = Sigma2)
xtest = rbind(x1_test, x2_test)
ytrain = c(rep(1, n_train), rep(2, n_train))
ytest = c(rep(1, n_test), rep(2, n_test))

## Apply DAP

# Given ytest, the function will return a miclassification error rate.
ClassificationError = apply_DAP(xtrain, ytrain, xtest, ytest)

# Without ytest, the function will return predictions.
Ypredict = apply_DAP(xtrain, ytrain, xtest)
</code></pre>

<hr>
<h2 id='classify_DAP'>Classification via DAP</h2><span id='topic+classify_DAP'></span>

<h3>Description</h3>

<p>Classify observations in the test set using the supplied matrix V and the training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classify_DAP(xtrain, ytrain, xtest, V, prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classify_DAP_+3A_xtrain">xtrain</code></td>
<td>
<p>A n x p training dataset; n observations on the rows and p features on the columns.</p>
</td></tr>
<tr><td><code id="classify_DAP_+3A_ytrain">ytrain</code></td>
<td>
<p>A n vector of training group labels, either 1 or 2.</p>
</td></tr>
<tr><td><code id="classify_DAP_+3A_xtest">xtest</code></td>
<td>
<p>A m x p testing dataset; m observations on the rows and p features on the columns.</p>
</td></tr>
<tr><td><code id="classify_DAP_+3A_v">V</code></td>
<td>
<p>A p x 2 projection matrix.</p>
</td></tr>
<tr><td><code id="classify_DAP_+3A_prior">prior</code></td>
<td>
<p>A logical indicating whether to put larger weights to the groups of larger size; the default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predicted class labels for the test data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is an example for classify_DAP

## Generate data
n_train = 50
n_test = 50
p = 100
mu1 = rep(0, p)
mu2 = rep(3, p)
Sigma1 = diag(p)
Sigma2 = 0.5* diag(p)

## Build training data and test data
x1 = MASS::mvrnorm(n = n_train, mu = mu1, Sigma = Sigma1)
x2 = MASS::mvrnorm(n = n_train, mu = mu2, Sigma = Sigma2)
xtrain = rbind(x1, x2)
x1_test = MASS::mvrnorm(n = n_test, mu = mu1, Sigma = Sigma1)
x2_test = MASS::mvrnorm(n = n_test, mu = mu2, Sigma = Sigma2)
xtest = rbind(x1_test, x2_test)
ytrain = c(rep(1, n_train), rep(2, n_train))

# Standardize the data
out_s = standardizeData(xtrain, ytrain, center = FALSE)

## Find V
out.proj = solve_DAP_C(X1 = out_s$X1, X2 = out_s$X2, lambda = 0.3)
V = cbind(diag(1/out_s$coef1)%*%out.proj$V[,1],diag(1/out_s$coef2)%*% out.proj$V[,2])

# Predict y using classify_DAP
ypred = classify_DAP(xtrain, ytrain, xtest, V = V)

</code></pre>

<hr>
<h2 id='cv_DAP'>Cross-validation for DAP</h2><span id='topic+cv_DAP'></span>

<h3>Description</h3>

<p>Chooses optimal tuning parameter lambda for DAP based on the k-fold cross-validation to minimize the misclassification error rate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_DAP(X, Y, lambda_seq, nfolds = 5, eps = 1e-04, maxiter = 1000,
  myseed = 1001, prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_DAP_+3A_x">X</code></td>
<td>
<p>A n x p training dataset; n observations on the rows and p features on the columns.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_y">Y</code></td>
<td>
<p>A n vector of training group labels, either 1 or 2.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_lambda_seq">lambda_seq</code></td>
<td>
<p>A sequence of tuning parameters to choose from.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for cross-validation, the default is 5.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold for the block-coordinate decent algorithm based on the maximum element-wise change in <code class="reqn">V</code>. The default is 1e-4.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations, the default is 10000.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_myseed">myseed</code></td>
<td>
<p>Optional specification of random seed for generating the folds, the default value is 1001.</p>
</td></tr>
<tr><td><code id="cv_DAP_+3A_prior">prior</code></td>
<td>
<p>A logical indicating whether to put larger weights to the groups of larger size; the default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>lambda_seq</code></td>
<td>
<p>The sequence of tuning parameters used.</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>The mean cross-validated error rate - a vector of length <code>length(lambda_seq)</code></p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p>The estimated standard error vector corresponding to <code>cvm</code>.</p>
</td></tr>
<tr><td><code>lambda_min</code></td>
<td>
<p>Value of tuning parameter corresponding to the minimal error in <code>cvm</code>.</p>
</td></tr>
<tr><td><code>lambda_1se</code></td>
<td>
<p>The largest value of tuning parameter such that the correspondig error is within 1 standard error of the minimal error in <code>cvm</code>.</p>
</td></tr>
<tr><td><code>nfeature_mat</code></td>
<td>
<p>A <code>nfolds</code> x <code>length(lambda_seq)</code> matrix of the number of selected features.</p>
</td></tr>
<tr><td><code>error_mat</code></td>
<td>
<p>A <code>nfolds</code> x <code>length(lambda_seq)</code> matrix of the error rates.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## This is an example for cv_DAP

## Generate data
n_train = 50
n_test = 50
p = 100
mu1 = rep(0, p)
mu2 = rep(3, p)
Sigma1 = diag(p)
Sigma2 = 0.5* diag(p)

## Build training data
x1 = MASS::mvrnorm(n = n_train, mu = mu1, Sigma = Sigma1)
x2 = MASS::mvrnorm(n = n_train, mu = mu2, Sigma = Sigma2)
xtrain = rbind(x1, x2)
ytrain = c(rep(1, n_train), rep(2, n_train))

## Apply cv_DAP
fit = cv_DAP(X = xtrain, Y = ytrain, lambda_seq = c(0.2, 0.3, 0.5, 0.7, 0.9))
</code></pre>

<hr>
<h2 id='solve_DAP_C'>Solves DAP optimization problem for a given lambda value</h2><span id='topic+solve_DAP_C'></span>

<h3>Description</h3>

<p>Uses block-coordinate descent algorithm to solve DAP problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solve_DAP_C(X1, X2, lambda, Vinit = NULL, eps = 1e-04, maxiter = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="solve_DAP_C_+3A_x1">X1</code></td>
<td>
<p>A n1 x p matrix of group 1 data
(scaled).</p>
</td></tr>
<tr><td><code id="solve_DAP_C_+3A_x2">X2</code></td>
<td>
<p>A n2 x p matrix of group 2 data
(scaled).</p>
</td></tr>
<tr><td><code id="solve_DAP_C_+3A_lambda">lambda</code></td>
<td>
<p>A value of the tuning parameter lambda.</p>
</td></tr>
<tr><td><code id="solve_DAP_C_+3A_vinit">Vinit</code></td>
<td>
<p>Optional starting point, the default is NULL, and the algorithm starts with the matrix of zeros.</p>
</td></tr>
<tr><td><code id="solve_DAP_C_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold for the block-coordinate decent algorithm based on the maximum element-wise change in <code class="reqn">V</code>. The default is 1e-4.</p>
</td></tr>
<tr><td><code id="solve_DAP_C_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations, the default is 10000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>V</code></td>
<td>
<p>A p x 2 projection matrix to be used in DAP classification algorithm.</p>
</td></tr>
<tr><td><code>nfeature</code></td>
<td>
<p>Number of nonzero features.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations until convergence.</p>
</td></tr>
</table>


<h3>Warnings</h3>

<p>Please use scaled <code>X1</code> and <code>X2</code> for this function, they can be obtained using <code>standardizeData</code> to do so.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is an example for solve_DAP_C

## Generate data
n_train = 50
n_test = 50
p = 100
mu1 = rep(0, p)
mu2 = rep(3, p)
Sigma1 = diag(p)
Sigma2 = 0.5* diag(p)

## Build training data
x1 = MASS::mvrnorm(n = n_train, mu = mu1, Sigma = Sigma1)
x2 = MASS::mvrnorm(n = n_train, mu = mu2, Sigma = Sigma2)
xtrain = rbind(x1, x2)
ytrain = c(rep(1, n_train), rep(2, n_train))

## Standardize the data
out_s = standardizeData(xtrain, ytrain, center = FALSE)

## Apply solve_DAP_C
out = solve_DAP_C(X1 = out_s$X1, X2 = out_s$X2, lambda = 0.3)
</code></pre>

<hr>
<h2 id='solve_DAP_seq'>Solves DAP optimization problem for a given sequence of lambda values</h2><span id='topic+solve_DAP_seq'></span>

<h3>Description</h3>

<p>Uses block-coordinate descent algorithm with warm initializations, starts with the maximal supplied lambda value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solve_DAP_seq(X1, X2, lambda_seq, eps = 1e-04, maxiter = 10000,
  feature_max = nrow(X1) + nrow(X2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="solve_DAP_seq_+3A_x1">X1</code></td>
<td>
<p>A n1 x p matrix of group 1 data (scaled).</p>
</td></tr>
<tr><td><code id="solve_DAP_seq_+3A_x2">X2</code></td>
<td>
<p>A n2 x p matrix of group 2 data (scaled).</p>
</td></tr>
<tr><td><code id="solve_DAP_seq_+3A_lambda_seq">lambda_seq</code></td>
<td>
<p>A supplied sequence of tunning parameters.</p>
</td></tr>
<tr><td><code id="solve_DAP_seq_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold for the block-coordinate decent algorithm based on the maximum element-wise change in <code class="reqn">V</code>. The default is 1e-4.</p>
</td></tr>
<tr><td><code id="solve_DAP_seq_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations, the default is 10000.</p>
</td></tr>
<tr><td><code id="solve_DAP_seq_+3A_feature_max">feature_max</code></td>
<td>
<p>An upper bound on the number of nonzero features in the solution; the default value is the total sample size. The algorithm trims the supplied <code>lambda_seq</code> to eliminate solutions that exceed <code>feature_max</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>lambda_seq</code></td>
<td>
<p>A sequence of considered lambda values.</p>
</td></tr>
<tr><td><code>V1_mat</code></td>
<td>
<p>A p x m matrix with columns corresponding to the 1st projection vector V1 found at each lambda from <code>lambda_seq</code>.</p>
</td></tr>
<tr><td><code>V2_mat</code></td>
<td>
<p>A p x m matrix with columns corresponding to the 2nd projection vector V2 found at each lambda from <code>lambda_seq</code>.</p>
</td></tr>
<tr><td><code>nfeature_vec</code></td>
<td>
<p>A sequence of corresponding number of selected features for each value in <code>lambda_seq</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## This is an example for solve_DAP_seq

## Generate data
n_train = 50
n_test = 50
p = 100
mu1 = rep(0, p)
mu2 = rep(3, p)
Sigma1 = diag(p)
Sigma2 = 0.5* diag(p)

## Build training data
x1 = MASS::mvrnorm(n = n_train, mu = mu1, Sigma = Sigma1)
x2 = MASS::mvrnorm(n = n_train, mu = mu2, Sigma = Sigma2)
xtrain = rbind(x1, x2)
ytrain = c(rep(1, n_train), rep(2, n_train))

## Standardize the data
out_s = standardizeData(xtrain, ytrain, center = FALSE)

####use solve_proj_seq
fit = solve_DAP_seq(X1 = out_s$X1, X2 = out_s$X2, lambda_seq = c(0.2, 0.3, 0.5, 0.7, 0.9))
</code></pre>

<hr>
<h2 id='standardizeData'>Divides the features matrix into two standardized submatrices</h2><span id='topic+standardizeData'></span>

<h3>Description</h3>

<p>Given matrix <code>X</code> with corresponding class labels in <code>Y</code>, the function column-centers <code>X</code>, divides it into two submatrices corresponding to each class, and scales the columns of each submatrix to have eucledean norm equal to one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardizeData(X, Y, center = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardizeData_+3A_x">X</code></td>
<td>
<p>A n x p training dataset; n observations on the rows and p features on the columns.</p>
</td></tr>
<tr><td><code id="standardizeData_+3A_y">Y</code></td>
<td>
<p>A n vector of training group labels, either 1 or 2.</p>
</td></tr>
<tr><td><code id="standardizeData_+3A_center">center</code></td>
<td>
<p>A logical indicating whether <code>X</code> should be centered, the default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>X1</code></td>
<td>
<p>A n1 x p standardized matrix with observations from group 1.</p>
</td></tr>
<tr><td><code>X2</code></td>
<td>
<p>A n2 x p standardized matrix with observations from group 2.</p>
</td></tr>
<tr><td><code>coef1</code></td>
<td>
<p>Back-scaling coefficients for <code>X1</code>.</p>
</td></tr>
<tr><td><code>coef2</code></td>
<td>
<p>Back-scaling coefficients for <code>X2</code>.</p>
</td></tr>
<tr><td><code>Xmean</code></td>
<td>
<p>Column means of the matrix <code>X</code> before centering.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># An example for the function standardizeData

## Generate data
n_train = 50
n_test = 50
p = 100
mu1 = rep(0, p)
mu2 = rep(3, p)
Sigma1 = diag(p)
Sigma2 = 0.5* diag(p)

## Build training data
x1 = MASS::mvrnorm(n = n_train, mu = mu1, Sigma = Sigma1)
x2 = MASS::mvrnorm(n = n_train, mu = mu2, Sigma = Sigma2)
xtrain = rbind(x1, x2)
ytrain = c(rep(1, n_train), rep(2, n_train))

## Standardize data
out_s = standardizeData(xtrain, ytrain, center = FALSE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
